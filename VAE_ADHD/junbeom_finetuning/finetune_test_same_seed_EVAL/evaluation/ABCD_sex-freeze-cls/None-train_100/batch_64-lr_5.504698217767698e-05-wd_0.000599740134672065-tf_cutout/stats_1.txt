"main_optuna_fix_2.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 5.504698217767698e-05 --weight_decay 0.000599740134672065 --BN inst"
{"epoch": 0, "training_loss": 70.44694828987122, "training_acc": 47.0, "val_loss": 17.494098842144012, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.13523840904236, "training_acc": 47.0, "val_loss": 17.434078454971313, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.77124047279358, "training_acc": 47.0, "val_loss": 17.391513288021088, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.69174122810364, "training_acc": 47.0, "val_loss": 17.35953986644745, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.44373273849487, "training_acc": 47.0, "val_loss": 17.3390731215477, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3148124217987, "training_acc": 48.0, "val_loss": 17.324675619602203, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.25767946243286, "training_acc": 53.0, "val_loss": 17.314673960208893, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15373253822327, "training_acc": 53.0, "val_loss": 17.309798300266266, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18305540084839, "training_acc": 53.0, "val_loss": 17.309269309043884, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1598904132843, "training_acc": 53.0, "val_loss": 17.31218546628952, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12680888175964, "training_acc": 53.0, "val_loss": 17.317017912864685, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13358497619629, "training_acc": 53.0, "val_loss": 17.32289046049118, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11300015449524, "training_acc": 53.0, "val_loss": 17.328333854675293, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16320157051086, "training_acc": 53.0, "val_loss": 17.33335703611374, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18782424926758, "training_acc": 53.0, "val_loss": 17.339099943637848, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17580723762512, "training_acc": 53.0, "val_loss": 17.342665791511536, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1607186794281, "training_acc": 53.0, "val_loss": 17.346177995204926, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20694375038147, "training_acc": 53.0, "val_loss": 17.346425354480743, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22821927070618, "training_acc": 53.0, "val_loss": 17.341910302639008, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16307091712952, "training_acc": 53.0, "val_loss": 17.33766496181488, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22023797035217, "training_acc": 53.0, "val_loss": 17.332759499549866, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16467261314392, "training_acc": 53.0, "val_loss": 17.33107715845108, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1332323551178, "training_acc": 53.0, "val_loss": 17.328956723213196, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16386461257935, "training_acc": 53.0, "val_loss": 17.326991260051727, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13759589195251, "training_acc": 53.0, "val_loss": 17.32623279094696, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14090847969055, "training_acc": 53.0, "val_loss": 17.323899269104004, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14137601852417, "training_acc": 53.0, "val_loss": 17.32179820537567, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17942714691162, "training_acc": 53.0, "val_loss": 17.318858206272125, "val_acc": 52.0}
