"main_optuna_fix_2.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 1.050531802303288e-05 --weight_decay 1.6467213137570964e-09 --BN inst"
{"epoch": 0, "training_loss": 69.2033703327179, "training_acc": 53.0, "val_loss": 17.38404631614685, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.31243371963501, "training_acc": 53.0, "val_loss": 17.390428483486176, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.21930384635925, "training_acc": 53.0, "val_loss": 17.38530695438385, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.04319739341736, "training_acc": 53.0, "val_loss": 17.37159639596939, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.0652027130127, "training_acc": 53.0, "val_loss": 17.35195517539978, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.81082201004028, "training_acc": 53.0, "val_loss": 17.380166053771973, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.92780351638794, "training_acc": 53.0, "val_loss": 17.35605150461197, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.63559436798096, "training_acc": 53.0, "val_loss": 17.348910868167877, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.57541584968567, "training_acc": 53.0, "val_loss": 17.405489087104797, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.59859943389893, "training_acc": 53.0, "val_loss": 17.46007353067398, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.70592522621155, "training_acc": 53.0, "val_loss": 17.400047183036804, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.64060974121094, "training_acc": 53.0, "val_loss": 17.362916469573975, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.62133693695068, "training_acc": 53.0, "val_loss": 17.36445426940918, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.35905003547668, "training_acc": 53.0, "val_loss": 17.408324778079987, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.43129968643188, "training_acc": 53.0, "val_loss": 17.44282841682434, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.32446360588074, "training_acc": 53.0, "val_loss": 17.393220961093903, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.83238220214844, "training_acc": 53.0, "val_loss": 17.3308864235878, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.80268979072571, "training_acc": 54.0, "val_loss": 17.323780059814453, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.20713877677917, "training_acc": 54.0, "val_loss": 17.337964475154877, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.9508798122406, "training_acc": 58.0, "val_loss": 17.386677861213684, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.06538438796997, "training_acc": 56.0, "val_loss": 17.480240762233734, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.17641496658325, "training_acc": 54.0, "val_loss": 17.374086380004883, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.52499437332153, "training_acc": 59.0, "val_loss": 17.526431381702423, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.87463212013245, "training_acc": 55.0, "val_loss": 17.34287291765213, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.37455725669861, "training_acc": 69.0, "val_loss": 17.561252415180206, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.46245574951172, "training_acc": 60.0, "val_loss": 17.299212515354156, "val_acc": 52.0}
{"epoch": 26, "training_loss": 65.3392345905304, "training_acc": 72.0, "val_loss": 17.527559399604797, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.01404309272766, "training_acc": 62.0, "val_loss": 17.302139103412628, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.22522521018982, "training_acc": 77.0, "val_loss": 17.730556428432465, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.50499248504639, "training_acc": 65.0, "val_loss": 17.690810561180115, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.08905935287476, "training_acc": 67.0, "val_loss": 17.20363199710846, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.20192074775696, "training_acc": 77.0, "val_loss": 17.88748949766159, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.06773209571838, "training_acc": 56.0, "val_loss": 17.73661971092224, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.04833579063416, "training_acc": 53.0, "val_loss": 17.58784055709839, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.60569047927856, "training_acc": 72.0, "val_loss": 17.237955331802368, "val_acc": 52.0}
{"epoch": 35, "training_loss": 65.62685561180115, "training_acc": 74.0, "val_loss": 17.7652969956398, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.47741389274597, "training_acc": 61.0, "val_loss": 17.79993623495102, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.65532755851746, "training_acc": 57.0, "val_loss": 17.215244472026825, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.74055051803589, "training_acc": 74.0, "val_loss": 17.43415743112564, "val_acc": 52.0}
{"epoch": 39, "training_loss": 63.32887315750122, "training_acc": 81.0, "val_loss": 17.76745915412903, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.57089972496033, "training_acc": 70.0, "val_loss": 17.62845814228058, "val_acc": 52.0}
{"epoch": 41, "training_loss": 63.610371112823486, "training_acc": 74.0, "val_loss": 17.57575422525406, "val_acc": 52.0}
{"epoch": 42, "training_loss": 63.98493027687073, "training_acc": 71.0, "val_loss": 17.657682299613953, "val_acc": 52.0}
{"epoch": 43, "training_loss": 62.740161657333374, "training_acc": 74.0, "val_loss": 17.386282980442047, "val_acc": 52.0}
{"epoch": 44, "training_loss": 61.50604510307312, "training_acc": 72.0, "val_loss": 18.115928769111633, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.374751329422, "training_acc": 70.0, "val_loss": 17.96019822359085, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.777965784072876, "training_acc": 73.0, "val_loss": 17.41700768470764, "val_acc": 52.0}
{"epoch": 47, "training_loss": 60.02751564979553, "training_acc": 82.0, "val_loss": 18.302394449710846, "val_acc": 52.0}
{"epoch": 48, "training_loss": 60.54192280769348, "training_acc": 79.0, "val_loss": 17.748835682868958, "val_acc": 52.0}
{"epoch": 49, "training_loss": 60.644814252853394, "training_acc": 77.0, "val_loss": 17.533285915851593, "val_acc": 52.0}
