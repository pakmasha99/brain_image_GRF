"main_optuna_fix_2.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 0.017484892311713827 --weight_decay 4.8567180166065447e-08 --BN none"
{"epoch": 0, "training_loss": 1901.154884338379, "training_acc": 41.0, "val_loss": 3.886605422889575e+22, "val_acc": 48.0}
{"epoch": 1, "training_loss": 8.479312526578536e+22, "training_acc": 59.0, "val_loss": 9566125600.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 31192285440.0, "training_acc": 51.0, "val_loss": 3439637600.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 9333265896.0, "training_acc": 47.0, "val_loss": 258318050.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 571919320.4746094, "training_acc": 56.0, "val_loss": 4196914400.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 25959130496.0, "training_acc": 51.0, "val_loss": 607127400.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 3492471232.0, "training_acc": 49.0, "val_loss": 730824300.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 9450316800.0, "training_acc": 53.0, "val_loss": 822550700.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72319431424.0, "training_acc": 55.0, "val_loss": 4907733200.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 181829685248.0, "training_acc": 49.0, "val_loss": 23543344000.0, "val_acc": 52.0}
{"epoch": 10, "training_loss": 58141350496.0, "training_acc": 53.0, "val_loss": 443705150.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2715925024.0, "training_acc": 55.0, "val_loss": 2486062200.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 8371694320.0, "training_acc": 47.0, "val_loss": 102103156.25, "val_acc": 52.0}
{"epoch": 13, "training_loss": 31231143872.0, "training_acc": 53.0, "val_loss": 10295625600.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 71038242304.0, "training_acc": 47.0, "val_loss": 1079764800.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2347211573.5, "training_acc": 59.0, "val_loss": 89430668.75, "val_acc": 52.0}
{"epoch": 16, "training_loss": 362266000.0, "training_acc": 53.0, "val_loss": 36631131.25, "val_acc": 52.0}
{"epoch": 17, "training_loss": 108824903.3125, "training_acc": 53.0, "val_loss": 82201568.75, "val_acc": 48.0}
{"epoch": 18, "training_loss": 201478175.96875, "training_acc": 47.0, "val_loss": 13821392000.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 34174500291.0, "training_acc": 60.0, "val_loss": 672629000.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1653543921.0, "training_acc": 55.0, "val_loss": 344402675.0, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2367063424.0, "training_acc": 41.0, "val_loss": 197960187.5, "val_acc": 48.0}
{"epoch": 22, "training_loss": 737176314.0, "training_acc": 47.0, "val_loss": 92205456.25, "val_acc": 48.0}
{"epoch": 23, "training_loss": 288672890.0, "training_acc": 47.0, "val_loss": 16983331.25, "val_acc": 52.0}
{"epoch": 24, "training_loss": 54766089.875, "training_acc": 59.0, "val_loss": 15362142.1875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 55397613.25, "training_acc": 53.0, "val_loss": 1959277.5390625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 19111467.0, "training_acc": 49.0, "val_loss": 3792255.46875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 42092546.75, "training_acc": 51.0, "val_loss": 2859646.875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 7363557.6875, "training_acc": 55.0, "val_loss": 939428.7109375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2938079.78125, "training_acc": 53.0, "val_loss": 1001950.9765625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3014852.734375, "training_acc": 53.0, "val_loss": 2392898.4375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 8319970.0625, "training_acc": 47.0, "val_loss": 358682.7392578125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1366372.4921875, "training_acc": 53.0, "val_loss": 959847.94921875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3518407.765625, "training_acc": 47.0, "val_loss": 693917.041015625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2579047.5234375, "training_acc": 53.0, "val_loss": 241828.3447265625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1245714.515625, "training_acc": 43.0, "val_loss": 227793.4326171875, "val_acc": 48.0}
{"epoch": 36, "training_loss": 896704.7421875, "training_acc": 49.0, "val_loss": 108386.90185546875, "val_acc": 48.0}
{"epoch": 37, "training_loss": 728159.30859375, "training_acc": 52.0, "val_loss": 127013.232421875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1152120.8359375, "training_acc": 57.0, "val_loss": 691975.0, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2380942.4375, "training_acc": 43.0, "val_loss": 41525.9521484375, "val_acc": 52.0}
{"epoch": 40, "training_loss": 656391.83203125, "training_acc": 53.0, "val_loss": 198973.4375, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1564529.90625, "training_acc": 49.0, "val_loss": 847874.12109375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 2656589.9140625, "training_acc": 53.0, "val_loss": 1039208.10546875, "val_acc": 48.0}
{"epoch": 43, "training_loss": 10230858.3125, "training_acc": 41.0, "val_loss": 1939053.125, "val_acc": 48.0}
{"epoch": 44, "training_loss": 7527077.59375, "training_acc": 47.0, "val_loss": 738634.86328125, "val_acc": 48.0}
{"epoch": 45, "training_loss": 2632135.875, "training_acc": 49.0, "val_loss": 1135511.328125, "val_acc": 52.0}
{"epoch": 46, "training_loss": 3654986.7890625, "training_acc": 53.0, "val_loss": 867264.94140625, "val_acc": 48.0}
{"epoch": 47, "training_loss": 2514715.37109375, "training_acc": 47.0, "val_loss": 849281.93359375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 3250481.7734375, "training_acc": 53.0, "val_loss": 366259.4970703125, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1427352.51953125, "training_acc": 45.0, "val_loss": 295342.3583984375, "val_acc": 48.0}
{"epoch": 50, "training_loss": 809318.146484375, "training_acc": 53.0, "val_loss": 96526.84326171875, "val_acc": 52.0}
{"epoch": 51, "training_loss": 424132.435546875, "training_acc": 53.0, "val_loss": 44275.50048828125, "val_acc": 48.0}
{"epoch": 52, "training_loss": 435863.1640625, "training_acc": 54.0, "val_loss": 368619.921875, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1206083.51953125, "training_acc": 53.0, "val_loss": 168465.90576171875, "val_acc": 48.0}
{"epoch": 54, "training_loss": 760083.80078125, "training_acc": 47.0, "val_loss": 46928.06396484375, "val_acc": 48.0}
{"epoch": 55, "training_loss": 406639.71484375, "training_acc": 57.0, "val_loss": 389533.642578125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1402904.1015625, "training_acc": 53.0, "val_loss": 42201.86767578125, "val_acc": 52.0}
{"epoch": 57, "training_loss": 697450.1796875, "training_acc": 44.0, "val_loss": 462155.56640625, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1657031.84765625, "training_acc": 47.0, "val_loss": 35307.43713378906, "val_acc": 52.0}
{"epoch": 59, "training_loss": 166067.74609375, "training_acc": 53.0, "val_loss": 63627.685546875, "val_acc": 48.0}
{"epoch": 60, "training_loss": 317205.39453125, "training_acc": 47.0, "val_loss": 43125.0, "val_acc": 48.0}
{"epoch": 61, "training_loss": 259677.296875, "training_acc": 49.0, "val_loss": 31632.968139648438, "val_acc": 48.0}
{"epoch": 62, "training_loss": 169199.5888671875, "training_acc": 52.0, "val_loss": 75567.3583984375, "val_acc": 48.0}
{"epoch": 63, "training_loss": 375810.037109375, "training_acc": 43.0, "val_loss": 20495.29266357422, "val_acc": 48.0}
{"epoch": 64, "training_loss": 192638.6064453125, "training_acc": 41.0, "val_loss": 95764.77661132812, "val_acc": 48.0}
{"epoch": 65, "training_loss": 257501.15258789062, "training_acc": 48.0, "val_loss": 220153.1494140625, "val_acc": 52.0}
{"epoch": 66, "training_loss": 888898.76171875, "training_acc": 53.0, "val_loss": 58531.35986328125, "val_acc": 52.0}
{"epoch": 67, "training_loss": 676262.3515625, "training_acc": 47.0, "val_loss": 415410.546875, "val_acc": 48.0}
{"epoch": 68, "training_loss": 1481249.453125, "training_acc": 47.0, "val_loss": 40444.07653808594, "val_acc": 52.0}
{"epoch": 69, "training_loss": 250992.56640625, "training_acc": 53.0, "val_loss": 93205.98754882812, "val_acc": 52.0}
{"epoch": 70, "training_loss": 371066.5615234375, "training_acc": 51.0, "val_loss": 103389.35546875, "val_acc": 48.0}
{"epoch": 71, "training_loss": 431967.37890625, "training_acc": 43.0, "val_loss": 86111.74926757812, "val_acc": 52.0}
{"epoch": 72, "training_loss": 379381.375, "training_acc": 45.0, "val_loss": 42932.928466796875, "val_acc": 48.0}
{"epoch": 73, "training_loss": 345737.314453125, "training_acc": 47.0, "val_loss": 190214.00146484375, "val_acc": 52.0}
{"epoch": 74, "training_loss": 571237.5283203125, "training_acc": 53.0, "val_loss": 174396.337890625, "val_acc": 48.0}
{"epoch": 75, "training_loss": 796793.0703125, "training_acc": 47.0, "val_loss": 139363.720703125, "val_acc": 48.0}
{"epoch": 76, "training_loss": 479155.673828125, "training_acc": 51.0, "val_loss": 185230.322265625, "val_acc": 52.0}
{"epoch": 77, "training_loss": 649858.7578125, "training_acc": 53.0, "val_loss": 49799.44763183594, "val_acc": 48.0}
{"epoch": 78, "training_loss": 238691.865234375, "training_acc": 47.0, "val_loss": 63260.321044921875, "val_acc": 52.0}
{"epoch": 79, "training_loss": 267961.927734375, "training_acc": 53.0, "val_loss": 60464.92919921875, "val_acc": 48.0}
{"epoch": 80, "training_loss": 210357.6357421875, "training_acc": 47.0, "val_loss": 111872.27783203125, "val_acc": 52.0}
{"epoch": 81, "training_loss": 456526.283203125, "training_acc": 53.0, "val_loss": 16257.058715820312, "val_acc": 52.0}
{"epoch": 82, "training_loss": 349800.96875, "training_acc": 50.0, "val_loss": 273653.0029296875, "val_acc": 48.0}
{"epoch": 83, "training_loss": 962593.5625, "training_acc": 47.0, "val_loss": 23274.769592285156, "val_acc": 52.0}
{"epoch": 84, "training_loss": 175382.4033203125, "training_acc": 53.0, "val_loss": 45930.975341796875, "val_acc": 52.0}
{"epoch": 85, "training_loss": 365931.12109375, "training_acc": 41.0, "val_loss": 117065.68603515625, "val_acc": 48.0}
{"epoch": 86, "training_loss": 311692.75, "training_acc": 52.0, "val_loss": 36486.43798828125, "val_acc": 52.0}
{"epoch": 87, "training_loss": 161524.4775390625, "training_acc": 53.0, "val_loss": 15389.360046386719, "val_acc": 48.0}
{"epoch": 88, "training_loss": 202485.041015625, "training_acc": 49.0, "val_loss": 111316.1376953125, "val_acc": 52.0}
{"epoch": 89, "training_loss": 286502.3840332031, "training_acc": 54.0, "val_loss": 199025.84228515625, "val_acc": 48.0}
{"epoch": 90, "training_loss": 879510.82421875, "training_acc": 47.0, "val_loss": 182459.33837890625, "val_acc": 48.0}
{"epoch": 91, "training_loss": 454463.2957763672, "training_acc": 50.0, "val_loss": 84363.98315429688, "val_acc": 52.0}
{"epoch": 92, "training_loss": 314027.8916015625, "training_acc": 53.0, "val_loss": 75338.28125, "val_acc": 48.0}
{"epoch": 93, "training_loss": 350111.728515625, "training_acc": 47.0, "val_loss": 15785.867309570312, "val_acc": 52.0}
{"epoch": 94, "training_loss": 60356.299072265625, "training_acc": 50.0, "val_loss": 17869.05975341797, "val_acc": 48.0}
{"epoch": 95, "training_loss": 149839.6298828125, "training_acc": 48.0, "val_loss": 57048.980712890625, "val_acc": 52.0}
{"epoch": 96, "training_loss": 219636.4638671875, "training_acc": 53.0, "val_loss": 46183.52966308594, "val_acc": 48.0}
{"epoch": 97, "training_loss": 158354.41357421875, "training_acc": 57.0, "val_loss": 76777.38037109375, "val_acc": 52.0}
{"epoch": 98, "training_loss": 200878.32495117188, "training_acc": 48.0, "val_loss": 65068.75, "val_acc": 48.0}
{"epoch": 99, "training_loss": 181785.65551757812, "training_acc": 47.0, "val_loss": 139378.21044921875, "val_acc": 52.0}
{"epoch": 100, "training_loss": 602688.05859375, "training_acc": 53.0, "val_loss": 126617.8466796875, "val_acc": 52.0}
{"epoch": 101, "training_loss": 438608.70947265625, "training_acc": 41.0, "val_loss": 48057.77282714844, "val_acc": 48.0}
{"epoch": 102, "training_loss": 184950.5693359375, "training_acc": 51.0, "val_loss": 42177.12707519531, "val_acc": 52.0}
{"epoch": 103, "training_loss": 172569.548828125, "training_acc": 53.0, "val_loss": 39049.92980957031, "val_acc": 48.0}
{"epoch": 104, "training_loss": 259867.4296875, "training_acc": 43.0, "val_loss": 94631.46362304688, "val_acc": 52.0}
{"epoch": 105, "training_loss": 237328.31420898438, "training_acc": 53.0, "val_loss": 171678.84521484375, "val_acc": 48.0}
{"epoch": 106, "training_loss": 770217.6953125, "training_acc": 47.0, "val_loss": 172583.53271484375, "val_acc": 48.0}
