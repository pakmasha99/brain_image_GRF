"main_optuna_fix_2.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 0.25463017943043054 --weight_decay 0.23019943315376581 --BN inst --foreach False"
{"epoch": 0, "training_loss": 1352.8826446533203, "training_acc": 40.0, "val_loss": 608.2940101623535, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1828.0399589538574, "training_acc": 72.0, "val_loss": 567.8905010223389, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1957.5744590759277, "training_acc": 28.0, "val_loss": 162.52343654632568, "val_acc": 72.0}
{"epoch": 3, "training_loss": 916.3792266845703, "training_acc": 72.0, "val_loss": 338.8197898864746, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1266.786075592041, "training_acc": 72.0, "val_loss": 133.37528705596924, "val_acc": 72.0}
{"epoch": 5, "training_loss": 659.4445877075195, "training_acc": 50.0, "val_loss": 41.54329597949982, "val_acc": 28.0}
{"epoch": 6, "training_loss": 389.4180507659912, "training_acc": 40.0, "val_loss": 239.07651901245117, "val_acc": 72.0}
{"epoch": 7, "training_loss": 959.3772125244141, "training_acc": 72.0, "val_loss": 184.1332197189331, "val_acc": 72.0}
{"epoch": 8, "training_loss": 580.0141000747681, "training_acc": 72.0, "val_loss": 194.14730072021484, "val_acc": 28.0}
{"epoch": 9, "training_loss": 722.4211521148682, "training_acc": 28.0, "val_loss": 97.52874374389648, "val_acc": 72.0}
{"epoch": 10, "training_loss": 492.2477970123291, "training_acc": 72.0, "val_loss": 198.31918478012085, "val_acc": 72.0}
{"epoch": 11, "training_loss": 740.8188171386719, "training_acc": 72.0, "val_loss": 78.77107858657837, "val_acc": 72.0}
{"epoch": 12, "training_loss": 316.40985107421875, "training_acc": 60.0, "val_loss": 43.454813957214355, "val_acc": 28.0}
{"epoch": 13, "training_loss": 298.00975608825684, "training_acc": 42.0, "val_loss": 176.44246816635132, "val_acc": 72.0}
{"epoch": 14, "training_loss": 717.9322242736816, "training_acc": 72.0, "val_loss": 123.53851795196533, "val_acc": 72.0}
{"epoch": 15, "training_loss": 337.6324863433838, "training_acc": 72.0, "val_loss": 285.26556491851807, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1078.6540718078613, "training_acc": 28.0, "val_loss": 44.680944085121155, "val_acc": 72.0}
{"epoch": 17, "training_loss": 263.9156036376953, "training_acc": 72.0, "val_loss": 124.64383840560913, "val_acc": 72.0}
{"epoch": 18, "training_loss": 442.1648235321045, "training_acc": 72.0, "val_loss": 15.399502217769623, "val_acc": 40.0}
{"epoch": 19, "training_loss": 141.45552158355713, "training_acc": 66.0, "val_loss": 35.24094820022583, "val_acc": 72.0}
{"epoch": 20, "training_loss": 160.99771690368652, "training_acc": 72.0, "val_loss": 14.834637939929962, "val_acc": 72.0}
{"epoch": 21, "training_loss": 95.72789859771729, "training_acc": 62.0, "val_loss": 63.57455849647522, "val_acc": 72.0}
{"epoch": 22, "training_loss": 312.6952610015869, "training_acc": 72.0, "val_loss": 48.053184151649475, "val_acc": 72.0}
{"epoch": 23, "training_loss": 254.128155708313, "training_acc": 58.0, "val_loss": 16.205666959285736, "val_acc": 72.0}
{"epoch": 24, "training_loss": 70.9913375377655, "training_acc": 72.0, "val_loss": 15.080426633358002, "val_acc": 72.0}
{"epoch": 25, "training_loss": 71.06379675865173, "training_acc": 72.0, "val_loss": 84.04683470726013, "val_acc": 28.0}
{"epoch": 26, "training_loss": 310.25017070770264, "training_acc": 42.0, "val_loss": 79.71436381340027, "val_acc": 72.0}
{"epoch": 27, "training_loss": 270.8126220703125, "training_acc": 72.0, "val_loss": 80.75254559516907, "val_acc": 28.0}
{"epoch": 28, "training_loss": 246.40932083129883, "training_acc": 44.0, "val_loss": 31.64398968219757, "val_acc": 72.0}
{"epoch": 29, "training_loss": 124.00305843353271, "training_acc": 58.0, "val_loss": 48.532843589782715, "val_acc": 72.0}
{"epoch": 30, "training_loss": 224.10309028625488, "training_acc": 72.0, "val_loss": 17.6141619682312, "val_acc": 28.0}
{"epoch": 31, "training_loss": 104.39830732345581, "training_acc": 30.0, "val_loss": 88.69548439979553, "val_acc": 72.0}
{"epoch": 32, "training_loss": 396.7140884399414, "training_acc": 72.0, "val_loss": 104.57373857498169, "val_acc": 72.0}
{"epoch": 33, "training_loss": 321.8514142036438, "training_acc": 72.0, "val_loss": 178.41870784759521, "val_acc": 28.0}
{"epoch": 34, "training_loss": 567.7794332504272, "training_acc": 28.0, "val_loss": 132.0414900779724, "val_acc": 72.0}
{"epoch": 35, "training_loss": 669.6655387878418, "training_acc": 72.0, "val_loss": 244.18072700500488, "val_acc": 72.0}
{"epoch": 36, "training_loss": 928.2081089019775, "training_acc": 72.0, "val_loss": 129.6457052230835, "val_acc": 72.0}
{"epoch": 37, "training_loss": 355.3353199958801, "training_acc": 72.0, "val_loss": 284.43663120269775, "val_acc": 28.0}
{"epoch": 38, "training_loss": 1056.971866607666, "training_acc": 28.0, "val_loss": 68.98211240768433, "val_acc": 72.0}
{"epoch": 39, "training_loss": 413.8261528015137, "training_acc": 72.0, "val_loss": 176.97356939315796, "val_acc": 72.0}
