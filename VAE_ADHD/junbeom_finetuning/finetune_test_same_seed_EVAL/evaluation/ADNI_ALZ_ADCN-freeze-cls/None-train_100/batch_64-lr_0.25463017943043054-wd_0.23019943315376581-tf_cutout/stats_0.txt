"main_optuna_fix_2.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 0.25463017943043054 --weight_decay 0.23019943315376581 --BN inst --foreach False"
{"epoch": 0, "training_loss": 1244.1180267333984, "training_acc": 42.0, "val_loss": 611.6930484771729, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1820.722068786621, "training_acc": 72.0, "val_loss": 627.5522232055664, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2225.4318771362305, "training_acc": 28.0, "val_loss": 137.92251348495483, "val_acc": 72.0}
{"epoch": 3, "training_loss": 781.3336219787598, "training_acc": 72.0, "val_loss": 343.3478832244873, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1304.7110786437988, "training_acc": 72.0, "val_loss": 176.67897939682007, "val_acc": 72.0}
{"epoch": 5, "training_loss": 634.6252222061157, "training_acc": 48.0, "val_loss": 19.56952065229416, "val_acc": 72.0}
{"epoch": 6, "training_loss": 76.02928185462952, "training_acc": 56.0, "val_loss": 42.12979078292847, "val_acc": 72.0}
{"epoch": 7, "training_loss": 146.47286200523376, "training_acc": 72.0, "val_loss": 16.25809073448181, "val_acc": 72.0}
{"epoch": 8, "training_loss": 77.26270484924316, "training_acc": 58.0, "val_loss": 74.54556822776794, "val_acc": 72.0}
{"epoch": 9, "training_loss": 293.6713547706604, "training_acc": 72.0, "val_loss": 24.165964126586914, "val_acc": 72.0}
{"epoch": 10, "training_loss": 327.87376976013184, "training_acc": 56.0, "val_loss": 14.967004954814911, "val_acc": 72.0}
{"epoch": 11, "training_loss": 159.30969715118408, "training_acc": 72.0, "val_loss": 94.26771402359009, "val_acc": 72.0}
{"epoch": 12, "training_loss": 305.82477140426636, "training_acc": 72.0, "val_loss": 153.9896845817566, "val_acc": 28.0}
{"epoch": 13, "training_loss": 400.50063037872314, "training_acc": 28.0, "val_loss": 148.25702905654907, "val_acc": 72.0}
{"epoch": 14, "training_loss": 732.2301177978516, "training_acc": 72.0, "val_loss": 231.0178279876709, "val_acc": 72.0}
{"epoch": 15, "training_loss": 836.9743728637695, "training_acc": 72.0, "val_loss": 69.86624002456665, "val_acc": 72.0}
{"epoch": 16, "training_loss": 416.9532051086426, "training_acc": 60.0, "val_loss": 162.4921202659607, "val_acc": 28.0}
{"epoch": 17, "training_loss": 463.18820667266846, "training_acc": 50.0, "val_loss": 155.11915683746338, "val_acc": 72.0}
{"epoch": 18, "training_loss": 661.5373573303223, "training_acc": 72.0, "val_loss": 125.66132545471191, "val_acc": 72.0}
{"epoch": 19, "training_loss": 396.71249413490295, "training_acc": 72.0, "val_loss": 252.70402431488037, "val_acc": 28.0}
{"epoch": 20, "training_loss": 859.9315280914307, "training_acc": 28.0, "val_loss": 112.34921216964722, "val_acc": 72.0}
{"epoch": 21, "training_loss": 638.3728637695312, "training_acc": 72.0, "val_loss": 232.46498107910156, "val_acc": 72.0}
{"epoch": 22, "training_loss": 874.025972366333, "training_acc": 72.0, "val_loss": 107.41680860519409, "val_acc": 72.0}
{"epoch": 23, "training_loss": 380.0995931625366, "training_acc": 54.0, "val_loss": 16.092917323112488, "val_acc": 28.0}
{"epoch": 24, "training_loss": 117.56170463562012, "training_acc": 72.0, "val_loss": 45.695215463638306, "val_acc": 72.0}
{"epoch": 25, "training_loss": 156.72379875183105, "training_acc": 58.0, "val_loss": 39.33061063289642, "val_acc": 72.0}
{"epoch": 26, "training_loss": 141.4404261112213, "training_acc": 72.0, "val_loss": 70.48119306564331, "val_acc": 28.0}
{"epoch": 27, "training_loss": 262.84221172332764, "training_acc": 44.0, "val_loss": 77.8590977191925, "val_acc": 72.0}
{"epoch": 28, "training_loss": 261.1995677947998, "training_acc": 72.0, "val_loss": 103.91029119491577, "val_acc": 28.0}
{"epoch": 29, "training_loss": 303.99282360076904, "training_acc": 44.0, "val_loss": 35.2232962846756, "val_acc": 72.0}
