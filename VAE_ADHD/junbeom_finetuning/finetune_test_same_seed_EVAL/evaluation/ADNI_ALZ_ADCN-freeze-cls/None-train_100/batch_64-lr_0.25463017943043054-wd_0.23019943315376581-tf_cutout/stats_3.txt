"main_optuna_fix_2.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 0.25463017943043054 --weight_decay 0.23019943315376581 --BN inst --foreach False"
{"epoch": 0, "training_loss": 916.1021003723145, "training_acc": 48.0, "val_loss": 634.412145614624, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1814.7479286193848, "training_acc": 72.0, "val_loss": 728.6884784698486, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2553.814956665039, "training_acc": 28.0, "val_loss": 129.63824272155762, "val_acc": 72.0}
{"epoch": 3, "training_loss": 776.9676704406738, "training_acc": 72.0, "val_loss": 328.6677360534668, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1236.8144187927246, "training_acc": 72.0, "val_loss": 138.36017847061157, "val_acc": 72.0}
{"epoch": 5, "training_loss": 556.1799621582031, "training_acc": 54.0, "val_loss": 16.869837045669556, "val_acc": 28.0}
{"epoch": 6, "training_loss": 188.93699645996094, "training_acc": 72.0, "val_loss": 96.4900255203247, "val_acc": 72.0}
{"epoch": 7, "training_loss": 294.9446258544922, "training_acc": 72.0, "val_loss": 215.58926105499268, "val_acc": 28.0}
{"epoch": 8, "training_loss": 625.0795278549194, "training_acc": 28.0, "val_loss": 166.73684120178223, "val_acc": 72.0}
{"epoch": 9, "training_loss": 809.0246849060059, "training_acc": 72.0, "val_loss": 292.9429292678833, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1119.8256301879883, "training_acc": 72.0, "val_loss": 168.43339204788208, "val_acc": 72.0}
{"epoch": 11, "training_loss": 455.9382185935974, "training_acc": 72.0, "val_loss": 342.0123100280762, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1383.1593055725098, "training_acc": 28.0, "val_loss": 17.66984909772873, "val_acc": 28.0}
{"epoch": 13, "training_loss": 300.60602951049805, "training_acc": 42.0, "val_loss": 243.78235340118408, "val_acc": 72.0}
{"epoch": 14, "training_loss": 990.366756439209, "training_acc": 72.0, "val_loss": 217.62759685516357, "val_acc": 72.0}
{"epoch": 15, "training_loss": 746.0495662689209, "training_acc": 72.0, "val_loss": 15.27920514345169, "val_acc": 52.0}
{"epoch": 16, "training_loss": 312.8076877593994, "training_acc": 60.0, "val_loss": 61.66148781776428, "val_acc": 28.0}
{"epoch": 17, "training_loss": 397.09280014038086, "training_acc": 42.0, "val_loss": 241.84565544128418, "val_acc": 72.0}
{"epoch": 18, "training_loss": 988.938060760498, "training_acc": 72.0, "val_loss": 235.158371925354, "val_acc": 72.0}
{"epoch": 19, "training_loss": 832.0861282348633, "training_acc": 72.0, "val_loss": 42.369720339775085, "val_acc": 72.0}
{"epoch": 20, "training_loss": 582.9903182983398, "training_acc": 52.0, "val_loss": 265.26620388031006, "val_acc": 28.0}
{"epoch": 21, "training_loss": 683.1331980228424, "training_acc": 48.0, "val_loss": 106.31805658340454, "val_acc": 72.0}
{"epoch": 22, "training_loss": 438.8728542327881, "training_acc": 72.0, "val_loss": 80.33270239830017, "val_acc": 72.0}
{"epoch": 23, "training_loss": 206.41852927207947, "training_acc": 72.0, "val_loss": 132.4229121208191, "val_acc": 28.0}
{"epoch": 24, "training_loss": 402.3781123161316, "training_acc": 42.0, "val_loss": 55.91664910316467, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.89945936203003, "training_acc": 72.0, "val_loss": 121.23156785964966, "val_acc": 28.0}
{"epoch": 26, "training_loss": 322.9034581184387, "training_acc": 48.0, "val_loss": 47.88447320461273, "val_acc": 72.0}
{"epoch": 27, "training_loss": 167.13987016677856, "training_acc": 72.0, "val_loss": 32.0611447095871, "val_acc": 28.0}
{"epoch": 28, "training_loss": 186.0455493927002, "training_acc": 44.0, "val_loss": 92.41739511489868, "val_acc": 72.0}
{"epoch": 29, "training_loss": 327.3781623840332, "training_acc": 72.0, "val_loss": 61.782634258270264, "val_acc": 28.0}
{"epoch": 30, "training_loss": 187.4653673171997, "training_acc": 44.0, "val_loss": 18.336986005306244, "val_acc": 72.0}
{"epoch": 31, "training_loss": 145.3605089187622, "training_acc": 54.0, "val_loss": 72.04329371452332, "val_acc": 72.0}
{"epoch": 32, "training_loss": 323.95526599884033, "training_acc": 72.0, "val_loss": 77.67624258995056, "val_acc": 72.0}
{"epoch": 33, "training_loss": 320.25943756103516, "training_acc": 44.0, "val_loss": 42.62368679046631, "val_acc": 72.0}
{"epoch": 34, "training_loss": 165.72098684310913, "training_acc": 72.0, "val_loss": 47.71318733692169, "val_acc": 28.0}
