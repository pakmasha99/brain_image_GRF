"main_optuna_fix_2.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --save_path finetune_test_same_seed_EVAL --binary_class True --batch_size 64 --eval_mode True --learning_rate 0.7959121369946751 --weight_decay 2.095952457066269e-05 --BN none --foreach True"
{"epoch": 0, "training_loss": 1407.127342224121, "training_acc": 72.0, "val_loss": 632.0192813873291, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1869.117244720459, "training_acc": 72.0, "val_loss": 810.3118896484375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2966.4076919555664, "training_acc": 28.0, "val_loss": 63.004070520401, "val_acc": 56.0}
{"epoch": 3, "training_loss": 668.5664367675781, "training_acc": 66.0, "val_loss": 506.04419708251953, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1986.7235107421875, "training_acc": 72.0, "val_loss": 523.9726543426514, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1810.1773567199707, "training_acc": 72.0, "val_loss": 183.9320182800293, "val_acc": 72.0}
{"epoch": 6, "training_loss": 661.6173572540283, "training_acc": 65.0, "val_loss": 304.81674671173096, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1359.2132415771484, "training_acc": 44.0, "val_loss": 122.9084849357605, "val_acc": 56.0}
{"epoch": 8, "training_loss": 564.0572481155396, "training_acc": 69.0, "val_loss": 239.20564651489258, "val_acc": 72.0}
{"epoch": 9, "training_loss": 978.7026748657227, "training_acc": 72.0, "val_loss": 210.09533405303955, "val_acc": 72.0}
{"epoch": 10, "training_loss": 581.4131183624268, "training_acc": 74.0, "val_loss": 113.33181858062744, "val_acc": 56.0}
{"epoch": 11, "training_loss": 851.7756118774414, "training_acc": 52.0, "val_loss": 166.14388227462769, "val_acc": 52.0}
{"epoch": 12, "training_loss": 452.4614324569702, "training_acc": 59.0, "val_loss": 200.88717937469482, "val_acc": 72.0}
{"epoch": 13, "training_loss": 740.9446659088135, "training_acc": 72.0, "val_loss": 255.87255954742432, "val_acc": 72.0}
{"epoch": 14, "training_loss": 810.3513221740723, "training_acc": 72.0, "val_loss": 52.50404477119446, "val_acc": 72.0}
{"epoch": 15, "training_loss": 323.7640075683594, "training_acc": 66.0, "val_loss": 159.89311933517456, "val_acc": 40.0}
{"epoch": 16, "training_loss": 432.01053857803345, "training_acc": 53.0, "val_loss": 136.64182424545288, "val_acc": 72.0}
{"epoch": 17, "training_loss": 496.1100158691406, "training_acc": 72.0, "val_loss": 108.45010280609131, "val_acc": 72.0}
{"epoch": 18, "training_loss": 292.86442041397095, "training_acc": 71.0, "val_loss": 98.39770197868347, "val_acc": 60.0}
{"epoch": 19, "training_loss": 319.56256198883057, "training_acc": 57.0, "val_loss": 65.91468453407288, "val_acc": 72.0}
{"epoch": 20, "training_loss": 257.84244537353516, "training_acc": 75.0, "val_loss": 68.97007822990417, "val_acc": 72.0}
{"epoch": 21, "training_loss": 267.812970161438, "training_acc": 58.0, "val_loss": 73.59832525253296, "val_acc": 48.0}
{"epoch": 22, "training_loss": 199.74775552749634, "training_acc": 61.0, "val_loss": 76.94140672683716, "val_acc": 72.0}
{"epoch": 23, "training_loss": 174.1247991323471, "training_acc": 74.0, "val_loss": 70.45714259147644, "val_acc": 44.0}
{"epoch": 24, "training_loss": 167.05074548721313, "training_acc": 58.0, "val_loss": 44.308021664619446, "val_acc": 68.0}
{"epoch": 25, "training_loss": 128.3266887664795, "training_acc": 69.0, "val_loss": 39.340633153915405, "val_acc": 68.0}
{"epoch": 26, "training_loss": 81.6421799659729, "training_acc": 83.0, "val_loss": 38.1850391626358, "val_acc": 64.0}
{"epoch": 27, "training_loss": 80.33972454071045, "training_acc": 77.0, "val_loss": 48.02045822143555, "val_acc": 60.0}
{"epoch": 28, "training_loss": 113.0058045387268, "training_acc": 72.0, "val_loss": 54.53936457633972, "val_acc": 76.0}
{"epoch": 29, "training_loss": 112.26228284835815, "training_acc": 75.0, "val_loss": 40.3950959444046, "val_acc": 60.0}
{"epoch": 30, "training_loss": 62.57561707496643, "training_acc": 78.0, "val_loss": 40.899866819381714, "val_acc": 60.0}
{"epoch": 31, "training_loss": 55.37044644355774, "training_acc": 79.0, "val_loss": 68.4190571308136, "val_acc": 72.0}
{"epoch": 32, "training_loss": 104.84516787528992, "training_acc": 75.0, "val_loss": 80.42446970939636, "val_acc": 32.0}
{"epoch": 33, "training_loss": 146.11028909683228, "training_acc": 61.0, "val_loss": 56.853705644607544, "val_acc": 68.0}
{"epoch": 34, "training_loss": 123.7753438949585, "training_acc": 63.0, "val_loss": 76.98732018470764, "val_acc": 72.0}
{"epoch": 35, "training_loss": 171.32569122314453, "training_acc": 72.0, "val_loss": 42.390742897987366, "val_acc": 60.0}
{"epoch": 36, "training_loss": 92.16714382171631, "training_acc": 70.0, "val_loss": 40.64768850803375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 82.3990421295166, "training_acc": 77.0, "val_loss": 42.197173833847046, "val_acc": 64.0}
{"epoch": 38, "training_loss": 73.08373236656189, "training_acc": 80.0, "val_loss": 42.43067800998688, "val_acc": 56.0}
{"epoch": 39, "training_loss": 137.3423547744751, "training_acc": 70.0, "val_loss": 72.61298894882202, "val_acc": 72.0}
{"epoch": 40, "training_loss": 112.87252831459045, "training_acc": 72.0, "val_loss": 46.60967290401459, "val_acc": 48.0}
{"epoch": 41, "training_loss": 102.8907117843628, "training_acc": 71.0, "val_loss": 76.9182562828064, "val_acc": 72.0}
{"epoch": 42, "training_loss": 100.14976751804352, "training_acc": 79.0, "val_loss": 75.53251385688782, "val_acc": 40.0}
{"epoch": 43, "training_loss": 173.9117546081543, "training_acc": 62.0, "val_loss": 75.76754689216614, "val_acc": 72.0}
{"epoch": 44, "training_loss": 144.05728220939636, "training_acc": 76.0, "val_loss": 43.90248358249664, "val_acc": 60.0}
{"epoch": 45, "training_loss": 100.26716160774231, "training_acc": 68.0, "val_loss": 55.231255292892456, "val_acc": 76.0}
{"epoch": 46, "training_loss": 119.15708804130554, "training_acc": 78.0, "val_loss": 26.952049136161804, "val_acc": 72.0}
{"epoch": 47, "training_loss": 48.30195593833923, "training_acc": 84.0, "val_loss": 24.979305267333984, "val_acc": 76.0}
{"epoch": 48, "training_loss": 31.992488265037537, "training_acc": 86.0, "val_loss": 25.36250650882721, "val_acc": 72.0}
{"epoch": 49, "training_loss": 50.427836894989014, "training_acc": 78.0, "val_loss": 36.28606200218201, "val_acc": 76.0}
{"epoch": 50, "training_loss": 49.05211925506592, "training_acc": 81.0, "val_loss": 31.34072721004486, "val_acc": 52.0}
{"epoch": 51, "training_loss": 30.82698082923889, "training_acc": 86.0, "val_loss": 28.451740741729736, "val_acc": 80.0}
{"epoch": 52, "training_loss": 30.41549849510193, "training_acc": 88.0, "val_loss": 27.659079432487488, "val_acc": 68.0}
{"epoch": 53, "training_loss": 36.0858119726181, "training_acc": 86.0, "val_loss": 30.87865710258484, "val_acc": 68.0}
{"epoch": 54, "training_loss": 37.84319996833801, "training_acc": 84.0, "val_loss": 32.60592222213745, "val_acc": 76.0}
{"epoch": 55, "training_loss": 30.164103388786316, "training_acc": 86.0, "val_loss": 30.64030408859253, "val_acc": 60.0}
{"epoch": 56, "training_loss": 36.47357201576233, "training_acc": 84.0, "val_loss": 60.147517919540405, "val_acc": 72.0}
{"epoch": 57, "training_loss": 84.72550666332245, "training_acc": 81.0, "val_loss": 84.98396873474121, "val_acc": 40.0}
{"epoch": 58, "training_loss": 187.69482517242432, "training_acc": 57.0, "val_loss": 61.19949221611023, "val_acc": 72.0}
{"epoch": 59, "training_loss": 86.9582142829895, "training_acc": 76.0, "val_loss": 48.14395010471344, "val_acc": 64.0}
{"epoch": 60, "training_loss": 107.49810409545898, "training_acc": 72.0, "val_loss": 53.154951333999634, "val_acc": 76.0}
{"epoch": 61, "training_loss": 98.35532355308533, "training_acc": 80.0, "val_loss": 47.76201546192169, "val_acc": 60.0}
{"epoch": 62, "training_loss": 83.81721341609955, "training_acc": 74.0, "val_loss": 42.62924790382385, "val_acc": 76.0}
{"epoch": 63, "training_loss": 79.84285950660706, "training_acc": 82.0, "val_loss": 39.895498752593994, "val_acc": 48.0}
{"epoch": 64, "training_loss": 61.238718926906586, "training_acc": 78.0, "val_loss": 60.35131812095642, "val_acc": 72.0}
{"epoch": 65, "training_loss": 141.399573802948, "training_acc": 72.0, "val_loss": 135.2797508239746, "val_acc": 44.0}
{"epoch": 66, "training_loss": 308.3596135377884, "training_acc": 51.0, "val_loss": 87.98481822013855, "val_acc": 72.0}
