"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.7071807384491, "training_acc": 57.0, "val_loss": 18.617460131645203, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.93095803260803, "training_acc": 54.0, "val_loss": 18.61005127429962, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.3959047794342, "training_acc": 55.0, "val_loss": 18.47565770149231, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.99725770950317, "training_acc": 55.0, "val_loss": 18.44630241394043, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.73641777038574, "training_acc": 52.0, "val_loss": 18.502244353294373, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0679349899292, "training_acc": 51.0, "val_loss": 18.55776011943817, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.33156752586365, "training_acc": 56.0, "val_loss": 18.558460474014282, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.47714185714722, "training_acc": 53.0, "val_loss": 18.58079433441162, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.05228471755981, "training_acc": 57.0, "val_loss": 18.686668574810028, "val_acc": 52.0}
{"epoch": 9, "training_loss": 67.6568832397461, "training_acc": 55.0, "val_loss": 18.759621679782867, "val_acc": 52.0}
{"epoch": 10, "training_loss": 67.79406785964966, "training_acc": 58.0, "val_loss": 18.8765749335289, "val_acc": 52.0}
{"epoch": 11, "training_loss": 67.94421672821045, "training_acc": 59.0, "val_loss": 19.020046293735504, "val_acc": 52.0}
{"epoch": 12, "training_loss": 67.31737184524536, "training_acc": 61.0, "val_loss": 19.144733250141144, "val_acc": 52.0}
{"epoch": 13, "training_loss": 67.0262234210968, "training_acc": 63.0, "val_loss": 19.166934490203857, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.23885202407837, "training_acc": 59.0, "val_loss": 19.061069190502167, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.59383654594421, "training_acc": 60.0, "val_loss": 18.866553902626038, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.53203964233398, "training_acc": 61.0, "val_loss": 18.75694841146469, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.41102910041809, "training_acc": 60.0, "val_loss": 18.72028261423111, "val_acc": 52.0}
{"epoch": 18, "training_loss": 66.54694533348083, "training_acc": 60.0, "val_loss": 18.684488534927368, "val_acc": 52.0}
{"epoch": 19, "training_loss": 66.8701982498169, "training_acc": 61.0, "val_loss": 18.617835640907288, "val_acc": 52.0}
{"epoch": 20, "training_loss": 66.42486047744751, "training_acc": 62.0, "val_loss": 18.57423335313797, "val_acc": 52.0}
{"epoch": 21, "training_loss": 66.5019793510437, "training_acc": 60.0, "val_loss": 18.53480637073517, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.87489795684814, "training_acc": 56.0, "val_loss": 18.555903434753418, "val_acc": 52.0}
