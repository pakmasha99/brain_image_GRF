"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 75.14715766906738, "training_acc": 42.0, "val_loss": 18.381492793560028, "val_acc": 56.0}
{"epoch": 1, "training_loss": 75.33762979507446, "training_acc": 45.0, "val_loss": 16.72358512878418, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.80611801147461, "training_acc": 48.0, "val_loss": 16.893604397773743, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.14373779296875, "training_acc": 49.0, "val_loss": 17.1938419342041, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.89232039451599, "training_acc": 51.0, "val_loss": 16.94156974554062, "val_acc": 60.0}
{"epoch": 5, "training_loss": 68.20187520980835, "training_acc": 62.0, "val_loss": 16.990762948989868, "val_acc": 60.0}
{"epoch": 6, "training_loss": 68.10949182510376, "training_acc": 58.0, "val_loss": 17.06078052520752, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.15457963943481, "training_acc": 53.0, "val_loss": 17.164143919944763, "val_acc": 52.0}
{"epoch": 8, "training_loss": 67.82961511611938, "training_acc": 61.0, "val_loss": 17.194825410842896, "val_acc": 52.0}
{"epoch": 9, "training_loss": 67.61740350723267, "training_acc": 57.0, "val_loss": 17.09968000650406, "val_acc": 52.0}
{"epoch": 10, "training_loss": 66.6421639919281, "training_acc": 59.0, "val_loss": 17.068712413311005, "val_acc": 52.0}
{"epoch": 11, "training_loss": 67.02407550811768, "training_acc": 64.0, "val_loss": 17.36583709716797, "val_acc": 52.0}
{"epoch": 12, "training_loss": 67.82115173339844, "training_acc": 63.0, "val_loss": 17.42534637451172, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.01759791374207, "training_acc": 55.0, "val_loss": 17.492972314357758, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.04145050048828, "training_acc": 62.0, "val_loss": 17.361770570278168, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.80108332633972, "training_acc": 63.0, "val_loss": 17.01657474040985, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.0481345653534, "training_acc": 59.0, "val_loss": 16.95249080657959, "val_acc": 52.0}
{"epoch": 17, "training_loss": 66.60695934295654, "training_acc": 63.0, "val_loss": 17.31887012720108, "val_acc": 52.0}
{"epoch": 18, "training_loss": 65.83004355430603, "training_acc": 68.0, "val_loss": 17.229051887989044, "val_acc": 52.0}
{"epoch": 19, "training_loss": 65.73850154876709, "training_acc": 63.0, "val_loss": 17.25965142250061, "val_acc": 52.0}
{"epoch": 20, "training_loss": 65.5497875213623, "training_acc": 62.0, "val_loss": 17.379947006702423, "val_acc": 52.0}
