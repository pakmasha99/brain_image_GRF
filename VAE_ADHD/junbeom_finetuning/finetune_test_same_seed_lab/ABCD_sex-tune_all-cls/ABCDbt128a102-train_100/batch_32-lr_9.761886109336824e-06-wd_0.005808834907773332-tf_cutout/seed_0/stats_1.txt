"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 75.14441013336182, "training_acc": 42.0, "val_loss": 18.38001161813736, "val_acc": 56.0}
{"epoch": 1, "training_loss": 75.36083889007568, "training_acc": 45.0, "val_loss": 16.65499210357666, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.74856519699097, "training_acc": 48.0, "val_loss": 16.900573670864105, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.15484046936035, "training_acc": 49.0, "val_loss": 17.227694392204285, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.89632415771484, "training_acc": 50.0, "val_loss": 16.96932166814804, "val_acc": 60.0}
{"epoch": 5, "training_loss": 68.21961736679077, "training_acc": 62.0, "val_loss": 17.03246235847473, "val_acc": 60.0}
{"epoch": 6, "training_loss": 68.22999954223633, "training_acc": 60.0, "val_loss": 17.114536464214325, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.24075078964233, "training_acc": 53.0, "val_loss": 17.232918739318848, "val_acc": 52.0}
{"epoch": 8, "training_loss": 67.83394312858582, "training_acc": 59.0, "val_loss": 17.283111810684204, "val_acc": 52.0}
{"epoch": 9, "training_loss": 67.68179941177368, "training_acc": 57.0, "val_loss": 17.234501242637634, "val_acc": 52.0}
{"epoch": 10, "training_loss": 66.90949726104736, "training_acc": 60.0, "val_loss": 17.11650788784027, "val_acc": 52.0}
{"epoch": 11, "training_loss": 67.47569274902344, "training_acc": 62.0, "val_loss": 17.222219705581665, "val_acc": 52.0}
{"epoch": 12, "training_loss": 66.53708863258362, "training_acc": 66.0, "val_loss": 17.077907919883728, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66.25954627990723, "training_acc": 62.0, "val_loss": 17.127856612205505, "val_acc": 52.0}
{"epoch": 14, "training_loss": 66.55087399482727, "training_acc": 58.0, "val_loss": 17.11544543504715, "val_acc": 52.0}
{"epoch": 15, "training_loss": 65.53243017196655, "training_acc": 63.0, "val_loss": 16.934524476528168, "val_acc": 52.0}
{"epoch": 16, "training_loss": 65.12785005569458, "training_acc": 61.0, "val_loss": 16.924819350242615, "val_acc": 52.0}
{"epoch": 17, "training_loss": 64.90931487083435, "training_acc": 63.0, "val_loss": 17.030805349349976, "val_acc": 52.0}
{"epoch": 18, "training_loss": 64.70145750045776, "training_acc": 66.0, "val_loss": 17.187440395355225, "val_acc": 52.0}
{"epoch": 19, "training_loss": 64.35291147232056, "training_acc": 60.0, "val_loss": 17.29256361722946, "val_acc": 52.0}
{"epoch": 20, "training_loss": 63.933329582214355, "training_acc": 65.0, "val_loss": 17.52813309431076, "val_acc": 48.0}
