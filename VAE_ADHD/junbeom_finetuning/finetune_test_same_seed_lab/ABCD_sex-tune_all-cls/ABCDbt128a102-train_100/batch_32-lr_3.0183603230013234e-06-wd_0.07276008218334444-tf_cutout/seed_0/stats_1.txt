"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 72.96453285217285, "training_acc": 49.0, "val_loss": 19.178679585456848, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.51649975776672, "training_acc": 52.0, "val_loss": 18.762071430683136, "val_acc": 48.0}
{"epoch": 2, "training_loss": 69.95306873321533, "training_acc": 51.0, "val_loss": 18.46330016851425, "val_acc": 48.0}
{"epoch": 3, "training_loss": 68.34850311279297, "training_acc": 54.0, "val_loss": 18.516242504119873, "val_acc": 48.0}
{"epoch": 4, "training_loss": 66.88888168334961, "training_acc": 58.0, "val_loss": 18.683476746082306, "val_acc": 52.0}
{"epoch": 5, "training_loss": 65.74814629554749, "training_acc": 61.0, "val_loss": 18.742530047893524, "val_acc": 56.0}
{"epoch": 6, "training_loss": 64.34946346282959, "training_acc": 63.0, "val_loss": 18.79931539297104, "val_acc": 52.0}
{"epoch": 7, "training_loss": 64.66666030883789, "training_acc": 62.0, "val_loss": 18.78640651702881, "val_acc": 52.0}
{"epoch": 8, "training_loss": 64.45224189758301, "training_acc": 61.0, "val_loss": 18.721164762973785, "val_acc": 48.0}
{"epoch": 9, "training_loss": 64.66952538490295, "training_acc": 67.0, "val_loss": 18.78904700279236, "val_acc": 48.0}
{"epoch": 10, "training_loss": 64.06374931335449, "training_acc": 64.0, "val_loss": 18.79628896713257, "val_acc": 48.0}
{"epoch": 11, "training_loss": 64.38789796829224, "training_acc": 65.0, "val_loss": 18.70138943195343, "val_acc": 48.0}
{"epoch": 12, "training_loss": 63.84806489944458, "training_acc": 66.0, "val_loss": 18.399785459041595, "val_acc": 52.0}
{"epoch": 13, "training_loss": 63.50160217285156, "training_acc": 66.0, "val_loss": 18.357278406620026, "val_acc": 52.0}
{"epoch": 14, "training_loss": 62.903334856033325, "training_acc": 67.0, "val_loss": 18.697528541088104, "val_acc": 52.0}
{"epoch": 15, "training_loss": 62.672593116760254, "training_acc": 71.0, "val_loss": 18.657125532627106, "val_acc": 52.0}
{"epoch": 16, "training_loss": 63.4681453704834, "training_acc": 66.0, "val_loss": 18.586741387844086, "val_acc": 52.0}
{"epoch": 17, "training_loss": 63.22431719303131, "training_acc": 65.0, "val_loss": 18.68555098772049, "val_acc": 52.0}
{"epoch": 18, "training_loss": 62.91882038116455, "training_acc": 68.0, "val_loss": 18.706294894218445, "val_acc": 52.0}
{"epoch": 19, "training_loss": 62.73259210586548, "training_acc": 67.0, "val_loss": 18.451298773288727, "val_acc": 56.0}
{"epoch": 20, "training_loss": 62.682032346725464, "training_acc": 64.0, "val_loss": 18.371346592903137, "val_acc": 56.0}
{"epoch": 21, "training_loss": 62.79771137237549, "training_acc": 68.0, "val_loss": 18.637771904468536, "val_acc": 52.0}
{"epoch": 22, "training_loss": 62.110061168670654, "training_acc": 72.0, "val_loss": 18.800348043441772, "val_acc": 48.0}
{"epoch": 23, "training_loss": 61.19977426528931, "training_acc": 67.0, "val_loss": 18.879416584968567, "val_acc": 52.0}
{"epoch": 24, "training_loss": 59.525445222854614, "training_acc": 69.0, "val_loss": 18.93511861562729, "val_acc": 52.0}
{"epoch": 25, "training_loss": 60.00962471961975, "training_acc": 69.0, "val_loss": 19.09124404191971, "val_acc": 52.0}
{"epoch": 26, "training_loss": 60.99774885177612, "training_acc": 68.0, "val_loss": 19.246619939804077, "val_acc": 48.0}
{"epoch": 27, "training_loss": 60.54658794403076, "training_acc": 66.0, "val_loss": 19.055646657943726, "val_acc": 48.0}
{"epoch": 28, "training_loss": 59.93295741081238, "training_acc": 68.0, "val_loss": 18.836447596549988, "val_acc": 56.0}
{"epoch": 29, "training_loss": 60.174904108047485, "training_acc": 70.0, "val_loss": 19.08898502588272, "val_acc": 52.0}
{"epoch": 30, "training_loss": 58.59949064254761, "training_acc": 75.0, "val_loss": 19.22134906053543, "val_acc": 52.0}
{"epoch": 31, "training_loss": 59.88135576248169, "training_acc": 75.0, "val_loss": 19.374878704547882, "val_acc": 52.0}
{"epoch": 32, "training_loss": 59.554495334625244, "training_acc": 72.0, "val_loss": 19.347797334194183, "val_acc": 52.0}
