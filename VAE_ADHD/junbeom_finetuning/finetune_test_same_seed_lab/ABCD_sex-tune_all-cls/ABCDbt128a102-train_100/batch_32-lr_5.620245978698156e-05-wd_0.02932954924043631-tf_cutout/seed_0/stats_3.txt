"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.22976088523865, "training_acc": 54.0, "val_loss": 17.03285127878189, "val_acc": 64.0}
{"epoch": 1, "training_loss": 70.82717823982239, "training_acc": 54.0, "val_loss": 18.102727830410004, "val_acc": 48.0}
{"epoch": 2, "training_loss": 71.23626518249512, "training_acc": 55.0, "val_loss": 18.655605614185333, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.46977424621582, "training_acc": 50.0, "val_loss": 17.399373650550842, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58541965484619, "training_acc": 49.0, "val_loss": 17.38835871219635, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11258697509766, "training_acc": 53.0, "val_loss": 17.54887104034424, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.64013981819153, "training_acc": 53.0, "val_loss": 17.681071162223816, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.08431363105774, "training_acc": 53.0, "val_loss": 17.52001941204071, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16921377182007, "training_acc": 53.0, "val_loss": 17.32597053050995, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14112138748169, "training_acc": 53.0, "val_loss": 17.32325702905655, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07121753692627, "training_acc": 53.0, "val_loss": 17.303569614887238, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14877271652222, "training_acc": 53.0, "val_loss": 17.304882407188416, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23645067214966, "training_acc": 53.0, "val_loss": 17.32717901468277, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.12583875656128, "training_acc": 49.0, "val_loss": 17.420025169849396, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.34936857223511, "training_acc": 46.0, "val_loss": 17.336589097976685, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11300253868103, "training_acc": 53.0, "val_loss": 17.345573008060455, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.38990783691406, "training_acc": 53.0, "val_loss": 17.41797924041748, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.29620718955994, "training_acc": 53.0, "val_loss": 17.43273288011551, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.32376337051392, "training_acc": 53.0, "val_loss": 17.387235164642334, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16059517860413, "training_acc": 53.0, "val_loss": 17.380183935165405, "val_acc": 52.0}
