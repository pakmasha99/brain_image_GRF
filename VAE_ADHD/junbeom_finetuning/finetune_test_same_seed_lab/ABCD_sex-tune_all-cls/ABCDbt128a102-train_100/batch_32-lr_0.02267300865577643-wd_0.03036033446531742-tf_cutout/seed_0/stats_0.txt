"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 1097.7927112579346, "training_acc": 50.0, "val_loss": 3.520031060938824e+21, "val_acc": 56.0}
{"epoch": 1, "training_loss": 4.3381784724075037e+21, "training_acc": 52.0, "val_loss": 19055.10711669922, "val_acc": 44.0}
{"epoch": 2, "training_loss": 77960.19677734375, "training_acc": 50.0, "val_loss": 1759986.1328125, "val_acc": 44.0}
{"epoch": 3, "training_loss": 2842648.5087890625, "training_acc": 50.0, "val_loss": 6972202.34375, "val_acc": 44.0}
{"epoch": 4, "training_loss": 10309462.986328125, "training_acc": 48.0, "val_loss": 28284.619140625, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1299618.033203125, "training_acc": 52.0, "val_loss": 5949.749755859375, "val_acc": 44.0}
{"epoch": 6, "training_loss": 53856.546875, "training_acc": 54.0, "val_loss": 14439.021301269531, "val_acc": 44.0}
{"epoch": 7, "training_loss": 66011.32177734375, "training_acc": 56.0, "val_loss": 7786.342620849609, "val_acc": 44.0}
{"epoch": 8, "training_loss": 209890.1787109375, "training_acc": 42.0, "val_loss": 9716.211700439453, "val_acc": 44.0}
{"epoch": 9, "training_loss": 41259.4033203125, "training_acc": 54.0, "val_loss": 41614.605712890625, "val_acc": 44.0}
{"epoch": 10, "training_loss": 59203.818298339844, "training_acc": 46.0, "val_loss": 909.6349716186523, "val_acc": 56.0}
{"epoch": 11, "training_loss": 7238.887451171875, "training_acc": 46.0, "val_loss": 441.8722629547119, "val_acc": 56.0}
{"epoch": 12, "training_loss": 20963.392456054688, "training_acc": 58.0, "val_loss": 217.62793064117432, "val_acc": 56.0}
{"epoch": 13, "training_loss": 544.6885888576508, "training_acc": 51.0, "val_loss": 154.45815324783325, "val_acc": 56.0}
{"epoch": 14, "training_loss": 6431.552047729492, "training_acc": 48.0, "val_loss": 815.250301361084, "val_acc": 44.0}
{"epoch": 15, "training_loss": 17947.319580078125, "training_acc": 46.0, "val_loss": 1820.17822265625, "val_acc": 56.0}
{"epoch": 16, "training_loss": 6280.550198316574, "training_acc": 53.0, "val_loss": 1173.923397064209, "val_acc": 44.0}
{"epoch": 17, "training_loss": 2851.1094665527344, "training_acc": 46.0, "val_loss": 460.5773448944092, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1573.600866317749, "training_acc": 50.0, "val_loss": 72.52711057662964, "val_acc": 56.0}
{"epoch": 19, "training_loss": 293.48661041259766, "training_acc": 50.0, "val_loss": 10184.679412841797, "val_acc": 56.0}
{"epoch": 20, "training_loss": 55740.018981933594, "training_acc": 52.0, "val_loss": 9338.623809814453, "val_acc": 56.0}
{"epoch": 21, "training_loss": 14369.855743408203, "training_acc": 46.0, "val_loss": 218.39184761047363, "val_acc": 44.0}
{"epoch": 22, "training_loss": 994.8791809082031, "training_acc": 48.0, "val_loss": 101.49160623550415, "val_acc": 44.0}
{"epoch": 23, "training_loss": 631.1098480224609, "training_acc": 43.0, "val_loss": 151.99437141418457, "val_acc": 44.0}
{"epoch": 24, "training_loss": 3053.872459411621, "training_acc": 44.0, "val_loss": 71.05939984321594, "val_acc": 56.0}
{"epoch": 25, "training_loss": 151.4363887310028, "training_acc": 48.0, "val_loss": 17.78860241174698, "val_acc": 56.0}
{"epoch": 26, "training_loss": 80.08473014831543, "training_acc": 44.0, "val_loss": 17.690877616405487, "val_acc": 56.0}
{"epoch": 27, "training_loss": 70.61936235427856, "training_acc": 53.0, "val_loss": 17.190608382225037, "val_acc": 56.0}
{"epoch": 28, "training_loss": 662.4645671844482, "training_acc": 43.0, "val_loss": 18.0512934923172, "val_acc": 56.0}
{"epoch": 29, "training_loss": 71.37793755531311, "training_acc": 43.0, "val_loss": 17.30661541223526, "val_acc": 56.0}
{"epoch": 30, "training_loss": 73.6888837814331, "training_acc": 50.0, "val_loss": 17.38923192024231, "val_acc": 56.0}
{"epoch": 31, "training_loss": 100.05733871459961, "training_acc": 48.0, "val_loss": 17.691512405872345, "val_acc": 56.0}
{"epoch": 32, "training_loss": 723.5092601776123, "training_acc": 46.0, "val_loss": 22.26617783308029, "val_acc": 44.0}
{"epoch": 33, "training_loss": 72.44214820861816, "training_acc": 53.0, "val_loss": 17.148585617542267, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.87630796432495, "training_acc": 55.0, "val_loss": 22.090886533260345, "val_acc": 44.0}
{"epoch": 35, "training_loss": 75.96183562278748, "training_acc": 50.0, "val_loss": 17.964191734790802, "val_acc": 56.0}
{"epoch": 36, "training_loss": 76.1435375213623, "training_acc": 52.0, "val_loss": 17.469920217990875, "val_acc": 56.0}
{"epoch": 37, "training_loss": 72.31228971481323, "training_acc": 51.0, "val_loss": 17.613011598587036, "val_acc": 56.0}
{"epoch": 38, "training_loss": 71.85297584533691, "training_acc": 48.0, "val_loss": 17.84922331571579, "val_acc": 56.0}
{"epoch": 39, "training_loss": 70.43392372131348, "training_acc": 46.0, "val_loss": 17.33918786048889, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.83741283416748, "training_acc": 48.0, "val_loss": 17.25620925426483, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.21503186225891, "training_acc": 52.0, "val_loss": 17.202769219875336, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.9733076095581, "training_acc": 56.0, "val_loss": 17.715652287006378, "val_acc": 56.0}
{"epoch": 43, "training_loss": 70.75093603134155, "training_acc": 40.0, "val_loss": 17.25851148366928, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.58887076377869, "training_acc": 46.0, "val_loss": 17.474786937236786, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.57148838043213, "training_acc": 46.0, "val_loss": 17.240673303604126, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.27282238006592, "training_acc": 52.0, "val_loss": 17.1538308262825, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.5122663974762, "training_acc": 52.0, "val_loss": 17.14918613433838, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.46346950531006, "training_acc": 52.0, "val_loss": 17.18827337026596, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.01847624778748, "training_acc": 54.0, "val_loss": 17.551909387111664, "val_acc": 56.0}
{"epoch": 50, "training_loss": 70.16357445716858, "training_acc": 48.0, "val_loss": 18.059679865837097, "val_acc": 56.0}
{"epoch": 51, "training_loss": 71.21409797668457, "training_acc": 48.0, "val_loss": 18.08430254459381, "val_acc": 56.0}
{"epoch": 52, "training_loss": 71.02997779846191, "training_acc": 48.0, "val_loss": 17.603357136249542, "val_acc": 56.0}
