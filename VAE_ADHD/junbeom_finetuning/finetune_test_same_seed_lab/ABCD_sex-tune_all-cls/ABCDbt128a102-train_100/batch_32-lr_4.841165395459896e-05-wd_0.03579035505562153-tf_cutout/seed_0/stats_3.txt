"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.1437816619873, "training_acc": 53.0, "val_loss": 15.980331599712372, "val_acc": 64.0}
{"epoch": 1, "training_loss": 72.66941118240356, "training_acc": 52.0, "val_loss": 16.430029273033142, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.50296449661255, "training_acc": 56.0, "val_loss": 18.006160855293274, "val_acc": 48.0}
{"epoch": 3, "training_loss": 70.00189447402954, "training_acc": 54.0, "val_loss": 17.729011178016663, "val_acc": 48.0}
{"epoch": 4, "training_loss": 69.37442374229431, "training_acc": 55.0, "val_loss": 17.820237576961517, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.46394300460815, "training_acc": 52.0, "val_loss": 17.670805752277374, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.8609881401062, "training_acc": 53.0, "val_loss": 17.53048300743103, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.42420148849487, "training_acc": 55.0, "val_loss": 17.653679847717285, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.87517261505127, "training_acc": 47.0, "val_loss": 17.62947291135788, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.67495965957642, "training_acc": 47.0, "val_loss": 17.55487024784088, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.08531665802002, "training_acc": 55.0, "val_loss": 17.67187863588333, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0097279548645, "training_acc": 52.0, "val_loss": 17.686279118061066, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.85577535629272, "training_acc": 57.0, "val_loss": 17.339248955249786, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.40421676635742, "training_acc": 56.0, "val_loss": 17.198851704597473, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2949812412262, "training_acc": 57.0, "val_loss": 17.482158541679382, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21936297416687, "training_acc": 53.0, "val_loss": 18.108129501342773, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.93643760681152, "training_acc": 53.0, "val_loss": 17.84839928150177, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.02139163017273, "training_acc": 52.0, "val_loss": 17.34825074672699, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.96208500862122, "training_acc": 54.0, "val_loss": 17.33028143644333, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.94572949409485, "training_acc": 55.0, "val_loss": 17.256999015808105, "val_acc": 52.0}
