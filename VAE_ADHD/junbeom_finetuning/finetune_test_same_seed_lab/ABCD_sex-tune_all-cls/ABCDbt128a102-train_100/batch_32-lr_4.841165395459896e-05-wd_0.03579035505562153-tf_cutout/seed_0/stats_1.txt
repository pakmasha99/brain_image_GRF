"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 74.59344506263733, "training_acc": 42.0, "val_loss": 17.32669621706009, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.34514141082764, "training_acc": 50.0, "val_loss": 18.32209676504135, "val_acc": 52.0}
{"epoch": 2, "training_loss": 68.18594598770142, "training_acc": 56.0, "val_loss": 17.900489270687103, "val_acc": 52.0}
{"epoch": 3, "training_loss": 67.54368352890015, "training_acc": 65.0, "val_loss": 17.480312287807465, "val_acc": 52.0}
{"epoch": 4, "training_loss": 66.85783267021179, "training_acc": 66.0, "val_loss": 17.723822593688965, "val_acc": 52.0}
{"epoch": 5, "training_loss": 67.50872468948364, "training_acc": 61.0, "val_loss": 18.314574658870697, "val_acc": 52.0}
{"epoch": 6, "training_loss": 67.85493421554565, "training_acc": 58.0, "val_loss": 18.29061508178711, "val_acc": 48.0}
{"epoch": 7, "training_loss": 73.74046993255615, "training_acc": 43.0, "val_loss": 19.34245228767395, "val_acc": 40.0}
{"epoch": 8, "training_loss": 70.07338285446167, "training_acc": 48.0, "val_loss": 20.627154409885406, "val_acc": 52.0}
{"epoch": 9, "training_loss": 84.12923860549927, "training_acc": 53.0, "val_loss": 17.453256249427795, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18877530097961, "training_acc": 52.0, "val_loss": 17.342230677604675, "val_acc": 52.0}
{"epoch": 11, "training_loss": 72.25873708724976, "training_acc": 47.0, "val_loss": 17.626257240772247, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.89084768295288, "training_acc": 47.0, "val_loss": 17.515738308429718, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.46743726730347, "training_acc": 48.0, "val_loss": 17.485888302326202, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11073851585388, "training_acc": 54.0, "val_loss": 17.509354650974274, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.98445224761963, "training_acc": 55.0, "val_loss": 17.671526968479156, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.40555500984192, "training_acc": 53.0, "val_loss": 17.671851813793182, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.44362926483154, "training_acc": 53.0, "val_loss": 17.39133447408676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.93133115768433, "training_acc": 53.0, "val_loss": 17.257198691368103, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16699934005737, "training_acc": 53.0, "val_loss": 17.272968590259552, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.27238869667053, "training_acc": 53.0, "val_loss": 17.48037338256836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.9664511680603, "training_acc": 53.0, "val_loss": 17.637111246585846, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.58255410194397, "training_acc": 53.0, "val_loss": 17.636127769947052, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.45319986343384, "training_acc": 53.0, "val_loss": 17.583709955215454, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.41052198410034, "training_acc": 51.0, "val_loss": 17.582949995994568, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.95563697814941, "training_acc": 54.0, "val_loss": 17.602504789829254, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.83465814590454, "training_acc": 56.0, "val_loss": 17.53876507282257, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.22513198852539, "training_acc": 51.0, "val_loss": 17.38782823085785, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14019513130188, "training_acc": 52.0, "val_loss": 17.200253903865814, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.29842138290405, "training_acc": 51.0, "val_loss": 17.185968160629272, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.21415114402771, "training_acc": 53.0, "val_loss": 17.259715497493744, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.26545667648315, "training_acc": 53.0, "val_loss": 17.351683974266052, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15690612792969, "training_acc": 54.0, "val_loss": 17.371664941310883, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.35194301605225, "training_acc": 53.0, "val_loss": 17.382602393627167, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.94065451622009, "training_acc": 53.0, "val_loss": 17.353571951389313, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.82751941680908, "training_acc": 53.0, "val_loss": 17.288510501384735, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.60846495628357, "training_acc": 53.0, "val_loss": 17.117439210414886, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.03025770187378, "training_acc": 52.0, "val_loss": 16.987904906272888, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.35692834854126, "training_acc": 47.0, "val_loss": 17.321065068244934, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.65644645690918, "training_acc": 56.0, "val_loss": 17.58337765932083, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.6423728466034, "training_acc": 55.0, "val_loss": 17.629146575927734, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.10727548599243, "training_acc": 56.0, "val_loss": 17.461887001991272, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.34762477874756, "training_acc": 64.0, "val_loss": 17.313052713871002, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.95186042785645, "training_acc": 49.0, "val_loss": 17.38380938768387, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.295156955719, "training_acc": 55.0, "val_loss": 17.704640328884125, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.16740870475769, "training_acc": 53.0, "val_loss": 17.580588161945343, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.2433385848999, "training_acc": 51.0, "val_loss": 17.609868943691254, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.18831491470337, "training_acc": 51.0, "val_loss": 17.737016081809998, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.09487915039062, "training_acc": 51.0, "val_loss": 17.82885640859604, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.77082967758179, "training_acc": 53.0, "val_loss": 17.999280989170074, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.1737904548645, "training_acc": 53.0, "val_loss": 18.205522000789642, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.99511218070984, "training_acc": 54.0, "val_loss": 17.99241155385971, "val_acc": 52.0}
{"epoch": 52, "training_loss": 70.03445172309875, "training_acc": 51.0, "val_loss": 17.570175230503082, "val_acc": 52.0}
{"epoch": 53, "training_loss": 70.17082834243774, "training_acc": 49.0, "val_loss": 17.18149483203888, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.43475842475891, "training_acc": 61.0, "val_loss": 17.294013500213623, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.7828426361084, "training_acc": 53.0, "val_loss": 17.375345528125763, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.49951267242432, "training_acc": 54.0, "val_loss": 17.05874651670456, "val_acc": 52.0}
