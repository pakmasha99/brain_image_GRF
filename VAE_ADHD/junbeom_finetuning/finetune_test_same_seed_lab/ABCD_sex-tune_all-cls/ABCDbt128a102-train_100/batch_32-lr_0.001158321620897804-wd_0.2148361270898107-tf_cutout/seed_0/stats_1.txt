"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 77.00151109695435, "training_acc": 49.0, "val_loss": 947.1272468566895, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1243.6287002563477, "training_acc": 57.0, "val_loss": 22.753635048866272, "val_acc": 48.0}
{"epoch": 2, "training_loss": 93.4269745349884, "training_acc": 49.0, "val_loss": 18.940532207489014, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.32270240783691, "training_acc": 53.0, "val_loss": 17.344653606414795, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.36295413970947, "training_acc": 53.0, "val_loss": 17.597439885139465, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.1027102470398, "training_acc": 47.0, "val_loss": 17.400649189949036, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.67592096328735, "training_acc": 53.0, "val_loss": 17.39254742860794, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.40750932693481, "training_acc": 51.0, "val_loss": 17.459671199321747, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.11514329910278, "training_acc": 47.0, "val_loss": 17.339646816253662, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.35222816467285, "training_acc": 53.0, "val_loss": 17.47361868619919, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.61699748039246, "training_acc": 47.0, "val_loss": 17.326560616493225, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.19627523422241, "training_acc": 53.0, "val_loss": 17.31906086206436, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.87919020652771, "training_acc": 53.0, "val_loss": 17.3267662525177, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.42423486709595, "training_acc": 53.0, "val_loss": 17.318347096443176, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.25465154647827, "training_acc": 55.0, "val_loss": 17.346595227718353, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.52348756790161, "training_acc": 47.0, "val_loss": 17.343513667583466, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.51637268066406, "training_acc": 47.0, "val_loss": 17.31008291244507, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17793464660645, "training_acc": 53.0, "val_loss": 17.327089607715607, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11525106430054, "training_acc": 53.0, "val_loss": 17.38155633211136, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.2989444732666, "training_acc": 53.0, "val_loss": 17.39761382341385, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.33376169204712, "training_acc": 53.0, "val_loss": 17.437680065631866, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.548424243927, "training_acc": 53.0, "val_loss": 17.47494637966156, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.48768281936646, "training_acc": 53.0, "val_loss": 17.358823120594025, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20811343193054, "training_acc": 53.0, "val_loss": 17.315661907196045, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2945966720581, "training_acc": 51.0, "val_loss": 17.352508008480072, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.5190634727478, "training_acc": 47.0, "val_loss": 17.340613901615143, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2486023902893, "training_acc": 53.0, "val_loss": 17.310871183872223, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18099427223206, "training_acc": 53.0, "val_loss": 17.309510707855225, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18227052688599, "training_acc": 53.0, "val_loss": 17.310169339179993, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20170259475708, "training_acc": 53.0, "val_loss": 17.338508367538452, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.33626008033752, "training_acc": 53.0, "val_loss": 17.343270778656006, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.23800277709961, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19514608383179, "training_acc": 53.0, "val_loss": 17.309191823005676, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1672523021698, "training_acc": 53.0, "val_loss": 17.314434051513672, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.2475745677948, "training_acc": 53.0, "val_loss": 17.352963984012604, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.24200201034546, "training_acc": 53.0, "val_loss": 17.314614355564117, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15860486030579, "training_acc": 53.0, "val_loss": 17.3148512840271, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16312503814697, "training_acc": 53.0, "val_loss": 17.31642484664917, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14574337005615, "training_acc": 53.0, "val_loss": 17.316459119319916, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.26380968093872, "training_acc": 53.0, "val_loss": 17.330022156238556, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.32769894599915, "training_acc": 53.0, "val_loss": 17.309734225273132, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16469717025757, "training_acc": 53.0, "val_loss": 17.30911433696747, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.16292262077332, "training_acc": 53.0, "val_loss": 17.309579253196716, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.17183542251587, "training_acc": 53.0, "val_loss": 17.30969399213791, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.21075057983398, "training_acc": 53.0, "val_loss": 17.30913519859314, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15330410003662, "training_acc": 53.0, "val_loss": 17.313891649246216, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14889097213745, "training_acc": 53.0, "val_loss": 17.312680184841156, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.2490906715393, "training_acc": 53.0, "val_loss": 17.320391535758972, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.1481864452362, "training_acc": 53.0, "val_loss": 17.309142649173737, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.15705227851868, "training_acc": 53.0, "val_loss": 17.32931286096573, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.45956659317017, "training_acc": 47.0, "val_loss": 17.339235544204712, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.35144853591919, "training_acc": 51.0, "val_loss": 17.313094437122345, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.21468210220337, "training_acc": 53.0, "val_loss": 17.314521968364716, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.24963736534119, "training_acc": 53.0, "val_loss": 17.330874502658844, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.33419251441956, "training_acc": 47.0, "val_loss": 17.334994673728943, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.35479259490967, "training_acc": 47.0, "val_loss": 17.33485758304596, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.35347175598145, "training_acc": 47.0, "val_loss": 17.336681485176086, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.40555810928345, "training_acc": 47.0, "val_loss": 17.331163585186005, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.25187683105469, "training_acc": 53.0, "val_loss": 17.312130331993103, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.11032485961914, "training_acc": 53.0, "val_loss": 17.31315702199936, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.04618549346924, "training_acc": 53.0, "val_loss": 17.343313992023468, "val_acc": 52.0}
