"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.38552713394165, "training_acc": 53.0, "val_loss": 17.30431318283081, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.08852338790894, "training_acc": 53.0, "val_loss": 17.319415509700775, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.35317993164062, "training_acc": 47.0, "val_loss": 17.31014996767044, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.42989444732666, "training_acc": 53.0, "val_loss": 17.320561408996582, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22365999221802, "training_acc": 53.0, "val_loss": 17.312335968017578, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11546325683594, "training_acc": 53.0, "val_loss": 17.308898270130157, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.23395085334778, "training_acc": 53.0, "val_loss": 17.309260368347168, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26970624923706, "training_acc": 53.0, "val_loss": 17.3270121216774, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19550204277039, "training_acc": 53.0, "val_loss": 17.316819727420807, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21024346351624, "training_acc": 53.0, "val_loss": 17.316360771656036, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.25683403015137, "training_acc": 53.0, "val_loss": 17.346888780593872, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.46810865402222, "training_acc": 47.0, "val_loss": 17.337574064731598, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.35714840888977, "training_acc": 45.0, "val_loss": 17.32553094625473, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.34326171875, "training_acc": 47.0, "val_loss": 17.31984317302704, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23090934753418, "training_acc": 53.0, "val_loss": 17.30884462594986, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17541599273682, "training_acc": 53.0, "val_loss": 17.310860753059387, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17858743667603, "training_acc": 53.0, "val_loss": 17.37484633922577, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20187997817993, "training_acc": 53.0, "val_loss": 17.45140552520752, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.48717832565308, "training_acc": 53.0, "val_loss": 17.539530992507935, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.87290477752686, "training_acc": 53.0, "val_loss": 17.644095420837402, "val_acc": 52.0}
