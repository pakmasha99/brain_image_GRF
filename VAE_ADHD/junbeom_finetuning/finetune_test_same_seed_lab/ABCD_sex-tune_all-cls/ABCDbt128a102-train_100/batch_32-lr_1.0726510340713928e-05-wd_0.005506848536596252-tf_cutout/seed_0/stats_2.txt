"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.84528851509094, "training_acc": 46.0, "val_loss": 17.455291748046875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 70.42874693870544, "training_acc": 45.0, "val_loss": 17.56507009267807, "val_acc": 52.0}
{"epoch": 2, "training_loss": 67.63453722000122, "training_acc": 57.0, "val_loss": 17.638805508613586, "val_acc": 48.0}
{"epoch": 3, "training_loss": 66.91353034973145, "training_acc": 60.0, "val_loss": 17.844785749912262, "val_acc": 48.0}
{"epoch": 4, "training_loss": 66.26244974136353, "training_acc": 56.0, "val_loss": 17.748676240444183, "val_acc": 48.0}
{"epoch": 5, "training_loss": 65.40220761299133, "training_acc": 60.0, "val_loss": 17.875967919826508, "val_acc": 48.0}
{"epoch": 6, "training_loss": 64.96740245819092, "training_acc": 61.0, "val_loss": 17.80002862215042, "val_acc": 48.0}
{"epoch": 7, "training_loss": 64.27349472045898, "training_acc": 66.0, "val_loss": 18.270643055438995, "val_acc": 52.0}
{"epoch": 8, "training_loss": 65.17518258094788, "training_acc": 57.0, "val_loss": 18.624360859394073, "val_acc": 52.0}
{"epoch": 9, "training_loss": 62.61639213562012, "training_acc": 65.0, "val_loss": 17.562881112098694, "val_acc": 48.0}
{"epoch": 10, "training_loss": 65.85037279129028, "training_acc": 67.0, "val_loss": 17.910920083522797, "val_acc": 52.0}
{"epoch": 11, "training_loss": 61.59354782104492, "training_acc": 70.0, "val_loss": 19.34158354997635, "val_acc": 56.0}
{"epoch": 12, "training_loss": 63.221179246902466, "training_acc": 68.0, "val_loss": 18.603917956352234, "val_acc": 56.0}
{"epoch": 13, "training_loss": 62.825809478759766, "training_acc": 65.0, "val_loss": 18.16432923078537, "val_acc": 48.0}
{"epoch": 14, "training_loss": 63.06107831001282, "training_acc": 64.0, "val_loss": 18.38293820619583, "val_acc": 56.0}
{"epoch": 15, "training_loss": 61.96656155586243, "training_acc": 67.0, "val_loss": 18.905827403068542, "val_acc": 56.0}
{"epoch": 16, "training_loss": 61.36432218551636, "training_acc": 70.0, "val_loss": 18.957677483558655, "val_acc": 48.0}
{"epoch": 17, "training_loss": 61.0416476726532, "training_acc": 68.0, "val_loss": 18.385498225688934, "val_acc": 48.0}
{"epoch": 18, "training_loss": 60.09204053878784, "training_acc": 72.0, "val_loss": 19.515421986579895, "val_acc": 56.0}
{"epoch": 19, "training_loss": 59.86294102668762, "training_acc": 70.0, "val_loss": 19.009923934936523, "val_acc": 52.0}
