"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.63482141494751, "training_acc": 50.0, "val_loss": 17.335958778858185, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1390700340271, "training_acc": 53.0, "val_loss": 17.34166294336319, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.61774706840515, "training_acc": 53.0, "val_loss": 17.434947192668915, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.00916695594788, "training_acc": 53.0, "val_loss": 17.447295784950256, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.57393169403076, "training_acc": 53.0, "val_loss": 17.344853281974792, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.4188723564148, "training_acc": 53.0, "val_loss": 17.322583496570587, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.40170240402222, "training_acc": 53.0, "val_loss": 17.358258366584778, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.25344204902649, "training_acc": 53.0, "val_loss": 17.312993109226227, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.08743858337402, "training_acc": 53.0, "val_loss": 17.33163446187973, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.88845944404602, "training_acc": 47.0, "val_loss": 17.331385612487793, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.09509992599487, "training_acc": 57.0, "val_loss": 17.32199788093567, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1879301071167, "training_acc": 53.0, "val_loss": 17.315852642059326, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.42670488357544, "training_acc": 53.0, "val_loss": 17.308692634105682, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18441557884216, "training_acc": 53.0, "val_loss": 17.30971485376358, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09727096557617, "training_acc": 53.0, "val_loss": 17.326556146144867, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.32641363143921, "training_acc": 48.0, "val_loss": 17.32800602912903, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.3125147819519, "training_acc": 54.0, "val_loss": 17.32696145772934, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.35786437988281, "training_acc": 49.0, "val_loss": 17.367754876613617, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.58510708808899, "training_acc": 47.0, "val_loss": 17.353293299674988, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.26762223243713, "training_acc": 53.0, "val_loss": 17.314526438713074, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1130576133728, "training_acc": 53.0, "val_loss": 17.343780398368835, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29198503494263, "training_acc": 53.0, "val_loss": 17.37447679042816, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.45871186256409, "training_acc": 53.0, "val_loss": 17.409858107566833, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.32533764839172, "training_acc": 53.0, "val_loss": 17.328082025051117, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.006906747818, "training_acc": 53.0, "val_loss": 17.335189878940582, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.45514678955078, "training_acc": 47.0, "val_loss": 17.372554540634155, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.56646633148193, "training_acc": 47.0, "val_loss": 17.36641228199005, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.57121253013611, "training_acc": 47.0, "val_loss": 17.378531396389008, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.66045713424683, "training_acc": 47.0, "val_loss": 17.403465509414673, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.67510390281677, "training_acc": 47.0, "val_loss": 17.370736598968506, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.6520471572876, "training_acc": 47.0, "val_loss": 17.365136742591858, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.52477240562439, "training_acc": 45.0, "val_loss": 17.325645685195923, "val_acc": 52.0}
