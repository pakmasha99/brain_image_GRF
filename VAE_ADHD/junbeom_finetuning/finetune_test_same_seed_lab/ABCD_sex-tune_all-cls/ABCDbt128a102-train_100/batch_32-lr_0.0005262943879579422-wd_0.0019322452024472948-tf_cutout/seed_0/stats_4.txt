"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 71.01238822937012, "training_acc": 45.0, "val_loss": 17.368479073047638, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.5033688545227, "training_acc": 47.0, "val_loss": 17.319491505622864, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.59608912467957, "training_acc": 45.0, "val_loss": 17.31310486793518, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14103889465332, "training_acc": 53.0, "val_loss": 17.332035303115845, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.29091739654541, "training_acc": 53.0, "val_loss": 17.368192970752716, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.50551652908325, "training_acc": 53.0, "val_loss": 17.398282885551453, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.40625309944153, "training_acc": 53.0, "val_loss": 17.338024079799652, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18962001800537, "training_acc": 53.0, "val_loss": 17.370441555976868, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21928691864014, "training_acc": 53.0, "val_loss": 17.313364148139954, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.28662943840027, "training_acc": 53.0, "val_loss": 17.406637966632843, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.12981009483337, "training_acc": 47.0, "val_loss": 17.31136441230774, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.08047842979431, "training_acc": 53.0, "val_loss": 17.537425458431244, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.38225626945496, "training_acc": 53.0, "val_loss": 17.469298839569092, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.81907248497009, "training_acc": 53.0, "val_loss": 17.31196939945221, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31400632858276, "training_acc": 53.0, "val_loss": 17.39182621240616, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.63525915145874, "training_acc": 53.0, "val_loss": 17.48821586370468, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.83969974517822, "training_acc": 53.0, "val_loss": 17.415763437747955, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.4129228591919, "training_acc": 53.0, "val_loss": 17.31809973716736, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20377898216248, "training_acc": 53.0, "val_loss": 17.401131987571716, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.97432971000671, "training_acc": 53.0, "val_loss": 17.363202571868896, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.369948387146, "training_acc": 53.0, "val_loss": 17.371287941932678, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.40472531318665, "training_acc": 49.0, "val_loss": 17.310915887355804, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18916440010071, "training_acc": 53.0, "val_loss": 17.35914945602417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20959115028381, "training_acc": 53.0, "val_loss": 17.310170829296112, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.3076560497284, "training_acc": 49.0, "val_loss": 17.310667037963867, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14616131782532, "training_acc": 53.0, "val_loss": 17.579849064350128, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.44277811050415, "training_acc": 53.0, "val_loss": 17.847323417663574, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.78865766525269, "training_acc": 53.0, "val_loss": 17.654746770858765, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.14192962646484, "training_acc": 53.0, "val_loss": 17.418816685676575, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.30123591423035, "training_acc": 53.0, "val_loss": 17.310340702533722, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.229989528656, "training_acc": 53.0, "val_loss": 17.310675978660583, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.45519256591797, "training_acc": 53.0, "val_loss": 17.323780059814453, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.31417798995972, "training_acc": 53.0, "val_loss": 17.308887839317322, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1497540473938, "training_acc": 55.0, "val_loss": 17.415110766887665, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.87137413024902, "training_acc": 47.0, "val_loss": 17.40114986896515, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.82480382919312, "training_acc": 47.0, "val_loss": 17.3829585313797, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.34975624084473, "training_acc": 51.0, "val_loss": 17.312876880168915, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.43405222892761, "training_acc": 53.0, "val_loss": 17.308974266052246, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.66752243041992, "training_acc": 47.0, "val_loss": 17.418910562992096, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.51280307769775, "training_acc": 45.0, "val_loss": 17.309802770614624, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.20908284187317, "training_acc": 53.0, "val_loss": 17.31938272714615, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.04151344299316, "training_acc": 53.0, "val_loss": 17.408864200115204, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.49033784866333, "training_acc": 53.0, "val_loss": 17.619606852531433, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.26269197463989, "training_acc": 53.0, "val_loss": 17.57560819387436, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.3857626914978, "training_acc": 53.0, "val_loss": 17.310424149036407, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.0040373802185, "training_acc": 51.0, "val_loss": 17.33759641647339, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.48129653930664, "training_acc": 49.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.44674682617188, "training_acc": 53.0, "val_loss": 17.318469285964966, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.14165115356445, "training_acc": 53.0, "val_loss": 17.314548790454865, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.52254676818848, "training_acc": 53.0, "val_loss": 17.31632649898529, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.34988021850586, "training_acc": 53.0, "val_loss": 17.579708993434906, "val_acc": 52.0}
{"epoch": 51, "training_loss": 70.15457534790039, "training_acc": 53.0, "val_loss": 17.857562005519867, "val_acc": 52.0}
{"epoch": 52, "training_loss": 71.65304398536682, "training_acc": 53.0, "val_loss": 18.007497489452362, "val_acc": 52.0}
{"epoch": 53, "training_loss": 71.06397151947021, "training_acc": 53.0, "val_loss": 17.498359084129333, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.4578046798706, "training_acc": 53.0, "val_loss": 17.30867773294449, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.1890459060669, "training_acc": 51.0, "val_loss": 17.339839041233063, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.6247980594635, "training_acc": 41.0, "val_loss": 17.31208711862564, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.23707389831543, "training_acc": 53.0, "val_loss": 17.412225902080536, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.34687399864197, "training_acc": 53.0, "val_loss": 17.542487382888794, "val_acc": 52.0}
{"epoch": 59, "training_loss": 70.04714608192444, "training_acc": 53.0, "val_loss": 17.609094083309174, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.91390895843506, "training_acc": 53.0, "val_loss": 17.45372712612152, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.56041646003723, "training_acc": 53.0, "val_loss": 17.44299679994583, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.55993556976318, "training_acc": 53.0, "val_loss": 17.449019849300385, "val_acc": 52.0}
