"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.82098770141602, "training_acc": 47.0, "val_loss": 17.436103522777557, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.89849138259888, "training_acc": 45.0, "val_loss": 17.39484965801239, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.71163702011108, "training_acc": 47.0, "val_loss": 17.43854284286499, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.89333629608154, "training_acc": 47.0, "val_loss": 17.343714833259583, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27702760696411, "training_acc": 51.0, "val_loss": 17.312057316303253, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15520763397217, "training_acc": 53.0, "val_loss": 17.3196941614151, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28620409965515, "training_acc": 53.0, "val_loss": 17.318488657474518, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1422655582428, "training_acc": 53.0, "val_loss": 17.31896996498108, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1998062133789, "training_acc": 53.0, "val_loss": 17.340567708015442, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.31628346443176, "training_acc": 53.0, "val_loss": 17.374156415462494, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.3047924041748, "training_acc": 53.0, "val_loss": 17.35844910144806, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24183964729309, "training_acc": 53.0, "val_loss": 17.364494502544403, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21020317077637, "training_acc": 53.0, "val_loss": 17.310842871665955, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.10410189628601, "training_acc": 53.0, "val_loss": 17.333510518074036, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.79414081573486, "training_acc": 47.0, "val_loss": 17.3212930560112, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.66252708435059, "training_acc": 53.0, "val_loss": 17.36215502023697, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.56645631790161, "training_acc": 53.0, "val_loss": 17.395074665546417, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.46011567115784, "training_acc": 53.0, "val_loss": 17.32790768146515, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.24599838256836, "training_acc": 53.0, "val_loss": 17.3721045255661, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.43537616729736, "training_acc": 53.0, "val_loss": 17.456920444965363, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.69491720199585, "training_acc": 53.0, "val_loss": 17.46314913034439, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.50253176689148, "training_acc": 53.0, "val_loss": 17.361408472061157, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.29281067848206, "training_acc": 53.0, "val_loss": 17.37765073776245, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.5616044998169, "training_acc": 53.0, "val_loss": 17.359763383865356, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23833632469177, "training_acc": 53.0, "val_loss": 17.311549186706543, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19037222862244, "training_acc": 53.0, "val_loss": 17.31054037809372, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15177989006042, "training_acc": 53.0, "val_loss": 17.32294112443924, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16232824325562, "training_acc": 53.0, "val_loss": 17.309565842151642, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.24961853027344, "training_acc": 53.0, "val_loss": 17.30979084968567, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1150872707367, "training_acc": 53.0, "val_loss": 17.433452606201172, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.71301913261414, "training_acc": 53.0, "val_loss": 17.605765163898468, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.04922533035278, "training_acc": 53.0, "val_loss": 17.618414759635925, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.14417290687561, "training_acc": 53.0, "val_loss": 17.52980202436447, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.61912727355957, "training_acc": 53.0, "val_loss": 17.381438612937927, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.37150502204895, "training_acc": 53.0, "val_loss": 17.334550619125366, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.22184538841248, "training_acc": 53.0, "val_loss": 17.318645119667053, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14605045318604, "training_acc": 53.0, "val_loss": 17.309650778770447, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16042613983154, "training_acc": 55.0, "val_loss": 17.362959682941437, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.55763530731201, "training_acc": 47.0, "val_loss": 17.37370789051056, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.66095876693726, "training_acc": 47.0, "val_loss": 17.38521158695221, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.46027183532715, "training_acc": 45.0, "val_loss": 17.316514253616333, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.43846940994263, "training_acc": 53.0, "val_loss": 17.31628328561783, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.47133159637451, "training_acc": 47.0, "val_loss": 17.352066934108734, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.31252908706665, "training_acc": 51.0, "val_loss": 17.308995127677917, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.18331384658813, "training_acc": 53.0, "val_loss": 17.311035096645355, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.06381344795227, "training_acc": 53.0, "val_loss": 17.347624897956848, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.21472191810608, "training_acc": 53.0, "val_loss": 17.47014820575714, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.73846101760864, "training_acc": 53.0, "val_loss": 17.508752644062042, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.42565655708313, "training_acc": 53.0, "val_loss": 17.344477772712708, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.07621383666992, "training_acc": 53.0, "val_loss": 17.312152683734894, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.22163963317871, "training_acc": 53.0, "val_loss": 17.315766215324402, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.26393222808838, "training_acc": 53.0, "val_loss": 17.312684655189514, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.13130784034729, "training_acc": 53.0, "val_loss": 17.308616638183594, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.48303818702698, "training_acc": 53.0, "val_loss": 17.308688163757324, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.22703647613525, "training_acc": 53.0, "val_loss": 17.421871423721313, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.49867105484009, "training_acc": 53.0, "val_loss": 17.626240849494934, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.72459411621094, "training_acc": 53.0, "val_loss": 17.8326278924942, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.69085264205933, "training_acc": 53.0, "val_loss": 17.578350007534027, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.73450136184692, "training_acc": 53.0, "val_loss": 17.36558824777603, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.16211295127869, "training_acc": 53.0, "val_loss": 17.31344610452652, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.28975439071655, "training_acc": 53.0, "val_loss": 17.32580214738846, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.20580744743347, "training_acc": 53.0, "val_loss": 17.36506074666977, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.22086000442505, "training_acc": 53.0, "val_loss": 17.415904998779297, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.54351949691772, "training_acc": 53.0, "val_loss": 17.47378557920456, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.5657217502594, "training_acc": 53.0, "val_loss": 17.427246272563934, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.57190346717834, "training_acc": 53.0, "val_loss": 17.46537685394287, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.64524459838867, "training_acc": 53.0, "val_loss": 17.489732801914215, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.57446932792664, "training_acc": 53.0, "val_loss": 17.33361780643463, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.2666826248169, "training_acc": 53.0, "val_loss": 17.33781397342682, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.29729795455933, "training_acc": 47.0, "val_loss": 17.402121424674988, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.69518375396729, "training_acc": 47.0, "val_loss": 17.39051192998886, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.87884092330933, "training_acc": 47.0, "val_loss": 17.44753271341324, "val_acc": 52.0}
