"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 71.29876661300659, "training_acc": 45.0, "val_loss": 16.13132506608963, "val_acc": 64.0}
{"epoch": 1, "training_loss": 68.71280837059021, "training_acc": 53.0, "val_loss": 18.24295222759247, "val_acc": 52.0}
{"epoch": 2, "training_loss": 68.10811233520508, "training_acc": 56.0, "val_loss": 18.283240497112274, "val_acc": 56.0}
{"epoch": 3, "training_loss": 65.9655876159668, "training_acc": 60.0, "val_loss": 18.171456456184387, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.90684723854065, "training_acc": 52.0, "val_loss": 17.937538027763367, "val_acc": 48.0}
{"epoch": 5, "training_loss": 69.80725860595703, "training_acc": 56.0, "val_loss": 17.294764518737793, "val_acc": 52.0}
{"epoch": 6, "training_loss": 67.07123184204102, "training_acc": 60.0, "val_loss": 17.485272884368896, "val_acc": 52.0}
{"epoch": 7, "training_loss": 67.30474328994751, "training_acc": 58.0, "val_loss": 17.6548033952713, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.03795051574707, "training_acc": 53.0, "val_loss": 16.82327687740326, "val_acc": 56.0}
{"epoch": 9, "training_loss": 70.05558586120605, "training_acc": 49.0, "val_loss": 16.667892038822174, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.43079805374146, "training_acc": 54.0, "val_loss": 16.473624110221863, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.71654772758484, "training_acc": 57.0, "val_loss": 17.24943071603775, "val_acc": 64.0}
{"epoch": 12, "training_loss": 67.25327777862549, "training_acc": 58.0, "val_loss": 17.35500693321228, "val_acc": 52.0}
{"epoch": 13, "training_loss": 67.17856168746948, "training_acc": 58.0, "val_loss": 17.043299973011017, "val_acc": 52.0}
{"epoch": 14, "training_loss": 67.2828094959259, "training_acc": 60.0, "val_loss": 16.871386766433716, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.74403429031372, "training_acc": 58.0, "val_loss": 17.06727147102356, "val_acc": 52.0}
{"epoch": 16, "training_loss": 66.3809061050415, "training_acc": 61.0, "val_loss": 16.929806768894196, "val_acc": 52.0}
{"epoch": 17, "training_loss": 66.47470474243164, "training_acc": 62.0, "val_loss": 17.211352288722992, "val_acc": 56.0}
{"epoch": 18, "training_loss": 67.02723789215088, "training_acc": 60.0, "val_loss": 17.296025156974792, "val_acc": 56.0}
{"epoch": 19, "training_loss": 66.5501778125763, "training_acc": 63.0, "val_loss": 17.281287908554077, "val_acc": 52.0}
