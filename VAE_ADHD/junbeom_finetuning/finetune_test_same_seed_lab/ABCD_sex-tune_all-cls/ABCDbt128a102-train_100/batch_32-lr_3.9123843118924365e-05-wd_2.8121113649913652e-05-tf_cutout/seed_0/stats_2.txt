"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.78768110275269, "training_acc": 51.0, "val_loss": 18.863174319267273, "val_acc": 44.0}
{"epoch": 1, "training_loss": 71.37144088745117, "training_acc": 47.0, "val_loss": 17.52324253320694, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.26340103149414, "training_acc": 53.0, "val_loss": 17.754720151424408, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.16188907623291, "training_acc": 58.0, "val_loss": 18.471285700798035, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.50870752334595, "training_acc": 45.0, "val_loss": 18.183711171150208, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.45416164398193, "training_acc": 60.0, "val_loss": 17.531394958496094, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.80938863754272, "training_acc": 45.0, "val_loss": 17.3629030585289, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.81276750564575, "training_acc": 51.0, "val_loss": 17.311739921569824, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.6397795677185, "training_acc": 51.0, "val_loss": 17.292964458465576, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.4062614440918, "training_acc": 50.0, "val_loss": 17.334678769111633, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.61198711395264, "training_acc": 52.0, "val_loss": 18.28799843788147, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.11813640594482, "training_acc": 49.0, "val_loss": 18.364299833774567, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1338849067688, "training_acc": 52.0, "val_loss": 17.125676572322845, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.58595085144043, "training_acc": 53.0, "val_loss": 17.219151556491852, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.03165578842163, "training_acc": 56.0, "val_loss": 17.180879414081573, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.0224256515503, "training_acc": 54.0, "val_loss": 17.519736289978027, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.58140468597412, "training_acc": 53.0, "val_loss": 17.39134043455124, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.41510486602783, "training_acc": 53.0, "val_loss": 17.263303697109222, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.3395881652832, "training_acc": 53.0, "val_loss": 17.22489893436432, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.49234318733215, "training_acc": 49.0, "val_loss": 17.400363087654114, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30431723594666, "training_acc": 47.0, "val_loss": 17.41976886987686, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.18962693214417, "training_acc": 52.0, "val_loss": 17.421813309192657, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18698334693909, "training_acc": 47.0, "val_loss": 17.40211248397827, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.83750629425049, "training_acc": 53.0, "val_loss": 17.407338321208954, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01530766487122, "training_acc": 53.0, "val_loss": 17.410022020339966, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.8754472732544, "training_acc": 53.0, "val_loss": 17.42790788412094, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.84012222290039, "training_acc": 53.0, "val_loss": 17.433567345142365, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.76099824905396, "training_acc": 53.0, "val_loss": 17.439565062522888, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.85923957824707, "training_acc": 53.0, "val_loss": 17.495669424533844, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.680997133255, "training_acc": 53.0, "val_loss": 17.531363666057587, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.67989015579224, "training_acc": 53.0, "val_loss": 17.442505061626434, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.86927556991577, "training_acc": 53.0, "val_loss": 17.56027191877365, "val_acc": 52.0}
