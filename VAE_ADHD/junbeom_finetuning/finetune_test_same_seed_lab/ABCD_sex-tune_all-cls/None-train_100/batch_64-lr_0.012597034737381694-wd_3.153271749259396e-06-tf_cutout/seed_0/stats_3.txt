"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 939.766902923584, "training_acc": 47.0, "val_loss": 3.270214083726541e+18, "val_acc": 52.0}
{"epoch": 1, "training_loss": 8.368158148876222e+18, "training_acc": 49.0, "val_loss": 18776632.8125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1971216436.0, "training_acc": 47.0, "val_loss": 424260350.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1160062681.5, "training_acc": 47.0, "val_loss": 58109250.0, "val_acc": 48.0}
{"epoch": 4, "training_loss": 143026349.90625, "training_acc": 47.0, "val_loss": 87270643.75, "val_acc": 52.0}
{"epoch": 5, "training_loss": 221677348.7783203, "training_acc": 52.0, "val_loss": 39292843.75, "val_acc": 48.0}
{"epoch": 6, "training_loss": 189460868.0, "training_acc": 47.0, "val_loss": 1787959.375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 4985956.5771484375, "training_acc": 55.0, "val_loss": 4866255.859375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 108215960.0, "training_acc": 47.0, "val_loss": 120972225.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 593879924.0, "training_acc": 53.0, "val_loss": 11336985.9375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1302973796.0, "training_acc": 45.0, "val_loss": 437812.01171875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 7538919911.5, "training_acc": 45.0, "val_loss": 60963550.0, "val_acc": 52.0}
{"epoch": 12, "training_loss": 150177426.3125, "training_acc": 53.0, "val_loss": 72863025.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 332764387.0, "training_acc": 49.0, "val_loss": 190443612.5, "val_acc": 48.0}
{"epoch": 14, "training_loss": 8618271904.0, "training_acc": 47.0, "val_loss": 3729786.328125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 35400677.5, "training_acc": 53.0, "val_loss": 29789512.5, "val_acc": 52.0}
{"epoch": 16, "training_loss": 268652606.0, "training_acc": 53.0, "val_loss": 22835081.25, "val_acc": 52.0}
{"epoch": 17, "training_loss": 77796267.75, "training_acc": 53.0, "val_loss": 72844006.25, "val_acc": 48.0}
{"epoch": 18, "training_loss": 233080827.75, "training_acc": 47.0, "val_loss": 726669300.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1996039840.0, "training_acc": 53.0, "val_loss": 25807967.1875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 116167405.5, "training_acc": 53.0, "val_loss": 20339389.0625, "val_acc": 48.0}
{"epoch": 21, "training_loss": 57245479.125, "training_acc": 47.0, "val_loss": 4282896.875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 14087615.03125, "training_acc": 53.0, "val_loss": 883741.6015625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 4427617.28125, "training_acc": 47.0, "val_loss": 557194.23828125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 3135897.640625, "training_acc": 51.0, "val_loss": 220641.2353515625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 12904848.375, "training_acc": 49.0, "val_loss": 1048048.4375, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5144249.46875, "training_acc": 47.0, "val_loss": 33839518.75, "val_acc": 52.0}
{"epoch": 27, "training_loss": 87876762.5625, "training_acc": 51.0, "val_loss": 2547908.203125, "val_acc": 48.0}
{"epoch": 28, "training_loss": 8167860.2890625, "training_acc": 41.0, "val_loss": 1168932.71484375, "val_acc": 48.0}
{"epoch": 29, "training_loss": 3661049.328125, "training_acc": 47.0, "val_loss": 1810368.9453125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 5329191.296875, "training_acc": 53.0, "val_loss": 1657311.9140625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4941132.4453125, "training_acc": 47.0, "val_loss": 534431.005859375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 5279681.75, "training_acc": 49.0, "val_loss": 889319.62890625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2342627.3198242188, "training_acc": 48.0, "val_loss": 83774.18823242188, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1122350.6171875, "training_acc": 43.0, "val_loss": 258038.9892578125, "val_acc": 52.0}
{"epoch": 35, "training_loss": 724594.9736328125, "training_acc": 53.0, "val_loss": 517206.34765625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1821561.93359375, "training_acc": 47.0, "val_loss": 487229.150390625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1268794.9389648438, "training_acc": 53.0, "val_loss": 307286.3037109375, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1036203.037109375, "training_acc": 45.0, "val_loss": 407217.67578125, "val_acc": 48.0}
{"epoch": 39, "training_loss": 993676.6320800781, "training_acc": 54.0, "val_loss": 110381.11572265625, "val_acc": 48.0}
{"epoch": 40, "training_loss": 693118.49609375, "training_acc": 55.0, "val_loss": 276484.1796875, "val_acc": 52.0}
{"epoch": 41, "training_loss": 846486.5634765625, "training_acc": 49.0, "val_loss": 55187.36572265625, "val_acc": 48.0}
{"epoch": 42, "training_loss": 303957.25390625, "training_acc": 45.0, "val_loss": 76766.30859375, "val_acc": 52.0}
{"epoch": 43, "training_loss": 371863.8125, "training_acc": 45.0, "val_loss": 7249.629211425781, "val_acc": 48.0}
{"epoch": 44, "training_loss": 221683.2255859375, "training_acc": 55.0, "val_loss": 85028.96728515625, "val_acc": 52.0}
{"epoch": 45, "training_loss": 654013.88671875, "training_acc": 53.0, "val_loss": 9679.57992553711, "val_acc": 52.0}
{"epoch": 46, "training_loss": 110988.236328125, "training_acc": 56.0, "val_loss": 21561.737060546875, "val_acc": 48.0}
{"epoch": 47, "training_loss": 245765.2109375, "training_acc": 45.0, "val_loss": 100609.24682617188, "val_acc": 52.0}
{"epoch": 48, "training_loss": 332074.2431640625, "training_acc": 49.0, "val_loss": 13245.697021484375, "val_acc": 48.0}
{"epoch": 49, "training_loss": 183854.2919921875, "training_acc": 49.0, "val_loss": 86616.93725585938, "val_acc": 52.0}
{"epoch": 50, "training_loss": 368015.1533203125, "training_acc": 45.0, "val_loss": 54485.25390625, "val_acc": 48.0}
{"epoch": 51, "training_loss": 169953.2861328125, "training_acc": 57.0, "val_loss": 58299.8291015625, "val_acc": 52.0}
{"epoch": 52, "training_loss": 163490.62280273438, "training_acc": 51.0, "val_loss": 3276.970672607422, "val_acc": 48.0}
{"epoch": 53, "training_loss": 98073.2529296875, "training_acc": 48.0, "val_loss": 22318.743896484375, "val_acc": 52.0}
{"epoch": 54, "training_loss": 146031.7275390625, "training_acc": 45.0, "val_loss": 60102.581787109375, "val_acc": 48.0}
{"epoch": 55, "training_loss": 174488.57885742188, "training_acc": 47.0, "val_loss": 55687.4267578125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 259178.8916015625, "training_acc": 53.0, "val_loss": 67735.97412109375, "val_acc": 52.0}
{"epoch": 57, "training_loss": 198893.47900390625, "training_acc": 53.0, "val_loss": 27402.557373046875, "val_acc": 48.0}
{"epoch": 58, "training_loss": 122168.96728515625, "training_acc": 47.0, "val_loss": 31505.340576171875, "val_acc": 48.0}
{"epoch": 59, "training_loss": 87550.197265625, "training_acc": 48.0, "val_loss": 26805.288696289062, "val_acc": 52.0}
{"epoch": 60, "training_loss": 100703.43310546875, "training_acc": 53.0, "val_loss": 7562.013244628906, "val_acc": 48.0}
{"epoch": 61, "training_loss": 27172.011474609375, "training_acc": 47.0, "val_loss": 9967.937469482422, "val_acc": 52.0}
{"epoch": 62, "training_loss": 35204.070251464844, "training_acc": 47.0, "val_loss": 10350.733184814453, "val_acc": 52.0}
{"epoch": 63, "training_loss": 58235.135498046875, "training_acc": 49.0, "val_loss": 974.7673988342285, "val_acc": 52.0}
{"epoch": 64, "training_loss": 37009.706787109375, "training_acc": 54.0, "val_loss": 615.5949592590332, "val_acc": 52.0}
{"epoch": 65, "training_loss": 17004.275756835938, "training_acc": 56.0, "val_loss": 26507.70263671875, "val_acc": 52.0}
{"epoch": 66, "training_loss": 83025.72631835938, "training_acc": 53.0, "val_loss": 44268.13659667969, "val_acc": 48.0}
{"epoch": 67, "training_loss": 197274.6064453125, "training_acc": 47.0, "val_loss": 11914.408874511719, "val_acc": 48.0}
{"epoch": 68, "training_loss": 70511.7548828125, "training_acc": 55.0, "val_loss": 52449.13330078125, "val_acc": 52.0}
{"epoch": 69, "training_loss": 189383.96728515625, "training_acc": 53.0, "val_loss": 24705.06591796875, "val_acc": 52.0}
{"epoch": 70, "training_loss": 77173.30139160156, "training_acc": 53.0, "val_loss": 13770.767211914062, "val_acc": 48.0}
{"epoch": 71, "training_loss": 55156.460205078125, "training_acc": 47.0, "val_loss": 3148.887825012207, "val_acc": 48.0}
{"epoch": 72, "training_loss": 20134.385620117188, "training_acc": 51.0, "val_loss": 8615.914154052734, "val_acc": 48.0}
{"epoch": 73, "training_loss": 37286.177978515625, "training_acc": 47.0, "val_loss": 4804.349899291992, "val_acc": 52.0}
{"epoch": 74, "training_loss": 18303.22283935547, "training_acc": 53.0, "val_loss": 68.43317747116089, "val_acc": 64.0}
{"epoch": 75, "training_loss": 9675.939453125, "training_acc": 47.0, "val_loss": 2335.3206634521484, "val_acc": 48.0}
{"epoch": 76, "training_loss": 6271.084495544434, "training_acc": 46.0, "val_loss": 17.320647835731506, "val_acc": 52.0}
{"epoch": 77, "training_loss": 69.34583473205566, "training_acc": 53.0, "val_loss": 17.310214042663574, "val_acc": 52.0}
{"epoch": 78, "training_loss": 69.34439873695374, "training_acc": 53.0, "val_loss": 17.308688163757324, "val_acc": 52.0}
{"epoch": 79, "training_loss": 69.15223026275635, "training_acc": 53.0, "val_loss": 17.30879247188568, "val_acc": 52.0}
{"epoch": 80, "training_loss": 69.14882469177246, "training_acc": 53.0, "val_loss": 17.309825122356415, "val_acc": 52.0}
{"epoch": 81, "training_loss": 69.13107252120972, "training_acc": 53.0, "val_loss": 17.314013838768005, "val_acc": 52.0}
{"epoch": 82, "training_loss": 69.15698623657227, "training_acc": 53.0, "val_loss": 17.32141524553299, "val_acc": 52.0}
{"epoch": 83, "training_loss": 69.1509518623352, "training_acc": 53.0, "val_loss": 17.321960628032684, "val_acc": 52.0}
{"epoch": 84, "training_loss": 69.16227841377258, "training_acc": 53.0, "val_loss": 17.317982017993927, "val_acc": 52.0}
{"epoch": 85, "training_loss": 69.16142201423645, "training_acc": 53.0, "val_loss": 17.31860339641571, "val_acc": 52.0}
{"epoch": 86, "training_loss": 69.15172696113586, "training_acc": 53.0, "val_loss": 17.315906286239624, "val_acc": 52.0}
{"epoch": 87, "training_loss": 69.14243412017822, "training_acc": 53.0, "val_loss": 17.31603443622589, "val_acc": 52.0}
{"epoch": 88, "training_loss": 69.1552402973175, "training_acc": 53.0, "val_loss": 17.314864695072174, "val_acc": 52.0}
{"epoch": 89, "training_loss": 69.13936996459961, "training_acc": 53.0, "val_loss": 17.316026985645294, "val_acc": 52.0}
{"epoch": 90, "training_loss": 69.17647385597229, "training_acc": 53.0, "val_loss": 17.31625646352768, "val_acc": 52.0}
{"epoch": 91, "training_loss": 69.12895131111145, "training_acc": 53.0, "val_loss": 17.313334345817566, "val_acc": 52.0}
{"epoch": 92, "training_loss": 69.13438057899475, "training_acc": 53.0, "val_loss": 17.310672998428345, "val_acc": 52.0}
{"epoch": 93, "training_loss": 69.13381886482239, "training_acc": 53.0, "val_loss": 17.309464514255524, "val_acc": 52.0}
{"epoch": 94, "training_loss": 69.22329068183899, "training_acc": 53.0, "val_loss": 17.308908700942993, "val_acc": 52.0}
{"epoch": 95, "training_loss": 69.16122794151306, "training_acc": 53.0, "val_loss": 17.30978488922119, "val_acc": 52.0}
{"epoch": 96, "training_loss": 69.14849066734314, "training_acc": 53.0, "val_loss": 17.310383915901184, "val_acc": 52.0}
{"epoch": 97, "training_loss": 69.14088487625122, "training_acc": 53.0, "val_loss": 17.31046289205551, "val_acc": 52.0}
