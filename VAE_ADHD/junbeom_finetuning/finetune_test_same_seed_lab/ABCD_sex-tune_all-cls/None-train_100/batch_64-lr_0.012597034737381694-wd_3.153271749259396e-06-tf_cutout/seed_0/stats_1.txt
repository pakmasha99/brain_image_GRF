"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 813.9756507873535, "training_acc": 51.0, "val_loss": 4783783526400.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 11430959176300.307, "training_acc": 53.0, "val_loss": 1412798.828125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3764498.5390625, "training_acc": 47.0, "val_loss": 51927.691650390625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 726659.140625, "training_acc": 51.0, "val_loss": 19768.4326171875, "val_acc": 48.0}
{"epoch": 4, "training_loss": 295396.7734375, "training_acc": 53.0, "val_loss": 72916.02783203125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 199989.5711669922, "training_acc": 47.0, "val_loss": 59743.524169921875, "val_acc": 52.0}
{"epoch": 6, "training_loss": 132550.2476387024, "training_acc": 57.0, "val_loss": 170.7091212272644, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4040.2378845214844, "training_acc": 37.0, "val_loss": 2672.1492767333984, "val_acc": 48.0}
{"epoch": 8, "training_loss": 8763.979949951172, "training_acc": 47.0, "val_loss": 1319.7025299072266, "val_acc": 52.0}
{"epoch": 9, "training_loss": 16382.3154296875, "training_acc": 51.0, "val_loss": 4725.405120849609, "val_acc": 52.0}
{"epoch": 10, "training_loss": 18822.989807128906, "training_acc": 53.0, "val_loss": 4916.231155395508, "val_acc": 52.0}
{"epoch": 11, "training_loss": 16478.500427246094, "training_acc": 53.0, "val_loss": 1361.8639945983887, "val_acc": 52.0}
{"epoch": 12, "training_loss": 4383.908088684082, "training_acc": 49.0, "val_loss": 289.8136615753174, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1535.3170776367188, "training_acc": 47.0, "val_loss": 2533.6044311523438, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6660.117874145508, "training_acc": 53.0, "val_loss": 2439.322280883789, "val_acc": 48.0}
{"epoch": 15, "training_loss": 7923.539794921875, "training_acc": 47.0, "val_loss": 19.595320522785187, "val_acc": 40.0}
{"epoch": 16, "training_loss": 1760.0761642456055, "training_acc": 42.0, "val_loss": 44.71902251243591, "val_acc": 52.0}
{"epoch": 17, "training_loss": 129.23028588294983, "training_acc": 55.0, "val_loss": 82.58146643638611, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1020.9762725830078, "training_acc": 45.0, "val_loss": 1566.1003112792969, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4583.170217514038, "training_acc": 47.0, "val_loss": 123.70423078536987, "val_acc": 48.0}
{"epoch": 20, "training_loss": 804.0579795837402, "training_acc": 51.0, "val_loss": 17.27168560028076, "val_acc": 52.0}
{"epoch": 21, "training_loss": 147.26922416687012, "training_acc": 53.0, "val_loss": 83.99060368537903, "val_acc": 48.0}
{"epoch": 22, "training_loss": 226.69117331504822, "training_acc": 53.0, "val_loss": 320.3470468521118, "val_acc": 52.0}
{"epoch": 23, "training_loss": 876.1829960346222, "training_acc": 53.0, "val_loss": 17.3247292637825, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.30093431472778, "training_acc": 51.0, "val_loss": 17.335526645183563, "val_acc": 52.0}
{"epoch": 25, "training_loss": 330.1208190917969, "training_acc": 47.0, "val_loss": 23.233823478221893, "val_acc": 48.0}
{"epoch": 26, "training_loss": 154.53839302062988, "training_acc": 47.0, "val_loss": 17.32059270143509, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.251708984375, "training_acc": 53.0, "val_loss": 41.134944558143616, "val_acc": 48.0}
{"epoch": 28, "training_loss": 118.6797022819519, "training_acc": 53.0, "val_loss": 19.609344005584717, "val_acc": 48.0}
{"epoch": 29, "training_loss": 80.11437630653381, "training_acc": 52.0, "val_loss": 17.393024265766144, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4296.066379547119, "training_acc": 53.0, "val_loss": 503.0205726623535, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1225.1450235843658, "training_acc": 55.0, "val_loss": 1637.4151229858398, "val_acc": 48.0}
{"epoch": 32, "training_loss": 4916.435382843018, "training_acc": 47.0, "val_loss": 1427.4545669555664, "val_acc": 52.0}
{"epoch": 33, "training_loss": 3136.00030708313, "training_acc": 53.0, "val_loss": 279.6751022338867, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1891.2118530273438, "training_acc": 51.0, "val_loss": 25.730431079864502, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1052.0356750488281, "training_acc": 53.0, "val_loss": 281.02941513061523, "val_acc": 48.0}
{"epoch": 36, "training_loss": 622.5390706062317, "training_acc": 61.0, "val_loss": 17.372801899909973, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.24908924102783, "training_acc": 53.0, "val_loss": 124.0182638168335, "val_acc": 48.0}
{"epoch": 38, "training_loss": 292.2755653858185, "training_acc": 51.0, "val_loss": 488.9896869659424, "val_acc": 48.0}
{"epoch": 39, "training_loss": 989.7479529380798, "training_acc": 55.0, "val_loss": 17.377452552318573, "val_acc": 52.0}
