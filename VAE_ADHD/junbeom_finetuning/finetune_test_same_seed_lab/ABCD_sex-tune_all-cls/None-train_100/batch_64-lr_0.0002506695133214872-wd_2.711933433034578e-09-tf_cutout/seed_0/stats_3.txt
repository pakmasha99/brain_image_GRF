"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34252548217773, "training_acc": 47.0, "val_loss": 17.314566671848297, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.46785068511963, "training_acc": 53.0, "val_loss": 17.31114089488983, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.30485272407532, "training_acc": 53.0, "val_loss": 17.4062117934227, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.31783890724182, "training_acc": 53.0, "val_loss": 17.32446998357773, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.48581314086914, "training_acc": 53.0, "val_loss": 17.310334742069244, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13161826133728, "training_acc": 53.0, "val_loss": 17.31962114572525, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28979539871216, "training_acc": 53.0, "val_loss": 17.310062050819397, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21767354011536, "training_acc": 53.0, "val_loss": 17.311862111091614, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14376044273376, "training_acc": 53.0, "val_loss": 17.30780154466629, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.47251963615417, "training_acc": 45.0, "val_loss": 17.30775386095047, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.30315709114075, "training_acc": 53.0, "val_loss": 17.360177636146545, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.232266664505, "training_acc": 53.0, "val_loss": 17.323827743530273, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10879182815552, "training_acc": 53.0, "val_loss": 17.311294376850128, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2883734703064, "training_acc": 50.0, "val_loss": 17.320293188095093, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.30046200752258, "training_acc": 53.0, "val_loss": 17.312775552272797, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.38829159736633, "training_acc": 53.0, "val_loss": 17.32040047645569, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.11087441444397, "training_acc": 53.0, "val_loss": 17.310161888599396, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21271252632141, "training_acc": 53.0, "val_loss": 17.325459420681, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.46388936042786, "training_acc": 47.0, "val_loss": 17.326906323432922, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.33851599693298, "training_acc": 53.0, "val_loss": 17.31743961572647, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12353134155273, "training_acc": 53.0, "val_loss": 17.34323501586914, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.33857727050781, "training_acc": 53.0, "val_loss": 17.354552447795868, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.3304512500763, "training_acc": 53.0, "val_loss": 17.312026023864746, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17380857467651, "training_acc": 53.0, "val_loss": 17.309708893299103, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14999079704285, "training_acc": 53.0, "val_loss": 17.310920357704163, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18924880027771, "training_acc": 53.0, "val_loss": 17.315033078193665, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.24186420440674, "training_acc": 53.0, "val_loss": 17.309504747390747, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14270257949829, "training_acc": 53.0, "val_loss": 17.31586456298828, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15264701843262, "training_acc": 53.0, "val_loss": 17.337581515312195, "val_acc": 52.0}
