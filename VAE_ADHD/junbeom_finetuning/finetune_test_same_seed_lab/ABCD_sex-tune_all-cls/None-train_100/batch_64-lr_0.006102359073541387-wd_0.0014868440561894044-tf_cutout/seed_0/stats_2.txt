"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 561.7220420837402, "training_acc": 39.0, "val_loss": 20434500.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 49922741.06324768, "training_acc": 53.0, "val_loss": 1829.1648864746094, "val_acc": 52.0}
{"epoch": 2, "training_loss": 6174.563186645508, "training_acc": 53.0, "val_loss": 3252.8743743896484, "val_acc": 52.0}
{"epoch": 3, "training_loss": 9114.232406616211, "training_acc": 53.0, "val_loss": 284.44459438323975, "val_acc": 52.0}
{"epoch": 4, "training_loss": 873.3223495483398, "training_acc": 53.0, "val_loss": 96.67486548423767, "val_acc": 48.0}
{"epoch": 5, "training_loss": 573.1370086669922, "training_acc": 47.0, "val_loss": 18.168124556541443, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.03483390808105, "training_acc": 47.0, "val_loss": 39.94678854942322, "val_acc": 52.0}
{"epoch": 7, "training_loss": 278.8510799407959, "training_acc": 53.0, "val_loss": 39.7537499666214, "val_acc": 48.0}
{"epoch": 8, "training_loss": 133.345299243927, "training_acc": 49.0, "val_loss": 21.410785615444183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 79.52724695205688, "training_acc": 53.0, "val_loss": 17.44861602783203, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14532494544983, "training_acc": 53.0, "val_loss": 17.604386806488037, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.5994336605072, "training_acc": 53.0, "val_loss": 19.055581092834473, "val_acc": 52.0}
{"epoch": 12, "training_loss": 73.04783201217651, "training_acc": 53.0, "val_loss": 17.359770834445953, "val_acc": 52.0}
{"epoch": 13, "training_loss": 72.90995073318481, "training_acc": 41.0, "val_loss": 17.505741119384766, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.20556712150574, "training_acc": 47.0, "val_loss": 17.35006272792816, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.94928336143494, "training_acc": 49.0, "val_loss": 17.32814759016037, "val_acc": 52.0}
{"epoch": 16, "training_loss": 71.9696261882782, "training_acc": 45.0, "val_loss": 17.315673828125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.7189998626709, "training_acc": 53.0, "val_loss": 17.57439523935318, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.91982221603394, "training_acc": 53.0, "val_loss": 17.88162589073181, "val_acc": 52.0}
{"epoch": 19, "training_loss": 73.84038138389587, "training_acc": 47.0, "val_loss": 17.34411269426346, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.45981287956238, "training_acc": 55.0, "val_loss": 18.591199815273285, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.50679850578308, "training_acc": 53.0, "val_loss": 17.408570647239685, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.98449897766113, "training_acc": 53.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2120988368988, "training_acc": 53.0, "val_loss": 17.34655350446701, "val_acc": 52.0}
{"epoch": 24, "training_loss": 72.36546277999878, "training_acc": 37.0, "val_loss": 17.30499565601349, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09217047691345, "training_acc": 53.0, "val_loss": 17.615053057670593, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.77463245391846, "training_acc": 53.0, "val_loss": 17.343132197856903, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.59522700309753, "training_acc": 53.0, "val_loss": 17.361755669116974, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.33966374397278, "training_acc": 53.0, "val_loss": 17.422521114349365, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.67558789253235, "training_acc": 53.0, "val_loss": 17.38904118537903, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14344024658203, "training_acc": 53.0, "val_loss": 17.311061918735504, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.36064076423645, "training_acc": 49.0, "val_loss": 17.355383932590485, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.41300511360168, "training_acc": 47.0, "val_loss": 17.307807505130768, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1811900138855, "training_acc": 53.0, "val_loss": 17.351415753364563, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14258217811584, "training_acc": 53.0, "val_loss": 17.308196425437927, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2004508972168, "training_acc": 53.0, "val_loss": 17.306819558143616, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.20059180259705, "training_acc": 53.0, "val_loss": 17.329001426696777, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.22394680976868, "training_acc": 53.0, "val_loss": 17.317362129688263, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14344429969788, "training_acc": 53.0, "val_loss": 17.308257520198822, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.22920727729797, "training_acc": 54.0, "val_loss": 17.329873144626617, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.32866406440735, "training_acc": 49.0, "val_loss": 17.312759160995483, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.1969883441925, "training_acc": 53.0, "val_loss": 17.313571274280548, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.71663975715637, "training_acc": 53.0, "val_loss": 17.326901853084564, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.76399183273315, "training_acc": 47.0, "val_loss": 17.30945110321045, "val_acc": 52.0}
