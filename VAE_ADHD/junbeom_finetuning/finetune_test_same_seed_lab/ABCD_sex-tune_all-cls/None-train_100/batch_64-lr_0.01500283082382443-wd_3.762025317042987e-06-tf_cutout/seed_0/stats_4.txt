"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 782.875602722168, "training_acc": 51.0, "val_loss": 1.33469573218304e+16, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3.94511042700031e+16, "training_acc": 39.0, "val_loss": 17606489.0625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 52194460208.0, "training_acc": 61.0, "val_loss": 3251153000.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8557302900.0, "training_acc": 53.0, "val_loss": 5957685.9375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 330538069.0, "training_acc": 43.0, "val_loss": 89941087.5, "val_acc": 48.0}
{"epoch": 5, "training_loss": 243371277.0, "training_acc": 51.0, "val_loss": 34146771.875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 108452175.5, "training_acc": 47.0, "val_loss": 4010335.9375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 14657058.5625, "training_acc": 49.0, "val_loss": 185952887.5, "val_acc": 52.0}
{"epoch": 8, "training_loss": 456785589.25, "training_acc": 53.0, "val_loss": 14088514.0625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 276901594.0, "training_acc": 49.0, "val_loss": 903162.5, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2839719.84375, "training_acc": 47.0, "val_loss": 3265211.71875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 8996781.2890625, "training_acc": 53.0, "val_loss": 898875.1953125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 5013059.5625, "training_acc": 47.0, "val_loss": 1538608.0078125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3714754.5078125, "training_acc": 53.0, "val_loss": 611366.40625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1707749.578125, "training_acc": 47.0, "val_loss": 2271969.140625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 6531923.7265625, "training_acc": 53.0, "val_loss": 193393.49365234375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 616336.048828125, "training_acc": 45.0, "val_loss": 63339.2822265625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 160419.98779296875, "training_acc": 55.0, "val_loss": 36748.919677734375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 138030.40625, "training_acc": 47.0, "val_loss": 6932.1624755859375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 60440.42333984375, "training_acc": 49.0, "val_loss": 14245.413208007812, "val_acc": 52.0}
{"epoch": 20, "training_loss": 63297.735107421875, "training_acc": 49.0, "val_loss": 33865.20690917969, "val_acc": 52.0}
{"epoch": 21, "training_loss": 94873.19580078125, "training_acc": 53.0, "val_loss": 80085.94970703125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 326203.1572265625, "training_acc": 47.0, "val_loss": 11846.920013427734, "val_acc": 48.0}
{"epoch": 23, "training_loss": 148921.841796875, "training_acc": 51.0, "val_loss": 121553.57666015625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 438238.5517578125, "training_acc": 53.0, "val_loss": 48401.116943359375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 157169.45263671875, "training_acc": 45.0, "val_loss": 29422.7783203125, "val_acc": 48.0}
{"epoch": 26, "training_loss": 102304.79809570312, "training_acc": 47.0, "val_loss": 5238.689422607422, "val_acc": 52.0}
{"epoch": 27, "training_loss": 20621.077087402344, "training_acc": 53.0, "val_loss": 1335.079574584961, "val_acc": 48.0}
{"epoch": 28, "training_loss": 5171.612098693848, "training_acc": 54.0, "val_loss": 1264.5852088928223, "val_acc": 48.0}
{"epoch": 29, "training_loss": 7344.005554199219, "training_acc": 56.0, "val_loss": 423.3224868774414, "val_acc": 48.0}
{"epoch": 30, "training_loss": 3357.8561401367188, "training_acc": 49.0, "val_loss": 2581.015968322754, "val_acc": 48.0}
{"epoch": 31, "training_loss": 7798.681915283203, "training_acc": 48.0, "val_loss": 4952.460479736328, "val_acc": 52.0}
{"epoch": 32, "training_loss": 19561.796447753906, "training_acc": 53.0, "val_loss": 1585.258960723877, "val_acc": 52.0}
{"epoch": 33, "training_loss": 8428.361907958984, "training_acc": 53.0, "val_loss": 4051.7982482910156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 13966.14193725586, "training_acc": 47.0, "val_loss": 636.1950397491455, "val_acc": 52.0}
{"epoch": 35, "training_loss": 3340.367874145508, "training_acc": 52.0, "val_loss": 43.79873275756836, "val_acc": 44.0}
{"epoch": 36, "training_loss": 1875.7941131591797, "training_acc": 52.0, "val_loss": 418.39685440063477, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1522.1329307556152, "training_acc": 52.0, "val_loss": 346.9101905822754, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2488.8199005126953, "training_acc": 49.0, "val_loss": 550.2265453338623, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1906.6637573242188, "training_acc": 49.0, "val_loss": 755.3853034973145, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2302.5336990356445, "training_acc": 55.0, "val_loss": 273.47962856292725, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1765.873062133789, "training_acc": 53.0, "val_loss": 64.23073410987854, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1535.6252899169922, "training_acc": 54.0, "val_loss": 550.8018493652344, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2200.5703468322754, "training_acc": 46.0, "val_loss": 50.858306884765625, "val_acc": 48.0}
{"epoch": 44, "training_loss": 467.53263664245605, "training_acc": 56.0, "val_loss": 198.6594557762146, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1155.6337242126465, "training_acc": 49.0, "val_loss": 42.24371314048767, "val_acc": 44.0}
{"epoch": 46, "training_loss": 849.4992866516113, "training_acc": 44.0, "val_loss": 598.5110282897949, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1913.1535396575928, "training_acc": 53.0, "val_loss": 631.2722206115723, "val_acc": 48.0}
{"epoch": 48, "training_loss": 2294.3190689086914, "training_acc": 47.0, "val_loss": 786.4541053771973, "val_acc": 52.0}
{"epoch": 49, "training_loss": 3414.629592895508, "training_acc": 53.0, "val_loss": 391.50569438934326, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1841.4826736450195, "training_acc": 55.0, "val_loss": 1095.7165718078613, "val_acc": 48.0}
{"epoch": 51, "training_loss": 3629.1557540893555, "training_acc": 47.0, "val_loss": 576.0467529296875, "val_acc": 52.0}
{"epoch": 52, "training_loss": 2654.460693359375, "training_acc": 53.0, "val_loss": 622.4684238433838, "val_acc": 52.0}
{"epoch": 53, "training_loss": 2026.8532485961914, "training_acc": 47.0, "val_loss": 402.2261142730713, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1368.6657981872559, "training_acc": 44.0, "val_loss": 113.60939741134644, "val_acc": 52.0}
{"epoch": 55, "training_loss": 822.2067413330078, "training_acc": 46.0, "val_loss": 39.443573355674744, "val_acc": 44.0}
{"epoch": 56, "training_loss": 533.4189186096191, "training_acc": 47.0, "val_loss": 151.36303901672363, "val_acc": 48.0}
{"epoch": 57, "training_loss": 544.32004737854, "training_acc": 52.0, "val_loss": 250.25618076324463, "val_acc": 52.0}
{"epoch": 58, "training_loss": 819.532717704773, "training_acc": 49.0, "val_loss": 273.4920024871826, "val_acc": 48.0}
{"epoch": 59, "training_loss": 878.683687210083, "training_acc": 50.0, "val_loss": 335.22512912750244, "val_acc": 52.0}
{"epoch": 60, "training_loss": 1288.1227188110352, "training_acc": 54.0, "val_loss": 68.1615948677063, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1247.6557083129883, "training_acc": 42.0, "val_loss": 527.1074295043945, "val_acc": 48.0}
{"epoch": 62, "training_loss": 1460.9902076721191, "training_acc": 49.0, "val_loss": 615.2946472167969, "val_acc": 52.0}
{"epoch": 63, "training_loss": 2526.6057357788086, "training_acc": 53.0, "val_loss": 564.4111156463623, "val_acc": 52.0}
{"epoch": 64, "training_loss": 1676.7099924087524, "training_acc": 53.0, "val_loss": 613.71750831604, "val_acc": 48.0}
{"epoch": 65, "training_loss": 2251.085205078125, "training_acc": 47.0, "val_loss": 158.2335352897644, "val_acc": 52.0}
{"epoch": 66, "training_loss": 750.5102729797363, "training_acc": 55.0, "val_loss": 141.3477897644043, "val_acc": 48.0}
{"epoch": 67, "training_loss": 581.4907531738281, "training_acc": 50.0, "val_loss": 246.39947414398193, "val_acc": 52.0}
{"epoch": 68, "training_loss": 773.5013847351074, "training_acc": 53.0, "val_loss": 355.5143117904663, "val_acc": 48.0}
{"epoch": 69, "training_loss": 1356.704418182373, "training_acc": 47.0, "val_loss": 43.42893064022064, "val_acc": 36.0}
{"epoch": 70, "training_loss": 694.2395706176758, "training_acc": 52.0, "val_loss": 407.5227737426758, "val_acc": 52.0}
{"epoch": 71, "training_loss": 1120.8532409667969, "training_acc": 51.0, "val_loss": 315.9245491027832, "val_acc": 48.0}
{"epoch": 72, "training_loss": 1130.3911323547363, "training_acc": 51.0, "val_loss": 40.697112679481506, "val_acc": 52.0}
{"epoch": 73, "training_loss": 594.1615028381348, "training_acc": 46.0, "val_loss": 48.06435406208038, "val_acc": 52.0}
{"epoch": 74, "training_loss": 540.0953102111816, "training_acc": 48.0, "val_loss": 138.80470991134644, "val_acc": 48.0}
