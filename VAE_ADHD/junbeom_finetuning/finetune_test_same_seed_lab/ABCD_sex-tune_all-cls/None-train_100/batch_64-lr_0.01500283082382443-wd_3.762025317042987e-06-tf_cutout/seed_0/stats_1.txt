"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1593.6717643737793, "training_acc": 35.0, "val_loss": 1.5824307017890967e+24, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.068312240934636e+24, "training_acc": 53.0, "val_loss": 4375785472000.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 537150856626176.0, "training_acc": 53.0, "val_loss": 6136415649792000.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2.1808190409628713e+18, "training_acc": 53.0, "val_loss": 9.58703742222336e+16, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2.127813449613312e+17, "training_acc": 53.0, "val_loss": 558705252761600.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2026118718685184.0, "training_acc": 53.0, "val_loss": 302842368000.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1897377261682688.0, "training_acc": 51.0, "val_loss": 32509335961600.0, "val_acc": 48.0}
{"epoch": 7, "training_loss": 123404413829120.0, "training_acc": 49.0, "val_loss": 26439386726400.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 82242931916800.0, "training_acc": 53.0, "val_loss": 3443075072000.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 13161951494144.0, "training_acc": 49.0, "val_loss": 26530577600.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2195361636352.0, "training_acc": 51.0, "val_loss": 746912409600.0, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2419724013568.0, "training_acc": 53.0, "val_loss": 295282995200.0, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1875078651904.0, "training_acc": 49.0, "val_loss": 713214310400.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2101837881344.0, "training_acc": 47.0, "val_loss": 276573286400.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1066424659968.0, "training_acc": 53.0, "val_loss": 114910668800.0, "val_acc": 52.0}
{"epoch": 15, "training_loss": 539906150400.0, "training_acc": 55.0, "val_loss": 107547264000.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 291970693632.0, "training_acc": 55.0, "val_loss": 23843556800.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 132070774784.0, "training_acc": 59.0, "val_loss": 43969798400.0, "val_acc": 48.0}
{"epoch": 18, "training_loss": 305317621760.0, "training_acc": 51.0, "val_loss": 2541934600.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 135325197312.0, "training_acc": 43.0, "val_loss": 83604224000.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 260911068160.0, "training_acc": 47.0, "val_loss": 299244620800.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1018086123520.0, "training_acc": 53.0, "val_loss": 10644918400.0, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72510325248.0, "training_acc": 51.0, "val_loss": 594096588800.0, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2189642584064.0, "training_acc": 51.0, "val_loss": 3.76956629549056e+16, "val_acc": 52.0}
{"epoch": 24, "training_loss": 9.94199669225554e+16, "training_acc": 49.0, "val_loss": 8918237026713600.0, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2.9795858445133414e+17, "training_acc": 49.0, "val_loss": 1.1266189950976e+16, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3.542278250220749e+16, "training_acc": 47.0, "val_loss": 7979676781772800.0, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3.1048612922261504e+16, "training_acc": 47.0, "val_loss": 1765032329216000.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 4814018615181312.0, "training_acc": 53.0, "val_loss": 205224607744000.0, "val_acc": 48.0}
{"epoch": 29, "training_loss": 934888391835648.0, "training_acc": 47.0, "val_loss": 82772878950400.0, "val_acc": 48.0}
{"epoch": 30, "training_loss": 246925227196416.0, "training_acc": 47.0, "val_loss": 3345898700800.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 48343102521344.0, "training_acc": 39.0, "val_loss": 2649938944000.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 356121132924928.0, "training_acc": 47.0, "val_loss": 3752315699200.0, "val_acc": 52.0}
{"epoch": 33, "training_loss": 10849422934016.0, "training_acc": 53.0, "val_loss": 162252154470400.0, "val_acc": 52.0}
{"epoch": 34, "training_loss": 536045531168768.0, "training_acc": 53.0, "val_loss": 12460285952000.0, "val_acc": 52.0}
{"epoch": 35, "training_loss": 73608642691072.0, "training_acc": 51.0, "val_loss": 16953409536000.0, "val_acc": 48.0}
{"epoch": 36, "training_loss": 50713815154688.0, "training_acc": 51.0, "val_loss": 3667789414400.0, "val_acc": 48.0}
{"epoch": 37, "training_loss": 9004805709824.0, "training_acc": 55.0, "val_loss": 60037689600.0, "val_acc": 48.0}
