"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 336.1381721496582, "training_acc": 55.0, "val_loss": 8.883899704142843e+24, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2.7152041933356377e+25, "training_acc": 53.0, "val_loss": 2.033362396498841e+24, "val_acc": 52.0}
{"epoch": 2, "training_loss": 6.796574123066536e+24, "training_acc": 53.0, "val_loss": 5.478203919481375e+23, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.3224521970445646e+24, "training_acc": 53.0, "val_loss": 2.207799076328571e+19, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1.5131463980134244e+21, "training_acc": 53.0, "val_loss": 2.3194422088306786e+21, "val_acc": 48.0}
{"epoch": 5, "training_loss": 7.781429686400683e+21, "training_acc": 49.0, "val_loss": 6.4860754422215475e+19, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.6008730850485076e+20, "training_acc": 53.0, "val_loss": 2.16873568305152e+16, "val_acc": 52.0}
{"epoch": 7, "training_loss": 5.600739037334733e+16, "training_acc": 53.0, "val_loss": 4104011120640000.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1.3880132951343104e+16, "training_acc": 47.0, "val_loss": 645269762867200.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1547382907600896.0, "training_acc": 55.0, "val_loss": 8143836774400.0, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4053322977771520.0, "training_acc": 53.0, "val_loss": 132418266726400.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 376729720848384.0, "training_acc": 53.0, "val_loss": 67749340774400.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 210391682252800.0, "training_acc": 45.0, "val_loss": 5525591654400.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 89630782259200.0, "training_acc": 55.0, "val_loss": 13242996326400.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 45680481009664.0, "training_acc": 47.0, "val_loss": 3412885708800.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 31356832710656.0, "training_acc": 49.0, "val_loss": 3044016947200.0, "val_acc": 52.0}
{"epoch": 16, "training_loss": 10387297959936.0, "training_acc": 47.0, "val_loss": 426319539200.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 128027770486784.0, "training_acc": 55.0, "val_loss": 5765711872000.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 75338913677312.0, "training_acc": 53.0, "val_loss": 23208837120000.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67450981515264.0, "training_acc": 53.0, "val_loss": 8569136742400.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 30218921181184.0, "training_acc": 53.0, "val_loss": 1452486553600.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6735248785408.0, "training_acc": 53.0, "val_loss": 1034884096000.0, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2895546980352.0, "training_acc": 53.0, "val_loss": 44128774400.0, "val_acc": 52.0}
{"epoch": 23, "training_loss": 262602446848.0, "training_acc": 47.0, "val_loss": 2934818406400.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 8332093378560.0, "training_acc": 47.0, "val_loss": 368754347212800.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 945989076680704.0, "training_acc": 51.0, "val_loss": 2276165017600.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 16306109546496.0, "training_acc": 47.0, "val_loss": 17404719923200.0, "val_acc": 48.0}
{"epoch": 27, "training_loss": 58176387219456.0, "training_acc": 47.0, "val_loss": 1368291020800.0, "val_acc": 48.0}
{"epoch": 28, "training_loss": 5782544859136.0, "training_acc": 47.0, "val_loss": 1970047590400.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 8324200038400.0, "training_acc": 53.0, "val_loss": 1185339494400.0, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4543736791040.0, "training_acc": 53.0, "val_loss": 798461132800.0, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2690233155584.0, "training_acc": 53.0, "val_loss": 139267763200.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 603932612608.0, "training_acc": 49.0, "val_loss": 59952416000.0, "val_acc": 48.0}
{"epoch": 33, "training_loss": 269502755840.0, "training_acc": 47.0, "val_loss": 524385843200.0, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1387003411968.0, "training_acc": 53.0, "val_loss": 115006131200.0, "val_acc": 48.0}
{"epoch": 35, "training_loss": 459478744064.0, "training_acc": 47.0, "val_loss": 69656435200.0, "val_acc": 48.0}
{"epoch": 36, "training_loss": 200687939584.0, "training_acc": 51.0, "val_loss": 7706822400.0, "val_acc": 52.0}
{"epoch": 37, "training_loss": 75557272576.0, "training_acc": 47.0, "val_loss": 6999040000.0, "val_acc": 48.0}
{"epoch": 38, "training_loss": 147508854784.0, "training_acc": 37.0, "val_loss": 38155788800.0, "val_acc": 52.0}
{"epoch": 39, "training_loss": 127609307648.0, "training_acc": 53.0, "val_loss": 3560486400.0, "val_acc": 52.0}
{"epoch": 40, "training_loss": 35440047360.0, "training_acc": 49.0, "val_loss": 22714560000.0, "val_acc": 48.0}
{"epoch": 41, "training_loss": 89371608832.0, "training_acc": 47.0, "val_loss": 13054699200.0, "val_acc": 48.0}
{"epoch": 42, "training_loss": 34937889760.0, "training_acc": 47.0, "val_loss": 10565011200.0, "val_acc": 52.0}
{"epoch": 43, "training_loss": 57070256896.0, "training_acc": 53.0, "val_loss": 17101523200.0, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62229629440.0, "training_acc": 53.0, "val_loss": 6345585600.0, "val_acc": 52.0}
{"epoch": 45, "training_loss": 14277637884.0, "training_acc": 54.0, "val_loss": 7709564800.0, "val_acc": 48.0}
{"epoch": 46, "training_loss": 32429948544.0, "training_acc": 47.0, "val_loss": 7853258400.0, "val_acc": 48.0}
{"epoch": 47, "training_loss": 28277062976.0, "training_acc": 47.0, "val_loss": 628850400.0, "val_acc": 48.0}
{"epoch": 48, "training_loss": 9809878464.0, "training_acc": 49.0, "val_loss": 7346904800.0, "val_acc": 52.0}
{"epoch": 49, "training_loss": 27733748544.0, "training_acc": 53.0, "val_loss": 3774054400.0, "val_acc": 52.0}
{"epoch": 50, "training_loss": 12204959808.0, "training_acc": 53.0, "val_loss": 383447675.0, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2164340320.0, "training_acc": 47.0, "val_loss": 118646787.5, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1835081264.0, "training_acc": 56.0, "val_loss": 1675994300.0, "val_acc": 52.0}
{"epoch": 53, "training_loss": 5633840400.0, "training_acc": 53.0, "val_loss": 640514300.0, "val_acc": 48.0}
{"epoch": 54, "training_loss": 2722655504.0, "training_acc": 47.0, "val_loss": 122583550.0, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1759950336.0, "training_acc": 54.0, "val_loss": 1659299800.0, "val_acc": 52.0}
{"epoch": 56, "training_loss": 5907692880.0, "training_acc": 53.0, "val_loss": 161168375.0, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1033325568.0, "training_acc": 49.0, "val_loss": 292653550.0, "val_acc": 52.0}
{"epoch": 58, "training_loss": 780894464.0, "training_acc": 51.0, "val_loss": 187166712.5, "val_acc": 48.0}
{"epoch": 59, "training_loss": 1701936096.0, "training_acc": 45.0, "val_loss": 583170550.0, "val_acc": 52.0}
{"epoch": 60, "training_loss": 2225371400.0, "training_acc": 51.0, "val_loss": 448540150.0, "val_acc": 48.0}
{"epoch": 61, "training_loss": 2601775648.0, "training_acc": 41.0, "val_loss": 687970550.0, "val_acc": 52.0}
{"epoch": 62, "training_loss": 1953862908.0, "training_acc": 53.0, "val_loss": 48362243.75, "val_acc": 48.0}
{"epoch": 63, "training_loss": 755630084.0, "training_acc": 45.0, "val_loss": 1814454400.0, "val_acc": 52.0}
{"epoch": 64, "training_loss": 7511507552.0, "training_acc": 53.0, "val_loss": 962071900.0, "val_acc": 52.0}
{"epoch": 65, "training_loss": 3894450448.0, "training_acc": 53.0, "val_loss": 1662980400.0, "val_acc": 48.0}
{"epoch": 66, "training_loss": 5652125728.0, "training_acc": 47.0, "val_loss": 759807200.0, "val_acc": 52.0}
{"epoch": 67, "training_loss": 3794486144.0, "training_acc": 53.0, "val_loss": 1019306200.0, "val_acc": 52.0}
{"epoch": 68, "training_loss": 2657790086.0, "training_acc": 53.0, "val_loss": 1487164500.0, "val_acc": 48.0}
{"epoch": 69, "training_loss": 6990687552.0, "training_acc": 47.0, "val_loss": 1725762000.0, "val_acc": 48.0}
{"epoch": 70, "training_loss": 5719827552.0, "training_acc": 47.0, "val_loss": 323755375.0, "val_acc": 52.0}
{"epoch": 71, "training_loss": 2086070656.0, "training_acc": 53.0, "val_loss": 697941400.0, "val_acc": 52.0}
{"epoch": 72, "training_loss": 2292934980.0, "training_acc": 53.0, "val_loss": 345990525.0, "val_acc": 48.0}
{"epoch": 73, "training_loss": 1524987076.0, "training_acc": 47.0, "val_loss": 63120568.75, "val_acc": 52.0}
{"epoch": 74, "training_loss": 760860420.0, "training_acc": 49.0, "val_loss": 177566337.5, "val_acc": 52.0}
{"epoch": 75, "training_loss": 595263489.0, "training_acc": 62.0, "val_loss": 12496700.78125, "val_acc": 44.0}
{"epoch": 76, "training_loss": 107379191.0, "training_acc": 57.0, "val_loss": 126714875.0, "val_acc": 52.0}
{"epoch": 77, "training_loss": 455313477.0, "training_acc": 50.0, "val_loss": 94821568.75, "val_acc": 52.0}
{"epoch": 78, "training_loss": 289561345.25, "training_acc": 56.0, "val_loss": 115622850.0, "val_acc": 48.0}
{"epoch": 79, "training_loss": 342427328.0, "training_acc": 56.0, "val_loss": 10578178.125, "val_acc": 64.0}
{"epoch": 80, "training_loss": 171326592.0, "training_acc": 53.0, "val_loss": 160765825.0, "val_acc": 48.0}
{"epoch": 81, "training_loss": 490861442.5, "training_acc": 49.0, "val_loss": 169503487.5, "val_acc": 52.0}
{"epoch": 82, "training_loss": 637262268.0, "training_acc": 53.0, "val_loss": 105148537.5, "val_acc": 48.0}
{"epoch": 83, "training_loss": 399492543.0, "training_acc": 46.0, "val_loss": 179423287.5, "val_acc": 52.0}
{"epoch": 84, "training_loss": 698645564.0, "training_acc": 53.0, "val_loss": 59307656.25, "val_acc": 48.0}
{"epoch": 85, "training_loss": 233380958.0, "training_acc": 48.0, "val_loss": 139757562.5, "val_acc": 52.0}
{"epoch": 86, "training_loss": 619960008.0, "training_acc": 53.0, "val_loss": 23919746.875, "val_acc": 48.0}
{"epoch": 87, "training_loss": 195192894.0, "training_acc": 47.0, "val_loss": 14571387.5, "val_acc": 52.0}
{"epoch": 88, "training_loss": 129240956.0, "training_acc": 49.0, "val_loss": 52177671.875, "val_acc": 48.0}
{"epoch": 89, "training_loss": 184139462.0, "training_acc": 55.0, "val_loss": 18171964.0625, "val_acc": 52.0}
{"epoch": 90, "training_loss": 181396099.0, "training_acc": 51.0, "val_loss": 6693117.96875, "val_acc": 56.0}
{"epoch": 91, "training_loss": 164923523.0, "training_acc": 53.0, "val_loss": 70164806.25, "val_acc": 48.0}
{"epoch": 92, "training_loss": 224147077.0, "training_acc": 45.0, "val_loss": 116717887.5, "val_acc": 52.0}
{"epoch": 93, "training_loss": 466629188.0, "training_acc": 53.0, "val_loss": 111287487.5, "val_acc": 48.0}
{"epoch": 94, "training_loss": 475271232.0, "training_acc": 46.0, "val_loss": 50671034.375, "val_acc": 52.0}
{"epoch": 95, "training_loss": 185351656.5, "training_acc": 51.0, "val_loss": 90140875.0, "val_acc": 48.0}
{"epoch": 96, "training_loss": 350235389.0, "training_acc": 45.0, "val_loss": 130269112.5, "val_acc": 52.0}
{"epoch": 97, "training_loss": 613146110.0, "training_acc": 53.0, "val_loss": 60532537.5, "val_acc": 52.0}
{"epoch": 98, "training_loss": 324076614.0, "training_acc": 63.0, "val_loss": 251745850.0, "val_acc": 48.0}
{"epoch": 99, "training_loss": 879922554.0, "training_acc": 47.0, "val_loss": 79262262.5, "val_acc": 52.0}
{"epoch": 100, "training_loss": 422471166.0, "training_acc": 53.0, "val_loss": 92416062.5, "val_acc": 52.0}
{"epoch": 101, "training_loss": 365583296.0, "training_acc": 55.0, "val_loss": 102073087.5, "val_acc": 48.0}
{"epoch": 102, "training_loss": 299751739.5, "training_acc": 47.0, "val_loss": 5687870.3125, "val_acc": 52.0}
{"epoch": 103, "training_loss": 74152901.0, "training_acc": 44.0, "val_loss": 59328568.75, "val_acc": 52.0}
{"epoch": 104, "training_loss": 211655722.5, "training_acc": 49.0, "val_loss": 32500475.0, "val_acc": 52.0}
{"epoch": 105, "training_loss": 209738755.0, "training_acc": 45.0, "val_loss": 14739548.4375, "val_acc": 52.0}
{"epoch": 106, "training_loss": 79116380.5, "training_acc": 50.0, "val_loss": 45793115.625, "val_acc": 52.0}
{"epoch": 107, "training_loss": 221486088.5, "training_acc": 46.0, "val_loss": 32516475.0, "val_acc": 52.0}
{"epoch": 108, "training_loss": 171421176.0, "training_acc": 46.0, "val_loss": 5224253.515625, "val_acc": 44.0}
{"epoch": 109, "training_loss": 67880832.25, "training_acc": 45.0, "val_loss": 36254140.625, "val_acc": 52.0}
{"epoch": 110, "training_loss": 113963635.25, "training_acc": 59.0, "val_loss": 15495900.0, "val_acc": 52.0}
{"epoch": 111, "training_loss": 118433598.5, "training_acc": 51.0, "val_loss": 19885082.8125, "val_acc": 52.0}
{"epoch": 112, "training_loss": 189266308.0, "training_acc": 40.0, "val_loss": 41345334.375, "val_acc": 52.0}
{"epoch": 113, "training_loss": 153583812.0, "training_acc": 51.0, "val_loss": 26122843.75, "val_acc": 52.0}
{"epoch": 114, "training_loss": 184005278.0, "training_acc": 50.0, "val_loss": 7536739.0625, "val_acc": 52.0}
{"epoch": 115, "training_loss": 140639298.0, "training_acc": 52.0, "val_loss": 57070200.0, "val_acc": 52.0}
{"epoch": 116, "training_loss": 345760194.0, "training_acc": 42.0, "val_loss": 84622918.75, "val_acc": 48.0}
{"epoch": 117, "training_loss": 298283424.0, "training_acc": 51.0, "val_loss": 76521300.0, "val_acc": 52.0}
{"epoch": 118, "training_loss": 286850288.5, "training_acc": 44.0, "val_loss": 8344194.53125, "val_acc": 48.0}
{"epoch": 119, "training_loss": 153076800.0, "training_acc": 45.0, "val_loss": 9455932.8125, "val_acc": 52.0}
{"epoch": 120, "training_loss": 300031542.0, "training_acc": 48.0, "val_loss": 147084350.0, "val_acc": 48.0}
{"epoch": 121, "training_loss": 408774882.75, "training_acc": 49.0, "val_loss": 148018775.0, "val_acc": 52.0}
{"epoch": 122, "training_loss": 695373244.0, "training_acc": 53.0, "val_loss": 122157762.5, "val_acc": 52.0}
{"epoch": 123, "training_loss": 279075044.0, "training_acc": 61.0, "val_loss": 99178781.25, "val_acc": 48.0}
{"epoch": 124, "training_loss": 319923336.0, "training_acc": 47.0, "val_loss": 107210850.0, "val_acc": 52.0}
{"epoch": 125, "training_loss": 473202758.0, "training_acc": 53.0, "val_loss": 67952056.25, "val_acc": 52.0}
{"epoch": 126, "training_loss": 331277699.0, "training_acc": 50.0, "val_loss": 128567362.5, "val_acc": 48.0}
{"epoch": 127, "training_loss": 366838692.5, "training_acc": 47.0, "val_loss": 156111800.0, "val_acc": 52.0}
