"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 923.3630981445312, "training_acc": 55.0, "val_loss": 292589168230400.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 800166746826897.0, "training_acc": 45.0, "val_loss": 1493935500.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3872812296.0, "training_acc": 53.0, "val_loss": 31500528.125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 100936479.75, "training_acc": 47.0, "val_loss": 303449.2431640625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 15816580.875, "training_acc": 51.0, "val_loss": 10009844.53125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 29122098.96875, "training_acc": 53.0, "val_loss": 441037.59765625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1335598.716796875, "training_acc": 53.0, "val_loss": 8645.857238769531, "val_acc": 48.0}
{"epoch": 7, "training_loss": 695559.673828125, "training_acc": 49.0, "val_loss": 740241650.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3658946560.0, "training_acc": 53.0, "val_loss": 121986200.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 664897984.0, "training_acc": 47.0, "val_loss": 964373300.0, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2255653455.75, "training_acc": 53.0, "val_loss": 10471666.40625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 49436948.0, "training_acc": 53.0, "val_loss": 5257732.03125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1759968298.0, "training_acc": 53.0, "val_loss": 7867685.15625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 19681711.90625, "training_acc": 53.0, "val_loss": 2394588.671875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 8483504.46875, "training_acc": 47.0, "val_loss": 643134.375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2295237.0859375, "training_acc": 49.0, "val_loss": 6671954.6875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 26737341.125, "training_acc": 47.0, "val_loss": 12581832.8125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 677625740.0, "training_acc": 47.0, "val_loss": 7179258.59375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 47418237.0, "training_acc": 47.0, "val_loss": 88812.78686523438, "val_acc": 52.0}
{"epoch": 19, "training_loss": 381011.314453125, "training_acc": 53.0, "val_loss": 1661538.8671875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 6420719.515625, "training_acc": 51.0, "val_loss": 3087340.4296875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 9014556.6640625, "training_acc": 47.0, "val_loss": 12829083.59375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 35371189.3125, "training_acc": 53.0, "val_loss": 8832889.84375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 37879038.875, "training_acc": 47.0, "val_loss": 12025300.0, "val_acc": 48.0}
{"epoch": 24, "training_loss": 36827551.5, "training_acc": 47.0, "val_loss": 306171.7529296875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 48400247.5, "training_acc": 56.0, "val_loss": 113702.25830078125, "val_acc": 52.0}
