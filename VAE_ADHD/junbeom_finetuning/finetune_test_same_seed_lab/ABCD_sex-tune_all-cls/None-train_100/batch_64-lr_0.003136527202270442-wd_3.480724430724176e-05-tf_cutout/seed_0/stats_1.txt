"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 277.8969669342041, "training_acc": 43.0, "val_loss": 5930.820083618164, "val_acc": 48.0}
{"epoch": 1, "training_loss": 13970.507279396057, "training_acc": 55.0, "val_loss": 18.26145499944687, "val_acc": 52.0}
{"epoch": 2, "training_loss": 715.5316734313965, "training_acc": 47.0, "val_loss": 23.578844964504242, "val_acc": 52.0}
{"epoch": 3, "training_loss": 89.25397419929504, "training_acc": 53.0, "val_loss": 18.160994350910187, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.22129845619202, "training_acc": 53.0, "val_loss": 17.35120415687561, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33875632286072, "training_acc": 53.0, "val_loss": 17.30458438396454, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.38302874565125, "training_acc": 47.0, "val_loss": 17.308323085308075, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.0734794139862, "training_acc": 53.0, "val_loss": 17.69964247941971, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.89276170730591, "training_acc": 53.0, "val_loss": 17.31404811143875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.24619388580322, "training_acc": 53.0, "val_loss": 17.316265404224396, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.75809788703918, "training_acc": 37.0, "val_loss": 17.313289642333984, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.21959328651428, "training_acc": 53.0, "val_loss": 17.350584268569946, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19125604629517, "training_acc": 53.0, "val_loss": 17.311565577983856, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.10424733161926, "training_acc": 53.0, "val_loss": 17.31262356042862, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31048083305359, "training_acc": 53.0, "val_loss": 17.310073971748352, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29342651367188, "training_acc": 53.0, "val_loss": 17.325830459594727, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16914796829224, "training_acc": 53.0, "val_loss": 17.314468324184418, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15441989898682, "training_acc": 53.0, "val_loss": 17.31962412595749, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.28088188171387, "training_acc": 53.0, "val_loss": 17.32371300458908, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24714684486389, "training_acc": 53.0, "val_loss": 17.347289621829987, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1382987499237, "training_acc": 53.0, "val_loss": 17.310820519924164, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.53128433227539, "training_acc": 53.0, "val_loss": 17.31182485818863, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18850517272949, "training_acc": 53.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12713718414307, "training_acc": 53.0, "val_loss": 17.315730452537537, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1891541481018, "training_acc": 53.0, "val_loss": 17.33747273683548, "val_acc": 52.0}
