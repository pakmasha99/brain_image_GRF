"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 237.2843418121338, "training_acc": 42.0, "val_loss": 23455.682373046875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 55236.60218811035, "training_acc": 55.0, "val_loss": 160.4804515838623, "val_acc": 48.0}
{"epoch": 2, "training_loss": 440.64755153656006, "training_acc": 47.0, "val_loss": 19.133560359477997, "val_acc": 52.0}
{"epoch": 3, "training_loss": 76.14382719993591, "training_acc": 45.0, "val_loss": 51.66863203048706, "val_acc": 52.0}
{"epoch": 4, "training_loss": 148.0041048526764, "training_acc": 53.0, "val_loss": 19.370006024837494, "val_acc": 48.0}
{"epoch": 5, "training_loss": 75.80754113197327, "training_acc": 47.0, "val_loss": 17.308834195137024, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.38590550422668, "training_acc": 53.0, "val_loss": 17.31102019548416, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.36114883422852, "training_acc": 51.0, "val_loss": 17.672856152057648, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.16088509559631, "training_acc": 53.0, "val_loss": 17.311950027942657, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20230841636658, "training_acc": 53.0, "val_loss": 17.448963224887848, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.51412320137024, "training_acc": 53.0, "val_loss": 17.31359213590622, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.677969455719, "training_acc": 53.0, "val_loss": 17.387616634368896, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.09644746780396, "training_acc": 47.0, "val_loss": 17.310836911201477, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.07362842559814, "training_acc": 53.0, "val_loss": 17.461341619491577, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.37127423286438, "training_acc": 53.0, "val_loss": 17.401202023029327, "val_acc": 52.0}
{"epoch": 15, "training_loss": 73.46335554122925, "training_acc": 47.0, "val_loss": 17.49989539384842, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.7256178855896, "training_acc": 53.0, "val_loss": 17.320479452610016, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.86148595809937, "training_acc": 55.0, "val_loss": 17.846770584583282, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.95947790145874, "training_acc": 45.0, "val_loss": 17.444005608558655, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.13489079475403, "training_acc": 53.0, "val_loss": 17.32635647058487, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.17828130722046, "training_acc": 49.0, "val_loss": 17.38857626914978, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29595923423767, "training_acc": 51.0, "val_loss": 17.38736629486084, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.09413456916809, "training_acc": 53.0, "val_loss": 17.382484674453735, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24530339241028, "training_acc": 53.0, "val_loss": 17.373190820217133, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.80305862426758, "training_acc": 47.0, "val_loss": 17.392753064632416, "val_acc": 52.0}
