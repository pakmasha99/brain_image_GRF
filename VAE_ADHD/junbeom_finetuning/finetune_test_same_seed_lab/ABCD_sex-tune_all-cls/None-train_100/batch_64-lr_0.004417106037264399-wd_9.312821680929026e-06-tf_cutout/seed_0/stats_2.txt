"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 353.5753974914551, "training_acc": 43.0, "val_loss": 7932730.46875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 18788115.288943768, "training_acc": 53.0, "val_loss": 10826.764678955078, "val_acc": 48.0}
{"epoch": 2, "training_loss": 29118.475341796875, "training_acc": 47.0, "val_loss": 98.55725765228271, "val_acc": 52.0}
{"epoch": 3, "training_loss": 787.8755378723145, "training_acc": 47.0, "val_loss": 198.89553785324097, "val_acc": 52.0}
{"epoch": 4, "training_loss": 544.7546305656433, "training_acc": 53.0, "val_loss": 112.228524684906, "val_acc": 48.0}
{"epoch": 5, "training_loss": 343.6967086791992, "training_acc": 47.0, "val_loss": 17.35444813966751, "val_acc": 52.0}
{"epoch": 6, "training_loss": 77.79595160484314, "training_acc": 46.0, "val_loss": 45.79348564147949, "val_acc": 48.0}
{"epoch": 7, "training_loss": 208.38544940948486, "training_acc": 51.0, "val_loss": 26.84943675994873, "val_acc": 52.0}
{"epoch": 8, "training_loss": 97.95016407966614, "training_acc": 47.0, "val_loss": 18.51595789194107, "val_acc": 52.0}
{"epoch": 9, "training_loss": 133.9747486114502, "training_acc": 51.0, "val_loss": 27.30676829814911, "val_acc": 52.0}
{"epoch": 10, "training_loss": 101.70185923576355, "training_acc": 53.0, "val_loss": 46.560513973236084, "val_acc": 48.0}
{"epoch": 11, "training_loss": 338.3766918182373, "training_acc": 47.0, "val_loss": 25.977110862731934, "val_acc": 52.0}
{"epoch": 12, "training_loss": 101.6680359840393, "training_acc": 51.0, "val_loss": 19.932453334331512, "val_acc": 48.0}
{"epoch": 13, "training_loss": 78.00184631347656, "training_acc": 47.0, "val_loss": 17.61184334754944, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.35886430740356, "training_acc": 47.0, "val_loss": 17.31041669845581, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.2601273059845, "training_acc": 53.0, "val_loss": 17.33073890209198, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.3804943561554, "training_acc": 45.0, "val_loss": 17.31456220149994, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.33378553390503, "training_acc": 47.0, "val_loss": 17.986293137073517, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.5069510936737, "training_acc": 53.0, "val_loss": 17.423461377620697, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.00116395950317, "training_acc": 47.0, "val_loss": 17.308470606803894, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.49668097496033, "training_acc": 53.0, "val_loss": 17.348657548427582, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.06838989257812, "training_acc": 53.0, "val_loss": 17.54235178232193, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.43938660621643, "training_acc": 53.0, "val_loss": 17.661559581756592, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.35735440254211, "training_acc": 53.0, "val_loss": 17.33746826648712, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.30649256706238, "training_acc": 51.0, "val_loss": 17.36113578081131, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.4066812992096, "training_acc": 50.0, "val_loss": 17.316478490829468, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.4107666015625, "training_acc": 53.0, "val_loss": 17.365948855876923, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17283749580383, "training_acc": 53.0, "val_loss": 17.316487431526184, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27503943443298, "training_acc": 51.0, "val_loss": 17.342963814735413, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.03185319900513, "training_acc": 41.0, "val_loss": 17.312802374362946, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16739273071289, "training_acc": 53.0, "val_loss": 17.31032282114029, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17837524414062, "training_acc": 53.0, "val_loss": 17.324981093406677, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.38864064216614, "training_acc": 46.0, "val_loss": 17.308489978313446, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.24473285675049, "training_acc": 53.0, "val_loss": 17.35980212688446, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.53069233894348, "training_acc": 53.0, "val_loss": 17.370912432670593, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.56095433235168, "training_acc": 53.0, "val_loss": 17.32252538204193, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.33392357826233, "training_acc": 53.0, "val_loss": 17.30993390083313, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.3166983127594, "training_acc": 53.0, "val_loss": 17.313003540039062, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12355494499207, "training_acc": 53.0, "val_loss": 17.308999598026276, "val_acc": 52.0}
