"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 339.64612197875977, "training_acc": 43.0, "val_loss": 241865775.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 642425110.6946354, "training_acc": 47.0, "val_loss": 1364.8857116699219, "val_acc": 48.0}
{"epoch": 2, "training_loss": 8876.238586425781, "training_acc": 49.0, "val_loss": 65415.350341796875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 184663.3299560547, "training_acc": 47.0, "val_loss": 2326.000213623047, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5530.440170288086, "training_acc": 47.0, "val_loss": 1102.2316932678223, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3826.9283142089844, "training_acc": 53.0, "val_loss": 201.24411582946777, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1119.9905319213867, "training_acc": 59.0, "val_loss": 153.24490070343018, "val_acc": 48.0}
{"epoch": 7, "training_loss": 670.9236736297607, "training_acc": 47.0, "val_loss": 91.13516807556152, "val_acc": 48.0}
{"epoch": 8, "training_loss": 550.9598808288574, "training_acc": 53.0, "val_loss": 93.95869374275208, "val_acc": 52.0}
{"epoch": 9, "training_loss": 414.92480850219727, "training_acc": 53.0, "val_loss": 65.8383309841156, "val_acc": 48.0}
{"epoch": 10, "training_loss": 272.7549571990967, "training_acc": 51.0, "val_loss": 25.41179358959198, "val_acc": 52.0}
{"epoch": 11, "training_loss": 249.95440864562988, "training_acc": 49.0, "val_loss": 24.188746511936188, "val_acc": 48.0}
{"epoch": 12, "training_loss": 121.0731725692749, "training_acc": 55.0, "val_loss": 20.641405880451202, "val_acc": 52.0}
{"epoch": 13, "training_loss": 102.08334732055664, "training_acc": 53.0, "val_loss": 18.63861232995987, "val_acc": 52.0}
{"epoch": 14, "training_loss": 71.8729157447815, "training_acc": 53.0, "val_loss": 85.81110835075378, "val_acc": 48.0}
{"epoch": 15, "training_loss": 226.58340501785278, "training_acc": 59.0, "val_loss": 32.66679346561432, "val_acc": 52.0}
{"epoch": 16, "training_loss": 110.20447707176208, "training_acc": 53.0, "val_loss": 24.18687343597412, "val_acc": 48.0}
{"epoch": 17, "training_loss": 87.38376569747925, "training_acc": 47.0, "val_loss": 17.510753870010376, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.33196353912354, "training_acc": 53.0, "val_loss": 17.399320006370544, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.56996488571167, "training_acc": 57.0, "val_loss": 23.485282063484192, "val_acc": 48.0}
{"epoch": 20, "training_loss": 108.94539880752563, "training_acc": 37.0, "val_loss": 19.79498416185379, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.70572519302368, "training_acc": 53.0, "val_loss": 19.792939722537994, "val_acc": 48.0}
{"epoch": 22, "training_loss": 76.13825988769531, "training_acc": 49.0, "val_loss": 18.44881922006607, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.96488881111145, "training_acc": 53.0, "val_loss": 18.461105227470398, "val_acc": 48.0}
{"epoch": 24, "training_loss": 72.40087461471558, "training_acc": 49.0, "val_loss": 17.441803216934204, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.38597583770752, "training_acc": 53.0, "val_loss": 17.32114553451538, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.51382803916931, "training_acc": 50.0, "val_loss": 17.33417510986328, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19582486152649, "training_acc": 53.0, "val_loss": 17.444021999835968, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.70548796653748, "training_acc": 53.0, "val_loss": 17.309321463108063, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.71840000152588, "training_acc": 53.0, "val_loss": 17.30935573577881, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15118503570557, "training_acc": 55.0, "val_loss": 17.459121346473694, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.18213987350464, "training_acc": 47.0, "val_loss": 17.465801537036896, "val_acc": 52.0}
{"epoch": 32, "training_loss": 80.25972127914429, "training_acc": 53.0, "val_loss": 17.40763634443283, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.2973701953888, "training_acc": 49.0, "val_loss": 17.834703624248505, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.53824543952942, "training_acc": 47.0, "val_loss": 17.439498007297516, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20072197914124, "training_acc": 53.0, "val_loss": 17.445464432239532, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.41457676887512, "training_acc": 53.0, "val_loss": 17.693759500980377, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70.14720177650452, "training_acc": 53.0, "val_loss": 17.380347847938538, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.24183344841003, "training_acc": 50.0, "val_loss": 17.385074496269226, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.25664901733398, "training_acc": 51.0, "val_loss": 20.59583216905594, "val_acc": 52.0}
{"epoch": 40, "training_loss": 76.87216329574585, "training_acc": 51.0, "val_loss": 18.348103761672974, "val_acc": 40.0}
{"epoch": 41, "training_loss": 71.46422123908997, "training_acc": 47.0, "val_loss": 17.85612851381302, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.90355277061462, "training_acc": 53.0, "val_loss": 17.93002039194107, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.50735831260681, "training_acc": 53.0, "val_loss": 17.333896458148956, "val_acc": 52.0}
{"epoch": 44, "training_loss": 71.07535672187805, "training_acc": 43.0, "val_loss": 17.46579110622406, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.47048878669739, "training_acc": 45.0, "val_loss": 17.526356875896454, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.79404282569885, "training_acc": 53.0, "val_loss": 17.331013083457947, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.73010730743408, "training_acc": 49.0, "val_loss": 17.6008939743042, "val_acc": 52.0}
