"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 236.75604057312012, "training_acc": 53.0, "val_loss": 625806.103515625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1562348.4417419434, "training_acc": 51.0, "val_loss": 1492.818832397461, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3929.0928621292114, "training_acc": 53.0, "val_loss": 481.02331161499023, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1320.2394123077393, "training_acc": 47.0, "val_loss": 102.97821760177612, "val_acc": 52.0}
{"epoch": 4, "training_loss": 318.5871047973633, "training_acc": 53.0, "val_loss": 17.869265377521515, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.64667248725891, "training_acc": 43.0, "val_loss": 19.5472851395607, "val_acc": 48.0}
{"epoch": 6, "training_loss": 78.58330726623535, "training_acc": 45.0, "val_loss": 17.31557846069336, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.8885395526886, "training_acc": 53.0, "val_loss": 21.929477155208588, "val_acc": 48.0}
{"epoch": 8, "training_loss": 102.29994106292725, "training_acc": 41.0, "val_loss": 17.3196479678154, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.32564544677734, "training_acc": 49.0, "val_loss": 17.416007816791534, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.63964200019836, "training_acc": 51.0, "val_loss": 17.369253933429718, "val_acc": 52.0}
{"epoch": 11, "training_loss": 74.98116397857666, "training_acc": 53.0, "val_loss": 23.12518060207367, "val_acc": 48.0}
{"epoch": 12, "training_loss": 88.76338291168213, "training_acc": 47.0, "val_loss": 17.329177260398865, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.92847084999084, "training_acc": 52.0, "val_loss": 18.456339836120605, "val_acc": 52.0}
{"epoch": 14, "training_loss": 71.73397397994995, "training_acc": 53.0, "val_loss": 17.34451651573181, "val_acc": 52.0}
{"epoch": 15, "training_loss": 74.32524132728577, "training_acc": 47.0, "val_loss": 17.321540415287018, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.56375050544739, "training_acc": 53.0, "val_loss": 17.931941151618958, "val_acc": 52.0}
{"epoch": 17, "training_loss": 71.27787804603577, "training_acc": 53.0, "val_loss": 17.68668293952942, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.94477796554565, "training_acc": 53.0, "val_loss": 17.337943613529205, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.92276549339294, "training_acc": 53.0, "val_loss": 17.342740297317505, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.35741925239563, "training_acc": 47.0, "val_loss": 17.399626970291138, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.90690875053406, "training_acc": 47.0, "val_loss": 17.391569912433624, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.63799095153809, "training_acc": 47.0, "val_loss": 17.360298335552216, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.4733772277832, "training_acc": 47.0, "val_loss": 17.309875786304474, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.87984585762024, "training_acc": 53.0, "val_loss": 17.397911846637726, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.54619193077087, "training_acc": 53.0, "val_loss": 17.319256067276, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22653698921204, "training_acc": 53.0, "val_loss": 17.31402575969696, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24669408798218, "training_acc": 53.0, "val_loss": 17.310288548469543, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13627314567566, "training_acc": 53.0, "val_loss": 17.311236262321472, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14243197441101, "training_acc": 53.0, "val_loss": 17.32262521982193, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.38082242012024, "training_acc": 53.0, "val_loss": 17.333602905273438, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.11848187446594, "training_acc": 53.0, "val_loss": 17.312641441822052, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.32301735877991, "training_acc": 53.0, "val_loss": 17.3134908080101, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21709132194519, "training_acc": 53.0, "val_loss": 17.31068640947342, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.18388104438782, "training_acc": 53.0, "val_loss": 17.309753596782684, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.28153443336487, "training_acc": 53.0, "val_loss": 17.312823235988617, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13410639762878, "training_acc": 53.0, "val_loss": 17.310845851898193, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20559787750244, "training_acc": 53.0, "val_loss": 17.31024533510208, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12687587738037, "training_acc": 53.0, "val_loss": 17.314040660858154, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.37258386611938, "training_acc": 53.0, "val_loss": 17.324969172477722, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.12994360923767, "training_acc": 53.0, "val_loss": 17.31726825237274, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13258385658264, "training_acc": 53.0, "val_loss": 17.313779890537262, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.18697023391724, "training_acc": 53.0, "val_loss": 17.310859262943268, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13045930862427, "training_acc": 53.0, "val_loss": 17.313282191753387, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13003969192505, "training_acc": 53.0, "val_loss": 17.31596738100052, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.13363289833069, "training_acc": 53.0, "val_loss": 17.318633198738098, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13858008384705, "training_acc": 53.0, "val_loss": 17.320267856121063, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.14936423301697, "training_acc": 53.0, "val_loss": 17.32223480939865, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13706707954407, "training_acc": 53.0, "val_loss": 17.32800453901291, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12978005409241, "training_acc": 53.0, "val_loss": 17.326010763645172, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13912177085876, "training_acc": 53.0, "val_loss": 17.31863021850586, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.16348218917847, "training_acc": 53.0, "val_loss": 17.31502264738083, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.23313927650452, "training_acc": 53.0, "val_loss": 17.31010526418686, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.12166047096252, "training_acc": 53.0, "val_loss": 17.310386896133423, "val_acc": 52.0}
