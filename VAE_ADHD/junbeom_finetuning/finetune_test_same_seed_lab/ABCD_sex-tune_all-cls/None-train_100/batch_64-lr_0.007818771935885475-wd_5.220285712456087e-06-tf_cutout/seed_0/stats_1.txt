"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 415.8730163574219, "training_acc": 53.0, "val_loss": 1736515600.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4582316614.1623535, "training_acc": 47.0, "val_loss": 61349.2919921875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 176098.39721679688, "training_acc": 47.0, "val_loss": 3555.1597595214844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 9490.002052307129, "training_acc": 51.0, "val_loss": 19355.74493408203, "val_acc": 52.0}
{"epoch": 4, "training_loss": 52503.15655517578, "training_acc": 53.0, "val_loss": 161.24051809310913, "val_acc": 52.0}
{"epoch": 5, "training_loss": 19162.959716796875, "training_acc": 49.0, "val_loss": 1371.9621658325195, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3729.7459201812744, "training_acc": 47.0, "val_loss": 116.10137224197388, "val_acc": 52.0}
{"epoch": 7, "training_loss": 332.7675724029541, "training_acc": 53.0, "val_loss": 361.22446060180664, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4404.905456542969, "training_acc": 57.0, "val_loss": 136.953866481781, "val_acc": 48.0}
{"epoch": 9, "training_loss": 892.198112487793, "training_acc": 47.0, "val_loss": 376.2761116027832, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1401.1904220581055, "training_acc": 47.0, "val_loss": 159.54487323760986, "val_acc": 48.0}
{"epoch": 11, "training_loss": 581.9187660217285, "training_acc": 45.0, "val_loss": 48.75379204750061, "val_acc": 52.0}
{"epoch": 12, "training_loss": 423.88146591186523, "training_acc": 61.0, "val_loss": 111.37794256210327, "val_acc": 48.0}
{"epoch": 13, "training_loss": 308.2557895183563, "training_acc": 51.0, "val_loss": 28.56755256652832, "val_acc": 52.0}
{"epoch": 14, "training_loss": 98.92146849632263, "training_acc": 53.0, "val_loss": 18.013329803943634, "val_acc": 52.0}
{"epoch": 15, "training_loss": 66.48476815223694, "training_acc": 61.0, "val_loss": 29.792630672454834, "val_acc": 52.0}
{"epoch": 16, "training_loss": 99.05055546760559, "training_acc": 52.0, "val_loss": 25.47442615032196, "val_acc": 48.0}
{"epoch": 17, "training_loss": 91.79560565948486, "training_acc": 47.0, "val_loss": 22.0291405916214, "val_acc": 52.0}
{"epoch": 18, "training_loss": 85.24376392364502, "training_acc": 53.0, "val_loss": 17.30743795633316, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.95889568328857, "training_acc": 57.0, "val_loss": 18.70301067829132, "val_acc": 48.0}
{"epoch": 20, "training_loss": 73.06464004516602, "training_acc": 49.0, "val_loss": 18.725737929344177, "val_acc": 52.0}
{"epoch": 21, "training_loss": 72.59874820709229, "training_acc": 53.0, "val_loss": 19.263887405395508, "val_acc": 48.0}
{"epoch": 22, "training_loss": 77.59857892990112, "training_acc": 47.0, "val_loss": 17.683957517147064, "val_acc": 52.0}
{"epoch": 23, "training_loss": 72.13499188423157, "training_acc": 53.0, "val_loss": 19.161754846572876, "val_acc": 52.0}
{"epoch": 24, "training_loss": 72.6009750366211, "training_acc": 53.0, "val_loss": 18.66946965456009, "val_acc": 48.0}
{"epoch": 25, "training_loss": 75.5596342086792, "training_acc": 47.0, "val_loss": 17.404037714004517, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.51568126678467, "training_acc": 55.0, "val_loss": 19.296689331531525, "val_acc": 52.0}
{"epoch": 27, "training_loss": 75.36723327636719, "training_acc": 53.0, "val_loss": 17.336826026439667, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.0252776145935, "training_acc": 49.0, "val_loss": 17.912088334560394, "val_acc": 52.0}
{"epoch": 29, "training_loss": 72.8739812374115, "training_acc": 41.0, "val_loss": 17.392192780971527, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.41896152496338, "training_acc": 53.0, "val_loss": 17.350371181964874, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.25290656089783, "training_acc": 53.0, "val_loss": 17.306876182556152, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.28284478187561, "training_acc": 48.0, "val_loss": 17.30787307024002, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.3615562915802, "training_acc": 53.0, "val_loss": 17.34515279531479, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.79051470756531, "training_acc": 45.0, "val_loss": 17.31989085674286, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.10249614715576, "training_acc": 53.0, "val_loss": 17.381222546100616, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.27072501182556, "training_acc": 53.0, "val_loss": 17.332491278648376, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.55679321289062, "training_acc": 46.0, "val_loss": 17.31726974248886, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.70839738845825, "training_acc": 54.0, "val_loss": 17.348724603652954, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.79576992988586, "training_acc": 41.0, "val_loss": 17.31344312429428, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.97685551643372, "training_acc": 53.0, "val_loss": 17.64136403799057, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.09394860267639, "training_acc": 53.0, "val_loss": 17.439401149749756, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.82887673377991, "training_acc": 53.0, "val_loss": 17.31465309858322, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.12658047676086, "training_acc": 53.0, "val_loss": 17.326295375823975, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.99171447753906, "training_acc": 53.0, "val_loss": 17.315347492694855, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.20303225517273, "training_acc": 41.0, "val_loss": 17.342452704906464, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.40280961990356, "training_acc": 53.0, "val_loss": 17.802341282367706, "val_acc": 52.0}
{"epoch": 47, "training_loss": 70.30289006233215, "training_acc": 53.0, "val_loss": 17.32320487499237, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.00035214424133, "training_acc": 53.0, "val_loss": 17.562058568000793, "val_acc": 52.0}
{"epoch": 49, "training_loss": 70.17973828315735, "training_acc": 47.0, "val_loss": 17.324280738830566, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.32197046279907, "training_acc": 53.0, "val_loss": 17.569500207901, "val_acc": 52.0}
