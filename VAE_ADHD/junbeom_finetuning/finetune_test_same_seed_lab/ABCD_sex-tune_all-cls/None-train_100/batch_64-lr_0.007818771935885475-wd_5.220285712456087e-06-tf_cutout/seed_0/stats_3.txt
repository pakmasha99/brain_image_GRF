"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 369.08099365234375, "training_acc": 49.0, "val_loss": 8597952000.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 22119391279.11438, "training_acc": 49.0, "val_loss": 50547.44567871094, "val_acc": 52.0}
{"epoch": 2, "training_loss": 11059118.046875, "training_acc": 45.0, "val_loss": 246319.091796875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 572830.2583007812, "training_acc": 47.0, "val_loss": 19248.336791992188, "val_acc": 52.0}
{"epoch": 4, "training_loss": 52370.14855957031, "training_acc": 53.0, "val_loss": 10610.49575805664, "val_acc": 48.0}
{"epoch": 5, "training_loss": 32700.70526123047, "training_acc": 47.0, "val_loss": 2473.286247253418, "val_acc": 52.0}
{"epoch": 6, "training_loss": 8307.66389465332, "training_acc": 53.0, "val_loss": 2232.6080322265625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 7431.379364013672, "training_acc": 47.0, "val_loss": 765.3704643249512, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2512.8396072387695, "training_acc": 53.0, "val_loss": 32.6315313577652, "val_acc": 48.0}
{"epoch": 9, "training_loss": 346.9788875579834, "training_acc": 47.0, "val_loss": 151.32242441177368, "val_acc": 48.0}
{"epoch": 10, "training_loss": 520.215744972229, "training_acc": 43.0, "val_loss": 129.51117753982544, "val_acc": 48.0}
{"epoch": 11, "training_loss": 388.4202718734741, "training_acc": 53.0, "val_loss": 61.63564324378967, "val_acc": 48.0}
{"epoch": 12, "training_loss": 224.9999418258667, "training_acc": 55.0, "val_loss": 29.911357164382935, "val_acc": 52.0}
{"epoch": 13, "training_loss": 263.29051780700684, "training_acc": 53.0, "val_loss": 59.555673599243164, "val_acc": 48.0}
{"epoch": 14, "training_loss": 212.1834273338318, "training_acc": 53.0, "val_loss": 34.616389870643616, "val_acc": 48.0}
{"epoch": 15, "training_loss": 338.3454780578613, "training_acc": 51.0, "val_loss": 23.238524794578552, "val_acc": 48.0}
{"epoch": 16, "training_loss": 267.0889015197754, "training_acc": 49.0, "val_loss": 20.45316845178604, "val_acc": 48.0}
{"epoch": 17, "training_loss": 153.8886318206787, "training_acc": 45.0, "val_loss": 143.0842399597168, "val_acc": 48.0}
{"epoch": 18, "training_loss": 508.3146963119507, "training_acc": 47.0, "val_loss": 77.59226560592651, "val_acc": 52.0}
{"epoch": 19, "training_loss": 277.3514652252197, "training_acc": 53.0, "val_loss": 79.83206510543823, "val_acc": 48.0}
{"epoch": 20, "training_loss": 215.57463598251343, "training_acc": 55.0, "val_loss": 20.21336555480957, "val_acc": 52.0}
{"epoch": 21, "training_loss": 90.4291844367981, "training_acc": 49.0, "val_loss": 17.49279797077179, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.36262440681458, "training_acc": 53.0, "val_loss": 18.66629123687744, "val_acc": 52.0}
{"epoch": 23, "training_loss": 98.20257043838501, "training_acc": 43.0, "val_loss": 24.31357651948929, "val_acc": 52.0}
{"epoch": 24, "training_loss": 89.09614562988281, "training_acc": 53.0, "val_loss": 19.837917387485504, "val_acc": 48.0}
{"epoch": 25, "training_loss": 84.89455342292786, "training_acc": 47.0, "val_loss": 23.548395931720734, "val_acc": 52.0}
{"epoch": 26, "training_loss": 94.56943655014038, "training_acc": 53.0, "val_loss": 18.285377323627472, "val_acc": 60.0}
{"epoch": 27, "training_loss": 90.0225419998169, "training_acc": 46.0, "val_loss": 17.32407659292221, "val_acc": 52.0}
{"epoch": 28, "training_loss": 78.39467740058899, "training_acc": 49.0, "val_loss": 21.876198053359985, "val_acc": 52.0}
{"epoch": 29, "training_loss": 77.12330460548401, "training_acc": 51.0, "val_loss": 20.525628328323364, "val_acc": 48.0}
{"epoch": 30, "training_loss": 88.34837579727173, "training_acc": 47.0, "val_loss": 17.299798130989075, "val_acc": 52.0}
{"epoch": 31, "training_loss": 72.4038507938385, "training_acc": 52.0, "val_loss": 19.582538306713104, "val_acc": 52.0}
{"epoch": 32, "training_loss": 75.82765507698059, "training_acc": 53.0, "val_loss": 17.479102313518524, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.49180483818054, "training_acc": 46.0, "val_loss": 17.799153923988342, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.82025074958801, "training_acc": 48.0, "val_loss": 17.583611607551575, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.83315467834473, "training_acc": 53.0, "val_loss": 17.62586534023285, "val_acc": 52.0}
{"epoch": 36, "training_loss": 71.06410837173462, "training_acc": 50.0, "val_loss": 17.338095605373383, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.67009282112122, "training_acc": 47.0, "val_loss": 17.323271930217743, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.83436918258667, "training_acc": 48.0, "val_loss": 17.27461963891983, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.80744552612305, "training_acc": 52.0, "val_loss": 17.43391305208206, "val_acc": 52.0}
{"epoch": 40, "training_loss": 70.91632390022278, "training_acc": 51.0, "val_loss": 17.277133464813232, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.33924984931946, "training_acc": 53.0, "val_loss": 17.276592552661896, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.47254610061646, "training_acc": 48.0, "val_loss": 17.277289927005768, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.94343638420105, "training_acc": 56.0, "val_loss": 17.458738386631012, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.55074715614319, "training_acc": 49.0, "val_loss": 17.33488440513611, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.26454401016235, "training_acc": 44.0, "val_loss": 17.425477504730225, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.70157670974731, "training_acc": 50.0, "val_loss": 17.478644847869873, "val_acc": 52.0}
{"epoch": 47, "training_loss": 70.77259564399719, "training_acc": 53.0, "val_loss": 17.413005232810974, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.89243173599243, "training_acc": 52.0, "val_loss": 17.434994876384735, "val_acc": 52.0}
{"epoch": 49, "training_loss": 70.07811450958252, "training_acc": 48.0, "val_loss": 17.48078465461731, "val_acc": 52.0}
{"epoch": 50, "training_loss": 70.20599389076233, "training_acc": 49.0, "val_loss": 17.453426122665405, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.18323397636414, "training_acc": 53.0, "val_loss": 17.670294642448425, "val_acc": 52.0}
{"epoch": 52, "training_loss": 70.14635872840881, "training_acc": 53.0, "val_loss": 17.298461496829987, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.95758748054504, "training_acc": 47.0, "val_loss": 17.57400631904602, "val_acc": 52.0}
{"epoch": 54, "training_loss": 70.21817421913147, "training_acc": 47.0, "val_loss": 17.285142838954926, "val_acc": 52.0}
{"epoch": 55, "training_loss": 80.0350980758667, "training_acc": 52.0, "val_loss": 18.394561111927032, "val_acc": 52.0}
{"epoch": 56, "training_loss": 73.91033673286438, "training_acc": 53.0, "val_loss": 17.621982097625732, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.62550473213196, "training_acc": 53.0, "val_loss": 17.41424947977066, "val_acc": 52.0}
