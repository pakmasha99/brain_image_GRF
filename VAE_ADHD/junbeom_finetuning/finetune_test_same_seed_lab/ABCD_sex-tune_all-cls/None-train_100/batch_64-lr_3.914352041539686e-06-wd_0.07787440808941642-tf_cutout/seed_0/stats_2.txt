"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.54806065559387, "training_acc": 47.0, "val_loss": 17.57924258708954, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.58292508125305, "training_acc": 47.0, "val_loss": 17.50738173723221, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.13979744911194, "training_acc": 47.0, "val_loss": 17.438632249832153, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.74604153633118, "training_acc": 47.0, "val_loss": 17.384296655654907, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.59132385253906, "training_acc": 47.0, "val_loss": 17.343276739120483, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3119592666626, "training_acc": 51.0, "val_loss": 17.322658002376556, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15748643875122, "training_acc": 53.0, "val_loss": 17.318053543567657, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18463349342346, "training_acc": 53.0, "val_loss": 17.325791716575623, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18702912330627, "training_acc": 53.0, "val_loss": 17.33904927968979, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15969133377075, "training_acc": 53.0, "val_loss": 17.35014170408249, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17140913009644, "training_acc": 53.0, "val_loss": 17.356303334236145, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14632892608643, "training_acc": 53.0, "val_loss": 17.356635630130768, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13437604904175, "training_acc": 53.0, "val_loss": 17.35922545194626, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13510227203369, "training_acc": 53.0, "val_loss": 17.35742688179016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13828301429749, "training_acc": 53.0, "val_loss": 17.350856959819794, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12135529518127, "training_acc": 53.0, "val_loss": 17.343714833259583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.120037317276, "training_acc": 53.0, "val_loss": 17.33868420124054, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1668918132782, "training_acc": 53.0, "val_loss": 17.334872484207153, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10443115234375, "training_acc": 53.0, "val_loss": 17.33459383249283, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1057960987091, "training_acc": 53.0, "val_loss": 17.334845662117004, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12520217895508, "training_acc": 53.0, "val_loss": 17.332325875759125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.09911060333252, "training_acc": 53.0, "val_loss": 17.3323854804039, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.08677625656128, "training_acc": 53.0, "val_loss": 17.332221567630768, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.08433294296265, "training_acc": 53.0, "val_loss": 17.332206666469574, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.0900399684906, "training_acc": 53.0, "val_loss": 17.330509424209595, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.068124294281, "training_acc": 53.0, "val_loss": 17.32957810163498, "val_acc": 52.0}
