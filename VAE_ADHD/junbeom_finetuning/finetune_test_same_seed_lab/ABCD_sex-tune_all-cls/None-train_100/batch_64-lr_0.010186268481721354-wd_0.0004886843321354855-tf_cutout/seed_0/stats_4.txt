"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 705.4381942749023, "training_acc": 49.0, "val_loss": 2035393536000.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4997703055113.168, "training_acc": 51.0, "val_loss": 504176.3671875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2245370.28125, "training_acc": 41.0, "val_loss": 880774.609375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2876661.23828125, "training_acc": 47.0, "val_loss": 53063.446044921875, "val_acc": 48.0}
{"epoch": 4, "training_loss": 209187.46923828125, "training_acc": 47.0, "val_loss": 19092.507934570312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 50132.43518066406, "training_acc": 53.0, "val_loss": 26017.282104492188, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69062.18188476562, "training_acc": 53.0, "val_loss": 13218.148803710938, "val_acc": 48.0}
{"epoch": 7, "training_loss": 36486.153076171875, "training_acc": 47.0, "val_loss": 7844.956207275391, "val_acc": 52.0}
{"epoch": 8, "training_loss": 24995.22198486328, "training_acc": 53.0, "val_loss": 97.72518873214722, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1424.777328491211, "training_acc": 53.0, "val_loss": 1378.028678894043, "val_acc": 48.0}
{"epoch": 10, "training_loss": 4045.708713531494, "training_acc": 45.0, "val_loss": 703.3273220062256, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2347.5733757019043, "training_acc": 47.0, "val_loss": 80.9132993221283, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1225.3543243408203, "training_acc": 51.0, "val_loss": 460.7186794281006, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1768.7794570922852, "training_acc": 49.0, "val_loss": 246.634840965271, "val_acc": 52.0}
{"epoch": 14, "training_loss": 978.7501373291016, "training_acc": 43.0, "val_loss": 77.21735835075378, "val_acc": 48.0}
{"epoch": 15, "training_loss": 483.0779800415039, "training_acc": 45.0, "val_loss": 192.40175485610962, "val_acc": 52.0}
{"epoch": 16, "training_loss": 587.1272430419922, "training_acc": 53.0, "val_loss": 90.48495292663574, "val_acc": 48.0}
{"epoch": 17, "training_loss": 413.9384479522705, "training_acc": 47.0, "val_loss": 33.68505537509918, "val_acc": 48.0}
{"epoch": 18, "training_loss": 356.55804443359375, "training_acc": 43.0, "val_loss": 83.24986100196838, "val_acc": 52.0}
{"epoch": 19, "training_loss": 336.8676881790161, "training_acc": 49.0, "val_loss": 34.162697196006775, "val_acc": 52.0}
{"epoch": 20, "training_loss": 156.6512393951416, "training_acc": 53.0, "val_loss": 24.495117366313934, "val_acc": 52.0}
{"epoch": 21, "training_loss": 118.03357410430908, "training_acc": 45.0, "val_loss": 38.703298568725586, "val_acc": 48.0}
{"epoch": 22, "training_loss": 135.48101258277893, "training_acc": 47.0, "val_loss": 18.399493396282196, "val_acc": 52.0}
{"epoch": 23, "training_loss": 80.28591990470886, "training_acc": 53.0, "val_loss": 21.73585444688797, "val_acc": 52.0}
{"epoch": 24, "training_loss": 80.78087878227234, "training_acc": 52.0, "val_loss": 21.99055850505829, "val_acc": 48.0}
{"epoch": 25, "training_loss": 80.95624947547913, "training_acc": 47.0, "val_loss": 59.430599212646484, "val_acc": 52.0}
{"epoch": 26, "training_loss": 202.20049405097961, "training_acc": 41.0, "val_loss": 19.074197113513947, "val_acc": 48.0}
{"epoch": 27, "training_loss": 74.03604435920715, "training_acc": 49.0, "val_loss": 19.544169306755066, "val_acc": 52.0}
{"epoch": 28, "training_loss": 73.07390284538269, "training_acc": 52.0, "val_loss": 19.54275816679001, "val_acc": 48.0}
{"epoch": 29, "training_loss": 73.8340847492218, "training_acc": 51.0, "val_loss": 20.791615545749664, "val_acc": 52.0}
{"epoch": 30, "training_loss": 81.86041259765625, "training_acc": 53.0, "val_loss": 24.738067388534546, "val_acc": 48.0}
{"epoch": 31, "training_loss": 101.00481128692627, "training_acc": 47.0, "val_loss": 24.813956022262573, "val_acc": 52.0}
{"epoch": 32, "training_loss": 99.09213638305664, "training_acc": 53.0, "val_loss": 17.293523252010345, "val_acc": 52.0}
{"epoch": 33, "training_loss": 173.4540147781372, "training_acc": 44.0, "val_loss": 29.686278104782104, "val_acc": 52.0}
{"epoch": 34, "training_loss": 109.0256724357605, "training_acc": 53.0, "val_loss": 70.01258134841919, "val_acc": 48.0}
{"epoch": 35, "training_loss": 239.45547676086426, "training_acc": 45.0, "val_loss": 34.26348567008972, "val_acc": 52.0}
{"epoch": 36, "training_loss": 116.5328459739685, "training_acc": 53.0, "val_loss": 17.306041717529297, "val_acc": 52.0}
{"epoch": 37, "training_loss": 81.20326662063599, "training_acc": 48.0, "val_loss": 25.185099244117737, "val_acc": 48.0}
{"epoch": 38, "training_loss": 93.93851947784424, "training_acc": 47.0, "val_loss": 56.07838034629822, "val_acc": 52.0}
{"epoch": 39, "training_loss": 158.31425166130066, "training_acc": 50.0, "val_loss": 17.496715486049652, "val_acc": 52.0}
{"epoch": 40, "training_loss": 70.7223699092865, "training_acc": 47.0, "val_loss": 17.347078025341034, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.73229503631592, "training_acc": 51.0, "val_loss": 17.571020126342773, "val_acc": 52.0}
{"epoch": 42, "training_loss": 71.28547644615173, "training_acc": 53.0, "val_loss": 17.46377944946289, "val_acc": 52.0}
{"epoch": 43, "training_loss": 72.6941134929657, "training_acc": 53.0, "val_loss": 17.439718544483185, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.85796689987183, "training_acc": 47.0, "val_loss": 17.565937340259552, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.0892596244812, "training_acc": 53.0, "val_loss": 17.298290133476257, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.48916554450989, "training_acc": 43.0, "val_loss": 17.323926091194153, "val_acc": 52.0}
{"epoch": 47, "training_loss": 70.01987528800964, "training_acc": 49.0, "val_loss": 17.32940971851349, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.47338032722473, "training_acc": 49.0, "val_loss": 17.310144007205963, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.26147842407227, "training_acc": 53.0, "val_loss": 17.496439814567566, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.84704613685608, "training_acc": 53.0, "val_loss": 17.42434650659561, "val_acc": 52.0}
{"epoch": 51, "training_loss": 70.33558392524719, "training_acc": 48.0, "val_loss": 17.42471307516098, "val_acc": 52.0}
