"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 338.6224937438965, "training_acc": 50.0, "val_loss": 6504286309580800.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.5469117138138136e+16, "training_acc": 53.0, "val_loss": 293704.345703125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 836294.5966796875, "training_acc": 49.0, "val_loss": 2594481.25, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7465801.8046875, "training_acc": 47.0, "val_loss": 50611.59973144531, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1048618.4296875, "training_acc": 51.0, "val_loss": 11523.582458496094, "val_acc": 48.0}
{"epoch": 5, "training_loss": 329951.130859375, "training_acc": 57.0, "val_loss": 3267688.8671875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 9190036.393066406, "training_acc": 47.0, "val_loss": 94670.20263671875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 327463.216796875, "training_acc": 51.0, "val_loss": 72728.72314453125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2044003.859375, "training_acc": 49.0, "val_loss": 242591.2841796875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 584030.3271484375, "training_acc": 53.0, "val_loss": 558515.478515625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1841003.53125, "training_acc": 43.0, "val_loss": 74944.2626953125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 859432.8671875, "training_acc": 45.0, "val_loss": 301275.5615234375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1308458.1953125, "training_acc": 51.0, "val_loss": 29313.726806640625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 241487.134765625, "training_acc": 59.0, "val_loss": 39377.48107910156, "val_acc": 52.0}
{"epoch": 14, "training_loss": 103821.09375, "training_acc": 59.0, "val_loss": 44135.357666015625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 424388.796875, "training_acc": 51.0, "val_loss": 24045.472717285156, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72235.26977539062, "training_acc": 53.0, "val_loss": 94986.1328125, "val_acc": 48.0}
{"epoch": 17, "training_loss": 255400.53344726562, "training_acc": 51.0, "val_loss": 8439.480590820312, "val_acc": 52.0}
{"epoch": 18, "training_loss": 42559.02294921875, "training_acc": 47.0, "val_loss": 8088.753509521484, "val_acc": 48.0}
{"epoch": 19, "training_loss": 24981.46514892578, "training_acc": 51.0, "val_loss": 4468.471527099609, "val_acc": 52.0}
{"epoch": 20, "training_loss": 12090.209480285645, "training_acc": 51.0, "val_loss": 5744.449996948242, "val_acc": 48.0}
{"epoch": 21, "training_loss": 21778.55078125, "training_acc": 47.0, "val_loss": 986.2846374511719, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4278.103759765625, "training_acc": 53.0, "val_loss": 2248.9824295043945, "val_acc": 48.0}
{"epoch": 23, "training_loss": 6619.941390991211, "training_acc": 55.0, "val_loss": 2703.9106369018555, "val_acc": 48.0}
{"epoch": 24, "training_loss": 9497.187530517578, "training_acc": 47.0, "val_loss": 1253.1888961791992, "val_acc": 52.0}
{"epoch": 25, "training_loss": 4549.898345947266, "training_acc": 53.0, "val_loss": 553.6032676696777, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1662.6279678344727, "training_acc": 45.0, "val_loss": 1391.1012649536133, "val_acc": 52.0}
{"epoch": 27, "training_loss": 5222.295455932617, "training_acc": 53.0, "val_loss": 399.44145679473877, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2442.304641723633, "training_acc": 47.0, "val_loss": 241.42940044403076, "val_acc": 48.0}
{"epoch": 29, "training_loss": 3103.3553466796875, "training_acc": 46.0, "val_loss": 1041.2405014038086, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3651.40567779541, "training_acc": 47.0, "val_loss": 313.78509998321533, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2133.477066040039, "training_acc": 46.0, "val_loss": 791.9623374938965, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1982.3162784576416, "training_acc": 51.0, "val_loss": 175.49147605895996, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1093.5532760620117, "training_acc": 52.0, "val_loss": 334.64982509613037, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1111.5027542114258, "training_acc": 57.0, "val_loss": 351.6430377960205, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1787.1916809082031, "training_acc": 43.0, "val_loss": 401.5815258026123, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1532.9414253234863, "training_acc": 44.0, "val_loss": 136.23123168945312, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1162.3954315185547, "training_acc": 45.0, "val_loss": 458.1510066986084, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1372.3035984039307, "training_acc": 43.0, "val_loss": 297.48034477233887, "val_acc": 48.0}
{"epoch": 39, "training_loss": 794.2056140899658, "training_acc": 55.0, "val_loss": 117.59566068649292, "val_acc": 52.0}
{"epoch": 40, "training_loss": 865.86279296875, "training_acc": 43.0, "val_loss": 30.44475018978119, "val_acc": 44.0}
{"epoch": 41, "training_loss": 671.3556022644043, "training_acc": 53.0, "val_loss": 246.1139678955078, "val_acc": 52.0}
{"epoch": 42, "training_loss": 931.2482643127441, "training_acc": 57.0, "val_loss": 324.1445302963257, "val_acc": 48.0}
{"epoch": 43, "training_loss": 962.1113357543945, "training_acc": 54.0, "val_loss": 199.5021939277649, "val_acc": 52.0}
{"epoch": 44, "training_loss": 725.7089252471924, "training_acc": 53.0, "val_loss": 92.52390265464783, "val_acc": 48.0}
{"epoch": 45, "training_loss": 943.6236801147461, "training_acc": 44.0, "val_loss": 359.55092906951904, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1015.9342498779297, "training_acc": 54.0, "val_loss": 198.86419773101807, "val_acc": 48.0}
{"epoch": 47, "training_loss": 706.9821681976318, "training_acc": 53.0, "val_loss": 97.4190354347229, "val_acc": 52.0}
{"epoch": 48, "training_loss": 676.1258430480957, "training_acc": 52.0, "val_loss": 141.8787956237793, "val_acc": 48.0}
{"epoch": 49, "training_loss": 814.4910926818848, "training_acc": 55.0, "val_loss": 488.7551784515381, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1486.7274780273438, "training_acc": 53.0, "val_loss": 481.23111724853516, "val_acc": 48.0}
{"epoch": 51, "training_loss": 2187.2250595092773, "training_acc": 47.0, "val_loss": 345.7097053527832, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1422.3352851867676, "training_acc": 47.0, "val_loss": 559.0056419372559, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1927.2206954956055, "training_acc": 53.0, "val_loss": 175.8634090423584, "val_acc": 48.0}
{"epoch": 54, "training_loss": 976.9821701049805, "training_acc": 48.0, "val_loss": 90.0384783744812, "val_acc": 52.0}
{"epoch": 55, "training_loss": 417.8257083892822, "training_acc": 60.0, "val_loss": 78.00529599189758, "val_acc": 48.0}
{"epoch": 56, "training_loss": 369.33514976501465, "training_acc": 51.0, "val_loss": 310.94067096710205, "val_acc": 52.0}
{"epoch": 57, "training_loss": 1206.675090789795, "training_acc": 53.0, "val_loss": 22.349917888641357, "val_acc": 40.0}
{"epoch": 58, "training_loss": 407.3919506072998, "training_acc": 49.0, "val_loss": 42.66976714134216, "val_acc": 56.0}
{"epoch": 59, "training_loss": 300.1380252838135, "training_acc": 54.0, "val_loss": 191.15240573883057, "val_acc": 48.0}
{"epoch": 60, "training_loss": 604.4392080307007, "training_acc": 46.0, "val_loss": 283.66992473602295, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1020.6538887023926, "training_acc": 53.0, "val_loss": 71.62313461303711, "val_acc": 48.0}
{"epoch": 62, "training_loss": 457.62485122680664, "training_acc": 42.0, "val_loss": 172.54598140716553, "val_acc": 52.0}
{"epoch": 63, "training_loss": 619.3229026794434, "training_acc": 53.0, "val_loss": 227.52857208251953, "val_acc": 48.0}
{"epoch": 64, "training_loss": 960.9145698547363, "training_acc": 47.0, "val_loss": 423.91467094421387, "val_acc": 52.0}
{"epoch": 65, "training_loss": 1525.2624950408936, "training_acc": 53.0, "val_loss": 135.43195724487305, "val_acc": 48.0}
{"epoch": 66, "training_loss": 464.4443383216858, "training_acc": 48.0, "val_loss": 192.98354387283325, "val_acc": 52.0}
{"epoch": 67, "training_loss": 604.990608215332, "training_acc": 54.0, "val_loss": 281.4258337020874, "val_acc": 48.0}
{"epoch": 68, "training_loss": 1168.1352462768555, "training_acc": 47.0, "val_loss": 100.13060569763184, "val_acc": 52.0}
{"epoch": 69, "training_loss": 530.4937133789062, "training_acc": 54.0, "val_loss": 30.665478110313416, "val_acc": 52.0}
{"epoch": 70, "training_loss": 204.80524349212646, "training_acc": 50.0, "val_loss": 185.1285696029663, "val_acc": 52.0}
{"epoch": 71, "training_loss": 651.0054397583008, "training_acc": 53.0, "val_loss": 216.5712594985962, "val_acc": 48.0}
{"epoch": 72, "training_loss": 907.3947906494141, "training_acc": 47.0, "val_loss": 131.92874193191528, "val_acc": 52.0}
{"epoch": 73, "training_loss": 593.1484527587891, "training_acc": 52.0, "val_loss": 24.886487424373627, "val_acc": 44.0}
{"epoch": 74, "training_loss": 247.98456859588623, "training_acc": 44.0, "val_loss": 94.36452388763428, "val_acc": 52.0}
{"epoch": 75, "training_loss": 288.96157932281494, "training_acc": 55.0, "val_loss": 170.7217812538147, "val_acc": 48.0}
{"epoch": 76, "training_loss": 588.7978343963623, "training_acc": 44.0, "val_loss": 213.5772705078125, "val_acc": 52.0}
