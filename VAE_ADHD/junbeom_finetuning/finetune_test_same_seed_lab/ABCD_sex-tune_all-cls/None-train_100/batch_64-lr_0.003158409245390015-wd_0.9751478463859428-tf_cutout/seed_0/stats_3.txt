"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 203.40974807739258, "training_acc": 51.0, "val_loss": 3149.537467956543, "val_acc": 48.0}
{"epoch": 1, "training_loss": 9059.055374145508, "training_acc": 51.0, "val_loss": 28.69444191455841, "val_acc": 52.0}
{"epoch": 2, "training_loss": 99.91256022453308, "training_acc": 53.0, "val_loss": 17.347480356693268, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.5586187839508, "training_acc": 53.0, "val_loss": 17.349712550640106, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.6716001033783, "training_acc": 53.0, "val_loss": 18.006408214569092, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.55686545372009, "training_acc": 55.0, "val_loss": 18.14516931772232, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.58771634101868, "training_acc": 47.0, "val_loss": 17.4092635512352, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.40128970146179, "training_acc": 53.0, "val_loss": 17.38683730363846, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.92204666137695, "training_acc": 53.0, "val_loss": 17.308829724788666, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.57425308227539, "training_acc": 53.0, "val_loss": 17.315123975276947, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23173117637634, "training_acc": 53.0, "val_loss": 17.308194935321808, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15109729766846, "training_acc": 53.0, "val_loss": 17.310819029808044, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.45315432548523, "training_acc": 53.0, "val_loss": 17.313624918460846, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11064291000366, "training_acc": 53.0, "val_loss": 17.308810353279114, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15666508674622, "training_acc": 53.0, "val_loss": 17.310813069343567, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17787504196167, "training_acc": 53.0, "val_loss": 17.313964664936066, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22223472595215, "training_acc": 53.0, "val_loss": 17.315341532230377, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23499417304993, "training_acc": 53.0, "val_loss": 17.316395044326782, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22210621833801, "training_acc": 53.0, "val_loss": 17.3120379447937, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17319202423096, "training_acc": 53.0, "val_loss": 17.309191823005676, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19978260993958, "training_acc": 53.0, "val_loss": 17.313209176063538, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13493847846985, "training_acc": 53.0, "val_loss": 17.316630482673645, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13757681846619, "training_acc": 53.0, "val_loss": 17.318233847618103, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14338374137878, "training_acc": 53.0, "val_loss": 17.317745089530945, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13404965400696, "training_acc": 53.0, "val_loss": 17.314086854457855, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.25815153121948, "training_acc": 53.0, "val_loss": 17.310313880443573, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14394068717957, "training_acc": 53.0, "val_loss": 17.312145233154297, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15021538734436, "training_acc": 53.0, "val_loss": 17.317546904087067, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.233074426651, "training_acc": 53.0, "val_loss": 17.320574820041656, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13133597373962, "training_acc": 53.0, "val_loss": 17.31501668691635, "val_acc": 52.0}
