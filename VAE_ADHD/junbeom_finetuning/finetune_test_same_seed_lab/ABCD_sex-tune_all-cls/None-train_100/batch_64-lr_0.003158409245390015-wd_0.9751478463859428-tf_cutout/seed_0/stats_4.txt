"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 253.99173164367676, "training_acc": 45.0, "val_loss": 6481.327819824219, "val_acc": 52.0}
{"epoch": 1, "training_loss": 16473.58595442772, "training_acc": 49.0, "val_loss": 18.680453300476074, "val_acc": 48.0}
{"epoch": 2, "training_loss": 165.06454753875732, "training_acc": 53.0, "val_loss": 117.78972148895264, "val_acc": 48.0}
{"epoch": 3, "training_loss": 326.5929367542267, "training_acc": 47.0, "val_loss": 18.46911758184433, "val_acc": 48.0}
{"epoch": 4, "training_loss": 72.90271401405334, "training_acc": 47.0, "val_loss": 17.396576702594757, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.5219042301178, "training_acc": 47.0, "val_loss": 17.316637933254242, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2158625125885, "training_acc": 53.0, "val_loss": 17.326413094997406, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1905243396759, "training_acc": 53.0, "val_loss": 17.361104488372803, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.27317476272583, "training_acc": 53.0, "val_loss": 17.31129288673401, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1772210597992, "training_acc": 53.0, "val_loss": 17.308910191059113, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.48674201965332, "training_acc": 53.0, "val_loss": 17.31414794921875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14367294311523, "training_acc": 53.0, "val_loss": 17.30899065732956, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17905497550964, "training_acc": 53.0, "val_loss": 17.311690747737885, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2084231376648, "training_acc": 53.0, "val_loss": 17.31107234954834, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21473145484924, "training_acc": 53.0, "val_loss": 17.310506105422974, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18851113319397, "training_acc": 53.0, "val_loss": 17.31073409318924, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18874740600586, "training_acc": 53.0, "val_loss": 17.309780418872833, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17523908615112, "training_acc": 53.0, "val_loss": 17.3087939620018, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15698742866516, "training_acc": 53.0, "val_loss": 17.308908700942993, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14536190032959, "training_acc": 53.0, "val_loss": 17.314061522483826, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17475628852844, "training_acc": 53.0, "val_loss": 17.322000861167908, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15660166740417, "training_acc": 53.0, "val_loss": 17.321640253067017, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1404037475586, "training_acc": 53.0, "val_loss": 17.315436899662018, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15540313720703, "training_acc": 53.0, "val_loss": 17.311665415763855, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1391453742981, "training_acc": 53.0, "val_loss": 17.310838401317596, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14082884788513, "training_acc": 53.0, "val_loss": 17.30956733226776, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19124555587769, "training_acc": 53.0, "val_loss": 17.308922111988068, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16467499732971, "training_acc": 53.0, "val_loss": 17.309412360191345, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14115977287292, "training_acc": 53.0, "val_loss": 17.309318482875824, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15997791290283, "training_acc": 53.0, "val_loss": 17.30925291776657, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14613199234009, "training_acc": 53.0, "val_loss": 17.310132086277008, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14276099205017, "training_acc": 53.0, "val_loss": 17.311181128025055, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14656805992126, "training_acc": 53.0, "val_loss": 17.312264442443848, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13802790641785, "training_acc": 53.0, "val_loss": 17.312005162239075, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1483154296875, "training_acc": 53.0, "val_loss": 17.312030494213104, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14051914215088, "training_acc": 53.0, "val_loss": 17.313534021377563, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13713192939758, "training_acc": 53.0, "val_loss": 17.314034700393677, "val_acc": 52.0}
