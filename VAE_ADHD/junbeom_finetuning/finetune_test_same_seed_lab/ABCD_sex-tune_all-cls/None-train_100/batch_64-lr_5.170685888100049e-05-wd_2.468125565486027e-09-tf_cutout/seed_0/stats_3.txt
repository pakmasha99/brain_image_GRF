"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.41002011299133, "training_acc": 54.0, "val_loss": 17.312152683734894, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.42958760261536, "training_acc": 49.0, "val_loss": 17.31208711862564, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14074349403381, "training_acc": 53.0, "val_loss": 17.331573367118835, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2151997089386, "training_acc": 53.0, "val_loss": 17.33710765838623, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13752436637878, "training_acc": 53.0, "val_loss": 17.310521006584167, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13699007034302, "training_acc": 53.0, "val_loss": 17.301955819129944, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.37115836143494, "training_acc": 53.0, "val_loss": 17.304769158363342, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22659015655518, "training_acc": 53.0, "val_loss": 17.31313318014145, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.0624725818634, "training_acc": 53.0, "val_loss": 17.361481487751007, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2323226928711, "training_acc": 53.0, "val_loss": 17.376866936683655, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24847078323364, "training_acc": 53.0, "val_loss": 17.362017929553986, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24720430374146, "training_acc": 53.0, "val_loss": 17.333754897117615, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1703531742096, "training_acc": 53.0, "val_loss": 17.3229917883873, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15419030189514, "training_acc": 53.0, "val_loss": 17.32250303030014, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21403527259827, "training_acc": 53.0, "val_loss": 17.3290878534317, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13739371299744, "training_acc": 53.0, "val_loss": 17.315424978733063, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1534492969513, "training_acc": 53.0, "val_loss": 17.315751314163208, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21296787261963, "training_acc": 53.0, "val_loss": 17.31913536787033, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29671335220337, "training_acc": 53.0, "val_loss": 17.340633273124695, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21481013298035, "training_acc": 53.0, "val_loss": 17.32562780380249, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.08503842353821, "training_acc": 53.0, "val_loss": 17.322948575019836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25577187538147, "training_acc": 53.0, "val_loss": 17.322172224521637, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.0811493396759, "training_acc": 53.0, "val_loss": 17.317019402980804, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10299634933472, "training_acc": 53.0, "val_loss": 17.324794828891754, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19999194145203, "training_acc": 53.0, "val_loss": 17.332257330417633, "val_acc": 52.0}
