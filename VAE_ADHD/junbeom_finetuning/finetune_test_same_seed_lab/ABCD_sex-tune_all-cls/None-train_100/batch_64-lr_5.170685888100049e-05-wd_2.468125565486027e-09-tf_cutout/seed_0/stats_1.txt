"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.54322838783264, "training_acc": 40.0, "val_loss": 17.31555461883545, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.24553871154785, "training_acc": 52.0, "val_loss": 17.30865389108658, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.8703076839447, "training_acc": 53.0, "val_loss": 17.313896119594574, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.36308431625366, "training_acc": 53.0, "val_loss": 17.339687049388885, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.21886849403381, "training_acc": 53.0, "val_loss": 17.317350208759308, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12435865402222, "training_acc": 53.0, "val_loss": 17.30693280696869, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2449426651001, "training_acc": 53.0, "val_loss": 17.310981452465057, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18208765983582, "training_acc": 53.0, "val_loss": 17.30698049068451, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1318678855896, "training_acc": 53.0, "val_loss": 17.312684655189514, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11321234703064, "training_acc": 53.0, "val_loss": 17.314621806144714, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.203786611557, "training_acc": 53.0, "val_loss": 17.32366979122162, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12111592292786, "training_acc": 53.0, "val_loss": 17.34473407268524, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.167160987854, "training_acc": 53.0, "val_loss": 17.33205020427704, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.42594623565674, "training_acc": 53.0, "val_loss": 17.313814163208008, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.06606411933899, "training_acc": 53.0, "val_loss": 17.322106659412384, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12599563598633, "training_acc": 53.0, "val_loss": 17.33175963163376, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14780449867249, "training_acc": 53.0, "val_loss": 17.33633726835251, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13813829421997, "training_acc": 53.0, "val_loss": 17.321239411830902, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15354514122009, "training_acc": 53.0, "val_loss": 17.31240451335907, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08411741256714, "training_acc": 53.0, "val_loss": 17.327263951301575, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23996305465698, "training_acc": 51.0, "val_loss": 17.33551174402237, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.2096676826477, "training_acc": 65.0, "val_loss": 17.3200324177742, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19423794746399, "training_acc": 53.0, "val_loss": 17.313656210899353, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.08628487586975, "training_acc": 53.0, "val_loss": 17.32092946767807, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11689686775208, "training_acc": 53.0, "val_loss": 17.33563542366028, "val_acc": 52.0}
