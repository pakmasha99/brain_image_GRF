"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 88.93317604064941, "training_acc": 50.0, "val_loss": 201.78930759429932, "val_acc": 52.0}
{"epoch": 1, "training_loss": 609.7929313182831, "training_acc": 41.0, "val_loss": 18.676486611366272, "val_acc": 52.0}
{"epoch": 2, "training_loss": 86.44608783721924, "training_acc": 37.0, "val_loss": 17.34636425971985, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22396922111511, "training_acc": 53.0, "val_loss": 17.52888858318329, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.79931402206421, "training_acc": 53.0, "val_loss": 17.336997389793396, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.87201046943665, "training_acc": 45.0, "val_loss": 17.310859262943268, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.33030700683594, "training_acc": 53.0, "val_loss": 17.34856367111206, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.33367872238159, "training_acc": 53.0, "val_loss": 17.339880764484406, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17546010017395, "training_acc": 53.0, "val_loss": 17.36723929643631, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22045159339905, "training_acc": 53.0, "val_loss": 17.362642288208008, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.44069766998291, "training_acc": 53.0, "val_loss": 17.320314049720764, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22053837776184, "training_acc": 53.0, "val_loss": 17.326751351356506, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16518139839172, "training_acc": 53.0, "val_loss": 17.31218695640564, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18222117424011, "training_acc": 53.0, "val_loss": 17.31071025133133, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13530850410461, "training_acc": 53.0, "val_loss": 17.31763780117035, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16738224029541, "training_acc": 53.0, "val_loss": 17.322908341884613, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17268919944763, "training_acc": 53.0, "val_loss": 17.33842045068741, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1609206199646, "training_acc": 53.0, "val_loss": 17.334531247615814, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15701746940613, "training_acc": 53.0, "val_loss": 17.324519157409668, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13673853874207, "training_acc": 53.0, "val_loss": 17.319156229496002, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12917900085449, "training_acc": 53.0, "val_loss": 17.31296181678772, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12405204772949, "training_acc": 53.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20083475112915, "training_acc": 53.0, "val_loss": 17.3102468252182, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18061542510986, "training_acc": 53.0, "val_loss": 17.30959117412567, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14958167076111, "training_acc": 53.0, "val_loss": 17.310750484466553, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13987731933594, "training_acc": 53.0, "val_loss": 17.31478124856949, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16086053848267, "training_acc": 53.0, "val_loss": 17.31823831796646, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16299796104431, "training_acc": 53.0, "val_loss": 17.315375804901123, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14263391494751, "training_acc": 53.0, "val_loss": 17.319102585315704, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13252401351929, "training_acc": 53.0, "val_loss": 17.31869727373123, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13816857337952, "training_acc": 53.0, "val_loss": 17.317460477352142, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13753461837769, "training_acc": 53.0, "val_loss": 17.31846332550049, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12946915626526, "training_acc": 53.0, "val_loss": 17.3162043094635, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12881898880005, "training_acc": 53.0, "val_loss": 17.313234508037567, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1825304031372, "training_acc": 53.0, "val_loss": 17.311978340148926, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.12017369270325, "training_acc": 53.0, "val_loss": 17.30997860431671, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15774941444397, "training_acc": 53.0, "val_loss": 17.310689389705658, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.22729468345642, "training_acc": 53.0, "val_loss": 17.310509085655212, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.19271111488342, "training_acc": 53.0, "val_loss": 17.30870008468628, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.23700642585754, "training_acc": 53.0, "val_loss": 17.3104390501976, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.19013619422913, "training_acc": 53.0, "val_loss": 17.310461401939392, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13379669189453, "training_acc": 53.0, "val_loss": 17.313958704471588, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.2514545917511, "training_acc": 53.0, "val_loss": 17.322921752929688, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14857029914856, "training_acc": 53.0, "val_loss": 17.32102483510971, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1342544555664, "training_acc": 53.0, "val_loss": 17.31612980365753, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.30141162872314, "training_acc": 53.0, "val_loss": 17.313073575496674, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.12329816818237, "training_acc": 53.0, "val_loss": 17.318980395793915, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13228726387024, "training_acc": 53.0, "val_loss": 17.32548475265503, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.15109348297119, "training_acc": 53.0, "val_loss": 17.335064709186554, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.16146516799927, "training_acc": 53.0, "val_loss": 17.349131405353546, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.26354026794434, "training_acc": 53.0, "val_loss": 17.36585646867752, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.22737979888916, "training_acc": 53.0, "val_loss": 17.35013574361801, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.20029354095459, "training_acc": 53.0, "val_loss": 17.332643270492554, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.15410494804382, "training_acc": 53.0, "val_loss": 17.32345223426819, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.14037346839905, "training_acc": 53.0, "val_loss": 17.317432165145874, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.13386726379395, "training_acc": 53.0, "val_loss": 17.31371283531189, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.13966226577759, "training_acc": 53.0, "val_loss": 17.311683297157288, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.1353988647461, "training_acc": 53.0, "val_loss": 17.311498522758484, "val_acc": 52.0}
