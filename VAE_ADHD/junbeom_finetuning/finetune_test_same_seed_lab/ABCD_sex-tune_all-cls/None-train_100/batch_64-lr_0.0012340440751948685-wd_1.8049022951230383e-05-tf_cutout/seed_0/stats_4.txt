"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 144.21757221221924, "training_acc": 41.0, "val_loss": 133.3392858505249, "val_acc": 48.0}
{"epoch": 1, "training_loss": 387.5361518859863, "training_acc": 51.0, "val_loss": 18.128322064876556, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.39477515220642, "training_acc": 53.0, "val_loss": 17.488601803779602, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.68468856811523, "training_acc": 53.0, "val_loss": 17.317689955234528, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.92504954338074, "training_acc": 53.0, "val_loss": 17.36256629228592, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.62799668312073, "training_acc": 47.0, "val_loss": 17.347733676433563, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22817015647888, "training_acc": 51.0, "val_loss": 17.373259365558624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.36061573028564, "training_acc": 53.0, "val_loss": 17.391029000282288, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.98932385444641, "training_acc": 53.0, "val_loss": 17.311011254787445, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30971598625183, "training_acc": 53.0, "val_loss": 17.311343550682068, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1618914604187, "training_acc": 53.0, "val_loss": 17.31071025133133, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1457896232605, "training_acc": 53.0, "val_loss": 17.30985939502716, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20017719268799, "training_acc": 53.0, "val_loss": 17.31070727109909, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.20844411849976, "training_acc": 53.0, "val_loss": 17.31581836938858, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21791124343872, "training_acc": 53.0, "val_loss": 17.312385141849518, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.44889569282532, "training_acc": 53.0, "val_loss": 17.309604585170746, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15198135375977, "training_acc": 53.0, "val_loss": 17.309319972991943, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16895914077759, "training_acc": 53.0, "val_loss": 17.30962097644806, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15793323516846, "training_acc": 53.0, "val_loss": 17.31167584657669, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18826293945312, "training_acc": 53.0, "val_loss": 17.313705384731293, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.107346534729, "training_acc": 53.0, "val_loss": 17.325359582901, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21783804893494, "training_acc": 53.0, "val_loss": 17.345497012138367, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21769118309021, "training_acc": 53.0, "val_loss": 17.34495460987091, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17358064651489, "training_acc": 53.0, "val_loss": 17.331159114837646, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13276481628418, "training_acc": 53.0, "val_loss": 17.318086326122284, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09506845474243, "training_acc": 53.0, "val_loss": 17.310374975204468, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12501120567322, "training_acc": 53.0, "val_loss": 17.311908304691315, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.3380823135376, "training_acc": 53.0, "val_loss": 17.318281531333923, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.26343894004822, "training_acc": 53.0, "val_loss": 17.31482893228531, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.22948431968689, "training_acc": 53.0, "val_loss": 17.312568426132202, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.25535988807678, "training_acc": 53.0, "val_loss": 17.30918437242508, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15446758270264, "training_acc": 53.0, "val_loss": 17.309507727622986, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13002586364746, "training_acc": 53.0, "val_loss": 17.31393337249756, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13801884651184, "training_acc": 53.0, "val_loss": 17.323631048202515, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.27502822875977, "training_acc": 53.0, "val_loss": 17.330190539360046, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13672399520874, "training_acc": 53.0, "val_loss": 17.319175601005554, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.20555806159973, "training_acc": 53.0, "val_loss": 17.311494052410126, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13368558883667, "training_acc": 53.0, "val_loss": 17.310577630996704, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13583517074585, "training_acc": 53.0, "val_loss": 17.31008142232895, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16627621650696, "training_acc": 53.0, "val_loss": 17.310063540935516, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14124655723572, "training_acc": 53.0, "val_loss": 17.30927675962448, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.173992395401, "training_acc": 53.0, "val_loss": 17.309096455574036, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15076780319214, "training_acc": 53.0, "val_loss": 17.309413850307465, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.22185206413269, "training_acc": 53.0, "val_loss": 17.311157286167145, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13857197761536, "training_acc": 53.0, "val_loss": 17.310906946659088, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.13831925392151, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14796900749207, "training_acc": 53.0, "val_loss": 17.31148511171341, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13470029830933, "training_acc": 53.0, "val_loss": 17.313258349895477, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13421940803528, "training_acc": 53.0, "val_loss": 17.315207421779633, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13366293907166, "training_acc": 53.0, "val_loss": 17.31688231229782, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13243412971497, "training_acc": 53.0, "val_loss": 17.318016290664673, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.13635492324829, "training_acc": 53.0, "val_loss": 17.319324612617493, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1464467048645, "training_acc": 53.0, "val_loss": 17.321832478046417, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.14104390144348, "training_acc": 53.0, "val_loss": 17.321640253067017, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.14278650283813, "training_acc": 53.0, "val_loss": 17.31930375099182, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.15110039710999, "training_acc": 53.0, "val_loss": 17.31799989938736, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.16664123535156, "training_acc": 53.0, "val_loss": 17.314065992832184, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.1299216747284, "training_acc": 53.0, "val_loss": 17.313361167907715, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13406682014465, "training_acc": 53.0, "val_loss": 17.312908172607422, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.13681888580322, "training_acc": 53.0, "val_loss": 17.31255352497101, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.13586091995239, "training_acc": 53.0, "val_loss": 17.312854528427124, "val_acc": 52.0}
