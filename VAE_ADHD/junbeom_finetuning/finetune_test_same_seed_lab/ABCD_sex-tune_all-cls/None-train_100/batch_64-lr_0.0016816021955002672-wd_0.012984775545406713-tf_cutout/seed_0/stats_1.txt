"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 111.7585802078247, "training_acc": 49.0, "val_loss": 409.5256805419922, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1103.9511046409607, "training_acc": 49.0, "val_loss": 17.44624227285385, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.27158546447754, "training_acc": 49.0, "val_loss": 18.969331681728363, "val_acc": 48.0}
{"epoch": 3, "training_loss": 80.01180386543274, "training_acc": 45.0, "val_loss": 17.6600381731987, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.02163290977478, "training_acc": 53.0, "val_loss": 17.331811785697937, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22885131835938, "training_acc": 53.0, "val_loss": 17.321743071079254, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5449755191803, "training_acc": 53.0, "val_loss": 17.32693612575531, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13626027107239, "training_acc": 53.0, "val_loss": 17.422965168952942, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.46336841583252, "training_acc": 53.0, "val_loss": 17.391856014728546, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.46536350250244, "training_acc": 53.0, "val_loss": 17.322559654712677, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1479229927063, "training_acc": 53.0, "val_loss": 17.324340343475342, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.36665391921997, "training_acc": 53.0, "val_loss": 17.321807146072388, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.333984375, "training_acc": 47.0, "val_loss": 17.322444915771484, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21404719352722, "training_acc": 53.0, "val_loss": 17.310044169425964, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15993523597717, "training_acc": 53.0, "val_loss": 17.31240004301071, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13609838485718, "training_acc": 53.0, "val_loss": 17.318956553936005, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29520058631897, "training_acc": 53.0, "val_loss": 17.319679260253906, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24686074256897, "training_acc": 53.0, "val_loss": 17.336946725845337, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.24145722389221, "training_acc": 53.0, "val_loss": 17.335444688796997, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14889979362488, "training_acc": 53.0, "val_loss": 17.319849133491516, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18207097053528, "training_acc": 53.0, "val_loss": 17.311377823352814, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13404965400696, "training_acc": 53.0, "val_loss": 17.310260236263275, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1519935131073, "training_acc": 53.0, "val_loss": 17.309768497943878, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15035033226013, "training_acc": 53.0, "val_loss": 17.309869825839996, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15459036827087, "training_acc": 53.0, "val_loss": 17.31087863445282, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15452694892883, "training_acc": 53.0, "val_loss": 17.314612865447998, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14709568023682, "training_acc": 53.0, "val_loss": 17.317695915699005, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20152854919434, "training_acc": 53.0, "val_loss": 17.31690913438797, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13186693191528, "training_acc": 53.0, "val_loss": 17.322270572185516, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13948130607605, "training_acc": 53.0, "val_loss": 17.327071726322174, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16463971138, "training_acc": 53.0, "val_loss": 17.33265221118927, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1891872882843, "training_acc": 53.0, "val_loss": 17.330142855644226, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18717122077942, "training_acc": 53.0, "val_loss": 17.320609092712402, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.11735606193542, "training_acc": 53.0, "val_loss": 17.31046289205551, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14139103889465, "training_acc": 53.0, "val_loss": 17.30963885784149, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16556668281555, "training_acc": 53.0, "val_loss": 17.31152832508087, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.19071650505066, "training_acc": 53.0, "val_loss": 17.311817407608032, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18887686729431, "training_acc": 53.0, "val_loss": 17.310452461242676, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17172932624817, "training_acc": 53.0, "val_loss": 17.30913519859314, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15058326721191, "training_acc": 53.0, "val_loss": 17.309294641017914, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.1291778087616, "training_acc": 53.0, "val_loss": 17.311634123325348, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.2084732055664, "training_acc": 53.0, "val_loss": 17.316558957099915, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14808320999146, "training_acc": 53.0, "val_loss": 17.316779494285583, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16409611701965, "training_acc": 53.0, "val_loss": 17.314256727695465, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17284059524536, "training_acc": 53.0, "val_loss": 17.315246164798737, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1401903629303, "training_acc": 53.0, "val_loss": 17.312784492969513, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.17031025886536, "training_acc": 53.0, "val_loss": 17.31175184249878, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13401794433594, "training_acc": 53.0, "val_loss": 17.313092947006226, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13176012039185, "training_acc": 53.0, "val_loss": 17.31552481651306, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13553667068481, "training_acc": 53.0, "val_loss": 17.319902777671814, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.14084362983704, "training_acc": 53.0, "val_loss": 17.32305735349655, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14445781707764, "training_acc": 53.0, "val_loss": 17.32402890920639, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.14680123329163, "training_acc": 53.0, "val_loss": 17.324286699295044, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.15629482269287, "training_acc": 53.0, "val_loss": 17.322508990764618, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.1726222038269, "training_acc": 53.0, "val_loss": 17.322219908237457, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.14409565925598, "training_acc": 53.0, "val_loss": 17.32635498046875, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.15904784202576, "training_acc": 53.0, "val_loss": 17.327506840229034, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.1704511642456, "training_acc": 53.0, "val_loss": 17.330920696258545, "val_acc": 52.0}
