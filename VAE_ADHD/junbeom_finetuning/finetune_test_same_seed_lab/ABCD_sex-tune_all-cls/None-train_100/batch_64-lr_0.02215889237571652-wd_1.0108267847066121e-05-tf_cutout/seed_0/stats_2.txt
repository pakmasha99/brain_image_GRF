"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1317.585464477539, "training_acc": 55.0, "val_loss": 9237278438195200.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.2945394229649664e+16, "training_acc": 51.0, "val_loss": 4344078745600.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 12503696507904.0, "training_acc": 41.0, "val_loss": 169073433600.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 570595348480.0, "training_acc": 49.0, "val_loss": 229945523200.0, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1172480012288.0, "training_acc": 41.0, "val_loss": 2389295000.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 35509257984.0, "training_acc": 43.0, "val_loss": 22079736000.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 817437732864.0, "training_acc": 53.0, "val_loss": 22838419200.0, "val_acc": 48.0}
{"epoch": 7, "training_loss": 93849989632.0, "training_acc": 49.0, "val_loss": 104298246400.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 298650931136.0, "training_acc": 47.0, "val_loss": 21501472000.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 233754560512.0, "training_acc": 49.0, "val_loss": 5012592400.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 63506294784.0, "training_acc": 51.0, "val_loss": 36271659417600.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 85150535630848.0, "training_acc": 53.0, "val_loss": 5182330880000.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 13059702018048.0, "training_acc": 47.0, "val_loss": 1650409900.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 4927409576.0, "training_acc": 53.0, "val_loss": 56385164800.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 196393639936.0, "training_acc": 47.0, "val_loss": 15442222400.0, "val_acc": 52.0}
{"epoch": 15, "training_loss": 38576053280.0, "training_acc": 55.0, "val_loss": 34935571200.0, "val_acc": 52.0}
{"epoch": 16, "training_loss": 92590752640.0, "training_acc": 53.0, "val_loss": 84697427200.0, "val_acc": 48.0}
{"epoch": 17, "training_loss": 238388933632.0, "training_acc": 49.0, "val_loss": 20825068800.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1978217992192.0, "training_acc": 47.0, "val_loss": 476263526400.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1203443125312.0, "training_acc": 53.0, "val_loss": 77081280000.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 377021419520.0, "training_acc": 41.0, "val_loss": 73327737600.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 223204237492.0, "training_acc": 37.0, "val_loss": 294324225.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 7173105856.0, "training_acc": 51.0, "val_loss": 86710451200.0, "val_acc": 56.0}
{"epoch": 23, "training_loss": 3337077211136.0, "training_acc": 52.0, "val_loss": 302444655411200.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 818953427943424.0, "training_acc": 45.0, "val_loss": 7547614400.0, "val_acc": 48.0}
{"epoch": 25, "training_loss": 279684370432.0, "training_acc": 46.0, "val_loss": 9787549312614400.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2.2978389029975228e+16, "training_acc": 55.0, "val_loss": 3789732800.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 22728822400.0, "training_acc": 53.0, "val_loss": 946923100.0, "val_acc": 48.0}
{"epoch": 28, "training_loss": 23531823104.0, "training_acc": 51.0, "val_loss": 33079484800.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 217012951040.0, "training_acc": 53.0, "val_loss": 7957268000.0, "val_acc": 52.0}
{"epoch": 30, "training_loss": 188007786496.0, "training_acc": 55.0, "val_loss": 19036811200.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 55824372864.0, "training_acc": 51.0, "val_loss": 1281508761600.0, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3377192201664.0, "training_acc": 47.0, "val_loss": 3066336051200.0, "val_acc": 48.0}
{"epoch": 33, "training_loss": 75498539450368.0, "training_acc": 49.0, "val_loss": 21886074880000.0, "val_acc": 48.0}
{"epoch": 34, "training_loss": 54036972404736.0, "training_acc": 47.0, "val_loss": 729493145600.0, "val_acc": 48.0}
{"epoch": 35, "training_loss": 4302115782656.0, "training_acc": 47.0, "val_loss": 702570035200.0, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2255772028928.0, "training_acc": 47.0, "val_loss": 1288573747200.0, "val_acc": 48.0}
{"epoch": 37, "training_loss": 19564653445120.0, "training_acc": 51.0, "val_loss": 22936890572800.0, "val_acc": 52.0}
{"epoch": 38, "training_loss": 395517494296576.0, "training_acc": 53.0, "val_loss": 645112476467200.0, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1.0219442365530112e+16, "training_acc": 45.0, "val_loss": 14084104192000.0, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1.2181082501808128e+16, "training_acc": 47.0, "val_loss": 1132115660800.0, "val_acc": 52.0}
