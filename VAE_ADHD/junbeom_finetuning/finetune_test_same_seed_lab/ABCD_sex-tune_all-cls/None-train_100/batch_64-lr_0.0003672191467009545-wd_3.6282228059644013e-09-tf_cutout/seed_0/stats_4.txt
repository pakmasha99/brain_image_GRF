"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.61944222450256, "training_acc": 47.0, "val_loss": 17.337657511234283, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.7403039932251, "training_acc": 47.0, "val_loss": 17.403195798397064, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.34376525878906, "training_acc": 53.0, "val_loss": 17.3382431268692, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17690372467041, "training_acc": 53.0, "val_loss": 17.321957647800446, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.45466423034668, "training_acc": 53.0, "val_loss": 17.309413850307465, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23891377449036, "training_acc": 53.0, "val_loss": 17.31831580400467, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28681111335754, "training_acc": 53.0, "val_loss": 17.37491637468338, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.45646691322327, "training_acc": 53.0, "val_loss": 17.383086681365967, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19114756584167, "training_acc": 53.0, "val_loss": 17.309753596782684, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17898297309875, "training_acc": 53.0, "val_loss": 17.318043112754822, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21388244628906, "training_acc": 53.0, "val_loss": 17.314279079437256, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.11867070198059, "training_acc": 53.0, "val_loss": 17.339736223220825, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18749713897705, "training_acc": 53.0, "val_loss": 17.34164208173752, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.20044469833374, "training_acc": 53.0, "val_loss": 17.325115203857422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2523021697998, "training_acc": 53.0, "val_loss": 17.312806844711304, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24425435066223, "training_acc": 53.0, "val_loss": 17.315185070037842, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20395994186401, "training_acc": 53.0, "val_loss": 17.312996089458466, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15496063232422, "training_acc": 53.0, "val_loss": 17.357277870178223, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.51432371139526, "training_acc": 53.0, "val_loss": 17.339374125003815, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.5159068107605, "training_acc": 53.0, "val_loss": 17.36036241054535, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13254237174988, "training_acc": 53.0, "val_loss": 17.3093244433403, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.09880065917969, "training_acc": 53.0, "val_loss": 17.344747483730316, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.51740765571594, "training_acc": 41.0, "val_loss": 17.349226772785187, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.46331691741943, "training_acc": 47.0, "val_loss": 17.331919074058533, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23060297966003, "training_acc": 51.0, "val_loss": 17.317748069763184, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.14192700386047, "training_acc": 53.0, "val_loss": 17.380531132221222, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.24155282974243, "training_acc": 53.0, "val_loss": 17.313550412654877, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.27933955192566, "training_acc": 53.0, "val_loss": 17.313367128372192, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.21394062042236, "training_acc": 53.0, "val_loss": 17.309682071208954, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.38080143928528, "training_acc": 53.0, "val_loss": 17.31088161468506, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.02561283111572, "training_acc": 53.0, "val_loss": 17.37314611673355, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.51814007759094, "training_acc": 53.0, "val_loss": 17.448799312114716, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.45748591423035, "training_acc": 53.0, "val_loss": 17.35784113407135, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.08022809028625, "training_acc": 53.0, "val_loss": 17.3099547624588, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.09557628631592, "training_acc": 53.0, "val_loss": 17.35323816537857, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.55104374885559, "training_acc": 47.0, "val_loss": 17.390529811382294, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.6555073261261, "training_acc": 47.0, "val_loss": 17.40264892578125, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.78371477127075, "training_acc": 47.0, "val_loss": 17.330917716026306, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.65133595466614, "training_acc": 43.0, "val_loss": 17.33911633491516, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1481614112854, "training_acc": 53.0, "val_loss": 17.387734353542328, "val_acc": 52.0}
