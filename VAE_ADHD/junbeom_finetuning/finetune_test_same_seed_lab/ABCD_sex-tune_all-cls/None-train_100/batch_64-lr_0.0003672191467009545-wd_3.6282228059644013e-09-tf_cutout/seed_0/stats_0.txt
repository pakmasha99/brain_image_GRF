"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.02434277534485, "training_acc": 52.0, "val_loss": 17.16676652431488, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23137712478638, "training_acc": 52.0, "val_loss": 17.52140074968338, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.03918385505676, "training_acc": 46.0, "val_loss": 17.33585149049759, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.54490613937378, "training_acc": 46.0, "val_loss": 17.365987598896027, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.35235905647278, "training_acc": 48.0, "val_loss": 17.20682829618454, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.76408791542053, "training_acc": 52.0, "val_loss": 17.246828973293304, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.33539915084839, "training_acc": 50.0, "val_loss": 17.362144589424133, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.32032322883606, "training_acc": 47.0, "val_loss": 17.200395464897156, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.93539381027222, "training_acc": 52.0, "val_loss": 17.18498170375824, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.19818925857544, "training_acc": 52.0, "val_loss": 17.372411489486694, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.40320229530334, "training_acc": 48.0, "val_loss": 17.330901324748993, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.33582472801208, "training_acc": 48.0, "val_loss": 17.219413816928864, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.34042978286743, "training_acc": 52.0, "val_loss": 17.21305102109909, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.33267307281494, "training_acc": 52.0, "val_loss": 17.272119224071503, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.26005005836487, "training_acc": 52.0, "val_loss": 17.219124734401703, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24225544929504, "training_acc": 52.0, "val_loss": 17.172467708587646, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.3737165927887, "training_acc": 52.0, "val_loss": 17.16088503599167, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.33842420578003, "training_acc": 52.0, "val_loss": 17.224812507629395, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25369238853455, "training_acc": 52.0, "val_loss": 17.299197614192963, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.28108048439026, "training_acc": 52.0, "val_loss": 17.277240753173828, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.27245807647705, "training_acc": 52.0, "val_loss": 17.234531044960022, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22914457321167, "training_acc": 52.0, "val_loss": 17.177630960941315, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.5999641418457, "training_acc": 52.0, "val_loss": 17.157478630542755, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.29295206069946, "training_acc": 52.0, "val_loss": 17.243070900440216, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.17274785041809, "training_acc": 52.0, "val_loss": 17.40766167640686, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.56069254875183, "training_acc": 48.0, "val_loss": 17.429278790950775, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.10640454292297, "training_acc": 38.0, "val_loss": 17.265839874744415, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24695134162903, "training_acc": 52.0, "val_loss": 17.2866553068161, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.34875082969666, "training_acc": 52.0, "val_loss": 17.27428436279297, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.21489334106445, "training_acc": 52.0, "val_loss": 17.19747483730316, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.72893047332764, "training_acc": 52.0, "val_loss": 17.165683209896088, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.66731381416321, "training_acc": 52.0, "val_loss": 17.228442430496216, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24136924743652, "training_acc": 52.0, "val_loss": 17.226283252239227, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25746893882751, "training_acc": 52.0, "val_loss": 17.235711216926575, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.27962827682495, "training_acc": 52.0, "val_loss": 17.220892012119293, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23926091194153, "training_acc": 52.0, "val_loss": 17.239634692668915, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25824451446533, "training_acc": 52.0, "val_loss": 17.24373996257782, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.36519289016724, "training_acc": 52.0, "val_loss": 17.219120264053345, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.21196722984314, "training_acc": 52.0, "val_loss": 17.1661376953125, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.5988438129425, "training_acc": 52.0, "val_loss": 17.148002982139587, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.50868940353394, "training_acc": 52.0, "val_loss": 17.16172695159912, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.32856440544128, "training_acc": 52.0, "val_loss": 17.225171625614166, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.19685316085815, "training_acc": 52.0, "val_loss": 17.30627715587616, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.30058479309082, "training_acc": 52.0, "val_loss": 17.394301295280457, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.5335533618927, "training_acc": 48.0, "val_loss": 17.474904656410217, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.58530926704407, "training_acc": 48.0, "val_loss": 17.35876202583313, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.35764765739441, "training_acc": 48.0, "val_loss": 17.25810170173645, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.21114706993103, "training_acc": 52.0, "val_loss": 17.198912799358368, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.29676556587219, "training_acc": 52.0, "val_loss": 17.162181437015533, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.43474984169006, "training_acc": 52.0, "val_loss": 17.167724668979645, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.24950194358826, "training_acc": 52.0, "val_loss": 17.235904932022095, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.21652626991272, "training_acc": 52.0, "val_loss": 17.344267666339874, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.32893919944763, "training_acc": 48.0, "val_loss": 17.391464114189148, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.40859627723694, "training_acc": 48.0, "val_loss": 17.366936802864075, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.347163438797, "training_acc": 48.0, "val_loss": 17.290210723876953, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.4356997013092, "training_acc": 52.0, "val_loss": 17.203350365161896, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.29382753372192, "training_acc": 52.0, "val_loss": 17.193515598773956, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.28071427345276, "training_acc": 52.0, "val_loss": 17.220956087112427, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.234370470047, "training_acc": 52.0, "val_loss": 17.23250150680542, "val_acc": 56.0}
