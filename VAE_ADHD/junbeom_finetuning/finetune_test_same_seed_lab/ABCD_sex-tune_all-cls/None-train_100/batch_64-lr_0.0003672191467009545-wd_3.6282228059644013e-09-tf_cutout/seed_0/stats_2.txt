"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.68395233154297, "training_acc": 47.0, "val_loss": 17.318372428417206, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.08767008781433, "training_acc": 53.0, "val_loss": 17.508311569690704, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.37535738945007, "training_acc": 53.0, "val_loss": 17.330646514892578, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.66037678718567, "training_acc": 49.0, "val_loss": 17.397300899028778, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4690191745758, "training_acc": 53.0, "val_loss": 17.333196103572845, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.65546751022339, "training_acc": 53.0, "val_loss": 17.326095700263977, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13905763626099, "training_acc": 53.0, "val_loss": 17.400313913822174, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.34271168708801, "training_acc": 53.0, "val_loss": 17.359092831611633, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.53778862953186, "training_acc": 53.0, "val_loss": 17.324884235858917, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.36448407173157, "training_acc": 53.0, "val_loss": 17.33352243900299, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23024654388428, "training_acc": 53.0, "val_loss": 17.30780601501465, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.23861265182495, "training_acc": 53.0, "val_loss": 17.31022447347641, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15854096412659, "training_acc": 53.0, "val_loss": 17.34616756439209, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.33234286308289, "training_acc": 53.0, "val_loss": 17.33843982219696, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.24281883239746, "training_acc": 53.0, "val_loss": 17.34297126531601, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16790699958801, "training_acc": 53.0, "val_loss": 17.310377955436707, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19469451904297, "training_acc": 53.0, "val_loss": 17.30872243642807, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19332242012024, "training_acc": 53.0, "val_loss": 17.312391102313995, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21909427642822, "training_acc": 53.0, "val_loss": 17.311635613441467, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12360572814941, "training_acc": 53.0, "val_loss": 17.309467494487762, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30488896369934, "training_acc": 53.0, "val_loss": 17.310050129890442, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.24430799484253, "training_acc": 53.0, "val_loss": 17.32621341943741, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.157630443573, "training_acc": 53.0, "val_loss": 17.33359694480896, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16140055656433, "training_acc": 53.0, "val_loss": 17.317578196525574, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13397789001465, "training_acc": 53.0, "val_loss": 17.308902740478516, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.2785313129425, "training_acc": 53.0, "val_loss": 17.30952262878418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21906852722168, "training_acc": 53.0, "val_loss": 17.31649339199066, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13849568367004, "training_acc": 53.0, "val_loss": 17.323870956897736, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15561604499817, "training_acc": 53.0, "val_loss": 17.320145666599274, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16291761398315, "training_acc": 53.0, "val_loss": 17.31802374124527, "val_acc": 52.0}
