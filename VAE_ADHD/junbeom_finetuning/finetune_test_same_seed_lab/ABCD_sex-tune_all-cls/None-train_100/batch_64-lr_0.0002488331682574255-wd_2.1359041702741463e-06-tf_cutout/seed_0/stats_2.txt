"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.10188746452332, "training_acc": 53.0, "val_loss": 17.3166424036026, "val_acc": 52.0}
{"epoch": 1, "training_loss": 82.52294111251831, "training_acc": 53.0, "val_loss": 17.747090756893158, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.857661485672, "training_acc": 47.0, "val_loss": 17.84749925136566, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.25197672843933, "training_acc": 47.0, "val_loss": 17.422161996364594, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.57223963737488, "training_acc": 47.0, "val_loss": 17.318589985370636, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.07905292510986, "training_acc": 53.0, "val_loss": 17.340850830078125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13763475418091, "training_acc": 53.0, "val_loss": 17.43808388710022, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.7833788394928, "training_acc": 53.0, "val_loss": 17.41950958967209, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.76121592521667, "training_acc": 53.0, "val_loss": 17.313125729560852, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13658809661865, "training_acc": 53.0, "val_loss": 17.3097625374794, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16045880317688, "training_acc": 53.0, "val_loss": 17.309533059597015, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.23698425292969, "training_acc": 53.0, "val_loss": 17.311982810497284, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14987182617188, "training_acc": 53.0, "val_loss": 17.312251031398773, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14204668998718, "training_acc": 53.0, "val_loss": 17.314301431179047, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15770411491394, "training_acc": 53.0, "val_loss": 17.320598661899567, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13317799568176, "training_acc": 53.0, "val_loss": 17.323698103427887, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.10690236091614, "training_acc": 53.0, "val_loss": 17.332036793231964, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14388370513916, "training_acc": 53.0, "val_loss": 17.34250634908676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15790176391602, "training_acc": 53.0, "val_loss": 17.33509451150894, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12120604515076, "training_acc": 53.0, "val_loss": 17.320817708969116, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10306596755981, "training_acc": 53.0, "val_loss": 17.316949367523193, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16451716423035, "training_acc": 53.0, "val_loss": 17.31746643781662, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1394190788269, "training_acc": 53.0, "val_loss": 17.318400740623474, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15742993354797, "training_acc": 53.0, "val_loss": 17.322975397109985, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14385676383972, "training_acc": 53.0, "val_loss": 17.340755462646484, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11893510818481, "training_acc": 53.0, "val_loss": 17.384396493434906, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.33741664886475, "training_acc": 53.0, "val_loss": 17.4031063914299, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.36690950393677, "training_acc": 53.0, "val_loss": 17.366813123226166, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19985771179199, "training_acc": 53.0, "val_loss": 17.344291508197784, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.254234790802, "training_acc": 53.0, "val_loss": 17.32092648744583, "val_acc": 52.0}
