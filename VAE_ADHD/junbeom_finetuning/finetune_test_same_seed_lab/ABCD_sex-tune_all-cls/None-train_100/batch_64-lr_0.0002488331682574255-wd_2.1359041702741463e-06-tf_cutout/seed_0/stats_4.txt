"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.2102153301239, "training_acc": 47.0, "val_loss": 17.722594738006592, "val_acc": 52.0}
{"epoch": 1, "training_loss": 103.34955215454102, "training_acc": 51.0, "val_loss": 17.526893317699432, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.30799984931946, "training_acc": 53.0, "val_loss": 18.31393539905548, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.77906060218811, "training_acc": 53.0, "val_loss": 17.413221299648285, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33461689949036, "training_acc": 53.0, "val_loss": 17.306743562221527, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22865271568298, "training_acc": 53.0, "val_loss": 17.30695366859436, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09051823616028, "training_acc": 53.0, "val_loss": 17.369911074638367, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.51237607002258, "training_acc": 53.0, "val_loss": 17.349494993686676, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.20882797241211, "training_acc": 53.0, "val_loss": 17.360953986644745, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.49896264076233, "training_acc": 47.0, "val_loss": 17.362651228904724, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.53059315681458, "training_acc": 45.0, "val_loss": 17.310838401317596, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.37887716293335, "training_acc": 53.0, "val_loss": 17.315468192100525, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12468600273132, "training_acc": 53.0, "val_loss": 17.313440144062042, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13821816444397, "training_acc": 53.0, "val_loss": 17.311088740825653, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18627595901489, "training_acc": 53.0, "val_loss": 17.310646176338196, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20606470108032, "training_acc": 53.0, "val_loss": 17.31911450624466, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15320634841919, "training_acc": 53.0, "val_loss": 17.35878735780716, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.33053922653198, "training_acc": 53.0, "val_loss": 17.356644570827484, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16295576095581, "training_acc": 53.0, "val_loss": 17.317214608192444, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13044738769531, "training_acc": 53.0, "val_loss": 17.308704555034637, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22208523750305, "training_acc": 53.0, "val_loss": 17.312850058078766, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21552014350891, "training_acc": 53.0, "val_loss": 17.310775816440582, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14567875862122, "training_acc": 53.0, "val_loss": 17.311397194862366, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24528813362122, "training_acc": 53.0, "val_loss": 17.312712967395782, "val_acc": 52.0}
