"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.46604943275452, "training_acc": 48.0, "val_loss": 17.319965362548828, "val_acc": 52.0}
{"epoch": 1, "training_loss": 98.1175012588501, "training_acc": 53.0, "val_loss": 17.814399302005768, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.27820563316345, "training_acc": 47.0, "val_loss": 18.082626163959503, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.7328290939331, "training_acc": 47.0, "val_loss": 17.415736615657806, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.84812664985657, "training_acc": 47.0, "val_loss": 17.319542169570923, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.39549374580383, "training_acc": 53.0, "val_loss": 17.315107583999634, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15199303627014, "training_acc": 53.0, "val_loss": 17.31528788805008, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15800404548645, "training_acc": 53.0, "val_loss": 17.313899099826813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13190960884094, "training_acc": 53.0, "val_loss": 17.330369353294373, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.36217999458313, "training_acc": 53.0, "val_loss": 17.346131801605225, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15439581871033, "training_acc": 53.0, "val_loss": 17.415225505828857, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.64824032783508, "training_acc": 53.0, "val_loss": 17.392398416996002, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.64770412445068, "training_acc": 53.0, "val_loss": 17.31582283973694, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14057064056396, "training_acc": 53.0, "val_loss": 17.31356829404831, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15313148498535, "training_acc": 53.0, "val_loss": 17.313718795776367, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21448588371277, "training_acc": 53.0, "val_loss": 17.314423620700836, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15097880363464, "training_acc": 53.0, "val_loss": 17.313513159751892, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14038896560669, "training_acc": 53.0, "val_loss": 17.31390655040741, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15524291992188, "training_acc": 53.0, "val_loss": 17.319658398628235, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13388252258301, "training_acc": 53.0, "val_loss": 17.323066294193268, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12117791175842, "training_acc": 53.0, "val_loss": 17.333148419857025, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16927170753479, "training_acc": 53.0, "val_loss": 17.347128689289093, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19476246833801, "training_acc": 53.0, "val_loss": 17.33722686767578, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12681698799133, "training_acc": 53.0, "val_loss": 17.317909002304077, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12432026863098, "training_acc": 53.0, "val_loss": 17.313779890537262, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19036889076233, "training_acc": 53.0, "val_loss": 17.314495146274567, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15651226043701, "training_acc": 53.0, "val_loss": 17.31540709733963, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19789052009583, "training_acc": 53.0, "val_loss": 17.317581176757812, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14079427719116, "training_acc": 53.0, "val_loss": 17.33139604330063, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1128294467926, "training_acc": 53.0, "val_loss": 17.376655340194702, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.34043169021606, "training_acc": 53.0, "val_loss": 17.40422397851944, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.38354229927063, "training_acc": 53.0, "val_loss": 17.363043129444122, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19583082199097, "training_acc": 53.0, "val_loss": 17.33783632516861, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.28788805007935, "training_acc": 53.0, "val_loss": 17.314539849758148, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14435768127441, "training_acc": 53.0, "val_loss": 17.315421998500824, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.11755418777466, "training_acc": 53.0, "val_loss": 17.322486639022827, "val_acc": 52.0}
