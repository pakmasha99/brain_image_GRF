"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.57699680328369, "training_acc": 45.0, "val_loss": 17.602194845676422, "val_acc": 52.0}
{"epoch": 1, "training_loss": 103.17754983901978, "training_acc": 45.0, "val_loss": 17.4240380525589, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.84192967414856, "training_acc": 53.0, "val_loss": 18.050676584243774, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.06288456916809, "training_acc": 53.0, "val_loss": 17.403534054756165, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.34237408638, "training_acc": 53.0, "val_loss": 17.31146275997162, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15308833122253, "training_acc": 53.0, "val_loss": 17.307618260383606, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.44785761833191, "training_acc": 53.0, "val_loss": 17.31463223695755, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29014921188354, "training_acc": 53.0, "val_loss": 17.30407625436783, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.03930306434631, "training_acc": 53.0, "val_loss": 17.37002581357956, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29261016845703, "training_acc": 53.0, "val_loss": 17.432621121406555, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.49299883842468, "training_acc": 53.0, "val_loss": 17.385146021842957, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.34386920928955, "training_acc": 53.0, "val_loss": 17.330721020698547, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23944091796875, "training_acc": 53.0, "val_loss": 17.31167435646057, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16815519332886, "training_acc": 53.0, "val_loss": 17.30983257293701, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15544629096985, "training_acc": 53.0, "val_loss": 17.31238067150116, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12910795211792, "training_acc": 53.0, "val_loss": 17.3123762011528, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13230729103088, "training_acc": 53.0, "val_loss": 17.314313352108, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17324185371399, "training_acc": 53.0, "val_loss": 17.31782555580139, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.28168988227844, "training_acc": 53.0, "val_loss": 17.330802977085114, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16232371330261, "training_acc": 53.0, "val_loss": 17.326219379901886, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13094687461853, "training_acc": 53.0, "val_loss": 17.324939370155334, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20203018188477, "training_acc": 53.0, "val_loss": 17.322757840156555, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11074638366699, "training_acc": 53.0, "val_loss": 17.315398156642914, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10599064826965, "training_acc": 53.0, "val_loss": 17.313851416110992, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12524199485779, "training_acc": 53.0, "val_loss": 17.317019402980804, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18008756637573, "training_acc": 53.0, "val_loss": 17.322024703025818, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.241135597229, "training_acc": 53.0, "val_loss": 17.325149476528168, "val_acc": 52.0}
