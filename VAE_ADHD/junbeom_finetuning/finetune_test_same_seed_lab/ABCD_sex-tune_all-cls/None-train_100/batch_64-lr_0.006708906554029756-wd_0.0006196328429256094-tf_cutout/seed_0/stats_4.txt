"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 581.1996040344238, "training_acc": 41.0, "val_loss": 560551270400.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1395670123444.3264, "training_acc": 51.0, "val_loss": 630.208683013916, "val_acc": 52.0}
{"epoch": 2, "training_loss": 199741.46826171875, "training_acc": 51.0, "val_loss": 88183.26416015625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 222294.06201171875, "training_acc": 53.0, "val_loss": 2089.5023345947266, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5608.834701538086, "training_acc": 53.0, "val_loss": 349.38440322875977, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1427.8940124511719, "training_acc": 55.0, "val_loss": 520.0065612792969, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2076.346878051758, "training_acc": 47.0, "val_loss": 763.5879993438721, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2224.5226764678955, "training_acc": 47.0, "val_loss": 998.6506462097168, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2670.7779579162598, "training_acc": 53.0, "val_loss": 199.74960088729858, "val_acc": 48.0}
{"epoch": 9, "training_loss": 597.2650232315063, "training_acc": 49.0, "val_loss": 26.47574245929718, "val_acc": 48.0}
{"epoch": 10, "training_loss": 387.4250793457031, "training_acc": 55.0, "val_loss": 663.609504699707, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2999.541946411133, "training_acc": 47.0, "val_loss": 404.8445224761963, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6308.434326171875, "training_acc": 39.0, "val_loss": 272.9944705963135, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1164.0904006958008, "training_acc": 47.0, "val_loss": 210.88910102844238, "val_acc": 48.0}
{"epoch": 14, "training_loss": 614.3250017166138, "training_acc": 47.0, "val_loss": 116.41829013824463, "val_acc": 52.0}
{"epoch": 15, "training_loss": 346.7621536254883, "training_acc": 53.0, "val_loss": 202.87227630615234, "val_acc": 48.0}
{"epoch": 16, "training_loss": 558.2873935699463, "training_acc": 47.0, "val_loss": 104.58512306213379, "val_acc": 52.0}
{"epoch": 17, "training_loss": 290.8929407596588, "training_acc": 53.0, "val_loss": 234.2823028564453, "val_acc": 48.0}
{"epoch": 18, "training_loss": 676.5634326934814, "training_acc": 47.0, "val_loss": 104.22683954238892, "val_acc": 52.0}
{"epoch": 19, "training_loss": 350.3590478897095, "training_acc": 53.0, "val_loss": 73.51648807525635, "val_acc": 48.0}
{"epoch": 20, "training_loss": 231.56748056411743, "training_acc": 53.0, "val_loss": 122.59708642959595, "val_acc": 48.0}
{"epoch": 21, "training_loss": 761.5321846008301, "training_acc": 47.0, "val_loss": 71.2390124797821, "val_acc": 52.0}
{"epoch": 22, "training_loss": 193.45802855491638, "training_acc": 53.0, "val_loss": 24.593080580234528, "val_acc": 48.0}
{"epoch": 23, "training_loss": 88.77379989624023, "training_acc": 51.0, "val_loss": 17.60731041431427, "val_acc": 52.0}
{"epoch": 24, "training_loss": 75.68695497512817, "training_acc": 43.0, "val_loss": 18.15868318080902, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.96967673301697, "training_acc": 55.0, "val_loss": 23.46438318490982, "val_acc": 52.0}
{"epoch": 26, "training_loss": 101.63504266738892, "training_acc": 51.0, "val_loss": 17.40303635597229, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.20442962646484, "training_acc": 53.0, "val_loss": 17.46021807193756, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.45336842536926, "training_acc": 49.0, "val_loss": 17.310509085655212, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.64229989051819, "training_acc": 47.0, "val_loss": 19.181819260120392, "val_acc": 52.0}
{"epoch": 30, "training_loss": 79.95890545845032, "training_acc": 43.0, "val_loss": 17.484766244888306, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.4736864566803, "training_acc": 53.0, "val_loss": 17.306484282016754, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.52715277671814, "training_acc": 54.0, "val_loss": 18.550927937030792, "val_acc": 48.0}
{"epoch": 33, "training_loss": 75.64425778388977, "training_acc": 41.0, "val_loss": 17.310240864753723, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.3379259109497, "training_acc": 53.0, "val_loss": 17.293302714824677, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.48504567146301, "training_acc": 47.0, "val_loss": 17.351512610912323, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.10508275032043, "training_acc": 53.0, "val_loss": 17.314107716083527, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.42639327049255, "training_acc": 51.0, "val_loss": 18.629959225654602, "val_acc": 52.0}
{"epoch": 38, "training_loss": 81.74046421051025, "training_acc": 45.0, "val_loss": 17.446258664131165, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.35609126091003, "training_acc": 51.0, "val_loss": 17.94847398996353, "val_acc": 52.0}
{"epoch": 40, "training_loss": 71.24206352233887, "training_acc": 53.0, "val_loss": 17.290572822093964, "val_acc": 52.0}
{"epoch": 41, "training_loss": 71.63845896720886, "training_acc": 45.0, "val_loss": 17.28833317756653, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.32773470878601, "training_acc": 52.0, "val_loss": 17.689640820026398, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.14820337295532, "training_acc": 53.0, "val_loss": 17.438681423664093, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.9249153137207, "training_acc": 47.0, "val_loss": 17.57623702287674, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.9423520565033, "training_acc": 53.0, "val_loss": 17.4311101436615, "val_acc": 52.0}
{"epoch": 46, "training_loss": 71.95302128791809, "training_acc": 53.0, "val_loss": 19.433532655239105, "val_acc": 48.0}
{"epoch": 47, "training_loss": 77.71111631393433, "training_acc": 47.0, "val_loss": 17.65219122171402, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.209477186203, "training_acc": 47.0, "val_loss": 19.11318004131317, "val_acc": 52.0}
{"epoch": 49, "training_loss": 75.349773645401, "training_acc": 53.0, "val_loss": 17.651307582855225, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.4001693725586, "training_acc": 57.0, "val_loss": 19.106628000736237, "val_acc": 48.0}
{"epoch": 51, "training_loss": 74.99643468856812, "training_acc": 47.0, "val_loss": 17.44293123483658, "val_acc": 52.0}
{"epoch": 52, "training_loss": 70.3787271976471, "training_acc": 53.0, "val_loss": 17.978928983211517, "val_acc": 52.0}
{"epoch": 53, "training_loss": 71.10941624641418, "training_acc": 53.0, "val_loss": 17.328231036663055, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.05691456794739, "training_acc": 53.0, "val_loss": 17.324769496917725, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.10785937309265, "training_acc": 53.0, "val_loss": 17.4036905169487, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.71540117263794, "training_acc": 53.0, "val_loss": 22.644072771072388, "val_acc": 48.0}
{"epoch": 57, "training_loss": 176.0488166809082, "training_acc": 51.0, "val_loss": 35.80591082572937, "val_acc": 48.0}
{"epoch": 58, "training_loss": 121.59933519363403, "training_acc": 47.0, "val_loss": 17.60125756263733, "val_acc": 52.0}
{"epoch": 59, "training_loss": 70.41284537315369, "training_acc": 47.0, "val_loss": 17.331422865390778, "val_acc": 52.0}
{"epoch": 60, "training_loss": 76.26993536949158, "training_acc": 52.0, "val_loss": 25.340616703033447, "val_acc": 48.0}
