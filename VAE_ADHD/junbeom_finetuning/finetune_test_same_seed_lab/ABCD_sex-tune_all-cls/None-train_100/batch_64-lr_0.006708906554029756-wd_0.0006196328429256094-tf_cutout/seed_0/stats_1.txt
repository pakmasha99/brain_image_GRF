"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 237.20483207702637, "training_acc": 53.0, "val_loss": 21626025.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 52519094.51187134, "training_acc": 53.0, "val_loss": 3476.309585571289, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1093837.837890625, "training_acc": 51.0, "val_loss": 1643.9516067504883, "val_acc": 52.0}
{"epoch": 3, "training_loss": 4632.231071472168, "training_acc": 53.0, "val_loss": 219.4971799850464, "val_acc": 48.0}
{"epoch": 4, "training_loss": 666.4511024951935, "training_acc": 41.0, "val_loss": 114.62057828903198, "val_acc": 48.0}
{"epoch": 5, "training_loss": 558.4283599853516, "training_acc": 45.0, "val_loss": 45.58936953544617, "val_acc": 52.0}
{"epoch": 6, "training_loss": 242.7258653640747, "training_acc": 45.0, "val_loss": 34.21497941017151, "val_acc": 48.0}
{"epoch": 7, "training_loss": 151.96122121810913, "training_acc": 41.0, "val_loss": 36.44475340843201, "val_acc": 48.0}
{"epoch": 8, "training_loss": 122.21079206466675, "training_acc": 51.0, "val_loss": 18.263204395771027, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44144749641418, "training_acc": 57.0, "val_loss": 45.22278606891632, "val_acc": 52.0}
{"epoch": 10, "training_loss": 162.78841495513916, "training_acc": 47.0, "val_loss": 26.823848485946655, "val_acc": 48.0}
{"epoch": 11, "training_loss": 99.56369066238403, "training_acc": 55.0, "val_loss": 24.380476772785187, "val_acc": 48.0}
{"epoch": 12, "training_loss": 105.4851427078247, "training_acc": 49.0, "val_loss": 20.873257517814636, "val_acc": 48.0}
{"epoch": 13, "training_loss": 118.61430597305298, "training_acc": 49.0, "val_loss": 18.93085688352585, "val_acc": 48.0}
{"epoch": 14, "training_loss": 74.160893201828, "training_acc": 47.0, "val_loss": 44.231513142585754, "val_acc": 52.0}
{"epoch": 15, "training_loss": 158.10655307769775, "training_acc": 51.0, "val_loss": 19.201506674289703, "val_acc": 48.0}
{"epoch": 16, "training_loss": 72.97011995315552, "training_acc": 53.0, "val_loss": 18.277305364608765, "val_acc": 52.0}
{"epoch": 17, "training_loss": 76.41556763648987, "training_acc": 43.0, "val_loss": 17.326626181602478, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.32026314735413, "training_acc": 53.0, "val_loss": 17.670074105262756, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.9791374206543, "training_acc": 45.0, "val_loss": 17.28624850511551, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.48331427574158, "training_acc": 52.0, "val_loss": 17.352336645126343, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.38805747032166, "training_acc": 53.0, "val_loss": 17.661620676517487, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.71140789985657, "training_acc": 47.0, "val_loss": 17.29702651500702, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.91069793701172, "training_acc": 53.0, "val_loss": 17.46658831834793, "val_acc": 52.0}
{"epoch": 24, "training_loss": 73.38696384429932, "training_acc": 39.0, "val_loss": 17.429770529270172, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.6639015674591, "training_acc": 49.0, "val_loss": 17.53900498151779, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.78865718841553, "training_acc": 53.0, "val_loss": 17.465730011463165, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.84482932090759, "training_acc": 53.0, "val_loss": 17.311084270477295, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.26057147979736, "training_acc": 53.0, "val_loss": 17.301703989505768, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17570090293884, "training_acc": 53.0, "val_loss": 17.311644554138184, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.34090971946716, "training_acc": 53.0, "val_loss": 17.309536039829254, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.43450045585632, "training_acc": 43.0, "val_loss": 17.308448255062103, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13323545455933, "training_acc": 53.0, "val_loss": 17.3145592212677, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.26239919662476, "training_acc": 53.0, "val_loss": 17.374518513679504, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.33707523345947, "training_acc": 53.0, "val_loss": 17.366409301757812, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.38627552986145, "training_acc": 53.0, "val_loss": 17.325611412525177, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17267990112305, "training_acc": 53.0, "val_loss": 17.314518988132477, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13679099082947, "training_acc": 53.0, "val_loss": 17.310132086277008, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.2496874332428, "training_acc": 53.0, "val_loss": 17.309920489788055, "val_acc": 52.0}
