"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 619.3680610656738, "training_acc": 39.0, "val_loss": 131463150.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 320821152.2729187, "training_acc": 53.0, "val_loss": 10688.550567626953, "val_acc": 52.0}
{"epoch": 2, "training_loss": 33617.125244140625, "training_acc": 53.0, "val_loss": 10344.052124023438, "val_acc": 52.0}
{"epoch": 3, "training_loss": 28475.033142089844, "training_acc": 53.0, "val_loss": 520.1333999633789, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1354.4650230407715, "training_acc": 53.0, "val_loss": 387.7948760986328, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1054.6244628429413, "training_acc": 47.0, "val_loss": 65.84069728851318, "val_acc": 48.0}
{"epoch": 6, "training_loss": 466.85595703125, "training_acc": 53.0, "val_loss": 146.6794729232788, "val_acc": 52.0}
{"epoch": 7, "training_loss": 391.4216070175171, "training_acc": 53.0, "val_loss": 29.357916116714478, "val_acc": 48.0}
{"epoch": 8, "training_loss": 115.50301218032837, "training_acc": 49.0, "val_loss": 30.39737343788147, "val_acc": 48.0}
{"epoch": 9, "training_loss": 101.15023732185364, "training_acc": 51.0, "val_loss": 30.91546893119812, "val_acc": 52.0}
{"epoch": 10, "training_loss": 128.40781450271606, "training_acc": 53.0, "val_loss": 18.645450472831726, "val_acc": 52.0}
{"epoch": 11, "training_loss": 77.21226620674133, "training_acc": 53.0, "val_loss": 32.874083518981934, "val_acc": 52.0}
{"epoch": 12, "training_loss": 107.90333127975464, "training_acc": 51.0, "val_loss": 20.424428582191467, "val_acc": 48.0}
{"epoch": 13, "training_loss": 81.76718831062317, "training_acc": 41.0, "val_loss": 17.413966357707977, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.66928362846375, "training_acc": 57.0, "val_loss": 30.218452215194702, "val_acc": 48.0}
{"epoch": 15, "training_loss": 136.9219102859497, "training_acc": 49.0, "val_loss": 31.72372877597809, "val_acc": 52.0}
{"epoch": 16, "training_loss": 116.34437680244446, "training_acc": 53.0, "val_loss": 18.356147408485413, "val_acc": 52.0}
{"epoch": 17, "training_loss": 72.1326904296875, "training_acc": 53.0, "val_loss": 19.453604519367218, "val_acc": 48.0}
{"epoch": 18, "training_loss": 85.16214752197266, "training_acc": 41.0, "val_loss": 22.072535753250122, "val_acc": 48.0}
{"epoch": 19, "training_loss": 76.2194595336914, "training_acc": 57.0, "val_loss": 40.3929203748703, "val_acc": 48.0}
{"epoch": 20, "training_loss": 551.6049385070801, "training_acc": 55.0, "val_loss": 68.76692771911621, "val_acc": 52.0}
{"epoch": 21, "training_loss": 200.8020634651184, "training_acc": 53.0, "val_loss": 76.83760523796082, "val_acc": 48.0}
{"epoch": 22, "training_loss": 258.7565155029297, "training_acc": 45.0, "val_loss": 19.07677948474884, "val_acc": 48.0}
{"epoch": 23, "training_loss": 92.69345664978027, "training_acc": 49.0, "val_loss": 17.374305427074432, "val_acc": 52.0}
{"epoch": 24, "training_loss": 122.84321117401123, "training_acc": 37.0, "val_loss": 17.43709146976471, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.38922548294067, "training_acc": 53.0, "val_loss": 21.883729100227356, "val_acc": 52.0}
{"epoch": 26, "training_loss": 91.78070044517517, "training_acc": 45.0, "val_loss": 82.72150754928589, "val_acc": 52.0}
{"epoch": 27, "training_loss": 254.49167490005493, "training_acc": 53.0, "val_loss": 17.31259822845459, "val_acc": 52.0}
{"epoch": 28, "training_loss": 92.96132850646973, "training_acc": 43.0, "val_loss": 107.13024139404297, "val_acc": 52.0}
{"epoch": 29, "training_loss": 271.1189796924591, "training_acc": 53.0, "val_loss": 18.779662251472473, "val_acc": 48.0}
{"epoch": 30, "training_loss": 74.02727484703064, "training_acc": 47.0, "val_loss": 17.317630350589752, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.72385716438293, "training_acc": 49.0, "val_loss": 17.32347458600998, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.66286611557007, "training_acc": 51.0, "val_loss": 22.410987317562103, "val_acc": 52.0}
{"epoch": 33, "training_loss": 84.28365325927734, "training_acc": 51.0, "val_loss": 19.109073281288147, "val_acc": 48.0}
{"epoch": 34, "training_loss": 74.37926578521729, "training_acc": 47.0, "val_loss": 18.179485201835632, "val_acc": 52.0}
{"epoch": 35, "training_loss": 71.7966320514679, "training_acc": 49.0, "val_loss": 17.333796620368958, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.28016591072083, "training_acc": 53.0, "val_loss": 40.448400378227234, "val_acc": 48.0}
{"epoch": 37, "training_loss": 132.40705966949463, "training_acc": 47.0, "val_loss": 17.367023229599, "val_acc": 52.0}
{"epoch": 38, "training_loss": 71.96252751350403, "training_acc": 53.0, "val_loss": 17.7105650305748, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.43352031707764, "training_acc": 49.0, "val_loss": 17.536823451519012, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.33104515075684, "training_acc": 52.0, "val_loss": 17.85523146390915, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.67562627792358, "training_acc": 53.0, "val_loss": 17.927823960781097, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.22432732582092, "training_acc": 59.0, "val_loss": 24.504630267620087, "val_acc": 48.0}
{"epoch": 43, "training_loss": 85.37536239624023, "training_acc": 53.0, "val_loss": 20.989802479743958, "val_acc": 52.0}
{"epoch": 44, "training_loss": 81.22948431968689, "training_acc": 53.0, "val_loss": 17.711468040943146, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.24512982368469, "training_acc": 53.0, "val_loss": 21.13867551088333, "val_acc": 52.0}
{"epoch": 46, "training_loss": 75.76640844345093, "training_acc": 55.0, "val_loss": 17.497603595256805, "val_acc": 52.0}
