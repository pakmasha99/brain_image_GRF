"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 85.76670598983765, "training_acc": 52.0, "val_loss": 13409666400.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 32263054808.23697, "training_acc": 47.0, "val_loss": 553.9494037628174, "val_acc": 48.0}
{"epoch": 2, "training_loss": 13285.100952148438, "training_acc": 49.0, "val_loss": 3435.6529235839844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8205.87532043457, "training_acc": 61.0, "val_loss": 5843.461608886719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 16937.42430114746, "training_acc": 53.0, "val_loss": 1275.1862525939941, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3632.5447959899902, "training_acc": 53.0, "val_loss": 49.317947030067444, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1037.7169036865234, "training_acc": 63.0, "val_loss": 140.84429740905762, "val_acc": 52.0}
{"epoch": 7, "training_loss": 523.6158351898193, "training_acc": 55.0, "val_loss": 470.2463150024414, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1414.5577087402344, "training_acc": 53.0, "val_loss": 187.2148036956787, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1492.8061218261719, "training_acc": 49.0, "val_loss": 87.11867928504944, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1419.355453491211, "training_acc": 57.0, "val_loss": 253.13141345977783, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1110.3403015136719, "training_acc": 63.0, "val_loss": 113.60218524932861, "val_acc": 52.0}
{"epoch": 12, "training_loss": 923.0369033813477, "training_acc": 47.0, "val_loss": 157.0619821548462, "val_acc": 48.0}
{"epoch": 13, "training_loss": 742.2908515930176, "training_acc": 41.0, "val_loss": 122.0409631729126, "val_acc": 48.0}
{"epoch": 14, "training_loss": 467.3725070953369, "training_acc": 51.0, "val_loss": 46.517786383628845, "val_acc": 52.0}
{"epoch": 15, "training_loss": 298.55312728881836, "training_acc": 53.0, "val_loss": 24.066638946533203, "val_acc": 52.0}
{"epoch": 16, "training_loss": 89.30998301506042, "training_acc": 51.0, "val_loss": 87.71488666534424, "val_acc": 52.0}
{"epoch": 17, "training_loss": 272.6836853027344, "training_acc": 47.0, "val_loss": 25.42864680290222, "val_acc": 52.0}
{"epoch": 18, "training_loss": 91.02092957496643, "training_acc": 49.0, "val_loss": 17.343661189079285, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.24941754341125, "training_acc": 48.0, "val_loss": 18.87030005455017, "val_acc": 48.0}
{"epoch": 20, "training_loss": 72.57596135139465, "training_acc": 47.0, "val_loss": 28.281870484352112, "val_acc": 52.0}
{"epoch": 21, "training_loss": 99.68824887275696, "training_acc": 47.0, "val_loss": 17.734065651893616, "val_acc": 52.0}
{"epoch": 22, "training_loss": 135.32074451446533, "training_acc": 37.0, "val_loss": 34.67932939529419, "val_acc": 48.0}
{"epoch": 23, "training_loss": 126.87233591079712, "training_acc": 47.0, "val_loss": 44.05759274959564, "val_acc": 52.0}
{"epoch": 24, "training_loss": 148.92747497558594, "training_acc": 53.0, "val_loss": 27.526545524597168, "val_acc": 48.0}
{"epoch": 25, "training_loss": 102.95769906044006, "training_acc": 47.0, "val_loss": 17.909064888954163, "val_acc": 52.0}
{"epoch": 26, "training_loss": 72.19613313674927, "training_acc": 53.0, "val_loss": 17.32316166162491, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.0281834602356, "training_acc": 51.0, "val_loss": 18.858210742473602, "val_acc": 48.0}
{"epoch": 28, "training_loss": 74.21892857551575, "training_acc": 49.0, "val_loss": 18.297965824604034, "val_acc": 52.0}
{"epoch": 29, "training_loss": 71.56118392944336, "training_acc": 53.0, "val_loss": 18.34625154733658, "val_acc": 60.0}
{"epoch": 30, "training_loss": 73.69917893409729, "training_acc": 47.0, "val_loss": 17.306269705295563, "val_acc": 52.0}
{"epoch": 31, "training_loss": 72.40272545814514, "training_acc": 53.0, "val_loss": 17.33405888080597, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.61012768745422, "training_acc": 50.0, "val_loss": 17.480526864528656, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.48603081703186, "training_acc": 53.0, "val_loss": 17.420700192451477, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.8624575138092, "training_acc": 43.0, "val_loss": 17.41706281900406, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.31196570396423, "training_acc": 51.0, "val_loss": 17.537005245685577, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.30862545967102, "training_acc": 53.0, "val_loss": 17.50575602054596, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.72073459625244, "training_acc": 53.0, "val_loss": 17.352202534675598, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.61262631416321, "training_acc": 47.0, "val_loss": 17.341963946819305, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.89181160926819, "training_acc": 44.0, "val_loss": 17.369048297405243, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.37978053092957, "training_acc": 49.0, "val_loss": 17.45307892560959, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.38789558410645, "training_acc": 53.0, "val_loss": 17.310087382793427, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.84243845939636, "training_acc": 49.0, "val_loss": 17.517444491386414, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.99246454238892, "training_acc": 39.0, "val_loss": 17.309314012527466, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.40460515022278, "training_acc": 53.0, "val_loss": 17.306555807590485, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.2399799823761, "training_acc": 53.0, "val_loss": 17.30739176273346, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.09590649604797, "training_acc": 53.0, "val_loss": 17.318904399871826, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.31670117378235, "training_acc": 53.0, "val_loss": 17.34563261270523, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.39869713783264, "training_acc": 53.0, "val_loss": 17.41020977497101, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.4430582523346, "training_acc": 53.0, "val_loss": 17.31620728969574, "val_acc": 52.0}
