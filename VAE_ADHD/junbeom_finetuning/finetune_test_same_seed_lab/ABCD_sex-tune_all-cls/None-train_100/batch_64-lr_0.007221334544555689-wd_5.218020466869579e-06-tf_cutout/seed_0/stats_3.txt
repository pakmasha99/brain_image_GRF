"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 280.38005447387695, "training_acc": 51.0, "val_loss": 23181987200.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 59929256502.78607, "training_acc": 49.0, "val_loss": 14080.552673339844, "val_acc": 52.0}
{"epoch": 2, "training_loss": 87050.86669921875, "training_acc": 47.0, "val_loss": 11083.523559570312, "val_acc": 52.0}
{"epoch": 3, "training_loss": 30829.174255371094, "training_acc": 53.0, "val_loss": 545.2258110046387, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3578.3804779052734, "training_acc": 49.0, "val_loss": 793.2801246643066, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2493.106922149658, "training_acc": 45.0, "val_loss": 206.50346279144287, "val_acc": 52.0}
{"epoch": 6, "training_loss": 897.9252395629883, "training_acc": 47.0, "val_loss": 98.36469292640686, "val_acc": 52.0}
{"epoch": 7, "training_loss": 244.78764152526855, "training_acc": 63.0, "val_loss": 66.89398288726807, "val_acc": 52.0}
{"epoch": 8, "training_loss": 275.2250804901123, "training_acc": 45.0, "val_loss": 50.435733795166016, "val_acc": 52.0}
{"epoch": 9, "training_loss": 141.53812193870544, "training_acc": 55.0, "val_loss": 17.305484414100647, "val_acc": 52.0}
{"epoch": 10, "training_loss": 87.82565641403198, "training_acc": 51.0, "val_loss": 32.257699966430664, "val_acc": 48.0}
{"epoch": 11, "training_loss": 110.42867612838745, "training_acc": 51.0, "val_loss": 20.07906883955002, "val_acc": 48.0}
{"epoch": 12, "training_loss": 101.35668420791626, "training_acc": 45.0, "val_loss": 31.528812646865845, "val_acc": 48.0}
{"epoch": 13, "training_loss": 110.08321595191956, "training_acc": 47.0, "val_loss": 38.72506618499756, "val_acc": 52.0}
{"epoch": 14, "training_loss": 117.51599431037903, "training_acc": 53.0, "val_loss": 28.04284393787384, "val_acc": 48.0}
{"epoch": 15, "training_loss": 102.68077659606934, "training_acc": 47.0, "val_loss": 27.74997353553772, "val_acc": 48.0}
{"epoch": 16, "training_loss": 113.75153970718384, "training_acc": 45.0, "val_loss": 17.575564980506897, "val_acc": 52.0}
{"epoch": 17, "training_loss": 71.85693669319153, "training_acc": 47.0, "val_loss": 18.485192954540253, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72.23419499397278, "training_acc": 53.0, "val_loss": 19.074855744838715, "val_acc": 48.0}
{"epoch": 19, "training_loss": 76.41360926628113, "training_acc": 47.0, "val_loss": 20.812469720840454, "val_acc": 52.0}
{"epoch": 20, "training_loss": 81.88121938705444, "training_acc": 53.0, "val_loss": 17.34885722398758, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.99524092674255, "training_acc": 50.0, "val_loss": 17.76595264673233, "val_acc": 52.0}
{"epoch": 22, "training_loss": 77.18750429153442, "training_acc": 51.0, "val_loss": 18.14466416835785, "val_acc": 52.0}
{"epoch": 23, "training_loss": 74.87677836418152, "training_acc": 47.0, "val_loss": 17.391936480998993, "val_acc": 52.0}
{"epoch": 24, "training_loss": 76.69200563430786, "training_acc": 53.0, "val_loss": 17.875780165195465, "val_acc": 52.0}
{"epoch": 25, "training_loss": 71.68745470046997, "training_acc": 51.0, "val_loss": 19.201476871967316, "val_acc": 48.0}
{"epoch": 26, "training_loss": 77.01338505744934, "training_acc": 42.0, "val_loss": 17.670539021492004, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.03852415084839, "training_acc": 53.0, "val_loss": 17.37087517976761, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.87655997276306, "training_acc": 53.0, "val_loss": 17.557403445243835, "val_acc": 52.0}
