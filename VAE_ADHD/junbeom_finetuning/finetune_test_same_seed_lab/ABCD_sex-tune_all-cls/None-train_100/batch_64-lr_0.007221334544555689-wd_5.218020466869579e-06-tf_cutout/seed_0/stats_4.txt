"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 224.12495231628418, "training_acc": 59.0, "val_loss": 869191.89453125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2304476.4809570312, "training_acc": 47.0, "val_loss": 994.830322265625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5594.834564208984, "training_acc": 59.0, "val_loss": 179.90423440933228, "val_acc": 52.0}
{"epoch": 3, "training_loss": 422.64528036117554, "training_acc": 57.0, "val_loss": 17.882639169692993, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1181.8039627075195, "training_acc": 45.0, "val_loss": 19.983673095703125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 194.7040023803711, "training_acc": 53.0, "val_loss": 35.12019217014313, "val_acc": 52.0}
{"epoch": 6, "training_loss": 126.04990315437317, "training_acc": 47.0, "val_loss": 52.657002210617065, "val_acc": 52.0}
{"epoch": 7, "training_loss": 159.5784730911255, "training_acc": 53.0, "val_loss": 21.92375510931015, "val_acc": 48.0}
{"epoch": 8, "training_loss": 850.8066749572754, "training_acc": 49.0, "val_loss": 19.542300701141357, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.97034096717834, "training_acc": 59.0, "val_loss": 20.806770026683807, "val_acc": 52.0}
{"epoch": 10, "training_loss": 109.96921491622925, "training_acc": 55.0, "val_loss": 17.49073714017868, "val_acc": 52.0}
{"epoch": 11, "training_loss": 94.38345909118652, "training_acc": 55.0, "val_loss": 24.51757788658142, "val_acc": 52.0}
{"epoch": 12, "training_loss": 102.53621006011963, "training_acc": 53.0, "val_loss": 17.63378530740738, "val_acc": 52.0}
{"epoch": 13, "training_loss": 74.03091502189636, "training_acc": 49.0, "val_loss": 18.16793829202652, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.47727131843567, "training_acc": 53.0, "val_loss": 17.5955131649971, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.3067696094513, "training_acc": 47.0, "val_loss": 17.895475029945374, "val_acc": 52.0}
{"epoch": 16, "training_loss": 73.94302368164062, "training_acc": 45.0, "val_loss": 17.308802902698517, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.90457844734192, "training_acc": 53.0, "val_loss": 19.110126793384552, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.46837067604065, "training_acc": 53.0, "val_loss": 17.49369353055954, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.3378255367279, "training_acc": 47.0, "val_loss": 17.36772358417511, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.07441353797913, "training_acc": 53.0, "val_loss": 17.52704381942749, "val_acc": 52.0}
{"epoch": 21, "training_loss": 72.13108134269714, "training_acc": 47.0, "val_loss": 17.317867279052734, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25526928901672, "training_acc": 51.0, "val_loss": 17.370624840259552, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.25924897193909, "training_acc": 53.0, "val_loss": 17.477495968341827, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.86018323898315, "training_acc": 51.0, "val_loss": 17.335769534111023, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20623731613159, "training_acc": 53.0, "val_loss": 17.438122630119324, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.85425114631653, "training_acc": 52.0, "val_loss": 17.32548475265503, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.42989015579224, "training_acc": 53.0, "val_loss": 17.340955138206482, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.39829730987549, "training_acc": 50.0, "val_loss": 17.369119822978973, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21625590324402, "training_acc": 51.0, "val_loss": 18.8491553068161, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.02339386940002, "training_acc": 57.0, "val_loss": 17.86429136991501, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.70563530921936, "training_acc": 47.0, "val_loss": 17.311125993728638, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.61429142951965, "training_acc": 53.0, "val_loss": 17.40129441022873, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21832585334778, "training_acc": 53.0, "val_loss": 17.308197915554047, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.18435764312744, "training_acc": 53.0, "val_loss": 17.31102168560028, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13060307502747, "training_acc": 53.0, "val_loss": 17.375674843788147, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.53883481025696, "training_acc": 53.0, "val_loss": 17.350417375564575, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16188955307007, "training_acc": 53.0, "val_loss": 17.377331852912903, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.46497297286987, "training_acc": 53.0, "val_loss": 17.32448935508728, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.97681093215942, "training_acc": 53.0, "val_loss": 17.321309447288513, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.31023907661438, "training_acc": 51.0, "val_loss": 17.379194498062134, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.6033546924591, "training_acc": 47.0, "val_loss": 17.360417544841766, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.54308700561523, "training_acc": 44.0, "val_loss": 17.3095703125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13718962669373, "training_acc": 53.0, "val_loss": 17.316389083862305, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.03849911689758, "training_acc": 53.0, "val_loss": 17.36316978931427, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.2399492263794, "training_acc": 53.0, "val_loss": 17.42159277200699, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.39650845527649, "training_acc": 53.0, "val_loss": 17.38726645708084, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.41547107696533, "training_acc": 53.0, "val_loss": 17.32846349477768, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.12115859985352, "training_acc": 53.0, "val_loss": 17.31502115726471, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.17180585861206, "training_acc": 53.0, "val_loss": 17.30925589799881, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.22259068489075, "training_acc": 53.0, "val_loss": 17.30840653181076, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.17754578590393, "training_acc": 53.0, "val_loss": 17.308272421360016, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.42853546142578, "training_acc": 53.0, "val_loss": 17.31094717979431, "val_acc": 52.0}
