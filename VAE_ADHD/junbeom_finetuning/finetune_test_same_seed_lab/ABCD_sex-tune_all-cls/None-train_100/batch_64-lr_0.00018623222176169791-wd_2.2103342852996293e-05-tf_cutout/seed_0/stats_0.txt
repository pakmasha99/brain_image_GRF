"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.04193806648254, "training_acc": 52.0, "val_loss": 17.17151403427124, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.31489491462708, "training_acc": 52.0, "val_loss": 17.35937148332596, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.63257598876953, "training_acc": 45.0, "val_loss": 17.33543574810028, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.42426919937134, "training_acc": 50.0, "val_loss": 17.347079515457153, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.32806062698364, "training_acc": 46.0, "val_loss": 17.23639667034149, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.64232635498047, "training_acc": 52.0, "val_loss": 17.25212037563324, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.29362988471985, "training_acc": 50.0, "val_loss": 17.331145703792572, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.29267883300781, "training_acc": 53.0, "val_loss": 17.214196920394897, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.79386639595032, "training_acc": 52.0, "val_loss": 17.192023992538452, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.1942765712738, "training_acc": 52.0, "val_loss": 17.34534353017807, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.34994554519653, "training_acc": 48.0, "val_loss": 17.327596247196198, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.32059073448181, "training_acc": 52.0, "val_loss": 17.22884327173233, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.30771994590759, "training_acc": 52.0, "val_loss": 17.228706181049347, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.31111454963684, "training_acc": 52.0, "val_loss": 17.277052998542786, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24566435813904, "training_acc": 52.0, "val_loss": 17.220380902290344, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2376663684845, "training_acc": 52.0, "val_loss": 17.178694903850555, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.352530002594, "training_acc": 52.0, "val_loss": 17.167744040489197, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.32657241821289, "training_acc": 52.0, "val_loss": 17.23506897687912, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.23808121681213, "training_acc": 52.0, "val_loss": 17.300300300121307, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26156330108643, "training_acc": 52.0, "val_loss": 17.277522385120392, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2556300163269, "training_acc": 52.0, "val_loss": 17.241846024990082, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21820831298828, "training_acc": 52.0, "val_loss": 17.187446355819702, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.56085681915283, "training_acc": 52.0, "val_loss": 17.164447903633118, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.280517578125, "training_acc": 52.0, "val_loss": 17.246049642562866, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.17084789276123, "training_acc": 52.0, "val_loss": 17.389369010925293, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.49113249778748, "training_acc": 48.0, "val_loss": 17.402146756649017, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.02143216133118, "training_acc": 38.0, "val_loss": 17.27195382118225, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24004292488098, "training_acc": 52.0, "val_loss": 17.305000126361847, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.36089253425598, "training_acc": 46.0, "val_loss": 17.286208271980286, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.21413350105286, "training_acc": 52.0, "val_loss": 17.2007218003273, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.69581341743469, "training_acc": 52.0, "val_loss": 17.170561850070953, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.62963604927063, "training_acc": 52.0, "val_loss": 17.224422097206116, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24106979370117, "training_acc": 52.0, "val_loss": 17.219267785549164, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25801968574524, "training_acc": 52.0, "val_loss": 17.23410338163376, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26808977127075, "training_acc": 52.0, "val_loss": 17.22724139690399, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23027443885803, "training_acc": 52.0, "val_loss": 17.256304621696472, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25881314277649, "training_acc": 52.0, "val_loss": 17.256399989128113, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.36117959022522, "training_acc": 52.0, "val_loss": 17.218993604183197, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.19014072418213, "training_acc": 52.0, "val_loss": 17.163807153701782, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.61855053901672, "training_acc": 52.0, "val_loss": 17.151279747486115, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.48634815216064, "training_acc": 52.0, "val_loss": 17.173513770103455, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28875827789307, "training_acc": 52.0, "val_loss": 17.242594063282013, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.21104288101196, "training_acc": 52.0, "val_loss": 17.303286492824554, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.3462986946106, "training_acc": 52.0, "val_loss": 17.365604639053345, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.46196699142456, "training_acc": 48.0, "val_loss": 17.438112199306488, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.50718975067139, "training_acc": 48.0, "val_loss": 17.331010103225708, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.3062469959259, "training_acc": 54.0, "val_loss": 17.250262200832367, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.21925377845764, "training_acc": 52.0, "val_loss": 17.2068789601326, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.27202939987183, "training_acc": 52.0, "val_loss": 17.172996699810028, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.37836527824402, "training_acc": 52.0, "val_loss": 17.182230949401855, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.22121620178223, "training_acc": 52.0, "val_loss": 17.25352704524994, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.22034001350403, "training_acc": 52.0, "val_loss": 17.35188066959381, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.33211255073547, "training_acc": 48.0, "val_loss": 17.381341755390167, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.37452745437622, "training_acc": 48.0, "val_loss": 17.351368069648743, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.3083348274231, "training_acc": 47.0, "val_loss": 17.28062778711319, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.40652203559875, "training_acc": 52.0, "val_loss": 17.206306755542755, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.27673745155334, "training_acc": 52.0, "val_loss": 17.20110923051834, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.26270413398743, "training_acc": 52.0, "val_loss": 17.22871959209442, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22076368331909, "training_acc": 52.0, "val_loss": 17.238961160182953, "val_acc": 56.0}
