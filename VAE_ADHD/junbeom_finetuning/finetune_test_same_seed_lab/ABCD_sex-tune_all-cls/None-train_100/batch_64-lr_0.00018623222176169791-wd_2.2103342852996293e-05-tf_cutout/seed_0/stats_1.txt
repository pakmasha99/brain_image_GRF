"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.06549882888794, "training_acc": 47.0, "val_loss": 17.354780435562134, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16504788398743, "training_acc": 53.0, "val_loss": 17.459630966186523, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.47592067718506, "training_acc": 53.0, "val_loss": 17.377322912216187, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3630096912384, "training_acc": 53.0, "val_loss": 17.391909658908844, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.02890086174011, "training_acc": 53.0, "val_loss": 17.337772250175476, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0891444683075, "training_acc": 53.0, "val_loss": 17.31724888086319, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.60094118118286, "training_acc": 45.0, "val_loss": 17.31298416852951, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.79237627983093, "training_acc": 53.0, "val_loss": 17.326165735721588, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19003629684448, "training_acc": 53.0, "val_loss": 17.311398684978485, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.3833236694336, "training_acc": 53.0, "val_loss": 17.31754094362259, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.08457946777344, "training_acc": 53.0, "val_loss": 17.366759479045868, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25993084907532, "training_acc": 53.0, "val_loss": 17.386603355407715, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.30151343345642, "training_acc": 53.0, "val_loss": 17.372745275497437, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.20111393928528, "training_acc": 53.0, "val_loss": 17.32145845890045, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18997311592102, "training_acc": 53.0, "val_loss": 17.31274425983429, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1577684879303, "training_acc": 53.0, "val_loss": 17.314140498638153, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15943002700806, "training_acc": 53.0, "val_loss": 17.321288585662842, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20498704910278, "training_acc": 53.0, "val_loss": 17.34626293182373, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21234631538391, "training_acc": 53.0, "val_loss": 17.38765239715576, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.4122326374054, "training_acc": 53.0, "val_loss": 17.354586720466614, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.27063584327698, "training_acc": 53.0, "val_loss": 17.340272665023804, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25458002090454, "training_acc": 53.0, "val_loss": 17.312324047088623, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24631571769714, "training_acc": 53.0, "val_loss": 17.332038283348083, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.31248164176941, "training_acc": 48.0, "val_loss": 17.325027287006378, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.54671168327332, "training_acc": 39.0, "val_loss": 17.31134057044983, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16114139556885, "training_acc": 53.0, "val_loss": 17.350783944129944, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2063570022583, "training_acc": 53.0, "val_loss": 17.39083230495453, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.37682175636292, "training_acc": 53.0, "val_loss": 17.37489402294159, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.36338400840759, "training_acc": 53.0, "val_loss": 17.350681126117706, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17235922813416, "training_acc": 53.0, "val_loss": 17.310361564159393, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13749265670776, "training_acc": 53.0, "val_loss": 17.314285039901733, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.52614617347717, "training_acc": 43.0, "val_loss": 17.325063049793243, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.21737384796143, "training_acc": 53.0, "val_loss": 17.310164868831635, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21050572395325, "training_acc": 53.0, "val_loss": 17.343993484973907, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19895625114441, "training_acc": 53.0, "val_loss": 17.356887459754944, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.30085182189941, "training_acc": 53.0, "val_loss": 17.33691245317459, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17205142974854, "training_acc": 53.0, "val_loss": 17.33146756887436, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16900300979614, "training_acc": 53.0, "val_loss": 17.323783040046692, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.28893780708313, "training_acc": 53.0, "val_loss": 17.319998145103455, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18037343025208, "training_acc": 53.0, "val_loss": 17.30925738811493, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17013740539551, "training_acc": 53.0, "val_loss": 17.311131954193115, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.19002938270569, "training_acc": 53.0, "val_loss": 17.309577763080597, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.18542408943176, "training_acc": 53.0, "val_loss": 17.315810918807983, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.12875866889954, "training_acc": 53.0, "val_loss": 17.323637008666992, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.15215611457825, "training_acc": 53.0, "val_loss": 17.33856201171875, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.16943597793579, "training_acc": 53.0, "val_loss": 17.335639894008636, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.21460890769958, "training_acc": 53.0, "val_loss": 17.3217311501503, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16363453865051, "training_acc": 53.0, "val_loss": 17.31889247894287, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.42110395431519, "training_acc": 53.0, "val_loss": 17.310649156570435, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12017726898193, "training_acc": 53.0, "val_loss": 17.31906831264496, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.11189198493958, "training_acc": 53.0, "val_loss": 17.340362071990967, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14822745323181, "training_acc": 53.0, "val_loss": 17.372268438339233, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.31229829788208, "training_acc": 53.0, "val_loss": 17.396433651447296, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.3121485710144, "training_acc": 53.0, "val_loss": 17.360401153564453, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.48874235153198, "training_acc": 53.0, "val_loss": 17.32275038957596, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.14864039421082, "training_acc": 53.0, "val_loss": 17.31933206319809, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.1345055103302, "training_acc": 53.0, "val_loss": 17.318277060985565, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.14019060134888, "training_acc": 53.0, "val_loss": 17.31681376695633, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13330507278442, "training_acc": 53.0, "val_loss": 17.313644289970398, "val_acc": 52.0}
