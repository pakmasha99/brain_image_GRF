"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 180.34101486206055, "training_acc": 50.0, "val_loss": 4587.061309814453, "val_acc": 56.0}
{"epoch": 1, "training_loss": 14124.10969543457, "training_acc": 52.0, "val_loss": 75.28714537620544, "val_acc": 44.0}
{"epoch": 2, "training_loss": 216.86020350456238, "training_acc": 48.0, "val_loss": 17.645011842250824, "val_acc": 56.0}
{"epoch": 3, "training_loss": 71.05054473876953, "training_acc": 46.0, "val_loss": 17.189349234104156, "val_acc": 56.0}
{"epoch": 4, "training_loss": 70.11657285690308, "training_acc": 50.0, "val_loss": 17.225128412246704, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.14357113838196, "training_acc": 52.0, "val_loss": 18.654701113700867, "val_acc": 56.0}
{"epoch": 6, "training_loss": 71.57408452033997, "training_acc": 48.0, "val_loss": 17.15545654296875, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.45761895179749, "training_acc": 52.0, "val_loss": 17.155584692955017, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.24805784225464, "training_acc": 52.0, "val_loss": 18.132883310317993, "val_acc": 56.0}
{"epoch": 9, "training_loss": 70.9825336933136, "training_acc": 48.0, "val_loss": 17.39938259124756, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.33505272865295, "training_acc": 50.0, "val_loss": 17.187179625034332, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.31440854072571, "training_acc": 52.0, "val_loss": 17.166532576084137, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.31652402877808, "training_acc": 52.0, "val_loss": 17.207762598991394, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.32591700553894, "training_acc": 52.0, "val_loss": 17.294742166996002, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.31040501594543, "training_acc": 52.0, "val_loss": 17.28087216615677, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2505955696106, "training_acc": 52.0, "val_loss": 17.206035554409027, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.31547784805298, "training_acc": 52.0, "val_loss": 17.163005471229553, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.3377115726471, "training_acc": 52.0, "val_loss": 17.18832403421402, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.26690316200256, "training_acc": 52.0, "val_loss": 17.23177134990692, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.23186087608337, "training_acc": 52.0, "val_loss": 17.259471118450165, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.27462410926819, "training_acc": 52.0, "val_loss": 17.274944484233856, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2716875076294, "training_acc": 52.0, "val_loss": 17.241474986076355, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.37771701812744, "training_acc": 52.0, "val_loss": 17.197629809379578, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25646805763245, "training_acc": 52.0, "val_loss": 17.215219140052795, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21492075920105, "training_acc": 52.0, "val_loss": 17.25592315196991, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.29061603546143, "training_acc": 52.0, "val_loss": 17.299461364746094, "val_acc": 56.0}
