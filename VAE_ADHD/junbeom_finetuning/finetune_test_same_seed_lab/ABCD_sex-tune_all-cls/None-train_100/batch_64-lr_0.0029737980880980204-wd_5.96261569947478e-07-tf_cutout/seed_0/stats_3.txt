"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 146.74365711212158, "training_acc": 44.0, "val_loss": 19149.11346435547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 49732.28144264221, "training_acc": 49.0, "val_loss": 21.40543907880783, "val_acc": 48.0}
{"epoch": 2, "training_loss": 90.27432870864868, "training_acc": 53.0, "val_loss": 33.09147655963898, "val_acc": 48.0}
{"epoch": 3, "training_loss": 105.72349095344543, "training_acc": 52.0, "val_loss": 18.117420375347137, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.9644730091095, "training_acc": 53.0, "val_loss": 18.645310401916504, "val_acc": 48.0}
{"epoch": 5, "training_loss": 72.19006276130676, "training_acc": 51.0, "val_loss": 18.467174470424652, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.14361214637756, "training_acc": 53.0, "val_loss": 17.466041445732117, "val_acc": 52.0}
{"epoch": 7, "training_loss": 71.63419079780579, "training_acc": 47.0, "val_loss": 17.541246116161346, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72.7167718410492, "training_acc": 53.0, "val_loss": 17.60030835866928, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.08978366851807, "training_acc": 53.0, "val_loss": 17.31751561164856, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14348030090332, "training_acc": 53.0, "val_loss": 17.314332723617554, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.5768973827362, "training_acc": 53.0, "val_loss": 17.319899797439575, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23746609687805, "training_acc": 53.0, "val_loss": 17.371173202991486, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.66417837142944, "training_acc": 43.0, "val_loss": 17.324750125408173, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.33487391471863, "training_acc": 53.0, "val_loss": 17.311252653598785, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.35349678993225, "training_acc": 53.0, "val_loss": 17.309531569480896, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2359082698822, "training_acc": 53.0, "val_loss": 17.312046885490417, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1561233997345, "training_acc": 53.0, "val_loss": 17.315128445625305, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10813331604004, "training_acc": 53.0, "val_loss": 17.356082797050476, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.37729001045227, "training_acc": 53.0, "val_loss": 17.359469830989838, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.20866513252258, "training_acc": 53.0, "val_loss": 17.31002777814865, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1635468006134, "training_acc": 53.0, "val_loss": 17.31557846069336, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22185182571411, "training_acc": 53.0, "val_loss": 17.315177619457245, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22795581817627, "training_acc": 53.0, "val_loss": 17.310142517089844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.32888913154602, "training_acc": 53.0, "val_loss": 17.309395968914032, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.0537269115448, "training_acc": 53.0, "val_loss": 17.340008914470673, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.27657651901245, "training_acc": 53.0, "val_loss": 17.400749027729034, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.60125470161438, "training_acc": 53.0, "val_loss": 17.373520135879517, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13163113594055, "training_acc": 53.0, "val_loss": 17.311644554138184, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.36100697517395, "training_acc": 53.0, "val_loss": 17.315155267715454, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.24638652801514, "training_acc": 53.0, "val_loss": 17.313343286514282, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20645689964294, "training_acc": 53.0, "val_loss": 17.308956384658813, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16081762313843, "training_acc": 53.0, "val_loss": 17.309947311878204, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21600699424744, "training_acc": 53.0, "val_loss": 17.31864959001541, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.33210349082947, "training_acc": 53.0, "val_loss": 17.31819361448288, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.17400288581848, "training_acc": 53.0, "val_loss": 17.30865389108658, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1588487625122, "training_acc": 53.0, "val_loss": 17.309468984603882, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20445656776428, "training_acc": 53.0, "val_loss": 17.308643460273743, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15827560424805, "training_acc": 53.0, "val_loss": 17.308463156223297, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14650797843933, "training_acc": 53.0, "val_loss": 17.309927940368652, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.12115216255188, "training_acc": 53.0, "val_loss": 17.31414943933487, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13881850242615, "training_acc": 53.0, "val_loss": 17.322823405265808, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.16536498069763, "training_acc": 53.0, "val_loss": 17.32591539621353, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16439032554626, "training_acc": 53.0, "val_loss": 17.319612205028534, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.24232816696167, "training_acc": 53.0, "val_loss": 17.31160283088684, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.14610838890076, "training_acc": 53.0, "val_loss": 17.312070727348328, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13203144073486, "training_acc": 53.0, "val_loss": 17.311854660511017, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16696524620056, "training_acc": 53.0, "val_loss": 17.312338948249817, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13050770759583, "training_acc": 53.0, "val_loss": 17.318515479564667, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13300442695618, "training_acc": 53.0, "val_loss": 17.32359677553177, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13839173316956, "training_acc": 53.0, "val_loss": 17.330799996852875, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.30862545967102, "training_acc": 53.0, "val_loss": 17.329703271389008, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1733980178833, "training_acc": 53.0, "val_loss": 17.31463372707367, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.16463613510132, "training_acc": 53.0, "val_loss": 17.311355471611023, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.23774218559265, "training_acc": 53.0, "val_loss": 17.311030626296997, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.12306451797485, "training_acc": 53.0, "val_loss": 17.309477925300598, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.17501187324524, "training_acc": 53.0, "val_loss": 17.31064021587372, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.17415714263916, "training_acc": 53.0, "val_loss": 17.31080263853073, "val_acc": 52.0}
