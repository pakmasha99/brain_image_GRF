"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1916.62349319458, "training_acc": 51.0, "val_loss": 6.302221913801821e+23, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.3254217462746172e+24, "training_acc": 61.0, "val_loss": 120785456332800.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1.0064005087933497e+19, "training_acc": 45.0, "val_loss": 5702744748851200.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.6165688573952e+16, "training_acc": 53.0, "val_loss": 45124458905600.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 138044542025728.0, "training_acc": 53.0, "val_loss": 8001318912000.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 23210545750016.0, "training_acc": 43.0, "val_loss": 113951961600.0, "val_acc": 48.0}
{"epoch": 6, "training_loss": 321211748352.0, "training_acc": 51.0, "val_loss": 96334566400.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 848697716736.0, "training_acc": 45.0, "val_loss": 173492646400.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 615694021632.0, "training_acc": 47.0, "val_loss": 112838681600.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 323491082496.0, "training_acc": 53.0, "val_loss": 126979494400.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 338013172224.0, "training_acc": 47.0, "val_loss": 224755353600.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 714972479488.0, "training_acc": 53.0, "val_loss": 26557896000.0, "val_acc": 52.0}
{"epoch": 12, "training_loss": 82399494656.0, "training_acc": 63.0, "val_loss": 14585219200.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2146757074944.0, "training_acc": 49.0, "val_loss": 1747403564646400.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 5182616886050816.0, "training_acc": 53.0, "val_loss": 280826426163200.0, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1014885913722880.0, "training_acc": 53.0, "val_loss": 712514941747200.0, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1707688895447040.0, "training_acc": 53.0, "val_loss": 212879474688000.0, "val_acc": 48.0}
{"epoch": 17, "training_loss": 3.24813243547648e+17, "training_acc": 47.0, "val_loss": 176733867212800.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 846915231023104.0, "training_acc": 48.0, "val_loss": 135231124275200.0, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1209536090210304.0, "training_acc": 43.0, "val_loss": 248664739020800.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2092893892247552.0, "training_acc": 53.0, "val_loss": 101312469401600.0, "val_acc": 48.0}
{"epoch": 21, "training_loss": 315852658835456.0, "training_acc": 45.0, "val_loss": 225363964723200.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 672901951913984.0, "training_acc": 47.0, "val_loss": 27229066035200.0, "val_acc": 48.0}
{"epoch": 23, "training_loss": 80551041957888.0, "training_acc": 47.0, "val_loss": 78221207142400.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 327051456282624.0, "training_acc": 61.0, "val_loss": 3966536096153600.0, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.1189175387553792e+16, "training_acc": 43.0, "val_loss": 302306846310400.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 868857727156224.0, "training_acc": 49.0, "val_loss": 216500155187200.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 524136931262464.0, "training_acc": 53.0, "val_loss": 4794948812800.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 286414770012160.0, "training_acc": 39.0, "val_loss": 623317811200.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 53108998144000.0, "training_acc": 52.0, "val_loss": 2819875667968000.0, "val_acc": 52.0}
{"epoch": 30, "training_loss": 6595099782807552.0, "training_acc": 55.0, "val_loss": 392508656844800.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1093464397709312.0, "training_acc": 47.0, "val_loss": 164675334963200.0, "val_acc": 48.0}
