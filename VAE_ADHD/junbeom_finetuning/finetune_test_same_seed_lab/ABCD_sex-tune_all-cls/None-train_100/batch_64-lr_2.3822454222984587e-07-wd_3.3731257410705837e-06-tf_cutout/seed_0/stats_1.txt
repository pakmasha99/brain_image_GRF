"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.17029309272766, "training_acc": 54.0, "val_loss": 17.409013211727142, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.69083309173584, "training_acc": 47.0, "val_loss": 17.403507232666016, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.67120814323425, "training_acc": 47.0, "val_loss": 17.396514117717743, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.62140774726868, "training_acc": 47.0, "val_loss": 17.388667166233063, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58373236656189, "training_acc": 47.0, "val_loss": 17.381219565868378, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.50635266304016, "training_acc": 47.0, "val_loss": 17.375734448432922, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.54464340209961, "training_acc": 47.0, "val_loss": 17.370139062404633, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.48285436630249, "training_acc": 47.0, "val_loss": 17.36542135477066, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.46870017051697, "training_acc": 47.0, "val_loss": 17.361602187156677, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44018959999084, "training_acc": 47.0, "val_loss": 17.35808700323105, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.39910364151001, "training_acc": 47.0, "val_loss": 17.354001104831696, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.36655783653259, "training_acc": 47.0, "val_loss": 17.3506960272789, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.38638496398926, "training_acc": 47.0, "val_loss": 17.34713912010193, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.37043070793152, "training_acc": 47.0, "val_loss": 17.343685030937195, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.34394264221191, "training_acc": 48.0, "val_loss": 17.340224981307983, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.32143807411194, "training_acc": 50.0, "val_loss": 17.337189614772797, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.32329559326172, "training_acc": 42.0, "val_loss": 17.334647476673126, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24907422065735, "training_acc": 53.0, "val_loss": 17.33190268278122, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.30770611763, "training_acc": 52.0, "val_loss": 17.329487204551697, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.26928186416626, "training_acc": 53.0, "val_loss": 17.327037453651428, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.26488924026489, "training_acc": 53.0, "val_loss": 17.32490062713623, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26245832443237, "training_acc": 53.0, "val_loss": 17.323508858680725, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.23475694656372, "training_acc": 53.0, "val_loss": 17.322412133216858, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22588682174683, "training_acc": 53.0, "val_loss": 17.32160896062851, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.25520944595337, "training_acc": 53.0, "val_loss": 17.32063591480255, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.25967788696289, "training_acc": 53.0, "val_loss": 17.319753766059875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22721815109253, "training_acc": 53.0, "val_loss": 17.319054901599884, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.21741390228271, "training_acc": 53.0, "val_loss": 17.318326234817505, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.21187257766724, "training_acc": 53.0, "val_loss": 17.31727570295334, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21929287910461, "training_acc": 53.0, "val_loss": 17.316478490829468, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.21901798248291, "training_acc": 53.0, "val_loss": 17.315588891506195, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17602849006653, "training_acc": 53.0, "val_loss": 17.31521636247635, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17773580551147, "training_acc": 53.0, "val_loss": 17.3148050904274, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19480872154236, "training_acc": 53.0, "val_loss": 17.31444001197815, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17694997787476, "training_acc": 53.0, "val_loss": 17.314085364341736, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.21251130104065, "training_acc": 53.0, "val_loss": 17.313851416110992, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14438199996948, "training_acc": 53.0, "val_loss": 17.313629388809204, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15135025978088, "training_acc": 53.0, "val_loss": 17.313195765018463, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.18515396118164, "training_acc": 53.0, "val_loss": 17.312929034233093, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15433549880981, "training_acc": 53.0, "val_loss": 17.31279343366623, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.15763783454895, "training_acc": 53.0, "val_loss": 17.31249988079071, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15858769416809, "training_acc": 53.0, "val_loss": 17.312368750572205, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13936710357666, "training_acc": 53.0, "val_loss": 17.312511801719666, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.170405626297, "training_acc": 53.0, "val_loss": 17.312467098236084, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1642529964447, "training_acc": 53.0, "val_loss": 17.312537133693695, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15622305870056, "training_acc": 53.0, "val_loss": 17.312516272068024, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.16460251808167, "training_acc": 53.0, "val_loss": 17.312458157539368, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17395615577698, "training_acc": 53.0, "val_loss": 17.312607169151306, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.1532289981842, "training_acc": 53.0, "val_loss": 17.312580347061157, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.1562192440033, "training_acc": 53.0, "val_loss": 17.312900722026825, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.15689754486084, "training_acc": 53.0, "val_loss": 17.312827706336975, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.1189775466919, "training_acc": 53.0, "val_loss": 17.312976717948914, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.14843368530273, "training_acc": 53.0, "val_loss": 17.31303036212921, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.13015413284302, "training_acc": 53.0, "val_loss": 17.313188314437866, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.13677835464478, "training_acc": 53.0, "val_loss": 17.31351464986801, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.16419982910156, "training_acc": 53.0, "val_loss": 17.313489317893982, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.14637732505798, "training_acc": 53.0, "val_loss": 17.31339991092682, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15621781349182, "training_acc": 53.0, "val_loss": 17.31351763010025, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.14378380775452, "training_acc": 53.0, "val_loss": 17.31378138065338, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.12526631355286, "training_acc": 53.0, "val_loss": 17.314018309116364, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.13152623176575, "training_acc": 53.0, "val_loss": 17.314141988754272, "val_acc": 52.0}
