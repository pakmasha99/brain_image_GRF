"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31675744056702, "training_acc": 54.0, "val_loss": 17.447087168693542, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.87109589576721, "training_acc": 47.0, "val_loss": 17.43829697370529, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.83888936042786, "training_acc": 47.0, "val_loss": 17.428046464920044, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.76760578155518, "training_acc": 47.0, "val_loss": 17.417441308498383, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.74547696113586, "training_acc": 47.0, "val_loss": 17.406827211380005, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.69268798828125, "training_acc": 47.0, "val_loss": 17.396531999111176, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.62025308609009, "training_acc": 47.0, "val_loss": 17.38618016242981, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.61438083648682, "training_acc": 47.0, "val_loss": 17.37668514251709, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.58850860595703, "training_acc": 47.0, "val_loss": 17.368118464946747, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.47154974937439, "training_acc": 47.0, "val_loss": 17.360763251781464, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.47317504882812, "training_acc": 47.0, "val_loss": 17.353753745555878, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.44765090942383, "training_acc": 47.0, "val_loss": 17.347131669521332, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.37380719184875, "training_acc": 48.0, "val_loss": 17.341655492782593, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.3643581867218, "training_acc": 47.0, "val_loss": 17.335975170135498, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.35779237747192, "training_acc": 42.0, "val_loss": 17.33115017414093, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.38649821281433, "training_acc": 45.0, "val_loss": 17.32657253742218, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29220676422119, "training_acc": 53.0, "val_loss": 17.323017120361328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2760739326477, "training_acc": 52.0, "val_loss": 17.320437729358673, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29894089698792, "training_acc": 53.0, "val_loss": 17.31826364994049, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.26543521881104, "training_acc": 53.0, "val_loss": 17.316091060638428, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2966661453247, "training_acc": 53.0, "val_loss": 17.314434051513672, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25628089904785, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24384784698486, "training_acc": 53.0, "val_loss": 17.312277853488922, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17977356910706, "training_acc": 53.0, "val_loss": 17.31133759021759, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22294497489929, "training_acc": 53.0, "val_loss": 17.31037348508835, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17393803596497, "training_acc": 53.0, "val_loss": 17.30954647064209, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2202422618866, "training_acc": 53.0, "val_loss": 17.30884313583374, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1843991279602, "training_acc": 53.0, "val_loss": 17.308470606803894, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17627453804016, "training_acc": 53.0, "val_loss": 17.307990789413452, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20375180244446, "training_acc": 53.0, "val_loss": 17.307880520820618, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16607403755188, "training_acc": 53.0, "val_loss": 17.30741411447525, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1667332649231, "training_acc": 53.0, "val_loss": 17.306990921497345, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16362309455872, "training_acc": 53.0, "val_loss": 17.30658710002899, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1534435749054, "training_acc": 53.0, "val_loss": 17.306266725063324, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15851998329163, "training_acc": 53.0, "val_loss": 17.30634719133377, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.19908714294434, "training_acc": 53.0, "val_loss": 17.30569750070572, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14764451980591, "training_acc": 53.0, "val_loss": 17.305727303028107, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.17538499832153, "training_acc": 53.0, "val_loss": 17.305830121040344, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.19111514091492, "training_acc": 53.0, "val_loss": 17.30577051639557, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19144487380981, "training_acc": 53.0, "val_loss": 17.305727303028107, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.20607805252075, "training_acc": 53.0, "val_loss": 17.305904626846313, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.19125294685364, "training_acc": 53.0, "val_loss": 17.306022346019745, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.159503698349, "training_acc": 53.0, "val_loss": 17.305848002433777, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.21204328536987, "training_acc": 53.0, "val_loss": 17.306147515773773, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17241930961609, "training_acc": 53.0, "val_loss": 17.3061341047287, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.08893322944641, "training_acc": 53.0, "val_loss": 17.30601340532303, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14193725585938, "training_acc": 53.0, "val_loss": 17.30627715587616, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.15979886054993, "training_acc": 53.0, "val_loss": 17.306484282016754, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.10273385047913, "training_acc": 53.0, "val_loss": 17.306506633758545, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12110137939453, "training_acc": 53.0, "val_loss": 17.30668991804123, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.1356291770935, "training_acc": 53.0, "val_loss": 17.306694388389587, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14795446395874, "training_acc": 53.0, "val_loss": 17.306897044181824, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.18285846710205, "training_acc": 53.0, "val_loss": 17.30698049068451, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.16087460517883, "training_acc": 53.0, "val_loss": 17.30719357728958, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.1441171169281, "training_acc": 53.0, "val_loss": 17.30734258890152, "val_acc": 52.0}
