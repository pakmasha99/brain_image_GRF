"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 116.54300594329834, "training_acc": 47.0, "val_loss": 262.72027492523193, "val_acc": 52.0}
{"epoch": 1, "training_loss": 779.8074526786804, "training_acc": 43.0, "val_loss": 17.709018290042877, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.36185002326965, "training_acc": 45.0, "val_loss": 17.38315224647522, "val_acc": 52.0}
{"epoch": 3, "training_loss": 82.96590280532837, "training_acc": 43.0, "val_loss": 17.35013723373413, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.81187081336975, "training_acc": 47.0, "val_loss": 17.58824735879898, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.20659470558167, "training_acc": 47.0, "val_loss": 17.318612337112427, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1804575920105, "training_acc": 53.0, "val_loss": 17.310672998428345, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2862446308136, "training_acc": 53.0, "val_loss": 17.32609272003174, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13468313217163, "training_acc": 53.0, "val_loss": 17.36602783203125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.4589204788208, "training_acc": 53.0, "val_loss": 17.36549735069275, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.48985433578491, "training_acc": 53.0, "val_loss": 17.3171728849411, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13007974624634, "training_acc": 53.0, "val_loss": 17.312589287757874, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12721562385559, "training_acc": 53.0, "val_loss": 17.310309410095215, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1919891834259, "training_acc": 53.0, "val_loss": 17.310693860054016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16192746162415, "training_acc": 53.0, "val_loss": 17.309385538101196, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16396737098694, "training_acc": 53.0, "val_loss": 17.309442162513733, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16163492202759, "training_acc": 53.0, "val_loss": 17.313453555107117, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13878226280212, "training_acc": 53.0, "val_loss": 17.315463721752167, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12922787666321, "training_acc": 53.0, "val_loss": 17.320285737514496, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1562430858612, "training_acc": 53.0, "val_loss": 17.327754199504852, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1673743724823, "training_acc": 53.0, "val_loss": 17.325735092163086, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1418719291687, "training_acc": 53.0, "val_loss": 17.315925657749176, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13164567947388, "training_acc": 53.0, "val_loss": 17.311187088489532, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16869807243347, "training_acc": 53.0, "val_loss": 17.309775948524475, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14239835739136, "training_acc": 53.0, "val_loss": 17.31080561876297, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20277142524719, "training_acc": 53.0, "val_loss": 17.311860620975494, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15927863121033, "training_acc": 53.0, "val_loss": 17.318691313266754, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12040257453918, "training_acc": 53.0, "val_loss": 17.33899861574173, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.23111772537231, "training_acc": 53.0, "val_loss": 17.355605959892273, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24546599388123, "training_acc": 53.0, "val_loss": 17.347557842731476, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19916701316833, "training_acc": 53.0, "val_loss": 17.343319952487946, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.22787547111511, "training_acc": 53.0, "val_loss": 17.33066588640213, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17122769355774, "training_acc": 53.0, "val_loss": 17.325852811336517, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14832496643066, "training_acc": 53.0, "val_loss": 17.323946952819824, "val_acc": 52.0}
