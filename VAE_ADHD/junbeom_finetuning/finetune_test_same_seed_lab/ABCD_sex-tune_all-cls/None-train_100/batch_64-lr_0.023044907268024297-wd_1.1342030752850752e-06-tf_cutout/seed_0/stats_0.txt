"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1642.813377380371, "training_acc": 50.0, "val_loss": 2.1501870656177245e+23, "val_acc": 56.0}
{"epoch": 1, "training_loss": 5.711395151567133e+23, "training_acc": 52.0, "val_loss": 1041570918400.0, "val_acc": 44.0}
{"epoch": 2, "training_loss": 3409362108416.0, "training_acc": 48.0, "val_loss": 248164172800.0, "val_acc": 56.0}
{"epoch": 3, "training_loss": 644019432960.0, "training_acc": 52.0, "val_loss": 805519600.0, "val_acc": 56.0}
{"epoch": 4, "training_loss": 6820080160.0, "training_acc": 50.0, "val_loss": 644071050.0, "val_acc": 56.0}
{"epoch": 5, "training_loss": 2028431288.0, "training_acc": 52.0, "val_loss": 170350775.0, "val_acc": 44.0}
{"epoch": 6, "training_loss": 14014482304.0, "training_acc": 50.0, "val_loss": 456000950.0, "val_acc": 56.0}
{"epoch": 7, "training_loss": 1351515737.5, "training_acc": 52.0, "val_loss": 72971881.25, "val_acc": 56.0}
{"epoch": 8, "training_loss": 4751874624.0, "training_acc": 52.0, "val_loss": 179689087.5, "val_acc": 44.0}
{"epoch": 9, "training_loss": 4291343200.0, "training_acc": 48.0, "val_loss": 2127353200.0, "val_acc": 44.0}
{"epoch": 10, "training_loss": 5531197180.0, "training_acc": 50.0, "val_loss": 1497126600.0, "val_acc": 44.0}
{"epoch": 11, "training_loss": 106412212224.0, "training_acc": 48.0, "val_loss": 19917593600.0, "val_acc": 56.0}
{"epoch": 12, "training_loss": 61687883008.0, "training_acc": 54.0, "val_loss": 1139796500.0, "val_acc": 44.0}
{"epoch": 13, "training_loss": 5060084384.0, "training_acc": 48.0, "val_loss": 671617950.0, "val_acc": 44.0}
{"epoch": 14, "training_loss": 2703320056.0, "training_acc": 52.0, "val_loss": 2261455800.0, "val_acc": 44.0}
{"epoch": 15, "training_loss": 5414393220.0, "training_acc": 54.0, "val_loss": 12337548000.0, "val_acc": 44.0}
{"epoch": 16, "training_loss": 29866056464.0, "training_acc": 48.0, "val_loss": 1862050200.0, "val_acc": 56.0}
{"epoch": 17, "training_loss": 7095328720.0, "training_acc": 52.0, "val_loss": 683250550.0, "val_acc": 44.0}
{"epoch": 18, "training_loss": 1914076692.0, "training_acc": 48.0, "val_loss": 72560318.75, "val_acc": 44.0}
{"epoch": 19, "training_loss": 396431560.0, "training_acc": 48.0, "val_loss": 5758843600.0, "val_acc": 56.0}
{"epoch": 20, "training_loss": 16916909636.0, "training_acc": 48.0, "val_loss": 14611574400.0, "val_acc": 56.0}
{"epoch": 21, "training_loss": 36183251808256.0, "training_acc": 52.0, "val_loss": 6.47973528666112e+16, "val_acc": 44.0}
{"epoch": 22, "training_loss": 1.6443736484923648e+17, "training_acc": 48.0, "val_loss": 1873383833600.0, "val_acc": 56.0}
{"epoch": 23, "training_loss": 203817225814016.0, "training_acc": 52.0, "val_loss": 79545997721600.0, "val_acc": 56.0}
{"epoch": 24, "training_loss": 2.304303570930893e+16, "training_acc": 52.0, "val_loss": 2576137951641600.0, "val_acc": 44.0}
{"epoch": 25, "training_loss": 5830261222670336.0, "training_acc": 48.0, "val_loss": 420772524851200.0, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1745047171104768.0, "training_acc": 38.0, "val_loss": 1046253718732800.0, "val_acc": 44.0}
{"epoch": 27, "training_loss": 2559057075634176.0, "training_acc": 48.0, "val_loss": 547146432512000.0, "val_acc": 56.0}
{"epoch": 28, "training_loss": 2315768159010816.0, "training_acc": 52.0, "val_loss": 26141055385600.0, "val_acc": 44.0}
{"epoch": 29, "training_loss": 795526740049920.0, "training_acc": 52.0, "val_loss": 30355764019200.0, "val_acc": 44.0}
{"epoch": 30, "training_loss": 92114572869632.0, "training_acc": 40.0, "val_loss": 8811678924800.0, "val_acc": 44.0}
{"epoch": 31, "training_loss": 169029182423040.0, "training_acc": 58.0, "val_loss": 23630351564800.0, "val_acc": 44.0}
{"epoch": 32, "training_loss": 122315959435264.0, "training_acc": 48.0, "val_loss": 112160394444800.0, "val_acc": 44.0}
{"epoch": 33, "training_loss": 395041341177856.0, "training_acc": 48.0, "val_loss": 4538262093824000.0, "val_acc": 44.0}
{"epoch": 34, "training_loss": 1.126064072032256e+16, "training_acc": 46.0, "val_loss": 3478516121600.0, "val_acc": 56.0}
{"epoch": 35, "training_loss": 12823529914368.0, "training_acc": 52.0, "val_loss": 1875893043200.0, "val_acc": 56.0}
{"epoch": 36, "training_loss": 6222608859136.0, "training_acc": 52.0, "val_loss": 8203467161600.0, "val_acc": 44.0}
{"epoch": 37, "training_loss": 19867393720320.0, "training_acc": 48.0, "val_loss": 14406919782400.0, "val_acc": 56.0}
