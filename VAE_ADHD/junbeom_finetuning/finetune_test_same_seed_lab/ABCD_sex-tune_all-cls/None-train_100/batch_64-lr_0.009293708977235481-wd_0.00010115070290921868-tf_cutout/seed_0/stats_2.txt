"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 657.545581817627, "training_acc": 48.0, "val_loss": 57193837363200.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 149858438693336.44, "training_acc": 47.0, "val_loss": 605311.474609375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1981656.36328125, "training_acc": 47.0, "val_loss": 12176710.9375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 33155369.87890625, "training_acc": 53.0, "val_loss": 4751342.96875, "val_acc": 48.0}
{"epoch": 4, "training_loss": 13008606.265625, "training_acc": 47.0, "val_loss": 21768.36700439453, "val_acc": 48.0}
{"epoch": 5, "training_loss": 117523.294921875, "training_acc": 49.0, "val_loss": 158196.81396484375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 434658.0078125, "training_acc": 51.0, "val_loss": 25065.203857421875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 94338.08129882812, "training_acc": 53.0, "val_loss": 28985.357666015625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 113047.71899414062, "training_acc": 45.0, "val_loss": 23801.56707763672, "val_acc": 48.0}
{"epoch": 9, "training_loss": 65507.437255859375, "training_acc": 47.0, "val_loss": 31947.65625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 110425.74731445312, "training_acc": 53.0, "val_loss": 31160.614013671875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 187737.3916015625, "training_acc": 53.0, "val_loss": 25826.57470703125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 76778.92199707031, "training_acc": 47.0, "val_loss": 1572.0321655273438, "val_acc": 48.0}
{"epoch": 13, "training_loss": 18431.150268554688, "training_acc": 49.0, "val_loss": 193.52397918701172, "val_acc": 48.0}
{"epoch": 14, "training_loss": 23556.661071777344, "training_acc": 47.0, "val_loss": 2678.3021926879883, "val_acc": 52.0}
{"epoch": 15, "training_loss": 11338.02114868164, "training_acc": 47.0, "val_loss": 3608.9488983154297, "val_acc": 48.0}
{"epoch": 16, "training_loss": 13382.275268554688, "training_acc": 47.0, "val_loss": 834.6420288085938, "val_acc": 48.0}
{"epoch": 17, "training_loss": 4928.254455566406, "training_acc": 49.0, "val_loss": 713.616132736206, "val_acc": 52.0}
{"epoch": 18, "training_loss": 105122.2646484375, "training_acc": 49.0, "val_loss": 3852.0828247070312, "val_acc": 52.0}
{"epoch": 19, "training_loss": 15777.269348144531, "training_acc": 53.0, "val_loss": 16311.799621582031, "val_acc": 52.0}
{"epoch": 20, "training_loss": 42725.168701171875, "training_acc": 53.0, "val_loss": 13656.175231933594, "val_acc": 48.0}
{"epoch": 21, "training_loss": 164707.4267578125, "training_acc": 49.0, "val_loss": 811.0479354858398, "val_acc": 40.0}
{"epoch": 22, "training_loss": 32424.224609375, "training_acc": 46.0, "val_loss": 19345.538330078125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 64567.245849609375, "training_acc": 55.0, "val_loss": 9119.976043701172, "val_acc": 52.0}
{"epoch": 24, "training_loss": 48834.472412109375, "training_acc": 51.0, "val_loss": 4796.807098388672, "val_acc": 52.0}
{"epoch": 25, "training_loss": 25152.289672851562, "training_acc": 45.0, "val_loss": 2611.135673522949, "val_acc": 52.0}
{"epoch": 26, "training_loss": 9077.075103759766, "training_acc": 53.0, "val_loss": 6111.12174987793, "val_acc": 52.0}
{"epoch": 27, "training_loss": 14350.54360961914, "training_acc": 53.0, "val_loss": 20388.136291503906, "val_acc": 48.0}
{"epoch": 28, "training_loss": 60251.89440917969, "training_acc": 47.0, "val_loss": 72430.30395507812, "val_acc": 52.0}
{"epoch": 29, "training_loss": 550080.45703125, "training_acc": 45.0, "val_loss": 34518.475341796875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 104320.32763671875, "training_acc": 59.0, "val_loss": 11302.713012695312, "val_acc": 52.0}
{"epoch": 31, "training_loss": 172239.8076171875, "training_acc": 55.0, "val_loss": 452373.2421875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1141967.0720214844, "training_acc": 51.0, "val_loss": 19505.53436279297, "val_acc": 48.0}
