"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 582.9475212097168, "training_acc": 47.0, "val_loss": 6103956769996800.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.5589204423825886e+16, "training_acc": 49.0, "val_loss": 782715.869140625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2235170.26953125, "training_acc": 53.0, "val_loss": 589760.009765625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1796740.7060546875, "training_acc": 47.0, "val_loss": 9717.770385742188, "val_acc": 48.0}
{"epoch": 4, "training_loss": 126361.7685546875, "training_acc": 45.0, "val_loss": 2076.097297668457, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1078928.130859375, "training_acc": 45.0, "val_loss": 35678.55529785156, "val_acc": 48.0}
{"epoch": 6, "training_loss": 704588.7421875, "training_acc": 41.0, "val_loss": 44722.00622558594, "val_acc": 52.0}
{"epoch": 7, "training_loss": 141030.04760742188, "training_acc": 53.0, "val_loss": 5034.189224243164, "val_acc": 52.0}
{"epoch": 8, "training_loss": 58562.1474609375, "training_acc": 43.0, "val_loss": 7363.518524169922, "val_acc": 52.0}
{"epoch": 9, "training_loss": 33102.774658203125, "training_acc": 47.0, "val_loss": 178.10148000717163, "val_acc": 52.0}
{"epoch": 10, "training_loss": 8414.172668457031, "training_acc": 46.0, "val_loss": 5778.545761108398, "val_acc": 52.0}
{"epoch": 11, "training_loss": 19957.02813720703, "training_acc": 51.0, "val_loss": 4244.633865356445, "val_acc": 52.0}
{"epoch": 12, "training_loss": 11028.51294708252, "training_acc": 51.0, "val_loss": 3182.642936706543, "val_acc": 52.0}
{"epoch": 13, "training_loss": 8171.1443247795105, "training_acc": 52.0, "val_loss": 10081.326293945312, "val_acc": 48.0}
{"epoch": 14, "training_loss": 28066.733825683594, "training_acc": 47.0, "val_loss": 32699.371337890625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 93339.7275390625, "training_acc": 53.0, "val_loss": 6312.847137451172, "val_acc": 48.0}
{"epoch": 16, "training_loss": 72614.97607421875, "training_acc": 57.0, "val_loss": 6745.630645751953, "val_acc": 48.0}
{"epoch": 17, "training_loss": 19722.969955444336, "training_acc": 47.0, "val_loss": 1768.140983581543, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6037.93049621582, "training_acc": 53.0, "val_loss": 2076.9073486328125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6067.03938293457, "training_acc": 47.0, "val_loss": 1452.2331237792969, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3629.87451171875, "training_acc": 53.0, "val_loss": 1844.930648803711, "val_acc": 48.0}
{"epoch": 21, "training_loss": 5525.463417053223, "training_acc": 47.0, "val_loss": 233.23988914489746, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2737.6574096679688, "training_acc": 47.0, "val_loss": 29430.484008789062, "val_acc": 48.0}
{"epoch": 23, "training_loss": 64804.84765625, "training_acc": 47.0, "val_loss": 2499.1254806518555, "val_acc": 52.0}
{"epoch": 24, "training_loss": 9378.141693115234, "training_acc": 53.0, "val_loss": 1594.45161819458, "val_acc": 52.0}
{"epoch": 25, "training_loss": 4310.5732421875, "training_acc": 49.0, "val_loss": 1303.4896850585938, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3683.244188308716, "training_acc": 45.0, "val_loss": 1332.8901290893555, "val_acc": 52.0}
{"epoch": 27, "training_loss": 5008.430435180664, "training_acc": 53.0, "val_loss": 526.4233112335205, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1605.1613311767578, "training_acc": 51.0, "val_loss": 389.9282217025757, "val_acc": 52.0}
