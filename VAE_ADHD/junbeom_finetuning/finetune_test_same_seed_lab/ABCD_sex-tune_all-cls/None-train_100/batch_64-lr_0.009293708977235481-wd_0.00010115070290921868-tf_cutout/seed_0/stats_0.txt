"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 512.8481750488281, "training_acc": 50.0, "val_loss": 9490400800.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 25426435780.882812, "training_acc": 52.0, "val_loss": 935261.81640625, "val_acc": 44.0}
{"epoch": 2, "training_loss": 2361593.6420898438, "training_acc": 46.0, "val_loss": 2312677.9296875, "val_acc": 44.0}
{"epoch": 3, "training_loss": 5741966.0869140625, "training_acc": 48.0, "val_loss": 2845.92227935791, "val_acc": 56.0}
{"epoch": 4, "training_loss": 16385.13916015625, "training_acc": 50.0, "val_loss": 3930.3070068359375, "val_acc": 56.0}
{"epoch": 5, "training_loss": 12179.970642089844, "training_acc": 56.0, "val_loss": 15625.836181640625, "val_acc": 56.0}
{"epoch": 6, "training_loss": 45292.502502441406, "training_acc": 52.0, "val_loss": 5994.2626953125, "val_acc": 44.0}
{"epoch": 7, "training_loss": 17823.902435302734, "training_acc": 48.0, "val_loss": 870.8474159240723, "val_acc": 44.0}
{"epoch": 8, "training_loss": 4124.15234375, "training_acc": 42.0, "val_loss": 2752.338981628418, "val_acc": 44.0}
{"epoch": 9, "training_loss": 337413.3330078125, "training_acc": 48.0, "val_loss": 76320.01953125, "val_acc": 56.0}
{"epoch": 10, "training_loss": 228294.27893066406, "training_acc": 52.0, "val_loss": 115826.50146484375, "val_acc": 44.0}
{"epoch": 11, "training_loss": 294711.95764160156, "training_acc": 48.0, "val_loss": 17545.10955810547, "val_acc": 56.0}
{"epoch": 12, "training_loss": 61300.50646972656, "training_acc": 52.0, "val_loss": 1928.228759765625, "val_acc": 56.0}
{"epoch": 13, "training_loss": 21194.238891601562, "training_acc": 48.0, "val_loss": 5056.655502319336, "val_acc": 44.0}
{"epoch": 14, "training_loss": 16083.600402832031, "training_acc": 52.0, "val_loss": 543.5147762298584, "val_acc": 44.0}
{"epoch": 15, "training_loss": 4817.959411621094, "training_acc": 54.0, "val_loss": 1447.835636138916, "val_acc": 56.0}
{"epoch": 16, "training_loss": 9550.251708984375, "training_acc": 52.0, "val_loss": 494.5240020751953, "val_acc": 44.0}
{"epoch": 17, "training_loss": 1308.2468004226685, "training_acc": 49.0, "val_loss": 76635.26611328125, "val_acc": 56.0}
{"epoch": 18, "training_loss": 354925.0009765625, "training_acc": 50.0, "val_loss": 43573.651123046875, "val_acc": 56.0}
{"epoch": 19, "training_loss": 117438.4215927124, "training_acc": 52.0, "val_loss": 1650.0251770019531, "val_acc": 44.0}
{"epoch": 20, "training_loss": 5181.297607421875, "training_acc": 48.0, "val_loss": 1044.5927619934082, "val_acc": 56.0}
{"epoch": 21, "training_loss": 8562.388427734375, "training_acc": 46.0, "val_loss": 4948.585891723633, "val_acc": 56.0}
{"epoch": 22, "training_loss": 15253.461456298828, "training_acc": 56.0, "val_loss": 4695.7244873046875, "val_acc": 44.0}
{"epoch": 23, "training_loss": 13824.745086669922, "training_acc": 46.0, "val_loss": 517.7339553833008, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1799.39888381958, "training_acc": 54.0, "val_loss": 494.98329162597656, "val_acc": 56.0}
{"epoch": 25, "training_loss": 1452.7981605529785, "training_acc": 52.0, "val_loss": 828.1557083129883, "val_acc": 44.0}
{"epoch": 26, "training_loss": 2525.0643634796143, "training_acc": 38.0, "val_loss": 1333.8323593139648, "val_acc": 44.0}
{"epoch": 27, "training_loss": 3637.7043495178223, "training_acc": 48.0, "val_loss": 3616.497802734375, "val_acc": 44.0}
{"epoch": 28, "training_loss": 10935.894104003906, "training_acc": 54.0, "val_loss": 327.39758491516113, "val_acc": 56.0}
{"epoch": 29, "training_loss": 1161.0589618682861, "training_acc": 52.0, "val_loss": 65.28626084327698, "val_acc": 56.0}
{"epoch": 30, "training_loss": 178.37191462516785, "training_acc": 51.0, "val_loss": 89.77072238922119, "val_acc": 44.0}
{"epoch": 31, "training_loss": 244.17342329025269, "training_acc": 48.0, "val_loss": 254.10499572753906, "val_acc": 56.0}
{"epoch": 32, "training_loss": 732.2666096687317, "training_acc": 52.0, "val_loss": 230.57303428649902, "val_acc": 56.0}
{"epoch": 33, "training_loss": 686.1671798229218, "training_acc": 48.0, "val_loss": 39.27455544471741, "val_acc": 44.0}
{"epoch": 34, "training_loss": 154.46613216400146, "training_acc": 46.0, "val_loss": 18.692855536937714, "val_acc": 56.0}
{"epoch": 35, "training_loss": 106.9949164390564, "training_acc": 50.0, "val_loss": 25.444746017456055, "val_acc": 44.0}
{"epoch": 36, "training_loss": 95.79922580718994, "training_acc": 52.0, "val_loss": 17.149680852890015, "val_acc": 56.0}
{"epoch": 37, "training_loss": 129.18365955352783, "training_acc": 41.0, "val_loss": 22.826510667800903, "val_acc": 56.0}
{"epoch": 38, "training_loss": 94.75010418891907, "training_acc": 52.0, "val_loss": 17.699117958545685, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.3397445678711, "training_acc": 48.0, "val_loss": 17.386402189731598, "val_acc": 56.0}
{"epoch": 40, "training_loss": 71.17887687683105, "training_acc": 49.0, "val_loss": 16.99969470500946, "val_acc": 56.0}
{"epoch": 41, "training_loss": 72.01086378097534, "training_acc": 49.0, "val_loss": 17.547187209129333, "val_acc": 56.0}
{"epoch": 42, "training_loss": 78.08340001106262, "training_acc": 43.0, "val_loss": 17.736294865608215, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.91437244415283, "training_acc": 49.0, "val_loss": 18.249651789665222, "val_acc": 56.0}
{"epoch": 44, "training_loss": 70.53437829017639, "training_acc": 50.0, "val_loss": 17.371733486652374, "val_acc": 56.0}
{"epoch": 45, "training_loss": 73.19666266441345, "training_acc": 52.0, "val_loss": 17.74407923221588, "val_acc": 56.0}
{"epoch": 46, "training_loss": 71.10731196403503, "training_acc": 48.0, "val_loss": 17.207065224647522, "val_acc": 56.0}
{"epoch": 47, "training_loss": 67.76258039474487, "training_acc": 56.0, "val_loss": 17.455115914344788, "val_acc": 56.0}
{"epoch": 48, "training_loss": 71.24513745307922, "training_acc": 53.0, "val_loss": 18.196098506450653, "val_acc": 56.0}
{"epoch": 49, "training_loss": 71.18594670295715, "training_acc": 48.0, "val_loss": 17.32909232378006, "val_acc": 56.0}
{"epoch": 50, "training_loss": 70.47524237632751, "training_acc": 46.0, "val_loss": 17.046168446540833, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.55221486091614, "training_acc": 52.0, "val_loss": 17.56299138069153, "val_acc": 56.0}
{"epoch": 52, "training_loss": 70.76771068572998, "training_acc": 47.0, "val_loss": 17.096230387687683, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.38383173942566, "training_acc": 52.0, "val_loss": 17.27263182401657, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.18473410606384, "training_acc": 53.0, "val_loss": 17.07652062177658, "val_acc": 56.0}
{"epoch": 55, "training_loss": 70.7005398273468, "training_acc": 55.0, "val_loss": 17.23847985267639, "val_acc": 56.0}
{"epoch": 56, "training_loss": 68.53860878944397, "training_acc": 54.0, "val_loss": 18.09414178133011, "val_acc": 56.0}
{"epoch": 57, "training_loss": 70.05535078048706, "training_acc": 48.0, "val_loss": 17.14935004711151, "val_acc": 56.0}
{"epoch": 58, "training_loss": 70.67300415039062, "training_acc": 52.0, "val_loss": 17.098037898540497, "val_acc": 56.0}
{"epoch": 59, "training_loss": 71.46505451202393, "training_acc": 46.0, "val_loss": 17.957046627998352, "val_acc": 56.0}
