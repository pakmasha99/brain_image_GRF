"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 92.15967035293579, "training_acc": 47.0, "val_loss": 60.76943278312683, "val_acc": 52.0}
{"epoch": 1, "training_loss": 205.30382633209229, "training_acc": 43.0, "val_loss": 17.382001876831055, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.16051363945007, "training_acc": 45.0, "val_loss": 17.43246018886566, "val_acc": 52.0}
{"epoch": 3, "training_loss": 75.2836844921112, "training_acc": 43.0, "val_loss": 17.30804145336151, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.44815850257874, "training_acc": 52.0, "val_loss": 17.430134117603302, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.6634521484375, "training_acc": 47.0, "val_loss": 17.300879955291748, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1139268875122, "training_acc": 53.0, "val_loss": 17.3269122838974, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.47379446029663, "training_acc": 53.0, "val_loss": 17.334651947021484, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16218733787537, "training_acc": 53.0, "val_loss": 17.382879555225372, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.49745893478394, "training_acc": 53.0, "val_loss": 17.37222820520401, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.513592004776, "training_acc": 53.0, "val_loss": 17.316588759422302, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13880372047424, "training_acc": 53.0, "val_loss": 17.313282191753387, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1314058303833, "training_acc": 53.0, "val_loss": 17.310336232185364, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1715099811554, "training_acc": 53.0, "val_loss": 17.3090398311615, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15511751174927, "training_acc": 53.0, "val_loss": 17.306654155254364, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16508340835571, "training_acc": 53.0, "val_loss": 17.306944727897644, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16346573829651, "training_acc": 53.0, "val_loss": 17.309947311878204, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.142737865448, "training_acc": 53.0, "val_loss": 17.312350869178772, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12564468383789, "training_acc": 53.0, "val_loss": 17.31850802898407, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15493035316467, "training_acc": 53.0, "val_loss": 17.3281192779541, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17080354690552, "training_acc": 53.0, "val_loss": 17.328250408172607, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1439139842987, "training_acc": 53.0, "val_loss": 17.319390177726746, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13285303115845, "training_acc": 53.0, "val_loss": 17.31356829404831, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16119074821472, "training_acc": 53.0, "val_loss": 17.311091721057892, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13287782669067, "training_acc": 53.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
