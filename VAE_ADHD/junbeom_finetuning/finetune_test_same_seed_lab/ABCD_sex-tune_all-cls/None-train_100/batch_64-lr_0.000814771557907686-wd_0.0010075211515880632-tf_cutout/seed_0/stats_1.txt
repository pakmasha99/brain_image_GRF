"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 83.81855392456055, "training_acc": 49.0, "val_loss": 39.710769057273865, "val_acc": 52.0}
{"epoch": 1, "training_loss": 144.29089879989624, "training_acc": 49.0, "val_loss": 17.326152324676514, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.30813550949097, "training_acc": 53.0, "val_loss": 17.486442625522614, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.69779920578003, "training_acc": 53.0, "val_loss": 17.31148511171341, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.80959916114807, "training_acc": 41.0, "val_loss": 17.335468530654907, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.98021578788757, "training_acc": 53.0, "val_loss": 17.424388229846954, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52899169921875, "training_acc": 53.0, "val_loss": 17.48330295085907, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.69852542877197, "training_acc": 53.0, "val_loss": 17.448794841766357, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.5619707107544, "training_acc": 53.0, "val_loss": 17.38172471523285, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.27655816078186, "training_acc": 53.0, "val_loss": 17.342597246170044, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.174161195755, "training_acc": 53.0, "val_loss": 17.31320172548294, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10913586616516, "training_acc": 53.0, "val_loss": 17.308706045150757, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21462655067444, "training_acc": 53.0, "val_loss": 17.3128604888916, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21943211555481, "training_acc": 53.0, "val_loss": 17.31346994638443, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18867611885071, "training_acc": 53.0, "val_loss": 17.30997860431671, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15606379508972, "training_acc": 53.0, "val_loss": 17.310932278633118, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2198793888092, "training_acc": 53.0, "val_loss": 17.31339395046234, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24193143844604, "training_acc": 53.0, "val_loss": 17.328152060508728, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23889207839966, "training_acc": 53.0, "val_loss": 17.331603169441223, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1510820388794, "training_acc": 53.0, "val_loss": 17.32156276702881, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16990065574646, "training_acc": 53.0, "val_loss": 17.314817011356354, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13249683380127, "training_acc": 53.0, "val_loss": 17.313160002231598, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14228010177612, "training_acc": 53.0, "val_loss": 17.311479151248932, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14129972457886, "training_acc": 53.0, "val_loss": 17.31111854314804, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15308880805969, "training_acc": 53.0, "val_loss": 17.31165647506714, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14245629310608, "training_acc": 53.0, "val_loss": 17.315463721752167, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14236068725586, "training_acc": 53.0, "val_loss": 17.31746643781662, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20643591880798, "training_acc": 53.0, "val_loss": 17.31586456298828, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12775254249573, "training_acc": 53.0, "val_loss": 17.320892214775085, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13674092292786, "training_acc": 53.0, "val_loss": 17.325778305530548, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15945482254028, "training_acc": 53.0, "val_loss": 17.331725358963013, "val_acc": 52.0}
