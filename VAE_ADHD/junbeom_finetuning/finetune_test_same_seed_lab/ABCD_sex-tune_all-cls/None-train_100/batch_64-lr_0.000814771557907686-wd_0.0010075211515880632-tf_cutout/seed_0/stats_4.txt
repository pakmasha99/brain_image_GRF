"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 92.80625438690186, "training_acc": 51.0, "val_loss": 21.018563210964203, "val_acc": 52.0}
{"epoch": 1, "training_loss": 184.1328649520874, "training_acc": 55.0, "val_loss": 18.294641375541687, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72.15562772750854, "training_acc": 47.0, "val_loss": 17.338407039642334, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18453621864319, "training_acc": 51.0, "val_loss": 17.461545765399933, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.80350375175476, "training_acc": 53.0, "val_loss": 17.449243366718292, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.56504154205322, "training_acc": 53.0, "val_loss": 17.31194257736206, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.40738677978516, "training_acc": 51.0, "val_loss": 17.340941727161407, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.65881299972534, "training_acc": 45.0, "val_loss": 17.311859130859375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15067267417908, "training_acc": 53.0, "val_loss": 17.30407625436783, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.38386297225952, "training_acc": 53.0, "val_loss": 17.303156852722168, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.10082960128784, "training_acc": 53.0, "val_loss": 17.349399626255035, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.51463413238525, "training_acc": 53.0, "val_loss": 17.333175241947174, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.62350010871887, "training_acc": 53.0, "val_loss": 17.30642318725586, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.25907158851624, "training_acc": 53.0, "val_loss": 17.3061341047287, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19716739654541, "training_acc": 53.0, "val_loss": 17.30795055627823, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2539598941803, "training_acc": 53.0, "val_loss": 17.304641008377075, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17960238456726, "training_acc": 53.0, "val_loss": 17.304596304893494, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24990034103394, "training_acc": 53.0, "val_loss": 17.305490374565125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1469373703003, "training_acc": 53.0, "val_loss": 17.305496335029602, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.38676619529724, "training_acc": 53.0, "val_loss": 17.313647270202637, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23298692703247, "training_acc": 53.0, "val_loss": 17.308536171913147, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13696908950806, "training_acc": 53.0, "val_loss": 17.310035228729248, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14550471305847, "training_acc": 53.0, "val_loss": 17.311279475688934, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15651082992554, "training_acc": 53.0, "val_loss": 17.314831912517548, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1302227973938, "training_acc": 53.0, "val_loss": 17.32420325279236, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14953637123108, "training_acc": 53.0, "val_loss": 17.33156144618988, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18731451034546, "training_acc": 53.0, "val_loss": 17.33732968568802, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17816519737244, "training_acc": 53.0, "val_loss": 17.329135537147522, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16734433174133, "training_acc": 53.0, "val_loss": 17.319197952747345, "val_acc": 52.0}
