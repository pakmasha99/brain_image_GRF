"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 389.2476997375488, "training_acc": 49.0, "val_loss": 5.90937753449591e+24, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.5564613583684498e+25, "training_acc": 53.0, "val_loss": 2.0073782029087828e+22, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4.590103832844161e+22, "training_acc": 53.0, "val_loss": 3.5224746155803935e+20, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1.1701016695594748e+21, "training_acc": 41.0, "val_loss": 1.35449041436672e+17, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3.8364608969939354e+17, "training_acc": 53.0, "val_loss": 7180061245440000.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2.3464794082246656e+16, "training_acc": 53.0, "val_loss": 3544667127808000.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1.2675431836680192e+16, "training_acc": 53.0, "val_loss": 122587984691200.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 343755599904768.0, "training_acc": 47.0, "val_loss": 90265917849600.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 214421506228224.0, "training_acc": 57.0, "val_loss": 2508416614400.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 38520569987072.0, "training_acc": 51.0, "val_loss": 13839628697600.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 80340316585984.0, "training_acc": 41.0, "val_loss": 13334543564800.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 38186921984000.0, "training_acc": 53.0, "val_loss": 91557920000.0, "val_acc": 52.0}
{"epoch": 12, "training_loss": 42557090463744.0, "training_acc": 47.0, "val_loss": 1445841305600.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 694342522765312.0, "training_acc": 49.0, "val_loss": 2001392230400.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 23699017433088.0, "training_acc": 51.0, "val_loss": 120564246118400.0, "val_acc": 52.0}
{"epoch": 15, "training_loss": 383803315322880.0, "training_acc": 37.0, "val_loss": 63381910323200.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 215053357285376.0, "training_acc": 43.0, "val_loss": 5660510208000.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 15861158379520.0, "training_acc": 53.0, "val_loss": 686124134400.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2035696619520.0, "training_acc": 53.0, "val_loss": 55831776000.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1404459646976.0, "training_acc": 47.0, "val_loss": 492179148800.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2090741293056.0, "training_acc": 47.0, "val_loss": 434680422400.0, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1361380550656.0, "training_acc": 47.0, "val_loss": 64718923366400.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 174611415564288.0, "training_acc": 51.0, "val_loss": 3722903142400.0, "val_acc": 52.0}
{"epoch": 23, "training_loss": 28024901599232.0, "training_acc": 53.0, "val_loss": 2458086195200.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11613139763200.0, "training_acc": 53.0, "val_loss": 6241028721868800.0, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1.6598556137750528e+16, "training_acc": 47.0, "val_loss": 773161746432000.0, "val_acc": 52.0}
{"epoch": 26, "training_loss": 6208038507642880.0, "training_acc": 53.0, "val_loss": 82785075200000.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 228020124778496.0, "training_acc": 53.0, "val_loss": 10044839526400.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 29007865249792.0, "training_acc": 53.0, "val_loss": 886779289600.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3349264973824.0, "training_acc": 53.0, "val_loss": 176076979200.0, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2534797803520.0, "training_acc": 43.0, "val_loss": 384157004800.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1530709880832.0, "training_acc": 47.0, "val_loss": 1871249203200.0, "val_acc": 52.0}
{"epoch": 32, "training_loss": 6155097817088.0, "training_acc": 53.0, "val_loss": 2005028044800.0, "val_acc": 52.0}
{"epoch": 33, "training_loss": 15728231841792.0, "training_acc": 51.0, "val_loss": 1405030707200.0, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4274068623360.0, "training_acc": 47.0, "val_loss": 5747669401600.0, "val_acc": 52.0}
{"epoch": 35, "training_loss": 17819304951808.0, "training_acc": 53.0, "val_loss": 335616793600.0, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3032745951232.0, "training_acc": 49.0, "val_loss": 125810150400.0, "val_acc": 48.0}
{"epoch": 37, "training_loss": 595887974400.0, "training_acc": 53.0, "val_loss": 104078355200.0, "val_acc": 48.0}
{"epoch": 38, "training_loss": 475946776576.0, "training_acc": 51.0, "val_loss": 15776483200.0, "val_acc": 52.0}
{"epoch": 39, "training_loss": 275354669056.0, "training_acc": 48.0, "val_loss": 1441347072000.0, "val_acc": 52.0}
{"epoch": 40, "training_loss": 12748843778048.0, "training_acc": 53.0, "val_loss": 12754622054400.0, "val_acc": 48.0}
{"epoch": 41, "training_loss": 39438168260608.0, "training_acc": 47.0, "val_loss": 3787814092800.0, "val_acc": 52.0}
{"epoch": 42, "training_loss": 22825312714752.0, "training_acc": 45.0, "val_loss": 2109556121600.0, "val_acc": 52.0}
{"epoch": 43, "training_loss": 5418543587328.0, "training_acc": 53.0, "val_loss": 1626047385600.0, "val_acc": 48.0}
{"epoch": 44, "training_loss": 4577300332544.0, "training_acc": 51.0, "val_loss": 11403260723200.0, "val_acc": 48.0}
{"epoch": 45, "training_loss": 430041531940864.0, "training_acc": 57.0, "val_loss": 1638333644800.0, "val_acc": 48.0}
{"epoch": 46, "training_loss": 11809601683456.0, "training_acc": 47.0, "val_loss": 2771516825600.0, "val_acc": 48.0}
{"epoch": 47, "training_loss": 15038754783232.0, "training_acc": 55.0, "val_loss": 3573489664000.0, "val_acc": 48.0}
{"epoch": 48, "training_loss": 18062252048384.0, "training_acc": 47.0, "val_loss": 1088397516800.0, "val_acc": 48.0}
{"epoch": 49, "training_loss": 3602922119168.0, "training_acc": 47.0, "val_loss": 160541926400.0, "val_acc": 48.0}
{"epoch": 50, "training_loss": 459473123840.0, "training_acc": 47.0, "val_loss": 106617459200.0, "val_acc": 52.0}
{"epoch": 51, "training_loss": 7920337453056.0, "training_acc": 51.0, "val_loss": 54710464000.0, "val_acc": 52.0}
{"epoch": 52, "training_loss": 609736265728.0, "training_acc": 53.0, "val_loss": 97360928000.0, "val_acc": 48.0}
{"epoch": 53, "training_loss": 2579675742208.0, "training_acc": 47.0, "val_loss": 1224172032000.0, "val_acc": 52.0}
{"epoch": 54, "training_loss": 3327203766272.0, "training_acc": 53.0, "val_loss": 338466227200.0, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1391434788864.0, "training_acc": 55.0, "val_loss": 132057971200.0, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1019786084352.0, "training_acc": 55.0, "val_loss": 392403481600.0, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1858839937024.0, "training_acc": 39.0, "val_loss": 281186227200.0, "val_acc": 52.0}
