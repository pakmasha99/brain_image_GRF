"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.19589924812317, "training_acc": 47.0, "val_loss": 17.463813722133636, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.57037091255188, "training_acc": 47.0, "val_loss": 17.32185333967209, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.10669255256653, "training_acc": 53.0, "val_loss": 17.335258424282074, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22817158699036, "training_acc": 53.0, "val_loss": 17.34444946050644, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.62804508209229, "training_acc": 53.0, "val_loss": 17.34115183353424, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.05484819412231, "training_acc": 53.0, "val_loss": 17.317016422748566, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.42310452461243, "training_acc": 46.0, "val_loss": 17.30620563030243, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.53852796554565, "training_acc": 53.0, "val_loss": 17.311424016952515, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16843008995056, "training_acc": 53.0, "val_loss": 17.309436202049255, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.26237058639526, "training_acc": 53.0, "val_loss": 17.32109785079956, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07467269897461, "training_acc": 53.0, "val_loss": 17.365463078022003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21743035316467, "training_acc": 53.0, "val_loss": 17.38755702972412, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.26133346557617, "training_acc": 53.0, "val_loss": 17.37884134054184, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19962739944458, "training_acc": 53.0, "val_loss": 17.331695556640625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17316746711731, "training_acc": 53.0, "val_loss": 17.318227887153625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13431429862976, "training_acc": 53.0, "val_loss": 17.31904149055481, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16491723060608, "training_acc": 53.0, "val_loss": 17.324310541152954, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17311978340149, "training_acc": 53.0, "val_loss": 17.341487109661102, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17895579338074, "training_acc": 53.0, "val_loss": 17.38235503435135, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.32091045379639, "training_acc": 53.0, "val_loss": 17.374134063720703, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.27305936813354, "training_acc": 53.0, "val_loss": 17.36031174659729, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.2571063041687, "training_acc": 53.0, "val_loss": 17.321763932704926, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.203115940094, "training_acc": 53.0, "val_loss": 17.324553430080414, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22838687896729, "training_acc": 53.0, "val_loss": 17.32794940471649, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.55698823928833, "training_acc": 39.0, "val_loss": 17.318521440029144, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17806005477905, "training_acc": 53.0, "val_loss": 17.32889860868454, "val_acc": 52.0}
