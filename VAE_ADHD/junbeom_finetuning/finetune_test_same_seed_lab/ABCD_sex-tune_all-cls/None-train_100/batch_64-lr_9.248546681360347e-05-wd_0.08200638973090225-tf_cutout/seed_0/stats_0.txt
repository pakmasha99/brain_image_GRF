"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.1018328666687, "training_acc": 52.0, "val_loss": 17.210033535957336, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.3200421333313, "training_acc": 52.0, "val_loss": 17.267335951328278, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.30425763130188, "training_acc": 52.0, "val_loss": 17.31245517730713, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.35093665122986, "training_acc": 52.0, "val_loss": 17.320622503757477, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.28441333770752, "training_acc": 54.0, "val_loss": 17.275390028953552, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.47948384284973, "training_acc": 52.0, "val_loss": 17.256000638008118, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25274705886841, "training_acc": 52.0, "val_loss": 17.306581139564514, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2543454170227, "training_acc": 52.0, "val_loss": 17.250782251358032, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.60175633430481, "training_acc": 52.0, "val_loss": 17.214305698871613, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.19322156906128, "training_acc": 52.0, "val_loss": 17.30201244354248, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2579071521759, "training_acc": 53.0, "val_loss": 17.312288284301758, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.29823160171509, "training_acc": 52.0, "val_loss": 17.247745394706726, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.280357837677, "training_acc": 52.0, "val_loss": 17.237968742847443, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.24951791763306, "training_acc": 52.0, "val_loss": 17.26846992969513, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.21270656585693, "training_acc": 52.0, "val_loss": 17.228980362415314, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.20640683174133, "training_acc": 52.0, "val_loss": 17.198476195335388, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2626805305481, "training_acc": 52.0, "val_loss": 17.18266010284424, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.31676506996155, "training_acc": 52.0, "val_loss": 17.230243980884552, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.21055912971497, "training_acc": 52.0, "val_loss": 17.281682789325714, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21475553512573, "training_acc": 52.0, "val_loss": 17.282651364803314, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2627112865448, "training_acc": 52.0, "val_loss": 17.27289706468582, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21647238731384, "training_acc": 52.0, "val_loss": 17.218822240829468, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.47235202789307, "training_acc": 52.0, "val_loss": 17.181788384914398, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25255513191223, "training_acc": 52.0, "val_loss": 17.23213940858841, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.14015126228333, "training_acc": 52.0, "val_loss": 17.339010536670685, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.35990953445435, "training_acc": 53.0, "val_loss": 17.378154397010803, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.85702204704285, "training_acc": 38.0, "val_loss": 17.28094071149826, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.20768022537231, "training_acc": 52.0, "val_loss": 17.326730489730835, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33381223678589, "training_acc": 46.0, "val_loss": 17.31451153755188, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.19941091537476, "training_acc": 52.0, "val_loss": 17.22094714641571, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.64370894432068, "training_acc": 52.0, "val_loss": 17.18025952577591, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.59984850883484, "training_acc": 52.0, "val_loss": 17.227938771247864, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.22860836982727, "training_acc": 52.0, "val_loss": 17.22191423177719, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.22864007949829, "training_acc": 52.0, "val_loss": 17.23790317773819, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.23488092422485, "training_acc": 52.0, "val_loss": 17.23780781030655, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.20965552330017, "training_acc": 52.0, "val_loss": 17.268207669258118, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23158097267151, "training_acc": 52.0, "val_loss": 17.274366319179535, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.33030819892883, "training_acc": 52.0, "val_loss": 17.239519953727722, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.13530826568604, "training_acc": 52.0, "val_loss": 17.182809114456177, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.53751826286316, "training_acc": 52.0, "val_loss": 17.161689698696136, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.41944932937622, "training_acc": 52.0, "val_loss": 17.178067564964294, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28126955032349, "training_acc": 52.0, "val_loss": 17.236129939556122, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.17785263061523, "training_acc": 52.0, "val_loss": 17.303702235221863, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.26556134223938, "training_acc": 52.0, "val_loss": 17.372436821460724, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.41541981697083, "training_acc": 48.0, "val_loss": 17.443393170833588, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.45801091194153, "training_acc": 48.0, "val_loss": 17.361389100551605, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.2982850074768, "training_acc": 49.0, "val_loss": 17.28701740503311, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.17765474319458, "training_acc": 52.0, "val_loss": 17.235660552978516, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22791337966919, "training_acc": 52.0, "val_loss": 17.19149947166443, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.32584309577942, "training_acc": 52.0, "val_loss": 17.197220027446747, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.19867277145386, "training_acc": 52.0, "val_loss": 17.256270349025726, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.18190240859985, "training_acc": 52.0, "val_loss": 17.33674257993698, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.2780294418335, "training_acc": 55.0, "val_loss": 17.36597716808319, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.28765797615051, "training_acc": 53.0, "val_loss": 17.35154688358307, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.23829936981201, "training_acc": 64.0, "val_loss": 17.291688919067383, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.35765290260315, "training_acc": 52.0, "val_loss": 17.22063273191452, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.21269130706787, "training_acc": 52.0, "val_loss": 17.226527631282806, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2053587436676, "training_acc": 52.0, "val_loss": 17.2636941075325, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.1452419757843, "training_acc": 52.0, "val_loss": 17.272914946079254, "val_acc": 56.0}
