"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 301.3758487701416, "training_acc": 43.0, "val_loss": 11826.417541503906, "val_acc": 48.0}
{"epoch": 1, "training_loss": 27760.142973423004, "training_acc": 55.0, "val_loss": 19.96070295572281, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1622.2644309997559, "training_acc": 47.0, "val_loss": 20.172643661499023, "val_acc": 52.0}
{"epoch": 3, "training_loss": 97.10912990570068, "training_acc": 53.0, "val_loss": 21.34171575307846, "val_acc": 52.0}
{"epoch": 4, "training_loss": 79.62274241447449, "training_acc": 53.0, "val_loss": 17.33708083629608, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.59165573120117, "training_acc": 53.0, "val_loss": 17.31516569852829, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18124341964722, "training_acc": 53.0, "val_loss": 18.021485209465027, "val_acc": 52.0}
{"epoch": 7, "training_loss": 71.89084720611572, "training_acc": 47.0, "val_loss": 17.34199821949005, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.33431339263916, "training_acc": 49.0, "val_loss": 17.39700585603714, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29835200309753, "training_acc": 53.0, "val_loss": 17.32291728258133, "val_acc": 52.0}
{"epoch": 10, "training_loss": 73.08694076538086, "training_acc": 37.0, "val_loss": 17.336715757846832, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.40076470375061, "training_acc": 43.0, "val_loss": 17.373138666152954, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.31620836257935, "training_acc": 53.0, "val_loss": 17.308762669563293, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.10007572174072, "training_acc": 53.0, "val_loss": 17.31771230697632, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.29505610466003, "training_acc": 53.0, "val_loss": 17.309264838695526, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.337899684906, "training_acc": 53.0, "val_loss": 17.339058220386505, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21327304840088, "training_acc": 53.0, "val_loss": 17.310374975204468, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15188932418823, "training_acc": 53.0, "val_loss": 17.310872673988342, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19228434562683, "training_acc": 53.0, "val_loss": 17.320053279399872, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.22659635543823, "training_acc": 53.0, "val_loss": 17.354188859462738, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19340968132019, "training_acc": 53.0, "val_loss": 17.32524037361145, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.50337314605713, "training_acc": 53.0, "val_loss": 17.30811297893524, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14683890342712, "training_acc": 53.0, "val_loss": 17.308834195137024, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13764262199402, "training_acc": 53.0, "val_loss": 17.3123762011528, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15761876106262, "training_acc": 53.0, "val_loss": 17.321929335594177, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20827794075012, "training_acc": 53.0, "val_loss": 17.32487380504608, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22513961791992, "training_acc": 53.0, "val_loss": 17.316676676273346, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10859370231628, "training_acc": 53.0, "val_loss": 17.308548092842102, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1489851474762, "training_acc": 53.0, "val_loss": 17.309074103832245, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17513632774353, "training_acc": 53.0, "val_loss": 17.310526967048645, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18842029571533, "training_acc": 53.0, "val_loss": 17.310722172260284, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18775868415833, "training_acc": 53.0, "val_loss": 17.309749126434326, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17202591896057, "training_acc": 53.0, "val_loss": 17.3084557056427, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14993000030518, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12172889709473, "training_acc": 53.0, "val_loss": 17.315424978733063, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.31822633743286, "training_acc": 53.0, "val_loss": 17.325036227703094, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13481640815735, "training_acc": 53.0, "val_loss": 17.317353188991547, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18722462654114, "training_acc": 53.0, "val_loss": 17.311805486679077, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15560173988342, "training_acc": 53.0, "val_loss": 17.311392724514008, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1437759399414, "training_acc": 53.0, "val_loss": 17.30976402759552, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17080330848694, "training_acc": 53.0, "val_loss": 17.309333384037018, "val_acc": 52.0}
