"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 201.4686164855957, "training_acc": 50.0, "val_loss": 12262.616729736328, "val_acc": 56.0}
{"epoch": 1, "training_loss": 37046.105529785156, "training_acc": 52.0, "val_loss": 132.3641300201416, "val_acc": 44.0}
{"epoch": 2, "training_loss": 361.02765011787415, "training_acc": 48.0, "val_loss": 17.55886971950531, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.4756851196289, "training_acc": 46.0, "val_loss": 17.165595293045044, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.62968611717224, "training_acc": 52.0, "val_loss": 17.41582453250885, "val_acc": 56.0}
{"epoch": 5, "training_loss": 72.5450508594513, "training_acc": 44.0, "val_loss": 17.319156229496002, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.80136799812317, "training_acc": 50.0, "val_loss": 17.622219026088715, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.54114174842834, "training_acc": 48.0, "val_loss": 17.165905237197876, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.40011954307556, "training_acc": 52.0, "val_loss": 17.15504080057144, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.3102297782898, "training_acc": 52.0, "val_loss": 17.304927110671997, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.3543541431427, "training_acc": 50.0, "val_loss": 17.40206480026245, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.43419361114502, "training_acc": 48.0, "val_loss": 17.31012761592865, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.3511233329773, "training_acc": 52.0, "val_loss": 17.244403064250946, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.24468684196472, "training_acc": 52.0, "val_loss": 17.22843497991562, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.22595047950745, "training_acc": 52.0, "val_loss": 17.20084398984909, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2581479549408, "training_acc": 52.0, "val_loss": 17.18260794878006, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.30070996284485, "training_acc": 52.0, "val_loss": 17.171093821525574, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.3031075000763, "training_acc": 52.0, "val_loss": 17.202535271644592, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25162100791931, "training_acc": 52.0, "val_loss": 17.24826842546463, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.23993062973022, "training_acc": 52.0, "val_loss": 17.267602682113647, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.29142022132874, "training_acc": 52.0, "val_loss": 17.269054055213928, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24781703948975, "training_acc": 52.0, "val_loss": 17.2250896692276, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.36990809440613, "training_acc": 52.0, "val_loss": 17.1909898519516, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25503373146057, "training_acc": 52.0, "val_loss": 17.20964163541794, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21358513832092, "training_acc": 52.0, "val_loss": 17.25420653820038, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.30013394355774, "training_acc": 52.0, "val_loss": 17.30562597513199, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.475501537323, "training_acc": 52.0, "val_loss": 17.27995276451111, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.25979924201965, "training_acc": 52.0, "val_loss": 17.30469912290573, "val_acc": 56.0}
