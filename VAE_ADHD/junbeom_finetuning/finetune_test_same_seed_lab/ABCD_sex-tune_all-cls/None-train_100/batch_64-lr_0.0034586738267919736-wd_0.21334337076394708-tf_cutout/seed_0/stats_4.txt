"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.68905305862427, "training_acc": 55.0, "val_loss": 87582.8857421875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 237081.9601817131, "training_acc": 53.0, "val_loss": 626.5193939208984, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1776.842282295227, "training_acc": 47.0, "val_loss": 18.24166476726532, "val_acc": 52.0}
{"epoch": 3, "training_loss": 125.63651847839355, "training_acc": 47.0, "val_loss": 17.326998710632324, "val_acc": 52.0}
{"epoch": 4, "training_loss": 76.68112206459045, "training_acc": 51.0, "val_loss": 19.104743003845215, "val_acc": 48.0}
{"epoch": 5, "training_loss": 74.10626173019409, "training_acc": 49.0, "val_loss": 18.048173189163208, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.08922743797302, "training_acc": 53.0, "val_loss": 17.39063411951065, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.35455632209778, "training_acc": 51.0, "val_loss": 17.80121922492981, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.43499302864075, "training_acc": 53.0, "val_loss": 17.321287095546722, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.73595905303955, "training_acc": 53.0, "val_loss": 17.317621409893036, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.60596632957458, "training_acc": 49.0, "val_loss": 17.31623411178589, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.08260703086853, "training_acc": 53.0, "val_loss": 17.448188364505768, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.448734998703, "training_acc": 53.0, "val_loss": 17.312107980251312, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.23885440826416, "training_acc": 43.0, "val_loss": 17.311684787273407, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.05444502830505, "training_acc": 53.0, "val_loss": 17.4843892455101, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.4763286113739, "training_acc": 53.0, "val_loss": 17.330382764339447, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.01387143135071, "training_acc": 53.0, "val_loss": 17.340342700481415, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.4425437450409, "training_acc": 43.0, "val_loss": 17.36822873353958, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.58852481842041, "training_acc": 47.0, "val_loss": 17.34524518251419, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.28562784194946, "training_acc": 51.0, "val_loss": 17.313987016677856, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.0872414112091, "training_acc": 53.0, "val_loss": 17.35393851995468, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1832766532898, "training_acc": 53.0, "val_loss": 17.311425507068634, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22793197631836, "training_acc": 53.0, "val_loss": 17.309291660785675, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19226431846619, "training_acc": 53.0, "val_loss": 17.30848401784897, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.33202385902405, "training_acc": 53.0, "val_loss": 17.309068143367767, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14611530303955, "training_acc": 53.0, "val_loss": 17.309901118278503, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21999716758728, "training_acc": 53.0, "val_loss": 17.32534021139145, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18944215774536, "training_acc": 53.0, "val_loss": 17.323298752307892, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13422083854675, "training_acc": 53.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19287824630737, "training_acc": 53.0, "val_loss": 17.30940341949463, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.3378918170929, "training_acc": 53.0, "val_loss": 17.311355471611023, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1884343624115, "training_acc": 53.0, "val_loss": 17.326408624649048, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.58064365386963, "training_acc": 41.0, "val_loss": 17.323985695838928, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.39666414260864, "training_acc": 53.0, "val_loss": 17.308636009693146, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14291858673096, "training_acc": 53.0, "val_loss": 17.30918288230896, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18012118339539, "training_acc": 53.0, "val_loss": 17.310374975204468, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14935374259949, "training_acc": 53.0, "val_loss": 17.310237884521484, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13629841804504, "training_acc": 53.0, "val_loss": 17.311348021030426, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13282871246338, "training_acc": 53.0, "val_loss": 17.31339544057846, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18508219718933, "training_acc": 53.0, "val_loss": 17.315395176410675, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13577175140381, "training_acc": 53.0, "val_loss": 17.31330007314682, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16997647285461, "training_acc": 53.0, "val_loss": 17.31072962284088, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13390469551086, "training_acc": 53.0, "val_loss": 17.310796678066254, "val_acc": 52.0}
