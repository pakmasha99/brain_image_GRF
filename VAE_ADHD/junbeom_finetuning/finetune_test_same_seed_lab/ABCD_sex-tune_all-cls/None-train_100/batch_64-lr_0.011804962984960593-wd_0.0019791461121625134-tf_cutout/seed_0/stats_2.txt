"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 674.7454223632812, "training_acc": 49.0, "val_loss": 738556641280000.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1576618690122040.0, "training_acc": 59.0, "val_loss": 10010543200.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 33029841344.0, "training_acc": 47.0, "val_loss": 8643887.5, "val_acc": 52.0}
{"epoch": 3, "training_loss": 83742580.5, "training_acc": 51.0, "val_loss": 54895756.25, "val_acc": 52.0}
{"epoch": 4, "training_loss": 308516578.0, "training_acc": 53.0, "val_loss": 3575908.984375, "val_acc": 48.0}
{"epoch": 5, "training_loss": 19014940.625, "training_acc": 47.0, "val_loss": 5126663.28125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 18091700.125, "training_acc": 53.0, "val_loss": 18060254400.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 43096025941.0, "training_acc": 53.0, "val_loss": 6845975200.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 19774728224.0, "training_acc": 51.0, "val_loss": 1740429200.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 5872286752.0, "training_acc": 47.0, "val_loss": 82435925.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 265087525.5, "training_acc": 47.0, "val_loss": 5183809.375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 66558903.5, "training_acc": 57.0, "val_loss": 41602462.5, "val_acc": 52.0}
{"epoch": 12, "training_loss": 92293655.890625, "training_acc": 57.0, "val_loss": 7722250.78125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 19894736.2890625, "training_acc": 51.0, "val_loss": 4120761.328125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 795659528.0, "training_acc": 49.0, "val_loss": 6019941.015625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 31940782.0, "training_acc": 53.0, "val_loss": 1831422.8515625, "val_acc": 52.0}
{"epoch": 16, "training_loss": 10357547.9375, "training_acc": 57.0, "val_loss": 485652.685546875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 4120346.125, "training_acc": 45.0, "val_loss": 56727.691650390625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6850748.125, "training_acc": 48.0, "val_loss": 482652.099609375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4411021.3125, "training_acc": 59.0, "val_loss": 3609416.015625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 12640648.625, "training_acc": 53.0, "val_loss": 359889.501953125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3679135.59375, "training_acc": 51.0, "val_loss": 158815.53955078125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 13652284.09375, "training_acc": 47.0, "val_loss": 225200.9765625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 634857.2060546875, "training_acc": 47.0, "val_loss": 324710.3271484375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 9581680.75, "training_acc": 47.0, "val_loss": 1319919.62890625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 4103875.78125, "training_acc": 51.0, "val_loss": 553111.9140625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3477517.828125, "training_acc": 55.0, "val_loss": 633802.9296875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 14179675.5, "training_acc": 53.0, "val_loss": 1230200.68359375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 14892145.875, "training_acc": 53.0, "val_loss": 648452800.0, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1573409415.5, "training_acc": 47.0, "val_loss": 136841787.5, "val_acc": 52.0}
{"epoch": 30, "training_loss": 470376063.0, "training_acc": 53.0, "val_loss": 108606912.5, "val_acc": 48.0}
{"epoch": 31, "training_loss": 349446423.0, "training_acc": 49.0, "val_loss": 418250800.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 953106932.5, "training_acc": 57.0, "val_loss": 13837067.1875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 46755973.125, "training_acc": 51.0, "val_loss": 24002195.3125, "val_acc": 48.0}
{"epoch": 34, "training_loss": 96773341.0, "training_acc": 53.0, "val_loss": 3316534.375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 113151253.5, "training_acc": 52.0, "val_loss": 27017034.375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 109498818.5, "training_acc": 53.0, "val_loss": 16153695.3125, "val_acc": 52.0}
