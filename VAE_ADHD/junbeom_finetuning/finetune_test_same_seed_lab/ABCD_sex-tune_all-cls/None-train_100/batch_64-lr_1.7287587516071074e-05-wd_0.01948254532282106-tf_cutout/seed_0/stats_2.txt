"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.12379884719849, "training_acc": 54.0, "val_loss": 17.337022721767426, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.19634366035461, "training_acc": 54.0, "val_loss": 17.371506989002228, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.33208346366882, "training_acc": 53.0, "val_loss": 17.386551201343536, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.53123116493225, "training_acc": 53.0, "val_loss": 17.424938082695007, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25143480300903, "training_acc": 53.0, "val_loss": 17.348891496658325, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20050501823425, "training_acc": 53.0, "val_loss": 17.32643097639084, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.56749510765076, "training_acc": 41.0, "val_loss": 17.342716455459595, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28390049934387, "training_acc": 47.0, "val_loss": 17.32252538204193, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12344741821289, "training_acc": 53.0, "val_loss": 17.324532568454742, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.03988647460938, "training_acc": 53.0, "val_loss": 17.34767109155655, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18482160568237, "training_acc": 53.0, "val_loss": 17.38380193710327, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24850797653198, "training_acc": 53.0, "val_loss": 17.38460063934326, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17177224159241, "training_acc": 53.0, "val_loss": 17.34783500432968, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.0657229423523, "training_acc": 53.0, "val_loss": 17.32614040374756, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.29210233688354, "training_acc": 53.0, "val_loss": 17.331688106060028, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1724750995636, "training_acc": 53.0, "val_loss": 17.33044534921646, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17996335029602, "training_acc": 53.0, "val_loss": 17.328844964504242, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13866877555847, "training_acc": 53.0, "val_loss": 17.328381538391113, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.07093095779419, "training_acc": 53.0, "val_loss": 17.328138649463654, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.06877517700195, "training_acc": 53.0, "val_loss": 17.33165681362152, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05195546150208, "training_acc": 53.0, "val_loss": 17.341533303260803, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.98930096626282, "training_acc": 53.0, "val_loss": 17.373026907444, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26712036132812, "training_acc": 53.0, "val_loss": 17.39921122789383, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26612901687622, "training_acc": 53.0, "val_loss": 17.36958622932434, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.04742193222046, "training_acc": 53.0, "val_loss": 17.35754758119583, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.98534035682678, "training_acc": 53.0, "val_loss": 17.342738807201385, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.96971154212952, "training_acc": 53.0, "val_loss": 17.33318269252777, "val_acc": 52.0}
