"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.12245988845825, "training_acc": 55.0, "val_loss": 17.33577698469162, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18605399131775, "training_acc": 53.0, "val_loss": 17.382441461086273, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.39510822296143, "training_acc": 53.0, "val_loss": 17.387908697128296, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.53507256507874, "training_acc": 53.0, "val_loss": 17.419756948947906, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22434067726135, "training_acc": 53.0, "val_loss": 17.341606318950653, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20436406135559, "training_acc": 53.0, "val_loss": 17.332270741462708, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.62475538253784, "training_acc": 41.0, "val_loss": 17.35033541917801, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.31700253486633, "training_acc": 46.0, "val_loss": 17.322802543640137, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10276532173157, "training_acc": 53.0, "val_loss": 17.330214381217957, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.03545427322388, "training_acc": 53.0, "val_loss": 17.36326366662979, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.22310423851013, "training_acc": 53.0, "val_loss": 17.400653660297394, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.28177213668823, "training_acc": 53.0, "val_loss": 17.391951382160187, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16777038574219, "training_acc": 53.0, "val_loss": 17.346486449241638, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04783201217651, "training_acc": 53.0, "val_loss": 17.325732111930847, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.3212640285492, "training_acc": 53.0, "val_loss": 17.33476370573044, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20865988731384, "training_acc": 53.0, "val_loss": 17.330482602119446, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20517826080322, "training_acc": 53.0, "val_loss": 17.326746881008148, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14438152313232, "training_acc": 53.0, "val_loss": 17.325763404369354, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.07200932502747, "training_acc": 53.0, "val_loss": 17.326167225837708, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.0578339099884, "training_acc": 53.0, "val_loss": 17.331266403198242, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05512523651123, "training_acc": 53.0, "val_loss": 17.343206703662872, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.00366377830505, "training_acc": 53.0, "val_loss": 17.37746000289917, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28023838996887, "training_acc": 53.0, "val_loss": 17.40194261074066, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27987027168274, "training_acc": 53.0, "val_loss": 17.36786961555481, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.03366899490356, "training_acc": 53.0, "val_loss": 17.355214059352875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.98702931404114, "training_acc": 53.0, "val_loss": 17.342662811279297, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.96644997596741, "training_acc": 53.0, "val_loss": 17.334850132465363, "val_acc": 52.0}
