"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.22929382324219, "training_acc": 47.0, "val_loss": 17.438751459121704, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.15589499473572, "training_acc": 43.0, "val_loss": 17.313918471336365, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16965174674988, "training_acc": 53.0, "val_loss": 17.33347475528717, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3693323135376, "training_acc": 53.0, "val_loss": 17.3772394657135, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33910465240479, "training_acc": 53.0, "val_loss": 17.326949536800385, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13459753990173, "training_acc": 53.0, "val_loss": 17.30910986661911, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.33230710029602, "training_acc": 53.0, "val_loss": 17.31850951910019, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.27314376831055, "training_acc": 53.0, "val_loss": 17.31763780117035, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11739373207092, "training_acc": 53.0, "val_loss": 17.314837872982025, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.03159809112549, "training_acc": 53.0, "val_loss": 17.347025871276855, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28887033462524, "training_acc": 53.0, "val_loss": 17.394836246967316, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27329683303833, "training_acc": 53.0, "val_loss": 17.37668067216873, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25763392448425, "training_acc": 53.0, "val_loss": 17.338256537914276, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24716091156006, "training_acc": 53.0, "val_loss": 17.31804609298706, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.07510209083557, "training_acc": 53.0, "val_loss": 17.315717041492462, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12289810180664, "training_acc": 53.0, "val_loss": 17.31475442647934, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.07988715171814, "training_acc": 53.0, "val_loss": 17.315146327018738, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.0751564502716, "training_acc": 53.0, "val_loss": 17.315417528152466, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13988065719604, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.03903865814209, "training_acc": 53.0, "val_loss": 17.321202158927917, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1760823726654, "training_acc": 53.0, "val_loss": 17.337222397327423, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22235107421875, "training_acc": 53.0, "val_loss": 17.334003746509552, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20797729492188, "training_acc": 53.0, "val_loss": 17.342111468315125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.09153294563293, "training_acc": 53.0, "val_loss": 17.32000708580017, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01440238952637, "training_acc": 53.0, "val_loss": 17.311838269233704, "val_acc": 52.0}
