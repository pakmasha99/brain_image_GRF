"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 133.728985786438, "training_acc": 51.0, "val_loss": 55.452245473861694, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1089.977294921875, "training_acc": 53.0, "val_loss": 18.585236370563507, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.24511384963989, "training_acc": 53.0, "val_loss": 18.7323197722435, "val_acc": 48.0}
{"epoch": 3, "training_loss": 73.15105390548706, "training_acc": 49.0, "val_loss": 18.39994341135025, "val_acc": 52.0}
{"epoch": 4, "training_loss": 72.4721348285675, "training_acc": 49.0, "val_loss": 17.490145564079285, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.72866916656494, "training_acc": 47.0, "val_loss": 17.340002954006195, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19853234291077, "training_acc": 53.0, "val_loss": 17.46041476726532, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.41185688972473, "training_acc": 53.0, "val_loss": 17.33076274394989, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.5550012588501, "training_acc": 53.0, "val_loss": 17.30818897485733, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19552707672119, "training_acc": 53.0, "val_loss": 17.386147379875183, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28724789619446, "training_acc": 53.0, "val_loss": 17.318609356880188, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21585631370544, "training_acc": 53.0, "val_loss": 17.306417226791382, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17867279052734, "training_acc": 53.0, "val_loss": 17.30743795633316, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.57439136505127, "training_acc": 53.0, "val_loss": 17.31797754764557, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13729047775269, "training_acc": 53.0, "val_loss": 17.30697602033615, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1718327999115, "training_acc": 53.0, "val_loss": 17.309054732322693, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21580600738525, "training_acc": 53.0, "val_loss": 17.308051884174347, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21423411369324, "training_acc": 53.0, "val_loss": 17.307662963867188, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16820979118347, "training_acc": 53.0, "val_loss": 17.308475077152252, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17820072174072, "training_acc": 53.0, "val_loss": 17.30768233537674, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1646237373352, "training_acc": 53.0, "val_loss": 17.30807274580002, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14779424667358, "training_acc": 53.0, "val_loss": 17.317046225070953, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15506482124329, "training_acc": 53.0, "val_loss": 17.350049316883087, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.30014419555664, "training_acc": 53.0, "val_loss": 17.351077497005463, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17629361152649, "training_acc": 53.0, "val_loss": 17.319293320178986, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13615393638611, "training_acc": 53.0, "val_loss": 17.308302223682404, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2047426700592, "training_acc": 53.0, "val_loss": 17.309074103832245, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19905066490173, "training_acc": 53.0, "val_loss": 17.30838567018509, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1505994796753, "training_acc": 53.0, "val_loss": 17.308364808559418, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24710273742676, "training_acc": 53.0, "val_loss": 17.308740317821503, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.24643993377686, "training_acc": 53.0, "val_loss": 17.314837872982025, "val_acc": 52.0}
