"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 117.48218250274658, "training_acc": 49.0, "val_loss": 621.7199802398682, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1656.6141648292542, "training_acc": 49.0, "val_loss": 18.21649521589279, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.4040789604187, "training_acc": 49.0, "val_loss": 17.39085167646408, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.14328813552856, "training_acc": 45.0, "val_loss": 17.659229040145874, "val_acc": 52.0}
{"epoch": 4, "training_loss": 74.13700914382935, "training_acc": 47.0, "val_loss": 17.33504980802536, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06568932533264, "training_acc": 53.0, "val_loss": 17.644527554512024, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.78278398513794, "training_acc": 53.0, "val_loss": 17.38215982913971, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.39608216285706, "training_acc": 53.0, "val_loss": 17.3613503575325, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.28027105331421, "training_acc": 53.0, "val_loss": 17.350932955741882, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.39100980758667, "training_acc": 53.0, "val_loss": 17.328639328479767, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14962387084961, "training_acc": 53.0, "val_loss": 17.310956120491028, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.28696942329407, "training_acc": 53.0, "val_loss": 17.31637865304947, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.3532943725586, "training_acc": 47.0, "val_loss": 17.322997748851776, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22729420661926, "training_acc": 53.0, "val_loss": 17.308059334754944, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15306568145752, "training_acc": 53.0, "val_loss": 17.323148250579834, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15489673614502, "training_acc": 53.0, "val_loss": 17.343460023403168, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.48512959480286, "training_acc": 53.0, "val_loss": 17.32989400625229, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27528858184814, "training_acc": 53.0, "val_loss": 17.345714569091797, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23420810699463, "training_acc": 53.0, "val_loss": 17.333781719207764, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13891673088074, "training_acc": 53.0, "val_loss": 17.314966022968292, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18059587478638, "training_acc": 53.0, "val_loss": 17.308874428272247, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14275908470154, "training_acc": 53.0, "val_loss": 17.308305203914642, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15644812583923, "training_acc": 53.0, "val_loss": 17.3079714179039, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15215396881104, "training_acc": 53.0, "val_loss": 17.30821132659912, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15027666091919, "training_acc": 53.0, "val_loss": 17.30998009443283, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16115546226501, "training_acc": 53.0, "val_loss": 17.318937182426453, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16002607345581, "training_acc": 53.0, "val_loss": 17.324374616146088, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.25885510444641, "training_acc": 53.0, "val_loss": 17.319858074188232, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13696789741516, "training_acc": 53.0, "val_loss": 17.326460778713226, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15481114387512, "training_acc": 53.0, "val_loss": 17.330752313137054, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1759078502655, "training_acc": 53.0, "val_loss": 17.335033416748047, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.19514894485474, "training_acc": 53.0, "val_loss": 17.328445613384247, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17210340499878, "training_acc": 53.0, "val_loss": 17.31618642807007, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.11046600341797, "training_acc": 53.0, "val_loss": 17.308391630649567, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15684151649475, "training_acc": 53.0, "val_loss": 17.310510575771332, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.19324994087219, "training_acc": 53.0, "val_loss": 17.313072085380554, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.21122336387634, "training_acc": 53.0, "val_loss": 17.31276661157608, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20079159736633, "training_acc": 53.0, "val_loss": 17.31056421995163, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17237186431885, "training_acc": 53.0, "val_loss": 17.308399081230164, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.142746925354, "training_acc": 53.0, "val_loss": 17.310073971748352, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.11872220039368, "training_acc": 53.0, "val_loss": 17.31697767972946, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.27664995193481, "training_acc": 53.0, "val_loss": 17.328257858753204, "val_acc": 52.0}
