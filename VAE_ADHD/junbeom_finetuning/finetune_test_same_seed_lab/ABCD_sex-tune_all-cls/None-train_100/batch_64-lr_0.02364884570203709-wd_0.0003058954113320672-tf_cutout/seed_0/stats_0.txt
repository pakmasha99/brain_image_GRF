"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1704.8386154174805, "training_acc": 50.0, "val_loss": 4.532912994395097e+23, "val_acc": 56.0}
{"epoch": 1, "training_loss": 1.2035601252053347e+24, "training_acc": 52.0, "val_loss": 111799094476800.0, "val_acc": 44.0}
{"epoch": 2, "training_loss": 1.2562574350064026e+17, "training_acc": 46.0, "val_loss": 3.2371353059328e+16, "val_acc": 44.0}
{"epoch": 3, "training_loss": 8.01546833011671e+16, "training_acc": 48.0, "val_loss": 10923722342400.0, "val_acc": 44.0}
{"epoch": 4, "training_loss": 32279617077248.0, "training_acc": 48.0, "val_loss": 13478789939200.0, "val_acc": 56.0}
{"epoch": 5, "training_loss": 33697061867904.0, "training_acc": 56.0, "val_loss": 1399319654400.0, "val_acc": 44.0}
{"epoch": 6, "training_loss": 7120147480576.0, "training_acc": 50.0, "val_loss": 1561556684800.0, "val_acc": 56.0}
{"epoch": 7, "training_loss": 4738214010880.0, "training_acc": 52.0, "val_loss": 192879795200.0, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1462625632256.0, "training_acc": 42.0, "val_loss": 2144617062400.0, "val_acc": 44.0}
{"epoch": 9, "training_loss": 21305399443456.0, "training_acc": 48.0, "val_loss": 13539881779200.0, "val_acc": 56.0}
{"epoch": 10, "training_loss": 43347694780416.0, "training_acc": 52.0, "val_loss": 1425145036800.0, "val_acc": 56.0}
{"epoch": 11, "training_loss": 4169379672064.0, "training_acc": 52.0, "val_loss": 11850399744000.0, "val_acc": 44.0}
{"epoch": 12, "training_loss": 29557460015104.0, "training_acc": 46.0, "val_loss": 296105241600.0, "val_acc": 56.0}
{"epoch": 13, "training_loss": 937776901120.0, "training_acc": 52.0, "val_loss": 315396377600.0, "val_acc": 44.0}
{"epoch": 14, "training_loss": 4815178596352.0, "training_acc": 52.0, "val_loss": 186772928000.0, "val_acc": 56.0}
{"epoch": 15, "training_loss": 758148397056.0, "training_acc": 46.0, "val_loss": 167063872000.0, "val_acc": 44.0}
{"epoch": 16, "training_loss": 647666571264.0, "training_acc": 48.0, "val_loss": 863202406400.0, "val_acc": 56.0}
{"epoch": 17, "training_loss": 2650843899904.0, "training_acc": 50.0, "val_loss": 841352704000.0, "val_acc": 56.0}
{"epoch": 18, "training_loss": 3139886882816.0, "training_acc": 50.0, "val_loss": 12509929472000.0, "val_acc": 56.0}
{"epoch": 19, "training_loss": 34117906677760.0, "training_acc": 52.0, "val_loss": 782215680000.0, "val_acc": 44.0}
{"epoch": 20, "training_loss": 2084864094208.0, "training_acc": 48.0, "val_loss": 184915328000.0, "val_acc": 56.0}
{"epoch": 21, "training_loss": 844609583104.0, "training_acc": 46.0, "val_loss": 41201174400.0, "val_acc": 56.0}
{"epoch": 22, "training_loss": 187913053184.0, "training_acc": 52.0, "val_loss": 23971395200.0, "val_acc": 56.0}
{"epoch": 23, "training_loss": 77023977984.0, "training_acc": 54.0, "val_loss": 11927045600.0, "val_acc": 44.0}
{"epoch": 24, "training_loss": 42138352256.0, "training_acc": 46.0, "val_loss": 4536490000.0, "val_acc": 44.0}
{"epoch": 25, "training_loss": 14039362656.0, "training_acc": 52.0, "val_loss": 4771666800.0, "val_acc": 44.0}
{"epoch": 26, "training_loss": 13565570180.0, "training_acc": 44.0, "val_loss": 4040869200.0, "val_acc": 44.0}
{"epoch": 27, "training_loss": 12669263104.0, "training_acc": 48.0, "val_loss": 1462432500.0, "val_acc": 44.0}
{"epoch": 28, "training_loss": 9177467072.0, "training_acc": 54.0, "val_loss": 1781192000.0, "val_acc": 56.0}
{"epoch": 29, "training_loss": 15436104832.0, "training_acc": 48.0, "val_loss": 4473628000.0, "val_acc": 44.0}
{"epoch": 30, "training_loss": 16474594272.0, "training_acc": 40.0, "val_loss": 1730588400.0, "val_acc": 56.0}
{"epoch": 31, "training_loss": 5895931924.0, "training_acc": 44.0, "val_loss": 281934625.0, "val_acc": 56.0}
{"epoch": 32, "training_loss": 1647648200.0, "training_acc": 53.0, "val_loss": 218778950.0, "val_acc": 56.0}
{"epoch": 33, "training_loss": 2332267056.0, "training_acc": 48.0, "val_loss": 288643800.0, "val_acc": 44.0}
{"epoch": 34, "training_loss": 5918398592.0, "training_acc": 45.0, "val_loss": 2487630600.0, "val_acc": 56.0}
{"epoch": 35, "training_loss": 7507932296.0, "training_acc": 52.0, "val_loss": 2433473400.0, "val_acc": 44.0}
{"epoch": 36, "training_loss": 9854372384.0, "training_acc": 48.0, "val_loss": 1617922800.0, "val_acc": 44.0}
{"epoch": 37, "training_loss": 3960460024.0, "training_acc": 58.0, "val_loss": 463487000.0, "val_acc": 56.0}
{"epoch": 38, "training_loss": 2033416176.0, "training_acc": 42.0, "val_loss": 41848959.375, "val_acc": 56.0}
{"epoch": 39, "training_loss": 192062974.5, "training_acc": 49.0, "val_loss": 54746481.25, "val_acc": 56.0}
{"epoch": 40, "training_loss": 852861896.0, "training_acc": 50.0, "val_loss": 273083325.0, "val_acc": 44.0}
{"epoch": 41, "training_loss": 1302182696.0, "training_acc": 50.0, "val_loss": 492400900.0, "val_acc": 56.0}
{"epoch": 42, "training_loss": 1560728628.0, "training_acc": 52.0, "val_loss": 377570000.0, "val_acc": 44.0}
{"epoch": 43, "training_loss": 1362276192.0, "training_acc": 48.0, "val_loss": 287568325.0, "val_acc": 44.0}
{"epoch": 44, "training_loss": 759555523.0, "training_acc": 48.0, "val_loss": 125072537.5, "val_acc": 56.0}
{"epoch": 45, "training_loss": 386766919.0, "training_acc": 51.0, "val_loss": 452729100.0, "val_acc": 44.0}
{"epoch": 46, "training_loss": 1481279304.0, "training_acc": 48.0, "val_loss": 25385079.6875, "val_acc": 48.0}
{"epoch": 47, "training_loss": 213713416.0, "training_acc": 52.0, "val_loss": 73607987.5, "val_acc": 44.0}
{"epoch": 48, "training_loss": 228904593.5, "training_acc": 47.0, "val_loss": 13999928.125, "val_acc": 40.0}
{"epoch": 49, "training_loss": 115604929.0, "training_acc": 49.0, "val_loss": 63708062.5, "val_acc": 56.0}
{"epoch": 50, "training_loss": 190819104.0, "training_acc": 58.0, "val_loss": 44004446.875, "val_acc": 56.0}
{"epoch": 51, "training_loss": 154031008.0, "training_acc": 49.0, "val_loss": 18241767.1875, "val_acc": 48.0}
{"epoch": 52, "training_loss": 209897868.0, "training_acc": 56.0, "val_loss": 83637031.25, "val_acc": 44.0}
{"epoch": 53, "training_loss": 258110222.0, "training_acc": 48.0, "val_loss": 55293337.5, "val_acc": 56.0}
{"epoch": 54, "training_loss": 185444225.0, "training_acc": 53.0, "val_loss": 68329143.75, "val_acc": 44.0}
{"epoch": 55, "training_loss": 239526399.5, "training_acc": 48.0, "val_loss": 13651115.625, "val_acc": 40.0}
{"epoch": 56, "training_loss": 163322921.0, "training_acc": 43.0, "val_loss": 71450093.75, "val_acc": 56.0}
{"epoch": 57, "training_loss": 255765278.5, "training_acc": 51.0, "val_loss": 35843384.375, "val_acc": 44.0}
{"epoch": 58, "training_loss": 142556859.5, "training_acc": 48.0, "val_loss": 28758871.875, "val_acc": 44.0}
{"epoch": 59, "training_loss": 82012176.25, "training_acc": 53.0, "val_loss": 39176265.625, "val_acc": 56.0}
{"epoch": 60, "training_loss": 159682325.5, "training_acc": 52.0, "val_loss": 5764632.03125, "val_acc": 52.0}
{"epoch": 61, "training_loss": 62996180.5, "training_acc": 49.0, "val_loss": 39532462.5, "val_acc": 44.0}
{"epoch": 62, "training_loss": 98239224.0625, "training_acc": 48.0, "val_loss": 16093020.3125, "val_acc": 56.0}
{"epoch": 63, "training_loss": 60720503.6875, "training_acc": 53.0, "val_loss": 27933740.625, "val_acc": 44.0}
{"epoch": 64, "training_loss": 83081396.25, "training_acc": 53.0, "val_loss": 3212924.0234375, "val_acc": 60.0}
{"epoch": 65, "training_loss": 53232581.0, "training_acc": 52.0, "val_loss": 8161467.1875, "val_acc": 56.0}
{"epoch": 66, "training_loss": 57965791.25, "training_acc": 49.0, "val_loss": 22086871.875, "val_acc": 44.0}
{"epoch": 67, "training_loss": 64270684.125, "training_acc": 43.0, "val_loss": 6432319.921875, "val_acc": 56.0}
{"epoch": 68, "training_loss": 40006916.25, "training_acc": 51.0, "val_loss": 23242007.8125, "val_acc": 44.0}
{"epoch": 69, "training_loss": 72113108.5, "training_acc": 48.0, "val_loss": 8437100.0, "val_acc": 56.0}
{"epoch": 70, "training_loss": 51942863.25, "training_acc": 52.0, "val_loss": 2097100.0, "val_acc": 56.0}
{"epoch": 71, "training_loss": 21538535.625, "training_acc": 65.0, "val_loss": 10599821.09375, "val_acc": 44.0}
{"epoch": 72, "training_loss": 42430124.625, "training_acc": 44.0, "val_loss": 3935896.09375, "val_acc": 52.0}
{"epoch": 73, "training_loss": 21521184.0, "training_acc": 56.0, "val_loss": 5270344.921875, "val_acc": 40.0}
{"epoch": 74, "training_loss": 30417579.75, "training_acc": 48.0, "val_loss": 2399040.0390625, "val_acc": 52.0}
{"epoch": 75, "training_loss": 28321153.5, "training_acc": 49.0, "val_loss": 2850324.21875, "val_acc": 40.0}
{"epoch": 76, "training_loss": 26509636.125, "training_acc": 51.0, "val_loss": 5528183.984375, "val_acc": 52.0}
{"epoch": 77, "training_loss": 27243088.125, "training_acc": 54.0, "val_loss": 6482943.75, "val_acc": 40.0}
{"epoch": 78, "training_loss": 26114396.0, "training_acc": 56.0, "val_loss": 8973879.6875, "val_acc": 56.0}
{"epoch": 79, "training_loss": 30633704.25, "training_acc": 53.0, "val_loss": 7134575.78125, "val_acc": 40.0}
{"epoch": 80, "training_loss": 21815056.0, "training_acc": 57.0, "val_loss": 2219475.9765625, "val_acc": 48.0}
{"epoch": 81, "training_loss": 17639432.3125, "training_acc": 56.0, "val_loss": 3036460.15625, "val_acc": 36.0}
{"epoch": 82, "training_loss": 19383199.9375, "training_acc": 48.0, "val_loss": 5439655.859375, "val_acc": 40.0}
{"epoch": 83, "training_loss": 21148439.9375, "training_acc": 45.0, "val_loss": 3482571.875, "val_acc": 48.0}
{"epoch": 84, "training_loss": 21848743.9375, "training_acc": 54.0, "val_loss": 2328679.8828125, "val_acc": 52.0}
{"epoch": 85, "training_loss": 17285500.0625, "training_acc": 52.0, "val_loss": 9549200.0, "val_acc": 44.0}
{"epoch": 86, "training_loss": 27330628.25, "training_acc": 42.0, "val_loss": 6367643.75, "val_acc": 56.0}
{"epoch": 87, "training_loss": 22519464.0625, "training_acc": 50.0, "val_loss": 5329900.0, "val_acc": 40.0}
{"epoch": 88, "training_loss": 26181975.875, "training_acc": 45.0, "val_loss": 2258383.984375, "val_acc": 40.0}
{"epoch": 89, "training_loss": 20436684.25, "training_acc": 46.0, "val_loss": 8539823.4375, "val_acc": 56.0}
