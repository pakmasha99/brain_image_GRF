"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2766.557083129883, "training_acc": 45.0, "val_loss": 4.73566348836864e+16, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1.3582463345214915e+17, "training_acc": 41.0, "val_loss": 342815206400.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 968929244480.0, "training_acc": 53.0, "val_loss": 76556441600.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 179732778960.0, "training_acc": 47.0, "val_loss": 2382658000.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 10599932672.0, "training_acc": 59.0, "val_loss": 9826848800.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 24223601952.0, "training_acc": 55.0, "val_loss": 94493792000.0, "val_acc": 48.0}
{"epoch": 6, "training_loss": 321287801344.0, "training_acc": 49.0, "val_loss": 26569556800.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1139068510208.0, "training_acc": 53.0, "val_loss": 1247218688000.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3507182903296.0, "training_acc": 51.0, "val_loss": 13276269772800.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 31273560400288.0, "training_acc": 47.0, "val_loss": 16761016000.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 21403010007040.0, "training_acc": 51.0, "val_loss": 1.0614135062528e+16, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3.128170554536755e+16, "training_acc": 43.0, "val_loss": 298230716825600.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 825766474022912.0, "training_acc": 45.0, "val_loss": 93086836326400.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 4921455301099520.0, "training_acc": 47.0, "val_loss": 84696524390400.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1265951408390144.0, "training_acc": 47.0, "val_loss": 3129023764889600.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 8074892281307136.0, "training_acc": 52.0, "val_loss": 5062906675200.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 359489793425408.0, "training_acc": 49.0, "val_loss": 129908224819200.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 892643013820416.0, "training_acc": 51.0, "val_loss": 30925386547200.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 140431163129856.0, "training_acc": 53.0, "val_loss": 342851924787200.0, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1252300039389184.0, "training_acc": 47.0, "val_loss": 5221828608000.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 12900634468352.0, "training_acc": 53.0, "val_loss": 1698594508800.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1.036212082835456e+16, "training_acc": 55.0, "val_loss": 2.90779486486528e+16, "val_acc": 52.0}
{"epoch": 22, "training_loss": 7.17431539761152e+16, "training_acc": 53.0, "val_loss": 439340184371200.0, "val_acc": 52.0}
