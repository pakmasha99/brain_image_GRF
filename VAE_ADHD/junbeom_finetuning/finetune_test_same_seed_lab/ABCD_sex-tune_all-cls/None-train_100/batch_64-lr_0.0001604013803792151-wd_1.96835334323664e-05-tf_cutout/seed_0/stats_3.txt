"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.27440190315247, "training_acc": 53.0, "val_loss": 17.316335439682007, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.66879367828369, "training_acc": 53.0, "val_loss": 18.377555906772614, "val_acc": 40.0}
{"epoch": 2, "training_loss": 72.4510350227356, "training_acc": 47.0, "val_loss": 17.306599020957947, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.83571195602417, "training_acc": 53.0, "val_loss": 17.38703101873398, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.52107286453247, "training_acc": 53.0, "val_loss": 17.304523289203644, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1998643875122, "training_acc": 53.0, "val_loss": 17.303654551506042, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16076326370239, "training_acc": 53.0, "val_loss": 17.30882376432419, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.20169377326965, "training_acc": 53.0, "val_loss": 17.31499880552292, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24231767654419, "training_acc": 53.0, "val_loss": 17.305724322795868, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14053130149841, "training_acc": 53.0, "val_loss": 17.311827838420868, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19297742843628, "training_acc": 53.0, "val_loss": 17.3261359333992, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15373301506042, "training_acc": 53.0, "val_loss": 17.363733053207397, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.32524061203003, "training_acc": 53.0, "val_loss": 17.355039715766907, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21413850784302, "training_acc": 53.0, "val_loss": 17.31094866991043, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09804105758667, "training_acc": 53.0, "val_loss": 17.323827743530273, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.57404088973999, "training_acc": 43.0, "val_loss": 17.33572781085968, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2484974861145, "training_acc": 55.0, "val_loss": 17.313644289970398, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.01946687698364, "training_acc": 53.0, "val_loss": 17.357023060321808, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18438768386841, "training_acc": 53.0, "val_loss": 17.408153414726257, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.4051628112793, "training_acc": 53.0, "val_loss": 17.399367690086365, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.36979246139526, "training_acc": 53.0, "val_loss": 17.348334193229675, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26420140266418, "training_acc": 53.0, "val_loss": 17.318865656852722, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17472052574158, "training_acc": 53.0, "val_loss": 17.311950027942657, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14091563224792, "training_acc": 53.0, "val_loss": 17.311401665210724, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13643884658813, "training_acc": 53.0, "val_loss": 17.309392988681793, "val_acc": 52.0}
