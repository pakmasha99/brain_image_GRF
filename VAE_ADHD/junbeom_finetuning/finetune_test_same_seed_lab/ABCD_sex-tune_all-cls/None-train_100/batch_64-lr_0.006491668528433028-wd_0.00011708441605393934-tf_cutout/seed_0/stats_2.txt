"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 430.20015716552734, "training_acc": 50.0, "val_loss": 1755811200.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4338345257.261475, "training_acc": 51.0, "val_loss": 12447.723388671875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 35975.963928222656, "training_acc": 47.0, "val_loss": 127.22835540771484, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2962.1210021972656, "training_acc": 59.0, "val_loss": 473.5783100128174, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1460.1769676208496, "training_acc": 49.0, "val_loss": 17.325885593891144, "val_acc": 52.0}
{"epoch": 5, "training_loss": 117.62118911743164, "training_acc": 53.0, "val_loss": 429.5790195465088, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1313.602131843567, "training_acc": 47.0, "val_loss": 19.59347426891327, "val_acc": 52.0}
{"epoch": 7, "training_loss": 93.95561742782593, "training_acc": 53.0, "val_loss": 17.313747107982635, "val_acc": 52.0}
{"epoch": 8, "training_loss": 126.56030178070068, "training_acc": 49.0, "val_loss": 76.0327160358429, "val_acc": 52.0}
{"epoch": 9, "training_loss": 250.83169150352478, "training_acc": 53.0, "val_loss": 18.584606051445007, "val_acc": 52.0}
{"epoch": 10, "training_loss": 117.08109140396118, "training_acc": 55.0, "val_loss": 17.697854340076447, "val_acc": 52.0}
{"epoch": 11, "training_loss": 86.92975425720215, "training_acc": 53.0, "val_loss": 18.483340740203857, "val_acc": 48.0}
{"epoch": 12, "training_loss": 76.77589535713196, "training_acc": 47.0, "val_loss": 17.65739768743515, "val_acc": 52.0}
{"epoch": 13, "training_loss": 73.94233798980713, "training_acc": 53.0, "val_loss": 19.519582390785217, "val_acc": 48.0}
{"epoch": 14, "training_loss": 76.94493198394775, "training_acc": 47.0, "val_loss": 24.548543989658356, "val_acc": 52.0}
{"epoch": 15, "training_loss": 90.00824308395386, "training_acc": 53.0, "val_loss": 21.567054092884064, "val_acc": 48.0}
{"epoch": 16, "training_loss": 88.81659317016602, "training_acc": 47.0, "val_loss": 17.362365126609802, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.48183465003967, "training_acc": 53.0, "val_loss": 21.075060963630676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 80.43453431129456, "training_acc": 53.0, "val_loss": 17.313842475414276, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.55585789680481, "training_acc": 45.0, "val_loss": 17.352569103240967, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15802311897278, "training_acc": 53.0, "val_loss": 17.310018837451935, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.36411237716675, "training_acc": 51.0, "val_loss": 17.341001331806183, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28539037704468, "training_acc": 50.0, "val_loss": 17.761941254138947, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.16890048980713, "training_acc": 53.0, "val_loss": 17.487764358520508, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.18694591522217, "training_acc": 47.0, "val_loss": 17.56984293460846, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.441730260849, "training_acc": 47.0, "val_loss": 17.412318289279938, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.81107807159424, "training_acc": 53.0, "val_loss": 17.329394817352295, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12376546859741, "training_acc": 55.0, "val_loss": 17.9424986243248, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.7825870513916, "training_acc": 47.0, "val_loss": 17.366790771484375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.46356678009033, "training_acc": 49.0, "val_loss": 17.62031465768814, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.04544734954834, "training_acc": 53.0, "val_loss": 17.644187808036804, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.96459650993347, "training_acc": 53.0, "val_loss": 17.35856980085373, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.06464052200317, "training_acc": 53.0, "val_loss": 17.35924482345581, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.54122519493103, "training_acc": 47.0, "val_loss": 17.42464452981949, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.79985570907593, "training_acc": 47.0, "val_loss": 17.314817011356354, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13162732124329, "training_acc": 53.0, "val_loss": 17.33555942773819, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.11400413513184, "training_acc": 53.0, "val_loss": 17.41727590560913, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.78845691680908, "training_acc": 53.0, "val_loss": 17.4728661775589, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.41710543632507, "training_acc": 53.0, "val_loss": 17.315618693828583, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.30057430267334, "training_acc": 53.0, "val_loss": 17.340625822544098, "val_acc": 52.0}
