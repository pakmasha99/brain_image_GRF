"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 398.7647171020508, "training_acc": 47.0, "val_loss": 2719209400.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7463691465.109894, "training_acc": 45.0, "val_loss": 2809.010696411133, "val_acc": 48.0}
{"epoch": 2, "training_loss": 10992.965728759766, "training_acc": 47.0, "val_loss": 59.2240571975708, "val_acc": 52.0}
{"epoch": 3, "training_loss": 913.7840881347656, "training_acc": 53.0, "val_loss": 406.09941482543945, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1225.4512577056885, "training_acc": 53.0, "val_loss": 36.153146624565125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 172.10883808135986, "training_acc": 47.0, "val_loss": 25.34959614276886, "val_acc": 48.0}
{"epoch": 6, "training_loss": 209.65245628356934, "training_acc": 51.0, "val_loss": 55.930912494659424, "val_acc": 48.0}
{"epoch": 7, "training_loss": 169.2197229862213, "training_acc": 47.0, "val_loss": 84.72437858581543, "val_acc": 52.0}
{"epoch": 8, "training_loss": 490.08884048461914, "training_acc": 45.0, "val_loss": 27.139806747436523, "val_acc": 52.0}
{"epoch": 9, "training_loss": 101.46199679374695, "training_acc": 43.0, "val_loss": 30.83139657974243, "val_acc": 52.0}
{"epoch": 10, "training_loss": 118.47325849533081, "training_acc": 51.0, "val_loss": 17.32376664876938, "val_acc": 52.0}
{"epoch": 11, "training_loss": 92.13543128967285, "training_acc": 53.0, "val_loss": 17.365504801273346, "val_acc": 52.0}
{"epoch": 12, "training_loss": 85.98115396499634, "training_acc": 45.0, "val_loss": 18.99203509092331, "val_acc": 48.0}
{"epoch": 13, "training_loss": 71.06466269493103, "training_acc": 55.0, "val_loss": 21.888743340969086, "val_acc": 52.0}
{"epoch": 14, "training_loss": 84.28821110725403, "training_acc": 53.0, "val_loss": 17.359550297260284, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.60627126693726, "training_acc": 53.0, "val_loss": 19.355174899101257, "val_acc": 48.0}
{"epoch": 16, "training_loss": 77.0352852344513, "training_acc": 47.0, "val_loss": 17.34548956155777, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12544798851013, "training_acc": 53.0, "val_loss": 17.693038284778595, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.43054270744324, "training_acc": 53.0, "val_loss": 17.405880987644196, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.22034120559692, "training_acc": 53.0, "val_loss": 17.352357506752014, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.9438636302948, "training_acc": 47.0, "val_loss": 17.469440400600433, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.54949188232422, "training_acc": 53.0, "val_loss": 17.483752965927124, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.57088208198547, "training_acc": 53.0, "val_loss": 17.311587929725647, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.28067755699158, "training_acc": 53.0, "val_loss": 17.312869429588318, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23658418655396, "training_acc": 49.0, "val_loss": 17.354321479797363, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.18772435188293, "training_acc": 47.0, "val_loss": 17.31278747320175, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.81367659568787, "training_acc": 53.0, "val_loss": 17.54574328660965, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.85224461555481, "training_acc": 53.0, "val_loss": 17.704401910305023, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.48742747306824, "training_acc": 53.0, "val_loss": 17.455890774726868, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.89250898361206, "training_acc": 53.0, "val_loss": 17.322389781475067, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17751693725586, "training_acc": 53.0, "val_loss": 17.307475209236145, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.3147804737091, "training_acc": 53.0, "val_loss": 17.30765998363495, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19691967964172, "training_acc": 53.0, "val_loss": 17.32466071844101, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20325493812561, "training_acc": 53.0, "val_loss": 17.331908643245697, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16252613067627, "training_acc": 53.0, "val_loss": 17.342811822891235, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.29137206077576, "training_acc": 53.0, "val_loss": 17.322082817554474, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22666645050049, "training_acc": 53.0, "val_loss": 17.313209176063538, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.32709836959839, "training_acc": 51.0, "val_loss": 17.41584688425064, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.86664915084839, "training_acc": 47.0, "val_loss": 17.374297976493835, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.40864968299866, "training_acc": 51.0, "val_loss": 17.31218993663788, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.27173900604248, "training_acc": 53.0, "val_loss": 17.4275204539299, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.47843670845032, "training_acc": 53.0, "val_loss": 17.44544953107834, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.51987195014954, "training_acc": 53.0, "val_loss": 17.350880801677704, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14412021636963, "training_acc": 53.0, "val_loss": 17.31025129556656, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.34930443763733, "training_acc": 53.0, "val_loss": 17.331404983997345, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.3328948020935, "training_acc": 45.0, "val_loss": 17.328238487243652, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.38494491577148, "training_acc": 48.0, "val_loss": 17.31419861316681, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.245774269104, "training_acc": 53.0, "val_loss": 17.326466739177704, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.57446336746216, "training_acc": 53.0, "val_loss": 17.36295223236084, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.22339725494385, "training_acc": 53.0, "val_loss": 17.32601821422577, "val_acc": 52.0}
