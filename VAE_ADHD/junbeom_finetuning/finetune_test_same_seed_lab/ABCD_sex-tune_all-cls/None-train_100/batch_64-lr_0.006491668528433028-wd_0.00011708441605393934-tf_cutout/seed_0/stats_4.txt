"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 135.69656372070312, "training_acc": 49.0, "val_loss": 1232035700.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2734910079.339508, "training_acc": 53.0, "val_loss": 3115.416145324707, "val_acc": 48.0}
{"epoch": 2, "training_loss": 9012.709487915039, "training_acc": 47.0, "val_loss": 1003.5670280456543, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2501.3605213165283, "training_acc": 53.0, "val_loss": 610.81223487854, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1975.5884094238281, "training_acc": 47.0, "val_loss": 27.217715978622437, "val_acc": 52.0}
{"epoch": 5, "training_loss": 244.81658172607422, "training_acc": 51.0, "val_loss": 39.293310046195984, "val_acc": 52.0}
{"epoch": 6, "training_loss": 327.71947288513184, "training_acc": 47.0, "val_loss": 23.89763444662094, "val_acc": 52.0}
{"epoch": 7, "training_loss": 157.50303554534912, "training_acc": 45.0, "val_loss": 113.68777751922607, "val_acc": 52.0}
{"epoch": 8, "training_loss": 361.29391860961914, "training_acc": 53.0, "val_loss": 91.37405157089233, "val_acc": 48.0}
{"epoch": 9, "training_loss": 253.75198769569397, "training_acc": 47.0, "val_loss": 25.419828295707703, "val_acc": 52.0}
{"epoch": 10, "training_loss": 90.03853106498718, "training_acc": 53.0, "val_loss": 24.43271577358246, "val_acc": 48.0}
{"epoch": 11, "training_loss": 86.21580481529236, "training_acc": 51.0, "val_loss": 20.626090466976166, "val_acc": 52.0}
{"epoch": 12, "training_loss": 79.22306776046753, "training_acc": 51.0, "val_loss": 18.036101758480072, "val_acc": 52.0}
{"epoch": 13, "training_loss": 73.64778852462769, "training_acc": 43.0, "val_loss": 19.849151372909546, "val_acc": 52.0}
{"epoch": 14, "training_loss": 75.92380785942078, "training_acc": 53.0, "val_loss": 17.973028123378754, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.97236561775208, "training_acc": 47.0, "val_loss": 17.317451536655426, "val_acc": 52.0}
{"epoch": 16, "training_loss": 76.88962268829346, "training_acc": 44.0, "val_loss": 27.74779200553894, "val_acc": 52.0}
{"epoch": 17, "training_loss": 97.35377597808838, "training_acc": 53.0, "val_loss": 17.30601042509079, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72.7892632484436, "training_acc": 49.0, "val_loss": 17.519648373126984, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.16683530807495, "training_acc": 49.0, "val_loss": 18.438720703125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.99842953681946, "training_acc": 51.0, "val_loss": 17.526984214782715, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.46459627151489, "training_acc": 41.0, "val_loss": 17.29607582092285, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.09188199043274, "training_acc": 53.0, "val_loss": 17.356589436531067, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.42899799346924, "training_acc": 53.0, "val_loss": 17.323867976665497, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.99001288414001, "training_acc": 53.0, "val_loss": 17.37075448036194, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.53986024856567, "training_acc": 47.0, "val_loss": 17.298099398612976, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.51127028465271, "training_acc": 53.0, "val_loss": 17.402541637420654, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.28575325012207, "training_acc": 53.0, "val_loss": 17.3017218708992, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.44696402549744, "training_acc": 49.0, "val_loss": 17.3048734664917, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15097498893738, "training_acc": 52.0, "val_loss": 17.400436103343964, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.44534158706665, "training_acc": 53.0, "val_loss": 17.382507026195526, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.28085160255432, "training_acc": 53.0, "val_loss": 17.302407324314117, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.29936957359314, "training_acc": 51.0, "val_loss": 17.3138827085495, "val_acc": 52.0}
{"epoch": 33, "training_loss": 71.49420285224915, "training_acc": 53.0, "val_loss": 17.35171526670456, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.56679630279541, "training_acc": 47.0, "val_loss": 17.61525273323059, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.91736555099487, "training_acc": 47.0, "val_loss": 17.59343445301056, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.1335220336914, "training_acc": 53.0, "val_loss": 17.322058975696564, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.47673439979553, "training_acc": 53.0, "val_loss": 18.036924302577972, "val_acc": 52.0}
{"epoch": 38, "training_loss": 72.4082624912262, "training_acc": 53.0, "val_loss": 17.495819926261902, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.40255832672119, "training_acc": 53.0, "val_loss": 17.294825613498688, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16178107261658, "training_acc": 54.0, "val_loss": 17.30000525712967, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.74093747138977, "training_acc": 53.0, "val_loss": 17.30128973722458, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1436219215393, "training_acc": 53.0, "val_loss": 17.30577200651169, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.17878651618958, "training_acc": 56.0, "val_loss": 17.392195761203766, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.66679883003235, "training_acc": 53.0, "val_loss": 17.448318004608154, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.29302978515625, "training_acc": 53.0, "val_loss": 17.299634218215942, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.55403161048889, "training_acc": 47.0, "val_loss": 17.47257262468338, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.57621693611145, "training_acc": 51.0, "val_loss": 17.541974782943726, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.9265604019165, "training_acc": 53.0, "val_loss": 17.605921626091003, "val_acc": 52.0}
{"epoch": 49, "training_loss": 70.1011917591095, "training_acc": 53.0, "val_loss": 17.301923036575317, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.56123352050781, "training_acc": 47.0, "val_loss": 17.318908870220184, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.35248899459839, "training_acc": 50.0, "val_loss": 17.34825223684311, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.44265723228455, "training_acc": 53.0, "val_loss": 17.369766533374786, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.32751083374023, "training_acc": 53.0, "val_loss": 17.424052953720093, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.45041537284851, "training_acc": 53.0, "val_loss": 17.38205999135971, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.60242772102356, "training_acc": 53.0, "val_loss": 17.303338646888733, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.1664137840271, "training_acc": 53.0, "val_loss": 17.30450838804245, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.26413941383362, "training_acc": 53.0, "val_loss": 17.30930656194687, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.18563890457153, "training_acc": 53.0, "val_loss": 17.306147515773773, "val_acc": 52.0}
