"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 351.2028274536133, "training_acc": 50.0, "val_loss": 11567150.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 31431226.794921875, "training_acc": 52.0, "val_loss": 33099.371337890625, "val_acc": 44.0}
{"epoch": 2, "training_loss": 85758.42681884766, "training_acc": 48.0, "val_loss": 240.9200668334961, "val_acc": 56.0}
{"epoch": 3, "training_loss": 673.1695084571838, "training_acc": 54.0, "val_loss": 595.8240985870361, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1907.5645694732666, "training_acc": 52.0, "val_loss": 78.84543538093567, "val_acc": 44.0}
{"epoch": 5, "training_loss": 229.62436604499817, "training_acc": 48.0, "val_loss": 23.50025475025177, "val_acc": 56.0}
{"epoch": 6, "training_loss": 132.80024003982544, "training_acc": 50.0, "val_loss": 26.092490553855896, "val_acc": 56.0}
{"epoch": 7, "training_loss": 98.7454104423523, "training_acc": 52.0, "val_loss": 18.21427047252655, "val_acc": 56.0}
{"epoch": 8, "training_loss": 161.14710998535156, "training_acc": 42.0, "val_loss": 62.55050301551819, "val_acc": 44.0}
{"epoch": 9, "training_loss": 187.15684700012207, "training_acc": 48.0, "val_loss": 18.296702206134796, "val_acc": 56.0}
{"epoch": 10, "training_loss": 70.85827565193176, "training_acc": 48.0, "val_loss": 18.717098236083984, "val_acc": 56.0}
{"epoch": 11, "training_loss": 74.49711179733276, "training_acc": 52.0, "val_loss": 24.756701290607452, "val_acc": 44.0}
{"epoch": 12, "training_loss": 88.66507649421692, "training_acc": 46.0, "val_loss": 17.599593102931976, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.21782064437866, "training_acc": 52.0, "val_loss": 20.769470930099487, "val_acc": 56.0}
{"epoch": 14, "training_loss": 110.54257822036743, "training_acc": 48.0, "val_loss": 17.53276437520981, "val_acc": 56.0}
{"epoch": 15, "training_loss": 74.06639409065247, "training_acc": 52.0, "val_loss": 18.158118426799774, "val_acc": 56.0}
{"epoch": 16, "training_loss": 72.95935726165771, "training_acc": 52.0, "val_loss": 18.78606826066971, "val_acc": 56.0}
{"epoch": 17, "training_loss": 73.48495936393738, "training_acc": 50.0, "val_loss": 17.594139277935028, "val_acc": 56.0}
{"epoch": 18, "training_loss": 70.49926090240479, "training_acc": 48.0, "val_loss": 17.252802848815918, "val_acc": 56.0}
{"epoch": 19, "training_loss": 70.3853907585144, "training_acc": 52.0, "val_loss": 17.732074856758118, "val_acc": 56.0}
{"epoch": 20, "training_loss": 70.81105542182922, "training_acc": 48.0, "val_loss": 17.213816940784454, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.02934980392456, "training_acc": 52.0, "val_loss": 17.296752333641052, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.71339464187622, "training_acc": 52.0, "val_loss": 17.72349178791046, "val_acc": 56.0}
{"epoch": 23, "training_loss": 70.1473982334137, "training_acc": 48.0, "val_loss": 17.508728802204132, "val_acc": 56.0}
{"epoch": 24, "training_loss": 72.0275022983551, "training_acc": 46.0, "val_loss": 17.451347410678864, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.59655547142029, "training_acc": 48.0, "val_loss": 17.571131885051727, "val_acc": 56.0}
{"epoch": 26, "training_loss": 72.45013809204102, "training_acc": 38.0, "val_loss": 17.22012311220169, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.26137900352478, "training_acc": 52.0, "val_loss": 17.817071080207825, "val_acc": 56.0}
{"epoch": 28, "training_loss": 70.11549472808838, "training_acc": 48.0, "val_loss": 17.164190113544464, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.42656660079956, "training_acc": 52.0, "val_loss": 17.27866679430008, "val_acc": 56.0}
{"epoch": 30, "training_loss": 70.77529644966125, "training_acc": 52.0, "val_loss": 17.306123673915863, "val_acc": 56.0}
{"epoch": 31, "training_loss": 71.47076559066772, "training_acc": 42.0, "val_loss": 18.047891557216644, "val_acc": 56.0}
{"epoch": 32, "training_loss": 70.72659301757812, "training_acc": 48.0, "val_loss": 17.4776628613472, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.35916924476624, "training_acc": 52.0, "val_loss": 17.20622181892395, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.47361850738525, "training_acc": 52.0, "val_loss": 17.153893411159515, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.51662755012512, "training_acc": 52.0, "val_loss": 17.21540540456772, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.80740070343018, "training_acc": 48.0, "val_loss": 17.261967062950134, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.12847757339478, "training_acc": 52.0, "val_loss": 17.156021296977997, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.39294600486755, "training_acc": 52.0, "val_loss": 17.153525352478027, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.75310134887695, "training_acc": 52.0, "val_loss": 17.155806720256805, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.57916188240051, "training_acc": 52.0, "val_loss": 17.17010587453842, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2862401008606, "training_acc": 52.0, "val_loss": 17.260436713695526, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26272630691528, "training_acc": 52.0, "val_loss": 17.337246239185333, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.41709470748901, "training_acc": 40.0, "val_loss": 17.369921505451202, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.47656011581421, "training_acc": 48.0, "val_loss": 17.420345544815063, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.45763802528381, "training_acc": 48.0, "val_loss": 17.35798567533493, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.34955739974976, "training_acc": 45.0, "val_loss": 17.307090759277344, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.2639844417572, "training_acc": 52.0, "val_loss": 17.262019217014313, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.27785038948059, "training_acc": 52.0, "val_loss": 17.20762848854065, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.32886219024658, "training_acc": 52.0, "val_loss": 17.19234585762024, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.24237942695618, "training_acc": 52.0, "val_loss": 17.21174269914627, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.22488522529602, "training_acc": 52.0, "val_loss": 17.27350205183029, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.27257585525513, "training_acc": 52.0, "val_loss": 17.289897799491882, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26585865020752, "training_acc": 52.0, "val_loss": 17.301177978515625, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.28981900215149, "training_acc": 52.0, "val_loss": 17.28624701499939, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.37378668785095, "training_acc": 52.0, "val_loss": 17.238032817840576, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24394631385803, "training_acc": 52.0, "val_loss": 17.24477708339691, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.25271940231323, "training_acc": 52.0, "val_loss": 17.246635258197784, "val_acc": 56.0}
