"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1394.0033798217773, "training_acc": 46.0, "val_loss": 3.665420363088947e+21, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9.387841806396531e+21, "training_acc": 49.0, "val_loss": 860117500.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4574088240.0, "training_acc": 47.0, "val_loss": 92087181.25, "val_acc": 48.0}
{"epoch": 3, "training_loss": 390081189.0, "training_acc": 47.0, "val_loss": 198155162.5, "val_acc": 48.0}
{"epoch": 4, "training_loss": 543755128.5, "training_acc": 53.0, "val_loss": 770865500.0, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2235218620.0, "training_acc": 43.0, "val_loss": 35330287.5, "val_acc": 52.0}
{"epoch": 6, "training_loss": 149566082.5, "training_acc": 53.0, "val_loss": 1003051.26953125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 17612757.375, "training_acc": 45.0, "val_loss": 27335400.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 67329992.0, "training_acc": 55.0, "val_loss": 222888.76953125, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1679016.6484375, "training_acc": 47.0, "val_loss": 1309336.81640625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 17881576.0, "training_acc": 53.0, "val_loss": 3585864.84375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 8424156.70703125, "training_acc": 57.0, "val_loss": 3186140.4296875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 31258655.0, "training_acc": 51.0, "val_loss": 60544.342041015625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 159645434.453125, "training_acc": 53.0, "val_loss": 11447116.40625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 140703615.0, "training_acc": 47.0, "val_loss": 8358207.8125, "val_acc": 48.0}
{"epoch": 15, "training_loss": 28167841.5, "training_acc": 47.0, "val_loss": 14701810.9375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 44534748.3125, "training_acc": 47.0, "val_loss": 304244.7021484375, "val_acc": 48.0}
{"epoch": 17, "training_loss": 8086128.0625, "training_acc": 53.0, "val_loss": 5202410.546875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 15567460.59375, "training_acc": 51.0, "val_loss": 305747.216796875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1902974742.9375, "training_acc": 45.0, "val_loss": 3804148.046875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 168141978.0, "training_acc": 53.0, "val_loss": 26416590.625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 475843920.0, "training_acc": 47.0, "val_loss": 7468671.09375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 26712480.25, "training_acc": 53.0, "val_loss": 12071778.90625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 26347893184.0, "training_acc": 51.0, "val_loss": 1977518.1640625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 7185150.28125, "training_acc": 49.0, "val_loss": 630515050.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1535814079.5, "training_acc": 53.0, "val_loss": 364889850.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1042601923.0, "training_acc": 47.0, "val_loss": 28866665.625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 93284135.75, "training_acc": 47.0, "val_loss": 2593192.7734375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 14574991.3125, "training_acc": 56.0, "val_loss": 9672100.78125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68095030.0, "training_acc": 45.0, "val_loss": 6076505.46875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 48348726.25, "training_acc": 57.0, "val_loss": 14387978.125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 44778540.125, "training_acc": 53.0, "val_loss": 1099938.0859375, "val_acc": 48.0}
