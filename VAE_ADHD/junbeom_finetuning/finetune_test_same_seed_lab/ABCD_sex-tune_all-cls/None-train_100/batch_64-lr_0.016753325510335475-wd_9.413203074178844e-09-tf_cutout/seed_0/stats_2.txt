"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1261.7617988586426, "training_acc": 47.0, "val_loss": 7.86686320003032e+22, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.93951463105984e+23, "training_acc": 51.0, "val_loss": 1470488500.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 13202493440.0, "training_acc": 53.0, "val_loss": 1819592800.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4626661666.0, "training_acc": 53.0, "val_loss": 390790850.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 902251703.0, "training_acc": 59.0, "val_loss": 639286750.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1674068138.0, "training_acc": 53.0, "val_loss": 9620048.4375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 31869875.9375, "training_acc": 47.0, "val_loss": 11524443.75, "val_acc": 52.0}
{"epoch": 7, "training_loss": 80830728.0, "training_acc": 45.0, "val_loss": 21677415.625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 113821678.5, "training_acc": 45.0, "val_loss": 226087375.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 922809124.0, "training_acc": 49.0, "val_loss": 2580715.0390625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 7852336.234375, "training_acc": 53.0, "val_loss": 1500195.99609375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 16287786.125, "training_acc": 55.0, "val_loss": 37481643.75, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1365025592.0, "training_acc": 51.0, "val_loss": 23451017.1875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 67942606.0, "training_acc": 53.0, "val_loss": 741754200.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3344827216.0, "training_acc": 53.0, "val_loss": 1560102.63671875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 10035003.6875, "training_acc": 55.0, "val_loss": 4575733.984375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1849590850.0, "training_acc": 45.0, "val_loss": 850502.05078125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3325790.03125, "training_acc": 53.0, "val_loss": 1249907.71484375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3856550.2890625, "training_acc": 53.0, "val_loss": 589955.615234375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1987175.76953125, "training_acc": 53.0, "val_loss": 1416377.734375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3988815.6474609375, "training_acc": 53.0, "val_loss": 219182.6416015625, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1978616.328125, "training_acc": 49.0, "val_loss": 1556679.98046875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 3617474.8732910156, "training_acc": 55.0, "val_loss": 1072112.3046875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3243846.609375, "training_acc": 51.0, "val_loss": 2889188.8671875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 7680330.515625, "training_acc": 55.0, "val_loss": 622267.041015625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1891317.505859375, "training_acc": 47.0, "val_loss": 769683.740234375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2453669.921875, "training_acc": 53.0, "val_loss": 279267.919921875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 708767.7783203125, "training_acc": 47.0, "val_loss": 393154.8095703125, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1267201.943359375, "training_acc": 53.0, "val_loss": 141528.18603515625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 493705.0712890625, "training_acc": 47.0, "val_loss": 89793.84155273438, "val_acc": 52.0}
{"epoch": 30, "training_loss": 344143.650390625, "training_acc": 53.0, "val_loss": 87318.00537109375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 312910.9521484375, "training_acc": 47.0, "val_loss": 103692.7978515625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 370760.095703125, "training_acc": 53.0, "val_loss": 8001.474761962891, "val_acc": 48.0}
{"epoch": 33, "training_loss": 45485.109375, "training_acc": 46.0, "val_loss": 88689.56298828125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 366452.791015625, "training_acc": 53.0, "val_loss": 56916.93115234375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 177776.6103515625, "training_acc": 51.0, "val_loss": 38284.04541015625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 105749.53189086914, "training_acc": 48.0, "val_loss": 37654.998779296875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 138595.64599609375, "training_acc": 53.0, "val_loss": 3368.5867309570312, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65882.2841796875, "training_acc": 48.0, "val_loss": 37370.54748535156, "val_acc": 48.0}
{"epoch": 39, "training_loss": 118188.39050292969, "training_acc": 47.0, "val_loss": 54199.822998046875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 197328.6845703125, "training_acc": 53.0, "val_loss": 16127.030944824219, "val_acc": 52.0}
{"epoch": 41, "training_loss": 96575.4765625, "training_acc": 41.0, "val_loss": 30943.142700195312, "val_acc": 48.0}
{"epoch": 42, "training_loss": 95793.61791992188, "training_acc": 47.0, "val_loss": 21634.486389160156, "val_acc": 52.0}
{"epoch": 43, "training_loss": 86965.57421875, "training_acc": 53.0, "val_loss": 15474.06005859375, "val_acc": 52.0}
{"epoch": 44, "training_loss": 48503.522521972656, "training_acc": 48.0, "val_loss": 4130.999374389648, "val_acc": 48.0}
{"epoch": 45, "training_loss": 25453.914184570312, "training_acc": 50.0, "val_loss": 11252.476501464844, "val_acc": 52.0}
{"epoch": 46, "training_loss": 33538.91519165039, "training_acc": 53.0, "val_loss": 10860.38818359375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 45553.15881347656, "training_acc": 47.0, "val_loss": 2556.852912902832, "val_acc": 48.0}
{"epoch": 48, "training_loss": 33127.732666015625, "training_acc": 44.0, "val_loss": 17616.2841796875, "val_acc": 52.0}
{"epoch": 49, "training_loss": 54372.88928222656, "training_acc": 53.0, "val_loss": 4836.731338500977, "val_acc": 48.0}
{"epoch": 50, "training_loss": 20122.52471923828, "training_acc": 47.0, "val_loss": 1192.4562454223633, "val_acc": 52.0}
{"epoch": 51, "training_loss": 6112.161529541016, "training_acc": 49.0, "val_loss": 2770.3222274780273, "val_acc": 48.0}
{"epoch": 52, "training_loss": 10158.332427978516, "training_acc": 48.0, "val_loss": 3262.20703125, "val_acc": 52.0}
{"epoch": 53, "training_loss": 12570.660705566406, "training_acc": 51.0, "val_loss": 966.0007476806641, "val_acc": 48.0}
{"epoch": 54, "training_loss": 7692.468658447266, "training_acc": 50.0, "val_loss": 2201.082229614258, "val_acc": 52.0}
{"epoch": 55, "training_loss": 9081.736938476562, "training_acc": 56.0, "val_loss": 605.1501274108887, "val_acc": 48.0}
{"epoch": 56, "training_loss": 4804.889869689941, "training_acc": 47.0, "val_loss": 1914.4779205322266, "val_acc": 52.0}
{"epoch": 57, "training_loss": 8532.389724731445, "training_acc": 49.0, "val_loss": 2693.427848815918, "val_acc": 48.0}
{"epoch": 58, "training_loss": 7372.554260253906, "training_acc": 47.0, "val_loss": 2886.8104934692383, "val_acc": 52.0}
{"epoch": 59, "training_loss": 10384.558532714844, "training_acc": 48.0, "val_loss": 2054.3148040771484, "val_acc": 48.0}
{"epoch": 60, "training_loss": 7124.341339111328, "training_acc": 46.0, "val_loss": 3459.2857360839844, "val_acc": 52.0}
{"epoch": 61, "training_loss": 15478.440246582031, "training_acc": 52.0, "val_loss": 1306.2461853027344, "val_acc": 52.0}
{"epoch": 62, "training_loss": 9732.481201171875, "training_acc": 50.0, "val_loss": 5476.865768432617, "val_acc": 48.0}
{"epoch": 63, "training_loss": 17182.480926513672, "training_acc": 47.0, "val_loss": 4937.355422973633, "val_acc": 52.0}
{"epoch": 64, "training_loss": 22785.348388671875, "training_acc": 55.0, "val_loss": 6970.859527587891, "val_acc": 52.0}
{"epoch": 65, "training_loss": 19041.242584228516, "training_acc": 53.0, "val_loss": 4095.8240509033203, "val_acc": 48.0}
{"epoch": 66, "training_loss": 20320.394409179688, "training_acc": 47.0, "val_loss": 4981.852340698242, "val_acc": 48.0}
{"epoch": 67, "training_loss": 14657.337127685547, "training_acc": 47.0, "val_loss": 1969.2689895629883, "val_acc": 52.0}
{"epoch": 68, "training_loss": 7542.911529541016, "training_acc": 45.0, "val_loss": 891.1389350891113, "val_acc": 52.0}
{"epoch": 69, "training_loss": 4467.296310424805, "training_acc": 52.0, "val_loss": 2491.061782836914, "val_acc": 48.0}
{"epoch": 70, "training_loss": 9640.263671875, "training_acc": 49.0, "val_loss": 1207.4220657348633, "val_acc": 52.0}
{"epoch": 71, "training_loss": 6246.428955078125, "training_acc": 52.0, "val_loss": 138.92990350723267, "val_acc": 52.0}
{"epoch": 72, "training_loss": 4668.6123046875, "training_acc": 51.0, "val_loss": 346.3696479797363, "val_acc": 44.0}
{"epoch": 73, "training_loss": 4243.150421142578, "training_acc": 52.0, "val_loss": 1589.2340660095215, "val_acc": 52.0}
{"epoch": 74, "training_loss": 5718.914779663086, "training_acc": 51.0, "val_loss": 574.2554664611816, "val_acc": 48.0}
{"epoch": 75, "training_loss": 3396.6551208496094, "training_acc": 49.0, "val_loss": 1500.6357192993164, "val_acc": 52.0}
{"epoch": 76, "training_loss": 6013.523132324219, "training_acc": 47.0, "val_loss": 158.97303819656372, "val_acc": 52.0}
{"epoch": 77, "training_loss": 2958.702926635742, "training_acc": 47.0, "val_loss": 221.93622589111328, "val_acc": 48.0}
{"epoch": 78, "training_loss": 4642.025054931641, "training_acc": 53.0, "val_loss": 625.6185054779053, "val_acc": 48.0}
{"epoch": 79, "training_loss": 5745.70751953125, "training_acc": 45.0, "val_loss": 3785.258102416992, "val_acc": 52.0}
{"epoch": 80, "training_loss": 12363.567932128906, "training_acc": 52.0, "val_loss": 1107.1351051330566, "val_acc": 48.0}
{"epoch": 81, "training_loss": 6509.427185058594, "training_acc": 48.0, "val_loss": 495.0838088989258, "val_acc": 52.0}
{"epoch": 82, "training_loss": 3358.876998901367, "training_acc": 54.0, "val_loss": 134.29524898529053, "val_acc": 52.0}
{"epoch": 83, "training_loss": 3878.171356201172, "training_acc": 49.0, "val_loss": 300.12972354888916, "val_acc": 52.0}
{"epoch": 84, "training_loss": 3121.6185607910156, "training_acc": 50.0, "val_loss": 237.53747940063477, "val_acc": 48.0}
{"epoch": 85, "training_loss": 3473.815399169922, "training_acc": 46.0, "val_loss": 411.70969009399414, "val_acc": 52.0}
{"epoch": 86, "training_loss": 2182.973976135254, "training_acc": 55.0, "val_loss": 1864.865493774414, "val_acc": 48.0}
{"epoch": 87, "training_loss": 6248.557159423828, "training_acc": 46.0, "val_loss": 2248.8197326660156, "val_acc": 52.0}
{"epoch": 88, "training_loss": 8559.603454589844, "training_acc": 54.0, "val_loss": 510.30473709106445, "val_acc": 52.0}
{"epoch": 89, "training_loss": 4542.8765869140625, "training_acc": 60.0, "val_loss": 3160.62068939209, "val_acc": 48.0}
{"epoch": 90, "training_loss": 10571.51741027832, "training_acc": 46.0, "val_loss": 3278.955841064453, "val_acc": 52.0}
{"epoch": 91, "training_loss": 13007.102844238281, "training_acc": 53.0, "val_loss": 3292.351531982422, "val_acc": 52.0}
{"epoch": 92, "training_loss": 8152.133743286133, "training_acc": 53.0, "val_loss": 3875.495147705078, "val_acc": 48.0}
{"epoch": 93, "training_loss": 18165.05303955078, "training_acc": 47.0, "val_loss": 3578.7742614746094, "val_acc": 48.0}
{"epoch": 94, "training_loss": 9269.34186553955, "training_acc": 49.0, "val_loss": 3358.677291870117, "val_acc": 52.0}
{"epoch": 95, "training_loss": 12574.646484375, "training_acc": 54.0, "val_loss": 2804.0252685546875, "val_acc": 52.0}
{"epoch": 96, "training_loss": 9685.140686035156, "training_acc": 51.0, "val_loss": 2095.2821731567383, "val_acc": 48.0}
{"epoch": 97, "training_loss": 9050.75894165039, "training_acc": 42.0, "val_loss": 1254.0955543518066, "val_acc": 52.0}
{"epoch": 98, "training_loss": 5592.578277587891, "training_acc": 40.0, "val_loss": 143.52959394454956, "val_acc": 44.0}
{"epoch": 99, "training_loss": 3162.210403442383, "training_acc": 49.0, "val_loss": 205.7096242904663, "val_acc": 56.0}
{"epoch": 100, "training_loss": 3597.3208770751953, "training_acc": 53.0, "val_loss": 162.2833013534546, "val_acc": 56.0}
{"epoch": 101, "training_loss": 2080.0392532348633, "training_acc": 45.0, "val_loss": 614.251708984375, "val_acc": 48.0}
