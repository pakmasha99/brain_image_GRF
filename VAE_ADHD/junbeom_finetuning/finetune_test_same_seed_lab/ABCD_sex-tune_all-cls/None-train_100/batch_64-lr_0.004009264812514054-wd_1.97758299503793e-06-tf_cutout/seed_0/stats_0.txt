"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 226.65468788146973, "training_acc": 50.0, "val_loss": 49890.863037109375, "val_acc": 56.0}
{"epoch": 1, "training_loss": 144689.0780029297, "training_acc": 52.0, "val_loss": 492.53764152526855, "val_acc": 44.0}
{"epoch": 2, "training_loss": 1336.4730997085571, "training_acc": 48.0, "val_loss": 18.766508996486664, "val_acc": 68.0}
{"epoch": 3, "training_loss": 73.60907554626465, "training_acc": 46.0, "val_loss": 17.228786647319794, "val_acc": 56.0}
{"epoch": 4, "training_loss": 82.75696659088135, "training_acc": 50.0, "val_loss": 20.019035041332245, "val_acc": 56.0}
{"epoch": 5, "training_loss": 84.01549100875854, "training_acc": 52.0, "val_loss": 17.60428696870804, "val_acc": 56.0}
{"epoch": 6, "training_loss": 71.63748979568481, "training_acc": 52.0, "val_loss": 17.59844869375229, "val_acc": 56.0}
{"epoch": 7, "training_loss": 70.63275146484375, "training_acc": 48.0, "val_loss": 17.464177310466766, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.59704422950745, "training_acc": 42.0, "val_loss": 17.183852195739746, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2185788154602, "training_acc": 52.0, "val_loss": 17.282114923000336, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.30292177200317, "training_acc": 50.0, "val_loss": 17.345134913921356, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.33527660369873, "training_acc": 48.0, "val_loss": 17.26057231426239, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.34244918823242, "training_acc": 52.0, "val_loss": 17.21520572900772, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.29093217849731, "training_acc": 52.0, "val_loss": 17.240482568740845, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.23809576034546, "training_acc": 52.0, "val_loss": 17.21162497997284, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.26251578330994, "training_acc": 52.0, "val_loss": 17.179815471172333, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.33571815490723, "training_acc": 52.0, "val_loss": 17.16647297143936, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.32076597213745, "training_acc": 52.0, "val_loss": 17.23620593547821, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.26018142700195, "training_acc": 52.0, "val_loss": 17.29666292667389, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.28010106086731, "training_acc": 52.0, "val_loss": 17.278774082660675, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.26702880859375, "training_acc": 52.0, "val_loss": 17.24889874458313, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23211550712585, "training_acc": 52.0, "val_loss": 17.19929128885269, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.49172711372375, "training_acc": 52.0, "val_loss": 17.17020720243454, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25648641586304, "training_acc": 52.0, "val_loss": 17.21949875354767, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.18757009506226, "training_acc": 52.0, "val_loss": 17.29912906885147, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.34650182723999, "training_acc": 48.0, "val_loss": 17.349886894226074, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.54336166381836, "training_acc": 38.0, "val_loss": 17.31771230697632, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.3014030456543, "training_acc": 52.0, "val_loss": 17.33800321817398, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.36452054977417, "training_acc": 48.0, "val_loss": 17.316874861717224, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25586438179016, "training_acc": 52.0, "val_loss": 17.242175340652466, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.62720465660095, "training_acc": 52.0, "val_loss": 17.200210690498352, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.44107985496521, "training_acc": 52.0, "val_loss": 17.246171832084656, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23362278938293, "training_acc": 52.0, "val_loss": 17.240826785564423, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2361478805542, "training_acc": 52.0, "val_loss": 17.23448485136032, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25708079338074, "training_acc": 52.0, "val_loss": 17.22152680158615, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23900151252747, "training_acc": 52.0, "val_loss": 17.22581684589386, "val_acc": 56.0}
