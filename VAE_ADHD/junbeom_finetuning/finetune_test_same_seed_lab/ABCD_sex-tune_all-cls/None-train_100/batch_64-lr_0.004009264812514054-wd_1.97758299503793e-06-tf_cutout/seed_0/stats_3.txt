"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 330.754358291626, "training_acc": 45.0, "val_loss": 16362.019348144531, "val_acc": 52.0}
{"epoch": 1, "training_loss": 46072.83254432678, "training_acc": 43.0, "val_loss": 292.9763078689575, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1361.5375900268555, "training_acc": 59.0, "val_loss": 33.110371232032776, "val_acc": 48.0}
{"epoch": 3, "training_loss": 106.78125095367432, "training_acc": 47.0, "val_loss": 18.32893341779709, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.34620380401611, "training_acc": 53.0, "val_loss": 17.972926795482635, "val_acc": 52.0}
{"epoch": 5, "training_loss": 80.38951468467712, "training_acc": 39.0, "val_loss": 17.57432520389557, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.3991048336029, "training_acc": 47.0, "val_loss": 17.30913519859314, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.45220923423767, "training_acc": 53.0, "val_loss": 17.32051819562912, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04115748405457, "training_acc": 53.0, "val_loss": 17.61978715658188, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.0959939956665, "training_acc": 43.0, "val_loss": 17.30934828519821, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20531749725342, "training_acc": 53.0, "val_loss": 17.30893850326538, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1378664970398, "training_acc": 53.0, "val_loss": 17.32843965291977, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14669513702393, "training_acc": 53.0, "val_loss": 17.370720207691193, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.44718933105469, "training_acc": 53.0, "val_loss": 17.314809560775757, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21422338485718, "training_acc": 51.0, "val_loss": 17.34139919281006, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.3216335773468, "training_acc": 49.0, "val_loss": 17.31008142232895, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18264746665955, "training_acc": 53.0, "val_loss": 17.314331233501434, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13101530075073, "training_acc": 53.0, "val_loss": 17.309966683387756, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.37005233764648, "training_acc": 41.0, "val_loss": 17.313769459724426, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.0423104763031, "training_acc": 53.0, "val_loss": 17.36638993024826, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.35059404373169, "training_acc": 53.0, "val_loss": 17.385204136371613, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.46705627441406, "training_acc": 53.0, "val_loss": 17.335179448127747, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.05191946029663, "training_acc": 53.0, "val_loss": 17.3152893781662, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.86825919151306, "training_acc": 45.0, "val_loss": 17.312702536582947, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15276026725769, "training_acc": 53.0, "val_loss": 17.31126755475998, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1388783454895, "training_acc": 53.0, "val_loss": 17.321301996707916, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.29669141769409, "training_acc": 53.0, "val_loss": 17.320214211940765, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.25929594039917, "training_acc": 53.0, "val_loss": 17.322932183742523, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27576899528503, "training_acc": 53.0, "val_loss": 17.31230467557907, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17619180679321, "training_acc": 53.0, "val_loss": 17.309531569480896, "val_acc": 52.0}
