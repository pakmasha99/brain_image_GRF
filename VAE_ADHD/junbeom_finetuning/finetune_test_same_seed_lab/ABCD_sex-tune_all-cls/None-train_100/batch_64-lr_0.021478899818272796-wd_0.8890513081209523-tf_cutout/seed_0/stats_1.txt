"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1497.2986526489258, "training_acc": 44.0, "val_loss": 6.056069794868538e+23, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.293285638564752e+24, "training_acc": 53.0, "val_loss": 227439750.0, "val_acc": 52.0}
{"epoch": 2, "training_loss": 929679511168.0, "training_acc": 53.0, "val_loss": 2296245657600.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5559301829760.0, "training_acc": 53.0, "val_loss": 350036800.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 854958071.25, "training_acc": 53.0, "val_loss": 401914175.0, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1016167122.5, "training_acc": 51.0, "val_loss": 7021605.46875, "val_acc": 52.0}
{"epoch": 6, "training_loss": 23092962.25, "training_acc": 49.0, "val_loss": 15645521.875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 47236665.5625, "training_acc": 53.0, "val_loss": 591699.462890625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4909176.96875, "training_acc": 47.0, "val_loss": 346117.96875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 996757.810546875, "training_acc": 47.0, "val_loss": 1075801.953125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3147443.9731445312, "training_acc": 53.0, "val_loss": 76876.82495117188, "val_acc": 48.0}
{"epoch": 11, "training_loss": 240185.0478515625, "training_acc": 47.0, "val_loss": 15957.536315917969, "val_acc": 48.0}
{"epoch": 12, "training_loss": 52638.9755859375, "training_acc": 47.0, "val_loss": 1890.5929565429688, "val_acc": 48.0}
{"epoch": 13, "training_loss": 12450.153381347656, "training_acc": 47.0, "val_loss": 2418.76163482666, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6615.267517089844, "training_acc": 53.0, "val_loss": 150.84060430526733, "val_acc": 48.0}
{"epoch": 15, "training_loss": 648.5061779022217, "training_acc": 47.0, "val_loss": 52.97492742538452, "val_acc": 52.0}
{"epoch": 16, "training_loss": 434.8441734313965, "training_acc": 53.0, "val_loss": 142.81224012374878, "val_acc": 48.0}
{"epoch": 17, "training_loss": 484.6947326660156, "training_acc": 47.0, "val_loss": 18.4223011136055, "val_acc": 44.0}
{"epoch": 18, "training_loss": 146.71082496643066, "training_acc": 49.0, "val_loss": 39.2532616853714, "val_acc": 52.0}
{"epoch": 19, "training_loss": 128.34676098823547, "training_acc": 53.0, "val_loss": 17.88354516029358, "val_acc": 52.0}
{"epoch": 20, "training_loss": 71.00462174415588, "training_acc": 52.0, "val_loss": 17.33766496181488, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20942425727844, "training_acc": 49.0, "val_loss": 17.382700741291046, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25582313537598, "training_acc": 53.0, "val_loss": 17.489787936210632, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.60267281532288, "training_acc": 53.0, "val_loss": 17.459480464458466, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.54940843582153, "training_acc": 53.0, "val_loss": 17.418895661830902, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.3441960811615, "training_acc": 53.0, "val_loss": 17.370061576366425, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.33392786979675, "training_acc": 53.0, "val_loss": 17.344117164611816, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.21496891975403, "training_acc": 53.0, "val_loss": 17.336371541023254, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18168306350708, "training_acc": 53.0, "val_loss": 17.316803336143494, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.35376572608948, "training_acc": 53.0, "val_loss": 17.310313880443573, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13094305992126, "training_acc": 53.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14489316940308, "training_acc": 53.0, "val_loss": 17.31349676847458, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13124394416809, "training_acc": 53.0, "val_loss": 17.314709722995758, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13511967658997, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13988709449768, "training_acc": 53.0, "val_loss": 17.311690747737885, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1359314918518, "training_acc": 53.0, "val_loss": 17.310553789138794, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1530339717865, "training_acc": 53.0, "val_loss": 17.309395968914032, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16991209983826, "training_acc": 53.0, "val_loss": 17.308951914310455, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14646863937378, "training_acc": 53.0, "val_loss": 17.308959364891052, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15804719924927, "training_acc": 53.0, "val_loss": 17.308855056762695, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.15506386756897, "training_acc": 53.0, "val_loss": 17.30896383523941, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.1695351600647, "training_acc": 53.0, "val_loss": 17.30876863002777, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1590347290039, "training_acc": 53.0, "val_loss": 17.308802902698517, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.15998911857605, "training_acc": 53.0, "val_loss": 17.309218645095825, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.20933961868286, "training_acc": 53.0, "val_loss": 17.30981022119522, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17819142341614, "training_acc": 53.0, "val_loss": 17.309726774692535, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.17722392082214, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17728424072266, "training_acc": 53.0, "val_loss": 17.309415340423584, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.18270564079285, "training_acc": 53.0, "val_loss": 17.309075593948364, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.16746497154236, "training_acc": 53.0, "val_loss": 17.309018969535828, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.17230939865112, "training_acc": 53.0, "val_loss": 17.308947443962097, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.17786526679993, "training_acc": 53.0, "val_loss": 17.309066653251648, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1670925617218, "training_acc": 53.0, "val_loss": 17.308922111988068, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.1663601398468, "training_acc": 53.0, "val_loss": 17.30874478816986, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.1592104434967, "training_acc": 53.0, "val_loss": 17.308685183525085, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.15907263755798, "training_acc": 53.0, "val_loss": 17.30867326259613, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.15129947662354, "training_acc": 53.0, "val_loss": 17.30879694223404, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.14587736129761, "training_acc": 53.0, "val_loss": 17.309170961380005, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.1742103099823, "training_acc": 53.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.1428120136261, "training_acc": 53.0, "val_loss": 17.309485375881195, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.14181923866272, "training_acc": 53.0, "val_loss": 17.30940341949463, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.14385533332825, "training_acc": 53.0, "val_loss": 17.309312522411346, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.14409923553467, "training_acc": 53.0, "val_loss": 17.309372127056122, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.14804935455322, "training_acc": 53.0, "val_loss": 17.30923056602478, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.14337396621704, "training_acc": 53.0, "val_loss": 17.30937957763672, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.14230346679688, "training_acc": 53.0, "val_loss": 17.309533059597015, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.14556908607483, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.15074920654297, "training_acc": 53.0, "val_loss": 17.310138046741486, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.17508602142334, "training_acc": 53.0, "val_loss": 17.309734225273132, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.1381573677063, "training_acc": 53.0, "val_loss": 17.310592532157898, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.13585638999939, "training_acc": 53.0, "val_loss": 17.31209307909012, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.130446434021, "training_acc": 53.0, "val_loss": 17.315104603767395, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.14993524551392, "training_acc": 53.0, "val_loss": 17.32063889503479, "val_acc": 52.0}
{"epoch": 73, "training_loss": 69.14114308357239, "training_acc": 53.0, "val_loss": 17.321351170539856, "val_acc": 52.0}
{"epoch": 74, "training_loss": 69.21309661865234, "training_acc": 53.0, "val_loss": 17.31763184070587, "val_acc": 52.0}
