"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.36091423034668, "training_acc": 54.0, "val_loss": 17.32322722673416, "val_acc": 52.0}
{"epoch": 1, "training_loss": 72.51622343063354, "training_acc": 53.0, "val_loss": 17.80877858400345, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.15018439292908, "training_acc": 47.0, "val_loss": 17.324379086494446, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.64046883583069, "training_acc": 53.0, "val_loss": 17.369115352630615, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.96906161308289, "training_acc": 53.0, "val_loss": 17.30664372444153, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.28213667869568, "training_acc": 53.0, "val_loss": 17.335417866706848, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19258952140808, "training_acc": 53.0, "val_loss": 17.308063805103302, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13743281364441, "training_acc": 53.0, "val_loss": 17.31940060853958, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.32106041908264, "training_acc": 49.0, "val_loss": 17.33427196741104, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30941247940063, "training_acc": 56.0, "val_loss": 17.314916849136353, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4362576007843, "training_acc": 53.0, "val_loss": 17.333336174488068, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09597969055176, "training_acc": 53.0, "val_loss": 17.312078177928925, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.0775294303894, "training_acc": 53.0, "val_loss": 17.3353910446167, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.46403908729553, "training_acc": 50.0, "val_loss": 17.355170845985413, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38112378120422, "training_acc": 47.0, "val_loss": 17.3159196972847, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.106192111969, "training_acc": 53.0, "val_loss": 17.32376664876938, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.274897813797, "training_acc": 53.0, "val_loss": 17.35534965991974, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20663142204285, "training_acc": 53.0, "val_loss": 17.341500520706177, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18298363685608, "training_acc": 53.0, "val_loss": 17.331477999687195, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10224652290344, "training_acc": 53.0, "val_loss": 17.31620728969574, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11577153205872, "training_acc": 53.0, "val_loss": 17.317022383213043, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15846705436707, "training_acc": 53.0, "val_loss": 17.321710288524628, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18817067146301, "training_acc": 53.0, "val_loss": 17.320498824119568, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1572732925415, "training_acc": 53.0, "val_loss": 17.316852509975433, "val_acc": 52.0}
