"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.5556366443634, "training_acc": 55.0, "val_loss": 17.315533757209778, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.23090720176697, "training_acc": 53.0, "val_loss": 19.978584349155426, "val_acc": 52.0}
{"epoch": 2, "training_loss": 79.60214281082153, "training_acc": 43.0, "val_loss": 17.42784082889557, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.98862814903259, "training_acc": 47.0, "val_loss": 17.341651022434235, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.46642756462097, "training_acc": 43.0, "val_loss": 17.31709986925125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3031599521637, "training_acc": 51.0, "val_loss": 17.306937277317047, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32194066047668, "training_acc": 53.0, "val_loss": 17.316095530986786, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29068684577942, "training_acc": 53.0, "val_loss": 17.409667372703552, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.34999012947083, "training_acc": 53.0, "val_loss": 17.37375259399414, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.31313920021057, "training_acc": 53.0, "val_loss": 17.324790358543396, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13428497314453, "training_acc": 53.0, "val_loss": 17.315737903118134, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18497943878174, "training_acc": 53.0, "val_loss": 17.313064634799957, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14280700683594, "training_acc": 53.0, "val_loss": 17.317119240760803, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2158043384552, "training_acc": 53.0, "val_loss": 17.32008010149002, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.43273735046387, "training_acc": 43.0, "val_loss": 17.31644570827484, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.30631852149963, "training_acc": 53.0, "val_loss": 17.32207089662552, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.25385618209839, "training_acc": 53.0, "val_loss": 17.3380509018898, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13515424728394, "training_acc": 53.0, "val_loss": 17.324720323085785, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12457013130188, "training_acc": 53.0, "val_loss": 17.315539717674255, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13709354400635, "training_acc": 53.0, "val_loss": 17.315396666526794, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24833035469055, "training_acc": 53.0, "val_loss": 17.317111790180206, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.09232544898987, "training_acc": 53.0, "val_loss": 17.332999408245087, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.31886792182922, "training_acc": 53.0, "val_loss": 17.354056239128113, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.265873670578, "training_acc": 53.0, "val_loss": 17.335312068462372, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10340428352356, "training_acc": 53.0, "val_loss": 17.333920300006866, "val_acc": 52.0}
