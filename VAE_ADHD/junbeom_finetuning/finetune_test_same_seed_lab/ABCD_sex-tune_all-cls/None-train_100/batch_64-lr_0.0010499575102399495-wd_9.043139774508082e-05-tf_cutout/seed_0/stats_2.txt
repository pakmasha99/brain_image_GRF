"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 101.77596473693848, "training_acc": 47.0, "val_loss": 115.80396890640259, "val_acc": 52.0}
{"epoch": 1, "training_loss": 360.4247727394104, "training_acc": 43.0, "val_loss": 17.513541877269745, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.47744679450989, "training_acc": 45.0, "val_loss": 17.328116297721863, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.99280595779419, "training_acc": 44.0, "val_loss": 17.676177620887756, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.8670585155487, "training_acc": 47.0, "val_loss": 17.358967661857605, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.4075813293457, "training_acc": 50.0, "val_loss": 17.305518686771393, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.08237385749817, "training_acc": 53.0, "val_loss": 17.32562631368637, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.56418204307556, "training_acc": 53.0, "val_loss": 17.340926826000214, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17934942245483, "training_acc": 53.0, "val_loss": 17.385676503181458, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44000291824341, "training_acc": 53.0, "val_loss": 17.366062104701996, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.50286865234375, "training_acc": 53.0, "val_loss": 17.316222190856934, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13836741447449, "training_acc": 53.0, "val_loss": 17.313438653945923, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13445234298706, "training_acc": 53.0, "val_loss": 17.311300337314606, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17084550857544, "training_acc": 53.0, "val_loss": 17.31056123971939, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15704274177551, "training_acc": 53.0, "val_loss": 17.307807505130768, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15980100631714, "training_acc": 53.0, "val_loss": 17.30804443359375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16138768196106, "training_acc": 53.0, "val_loss": 17.31013059616089, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14730381965637, "training_acc": 53.0, "val_loss": 17.311488091945648, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12944316864014, "training_acc": 53.0, "val_loss": 17.316201329231262, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.154629945755, "training_acc": 53.0, "val_loss": 17.324919998645782, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16979551315308, "training_acc": 53.0, "val_loss": 17.326469719409943, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14057660102844, "training_acc": 53.0, "val_loss": 17.31966733932495, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13359761238098, "training_acc": 53.0, "val_loss": 17.31444150209427, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16061067581177, "training_acc": 53.0, "val_loss": 17.311687767505646, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13557028770447, "training_acc": 53.0, "val_loss": 17.312423884868622, "val_acc": 52.0}
