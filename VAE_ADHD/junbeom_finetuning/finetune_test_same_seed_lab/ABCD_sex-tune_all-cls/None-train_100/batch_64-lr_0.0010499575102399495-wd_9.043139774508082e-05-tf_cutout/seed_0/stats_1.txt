"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 90.64233827590942, "training_acc": 49.0, "val_loss": 78.15670371055603, "val_acc": 52.0}
{"epoch": 1, "training_loss": 246.39401245117188, "training_acc": 49.0, "val_loss": 17.33051687479019, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.48052549362183, "training_acc": 53.0, "val_loss": 17.45952218770981, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12055850028992, "training_acc": 53.0, "val_loss": 20.039954781532288, "val_acc": 48.0}
{"epoch": 4, "training_loss": 71.46056032180786, "training_acc": 59.0, "val_loss": 19.46313977241516, "val_acc": 52.0}
{"epoch": 5, "training_loss": 75.58171963691711, "training_acc": 53.0, "val_loss": 17.46387630701065, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.88981986045837, "training_acc": 53.0, "val_loss": 17.35488325357437, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28344774246216, "training_acc": 53.0, "val_loss": 17.338508367538452, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19894742965698, "training_acc": 53.0, "val_loss": 17.333626747131348, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22046566009521, "training_acc": 53.0, "val_loss": 17.329204082489014, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15419316291809, "training_acc": 53.0, "val_loss": 17.311713099479675, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14126205444336, "training_acc": 53.0, "val_loss": 17.30707138776779, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25007629394531, "training_acc": 53.0, "val_loss": 17.31298565864563, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2344696521759, "training_acc": 53.0, "val_loss": 17.309875786304474, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17745900154114, "training_acc": 53.0, "val_loss": 17.308349907398224, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14119267463684, "training_acc": 53.0, "val_loss": 17.31427162885666, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.24333381652832, "training_acc": 53.0, "val_loss": 17.31812208890915, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24843525886536, "training_acc": 53.0, "val_loss": 17.334575951099396, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23814868927002, "training_acc": 53.0, "val_loss": 17.334072291851044, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15569424629211, "training_acc": 53.0, "val_loss": 17.321431636810303, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17403650283813, "training_acc": 53.0, "val_loss": 17.313173413276672, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13197684288025, "training_acc": 53.0, "val_loss": 17.311297357082367, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14227652549744, "training_acc": 53.0, "val_loss": 17.30981022119522, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1415786743164, "training_acc": 53.0, "val_loss": 17.309734225273132, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15341544151306, "training_acc": 53.0, "val_loss": 17.310568690299988, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14818024635315, "training_acc": 53.0, "val_loss": 17.313924431800842, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14308261871338, "training_acc": 53.0, "val_loss": 17.315973341464996, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18585348129272, "training_acc": 53.0, "val_loss": 17.315632104873657, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13005757331848, "training_acc": 53.0, "val_loss": 17.32049137353897, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13594937324524, "training_acc": 53.0, "val_loss": 17.325255274772644, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16227841377258, "training_acc": 53.0, "val_loss": 17.330817878246307, "val_acc": 52.0}
