"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 103.48355340957642, "training_acc": 51.0, "val_loss": 28.257641196250916, "val_acc": 52.0}
{"epoch": 1, "training_loss": 162.56103992462158, "training_acc": 55.0, "val_loss": 18.30126941204071, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72.32680344581604, "training_acc": 47.0, "val_loss": 17.31220930814743, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.07013154029846, "training_acc": 53.0, "val_loss": 17.64080822467804, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.43026685714722, "training_acc": 45.0, "val_loss": 17.317870259284973, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.47814106941223, "training_acc": 53.0, "val_loss": 17.345497012138367, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18406963348389, "training_acc": 53.0, "val_loss": 17.331069707870483, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.43403339385986, "training_acc": 45.0, "val_loss": 17.308126389980316, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19155216217041, "training_acc": 53.0, "val_loss": 17.304442822933197, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29652428627014, "training_acc": 53.0, "val_loss": 17.32000857591629, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13429188728333, "training_acc": 53.0, "val_loss": 17.39966571331024, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.50467491149902, "training_acc": 53.0, "val_loss": 17.329593002796173, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.62718963623047, "training_acc": 53.0, "val_loss": 17.30792373418808, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.25771284103394, "training_acc": 53.0, "val_loss": 17.307819426059723, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21677660942078, "training_acc": 53.0, "val_loss": 17.31056421995163, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.27025246620178, "training_acc": 53.0, "val_loss": 17.306765913963318, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20286226272583, "training_acc": 53.0, "val_loss": 17.306368052959442, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.25522994995117, "training_acc": 53.0, "val_loss": 17.30656772851944, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13680744171143, "training_acc": 53.0, "val_loss": 17.31008142232895, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.55949425697327, "training_acc": 53.0, "val_loss": 17.32245236635208, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.34522938728333, "training_acc": 53.0, "val_loss": 17.306537926197052, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13776731491089, "training_acc": 53.0, "val_loss": 17.305941879749298, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15472626686096, "training_acc": 53.0, "val_loss": 17.306138575077057, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1600112915039, "training_acc": 53.0, "val_loss": 17.307475209236145, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12971472740173, "training_acc": 53.0, "val_loss": 17.314128577709198, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12214636802673, "training_acc": 53.0, "val_loss": 17.323073744773865, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17562937736511, "training_acc": 53.0, "val_loss": 17.334313690662384, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16595101356506, "training_acc": 53.0, "val_loss": 17.332860827445984, "val_acc": 52.0}
