"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 90.81788301467896, "training_acc": 43.0, "val_loss": 19.446876645088196, "val_acc": 52.0}
{"epoch": 1, "training_loss": 104.82416820526123, "training_acc": 41.0, "val_loss": 17.691001296043396, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.97321152687073, "training_acc": 47.0, "val_loss": 17.322377860546112, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.37797665596008, "training_acc": 53.0, "val_loss": 17.59658455848694, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.13489890098572, "training_acc": 53.0, "val_loss": 17.481601238250732, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.80646896362305, "training_acc": 53.0, "val_loss": 17.307132482528687, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.37116312980652, "training_acc": 53.0, "val_loss": 17.30998605489731, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26292014122009, "training_acc": 51.0, "val_loss": 17.351970076560974, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.90581059455872, "training_acc": 41.0, "val_loss": 17.30741411447525, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.26948094367981, "training_acc": 53.0, "val_loss": 17.307744920253754, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14321899414062, "training_acc": 53.0, "val_loss": 17.313045263290405, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1559944152832, "training_acc": 53.0, "val_loss": 17.35256165266037, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22682785987854, "training_acc": 53.0, "val_loss": 17.342379689216614, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.84414982795715, "training_acc": 53.0, "val_loss": 17.31138378381729, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27196073532104, "training_acc": 53.0, "val_loss": 17.32298582792282, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20696377754211, "training_acc": 53.0, "val_loss": 17.31303781270981, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.11354780197144, "training_acc": 53.0, "val_loss": 17.30656772851944, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2340898513794, "training_acc": 53.0, "val_loss": 17.312778532505035, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21146321296692, "training_acc": 53.0, "val_loss": 17.30963885784149, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17686009407043, "training_acc": 53.0, "val_loss": 17.307841777801514, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14216184616089, "training_acc": 53.0, "val_loss": 17.309722304344177, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11358332633972, "training_acc": 53.0, "val_loss": 17.31935441493988, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18852972984314, "training_acc": 53.0, "val_loss": 17.3416405916214, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19802379608154, "training_acc": 53.0, "val_loss": 17.337718605995178, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.38000583648682, "training_acc": 53.0, "val_loss": 17.318424582481384, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13775897026062, "training_acc": 53.0, "val_loss": 17.319904267787933, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15382385253906, "training_acc": 53.0, "val_loss": 17.321082949638367, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1474335193634, "training_acc": 53.0, "val_loss": 17.324286699295044, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16875457763672, "training_acc": 53.0, "val_loss": 17.320138216018677, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17303586006165, "training_acc": 53.0, "val_loss": 17.311832308769226, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10398077964783, "training_acc": 53.0, "val_loss": 17.31000542640686, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18142366409302, "training_acc": 53.0, "val_loss": 17.317141592502594, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.23427677154541, "training_acc": 53.0, "val_loss": 17.318475246429443, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.23550391197205, "training_acc": 53.0, "val_loss": 17.313949763774872, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19025993347168, "training_acc": 53.0, "val_loss": 17.310023307800293, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13960218429565, "training_acc": 53.0, "val_loss": 17.309194803237915, "val_acc": 52.0}
