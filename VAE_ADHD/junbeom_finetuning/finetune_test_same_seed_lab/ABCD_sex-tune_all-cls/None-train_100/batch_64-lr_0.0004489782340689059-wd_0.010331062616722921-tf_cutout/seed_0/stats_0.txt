"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.51856398582458, "training_acc": 50.0, "val_loss": 20.347541570663452, "val_acc": 56.0}
{"epoch": 1, "training_loss": 82.65326499938965, "training_acc": 52.0, "val_loss": 17.22732186317444, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.38475751876831, "training_acc": 52.0, "val_loss": 17.203466594219208, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.0914397239685, "training_acc": 53.0, "val_loss": 17.56909489631653, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.76151990890503, "training_acc": 48.0, "val_loss": 17.235055565834045, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.00225234031677, "training_acc": 52.0, "val_loss": 17.169184982776642, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.35289025306702, "training_acc": 52.0, "val_loss": 17.248019576072693, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.29053497314453, "training_acc": 52.0, "val_loss": 17.271122336387634, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.4560215473175, "training_acc": 52.0, "val_loss": 17.23862737417221, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.21768546104431, "training_acc": 52.0, "val_loss": 17.27466583251953, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.27244234085083, "training_acc": 52.0, "val_loss": 17.29012131690979, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26632809638977, "training_acc": 52.0, "val_loss": 17.257577180862427, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.27200412750244, "training_acc": 52.0, "val_loss": 17.23466068506241, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.24196362495422, "training_acc": 52.0, "val_loss": 17.24197566509247, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2183485031128, "training_acc": 52.0, "val_loss": 17.226241528987885, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2254798412323, "training_acc": 52.0, "val_loss": 17.20813661813736, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2648766040802, "training_acc": 52.0, "val_loss": 17.190077900886536, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.27668857574463, "training_acc": 52.0, "val_loss": 17.21021682024002, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.22696113586426, "training_acc": 52.0, "val_loss": 17.242230474948883, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.20236539840698, "training_acc": 52.0, "val_loss": 17.269763350486755, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.25046372413635, "training_acc": 52.0, "val_loss": 17.29031652212143, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23974394798279, "training_acc": 52.0, "val_loss": 17.26756989955902, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.35992050170898, "training_acc": 52.0, "val_loss": 17.22142994403839, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.23700451850891, "training_acc": 52.0, "val_loss": 17.228053510189056, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.18897747993469, "training_acc": 52.0, "val_loss": 17.25795269012451, "val_acc": 56.0}
