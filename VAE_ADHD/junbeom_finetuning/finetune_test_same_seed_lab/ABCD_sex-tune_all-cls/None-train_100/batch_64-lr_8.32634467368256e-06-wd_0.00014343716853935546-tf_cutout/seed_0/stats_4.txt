"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.65562796592712, "training_acc": 47.0, "val_loss": 17.53436177968979, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.01984357833862, "training_acc": 47.0, "val_loss": 17.327526211738586, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.5528461933136, "training_acc": 44.0, "val_loss": 17.309243977069855, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.23428750038147, "training_acc": 53.0, "val_loss": 17.370764911174774, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.28831481933594, "training_acc": 53.0, "val_loss": 17.37988293170929, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.39890313148499, "training_acc": 53.0, "val_loss": 17.35256165266037, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.29446125030518, "training_acc": 53.0, "val_loss": 17.32366979122162, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.33375859260559, "training_acc": 53.0, "val_loss": 17.29816347360611, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1451678276062, "training_acc": 53.0, "val_loss": 17.296160757541656, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2261712551117, "training_acc": 53.0, "val_loss": 17.29925274848938, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18480634689331, "training_acc": 53.0, "val_loss": 17.29874014854431, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18226337432861, "training_acc": 53.0, "val_loss": 17.299138009548187, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20728659629822, "training_acc": 53.0, "val_loss": 17.298635840415955, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13872575759888, "training_acc": 53.0, "val_loss": 17.299140989780426, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09892916679382, "training_acc": 53.0, "val_loss": 17.301657795906067, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.05855345726013, "training_acc": 53.0, "val_loss": 17.311294376850128, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06616759300232, "training_acc": 53.0, "val_loss": 17.330652475357056, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20846486091614, "training_acc": 53.0, "val_loss": 17.35050529241562, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22520399093628, "training_acc": 53.0, "val_loss": 17.34360009431839, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21057534217834, "training_acc": 53.0, "val_loss": 17.32676327228546, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16378593444824, "training_acc": 53.0, "val_loss": 17.311827838420868, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.04802250862122, "training_acc": 53.0, "val_loss": 17.306910455226898, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.07149577140808, "training_acc": 53.0, "val_loss": 17.301861941814423, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.04551768302917, "training_acc": 53.0, "val_loss": 17.29956716299057, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09631299972534, "training_acc": 53.0, "val_loss": 17.299243807792664, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14911246299744, "training_acc": 53.0, "val_loss": 17.299845814704895, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1032383441925, "training_acc": 53.0, "val_loss": 17.299605906009674, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.08325576782227, "training_acc": 53.0, "val_loss": 17.304006218910217, "val_acc": 52.0}
