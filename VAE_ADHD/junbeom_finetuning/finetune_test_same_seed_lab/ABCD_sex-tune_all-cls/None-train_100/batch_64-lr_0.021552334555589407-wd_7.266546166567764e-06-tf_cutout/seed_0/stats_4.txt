"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1686.5662078857422, "training_acc": 51.0, "val_loss": 1.582803200715522e+20, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3.60842968475061e+20, "training_acc": 55.0, "val_loss": 4504532400.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 116127757312.0, "training_acc": 49.0, "val_loss": 26967104000.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 71754722208.0, "training_acc": 47.0, "val_loss": 1652965700.0, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5687265872.0, "training_acc": 47.0, "val_loss": 8429864000.0, "val_acc": 48.0}
{"epoch": 5, "training_loss": 45862417664.0, "training_acc": 47.0, "val_loss": 4266374000.0, "val_acc": 48.0}
{"epoch": 6, "training_loss": 15374876832.0, "training_acc": 47.0, "val_loss": 5161016800.0, "val_acc": 48.0}
{"epoch": 7, "training_loss": 410592657221632.0, "training_acc": 45.0, "val_loss": 727095808000.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 4204758597632.0, "training_acc": 51.0, "val_loss": 84827980800.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 331507279872.0, "training_acc": 47.0, "val_loss": 126708441600.0, "val_acc": 48.0}
{"epoch": 10, "training_loss": 422225597440.0, "training_acc": 47.0, "val_loss": 16432862400.0, "val_acc": 48.0}
{"epoch": 11, "training_loss": 49503588320.0, "training_acc": 47.0, "val_loss": 3482093977600.0, "val_acc": 52.0}
{"epoch": 12, "training_loss": 10248223215616.0, "training_acc": 43.0, "val_loss": 809857280000.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2413934466048.0, "training_acc": 47.0, "val_loss": 86646316800.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 252461216000.0, "training_acc": 47.0, "val_loss": 12055177600.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 503948793856.0, "training_acc": 47.0, "val_loss": 277938304000.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 768084100160.0, "training_acc": 47.0, "val_loss": 12265598400.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 57784334080.0, "training_acc": 43.0, "val_loss": 18230595200.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 57125992320.0, "training_acc": 47.0, "val_loss": 2421054400.0, "val_acc": 52.0}
{"epoch": 19, "training_loss": 19204265728.0, "training_acc": 61.0, "val_loss": 1207320000.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 41472164608.0, "training_acc": 43.0, "val_loss": 3382892000.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 11674155104.0, "training_acc": 53.0, "val_loss": 6170053600.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 17253829920.0, "training_acc": 53.0, "val_loss": 2160117000.0, "val_acc": 48.0}
{"epoch": 23, "training_loss": 9045793664.0, "training_acc": 57.0, "val_loss": 1524717900.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 15135590272.0, "training_acc": 49.0, "val_loss": 351080499200.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 579149610352640.0, "training_acc": 47.0, "val_loss": 647487795200.0, "val_acc": 52.0}
{"epoch": 26, "training_loss": 9233911673782272.0, "training_acc": 53.0, "val_loss": 230505497600.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 24720445014016.0, "training_acc": 51.0, "val_loss": 3348726784000.0, "val_acc": 48.0}
{"epoch": 28, "training_loss": 51739577286656.0, "training_acc": 47.0, "val_loss": 72288744243200.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 223339249664000.0, "training_acc": 47.0, "val_loss": 27789600358400.0, "val_acc": 48.0}
{"epoch": 30, "training_loss": 89575515750400.0, "training_acc": 47.0, "val_loss": 1565466828800.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4757717032960.0, "training_acc": 47.0, "val_loss": 624905216000.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2240433258496.0, "training_acc": 47.0, "val_loss": 1.36068061986816e+16, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3.488130115580723e+16, "training_acc": 47.0, "val_loss": 1093412795187200.0, "val_acc": 48.0}
{"epoch": 34, "training_loss": 6.463925002017178e+16, "training_acc": 47.0, "val_loss": 6794832458547200.0, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1.75042460647424e+16, "training_acc": 51.0, "val_loss": 184199086080000.0, "val_acc": 48.0}
{"epoch": 36, "training_loss": 498573773373440.0, "training_acc": 47.0, "val_loss": 2.67491603382272e+16, "val_acc": 52.0}
{"epoch": 37, "training_loss": 5.795860611229286e+16, "training_acc": 59.0, "val_loss": 51751554252800.0, "val_acc": 48.0}
{"epoch": 38, "training_loss": 181451823251456.0, "training_acc": 49.0, "val_loss": 894863356723200.0, "val_acc": 48.0}
