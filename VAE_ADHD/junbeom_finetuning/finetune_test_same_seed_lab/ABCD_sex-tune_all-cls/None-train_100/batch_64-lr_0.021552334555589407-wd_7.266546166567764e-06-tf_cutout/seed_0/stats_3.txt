"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 101.30624675750732, "training_acc": 52.0, "val_loss": 9.826187643071339e+21, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2.6019166292970115e+22, "training_acc": 47.0, "val_loss": 4633075200.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 18936414208.0, "training_acc": 47.0, "val_loss": 735476200.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4091792176.0, "training_acc": 47.0, "val_loss": 3534721200.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 9726480388.0, "training_acc": 45.0, "val_loss": 87599518.75, "val_acc": 48.0}
{"epoch": 5, "training_loss": 295085983.0, "training_acc": 47.0, "val_loss": 177702175.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1133302480.0, "training_acc": 53.0, "val_loss": 117909850.0, "val_acc": 48.0}
{"epoch": 7, "training_loss": 852981576.0, "training_acc": 45.0, "val_loss": 789512950.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2394689084.0, "training_acc": 47.0, "val_loss": 358463500.0, "val_acc": 48.0}
{"epoch": 9, "training_loss": 995232569.0, "training_acc": 47.0, "val_loss": 26017287.5, "val_acc": 48.0}
{"epoch": 10, "training_loss": 578808220.0, "training_acc": 43.0, "val_loss": 112271487.5, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1610090944.0, "training_acc": 55.0, "val_loss": 5248551.953125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 44684936.25, "training_acc": 43.0, "val_loss": 247782575.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 652894886.5625, "training_acc": 53.0, "val_loss": 17970381.25, "val_acc": 48.0}
{"epoch": 14, "training_loss": 68896327.25, "training_acc": 47.0, "val_loss": 2655581.4453125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 45330514.0, "training_acc": 47.0, "val_loss": 9323685.15625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 88569849.5, "training_acc": 45.0, "val_loss": 9439578.90625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 92901989.5, "training_acc": 47.0, "val_loss": 216649850.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 678884598.0, "training_acc": 55.0, "val_loss": 22853475.0, "val_acc": 48.0}
{"epoch": 19, "training_loss": 200965475.0, "training_acc": 47.0, "val_loss": 73788200.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 256125160.5, "training_acc": 53.0, "val_loss": 39825156.25, "val_acc": 52.0}
{"epoch": 21, "training_loss": 106417936.5, "training_acc": 53.0, "val_loss": 302022625.0, "val_acc": 52.0}
{"epoch": 22, "training_loss": 917967031552.0, "training_acc": 49.0, "val_loss": 267335859200.0, "val_acc": 52.0}
{"epoch": 23, "training_loss": 688450274864.0, "training_acc": 45.0, "val_loss": 200526784000.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 16124265562112.0, "training_acc": 47.0, "val_loss": 5393739200.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 12974234306.0, "training_acc": 53.0, "val_loss": 1910160600.0, "val_acc": 52.0}
{"epoch": 26, "training_loss": 10814564021760.0, "training_acc": 53.0, "val_loss": 5393784800.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2855798124544.0, "training_acc": 53.0, "val_loss": 7524802400.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 457782411264.0, "training_acc": 53.0, "val_loss": 253996825600.0, "val_acc": 48.0}
{"epoch": 29, "training_loss": 575898011648.0, "training_acc": 47.0, "val_loss": 16447012800.0, "val_acc": 48.0}
{"epoch": 30, "training_loss": 814385651712.0, "training_acc": 53.0, "val_loss": 467107225600.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1399716251648.0, "training_acc": 53.0, "val_loss": 1579327795200.0, "val_acc": 52.0}
{"epoch": 32, "training_loss": 4287662534656.0, "training_acc": 49.0, "val_loss": 622172876800.0, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1761320206336.0, "training_acc": 51.0, "val_loss": 20686790400.0, "val_acc": 48.0}
