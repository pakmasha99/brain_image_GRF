"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.04887104034424, "training_acc": 56.0, "val_loss": 17.34275221824646, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.37988948822021, "training_acc": 43.0, "val_loss": 17.342792451381683, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.3220443725586, "training_acc": 47.0, "val_loss": 17.341698706150055, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.33616876602173, "training_acc": 52.0, "val_loss": 17.340722680091858, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.32242250442505, "training_acc": 49.0, "val_loss": 17.339587211608887, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.31463599205017, "training_acc": 51.0, "val_loss": 17.338380217552185, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2817816734314, "training_acc": 50.0, "val_loss": 17.337554693222046, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29196572303772, "training_acc": 54.0, "val_loss": 17.337045073509216, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3295271396637, "training_acc": 43.0, "val_loss": 17.33657568693161, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.28799962997437, "training_acc": 57.0, "val_loss": 17.33572483062744, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28966188430786, "training_acc": 53.0, "val_loss": 17.335273325443268, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.30369400978088, "training_acc": 54.0, "val_loss": 17.334550619125366, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.26147270202637, "training_acc": 55.0, "val_loss": 17.33379364013672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.29101490974426, "training_acc": 52.0, "val_loss": 17.33296513557434, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.25070571899414, "training_acc": 53.0, "val_loss": 17.33207106590271, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29501080513, "training_acc": 53.0, "val_loss": 17.331016063690186, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.24038243293762, "training_acc": 53.0, "val_loss": 17.33030676841736, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2756290435791, "training_acc": 53.0, "val_loss": 17.329762876033783, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.28188276290894, "training_acc": 53.0, "val_loss": 17.32899099588394, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.25982689857483, "training_acc": 53.0, "val_loss": 17.328481376171112, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21489715576172, "training_acc": 53.0, "val_loss": 17.327897250652313, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22199273109436, "training_acc": 53.0, "val_loss": 17.327186465263367, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25227212905884, "training_acc": 53.0, "val_loss": 17.326483130455017, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.25453662872314, "training_acc": 53.0, "val_loss": 17.325785756111145, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.27381038665771, "training_acc": 53.0, "val_loss": 17.32506901025772, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.2043604850769, "training_acc": 53.0, "val_loss": 17.324267327785492, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22838616371155, "training_acc": 53.0, "val_loss": 17.323729395866394, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18679690361023, "training_acc": 53.0, "val_loss": 17.32322722673416, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.20929217338562, "training_acc": 53.0, "val_loss": 17.322582006454468, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24163174629211, "training_acc": 53.0, "val_loss": 17.322084307670593, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18993067741394, "training_acc": 53.0, "val_loss": 17.321425676345825, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15964365005493, "training_acc": 53.0, "val_loss": 17.320632934570312, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.20208048820496, "training_acc": 53.0, "val_loss": 17.320244014263153, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.24527359008789, "training_acc": 53.0, "val_loss": 17.319899797439575, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.21931314468384, "training_acc": 53.0, "val_loss": 17.31957197189331, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20622038841248, "training_acc": 53.0, "val_loss": 17.319194972515106, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.18081068992615, "training_acc": 53.0, "val_loss": 17.318862676620483, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.19533658027649, "training_acc": 53.0, "val_loss": 17.31835901737213, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.18318510055542, "training_acc": 53.0, "val_loss": 17.318065464496613, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1982581615448, "training_acc": 53.0, "val_loss": 17.317716777324677, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.20336365699768, "training_acc": 53.0, "val_loss": 17.31744110584259, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18862915039062, "training_acc": 53.0, "val_loss": 17.317111790180206, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13343787193298, "training_acc": 53.0, "val_loss": 17.316852509975433, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.19893622398376, "training_acc": 53.0, "val_loss": 17.316649854183197, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.21063113212585, "training_acc": 53.0, "val_loss": 17.31642484664917, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17885518074036, "training_acc": 53.0, "val_loss": 17.31620579957962, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.17463541030884, "training_acc": 53.0, "val_loss": 17.316004633903503, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17232060432434, "training_acc": 53.0, "val_loss": 17.315757274627686, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13773083686829, "training_acc": 53.0, "val_loss": 17.315588891506195, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.16054606437683, "training_acc": 53.0, "val_loss": 17.31528788805008, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13907933235168, "training_acc": 53.0, "val_loss": 17.315226793289185, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.16811871528625, "training_acc": 53.0, "val_loss": 17.31504797935486, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.16820073127747, "training_acc": 53.0, "val_loss": 17.314977943897247, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.15667748451233, "training_acc": 53.0, "val_loss": 17.314906418323517, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.18160629272461, "training_acc": 53.0, "val_loss": 17.314720153808594, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.13952708244324, "training_acc": 53.0, "val_loss": 17.314600944519043, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.14115643501282, "training_acc": 53.0, "val_loss": 17.314429581165314, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15574979782104, "training_acc": 53.0, "val_loss": 17.314495146274567, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.17110180854797, "training_acc": 53.0, "val_loss": 17.314250767230988, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.15553379058838, "training_acc": 53.0, "val_loss": 17.314136028289795, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.16451668739319, "training_acc": 53.0, "val_loss": 17.31407195329666, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.16795682907104, "training_acc": 53.0, "val_loss": 17.31400489807129, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.09535765647888, "training_acc": 53.0, "val_loss": 17.313963174819946, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.17904281616211, "training_acc": 53.0, "val_loss": 17.31405407190323, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.10125303268433, "training_acc": 53.0, "val_loss": 17.313745617866516, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.09697556495667, "training_acc": 53.0, "val_loss": 17.31376200914383, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.13180994987488, "training_acc": 53.0, "val_loss": 17.313502728939056, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.16443657875061, "training_acc": 53.0, "val_loss": 17.313605546951294, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.13824892044067, "training_acc": 53.0, "val_loss": 17.313535511493683, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.09030175209045, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.11569547653198, "training_acc": 53.0, "val_loss": 17.31361746788025, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.15014314651489, "training_acc": 53.0, "val_loss": 17.31352210044861, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.17117643356323, "training_acc": 53.0, "val_loss": 17.313535511493683, "val_acc": 52.0}
{"epoch": 73, "training_loss": 69.11209225654602, "training_acc": 53.0, "val_loss": 17.313674092292786, "val_acc": 52.0}
{"epoch": 74, "training_loss": 69.14769792556763, "training_acc": 53.0, "val_loss": 17.31375902891159, "val_acc": 52.0}
{"epoch": 75, "training_loss": 69.15240406990051, "training_acc": 53.0, "val_loss": 17.3136904835701, "val_acc": 52.0}
{"epoch": 76, "training_loss": 69.14777445793152, "training_acc": 53.0, "val_loss": 17.313751578330994, "val_acc": 52.0}
{"epoch": 77, "training_loss": 69.07792496681213, "training_acc": 53.0, "val_loss": 17.313724756240845, "val_acc": 52.0}
{"epoch": 78, "training_loss": 69.13587546348572, "training_acc": 53.0, "val_loss": 17.313827574253082, "val_acc": 52.0}
{"epoch": 79, "training_loss": 69.17060017585754, "training_acc": 53.0, "val_loss": 17.313827574253082, "val_acc": 52.0}
{"epoch": 80, "training_loss": 69.11751651763916, "training_acc": 53.0, "val_loss": 17.313861846923828, "val_acc": 52.0}
{"epoch": 81, "training_loss": 69.10403418540955, "training_acc": 53.0, "val_loss": 17.3138290643692, "val_acc": 52.0}
{"epoch": 82, "training_loss": 69.13898038864136, "training_acc": 53.0, "val_loss": 17.313838005065918, "val_acc": 52.0}
{"epoch": 83, "training_loss": 69.10709428787231, "training_acc": 53.0, "val_loss": 17.313896119594574, "val_acc": 52.0}
{"epoch": 84, "training_loss": 69.13540577888489, "training_acc": 53.0, "val_loss": 17.313888669013977, "val_acc": 52.0}
{"epoch": 85, "training_loss": 69.1500129699707, "training_acc": 53.0, "val_loss": 17.31393039226532, "val_acc": 52.0}
