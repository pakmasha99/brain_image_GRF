"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.65525674819946, "training_acc": 52.0, "val_loss": 17.18810796737671, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.78054404258728, "training_acc": 52.0, "val_loss": 17.187052965164185, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.79739737510681, "training_acc": 52.0, "val_loss": 17.185893654823303, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.76411771774292, "training_acc": 52.0, "val_loss": 17.184829711914062, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.69430947303772, "training_acc": 52.0, "val_loss": 17.183545231819153, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.7056450843811, "training_acc": 52.0, "val_loss": 17.182521522045135, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.72507810592651, "training_acc": 52.0, "val_loss": 17.18132495880127, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.71907138824463, "training_acc": 52.0, "val_loss": 17.180313169956207, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.68421292304993, "training_acc": 52.0, "val_loss": 17.17943549156189, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.70570468902588, "training_acc": 52.0, "val_loss": 17.178474366664886, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.62100672721863, "training_acc": 52.0, "val_loss": 17.177557945251465, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.67733788490295, "training_acc": 52.0, "val_loss": 17.176780104637146, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.6558210849762, "training_acc": 52.0, "val_loss": 17.176048457622528, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.58714604377747, "training_acc": 52.0, "val_loss": 17.175322771072388, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.60853505134583, "training_acc": 52.0, "val_loss": 17.174676060676575, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.58480882644653, "training_acc": 52.0, "val_loss": 17.174185812473297, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.61082863807678, "training_acc": 52.0, "val_loss": 17.173568904399872, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.60175347328186, "training_acc": 52.0, "val_loss": 17.173300683498383, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.53865599632263, "training_acc": 52.0, "val_loss": 17.17263013124466, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.5593101978302, "training_acc": 52.0, "val_loss": 17.17248558998108, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.51940703392029, "training_acc": 52.0, "val_loss": 17.172005772590637, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.50771832466125, "training_acc": 52.0, "val_loss": 17.17178076505661, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.54176449775696, "training_acc": 52.0, "val_loss": 17.171576619148254, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.51441383361816, "training_acc": 52.0, "val_loss": 17.171409726142883, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.5025246143341, "training_acc": 52.0, "val_loss": 17.171289026737213, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.49121451377869, "training_acc": 52.0, "val_loss": 17.170913517475128, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.48656988143921, "training_acc": 52.0, "val_loss": 17.171084880828857, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.49725532531738, "training_acc": 52.0, "val_loss": 17.170913517475128, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.40380430221558, "training_acc": 52.0, "val_loss": 17.17090606689453, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.4854109287262, "training_acc": 52.0, "val_loss": 17.170913517475128, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.4390115737915, "training_acc": 52.0, "val_loss": 17.171134054660797, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.47930932044983, "training_acc": 52.0, "val_loss": 17.171071469783783, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.43853378295898, "training_acc": 52.0, "val_loss": 17.171233892440796, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.3855345249176, "training_acc": 52.0, "val_loss": 17.171332240104675, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.37195014953613, "training_acc": 52.0, "val_loss": 17.17144548892975, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.44824886322021, "training_acc": 52.0, "val_loss": 17.17175841331482, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.39513874053955, "training_acc": 52.0, "val_loss": 17.17190146446228, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.44792866706848, "training_acc": 52.0, "val_loss": 17.172186076641083, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.3453266620636, "training_acc": 52.0, "val_loss": 17.172428965568542, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.37034630775452, "training_acc": 52.0, "val_loss": 17.172598838806152, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.3567521572113, "training_acc": 52.0, "val_loss": 17.17277616262436, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.39674234390259, "training_acc": 52.0, "val_loss": 17.173074185848236, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.39763355255127, "training_acc": 52.0, "val_loss": 17.17333495616913, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.36567783355713, "training_acc": 52.0, "val_loss": 17.1735480427742, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.38132190704346, "training_acc": 52.0, "val_loss": 17.173931002616882, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.35699462890625, "training_acc": 52.0, "val_loss": 17.174461483955383, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.36879587173462, "training_acc": 52.0, "val_loss": 17.174798250198364, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.33171558380127, "training_acc": 52.0, "val_loss": 17.17529296875, "val_acc": 56.0}
