"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 235.2921905517578, "training_acc": 50.0, "val_loss": 94793.32885742188, "val_acc": 56.0}
{"epoch": 1, "training_loss": 269282.12145996094, "training_acc": 52.0, "val_loss": 1243.795394897461, "val_acc": 44.0}
{"epoch": 2, "training_loss": 3282.267023086548, "training_acc": 48.0, "val_loss": 21.007616817951202, "val_acc": 44.0}
{"epoch": 3, "training_loss": 89.95690774917603, "training_acc": 46.0, "val_loss": 18.203382194042206, "val_acc": 56.0}
{"epoch": 4, "training_loss": 93.68848276138306, "training_acc": 50.0, "val_loss": 18.078415095806122, "val_acc": 56.0}
{"epoch": 5, "training_loss": 81.81235146522522, "training_acc": 52.0, "val_loss": 17.223742604255676, "val_acc": 56.0}
{"epoch": 6, "training_loss": 71.80362486839294, "training_acc": 50.0, "val_loss": 18.924354016780853, "val_acc": 44.0}
{"epoch": 7, "training_loss": 71.94198656082153, "training_acc": 48.0, "val_loss": 17.14819371700287, "val_acc": 56.0}
{"epoch": 8, "training_loss": 72.41984868049622, "training_acc": 52.0, "val_loss": 17.15390533208847, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.36942625045776, "training_acc": 52.0, "val_loss": 17.676588892936707, "val_acc": 56.0}
{"epoch": 10, "training_loss": 70.15022706985474, "training_acc": 48.0, "val_loss": 17.61065423488617, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.78507995605469, "training_acc": 48.0, "val_loss": 17.257842421531677, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.44659543037415, "training_acc": 52.0, "val_loss": 17.182891070842743, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.34250950813293, "training_acc": 52.0, "val_loss": 17.240437865257263, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.27049565315247, "training_acc": 52.0, "val_loss": 17.2214537858963, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.26535177230835, "training_acc": 52.0, "val_loss": 17.179179191589355, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.34302139282227, "training_acc": 52.0, "val_loss": 17.16010570526123, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.34042954444885, "training_acc": 52.0, "val_loss": 17.209850251674652, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.26377415657043, "training_acc": 52.0, "val_loss": 17.27273017168045, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26401448249817, "training_acc": 52.0, "val_loss": 17.28612929582596, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2876250743866, "training_acc": 52.0, "val_loss": 17.27268546819687, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24691843986511, "training_acc": 52.0, "val_loss": 17.218470573425293, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.43027973175049, "training_acc": 52.0, "val_loss": 17.17677414417267, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.27265954017639, "training_acc": 52.0, "val_loss": 17.21469908952713, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.19645571708679, "training_acc": 52.0, "val_loss": 17.319583892822266, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.45334553718567, "training_acc": 48.0, "val_loss": 17.341667413711548, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.80688834190369, "training_acc": 38.0, "val_loss": 17.243465781211853, "val_acc": 56.0}
