"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 424.0034294128418, "training_acc": 37.0, "val_loss": 285375.6591796875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 823864.9089202881, "training_acc": 53.0, "val_loss": 738.157320022583, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2014.889591217041, "training_acc": 47.0, "val_loss": 444.6615219116211, "val_acc": 52.0}
{"epoch": 3, "training_loss": 983.1524050235748, "training_acc": 53.0, "val_loss": 129.82925176620483, "val_acc": 48.0}
{"epoch": 4, "training_loss": 394.4305810928345, "training_acc": 47.0, "val_loss": 19.613245129585266, "val_acc": 48.0}
{"epoch": 5, "training_loss": 76.85642743110657, "training_acc": 49.0, "val_loss": 17.436769604682922, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.17550873756409, "training_acc": 51.0, "val_loss": 21.148313581943512, "val_acc": 52.0}
{"epoch": 7, "training_loss": 74.40143871307373, "training_acc": 53.0, "val_loss": 26.351267099380493, "val_acc": 48.0}
{"epoch": 8, "training_loss": 91.14885067939758, "training_acc": 51.0, "val_loss": 18.71003359556198, "val_acc": 52.0}
{"epoch": 9, "training_loss": 72.90356922149658, "training_acc": 53.0, "val_loss": 17.376436293125153, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.47373223304749, "training_acc": 47.0, "val_loss": 18.202900886535645, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.76289129257202, "training_acc": 47.0, "val_loss": 18.05688589811325, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.75361227989197, "training_acc": 52.0, "val_loss": 18.856456875801086, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.90169286727905, "training_acc": 53.0, "val_loss": 18.01591068506241, "val_acc": 52.0}
{"epoch": 14, "training_loss": 72.43712162971497, "training_acc": 45.0, "val_loss": 17.371103167533875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21936345100403, "training_acc": 53.0, "val_loss": 17.312772572040558, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19752645492554, "training_acc": 53.0, "val_loss": 17.31894612312317, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.37160444259644, "training_acc": 53.0, "val_loss": 17.357532680034637, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26364636421204, "training_acc": 53.0, "val_loss": 17.322345077991486, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.03093361854553, "training_acc": 41.0, "val_loss": 17.871271073818207, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.84884595870972, "training_acc": 53.0, "val_loss": 17.337344586849213, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.35513687133789, "training_acc": 53.0, "val_loss": 17.3081636428833, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.50718212127686, "training_acc": 53.0, "val_loss": 17.34197735786438, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.63414072990417, "training_acc": 53.0, "val_loss": 17.3138827085495, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20955872535706, "training_acc": 53.0, "val_loss": 17.31957644224167, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.561518907547, "training_acc": 54.0, "val_loss": 17.337501049041748, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16480255126953, "training_acc": 53.0, "val_loss": 17.414362728595734, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.3862316608429, "training_acc": 53.0, "val_loss": 17.343878746032715, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.45007848739624, "training_acc": 53.0, "val_loss": 17.317594587802887, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.34289383888245, "training_acc": 53.0, "val_loss": 17.332270741462708, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20713138580322, "training_acc": 53.0, "val_loss": 17.309390008449554, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20866131782532, "training_acc": 53.0, "val_loss": 17.309191823005676, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15539646148682, "training_acc": 53.0, "val_loss": 17.319627106189728, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.18096256256104, "training_acc": 53.0, "val_loss": 17.33134090900421, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.20774459838867, "training_acc": 53.0, "val_loss": 17.356273531913757, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.22972106933594, "training_acc": 53.0, "val_loss": 17.33556091785431, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.19072031974792, "training_acc": 53.0, "val_loss": 17.31504648923874, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.120689868927, "training_acc": 53.0, "val_loss": 17.309924960136414, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12464213371277, "training_acc": 53.0, "val_loss": 17.30905920267105, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14813351631165, "training_acc": 53.0, "val_loss": 17.311233282089233, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.23754119873047, "training_acc": 53.0, "val_loss": 17.31182038784027, "val_acc": 52.0}
