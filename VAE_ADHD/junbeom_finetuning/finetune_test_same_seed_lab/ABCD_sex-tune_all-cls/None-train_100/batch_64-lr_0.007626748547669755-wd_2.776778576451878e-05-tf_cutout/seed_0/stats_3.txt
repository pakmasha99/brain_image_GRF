"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 654.8433609008789, "training_acc": 41.0, "val_loss": 17590886400.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 37937993215.26062, "training_acc": 53.0, "val_loss": 513414.990234375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1850184.84765625, "training_acc": 47.0, "val_loss": 14119.07958984375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 161298.3779296875, "training_acc": 45.0, "val_loss": 21.88618928194046, "val_acc": 52.0}
{"epoch": 4, "training_loss": 41134.98880767822, "training_acc": 54.0, "val_loss": 5800.063323974609, "val_acc": 48.0}
{"epoch": 5, "training_loss": 15664.841510772705, "training_acc": 47.0, "val_loss": 1501.4193534851074, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4291.449311256409, "training_acc": 53.0, "val_loss": 1070.5485343933105, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2691.2708897590637, "training_acc": 51.0, "val_loss": 449.1017818450928, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1302.0189218521118, "training_acc": 47.0, "val_loss": 843.7644004821777, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2377.643642425537, "training_acc": 53.0, "val_loss": 240.09337425231934, "val_acc": 48.0}
{"epoch": 10, "training_loss": 650.7633514404297, "training_acc": 47.0, "val_loss": 206.21652603149414, "val_acc": 52.0}
{"epoch": 11, "training_loss": 703.1324405670166, "training_acc": 53.0, "val_loss": 17.391078174114227, "val_acc": 52.0}
{"epoch": 12, "training_loss": 101.20570468902588, "training_acc": 47.0, "val_loss": 33.061838150024414, "val_acc": 52.0}
{"epoch": 13, "training_loss": 110.74304437637329, "training_acc": 59.0, "val_loss": 35.66456437110901, "val_acc": 52.0}
{"epoch": 14, "training_loss": 206.68625354766846, "training_acc": 49.0, "val_loss": 31.844836473464966, "val_acc": 48.0}
{"epoch": 15, "training_loss": 254.94643211364746, "training_acc": 39.0, "val_loss": 20.979902148246765, "val_acc": 52.0}
{"epoch": 16, "training_loss": 131.29550457000732, "training_acc": 57.0, "val_loss": 17.813920974731445, "val_acc": 52.0}
{"epoch": 17, "training_loss": 109.96791791915894, "training_acc": 51.0, "val_loss": 18.084213137626648, "val_acc": 52.0}
{"epoch": 18, "training_loss": 111.28175163269043, "training_acc": 51.0, "val_loss": 23.90342652797699, "val_acc": 52.0}
{"epoch": 19, "training_loss": 89.72953486442566, "training_acc": 53.0, "val_loss": 116.7742371559143, "val_acc": 52.0}
{"epoch": 20, "training_loss": 354.2012701034546, "training_acc": 53.0, "val_loss": 30.754289031028748, "val_acc": 48.0}
{"epoch": 21, "training_loss": 258.5125923156738, "training_acc": 45.0, "val_loss": 17.319104075431824, "val_acc": 52.0}
{"epoch": 22, "training_loss": 154.66324424743652, "training_acc": 50.0, "val_loss": 36.60142421722412, "val_acc": 52.0}
{"epoch": 23, "training_loss": 111.28198599815369, "training_acc": 55.0, "val_loss": 22.51572757959366, "val_acc": 48.0}
{"epoch": 24, "training_loss": 99.86822128295898, "training_acc": 55.0, "val_loss": 18.696527183055878, "val_acc": 52.0}
{"epoch": 25, "training_loss": 206.86315536499023, "training_acc": 45.0, "val_loss": 18.72889995574951, "val_acc": 52.0}
{"epoch": 26, "training_loss": 93.95842742919922, "training_acc": 53.0, "val_loss": 19.21292394399643, "val_acc": 52.0}
{"epoch": 27, "training_loss": 81.63046193122864, "training_acc": 55.0, "val_loss": 18.37032288312912, "val_acc": 48.0}
{"epoch": 28, "training_loss": 73.4001579284668, "training_acc": 55.0, "val_loss": 20.557308197021484, "val_acc": 52.0}
{"epoch": 29, "training_loss": 113.32906818389893, "training_acc": 45.0, "val_loss": 19.754232466220856, "val_acc": 52.0}
{"epoch": 30, "training_loss": 88.20708560943604, "training_acc": 53.0, "val_loss": 17.710769176483154, "val_acc": 52.0}
{"epoch": 31, "training_loss": 74.70533514022827, "training_acc": 55.0, "val_loss": 22.359775006771088, "val_acc": 48.0}
{"epoch": 32, "training_loss": 84.90097546577454, "training_acc": 47.0, "val_loss": 20.90727537870407, "val_acc": 52.0}
{"epoch": 33, "training_loss": 78.31513261795044, "training_acc": 53.0, "val_loss": 17.676343023777008, "val_acc": 52.0}
{"epoch": 34, "training_loss": 72.49257206916809, "training_acc": 47.0, "val_loss": 17.407771944999695, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.44198203086853, "training_acc": 55.0, "val_loss": 18.822351098060608, "val_acc": 52.0}
{"epoch": 36, "training_loss": 74.14965558052063, "training_acc": 53.0, "val_loss": 17.389830946922302, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.32401847839355, "training_acc": 50.0, "val_loss": 17.504699528217316, "val_acc": 52.0}
{"epoch": 38, "training_loss": 71.61909604072571, "training_acc": 39.0, "val_loss": 17.311054468154907, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.19835472106934, "training_acc": 45.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.67184019088745, "training_acc": 54.0, "val_loss": 17.96157956123352, "val_acc": 52.0}
{"epoch": 41, "training_loss": 71.32221364974976, "training_acc": 53.0, "val_loss": 17.32603758573532, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.54294633865356, "training_acc": 53.0, "val_loss": 18.059036135673523, "val_acc": 52.0}
{"epoch": 43, "training_loss": 72.25649333000183, "training_acc": 46.0, "val_loss": 17.318826913833618, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.91837763786316, "training_acc": 53.0, "val_loss": 17.519423365592957, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.88636827468872, "training_acc": 53.0, "val_loss": 17.381782829761505, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.20949244499207, "training_acc": 53.0, "val_loss": 17.310282588005066, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.81316375732422, "training_acc": 45.0, "val_loss": 17.329934239387512, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.93871140480042, "training_acc": 55.0, "val_loss": 17.476768791675568, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.71858596801758, "training_acc": 53.0, "val_loss": 17.401085793972015, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.29447531700134, "training_acc": 53.0, "val_loss": 17.390000820159912, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.9600739479065, "training_acc": 47.0, "val_loss": 17.610682547092438, "val_acc": 52.0}
{"epoch": 52, "training_loss": 70.7045738697052, "training_acc": 47.0, "val_loss": 17.598386108875275, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.97634625434875, "training_acc": 53.0, "val_loss": 18.89015883207321, "val_acc": 52.0}
{"epoch": 54, "training_loss": 73.50460624694824, "training_acc": 53.0, "val_loss": 17.312301695346832, "val_acc": 52.0}
{"epoch": 55, "training_loss": 72.82036638259888, "training_acc": 44.0, "val_loss": 17.652122676372528, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.06503224372864, "training_acc": 58.0, "val_loss": 18.08962970972061, "val_acc": 52.0}
{"epoch": 57, "training_loss": 72.00292325019836, "training_acc": 53.0, "val_loss": 18.13606172800064, "val_acc": 52.0}
{"epoch": 58, "training_loss": 72.30873155593872, "training_acc": 53.0, "val_loss": 17.50691384077072, "val_acc": 52.0}
