"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 196.34831428527832, "training_acc": 43.0, "val_loss": 1231351700.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2854887040.0469666, "training_acc": 53.0, "val_loss": 665.2795791625977, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1497.3670659065247, "training_acc": 47.0, "val_loss": 12747.83935546875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 34658.6432800293, "training_acc": 47.0, "val_loss": 534.3857288360596, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1762.7223052978516, "training_acc": 47.0, "val_loss": 159.7038745880127, "val_acc": 48.0}
{"epoch": 5, "training_loss": 600.2070293426514, "training_acc": 55.0, "val_loss": 384.4466209411621, "val_acc": 48.0}
{"epoch": 6, "training_loss": 975.9397678375244, "training_acc": 53.0, "val_loss": 226.24025344848633, "val_acc": 48.0}
{"epoch": 7, "training_loss": 751.7624568939209, "training_acc": 43.0, "val_loss": 183.67544412612915, "val_acc": 48.0}
{"epoch": 8, "training_loss": 496.91267561912537, "training_acc": 47.0, "val_loss": 59.97631549835205, "val_acc": 52.0}
{"epoch": 9, "training_loss": 4822.454681396484, "training_acc": 59.0, "val_loss": 78.22370529174805, "val_acc": 52.0}
{"epoch": 10, "training_loss": 389.01543617248535, "training_acc": 47.0, "val_loss": 396.7346668243408, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1068.9634201526642, "training_acc": 53.0, "val_loss": 1218.162727355957, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3412.062385559082, "training_acc": 47.0, "val_loss": 569.9229717254639, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1567.2190628051758, "training_acc": 53.0, "val_loss": 47.19564616680145, "val_acc": 48.0}
{"epoch": 14, "training_loss": 140.1407594680786, "training_acc": 47.0, "val_loss": 43.202781677246094, "val_acc": 52.0}
{"epoch": 15, "training_loss": 284.8122081756592, "training_acc": 57.0, "val_loss": 36.70240044593811, "val_acc": 48.0}
{"epoch": 16, "training_loss": 250.74400901794434, "training_acc": 41.0, "val_loss": 38.94779980182648, "val_acc": 52.0}
{"epoch": 17, "training_loss": 139.49415111541748, "training_acc": 53.0, "val_loss": 17.49778687953949, "val_acc": 52.0}
{"epoch": 18, "training_loss": 91.64755344390869, "training_acc": 47.0, "val_loss": 65.08501768112183, "val_acc": 52.0}
{"epoch": 19, "training_loss": 265.5611000061035, "training_acc": 53.0, "val_loss": 63.13987374305725, "val_acc": 52.0}
{"epoch": 20, "training_loss": 186.56766366958618, "training_acc": 53.0, "val_loss": 32.72163271903992, "val_acc": 48.0}
{"epoch": 21, "training_loss": 106.62884473800659, "training_acc": 49.0, "val_loss": 27.70715355873108, "val_acc": 52.0}
{"epoch": 22, "training_loss": 99.16505551338196, "training_acc": 53.0, "val_loss": 19.593445956707, "val_acc": 48.0}
{"epoch": 23, "training_loss": 78.84958720207214, "training_acc": 47.0, "val_loss": 17.380380630493164, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.78792595863342, "training_acc": 47.0, "val_loss": 17.40880161523819, "val_acc": 52.0}
{"epoch": 25, "training_loss": 76.17087960243225, "training_acc": 47.0, "val_loss": 23.035314679145813, "val_acc": 52.0}
{"epoch": 26, "training_loss": 84.98766660690308, "training_acc": 53.0, "val_loss": 17.97504723072052, "val_acc": 52.0}
{"epoch": 27, "training_loss": 73.46439695358276, "training_acc": 47.0, "val_loss": 17.50144511461258, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.50032353401184, "training_acc": 53.0, "val_loss": 19.152022898197174, "val_acc": 48.0}
{"epoch": 29, "training_loss": 102.74377298355103, "training_acc": 43.0, "val_loss": 17.343536019325256, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.40331983566284, "training_acc": 63.0, "val_loss": 21.085284650325775, "val_acc": 48.0}
{"epoch": 31, "training_loss": 80.18968892097473, "training_acc": 47.0, "val_loss": 17.701293528079987, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.54996752738953, "training_acc": 53.0, "val_loss": 17.391948401927948, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.59066033363342, "training_acc": 47.0, "val_loss": 17.443440854549408, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.02616882324219, "training_acc": 53.0, "val_loss": 17.51597970724106, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.84278798103333, "training_acc": 53.0, "val_loss": 17.470736801624298, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.91256928443909, "training_acc": 47.0, "val_loss": 17.340993881225586, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1070191860199, "training_acc": 53.0, "val_loss": 17.522935569286346, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.7476806640625, "training_acc": 53.0, "val_loss": 17.348548769950867, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.59211373329163, "training_acc": 53.0, "val_loss": 17.33401119709015, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.09362530708313, "training_acc": 54.0, "val_loss": 17.49468892812729, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.19558811187744, "training_acc": 47.0, "val_loss": 17.331402003765106, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.37719798088074, "training_acc": 53.0, "val_loss": 17.550578713417053, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.66070532798767, "training_acc": 53.0, "val_loss": 17.357034981250763, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.07282757759094, "training_acc": 43.0, "val_loss": 17.326919734477997, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.09259748458862, "training_acc": 53.0, "val_loss": 17.34967827796936, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.18391799926758, "training_acc": 53.0, "val_loss": 17.38124042749405, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.24494981765747, "training_acc": 53.0, "val_loss": 17.393840849399567, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.21366500854492, "training_acc": 53.0, "val_loss": 17.337587475776672, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.25133204460144, "training_acc": 53.0, "val_loss": 17.333732545375824, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.24967408180237, "training_acc": 55.0, "val_loss": 17.330394685268402, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.23420763015747, "training_acc": 53.0, "val_loss": 17.33722686767578, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.18251967430115, "training_acc": 53.0, "val_loss": 17.373256385326385, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.25827813148499, "training_acc": 53.0, "val_loss": 17.43982285261154, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.4698395729065, "training_acc": 53.0, "val_loss": 17.39606410264969, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.27012085914612, "training_acc": 53.0, "val_loss": 17.35806167125702, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.02508401870728, "training_acc": 53.0, "val_loss": 17.327462136745453, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.26251292228699, "training_acc": 55.0, "val_loss": 17.380431294441223, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.44840931892395, "training_acc": 46.0, "val_loss": 17.393779754638672, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.67090249061584, "training_acc": 47.0, "val_loss": 17.356353998184204, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.24224209785461, "training_acc": 47.0, "val_loss": 17.33711212873459, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.05215191841125, "training_acc": 53.0, "val_loss": 17.412839829921722, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.31184506416321, "training_acc": 53.0, "val_loss": 17.453530430793762, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.50240325927734, "training_acc": 53.0, "val_loss": 17.44270622730255, "val_acc": 52.0}
