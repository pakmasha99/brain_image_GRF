"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 414.0313720703125, "training_acc": 50.0, "val_loss": 175143450.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 472260668.9995117, "training_acc": 52.0, "val_loss": 111295.41015625, "val_acc": 44.0}
{"epoch": 2, "training_loss": 282803.33197021484, "training_acc": 48.0, "val_loss": 8569.878387451172, "val_acc": 56.0}
{"epoch": 3, "training_loss": 22189.88226222992, "training_acc": 52.0, "val_loss": 29227.349853515625, "val_acc": 44.0}
{"epoch": 4, "training_loss": 70404.43072509766, "training_acc": 48.0, "val_loss": 17.14211106300354, "val_acc": 56.0}
{"epoch": 5, "training_loss": 355.7973442077637, "training_acc": 52.0, "val_loss": 30.80914318561554, "val_acc": 56.0}
{"epoch": 6, "training_loss": 161.87809562683105, "training_acc": 50.0, "val_loss": 542.7099704742432, "val_acc": 56.0}
{"epoch": 7, "training_loss": 1701.1467838287354, "training_acc": 48.0, "val_loss": 130.35714626312256, "val_acc": 44.0}
{"epoch": 8, "training_loss": 698.7959938049316, "training_acc": 42.0, "val_loss": 89.07613158226013, "val_acc": 44.0}
{"epoch": 9, "training_loss": 274.76823902130127, "training_acc": 48.0, "val_loss": 48.607829213142395, "val_acc": 44.0}
{"epoch": 10, "training_loss": 146.56670784950256, "training_acc": 50.0, "val_loss": 27.43036150932312, "val_acc": 44.0}
{"epoch": 11, "training_loss": 127.97260522842407, "training_acc": 48.0, "val_loss": 17.2369584441185, "val_acc": 56.0}
{"epoch": 12, "training_loss": 75.38404154777527, "training_acc": 49.0, "val_loss": 17.193736135959625, "val_acc": 56.0}
{"epoch": 13, "training_loss": 71.6148829460144, "training_acc": 52.0, "val_loss": 17.814499139785767, "val_acc": 56.0}
{"epoch": 14, "training_loss": 71.3482620716095, "training_acc": 48.0, "val_loss": 23.00097644329071, "val_acc": 56.0}
{"epoch": 15, "training_loss": 103.14116144180298, "training_acc": 46.0, "val_loss": 21.967963874340057, "val_acc": 56.0}
{"epoch": 16, "training_loss": 84.0562789440155, "training_acc": 50.0, "val_loss": 23.86597841978073, "val_acc": 44.0}
{"epoch": 17, "training_loss": 82.68793225288391, "training_acc": 50.0, "val_loss": 17.21869260072708, "val_acc": 56.0}
{"epoch": 18, "training_loss": 79.81091284751892, "training_acc": 50.0, "val_loss": 26.697537302970886, "val_acc": 56.0}
{"epoch": 19, "training_loss": 99.95242619514465, "training_acc": 52.0, "val_loss": 27.35941708087921, "val_acc": 44.0}
{"epoch": 20, "training_loss": 93.18205714225769, "training_acc": 48.0, "val_loss": 17.516744136810303, "val_acc": 56.0}
{"epoch": 21, "training_loss": 72.71699452400208, "training_acc": 52.0, "val_loss": 17.383265495300293, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.58800935745239, "training_acc": 43.0, "val_loss": 19.559741020202637, "val_acc": 44.0}
{"epoch": 23, "training_loss": 76.74344372749329, "training_acc": 46.0, "val_loss": 17.400367558002472, "val_acc": 56.0}
