"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 252.16979217529297, "training_acc": 52.0, "val_loss": 8985687200.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 22568392053.00476, "training_acc": 47.0, "val_loss": 244532.6416015625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 701108.8408203125, "training_acc": 53.0, "val_loss": 19480.807495117188, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73641.8759765625, "training_acc": 51.0, "val_loss": 12976.580810546875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 37233.46887207031, "training_acc": 53.0, "val_loss": 4388.154220581055, "val_acc": 48.0}
{"epoch": 5, "training_loss": 12596.794654846191, "training_acc": 47.0, "val_loss": 148.033607006073, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1702.074935913086, "training_acc": 51.0, "val_loss": 683.232307434082, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2251.0901679992676, "training_acc": 49.0, "val_loss": 496.38471603393555, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1206.8904566764832, "training_acc": 53.0, "val_loss": 475.0763416290283, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1481.4738121032715, "training_acc": 45.0, "val_loss": 172.83167839050293, "val_acc": 52.0}
{"epoch": 10, "training_loss": 741.6870651245117, "training_acc": 53.0, "val_loss": 178.7636637687683, "val_acc": 52.0}
{"epoch": 11, "training_loss": 792.4703559875488, "training_acc": 47.0, "val_loss": 18.157024681568146, "val_acc": 52.0}
{"epoch": 12, "training_loss": 577.582649230957, "training_acc": 49.0, "val_loss": 124.54497814178467, "val_acc": 52.0}
{"epoch": 13, "training_loss": 431.98997020721436, "training_acc": 51.0, "val_loss": 84.896719455719, "val_acc": 48.0}
{"epoch": 14, "training_loss": 266.1712303161621, "training_acc": 49.0, "val_loss": 33.57782959938049, "val_acc": 52.0}
{"epoch": 15, "training_loss": 131.80120515823364, "training_acc": 53.0, "val_loss": 26.718509197235107, "val_acc": 48.0}
{"epoch": 16, "training_loss": 109.51926708221436, "training_acc": 53.0, "val_loss": 34.89376604557037, "val_acc": 52.0}
{"epoch": 17, "training_loss": 117.35102081298828, "training_acc": 53.0, "val_loss": 25.148963928222656, "val_acc": 48.0}
{"epoch": 18, "training_loss": 99.52681851387024, "training_acc": 49.0, "val_loss": 21.87332510948181, "val_acc": 52.0}
{"epoch": 19, "training_loss": 87.94364213943481, "training_acc": 49.0, "val_loss": 19.867447018623352, "val_acc": 48.0}
{"epoch": 20, "training_loss": 81.6165862083435, "training_acc": 47.0, "val_loss": 20.327475666999817, "val_acc": 52.0}
{"epoch": 21, "training_loss": 75.6419312953949, "training_acc": 49.0, "val_loss": 20.319093763828278, "val_acc": 48.0}
{"epoch": 22, "training_loss": 78.79561996459961, "training_acc": 47.0, "val_loss": 30.827397108078003, "val_acc": 52.0}
{"epoch": 23, "training_loss": 91.7048089504242, "training_acc": 54.0, "val_loss": 19.526483118534088, "val_acc": 48.0}
{"epoch": 24, "training_loss": 82.14706110954285, "training_acc": 45.0, "val_loss": 23.788587749004364, "val_acc": 48.0}
{"epoch": 25, "training_loss": 90.60922908782959, "training_acc": 47.0, "val_loss": 18.160197138786316, "val_acc": 52.0}
{"epoch": 26, "training_loss": 74.44040966033936, "training_acc": 53.0, "val_loss": 20.84946185350418, "val_acc": 52.0}
{"epoch": 27, "training_loss": 76.46555685997009, "training_acc": 53.0, "val_loss": 19.932536780834198, "val_acc": 48.0}
{"epoch": 28, "training_loss": 79.72445774078369, "training_acc": 47.0, "val_loss": 17.54480004310608, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.01540851593018, "training_acc": 56.0, "val_loss": 19.49189454317093, "val_acc": 52.0}
{"epoch": 30, "training_loss": 75.90294241905212, "training_acc": 53.0, "val_loss": 17.426832020282745, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.26804065704346, "training_acc": 55.0, "val_loss": 18.451698124408722, "val_acc": 48.0}
{"epoch": 32, "training_loss": 73.31292724609375, "training_acc": 47.0, "val_loss": 17.35847443342209, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2858362197876, "training_acc": 55.0, "val_loss": 17.919276654720306, "val_acc": 52.0}
{"epoch": 34, "training_loss": 74.73149681091309, "training_acc": 40.0, "val_loss": 17.37191677093506, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.51744174957275, "training_acc": 53.0, "val_loss": 17.596089839935303, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.81491804122925, "training_acc": 49.0, "val_loss": 17.341549694538116, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70.11143469810486, "training_acc": 43.0, "val_loss": 17.525102198123932, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.49680280685425, "training_acc": 53.0, "val_loss": 17.82870888710022, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.77203011512756, "training_acc": 53.0, "val_loss": 17.389515042304993, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.38607454299927, "training_acc": 51.0, "val_loss": 17.795252799987793, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.82829809188843, "training_acc": 48.0, "val_loss": 17.765718698501587, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.82576870918274, "training_acc": 53.0, "val_loss": 17.606520652770996, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.72538900375366, "training_acc": 54.0, "val_loss": 17.780157923698425, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.94010734558105, "training_acc": 47.0, "val_loss": 17.344659566879272, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.25453305244446, "training_acc": 52.0, "val_loss": 17.764712870121002, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.97150444984436, "training_acc": 53.0, "val_loss": 17.358963191509247, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.61200737953186, "training_acc": 42.0, "val_loss": 17.577049136161804, "val_acc": 52.0}
{"epoch": 48, "training_loss": 70.47547459602356, "training_acc": 45.0, "val_loss": 17.394202947616577, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.41920161247253, "training_acc": 53.0, "val_loss": 17.347458004951477, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.49886393547058, "training_acc": 51.0, "val_loss": 17.36530065536499, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.33322763442993, "training_acc": 49.0, "val_loss": 17.340241372585297, "val_acc": 52.0}
{"epoch": 52, "training_loss": 71.50220036506653, "training_acc": 54.0, "val_loss": 17.444708943367004, "val_acc": 52.0}
{"epoch": 53, "training_loss": 70.5391457080841, "training_acc": 47.0, "val_loss": 17.57735013961792, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.08989071846008, "training_acc": 49.0, "val_loss": 17.527543008327484, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.16152286529541, "training_acc": 53.0, "val_loss": 17.875079810619354, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.55808091163635, "training_acc": 53.0, "val_loss": 17.416879534721375, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.5859637260437, "training_acc": 51.0, "val_loss": 17.68370419740677, "val_acc": 52.0}
{"epoch": 58, "training_loss": 70.80619144439697, "training_acc": 49.0, "val_loss": 17.84847527742386, "val_acc": 52.0}
{"epoch": 59, "training_loss": 71.09039282798767, "training_acc": 53.0, "val_loss": 17.548294365406036, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.81999516487122, "training_acc": 53.0, "val_loss": 17.370115220546722, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.44128346443176, "training_acc": 46.0, "val_loss": 17.327764630317688, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.13265299797058, "training_acc": 60.0, "val_loss": 17.35422909259796, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.8101601600647, "training_acc": 48.0, "val_loss": 17.342106997966766, "val_acc": 52.0}
{"epoch": 64, "training_loss": 68.94298076629639, "training_acc": 53.0, "val_loss": 17.5480917096138, "val_acc": 52.0}
{"epoch": 65, "training_loss": 70.63824152946472, "training_acc": 53.0, "val_loss": 17.318810522556305, "val_acc": 52.0}
{"epoch": 66, "training_loss": 68.99266290664673, "training_acc": 55.0, "val_loss": 17.90604144334793, "val_acc": 52.0}
{"epoch": 67, "training_loss": 71.74745488166809, "training_acc": 47.0, "val_loss": 17.47686117887497, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.54169011116028, "training_acc": 53.0, "val_loss": 18.852615356445312, "val_acc": 52.0}
{"epoch": 69, "training_loss": 72.80029296875, "training_acc": 53.0, "val_loss": 17.506462335586548, "val_acc": 52.0}
{"epoch": 70, "training_loss": 71.54769253730774, "training_acc": 45.0, "val_loss": 20.096370577812195, "val_acc": 48.0}
{"epoch": 71, "training_loss": 78.24299311637878, "training_acc": 47.0, "val_loss": 17.337287962436676, "val_acc": 52.0}
{"epoch": 72, "training_loss": 72.27901268005371, "training_acc": 53.0, "val_loss": 18.369896709918976, "val_acc": 52.0}
{"epoch": 73, "training_loss": 71.50481867790222, "training_acc": 53.0, "val_loss": 17.731407284736633, "val_acc": 52.0}
{"epoch": 74, "training_loss": 71.7783465385437, "training_acc": 47.0, "val_loss": 17.399851977825165, "val_acc": 52.0}
{"epoch": 75, "training_loss": 68.65457391738892, "training_acc": 58.0, "val_loss": 18.853899836540222, "val_acc": 52.0}
{"epoch": 76, "training_loss": 74.23173141479492, "training_acc": 53.0, "val_loss": 17.602084577083588, "val_acc": 52.0}
{"epoch": 77, "training_loss": 69.80540895462036, "training_acc": 54.0, "val_loss": 18.24328899383545, "val_acc": 52.0}
{"epoch": 78, "training_loss": 72.31833529472351, "training_acc": 47.0, "val_loss": 17.35740453004837, "val_acc": 52.0}
{"epoch": 79, "training_loss": 69.21626782417297, "training_acc": 50.0, "val_loss": 17.63683259487152, "val_acc": 52.0}
{"epoch": 80, "training_loss": 69.5170681476593, "training_acc": 53.0, "val_loss": 17.343440651893616, "val_acc": 52.0}
{"epoch": 81, "training_loss": 72.15074467658997, "training_acc": 39.0, "val_loss": 17.335496842861176, "val_acc": 52.0}
{"epoch": 82, "training_loss": 70.60450768470764, "training_acc": 52.0, "val_loss": 17.836976051330566, "val_acc": 52.0}
{"epoch": 83, "training_loss": 70.24088764190674, "training_acc": 53.0, "val_loss": 17.4061119556427, "val_acc": 52.0}
{"epoch": 84, "training_loss": 69.51023983955383, "training_acc": 46.0, "val_loss": 17.496027052402496, "val_acc": 52.0}
