"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 548.0275573730469, "training_acc": 53.0, "val_loss": 9948066611200.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 27014383860572.195, "training_acc": 45.0, "val_loss": 691274.12109375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3170529.578125, "training_acc": 47.0, "val_loss": 235950.1708984375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 626572.6572265625, "training_acc": 49.0, "val_loss": 12967.977905273438, "val_acc": 52.0}
{"epoch": 4, "training_loss": 37642.99136352539, "training_acc": 53.0, "val_loss": 60686.358642578125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 147111.58197021484, "training_acc": 53.0, "val_loss": 2928.2970428466797, "val_acc": 52.0}
{"epoch": 6, "training_loss": 23420.298461914062, "training_acc": 61.0, "val_loss": 2398.8765716552734, "val_acc": 48.0}
{"epoch": 7, "training_loss": 22635.922973632812, "training_acc": 55.0, "val_loss": 12419.762420654297, "val_acc": 52.0}
{"epoch": 8, "training_loss": 39863.51281738281, "training_acc": 53.0, "val_loss": 1901.6731262207031, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3928.7341690063477, "training_acc": 63.0, "val_loss": 801.1570930480957, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2912.1337852478027, "training_acc": 47.0, "val_loss": 60.070377588272095, "val_acc": 48.0}
{"epoch": 11, "training_loss": 421.37419509887695, "training_acc": 61.0, "val_loss": 144.5381999015808, "val_acc": 52.0}
{"epoch": 12, "training_loss": 3505.1361389160156, "training_acc": 47.0, "val_loss": 229.84662055969238, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1000.3010673522949, "training_acc": 43.0, "val_loss": 609.9366188049316, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1956.6718215942383, "training_acc": 51.0, "val_loss": 345.6050395965576, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1087.3103485107422, "training_acc": 53.0, "val_loss": 257.8049898147583, "val_acc": 48.0}
{"epoch": 16, "training_loss": 961.5727424621582, "training_acc": 47.0, "val_loss": 137.34480142593384, "val_acc": 52.0}
{"epoch": 17, "training_loss": 531.7680969238281, "training_acc": 53.0, "val_loss": 28.554436564445496, "val_acc": 52.0}
{"epoch": 18, "training_loss": 325.18596267700195, "training_acc": 49.0, "val_loss": 158.18183422088623, "val_acc": 48.0}
{"epoch": 19, "training_loss": 481.1502137184143, "training_acc": 47.0, "val_loss": 111.85444593429565, "val_acc": 52.0}
{"epoch": 20, "training_loss": 445.6790523529053, "training_acc": 53.0, "val_loss": 90.66271185874939, "val_acc": 52.0}
{"epoch": 21, "training_loss": 251.3994426727295, "training_acc": 53.0, "val_loss": 74.95426535606384, "val_acc": 48.0}
{"epoch": 22, "training_loss": 326.94142055511475, "training_acc": 47.0, "val_loss": 74.37402009963989, "val_acc": 48.0}
{"epoch": 23, "training_loss": 225.61786770820618, "training_acc": 47.0, "val_loss": 63.24779987335205, "val_acc": 52.0}
{"epoch": 24, "training_loss": 250.17597007751465, "training_acc": 53.0, "val_loss": 47.69405126571655, "val_acc": 52.0}
{"epoch": 25, "training_loss": 152.4990837574005, "training_acc": 53.0, "val_loss": 33.878299593925476, "val_acc": 48.0}
{"epoch": 26, "training_loss": 135.2389030456543, "training_acc": 47.0, "val_loss": 21.62807732820511, "val_acc": 48.0}
{"epoch": 27, "training_loss": 78.03431415557861, "training_acc": 53.0, "val_loss": 26.211094856262207, "val_acc": 52.0}
{"epoch": 28, "training_loss": 101.32322645187378, "training_acc": 53.0, "val_loss": 19.954946637153625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 76.9682948589325, "training_acc": 49.0, "val_loss": 20.524051785469055, "val_acc": 48.0}
{"epoch": 30, "training_loss": 83.7708592414856, "training_acc": 47.0, "val_loss": 18.471336364746094, "val_acc": 48.0}
{"epoch": 31, "training_loss": 69.70407128334045, "training_acc": 55.0, "val_loss": 19.871295988559723, "val_acc": 52.0}
{"epoch": 32, "training_loss": 79.06256413459778, "training_acc": 53.0, "val_loss": 20.235076546669006, "val_acc": 52.0}
{"epoch": 33, "training_loss": 76.54039406776428, "training_acc": 53.0, "val_loss": 17.72921532392502, "val_acc": 52.0}
{"epoch": 34, "training_loss": 76.60881876945496, "training_acc": 47.0, "val_loss": 19.17797029018402, "val_acc": 48.0}
{"epoch": 35, "training_loss": 75.55701017379761, "training_acc": 49.0, "val_loss": 17.35205352306366, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.75061464309692, "training_acc": 41.0, "val_loss": 17.63303279876709, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.68994927406311, "training_acc": 53.0, "val_loss": 17.476923763751984, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.93522667884827, "training_acc": 52.0, "val_loss": 17.377936840057373, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.02552890777588, "training_acc": 48.0, "val_loss": 17.3514261841774, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.94878315925598, "training_acc": 57.0, "val_loss": 17.369994521141052, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.36081337928772, "training_acc": 53.0, "val_loss": 17.42926388978958, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.51385927200317, "training_acc": 54.0, "val_loss": 17.344053089618683, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.62145233154297, "training_acc": 55.0, "val_loss": 17.386451363563538, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.5913188457489, "training_acc": 47.0, "val_loss": 17.35295206308365, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.27799677848816, "training_acc": 50.0, "val_loss": 17.40162968635559, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.79877090454102, "training_acc": 53.0, "val_loss": 17.36481934785843, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.19525790214539, "training_acc": 54.0, "val_loss": 17.352698743343353, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.92052125930786, "training_acc": 52.0, "val_loss": 17.36406683921814, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.62215518951416, "training_acc": 57.0, "val_loss": 17.382587492465973, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.49631857872009, "training_acc": 47.0, "val_loss": 17.354348301887512, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.19106388092041, "training_acc": 53.0, "val_loss": 17.35036075115204, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.44111752510071, "training_acc": 50.0, "val_loss": 17.42604821920395, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.58049440383911, "training_acc": 50.0, "val_loss": 17.34691560268402, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.94263815879822, "training_acc": 52.0, "val_loss": 17.762914299964905, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.93592357635498, "training_acc": 53.0, "val_loss": 17.428632080554962, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.9740161895752, "training_acc": 46.0, "val_loss": 17.385536432266235, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.50042128562927, "training_acc": 49.0, "val_loss": 17.53769963979721, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.2022979259491, "training_acc": 53.0, "val_loss": 17.52498894929886, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.77464866638184, "training_acc": 53.0, "val_loss": 17.412014305591583, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.33993792533875, "training_acc": 45.0, "val_loss": 17.479923367500305, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.87737560272217, "training_acc": 48.0, "val_loss": 17.522647976875305, "val_acc": 52.0}
