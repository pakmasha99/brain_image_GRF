"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 164.93491077423096, "training_acc": 48.0, "val_loss": 3057.16552734375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 26842.317016601562, "training_acc": 45.0, "val_loss": 217.9365873336792, "val_acc": 52.0}
{"epoch": 2, "training_loss": 574.5159821510315, "training_acc": 53.0, "val_loss": 18.18161904811859, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73.55386781692505, "training_acc": 43.0, "val_loss": 17.357495427131653, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.47805261611938, "training_acc": 45.0, "val_loss": 19.893190264701843, "val_acc": 48.0}
{"epoch": 5, "training_loss": 78.93736982345581, "training_acc": 47.0, "val_loss": 17.437264323234558, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.37499761581421, "training_acc": 47.0, "val_loss": 17.60290116071701, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.89651608467102, "training_acc": 53.0, "val_loss": 17.330585420131683, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3739402294159, "training_acc": 47.0, "val_loss": 17.36687868833542, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.87589621543884, "training_acc": 53.0, "val_loss": 17.538990080356598, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.79441928863525, "training_acc": 53.0, "val_loss": 17.495788633823395, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.49556946754456, "training_acc": 53.0, "val_loss": 17.311249673366547, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.38241076469421, "training_acc": 43.0, "val_loss": 17.338190972805023, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.29677271842957, "training_acc": 49.0, "val_loss": 17.39053726196289, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.24828457832336, "training_acc": 53.0, "val_loss": 17.392268776893616, "val_acc": 52.0}
{"epoch": 15, "training_loss": 72.86084413528442, "training_acc": 43.0, "val_loss": 17.316608130931854, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.31574940681458, "training_acc": 49.0, "val_loss": 17.336635291576385, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.36681938171387, "training_acc": 47.0, "val_loss": 17.320042848587036, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29598307609558, "training_acc": 53.0, "val_loss": 17.30978786945343, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.27602410316467, "training_acc": 53.0, "val_loss": 17.32494831085205, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10774564743042, "training_acc": 53.0, "val_loss": 17.409083247184753, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.44923901557922, "training_acc": 53.0, "val_loss": 17.370566725730896, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1017382144928, "training_acc": 53.0, "val_loss": 17.3166885972023, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.31194281578064, "training_acc": 51.0, "val_loss": 17.359519004821777, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.44743037223816, "training_acc": 47.0, "val_loss": 17.312091588974, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12011861801147, "training_acc": 53.0, "val_loss": 17.324237525463104, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17533993721008, "training_acc": 53.0, "val_loss": 17.375366389751434, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.48396420478821, "training_acc": 53.0, "val_loss": 17.358700931072235, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.4800546169281, "training_acc": 53.0, "val_loss": 17.360764741897583, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21504068374634, "training_acc": 53.0, "val_loss": 17.39620566368103, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.37499737739563, "training_acc": 53.0, "val_loss": 17.378531396389008, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.41975498199463, "training_acc": 53.0, "val_loss": 17.323005199432373, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13355445861816, "training_acc": 53.0, "val_loss": 17.313005030155182, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.24066615104675, "training_acc": 53.0, "val_loss": 17.309047281742096, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15082550048828, "training_acc": 53.0, "val_loss": 17.311246693134308, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.12529921531677, "training_acc": 53.0, "val_loss": 17.321330308914185, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14455771446228, "training_acc": 53.0, "val_loss": 17.333483695983887, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.25614500045776, "training_acc": 53.0, "val_loss": 17.350707948207855, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.21171617507935, "training_acc": 53.0, "val_loss": 17.330840229988098, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18753147125244, "training_acc": 53.0, "val_loss": 17.319446802139282, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13193559646606, "training_acc": 53.0, "val_loss": 17.31712371110916, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18976211547852, "training_acc": 53.0, "val_loss": 17.31487661600113, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14829754829407, "training_acc": 53.0, "val_loss": 17.319150269031525, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13719844818115, "training_acc": 53.0, "val_loss": 17.31954663991928, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13744473457336, "training_acc": 53.0, "val_loss": 17.318347096443176, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1424355506897, "training_acc": 53.0, "val_loss": 17.318420112133026, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14378476142883, "training_acc": 53.0, "val_loss": 17.315684258937836, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.12842178344727, "training_acc": 53.0, "val_loss": 17.31123924255371, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.17055082321167, "training_acc": 53.0, "val_loss": 17.309299111366272, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.14931416511536, "training_acc": 53.0, "val_loss": 17.309415340423584, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.14934873580933, "training_acc": 53.0, "val_loss": 17.309673130512238, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14487075805664, "training_acc": 53.0, "val_loss": 17.310413718223572, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.14736461639404, "training_acc": 53.0, "val_loss": 17.31174886226654, "val_acc": 52.0}
