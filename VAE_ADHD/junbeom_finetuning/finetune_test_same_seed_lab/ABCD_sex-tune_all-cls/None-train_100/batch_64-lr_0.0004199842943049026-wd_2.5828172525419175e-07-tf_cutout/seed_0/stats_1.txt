"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.95797228813171, "training_acc": 47.0, "val_loss": 17.326274514198303, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16766834259033, "training_acc": 53.0, "val_loss": 17.695219814777374, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.15420341491699, "training_acc": 53.0, "val_loss": 17.387866973876953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.64985084533691, "training_acc": 53.0, "val_loss": 17.376910150051117, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.33761048316956, "training_acc": 53.0, "val_loss": 17.34504997730255, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.02035880088806, "training_acc": 53.0, "val_loss": 17.339839041233063, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.83730053901672, "training_acc": 47.0, "val_loss": 17.31623262166977, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.97760343551636, "training_acc": 53.0, "val_loss": 17.323994636535645, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.20011854171753, "training_acc": 53.0, "val_loss": 17.309081554412842, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.43322825431824, "training_acc": 53.0, "val_loss": 17.31662005186081, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.06683993339539, "training_acc": 53.0, "val_loss": 17.39066243171692, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.37614870071411, "training_acc": 53.0, "val_loss": 17.403830587863922, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.3598108291626, "training_acc": 53.0, "val_loss": 17.367573082447052, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2041163444519, "training_acc": 53.0, "val_loss": 17.31051802635193, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20787119865417, "training_acc": 53.0, "val_loss": 17.31085181236267, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18036389350891, "training_acc": 53.0, "val_loss": 17.30954945087433, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15165781974792, "training_acc": 53.0, "val_loss": 17.324523627758026, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22731065750122, "training_acc": 53.0, "val_loss": 17.357680201530457, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.27008175849915, "training_acc": 53.0, "val_loss": 17.40279793739319, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.48586964607239, "training_acc": 53.0, "val_loss": 17.348863184452057, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24151730537415, "training_acc": 53.0, "val_loss": 17.32768416404724, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22721004486084, "training_acc": 53.0, "val_loss": 17.30911433696747, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.313969373703, "training_acc": 49.0, "val_loss": 17.351733148097992, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.43994092941284, "training_acc": 47.0, "val_loss": 17.32558161020279, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.52011156082153, "training_acc": 39.0, "val_loss": 17.308391630649567, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1692578792572, "training_acc": 53.0, "val_loss": 17.40167587995529, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.3604142665863, "training_acc": 53.0, "val_loss": 17.433275282382965, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.54473876953125, "training_acc": 53.0, "val_loss": 17.37368553876877, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.32910990715027, "training_acc": 53.0, "val_loss": 17.336072027683258, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15335869789124, "training_acc": 53.0, "val_loss": 17.309199273586273, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1789333820343, "training_acc": 53.0, "val_loss": 17.32228845357895, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.61288380622864, "training_acc": 43.0, "val_loss": 17.330943048000336, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.2117657661438, "training_acc": 53.0, "val_loss": 17.313013970851898, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2451982498169, "training_acc": 53.0, "val_loss": 17.38024801015854, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.30344772338867, "training_acc": 53.0, "val_loss": 17.382624745368958, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.40781140327454, "training_acc": 53.0, "val_loss": 17.337894439697266, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1856997013092, "training_acc": 53.0, "val_loss": 17.32255667448044, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15808415412903, "training_acc": 53.0, "val_loss": 17.31482595205307, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.29545664787292, "training_acc": 53.0, "val_loss": 17.313694953918457, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18506646156311, "training_acc": 53.0, "val_loss": 17.309662699699402, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.18058967590332, "training_acc": 53.0, "val_loss": 17.310012876987457, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.17393445968628, "training_acc": 53.0, "val_loss": 17.30930805206299, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.18510150909424, "training_acc": 53.0, "val_loss": 17.32008010149002, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16035962104797, "training_acc": 53.0, "val_loss": 17.32570230960846, "val_acc": 52.0}
