"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.1702229976654, "training_acc": 53.0, "val_loss": 17.38910973072052, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.24647736549377, "training_acc": 53.0, "val_loss": 17.313051223754883, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.84721112251282, "training_acc": 53.0, "val_loss": 17.31349527835846, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.62906336784363, "training_acc": 53.0, "val_loss": 17.34340190887451, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.40661716461182, "training_acc": 47.0, "val_loss": 17.31879413127899, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25962567329407, "training_acc": 53.0, "val_loss": 17.32581853866577, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.43141174316406, "training_acc": 53.0, "val_loss": 17.32174903154373, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.40987825393677, "training_acc": 53.0, "val_loss": 17.310674488544464, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29021406173706, "training_acc": 53.0, "val_loss": 17.31807291507721, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1111798286438, "training_acc": 53.0, "val_loss": 17.376555502414703, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28428149223328, "training_acc": 53.0, "val_loss": 17.349709570407867, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.48442506790161, "training_acc": 53.0, "val_loss": 17.312511801719666, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1816942691803, "training_acc": 53.0, "val_loss": 17.321784794330597, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.50349044799805, "training_acc": 53.0, "val_loss": 17.312727868556976, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.52152609825134, "training_acc": 53.0, "val_loss": 17.32596606016159, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.27859807014465, "training_acc": 53.0, "val_loss": 17.30954647064209, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.86706590652466, "training_acc": 53.0, "val_loss": 17.321956157684326, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2449803352356, "training_acc": 53.0, "val_loss": 17.309027910232544, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.86743712425232, "training_acc": 39.0, "val_loss": 17.326682806015015, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24725413322449, "training_acc": 53.0, "val_loss": 17.308707535266876, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.37264966964722, "training_acc": 53.0, "val_loss": 17.329871654510498, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15870332717896, "training_acc": 53.0, "val_loss": 17.33204573392868, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16221761703491, "training_acc": 53.0, "val_loss": 17.327934503555298, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16608357429504, "training_acc": 53.0, "val_loss": 17.317791283130646, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14161324501038, "training_acc": 53.0, "val_loss": 17.31375902891159, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15935444831848, "training_acc": 53.0, "val_loss": 17.309217154979706, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.24087142944336, "training_acc": 53.0, "val_loss": 17.310050129890442, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17316555976868, "training_acc": 53.0, "val_loss": 17.30884164571762, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.176353931427, "training_acc": 53.0, "val_loss": 17.308829724788666, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.2512435913086, "training_acc": 53.0, "val_loss": 17.310109734535217, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14200806617737, "training_acc": 53.0, "val_loss": 17.30872094631195, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20479607582092, "training_acc": 53.0, "val_loss": 17.308728396892548, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15751004219055, "training_acc": 53.0, "val_loss": 17.31664091348648, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.28939414024353, "training_acc": 53.0, "val_loss": 17.355626821517944, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.24446225166321, "training_acc": 53.0, "val_loss": 17.34449416399002, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.19593834877014, "training_acc": 53.0, "val_loss": 17.333248257637024, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17450594902039, "training_acc": 53.0, "val_loss": 17.320816218852997, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13660073280334, "training_acc": 53.0, "val_loss": 17.31426566839218, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.31553173065186, "training_acc": 53.0, "val_loss": 17.310641705989838, "val_acc": 52.0}
