"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.21367383003235, "training_acc": 51.0, "val_loss": 17.43423044681549, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.73082828521729, "training_acc": 53.0, "val_loss": 17.319247126579285, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14093780517578, "training_acc": 53.0, "val_loss": 17.31218993663788, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26879811286926, "training_acc": 53.0, "val_loss": 17.322398722171783, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.37604022026062, "training_acc": 43.0, "val_loss": 17.313338816165924, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08330655097961, "training_acc": 53.0, "val_loss": 17.404864728450775, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32772946357727, "training_acc": 53.0, "val_loss": 17.314185202121735, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2457664012909, "training_acc": 53.0, "val_loss": 17.30978786945343, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1330189704895, "training_acc": 53.0, "val_loss": 17.33313351869583, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.60055088996887, "training_acc": 53.0, "val_loss": 17.332179844379425, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15640234947205, "training_acc": 53.0, "val_loss": 17.321982979774475, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.53661012649536, "training_acc": 53.0, "val_loss": 17.318589985370636, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.33319306373596, "training_acc": 49.0, "val_loss": 17.32086092233658, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.8914406299591, "training_acc": 53.0, "val_loss": 17.31146275997162, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18187069892883, "training_acc": 53.0, "val_loss": 17.31061190366745, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2716794013977, "training_acc": 53.0, "val_loss": 17.324259877204895, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26477360725403, "training_acc": 53.0, "val_loss": 17.309056222438812, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19784641265869, "training_acc": 53.0, "val_loss": 17.328651249408722, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29346585273743, "training_acc": 53.0, "val_loss": 17.40148663520813, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.39824199676514, "training_acc": 53.0, "val_loss": 17.35616773366928, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.26121401786804, "training_acc": 53.0, "val_loss": 17.308974266052246, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14740705490112, "training_acc": 53.0, "val_loss": 17.31390357017517, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.4386339187622, "training_acc": 45.0, "val_loss": 17.31805056333542, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17164993286133, "training_acc": 53.0, "val_loss": 17.318561673164368, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10613059997559, "training_acc": 53.0, "val_loss": 17.403018474578857, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.51605296134949, "training_acc": 53.0, "val_loss": 17.411302030086517, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.55927300453186, "training_acc": 53.0, "val_loss": 17.32526421546936, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.30995845794678, "training_acc": 53.0, "val_loss": 17.311617732048035, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16372203826904, "training_acc": 53.0, "val_loss": 17.31712520122528, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17720770835876, "training_acc": 53.0, "val_loss": 17.3134908080101, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12113690376282, "training_acc": 53.0, "val_loss": 17.30865240097046, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20419311523438, "training_acc": 53.0, "val_loss": 17.311201989650726, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18363118171692, "training_acc": 53.0, "val_loss": 17.309339344501495, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1348226070404, "training_acc": 53.0, "val_loss": 17.329110205173492, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14048957824707, "training_acc": 53.0, "val_loss": 17.38528609275818, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.3608250617981, "training_acc": 53.0, "val_loss": 17.44469404220581, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.71148157119751, "training_acc": 53.0, "val_loss": 17.37581193447113, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.57582330703735, "training_acc": 53.0, "val_loss": 17.31027513742447, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.40842747688293, "training_acc": 45.0, "val_loss": 17.32257604598999, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.33873200416565, "training_acc": 53.0, "val_loss": 17.308658361434937, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.18463611602783, "training_acc": 53.0, "val_loss": 17.31199473142624, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.25260138511658, "training_acc": 53.0, "val_loss": 17.315790057182312, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.20956516265869, "training_acc": 53.0, "val_loss": 17.309190332889557, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.207435131073, "training_acc": 53.0, "val_loss": 17.31126606464386, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.18515753746033, "training_acc": 53.0, "val_loss": 17.331883311271667, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1800696849823, "training_acc": 53.0, "val_loss": 17.334464192390442, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.16677498817444, "training_acc": 53.0, "val_loss": 17.337794601917267, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17883586883545, "training_acc": 53.0, "val_loss": 17.330661416053772, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.3065881729126, "training_acc": 53.0, "val_loss": 17.321206629276276, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.097412109375, "training_acc": 53.0, "val_loss": 17.310595512390137, "val_acc": 52.0}
