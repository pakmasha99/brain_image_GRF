"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.05535984039307, "training_acc": 52.0, "val_loss": 17.1701580286026, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2261312007904, "training_acc": 52.0, "val_loss": 17.54046529531479, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.21295619010925, "training_acc": 46.0, "val_loss": 17.37953871488571, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.61795091629028, "training_acc": 46.0, "val_loss": 17.367543280124664, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.33633685112, "training_acc": 48.0, "val_loss": 17.213059961795807, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.79472851753235, "training_acc": 52.0, "val_loss": 17.228706181049347, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.32315826416016, "training_acc": 50.0, "val_loss": 17.37242043018341, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.3442690372467, "training_acc": 48.0, "val_loss": 17.205974459648132, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.93996930122375, "training_acc": 52.0, "val_loss": 17.17502921819687, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.21347451210022, "training_acc": 52.0, "val_loss": 17.355363070964813, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.39228415489197, "training_acc": 48.0, "val_loss": 17.365920543670654, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.37506556510925, "training_acc": 48.0, "val_loss": 17.23485291004181, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.36180877685547, "training_acc": 52.0, "val_loss": 17.205417156219482, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.31784081459045, "training_acc": 52.0, "val_loss": 17.25752055644989, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25945711135864, "training_acc": 52.0, "val_loss": 17.224296927452087, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25030326843262, "training_acc": 52.0, "val_loss": 17.17902570962906, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.35729575157166, "training_acc": 52.0, "val_loss": 17.1599879860878, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.34633660316467, "training_acc": 52.0, "val_loss": 17.213788628578186, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25302958488464, "training_acc": 52.0, "val_loss": 17.29145050048828, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.27113676071167, "training_acc": 52.0, "val_loss": 17.28605180978775, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.28798604011536, "training_acc": 52.0, "val_loss": 17.24543571472168, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22369003295898, "training_acc": 52.0, "val_loss": 17.17998832464218, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.59968304634094, "training_acc": 52.0, "val_loss": 17.156389355659485, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.30138754844666, "training_acc": 52.0, "val_loss": 17.244435846805573, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.17188143730164, "training_acc": 52.0, "val_loss": 17.41802990436554, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.58684968948364, "training_acc": 48.0, "val_loss": 17.438197135925293, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.15831398963928, "training_acc": 38.0, "val_loss": 17.26129502058029, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.2457046508789, "training_acc": 52.0, "val_loss": 17.274628579616547, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33423686027527, "training_acc": 52.0, "val_loss": 17.261752486228943, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.21224880218506, "training_acc": 52.0, "val_loss": 17.19248592853546, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.750648021698, "training_acc": 52.0, "val_loss": 17.167118191719055, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.7220733165741, "training_acc": 52.0, "val_loss": 17.243032157421112, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24479651451111, "training_acc": 52.0, "val_loss": 17.235484719276428, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25751042366028, "training_acc": 52.0, "val_loss": 17.2368124127388, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.29472327232361, "training_acc": 52.0, "val_loss": 17.21392720937729, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24166917800903, "training_acc": 52.0, "val_loss": 17.234916985034943, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.26209497451782, "training_acc": 52.0, "val_loss": 17.242108285427094, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.39347910881042, "training_acc": 52.0, "val_loss": 17.216205596923828, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2211503982544, "training_acc": 52.0, "val_loss": 17.162103950977325, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.65935969352722, "training_acc": 52.0, "val_loss": 17.148463428020477, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.51516485214233, "training_acc": 52.0, "val_loss": 17.172035574913025, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.29462432861328, "training_acc": 52.0, "val_loss": 17.255809903144836, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.22533535957336, "training_acc": 52.0, "val_loss": 17.333796620368958, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.39414620399475, "training_acc": 40.0, "val_loss": 17.398923635482788, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.53392267227173, "training_acc": 48.0, "val_loss": 17.454464733600616, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.5545425415039, "training_acc": 48.0, "val_loss": 17.315830290317535, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.31003975868225, "training_acc": 52.0, "val_loss": 17.22414493560791, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22870373725891, "training_acc": 52.0, "val_loss": 17.187032103538513, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.31438612937927, "training_acc": 52.0, "val_loss": 17.164482176303864, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.39392447471619, "training_acc": 52.0, "val_loss": 17.182403802871704, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.20205235481262, "training_acc": 52.0, "val_loss": 17.279058694839478, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25298237800598, "training_acc": 52.0, "val_loss": 17.399680614471436, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.42845487594604, "training_acc": 48.0, "val_loss": 17.397090792655945, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.41401314735413, "training_acc": 48.0, "val_loss": 17.329534888267517, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2802574634552, "training_acc": 52.0, "val_loss": 17.246916890144348, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.42668509483337, "training_acc": 52.0, "val_loss": 17.18289852142334, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.30268859863281, "training_acc": 52.0, "val_loss": 17.192482948303223, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.3015558719635, "training_acc": 52.0, "val_loss": 17.244097590446472, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23465609550476, "training_acc": 52.0, "val_loss": 17.26369857788086, "val_acc": 56.0}
