"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 96.1273341178894, "training_acc": 43.0, "val_loss": 7437.8692626953125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 17394.619765520096, "training_acc": 55.0, "val_loss": 39.277487993240356, "val_acc": 48.0}
{"epoch": 2, "training_loss": 123.97625255584717, "training_acc": 59.0, "val_loss": 17.568957805633545, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.36506342887878, "training_acc": 47.0, "val_loss": 17.322786152362823, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.82228422164917, "training_acc": 53.0, "val_loss": 17.578451335430145, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.96696090698242, "training_acc": 53.0, "val_loss": 17.533308267593384, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.86657333374023, "training_acc": 53.0, "val_loss": 17.32332557439804, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28282165527344, "training_acc": 53.0, "val_loss": 17.32465773820877, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.37401533126831, "training_acc": 51.0, "val_loss": 17.363448441028595, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.92010998725891, "training_acc": 41.0, "val_loss": 17.31010377407074, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20285749435425, "training_acc": 53.0, "val_loss": 17.309878766536713, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13960123062134, "training_acc": 53.0, "val_loss": 17.316845059394836, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13951206207275, "training_acc": 53.0, "val_loss": 17.336736619472504, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17480254173279, "training_acc": 53.0, "val_loss": 17.336104810237885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.62663984298706, "training_acc": 53.0, "val_loss": 17.320530116558075, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2982075214386, "training_acc": 53.0, "val_loss": 17.33860969543457, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22120404243469, "training_acc": 53.0, "val_loss": 17.323242127895355, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11128497123718, "training_acc": 53.0, "val_loss": 17.309395968914032, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2189552783966, "training_acc": 53.0, "val_loss": 17.310906946659088, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19066119194031, "training_acc": 53.0, "val_loss": 17.309756577014923, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17703533172607, "training_acc": 53.0, "val_loss": 17.30862259864807, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1503517627716, "training_acc": 53.0, "val_loss": 17.310912907123566, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13251948356628, "training_acc": 53.0, "val_loss": 17.318885028362274, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18517470359802, "training_acc": 53.0, "val_loss": 17.338155210018158, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18398356437683, "training_acc": 53.0, "val_loss": 17.332004010677338, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.38337540626526, "training_acc": 53.0, "val_loss": 17.317616939544678, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13223242759705, "training_acc": 53.0, "val_loss": 17.319144308567047, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14600324630737, "training_acc": 53.0, "val_loss": 17.319926619529724, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15348792076111, "training_acc": 53.0, "val_loss": 17.322301864624023, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17906904220581, "training_acc": 53.0, "val_loss": 17.31915771961212, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19552946090698, "training_acc": 53.0, "val_loss": 17.311957478523254, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.10603284835815, "training_acc": 53.0, "val_loss": 17.31170564889908, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18984580039978, "training_acc": 53.0, "val_loss": 17.31778085231781, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21963405609131, "training_acc": 53.0, "val_loss": 17.314143478870392, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19598293304443, "training_acc": 53.0, "val_loss": 17.310500144958496, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16479182243347, "training_acc": 53.0, "val_loss": 17.309387028217316, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13277649879456, "training_acc": 53.0, "val_loss": 17.31252670288086, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12393975257874, "training_acc": 53.0, "val_loss": 17.320258915424347, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13127493858337, "training_acc": 53.0, "val_loss": 17.328357696533203, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.26954960823059, "training_acc": 53.0, "val_loss": 17.33579933643341, "val_acc": 52.0}
