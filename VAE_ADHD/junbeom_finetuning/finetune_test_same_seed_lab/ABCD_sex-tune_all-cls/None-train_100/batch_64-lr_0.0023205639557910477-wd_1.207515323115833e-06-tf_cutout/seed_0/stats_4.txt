"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 137.06864833831787, "training_acc": 43.0, "val_loss": 3486.811065673828, "val_acc": 52.0}
{"epoch": 1, "training_loss": 8281.376403808594, "training_acc": 55.0, "val_loss": 18.970976769924164, "val_acc": 48.0}
{"epoch": 2, "training_loss": 119.64484930038452, "training_acc": 41.0, "val_loss": 17.46104061603546, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.99087285995483, "training_acc": 47.0, "val_loss": 17.806506156921387, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.60495209693909, "training_acc": 47.0, "val_loss": 17.3234760761261, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.07629442214966, "training_acc": 53.0, "val_loss": 17.31671541929245, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.34264707565308, "training_acc": 51.0, "val_loss": 17.33327805995941, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22841453552246, "training_acc": 54.0, "val_loss": 17.375297844409943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.56725025177002, "training_acc": 53.0, "val_loss": 17.39313453435898, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.28717732429504, "training_acc": 53.0, "val_loss": 17.311643064022064, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14699721336365, "training_acc": 53.0, "val_loss": 17.333726584911346, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.31741762161255, "training_acc": 53.0, "val_loss": 17.349974811077118, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15826082229614, "training_acc": 53.0, "val_loss": 17.311622202396393, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08550238609314, "training_acc": 53.0, "val_loss": 17.32138842344284, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.37818145751953, "training_acc": 53.0, "val_loss": 17.32178032398224, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.44481372833252, "training_acc": 53.0, "val_loss": 17.321252822875977, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26369404792786, "training_acc": 53.0, "val_loss": 17.330320179462433, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.47858738899231, "training_acc": 44.0, "val_loss": 17.322513461112976, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.37385559082031, "training_acc": 53.0, "val_loss": 17.30872243642807, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17265343666077, "training_acc": 53.0, "val_loss": 17.308470606803894, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21406102180481, "training_acc": 53.0, "val_loss": 17.31085330247879, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13845896720886, "training_acc": 53.0, "val_loss": 17.312629520893097, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13033032417297, "training_acc": 53.0, "val_loss": 17.316803336143494, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.138906955719, "training_acc": 53.0, "val_loss": 17.32221692800522, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2243287563324, "training_acc": 53.0, "val_loss": 17.324313521385193, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13388586044312, "training_acc": 53.0, "val_loss": 17.315812408924103, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.20066165924072, "training_acc": 53.0, "val_loss": 17.31058657169342, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13956594467163, "training_acc": 53.0, "val_loss": 17.31048971414566, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1387209892273, "training_acc": 53.0, "val_loss": 17.310363054275513, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19732117652893, "training_acc": 53.0, "val_loss": 17.310568690299988, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13815689086914, "training_acc": 53.0, "val_loss": 17.308995127677917, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17701888084412, "training_acc": 53.0, "val_loss": 17.308631539344788, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14966082572937, "training_acc": 53.0, "val_loss": 17.3090398311615, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2193820476532, "training_acc": 53.0, "val_loss": 17.31056421995163, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14006972312927, "training_acc": 53.0, "val_loss": 17.310121655464172, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14062809944153, "training_acc": 53.0, "val_loss": 17.310477793216705, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15373182296753, "training_acc": 53.0, "val_loss": 17.310450971126556, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13699746131897, "training_acc": 53.0, "val_loss": 17.312312126159668, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13676953315735, "training_acc": 53.0, "val_loss": 17.31458306312561, "val_acc": 52.0}
