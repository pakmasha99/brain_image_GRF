"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 580.5085906982422, "training_acc": 55.0, "val_loss": 3.2653492650487904e+23, "val_acc": 48.0}
{"epoch": 1, "training_loss": 8.647698153498976e+23, "training_acc": 47.0, "val_loss": 379039180800.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1142118872064.0, "training_acc": 47.0, "val_loss": 38370860800.0, "val_acc": 48.0}
{"epoch": 3, "training_loss": 227489267712.0, "training_acc": 45.0, "val_loss": 998961200.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2575867585.0, "training_acc": 50.0, "val_loss": 2354725683200.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5676021332992.0, "training_acc": 53.0, "val_loss": 1067633459200.0, "val_acc": 48.0}
{"epoch": 6, "training_loss": 8143520989184.0, "training_acc": 47.0, "val_loss": 6566182800.0, "val_acc": 48.0}
{"epoch": 7, "training_loss": 154913069056.0, "training_acc": 45.0, "val_loss": 6863876800.0, "val_acc": 52.0}
{"epoch": 8, "training_loss": 288507392000.0, "training_acc": 57.0, "val_loss": 17325480000.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 59958749440.0, "training_acc": 53.0, "val_loss": 2766760800.0, "val_acc": 52.0}
{"epoch": 10, "training_loss": 8934982144.0, "training_acc": 53.0, "val_loss": 37952598400.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 117960893056.0, "training_acc": 53.0, "val_loss": 27900595200.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 77255463232.0, "training_acc": 47.0, "val_loss": 172257425.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2064171168.0, "training_acc": 47.0, "val_loss": 69417139200.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 164830992040.0, "training_acc": 53.0, "val_loss": 458541250.0, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3321824144.0, "training_acc": 55.0, "val_loss": 671494450.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 8762726464.0, "training_acc": 49.0, "val_loss": 3157525400.0, "val_acc": 48.0}
{"epoch": 17, "training_loss": 8620599738.0, "training_acc": 47.0, "val_loss": 851707100.0, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2302417302.0, "training_acc": 51.0, "val_loss": 52403331.25, "val_acc": 52.0}
{"epoch": 19, "training_loss": 959970896.0, "training_acc": 45.0, "val_loss": 28170550.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 584447596.0, "training_acc": 53.0, "val_loss": 364089150.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1086133436.0, "training_acc": 53.0, "val_loss": 472233950.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1360780892.0, "training_acc": 47.0, "val_loss": 583770750.0, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1392314440.5, "training_acc": 55.0, "val_loss": 433960450.0, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1511563964.0, "training_acc": 53.0, "val_loss": 95065712.5, "val_acc": 48.0}
{"epoch": 25, "training_loss": 235202334.0, "training_acc": 60.0, "val_loss": 330451900.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 857991654.5, "training_acc": 55.0, "val_loss": 926889600.0, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2669793186.0, "training_acc": 53.0, "val_loss": 63339012.5, "val_acc": 52.0}
{"epoch": 28, "training_loss": 289662679.0, "training_acc": 49.0, "val_loss": 93600206.25, "val_acc": 48.0}
{"epoch": 29, "training_loss": 252760459.25, "training_acc": 51.0, "val_loss": 34783975.0, "val_acc": 52.0}
{"epoch": 30, "training_loss": 121972975.75, "training_acc": 53.0, "val_loss": 12853930.46875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 130581600.0, "training_acc": 48.0, "val_loss": 43296918.75, "val_acc": 48.0}
{"epoch": 32, "training_loss": 120262537.484375, "training_acc": 46.0, "val_loss": 49204637.5, "val_acc": 52.0}
{"epoch": 33, "training_loss": 179586936.5, "training_acc": 53.0, "val_loss": 79437325.0, "val_acc": 52.0}
{"epoch": 34, "training_loss": 206264642.0625, "training_acc": 49.0, "val_loss": 3285376600.0, "val_acc": 48.0}
{"epoch": 35, "training_loss": 7452470757.5, "training_acc": 57.0, "val_loss": 306850300.0, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1408146200.0, "training_acc": 53.0, "val_loss": 128654812.5, "val_acc": 48.0}
{"epoch": 37, "training_loss": 549708002.0, "training_acc": 53.0, "val_loss": 52484312.5, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1821165648.0, "training_acc": 51.0, "val_loss": 369759150.0, "val_acc": 48.0}
{"epoch": 39, "training_loss": 3710889888.0, "training_acc": 39.0, "val_loss": 824865000.0, "val_acc": 52.0}
{"epoch": 40, "training_loss": 8602571648.0, "training_acc": 53.0, "val_loss": 139204225.0, "val_acc": 52.0}
{"epoch": 41, "training_loss": 509583102.0, "training_acc": 53.0, "val_loss": 185627200.0, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1396513320.0, "training_acc": 55.0, "val_loss": 337796850.0, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2738111232.0, "training_acc": 43.0, "val_loss": 94376700.0, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1830998016.0, "training_acc": 49.0, "val_loss": 125261475.0, "val_acc": 48.0}
{"epoch": 45, "training_loss": 671842488.0, "training_acc": 51.0, "val_loss": 89822525.0, "val_acc": 52.0}
{"epoch": 46, "training_loss": 325448508.0, "training_acc": 53.0, "val_loss": 28256112.5, "val_acc": 52.0}
{"epoch": 47, "training_loss": 219383672.0, "training_acc": 55.0, "val_loss": 1404969.23828125, "val_acc": 36.0}
{"epoch": 48, "training_loss": 226795373.0, "training_acc": 57.0, "val_loss": 24302350.0, "val_acc": 52.0}
{"epoch": 49, "training_loss": 117213383.5, "training_acc": 51.0, "val_loss": 3927389.0625, "val_acc": 52.0}
{"epoch": 50, "training_loss": 261072955.5, "training_acc": 53.0, "val_loss": 19180537.5, "val_acc": 52.0}
{"epoch": 51, "training_loss": 52219849.25, "training_acc": 54.0, "val_loss": 49398493.75, "val_acc": 48.0}
{"epoch": 52, "training_loss": 148115471.5, "training_acc": 47.0, "val_loss": 21605939.0625, "val_acc": 52.0}
{"epoch": 53, "training_loss": 80684948.75, "training_acc": 53.0, "val_loss": 23071503.125, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69997248.0, "training_acc": 53.0, "val_loss": 9664043.75, "val_acc": 48.0}
{"epoch": 55, "training_loss": 37552867.625, "training_acc": 47.0, "val_loss": 4767766.796875, "val_acc": 48.0}
{"epoch": 56, "training_loss": 16135205.21875, "training_acc": 45.0, "val_loss": 2005191.796875, "val_acc": 52.0}
{"epoch": 57, "training_loss": 6133921.1953125, "training_acc": 46.0, "val_loss": 380107.9833984375, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1801918.6328125, "training_acc": 49.0, "val_loss": 1392770.3125, "val_acc": 52.0}
{"epoch": 59, "training_loss": 4507497.5, "training_acc": 52.0, "val_loss": 1061936.71875, "val_acc": 48.0}
{"epoch": 60, "training_loss": 2715216.32421875, "training_acc": 51.0, "val_loss": 224535.302734375, "val_acc": 48.0}
{"epoch": 61, "training_loss": 2318533.3125, "training_acc": 44.0, "val_loss": 279157.12890625, "val_acc": 48.0}
{"epoch": 62, "training_loss": 2079187.0, "training_acc": 43.0, "val_loss": 665977.001953125, "val_acc": 48.0}
{"epoch": 63, "training_loss": 2087833.64453125, "training_acc": 49.0, "val_loss": 1389974.609375, "val_acc": 52.0}
{"epoch": 64, "training_loss": 5356170.046875, "training_acc": 53.0, "val_loss": 441604.4921875, "val_acc": 48.0}
{"epoch": 65, "training_loss": 1157204.349609375, "training_acc": 48.0, "val_loss": 600119.482421875, "val_acc": 52.0}
{"epoch": 66, "training_loss": 2142044.0703125, "training_acc": 49.0, "val_loss": 247801.66015625, "val_acc": 52.0}
{"epoch": 67, "training_loss": 1890521.4140625, "training_acc": 48.0, "val_loss": 295320.751953125, "val_acc": 52.0}
{"epoch": 68, "training_loss": 1045498.966796875, "training_acc": 52.0, "val_loss": 334872.55859375, "val_acc": 52.0}
{"epoch": 69, "training_loss": 1439368.0703125, "training_acc": 48.0, "val_loss": 275966.796875, "val_acc": 52.0}
{"epoch": 70, "training_loss": 719800.216796875, "training_acc": 53.0, "val_loss": 198969.53125, "val_acc": 48.0}
{"epoch": 71, "training_loss": 1894627.453125, "training_acc": 44.0, "val_loss": 495279.6875, "val_acc": 52.0}
{"epoch": 72, "training_loss": 3063190.171875, "training_acc": 45.0, "val_loss": 835191.2109375, "val_acc": 48.0}
{"epoch": 73, "training_loss": 2949719.46875, "training_acc": 47.0, "val_loss": 668162.98828125, "val_acc": 52.0}
{"epoch": 74, "training_loss": 1872653.13671875, "training_acc": 50.0, "val_loss": 153607.65380859375, "val_acc": 52.0}
{"epoch": 75, "training_loss": 877371.13671875, "training_acc": 44.0, "val_loss": 621849.755859375, "val_acc": 52.0}
{"epoch": 76, "training_loss": 2060251.84375, "training_acc": 53.0, "val_loss": 574667.919921875, "val_acc": 48.0}
{"epoch": 77, "training_loss": 2250696.875, "training_acc": 47.0, "val_loss": 717192.236328125, "val_acc": 52.0}
{"epoch": 78, "training_loss": 2853911.40625, "training_acc": 53.0, "val_loss": 266852.34375, "val_acc": 52.0}
{"epoch": 79, "training_loss": 1537018.65625, "training_acc": 61.0, "val_loss": 1408861.23046875, "val_acc": 48.0}
{"epoch": 80, "training_loss": 4874895.40625, "training_acc": 47.0, "val_loss": 590753.80859375, "val_acc": 52.0}
{"epoch": 81, "training_loss": 2624977.984375, "training_acc": 53.0, "val_loss": 780911.9140625, "val_acc": 52.0}
{"epoch": 82, "training_loss": 1645037.1767578125, "training_acc": 56.0, "val_loss": 1329151.3671875, "val_acc": 48.0}
{"epoch": 83, "training_loss": 5744960.21875, "training_acc": 47.0, "val_loss": 1212055.46875, "val_acc": 48.0}
{"epoch": 84, "training_loss": 3174722.673828125, "training_acc": 47.0, "val_loss": 1270036.71875, "val_acc": 52.0}
{"epoch": 85, "training_loss": 5796395.75, "training_acc": 53.0, "val_loss": 1920993.75, "val_acc": 52.0}
{"epoch": 86, "training_loss": 6796828.578125, "training_acc": 53.0, "val_loss": 489122.119140625, "val_acc": 52.0}
{"epoch": 87, "training_loss": 1830152.7265625, "training_acc": 63.0, "val_loss": 1511199.21875, "val_acc": 48.0}
{"epoch": 88, "training_loss": 5806190.078125, "training_acc": 47.0, "val_loss": 675741.796875, "val_acc": 48.0}
{"epoch": 89, "training_loss": 3147026.3125, "training_acc": 42.0, "val_loss": 1235216.89453125, "val_acc": 52.0}
{"epoch": 90, "training_loss": 4701467.078125, "training_acc": 53.0, "val_loss": 556446.38671875, "val_acc": 52.0}
{"epoch": 91, "training_loss": 1852680.26171875, "training_acc": 53.0, "val_loss": 660851.171875, "val_acc": 48.0}
{"epoch": 92, "training_loss": 2279514.140625, "training_acc": 47.0, "val_loss": 371005.029296875, "val_acc": 52.0}
{"epoch": 93, "training_loss": 1727906.3125, "training_acc": 53.0, "val_loss": 397308.2763671875, "val_acc": 52.0}
