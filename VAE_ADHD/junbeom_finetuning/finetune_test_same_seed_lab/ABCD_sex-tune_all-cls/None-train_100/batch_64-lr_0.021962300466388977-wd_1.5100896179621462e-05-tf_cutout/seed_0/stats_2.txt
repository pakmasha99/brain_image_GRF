"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1882.2332916259766, "training_acc": 49.0, "val_loss": 81588499251200.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 180433120473344.0, "training_acc": 57.0, "val_loss": 13333848800.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 42145010752.0, "training_acc": 47.0, "val_loss": 31345534.375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 855480176.0, "training_acc": 51.0, "val_loss": 156212537.5, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1791755536.0, "training_acc": 59.0, "val_loss": 206929400.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2799922464.0, "training_acc": 53.0, "val_loss": 567347700.0, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1787703956.0, "training_acc": 51.0, "val_loss": 21133887.5, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69803542.25, "training_acc": 53.0, "val_loss": 8544521.875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 379970452.0, "training_acc": 53.0, "val_loss": 23230507.8125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 97911843.5, "training_acc": 53.0, "val_loss": 275618650.0, "val_acc": 52.0}
{"epoch": 10, "training_loss": 713460099.0, "training_acc": 55.0, "val_loss": 18628523200.0, "val_acc": 52.0}
{"epoch": 11, "training_loss": 42521913861.0, "training_acc": 55.0, "val_loss": 592495750.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4156187872.0, "training_acc": 57.0, "val_loss": 8797592000.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 65654501888.0, "training_acc": 47.0, "val_loss": 227413657600.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 967588790272.0, "training_acc": 57.0, "val_loss": 27942368000.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 243781306368.0, "training_acc": 47.0, "val_loss": 483449450.0, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1743682168.0, "training_acc": 47.0, "val_loss": 51314731.25, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1488658816.0, "training_acc": 51.0, "val_loss": 280421950.0, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3210452976.0, "training_acc": 41.0, "val_loss": 1249691100.0, "val_acc": 48.0}
{"epoch": 19, "training_loss": 3554402268.0, "training_acc": 51.0, "val_loss": 15713688000.0, "val_acc": 52.0}
{"epoch": 20, "training_loss": 33725661511.5, "training_acc": 58.0, "val_loss": 1863343400.0, "val_acc": 52.0}
{"epoch": 21, "training_loss": 5828414816.0, "training_acc": 43.0, "val_loss": 393578100.0, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1199216732.0, "training_acc": 47.0, "val_loss": 4808366400.0, "val_acc": 48.0}
{"epoch": 23, "training_loss": 16206398046.5, "training_acc": 49.0, "val_loss": 145852637.5, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2764427280.0, "training_acc": 44.0, "val_loss": 1230852812800.0, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3104293257984.0, "training_acc": 47.0, "val_loss": 9301921600.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 26550947936.0, "training_acc": 51.0, "val_loss": 1634557000.0, "val_acc": 52.0}
