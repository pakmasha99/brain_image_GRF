"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.65248227119446, "training_acc": 52.0, "val_loss": 17.18747317790985, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.77052712440491, "training_acc": 52.0, "val_loss": 17.184944450855255, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.76242399215698, "training_acc": 52.0, "val_loss": 17.181900143623352, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.70575785636902, "training_acc": 52.0, "val_loss": 17.179131507873535, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.61540269851685, "training_acc": 52.0, "val_loss": 17.176586389541626, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.59206461906433, "training_acc": 52.0, "val_loss": 17.174668610095978, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.59839200973511, "training_acc": 52.0, "val_loss": 17.173084616661072, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.57404565811157, "training_acc": 52.0, "val_loss": 17.171786725521088, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.50968337059021, "training_acc": 52.0, "val_loss": 17.17122793197632, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.52274012565613, "training_acc": 52.0, "val_loss": 17.170943319797516, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.42238163948059, "training_acc": 52.0, "val_loss": 17.170964181423187, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.46892619132996, "training_acc": 52.0, "val_loss": 17.171385884284973, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.42973899841309, "training_acc": 52.0, "val_loss": 17.172156274318695, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.3570020198822, "training_acc": 52.0, "val_loss": 17.17321425676346, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.37584280967712, "training_acc": 52.0, "val_loss": 17.17447191476822, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.3472330570221, "training_acc": 52.0, "val_loss": 17.17594861984253, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.36004590988159, "training_acc": 52.0, "val_loss": 17.177249491214752, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.34983015060425, "training_acc": 52.0, "val_loss": 17.179103195667267, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.28658986091614, "training_acc": 52.0, "val_loss": 17.180904746055603, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.30268597602844, "training_acc": 52.0, "val_loss": 17.182765901088715, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.26083493232727, "training_acc": 52.0, "val_loss": 17.184877395629883, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26191639900208, "training_acc": 52.0, "val_loss": 17.187076807022095, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29000091552734, "training_acc": 52.0, "val_loss": 17.188698053359985, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.267019033432, "training_acc": 52.0, "val_loss": 17.19089150428772, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26050209999084, "training_acc": 52.0, "val_loss": 17.19311624765396, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24620795249939, "training_acc": 52.0, "val_loss": 17.19558537006378, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.25750064849854, "training_acc": 52.0, "val_loss": 17.197726666927338, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.25238752365112, "training_acc": 52.0, "val_loss": 17.20041185617447, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.16563868522644, "training_acc": 52.0, "val_loss": 17.203183472156525, "val_acc": 56.0}
