"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 377.27345275878906, "training_acc": 50.0, "val_loss": 36747512.5, "val_acc": 56.0}
{"epoch": 1, "training_loss": 99392804.45263672, "training_acc": 52.0, "val_loss": 39036.68212890625, "val_acc": 44.0}
{"epoch": 2, "training_loss": 101677.28698730469, "training_acc": 48.0, "val_loss": 538.9428615570068, "val_acc": 56.0}
{"epoch": 3, "training_loss": 1565.1994705200195, "training_acc": 54.0, "val_loss": 345.48633098602295, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1174.0043640136719, "training_acc": 52.0, "val_loss": 21.535736322402954, "val_acc": 44.0}
{"epoch": 5, "training_loss": 92.8781909942627, "training_acc": 48.0, "val_loss": 27.130737900733948, "val_acc": 56.0}
{"epoch": 6, "training_loss": 154.92187786102295, "training_acc": 50.0, "val_loss": 18.970200419425964, "val_acc": 44.0}
{"epoch": 7, "training_loss": 74.21585130691528, "training_acc": 52.0, "val_loss": 17.129941284656525, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.17787480354309, "training_acc": 52.0, "val_loss": 54.759806394577026, "val_acc": 44.0}
{"epoch": 9, "training_loss": 206.55650806427002, "training_acc": 48.0, "val_loss": 26.248008012771606, "val_acc": 56.0}
{"epoch": 10, "training_loss": 125.54795217514038, "training_acc": 50.0, "val_loss": 17.225049436092377, "val_acc": 56.0}
{"epoch": 11, "training_loss": 81.09942865371704, "training_acc": 52.0, "val_loss": 17.152780294418335, "val_acc": 56.0}
{"epoch": 12, "training_loss": 70.00145673751831, "training_acc": 54.0, "val_loss": 17.5558865070343, "val_acc": 56.0}
{"epoch": 13, "training_loss": 70.03387379646301, "training_acc": 52.0, "val_loss": 17.333462834358215, "val_acc": 56.0}
{"epoch": 14, "training_loss": 78.23203349113464, "training_acc": 48.0, "val_loss": 17.613662779331207, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.98982191085815, "training_acc": 54.0, "val_loss": 17.155027389526367, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.18990468978882, "training_acc": 53.0, "val_loss": 17.473338544368744, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.53802037239075, "training_acc": 50.0, "val_loss": 17.195922136306763, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.45666575431824, "training_acc": 50.0, "val_loss": 17.148134112358093, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.44147801399231, "training_acc": 52.0, "val_loss": 17.68655925989151, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.91171193122864, "training_acc": 48.0, "val_loss": 17.59852170944214, "val_acc": 56.0}
{"epoch": 21, "training_loss": 72.9294707775116, "training_acc": 46.0, "val_loss": 17.29040890932083, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.44359278678894, "training_acc": 52.0, "val_loss": 17.234227061271667, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.13510823249817, "training_acc": 54.0, "val_loss": 17.701245844364166, "val_acc": 56.0}
{"epoch": 24, "training_loss": 70.09051442146301, "training_acc": 48.0, "val_loss": 17.292438447475433, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.27203488349915, "training_acc": 52.0, "val_loss": 17.155666649341583, "val_acc": 56.0}
{"epoch": 26, "training_loss": 72.11350226402283, "training_acc": 52.0, "val_loss": 17.209120094776154, "val_acc": 56.0}
