"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 420.6363868713379, "training_acc": 47.0, "val_loss": 279363225.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 801858629.9228516, "training_acc": 41.0, "val_loss": 58056.15234375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 155830.38330078125, "training_acc": 55.0, "val_loss": 2595.952033996582, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8732.29443359375, "training_acc": 53.0, "val_loss": 2097.2951889038086, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5934.119737625122, "training_acc": 47.0, "val_loss": 1051.6003608703613, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2677.679965019226, "training_acc": 53.0, "val_loss": 5264.997100830078, "val_acc": 48.0}
{"epoch": 6, "training_loss": 15613.416023254395, "training_acc": 47.0, "val_loss": 490.71807861328125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1301.6593136787415, "training_acc": 56.0, "val_loss": 628.0542373657227, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1570.866813659668, "training_acc": 53.0, "val_loss": 242.79026985168457, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1154.8048210144043, "training_acc": 49.0, "val_loss": 240.90468883514404, "val_acc": 52.0}
{"epoch": 10, "training_loss": 636.4428005218506, "training_acc": 53.0, "val_loss": 211.83364391326904, "val_acc": 48.0}
{"epoch": 11, "training_loss": 715.8210754394531, "training_acc": 47.0, "val_loss": 91.32769703865051, "val_acc": 52.0}
{"epoch": 12, "training_loss": 225.49544477462769, "training_acc": 54.0, "val_loss": 112.07141876220703, "val_acc": 48.0}
{"epoch": 13, "training_loss": 554.0438632965088, "training_acc": 41.0, "val_loss": 18.03198605775833, "val_acc": 52.0}
{"epoch": 14, "training_loss": 392.7265090942383, "training_acc": 53.0, "val_loss": 212.26820945739746, "val_acc": 52.0}
{"epoch": 15, "training_loss": 723.1360511779785, "training_acc": 53.0, "val_loss": 112.7320647239685, "val_acc": 48.0}
{"epoch": 16, "training_loss": 394.61486434936523, "training_acc": 47.0, "val_loss": 128.32658290863037, "val_acc": 52.0}
{"epoch": 17, "training_loss": 352.22659730911255, "training_acc": 53.0, "val_loss": 46.20123207569122, "val_acc": 48.0}
{"epoch": 18, "training_loss": 145.92756819725037, "training_acc": 47.0, "val_loss": 41.011497378349304, "val_acc": 52.0}
{"epoch": 19, "training_loss": 166.01748132705688, "training_acc": 45.0, "val_loss": 33.46295952796936, "val_acc": 52.0}
{"epoch": 20, "training_loss": 118.60697269439697, "training_acc": 53.0, "val_loss": 44.91459131240845, "val_acc": 48.0}
{"epoch": 21, "training_loss": 147.82366967201233, "training_acc": 47.0, "val_loss": 31.29800856113434, "val_acc": 52.0}
{"epoch": 22, "training_loss": 110.44177269935608, "training_acc": 53.0, "val_loss": 19.529445469379425, "val_acc": 48.0}
{"epoch": 23, "training_loss": 80.34876418113708, "training_acc": 47.0, "val_loss": 19.72924917936325, "val_acc": 52.0}
{"epoch": 24, "training_loss": 77.17678809165955, "training_acc": 53.0, "val_loss": 17.161862552165985, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.93364810943604, "training_acc": 49.0, "val_loss": 17.25958287715912, "val_acc": 52.0}
{"epoch": 26, "training_loss": 74.51671504974365, "training_acc": 42.0, "val_loss": 17.197461426258087, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.85846328735352, "training_acc": 52.0, "val_loss": 19.25782412290573, "val_acc": 48.0}
{"epoch": 28, "training_loss": 77.25714635848999, "training_acc": 47.0, "val_loss": 17.418625950813293, "val_acc": 52.0}
{"epoch": 29, "training_loss": 71.60973691940308, "training_acc": 53.0, "val_loss": 17.782887816429138, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.54801487922668, "training_acc": 51.0, "val_loss": 18.024063110351562, "val_acc": 52.0}
{"epoch": 31, "training_loss": 71.9180018901825, "training_acc": 47.0, "val_loss": 17.399807274341583, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.35001945495605, "training_acc": 53.0, "val_loss": 17.651887238025665, "val_acc": 52.0}
{"epoch": 33, "training_loss": 71.30769085884094, "training_acc": 51.0, "val_loss": 17.279373109340668, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.04086399078369, "training_acc": 42.0, "val_loss": 17.23175346851349, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.79319381713867, "training_acc": 53.0, "val_loss": 17.543941736221313, "val_acc": 52.0}
{"epoch": 36, "training_loss": 71.26413798332214, "training_acc": 53.0, "val_loss": 17.215660214424133, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.72884106636047, "training_acc": 44.0, "val_loss": 17.81562715768814, "val_acc": 52.0}
{"epoch": 38, "training_loss": 70.7417938709259, "training_acc": 47.0, "val_loss": 17.508846521377563, "val_acc": 52.0}
{"epoch": 39, "training_loss": 75.45346117019653, "training_acc": 53.0, "val_loss": 17.351897060871124, "val_acc": 52.0}
{"epoch": 40, "training_loss": 72.40520024299622, "training_acc": 49.0, "val_loss": 17.792975902557373, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.976646900177, "training_acc": 47.0, "val_loss": 18.25672835111618, "val_acc": 52.0}
{"epoch": 42, "training_loss": 73.14512825012207, "training_acc": 53.0, "val_loss": 18.254317343235016, "val_acc": 52.0}
{"epoch": 43, "training_loss": 72.57068085670471, "training_acc": 53.0, "val_loss": 17.424000799655914, "val_acc": 52.0}
