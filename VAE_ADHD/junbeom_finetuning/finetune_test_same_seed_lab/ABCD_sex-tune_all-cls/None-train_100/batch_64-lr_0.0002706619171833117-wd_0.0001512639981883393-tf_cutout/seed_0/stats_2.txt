"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.68130874633789, "training_acc": 47.0, "val_loss": 17.312389612197876, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.08205962181091, "training_acc": 53.0, "val_loss": 17.460626363754272, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.49689030647278, "training_acc": 53.0, "val_loss": 17.309163510799408, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.69023561477661, "training_acc": 45.0, "val_loss": 17.33183264732361, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.29489850997925, "training_acc": 53.0, "val_loss": 17.334505915641785, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.51860475540161, "training_acc": 53.0, "val_loss": 17.329545319080353, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1598846912384, "training_acc": 53.0, "val_loss": 17.376616597175598, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28609800338745, "training_acc": 53.0, "val_loss": 17.35164374113083, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.450679063797, "training_acc": 53.0, "val_loss": 17.327509820461273, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.32215905189514, "training_acc": 53.0, "val_loss": 17.333050072193146, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21618890762329, "training_acc": 53.0, "val_loss": 17.307616770267487, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22084879875183, "training_acc": 53.0, "val_loss": 17.30985939502716, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15265393257141, "training_acc": 53.0, "val_loss": 17.33965277671814, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.31070828437805, "training_acc": 53.0, "val_loss": 17.334258556365967, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23017477989197, "training_acc": 53.0, "val_loss": 17.34418421983719, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17189502716064, "training_acc": 53.0, "val_loss": 17.311881482601166, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18340301513672, "training_acc": 53.0, "val_loss": 17.30777770280838, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17631721496582, "training_acc": 53.0, "val_loss": 17.310108244419098, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21635007858276, "training_acc": 53.0, "val_loss": 17.310722172260284, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13036799430847, "training_acc": 53.0, "val_loss": 17.308877408504486, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.287278175354, "training_acc": 53.0, "val_loss": 17.30932891368866, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23858666419983, "training_acc": 53.0, "val_loss": 17.32174903154373, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15179562568665, "training_acc": 53.0, "val_loss": 17.329348623752594, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15401864051819, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13173937797546, "training_acc": 53.0, "val_loss": 17.309333384037018, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.25727558135986, "training_acc": 53.0, "val_loss": 17.308610677719116, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.20696949958801, "training_acc": 53.0, "val_loss": 17.316834628582, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13665437698364, "training_acc": 53.0, "val_loss": 17.321020364761353, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15784525871277, "training_acc": 53.0, "val_loss": 17.317363619804382, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15587592124939, "training_acc": 53.0, "val_loss": 17.31759011745453, "val_acc": 52.0}
