"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.04936242103577, "training_acc": 52.0, "val_loss": 17.172923684120178, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2328839302063, "training_acc": 52.0, "val_loss": 17.437539994716644, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.84942150115967, "training_acc": 46.0, "val_loss": 17.318201065063477, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.49140691757202, "training_acc": 53.0, "val_loss": 17.359596490859985, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.3480498790741, "training_acc": 48.0, "val_loss": 17.223159968852997, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.71645855903625, "training_acc": 52.0, "val_loss": 17.240694165229797, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.29948353767395, "training_acc": 50.0, "val_loss": 17.325593531131744, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.28666400909424, "training_acc": 52.0, "val_loss": 17.200641334056854, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.81890058517456, "training_acc": 52.0, "val_loss": 17.192931473255157, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.19422554969788, "training_acc": 52.0, "val_loss": 17.373745143413544, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.40008544921875, "training_acc": 48.0, "val_loss": 17.3378124833107, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.34108304977417, "training_acc": 48.0, "val_loss": 17.22051650285721, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.33887982368469, "training_acc": 52.0, "val_loss": 17.213618755340576, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.31435513496399, "training_acc": 52.0, "val_loss": 17.26309508085251, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25299787521362, "training_acc": 52.0, "val_loss": 17.2139972448349, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25265836715698, "training_acc": 52.0, "val_loss": 17.17565953731537, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.34998846054077, "training_acc": 52.0, "val_loss": 17.163626849651337, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.32814145088196, "training_acc": 52.0, "val_loss": 17.229430377483368, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.248699426651, "training_acc": 52.0, "val_loss": 17.288939654827118, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.27048087120056, "training_acc": 52.0, "val_loss": 17.268556356430054, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.27208662033081, "training_acc": 52.0, "val_loss": 17.235340178012848, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22973346710205, "training_acc": 52.0, "val_loss": 17.181167006492615, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.59607768058777, "training_acc": 52.0, "val_loss": 17.16085374355316, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.28026556968689, "training_acc": 52.0, "val_loss": 17.25078970193863, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.17922759056091, "training_acc": 52.0, "val_loss": 17.40703582763672, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.54929542541504, "training_acc": 48.0, "val_loss": 17.419341206550598, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.08811640739441, "training_acc": 38.0, "val_loss": 17.26357191801071, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24446821212769, "training_acc": 52.0, "val_loss": 17.281757295131683, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33475995063782, "training_acc": 52.0, "val_loss": 17.270417511463165, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2173330783844, "training_acc": 52.0, "val_loss": 17.19910055398941, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.70538425445557, "training_acc": 52.0, "val_loss": 17.169633507728577, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.64990162849426, "training_acc": 52.0, "val_loss": 17.23209321498871, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24398255348206, "training_acc": 52.0, "val_loss": 17.225255072116852, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25526523590088, "training_acc": 52.0, "val_loss": 17.232181131839752, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.28035926818848, "training_acc": 52.0, "val_loss": 17.2194242477417, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2400815486908, "training_acc": 52.0, "val_loss": 17.24141240119934, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25939321517944, "training_acc": 52.0, "val_loss": 17.246177792549133, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.36921620368958, "training_acc": 52.0, "val_loss": 17.219871282577515, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.20745658874512, "training_acc": 52.0, "val_loss": 17.167098820209503, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.58400821685791, "training_acc": 52.0, "val_loss": 17.149484157562256, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.49087142944336, "training_acc": 52.0, "val_loss": 17.165298759937286, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.31931495666504, "training_acc": 52.0, "val_loss": 17.227312922477722, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.19594597816467, "training_acc": 52.0, "val_loss": 17.303234338760376, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.30539417266846, "training_acc": 52.0, "val_loss": 17.384469509124756, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.5147135257721, "training_acc": 48.0, "val_loss": 17.467021942138672, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.56622624397278, "training_acc": 48.0, "val_loss": 17.361415922641754, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.35986042022705, "training_acc": 48.0, "val_loss": 17.26602464914322, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.21640706062317, "training_acc": 52.0, "val_loss": 17.207707464694977, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.28022241592407, "training_acc": 52.0, "val_loss": 17.168375849723816, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.40720868110657, "training_acc": 52.0, "val_loss": 17.17030555009842, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25856018066406, "training_acc": 52.0, "val_loss": 17.228521406650543, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.21548056602478, "training_acc": 52.0, "val_loss": 17.32609272003174, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.30383610725403, "training_acc": 54.0, "val_loss": 17.373204231262207, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.38088178634644, "training_acc": 48.0, "val_loss": 17.360763251781464, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.34300565719604, "training_acc": 48.0, "val_loss": 17.29385554790497, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.43014144897461, "training_acc": 52.0, "val_loss": 17.209632694721222, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.28300905227661, "training_acc": 52.0, "val_loss": 17.19864457845688, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.26836109161377, "training_acc": 52.0, "val_loss": 17.22213327884674, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23087310791016, "training_acc": 52.0, "val_loss": 17.231398820877075, "val_acc": 56.0}
