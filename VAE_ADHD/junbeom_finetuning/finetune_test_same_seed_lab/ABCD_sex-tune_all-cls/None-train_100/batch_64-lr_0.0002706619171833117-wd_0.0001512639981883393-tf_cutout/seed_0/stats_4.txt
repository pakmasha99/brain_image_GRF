"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.20026302337646, "training_acc": 55.0, "val_loss": 17.31126606464386, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.83820724487305, "training_acc": 43.0, "val_loss": 17.42064654827118, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.61222815513611, "training_acc": 53.0, "val_loss": 17.315581440925598, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3411340713501, "training_acc": 53.0, "val_loss": 17.316074669361115, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.35514068603516, "training_acc": 53.0, "val_loss": 17.312614619731903, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.63101243972778, "training_acc": 53.0, "val_loss": 17.313911020755768, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32326221466064, "training_acc": 49.0, "val_loss": 17.312587797641754, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13686966896057, "training_acc": 53.0, "val_loss": 17.33434945344925, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.17934083938599, "training_acc": 53.0, "val_loss": 17.345641553401947, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16903042793274, "training_acc": 53.0, "val_loss": 17.31172353029251, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.3358850479126, "training_acc": 47.0, "val_loss": 17.30911433696747, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24122262001038, "training_acc": 53.0, "val_loss": 17.318522930145264, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.536541223526, "training_acc": 53.0, "val_loss": 17.319361865520477, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.09984922409058, "training_acc": 53.0, "val_loss": 17.378470301628113, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.47876596450806, "training_acc": 53.0, "val_loss": 17.395062744617462, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.23230385780334, "training_acc": 53.0, "val_loss": 17.31363981962204, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.0524353981018, "training_acc": 53.0, "val_loss": 17.324399948120117, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.36183571815491, "training_acc": 53.0, "val_loss": 17.340785264968872, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.68851470947266, "training_acc": 37.0, "val_loss": 17.338554561138153, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.37989544868469, "training_acc": 47.0, "val_loss": 17.34793782234192, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.63877534866333, "training_acc": 47.0, "val_loss": 17.31768697500229, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.55251622200012, "training_acc": 53.0, "val_loss": 17.33180582523346, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17913770675659, "training_acc": 53.0, "val_loss": 17.350715398788452, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.40147352218628, "training_acc": 53.0, "val_loss": 17.362990975379944, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.31750798225403, "training_acc": 53.0, "val_loss": 17.31799691915512, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16004967689514, "training_acc": 53.0, "val_loss": 17.30991303920746, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13727760314941, "training_acc": 53.0, "val_loss": 17.30981469154358, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.32065343856812, "training_acc": 53.0, "val_loss": 17.31109619140625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11442494392395, "training_acc": 53.0, "val_loss": 17.309048771858215, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.36956095695496, "training_acc": 53.0, "val_loss": 17.317315936088562, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.25872588157654, "training_acc": 53.0, "val_loss": 17.307886481285095, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1449875831604, "training_acc": 53.0, "val_loss": 17.31756627559662, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.36212658882141, "training_acc": 53.0, "val_loss": 17.328788340091705, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14677405357361, "training_acc": 53.0, "val_loss": 17.3105850815773, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.27789616584778, "training_acc": 53.0, "val_loss": 17.30814278125763, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16408467292786, "training_acc": 53.0, "val_loss": 17.3095703125, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.48930501937866, "training_acc": 53.0, "val_loss": 17.32606142759323, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16545820236206, "training_acc": 53.0, "val_loss": 17.313888669013977, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13407158851624, "training_acc": 53.0, "val_loss": 17.310258746147156, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.2394073009491, "training_acc": 53.0, "val_loss": 17.30808913707733, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14444470405579, "training_acc": 53.0, "val_loss": 17.31259822845459, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13306403160095, "training_acc": 53.0, "val_loss": 17.32015758752823, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.140549659729, "training_acc": 53.0, "val_loss": 17.323827743530273, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14984083175659, "training_acc": 53.0, "val_loss": 17.320825159549713, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.16680860519409, "training_acc": 53.0, "val_loss": 17.31877028942108, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15484285354614, "training_acc": 53.0, "val_loss": 17.322692275047302, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.1380352973938, "training_acc": 53.0, "val_loss": 17.31598675251007, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.15062379837036, "training_acc": 53.0, "val_loss": 17.30869710445404, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.19720268249512, "training_acc": 53.0, "val_loss": 17.308051884174347, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.27422714233398, "training_acc": 53.0, "val_loss": 17.30811893939972, "val_acc": 52.0}
