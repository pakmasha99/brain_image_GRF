"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 86.19841384887695, "training_acc": 50.0, "val_loss": 36.04181110858917, "val_acc": 56.0}
{"epoch": 1, "training_loss": 129.3841564655304, "training_acc": 52.0, "val_loss": 17.25834608078003, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.93242645263672, "training_acc": 52.0, "val_loss": 17.17594861984253, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.13632202148438, "training_acc": 52.0, "val_loss": 17.642201483249664, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.77513480186462, "training_acc": 48.0, "val_loss": 17.17115342617035, "val_acc": 56.0}
{"epoch": 5, "training_loss": 71.04579043388367, "training_acc": 52.0, "val_loss": 17.218488454818726, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.30951762199402, "training_acc": 50.0, "val_loss": 17.361317574977875, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.36426401138306, "training_acc": 48.0, "val_loss": 17.285554111003876, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.51188254356384, "training_acc": 52.0, "val_loss": 17.22267121076584, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.22893404960632, "training_acc": 52.0, "val_loss": 17.248503863811493, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.25624656677246, "training_acc": 52.0, "val_loss": 17.277026176452637, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26815605163574, "training_acc": 52.0, "val_loss": 17.261970043182373, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.28418040275574, "training_acc": 52.0, "val_loss": 17.243823409080505, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.25824475288391, "training_acc": 52.0, "val_loss": 17.24656969308853, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.23311948776245, "training_acc": 52.0, "val_loss": 17.225532233715057, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23122954368591, "training_acc": 52.0, "val_loss": 17.204222083091736, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.26438283920288, "training_acc": 52.0, "val_loss": 17.185211181640625, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.26940393447876, "training_acc": 52.0, "val_loss": 17.191821336746216, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25617289543152, "training_acc": 52.0, "val_loss": 17.20843017101288, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.22910857200623, "training_acc": 52.0, "val_loss": 17.228572070598602, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2502110004425, "training_acc": 52.0, "val_loss": 17.253994941711426, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26197028160095, "training_acc": 52.0, "val_loss": 17.256908118724823, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.30000329017639, "training_acc": 52.0, "val_loss": 17.23335087299347, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.23579025268555, "training_acc": 52.0, "val_loss": 17.236560583114624, "val_acc": 56.0}
