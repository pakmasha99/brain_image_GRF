"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 75.52340269088745, "training_acc": 43.0, "val_loss": 66.72115921974182, "val_acc": 52.0}
{"epoch": 1, "training_loss": 183.8826060295105, "training_acc": 55.0, "val_loss": 17.324163019657135, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.66741132736206, "training_acc": 41.0, "val_loss": 18.48253607749939, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.68534088134766, "training_acc": 53.0, "val_loss": 17.314721643924713, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.29955530166626, "training_acc": 41.0, "val_loss": 17.31146275997162, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.90338373184204, "training_acc": 53.0, "val_loss": 17.399685084819794, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.37125420570374, "training_acc": 53.0, "val_loss": 17.455540597438812, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.68817520141602, "training_acc": 53.0, "val_loss": 17.36770272254944, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22526860237122, "training_acc": 53.0, "val_loss": 17.31373816728592, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15957045555115, "training_acc": 53.0, "val_loss": 17.30940192937851, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28973507881165, "training_acc": 53.0, "val_loss": 17.320556938648224, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27770137786865, "training_acc": 53.0, "val_loss": 17.31320470571518, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18712258338928, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13684797286987, "training_acc": 53.0, "val_loss": 17.32294112443924, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.30871248245239, "training_acc": 53.0, "val_loss": 17.32601523399353, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2790253162384, "training_acc": 53.0, "val_loss": 17.34762191772461, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26717734336853, "training_acc": 53.0, "val_loss": 17.341068387031555, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15608334541321, "training_acc": 53.0, "val_loss": 17.32095330953598, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18834066390991, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12909936904907, "training_acc": 53.0, "val_loss": 17.309775948524475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14902544021606, "training_acc": 53.0, "val_loss": 17.309626936912537, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14871191978455, "training_acc": 53.0, "val_loss": 17.309726774692535, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14721035957336, "training_acc": 53.0, "val_loss": 17.311351001262665, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15194082260132, "training_acc": 53.0, "val_loss": 17.31807291507721, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15079879760742, "training_acc": 53.0, "val_loss": 17.322690784931183, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.21818947792053, "training_acc": 53.0, "val_loss": 17.3204243183136, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1327486038208, "training_acc": 53.0, "val_loss": 17.326638102531433, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1496741771698, "training_acc": 53.0, "val_loss": 17.331641912460327, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16662621498108, "training_acc": 53.0, "val_loss": 17.3362597823143, "val_acc": 52.0}
