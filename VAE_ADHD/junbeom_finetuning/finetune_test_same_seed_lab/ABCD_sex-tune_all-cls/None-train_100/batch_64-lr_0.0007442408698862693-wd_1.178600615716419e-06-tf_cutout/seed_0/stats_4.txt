"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 95.64912796020508, "training_acc": 39.0, "val_loss": 22.72140085697174, "val_acc": 52.0}
{"epoch": 1, "training_loss": 127.6704649925232, "training_acc": 51.0, "val_loss": 17.40182638168335, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14415717124939, "training_acc": 53.0, "val_loss": 18.64018142223358, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.77283191680908, "training_acc": 53.0, "val_loss": 17.33972281217575, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14149403572083, "training_acc": 53.0, "val_loss": 17.306190729141235, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.83275294303894, "training_acc": 43.0, "val_loss": 17.320339381694794, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.94421052932739, "training_acc": 53.0, "val_loss": 17.328211665153503, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19414782524109, "training_acc": 53.0, "val_loss": 17.313644289970398, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22456860542297, "training_acc": 53.0, "val_loss": 17.312484979629517, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1236846446991, "training_acc": 53.0, "val_loss": 17.308582365512848, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.34704971313477, "training_acc": 53.0, "val_loss": 17.3125222325325, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17927289009094, "training_acc": 53.0, "val_loss": 17.310531437397003, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.42217993736267, "training_acc": 53.0, "val_loss": 17.319171130657196, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22363328933716, "training_acc": 53.0, "val_loss": 17.315325140953064, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13335371017456, "training_acc": 53.0, "val_loss": 17.32003390789032, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14089131355286, "training_acc": 53.0, "val_loss": 17.32284277677536, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16565179824829, "training_acc": 53.0, "val_loss": 17.32736974954605, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14529228210449, "training_acc": 53.0, "val_loss": 17.339907586574554, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18019914627075, "training_acc": 53.0, "val_loss": 17.345210909843445, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20542454719543, "training_acc": 53.0, "val_loss": 17.34612286090851, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18725180625916, "training_acc": 53.0, "val_loss": 17.3316553235054, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16936922073364, "training_acc": 53.0, "val_loss": 17.31971949338913, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16626358032227, "training_acc": 53.0, "val_loss": 17.3143669962883, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14020085334778, "training_acc": 53.0, "val_loss": 17.31320470571518, "val_acc": 52.0}
