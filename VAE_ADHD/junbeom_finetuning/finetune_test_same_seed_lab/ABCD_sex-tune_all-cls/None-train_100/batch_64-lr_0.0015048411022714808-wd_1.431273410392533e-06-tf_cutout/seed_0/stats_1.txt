"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 105.51650047302246, "training_acc": 49.0, "val_loss": 288.40882778167725, "val_acc": 52.0}
{"epoch": 1, "training_loss": 799.4047923088074, "training_acc": 49.0, "val_loss": 17.37203150987625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.81981587409973, "training_acc": 49.0, "val_loss": 17.431166768074036, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.79049873352051, "training_acc": 55.0, "val_loss": 21.66929990053177, "val_acc": 48.0}
{"epoch": 4, "training_loss": 74.17068767547607, "training_acc": 59.0, "val_loss": 19.12136673927307, "val_acc": 52.0}
{"epoch": 5, "training_loss": 74.59613370895386, "training_acc": 53.0, "val_loss": 17.381559312343597, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.76475667953491, "training_acc": 53.0, "val_loss": 17.31569617986679, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18389177322388, "training_acc": 53.0, "val_loss": 17.321327328681946, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.139808177948, "training_acc": 53.0, "val_loss": 17.339147627353668, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.37074971199036, "training_acc": 53.0, "val_loss": 17.343831062316895, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17866468429565, "training_acc": 53.0, "val_loss": 17.313122749328613, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12820768356323, "training_acc": 53.0, "val_loss": 17.30869710445404, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23928999900818, "training_acc": 53.0, "val_loss": 17.31463372707367, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.23202514648438, "training_acc": 53.0, "val_loss": 17.31303036212921, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.192143201828, "training_acc": 53.0, "val_loss": 17.309491336345673, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14986443519592, "training_acc": 53.0, "val_loss": 17.31240451335907, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20944237709045, "training_acc": 53.0, "val_loss": 17.315387725830078, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22927188873291, "training_acc": 53.0, "val_loss": 17.329348623752594, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22649025917053, "training_acc": 53.0, "val_loss": 17.331573367118835, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1481773853302, "training_acc": 53.0, "val_loss": 17.320390045642853, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1725504398346, "training_acc": 53.0, "val_loss": 17.31279194355011, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13077116012573, "training_acc": 53.0, "val_loss": 17.311042547225952, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14651036262512, "training_acc": 53.0, "val_loss": 17.309904098510742, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14458727836609, "training_acc": 53.0, "val_loss": 17.309939861297607, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15224838256836, "training_acc": 53.0, "val_loss": 17.310898005962372, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14941143989563, "training_acc": 53.0, "val_loss": 17.314551770687103, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14380240440369, "training_acc": 53.0, "val_loss": 17.31732189655304, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18517231941223, "training_acc": 53.0, "val_loss": 17.317207157611847, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13046979904175, "training_acc": 53.0, "val_loss": 17.322656512260437, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13744282722473, "training_acc": 53.0, "val_loss": 17.327652871608734, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16404461860657, "training_acc": 53.0, "val_loss": 17.33323186635971, "val_acc": 52.0}
