"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.48117804527283, "training_acc": 52.0, "val_loss": 17.503154277801514, "val_acc": 52.0}
{"epoch": 1, "training_loss": 83.02906274795532, "training_acc": 45.0, "val_loss": 17.310495674610138, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.93087410926819, "training_acc": 49.0, "val_loss": 17.777833342552185, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.9328339099884, "training_acc": 47.0, "val_loss": 17.34554022550583, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.6729724407196, "training_acc": 43.0, "val_loss": 17.30668842792511, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22486853599548, "training_acc": 53.0, "val_loss": 17.307868599891663, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28195118904114, "training_acc": 53.0, "val_loss": 17.310622334480286, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.40108680725098, "training_acc": 47.0, "val_loss": 17.323391139507294, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29338645935059, "training_acc": 53.0, "val_loss": 17.31989085674286, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16733860969543, "training_acc": 53.0, "val_loss": 17.33504831790924, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.36066055297852, "training_acc": 53.0, "val_loss": 17.340946197509766, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.34858202934265, "training_acc": 53.0, "val_loss": 17.31458306312561, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16888523101807, "training_acc": 53.0, "val_loss": 17.31257140636444, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15455055236816, "training_acc": 53.0, "val_loss": 17.313329875469208, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15874600410461, "training_acc": 53.0, "val_loss": 17.31528490781784, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16861367225647, "training_acc": 53.0, "val_loss": 17.311519384384155, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12664914131165, "training_acc": 53.0, "val_loss": 17.314590513706207, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12432169914246, "training_acc": 53.0, "val_loss": 17.32614040374756, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10764026641846, "training_acc": 53.0, "val_loss": 17.35660880804062, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.26562118530273, "training_acc": 53.0, "val_loss": 17.37169176340103, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21870732307434, "training_acc": 53.0, "val_loss": 17.32933819293976, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08605122566223, "training_acc": 53.0, "val_loss": 17.314565181732178, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.46664118766785, "training_acc": 53.0, "val_loss": 17.323023080825806, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.31120276451111, "training_acc": 53.0, "val_loss": 17.31257140636444, "val_acc": 52.0}
