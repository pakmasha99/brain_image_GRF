"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 527.3644866943359, "training_acc": 53.0, "val_loss": 59635257600.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 144142182157.0719, "training_acc": 53.0, "val_loss": 35402.60925292969, "val_acc": 48.0}
{"epoch": 2, "training_loss": 158904.90869140625, "training_acc": 51.0, "val_loss": 12113.655090332031, "val_acc": 48.0}
{"epoch": 3, "training_loss": 40948.109375, "training_acc": 47.0, "val_loss": 49.89472031593323, "val_acc": 52.0}
{"epoch": 4, "training_loss": 58447.87715148926, "training_acc": 57.0, "val_loss": 341.6522741317749, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4879.596923828125, "training_acc": 49.0, "val_loss": 763.6133193969727, "val_acc": 48.0}
{"epoch": 6, "training_loss": 9628.010314941406, "training_acc": 41.0, "val_loss": 2344.9071884155273, "val_acc": 52.0}
{"epoch": 7, "training_loss": 6981.412467956543, "training_acc": 53.0, "val_loss": 384.61883068084717, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1674.553424835205, "training_acc": 39.0, "val_loss": 1124.6073722839355, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3233.8103065490723, "training_acc": 43.0, "val_loss": 1896.4118957519531, "val_acc": 48.0}
{"epoch": 10, "training_loss": 5503.37043762207, "training_acc": 47.0, "val_loss": 1290.185260772705, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4197.241188049316, "training_acc": 53.0, "val_loss": 149.5823621749878, "val_acc": 52.0}
{"epoch": 12, "training_loss": 802.7282218933105, "training_acc": 43.0, "val_loss": 41.15172624588013, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1393.3301849365234, "training_acc": 47.0, "val_loss": 193.12913417816162, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1901.7597198486328, "training_acc": 53.0, "val_loss": 584.0419292449951, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1943.5053596496582, "training_acc": 47.0, "val_loss": 50.69009065628052, "val_acc": 48.0}
{"epoch": 16, "training_loss": 709.8129196166992, "training_acc": 45.0, "val_loss": 18.459415435791016, "val_acc": 48.0}
{"epoch": 17, "training_loss": 237.74132919311523, "training_acc": 47.0, "val_loss": 301.4017343521118, "val_acc": 52.0}
{"epoch": 18, "training_loss": 849.960910320282, "training_acc": 53.0, "val_loss": 658.8293075561523, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2170.9810791015625, "training_acc": 47.0, "val_loss": 56.201738119125366, "val_acc": 48.0}
{"epoch": 20, "training_loss": 188.7652678489685, "training_acc": 45.0, "val_loss": 72.48380780220032, "val_acc": 48.0}
{"epoch": 21, "training_loss": 201.11755180358887, "training_acc": 55.0, "val_loss": 20.006974041461945, "val_acc": 48.0}
{"epoch": 22, "training_loss": 82.9514045715332, "training_acc": 55.0, "val_loss": 22.619426250457764, "val_acc": 48.0}
{"epoch": 23, "training_loss": 88.14618968963623, "training_acc": 47.0, "val_loss": 17.92987734079361, "val_acc": 52.0}
{"epoch": 24, "training_loss": 73.70471358299255, "training_acc": 45.0, "val_loss": 17.347732186317444, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.42852878570557, "training_acc": 50.0, "val_loss": 17.823047935962677, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.6544041633606, "training_acc": 53.0, "val_loss": 17.313337326049805, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.35546016693115, "training_acc": 48.0, "val_loss": 17.415566742420197, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.41637134552002, "training_acc": 44.0, "val_loss": 17.60530024766922, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.29569721221924, "training_acc": 53.0, "val_loss": 17.444637417793274, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.33958911895752, "training_acc": 53.0, "val_loss": 17.302753031253815, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.599858045578, "training_acc": 55.0, "val_loss": 23.53932112455368, "val_acc": 48.0}
{"epoch": 32, "training_loss": 86.34636640548706, "training_acc": 55.0, "val_loss": 17.403987050056458, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.57742619514465, "training_acc": 45.0, "val_loss": 17.56465882062912, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.32154202461243, "training_acc": 47.0, "val_loss": 17.379900813102722, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.18721079826355, "training_acc": 47.0, "val_loss": 17.354142665863037, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.40542578697205, "training_acc": 46.0, "val_loss": 17.374522984027863, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.69501996040344, "training_acc": 47.0, "val_loss": 17.31676608324051, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.96635961532593, "training_acc": 53.0, "val_loss": 17.52042919397354, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.06119894981384, "training_acc": 53.0, "val_loss": 17.411164939403534, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.73508787155151, "training_acc": 53.0, "val_loss": 17.330680787563324, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.35732769966125, "training_acc": 47.0, "val_loss": 17.32838749885559, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.25658750534058, "training_acc": 52.0, "val_loss": 17.311589419841766, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.24032807350159, "training_acc": 53.0, "val_loss": 17.311930656433105, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.20550298690796, "training_acc": 53.0, "val_loss": 17.310218513011932, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.41149854660034, "training_acc": 53.0, "val_loss": 17.310769855976105, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.1283187866211, "training_acc": 53.0, "val_loss": 17.319455742836, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.10733795166016, "training_acc": 53.0, "val_loss": 17.385128140449524, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.5679132938385, "training_acc": 53.0, "val_loss": 17.325881123542786, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.2283067703247, "training_acc": 53.0, "val_loss": 17.332740128040314, "val_acc": 52.0}
