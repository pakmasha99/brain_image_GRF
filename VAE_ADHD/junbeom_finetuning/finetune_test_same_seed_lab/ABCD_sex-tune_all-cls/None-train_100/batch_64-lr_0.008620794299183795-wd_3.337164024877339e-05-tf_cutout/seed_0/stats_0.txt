"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 471.9896774291992, "training_acc": 50.0, "val_loss": 1067674000.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 2871850197.0654297, "training_acc": 52.0, "val_loss": 326948.6572265625, "val_acc": 44.0}
{"epoch": 2, "training_loss": 820129.7869873047, "training_acc": 46.0, "val_loss": 3766036.328125, "val_acc": 44.0}
{"epoch": 3, "training_loss": 9314368.316894531, "training_acc": 48.0, "val_loss": 1071.7647552490234, "val_acc": 56.0}
{"epoch": 4, "training_loss": 4228.788650512695, "training_acc": 52.0, "val_loss": 3420.835494995117, "val_acc": 44.0}
{"epoch": 5, "training_loss": 11118.038604736328, "training_acc": 44.0, "val_loss": 2005.5192947387695, "val_acc": 44.0}
{"epoch": 6, "training_loss": 5560.428657531738, "training_acc": 50.0, "val_loss": 352.4017810821533, "val_acc": 44.0}
{"epoch": 7, "training_loss": 13032.774719238281, "training_acc": 52.0, "val_loss": 238.7909173965454, "val_acc": 44.0}
{"epoch": 8, "training_loss": 991.7810745239258, "training_acc": 42.0, "val_loss": 16905.667114257812, "val_acc": 44.0}
{"epoch": 9, "training_loss": 41611.22583770752, "training_acc": 48.0, "val_loss": 1880.704689025879, "val_acc": 56.0}
{"epoch": 10, "training_loss": 6027.271759033203, "training_acc": 50.0, "val_loss": 1168.880558013916, "val_acc": 56.0}
{"epoch": 11, "training_loss": 3924.9347915649414, "training_acc": 52.0, "val_loss": 844.1762924194336, "val_acc": 44.0}
{"epoch": 12, "training_loss": 2626.0184478759766, "training_acc": 46.0, "val_loss": 158.262300491333, "val_acc": 44.0}
{"epoch": 13, "training_loss": 860.6221809387207, "training_acc": 52.0, "val_loss": 193.73571872711182, "val_acc": 56.0}
{"epoch": 14, "training_loss": 2632.3783569335938, "training_acc": 48.0, "val_loss": 686.0260009765625, "val_acc": 44.0}
{"epoch": 15, "training_loss": 1723.030710220337, "training_acc": 48.0, "val_loss": 462.35499382019043, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1580.488166809082, "training_acc": 52.0, "val_loss": 330.73132038116455, "val_acc": 44.0}
{"epoch": 17, "training_loss": 1020.0200157165527, "training_acc": 48.0, "val_loss": 101.4211654663086, "val_acc": 56.0}
{"epoch": 18, "training_loss": 352.8072671890259, "training_acc": 52.0, "val_loss": 108.00483226776123, "val_acc": 44.0}
{"epoch": 19, "training_loss": 65727.07150268555, "training_acc": 48.0, "val_loss": 175.10693073272705, "val_acc": 56.0}
{"epoch": 20, "training_loss": 840.1566200256348, "training_acc": 52.0, "val_loss": 326.23095512390137, "val_acc": 56.0}
{"epoch": 21, "training_loss": 1096.8888854980469, "training_acc": 52.0, "val_loss": 956.302547454834, "val_acc": 44.0}
{"epoch": 22, "training_loss": 2699.185272216797, "training_acc": 44.0, "val_loss": 541.7716026306152, "val_acc": 44.0}
{"epoch": 23, "training_loss": 2090.2392959594727, "training_acc": 46.0, "val_loss": 48.914581537246704, "val_acc": 56.0}
{"epoch": 24, "training_loss": 789.7835311889648, "training_acc": 54.0, "val_loss": 63.50833177566528, "val_acc": 56.0}
{"epoch": 25, "training_loss": 448.75273513793945, "training_acc": 48.0, "val_loss": 50.42722821235657, "val_acc": 44.0}
{"epoch": 26, "training_loss": 744.0819549560547, "training_acc": 38.0, "val_loss": 17.216207087039948, "val_acc": 56.0}
{"epoch": 27, "training_loss": 71.77286148071289, "training_acc": 46.0, "val_loss": 329.64351177215576, "val_acc": 56.0}
{"epoch": 28, "training_loss": 1099.8710327148438, "training_acc": 46.0, "val_loss": 202.4158239364624, "val_acc": 44.0}
{"epoch": 29, "training_loss": 495.5787148475647, "training_acc": 52.0, "val_loss": 514.8804664611816, "val_acc": 44.0}
{"epoch": 30, "training_loss": 1716.5786094665527, "training_acc": 40.0, "val_loss": 62.945592403411865, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1115.4087829589844, "training_acc": 42.0, "val_loss": 419.74987983703613, "val_acc": 56.0}
{"epoch": 32, "training_loss": 1198.7746925354004, "training_acc": 52.0, "val_loss": 20.1242133975029, "val_acc": 44.0}
{"epoch": 33, "training_loss": 107.00916719436646, "training_acc": 48.0, "val_loss": 17.285960912704468, "val_acc": 56.0}
{"epoch": 34, "training_loss": 166.47011947631836, "training_acc": 45.0, "val_loss": 72.5062906742096, "val_acc": 44.0}
{"epoch": 35, "training_loss": 223.30596113204956, "training_acc": 48.0, "val_loss": 59.430527687072754, "val_acc": 56.0}
{"epoch": 36, "training_loss": 220.170907497406, "training_acc": 52.0, "val_loss": 23.971176147460938, "val_acc": 44.0}
{"epoch": 37, "training_loss": 122.79993152618408, "training_acc": 48.0, "val_loss": 18.588729202747345, "val_acc": 56.0}
{"epoch": 38, "training_loss": 82.27407193183899, "training_acc": 52.0, "val_loss": 18.457674980163574, "val_acc": 56.0}
{"epoch": 39, "training_loss": 83.876455783844, "training_acc": 56.0, "val_loss": 17.619800567626953, "val_acc": 56.0}
{"epoch": 40, "training_loss": 73.2978515625, "training_acc": 52.0, "val_loss": 17.208902537822723, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.7787549495697, "training_acc": 50.0, "val_loss": 17.17035323381424, "val_acc": 56.0}
{"epoch": 42, "training_loss": 70.59071755409241, "training_acc": 52.0, "val_loss": 17.139442265033722, "val_acc": 56.0}
{"epoch": 43, "training_loss": 70.60408973693848, "training_acc": 52.0, "val_loss": 19.097325205802917, "val_acc": 44.0}
{"epoch": 44, "training_loss": 75.88183760643005, "training_acc": 48.0, "val_loss": 18.121221661567688, "val_acc": 56.0}
{"epoch": 45, "training_loss": 72.25196719169617, "training_acc": 46.0, "val_loss": 17.4044668674469, "val_acc": 56.0}
{"epoch": 46, "training_loss": 70.81059527397156, "training_acc": 52.0, "val_loss": 17.754793167114258, "val_acc": 56.0}
{"epoch": 47, "training_loss": 72.07453799247742, "training_acc": 48.0, "val_loss": 17.25718528032303, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.86829042434692, "training_acc": 52.0, "val_loss": 17.21884459257126, "val_acc": 56.0}
{"epoch": 49, "training_loss": 70.19153332710266, "training_acc": 52.0, "val_loss": 17.237989604473114, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.20886278152466, "training_acc": 54.0, "val_loss": 17.892475426197052, "val_acc": 56.0}
{"epoch": 51, "training_loss": 70.66339945793152, "training_acc": 48.0, "val_loss": 17.724108695983887, "val_acc": 56.0}
{"epoch": 52, "training_loss": 70.32106518745422, "training_acc": 47.0, "val_loss": 17.20506250858307, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.32162404060364, "training_acc": 52.0, "val_loss": 17.15378314256668, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.60291242599487, "training_acc": 52.0, "val_loss": 17.16446876525879, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.44821953773499, "training_acc": 52.0, "val_loss": 17.236852645874023, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.18888306617737, "training_acc": 53.0, "val_loss": 17.40221679210663, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.65396428108215, "training_acc": 48.0, "val_loss": 17.4694761633873, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.65408992767334, "training_acc": 48.0, "val_loss": 17.299315333366394, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.10195541381836, "training_acc": 53.0, "val_loss": 17.186887562274933, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.60189366340637, "training_acc": 52.0, "val_loss": 17.151929438114166, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.394864320755, "training_acc": 52.0, "val_loss": 17.169372737407684, "val_acc": 56.0}
