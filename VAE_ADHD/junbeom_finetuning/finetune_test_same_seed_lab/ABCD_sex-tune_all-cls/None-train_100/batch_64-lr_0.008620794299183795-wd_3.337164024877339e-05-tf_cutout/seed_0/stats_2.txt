"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 718.8093414306641, "training_acc": 45.0, "val_loss": 70808512.5, "val_acc": 48.0}
{"epoch": 1, "training_loss": 204878106.64257812, "training_acc": 41.0, "val_loss": 42424.27978515625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 122472.9839477539, "training_acc": 43.0, "val_loss": 50274.444580078125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 137095.41464996338, "training_acc": 53.0, "val_loss": 1845.257568359375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5706.347980499268, "training_acc": 41.0, "val_loss": 2051.6845703125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 6149.038761138916, "training_acc": 47.0, "val_loss": 648.3885288238525, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1763.2739658355713, "training_acc": 53.0, "val_loss": 1612.6371383666992, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3807.4012336730957, "training_acc": 47.0, "val_loss": 196.60943746566772, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1231.765625, "training_acc": 53.0, "val_loss": 496.09522819519043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2733.072006225586, "training_acc": 45.0, "val_loss": 532.6086521148682, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1400.7686500549316, "training_acc": 47.0, "val_loss": 387.88952827453613, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1219.5548706054688, "training_acc": 53.0, "val_loss": 21.308252215385437, "val_acc": 52.0}
{"epoch": 12, "training_loss": 496.9100685119629, "training_acc": 55.0, "val_loss": 307.69457817077637, "val_acc": 52.0}
{"epoch": 13, "training_loss": 869.7976236343384, "training_acc": 53.0, "val_loss": 2472.8612899780273, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6563.854831695557, "training_acc": 53.0, "val_loss": 5572.834777832031, "val_acc": 48.0}
{"epoch": 15, "training_loss": 15198.68253326416, "training_acc": 47.0, "val_loss": 1077.0143508911133, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2727.046208381653, "training_acc": 51.0, "val_loss": 496.99573516845703, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1607.470142364502, "training_acc": 53.0, "val_loss": 738.5293006896973, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1900.3357315063477, "training_acc": 51.0, "val_loss": 18.506841361522675, "val_acc": 52.0}
{"epoch": 19, "training_loss": 243.73721885681152, "training_acc": 53.0, "val_loss": 67.69354343414307, "val_acc": 52.0}
{"epoch": 20, "training_loss": 221.2351689338684, "training_acc": 53.0, "val_loss": 139.80003595352173, "val_acc": 48.0}
{"epoch": 21, "training_loss": 454.04789543151855, "training_acc": 47.0, "val_loss": 134.27828550338745, "val_acc": 52.0}
{"epoch": 22, "training_loss": 490.55022621154785, "training_acc": 53.0, "val_loss": 33.91038775444031, "val_acc": 52.0}
{"epoch": 23, "training_loss": 203.23624324798584, "training_acc": 53.0, "val_loss": 17.878516018390656, "val_acc": 52.0}
{"epoch": 24, "training_loss": 75.25808262825012, "training_acc": 53.0, "val_loss": 136.27467155456543, "val_acc": 48.0}
{"epoch": 25, "training_loss": 502.5081911087036, "training_acc": 41.0, "val_loss": 19.924022257328033, "val_acc": 52.0}
{"epoch": 26, "training_loss": 131.47817611694336, "training_acc": 47.0, "val_loss": 17.489829659461975, "val_acc": 52.0}
{"epoch": 27, "training_loss": 77.81788969039917, "training_acc": 53.0, "val_loss": 17.708563804626465, "val_acc": 52.0}
{"epoch": 28, "training_loss": 99.30187845230103, "training_acc": 45.0, "val_loss": 17.329290509223938, "val_acc": 52.0}
{"epoch": 29, "training_loss": 79.88215732574463, "training_acc": 53.0, "val_loss": 20.357656478881836, "val_acc": 52.0}
{"epoch": 30, "training_loss": 77.31685757637024, "training_acc": 49.0, "val_loss": 19.30093914270401, "val_acc": 48.0}
{"epoch": 31, "training_loss": 75.33601355552673, "training_acc": 47.0, "val_loss": 18.096596002578735, "val_acc": 52.0}
{"epoch": 32, "training_loss": 71.76902413368225, "training_acc": 53.0, "val_loss": 17.655280232429504, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.64485096931458, "training_acc": 48.0, "val_loss": 17.43406653404236, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.96706867218018, "training_acc": 46.0, "val_loss": 17.371170222759247, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.91839909553528, "training_acc": 51.0, "val_loss": 17.48887151479721, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.65180563926697, "training_acc": 47.0, "val_loss": 18.207915127277374, "val_acc": 52.0}
{"epoch": 37, "training_loss": 71.89006114006042, "training_acc": 53.0, "val_loss": 17.45203286409378, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.59340000152588, "training_acc": 53.0, "val_loss": 17.730791866779327, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.9994068145752, "training_acc": 47.0, "val_loss": 17.34408289194107, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.53148007392883, "training_acc": 53.0, "val_loss": 18.257896602153778, "val_acc": 52.0}
{"epoch": 41, "training_loss": 71.32841420173645, "training_acc": 53.0, "val_loss": 17.497539520263672, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.45874547958374, "training_acc": 50.0, "val_loss": 17.45489090681076, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.89477634429932, "training_acc": 47.0, "val_loss": 17.31099784374237, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.47047114372253, "training_acc": 52.0, "val_loss": 17.362409830093384, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.06452417373657, "training_acc": 53.0, "val_loss": 17.30155497789383, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.41157555580139, "training_acc": 51.0, "val_loss": 17.41752326488495, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.65158200263977, "training_acc": 53.0, "val_loss": 17.37879514694214, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.97351932525635, "training_acc": 53.0, "val_loss": 17.64634996652603, "val_acc": 52.0}
{"epoch": 49, "training_loss": 70.1439061164856, "training_acc": 53.0, "val_loss": 17.461617290973663, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.01626229286194, "training_acc": 53.0, "val_loss": 17.346331477165222, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.25183701515198, "training_acc": 54.0, "val_loss": 17.416946589946747, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.82030487060547, "training_acc": 52.0, "val_loss": 17.30371117591858, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.99708008766174, "training_acc": 53.0, "val_loss": 17.51866340637207, "val_acc": 52.0}
{"epoch": 54, "training_loss": 71.71423268318176, "training_acc": 49.0, "val_loss": 17.36673265695572, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.32907199859619, "training_acc": 53.0, "val_loss": 17.403343319892883, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.43900990486145, "training_acc": 52.0, "val_loss": 17.487479746341705, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.89206957817078, "training_acc": 47.0, "val_loss": 17.311808466911316, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.94488310813904, "training_acc": 50.0, "val_loss": 17.40095466375351, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.44675183296204, "training_acc": 52.0, "val_loss": 17.302730679512024, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.90676546096802, "training_acc": 52.0, "val_loss": 17.302995920181274, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.52321553230286, "training_acc": 49.0, "val_loss": 17.363324761390686, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.5038959980011, "training_acc": 47.0, "val_loss": 17.330816388130188, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.02243781089783, "training_acc": 53.0, "val_loss": 17.854690551757812, "val_acc": 52.0}
{"epoch": 64, "training_loss": 71.17170214653015, "training_acc": 53.0, "val_loss": 17.634953558444977, "val_acc": 52.0}
