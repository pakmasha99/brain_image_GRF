"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 274.33214569091797, "training_acc": 53.0, "val_loss": 8145314611200.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 22193522095239.6, "training_acc": 47.0, "val_loss": 637547.509765625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4054684.1875, "training_acc": 53.0, "val_loss": 165056.93359375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 730371.818359375, "training_acc": 45.0, "val_loss": 31678.802490234375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 113930.49609375, "training_acc": 51.0, "val_loss": 7352.9296875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 33424.88830566406, "training_acc": 51.0, "val_loss": 1422.6996421813965, "val_acc": 48.0}
{"epoch": 6, "training_loss": 22129.826416015625, "training_acc": 55.0, "val_loss": 4375.646209716797, "val_acc": 52.0}
{"epoch": 7, "training_loss": 11487.588844299316, "training_acc": 53.0, "val_loss": 713.9707565307617, "val_acc": 52.0}
{"epoch": 8, "training_loss": 4324.622375488281, "training_acc": 61.0, "val_loss": 1378.5944938659668, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5855.078689575195, "training_acc": 45.0, "val_loss": 360.25896072387695, "val_acc": 48.0}
{"epoch": 10, "training_loss": 4797.4833984375, "training_acc": 51.0, "val_loss": 1424.74946975708, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3614.2919998168945, "training_acc": 63.0, "val_loss": 328.69577407836914, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2091.9266967773438, "training_acc": 61.0, "val_loss": 328.44207286834717, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2197.3526153564453, "training_acc": 39.0, "val_loss": 3269.198226928711, "val_acc": 52.0}
{"epoch": 14, "training_loss": 9800.448867797852, "training_acc": 47.0, "val_loss": 264.1827344894409, "val_acc": 52.0}
{"epoch": 15, "training_loss": 857.196325302124, "training_acc": 57.0, "val_loss": 120.80987691879272, "val_acc": 52.0}
{"epoch": 16, "training_loss": 818.1858520507812, "training_acc": 49.0, "val_loss": 457.3382377624512, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1277.6998558044434, "training_acc": 53.0, "val_loss": 1083.554458618164, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3547.66056060791, "training_acc": 47.0, "val_loss": 1314.7584915161133, "val_acc": 52.0}
{"epoch": 19, "training_loss": 4240.038101196289, "training_acc": 53.0, "val_loss": 124.73481893539429, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1080.974105834961, "training_acc": 49.0, "val_loss": 528.4402370452881, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1831.685546875, "training_acc": 47.0, "val_loss": 28.83494198322296, "val_acc": 52.0}
{"epoch": 22, "training_loss": 247.80774879455566, "training_acc": 53.0, "val_loss": 90.42741060256958, "val_acc": 52.0}
{"epoch": 23, "training_loss": 307.11479091644287, "training_acc": 53.0, "val_loss": 60.838013887405396, "val_acc": 48.0}
{"epoch": 24, "training_loss": 234.75271606445312, "training_acc": 43.0, "val_loss": 20.356284081935883, "val_acc": 52.0}
{"epoch": 25, "training_loss": 113.16930389404297, "training_acc": 51.0, "val_loss": 18.63844096660614, "val_acc": 52.0}
{"epoch": 26, "training_loss": 109.91698122024536, "training_acc": 53.0, "val_loss": 31.129366159439087, "val_acc": 52.0}
{"epoch": 27, "training_loss": 163.60058879852295, "training_acc": 45.0, "val_loss": 31.009382009506226, "val_acc": 48.0}
{"epoch": 28, "training_loss": 145.47265577316284, "training_acc": 45.0, "val_loss": 40.11210501194, "val_acc": 52.0}
{"epoch": 29, "training_loss": 133.49181056022644, "training_acc": 48.0, "val_loss": 28.803294897079468, "val_acc": 48.0}
{"epoch": 30, "training_loss": 100.58565068244934, "training_acc": 47.0, "val_loss": 25.830361247062683, "val_acc": 52.0}
{"epoch": 31, "training_loss": 101.70222806930542, "training_acc": 53.0, "val_loss": 17.298339307308197, "val_acc": 52.0}
{"epoch": 32, "training_loss": 79.63330483436584, "training_acc": 52.0, "val_loss": 19.363071024417877, "val_acc": 48.0}
{"epoch": 33, "training_loss": 69.97179245948792, "training_acc": 57.0, "val_loss": 25.621020793914795, "val_acc": 52.0}
{"epoch": 34, "training_loss": 92.57325839996338, "training_acc": 53.0, "val_loss": 21.50433510541916, "val_acc": 48.0}
{"epoch": 35, "training_loss": 83.52866458892822, "training_acc": 47.0, "val_loss": 17.918555438518524, "val_acc": 52.0}
{"epoch": 36, "training_loss": 73.44655704498291, "training_acc": 53.0, "val_loss": 18.201830983161926, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70.94011664390564, "training_acc": 50.0, "val_loss": 18.575401604175568, "val_acc": 52.0}
{"epoch": 38, "training_loss": 72.8594286441803, "training_acc": 47.0, "val_loss": 18.068289756774902, "val_acc": 52.0}
{"epoch": 39, "training_loss": 72.69053387641907, "training_acc": 53.0, "val_loss": 17.259103059768677, "val_acc": 52.0}
{"epoch": 40, "training_loss": 71.80938339233398, "training_acc": 46.0, "val_loss": 17.54952073097229, "val_acc": 52.0}
{"epoch": 41, "training_loss": 72.77491307258606, "training_acc": 45.0, "val_loss": 17.943793535232544, "val_acc": 52.0}
{"epoch": 42, "training_loss": 72.02333807945251, "training_acc": 49.0, "val_loss": 17.721618711948395, "val_acc": 52.0}
{"epoch": 43, "training_loss": 71.64453291893005, "training_acc": 51.0, "val_loss": 17.346782982349396, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.19015645980835, "training_acc": 53.0, "val_loss": 17.26282835006714, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.60557198524475, "training_acc": 47.0, "val_loss": 17.33507066965103, "val_acc": 52.0}
{"epoch": 46, "training_loss": 71.20183658599854, "training_acc": 46.0, "val_loss": 17.38566905260086, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.12376832962036, "training_acc": 53.0, "val_loss": 17.37397313117981, "val_acc": 52.0}
{"epoch": 48, "training_loss": 70.44631505012512, "training_acc": 42.0, "val_loss": 17.31172949075699, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.59452867507935, "training_acc": 53.0, "val_loss": 17.448338866233826, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.76344919204712, "training_acc": 50.0, "val_loss": 17.32666790485382, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.7682945728302, "training_acc": 51.0, "val_loss": 17.30908900499344, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.7379081249237, "training_acc": 53.0, "val_loss": 17.27132797241211, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.87707257270813, "training_acc": 53.0, "val_loss": 17.531302571296692, "val_acc": 52.0}
{"epoch": 54, "training_loss": 70.54741954803467, "training_acc": 44.0, "val_loss": 17.310744524002075, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.60665488243103, "training_acc": 55.0, "val_loss": 17.690829932689667, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.88848686218262, "training_acc": 53.0, "val_loss": 17.28532761335373, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.20262265205383, "training_acc": 49.0, "val_loss": 17.376619577407837, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.53287982940674, "training_acc": 53.0, "val_loss": 18.691259622573853, "val_acc": 52.0}
