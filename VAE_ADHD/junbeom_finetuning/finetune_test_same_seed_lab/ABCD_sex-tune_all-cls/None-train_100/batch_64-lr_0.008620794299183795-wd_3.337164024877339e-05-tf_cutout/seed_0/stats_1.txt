"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 263.9849262237549, "training_acc": 53.0, "val_loss": 2383364800.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 6850088592.766235, "training_acc": 47.0, "val_loss": 1355191.50390625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3252220.455078125, "training_acc": 53.0, "val_loss": 9243.234252929688, "val_acc": 48.0}
{"epoch": 3, "training_loss": 37404.83483886719, "training_acc": 55.0, "val_loss": 661.1823558807373, "val_acc": 52.0}
{"epoch": 4, "training_loss": 11142.330322265625, "training_acc": 59.0, "val_loss": 64.82948064804077, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1940.9295043945312, "training_acc": 49.0, "val_loss": 469.5147514343262, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1673.4938888549805, "training_acc": 43.0, "val_loss": 584.5187664031982, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1818.6072578430176, "training_acc": 53.0, "val_loss": 47.08537459373474, "val_acc": 52.0}
{"epoch": 8, "training_loss": 637.3578948974609, "training_acc": 45.0, "val_loss": 54.81875538825989, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1739.3068084716797, "training_acc": 49.0, "val_loss": 343.3087348937988, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1377.911060333252, "training_acc": 51.0, "val_loss": 98.7045407295227, "val_acc": 48.0}
{"epoch": 11, "training_loss": 287.9587812423706, "training_acc": 51.0, "val_loss": 77.13621258735657, "val_acc": 48.0}
{"epoch": 12, "training_loss": 364.61807441711426, "training_acc": 49.0, "val_loss": 33.636584877967834, "val_acc": 52.0}
{"epoch": 13, "training_loss": 326.7120532989502, "training_acc": 47.0, "val_loss": 104.16415929794312, "val_acc": 48.0}
{"epoch": 14, "training_loss": 261.4046220779419, "training_acc": 55.0, "val_loss": 92.16954112052917, "val_acc": 52.0}
{"epoch": 15, "training_loss": 297.64008045196533, "training_acc": 53.0, "val_loss": 18.393118679523468, "val_acc": 48.0}
{"epoch": 16, "training_loss": 74.68932580947876, "training_acc": 47.0, "val_loss": 43.55764985084534, "val_acc": 52.0}
{"epoch": 17, "training_loss": 124.66607356071472, "training_acc": 55.0, "val_loss": 23.67449551820755, "val_acc": 48.0}
{"epoch": 18, "training_loss": 134.60595798492432, "training_acc": 39.0, "val_loss": 186.61422729492188, "val_acc": 48.0}
{"epoch": 19, "training_loss": 550.139931678772, "training_acc": 47.0, "val_loss": 171.64723873138428, "val_acc": 52.0}
{"epoch": 20, "training_loss": 651.5032615661621, "training_acc": 53.0, "val_loss": 34.76836979389191, "val_acc": 52.0}
{"epoch": 21, "training_loss": 291.79429054260254, "training_acc": 39.0, "val_loss": 59.25073027610779, "val_acc": 48.0}
{"epoch": 22, "training_loss": 184.52531790733337, "training_acc": 47.0, "val_loss": 29.798582196235657, "val_acc": 52.0}
{"epoch": 23, "training_loss": 115.3452000617981, "training_acc": 53.0, "val_loss": 22.357581555843353, "val_acc": 52.0}
{"epoch": 24, "training_loss": 84.89670658111572, "training_acc": 53.0, "val_loss": 17.320935428142548, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.15023970603943, "training_acc": 58.0, "val_loss": 17.699719965457916, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.89824628829956, "training_acc": 50.0, "val_loss": 17.3775777220726, "val_acc": 52.0}
{"epoch": 27, "training_loss": 72.29631495475769, "training_acc": 53.0, "val_loss": 18.908800184726715, "val_acc": 48.0}
{"epoch": 28, "training_loss": 76.40752649307251, "training_acc": 47.0, "val_loss": 19.44812685251236, "val_acc": 52.0}
{"epoch": 29, "training_loss": 75.21518301963806, "training_acc": 53.0, "val_loss": 17.487384378910065, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.5414080619812, "training_acc": 52.0, "val_loss": 17.8522527217865, "val_acc": 52.0}
{"epoch": 31, "training_loss": 71.46005249023438, "training_acc": 47.0, "val_loss": 17.263856530189514, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.6759045124054, "training_acc": 53.0, "val_loss": 18.167224526405334, "val_acc": 52.0}
{"epoch": 33, "training_loss": 71.49615550041199, "training_acc": 53.0, "val_loss": 17.251266539096832, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.57348942756653, "training_acc": 50.0, "val_loss": 17.40299165248871, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.99472522735596, "training_acc": 41.0, "val_loss": 17.300815880298615, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.37913966178894, "training_acc": 53.0, "val_loss": 17.261336743831635, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.30738306045532, "training_acc": 53.0, "val_loss": 17.272964119911194, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.42186975479126, "training_acc": 53.0, "val_loss": 17.268085479736328, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.27634739875793, "training_acc": 53.0, "val_loss": 17.273879051208496, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.58104705810547, "training_acc": 55.0, "val_loss": 17.25666970014572, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.22219634056091, "training_acc": 51.0, "val_loss": 17.285114526748657, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.03740930557251, "training_acc": 53.0, "val_loss": 17.296451330184937, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.39085698127747, "training_acc": 53.0, "val_loss": 17.260736227035522, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.73639273643494, "training_acc": 53.0, "val_loss": 17.261552810668945, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.93540740013123, "training_acc": 40.0, "val_loss": 17.257145047187805, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.00634598731995, "training_acc": 54.0, "val_loss": 17.428790032863617, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.50822806358337, "training_acc": 53.0, "val_loss": 17.491741478443146, "val_acc": 52.0}
{"epoch": 48, "training_loss": 70.05667901039124, "training_acc": 53.0, "val_loss": 17.322760820388794, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.22235441207886, "training_acc": 53.0, "val_loss": 17.262576520442963, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.12591171264648, "training_acc": 53.0, "val_loss": 17.285442352294922, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.92654800415039, "training_acc": 42.0, "val_loss": 17.259815335273743, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.15398144721985, "training_acc": 54.0, "val_loss": 17.538529634475708, "val_acc": 52.0}
