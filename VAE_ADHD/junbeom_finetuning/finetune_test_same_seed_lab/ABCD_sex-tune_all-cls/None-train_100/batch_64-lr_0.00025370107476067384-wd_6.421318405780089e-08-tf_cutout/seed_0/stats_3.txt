"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.64033627510071, "training_acc": 45.0, "val_loss": 17.310887575149536, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.6584255695343, "training_acc": 53.0, "val_loss": 17.320983111858368, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.45068550109863, "training_acc": 53.0, "val_loss": 17.320558428764343, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.29032444953918, "training_acc": 53.0, "val_loss": 17.31068789958954, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13505244255066, "training_acc": 53.0, "val_loss": 17.332202196121216, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2781572341919, "training_acc": 53.0, "val_loss": 17.309555411338806, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.26395344734192, "training_acc": 53.0, "val_loss": 17.312461137771606, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1704454421997, "training_acc": 53.0, "val_loss": 17.326340079307556, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1360764503479, "training_acc": 53.0, "val_loss": 17.378568649291992, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29159736633301, "training_acc": 53.0, "val_loss": 17.354610562324524, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16513395309448, "training_acc": 53.0, "val_loss": 17.308299243450165, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14611172676086, "training_acc": 53.0, "val_loss": 17.318077385425568, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.55837607383728, "training_acc": 45.0, "val_loss": 17.318792641162872, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.31969499588013, "training_acc": 53.0, "val_loss": 17.333728075027466, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18173313140869, "training_acc": 53.0, "val_loss": 17.346641421318054, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.35417294502258, "training_acc": 53.0, "val_loss": 17.32349693775177, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15125393867493, "training_acc": 53.0, "val_loss": 17.329129576683044, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22364020347595, "training_acc": 53.0, "val_loss": 17.3196479678154, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.144770860672, "training_acc": 53.0, "val_loss": 17.32507050037384, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.52203798294067, "training_acc": 53.0, "val_loss": 17.3179030418396, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23119735717773, "training_acc": 53.0, "val_loss": 17.319409549236298, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.34091591835022, "training_acc": 47.0, "val_loss": 17.315959930419922, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.88981008529663, "training_acc": 53.0, "val_loss": 17.314225435256958, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12808609008789, "training_acc": 53.0, "val_loss": 17.308856546878815, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20215630531311, "training_acc": 53.0, "val_loss": 17.312079668045044, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19593501091003, "training_acc": 53.0, "val_loss": 17.308734357357025, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.23191213607788, "training_acc": 53.0, "val_loss": 17.314521968364716, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.81713199615479, "training_acc": 53.0, "val_loss": 17.356272041797638, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27914142608643, "training_acc": 53.0, "val_loss": 17.320670187473297, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21753811836243, "training_acc": 53.0, "val_loss": 17.312155663967133, "val_acc": 52.0}
