"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.04788398742676, "training_acc": 52.0, "val_loss": 17.165103554725647, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23147320747375, "training_acc": 52.0, "val_loss": 17.44297295808792, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.82558178901672, "training_acc": 46.0, "val_loss": 17.33878254890442, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.48904371261597, "training_acc": 45.0, "val_loss": 17.363332211971283, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.34133124351501, "training_acc": 48.0, "val_loss": 17.223472893238068, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.71387839317322, "training_acc": 52.0, "val_loss": 17.224512994289398, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.28319311141968, "training_acc": 51.0, "val_loss": 17.33613908290863, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.31941294670105, "training_acc": 53.0, "val_loss": 17.22114086151123, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.81728291511536, "training_acc": 52.0, "val_loss": 17.189982533454895, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.20215559005737, "training_acc": 52.0, "val_loss": 17.34117865562439, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.34547758102417, "training_acc": 48.0, "val_loss": 17.337332665920258, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.33611798286438, "training_acc": 47.0, "val_loss": 17.22930520772934, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.33478283882141, "training_acc": 52.0, "val_loss": 17.217649519443512, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.318852186203, "training_acc": 52.0, "val_loss": 17.27248728275299, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25735139846802, "training_acc": 52.0, "val_loss": 17.221370339393616, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23391819000244, "training_acc": 52.0, "val_loss": 17.174701392650604, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.36125183105469, "training_acc": 52.0, "val_loss": 17.164728045463562, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.32927370071411, "training_acc": 52.0, "val_loss": 17.236648499965668, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25050783157349, "training_acc": 52.0, "val_loss": 17.302189767360687, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.2786157131195, "training_acc": 52.0, "val_loss": 17.26999580860138, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.26181077957153, "training_acc": 52.0, "val_loss": 17.230473458766937, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22757148742676, "training_acc": 52.0, "val_loss": 17.178790271282196, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.58720421791077, "training_acc": 52.0, "val_loss": 17.162489891052246, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26330876350403, "training_acc": 52.0, "val_loss": 17.26287752389908, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.19233727455139, "training_acc": 52.0, "val_loss": 17.41458922624588, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.54580545425415, "training_acc": 48.0, "val_loss": 17.413531243801117, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.07109475135803, "training_acc": 38.0, "val_loss": 17.261508107185364, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24004411697388, "training_acc": 52.0, "val_loss": 17.27992743253708, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33237433433533, "training_acc": 52.0, "val_loss": 17.2690287232399, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.21488118171692, "training_acc": 52.0, "val_loss": 17.196574807167053, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.71163511276245, "training_acc": 52.0, "val_loss": 17.168864607810974, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.66634035110474, "training_acc": 52.0, "val_loss": 17.234455049037933, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24206066131592, "training_acc": 52.0, "val_loss": 17.22729206085205, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2554440498352, "training_acc": 52.0, "val_loss": 17.232558131217957, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.28123807907104, "training_acc": 52.0, "val_loss": 17.217986285686493, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23807144165039, "training_acc": 52.0, "val_loss": 17.240142822265625, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.26148581504822, "training_acc": 52.0, "val_loss": 17.245425283908844, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.37469792366028, "training_acc": 52.0, "val_loss": 17.218051850795746, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.20874953269958, "training_acc": 52.0, "val_loss": 17.163926362991333, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.61927652359009, "training_acc": 52.0, "val_loss": 17.148831486701965, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.50905656814575, "training_acc": 52.0, "val_loss": 17.16618686914444, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.31268048286438, "training_acc": 52.0, "val_loss": 17.233897745609283, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2046582698822, "training_acc": 52.0, "val_loss": 17.30891615152359, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.32438635826111, "training_acc": 52.0, "val_loss": 17.383286356925964, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.5033962726593, "training_acc": 48.0, "val_loss": 17.45828241109848, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.55072474479675, "training_acc": 48.0, "val_loss": 17.348533868789673, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.34126305580139, "training_acc": 48.0, "val_loss": 17.256760597229004, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.21628880500793, "training_acc": 52.0, "val_loss": 17.20479130744934, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.28302788734436, "training_acc": 52.0, "val_loss": 17.16873347759247, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.39995193481445, "training_acc": 52.0, "val_loss": 17.174774408340454, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2386200428009, "training_acc": 52.0, "val_loss": 17.239798605442047, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.21653842926025, "training_acc": 52.0, "val_loss": 17.340512573719025, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.32287955284119, "training_acc": 48.0, "val_loss": 17.379505932331085, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.38350510597229, "training_acc": 48.0, "val_loss": 17.355994880199432, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.3278980255127, "training_acc": 48.0, "val_loss": 17.285238206386566, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.42172336578369, "training_acc": 52.0, "val_loss": 17.205223441123962, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.28532886505127, "training_acc": 52.0, "val_loss": 17.197056114673615, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2727861404419, "training_acc": 52.0, "val_loss": 17.222614586353302, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23124384880066, "training_acc": 52.0, "val_loss": 17.234212160110474, "val_acc": 56.0}
