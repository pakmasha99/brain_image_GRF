"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.09481430053711, "training_acc": 47.0, "val_loss": 17.32247918844223, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.09315586090088, "training_acc": 52.0, "val_loss": 17.47214049100876, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.54515480995178, "training_acc": 53.0, "val_loss": 17.38726794719696, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51536107063293, "training_acc": 53.0, "val_loss": 17.405234277248383, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.13760042190552, "training_acc": 53.0, "val_loss": 17.346735298633575, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06954741477966, "training_acc": 53.0, "val_loss": 17.325636744499207, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.68494462966919, "training_acc": 45.0, "val_loss": 17.30954200029373, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.88411521911621, "training_acc": 53.0, "val_loss": 17.327331006526947, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19455480575562, "training_acc": 53.0, "val_loss": 17.312125861644745, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.40304660797119, "training_acc": 53.0, "val_loss": 17.317745089530945, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07784128189087, "training_acc": 53.0, "val_loss": 17.379766702651978, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.32276844978333, "training_acc": 53.0, "val_loss": 17.388656735420227, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.30684041976929, "training_acc": 53.0, "val_loss": 17.360074818134308, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1815242767334, "training_acc": 53.0, "val_loss": 17.314164340496063, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18843197822571, "training_acc": 53.0, "val_loss": 17.311082780361176, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15830683708191, "training_acc": 53.0, "val_loss": 17.31158047914505, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15613460540771, "training_acc": 53.0, "val_loss": 17.324189841747284, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22536754608154, "training_acc": 53.0, "val_loss": 17.352768778800964, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.24119162559509, "training_acc": 53.0, "val_loss": 17.400775849819183, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.44235181808472, "training_acc": 53.0, "val_loss": 17.356862127780914, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25520467758179, "training_acc": 53.0, "val_loss": 17.334899306297302, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22285485267639, "training_acc": 53.0, "val_loss": 17.310182750225067, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2879536151886, "training_acc": 50.0, "val_loss": 17.347754538059235, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.40815591812134, "training_acc": 47.0, "val_loss": 17.33180582523346, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.5527069568634, "training_acc": 47.0, "val_loss": 17.311091721057892, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1706326007843, "training_acc": 53.0, "val_loss": 17.366313934326172, "val_acc": 52.0}
