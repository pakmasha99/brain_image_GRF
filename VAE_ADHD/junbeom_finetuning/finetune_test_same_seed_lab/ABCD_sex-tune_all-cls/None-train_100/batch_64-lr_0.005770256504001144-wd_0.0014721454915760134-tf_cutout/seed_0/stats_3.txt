"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 431.3790054321289, "training_acc": 49.0, "val_loss": 26652531.25, "val_acc": 52.0}
{"epoch": 1, "training_loss": 73751826.21685791, "training_acc": 45.0, "val_loss": 6137.470626831055, "val_acc": 48.0}
{"epoch": 2, "training_loss": 20152.913208007812, "training_acc": 51.0, "val_loss": 10407.568359375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 29324.580001831055, "training_acc": 47.0, "val_loss": 317.86296367645264, "val_acc": 48.0}
{"epoch": 4, "training_loss": 982.3122520446777, "training_acc": 55.0, "val_loss": 94.29064989089966, "val_acc": 48.0}
{"epoch": 5, "training_loss": 944.5619583129883, "training_acc": 55.0, "val_loss": 92.45965480804443, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1894.9093627929688, "training_acc": 53.0, "val_loss": 208.5108995437622, "val_acc": 48.0}
{"epoch": 7, "training_loss": 785.9251461029053, "training_acc": 45.0, "val_loss": 66.6814923286438, "val_acc": 52.0}
{"epoch": 8, "training_loss": 365.7176265716553, "training_acc": 53.0, "val_loss": 47.37962186336517, "val_acc": 52.0}
{"epoch": 9, "training_loss": 159.2287311553955, "training_acc": 49.0, "val_loss": 123.16721677780151, "val_acc": 52.0}
{"epoch": 10, "training_loss": 346.573050737381, "training_acc": 49.0, "val_loss": 18.845859169960022, "val_acc": 52.0}
{"epoch": 11, "training_loss": 92.42192268371582, "training_acc": 45.0, "val_loss": 49.7990757226944, "val_acc": 52.0}
{"epoch": 12, "training_loss": 163.0837025642395, "training_acc": 53.0, "val_loss": 26.80904269218445, "val_acc": 48.0}
{"epoch": 13, "training_loss": 95.19664335250854, "training_acc": 49.0, "val_loss": 20.233307778835297, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.57798910140991, "training_acc": 55.0, "val_loss": 26.838770508766174, "val_acc": 48.0}
{"epoch": 15, "training_loss": 92.60610246658325, "training_acc": 47.0, "val_loss": 23.921503126621246, "val_acc": 52.0}
{"epoch": 16, "training_loss": 90.61697363853455, "training_acc": 53.0, "val_loss": 17.38072782754898, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.67745757102966, "training_acc": 55.0, "val_loss": 18.812930583953857, "val_acc": 48.0}
{"epoch": 18, "training_loss": 74.0058491230011, "training_acc": 45.0, "val_loss": 17.703430354595184, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.18261408805847, "training_acc": 53.0, "val_loss": 17.30836033821106, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.79843640327454, "training_acc": 47.0, "val_loss": 17.420968413352966, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.06538677215576, "training_acc": 55.0, "val_loss": 17.676571011543274, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.73892545700073, "training_acc": 53.0, "val_loss": 17.771190404891968, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.49007868766785, "training_acc": 53.0, "val_loss": 17.31179803609848, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.45936298370361, "training_acc": 49.0, "val_loss": 17.346228659152985, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.24670362472534, "training_acc": 51.0, "val_loss": 17.79695898294449, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.54743099212646, "training_acc": 53.0, "val_loss": 17.367023229599, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.57809829711914, "training_acc": 47.0, "val_loss": 17.313842475414276, "val_acc": 52.0}
{"epoch": 28, "training_loss": 73.018394947052, "training_acc": 39.0, "val_loss": 17.431360483169556, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14067196846008, "training_acc": 55.0, "val_loss": 17.7602156996727, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.32018804550171, "training_acc": 53.0, "val_loss": 17.408831417560577, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.81735944747925, "training_acc": 53.0, "val_loss": 17.32366681098938, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16993713378906, "training_acc": 53.0, "val_loss": 17.362771928310394, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21794199943542, "training_acc": 53.0, "val_loss": 17.41851717233658, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.47557020187378, "training_acc": 53.0, "val_loss": 17.383651435375214, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2976655960083, "training_acc": 53.0, "val_loss": 17.344358563423157, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.33416295051575, "training_acc": 53.0, "val_loss": 17.30874478816986, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14529466629028, "training_acc": 53.0, "val_loss": 17.31005311012268, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.3035397529602, "training_acc": 53.0, "val_loss": 17.309144139289856, "val_acc": 52.0}
