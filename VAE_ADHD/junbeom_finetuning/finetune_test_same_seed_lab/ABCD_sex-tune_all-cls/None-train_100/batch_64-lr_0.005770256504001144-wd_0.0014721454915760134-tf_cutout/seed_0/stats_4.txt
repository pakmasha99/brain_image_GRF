"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 358.70263290405273, "training_acc": 50.0, "val_loss": 25438.446044921875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1651487.140625, "training_acc": 53.0, "val_loss": 63.66918683052063, "val_acc": 48.0}
{"epoch": 2, "training_loss": 211.89533805847168, "training_acc": 39.0, "val_loss": 25.88041126728058, "val_acc": 52.0}
{"epoch": 3, "training_loss": 485.64682388305664, "training_acc": 45.0, "val_loss": 46.92867994308472, "val_acc": 52.0}
{"epoch": 4, "training_loss": 153.0080337524414, "training_acc": 53.0, "val_loss": 68.14974546432495, "val_acc": 48.0}
{"epoch": 5, "training_loss": 239.3906090259552, "training_acc": 37.0, "val_loss": 17.448773980140686, "val_acc": 52.0}
{"epoch": 6, "training_loss": 84.95571851730347, "training_acc": 53.0, "val_loss": 67.13966131210327, "val_acc": 48.0}
{"epoch": 7, "training_loss": 167.5765347480774, "training_acc": 47.0, "val_loss": 109.87412929534912, "val_acc": 52.0}
{"epoch": 8, "training_loss": 322.7319416999817, "training_acc": 53.0, "val_loss": 21.618574857711792, "val_acc": 48.0}
{"epoch": 9, "training_loss": 83.94141864776611, "training_acc": 47.0, "val_loss": 17.34161376953125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24909210205078, "training_acc": 53.0, "val_loss": 17.309871315956116, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15957760810852, "training_acc": 53.0, "val_loss": 18.233489990234375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 76.32771492004395, "training_acc": 49.0, "val_loss": 17.663298547267914, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.50017881393433, "training_acc": 53.0, "val_loss": 19.910842180252075, "val_acc": 52.0}
{"epoch": 14, "training_loss": 95.11946725845337, "training_acc": 49.0, "val_loss": 20.58151215314865, "val_acc": 52.0}
{"epoch": 15, "training_loss": 73.43563175201416, "training_acc": 53.0, "val_loss": 18.17927360534668, "val_acc": 52.0}
{"epoch": 16, "training_loss": 73.91499710083008, "training_acc": 51.0, "val_loss": 42.97471642494202, "val_acc": 48.0}
{"epoch": 17, "training_loss": 173.51838493347168, "training_acc": 47.0, "val_loss": 20.5230712890625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72.6629593372345, "training_acc": 57.0, "val_loss": 20.6244096159935, "val_acc": 48.0}
{"epoch": 19, "training_loss": 80.15560746192932, "training_acc": 49.0, "val_loss": 17.375163733959198, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.31067872047424, "training_acc": 47.0, "val_loss": 28.759613633155823, "val_acc": 52.0}
{"epoch": 21, "training_loss": 108.06659436225891, "training_acc": 45.0, "val_loss": 17.337539792060852, "val_acc": 52.0}
{"epoch": 22, "training_loss": 75.50762295722961, "training_acc": 58.0, "val_loss": 17.41584539413452, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.49944710731506, "training_acc": 47.0, "val_loss": 17.315973341464996, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.54169845581055, "training_acc": 53.0, "val_loss": 17.320431768894196, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.61963391304016, "training_acc": 49.0, "val_loss": 17.42391139268875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.39216637611389, "training_acc": 53.0, "val_loss": 17.358501255512238, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.15416741371155, "training_acc": 47.0, "val_loss": 17.5920307636261, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.72530364990234, "training_acc": 53.0, "val_loss": 17.314045131206512, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.22642970085144, "training_acc": 53.0, "val_loss": 17.452852427959442, "val_acc": 52.0}
