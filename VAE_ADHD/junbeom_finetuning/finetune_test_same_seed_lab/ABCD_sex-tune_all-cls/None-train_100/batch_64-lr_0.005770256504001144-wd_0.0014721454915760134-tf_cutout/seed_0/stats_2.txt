"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 238.6690273284912, "training_acc": 55.0, "val_loss": 858984.86328125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2493848.174682617, "training_acc": 41.0, "val_loss": 921.7373847961426, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2623.5515060424805, "training_acc": 55.0, "val_loss": 315.0052309036255, "val_acc": 52.0}
{"epoch": 3, "training_loss": 819.6535663604736, "training_acc": 53.0, "val_loss": 142.80645847320557, "val_acc": 48.0}
{"epoch": 4, "training_loss": 370.4860291481018, "training_acc": 47.0, "val_loss": 105.45517206192017, "val_acc": 52.0}
{"epoch": 5, "training_loss": 301.7081503868103, "training_acc": 53.0, "val_loss": 18.17624270915985, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.6714825630188, "training_acc": 53.0, "val_loss": 18.905675411224365, "val_acc": 48.0}
{"epoch": 7, "training_loss": 70.11041641235352, "training_acc": 57.0, "val_loss": 52.16569900512695, "val_acc": 52.0}
{"epoch": 8, "training_loss": 168.37626004219055, "training_acc": 45.0, "val_loss": 18.3810293674469, "val_acc": 48.0}
{"epoch": 9, "training_loss": 122.43368244171143, "training_acc": 41.0, "val_loss": 24.172231554985046, "val_acc": 48.0}
{"epoch": 10, "training_loss": 93.35222482681274, "training_acc": 47.0, "val_loss": 17.975999414920807, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.5734794139862, "training_acc": 51.0, "val_loss": 17.597395181655884, "val_acc": 52.0}
{"epoch": 12, "training_loss": 93.94845914840698, "training_acc": 37.0, "val_loss": 18.354736268520355, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.77876782417297, "training_acc": 53.0, "val_loss": 17.68932044506073, "val_acc": 52.0}
{"epoch": 14, "training_loss": 110.4160304069519, "training_acc": 45.0, "val_loss": 28.436917066574097, "val_acc": 52.0}
{"epoch": 15, "training_loss": 111.02396416664124, "training_acc": 53.0, "val_loss": 17.73652583360672, "val_acc": 52.0}
{"epoch": 16, "training_loss": 74.2505235671997, "training_acc": 43.0, "val_loss": 17.582429945468903, "val_acc": 52.0}
{"epoch": 17, "training_loss": 71.77537655830383, "training_acc": 53.0, "val_loss": 17.409637570381165, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.73690462112427, "training_acc": 47.0, "val_loss": 17.315788567066193, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1139907836914, "training_acc": 53.0, "val_loss": 17.62770414352417, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.79783749580383, "training_acc": 51.0, "val_loss": 17.37118512392044, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.3960530757904, "training_acc": 49.0, "val_loss": 17.46222674846649, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.37382102012634, "training_acc": 53.0, "val_loss": 17.33660399913788, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2936053276062, "training_acc": 51.0, "val_loss": 17.490339279174805, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.60196733474731, "training_acc": 53.0, "val_loss": 17.321772873401642, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.27349543571472, "training_acc": 53.0, "val_loss": 17.379239201545715, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.85972571372986, "training_acc": 45.0, "val_loss": 17.310866713523865, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13593745231628, "training_acc": 53.0, "val_loss": 17.31323152780533, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27644324302673, "training_acc": 53.0, "val_loss": 17.309169471263885, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.59474635124207, "training_acc": 47.0, "val_loss": 17.309199273586273, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.77240872383118, "training_acc": 53.0, "val_loss": 17.343276739120483, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.56543183326721, "training_acc": 52.0, "val_loss": 17.33781397342682, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.45812654495239, "training_acc": 47.0, "val_loss": 17.312373220920563, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.06009817123413, "training_acc": 53.0, "val_loss": 17.47998595237732, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.33180928230286, "training_acc": 53.0, "val_loss": 17.411956191062927, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.57183384895325, "training_acc": 53.0, "val_loss": 17.314401268959045, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.20558834075928, "training_acc": 53.0, "val_loss": 17.309369146823883, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.28245735168457, "training_acc": 53.0, "val_loss": 17.311473190784454, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.09519672393799, "training_acc": 53.0, "val_loss": 17.382602393627167, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.41034460067749, "training_acc": 53.0, "val_loss": 17.33039617538452, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.08604049682617, "training_acc": 53.0, "val_loss": 17.31649786233902, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.62236452102661, "training_acc": 45.0, "val_loss": 17.32165813446045, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.16708302497864, "training_acc": 53.0, "val_loss": 17.314249277114868, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.41872525215149, "training_acc": 53.0, "val_loss": 17.373469471931458, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.31126832962036, "training_acc": 53.0, "val_loss": 17.34917014837265, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.55254673957825, "training_acc": 53.0, "val_loss": 17.308680713176727, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.25952935218811, "training_acc": 53.0, "val_loss": 17.308393120765686, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13196635246277, "training_acc": 53.0, "val_loss": 17.326565086841583, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.2595226764679, "training_acc": 53.0, "val_loss": 17.344026267528534, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.18281412124634, "training_acc": 53.0, "val_loss": 17.324845492839813, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13908123970032, "training_acc": 53.0, "val_loss": 17.312146723270416, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14261651039124, "training_acc": 53.0, "val_loss": 17.309264838695526, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.19711756706238, "training_acc": 53.0, "val_loss": 17.31177121400833, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.32990312576294, "training_acc": 53.0, "val_loss": 17.30857938528061, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.11275029182434, "training_acc": 53.0, "val_loss": 17.33606606721878, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.26681518554688, "training_acc": 53.0, "val_loss": 17.381995916366577, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.3498649597168, "training_acc": 53.0, "val_loss": 17.361459136009216, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.21428799629211, "training_acc": 53.0, "val_loss": 17.322078347206116, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.1743540763855, "training_acc": 53.0, "val_loss": 17.30928122997284, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.37509989738464, "training_acc": 53.0, "val_loss": 17.30874925851822, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.21109366416931, "training_acc": 53.0, "val_loss": 17.310836911201477, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.1251175403595, "training_acc": 53.0, "val_loss": 17.31431931257248, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.16160941123962, "training_acc": 53.0, "val_loss": 17.316290736198425, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.16156125068665, "training_acc": 53.0, "val_loss": 17.314869165420532, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.18853402137756, "training_acc": 53.0, "val_loss": 17.309844493865967, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.18173241615295, "training_acc": 53.0, "val_loss": 17.31005758047104, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.1383695602417, "training_acc": 53.0, "val_loss": 17.308339476585388, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.23950052261353, "training_acc": 53.0, "val_loss": 17.308230698108673, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.13849115371704, "training_acc": 53.0, "val_loss": 17.310819029808044, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.10847973823547, "training_acc": 53.0, "val_loss": 17.32228249311447, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.12503433227539, "training_acc": 53.0, "val_loss": 17.346008121967316, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.18812608718872, "training_acc": 53.0, "val_loss": 17.36779361963272, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.28647089004517, "training_acc": 53.0, "val_loss": 17.359912395477295, "val_acc": 52.0}
{"epoch": 73, "training_loss": 69.30825519561768, "training_acc": 53.0, "val_loss": 17.356006801128387, "val_acc": 52.0}
{"epoch": 74, "training_loss": 69.17261171340942, "training_acc": 53.0, "val_loss": 17.331463098526, "val_acc": 52.0}
{"epoch": 75, "training_loss": 69.12560606002808, "training_acc": 53.0, "val_loss": 17.313651740550995, "val_acc": 52.0}
{"epoch": 76, "training_loss": 69.09238409996033, "training_acc": 53.0, "val_loss": 17.308250069618225, "val_acc": 52.0}
{"epoch": 77, "training_loss": 69.1139874458313, "training_acc": 53.0, "val_loss": 17.310649156570435, "val_acc": 52.0}
{"epoch": 78, "training_loss": 69.20566296577454, "training_acc": 53.0, "val_loss": 17.31857657432556, "val_acc": 52.0}
{"epoch": 79, "training_loss": 69.26147818565369, "training_acc": 53.0, "val_loss": 17.321261763572693, "val_acc": 52.0}
{"epoch": 80, "training_loss": 69.29473209381104, "training_acc": 53.0, "val_loss": 17.317958176136017, "val_acc": 52.0}
{"epoch": 81, "training_loss": 69.25309491157532, "training_acc": 53.0, "val_loss": 17.309409379959106, "val_acc": 52.0}
{"epoch": 82, "training_loss": 69.19294333457947, "training_acc": 53.0, "val_loss": 17.3115536570549, "val_acc": 52.0}
{"epoch": 83, "training_loss": 69.1247787475586, "training_acc": 53.0, "val_loss": 17.321068048477173, "val_acc": 52.0}
{"epoch": 84, "training_loss": 69.20389914512634, "training_acc": 53.0, "val_loss": 17.32625663280487, "val_acc": 52.0}
{"epoch": 85, "training_loss": 69.15188574790955, "training_acc": 53.0, "val_loss": 17.31710135936737, "val_acc": 52.0}
{"epoch": 86, "training_loss": 69.20910978317261, "training_acc": 53.0, "val_loss": 17.314203083515167, "val_acc": 52.0}
