"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 313.02657318115234, "training_acc": 50.0, "val_loss": 3279410.9375, "val_acc": 56.0}
{"epoch": 1, "training_loss": 8922006.525878906, "training_acc": 52.0, "val_loss": 19397.555541992188, "val_acc": 44.0}
{"epoch": 2, "training_loss": 49904.53742980957, "training_acc": 48.0, "val_loss": 44.59666311740875, "val_acc": 56.0}
{"epoch": 3, "training_loss": 516.1053733825684, "training_acc": 54.0, "val_loss": 313.5195255279541, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1236.628288269043, "training_acc": 52.0, "val_loss": 32.97340273857117, "val_acc": 56.0}
{"epoch": 5, "training_loss": 163.794415473938, "training_acc": 56.0, "val_loss": 37.52636909484863, "val_acc": 44.0}
{"epoch": 6, "training_loss": 112.75458192825317, "training_acc": 50.0, "val_loss": 22.73673564195633, "val_acc": 56.0}
{"epoch": 7, "training_loss": 93.56168746948242, "training_acc": 48.0, "val_loss": 18.352113664150238, "val_acc": 56.0}
{"epoch": 8, "training_loss": 76.44916605949402, "training_acc": 42.0, "val_loss": 19.539916515350342, "val_acc": 44.0}
{"epoch": 9, "training_loss": 73.94496583938599, "training_acc": 48.0, "val_loss": 17.17115044593811, "val_acc": 56.0}
{"epoch": 10, "training_loss": 71.38111925125122, "training_acc": 50.0, "val_loss": 17.43609756231308, "val_acc": 56.0}
{"epoch": 11, "training_loss": 70.53771185874939, "training_acc": 48.0, "val_loss": 17.695270478725433, "val_acc": 56.0}
{"epoch": 12, "training_loss": 75.54738736152649, "training_acc": 46.0, "val_loss": 26.85912251472473, "val_acc": 44.0}
{"epoch": 13, "training_loss": 87.6264374256134, "training_acc": 48.0, "val_loss": 17.684592306613922, "val_acc": 56.0}
{"epoch": 14, "training_loss": 72.4377601146698, "training_acc": 52.0, "val_loss": 17.35752671957016, "val_acc": 56.0}
{"epoch": 15, "training_loss": 74.0412266254425, "training_acc": 48.0, "val_loss": 18.48710924386978, "val_acc": 56.0}
{"epoch": 16, "training_loss": 75.14753746986389, "training_acc": 52.0, "val_loss": 18.073955178260803, "val_acc": 56.0}
{"epoch": 17, "training_loss": 71.12655997276306, "training_acc": 48.0, "val_loss": 17.308352887630463, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.31693506240845, "training_acc": 48.0, "val_loss": 17.137731611728668, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.30325698852539, "training_acc": 52.0, "val_loss": 18.21010559797287, "val_acc": 56.0}
{"epoch": 20, "training_loss": 70.07397866249084, "training_acc": 52.0, "val_loss": 17.48792678117752, "val_acc": 56.0}
{"epoch": 21, "training_loss": 72.07390069961548, "training_acc": 52.0, "val_loss": 17.191481590270996, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.31653189659119, "training_acc": 52.0, "val_loss": 17.653119564056396, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.96183395385742, "training_acc": 48.0, "val_loss": 17.48615801334381, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.66503238677979, "training_acc": 46.0, "val_loss": 17.28070080280304, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.33564972877502, "training_acc": 48.0, "val_loss": 17.19432920217514, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.62474584579468, "training_acc": 52.0, "val_loss": 17.165423929691315, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.21758222579956, "training_acc": 52.0, "val_loss": 17.494742572307587, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.98928475379944, "training_acc": 48.0, "val_loss": 17.49340444803238, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.41058707237244, "training_acc": 51.0, "val_loss": 17.19619333744049, "val_acc": 56.0}
{"epoch": 30, "training_loss": 70.04000616073608, "training_acc": 52.0, "val_loss": 17.143771052360535, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.79570841789246, "training_acc": 52.0, "val_loss": 17.19171851873398, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.26675462722778, "training_acc": 52.0, "val_loss": 17.22044199705124, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24809908866882, "training_acc": 52.0, "val_loss": 17.258937656879425, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.28567862510681, "training_acc": 52.0, "val_loss": 17.24148541688919, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.25797033309937, "training_acc": 52.0, "val_loss": 17.247451841831207, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25048089027405, "training_acc": 52.0, "val_loss": 17.23504364490509, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.287034034729, "training_acc": 52.0, "val_loss": 17.206397652626038, "val_acc": 56.0}
