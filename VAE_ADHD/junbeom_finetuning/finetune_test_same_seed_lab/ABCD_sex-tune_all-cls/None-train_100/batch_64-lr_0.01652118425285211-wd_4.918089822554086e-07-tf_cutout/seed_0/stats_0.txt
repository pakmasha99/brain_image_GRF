"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1042.3882293701172, "training_acc": 50.0, "val_loss": 4.78188673171456e+16, "val_acc": 56.0}
{"epoch": 1, "training_loss": 1.2705197880517461e+17, "training_acc": 52.0, "val_loss": 279857025.0, "val_acc": 56.0}
{"epoch": 2, "training_loss": 20215633920.0, "training_acc": 54.0, "val_loss": 9901131200.0, "val_acc": 44.0}
{"epoch": 3, "training_loss": 24569572195.25, "training_acc": 48.0, "val_loss": 6612228.90625, "val_acc": 56.0}
{"epoch": 4, "training_loss": 67384094.0, "training_acc": 50.0, "val_loss": 190166587.5, "val_acc": 56.0}
{"epoch": 5, "training_loss": 502110846.5, "training_acc": 56.0, "val_loss": 250875.5615234375, "val_acc": 56.0}
{"epoch": 6, "training_loss": 101036933.1875, "training_acc": 50.0, "val_loss": 18222015.625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 75452684.0, "training_acc": 48.0, "val_loss": 52777143.75, "val_acc": 56.0}
{"epoch": 8, "training_loss": 141231120.375, "training_acc": 52.0, "val_loss": 50694134.375, "val_acc": 44.0}
{"epoch": 9, "training_loss": 141367307.5, "training_acc": 48.0, "val_loss": 81951431.25, "val_acc": 44.0}
{"epoch": 10, "training_loss": 266552252.0, "training_acc": 50.0, "val_loss": 10411821.09375, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1310214210.0, "training_acc": 52.0, "val_loss": 50687471.875, "val_acc": 56.0}
{"epoch": 12, "training_loss": 156981007.5, "training_acc": 52.0, "val_loss": 33155940.625, "val_acc": 56.0}
{"epoch": 13, "training_loss": 107139836.0, "training_acc": 52.0, "val_loss": 2618282.421875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 11393915.4375, "training_acc": 48.0, "val_loss": 6688583.59375, "val_acc": 56.0}
{"epoch": 15, "training_loss": 24708180.0, "training_acc": 46.0, "val_loss": 2893494.140625, "val_acc": 56.0}
{"epoch": 16, "training_loss": 15098324.5625, "training_acc": 52.0, "val_loss": 417502400.0, "val_acc": 44.0}
{"epoch": 17, "training_loss": 987695342.25, "training_acc": 50.0, "val_loss": 165587487.5, "val_acc": 56.0}
{"epoch": 18, "training_loss": 520957168.5, "training_acc": 52.0, "val_loss": 20148359.375, "val_acc": 56.0}
{"epoch": 19, "training_loss": 193775377.0, "training_acc": 52.0, "val_loss": 14694751.5625, "val_acc": 44.0}
{"epoch": 20, "training_loss": 34360220.328125, "training_acc": 52.0, "val_loss": 186333.056640625, "val_acc": 56.0}
{"epoch": 21, "training_loss": 207784698.375, "training_acc": 46.0, "val_loss": 5465951.5625, "val_acc": 56.0}
{"epoch": 22, "training_loss": 46807804.5, "training_acc": 52.0, "val_loss": 18002615.625, "val_acc": 56.0}
{"epoch": 23, "training_loss": 57238891.625, "training_acc": 52.0, "val_loss": 1840257.6171875, "val_acc": 56.0}
{"epoch": 24, "training_loss": 6780448.484375, "training_acc": 54.0, "val_loss": 1143018.75, "val_acc": 44.0}
{"epoch": 25, "training_loss": 60907302.5, "training_acc": 52.0, "val_loss": 73009.80834960938, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1810316.8125, "training_acc": 48.0, "val_loss": 4779812.890625, "val_acc": 56.0}
{"epoch": 27, "training_loss": 14508904.5, "training_acc": 52.0, "val_loss": 4347192.96875, "val_acc": 56.0}
{"epoch": 28, "training_loss": 13435257.3984375, "training_acc": 52.0, "val_loss": 619940.185546875, "val_acc": 44.0}
{"epoch": 29, "training_loss": 2784642.453125, "training_acc": 48.0, "val_loss": 293037.4267578125, "val_acc": 44.0}
{"epoch": 30, "training_loss": 2618340.46875, "training_acc": 40.0, "val_loss": 916579.00390625, "val_acc": 56.0}
{"epoch": 31, "training_loss": 3071567.720703125, "training_acc": 52.0, "val_loss": 1086343.45703125, "val_acc": 44.0}
{"epoch": 32, "training_loss": 3825302.453125, "training_acc": 48.0, "val_loss": 2372110.9375, "val_acc": 44.0}
{"epoch": 33, "training_loss": 6493864.4765625, "training_acc": 52.0, "val_loss": 975850.5859375, "val_acc": 56.0}
{"epoch": 34, "training_loss": 3607290.5390625, "training_acc": 52.0, "val_loss": 9182741.40625, "val_acc": 44.0}
{"epoch": 35, "training_loss": 21728637.5625, "training_acc": 50.0, "val_loss": 9814.908599853516, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1140696.4296875, "training_acc": 44.0, "val_loss": 1200537.890625, "val_acc": 56.0}
{"epoch": 37, "training_loss": 4083356.435546875, "training_acc": 52.0, "val_loss": 3602295.703125, "val_acc": 44.0}
{"epoch": 38, "training_loss": 8802878.0, "training_acc": 48.0, "val_loss": 752240.966796875, "val_acc": 56.0}
{"epoch": 39, "training_loss": 2590110.2265625, "training_acc": 52.0, "val_loss": 182172.96142578125, "val_acc": 44.0}
{"epoch": 40, "training_loss": 3652620.71875, "training_acc": 50.0, "val_loss": 48820915.625, "val_acc": 56.0}
{"epoch": 41, "training_loss": 159718072.25, "training_acc": 50.0, "val_loss": 595639.74609375, "val_acc": 56.0}
{"epoch": 42, "training_loss": 4936907.46875, "training_acc": 52.0, "val_loss": 3629382.421875, "val_acc": 56.0}
{"epoch": 43, "training_loss": 11833547.125, "training_acc": 52.0, "val_loss": 78490.43579101562, "val_acc": 52.0}
{"epoch": 44, "training_loss": 38359595.375, "training_acc": 46.0, "val_loss": 2746047.8515625, "val_acc": 44.0}
{"epoch": 45, "training_loss": 7518309.3515625, "training_acc": 48.0, "val_loss": 1063463.37890625, "val_acc": 56.0}
{"epoch": 46, "training_loss": 4337809.625, "training_acc": 52.0, "val_loss": 1287232.2265625, "val_acc": 44.0}
{"epoch": 47, "training_loss": 14586040.0, "training_acc": 54.0, "val_loss": 81637.40234375, "val_acc": 44.0}
{"epoch": 48, "training_loss": 1400711.0625, "training_acc": 52.0, "val_loss": 557362.353515625, "val_acc": 56.0}
{"epoch": 49, "training_loss": 1673600.904296875, "training_acc": 56.0, "val_loss": 102942.76123046875, "val_acc": 56.0}
{"epoch": 50, "training_loss": 732571.6953125, "training_acc": 54.0, "val_loss": 9842.16079711914, "val_acc": 48.0}
{"epoch": 51, "training_loss": 183422.6845703125, "training_acc": 52.0, "val_loss": 305374.2431640625, "val_acc": 44.0}
{"epoch": 52, "training_loss": 915322.685546875, "training_acc": 48.0, "val_loss": 311405.419921875, "val_acc": 56.0}
{"epoch": 53, "training_loss": 1286705.4765625, "training_acc": 52.0, "val_loss": 142474.2919921875, "val_acc": 44.0}
{"epoch": 54, "training_loss": 397720.603515625, "training_acc": 51.0, "val_loss": 1266089.94140625, "val_acc": 44.0}
{"epoch": 55, "training_loss": 3671808.5, "training_acc": 44.0, "val_loss": 5051.587677001953, "val_acc": 52.0}
{"epoch": 56, "training_loss": 140873.091796875, "training_acc": 47.0, "val_loss": 116668.212890625, "val_acc": 56.0}
{"epoch": 57, "training_loss": 442800.5126953125, "training_acc": 52.0, "val_loss": 211810.1318359375, "val_acc": 44.0}
{"epoch": 58, "training_loss": 695801.876953125, "training_acc": 48.0, "val_loss": 44735.296630859375, "val_acc": 56.0}
{"epoch": 59, "training_loss": 160277.72607421875, "training_acc": 52.0, "val_loss": 119406.0546875, "val_acc": 44.0}
{"epoch": 60, "training_loss": 373770.6484375, "training_acc": 48.0, "val_loss": 40902.2216796875, "val_acc": 56.0}
{"epoch": 61, "training_loss": 178144.57568359375, "training_acc": 52.0, "val_loss": 55063.5986328125, "val_acc": 44.0}
{"epoch": 62, "training_loss": 147767.07690429688, "training_acc": 50.0, "val_loss": 53171.722412109375, "val_acc": 56.0}
{"epoch": 63, "training_loss": 224590.27587890625, "training_acc": 52.0, "val_loss": 9198.615264892578, "val_acc": 44.0}
{"epoch": 64, "training_loss": 56299.889404296875, "training_acc": 46.0, "val_loss": 25975.167846679688, "val_acc": 56.0}
{"epoch": 65, "training_loss": 99795.14733886719, "training_acc": 50.0, "val_loss": 48969.71740722656, "val_acc": 44.0}
{"epoch": 66, "training_loss": 132813.63989257812, "training_acc": 48.0, "val_loss": 33523.77014160156, "val_acc": 56.0}
{"epoch": 67, "training_loss": 182884.3408203125, "training_acc": 52.0, "val_loss": 11357.972717285156, "val_acc": 56.0}
{"epoch": 68, "training_loss": 96599.63671875, "training_acc": 57.0, "val_loss": 77813.53149414062, "val_acc": 44.0}
{"epoch": 69, "training_loss": 225276.60986328125, "training_acc": 48.0, "val_loss": 66192.529296875, "val_acc": 56.0}
{"epoch": 70, "training_loss": 298255.0830078125, "training_acc": 52.0, "val_loss": 30479.342651367188, "val_acc": 56.0}
{"epoch": 71, "training_loss": 94566.59790039062, "training_acc": 64.0, "val_loss": 64065.960693359375, "val_acc": 44.0}
{"epoch": 72, "training_loss": 205943.27197265625, "training_acc": 48.0, "val_loss": 25437.586975097656, "val_acc": 56.0}
{"epoch": 73, "training_loss": 131535.03076171875, "training_acc": 52.0, "val_loss": 14596.113586425781, "val_acc": 56.0}
{"epoch": 74, "training_loss": 81469.724609375, "training_acc": 55.0, "val_loss": 57373.040771484375, "val_acc": 44.0}
