"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1570.366844177246, "training_acc": 39.0, "val_loss": 5.058903664893184e+22, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1.4132591967544097e+23, "training_acc": 53.0, "val_loss": 1763733800.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5073781764.0, "training_acc": 47.0, "val_loss": 466050100.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1263375374.65625, "training_acc": 45.0, "val_loss": 2192456.4453125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 352076981.0, "training_acc": 45.0, "val_loss": 135546050.0, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2213318752.0, "training_acc": 47.0, "val_loss": 511670200.0, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1309476428.3125, "training_acc": 49.0, "val_loss": 157580187.5, "val_acc": 52.0}
{"epoch": 7, "training_loss": 375474229.75, "training_acc": 53.0, "val_loss": 16570643.75, "val_acc": 48.0}
{"epoch": 8, "training_loss": 58419102.0, "training_acc": 47.0, "val_loss": 5666289.84375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 85787312.0, "training_acc": 51.0, "val_loss": 4130926.5625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 48344990484.0, "training_acc": 52.0, "val_loss": 15059917.1875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 523798036.0, "training_acc": 47.0, "val_loss": 162235362.5, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1625180424.0, "training_acc": 47.0, "val_loss": 69237550.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 6856626064.0, "training_acc": 53.0, "val_loss": 2487744800.0, "val_acc": 48.0}
{"epoch": 14, "training_loss": 9531016608.0, "training_acc": 47.0, "val_loss": 517174900.0, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1187149224.625, "training_acc": 59.0, "val_loss": 30058334.375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 522204208.0, "training_acc": 53.0, "val_loss": 946690800.0, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2666386578.0, "training_acc": 47.0, "val_loss": 3734728000.0, "val_acc": 48.0}
{"epoch": 18, "training_loss": 9521785647.9375, "training_acc": 49.0, "val_loss": 16330095.3125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 57182802.25, "training_acc": 53.0, "val_loss": 2258291.40625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 17537860.25, "training_acc": 49.0, "val_loss": 18800393.75, "val_acc": 52.0}
{"epoch": 21, "training_loss": 48599001.42578125, "training_acc": 53.0, "val_loss": 725468.1640625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 5652475.09375, "training_acc": 47.0, "val_loss": 6164820.703125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 17159459.78125, "training_acc": 49.0, "val_loss": 382716.2841796875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 6354708.3125, "training_acc": 53.0, "val_loss": 687881.73828125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2219918.2734375, "training_acc": 53.0, "val_loss": 745795.1171875, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3351076.5, "training_acc": 47.0, "val_loss": 780335.15625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 58613393.75, "training_acc": 53.0, "val_loss": 627933.349609375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1740367.5009765625, "training_acc": 49.0, "val_loss": 1221004.19921875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 4491201.796875, "training_acc": 47.0, "val_loss": 1191683.0078125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 5678152.6875, "training_acc": 47.0, "val_loss": 1580582.8125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 4230009.87890625, "training_acc": 55.0, "val_loss": 6554900.0, "val_acc": 52.0}
{"epoch": 32, "training_loss": 20045138.5625, "training_acc": 41.0, "val_loss": 858559.27734375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2394842.681640625, "training_acc": 47.0, "val_loss": 1119089.0625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 4151489.265625, "training_acc": 53.0, "val_loss": 207629.150390625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 2198540.125, "training_acc": 45.0, "val_loss": 962781.640625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 3142926.76953125, "training_acc": 47.0, "val_loss": 412301.46484375, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1773719.890625, "training_acc": 53.0, "val_loss": 258624.31640625, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1077574.15234375, "training_acc": 41.0, "val_loss": 142293.26171875, "val_acc": 48.0}
{"epoch": 39, "training_loss": 386743.0695800781, "training_acc": 49.0, "val_loss": 87119.95239257812, "val_acc": 52.0}
{"epoch": 40, "training_loss": 236331.34130859375, "training_acc": 50.0, "val_loss": 126540.22216796875, "val_acc": 48.0}
{"epoch": 41, "training_loss": 446706.0166015625, "training_acc": 47.0, "val_loss": 127487.85400390625, "val_acc": 52.0}
{"epoch": 42, "training_loss": 501830.505859375, "training_acc": 53.0, "val_loss": 72155.18798828125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 264907.19921875, "training_acc": 51.0, "val_loss": 90102.67944335938, "val_acc": 48.0}
{"epoch": 44, "training_loss": 329079.86328125, "training_acc": 47.0, "val_loss": 23932.667541503906, "val_acc": 52.0}
{"epoch": 45, "training_loss": 110621.76953125, "training_acc": 51.0, "val_loss": 21582.366943359375, "val_acc": 52.0}
{"epoch": 46, "training_loss": 90244.70581054688, "training_acc": 52.0, "val_loss": 28759.530639648438, "val_acc": 48.0}
{"epoch": 47, "training_loss": 97952.22729492188, "training_acc": 46.0, "val_loss": 26164.346313476562, "val_acc": 52.0}
{"epoch": 48, "training_loss": 116252.73388671875, "training_acc": 54.0, "val_loss": 18730.4443359375, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68524.04760742188, "training_acc": 57.0, "val_loss": 25668.22509765625, "val_acc": 48.0}
{"epoch": 50, "training_loss": 84444.6650390625, "training_acc": 46.0, "val_loss": 23432.325744628906, "val_acc": 52.0}
{"epoch": 51, "training_loss": 87396.13598632812, "training_acc": 53.0, "val_loss": 17420.236206054688, "val_acc": 52.0}
{"epoch": 52, "training_loss": 51425.73278808594, "training_acc": 50.0, "val_loss": 10298.536682128906, "val_acc": 48.0}
{"epoch": 53, "training_loss": 36712.52166748047, "training_acc": 46.0, "val_loss": 4461.540985107422, "val_acc": 52.0}
{"epoch": 54, "training_loss": 17105.130920410156, "training_acc": 53.0, "val_loss": 4491.64924621582, "val_acc": 48.0}
{"epoch": 55, "training_loss": 29113.129150390625, "training_acc": 43.0, "val_loss": 3758.1863403320312, "val_acc": 52.0}
{"epoch": 56, "training_loss": 23511.58642578125, "training_acc": 42.0, "val_loss": 2766.957473754883, "val_acc": 52.0}
{"epoch": 57, "training_loss": 13299.651611328125, "training_acc": 61.0, "val_loss": 1939.161491394043, "val_acc": 52.0}
{"epoch": 58, "training_loss": 24824.715087890625, "training_acc": 51.0, "val_loss": 619.4727420806885, "val_acc": 56.0}
{"epoch": 59, "training_loss": 19194.187133789062, "training_acc": 60.0, "val_loss": 10522.095489501953, "val_acc": 52.0}
{"epoch": 60, "training_loss": 30555.240112304688, "training_acc": 51.0, "val_loss": 8859.639739990234, "val_acc": 48.0}
{"epoch": 61, "training_loss": 31363.017578125, "training_acc": 47.0, "val_loss": 11329.147338867188, "val_acc": 52.0}
{"epoch": 62, "training_loss": 43286.318359375, "training_acc": 53.0, "val_loss": 2738.944435119629, "val_acc": 52.0}
{"epoch": 63, "training_loss": 23014.678955078125, "training_acc": 51.0, "val_loss": 13600.965881347656, "val_acc": 48.0}
{"epoch": 64, "training_loss": 40945.41815185547, "training_acc": 47.0, "val_loss": 16203.317260742188, "val_acc": 52.0}
{"epoch": 65, "training_loss": 74348.8017578125, "training_acc": 53.0, "val_loss": 19539.288330078125, "val_acc": 52.0}
{"epoch": 66, "training_loss": 53070.17333984375, "training_acc": 53.0, "val_loss": 16237.705993652344, "val_acc": 48.0}
{"epoch": 67, "training_loss": 81508.8046875, "training_acc": 47.0, "val_loss": 22027.25372314453, "val_acc": 48.0}
{"epoch": 68, "training_loss": 71976.69897460938, "training_acc": 47.0, "val_loss": 11614.167785644531, "val_acc": 52.0}
{"epoch": 69, "training_loss": 57063.6005859375, "training_acc": 53.0, "val_loss": 21693.56231689453, "val_acc": 52.0}
{"epoch": 70, "training_loss": 72147.62097167969, "training_acc": 53.0, "val_loss": 3011.4023208618164, "val_acc": 48.0}
{"epoch": 71, "training_loss": 22304.212036132812, "training_acc": 48.0, "val_loss": 2277.9680252075195, "val_acc": 48.0}
{"epoch": 72, "training_loss": 20047.624755859375, "training_acc": 50.0, "val_loss": 10259.488677978516, "val_acc": 52.0}
{"epoch": 73, "training_loss": 28933.084533691406, "training_acc": 53.0, "val_loss": 8456.328582763672, "val_acc": 48.0}
{"epoch": 74, "training_loss": 39712.212158203125, "training_acc": 47.0, "val_loss": 3004.1505813598633, "val_acc": 48.0}
{"epoch": 75, "training_loss": 23254.76171875, "training_acc": 49.0, "val_loss": 14831.451416015625, "val_acc": 52.0}
{"epoch": 76, "training_loss": 50530.690673828125, "training_acc": 53.0, "val_loss": 1721.1843490600586, "val_acc": 48.0}
{"epoch": 77, "training_loss": 13177.405151367188, "training_acc": 45.0, "val_loss": 4343.1732177734375, "val_acc": 52.0}
