"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.10045862197876, "training_acc": 47.0, "val_loss": 19.507890939712524, "val_acc": 48.0}
{"epoch": 1, "training_loss": 78.23549270629883, "training_acc": 47.0, "val_loss": 19.056524336338043, "val_acc": 48.0}
{"epoch": 2, "training_loss": 76.18634796142578, "training_acc": 47.0, "val_loss": 18.576328456401825, "val_acc": 48.0}
{"epoch": 3, "training_loss": 74.22065687179565, "training_acc": 47.0, "val_loss": 18.156440556049347, "val_acc": 52.0}
{"epoch": 4, "training_loss": 72.47529458999634, "training_acc": 47.0, "val_loss": 17.822013795375824, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.369708776474, "training_acc": 47.0, "val_loss": 17.57652759552002, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.26577877998352, "training_acc": 47.0, "val_loss": 17.418278753757477, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.77174496650696, "training_acc": 47.0, "val_loss": 17.332984507083893, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.34500980377197, "training_acc": 48.0, "val_loss": 17.30572134256363, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.07665228843689, "training_acc": 53.0, "val_loss": 17.314669489860535, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16559171676636, "training_acc": 53.0, "val_loss": 17.345061898231506, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27439665794373, "training_acc": 53.0, "val_loss": 17.38303303718567, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.3082811832428, "training_acc": 53.0, "val_loss": 17.40850806236267, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.53775119781494, "training_acc": 53.0, "val_loss": 17.428958415985107, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.42507147789001, "training_acc": 53.0, "val_loss": 17.425537109375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.43966007232666, "training_acc": 53.0, "val_loss": 17.413288354873657, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.40983581542969, "training_acc": 53.0, "val_loss": 17.390212416648865, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.37106037139893, "training_acc": 53.0, "val_loss": 17.364199459552765, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.28783416748047, "training_acc": 53.0, "val_loss": 17.34669953584671, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1570999622345, "training_acc": 53.0, "val_loss": 17.3344686627388, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2401225566864, "training_acc": 53.0, "val_loss": 17.32059121131897, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11209440231323, "training_acc": 53.0, "val_loss": 17.313800752162933, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13946413993835, "training_acc": 53.0, "val_loss": 17.30913668870926, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20193982124329, "training_acc": 53.0, "val_loss": 17.306555807590485, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17038178443909, "training_acc": 53.0, "val_loss": 17.30605661869049, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.10707187652588, "training_acc": 53.0, "val_loss": 17.305900156497955, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15575408935547, "training_acc": 53.0, "val_loss": 17.306534945964813, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1007559299469, "training_acc": 53.0, "val_loss": 17.306528985500336, "val_acc": 52.0}
