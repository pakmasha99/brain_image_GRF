"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.88626527786255, "training_acc": 53.0, "val_loss": 17.310898005962372, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55882573127747, "training_acc": 53.0, "val_loss": 18.126246333122253, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.5787422657013, "training_acc": 47.0, "val_loss": 17.33636111021042, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.30023169517517, "training_acc": 53.0, "val_loss": 17.5642728805542, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.69611096382141, "training_acc": 53.0, "val_loss": 17.303583025932312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0401611328125, "training_acc": 53.0, "val_loss": 17.357237637043, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.25969457626343, "training_acc": 47.0, "val_loss": 17.343781888484955, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07656192779541, "training_acc": 53.0, "val_loss": 17.361529171466827, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.23632860183716, "training_acc": 53.0, "val_loss": 17.478415369987488, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.67899632453918, "training_acc": 53.0, "val_loss": 17.48621016740799, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.73703503608704, "training_acc": 53.0, "val_loss": 17.379865050315857, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29145550727844, "training_acc": 53.0, "val_loss": 17.31773018836975, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17111897468567, "training_acc": 53.0, "val_loss": 17.30966866016388, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18160271644592, "training_acc": 53.0, "val_loss": 17.324085533618927, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.35699033737183, "training_acc": 47.0, "val_loss": 17.338599264621735, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.32315826416016, "training_acc": 47.0, "val_loss": 17.31496751308441, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21830606460571, "training_acc": 53.0, "val_loss": 17.30446219444275, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13591504096985, "training_acc": 53.0, "val_loss": 17.322543263435364, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2891354560852, "training_acc": 53.0, "val_loss": 17.332616448402405, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.36716914176941, "training_acc": 53.0, "val_loss": 17.370571196079254, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.32767915725708, "training_acc": 53.0, "val_loss": 17.351697385311127, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1486656665802, "training_acc": 53.0, "val_loss": 17.31608957052231, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22488713264465, "training_acc": 53.0, "val_loss": 17.306362092494965, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12603044509888, "training_acc": 53.0, "val_loss": 17.306575179100037, "val_acc": 52.0}
