"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.19471096992493, "training_acc": 51.0, "val_loss": 17.451465129852295, "val_acc": 52.0}
{"epoch": 1, "training_loss": 80.05465054512024, "training_acc": 45.0, "val_loss": 17.425505816936493, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.97459888458252, "training_acc": 51.0, "val_loss": 17.89199411869049, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.37607836723328, "training_acc": 47.0, "val_loss": 17.42461770772934, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25231432914734, "training_acc": 55.0, "val_loss": 17.32562482357025, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.38269758224487, "training_acc": 53.0, "val_loss": 17.44777262210846, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.50317478179932, "training_acc": 53.0, "val_loss": 17.361819744110107, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18488550186157, "training_acc": 53.0, "val_loss": 17.304521799087524, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15485715866089, "training_acc": 53.0, "val_loss": 17.327365279197693, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.47459650039673, "training_acc": 46.0, "val_loss": 17.335166037082672, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.25463223457336, "training_acc": 51.0, "val_loss": 17.308391630649567, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24560070037842, "training_acc": 53.0, "val_loss": 17.32463389635086, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1693000793457, "training_acc": 53.0, "val_loss": 17.333367466926575, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.35852074623108, "training_acc": 53.0, "val_loss": 17.350788414478302, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21710515022278, "training_acc": 53.0, "val_loss": 17.327556014060974, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14493179321289, "training_acc": 53.0, "val_loss": 17.313507199287415, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.0865843296051, "training_acc": 53.0, "val_loss": 17.30409413576126, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2900505065918, "training_acc": 53.0, "val_loss": 17.306819558143616, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17972445487976, "training_acc": 53.0, "val_loss": 17.306825518608093, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.28920865058899, "training_acc": 53.0, "val_loss": 17.30532795190811, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18898415565491, "training_acc": 53.0, "val_loss": 17.305666208267212, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12987208366394, "training_acc": 53.0, "val_loss": 17.30787754058838, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.09113264083862, "training_acc": 53.0, "val_loss": 17.31305718421936, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10409784317017, "training_acc": 53.0, "val_loss": 17.320632934570312, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11973309516907, "training_acc": 53.0, "val_loss": 17.334705591201782, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15353345870972, "training_acc": 53.0, "val_loss": 17.344237864017487, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17478680610657, "training_acc": 53.0, "val_loss": 17.34839528799057, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1686282157898, "training_acc": 53.0, "val_loss": 17.336997389793396, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14181137084961, "training_acc": 53.0, "val_loss": 17.32136905193329, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14149904251099, "training_acc": 53.0, "val_loss": 17.312614619731903, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10650587081909, "training_acc": 53.0, "val_loss": 17.310594022274017, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.07501697540283, "training_acc": 53.0, "val_loss": 17.3107847571373, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.07709217071533, "training_acc": 53.0, "val_loss": 17.311593890190125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1077573299408, "training_acc": 53.0, "val_loss": 17.314045131206512, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.11684894561768, "training_acc": 53.0, "val_loss": 17.315363883972168, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.10403895378113, "training_acc": 53.0, "val_loss": 17.31436848640442, "val_acc": 52.0}
