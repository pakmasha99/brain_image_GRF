"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 811.8989791870117, "training_acc": 50.0, "val_loss": 87788355584000.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 234104728356668.44, "training_acc": 52.0, "val_loss": 30712218.75, "val_acc": 44.0}
{"epoch": 2, "training_loss": 340292400.0, "training_acc": 46.0, "val_loss": 59183981.25, "val_acc": 44.0}
{"epoch": 3, "training_loss": 151846298.5, "training_acc": 48.0, "val_loss": 1519282.421875, "val_acc": 44.0}
{"epoch": 4, "training_loss": 4141041.140625, "training_acc": 50.0, "val_loss": 119801925.0, "val_acc": 44.0}
{"epoch": 5, "training_loss": 306037563.5625, "training_acc": 48.0, "val_loss": 4058406.25, "val_acc": 56.0}
{"epoch": 6, "training_loss": 13887286.96875, "training_acc": 50.0, "val_loss": 2123685.9375, "val_acc": 56.0}
{"epoch": 7, "training_loss": 850598480.0, "training_acc": 48.0, "val_loss": 1773137.6953125, "val_acc": 44.0}
{"epoch": 8, "training_loss": 30182227.5, "training_acc": 48.0, "val_loss": 2445327.5390625, "val_acc": 44.0}
{"epoch": 9, "training_loss": 5933017.4677734375, "training_acc": 48.0, "val_loss": 371698.4375, "val_acc": 56.0}
{"epoch": 10, "training_loss": 1212235.283203125, "training_acc": 50.0, "val_loss": 1779288.28125, "val_acc": 56.0}
{"epoch": 11, "training_loss": 16912513.75, "training_acc": 52.0, "val_loss": 489413.671875, "val_acc": 56.0}
{"epoch": 12, "training_loss": 17852177.625, "training_acc": 54.0, "val_loss": 1855137.3046875, "val_acc": 56.0}
{"epoch": 13, "training_loss": 5529164.458984375, "training_acc": 48.0, "val_loss": 160894.189453125, "val_acc": 56.0}
{"epoch": 14, "training_loss": 813244.625, "training_acc": 52.0, "val_loss": 1109660.9375, "val_acc": 44.0}
{"epoch": 15, "training_loss": 2809478.0703125, "training_acc": 48.0, "val_loss": 86974.609375, "val_acc": 56.0}
{"epoch": 16, "training_loss": 413463.42578125, "training_acc": 52.0, "val_loss": 71878.55834960938, "val_acc": 56.0}
{"epoch": 17, "training_loss": 244912.27392578125, "training_acc": 52.0, "val_loss": 2636.0740661621094, "val_acc": 56.0}
{"epoch": 18, "training_loss": 49492.63720703125, "training_acc": 50.0, "val_loss": 27030.37109375, "val_acc": 44.0}
{"epoch": 19, "training_loss": 36080086.4453125, "training_acc": 48.0, "val_loss": 754611.23046875, "val_acc": 44.0}
{"epoch": 20, "training_loss": 11241735.25, "training_acc": 48.0, "val_loss": 3997943.75, "val_acc": 44.0}
{"epoch": 21, "training_loss": 14194343.15625, "training_acc": 48.0, "val_loss": 890272.36328125, "val_acc": 44.0}
{"epoch": 22, "training_loss": 14953620.0, "training_acc": 44.0, "val_loss": 1024708.10546875, "val_acc": 44.0}
{"epoch": 23, "training_loss": 10630287.75, "training_acc": 46.0, "val_loss": 4430982.8125, "val_acc": 44.0}
{"epoch": 24, "training_loss": 11264335.4296875, "training_acc": 48.0, "val_loss": 16810.171508789062, "val_acc": 44.0}
{"epoch": 25, "training_loss": 53638.61291503906, "training_acc": 48.0, "val_loss": 8836.85531616211, "val_acc": 44.0}
{"epoch": 26, "training_loss": 69556.9755859375, "training_acc": 48.0, "val_loss": 2323.282241821289, "val_acc": 56.0}
{"epoch": 27, "training_loss": 102086.677734375, "training_acc": 53.0, "val_loss": 10445.20492553711, "val_acc": 44.0}
{"epoch": 28, "training_loss": 83357.51953125, "training_acc": 54.0, "val_loss": 1391416.6015625, "val_acc": 44.0}
{"epoch": 29, "training_loss": 3225858.8916015625, "training_acc": 48.0, "val_loss": 291796.1181640625, "val_acc": 56.0}
{"epoch": 30, "training_loss": 794771.8232421875, "training_acc": 52.0, "val_loss": 158837.841796875, "val_acc": 44.0}
{"epoch": 31, "training_loss": 559245.79296875, "training_acc": 48.0, "val_loss": 48423.66638183594, "val_acc": 44.0}
{"epoch": 32, "training_loss": 157340.00390625, "training_acc": 48.0, "val_loss": 8059.892272949219, "val_acc": 56.0}
{"epoch": 33, "training_loss": 133795.166015625, "training_acc": 48.0, "val_loss": 2450.4310607910156, "val_acc": 56.0}
{"epoch": 34, "training_loss": 27836.91357421875, "training_acc": 54.0, "val_loss": 9639.444732666016, "val_acc": 56.0}
{"epoch": 35, "training_loss": 29726.0654296875, "training_acc": 52.0, "val_loss": 35215.277099609375, "val_acc": 44.0}
{"epoch": 36, "training_loss": 124693.416015625, "training_acc": 48.0, "val_loss": 10971.516418457031, "val_acc": 44.0}
{"epoch": 37, "training_loss": 35332.59826660156, "training_acc": 58.0, "val_loss": 17895.925903320312, "val_acc": 56.0}
{"epoch": 38, "training_loss": 72579.88049316406, "training_acc": 52.0, "val_loss": 5684.584045410156, "val_acc": 56.0}
{"epoch": 39, "training_loss": 26341.42431640625, "training_acc": 56.0, "val_loss": 13133.851623535156, "val_acc": 44.0}
{"epoch": 40, "training_loss": 37632.57049560547, "training_acc": 48.0, "val_loss": 4469.365310668945, "val_acc": 56.0}
{"epoch": 41, "training_loss": 22323.108032226562, "training_acc": 52.0, "val_loss": 4143.886947631836, "val_acc": 56.0}
{"epoch": 42, "training_loss": 11710.482124328613, "training_acc": 53.0, "val_loss": 4527.398300170898, "val_acc": 44.0}
{"epoch": 43, "training_loss": 15437.748901367188, "training_acc": 48.0, "val_loss": 413.59877586364746, "val_acc": 60.0}
{"epoch": 44, "training_loss": 2789.7618255615234, "training_acc": 52.0, "val_loss": 1254.3310165405273, "val_acc": 44.0}
{"epoch": 45, "training_loss": 3673.492977142334, "training_acc": 44.0, "val_loss": 1069.9921607971191, "val_acc": 56.0}
{"epoch": 46, "training_loss": 3964.868782043457, "training_acc": 52.0, "val_loss": 2047.3217010498047, "val_acc": 44.0}
{"epoch": 47, "training_loss": 8274.33853149414, "training_acc": 48.0, "val_loss": 519.6123123168945, "val_acc": 44.0}
{"epoch": 48, "training_loss": 5130.463775634766, "training_acc": 48.0, "val_loss": 3123.611068725586, "val_acc": 56.0}
{"epoch": 49, "training_loss": 12628.527893066406, "training_acc": 52.0, "val_loss": 737.5797748565674, "val_acc": 56.0}
{"epoch": 50, "training_loss": 4629.890197753906, "training_acc": 54.0, "val_loss": 3415.595245361328, "val_acc": 44.0}
{"epoch": 51, "training_loss": 12372.11294555664, "training_acc": 48.0, "val_loss": 1527.8780937194824, "val_acc": 44.0}
{"epoch": 52, "training_loss": 5532.614273071289, "training_acc": 46.0, "val_loss": 1721.156883239746, "val_acc": 56.0}
{"epoch": 53, "training_loss": 7402.745697021484, "training_acc": 52.0, "val_loss": 468.2715892791748, "val_acc": 56.0}
{"epoch": 54, "training_loss": 3282.944290161133, "training_acc": 51.0, "val_loss": 2070.8324432373047, "val_acc": 44.0}
{"epoch": 55, "training_loss": 6799.069610595703, "training_acc": 48.0, "val_loss": 84.78618264198303, "val_acc": 56.0}
{"epoch": 56, "training_loss": 1663.5977630615234, "training_acc": 54.0, "val_loss": 395.4685688018799, "val_acc": 56.0}
{"epoch": 57, "training_loss": 2310.6153717041016, "training_acc": 48.0, "val_loss": 732.2440147399902, "val_acc": 44.0}
{"epoch": 58, "training_loss": 2044.520149230957, "training_acc": 48.0, "val_loss": 396.8886613845825, "val_acc": 56.0}
{"epoch": 59, "training_loss": 1585.4116287231445, "training_acc": 45.0, "val_loss": 328.57842445373535, "val_acc": 48.0}
{"epoch": 60, "training_loss": 1582.0584869384766, "training_acc": 49.0, "val_loss": 177.5685429573059, "val_acc": 48.0}
{"epoch": 61, "training_loss": 743.6817436218262, "training_acc": 53.0, "val_loss": 185.1857304573059, "val_acc": 56.0}
{"epoch": 62, "training_loss": 1051.1206150054932, "training_acc": 51.0, "val_loss": 86.11612319946289, "val_acc": 48.0}
{"epoch": 63, "training_loss": 727.1409797668457, "training_acc": 50.0, "val_loss": 55.33456802368164, "val_acc": 48.0}
{"epoch": 64, "training_loss": 608.4439449310303, "training_acc": 50.0, "val_loss": 193.81933212280273, "val_acc": 56.0}
{"epoch": 65, "training_loss": 1070.4160861968994, "training_acc": 46.0, "val_loss": 334.42938327789307, "val_acc": 44.0}
{"epoch": 66, "training_loss": 1035.164707183838, "training_acc": 48.0, "val_loss": 169.49676275253296, "val_acc": 56.0}
{"epoch": 67, "training_loss": 895.5384502410889, "training_acc": 45.0, "val_loss": 330.7123899459839, "val_acc": 44.0}
{"epoch": 68, "training_loss": 1572.2398071289062, "training_acc": 42.0, "val_loss": 166.7072892189026, "val_acc": 56.0}
{"epoch": 69, "training_loss": 1157.0709991455078, "training_acc": 52.0, "val_loss": 423.98200035095215, "val_acc": 44.0}
{"epoch": 70, "training_loss": 1936.0388259887695, "training_acc": 46.0, "val_loss": 581.3594818115234, "val_acc": 56.0}
{"epoch": 71, "training_loss": 1575.9590396881104, "training_acc": 56.0, "val_loss": 1425.2878189086914, "val_acc": 44.0}
{"epoch": 72, "training_loss": 5659.990509033203, "training_acc": 48.0, "val_loss": 1365.05708694458, "val_acc": 44.0}
{"epoch": 73, "training_loss": 3721.7016105651855, "training_acc": 50.0, "val_loss": 1126.8449783325195, "val_acc": 56.0}
{"epoch": 74, "training_loss": 5682.62744140625, "training_acc": 52.0, "val_loss": 1183.2990646362305, "val_acc": 56.0}
{"epoch": 75, "training_loss": 3798.4206008911133, "training_acc": 50.0, "val_loss": 1378.4177780151367, "val_acc": 44.0}
{"epoch": 76, "training_loss": 5964.246124267578, "training_acc": 48.0, "val_loss": 1854.9827575683594, "val_acc": 44.0}
{"epoch": 77, "training_loss": 5559.988899230957, "training_acc": 48.0, "val_loss": 543.6978816986084, "val_acc": 56.0}
{"epoch": 78, "training_loss": 3064.7971954345703, "training_acc": 52.0, "val_loss": 1055.1469802856445, "val_acc": 56.0}
{"epoch": 79, "training_loss": 4073.568634033203, "training_acc": 52.0, "val_loss": 436.4692687988281, "val_acc": 44.0}
{"epoch": 80, "training_loss": 2358.448516845703, "training_acc": 48.0, "val_loss": 523.1238842010498, "val_acc": 44.0}
{"epoch": 81, "training_loss": 1925.820053100586, "training_acc": 51.0, "val_loss": 536.0060214996338, "val_acc": 56.0}
{"epoch": 82, "training_loss": 2248.8268966674805, "training_acc": 52.0, "val_loss": 459.14058685302734, "val_acc": 44.0}
