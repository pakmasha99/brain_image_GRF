"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.52580666542053, "training_acc": 53.0, "val_loss": 17.326661944389343, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.49967503547668, "training_acc": 51.0, "val_loss": 17.323946952819824, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.75872826576233, "training_acc": 53.0, "val_loss": 17.335230112075806, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.37386512756348, "training_acc": 47.0, "val_loss": 17.396415770053864, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.72825288772583, "training_acc": 53.0, "val_loss": 17.448899149894714, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.55887055397034, "training_acc": 53.0, "val_loss": 17.40184724330902, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.3184700012207, "training_acc": 53.0, "val_loss": 17.308692634105682, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21657419204712, "training_acc": 51.0, "val_loss": 17.332741618156433, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.57436347007751, "training_acc": 45.0, "val_loss": 17.31126308441162, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.83976817131042, "training_acc": 43.0, "val_loss": 17.320723831653595, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.38083338737488, "training_acc": 53.0, "val_loss": 17.535430192947388, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.81966996192932, "training_acc": 53.0, "val_loss": 17.72902011871338, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.41576361656189, "training_acc": 53.0, "val_loss": 17.354816198349, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.34380769729614, "training_acc": 53.0, "val_loss": 17.333006858825684, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.40139245986938, "training_acc": 47.0, "val_loss": 17.314590513706207, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10974192619324, "training_acc": 53.0, "val_loss": 17.366139590740204, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21629762649536, "training_acc": 53.0, "val_loss": 17.481417953968048, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.74294352531433, "training_acc": 53.0, "val_loss": 17.360763251781464, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.39575529098511, "training_acc": 53.0, "val_loss": 17.363211512565613, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.5952501296997, "training_acc": 47.0, "val_loss": 17.329497635364532, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1921010017395, "training_acc": 57.0, "val_loss": 17.384164035320282, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.77380084991455, "training_acc": 53.0, "val_loss": 17.64226257801056, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.19763612747192, "training_acc": 53.0, "val_loss": 17.309054732322693, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21395492553711, "training_acc": 51.0, "val_loss": 17.375852167606354, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.03665232658386, "training_acc": 39.0, "val_loss": 17.33139157295227, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.3309109210968, "training_acc": 47.0, "val_loss": 17.323113977909088, "val_acc": 52.0}
