"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.18717217445374, "training_acc": 52.0, "val_loss": 18.69829148054123, "val_acc": 56.0}
{"epoch": 1, "training_loss": 72.22164583206177, "training_acc": 48.0, "val_loss": 17.215588688850403, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.36328482627869, "training_acc": 52.0, "val_loss": 17.323894798755646, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.36259531974792, "training_acc": 52.0, "val_loss": 17.563261091709137, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.59623837471008, "training_acc": 48.0, "val_loss": 17.17742085456848, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.18577742576599, "training_acc": 52.0, "val_loss": 17.22169518470764, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.48201870918274, "training_acc": 50.0, "val_loss": 17.60101318359375, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.68100380897522, "training_acc": 48.0, "val_loss": 17.18507409095764, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.72880911827087, "training_acc": 52.0, "val_loss": 17.148399353027344, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.34205150604248, "training_acc": 52.0, "val_loss": 17.49197691679001, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.78184247016907, "training_acc": 48.0, "val_loss": 17.576678097248077, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.71066641807556, "training_acc": 48.0, "val_loss": 17.192542552947998, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.60163068771362, "training_acc": 52.0, "val_loss": 17.1507328748703, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.52545189857483, "training_acc": 52.0, "val_loss": 17.260558903217316, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.36466264724731, "training_acc": 48.0, "val_loss": 17.287364602088928, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.27452516555786, "training_acc": 52.0, "val_loss": 17.17529594898224, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.465012550354, "training_acc": 52.0, "val_loss": 17.148704826831818, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.45543789863586, "training_acc": 52.0, "val_loss": 17.244617640972137, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.29356479644775, "training_acc": 50.0, "val_loss": 17.372672259807587, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.37787532806396, "training_acc": 48.0, "val_loss": 17.258140444755554, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.23263907432556, "training_acc": 52.0, "val_loss": 17.183171212673187, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.30249333381653, "training_acc": 52.0, "val_loss": 17.154838144779205, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.78103375434875, "training_acc": 52.0, "val_loss": 17.169277369976044, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.110666513443, "training_acc": 52.0, "val_loss": 17.513813078403473, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.64862537384033, "training_acc": 48.0, "val_loss": 17.606575787067413, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.72544431686401, "training_acc": 48.0, "val_loss": 17.246899008750916, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.23426294326782, "training_acc": 52.0, "val_loss": 17.150981724262238, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.45298194885254, "training_acc": 52.0, "val_loss": 17.3586905002594, "val_acc": 56.0}
