"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.20168232917786, "training_acc": 43.0, "val_loss": 17.576006054878235, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.87078547477722, "training_acc": 43.0, "val_loss": 17.450954020023346, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.58728289604187, "training_acc": 53.0, "val_loss": 17.334531247615814, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.79297947883606, "training_acc": 47.0, "val_loss": 17.374347150325775, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.09365057945251, "training_acc": 43.0, "val_loss": 17.308971285820007, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23620676994324, "training_acc": 53.0, "val_loss": 17.310920357704163, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.9027829170227, "training_acc": 43.0, "val_loss": 17.308759689331055, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.98834300041199, "training_acc": 53.0, "val_loss": 17.466850578784943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.80929684638977, "training_acc": 53.0, "val_loss": 17.454372346401215, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.46165490150452, "training_acc": 53.0, "val_loss": 17.34459698200226, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41636204719543, "training_acc": 47.0, "val_loss": 17.32899099588394, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24278235435486, "training_acc": 53.0, "val_loss": 17.32019931077957, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07370162010193, "training_acc": 53.0, "val_loss": 17.447425425052643, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.53720784187317, "training_acc": 53.0, "val_loss": 17.53062903881073, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.80425071716309, "training_acc": 53.0, "val_loss": 17.35265552997589, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13307905197144, "training_acc": 53.0, "val_loss": 17.309556901454926, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21383380889893, "training_acc": 53.0, "val_loss": 17.336006462574005, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.34793591499329, "training_acc": 47.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08076047897339, "training_acc": 53.0, "val_loss": 17.359444499015808, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.23353219032288, "training_acc": 53.0, "val_loss": 17.443697154521942, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.46281814575195, "training_acc": 53.0, "val_loss": 17.364244163036346, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29358506202698, "training_acc": 53.0, "val_loss": 17.309828102588654, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19705295562744, "training_acc": 53.0, "val_loss": 17.317843437194824, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22865056991577, "training_acc": 53.0, "val_loss": 17.309249937534332, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11459136009216, "training_acc": 53.0, "val_loss": 17.338554561138153, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17146325111389, "training_acc": 53.0, "val_loss": 17.365512251853943, "val_acc": 52.0}
