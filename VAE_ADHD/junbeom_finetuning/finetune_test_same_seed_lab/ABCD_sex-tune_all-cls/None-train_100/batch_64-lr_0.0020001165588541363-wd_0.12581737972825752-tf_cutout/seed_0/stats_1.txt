"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.74113416671753, "training_acc": 46.0, "val_loss": 17.55402833223343, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.54415917396545, "training_acc": 55.0, "val_loss": 18.682225048542023, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.32475900650024, "training_acc": 53.0, "val_loss": 17.666001617908478, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.82456159591675, "training_acc": 53.0, "val_loss": 17.31763780117035, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.28920078277588, "training_acc": 51.0, "val_loss": 17.312276363372803, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.23048520088196, "training_acc": 53.0, "val_loss": 17.30901747941971, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.71920108795166, "training_acc": 47.0, "val_loss": 17.35241264104843, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28409504890442, "training_acc": 53.0, "val_loss": 17.339669167995453, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29387712478638, "training_acc": 53.0, "val_loss": 17.450179159641266, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.42901802062988, "training_acc": 53.0, "val_loss": 17.32209026813507, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.96025133132935, "training_acc": 37.0, "val_loss": 17.312927544116974, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.81596684455872, "training_acc": 53.0, "val_loss": 17.399592697620392, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.65593647956848, "training_acc": 53.0, "val_loss": 17.33628362417221, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.05523300170898, "training_acc": 53.0, "val_loss": 17.356212437152863, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.79614734649658, "training_acc": 47.0, "val_loss": 17.387954890727997, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.6079957485199, "training_acc": 47.0, "val_loss": 17.31444150209427, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.096675157547, "training_acc": 53.0, "val_loss": 17.399364709854126, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.34865212440491, "training_acc": 53.0, "val_loss": 17.406538128852844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.54776787757874, "training_acc": 53.0, "val_loss": 17.335087060928345, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17860341072083, "training_acc": 53.0, "val_loss": 17.31685996055603, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10903859138489, "training_acc": 53.0, "val_loss": 17.311212420463562, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.88413333892822, "training_acc": 41.0, "val_loss": 17.315156757831573, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.10852456092834, "training_acc": 53.0, "val_loss": 17.38511621952057, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27889370918274, "training_acc": 53.0, "val_loss": 17.48778373003006, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.65283393859863, "training_acc": 53.0, "val_loss": 17.396225035190582, "val_acc": 52.0}
