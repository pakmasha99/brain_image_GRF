"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.88484907150269, "training_acc": 47.0, "val_loss": 17.40681082010269, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.26380133628845, "training_acc": 57.0, "val_loss": 20.019514858722687, "val_acc": 52.0}
{"epoch": 2, "training_loss": 76.67785549163818, "training_acc": 53.0, "val_loss": 17.530986666679382, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.04263472557068, "training_acc": 53.0, "val_loss": 17.53120720386505, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.34382104873657, "training_acc": 47.0, "val_loss": 17.446759343147278, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.57821750640869, "training_acc": 51.0, "val_loss": 17.33664870262146, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16078042984009, "training_acc": 53.0, "val_loss": 17.39354282617569, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.10948967933655, "training_acc": 53.0, "val_loss": 17.358148097991943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22709846496582, "training_acc": 53.0, "val_loss": 17.416687309741974, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.83064603805542, "training_acc": 53.0, "val_loss": 17.317794263362885, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.33254861831665, "training_acc": 43.0, "val_loss": 17.39107519388199, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.53601098060608, "training_acc": 47.0, "val_loss": 17.309658229351044, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16408324241638, "training_acc": 53.0, "val_loss": 17.388010025024414, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.65241169929504, "training_acc": 53.0, "val_loss": 17.36094057559967, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.32384824752808, "training_acc": 53.0, "val_loss": 17.320899665355682, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.34910583496094, "training_acc": 49.0, "val_loss": 17.322249710559845, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.31646800041199, "training_acc": 53.0, "val_loss": 17.318710684776306, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15392637252808, "training_acc": 53.0, "val_loss": 17.343822121620178, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19930911064148, "training_acc": 53.0, "val_loss": 17.37026423215866, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.31844830513, "training_acc": 53.0, "val_loss": 17.349740862846375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13048124313354, "training_acc": 53.0, "val_loss": 17.31088161468506, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25573706626892, "training_acc": 51.0, "val_loss": 17.358829081058502, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.43980598449707, "training_acc": 47.0, "val_loss": 17.31056123971939, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.09003925323486, "training_acc": 53.0, "val_loss": 17.361770570278168, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.32446670532227, "training_acc": 53.0, "val_loss": 17.447112500667572, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.07890820503235, "training_acc": 53.0, "val_loss": 17.345382273197174, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.010586977005, "training_acc": 53.0, "val_loss": 17.359326779842377, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24815058708191, "training_acc": 53.0, "val_loss": 17.522692680358887, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.83771061897278, "training_acc": 53.0, "val_loss": 17.392142117023468, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.85771036148071, "training_acc": 53.0, "val_loss": 17.334774136543274, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.34998750686646, "training_acc": 47.0, "val_loss": 17.326365411281586, "val_acc": 52.0}
