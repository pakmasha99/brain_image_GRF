"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 116.35277938842773, "training_acc": 47.0, "val_loss": 260.1191759109497, "val_acc": 52.0}
{"epoch": 1, "training_loss": 772.0210666656494, "training_acc": 43.0, "val_loss": 17.584672570228577, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.84798836708069, "training_acc": 45.0, "val_loss": 17.341502010822296, "val_acc": 52.0}
{"epoch": 3, "training_loss": 78.1525387763977, "training_acc": 43.0, "val_loss": 17.614150047302246, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.89333271980286, "training_acc": 47.0, "val_loss": 17.433585226535797, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.65612769126892, "training_acc": 47.0, "val_loss": 17.310191690921783, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1547634601593, "training_acc": 53.0, "val_loss": 17.311501502990723, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26897692680359, "training_acc": 53.0, "val_loss": 17.324168980121613, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12498450279236, "training_acc": 53.0, "val_loss": 17.361335456371307, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44674515724182, "training_acc": 53.0, "val_loss": 17.3684760928154, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.46990585327148, "training_acc": 53.0, "val_loss": 17.320534586906433, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1366457939148, "training_acc": 53.0, "val_loss": 17.314180731773376, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12713313102722, "training_acc": 53.0, "val_loss": 17.310525476932526, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17661905288696, "training_acc": 53.0, "val_loss": 17.30988472700119, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16065263748169, "training_acc": 53.0, "val_loss": 17.308463156223297, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16931200027466, "training_acc": 53.0, "val_loss": 17.308612167835236, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16411757469177, "training_acc": 53.0, "val_loss": 17.311033606529236, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14386868476868, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12692189216614, "training_acc": 53.0, "val_loss": 17.319419980049133, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15591812133789, "training_acc": 53.0, "val_loss": 17.3288494348526, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17171120643616, "training_acc": 53.0, "val_loss": 17.32895076274872, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14538979530334, "training_acc": 53.0, "val_loss": 17.31782853603363, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.133460521698, "training_acc": 53.0, "val_loss": 17.31087416410446, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18699645996094, "training_acc": 53.0, "val_loss": 17.309589684009552, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1421046257019, "training_acc": 53.0, "val_loss": 17.31277108192444, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20445084571838, "training_acc": 53.0, "val_loss": 17.31448471546173, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17379879951477, "training_acc": 53.0, "val_loss": 17.322726547718048, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12759137153625, "training_acc": 53.0, "val_loss": 17.344161868095398, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.24166440963745, "training_acc": 53.0, "val_loss": 17.357459664344788, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.26229906082153, "training_acc": 53.0, "val_loss": 17.344550788402557, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18970823287964, "training_acc": 53.0, "val_loss": 17.338964343070984, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.23237562179565, "training_acc": 53.0, "val_loss": 17.325402796268463, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16712641716003, "training_acc": 53.0, "val_loss": 17.322419583797455, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14466714859009, "training_acc": 53.0, "val_loss": 17.323215305805206, "val_acc": 52.0}
