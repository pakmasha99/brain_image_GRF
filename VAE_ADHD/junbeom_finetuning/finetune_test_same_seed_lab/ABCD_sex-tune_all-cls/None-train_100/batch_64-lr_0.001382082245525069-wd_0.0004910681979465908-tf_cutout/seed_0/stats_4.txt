"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 142.86652755737305, "training_acc": 45.0, "val_loss": 108.56173038482666, "val_acc": 52.0}
{"epoch": 1, "training_loss": 365.1945695877075, "training_acc": 49.0, "val_loss": 18.288736045360565, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72.10636019706726, "training_acc": 47.0, "val_loss": 17.308978736400604, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.23267936706543, "training_acc": 53.0, "val_loss": 17.32580214738846, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.19333362579346, "training_acc": 49.0, "val_loss": 17.507460713386536, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.73819708824158, "training_acc": 53.0, "val_loss": 17.35716164112091, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52876687049866, "training_acc": 53.0, "val_loss": 17.4222469329834, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.97001028060913, "training_acc": 47.0, "val_loss": 17.420002818107605, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.5955696105957, "training_acc": 47.0, "val_loss": 17.30935573577881, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30186438560486, "training_acc": 53.0, "val_loss": 17.31170564889908, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.26475858688354, "training_acc": 53.0, "val_loss": 17.314791679382324, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13796019554138, "training_acc": 53.0, "val_loss": 17.305585741996765, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14003729820251, "training_acc": 53.0, "val_loss": 17.305713891983032, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19752836227417, "training_acc": 53.0, "val_loss": 17.305858433246613, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1864321231842, "training_acc": 53.0, "val_loss": 17.31031835079193, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14900279045105, "training_acc": 53.0, "val_loss": 17.3466756939888, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.32294034957886, "training_acc": 53.0, "val_loss": 17.348022758960724, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15507626533508, "training_acc": 53.0, "val_loss": 17.312930524349213, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13035655021667, "training_acc": 53.0, "val_loss": 17.30678528547287, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21424984931946, "training_acc": 53.0, "val_loss": 17.309586703777313, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2095787525177, "training_acc": 53.0, "val_loss": 17.308685183525085, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1818516254425, "training_acc": 53.0, "val_loss": 17.308098077774048, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2055823802948, "training_acc": 53.0, "val_loss": 17.307421565055847, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2186667919159, "training_acc": 53.0, "val_loss": 17.30838418006897, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13706731796265, "training_acc": 53.0, "val_loss": 17.31034815311432, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15610027313232, "training_acc": 53.0, "val_loss": 17.312486469745636, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13673543930054, "training_acc": 53.0, "val_loss": 17.320074141025543, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14393544197083, "training_acc": 53.0, "val_loss": 17.326709628105164, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17303514480591, "training_acc": 53.0, "val_loss": 17.329074442386627, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1610460281372, "training_acc": 53.0, "val_loss": 17.321670055389404, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17952275276184, "training_acc": 53.0, "val_loss": 17.316651344299316, "val_acc": 52.0}
