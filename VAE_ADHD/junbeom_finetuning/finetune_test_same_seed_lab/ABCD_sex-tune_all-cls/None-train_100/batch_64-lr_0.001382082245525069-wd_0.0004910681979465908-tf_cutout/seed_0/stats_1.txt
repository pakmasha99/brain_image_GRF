"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 101.33911228179932, "training_acc": 49.0, "val_loss": 225.500750541687, "val_acc": 52.0}
{"epoch": 1, "training_loss": 630.5592865943909, "training_acc": 49.0, "val_loss": 17.40913689136505, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50934219360352, "training_acc": 49.0, "val_loss": 17.44723916053772, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.43228054046631, "training_acc": 53.0, "val_loss": 26.08831524848938, "val_acc": 48.0}
{"epoch": 4, "training_loss": 82.42649292945862, "training_acc": 59.0, "val_loss": 19.428730010986328, "val_acc": 52.0}
{"epoch": 5, "training_loss": 75.67470240592957, "training_acc": 53.0, "val_loss": 17.524024844169617, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.1730797290802, "training_acc": 53.0, "val_loss": 17.36592799425125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.31553959846497, "training_acc": 53.0, "val_loss": 17.34985262155533, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22084832191467, "training_acc": 53.0, "val_loss": 17.346985638141632, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.27386927604675, "training_acc": 53.0, "val_loss": 17.34096109867096, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1771023273468, "training_acc": 53.0, "val_loss": 17.315295338630676, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12173986434937, "training_acc": 53.0, "val_loss": 17.308354377746582, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21565341949463, "training_acc": 53.0, "val_loss": 17.31046289205551, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22042393684387, "training_acc": 53.0, "val_loss": 17.31204390525818, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19654893875122, "training_acc": 53.0, "val_loss": 17.30913072824478, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16581010818481, "training_acc": 53.0, "val_loss": 17.309001088142395, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20323443412781, "training_acc": 53.0, "val_loss": 17.31119155883789, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22856736183167, "training_acc": 53.0, "val_loss": 17.322658002376556, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22620034217834, "training_acc": 53.0, "val_loss": 17.32739955186844, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14784646034241, "training_acc": 53.0, "val_loss": 17.32126921415329, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1632194519043, "training_acc": 53.0, "val_loss": 17.31545925140381, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13130593299866, "training_acc": 53.0, "val_loss": 17.313632369041443, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14036870002747, "training_acc": 53.0, "val_loss": 17.31191575527191, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1391453742981, "training_acc": 53.0, "val_loss": 17.3115074634552, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14981031417847, "training_acc": 53.0, "val_loss": 17.311973869800568, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14435243606567, "training_acc": 53.0, "val_loss": 17.315104603767395, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14018940925598, "training_acc": 53.0, "val_loss": 17.31707751750946, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18398714065552, "training_acc": 53.0, "val_loss": 17.316539585590363, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12981367111206, "training_acc": 53.0, "val_loss": 17.3211470246315, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13427758216858, "training_acc": 53.0, "val_loss": 17.325793206691742, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1593930721283, "training_acc": 53.0, "val_loss": 17.331285774707794, "val_acc": 52.0}
