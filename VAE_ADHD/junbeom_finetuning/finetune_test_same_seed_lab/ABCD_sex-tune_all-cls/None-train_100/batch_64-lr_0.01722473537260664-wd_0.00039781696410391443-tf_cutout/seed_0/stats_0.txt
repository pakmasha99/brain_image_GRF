"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1101.6666793823242, "training_acc": 50.0, "val_loss": 2.565980697919488e+17, "val_acc": 56.0}
{"epoch": 1, "training_loss": 6.804485763543156e+17, "training_acc": 52.0, "val_loss": 618741600.0, "val_acc": 56.0}
{"epoch": 2, "training_loss": 16275711872.0, "training_acc": 54.0, "val_loss": 7441542400.0, "val_acc": 44.0}
{"epoch": 3, "training_loss": 18656109884.0, "training_acc": 48.0, "val_loss": 219982875.0, "val_acc": 56.0}
{"epoch": 4, "training_loss": 875532112.0, "training_acc": 50.0, "val_loss": 13282470.3125, "val_acc": 44.0}
{"epoch": 5, "training_loss": 141680605.0, "training_acc": 44.0, "val_loss": 70864300.0, "val_acc": 44.0}
{"epoch": 6, "training_loss": 286626873.0, "training_acc": 48.0, "val_loss": 2896202.34375, "val_acc": 56.0}
{"epoch": 7, "training_loss": 66278084778.0, "training_acc": 48.0, "val_loss": 56649625.0, "val_acc": 56.0}
{"epoch": 8, "training_loss": 1163191599840.0, "training_acc": 51.0, "val_loss": 2778031600.0, "val_acc": 56.0}
{"epoch": 9, "training_loss": 9481387344.0, "training_acc": 52.0, "val_loss": 1996137062400.0, "val_acc": 56.0}
{"epoch": 10, "training_loss": 5567055578704.0, "training_acc": 50.0, "val_loss": 25811376000.0, "val_acc": 44.0}
{"epoch": 11, "training_loss": 62225902928.0, "training_acc": 48.0, "val_loss": 4094306400.0, "val_acc": 44.0}
{"epoch": 12, "training_loss": 15114723328.0, "training_acc": 46.0, "val_loss": 18597866700800.0, "val_acc": 44.0}
{"epoch": 13, "training_loss": 42631233126400.0, "training_acc": 48.0, "val_loss": 81896076800.0, "val_acc": 44.0}
{"epoch": 14, "training_loss": 231280844800.0, "training_acc": 48.0, "val_loss": 137901913600.0, "val_acc": 56.0}
{"epoch": 15, "training_loss": 819036127232.0, "training_acc": 46.0, "val_loss": 428360780800.0, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1334328717312.0, "training_acc": 52.0, "val_loss": 277602227200.0, "val_acc": 56.0}
{"epoch": 17, "training_loss": 778851799680.0, "training_acc": 52.0, "val_loss": 1814912000.0, "val_acc": 44.0}
{"epoch": 18, "training_loss": 14728386176.0, "training_acc": 50.0, "val_loss": 17466011200.0, "val_acc": 44.0}
{"epoch": 19, "training_loss": 45687317600.0, "training_acc": 48.0, "val_loss": 3183223200.0, "val_acc": 44.0}
{"epoch": 20, "training_loss": 11245321568.0, "training_acc": 52.0, "val_loss": 74455084800.0, "val_acc": 44.0}
{"epoch": 21, "training_loss": 164320072616.0, "training_acc": 48.0, "val_loss": 87266543.75, "val_acc": 44.0}
{"epoch": 22, "training_loss": 288818001.5, "training_acc": 48.0, "val_loss": 333404150.0, "val_acc": 44.0}
{"epoch": 23, "training_loss": 1035941690.0, "training_acc": 46.0, "val_loss": 154020625.0, "val_acc": 56.0}
{"epoch": 24, "training_loss": 703059208.0, "training_acc": 52.0, "val_loss": 125843412.5, "val_acc": 56.0}
{"epoch": 25, "training_loss": 509673055.0, "training_acc": 48.0, "val_loss": 81441756.25, "val_acc": 56.0}
