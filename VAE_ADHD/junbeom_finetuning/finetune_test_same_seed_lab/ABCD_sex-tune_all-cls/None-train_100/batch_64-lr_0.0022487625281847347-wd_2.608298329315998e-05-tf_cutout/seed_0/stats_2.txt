"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 141.35078811645508, "training_acc": 47.0, "val_loss": 821.1731910705566, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2027.180941581726, "training_acc": 55.0, "val_loss": 17.734187841415405, "val_acc": 52.0}
{"epoch": 2, "training_loss": 83.79944038391113, "training_acc": 43.0, "val_loss": 17.48121529817581, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.52216386795044, "training_acc": 47.0, "val_loss": 17.41153746843338, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.34264707565308, "training_acc": 51.0, "val_loss": 18.047504127025604, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.1368248462677, "training_acc": 53.0, "val_loss": 17.387782037258148, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.43035864830017, "training_acc": 47.0, "val_loss": 17.309245467185974, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07315921783447, "training_acc": 53.0, "val_loss": 17.384470999240875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.7711124420166, "training_acc": 53.0, "val_loss": 17.337097227573395, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.78635334968567, "training_acc": 53.0, "val_loss": 17.313620448112488, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19620823860168, "training_acc": 53.0, "val_loss": 17.321106791496277, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15982127189636, "training_acc": 53.0, "val_loss": 17.358742654323578, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.51726245880127, "training_acc": 53.0, "val_loss": 17.319177091121674, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22518658638, "training_acc": 53.0, "val_loss": 17.316947877407074, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23912262916565, "training_acc": 53.0, "val_loss": 17.31337159872055, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2229335308075, "training_acc": 53.0, "val_loss": 17.308779060840607, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15617966651917, "training_acc": 53.0, "val_loss": 17.31140911579132, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11664772033691, "training_acc": 53.0, "val_loss": 17.328758537769318, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.212961435318, "training_acc": 53.0, "val_loss": 17.355795204639435, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.23629117012024, "training_acc": 53.0, "val_loss": 17.33572781085968, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15073990821838, "training_acc": 53.0, "val_loss": 17.310966551303864, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13668894767761, "training_acc": 53.0, "val_loss": 17.30811297893524, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20581817626953, "training_acc": 53.0, "val_loss": 17.30814278125763, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17214441299438, "training_acc": 53.0, "val_loss": 17.308346927165985, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18760752677917, "training_acc": 53.0, "val_loss": 17.30969548225403, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15505909919739, "training_acc": 53.0, "val_loss": 17.31584072113037, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11071801185608, "training_acc": 53.0, "val_loss": 17.338792979717255, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24868988990784, "training_acc": 53.0, "val_loss": 17.358697950839996, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.26949405670166, "training_acc": 53.0, "val_loss": 17.345641553401947, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19254970550537, "training_acc": 53.0, "val_loss": 17.339468002319336, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.24343967437744, "training_acc": 53.0, "val_loss": 17.324328422546387, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1657783985138, "training_acc": 53.0, "val_loss": 17.32032299041748, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13951683044434, "training_acc": 53.0, "val_loss": 17.32029616832733, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.16704511642456, "training_acc": 53.0, "val_loss": 17.32032001018524, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17349553108215, "training_acc": 53.0, "val_loss": 17.325706779956818, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15407681465149, "training_acc": 53.0, "val_loss": 17.321616411209106, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1558313369751, "training_acc": 53.0, "val_loss": 17.31884330511093, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13728833198547, "training_acc": 53.0, "val_loss": 17.319464683532715, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.16521453857422, "training_acc": 53.0, "val_loss": 17.31862723827362, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14720058441162, "training_acc": 53.0, "val_loss": 17.322342097759247, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14241123199463, "training_acc": 53.0, "val_loss": 17.321540415287018, "val_acc": 52.0}
