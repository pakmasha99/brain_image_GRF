"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 148.9773826599121, "training_acc": 50.0, "val_loss": 824.849796295166, "val_acc": 56.0}
{"epoch": 1, "training_loss": 2661.7507820129395, "training_acc": 52.0, "val_loss": 21.97432667016983, "val_acc": 44.0}
{"epoch": 2, "training_loss": 81.04312586784363, "training_acc": 48.0, "val_loss": 17.24371314048767, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.39100360870361, "training_acc": 52.0, "val_loss": 17.22732186317444, "val_acc": 56.0}
{"epoch": 4, "training_loss": 70.60792803764343, "training_acc": 50.0, "val_loss": 17.814476788043976, "val_acc": 56.0}
{"epoch": 5, "training_loss": 72.77093553543091, "training_acc": 52.0, "val_loss": 17.170491814613342, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.38179135322571, "training_acc": 52.0, "val_loss": 17.449747025966644, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.63855767250061, "training_acc": 48.0, "val_loss": 17.423878610134125, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.77392745018005, "training_acc": 42.0, "val_loss": 17.265784740447998, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25543165206909, "training_acc": 52.0, "val_loss": 17.254100739955902, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23965120315552, "training_acc": 52.0, "val_loss": 17.248588800430298, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.24467206001282, "training_acc": 52.0, "val_loss": 17.23090261220932, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.27036023139954, "training_acc": 52.0, "val_loss": 17.23165512084961, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.27730321884155, "training_acc": 52.0, "val_loss": 17.26476699113846, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25200390815735, "training_acc": 52.0, "val_loss": 17.24606603384018, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23343753814697, "training_acc": 52.0, "val_loss": 17.209765315055847, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.27272415161133, "training_acc": 52.0, "val_loss": 17.179910838603973, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.29622006416321, "training_acc": 52.0, "val_loss": 17.19299405813217, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25587010383606, "training_acc": 52.0, "val_loss": 17.216476798057556, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.2304162979126, "training_acc": 52.0, "val_loss": 17.23799854516983, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.26247882843018, "training_acc": 52.0, "val_loss": 17.261630296707153, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26712012290955, "training_acc": 52.0, "val_loss": 17.25984215736389, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.30536222457886, "training_acc": 52.0, "val_loss": 17.235326766967773, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.24149942398071, "training_acc": 52.0, "val_loss": 17.237766087055206, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.23325777053833, "training_acc": 52.0, "val_loss": 17.249572277069092, "val_acc": 56.0}
