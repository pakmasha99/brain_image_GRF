"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 209.8574047088623, "training_acc": 43.0, "val_loss": 5174.190139770508, "val_acc": 52.0}
{"epoch": 1, "training_loss": 15125.282089710236, "training_acc": 41.0, "val_loss": 20.799972116947174, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1089.0320205688477, "training_acc": 47.0, "val_loss": 21.54395878314972, "val_acc": 48.0}
{"epoch": 3, "training_loss": 76.32622218132019, "training_acc": 47.0, "val_loss": 17.312759160995483, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.97828269004822, "training_acc": 53.0, "val_loss": 17.445288598537445, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.502774477005, "training_acc": 53.0, "val_loss": 17.542140185832977, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.73930740356445, "training_acc": 53.0, "val_loss": 17.64087677001953, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.43137454986572, "training_acc": 47.0, "val_loss": 17.309634387493134, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.3049533367157, "training_acc": 53.0, "val_loss": 17.369219660758972, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.45492672920227, "training_acc": 53.0, "val_loss": 17.306357622146606, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23946857452393, "training_acc": 53.0, "val_loss": 17.30673909187317, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15008020401001, "training_acc": 53.0, "val_loss": 17.32781231403351, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16550970077515, "training_acc": 53.0, "val_loss": 17.327962815761566, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.02765035629272, "training_acc": 53.0, "val_loss": 17.31044203042984, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.35073566436768, "training_acc": 53.0, "val_loss": 17.33141839504242, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2309923171997, "training_acc": 53.0, "val_loss": 17.318788170814514, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.10839462280273, "training_acc": 53.0, "val_loss": 17.307300865650177, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20443367958069, "training_acc": 53.0, "val_loss": 17.30709820985794, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17307496070862, "training_acc": 53.0, "val_loss": 17.30715185403824, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14553332328796, "training_acc": 53.0, "val_loss": 17.307880520820618, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13687825202942, "training_acc": 53.0, "val_loss": 17.310473322868347, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13209080696106, "training_acc": 53.0, "val_loss": 17.31600910425186, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17073774337769, "training_acc": 53.0, "val_loss": 17.331403493881226, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18038177490234, "training_acc": 53.0, "val_loss": 17.330461740493774, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.33965730667114, "training_acc": 53.0, "val_loss": 17.31637865304947, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14166188240051, "training_acc": 53.0, "val_loss": 17.31756180524826, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15053224563599, "training_acc": 53.0, "val_loss": 17.318660020828247, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16149306297302, "training_acc": 53.0, "val_loss": 17.321939766407013, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17791748046875, "training_acc": 53.0, "val_loss": 17.32008308172226, "val_acc": 52.0}
