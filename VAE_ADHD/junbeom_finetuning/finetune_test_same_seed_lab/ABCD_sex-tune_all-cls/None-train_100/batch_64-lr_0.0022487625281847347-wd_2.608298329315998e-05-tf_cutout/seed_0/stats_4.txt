"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 144.2819061279297, "training_acc": 49.0, "val_loss": 822.9097366333008, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2195.6489810943604, "training_acc": 55.0, "val_loss": 19.258594512939453, "val_acc": 48.0}
{"epoch": 2, "training_loss": 74.5077133178711, "training_acc": 49.0, "val_loss": 17.828866839408875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.24902009963989, "training_acc": 47.0, "val_loss": 17.577220499515533, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.27026438713074, "training_acc": 53.0, "val_loss": 18.3549165725708, "val_acc": 48.0}
{"epoch": 5, "training_loss": 72.22318744659424, "training_acc": 47.0, "val_loss": 17.31499880552292, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.06799411773682, "training_acc": 53.0, "val_loss": 17.436274886131287, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.17058682441711, "training_acc": 53.0, "val_loss": 17.45269000530243, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.39571118354797, "training_acc": 53.0, "val_loss": 17.31003373861313, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.56292271614075, "training_acc": 53.0, "val_loss": 17.31560081243515, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21701550483704, "training_acc": 53.0, "val_loss": 17.306743562221527, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14961743354797, "training_acc": 53.0, "val_loss": 17.313221096992493, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22402667999268, "training_acc": 53.0, "val_loss": 17.320598661899567, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16313529014587, "training_acc": 53.0, "val_loss": 17.30944812297821, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.24741530418396, "training_acc": 53.0, "val_loss": 17.30918288230896, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1659471988678, "training_acc": 53.0, "val_loss": 17.317576706409454, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15166139602661, "training_acc": 53.0, "val_loss": 17.318332195281982, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14291501045227, "training_acc": 53.0, "val_loss": 17.31298565864563, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13188982009888, "training_acc": 53.0, "val_loss": 17.31012761592865, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14724135398865, "training_acc": 53.0, "val_loss": 17.30921119451523, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13550615310669, "training_acc": 53.0, "val_loss": 17.312893271446228, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12546133995056, "training_acc": 53.0, "val_loss": 17.322927713394165, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.23978090286255, "training_acc": 53.0, "val_loss": 17.329005897045135, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18176293373108, "training_acc": 53.0, "val_loss": 17.314161360263824, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14973020553589, "training_acc": 53.0, "val_loss": 17.311744391918182, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13690948486328, "training_acc": 53.0, "val_loss": 17.31230914592743, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21639585494995, "training_acc": 53.0, "val_loss": 17.312636971473694, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24517369270325, "training_acc": 53.0, "val_loss": 17.321929335594177, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15290355682373, "training_acc": 53.0, "val_loss": 17.3176571726799, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12340092658997, "training_acc": 53.0, "val_loss": 17.311294376850128, "val_acc": 52.0}
