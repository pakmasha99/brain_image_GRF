"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 159.1558542251587, "training_acc": 49.0, "val_loss": 178.00582647323608, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1490.4458389282227, "training_acc": 53.0, "val_loss": 32.202985882759094, "val_acc": 52.0}
{"epoch": 2, "training_loss": 109.41407823562622, "training_acc": 53.0, "val_loss": 17.429114878177643, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.1126058101654, "training_acc": 49.0, "val_loss": 17.333947122097015, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.74238920211792, "training_acc": 47.0, "val_loss": 21.235446631908417, "val_acc": 52.0}
{"epoch": 5, "training_loss": 81.05742120742798, "training_acc": 47.0, "val_loss": 17.40904450416565, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.76313710212708, "training_acc": 45.0, "val_loss": 17.325305938720703, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2481632232666, "training_acc": 53.0, "val_loss": 17.34824925661087, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2055127620697, "training_acc": 53.0, "val_loss": 17.360135912895203, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.16662907600403, "training_acc": 43.0, "val_loss": 17.310015857219696, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.81256628036499, "training_acc": 53.0, "val_loss": 17.329898476600647, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.32635140419006, "training_acc": 53.0, "val_loss": 17.310817539691925, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17987179756165, "training_acc": 53.0, "val_loss": 17.30988472700119, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.46227979660034, "training_acc": 53.0, "val_loss": 17.309729754924774, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13122987747192, "training_acc": 53.0, "val_loss": 17.31172502040863, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20779728889465, "training_acc": 53.0, "val_loss": 17.314229905605316, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20534205436707, "training_acc": 53.0, "val_loss": 17.317089438438416, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.26234269142151, "training_acc": 53.0, "val_loss": 17.315471172332764, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22519040107727, "training_acc": 53.0, "val_loss": 17.31473058462143, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1964008808136, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14045071601868, "training_acc": 53.0, "val_loss": 17.312484979629517, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.215984582901, "training_acc": 53.0, "val_loss": 17.326124012470245, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15850949287415, "training_acc": 53.0, "val_loss": 17.32497364282608, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15723919868469, "training_acc": 53.0, "val_loss": 17.31848269701004, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13474607467651, "training_acc": 53.0, "val_loss": 17.312955856323242, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12718677520752, "training_acc": 53.0, "val_loss": 17.309600114822388, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.3349118232727, "training_acc": 53.0, "val_loss": 17.309103906154633, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13935923576355, "training_acc": 53.0, "val_loss": 17.31107532978058, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16451358795166, "training_acc": 53.0, "val_loss": 17.321307957172394, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.32892847061157, "training_acc": 53.0, "val_loss": 17.32375919818878, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.11762547492981, "training_acc": 53.0, "val_loss": 17.31273978948593, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20367240905762, "training_acc": 53.0, "val_loss": 17.308738827705383, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16095781326294, "training_acc": 53.0, "val_loss": 17.30874925851822, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14521074295044, "training_acc": 53.0, "val_loss": 17.31044352054596, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1328547000885, "training_acc": 53.0, "val_loss": 17.313949763774872, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20159077644348, "training_acc": 53.0, "val_loss": 17.322711646556854, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.28361105918884, "training_acc": 53.0, "val_loss": 17.317791283130646, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16748142242432, "training_acc": 53.0, "val_loss": 17.309191823005676, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14964032173157, "training_acc": 53.0, "val_loss": 17.309142649173737, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16819787025452, "training_acc": 53.0, "val_loss": 17.309319972991943, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16722583770752, "training_acc": 53.0, "val_loss": 17.309550940990448, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16548562049866, "training_acc": 53.0, "val_loss": 17.30932742357254, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13827729225159, "training_acc": 53.0, "val_loss": 17.310956120491028, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1383445262909, "training_acc": 53.0, "val_loss": 17.318202555179596, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.15982556343079, "training_acc": 53.0, "val_loss": 17.32570379972458, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17370533943176, "training_acc": 53.0, "val_loss": 17.322999238967896, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.21326875686646, "training_acc": 53.0, "val_loss": 17.313694953918457, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.1355128288269, "training_acc": 53.0, "val_loss": 17.313119769096375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.1331627368927, "training_acc": 53.0, "val_loss": 17.312057316303253, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.16292190551758, "training_acc": 53.0, "val_loss": 17.311453819274902, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13717651367188, "training_acc": 53.0, "val_loss": 17.313455045223236, "val_acc": 52.0}
