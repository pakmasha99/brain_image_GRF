"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 868.4106254577637, "training_acc": 47.0, "val_loss": 2.24279534764032e+16, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4.973652015161519e+16, "training_acc": 57.0, "val_loss": 192011.9384765625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1445826.765625, "training_acc": 43.0, "val_loss": 247332.03125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 744666.2973632812, "training_acc": 47.0, "val_loss": 8808.527374267578, "val_acc": 48.0}
{"epoch": 4, "training_loss": 33749.87438964844, "training_acc": 49.0, "val_loss": 28680.368041992188, "val_acc": 48.0}
{"epoch": 5, "training_loss": 72881.34814453125, "training_acc": 59.0, "val_loss": 107528.86962890625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 369579.998046875, "training_acc": 41.0, "val_loss": 855.6427001953125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 10545.5068359375, "training_acc": 49.0, "val_loss": 5545.367431640625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 16568.906799316406, "training_acc": 49.0, "val_loss": 20677.51922607422, "val_acc": 48.0}
{"epoch": 9, "training_loss": 52928.20933532715, "training_acc": 47.0, "val_loss": 17843.702697753906, "val_acc": 52.0}
{"epoch": 10, "training_loss": 53238.75378417969, "training_acc": 53.0, "val_loss": 539070.361328125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1425046.9130859375, "training_acc": 49.0, "val_loss": 348096.4599609375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1295393.359375, "training_acc": 47.0, "val_loss": 86662.02392578125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 401084.791015625, "training_acc": 53.0, "val_loss": 633492.529296875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1848583.74609375, "training_acc": 47.0, "val_loss": 99894.01245117188, "val_acc": 48.0}
{"epoch": 15, "training_loss": 539645.98828125, "training_acc": 55.0, "val_loss": 55716.680908203125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 399218.95703125, "training_acc": 53.0, "val_loss": 124282.275390625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 470911.1015625, "training_acc": 49.0, "val_loss": 12133418.75, "val_acc": 48.0}
{"epoch": 18, "training_loss": 27490929.182128906, "training_acc": 48.0, "val_loss": 308544.62890625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 980354.884765625, "training_acc": 53.0, "val_loss": 89654.88891601562, "val_acc": 52.0}
{"epoch": 20, "training_loss": 298029.2587890625, "training_acc": 47.0, "val_loss": 828336.328125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2226496.0, "training_acc": 53.0, "val_loss": 60531.097412109375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 160902.07069396973, "training_acc": 48.0, "val_loss": 1613.644027709961, "val_acc": 52.0}
{"epoch": 23, "training_loss": 39402.0576171875, "training_acc": 53.0, "val_loss": 18143.557739257812, "val_acc": 48.0}
{"epoch": 24, "training_loss": 53735.05078125, "training_acc": 47.0, "val_loss": 14766.319274902344, "val_acc": 52.0}
{"epoch": 25, "training_loss": 52681.89111328125, "training_acc": 53.0, "val_loss": 1961.305809020996, "val_acc": 52.0}
