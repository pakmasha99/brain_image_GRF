"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 818.812873840332, "training_acc": 47.0, "val_loss": 2.354680601300173e+19, "val_acc": 52.0}
{"epoch": 1, "training_loss": 6.40979215012041e+19, "training_acc": 45.0, "val_loss": 114187887.5, "val_acc": 48.0}
{"epoch": 2, "training_loss": 980303880.0, "training_acc": 47.0, "val_loss": 119450712.5, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3570523488.0, "training_acc": 49.0, "val_loss": 78221800.0, "val_acc": 48.0}
{"epoch": 4, "training_loss": 908275608.0, "training_acc": 41.0, "val_loss": 1300276700.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4803997008.0, "training_acc": 49.0, "val_loss": 35756846.875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 212164773.0, "training_acc": 49.0, "val_loss": 46693815.625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 135068151.625, "training_acc": 49.0, "val_loss": 7345920.3125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 628599206.0, "training_acc": 47.0, "val_loss": 1545065.72265625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 9116289.625, "training_acc": 47.0, "val_loss": 15770543.75, "val_acc": 48.0}
{"epoch": 10, "training_loss": 41129694.25, "training_acc": 49.0, "val_loss": 3219331.4453125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 14625299.75, "training_acc": 47.0, "val_loss": 23836167.1875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 73944872.125, "training_acc": 53.0, "val_loss": 13874075.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 41552061.15625, "training_acc": 47.0, "val_loss": 3985483.59375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 12913754.46875, "training_acc": 53.0, "val_loss": 5063376.5625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 32110852.5, "training_acc": 53.0, "val_loss": 4203292.96875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 14595513.9375, "training_acc": 47.0, "val_loss": 1421803.515625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 4304925.921875, "training_acc": 53.0, "val_loss": 40586912.5, "val_acc": 48.0}
{"epoch": 18, "training_loss": 114551760.0625, "training_acc": 47.0, "val_loss": 982164.35546875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 5053226.9375, "training_acc": 53.0, "val_loss": 3952010.9375, "val_acc": 48.0}
{"epoch": 20, "training_loss": 10453083.5, "training_acc": 59.0, "val_loss": 5619552.34375, "val_acc": 48.0}
{"epoch": 21, "training_loss": 17030446.65625, "training_acc": 51.0, "val_loss": 1318612.6953125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 5145619.90625, "training_acc": 51.0, "val_loss": 152323.2666015625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 22729913.625, "training_acc": 45.0, "val_loss": 689356.8359375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2280682.640625, "training_acc": 51.0, "val_loss": 709574.609375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2499200.5625, "training_acc": 47.0, "val_loss": 323055.7373046875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1247732.5, "training_acc": 53.0, "val_loss": 375616.748046875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1084053.33984375, "training_acc": 47.0, "val_loss": 436971.2890625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1676815.3359375, "training_acc": 53.0, "val_loss": 399399.2431640625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1055917.12890625, "training_acc": 53.0, "val_loss": 121770.78857421875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 702781.87890625, "training_acc": 45.0, "val_loss": 81756.71997070312, "val_acc": 52.0}
{"epoch": 31, "training_loss": 781922.3046875, "training_acc": 57.0, "val_loss": 482919.091796875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1475647.0390625, "training_acc": 47.0, "val_loss": 389680.37109375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1625654.140625, "training_acc": 53.0, "val_loss": 425246.630859375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1313546.4453125, "training_acc": 53.0, "val_loss": 171984.4970703125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 858067.06640625, "training_acc": 47.0, "val_loss": 217087.0849609375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 653303.9985351562, "training_acc": 38.0, "val_loss": 39884.100341796875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 129920.62548828125, "training_acc": 53.0, "val_loss": 16114.833068847656, "val_acc": 52.0}
{"epoch": 38, "training_loss": 106304.7509765625, "training_acc": 47.0, "val_loss": 14393.986511230469, "val_acc": 52.0}
{"epoch": 39, "training_loss": 92415.50537109375, "training_acc": 41.0, "val_loss": 35133.349609375, "val_acc": 52.0}
{"epoch": 40, "training_loss": 120200.22338867188, "training_acc": 53.0, "val_loss": 52983.355712890625, "val_acc": 48.0}
{"epoch": 41, "training_loss": 201949.2822265625, "training_acc": 47.0, "val_loss": 26461.953735351562, "val_acc": 52.0}
{"epoch": 42, "training_loss": 118005.54541015625, "training_acc": 53.0, "val_loss": 9205.632781982422, "val_acc": 48.0}
{"epoch": 43, "training_loss": 48811.274169921875, "training_acc": 43.0, "val_loss": 26951.18408203125, "val_acc": 48.0}
{"epoch": 44, "training_loss": 78908.65753173828, "training_acc": 44.0, "val_loss": 43932.73010253906, "val_acc": 52.0}
{"epoch": 45, "training_loss": 163882.0302734375, "training_acc": 53.0, "val_loss": 5494.160079956055, "val_acc": 48.0}
{"epoch": 46, "training_loss": 36263.640625, "training_acc": 49.0, "val_loss": 27027.886962890625, "val_acc": 52.0}
{"epoch": 47, "training_loss": 98578.24169921875, "training_acc": 53.0, "val_loss": 22734.68475341797, "val_acc": 48.0}
{"epoch": 48, "training_loss": 84322.44506835938, "training_acc": 47.0, "val_loss": 29819.43359375, "val_acc": 52.0}
{"epoch": 49, "training_loss": 116535.34326171875, "training_acc": 53.0, "val_loss": 2113.5175704956055, "val_acc": 48.0}
{"epoch": 50, "training_loss": 34131.418701171875, "training_acc": 43.0, "val_loss": 16714.378356933594, "val_acc": 52.0}
{"epoch": 51, "training_loss": 51864.74035644531, "training_acc": 53.0, "val_loss": 42073.37341308594, "val_acc": 48.0}
{"epoch": 52, "training_loss": 163719.89501953125, "training_acc": 47.0, "val_loss": 6892.2607421875, "val_acc": 52.0}
{"epoch": 53, "training_loss": 39552.16259765625, "training_acc": 53.0, "val_loss": 18607.86895751953, "val_acc": 48.0}
{"epoch": 54, "training_loss": 65783.27160644531, "training_acc": 46.0, "val_loss": 31211.85302734375, "val_acc": 52.0}
{"epoch": 55, "training_loss": 124469.767578125, "training_acc": 53.0, "val_loss": 7894.393157958984, "val_acc": 52.0}
{"epoch": 56, "training_loss": 88951.74853515625, "training_acc": 53.0, "val_loss": 67809.21630859375, "val_acc": 48.0}
{"epoch": 57, "training_loss": 241380.1484375, "training_acc": 47.0, "val_loss": 10857.48291015625, "val_acc": 52.0}
{"epoch": 58, "training_loss": 58456.71240234375, "training_acc": 53.0, "val_loss": 13291.975402832031, "val_acc": 52.0}
{"epoch": 59, "training_loss": 79561.814453125, "training_acc": 49.0, "val_loss": 31419.229125976562, "val_acc": 48.0}
{"epoch": 60, "training_loss": 84965.51498413086, "training_acc": 50.0, "val_loss": 24689.993286132812, "val_acc": 52.0}
{"epoch": 61, "training_loss": 87997.05981445312, "training_acc": 53.0, "val_loss": 17079.97283935547, "val_acc": 48.0}
{"epoch": 62, "training_loss": 65702.7080078125, "training_acc": 47.0, "val_loss": 18907.485961914062, "val_acc": 52.0}
{"epoch": 63, "training_loss": 76081.513671875, "training_acc": 53.0, "val_loss": 1670.8381652832031, "val_acc": 48.0}
{"epoch": 64, "training_loss": 15362.609619140625, "training_acc": 49.0, "val_loss": 19157.090759277344, "val_acc": 52.0}
{"epoch": 65, "training_loss": 66769.61010742188, "training_acc": 53.0, "val_loss": 17829.229736328125, "val_acc": 48.0}
{"epoch": 66, "training_loss": 69603.28881835938, "training_acc": 47.0, "val_loss": 12779.708099365234, "val_acc": 52.0}
{"epoch": 67, "training_loss": 46238.86181640625, "training_acc": 53.0, "val_loss": 18451.914978027344, "val_acc": 48.0}
{"epoch": 68, "training_loss": 67081.38647460938, "training_acc": 47.0, "val_loss": 17328.2470703125, "val_acc": 52.0}
{"epoch": 69, "training_loss": 68979.90942382812, "training_acc": 53.0, "val_loss": 348.30758571624756, "val_acc": 56.0}
{"epoch": 70, "training_loss": 37694.759033203125, "training_acc": 47.0, "val_loss": 986.8124008178711, "val_acc": 48.0}
{"epoch": 71, "training_loss": 68549.70068359375, "training_acc": 45.0, "val_loss": 45447.40905761719, "val_acc": 52.0}
{"epoch": 72, "training_loss": 150806.47509765625, "training_acc": 53.0, "val_loss": 10187.730407714844, "val_acc": 48.0}
{"epoch": 73, "training_loss": 57360.76171875, "training_acc": 47.0, "val_loss": 3783.8943481445312, "val_acc": 48.0}
{"epoch": 74, "training_loss": 50930.779296875, "training_acc": 53.0, "val_loss": 38925.982666015625, "val_acc": 52.0}
{"epoch": 75, "training_loss": 128922.0087890625, "training_acc": 53.0, "val_loss": 9852.615356445312, "val_acc": 48.0}
{"epoch": 76, "training_loss": 56247.506591796875, "training_acc": 47.0, "val_loss": 3807.628631591797, "val_acc": 52.0}
{"epoch": 77, "training_loss": 15943.589660644531, "training_acc": 53.0, "val_loss": 19504.457092285156, "val_acc": 48.0}
{"epoch": 78, "training_loss": 74288.71923828125, "training_acc": 47.0, "val_loss": 11640.760803222656, "val_acc": 52.0}
{"epoch": 79, "training_loss": 55680.27783203125, "training_acc": 53.0, "val_loss": 2540.8472061157227, "val_acc": 48.0}
{"epoch": 80, "training_loss": 12354.34896850586, "training_acc": 50.0, "val_loss": 1601.3187408447266, "val_acc": 48.0}
{"epoch": 81, "training_loss": 17631.175415039062, "training_acc": 48.0, "val_loss": 2755.3030014038086, "val_acc": 48.0}
{"epoch": 82, "training_loss": 14674.253784179688, "training_acc": 51.0, "val_loss": 6946.379852294922, "val_acc": 48.0}
{"epoch": 83, "training_loss": 31604.836303710938, "training_acc": 43.0, "val_loss": 4361.546325683594, "val_acc": 48.0}
{"epoch": 84, "training_loss": 16312.129821777344, "training_acc": 50.0, "val_loss": 8507.742309570312, "val_acc": 48.0}
{"epoch": 85, "training_loss": 29681.520629882812, "training_acc": 47.0, "val_loss": 4571.619033813477, "val_acc": 48.0}
{"epoch": 86, "training_loss": 33205.231201171875, "training_acc": 41.0, "val_loss": 237.77220249176025, "val_acc": 60.0}
{"epoch": 87, "training_loss": 7843.5146484375, "training_acc": 47.0, "val_loss": 12582.210540771484, "val_acc": 48.0}
{"epoch": 88, "training_loss": 40266.627197265625, "training_acc": 47.0, "val_loss": 23481.838989257812, "val_acc": 52.0}
{"epoch": 89, "training_loss": 100539.2333984375, "training_acc": 53.0, "val_loss": 18990.13214111328, "val_acc": 52.0}
{"epoch": 90, "training_loss": 71670.4931640625, "training_acc": 43.0, "val_loss": 14130.400085449219, "val_acc": 48.0}
{"epoch": 91, "training_loss": 44333.31066894531, "training_acc": 47.0, "val_loss": 3128.169822692871, "val_acc": 52.0}
{"epoch": 92, "training_loss": 36169.991455078125, "training_acc": 45.0, "val_loss": 10536.419677734375, "val_acc": 48.0}
{"epoch": 93, "training_loss": 38317.23107910156, "training_acc": 57.0, "val_loss": 19625.16632080078, "val_acc": 52.0}
{"epoch": 94, "training_loss": 61570.12390136719, "training_acc": 53.0, "val_loss": 19133.14666748047, "val_acc": 48.0}
{"epoch": 95, "training_loss": 88979.623046875, "training_acc": 47.0, "val_loss": 9834.442138671875, "val_acc": 48.0}
{"epoch": 96, "training_loss": 53239.823486328125, "training_acc": 52.0, "val_loss": 33586.02294921875, "val_acc": 52.0}
{"epoch": 97, "training_loss": 122383.11352539062, "training_acc": 53.0, "val_loss": 6949.01123046875, "val_acc": 52.0}
{"epoch": 98, "training_loss": 52021.4814453125, "training_acc": 55.0, "val_loss": 41878.98254394531, "val_acc": 48.0}
{"epoch": 99, "training_loss": 157903.6923828125, "training_acc": 47.0, "val_loss": 11680.085754394531, "val_acc": 48.0}
{"epoch": 100, "training_loss": 89190.33740234375, "training_acc": 37.0, "val_loss": 41909.20715332031, "val_acc": 52.0}
{"epoch": 101, "training_loss": 157408.39379882812, "training_acc": 53.0, "val_loss": 23505.76171875, "val_acc": 52.0}
{"epoch": 102, "training_loss": 71532.36053466797, "training_acc": 47.0, "val_loss": 14508.171081542969, "val_acc": 48.0}
{"epoch": 103, "training_loss": 45246.94354248047, "training_acc": 47.0, "val_loss": 11189.071655273438, "val_acc": 52.0}
{"epoch": 104, "training_loss": 43507.51037597656, "training_acc": 53.0, "val_loss": 3684.6664428710938, "val_acc": 52.0}
{"epoch": 105, "training_loss": 45379.040771484375, "training_acc": 42.0, "val_loss": 20403.550720214844, "val_acc": 48.0}
