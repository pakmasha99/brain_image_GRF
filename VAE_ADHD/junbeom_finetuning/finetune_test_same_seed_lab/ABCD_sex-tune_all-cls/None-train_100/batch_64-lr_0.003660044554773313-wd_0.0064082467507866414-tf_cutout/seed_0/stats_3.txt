"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 228.44243240356445, "training_acc": 51.0, "val_loss": 2670.836639404297, "val_acc": 48.0}
{"epoch": 1, "training_loss": 20345.145141601562, "training_acc": 45.0, "val_loss": 38.26310336589813, "val_acc": 52.0}
{"epoch": 2, "training_loss": 113.13897609710693, "training_acc": 53.0, "val_loss": 18.01845133304596, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73.14146971702576, "training_acc": 47.0, "val_loss": 17.310401797294617, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.77221989631653, "training_acc": 53.0, "val_loss": 17.724379897117615, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.42007541656494, "training_acc": 47.0, "val_loss": 17.94966459274292, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.80885434150696, "training_acc": 53.0, "val_loss": 17.44733452796936, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.29649615287781, "training_acc": 47.0, "val_loss": 17.42105484008789, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.57666230201721, "training_acc": 49.0, "val_loss": 17.358481884002686, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.37154078483582, "training_acc": 53.0, "val_loss": 17.70447939634323, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.92066693305969, "training_acc": 47.0, "val_loss": 17.402437329292297, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.00735425949097, "training_acc": 53.0, "val_loss": 17.345793545246124, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21518421173096, "training_acc": 53.0, "val_loss": 17.41088777780533, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.48611521720886, "training_acc": 53.0, "val_loss": 17.33924001455307, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.34067893028259, "training_acc": 53.0, "val_loss": 17.319005727767944, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18126249313354, "training_acc": 55.0, "val_loss": 17.417012155056, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.95703768730164, "training_acc": 47.0, "val_loss": 17.314521968364716, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.09472966194153, "training_acc": 53.0, "val_loss": 17.356061935424805, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.27052354812622, "training_acc": 53.0, "val_loss": 17.378444969654083, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.40608501434326, "training_acc": 53.0, "val_loss": 17.320506274700165, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25657987594604, "training_acc": 53.0, "val_loss": 17.316143214702606, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.33446431159973, "training_acc": 53.0, "val_loss": 17.308861017227173, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.29265642166138, "training_acc": 49.0, "val_loss": 17.336691915988922, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.33408641815186, "training_acc": 49.0, "val_loss": 17.31324940919876, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.309650182724, "training_acc": 53.0, "val_loss": 17.311793565750122, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14034080505371, "training_acc": 53.0, "val_loss": 17.31516420841217, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15124154090881, "training_acc": 53.0, "val_loss": 17.32393652200699, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14855289459229, "training_acc": 53.0, "val_loss": 17.346324026584625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.2150547504425, "training_acc": 53.0, "val_loss": 17.352212965488434, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.18642711639404, "training_acc": 53.0, "val_loss": 17.31981486082077, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10344171524048, "training_acc": 53.0, "val_loss": 17.308875918388367, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.36662602424622, "training_acc": 53.0, "val_loss": 17.313605546951294, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.22915387153625, "training_acc": 53.0, "val_loss": 17.309869825839996, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13706707954407, "training_acc": 53.0, "val_loss": 17.31458306312561, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17812013626099, "training_acc": 53.0, "val_loss": 17.31584519147873, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13663411140442, "training_acc": 53.0, "val_loss": 17.32819974422455, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16788935661316, "training_acc": 53.0, "val_loss": 17.330318689346313, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1639244556427, "training_acc": 53.0, "val_loss": 17.333336174488068, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.34323835372925, "training_acc": 53.0, "val_loss": 17.32635796070099, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.17615127563477, "training_acc": 53.0, "val_loss": 17.310021817684174, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.18129682540894, "training_acc": 53.0, "val_loss": 17.308878898620605, "val_acc": 52.0}
