"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 210.73875999450684, "training_acc": 50.0, "val_loss": 19396.85821533203, "val_acc": 56.0}
{"epoch": 1, "training_loss": 58022.55487060547, "training_acc": 52.0, "val_loss": 262.59288787841797, "val_acc": 44.0}
{"epoch": 2, "training_loss": 718.1710319519043, "training_acc": 48.0, "val_loss": 17.657458782196045, "val_acc": 56.0}
{"epoch": 3, "training_loss": 71.67983651161194, "training_acc": 46.0, "val_loss": 17.245881259441376, "val_acc": 56.0}
{"epoch": 4, "training_loss": 71.67367506027222, "training_acc": 50.0, "val_loss": 17.645782232284546, "val_acc": 56.0}
{"epoch": 5, "training_loss": 73.56399321556091, "training_acc": 52.0, "val_loss": 17.39935576915741, "val_acc": 56.0}
{"epoch": 6, "training_loss": 70.39513278007507, "training_acc": 48.0, "val_loss": 17.716360092163086, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.42108464241028, "training_acc": 52.0, "val_loss": 17.52278059720993, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.72497916221619, "training_acc": 52.0, "val_loss": 17.887558043003082, "val_acc": 56.0}
{"epoch": 9, "training_loss": 70.69973731040955, "training_acc": 48.0, "val_loss": 17.790275812149048, "val_acc": 56.0}
{"epoch": 10, "training_loss": 70.03768277168274, "training_acc": 48.0, "val_loss": 17.29568839073181, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.36085557937622, "training_acc": 52.0, "val_loss": 17.16298609972, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.4801971912384, "training_acc": 52.0, "val_loss": 17.197509109973907, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.49044752120972, "training_acc": 48.0, "val_loss": 17.329666018486023, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25906109809875, "training_acc": 49.0, "val_loss": 17.179690301418304, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2875669002533, "training_acc": 52.0, "val_loss": 17.15388298034668, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.49226880073547, "training_acc": 52.0, "val_loss": 17.170074582099915, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.304860830307, "training_acc": 52.0, "val_loss": 17.269442975521088, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.27820658683777, "training_acc": 52.0, "val_loss": 17.288970947265625, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.28489804267883, "training_acc": 52.0, "val_loss": 17.23053753376007, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.25323104858398, "training_acc": 52.0, "val_loss": 17.222881317138672, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26920700073242, "training_acc": 52.0, "val_loss": 17.202457785606384, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.41523766517639, "training_acc": 52.0, "val_loss": 17.18374341726303, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.23070120811462, "training_acc": 52.0, "val_loss": 17.230457067489624, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.20700669288635, "training_acc": 52.0, "val_loss": 17.282240092754364, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.3145592212677, "training_acc": 52.0, "val_loss": 17.326995730400085, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.51630806922913, "training_acc": 52.0, "val_loss": 17.296336591243744, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.27281498908997, "training_acc": 52.0, "val_loss": 17.31984317302704, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.34215950965881, "training_acc": 46.0, "val_loss": 17.319750785827637, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.27790546417236, "training_acc": 52.0, "val_loss": 17.274150252342224, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.44163060188293, "training_acc": 52.0, "val_loss": 17.22628027200699, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29572749137878, "training_acc": 52.0, "val_loss": 17.22860336303711, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23957061767578, "training_acc": 52.0, "val_loss": 17.210163176059723, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.23721647262573, "training_acc": 52.0, "val_loss": 17.204242944717407, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26593470573425, "training_acc": 52.0, "val_loss": 17.199058830738068, "val_acc": 56.0}
