"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 110.98256015777588, "training_acc": 53.0, "val_loss": 102551.15966796875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 224447.24744606018, "training_acc": 47.0, "val_loss": 772.2215175628662, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1859.6747455596924, "training_acc": 53.0, "val_loss": 18.024447560310364, "val_acc": 52.0}
{"epoch": 3, "training_loss": 83.45474481582642, "training_acc": 51.0, "val_loss": 17.328602075576782, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.45814490318298, "training_acc": 53.0, "val_loss": 23.58250319957733, "val_acc": 52.0}
{"epoch": 5, "training_loss": 84.23950719833374, "training_acc": 51.0, "val_loss": 18.172556161880493, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.7786135673523, "training_acc": 49.0, "val_loss": 17.67571270465851, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.08805131912231, "training_acc": 53.0, "val_loss": 18.703658878803253, "val_acc": 48.0}
{"epoch": 8, "training_loss": 72.36921977996826, "training_acc": 51.0, "val_loss": 18.622638285160065, "val_acc": 52.0}
{"epoch": 9, "training_loss": 73.84156107902527, "training_acc": 53.0, "val_loss": 17.310546338558197, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.44312596321106, "training_acc": 53.0, "val_loss": 17.309218645095825, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15309119224548, "training_acc": 53.0, "val_loss": 17.32902228832245, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.28187561035156, "training_acc": 52.0, "val_loss": 17.316654324531555, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19957399368286, "training_acc": 53.0, "val_loss": 17.33776479959488, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.3091881275177, "training_acc": 53.0, "val_loss": 17.312230169773102, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15535616874695, "training_acc": 53.0, "val_loss": 17.450080811977386, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.58026885986328, "training_acc": 53.0, "val_loss": 17.308036983013153, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.69144344329834, "training_acc": 53.0, "val_loss": 17.31446087360382, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.37813425064087, "training_acc": 49.0, "val_loss": 17.313602566719055, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10284328460693, "training_acc": 53.0, "val_loss": 17.438240349292755, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.42214512825012, "training_acc": 53.0, "val_loss": 17.310993373394012, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.61227369308472, "training_acc": 43.0, "val_loss": 17.309367656707764, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.04312539100647, "training_acc": 53.0, "val_loss": 17.334194481372833, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11104798316956, "training_acc": 53.0, "val_loss": 17.32437163591385, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.34140801429749, "training_acc": 53.0, "val_loss": 17.323677241802216, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.6846432685852, "training_acc": 53.0, "val_loss": 17.31324940919876, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.32015180587769, "training_acc": 49.0, "val_loss": 17.32850670814514, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.27831363677979, "training_acc": 52.0, "val_loss": 17.3098087310791, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.0218677520752, "training_acc": 53.0, "val_loss": 17.31259822845459, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12335991859436, "training_acc": 53.0, "val_loss": 17.312492430210114, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.25347661972046, "training_acc": 53.0, "val_loss": 17.311756312847137, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.23714923858643, "training_acc": 53.0, "val_loss": 17.313309013843536, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.3634762763977, "training_acc": 53.0, "val_loss": 17.31172502040863, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.0985221862793, "training_acc": 53.0, "val_loss": 17.347028851509094, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.51131510734558, "training_acc": 53.0, "val_loss": 17.373767495155334, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.19614911079407, "training_acc": 53.0, "val_loss": 17.318016290664673, "val_acc": 52.0}
