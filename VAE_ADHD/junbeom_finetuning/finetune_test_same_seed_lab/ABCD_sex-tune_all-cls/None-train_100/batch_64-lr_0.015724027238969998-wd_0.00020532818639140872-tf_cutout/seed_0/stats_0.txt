"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 976.5207977294922, "training_acc": 50.0, "val_loss": 1.13818990542848e+16, "val_acc": 56.0}
{"epoch": 1, "training_loss": 3.025214331950291e+16, "training_acc": 52.0, "val_loss": 38518312.5, "val_acc": 56.0}
{"epoch": 2, "training_loss": 1398596016.0, "training_acc": 54.0, "val_loss": 244301650.0, "val_acc": 44.0}
{"epoch": 3, "training_loss": 643109408.75, "training_acc": 48.0, "val_loss": 7639526.5625, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1077042820.0, "training_acc": 50.0, "val_loss": 35970021.875, "val_acc": 44.0}
{"epoch": 5, "training_loss": 9255655520.0, "training_acc": 48.0, "val_loss": 8302478.90625, "val_acc": 56.0}
{"epoch": 6, "training_loss": 24762593.578125, "training_acc": 50.0, "val_loss": 27833331.25, "val_acc": 56.0}
{"epoch": 7, "training_loss": 88779557.75, "training_acc": 52.0, "val_loss": 8282990400.0, "val_acc": 44.0}
{"epoch": 8, "training_loss": 22048677280.0, "training_acc": 42.0, "val_loss": 381344175.0, "val_acc": 44.0}
{"epoch": 9, "training_loss": 14660416128.0, "training_acc": 48.0, "val_loss": 361585525.0, "val_acc": 56.0}
{"epoch": 10, "training_loss": 1087643731.0, "training_acc": 52.0, "val_loss": 1509805.17578125, "val_acc": 56.0}
{"epoch": 11, "training_loss": 32857489.25, "training_acc": 52.0, "val_loss": 7579744.53125, "val_acc": 56.0}
{"epoch": 12, "training_loss": 1825827096.0, "training_acc": 54.0, "val_loss": 1130742500.0, "val_acc": 56.0}
{"epoch": 13, "training_loss": 3318072898.0, "training_acc": 48.0, "val_loss": 10353117.96875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 621595024.0, "training_acc": 52.0, "val_loss": 824714350.0, "val_acc": 44.0}
{"epoch": 15, "training_loss": 1815579255.875, "training_acc": 48.0, "val_loss": 8847042.1875, "val_acc": 56.0}
{"epoch": 16, "training_loss": 75568606.0, "training_acc": 52.0, "val_loss": 25786964.0625, "val_acc": 56.0}
{"epoch": 17, "training_loss": 330691858.0, "training_acc": 52.0, "val_loss": 17720039.0625, "val_acc": 44.0}
{"epoch": 18, "training_loss": 78907094.5, "training_acc": 48.0, "val_loss": 9585496.875, "val_acc": 44.0}
{"epoch": 19, "training_loss": 26925625.5625, "training_acc": 48.0, "val_loss": 3439439.0625, "val_acc": 44.0}
{"epoch": 20, "training_loss": 11433007.5625, "training_acc": 48.0, "val_loss": 487407.8125, "val_acc": 44.0}
{"epoch": 21, "training_loss": 2947939.625, "training_acc": 54.0, "val_loss": 740938.818359375, "val_acc": 44.0}
{"epoch": 22, "training_loss": 5039603.03125, "training_acc": 44.0, "val_loss": 494827.5390625, "val_acc": 56.0}
{"epoch": 23, "training_loss": 4750048.78125, "training_acc": 54.0, "val_loss": 2567771.484375, "val_acc": 44.0}
{"epoch": 24, "training_loss": 7425689.4765625, "training_acc": 48.0, "val_loss": 657875.341796875, "val_acc": 56.0}
{"epoch": 25, "training_loss": 2098676.509765625, "training_acc": 52.0, "val_loss": 1090317.1875, "val_acc": 44.0}
{"epoch": 26, "training_loss": 3398464.26953125, "training_acc": 48.0, "val_loss": 233619.189453125, "val_acc": 56.0}
{"epoch": 27, "training_loss": 801093.646484375, "training_acc": 52.0, "val_loss": 131282.8125, "val_acc": 44.0}
{"epoch": 28, "training_loss": 410700.828125, "training_acc": 48.0, "val_loss": 40514.54162597656, "val_acc": 56.0}
{"epoch": 29, "training_loss": 139489.16821289062, "training_acc": 52.0, "val_loss": 75818.19458007812, "val_acc": 44.0}
{"epoch": 30, "training_loss": 233063.58203125, "training_acc": 48.0, "val_loss": 17416.91436767578, "val_acc": 56.0}
{"epoch": 31, "training_loss": 67310.76013183594, "training_acc": 52.0, "val_loss": 2652.468681335449, "val_acc": 44.0}
{"epoch": 32, "training_loss": 9977.621154785156, "training_acc": 48.0, "val_loss": 3371.3367462158203, "val_acc": 56.0}
{"epoch": 33, "training_loss": 10932.679595947266, "training_acc": 52.0, "val_loss": 161.3935947418213, "val_acc": 40.0}
{"epoch": 34, "training_loss": 1756.8241271972656, "training_acc": 40.0, "val_loss": 2669.634437561035, "val_acc": 44.0}
{"epoch": 35, "training_loss": 6767.004188537598, "training_acc": 49.0, "val_loss": 1656.8992614746094, "val_acc": 44.0}
{"epoch": 36, "training_loss": 4105.24821472168, "training_acc": 55.0, "val_loss": 360.2506399154663, "val_acc": 56.0}
{"epoch": 37, "training_loss": 3888.3104553222656, "training_acc": 44.0, "val_loss": 823.979663848877, "val_acc": 44.0}
{"epoch": 38, "training_loss": 2592.16414642334, "training_acc": 56.0, "val_loss": 4095.258331298828, "val_acc": 44.0}
{"epoch": 39, "training_loss": 14058.970672607422, "training_acc": 44.0, "val_loss": 1186.9525909423828, "val_acc": 56.0}
{"epoch": 40, "training_loss": 6773.739349365234, "training_acc": 50.0, "val_loss": 804.6022415161133, "val_acc": 44.0}
{"epoch": 41, "training_loss": 9650.910278320312, "training_acc": 53.0, "val_loss": 4028.420639038086, "val_acc": 56.0}
{"epoch": 42, "training_loss": 11911.856018066406, "training_acc": 56.0, "val_loss": 2256.1357498168945, "val_acc": 44.0}
{"epoch": 43, "training_loss": 11241.322570800781, "training_acc": 40.0, "val_loss": 1151.7474174499512, "val_acc": 56.0}
{"epoch": 44, "training_loss": 8870.640686035156, "training_acc": 48.0, "val_loss": 4118.201065063477, "val_acc": 44.0}
{"epoch": 45, "training_loss": 11099.838279724121, "training_acc": 48.0, "val_loss": 3623.0464935302734, "val_acc": 56.0}
{"epoch": 46, "training_loss": 17855.4609375, "training_acc": 52.0, "val_loss": 3175.3734588623047, "val_acc": 56.0}
{"epoch": 47, "training_loss": 9747.268463134766, "training_acc": 51.0, "val_loss": 2706.8824768066406, "val_acc": 44.0}
{"epoch": 48, "training_loss": 10219.564697265625, "training_acc": 48.0, "val_loss": 1614.8714065551758, "val_acc": 44.0}
{"epoch": 49, "training_loss": 6054.857681274414, "training_acc": 44.0, "val_loss": 1720.9333419799805, "val_acc": 56.0}
{"epoch": 50, "training_loss": 6451.87614440918, "training_acc": 52.0, "val_loss": 724.7026443481445, "val_acc": 44.0}
{"epoch": 51, "training_loss": 2988.5079040527344, "training_acc": 49.0, "val_loss": 331.0438871383667, "val_acc": 44.0}
{"epoch": 52, "training_loss": 3115.3629455566406, "training_acc": 46.0, "val_loss": 1748.526382446289, "val_acc": 56.0}
{"epoch": 53, "training_loss": 6750.900390625, "training_acc": 52.0, "val_loss": 45.59239745140076, "val_acc": 64.0}
{"epoch": 54, "training_loss": 3085.10009765625, "training_acc": 46.0, "val_loss": 2404.018211364746, "val_acc": 44.0}
{"epoch": 55, "training_loss": 8074.911148071289, "training_acc": 48.0, "val_loss": 719.146203994751, "val_acc": 44.0}
{"epoch": 56, "training_loss": 3534.9593048095703, "training_acc": 46.0, "val_loss": 1726.910400390625, "val_acc": 56.0}
{"epoch": 57, "training_loss": 7549.395263671875, "training_acc": 52.0, "val_loss": 969.867992401123, "val_acc": 56.0}
{"epoch": 58, "training_loss": 2924.901657104492, "training_acc": 53.0, "val_loss": 908.0557823181152, "val_acc": 44.0}
{"epoch": 59, "training_loss": 3132.033676147461, "training_acc": 48.0, "val_loss": 196.80962562561035, "val_acc": 56.0}
{"epoch": 60, "training_loss": 1356.2918319702148, "training_acc": 53.0, "val_loss": 201.3094425201416, "val_acc": 56.0}
{"epoch": 61, "training_loss": 1390.7249603271484, "training_acc": 53.0, "val_loss": 714.2311096191406, "val_acc": 44.0}
{"epoch": 62, "training_loss": 1573.4579944610596, "training_acc": 53.0, "val_loss": 746.6294765472412, "val_acc": 56.0}
{"epoch": 63, "training_loss": 3292.958526611328, "training_acc": 52.0, "val_loss": 574.1780757904053, "val_acc": 56.0}
{"epoch": 64, "training_loss": 1903.9117050170898, "training_acc": 50.0, "val_loss": 502.91152000427246, "val_acc": 44.0}
{"epoch": 65, "training_loss": 1301.3976154327393, "training_acc": 53.0, "val_loss": 469.65203285217285, "val_acc": 56.0}
{"epoch": 66, "training_loss": 1825.714958190918, "training_acc": 53.0, "val_loss": 64.23574686050415, "val_acc": 56.0}
{"epoch": 67, "training_loss": 904.9548110961914, "training_acc": 61.0, "val_loss": 639.1619682312012, "val_acc": 44.0}
{"epoch": 68, "training_loss": 1706.7810039520264, "training_acc": 47.0, "val_loss": 388.77739906311035, "val_acc": 56.0}
{"epoch": 69, "training_loss": 1581.7125854492188, "training_acc": 52.0, "val_loss": 270.74267864227295, "val_acc": 44.0}
{"epoch": 70, "training_loss": 1257.7562217712402, "training_acc": 47.0, "val_loss": 114.32584524154663, "val_acc": 56.0}
{"epoch": 71, "training_loss": 750.5187606811523, "training_acc": 56.0, "val_loss": 262.795352935791, "val_acc": 44.0}
{"epoch": 72, "training_loss": 959.2610149383545, "training_acc": 54.0, "val_loss": 163.66757154464722, "val_acc": 56.0}
