"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.37562298774719, "training_acc": 42.0, "val_loss": 17.398306727409363, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.04312086105347, "training_acc": 53.0, "val_loss": 17.473992705345154, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.73797059059143, "training_acc": 47.0, "val_loss": 17.39441007375717, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.29358649253845, "training_acc": 53.0, "val_loss": 17.502185702323914, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.37720990180969, "training_acc": 53.0, "val_loss": 17.327535152435303, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1087281703949, "training_acc": 53.0, "val_loss": 17.336684465408325, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.48402857780457, "training_acc": 53.0, "val_loss": 17.338715493679047, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.56559944152832, "training_acc": 53.0, "val_loss": 17.31179803609848, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12020349502563, "training_acc": 53.0, "val_loss": 17.31330007314682, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11792397499084, "training_acc": 53.0, "val_loss": 17.32080429792404, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17174458503723, "training_acc": 53.0, "val_loss": 17.332294583320618, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.11898589134216, "training_acc": 53.0, "val_loss": 17.320463061332703, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.06570100784302, "training_acc": 53.0, "val_loss": 17.317557334899902, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.07952547073364, "training_acc": 53.0, "val_loss": 17.319612205028534, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11583471298218, "training_acc": 53.0, "val_loss": 17.31954962015152, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.09515762329102, "training_acc": 53.0, "val_loss": 17.328861355781555, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06571173667908, "training_acc": 53.0, "val_loss": 17.346961796283722, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11611366271973, "training_acc": 53.0, "val_loss": 17.340850830078125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.06017279624939, "training_acc": 53.0, "val_loss": 17.322316765785217, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.07069325447083, "training_acc": 53.0, "val_loss": 17.320722341537476, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11554837226868, "training_acc": 53.0, "val_loss": 17.32008457183838, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.01832318305969, "training_acc": 53.0, "val_loss": 17.329876124858856, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14513373374939, "training_acc": 53.0, "val_loss": 17.347948253154755, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14064073562622, "training_acc": 53.0, "val_loss": 17.396743595600128, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16759324073792, "training_acc": 53.0, "val_loss": 17.50340610742569, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.6222722530365, "training_acc": 53.0, "val_loss": 17.465336620807648, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.55916261672974, "training_acc": 53.0, "val_loss": 17.344458401203156, "val_acc": 52.0}
