"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.21967005729675, "training_acc": 53.0, "val_loss": 17.313361167907715, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.63761448860168, "training_acc": 53.0, "val_loss": 17.46097207069397, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.3496766090393, "training_acc": 47.0, "val_loss": 17.50524491071701, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.00924301147461, "training_acc": 47.0, "val_loss": 17.339913547039032, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20283150672913, "training_acc": 53.0, "val_loss": 17.392924427986145, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.51113200187683, "training_acc": 53.0, "val_loss": 17.32598841190338, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.25564622879028, "training_acc": 53.0, "val_loss": 17.31102764606476, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17527627944946, "training_acc": 53.0, "val_loss": 17.312602698802948, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10536456108093, "training_acc": 53.0, "val_loss": 17.303620278835297, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13765835762024, "training_acc": 53.0, "val_loss": 17.305198311805725, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.52029800415039, "training_acc": 44.0, "val_loss": 17.310966551303864, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24173069000244, "training_acc": 53.0, "val_loss": 17.31165647506714, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.97580671310425, "training_acc": 53.0, "val_loss": 17.428763210773468, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.38999795913696, "training_acc": 53.0, "val_loss": 17.49543398618698, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.56434488296509, "training_acc": 53.0, "val_loss": 17.426379024982452, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.40675854682922, "training_acc": 53.0, "val_loss": 17.335383594036102, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21200180053711, "training_acc": 53.0, "val_loss": 17.308427393436432, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1577045917511, "training_acc": 53.0, "val_loss": 17.30695813894272, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15053987503052, "training_acc": 53.0, "val_loss": 17.307528853416443, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.077632188797, "training_acc": 53.0, "val_loss": 17.31083244085312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.08178424835205, "training_acc": 53.0, "val_loss": 17.31664687395096, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16818356513977, "training_acc": 53.0, "val_loss": 17.32683926820755, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.3659439086914, "training_acc": 53.0, "val_loss": 17.35161542892456, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22475171089172, "training_acc": 53.0, "val_loss": 17.33153909444809, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13579106330872, "training_acc": 53.0, "val_loss": 17.320728302001953, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1678581237793, "training_acc": 53.0, "val_loss": 17.31591820716858, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.02382183074951, "training_acc": 53.0, "val_loss": 17.317691445350647, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11448240280151, "training_acc": 53.0, "val_loss": 17.328311502933502, "val_acc": 52.0}
