"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.52917528152466, "training_acc": 53.0, "val_loss": 17.312751710414886, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.36902856826782, "training_acc": 53.0, "val_loss": 17.517997324466705, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.03975796699524, "training_acc": 47.0, "val_loss": 17.313119769096375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10226917266846, "training_acc": 53.0, "val_loss": 17.70741194486618, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.31620526313782, "training_acc": 53.0, "val_loss": 17.4040749669075, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10249972343445, "training_acc": 53.0, "val_loss": 17.31165498495102, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.089111328125, "training_acc": 41.0, "val_loss": 17.38785356283188, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.43244552612305, "training_acc": 47.0, "val_loss": 17.307399213314056, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.0244288444519, "training_acc": 53.0, "val_loss": 17.31516867876053, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.04452466964722, "training_acc": 53.0, "val_loss": 17.41010695695877, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.44570589065552, "training_acc": 53.0, "val_loss": 17.460952699184418, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.70239996910095, "training_acc": 53.0, "val_loss": 17.399583756923676, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.34381937980652, "training_acc": 53.0, "val_loss": 17.31160283088684, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.03014421463013, "training_acc": 53.0, "val_loss": 17.306242883205414, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.28928351402283, "training_acc": 53.0, "val_loss": 17.331576347351074, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.3325502872467, "training_acc": 44.0, "val_loss": 17.32461452484131, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26569628715515, "training_acc": 53.0, "val_loss": 17.304320633411407, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15407991409302, "training_acc": 53.0, "val_loss": 17.306919395923615, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22549605369568, "training_acc": 53.0, "val_loss": 17.31678396463394, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.34558939933777, "training_acc": 53.0, "val_loss": 17.355498671531677, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.34607172012329, "training_acc": 53.0, "val_loss": 17.352594435214996, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16821956634521, "training_acc": 53.0, "val_loss": 17.317451536655426, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22111201286316, "training_acc": 53.0, "val_loss": 17.30506420135498, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10641098022461, "training_acc": 53.0, "val_loss": 17.307662963867188, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1593062877655, "training_acc": 53.0, "val_loss": 17.310479283332825, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1599051952362, "training_acc": 53.0, "val_loss": 17.31119155883789, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14257073402405, "training_acc": 53.0, "val_loss": 17.310798168182373, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1278612613678, "training_acc": 53.0, "val_loss": 17.315633594989777, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.10400414466858, "training_acc": 53.0, "val_loss": 17.322520911693573, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19059300422668, "training_acc": 53.0, "val_loss": 17.32342541217804, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10256934165955, "training_acc": 53.0, "val_loss": 17.333610355854034, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12019729614258, "training_acc": 53.0, "val_loss": 17.341767251491547, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15988492965698, "training_acc": 53.0, "val_loss": 17.347468435764313, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.16105008125305, "training_acc": 53.0, "val_loss": 17.337757349014282, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.10589003562927, "training_acc": 53.0, "val_loss": 17.320354282855988, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.07584428787231, "training_acc": 53.0, "val_loss": 17.311526834964752, "val_acc": 52.0}
