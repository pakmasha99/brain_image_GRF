"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.78754377365112, "training_acc": 53.0, "val_loss": 18.138262629508972, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.78880310058594, "training_acc": 53.0, "val_loss": 19.060558080673218, "val_acc": 48.0}
{"epoch": 2, "training_loss": 75.03236365318298, "training_acc": 47.0, "val_loss": 17.384742200374603, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.4427273273468, "training_acc": 43.0, "val_loss": 17.484909296035767, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.74020290374756, "training_acc": 53.0, "val_loss": 17.43118017911911, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.7690782546997, "training_acc": 53.0, "val_loss": 17.325061559677124, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.20166826248169, "training_acc": 53.0, "val_loss": 17.31388121843338, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29544949531555, "training_acc": 53.0, "val_loss": 17.315980792045593, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29649567604065, "training_acc": 53.0, "val_loss": 17.310042679309845, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15165567398071, "training_acc": 53.0, "val_loss": 17.310655117034912, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13240885734558, "training_acc": 53.0, "val_loss": 17.313438653945923, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13765382766724, "training_acc": 53.0, "val_loss": 17.32085794210434, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13250708580017, "training_acc": 53.0, "val_loss": 17.34178513288498, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15534257888794, "training_acc": 53.0, "val_loss": 17.357738316059113, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.26542401313782, "training_acc": 53.0, "val_loss": 17.361198365688324, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1699059009552, "training_acc": 53.0, "val_loss": 17.336949706077576, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15878510475159, "training_acc": 53.0, "val_loss": 17.316383123397827, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15832996368408, "training_acc": 53.0, "val_loss": 17.30811595916748, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10730838775635, "training_acc": 53.0, "val_loss": 17.30823814868927, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.07998776435852, "training_acc": 53.0, "val_loss": 17.311954498291016, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.08847165107727, "training_acc": 53.0, "val_loss": 17.31604039669037, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08745455741882, "training_acc": 53.0, "val_loss": 17.322365939617157, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.09713816642761, "training_acc": 53.0, "val_loss": 17.32405424118042, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.06187391281128, "training_acc": 53.0, "val_loss": 17.321914434432983, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.06689500808716, "training_acc": 53.0, "val_loss": 17.322784662246704, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16455936431885, "training_acc": 53.0, "val_loss": 17.325274646282196, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.9877679347992, "training_acc": 53.0, "val_loss": 17.31647402048111, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.09707021713257, "training_acc": 53.0, "val_loss": 17.31395721435547, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.10004472732544, "training_acc": 53.0, "val_loss": 17.312468588352203, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.08917593955994, "training_acc": 53.0, "val_loss": 17.31235831975937, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.04860043525696, "training_acc": 53.0, "val_loss": 17.31415092945099, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12261033058167, "training_acc": 53.0, "val_loss": 17.31116473674774, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.01517486572266, "training_acc": 53.0, "val_loss": 17.312495410442352, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.98049139976501, "training_acc": 53.0, "val_loss": 17.33122020959854, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.05708050727844, "training_acc": 53.0, "val_loss": 17.37673729658127, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20692801475525, "training_acc": 53.0, "val_loss": 17.389842867851257, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13588261604309, "training_acc": 53.0, "val_loss": 17.350028455257416, "val_acc": 52.0}
