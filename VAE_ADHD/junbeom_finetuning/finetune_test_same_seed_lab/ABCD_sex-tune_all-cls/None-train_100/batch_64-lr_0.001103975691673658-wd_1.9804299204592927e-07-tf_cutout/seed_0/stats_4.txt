"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 125.83950424194336, "training_acc": 45.0, "val_loss": 57.31978416442871, "val_acc": 52.0}
{"epoch": 1, "training_loss": 285.89165210723877, "training_acc": 49.0, "val_loss": 18.2473286986351, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.04508090019226, "training_acc": 47.0, "val_loss": 17.326827347278595, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26095700263977, "training_acc": 53.0, "val_loss": 17.427264153957367, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.49403071403503, "training_acc": 53.0, "val_loss": 17.3064187169075, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.41958522796631, "training_acc": 49.0, "val_loss": 17.791709303855896, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.13025307655334, "training_acc": 53.0, "val_loss": 17.343473434448242, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.87573552131653, "training_acc": 47.0, "val_loss": 17.589911818504333, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.25038504600525, "training_acc": 47.0, "val_loss": 17.35409051179886, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.50845336914062, "training_acc": 45.0, "val_loss": 17.306460440158844, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28078055381775, "training_acc": 53.0, "val_loss": 17.30213463306427, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15459442138672, "training_acc": 53.0, "val_loss": 17.301826179027557, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1532826423645, "training_acc": 53.0, "val_loss": 17.30250120162964, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1651771068573, "training_acc": 53.0, "val_loss": 17.304177582263947, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15417122840881, "training_acc": 53.0, "val_loss": 17.310988903045654, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.146240234375, "training_acc": 53.0, "val_loss": 17.33567714691162, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26218128204346, "training_acc": 53.0, "val_loss": 17.346903681755066, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21218299865723, "training_acc": 53.0, "val_loss": 17.32473522424698, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1579258441925, "training_acc": 53.0, "val_loss": 17.30670928955078, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19765019416809, "training_acc": 53.0, "val_loss": 17.304566502571106, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1648907661438, "training_acc": 53.0, "val_loss": 17.30530560016632, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17411756515503, "training_acc": 53.0, "val_loss": 17.306098341941833, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24158787727356, "training_acc": 53.0, "val_loss": 17.305922508239746, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.23011708259583, "training_acc": 53.0, "val_loss": 17.305171489715576, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14656472206116, "training_acc": 53.0, "val_loss": 17.306533455848694, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15590834617615, "training_acc": 53.0, "val_loss": 17.308105528354645, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13774037361145, "training_acc": 53.0, "val_loss": 17.3135906457901, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13962936401367, "training_acc": 53.0, "val_loss": 17.319244146347046, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16529250144958, "training_acc": 53.0, "val_loss": 17.322908341884613, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15423464775085, "training_acc": 53.0, "val_loss": 17.319461703300476, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16964316368103, "training_acc": 53.0, "val_loss": 17.316418886184692, "val_acc": 52.0}
