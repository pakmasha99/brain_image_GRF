"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 92.30678844451904, "training_acc": 49.0, "val_loss": 93.7134325504303, "val_acc": 52.0}
{"epoch": 1, "training_loss": 285.00397634506226, "training_acc": 49.0, "val_loss": 17.355652153491974, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.4452793598175, "training_acc": 49.0, "val_loss": 17.48863309621811, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14914155006409, "training_acc": 53.0, "val_loss": 20.732417702674866, "val_acc": 48.0}
{"epoch": 4, "training_loss": 72.63602447509766, "training_acc": 59.0, "val_loss": 18.43804568052292, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.63290882110596, "training_acc": 53.0, "val_loss": 17.54230409860611, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.21926951408386, "training_acc": 53.0, "val_loss": 17.364974319934845, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.325923204422, "training_acc": 53.0, "val_loss": 17.34054535627365, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21288871765137, "training_acc": 53.0, "val_loss": 17.33296513557434, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22519731521606, "training_acc": 53.0, "val_loss": 17.329080402851105, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15523052215576, "training_acc": 53.0, "val_loss": 17.312484979629517, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14020586013794, "training_acc": 53.0, "val_loss": 17.3077791929245, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20947670936584, "training_acc": 53.0, "val_loss": 17.30976402759552, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2090675830841, "training_acc": 53.0, "val_loss": 17.310731112957, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1813006401062, "training_acc": 53.0, "val_loss": 17.309048771858215, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15422129631042, "training_acc": 53.0, "val_loss": 17.310890555381775, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21511483192444, "training_acc": 53.0, "val_loss": 17.31390357017517, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23716044425964, "training_acc": 53.0, "val_loss": 17.32906550168991, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23656296730042, "training_acc": 53.0, "val_loss": 17.33320653438568, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15533375740051, "training_acc": 53.0, "val_loss": 17.323964834213257, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17026448249817, "training_acc": 53.0, "val_loss": 17.316150665283203, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13182425498962, "training_acc": 53.0, "val_loss": 17.313465476036072, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14293622970581, "training_acc": 53.0, "val_loss": 17.31124520301819, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14004850387573, "training_acc": 53.0, "val_loss": 17.310592532157898, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.153883934021, "training_acc": 53.0, "val_loss": 17.310836911201477, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14544820785522, "training_acc": 53.0, "val_loss": 17.313632369041443, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14102220535278, "training_acc": 53.0, "val_loss": 17.315563559532166, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1836621761322, "training_acc": 53.0, "val_loss": 17.315277457237244, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12884831428528, "training_acc": 53.0, "val_loss": 17.319904267787933, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13443756103516, "training_acc": 53.0, "val_loss": 17.324775457382202, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15897059440613, "training_acc": 53.0, "val_loss": 17.330734431743622, "val_acc": 52.0}
