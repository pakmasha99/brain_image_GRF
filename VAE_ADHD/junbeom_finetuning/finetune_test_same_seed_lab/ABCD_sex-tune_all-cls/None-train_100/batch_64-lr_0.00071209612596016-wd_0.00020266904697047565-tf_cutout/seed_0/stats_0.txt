"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 85.03144693374634, "training_acc": 50.0, "val_loss": 33.71451199054718, "val_acc": 56.0}
{"epoch": 1, "training_loss": 120.9987518787384, "training_acc": 52.0, "val_loss": 17.297567427158356, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.9633572101593, "training_acc": 52.0, "val_loss": 17.182525992393494, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.15958261489868, "training_acc": 52.0, "val_loss": 17.537759244441986, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.66511845588684, "training_acc": 48.0, "val_loss": 17.180898785591125, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.67510151863098, "training_acc": 52.0, "val_loss": 17.18181222677231, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.32168769836426, "training_acc": 52.0, "val_loss": 17.339511215686798, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.39242911338806, "training_acc": 48.0, "val_loss": 17.295445501804352, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.56794548034668, "training_acc": 52.0, "val_loss": 17.21864342689514, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.23303985595703, "training_acc": 52.0, "val_loss": 17.245784401893616, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.26407265663147, "training_acc": 52.0, "val_loss": 17.276419699192047, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.268150806427, "training_acc": 52.0, "val_loss": 17.254750430583954, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.28486680984497, "training_acc": 52.0, "val_loss": 17.23610609769821, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.25546193122864, "training_acc": 52.0, "val_loss": 17.242935299873352, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.23171353340149, "training_acc": 52.0, "val_loss": 17.22746193408966, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23282289505005, "training_acc": 52.0, "val_loss": 17.208334803581238, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.26111650466919, "training_acc": 52.0, "val_loss": 17.188164591789246, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.26821208000183, "training_acc": 52.0, "val_loss": 17.19367951154709, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25757765769958, "training_acc": 52.0, "val_loss": 17.21026599407196, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.23257040977478, "training_acc": 52.0, "val_loss": 17.229968309402466, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.25236105918884, "training_acc": 52.0, "val_loss": 17.254449427127838, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26060795783997, "training_acc": 52.0, "val_loss": 17.25618690252304, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.30155515670776, "training_acc": 52.0, "val_loss": 17.23102182149887, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.23155283927917, "training_acc": 52.0, "val_loss": 17.235492169857025, "val_acc": 56.0}
