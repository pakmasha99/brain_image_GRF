"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 87.55214309692383, "training_acc": 50.0, "val_loss": 17.54663735628128, "val_acc": 52.0}
{"epoch": 1, "training_loss": 192.22915840148926, "training_acc": 51.0, "val_loss": 18.291695415973663, "val_acc": 60.0}
{"epoch": 2, "training_loss": 70.5385594367981, "training_acc": 47.0, "val_loss": 17.501987516880035, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.40638828277588, "training_acc": 53.0, "val_loss": 17.79477894306183, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.47442197799683, "training_acc": 53.0, "val_loss": 17.467813193798065, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16001844406128, "training_acc": 53.0, "val_loss": 17.319944500923157, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.80770993232727, "training_acc": 45.0, "val_loss": 17.339231073856354, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.44290781021118, "training_acc": 47.0, "val_loss": 17.372913658618927, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.42774391174316, "training_acc": 53.0, "val_loss": 17.348161339759827, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17733836174011, "training_acc": 53.0, "val_loss": 17.38273650407791, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.22538423538208, "training_acc": 53.0, "val_loss": 17.365823686122894, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.44575810432434, "training_acc": 53.0, "val_loss": 17.321300506591797, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21854019165039, "training_acc": 53.0, "val_loss": 17.3285573720932, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15768384933472, "training_acc": 53.0, "val_loss": 17.317698895931244, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16382813453674, "training_acc": 53.0, "val_loss": 17.317451536655426, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1247808933258, "training_acc": 53.0, "val_loss": 17.33085662126541, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18841290473938, "training_acc": 53.0, "val_loss": 17.336174845695496, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19905591011047, "training_acc": 53.0, "val_loss": 17.354290187358856, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16091084480286, "training_acc": 53.0, "val_loss": 17.33347326517105, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16011357307434, "training_acc": 53.0, "val_loss": 17.31945425271988, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.126216173172, "training_acc": 53.0, "val_loss": 17.317168414592743, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14587450027466, "training_acc": 53.0, "val_loss": 17.31574535369873, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13540387153625, "training_acc": 53.0, "val_loss": 17.31516569852829, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19797658920288, "training_acc": 53.0, "val_loss": 17.315363883972168, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17804670333862, "training_acc": 53.0, "val_loss": 17.316648364067078, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13090991973877, "training_acc": 53.0, "val_loss": 17.32219308614731, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1162965297699, "training_acc": 53.0, "val_loss": 17.33018457889557, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1442883014679, "training_acc": 53.0, "val_loss": 17.332234978675842, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17220163345337, "training_acc": 53.0, "val_loss": 17.32197105884552, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13013458251953, "training_acc": 53.0, "val_loss": 17.322459816932678, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12808513641357, "training_acc": 53.0, "val_loss": 17.319877445697784, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12786030769348, "training_acc": 53.0, "val_loss": 17.319174110889435, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1328387260437, "training_acc": 53.0, "val_loss": 17.322303354740143, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12152194976807, "training_acc": 53.0, "val_loss": 17.3221617937088, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.11673355102539, "training_acc": 53.0, "val_loss": 17.320239543914795, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.22402787208557, "training_acc": 53.0, "val_loss": 17.31906682252884, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.0972671508789, "training_acc": 53.0, "val_loss": 17.316310107707977, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16179609298706, "training_acc": 53.0, "val_loss": 17.31889694929123, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.24734902381897, "training_acc": 53.0, "val_loss": 17.318090796470642, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.20656132698059, "training_acc": 53.0, "val_loss": 17.313681542873383, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.28065967559814, "training_acc": 53.0, "val_loss": 17.317351698875427, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.20215225219727, "training_acc": 53.0, "val_loss": 17.31528490781784, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1246554851532, "training_acc": 53.0, "val_loss": 17.320643365383148, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.27565884590149, "training_acc": 53.0, "val_loss": 17.33267605304718, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.14107656478882, "training_acc": 53.0, "val_loss": 17.326293885707855, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12755370140076, "training_acc": 53.0, "val_loss": 17.317725718021393, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.34439182281494, "training_acc": 53.0, "val_loss": 17.313776910305023, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.11656975746155, "training_acc": 53.0, "val_loss": 17.31944978237152, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.11836242675781, "training_acc": 53.0, "val_loss": 17.329120635986328, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12864756584167, "training_acc": 53.0, "val_loss": 17.347705364227295, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.16797208786011, "training_acc": 53.0, "val_loss": 17.375922203063965, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.36735892295837, "training_acc": 53.0, "val_loss": 17.39271432161331, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.24067997932434, "training_acc": 53.0, "val_loss": 17.34917461872101, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.1898922920227, "training_acc": 53.0, "val_loss": 17.323674261569977, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.12225985527039, "training_acc": 53.0, "val_loss": 17.316922545433044, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.12711715698242, "training_acc": 53.0, "val_loss": 17.31470227241516, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.14144206047058, "training_acc": 53.0, "val_loss": 17.314250767230988, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.1429488658905, "training_acc": 53.0, "val_loss": 17.314834892749786, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.14399838447571, "training_acc": 53.0, "val_loss": 17.317470908164978, "val_acc": 52.0}
