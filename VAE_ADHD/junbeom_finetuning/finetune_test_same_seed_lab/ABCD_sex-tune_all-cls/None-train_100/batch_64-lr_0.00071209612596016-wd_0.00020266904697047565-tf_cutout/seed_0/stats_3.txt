"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 94.20681238174438, "training_acc": 49.0, "val_loss": 22.65384942293167, "val_acc": 52.0}
{"epoch": 1, "training_loss": 320.8213748931885, "training_acc": 47.0, "val_loss": 19.818030297756195, "val_acc": 48.0}
{"epoch": 2, "training_loss": 74.77058744430542, "training_acc": 47.0, "val_loss": 17.29646623134613, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21045327186584, "training_acc": 53.0, "val_loss": 17.392154037952423, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.42416000366211, "training_acc": 53.0, "val_loss": 17.293177545070648, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10208249092102, "training_acc": 53.0, "val_loss": 17.35309511423111, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.00097322463989, "training_acc": 47.0, "val_loss": 17.299266159534454, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.65245914459229, "training_acc": 53.0, "val_loss": 17.39181876182556, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.36298036575317, "training_acc": 53.0, "val_loss": 17.296431958675385, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.35879063606262, "training_acc": 53.0, "val_loss": 17.300686240196228, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17858099937439, "training_acc": 53.0, "val_loss": 17.30688512325287, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1479799747467, "training_acc": 53.0, "val_loss": 17.33410954475403, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22348022460938, "training_acc": 53.0, "val_loss": 17.348039150238037, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.66972398757935, "training_acc": 53.0, "val_loss": 17.310073971748352, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.245365858078, "training_acc": 53.0, "val_loss": 17.318065464496613, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.35141587257385, "training_acc": 47.0, "val_loss": 17.33037680387497, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.47847056388855, "training_acc": 37.0, "val_loss": 17.320331931114197, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.28004813194275, "training_acc": 53.0, "val_loss": 17.320041358470917, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26908206939697, "training_acc": 53.0, "val_loss": 17.317603528499603, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24012207984924, "training_acc": 53.0, "val_loss": 17.310091853141785, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17718124389648, "training_acc": 53.0, "val_loss": 17.306213080883026, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.39477920532227, "training_acc": 53.0, "val_loss": 17.31042116880417, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14629817008972, "training_acc": 53.0, "val_loss": 17.310430109500885, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20494842529297, "training_acc": 53.0, "val_loss": 17.312493920326233, "val_acc": 52.0}
