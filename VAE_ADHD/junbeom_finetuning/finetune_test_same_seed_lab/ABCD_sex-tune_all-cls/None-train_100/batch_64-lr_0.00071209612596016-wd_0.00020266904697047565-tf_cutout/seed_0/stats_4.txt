"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.67300796508789, "training_acc": 55.0, "val_loss": 22.713705897331238, "val_acc": 52.0}
{"epoch": 1, "training_loss": 317.214693069458, "training_acc": 45.0, "val_loss": 18.68027001619339, "val_acc": 48.0}
{"epoch": 2, "training_loss": 73.60042643547058, "training_acc": 47.0, "val_loss": 17.60028451681137, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.12301206588745, "training_acc": 53.0, "val_loss": 17.30227619409561, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27668571472168, "training_acc": 51.0, "val_loss": 17.313571274280548, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.34453272819519, "training_acc": 53.0, "val_loss": 17.349740862846375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.57698559761047, "training_acc": 49.0, "val_loss": 17.301566898822784, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09240102767944, "training_acc": 53.0, "val_loss": 17.475375533103943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.69181180000305, "training_acc": 53.0, "val_loss": 17.305046319961548, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.38696718215942, "training_acc": 53.0, "val_loss": 17.30303019285202, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.27361917495728, "training_acc": 52.0, "val_loss": 17.307178676128387, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14077115058899, "training_acc": 53.0, "val_loss": 17.34204888343811, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.26598453521729, "training_acc": 53.0, "val_loss": 17.352236807346344, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.77872085571289, "training_acc": 53.0, "val_loss": 17.304280400276184, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.39225697517395, "training_acc": 53.0, "val_loss": 17.315207421779633, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13800048828125, "training_acc": 53.0, "val_loss": 17.305198311805725, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12803077697754, "training_acc": 53.0, "val_loss": 17.31111705303192, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27733016014099, "training_acc": 53.0, "val_loss": 17.31831133365631, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.28684568405151, "training_acc": 58.0, "val_loss": 17.327630519866943, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.26200222969055, "training_acc": 53.0, "val_loss": 17.310431599617004, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.63296246528625, "training_acc": 53.0, "val_loss": 17.31092780828476, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13406872749329, "training_acc": 53.0, "val_loss": 17.308734357357025, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1684296131134, "training_acc": 53.0, "val_loss": 17.30853170156479, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15674233436584, "training_acc": 53.0, "val_loss": 17.310817539691925, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2205696105957, "training_acc": 53.0, "val_loss": 17.312240600585938, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.10612201690674, "training_acc": 53.0, "val_loss": 17.324508726596832, "val_acc": 52.0}
