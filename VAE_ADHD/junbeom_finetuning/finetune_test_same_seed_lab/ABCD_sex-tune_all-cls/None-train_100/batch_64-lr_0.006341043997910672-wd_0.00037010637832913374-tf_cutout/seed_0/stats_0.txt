"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 343.0985908508301, "training_acc": 50.0, "val_loss": 9074515.625, "val_acc": 56.0}
{"epoch": 1, "training_loss": 24651211.209960938, "training_acc": 52.0, "val_loss": 38446.86279296875, "val_acc": 44.0}
{"epoch": 2, "training_loss": 97764.66697692871, "training_acc": 48.0, "val_loss": 247.2698211669922, "val_acc": 56.0}
{"epoch": 3, "training_loss": 979.3260498046875, "training_acc": 54.0, "val_loss": 399.9695301055908, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1358.9778366088867, "training_acc": 52.0, "val_loss": 28.939902782440186, "val_acc": 44.0}
{"epoch": 5, "training_loss": 101.84001564979553, "training_acc": 48.0, "val_loss": 35.616832971572876, "val_acc": 56.0}
{"epoch": 6, "training_loss": 267.7985305786133, "training_acc": 50.0, "val_loss": 27.543053030967712, "val_acc": 44.0}
{"epoch": 7, "training_loss": 96.46403861045837, "training_acc": 52.0, "val_loss": 37.44653761386871, "val_acc": 44.0}
{"epoch": 8, "training_loss": 152.2332968711853, "training_acc": 42.0, "val_loss": 19.26606446504593, "val_acc": 44.0}
{"epoch": 9, "training_loss": 73.74829125404358, "training_acc": 48.0, "val_loss": 26.791369915008545, "val_acc": 44.0}
{"epoch": 10, "training_loss": 141.62444591522217, "training_acc": 50.0, "val_loss": 18.245521187782288, "val_acc": 56.0}
{"epoch": 11, "training_loss": 78.64995312690735, "training_acc": 52.0, "val_loss": 20.81398367881775, "val_acc": 44.0}
{"epoch": 12, "training_loss": 77.53136014938354, "training_acc": 46.0, "val_loss": 17.758525907993317, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.39896655082703, "training_acc": 52.0, "val_loss": 20.13564705848694, "val_acc": 44.0}
{"epoch": 14, "training_loss": 81.88673377037048, "training_acc": 52.0, "val_loss": 62.750595808029175, "val_acc": 44.0}
{"epoch": 15, "training_loss": 210.71435451507568, "training_acc": 54.0, "val_loss": 28.86936068534851, "val_acc": 44.0}
{"epoch": 16, "training_loss": 96.57961106300354, "training_acc": 48.0, "val_loss": 21.88003361225128, "val_acc": 56.0}
{"epoch": 17, "training_loss": 85.01340579986572, "training_acc": 50.0, "val_loss": 20.058102905750275, "val_acc": 44.0}
{"epoch": 18, "training_loss": 74.51109790802002, "training_acc": 48.0, "val_loss": 17.14511215686798, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.50154876708984, "training_acc": 52.0, "val_loss": 20.62709331512451, "val_acc": 44.0}
{"epoch": 20, "training_loss": 75.8296251296997, "training_acc": 52.0, "val_loss": 18.248997628688812, "val_acc": 56.0}
{"epoch": 21, "training_loss": 79.07110953330994, "training_acc": 46.0, "val_loss": 17.51062721014023, "val_acc": 56.0}
{"epoch": 22, "training_loss": 71.31210541725159, "training_acc": 52.0, "val_loss": 29.506564140319824, "val_acc": 44.0}
{"epoch": 23, "training_loss": 106.30914688110352, "training_acc": 46.0, "val_loss": 21.141961216926575, "val_acc": 56.0}
{"epoch": 24, "training_loss": 85.8020691871643, "training_acc": 52.0, "val_loss": 17.184340953826904, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.54439949989319, "training_acc": 48.0, "val_loss": 18.06294173002243, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.4716203212738, "training_acc": 48.0, "val_loss": 17.619091272354126, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.82206010818481, "training_acc": 48.0, "val_loss": 17.256532609462738, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.21350073814392, "training_acc": 52.0, "val_loss": 17.201438546180725, "val_acc": 56.0}
{"epoch": 29, "training_loss": 70.15849328041077, "training_acc": 52.0, "val_loss": 17.264167964458466, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.86935329437256, "training_acc": 52.0, "val_loss": 17.515063285827637, "val_acc": 56.0}
{"epoch": 31, "training_loss": 71.11732196807861, "training_acc": 48.0, "val_loss": 17.645400762557983, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.89992880821228, "training_acc": 48.0, "val_loss": 17.234668135643005, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.23780870437622, "training_acc": 52.0, "val_loss": 17.19013750553131, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.43620944023132, "training_acc": 52.0, "val_loss": 17.196838557720184, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.33044171333313, "training_acc": 52.0, "val_loss": 17.344829440116882, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.30678153038025, "training_acc": 56.0, "val_loss": 17.220434546470642, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.56832695007324, "training_acc": 52.0, "val_loss": 17.157825827598572, "val_acc": 56.0}
