"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 257.6724491119385, "training_acc": 36.0, "val_loss": 4318570.3125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 11450970.189422607, "training_acc": 47.0, "val_loss": 16882.421875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 56676.68420410156, "training_acc": 49.0, "val_loss": 824.8715400695801, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2265.1668815612793, "training_acc": 47.0, "val_loss": 26.92345678806305, "val_acc": 52.0}
{"epoch": 4, "training_loss": 609.3641014099121, "training_acc": 47.0, "val_loss": 109.9647045135498, "val_acc": 52.0}
{"epoch": 5, "training_loss": 293.79518246650696, "training_acc": 53.0, "val_loss": 160.9518527984619, "val_acc": 48.0}
{"epoch": 6, "training_loss": 407.6274263858795, "training_acc": 47.0, "val_loss": 84.2616319656372, "val_acc": 52.0}
{"epoch": 7, "training_loss": 226.53275179862976, "training_acc": 53.0, "val_loss": 18.37873011827469, "val_acc": 56.0}
{"epoch": 8, "training_loss": 83.44700145721436, "training_acc": 49.0, "val_loss": 25.107082724571228, "val_acc": 48.0}
{"epoch": 9, "training_loss": 86.16192960739136, "training_acc": 47.0, "val_loss": 29.541203379631042, "val_acc": 52.0}
{"epoch": 10, "training_loss": 102.96296620368958, "training_acc": 53.0, "val_loss": 19.95881199836731, "val_acc": 48.0}
{"epoch": 11, "training_loss": 75.82027912139893, "training_acc": 47.0, "val_loss": 30.562707781791687, "val_acc": 52.0}
{"epoch": 12, "training_loss": 516.8789405822754, "training_acc": 53.0, "val_loss": 37.12413311004639, "val_acc": 52.0}
{"epoch": 13, "training_loss": 134.8183822631836, "training_acc": 53.0, "val_loss": 45.76677680015564, "val_acc": 48.0}
{"epoch": 14, "training_loss": 207.08080768585205, "training_acc": 47.0, "val_loss": 41.54593646526337, "val_acc": 52.0}
{"epoch": 15, "training_loss": 139.27009534835815, "training_acc": 53.0, "val_loss": 17.313140630722046, "val_acc": 52.0}
{"epoch": 16, "training_loss": 81.59122276306152, "training_acc": 52.0, "val_loss": 21.259140968322754, "val_acc": 48.0}
{"epoch": 17, "training_loss": 83.78267765045166, "training_acc": 43.0, "val_loss": 17.302779853343964, "val_acc": 52.0}
{"epoch": 18, "training_loss": 73.1008985042572, "training_acc": 53.0, "val_loss": 25.139257311820984, "val_acc": 48.0}
{"epoch": 19, "training_loss": 88.27246522903442, "training_acc": 47.0, "val_loss": 26.62036418914795, "val_acc": 52.0}
{"epoch": 20, "training_loss": 98.23652696609497, "training_acc": 53.0, "val_loss": 17.748957872390747, "val_acc": 52.0}
{"epoch": 21, "training_loss": 82.64105081558228, "training_acc": 47.0, "val_loss": 17.584413290023804, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.30000233650208, "training_acc": 57.0, "val_loss": 18.901297450065613, "val_acc": 52.0}
{"epoch": 23, "training_loss": 78.58072280883789, "training_acc": 43.0, "val_loss": 19.49888914823532, "val_acc": 52.0}
{"epoch": 24, "training_loss": 76.01970219612122, "training_acc": 53.0, "val_loss": 17.389914393424988, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.99020171165466, "training_acc": 44.0, "val_loss": 18.569383025169373, "val_acc": 48.0}
{"epoch": 26, "training_loss": 71.890629529953, "training_acc": 47.0, "val_loss": 18.87131631374359, "val_acc": 52.0}
{"epoch": 27, "training_loss": 75.3818769454956, "training_acc": 53.0, "val_loss": 17.310404777526855, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.3649353981018, "training_acc": 55.0, "val_loss": 18.28036904335022, "val_acc": 52.0}
{"epoch": 29, "training_loss": 72.17684483528137, "training_acc": 47.0, "val_loss": 17.77820587158203, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.43976712226868, "training_acc": 53.0, "val_loss": 17.541034519672394, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.54449129104614, "training_acc": 53.0, "val_loss": 17.34233945608139, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.48912143707275, "training_acc": 47.0, "val_loss": 17.318889498710632, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.41534781455994, "training_acc": 53.0, "val_loss": 17.346377670764923, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.50053429603577, "training_acc": 45.0, "val_loss": 18.04002672433853, "val_acc": 52.0}
{"epoch": 35, "training_loss": 72.09531760215759, "training_acc": 47.0, "val_loss": 17.594441771507263, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.16470384597778, "training_acc": 47.0, "val_loss": 17.34694242477417, "val_acc": 52.0}
