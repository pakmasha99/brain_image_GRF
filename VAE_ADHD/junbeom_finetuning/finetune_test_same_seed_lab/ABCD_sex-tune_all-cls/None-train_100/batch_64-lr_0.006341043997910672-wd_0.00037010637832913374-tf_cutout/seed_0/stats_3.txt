"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 200.1680850982666, "training_acc": 53.0, "val_loss": 17833871.875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 42110816.21103573, "training_acc": 55.0, "val_loss": 11275.618743896484, "val_acc": 48.0}
{"epoch": 2, "training_loss": 61193.099853515625, "training_acc": 47.0, "val_loss": 3454.261016845703, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8473.936096191406, "training_acc": 53.0, "val_loss": 18.526747822761536, "val_acc": 56.0}
{"epoch": 4, "training_loss": 497.0426940917969, "training_acc": 43.0, "val_loss": 95.48237323760986, "val_acc": 48.0}
{"epoch": 5, "training_loss": 282.2316105365753, "training_acc": 49.0, "val_loss": 32.90267586708069, "val_acc": 48.0}
{"epoch": 6, "training_loss": 151.45445108413696, "training_acc": 47.0, "val_loss": 19.113689661026, "val_acc": 48.0}
{"epoch": 7, "training_loss": 72.90583896636963, "training_acc": 47.0, "val_loss": 90.26612043380737, "val_acc": 52.0}
{"epoch": 8, "training_loss": 233.13898849487305, "training_acc": 55.0, "val_loss": 25.331619381904602, "val_acc": 48.0}
{"epoch": 9, "training_loss": 130.88483667373657, "training_acc": 45.0, "val_loss": 17.349353432655334, "val_acc": 52.0}
{"epoch": 10, "training_loss": 103.89447116851807, "training_acc": 47.0, "val_loss": 19.720159471035004, "val_acc": 52.0}
{"epoch": 11, "training_loss": 79.42845821380615, "training_acc": 53.0, "val_loss": 17.33255386352539, "val_acc": 52.0}
{"epoch": 12, "training_loss": 78.92104291915894, "training_acc": 45.0, "val_loss": 17.314456403255463, "val_acc": 52.0}
{"epoch": 13, "training_loss": 74.23559212684631, "training_acc": 53.0, "val_loss": 18.077452480793, "val_acc": 52.0}
{"epoch": 14, "training_loss": 72.26430821418762, "training_acc": 47.0, "val_loss": 17.429789900779724, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.59705781936646, "training_acc": 45.0, "val_loss": 17.307738959789276, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.48024296760559, "training_acc": 49.0, "val_loss": 17.349453270435333, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.52762222290039, "training_acc": 53.0, "val_loss": 17.371562123298645, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.06447625160217, "training_acc": 53.0, "val_loss": 17.42946207523346, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.78304123878479, "training_acc": 47.0, "val_loss": 17.331717908382416, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.38706088066101, "training_acc": 53.0, "val_loss": 17.332646250724792, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.86982655525208, "training_acc": 48.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.76089429855347, "training_acc": 53.0, "val_loss": 18.059799075126648, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.76795840263367, "training_acc": 53.0, "val_loss": 17.306241393089294, "val_acc": 52.0}
{"epoch": 24, "training_loss": 72.22454476356506, "training_acc": 43.0, "val_loss": 17.55703240633011, "val_acc": 52.0}
{"epoch": 25, "training_loss": 73.47476601600647, "training_acc": 41.0, "val_loss": 17.30598360300064, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.37948679924011, "training_acc": 49.0, "val_loss": 17.613746225833893, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.28964138031006, "training_acc": 49.0, "val_loss": 17.315252125263214, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.97195100784302, "training_acc": 53.0, "val_loss": 17.3108771443367, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.0535626411438, "training_acc": 54.0, "val_loss": 17.457400262355804, "val_acc": 52.0}
{"epoch": 30, "training_loss": 71.27770733833313, "training_acc": 35.0, "val_loss": 17.3834890127182, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.59348917007446, "training_acc": 47.0, "val_loss": 17.404742538928986, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.78405928611755, "training_acc": 45.0, "val_loss": 17.30712801218033, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.38207364082336, "training_acc": 53.0, "val_loss": 17.34049767255783, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.36465859413147, "training_acc": 53.0, "val_loss": 17.31811910867691, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.51979994773865, "training_acc": 53.0, "val_loss": 17.31923222541809, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22715377807617, "training_acc": 53.0, "val_loss": 17.3069030046463, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.37315368652344, "training_acc": 53.0, "val_loss": 17.34471023082733, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.18644452095032, "training_acc": 53.0, "val_loss": 17.331446707248688, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11540269851685, "training_acc": 53.0, "val_loss": 17.307300865650177, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.19056272506714, "training_acc": 53.0, "val_loss": 17.308513820171356, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16871738433838, "training_acc": 53.0, "val_loss": 17.307792603969574, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.2120201587677, "training_acc": 53.0, "val_loss": 17.318911850452423, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16315007209778, "training_acc": 53.0, "val_loss": 17.317989468574524, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17133927345276, "training_acc": 53.0, "val_loss": 17.308077216148376, "val_acc": 52.0}
