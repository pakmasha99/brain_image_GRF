"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.44920086860657, "training_acc": 51.0, "val_loss": 17.551879584789276, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.54943013191223, "training_acc": 53.0, "val_loss": 17.52350628376007, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.22551369667053, "training_acc": 53.0, "val_loss": 17.706511914730072, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.80831909179688, "training_acc": 53.0, "val_loss": 17.37331598997116, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.96152687072754, "training_acc": 53.0, "val_loss": 17.347902059555054, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.32969427108765, "training_acc": 47.0, "val_loss": 17.442889511585236, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.09841227531433, "training_acc": 47.0, "val_loss": 17.44365394115448, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.88383889198303, "training_acc": 47.0, "val_loss": 17.33778268098831, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.4611656665802, "training_acc": 43.0, "val_loss": 17.31470078229904, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16331577301025, "training_acc": 53.0, "val_loss": 17.33044981956482, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11999917030334, "training_acc": 53.0, "val_loss": 17.34546571969986, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13573122024536, "training_acc": 53.0, "val_loss": 17.35544502735138, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2006733417511, "training_acc": 53.0, "val_loss": 17.35522598028183, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14573049545288, "training_acc": 53.0, "val_loss": 17.365756630897522, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.25243496894836, "training_acc": 53.0, "val_loss": 17.366689443588257, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.25738453865051, "training_acc": 53.0, "val_loss": 17.341728508472443, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.10618114471436, "training_acc": 53.0, "val_loss": 17.33420193195343, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10178065299988, "training_acc": 53.0, "val_loss": 17.327971756458282, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.09571933746338, "training_acc": 53.0, "val_loss": 17.32410043478012, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.07316899299622, "training_acc": 53.0, "val_loss": 17.319388687610626, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09010124206543, "training_acc": 53.0, "val_loss": 17.318177223205566, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08993554115295, "training_acc": 53.0, "val_loss": 17.318297922611237, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.06018304824829, "training_acc": 53.0, "val_loss": 17.318522930145264, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.04809522628784, "training_acc": 53.0, "val_loss": 17.322495579719543, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09887671470642, "training_acc": 53.0, "val_loss": 17.332321405410767, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09566879272461, "training_acc": 53.0, "val_loss": 17.336463928222656, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.09255623817444, "training_acc": 53.0, "val_loss": 17.33039766550064, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.03407740592957, "training_acc": 53.0, "val_loss": 17.325778305530548, "val_acc": 52.0}
