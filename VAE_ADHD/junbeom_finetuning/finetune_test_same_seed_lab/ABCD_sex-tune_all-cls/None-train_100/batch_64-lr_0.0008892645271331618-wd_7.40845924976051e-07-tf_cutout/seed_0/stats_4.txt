"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 87.66236162185669, "training_acc": 45.0, "val_loss": 150.60373544692993, "val_acc": 52.0}
{"epoch": 1, "training_loss": 384.6921272277832, "training_acc": 55.0, "val_loss": 17.39303171634674, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.41212964057922, "training_acc": 45.0, "val_loss": 18.018506467342377, "val_acc": 52.0}
{"epoch": 3, "training_loss": 76.25793504714966, "training_acc": 41.0, "val_loss": 17.376895248889923, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.49152827262878, "training_acc": 53.0, "val_loss": 17.379648983478546, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.47836470603943, "training_acc": 47.0, "val_loss": 17.31914132833481, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.23335671424866, "training_acc": 53.0, "val_loss": 17.33207255601883, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14444351196289, "training_acc": 53.0, "val_loss": 17.337562143802643, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.565514087677, "training_acc": 49.0, "val_loss": 17.31559783220291, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23450779914856, "training_acc": 53.0, "val_loss": 17.34035462141037, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.29585266113281, "training_acc": 53.0, "val_loss": 17.33691692352295, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18115544319153, "training_acc": 53.0, "val_loss": 17.347942292690277, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.26992464065552, "training_acc": 53.0, "val_loss": 17.35680401325226, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2178909778595, "training_acc": 53.0, "val_loss": 17.333202064037323, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1182165145874, "training_acc": 53.0, "val_loss": 17.311687767505646, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.09490299224854, "training_acc": 53.0, "val_loss": 17.311377823352814, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20499920845032, "training_acc": 53.0, "val_loss": 17.324866354465485, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27362751960754, "training_acc": 53.0, "val_loss": 17.350736260414124, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.66076683998108, "training_acc": 47.0, "val_loss": 17.33447164297104, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.47709274291992, "training_acc": 43.0, "val_loss": 17.31015294790268, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1342658996582, "training_acc": 53.0, "val_loss": 17.31327474117279, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23613476753235, "training_acc": 53.0, "val_loss": 17.323829233646393, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15652275085449, "training_acc": 53.0, "val_loss": 17.32318103313446, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14266538619995, "training_acc": 53.0, "val_loss": 17.326049506664276, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14456176757812, "training_acc": 53.0, "val_loss": 17.329499125480652, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.24343919754028, "training_acc": 53.0, "val_loss": 17.3256978392601, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11320352554321, "training_acc": 53.0, "val_loss": 17.31235831975937, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24139332771301, "training_acc": 53.0, "val_loss": 17.30990707874298, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16330909729004, "training_acc": 53.0, "val_loss": 17.309433221817017, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15724611282349, "training_acc": 53.0, "val_loss": 17.30930656194687, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.22373247146606, "training_acc": 53.0, "val_loss": 17.309369146823883, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14231586456299, "training_acc": 53.0, "val_loss": 17.30908304452896, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17171597480774, "training_acc": 53.0, "val_loss": 17.309103906154633, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13736295700073, "training_acc": 53.0, "val_loss": 17.310409247875214, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.2562153339386, "training_acc": 53.0, "val_loss": 17.314696311950684, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13752055168152, "training_acc": 53.0, "val_loss": 17.313633859157562, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13814520835876, "training_acc": 53.0, "val_loss": 17.31378734111786, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15813183784485, "training_acc": 53.0, "val_loss": 17.312629520893097, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13394665718079, "training_acc": 53.0, "val_loss": 17.31441020965576, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13208627700806, "training_acc": 53.0, "val_loss": 17.315736413002014, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13589000701904, "training_acc": 53.0, "val_loss": 17.316637933254242, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13504886627197, "training_acc": 53.0, "val_loss": 17.31669157743454, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13920545578003, "training_acc": 53.0, "val_loss": 17.31693297624588, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13976764678955, "training_acc": 53.0, "val_loss": 17.31911450624466, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13927459716797, "training_acc": 53.0, "val_loss": 17.31874644756317, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1408302783966, "training_acc": 53.0, "val_loss": 17.316675186157227, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14825391769409, "training_acc": 53.0, "val_loss": 17.31598973274231, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17057847976685, "training_acc": 53.0, "val_loss": 17.3123836517334, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.12978315353394, "training_acc": 53.0, "val_loss": 17.312493920326233, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13363480567932, "training_acc": 53.0, "val_loss": 17.312657833099365, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.12998270988464, "training_acc": 53.0, "val_loss": 17.313052713871002, "val_acc": 52.0}
