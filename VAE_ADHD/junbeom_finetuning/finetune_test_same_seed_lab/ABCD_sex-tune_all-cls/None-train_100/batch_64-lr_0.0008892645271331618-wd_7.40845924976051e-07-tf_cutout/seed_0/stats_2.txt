"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 108.4679856300354, "training_acc": 51.0, "val_loss": 33.73636603355408, "val_acc": 52.0}
{"epoch": 1, "training_loss": 240.6166934967041, "training_acc": 57.0, "val_loss": 19.749265909194946, "val_acc": 48.0}
{"epoch": 2, "training_loss": 76.23412704467773, "training_acc": 47.0, "val_loss": 17.37722009420395, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26729583740234, "training_acc": 51.0, "val_loss": 17.507654428482056, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.92272925376892, "training_acc": 53.0, "val_loss": 17.323459684848785, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.28509545326233, "training_acc": 47.0, "val_loss": 17.333556711673737, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.9882287979126, "training_acc": 54.0, "val_loss": 17.59546250104904, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.99109029769897, "training_acc": 53.0, "val_loss": 17.32747256755829, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.94481253623962, "training_acc": 53.0, "val_loss": 17.40114539861679, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.66903424263, "training_acc": 47.0, "val_loss": 17.33105480670929, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.25132513046265, "training_acc": 53.0, "val_loss": 17.33047217130661, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09966278076172, "training_acc": 53.0, "val_loss": 17.364278435707092, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19998121261597, "training_acc": 53.0, "val_loss": 17.37855076789856, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.58757519721985, "training_acc": 53.0, "val_loss": 17.33420193195343, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.43009495735168, "training_acc": 53.0, "val_loss": 17.333850264549255, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11480832099915, "training_acc": 53.0, "val_loss": 17.372427880764008, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.30975914001465, "training_acc": 53.0, "val_loss": 17.387431859970093, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.34840202331543, "training_acc": 53.0, "val_loss": 17.345386743545532, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1438660621643, "training_acc": 53.0, "val_loss": 17.331497371196747, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.22061848640442, "training_acc": 53.0, "val_loss": 17.319689691066742, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14158964157104, "training_acc": 53.0, "val_loss": 17.31846332550049, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12275862693787, "training_acc": 53.0, "val_loss": 17.320439219474792, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12839102745056, "training_acc": 53.0, "val_loss": 17.323699593544006, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1631281375885, "training_acc": 53.0, "val_loss": 17.333079874515533, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12911319732666, "training_acc": 53.0, "val_loss": 17.33395755290985, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1360809803009, "training_acc": 53.0, "val_loss": 17.333823442459106, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14474654197693, "training_acc": 53.0, "val_loss": 17.33573079109192, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15877294540405, "training_acc": 53.0, "val_loss": 17.333078384399414, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13993883132935, "training_acc": 53.0, "val_loss": 17.336253821849823, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13052129745483, "training_acc": 53.0, "val_loss": 17.332591116428375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12973833084106, "training_acc": 53.0, "val_loss": 17.32756793498993, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1177716255188, "training_acc": 53.0, "val_loss": 17.325370013713837, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12590718269348, "training_acc": 53.0, "val_loss": 17.32240468263626, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12561917304993, "training_acc": 53.0, "val_loss": 17.318834364414215, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16203713417053, "training_acc": 53.0, "val_loss": 17.31788069009781, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14637088775635, "training_acc": 53.0, "val_loss": 17.317935824394226, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13094401359558, "training_acc": 53.0, "val_loss": 17.318545281887054, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13272547721863, "training_acc": 53.0, "val_loss": 17.320328950881958, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14389419555664, "training_acc": 53.0, "val_loss": 17.3233300447464, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.12001729011536, "training_acc": 53.0, "val_loss": 17.32490360736847, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13094711303711, "training_acc": 53.0, "val_loss": 17.330405116081238, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12120079994202, "training_acc": 53.0, "val_loss": 17.331562936306, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.11387205123901, "training_acc": 53.0, "val_loss": 17.330417037010193, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.12656831741333, "training_acc": 53.0, "val_loss": 17.330949008464813, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1412558555603, "training_acc": 53.0, "val_loss": 17.32677072286606, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.09994006156921, "training_acc": 53.0, "val_loss": 17.322498559951782, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15288496017456, "training_acc": 53.0, "val_loss": 17.320799827575684, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.09277963638306, "training_acc": 53.0, "val_loss": 17.319197952747345, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.14690375328064, "training_acc": 53.0, "val_loss": 17.321109771728516, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.22939229011536, "training_acc": 53.0, "val_loss": 17.321492731571198, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.19395923614502, "training_acc": 53.0, "val_loss": 17.318755388259888, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.2382435798645, "training_acc": 53.0, "val_loss": 17.31971651315689, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.19788813591003, "training_acc": 53.0, "val_loss": 17.31887459754944, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.12184977531433, "training_acc": 53.0, "val_loss": 17.323128879070282, "val_acc": 52.0}
