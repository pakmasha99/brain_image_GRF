"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 85.90405511856079, "training_acc": 49.0, "val_loss": 47.577452659606934, "val_acc": 52.0}
{"epoch": 1, "training_loss": 162.48864078521729, "training_acc": 49.0, "val_loss": 17.31746792793274, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.47600197792053, "training_acc": 53.0, "val_loss": 17.412376403808594, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1068844795227, "training_acc": 53.0, "val_loss": 18.487849831581116, "val_acc": 48.0}
{"epoch": 4, "training_loss": 70.7359972000122, "training_acc": 47.0, "val_loss": 18.045102059841156, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.47336292266846, "training_acc": 53.0, "val_loss": 17.51548796892166, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.14105558395386, "training_acc": 53.0, "val_loss": 17.381267249584198, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.35094952583313, "training_acc": 53.0, "val_loss": 17.37372577190399, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29833579063416, "training_acc": 53.0, "val_loss": 17.36079752445221, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.31468749046326, "training_acc": 53.0, "val_loss": 17.338649928569794, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16056084632874, "training_acc": 53.0, "val_loss": 17.31075644493103, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13512468338013, "training_acc": 53.0, "val_loss": 17.30927675962448, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2606737613678, "training_acc": 53.0, "val_loss": 17.31840819120407, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.25368046760559, "training_acc": 53.0, "val_loss": 17.313475906848907, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1932282447815, "training_acc": 53.0, "val_loss": 17.309866845607758, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1405417919159, "training_acc": 53.0, "val_loss": 17.318519949913025, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.23329377174377, "training_acc": 53.0, "val_loss": 17.32442080974579, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.26530575752258, "training_acc": 53.0, "val_loss": 17.346569895744324, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26191449165344, "training_acc": 53.0, "val_loss": 17.344753444194794, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16982436180115, "training_acc": 53.0, "val_loss": 17.326469719409943, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18756127357483, "training_acc": 53.0, "val_loss": 17.3141211271286, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1293876171112, "training_acc": 53.0, "val_loss": 17.3106387257576, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14816117286682, "training_acc": 53.0, "val_loss": 17.308609187602997, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14950561523438, "training_acc": 53.0, "val_loss": 17.308439314365387, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16082096099854, "training_acc": 53.0, "val_loss": 17.309294641017914, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1495361328125, "training_acc": 53.0, "val_loss": 17.313361167907715, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14412999153137, "training_acc": 53.0, "val_loss": 17.316779494285583, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19150924682617, "training_acc": 53.0, "val_loss": 17.316797375679016, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12645745277405, "training_acc": 53.0, "val_loss": 17.32308864593506, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13920712471008, "training_acc": 53.0, "val_loss": 17.3288956284523, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.165283203125, "training_acc": 53.0, "val_loss": 17.334739863872528, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.19153642654419, "training_acc": 53.0, "val_loss": 17.332732677459717, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1863100528717, "training_acc": 53.0, "val_loss": 17.323414981365204, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1180100440979, "training_acc": 53.0, "val_loss": 17.312152683734894, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.134113073349, "training_acc": 53.0, "val_loss": 17.3092320561409, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15307950973511, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16735172271729, "training_acc": 53.0, "val_loss": 17.31008291244507, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.17612099647522, "training_acc": 53.0, "val_loss": 17.309841513633728, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.16672229766846, "training_acc": 53.0, "val_loss": 17.309297621250153, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14040398597717, "training_acc": 53.0, "val_loss": 17.310266196727753, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.121750831604, "training_acc": 53.0, "val_loss": 17.31390208005905, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.22771835327148, "training_acc": 53.0, "val_loss": 17.320843040943146, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14929986000061, "training_acc": 53.0, "val_loss": 17.319682240486145, "val_acc": 52.0}
