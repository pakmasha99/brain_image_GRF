"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 251.29928016662598, "training_acc": 49.0, "val_loss": 6264.241027832031, "val_acc": 48.0}
{"epoch": 1, "training_loss": 61361.13037109375, "training_acc": 45.0, "val_loss": 56.709372997283936, "val_acc": 52.0}
{"epoch": 2, "training_loss": 169.67738795280457, "training_acc": 53.0, "val_loss": 32.382386922836304, "val_acc": 48.0}
{"epoch": 3, "training_loss": 106.87408447265625, "training_acc": 47.0, "val_loss": 22.56879359483719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 81.73386359214783, "training_acc": 51.0, "val_loss": 18.922309577465057, "val_acc": 48.0}
{"epoch": 5, "training_loss": 71.17169523239136, "training_acc": 57.0, "val_loss": 26.08005702495575, "val_acc": 52.0}
{"epoch": 6, "training_loss": 85.02366352081299, "training_acc": 53.0, "val_loss": 18.542766571044922, "val_acc": 48.0}
{"epoch": 7, "training_loss": 74.4578378200531, "training_acc": 47.0, "val_loss": 17.64681190252304, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.89406156539917, "training_acc": 45.0, "val_loss": 17.32500046491623, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.2325325012207, "training_acc": 53.0, "val_loss": 17.325259745121002, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.38016152381897, "training_acc": 49.0, "val_loss": 17.34211891889572, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.32077097892761, "training_acc": 51.0, "val_loss": 17.313624918460846, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.43718814849854, "training_acc": 53.0, "val_loss": 17.356184124946594, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18409252166748, "training_acc": 53.0, "val_loss": 17.31248050928116, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.45027732849121, "training_acc": 47.0, "val_loss": 17.316444218158722, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2513439655304, "training_acc": 53.0, "val_loss": 17.309580743312836, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.52841806411743, "training_acc": 53.0, "val_loss": 17.31301099061966, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13759469985962, "training_acc": 53.0, "val_loss": 17.34180748462677, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.42795991897583, "training_acc": 53.0, "val_loss": 17.381736636161804, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.23687434196472, "training_acc": 53.0, "val_loss": 17.325080931186676, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09503388404846, "training_acc": 53.0, "val_loss": 17.30855107307434, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17559552192688, "training_acc": 53.0, "val_loss": 17.31582283973694, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.3412652015686, "training_acc": 53.0, "val_loss": 17.32422411441803, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.28657817840576, "training_acc": 53.0, "val_loss": 17.342789471149445, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.6028356552124, "training_acc": 47.0, "val_loss": 17.33102947473526, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.42325139045715, "training_acc": 42.0, "val_loss": 17.309576272964478, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15276312828064, "training_acc": 53.0, "val_loss": 17.309485375881195, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.22732996940613, "training_acc": 53.0, "val_loss": 17.314596474170685, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14794087409973, "training_acc": 53.0, "val_loss": 17.314723134040833, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13077235221863, "training_acc": 53.0, "val_loss": 17.319408059120178, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14289164543152, "training_acc": 53.0, "val_loss": 17.32560247182846, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.26224493980408, "training_acc": 53.0, "val_loss": 17.326432466506958, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12232255935669, "training_acc": 53.0, "val_loss": 17.315880954265594, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2082839012146, "training_acc": 53.0, "val_loss": 17.310641705989838, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14670920372009, "training_acc": 53.0, "val_loss": 17.31114089488983, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14006876945496, "training_acc": 53.0, "val_loss": 17.311063408851624, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.20110011100769, "training_acc": 53.0, "val_loss": 17.311474680900574, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1378481388092, "training_acc": 53.0, "val_loss": 17.30950176715851, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.18137860298157, "training_acc": 53.0, "val_loss": 17.309226095676422, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1518828868866, "training_acc": 53.0, "val_loss": 17.30995923280716, "val_acc": 52.0}
