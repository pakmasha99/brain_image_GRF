"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 179.05295753479004, "training_acc": 51.0, "val_loss": 5519176.953125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 13222739.666816711, "training_acc": 55.0, "val_loss": 141.914963722229, "val_acc": 52.0}
{"epoch": 2, "training_loss": 14142.794982910156, "training_acc": 47.0, "val_loss": 40.400850772857666, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2916.8945541381836, "training_acc": 51.0, "val_loss": 477.3440361022949, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1430.985836982727, "training_acc": 53.0, "val_loss": 50.560128688812256, "val_acc": 52.0}
{"epoch": 5, "training_loss": 152.71241188049316, "training_acc": 55.0, "val_loss": 88.74746561050415, "val_acc": 52.0}
{"epoch": 6, "training_loss": 286.4874744415283, "training_acc": 49.0, "val_loss": 17.942743003368378, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.96273374557495, "training_acc": 53.0, "val_loss": 17.485465109348297, "val_acc": 52.0}
{"epoch": 8, "training_loss": 91.69720792770386, "training_acc": 49.0, "val_loss": 30.955109000205994, "val_acc": 48.0}
{"epoch": 9, "training_loss": 99.12390184402466, "training_acc": 47.0, "val_loss": 26.636087894439697, "val_acc": 52.0}
{"epoch": 10, "training_loss": 92.72274971008301, "training_acc": 53.0, "val_loss": 18.099477887153625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 73.2666928768158, "training_acc": 47.0, "val_loss": 17.343799769878387, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.47635507583618, "training_acc": 49.0, "val_loss": 18.001866340637207, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.24342703819275, "training_acc": 53.0, "val_loss": 17.78472512960434, "val_acc": 52.0}
{"epoch": 14, "training_loss": 72.18514943122864, "training_acc": 45.0, "val_loss": 17.32962429523468, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.49946188926697, "training_acc": 42.0, "val_loss": 17.31373518705368, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.53179621696472, "training_acc": 49.0, "val_loss": 17.920295894145966, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.50795435905457, "training_acc": 53.0, "val_loss": 17.419153451919556, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.03648543357849, "training_acc": 47.0, "val_loss": 17.32943505048752, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.5394639968872, "training_acc": 53.0, "val_loss": 17.30484962463379, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16859531402588, "training_acc": 53.0, "val_loss": 17.34502613544464, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25939321517944, "training_acc": 53.0, "val_loss": 17.962750792503357, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.3943030834198, "training_acc": 53.0, "val_loss": 17.3483669757843, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.56661367416382, "training_acc": 47.0, "val_loss": 17.36723929643631, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.43981456756592, "training_acc": 54.0, "val_loss": 17.33546406030655, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.55662798881531, "training_acc": 53.0, "val_loss": 17.420358955860138, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21271920204163, "training_acc": 53.0, "val_loss": 17.312614619731903, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.29618167877197, "training_acc": 51.0, "val_loss": 17.334815859794617, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.881267786026, "training_acc": 41.0, "val_loss": 17.31010228395462, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20673871040344, "training_acc": 53.0, "val_loss": 17.31744408607483, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.23415684700012, "training_acc": 53.0, "val_loss": 17.313292622566223, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.25967931747437, "training_acc": 53.0, "val_loss": 17.307111620903015, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.27999806404114, "training_acc": 53.0, "val_loss": 17.35060214996338, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.57625126838684, "training_acc": 53.0, "val_loss": 17.34928786754608, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.58582139015198, "training_acc": 53.0, "val_loss": 17.30700582265854, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.26632714271545, "training_acc": 53.0, "val_loss": 17.30690747499466, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.49829483032227, "training_acc": 53.0, "val_loss": 17.32235848903656, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14627385139465, "training_acc": 53.0, "val_loss": 17.310023307800293, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17203044891357, "training_acc": 53.0, "val_loss": 17.308080196380615, "val_acc": 52.0}
