"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.12590146064758, "training_acc": 49.0, "val_loss": 17.372533679008484, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.75293326377869, "training_acc": 45.0, "val_loss": 17.34929233789444, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.79815649986267, "training_acc": 47.0, "val_loss": 17.362160980701447, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.58962559700012, "training_acc": 45.0, "val_loss": 17.307335138320923, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27954912185669, "training_acc": 53.0, "val_loss": 17.312397062778473, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06494188308716, "training_acc": 53.0, "val_loss": 17.296825349330902, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11753463745117, "training_acc": 53.0, "val_loss": 17.29835420846939, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12722420692444, "training_acc": 53.0, "val_loss": 17.298847436904907, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1562123298645, "training_acc": 53.0, "val_loss": 17.304904758930206, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.00221157073975, "training_acc": 53.0, "val_loss": 17.37176477909088, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.36360096931458, "training_acc": 53.0, "val_loss": 17.406508326530457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.31047677993774, "training_acc": 53.0, "val_loss": 17.323562502861023, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.9665892124176, "training_acc": 53.0, "val_loss": 17.30988323688507, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.61965990066528, "training_acc": 43.0, "val_loss": 17.345520853996277, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.47117924690247, "training_acc": 47.0, "val_loss": 17.311003804206848, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.9363660812378, "training_acc": 53.0, "val_loss": 17.379362881183624, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15537023544312, "training_acc": 53.0, "val_loss": 17.50987321138382, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.60025477409363, "training_acc": 53.0, "val_loss": 17.509570717811584, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.55242252349854, "training_acc": 53.0, "val_loss": 17.39361882209778, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24682593345642, "training_acc": 53.0, "val_loss": 17.32429414987564, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14344596862793, "training_acc": 53.0, "val_loss": 17.31496751308441, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08301210403442, "training_acc": 53.0, "val_loss": 17.31828600168228, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11643195152283, "training_acc": 53.0, "val_loss": 17.31954962015152, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.08803820610046, "training_acc": 53.0, "val_loss": 17.319239675998688, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.08074522018433, "training_acc": 53.0, "val_loss": 17.32860505580902, "val_acc": 52.0}
