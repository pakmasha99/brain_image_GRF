"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.65017342567444, "training_acc": 52.0, "val_loss": 17.18701869249344, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.75773310661316, "training_acc": 52.0, "val_loss": 17.182309925556183, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.72046709060669, "training_acc": 52.0, "val_loss": 17.177972197532654, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.63785338401794, "training_acc": 52.0, "val_loss": 17.174245417118073, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.5279803276062, "training_acc": 52.0, "val_loss": 17.171664535999298, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.4709894657135, "training_acc": 52.0, "val_loss": 17.170825600624084, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.47034358978271, "training_acc": 52.0, "val_loss": 17.171382904052734, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.43532609939575, "training_acc": 52.0, "val_loss": 17.172880470752716, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.35041046142578, "training_acc": 52.0, "val_loss": 17.175380885601044, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.36819767951965, "training_acc": 52.0, "val_loss": 17.17875897884369, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.26750779151917, "training_acc": 52.0, "val_loss": 17.18318462371826, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.31883573532104, "training_acc": 52.0, "val_loss": 17.188140749931335, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.27664566040039, "training_acc": 52.0, "val_loss": 17.19338148832321, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.21742463111877, "training_acc": 52.0, "val_loss": 17.19914823770523, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2498025894165, "training_acc": 52.0, "val_loss": 17.204421758651733, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.22911858558655, "training_acc": 52.0, "val_loss": 17.209400236606598, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2449734210968, "training_acc": 52.0, "val_loss": 17.213019728660583, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24154686927795, "training_acc": 52.0, "val_loss": 17.216798663139343, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.19387340545654, "training_acc": 52.0, "val_loss": 17.22043603658676, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21418118476868, "training_acc": 52.0, "val_loss": 17.22339540719986, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.17912364006042, "training_acc": 52.0, "val_loss": 17.22661405801773, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.19424390792847, "training_acc": 52.0, "val_loss": 17.229001224040985, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.23449683189392, "training_acc": 52.0, "val_loss": 17.22995489835739, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.2129373550415, "training_acc": 52.0, "val_loss": 17.231935262680054, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21693420410156, "training_acc": 52.0, "val_loss": 17.234262824058533, "val_acc": 56.0}
