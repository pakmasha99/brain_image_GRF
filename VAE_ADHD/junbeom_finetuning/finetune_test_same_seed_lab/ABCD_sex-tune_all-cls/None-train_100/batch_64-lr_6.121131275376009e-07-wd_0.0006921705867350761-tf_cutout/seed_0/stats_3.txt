"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.47372555732727, "training_acc": 47.0, "val_loss": 17.31117218732834, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1222198009491, "training_acc": 53.0, "val_loss": 17.311136424541473, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.11637806892395, "training_acc": 53.0, "val_loss": 17.31094866991043, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13480734825134, "training_acc": 53.0, "val_loss": 17.310620844364166, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.12765216827393, "training_acc": 53.0, "val_loss": 17.310553789138794, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12843441963196, "training_acc": 53.0, "val_loss": 17.31078326702118, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09220552444458, "training_acc": 53.0, "val_loss": 17.310956120491028, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11542463302612, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.09779667854309, "training_acc": 53.0, "val_loss": 17.31170564889908, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.10547232627869, "training_acc": 53.0, "val_loss": 17.31221377849579, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1372606754303, "training_acc": 53.0, "val_loss": 17.312702536582947, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.11626839637756, "training_acc": 53.0, "val_loss": 17.312778532505035, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16376686096191, "training_acc": 53.0, "val_loss": 17.312951385974884, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.10688900947571, "training_acc": 53.0, "val_loss": 17.312996089458466, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15088963508606, "training_acc": 53.0, "val_loss": 17.31273978948593, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16104459762573, "training_acc": 53.0, "val_loss": 17.31269359588623, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15607166290283, "training_acc": 53.0, "val_loss": 17.312678694725037, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16511678695679, "training_acc": 53.0, "val_loss": 17.312614619731903, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11480689048767, "training_acc": 53.0, "val_loss": 17.31267124414444, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15762042999268, "training_acc": 53.0, "val_loss": 17.312699556350708, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1250991821289, "training_acc": 53.0, "val_loss": 17.312820255756378, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10552597045898, "training_acc": 53.0, "val_loss": 17.312806844711304, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.10622143745422, "training_acc": 53.0, "val_loss": 17.312999069690704, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1142041683197, "training_acc": 53.0, "val_loss": 17.312896251678467, "val_acc": 52.0}
