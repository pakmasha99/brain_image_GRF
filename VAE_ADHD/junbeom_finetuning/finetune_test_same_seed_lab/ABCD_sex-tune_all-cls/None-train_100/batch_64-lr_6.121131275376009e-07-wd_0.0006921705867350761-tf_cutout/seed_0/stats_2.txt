"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3737461566925, "training_acc": 53.0, "val_loss": 17.33500212430954, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.12656140327454, "training_acc": 53.0, "val_loss": 17.335139214992523, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.11257719993591, "training_acc": 53.0, "val_loss": 17.332614958286285, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12720537185669, "training_acc": 53.0, "val_loss": 17.329995334148407, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14887595176697, "training_acc": 53.0, "val_loss": 17.32805371284485, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1561553478241, "training_acc": 53.0, "val_loss": 17.32717603445053, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1207766532898, "training_acc": 53.0, "val_loss": 17.32638329267502, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13789439201355, "training_acc": 53.0, "val_loss": 17.32657253742218, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.126882314682, "training_acc": 53.0, "val_loss": 17.327891290187836, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1314845085144, "training_acc": 53.0, "val_loss": 17.329226434230804, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.09500980377197, "training_acc": 53.0, "val_loss": 17.329879105091095, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13163828849792, "training_acc": 53.0, "val_loss": 17.33059585094452, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17386078834534, "training_acc": 53.0, "val_loss": 17.330965399742126, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11784172058105, "training_acc": 53.0, "val_loss": 17.331507802009583, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12672924995422, "training_acc": 53.0, "val_loss": 17.332270741462708, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10563445091248, "training_acc": 53.0, "val_loss": 17.332836985588074, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12199330329895, "training_acc": 53.0, "val_loss": 17.33369082212448, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17060208320618, "training_acc": 53.0, "val_loss": 17.333854734897614, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1378288269043, "training_acc": 53.0, "val_loss": 17.33384281396866, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13287353515625, "training_acc": 53.0, "val_loss": 17.334143817424774, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12718296051025, "training_acc": 53.0, "val_loss": 17.333965003490448, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13352417945862, "training_acc": 53.0, "val_loss": 17.334379255771637, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16207933425903, "training_acc": 53.0, "val_loss": 17.33418107032776, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13368391990662, "training_acc": 53.0, "val_loss": 17.33383685350418, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.08656740188599, "training_acc": 53.0, "val_loss": 17.33342707157135, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.0917239189148, "training_acc": 53.0, "val_loss": 17.332588136196136, "val_acc": 52.0}
