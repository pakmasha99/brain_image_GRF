"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.62237477302551, "training_acc": 47.0, "val_loss": 17.42579936981201, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.72273302078247, "training_acc": 47.0, "val_loss": 17.4224391579628, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.70872354507446, "training_acc": 47.0, "val_loss": 17.412546277046204, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.67454719543457, "training_acc": 47.0, "val_loss": 17.402739822864532, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.62113976478577, "training_acc": 47.0, "val_loss": 17.392559349536896, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.5665557384491, "training_acc": 47.0, "val_loss": 17.38264411687851, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5439350605011, "training_acc": 47.0, "val_loss": 17.373459041118622, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4725067615509, "training_acc": 47.0, "val_loss": 17.365966737270355, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.48097276687622, "training_acc": 47.0, "val_loss": 17.359407246112823, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.38306522369385, "training_acc": 47.0, "val_loss": 17.35420972108841, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.37734913825989, "training_acc": 47.0, "val_loss": 17.349141836166382, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.345299243927, "training_acc": 47.0, "val_loss": 17.34401434659958, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.38475942611694, "training_acc": 48.0, "val_loss": 17.339660227298737, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.32038164138794, "training_acc": 44.0, "val_loss": 17.335936427116394, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2750985622406, "training_acc": 55.0, "val_loss": 17.33206957578659, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.28855609893799, "training_acc": 53.0, "val_loss": 17.329202592372894, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.23541378974915, "training_acc": 53.0, "val_loss": 17.327316105365753, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2143383026123, "training_acc": 53.0, "val_loss": 17.32562482357025, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23899865150452, "training_acc": 53.0, "val_loss": 17.323997616767883, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19152879714966, "training_acc": 53.0, "val_loss": 17.322689294815063, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16105675697327, "training_acc": 53.0, "val_loss": 17.321521043777466, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16631031036377, "training_acc": 53.0, "val_loss": 17.32059121131897, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18880152702332, "training_acc": 53.0, "val_loss": 17.31974333524704, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17422246932983, "training_acc": 53.0, "val_loss": 17.319291830062866, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14073038101196, "training_acc": 53.0, "val_loss": 17.318876087665558, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14520239830017, "training_acc": 53.0, "val_loss": 17.318718135356903, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18572354316711, "training_acc": 53.0, "val_loss": 17.31855571269989, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19934678077698, "training_acc": 53.0, "val_loss": 17.318522930145264, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17363166809082, "training_acc": 53.0, "val_loss": 17.31874644756317, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16834211349487, "training_acc": 53.0, "val_loss": 17.318926751613617, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12471127510071, "training_acc": 53.0, "val_loss": 17.318958044052124, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17877149581909, "training_acc": 53.0, "val_loss": 17.31914132833481, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.11719131469727, "training_acc": 53.0, "val_loss": 17.319247126579285, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.10817241668701, "training_acc": 53.0, "val_loss": 17.319312691688538, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17528820037842, "training_acc": 53.0, "val_loss": 17.319536209106445, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.10647797584534, "training_acc": 53.0, "val_loss": 17.319586873054504, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14072871208191, "training_acc": 53.0, "val_loss": 17.3197403550148, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11747002601624, "training_acc": 53.0, "val_loss": 17.31998771429062, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17714405059814, "training_acc": 53.0, "val_loss": 17.320328950881958, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14363718032837, "training_acc": 53.0, "val_loss": 17.320512235164642, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.12085890769958, "training_acc": 53.0, "val_loss": 17.32046604156494, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.09772610664368, "training_acc": 53.0, "val_loss": 17.32066720724106, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.17964887619019, "training_acc": 53.0, "val_loss": 17.320625483989716, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.08463454246521, "training_acc": 53.0, "val_loss": 17.320697009563446, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.11801648139954, "training_acc": 53.0, "val_loss": 17.321035265922546, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12642741203308, "training_acc": 53.0, "val_loss": 17.32145845890045, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.11192440986633, "training_acc": 53.0, "val_loss": 17.321692407131195, "val_acc": 52.0}
