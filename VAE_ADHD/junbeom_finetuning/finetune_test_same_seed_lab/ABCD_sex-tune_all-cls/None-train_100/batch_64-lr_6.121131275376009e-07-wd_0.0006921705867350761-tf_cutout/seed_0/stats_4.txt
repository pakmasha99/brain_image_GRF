"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.17772126197815, "training_acc": 47.0, "val_loss": 18.738830089569092, "val_acc": 48.0}
{"epoch": 1, "training_loss": 75.1366639137268, "training_acc": 47.0, "val_loss": 18.669986724853516, "val_acc": 48.0}
{"epoch": 2, "training_loss": 74.82008743286133, "training_acc": 47.0, "val_loss": 18.588243424892426, "val_acc": 48.0}
{"epoch": 3, "training_loss": 74.47691178321838, "training_acc": 47.0, "val_loss": 18.504227697849274, "val_acc": 48.0}
{"epoch": 4, "training_loss": 74.15404510498047, "training_acc": 47.0, "val_loss": 18.42161864042282, "val_acc": 48.0}
{"epoch": 5, "training_loss": 73.80815649032593, "training_acc": 47.0, "val_loss": 18.341360986232758, "val_acc": 36.0}
{"epoch": 6, "training_loss": 73.49529242515564, "training_acc": 47.0, "val_loss": 18.264198303222656, "val_acc": 48.0}
{"epoch": 7, "training_loss": 73.16151356697083, "training_acc": 47.0, "val_loss": 18.18961352109909, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72.86506152153015, "training_acc": 47.0, "val_loss": 18.118709325790405, "val_acc": 52.0}
{"epoch": 9, "training_loss": 72.60893368721008, "training_acc": 47.0, "val_loss": 18.05250644683838, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.33448696136475, "training_acc": 47.0, "val_loss": 17.989684641361237, "val_acc": 52.0}
{"epoch": 11, "training_loss": 72.0875825881958, "training_acc": 47.0, "val_loss": 17.93072521686554, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.77004981040955, "training_acc": 47.0, "val_loss": 17.87583827972412, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.59518933296204, "training_acc": 47.0, "val_loss": 17.824681103229523, "val_acc": 52.0}
{"epoch": 14, "training_loss": 71.47255349159241, "training_acc": 47.0, "val_loss": 17.777234315872192, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.16481328010559, "training_acc": 47.0, "val_loss": 17.734405398368835, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.98774433135986, "training_acc": 47.0, "val_loss": 17.694823443889618, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.86409401893616, "training_acc": 47.0, "val_loss": 17.658062279224396, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.7422034740448, "training_acc": 47.0, "val_loss": 17.625287175178528, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.58708500862122, "training_acc": 47.0, "val_loss": 17.595577239990234, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.3928382396698, "training_acc": 47.0, "val_loss": 17.568108439445496, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.28753972053528, "training_acc": 47.0, "val_loss": 17.542506754398346, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.18839144706726, "training_acc": 47.0, "val_loss": 17.51856803894043, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.11231350898743, "training_acc": 47.0, "val_loss": 17.495788633823395, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.97503161430359, "training_acc": 47.0, "val_loss": 17.474517226219177, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.91480898857117, "training_acc": 47.0, "val_loss": 17.456208169460297, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.84038281440735, "training_acc": 47.0, "val_loss": 17.440108954906464, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.7395887374878, "training_acc": 47.0, "val_loss": 17.425361275672913, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.7089569568634, "training_acc": 47.0, "val_loss": 17.411406338214874, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.64179706573486, "training_acc": 47.0, "val_loss": 17.399480938911438, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.55062055587769, "training_acc": 47.0, "val_loss": 17.38877445459366, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.50025463104248, "training_acc": 47.0, "val_loss": 17.378585040569305, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.48087477684021, "training_acc": 47.0, "val_loss": 17.370028793811798, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.39830780029297, "training_acc": 47.0, "val_loss": 17.36285537481308, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.44028377532959, "training_acc": 47.0, "val_loss": 17.355620861053467, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.32991766929626, "training_acc": 47.0, "val_loss": 17.34953224658966, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.31690621376038, "training_acc": 46.0, "val_loss": 17.344290018081665, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.28037190437317, "training_acc": 62.0, "val_loss": 17.340171337127686, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.2685432434082, "training_acc": 51.0, "val_loss": 17.33677089214325, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.23414635658264, "training_acc": 53.0, "val_loss": 17.33364760875702, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.2196888923645, "training_acc": 53.0, "val_loss": 17.331096529960632, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.33156156539917, "training_acc": 53.0, "val_loss": 17.329129576683044, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.20714855194092, "training_acc": 53.0, "val_loss": 17.32739955186844, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.15505695343018, "training_acc": 53.0, "val_loss": 17.326129972934723, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.19470191001892, "training_acc": 53.0, "val_loss": 17.324814200401306, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15241932868958, "training_acc": 53.0, "val_loss": 17.324121296405792, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.18510174751282, "training_acc": 53.0, "val_loss": 17.323392629623413, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.18785786628723, "training_acc": 53.0, "val_loss": 17.323067784309387, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.11984157562256, "training_acc": 53.0, "val_loss": 17.32262372970581, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.1039171218872, "training_acc": 53.0, "val_loss": 17.322658002376556, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.15795826911926, "training_acc": 53.0, "val_loss": 17.322534322738647, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.09611368179321, "training_acc": 53.0, "val_loss": 17.322590947151184, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.04972243309021, "training_acc": 53.0, "val_loss": 17.322690784931183, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.1677176952362, "training_acc": 53.0, "val_loss": 17.322877049446106, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.17497944831848, "training_acc": 53.0, "val_loss": 17.323105037212372, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.0726671218872, "training_acc": 53.0, "val_loss": 17.323318123817444, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.130215883255, "training_acc": 53.0, "val_loss": 17.323462665081024, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.09530401229858, "training_acc": 53.0, "val_loss": 17.323632538318634, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13777875900269, "training_acc": 53.0, "val_loss": 17.323942482471466, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.12644338607788, "training_acc": 53.0, "val_loss": 17.323869466781616, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.16225862503052, "training_acc": 53.0, "val_loss": 17.323987185955048, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.11783695220947, "training_acc": 53.0, "val_loss": 17.324073612689972, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.06612133979797, "training_acc": 53.0, "val_loss": 17.324455082416534, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.16865372657776, "training_acc": 53.0, "val_loss": 17.324794828891754, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.12387824058533, "training_acc": 53.0, "val_loss": 17.325063049793243, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.07362842559814, "training_acc": 53.0, "val_loss": 17.32538193464279, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.17667388916016, "training_acc": 53.0, "val_loss": 17.32557862997055, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.19116163253784, "training_acc": 53.0, "val_loss": 17.325568199157715, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.18191266059875, "training_acc": 53.0, "val_loss": 17.325301468372345, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.07474303245544, "training_acc": 53.0, "val_loss": 17.325060069561005, "val_acc": 52.0}
