"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 510.17903900146484, "training_acc": 53.0, "val_loss": 1182235443200.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3116510896436.0254, "training_acc": 47.0, "val_loss": 521918.9453125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1501301.228515625, "training_acc": 47.0, "val_loss": 54803.9306640625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 217577.11328125, "training_acc": 51.0, "val_loss": 1932.8250885009766, "val_acc": 52.0}
{"epoch": 4, "training_loss": 22594.115844726562, "training_acc": 51.0, "val_loss": 13768.464660644531, "val_acc": 52.0}
{"epoch": 5, "training_loss": 35854.492500305176, "training_acc": 53.0, "val_loss": 7963.4613037109375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 23574.47671508789, "training_acc": 47.0, "val_loss": 6172.196960449219, "val_acc": 52.0}
{"epoch": 7, "training_loss": 20716.787109375, "training_acc": 53.0, "val_loss": 772.8997707366943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 14903.713256835938, "training_acc": 43.0, "val_loss": 1478.1983375549316, "val_acc": 48.0}
{"epoch": 9, "training_loss": 13513.553344726562, "training_acc": 49.0, "val_loss": 1552.0575523376465, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6680.426177978516, "training_acc": 45.0, "val_loss": 486.4752769470215, "val_acc": 48.0}
{"epoch": 11, "training_loss": 5063.564147949219, "training_acc": 45.0, "val_loss": 1001.638126373291, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2429.8555870056152, "training_acc": 61.0, "val_loss": 81.6126823425293, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1235.1832656860352, "training_acc": 49.0, "val_loss": 416.4316177368164, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1622.8437576293945, "training_acc": 47.0, "val_loss": 111.62923574447632, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1047.333610534668, "training_acc": 39.0, "val_loss": 131.79214000701904, "val_acc": 48.0}
{"epoch": 16, "training_loss": 740.4608955383301, "training_acc": 49.0, "val_loss": 199.3812084197998, "val_acc": 52.0}
{"epoch": 17, "training_loss": 717.8296184539795, "training_acc": 53.0, "val_loss": 87.95351982116699, "val_acc": 52.0}
{"epoch": 18, "training_loss": 370.54191493988037, "training_acc": 45.0, "val_loss": 56.02772235870361, "val_acc": 48.0}
{"epoch": 19, "training_loss": 319.29662704467773, "training_acc": 43.0, "val_loss": 18.877577781677246, "val_acc": 52.0}
{"epoch": 20, "training_loss": 99.08303165435791, "training_acc": 51.0, "val_loss": 23.473307490348816, "val_acc": 48.0}
{"epoch": 21, "training_loss": 116.97015714645386, "training_acc": 43.0, "val_loss": 19.14457529783249, "val_acc": 52.0}
{"epoch": 22, "training_loss": 122.71611595153809, "training_acc": 43.0, "val_loss": 17.771048843860626, "val_acc": 52.0}
{"epoch": 23, "training_loss": 82.48234462738037, "training_acc": 50.0, "val_loss": 27.976873517036438, "val_acc": 52.0}
{"epoch": 24, "training_loss": 92.60712361335754, "training_acc": 51.0, "val_loss": 27.423983812332153, "val_acc": 48.0}
{"epoch": 25, "training_loss": 99.88897037506104, "training_acc": 47.0, "val_loss": 18.935969471931458, "val_acc": 52.0}
{"epoch": 26, "training_loss": 78.0201575756073, "training_acc": 53.0, "val_loss": 20.80066204071045, "val_acc": 52.0}
{"epoch": 27, "training_loss": 77.12246131896973, "training_acc": 51.0, "val_loss": 17.819789052009583, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.54269337654114, "training_acc": 48.0, "val_loss": 23.3233243227005, "val_acc": 52.0}
{"epoch": 29, "training_loss": 78.64281392097473, "training_acc": 59.0, "val_loss": 26.511818170547485, "val_acc": 48.0}
{"epoch": 30, "training_loss": 94.62577962875366, "training_acc": 47.0, "val_loss": 20.707206428050995, "val_acc": 52.0}
{"epoch": 31, "training_loss": 86.45307636260986, "training_acc": 53.0, "val_loss": 18.68986040353775, "val_acc": 52.0}
{"epoch": 32, "training_loss": 74.60353803634644, "training_acc": 49.0, "val_loss": 20.2545166015625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 77.91424918174744, "training_acc": 48.0, "val_loss": 18.153037130832672, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.60822606086731, "training_acc": 53.0, "val_loss": 17.40057021379471, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.35139536857605, "training_acc": 50.0, "val_loss": 17.383792996406555, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22406339645386, "training_acc": 53.0, "val_loss": 17.565694451332092, "val_acc": 52.0}
{"epoch": 37, "training_loss": 71.14381432533264, "training_acc": 47.0, "val_loss": 19.538718461990356, "val_acc": 52.0}
{"epoch": 38, "training_loss": 73.40871000289917, "training_acc": 53.0, "val_loss": 18.699605762958527, "val_acc": 48.0}
{"epoch": 39, "training_loss": 78.26515245437622, "training_acc": 47.0, "val_loss": 17.41473376750946, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.91081190109253, "training_acc": 52.0, "val_loss": 19.812361896038055, "val_acc": 52.0}
{"epoch": 41, "training_loss": 76.83591485023499, "training_acc": 53.0, "val_loss": 17.648853361606598, "val_acc": 52.0}
{"epoch": 42, "training_loss": 71.36798596382141, "training_acc": 45.0, "val_loss": 17.625312507152557, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.52077341079712, "training_acc": 47.0, "val_loss": 17.342808842658997, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.20553278923035, "training_acc": 52.0, "val_loss": 17.527347803115845, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.65901565551758, "training_acc": 53.0, "val_loss": 17.359720170497894, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.87546873092651, "training_acc": 53.0, "val_loss": 17.36319661140442, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.97912883758545, "training_acc": 53.0, "val_loss": 17.31528490781784, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.03602838516235, "training_acc": 53.0, "val_loss": 17.337146401405334, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.36388826370239, "training_acc": 44.0, "val_loss": 17.340853810310364, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.12514472007751, "training_acc": 57.0, "val_loss": 17.329907417297363, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.8413097858429, "training_acc": 53.0, "val_loss": 17.35493093729019, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.42517495155334, "training_acc": 53.0, "val_loss": 17.353706061840057, "val_acc": 52.0}
{"epoch": 53, "training_loss": 70.4380190372467, "training_acc": 54.0, "val_loss": 17.38956719636917, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.52955222129822, "training_acc": 53.0, "val_loss": 17.543788254261017, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.92200207710266, "training_acc": 53.0, "val_loss": 17.375299334526062, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.31577229499817, "training_acc": 53.0, "val_loss": 17.358766496181488, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.83583903312683, "training_acc": 48.0, "val_loss": 17.531633377075195, "val_acc": 52.0}
{"epoch": 58, "training_loss": 70.71227025985718, "training_acc": 47.0, "val_loss": 17.34960824251175, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.23590779304504, "training_acc": 53.0, "val_loss": 17.509157955646515, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.6993772983551, "training_acc": 53.0, "val_loss": 17.558902502059937, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.7335205078125, "training_acc": 53.0, "val_loss": 17.342014610767365, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.21628999710083, "training_acc": 52.0, "val_loss": 17.58679896593094, "val_acc": 52.0}
{"epoch": 63, "training_loss": 70.86002826690674, "training_acc": 47.0, "val_loss": 17.490150034427643, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.32091426849365, "training_acc": 48.0, "val_loss": 17.38223433494568, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.68472599983215, "training_acc": 53.0, "val_loss": 17.94670671224594, "val_acc": 52.0}
{"epoch": 66, "training_loss": 71.00945019721985, "training_acc": 53.0, "val_loss": 17.657428979873657, "val_acc": 52.0}
