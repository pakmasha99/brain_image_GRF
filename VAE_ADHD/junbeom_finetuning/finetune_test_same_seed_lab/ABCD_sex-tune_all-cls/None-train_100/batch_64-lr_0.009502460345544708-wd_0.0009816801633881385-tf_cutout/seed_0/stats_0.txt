"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 525.8512496948242, "training_acc": 50.0, "val_loss": 14948075200.0, "val_acc": 56.0}
{"epoch": 1, "training_loss": 40066981830.78125, "training_acc": 52.0, "val_loss": 883600.29296875, "val_acc": 44.0}
{"epoch": 2, "training_loss": 2233324.1889648438, "training_acc": 48.0, "val_loss": 303128.6376953125, "val_acc": 56.0}
{"epoch": 3, "training_loss": 795899.2485351562, "training_acc": 54.0, "val_loss": 2878.9011001586914, "val_acc": 56.0}
{"epoch": 4, "training_loss": 27131.347900390625, "training_acc": 50.0, "val_loss": 2919.431495666504, "val_acc": 44.0}
{"epoch": 5, "training_loss": 9213.44369506836, "training_acc": 44.0, "val_loss": 651.9313812255859, "val_acc": 44.0}
{"epoch": 6, "training_loss": 2730.9082794189453, "training_acc": 50.0, "val_loss": 823.5326766967773, "val_acc": 44.0}
{"epoch": 7, "training_loss": 2793.357276916504, "training_acc": 52.0, "val_loss": 79.5896589756012, "val_acc": 44.0}
{"epoch": 8, "training_loss": 837.5959396362305, "training_acc": 42.0, "val_loss": 464.24598693847656, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1483.1118850708008, "training_acc": 48.0, "val_loss": 15289.845275878906, "val_acc": 44.0}
{"epoch": 10, "training_loss": 35459.20101976395, "training_acc": 50.0, "val_loss": 1139.0698432922363, "val_acc": 56.0}
{"epoch": 11, "training_loss": 7294.842742919922, "training_acc": 52.0, "val_loss": 1183.9621543884277, "val_acc": 56.0}
{"epoch": 12, "training_loss": 14291.902709960938, "training_acc": 54.0, "val_loss": 835.9256744384766, "val_acc": 44.0}
{"epoch": 13, "training_loss": 3522.031707763672, "training_acc": 52.0, "val_loss": 629.998254776001, "val_acc": 56.0}
{"epoch": 14, "training_loss": 3366.1963653564453, "training_acc": 48.0, "val_loss": 18.63061636686325, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2199.4740142822266, "training_acc": 53.0, "val_loss": 20920.2880859375, "val_acc": 56.0}
{"epoch": 16, "training_loss": 58046.70245361328, "training_acc": 52.0, "val_loss": 1276.4413833618164, "val_acc": 44.0}
{"epoch": 17, "training_loss": 3438.87890625, "training_acc": 50.0, "val_loss": 747.21360206604, "val_acc": 44.0}
{"epoch": 18, "training_loss": 4053.5862579345703, "training_acc": 50.0, "val_loss": 704.1356563568115, "val_acc": 56.0}
{"epoch": 19, "training_loss": 2449.1087799072266, "training_acc": 52.0, "val_loss": 27.615681290626526, "val_acc": 44.0}
{"epoch": 20, "training_loss": 875.0535354614258, "training_acc": 52.0, "val_loss": 123.49326610565186, "val_acc": 44.0}
{"epoch": 21, "training_loss": 625.1369667053223, "training_acc": 54.0, "val_loss": 96.5295672416687, "val_acc": 56.0}
{"epoch": 22, "training_loss": 543.114429473877, "training_acc": 56.0, "val_loss": 189.82925415039062, "val_acc": 44.0}
{"epoch": 23, "training_loss": 532.4446144104004, "training_acc": 46.0, "val_loss": 17.149843275547028, "val_acc": 56.0}
{"epoch": 24, "training_loss": 146.36405658721924, "training_acc": 53.0, "val_loss": 50.19717216491699, "val_acc": 56.0}
{"epoch": 25, "training_loss": 297.19659423828125, "training_acc": 48.0, "val_loss": 76.5550971031189, "val_acc": 56.0}
{"epoch": 26, "training_loss": 247.55395984649658, "training_acc": 52.0, "val_loss": 111.34604215621948, "val_acc": 44.0}
{"epoch": 27, "training_loss": 400.9910593032837, "training_acc": 48.0, "val_loss": 25.428912043571472, "val_acc": 44.0}
{"epoch": 28, "training_loss": 119.95955657958984, "training_acc": 54.0, "val_loss": 41.87913537025452, "val_acc": 56.0}
{"epoch": 29, "training_loss": 146.45526432991028, "training_acc": 52.0, "val_loss": 25.18233060836792, "val_acc": 44.0}
{"epoch": 30, "training_loss": 91.76764798164368, "training_acc": 48.0, "val_loss": 17.352373898029327, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.26977157592773, "training_acc": 59.0, "val_loss": 18.46831440925598, "val_acc": 56.0}
{"epoch": 32, "training_loss": 74.25482964515686, "training_acc": 52.0, "val_loss": 20.063140988349915, "val_acc": 44.0}
{"epoch": 33, "training_loss": 74.2179594039917, "training_acc": 47.0, "val_loss": 18.43838393688202, "val_acc": 56.0}
{"epoch": 34, "training_loss": 73.70508313179016, "training_acc": 52.0, "val_loss": 23.221774399280548, "val_acc": 44.0}
{"epoch": 35, "training_loss": 80.78553509712219, "training_acc": 51.0, "val_loss": 18.139921128749847, "val_acc": 56.0}
{"epoch": 36, "training_loss": 75.09971499443054, "training_acc": 52.0, "val_loss": 17.09882766008377, "val_acc": 56.0}
{"epoch": 37, "training_loss": 70.40756916999817, "training_acc": 43.0, "val_loss": 17.33384281396866, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.94245028495789, "training_acc": 45.0, "val_loss": 17.087186872959137, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.93886518478394, "training_acc": 52.0, "val_loss": 17.072132229804993, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.75608682632446, "training_acc": 52.0, "val_loss": 17.259536683559418, "val_acc": 56.0}
{"epoch": 41, "training_loss": 70.36091542243958, "training_acc": 47.0, "val_loss": 17.193569242954254, "val_acc": 56.0}
{"epoch": 42, "training_loss": 70.60767030715942, "training_acc": 42.0, "val_loss": 17.057162523269653, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.78342056274414, "training_acc": 52.0, "val_loss": 17.107868194580078, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.47918438911438, "training_acc": 50.0, "val_loss": 17.66403466463089, "val_acc": 56.0}
{"epoch": 45, "training_loss": 70.27627611160278, "training_acc": 48.0, "val_loss": 17.423179745674133, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.73175120353699, "training_acc": 51.0, "val_loss": 17.123311758041382, "val_acc": 56.0}
{"epoch": 47, "training_loss": 68.81093335151672, "training_acc": 50.0, "val_loss": 17.058666050434113, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.61612010002136, "training_acc": 52.0, "val_loss": 17.056137323379517, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.26531171798706, "training_acc": 52.0, "val_loss": 17.12791472673416, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.16480350494385, "training_acc": 53.0, "val_loss": 17.45201051235199, "val_acc": 56.0}
{"epoch": 51, "training_loss": 70.02300381660461, "training_acc": 46.0, "val_loss": 17.464907467365265, "val_acc": 56.0}
{"epoch": 52, "training_loss": 70.27135992050171, "training_acc": 49.0, "val_loss": 17.181317508220673, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.28168225288391, "training_acc": 53.0, "val_loss": 17.090660333633423, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.165278673172, "training_acc": 52.0, "val_loss": 17.085960507392883, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.41933536529541, "training_acc": 52.0, "val_loss": 17.099598050117493, "val_acc": 56.0}
{"epoch": 56, "training_loss": 68.98504757881165, "training_acc": 52.0, "val_loss": 17.2659695148468, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.50475430488586, "training_acc": 51.0, "val_loss": 17.416907846927643, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.69770431518555, "training_acc": 48.0, "val_loss": 17.209579050540924, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.35910558700562, "training_acc": 49.0, "val_loss": 17.093543708324432, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.81151247024536, "training_acc": 52.0, "val_loss": 17.074482142925262, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.5017318725586, "training_acc": 52.0, "val_loss": 17.121589183807373, "val_acc": 56.0}
{"epoch": 62, "training_loss": 69.39364576339722, "training_acc": 53.0, "val_loss": 17.265892028808594, "val_acc": 56.0}
{"epoch": 63, "training_loss": 69.58568358421326, "training_acc": 49.0, "val_loss": 17.290976643562317, "val_acc": 56.0}
{"epoch": 64, "training_loss": 69.23419308662415, "training_acc": 51.0, "val_loss": 17.12532639503479, "val_acc": 56.0}
{"epoch": 65, "training_loss": 69.41672611236572, "training_acc": 52.0, "val_loss": 17.085327208042145, "val_acc": 56.0}
{"epoch": 66, "training_loss": 69.70195317268372, "training_acc": 52.0, "val_loss": 17.089805006980896, "val_acc": 56.0}
{"epoch": 67, "training_loss": 69.98040533065796, "training_acc": 52.0, "val_loss": 17.124198377132416, "val_acc": 56.0}
