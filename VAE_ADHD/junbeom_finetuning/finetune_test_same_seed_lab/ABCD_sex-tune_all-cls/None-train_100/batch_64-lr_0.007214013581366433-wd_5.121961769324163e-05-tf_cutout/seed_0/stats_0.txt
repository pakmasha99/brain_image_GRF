"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 390.82186126708984, "training_acc": 50.0, "val_loss": 68621056.25, "val_acc": 56.0}
{"epoch": 1, "training_loss": 185423285.359375, "training_acc": 52.0, "val_loss": 50184.02099609375, "val_acc": 44.0}
{"epoch": 2, "training_loss": 128993.70275878906, "training_acc": 48.0, "val_loss": 1124.5768547058105, "val_acc": 56.0}
{"epoch": 3, "training_loss": 3219.0305557250977, "training_acc": 54.0, "val_loss": 628.7253379821777, "val_acc": 56.0}
{"epoch": 4, "training_loss": 1852.1722230911255, "training_acc": 52.0, "val_loss": 384.20939445495605, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1121.7962532043457, "training_acc": 48.0, "val_loss": 27.642175555229187, "val_acc": 44.0}
{"epoch": 6, "training_loss": 232.6814136505127, "training_acc": 50.0, "val_loss": 148.70315790176392, "val_acc": 44.0}
{"epoch": 7, "training_loss": 472.88537788391113, "training_acc": 52.0, "val_loss": 40.43450355529785, "val_acc": 56.0}
{"epoch": 8, "training_loss": 181.35042572021484, "training_acc": 58.0, "val_loss": 27.753719687461853, "val_acc": 44.0}
{"epoch": 9, "training_loss": 100.56960320472717, "training_acc": 48.0, "val_loss": 19.00814026594162, "val_acc": 56.0}
{"epoch": 10, "training_loss": 78.13749289512634, "training_acc": 50.0, "val_loss": 17.12273508310318, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.52930068969727, "training_acc": 52.0, "val_loss": 22.4138006567955, "val_acc": 44.0}
{"epoch": 12, "training_loss": 81.63091778755188, "training_acc": 46.0, "val_loss": 17.208360135555267, "val_acc": 56.0}
{"epoch": 13, "training_loss": 70.15994882583618, "training_acc": 52.0, "val_loss": 17.13929921388626, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.12269639968872, "training_acc": 48.0, "val_loss": 17.145901918411255, "val_acc": 56.0}
{"epoch": 15, "training_loss": 70.14230799674988, "training_acc": 46.0, "val_loss": 17.191165685653687, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.43400049209595, "training_acc": 52.0, "val_loss": 17.173926532268524, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.36628651618958, "training_acc": 50.0, "val_loss": 17.155466973781586, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.361083984375, "training_acc": 52.0, "val_loss": 17.363519966602325, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.42450070381165, "training_acc": 50.0, "val_loss": 17.346565425395966, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.54372763633728, "training_acc": 47.0, "val_loss": 17.20348745584488, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.1736798286438, "training_acc": 52.0, "val_loss": 17.162536084651947, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.27895450592041, "training_acc": 52.0, "val_loss": 17.22077876329422, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.03074717521667, "training_acc": 54.0, "val_loss": 17.920584976673126, "val_acc": 56.0}
{"epoch": 24, "training_loss": 70.56053900718689, "training_acc": 48.0, "val_loss": 17.254512012004852, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.57458472251892, "training_acc": 48.0, "val_loss": 17.16424971818924, "val_acc": 56.0}
{"epoch": 26, "training_loss": 72.96411108970642, "training_acc": 52.0, "val_loss": 17.308959364891052, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.38402676582336, "training_acc": 52.0, "val_loss": 17.535224556922913, "val_acc": 56.0}
{"epoch": 28, "training_loss": 71.47226119041443, "training_acc": 48.0, "val_loss": 17.520734667778015, "val_acc": 56.0}
{"epoch": 29, "training_loss": 71.71267247200012, "training_acc": 52.0, "val_loss": 17.170539498329163, "val_acc": 56.0}
