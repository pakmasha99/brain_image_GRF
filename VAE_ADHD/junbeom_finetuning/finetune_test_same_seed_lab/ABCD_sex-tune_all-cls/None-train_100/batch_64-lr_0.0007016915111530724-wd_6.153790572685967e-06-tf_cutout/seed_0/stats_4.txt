"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 104.08957147598267, "training_acc": 45.0, "val_loss": 26.518920063972473, "val_acc": 52.0}
{"epoch": 1, "training_loss": 173.381516456604, "training_acc": 49.0, "val_loss": 18.62652599811554, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72.25893521308899, "training_acc": 47.0, "val_loss": 17.3126220703125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.08586955070496, "training_acc": 53.0, "val_loss": 17.522306740283966, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.7768714427948, "training_acc": 53.0, "val_loss": 17.318446934223175, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.47866106033325, "training_acc": 49.0, "val_loss": 17.33463406562805, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2924816608429, "training_acc": 49.0, "val_loss": 17.376743257045746, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.31817507743835, "training_acc": 53.0, "val_loss": 17.314258217811584, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.29947662353516, "training_acc": 53.0, "val_loss": 17.318034172058105, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22433066368103, "training_acc": 53.0, "val_loss": 17.308394610881805, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.90833044052124, "training_acc": 53.0, "val_loss": 17.33139455318451, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17452359199524, "training_acc": 53.0, "val_loss": 17.305150628089905, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20866632461548, "training_acc": 53.0, "val_loss": 17.315708100795746, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.27345705032349, "training_acc": 53.0, "val_loss": 17.311803996562958, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27909421920776, "training_acc": 53.0, "val_loss": 17.308102548122406, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19247555732727, "training_acc": 53.0, "val_loss": 17.307229340076447, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1761212348938, "training_acc": 53.0, "val_loss": 17.30603575706482, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1438558101654, "training_acc": 53.0, "val_loss": 17.309078574180603, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13989901542664, "training_acc": 53.0, "val_loss": 17.321164906024933, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16844534873962, "training_acc": 53.0, "val_loss": 17.354366183280945, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.31477403640747, "training_acc": 53.0, "val_loss": 17.352600395679474, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17686486244202, "training_acc": 53.0, "val_loss": 17.318490147590637, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14048528671265, "training_acc": 53.0, "val_loss": 17.30610579252243, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19806790351868, "training_acc": 53.0, "val_loss": 17.307589948177338, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18527722358704, "training_acc": 53.0, "val_loss": 17.30785369873047, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1801369190216, "training_acc": 53.0, "val_loss": 17.307883501052856, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.23045086860657, "training_acc": 53.0, "val_loss": 17.307166755199432, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2364490032196, "training_acc": 53.0, "val_loss": 17.308209836483, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13660097122192, "training_acc": 53.0, "val_loss": 17.311106622219086, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15107798576355, "training_acc": 53.0, "val_loss": 17.313776910305023, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14175462722778, "training_acc": 53.0, "val_loss": 17.321528494358063, "val_acc": 52.0}
