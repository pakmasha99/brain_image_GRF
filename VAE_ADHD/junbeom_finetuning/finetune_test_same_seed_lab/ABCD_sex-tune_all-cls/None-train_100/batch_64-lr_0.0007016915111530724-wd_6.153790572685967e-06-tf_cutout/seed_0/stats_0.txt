"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.66002321243286, "training_acc": 50.0, "val_loss": 32.983145117759705, "val_acc": 56.0}
{"epoch": 1, "training_loss": 118.9862265586853, "training_acc": 52.0, "val_loss": 17.26095974445343, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.93112230300903, "training_acc": 52.0, "val_loss": 17.193016409873962, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.12462306022644, "training_acc": 52.0, "val_loss": 17.72391051054001, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.8528835773468, "training_acc": 50.0, "val_loss": 17.19430536031723, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.7889666557312, "training_acc": 52.0, "val_loss": 17.23436564207077, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.37091159820557, "training_acc": 50.0, "val_loss": 17.43476390838623, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.48353338241577, "training_acc": 48.0, "val_loss": 17.27234274148941, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.60123825073242, "training_acc": 52.0, "val_loss": 17.19154864549637, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24866461753845, "training_acc": 52.0, "val_loss": 17.213252186775208, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.244544506073, "training_acc": 52.0, "val_loss": 17.246703803539276, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.23663711547852, "training_acc": 52.0, "val_loss": 17.263232171535492, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.25441932678223, "training_acc": 52.0, "val_loss": 17.27098822593689, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.27909898757935, "training_acc": 52.0, "val_loss": 17.279167473316193, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25303196907043, "training_acc": 52.0, "val_loss": 17.25299209356308, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.22631454467773, "training_acc": 52.0, "val_loss": 17.220589518547058, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25637769699097, "training_acc": 52.0, "val_loss": 17.191031575202942, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.26023316383362, "training_acc": 52.0, "val_loss": 17.18687415122986, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2687566280365, "training_acc": 52.0, "val_loss": 17.19471514225006, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.24990391731262, "training_acc": 52.0, "val_loss": 17.20883846282959, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.25805187225342, "training_acc": 52.0, "val_loss": 17.232781648635864, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26528310775757, "training_acc": 52.0, "val_loss": 17.243951559066772, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.2732207775116, "training_acc": 52.0, "val_loss": 17.232780158519745, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.23099207878113, "training_acc": 52.0, "val_loss": 17.24041849374771, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.22508358955383, "training_acc": 52.0, "val_loss": 17.25534200668335, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25179958343506, "training_acc": 52.0, "val_loss": 17.273691296577454, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.34466552734375, "training_acc": 52.0, "val_loss": 17.268620431423187, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23516821861267, "training_acc": 52.0, "val_loss": 17.29189306497574, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.28990912437439, "training_acc": 52.0, "val_loss": 17.304310202598572, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2662365436554, "training_acc": 52.0, "val_loss": 17.28609949350357, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.35703325271606, "training_acc": 52.0, "val_loss": 17.25739687681198, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27636909484863, "training_acc": 52.0, "val_loss": 17.256397008895874, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.2360246181488, "training_acc": 52.0, "val_loss": 17.235194146633148, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.21593499183655, "training_acc": 52.0, "val_loss": 17.222754657268524, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2428777217865, "training_acc": 52.0, "val_loss": 17.211174964904785, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23408722877502, "training_acc": 52.0, "val_loss": 17.212317883968353, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23413610458374, "training_acc": 52.0, "val_loss": 17.21627414226532, "val_acc": 56.0}
