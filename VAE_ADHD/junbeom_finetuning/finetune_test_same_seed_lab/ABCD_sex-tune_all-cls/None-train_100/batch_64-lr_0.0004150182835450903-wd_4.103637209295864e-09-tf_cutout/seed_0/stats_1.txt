"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.16763114929199, "training_acc": 49.0, "val_loss": 18.50644201040268, "val_acc": 52.0}
{"epoch": 1, "training_loss": 92.84343194961548, "training_acc": 49.0, "val_loss": 17.41509586572647, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.18115210533142, "training_acc": 53.0, "val_loss": 17.555083334445953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.56811237335205, "training_acc": 53.0, "val_loss": 17.310968041419983, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.04377841949463, "training_acc": 41.0, "val_loss": 17.30627715587616, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.98636603355408, "training_acc": 53.0, "val_loss": 17.50390976667404, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.2013328075409, "training_acc": 53.0, "val_loss": 17.383795976638794, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.42134809494019, "training_acc": 53.0, "val_loss": 17.379721999168396, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.37002921104431, "training_acc": 53.0, "val_loss": 17.35895127058029, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.34537243843079, "training_acc": 53.0, "val_loss": 17.331120371818542, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16674709320068, "training_acc": 53.0, "val_loss": 17.3080712556839, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16797184944153, "training_acc": 53.0, "val_loss": 17.31363981962204, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.28483438491821, "training_acc": 53.0, "val_loss": 17.324376106262207, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24625563621521, "training_acc": 53.0, "val_loss": 17.315608263015747, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1796350479126, "training_acc": 53.0, "val_loss": 17.316627502441406, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13230109214783, "training_acc": 53.0, "val_loss": 17.336276173591614, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.42917251586914, "training_acc": 53.0, "val_loss": 17.333093285560608, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.30660796165466, "training_acc": 53.0, "val_loss": 17.357276380062103, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.27185845375061, "training_acc": 53.0, "val_loss": 17.345677316188812, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15266156196594, "training_acc": 53.0, "val_loss": 17.32190102338791, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18350601196289, "training_acc": 53.0, "val_loss": 17.31330305337906, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12897443771362, "training_acc": 53.0, "val_loss": 17.312975227832794, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14910221099854, "training_acc": 53.0, "val_loss": 17.31303781270981, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14756798744202, "training_acc": 53.0, "val_loss": 17.31339991092682, "val_acc": 52.0}
