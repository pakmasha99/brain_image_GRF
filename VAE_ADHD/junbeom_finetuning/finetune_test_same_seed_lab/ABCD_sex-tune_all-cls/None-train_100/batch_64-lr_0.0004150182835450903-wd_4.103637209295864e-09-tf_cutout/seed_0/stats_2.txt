"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.69417691230774, "training_acc": 55.0, "val_loss": 18.029440939426422, "val_acc": 52.0}
{"epoch": 1, "training_loss": 72.90810561180115, "training_acc": 53.0, "val_loss": 17.504197359085083, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.64515566825867, "training_acc": 51.0, "val_loss": 17.55724996328354, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.87538075447083, "training_acc": 53.0, "val_loss": 17.34536737203598, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.17374777793884, "training_acc": 53.0, "val_loss": 17.318378388881683, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.27513837814331, "training_acc": 53.0, "val_loss": 17.327162623405457, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.27235174179077, "training_acc": 53.0, "val_loss": 17.344626784324646, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4284987449646, "training_acc": 45.0, "val_loss": 17.324194312095642, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.39956331253052, "training_acc": 43.0, "val_loss": 17.319467663764954, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.36674404144287, "training_acc": 53.0, "val_loss": 17.367030680179596, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.34718775749207, "training_acc": 53.0, "val_loss": 17.340321838855743, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.06639790534973, "training_acc": 53.0, "val_loss": 17.321330308914185, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.24393844604492, "training_acc": 53.0, "val_loss": 17.32817441225052, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24067902565002, "training_acc": 53.0, "val_loss": 17.319801449775696, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21237564086914, "training_acc": 53.0, "val_loss": 17.320775985717773, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.08493566513062, "training_acc": 53.0, "val_loss": 17.368583381175995, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.64993619918823, "training_acc": 53.0, "val_loss": 17.38380640745163, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.50123810768127, "training_acc": 53.0, "val_loss": 17.325007915496826, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1293032169342, "training_acc": 53.0, "val_loss": 17.320041358470917, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12161135673523, "training_acc": 53.0, "val_loss": 17.31872260570526, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16400289535522, "training_acc": 53.0, "val_loss": 17.317692935466766, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13384056091309, "training_acc": 53.0, "val_loss": 17.3145592212677, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14462685585022, "training_acc": 53.0, "val_loss": 17.314450442790985, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14060997962952, "training_acc": 53.0, "val_loss": 17.31583923101425, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13381171226501, "training_acc": 53.0, "val_loss": 17.31734573841095, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11918616294861, "training_acc": 53.0, "val_loss": 17.323610186576843, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14460754394531, "training_acc": 53.0, "val_loss": 17.33594983816147, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16694664955139, "training_acc": 53.0, "val_loss": 17.335359752178192, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13390469551086, "training_acc": 53.0, "val_loss": 17.321784794330597, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11380648612976, "training_acc": 53.0, "val_loss": 17.315608263015747, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15958333015442, "training_acc": 53.0, "val_loss": 17.314258217811584, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13772320747375, "training_acc": 53.0, "val_loss": 17.31577217578888, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18689203262329, "training_acc": 53.0, "val_loss": 17.31785237789154, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15030646324158, "training_acc": 53.0, "val_loss": 17.327991127967834, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1058566570282, "training_acc": 53.0, "val_loss": 17.359095811843872, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.27321410179138, "training_acc": 53.0, "val_loss": 17.378152906894684, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.29945063591003, "training_acc": 53.0, "val_loss": 17.354966700077057, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18805742263794, "training_acc": 53.0, "val_loss": 17.341411113739014, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.24544167518616, "training_acc": 53.0, "val_loss": 17.323869466781616, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15543055534363, "training_acc": 53.0, "val_loss": 17.320506274700165, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13040280342102, "training_acc": 53.0, "val_loss": 17.323467135429382, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15006375312805, "training_acc": 53.0, "val_loss": 17.327140271663666, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.17866587638855, "training_acc": 53.0, "val_loss": 17.338472604751587, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14016461372375, "training_acc": 53.0, "val_loss": 17.331424355506897, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.14320492744446, "training_acc": 53.0, "val_loss": 17.326392233371735, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.11491870880127, "training_acc": 53.0, "val_loss": 17.327405512332916, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15219211578369, "training_acc": 53.0, "val_loss": 17.326384782791138, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.12631273269653, "training_acc": 53.0, "val_loss": 17.333942651748657, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.08361983299255, "training_acc": 53.0, "val_loss": 17.335666716098785, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13210225105286, "training_acc": 53.0, "val_loss": 17.332300543785095, "val_acc": 52.0}
