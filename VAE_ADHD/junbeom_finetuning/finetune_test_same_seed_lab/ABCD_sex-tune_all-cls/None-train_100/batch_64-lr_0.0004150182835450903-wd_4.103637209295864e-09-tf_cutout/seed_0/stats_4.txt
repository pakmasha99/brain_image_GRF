"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 75.87551259994507, "training_acc": 49.0, "val_loss": 17.522068321704865, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.49178433418274, "training_acc": 55.0, "val_loss": 30.20479679107666, "val_acc": 52.0}
{"epoch": 2, "training_loss": 100.0250735282898, "training_acc": 53.0, "val_loss": 17.365257441997528, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.47361826896667, "training_acc": 53.0, "val_loss": 17.309339344501495, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38591384887695, "training_acc": 53.0, "val_loss": 17.31269359588623, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15717458724976, "training_acc": 53.0, "val_loss": 17.32661724090576, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.22695064544678, "training_acc": 41.0, "val_loss": 17.309147119522095, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.12753224372864, "training_acc": 53.0, "val_loss": 17.411354184150696, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.32221722602844, "training_acc": 53.0, "val_loss": 17.312152683734894, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.49372005462646, "training_acc": 53.0, "val_loss": 17.310641705989838, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16676259040833, "training_acc": 53.0, "val_loss": 17.31438636779785, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14201617240906, "training_acc": 53.0, "val_loss": 17.330707609653473, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2252995967865, "training_acc": 53.0, "val_loss": 17.331184446811676, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18057179450989, "training_acc": 53.0, "val_loss": 17.3123300075531, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2202000617981, "training_acc": 53.0, "val_loss": 17.309503257274628, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15264630317688, "training_acc": 53.0, "val_loss": 17.31221377849579, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14635443687439, "training_acc": 53.0, "val_loss": 17.314180731773376, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12499618530273, "training_acc": 53.0, "val_loss": 17.312881350517273, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13477945327759, "training_acc": 53.0, "val_loss": 17.31226295232773, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14400935173035, "training_acc": 53.0, "val_loss": 17.31221228837967, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13469505310059, "training_acc": 53.0, "val_loss": 17.313970625400543, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12762117385864, "training_acc": 53.0, "val_loss": 17.31853485107422, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17621302604675, "training_acc": 53.0, "val_loss": 17.324736714363098, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14198994636536, "training_acc": 53.0, "val_loss": 17.318381369113922, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13990569114685, "training_acc": 53.0, "val_loss": 17.314906418323517, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11315679550171, "training_acc": 53.0, "val_loss": 17.31467843055725, "val_acc": 52.0}
