"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.54959487915039, "training_acc": 47.0, "val_loss": 17.58088618516922, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.59028196334839, "training_acc": 47.0, "val_loss": 17.512167990207672, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.1659984588623, "training_acc": 47.0, "val_loss": 17.44523197412491, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.78518986701965, "training_acc": 47.0, "val_loss": 17.391280829906464, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.629399061203, "training_acc": 47.0, "val_loss": 17.3491969704628, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.34866309165955, "training_acc": 47.0, "val_loss": 17.326129972934723, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18541073799133, "training_acc": 53.0, "val_loss": 17.317870259284973, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.20051670074463, "training_acc": 53.0, "val_loss": 17.322127521038055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18879008293152, "training_acc": 53.0, "val_loss": 17.333072423934937, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15281391143799, "training_acc": 53.0, "val_loss": 17.343254387378693, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16236567497253, "training_acc": 53.0, "val_loss": 17.350374162197113, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12822365760803, "training_acc": 53.0, "val_loss": 17.35237091779709, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12945604324341, "training_acc": 53.0, "val_loss": 17.356228828430176, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13336300849915, "training_acc": 53.0, "val_loss": 17.356009781360626, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13737893104553, "training_acc": 53.0, "val_loss": 17.351098358631134, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12176084518433, "training_acc": 53.0, "val_loss": 17.34527498483658, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1217999458313, "training_acc": 53.0, "val_loss": 17.34059453010559, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16537761688232, "training_acc": 53.0, "val_loss": 17.33701229095459, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10787773132324, "training_acc": 53.0, "val_loss": 17.336715757846832, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10887455940247, "training_acc": 53.0, "val_loss": 17.336924374103546, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12559580802917, "training_acc": 53.0, "val_loss": 17.334169149398804, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.09986972808838, "training_acc": 53.0, "val_loss": 17.33408272266388, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.08853578567505, "training_acc": 53.0, "val_loss": 17.333851754665375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.08522534370422, "training_acc": 53.0, "val_loss": 17.333385348320007, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09234714508057, "training_acc": 53.0, "val_loss": 17.331239581108093, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.07123136520386, "training_acc": 53.0, "val_loss": 17.33010858297348, "val_acc": 52.0}
