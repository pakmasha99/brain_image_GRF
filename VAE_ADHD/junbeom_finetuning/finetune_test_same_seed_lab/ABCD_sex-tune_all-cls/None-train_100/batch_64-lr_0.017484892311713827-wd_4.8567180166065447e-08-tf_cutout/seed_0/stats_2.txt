"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1914.0322914123535, "training_acc": 41.0, "val_loss": 4.441079197191897e+21, "val_acc": 48.0}
{"epoch": 1, "training_loss": 9.796034002872514e+21, "training_acc": 59.0, "val_loss": 9408122.65625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 568257496.0, "training_acc": 51.0, "val_loss": 66706700.0, "val_acc": 52.0}
{"epoch": 3, "training_loss": 269057265.0, "training_acc": 53.0, "val_loss": 16080117.1875, "val_acc": 48.0}
{"epoch": 4, "training_loss": 118747822.5, "training_acc": 43.0, "val_loss": 38305162.5, "val_acc": 48.0}
{"epoch": 5, "training_loss": 111093138.625, "training_acc": 47.0, "val_loss": 1585630.56640625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 19235116.25, "training_acc": 53.0, "val_loss": 6984214.84375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 30918759.875, "training_acc": 39.0, "val_loss": 22029439.0625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 75889201.375, "training_acc": 45.0, "val_loss": 5182274.21875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 27323108.5, "training_acc": 53.0, "val_loss": 510165.13671875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 38920716.5, "training_acc": 53.0, "val_loss": 871989.94140625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 114979529.0, "training_acc": 45.0, "val_loss": 9213597.65625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 43584498.75, "training_acc": 47.0, "val_loss": 904725.0, "val_acc": 48.0}
{"epoch": 13, "training_loss": 288336247.0, "training_acc": 41.0, "val_loss": 192423.84033203125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 28905779.3125, "training_acc": 47.0, "val_loss": 2009264.6484375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 17100415.5, "training_acc": 53.0, "val_loss": 241306.5673828125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2546347.125, "training_acc": 47.0, "val_loss": 609304.4921875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1651326.8828125, "training_acc": 46.0, "val_loss": 2972412.890625, "val_acc": 48.0}
{"epoch": 18, "training_loss": 41748147.5, "training_acc": 53.0, "val_loss": 69720831.25, "val_acc": 48.0}
{"epoch": 19, "training_loss": 195231668.75, "training_acc": 49.0, "val_loss": 2671026600.0, "val_acc": 48.0}
{"epoch": 20, "training_loss": 229769461760.0, "training_acc": 47.0, "val_loss": 13405628.125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 30324739.96875, "training_acc": 53.0, "val_loss": 1167372.4609375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 587361877.5, "training_acc": 53.0, "val_loss": 5372969.53125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 19983764.8125, "training_acc": 53.0, "val_loss": 1308657.51953125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 147986108.5, "training_acc": 59.0, "val_loss": 3180304.1015625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 8865634.046875, "training_acc": 58.0, "val_loss": 1810495600.0, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5010293716.0, "training_acc": 49.0, "val_loss": 276098650.0, "val_acc": 52.0}
{"epoch": 27, "training_loss": 38870986368.0, "training_acc": 53.0, "val_loss": 5264225200.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 15644752103.125, "training_acc": 53.0, "val_loss": 515062450.0, "val_acc": 48.0}
{"epoch": 29, "training_loss": 86558631680.0, "training_acc": 47.0, "val_loss": 390543475.0, "val_acc": 52.0}
{"epoch": 30, "training_loss": 999548595.0, "training_acc": 53.0, "val_loss": 56822550.0, "val_acc": 52.0}
{"epoch": 31, "training_loss": 185056481.5, "training_acc": 53.0, "val_loss": 485790600.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1668297368.0, "training_acc": 45.0, "val_loss": 322899525.0, "val_acc": 52.0}
