"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 423.36203384399414, "training_acc": 46.0, "val_loss": 2.8861671704992154e+20, "val_acc": 52.0}
{"epoch": 1, "training_loss": 6.63731857726395e+20, "training_acc": 53.0, "val_loss": 93999600.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 527876432.0, "training_acc": 55.0, "val_loss": 25866751.5625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 81723546.75, "training_acc": 47.0, "val_loss": 3895075.0, "val_acc": 48.0}
{"epoch": 4, "training_loss": 14255824.0625, "training_acc": 47.0, "val_loss": 5213014.453125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 17653142.25, "training_acc": 55.0, "val_loss": 18566973.4375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1079637700.0, "training_acc": 47.0, "val_loss": 8039089.0625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 94185857.5, "training_acc": 53.0, "val_loss": 259601950.0, "val_acc": 48.0}
{"epoch": 8, "training_loss": 977777850.0, "training_acc": 47.0, "val_loss": 6525242400.0, "val_acc": 52.0}
{"epoch": 9, "training_loss": 15680273656.0, "training_acc": 53.0, "val_loss": 204313862.5, "val_acc": 48.0}
{"epoch": 10, "training_loss": 802808902.0, "training_acc": 47.0, "val_loss": 99843575.0, "val_acc": 48.0}
{"epoch": 11, "training_loss": 351827840.0, "training_acc": 47.0, "val_loss": 33682046.875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 110605615.5, "training_acc": 47.0, "val_loss": 6982785.15625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 19779014.0625, "training_acc": 47.0, "val_loss": 323182.421875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1798352.3828125, "training_acc": 43.0, "val_loss": 1804054.6875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 12078252.25, "training_acc": 48.0, "val_loss": 8561293.75, "val_acc": 52.0}
{"epoch": 16, "training_loss": 23778858.25, "training_acc": 53.0, "val_loss": 12999041.40625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 39787090.9375, "training_acc": 47.0, "val_loss": 1701218.1640625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69809437.5, "training_acc": 53.0, "val_loss": 506642.08984375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1419218.998046875, "training_acc": 46.0, "val_loss": 1301531.8359375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 181216846.25, "training_acc": 53.0, "val_loss": 257459.9365234375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6717573.6875, "training_acc": 57.0, "val_loss": 542031.25, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2075987624.75, "training_acc": 47.0, "val_loss": 507940.0390625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1202422313.5, "training_acc": 46.0, "val_loss": 25545943.75, "val_acc": 52.0}
{"epoch": 24, "training_loss": 113270448.5, "training_acc": 53.0, "val_loss": 7350274.21875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 48381417.0, "training_acc": 47.0, "val_loss": 1700782.2265625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 21537826.375, "training_acc": 50.0, "val_loss": 3463893.75, "val_acc": 52.0}
{"epoch": 27, "training_loss": 11964611.09375, "training_acc": 49.0, "val_loss": 2336809400.0, "val_acc": 48.0}
{"epoch": 28, "training_loss": 7375803384.0, "training_acc": 41.0, "val_loss": 389722075.0, "val_acc": 52.0}
{"epoch": 29, "training_loss": 8003369984.0, "training_acc": 53.0, "val_loss": 120311212.5, "val_acc": 48.0}
{"epoch": 30, "training_loss": 437879362.0, "training_acc": 47.0, "val_loss": 1777756800.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 10665225792.0, "training_acc": 47.0, "val_loss": 161549400.0, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1490048472.0, "training_acc": 47.0, "val_loss": 14132601.5625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 110454842.0, "training_acc": 53.0, "val_loss": 364216000.0, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1769220192.0, "training_acc": 43.0, "val_loss": 8731973.4375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2511779036.0, "training_acc": 47.0, "val_loss": 581119550.0, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1612264664.0, "training_acc": 53.0, "val_loss": 239705175.0, "val_acc": 48.0}
{"epoch": 37, "training_loss": 798033994.0, "training_acc": 47.0, "val_loss": 45253765.625, "val_acc": 52.0}
{"epoch": 38, "training_loss": 134730042.0, "training_acc": 47.0, "val_loss": 46683806.25, "val_acc": 52.0}
{"epoch": 39, "training_loss": 169450592.0, "training_acc": 53.0, "val_loss": 34638846.875, "val_acc": 52.0}
