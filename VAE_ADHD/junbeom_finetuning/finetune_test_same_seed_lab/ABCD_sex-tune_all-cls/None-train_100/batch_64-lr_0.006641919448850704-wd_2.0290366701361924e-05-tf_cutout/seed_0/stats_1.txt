"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 225.5207691192627, "training_acc": 55.0, "val_loss": 37220128.125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 90412586.57538486, "training_acc": 47.0, "val_loss": 162487.68310546875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 436940.04693603516, "training_acc": 53.0, "val_loss": 82.12212324142456, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2560.8695068359375, "training_acc": 49.0, "val_loss": 21.30454182624817, "val_acc": 48.0}
{"epoch": 4, "training_loss": 112.76106929779053, "training_acc": 47.0, "val_loss": 288.22546005249023, "val_acc": 52.0}
{"epoch": 5, "training_loss": 915.3687515258789, "training_acc": 37.0, "val_loss": 29.74952757358551, "val_acc": 52.0}
{"epoch": 6, "training_loss": 96.39512586593628, "training_acc": 57.0, "val_loss": 17.638656497001648, "val_acc": 52.0}
{"epoch": 7, "training_loss": 110.12066507339478, "training_acc": 41.0, "val_loss": 20.747722685337067, "val_acc": 48.0}
{"epoch": 8, "training_loss": 85.41277027130127, "training_acc": 47.0, "val_loss": 17.301782965660095, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.24265360832214, "training_acc": 53.0, "val_loss": 17.288009822368622, "val_acc": 52.0}
{"epoch": 10, "training_loss": 71.88145518302917, "training_acc": 53.0, "val_loss": 35.281577706336975, "val_acc": 48.0}
{"epoch": 11, "training_loss": 114.49071145057678, "training_acc": 51.0, "val_loss": 24.114806950092316, "val_acc": 52.0}
{"epoch": 12, "training_loss": 88.82951855659485, "training_acc": 53.0, "val_loss": 17.40894615650177, "val_acc": 52.0}
{"epoch": 13, "training_loss": 72.75444722175598, "training_acc": 45.0, "val_loss": 17.31807291507721, "val_acc": 52.0}
{"epoch": 14, "training_loss": 73.1805853843689, "training_acc": 53.0, "val_loss": 17.55208522081375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.24605393409729, "training_acc": 45.0, "val_loss": 17.795033752918243, "val_acc": 52.0}
{"epoch": 16, "training_loss": 82.79155445098877, "training_acc": 41.0, "val_loss": 17.679916322231293, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.83342742919922, "training_acc": 51.0, "val_loss": 17.579686641693115, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.61268925666809, "training_acc": 47.0, "val_loss": 22.919650375843048, "val_acc": 52.0}
{"epoch": 19, "training_loss": 81.59458231925964, "training_acc": 53.0, "val_loss": 17.53135323524475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 81.86882543563843, "training_acc": 43.0, "val_loss": 18.062156438827515, "val_acc": 52.0}
{"epoch": 21, "training_loss": 72.46492671966553, "training_acc": 47.0, "val_loss": 18.262170255184174, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72.65157222747803, "training_acc": 47.0, "val_loss": 17.364080250263214, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.35094141960144, "training_acc": 49.0, "val_loss": 17.455171048641205, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.57850122451782, "training_acc": 53.0, "val_loss": 17.48589277267456, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.48471307754517, "training_acc": 53.0, "val_loss": 17.334678769111633, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.24786639213562, "training_acc": 53.0, "val_loss": 17.323867976665497, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2502052783966, "training_acc": 53.0, "val_loss": 17.337343096733093, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12001276016235, "training_acc": 53.0, "val_loss": 17.373432219028473, "val_acc": 52.0}
