"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 94.29938077926636, "training_acc": 53.0, "val_loss": 19.22604888677597, "val_acc": 52.0}
{"epoch": 1, "training_loss": 595.6413459777832, "training_acc": 59.0, "val_loss": 20.303305983543396, "val_acc": 48.0}
{"epoch": 2, "training_loss": 76.70244646072388, "training_acc": 47.0, "val_loss": 17.39066243171692, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73.07622122764587, "training_acc": 53.0, "val_loss": 17.310521006584167, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.86701679229736, "training_acc": 55.0, "val_loss": 17.596906423568726, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.76542139053345, "training_acc": 47.0, "val_loss": 17.29927361011505, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.91747426986694, "training_acc": 53.0, "val_loss": 17.922109365463257, "val_acc": 52.0}
{"epoch": 7, "training_loss": 71.90285515785217, "training_acc": 53.0, "val_loss": 17.302563786506653, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.7826201915741, "training_acc": 43.0, "val_loss": 17.343325912952423, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.40097880363464, "training_acc": 47.0, "val_loss": 17.32339859008789, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.26902461051941, "training_acc": 53.0, "val_loss": 17.306125164031982, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14065551757812, "training_acc": 53.0, "val_loss": 17.307746410369873, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10974955558777, "training_acc": 53.0, "val_loss": 17.35951602458954, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.27477383613586, "training_acc": 53.0, "val_loss": 17.38172173500061, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.34847354888916, "training_acc": 53.0, "val_loss": 17.347918450832367, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2122905254364, "training_acc": 53.0, "val_loss": 17.306232452392578, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19630551338196, "training_acc": 53.0, "val_loss": 17.311330139636993, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24528932571411, "training_acc": 53.0, "val_loss": 17.31005609035492, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1702790260315, "training_acc": 53.0, "val_loss": 17.305751144886017, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14988303184509, "training_acc": 53.0, "val_loss": 17.30981022119522, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13349533081055, "training_acc": 53.0, "val_loss": 17.315280437469482, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15069699287415, "training_acc": 53.0, "val_loss": 17.320212721824646, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15264248847961, "training_acc": 53.0, "val_loss": 17.31846034526825, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15586137771606, "training_acc": 53.0, "val_loss": 17.313309013843536, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14923429489136, "training_acc": 53.0, "val_loss": 17.31075942516327, "val_acc": 52.0}
