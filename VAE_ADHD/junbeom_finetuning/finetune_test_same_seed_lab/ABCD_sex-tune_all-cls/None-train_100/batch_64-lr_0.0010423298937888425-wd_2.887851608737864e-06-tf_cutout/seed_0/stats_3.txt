"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.91840481758118, "training_acc": 53.0, "val_loss": 154.885733127594, "val_acc": 48.0}
{"epoch": 1, "training_loss": 441.518586397171, "training_acc": 47.0, "val_loss": 17.333433032035828, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.18139624595642, "training_acc": 47.0, "val_loss": 27.792823314666748, "val_acc": 52.0}
{"epoch": 3, "training_loss": 90.93072652816772, "training_acc": 55.0, "val_loss": 18.016761541366577, "val_acc": 52.0}
{"epoch": 4, "training_loss": 72.17031598091125, "training_acc": 47.0, "val_loss": 17.554767429828644, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.3924913406372, "training_acc": 47.0, "val_loss": 17.303752899169922, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.46648097038269, "training_acc": 53.0, "val_loss": 17.33936220407486, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.20331645011902, "training_acc": 53.0, "val_loss": 17.30813980102539, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12063717842102, "training_acc": 53.0, "val_loss": 17.30952560901642, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.26704668998718, "training_acc": 53.0, "val_loss": 17.3144668340683, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.2366623878479, "training_acc": 53.0, "val_loss": 17.31606274843216, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.06688022613525, "training_acc": 53.0, "val_loss": 17.42819994688034, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.61358833312988, "training_acc": 53.0, "val_loss": 17.36433207988739, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.23159718513489, "training_acc": 53.0, "val_loss": 17.302905023097992, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11626172065735, "training_acc": 53.0, "val_loss": 17.310939729213715, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.39223885536194, "training_acc": 53.0, "val_loss": 17.31780171394348, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2860062122345, "training_acc": 53.0, "val_loss": 17.30736941099167, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10125970840454, "training_acc": 53.0, "val_loss": 17.316003143787384, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1033787727356, "training_acc": 53.0, "val_loss": 17.35508292913437, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24973726272583, "training_acc": 53.0, "val_loss": 17.38278865814209, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.3317449092865, "training_acc": 53.0, "val_loss": 17.354796826839447, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.28324127197266, "training_acc": 53.0, "val_loss": 17.326968908309937, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19633603096008, "training_acc": 53.0, "val_loss": 17.317984998226166, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15295481681824, "training_acc": 53.0, "val_loss": 17.317016422748566, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14816379547119, "training_acc": 53.0, "val_loss": 17.312978208065033, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13987398147583, "training_acc": 53.0, "val_loss": 17.31243133544922, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19117283821106, "training_acc": 53.0, "val_loss": 17.312975227832794, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.25437641143799, "training_acc": 53.0, "val_loss": 17.317970097064972, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14913964271545, "training_acc": 53.0, "val_loss": 17.315328121185303, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1338701248169, "training_acc": 53.0, "val_loss": 17.31553226709366, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20921421051025, "training_acc": 53.0, "val_loss": 17.315673828125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12590408325195, "training_acc": 53.0, "val_loss": 17.310386896133423, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12619853019714, "training_acc": 53.0, "val_loss": 17.308612167835236, "val_acc": 52.0}
