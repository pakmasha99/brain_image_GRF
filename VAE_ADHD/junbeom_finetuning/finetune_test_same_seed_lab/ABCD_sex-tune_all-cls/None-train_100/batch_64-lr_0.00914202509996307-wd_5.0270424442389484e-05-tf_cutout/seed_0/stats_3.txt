"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 332.51950454711914, "training_acc": 49.0, "val_loss": 699535248588800.0, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1907871985969003.2, "training_acc": 53.0, "val_loss": 27373.626708984375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 87546.02783203125, "training_acc": 47.0, "val_loss": 11654.737854003906, "val_acc": 52.0}
{"epoch": 3, "training_loss": 29844.840927124023, "training_acc": 51.0, "val_loss": 7224.9664306640625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 18507.098236083984, "training_acc": 61.0, "val_loss": 1013.7576103210449, "val_acc": 52.0}
{"epoch": 5, "training_loss": 18083.966796875, "training_acc": 45.0, "val_loss": 18113.4765625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71480.89013671875, "training_acc": 53.0, "val_loss": 26013.699340820312, "val_acc": 48.0}
{"epoch": 7, "training_loss": 77044.09802246094, "training_acc": 47.0, "val_loss": 1239.9520874023438, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3994.6408309936523, "training_acc": 47.0, "val_loss": 389.1569137573242, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1050.949016571045, "training_acc": 57.0, "val_loss": 435.2715492248535, "val_acc": 52.0}
{"epoch": 10, "training_loss": 16933.399780273438, "training_acc": 47.0, "val_loss": 293.3427572250366, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2331.5086364746094, "training_acc": 45.0, "val_loss": 226.75518989562988, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2818.864501953125, "training_acc": 53.0, "val_loss": 2023.6989974975586, "val_acc": 52.0}
{"epoch": 13, "training_loss": 7769.654205322266, "training_acc": 47.0, "val_loss": 1650.398826599121, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4319.655558586121, "training_acc": 53.0, "val_loss": 985.9160423278809, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2846.6661529541016, "training_acc": 47.0, "val_loss": 207.56990909576416, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3675.7476806640625, "training_acc": 41.0, "val_loss": 1501.2717247009277, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3812.3760986328125, "training_acc": 53.0, "val_loss": 2540.5473709106445, "val_acc": 48.0}
{"epoch": 18, "training_loss": 8566.516174316406, "training_acc": 47.0, "val_loss": 467.54140853881836, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1808.6390380859375, "training_acc": 55.0, "val_loss": 303.2365560531616, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1144.33345413208, "training_acc": 49.0, "val_loss": 1447.3402976989746, "val_acc": 52.0}
{"epoch": 21, "training_loss": 4374.591156005859, "training_acc": 43.0, "val_loss": 154.40654754638672, "val_acc": 48.0}
{"epoch": 22, "training_loss": 467.7687883377075, "training_acc": 57.0, "val_loss": 362.4638319015503, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1109.7260398864746, "training_acc": 51.0, "val_loss": 317.6849842071533, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1293.341209411621, "training_acc": 55.0, "val_loss": 473.3806610107422, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1418.7024955749512, "training_acc": 53.0, "val_loss": 352.4399757385254, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1226.8789749145508, "training_acc": 47.0, "val_loss": 426.97434425354004, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1207.915033340454, "training_acc": 53.0, "val_loss": 358.6575746536255, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1281.1679153442383, "training_acc": 47.0, "val_loss": 82.29231238365173, "val_acc": 48.0}
{"epoch": 29, "training_loss": 638.7357559204102, "training_acc": 37.0, "val_loss": 177.01239585876465, "val_acc": 48.0}
{"epoch": 30, "training_loss": 742.5987854003906, "training_acc": 49.0, "val_loss": 201.07417106628418, "val_acc": 52.0}
{"epoch": 31, "training_loss": 551.3883264064789, "training_acc": 50.0, "val_loss": 151.78790092468262, "val_acc": 48.0}
{"epoch": 32, "training_loss": 458.4877166748047, "training_acc": 47.0, "val_loss": 135.7203245162964, "val_acc": 52.0}
{"epoch": 33, "training_loss": 577.4525356292725, "training_acc": 53.0, "val_loss": 112.51866817474365, "val_acc": 52.0}
{"epoch": 34, "training_loss": 286.57461953163147, "training_acc": 52.0, "val_loss": 79.31211590766907, "val_acc": 48.0}
{"epoch": 35, "training_loss": 243.85964918136597, "training_acc": 47.0, "val_loss": 178.7211775779724, "val_acc": 52.0}
{"epoch": 36, "training_loss": 568.7587871551514, "training_acc": 53.0, "val_loss": 17.422856390476227, "val_acc": 52.0}
{"epoch": 37, "training_loss": 146.83882808685303, "training_acc": 48.0, "val_loss": 34.67228710651398, "val_acc": 48.0}
{"epoch": 38, "training_loss": 145.3293170928955, "training_acc": 45.0, "val_loss": 169.38462257385254, "val_acc": 48.0}
{"epoch": 39, "training_loss": 500.3408603668213, "training_acc": 55.0, "val_loss": 94.53825950622559, "val_acc": 52.0}
{"epoch": 40, "training_loss": 296.39587688446045, "training_acc": 53.0, "val_loss": 19.545789062976837, "val_acc": 48.0}
{"epoch": 41, "training_loss": 94.70391082763672, "training_acc": 47.0, "val_loss": 31.87076449394226, "val_acc": 48.0}
{"epoch": 42, "training_loss": 115.96498847007751, "training_acc": 46.0, "val_loss": 23.11791330575943, "val_acc": 52.0}
{"epoch": 43, "training_loss": 89.68211460113525, "training_acc": 53.0, "val_loss": 17.534148693084717, "val_acc": 52.0}
{"epoch": 44, "training_loss": 73.70526194572449, "training_acc": 45.0, "val_loss": 18.936286866664886, "val_acc": 48.0}
{"epoch": 45, "training_loss": 67.53700184822083, "training_acc": 61.0, "val_loss": 26.812627911567688, "val_acc": 52.0}
{"epoch": 46, "training_loss": 94.91951036453247, "training_acc": 53.0, "val_loss": 19.708362221717834, "val_acc": 48.0}
{"epoch": 47, "training_loss": 82.95045590400696, "training_acc": 48.0, "val_loss": 18.539518117904663, "val_acc": 40.0}
{"epoch": 48, "training_loss": 71.53084683418274, "training_acc": 53.0, "val_loss": 21.4460551738739, "val_acc": 52.0}
{"epoch": 49, "training_loss": 82.48304843902588, "training_acc": 53.0, "val_loss": 17.363913357257843, "val_acc": 52.0}
{"epoch": 50, "training_loss": 75.98994159698486, "training_acc": 48.0, "val_loss": 19.013942778110504, "val_acc": 48.0}
{"epoch": 51, "training_loss": 78.36394596099854, "training_acc": 42.0, "val_loss": 18.311050534248352, "val_acc": 52.0}
{"epoch": 52, "training_loss": 72.49792504310608, "training_acc": 53.0, "val_loss": 17.632494866847992, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.72440361976624, "training_acc": 55.0, "val_loss": 17.757365107536316, "val_acc": 52.0}
{"epoch": 54, "training_loss": 73.1091685295105, "training_acc": 45.0, "val_loss": 17.395825684070587, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.91265797615051, "training_acc": 47.0, "val_loss": 18.190741539001465, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.47410154342651, "training_acc": 53.0, "val_loss": 17.354311048984528, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.49516677856445, "training_acc": 49.0, "val_loss": 17.826350033283234, "val_acc": 52.0}
{"epoch": 58, "training_loss": 70.68765115737915, "training_acc": 50.0, "val_loss": 17.367663979530334, "val_acc": 52.0}
{"epoch": 59, "training_loss": 67.90959787368774, "training_acc": 55.0, "val_loss": 17.737525701522827, "val_acc": 52.0}
{"epoch": 60, "training_loss": 71.85058259963989, "training_acc": 51.0, "val_loss": 17.523542046546936, "val_acc": 52.0}
{"epoch": 61, "training_loss": 70.11574101448059, "training_acc": 53.0, "val_loss": 17.345911264419556, "val_acc": 52.0}
{"epoch": 62, "training_loss": 71.07957577705383, "training_acc": 49.0, "val_loss": 17.499089241027832, "val_acc": 52.0}
{"epoch": 63, "training_loss": 71.62397408485413, "training_acc": 42.0, "val_loss": 17.644719779491425, "val_acc": 52.0}
{"epoch": 64, "training_loss": 70.19903302192688, "training_acc": 52.0, "val_loss": 17.339539527893066, "val_acc": 52.0}
{"epoch": 65, "training_loss": 70.19657802581787, "training_acc": 52.0, "val_loss": 17.377109825611115, "val_acc": 52.0}
{"epoch": 66, "training_loss": 70.55152463912964, "training_acc": 50.0, "val_loss": 17.36989915370941, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.38695955276489, "training_acc": 55.0, "val_loss": 17.374296486377716, "val_acc": 52.0}
{"epoch": 68, "training_loss": 68.97943615913391, "training_acc": 45.0, "val_loss": 17.653213441371918, "val_acc": 52.0}
{"epoch": 69, "training_loss": 70.63756155967712, "training_acc": 48.0, "val_loss": 17.518889904022217, "val_acc": 52.0}
{"epoch": 70, "training_loss": 70.52800393104553, "training_acc": 44.0, "val_loss": 17.57839024066925, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.76727628707886, "training_acc": 52.0, "val_loss": 17.371341586112976, "val_acc": 52.0}
{"epoch": 72, "training_loss": 68.84784746170044, "training_acc": 55.0, "val_loss": 17.637960612773895, "val_acc": 52.0}
{"epoch": 73, "training_loss": 71.40835857391357, "training_acc": 47.0, "val_loss": 17.350681126117706, "val_acc": 52.0}
{"epoch": 74, "training_loss": 69.14770150184631, "training_acc": 53.0, "val_loss": 18.289199471473694, "val_acc": 52.0}
{"epoch": 75, "training_loss": 72.78225684165955, "training_acc": 53.0, "val_loss": 17.40972548723221, "val_acc": 52.0}
{"epoch": 76, "training_loss": 69.01579928398132, "training_acc": 51.0, "val_loss": 18.133533000946045, "val_acc": 52.0}
{"epoch": 77, "training_loss": 71.71191740036011, "training_acc": 47.0, "val_loss": 17.347921431064606, "val_acc": 52.0}
{"epoch": 78, "training_loss": 68.18826079368591, "training_acc": 56.0, "val_loss": 18.1217223405838, "val_acc": 52.0}
{"epoch": 79, "training_loss": 71.1836621761322, "training_acc": 53.0, "val_loss": 17.39570051431656, "val_acc": 52.0}
{"epoch": 80, "training_loss": 68.35026478767395, "training_acc": 55.0, "val_loss": 17.728979885578156, "val_acc": 52.0}
{"epoch": 81, "training_loss": 70.88826560974121, "training_acc": 47.0, "val_loss": 17.36956685781479, "val_acc": 52.0}
{"epoch": 82, "training_loss": 67.9909017086029, "training_acc": 55.0, "val_loss": 17.708060145378113, "val_acc": 52.0}
{"epoch": 83, "training_loss": 71.12162208557129, "training_acc": 53.0, "val_loss": 17.422078549861908, "val_acc": 52.0}
