"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.1246829032898, "training_acc": 54.0, "val_loss": 17.337241768836975, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.19912719726562, "training_acc": 53.0, "val_loss": 17.36791580915451, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.3166081905365, "training_acc": 53.0, "val_loss": 17.384783923625946, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.5246274471283, "training_acc": 53.0, "val_loss": 17.42423176765442, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.26230525970459, "training_acc": 53.0, "val_loss": 17.35062748193741, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20245409011841, "training_acc": 53.0, "val_loss": 17.326156795024872, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.55899596214294, "training_acc": 41.0, "val_loss": 17.342017590999603, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.27595448493958, "training_acc": 46.0, "val_loss": 17.322467267513275, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12746453285217, "training_acc": 53.0, "val_loss": 17.324374616146088, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.04090809822083, "training_acc": 53.0, "val_loss": 17.34602302312851, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17936325073242, "training_acc": 53.0, "val_loss": 17.379780113697052, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.23935747146606, "training_acc": 53.0, "val_loss": 17.382316291332245, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16142678260803, "training_acc": 53.0, "val_loss": 17.34735071659088, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.06616544723511, "training_acc": 53.0, "val_loss": 17.32547879219055, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.28074598312378, "training_acc": 53.0, "val_loss": 17.32974648475647, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15343022346497, "training_acc": 53.0, "val_loss": 17.32872575521469, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15896439552307, "training_acc": 53.0, "val_loss": 17.3283189535141, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1297996044159, "training_acc": 53.0, "val_loss": 17.32797622680664, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08218741416931, "training_acc": 53.0, "val_loss": 17.32805222272873, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.07216763496399, "training_acc": 53.0, "val_loss": 17.330928146839142, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05911469459534, "training_acc": 53.0, "val_loss": 17.34064668416977, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.99034810066223, "training_acc": 53.0, "val_loss": 17.373786866664886, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.27795147895813, "training_acc": 53.0, "val_loss": 17.401939630508423, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27196598052979, "training_acc": 53.0, "val_loss": 17.37101376056671, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.04021573066711, "training_acc": 53.0, "val_loss": 17.358867824077606, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.99438810348511, "training_acc": 53.0, "val_loss": 17.34335720539093, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.96582221984863, "training_acc": 53.0, "val_loss": 17.33311116695404, "val_acc": 52.0}
