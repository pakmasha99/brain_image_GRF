"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.19094634056091, "training_acc": 53.0, "val_loss": 17.357932031154633, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30090069770813, "training_acc": 53.0, "val_loss": 17.333920300006866, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.13507890701294, "training_acc": 53.0, "val_loss": 17.332907021045685, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1271903514862, "training_acc": 53.0, "val_loss": 17.339767515659332, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.11331963539124, "training_acc": 53.0, "val_loss": 17.347972095012665, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08452582359314, "training_acc": 53.0, "val_loss": 17.347916960716248, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.97336745262146, "training_acc": 53.0, "val_loss": 17.397941648960114, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.8517324924469, "training_acc": 53.0, "val_loss": 17.402145266532898, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.9005138874054, "training_acc": 53.0, "val_loss": 17.345279455184937, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.65186333656311, "training_acc": 53.0, "val_loss": 17.317557334899902, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.74397778511047, "training_acc": 53.0, "val_loss": 17.31303036212921, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.01468777656555, "training_acc": 53.0, "val_loss": 17.323695123195648, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.78451657295227, "training_acc": 53.0, "val_loss": 17.30913370847702, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.98805618286133, "training_acc": 53.0, "val_loss": 17.301401495933533, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.63725209236145, "training_acc": 53.0, "val_loss": 17.3189714550972, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.47016954421997, "training_acc": 53.0, "val_loss": 17.359066009521484, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.2818992137909, "training_acc": 53.0, "val_loss": 17.307768762111664, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.57303357124329, "training_acc": 53.0, "val_loss": 17.3039048910141, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.51001977920532, "training_acc": 53.0, "val_loss": 17.420370876789093, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.21646881103516, "training_acc": 53.0, "val_loss": 17.472732067108154, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.05921149253845, "training_acc": 53.0, "val_loss": 17.43752211332321, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.42509317398071, "training_acc": 53.0, "val_loss": 17.343372106552124, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.31705045700073, "training_acc": 53.0, "val_loss": 17.3753023147583, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.01249122619629, "training_acc": 53.0, "val_loss": 17.44910329580307, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.53140330314636, "training_acc": 53.0, "val_loss": 17.507563531398773, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.75574040412903, "training_acc": 53.0, "val_loss": 17.44123101234436, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.83063006401062, "training_acc": 54.0, "val_loss": 17.329052090644836, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.8760917186737, "training_acc": 57.0, "val_loss": 17.524848878383636, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.36869931221008, "training_acc": 55.0, "val_loss": 17.60714501142502, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.28768658638, "training_acc": 53.0, "val_loss": 17.60244369506836, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.54087400436401, "training_acc": 56.0, "val_loss": 17.3016294836998, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.87338757514954, "training_acc": 64.0, "val_loss": 17.491497099399567, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.03059887886047, "training_acc": 58.0, "val_loss": 17.704789340496063, "val_acc": 52.0}
