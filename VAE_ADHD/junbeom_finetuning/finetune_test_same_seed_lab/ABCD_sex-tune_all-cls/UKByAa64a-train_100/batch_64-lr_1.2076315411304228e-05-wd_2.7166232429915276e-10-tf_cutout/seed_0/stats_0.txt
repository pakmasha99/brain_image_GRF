"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34268355369568, "training_acc": 52.0, "val_loss": 17.276376485824585, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23984909057617, "training_acc": 52.0, "val_loss": 17.296479642391205, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.11784076690674, "training_acc": 52.0, "val_loss": 17.30669140815735, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.17784190177917, "training_acc": 52.0, "val_loss": 17.303763329982758, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.04135870933533, "training_acc": 54.0, "val_loss": 17.319579422473907, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.00962567329407, "training_acc": 54.0, "val_loss": 17.29077249765396, "val_acc": 56.0}
{"epoch": 6, "training_loss": 68.99182081222534, "training_acc": 54.0, "val_loss": 17.324046790599823, "val_acc": 56.0}
{"epoch": 7, "training_loss": 68.80056476593018, "training_acc": 55.0, "val_loss": 17.31080561876297, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.02126264572144, "training_acc": 53.0, "val_loss": 17.27812886238098, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.0363392829895, "training_acc": 52.0, "val_loss": 17.219524085521698, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.00633978843689, "training_acc": 52.0, "val_loss": 17.210346460342407, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.83321118354797, "training_acc": 52.0, "val_loss": 17.198993265628815, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.7317476272583, "training_acc": 53.0, "val_loss": 17.217616736888885, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.64761590957642, "training_acc": 54.0, "val_loss": 17.238345742225647, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.73797702789307, "training_acc": 56.0, "val_loss": 17.25618690252304, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.47542190551758, "training_acc": 51.0, "val_loss": 17.215357720851898, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.19410443305969, "training_acc": 53.0, "val_loss": 17.210520803928375, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.54205346107483, "training_acc": 53.0, "val_loss": 17.291712760925293, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.21936464309692, "training_acc": 58.0, "val_loss": 17.230328917503357, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.13761377334595, "training_acc": 52.0, "val_loss": 17.25078970193863, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.42267537117004, "training_acc": 55.0, "val_loss": 17.277759313583374, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.05353140830994, "training_acc": 56.0, "val_loss": 17.30918437242508, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.17711043357849, "training_acc": 55.0, "val_loss": 17.260384559631348, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.00628733634949, "training_acc": 61.0, "val_loss": 17.1785905957222, "val_acc": 56.0}
{"epoch": 24, "training_loss": 67.78592348098755, "training_acc": 55.0, "val_loss": 17.225748300552368, "val_acc": 56.0}
{"epoch": 25, "training_loss": 67.3795657157898, "training_acc": 62.0, "val_loss": 17.225970327854156, "val_acc": 56.0}
{"epoch": 26, "training_loss": 67.15757441520691, "training_acc": 60.0, "val_loss": 17.219744622707367, "val_acc": 56.0}
{"epoch": 27, "training_loss": 67.47334241867065, "training_acc": 58.0, "val_loss": 17.49435067176819, "val_acc": 56.0}
{"epoch": 28, "training_loss": 67.32040023803711, "training_acc": 63.0, "val_loss": 17.29785054922104, "val_acc": 56.0}
{"epoch": 29, "training_loss": 67.0583803653717, "training_acc": 60.0, "val_loss": 17.219600081443787, "val_acc": 56.0}
{"epoch": 30, "training_loss": 66.83325600624084, "training_acc": 64.0, "val_loss": 17.422914505004883, "val_acc": 56.0}
{"epoch": 31, "training_loss": 67.1198616027832, "training_acc": 65.0, "val_loss": 17.27256029844284, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.94034814834595, "training_acc": 53.0, "val_loss": 17.27045774459839, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.81913018226624, "training_acc": 52.0, "val_loss": 17.26248562335968, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.91232395172119, "training_acc": 52.0, "val_loss": 17.254899442195892, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.03521084785461, "training_acc": 52.0, "val_loss": 17.25742369890213, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.70634961128235, "training_acc": 53.0, "val_loss": 17.261995375156403, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.8431932926178, "training_acc": 53.0, "val_loss": 17.24936217069626, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.4228298664093, "training_acc": 55.0, "val_loss": 17.231978476047516, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.33586406707764, "training_acc": 53.0, "val_loss": 17.21675395965576, "val_acc": 56.0}
{"epoch": 40, "training_loss": 68.28028869628906, "training_acc": 53.0, "val_loss": 17.232459783554077, "val_acc": 56.0}
{"epoch": 41, "training_loss": 68.21329045295715, "training_acc": 54.0, "val_loss": 17.281919717788696, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.10037350654602, "training_acc": 58.0, "val_loss": 17.317740619182587, "val_acc": 56.0}
