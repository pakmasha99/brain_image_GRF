"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.11497235298157, "training_acc": 47.0, "val_loss": 17.346906661987305, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.63662600517273, "training_acc": 47.0, "val_loss": 17.33914464712143, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24050164222717, "training_acc": 51.0, "val_loss": 17.36632138490677, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18464708328247, "training_acc": 53.0, "val_loss": 17.364202439785004, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.23859763145447, "training_acc": 53.0, "val_loss": 17.32364296913147, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22356510162354, "training_acc": 53.0, "val_loss": 17.30247139930725, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.05163359642029, "training_acc": 53.0, "val_loss": 17.322255671024323, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4631700515747, "training_acc": 53.0, "val_loss": 17.32201725244522, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10334038734436, "training_acc": 53.0, "val_loss": 17.33650118112564, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18057203292847, "training_acc": 53.0, "val_loss": 17.33807474374771, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15796208381653, "training_acc": 53.0, "val_loss": 17.347370088100433, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17872428894043, "training_acc": 53.0, "val_loss": 17.325714230537415, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17627835273743, "training_acc": 53.0, "val_loss": 17.310237884521484, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11843037605286, "training_acc": 53.0, "val_loss": 17.32800602912903, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.3093593120575, "training_acc": 52.0, "val_loss": 17.328277230262756, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.27060556411743, "training_acc": 52.0, "val_loss": 17.311903834342957, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15888404846191, "training_acc": 53.0, "val_loss": 17.31296330690384, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1059296131134, "training_acc": 53.0, "val_loss": 17.324835062026978, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15036821365356, "training_acc": 53.0, "val_loss": 17.339283227920532, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16725873947144, "training_acc": 53.0, "val_loss": 17.351481318473816, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.20508766174316, "training_acc": 53.0, "val_loss": 17.346343398094177, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.2744038105011, "training_acc": 53.0, "val_loss": 17.338718473911285, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11042308807373, "training_acc": 53.0, "val_loss": 17.31298863887787, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.29139566421509, "training_acc": 53.0, "val_loss": 17.312659323215485, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.27353644371033, "training_acc": 53.0, "val_loss": 17.310886085033417, "val_acc": 52.0}
