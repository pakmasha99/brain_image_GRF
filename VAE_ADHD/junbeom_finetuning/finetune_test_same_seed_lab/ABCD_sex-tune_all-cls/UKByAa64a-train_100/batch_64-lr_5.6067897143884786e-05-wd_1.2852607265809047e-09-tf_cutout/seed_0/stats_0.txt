"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.28842353820801, "training_acc": 52.0, "val_loss": 17.33204573392868, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.20776414871216, "training_acc": 52.0, "val_loss": 17.27123260498047, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.32583928108215, "training_acc": 52.0, "val_loss": 17.275281250476837, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.22555470466614, "training_acc": 52.0, "val_loss": 17.305149137973785, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.10545468330383, "training_acc": 51.0, "val_loss": 17.283834517002106, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.34381222724915, "training_acc": 51.0, "val_loss": 17.269892990589142, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.18304014205933, "training_acc": 52.0, "val_loss": 17.318545281887054, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.12587761878967, "training_acc": 55.0, "val_loss": 17.274045944213867, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.40766882896423, "training_acc": 52.0, "val_loss": 17.224635183811188, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.06098484992981, "training_acc": 52.0, "val_loss": 17.310677468776703, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.06221389770508, "training_acc": 56.0, "val_loss": 17.406804859638214, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.15295791625977, "training_acc": 52.0, "val_loss": 17.324481904506683, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.93374967575073, "training_acc": 55.0, "val_loss": 17.324337363243103, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.66974639892578, "training_acc": 55.0, "val_loss": 17.416000366210938, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.76234173774719, "training_acc": 53.0, "val_loss": 17.3334538936615, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.51874160766602, "training_acc": 55.0, "val_loss": 17.346268892288208, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.15378761291504, "training_acc": 54.0, "val_loss": 17.420485615730286, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.57362818717957, "training_acc": 56.0, "val_loss": 17.510125041007996, "val_acc": 56.0}
{"epoch": 18, "training_loss": 67.96462869644165, "training_acc": 64.0, "val_loss": 17.257891595363617, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.19652247428894, "training_acc": 50.0, "val_loss": 17.773860692977905, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.4302487373352, "training_acc": 51.0, "val_loss": 17.583678662776947, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.5863049030304, "training_acc": 57.0, "val_loss": 17.2043114900589, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.44154691696167, "training_acc": 52.0, "val_loss": 17.149639129638672, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.16067957878113, "training_acc": 52.0, "val_loss": 17.24999248981476, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.96571731567383, "training_acc": 52.0, "val_loss": 17.362281680107117, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.06245589256287, "training_acc": 50.0, "val_loss": 17.407608032226562, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.44385170936584, "training_acc": 47.0, "val_loss": 17.298129200935364, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.95437026023865, "training_acc": 53.0, "val_loss": 17.42311418056488, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.93559980392456, "training_acc": 57.0, "val_loss": 17.468783259391785, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.69650316238403, "training_acc": 61.0, "val_loss": 17.289462685585022, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.18899893760681, "training_acc": 52.0, "val_loss": 17.24129468202591, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.12640261650085, "training_acc": 52.0, "val_loss": 17.35912263393402, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.72349405288696, "training_acc": 56.0, "val_loss": 17.364703118801117, "val_acc": 56.0}
{"epoch": 33, "training_loss": 67.60230350494385, "training_acc": 63.0, "val_loss": 17.379130423069, "val_acc": 56.0}
{"epoch": 34, "training_loss": 67.878338098526, "training_acc": 57.0, "val_loss": 17.521005868911743, "val_acc": 56.0}
{"epoch": 35, "training_loss": 67.87663412094116, "training_acc": 65.0, "val_loss": 17.419864237308502, "val_acc": 56.0}
{"epoch": 36, "training_loss": 66.13392353057861, "training_acc": 65.0, "val_loss": 17.28113144636154, "val_acc": 56.0}
{"epoch": 37, "training_loss": 67.79799199104309, "training_acc": 59.0, "val_loss": 17.292258143424988, "val_acc": 56.0}
{"epoch": 38, "training_loss": 67.19972157478333, "training_acc": 61.0, "val_loss": 17.215994000434875, "val_acc": 56.0}
{"epoch": 39, "training_loss": 67.60349631309509, "training_acc": 61.0, "val_loss": 17.211855947971344, "val_acc": 56.0}
{"epoch": 40, "training_loss": 66.65200114250183, "training_acc": 59.0, "val_loss": 17.793700098991394, "val_acc": 56.0}
{"epoch": 41, "training_loss": 67.91211009025574, "training_acc": 59.0, "val_loss": 17.524468898773193, "val_acc": 56.0}
