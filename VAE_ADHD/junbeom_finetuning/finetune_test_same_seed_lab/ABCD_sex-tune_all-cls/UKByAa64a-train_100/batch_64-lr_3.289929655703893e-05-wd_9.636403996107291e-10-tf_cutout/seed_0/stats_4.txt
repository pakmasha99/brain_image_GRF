"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.01314878463745, "training_acc": 53.0, "val_loss": 17.3858180642128, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.34156703948975, "training_acc": 48.0, "val_loss": 17.393508553504944, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.05275559425354, "training_acc": 53.0, "val_loss": 17.389892041683197, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16061425209045, "training_acc": 53.0, "val_loss": 17.382314801216125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.01837205886841, "training_acc": 53.0, "val_loss": 17.28750616312027, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.02952003479004, "training_acc": 49.0, "val_loss": 17.279617488384247, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.88871693611145, "training_acc": 52.0, "val_loss": 17.343680560588837, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.68417525291443, "training_acc": 53.0, "val_loss": 17.271770536899567, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.60133028030396, "training_acc": 55.0, "val_loss": 17.235608398914337, "val_acc": 52.0}
{"epoch": 9, "training_loss": 67.73567986488342, "training_acc": 52.0, "val_loss": 17.36106276512146, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.39742183685303, "training_acc": 53.0, "val_loss": 17.37658977508545, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.9532299041748, "training_acc": 48.0, "val_loss": 17.561671137809753, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.54708075523376, "training_acc": 47.0, "val_loss": 17.297761142253876, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15047359466553, "training_acc": 51.0, "val_loss": 17.38610863685608, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18497776985168, "training_acc": 53.0, "val_loss": 17.33059585094452, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.74943470954895, "training_acc": 53.0, "val_loss": 17.269296944141388, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.73170208930969, "training_acc": 63.0, "val_loss": 17.30106770992279, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.02378106117249, "training_acc": 54.0, "val_loss": 17.26040542125702, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.5188295841217, "training_acc": 53.0, "val_loss": 17.329654097557068, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.83339428901672, "training_acc": 53.0, "val_loss": 17.509645223617554, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.83124852180481, "training_acc": 53.0, "val_loss": 17.35333651304245, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.42181324958801, "training_acc": 53.0, "val_loss": 17.20365881919861, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.10669422149658, "training_acc": 61.0, "val_loss": 17.258736491203308, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.90620374679565, "training_acc": 50.0, "val_loss": 17.15587228536606, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.26641416549683, "training_acc": 59.0, "val_loss": 17.318084836006165, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.60276746749878, "training_acc": 53.0, "val_loss": 17.22245365381241, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.46274185180664, "training_acc": 55.0, "val_loss": 17.17585176229477, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.65383625030518, "training_acc": 60.0, "val_loss": 17.234763503074646, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.23348236083984, "training_acc": 54.0, "val_loss": 17.151357233524323, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.41278862953186, "training_acc": 58.0, "val_loss": 17.094025015830994, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.57939600944519, "training_acc": 64.0, "val_loss": 17.254461348056793, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.81746196746826, "training_acc": 62.0, "val_loss": 17.038515210151672, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.84609699249268, "training_acc": 65.0, "val_loss": 16.92638397216797, "val_acc": 52.0}
{"epoch": 33, "training_loss": 63.640069246292114, "training_acc": 72.0, "val_loss": 17.046992480754852, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.83877921104431, "training_acc": 61.0, "val_loss": 17.982394993305206, "val_acc": 52.0}
{"epoch": 35, "training_loss": 63.556103229522705, "training_acc": 56.0, "val_loss": 18.415528535842896, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.72446179389954, "training_acc": 47.0, "val_loss": 16.988828778266907, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.34932279586792, "training_acc": 62.0, "val_loss": 18.708136677742004, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.35475945472717, "training_acc": 66.0, "val_loss": 17.169246077537537, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.1153404712677, "training_acc": 60.0, "val_loss": 16.804639995098114, "val_acc": 52.0}
{"epoch": 40, "training_loss": 61.184483766555786, "training_acc": 79.0, "val_loss": 18.478667736053467, "val_acc": 52.0}
{"epoch": 41, "training_loss": 62.49020767211914, "training_acc": 59.0, "val_loss": 16.531091928482056, "val_acc": 52.0}
{"epoch": 42, "training_loss": 60.32997679710388, "training_acc": 78.0, "val_loss": 16.432476043701172, "val_acc": 52.0}
{"epoch": 43, "training_loss": 55.141186237335205, "training_acc": 78.0, "val_loss": 16.88636988401413, "val_acc": 52.0}
{"epoch": 44, "training_loss": 55.70920991897583, "training_acc": 72.0, "val_loss": 16.61963015794754, "val_acc": 52.0}
{"epoch": 45, "training_loss": 51.92974519729614, "training_acc": 77.0, "val_loss": 19.30432617664337, "val_acc": 52.0}
{"epoch": 46, "training_loss": 53.08033537864685, "training_acc": 67.0, "val_loss": 23.498500883579254, "val_acc": 52.0}
{"epoch": 47, "training_loss": 67.15759778022766, "training_acc": 60.0, "val_loss": 30.651605129241943, "val_acc": 48.0}
{"epoch": 48, "training_loss": 108.88869500160217, "training_acc": 47.0, "val_loss": 18.095412850379944, "val_acc": 48.0}
{"epoch": 49, "training_loss": 70.92955350875854, "training_acc": 47.0, "val_loss": 18.960659205913544, "val_acc": 52.0}
{"epoch": 50, "training_loss": 74.1692373752594, "training_acc": 53.0, "val_loss": 18.332168459892273, "val_acc": 52.0}
{"epoch": 51, "training_loss": 71.41314816474915, "training_acc": 53.0, "val_loss": 17.299702763557434, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.95301485061646, "training_acc": 49.0, "val_loss": 17.805932462215424, "val_acc": 52.0}
{"epoch": 53, "training_loss": 71.74470257759094, "training_acc": 47.0, "val_loss": 17.429858446121216, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.55057954788208, "training_acc": 47.0, "val_loss": 17.30179935693741, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.7808609008789, "training_acc": 53.0, "val_loss": 17.382843792438507, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.09786319732666, "training_acc": 53.0, "val_loss": 17.507819831371307, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.67152905464172, "training_acc": 53.0, "val_loss": 17.36149936914444, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.1021499633789, "training_acc": 53.0, "val_loss": 17.328807711601257, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.85573983192444, "training_acc": 53.0, "val_loss": 17.325565218925476, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.63125610351562, "training_acc": 53.0, "val_loss": 17.303387820720673, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.73039555549622, "training_acc": 53.0, "val_loss": 17.295673489570618, "val_acc": 52.0}
