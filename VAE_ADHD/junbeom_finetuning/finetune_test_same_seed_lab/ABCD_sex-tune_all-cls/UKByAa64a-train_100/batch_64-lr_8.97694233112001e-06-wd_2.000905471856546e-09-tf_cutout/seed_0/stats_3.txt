"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.29959011077881, "training_acc": 53.0, "val_loss": 17.335274815559387, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13105726242065, "training_acc": 53.0, "val_loss": 17.355212569236755, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.08208775520325, "training_acc": 53.0, "val_loss": 17.384055256843567, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.79898834228516, "training_acc": 53.0, "val_loss": 17.34762191772461, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.85253477096558, "training_acc": 53.0, "val_loss": 17.33868569135666, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.86338496208191, "training_acc": 53.0, "val_loss": 17.310598492622375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.76485395431519, "training_acc": 53.0, "val_loss": 17.33333021402359, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.69699811935425, "training_acc": 53.0, "val_loss": 17.392654716968536, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.72925639152527, "training_acc": 53.0, "val_loss": 17.38041192293167, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.09424710273743, "training_acc": 53.0, "val_loss": 17.389072477817535, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.7435073852539, "training_acc": 53.0, "val_loss": 17.388813197612762, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.67135310173035, "training_acc": 53.0, "val_loss": 17.38901436328888, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.5831048488617, "training_acc": 53.0, "val_loss": 17.404797673225403, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.72382855415344, "training_acc": 53.0, "val_loss": 17.441989481449127, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.18645811080933, "training_acc": 53.0, "val_loss": 17.490355670452118, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.52724862098694, "training_acc": 53.0, "val_loss": 17.450208961963654, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.57784748077393, "training_acc": 53.0, "val_loss": 17.459888756275177, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.82535290718079, "training_acc": 53.0, "val_loss": 17.485220730304718, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.37518453598022, "training_acc": 53.0, "val_loss": 17.49987006187439, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.45374655723572, "training_acc": 53.0, "val_loss": 17.545437812805176, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.2789318561554, "training_acc": 53.0, "val_loss": 17.58204996585846, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.56604313850403, "training_acc": 53.0, "val_loss": 17.488284409046173, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.94231867790222, "training_acc": 53.0, "val_loss": 17.532595992088318, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.00898861885071, "training_acc": 53.0, "val_loss": 17.597106099128723, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.7714204788208, "training_acc": 54.0, "val_loss": 17.53275841474533, "val_acc": 52.0}
