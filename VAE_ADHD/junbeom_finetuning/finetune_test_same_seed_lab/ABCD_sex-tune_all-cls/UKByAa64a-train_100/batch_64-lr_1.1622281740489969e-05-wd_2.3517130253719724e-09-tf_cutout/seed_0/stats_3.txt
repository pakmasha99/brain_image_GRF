"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.12474060058594, "training_acc": 54.0, "val_loss": 17.30930656194687, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13252997398376, "training_acc": 53.0, "val_loss": 17.322811484336853, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.01637077331543, "training_acc": 52.0, "val_loss": 17.30845868587494, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14824223518372, "training_acc": 53.0, "val_loss": 17.30622500181198, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.05727863311768, "training_acc": 53.0, "val_loss": 17.3164501786232, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06058263778687, "training_acc": 53.0, "val_loss": 17.329059541225433, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.7367057800293, "training_acc": 53.0, "val_loss": 17.32271909713745, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.67854332923889, "training_acc": 53.0, "val_loss": 17.34217405319214, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.57748484611511, "training_acc": 53.0, "val_loss": 17.350293695926666, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.63594889640808, "training_acc": 53.0, "val_loss": 17.321281135082245, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.52426958084106, "training_acc": 53.0, "val_loss": 17.413154244422913, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.46927189826965, "training_acc": 53.0, "val_loss": 17.42839813232422, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.28320026397705, "training_acc": 53.0, "val_loss": 17.446310818195343, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.4866635799408, "training_acc": 53.0, "val_loss": 17.415039241313934, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.09536290168762, "training_acc": 53.0, "val_loss": 17.447154223918915, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.08343935012817, "training_acc": 52.0, "val_loss": 17.46547669172287, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.75297474861145, "training_acc": 53.0, "val_loss": 17.448896169662476, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.94069600105286, "training_acc": 57.0, "val_loss": 17.408427596092224, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.20045399665833, "training_acc": 70.0, "val_loss": 17.426125705242157, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.51693844795227, "training_acc": 59.0, "val_loss": 17.460498213768005, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.90552234649658, "training_acc": 54.0, "val_loss": 17.425931990146637, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.4049985408783, "training_acc": 57.0, "val_loss": 17.429065704345703, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.18070912361145, "training_acc": 62.0, "val_loss": 17.65606254339218, "val_acc": 52.0}
