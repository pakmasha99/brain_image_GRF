"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.27092671394348, "training_acc": 54.0, "val_loss": 17.327779531478882, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21707892417908, "training_acc": 53.0, "val_loss": 17.306259274482727, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.11700534820557, "training_acc": 53.0, "val_loss": 17.306140065193176, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.95850658416748, "training_acc": 53.0, "val_loss": 17.282947897911072, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.85428595542908, "training_acc": 53.0, "val_loss": 17.27004051208496, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.73221778869629, "training_acc": 53.0, "val_loss": 17.197147011756897, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.77881503105164, "training_acc": 53.0, "val_loss": 17.20413565635681, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.65442681312561, "training_acc": 53.0, "val_loss": 17.232616245746613, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.7128837108612, "training_acc": 53.0, "val_loss": 17.223168909549713, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.52144050598145, "training_acc": 53.0, "val_loss": 17.198210954666138, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.91905975341797, "training_acc": 53.0, "val_loss": 17.25590080022812, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.86719465255737, "training_acc": 53.0, "val_loss": 17.2575443983078, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.90999269485474, "training_acc": 53.0, "val_loss": 17.252036929130554, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.50274205207825, "training_acc": 53.0, "val_loss": 17.20978319644928, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.03444981575012, "training_acc": 53.0, "val_loss": 17.222800850868225, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.61674213409424, "training_acc": 53.0, "val_loss": 17.254120111465454, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.33160018920898, "training_acc": 53.0, "val_loss": 17.23106950521469, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.4795401096344, "training_acc": 53.0, "val_loss": 17.226922512054443, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.32433438301086, "training_acc": 53.0, "val_loss": 17.269572615623474, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.32336926460266, "training_acc": 53.0, "val_loss": 17.245155572891235, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.63497519493103, "training_acc": 53.0, "val_loss": 17.208491265773773, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.54671788215637, "training_acc": 53.0, "val_loss": 17.20159351825714, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.30666732788086, "training_acc": 53.0, "val_loss": 17.15979129076004, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.98381733894348, "training_acc": 54.0, "val_loss": 17.151695489883423, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.32092428207397, "training_acc": 60.0, "val_loss": 17.121486365795135, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.65575909614563, "training_acc": 53.0, "val_loss": 17.142556607723236, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.60824060440063, "training_acc": 58.0, "val_loss": 17.15330481529236, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.56494879722595, "training_acc": 60.0, "val_loss": 17.126215994358063, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.41989254951477, "training_acc": 62.0, "val_loss": 17.058436572551727, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.5442464351654, "training_acc": 63.0, "val_loss": 17.016281187534332, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.85816955566406, "training_acc": 59.0, "val_loss": 17.00478494167328, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.01947808265686, "training_acc": 53.0, "val_loss": 17.104458808898926, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.9211995601654, "training_acc": 60.0, "val_loss": 16.9497013092041, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.27155232429504, "training_acc": 60.0, "val_loss": 16.974321007728577, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.41589641571045, "training_acc": 66.0, "val_loss": 17.01614409685135, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.31843137741089, "training_acc": 71.0, "val_loss": 17.00902134180069, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.39017915725708, "training_acc": 58.0, "val_loss": 16.97179824113846, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.05385327339172, "training_acc": 75.0, "val_loss": 16.841480135917664, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.46862721443176, "training_acc": 66.0, "val_loss": 16.83698296546936, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.14933705329895, "training_acc": 68.0, "val_loss": 16.93177819252014, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.85632419586182, "training_acc": 74.0, "val_loss": 16.900229454040527, "val_acc": 52.0}
{"epoch": 41, "training_loss": 63.89344835281372, "training_acc": 64.0, "val_loss": 16.855338215827942, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.746071577072144, "training_acc": 82.0, "val_loss": 16.73753261566162, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.28114366531372, "training_acc": 71.0, "val_loss": 16.929741203784943, "val_acc": 52.0}
{"epoch": 44, "training_loss": 63.03761649131775, "training_acc": 75.0, "val_loss": 16.767863929271698, "val_acc": 52.0}
{"epoch": 45, "training_loss": 60.53105330467224, "training_acc": 82.0, "val_loss": 17.25996881723404, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.082364320755005, "training_acc": 83.0, "val_loss": 17.19443053007126, "val_acc": 52.0}
{"epoch": 47, "training_loss": 65.7422206401825, "training_acc": 57.0, "val_loss": 17.1468123793602, "val_acc": 52.0}
{"epoch": 48, "training_loss": 63.656174659729004, "training_acc": 72.0, "val_loss": 16.80483967065811, "val_acc": 52.0}
{"epoch": 49, "training_loss": 62.410712480545044, "training_acc": 73.0, "val_loss": 17.419692873954773, "val_acc": 52.0}
{"epoch": 50, "training_loss": 63.262901306152344, "training_acc": 57.0, "val_loss": 16.888795793056488, "val_acc": 52.0}
{"epoch": 51, "training_loss": 62.48782706260681, "training_acc": 71.0, "val_loss": 17.298081517219543, "val_acc": 52.0}
{"epoch": 52, "training_loss": 62.69549083709717, "training_acc": 72.0, "val_loss": 17.029647529125214, "val_acc": 52.0}
{"epoch": 53, "training_loss": 62.49173092842102, "training_acc": 66.0, "val_loss": 16.826987266540527, "val_acc": 52.0}
{"epoch": 54, "training_loss": 61.920958518981934, "training_acc": 78.0, "val_loss": 16.72641783952713, "val_acc": 52.0}
{"epoch": 55, "training_loss": 59.69105911254883, "training_acc": 81.0, "val_loss": 16.597776114940643, "val_acc": 52.0}
{"epoch": 56, "training_loss": 58.10156774520874, "training_acc": 84.0, "val_loss": 16.696609556674957, "val_acc": 56.0}
{"epoch": 57, "training_loss": 55.949458599090576, "training_acc": 86.0, "val_loss": 17.007751762866974, "val_acc": 52.0}
{"epoch": 58, "training_loss": 58.826005697250366, "training_acc": 74.0, "val_loss": 17.0481875538826, "val_acc": 52.0}
{"epoch": 59, "training_loss": 56.54894542694092, "training_acc": 87.0, "val_loss": 16.962912678718567, "val_acc": 52.0}
{"epoch": 60, "training_loss": 57.16650319099426, "training_acc": 75.0, "val_loss": 17.08039939403534, "val_acc": 60.0}
{"epoch": 61, "training_loss": 56.6005973815918, "training_acc": 85.0, "val_loss": 16.697123646736145, "val_acc": 56.0}
{"epoch": 62, "training_loss": 55.9023711681366, "training_acc": 74.0, "val_loss": 16.599546372890472, "val_acc": 56.0}
{"epoch": 63, "training_loss": 52.61510467529297, "training_acc": 89.0, "val_loss": 16.439995169639587, "val_acc": 56.0}
{"epoch": 64, "training_loss": 52.09719944000244, "training_acc": 86.0, "val_loss": 16.57237410545349, "val_acc": 56.0}
{"epoch": 65, "training_loss": 50.630337715148926, "training_acc": 87.0, "val_loss": 16.840650141239166, "val_acc": 60.0}
{"epoch": 66, "training_loss": 52.46537232398987, "training_acc": 85.0, "val_loss": 16.670413315296173, "val_acc": 56.0}
{"epoch": 67, "training_loss": 48.70748674869537, "training_acc": 95.0, "val_loss": 16.553108394145966, "val_acc": 56.0}
{"epoch": 68, "training_loss": 49.808186054229736, "training_acc": 90.0, "val_loss": 16.732001304626465, "val_acc": 64.0}
{"epoch": 69, "training_loss": 47.933178305625916, "training_acc": 92.0, "val_loss": 17.287351191043854, "val_acc": 60.0}
{"epoch": 70, "training_loss": 46.06742858886719, "training_acc": 93.0, "val_loss": 16.886207461357117, "val_acc": 60.0}
{"epoch": 71, "training_loss": 46.46404325962067, "training_acc": 92.0, "val_loss": 16.922813653945923, "val_acc": 56.0}
{"epoch": 72, "training_loss": 50.07890498638153, "training_acc": 84.0, "val_loss": 16.967861354351044, "val_acc": 60.0}
{"epoch": 73, "training_loss": 44.71290051937103, "training_acc": 93.0, "val_loss": 16.966404020786285, "val_acc": 64.0}
{"epoch": 74, "training_loss": 43.9783798456192, "training_acc": 94.0, "val_loss": 16.599944233894348, "val_acc": 60.0}
{"epoch": 75, "training_loss": 43.301809310913086, "training_acc": 94.0, "val_loss": 17.30630099773407, "val_acc": 60.0}
{"epoch": 76, "training_loss": 43.09901535511017, "training_acc": 93.0, "val_loss": 16.628575325012207, "val_acc": 60.0}
{"epoch": 77, "training_loss": 43.056442618370056, "training_acc": 96.0, "val_loss": 17.063862085342407, "val_acc": 56.0}
{"epoch": 78, "training_loss": 46.966527581214905, "training_acc": 85.0, "val_loss": 17.877578735351562, "val_acc": 60.0}
{"epoch": 79, "training_loss": 44.266812562942505, "training_acc": 94.0, "val_loss": 16.854850947856903, "val_acc": 64.0}
{"epoch": 80, "training_loss": 41.77138674259186, "training_acc": 97.0, "val_loss": 16.958782076835632, "val_acc": 56.0}
{"epoch": 81, "training_loss": 41.685803055763245, "training_acc": 91.0, "val_loss": 17.728331685066223, "val_acc": 52.0}
{"epoch": 82, "training_loss": 39.858611702919006, "training_acc": 98.0, "val_loss": 16.80489480495453, "val_acc": 56.0}
