"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.79420781135559, "training_acc": 53.0, "val_loss": 17.55383014678955, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.86261677742004, "training_acc": 53.0, "val_loss": 17.45908111333847, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50889039039612, "training_acc": 53.0, "val_loss": 17.39502251148224, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.42803883552551, "training_acc": 53.0, "val_loss": 17.369715869426727, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.03814601898193, "training_acc": 53.0, "val_loss": 17.356710135936737, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0199453830719, "training_acc": 53.0, "val_loss": 17.3660546541214, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14010739326477, "training_acc": 53.0, "val_loss": 17.32887178659439, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.8252341747284, "training_acc": 53.0, "val_loss": 17.378802597522736, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.83701729774475, "training_acc": 53.0, "val_loss": 17.340609431266785, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.78913807868958, "training_acc": 53.0, "val_loss": 17.392665147781372, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.96352481842041, "training_acc": 53.0, "val_loss": 17.454391717910767, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.64507007598877, "training_acc": 53.0, "val_loss": 17.439544200897217, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.36173939704895, "training_acc": 53.0, "val_loss": 17.392393946647644, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.23264050483704, "training_acc": 55.0, "val_loss": 17.48071312904358, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.32446217536926, "training_acc": 53.0, "val_loss": 17.520199716091156, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.34242963790894, "training_acc": 53.0, "val_loss": 17.44602471590042, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.75837302207947, "training_acc": 57.0, "val_loss": 17.450210452079773, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.95899510383606, "training_acc": 59.0, "val_loss": 17.567309737205505, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.34232330322266, "training_acc": 57.0, "val_loss": 17.623713612556458, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.3164701461792, "training_acc": 59.0, "val_loss": 17.552359402179718, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.71050572395325, "training_acc": 61.0, "val_loss": 17.705298960208893, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.4258759021759, "training_acc": 62.0, "val_loss": 17.739422619342804, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.50304388999939, "training_acc": 52.0, "val_loss": 17.801006138324738, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.96717548370361, "training_acc": 64.0, "val_loss": 17.432743310928345, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.60443425178528, "training_acc": 65.0, "val_loss": 17.704714834690094, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.82098913192749, "training_acc": 58.0, "val_loss": 17.874547839164734, "val_acc": 52.0}
