"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39102125167847, "training_acc": 49.0, "val_loss": 17.197147011756897, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.51554489135742, "training_acc": 52.0, "val_loss": 17.412662506103516, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.92514824867249, "training_acc": 46.0, "val_loss": 17.39048659801483, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.65331482887268, "training_acc": 46.0, "val_loss": 17.405490577220917, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.41167521476746, "training_acc": 48.0, "val_loss": 17.23412126302719, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.82974314689636, "training_acc": 52.0, "val_loss": 17.226356267929077, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.31663942337036, "training_acc": 50.0, "val_loss": 17.382316291332245, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.37423610687256, "training_acc": 48.0, "val_loss": 17.228052020072937, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.90093612670898, "training_acc": 52.0, "val_loss": 17.17635542154312, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.21573948860168, "training_acc": 52.0, "val_loss": 17.335854470729828, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.36990094184875, "training_acc": 48.0, "val_loss": 17.360734939575195, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.36606979370117, "training_acc": 48.0, "val_loss": 17.242950201034546, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.349440574646, "training_acc": 52.0, "val_loss": 17.20428466796875, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.30273032188416, "training_acc": 52.0, "val_loss": 17.240925133228302, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25359082221985, "training_acc": 52.0, "val_loss": 17.215614020824432, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.26864266395569, "training_acc": 52.0, "val_loss": 17.181025445461273, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.33895182609558, "training_acc": 52.0, "val_loss": 17.162925004959106, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.32618856430054, "training_acc": 52.0, "val_loss": 17.211900651454926, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25164794921875, "training_acc": 52.0, "val_loss": 17.281514406204224, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26332473754883, "training_acc": 52.0, "val_loss": 17.28222221136093, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2873842716217, "training_acc": 52.0, "val_loss": 17.25166141986847, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23012399673462, "training_acc": 52.0, "val_loss": 17.18636453151703, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.57210087776184, "training_acc": 52.0, "val_loss": 17.156657576560974, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.32195258140564, "training_acc": 52.0, "val_loss": 17.22228080034256, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.16001200675964, "training_acc": 52.0, "val_loss": 17.38431304693222, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.54468297958374, "training_acc": 48.0, "val_loss": 17.454959452152252, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.07250332832336, "training_acc": 38.0, "val_loss": 17.300598323345184, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.28133058547974, "training_acc": 52.0, "val_loss": 17.290550470352173, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.31484031677246, "training_acc": 52.0, "val_loss": 17.25352108478546, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.20073819160461, "training_acc": 52.0, "val_loss": 17.180731892585754, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.77634382247925, "training_acc": 52.0, "val_loss": 17.159870266914368, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.75761842727661, "training_acc": 52.0, "val_loss": 17.235112190246582, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23721718788147, "training_acc": 52.0, "val_loss": 17.241451144218445, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.26555728912354, "training_acc": 52.0, "val_loss": 17.249038815498352, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2939965724945, "training_acc": 52.0, "val_loss": 17.221923172473907, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23833107948303, "training_acc": 52.0, "val_loss": 17.234934866428375, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25535559654236, "training_acc": 52.0, "val_loss": 17.235663533210754, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.37494778633118, "training_acc": 52.0, "val_loss": 17.212648689746857, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2246310710907, "training_acc": 52.0, "val_loss": 17.163075506687164, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.6264419555664, "training_acc": 52.0, "val_loss": 17.148201167583466, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.52188420295715, "training_acc": 52.0, "val_loss": 17.166174948215485, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.31147456169128, "training_acc": 52.0, "val_loss": 17.240993678569794, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2056348323822, "training_acc": 52.0, "val_loss": 17.325042188167572, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.35062170028687, "training_acc": 52.0, "val_loss": 17.406344413757324, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.55028939247131, "training_acc": 48.0, "val_loss": 17.46792048215866, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.57683944702148, "training_acc": 48.0, "val_loss": 17.3404723405838, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.33654737472534, "training_acc": 48.0, "val_loss": 17.244182527065277, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23225212097168, "training_acc": 52.0, "val_loss": 17.195381224155426, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.3089439868927, "training_acc": 52.0, "val_loss": 17.16189980506897, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.43522715568542, "training_acc": 52.0, "val_loss": 17.17188209295273, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2273268699646, "training_acc": 52.0, "val_loss": 17.255187034606934, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.22926378250122, "training_acc": 52.0, "val_loss": 17.364634573459625, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.36814713478088, "training_acc": 48.0, "val_loss": 17.398826777935028, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.41876935958862, "training_acc": 48.0, "val_loss": 17.34420210123062, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.30606150627136, "training_acc": 52.0, "val_loss": 17.255762219429016, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.44034147262573, "training_acc": 52.0, "val_loss": 17.19263792037964, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.27009582519531, "training_acc": 52.0, "val_loss": 17.20716804265976, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.28914666175842, "training_acc": 52.0, "val_loss": 17.24865883588791, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.24327087402344, "training_acc": 52.0, "val_loss": 17.252281308174133, "val_acc": 56.0}
