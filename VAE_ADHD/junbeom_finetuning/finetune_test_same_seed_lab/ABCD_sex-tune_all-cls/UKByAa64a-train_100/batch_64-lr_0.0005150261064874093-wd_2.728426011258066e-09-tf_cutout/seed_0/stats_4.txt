"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.6230800151825, "training_acc": 49.0, "val_loss": 17.31068789958954, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.68990278244019, "training_acc": 53.0, "val_loss": 17.31128990650177, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.35779809951782, "training_acc": 53.0, "val_loss": 17.320209741592407, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22163009643555, "training_acc": 53.0, "val_loss": 17.319080233573914, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1462345123291, "training_acc": 53.0, "val_loss": 17.312222719192505, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23643040657043, "training_acc": 53.0, "val_loss": 17.326362431049347, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1525948047638, "training_acc": 53.0, "val_loss": 17.357032001018524, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.24895119667053, "training_acc": 53.0, "val_loss": 17.32596606016159, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3234212398529, "training_acc": 53.0, "val_loss": 17.309388518333435, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30300259590149, "training_acc": 49.0, "val_loss": 17.316481471061707, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18287587165833, "training_acc": 53.0, "val_loss": 17.3283651471138, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.19154238700867, "training_acc": 53.0, "val_loss": 17.36394912004471, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.7175076007843, "training_acc": 53.0, "val_loss": 17.323507368564606, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.51325702667236, "training_acc": 53.0, "val_loss": 17.3474982380867, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13204145431519, "training_acc": 53.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11913967132568, "training_acc": 53.0, "val_loss": 17.339450120925903, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.51785731315613, "training_acc": 41.0, "val_loss": 17.340758442878723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.43022465705872, "training_acc": 47.0, "val_loss": 17.329780757427216, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23685479164124, "training_acc": 51.0, "val_loss": 17.31421798467636, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.07748007774353, "training_acc": 53.0, "val_loss": 17.365244030952454, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21055197715759, "training_acc": 53.0, "val_loss": 17.312540113925934, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.27273297309875, "training_acc": 53.0, "val_loss": 17.310483753681183, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19478940963745, "training_acc": 53.0, "val_loss": 17.308802902698517, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.42219614982605, "training_acc": 53.0, "val_loss": 17.30957329273224, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.04717516899109, "training_acc": 53.0, "val_loss": 17.360404133796692, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.46301984786987, "training_acc": 53.0, "val_loss": 17.423339188098907, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.4085762500763, "training_acc": 53.0, "val_loss": 17.3600435256958, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11285519599915, "training_acc": 53.0, "val_loss": 17.30865240097046, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.07884454727173, "training_acc": 53.0, "val_loss": 17.33722686767578, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.40694785118103, "training_acc": 47.0, "val_loss": 17.384326457977295, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.62853956222534, "training_acc": 47.0, "val_loss": 17.413412034511566, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.90129804611206, "training_acc": 47.0, "val_loss": 17.34963208436966, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.6912796497345, "training_acc": 43.0, "val_loss": 17.320352792739868, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.0795681476593, "training_acc": 53.0, "val_loss": 17.377036809921265, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.57060289382935, "training_acc": 53.0, "val_loss": 17.42509752511978, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.46540546417236, "training_acc": 53.0, "val_loss": 17.35471934080124, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.23207020759583, "training_acc": 53.0, "val_loss": 17.31814742088318, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13474488258362, "training_acc": 53.0, "val_loss": 17.308849096298218, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.25426244735718, "training_acc": 53.0, "val_loss": 17.309191823005676, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15154314041138, "training_acc": 53.0, "val_loss": 17.320816218852997, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.45688319206238, "training_acc": 45.0, "val_loss": 17.323529720306396, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.30540633201599, "training_acc": 53.0, "val_loss": 17.3116534948349, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14124870300293, "training_acc": 53.0, "val_loss": 17.334529757499695, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.42174124717712, "training_acc": 53.0, "val_loss": 17.341405153274536, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.16385984420776, "training_acc": 53.0, "val_loss": 17.309845983982086, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.34298729896545, "training_acc": 53.0, "val_loss": 17.310568690299988, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.18298864364624, "training_acc": 53.0, "val_loss": 17.31034815311432, "val_acc": 52.0}
