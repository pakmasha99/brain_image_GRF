"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.6785535812378, "training_acc": 46.0, "val_loss": 17.34774559736252, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.33390092849731, "training_acc": 53.0, "val_loss": 17.377839982509613, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.17378354072571, "training_acc": 53.0, "val_loss": 17.358846962451935, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.93899607658386, "training_acc": 45.0, "val_loss": 17.317938804626465, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.29406881332397, "training_acc": 53.0, "val_loss": 17.31276661157608, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.41414332389832, "training_acc": 47.0, "val_loss": 17.332807183265686, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.4016695022583, "training_acc": 53.0, "val_loss": 17.354334890842438, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17897605895996, "training_acc": 53.0, "val_loss": 17.309917509555817, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17906713485718, "training_acc": 53.0, "val_loss": 17.30871945619583, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2199809551239, "training_acc": 53.0, "val_loss": 17.31320172548294, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.29166436195374, "training_acc": 53.0, "val_loss": 17.312563955783844, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24844217300415, "training_acc": 53.0, "val_loss": 17.34042763710022, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16498708724976, "training_acc": 53.0, "val_loss": 17.312580347061157, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19565773010254, "training_acc": 53.0, "val_loss": 17.308741807937622, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2031819820404, "training_acc": 53.0, "val_loss": 17.315246164798737, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15457367897034, "training_acc": 53.0, "val_loss": 17.3104926943779, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14091563224792, "training_acc": 53.0, "val_loss": 17.30879545211792, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.51153755187988, "training_acc": 53.0, "val_loss": 17.308683693408966, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12616896629333, "training_acc": 53.0, "val_loss": 17.324844002723694, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.3035044670105, "training_acc": 51.0, "val_loss": 17.322608828544617, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.32235050201416, "training_acc": 53.0, "val_loss": 17.310598492622375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.28280901908875, "training_acc": 53.0, "val_loss": 17.382745444774628, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.65206670761108, "training_acc": 53.0, "val_loss": 17.35689491033554, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.69540619850159, "training_acc": 53.0, "val_loss": 17.30879545211792, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.29147291183472, "training_acc": 53.0, "val_loss": 17.30925291776657, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.50103759765625, "training_acc": 53.0, "val_loss": 17.320016026496887, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12226891517639, "training_acc": 53.0, "val_loss": 17.30862706899643, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16090321540833, "training_acc": 53.0, "val_loss": 17.31124520301819, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.91577816009521, "training_acc": 37.0, "val_loss": 17.309805750846863, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.09458184242249, "training_acc": 53.0, "val_loss": 17.36225336790085, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20849967002869, "training_acc": 53.0, "val_loss": 17.430488765239716, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.51670575141907, "training_acc": 53.0, "val_loss": 17.445720732212067, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.5926022529602, "training_acc": 53.0, "val_loss": 17.424485087394714, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.45989632606506, "training_acc": 53.0, "val_loss": 17.38215833902359, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.20976424217224, "training_acc": 53.0, "val_loss": 17.31385439634323, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.214688539505, "training_acc": 53.0, "val_loss": 17.317679524421692, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.25221848487854, "training_acc": 53.0, "val_loss": 17.31875389814377, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.2383713722229, "training_acc": 53.0, "val_loss": 17.309361696243286, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.16487693786621, "training_acc": 53.0, "val_loss": 17.314304411411285, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.12115430831909, "training_acc": 53.0, "val_loss": 17.330989241600037, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.20288562774658, "training_acc": 53.0, "val_loss": 17.342840135097504, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18090510368347, "training_acc": 53.0, "val_loss": 17.32478141784668, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12892150878906, "training_acc": 53.0, "val_loss": 17.309564352035522, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.15229749679565, "training_acc": 53.0, "val_loss": 17.315654456615448, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.23056364059448, "training_acc": 53.0, "val_loss": 17.31720119714737, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.2682797908783, "training_acc": 53.0, "val_loss": 17.310573160648346, "val_acc": 52.0}
