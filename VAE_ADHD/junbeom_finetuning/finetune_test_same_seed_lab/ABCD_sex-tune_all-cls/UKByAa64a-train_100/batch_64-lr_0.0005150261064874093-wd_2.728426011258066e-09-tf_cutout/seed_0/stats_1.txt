"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.86304473876953, "training_acc": 51.0, "val_loss": 17.394734919071198, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.43084526062012, "training_acc": 53.0, "val_loss": 17.80575066804886, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.45541787147522, "training_acc": 53.0, "val_loss": 17.354346811771393, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.58944392204285, "training_acc": 53.0, "val_loss": 17.3640176653862, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.37809443473816, "training_acc": 53.0, "val_loss": 17.350730299949646, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.00251722335815, "training_acc": 53.0, "val_loss": 17.3522487282753, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.92108273506165, "training_acc": 47.0, "val_loss": 17.331306636333466, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.94709515571594, "training_acc": 41.0, "val_loss": 17.318707704544067, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15612077713013, "training_acc": 53.0, "val_loss": 17.315754294395447, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.40638756752014, "training_acc": 53.0, "val_loss": 17.322874069213867, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.10580778121948, "training_acc": 53.0, "val_loss": 17.3759862780571, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.3452365398407, "training_acc": 53.0, "val_loss": 17.384834587574005, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.30718326568604, "training_acc": 53.0, "val_loss": 17.365823686122894, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21928262710571, "training_acc": 53.0, "val_loss": 17.31802672147751, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1930673122406, "training_acc": 53.0, "val_loss": 17.308883368968964, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1595664024353, "training_acc": 53.0, "val_loss": 17.30877310037613, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17626714706421, "training_acc": 53.0, "val_loss": 17.312274873256683, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19169926643372, "training_acc": 53.0, "val_loss": 17.335769534111023, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2095377445221, "training_acc": 53.0, "val_loss": 17.39584356546402, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.39953708648682, "training_acc": 53.0, "val_loss": 17.376823723316193, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.32765650749207, "training_acc": 53.0, "val_loss": 17.349538207054138, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23020076751709, "training_acc": 53.0, "val_loss": 17.310111224651337, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.27255296707153, "training_acc": 53.0, "val_loss": 17.345981299877167, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.41248750686646, "training_acc": 47.0, "val_loss": 17.347870767116547, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.70830941200256, "training_acc": 47.0, "val_loss": 17.318782210350037, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.21697187423706, "training_acc": 53.0, "val_loss": 17.348670959472656, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1981110572815, "training_acc": 53.0, "val_loss": 17.429354786872864, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.46396970748901, "training_acc": 53.0, "val_loss": 17.43573397397995, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.54654240608215, "training_acc": 53.0, "val_loss": 17.392253875732422, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.26930856704712, "training_acc": 53.0, "val_loss": 17.31376200914383, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.05742692947388, "training_acc": 53.0, "val_loss": 17.31799691915512, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.64137291908264, "training_acc": 43.0, "val_loss": 17.347246408462524, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.36242628097534, "training_acc": 47.0, "val_loss": 17.31226295232773, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.25106406211853, "training_acc": 53.0, "val_loss": 17.32664257287979, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16937279701233, "training_acc": 53.0, "val_loss": 17.360134422779083, "val_acc": 52.0}
