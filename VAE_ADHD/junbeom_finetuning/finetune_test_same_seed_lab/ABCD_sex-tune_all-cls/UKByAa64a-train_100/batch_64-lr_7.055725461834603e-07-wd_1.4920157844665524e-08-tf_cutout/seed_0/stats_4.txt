"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.58603405952454, "training_acc": 47.0, "val_loss": 17.34538972377777, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.48309969902039, "training_acc": 47.0, "val_loss": 17.33728051185608, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50541234016418, "training_acc": 47.0, "val_loss": 17.330452799797058, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.41489911079407, "training_acc": 47.0, "val_loss": 17.328938841819763, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.54229807853699, "training_acc": 47.0, "val_loss": 17.323802411556244, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3895833492279, "training_acc": 47.0, "val_loss": 17.316588759422302, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.45160031318665, "training_acc": 47.0, "val_loss": 17.308196425437927, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.34338068962097, "training_acc": 47.0, "val_loss": 17.305724322795868, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.40390300750732, "training_acc": 47.0, "val_loss": 17.305728793144226, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.46035099029541, "training_acc": 46.0, "val_loss": 17.31114536523819, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.33820676803589, "training_acc": 49.0, "val_loss": 17.314979434013367, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.35533547401428, "training_acc": 47.0, "val_loss": 17.315717041492462, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.41417384147644, "training_acc": 48.0, "val_loss": 17.314977943897247, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.25252628326416, "training_acc": 58.0, "val_loss": 17.314930260181427, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.35993885993958, "training_acc": 48.0, "val_loss": 17.313766479492188, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.30262231826782, "training_acc": 57.0, "val_loss": 17.31078177690506, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.31386280059814, "training_acc": 54.0, "val_loss": 17.30705201625824, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10740399360657, "training_acc": 56.0, "val_loss": 17.304088175296783, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18359112739563, "training_acc": 61.0, "val_loss": 17.300380766391754, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10400199890137, "training_acc": 57.0, "val_loss": 17.296378314495087, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14800596237183, "training_acc": 56.0, "val_loss": 17.293129861354828, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22050952911377, "training_acc": 48.0, "val_loss": 17.290854454040527, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.06324505805969, "training_acc": 55.0, "val_loss": 17.288166284561157, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.93822765350342, "training_acc": 59.0, "val_loss": 17.2883540391922, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2702989578247, "training_acc": 53.0, "val_loss": 17.285190522670746, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09693241119385, "training_acc": 54.0, "val_loss": 17.283309996128082, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.95002675056458, "training_acc": 54.0, "val_loss": 17.280982434749603, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10314559936523, "training_acc": 55.0, "val_loss": 17.282263934612274, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.04420018196106, "training_acc": 55.0, "val_loss": 17.284533381462097, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.84179735183716, "training_acc": 61.0, "val_loss": 17.28699803352356, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.94394040107727, "training_acc": 57.0, "val_loss": 17.287924885749817, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14622807502747, "training_acc": 52.0, "val_loss": 17.2870934009552, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.91148495674133, "training_acc": 56.0, "val_loss": 17.284034192562103, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.00811195373535, "training_acc": 56.0, "val_loss": 17.276935279369354, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.95308709144592, "training_acc": 54.0, "val_loss": 17.27454364299774, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16441750526428, "training_acc": 49.0, "val_loss": 17.27500557899475, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.91453337669373, "training_acc": 55.0, "val_loss": 17.276345193386078, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.83969974517822, "training_acc": 57.0, "val_loss": 17.277823388576508, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.8667483329773, "training_acc": 52.0, "val_loss": 17.2770693898201, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.74237537384033, "training_acc": 60.0, "val_loss": 17.27709174156189, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.01062822341919, "training_acc": 51.0, "val_loss": 17.27740615606308, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.83177185058594, "training_acc": 59.0, "val_loss": 17.27866679430008, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.64562654495239, "training_acc": 57.0, "val_loss": 17.280244827270508, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.98126220703125, "training_acc": 54.0, "val_loss": 17.281867563724518, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.75668287277222, "training_acc": 60.0, "val_loss": 17.28173792362213, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.99915432929993, "training_acc": 53.0, "val_loss": 17.277324199676514, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.68891954421997, "training_acc": 57.0, "val_loss": 17.269524931907654, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.74257636070251, "training_acc": 54.0, "val_loss": 17.26347506046295, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.86505913734436, "training_acc": 56.0, "val_loss": 17.254939675331116, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.68992209434509, "training_acc": 55.0, "val_loss": 17.246535420417786, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.83960056304932, "training_acc": 50.0, "val_loss": 17.241954803466797, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.58426594734192, "training_acc": 55.0, "val_loss": 17.239075899124146, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.72213459014893, "training_acc": 57.0, "val_loss": 17.238935828208923, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.87607717514038, "training_acc": 52.0, "val_loss": 17.24029630422592, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.80098390579224, "training_acc": 59.0, "val_loss": 17.24044531583786, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.7716326713562, "training_acc": 52.0, "val_loss": 17.24126636981964, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.62030124664307, "training_acc": 57.0, "val_loss": 17.241287231445312, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.67415595054626, "training_acc": 54.0, "val_loss": 17.239920794963837, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.67271542549133, "training_acc": 57.0, "val_loss": 17.24095493555069, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.8397786617279, "training_acc": 50.0, "val_loss": 17.24262535572052, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.88704299926758, "training_acc": 52.0, "val_loss": 17.244262993335724, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.42249798774719, "training_acc": 57.0, "val_loss": 17.244307696819305, "val_acc": 52.0}
{"epoch": 62, "training_loss": 68.59298729896545, "training_acc": 54.0, "val_loss": 17.239871621131897, "val_acc": 52.0}
{"epoch": 63, "training_loss": 68.57749676704407, "training_acc": 49.0, "val_loss": 17.23392903804779, "val_acc": 52.0}
{"epoch": 64, "training_loss": 68.54238653182983, "training_acc": 59.0, "val_loss": 17.229102551937103, "val_acc": 52.0}
{"epoch": 65, "training_loss": 68.55487322807312, "training_acc": 57.0, "val_loss": 17.227771878242493, "val_acc": 52.0}
{"epoch": 66, "training_loss": 68.81944632530212, "training_acc": 51.0, "val_loss": 17.23065972328186, "val_acc": 52.0}
{"epoch": 67, "training_loss": 68.27930760383606, "training_acc": 57.0, "val_loss": 17.238330841064453, "val_acc": 52.0}
{"epoch": 68, "training_loss": 68.56213688850403, "training_acc": 58.0, "val_loss": 17.24654883146286, "val_acc": 52.0}
{"epoch": 69, "training_loss": 68.58147549629211, "training_acc": 51.0, "val_loss": 17.24945604801178, "val_acc": 52.0}
{"epoch": 70, "training_loss": 68.21746683120728, "training_acc": 54.0, "val_loss": 17.2494575381279, "val_acc": 52.0}
{"epoch": 71, "training_loss": 68.4606819152832, "training_acc": 55.0, "val_loss": 17.247192561626434, "val_acc": 52.0}
{"epoch": 72, "training_loss": 68.54276967048645, "training_acc": 56.0, "val_loss": 17.244482040405273, "val_acc": 52.0}
{"epoch": 73, "training_loss": 68.4560718536377, "training_acc": 55.0, "val_loss": 17.240336537361145, "val_acc": 52.0}
{"epoch": 74, "training_loss": 68.50532150268555, "training_acc": 57.0, "val_loss": 17.239104211330414, "val_acc": 52.0}
{"epoch": 75, "training_loss": 68.34580278396606, "training_acc": 60.0, "val_loss": 17.23805069923401, "val_acc": 52.0}
{"epoch": 76, "training_loss": 68.75009489059448, "training_acc": 52.0, "val_loss": 17.23737120628357, "val_acc": 52.0}
{"epoch": 77, "training_loss": 68.2891845703125, "training_acc": 57.0, "val_loss": 17.2398641705513, "val_acc": 52.0}
{"epoch": 78, "training_loss": 68.63279294967651, "training_acc": 52.0, "val_loss": 17.24335104227066, "val_acc": 52.0}
{"epoch": 79, "training_loss": 68.51224184036255, "training_acc": 54.0, "val_loss": 17.245875298976898, "val_acc": 52.0}
{"epoch": 80, "training_loss": 68.60409140586853, "training_acc": 54.0, "val_loss": 17.25136935710907, "val_acc": 52.0}
{"epoch": 81, "training_loss": 68.1352047920227, "training_acc": 57.0, "val_loss": 17.25250333547592, "val_acc": 52.0}
{"epoch": 82, "training_loss": 68.67171263694763, "training_acc": 54.0, "val_loss": 17.252229154109955, "val_acc": 52.0}
{"epoch": 83, "training_loss": 68.34624791145325, "training_acc": 59.0, "val_loss": 17.253436148166656, "val_acc": 52.0}
{"epoch": 84, "training_loss": 68.40295028686523, "training_acc": 54.0, "val_loss": 17.253242433071136, "val_acc": 52.0}
