"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.45769596099854, "training_acc": 47.0, "val_loss": 17.33175218105316, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55502724647522, "training_acc": 47.0, "val_loss": 17.333833873271942, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.42568826675415, "training_acc": 47.0, "val_loss": 17.330212891101837, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.50448679924011, "training_acc": 47.0, "val_loss": 17.329446971416473, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38271737098694, "training_acc": 47.0, "val_loss": 17.325159907341003, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.38763070106506, "training_acc": 48.0, "val_loss": 17.321354150772095, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32717895507812, "training_acc": 48.0, "val_loss": 17.32061356306076, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17917227745056, "training_acc": 49.0, "val_loss": 17.31787770986557, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.25953245162964, "training_acc": 50.0, "val_loss": 17.314958572387695, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21308159828186, "training_acc": 52.0, "val_loss": 17.310155928134918, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18355059623718, "training_acc": 52.0, "val_loss": 17.305736243724823, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17058157920837, "training_acc": 52.0, "val_loss": 17.3032209277153, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21692657470703, "training_acc": 51.0, "val_loss": 17.301639914512634, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2552843093872, "training_acc": 50.0, "val_loss": 17.301031947135925, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09293842315674, "training_acc": 56.0, "val_loss": 17.299337685108185, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.04024815559387, "training_acc": 61.0, "val_loss": 17.298775911331177, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.04095387458801, "training_acc": 58.0, "val_loss": 17.298398911952972, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.02390956878662, "training_acc": 63.0, "val_loss": 17.298731207847595, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.95372867584229, "training_acc": 66.0, "val_loss": 17.301145195961, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.90561032295227, "training_acc": 67.0, "val_loss": 17.303466796875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.9606945514679, "training_acc": 60.0, "val_loss": 17.306098341941833, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1928322315216, "training_acc": 53.0, "val_loss": 17.308399081230164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.93249249458313, "training_acc": 61.0, "val_loss": 17.307431995868683, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.90058493614197, "training_acc": 61.0, "val_loss": 17.308534681797028, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17547249794006, "training_acc": 51.0, "val_loss": 17.30865389108658, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11531567573547, "training_acc": 57.0, "val_loss": 17.307788133621216, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.08774924278259, "training_acc": 54.0, "val_loss": 17.307835817337036, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.86189389228821, "training_acc": 57.0, "val_loss": 17.308039963245392, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.86338520050049, "training_acc": 63.0, "val_loss": 17.30848401784897, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.85499310493469, "training_acc": 62.0, "val_loss": 17.309094965457916, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.90351223945618, "training_acc": 60.0, "val_loss": 17.31111705303192, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.07630681991577, "training_acc": 50.0, "val_loss": 17.318107187747955, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.90126299858093, "training_acc": 58.0, "val_loss": 17.32478141784668, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.58850765228271, "training_acc": 69.0, "val_loss": 17.32765883207321, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.7415201663971, "training_acc": 64.0, "val_loss": 17.326369881629944, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.77666401863098, "training_acc": 60.0, "val_loss": 17.323113977909088, "val_acc": 52.0}
