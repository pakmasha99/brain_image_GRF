"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.4933729171753, "training_acc": 45.0, "val_loss": 17.391587793827057, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.12739992141724, "training_acc": 58.0, "val_loss": 17.333002388477325, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.3665406703949, "training_acc": 53.0, "val_loss": 17.296883463859558, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.23593211174011, "training_acc": 53.0, "val_loss": 17.30048507452011, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14604496955872, "training_acc": 53.0, "val_loss": 17.3067107796669, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0926353931427, "training_acc": 53.0, "val_loss": 17.306269705295563, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17890930175781, "training_acc": 53.0, "val_loss": 17.267224192619324, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.02907633781433, "training_acc": 53.0, "val_loss": 17.2918900847435, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.00513887405396, "training_acc": 53.0, "val_loss": 17.303282022476196, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.99899411201477, "training_acc": 53.0, "val_loss": 17.29859858751297, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0377242565155, "training_acc": 53.0, "val_loss": 17.293153703212738, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.85275340080261, "training_acc": 53.0, "val_loss": 17.30216145515442, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.79356241226196, "training_acc": 53.0, "val_loss": 17.330414056777954, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.77114486694336, "training_acc": 53.0, "val_loss": 17.366433143615723, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.63520169258118, "training_acc": 53.0, "val_loss": 17.397353053092957, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.70843553543091, "training_acc": 53.0, "val_loss": 17.373688519001007, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.31300854682922, "training_acc": 53.0, "val_loss": 17.34801083803177, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.4912576675415, "training_acc": 53.0, "val_loss": 17.359648644924164, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.32464337348938, "training_acc": 53.0, "val_loss": 17.376351356506348, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.21726274490356, "training_acc": 53.0, "val_loss": 17.33374148607254, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.57957077026367, "training_acc": 58.0, "val_loss": 17.30416864156723, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.15782165527344, "training_acc": 64.0, "val_loss": 17.30884462594986, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.09209489822388, "training_acc": 56.0, "val_loss": 17.372247576713562, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.97113561630249, "training_acc": 53.0, "val_loss": 17.430274188518524, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.46353530883789, "training_acc": 53.0, "val_loss": 17.38322079181671, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.92660450935364, "training_acc": 55.0, "val_loss": 17.378494143486023, "val_acc": 52.0}
