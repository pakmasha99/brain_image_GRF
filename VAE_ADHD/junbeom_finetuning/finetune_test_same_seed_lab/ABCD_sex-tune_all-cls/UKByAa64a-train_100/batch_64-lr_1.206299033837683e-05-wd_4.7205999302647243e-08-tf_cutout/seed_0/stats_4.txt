"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.11465239524841, "training_acc": 48.0, "val_loss": 17.36179292201996, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.33463525772095, "training_acc": 55.0, "val_loss": 17.30978786945343, "val_acc": 52.0}
{"epoch": 2, "training_loss": 68.98795056343079, "training_acc": 53.0, "val_loss": 17.382556200027466, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19529342651367, "training_acc": 53.0, "val_loss": 17.43089407682419, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.23545837402344, "training_acc": 53.0, "val_loss": 17.33746826648712, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25466275215149, "training_acc": 53.0, "val_loss": 17.299890518188477, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.92999863624573, "training_acc": 53.0, "val_loss": 17.28636473417282, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.05880880355835, "training_acc": 57.0, "val_loss": 17.284822463989258, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.6131944656372, "training_acc": 52.0, "val_loss": 17.272011935710907, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.55642867088318, "training_acc": 60.0, "val_loss": 17.297376692295074, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.032466173172, "training_acc": 53.0, "val_loss": 17.364521324634552, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.73033905029297, "training_acc": 53.0, "val_loss": 17.32565313577652, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.9881808757782, "training_acc": 53.0, "val_loss": 17.283466458320618, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.49139022827148, "training_acc": 53.0, "val_loss": 17.273637652397156, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.52183794975281, "training_acc": 53.0, "val_loss": 17.283912003040314, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.1597912311554, "training_acc": 53.0, "val_loss": 17.248836159706116, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.07068419456482, "training_acc": 53.0, "val_loss": 17.21820831298828, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.12801623344421, "training_acc": 59.0, "val_loss": 17.220818996429443, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.5848274230957, "training_acc": 57.0, "val_loss": 17.26647913455963, "val_acc": 52.0}
{"epoch": 19, "training_loss": 66.99497652053833, "training_acc": 56.0, "val_loss": 17.215274274349213, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.23340964317322, "training_acc": 59.0, "val_loss": 17.179805040359497, "val_acc": 52.0}
{"epoch": 21, "training_loss": 66.75400185585022, "training_acc": 74.0, "val_loss": 17.150595784187317, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.42585110664368, "training_acc": 61.0, "val_loss": 17.17488020658493, "val_acc": 52.0}
{"epoch": 23, "training_loss": 65.37940192222595, "training_acc": 65.0, "val_loss": 17.318500578403473, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.39769411087036, "training_acc": 60.0, "val_loss": 17.406392097473145, "val_acc": 52.0}
{"epoch": 25, "training_loss": 64.38711261749268, "training_acc": 59.0, "val_loss": 17.237208783626556, "val_acc": 52.0}
{"epoch": 26, "training_loss": 64.90045189857483, "training_acc": 60.0, "val_loss": 16.87862128019333, "val_acc": 52.0}
{"epoch": 27, "training_loss": 63.7862434387207, "training_acc": 67.0, "val_loss": 17.366184294223785, "val_acc": 52.0}
{"epoch": 28, "training_loss": 62.97185945510864, "training_acc": 61.0, "val_loss": 16.790196299552917, "val_acc": 52.0}
{"epoch": 29, "training_loss": 60.09183478355408, "training_acc": 78.0, "val_loss": 17.843730747699738, "val_acc": 52.0}
{"epoch": 30, "training_loss": 59.72575306892395, "training_acc": 70.0, "val_loss": 16.78590178489685, "val_acc": 52.0}
{"epoch": 31, "training_loss": 57.94389295578003, "training_acc": 80.0, "val_loss": 17.987653613090515, "val_acc": 52.0}
{"epoch": 32, "training_loss": 58.26166558265686, "training_acc": 75.0, "val_loss": 17.923463881015778, "val_acc": 52.0}
{"epoch": 33, "training_loss": 56.619518518447876, "training_acc": 74.0, "val_loss": 16.446971893310547, "val_acc": 52.0}
{"epoch": 34, "training_loss": 50.72423219680786, "training_acc": 84.0, "val_loss": 16.203035414218903, "val_acc": 64.0}
{"epoch": 35, "training_loss": 51.216726303100586, "training_acc": 80.0, "val_loss": 22.278660535812378, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.5894136428833, "training_acc": 58.0, "val_loss": 16.819384694099426, "val_acc": 72.0}
{"epoch": 37, "training_loss": 50.996044874191284, "training_acc": 75.0, "val_loss": 18.607261776924133, "val_acc": 52.0}
{"epoch": 38, "training_loss": 50.36052989959717, "training_acc": 77.0, "val_loss": 16.05454981327057, "val_acc": 68.0}
{"epoch": 39, "training_loss": 45.96077382564545, "training_acc": 82.0, "val_loss": 20.302625000476837, "val_acc": 52.0}
{"epoch": 40, "training_loss": 53.045408964157104, "training_acc": 72.0, "val_loss": 16.952399909496307, "val_acc": 68.0}
{"epoch": 41, "training_loss": 47.51504182815552, "training_acc": 80.0, "val_loss": 18.760517239570618, "val_acc": 52.0}
{"epoch": 42, "training_loss": 46.68721032142639, "training_acc": 79.0, "val_loss": 16.86009019613266, "val_acc": 52.0}
{"epoch": 43, "training_loss": 42.37616789340973, "training_acc": 80.0, "val_loss": 17.0473650097847, "val_acc": 64.0}
{"epoch": 44, "training_loss": 46.95101523399353, "training_acc": 77.0, "val_loss": 23.995907604694366, "val_acc": 52.0}
{"epoch": 45, "training_loss": 48.99444580078125, "training_acc": 75.0, "val_loss": 18.82687658071518, "val_acc": 60.0}
{"epoch": 46, "training_loss": 41.81047487258911, "training_acc": 80.0, "val_loss": 17.26893037557602, "val_acc": 56.0}
{"epoch": 47, "training_loss": 37.573883414268494, "training_acc": 85.0, "val_loss": 16.78086370229721, "val_acc": 64.0}
{"epoch": 48, "training_loss": 29.97569477558136, "training_acc": 94.0, "val_loss": 16.139397025108337, "val_acc": 72.0}
{"epoch": 49, "training_loss": 32.57074320316315, "training_acc": 91.0, "val_loss": 20.699045062065125, "val_acc": 52.0}
{"epoch": 50, "training_loss": 31.49966287612915, "training_acc": 89.0, "val_loss": 17.383810877799988, "val_acc": 64.0}
{"epoch": 51, "training_loss": 31.723547279834747, "training_acc": 90.0, "val_loss": 24.109181761741638, "val_acc": 52.0}
{"epoch": 52, "training_loss": 28.330636858940125, "training_acc": 91.0, "val_loss": 20.803160965442657, "val_acc": 56.0}
{"epoch": 53, "training_loss": 32.245352387428284, "training_acc": 85.0, "val_loss": 21.930456161499023, "val_acc": 60.0}
{"epoch": 54, "training_loss": 34.02357876300812, "training_acc": 88.0, "val_loss": 26.702210307121277, "val_acc": 52.0}
{"epoch": 55, "training_loss": 35.57239031791687, "training_acc": 86.0, "val_loss": 18.540389835834503, "val_acc": 68.0}
{"epoch": 56, "training_loss": 27.767717599868774, "training_acc": 87.0, "val_loss": 31.29909336566925, "val_acc": 52.0}
{"epoch": 57, "training_loss": 32.88362669944763, "training_acc": 85.0, "val_loss": 18.45424771308899, "val_acc": 76.0}
