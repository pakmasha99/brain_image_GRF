"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.44205927848816, "training_acc": 43.0, "val_loss": 17.31516867876053, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1687684059143, "training_acc": 55.0, "val_loss": 17.31632649898529, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1506118774414, "training_acc": 53.0, "val_loss": 17.31536090373993, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.07269310951233, "training_acc": 53.0, "val_loss": 17.30724722146988, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.08963775634766, "training_acc": 55.0, "val_loss": 17.30005294084549, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06089067459106, "training_acc": 58.0, "val_loss": 17.29387193918228, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1134569644928, "training_acc": 56.0, "val_loss": 17.28016585111618, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.0645842552185, "training_acc": 54.0, "val_loss": 17.275752127170563, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04207921028137, "training_acc": 53.0, "val_loss": 17.27222055196762, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.98539400100708, "training_acc": 54.0, "val_loss": 17.264972627162933, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.02649641036987, "training_acc": 53.0, "val_loss": 17.264224588871002, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0630271434784, "training_acc": 52.0, "val_loss": 17.276841402053833, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.80407667160034, "training_acc": 53.0, "val_loss": 17.283937335014343, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.7572386264801, "training_acc": 53.0, "val_loss": 17.281043529510498, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.98832249641418, "training_acc": 53.0, "val_loss": 17.27902740240097, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.68259119987488, "training_acc": 53.0, "val_loss": 17.300279438495636, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.69128608703613, "training_acc": 53.0, "val_loss": 17.303426563739777, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.63725709915161, "training_acc": 53.0, "val_loss": 17.303477227687836, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.70970249176025, "training_acc": 53.0, "val_loss": 17.29692369699478, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.54587292671204, "training_acc": 53.0, "val_loss": 17.281313240528107, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.55268120765686, "training_acc": 53.0, "val_loss": 17.286376655101776, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.52682161331177, "training_acc": 53.0, "val_loss": 17.285799980163574, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.54266357421875, "training_acc": 53.0, "val_loss": 17.279571294784546, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.4086401462555, "training_acc": 53.0, "val_loss": 17.28677749633789, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.39219093322754, "training_acc": 53.0, "val_loss": 17.29910671710968, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.45189380645752, "training_acc": 54.0, "val_loss": 17.315655946731567, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.41959285736084, "training_acc": 53.0, "val_loss": 17.327240109443665, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.66915154457092, "training_acc": 53.0, "val_loss": 17.327705025672913, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.34458994865417, "training_acc": 54.0, "val_loss": 17.328529059886932, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.17297339439392, "training_acc": 53.0, "val_loss": 17.32887178659439, "val_acc": 52.0}
