"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3331310749054, "training_acc": 53.0, "val_loss": 17.34868437051773, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17282032966614, "training_acc": 53.0, "val_loss": 17.383652925491333, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18983745574951, "training_acc": 53.0, "val_loss": 17.393456399440765, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.25248074531555, "training_acc": 53.0, "val_loss": 17.377138137817383, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19989538192749, "training_acc": 53.0, "val_loss": 17.31489896774292, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06203603744507, "training_acc": 53.0, "val_loss": 17.32659488916397, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1480405330658, "training_acc": 53.0, "val_loss": 17.315639555454254, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12274861335754, "training_acc": 53.0, "val_loss": 17.32746511697769, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.01136755943298, "training_acc": 53.0, "val_loss": 17.351390421390533, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.7063057422638, "training_acc": 53.0, "val_loss": 17.3465758562088, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.97883558273315, "training_acc": 53.0, "val_loss": 17.35154539346695, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.88822531700134, "training_acc": 53.0, "val_loss": 17.350518703460693, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.93260765075684, "training_acc": 53.0, "val_loss": 17.325754463672638, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.86919641494751, "training_acc": 53.0, "val_loss": 17.312845587730408, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.97321724891663, "training_acc": 53.0, "val_loss": 17.302055656909943, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.82142376899719, "training_acc": 53.0, "val_loss": 17.32051968574524, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.8089210987091, "training_acc": 53.0, "val_loss": 17.29034036397934, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.74657893180847, "training_acc": 53.0, "val_loss": 17.27225035429001, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.7685158252716, "training_acc": 53.0, "val_loss": 17.29707270860672, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.59541249275208, "training_acc": 53.0, "val_loss": 17.331424355506897, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.71589541435242, "training_acc": 53.0, "val_loss": 17.34829843044281, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.49870228767395, "training_acc": 53.0, "val_loss": 17.33846217393875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.56454491615295, "training_acc": 53.0, "val_loss": 17.33694076538086, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.51633501052856, "training_acc": 53.0, "val_loss": 17.346124351024628, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.47207593917847, "training_acc": 53.0, "val_loss": 17.359116673469543, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.43290615081787, "training_acc": 53.0, "val_loss": 17.365717887878418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.08321189880371, "training_acc": 53.0, "val_loss": 17.36305058002472, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.29533457756042, "training_acc": 53.0, "val_loss": 17.373262345790863, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.18986964225769, "training_acc": 54.0, "val_loss": 17.386581003665924, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.04555439949036, "training_acc": 53.0, "val_loss": 17.400062084197998, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.74381566047668, "training_acc": 53.0, "val_loss": 17.389817535877228, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.69761610031128, "training_acc": 55.0, "val_loss": 17.393481731414795, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.66035771369934, "training_acc": 57.0, "val_loss": 17.437930405139923, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.67059421539307, "training_acc": 54.0, "val_loss": 17.47533828020096, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.74621987342834, "training_acc": 53.0, "val_loss": 17.45089292526245, "val_acc": 52.0}
{"epoch": 35, "training_loss": 67.39676332473755, "training_acc": 54.0, "val_loss": 17.444244027137756, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.06652975082397, "training_acc": 58.0, "val_loss": 17.41895079612732, "val_acc": 52.0}
