"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3922507762909, "training_acc": 47.0, "val_loss": 17.30448305606842, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.35922360420227, "training_acc": 52.0, "val_loss": 17.27549582719803, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12399768829346, "training_acc": 60.0, "val_loss": 17.25693792104721, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16597485542297, "training_acc": 47.0, "val_loss": 17.25047677755356, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.09889316558838, "training_acc": 50.0, "val_loss": 17.234407365322113, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.07672953605652, "training_acc": 53.0, "val_loss": 17.244981229305267, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.99616169929504, "training_acc": 52.0, "val_loss": 17.2139972448349, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.90563225746155, "training_acc": 57.0, "val_loss": 17.243245244026184, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.68095541000366, "training_acc": 56.0, "val_loss": 17.211736738681793, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.79009675979614, "training_acc": 54.0, "val_loss": 17.208358645439148, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.87228322029114, "training_acc": 53.0, "val_loss": 17.23930537700653, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.61621761322021, "training_acc": 54.0, "val_loss": 17.24456399679184, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.84363269805908, "training_acc": 52.0, "val_loss": 17.254947125911713, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.83075308799744, "training_acc": 53.0, "val_loss": 17.26495325565338, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.32244491577148, "training_acc": 53.0, "val_loss": 17.234092950820923, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.38541769981384, "training_acc": 53.0, "val_loss": 17.251627147197723, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.58549928665161, "training_acc": 53.0, "val_loss": 17.222991585731506, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.28485822677612, "training_acc": 53.0, "val_loss": 17.20549166202545, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.64181995391846, "training_acc": 52.0, "val_loss": 17.210498452186584, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.31214570999146, "training_acc": 53.0, "val_loss": 17.236685752868652, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.21016502380371, "training_acc": 54.0, "val_loss": 17.21133440732956, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.18795418739319, "training_acc": 53.0, "val_loss": 17.23516881465912, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.22108101844788, "training_acc": 53.0, "val_loss": 17.252665758132935, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.21085047721863, "training_acc": 53.0, "val_loss": 17.256374657154083, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.06521606445312, "training_acc": 53.0, "val_loss": 17.25071668624878, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.9097785949707, "training_acc": 53.0, "val_loss": 17.225119471549988, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.07912874221802, "training_acc": 53.0, "val_loss": 17.219790816307068, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.04637837409973, "training_acc": 55.0, "val_loss": 17.284469306468964, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.99816083908081, "training_acc": 54.0, "val_loss": 17.27049946784973, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.56045126914978, "training_acc": 54.0, "val_loss": 17.263463139533997, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.3687756061554, "training_acc": 57.0, "val_loss": 17.271117866039276, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.57955765724182, "training_acc": 57.0, "val_loss": 17.21598207950592, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.40287756919861, "training_acc": 58.0, "val_loss": 17.244483530521393, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.28256225585938, "training_acc": 53.0, "val_loss": 17.227256298065186, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.78633999824524, "training_acc": 53.0, "val_loss": 17.21443086862564, "val_acc": 52.0}
{"epoch": 35, "training_loss": 67.55609393119812, "training_acc": 55.0, "val_loss": 17.206518352031708, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.48328185081482, "training_acc": 57.0, "val_loss": 17.163600027561188, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.04542756080627, "training_acc": 60.0, "val_loss": 17.164283990859985, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.08891224861145, "training_acc": 57.0, "val_loss": 17.19505488872528, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.77698302268982, "training_acc": 62.0, "val_loss": 17.213402688503265, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.14560055732727, "training_acc": 61.0, "val_loss": 17.177192866802216, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.72930216789246, "training_acc": 64.0, "val_loss": 17.178975045681, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.06933093070984, "training_acc": 61.0, "val_loss": 17.20375418663025, "val_acc": 52.0}
{"epoch": 43, "training_loss": 66.84018778800964, "training_acc": 54.0, "val_loss": 17.180262506008148, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.98963141441345, "training_acc": 56.0, "val_loss": 17.126573622226715, "val_acc": 52.0}
{"epoch": 45, "training_loss": 65.905437707901, "training_acc": 62.0, "val_loss": 17.14373379945755, "val_acc": 52.0}
{"epoch": 46, "training_loss": 66.24384999275208, "training_acc": 66.0, "val_loss": 17.12515950202942, "val_acc": 52.0}
{"epoch": 47, "training_loss": 66.20761704444885, "training_acc": 57.0, "val_loss": 17.182117700576782, "val_acc": 52.0}
{"epoch": 48, "training_loss": 66.12074542045593, "training_acc": 58.0, "val_loss": 17.142148315906525, "val_acc": 52.0}
{"epoch": 49, "training_loss": 66.00256681442261, "training_acc": 68.0, "val_loss": 17.167064547538757, "val_acc": 52.0}
{"epoch": 50, "training_loss": 65.91655421257019, "training_acc": 71.0, "val_loss": 17.15102344751358, "val_acc": 52.0}
{"epoch": 51, "training_loss": 66.31082344055176, "training_acc": 57.0, "val_loss": 17.164061963558197, "val_acc": 52.0}
{"epoch": 52, "training_loss": 64.87484288215637, "training_acc": 66.0, "val_loss": 17.164188623428345, "val_acc": 52.0}
{"epoch": 53, "training_loss": 65.78247690200806, "training_acc": 70.0, "val_loss": 17.134734988212585, "val_acc": 52.0}
{"epoch": 54, "training_loss": 65.15008687973022, "training_acc": 69.0, "val_loss": 17.215970158576965, "val_acc": 52.0}
{"epoch": 55, "training_loss": 65.17818427085876, "training_acc": 61.0, "val_loss": 17.198364436626434, "val_acc": 52.0}
{"epoch": 56, "training_loss": 64.77960133552551, "training_acc": 77.0, "val_loss": 17.20985621213913, "val_acc": 52.0}
{"epoch": 57, "training_loss": 65.04622769355774, "training_acc": 70.0, "val_loss": 17.252424359321594, "val_acc": 52.0}
{"epoch": 58, "training_loss": 64.32033085823059, "training_acc": 69.0, "val_loss": 17.182154953479767, "val_acc": 52.0}
{"epoch": 59, "training_loss": 64.80305814743042, "training_acc": 77.0, "val_loss": 17.240165174007416, "val_acc": 52.0}
{"epoch": 60, "training_loss": 64.24755859375, "training_acc": 74.0, "val_loss": 17.24366694688797, "val_acc": 52.0}
{"epoch": 61, "training_loss": 63.69778752326965, "training_acc": 70.0, "val_loss": 17.229871451854706, "val_acc": 52.0}
{"epoch": 62, "training_loss": 64.89130020141602, "training_acc": 85.0, "val_loss": 17.21879541873932, "val_acc": 52.0}
{"epoch": 63, "training_loss": 63.28957676887512, "training_acc": 76.0, "val_loss": 17.342445254325867, "val_acc": 52.0}
{"epoch": 64, "training_loss": 62.91540575027466, "training_acc": 70.0, "val_loss": 17.27718859910965, "val_acc": 52.0}
{"epoch": 65, "training_loss": 63.14326024055481, "training_acc": 69.0, "val_loss": 17.178112268447876, "val_acc": 52.0}
