"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.85817313194275, "training_acc": 47.0, "val_loss": 17.39935278892517, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.67627286911011, "training_acc": 47.0, "val_loss": 17.344550788402557, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.53968524932861, "training_acc": 47.0, "val_loss": 17.318589985370636, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.31730794906616, "training_acc": 47.0, "val_loss": 17.29658842086792, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25426602363586, "training_acc": 49.0, "val_loss": 17.28328913450241, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22067737579346, "training_acc": 52.0, "val_loss": 17.28077083826065, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.31895017623901, "training_acc": 59.0, "val_loss": 17.28128045797348, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.30374836921692, "training_acc": 52.0, "val_loss": 17.259761691093445, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.09737944602966, "training_acc": 55.0, "val_loss": 17.287860810756683, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.88654112815857, "training_acc": 66.0, "val_loss": 17.309865355491638, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.25124716758728, "training_acc": 54.0, "val_loss": 17.296776175498962, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.91854691505432, "training_acc": 64.0, "val_loss": 17.274652421474457, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.6663715839386, "training_acc": 66.0, "val_loss": 17.256174981594086, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.34847354888916, "training_acc": 66.0, "val_loss": 17.227891087532043, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.51654767990112, "training_acc": 56.0, "val_loss": 17.275777459144592, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.99298596382141, "training_acc": 51.0, "val_loss": 17.330695688724518, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.83433365821838, "training_acc": 49.0, "val_loss": 17.367343604564667, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.60696268081665, "training_acc": 55.0, "val_loss": 17.369870841503143, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.77706527709961, "training_acc": 62.0, "val_loss": 17.361880838871002, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.61193656921387, "training_acc": 60.0, "val_loss": 17.349590361118317, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.73700308799744, "training_acc": 50.0, "val_loss": 17.28997379541397, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.65856742858887, "training_acc": 53.0, "val_loss": 17.26837456226349, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.59768152236938, "training_acc": 53.0, "val_loss": 17.278549075126648, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.39893174171448, "training_acc": 55.0, "val_loss": 17.302171885967255, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.12446403503418, "training_acc": 60.0, "val_loss": 17.297513782978058, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.32600331306458, "training_acc": 54.0, "val_loss": 17.271000146865845, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.03956413269043, "training_acc": 59.0, "val_loss": 17.296801507472992, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.38682913780212, "training_acc": 59.0, "val_loss": 17.329353094100952, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.23160672187805, "training_acc": 60.0, "val_loss": 17.281252145767212, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.04296922683716, "training_acc": 58.0, "val_loss": 17.234019935131073, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.20624089241028, "training_acc": 51.0, "val_loss": 17.247840762138367, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.87220478057861, "training_acc": 54.0, "val_loss": 17.322807013988495, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.13485670089722, "training_acc": 61.0, "val_loss": 17.36106127500534, "val_acc": 52.0}
