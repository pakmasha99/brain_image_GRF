"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.93519425392151, "training_acc": 53.0, "val_loss": 17.493072152137756, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.78681945800781, "training_acc": 53.0, "val_loss": 17.476940155029297, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.47208642959595, "training_acc": 53.0, "val_loss": 17.482464015483856, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.39114117622375, "training_acc": 53.0, "val_loss": 17.45370626449585, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33851933479309, "training_acc": 53.0, "val_loss": 17.458003759384155, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20638298988342, "training_acc": 53.0, "val_loss": 17.44142472743988, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21443486213684, "training_acc": 53.0, "val_loss": 17.385368049144745, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.3377730846405, "training_acc": 53.0, "val_loss": 17.318007349967957, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2199969291687, "training_acc": 53.0, "val_loss": 17.307056486606598, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23821258544922, "training_acc": 53.0, "val_loss": 17.34369993209839, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20355939865112, "training_acc": 53.0, "val_loss": 17.373082041740417, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.99097013473511, "training_acc": 53.0, "val_loss": 17.40381270647049, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.02644085884094, "training_acc": 53.0, "val_loss": 17.39860475063324, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.89443325996399, "training_acc": 53.0, "val_loss": 17.38015115261078, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.90667295455933, "training_acc": 53.0, "val_loss": 17.322003841400146, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.90152025222778, "training_acc": 53.0, "val_loss": 17.28280782699585, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.59684491157532, "training_acc": 53.0, "val_loss": 17.320415377616882, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.66677570343018, "training_acc": 53.0, "val_loss": 17.344701290130615, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.58691120147705, "training_acc": 53.0, "val_loss": 17.37005263566971, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.47036385536194, "training_acc": 53.0, "val_loss": 17.381522059440613, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.50149250030518, "training_acc": 53.0, "val_loss": 17.39477515220642, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.31314277648926, "training_acc": 53.0, "val_loss": 17.414550483226776, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.53031635284424, "training_acc": 53.0, "val_loss": 17.39981472492218, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.1383626461029, "training_acc": 53.0, "val_loss": 17.427249252796173, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.3552508354187, "training_acc": 53.0, "val_loss": 17.415066063404083, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.45283842086792, "training_acc": 53.0, "val_loss": 17.41175651550293, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.1144208908081, "training_acc": 53.0, "val_loss": 17.44970977306366, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.36790871620178, "training_acc": 53.0, "val_loss": 17.430810630321503, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.93812084197998, "training_acc": 53.0, "val_loss": 17.336532473564148, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.05402827262878, "training_acc": 54.0, "val_loss": 17.30891615152359, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.29023098945618, "training_acc": 54.0, "val_loss": 17.366915941238403, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.15280270576477, "training_acc": 54.0, "val_loss": 17.510907351970673, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.14304208755493, "training_acc": 53.0, "val_loss": 17.504416406154633, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.28359651565552, "training_acc": 53.0, "val_loss": 17.474551498889923, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.68258810043335, "training_acc": 54.0, "val_loss": 17.415934801101685, "val_acc": 52.0}
