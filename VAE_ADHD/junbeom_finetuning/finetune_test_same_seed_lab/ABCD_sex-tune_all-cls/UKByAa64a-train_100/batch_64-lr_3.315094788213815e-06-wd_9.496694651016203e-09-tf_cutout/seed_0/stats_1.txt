"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.91043877601624, "training_acc": 47.0, "val_loss": 17.641039192676544, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.7334930896759, "training_acc": 47.0, "val_loss": 17.56908744573593, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.44514966011047, "training_acc": 47.0, "val_loss": 17.527049779891968, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.3860023021698, "training_acc": 47.0, "val_loss": 17.45830327272415, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.16928577423096, "training_acc": 47.0, "val_loss": 17.40209311246872, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.23534655570984, "training_acc": 47.0, "val_loss": 17.365942895412445, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.71583986282349, "training_acc": 47.0, "val_loss": 17.348140478134155, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.74161744117737, "training_acc": 47.0, "val_loss": 17.354072630405426, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.82293009757996, "training_acc": 47.0, "val_loss": 17.35178381204605, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.41544437408447, "training_acc": 47.0, "val_loss": 17.33211874961853, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4013819694519, "training_acc": 47.0, "val_loss": 17.29811131954193, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.39446187019348, "training_acc": 49.0, "val_loss": 17.258460819721222, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.61200284957886, "training_acc": 50.0, "val_loss": 17.253050208091736, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22796750068665, "training_acc": 54.0, "val_loss": 17.246612906455994, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.88805031776428, "training_acc": 56.0, "val_loss": 17.249737679958344, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.3195481300354, "training_acc": 58.0, "val_loss": 17.27563887834549, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06754970550537, "training_acc": 60.0, "val_loss": 17.298060655593872, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.72039532661438, "training_acc": 64.0, "val_loss": 17.268672585487366, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.88589000701904, "training_acc": 54.0, "val_loss": 17.233218252658844, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.53852272033691, "training_acc": 58.0, "val_loss": 17.221876978874207, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.6934883594513, "training_acc": 62.0, "val_loss": 17.239783704280853, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.61204648017883, "training_acc": 59.0, "val_loss": 17.25427210330963, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.16880416870117, "training_acc": 63.0, "val_loss": 17.24524199962616, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.15070486068726, "training_acc": 61.0, "val_loss": 17.226549983024597, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.1419050693512, "training_acc": 59.0, "val_loss": 17.183993756771088, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.62587571144104, "training_acc": 60.0, "val_loss": 17.121398448944092, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.55548024177551, "training_acc": 58.0, "val_loss": 17.18958467245102, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.00492119789124, "training_acc": 47.0, "val_loss": 17.220674455165863, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.51186418533325, "training_acc": 54.0, "val_loss": 17.324014008045197, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.93955326080322, "training_acc": 50.0, "val_loss": 17.36665815114975, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.08612036705017, "training_acc": 61.0, "val_loss": 17.31066405773163, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.37094116210938, "training_acc": 60.0, "val_loss": 17.222468554973602, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.72552442550659, "training_acc": 52.0, "val_loss": 17.196914553642273, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.8260669708252, "training_acc": 53.0, "val_loss": 17.181262373924255, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.71162152290344, "training_acc": 57.0, "val_loss": 17.220614850521088, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.6631293296814, "training_acc": 53.0, "val_loss": 17.284604907035828, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.02994847297668, "training_acc": 60.0, "val_loss": 17.27205216884613, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.349538564682, "training_acc": 54.0, "val_loss": 17.224933207035065, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.29045486450195, "training_acc": 55.0, "val_loss": 17.17507690191269, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.5331118106842, "training_acc": 49.0, "val_loss": 17.17951148748398, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.84230732917786, "training_acc": 59.0, "val_loss": 17.21189022064209, "val_acc": 52.0}
{"epoch": 41, "training_loss": 67.95516204833984, "training_acc": 59.0, "val_loss": 17.236118018627167, "val_acc": 52.0}
{"epoch": 42, "training_loss": 67.75064325332642, "training_acc": 58.0, "val_loss": 17.25095957517624, "val_acc": 52.0}
{"epoch": 43, "training_loss": 67.98550748825073, "training_acc": 59.0, "val_loss": 17.328011989593506, "val_acc": 52.0}
{"epoch": 44, "training_loss": 67.88083338737488, "training_acc": 53.0, "val_loss": 17.316627502441406, "val_acc": 52.0}
