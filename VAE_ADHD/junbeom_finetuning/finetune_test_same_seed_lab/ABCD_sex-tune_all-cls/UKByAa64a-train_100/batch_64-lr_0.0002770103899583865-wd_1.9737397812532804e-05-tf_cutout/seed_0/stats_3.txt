"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.04045939445496, "training_acc": 50.0, "val_loss": 17.39349663257599, "val_acc": 52.0}
{"epoch": 1, "training_loss": 145.4178009033203, "training_acc": 47.0, "val_loss": 18.31323206424713, "val_acc": 56.0}
{"epoch": 2, "training_loss": 74.40794587135315, "training_acc": 47.0, "val_loss": 17.37811267375946, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.38988184928894, "training_acc": 46.0, "val_loss": 22.983136773109436, "val_acc": 52.0}
{"epoch": 4, "training_loss": 86.44517230987549, "training_acc": 55.0, "val_loss": 18.325063586235046, "val_acc": 48.0}
{"epoch": 5, "training_loss": 69.89825820922852, "training_acc": 57.0, "val_loss": 17.878417670726776, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.2422456741333, "training_acc": 53.0, "val_loss": 17.860740423202515, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.83384799957275, "training_acc": 53.0, "val_loss": 17.386001348495483, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.64337396621704, "training_acc": 53.0, "val_loss": 17.322522401809692, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.25851464271545, "training_acc": 53.0, "val_loss": 17.31684058904648, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.08075404167175, "training_acc": 53.0, "val_loss": 17.43158996105194, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.49614834785461, "training_acc": 53.0, "val_loss": 17.345477640628815, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.31825375556946, "training_acc": 53.0, "val_loss": 17.31712520122528, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.36394166946411, "training_acc": 53.0, "val_loss": 17.32199490070343, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.24203038215637, "training_acc": 53.0, "val_loss": 17.317548394203186, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22347688674927, "training_acc": 53.0, "val_loss": 17.312487959861755, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20749568939209, "training_acc": 53.0, "val_loss": 17.36225038766861, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.03246116638184, "training_acc": 53.0, "val_loss": 17.44799017906189, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.57340240478516, "training_acc": 53.0, "val_loss": 17.31695532798767, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13231229782104, "training_acc": 53.0, "val_loss": 17.312799394130707, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.37156224250793, "training_acc": 53.0, "val_loss": 17.31443703174591, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17162132263184, "training_acc": 53.0, "val_loss": 17.330005764961243, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.34187865257263, "training_acc": 54.0, "val_loss": 17.325592041015625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27619886398315, "training_acc": 53.0, "val_loss": 17.320817708969116, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.29040122032166, "training_acc": 53.0, "val_loss": 17.316600680351257, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18575477600098, "training_acc": 53.0, "val_loss": 17.317834496498108, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11240863800049, "training_acc": 53.0, "val_loss": 17.323453724384308, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.08956623077393, "training_acc": 53.0, "val_loss": 17.348313331604004, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.28774642944336, "training_acc": 53.0, "val_loss": 17.3652246594429, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19021344184875, "training_acc": 53.0, "val_loss": 17.33042448759079, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.09476351737976, "training_acc": 53.0, "val_loss": 17.320677638053894, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12664341926575, "training_acc": 53.0, "val_loss": 17.32315421104431, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17577362060547, "training_acc": 53.0, "val_loss": 17.32383668422699, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.38995003700256, "training_acc": 53.0, "val_loss": 17.321565747261047, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.01844024658203, "training_acc": 53.0, "val_loss": 17.345798015594482, "val_acc": 52.0}
