"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.50287580490112, "training_acc": 50.0, "val_loss": 17.802348732948303, "val_acc": 52.0}
{"epoch": 1, "training_loss": 75.67159271240234, "training_acc": 47.0, "val_loss": 17.312738299369812, "val_acc": 52.0}
{"epoch": 2, "training_loss": 82.7156891822815, "training_acc": 53.0, "val_loss": 17.629802227020264, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.20551800727844, "training_acc": 47.0, "val_loss": 17.346888780593872, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30961227416992, "training_acc": 54.0, "val_loss": 17.455416917800903, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.83940052986145, "training_acc": 47.0, "val_loss": 17.94281005859375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.00075078010559, "training_acc": 53.0, "val_loss": 17.392753064632416, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28187870979309, "training_acc": 53.0, "val_loss": 17.366915941238403, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.51213765144348, "training_acc": 47.0, "val_loss": 17.307543754577637, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20896911621094, "training_acc": 53.0, "val_loss": 17.441868782043457, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.44752883911133, "training_acc": 53.0, "val_loss": 17.32824146747589, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.28156518936157, "training_acc": 53.0, "val_loss": 17.3227921128273, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25611853599548, "training_acc": 53.0, "val_loss": 17.311470210552216, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.82123494148254, "training_acc": 53.0, "val_loss": 17.359259724617004, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17619180679321, "training_acc": 53.0, "val_loss": 17.31051802635193, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16223335266113, "training_acc": 53.0, "val_loss": 17.320357263088226, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.27634501457214, "training_acc": 53.0, "val_loss": 17.313438653945923, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.305428981781, "training_acc": 53.0, "val_loss": 17.309892177581787, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14837384223938, "training_acc": 53.0, "val_loss": 17.31017678976059, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14843797683716, "training_acc": 53.0, "val_loss": 17.308980226516724, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14104199409485, "training_acc": 53.0, "val_loss": 17.316709458827972, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14240264892578, "training_acc": 53.0, "val_loss": 17.34408140182495, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20832109451294, "training_acc": 53.0, "val_loss": 17.404137551784515, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.40445947647095, "training_acc": 53.0, "val_loss": 17.36745983362198, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1075701713562, "training_acc": 53.0, "val_loss": 17.308352887630463, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15360140800476, "training_acc": 53.0, "val_loss": 17.338259518146515, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.45486664772034, "training_acc": 47.0, "val_loss": 17.338286340236664, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.40364837646484, "training_acc": 45.0, "val_loss": 17.310260236263275, "val_acc": 52.0}
