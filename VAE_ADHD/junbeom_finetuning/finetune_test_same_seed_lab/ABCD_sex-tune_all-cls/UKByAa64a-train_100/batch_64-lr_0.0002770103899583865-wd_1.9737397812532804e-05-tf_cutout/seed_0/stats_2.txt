"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.02176213264465, "training_acc": 47.0, "val_loss": 17.958201467990875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 79.26660132408142, "training_acc": 49.0, "val_loss": 17.61699765920639, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.50363039970398, "training_acc": 51.0, "val_loss": 20.927077531814575, "val_acc": 52.0}
{"epoch": 3, "training_loss": 75.0997850894928, "training_acc": 57.0, "val_loss": 17.444099485874176, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.45149731636047, "training_acc": 51.0, "val_loss": 17.514148354530334, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.6445620059967, "training_acc": 53.0, "val_loss": 17.30102151632309, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17327976226807, "training_acc": 53.0, "val_loss": 17.361940443515778, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.68902897834778, "training_acc": 47.0, "val_loss": 17.67234355211258, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.21473431587219, "training_acc": 53.0, "val_loss": 17.436376214027405, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2187488079071, "training_acc": 53.0, "val_loss": 17.33713150024414, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.35043740272522, "training_acc": 46.0, "val_loss": 17.355002462863922, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.39503216743469, "training_acc": 50.0, "val_loss": 17.307540774345398, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15368056297302, "training_acc": 53.0, "val_loss": 17.362089455127716, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.26697778701782, "training_acc": 53.0, "val_loss": 17.351138591766357, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21239805221558, "training_acc": 53.0, "val_loss": 17.3263281583786, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.76641535758972, "training_acc": 53.0, "val_loss": 17.305274307727814, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.42067813873291, "training_acc": 53.0, "val_loss": 17.32848286628723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13135099411011, "training_acc": 53.0, "val_loss": 17.463210225105286, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.71523332595825, "training_acc": 53.0, "val_loss": 17.47060716152191, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.69407320022583, "training_acc": 53.0, "val_loss": 17.340999841690063, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1217930316925, "training_acc": 53.0, "val_loss": 17.314830422401428, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.35159182548523, "training_acc": 53.0, "val_loss": 17.317982017993927, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2202217578888, "training_acc": 53.0, "val_loss": 17.31049120426178, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11109280586243, "training_acc": 53.0, "val_loss": 17.31782853603363, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09880757331848, "training_acc": 53.0, "val_loss": 17.34047532081604, "val_acc": 52.0}
