"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.0250096321106, "training_acc": 53.0, "val_loss": 17.281851172447205, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.11614322662354, "training_acc": 53.0, "val_loss": 17.292506992816925, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.05537033081055, "training_acc": 53.0, "val_loss": 17.33373999595642, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13280034065247, "training_acc": 53.0, "val_loss": 17.270782589912415, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.8804771900177, "training_acc": 53.0, "val_loss": 17.2650545835495, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.01442313194275, "training_acc": 53.0, "val_loss": 17.236261069774628, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.8782434463501, "training_acc": 53.0, "val_loss": 17.251990735530853, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.72871088981628, "training_acc": 53.0, "val_loss": 17.29641705751419, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.7658920288086, "training_acc": 53.0, "val_loss": 17.3209011554718, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.8756411075592, "training_acc": 53.0, "val_loss": 17.287549376487732, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.6646044254303, "training_acc": 53.0, "val_loss": 17.27374643087387, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.78894376754761, "training_acc": 53.0, "val_loss": 17.259852588176727, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.6568489074707, "training_acc": 53.0, "val_loss": 17.20731258392334, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.4775116443634, "training_acc": 53.0, "val_loss": 17.221665382385254, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.5545437335968, "training_acc": 53.0, "val_loss": 17.213353514671326, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.63660073280334, "training_acc": 53.0, "val_loss": 17.203885316848755, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.49334955215454, "training_acc": 53.0, "val_loss": 17.196685075759888, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.12701082229614, "training_acc": 53.0, "val_loss": 17.167174816131592, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.40238189697266, "training_acc": 53.0, "val_loss": 17.18624085187912, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.27390336990356, "training_acc": 53.0, "val_loss": 17.176364362239838, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.02686500549316, "training_acc": 53.0, "val_loss": 17.215342819690704, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.92530560493469, "training_acc": 53.0, "val_loss": 17.253637313842773, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.95080900192261, "training_acc": 53.0, "val_loss": 17.194393277168274, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.83043622970581, "training_acc": 53.0, "val_loss": 17.145507037639618, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.73714923858643, "training_acc": 55.0, "val_loss": 17.154641449451447, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.1393187046051, "training_acc": 54.0, "val_loss": 17.13014990091324, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.13050436973572, "training_acc": 53.0, "val_loss": 17.226772010326385, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.20534634590149, "training_acc": 53.0, "val_loss": 17.03854352235794, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.98158955574036, "training_acc": 67.0, "val_loss": 17.126481235027313, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.13179039955139, "training_acc": 75.0, "val_loss": 17.048896849155426, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.9618992805481, "training_acc": 59.0, "val_loss": 17.051342129707336, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.85464906692505, "training_acc": 55.0, "val_loss": 17.09563434123993, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.75418138504028, "training_acc": 74.0, "val_loss": 16.95368140935898, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.43466687202454, "training_acc": 75.0, "val_loss": 17.07242578268051, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.75027704238892, "training_acc": 62.0, "val_loss": 16.910812258720398, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.70949125289917, "training_acc": 76.0, "val_loss": 17.034251987934113, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.93217658996582, "training_acc": 57.0, "val_loss": 17.103837430477142, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.4376220703125, "training_acc": 76.0, "val_loss": 16.894595324993134, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.18143057823181, "training_acc": 75.0, "val_loss": 17.142195999622345, "val_acc": 52.0}
{"epoch": 39, "training_loss": 63.95137143135071, "training_acc": 67.0, "val_loss": 17.04947203397751, "val_acc": 52.0}
{"epoch": 40, "training_loss": 65.04584431648254, "training_acc": 82.0, "val_loss": 16.80959314107895, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.02631568908691, "training_acc": 67.0, "val_loss": 16.73971712589264, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.39618992805481, "training_acc": 80.0, "val_loss": 16.836650669574738, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.06620478630066, "training_acc": 77.0, "val_loss": 16.725093126296997, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62.321282148361206, "training_acc": 85.0, "val_loss": 16.731107234954834, "val_acc": 52.0}
{"epoch": 45, "training_loss": 60.80951237678528, "training_acc": 76.0, "val_loss": 16.776657104492188, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.22908592224121, "training_acc": 83.0, "val_loss": 16.717366874217987, "val_acc": 52.0}
{"epoch": 47, "training_loss": 60.999576568603516, "training_acc": 75.0, "val_loss": 16.5259912610054, "val_acc": 52.0}
{"epoch": 48, "training_loss": 60.15657043457031, "training_acc": 76.0, "val_loss": 16.89651906490326, "val_acc": 52.0}
{"epoch": 49, "training_loss": 62.79406023025513, "training_acc": 77.0, "val_loss": 16.51180386543274, "val_acc": 52.0}
{"epoch": 50, "training_loss": 60.535205364227295, "training_acc": 75.0, "val_loss": 16.51315689086914, "val_acc": 52.0}
{"epoch": 51, "training_loss": 59.07702445983887, "training_acc": 89.0, "val_loss": 16.559724509716034, "val_acc": 52.0}
{"epoch": 52, "training_loss": 57.98822379112244, "training_acc": 81.0, "val_loss": 16.693294048309326, "val_acc": 52.0}
{"epoch": 53, "training_loss": 57.335182905197144, "training_acc": 91.0, "val_loss": 16.606801748275757, "val_acc": 52.0}
{"epoch": 54, "training_loss": 55.82150149345398, "training_acc": 87.0, "val_loss": 17.215697467327118, "val_acc": 52.0}
{"epoch": 55, "training_loss": 58.61847424507141, "training_acc": 82.0, "val_loss": 16.527190804481506, "val_acc": 52.0}
{"epoch": 56, "training_loss": 56.729114294052124, "training_acc": 87.0, "val_loss": 16.341739892959595, "val_acc": 52.0}
{"epoch": 57, "training_loss": 54.06801700592041, "training_acc": 89.0, "val_loss": 16.658900678157806, "val_acc": 52.0}
{"epoch": 58, "training_loss": 53.02653622627258, "training_acc": 96.0, "val_loss": 16.42601042985916, "val_acc": 52.0}
{"epoch": 59, "training_loss": 54.60405945777893, "training_acc": 88.0, "val_loss": 16.393691301345825, "val_acc": 52.0}
{"epoch": 60, "training_loss": 54.12080001831055, "training_acc": 84.0, "val_loss": 16.56203418970108, "val_acc": 56.0}
{"epoch": 61, "training_loss": 54.47024464607239, "training_acc": 88.0, "val_loss": 16.248683631420135, "val_acc": 52.0}
{"epoch": 62, "training_loss": 52.34544849395752, "training_acc": 91.0, "val_loss": 16.527831554412842, "val_acc": 60.0}
{"epoch": 63, "training_loss": 52.552844285964966, "training_acc": 90.0, "val_loss": 16.51459038257599, "val_acc": 52.0}
{"epoch": 64, "training_loss": 51.639195680618286, "training_acc": 89.0, "val_loss": 16.184459626674652, "val_acc": 56.0}
{"epoch": 65, "training_loss": 50.108580112457275, "training_acc": 94.0, "val_loss": 16.2821963429451, "val_acc": 56.0}
{"epoch": 66, "training_loss": 49.59417510032654, "training_acc": 95.0, "val_loss": 16.291412711143494, "val_acc": 60.0}
{"epoch": 67, "training_loss": 49.89989447593689, "training_acc": 89.0, "val_loss": 17.10818111896515, "val_acc": 72.0}
{"epoch": 68, "training_loss": 50.653424859046936, "training_acc": 89.0, "val_loss": 17.45356321334839, "val_acc": 52.0}
{"epoch": 69, "training_loss": 53.615683794021606, "training_acc": 80.0, "val_loss": 16.577933728694916, "val_acc": 60.0}
{"epoch": 70, "training_loss": 51.48336362838745, "training_acc": 88.0, "val_loss": 16.46014004945755, "val_acc": 60.0}
{"epoch": 71, "training_loss": 51.91949462890625, "training_acc": 88.0, "val_loss": 16.332723200321198, "val_acc": 60.0}
{"epoch": 72, "training_loss": 49.344557762145996, "training_acc": 91.0, "val_loss": 16.711705923080444, "val_acc": 52.0}
{"epoch": 73, "training_loss": 48.773335218429565, "training_acc": 91.0, "val_loss": 16.44476354122162, "val_acc": 72.0}
{"epoch": 74, "training_loss": 47.435577630996704, "training_acc": 95.0, "val_loss": 16.68560355901718, "val_acc": 52.0}
{"epoch": 75, "training_loss": 49.70845437049866, "training_acc": 89.0, "val_loss": 16.332751512527466, "val_acc": 72.0}
{"epoch": 76, "training_loss": 48.08077621459961, "training_acc": 93.0, "val_loss": 16.641822457313538, "val_acc": 52.0}
{"epoch": 77, "training_loss": 46.38330626487732, "training_acc": 93.0, "val_loss": 16.77367389202118, "val_acc": 68.0}
{"epoch": 78, "training_loss": 46.02361023426056, "training_acc": 95.0, "val_loss": 16.30556434392929, "val_acc": 56.0}
{"epoch": 79, "training_loss": 43.49746072292328, "training_acc": 94.0, "val_loss": 16.694511473178864, "val_acc": 68.0}
{"epoch": 80, "training_loss": 45.49590075016022, "training_acc": 95.0, "val_loss": 16.428184509277344, "val_acc": 52.0}
{"epoch": 81, "training_loss": 42.86717092990875, "training_acc": 95.0, "val_loss": 16.380496323108673, "val_acc": 68.0}
{"epoch": 82, "training_loss": 44.11992430686951, "training_acc": 98.0, "val_loss": 16.803061962127686, "val_acc": 52.0}
{"epoch": 83, "training_loss": 43.80747306346893, "training_acc": 94.0, "val_loss": 16.28149449825287, "val_acc": 64.0}
