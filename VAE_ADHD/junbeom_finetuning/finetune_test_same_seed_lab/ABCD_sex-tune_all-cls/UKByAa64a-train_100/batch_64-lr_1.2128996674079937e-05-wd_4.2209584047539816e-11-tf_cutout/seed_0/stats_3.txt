"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.48625230789185, "training_acc": 53.0, "val_loss": 17.496688663959503, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55535554885864, "training_acc": 53.0, "val_loss": 17.449800670146942, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.43759226799011, "training_acc": 53.0, "val_loss": 17.396079003810883, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.30648016929626, "training_acc": 53.0, "val_loss": 17.341139912605286, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.0929901599884, "training_acc": 53.0, "val_loss": 17.285537719726562, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.99137854576111, "training_acc": 53.0, "val_loss": 17.277172207832336, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.03114914894104, "training_acc": 53.0, "val_loss": 17.280682921409607, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09428787231445, "training_acc": 53.0, "val_loss": 17.30343997478485, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.88517045974731, "training_acc": 53.0, "val_loss": 17.34565496444702, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.93149304389954, "training_acc": 53.0, "val_loss": 17.361082136631012, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.63862919807434, "training_acc": 53.0, "val_loss": 17.346636950969696, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.65369915962219, "training_acc": 53.0, "val_loss": 17.31676459312439, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.47498679161072, "training_acc": 53.0, "val_loss": 17.328840494155884, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.4525454044342, "training_acc": 53.0, "val_loss": 17.35854744911194, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.49192357063293, "training_acc": 53.0, "val_loss": 17.37464666366577, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.36645531654358, "training_acc": 53.0, "val_loss": 17.35525131225586, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.53789520263672, "training_acc": 53.0, "val_loss": 17.343640327453613, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.09119939804077, "training_acc": 53.0, "val_loss": 17.31038987636566, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.10821747779846, "training_acc": 54.0, "val_loss": 17.32918471097946, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.88619470596313, "training_acc": 53.0, "val_loss": 17.352195084095, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.66748356819153, "training_acc": 53.0, "val_loss": 17.36447513103485, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.58878254890442, "training_acc": 53.0, "val_loss": 17.39872694015503, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.70132875442505, "training_acc": 53.0, "val_loss": 17.398644983768463, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.64831447601318, "training_acc": 53.0, "val_loss": 17.402498424053192, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.16229748725891, "training_acc": 57.0, "val_loss": 17.396265268325806, "val_acc": 52.0}
