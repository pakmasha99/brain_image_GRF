"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.51550626754761, "training_acc": 52.0, "val_loss": 17.404796183109283, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15527510643005, "training_acc": 53.0, "val_loss": 17.312930524349213, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.55966186523438, "training_acc": 45.0, "val_loss": 17.35498756170273, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21778678894043, "training_acc": 53.0, "val_loss": 17.415012419223785, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.32428050041199, "training_acc": 53.0, "val_loss": 17.310333251953125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25932383537292, "training_acc": 53.0, "val_loss": 17.31477379798889, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.57904267311096, "training_acc": 41.0, "val_loss": 17.309893667697906, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.92811179161072, "training_acc": 53.0, "val_loss": 17.544612288475037, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.00565767288208, "training_acc": 53.0, "val_loss": 17.562362551689148, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.9485673904419, "training_acc": 53.0, "val_loss": 17.451217770576477, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.57557034492493, "training_acc": 53.0, "val_loss": 17.334619164466858, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20731806755066, "training_acc": 53.0, "val_loss": 17.30869710445404, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20477628707886, "training_acc": 53.0, "val_loss": 17.348217964172363, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.63964533805847, "training_acc": 41.0, "val_loss": 17.32523739337921, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.3830418586731, "training_acc": 47.0, "val_loss": 17.312689125537872, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10443997383118, "training_acc": 53.0, "val_loss": 17.341426014900208, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.24873471260071, "training_acc": 53.0, "val_loss": 17.434123158454895, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.43754887580872, "training_acc": 53.0, "val_loss": 17.36867129802704, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.33261227607727, "training_acc": 53.0, "val_loss": 17.31099635362625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.4083321094513, "training_acc": 53.0, "val_loss": 17.335715889930725, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.313791513443, "training_acc": 53.0, "val_loss": 17.314504086971283, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08475804328918, "training_acc": 53.0, "val_loss": 17.329291999340057, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.50932049751282, "training_acc": 47.0, "val_loss": 17.349624633789062, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.43212747573853, "training_acc": 47.0, "val_loss": 17.30882227420807, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1031608581543, "training_acc": 53.0, "val_loss": 17.345768213272095, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18899297714233, "training_acc": 53.0, "val_loss": 17.38903373479843, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.3934211730957, "training_acc": 53.0, "val_loss": 17.366984486579895, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.26603317260742, "training_acc": 53.0, "val_loss": 17.343276739120483, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13512516021729, "training_acc": 53.0, "val_loss": 17.308874428272247, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.78452229499817, "training_acc": 41.0, "val_loss": 17.32129007577896, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19636130332947, "training_acc": 53.0, "val_loss": 17.316429316997528, "val_acc": 52.0}
