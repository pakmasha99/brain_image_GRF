"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.78883028030396, "training_acc": 53.0, "val_loss": 17.416566610336304, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.76410675048828, "training_acc": 55.0, "val_loss": 18.15628558397293, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.624107837677, "training_acc": 47.0, "val_loss": 17.3710897564888, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.9286777973175, "training_acc": 47.0, "val_loss": 17.40936189889908, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.1874508857727, "training_acc": 53.0, "val_loss": 17.461322247982025, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25471878051758, "training_acc": 53.0, "val_loss": 17.315486073493958, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.23018646240234, "training_acc": 53.0, "val_loss": 17.389947175979614, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.59585928916931, "training_acc": 47.0, "val_loss": 17.31116771697998, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.08807826042175, "training_acc": 53.0, "val_loss": 17.397917807102203, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.59624910354614, "training_acc": 53.0, "val_loss": 17.431987822055817, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4549949169159, "training_acc": 53.0, "val_loss": 17.440831661224365, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.6222755908966, "training_acc": 53.0, "val_loss": 17.33253300189972, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.00585579872131, "training_acc": 43.0, "val_loss": 17.35242009162903, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.41449427604675, "training_acc": 47.0, "val_loss": 17.315490543842316, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20419263839722, "training_acc": 53.0, "val_loss": 17.319245636463165, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.45877742767334, "training_acc": 53.0, "val_loss": 17.348480224609375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22478032112122, "training_acc": 53.0, "val_loss": 17.313136160373688, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17562961578369, "training_acc": 53.0, "val_loss": 17.308874428272247, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17711591720581, "training_acc": 53.0, "val_loss": 17.312009632587433, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21220135688782, "training_acc": 53.0, "val_loss": 17.313560843467712, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13286638259888, "training_acc": 53.0, "val_loss": 17.335520684719086, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25184679031372, "training_acc": 53.0, "val_loss": 17.35922247171402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2378191947937, "training_acc": 53.0, "val_loss": 17.31683313846588, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14503455162048, "training_acc": 53.0, "val_loss": 17.321594059467316, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.28417468070984, "training_acc": 53.0, "val_loss": 17.322608828544617, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.26283669471741, "training_acc": 53.0, "val_loss": 17.310060560703278, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15733456611633, "training_acc": 53.0, "val_loss": 17.37380176782608, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.49668598175049, "training_acc": 53.0, "val_loss": 17.39460378885269, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.75231766700745, "training_acc": 53.0, "val_loss": 17.431719601154327, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.47430920600891, "training_acc": 53.0, "val_loss": 17.5037682056427, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.68013143539429, "training_acc": 53.0, "val_loss": 17.380274832248688, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.67277145385742, "training_acc": 53.0, "val_loss": 17.314830422401428, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.21984124183655, "training_acc": 53.0, "val_loss": 17.326495051383972, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.4312949180603, "training_acc": 45.0, "val_loss": 17.310836911201477, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.05826687812805, "training_acc": 53.0, "val_loss": 17.36275851726532, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.24602603912354, "training_acc": 53.0, "val_loss": 17.46353507041931, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.62840819358826, "training_acc": 53.0, "val_loss": 17.40250736474991, "val_acc": 52.0}
