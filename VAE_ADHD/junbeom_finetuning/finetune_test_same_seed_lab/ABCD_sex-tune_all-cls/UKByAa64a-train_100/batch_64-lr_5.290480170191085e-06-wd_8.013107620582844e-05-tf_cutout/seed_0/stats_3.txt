"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3162202835083, "training_acc": 53.0, "val_loss": 17.36759841442108, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15510296821594, "training_acc": 53.0, "val_loss": 17.361590266227722, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14182639122009, "training_acc": 53.0, "val_loss": 17.33512282371521, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.02148151397705, "training_acc": 53.0, "val_loss": 17.31913536787033, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13492512702942, "training_acc": 53.0, "val_loss": 17.309342324733734, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.97573399543762, "training_acc": 53.0, "val_loss": 17.316657304763794, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.95076084136963, "training_acc": 53.0, "val_loss": 17.321231961250305, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.91808319091797, "training_acc": 53.0, "val_loss": 17.334628105163574, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.82557034492493, "training_acc": 53.0, "val_loss": 17.366115748882294, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.80357766151428, "training_acc": 53.0, "val_loss": 17.37293154001236, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.80819964408875, "training_acc": 53.0, "val_loss": 17.392249405384064, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.70543789863586, "training_acc": 53.0, "val_loss": 17.397063970565796, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.76074600219727, "training_acc": 53.0, "val_loss": 17.389079928398132, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.50622916221619, "training_acc": 53.0, "val_loss": 17.373156547546387, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.53612232208252, "training_acc": 53.0, "val_loss": 17.378878593444824, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.33695268630981, "training_acc": 53.0, "val_loss": 17.382091283798218, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.46350574493408, "training_acc": 53.0, "val_loss": 17.384321987628937, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.48640751838684, "training_acc": 53.0, "val_loss": 17.385824024677277, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.1723701953888, "training_acc": 53.0, "val_loss": 17.412228882312775, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.25439882278442, "training_acc": 53.0, "val_loss": 17.418572306632996, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.09565377235413, "training_acc": 53.0, "val_loss": 17.41199642419815, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.24162697792053, "training_acc": 53.0, "val_loss": 17.386730015277863, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.0594437122345, "training_acc": 53.0, "val_loss": 17.38206446170807, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.11331176757812, "training_acc": 53.0, "val_loss": 17.433349788188934, "val_acc": 52.0}
