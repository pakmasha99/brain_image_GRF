"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38902688026428, "training_acc": 52.0, "val_loss": 17.323173582553864, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.34686398506165, "training_acc": 52.0, "val_loss": 17.322055995464325, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24914240837097, "training_acc": 55.0, "val_loss": 17.32156276702881, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32362771034241, "training_acc": 54.0, "val_loss": 17.32107549905777, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33284568786621, "training_acc": 51.0, "val_loss": 17.319995164871216, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20890212059021, "training_acc": 57.0, "val_loss": 17.318905889987946, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.34717607498169, "training_acc": 54.0, "val_loss": 17.31829047203064, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29839944839478, "training_acc": 51.0, "val_loss": 17.316974699497223, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1219470500946, "training_acc": 57.0, "val_loss": 17.315581440925598, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.3134696483612, "training_acc": 49.0, "val_loss": 17.31460392475128, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23658752441406, "training_acc": 56.0, "val_loss": 17.31344610452652, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16780018806458, "training_acc": 63.0, "val_loss": 17.312641441822052, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25545406341553, "training_acc": 53.0, "val_loss": 17.31184720993042, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04712843894958, "training_acc": 53.0, "val_loss": 17.31169819831848, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.99049878120422, "training_acc": 54.0, "val_loss": 17.311839759349823, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16372275352478, "training_acc": 53.0, "val_loss": 17.312079668045044, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06769180297852, "training_acc": 52.0, "val_loss": 17.31242537498474, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18115305900574, "training_acc": 53.0, "val_loss": 17.312397062778473, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08618474006653, "training_acc": 52.0, "val_loss": 17.312337458133698, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.05031561851501, "training_acc": 55.0, "val_loss": 17.31257140636444, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13629245758057, "training_acc": 51.0, "val_loss": 17.312680184841156, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.41777968406677, "training_acc": 51.0, "val_loss": 17.312699556350708, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12747359275818, "training_acc": 52.0, "val_loss": 17.31325089931488, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.97957348823547, "training_acc": 53.0, "val_loss": 17.313742637634277, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.0677444934845, "training_acc": 52.0, "val_loss": 17.31400191783905, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.07519149780273, "training_acc": 54.0, "val_loss": 17.314405739307404, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19165802001953, "training_acc": 51.0, "val_loss": 17.315007746219635, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10061573982239, "training_acc": 53.0, "val_loss": 17.315810918807983, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.07507729530334, "training_acc": 53.0, "val_loss": 17.316576838493347, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.08678007125854, "training_acc": 52.0, "val_loss": 17.31727570295334, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.04245042800903, "training_acc": 53.0, "val_loss": 17.317867279052734, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1578757762909, "training_acc": 53.0, "val_loss": 17.31812208890915, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.96552181243896, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
