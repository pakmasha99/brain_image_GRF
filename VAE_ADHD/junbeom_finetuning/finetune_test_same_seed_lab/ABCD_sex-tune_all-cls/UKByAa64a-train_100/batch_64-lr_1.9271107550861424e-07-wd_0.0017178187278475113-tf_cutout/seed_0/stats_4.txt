"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39345908164978, "training_acc": 49.0, "val_loss": 17.320121824741364, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.43200016021729, "training_acc": 52.0, "val_loss": 17.319293320178986, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.31698226928711, "training_acc": 52.0, "val_loss": 17.318521440029144, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1779797077179, "training_acc": 51.0, "val_loss": 17.31777936220169, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.10184574127197, "training_acc": 56.0, "val_loss": 17.317302525043488, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11829996109009, "training_acc": 56.0, "val_loss": 17.316968739032745, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.39301323890686, "training_acc": 49.0, "val_loss": 17.316757142543793, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.35754752159119, "training_acc": 51.0, "val_loss": 17.316600680351257, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.26000118255615, "training_acc": 57.0, "val_loss": 17.316587269306183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1087875366211, "training_acc": 52.0, "val_loss": 17.31630265712738, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.08704686164856, "training_acc": 54.0, "val_loss": 17.316246032714844, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25195288658142, "training_acc": 54.0, "val_loss": 17.316104471683502, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10852694511414, "training_acc": 53.0, "val_loss": 17.316047847270966, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.03216171264648, "training_acc": 54.0, "val_loss": 17.31596738100052, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.10473084449768, "training_acc": 55.0, "val_loss": 17.315679788589478, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.25784230232239, "training_acc": 52.0, "val_loss": 17.315509915351868, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29153776168823, "training_acc": 52.0, "val_loss": 17.31523871421814, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21305799484253, "training_acc": 52.0, "val_loss": 17.315155267715454, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22831201553345, "training_acc": 53.0, "val_loss": 17.315015196800232, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.99909567832947, "training_acc": 53.0, "val_loss": 17.315025627613068, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22150468826294, "training_acc": 50.0, "val_loss": 17.314845323562622, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1349105834961, "training_acc": 53.0, "val_loss": 17.31472760438919, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.05829691886902, "training_acc": 53.0, "val_loss": 17.314717173576355, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27795934677124, "training_acc": 54.0, "val_loss": 17.314431071281433, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.04364776611328, "training_acc": 53.0, "val_loss": 17.31427311897278, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11675071716309, "training_acc": 54.0, "val_loss": 17.31398105621338, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.23580312728882, "training_acc": 50.0, "val_loss": 17.313610017299652, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11089992523193, "training_acc": 53.0, "val_loss": 17.313577234745026, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.31607484817505, "training_acc": 53.0, "val_loss": 17.31356531381607, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.98548603057861, "training_acc": 54.0, "val_loss": 17.3135444521904, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19115829467773, "training_acc": 53.0, "val_loss": 17.313608527183533, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.29587292671204, "training_acc": 52.0, "val_loss": 17.313861846923828, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.21385335922241, "training_acc": 52.0, "val_loss": 17.314279079437256, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15871024131775, "training_acc": 53.0, "val_loss": 17.314371466636658, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.08309888839722, "training_acc": 52.0, "val_loss": 17.314626276493073, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20968651771545, "training_acc": 53.0, "val_loss": 17.314468324184418, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16411709785461, "training_acc": 53.0, "val_loss": 17.314526438713074, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.10852146148682, "training_acc": 52.0, "val_loss": 17.314524948596954, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1120958328247, "training_acc": 53.0, "val_loss": 17.314191162586212, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.99254631996155, "training_acc": 53.0, "val_loss": 17.31419712305069, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.76771926879883, "training_acc": 53.0, "val_loss": 17.314085364341736, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.00392603874207, "training_acc": 53.0, "val_loss": 17.31395721435547, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1526575088501, "training_acc": 53.0, "val_loss": 17.313997447490692, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.0620436668396, "training_acc": 53.0, "val_loss": 17.314155399799347, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.24539875984192, "training_acc": 53.0, "val_loss": 17.31429696083069, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.99726414680481, "training_acc": 53.0, "val_loss": 17.314422130584717, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.02024507522583, "training_acc": 53.0, "val_loss": 17.31449067592621, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.97220706939697, "training_acc": 53.0, "val_loss": 17.314746975898743, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.05200576782227, "training_acc": 53.0, "val_loss": 17.314885556697845, "val_acc": 52.0}
