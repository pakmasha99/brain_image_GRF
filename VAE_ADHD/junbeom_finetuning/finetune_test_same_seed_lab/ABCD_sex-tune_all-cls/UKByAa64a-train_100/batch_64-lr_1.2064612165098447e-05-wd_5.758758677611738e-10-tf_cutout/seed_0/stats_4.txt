"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3276379108429, "training_acc": 53.0, "val_loss": 17.391499876976013, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.240886926651, "training_acc": 53.0, "val_loss": 17.35018938779831, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22779726982117, "training_acc": 53.0, "val_loss": 17.323027551174164, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21446633338928, "training_acc": 53.0, "val_loss": 17.28380173444748, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1353828907013, "training_acc": 53.0, "val_loss": 17.261430621147156, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13571190834045, "training_acc": 53.0, "val_loss": 17.27168560028076, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.04012393951416, "training_acc": 53.0, "val_loss": 17.274639010429382, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.90040636062622, "training_acc": 53.0, "val_loss": 17.271308600902557, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02503681182861, "training_acc": 53.0, "val_loss": 17.29792356491089, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.99030780792236, "training_acc": 53.0, "val_loss": 17.29395240545273, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.78868126869202, "training_acc": 53.0, "val_loss": 17.2742560505867, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.77632093429565, "training_acc": 53.0, "val_loss": 17.274776101112366, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.88222622871399, "training_acc": 53.0, "val_loss": 17.304448783397675, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.83510327339172, "training_acc": 53.0, "val_loss": 17.34038144350052, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.81739401817322, "training_acc": 53.0, "val_loss": 17.32902228832245, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.6899025440216, "training_acc": 53.0, "val_loss": 17.30239987373352, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.69210433959961, "training_acc": 53.0, "val_loss": 17.3031747341156, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.51883006095886, "training_acc": 53.0, "val_loss": 17.293725907802582, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.4346194267273, "training_acc": 53.0, "val_loss": 17.292441427707672, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.46382451057434, "training_acc": 53.0, "val_loss": 17.274685204029083, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.48014664649963, "training_acc": 53.0, "val_loss": 17.261607944965363, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.61636900901794, "training_acc": 53.0, "val_loss": 17.263971269130707, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.54937672615051, "training_acc": 53.0, "val_loss": 17.249426245689392, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.35892343521118, "training_acc": 53.0, "val_loss": 17.243202030658722, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.01937890052795, "training_acc": 53.0, "val_loss": 17.210441827774048, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.12096762657166, "training_acc": 53.0, "val_loss": 17.220701277256012, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.84800696372986, "training_acc": 53.0, "val_loss": 17.192023992538452, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.49594187736511, "training_acc": 67.0, "val_loss": 17.26003587245941, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.76165127754211, "training_acc": 77.0, "val_loss": 17.177189886569977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.23017573356628, "training_acc": 71.0, "val_loss": 17.18229651451111, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.5018162727356, "training_acc": 57.0, "val_loss": 17.177759110927582, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.47290420532227, "training_acc": 61.0, "val_loss": 17.160819470882416, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.98515701293945, "training_acc": 75.0, "val_loss": 17.13666468858719, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.28541231155396, "training_acc": 61.0, "val_loss": 17.160426080226898, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.49806046485901, "training_acc": 56.0, "val_loss": 17.100276052951813, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.1843569278717, "training_acc": 69.0, "val_loss": 17.17722862958908, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.39703440666199, "training_acc": 76.0, "val_loss": 17.113447189331055, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.82142329216003, "training_acc": 77.0, "val_loss": 17.154662311077118, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.92069053649902, "training_acc": 55.0, "val_loss": 17.071597278118134, "val_acc": 52.0}
{"epoch": 39, "training_loss": 64.90341186523438, "training_acc": 73.0, "val_loss": 17.343835532665253, "val_acc": 52.0}
{"epoch": 40, "training_loss": 65.8823311328888, "training_acc": 80.0, "val_loss": 17.081153392791748, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.82891821861267, "training_acc": 60.0, "val_loss": 17.304719984531403, "val_acc": 52.0}
{"epoch": 42, "training_loss": 65.50054335594177, "training_acc": 58.0, "val_loss": 17.06825941801071, "val_acc": 52.0}
{"epoch": 43, "training_loss": 64.5812029838562, "training_acc": 83.0, "val_loss": 17.167022824287415, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.13903307914734, "training_acc": 76.0, "val_loss": 17.096595466136932, "val_acc": 52.0}
{"epoch": 45, "training_loss": 65.05509281158447, "training_acc": 57.0, "val_loss": 17.14576631784439, "val_acc": 52.0}
{"epoch": 46, "training_loss": 64.88423871994019, "training_acc": 62.0, "val_loss": 17.06923395395279, "val_acc": 52.0}
{"epoch": 47, "training_loss": 63.39458632469177, "training_acc": 86.0, "val_loss": 16.88087433576584, "val_acc": 52.0}
{"epoch": 48, "training_loss": 62.547733783721924, "training_acc": 76.0, "val_loss": 16.850903630256653, "val_acc": 52.0}
{"epoch": 49, "training_loss": 63.229050397872925, "training_acc": 77.0, "val_loss": 16.831469535827637, "val_acc": 52.0}
{"epoch": 50, "training_loss": 62.12804317474365, "training_acc": 77.0, "val_loss": 16.76754355430603, "val_acc": 52.0}
{"epoch": 51, "training_loss": 61.41136193275452, "training_acc": 81.0, "val_loss": 16.74302965402603, "val_acc": 52.0}
{"epoch": 52, "training_loss": 59.19666075706482, "training_acc": 84.0, "val_loss": 16.745083034038544, "val_acc": 52.0}
{"epoch": 53, "training_loss": 60.586886405944824, "training_acc": 81.0, "val_loss": 16.727115213871002, "val_acc": 52.0}
{"epoch": 54, "training_loss": 60.96131134033203, "training_acc": 84.0, "val_loss": 16.845835745334625, "val_acc": 52.0}
{"epoch": 55, "training_loss": 60.45653486251831, "training_acc": 77.0, "val_loss": 16.797921061515808, "val_acc": 52.0}
{"epoch": 56, "training_loss": 59.83030319213867, "training_acc": 82.0, "val_loss": 16.63474291563034, "val_acc": 52.0}
{"epoch": 57, "training_loss": 57.3996205329895, "training_acc": 85.0, "val_loss": 16.683518886566162, "val_acc": 52.0}
{"epoch": 58, "training_loss": 58.267412424087524, "training_acc": 90.0, "val_loss": 16.503143310546875, "val_acc": 52.0}
{"epoch": 59, "training_loss": 58.352375984191895, "training_acc": 81.0, "val_loss": 16.48048311471939, "val_acc": 52.0}
{"epoch": 60, "training_loss": 57.85068678855896, "training_acc": 86.0, "val_loss": 16.56729429960251, "val_acc": 52.0}
{"epoch": 61, "training_loss": 56.002081871032715, "training_acc": 84.0, "val_loss": 16.47650897502899, "val_acc": 52.0}
{"epoch": 62, "training_loss": 54.75025248527527, "training_acc": 93.0, "val_loss": 16.4437934756279, "val_acc": 52.0}
{"epoch": 63, "training_loss": 55.485116720199585, "training_acc": 86.0, "val_loss": 16.423456370830536, "val_acc": 52.0}
{"epoch": 64, "training_loss": 54.69961595535278, "training_acc": 90.0, "val_loss": 16.282950341701508, "val_acc": 52.0}
{"epoch": 65, "training_loss": 54.67663526535034, "training_acc": 90.0, "val_loss": 16.24007821083069, "val_acc": 52.0}
{"epoch": 66, "training_loss": 54.306801080703735, "training_acc": 84.0, "val_loss": 16.347312927246094, "val_acc": 56.0}
{"epoch": 67, "training_loss": 54.0330970287323, "training_acc": 87.0, "val_loss": 16.281625628471375, "val_acc": 52.0}
{"epoch": 68, "training_loss": 52.86467385292053, "training_acc": 85.0, "val_loss": 16.413091123104095, "val_acc": 60.0}
{"epoch": 69, "training_loss": 52.39386022090912, "training_acc": 91.0, "val_loss": 16.240477561950684, "val_acc": 52.0}
{"epoch": 70, "training_loss": 50.457547664642334, "training_acc": 88.0, "val_loss": 16.701583564281464, "val_acc": 68.0}
{"epoch": 71, "training_loss": 51.69733810424805, "training_acc": 91.0, "val_loss": 16.228660941123962, "val_acc": 56.0}
{"epoch": 72, "training_loss": 49.491634488105774, "training_acc": 94.0, "val_loss": 16.1136656999588, "val_acc": 56.0}
{"epoch": 73, "training_loss": 48.93352520465851, "training_acc": 90.0, "val_loss": 16.159121692180634, "val_acc": 60.0}
{"epoch": 74, "training_loss": 47.06765520572662, "training_acc": 95.0, "val_loss": 16.199636459350586, "val_acc": 56.0}
{"epoch": 75, "training_loss": 48.48084855079651, "training_acc": 95.0, "val_loss": 16.199880838394165, "val_acc": 60.0}
{"epoch": 76, "training_loss": 47.82469582557678, "training_acc": 92.0, "val_loss": 16.70079380273819, "val_acc": 72.0}
{"epoch": 77, "training_loss": 47.8929363489151, "training_acc": 91.0, "val_loss": 16.50390326976776, "val_acc": 52.0}
{"epoch": 78, "training_loss": 46.65283644199371, "training_acc": 92.0, "val_loss": 16.68182462453842, "val_acc": 72.0}
{"epoch": 79, "training_loss": 48.553271889686584, "training_acc": 91.0, "val_loss": 16.021442413330078, "val_acc": 64.0}
{"epoch": 80, "training_loss": 46.4643360376358, "training_acc": 93.0, "val_loss": 16.091111302375793, "val_acc": 64.0}
{"epoch": 81, "training_loss": 43.10454344749451, "training_acc": 98.0, "val_loss": 15.933595597743988, "val_acc": 60.0}
{"epoch": 82, "training_loss": 45.58384704589844, "training_acc": 94.0, "val_loss": 15.96497893333435, "val_acc": 64.0}
{"epoch": 83, "training_loss": 44.76612687110901, "training_acc": 94.0, "val_loss": 16.538414359092712, "val_acc": 68.0}
{"epoch": 84, "training_loss": 44.3134309053421, "training_acc": 92.0, "val_loss": 17.062827944755554, "val_acc": 56.0}
{"epoch": 85, "training_loss": 46.089412689208984, "training_acc": 89.0, "val_loss": 18.162940442562103, "val_acc": 56.0}
{"epoch": 86, "training_loss": 53.44289541244507, "training_acc": 78.0, "val_loss": 16.99776202440262, "val_acc": 56.0}
{"epoch": 87, "training_loss": 44.8187392950058, "training_acc": 90.0, "val_loss": 16.319923102855682, "val_acc": 68.0}
{"epoch": 88, "training_loss": 41.524972558021545, "training_acc": 98.0, "val_loss": 16.048093140125275, "val_acc": 68.0}
{"epoch": 89, "training_loss": 42.89237940311432, "training_acc": 94.0, "val_loss": 16.158100962638855, "val_acc": 60.0}
{"epoch": 90, "training_loss": 40.13595354557037, "training_acc": 97.0, "val_loss": 17.106834053993225, "val_acc": 60.0}
{"epoch": 91, "training_loss": 44.34890031814575, "training_acc": 95.0, "val_loss": 16.913795471191406, "val_acc": 56.0}
{"epoch": 92, "training_loss": 45.699851632118225, "training_acc": 84.0, "val_loss": 16.86108112335205, "val_acc": 68.0}
{"epoch": 93, "training_loss": 42.76142871379852, "training_acc": 97.0, "val_loss": 16.277866065502167, "val_acc": 60.0}
{"epoch": 94, "training_loss": 44.0017454624176, "training_acc": 87.0, "val_loss": 16.49986207485199, "val_acc": 72.0}
{"epoch": 95, "training_loss": 41.6568968296051, "training_acc": 94.0, "val_loss": 16.03269875049591, "val_acc": 68.0}
{"epoch": 96, "training_loss": 38.64229476451874, "training_acc": 98.0, "val_loss": 16.15835279226303, "val_acc": 60.0}
{"epoch": 97, "training_loss": 40.630348801612854, "training_acc": 99.0, "val_loss": 16.821227967739105, "val_acc": 68.0}
{"epoch": 98, "training_loss": 36.927166223526, "training_acc": 100.0, "val_loss": 16.380496323108673, "val_acc": 60.0}
{"epoch": 99, "training_loss": 38.46221709251404, "training_acc": 98.0, "val_loss": 16.161546111106873, "val_acc": 68.0}
{"epoch": 100, "training_loss": 38.68799555301666, "training_acc": 98.0, "val_loss": 16.107340157032013, "val_acc": 64.0}
