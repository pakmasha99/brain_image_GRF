"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.92104434967041, "training_acc": 47.0, "val_loss": 17.418037354946136, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.73655104637146, "training_acc": 47.0, "val_loss": 17.413944005966187, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.57191348075867, "training_acc": 47.0, "val_loss": 17.43217408657074, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.36360502243042, "training_acc": 47.0, "val_loss": 17.368698120117188, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.60209393501282, "training_acc": 48.0, "val_loss": 17.33812987804413, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23836207389832, "training_acc": 54.0, "val_loss": 17.336709797382355, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.03001832962036, "training_acc": 59.0, "val_loss": 17.30203926563263, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.23072147369385, "training_acc": 49.0, "val_loss": 17.317911982536316, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.166424036026, "training_acc": 52.0, "val_loss": 17.307153344154358, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.80195641517639, "training_acc": 58.0, "val_loss": 17.293477058410645, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0957944393158, "training_acc": 49.0, "val_loss": 17.312949895858765, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20343041419983, "training_acc": 55.0, "val_loss": 17.299358546733856, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23295783996582, "training_acc": 46.0, "val_loss": 17.294080555438995, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.06321048736572, "training_acc": 55.0, "val_loss": 17.268136143684387, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.88969230651855, "training_acc": 52.0, "val_loss": 17.27089285850525, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.94084191322327, "training_acc": 52.0, "val_loss": 17.30765551328659, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.89700436592102, "training_acc": 53.0, "val_loss": 17.319218814373016, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.88502502441406, "training_acc": 53.0, "val_loss": 17.351490259170532, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.77986073493958, "training_acc": 55.0, "val_loss": 17.33318418264389, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.76098942756653, "training_acc": 53.0, "val_loss": 17.34640598297119, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.50657486915588, "training_acc": 53.0, "val_loss": 17.310279607772827, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.77885794639587, "training_acc": 53.0, "val_loss": 17.29225516319275, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.69355583190918, "training_acc": 53.0, "val_loss": 17.293231189250946, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.5148937702179, "training_acc": 53.0, "val_loss": 17.29830503463745, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.55113935470581, "training_acc": 53.0, "val_loss": 17.329946160316467, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.21286797523499, "training_acc": 53.0, "val_loss": 17.332547903060913, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.35497283935547, "training_acc": 53.0, "val_loss": 17.305894196033478, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.376309633255, "training_acc": 53.0, "val_loss": 17.318427562713623, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.0568778514862, "training_acc": 53.0, "val_loss": 17.34347492456436, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.92678904533386, "training_acc": 54.0, "val_loss": 17.33604520559311, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.4081883430481, "training_acc": 53.0, "val_loss": 17.31201857328415, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.40248107910156, "training_acc": 53.0, "val_loss": 17.27733165025711, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.01842212677002, "training_acc": 56.0, "val_loss": 17.30111539363861, "val_acc": 52.0}
