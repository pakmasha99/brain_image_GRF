"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.29946327209473, "training_acc": 48.0, "val_loss": 17.325973510742188, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13344311714172, "training_acc": 53.0, "val_loss": 17.311382293701172, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12311935424805, "training_acc": 53.0, "val_loss": 17.309489846229553, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.30882716178894, "training_acc": 53.0, "val_loss": 17.38121807575226, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.65066862106323, "training_acc": 53.0, "val_loss": 17.436330020427704, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.46870493888855, "training_acc": 53.0, "val_loss": 17.375949025154114, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21446990966797, "training_acc": 53.0, "val_loss": 17.30770766735077, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14507675170898, "training_acc": 53.0, "val_loss": 17.32645034790039, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.31092381477356, "training_acc": 53.0, "val_loss": 17.311936616897583, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16422462463379, "training_acc": 53.0, "val_loss": 17.324553430080414, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41458439826965, "training_acc": 53.0, "val_loss": 17.363284528255463, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21076345443726, "training_acc": 53.0, "val_loss": 17.31356978416443, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.67227482795715, "training_acc": 53.0, "val_loss": 17.308616638183594, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.43362259864807, "training_acc": 53.0, "val_loss": 17.332209646701813, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15562272071838, "training_acc": 53.0, "val_loss": 17.31930822134018, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.36650085449219, "training_acc": 53.0, "val_loss": 17.312021553516388, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13708329200745, "training_acc": 53.0, "val_loss": 17.32984483242035, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15947008132935, "training_acc": 53.0, "val_loss": 17.334702610969543, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19605731964111, "training_acc": 53.0, "val_loss": 17.32025295495987, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18546724319458, "training_acc": 53.0, "val_loss": 17.308548092842102, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.28536295890808, "training_acc": 53.0, "val_loss": 17.308631539344788, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20357060432434, "training_acc": 53.0, "val_loss": 17.319756746292114, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17614722251892, "training_acc": 53.0, "val_loss": 17.330428957939148, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15597081184387, "training_acc": 53.0, "val_loss": 17.32019931077957, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13622236251831, "training_acc": 53.0, "val_loss": 17.31184870004654, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15622782707214, "training_acc": 53.0, "val_loss": 17.309264838695526, "val_acc": 52.0}
