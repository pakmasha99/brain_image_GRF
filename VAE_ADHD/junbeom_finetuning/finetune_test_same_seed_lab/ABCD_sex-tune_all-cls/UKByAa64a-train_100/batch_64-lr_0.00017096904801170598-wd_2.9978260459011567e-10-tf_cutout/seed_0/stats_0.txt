"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34414052963257, "training_acc": 53.0, "val_loss": 17.286424338817596, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.32711338996887, "training_acc": 52.0, "val_loss": 17.274110019207, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.51540851593018, "training_acc": 52.0, "val_loss": 17.29855239391327, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.36596941947937, "training_acc": 52.0, "val_loss": 17.338664829730988, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.30178570747375, "training_acc": 50.0, "val_loss": 17.23150908946991, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.6568214893341, "training_acc": 52.0, "val_loss": 17.21961498260498, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27141690254211, "training_acc": 52.0, "val_loss": 17.304980754852295, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.30974841117859, "training_acc": 52.0, "val_loss": 17.232787609100342, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.71550488471985, "training_acc": 52.0, "val_loss": 17.203956842422485, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.19684267044067, "training_acc": 52.0, "val_loss": 17.328767478466034, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.32252717018127, "training_acc": 50.0, "val_loss": 17.296186089515686, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2923309803009, "training_acc": 52.0, "val_loss": 17.22348779439926, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.31330466270447, "training_acc": 52.0, "val_loss": 17.21818745136261, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.31724548339844, "training_acc": 52.0, "val_loss": 17.27210134267807, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.26516699790955, "training_acc": 52.0, "val_loss": 17.225758731365204, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23569917678833, "training_acc": 52.0, "val_loss": 17.179115116596222, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.34180116653442, "training_acc": 52.0, "val_loss": 17.160314321517944, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.33735656738281, "training_acc": 52.0, "val_loss": 17.200662195682526, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25357842445374, "training_acc": 52.0, "val_loss": 17.262202501296997, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.2456521987915, "training_acc": 52.0, "val_loss": 17.282192409038544, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.29293179512024, "training_acc": 52.0, "val_loss": 17.264147102832794, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24391293525696, "training_acc": 52.0, "val_loss": 17.201828956604004, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.49449133872986, "training_acc": 52.0, "val_loss": 17.165552079677582, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.30030345916748, "training_acc": 52.0, "val_loss": 17.21125692129135, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.18260860443115, "training_acc": 52.0, "val_loss": 17.314164340496063, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.39466595649719, "training_acc": 48.0, "val_loss": 17.37249195575714, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.78395509719849, "training_acc": 38.0, "val_loss": 17.289093136787415, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.26509523391724, "training_acc": 52.0, "val_loss": 17.314285039901733, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.35270237922668, "training_acc": 46.0, "val_loss": 17.296622693538666, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.23584175109863, "training_acc": 52.0, "val_loss": 17.219674587249756, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.60598158836365, "training_acc": 52.0, "val_loss": 17.177289724349976, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.49324774742126, "training_acc": 52.0, "val_loss": 17.209216952323914, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24892354011536, "training_acc": 52.0, "val_loss": 17.204497754573822, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.26035141944885, "training_acc": 52.0, "val_loss": 17.215825617313385, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25966000556946, "training_acc": 52.0, "val_loss": 17.218120396137238, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23945307731628, "training_acc": 52.0, "val_loss": 17.245858907699585, "val_acc": 56.0}
