"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.81128549575806, "training_acc": 47.0, "val_loss": 17.441561818122864, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.72520804405212, "training_acc": 47.0, "val_loss": 17.380504310131073, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.68920421600342, "training_acc": 47.0, "val_loss": 17.373797297477722, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.61150455474854, "training_acc": 47.0, "val_loss": 17.361320555210114, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.54720997810364, "training_acc": 47.0, "val_loss": 17.326514422893524, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.26811671257019, "training_acc": 47.0, "val_loss": 17.29663759469986, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09964323043823, "training_acc": 53.0, "val_loss": 17.29874014854431, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09261417388916, "training_acc": 53.0, "val_loss": 17.33175218105316, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1559431552887, "training_acc": 53.0, "val_loss": 17.362283170223236, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.04414081573486, "training_acc": 53.0, "val_loss": 17.36244112253189, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.02149534225464, "training_acc": 53.0, "val_loss": 17.342528700828552, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20764350891113, "training_acc": 53.0, "val_loss": 17.32688546180725, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13098669052124, "training_acc": 53.0, "val_loss": 17.318876087665558, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04063129425049, "training_acc": 53.0, "val_loss": 17.31850355863571, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.00243735313416, "training_acc": 53.0, "val_loss": 17.31879711151123, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.09542846679688, "training_acc": 53.0, "val_loss": 17.314891517162323, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.96401953697205, "training_acc": 53.0, "val_loss": 17.308346927165985, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.87051796913147, "training_acc": 53.0, "val_loss": 17.30993241071701, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.97546720504761, "training_acc": 53.0, "val_loss": 17.317649722099304, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.84963774681091, "training_acc": 53.0, "val_loss": 17.331454157829285, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.93521785736084, "training_acc": 53.0, "val_loss": 17.319947481155396, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.05354642868042, "training_acc": 53.0, "val_loss": 17.30864644050598, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.78720784187317, "training_acc": 53.0, "val_loss": 17.30511784553528, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.8505756855011, "training_acc": 51.0, "val_loss": 17.305168509483337, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.753408908844, "training_acc": 54.0, "val_loss": 17.309416830539703, "val_acc": 52.0}
