"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31223034858704, "training_acc": 53.0, "val_loss": 17.330020666122437, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27820706367493, "training_acc": 53.0, "val_loss": 17.323867976665497, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.10049319267273, "training_acc": 53.0, "val_loss": 17.325854301452637, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16979169845581, "training_acc": 53.0, "val_loss": 17.324379086494446, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14736413955688, "training_acc": 53.0, "val_loss": 17.31872260570526, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10474491119385, "training_acc": 53.0, "val_loss": 17.306743562221527, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.0206069946289, "training_acc": 53.0, "val_loss": 17.294736206531525, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.95678901672363, "training_acc": 53.0, "val_loss": 17.298686504364014, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.01678800582886, "training_acc": 53.0, "val_loss": 17.30649173259735, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.0162308216095, "training_acc": 53.0, "val_loss": 17.30506867170334, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.97268033027649, "training_acc": 53.0, "val_loss": 17.283031344413757, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.78197193145752, "training_acc": 53.0, "val_loss": 17.277808487415314, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.9620509147644, "training_acc": 53.0, "val_loss": 17.27920174598694, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.91513085365295, "training_acc": 53.0, "val_loss": 17.269974946975708, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.0377345085144, "training_acc": 53.0, "val_loss": 17.26425141096115, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.71136903762817, "training_acc": 53.0, "val_loss": 17.288291454315186, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.62672472000122, "training_acc": 53.0, "val_loss": 17.293724417686462, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.97491765022278, "training_acc": 53.0, "val_loss": 17.261740565299988, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.52426934242249, "training_acc": 53.0, "val_loss": 17.283502221107483, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.56877446174622, "training_acc": 53.0, "val_loss": 17.25795716047287, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.30896377563477, "training_acc": 53.0, "val_loss": 17.222900688648224, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.44059824943542, "training_acc": 53.0, "val_loss": 17.2056645154953, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.28822731971741, "training_acc": 53.0, "val_loss": 17.28961169719696, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.10315918922424, "training_acc": 53.0, "val_loss": 17.185309529304504, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.11585354804993, "training_acc": 53.0, "val_loss": 17.16204434633255, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.88249468803406, "training_acc": 64.0, "val_loss": 17.11994856595993, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.64765214920044, "training_acc": 58.0, "val_loss": 17.44094491004944, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.12374758720398, "training_acc": 53.0, "val_loss": 17.121055722236633, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.62933731079102, "training_acc": 64.0, "val_loss": 17.095111310482025, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.77309918403625, "training_acc": 66.0, "val_loss": 17.52166748046875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.01494979858398, "training_acc": 53.0, "val_loss": 17.056269943714142, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.16886806488037, "training_acc": 57.0, "val_loss": 17.316070199012756, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.51057529449463, "training_acc": 56.0, "val_loss": 17.11159497499466, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.50616407394409, "training_acc": 61.0, "val_loss": 17.601145803928375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.89627432823181, "training_acc": 53.0, "val_loss": 17.352908849716187, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.97804284095764, "training_acc": 52.0, "val_loss": 17.08086133003235, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.31985521316528, "training_acc": 64.0, "val_loss": 17.05097407102585, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.957195520401, "training_acc": 64.0, "val_loss": 17.23998636007309, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.57892346382141, "training_acc": 62.0, "val_loss": 16.956104338169098, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.4110107421875, "training_acc": 67.0, "val_loss": 16.896918416023254, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.28542280197144, "training_acc": 67.0, "val_loss": 16.76417887210846, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.56249713897705, "training_acc": 74.0, "val_loss": 17.811311781406403, "val_acc": 52.0}
{"epoch": 42, "training_loss": 67.14113473892212, "training_acc": 53.0, "val_loss": 17.679664492607117, "val_acc": 52.0}
{"epoch": 43, "training_loss": 70.39682698249817, "training_acc": 47.0, "val_loss": 17.43215173482895, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.64580249786377, "training_acc": 47.0, "val_loss": 17.336532473564148, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.30688214302063, "training_acc": 54.0, "val_loss": 17.318418622016907, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.12233853340149, "training_acc": 53.0, "val_loss": 17.31523424386978, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.07924771308899, "training_acc": 53.0, "val_loss": 17.31969863176346, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.12323498725891, "training_acc": 53.0, "val_loss": 17.340008914470673, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13721036911011, "training_acc": 53.0, "val_loss": 17.343981564044952, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.08180928230286, "training_acc": 53.0, "val_loss": 17.33330637216568, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.03908634185791, "training_acc": 53.0, "val_loss": 17.319823801517487, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.03402423858643, "training_acc": 53.0, "val_loss": 17.307724058628082, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.10081267356873, "training_acc": 53.0, "val_loss": 17.29944795370102, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.06840491294861, "training_acc": 53.0, "val_loss": 17.29951798915863, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.10157632827759, "training_acc": 53.0, "val_loss": 17.300568521022797, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.04241991043091, "training_acc": 53.0, "val_loss": 17.300520837306976, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.08477449417114, "training_acc": 53.0, "val_loss": 17.299923300743103, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.01249670982361, "training_acc": 53.0, "val_loss": 17.29961782693863, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.03032231330872, "training_acc": 53.0, "val_loss": 17.300373315811157, "val_acc": 52.0}
