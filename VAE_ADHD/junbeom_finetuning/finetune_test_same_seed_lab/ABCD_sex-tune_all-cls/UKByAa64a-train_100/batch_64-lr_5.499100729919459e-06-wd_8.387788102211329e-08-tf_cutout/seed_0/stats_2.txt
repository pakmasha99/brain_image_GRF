"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.9661750793457, "training_acc": 47.0, "val_loss": 17.81846433877945, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.72937393188477, "training_acc": 47.0, "val_loss": 17.72124618291855, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.51146721839905, "training_acc": 47.0, "val_loss": 17.689962685108185, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.0806131362915, "training_acc": 47.0, "val_loss": 17.613986134529114, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.02456378936768, "training_acc": 47.0, "val_loss": 17.557327449321747, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.44686603546143, "training_acc": 47.0, "val_loss": 17.484892904758453, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.29799222946167, "training_acc": 47.0, "val_loss": 17.44602918624878, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.86732244491577, "training_acc": 47.0, "val_loss": 17.39562600851059, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.19737243652344, "training_acc": 47.0, "val_loss": 17.350299656391144, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.74072360992432, "training_acc": 47.0, "val_loss": 17.334701120853424, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.60335922241211, "training_acc": 47.0, "val_loss": 17.308887839317322, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.37316632270813, "training_acc": 47.0, "val_loss": 17.308418452739716, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.5448386669159, "training_acc": 48.0, "val_loss": 17.295190691947937, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.06548619270325, "training_acc": 54.0, "val_loss": 17.24347472190857, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.0806987285614, "training_acc": 53.0, "val_loss": 17.22913682460785, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.69505429267883, "training_acc": 60.0, "val_loss": 17.207564413547516, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.11236476898193, "training_acc": 57.0, "val_loss": 17.212451994419098, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.31890892982483, "training_acc": 58.0, "val_loss": 17.22179800271988, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.53836011886597, "training_acc": 63.0, "val_loss": 17.190109193325043, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.23520135879517, "training_acc": 63.0, "val_loss": 17.17474013566971, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.91762590408325, "training_acc": 55.0, "val_loss": 17.174334824085236, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.58537673950195, "training_acc": 57.0, "val_loss": 17.155982553958893, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.00725173950195, "training_acc": 61.0, "val_loss": 17.179352045059204, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.00105381011963, "training_acc": 54.0, "val_loss": 17.214886844158173, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.89210629463196, "training_acc": 55.0, "val_loss": 17.25068837404251, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.65744137763977, "training_acc": 62.0, "val_loss": 17.23138839006424, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.65666699409485, "training_acc": 57.0, "val_loss": 17.199911177158356, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.33063244819641, "training_acc": 58.0, "val_loss": 17.188888788223267, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.30897641181946, "training_acc": 60.0, "val_loss": 17.18113422393799, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.91283297538757, "training_acc": 61.0, "val_loss": 17.190875113010406, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.71102666854858, "training_acc": 66.0, "val_loss": 17.18500703573227, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.31742453575134, "training_acc": 71.0, "val_loss": 17.19074845314026, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.61403322219849, "training_acc": 62.0, "val_loss": 17.170146107673645, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.49328327178955, "training_acc": 60.0, "val_loss": 17.167989909648895, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.18216609954834, "training_acc": 61.0, "val_loss": 17.187099158763885, "val_acc": 52.0}
{"epoch": 35, "training_loss": 67.64265751838684, "training_acc": 73.0, "val_loss": 17.187759280204773, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.96554565429688, "training_acc": 66.0, "val_loss": 17.21889078617096, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.52589416503906, "training_acc": 58.0, "val_loss": 17.213745415210724, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.19496464729309, "training_acc": 66.0, "val_loss": 17.24665015935898, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.88338351249695, "training_acc": 72.0, "val_loss": 17.253772914409637, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.76913571357727, "training_acc": 71.0, "val_loss": 17.219172418117523, "val_acc": 52.0}
