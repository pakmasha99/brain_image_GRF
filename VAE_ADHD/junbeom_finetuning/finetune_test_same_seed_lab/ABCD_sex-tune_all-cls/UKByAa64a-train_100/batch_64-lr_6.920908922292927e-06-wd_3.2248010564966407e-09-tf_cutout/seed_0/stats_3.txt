"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.14102482795715, "training_acc": 53.0, "val_loss": 17.345477640628815, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.23297953605652, "training_acc": 53.0, "val_loss": 17.36910790205002, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.17876124382019, "training_acc": 53.0, "val_loss": 17.355388402938843, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.98298788070679, "training_acc": 53.0, "val_loss": 17.351338267326355, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.10589909553528, "training_acc": 53.0, "val_loss": 17.330600321292877, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.9334409236908, "training_acc": 53.0, "val_loss": 17.335715889930725, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.84814834594727, "training_acc": 53.0, "val_loss": 17.376941442489624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.78071212768555, "training_acc": 53.0, "val_loss": 17.417658865451813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.91078305244446, "training_acc": 53.0, "val_loss": 17.36258715391159, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.81869268417358, "training_acc": 53.0, "val_loss": 17.355790734291077, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.66593408584595, "training_acc": 53.0, "val_loss": 17.397812008857727, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.62530899047852, "training_acc": 53.0, "val_loss": 17.440490424633026, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.5784854888916, "training_acc": 53.0, "val_loss": 17.466558516025543, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.61178588867188, "training_acc": 53.0, "val_loss": 17.480461299419403, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.66723847389221, "training_acc": 53.0, "val_loss": 17.46085435152054, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.41968488693237, "training_acc": 53.0, "val_loss": 17.4360990524292, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.16092228889465, "training_acc": 53.0, "val_loss": 17.495040595531464, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.03747606277466, "training_acc": 53.0, "val_loss": 17.488472163677216, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.10082340240479, "training_acc": 53.0, "val_loss": 17.442747950553894, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.0893611907959, "training_acc": 54.0, "val_loss": 17.442454397678375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.49393010139465, "training_acc": 58.0, "val_loss": 17.560553550720215, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.75206398963928, "training_acc": 55.0, "val_loss": 17.564399540424347, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.81649398803711, "training_acc": 59.0, "val_loss": 17.466580867767334, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.39980030059814, "training_acc": 67.0, "val_loss": 17.579399049282074, "val_acc": 52.0}
