"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.28772187232971, "training_acc": 53.0, "val_loss": 17.297573387622833, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.28558850288391, "training_acc": 52.0, "val_loss": 17.250390350818634, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24647641181946, "training_acc": 52.0, "val_loss": 17.258159816265106, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.21338939666748, "training_acc": 52.0, "val_loss": 17.271672189235687, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.17002582550049, "training_acc": 54.0, "val_loss": 17.25299209356308, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.3739972114563, "training_acc": 52.0, "val_loss": 17.244265973567963, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.28218078613281, "training_acc": 52.0, "val_loss": 17.291855812072754, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.18165802955627, "training_acc": 52.0, "val_loss": 17.235171794891357, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.485036611557, "training_acc": 52.0, "val_loss": 17.206445336341858, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.12136149406433, "training_acc": 52.0, "val_loss": 17.281119525432587, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.18683910369873, "training_acc": 54.0, "val_loss": 17.321261763572693, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.22652649879456, "training_acc": 50.0, "val_loss": 17.268428206443787, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.14949536323547, "training_acc": 52.0, "val_loss": 17.25464165210724, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.10214972496033, "training_acc": 52.0, "val_loss": 17.281582951545715, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.0921528339386, "training_acc": 52.0, "val_loss": 17.249475419521332, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.99819207191467, "training_acc": 52.0, "val_loss": 17.216159403324127, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.91423892974854, "training_acc": 52.0, "val_loss": 17.194919288158417, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.29470872879028, "training_acc": 52.0, "val_loss": 17.2499418258667, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.05155205726624, "training_acc": 53.0, "val_loss": 17.31794774532318, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.0934407711029, "training_acc": 49.0, "val_loss": 17.327991127967834, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.10935163497925, "training_acc": 54.0, "val_loss": 17.33057051897049, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.90715479850769, "training_acc": 55.0, "val_loss": 17.260895669460297, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.4368212223053, "training_acc": 52.0, "val_loss": 17.21600741147995, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.08157658576965, "training_acc": 52.0, "val_loss": 17.289897799491882, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.99845433235168, "training_acc": 53.0, "val_loss": 17.421524226665497, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.20621657371521, "training_acc": 51.0, "val_loss": 17.44249314069748, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.63720273971558, "training_acc": 45.0, "val_loss": 17.311376333236694, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.0234911441803, "training_acc": 52.0, "val_loss": 17.37200915813446, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.90773248672485, "training_acc": 61.0, "val_loss": 17.39995926618576, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.82763981819153, "training_acc": 61.0, "val_loss": 17.287439107894897, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.35303926467896, "training_acc": 52.0, "val_loss": 17.233112454414368, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.32805752754211, "training_acc": 52.0, "val_loss": 17.30359196662903, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.81791353225708, "training_acc": 53.0, "val_loss": 17.329616844654083, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.70179343223572, "training_acc": 57.0, "val_loss": 17.374928295612335, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.74377799034119, "training_acc": 51.0, "val_loss": 17.37644672393799, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.70450377464294, "training_acc": 57.0, "val_loss": 17.460329830646515, "val_acc": 56.0}
