"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.59052634239197, "training_acc": 47.0, "val_loss": 17.675821483135223, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.01354551315308, "training_acc": 47.0, "val_loss": 17.471621930599213, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.97549414634705, "training_acc": 47.0, "val_loss": 17.362380027770996, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.34286308288574, "training_acc": 47.0, "val_loss": 17.32991635799408, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2995536327362, "training_acc": 50.0, "val_loss": 17.316138744354248, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1834945678711, "training_acc": 52.0, "val_loss": 17.317958176136017, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28403806686401, "training_acc": 53.0, "val_loss": 17.296871542930603, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.96412754058838, "training_acc": 53.0, "val_loss": 17.306804656982422, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.34513878822327, "training_acc": 53.0, "val_loss": 17.324762046337128, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.04813766479492, "training_acc": 53.0, "val_loss": 17.307639122009277, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0885419845581, "training_acc": 53.0, "val_loss": 17.301593720912933, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.06969451904297, "training_acc": 53.0, "val_loss": 17.30199158191681, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18337321281433, "training_acc": 53.0, "val_loss": 17.302337288856506, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.0365879535675, "training_acc": 53.0, "val_loss": 17.32822060585022, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23194980621338, "training_acc": 53.0, "val_loss": 17.33834594488144, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31131410598755, "training_acc": 53.0, "val_loss": 17.310824990272522, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29207968711853, "training_acc": 53.0, "val_loss": 17.32059419155121, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1513442993164, "training_acc": 53.0, "val_loss": 17.30084717273712, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10482597351074, "training_acc": 53.0, "val_loss": 17.298761010169983, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.05575108528137, "training_acc": 53.0, "val_loss": 17.298774421215057, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30440831184387, "training_acc": 53.0, "val_loss": 17.301957309246063, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.05060601234436, "training_acc": 53.0, "val_loss": 17.30051338672638, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.41985607147217, "training_acc": 53.0, "val_loss": 17.336924374103546, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18816351890564, "training_acc": 53.0, "val_loss": 17.322151362895966, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01445603370667, "training_acc": 53.0, "val_loss": 17.323963344097137, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.04129600524902, "training_acc": 53.0, "val_loss": 17.31603443622589, "val_acc": 52.0}
