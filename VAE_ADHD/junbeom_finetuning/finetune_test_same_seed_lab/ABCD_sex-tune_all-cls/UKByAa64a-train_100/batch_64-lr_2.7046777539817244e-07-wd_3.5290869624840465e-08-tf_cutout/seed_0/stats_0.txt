"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39370346069336, "training_acc": 52.0, "val_loss": 17.273876070976257, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2097008228302, "training_acc": 52.0, "val_loss": 17.275777459144592, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.19752311706543, "training_acc": 52.0, "val_loss": 17.27648824453354, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.19201397895813, "training_acc": 52.0, "val_loss": 17.27563887834549, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.34743118286133, "training_acc": 52.0, "val_loss": 17.27357506752014, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2517683506012, "training_acc": 52.0, "val_loss": 17.272591590881348, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.15959811210632, "training_acc": 52.0, "val_loss": 17.272907495498657, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.32985758781433, "training_acc": 52.0, "val_loss": 17.272062599658966, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.23000073432922, "training_acc": 52.0, "val_loss": 17.270369827747345, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25869464874268, "training_acc": 52.0, "val_loss": 17.269618809223175, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.1520357131958, "training_acc": 52.0, "val_loss": 17.267736792564392, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.19533133506775, "training_acc": 52.0, "val_loss": 17.266517877578735, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.05863952636719, "training_acc": 52.0, "val_loss": 17.265121638774872, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.159264087677, "training_acc": 52.0, "val_loss": 17.266471683979034, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.18195009231567, "training_acc": 52.0, "val_loss": 17.265315353870392, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24914216995239, "training_acc": 52.0, "val_loss": 17.26279854774475, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.20743894577026, "training_acc": 52.0, "val_loss": 17.260293662548065, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.11657118797302, "training_acc": 52.0, "val_loss": 17.25858896970749, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.12567639350891, "training_acc": 52.0, "val_loss": 17.25742369890213, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.13089871406555, "training_acc": 52.0, "val_loss": 17.256377637386322, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.05681204795837, "training_acc": 52.0, "val_loss": 17.254766821861267, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.05803751945496, "training_acc": 52.0, "val_loss": 17.25330501794815, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.16411471366882, "training_acc": 52.0, "val_loss": 17.25132167339325, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.17116189002991, "training_acc": 52.0, "val_loss": 17.24923998117447, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.1405975818634, "training_acc": 52.0, "val_loss": 17.24856197834015, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.11688494682312, "training_acc": 52.0, "val_loss": 17.248454689979553, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.00181245803833, "training_acc": 52.0, "val_loss": 17.24700629711151, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.09734606742859, "training_acc": 52.0, "val_loss": 17.246970534324646, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.14870643615723, "training_acc": 52.0, "val_loss": 17.247644066810608, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.04879879951477, "training_acc": 52.0, "val_loss": 17.2482430934906, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.02994513511658, "training_acc": 52.0, "val_loss": 17.247650027275085, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.07578730583191, "training_acc": 52.0, "val_loss": 17.248357832431793, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.06122136116028, "training_acc": 52.0, "val_loss": 17.248688638210297, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.8862476348877, "training_acc": 52.0, "val_loss": 17.24775731563568, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.14584732055664, "training_acc": 52.0, "val_loss": 17.24744886159897, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.04490637779236, "training_acc": 52.0, "val_loss": 17.24785715341568, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.97183537483215, "training_acc": 52.0, "val_loss": 17.248310148715973, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.99860453605652, "training_acc": 52.0, "val_loss": 17.248891294002533, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.96982526779175, "training_acc": 52.0, "val_loss": 17.248809337615967, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.14256405830383, "training_acc": 52.0, "val_loss": 17.24793165922165, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.05543231964111, "training_acc": 52.0, "val_loss": 17.24797785282135, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.06631302833557, "training_acc": 52.0, "val_loss": 17.248836159706116, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.96814274787903, "training_acc": 52.0, "val_loss": 17.248719930648804, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.0179374217987, "training_acc": 52.0, "val_loss": 17.248938977718353, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.00156092643738, "training_acc": 52.0, "val_loss": 17.249831557273865, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.08198928833008, "training_acc": 52.0, "val_loss": 17.250949144363403, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.06237435340881, "training_acc": 52.0, "val_loss": 17.252624034881592, "val_acc": 56.0}
