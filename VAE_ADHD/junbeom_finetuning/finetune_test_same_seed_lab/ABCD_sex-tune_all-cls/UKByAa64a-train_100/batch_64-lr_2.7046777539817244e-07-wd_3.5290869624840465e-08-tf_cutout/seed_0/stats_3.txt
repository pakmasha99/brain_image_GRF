"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.22704553604126, "training_acc": 55.0, "val_loss": 17.345748841762543, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.32289910316467, "training_acc": 52.0, "val_loss": 17.34541207551956, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22732067108154, "training_acc": 53.0, "val_loss": 17.34379678964615, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.30062794685364, "training_acc": 56.0, "val_loss": 17.34239310026169, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2827820777893, "training_acc": 51.0, "val_loss": 17.3415407538414, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23434972763062, "training_acc": 50.0, "val_loss": 17.34098792076111, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24609780311584, "training_acc": 52.0, "val_loss": 17.341025173664093, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.23533129692078, "training_acc": 51.0, "val_loss": 17.341145873069763, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.30161428451538, "training_acc": 50.0, "val_loss": 17.340198159217834, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2690315246582, "training_acc": 50.0, "val_loss": 17.341354489326477, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21183133125305, "training_acc": 52.0, "val_loss": 17.3397958278656, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24866104125977, "training_acc": 52.0, "val_loss": 17.338016629219055, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19587111473083, "training_acc": 56.0, "val_loss": 17.337431013584137, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18159937858582, "training_acc": 54.0, "val_loss": 17.336606979370117, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21716618537903, "training_acc": 49.0, "val_loss": 17.33573079109192, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10875058174133, "training_acc": 52.0, "val_loss": 17.336244881153107, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13979768753052, "training_acc": 53.0, "val_loss": 17.335788905620575, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24987411499023, "training_acc": 52.0, "val_loss": 17.335425317287445, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08198475837708, "training_acc": 53.0, "val_loss": 17.334257066249847, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.2722852230072, "training_acc": 55.0, "val_loss": 17.331406474113464, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19885301589966, "training_acc": 53.0, "val_loss": 17.32936054468155, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.02173733711243, "training_acc": 53.0, "val_loss": 17.327362298965454, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1545832157135, "training_acc": 55.0, "val_loss": 17.325913906097412, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.31044483184814, "training_acc": 51.0, "val_loss": 17.324298620224, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.29451870918274, "training_acc": 53.0, "val_loss": 17.322902381420135, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.07776737213135, "training_acc": 53.0, "val_loss": 17.32189506292343, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.09340023994446, "training_acc": 52.0, "val_loss": 17.321807146072388, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20052456855774, "training_acc": 53.0, "val_loss": 17.321738600730896, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.10711216926575, "training_acc": 52.0, "val_loss": 17.322489619255066, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14567160606384, "training_acc": 52.0, "val_loss": 17.32161045074463, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19927048683167, "training_acc": 51.0, "val_loss": 17.321506142616272, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.99074268341064, "training_acc": 55.0, "val_loss": 17.321956157684326, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.9755289554596, "training_acc": 53.0, "val_loss": 17.322970926761627, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.11674666404724, "training_acc": 52.0, "val_loss": 17.323775589466095, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.01435208320618, "training_acc": 51.0, "val_loss": 17.325234413146973, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1854841709137, "training_acc": 53.0, "val_loss": 17.32614040374756, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.97960615158081, "training_acc": 56.0, "val_loss": 17.326129972934723, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.07799649238586, "training_acc": 55.0, "val_loss": 17.326103150844574, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.88504457473755, "training_acc": 52.0, "val_loss": 17.325706779956818, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16154980659485, "training_acc": 53.0, "val_loss": 17.32528507709503, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.86884260177612, "training_acc": 52.0, "val_loss": 17.324809730052948, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.11029410362244, "training_acc": 53.0, "val_loss": 17.325007915496826, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.06269598007202, "training_acc": 54.0, "val_loss": 17.325636744499207, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.00649189949036, "training_acc": 53.0, "val_loss": 17.325744032859802, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.87248754501343, "training_acc": 56.0, "val_loss": 17.325396835803986, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.07196736335754, "training_acc": 52.0, "val_loss": 17.32538938522339, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15714716911316, "training_acc": 53.0, "val_loss": 17.324893176555634, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.04194569587708, "training_acc": 53.0, "val_loss": 17.323827743530273, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.02040958404541, "training_acc": 54.0, "val_loss": 17.323939502239227, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.04535388946533, "training_acc": 52.0, "val_loss": 17.32463836669922, "val_acc": 52.0}
