"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.18089866638184, "training_acc": 53.0, "val_loss": 17.26325750350952, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13329935073853, "training_acc": 53.0, "val_loss": 17.261166870594025, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20375776290894, "training_acc": 53.0, "val_loss": 17.260070145130157, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10154700279236, "training_acc": 53.0, "val_loss": 17.259100079536438, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16281151771545, "training_acc": 53.0, "val_loss": 17.25858300924301, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19413614273071, "training_acc": 53.0, "val_loss": 17.25885570049286, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12836861610413, "training_acc": 53.0, "val_loss": 17.25885421037674, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07033109664917, "training_acc": 53.0, "val_loss": 17.258936166763306, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16607594490051, "training_acc": 53.0, "val_loss": 17.25737303495407, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17767310142517, "training_acc": 53.0, "val_loss": 17.255672812461853, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17074704170227, "training_acc": 53.0, "val_loss": 17.253661155700684, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15268039703369, "training_acc": 53.0, "val_loss": 17.253006994724274, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.06821131706238, "training_acc": 53.0, "val_loss": 17.25197732448578, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11736392974854, "training_acc": 53.0, "val_loss": 17.25098043680191, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.05518817901611, "training_acc": 53.0, "val_loss": 17.250505089759827, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12089776992798, "training_acc": 53.0, "val_loss": 17.25035011768341, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1257712841034, "training_acc": 53.0, "val_loss": 17.249751091003418, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.09387230873108, "training_acc": 53.0, "val_loss": 17.24967509508133, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.09646797180176, "training_acc": 53.0, "val_loss": 17.250533401966095, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.03119730949402, "training_acc": 53.0, "val_loss": 17.250879108905792, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2283251285553, "training_acc": 53.0, "val_loss": 17.251166701316833, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11669278144836, "training_acc": 53.0, "val_loss": 17.25216507911682, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16050386428833, "training_acc": 53.0, "val_loss": 17.25327968597412, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12862014770508, "training_acc": 53.0, "val_loss": 17.254386842250824, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.87869167327881, "training_acc": 53.0, "val_loss": 17.255565524101257, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.9574658870697, "training_acc": 53.0, "val_loss": 17.25624054670334, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.08260774612427, "training_acc": 53.0, "val_loss": 17.257167398929596, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.96859669685364, "training_acc": 53.0, "val_loss": 17.25793033838272, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.03352475166321, "training_acc": 53.0, "val_loss": 17.258749902248383, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.08659815788269, "training_acc": 53.0, "val_loss": 17.25894957780838, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.04721808433533, "training_acc": 53.0, "val_loss": 17.2588974237442, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.01110434532166, "training_acc": 53.0, "val_loss": 17.25836843252182, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.01510167121887, "training_acc": 53.0, "val_loss": 17.258407175540924, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.03639316558838, "training_acc": 53.0, "val_loss": 17.259269952774048, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.9851815700531, "training_acc": 53.0, "val_loss": 17.259353399276733, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.00754523277283, "training_acc": 53.0, "val_loss": 17.25911647081375, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.00436568260193, "training_acc": 53.0, "val_loss": 17.25825071334839, "val_acc": 52.0}
