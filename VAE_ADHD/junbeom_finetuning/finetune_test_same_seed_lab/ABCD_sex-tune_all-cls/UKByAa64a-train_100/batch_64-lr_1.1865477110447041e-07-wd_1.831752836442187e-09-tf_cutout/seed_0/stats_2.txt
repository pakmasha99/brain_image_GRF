"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.99081897735596, "training_acc": 53.0, "val_loss": 17.368510365486145, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.10054349899292, "training_acc": 53.0, "val_loss": 17.36747920513153, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15977835655212, "training_acc": 53.0, "val_loss": 17.36680567264557, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22768688201904, "training_acc": 53.0, "val_loss": 17.366664111614227, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.10263681411743, "training_acc": 53.0, "val_loss": 17.366710305213928, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3344259262085, "training_acc": 53.0, "val_loss": 17.36624836921692, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1896984577179, "training_acc": 53.0, "val_loss": 17.365530133247375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.23965454101562, "training_acc": 53.0, "val_loss": 17.365071177482605, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11795234680176, "training_acc": 53.0, "val_loss": 17.364580929279327, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.09016466140747, "training_acc": 53.0, "val_loss": 17.36365407705307, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11777591705322, "training_acc": 53.0, "val_loss": 17.362774908542633, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09388279914856, "training_acc": 53.0, "val_loss": 17.362019419670105, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.0432710647583, "training_acc": 53.0, "val_loss": 17.36186146736145, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21277737617493, "training_acc": 53.0, "val_loss": 17.361821234226227, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12430191040039, "training_acc": 53.0, "val_loss": 17.361682653427124, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.07072162628174, "training_acc": 53.0, "val_loss": 17.361776530742645, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22223281860352, "training_acc": 53.0, "val_loss": 17.361198365688324, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12416768074036, "training_acc": 53.0, "val_loss": 17.360831797122955, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.06174325942993, "training_acc": 53.0, "val_loss": 17.359937727451324, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.01148724555969, "training_acc": 53.0, "val_loss": 17.358577251434326, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18594622612, "training_acc": 53.0, "val_loss": 17.356988787651062, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.19699573516846, "training_acc": 53.0, "val_loss": 17.355556786060333, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.096750497818, "training_acc": 53.0, "val_loss": 17.354358732700348, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.0648205280304, "training_acc": 53.0, "val_loss": 17.353257536888123, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11868524551392, "training_acc": 53.0, "val_loss": 17.352384328842163, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16097450256348, "training_acc": 53.0, "val_loss": 17.35192835330963, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.06755208969116, "training_acc": 53.0, "val_loss": 17.351751029491425, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.09318089485168, "training_acc": 53.0, "val_loss": 17.351490259170532, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.02507901191711, "training_acc": 53.0, "val_loss": 17.350952327251434, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.04535388946533, "training_acc": 53.0, "val_loss": 17.350874841213226, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1226053237915, "training_acc": 53.0, "val_loss": 17.35103726387024, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.0530595779419, "training_acc": 53.0, "val_loss": 17.35101491212845, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.06692051887512, "training_acc": 53.0, "val_loss": 17.350928485393524, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.01140069961548, "training_acc": 53.0, "val_loss": 17.351266741752625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.03826475143433, "training_acc": 53.0, "val_loss": 17.351199686527252, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.99327039718628, "training_acc": 53.0, "val_loss": 17.35118478536606, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.00351428985596, "training_acc": 53.0, "val_loss": 17.35127568244934, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.05882000923157, "training_acc": 53.0, "val_loss": 17.35142469406128, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.99940538406372, "training_acc": 53.0, "val_loss": 17.351512610912323, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14245557785034, "training_acc": 53.0, "val_loss": 17.35134869813919, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.06344676017761, "training_acc": 53.0, "val_loss": 17.35142022371292, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.01994252204895, "training_acc": 53.0, "val_loss": 17.351315915584564, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1142361164093, "training_acc": 53.0, "val_loss": 17.350955307483673, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1310088634491, "training_acc": 53.0, "val_loss": 17.350642383098602, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.02909779548645, "training_acc": 53.0, "val_loss": 17.35055148601532, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.97938561439514, "training_acc": 53.0, "val_loss": 17.35032945871353, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.98125767707825, "training_acc": 53.0, "val_loss": 17.35002100467682, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13940525054932, "training_acc": 53.0, "val_loss": 17.349818348884583, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.08537149429321, "training_acc": 53.0, "val_loss": 17.349860072135925, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.08927607536316, "training_acc": 53.0, "val_loss": 17.349572479724884, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.96525478363037, "training_acc": 53.0, "val_loss": 17.349979281425476, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.96736884117126, "training_acc": 53.0, "val_loss": 17.350265383720398, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.06467270851135, "training_acc": 53.0, "val_loss": 17.350423336029053, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.05278635025024, "training_acc": 53.0, "val_loss": 17.350484430789948, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.98989677429199, "training_acc": 53.0, "val_loss": 17.350471019744873, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.0556366443634, "training_acc": 53.0, "val_loss": 17.350734770298004, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.90975618362427, "training_acc": 53.0, "val_loss": 17.350734770298004, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.0355224609375, "training_acc": 53.0, "val_loss": 17.350871860980988, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.07225036621094, "training_acc": 53.0, "val_loss": 17.350859940052032, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.98253631591797, "training_acc": 53.0, "val_loss": 17.351646721363068, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.91793942451477, "training_acc": 53.0, "val_loss": 17.352309823036194, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.05655074119568, "training_acc": 53.0, "val_loss": 17.35318750143051, "val_acc": 52.0}
{"epoch": 62, "training_loss": 68.96625447273254, "training_acc": 53.0, "val_loss": 17.354194819927216, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.14558792114258, "training_acc": 53.0, "val_loss": 17.354552447795868, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.0095784664154, "training_acc": 53.0, "val_loss": 17.35489070415497, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.1132972240448, "training_acc": 53.0, "val_loss": 17.354661226272583, "val_acc": 52.0}
{"epoch": 66, "training_loss": 68.97302222251892, "training_acc": 53.0, "val_loss": 17.35466867685318, "val_acc": 52.0}
{"epoch": 67, "training_loss": 68.98536229133606, "training_acc": 53.0, "val_loss": 17.354293167591095, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.14136791229248, "training_acc": 53.0, "val_loss": 17.35427677631378, "val_acc": 52.0}
