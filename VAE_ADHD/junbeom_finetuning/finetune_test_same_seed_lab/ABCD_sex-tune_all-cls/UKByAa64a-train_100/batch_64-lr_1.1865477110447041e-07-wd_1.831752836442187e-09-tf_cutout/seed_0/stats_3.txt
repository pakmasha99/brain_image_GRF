"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2113745212555, "training_acc": 53.0, "val_loss": 17.3713356256485, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13928604125977, "training_acc": 53.0, "val_loss": 17.37053692340851, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2512276172638, "training_acc": 53.0, "val_loss": 17.369557917118073, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09461903572083, "training_acc": 53.0, "val_loss": 17.36779808998108, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14348530769348, "training_acc": 53.0, "val_loss": 17.365500330924988, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25087404251099, "training_acc": 53.0, "val_loss": 17.36369878053665, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2628824710846, "training_acc": 53.0, "val_loss": 17.362308502197266, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.30790448188782, "training_acc": 53.0, "val_loss": 17.360690236091614, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.253413438797, "training_acc": 53.0, "val_loss": 17.35891103744507, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23902606964111, "training_acc": 53.0, "val_loss": 17.357780039310455, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21499729156494, "training_acc": 53.0, "val_loss": 17.356710135936737, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22366952896118, "training_acc": 53.0, "val_loss": 17.355816066265106, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17629361152649, "training_acc": 53.0, "val_loss": 17.355163395404816, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2199547290802, "training_acc": 53.0, "val_loss": 17.354823648929596, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16640591621399, "training_acc": 53.0, "val_loss": 17.354503273963928, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20063996315002, "training_acc": 53.0, "val_loss": 17.354285717010498, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2560043334961, "training_acc": 53.0, "val_loss": 17.354294657707214, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12770128250122, "training_acc": 53.0, "val_loss": 17.355109751224518, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.25979542732239, "training_acc": 53.0, "val_loss": 17.355704307556152, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16966533660889, "training_acc": 53.0, "val_loss": 17.356255650520325, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21462655067444, "training_acc": 53.0, "val_loss": 17.356212437152863, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1954083442688, "training_acc": 53.0, "val_loss": 17.356356978416443, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24519324302673, "training_acc": 53.0, "val_loss": 17.355521023273468, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21203207969666, "training_acc": 53.0, "val_loss": 17.355182766914368, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.25602078437805, "training_acc": 53.0, "val_loss": 17.355182766914368, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12934732437134, "training_acc": 53.0, "val_loss": 17.3553466796875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12078499794006, "training_acc": 53.0, "val_loss": 17.355747520923615, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.22326421737671, "training_acc": 53.0, "val_loss": 17.356249690055847, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.05931997299194, "training_acc": 53.0, "val_loss": 17.356812953948975, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17491841316223, "training_acc": 53.0, "val_loss": 17.35725700855255, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17661356925964, "training_acc": 53.0, "val_loss": 17.357628047466278, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18714547157288, "training_acc": 53.0, "val_loss": 17.35824942588806, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.10072827339172, "training_acc": 53.0, "val_loss": 17.3581600189209, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12278485298157, "training_acc": 53.0, "val_loss": 17.35779494047165, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19134831428528, "training_acc": 53.0, "val_loss": 17.35728234052658, "val_acc": 52.0}
