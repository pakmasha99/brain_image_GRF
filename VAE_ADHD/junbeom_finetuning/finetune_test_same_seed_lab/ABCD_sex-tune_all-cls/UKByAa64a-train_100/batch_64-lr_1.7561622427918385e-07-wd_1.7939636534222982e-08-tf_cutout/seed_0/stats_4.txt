"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.42513966560364, "training_acc": 48.0, "val_loss": 17.341308295726776, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15375471115112, "training_acc": 55.0, "val_loss": 17.340809106826782, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.3740234375, "training_acc": 46.0, "val_loss": 17.340506613254547, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10974073410034, "training_acc": 52.0, "val_loss": 17.340172827243805, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.12275290489197, "training_acc": 53.0, "val_loss": 17.33970195055008, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.01945376396179, "training_acc": 55.0, "val_loss": 17.339034378528595, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24864625930786, "training_acc": 50.0, "val_loss": 17.3386812210083, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.03176999092102, "training_acc": 51.0, "val_loss": 17.338456213474274, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.96051526069641, "training_acc": 56.0, "val_loss": 17.338119447231293, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.42759895324707, "training_acc": 47.0, "val_loss": 17.337991297245026, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.27436828613281, "training_acc": 49.0, "val_loss": 17.33790785074234, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15622568130493, "training_acc": 53.0, "val_loss": 17.33805388212204, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.38659429550171, "training_acc": 47.0, "val_loss": 17.33826845884323, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.98340272903442, "training_acc": 52.0, "val_loss": 17.338599264621735, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.00738143920898, "training_acc": 56.0, "val_loss": 17.33880639076233, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10040044784546, "training_acc": 54.0, "val_loss": 17.338930070400238, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17023372650146, "training_acc": 52.0, "val_loss": 17.338840663433075, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23555326461792, "training_acc": 50.0, "val_loss": 17.338980734348297, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.02425456047058, "training_acc": 53.0, "val_loss": 17.338940501213074, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20069622993469, "training_acc": 51.0, "val_loss": 17.33897775411606, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21665239334106, "training_acc": 49.0, "val_loss": 17.338794469833374, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.02320432662964, "training_acc": 56.0, "val_loss": 17.338500916957855, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18387126922607, "training_acc": 52.0, "val_loss": 17.338140308856964, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26296210289001, "training_acc": 52.0, "val_loss": 17.337757349014282, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.052973985672, "training_acc": 55.0, "val_loss": 17.3374205827713, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1535575389862, "training_acc": 50.0, "val_loss": 17.33718514442444, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21306371688843, "training_acc": 53.0, "val_loss": 17.337004840373993, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.91044664382935, "training_acc": 56.0, "val_loss": 17.33647733926773, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.95864963531494, "training_acc": 54.0, "val_loss": 17.336003482341766, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.08091711997986, "training_acc": 53.0, "val_loss": 17.335382103919983, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.26572751998901, "training_acc": 53.0, "val_loss": 17.335043847560883, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.32473587989807, "training_acc": 49.0, "val_loss": 17.334721982479095, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.24879455566406, "training_acc": 49.0, "val_loss": 17.33459383249283, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.01429104804993, "training_acc": 53.0, "val_loss": 17.3345148563385, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.0313503742218, "training_acc": 55.0, "val_loss": 17.334461212158203, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.09377646446228, "training_acc": 52.0, "val_loss": 17.33441948890686, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12283754348755, "training_acc": 52.0, "val_loss": 17.33459085226059, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.0618908405304, "training_acc": 52.0, "val_loss": 17.33461767435074, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.92504811286926, "training_acc": 55.0, "val_loss": 17.334644496440887, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1278383731842, "training_acc": 51.0, "val_loss": 17.334532737731934, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.92424750328064, "training_acc": 53.0, "val_loss": 17.334716022014618, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.11521863937378, "training_acc": 53.0, "val_loss": 17.334705591201782, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.17368507385254, "training_acc": 54.0, "val_loss": 17.334672808647156, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.0370147228241, "training_acc": 55.0, "val_loss": 17.334599792957306, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.11701273918152, "training_acc": 53.0, "val_loss": 17.334792017936707, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.21915054321289, "training_acc": 51.0, "val_loss": 17.334821820259094, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.89372611045837, "training_acc": 54.0, "val_loss": 17.33497828245163, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.02220916748047, "training_acc": 54.0, "val_loss": 17.334701120853424, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.97174906730652, "training_acc": 55.0, "val_loss": 17.33464002609253, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.2300717830658, "training_acc": 54.0, "val_loss": 17.334815859794617, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.08707785606384, "training_acc": 53.0, "val_loss": 17.334872484207153, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.81470799446106, "training_acc": 52.0, "val_loss": 17.334972321987152, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.98594641685486, "training_acc": 53.0, "val_loss": 17.335006594657898, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.9137909412384, "training_acc": 54.0, "val_loss": 17.335084080696106, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.9470477104187, "training_acc": 53.0, "val_loss": 17.33514368534088, "val_acc": 52.0}
