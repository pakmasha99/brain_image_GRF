"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.15007734298706, "training_acc": 53.0, "val_loss": 17.34401136636734, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16484689712524, "training_acc": 53.0, "val_loss": 17.33766198158264, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1003029346466, "training_acc": 53.0, "val_loss": 17.332859337329865, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05124378204346, "training_acc": 53.0, "val_loss": 17.368514835834503, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.86449980735779, "training_acc": 53.0, "val_loss": 17.314323782920837, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.89127802848816, "training_acc": 53.0, "val_loss": 17.31114536523819, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.05155181884766, "training_acc": 53.0, "val_loss": 17.335349321365356, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.87745690345764, "training_acc": 53.0, "val_loss": 17.330975830554962, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.75533437728882, "training_acc": 53.0, "val_loss": 17.372050881385803, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.03537440299988, "training_acc": 53.0, "val_loss": 17.399965226650238, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.92307305335999, "training_acc": 53.0, "val_loss": 17.36207604408264, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.00088167190552, "training_acc": 53.0, "val_loss": 17.300574481487274, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.73987650871277, "training_acc": 53.0, "val_loss": 17.310434579849243, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.89464664459229, "training_acc": 53.0, "val_loss": 17.330588400363922, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.6840558052063, "training_acc": 53.0, "val_loss": 17.341983318328857, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.46607327461243, "training_acc": 53.0, "val_loss": 17.41698831319809, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.777503490448, "training_acc": 53.0, "val_loss": 17.4676775932312, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.19513607025146, "training_acc": 53.0, "val_loss": 17.329221963882446, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.55229830741882, "training_acc": 53.0, "val_loss": 17.34383851289749, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.20709729194641, "training_acc": 54.0, "val_loss": 17.482930421829224, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.56701231002808, "training_acc": 53.0, "val_loss": 17.390725016593933, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13328719139099, "training_acc": 53.0, "val_loss": 17.35893040895462, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25101017951965, "training_acc": 53.0, "val_loss": 17.345012724399567, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.0437445640564, "training_acc": 53.0, "val_loss": 17.36656278371811, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01178479194641, "training_acc": 53.0, "val_loss": 17.354655265808105, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1297767162323, "training_acc": 53.0, "val_loss": 17.329010367393494, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.93543934822083, "training_acc": 53.0, "val_loss": 17.321674525737762, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.91558456420898, "training_acc": 53.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.9749767780304, "training_acc": 53.0, "val_loss": 17.31235533952713, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.97630453109741, "training_acc": 58.0, "val_loss": 17.310424149036407, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.63816571235657, "training_acc": 55.0, "val_loss": 17.318984866142273, "val_acc": 52.0}
