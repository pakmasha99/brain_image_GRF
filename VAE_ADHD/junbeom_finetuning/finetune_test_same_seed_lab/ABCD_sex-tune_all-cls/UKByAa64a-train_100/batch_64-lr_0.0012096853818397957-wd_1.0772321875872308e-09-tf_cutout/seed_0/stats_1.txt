"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 103.89374208450317, "training_acc": 43.0, "val_loss": 125.21693706512451, "val_acc": 52.0}
{"epoch": 1, "training_loss": 512.9315338134766, "training_acc": 45.0, "val_loss": 17.349471151828766, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.51189160346985, "training_acc": 47.0, "val_loss": 133.5366129875183, "val_acc": 52.0}
{"epoch": 3, "training_loss": 327.6006968021393, "training_acc": 53.0, "val_loss": 17.84432679414749, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.41996359825134, "training_acc": 47.0, "val_loss": 17.334720492362976, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.72082209587097, "training_acc": 52.0, "val_loss": 17.312560975551605, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.12560772895813, "training_acc": 47.0, "val_loss": 17.348845303058624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15482425689697, "training_acc": 53.0, "val_loss": 17.35066920518875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.27704548835754, "training_acc": 53.0, "val_loss": 17.382414638996124, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23325085639954, "training_acc": 53.0, "val_loss": 17.33740121126175, "val_acc": 52.0}
{"epoch": 10, "training_loss": 74.68778944015503, "training_acc": 47.0, "val_loss": 17.306476831436157, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.51217722892761, "training_acc": 53.0, "val_loss": 17.327165603637695, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.32507014274597, "training_acc": 53.0, "val_loss": 17.310775816440582, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.0936131477356, "training_acc": 53.0, "val_loss": 17.31337457895279, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.414311170578, "training_acc": 47.0, "val_loss": 17.320789396762848, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31433463096619, "training_acc": 53.0, "val_loss": 17.311345040798187, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.11625003814697, "training_acc": 53.0, "val_loss": 17.341068387031555, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19487810134888, "training_acc": 53.0, "val_loss": 17.350192368030548, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.33945798873901, "training_acc": 53.0, "val_loss": 17.329958081245422, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18283200263977, "training_acc": 53.0, "val_loss": 17.330561578273773, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14257526397705, "training_acc": 53.0, "val_loss": 17.31344163417816, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.49702954292297, "training_acc": 53.0, "val_loss": 17.308661341667175, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14637565612793, "training_acc": 53.0, "val_loss": 17.311717569828033, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11115288734436, "training_acc": 53.0, "val_loss": 17.32567995786667, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19651961326599, "training_acc": 53.0, "val_loss": 17.348022758960724, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.27407121658325, "training_acc": 53.0, "val_loss": 17.339549958705902, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21617841720581, "training_acc": 53.0, "val_loss": 17.315049469470978, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.0914535522461, "training_acc": 53.0, "val_loss": 17.313891649246216, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.23188972473145, "training_acc": 53.0, "val_loss": 17.329369485378265, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.31403350830078, "training_acc": 50.0, "val_loss": 17.32652634382248, "val_acc": 52.0}
