"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 82.40822553634644, "training_acc": 57.0, "val_loss": 85.57323813438416, "val_acc": 52.0}
{"epoch": 1, "training_loss": 223142.21505737305, "training_acc": 49.0, "val_loss": 63.206130266189575, "val_acc": 48.0}
{"epoch": 2, "training_loss": 164.00218105316162, "training_acc": 59.0, "val_loss": 140.80359935760498, "val_acc": 52.0}
{"epoch": 3, "training_loss": 496.1568193435669, "training_acc": 53.0, "val_loss": 100.94598531723022, "val_acc": 48.0}
{"epoch": 4, "training_loss": 333.4935336112976, "training_acc": 41.0, "val_loss": 17.396755516529083, "val_acc": 52.0}
{"epoch": 5, "training_loss": 97.91220045089722, "training_acc": 47.0, "val_loss": 233.80937576293945, "val_acc": 52.0}
{"epoch": 6, "training_loss": 712.1762981414795, "training_acc": 53.0, "val_loss": 17.946188151836395, "val_acc": 52.0}
{"epoch": 7, "training_loss": 92.4832444190979, "training_acc": 47.0, "val_loss": 21.178773045539856, "val_acc": 48.0}
{"epoch": 8, "training_loss": 87.3308641910553, "training_acc": 43.0, "val_loss": 19.724158942699432, "val_acc": 52.0}
{"epoch": 9, "training_loss": 75.32136273384094, "training_acc": 53.0, "val_loss": 17.95809119939804, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.27014422416687, "training_acc": 47.0, "val_loss": 17.390628159046173, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.27004432678223, "training_acc": 53.0, "val_loss": 17.54859834909439, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.18055033683777, "training_acc": 47.0, "val_loss": 17.551247775554657, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.70933699607849, "training_acc": 47.0, "val_loss": 17.56664216518402, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.66289734840393, "training_acc": 53.0, "val_loss": 17.655937373638153, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.41649556159973, "training_acc": 53.0, "val_loss": 17.398639023303986, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.07945585250854, "training_acc": 47.0, "val_loss": 17.57645606994629, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.192467212677, "training_acc": 47.0, "val_loss": 17.32075810432434, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.96999430656433, "training_acc": 53.0, "val_loss": 17.61283427476883, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.0070812702179, "training_acc": 53.0, "val_loss": 17.462870478630066, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.57577991485596, "training_acc": 53.0, "val_loss": 17.31707751750946, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.03003811836243, "training_acc": 37.0, "val_loss": 17.312297224998474, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.0674078464508, "training_acc": 53.0, "val_loss": 17.46385097503662, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.79796528816223, "training_acc": 53.0, "val_loss": 17.506027221679688, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.88581824302673, "training_acc": 53.0, "val_loss": 17.329543828964233, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11660528182983, "training_acc": 53.0, "val_loss": 17.31308400630951, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.44868564605713, "training_acc": 45.0, "val_loss": 17.32178032398224, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16283583641052, "training_acc": 53.0, "val_loss": 17.323338985443115, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.09184789657593, "training_acc": 53.0, "val_loss": 17.41454303264618, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.39930725097656, "training_acc": 53.0, "val_loss": 17.4117773771286, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.39904022216797, "training_acc": 53.0, "val_loss": 17.37745553255081, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.29624080657959, "training_acc": 53.0, "val_loss": 17.313072085380554, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.29255723953247, "training_acc": 53.0, "val_loss": 17.319324612617493, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21768617630005, "training_acc": 53.0, "val_loss": 17.313310503959656, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17240571975708, "training_acc": 53.0, "val_loss": 17.321662604808807, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2042019367218, "training_acc": 53.0, "val_loss": 17.369891703128815, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22653150558472, "training_acc": 53.0, "val_loss": 17.369334399700165, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20893263816833, "training_acc": 53.0, "val_loss": 17.3374205827713, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13686060905457, "training_acc": 53.0, "val_loss": 17.319566011428833, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.09566116333008, "training_acc": 53.0, "val_loss": 17.31511503458023, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.15228986740112, "training_acc": 53.0, "val_loss": 17.322024703025818, "val_acc": 52.0}
