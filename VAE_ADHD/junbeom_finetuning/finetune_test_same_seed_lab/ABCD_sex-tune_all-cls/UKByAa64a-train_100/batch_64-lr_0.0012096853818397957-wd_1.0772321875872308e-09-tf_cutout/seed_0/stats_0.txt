"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.39403343200684, "training_acc": 50.0, "val_loss": 110.98577976226807, "val_acc": 44.0}
{"epoch": 1, "training_loss": 3360.2978515625, "training_acc": 48.0, "val_loss": 17.31943041086197, "val_acc": 56.0}
{"epoch": 2, "training_loss": 101.61319255828857, "training_acc": 54.0, "val_loss": 17.650848627090454, "val_acc": 56.0}
{"epoch": 3, "training_loss": 83.91761207580566, "training_acc": 46.0, "val_loss": 19.78752911090851, "val_acc": 44.0}
{"epoch": 4, "training_loss": 77.21608328819275, "training_acc": 48.0, "val_loss": 17.710183560848236, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.9127345085144, "training_acc": 44.0, "val_loss": 17.18573272228241, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27452087402344, "training_acc": 52.0, "val_loss": 17.285063862800598, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.35533785820007, "training_acc": 48.0, "val_loss": 17.21165031194687, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.29668474197388, "training_acc": 52.0, "val_loss": 17.1619713306427, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26954388618469, "training_acc": 52.0, "val_loss": 17.347460985183716, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.43959975242615, "training_acc": 48.0, "val_loss": 17.44685173034668, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.50242853164673, "training_acc": 48.0, "val_loss": 17.24301129579544, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.38592338562012, "training_acc": 52.0, "val_loss": 17.188461124897003, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.31773734092712, "training_acc": 52.0, "val_loss": 17.227792739868164, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25555443763733, "training_acc": 52.0, "val_loss": 17.242325842380524, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25934433937073, "training_acc": 52.0, "val_loss": 17.2243669629097, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.24235200881958, "training_acc": 52.0, "val_loss": 17.192772030830383, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.27772355079651, "training_acc": 52.0, "val_loss": 17.206089198589325, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24063539505005, "training_acc": 52.0, "val_loss": 17.235438525676727, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21962809562683, "training_acc": 52.0, "val_loss": 17.266948521137238, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2939989566803, "training_acc": 52.0, "val_loss": 17.290709912776947, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.25892376899719, "training_acc": 52.0, "val_loss": 17.247065901756287, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.42596673965454, "training_acc": 52.0, "val_loss": 17.19317138195038, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.27250838279724, "training_acc": 52.0, "val_loss": 17.21320152282715, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.20060849189758, "training_acc": 52.0, "val_loss": 17.274639010429382, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.31923460960388, "training_acc": 50.0, "val_loss": 17.340688407421112, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.52290320396423, "training_acc": 46.0, "val_loss": 17.309702932834625, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.27706265449524, "training_acc": 52.0, "val_loss": 17.33972579240799, "val_acc": 56.0}
