"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 88.38930702209473, "training_acc": 49.0, "val_loss": 109.56665277481079, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3842.7765197753906, "training_acc": 47.0, "val_loss": 41.437047719955444, "val_acc": 48.0}
{"epoch": 2, "training_loss": 139.37779998779297, "training_acc": 47.0, "val_loss": 17.55206137895584, "val_acc": 52.0}
{"epoch": 3, "training_loss": 172.1314458847046, "training_acc": 49.0, "val_loss": 45.3881710767746, "val_acc": 52.0}
{"epoch": 4, "training_loss": 147.96303176879883, "training_acc": 53.0, "val_loss": 17.606553435325623, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.03221130371094, "training_acc": 43.0, "val_loss": 17.494475841522217, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.31933975219727, "training_acc": 47.0, "val_loss": 17.36006885766983, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.41856908798218, "training_acc": 47.0, "val_loss": 17.307791113853455, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17534232139587, "training_acc": 53.0, "val_loss": 17.415495216846466, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.47065830230713, "training_acc": 53.0, "val_loss": 17.38469898700714, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.08800911903381, "training_acc": 53.0, "val_loss": 17.374232411384583, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.49808502197266, "training_acc": 47.0, "val_loss": 17.454269528388977, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.89979863166809, "training_acc": 47.0, "val_loss": 17.377443611621857, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.69275736808777, "training_acc": 43.0, "val_loss": 17.312201857566833, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17289924621582, "training_acc": 53.0, "val_loss": 17.30729639530182, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11606574058533, "training_acc": 53.0, "val_loss": 17.32873171567917, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16405272483826, "training_acc": 53.0, "val_loss": 17.35081374645233, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.29886174201965, "training_acc": 53.0, "val_loss": 17.347945272922516, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21368098258972, "training_acc": 53.0, "val_loss": 17.314505577087402, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1450355052948, "training_acc": 53.0, "val_loss": 17.30547696352005, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14290475845337, "training_acc": 53.0, "val_loss": 17.307212948799133, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16799116134644, "training_acc": 53.0, "val_loss": 17.30935424566269, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.31331729888916, "training_acc": 53.0, "val_loss": 17.31042116880417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1548159122467, "training_acc": 53.0, "val_loss": 17.307479679584503, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17913937568665, "training_acc": 53.0, "val_loss": 17.318230867385864, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.33469319343567, "training_acc": 53.0, "val_loss": 17.33049899339676, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16012501716614, "training_acc": 53.0, "val_loss": 17.32051372528076, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2235677242279, "training_acc": 53.0, "val_loss": 17.310282588005066, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15924119949341, "training_acc": 53.0, "val_loss": 17.308925092220306, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13799262046814, "training_acc": 53.0, "val_loss": 17.309875786304474, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14361643791199, "training_acc": 53.0, "val_loss": 17.31078326702118, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.16665363311768, "training_acc": 53.0, "val_loss": 17.31424331665039, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.21260118484497, "training_acc": 53.0, "val_loss": 17.314809560775757, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1512839794159, "training_acc": 53.0, "val_loss": 17.309680581092834, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13688611984253, "training_acc": 53.0, "val_loss": 17.30833798646927, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14743494987488, "training_acc": 53.0, "val_loss": 17.308206856250763, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1600239276886, "training_acc": 53.0, "val_loss": 17.30828434228897, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16132020950317, "training_acc": 53.0, "val_loss": 17.308279871940613, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14737844467163, "training_acc": 53.0, "val_loss": 17.30886548757553, "val_acc": 52.0}
