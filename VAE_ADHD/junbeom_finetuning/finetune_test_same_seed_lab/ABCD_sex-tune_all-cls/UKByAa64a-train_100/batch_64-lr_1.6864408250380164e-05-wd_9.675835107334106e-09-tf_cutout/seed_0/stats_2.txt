"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24419045448303, "training_acc": 53.0, "val_loss": 17.286430299282074, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21000576019287, "training_acc": 53.0, "val_loss": 17.277534306049347, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.05518078804016, "training_acc": 53.0, "val_loss": 17.280738055706024, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.89839839935303, "training_acc": 53.0, "val_loss": 17.265039682388306, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.89132308959961, "training_acc": 53.0, "val_loss": 17.290732264518738, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17599391937256, "training_acc": 53.0, "val_loss": 17.298075556755066, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14453029632568, "training_acc": 53.0, "val_loss": 17.30893701314926, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.97470593452454, "training_acc": 53.0, "val_loss": 17.321592569351196, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04549813270569, "training_acc": 53.0, "val_loss": 17.326875030994415, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.01165270805359, "training_acc": 53.0, "val_loss": 17.349474132061005, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.00328803062439, "training_acc": 53.0, "val_loss": 17.32947826385498, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.8896255493164, "training_acc": 53.0, "val_loss": 17.323017120361328, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.91273164749146, "training_acc": 53.0, "val_loss": 17.305666208267212, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.82130026817322, "training_acc": 53.0, "val_loss": 17.292533814907074, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.87079548835754, "training_acc": 53.0, "val_loss": 17.28428453207016, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.79499936103821, "training_acc": 53.0, "val_loss": 17.297329008579254, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.76189351081848, "training_acc": 53.0, "val_loss": 17.29464679956436, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.53317713737488, "training_acc": 53.0, "val_loss": 17.30448454618454, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.67052507400513, "training_acc": 53.0, "val_loss": 17.285513877868652, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.45765423774719, "training_acc": 53.0, "val_loss": 17.279279232025146, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.57506132125854, "training_acc": 53.0, "val_loss": 17.262370884418488, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.4779040813446, "training_acc": 53.0, "val_loss": 17.275696992874146, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.11679482460022, "training_acc": 53.0, "val_loss": 17.307977378368378, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.07840824127197, "training_acc": 53.0, "val_loss": 17.274361848831177, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.35440182685852, "training_acc": 53.0, "val_loss": 17.260171473026276, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.95668840408325, "training_acc": 53.0, "val_loss": 17.268428206443787, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.04109215736389, "training_acc": 53.0, "val_loss": 17.2540545463562, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.85379433631897, "training_acc": 53.0, "val_loss": 17.25870817899704, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.16644263267517, "training_acc": 53.0, "val_loss": 17.275960743427277, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.36023807525635, "training_acc": 53.0, "val_loss": 17.218059301376343, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.02249836921692, "training_acc": 53.0, "val_loss": 17.206865549087524, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.20249104499817, "training_acc": 61.0, "val_loss": 17.136168479919434, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.5308735370636, "training_acc": 58.0, "val_loss": 17.24258065223694, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.5036997795105, "training_acc": 53.0, "val_loss": 17.281077802181244, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.44190883636475, "training_acc": 77.0, "val_loss": 17.110668122768402, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.93705105781555, "training_acc": 57.0, "val_loss": 17.388032376766205, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.86825203895569, "training_acc": 54.0, "val_loss": 17.288875579833984, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.82251310348511, "training_acc": 75.0, "val_loss": 17.33534038066864, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.42560744285583, "training_acc": 83.0, "val_loss": 17.156454920768738, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.82701635360718, "training_acc": 58.0, "val_loss": 17.12823063135147, "val_acc": 52.0}
{"epoch": 40, "training_loss": 66.28681182861328, "training_acc": 53.0, "val_loss": 17.095130681991577, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.29907894134521, "training_acc": 77.0, "val_loss": 17.086273431777954, "val_acc": 52.0}
{"epoch": 42, "training_loss": 65.20910358428955, "training_acc": 56.0, "val_loss": 16.992808878421783, "val_acc": 52.0}
{"epoch": 43, "training_loss": 64.25783944129944, "training_acc": 73.0, "val_loss": 16.9815331697464, "val_acc": 52.0}
{"epoch": 44, "training_loss": 64.66931080818176, "training_acc": 74.0, "val_loss": 17.004579305648804, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.27466678619385, "training_acc": 69.0, "val_loss": 17.074312269687653, "val_acc": 52.0}
{"epoch": 46, "training_loss": 62.99525785446167, "training_acc": 84.0, "val_loss": 17.42579936981201, "val_acc": 52.0}
{"epoch": 47, "training_loss": 66.75453996658325, "training_acc": 54.0, "val_loss": 17.29205995798111, "val_acc": 52.0}
{"epoch": 48, "training_loss": 64.68399548530579, "training_acc": 74.0, "val_loss": 16.988959908485413, "val_acc": 52.0}
{"epoch": 49, "training_loss": 64.5476758480072, "training_acc": 68.0, "val_loss": 16.796819865703583, "val_acc": 52.0}
{"epoch": 50, "training_loss": 62.40331268310547, "training_acc": 80.0, "val_loss": 16.882959008216858, "val_acc": 52.0}
{"epoch": 51, "training_loss": 62.876157999038696, "training_acc": 80.0, "val_loss": 16.703902184963226, "val_acc": 52.0}
{"epoch": 52, "training_loss": 61.781250953674316, "training_acc": 78.0, "val_loss": 16.732825338840485, "val_acc": 52.0}
{"epoch": 53, "training_loss": 62.379101514816284, "training_acc": 71.0, "val_loss": 17.53043830394745, "val_acc": 52.0}
{"epoch": 54, "training_loss": 64.08399415016174, "training_acc": 70.0, "val_loss": 16.75010770559311, "val_acc": 52.0}
{"epoch": 55, "training_loss": 60.55615592002869, "training_acc": 72.0, "val_loss": 16.864857077598572, "val_acc": 52.0}
{"epoch": 56, "training_loss": 60.288816928863525, "training_acc": 85.0, "val_loss": 16.65811687707901, "val_acc": 52.0}
{"epoch": 57, "training_loss": 60.225491523742676, "training_acc": 72.0, "val_loss": 16.592033207416534, "val_acc": 52.0}
{"epoch": 58, "training_loss": 59.53351378440857, "training_acc": 87.0, "val_loss": 17.04181581735611, "val_acc": 52.0}
{"epoch": 59, "training_loss": 57.66144299507141, "training_acc": 88.0, "val_loss": 17.234531044960022, "val_acc": 52.0}
{"epoch": 60, "training_loss": 61.55923104286194, "training_acc": 64.0, "val_loss": 17.022857069969177, "val_acc": 56.0}
{"epoch": 61, "training_loss": 58.73838257789612, "training_acc": 87.0, "val_loss": 16.732503473758698, "val_acc": 52.0}
{"epoch": 62, "training_loss": 54.97108197212219, "training_acc": 91.0, "val_loss": 16.367830336093903, "val_acc": 52.0}
{"epoch": 63, "training_loss": 53.32438683509827, "training_acc": 96.0, "val_loss": 16.83959662914276, "val_acc": 56.0}
{"epoch": 64, "training_loss": 53.125293016433716, "training_acc": 93.0, "val_loss": 16.764746606349945, "val_acc": 52.0}
{"epoch": 65, "training_loss": 59.01762509346008, "training_acc": 66.0, "val_loss": 17.426015436649323, "val_acc": 64.0}
{"epoch": 66, "training_loss": 57.26719546318054, "training_acc": 79.0, "val_loss": 17.067241668701172, "val_acc": 52.0}
{"epoch": 67, "training_loss": 60.12622141838074, "training_acc": 69.0, "val_loss": 16.608572006225586, "val_acc": 56.0}
{"epoch": 68, "training_loss": 53.90500354766846, "training_acc": 87.0, "val_loss": 16.325055062770844, "val_acc": 56.0}
{"epoch": 69, "training_loss": 50.47427749633789, "training_acc": 93.0, "val_loss": 16.8868288397789, "val_acc": 60.0}
{"epoch": 70, "training_loss": 52.90522360801697, "training_acc": 87.0, "val_loss": 16.815949976444244, "val_acc": 64.0}
{"epoch": 71, "training_loss": 49.71591877937317, "training_acc": 96.0, "val_loss": 16.321420669555664, "val_acc": 56.0}
{"epoch": 72, "training_loss": 53.51450300216675, "training_acc": 85.0, "val_loss": 16.334258019924164, "val_acc": 56.0}
{"epoch": 73, "training_loss": 49.62948274612427, "training_acc": 94.0, "val_loss": 16.262704133987427, "val_acc": 56.0}
{"epoch": 74, "training_loss": 48.52097940444946, "training_acc": 93.0, "val_loss": 16.885143518447876, "val_acc": 68.0}
{"epoch": 75, "training_loss": 48.21396863460541, "training_acc": 95.0, "val_loss": 16.194505989551544, "val_acc": 60.0}
{"epoch": 76, "training_loss": 47.27467346191406, "training_acc": 94.0, "val_loss": 16.255953907966614, "val_acc": 56.0}
{"epoch": 77, "training_loss": 48.17048132419586, "training_acc": 90.0, "val_loss": 17.119258642196655, "val_acc": 68.0}
{"epoch": 78, "training_loss": 46.26463866233826, "training_acc": 94.0, "val_loss": 17.781463265419006, "val_acc": 60.0}
{"epoch": 79, "training_loss": 45.48065221309662, "training_acc": 99.0, "val_loss": 16.198593378067017, "val_acc": 56.0}
{"epoch": 80, "training_loss": 52.0080406665802, "training_acc": 81.0, "val_loss": 16.72891229391098, "val_acc": 68.0}
{"epoch": 81, "training_loss": 47.07624864578247, "training_acc": 91.0, "val_loss": 16.77028387784958, "val_acc": 68.0}
{"epoch": 82, "training_loss": 44.63819181919098, "training_acc": 94.0, "val_loss": 15.969415009021759, "val_acc": 60.0}
{"epoch": 83, "training_loss": 44.180631160736084, "training_acc": 93.0, "val_loss": 16.96763038635254, "val_acc": 68.0}
{"epoch": 84, "training_loss": 43.946613788604736, "training_acc": 97.0, "val_loss": 16.2711501121521, "val_acc": 56.0}
{"epoch": 85, "training_loss": 47.38860309123993, "training_acc": 88.0, "val_loss": 17.890365421772003, "val_acc": 56.0}
{"epoch": 86, "training_loss": 45.07094061374664, "training_acc": 95.0, "val_loss": 15.978600084781647, "val_acc": 60.0}
{"epoch": 87, "training_loss": 44.21485900878906, "training_acc": 93.0, "val_loss": 16.019004583358765, "val_acc": 60.0}
{"epoch": 88, "training_loss": 44.97247529029846, "training_acc": 89.0, "val_loss": 17.714887857437134, "val_acc": 56.0}
{"epoch": 89, "training_loss": 44.029191851615906, "training_acc": 96.0, "val_loss": 16.83221459388733, "val_acc": 56.0}
{"epoch": 90, "training_loss": 46.37869656085968, "training_acc": 87.0, "val_loss": 18.612125515937805, "val_acc": 44.0}
{"epoch": 91, "training_loss": 48.65555429458618, "training_acc": 84.0, "val_loss": 16.71576201915741, "val_acc": 56.0}
{"epoch": 92, "training_loss": 44.68443262577057, "training_acc": 90.0, "val_loss": 18.177396059036255, "val_acc": 56.0}
{"epoch": 93, "training_loss": 46.00032591819763, "training_acc": 91.0, "val_loss": 16.662780940532684, "val_acc": 56.0}
{"epoch": 94, "training_loss": 45.17833149433136, "training_acc": 89.0, "val_loss": 16.602985560894012, "val_acc": 68.0}
{"epoch": 95, "training_loss": 41.041372537612915, "training_acc": 97.0, "val_loss": 17.98439919948578, "val_acc": 52.0}
{"epoch": 96, "training_loss": 42.26561522483826, "training_acc": 97.0, "val_loss": 16.35367125272751, "val_acc": 56.0}
{"epoch": 97, "training_loss": 40.450541377067566, "training_acc": 96.0, "val_loss": 17.770831286907196, "val_acc": 60.0}
{"epoch": 98, "training_loss": 39.372809052467346, "training_acc": 98.0, "val_loss": 16.24547988176346, "val_acc": 56.0}
{"epoch": 99, "training_loss": 38.60612082481384, "training_acc": 99.0, "val_loss": 17.38782823085785, "val_acc": 68.0}
{"epoch": 100, "training_loss": 36.62131094932556, "training_acc": 99.0, "val_loss": 16.762760281562805, "val_acc": 68.0}
{"epoch": 101, "training_loss": 37.57396709918976, "training_acc": 100.0, "val_loss": 17.466382682323456, "val_acc": 64.0}
