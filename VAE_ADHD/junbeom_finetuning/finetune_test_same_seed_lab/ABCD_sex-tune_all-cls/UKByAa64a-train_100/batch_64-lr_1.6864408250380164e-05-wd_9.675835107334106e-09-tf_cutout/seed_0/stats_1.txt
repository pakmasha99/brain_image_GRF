"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.27287411689758, "training_acc": 53.0, "val_loss": 17.34936088323593, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2324001789093, "training_acc": 54.0, "val_loss": 17.361602187156677, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.06808090209961, "training_acc": 54.0, "val_loss": 17.28910356760025, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10467648506165, "training_acc": 53.0, "val_loss": 17.309100925922394, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14729809761047, "training_acc": 53.0, "val_loss": 17.3173189163208, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.94501447677612, "training_acc": 53.0, "val_loss": 17.31652468442917, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.08607244491577, "training_acc": 53.0, "val_loss": 17.324790358543396, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.9018292427063, "training_acc": 53.0, "val_loss": 17.35268384218216, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.81143879890442, "training_acc": 53.0, "val_loss": 17.3648864030838, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.66276240348816, "training_acc": 53.0, "val_loss": 17.362752556800842, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.79600644111633, "training_acc": 53.0, "val_loss": 17.331193387508392, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.76934099197388, "training_acc": 53.0, "val_loss": 17.32620596885681, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.51825046539307, "training_acc": 53.0, "val_loss": 17.31381118297577, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.2344925403595, "training_acc": 53.0, "val_loss": 17.335975170135498, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.70192790031433, "training_acc": 53.0, "val_loss": 17.349781095981598, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.48973202705383, "training_acc": 53.0, "val_loss": 17.31470078229904, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.9461579322815, "training_acc": 53.0, "val_loss": 17.272943258285522, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.81919193267822, "training_acc": 53.0, "val_loss": 17.27771759033203, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.65856981277466, "training_acc": 53.0, "val_loss": 17.30482578277588, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.45391011238098, "training_acc": 53.0, "val_loss": 17.299363017082214, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.19818663597107, "training_acc": 54.0, "val_loss": 17.30407327413559, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.11275887489319, "training_acc": 53.0, "val_loss": 17.357178032398224, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.0213897228241, "training_acc": 54.0, "val_loss": 17.309804260730743, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.97258472442627, "training_acc": 63.0, "val_loss": 17.32987016439438, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.75030732154846, "training_acc": 69.0, "val_loss": 17.353564500808716, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.92934489250183, "training_acc": 53.0, "val_loss": 17.42015928030014, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.87905550003052, "training_acc": 53.0, "val_loss": 17.327935993671417, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.04756212234497, "training_acc": 53.0, "val_loss": 17.3202782869339, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.45467066764832, "training_acc": 67.0, "val_loss": 17.30196326971054, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.18336987495422, "training_acc": 64.0, "val_loss": 17.44495928287506, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.93583512306213, "training_acc": 53.0, "val_loss": 17.433683574199677, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.83103489875793, "training_acc": 53.0, "val_loss": 17.301882803440094, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.0265793800354, "training_acc": 59.0, "val_loss": 17.312516272068024, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.79687595367432, "training_acc": 74.0, "val_loss": 17.286381125450134, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.48993611335754, "training_acc": 72.0, "val_loss": 17.32008159160614, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.65911030769348, "training_acc": 57.0, "val_loss": 17.2862246632576, "val_acc": 52.0}
