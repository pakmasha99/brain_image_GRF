"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31700086593628, "training_acc": 52.0, "val_loss": 17.268581688404083, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24329948425293, "training_acc": 52.0, "val_loss": 17.294375598430634, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.08045148849487, "training_acc": 52.0, "val_loss": 17.279687523841858, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.07814908027649, "training_acc": 52.0, "val_loss": 17.261028289794922, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.00660014152527, "training_acc": 52.0, "val_loss": 17.269501090049744, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.14209198951721, "training_acc": 52.0, "val_loss": 17.29270964860916, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.03671383857727, "training_acc": 52.0, "val_loss": 17.33071357011795, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.10746383666992, "training_acc": 52.0, "val_loss": 17.33798235654831, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.12166357040405, "training_acc": 53.0, "val_loss": 17.313916981220245, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.00785851478577, "training_acc": 52.0, "val_loss": 17.34493225812912, "val_acc": 56.0}
{"epoch": 10, "training_loss": 68.87460207939148, "training_acc": 52.0, "val_loss": 17.364266514778137, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.94095230102539, "training_acc": 57.0, "val_loss": 17.33258068561554, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.58140230178833, "training_acc": 55.0, "val_loss": 17.31429696083069, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.29065895080566, "training_acc": 55.0, "val_loss": 17.343734204769135, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.50047087669373, "training_acc": 55.0, "val_loss": 17.331776022911072, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.46710801124573, "training_acc": 54.0, "val_loss": 17.314600944519043, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.30494403839111, "training_acc": 54.0, "val_loss": 17.275044322013855, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.33951544761658, "training_acc": 53.0, "val_loss": 17.436744272708893, "val_acc": 56.0}
{"epoch": 18, "training_loss": 67.79621171951294, "training_acc": 61.0, "val_loss": 17.50495880842209, "val_acc": 56.0}
{"epoch": 19, "training_loss": 67.99818086624146, "training_acc": 60.0, "val_loss": 17.29213446378708, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.38694143295288, "training_acc": 63.0, "val_loss": 17.505115270614624, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.66624164581299, "training_acc": 68.0, "val_loss": 17.501479387283325, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.51298141479492, "training_acc": 58.0, "val_loss": 17.332130670547485, "val_acc": 56.0}
