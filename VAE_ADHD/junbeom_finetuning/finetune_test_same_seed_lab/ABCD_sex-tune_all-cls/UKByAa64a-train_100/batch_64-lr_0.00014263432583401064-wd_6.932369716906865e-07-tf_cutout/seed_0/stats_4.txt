"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.94210004806519, "training_acc": 53.0, "val_loss": 17.57340580224991, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.17581844329834, "training_acc": 51.0, "val_loss": 17.33134090900421, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.99076962471008, "training_acc": 53.0, "val_loss": 17.502513527870178, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.16646265983582, "training_acc": 45.0, "val_loss": 17.351798713207245, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.35245776176453, "training_acc": 49.0, "val_loss": 17.382541298866272, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.73125958442688, "training_acc": 53.0, "val_loss": 17.33514368534088, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.0362389087677, "training_acc": 53.0, "val_loss": 17.312930524349213, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17502188682556, "training_acc": 51.0, "val_loss": 17.34035313129425, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.96844220161438, "training_acc": 47.0, "val_loss": 17.311258614063263, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.8580048084259, "training_acc": 53.0, "val_loss": 17.41395592689514, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.30258107185364, "training_acc": 53.0, "val_loss": 17.32475310564041, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.67208886146545, "training_acc": 45.0, "val_loss": 17.324188351631165, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16982936859131, "training_acc": 53.0, "val_loss": 17.334532737731934, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13624668121338, "training_acc": 53.0, "val_loss": 17.356601357460022, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2162926197052, "training_acc": 53.0, "val_loss": 17.328262329101562, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20837354660034, "training_acc": 53.0, "val_loss": 17.316214740276337, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.36256194114685, "training_acc": 45.0, "val_loss": 17.31158047914505, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23452615737915, "training_acc": 53.0, "val_loss": 17.33766943216324, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19600987434387, "training_acc": 53.0, "val_loss": 17.34211891889572, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12189984321594, "training_acc": 53.0, "val_loss": 17.31424480676651, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09951376914978, "training_acc": 53.0, "val_loss": 17.312321066856384, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10907363891602, "training_acc": 53.0, "val_loss": 17.315615713596344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.06397366523743, "training_acc": 53.0, "val_loss": 17.33226180076599, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.04628801345825, "training_acc": 53.0, "val_loss": 17.360271513462067, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.24634575843811, "training_acc": 53.0, "val_loss": 17.349624633789062, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15460896492004, "training_acc": 53.0, "val_loss": 17.319928109645844, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16089510917664, "training_acc": 53.0, "val_loss": 17.320141196250916, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.06462121009827, "training_acc": 53.0, "val_loss": 17.328888177871704, "val_acc": 52.0}
