"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.50268912315369, "training_acc": 44.0, "val_loss": 17.36193597316742, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1836519241333, "training_acc": 53.0, "val_loss": 46.397608518600464, "val_acc": 52.0}
{"epoch": 2, "training_loss": 132.07641005516052, "training_acc": 53.0, "val_loss": 17.312274873256683, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.98814082145691, "training_acc": 53.0, "val_loss": 17.59430319070816, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.59890913963318, "training_acc": 47.0, "val_loss": 17.34381467103958, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.25374436378479, "training_acc": 49.0, "val_loss": 17.36864000558853, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.68598484992981, "training_acc": 55.0, "val_loss": 18.053153157234192, "val_acc": 52.0}
{"epoch": 7, "training_loss": 72.47720837593079, "training_acc": 44.0, "val_loss": 17.342151701450348, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.95911240577698, "training_acc": 53.0, "val_loss": 17.36571490764618, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1138653755188, "training_acc": 53.0, "val_loss": 17.341987788677216, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07270836830139, "training_acc": 53.0, "val_loss": 17.348551750183105, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.28707075119019, "training_acc": 53.0, "val_loss": 17.363643646240234, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09369397163391, "training_acc": 51.0, "val_loss": 17.393070459365845, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04244613647461, "training_acc": 55.0, "val_loss": 17.412281036376953, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.24525237083435, "training_acc": 53.0, "val_loss": 17.418108880519867, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.05575370788574, "training_acc": 53.0, "val_loss": 17.412395775318146, "val_acc": 52.0}
{"epoch": 16, "training_loss": 71.17565202713013, "training_acc": 48.0, "val_loss": 17.357471585273743, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.39719414710999, "training_acc": 53.0, "val_loss": 17.715005576610565, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.45492720603943, "training_acc": 53.0, "val_loss": 17.517192661762238, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21246814727783, "training_acc": 53.0, "val_loss": 17.308436334133148, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1006920337677, "training_acc": 55.0, "val_loss": 17.570926249027252, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.77644038200378, "training_acc": 47.0, "val_loss": 17.447911202907562, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.41664838790894, "training_acc": 50.0, "val_loss": 17.338450253009796, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24894690513611, "training_acc": 53.0, "val_loss": 17.533694207668304, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.75085544586182, "training_acc": 53.0, "val_loss": 17.463785409927368, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.46281433105469, "training_acc": 53.0, "val_loss": 17.339755594730377, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.00001430511475, "training_acc": 53.0, "val_loss": 17.31535494327545, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.41945266723633, "training_acc": 49.0, "val_loss": 17.4052432179451, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.63975071907043, "training_acc": 47.0, "val_loss": 17.352549731731415, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.48316049575806, "training_acc": 45.0, "val_loss": 17.314082384109497, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.0356798171997, "training_acc": 53.0, "val_loss": 17.339487373828888, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1258807182312, "training_acc": 53.0, "val_loss": 17.37343519926071, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19570183753967, "training_acc": 53.0, "val_loss": 17.381247878074646, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14746046066284, "training_acc": 53.0, "val_loss": 17.368583381175995, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.11740589141846, "training_acc": 53.0, "val_loss": 17.337581515312195, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.99484586715698, "training_acc": 53.0, "val_loss": 17.324310541152954, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.24921107292175, "training_acc": 53.0, "val_loss": 17.33165681362152, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.09509634971619, "training_acc": 53.0, "val_loss": 17.33195036649704, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.06061267852783, "training_acc": 53.0, "val_loss": 17.342109978199005, "val_acc": 52.0}
