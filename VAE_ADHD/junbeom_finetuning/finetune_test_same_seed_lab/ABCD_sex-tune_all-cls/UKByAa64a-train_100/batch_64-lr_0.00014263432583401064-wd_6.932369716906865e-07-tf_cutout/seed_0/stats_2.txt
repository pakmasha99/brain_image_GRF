"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.5493974685669, "training_acc": 54.0, "val_loss": 17.522604763507843, "val_acc": 52.0}
{"epoch": 1, "training_loss": 125.03769111633301, "training_acc": 47.0, "val_loss": 17.397454380989075, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.93874192237854, "training_acc": 47.0, "val_loss": 17.57136881351471, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.29416251182556, "training_acc": 53.0, "val_loss": 17.389312386512756, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.02507519721985, "training_acc": 53.0, "val_loss": 17.689959704875946, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.05119323730469, "training_acc": 45.0, "val_loss": 17.550557851791382, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.11343479156494, "training_acc": 49.0, "val_loss": 17.55533218383789, "val_acc": 52.0}
{"epoch": 7, "training_loss": 74.22610545158386, "training_acc": 53.0, "val_loss": 17.441126704216003, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.47827076911926, "training_acc": 56.0, "val_loss": 17.867648601531982, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.30313181877136, "training_acc": 47.0, "val_loss": 17.408567667007446, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0328598022461, "training_acc": 53.0, "val_loss": 17.70414263010025, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.95364475250244, "training_acc": 53.0, "val_loss": 17.44345873594284, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.4098551273346, "training_acc": 43.0, "val_loss": 17.357364296913147, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08128666877747, "training_acc": 53.0, "val_loss": 17.35648512840271, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.71280217170715, "training_acc": 53.0, "val_loss": 17.414410412311554, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.62473654747009, "training_acc": 53.0, "val_loss": 17.339545488357544, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13744449615479, "training_acc": 53.0, "val_loss": 17.33703762292862, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11501336097717, "training_acc": 53.0, "val_loss": 17.33919531106949, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22408747673035, "training_acc": 53.0, "val_loss": 17.340929806232452, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.09180045127869, "training_acc": 53.0, "val_loss": 17.328056693077087, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11675238609314, "training_acc": 53.0, "val_loss": 17.32223480939865, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10363793373108, "training_acc": 53.0, "val_loss": 17.3227459192276, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.01407361030579, "training_acc": 53.0, "val_loss": 17.32695698738098, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.03147864341736, "training_acc": 53.0, "val_loss": 17.34709143638611, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18093204498291, "training_acc": 53.0, "val_loss": 17.369361221790314, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16409635543823, "training_acc": 53.0, "val_loss": 17.33378916978836, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.07162070274353, "training_acc": 53.0, "val_loss": 17.325100302696228, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10071182250977, "training_acc": 53.0, "val_loss": 17.33369380235672, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11505174636841, "training_acc": 56.0, "val_loss": 17.322222888469696, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.02894997596741, "training_acc": 53.0, "val_loss": 17.34715849161148, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.06421709060669, "training_acc": 53.0, "val_loss": 17.387504875659943, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.41608738899231, "training_acc": 53.0, "val_loss": 17.450648546218872, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.25127911567688, "training_acc": 53.0, "val_loss": 17.54249334335327, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.57075500488281, "training_acc": 53.0, "val_loss": 17.437194287776947, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.46247911453247, "training_acc": 53.0, "val_loss": 17.3182412981987, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.95596981048584, "training_acc": 53.0, "val_loss": 17.318643629550934, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22612261772156, "training_acc": 48.0, "val_loss": 17.32199788093567, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.084397315979, "training_acc": 58.0, "val_loss": 17.303374409675598, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.91327238082886, "training_acc": 53.0, "val_loss": 17.32480376958847, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.01835751533508, "training_acc": 53.0, "val_loss": 17.368102073669434, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.19875884056091, "training_acc": 53.0, "val_loss": 17.403870820999146, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16425824165344, "training_acc": 53.0, "val_loss": 17.345888912677765, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15615010261536, "training_acc": 53.0, "val_loss": 17.318393290042877, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.9329035282135, "training_acc": 53.0, "val_loss": 17.31885075569153, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.04927015304565, "training_acc": 53.0, "val_loss": 17.321430146694183, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.92328667640686, "training_acc": 53.0, "val_loss": 17.33735054731369, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.91803431510925, "training_acc": 53.0, "val_loss": 17.34580248594284, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.84345579147339, "training_acc": 53.0, "val_loss": 17.33972579240799, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.9141731262207, "training_acc": 53.0, "val_loss": 17.333677411079407, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.87276673316956, "training_acc": 53.0, "val_loss": 17.331479489803314, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.06393814086914, "training_acc": 53.0, "val_loss": 17.332658171653748, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.94596934318542, "training_acc": 61.0, "val_loss": 17.324504256248474, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.88542246818542, "training_acc": 53.0, "val_loss": 17.347165942192078, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.88553190231323, "training_acc": 53.0, "val_loss": 17.357726395130157, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.85782790184021, "training_acc": 53.0, "val_loss": 17.32870489358902, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.60029149055481, "training_acc": 53.0, "val_loss": 17.32179969549179, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.96936583518982, "training_acc": 56.0, "val_loss": 17.327453196048737, "val_acc": 52.0}
