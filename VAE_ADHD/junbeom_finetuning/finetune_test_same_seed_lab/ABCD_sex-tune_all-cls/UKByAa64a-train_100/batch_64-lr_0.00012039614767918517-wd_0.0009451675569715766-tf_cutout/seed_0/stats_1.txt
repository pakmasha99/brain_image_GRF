"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.12070846557617, "training_acc": 47.0, "val_loss": 17.415885627269745, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.4988169670105, "training_acc": 47.0, "val_loss": 17.332670092582703, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.13759183883667, "training_acc": 53.0, "val_loss": 17.372241616249084, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19422245025635, "training_acc": 53.0, "val_loss": 17.381469905376434, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.7560875415802, "training_acc": 53.0, "val_loss": 17.337411642074585, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12982177734375, "training_acc": 53.0, "val_loss": 17.310450971126556, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52256202697754, "training_acc": 45.0, "val_loss": 17.310382425785065, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.64629650115967, "training_acc": 53.0, "val_loss": 17.32102483510971, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16369557380676, "training_acc": 53.0, "val_loss": 17.311671376228333, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.4269495010376, "training_acc": 53.0, "val_loss": 17.328394949436188, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14569091796875, "training_acc": 53.0, "val_loss": 17.36769825220108, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.36382508277893, "training_acc": 53.0, "val_loss": 17.36970990896225, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.24260377883911, "training_acc": 53.0, "val_loss": 17.352943122386932, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16820573806763, "training_acc": 53.0, "val_loss": 17.3141747713089, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18544220924377, "training_acc": 53.0, "val_loss": 17.30988621711731, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14697456359863, "training_acc": 53.0, "val_loss": 17.317460477352142, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17919325828552, "training_acc": 53.0, "val_loss": 17.325668036937714, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27375817298889, "training_acc": 53.0, "val_loss": 17.343981564044952, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.211754322052, "training_acc": 53.0, "val_loss": 17.377181351184845, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.40019226074219, "training_acc": 53.0, "val_loss": 17.34287440776825, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25427603721619, "training_acc": 53.0, "val_loss": 17.3318549990654, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25742030143738, "training_acc": 53.0, "val_loss": 17.309409379959106, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24287724494934, "training_acc": 53.0, "val_loss": 17.324531078338623, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.29370260238647, "training_acc": 53.0, "val_loss": 17.313861846923828, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.50071549415588, "training_acc": 42.0, "val_loss": 17.309311032295227, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15294027328491, "training_acc": 53.0, "val_loss": 17.346465587615967, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19947147369385, "training_acc": 53.0, "val_loss": 17.370910942554474, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.33607983589172, "training_acc": 53.0, "val_loss": 17.354662716388702, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.31703209877014, "training_acc": 53.0, "val_loss": 17.34355539083481, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16263341903687, "training_acc": 53.0, "val_loss": 17.310892045497894, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14511466026306, "training_acc": 53.0, "val_loss": 17.31012761592865, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.44016194343567, "training_acc": 53.0, "val_loss": 17.316272854804993, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19111013412476, "training_acc": 53.0, "val_loss": 17.309613525867462, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19830632209778, "training_acc": 53.0, "val_loss": 17.33558624982834, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17417216300964, "training_acc": 53.0, "val_loss": 17.344382405281067, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2621283531189, "training_acc": 53.0, "val_loss": 17.33303815126419, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16024327278137, "training_acc": 53.0, "val_loss": 17.334116995334625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.17173981666565, "training_acc": 53.0, "val_loss": 17.329096794128418, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.27340340614319, "training_acc": 53.0, "val_loss": 17.323501408100128, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18161392211914, "training_acc": 53.0, "val_loss": 17.309102416038513, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.1533899307251, "training_acc": 53.0, "val_loss": 17.310230433940887, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18380427360535, "training_acc": 53.0, "val_loss": 17.309866845607758, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.18235158920288, "training_acc": 53.0, "val_loss": 17.311272025108337, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14276218414307, "training_acc": 53.0, "val_loss": 17.316028475761414, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1375846862793, "training_acc": 53.0, "val_loss": 17.32875406742096, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15569615364075, "training_acc": 53.0, "val_loss": 17.333118617534637, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.19039058685303, "training_acc": 53.0, "val_loss": 17.3260897397995, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.18102955818176, "training_acc": 53.0, "val_loss": 17.324790358543396, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.37934184074402, "training_acc": 53.0, "val_loss": 17.313170433044434, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13012838363647, "training_acc": 53.0, "val_loss": 17.319968342781067, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13663744926453, "training_acc": 53.0, "val_loss": 17.331835627555847, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14950203895569, "training_acc": 53.0, "val_loss": 17.35101342201233, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.24508619308472, "training_acc": 53.0, "val_loss": 17.37016886472702, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.25086331367493, "training_acc": 53.0, "val_loss": 17.352105677127838, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.40902304649353, "training_acc": 53.0, "val_loss": 17.326045036315918, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.15159106254578, "training_acc": 53.0, "val_loss": 17.3247292637825, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.14580464363098, "training_acc": 53.0, "val_loss": 17.323073744773865, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.14087009429932, "training_acc": 53.0, "val_loss": 17.318999767303467, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13297033309937, "training_acc": 53.0, "val_loss": 17.31313467025757, "val_acc": 52.0}
