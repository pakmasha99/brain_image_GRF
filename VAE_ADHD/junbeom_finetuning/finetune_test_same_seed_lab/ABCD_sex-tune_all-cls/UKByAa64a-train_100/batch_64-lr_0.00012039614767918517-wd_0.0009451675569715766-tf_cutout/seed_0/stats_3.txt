"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.30014133453369, "training_acc": 47.0, "val_loss": 17.33390986919403, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18067479133606, "training_acc": 53.0, "val_loss": 17.332954704761505, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.13493609428406, "training_acc": 53.0, "val_loss": 17.323487997055054, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.44162178039551, "training_acc": 53.0, "val_loss": 17.351451516151428, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15213561058044, "training_acc": 53.0, "val_loss": 17.327770590782166, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.30257153511047, "training_acc": 53.0, "val_loss": 17.31671541929245, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.10336756706238, "training_acc": 53.0, "val_loss": 17.331410944461823, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.74733805656433, "training_acc": 53.0, "val_loss": 17.32369214296341, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24537205696106, "training_acc": 53.0, "val_loss": 17.31085777282715, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23521113395691, "training_acc": 53.0, "val_loss": 17.309771478176117, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.93262195587158, "training_acc": 53.0, "val_loss": 17.322948575019836, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.07071685791016, "training_acc": 53.0, "val_loss": 17.311404645442963, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.273268699646, "training_acc": 54.0, "val_loss": 17.32316017150879, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.26413893699646, "training_acc": 53.0, "val_loss": 17.308834195137024, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20826649665833, "training_acc": 53.0, "val_loss": 17.31863021850586, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.82347583770752, "training_acc": 53.0, "val_loss": 17.35832244157791, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29943823814392, "training_acc": 53.0, "val_loss": 17.318086326122284, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21057653427124, "training_acc": 53.0, "val_loss": 17.310526967048645, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19467949867249, "training_acc": 53.0, "val_loss": 17.312389612197876, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19718194007874, "training_acc": 53.0, "val_loss": 17.311660945415497, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.20409369468689, "training_acc": 53.0, "val_loss": 17.308896780014038, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15279054641724, "training_acc": 53.0, "val_loss": 17.311908304691315, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12651181221008, "training_acc": 53.0, "val_loss": 17.332813143730164, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17216348648071, "training_acc": 53.0, "val_loss": 17.350448668003082, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.27821087837219, "training_acc": 53.0, "val_loss": 17.338454723358154, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18762111663818, "training_acc": 53.0, "val_loss": 17.33679473400116, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.498859167099, "training_acc": 53.0, "val_loss": 17.33805239200592, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.3503201007843, "training_acc": 53.0, "val_loss": 17.309364676475525, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13252568244934, "training_acc": 53.0, "val_loss": 17.308852076530457, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15422487258911, "training_acc": 53.0, "val_loss": 17.310233414173126, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20132517814636, "training_acc": 53.0, "val_loss": 17.310023307800293, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.2235734462738, "training_acc": 53.0, "val_loss": 17.308998107910156, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13935470581055, "training_acc": 53.0, "val_loss": 17.31005758047104, "val_acc": 52.0}
