"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.20674395561218, "training_acc": 53.0, "val_loss": 17.324277758598328, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17391395568848, "training_acc": 53.0, "val_loss": 17.30337291955948, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.01979374885559, "training_acc": 53.0, "val_loss": 17.294982075691223, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.87250065803528, "training_acc": 53.0, "val_loss": 17.313846945762634, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.01351523399353, "training_acc": 53.0, "val_loss": 17.286083102226257, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.99693608283997, "training_acc": 53.0, "val_loss": 17.28033572435379, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.85259938240051, "training_acc": 53.0, "val_loss": 17.27748066186905, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.68145060539246, "training_acc": 53.0, "val_loss": 17.306701838970184, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.79444074630737, "training_acc": 53.0, "val_loss": 17.29961782693863, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.85324025154114, "training_acc": 53.0, "val_loss": 17.29879081249237, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.86972427368164, "training_acc": 53.0, "val_loss": 17.28549152612686, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.76865148544312, "training_acc": 53.0, "val_loss": 17.277343571186066, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.61670780181885, "training_acc": 53.0, "val_loss": 17.272135615348816, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.42052578926086, "training_acc": 53.0, "val_loss": 17.273978888988495, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.51629638671875, "training_acc": 53.0, "val_loss": 17.27609634399414, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.42921543121338, "training_acc": 53.0, "val_loss": 17.272289097309113, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.19858026504517, "training_acc": 53.0, "val_loss": 17.257989943027496, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.32995223999023, "training_acc": 53.0, "val_loss": 17.271529138088226, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.22561931610107, "training_acc": 53.0, "val_loss": 17.25466102361679, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.81238269805908, "training_acc": 53.0, "val_loss": 17.25219637155533, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.8144006729126, "training_acc": 54.0, "val_loss": 17.23754107952118, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.74298596382141, "training_acc": 54.0, "val_loss": 17.236007750034332, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.73309326171875, "training_acc": 53.0, "val_loss": 17.228972911834717, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.57893490791321, "training_acc": 68.0, "val_loss": 17.245212197303772, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.80238270759583, "training_acc": 64.0, "val_loss": 17.255306243896484, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.52156472206116, "training_acc": 56.0, "val_loss": 17.225275933742523, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.90477252006531, "training_acc": 69.0, "val_loss": 17.265598475933075, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.62773275375366, "training_acc": 53.0, "val_loss": 17.285922169685364, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.22106862068176, "training_acc": 61.0, "val_loss": 17.22787469625473, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.00669717788696, "training_acc": 70.0, "val_loss": 17.220087349414825, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.66969060897827, "training_acc": 66.0, "val_loss": 17.24289059638977, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.16332864761353, "training_acc": 57.0, "val_loss": 17.2048419713974, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.51740384101868, "training_acc": 71.0, "val_loss": 17.21789836883545, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.04224705696106, "training_acc": 60.0, "val_loss": 17.25422292947769, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.633136510849, "training_acc": 80.0, "val_loss": 17.192894220352173, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.63390707969666, "training_acc": 78.0, "val_loss": 17.270298302173615, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.96545886993408, "training_acc": 60.0, "val_loss": 17.168046534061432, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.18032264709473, "training_acc": 74.0, "val_loss": 17.13532954454422, "val_acc": 52.0}
{"epoch": 38, "training_loss": 63.847803354263306, "training_acc": 72.0, "val_loss": 17.146076261997223, "val_acc": 52.0}
{"epoch": 39, "training_loss": 64.61372208595276, "training_acc": 68.0, "val_loss": 17.162303626537323, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.16120791435242, "training_acc": 80.0, "val_loss": 17.2687828540802, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.24266934394836, "training_acc": 64.0, "val_loss": 17.100246250629425, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.85004496574402, "training_acc": 79.0, "val_loss": 17.185547947883606, "val_acc": 52.0}
{"epoch": 43, "training_loss": 62.95303153991699, "training_acc": 65.0, "val_loss": 17.111724615097046, "val_acc": 52.0}
{"epoch": 44, "training_loss": 61.904210329055786, "training_acc": 86.0, "val_loss": 17.174537479877472, "val_acc": 52.0}
{"epoch": 45, "training_loss": 61.91342115402222, "training_acc": 70.0, "val_loss": 17.170287668704987, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.72453022003174, "training_acc": 86.0, "val_loss": 17.23540723323822, "val_acc": 52.0}
{"epoch": 47, "training_loss": 63.59410095214844, "training_acc": 62.0, "val_loss": 16.9811874628067, "val_acc": 52.0}
{"epoch": 48, "training_loss": 60.455005168914795, "training_acc": 86.0, "val_loss": 17.12687611579895, "val_acc": 52.0}
{"epoch": 49, "training_loss": 58.330225706100464, "training_acc": 90.0, "val_loss": 17.45302528142929, "val_acc": 52.0}
{"epoch": 50, "training_loss": 62.1960985660553, "training_acc": 67.0, "val_loss": 17.25786179304123, "val_acc": 52.0}
{"epoch": 51, "training_loss": 60.737876415252686, "training_acc": 86.0, "val_loss": 17.286567389965057, "val_acc": 52.0}
{"epoch": 52, "training_loss": 61.1717574596405, "training_acc": 68.0, "val_loss": 17.009101808071136, "val_acc": 52.0}
{"epoch": 53, "training_loss": 59.77212834358215, "training_acc": 81.0, "val_loss": 17.116396129131317, "val_acc": 52.0}
{"epoch": 54, "training_loss": 60.66849112510681, "training_acc": 78.0, "val_loss": 17.366035282611847, "val_acc": 52.0}
{"epoch": 55, "training_loss": 60.07648539543152, "training_acc": 74.0, "val_loss": 17.025676369667053, "val_acc": 52.0}
{"epoch": 56, "training_loss": 57.46712613105774, "training_acc": 87.0, "val_loss": 17.155179381370544, "val_acc": 52.0}
{"epoch": 57, "training_loss": 57.790879249572754, "training_acc": 82.0, "val_loss": 17.130933701992035, "val_acc": 52.0}
{"epoch": 58, "training_loss": 58.392231941223145, "training_acc": 86.0, "val_loss": 17.058201134204865, "val_acc": 52.0}
{"epoch": 59, "training_loss": 57.339927196502686, "training_acc": 82.0, "val_loss": 16.875098645687103, "val_acc": 52.0}
{"epoch": 60, "training_loss": 55.616938829422, "training_acc": 90.0, "val_loss": 16.845279932022095, "val_acc": 52.0}
{"epoch": 61, "training_loss": 56.79798603057861, "training_acc": 85.0, "val_loss": 16.87536984682083, "val_acc": 52.0}
{"epoch": 62, "training_loss": 54.45686864852905, "training_acc": 94.0, "val_loss": 17.253263294696808, "val_acc": 52.0}
{"epoch": 63, "training_loss": 56.088459730148315, "training_acc": 86.0, "val_loss": 17.124076187610626, "val_acc": 52.0}
{"epoch": 64, "training_loss": 55.10133099555969, "training_acc": 87.0, "val_loss": 16.802531480789185, "val_acc": 52.0}
{"epoch": 65, "training_loss": 53.738919496536255, "training_acc": 90.0, "val_loss": 16.949717700481415, "val_acc": 52.0}
{"epoch": 66, "training_loss": 53.96656823158264, "training_acc": 88.0, "val_loss": 17.06928014755249, "val_acc": 52.0}
{"epoch": 67, "training_loss": 53.64445233345032, "training_acc": 94.0, "val_loss": 16.908958554267883, "val_acc": 52.0}
{"epoch": 68, "training_loss": 52.89187979698181, "training_acc": 91.0, "val_loss": 16.827139258384705, "val_acc": 52.0}
{"epoch": 69, "training_loss": 54.14558291435242, "training_acc": 91.0, "val_loss": 17.208658158779144, "val_acc": 52.0}
{"epoch": 70, "training_loss": 52.38990330696106, "training_acc": 90.0, "val_loss": 17.50968098640442, "val_acc": 48.0}
{"epoch": 71, "training_loss": 53.70008206367493, "training_acc": 91.0, "val_loss": 16.999681293964386, "val_acc": 52.0}
{"epoch": 72, "training_loss": 50.80415403842926, "training_acc": 95.0, "val_loss": 17.086397111415863, "val_acc": 56.0}
{"epoch": 73, "training_loss": 51.07366240024567, "training_acc": 95.0, "val_loss": 17.106029391288757, "val_acc": 52.0}
{"epoch": 74, "training_loss": 49.94626438617706, "training_acc": 94.0, "val_loss": 16.92402958869934, "val_acc": 56.0}
{"epoch": 75, "training_loss": 49.83014535903931, "training_acc": 93.0, "val_loss": 17.0312762260437, "val_acc": 52.0}
{"epoch": 76, "training_loss": 49.40949511528015, "training_acc": 95.0, "val_loss": 16.86769425868988, "val_acc": 52.0}
{"epoch": 77, "training_loss": 48.77572786808014, "training_acc": 94.0, "val_loss": 16.851766407489777, "val_acc": 56.0}
{"epoch": 78, "training_loss": 48.37682354450226, "training_acc": 97.0, "val_loss": 17.00129210948944, "val_acc": 52.0}
{"epoch": 79, "training_loss": 49.23760998249054, "training_acc": 94.0, "val_loss": 17.30613261461258, "val_acc": 56.0}
{"epoch": 80, "training_loss": 50.93179166316986, "training_acc": 89.0, "val_loss": 16.874030232429504, "val_acc": 52.0}
{"epoch": 81, "training_loss": 47.47021520137787, "training_acc": 96.0, "val_loss": 16.94866567850113, "val_acc": 52.0}
{"epoch": 82, "training_loss": 47.908690094947815, "training_acc": 92.0, "val_loss": 17.436210811138153, "val_acc": 64.0}
{"epoch": 83, "training_loss": 49.19693911075592, "training_acc": 92.0, "val_loss": 17.16076284646988, "val_acc": 52.0}
