"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.19974946975708, "training_acc": 53.0, "val_loss": 17.34042763710022, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.24678087234497, "training_acc": 53.0, "val_loss": 17.314094305038452, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1002721786499, "training_acc": 53.0, "val_loss": 17.291085422039032, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.07984662055969, "training_acc": 53.0, "val_loss": 17.31816828250885, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14025473594666, "training_acc": 53.0, "val_loss": 17.282859981060028, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.01866292953491, "training_acc": 53.0, "val_loss": 17.324241995811462, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.9121630191803, "training_acc": 53.0, "val_loss": 17.321982979774475, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.87064480781555, "training_acc": 53.0, "val_loss": 17.328058183193207, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.87738347053528, "training_acc": 53.0, "val_loss": 17.298544943332672, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.91758608818054, "training_acc": 53.0, "val_loss": 17.311176657676697, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.82297968864441, "training_acc": 53.0, "val_loss": 17.28525161743164, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.64541268348694, "training_acc": 53.0, "val_loss": 17.282548546791077, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.74073004722595, "training_acc": 53.0, "val_loss": 17.251211404800415, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.69801640510559, "training_acc": 53.0, "val_loss": 17.241111397743225, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.68424582481384, "training_acc": 53.0, "val_loss": 17.249464988708496, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.42627453804016, "training_acc": 53.0, "val_loss": 17.25974977016449, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.49322247505188, "training_acc": 53.0, "val_loss": 17.258372902870178, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.46482419967651, "training_acc": 53.0, "val_loss": 17.268677055835724, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.28021717071533, "training_acc": 53.0, "val_loss": 17.258569598197937, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.17039036750793, "training_acc": 53.0, "val_loss": 17.263275384902954, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.58412289619446, "training_acc": 53.0, "val_loss": 17.30262190103531, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.5264961719513, "training_acc": 53.0, "val_loss": 17.28648692369461, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.60047650337219, "training_acc": 53.0, "val_loss": 17.246916890144348, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.89508986473083, "training_acc": 53.0, "val_loss": 17.35117733478546, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.54631066322327, "training_acc": 53.0, "val_loss": 17.329517006874084, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.84566044807434, "training_acc": 53.0, "val_loss": 17.305701971054077, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.3600115776062, "training_acc": 53.0, "val_loss": 17.296767234802246, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.05323052406311, "training_acc": 53.0, "val_loss": 17.280003428459167, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.78237080574036, "training_acc": 53.0, "val_loss": 17.265117168426514, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.69329118728638, "training_acc": 53.0, "val_loss": 17.2458678483963, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.15725421905518, "training_acc": 53.0, "val_loss": 17.263366281986237, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.37049102783203, "training_acc": 55.0, "val_loss": 17.32686758041382, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.86574912071228, "training_acc": 66.0, "val_loss": 17.295917868614197, "val_acc": 52.0}
