"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.58269095420837, "training_acc": 53.0, "val_loss": 17.484481632709503, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.50071334838867, "training_acc": 53.0, "val_loss": 17.450828850269318, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.46297430992126, "training_acc": 53.0, "val_loss": 17.46150106191635, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.45672535896301, "training_acc": 53.0, "val_loss": 17.466308176517487, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.28826236724854, "training_acc": 53.0, "val_loss": 17.4393892288208, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.39038968086243, "training_acc": 53.0, "val_loss": 17.411381006240845, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21494317054749, "training_acc": 53.0, "val_loss": 17.410770058631897, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15936827659607, "training_acc": 53.0, "val_loss": 17.40855723619461, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02253127098083, "training_acc": 53.0, "val_loss": 17.393486201763153, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.02068758010864, "training_acc": 53.0, "val_loss": 17.39531308412552, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.96474003791809, "training_acc": 53.0, "val_loss": 17.408645153045654, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.82953476905823, "training_acc": 53.0, "val_loss": 17.3716202378273, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.72193217277527, "training_acc": 53.0, "val_loss": 17.34069436788559, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.56059622764587, "training_acc": 53.0, "val_loss": 17.402152717113495, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.63538551330566, "training_acc": 53.0, "val_loss": 17.426249384880066, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.80575180053711, "training_acc": 53.0, "val_loss": 17.427745461463928, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.91606330871582, "training_acc": 53.0, "val_loss": 17.3868328332901, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.72881174087524, "training_acc": 53.0, "val_loss": 17.297454178333282, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.78284215927124, "training_acc": 53.0, "val_loss": 17.270034551620483, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.54415845870972, "training_acc": 53.0, "val_loss": 17.254634201526642, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.67923188209534, "training_acc": 53.0, "val_loss": 17.367255687713623, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.30732870101929, "training_acc": 53.0, "val_loss": 17.41448938846588, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.16609311103821, "training_acc": 53.0, "val_loss": 17.39499419927597, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.97197318077087, "training_acc": 53.0, "val_loss": 17.441219091415405, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.94462752342224, "training_acc": 53.0, "val_loss": 17.47819036245346, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.36544990539551, "training_acc": 53.0, "val_loss": 17.48470664024353, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.48163151741028, "training_acc": 58.0, "val_loss": 17.388977110385895, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.73969388008118, "training_acc": 66.0, "val_loss": 17.427663505077362, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.13641405105591, "training_acc": 58.0, "val_loss": 17.532306909561157, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.8352324962616, "training_acc": 55.0, "val_loss": 17.49201864004135, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.51718711853027, "training_acc": 61.0, "val_loss": 17.601734399795532, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.62801766395569, "training_acc": 56.0, "val_loss": 17.54574030637741, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.49339413642883, "training_acc": 61.0, "val_loss": 17.61460304260254, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.51964569091797, "training_acc": 56.0, "val_loss": 17.69092082977295, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.46012234687805, "training_acc": 64.0, "val_loss": 17.678916454315186, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.53472518920898, "training_acc": 60.0, "val_loss": 17.647133767604828, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.05645036697388, "training_acc": 71.0, "val_loss": 17.414458096027374, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.19155025482178, "training_acc": 76.0, "val_loss": 17.735539376735687, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.33362913131714, "training_acc": 55.0, "val_loss": 17.43473708629608, "val_acc": 52.0}
