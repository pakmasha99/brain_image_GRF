"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23526668548584, "training_acc": 53.0, "val_loss": 17.379435896873474, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22137355804443, "training_acc": 53.0, "val_loss": 17.377182841300964, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22204971313477, "training_acc": 53.0, "val_loss": 17.375892400741577, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22629570960999, "training_acc": 53.0, "val_loss": 17.374327778816223, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.29245066642761, "training_acc": 53.0, "val_loss": 17.37164855003357, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08755040168762, "training_acc": 53.0, "val_loss": 17.362186312675476, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13750576972961, "training_acc": 53.0, "val_loss": 17.352527379989624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.0946102142334, "training_acc": 53.0, "val_loss": 17.351442575454712, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10481262207031, "training_acc": 53.0, "val_loss": 17.352859675884247, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.99795746803284, "training_acc": 53.0, "val_loss": 17.35447645187378, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.9691846370697, "training_acc": 53.0, "val_loss": 17.357642948627472, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.90179705619812, "training_acc": 53.0, "val_loss": 17.358912527561188, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.93196487426758, "training_acc": 53.0, "val_loss": 17.357808351516724, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.02737069129944, "training_acc": 53.0, "val_loss": 17.352348566055298, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.96560287475586, "training_acc": 53.0, "val_loss": 17.356112599372864, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.9002845287323, "training_acc": 53.0, "val_loss": 17.357131838798523, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.87326169013977, "training_acc": 53.0, "val_loss": 17.350517213344574, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.90732526779175, "training_acc": 53.0, "val_loss": 17.353588342666626, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.93568921089172, "training_acc": 53.0, "val_loss": 17.364299297332764, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.854900598526, "training_acc": 53.0, "val_loss": 17.367495596408844, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.83674168586731, "training_acc": 53.0, "val_loss": 17.367473244667053, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.75959396362305, "training_acc": 53.0, "val_loss": 17.368711531162262, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.79312109947205, "training_acc": 53.0, "val_loss": 17.370277643203735, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.64450812339783, "training_acc": 53.0, "val_loss": 17.376545071601868, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.63404202461243, "training_acc": 53.0, "val_loss": 17.373943328857422, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.78445029258728, "training_acc": 53.0, "val_loss": 17.374932765960693, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.59249877929688, "training_acc": 53.0, "val_loss": 17.382118105888367, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.69837689399719, "training_acc": 53.0, "val_loss": 17.40090548992157, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.61431884765625, "training_acc": 53.0, "val_loss": 17.411068081855774, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.5360426902771, "training_acc": 53.0, "val_loss": 17.41945594549179, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.68744969367981, "training_acc": 53.0, "val_loss": 17.422614991664886, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.55216717720032, "training_acc": 53.0, "val_loss": 17.423813045024872, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.62866997718811, "training_acc": 53.0, "val_loss": 17.41977483034134, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.77208805084229, "training_acc": 53.0, "val_loss": 17.41168349981308, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.51173448562622, "training_acc": 53.0, "val_loss": 17.403113842010498, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.53052759170532, "training_acc": 53.0, "val_loss": 17.403976619243622, "val_acc": 52.0}
