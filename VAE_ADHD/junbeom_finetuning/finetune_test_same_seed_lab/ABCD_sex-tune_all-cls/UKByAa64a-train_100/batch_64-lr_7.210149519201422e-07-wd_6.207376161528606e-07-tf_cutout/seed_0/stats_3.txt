"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.21713948249817, "training_acc": 53.0, "val_loss": 17.34723299741745, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15750050544739, "training_acc": 53.0, "val_loss": 17.345216870307922, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1911096572876, "training_acc": 53.0, "val_loss": 17.346179485321045, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20205044746399, "training_acc": 53.0, "val_loss": 17.343032360076904, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18244481086731, "training_acc": 53.0, "val_loss": 17.3446923494339, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08470582962036, "training_acc": 53.0, "val_loss": 17.347076535224915, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09794330596924, "training_acc": 53.0, "val_loss": 17.351317405700684, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09064555168152, "training_acc": 53.0, "val_loss": 17.348189651966095, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04903793334961, "training_acc": 53.0, "val_loss": 17.343635857105255, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.99818730354309, "training_acc": 53.0, "val_loss": 17.34045147895813, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.94852924346924, "training_acc": 53.0, "val_loss": 17.340829968452454, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.88607358932495, "training_acc": 53.0, "val_loss": 17.341697216033936, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.00722932815552, "training_acc": 53.0, "val_loss": 17.34367460012436, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08291840553284, "training_acc": 53.0, "val_loss": 17.344851791858673, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.93689012527466, "training_acc": 53.0, "val_loss": 17.345544695854187, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.97774481773376, "training_acc": 53.0, "val_loss": 17.347365617752075, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.95916819572449, "training_acc": 53.0, "val_loss": 17.350652813911438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.84846806526184, "training_acc": 53.0, "val_loss": 17.351751029491425, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.95193243026733, "training_acc": 53.0, "val_loss": 17.354099452495575, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.79979538917542, "training_acc": 53.0, "val_loss": 17.355743050575256, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.9416356086731, "training_acc": 53.0, "val_loss": 17.35589951276779, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.02911138534546, "training_acc": 53.0, "val_loss": 17.35365241765976, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.86731457710266, "training_acc": 53.0, "val_loss": 17.350299656391144, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.80594086647034, "training_acc": 53.0, "val_loss": 17.347414791584015, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.63141059875488, "training_acc": 53.0, "val_loss": 17.346568405628204, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.80127811431885, "training_acc": 53.0, "val_loss": 17.346088588237762, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.6645667552948, "training_acc": 53.0, "val_loss": 17.344951629638672, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.90566372871399, "training_acc": 53.0, "val_loss": 17.34537035226822, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.68951725959778, "training_acc": 53.0, "val_loss": 17.344947159290314, "val_acc": 52.0}
