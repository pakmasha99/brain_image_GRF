"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.02825856208801, "training_acc": 53.0, "val_loss": 17.373454570770264, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18225860595703, "training_acc": 53.0, "val_loss": 17.372895777225494, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.09573864936829, "training_acc": 53.0, "val_loss": 17.367053031921387, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09988403320312, "training_acc": 53.0, "val_loss": 17.364966869354248, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.00624895095825, "training_acc": 53.0, "val_loss": 17.36452281475067, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.99765849113464, "training_acc": 53.0, "val_loss": 17.360714077949524, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11517453193665, "training_acc": 53.0, "val_loss": 17.352651059627533, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.98418688774109, "training_acc": 53.0, "val_loss": 17.350798845291138, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.09415054321289, "training_acc": 53.0, "val_loss": 17.347757518291473, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15726137161255, "training_acc": 53.0, "val_loss": 17.347852885723114, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.87923216819763, "training_acc": 53.0, "val_loss": 17.350666224956512, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10161542892456, "training_acc": 53.0, "val_loss": 17.34931468963623, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.96814060211182, "training_acc": 53.0, "val_loss": 17.348606884479523, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.88981318473816, "training_acc": 53.0, "val_loss": 17.349204421043396, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.00954341888428, "training_acc": 53.0, "val_loss": 17.349843680858612, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.9754638671875, "training_acc": 53.0, "val_loss": 17.3514723777771, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.91372060775757, "training_acc": 53.0, "val_loss": 17.3541858792305, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.88108015060425, "training_acc": 53.0, "val_loss": 17.35590696334839, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.89482498168945, "training_acc": 53.0, "val_loss": 17.357254028320312, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.78622913360596, "training_acc": 53.0, "val_loss": 17.359301447868347, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.75366187095642, "training_acc": 53.0, "val_loss": 17.361512780189514, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.81235814094543, "training_acc": 53.0, "val_loss": 17.36118793487549, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.82318472862244, "training_acc": 53.0, "val_loss": 17.357754707336426, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.91968441009521, "training_acc": 53.0, "val_loss": 17.355820536613464, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.79462027549744, "training_acc": 53.0, "val_loss": 17.352358996868134, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.62860035896301, "training_acc": 53.0, "val_loss": 17.350493371486664, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.87141299247742, "training_acc": 53.0, "val_loss": 17.351002991199493, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.86016941070557, "training_acc": 53.0, "val_loss": 17.351172864437103, "val_acc": 52.0}
