"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.81877064704895, "training_acc": 53.0, "val_loss": 18.24856549501419, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.34136319160461, "training_acc": 53.0, "val_loss": 17.369291186332703, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.40308809280396, "training_acc": 49.0, "val_loss": 17.30963885784149, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.65889739990234, "training_acc": 47.0, "val_loss": 17.328786849975586, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.57245302200317, "training_acc": 53.0, "val_loss": 17.403006553649902, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.40924525260925, "training_acc": 53.0, "val_loss": 17.38179326057434, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.25348401069641, "training_acc": 53.0, "val_loss": 17.308887839317322, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11905264854431, "training_acc": 53.0, "val_loss": 17.357516288757324, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.4770348072052, "training_acc": 47.0, "val_loss": 17.32749491930008, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19959473609924, "training_acc": 53.0, "val_loss": 17.334525287151337, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.55838751792908, "training_acc": 53.0, "val_loss": 17.423509061336517, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.35561800003052, "training_acc": 53.0, "val_loss": 17.3202246427536, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.96353507041931, "training_acc": 41.0, "val_loss": 17.314395308494568, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.50031924247742, "training_acc": 53.0, "val_loss": 17.31986403465271, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13938975334167, "training_acc": 53.0, "val_loss": 17.318490147590637, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.38359951972961, "training_acc": 53.0, "val_loss": 17.314860224723816, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14635443687439, "training_acc": 53.0, "val_loss": 17.345401644706726, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20145535469055, "training_acc": 53.0, "val_loss": 17.34713762998581, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21454763412476, "training_acc": 53.0, "val_loss": 17.318768799304962, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21260571479797, "training_acc": 53.0, "val_loss": 17.313194274902344, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.38758778572083, "training_acc": 45.0, "val_loss": 17.31170266866684, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25080609321594, "training_acc": 53.0, "val_loss": 17.328324913978577, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22204804420471, "training_acc": 53.0, "val_loss": 17.351077497005463, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19499635696411, "training_acc": 53.0, "val_loss": 17.323344945907593, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13859486579895, "training_acc": 53.0, "val_loss": 17.308902740478516, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18924069404602, "training_acc": 53.0, "val_loss": 17.309531569480896, "val_acc": 52.0}
