"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15228199958801, "training_acc": 53.0, "val_loss": 17.407293617725372, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.84696698188782, "training_acc": 53.0, "val_loss": 18.053920567035675, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.29439568519592, "training_acc": 45.0, "val_loss": 17.35997349023819, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.96227598190308, "training_acc": 47.0, "val_loss": 17.347605526447296, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.91513800621033, "training_acc": 53.0, "val_loss": 17.439673840999603, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33942866325378, "training_acc": 53.0, "val_loss": 17.30872094631195, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11810326576233, "training_acc": 53.0, "val_loss": 17.356227338314056, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.50488543510437, "training_acc": 47.0, "val_loss": 17.320193350315094, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1607141494751, "training_acc": 53.0, "val_loss": 17.340169847011566, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.35790181159973, "training_acc": 53.0, "val_loss": 17.408938705921173, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.39569854736328, "training_acc": 53.0, "val_loss": 17.477083206176758, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.8045129776001, "training_acc": 53.0, "val_loss": 17.368243634700775, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.89992165565491, "training_acc": 53.0, "val_loss": 17.318813502788544, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.25984740257263, "training_acc": 53.0, "val_loss": 17.317910492420197, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.22874855995178, "training_acc": 53.0, "val_loss": 17.308731377124786, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.38440442085266, "training_acc": 53.0, "val_loss": 17.321106791496277, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16316437721252, "training_acc": 53.0, "val_loss": 17.310962080955505, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14992094039917, "training_acc": 53.0, "val_loss": 17.311963438987732, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17354273796082, "training_acc": 53.0, "val_loss": 17.315661907196045, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19669270515442, "training_acc": 53.0, "val_loss": 17.31492131948471, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15204167366028, "training_acc": 53.0, "val_loss": 17.32896715402603, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22525191307068, "training_acc": 53.0, "val_loss": 17.350859940052032, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2181248664856, "training_acc": 53.0, "val_loss": 17.320197820663452, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13764452934265, "training_acc": 53.0, "val_loss": 17.31122136116028, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2011251449585, "training_acc": 53.0, "val_loss": 17.315199971199036, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.26784157752991, "training_acc": 53.0, "val_loss": 17.30871945619583, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15532636642456, "training_acc": 53.0, "val_loss": 17.337515950202942, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.35999870300293, "training_acc": 53.0, "val_loss": 17.364685237407684, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.49292707443237, "training_acc": 53.0, "val_loss": 17.425715923309326, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.45889163017273, "training_acc": 53.0, "val_loss": 17.527593672275543, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.78378653526306, "training_acc": 53.0, "val_loss": 17.424659430980682, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.6817512512207, "training_acc": 53.0, "val_loss": 17.309415340423584, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.11842322349548, "training_acc": 53.0, "val_loss": 17.31899082660675, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.45176243782043, "training_acc": 45.0, "val_loss": 17.325298488140106, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.21887969970703, "training_acc": 53.0, "val_loss": 17.310455441474915, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.09277486801147, "training_acc": 53.0, "val_loss": 17.368049919605255, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.23509383201599, "training_acc": 53.0, "val_loss": 17.42035299539566, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.53619813919067, "training_acc": 53.0, "val_loss": 17.420165240764618, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.40241169929504, "training_acc": 53.0, "val_loss": 17.32805222272873, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.28255009651184, "training_acc": 53.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17310047149658, "training_acc": 53.0, "val_loss": 17.31048673391342, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.27327394485474, "training_acc": 53.0, "val_loss": 17.308783531188965, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.21265649795532, "training_acc": 53.0, "val_loss": 17.328286170959473, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16346716880798, "training_acc": 53.0, "val_loss": 17.34376847743988, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.19277667999268, "training_acc": 53.0, "val_loss": 17.33662337064743, "val_acc": 52.0}
