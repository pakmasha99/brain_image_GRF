"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.16785430908203, "training_acc": 53.0, "val_loss": 17.344188690185547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.12789559364319, "training_acc": 53.0, "val_loss": 17.351655662059784, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.0063784122467, "training_acc": 53.0, "val_loss": 17.318496108055115, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.01786756515503, "training_acc": 53.0, "val_loss": 17.336344718933105, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.97179293632507, "training_acc": 53.0, "val_loss": 17.352893948554993, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.95847535133362, "training_acc": 53.0, "val_loss": 17.322131991386414, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.89745545387268, "training_acc": 53.0, "val_loss": 17.361362278461456, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.79285550117493, "training_acc": 53.0, "val_loss": 17.38019287586212, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.72145628929138, "training_acc": 53.0, "val_loss": 17.399074137210846, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.62772011756897, "training_acc": 53.0, "val_loss": 17.42151230573654, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.51501703262329, "training_acc": 53.0, "val_loss": 17.435722053050995, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.5284469127655, "training_acc": 53.0, "val_loss": 17.413175106048584, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.07107162475586, "training_acc": 53.0, "val_loss": 17.452986538410187, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.36748433113098, "training_acc": 53.0, "val_loss": 17.390404641628265, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.20225858688354, "training_acc": 53.0, "val_loss": 17.46162176132202, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.80257821083069, "training_acc": 53.0, "val_loss": 17.459475994110107, "val_acc": 52.0}
{"epoch": 16, "training_loss": 66.94679570198059, "training_acc": 55.0, "val_loss": 17.40662008523941, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.93323254585266, "training_acc": 62.0, "val_loss": 17.443951964378357, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.134192943573, "training_acc": 57.0, "val_loss": 17.46547669172287, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.55534052848816, "training_acc": 56.0, "val_loss": 17.395806312561035, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.25733685493469, "training_acc": 60.0, "val_loss": 17.301063239574432, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.3399167060852, "training_acc": 72.0, "val_loss": 17.513608932495117, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.87037301063538, "training_acc": 53.0, "val_loss": 17.43225008249283, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.27885031700134, "training_acc": 59.0, "val_loss": 17.40298867225647, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.04251027107239, "training_acc": 69.0, "val_loss": 17.430415749549866, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.01177716255188, "training_acc": 73.0, "val_loss": 17.571833729743958, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.05629587173462, "training_acc": 54.0, "val_loss": 17.648154497146606, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.2060329914093, "training_acc": 53.0, "val_loss": 17.48024970293045, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.04962134361267, "training_acc": 64.0, "val_loss": 17.43074357509613, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.06759691238403, "training_acc": 73.0, "val_loss": 17.49963015317917, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.0673041343689, "training_acc": 70.0, "val_loss": 17.53731071949005, "val_acc": 52.0}
{"epoch": 31, "training_loss": 64.40064191818237, "training_acc": 77.0, "val_loss": 17.728662490844727, "val_acc": 52.0}
{"epoch": 32, "training_loss": 63.796684980392456, "training_acc": 67.0, "val_loss": 17.515145242214203, "val_acc": 52.0}
{"epoch": 33, "training_loss": 63.849228382110596, "training_acc": 77.0, "val_loss": 18.162362277507782, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.65042519569397, "training_acc": 64.0, "val_loss": 18.0937260389328, "val_acc": 52.0}
{"epoch": 35, "training_loss": 63.09324240684509, "training_acc": 69.0, "val_loss": 17.53055304288864, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.40343594551086, "training_acc": 68.0, "val_loss": 17.45445728302002, "val_acc": 52.0}
{"epoch": 37, "training_loss": 62.0454843044281, "training_acc": 75.0, "val_loss": 17.6869735121727, "val_acc": 52.0}
{"epoch": 38, "training_loss": 58.473166942596436, "training_acc": 88.0, "val_loss": 18.44177395105362, "val_acc": 52.0}
{"epoch": 39, "training_loss": 61.16800832748413, "training_acc": 71.0, "val_loss": 17.454583942890167, "val_acc": 52.0}
