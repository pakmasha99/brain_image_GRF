"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.96590423583984, "training_acc": 55.0, "val_loss": 17.2942653298378, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.14630842208862, "training_acc": 57.0, "val_loss": 17.29394942522049, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.39410853385925, "training_acc": 48.0, "val_loss": 17.293380200862885, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.33430576324463, "training_acc": 51.0, "val_loss": 17.293064296245575, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.29349446296692, "training_acc": 53.0, "val_loss": 17.29264259338379, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.34217190742493, "training_acc": 53.0, "val_loss": 17.292433977127075, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28711700439453, "training_acc": 54.0, "val_loss": 17.29215234518051, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2297203540802, "training_acc": 53.0, "val_loss": 17.291685938835144, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.48297452926636, "training_acc": 48.0, "val_loss": 17.291174829006195, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.59806489944458, "training_acc": 46.0, "val_loss": 17.290744185447693, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17110681533813, "training_acc": 54.0, "val_loss": 17.290563881397247, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29767179489136, "training_acc": 49.0, "val_loss": 17.290273308753967, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.27264881134033, "training_acc": 51.0, "val_loss": 17.289958894252777, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.38694334030151, "training_acc": 48.0, "val_loss": 17.289967834949493, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.028963804245, "training_acc": 54.0, "val_loss": 17.28985607624054, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.37105107307434, "training_acc": 51.0, "val_loss": 17.289647459983826, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.5162570476532, "training_acc": 48.0, "val_loss": 17.289413511753082, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.29376697540283, "training_acc": 51.0, "val_loss": 17.289626598358154, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29159283638, "training_acc": 54.0, "val_loss": 17.28963404893875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.27655982971191, "training_acc": 51.0, "val_loss": 17.28970855474472, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.26138663291931, "training_acc": 53.0, "val_loss": 17.289794981479645, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22555923461914, "training_acc": 54.0, "val_loss": 17.28987842798233, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.96062850952148, "training_acc": 55.0, "val_loss": 17.289935052394867, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.32558751106262, "training_acc": 52.0, "val_loss": 17.289885878562927, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.32563877105713, "training_acc": 52.0, "val_loss": 17.289794981479645, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.24327230453491, "training_acc": 51.0, "val_loss": 17.290088534355164, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18079495429993, "training_acc": 53.0, "val_loss": 17.290306091308594, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.33849382400513, "training_acc": 51.0, "val_loss": 17.290328443050385, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.45222306251526, "training_acc": 51.0, "val_loss": 17.290636897087097, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.07346391677856, "training_acc": 52.0, "val_loss": 17.29099452495575, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.33293437957764, "training_acc": 53.0, "val_loss": 17.291152477264404, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.2504506111145, "training_acc": 52.0, "val_loss": 17.291565239429474, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15533900260925, "training_acc": 53.0, "val_loss": 17.291763424873352, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.35864996910095, "training_acc": 51.0, "val_loss": 17.292262613773346, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.20840764045715, "training_acc": 50.0, "val_loss": 17.292411625385284, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.25271582603455, "training_acc": 52.0, "val_loss": 17.292743921279907, "val_acc": 52.0}
