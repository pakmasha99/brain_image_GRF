"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.5398805141449, "training_acc": 47.0, "val_loss": 17.559367418289185, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.68715381622314, "training_acc": 47.0, "val_loss": 17.553073167800903, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.98953652381897, "training_acc": 47.0, "val_loss": 17.320522665977478, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.59128975868225, "training_acc": 53.0, "val_loss": 17.318814992904663, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33680367469788, "training_acc": 53.0, "val_loss": 17.312970757484436, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.5051121711731, "training_acc": 43.0, "val_loss": 17.311780154705048, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09362030029297, "training_acc": 53.0, "val_loss": 17.357437312602997, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.92944836616516, "training_acc": 53.0, "val_loss": 17.353978753089905, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.64063596725464, "training_acc": 53.0, "val_loss": 17.31451451778412, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15137672424316, "training_acc": 53.0, "val_loss": 17.32294112443924, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20626139640808, "training_acc": 53.0, "val_loss": 17.319993674755096, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27846956253052, "training_acc": 53.0, "val_loss": 17.331835627555847, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1646842956543, "training_acc": 53.0, "val_loss": 17.36791729927063, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.27274990081787, "training_acc": 53.0, "val_loss": 17.353837192058563, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.228351354599, "training_acc": 53.0, "val_loss": 17.33122169971466, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15226340293884, "training_acc": 53.0, "val_loss": 17.30983704328537, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1821072101593, "training_acc": 53.0, "val_loss": 17.309127748012543, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19642639160156, "training_acc": 53.0, "val_loss": 17.309851944446564, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10934281349182, "training_acc": 53.0, "val_loss": 17.33301877975464, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16831159591675, "training_acc": 53.0, "val_loss": 17.35154837369919, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.20918869972229, "training_acc": 53.0, "val_loss": 17.333564162254333, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17497301101685, "training_acc": 53.0, "val_loss": 17.31904149055481, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12507486343384, "training_acc": 53.0, "val_loss": 17.31042116880417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15890192985535, "training_acc": 53.0, "val_loss": 17.309273779392242, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14331340789795, "training_acc": 53.0, "val_loss": 17.312705516815186, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.39780807495117, "training_acc": 53.0, "val_loss": 17.32379049062729, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13497591018677, "training_acc": 53.0, "val_loss": 17.310291528701782, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14650273323059, "training_acc": 53.0, "val_loss": 17.309269309043884, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18941736221313, "training_acc": 53.0, "val_loss": 17.30904132127762, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20545673370361, "training_acc": 53.0, "val_loss": 17.309224605560303, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15305733680725, "training_acc": 53.0, "val_loss": 17.31102466583252, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18888473510742, "training_acc": 53.0, "val_loss": 17.309096455574036, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15870666503906, "training_acc": 53.0, "val_loss": 17.312222719192505, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13668870925903, "training_acc": 53.0, "val_loss": 17.33238250017166, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19195866584778, "training_acc": 53.0, "val_loss": 17.37561970949173, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.34051370620728, "training_acc": 53.0, "val_loss": 17.370732128620148, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.20439267158508, "training_acc": 53.0, "val_loss": 17.324450612068176, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14283585548401, "training_acc": 53.0, "val_loss": 17.309048771858215, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.26439213752747, "training_acc": 53.0, "val_loss": 17.315499484539032, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.27225995063782, "training_acc": 53.0, "val_loss": 17.309291660785675, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16834568977356, "training_acc": 53.0, "val_loss": 17.309056222438812, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.26190257072449, "training_acc": 53.0, "val_loss": 17.312723398208618, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.32922148704529, "training_acc": 53.0, "val_loss": 17.33999252319336, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1818118095398, "training_acc": 53.0, "val_loss": 17.33432114124298, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.30039954185486, "training_acc": 53.0, "val_loss": 17.32141673564911, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1448221206665, "training_acc": 53.0, "val_loss": 17.32649803161621, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15242052078247, "training_acc": 53.0, "val_loss": 17.323918640613556, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16016292572021, "training_acc": 53.0, "val_loss": 17.31763184070587, "val_acc": 52.0}
