"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.19035983085632, "training_acc": 53.0, "val_loss": 17.319896817207336, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.07362937927246, "training_acc": 53.0, "val_loss": 17.318911850452423, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50243878364563, "training_acc": 53.0, "val_loss": 17.346961796283722, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.23193287849426, "training_acc": 53.0, "val_loss": 17.379654943943024, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.34162831306458, "training_acc": 53.0, "val_loss": 17.329253256320953, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14086937904358, "training_acc": 53.0, "val_loss": 17.30782985687256, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24776482582092, "training_acc": 53.0, "val_loss": 17.30813980102539, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.56410551071167, "training_acc": 43.0, "val_loss": 17.308364808559418, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.25327682495117, "training_acc": 53.0, "val_loss": 17.336010932922363, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11955785751343, "training_acc": 53.0, "val_loss": 17.42587387561798, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.43337678909302, "training_acc": 53.0, "val_loss": 17.42621511220932, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.41728615760803, "training_acc": 53.0, "val_loss": 17.367030680179596, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2587559223175, "training_acc": 53.0, "val_loss": 17.320652306079865, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.23002600669861, "training_acc": 53.0, "val_loss": 17.310191690921783, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16717314720154, "training_acc": 53.0, "val_loss": 17.314191162586212, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24446868896484, "training_acc": 53.0, "val_loss": 17.32969880104065, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1718521118164, "training_acc": 53.0, "val_loss": 17.31816679239273, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14969658851624, "training_acc": 53.0, "val_loss": 17.31499284505844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.27818655967712, "training_acc": 53.0, "val_loss": 17.31625646352768, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.43522000312805, "training_acc": 53.0, "val_loss": 17.340286076068878, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23307728767395, "training_acc": 53.0, "val_loss": 17.31930822134018, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13831424713135, "training_acc": 53.0, "val_loss": 17.314375936985016, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28855180740356, "training_acc": 53.0, "val_loss": 17.31189340353012, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11054039001465, "training_acc": 53.0, "val_loss": 17.310121655464172, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19289183616638, "training_acc": 53.0, "val_loss": 17.31640249490738, "val_acc": 52.0}
