"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.98982167243958, "training_acc": 50.0, "val_loss": 17.44256615638733, "val_acc": 56.0}
{"epoch": 1, "training_loss": 75.0753390789032, "training_acc": 52.0, "val_loss": 17.568376660346985, "val_acc": 56.0}
{"epoch": 2, "training_loss": 72.08011722564697, "training_acc": 46.0, "val_loss": 17.25098192691803, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.38607907295227, "training_acc": 52.0, "val_loss": 19.050903618335724, "val_acc": 44.0}
{"epoch": 4, "training_loss": 72.08570146560669, "training_acc": 50.0, "val_loss": 17.974787950515747, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.50613141059875, "training_acc": 52.0, "val_loss": 17.733527719974518, "val_acc": 56.0}
{"epoch": 6, "training_loss": 70.1462972164154, "training_acc": 48.0, "val_loss": 17.35234260559082, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.13709688186646, "training_acc": 52.0, "val_loss": 17.15732514858246, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.10850691795349, "training_acc": 52.0, "val_loss": 17.15341955423355, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.3067991733551, "training_acc": 52.0, "val_loss": 17.335116863250732, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.39075446128845, "training_acc": 50.0, "val_loss": 17.497852444648743, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.5554928779602, "training_acc": 48.0, "val_loss": 17.281977832317352, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.41628646850586, "training_acc": 52.0, "val_loss": 17.188377678394318, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.29127073287964, "training_acc": 52.0, "val_loss": 17.220735549926758, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24098515510559, "training_acc": 52.0, "val_loss": 17.238250374794006, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2634015083313, "training_acc": 52.0, "val_loss": 17.219695448875427, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.23863196372986, "training_acc": 52.0, "val_loss": 17.186252772808075, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.27913117408752, "training_acc": 52.0, "val_loss": 17.23218560218811, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.21268105506897, "training_acc": 52.0, "val_loss": 17.293697595596313, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.19861435890198, "training_acc": 52.0, "val_loss": 17.290931940078735, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20625829696655, "training_acc": 52.0, "val_loss": 17.27130264043808, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.14765429496765, "training_acc": 52.0, "val_loss": 17.20542460680008, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.65577435493469, "training_acc": 52.0, "val_loss": 17.183732986450195, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.18118238449097, "training_acc": 52.0, "val_loss": 17.30521321296692, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.14512991905212, "training_acc": 52.0, "val_loss": 17.487259209156036, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.52684783935547, "training_acc": 48.0, "val_loss": 17.47508943080902, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.99881672859192, "training_acc": 38.0, "val_loss": 17.281466722488403, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.20346093177795, "training_acc": 52.0, "val_loss": 17.276805639266968, "val_acc": 56.0}
