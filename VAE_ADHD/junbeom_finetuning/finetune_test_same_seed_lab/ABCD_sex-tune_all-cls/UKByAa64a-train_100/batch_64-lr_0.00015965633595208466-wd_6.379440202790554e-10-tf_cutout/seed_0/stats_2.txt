"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.56321406364441, "training_acc": 54.0, "val_loss": 17.480041086673737, "val_acc": 52.0}
{"epoch": 1, "training_loss": 221.29520988464355, "training_acc": 47.0, "val_loss": 17.37590730190277, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.9105019569397, "training_acc": 47.0, "val_loss": 17.556098103523254, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.3086428642273, "training_acc": 53.0, "val_loss": 17.471766471862793, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.12520217895508, "training_acc": 53.0, "val_loss": 17.76416301727295, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.01435780525208, "training_acc": 44.0, "val_loss": 17.575611174106598, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.34771847724915, "training_acc": 50.0, "val_loss": 17.954641580581665, "val_acc": 52.0}
{"epoch": 7, "training_loss": 74.09227776527405, "training_acc": 53.0, "val_loss": 17.449235916137695, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.07813549041748, "training_acc": 53.0, "val_loss": 17.925238609313965, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.39647936820984, "training_acc": 47.0, "val_loss": 17.38341599702835, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0537805557251, "training_acc": 53.0, "val_loss": 17.74280071258545, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.98121905326843, "training_acc": 53.0, "val_loss": 17.378555238246918, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.38671851158142, "training_acc": 41.0, "val_loss": 17.372019588947296, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.0896463394165, "training_acc": 56.0, "val_loss": 17.4184188246727, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.18252563476562, "training_acc": 53.0, "val_loss": 17.497368156909943, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.02524518966675, "training_acc": 53.0, "val_loss": 17.341651022434235, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15825700759888, "training_acc": 53.0, "val_loss": 17.341770231723785, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19270348548889, "training_acc": 53.0, "val_loss": 17.334488034248352, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29560017585754, "training_acc": 53.0, "val_loss": 17.338691651821136, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10417032241821, "training_acc": 53.0, "val_loss": 17.331145703792572, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11383104324341, "training_acc": 53.0, "val_loss": 17.32843816280365, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10892868041992, "training_acc": 53.0, "val_loss": 17.33521968126297, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.07954502105713, "training_acc": 53.0, "val_loss": 17.330527305603027, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.0607237815857, "training_acc": 53.0, "val_loss": 17.33919531106949, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17254686355591, "training_acc": 53.0, "val_loss": 17.357617616653442, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14273452758789, "training_acc": 53.0, "val_loss": 17.334094643592834, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.09737348556519, "training_acc": 53.0, "val_loss": 17.32287108898163, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10972809791565, "training_acc": 53.0, "val_loss": 17.321178317070007, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1042366027832, "training_acc": 53.0, "val_loss": 17.31320470571518, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.02863049507141, "training_acc": 53.0, "val_loss": 17.35779494047165, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.24004793167114, "training_acc": 53.0, "val_loss": 17.37825572490692, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.53931140899658, "training_acc": 53.0, "val_loss": 17.418663203716278, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.25296807289124, "training_acc": 53.0, "val_loss": 17.50357747077942, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.50109529495239, "training_acc": 53.0, "val_loss": 17.413444817066193, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.43739008903503, "training_acc": 53.0, "val_loss": 17.316630482673645, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.0103075504303, "training_acc": 53.0, "val_loss": 17.323289811611176, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.25535798072815, "training_acc": 50.0, "val_loss": 17.32558161020279, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.0509877204895, "training_acc": 54.0, "val_loss": 17.314448952674866, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.92361187934875, "training_acc": 53.0, "val_loss": 17.352645099163055, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.10811233520508, "training_acc": 53.0, "val_loss": 17.396628856658936, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.22739028930664, "training_acc": 53.0, "val_loss": 17.42473542690277, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18580365180969, "training_acc": 53.0, "val_loss": 17.357802391052246, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.19960427284241, "training_acc": 53.0, "val_loss": 17.327453196048737, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.99239039421082, "training_acc": 53.0, "val_loss": 17.326827347278595, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.06031513214111, "training_acc": 53.0, "val_loss": 17.328032851219177, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.93483066558838, "training_acc": 53.0, "val_loss": 17.344585061073303, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.94613265991211, "training_acc": 53.0, "val_loss": 17.357246577739716, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.93100237846375, "training_acc": 53.0, "val_loss": 17.3519566655159, "val_acc": 52.0}
