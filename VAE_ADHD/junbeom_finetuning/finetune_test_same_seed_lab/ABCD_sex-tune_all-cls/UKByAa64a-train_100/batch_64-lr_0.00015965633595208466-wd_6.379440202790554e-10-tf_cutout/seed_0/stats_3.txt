"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.04783749580383, "training_acc": 49.0, "val_loss": 17.925985157489777, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.4469063282013, "training_acc": 49.0, "val_loss": 18.22245717048645, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.73159909248352, "training_acc": 49.0, "val_loss": 17.329421639442444, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.39548802375793, "training_acc": 49.0, "val_loss": 17.692886292934418, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.32748436927795, "training_acc": 53.0, "val_loss": 17.36355721950531, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33050990104675, "training_acc": 53.0, "val_loss": 17.464706301689148, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.74040341377258, "training_acc": 47.0, "val_loss": 17.33427792787552, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11653256416321, "training_acc": 53.0, "val_loss": 17.45450496673584, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.11031699180603, "training_acc": 53.0, "val_loss": 17.351937294006348, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.95275211334229, "training_acc": 53.0, "val_loss": 17.3740953207016, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.50978779792786, "training_acc": 53.0, "val_loss": 17.333786189556122, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25538563728333, "training_acc": 54.0, "val_loss": 17.32105165719986, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.76169776916504, "training_acc": 53.0, "val_loss": 17.314106225967407, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08411526679993, "training_acc": 53.0, "val_loss": 17.311479151248932, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1889717578888, "training_acc": 53.0, "val_loss": 17.320041358470917, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2102153301239, "training_acc": 53.0, "val_loss": 17.33037531375885, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.30805921554565, "training_acc": 53.0, "val_loss": 17.327693104743958, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21165919303894, "training_acc": 53.0, "val_loss": 17.3271507024765, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.07442855834961, "training_acc": 53.0, "val_loss": 17.336396872997284, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.05242562294006, "training_acc": 53.0, "val_loss": 17.374984920024872, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2693555355072, "training_acc": 53.0, "val_loss": 17.38126575946808, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.08294939994812, "training_acc": 53.0, "val_loss": 17.334190011024475, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.04251885414124, "training_acc": 53.0, "val_loss": 17.347022891044617, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11337518692017, "training_acc": 55.0, "val_loss": 17.345212399959564, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01184487342834, "training_acc": 53.0, "val_loss": 17.34869033098221, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.48653197288513, "training_acc": 51.0, "val_loss": 17.355240881443024, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.0090856552124, "training_acc": 53.0, "val_loss": 17.419564723968506, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.37657427787781, "training_acc": 53.0, "val_loss": 17.44120717048645, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.5192186832428, "training_acc": 53.0, "val_loss": 17.33431965112686, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.88684296607971, "training_acc": 53.0, "val_loss": 17.39233285188675, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.20023465156555, "training_acc": 47.0, "val_loss": 17.389093339443207, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.23590683937073, "training_acc": 53.0, "val_loss": 17.329807579517365, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19874954223633, "training_acc": 53.0, "val_loss": 17.429456114768982, "val_acc": 52.0}
