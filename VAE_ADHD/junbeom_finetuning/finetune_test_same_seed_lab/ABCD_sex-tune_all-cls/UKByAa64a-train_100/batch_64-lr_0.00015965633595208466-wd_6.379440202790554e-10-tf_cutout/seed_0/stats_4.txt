"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.12699055671692, "training_acc": 45.0, "val_loss": 17.46344119310379, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.89626002311707, "training_acc": 53.0, "val_loss": 17.638063430786133, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.75299906730652, "training_acc": 51.0, "val_loss": 18.27148199081421, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.17029547691345, "training_acc": 53.0, "val_loss": 17.47407466173172, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.67101168632507, "training_acc": 46.0, "val_loss": 17.334219813346863, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11755871772766, "training_acc": 53.0, "val_loss": 17.37557351589203, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.47293376922607, "training_acc": 49.0, "val_loss": 17.393244802951813, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.61845445632935, "training_acc": 53.0, "val_loss": 17.329856753349304, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24033546447754, "training_acc": 51.0, "val_loss": 17.38540679216385, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.49484968185425, "training_acc": 43.0, "val_loss": 17.31444001197815, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4518313407898, "training_acc": 53.0, "val_loss": 17.32904464006424, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.2032699584961, "training_acc": 53.0, "val_loss": 17.308227717876434, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.31574726104736, "training_acc": 51.0, "val_loss": 17.359991371631622, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.40078163146973, "training_acc": 49.0, "val_loss": 17.30925291776657, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09281587600708, "training_acc": 53.0, "val_loss": 17.35944151878357, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.39302015304565, "training_acc": 53.0, "val_loss": 17.40523725748062, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.38430857658386, "training_acc": 53.0, "val_loss": 17.414066195487976, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.26420736312866, "training_acc": 53.0, "val_loss": 17.309123277664185, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.97933411598206, "training_acc": 53.0, "val_loss": 17.368033528327942, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.5057942867279, "training_acc": 47.0, "val_loss": 17.34466850757599, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24927520751953, "training_acc": 53.0, "val_loss": 17.312534153461456, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.39989018440247, "training_acc": 53.0, "val_loss": 17.38726645708084, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.27359700202942, "training_acc": 53.0, "val_loss": 17.331844568252563, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.65229845046997, "training_acc": 53.0, "val_loss": 17.305316030979156, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.3115394115448, "training_acc": 53.0, "val_loss": 17.31734275817871, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12243819236755, "training_acc": 53.0, "val_loss": 17.30990558862686, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.33844423294067, "training_acc": 53.0, "val_loss": 17.30784922838211, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11949753761292, "training_acc": 53.0, "val_loss": 17.32800304889679, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12895655632019, "training_acc": 53.0, "val_loss": 17.341887950897217, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.18164420127869, "training_acc": 53.0, "val_loss": 17.329150438308716, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1538360118866, "training_acc": 53.0, "val_loss": 17.30981171131134, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.25480914115906, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15951538085938, "training_acc": 53.0, "val_loss": 17.316871881484985, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13324666023254, "training_acc": 53.0, "val_loss": 17.323726415634155, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.09854578971863, "training_acc": 53.0, "val_loss": 17.315886914730072, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.07373380661011, "training_acc": 53.0, "val_loss": 17.30993390083313, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.0908215045929, "training_acc": 53.0, "val_loss": 17.308732867240906, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.06699752807617, "training_acc": 53.0, "val_loss": 17.313674092292786, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.06486630439758, "training_acc": 53.0, "val_loss": 17.322733998298645, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13470768928528, "training_acc": 53.0, "val_loss": 17.322757840156555, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.07181239128113, "training_acc": 53.0, "val_loss": 17.305098474025726, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.08915138244629, "training_acc": 53.0, "val_loss": 17.304252088069916, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.0151846408844, "training_acc": 53.0, "val_loss": 17.316725850105286, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.17867255210876, "training_acc": 53.0, "val_loss": 17.326153814792633, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.3496732711792, "training_acc": 53.0, "val_loss": 17.367273569107056, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.149897813797, "training_acc": 53.0, "val_loss": 17.32102781534195, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.97269773483276, "training_acc": 53.0, "val_loss": 17.309388518333435, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.10927295684814, "training_acc": 53.0, "val_loss": 17.33211725950241, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.36551475524902, "training_acc": 47.0, "val_loss": 17.353971302509308, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.35078763961792, "training_acc": 47.0, "val_loss": 17.313705384731293, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.74828863143921, "training_acc": 53.0, "val_loss": 17.30802059173584, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.09693837165833, "training_acc": 53.0, "val_loss": 17.304803431034088, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.07206702232361, "training_acc": 53.0, "val_loss": 17.3043891787529, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.10290479660034, "training_acc": 53.0, "val_loss": 17.311614751815796, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.20070028305054, "training_acc": 53.0, "val_loss": 17.313534021377563, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.05101609230042, "training_acc": 53.0, "val_loss": 17.341983318328857, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.24450373649597, "training_acc": 53.0, "val_loss": 17.373283207416534, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15121865272522, "training_acc": 53.0, "val_loss": 17.333967983722687, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.00094985961914, "training_acc": 53.0, "val_loss": 17.30523705482483, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.00463008880615, "training_acc": 53.0, "val_loss": 17.312929034233093, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.19477200508118, "training_acc": 53.0, "val_loss": 17.337945103645325, "val_acc": 52.0}
