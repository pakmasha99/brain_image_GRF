"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2764823436737, "training_acc": 52.0, "val_loss": 17.30833202600479, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2269549369812, "training_acc": 52.0, "val_loss": 17.31962561607361, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.26774644851685, "training_acc": 52.0, "val_loss": 17.290981113910675, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.18675208091736, "training_acc": 52.0, "val_loss": 17.303714156150818, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.0439875125885, "training_acc": 52.0, "val_loss": 17.29346215724945, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.1078269481659, "training_acc": 52.0, "val_loss": 17.281167209148407, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.12572026252747, "training_acc": 52.0, "val_loss": 17.323359847068787, "val_acc": 56.0}
{"epoch": 7, "training_loss": 68.96025919914246, "training_acc": 58.0, "val_loss": 17.264696955680847, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.29609155654907, "training_acc": 54.0, "val_loss": 17.184264957904816, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.05238342285156, "training_acc": 52.0, "val_loss": 17.244113981723785, "val_acc": 56.0}
{"epoch": 10, "training_loss": 68.97912836074829, "training_acc": 52.0, "val_loss": 17.27961301803589, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.01093745231628, "training_acc": 53.0, "val_loss": 17.275069653987885, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.9679343700409, "training_acc": 53.0, "val_loss": 17.329402267932892, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.68473744392395, "training_acc": 56.0, "val_loss": 17.354770004749298, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.56078290939331, "training_acc": 59.0, "val_loss": 17.26987361907959, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.60087275505066, "training_acc": 53.0, "val_loss": 17.26904660463333, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.21979069709778, "training_acc": 54.0, "val_loss": 17.330458760261536, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.62622499465942, "training_acc": 54.0, "val_loss": 17.42478907108307, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.24561381340027, "training_acc": 64.0, "val_loss": 17.295904457569122, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.41734385490417, "training_acc": 52.0, "val_loss": 17.335505783557892, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.45011234283447, "training_acc": 56.0, "val_loss": 17.43520349264145, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.90774083137512, "training_acc": 60.0, "val_loss": 17.321626842021942, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.66141867637634, "training_acc": 53.0, "val_loss": 17.27122813463211, "val_acc": 56.0}
{"epoch": 23, "training_loss": 67.70321011543274, "training_acc": 55.0, "val_loss": 17.59665310382843, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.14809370040894, "training_acc": 60.0, "val_loss": 17.670632898807526, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.00803303718567, "training_acc": 54.0, "val_loss": 17.365340888500214, "val_acc": 56.0}
{"epoch": 26, "training_loss": 67.98634338378906, "training_acc": 62.0, "val_loss": 17.292657494544983, "val_acc": 56.0}
{"epoch": 27, "training_loss": 67.86486387252808, "training_acc": 57.0, "val_loss": 17.534618079662323, "val_acc": 56.0}
