"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23350191116333, "training_acc": 53.0, "val_loss": 17.41582602262497, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2899100780487, "training_acc": 53.0, "val_loss": 17.420901358127594, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16046071052551, "training_acc": 53.0, "val_loss": 17.385298013687134, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.99122548103333, "training_acc": 53.0, "val_loss": 17.391440272331238, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.93932747840881, "training_acc": 53.0, "val_loss": 17.38649308681488, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.77648901939392, "training_acc": 53.0, "val_loss": 17.39969253540039, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.91453313827515, "training_acc": 53.0, "val_loss": 17.41092801094055, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.01233768463135, "training_acc": 53.0, "val_loss": 17.397917807102203, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.80401921272278, "training_acc": 53.0, "val_loss": 17.411838471889496, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.76602673530579, "training_acc": 53.0, "val_loss": 17.345526814460754, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.7556381225586, "training_acc": 53.0, "val_loss": 17.286624014377594, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.91851162910461, "training_acc": 53.0, "val_loss": 17.288443446159363, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07552313804626, "training_acc": 53.0, "val_loss": 17.328666150569916, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.96554255485535, "training_acc": 53.0, "val_loss": 17.353084683418274, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.7802414894104, "training_acc": 53.0, "val_loss": 17.369444668293, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.62565207481384, "training_acc": 53.0, "val_loss": 17.378349602222443, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.34911751747131, "training_acc": 53.0, "val_loss": 17.402957379817963, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.47820854187012, "training_acc": 53.0, "val_loss": 17.382575571537018, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.45814251899719, "training_acc": 53.0, "val_loss": 17.343352735042572, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.46426320075989, "training_acc": 53.0, "val_loss": 17.314709722995758, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.39227390289307, "training_acc": 53.0, "val_loss": 17.347480356693268, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.14538669586182, "training_acc": 53.0, "val_loss": 17.399606108665466, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.0777428150177, "training_acc": 53.0, "val_loss": 17.45000034570694, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.21177363395691, "training_acc": 53.0, "val_loss": 17.477573454380035, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.86239695549011, "training_acc": 53.0, "val_loss": 17.47116446495056, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.8366003036499, "training_acc": 53.0, "val_loss": 17.409449815750122, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.9356632232666, "training_acc": 53.0, "val_loss": 17.392604053020477, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.98673629760742, "training_acc": 53.0, "val_loss": 17.463386058807373, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.96975898742676, "training_acc": 53.0, "val_loss": 17.475086450576782, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.6673526763916, "training_acc": 53.0, "val_loss": 17.47046262025833, "val_acc": 52.0}
