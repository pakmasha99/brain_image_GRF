"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.73271822929382, "training_acc": 47.0, "val_loss": 17.424263060092926, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.74574685096741, "training_acc": 47.0, "val_loss": 17.377105355262756, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.37063717842102, "training_acc": 47.0, "val_loss": 17.3537939786911, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32833909988403, "training_acc": 45.0, "val_loss": 17.30111688375473, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20305633544922, "training_acc": 53.0, "val_loss": 17.294326424598694, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.97458124160767, "training_acc": 53.0, "val_loss": 17.304974794387817, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17402720451355, "training_acc": 53.0, "val_loss": 17.301413416862488, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2310950756073, "training_acc": 53.0, "val_loss": 17.292147874832153, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.97707104682922, "training_acc": 53.0, "val_loss": 17.285504937171936, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.02787137031555, "training_acc": 53.0, "val_loss": 17.29123443365097, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.05599403381348, "training_acc": 53.0, "val_loss": 17.29157418012619, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.87209272384644, "training_acc": 53.0, "val_loss": 17.303824424743652, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.95862770080566, "training_acc": 53.0, "val_loss": 17.33427345752716, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.61448335647583, "training_acc": 53.0, "val_loss": 17.362676560878754, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.80645561218262, "training_acc": 53.0, "val_loss": 17.364822328090668, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.76414847373962, "training_acc": 53.0, "val_loss": 17.35541820526123, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.67110562324524, "training_acc": 53.0, "val_loss": 17.35323816537857, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.56407904624939, "training_acc": 53.0, "val_loss": 17.353522777557373, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.36236500740051, "training_acc": 53.0, "val_loss": 17.380905151367188, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.70066261291504, "training_acc": 53.0, "val_loss": 17.355403304100037, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.2954158782959, "training_acc": 53.0, "val_loss": 17.32870787382126, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.3347635269165, "training_acc": 62.0, "val_loss": 17.33948141336441, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.08871173858643, "training_acc": 73.0, "val_loss": 17.352581024169922, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.83350729942322, "training_acc": 58.0, "val_loss": 17.391568422317505, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.29315233230591, "training_acc": 53.0, "val_loss": 17.380939424037933, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.77065372467041, "training_acc": 57.0, "val_loss": 17.326511442661285, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.82720756530762, "training_acc": 66.0, "val_loss": 17.335714399814606, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.7834141254425, "training_acc": 67.0, "val_loss": 17.47356504201889, "val_acc": 52.0}
