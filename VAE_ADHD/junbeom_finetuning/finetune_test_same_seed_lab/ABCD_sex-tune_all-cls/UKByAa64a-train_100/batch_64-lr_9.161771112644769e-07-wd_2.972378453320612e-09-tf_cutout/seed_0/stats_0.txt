"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39217352867126, "training_acc": 52.0, "val_loss": 17.274729907512665, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2117702960968, "training_acc": 52.0, "val_loss": 17.27883070707321, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.18811225891113, "training_acc": 52.0, "val_loss": 17.276732623577118, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.1670868396759, "training_acc": 52.0, "val_loss": 17.273183166980743, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.29079103469849, "training_acc": 52.0, "val_loss": 17.277581989765167, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.24253273010254, "training_acc": 52.0, "val_loss": 17.284469306468964, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.15702652931213, "training_acc": 52.0, "val_loss": 17.288577556610107, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.27598309516907, "training_acc": 52.0, "val_loss": 17.28586107492447, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.17666029930115, "training_acc": 52.0, "val_loss": 17.28471666574478, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.18196964263916, "training_acc": 52.0, "val_loss": 17.282693088054657, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.09047889709473, "training_acc": 52.0, "val_loss": 17.282336950302124, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.09525465965271, "training_acc": 52.0, "val_loss": 17.279134690761566, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.92588186264038, "training_acc": 52.0, "val_loss": 17.276085913181305, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.0185317993164, "training_acc": 52.0, "val_loss": 17.2722190618515, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.07237434387207, "training_acc": 52.0, "val_loss": 17.270995676517487, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.0673942565918, "training_acc": 52.0, "val_loss": 17.271065711975098, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.03724813461304, "training_acc": 52.0, "val_loss": 17.270274460315704, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.9610641002655, "training_acc": 52.0, "val_loss": 17.26609766483307, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.85982871055603, "training_acc": 52.0, "val_loss": 17.261458933353424, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.90723538398743, "training_acc": 52.0, "val_loss": 17.256061732769012, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.93294978141785, "training_acc": 52.0, "val_loss": 17.255550622940063, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.87713313102722, "training_acc": 52.0, "val_loss": 17.258672416210175, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.91340589523315, "training_acc": 52.0, "val_loss": 17.26268380880356, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.91210556030273, "training_acc": 52.0, "val_loss": 17.268237471580505, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.89989066123962, "training_acc": 52.0, "val_loss": 17.277444899082184, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.955482006073, "training_acc": 52.0, "val_loss": 17.27815270423889, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.6346046924591, "training_acc": 52.0, "val_loss": 17.272451519966125, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.94491124153137, "training_acc": 52.0, "val_loss": 17.269375920295715, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.87000322341919, "training_acc": 52.0, "val_loss": 17.26953089237213, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.78869009017944, "training_acc": 52.0, "val_loss": 17.271526157855988, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.8362820148468, "training_acc": 52.0, "val_loss": 17.272548377513885, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.81397938728333, "training_acc": 52.0, "val_loss": 17.2739177942276, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.83690237998962, "training_acc": 52.0, "val_loss": 17.269694805145264, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.55419421195984, "training_acc": 52.0, "val_loss": 17.26636290550232, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.8644392490387, "training_acc": 52.0, "val_loss": 17.265288531780243, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.72586798667908, "training_acc": 52.0, "val_loss": 17.26977527141571, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.63281345367432, "training_acc": 52.0, "val_loss": 17.273831367492676, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.68816113471985, "training_acc": 52.0, "val_loss": 17.27581024169922, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.72574973106384, "training_acc": 52.0, "val_loss": 17.277398705482483, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.78924608230591, "training_acc": 52.0, "val_loss": 17.274102568626404, "val_acc": 56.0}
