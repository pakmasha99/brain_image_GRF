"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.5091803073883, "training_acc": 47.0, "val_loss": 17.42865741252899, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.10053992271423, "training_acc": 47.0, "val_loss": 17.43527203798294, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.78757452964783, "training_acc": 47.0, "val_loss": 17.342601716518402, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.57117867469788, "training_acc": 47.0, "val_loss": 17.318671941757202, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.41602849960327, "training_acc": 53.0, "val_loss": 17.2911137342453, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24537372589111, "training_acc": 51.0, "val_loss": 17.29557067155838, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2158317565918, "training_acc": 56.0, "val_loss": 17.35319346189499, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.65417814254761, "training_acc": 39.0, "val_loss": 17.330598831176758, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.09590077400208, "training_acc": 53.0, "val_loss": 17.353808879852295, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.06932473182678, "training_acc": 53.0, "val_loss": 17.365756630897522, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18262696266174, "training_acc": 53.0, "val_loss": 17.361190915107727, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.35377979278564, "training_acc": 53.0, "val_loss": 17.363834381103516, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22366285324097, "training_acc": 53.0, "val_loss": 17.32078194618225, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12073421478271, "training_acc": 53.0, "val_loss": 17.313872277736664, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.37420415878296, "training_acc": 53.0, "val_loss": 17.312541604042053, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17321681976318, "training_acc": 53.0, "val_loss": 17.30751395225525, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17405247688293, "training_acc": 53.0, "val_loss": 17.330090701580048, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1288685798645, "training_acc": 53.0, "val_loss": 17.340995371341705, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22133207321167, "training_acc": 53.0, "val_loss": 17.334407567977905, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10560941696167, "training_acc": 53.0, "val_loss": 17.33989715576172, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15084147453308, "training_acc": 53.0, "val_loss": 17.334838211536407, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.28762078285217, "training_acc": 53.0, "val_loss": 17.328889667987823, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11355137825012, "training_acc": 53.0, "val_loss": 17.310731112957, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12611079216003, "training_acc": 53.0, "val_loss": 17.310042679309845, "val_acc": 52.0}
