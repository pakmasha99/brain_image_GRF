"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.53616976737976, "training_acc": 47.0, "val_loss": 17.296165227890015, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27640795707703, "training_acc": 53.0, "val_loss": 17.274905741214752, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14825010299683, "training_acc": 53.0, "val_loss": 17.27214753627777, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.01865863800049, "training_acc": 53.0, "val_loss": 17.32054501771927, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.06180310249329, "training_acc": 53.0, "val_loss": 17.323772609233856, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1849615573883, "training_acc": 53.0, "val_loss": 17.260800302028656, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24061965942383, "training_acc": 53.0, "val_loss": 17.234182357788086, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.72073316574097, "training_acc": 53.0, "val_loss": 17.26454347372055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.77406024932861, "training_acc": 53.0, "val_loss": 17.274443805217743, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.60679173469543, "training_acc": 53.0, "val_loss": 17.297369241714478, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.64150214195251, "training_acc": 53.0, "val_loss": 17.29593276977539, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.64623522758484, "training_acc": 53.0, "val_loss": 17.264899611473083, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.5890007019043, "training_acc": 53.0, "val_loss": 17.237895727157593, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.57861185073853, "training_acc": 53.0, "val_loss": 17.23053753376007, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.60105872154236, "training_acc": 53.0, "val_loss": 17.219699919223785, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.48812508583069, "training_acc": 53.0, "val_loss": 17.211151123046875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.25412845611572, "training_acc": 53.0, "val_loss": 17.21290946006775, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.28216814994812, "training_acc": 53.0, "val_loss": 17.19990074634552, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.90715146064758, "training_acc": 54.0, "val_loss": 17.20171719789505, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.2162868976593, "training_acc": 53.0, "val_loss": 17.34635829925537, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.17044234275818, "training_acc": 53.0, "val_loss": 17.287570238113403, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.8716721534729, "training_acc": 53.0, "val_loss": 17.198897898197174, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.10005235671997, "training_acc": 67.0, "val_loss": 17.2101691365242, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.07517147064209, "training_acc": 72.0, "val_loss": 17.17229187488556, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.33499336242676, "training_acc": 64.0, "val_loss": 17.220857739448547, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.98475742340088, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.61667227745056, "training_acc": 53.0, "val_loss": 17.230579257011414, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.5871171951294, "training_acc": 56.0, "val_loss": 17.169226706027985, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.44697213172913, "training_acc": 62.0, "val_loss": 17.165853083133698, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.47265577316284, "training_acc": 62.0, "val_loss": 17.15768426656723, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.49191403388977, "training_acc": 63.0, "val_loss": 17.25665181875229, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.03372240066528, "training_acc": 61.0, "val_loss": 17.202578485012054, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.59219670295715, "training_acc": 60.0, "val_loss": 17.13617444038391, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.21015810966492, "training_acc": 68.0, "val_loss": 17.07143485546112, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.89846467971802, "training_acc": 69.0, "val_loss": 17.135997116565704, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.0502998828888, "training_acc": 71.0, "val_loss": 17.04876273870468, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.66534304618835, "training_acc": 67.0, "val_loss": 17.239536345005035, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.11738181114197, "training_acc": 69.0, "val_loss": 17.065510153770447, "val_acc": 52.0}
{"epoch": 38, "training_loss": 63.84918189048767, "training_acc": 74.0, "val_loss": 16.932545602321625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 62.85592770576477, "training_acc": 78.0, "val_loss": 16.864725947380066, "val_acc": 52.0}
{"epoch": 40, "training_loss": 60.85817360877991, "training_acc": 81.0, "val_loss": 16.96661412715912, "val_acc": 52.0}
{"epoch": 41, "training_loss": 61.34176516532898, "training_acc": 70.0, "val_loss": 16.588199138641357, "val_acc": 52.0}
{"epoch": 42, "training_loss": 59.891128063201904, "training_acc": 77.0, "val_loss": 17.350180447101593, "val_acc": 52.0}
{"epoch": 43, "training_loss": 62.13406848907471, "training_acc": 58.0, "val_loss": 18.18806380033493, "val_acc": 56.0}
{"epoch": 44, "training_loss": 68.00381517410278, "training_acc": 48.0, "val_loss": 17.821775376796722, "val_acc": 60.0}
{"epoch": 45, "training_loss": 61.734402894973755, "training_acc": 65.0, "val_loss": 18.999984860420227, "val_acc": 52.0}
{"epoch": 46, "training_loss": 72.18624114990234, "training_acc": 53.0, "val_loss": 19.268637895584106, "val_acc": 52.0}
{"epoch": 47, "training_loss": 72.84703707695007, "training_acc": 53.0, "val_loss": 18.08445453643799, "val_acc": 52.0}
{"epoch": 48, "training_loss": 70.45108556747437, "training_acc": 53.0, "val_loss": 17.51115769147873, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.88947987556458, "training_acc": 53.0, "val_loss": 17.223358154296875, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.40617990493774, "training_acc": 53.0, "val_loss": 17.200088500976562, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.20654034614563, "training_acc": 71.0, "val_loss": 17.256705462932587, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.55767822265625, "training_acc": 53.0, "val_loss": 17.242400348186493, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.58230233192444, "training_acc": 59.0, "val_loss": 17.1675905585289, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.20298790931702, "training_acc": 62.0, "val_loss": 17.125995457172394, "val_acc": 52.0}
{"epoch": 55, "training_loss": 67.66247320175171, "training_acc": 53.0, "val_loss": 17.13615506887436, "val_acc": 52.0}
{"epoch": 56, "training_loss": 67.88114929199219, "training_acc": 53.0, "val_loss": 17.13702380657196, "val_acc": 52.0}
{"epoch": 57, "training_loss": 67.98336172103882, "training_acc": 53.0, "val_loss": 17.122825980186462, "val_acc": 52.0}
{"epoch": 58, "training_loss": 67.92873072624207, "training_acc": 53.0, "val_loss": 17.067624628543854, "val_acc": 52.0}
{"epoch": 59, "training_loss": 67.32244229316711, "training_acc": 53.0, "val_loss": 17.03457087278366, "val_acc": 52.0}
{"epoch": 60, "training_loss": 66.85376763343811, "training_acc": 54.0, "val_loss": 17.028911411762238, "val_acc": 52.0}
