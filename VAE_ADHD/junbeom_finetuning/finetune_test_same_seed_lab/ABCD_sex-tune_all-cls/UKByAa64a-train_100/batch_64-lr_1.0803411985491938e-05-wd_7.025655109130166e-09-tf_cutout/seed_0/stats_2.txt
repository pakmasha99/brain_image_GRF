"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.16203022003174, "training_acc": 47.0, "val_loss": 17.41059422492981, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.4556839466095, "training_acc": 47.0, "val_loss": 17.3243448138237, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.13849592208862, "training_acc": 53.0, "val_loss": 17.36527532339096, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05131459236145, "training_acc": 53.0, "val_loss": 17.381173372268677, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.98070168495178, "training_acc": 53.0, "val_loss": 17.37823784351349, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.07779359817505, "training_acc": 53.0, "val_loss": 17.372412979602814, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.96171116828918, "training_acc": 53.0, "val_loss": 17.370299994945526, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.9969413280487, "training_acc": 53.0, "val_loss": 17.371048033237457, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.88271760940552, "training_acc": 53.0, "val_loss": 17.33987033367157, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.9189395904541, "training_acc": 53.0, "val_loss": 17.343631386756897, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.47279405593872, "training_acc": 53.0, "val_loss": 17.374102771282196, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.69626235961914, "training_acc": 53.0, "val_loss": 17.377398908138275, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.29210782051086, "training_acc": 53.0, "val_loss": 17.387373745441437, "val_acc": 52.0}
{"epoch": 13, "training_loss": 67.92829990386963, "training_acc": 54.0, "val_loss": 17.3711359500885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.14415097236633, "training_acc": 59.0, "val_loss": 17.369788885116577, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.84574484825134, "training_acc": 58.0, "val_loss": 17.383399605751038, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.22476887702942, "training_acc": 56.0, "val_loss": 17.34331101179123, "val_acc": 52.0}
{"epoch": 17, "training_loss": 66.60958981513977, "training_acc": 67.0, "val_loss": 17.33386516571045, "val_acc": 52.0}
{"epoch": 18, "training_loss": 65.69679689407349, "training_acc": 71.0, "val_loss": 17.364253103733063, "val_acc": 52.0}
{"epoch": 19, "training_loss": 65.4153835773468, "training_acc": 55.0, "val_loss": 17.378734052181244, "val_acc": 52.0}
{"epoch": 20, "training_loss": 64.16084671020508, "training_acc": 71.0, "val_loss": 17.322173714637756, "val_acc": 52.0}
{"epoch": 21, "training_loss": 63.58382868766785, "training_acc": 65.0, "val_loss": 17.349372804164886, "val_acc": 52.0}
{"epoch": 22, "training_loss": 62.98726010322571, "training_acc": 74.0, "val_loss": 17.7699014544487, "val_acc": 52.0}
{"epoch": 23, "training_loss": 61.70209050178528, "training_acc": 68.0, "val_loss": 18.492640554904938, "val_acc": 52.0}
{"epoch": 24, "training_loss": 64.03577184677124, "training_acc": 57.0, "val_loss": 18.675711750984192, "val_acc": 56.0}
{"epoch": 25, "training_loss": 65.12342166900635, "training_acc": 54.0, "val_loss": 17.218071222305298, "val_acc": 52.0}
{"epoch": 26, "training_loss": 59.526368141174316, "training_acc": 68.0, "val_loss": 17.54094660282135, "val_acc": 52.0}
{"epoch": 27, "training_loss": 56.04892015457153, "training_acc": 71.0, "val_loss": 18.74358355998993, "val_acc": 56.0}
{"epoch": 28, "training_loss": 58.462148904800415, "training_acc": 70.0, "val_loss": 17.904704809188843, "val_acc": 52.0}
{"epoch": 29, "training_loss": 56.794947385787964, "training_acc": 70.0, "val_loss": 17.99219846725464, "val_acc": 52.0}
{"epoch": 30, "training_loss": 53.13106191158295, "training_acc": 78.0, "val_loss": 17.251817882061005, "val_acc": 56.0}
{"epoch": 31, "training_loss": 48.1740505695343, "training_acc": 88.0, "val_loss": 17.535503208637238, "val_acc": 60.0}
{"epoch": 32, "training_loss": 49.8466112613678, "training_acc": 81.0, "val_loss": 17.715375125408173, "val_acc": 56.0}
{"epoch": 33, "training_loss": 46.96973395347595, "training_acc": 81.0, "val_loss": 18.510474264621735, "val_acc": 56.0}
{"epoch": 34, "training_loss": 43.05081927776337, "training_acc": 88.0, "val_loss": 18.977244198322296, "val_acc": 52.0}
{"epoch": 35, "training_loss": 59.24224376678467, "training_acc": 69.0, "val_loss": 17.609596252441406, "val_acc": 60.0}
{"epoch": 36, "training_loss": 59.71621823310852, "training_acc": 73.0, "val_loss": 18.082286417484283, "val_acc": 56.0}
{"epoch": 37, "training_loss": 43.212050437927246, "training_acc": 83.0, "val_loss": 24.41508173942566, "val_acc": 52.0}
{"epoch": 38, "training_loss": 56.013975381851196, "training_acc": 66.0, "val_loss": 24.33749884366989, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.75365805625916, "training_acc": 53.0, "val_loss": 18.351489305496216, "val_acc": 52.0}
{"epoch": 40, "training_loss": 47.47820258140564, "training_acc": 75.0, "val_loss": 22.90925532579422, "val_acc": 52.0}
{"epoch": 41, "training_loss": 62.38566780090332, "training_acc": 59.0, "val_loss": 17.244498431682587, "val_acc": 60.0}
{"epoch": 42, "training_loss": 44.942795276641846, "training_acc": 84.0, "val_loss": 19.361479580402374, "val_acc": 52.0}
{"epoch": 43, "training_loss": 47.87918841838837, "training_acc": 75.0, "val_loss": 17.299114167690277, "val_acc": 60.0}
{"epoch": 44, "training_loss": 41.52367055416107, "training_acc": 87.0, "val_loss": 18.881969153881073, "val_acc": 56.0}
