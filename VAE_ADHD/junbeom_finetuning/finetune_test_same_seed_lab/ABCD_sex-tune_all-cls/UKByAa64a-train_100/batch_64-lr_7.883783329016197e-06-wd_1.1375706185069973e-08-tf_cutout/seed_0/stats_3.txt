"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.20748376846313, "training_acc": 53.0, "val_loss": 17.359866201877594, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.31017756462097, "training_acc": 53.0, "val_loss": 17.311054468154907, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.07322335243225, "training_acc": 53.0, "val_loss": 17.279475927352905, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1542501449585, "training_acc": 53.0, "val_loss": 17.263133823871613, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.98375248908997, "training_acc": 53.0, "val_loss": 17.277657985687256, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.97534108161926, "training_acc": 53.0, "val_loss": 17.304866015911102, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.70705342292786, "training_acc": 53.0, "val_loss": 17.303092777729034, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.95826268196106, "training_acc": 53.0, "val_loss": 17.270557582378387, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.83214592933655, "training_acc": 53.0, "val_loss": 17.271773517131805, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.85587811470032, "training_acc": 53.0, "val_loss": 17.306706309318542, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.62669086456299, "training_acc": 53.0, "val_loss": 17.345088720321655, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.68539667129517, "training_acc": 53.0, "val_loss": 17.33882874250412, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.68609356880188, "training_acc": 53.0, "val_loss": 17.301219701766968, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.52486157417297, "training_acc": 53.0, "val_loss": 17.297793924808502, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.5631890296936, "training_acc": 53.0, "val_loss": 17.27360486984253, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.32509684562683, "training_acc": 53.0, "val_loss": 17.263874411582947, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.32387733459473, "training_acc": 53.0, "val_loss": 17.290090024471283, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.36097621917725, "training_acc": 53.0, "val_loss": 17.31284260749817, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.18912625312805, "training_acc": 53.0, "val_loss": 17.339012026786804, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.96819281578064, "training_acc": 53.0, "val_loss": 17.355653643608093, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.3258285522461, "training_acc": 53.0, "val_loss": 17.31359511613846, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.85177707672119, "training_acc": 53.0, "val_loss": 17.303869128227234, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.81915307044983, "training_acc": 53.0, "val_loss": 17.382635176181793, "val_acc": 52.0}
