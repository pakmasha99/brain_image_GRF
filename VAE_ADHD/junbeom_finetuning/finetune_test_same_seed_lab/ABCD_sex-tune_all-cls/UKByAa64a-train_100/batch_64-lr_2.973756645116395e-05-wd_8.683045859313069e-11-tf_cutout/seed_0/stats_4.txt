"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.51582360267639, "training_acc": 47.0, "val_loss": 17.361469566822052, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.47265410423279, "training_acc": 47.0, "val_loss": 17.33284592628479, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24573087692261, "training_acc": 49.0, "val_loss": 17.294497787952423, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.31878352165222, "training_acc": 54.0, "val_loss": 17.299620807170868, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07909488677979, "training_acc": 53.0, "val_loss": 17.287003993988037, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.01664280891418, "training_acc": 53.0, "val_loss": 17.298461496829987, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.02575659751892, "training_acc": 53.0, "val_loss": 17.30721890926361, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.8895366191864, "training_acc": 53.0, "val_loss": 17.297202348709106, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.00795817375183, "training_acc": 53.0, "val_loss": 17.30440855026245, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.91521096229553, "training_acc": 53.0, "val_loss": 17.323584854602814, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.8805205821991, "training_acc": 53.0, "val_loss": 17.338310182094574, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.96525526046753, "training_acc": 53.0, "val_loss": 17.335407435894012, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18475723266602, "training_acc": 53.0, "val_loss": 17.330533266067505, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11147427558899, "training_acc": 53.0, "val_loss": 17.32829213142395, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12641072273254, "training_acc": 53.0, "val_loss": 17.326976358890533, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1341826915741, "training_acc": 53.0, "val_loss": 17.320747673511505, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.04655194282532, "training_acc": 53.0, "val_loss": 17.311348021030426, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.04079937934875, "training_acc": 53.0, "val_loss": 17.310330271720886, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.97548699378967, "training_acc": 53.0, "val_loss": 17.321597039699554, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.92930769920349, "training_acc": 53.0, "val_loss": 17.316821217536926, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.8384141921997, "training_acc": 53.0, "val_loss": 17.306792736053467, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.8322868347168, "training_acc": 53.0, "val_loss": 17.302772402763367, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.79992032051086, "training_acc": 53.0, "val_loss": 17.302758991718292, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.6197657585144, "training_acc": 53.0, "val_loss": 17.33250766992569, "val_acc": 52.0}
