"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.43771862983704, "training_acc": 47.0, "val_loss": 17.38002747297287, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.59608340263367, "training_acc": 47.0, "val_loss": 17.372648417949677, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.48709893226624, "training_acc": 47.0, "val_loss": 17.366354167461395, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.46891903877258, "training_acc": 47.0, "val_loss": 17.359767854213715, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.61572051048279, "training_acc": 47.0, "val_loss": 17.35203266143799, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.49800944328308, "training_acc": 47.0, "val_loss": 17.34497845172882, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.45516705513, "training_acc": 49.0, "val_loss": 17.337971925735474, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.41473340988159, "training_acc": 47.0, "val_loss": 17.332208156585693, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.39018845558167, "training_acc": 54.0, "val_loss": 17.327944934368134, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44072008132935, "training_acc": 43.0, "val_loss": 17.32354313135147, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.37677478790283, "training_acc": 44.0, "val_loss": 17.320141196250916, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.32357883453369, "training_acc": 48.0, "val_loss": 17.318148910999298, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21442914009094, "training_acc": 57.0, "val_loss": 17.316876351833344, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2719714641571, "training_acc": 53.0, "val_loss": 17.315496504306793, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.25468730926514, "training_acc": 46.0, "val_loss": 17.31506735086441, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31674313545227, "training_acc": 52.0, "val_loss": 17.3154279589653, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.32154560089111, "training_acc": 52.0, "val_loss": 17.31584668159485, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20514965057373, "training_acc": 53.0, "val_loss": 17.31659471988678, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16595554351807, "training_acc": 54.0, "val_loss": 17.316901683807373, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21369481086731, "training_acc": 53.0, "val_loss": 17.317834496498108, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22398543357849, "training_acc": 53.0, "val_loss": 17.31932759284973, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17362952232361, "training_acc": 53.0, "val_loss": 17.320138216018677, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20377016067505, "training_acc": 53.0, "val_loss": 17.320220172405243, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.99486875534058, "training_acc": 53.0, "val_loss": 17.31986701488495, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.0997679233551, "training_acc": 52.0, "val_loss": 17.320019006729126, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14136266708374, "training_acc": 52.0, "val_loss": 17.320041358470917, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.0999162197113, "training_acc": 53.0, "val_loss": 17.320169508457184, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.22766137123108, "training_acc": 53.0, "val_loss": 17.319869995117188, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17093300819397, "training_acc": 53.0, "val_loss": 17.31972247362137, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16096782684326, "training_acc": 53.0, "val_loss": 17.31947362422943, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.0631365776062, "training_acc": 53.0, "val_loss": 17.319215834140778, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13900423049927, "training_acc": 53.0, "val_loss": 17.31896996498108, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.9627788066864, "training_acc": 53.0, "val_loss": 17.318719625473022, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14215135574341, "training_acc": 53.0, "val_loss": 17.318354547023773, "val_acc": 52.0}
