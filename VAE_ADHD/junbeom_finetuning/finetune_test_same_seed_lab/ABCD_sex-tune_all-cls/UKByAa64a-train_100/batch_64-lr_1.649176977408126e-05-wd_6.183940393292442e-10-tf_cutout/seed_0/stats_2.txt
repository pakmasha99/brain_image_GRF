"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25951266288757, "training_acc": 53.0, "val_loss": 17.297782003879547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27946090698242, "training_acc": 53.0, "val_loss": 17.29721575975418, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.19367456436157, "training_acc": 53.0, "val_loss": 17.319603264331818, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.04574680328369, "training_acc": 53.0, "val_loss": 17.305047810077667, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.81916761398315, "training_acc": 53.0, "val_loss": 17.259185016155243, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.74850964546204, "training_acc": 53.0, "val_loss": 17.31332689523697, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.88463521003723, "training_acc": 53.0, "val_loss": 17.31054335832596, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.02284169197083, "training_acc": 53.0, "val_loss": 17.31339395046234, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04997992515564, "training_acc": 53.0, "val_loss": 17.312563955783844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.87909126281738, "training_acc": 53.0, "val_loss": 17.29329228401184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.75488758087158, "training_acc": 53.0, "val_loss": 17.246685922145844, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.6517562866211, "training_acc": 53.0, "val_loss": 17.24487990140915, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.62064862251282, "training_acc": 53.0, "val_loss": 17.28772521018982, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.71053910255432, "training_acc": 53.0, "val_loss": 17.307616770267487, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.82600426673889, "training_acc": 53.0, "val_loss": 17.287257313728333, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.52341890335083, "training_acc": 53.0, "val_loss": 17.26660132408142, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.36854481697083, "training_acc": 53.0, "val_loss": 17.24451035261154, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.22486186027527, "training_acc": 53.0, "val_loss": 17.21794158220291, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.92794179916382, "training_acc": 53.0, "val_loss": 17.19745546579361, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.03537440299988, "training_acc": 53.0, "val_loss": 17.180633544921875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.14326786994934, "training_acc": 53.0, "val_loss": 17.17764586210251, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.3004195690155, "training_acc": 53.0, "val_loss": 17.198215425014496, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.23286890983582, "training_acc": 54.0, "val_loss": 17.3088401556015, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.98650908470154, "training_acc": 78.0, "val_loss": 17.275306582450867, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.71575927734375, "training_acc": 53.0, "val_loss": 17.311210930347443, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.98694205284119, "training_acc": 53.0, "val_loss": 17.34319031238556, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.23240613937378, "training_acc": 53.0, "val_loss": 17.329245805740356, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.97574186325073, "training_acc": 53.0, "val_loss": 17.325130105018616, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.93484783172607, "training_acc": 53.0, "val_loss": 17.333419620990753, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.87319254875183, "training_acc": 53.0, "val_loss": 17.335593700408936, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.92421793937683, "training_acc": 53.0, "val_loss": 17.309419810771942, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.68313312530518, "training_acc": 53.0, "val_loss": 17.295196652412415, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.54774832725525, "training_acc": 53.0, "val_loss": 17.29712188243866, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.61762571334839, "training_acc": 53.0, "val_loss": 17.293277382850647, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.3070375919342, "training_acc": 53.0, "val_loss": 17.283454537391663, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.37452411651611, "training_acc": 53.0, "val_loss": 17.278417944908142, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.31644940376282, "training_acc": 53.0, "val_loss": 17.26597249507904, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.11770606040955, "training_acc": 53.0, "val_loss": 17.264442145824432, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.91706848144531, "training_acc": 53.0, "val_loss": 17.237335443496704, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.4438099861145, "training_acc": 53.0, "val_loss": 17.218589782714844, "val_acc": 52.0}
