"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.33269929885864, "training_acc": 53.0, "val_loss": 17.306089401245117, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2297375202179, "training_acc": 51.0, "val_loss": 17.267635464668274, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.29791116714478, "training_acc": 52.0, "val_loss": 17.287734150886536, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.34267735481262, "training_acc": 52.0, "val_loss": 17.298579216003418, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24027395248413, "training_acc": 52.0, "val_loss": 17.23300963640213, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.51330351829529, "training_acc": 52.0, "val_loss": 17.24175214767456, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27779984474182, "training_acc": 52.0, "val_loss": 17.294086515903473, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2748658657074, "training_acc": 52.0, "val_loss": 17.22269207239151, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.65313649177551, "training_acc": 52.0, "val_loss": 17.199701070785522, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.20889353752136, "training_acc": 52.0, "val_loss": 17.30775237083435, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.29882144927979, "training_acc": 50.0, "val_loss": 17.312459647655487, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.30888080596924, "training_acc": 52.0, "val_loss": 17.236922681331635, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.29996228218079, "training_acc": 52.0, "val_loss": 17.224188148975372, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.29157757759094, "training_acc": 52.0, "val_loss": 17.26071685552597, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24941182136536, "training_acc": 52.0, "val_loss": 17.22213178873062, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.22595548629761, "training_acc": 52.0, "val_loss": 17.184430360794067, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2994737625122, "training_acc": 52.0, "val_loss": 17.164665460586548, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.33911895751953, "training_acc": 52.0, "val_loss": 17.201076447963715, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25490283966064, "training_acc": 52.0, "val_loss": 17.26250797510147, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.24039936065674, "training_acc": 52.0, "val_loss": 17.286743223667145, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.29716205596924, "training_acc": 52.0, "val_loss": 17.275826632976532, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23245668411255, "training_acc": 52.0, "val_loss": 17.20699667930603, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.51179623603821, "training_acc": 52.0, "val_loss": 17.164047062397003, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.32250761985779, "training_acc": 52.0, "val_loss": 17.19995141029358, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.19521832466125, "training_acc": 52.0, "val_loss": 17.288844287395477, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.3659291267395, "training_acc": 48.0, "val_loss": 17.368502914905548, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.68277215957642, "training_acc": 38.0, "val_loss": 17.313510179519653, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.29952025413513, "training_acc": 52.0, "val_loss": 17.337237298488617, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.36157989501953, "training_acc": 48.0, "val_loss": 17.310863733291626, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.24517345428467, "training_acc": 52.0, "val_loss": 17.225615680217743, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.58622717857361, "training_acc": 52.0, "val_loss": 17.17878133058548, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.45242953300476, "training_acc": 52.0, "val_loss": 17.20321625471115, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25700449943542, "training_acc": 52.0, "val_loss": 17.196574807167053, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2595055103302, "training_acc": 52.0, "val_loss": 17.209172248840332, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25701069831848, "training_acc": 52.0, "val_loss": 17.217056453227997, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24715805053711, "training_acc": 52.0, "val_loss": 17.24681854248047, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.24929285049438, "training_acc": 52.0, "val_loss": 17.26122945547104, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.34009170532227, "training_acc": 52.0, "val_loss": 17.245694994926453, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.19555640220642, "training_acc": 52.0, "val_loss": 17.19333976507187, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.42799925804138, "training_acc": 52.0, "val_loss": 17.157752811908722, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.37459301948547, "training_acc": 52.0, "val_loss": 17.16568171977997, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.31799006462097, "training_acc": 52.0, "val_loss": 17.191529273986816, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.25754237174988, "training_acc": 52.0, "val_loss": 17.230460047721863, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.20046639442444, "training_acc": 52.0, "val_loss": 17.29649156332016, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.36275839805603, "training_acc": 48.0, "val_loss": 17.388814687728882, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.41134572029114, "training_acc": 48.0, "val_loss": 17.375586926937103, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.3790135383606, "training_acc": 48.0, "val_loss": 17.332930862903595, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.30520582199097, "training_acc": 54.0, "val_loss": 17.279256880283356, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.27493023872375, "training_acc": 52.0, "val_loss": 17.21021831035614, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.35335922241211, "training_acc": 52.0, "val_loss": 17.185252904891968, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.27134704589844, "training_acc": 52.0, "val_loss": 17.20000058412552, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.2313380241394, "training_acc": 52.0, "val_loss": 17.23775416612625, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.22235465049744, "training_acc": 52.0, "val_loss": 17.2768697142601, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.24982857704163, "training_acc": 52.0, "val_loss": 17.314906418323517, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.32148766517639, "training_acc": 47.0, "val_loss": 17.32073724269867, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.3585934638977, "training_acc": 52.0, "val_loss": 17.27466583251953, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.27085542678833, "training_acc": 52.0, "val_loss": 17.257894575595856, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23756432533264, "training_acc": 52.0, "val_loss": 17.252321541309357, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2256863117218, "training_acc": 52.0, "val_loss": 17.228449881076813, "val_acc": 56.0}
