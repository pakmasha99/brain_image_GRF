"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.17696261405945, "training_acc": 50.0, "val_loss": 17.48388558626175, "val_acc": 56.0}
{"epoch": 1, "training_loss": 78.95940709114075, "training_acc": 52.0, "val_loss": 17.76977926492691, "val_acc": 56.0}
{"epoch": 2, "training_loss": 73.678870677948, "training_acc": 46.0, "val_loss": 17.33085960149765, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.13970637321472, "training_acc": 46.0, "val_loss": 20.699380338191986, "val_acc": 44.0}
{"epoch": 4, "training_loss": 75.8377411365509, "training_acc": 50.0, "val_loss": 17.23800003528595, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.6110212802887, "training_acc": 52.0, "val_loss": 17.21414178609848, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.48734641075134, "training_acc": 50.0, "val_loss": 17.551273107528687, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.47421002388, "training_acc": 48.0, "val_loss": 17.167985439300537, "val_acc": 56.0}
{"epoch": 8, "training_loss": 71.45911908149719, "training_acc": 52.0, "val_loss": 17.16589331626892, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25417351722717, "training_acc": 52.0, "val_loss": 17.41197407245636, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.46313548088074, "training_acc": 48.0, "val_loss": 17.37816333770752, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.40541934967041, "training_acc": 48.0, "val_loss": 17.210480570793152, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.381840467453, "training_acc": 52.0, "val_loss": 17.18328446149826, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.32399106025696, "training_acc": 52.0, "val_loss": 17.253200709819794, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.27824568748474, "training_acc": 52.0, "val_loss": 17.257840931415558, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23884868621826, "training_acc": 52.0, "val_loss": 17.202135920524597, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.30511498451233, "training_acc": 52.0, "val_loss": 17.16109812259674, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.34235286712646, "training_acc": 52.0, "val_loss": 17.18946546316147, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2268226146698, "training_acc": 52.0, "val_loss": 17.260755598545074, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21587061882019, "training_acc": 52.0, "val_loss": 17.30252057313919, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.27341938018799, "training_acc": 54.0, "val_loss": 17.291900515556335, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.18674111366272, "training_acc": 52.0, "val_loss": 17.213276028633118, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.51432347297668, "training_acc": 52.0, "val_loss": 17.17090904712677, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.31933188438416, "training_acc": 52.0, "val_loss": 17.21002608537674, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.12790513038635, "training_acc": 52.0, "val_loss": 17.32238531112671, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.3549554347992, "training_acc": 48.0, "val_loss": 17.424270510673523, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.68163251876831, "training_acc": 38.0, "val_loss": 17.35261231660843, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.29664134979248, "training_acc": 50.0, "val_loss": 17.356887459754944, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.28680515289307, "training_acc": 48.0, "val_loss": 17.318779230117798, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.17384362220764, "training_acc": 52.0, "val_loss": 17.2337606549263, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.56443071365356, "training_acc": 52.0, "val_loss": 17.1833798289299, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.43600869178772, "training_acc": 52.0, "val_loss": 17.201879620552063, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.21147465705872, "training_acc": 52.0, "val_loss": 17.200565338134766, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.22317886352539, "training_acc": 52.0, "val_loss": 17.22044199705124, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.186927318573, "training_acc": 52.0, "val_loss": 17.237162590026855, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.18033385276794, "training_acc": 52.0, "val_loss": 17.272914946079254, "val_acc": 56.0}
