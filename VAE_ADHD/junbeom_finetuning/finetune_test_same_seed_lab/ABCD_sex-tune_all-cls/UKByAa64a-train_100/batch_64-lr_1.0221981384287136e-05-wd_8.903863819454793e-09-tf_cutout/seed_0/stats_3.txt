"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38415193557739, "training_acc": 53.0, "val_loss": 17.36212819814682, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27089095115662, "training_acc": 53.0, "val_loss": 17.43396669626236, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12857341766357, "training_acc": 53.0, "val_loss": 17.303405702114105, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.08095264434814, "training_acc": 53.0, "val_loss": 17.30297952890396, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18306374549866, "training_acc": 53.0, "val_loss": 17.301301658153534, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.90578842163086, "training_acc": 53.0, "val_loss": 17.310568690299988, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.91085386276245, "training_acc": 53.0, "val_loss": 17.323283851146698, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.98129343986511, "training_acc": 53.0, "val_loss": 17.344599962234497, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.85413670539856, "training_acc": 53.0, "val_loss": 17.332732677459717, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.88227915763855, "training_acc": 53.0, "val_loss": 17.35830008983612, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.82578945159912, "training_acc": 53.0, "val_loss": 17.361825704574585, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.69703245162964, "training_acc": 53.0, "val_loss": 17.34578311443329, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.42819380760193, "training_acc": 53.0, "val_loss": 17.345240712165833, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.85433340072632, "training_acc": 53.0, "val_loss": 17.359203100204468, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.81408929824829, "training_acc": 53.0, "val_loss": 17.360295355319977, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.70341038703918, "training_acc": 53.0, "val_loss": 17.35295057296753, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.64110326766968, "training_acc": 53.0, "val_loss": 17.338134348392487, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.6996500492096, "training_acc": 53.0, "val_loss": 17.353782057762146, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.28067135810852, "training_acc": 53.0, "val_loss": 17.321960628032684, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.48940634727478, "training_acc": 53.0, "val_loss": 17.311589419841766, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.17648696899414, "training_acc": 53.0, "val_loss": 17.35375225543976, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.52899932861328, "training_acc": 53.0, "val_loss": 17.363888025283813, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.19151163101196, "training_acc": 53.0, "val_loss": 17.346344888210297, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.70896625518799, "training_acc": 53.0, "val_loss": 17.334647476673126, "val_acc": 52.0}
