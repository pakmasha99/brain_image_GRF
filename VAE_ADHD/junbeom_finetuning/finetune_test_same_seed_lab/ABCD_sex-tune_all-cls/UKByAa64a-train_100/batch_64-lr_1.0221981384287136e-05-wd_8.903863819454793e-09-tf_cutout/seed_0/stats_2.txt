"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23914432525635, "training_acc": 53.0, "val_loss": 17.354387044906616, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.40720295906067, "training_acc": 53.0, "val_loss": 17.321327328681946, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18216967582703, "training_acc": 53.0, "val_loss": 17.31712371110916, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.03955268859863, "training_acc": 53.0, "val_loss": 17.312106490135193, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.0263123512268, "training_acc": 53.0, "val_loss": 17.35805720090866, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.86203026771545, "training_acc": 53.0, "val_loss": 17.3263818025589, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.8305549621582, "training_acc": 53.0, "val_loss": 17.315585911273956, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.00845980644226, "training_acc": 53.0, "val_loss": 17.310097813606262, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.71458721160889, "training_acc": 53.0, "val_loss": 17.276395857334137, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.69621443748474, "training_acc": 53.0, "val_loss": 17.30857789516449, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.6114730834961, "training_acc": 53.0, "val_loss": 17.345473170280457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.6669991016388, "training_acc": 53.0, "val_loss": 17.316436767578125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.64599823951721, "training_acc": 53.0, "val_loss": 17.281097173690796, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.58907437324524, "training_acc": 53.0, "val_loss": 17.297911643981934, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.37148404121399, "training_acc": 53.0, "val_loss": 17.31269061565399, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.57950472831726, "training_acc": 53.0, "val_loss": 17.27185845375061, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.37735366821289, "training_acc": 53.0, "val_loss": 17.27469563484192, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.11440587043762, "training_acc": 53.0, "val_loss": 17.28224754333496, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.96475958824158, "training_acc": 53.0, "val_loss": 17.27983057498932, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.96153974533081, "training_acc": 53.0, "val_loss": 17.266397178173065, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.04434990882874, "training_acc": 62.0, "val_loss": 17.225363850593567, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.8375096321106, "training_acc": 53.0, "val_loss": 17.27607250213623, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.97866463661194, "training_acc": 53.0, "val_loss": 17.28624999523163, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.41706871986389, "training_acc": 55.0, "val_loss": 17.247065901756287, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.29289722442627, "training_acc": 58.0, "val_loss": 17.273101210594177, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.06807780265808, "training_acc": 53.0, "val_loss": 17.206086218357086, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.19835782051086, "training_acc": 69.0, "val_loss": 17.22147762775421, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.99195504188538, "training_acc": 65.0, "val_loss": 17.3547625541687, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.39622187614441, "training_acc": 53.0, "val_loss": 17.343781888484955, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.4087405204773, "training_acc": 53.0, "val_loss": 17.273999750614166, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.94286823272705, "training_acc": 55.0, "val_loss": 17.249587178230286, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.30234718322754, "training_acc": 73.0, "val_loss": 17.21009761095047, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.28149127960205, "training_acc": 67.0, "val_loss": 17.25839525461197, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.55368375778198, "training_acc": 57.0, "val_loss": 17.21155196428299, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.97951579093933, "training_acc": 66.0, "val_loss": 17.24841296672821, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.30789494514465, "training_acc": 54.0, "val_loss": 17.177219688892365, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.74844670295715, "training_acc": 75.0, "val_loss": 17.180296778678894, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.8752133846283, "training_acc": 78.0, "val_loss": 17.229467630386353, "val_acc": 52.0}
{"epoch": 38, "training_loss": 64.69130778312683, "training_acc": 73.0, "val_loss": 17.251388728618622, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.58198237419128, "training_acc": 74.0, "val_loss": 17.166148126125336, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.52267384529114, "training_acc": 79.0, "val_loss": 17.189283668994904, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.26132225990295, "training_acc": 74.0, "val_loss": 17.337219417095184, "val_acc": 52.0}
{"epoch": 42, "training_loss": 63.73327994346619, "training_acc": 67.0, "val_loss": 17.51948446035385, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.83878684043884, "training_acc": 52.0, "val_loss": 17.342358827590942, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.34474682807922, "training_acc": 51.0, "val_loss": 17.30196177959442, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.88467788696289, "training_acc": 53.0, "val_loss": 17.289206385612488, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.0071074962616, "training_acc": 53.0, "val_loss": 17.28166937828064, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.92790603637695, "training_acc": 53.0, "val_loss": 17.288842797279358, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.97762703895569, "training_acc": 53.0, "val_loss": 17.290346324443817, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.94029307365417, "training_acc": 53.0, "val_loss": 17.2892227768898, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.76035666465759, "training_acc": 53.0, "val_loss": 17.287178337574005, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.65295600891113, "training_acc": 53.0, "val_loss": 17.283742129802704, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.74706792831421, "training_acc": 53.0, "val_loss": 17.28445440530777, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.62490773200989, "training_acc": 53.0, "val_loss": 17.28205382823944, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.6142008304596, "training_acc": 53.0, "val_loss": 17.274460196495056, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.37237501144409, "training_acc": 53.0, "val_loss": 17.272856831550598, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.37901258468628, "training_acc": 54.0, "val_loss": 17.27191060781479, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.26564073562622, "training_acc": 53.0, "val_loss": 17.266231775283813, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.3669228553772, "training_acc": 53.0, "val_loss": 17.260459065437317, "val_acc": 52.0}
