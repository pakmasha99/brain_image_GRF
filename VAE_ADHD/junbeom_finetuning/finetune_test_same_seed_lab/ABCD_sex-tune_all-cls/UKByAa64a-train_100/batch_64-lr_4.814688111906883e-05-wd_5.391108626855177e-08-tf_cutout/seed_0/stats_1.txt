"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.54721641540527, "training_acc": 51.0, "val_loss": 17.34790802001953, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.42441034317017, "training_acc": 41.0, "val_loss": 17.308618128299713, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.10559701919556, "training_acc": 53.0, "val_loss": 17.639875411987305, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.68220615386963, "training_acc": 53.0, "val_loss": 17.406825721263885, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4757239818573, "training_acc": 53.0, "val_loss": 17.352813482284546, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15989422798157, "training_acc": 53.0, "val_loss": 17.341865599155426, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24094796180725, "training_acc": 53.0, "val_loss": 17.33328551054001, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.00596737861633, "training_acc": 53.0, "val_loss": 17.316535115242004, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2189519405365, "training_acc": 53.0, "val_loss": 17.318660020828247, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21170544624329, "training_acc": 48.0, "val_loss": 17.33294576406479, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07494759559631, "training_acc": 52.0, "val_loss": 17.3135444521904, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.91757988929749, "training_acc": 53.0, "val_loss": 17.382587492465973, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09064197540283, "training_acc": 53.0, "val_loss": 17.390871047973633, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.70387625694275, "training_acc": 53.0, "val_loss": 17.325398325920105, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.06744170188904, "training_acc": 53.0, "val_loss": 17.33659654855728, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.89657735824585, "training_acc": 53.0, "val_loss": 17.305083572864532, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.88348817825317, "training_acc": 55.0, "val_loss": 17.356076836586, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17377185821533, "training_acc": 49.0, "val_loss": 17.338691651821136, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.9029610157013, "training_acc": 62.0, "val_loss": 17.337748408317566, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.69024801254272, "training_acc": 53.0, "val_loss": 17.37137734889984, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.82744598388672, "training_acc": 53.0, "val_loss": 17.372621595859528, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.91862154006958, "training_acc": 53.0, "val_loss": 17.34808087348938, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.73715949058533, "training_acc": 53.0, "val_loss": 17.355994880199432, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.64195990562439, "training_acc": 53.0, "val_loss": 17.329920828342438, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.26529622077942, "training_acc": 48.0, "val_loss": 17.336413264274597, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.66875958442688, "training_acc": 51.0, "val_loss": 17.38475114107132, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.56088614463806, "training_acc": 53.0, "val_loss": 17.443841695785522, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.75273609161377, "training_acc": 53.0, "val_loss": 17.381709814071655, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.26482272148132, "training_acc": 53.0, "val_loss": 17.334088683128357, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.31985902786255, "training_acc": 60.0, "val_loss": 17.386741936206818, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.81985425949097, "training_acc": 50.0, "val_loss": 17.419157922267914, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.64965152740479, "training_acc": 51.0, "val_loss": 17.344844341278076, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.1465744972229, "training_acc": 52.0, "val_loss": 17.414437234401703, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.11613416671753, "training_acc": 53.0, "val_loss": 17.35658198595047, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.19427633285522, "training_acc": 57.0, "val_loss": 17.343929409980774, "val_acc": 52.0}
