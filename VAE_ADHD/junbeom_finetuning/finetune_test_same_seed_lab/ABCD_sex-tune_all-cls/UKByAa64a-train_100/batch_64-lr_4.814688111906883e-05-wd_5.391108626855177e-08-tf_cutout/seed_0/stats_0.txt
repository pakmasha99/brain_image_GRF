"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.87710452079773, "training_acc": 50.0, "val_loss": 17.322923243045807, "val_acc": 56.0}
{"epoch": 1, "training_loss": 68.94229173660278, "training_acc": 52.0, "val_loss": 17.397765815258026, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.41029095649719, "training_acc": 52.0, "val_loss": 18.081729114055634, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.20608162879944, "training_acc": 48.0, "val_loss": 17.595981061458588, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.18735480308533, "training_acc": 50.0, "val_loss": 17.233599722385406, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.05491900444031, "training_acc": 52.0, "val_loss": 17.2194242477417, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26874494552612, "training_acc": 52.0, "val_loss": 17.46618300676346, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.46925950050354, "training_acc": 50.0, "val_loss": 17.551307380199432, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.72164702415466, "training_acc": 44.0, "val_loss": 17.30363368988037, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.00037884712219, "training_acc": 52.0, "val_loss": 17.262685298919678, "val_acc": 56.0}
{"epoch": 10, "training_loss": 68.9831612110138, "training_acc": 52.0, "val_loss": 17.263224720954895, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.92540669441223, "training_acc": 52.0, "val_loss": 17.269787192344666, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.83764338493347, "training_acc": 52.0, "val_loss": 17.322705686092377, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.75980019569397, "training_acc": 57.0, "val_loss": 17.40228235721588, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.52454876899719, "training_acc": 64.0, "val_loss": 17.32175052165985, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.40080881118774, "training_acc": 53.0, "val_loss": 17.281906306743622, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.41901898384094, "training_acc": 52.0, "val_loss": 17.359694838523865, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.3036777973175, "training_acc": 53.0, "val_loss": 17.629626393318176, "val_acc": 56.0}
{"epoch": 18, "training_loss": 67.95944905281067, "training_acc": 60.0, "val_loss": 17.37106144428253, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.37762546539307, "training_acc": 52.0, "val_loss": 17.40962564945221, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.36018872261047, "training_acc": 52.0, "val_loss": 17.841804027557373, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.14699959754944, "training_acc": 62.0, "val_loss": 17.44823455810547, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.32548499107361, "training_acc": 52.0, "val_loss": 17.420966923236847, "val_acc": 56.0}
{"epoch": 23, "training_loss": 66.39638924598694, "training_acc": 61.0, "val_loss": 18.819701671600342, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.56342124938965, "training_acc": 49.0, "val_loss": 17.656634747982025, "val_acc": 56.0}
