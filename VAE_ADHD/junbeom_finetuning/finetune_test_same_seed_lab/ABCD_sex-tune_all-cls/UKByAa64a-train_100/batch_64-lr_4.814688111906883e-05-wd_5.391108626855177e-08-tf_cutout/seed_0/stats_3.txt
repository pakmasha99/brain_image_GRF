"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.26281905174255, "training_acc": 43.0, "val_loss": 17.40705817937851, "val_acc": 52.0}
{"epoch": 1, "training_loss": 74.43520760536194, "training_acc": 61.0, "val_loss": 17.450574040412903, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24362540245056, "training_acc": 49.0, "val_loss": 17.421913146972656, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.4728844165802, "training_acc": 47.0, "val_loss": 17.338813841342926, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.5804238319397, "training_acc": 53.0, "val_loss": 17.42253005504608, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.37235999107361, "training_acc": 53.0, "val_loss": 17.291200160980225, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2137520313263, "training_acc": 50.0, "val_loss": 17.323105037212372, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.25208592414856, "training_acc": 58.0, "val_loss": 17.321941256523132, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13017344474792, "training_acc": 53.0, "val_loss": 17.34292507171631, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.85250043869019, "training_acc": 51.0, "val_loss": 17.32032299041748, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.86567163467407, "training_acc": 53.0, "val_loss": 17.39596128463745, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.2579915523529, "training_acc": 53.0, "val_loss": 17.500095069408417, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.51913332939148, "training_acc": 53.0, "val_loss": 17.340609431266785, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.71351933479309, "training_acc": 53.0, "val_loss": 17.369087040424347, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.94065165519714, "training_acc": 47.0, "val_loss": 17.44718849658966, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.37982130050659, "training_acc": 47.0, "val_loss": 17.331960797309875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.03985261917114, "training_acc": 53.0, "val_loss": 17.386478185653687, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.07177090644836, "training_acc": 53.0, "val_loss": 17.407944798469543, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18793106079102, "training_acc": 53.0, "val_loss": 17.377440631389618, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.98007941246033, "training_acc": 53.0, "val_loss": 17.328883707523346, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11437201499939, "training_acc": 51.0, "val_loss": 17.367233335971832, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.32017827033997, "training_acc": 47.0, "val_loss": 17.35236942768097, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.23811054229736, "training_acc": 49.0, "val_loss": 17.33088791370392, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.88443326950073, "training_acc": 53.0, "val_loss": 17.354433238506317, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.89717030525208, "training_acc": 53.0, "val_loss": 17.387793958187103, "val_acc": 52.0}
