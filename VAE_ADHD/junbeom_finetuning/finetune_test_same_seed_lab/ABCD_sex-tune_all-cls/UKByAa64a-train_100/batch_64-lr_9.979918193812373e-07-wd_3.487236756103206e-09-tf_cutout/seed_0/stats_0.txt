"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39168429374695, "training_acc": 52.0, "val_loss": 17.274954915046692, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.21137547492981, "training_acc": 52.0, "val_loss": 17.279018461704254, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.18729281425476, "training_acc": 52.0, "val_loss": 17.2774538397789, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.1662666797638, "training_acc": 52.0, "val_loss": 17.273947596549988, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.28851819038391, "training_acc": 52.0, "val_loss": 17.277728021144867, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23850750923157, "training_acc": 52.0, "val_loss": 17.284101247787476, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.14228057861328, "training_acc": 52.0, "val_loss": 17.281778156757355, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24868202209473, "training_acc": 52.0, "val_loss": 17.280028760433197, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.14285182952881, "training_acc": 52.0, "val_loss": 17.276546359062195, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.14489579200745, "training_acc": 52.0, "val_loss": 17.275020480155945, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.12311482429504, "training_acc": 52.0, "val_loss": 17.278781533241272, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.0736129283905, "training_acc": 52.0, "val_loss": 17.283442616462708, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.95782279968262, "training_acc": 52.0, "val_loss": 17.285050451755524, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.016361951828, "training_acc": 52.0, "val_loss": 17.281806468963623, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.050302028656, "training_acc": 52.0, "val_loss": 17.28055030107498, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.04968738555908, "training_acc": 52.0, "val_loss": 17.27970838546753, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.0107536315918, "training_acc": 52.0, "val_loss": 17.27202534675598, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.9399037361145, "training_acc": 52.0, "val_loss": 17.26554036140442, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.87272262573242, "training_acc": 52.0, "val_loss": 17.260505259037018, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.91338276863098, "training_acc": 52.0, "val_loss": 17.255817353725433, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.8851866722107, "training_acc": 52.0, "val_loss": 17.25315749645233, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.8779149055481, "training_acc": 52.0, "val_loss": 17.25212186574936, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.93320941925049, "training_acc": 52.0, "val_loss": 17.249979078769684, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.92390847206116, "training_acc": 52.0, "val_loss": 17.249388992786407, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.95440793037415, "training_acc": 52.0, "val_loss": 17.251858115196228, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.90663313865662, "training_acc": 52.0, "val_loss": 17.253965139389038, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.59745478630066, "training_acc": 52.0, "val_loss": 17.25500524044037, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.90580081939697, "training_acc": 52.0, "val_loss": 17.258334159851074, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.8680419921875, "training_acc": 52.0, "val_loss": 17.266111075878143, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.83653116226196, "training_acc": 52.0, "val_loss": 17.271731793880463, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.82666397094727, "training_acc": 52.0, "val_loss": 17.276962101459503, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.81131052970886, "training_acc": 52.0, "val_loss": 17.27816015481949, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.81925702095032, "training_acc": 52.0, "val_loss": 17.27607697248459, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.50895023345947, "training_acc": 52.0, "val_loss": 17.272645235061646, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.85718321800232, "training_acc": 52.0, "val_loss": 17.27094054222107, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.71310448646545, "training_acc": 52.0, "val_loss": 17.272739112377167, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.59747123718262, "training_acc": 52.0, "val_loss": 17.274686694145203, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.64239573478699, "training_acc": 52.0, "val_loss": 17.276377975940704, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.68999600410461, "training_acc": 52.0, "val_loss": 17.27203279733658, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.7681655883789, "training_acc": 52.0, "val_loss": 17.26442277431488, "val_acc": 56.0}
{"epoch": 40, "training_loss": 68.76078343391418, "training_acc": 52.0, "val_loss": 17.258472740650177, "val_acc": 56.0}
{"epoch": 41, "training_loss": 68.73961329460144, "training_acc": 52.0, "val_loss": 17.25275069475174, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.64996337890625, "training_acc": 52.0, "val_loss": 17.25323498249054, "val_acc": 56.0}
