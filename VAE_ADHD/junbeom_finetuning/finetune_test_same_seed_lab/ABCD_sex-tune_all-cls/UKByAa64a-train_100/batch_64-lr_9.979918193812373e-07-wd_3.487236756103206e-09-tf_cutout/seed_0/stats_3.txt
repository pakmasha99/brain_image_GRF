"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.16857600212097, "training_acc": 53.0, "val_loss": 17.41107851266861, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.20338153839111, "training_acc": 53.0, "val_loss": 17.4087792634964, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18644452095032, "training_acc": 53.0, "val_loss": 17.40952581167221, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15063977241516, "training_acc": 53.0, "val_loss": 17.40744411945343, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.03918433189392, "training_acc": 53.0, "val_loss": 17.412172257900238, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.03232884407043, "training_acc": 53.0, "val_loss": 17.408370971679688, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.10098338127136, "training_acc": 53.0, "val_loss": 17.401523888111115, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.06795024871826, "training_acc": 53.0, "val_loss": 17.397400736808777, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.0403094291687, "training_acc": 53.0, "val_loss": 17.39818900823593, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.07874989509583, "training_acc": 53.0, "val_loss": 17.401185631752014, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.06295418739319, "training_acc": 53.0, "val_loss": 17.398701608181, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.91441774368286, "training_acc": 53.0, "val_loss": 17.39756166934967, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.9941794872284, "training_acc": 53.0, "val_loss": 17.396876215934753, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.98550009727478, "training_acc": 53.0, "val_loss": 17.393633723258972, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.00389885902405, "training_acc": 53.0, "val_loss": 17.387622594833374, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10635757446289, "training_acc": 53.0, "val_loss": 17.384791374206543, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.01029539108276, "training_acc": 53.0, "val_loss": 17.38247573375702, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.84431219100952, "training_acc": 53.0, "val_loss": 17.382235825061798, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.79217529296875, "training_acc": 53.0, "val_loss": 17.382726073265076, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.91264748573303, "training_acc": 53.0, "val_loss": 17.382819950580597, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.8293468952179, "training_acc": 53.0, "val_loss": 17.382128536701202, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.81339287757874, "training_acc": 53.0, "val_loss": 17.386844754219055, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.77102303504944, "training_acc": 53.0, "val_loss": 17.390216886997223, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.92111206054688, "training_acc": 53.0, "val_loss": 17.391473054885864, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.83410143852234, "training_acc": 53.0, "val_loss": 17.390404641628265, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.53032994270325, "training_acc": 53.0, "val_loss": 17.391620576381683, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.6982810497284, "training_acc": 53.0, "val_loss": 17.39577203989029, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.77391505241394, "training_acc": 53.0, "val_loss": 17.40042120218277, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.67443442344666, "training_acc": 53.0, "val_loss": 17.406608164310455, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.44935631752014, "training_acc": 53.0, "val_loss": 17.407839000225067, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.54470181465149, "training_acc": 53.0, "val_loss": 17.404422163963318, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.70627903938293, "training_acc": 53.0, "val_loss": 17.409105598926544, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.6861617565155, "training_acc": 53.0, "val_loss": 17.410758137702942, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.50846695899963, "training_acc": 53.0, "val_loss": 17.412398755550385, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.70621800422668, "training_acc": 53.0, "val_loss": 17.41134822368622, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.45153450965881, "training_acc": 53.0, "val_loss": 17.412883043289185, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.58024716377258, "training_acc": 53.0, "val_loss": 17.416079342365265, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.46402382850647, "training_acc": 53.0, "val_loss": 17.417655885219574, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.56412816047668, "training_acc": 53.0, "val_loss": 17.420844733715057, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.50255250930786, "training_acc": 53.0, "val_loss": 17.423808574676514, "val_acc": 52.0}
