"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.85532879829407, "training_acc": 52.0, "val_loss": 17.368867993354797, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.03046536445618, "training_acc": 53.0, "val_loss": 17.44677573442459, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.26402592658997, "training_acc": 55.0, "val_loss": 17.569202184677124, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.85037088394165, "training_acc": 53.0, "val_loss": 17.337948083877563, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16409373283386, "training_acc": 53.0, "val_loss": 17.309556901454926, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.41590189933777, "training_acc": 53.0, "val_loss": 17.311887443065643, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.8034131526947, "training_acc": 41.0, "val_loss": 17.31545627117157, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.94771528244019, "training_acc": 53.0, "val_loss": 17.504562437534332, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.91000366210938, "training_acc": 53.0, "val_loss": 17.537885904312134, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.85892820358276, "training_acc": 53.0, "val_loss": 17.46348887681961, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.60826182365417, "training_acc": 53.0, "val_loss": 17.345473170280457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.26143455505371, "training_acc": 53.0, "val_loss": 17.308738827705383, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19199681282043, "training_acc": 53.0, "val_loss": 17.344501614570618, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.66658520698547, "training_acc": 41.0, "val_loss": 17.321616411209106, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38011240959167, "training_acc": 47.0, "val_loss": 17.31497496366501, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13918256759644, "training_acc": 53.0, "val_loss": 17.33177900314331, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22093510627747, "training_acc": 53.0, "val_loss": 17.420026659965515, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.39729404449463, "training_acc": 53.0, "val_loss": 17.365916073322296, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.21494340896606, "training_acc": 53.0, "val_loss": 17.31470823287964, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.39844846725464, "training_acc": 53.0, "val_loss": 17.341487109661102, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30264902114868, "training_acc": 53.0, "val_loss": 17.317073047161102, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.0880777835846, "training_acc": 53.0, "val_loss": 17.317867279052734, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.40684604644775, "training_acc": 47.0, "val_loss": 17.33356863260269, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.35037231445312, "training_acc": 47.0, "val_loss": 17.30940192937851, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14236092567444, "training_acc": 53.0, "val_loss": 17.318150401115417, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12076544761658, "training_acc": 53.0, "val_loss": 17.350104451179504, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25043964385986, "training_acc": 53.0, "val_loss": 17.363815009593964, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2956874370575, "training_acc": 53.0, "val_loss": 17.370320856571198, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.21778988838196, "training_acc": 53.0, "val_loss": 17.322726547718048, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.65369391441345, "training_acc": 53.0, "val_loss": 17.30921119451523, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15136337280273, "training_acc": 53.0, "val_loss": 17.311397194862366, "val_acc": 52.0}
