"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.30965900421143, "training_acc": 52.0, "val_loss": 17.34539121389389, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.64259076118469, "training_acc": 49.0, "val_loss": 17.381572723388672, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.56618046760559, "training_acc": 49.0, "val_loss": 17.38286316394806, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.5727424621582, "training_acc": 53.0, "val_loss": 17.37678050994873, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.39915490150452, "training_acc": 53.0, "val_loss": 17.38402545452118, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.55796003341675, "training_acc": 53.0, "val_loss": 17.318786680698395, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.34466528892517, "training_acc": 49.0, "val_loss": 17.331300675868988, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29058384895325, "training_acc": 51.0, "val_loss": 17.31141209602356, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21971869468689, "training_acc": 53.0, "val_loss": 17.37982928752899, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.17804646492004, "training_acc": 53.0, "val_loss": 17.462874948978424, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.68048524856567, "training_acc": 53.0, "val_loss": 17.309781908988953, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15257978439331, "training_acc": 53.0, "val_loss": 17.315688729286194, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.57465720176697, "training_acc": 53.0, "val_loss": 17.31494814157486, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22076916694641, "training_acc": 53.0, "val_loss": 17.33308434486389, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.4605324268341, "training_acc": 43.0, "val_loss": 17.317424714565277, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29624199867249, "training_acc": 53.0, "val_loss": 17.31041520833969, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.32379174232483, "training_acc": 53.0, "val_loss": 17.308707535266876, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20109939575195, "training_acc": 53.0, "val_loss": 17.309707403182983, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16030478477478, "training_acc": 53.0, "val_loss": 17.312778532505035, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11439943313599, "training_acc": 53.0, "val_loss": 17.34117418527603, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.33707332611084, "training_acc": 53.0, "val_loss": 17.354056239128113, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1885871887207, "training_acc": 53.0, "val_loss": 17.310842871665955, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14565563201904, "training_acc": 53.0, "val_loss": 17.313426733016968, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21776819229126, "training_acc": 53.0, "val_loss": 17.31134206056595, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21349573135376, "training_acc": 53.0, "val_loss": 17.30889081954956, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.44902801513672, "training_acc": 53.0, "val_loss": 17.312948405742645, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.03453803062439, "training_acc": 53.0, "val_loss": 17.391133308410645, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.49230647087097, "training_acc": 53.0, "val_loss": 17.471401393413544, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.7473373413086, "training_acc": 53.0, "val_loss": 17.361579835414886, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.99898600578308, "training_acc": 53.0, "val_loss": 17.33406037092209, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.89424920082092, "training_acc": 47.0, "val_loss": 17.444278299808502, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.83077669143677, "training_acc": 47.0, "val_loss": 17.34171211719513, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.3140184879303, "training_acc": 49.0, "val_loss": 17.333918809890747, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.09957599639893, "training_acc": 53.0, "val_loss": 17.44314879179001, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.68862175941467, "training_acc": 53.0, "val_loss": 17.475375533103943, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.56576681137085, "training_acc": 53.0, "val_loss": 17.34144538640976, "val_acc": 52.0}
