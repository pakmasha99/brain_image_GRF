"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.67577195167542, "training_acc": 45.0, "val_loss": 17.35009402036667, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17917680740356, "training_acc": 53.0, "val_loss": 17.353995144367218, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50262117385864, "training_acc": 49.0, "val_loss": 17.471587657928467, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.55761790275574, "training_acc": 53.0, "val_loss": 17.340654134750366, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.11931276321411, "training_acc": 53.0, "val_loss": 17.308786511421204, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25933790206909, "training_acc": 51.0, "val_loss": 17.366234958171844, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.43927145004272, "training_acc": 49.0, "val_loss": 17.309372127056122, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4277229309082, "training_acc": 53.0, "val_loss": 17.32715219259262, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.23852133750916, "training_acc": 53.0, "val_loss": 17.309966683387756, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23247909545898, "training_acc": 51.0, "val_loss": 17.34483689069748, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.37498331069946, "training_acc": 49.0, "val_loss": 17.31003224849701, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12635922431946, "training_acc": 53.0, "val_loss": 17.3438623547554, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.26234841346741, "training_acc": 53.0, "val_loss": 17.414340376853943, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.46091842651367, "training_acc": 53.0, "val_loss": 17.442302405834198, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38664412498474, "training_acc": 53.0, "val_loss": 17.320342361927032, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.01716160774231, "training_acc": 53.0, "val_loss": 17.343345284461975, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.46562552452087, "training_acc": 47.0, "val_loss": 17.37784892320633, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.52355694770813, "training_acc": 47.0, "val_loss": 17.311695218086243, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.46455097198486, "training_acc": 53.0, "val_loss": 17.372870445251465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.28708004951477, "training_acc": 53.0, "val_loss": 17.378680408000946, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.683030128479, "training_acc": 53.0, "val_loss": 17.331813275814056, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.34732055664062, "training_acc": 53.0, "val_loss": 17.338337004184723, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15842747688293, "training_acc": 53.0, "val_loss": 17.30898767709732, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.50979709625244, "training_acc": 53.0, "val_loss": 17.313216626644135, "val_acc": 52.0}
