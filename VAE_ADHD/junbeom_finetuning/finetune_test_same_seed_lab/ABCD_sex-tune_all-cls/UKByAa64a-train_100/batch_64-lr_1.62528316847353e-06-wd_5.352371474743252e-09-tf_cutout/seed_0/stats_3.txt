"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.22700548171997, "training_acc": 53.0, "val_loss": 17.340579628944397, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17606663703918, "training_acc": 53.0, "val_loss": 17.34347939491272, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24177503585815, "training_acc": 53.0, "val_loss": 17.340479791164398, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.11255407333374, "training_acc": 53.0, "val_loss": 17.331553995609283, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.054447889328, "training_acc": 53.0, "val_loss": 17.334188520908356, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10290956497192, "training_acc": 53.0, "val_loss": 17.337536811828613, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14604592323303, "training_acc": 53.0, "val_loss": 17.337219417095184, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.02835512161255, "training_acc": 53.0, "val_loss": 17.335636913776398, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.99994230270386, "training_acc": 53.0, "val_loss": 17.334291338920593, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.98149752616882, "training_acc": 53.0, "val_loss": 17.330744862556458, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.96074414253235, "training_acc": 53.0, "val_loss": 17.32652485370636, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.89509582519531, "training_acc": 53.0, "val_loss": 17.327651381492615, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.82504606246948, "training_acc": 53.0, "val_loss": 17.325900495052338, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.86111044883728, "training_acc": 53.0, "val_loss": 17.324988543987274, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.82714009284973, "training_acc": 53.0, "val_loss": 17.326533794403076, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.69905638694763, "training_acc": 53.0, "val_loss": 17.32752025127411, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.72507786750793, "training_acc": 53.0, "val_loss": 17.32802540063858, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.71101427078247, "training_acc": 53.0, "val_loss": 17.322711646556854, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.83294105529785, "training_acc": 53.0, "val_loss": 17.32179820537567, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.63993120193481, "training_acc": 53.0, "val_loss": 17.32756197452545, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.68103814125061, "training_acc": 53.0, "val_loss": 17.335745692253113, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.62637782096863, "training_acc": 53.0, "val_loss": 17.33805388212204, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.65398907661438, "training_acc": 53.0, "val_loss": 17.342673242092133, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.57940912246704, "training_acc": 53.0, "val_loss": 17.345286905765533, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.7110857963562, "training_acc": 53.0, "val_loss": 17.35076904296875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.65807437896729, "training_acc": 53.0, "val_loss": 17.35202819108963, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.39554524421692, "training_acc": 53.0, "val_loss": 17.35106259584427, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.4848279953003, "training_acc": 53.0, "val_loss": 17.35236644744873, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.28191614151001, "training_acc": 53.0, "val_loss": 17.35469400882721, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.38051915168762, "training_acc": 53.0, "val_loss": 17.348632216453552, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.46474075317383, "training_acc": 53.0, "val_loss": 17.339511215686798, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.38448452949524, "training_acc": 53.0, "val_loss": 17.345057427883148, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.50021028518677, "training_acc": 53.0, "val_loss": 17.355942726135254, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.27120661735535, "training_acc": 53.0, "val_loss": 17.3640176653862, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.43994927406311, "training_acc": 53.0, "val_loss": 17.366375029087067, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.60787606239319, "training_acc": 53.0, "val_loss": 17.35827773809433, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.23719048500061, "training_acc": 53.0, "val_loss": 17.349225282669067, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.14856696128845, "training_acc": 53.0, "val_loss": 17.346860468387604, "val_acc": 52.0}
