"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39011788368225, "training_acc": 52.0, "val_loss": 17.275264859199524, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.21239900588989, "training_acc": 52.0, "val_loss": 17.281794548034668, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.18040537834167, "training_acc": 52.0, "val_loss": 17.281213402748108, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.15427994728088, "training_acc": 52.0, "val_loss": 17.280080914497375, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2127480506897, "training_acc": 52.0, "val_loss": 17.294566333293915, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.20226263999939, "training_acc": 52.0, "val_loss": 17.29743927717209, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.06241631507874, "training_acc": 52.0, "val_loss": 17.30175018310547, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.21277618408203, "training_acc": 52.0, "val_loss": 17.306217551231384, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.08458399772644, "training_acc": 52.0, "val_loss": 17.299632728099823, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.20266318321228, "training_acc": 52.0, "val_loss": 17.28811413049698, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.06132245063782, "training_acc": 52.0, "val_loss": 17.27750599384308, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.07891774177551, "training_acc": 52.0, "val_loss": 17.27316826581955, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.92281460762024, "training_acc": 52.0, "val_loss": 17.276306450366974, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.86445951461792, "training_acc": 52.0, "val_loss": 17.277060449123383, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.97417044639587, "training_acc": 52.0, "val_loss": 17.278510332107544, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.00403547286987, "training_acc": 52.0, "val_loss": 17.270343005657196, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.87878036499023, "training_acc": 52.0, "val_loss": 17.25795716047287, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.8981614112854, "training_acc": 52.0, "val_loss": 17.245589196681976, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.81528425216675, "training_acc": 52.0, "val_loss": 17.238911986351013, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.8258216381073, "training_acc": 52.0, "val_loss": 17.236118018627167, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.86460471153259, "training_acc": 52.0, "val_loss": 17.232705652713776, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.68105459213257, "training_acc": 52.0, "val_loss": 17.233070731163025, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.86202239990234, "training_acc": 52.0, "val_loss": 17.24114567041397, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.8463032245636, "training_acc": 52.0, "val_loss": 17.25829690694809, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.85344052314758, "training_acc": 52.0, "val_loss": 17.283958196640015, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.86253142356873, "training_acc": 52.0, "val_loss": 17.286472022533417, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.47041201591492, "training_acc": 52.0, "val_loss": 17.26917177438736, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.88427710533142, "training_acc": 52.0, "val_loss": 17.266643047332764, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.73310208320618, "training_acc": 52.0, "val_loss": 17.283332347869873, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.71583986282349, "training_acc": 52.0, "val_loss": 17.29959100484848, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.71010160446167, "training_acc": 53.0, "val_loss": 17.300134897232056, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.7546455860138, "training_acc": 53.0, "val_loss": 17.290668189525604, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.68432545661926, "training_acc": 53.0, "val_loss": 17.27376878261566, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.30190777778625, "training_acc": 53.0, "val_loss": 17.27181375026703, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.63976335525513, "training_acc": 53.0, "val_loss": 17.27868765592575, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.63300728797913, "training_acc": 52.0, "val_loss": 17.285408079624176, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.51858711242676, "training_acc": 53.0, "val_loss": 17.29019284248352, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.50039291381836, "training_acc": 53.0, "val_loss": 17.284560203552246, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.48822617530823, "training_acc": 52.0, "val_loss": 17.26633459329605, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.5736312866211, "training_acc": 52.0, "val_loss": 17.25180596113205, "val_acc": 56.0}
