"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.22716426849365, "training_acc": 53.0, "val_loss": 17.317362129688263, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15391254425049, "training_acc": 53.0, "val_loss": 17.320933938026428, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15746641159058, "training_acc": 53.0, "val_loss": 17.318589985370636, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05981779098511, "training_acc": 53.0, "val_loss": 17.314264178276062, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.00172472000122, "training_acc": 53.0, "val_loss": 17.31153428554535, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.00556087493896, "training_acc": 53.0, "val_loss": 17.31083244085312, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.95288896560669, "training_acc": 53.0, "val_loss": 17.293529212474823, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.87200593948364, "training_acc": 53.0, "val_loss": 17.280849814414978, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1020290851593, "training_acc": 53.0, "val_loss": 17.26815402507782, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.64972805976868, "training_acc": 53.0, "val_loss": 17.262659966945648, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.61416268348694, "training_acc": 53.0, "val_loss": 17.262767255306244, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.73010325431824, "training_acc": 53.0, "val_loss": 17.267657816410065, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.55044484138489, "training_acc": 53.0, "val_loss": 17.270247638225555, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.73552250862122, "training_acc": 53.0, "val_loss": 17.288070917129517, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.55978155136108, "training_acc": 53.0, "val_loss": 17.281803488731384, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.46830415725708, "training_acc": 53.0, "val_loss": 17.271849513053894, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.31902432441711, "training_acc": 53.0, "val_loss": 17.2539085149765, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.2353868484497, "training_acc": 53.0, "val_loss": 17.24914014339447, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.0977509021759, "training_acc": 53.0, "val_loss": 17.27661043405533, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.98907470703125, "training_acc": 53.0, "val_loss": 17.314782738685608, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.11350345611572, "training_acc": 53.0, "val_loss": 17.24734455347061, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.91429114341736, "training_acc": 53.0, "val_loss": 17.29409396648407, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.5819091796875, "training_acc": 53.0, "val_loss": 17.296817898750305, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.3729555606842, "training_acc": 53.0, "val_loss": 17.24845916032791, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.51908349990845, "training_acc": 54.0, "val_loss": 17.245639860630035, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.21804571151733, "training_acc": 62.0, "val_loss": 17.231306433677673, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.75059676170349, "training_acc": 53.0, "val_loss": 17.23603755235672, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.04329347610474, "training_acc": 59.0, "val_loss": 17.216163873672485, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.00896883010864, "training_acc": 65.0, "val_loss": 17.204539477825165, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.67141461372375, "training_acc": 61.0, "val_loss": 17.18757152557373, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.94013333320618, "training_acc": 56.0, "val_loss": 17.20612645149231, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.50531649589539, "training_acc": 59.0, "val_loss": 17.153112590312958, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.12818360328674, "training_acc": 67.0, "val_loss": 17.17725694179535, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.87527966499329, "training_acc": 62.0, "val_loss": 17.17618554830551, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.40326809883118, "training_acc": 67.0, "val_loss": 17.18325912952423, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.6513409614563, "training_acc": 66.0, "val_loss": 17.142778635025024, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.59947156906128, "training_acc": 62.0, "val_loss": 17.071959376335144, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.33362317085266, "training_acc": 82.0, "val_loss": 17.0871764421463, "val_acc": 52.0}
{"epoch": 38, "training_loss": 63.21461534500122, "training_acc": 77.0, "val_loss": 17.210009694099426, "val_acc": 52.0}
{"epoch": 39, "training_loss": 63.088722944259644, "training_acc": 55.0, "val_loss": 17.333945631980896, "val_acc": 52.0}
{"epoch": 40, "training_loss": 66.73587822914124, "training_acc": 74.0, "val_loss": 17.35810786485672, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.37019658088684, "training_acc": 83.0, "val_loss": 17.2123521566391, "val_acc": 52.0}
{"epoch": 42, "training_loss": 64.4983377456665, "training_acc": 55.0, "val_loss": 17.30283498764038, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.12210416793823, "training_acc": 66.0, "val_loss": 17.083579301834106, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62.86301040649414, "training_acc": 89.0, "val_loss": 17.122699320316315, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.821605920791626, "training_acc": 60.0, "val_loss": 17.03336089849472, "val_acc": 52.0}
{"epoch": 46, "training_loss": 60.42712330818176, "training_acc": 84.0, "val_loss": 17.054730653762817, "val_acc": 52.0}
{"epoch": 47, "training_loss": 61.64046549797058, "training_acc": 87.0, "val_loss": 17.09628701210022, "val_acc": 52.0}
{"epoch": 48, "training_loss": 61.13533902168274, "training_acc": 74.0, "val_loss": 17.08059012889862, "val_acc": 52.0}
{"epoch": 49, "training_loss": 58.73676776885986, "training_acc": 93.0, "val_loss": 17.24866032600403, "val_acc": 52.0}
{"epoch": 50, "training_loss": 59.70630216598511, "training_acc": 70.0, "val_loss": 16.993175446987152, "val_acc": 52.0}
{"epoch": 51, "training_loss": 57.63937497138977, "training_acc": 91.0, "val_loss": 17.000411450862885, "val_acc": 52.0}
{"epoch": 52, "training_loss": 57.6015625, "training_acc": 91.0, "val_loss": 17.078524827957153, "val_acc": 52.0}
{"epoch": 53, "training_loss": 58.21599531173706, "training_acc": 86.0, "val_loss": 17.108619213104248, "val_acc": 56.0}
{"epoch": 54, "training_loss": 55.92438292503357, "training_acc": 83.0, "val_loss": 17.106780409812927, "val_acc": 56.0}
{"epoch": 55, "training_loss": 55.99710488319397, "training_acc": 90.0, "val_loss": 16.958706080913544, "val_acc": 56.0}
{"epoch": 56, "training_loss": 54.39472150802612, "training_acc": 92.0, "val_loss": 17.185646295547485, "val_acc": 52.0}
{"epoch": 57, "training_loss": 53.510467529296875, "training_acc": 89.0, "val_loss": 17.15080291032791, "val_acc": 56.0}
{"epoch": 58, "training_loss": 54.140743017196655, "training_acc": 86.0, "val_loss": 17.4583837389946, "val_acc": 52.0}
{"epoch": 59, "training_loss": 55.75555920600891, "training_acc": 88.0, "val_loss": 17.21351593732834, "val_acc": 56.0}
{"epoch": 60, "training_loss": 51.750510931015015, "training_acc": 90.0, "val_loss": 16.97998046875, "val_acc": 52.0}
{"epoch": 61, "training_loss": 50.30741894245148, "training_acc": 95.0, "val_loss": 17.159883677959442, "val_acc": 56.0}
{"epoch": 62, "training_loss": 50.93636083602905, "training_acc": 94.0, "val_loss": 17.332759499549866, "val_acc": 56.0}
{"epoch": 63, "training_loss": 51.526833057403564, "training_acc": 91.0, "val_loss": 17.347799241542816, "val_acc": 56.0}
{"epoch": 64, "training_loss": 49.06244623661041, "training_acc": 91.0, "val_loss": 17.35232323408127, "val_acc": 56.0}
{"epoch": 65, "training_loss": 51.056413650512695, "training_acc": 94.0, "val_loss": 17.834952473640442, "val_acc": 56.0}
{"epoch": 66, "training_loss": 49.81857681274414, "training_acc": 88.0, "val_loss": 17.662063241004944, "val_acc": 56.0}
{"epoch": 67, "training_loss": 49.661680459976196, "training_acc": 94.0, "val_loss": 17.54816770553589, "val_acc": 52.0}
{"epoch": 68, "training_loss": 50.97280764579773, "training_acc": 88.0, "val_loss": 17.294219136238098, "val_acc": 48.0}
{"epoch": 69, "training_loss": 49.66203999519348, "training_acc": 86.0, "val_loss": 17.34458953142166, "val_acc": 48.0}
{"epoch": 70, "training_loss": 47.71493625640869, "training_acc": 94.0, "val_loss": 17.436185479164124, "val_acc": 56.0}
{"epoch": 71, "training_loss": 47.123470067977905, "training_acc": 93.0, "val_loss": 17.771407961845398, "val_acc": 56.0}
{"epoch": 72, "training_loss": 47.84952759742737, "training_acc": 90.0, "val_loss": 17.593669891357422, "val_acc": 60.0}
{"epoch": 73, "training_loss": 44.801143765449524, "training_acc": 97.0, "val_loss": 17.646943032741547, "val_acc": 56.0}
{"epoch": 74, "training_loss": 45.7490770816803, "training_acc": 94.0, "val_loss": 17.384569346904755, "val_acc": 56.0}
