"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38925647735596, "training_acc": 52.0, "val_loss": 17.323119938373566, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.34675645828247, "training_acc": 52.0, "val_loss": 17.322219908237457, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24904251098633, "training_acc": 55.0, "val_loss": 17.321422696113586, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32325434684753, "training_acc": 54.0, "val_loss": 17.320941388607025, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33269906044006, "training_acc": 51.0, "val_loss": 17.319871485233307, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20896482467651, "training_acc": 57.0, "val_loss": 17.318779230117798, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.34673810005188, "training_acc": 54.0, "val_loss": 17.31821745634079, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29850101470947, "training_acc": 50.0, "val_loss": 17.316749691963196, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12182354927063, "training_acc": 57.0, "val_loss": 17.315544188022614, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.31315398216248, "training_acc": 49.0, "val_loss": 17.3147052526474, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23607397079468, "training_acc": 55.0, "val_loss": 17.313262820243835, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16752457618713, "training_acc": 63.0, "val_loss": 17.312589287757874, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25456666946411, "training_acc": 52.0, "val_loss": 17.311887443065643, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04613161087036, "training_acc": 53.0, "val_loss": 17.31174886226654, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.99054765701294, "training_acc": 54.0, "val_loss": 17.311963438987732, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16386198997498, "training_acc": 53.0, "val_loss": 17.312133312225342, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06721472740173, "training_acc": 52.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18055653572083, "training_acc": 53.0, "val_loss": 17.312487959861755, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08537554740906, "training_acc": 52.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.04976320266724, "training_acc": 55.0, "val_loss": 17.31273978948593, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1355984210968, "training_acc": 52.0, "val_loss": 17.312893271446228, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.41743564605713, "training_acc": 51.0, "val_loss": 17.312657833099365, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12712502479553, "training_acc": 52.0, "val_loss": 17.313098907470703, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.97978925704956, "training_acc": 53.0, "val_loss": 17.31366664171219, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.06771969795227, "training_acc": 52.0, "val_loss": 17.313894629478455, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.0751359462738, "training_acc": 54.0, "val_loss": 17.314307391643524, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19107437133789, "training_acc": 51.0, "val_loss": 17.314903438091278, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10071778297424, "training_acc": 53.0, "val_loss": 17.31569766998291, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.0749180316925, "training_acc": 53.0, "val_loss": 17.31649786233902, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.08624219894409, "training_acc": 52.0, "val_loss": 17.31717437505722, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.04236841201782, "training_acc": 53.0, "val_loss": 17.31785237789154, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1573600769043, "training_acc": 53.0, "val_loss": 17.318053543567657, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.96483588218689, "training_acc": 53.0, "val_loss": 17.318187654018402, "val_acc": 52.0}
