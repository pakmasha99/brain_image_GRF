"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24076843261719, "training_acc": 51.0, "val_loss": 17.372651398181915, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.95414352416992, "training_acc": 53.0, "val_loss": 17.332598567008972, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.49448752403259, "training_acc": 53.0, "val_loss": 17.33277142047882, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2750735282898, "training_acc": 48.0, "val_loss": 17.30932593345642, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.34870481491089, "training_acc": 53.0, "val_loss": 17.32921153306961, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.49906706809998, "training_acc": 53.0, "val_loss": 17.325852811336517, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15153789520264, "training_acc": 53.0, "val_loss": 17.31751263141632, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.93908262252808, "training_acc": 41.0, "val_loss": 17.309893667697906, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.64994192123413, "training_acc": 53.0, "val_loss": 17.340774834156036, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17080426216125, "training_acc": 53.0, "val_loss": 17.31961965560913, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.45887899398804, "training_acc": 53.0, "val_loss": 17.31296330690384, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14560627937317, "training_acc": 53.0, "val_loss": 17.342807352542877, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19191861152649, "training_acc": 53.0, "val_loss": 17.3397034406662, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19334363937378, "training_acc": 53.0, "val_loss": 17.314045131206512, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20341777801514, "training_acc": 53.0, "val_loss": 17.310690879821777, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31478834152222, "training_acc": 53.0, "val_loss": 17.30862706899643, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2235791683197, "training_acc": 53.0, "val_loss": 17.33171045780182, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19449210166931, "training_acc": 53.0, "val_loss": 17.33362525701523, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15667366981506, "training_acc": 53.0, "val_loss": 17.31429696083069, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13487720489502, "training_acc": 53.0, "val_loss": 17.30891913175583, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17211103439331, "training_acc": 53.0, "val_loss": 17.308908700942993, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13613319396973, "training_acc": 53.0, "val_loss": 17.317339777946472, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12976455688477, "training_acc": 53.0, "val_loss": 17.333920300006866, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27871346473694, "training_acc": 53.0, "val_loss": 17.336879670619965, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20311450958252, "training_acc": 53.0, "val_loss": 17.311255633831024, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16693449020386, "training_acc": 53.0, "val_loss": 17.309199273586273, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14231967926025, "training_acc": 53.0, "val_loss": 17.313161492347717, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.30948638916016, "training_acc": 53.0, "val_loss": 17.317356169223785, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.39082455635071, "training_acc": 53.0, "val_loss": 17.348909378051758, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20327234268188, "training_acc": 53.0, "val_loss": 17.321716248989105, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.0969398021698, "training_acc": 53.0, "val_loss": 17.309042811393738, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.19260144233704, "training_acc": 53.0, "val_loss": 17.322121560573578, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.3529405593872, "training_acc": 49.0, "val_loss": 17.340244352817535, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.35196018218994, "training_acc": 47.0, "val_loss": 17.314080893993378, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.79521083831787, "training_acc": 53.0, "val_loss": 17.313440144062042, "val_acc": 52.0}
