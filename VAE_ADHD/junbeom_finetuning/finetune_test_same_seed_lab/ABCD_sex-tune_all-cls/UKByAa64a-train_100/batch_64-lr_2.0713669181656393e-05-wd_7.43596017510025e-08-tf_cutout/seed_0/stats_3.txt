"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.73883366584778, "training_acc": 53.0, "val_loss": 17.383261024951935, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.54272079467773, "training_acc": 53.0, "val_loss": 17.403551936149597, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.31901669502258, "training_acc": 53.0, "val_loss": 17.436425387859344, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.36268949508667, "training_acc": 53.0, "val_loss": 17.4296572804451, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.23760533332825, "training_acc": 53.0, "val_loss": 17.38545596599579, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.82165741920471, "training_acc": 53.0, "val_loss": 17.320796847343445, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.99791526794434, "training_acc": 53.0, "val_loss": 17.319461703300476, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15608620643616, "training_acc": 53.0, "val_loss": 17.319993674755096, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04437375068665, "training_acc": 53.0, "val_loss": 17.335200309753418, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.9206383228302, "training_acc": 53.0, "val_loss": 17.3502117395401, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.8836555480957, "training_acc": 53.0, "val_loss": 17.364905774593353, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0160140991211, "training_acc": 53.0, "val_loss": 17.361152172088623, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.83517575263977, "training_acc": 53.0, "val_loss": 17.347024381160736, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.79801106452942, "training_acc": 53.0, "val_loss": 17.353293299674988, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.74874114990234, "training_acc": 53.0, "val_loss": 17.39995777606964, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.51389527320862, "training_acc": 53.0, "val_loss": 17.407730221748352, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.66639256477356, "training_acc": 53.0, "val_loss": 17.40534007549286, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.68379664421082, "training_acc": 53.0, "val_loss": 17.417605221271515, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.45855784416199, "training_acc": 53.0, "val_loss": 17.35733598470688, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.25473833084106, "training_acc": 55.0, "val_loss": 17.387278378009796, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.44219660758972, "training_acc": 57.0, "val_loss": 17.352642118930817, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.16589522361755, "training_acc": 65.0, "val_loss": 17.418262362480164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.5362901687622, "training_acc": 55.0, "val_loss": 17.382682859897614, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.42767071723938, "training_acc": 72.0, "val_loss": 17.522665858268738, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.92026948928833, "training_acc": 64.0, "val_loss": 17.336781322956085, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.2171471118927, "training_acc": 71.0, "val_loss": 17.595916986465454, "val_acc": 52.0}
