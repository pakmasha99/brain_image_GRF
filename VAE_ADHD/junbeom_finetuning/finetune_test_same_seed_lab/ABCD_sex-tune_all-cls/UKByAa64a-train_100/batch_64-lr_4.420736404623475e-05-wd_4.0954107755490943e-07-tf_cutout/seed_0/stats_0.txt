"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.27813458442688, "training_acc": 52.0, "val_loss": 17.300529778003693, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.21707391738892, "training_acc": 52.0, "val_loss": 17.236553132534027, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.27109551429749, "training_acc": 52.0, "val_loss": 17.244066298007965, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.19682002067566, "training_acc": 52.0, "val_loss": 17.264121770858765, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.04556608200073, "training_acc": 54.0, "val_loss": 17.27920174598694, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.25678563117981, "training_acc": 53.0, "val_loss": 17.278258502483368, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.12289428710938, "training_acc": 51.0, "val_loss": 17.333072423934937, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.1681489944458, "training_acc": 56.0, "val_loss": 17.285755276679993, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.4766891002655, "training_acc": 51.0, "val_loss": 17.20883846282959, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.14184904098511, "training_acc": 52.0, "val_loss": 17.27534681558609, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.14207673072815, "training_acc": 53.0, "val_loss": 17.327964305877686, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2160120010376, "training_acc": 53.0, "val_loss": 17.30317622423172, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.95677757263184, "training_acc": 52.0, "val_loss": 17.31703132390976, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.76274228096008, "training_acc": 55.0, "val_loss": 17.347383499145508, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.74420666694641, "training_acc": 56.0, "val_loss": 17.262226343154907, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.73418474197388, "training_acc": 52.0, "val_loss": 17.281682789325714, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.47126698493958, "training_acc": 54.0, "val_loss": 17.344024777412415, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.6898455619812, "training_acc": 55.0, "val_loss": 17.435818910598755, "val_acc": 56.0}
{"epoch": 18, "training_loss": 67.98078227043152, "training_acc": 63.0, "val_loss": 17.291268706321716, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.05081677436829, "training_acc": 54.0, "val_loss": 17.68064796924591, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.83812642097473, "training_acc": 54.0, "val_loss": 17.532479763031006, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.28486227989197, "training_acc": 68.0, "val_loss": 17.28885769844055, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.67195320129395, "training_acc": 52.0, "val_loss": 17.235642671585083, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.90980195999146, "training_acc": 53.0, "val_loss": 17.300495505332947, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.96293187141418, "training_acc": 52.0, "val_loss": 17.408306896686554, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.21610975265503, "training_acc": 48.0, "val_loss": 17.44549125432968, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.35147619247437, "training_acc": 47.0, "val_loss": 17.365913093090057, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.00133204460144, "training_acc": 55.0, "val_loss": 17.449727654457092, "val_acc": 56.0}
