"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2588243484497, "training_acc": 53.0, "val_loss": 17.368634045124054, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15348696708679, "training_acc": 53.0, "val_loss": 17.319196462631226, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.06813931465149, "training_acc": 53.0, "val_loss": 17.310382425785065, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.11907601356506, "training_acc": 53.0, "val_loss": 17.290538549423218, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.47001624107361, "training_acc": 47.0, "val_loss": 17.289835214614868, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.30969095230103, "training_acc": 54.0, "val_loss": 17.317214608192444, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.195876121521, "training_acc": 53.0, "val_loss": 17.314612865447998, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11875891685486, "training_acc": 53.0, "val_loss": 17.306840419769287, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18797397613525, "training_acc": 53.0, "val_loss": 17.308352887630463, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13491415977478, "training_acc": 53.0, "val_loss": 17.31124520301819, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18940758705139, "training_acc": 53.0, "val_loss": 17.31555461883545, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10597848892212, "training_acc": 53.0, "val_loss": 17.334209382534027, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.36231207847595, "training_acc": 53.0, "val_loss": 17.35181361436844, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.29051375389099, "training_acc": 53.0, "val_loss": 17.32652187347412, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13384342193604, "training_acc": 53.0, "val_loss": 17.320111393928528, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.08778882026672, "training_acc": 53.0, "val_loss": 17.311488091945648, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.08304333686829, "training_acc": 53.0, "val_loss": 17.306457459926605, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12361454963684, "training_acc": 53.0, "val_loss": 17.298004031181335, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12881016731262, "training_acc": 53.0, "val_loss": 17.29622483253479, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11171388626099, "training_acc": 53.0, "val_loss": 17.294330894947052, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.08531022071838, "training_acc": 53.0, "val_loss": 17.29452908039093, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.97445440292358, "training_acc": 53.0, "val_loss": 17.30688065290451, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.04461288452148, "training_acc": 53.0, "val_loss": 17.327332496643066, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.112220287323, "training_acc": 53.0, "val_loss": 17.306362092494965, "val_acc": 52.0}
