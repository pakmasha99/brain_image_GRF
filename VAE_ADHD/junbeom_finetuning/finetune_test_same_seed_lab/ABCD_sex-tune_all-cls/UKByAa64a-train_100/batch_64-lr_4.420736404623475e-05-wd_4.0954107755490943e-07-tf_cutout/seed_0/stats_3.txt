"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.16487193107605, "training_acc": 56.0, "val_loss": 17.320922017097473, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.25811314582825, "training_acc": 52.0, "val_loss": 17.331616580486298, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.4051125049591, "training_acc": 53.0, "val_loss": 17.322874069213867, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.33054065704346, "training_acc": 53.0, "val_loss": 17.322370409965515, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.26571536064148, "training_acc": 53.0, "val_loss": 17.300650477409363, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12821698188782, "training_acc": 53.0, "val_loss": 17.30923354625702, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12108278274536, "training_acc": 53.0, "val_loss": 17.330384254455566, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07225823402405, "training_acc": 53.0, "val_loss": 17.346617579460144, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.96439385414124, "training_acc": 53.0, "val_loss": 17.345407605171204, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.01146006584167, "training_acc": 53.0, "val_loss": 17.354358732700348, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.97936201095581, "training_acc": 53.0, "val_loss": 17.340770363807678, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.95008969306946, "training_acc": 53.0, "val_loss": 17.325156927108765, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.89788818359375, "training_acc": 53.0, "val_loss": 17.326030135154724, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.9011640548706, "training_acc": 53.0, "val_loss": 17.32955574989319, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.884765625, "training_acc": 53.0, "val_loss": 17.333951592445374, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.66622972488403, "training_acc": 53.0, "val_loss": 17.373299598693848, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.74419593811035, "training_acc": 53.0, "val_loss": 17.41013526916504, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.74277853965759, "training_acc": 53.0, "val_loss": 17.33657866716385, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.63684463500977, "training_acc": 53.0, "val_loss": 17.341701686382294, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.71136498451233, "training_acc": 54.0, "val_loss": 17.388516664505005, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.57572937011719, "training_acc": 53.0, "val_loss": 17.45588630437851, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.72931218147278, "training_acc": 53.0, "val_loss": 17.513588070869446, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.89508080482483, "training_acc": 53.0, "val_loss": 17.425566911697388, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.17193341255188, "training_acc": 53.0, "val_loss": 17.355887591838837, "val_acc": 52.0}
