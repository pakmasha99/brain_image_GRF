"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.37404012680054, "training_acc": 46.0, "val_loss": 17.372991144657135, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.33838295936584, "training_acc": 43.0, "val_loss": 17.360571026802063, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.27428078651428, "training_acc": 50.0, "val_loss": 17.33766943216324, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.07268261909485, "training_acc": 62.0, "val_loss": 17.321670055389404, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.11886167526245, "training_acc": 57.0, "val_loss": 17.318469285964966, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12578582763672, "training_acc": 52.0, "val_loss": 17.30910837650299, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1210389137268, "training_acc": 52.0, "val_loss": 17.299897968769073, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13539528846741, "training_acc": 53.0, "val_loss": 17.29271411895752, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.92945528030396, "training_acc": 54.0, "val_loss": 17.28324592113495, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12472248077393, "training_acc": 54.0, "val_loss": 17.276883125305176, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.80463147163391, "training_acc": 55.0, "val_loss": 17.269611358642578, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.9128406047821, "training_acc": 53.0, "val_loss": 17.267823219299316, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.7974750995636, "training_acc": 53.0, "val_loss": 17.262962460517883, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11424612998962, "training_acc": 52.0, "val_loss": 17.253102362155914, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.80007672309875, "training_acc": 53.0, "val_loss": 17.251242697238922, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.83473110198975, "training_acc": 53.0, "val_loss": 17.255504429340363, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.73808765411377, "training_acc": 53.0, "val_loss": 17.257627844810486, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.62409996986389, "training_acc": 53.0, "val_loss": 17.26153939962387, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.60869431495667, "training_acc": 53.0, "val_loss": 17.26195067167282, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.7559962272644, "training_acc": 53.0, "val_loss": 17.263133823871613, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.65679860115051, "training_acc": 54.0, "val_loss": 17.261970043182373, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.60362362861633, "training_acc": 54.0, "val_loss": 17.260639369487762, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.4144241809845, "training_acc": 55.0, "val_loss": 17.25977659225464, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.44196319580078, "training_acc": 53.0, "val_loss": 17.258816957473755, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.35939335823059, "training_acc": 54.0, "val_loss": 17.26386249065399, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.58681058883667, "training_acc": 53.0, "val_loss": 17.266201972961426, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.6261146068573, "training_acc": 53.0, "val_loss": 17.26657897233963, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.28738260269165, "training_acc": 53.0, "val_loss": 17.268463969230652, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.42163562774658, "training_acc": 54.0, "val_loss": 17.27021038532257, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.54131436347961, "training_acc": 53.0, "val_loss": 17.26720631122589, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.58269190788269, "training_acc": 55.0, "val_loss": 17.267805337905884, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.42613101005554, "training_acc": 54.0, "val_loss": 17.26740002632141, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.43639254570007, "training_acc": 56.0, "val_loss": 17.27239191532135, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.13480710983276, "training_acc": 55.0, "val_loss": 17.27992594242096, "val_acc": 52.0}
