"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.28662037849426, "training_acc": 53.0, "val_loss": 17.304107546806335, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16041302680969, "training_acc": 53.0, "val_loss": 17.29808747768402, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.19274640083313, "training_acc": 53.0, "val_loss": 17.307019233703613, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09941101074219, "training_acc": 53.0, "val_loss": 17.30925291776657, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18882918357849, "training_acc": 53.0, "val_loss": 17.300117015838623, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22197318077087, "training_acc": 53.0, "val_loss": 17.282794415950775, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15959286689758, "training_acc": 53.0, "val_loss": 17.27927178144455, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.9762008190155, "training_acc": 53.0, "val_loss": 17.289817333221436, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.9233705997467, "training_acc": 53.0, "val_loss": 17.29825586080551, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.99899792671204, "training_acc": 53.0, "val_loss": 17.30715185403824, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.76739883422852, "training_acc": 53.0, "val_loss": 17.30949431657791, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0042040348053, "training_acc": 53.0, "val_loss": 17.316997051239014, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.93359375, "training_acc": 53.0, "val_loss": 17.32364594936371, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.91648459434509, "training_acc": 53.0, "val_loss": 17.326469719409943, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.77406430244446, "training_acc": 53.0, "val_loss": 17.32792854309082, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.76607990264893, "training_acc": 53.0, "val_loss": 17.330919206142426, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.82479190826416, "training_acc": 53.0, "val_loss": 17.331767082214355, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.74662470817566, "training_acc": 53.0, "val_loss": 17.329633235931396, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.83513569831848, "training_acc": 53.0, "val_loss": 17.330336570739746, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.89480876922607, "training_acc": 53.0, "val_loss": 17.332008481025696, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.60734534263611, "training_acc": 53.0, "val_loss": 17.332063615322113, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.66640210151672, "training_acc": 53.0, "val_loss": 17.33037531375885, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.70425796508789, "training_acc": 53.0, "val_loss": 17.329950630664825, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.59362506866455, "training_acc": 53.0, "val_loss": 17.330695688724518, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.85992527008057, "training_acc": 53.0, "val_loss": 17.331838607788086, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.8442063331604, "training_acc": 53.0, "val_loss": 17.336541414260864, "val_acc": 52.0}
