"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39988374710083, "training_acc": 53.0, "val_loss": 17.389491200447083, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.40836668014526, "training_acc": 53.0, "val_loss": 17.392072081565857, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24115467071533, "training_acc": 53.0, "val_loss": 17.36016869544983, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14599561691284, "training_acc": 53.0, "val_loss": 17.29990392923355, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.08632898330688, "training_acc": 53.0, "val_loss": 17.31192171573639, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.8329668045044, "training_acc": 53.0, "val_loss": 17.370110750198364, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.05157923698425, "training_acc": 53.0, "val_loss": 17.375193536281586, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.94292879104614, "training_acc": 53.0, "val_loss": 17.373408377170563, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.78942942619324, "training_acc": 53.0, "val_loss": 17.352628707885742, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.95265650749207, "training_acc": 53.0, "val_loss": 17.298445105552673, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.61809372901917, "training_acc": 53.0, "val_loss": 17.307166755199432, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.5665020942688, "training_acc": 53.0, "val_loss": 17.371436953544617, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.59118390083313, "training_acc": 53.0, "val_loss": 17.367316782474518, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.71978831291199, "training_acc": 53.0, "val_loss": 17.371389269828796, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.84657573699951, "training_acc": 53.0, "val_loss": 17.388202250003815, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.78522896766663, "training_acc": 53.0, "val_loss": 17.404641211032867, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.51750040054321, "training_acc": 53.0, "val_loss": 17.433281242847443, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.15739488601685, "training_acc": 53.0, "val_loss": 17.38395243883133, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.33532738685608, "training_acc": 53.0, "val_loss": 17.450131475925446, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.7950987815857, "training_acc": 53.0, "val_loss": 17.450881004333496, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.23450469970703, "training_acc": 54.0, "val_loss": 17.386668920516968, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.03525590896606, "training_acc": 55.0, "val_loss": 17.469225823879242, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.94700312614441, "training_acc": 53.0, "val_loss": 17.538699507713318, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.13859701156616, "training_acc": 53.0, "val_loss": 17.566028237342834, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.22345042228699, "training_acc": 53.0, "val_loss": 17.427948117256165, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.64659881591797, "training_acc": 58.0, "val_loss": 17.510414123535156, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.40963101387024, "training_acc": 54.0, "val_loss": 17.582738399505615, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.00072455406189, "training_acc": 56.0, "val_loss": 17.558351159095764, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.1756317615509, "training_acc": 61.0, "val_loss": 17.53656715154648, "val_acc": 52.0}
