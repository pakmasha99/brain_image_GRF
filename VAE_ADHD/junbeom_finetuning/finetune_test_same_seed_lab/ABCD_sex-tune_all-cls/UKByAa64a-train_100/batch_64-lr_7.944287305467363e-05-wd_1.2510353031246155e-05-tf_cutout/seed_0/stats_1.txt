"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.1194634437561, "training_acc": 47.0, "val_loss": 17.361341416835785, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.60879063606262, "training_acc": 47.0, "val_loss": 17.355437576770782, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12396597862244, "training_acc": 58.0, "val_loss": 17.30842888355255, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.0646743774414, "training_acc": 53.0, "val_loss": 17.292137444019318, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25018787384033, "training_acc": 53.0, "val_loss": 17.281705141067505, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15466260910034, "training_acc": 53.0, "val_loss": 17.303018271923065, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.01134419441223, "training_acc": 53.0, "val_loss": 17.314739525318146, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.56118321418762, "training_acc": 50.0, "val_loss": 17.302915453910828, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.07946801185608, "training_acc": 53.0, "val_loss": 17.344941198825836, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17841267585754, "training_acc": 53.0, "val_loss": 17.33192354440689, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.107017993927, "training_acc": 53.0, "val_loss": 17.33909398317337, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1843752861023, "training_acc": 53.0, "val_loss": 17.306213080883026, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2869713306427, "training_acc": 53.0, "val_loss": 17.314468324184418, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16244554519653, "training_acc": 48.0, "val_loss": 17.33737289905548, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.3362500667572, "training_acc": 47.0, "val_loss": 17.30700582265854, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10118889808655, "training_acc": 53.0, "val_loss": 17.323462665081024, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.10998892784119, "training_acc": 53.0, "val_loss": 17.323489487171173, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1319990158081, "training_acc": 53.0, "val_loss": 17.315883934497833, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1746654510498, "training_acc": 53.0, "val_loss": 17.31884330511093, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08980703353882, "training_acc": 53.0, "val_loss": 17.343272268772125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16894483566284, "training_acc": 53.0, "val_loss": 17.349040508270264, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.43588352203369, "training_acc": 53.0, "val_loss": 17.345333099365234, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.0757827758789, "training_acc": 53.0, "val_loss": 17.310039699077606, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.36784672737122, "training_acc": 53.0, "val_loss": 17.32260435819626, "val_acc": 52.0}
