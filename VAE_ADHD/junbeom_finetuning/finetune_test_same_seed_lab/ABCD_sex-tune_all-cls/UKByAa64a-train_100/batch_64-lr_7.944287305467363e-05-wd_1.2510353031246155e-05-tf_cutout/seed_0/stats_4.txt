"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.82396006584167, "training_acc": 47.0, "val_loss": 17.564979195594788, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.1775631904602, "training_acc": 47.0, "val_loss": 17.44132786989212, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.77652168273926, "training_acc": 47.0, "val_loss": 17.351825535297394, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09254550933838, "training_acc": 57.0, "val_loss": 17.308448255062103, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.99820399284363, "training_acc": 53.0, "val_loss": 17.308081686496735, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.56886601448059, "training_acc": 42.0, "val_loss": 17.316879332065582, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.62419843673706, "training_acc": 53.0, "val_loss": 17.302097380161285, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21319556236267, "training_acc": 53.0, "val_loss": 17.314715683460236, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.38219475746155, "training_acc": 53.0, "val_loss": 17.31288880109787, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11559867858887, "training_acc": 53.0, "val_loss": 17.304958403110504, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.46208310127258, "training_acc": 53.0, "val_loss": 17.307043075561523, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12015843391418, "training_acc": 53.0, "val_loss": 17.322486639022827, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.60394501686096, "training_acc": 53.0, "val_loss": 17.343585193157196, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.41992211341858, "training_acc": 53.0, "val_loss": 17.320331931114197, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11129689216614, "training_acc": 53.0, "val_loss": 17.325732111930847, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18458580970764, "training_acc": 53.0, "val_loss": 17.3233300447464, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.24600577354431, "training_acc": 53.0, "val_loss": 17.329296469688416, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14051866531372, "training_acc": 53.0, "val_loss": 17.350250482559204, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.24256920814514, "training_acc": 53.0, "val_loss": 17.34878718852997, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20436215400696, "training_acc": 53.0, "val_loss": 17.342498898506165, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15069198608398, "training_acc": 53.0, "val_loss": 17.317508161067963, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15733790397644, "training_acc": 53.0, "val_loss": 17.309188842773438, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18534183502197, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12624740600586, "training_acc": 53.0, "val_loss": 17.319774627685547, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15269756317139, "training_acc": 53.0, "val_loss": 17.33565926551819, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17057609558105, "training_acc": 53.0, "val_loss": 17.331549525260925, "val_acc": 52.0}
