"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.30891132354736, "training_acc": 53.0, "val_loss": 17.293208837509155, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.21747612953186, "training_acc": 52.0, "val_loss": 17.25327968597412, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.20021629333496, "training_acc": 52.0, "val_loss": 17.21964180469513, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.31012463569641, "training_acc": 52.0, "val_loss": 17.24083423614502, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.07638740539551, "training_acc": 52.0, "val_loss": 17.238180339336395, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.32797169685364, "training_acc": 52.0, "val_loss": 17.289523780345917, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.2702796459198, "training_acc": 55.0, "val_loss": 17.36322045326233, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.32521367073059, "training_acc": 53.0, "val_loss": 17.268459498882294, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.59290814399719, "training_acc": 52.0, "val_loss": 17.21133589744568, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.21927189826965, "training_acc": 52.0, "val_loss": 17.297376692295074, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2057421207428, "training_acc": 54.0, "val_loss": 17.339356243610382, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.31291151046753, "training_acc": 49.0, "val_loss": 17.265036702156067, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.24816250801086, "training_acc": 52.0, "val_loss": 17.2491654753685, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.12815952301025, "training_acc": 52.0, "val_loss": 17.28050261735916, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.14619469642639, "training_acc": 52.0, "val_loss": 17.240959405899048, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.06461668014526, "training_acc": 52.0, "val_loss": 17.215430736541748, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.13227558135986, "training_acc": 52.0, "val_loss": 17.209981381893158, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.1879472732544, "training_acc": 52.0, "val_loss": 17.276541888713837, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.9776725769043, "training_acc": 53.0, "val_loss": 17.320074141025543, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.04465174674988, "training_acc": 51.0, "val_loss": 17.306514084339142, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.99234080314636, "training_acc": 54.0, "val_loss": 17.303548753261566, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.78506588935852, "training_acc": 57.0, "val_loss": 17.24953055381775, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.50700449943542, "training_acc": 52.0, "val_loss": 17.197884619235992, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.14515399932861, "training_acc": 52.0, "val_loss": 17.307785153388977, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.01580500602722, "training_acc": 54.0, "val_loss": 17.495205998420715, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.4154405593872, "training_acc": 48.0, "val_loss": 17.486846446990967, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.83482956886292, "training_acc": 38.0, "val_loss": 17.305369675159454, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.14397096633911, "training_acc": 52.0, "val_loss": 17.4066960811615, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.89746451377869, "training_acc": 56.0, "val_loss": 17.45719313621521, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.78129482269287, "training_acc": 63.0, "val_loss": 17.279087007045746, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.42518162727356, "training_acc": 52.0, "val_loss": 17.238570749759674, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.6150209903717, "training_acc": 52.0, "val_loss": 17.29993224143982, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.03462648391724, "training_acc": 52.0, "val_loss": 17.326241731643677, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.5763521194458, "training_acc": 56.0, "val_loss": 17.44047850370407, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.45702338218689, "training_acc": 56.0, "val_loss": 17.59255677461624, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.4608428478241, "training_acc": 63.0, "val_loss": 17.377975583076477, "val_acc": 56.0}
{"epoch": 36, "training_loss": 67.66022968292236, "training_acc": 55.0, "val_loss": 17.347604036331177, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.87797999382019, "training_acc": 57.0, "val_loss": 17.374645173549652, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.26381945610046, "training_acc": 61.0, "val_loss": 17.389144003391266, "val_acc": 56.0}
{"epoch": 39, "training_loss": 67.61620712280273, "training_acc": 54.0, "val_loss": 17.809370160102844, "val_acc": 56.0}
{"epoch": 40, "training_loss": 68.33322596549988, "training_acc": 56.0, "val_loss": 17.36762225627899, "val_acc": 56.0}
{"epoch": 41, "training_loss": 68.0015516281128, "training_acc": 53.0, "val_loss": 17.5567626953125, "val_acc": 56.0}
