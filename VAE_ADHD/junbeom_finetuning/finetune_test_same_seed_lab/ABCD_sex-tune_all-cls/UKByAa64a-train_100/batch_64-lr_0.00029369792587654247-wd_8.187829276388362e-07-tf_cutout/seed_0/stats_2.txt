"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39613461494446, "training_acc": 53.0, "val_loss": 17.32475310564041, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.3005850315094, "training_acc": 53.0, "val_loss": 17.380698025226593, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.60665106773376, "training_acc": 47.0, "val_loss": 17.313113808631897, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21763134002686, "training_acc": 53.0, "val_loss": 17.329978942871094, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1704614162445, "training_acc": 53.0, "val_loss": 17.339931428432465, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.08467984199524, "training_acc": 53.0, "val_loss": 17.32681691646576, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13342714309692, "training_acc": 53.0, "val_loss": 17.38043874502182, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.71015191078186, "training_acc": 53.0, "val_loss": 17.326994240283966, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.74419832229614, "training_acc": 53.0, "val_loss": 17.30949878692627, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16528367996216, "training_acc": 53.0, "val_loss": 17.313706874847412, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13867163658142, "training_acc": 53.0, "val_loss": 17.3228457570076, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.31733226776123, "training_acc": 53.0, "val_loss": 17.316199839115143, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20838499069214, "training_acc": 53.0, "val_loss": 17.310532927513123, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1986517906189, "training_acc": 53.0, "val_loss": 17.308726906776428, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19506764411926, "training_acc": 53.0, "val_loss": 17.31744408607483, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18221044540405, "training_acc": 53.0, "val_loss": 17.320558428764343, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15035319328308, "training_acc": 53.0, "val_loss": 17.338107526302338, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23456525802612, "training_acc": 53.0, "val_loss": 17.344611883163452, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18682861328125, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14262843132019, "training_acc": 53.0, "val_loss": 17.31487661600113, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22754216194153, "training_acc": 53.0, "val_loss": 17.31223315000534, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21185374259949, "training_acc": 53.0, "val_loss": 17.31037050485611, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14558839797974, "training_acc": 53.0, "val_loss": 17.343711853027344, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.41305232048035, "training_acc": 53.0, "val_loss": 17.348365485668182, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.44159698486328, "training_acc": 53.0, "val_loss": 17.388153076171875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.32555484771729, "training_acc": 53.0, "val_loss": 17.462389171123505, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.60383677482605, "training_acc": 53.0, "val_loss": 17.413276433944702, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.56436848640442, "training_acc": 53.0, "val_loss": 17.321403324604034, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11447262763977, "training_acc": 53.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.32272458076477, "training_acc": 53.0, "val_loss": 17.311009764671326, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17822432518005, "training_acc": 53.0, "val_loss": 17.309938371181488, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.11056756973267, "training_acc": 53.0, "val_loss": 17.333388328552246, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17356157302856, "training_acc": 53.0, "val_loss": 17.355667054653168, "val_acc": 52.0}
