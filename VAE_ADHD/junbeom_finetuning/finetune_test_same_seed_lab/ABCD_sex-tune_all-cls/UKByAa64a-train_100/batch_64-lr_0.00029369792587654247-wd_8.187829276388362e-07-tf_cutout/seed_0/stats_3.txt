"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.11866092681885, "training_acc": 54.0, "val_loss": 17.378145456314087, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.39601755142212, "training_acc": 53.0, "val_loss": 17.516852915287018, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.32507514953613, "training_acc": 53.0, "val_loss": 17.336779832839966, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3083872795105, "training_acc": 49.0, "val_loss": 17.314830422401428, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.513742685318, "training_acc": 53.0, "val_loss": 17.30842888355255, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.1439471244812, "training_acc": 43.0, "val_loss": 17.31087416410446, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.41786646842957, "training_acc": 53.0, "val_loss": 17.35319495201111, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16625595092773, "training_acc": 53.0, "val_loss": 17.468971014022827, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.58624720573425, "training_acc": 53.0, "val_loss": 17.411215603351593, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.37950825691223, "training_acc": 53.0, "val_loss": 17.33437478542328, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20484781265259, "training_acc": 53.0, "val_loss": 17.31070727109909, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22819232940674, "training_acc": 53.0, "val_loss": 17.311900854110718, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11799645423889, "training_acc": 53.0, "val_loss": 17.339958250522614, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.37575650215149, "training_acc": 53.0, "val_loss": 17.36658364534378, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.26973009109497, "training_acc": 53.0, "val_loss": 17.314937710762024, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17672801017761, "training_acc": 53.0, "val_loss": 17.30882227420807, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.36270570755005, "training_acc": 53.0, "val_loss": 17.311130464076996, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.59745407104492, "training_acc": 53.0, "val_loss": 17.352308332920074, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26761603355408, "training_acc": 53.0, "val_loss": 17.32485741376877, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14323234558105, "training_acc": 53.0, "val_loss": 17.315635085105896, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.34352135658264, "training_acc": 53.0, "val_loss": 17.31078177690506, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10941076278687, "training_acc": 53.0, "val_loss": 17.31729805469513, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25818753242493, "training_acc": 53.0, "val_loss": 17.32814759016037, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.32160878181458, "training_acc": 53.0, "val_loss": 17.32756793498993, "val_acc": 52.0}
