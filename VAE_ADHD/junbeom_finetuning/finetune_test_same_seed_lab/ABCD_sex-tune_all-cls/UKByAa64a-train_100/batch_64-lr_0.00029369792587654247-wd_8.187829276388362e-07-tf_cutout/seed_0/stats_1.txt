"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.52481842041016, "training_acc": 52.0, "val_loss": 17.33376830816269, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22326302528381, "training_acc": 53.0, "val_loss": 17.332275211811066, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.904052734375, "training_acc": 47.0, "val_loss": 17.344947159290314, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19672632217407, "training_acc": 53.0, "val_loss": 17.375530302524567, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.24348855018616, "training_acc": 53.0, "val_loss": 17.314578592777252, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23929286003113, "training_acc": 53.0, "val_loss": 17.308686673641205, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.033860206604, "training_acc": 41.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.042964220047, "training_acc": 53.0, "val_loss": 17.376160621643066, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.42920517921448, "training_acc": 53.0, "val_loss": 17.421813309192657, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.43486833572388, "training_acc": 53.0, "val_loss": 17.44779497385025, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.51773500442505, "training_acc": 53.0, "val_loss": 17.387813329696655, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.34270858764648, "training_acc": 53.0, "val_loss": 17.330332100391388, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14608526229858, "training_acc": 53.0, "val_loss": 17.31138974428177, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.29256558418274, "training_acc": 53.0, "val_loss": 17.319096624851227, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.39592862129211, "training_acc": 47.0, "val_loss": 17.327380180358887, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24721121788025, "training_acc": 53.0, "val_loss": 17.308612167835236, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15213370323181, "training_acc": 53.0, "val_loss": 17.34764128923416, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21641254425049, "training_acc": 53.0, "val_loss": 17.365050315856934, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.69979214668274, "training_acc": 53.0, "val_loss": 17.346088588237762, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.40010213851929, "training_acc": 53.0, "val_loss": 17.373479902744293, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30130124092102, "training_acc": 53.0, "val_loss": 17.334158718585968, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10786533355713, "training_acc": 53.0, "val_loss": 17.30888932943344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.30240321159363, "training_acc": 53.0, "val_loss": 17.32313185930252, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.27941632270813, "training_acc": 53.0, "val_loss": 17.31579899787903, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2118935585022, "training_acc": 53.0, "val_loss": 17.30922907590866, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12972950935364, "training_acc": 53.0, "val_loss": 17.32017546892166, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13191819190979, "training_acc": 53.0, "val_loss": 17.343245446681976, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24957251548767, "training_acc": 53.0, "val_loss": 17.36905127763748, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.25370955467224, "training_acc": 53.0, "val_loss": 17.346037924289703, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.48802137374878, "training_acc": 53.0, "val_loss": 17.31647253036499, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13819622993469, "training_acc": 53.0, "val_loss": 17.31799989938736, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15061664581299, "training_acc": 53.0, "val_loss": 17.32170432806015, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16850733757019, "training_acc": 53.0, "val_loss": 17.329062521457672, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20652508735657, "training_acc": 53.0, "val_loss": 17.32172518968582, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.22354197502136, "training_acc": 53.0, "val_loss": 17.309188842773438, "val_acc": 52.0}
