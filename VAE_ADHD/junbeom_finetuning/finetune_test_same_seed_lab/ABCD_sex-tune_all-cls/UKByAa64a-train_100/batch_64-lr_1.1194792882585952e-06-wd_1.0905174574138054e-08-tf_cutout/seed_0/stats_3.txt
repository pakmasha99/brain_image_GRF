"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38017153739929, "training_acc": 53.0, "val_loss": 17.447201907634735, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.32154154777527, "training_acc": 53.0, "val_loss": 17.433220148086548, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12681007385254, "training_acc": 53.0, "val_loss": 17.416077852249146, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.28625011444092, "training_acc": 53.0, "val_loss": 17.397677898406982, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18209195137024, "training_acc": 53.0, "val_loss": 17.401133477687836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21008896827698, "training_acc": 53.0, "val_loss": 17.399851977825165, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.9575080871582, "training_acc": 53.0, "val_loss": 17.396819591522217, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15128636360168, "training_acc": 53.0, "val_loss": 17.391830682754517, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12844705581665, "training_acc": 53.0, "val_loss": 17.389287054538727, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11450982093811, "training_acc": 53.0, "val_loss": 17.389000952243805, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14451694488525, "training_acc": 53.0, "val_loss": 17.389604449272156, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.02328753471375, "training_acc": 53.0, "val_loss": 17.391838133335114, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.038569688797, "training_acc": 53.0, "val_loss": 17.397819459438324, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04891586303711, "training_acc": 53.0, "val_loss": 17.399726808071136, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.07174849510193, "training_acc": 53.0, "val_loss": 17.401015758514404, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.91614890098572, "training_acc": 53.0, "val_loss": 17.401300370693207, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.94690275192261, "training_acc": 53.0, "val_loss": 17.39514172077179, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.84521079063416, "training_acc": 53.0, "val_loss": 17.39078462123871, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.70296883583069, "training_acc": 53.0, "val_loss": 17.388717830181122, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.7963535785675, "training_acc": 53.0, "val_loss": 17.387600243091583, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.87317776679993, "training_acc": 53.0, "val_loss": 17.38707721233368, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.83789372444153, "training_acc": 53.0, "val_loss": 17.387032508850098, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.75487112998962, "training_acc": 53.0, "val_loss": 17.386506497859955, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.56407380104065, "training_acc": 53.0, "val_loss": 17.381198704242706, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.63484644889832, "training_acc": 53.0, "val_loss": 17.372752726078033, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.78719758987427, "training_acc": 53.0, "val_loss": 17.36367791891098, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.59919810295105, "training_acc": 53.0, "val_loss": 17.359748482704163, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.65284085273743, "training_acc": 53.0, "val_loss": 17.365455627441406, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.75637125968933, "training_acc": 53.0, "val_loss": 17.37392395734787, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.91732358932495, "training_acc": 53.0, "val_loss": 17.381422221660614, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.60145998001099, "training_acc": 53.0, "val_loss": 17.387336492538452, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.82778143882751, "training_acc": 53.0, "val_loss": 17.384640872478485, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.55355215072632, "training_acc": 53.0, "val_loss": 17.367589473724365, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.48026609420776, "training_acc": 53.0, "val_loss": 17.35399067401886, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.45131301879883, "training_acc": 53.0, "val_loss": 17.347951233386993, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.747567653656, "training_acc": 53.0, "val_loss": 17.346492409706116, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.35508441925049, "training_acc": 53.0, "val_loss": 17.349855601787567, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.4007658958435, "training_acc": 53.0, "val_loss": 17.352227866649628, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.56964564323425, "training_acc": 53.0, "val_loss": 17.36692637205124, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.43663477897644, "training_acc": 53.0, "val_loss": 17.388318479061127, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.44882559776306, "training_acc": 53.0, "val_loss": 17.405526340007782, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.52668738365173, "training_acc": 53.0, "val_loss": 17.413349449634552, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.34546208381653, "training_acc": 53.0, "val_loss": 17.41914302110672, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.45305943489075, "training_acc": 53.0, "val_loss": 17.41751879453659, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.47742009162903, "training_acc": 53.0, "val_loss": 17.400839924812317, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.45132637023926, "training_acc": 53.0, "val_loss": 17.377345263957977, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.87710285186768, "training_acc": 53.0, "val_loss": 17.37968772649765, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.57100415229797, "training_acc": 53.0, "val_loss": 17.392706871032715, "val_acc": 52.0}
{"epoch": 48, "training_loss": 67.97015357017517, "training_acc": 53.0, "val_loss": 17.39725023508072, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.33424305915833, "training_acc": 53.0, "val_loss": 17.393045127391815, "val_acc": 52.0}
{"epoch": 50, "training_loss": 67.9918384552002, "training_acc": 53.0, "val_loss": 17.40810126066208, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.10884809494019, "training_acc": 53.0, "val_loss": 17.40783005952835, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.12737083435059, "training_acc": 53.0, "val_loss": 17.419974505901337, "val_acc": 52.0}
{"epoch": 53, "training_loss": 67.96932935714722, "training_acc": 53.0, "val_loss": 17.434774339199066, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.38646149635315, "training_acc": 53.0, "val_loss": 17.441561818122864, "val_acc": 52.0}
