"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26288342475891, "training_acc": 53.0, "val_loss": 17.417743802070618, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.29274868965149, "training_acc": 53.0, "val_loss": 17.33173280954361, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.09064531326294, "training_acc": 53.0, "val_loss": 17.321166396141052, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22641110420227, "training_acc": 53.0, "val_loss": 17.29443073272705, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30008935928345, "training_acc": 53.0, "val_loss": 17.297331988811493, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.30035424232483, "training_acc": 53.0, "val_loss": 17.316463589668274, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15797114372253, "training_acc": 53.0, "val_loss": 17.313680052757263, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09432029724121, "training_acc": 53.0, "val_loss": 17.312917113304138, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.08879208564758, "training_acc": 53.0, "val_loss": 17.312423884868622, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.25203227996826, "training_acc": 53.0, "val_loss": 17.312610149383545, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15709662437439, "training_acc": 53.0, "val_loss": 17.332904040813446, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10816264152527, "training_acc": 53.0, "val_loss": 17.339542508125305, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07967495918274, "training_acc": 53.0, "val_loss": 17.331798374652863, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2325210571289, "training_acc": 53.0, "val_loss": 17.32168197631836, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31092262268066, "training_acc": 53.0, "val_loss": 17.308002710342407, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11452627182007, "training_acc": 53.0, "val_loss": 17.305614054203033, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14593887329102, "training_acc": 53.0, "val_loss": 17.306682467460632, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10231351852417, "training_acc": 53.0, "val_loss": 17.31889694929123, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.06994438171387, "training_acc": 53.0, "val_loss": 17.322713136672974, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.04780673980713, "training_acc": 53.0, "val_loss": 17.313534021377563, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.03149914741516, "training_acc": 53.0, "val_loss": 17.305278778076172, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.00703883171082, "training_acc": 53.0, "val_loss": 17.304235696792603, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.05968403816223, "training_acc": 53.0, "val_loss": 17.303840816020966, "val_acc": 52.0}
