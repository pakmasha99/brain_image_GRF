"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34093403816223, "training_acc": 53.0, "val_loss": 17.38829016685486, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2653739452362, "training_acc": 53.0, "val_loss": 17.35070049762726, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.27204942703247, "training_acc": 53.0, "val_loss": 17.328666150569916, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26745867729187, "training_acc": 53.0, "val_loss": 17.369285225868225, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.02265191078186, "training_acc": 53.0, "val_loss": 17.33381599187851, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.97926735877991, "training_acc": 53.0, "val_loss": 17.365680634975433, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.02379298210144, "training_acc": 53.0, "val_loss": 17.34776645898819, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09870457649231, "training_acc": 53.0, "val_loss": 17.33679473400116, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21901726722717, "training_acc": 53.0, "val_loss": 17.306964099407196, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.86440014839172, "training_acc": 53.0, "val_loss": 17.35878735780716, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.49256682395935, "training_acc": 53.0, "val_loss": 17.338958382606506, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.03223013877869, "training_acc": 56.0, "val_loss": 17.438822984695435, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.00771307945251, "training_acc": 53.0, "val_loss": 17.404864728450775, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04982829093933, "training_acc": 53.0, "val_loss": 17.427532374858856, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21256375312805, "training_acc": 53.0, "val_loss": 17.36462563276291, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.60517716407776, "training_acc": 53.0, "val_loss": 17.347727715969086, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.45996522903442, "training_acc": 53.0, "val_loss": 17.33514815568924, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.49332451820374, "training_acc": 53.0, "val_loss": 17.37198531627655, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.21263885498047, "training_acc": 59.0, "val_loss": 17.53927618265152, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.05640387535095, "training_acc": 53.0, "val_loss": 17.610551416873932, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.17226052284241, "training_acc": 60.0, "val_loss": 17.59166121482849, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.63714647293091, "training_acc": 58.0, "val_loss": 17.445626854896545, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.54652428627014, "training_acc": 66.0, "val_loss": 17.6971435546875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.42077159881592, "training_acc": 57.0, "val_loss": 17.416201531887054, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.36871576309204, "training_acc": 56.0, "val_loss": 17.726026475429535, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.24027752876282, "training_acc": 53.0, "val_loss": 17.533452808856964, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.67437934875488, "training_acc": 53.0, "val_loss": 17.39472597837448, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23883557319641, "training_acc": 53.0, "val_loss": 17.33580380678177, "val_acc": 52.0}
