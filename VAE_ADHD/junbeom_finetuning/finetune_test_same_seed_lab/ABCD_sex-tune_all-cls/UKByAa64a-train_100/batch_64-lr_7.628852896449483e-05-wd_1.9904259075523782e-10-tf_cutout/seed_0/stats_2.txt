"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.42692947387695, "training_acc": 49.0, "val_loss": 17.311233282089233, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.14604902267456, "training_acc": 53.0, "val_loss": 17.341068387031555, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.41908192634583, "training_acc": 53.0, "val_loss": 17.318207025527954, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.31021022796631, "training_acc": 53.0, "val_loss": 17.32211858034134, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19116759300232, "training_acc": 53.0, "val_loss": 17.30484366416931, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17094135284424, "training_acc": 53.0, "val_loss": 17.31366068124771, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13657546043396, "training_acc": 53.0, "val_loss": 17.33103096485138, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.28713703155518, "training_acc": 53.0, "val_loss": 17.3238143324852, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18010210990906, "training_acc": 53.0, "val_loss": 17.334872484207153, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14753675460815, "training_acc": 53.0, "val_loss": 17.31540709733963, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15585327148438, "training_acc": 53.0, "val_loss": 17.308667302131653, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14569425582886, "training_acc": 53.0, "val_loss": 17.3112615942955, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16260075569153, "training_acc": 53.0, "val_loss": 17.311356961727142, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11967468261719, "training_acc": 53.0, "val_loss": 17.31121391057968, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.22257590293884, "training_acc": 53.0, "val_loss": 17.31082946062088, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16868138313293, "training_acc": 53.0, "val_loss": 17.31722056865692, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.07817149162292, "training_acc": 53.0, "val_loss": 17.325225472450256, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16065192222595, "training_acc": 53.0, "val_loss": 17.32134073972702, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12387681007385, "training_acc": 53.0, "val_loss": 17.313820123672485, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20130586624146, "training_acc": 53.0, "val_loss": 17.310386896133423, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09597682952881, "training_acc": 53.0, "val_loss": 17.316752672195435, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.05162358283997, "training_acc": 53.0, "val_loss": 17.317332327365875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.00812602043152, "training_acc": 53.0, "val_loss": 17.31717139482498, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10883164405823, "training_acc": 53.0, "val_loss": 17.320169508457184, "val_acc": 52.0}
