"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.30189037322998, "training_acc": 53.0, "val_loss": 17.267772555351257, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.12118935585022, "training_acc": 52.0, "val_loss": 17.255347967147827, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.33428311347961, "training_acc": 52.0, "val_loss": 17.2763854265213, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.23688840866089, "training_acc": 52.0, "val_loss": 17.302629351615906, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.27845239639282, "training_acc": 52.0, "val_loss": 17.28200912475586, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.46104288101196, "training_acc": 52.0, "val_loss": 17.236357927322388, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.24681401252747, "training_acc": 52.0, "val_loss": 17.2907292842865, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25462007522583, "training_acc": 52.0, "val_loss": 17.26175844669342, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.53274464607239, "training_acc": 52.0, "val_loss": 17.214934527873993, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.20531105995178, "training_acc": 52.0, "val_loss": 17.273060977458954, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2601592540741, "training_acc": 52.0, "val_loss": 17.305666208267212, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.28583860397339, "training_acc": 52.0, "val_loss": 17.26205348968506, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.27526783943176, "training_acc": 52.0, "val_loss": 17.241767048835754, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.25012946128845, "training_acc": 52.0, "val_loss": 17.258116602897644, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2308919429779, "training_acc": 52.0, "val_loss": 17.225705087184906, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.18391537666321, "training_acc": 52.0, "val_loss": 17.1965554356575, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.24514317512512, "training_acc": 52.0, "val_loss": 17.18246191740036, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.28366804122925, "training_acc": 52.0, "val_loss": 17.223170399665833, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.23078989982605, "training_acc": 52.0, "val_loss": 17.27108657360077, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.20987749099731, "training_acc": 52.0, "val_loss": 17.284764349460602, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.26424860954285, "training_acc": 52.0, "val_loss": 17.28181391954422, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23368453979492, "training_acc": 52.0, "val_loss": 17.225241661071777, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.45665407180786, "training_acc": 52.0, "val_loss": 17.177943885326385, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.28377604484558, "training_acc": 52.0, "val_loss": 17.209400236606598, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.1823513507843, "training_acc": 52.0, "val_loss": 17.280782759189606, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.32130098342896, "training_acc": 49.0, "val_loss": 17.349357903003693, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.63665461540222, "training_acc": 38.0, "val_loss": 17.295996844768524, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24375581741333, "training_acc": 52.0, "val_loss": 17.33432710170746, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33650779724121, "training_acc": 45.0, "val_loss": 17.324262857437134, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2396011352539, "training_acc": 52.0, "val_loss": 17.24299192428589, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.54217600822449, "training_acc": 52.0, "val_loss": 17.19067394733429, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.4141309261322, "training_acc": 52.0, "val_loss": 17.21136122941971, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23610091209412, "training_acc": 52.0, "val_loss": 17.199893295764923, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24760675430298, "training_acc": 52.0, "val_loss": 17.209455370903015, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24374461174011, "training_acc": 52.0, "val_loss": 17.21590757369995, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23027038574219, "training_acc": 52.0, "val_loss": 17.247337102890015, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23477959632874, "training_acc": 52.0, "val_loss": 17.26231276988983, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.29951429367065, "training_acc": 52.0, "val_loss": 17.24383533000946, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.14501667022705, "training_acc": 52.0, "val_loss": 17.192180454730988, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.40428137779236, "training_acc": 52.0, "val_loss": 17.16306507587433, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.3629982471466, "training_acc": 52.0, "val_loss": 17.1792671084404, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2549216747284, "training_acc": 52.0, "val_loss": 17.217805981636047, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.20189237594604, "training_acc": 52.0, "val_loss": 17.260895669460297, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.17464923858643, "training_acc": 52.0, "val_loss": 17.32853353023529, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.34852194786072, "training_acc": 49.0, "val_loss": 17.41584688425064, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.38983035087585, "training_acc": 48.0, "val_loss": 17.384235560894012, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.30861377716064, "training_acc": 48.0, "val_loss": 17.322243750095367, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.17485499382019, "training_acc": 54.0, "val_loss": 17.26697087287903, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.19200992584229, "training_acc": 52.0, "val_loss": 17.206372320652008, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.30559968948364, "training_acc": 52.0, "val_loss": 17.205709218978882, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.16144895553589, "training_acc": 52.0, "val_loss": 17.25981831550598, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.18363666534424, "training_acc": 52.0, "val_loss": 17.30758249759674, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.22200775146484, "training_acc": 52.0, "val_loss": 17.319755256175995, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.1863100528717, "training_acc": 52.0, "val_loss": 17.32567995786667, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.20528221130371, "training_acc": 51.0, "val_loss": 17.283591628074646, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27595257759094, "training_acc": 52.0, "val_loss": 17.23051369190216, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.15298628807068, "training_acc": 52.0, "val_loss": 17.24638342857361, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.10012006759644, "training_acc": 52.0, "val_loss": 17.285647988319397, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.01005864143372, "training_acc": 52.0, "val_loss": 17.28692203760147, "val_acc": 56.0}
