"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15908551216125, "training_acc": 47.0, "val_loss": 17.397549748420715, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.79160737991333, "training_acc": 47.0, "val_loss": 17.32354164123535, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12145352363586, "training_acc": 51.0, "val_loss": 17.3237606883049, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05751466751099, "training_acc": 53.0, "val_loss": 17.30363667011261, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.36405158042908, "training_acc": 53.0, "val_loss": 17.30130910873413, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.01826167106628, "training_acc": 53.0, "val_loss": 17.299018800258636, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.46595001220703, "training_acc": 46.0, "val_loss": 17.296969890594482, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.46568322181702, "training_acc": 53.0, "val_loss": 17.31458306312561, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1744396686554, "training_acc": 53.0, "val_loss": 17.309944331645966, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.25751185417175, "training_acc": 53.0, "val_loss": 17.324461042881012, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1378185749054, "training_acc": 53.0, "val_loss": 17.35498458147049, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29370832443237, "training_acc": 53.0, "val_loss": 17.357823252677917, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20690679550171, "training_acc": 53.0, "val_loss": 17.35522449016571, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15305638313293, "training_acc": 53.0, "val_loss": 17.31724441051483, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17025470733643, "training_acc": 53.0, "val_loss": 17.31194406747818, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14019465446472, "training_acc": 53.0, "val_loss": 17.315036058425903, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17323684692383, "training_acc": 53.0, "val_loss": 17.320601642131805, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24681568145752, "training_acc": 53.0, "val_loss": 17.331472039222717, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16798329353333, "training_acc": 53.0, "val_loss": 17.36133098602295, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.33474469184875, "training_acc": 53.0, "val_loss": 17.347247898578644, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24865484237671, "training_acc": 53.0, "val_loss": 17.343434691429138, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.27968168258667, "training_acc": 53.0, "val_loss": 17.316855490207672, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21813011169434, "training_acc": 53.0, "val_loss": 17.31867343187332, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24330925941467, "training_acc": 53.0, "val_loss": 17.320625483989716, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.51676321029663, "training_acc": 39.0, "val_loss": 17.310895025730133, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17288589477539, "training_acc": 53.0, "val_loss": 17.32904464006424, "val_acc": 52.0}
