"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.74707698822021, "training_acc": 53.0, "val_loss": 17.573100328445435, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.56979417800903, "training_acc": 53.0, "val_loss": 17.44566261768341, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.51155591011047, "training_acc": 53.0, "val_loss": 17.41764545440674, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22925162315369, "training_acc": 53.0, "val_loss": 17.420978844165802, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13411235809326, "training_acc": 53.0, "val_loss": 17.39070862531662, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.05636215209961, "training_acc": 53.0, "val_loss": 17.345768213272095, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.98627185821533, "training_acc": 53.0, "val_loss": 17.30310022830963, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.98433661460876, "training_acc": 53.0, "val_loss": 17.283660173416138, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02557492256165, "training_acc": 53.0, "val_loss": 17.296764254570007, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.82050251960754, "training_acc": 53.0, "val_loss": 17.344580590724945, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.75059843063354, "training_acc": 53.0, "val_loss": 17.36655831336975, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.85036730766296, "training_acc": 53.0, "val_loss": 17.356623709201813, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.69964241981506, "training_acc": 53.0, "val_loss": 17.31552630662918, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.50633716583252, "training_acc": 53.0, "val_loss": 17.30053424835205, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.4448835849762, "training_acc": 53.0, "val_loss": 17.29675680398941, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.46403884887695, "training_acc": 58.0, "val_loss": 17.325641214847565, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.828364610672, "training_acc": 55.0, "val_loss": 17.328712344169617, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.31360578536987, "training_acc": 53.0, "val_loss": 17.363236844539642, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.17719602584839, "training_acc": 53.0, "val_loss": 17.39056408405304, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.95144367218018, "training_acc": 53.0, "val_loss": 17.36065447330475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.0864953994751, "training_acc": 54.0, "val_loss": 17.33892261981964, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.14798021316528, "training_acc": 57.0, "val_loss": 17.362189292907715, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.96344351768494, "training_acc": 54.0, "val_loss": 17.43377596139908, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.27716517448425, "training_acc": 55.0, "val_loss": 17.420612275600433, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.46473407745361, "training_acc": 53.0, "val_loss": 17.484815418720245, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.74027872085571, "training_acc": 53.0, "val_loss": 17.5042986869812, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.50647807121277, "training_acc": 54.0, "val_loss": 17.37511157989502, "val_acc": 52.0}
