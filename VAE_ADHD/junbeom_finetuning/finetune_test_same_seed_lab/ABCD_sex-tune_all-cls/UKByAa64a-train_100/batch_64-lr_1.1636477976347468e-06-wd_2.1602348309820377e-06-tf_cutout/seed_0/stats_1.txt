"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.60006260871887, "training_acc": 47.0, "val_loss": 17.423756420612335, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55013465881348, "training_acc": 47.0, "val_loss": 17.41034686565399, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.5015606880188, "training_acc": 47.0, "val_loss": 17.39918440580368, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.60082960128784, "training_acc": 47.0, "val_loss": 17.40008443593979, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.54852223396301, "training_acc": 47.0, "val_loss": 17.40451157093048, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.4141001701355, "training_acc": 47.0, "val_loss": 17.402547597885132, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.425217628479, "training_acc": 47.0, "val_loss": 17.38891899585724, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.3915491104126, "training_acc": 47.0, "val_loss": 17.370784282684326, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.26522088050842, "training_acc": 50.0, "val_loss": 17.36215204000473, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.32030081748962, "training_acc": 50.0, "val_loss": 17.355483770370483, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20249676704407, "training_acc": 50.0, "val_loss": 17.351220548152924, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18628883361816, "training_acc": 51.0, "val_loss": 17.344172298908234, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23360133171082, "training_acc": 58.0, "val_loss": 17.334632575511932, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19763112068176, "training_acc": 55.0, "val_loss": 17.328831553459167, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20050001144409, "training_acc": 55.0, "val_loss": 17.323949933052063, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.25744771957397, "training_acc": 48.0, "val_loss": 17.320391535758972, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15657615661621, "training_acc": 51.0, "val_loss": 17.32812523841858, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.0618793964386, "training_acc": 58.0, "val_loss": 17.33100414276123, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.03189182281494, "training_acc": 57.0, "val_loss": 17.32771098613739, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.00799632072449, "training_acc": 62.0, "val_loss": 17.31431484222412, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.97552967071533, "training_acc": 56.0, "val_loss": 17.303606867790222, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.0004780292511, "training_acc": 52.0, "val_loss": 17.298930883407593, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.7219398021698, "training_acc": 62.0, "val_loss": 17.29438602924347, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.0062096118927, "training_acc": 52.0, "val_loss": 17.29051172733307, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.07521367073059, "training_acc": 57.0, "val_loss": 17.29457676410675, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.93815970420837, "training_acc": 49.0, "val_loss": 17.291684448719025, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.78696417808533, "training_acc": 56.0, "val_loss": 17.291174829006195, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.04558873176575, "training_acc": 48.0, "val_loss": 17.29324907064438, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12882447242737, "training_acc": 48.0, "val_loss": 17.297720909118652, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.58559989929199, "training_acc": 58.0, "val_loss": 17.3028364777565, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.89218473434448, "training_acc": 56.0, "val_loss": 17.305758595466614, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.77410244941711, "training_acc": 54.0, "val_loss": 17.307846248149872, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.95443153381348, "training_acc": 51.0, "val_loss": 17.311522364616394, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.6433253288269, "training_acc": 60.0, "val_loss": 17.320232093334198, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.63239860534668, "training_acc": 54.0, "val_loss": 17.332875728607178, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.81009817123413, "training_acc": 56.0, "val_loss": 17.32606142759323, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.71863222122192, "training_acc": 58.0, "val_loss": 17.303460836410522, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.4158411026001, "training_acc": 60.0, "val_loss": 17.27777123451233, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.60776352882385, "training_acc": 54.0, "val_loss": 17.249807715415955, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.83098530769348, "training_acc": 56.0, "val_loss": 17.241117358207703, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.68726944923401, "training_acc": 57.0, "val_loss": 17.252399027347565, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.45994162559509, "training_acc": 55.0, "val_loss": 17.27546453475952, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.80263066291809, "training_acc": 51.0, "val_loss": 17.28944331407547, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.76158142089844, "training_acc": 56.0, "val_loss": 17.300109565258026, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.71475982666016, "training_acc": 55.0, "val_loss": 17.31354296207428, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.63360500335693, "training_acc": 59.0, "val_loss": 17.31524169445038, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.47513604164124, "training_acc": 57.0, "val_loss": 17.306634783744812, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.49700403213501, "training_acc": 62.0, "val_loss": 17.29280650615692, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.51280570030212, "training_acc": 57.0, "val_loss": 17.27950870990753, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.24553680419922, "training_acc": 60.0, "val_loss": 17.271265387535095, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.6260154247284, "training_acc": 54.0, "val_loss": 17.27137267589569, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.22745895385742, "training_acc": 54.0, "val_loss": 17.281338572502136, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.42101407051086, "training_acc": 57.0, "val_loss": 17.29222685098648, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.5262382030487, "training_acc": 52.0, "val_loss": 17.29869395494461, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.31874966621399, "training_acc": 53.0, "val_loss": 17.300863564014435, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.62963962554932, "training_acc": 54.0, "val_loss": 17.29487180709839, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.31626915931702, "training_acc": 58.0, "val_loss": 17.28707104921341, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.08507227897644, "training_acc": 55.0, "val_loss": 17.28028804063797, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.9036774635315, "training_acc": 51.0, "val_loss": 17.278850078582764, "val_acc": 52.0}
