"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.1297721862793, "training_acc": 53.0, "val_loss": 17.312251031398773, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.11604642868042, "training_acc": 53.0, "val_loss": 17.315196990966797, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18610405921936, "training_acc": 53.0, "val_loss": 17.3082172870636, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12515759468079, "training_acc": 53.0, "val_loss": 17.30702966451645, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.04192852973938, "training_acc": 53.0, "val_loss": 17.307893931865692, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08337759971619, "training_acc": 53.0, "val_loss": 17.312870919704437, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.02386426925659, "training_acc": 53.0, "val_loss": 17.31347292661667, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.98981785774231, "training_acc": 53.0, "val_loss": 17.3070028424263, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02955770492554, "training_acc": 53.0, "val_loss": 17.30843335390091, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.03898596763611, "training_acc": 53.0, "val_loss": 17.306064069271088, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0320212841034, "training_acc": 53.0, "val_loss": 17.3057422041893, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.00669550895691, "training_acc": 53.0, "val_loss": 17.304886877536774, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.89213848114014, "training_acc": 53.0, "val_loss": 17.304733395576477, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.90906071662903, "training_acc": 53.0, "val_loss": 17.29867160320282, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.02380108833313, "training_acc": 53.0, "val_loss": 17.289987206459045, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.94065022468567, "training_acc": 53.0, "val_loss": 17.276233434677124, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.84273648262024, "training_acc": 53.0, "val_loss": 17.269577085971832, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.86015510559082, "training_acc": 53.0, "val_loss": 17.271307110786438, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.73393297195435, "training_acc": 53.0, "val_loss": 17.27967858314514, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.82184624671936, "training_acc": 53.0, "val_loss": 17.292457818984985, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.74567341804504, "training_acc": 53.0, "val_loss": 17.300155758857727, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.6545295715332, "training_acc": 53.0, "val_loss": 17.29925274848938, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.72486996650696, "training_acc": 53.0, "val_loss": 17.294245958328247, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.66744780540466, "training_acc": 53.0, "val_loss": 17.29297786951065, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.64587736129761, "training_acc": 53.0, "val_loss": 17.29031205177307, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.74159383773804, "training_acc": 53.0, "val_loss": 17.288604378700256, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.5926468372345, "training_acc": 53.0, "val_loss": 17.28530526161194, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.67968010902405, "training_acc": 53.0, "val_loss": 17.283201217651367, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.64376783370972, "training_acc": 53.0, "val_loss": 17.27951169013977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.47716450691223, "training_acc": 53.0, "val_loss": 17.286470532417297, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.59452867507935, "training_acc": 53.0, "val_loss": 17.297764122486115, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.77774453163147, "training_acc": 53.0, "val_loss": 17.297139763832092, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.52397656440735, "training_acc": 53.0, "val_loss": 17.288009822368622, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.58032989501953, "training_acc": 53.0, "val_loss": 17.2784686088562, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.43217086791992, "training_acc": 53.0, "val_loss": 17.272868752479553, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.44050168991089, "training_acc": 53.0, "val_loss": 17.2736257314682, "val_acc": 52.0}
