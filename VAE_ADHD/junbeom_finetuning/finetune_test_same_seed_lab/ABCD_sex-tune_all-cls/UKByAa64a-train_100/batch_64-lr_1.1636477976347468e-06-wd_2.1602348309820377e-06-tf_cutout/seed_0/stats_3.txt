"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.36183857917786, "training_acc": 44.0, "val_loss": 17.31022000312805, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18600630760193, "training_acc": 60.0, "val_loss": 17.301711440086365, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.28587555885315, "training_acc": 55.0, "val_loss": 17.29051321744919, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16338682174683, "training_acc": 58.0, "val_loss": 17.287437617778778, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16111087799072, "training_acc": 58.0, "val_loss": 17.28307157754898, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12595415115356, "training_acc": 61.0, "val_loss": 17.282038927078247, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.145423412323, "training_acc": 55.0, "val_loss": 17.282725870609283, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13149976730347, "training_acc": 53.0, "val_loss": 17.293265461921692, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.05464363098145, "training_acc": 56.0, "val_loss": 17.302778363227844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.00979709625244, "training_acc": 56.0, "val_loss": 17.30804592370987, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15590786933899, "training_acc": 54.0, "val_loss": 17.315086722373962, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.96828269958496, "training_acc": 55.0, "val_loss": 17.320938408374786, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.0021140575409, "training_acc": 54.0, "val_loss": 17.31977015733719, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.90968012809753, "training_acc": 53.0, "val_loss": 17.315006256103516, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.85510921478271, "training_acc": 55.0, "val_loss": 17.307357490062714, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.80450892448425, "training_acc": 53.0, "val_loss": 17.296238243579865, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.8919448852539, "training_acc": 54.0, "val_loss": 17.290186882019043, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.68129062652588, "training_acc": 53.0, "val_loss": 17.28537082672119, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.76020836830139, "training_acc": 54.0, "val_loss": 17.282886803150177, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.84372067451477, "training_acc": 54.0, "val_loss": 17.282716929912567, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.8377480506897, "training_acc": 56.0, "val_loss": 17.28675067424774, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.7995216846466, "training_acc": 53.0, "val_loss": 17.290054261684418, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.66605830192566, "training_acc": 54.0, "val_loss": 17.294611036777496, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.69509053230286, "training_acc": 55.0, "val_loss": 17.30675995349884, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.54677963256836, "training_acc": 54.0, "val_loss": 17.31874942779541, "val_acc": 52.0}
