"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39160919189453, "training_acc": 52.0, "val_loss": 17.275191843509674, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.21203017234802, "training_acc": 52.0, "val_loss": 17.279791831970215, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.18525385856628, "training_acc": 52.0, "val_loss": 17.27965921163559, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.1616599559784, "training_acc": 52.0, "val_loss": 17.277151346206665, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.26787114143372, "training_acc": 52.0, "val_loss": 17.280907928943634, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23600029945374, "training_acc": 52.0, "val_loss": 17.28881299495697, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.14214706420898, "training_acc": 52.0, "val_loss": 17.289038002490997, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24703526496887, "training_acc": 52.0, "val_loss": 17.29028671979904, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.13797926902771, "training_acc": 52.0, "val_loss": 17.286907136440277, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.15115761756897, "training_acc": 52.0, "val_loss": 17.28697568178177, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.10179471969604, "training_acc": 52.0, "val_loss": 17.28549301624298, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.05980467796326, "training_acc": 52.0, "val_loss": 17.28222668170929, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.89705848693848, "training_acc": 52.0, "val_loss": 17.277437448501587, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.98876309394836, "training_acc": 52.0, "val_loss": 17.270904779434204, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.00719785690308, "training_acc": 52.0, "val_loss": 17.270877957344055, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.00260972976685, "training_acc": 52.0, "val_loss": 17.273367941379547, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.96374607086182, "training_acc": 52.0, "val_loss": 17.268340289592743, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.89448738098145, "training_acc": 52.0, "val_loss": 17.264501750469208, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.82158946990967, "training_acc": 52.0, "val_loss": 17.26122796535492, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.85335659980774, "training_acc": 52.0, "val_loss": 17.258208990097046, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.85749506950378, "training_acc": 52.0, "val_loss": 17.259210348129272, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.80558633804321, "training_acc": 52.0, "val_loss": 17.261382937431335, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.8531653881073, "training_acc": 52.0, "val_loss": 17.26130247116089, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.8584794998169, "training_acc": 52.0, "val_loss": 17.263518273830414, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.8926694393158, "training_acc": 52.0, "val_loss": 17.279018461704254, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.89773678779602, "training_acc": 52.0, "val_loss": 17.27960556745529, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.50617980957031, "training_acc": 52.0, "val_loss": 17.27101057767868, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.88519930839539, "training_acc": 52.0, "val_loss": 17.271026968955994, "val_acc": 56.0}
{"epoch": 28, "training_loss": 68.80908489227295, "training_acc": 52.0, "val_loss": 17.27742850780487, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.74892783164978, "training_acc": 52.0, "val_loss": 17.282718420028687, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.80667495727539, "training_acc": 52.0, "val_loss": 17.284928262233734, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.78083872795105, "training_acc": 52.0, "val_loss": 17.285095155239105, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.76220560073853, "training_acc": 52.0, "val_loss": 17.28132665157318, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.4493956565857, "training_acc": 52.0, "val_loss": 17.279422283172607, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.78977417945862, "training_acc": 52.0, "val_loss": 17.27668195962906, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.64070200920105, "training_acc": 52.0, "val_loss": 17.281213402748108, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.51982235908508, "training_acc": 52.0, "val_loss": 17.28382408618927, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.57574558258057, "training_acc": 52.0, "val_loss": 17.286422848701477, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.61409401893616, "training_acc": 52.0, "val_loss": 17.287127673625946, "val_acc": 56.0}
