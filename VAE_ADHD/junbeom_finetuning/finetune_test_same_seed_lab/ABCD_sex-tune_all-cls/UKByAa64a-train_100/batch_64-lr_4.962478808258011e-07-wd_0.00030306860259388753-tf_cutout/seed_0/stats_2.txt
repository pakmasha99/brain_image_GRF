"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.93091535568237, "training_acc": 53.0, "val_loss": 17.328864336013794, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27216815948486, "training_acc": 53.0, "val_loss": 17.326384782791138, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.07270336151123, "training_acc": 53.0, "val_loss": 17.323340475559235, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18147730827332, "training_acc": 53.0, "val_loss": 17.319276928901672, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.03282499313354, "training_acc": 53.0, "val_loss": 17.31579601764679, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.95447969436646, "training_acc": 53.0, "val_loss": 17.311592400074005, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.020503282547, "training_acc": 53.0, "val_loss": 17.308303713798523, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.06661796569824, "training_acc": 53.0, "val_loss": 17.306560277938843, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.0471556186676, "training_acc": 53.0, "val_loss": 17.304416000843048, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22114944458008, "training_acc": 53.0, "val_loss": 17.30254888534546, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.94466495513916, "training_acc": 53.0, "val_loss": 17.301364243030548, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.96168375015259, "training_acc": 53.0, "val_loss": 17.299285531044006, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.04933309555054, "training_acc": 53.0, "val_loss": 17.296242713928223, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.95069146156311, "training_acc": 54.0, "val_loss": 17.293940484523773, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.96051144599915, "training_acc": 53.0, "val_loss": 17.29314923286438, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11114382743835, "training_acc": 53.0, "val_loss": 17.292632162570953, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.91960144042969, "training_acc": 53.0, "val_loss": 17.292499542236328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.9794373512268, "training_acc": 53.0, "val_loss": 17.292337119579315, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.92462801933289, "training_acc": 54.0, "val_loss": 17.29230433702469, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.91154527664185, "training_acc": 53.0, "val_loss": 17.291301488876343, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.0477979183197, "training_acc": 55.0, "val_loss": 17.290407419204712, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.72229194641113, "training_acc": 53.0, "val_loss": 17.290164530277252, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.77166771888733, "training_acc": 54.0, "val_loss": 17.2907292842865, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.04088306427002, "training_acc": 53.0, "val_loss": 17.290975153446198, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.80218768119812, "training_acc": 54.0, "val_loss": 17.291399836540222, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.07851195335388, "training_acc": 53.0, "val_loss": 17.292331159114838, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.82807636260986, "training_acc": 53.0, "val_loss": 17.29339510202408, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.96888279914856, "training_acc": 53.0, "val_loss": 17.294088006019592, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.84045004844666, "training_acc": 54.0, "val_loss": 17.294582724571228, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.87106275558472, "training_acc": 53.0, "val_loss": 17.29496568441391, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.95230984687805, "training_acc": 53.0, "val_loss": 17.29440838098526, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.80307269096375, "training_acc": 53.0, "val_loss": 17.293870449066162, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.8581440448761, "training_acc": 53.0, "val_loss": 17.292873561382294, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.70336771011353, "training_acc": 53.0, "val_loss": 17.29257106781006, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.6860864162445, "training_acc": 53.0, "val_loss": 17.291375994682312, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.9031834602356, "training_acc": 53.0, "val_loss": 17.290081083774567, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.51357769966125, "training_acc": 54.0, "val_loss": 17.289020121097565, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.81965589523315, "training_acc": 53.0, "val_loss": 17.28871911764145, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.78711032867432, "training_acc": 54.0, "val_loss": 17.2883540391922, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.81193161010742, "training_acc": 54.0, "val_loss": 17.28908121585846, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.82393145561218, "training_acc": 54.0, "val_loss": 17.289921641349792, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.64941167831421, "training_acc": 54.0, "val_loss": 17.29074865579605, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.80837368965149, "training_acc": 55.0, "val_loss": 17.29198843240738, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.67388868331909, "training_acc": 56.0, "val_loss": 17.293456196784973, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.68419337272644, "training_acc": 55.0, "val_loss": 17.295490205287933, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.47565484046936, "training_acc": 55.0, "val_loss": 17.29961931705475, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.78323793411255, "training_acc": 55.0, "val_loss": 17.3031747341156, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.62237644195557, "training_acc": 54.0, "val_loss": 17.30559468269348, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.60549402236938, "training_acc": 55.0, "val_loss": 17.309311032295227, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.4713146686554, "training_acc": 58.0, "val_loss": 17.316512763500214, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.70402240753174, "training_acc": 56.0, "val_loss": 17.323589324951172, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.71799325942993, "training_acc": 55.0, "val_loss": 17.327798902988434, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.72482228279114, "training_acc": 54.0, "val_loss": 17.32996106147766, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.96350479125977, "training_acc": 51.0, "val_loss": 17.33330637216568, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.44519472122192, "training_acc": 60.0, "val_loss": 17.33662337064743, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.50917363166809, "training_acc": 61.0, "val_loss": 17.337682843208313, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.29161024093628, "training_acc": 59.0, "val_loss": 17.337138950824738, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.48807454109192, "training_acc": 56.0, "val_loss": 17.33713448047638, "val_acc": 52.0}
