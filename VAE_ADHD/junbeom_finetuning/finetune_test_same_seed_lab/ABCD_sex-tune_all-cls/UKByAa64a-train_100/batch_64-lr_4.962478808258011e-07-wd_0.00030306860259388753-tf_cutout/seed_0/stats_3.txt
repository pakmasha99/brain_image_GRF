"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.66147494316101, "training_acc": 47.0, "val_loss": 17.30884164571762, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18944978713989, "training_acc": 53.0, "val_loss": 17.304767668247223, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.25695490837097, "training_acc": 56.0, "val_loss": 17.30033904314041, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.35061955451965, "training_acc": 44.0, "val_loss": 17.29644685983658, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.35239768028259, "training_acc": 51.0, "val_loss": 17.291903495788574, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.27183771133423, "training_acc": 55.0, "val_loss": 17.28825569152832, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22956204414368, "training_acc": 52.0, "val_loss": 17.285381257534027, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.3727490901947, "training_acc": 53.0, "val_loss": 17.28285551071167, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.20708680152893, "training_acc": 53.0, "val_loss": 17.281466722488403, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.09773993492126, "training_acc": 53.0, "val_loss": 17.28108376264572, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20639109611511, "training_acc": 53.0, "val_loss": 17.281444370746613, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10238194465637, "training_acc": 53.0, "val_loss": 17.282089591026306, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22690320014954, "training_acc": 53.0, "val_loss": 17.283007502555847, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22778630256653, "training_acc": 53.0, "val_loss": 17.285050451755524, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11453938484192, "training_acc": 53.0, "val_loss": 17.287515103816986, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.06742858886719, "training_acc": 53.0, "val_loss": 17.289897799491882, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16642689704895, "training_acc": 53.0, "val_loss": 17.29302555322647, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12781023979187, "training_acc": 53.0, "val_loss": 17.29552447795868, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.98382997512817, "training_acc": 53.0, "val_loss": 17.297467589378357, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.95804619789124, "training_acc": 53.0, "val_loss": 17.298755049705505, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.99427723884583, "training_acc": 53.0, "val_loss": 17.29937642812729, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17348098754883, "training_acc": 53.0, "val_loss": 17.30063408613205, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.97281980514526, "training_acc": 53.0, "val_loss": 17.301669716835022, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.03936743736267, "training_acc": 53.0, "val_loss": 17.30261892080307, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.99363303184509, "training_acc": 53.0, "val_loss": 17.303740978240967, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.0103235244751, "training_acc": 53.0, "val_loss": 17.30509102344513, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.02707314491272, "training_acc": 53.0, "val_loss": 17.306098341941833, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.03373384475708, "training_acc": 53.0, "val_loss": 17.306676506996155, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.9404947757721, "training_acc": 53.0, "val_loss": 17.306555807590485, "val_acc": 52.0}
