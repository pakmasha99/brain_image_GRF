"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.63354587554932, "training_acc": 53.0, "val_loss": 17.450489103794098, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.44145560264587, "training_acc": 53.0, "val_loss": 17.365404963493347, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.26759028434753, "training_acc": 53.0, "val_loss": 17.394524812698364, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.24133086204529, "training_acc": 53.0, "val_loss": 17.395934462547302, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33384823799133, "training_acc": 53.0, "val_loss": 17.4489364027977, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.4280092716217, "training_acc": 53.0, "val_loss": 17.442747950553894, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.37862539291382, "training_acc": 53.0, "val_loss": 17.418155074119568, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.31774473190308, "training_acc": 53.0, "val_loss": 17.393529415130615, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11661124229431, "training_acc": 53.0, "val_loss": 17.377856373786926, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.88827133178711, "training_acc": 53.0, "val_loss": 17.36004799604416, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.02713322639465, "training_acc": 53.0, "val_loss": 17.33015477657318, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.05149030685425, "training_acc": 53.0, "val_loss": 17.282608151435852, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11880230903625, "training_acc": 53.0, "val_loss": 17.28675663471222, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.80339074134827, "training_acc": 53.0, "val_loss": 17.330564558506012, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.92255425453186, "training_acc": 53.0, "val_loss": 17.358310520648956, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.9721028804779, "training_acc": 53.0, "val_loss": 17.365653812885284, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.71187853813171, "training_acc": 53.0, "val_loss": 17.360973358154297, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.86856579780579, "training_acc": 53.0, "val_loss": 17.365285754203796, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.86248731613159, "training_acc": 53.0, "val_loss": 17.369845509529114, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.87224078178406, "training_acc": 53.0, "val_loss": 17.370077967643738, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.67348551750183, "training_acc": 53.0, "val_loss": 17.38245040178299, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.62733006477356, "training_acc": 53.0, "val_loss": 17.374269664287567, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.39672422409058, "training_acc": 53.0, "val_loss": 17.389576137065887, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.62865090370178, "training_acc": 53.0, "val_loss": 17.398801445961, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.28656053543091, "training_acc": 53.0, "val_loss": 17.392127215862274, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.36871433258057, "training_acc": 55.0, "val_loss": 17.26139634847641, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.8625340461731, "training_acc": 56.0, "val_loss": 17.20084547996521, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.66298007965088, "training_acc": 53.0, "val_loss": 17.27912127971649, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.52647829055786, "training_acc": 56.0, "val_loss": 17.387382686138153, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.27311444282532, "training_acc": 53.0, "val_loss": 17.409251630306244, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.13261795043945, "training_acc": 53.0, "val_loss": 17.38491952419281, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.90218043327332, "training_acc": 54.0, "val_loss": 17.37077087163925, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.72885203361511, "training_acc": 58.0, "val_loss": 17.383310198783875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.79662752151489, "training_acc": 59.0, "val_loss": 17.37026870250702, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.50254654884338, "training_acc": 60.0, "val_loss": 17.40051954984665, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.73379111289978, "training_acc": 62.0, "val_loss": 17.488472163677216, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.78290581703186, "training_acc": 54.0, "val_loss": 17.49834269285202, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.09899616241455, "training_acc": 53.0, "val_loss": 17.396071553230286, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.14860010147095, "training_acc": 75.0, "val_loss": 17.321433126926422, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.76332116127014, "training_acc": 66.0, "val_loss": 17.509371042251587, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.514892578125, "training_acc": 56.0, "val_loss": 17.499271035194397, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.52733278274536, "training_acc": 56.0, "val_loss": 17.389538884162903, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.21053338050842, "training_acc": 75.0, "val_loss": 17.42085963487625, "val_acc": 52.0}
{"epoch": 43, "training_loss": 66.38492512702942, "training_acc": 66.0, "val_loss": 17.538602650165558, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.7152373790741, "training_acc": 67.0, "val_loss": 17.391467094421387, "val_acc": 52.0}
{"epoch": 45, "training_loss": 64.56526589393616, "training_acc": 69.0, "val_loss": 17.460674047470093, "val_acc": 52.0}
