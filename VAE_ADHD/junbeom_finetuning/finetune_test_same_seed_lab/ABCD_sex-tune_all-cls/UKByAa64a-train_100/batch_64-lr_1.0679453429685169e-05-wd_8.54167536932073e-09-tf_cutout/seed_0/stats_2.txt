"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.22437834739685, "training_acc": 53.0, "val_loss": 17.367178201675415, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15045642852783, "training_acc": 53.0, "val_loss": 17.348895967006683, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16036677360535, "training_acc": 53.0, "val_loss": 17.32308566570282, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15621733665466, "training_acc": 53.0, "val_loss": 17.31579601764679, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.10848569869995, "training_acc": 53.0, "val_loss": 17.324337363243103, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06203889846802, "training_acc": 53.0, "val_loss": 17.33400821685791, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.93954396247864, "training_acc": 53.0, "val_loss": 17.326894402503967, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.95006084442139, "training_acc": 53.0, "val_loss": 17.31017231941223, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.73167204856873, "training_acc": 53.0, "val_loss": 17.325076460838318, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.72127485275269, "training_acc": 53.0, "val_loss": 17.319460213184357, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.74038410186768, "training_acc": 53.0, "val_loss": 17.30349510908127, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.59645247459412, "training_acc": 53.0, "val_loss": 17.30675846338272, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.71539950370789, "training_acc": 53.0, "val_loss": 17.307421565055847, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.81348776817322, "training_acc": 53.0, "val_loss": 17.300251126289368, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.66985249519348, "training_acc": 53.0, "val_loss": 17.310068011283875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.35641837120056, "training_acc": 53.0, "val_loss": 17.305178940296173, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.60505414009094, "training_acc": 55.0, "val_loss": 17.283454537391663, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.04909181594849, "training_acc": 54.0, "val_loss": 17.283400893211365, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.40267539024353, "training_acc": 53.0, "val_loss": 17.27953553199768, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.9292004108429, "training_acc": 53.0, "val_loss": 17.295189201831818, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.05412268638611, "training_acc": 53.0, "val_loss": 17.30431318283081, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.79793548583984, "training_acc": 58.0, "val_loss": 17.27643758058548, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.31530857086182, "training_acc": 63.0, "val_loss": 17.31298565864563, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.88257312774658, "training_acc": 53.0, "val_loss": 17.25136935710907, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.03878450393677, "training_acc": 63.0, "val_loss": 17.223407328128815, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.29683232307434, "training_acc": 59.0, "val_loss": 17.318201065063477, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.90734100341797, "training_acc": 64.0, "val_loss": 17.20789670944214, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.15073323249817, "training_acc": 55.0, "val_loss": 17.17565506696701, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.23082566261292, "training_acc": 68.0, "val_loss": 17.175990343093872, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.9710533618927, "training_acc": 66.0, "val_loss": 17.335081100463867, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.85345578193665, "training_acc": 58.0, "val_loss": 17.300809919834137, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.89361214637756, "training_acc": 73.0, "val_loss": 17.159366607666016, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.33379101753235, "training_acc": 67.0, "val_loss": 17.208367586135864, "val_acc": 52.0}
{"epoch": 33, "training_loss": 63.901145458221436, "training_acc": 69.0, "val_loss": 17.147140204906464, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.6402359008789, "training_acc": 77.0, "val_loss": 17.28510558605194, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.15519690513611, "training_acc": 65.0, "val_loss": 17.086991667747498, "val_acc": 52.0}
{"epoch": 36, "training_loss": 62.99835133552551, "training_acc": 78.0, "val_loss": 17.05325096845627, "val_acc": 52.0}
{"epoch": 37, "training_loss": 61.76817464828491, "training_acc": 83.0, "val_loss": 17.165428400039673, "val_acc": 52.0}
{"epoch": 38, "training_loss": 62.30170750617981, "training_acc": 72.0, "val_loss": 17.159628868103027, "val_acc": 52.0}
{"epoch": 39, "training_loss": 61.32042121887207, "training_acc": 82.0, "val_loss": 17.175042629241943, "val_acc": 52.0}
{"epoch": 40, "training_loss": 63.04637885093689, "training_acc": 65.0, "val_loss": 17.034952342510223, "val_acc": 52.0}
{"epoch": 41, "training_loss": 61.055981397628784, "training_acc": 73.0, "val_loss": 17.024241387844086, "val_acc": 52.0}
{"epoch": 42, "training_loss": 60.924238443374634, "training_acc": 86.0, "val_loss": 17.168258130550385, "val_acc": 52.0}
{"epoch": 43, "training_loss": 60.419047832489014, "training_acc": 69.0, "val_loss": 16.964420676231384, "val_acc": 52.0}
{"epoch": 44, "training_loss": 59.422566175460815, "training_acc": 87.0, "val_loss": 17.250926792621613, "val_acc": 52.0}
{"epoch": 45, "training_loss": 58.56648564338684, "training_acc": 75.0, "val_loss": 17.514754831790924, "val_acc": 52.0}
{"epoch": 46, "training_loss": 67.35385870933533, "training_acc": 58.0, "val_loss": 17.04055219888687, "val_acc": 52.0}
{"epoch": 47, "training_loss": 59.463589906692505, "training_acc": 75.0, "val_loss": 16.954559087753296, "val_acc": 52.0}
{"epoch": 48, "training_loss": 58.322354555130005, "training_acc": 82.0, "val_loss": 17.003387212753296, "val_acc": 52.0}
{"epoch": 49, "training_loss": 59.85171318054199, "training_acc": 79.0, "val_loss": 17.71993637084961, "val_acc": 52.0}
{"epoch": 50, "training_loss": 60.75231146812439, "training_acc": 70.0, "val_loss": 17.00403243303299, "val_acc": 52.0}
{"epoch": 51, "training_loss": 58.60628581047058, "training_acc": 86.0, "val_loss": 17.241138219833374, "val_acc": 52.0}
{"epoch": 52, "training_loss": 59.11818027496338, "training_acc": 68.0, "val_loss": 16.912947595119476, "val_acc": 52.0}
{"epoch": 53, "training_loss": 58.62962579727173, "training_acc": 74.0, "val_loss": 17.308804392814636, "val_acc": 60.0}
{"epoch": 54, "training_loss": 60.370068311691284, "training_acc": 78.0, "val_loss": 17.437918484210968, "val_acc": 52.0}
{"epoch": 55, "training_loss": 59.07995414733887, "training_acc": 68.0, "val_loss": 16.811542212963104, "val_acc": 52.0}
{"epoch": 56, "training_loss": 55.026280641555786, "training_acc": 92.0, "val_loss": 16.821330785751343, "val_acc": 52.0}
{"epoch": 57, "training_loss": 55.64203333854675, "training_acc": 89.0, "val_loss": 17.04668700695038, "val_acc": 52.0}
{"epoch": 58, "training_loss": 52.77200102806091, "training_acc": 94.0, "val_loss": 16.890084743499756, "val_acc": 56.0}
{"epoch": 59, "training_loss": 52.867940187454224, "training_acc": 92.0, "val_loss": 16.924293339252472, "val_acc": 52.0}
{"epoch": 60, "training_loss": 53.37751317024231, "training_acc": 89.0, "val_loss": 16.85430258512497, "val_acc": 56.0}
{"epoch": 61, "training_loss": 52.094114661216736, "training_acc": 90.0, "val_loss": 16.876059770584106, "val_acc": 52.0}
{"epoch": 62, "training_loss": 51.442657232284546, "training_acc": 92.0, "val_loss": 16.9004887342453, "val_acc": 52.0}
{"epoch": 63, "training_loss": 50.33212065696716, "training_acc": 94.0, "val_loss": 16.91254824399948, "val_acc": 52.0}
{"epoch": 64, "training_loss": 48.8941547870636, "training_acc": 95.0, "val_loss": 16.893476247787476, "val_acc": 60.0}
{"epoch": 65, "training_loss": 49.36968469619751, "training_acc": 96.0, "val_loss": 17.443394660949707, "val_acc": 52.0}
{"epoch": 66, "training_loss": 51.75468647480011, "training_acc": 84.0, "val_loss": 17.015285789966583, "val_acc": 56.0}
{"epoch": 67, "training_loss": 48.196380972862244, "training_acc": 96.0, "val_loss": 17.234578728675842, "val_acc": 56.0}
{"epoch": 68, "training_loss": 49.982879638671875, "training_acc": 95.0, "val_loss": 17.06375777721405, "val_acc": 60.0}
{"epoch": 69, "training_loss": 50.388181924819946, "training_acc": 90.0, "val_loss": 17.108584940433502, "val_acc": 60.0}
{"epoch": 70, "training_loss": 48.036975741386414, "training_acc": 95.0, "val_loss": 17.279021441936493, "val_acc": 56.0}
{"epoch": 71, "training_loss": 47.13739371299744, "training_acc": 96.0, "val_loss": 17.180676758289337, "val_acc": 52.0}
{"epoch": 72, "training_loss": 46.7805370092392, "training_acc": 97.0, "val_loss": 17.29339063167572, "val_acc": 52.0}
{"epoch": 73, "training_loss": 45.81898903846741, "training_acc": 96.0, "val_loss": 17.151649296283722, "val_acc": 56.0}
{"epoch": 74, "training_loss": 49.363521695137024, "training_acc": 88.0, "val_loss": 17.317430675029755, "val_acc": 56.0}
