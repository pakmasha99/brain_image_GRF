"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.14110684394836, "training_acc": 53.0, "val_loss": 17.316463589668274, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.09774231910706, "training_acc": 53.0, "val_loss": 17.31320172548294, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15067791938782, "training_acc": 53.0, "val_loss": 17.308570444583893, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.06654286384583, "training_acc": 53.0, "val_loss": 17.303965985774994, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16614818572998, "training_acc": 53.0, "val_loss": 17.304491996765137, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.02542519569397, "training_acc": 53.0, "val_loss": 17.301276326179504, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17602181434631, "training_acc": 53.0, "val_loss": 17.297515273094177, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09976243972778, "training_acc": 53.0, "val_loss": 17.29619950056076, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.96601843833923, "training_acc": 53.0, "val_loss": 17.295612394809723, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11998009681702, "training_acc": 53.0, "val_loss": 17.295265197753906, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.03783845901489, "training_acc": 53.0, "val_loss": 17.29489415884018, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.01427435874939, "training_acc": 53.0, "val_loss": 17.29443669319153, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.05801105499268, "training_acc": 53.0, "val_loss": 17.294780910015106, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.98182606697083, "training_acc": 53.0, "val_loss": 17.29457825422287, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.89848065376282, "training_acc": 53.0, "val_loss": 17.2957643866539, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.08299374580383, "training_acc": 53.0, "val_loss": 17.297938466072083, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.06179356575012, "training_acc": 53.0, "val_loss": 17.299146950244904, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.00952577590942, "training_acc": 53.0, "val_loss": 17.29838103055954, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.9983720779419, "training_acc": 53.0, "val_loss": 17.298075556755066, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.96924638748169, "training_acc": 53.0, "val_loss": 17.29850471019745, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.99008560180664, "training_acc": 53.0, "val_loss": 17.300117015838623, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.00277018547058, "training_acc": 53.0, "val_loss": 17.30104237794876, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.89462375640869, "training_acc": 53.0, "val_loss": 17.301766574382782, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.95132160186768, "training_acc": 53.0, "val_loss": 17.301207780838013, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.99556827545166, "training_acc": 53.0, "val_loss": 17.300567030906677, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.87859058380127, "training_acc": 53.0, "val_loss": 17.300428450107574, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.84799575805664, "training_acc": 53.0, "val_loss": 17.30196177959442, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.9530816078186, "training_acc": 53.0, "val_loss": 17.30223000049591, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.93848919868469, "training_acc": 53.0, "val_loss": 17.30210781097412, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.80528664588928, "training_acc": 53.0, "val_loss": 17.302820086479187, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.00480198860168, "training_acc": 53.0, "val_loss": 17.30494499206543, "val_acc": 52.0}
