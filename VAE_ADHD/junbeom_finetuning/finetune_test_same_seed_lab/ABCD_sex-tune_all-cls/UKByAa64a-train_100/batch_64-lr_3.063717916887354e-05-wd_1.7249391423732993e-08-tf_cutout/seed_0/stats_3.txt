"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.48456525802612, "training_acc": 53.0, "val_loss": 17.351095378398895, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.14184999465942, "training_acc": 53.0, "val_loss": 17.35609769821167, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2139790058136, "training_acc": 53.0, "val_loss": 17.374984920024872, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16659140586853, "training_acc": 53.0, "val_loss": 17.344653606414795, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.83274579048157, "training_acc": 53.0, "val_loss": 17.35187917947769, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14710187911987, "training_acc": 53.0, "val_loss": 17.3333540558815, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.86910080909729, "training_acc": 53.0, "val_loss": 17.359361052513123, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.92226719856262, "training_acc": 53.0, "val_loss": 17.358046770095825, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.6600239276886, "training_acc": 55.0, "val_loss": 17.387261986732483, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.63679456710815, "training_acc": 53.0, "val_loss": 17.446552217006683, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.48319363594055, "training_acc": 53.0, "val_loss": 17.426887154579163, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.51115202903748, "training_acc": 53.0, "val_loss": 17.367365956306458, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07319045066833, "training_acc": 53.0, "val_loss": 17.353077232837677, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08772706985474, "training_acc": 53.0, "val_loss": 17.330464720726013, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.84294819831848, "training_acc": 53.0, "val_loss": 17.325831949710846, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.81050777435303, "training_acc": 53.0, "val_loss": 17.33066588640213, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.84673261642456, "training_acc": 53.0, "val_loss": 17.33064204454422, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17328381538391, "training_acc": 52.0, "val_loss": 17.3314169049263, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.73091554641724, "training_acc": 57.0, "val_loss": 17.35074371099472, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15179252624512, "training_acc": 49.0, "val_loss": 17.354923486709595, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05467653274536, "training_acc": 54.0, "val_loss": 17.341552674770355, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.77349710464478, "training_acc": 62.0, "val_loss": 17.33652800321579, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.59731149673462, "training_acc": 56.0, "val_loss": 17.356640100479126, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.11514496803284, "training_acc": 56.0, "val_loss": 17.406056821346283, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.22714567184448, "training_acc": 54.0, "val_loss": 17.419782280921936, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.5680480003357, "training_acc": 62.0, "val_loss": 17.37878769636154, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.97247838973999, "training_acc": 64.0, "val_loss": 17.48819351196289, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.89326477050781, "training_acc": 62.0, "val_loss": 17.633482813835144, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.04874396324158, "training_acc": 59.0, "val_loss": 17.619960010051727, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.02510452270508, "training_acc": 62.0, "val_loss": 17.346099019050598, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.27080631256104, "training_acc": 66.0, "val_loss": 17.745807766914368, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.79842829704285, "training_acc": 57.0, "val_loss": 17.531760036945343, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.79837369918823, "training_acc": 65.0, "val_loss": 17.773181200027466, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.58979320526123, "training_acc": 71.0, "val_loss": 17.515233159065247, "val_acc": 52.0}
