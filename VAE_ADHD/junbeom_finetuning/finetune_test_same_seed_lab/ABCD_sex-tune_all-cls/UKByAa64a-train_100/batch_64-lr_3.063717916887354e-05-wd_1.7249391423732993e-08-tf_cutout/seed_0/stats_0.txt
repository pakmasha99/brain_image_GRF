"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26841640472412, "training_acc": 52.0, "val_loss": 17.299292981624603, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.09930467605591, "training_acc": 52.0, "val_loss": 17.305853962898254, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.15932178497314, "training_acc": 52.0, "val_loss": 17.276427149772644, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.238609790802, "training_acc": 52.0, "val_loss": 17.286841571331024, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.16709971427917, "training_acc": 52.0, "val_loss": 17.284151911735535, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22832417488098, "training_acc": 52.0, "val_loss": 17.27483868598938, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.19023513793945, "training_acc": 52.0, "val_loss": 17.309093475341797, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.12908887863159, "training_acc": 52.0, "val_loss": 17.296406626701355, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27006077766418, "training_acc": 52.0, "val_loss": 17.266474664211273, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.08094382286072, "training_acc": 52.0, "val_loss": 17.291201651096344, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.0696268081665, "training_acc": 52.0, "val_loss": 17.322057485580444, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.08608746528625, "training_acc": 53.0, "val_loss": 17.304836213588715, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.97386884689331, "training_acc": 52.0, "val_loss": 17.31695830821991, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.89584732055664, "training_acc": 53.0, "val_loss": 17.344675958156586, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.82599329948425, "training_acc": 53.0, "val_loss": 17.295314371585846, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.76318097114563, "training_acc": 53.0, "val_loss": 17.271563410758972, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.57866549491882, "training_acc": 52.0, "val_loss": 17.270205914974213, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.88526272773743, "training_acc": 53.0, "val_loss": 17.338673770427704, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.5691294670105, "training_acc": 55.0, "val_loss": 17.314280569553375, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.57565832138062, "training_acc": 52.0, "val_loss": 17.319422960281372, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.6920838356018, "training_acc": 58.0, "val_loss": 17.397935688495636, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.15193223953247, "training_acc": 59.0, "val_loss": 17.29019582271576, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.90345621109009, "training_acc": 52.0, "val_loss": 17.289917171001434, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.16525626182556, "training_acc": 55.0, "val_loss": 17.575375735759735, "val_acc": 56.0}
{"epoch": 24, "training_loss": 68.6763026714325, "training_acc": 55.0, "val_loss": 17.58621037006378, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.33321976661682, "training_acc": 56.0, "val_loss": 17.320339381694794, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.47113156318665, "training_acc": 56.0, "val_loss": 17.27321594953537, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.7131187915802, "training_acc": 52.0, "val_loss": 17.563574016094208, "val_acc": 56.0}
