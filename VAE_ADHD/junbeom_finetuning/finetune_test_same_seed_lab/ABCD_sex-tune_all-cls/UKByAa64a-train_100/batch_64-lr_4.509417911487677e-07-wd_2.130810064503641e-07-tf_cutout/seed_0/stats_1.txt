"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.64555406570435, "training_acc": 47.0, "val_loss": 17.397044599056244, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.45567059516907, "training_acc": 47.0, "val_loss": 17.394481599330902, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.48962903022766, "training_acc": 47.0, "val_loss": 17.391014099121094, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.46928405761719, "training_acc": 47.0, "val_loss": 17.3875093460083, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.43676114082336, "training_acc": 47.0, "val_loss": 17.386943101882935, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.43979024887085, "training_acc": 47.0, "val_loss": 17.38254576921463, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28351068496704, "training_acc": 47.0, "val_loss": 17.37544983625412, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.34345269203186, "training_acc": 47.0, "val_loss": 17.369742691516876, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3176646232605, "training_acc": 48.0, "val_loss": 17.36260950565338, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.391197681427, "training_acc": 48.0, "val_loss": 17.355795204639435, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4165050983429, "training_acc": 47.0, "val_loss": 17.350342869758606, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.34158253669739, "training_acc": 50.0, "val_loss": 17.34793186187744, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.37859201431274, "training_acc": 47.0, "val_loss": 17.345401644706726, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16980600357056, "training_acc": 53.0, "val_loss": 17.340926826000214, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27845335006714, "training_acc": 50.0, "val_loss": 17.33871102333069, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.46951007843018, "training_acc": 46.0, "val_loss": 17.335090041160583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18035197257996, "training_acc": 62.0, "val_loss": 17.33395904302597, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16949772834778, "training_acc": 57.0, "val_loss": 17.334219813346863, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20792293548584, "training_acc": 57.0, "val_loss": 17.337438464164734, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19149518013, "training_acc": 53.0, "val_loss": 17.340919375419617, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18570303916931, "training_acc": 58.0, "val_loss": 17.341554164886475, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21375894546509, "training_acc": 52.0, "val_loss": 17.34028160572052, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14339447021484, "training_acc": 56.0, "val_loss": 17.339351773262024, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.95342636108398, "training_acc": 62.0, "val_loss": 17.33730584383011, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.03047752380371, "training_acc": 57.0, "val_loss": 17.336302995681763, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.01050972938538, "training_acc": 57.0, "val_loss": 17.336349189281464, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16816806793213, "training_acc": 48.0, "val_loss": 17.338252067565918, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1677896976471, "training_acc": 53.0, "val_loss": 17.338736355304718, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19637274742126, "training_acc": 50.0, "val_loss": 17.333951592445374, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16801905632019, "training_acc": 51.0, "val_loss": 17.328697443008423, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.95615792274475, "training_acc": 56.0, "val_loss": 17.327508330345154, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.34146618843079, "training_acc": 46.0, "val_loss": 17.32971966266632, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.0778796672821, "training_acc": 59.0, "val_loss": 17.33219176530838, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.91233897209167, "training_acc": 62.0, "val_loss": 17.33906716108322, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.89925742149353, "training_acc": 61.0, "val_loss": 17.345382273197174, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.10873913764954, "training_acc": 50.0, "val_loss": 17.352302372455597, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.92627286911011, "training_acc": 58.0, "val_loss": 17.354004085063934, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.99879169464111, "training_acc": 57.0, "val_loss": 17.348766326904297, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.01509070396423, "training_acc": 61.0, "val_loss": 17.34057515859604, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.78747963905334, "training_acc": 61.0, "val_loss": 17.334680259227753, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.81529998779297, "training_acc": 62.0, "val_loss": 17.331142723560333, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.88694787025452, "training_acc": 57.0, "val_loss": 17.329128086566925, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.97425174713135, "training_acc": 48.0, "val_loss": 17.320261895656586, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.79578709602356, "training_acc": 61.0, "val_loss": 17.313572764396667, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.0858588218689, "training_acc": 51.0, "val_loss": 17.307771742343903, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.8091471195221, "training_acc": 62.0, "val_loss": 17.302879691123962, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.77369332313538, "training_acc": 50.0, "val_loss": 17.296995222568512, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.87673711776733, "training_acc": 55.0, "val_loss": 17.297855019569397, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.94645380973816, "training_acc": 54.0, "val_loss": 17.305731773376465, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.98291444778442, "training_acc": 51.0, "val_loss": 17.31576919555664, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.97963619232178, "training_acc": 53.0, "val_loss": 17.331285774707794, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.8174102306366, "training_acc": 56.0, "val_loss": 17.340482771396637, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.11073613166809, "training_acc": 52.0, "val_loss": 17.33938306570053, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.59780526161194, "training_acc": 60.0, "val_loss": 17.334644496440887, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.0427315235138, "training_acc": 47.0, "val_loss": 17.330795526504517, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.89082288742065, "training_acc": 56.0, "val_loss": 17.32995957136154, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.12585735321045, "training_acc": 54.0, "val_loss": 17.33137220144272, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.80490493774414, "training_acc": 56.0, "val_loss": 17.330478131771088, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.8930892944336, "training_acc": 61.0, "val_loss": 17.3327773809433, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.75550532341003, "training_acc": 55.0, "val_loss": 17.33771413564682, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.53565168380737, "training_acc": 67.0, "val_loss": 17.339403927326202, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.5600426197052, "training_acc": 57.0, "val_loss": 17.33963042497635, "val_acc": 52.0}
{"epoch": 62, "training_loss": 68.5533492565155, "training_acc": 59.0, "val_loss": 17.340022325515747, "val_acc": 52.0}
{"epoch": 63, "training_loss": 68.8111207485199, "training_acc": 57.0, "val_loss": 17.34272539615631, "val_acc": 52.0}
{"epoch": 64, "training_loss": 68.57441329956055, "training_acc": 55.0, "val_loss": 17.342448234558105, "val_acc": 52.0}
{"epoch": 65, "training_loss": 68.61569333076477, "training_acc": 57.0, "val_loss": 17.34183430671692, "val_acc": 52.0}
