"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.48401594161987, "training_acc": 53.0, "val_loss": 17.336006462574005, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.10728454589844, "training_acc": 53.0, "val_loss": 17.308588325977325, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18206524848938, "training_acc": 52.0, "val_loss": 17.31484830379486, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.99476027488708, "training_acc": 50.0, "val_loss": 17.370803654193878, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19544720649719, "training_acc": 53.0, "val_loss": 17.295822501182556, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.05590748786926, "training_acc": 53.0, "val_loss": 17.276334762573242, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.99580430984497, "training_acc": 53.0, "val_loss": 17.265067994594574, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.70612359046936, "training_acc": 53.0, "val_loss": 17.22360998392105, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.91152167320251, "training_acc": 59.0, "val_loss": 17.192529141902924, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.87229943275452, "training_acc": 58.0, "val_loss": 17.235472798347473, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.91160941123962, "training_acc": 53.0, "val_loss": 17.32345223426819, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.90033745765686, "training_acc": 53.0, "val_loss": 17.22935140132904, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.38553929328918, "training_acc": 59.0, "val_loss": 17.262493073940277, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.41527915000916, "training_acc": 61.0, "val_loss": 17.33018010854721, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.2502191066742, "training_acc": 53.0, "val_loss": 17.248602211475372, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.08989453315735, "training_acc": 52.0, "val_loss": 17.171528935432434, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.62274122238159, "training_acc": 60.0, "val_loss": 17.585022747516632, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16813135147095, "training_acc": 53.0, "val_loss": 17.352035641670227, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.7538115978241, "training_acc": 53.0, "val_loss": 17.14913845062256, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.00183296203613, "training_acc": 69.0, "val_loss": 17.17851608991623, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.64521765708923, "training_acc": 50.0, "val_loss": 17.181822657585144, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.36208009719849, "training_acc": 54.0, "val_loss": 17.135940492153168, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.2859992980957, "training_acc": 58.0, "val_loss": 17.106586694717407, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.82720613479614, "training_acc": 59.0, "val_loss": 17.130237817764282, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.98714804649353, "training_acc": 56.0, "val_loss": 17.001110315322876, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65.75091409683228, "training_acc": 70.0, "val_loss": 17.05452650785446, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.40592694282532, "training_acc": 56.0, "val_loss": 16.937153041362762, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.55776023864746, "training_acc": 59.0, "val_loss": 16.765117645263672, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.01879668235779, "training_acc": 63.0, "val_loss": 16.839618980884552, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.02381944656372, "training_acc": 63.0, "val_loss": 16.911233961582184, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.7203528881073, "training_acc": 66.0, "val_loss": 16.77819788455963, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.19112634658813, "training_acc": 57.0, "val_loss": 16.57785028219223, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.73414349555969, "training_acc": 71.0, "val_loss": 16.47995412349701, "val_acc": 52.0}
{"epoch": 33, "training_loss": 61.59181618690491, "training_acc": 70.0, "val_loss": 16.036197543144226, "val_acc": 52.0}
{"epoch": 34, "training_loss": 58.74677395820618, "training_acc": 70.0, "val_loss": 16.611891984939575, "val_acc": 52.0}
{"epoch": 35, "training_loss": 59.050198554992676, "training_acc": 66.0, "val_loss": 17.15584695339203, "val_acc": 52.0}
{"epoch": 36, "training_loss": 58.16623497009277, "training_acc": 65.0, "val_loss": 15.624959766864777, "val_acc": 56.0}
{"epoch": 37, "training_loss": 55.265252113342285, "training_acc": 74.0, "val_loss": 24.965274333953857, "val_acc": 52.0}
{"epoch": 38, "training_loss": 74.48927783966064, "training_acc": 62.0, "val_loss": 17.566503584384918, "val_acc": 60.0}
{"epoch": 39, "training_loss": 59.15311026573181, "training_acc": 67.0, "val_loss": 16.618572175502777, "val_acc": 52.0}
{"epoch": 40, "training_loss": 58.531540632247925, "training_acc": 66.0, "val_loss": 15.489397943019867, "val_acc": 56.0}
{"epoch": 41, "training_loss": 53.94821012020111, "training_acc": 76.0, "val_loss": 14.772030711174011, "val_acc": 76.0}
{"epoch": 42, "training_loss": 53.062875866889954, "training_acc": 76.0, "val_loss": 17.477494478225708, "val_acc": 52.0}
{"epoch": 43, "training_loss": 49.478792667388916, "training_acc": 71.0, "val_loss": 21.339771151542664, "val_acc": 48.0}
{"epoch": 44, "training_loss": 59.65550351142883, "training_acc": 64.0, "val_loss": 15.289199352264404, "val_acc": 56.0}
{"epoch": 45, "training_loss": 51.69208478927612, "training_acc": 72.0, "val_loss": 15.45591652393341, "val_acc": 60.0}
{"epoch": 46, "training_loss": 46.078027844429016, "training_acc": 78.0, "val_loss": 14.20648992061615, "val_acc": 76.0}
{"epoch": 47, "training_loss": 42.72366499900818, "training_acc": 83.0, "val_loss": 21.5265691280365, "val_acc": 48.0}
{"epoch": 48, "training_loss": 53.2359402179718, "training_acc": 65.0, "val_loss": 17.48478412628174, "val_acc": 52.0}
{"epoch": 49, "training_loss": 46.61579716205597, "training_acc": 75.0, "val_loss": 19.37195211648941, "val_acc": 56.0}
{"epoch": 50, "training_loss": 46.574448227882385, "training_acc": 73.0, "val_loss": 13.541296124458313, "val_acc": 76.0}
{"epoch": 51, "training_loss": 36.1918203830719, "training_acc": 87.0, "val_loss": 15.057085454463959, "val_acc": 72.0}
{"epoch": 52, "training_loss": 37.086562514305115, "training_acc": 84.0, "val_loss": 14.223520457744598, "val_acc": 76.0}
{"epoch": 53, "training_loss": 31.23039484024048, "training_acc": 93.0, "val_loss": 14.169764518737793, "val_acc": 76.0}
{"epoch": 54, "training_loss": 27.403656005859375, "training_acc": 94.0, "val_loss": 15.848244726657867, "val_acc": 72.0}
{"epoch": 55, "training_loss": 29.412843942642212, "training_acc": 88.0, "val_loss": 15.848495066165924, "val_acc": 72.0}
{"epoch": 56, "training_loss": 36.091877698898315, "training_acc": 82.0, "val_loss": 28.934475779533386, "val_acc": 56.0}
{"epoch": 57, "training_loss": 56.55602526664734, "training_acc": 71.0, "val_loss": 16.79486781358719, "val_acc": 68.0}
{"epoch": 58, "training_loss": 24.01488482952118, "training_acc": 91.0, "val_loss": 17.843416333198547, "val_acc": 64.0}
{"epoch": 59, "training_loss": 24.70253336429596, "training_acc": 92.0, "val_loss": 20.45685648918152, "val_acc": 64.0}
{"epoch": 60, "training_loss": 29.640748888254166, "training_acc": 87.0, "val_loss": 19.225743412971497, "val_acc": 64.0}
{"epoch": 61, "training_loss": 20.688176214694977, "training_acc": 89.0, "val_loss": 14.561741054058075, "val_acc": 76.0}
{"epoch": 62, "training_loss": 16.37055677175522, "training_acc": 96.0, "val_loss": 15.002825856208801, "val_acc": 72.0}
{"epoch": 63, "training_loss": 17.685014069080353, "training_acc": 96.0, "val_loss": 31.062886118888855, "val_acc": 56.0}
{"epoch": 64, "training_loss": 41.60938310623169, "training_acc": 77.0, "val_loss": 18.238894641399384, "val_acc": 64.0}
{"epoch": 65, "training_loss": 30.204197645187378, "training_acc": 86.0, "val_loss": 29.875558614730835, "val_acc": 56.0}
{"epoch": 66, "training_loss": 37.8924446105957, "training_acc": 81.0, "val_loss": 32.445475459098816, "val_acc": 56.0}
{"epoch": 67, "training_loss": 25.80571538209915, "training_acc": 92.0, "val_loss": 17.243672907352448, "val_acc": 68.0}
{"epoch": 68, "training_loss": 16.727516531944275, "training_acc": 94.0, "val_loss": 27.384960651397705, "val_acc": 60.0}
{"epoch": 69, "training_loss": 29.346018075942993, "training_acc": 88.0, "val_loss": 15.621186792850494, "val_acc": 76.0}
