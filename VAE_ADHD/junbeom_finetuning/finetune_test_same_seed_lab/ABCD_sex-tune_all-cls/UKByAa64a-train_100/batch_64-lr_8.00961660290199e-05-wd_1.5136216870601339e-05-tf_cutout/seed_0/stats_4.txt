"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.82453989982605, "training_acc": 47.0, "val_loss": 17.716333270072937, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.99454069137573, "training_acc": 47.0, "val_loss": 17.430274188518524, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.98983693122864, "training_acc": 47.0, "val_loss": 17.369937896728516, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.71554183959961, "training_acc": 42.0, "val_loss": 17.328377068042755, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27909278869629, "training_acc": 50.0, "val_loss": 17.302139103412628, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14949893951416, "training_acc": 53.0, "val_loss": 17.298704385757446, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15667819976807, "training_acc": 53.0, "val_loss": 17.347709834575653, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.20474910736084, "training_acc": 53.0, "val_loss": 17.3518106341362, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.09533309936523, "training_acc": 53.0, "val_loss": 17.316776514053345, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.0816433429718, "training_acc": 53.0, "val_loss": 17.31524169445038, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11707639694214, "training_acc": 53.0, "val_loss": 17.307990789413452, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.26871061325073, "training_acc": 53.0, "val_loss": 17.30937361717224, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.02464318275452, "training_acc": 53.0, "val_loss": 17.347390949726105, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24880146980286, "training_acc": 53.0, "val_loss": 17.36871302127838, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.49683117866516, "training_acc": 53.0, "val_loss": 17.32112467288971, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.28826642036438, "training_acc": 53.0, "val_loss": 17.321674525737762, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14046597480774, "training_acc": 53.0, "val_loss": 17.307130992412567, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12401533126831, "training_acc": 53.0, "val_loss": 17.307746410369873, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08862948417664, "training_acc": 53.0, "val_loss": 17.307651042938232, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.31039786338806, "training_acc": 54.0, "val_loss": 17.307567596435547, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.04094791412354, "training_acc": 53.0, "val_loss": 17.31417626142502, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.48247337341309, "training_acc": 53.0, "val_loss": 17.352084815502167, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2612817287445, "training_acc": 53.0, "val_loss": 17.32417196035385, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.03790187835693, "training_acc": 53.0, "val_loss": 17.32107102870941, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1016914844513, "training_acc": 53.0, "val_loss": 17.310893535614014, "val_acc": 52.0}
