"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68.99873638153076, "training_acc": 53.0, "val_loss": 17.33265221118927, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.07463192939758, "training_acc": 53.0, "val_loss": 17.318160831928253, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.27938413619995, "training_acc": 53.0, "val_loss": 17.307372391223907, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3956573009491, "training_acc": 53.0, "val_loss": 17.325599491596222, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15620636940002, "training_acc": 53.0, "val_loss": 17.31375902891159, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23418164253235, "training_acc": 53.0, "val_loss": 17.306677997112274, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.46602320671082, "training_acc": 45.0, "val_loss": 17.301322519779205, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.3546793460846, "training_acc": 53.0, "val_loss": 17.32882708311081, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22829079627991, "training_acc": 53.0, "val_loss": 17.319339513778687, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.08578848838806, "training_acc": 53.0, "val_loss": 17.30451136827469, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19366407394409, "training_acc": 53.0, "val_loss": 17.305302619934082, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12808203697205, "training_acc": 53.0, "val_loss": 17.310702800750732, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21727466583252, "training_acc": 53.0, "val_loss": 17.324355244636536, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11650562286377, "training_acc": 53.0, "val_loss": 17.36907958984375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.51914715766907, "training_acc": 53.0, "val_loss": 17.373113334178925, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.47789001464844, "training_acc": 53.0, "val_loss": 17.3201784491539, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13393330574036, "training_acc": 53.0, "val_loss": 17.312821745872498, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13324809074402, "training_acc": 53.0, "val_loss": 17.309123277664185, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18195343017578, "training_acc": 53.0, "val_loss": 17.307768762111664, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17224097251892, "training_acc": 53.0, "val_loss": 17.30732172727585, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15097761154175, "training_acc": 53.0, "val_loss": 17.30571538209915, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.183349609375, "training_acc": 53.0, "val_loss": 17.31056123971939, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13689827919006, "training_acc": 53.0, "val_loss": 17.31559783220291, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12169528007507, "training_acc": 53.0, "val_loss": 17.326994240283966, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19350504875183, "training_acc": 53.0, "val_loss": 17.339876294136047, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19763684272766, "training_acc": 53.0, "val_loss": 17.328597605228424, "val_acc": 52.0}
