"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.44376707077026, "training_acc": 53.0, "val_loss": 17.364512383937836, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.31788039207458, "training_acc": 53.0, "val_loss": 17.32611209154129, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.10172724723816, "training_acc": 53.0, "val_loss": 17.300613224506378, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20053839683533, "training_acc": 53.0, "val_loss": 17.309413850307465, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.05782747268677, "training_acc": 53.0, "val_loss": 17.285823822021484, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06711053848267, "training_acc": 53.0, "val_loss": 17.306922376155853, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.93637776374817, "training_acc": 53.0, "val_loss": 17.310959100723267, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.92950582504272, "training_acc": 53.0, "val_loss": 17.287814617156982, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.87457966804504, "training_acc": 53.0, "val_loss": 17.27983057498932, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.8561224937439, "training_acc": 53.0, "val_loss": 17.29017049074173, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.75516533851624, "training_acc": 53.0, "val_loss": 17.312560975551605, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.74905252456665, "training_acc": 53.0, "val_loss": 17.33136922121048, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.7490336894989, "training_acc": 53.0, "val_loss": 17.30419099330902, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.51216864585876, "training_acc": 53.0, "val_loss": 17.324648797512054, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.44541907310486, "training_acc": 53.0, "val_loss": 17.340601980686188, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.36734390258789, "training_acc": 53.0, "val_loss": 17.334645986557007, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.26532101631165, "training_acc": 53.0, "val_loss": 17.318548262119293, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.22909808158875, "training_acc": 53.0, "val_loss": 17.34439879655838, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.20273852348328, "training_acc": 53.0, "val_loss": 17.345334589481354, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.93977284431458, "training_acc": 53.0, "val_loss": 17.339465022087097, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.6523048877716, "training_acc": 53.0, "val_loss": 17.371082305908203, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.65525007247925, "training_acc": 53.0, "val_loss": 17.417778074741364, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.66760993003845, "training_acc": 53.0, "val_loss": 17.410938441753387, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.27579545974731, "training_acc": 54.0, "val_loss": 17.483018338680267, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.0991358757019, "training_acc": 55.0, "val_loss": 17.4306258559227, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.26670670509338, "training_acc": 60.0, "val_loss": 17.532679438591003, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.70060014724731, "training_acc": 60.0, "val_loss": 17.516745626926422, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.12762188911438, "training_acc": 58.0, "val_loss": 17.640189826488495, "val_acc": 52.0}
