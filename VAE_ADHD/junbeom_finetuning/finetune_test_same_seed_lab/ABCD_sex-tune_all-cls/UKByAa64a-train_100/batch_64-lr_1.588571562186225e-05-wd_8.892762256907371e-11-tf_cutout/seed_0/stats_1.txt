"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.16869044303894, "training_acc": 53.0, "val_loss": 17.34107881784439, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30952286720276, "training_acc": 53.0, "val_loss": 17.321810126304626, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.01509976387024, "training_acc": 53.0, "val_loss": 17.341773211956024, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09098267555237, "training_acc": 53.0, "val_loss": 17.33434796333313, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.12123799324036, "training_acc": 53.0, "val_loss": 17.338387668132782, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08761405944824, "training_acc": 53.0, "val_loss": 17.338649928569794, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11126327514648, "training_acc": 53.0, "val_loss": 17.331358790397644, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.01221084594727, "training_acc": 53.0, "val_loss": 17.324407398700714, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.94304919242859, "training_acc": 53.0, "val_loss": 17.330102622509003, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.88954901695251, "training_acc": 53.0, "val_loss": 17.29949414730072, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.83746838569641, "training_acc": 53.0, "val_loss": 17.31535941362381, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.82691287994385, "training_acc": 53.0, "val_loss": 17.37406551837921, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.70992684364319, "training_acc": 53.0, "val_loss": 17.430701851844788, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.80615663528442, "training_acc": 53.0, "val_loss": 17.428994178771973, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.68577885627747, "training_acc": 53.0, "val_loss": 17.41427630186081, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.80978846549988, "training_acc": 53.0, "val_loss": 17.355060577392578, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.66812062263489, "training_acc": 53.0, "val_loss": 17.35897809267044, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.6494677066803, "training_acc": 53.0, "val_loss": 17.38486886024475, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.82179880142212, "training_acc": 53.0, "val_loss": 17.385689914226532, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.55319023132324, "training_acc": 53.0, "val_loss": 17.36786812543869, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.30706477165222, "training_acc": 54.0, "val_loss": 17.3541858792305, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.31058502197266, "training_acc": 53.0, "val_loss": 17.34778583049774, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.52081251144409, "training_acc": 53.0, "val_loss": 17.336267232894897, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.07241415977478, "training_acc": 53.0, "val_loss": 17.333984375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.42991352081299, "training_acc": 53.0, "val_loss": 17.360858619213104, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.1269862651825, "training_acc": 53.0, "val_loss": 17.341037094593048, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.07559251785278, "training_acc": 53.0, "val_loss": 17.36031323671341, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.25434899330139, "training_acc": 58.0, "val_loss": 17.376044392585754, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.51212739944458, "training_acc": 69.0, "val_loss": 17.382293939590454, "val_acc": 52.0}
