"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.39287519454956, "training_acc": 52.0, "val_loss": 17.274416983127594, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.20988059043884, "training_acc": 52.0, "val_loss": 17.277881503105164, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.19402408599854, "training_acc": 52.0, "val_loss": 17.2776997089386, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.17848300933838, "training_acc": 52.0, "val_loss": 17.274226248264313, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.33405995368958, "training_acc": 52.0, "val_loss": 17.27006733417511, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.25329637527466, "training_acc": 52.0, "val_loss": 17.271995544433594, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.14997434616089, "training_acc": 52.0, "val_loss": 17.275676131248474, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.30036044120789, "training_acc": 52.0, "val_loss": 17.275430262088776, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.18513417243958, "training_acc": 52.0, "val_loss": 17.27551817893982, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.19482111930847, "training_acc": 52.0, "val_loss": 17.27072447538376, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.12108588218689, "training_acc": 52.0, "val_loss": 17.26684868335724, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.1238706111908, "training_acc": 52.0, "val_loss": 17.266464233398438, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.98659610748291, "training_acc": 52.0, "val_loss": 17.265619337558746, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.07496738433838, "training_acc": 52.0, "val_loss": 17.265206575393677, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.123530626297, "training_acc": 52.0, "val_loss": 17.26476699113846, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.13449025154114, "training_acc": 52.0, "val_loss": 17.263762652873993, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.10563969612122, "training_acc": 52.0, "val_loss": 17.262062430381775, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.02833008766174, "training_acc": 52.0, "val_loss": 17.260681092739105, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.99090433120728, "training_acc": 52.0, "val_loss": 17.257961630821228, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.0332305431366, "training_acc": 52.0, "val_loss": 17.25281924009323, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.98668313026428, "training_acc": 52.0, "val_loss": 17.24783033132553, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.95571160316467, "training_acc": 52.0, "val_loss": 17.243754863739014, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.06021857261658, "training_acc": 52.0, "val_loss": 17.239440977573395, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.10354685783386, "training_acc": 52.0, "val_loss": 17.236854135990143, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.06186819076538, "training_acc": 52.0, "val_loss": 17.236648499965668, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.02598261833191, "training_acc": 52.0, "val_loss": 17.239701747894287, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.79621052742004, "training_acc": 52.0, "val_loss": 17.240847647190094, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.04720306396484, "training_acc": 52.0, "val_loss": 17.241404950618744, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.02147674560547, "training_acc": 52.0, "val_loss": 17.24267601966858, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.90785193443298, "training_acc": 52.0, "val_loss": 17.246013879776, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.92218589782715, "training_acc": 52.0, "val_loss": 17.249232530593872, "val_acc": 56.0}
{"epoch": 31, "training_loss": 68.87720465660095, "training_acc": 52.0, "val_loss": 17.254917323589325, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.94648098945618, "training_acc": 52.0, "val_loss": 17.256365716457367, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.73600602149963, "training_acc": 52.0, "val_loss": 17.252467572689056, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.98926091194153, "training_acc": 52.0, "val_loss": 17.251412570476532, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.877854347229, "training_acc": 52.0, "val_loss": 17.252719402313232, "val_acc": 56.0}
{"epoch": 36, "training_loss": 68.76983761787415, "training_acc": 52.0, "val_loss": 17.254219949245453, "val_acc": 56.0}
{"epoch": 37, "training_loss": 68.77429270744324, "training_acc": 52.0, "val_loss": 17.25633591413498, "val_acc": 56.0}
{"epoch": 38, "training_loss": 68.84299325942993, "training_acc": 52.0, "val_loss": 17.25574880838394, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.96722793579102, "training_acc": 52.0, "val_loss": 17.25504696369171, "val_acc": 56.0}
{"epoch": 40, "training_loss": 68.8761899471283, "training_acc": 52.0, "val_loss": 17.254000902175903, "val_acc": 56.0}
{"epoch": 41, "training_loss": 68.87664413452148, "training_acc": 52.0, "val_loss": 17.256301641464233, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.77664184570312, "training_acc": 52.0, "val_loss": 17.25601851940155, "val_acc": 56.0}
{"epoch": 43, "training_loss": 68.77233815193176, "training_acc": 52.0, "val_loss": 17.255397140979767, "val_acc": 56.0}
