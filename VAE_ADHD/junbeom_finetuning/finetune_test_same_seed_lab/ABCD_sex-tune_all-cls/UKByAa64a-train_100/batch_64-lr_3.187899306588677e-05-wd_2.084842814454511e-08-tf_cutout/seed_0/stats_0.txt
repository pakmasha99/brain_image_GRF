"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.267422914505, "training_acc": 52.0, "val_loss": 17.303623259067535, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.1617841720581, "training_acc": 52.0, "val_loss": 17.310413718223572, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.0572612285614, "training_acc": 52.0, "val_loss": 17.27970689535141, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.1082866191864, "training_acc": 52.0, "val_loss": 17.315736413002014, "val_acc": 56.0}
{"epoch": 4, "training_loss": 68.92285966873169, "training_acc": 53.0, "val_loss": 17.31961816549301, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.08475971221924, "training_acc": 53.0, "val_loss": 17.30816960334778, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.02155327796936, "training_acc": 52.0, "val_loss": 17.28396564722061, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.01291728019714, "training_acc": 52.0, "val_loss": 17.228448390960693, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.18757009506226, "training_acc": 52.0, "val_loss": 17.227859795093536, "val_acc": 56.0}
{"epoch": 9, "training_loss": 68.95760416984558, "training_acc": 52.0, "val_loss": 17.25050061941147, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.00321936607361, "training_acc": 53.0, "val_loss": 17.245611548423767, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.89310765266418, "training_acc": 52.0, "val_loss": 17.204754054546356, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.82768654823303, "training_acc": 52.0, "val_loss": 17.284633219242096, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.58083844184875, "training_acc": 55.0, "val_loss": 17.375102639198303, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.66834235191345, "training_acc": 57.0, "val_loss": 17.29079931974411, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.30897402763367, "training_acc": 55.0, "val_loss": 17.26926416158676, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.09675574302673, "training_acc": 55.0, "val_loss": 17.324458062648773, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.6681137084961, "training_acc": 56.0, "val_loss": 17.45496094226837, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.27692890167236, "training_acc": 64.0, "val_loss": 17.25263148546219, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.42269086837769, "training_acc": 51.0, "val_loss": 17.265117168426514, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.66167092323303, "training_acc": 55.0, "val_loss": 17.399218678474426, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.97013735771179, "training_acc": 61.0, "val_loss": 17.356272041797638, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.51167488098145, "training_acc": 56.0, "val_loss": 17.272457480430603, "val_acc": 56.0}
{"epoch": 23, "training_loss": 67.47124433517456, "training_acc": 57.0, "val_loss": 17.455504834651947, "val_acc": 56.0}
{"epoch": 24, "training_loss": 67.74216556549072, "training_acc": 66.0, "val_loss": 17.52980202436447, "val_acc": 56.0}
{"epoch": 25, "training_loss": 67.3514187335968, "training_acc": 58.0, "val_loss": 17.2200545668602, "val_acc": 56.0}
{"epoch": 26, "training_loss": 66.73673391342163, "training_acc": 61.0, "val_loss": 17.22167134284973, "val_acc": 56.0}
{"epoch": 27, "training_loss": 67.20774555206299, "training_acc": 62.0, "val_loss": 17.642036080360413, "val_acc": 56.0}
{"epoch": 28, "training_loss": 67.32566523551941, "training_acc": 58.0, "val_loss": 17.27929264307022, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.0570068359375, "training_acc": 53.0, "val_loss": 17.222072184085846, "val_acc": 56.0}
{"epoch": 30, "training_loss": 67.62393236160278, "training_acc": 59.0, "val_loss": 17.387022078037262, "val_acc": 56.0}
