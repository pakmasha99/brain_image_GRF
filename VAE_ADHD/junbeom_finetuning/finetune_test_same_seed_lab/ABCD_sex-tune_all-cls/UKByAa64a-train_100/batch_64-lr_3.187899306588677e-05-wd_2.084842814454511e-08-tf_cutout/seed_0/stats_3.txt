"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.46458959579468, "training_acc": 45.0, "val_loss": 17.307139933109283, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.25500226020813, "training_acc": 50.0, "val_loss": 17.30174571275711, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.264075756073, "training_acc": 50.0, "val_loss": 17.32262372970581, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22735333442688, "training_acc": 53.0, "val_loss": 17.30809360742569, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38700580596924, "training_acc": 53.0, "val_loss": 17.2946959733963, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16753768920898, "training_acc": 53.0, "val_loss": 17.284978926181793, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.96622776985168, "training_acc": 53.0, "val_loss": 17.304809391498566, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.90027666091919, "training_acc": 53.0, "val_loss": 17.34796166419983, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.79141306877136, "training_acc": 53.0, "val_loss": 17.346274852752686, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.89071583747864, "training_acc": 53.0, "val_loss": 17.320261895656586, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.5569806098938, "training_acc": 53.0, "val_loss": 17.345030605793, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.85242319107056, "training_acc": 53.0, "val_loss": 17.340858280658722, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.32478523254395, "training_acc": 54.0, "val_loss": 17.314869165420532, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.23029899597168, "training_acc": 57.0, "val_loss": 17.32088029384613, "val_acc": 52.0}
{"epoch": 14, "training_loss": 67.83383274078369, "training_acc": 58.0, "val_loss": 17.39148050546646, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.36022114753723, "training_acc": 50.0, "val_loss": 17.39294081926346, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.44965839385986, "training_acc": 57.0, "val_loss": 17.28893220424652, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.10478329658508, "training_acc": 70.0, "val_loss": 17.312274873256683, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.20602917671204, "training_acc": 66.0, "val_loss": 17.513935267925262, "val_acc": 52.0}
{"epoch": 19, "training_loss": 66.99920320510864, "training_acc": 62.0, "val_loss": 17.346172034740448, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.89853954315186, "training_acc": 58.0, "val_loss": 17.30257123708725, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.56252217292786, "training_acc": 51.0, "val_loss": 17.39676594734192, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.16675305366516, "training_acc": 53.0, "val_loss": 17.544981837272644, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.66689229011536, "training_acc": 53.0, "val_loss": 17.44772344827652, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.13702702522278, "training_acc": 55.0, "val_loss": 17.383620142936707, "val_acc": 52.0}
