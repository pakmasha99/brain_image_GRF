"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.13585329055786, "training_acc": 53.0, "val_loss": 17.362266778945923, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.29694771766663, "training_acc": 53.0, "val_loss": 17.347092926502228, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.24526834487915, "training_acc": 53.0, "val_loss": 17.326799035072327, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12601161003113, "training_acc": 53.0, "val_loss": 17.357762157917023, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.02227449417114, "training_acc": 53.0, "val_loss": 17.378848791122437, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.02651715278625, "training_acc": 53.0, "val_loss": 17.358452081680298, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.88848328590393, "training_acc": 53.0, "val_loss": 17.3514261841774, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.92183041572571, "training_acc": 53.0, "val_loss": 17.353259027004242, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.98324084281921, "training_acc": 53.0, "val_loss": 17.379318177700043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.90980505943298, "training_acc": 53.0, "val_loss": 17.39077717065811, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.88274335861206, "training_acc": 53.0, "val_loss": 17.399539053440094, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.88894939422607, "training_acc": 53.0, "val_loss": 17.39014834165573, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.55933880805969, "training_acc": 53.0, "val_loss": 17.400279641151428, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.60846447944641, "training_acc": 53.0, "val_loss": 17.43176579475403, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.86211729049683, "training_acc": 53.0, "val_loss": 17.417064309120178, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.66534352302551, "training_acc": 53.0, "val_loss": 17.36016571521759, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.77312207221985, "training_acc": 53.0, "val_loss": 17.310328781604767, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.62128043174744, "training_acc": 53.0, "val_loss": 17.297181487083435, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.59549069404602, "training_acc": 53.0, "val_loss": 17.309272289276123, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.21516346931458, "training_acc": 53.0, "val_loss": 17.372532188892365, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.30174994468689, "training_acc": 53.0, "val_loss": 17.416200041770935, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.35820174217224, "training_acc": 53.0, "val_loss": 17.42495894432068, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.05224919319153, "training_acc": 53.0, "val_loss": 17.353571951389313, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.1406581401825, "training_acc": 55.0, "val_loss": 17.326556146144867, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.27692747116089, "training_acc": 57.0, "val_loss": 17.3809751868248, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.12688779830933, "training_acc": 53.0, "val_loss": 17.47196316719055, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.97813081741333, "training_acc": 53.0, "val_loss": 17.428261041641235, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.14800596237183, "training_acc": 53.0, "val_loss": 17.306503653526306, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.84407448768616, "training_acc": 55.0, "val_loss": 17.313483357429504, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.44271230697632, "training_acc": 58.0, "val_loss": 17.479392886161804, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.22607827186584, "training_acc": 54.0, "val_loss": 17.613525688648224, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.51049208641052, "training_acc": 54.0, "val_loss": 17.528036236763, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.03988265991211, "training_acc": 55.0, "val_loss": 17.412494122982025, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.0376524925232, "training_acc": 60.0, "val_loss": 17.606082558631897, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.22391295433044, "training_acc": 53.0, "val_loss": 17.66778528690338, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.85053539276123, "training_acc": 55.0, "val_loss": 17.62397289276123, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.38664555549622, "training_acc": 58.0, "val_loss": 17.44040995836258, "val_acc": 52.0}
