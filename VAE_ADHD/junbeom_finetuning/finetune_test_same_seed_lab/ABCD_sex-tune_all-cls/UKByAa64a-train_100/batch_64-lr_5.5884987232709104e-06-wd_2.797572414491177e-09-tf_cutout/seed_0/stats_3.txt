"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.4791808128357, "training_acc": 41.0, "val_loss": 17.346160113811493, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.23183822631836, "training_acc": 50.0, "val_loss": 17.339560389518738, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.30114102363586, "training_acc": 47.0, "val_loss": 17.36726015806198, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21090149879456, "training_acc": 54.0, "val_loss": 17.368631064891815, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.02630877494812, "training_acc": 54.0, "val_loss": 17.366822063922882, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.92267727851868, "training_acc": 53.0, "val_loss": 17.309872806072235, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.79607081413269, "training_acc": 55.0, "val_loss": 17.273208498954773, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.89369320869446, "training_acc": 54.0, "val_loss": 17.29753613471985, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.73464131355286, "training_acc": 53.0, "val_loss": 17.352977395057678, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.84091138839722, "training_acc": 56.0, "val_loss": 17.422623932361603, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.66459655761719, "training_acc": 51.0, "val_loss": 17.423079907894135, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.78686141967773, "training_acc": 54.0, "val_loss": 17.410899698734283, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.3025472164154, "training_acc": 58.0, "val_loss": 17.393331229686737, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.50613713264465, "training_acc": 55.0, "val_loss": 17.373551428318024, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.215904712677, "training_acc": 58.0, "val_loss": 17.395280301570892, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.49626898765564, "training_acc": 50.0, "val_loss": 17.417168617248535, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.14211583137512, "training_acc": 58.0, "val_loss": 17.42587983608246, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.51498746871948, "training_acc": 54.0, "val_loss": 17.427749931812286, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.2399365901947, "training_acc": 64.0, "val_loss": 17.417457699775696, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.06487965583801, "training_acc": 61.0, "val_loss": 17.41662174463272, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.64621591567993, "training_acc": 52.0, "val_loss": 17.41732358932495, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.04335474967957, "training_acc": 55.0, "val_loss": 17.445872724056244, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.42103242874146, "training_acc": 54.0, "val_loss": 17.44455248117447, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.57973837852478, "training_acc": 62.0, "val_loss": 17.398475110530853, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.98187232017517, "training_acc": 59.0, "val_loss": 17.450828850269318, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.74139595031738, "training_acc": 61.0, "val_loss": 17.488697171211243, "val_acc": 52.0}
