"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.15215730667114, "training_acc": 53.0, "val_loss": 17.3980250954628, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13743281364441, "training_acc": 53.0, "val_loss": 17.351503670215607, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14354252815247, "training_acc": 53.0, "val_loss": 17.32233464717865, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05036616325378, "training_acc": 53.0, "val_loss": 17.291851341724396, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.007009267807, "training_acc": 53.0, "val_loss": 17.30726957321167, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.93939065933228, "training_acc": 53.0, "val_loss": 17.29714125394821, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09283638000488, "training_acc": 53.0, "val_loss": 17.296619713306427, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.90314793586731, "training_acc": 53.0, "val_loss": 17.284317314624786, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.91508412361145, "training_acc": 53.0, "val_loss": 17.285023629665375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.71155858039856, "training_acc": 53.0, "val_loss": 17.278075218200684, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.89400029182434, "training_acc": 53.0, "val_loss": 17.26435124874115, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.67007040977478, "training_acc": 53.0, "val_loss": 17.24672019481659, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.78298687934875, "training_acc": 54.0, "val_loss": 17.285287380218506, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.61609244346619, "training_acc": 53.0, "val_loss": 17.240600287914276, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.68192291259766, "training_acc": 53.0, "val_loss": 17.244313657283783, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.28551864624023, "training_acc": 53.0, "val_loss": 17.229869961738586, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.0605194568634, "training_acc": 55.0, "val_loss": 17.248637974262238, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.35704064369202, "training_acc": 58.0, "val_loss": 17.27115958929062, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.0740134716034, "training_acc": 53.0, "val_loss": 17.271429300308228, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.5520830154419, "training_acc": 56.0, "val_loss": 17.198365926742554, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.62815928459167, "training_acc": 60.0, "val_loss": 17.189471423625946, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.65476608276367, "training_acc": 67.0, "val_loss": 17.13540554046631, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.85346579551697, "training_acc": 68.0, "val_loss": 17.405420541763306, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19794201850891, "training_acc": 50.0, "val_loss": 17.323501408100128, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23977017402649, "training_acc": 53.0, "val_loss": 17.287427186965942, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.95122194290161, "training_acc": 53.0, "val_loss": 17.301978170871735, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.92829918861389, "training_acc": 53.0, "val_loss": 17.295417189598083, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.75900888442993, "training_acc": 53.0, "val_loss": 17.306998372077942, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.69026684761047, "training_acc": 53.0, "val_loss": 17.29557067155838, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.35490822792053, "training_acc": 53.0, "val_loss": 17.326003313064575, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.3358564376831, "training_acc": 53.0, "val_loss": 17.241452634334564, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.80591797828674, "training_acc": 55.0, "val_loss": 17.245252430438995, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.67363405227661, "training_acc": 53.0, "val_loss": 17.34573394060135, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.07889986038208, "training_acc": 53.0, "val_loss": 17.455662786960602, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.78629851341248, "training_acc": 53.0, "val_loss": 17.289020121097565, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.82822346687317, "training_acc": 57.0, "val_loss": 17.30997860431671, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.47294282913208, "training_acc": 62.0, "val_loss": 17.284075915813446, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.09811329841614, "training_acc": 53.0, "val_loss": 17.202898859977722, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.61655449867249, "training_acc": 56.0, "val_loss": 17.16180443763733, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.09650158882141, "training_acc": 57.0, "val_loss": 17.085640132427216, "val_acc": 52.0}
{"epoch": 40, "training_loss": 65.76482462882996, "training_acc": 69.0, "val_loss": 17.155006527900696, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.44213032722473, "training_acc": 71.0, "val_loss": 17.737777531147003, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.13553953170776, "training_acc": 53.0, "val_loss": 17.41556078195572, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.2188708782196, "training_acc": 53.0, "val_loss": 17.340761423110962, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.8495864868164, "training_acc": 53.0, "val_loss": 17.306247353553772, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12742185592651, "training_acc": 53.0, "val_loss": 17.310456931591034, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.83313775062561, "training_acc": 53.0, "val_loss": 17.327216267585754, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.51163411140442, "training_acc": 53.0, "val_loss": 17.290891706943512, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.05376553535461, "training_acc": 53.0, "val_loss": 17.275777459144592, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.11417555809021, "training_acc": 69.0, "val_loss": 17.442233860492706, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.98550796508789, "training_acc": 53.0, "val_loss": 17.45002567768097, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.31000995635986, "training_acc": 53.0, "val_loss": 17.268629372119904, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.01847887039185, "training_acc": 61.0, "val_loss": 17.22039431333542, "val_acc": 52.0}
{"epoch": 53, "training_loss": 67.5352201461792, "training_acc": 70.0, "val_loss": 17.270398139953613, "val_acc": 52.0}
{"epoch": 54, "training_loss": 67.15389585494995, "training_acc": 61.0, "val_loss": 17.227478325366974, "val_acc": 52.0}
{"epoch": 55, "training_loss": 66.29719614982605, "training_acc": 74.0, "val_loss": 17.38879382610321, "val_acc": 52.0}
{"epoch": 56, "training_loss": 67.28958892822266, "training_acc": 53.0, "val_loss": 17.273254692554474, "val_acc": 52.0}
{"epoch": 57, "training_loss": 65.92209935188293, "training_acc": 70.0, "val_loss": 17.37729012966156, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.25677156448364, "training_acc": 53.0, "val_loss": 17.268916964530945, "val_acc": 52.0}
