"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31362247467041, "training_acc": 53.0, "val_loss": 17.395220696926117, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.24793243408203, "training_acc": 53.0, "val_loss": 17.36210584640503, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.30999779701233, "training_acc": 53.0, "val_loss": 17.35013872385025, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.06644368171692, "training_acc": 53.0, "val_loss": 17.29385107755661, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22517991065979, "training_acc": 53.0, "val_loss": 17.315921187400818, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22250080108643, "training_acc": 53.0, "val_loss": 17.351336777210236, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.10916209220886, "training_acc": 53.0, "val_loss": 17.32788383960724, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.99800539016724, "training_acc": 53.0, "val_loss": 17.32388138771057, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02511501312256, "training_acc": 53.0, "val_loss": 17.312875390052795, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.95578861236572, "training_acc": 53.0, "val_loss": 17.319366335868835, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.7622001171112, "training_acc": 53.0, "val_loss": 17.35389083623886, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.81120753288269, "training_acc": 53.0, "val_loss": 17.367495596408844, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.67357587814331, "training_acc": 53.0, "val_loss": 17.343969643115997, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.79733681678772, "training_acc": 53.0, "val_loss": 17.32688844203949, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.68003582954407, "training_acc": 53.0, "val_loss": 17.306312918663025, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.62533688545227, "training_acc": 53.0, "val_loss": 17.347106337547302, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.2569363117218, "training_acc": 53.0, "val_loss": 17.39203780889511, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.27259564399719, "training_acc": 53.0, "val_loss": 17.421916127204895, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.47125458717346, "training_acc": 53.0, "val_loss": 17.30404943227768, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.59849572181702, "training_acc": 54.0, "val_loss": 17.271146178245544, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.45226907730103, "training_acc": 54.0, "val_loss": 17.257502675056458, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.50283932685852, "training_acc": 53.0, "val_loss": 17.352019250392914, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.07428789138794, "training_acc": 53.0, "val_loss": 17.34233647584915, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.29973578453064, "training_acc": 53.0, "val_loss": 17.321833968162537, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.69476819038391, "training_acc": 53.0, "val_loss": 17.381328344345093, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.55556201934814, "training_acc": 54.0, "val_loss": 17.378494143486023, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.46106290817261, "training_acc": 54.0, "val_loss": 17.417462170124054, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.46229553222656, "training_acc": 53.0, "val_loss": 17.421752214431763, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.20379209518433, "training_acc": 58.0, "val_loss": 17.38421469926834, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.92138981819153, "training_acc": 68.0, "val_loss": 17.535176873207092, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.07414984703064, "training_acc": 55.0, "val_loss": 17.430485785007477, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.02334523200989, "training_acc": 72.0, "val_loss": 17.42904931306839, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.11631321907043, "training_acc": 74.0, "val_loss": 17.638806998729706, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.49889206886292, "training_acc": 59.0, "val_loss": 17.378339171409607, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.26683139801025, "training_acc": 71.0, "val_loss": 17.781570553779602, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.9165849685669, "training_acc": 56.0, "val_loss": 17.594502866268158, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.39516282081604, "training_acc": 62.0, "val_loss": 17.377887666225433, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.83100438117981, "training_acc": 55.0, "val_loss": 17.35173761844635, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.92234134674072, "training_acc": 60.0, "val_loss": 17.534171044826508, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.34856462478638, "training_acc": 53.0, "val_loss": 17.443473637104034, "val_acc": 52.0}
