"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.57233238220215, "training_acc": 43.0, "val_loss": 17.231234908103943, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.36710667610168, "training_acc": 49.0, "val_loss": 17.237094044685364, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.00068306922913, "training_acc": 53.0, "val_loss": 17.316798865795135, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.75593948364258, "training_acc": 53.0, "val_loss": 17.254549264907837, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.35534358024597, "training_acc": 53.0, "val_loss": 17.2105610370636, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.91395163536072, "training_acc": 53.0, "val_loss": 17.27346032857895, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.9710807800293, "training_acc": 54.0, "val_loss": 17.290958762168884, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14336466789246, "training_acc": 53.0, "val_loss": 17.291998863220215, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2412645816803, "training_acc": 52.0, "val_loss": 17.27767139673233, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.55310010910034, "training_acc": 56.0, "val_loss": 17.2741636633873, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24829077720642, "training_acc": 46.0, "val_loss": 17.245936393737793, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.29824829101562, "training_acc": 59.0, "val_loss": 17.23475605249405, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.69903993606567, "training_acc": 50.0, "val_loss": 17.236022651195526, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.40039539337158, "training_acc": 55.0, "val_loss": 17.262624204158783, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.43337631225586, "training_acc": 55.0, "val_loss": 17.253760993480682, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.4645049571991, "training_acc": 56.0, "val_loss": 17.24773347377777, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.79481172561646, "training_acc": 59.0, "val_loss": 17.52076894044876, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.14383816719055, "training_acc": 53.0, "val_loss": 17.46598780155182, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.46946454048157, "training_acc": 54.0, "val_loss": 17.256304621696472, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.02326512336731, "training_acc": 61.0, "val_loss": 17.27215349674225, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.27797675132751, "training_acc": 66.0, "val_loss": 17.318497598171234, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.74068355560303, "training_acc": 50.0, "val_loss": 17.298568785190582, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.7006254196167, "training_acc": 59.0, "val_loss": 17.255711555480957, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.3182110786438, "training_acc": 64.0, "val_loss": 17.27011799812317, "val_acc": 52.0}
