"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.88929271697998, "training_acc": 47.0, "val_loss": 17.747722566127777, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.301687002182, "training_acc": 47.0, "val_loss": 17.595703899860382, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.41645836830139, "training_acc": 47.0, "val_loss": 17.406731843948364, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.76149249076843, "training_acc": 41.0, "val_loss": 17.315322160720825, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20675230026245, "training_acc": 53.0, "val_loss": 17.288486659526825, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0610122680664, "training_acc": 53.0, "val_loss": 17.320045828819275, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15832209587097, "training_acc": 53.0, "val_loss": 17.32749193906784, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15289258956909, "training_acc": 53.0, "val_loss": 17.34199821949005, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.06578350067139, "training_acc": 53.0, "val_loss": 17.30806529521942, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.94542098045349, "training_acc": 53.0, "val_loss": 17.309074103832245, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.05019688606262, "training_acc": 53.0, "val_loss": 17.301928997039795, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13502216339111, "training_acc": 53.0, "val_loss": 17.311835289001465, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.8829574584961, "training_acc": 53.0, "val_loss": 17.384791374206543, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14736080169678, "training_acc": 53.0, "val_loss": 17.394202947616577, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.51352977752686, "training_acc": 53.0, "val_loss": 17.325134575366974, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1960232257843, "training_acc": 53.0, "val_loss": 17.330965399742126, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.05353236198425, "training_acc": 53.0, "val_loss": 17.31567084789276, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16140747070312, "training_acc": 53.0, "val_loss": 17.31409579515457, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.97172498703003, "training_acc": 53.0, "val_loss": 17.31673777103424, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12144017219543, "training_acc": 55.0, "val_loss": 17.31218248605728, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.63630414009094, "training_acc": 53.0, "val_loss": 17.35374927520752, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.3732283115387, "training_acc": 53.0, "val_loss": 17.366644740104675, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25115060806274, "training_acc": 53.0, "val_loss": 17.3185795545578, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.73894190788269, "training_acc": 53.0, "val_loss": 17.321491241455078, "val_acc": 52.0}
