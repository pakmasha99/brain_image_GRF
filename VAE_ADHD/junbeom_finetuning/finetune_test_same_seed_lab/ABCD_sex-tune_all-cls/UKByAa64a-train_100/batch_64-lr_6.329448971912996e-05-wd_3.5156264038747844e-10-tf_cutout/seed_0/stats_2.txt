"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.21867823600769, "training_acc": 53.0, "val_loss": 17.304137349128723, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1169958114624, "training_acc": 53.0, "val_loss": 17.323383688926697, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.29314160346985, "training_acc": 53.0, "val_loss": 17.329198122024536, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.02732110023499, "training_acc": 53.0, "val_loss": 17.3318013548851, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.24122738838196, "training_acc": 53.0, "val_loss": 17.2970712184906, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14351439476013, "training_acc": 53.0, "val_loss": 17.321819067001343, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16831159591675, "training_acc": 53.0, "val_loss": 17.29646623134613, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2358865737915, "training_acc": 53.0, "val_loss": 17.31475591659546, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17306685447693, "training_acc": 53.0, "val_loss": 17.304809391498566, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14497828483582, "training_acc": 53.0, "val_loss": 17.312420904636383, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14962673187256, "training_acc": 53.0, "val_loss": 17.32209026813507, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.44740915298462, "training_acc": 53.0, "val_loss": 17.322665452957153, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.08903527259827, "training_acc": 53.0, "val_loss": 17.361876368522644, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.4482684135437, "training_acc": 53.0, "val_loss": 17.358222603797913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.47745108604431, "training_acc": 53.0, "val_loss": 17.312589287757874, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10987067222595, "training_acc": 53.0, "val_loss": 17.313583195209503, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14521098136902, "training_acc": 53.0, "val_loss": 17.313440144062042, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19522833824158, "training_acc": 53.0, "val_loss": 17.31344908475876, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16833901405334, "training_acc": 53.0, "val_loss": 17.30886548757553, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18310952186584, "training_acc": 53.0, "val_loss": 17.307202517986298, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15452265739441, "training_acc": 53.0, "val_loss": 17.311987280845642, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15918016433716, "training_acc": 53.0, "val_loss": 17.314906418323517, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12442827224731, "training_acc": 53.0, "val_loss": 17.32453852891922, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15680408477783, "training_acc": 53.0, "val_loss": 17.338459193706512, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20541143417358, "training_acc": 53.0, "val_loss": 17.32761710882187, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14824795722961, "training_acc": 53.0, "val_loss": 17.310260236263275, "val_acc": 52.0}
