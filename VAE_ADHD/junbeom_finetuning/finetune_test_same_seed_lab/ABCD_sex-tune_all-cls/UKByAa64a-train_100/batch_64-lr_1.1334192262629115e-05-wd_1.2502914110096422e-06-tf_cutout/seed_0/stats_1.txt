"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.07971286773682, "training_acc": 47.0, "val_loss": 17.467978596687317, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.7067801952362, "training_acc": 47.0, "val_loss": 17.356708645820618, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.65419435501099, "training_acc": 47.0, "val_loss": 17.387767136096954, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.52011632919312, "training_acc": 46.0, "val_loss": 17.268425226211548, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33339715003967, "training_acc": 50.0, "val_loss": 17.201051115989685, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33769679069519, "training_acc": 51.0, "val_loss": 17.228953540325165, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.08458018302917, "training_acc": 53.0, "val_loss": 17.21573919057846, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.70682621002197, "training_acc": 70.0, "val_loss": 17.25718080997467, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11045169830322, "training_acc": 53.0, "val_loss": 17.24647432565689, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.82844471931458, "training_acc": 56.0, "val_loss": 17.20407009124756, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.87107920646667, "training_acc": 56.0, "val_loss": 17.23499596118927, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.76639366149902, "training_acc": 54.0, "val_loss": 17.243777215480804, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.58173727989197, "training_acc": 53.0, "val_loss": 17.268308997154236, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.78263425827026, "training_acc": 53.0, "val_loss": 17.30499565601349, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.59762525558472, "training_acc": 54.0, "val_loss": 17.337684333324432, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.4596939086914, "training_acc": 54.0, "val_loss": 17.313152551651, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.58018732070923, "training_acc": 54.0, "val_loss": 17.27612614631653, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.29408693313599, "training_acc": 54.0, "val_loss": 17.229944467544556, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.18186092376709, "training_acc": 53.0, "val_loss": 17.22615957260132, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.94577074050903, "training_acc": 55.0, "val_loss": 17.273876070976257, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.5682225227356, "training_acc": 53.0, "val_loss": 17.332172393798828, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.06678986549377, "training_acc": 54.0, "val_loss": 17.36273467540741, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.83796620368958, "training_acc": 55.0, "val_loss": 17.330779135227203, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.84648036956787, "training_acc": 53.0, "val_loss": 17.249278724193573, "val_acc": 52.0}
