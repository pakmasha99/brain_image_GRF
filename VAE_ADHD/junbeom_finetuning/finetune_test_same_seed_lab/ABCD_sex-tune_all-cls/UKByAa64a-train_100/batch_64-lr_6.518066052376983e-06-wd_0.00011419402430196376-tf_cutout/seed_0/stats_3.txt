"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.052166223526, "training_acc": 53.0, "val_loss": 17.38404482603073, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21548008918762, "training_acc": 53.0, "val_loss": 17.351603507995605, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.03790807723999, "training_acc": 53.0, "val_loss": 17.334632575511932, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.97520542144775, "training_acc": 53.0, "val_loss": 17.362575232982635, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.60163497924805, "training_acc": 53.0, "val_loss": 17.359760403633118, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06840515136719, "training_acc": 53.0, "val_loss": 17.403729259967804, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.64032435417175, "training_acc": 53.0, "val_loss": 17.436963319778442, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.65982937812805, "training_acc": 53.0, "val_loss": 17.43270307779312, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.54533386230469, "training_acc": 53.0, "val_loss": 17.45230108499527, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.21061038970947, "training_acc": 53.0, "val_loss": 17.45695471763611, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.27556300163269, "training_acc": 53.0, "val_loss": 17.525768280029297, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.32768678665161, "training_acc": 53.0, "val_loss": 17.58943200111389, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.04427289962769, "training_acc": 53.0, "val_loss": 17.616768181324005, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.45311188697815, "training_acc": 53.0, "val_loss": 17.627669870853424, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.04805421829224, "training_acc": 55.0, "val_loss": 17.569835484027863, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.96730399131775, "training_acc": 55.0, "val_loss": 17.668743431568146, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.57359051704407, "training_acc": 54.0, "val_loss": 17.670340836048126, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.79111075401306, "training_acc": 61.0, "val_loss": 17.3282653093338, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.76334118843079, "training_acc": 60.0, "val_loss": 17.309600114822388, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.26328206062317, "training_acc": 55.0, "val_loss": 17.659838497638702, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.28801441192627, "training_acc": 54.0, "val_loss": 17.738071084022522, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.16475772857666, "training_acc": 56.0, "val_loss": 17.49803125858307, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.6809446811676, "training_acc": 66.0, "val_loss": 17.545995116233826, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.07134962081909, "training_acc": 68.0, "val_loss": 17.82340556383133, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.74293494224548, "training_acc": 62.0, "val_loss": 17.513494193553925, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.56943202018738, "training_acc": 76.0, "val_loss": 17.67110824584961, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.79848861694336, "training_acc": 64.0, "val_loss": 17.955024540424347, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.32853817939758, "training_acc": 67.0, "val_loss": 17.64097809791565, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.68183755874634, "training_acc": 67.0, "val_loss": 17.800436913967133, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.45764470100403, "training_acc": 61.0, "val_loss": 18.05947571992874, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.46671056747437, "training_acc": 67.0, "val_loss": 18.000051379203796, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.36274266242981, "training_acc": 70.0, "val_loss": 17.67910271883011, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.49663877487183, "training_acc": 78.0, "val_loss": 18.08830201625824, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.95104575157166, "training_acc": 67.0, "val_loss": 17.381030321121216, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.01771664619446, "training_acc": 65.0, "val_loss": 18.017852306365967, "val_acc": 52.0}
{"epoch": 35, "training_loss": 65.65779566764832, "training_acc": 71.0, "val_loss": 18.002067506313324, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.99188423156738, "training_acc": 69.0, "val_loss": 17.804263532161713, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.6838948726654, "training_acc": 71.0, "val_loss": 17.63450652360916, "val_acc": 52.0}
