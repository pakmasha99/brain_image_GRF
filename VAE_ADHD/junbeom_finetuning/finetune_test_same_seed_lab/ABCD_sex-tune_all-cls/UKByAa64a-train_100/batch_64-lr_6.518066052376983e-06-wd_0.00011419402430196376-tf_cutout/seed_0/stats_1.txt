"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.59905052185059, "training_acc": 47.0, "val_loss": 17.32204556465149, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.50061917304993, "training_acc": 47.0, "val_loss": 17.33688861131668, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.62277293205261, "training_acc": 47.0, "val_loss": 17.33960658311844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.4926450252533, "training_acc": 47.0, "val_loss": 17.33126789331436, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.37686228752136, "training_acc": 47.0, "val_loss": 17.344096302986145, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2628903388977, "training_acc": 53.0, "val_loss": 17.349903285503387, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.25184082984924, "training_acc": 54.0, "val_loss": 17.347484827041626, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18478107452393, "training_acc": 51.0, "val_loss": 17.326919734477997, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.02913284301758, "training_acc": 54.0, "val_loss": 17.290769517421722, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.02414989471436, "training_acc": 53.0, "val_loss": 17.28765219449997, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.89200901985168, "training_acc": 54.0, "val_loss": 17.299102246761322, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.8695957660675, "training_acc": 53.0, "val_loss": 17.30799227952957, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.8573899269104, "training_acc": 53.0, "val_loss": 17.325788736343384, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.63418102264404, "training_acc": 53.0, "val_loss": 17.34633594751358, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.7600028514862, "training_acc": 52.0, "val_loss": 17.354072630405426, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.80307102203369, "training_acc": 53.0, "val_loss": 17.360076308250427, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.75547170639038, "training_acc": 53.0, "val_loss": 17.364346981048584, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.56255340576172, "training_acc": 54.0, "val_loss": 17.39143133163452, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.72707605361938, "training_acc": 52.0, "val_loss": 17.394717037677765, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.61084294319153, "training_acc": 53.0, "val_loss": 17.385585606098175, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.79921054840088, "training_acc": 53.0, "val_loss": 17.374591529369354, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.78768110275269, "training_acc": 53.0, "val_loss": 17.385457456111908, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.623694896698, "training_acc": 53.0, "val_loss": 17.39262491464615, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.35328698158264, "training_acc": 53.0, "val_loss": 17.38649010658264, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.13556456565857, "training_acc": 53.0, "val_loss": 17.3712819814682, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.2163462638855, "training_acc": 53.0, "val_loss": 17.357002198696136, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.52040410041809, "training_acc": 54.0, "val_loss": 17.345084249973297, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.47474384307861, "training_acc": 54.0, "val_loss": 17.34183430671692, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.1806902885437, "training_acc": 59.0, "val_loss": 17.35721528530121, "val_acc": 52.0}
