"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.36521172523499, "training_acc": 53.0, "val_loss": 17.328563332557678, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.11758875846863, "training_acc": 53.0, "val_loss": 17.35456734895706, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.9632179737091, "training_acc": 53.0, "val_loss": 17.34488010406494, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17206883430481, "training_acc": 53.0, "val_loss": 17.357242107391357, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.6150963306427, "training_acc": 53.0, "val_loss": 17.329798638820648, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.66047596931458, "training_acc": 53.0, "val_loss": 17.308156192302704, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1446545124054, "training_acc": 53.0, "val_loss": 17.319028079509735, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14819812774658, "training_acc": 53.0, "val_loss": 17.318102717399597, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2528932094574, "training_acc": 53.0, "val_loss": 17.312513291835785, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19958066940308, "training_acc": 53.0, "val_loss": 17.309875786304474, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19011974334717, "training_acc": 53.0, "val_loss": 17.30773150920868, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.19757795333862, "training_acc": 53.0, "val_loss": 17.31933057308197, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18090915679932, "training_acc": 53.0, "val_loss": 17.31918156147003, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15132141113281, "training_acc": 53.0, "val_loss": 17.329443991184235, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20447134971619, "training_acc": 53.0, "val_loss": 17.341648042201996, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1976752281189, "training_acc": 53.0, "val_loss": 17.316310107707977, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12312054634094, "training_acc": 53.0, "val_loss": 17.30966866016388, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17717480659485, "training_acc": 53.0, "val_loss": 17.3112154006958, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20706486701965, "training_acc": 53.0, "val_loss": 17.30739027261734, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13893294334412, "training_acc": 53.0, "val_loss": 17.33129471540451, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.28739976882935, "training_acc": 53.0, "val_loss": 17.345918715000153, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.3360366821289, "training_acc": 53.0, "val_loss": 17.379237711429596, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.29191613197327, "training_acc": 53.0, "val_loss": 17.44377464056015, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.53283309936523, "training_acc": 53.0, "val_loss": 17.41403192281723, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.53546214103699, "training_acc": 53.0, "val_loss": 17.332622408866882, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13618350028992, "training_acc": 53.0, "val_loss": 17.313064634799957, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.28807783126831, "training_acc": 53.0, "val_loss": 17.308761179447174, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15962243080139, "training_acc": 53.0, "val_loss": 17.310023307800293, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1162109375, "training_acc": 53.0, "val_loss": 17.32332408428192, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14012885093689, "training_acc": 53.0, "val_loss": 17.340442538261414, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.2907292842865, "training_acc": 53.0, "val_loss": 17.362281680107117, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.24609208106995, "training_acc": 53.0, "val_loss": 17.3339381814003, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.2214708328247, "training_acc": 53.0, "val_loss": 17.316633462905884, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13735485076904, "training_acc": 53.0, "val_loss": 17.312881350517273, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.21716976165771, "training_acc": 53.0, "val_loss": 17.311324179172516, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16125726699829, "training_acc": 53.0, "val_loss": 17.319147288799286, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.140625, "training_acc": 53.0, "val_loss": 17.32008010149002, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14563035964966, "training_acc": 53.0, "val_loss": 17.317256331443787, "val_acc": 52.0}
