"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.33464932441711, "training_acc": 53.0, "val_loss": 17.31809824705124, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2022488117218, "training_acc": 53.0, "val_loss": 17.342975735664368, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.09284377098083, "training_acc": 53.0, "val_loss": 17.303772270679474, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13485741615295, "training_acc": 53.0, "val_loss": 17.310985922813416, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.21811318397522, "training_acc": 53.0, "val_loss": 17.309509217739105, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0550889968872, "training_acc": 53.0, "val_loss": 17.317909002304077, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.42627692222595, "training_acc": 43.0, "val_loss": 17.319026589393616, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.30047941207886, "training_acc": 53.0, "val_loss": 17.30746030807495, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16934752464294, "training_acc": 53.0, "val_loss": 17.307132482528687, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18094253540039, "training_acc": 53.0, "val_loss": 17.323780059814453, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11615490913391, "training_acc": 53.0, "val_loss": 17.314644157886505, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.03587770462036, "training_acc": 53.0, "val_loss": 17.31162667274475, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.02107954025269, "training_acc": 53.0, "val_loss": 17.309001088142395, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.09321188926697, "training_acc": 53.0, "val_loss": 17.303813993930817, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.95207285881042, "training_acc": 53.0, "val_loss": 17.28675365447998, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.07090067863464, "training_acc": 53.0, "val_loss": 17.28229522705078, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.9811897277832, "training_acc": 53.0, "val_loss": 17.283520102500916, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.8866798877716, "training_acc": 53.0, "val_loss": 17.300817370414734, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13326573371887, "training_acc": 53.0, "val_loss": 17.30770617723465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.90430808067322, "training_acc": 53.0, "val_loss": 17.287909984588623, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.98801326751709, "training_acc": 53.0, "val_loss": 17.282570898532867, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.81619381904602, "training_acc": 53.0, "val_loss": 17.28890985250473, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13705372810364, "training_acc": 53.0, "val_loss": 17.317187786102295, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.82021856307983, "training_acc": 53.0, "val_loss": 17.285996675491333, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.64045691490173, "training_acc": 53.0, "val_loss": 17.283913493156433, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.76946949958801, "training_acc": 53.0, "val_loss": 17.27950870990753, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.64835667610168, "training_acc": 53.0, "val_loss": 17.316024005413055, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.56885647773743, "training_acc": 53.0, "val_loss": 17.305894196033478, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.34315848350525, "training_acc": 53.0, "val_loss": 17.258350551128387, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.39295220375061, "training_acc": 53.0, "val_loss": 17.253604531288147, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.03517436981201, "training_acc": 53.0, "val_loss": 17.342296242713928, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.36111497879028, "training_acc": 53.0, "val_loss": 17.236697673797607, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.87025117874146, "training_acc": 54.0, "val_loss": 17.220458388328552, "val_acc": 52.0}
{"epoch": 33, "training_loss": 67.5936210155487, "training_acc": 55.0, "val_loss": 17.257903516292572, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.82079243659973, "training_acc": 53.0, "val_loss": 17.27152019739151, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.75531935691833, "training_acc": 54.0, "val_loss": 17.249269783496857, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.6496262550354, "training_acc": 65.0, "val_loss": 17.414216697216034, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.72506046295166, "training_acc": 53.0, "val_loss": 17.187945544719696, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.57443928718567, "training_acc": 61.0, "val_loss": 17.194268107414246, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.46246409416199, "training_acc": 67.0, "val_loss": 17.521552741527557, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.89808535575867, "training_acc": 52.0, "val_loss": 17.19011664390564, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.08795070648193, "training_acc": 61.0, "val_loss": 17.123135924339294, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.69736933708191, "training_acc": 56.0, "val_loss": 17.21668839454651, "val_acc": 52.0}
{"epoch": 43, "training_loss": 66.22568440437317, "training_acc": 77.0, "val_loss": 17.047977447509766, "val_acc": 52.0}
{"epoch": 44, "training_loss": 64.20259475708008, "training_acc": 65.0, "val_loss": 16.952133178710938, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.80396866798401, "training_acc": 81.0, "val_loss": 17.266806960105896, "val_acc": 52.0}
{"epoch": 46, "training_loss": 63.431336641311646, "training_acc": 64.0, "val_loss": 17.75572896003723, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.44435095787048, "training_acc": 48.0, "val_loss": 17.74621307849884, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.81667280197144, "training_acc": 53.0, "val_loss": 17.494967579841614, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.77502918243408, "training_acc": 53.0, "val_loss": 17.305012047290802, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.282306432724, "training_acc": 53.0, "val_loss": 17.29333996772766, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.65613341331482, "training_acc": 56.0, "val_loss": 17.280307412147522, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68.39244484901428, "training_acc": 54.0, "val_loss": 17.298120260238647, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.28833293914795, "training_acc": 53.0, "val_loss": 17.295275628566742, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.27562713623047, "training_acc": 54.0, "val_loss": 17.265012860298157, "val_acc": 52.0}
{"epoch": 55, "training_loss": 67.34309458732605, "training_acc": 62.0, "val_loss": 17.25510209798813, "val_acc": 52.0}
{"epoch": 56, "training_loss": 67.9850549697876, "training_acc": 53.0, "val_loss": 17.253415286540985, "val_acc": 52.0}
{"epoch": 57, "training_loss": 66.34820175170898, "training_acc": 58.0, "val_loss": 17.316974699497223, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.37493968009949, "training_acc": 53.0, "val_loss": 17.240257561206818, "val_acc": 52.0}
{"epoch": 59, "training_loss": 65.25408577919006, "training_acc": 71.0, "val_loss": 17.55739152431488, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.54036164283752, "training_acc": 53.0, "val_loss": 17.503102123737335, "val_acc": 52.0}
{"epoch": 61, "training_loss": 66.41707611083984, "training_acc": 58.0, "val_loss": 17.1973317861557, "val_acc": 52.0}
{"epoch": 62, "training_loss": 65.58641719818115, "training_acc": 74.0, "val_loss": 17.063459753990173, "val_acc": 52.0}
{"epoch": 63, "training_loss": 63.28875660896301, "training_acc": 77.0, "val_loss": 17.117701470851898, "val_acc": 52.0}
