"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24600267410278, "training_acc": 52.0, "val_loss": 17.400604486465454, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17952680587769, "training_acc": 54.0, "val_loss": 17.340722680091858, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18990683555603, "training_acc": 53.0, "val_loss": 17.314593493938446, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17668867111206, "training_acc": 53.0, "val_loss": 17.311309278011322, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.37646055221558, "training_acc": 53.0, "val_loss": 17.3107773065567, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08100128173828, "training_acc": 53.0, "val_loss": 17.33502298593521, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12217450141907, "training_acc": 53.0, "val_loss": 17.36617237329483, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1249771118164, "training_acc": 53.0, "val_loss": 17.398519814014435, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24256944656372, "training_acc": 53.0, "val_loss": 17.407219111919403, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.31071972846985, "training_acc": 53.0, "val_loss": 17.38516539335251, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16246342658997, "training_acc": 53.0, "val_loss": 17.334768176078796, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.03530883789062, "training_acc": 53.0, "val_loss": 17.319191992282867, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.197012424469, "training_acc": 53.0, "val_loss": 17.317894101142883, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11999654769897, "training_acc": 53.0, "val_loss": 17.318803071975708, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19890308380127, "training_acc": 53.0, "val_loss": 17.31853485107422, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.02597904205322, "training_acc": 53.0, "val_loss": 17.321057617664337, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18076252937317, "training_acc": 53.0, "val_loss": 17.325109243392944, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19328784942627, "training_acc": 53.0, "val_loss": 17.353814840316772, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19497036933899, "training_acc": 53.0, "val_loss": 17.3583522439003, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.06929230690002, "training_acc": 53.0, "val_loss": 17.336532473564148, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.0944037437439, "training_acc": 53.0, "val_loss": 17.324183881282806, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.01487302780151, "training_acc": 53.0, "val_loss": 17.327173054218292, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.96900987625122, "training_acc": 53.0, "val_loss": 17.331168055534363, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.94116973876953, "training_acc": 53.0, "val_loss": 17.336487770080566, "val_acc": 52.0}
