"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.00811243057251, "training_acc": 47.0, "val_loss": 17.455074191093445, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.65442276000977, "training_acc": 47.0, "val_loss": 17.32838749885559, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.45463967323303, "training_acc": 45.0, "val_loss": 17.315076291561127, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22080206871033, "training_acc": 53.0, "val_loss": 17.3139289021492, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07696199417114, "training_acc": 53.0, "val_loss": 17.339885234832764, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16562294960022, "training_acc": 53.0, "val_loss": 17.324598133563995, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.05928564071655, "training_acc": 53.0, "val_loss": 17.314167320728302, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.05455327033997, "training_acc": 53.0, "val_loss": 17.303040623664856, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.25211429595947, "training_acc": 53.0, "val_loss": 17.30549931526184, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.23992824554443, "training_acc": 53.0, "val_loss": 17.31184422969818, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17920279502869, "training_acc": 53.0, "val_loss": 17.31414943933487, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.03181004524231, "training_acc": 53.0, "val_loss": 17.301669716835022, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.30078148841858, "training_acc": 53.0, "val_loss": 17.29777753353119, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.02115750312805, "training_acc": 53.0, "val_loss": 17.317739129066467, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.06135201454163, "training_acc": 53.0, "val_loss": 17.33362227678299, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.33778715133667, "training_acc": 53.0, "val_loss": 17.32354760169983, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.00225687026978, "training_acc": 53.0, "val_loss": 17.29557365179062, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17564225196838, "training_acc": 53.0, "val_loss": 17.30458438396454, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.25359892845154, "training_acc": 55.0, "val_loss": 17.298327386379242, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.95852088928223, "training_acc": 53.0, "val_loss": 17.335592210292816, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.97434258460999, "training_acc": 53.0, "val_loss": 17.376476526260376, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1878068447113, "training_acc": 53.0, "val_loss": 17.365872859954834, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.03681659698486, "training_acc": 53.0, "val_loss": 17.309674620628357, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.95512461662292, "training_acc": 53.0, "val_loss": 17.297561466693878, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.07896184921265, "training_acc": 53.0, "val_loss": 17.318449914455414, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17456936836243, "training_acc": 58.0, "val_loss": 17.305737733840942, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12762188911438, "training_acc": 53.0, "val_loss": 17.29693114757538, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.0458414554596, "training_acc": 53.0, "val_loss": 17.29923039674759, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.93040728569031, "training_acc": 53.0, "val_loss": 17.291845381259918, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.9139506816864, "training_acc": 53.0, "val_loss": 17.281746864318848, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.88338589668274, "training_acc": 53.0, "val_loss": 17.290005087852478, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.79754376411438, "training_acc": 53.0, "val_loss": 17.280253767967224, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.95223951339722, "training_acc": 53.0, "val_loss": 17.28152483701706, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.60890984535217, "training_acc": 53.0, "val_loss": 17.26243495941162, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.7351758480072, "training_acc": 54.0, "val_loss": 17.251956462860107, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.64016008377075, "training_acc": 54.0, "val_loss": 17.280906438827515, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.54071927070618, "training_acc": 53.0, "val_loss": 17.253658175468445, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.54326701164246, "training_acc": 55.0, "val_loss": 17.281574010849, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.82822847366333, "training_acc": 54.0, "val_loss": 17.360199987888336, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.0229160785675, "training_acc": 53.0, "val_loss": 17.276279628276825, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.50014185905457, "training_acc": 59.0, "val_loss": 17.29353815317154, "val_acc": 52.0}
{"epoch": 41, "training_loss": 67.21601963043213, "training_acc": 53.0, "val_loss": 17.261889576911926, "val_acc": 52.0}
{"epoch": 42, "training_loss": 67.41558051109314, "training_acc": 60.0, "val_loss": 17.210936546325684, "val_acc": 52.0}
{"epoch": 43, "training_loss": 66.6615834236145, "training_acc": 55.0, "val_loss": 17.17965602874756, "val_acc": 52.0}
{"epoch": 44, "training_loss": 66.67501616477966, "training_acc": 58.0, "val_loss": 17.53910332918167, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.11641263961792, "training_acc": 38.0, "val_loss": 17.349474132061005, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.9649384021759, "training_acc": 63.0, "val_loss": 17.3211470246315, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.85107636451721, "training_acc": 53.0, "val_loss": 17.33243763446808, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.04294490814209, "training_acc": 53.0, "val_loss": 17.369072139263153, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.99861240386963, "training_acc": 53.0, "val_loss": 17.429831624031067, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.19297075271606, "training_acc": 53.0, "val_loss": 17.349551618099213, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.75785160064697, "training_acc": 53.0, "val_loss": 17.3184797167778, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1769745349884, "training_acc": 53.0, "val_loss": 17.319276928901672, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.08107089996338, "training_acc": 53.0, "val_loss": 17.31472760438919, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.95237755775452, "training_acc": 53.0, "val_loss": 17.337949573993683, "val_acc": 52.0}
{"epoch": 55, "training_loss": 68.99602270126343, "training_acc": 53.0, "val_loss": 17.370128631591797, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.142174243927, "training_acc": 53.0, "val_loss": 17.407460510730743, "val_acc": 52.0}
{"epoch": 57, "training_loss": 68.95921444892883, "training_acc": 53.0, "val_loss": 17.356868088245392, "val_acc": 52.0}
{"epoch": 58, "training_loss": 68.80693650245667, "training_acc": 53.0, "val_loss": 17.34376847743988, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.83900499343872, "training_acc": 53.0, "val_loss": 17.352744936943054, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.81639099121094, "training_acc": 53.0, "val_loss": 17.349933087825775, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.62976002693176, "training_acc": 53.0, "val_loss": 17.357555031776428, "val_acc": 52.0}
{"epoch": 62, "training_loss": 68.99434280395508, "training_acc": 53.0, "val_loss": 17.34725385904312, "val_acc": 52.0}
