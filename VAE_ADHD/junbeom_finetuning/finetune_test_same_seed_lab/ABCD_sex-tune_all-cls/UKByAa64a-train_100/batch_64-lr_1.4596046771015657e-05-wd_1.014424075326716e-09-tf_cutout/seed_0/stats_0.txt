"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.32979607582092, "training_acc": 52.0, "val_loss": 17.27217584848404, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22736096382141, "training_acc": 52.0, "val_loss": 17.288406193256378, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.19733953475952, "training_acc": 52.0, "val_loss": 17.306357622146606, "val_acc": 56.0}
{"epoch": 3, "training_loss": 68.90503430366516, "training_acc": 52.0, "val_loss": 17.299212515354156, "val_acc": 56.0}
{"epoch": 4, "training_loss": 68.89297580718994, "training_acc": 52.0, "val_loss": 17.2968789935112, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.15256357192993, "training_acc": 52.0, "val_loss": 17.276252806186676, "val_acc": 56.0}
{"epoch": 6, "training_loss": 68.94307827949524, "training_acc": 52.0, "val_loss": 17.273081839084625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.07685780525208, "training_acc": 57.0, "val_loss": 17.264424264431, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.05664038658142, "training_acc": 56.0, "val_loss": 17.237374186515808, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.09232902526855, "training_acc": 52.0, "val_loss": 17.248384654521942, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.10031986236572, "training_acc": 53.0, "val_loss": 17.26393848657608, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.90590643882751, "training_acc": 52.0, "val_loss": 17.236800491809845, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.82058024406433, "training_acc": 56.0, "val_loss": 17.296576499938965, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.59265995025635, "training_acc": 57.0, "val_loss": 17.332440614700317, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.62802124023438, "training_acc": 59.0, "val_loss": 17.333373427391052, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.53882575035095, "training_acc": 56.0, "val_loss": 17.306682467460632, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.32345223426819, "training_acc": 52.0, "val_loss": 17.257823050022125, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.6224205493927, "training_acc": 52.0, "val_loss": 17.243491113185883, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.09312438964844, "training_acc": 55.0, "val_loss": 17.24604070186615, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.13020062446594, "training_acc": 55.0, "val_loss": 17.319995164871216, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.42863178253174, "training_acc": 58.0, "val_loss": 17.388613522052765, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.91386365890503, "training_acc": 60.0, "val_loss": 17.39216446876526, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.41215372085571, "training_acc": 56.0, "val_loss": 17.28527545928955, "val_acc": 56.0}
{"epoch": 23, "training_loss": 67.99064612388611, "training_acc": 53.0, "val_loss": 17.307062447071075, "val_acc": 56.0}
{"epoch": 24, "training_loss": 67.99863910675049, "training_acc": 56.0, "val_loss": 17.40162968635559, "val_acc": 56.0}
{"epoch": 25, "training_loss": 67.89803099632263, "training_acc": 67.0, "val_loss": 17.38898456096649, "val_acc": 56.0}
{"epoch": 26, "training_loss": 67.77757501602173, "training_acc": 62.0, "val_loss": 17.317870259284973, "val_acc": 56.0}
{"epoch": 27, "training_loss": 67.92358589172363, "training_acc": 57.0, "val_loss": 17.384223639965057, "val_acc": 56.0}
{"epoch": 28, "training_loss": 67.2632839679718, "training_acc": 70.0, "val_loss": 17.479850351810455, "val_acc": 56.0}
{"epoch": 29, "training_loss": 67.50170254707336, "training_acc": 66.0, "val_loss": 17.313772439956665, "val_acc": 56.0}
{"epoch": 30, "training_loss": 67.51081848144531, "training_acc": 65.0, "val_loss": 17.269235849380493, "val_acc": 56.0}
