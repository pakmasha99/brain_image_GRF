"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1155.0421676635742, "training_acc": 47.0, "val_loss": 144.10465955734253, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1062.9858474731445, "training_acc": 49.0, "val_loss": 693.6815738677979, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2662.256950378418, "training_acc": 53.0, "val_loss": 491.50147438049316, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1502.3211669921875, "training_acc": 53.0, "val_loss": 129.4435977935791, "val_acc": 48.0}
{"epoch": 4, "training_loss": 750.421085357666, "training_acc": 47.0, "val_loss": 318.27406883239746, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1067.3062858581543, "training_acc": 47.0, "val_loss": 19.84718292951584, "val_acc": 48.0}
{"epoch": 6, "training_loss": 337.61291694641113, "training_acc": 48.0, "val_loss": 248.88839721679688, "val_acc": 52.0}
{"epoch": 7, "training_loss": 921.636905670166, "training_acc": 53.0, "val_loss": 94.51218247413635, "val_acc": 52.0}
{"epoch": 8, "training_loss": 341.3728942871094, "training_acc": 55.0, "val_loss": 180.93186616897583, "val_acc": 48.0}
{"epoch": 9, "training_loss": 670.2952842712402, "training_acc": 47.0, "val_loss": 34.38728153705597, "val_acc": 48.0}
{"epoch": 10, "training_loss": 204.0237102508545, "training_acc": 56.0, "val_loss": 201.18346214294434, "val_acc": 52.0}
{"epoch": 11, "training_loss": 759.9953289031982, "training_acc": 53.0, "val_loss": 96.47893905639648, "val_acc": 52.0}
{"epoch": 12, "training_loss": 323.65600299835205, "training_acc": 53.0, "val_loss": 134.83608961105347, "val_acc": 48.0}
{"epoch": 13, "training_loss": 473.9068298339844, "training_acc": 47.0, "val_loss": 26.060396432876587, "val_acc": 48.0}
{"epoch": 14, "training_loss": 180.4468116760254, "training_acc": 51.0, "val_loss": 70.82546949386597, "val_acc": 52.0}
{"epoch": 15, "training_loss": 221.13187265396118, "training_acc": 51.0, "val_loss": 58.6146354675293, "val_acc": 48.0}
{"epoch": 16, "training_loss": 162.41400003433228, "training_acc": 54.0, "val_loss": 45.78646719455719, "val_acc": 52.0}
{"epoch": 17, "training_loss": 171.46558332443237, "training_acc": 53.0, "val_loss": 36.51789426803589, "val_acc": 48.0}
{"epoch": 18, "training_loss": 133.09895014762878, "training_acc": 53.0, "val_loss": 22.902430593967438, "val_acc": 52.0}
{"epoch": 19, "training_loss": 97.83946180343628, "training_acc": 58.0, "val_loss": 21.02101445198059, "val_acc": 52.0}
{"epoch": 20, "training_loss": 93.2693600654602, "training_acc": 59.0, "val_loss": 22.901800274848938, "val_acc": 52.0}
{"epoch": 21, "training_loss": 78.30497169494629, "training_acc": 60.0, "val_loss": 26.540863513946533, "val_acc": 52.0}
{"epoch": 22, "training_loss": 77.25966191291809, "training_acc": 59.0, "val_loss": 42.332860827445984, "val_acc": 52.0}
{"epoch": 23, "training_loss": 118.10552215576172, "training_acc": 56.0, "val_loss": 61.59566044807434, "val_acc": 48.0}
{"epoch": 24, "training_loss": 209.68329429626465, "training_acc": 47.0, "val_loss": 55.12939095497131, "val_acc": 52.0}
