"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2639.3096466064453, "training_acc": 51.0, "val_loss": 530.8216571807861, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3654.9983825683594, "training_acc": 45.0, "val_loss": 1631.5021514892578, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5990.9844970703125, "training_acc": 47.0, "val_loss": 308.748722076416, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1773.5270080566406, "training_acc": 51.0, "val_loss": 1305.111026763916, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5118.621047973633, "training_acc": 53.0, "val_loss": 1178.0317306518555, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3862.89005279541, "training_acc": 53.0, "val_loss": 38.553476333618164, "val_acc": 52.0}
{"epoch": 6, "training_loss": 994.2942504882812, "training_acc": 50.0, "val_loss": 649.3251800537109, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2173.092296600342, "training_acc": 47.0, "val_loss": 125.65971612930298, "val_acc": 52.0}
{"epoch": 8, "training_loss": 720.9659767150879, "training_acc": 53.0, "val_loss": 214.32201862335205, "val_acc": 52.0}
{"epoch": 9, "training_loss": 724.9815883636475, "training_acc": 49.0, "val_loss": 159.20963287353516, "val_acc": 48.0}
{"epoch": 10, "training_loss": 486.9983797073364, "training_acc": 48.0, "val_loss": 73.09356331825256, "val_acc": 52.0}
{"epoch": 11, "training_loss": 293.32533264160156, "training_acc": 57.0, "val_loss": 44.78790462017059, "val_acc": 52.0}
{"epoch": 12, "training_loss": 249.60847187042236, "training_acc": 52.0, "val_loss": 27.673357725143433, "val_acc": 56.0}
{"epoch": 13, "training_loss": 259.4094657897949, "training_acc": 56.0, "val_loss": 76.04643106460571, "val_acc": 52.0}
{"epoch": 14, "training_loss": 238.75428676605225, "training_acc": 55.0, "val_loss": 136.17801666259766, "val_acc": 48.0}
{"epoch": 15, "training_loss": 570.2823457717896, "training_acc": 48.0, "val_loss": 210.43014526367188, "val_acc": 52.0}
{"epoch": 16, "training_loss": 741.1670570373535, "training_acc": 53.0, "val_loss": 51.40720009803772, "val_acc": 56.0}
{"epoch": 17, "training_loss": 413.7286567687988, "training_acc": 57.0, "val_loss": 212.98844814300537, "val_acc": 48.0}
{"epoch": 18, "training_loss": 614.1929125785828, "training_acc": 57.0, "val_loss": 208.1047534942627, "val_acc": 52.0}
{"epoch": 19, "training_loss": 607.1544799804688, "training_acc": 53.0, "val_loss": 113.31146955490112, "val_acc": 48.0}
{"epoch": 20, "training_loss": 544.9399089813232, "training_acc": 47.0, "val_loss": 125.77847242355347, "val_acc": 52.0}
{"epoch": 21, "training_loss": 362.7026958465576, "training_acc": 56.0, "val_loss": 30.419546365737915, "val_acc": 64.0}
{"epoch": 22, "training_loss": 193.60338687896729, "training_acc": 53.0, "val_loss": 127.00076103210449, "val_acc": 52.0}
{"epoch": 23, "training_loss": 307.42809295654297, "training_acc": 55.0, "val_loss": 172.68965244293213, "val_acc": 48.0}
{"epoch": 24, "training_loss": 612.536657333374, "training_acc": 47.0, "val_loss": 168.12891960144043, "val_acc": 52.0}
{"epoch": 25, "training_loss": 669.8710975646973, "training_acc": 53.0, "val_loss": 33.79754424095154, "val_acc": 52.0}
{"epoch": 26, "training_loss": 303.26515007019043, "training_acc": 65.0, "val_loss": 108.08775424957275, "val_acc": 48.0}
{"epoch": 27, "training_loss": 468.7100200653076, "training_acc": 50.0, "val_loss": 252.59835720062256, "val_acc": 52.0}
{"epoch": 28, "training_loss": 609.8055329322815, "training_acc": 57.0, "val_loss": 258.2343578338623, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1098.7142639160156, "training_acc": 47.0, "val_loss": 46.22575342655182, "val_acc": 60.0}
{"epoch": 30, "training_loss": 676.7901344299316, "training_acc": 48.0, "val_loss": 407.23538398742676, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1276.7543182373047, "training_acc": 53.0, "val_loss": 111.25390529632568, "val_acc": 48.0}
