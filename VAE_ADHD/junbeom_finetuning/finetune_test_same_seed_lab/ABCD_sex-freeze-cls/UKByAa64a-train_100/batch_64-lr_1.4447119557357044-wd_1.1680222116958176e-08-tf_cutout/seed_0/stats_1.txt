"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3078.67427444458, "training_acc": 46.0, "val_loss": 634.1023921966553, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3080.047653198242, "training_acc": 53.0, "val_loss": 1642.630386352539, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6181.695037841797, "training_acc": 47.0, "val_loss": 455.41539192199707, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2153.908905029297, "training_acc": 51.0, "val_loss": 1199.4179725646973, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4557.515380859375, "training_acc": 53.0, "val_loss": 1070.2624320983887, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3176.867530822754, "training_acc": 53.0, "val_loss": 186.09120845794678, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1714.2725677490234, "training_acc": 47.0, "val_loss": 548.3628273010254, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1858.241844177246, "training_acc": 47.0, "val_loss": 397.1228361129761, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1548.809440612793, "training_acc": 53.0, "val_loss": 688.3421421051025, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2235.085018157959, "training_acc": 53.0, "val_loss": 86.62927150726318, "val_acc": 52.0}
{"epoch": 10, "training_loss": 903.9638519287109, "training_acc": 49.0, "val_loss": 644.3490982055664, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2472.5193481445312, "training_acc": 47.0, "val_loss": 142.37563610076904, "val_acc": 48.0}
{"epoch": 12, "training_loss": 895.5822219848633, "training_acc": 49.0, "val_loss": 665.894079208374, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2553.482696533203, "training_acc": 53.0, "val_loss": 495.6058979034424, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1319.2120685577393, "training_acc": 52.0, "val_loss": 482.321834564209, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2334.139175415039, "training_acc": 47.0, "val_loss": 680.8086395263672, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2248.667350769043, "training_acc": 47.0, "val_loss": 148.3736276626587, "val_acc": 52.0}
{"epoch": 17, "training_loss": 826.0763549804688, "training_acc": 55.0, "val_loss": 420.99175453186035, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1320.6336507797241, "training_acc": 53.0, "val_loss": 161.91684007644653, "val_acc": 48.0}
{"epoch": 19, "training_loss": 687.0179386138916, "training_acc": 47.0, "val_loss": 55.81247806549072, "val_acc": 40.0}
{"epoch": 20, "training_loss": 584.8448905944824, "training_acc": 50.0, "val_loss": 317.34609603881836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 821.0861721038818, "training_acc": 56.0, "val_loss": 189.64427709579468, "val_acc": 48.0}
{"epoch": 22, "training_loss": 853.7608337402344, "training_acc": 47.0, "val_loss": 81.69891238212585, "val_acc": 44.0}
{"epoch": 23, "training_loss": 616.4514389038086, "training_acc": 48.0, "val_loss": 405.2070617675781, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1256.5683288574219, "training_acc": 53.0, "val_loss": 49.584853649139404, "val_acc": 56.0}
{"epoch": 25, "training_loss": 593.2225456237793, "training_acc": 59.0, "val_loss": 278.43737602233887, "val_acc": 48.0}
{"epoch": 26, "training_loss": 716.1463308334351, "training_acc": 53.0, "val_loss": 346.026086807251, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1307.103614807129, "training_acc": 53.0, "val_loss": 399.7016429901123, "val_acc": 52.0}
{"epoch": 28, "training_loss": 941.2135028839111, "training_acc": 55.0, "val_loss": 337.003231048584, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1794.8435440063477, "training_acc": 47.0, "val_loss": 401.9391059875488, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1182.616132736206, "training_acc": 55.0, "val_loss": 416.0731315612793, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1544.0727233886719, "training_acc": 53.0, "val_loss": 576.7223834991455, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1675.0189781188965, "training_acc": 53.0, "val_loss": 63.07476758956909, "val_acc": 40.0}
{"epoch": 33, "training_loss": 546.1927680969238, "training_acc": 55.0, "val_loss": 216.52204990386963, "val_acc": 48.0}
{"epoch": 34, "training_loss": 914.8458042144775, "training_acc": 38.0, "val_loss": 210.9405755996704, "val_acc": 52.0}
{"epoch": 35, "training_loss": 573.7464294433594, "training_acc": 56.0, "val_loss": 79.10180687904358, "val_acc": 36.0}
{"epoch": 36, "training_loss": 438.24010848999023, "training_acc": 53.0, "val_loss": 110.7708215713501, "val_acc": 56.0}
{"epoch": 37, "training_loss": 314.4838809967041, "training_acc": 54.0, "val_loss": 80.49723505973816, "val_acc": 56.0}
{"epoch": 38, "training_loss": 353.61380767822266, "training_acc": 56.0, "val_loss": 40.0307834148407, "val_acc": 52.0}
{"epoch": 39, "training_loss": 296.69006729125977, "training_acc": 59.0, "val_loss": 137.50250339508057, "val_acc": 56.0}
{"epoch": 40, "training_loss": 322.49401664733887, "training_acc": 54.0, "val_loss": 78.50898504257202, "val_acc": 52.0}
{"epoch": 41, "training_loss": 356.8407459259033, "training_acc": 51.0, "val_loss": 160.02051830291748, "val_acc": 52.0}
{"epoch": 42, "training_loss": 428.94418954849243, "training_acc": 54.0, "val_loss": 44.34073567390442, "val_acc": 40.0}
{"epoch": 43, "training_loss": 280.07284355163574, "training_acc": 58.0, "val_loss": 32.259806990623474, "val_acc": 64.0}
{"epoch": 44, "training_loss": 152.58679962158203, "training_acc": 67.0, "val_loss": 36.25788688659668, "val_acc": 64.0}
{"epoch": 45, "training_loss": 113.97913455963135, "training_acc": 70.0, "val_loss": 22.038806974887848, "val_acc": 68.0}
{"epoch": 46, "training_loss": 118.25387144088745, "training_acc": 71.0, "val_loss": 19.80302929878235, "val_acc": 56.0}
{"epoch": 47, "training_loss": 141.97519874572754, "training_acc": 64.0, "val_loss": 23.387016355991364, "val_acc": 68.0}
{"epoch": 48, "training_loss": 126.68579006195068, "training_acc": 62.0, "val_loss": 110.42039394378662, "val_acc": 52.0}
{"epoch": 49, "training_loss": 256.33801317214966, "training_acc": 57.0, "val_loss": 155.3338885307312, "val_acc": 48.0}
{"epoch": 50, "training_loss": 530.954065322876, "training_acc": 47.0, "val_loss": 218.4354543685913, "val_acc": 52.0}
{"epoch": 51, "training_loss": 873.0611839294434, "training_acc": 53.0, "val_loss": 135.6176257133484, "val_acc": 52.0}
{"epoch": 52, "training_loss": 603.466796875, "training_acc": 51.0, "val_loss": 319.2744016647339, "val_acc": 48.0}
{"epoch": 53, "training_loss": 939.8782062530518, "training_acc": 47.0, "val_loss": 289.6451234817505, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1276.753662109375, "training_acc": 53.0, "val_loss": 366.8759346008301, "val_acc": 52.0}
{"epoch": 55, "training_loss": 961.8563842773438, "training_acc": 58.0, "val_loss": 364.1949653625488, "val_acc": 48.0}
{"epoch": 56, "training_loss": 1675.9079284667969, "training_acc": 47.0, "val_loss": 334.81414318084717, "val_acc": 48.0}
{"epoch": 57, "training_loss": 912.1727981567383, "training_acc": 49.0, "val_loss": 237.8572702407837, "val_acc": 52.0}
{"epoch": 58, "training_loss": 719.1096067428589, "training_acc": 53.0, "val_loss": 146.09708786010742, "val_acc": 48.0}
{"epoch": 59, "training_loss": 533.8251705169678, "training_acc": 47.0, "val_loss": 106.32325410842896, "val_acc": 52.0}
{"epoch": 60, "training_loss": 363.9870853424072, "training_acc": 54.0, "val_loss": 106.78274631500244, "val_acc": 48.0}
{"epoch": 61, "training_loss": 381.4301948547363, "training_acc": 46.0, "val_loss": 165.62161445617676, "val_acc": 52.0}
{"epoch": 62, "training_loss": 531.225751876831, "training_acc": 53.0, "val_loss": 31.108111143112183, "val_acc": 52.0}
{"epoch": 63, "training_loss": 267.66319847106934, "training_acc": 58.0, "val_loss": 113.84009122848511, "val_acc": 56.0}
{"epoch": 64, "training_loss": 312.1524410247803, "training_acc": 58.0, "val_loss": 44.86639201641083, "val_acc": 60.0}
{"epoch": 65, "training_loss": 194.2439661026001, "training_acc": 64.0, "val_loss": 58.95277261734009, "val_acc": 60.0}
