"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 44500.31558227539, "training_acc": 52.0, "val_loss": 14787.348937988281, "val_acc": 44.0}
{"epoch": 1, "training_loss": 45418.83020019531, "training_acc": 48.0, "val_loss": 15536.863708496094, "val_acc": 56.0}
{"epoch": 2, "training_loss": 71988.65380859375, "training_acc": 52.0, "val_loss": 6518.482208251953, "val_acc": 56.0}
{"epoch": 3, "training_loss": 37154.3193359375, "training_acc": 54.0, "val_loss": 25007.920837402344, "val_acc": 44.0}
{"epoch": 4, "training_loss": 83983.35961914062, "training_acc": 48.0, "val_loss": 2109.172248840332, "val_acc": 44.0}
{"epoch": 5, "training_loss": 39032.915283203125, "training_acc": 44.0, "val_loss": 27561.065673828125, "val_acc": 56.0}
{"epoch": 6, "training_loss": 120491.533203125, "training_acc": 52.0, "val_loss": 21130.6640625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 73496.83068847656, "training_acc": 52.0, "val_loss": 11845.699310302734, "val_acc": 44.0}
{"epoch": 8, "training_loss": 53609.226318359375, "training_acc": 48.0, "val_loss": 22801.280212402344, "val_acc": 44.0}
{"epoch": 9, "training_loss": 74472.57739257812, "training_acc": 48.0, "val_loss": 692.5801277160645, "val_acc": 44.0}
{"epoch": 10, "training_loss": 24990.275329589844, "training_acc": 52.0, "val_loss": 23812.98065185547, "val_acc": 56.0}
{"epoch": 11, "training_loss": 106542.10986328125, "training_acc": 52.0, "val_loss": 20859.120178222656, "val_acc": 56.0}
{"epoch": 12, "training_loss": 74281.73120117188, "training_acc": 52.0, "val_loss": 4706.019592285156, "val_acc": 44.0}
{"epoch": 13, "training_loss": 29905.13525390625, "training_acc": 48.0, "val_loss": 14030.973815917969, "val_acc": 44.0}
{"epoch": 14, "training_loss": 40660.61444091797, "training_acc": 48.0, "val_loss": 6504.866790771484, "val_acc": 56.0}
{"epoch": 15, "training_loss": 34529.98645019531, "training_acc": 52.0, "val_loss": 10207.350158691406, "val_acc": 56.0}
{"epoch": 16, "training_loss": 34590.543884277344, "training_acc": 52.0, "val_loss": 9001.206970214844, "val_acc": 44.0}
{"epoch": 17, "training_loss": 39899.575927734375, "training_acc": 48.0, "val_loss": 11308.451080322266, "val_acc": 44.0}
{"epoch": 18, "training_loss": 27546.00032043457, "training_acc": 48.0, "val_loss": 12059.947967529297, "val_acc": 56.0}
{"epoch": 19, "training_loss": 62701.950439453125, "training_acc": 52.0, "val_loss": 18621.19903564453, "val_acc": 56.0}
{"epoch": 20, "training_loss": 72901.4697265625, "training_acc": 52.0, "val_loss": 3281.525421142578, "val_acc": 56.0}
{"epoch": 21, "training_loss": 30931.959228515625, "training_acc": 46.0, "val_loss": 22968.20526123047, "val_acc": 44.0}
{"epoch": 22, "training_loss": 84008.60913085938, "training_acc": 48.0, "val_loss": 15972.663879394531, "val_acc": 44.0}
{"epoch": 23, "training_loss": 41826.90869140625, "training_acc": 48.0, "val_loss": 13084.178161621094, "val_acc": 56.0}
{"epoch": 24, "training_loss": 71486.5068359375, "training_acc": 52.0, "val_loss": 23127.601623535156, "val_acc": 56.0}
{"epoch": 25, "training_loss": 94793.02856445312, "training_acc": 52.0, "val_loss": 10619.810485839844, "val_acc": 56.0}
{"epoch": 26, "training_loss": 25432.99934387207, "training_acc": 62.0, "val_loss": 10596.05941772461, "val_acc": 44.0}
{"epoch": 27, "training_loss": 38875.99377441406, "training_acc": 48.0, "val_loss": 4125.701522827148, "val_acc": 44.0}
{"epoch": 28, "training_loss": 17963.866943359375, "training_acc": 54.0, "val_loss": 11559.525299072266, "val_acc": 56.0}
