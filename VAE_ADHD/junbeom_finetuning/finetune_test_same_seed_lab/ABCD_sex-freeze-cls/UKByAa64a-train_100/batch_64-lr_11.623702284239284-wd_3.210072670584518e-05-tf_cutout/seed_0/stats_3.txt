"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 94187.53067016602, "training_acc": 51.0, "val_loss": 19526.75323486328, "val_acc": 52.0}
{"epoch": 1, "training_loss": 98544.90087890625, "training_acc": 49.0, "val_loss": 42346.73767089844, "val_acc": 48.0}
{"epoch": 2, "training_loss": 158226.10009765625, "training_acc": 47.0, "val_loss": 10236.128997802734, "val_acc": 48.0}
{"epoch": 3, "training_loss": 60119.82470703125, "training_acc": 45.0, "val_loss": 33263.96484375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 132795.82470703125, "training_acc": 53.0, "val_loss": 28020.974731445312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 89287.93432617188, "training_acc": 53.0, "val_loss": 7345.648193359375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 42902.8125, "training_acc": 47.0, "val_loss": 16473.4375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 54433.28955078125, "training_acc": 47.0, "val_loss": 7948.915100097656, "val_acc": 52.0}
{"epoch": 8, "training_loss": 36113.970703125, "training_acc": 53.0, "val_loss": 12872.715759277344, "val_acc": 52.0}
{"epoch": 9, "training_loss": 41765.584411621094, "training_acc": 53.0, "val_loss": 6893.400573730469, "val_acc": 48.0}
{"epoch": 10, "training_loss": 32674.266235351562, "training_acc": 47.0, "val_loss": 5995.951080322266, "val_acc": 48.0}
{"epoch": 11, "training_loss": 28728.630859375, "training_acc": 39.0, "val_loss": 8157.4676513671875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 26190.53985595703, "training_acc": 53.0, "val_loss": 5721.786880493164, "val_acc": 48.0}
{"epoch": 13, "training_loss": 28234.892211914062, "training_acc": 47.0, "val_loss": 3084.810256958008, "val_acc": 48.0}
{"epoch": 14, "training_loss": 17501.136352539062, "training_acc": 53.0, "val_loss": 12525.699615478516, "val_acc": 52.0}
{"epoch": 15, "training_loss": 46487.16442871094, "training_acc": 53.0, "val_loss": 3556.378936767578, "val_acc": 52.0}
{"epoch": 16, "training_loss": 25316.140502929688, "training_acc": 47.0, "val_loss": 14471.945190429688, "val_acc": 48.0}
{"epoch": 17, "training_loss": 54657.31298828125, "training_acc": 47.0, "val_loss": 2110.5838775634766, "val_acc": 48.0}
{"epoch": 18, "training_loss": 29783.191162109375, "training_acc": 39.0, "val_loss": 18790.167236328125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 72813.43041992188, "training_acc": 53.0, "val_loss": 12751.921844482422, "val_acc": 52.0}
{"epoch": 20, "training_loss": 34608.660247802734, "training_acc": 53.0, "val_loss": 14181.431579589844, "val_acc": 48.0}
{"epoch": 21, "training_loss": 67658.69677734375, "training_acc": 47.0, "val_loss": 22435.13641357422, "val_acc": 48.0}
{"epoch": 22, "training_loss": 82317.5478515625, "training_acc": 47.0, "val_loss": 4045.230484008789, "val_acc": 48.0}
{"epoch": 23, "training_loss": 25479.9951171875, "training_acc": 53.0, "val_loss": 22202.345275878906, "val_acc": 52.0}
{"epoch": 24, "training_loss": 90098.20288085938, "training_acc": 53.0, "val_loss": 22639.75372314453, "val_acc": 52.0}
{"epoch": 25, "training_loss": 77381.64477539062, "training_acc": 53.0, "val_loss": 2390.5677795410156, "val_acc": 52.0}
{"epoch": 26, "training_loss": 27080.0927734375, "training_acc": 53.0, "val_loss": 25333.168029785156, "val_acc": 48.0}
{"epoch": 27, "training_loss": 105389.35229492188, "training_acc": 47.0, "val_loss": 22301.036071777344, "val_acc": 48.0}
{"epoch": 28, "training_loss": 73370.21484375, "training_acc": 47.0, "val_loss": 4832.210922241211, "val_acc": 52.0}
{"epoch": 29, "training_loss": 31806.5859375, "training_acc": 53.0, "val_loss": 15792.230224609375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 56168.62109375, "training_acc": 53.0, "val_loss": 3229.7325134277344, "val_acc": 52.0}
{"epoch": 31, "training_loss": 28564.833251953125, "training_acc": 45.0, "val_loss": 17689.683532714844, "val_acc": 48.0}
{"epoch": 32, "training_loss": 70029.4892578125, "training_acc": 47.0, "val_loss": 8131.886291503906, "val_acc": 48.0}
{"epoch": 33, "training_loss": 26303.90545654297, "training_acc": 53.0, "val_loss": 11544.820404052734, "val_acc": 52.0}
{"epoch": 34, "training_loss": 44972.71154785156, "training_acc": 53.0, "val_loss": 6450.45166015625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 16733.47149658203, "training_acc": 61.0, "val_loss": 7530.254364013672, "val_acc": 48.0}
{"epoch": 36, "training_loss": 26409.326416015625, "training_acc": 47.0, "val_loss": 4625.052642822266, "val_acc": 52.0}
