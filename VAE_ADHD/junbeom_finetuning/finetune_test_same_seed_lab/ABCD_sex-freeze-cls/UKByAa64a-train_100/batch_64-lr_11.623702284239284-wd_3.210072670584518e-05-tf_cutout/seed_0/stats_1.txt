"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 34416.76360321045, "training_acc": 51.0, "val_loss": 18141.81671142578, "val_acc": 48.0}
{"epoch": 1, "training_loss": 59857.585205078125, "training_acc": 47.0, "val_loss": 18428.347778320312, "val_acc": 52.0}
{"epoch": 2, "training_loss": 83831.5986328125, "training_acc": 53.0, "val_loss": 15050.025939941406, "val_acc": 52.0}
{"epoch": 3, "training_loss": 45364.33905029297, "training_acc": 51.0, "val_loss": 10100.760650634766, "val_acc": 48.0}
{"epoch": 4, "training_loss": 29748.479522705078, "training_acc": 47.0, "val_loss": 14435.096740722656, "val_acc": 52.0}
{"epoch": 5, "training_loss": 61487.298583984375, "training_acc": 53.0, "val_loss": 14412.14599609375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 41746.838958740234, "training_acc": 53.0, "val_loss": 15744.6044921875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 73622.9609375, "training_acc": 47.0, "val_loss": 20122.879028320312, "val_acc": 48.0}
{"epoch": 8, "training_loss": 65233.17224121094, "training_acc": 47.0, "val_loss": 7822.676849365234, "val_acc": 52.0}
{"epoch": 9, "training_loss": 35719.570556640625, "training_acc": 53.0, "val_loss": 15676.91650390625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 53846.512939453125, "training_acc": 53.0, "val_loss": 307.2664737701416, "val_acc": 32.0}
{"epoch": 11, "training_loss": 9364.115417480469, "training_acc": 54.0, "val_loss": 8561.286926269531, "val_acc": 48.0}
{"epoch": 12, "training_loss": 23761.994903564453, "training_acc": 47.0, "val_loss": 11763.160705566406, "val_acc": 52.0}
{"epoch": 13, "training_loss": 51864.394775390625, "training_acc": 53.0, "val_loss": 15289.372253417969, "val_acc": 52.0}
{"epoch": 14, "training_loss": 49205.15637207031, "training_acc": 53.0, "val_loss": 5078.401184082031, "val_acc": 48.0}
{"epoch": 15, "training_loss": 27588.542724609375, "training_acc": 47.0, "val_loss": 7126.203918457031, "val_acc": 48.0}
{"epoch": 16, "training_loss": 21379.59796142578, "training_acc": 51.0, "val_loss": 5259.08088684082, "val_acc": 52.0}
{"epoch": 17, "training_loss": 15513.856567382812, "training_acc": 53.0, "val_loss": 8521.56982421875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 35068.76184082031, "training_acc": 47.0, "val_loss": 3613.8595581054688, "val_acc": 48.0}
{"epoch": 19, "training_loss": 22071.9130859375, "training_acc": 47.0, "val_loss": 12803.103637695312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 47303.92248535156, "training_acc": 53.0, "val_loss": 3034.7164154052734, "val_acc": 52.0}
{"epoch": 21, "training_loss": 23135.995483398438, "training_acc": 49.0, "val_loss": 14368.902587890625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 53081.588134765625, "training_acc": 47.0, "val_loss": 1276.296615600586, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24043.210205078125, "training_acc": 47.0, "val_loss": 21719.22607421875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 87745.77783203125, "training_acc": 53.0, "val_loss": 18029.025268554688, "val_acc": 52.0}
{"epoch": 25, "training_loss": 52231.45764160156, "training_acc": 53.0, "val_loss": 8328.546905517578, "val_acc": 48.0}
{"epoch": 26, "training_loss": 44846.517578125, "training_acc": 47.0, "val_loss": 17948.480224609375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 63453.642333984375, "training_acc": 47.0, "val_loss": 461.12561225891113, "val_acc": 52.0}
{"epoch": 28, "training_loss": 8972.62548828125, "training_acc": 56.0, "val_loss": 4596.350479125977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 14492.747650146484, "training_acc": 51.0, "val_loss": 1876.030158996582, "val_acc": 48.0}
