"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3750.9833183288574, "training_acc": 47.0, "val_loss": 904.5646667480469, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3954.282257080078, "training_acc": 51.0, "val_loss": 1636.0898971557617, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5957.43928527832, "training_acc": 47.0, "val_loss": 194.4002628326416, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1769.628189086914, "training_acc": 53.0, "val_loss": 1744.9945449829102, "val_acc": 52.0}
{"epoch": 4, "training_loss": 6893.4014892578125, "training_acc": 53.0, "val_loss": 1599.57275390625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5411.112991333008, "training_acc": 53.0, "val_loss": 203.96099090576172, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1507.5349502563477, "training_acc": 59.0, "val_loss": 1533.266830444336, "val_acc": 48.0}
{"epoch": 7, "training_loss": 6287.682769775391, "training_acc": 47.0, "val_loss": 1458.5800170898438, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4989.709747314453, "training_acc": 47.0, "val_loss": 96.19985818862915, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1212.5873489379883, "training_acc": 58.0, "val_loss": 1339.1342163085938, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5565.397216796875, "training_acc": 53.0, "val_loss": 1419.4255828857422, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4958.713272094727, "training_acc": 53.0, "val_loss": 396.5464115142822, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1832.4219970703125, "training_acc": 45.0, "val_loss": 901.7317771911621, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3557.126174926758, "training_acc": 47.0, "val_loss": 703.5406112670898, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1944.765697479248, "training_acc": 46.0, "val_loss": 549.0372657775879, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2547.977409362793, "training_acc": 53.0, "val_loss": 987.9935264587402, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3614.9223022460938, "training_acc": 53.0, "val_loss": 415.64440727233887, "val_acc": 52.0}
{"epoch": 17, "training_loss": 977.2578067779541, "training_acc": 59.0, "val_loss": 558.8813304901123, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2307.1002197265625, "training_acc": 47.0, "val_loss": 318.09020042419434, "val_acc": 48.0}
{"epoch": 19, "training_loss": 964.0288639068604, "training_acc": 52.0, "val_loss": 445.3190326690674, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1723.0952377319336, "training_acc": 53.0, "val_loss": 123.21803569793701, "val_acc": 52.0}
{"epoch": 21, "training_loss": 604.3006896972656, "training_acc": 63.0, "val_loss": 594.830846786499, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2250.151123046875, "training_acc": 47.0, "val_loss": 114.99122381210327, "val_acc": 48.0}
{"epoch": 23, "training_loss": 788.7901420593262, "training_acc": 53.0, "val_loss": 728.4863948822021, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2785.447555541992, "training_acc": 53.0, "val_loss": 495.4373359680176, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1281.6545705795288, "training_acc": 51.0, "val_loss": 505.318546295166, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2370.2398681640625, "training_acc": 47.0, "val_loss": 508.3596706390381, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1462.1965265274048, "training_acc": 51.0, "val_loss": 458.2487106323242, "val_acc": 52.0}
