"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3651.2539558410645, "training_acc": 46.0, "val_loss": 753.7862777709961, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3661.2157135009766, "training_acc": 53.0, "val_loss": 1952.5821685791016, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7348.200836181641, "training_acc": 47.0, "val_loss": 541.3336277008057, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2560.381996154785, "training_acc": 51.0, "val_loss": 1425.7795333862305, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5417.526916503906, "training_acc": 53.0, "val_loss": 1272.2518920898438, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3776.356071472168, "training_acc": 53.0, "val_loss": 221.18656635284424, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2037.7416381835938, "training_acc": 47.0, "val_loss": 651.8187046051025, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2208.9144287109375, "training_acc": 47.0, "val_loss": 472.09062576293945, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1841.2032623291016, "training_acc": 53.0, "val_loss": 818.4738159179688, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2657.8601837158203, "training_acc": 53.0, "val_loss": 103.1975269317627, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1077.2561340332031, "training_acc": 49.0, "val_loss": 771.4815616607666, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2963.9534225463867, "training_acc": 47.0, "val_loss": 179.8450469970703, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1075.3115158081055, "training_acc": 49.0, "val_loss": 778.319501876831, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2982.402313232422, "training_acc": 53.0, "val_loss": 573.2562065124512, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1512.494194984436, "training_acc": 53.0, "val_loss": 557.4748516082764, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2663.2000122070312, "training_acc": 47.0, "val_loss": 733.2352638244629, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2339.52730178833, "training_acc": 47.0, "val_loss": 291.18597507476807, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1405.2623672485352, "training_acc": 53.0, "val_loss": 601.8893718719482, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1953.353952407837, "training_acc": 53.0, "val_loss": 94.70284581184387, "val_acc": 52.0}
{"epoch": 19, "training_loss": 532.3161506652832, "training_acc": 54.0, "val_loss": 95.2485203742981, "val_acc": 48.0}
{"epoch": 20, "training_loss": 698.6805229187012, "training_acc": 47.0, "val_loss": 321.2999105453491, "val_acc": 52.0}
{"epoch": 21, "training_loss": 758.1022615432739, "training_acc": 60.0, "val_loss": 254.4297218322754, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1104.5977745056152, "training_acc": 47.0, "val_loss": 57.64362812042236, "val_acc": 40.0}
{"epoch": 23, "training_loss": 643.7196235656738, "training_acc": 48.0, "val_loss": 465.1556968688965, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1357.8228034973145, "training_acc": 52.0, "val_loss": 75.25874376296997, "val_acc": 40.0}
{"epoch": 25, "training_loss": 625.9443397521973, "training_acc": 57.0, "val_loss": 107.56465196609497, "val_acc": 44.0}
{"epoch": 26, "training_loss": 419.5433712005615, "training_acc": 59.0, "val_loss": 334.2918872833252, "val_acc": 52.0}
{"epoch": 27, "training_loss": 775.4432010650635, "training_acc": 54.0, "val_loss": 193.1325912475586, "val_acc": 48.0}
{"epoch": 28, "training_loss": 940.708324432373, "training_acc": 47.0, "val_loss": 57.64741897583008, "val_acc": 48.0}
{"epoch": 29, "training_loss": 334.0056610107422, "training_acc": 66.0, "val_loss": 358.05840492248535, "val_acc": 52.0}
{"epoch": 30, "training_loss": 915.7282104492188, "training_acc": 51.0, "val_loss": 189.93264436721802, "val_acc": 48.0}
{"epoch": 31, "training_loss": 975.6684761047363, "training_acc": 47.0, "val_loss": 64.98345136642456, "val_acc": 56.0}
{"epoch": 32, "training_loss": 602.8497886657715, "training_acc": 56.0, "val_loss": 399.8880624771118, "val_acc": 52.0}
{"epoch": 33, "training_loss": 879.0845737457275, "training_acc": 52.0, "val_loss": 244.52672004699707, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1304.2546463012695, "training_acc": 47.0, "val_loss": 157.52673149108887, "val_acc": 48.0}
{"epoch": 35, "training_loss": 806.536584854126, "training_acc": 48.0, "val_loss": 396.70214653015137, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1029.2033882141113, "training_acc": 55.0, "val_loss": 45.83444893360138, "val_acc": 52.0}
{"epoch": 37, "training_loss": 598.5636940002441, "training_acc": 55.0, "val_loss": 85.99006533622742, "val_acc": 56.0}
{"epoch": 38, "training_loss": 383.10304260253906, "training_acc": 57.0, "val_loss": 161.88452243804932, "val_acc": 56.0}
{"epoch": 39, "training_loss": 449.04490089416504, "training_acc": 53.0, "val_loss": 53.334760665893555, "val_acc": 44.0}
{"epoch": 40, "training_loss": 380.7480239868164, "training_acc": 56.0, "val_loss": 187.9438877105713, "val_acc": 52.0}
{"epoch": 41, "training_loss": 447.2412419319153, "training_acc": 60.0, "val_loss": 114.65613842010498, "val_acc": 48.0}
{"epoch": 42, "training_loss": 305.1508173942566, "training_acc": 57.0, "val_loss": 186.80862188339233, "val_acc": 52.0}
{"epoch": 43, "training_loss": 472.809045791626, "training_acc": 53.0, "val_loss": 213.38903903961182, "val_acc": 48.0}
{"epoch": 44, "training_loss": 771.7960815429688, "training_acc": 48.0, "val_loss": 70.70994973182678, "val_acc": 60.0}
{"epoch": 45, "training_loss": 257.03959560394287, "training_acc": 61.0, "val_loss": 28.654560446739197, "val_acc": 60.0}
{"epoch": 46, "training_loss": 144.04005002975464, "training_acc": 70.0, "val_loss": 41.82627499103546, "val_acc": 64.0}
{"epoch": 47, "training_loss": 130.3401665687561, "training_acc": 68.0, "val_loss": 25.008830428123474, "val_acc": 48.0}
{"epoch": 48, "training_loss": 136.55635595321655, "training_acc": 68.0, "val_loss": 93.79984736442566, "val_acc": 56.0}
{"epoch": 49, "training_loss": 186.9255132675171, "training_acc": 58.0, "val_loss": 83.18510055541992, "val_acc": 56.0}
{"epoch": 50, "training_loss": 181.0431866645813, "training_acc": 58.0, "val_loss": 61.66367530822754, "val_acc": 56.0}
{"epoch": 51, "training_loss": 117.9150230884552, "training_acc": 68.0, "val_loss": 32.86013603210449, "val_acc": 56.0}
{"epoch": 52, "training_loss": 256.24474143981934, "training_acc": 54.0, "val_loss": 37.64182925224304, "val_acc": 64.0}
{"epoch": 53, "training_loss": 368.98134422302246, "training_acc": 63.0, "val_loss": 29.166558384895325, "val_acc": 52.0}
{"epoch": 54, "training_loss": 379.58818435668945, "training_acc": 56.0, "val_loss": 190.19646644592285, "val_acc": 52.0}
{"epoch": 55, "training_loss": 600.899658203125, "training_acc": 47.0, "val_loss": 76.2890636920929, "val_acc": 48.0}
{"epoch": 56, "training_loss": 358.9870414733887, "training_acc": 58.0, "val_loss": 272.1719980239868, "val_acc": 52.0}
{"epoch": 57, "training_loss": 620.1163907051086, "training_acc": 56.0, "val_loss": 227.53725051879883, "val_acc": 48.0}
{"epoch": 58, "training_loss": 896.7488288879395, "training_acc": 47.0, "val_loss": 182.90010690689087, "val_acc": 52.0}
{"epoch": 59, "training_loss": 673.4356880187988, "training_acc": 53.0, "val_loss": 51.800888776779175, "val_acc": 56.0}
{"epoch": 60, "training_loss": 264.6279830932617, "training_acc": 63.0, "val_loss": 191.60279035568237, "val_acc": 48.0}
{"epoch": 61, "training_loss": 589.7454671859741, "training_acc": 51.0, "val_loss": 139.92702960968018, "val_acc": 52.0}
{"epoch": 62, "training_loss": 368.37613677978516, "training_acc": 55.0, "val_loss": 48.64479601383209, "val_acc": 44.0}
{"epoch": 63, "training_loss": 192.27860641479492, "training_acc": 67.0, "val_loss": 177.87795066833496, "val_acc": 52.0}
{"epoch": 64, "training_loss": 436.7175416946411, "training_acc": 50.0, "val_loss": 43.32159757614136, "val_acc": 44.0}
{"epoch": 65, "training_loss": 311.68492698669434, "training_acc": 57.0, "val_loss": 108.60134363174438, "val_acc": 56.0}
{"epoch": 66, "training_loss": 526.1416358947754, "training_acc": 48.0, "val_loss": 138.53962421417236, "val_acc": 48.0}
