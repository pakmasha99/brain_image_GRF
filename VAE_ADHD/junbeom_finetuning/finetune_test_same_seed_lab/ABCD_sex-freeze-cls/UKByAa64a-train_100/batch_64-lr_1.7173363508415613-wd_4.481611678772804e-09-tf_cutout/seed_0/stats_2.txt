"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3561.528350830078, "training_acc": 53.0, "val_loss": 674.2542743682861, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3507.4979553222656, "training_acc": 55.0, "val_loss": 2112.1810913085938, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7902.966064453125, "training_acc": 47.0, "val_loss": 719.6817398071289, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2517.8410568237305, "training_acc": 53.0, "val_loss": 1244.0292358398438, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4855.962661743164, "training_acc": 53.0, "val_loss": 1061.8173599243164, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3257.6903762817383, "training_acc": 53.0, "val_loss": 498.3142375946045, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2636.614700317383, "training_acc": 47.0, "val_loss": 820.8633422851562, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2799.5411529541016, "training_acc": 47.0, "val_loss": 331.39235973358154, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1594.0515060424805, "training_acc": 53.0, "val_loss": 620.6408977508545, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1861.3804893493652, "training_acc": 53.0, "val_loss": 245.0289249420166, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1270.5476722717285, "training_acc": 47.0, "val_loss": 279.58831787109375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 965.3927364349365, "training_acc": 47.0, "val_loss": 273.5598087310791, "val_acc": 52.0}
{"epoch": 12, "training_loss": 737.5041780471802, "training_acc": 52.0, "val_loss": 320.0188159942627, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1246.9786186218262, "training_acc": 47.0, "val_loss": 95.9154486656189, "val_acc": 44.0}
{"epoch": 14, "training_loss": 699.3257331848145, "training_acc": 51.0, "val_loss": 410.0862503051758, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1280.4573402404785, "training_acc": 53.0, "val_loss": 191.97614192962646, "val_acc": 48.0}
{"epoch": 16, "training_loss": 812.5642852783203, "training_acc": 47.0, "val_loss": 120.11258602142334, "val_acc": 44.0}
{"epoch": 17, "training_loss": 578.4618530273438, "training_acc": 56.0, "val_loss": 311.159873008728, "val_acc": 52.0}
{"epoch": 18, "training_loss": 882.8119201660156, "training_acc": 57.0, "val_loss": 249.74699020385742, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1044.8226432800293, "training_acc": 47.0, "val_loss": 44.91186439990997, "val_acc": 56.0}
{"epoch": 20, "training_loss": 585.5124702453613, "training_acc": 56.0, "val_loss": 496.0441589355469, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1609.8361854553223, "training_acc": 53.0, "val_loss": 43.12918782234192, "val_acc": 52.0}
{"epoch": 22, "training_loss": 486.61599349975586, "training_acc": 54.0, "val_loss": 94.88668441772461, "val_acc": 48.0}
{"epoch": 23, "training_loss": 638.9419403076172, "training_acc": 49.0, "val_loss": 374.4253396987915, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1055.807991027832, "training_acc": 53.0, "val_loss": 208.3348512649536, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1058.8641319274902, "training_acc": 47.0, "val_loss": 132.9506754875183, "val_acc": 48.0}
{"epoch": 26, "training_loss": 698.7135314941406, "training_acc": 50.0, "val_loss": 413.79971504211426, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1152.8239078521729, "training_acc": 53.0, "val_loss": 90.93573689460754, "val_acc": 48.0}
{"epoch": 28, "training_loss": 540.4941253662109, "training_acc": 48.0, "val_loss": 109.55439805984497, "val_acc": 52.0}
{"epoch": 29, "training_loss": 311.46380615234375, "training_acc": 56.0, "val_loss": 34.17472839355469, "val_acc": 52.0}
{"epoch": 30, "training_loss": 249.70290851593018, "training_acc": 54.0, "val_loss": 212.28010654449463, "val_acc": 52.0}
{"epoch": 31, "training_loss": 571.754168510437, "training_acc": 54.0, "val_loss": 81.20604753494263, "val_acc": 44.0}
{"epoch": 32, "training_loss": 306.4479203224182, "training_acc": 53.0, "val_loss": 164.97914791107178, "val_acc": 52.0}
{"epoch": 33, "training_loss": 419.371036529541, "training_acc": 53.0, "val_loss": 115.68015813827515, "val_acc": 48.0}
{"epoch": 34, "training_loss": 336.35432624816895, "training_acc": 56.0, "val_loss": 144.34003829956055, "val_acc": 52.0}
{"epoch": 35, "training_loss": 307.2826175689697, "training_acc": 53.0, "val_loss": 34.92478132247925, "val_acc": 56.0}
{"epoch": 36, "training_loss": 164.28267192840576, "training_acc": 56.0, "val_loss": 32.380881905555725, "val_acc": 56.0}
{"epoch": 37, "training_loss": 140.90149116516113, "training_acc": 68.0, "val_loss": 169.55727338790894, "val_acc": 52.0}
{"epoch": 38, "training_loss": 327.6296076774597, "training_acc": 55.0, "val_loss": 31.99915885925293, "val_acc": 48.0}
{"epoch": 39, "training_loss": 103.88246440887451, "training_acc": 68.0, "val_loss": 92.6927924156189, "val_acc": 52.0}
{"epoch": 40, "training_loss": 93.2055242061615, "training_acc": 74.0, "val_loss": 43.86814832687378, "val_acc": 52.0}
{"epoch": 41, "training_loss": 294.00652980804443, "training_acc": 53.0, "val_loss": 71.39399647712708, "val_acc": 56.0}
{"epoch": 42, "training_loss": 372.5154342651367, "training_acc": 56.0, "val_loss": 55.537986755371094, "val_acc": 48.0}
{"epoch": 43, "training_loss": 493.05091094970703, "training_acc": 52.0, "val_loss": 331.88652992248535, "val_acc": 52.0}
{"epoch": 44, "training_loss": 765.5167937278748, "training_acc": 57.0, "val_loss": 336.0673666000366, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1426.3949966430664, "training_acc": 47.0, "val_loss": 153.2181978225708, "val_acc": 44.0}
{"epoch": 46, "training_loss": 840.4020156860352, "training_acc": 50.0, "val_loss": 558.4038734436035, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1828.1527938842773, "training_acc": 53.0, "val_loss": 122.92052507400513, "val_acc": 52.0}
{"epoch": 48, "training_loss": 696.8924942016602, "training_acc": 60.0, "val_loss": 644.4239139556885, "val_acc": 48.0}
{"epoch": 49, "training_loss": 2350.4925994873047, "training_acc": 46.0, "val_loss": 75.05967617034912, "val_acc": 52.0}
{"epoch": 50, "training_loss": 611.8428077697754, "training_acc": 62.0, "val_loss": 645.562219619751, "val_acc": 52.0}
{"epoch": 51, "training_loss": 2239.447883605957, "training_acc": 53.0, "val_loss": 198.2125759124756, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1069.328742980957, "training_acc": 49.0, "val_loss": 650.3084659576416, "val_acc": 48.0}
{"epoch": 53, "training_loss": 2277.4967498779297, "training_acc": 47.0, "val_loss": 83.86470675468445, "val_acc": 48.0}
{"epoch": 54, "training_loss": 660.9122467041016, "training_acc": 59.0, "val_loss": 612.7615928649902, "val_acc": 52.0}
{"epoch": 55, "training_loss": 2044.984619140625, "training_acc": 53.0, "val_loss": 172.959566116333, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1007.0362319946289, "training_acc": 46.0, "val_loss": 613.8528823852539, "val_acc": 48.0}
{"epoch": 57, "training_loss": 2284.7522773742676, "training_acc": 47.0, "val_loss": 44.690343737602234, "val_acc": 64.0}
