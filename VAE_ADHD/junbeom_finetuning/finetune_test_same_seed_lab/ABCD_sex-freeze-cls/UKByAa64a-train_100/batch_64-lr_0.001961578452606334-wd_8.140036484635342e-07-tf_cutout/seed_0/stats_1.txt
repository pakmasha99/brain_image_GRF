"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.68558120727539, "training_acc": 46.0, "val_loss": 17.30579286813736, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.20355772972107, "training_acc": 53.0, "val_loss": 17.27520078420639, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.4795229434967, "training_acc": 46.0, "val_loss": 17.291760444641113, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10895538330078, "training_acc": 60.0, "val_loss": 17.27062612771988, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15395712852478, "training_acc": 53.0, "val_loss": 17.31880158185959, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.37883758544922, "training_acc": 53.0, "val_loss": 17.331375181674957, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.3540267944336, "training_acc": 53.0, "val_loss": 17.280536890029907, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.03600454330444, "training_acc": 53.0, "val_loss": 17.274557054042816, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.99716687202454, "training_acc": 53.0, "val_loss": 17.272308468818665, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.92219996452332, "training_acc": 53.0, "val_loss": 17.285919189453125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.79141283035278, "training_acc": 53.0, "val_loss": 17.303776741027832, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.05292582511902, "training_acc": 53.0, "val_loss": 17.31112003326416, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09749412536621, "training_acc": 53.0, "val_loss": 17.274612188339233, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.81455206871033, "training_acc": 53.0, "val_loss": 17.252877354621887, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.8774209022522, "training_acc": 52.0, "val_loss": 17.256617546081543, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.90441298484802, "training_acc": 60.0, "val_loss": 17.264796793460846, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.69382929801941, "training_acc": 61.0, "val_loss": 17.249862849712372, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.88580012321472, "training_acc": 53.0, "val_loss": 17.24066436290741, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.91354322433472, "training_acc": 54.0, "val_loss": 17.247876524925232, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.66408634185791, "training_acc": 53.0, "val_loss": 17.304357886314392, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.68631100654602, "training_acc": 53.0, "val_loss": 17.322063446044922, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.64614486694336, "training_acc": 53.0, "val_loss": 17.27628856897354, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.58179974555969, "training_acc": 54.0, "val_loss": 17.245054244995117, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.37852168083191, "training_acc": 53.0, "val_loss": 17.24616140127182, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.50737810134888, "training_acc": 56.0, "val_loss": 17.252519726753235, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.31600666046143, "training_acc": 56.0, "val_loss": 17.24856197834015, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.44603705406189, "training_acc": 59.0, "val_loss": 17.24630743265152, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.61344027519226, "training_acc": 55.0, "val_loss": 17.26943552494049, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.44100165367126, "training_acc": 54.0, "val_loss": 17.294414341449738, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.7027153968811, "training_acc": 53.0, "val_loss": 17.289093136787415, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.91719889640808, "training_acc": 53.0, "val_loss": 17.299170792102814, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.2076723575592, "training_acc": 53.0, "val_loss": 17.29399859905243, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.55070185661316, "training_acc": 53.0, "val_loss": 17.285548150539398, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.42063856124878, "training_acc": 52.0, "val_loss": 17.262426018714905, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.65705227851868, "training_acc": 52.0, "val_loss": 17.245693504810333, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.77221369743347, "training_acc": 57.0, "val_loss": 17.26735532283783, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.44301342964172, "training_acc": 62.0, "val_loss": 17.29584038257599, "val_acc": 52.0}
