"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 565.8703994750977, "training_acc": 49.0, "val_loss": 134.4563126564026, "val_acc": 52.0}
{"epoch": 1, "training_loss": 614.1317176818848, "training_acc": 49.0, "val_loss": 241.8341875076294, "val_acc": 48.0}
{"epoch": 2, "training_loss": 872.0134963989258, "training_acc": 47.0, "val_loss": 20.296166837215424, "val_acc": 44.0}
{"epoch": 3, "training_loss": 223.6868667602539, "training_acc": 56.0, "val_loss": 229.14674282073975, "val_acc": 52.0}
{"epoch": 4, "training_loss": 813.5892143249512, "training_acc": 53.0, "val_loss": 153.9431929588318, "val_acc": 52.0}
{"epoch": 5, "training_loss": 367.4532775878906, "training_acc": 54.0, "val_loss": 108.79250764846802, "val_acc": 48.0}
{"epoch": 6, "training_loss": 566.2335834503174, "training_acc": 47.0, "val_loss": 162.5804305076599, "val_acc": 48.0}
{"epoch": 7, "training_loss": 571.51487159729, "training_acc": 47.0, "val_loss": 33.38945806026459, "val_acc": 52.0}
{"epoch": 8, "training_loss": 153.3132781982422, "training_acc": 58.0, "val_loss": 143.0500030517578, "val_acc": 52.0}
{"epoch": 9, "training_loss": 452.8747615814209, "training_acc": 53.0, "val_loss": 69.83146667480469, "val_acc": 52.0}
{"epoch": 10, "training_loss": 207.0470576286316, "training_acc": 46.0, "val_loss": 80.38108348846436, "val_acc": 48.0}
{"epoch": 11, "training_loss": 345.91328144073486, "training_acc": 47.0, "val_loss": 23.943832516670227, "val_acc": 40.0}
{"epoch": 12, "training_loss": 190.70492267608643, "training_acc": 42.0, "val_loss": 94.78477239608765, "val_acc": 52.0}
{"epoch": 13, "training_loss": 241.11590576171875, "training_acc": 53.0, "val_loss": 21.70344442129135, "val_acc": 40.0}
{"epoch": 14, "training_loss": 118.3366470336914, "training_acc": 52.0, "val_loss": 40.14902412891388, "val_acc": 48.0}
{"epoch": 15, "training_loss": 157.77987003326416, "training_acc": 50.0, "val_loss": 51.79092884063721, "val_acc": 52.0}
{"epoch": 16, "training_loss": 153.9422378540039, "training_acc": 53.0, "val_loss": 19.373314082622528, "val_acc": 48.0}
{"epoch": 17, "training_loss": 112.90130662918091, "training_acc": 57.0, "val_loss": 32.38667547702789, "val_acc": 48.0}
{"epoch": 18, "training_loss": 122.10638737678528, "training_acc": 53.0, "val_loss": 47.715285420417786, "val_acc": 52.0}
{"epoch": 19, "training_loss": 139.3545699119568, "training_acc": 53.0, "val_loss": 18.394966423511505, "val_acc": 56.0}
{"epoch": 20, "training_loss": 83.28030371665955, "training_acc": 56.0, "val_loss": 18.378722667694092, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.57764744758606, "training_acc": 58.0, "val_loss": 31.74838125705719, "val_acc": 52.0}
{"epoch": 22, "training_loss": 78.98196864128113, "training_acc": 64.0, "val_loss": 19.230449199676514, "val_acc": 48.0}
{"epoch": 23, "training_loss": 75.65877413749695, "training_acc": 54.0, "val_loss": 23.099735379219055, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.7045738697052, "training_acc": 57.0, "val_loss": 19.132675230503082, "val_acc": 44.0}
{"epoch": 25, "training_loss": 73.83610129356384, "training_acc": 60.0, "val_loss": 29.95598018169403, "val_acc": 52.0}
{"epoch": 26, "training_loss": 80.99423336982727, "training_acc": 55.0, "val_loss": 21.077220141887665, "val_acc": 52.0}
{"epoch": 27, "training_loss": 65.80604243278503, "training_acc": 65.0, "val_loss": 19.71580535173416, "val_acc": 56.0}
{"epoch": 28, "training_loss": 77.60300374031067, "training_acc": 54.0, "val_loss": 21.08251303434372, "val_acc": 56.0}
{"epoch": 29, "training_loss": 59.010841369628906, "training_acc": 71.0, "val_loss": 21.28928303718567, "val_acc": 56.0}
{"epoch": 30, "training_loss": 60.023083448410034, "training_acc": 65.0, "val_loss": 24.414847791194916, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.24986934661865, "training_acc": 69.0, "val_loss": 20.058634877204895, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.80389523506165, "training_acc": 64.0, "val_loss": 21.77477926015854, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.74067878723145, "training_acc": 63.0, "val_loss": 18.314701318740845, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.7903892993927, "training_acc": 59.0, "val_loss": 18.473748862743378, "val_acc": 52.0}
{"epoch": 35, "training_loss": 55.88467979431152, "training_acc": 75.0, "val_loss": 18.654540181159973, "val_acc": 36.0}
{"epoch": 36, "training_loss": 62.0950288772583, "training_acc": 64.0, "val_loss": 26.11592411994934, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.40842413902283, "training_acc": 55.0, "val_loss": 18.101829290390015, "val_acc": 48.0}
{"epoch": 38, "training_loss": 60.56025147438049, "training_acc": 64.0, "val_loss": 19.105693697929382, "val_acc": 52.0}
{"epoch": 39, "training_loss": 58.27836060523987, "training_acc": 70.0, "val_loss": 19.83300745487213, "val_acc": 52.0}
{"epoch": 40, "training_loss": 56.71561312675476, "training_acc": 68.0, "val_loss": 19.30036097764969, "val_acc": 52.0}
{"epoch": 41, "training_loss": 60.73733830451965, "training_acc": 66.0, "val_loss": 19.21369582414627, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.112446784973145, "training_acc": 65.0, "val_loss": 17.975112795829773, "val_acc": 52.0}
{"epoch": 43, "training_loss": 56.42701244354248, "training_acc": 77.0, "val_loss": 17.980235815048218, "val_acc": 52.0}
{"epoch": 44, "training_loss": 60.03716015815735, "training_acc": 69.0, "val_loss": 17.38141179084778, "val_acc": 40.0}
{"epoch": 45, "training_loss": 62.901495695114136, "training_acc": 62.0, "val_loss": 26.91342532634735, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.17305207252502, "training_acc": 57.0, "val_loss": 21.328838169574738, "val_acc": 52.0}
{"epoch": 47, "training_loss": 73.3670666217804, "training_acc": 55.0, "val_loss": 28.25888693332672, "val_acc": 52.0}
{"epoch": 48, "training_loss": 80.3746223449707, "training_acc": 60.0, "val_loss": 17.92512983083725, "val_acc": 68.0}
{"epoch": 49, "training_loss": 65.0846164226532, "training_acc": 63.0, "val_loss": 18.652476370334625, "val_acc": 52.0}
{"epoch": 50, "training_loss": 65.8114869594574, "training_acc": 59.0, "val_loss": 20.98543643951416, "val_acc": 52.0}
{"epoch": 51, "training_loss": 58.34370732307434, "training_acc": 66.0, "val_loss": 18.79028230905533, "val_acc": 52.0}
{"epoch": 52, "training_loss": 70.04077219963074, "training_acc": 55.0, "val_loss": 18.203306198120117, "val_acc": 52.0}
{"epoch": 53, "training_loss": 55.65693998336792, "training_acc": 71.0, "val_loss": 20.81836462020874, "val_acc": 52.0}
{"epoch": 54, "training_loss": 56.448588132858276, "training_acc": 72.0, "val_loss": 18.55878382921219, "val_acc": 48.0}
{"epoch": 55, "training_loss": 58.17906665802002, "training_acc": 70.0, "val_loss": 21.256597340106964, "val_acc": 56.0}
{"epoch": 56, "training_loss": 74.39720940589905, "training_acc": 54.0, "val_loss": 21.779879927635193, "val_acc": 52.0}
{"epoch": 57, "training_loss": 59.701213359832764, "training_acc": 67.0, "val_loss": 17.376521229743958, "val_acc": 52.0}
{"epoch": 58, "training_loss": 58.04441237449646, "training_acc": 75.0, "val_loss": 17.842334508895874, "val_acc": 52.0}
{"epoch": 59, "training_loss": 62.410505533218384, "training_acc": 65.0, "val_loss": 26.764124631881714, "val_acc": 52.0}
{"epoch": 60, "training_loss": 81.09407138824463, "training_acc": 55.0, "val_loss": 37.7393901348114, "val_acc": 48.0}
{"epoch": 61, "training_loss": 138.76194143295288, "training_acc": 47.0, "val_loss": 32.598745822906494, "val_acc": 52.0}
{"epoch": 62, "training_loss": 133.61746978759766, "training_acc": 53.0, "val_loss": 16.448889672756195, "val_acc": 72.0}
{"epoch": 63, "training_loss": 101.71518898010254, "training_acc": 52.0, "val_loss": 15.758739411830902, "val_acc": 56.0}
{"epoch": 64, "training_loss": 86.825674533844, "training_acc": 68.0, "val_loss": 26.725852489471436, "val_acc": 52.0}
{"epoch": 65, "training_loss": 84.21998643875122, "training_acc": 54.0, "val_loss": 27.777662873268127, "val_acc": 48.0}
{"epoch": 66, "training_loss": 96.02348685264587, "training_acc": 53.0, "val_loss": 40.41414558887482, "val_acc": 52.0}
{"epoch": 67, "training_loss": 99.5477614402771, "training_acc": 57.0, "val_loss": 25.009211897850037, "val_acc": 52.0}
{"epoch": 68, "training_loss": 88.51450538635254, "training_acc": 58.0, "val_loss": 32.228270173072815, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.1845965385437, "training_acc": 64.0, "val_loss": 18.182605504989624, "val_acc": 52.0}
{"epoch": 70, "training_loss": 56.91225814819336, "training_acc": 70.0, "val_loss": 26.098009943962097, "val_acc": 52.0}
{"epoch": 71, "training_loss": 52.12915635108948, "training_acc": 75.0, "val_loss": 24.237632751464844, "val_acc": 52.0}
{"epoch": 72, "training_loss": 83.03818202018738, "training_acc": 55.0, "val_loss": 46.04690372943878, "val_acc": 52.0}
{"epoch": 73, "training_loss": 121.92329263687134, "training_acc": 53.0, "val_loss": 25.699687004089355, "val_acc": 52.0}
{"epoch": 74, "training_loss": 100.87755918502808, "training_acc": 47.0, "val_loss": 25.36325454711914, "val_acc": 52.0}
{"epoch": 75, "training_loss": 76.74770617485046, "training_acc": 59.0, "val_loss": 18.125611543655396, "val_acc": 52.0}
{"epoch": 76, "training_loss": 57.2386417388916, "training_acc": 68.0, "val_loss": 19.549942016601562, "val_acc": 52.0}
{"epoch": 77, "training_loss": 62.99493861198425, "training_acc": 66.0, "val_loss": 23.25315773487091, "val_acc": 52.0}
{"epoch": 78, "training_loss": 56.16298317909241, "training_acc": 69.0, "val_loss": 18.401196599006653, "val_acc": 44.0}
{"epoch": 79, "training_loss": 66.37062883377075, "training_acc": 63.0, "val_loss": 24.100105464458466, "val_acc": 52.0}
{"epoch": 80, "training_loss": 53.39362072944641, "training_acc": 71.0, "val_loss": 17.64805167913437, "val_acc": 64.0}
{"epoch": 81, "training_loss": 60.87458944320679, "training_acc": 61.0, "val_loss": 25.963851809501648, "val_acc": 52.0}
{"epoch": 82, "training_loss": 60.42776894569397, "training_acc": 64.0, "val_loss": 18.13899725675583, "val_acc": 56.0}
