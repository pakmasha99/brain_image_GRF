"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 587.130615234375, "training_acc": 46.0, "val_loss": 113.3055329322815, "val_acc": 52.0}
{"epoch": 1, "training_loss": 551.1315879821777, "training_acc": 53.0, "val_loss": 293.8514232635498, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1105.4712295532227, "training_acc": 47.0, "val_loss": 81.47929310798645, "val_acc": 48.0}
{"epoch": 3, "training_loss": 385.01898193359375, "training_acc": 51.0, "val_loss": 214.51361179351807, "val_acc": 52.0}
{"epoch": 4, "training_loss": 815.7014999389648, "training_acc": 53.0, "val_loss": 191.40924215316772, "val_acc": 52.0}
{"epoch": 5, "training_loss": 568.7472629547119, "training_acc": 53.0, "val_loss": 35.141173005104065, "val_acc": 48.0}
{"epoch": 6, "training_loss": 318.0692729949951, "training_acc": 47.0, "val_loss": 107.7277660369873, "val_acc": 48.0}
{"epoch": 7, "training_loss": 374.32060718536377, "training_acc": 47.0, "val_loss": 55.78169822692871, "val_acc": 52.0}
{"epoch": 8, "training_loss": 221.56439590454102, "training_acc": 53.0, "val_loss": 104.39902544021606, "val_acc": 52.0}
{"epoch": 9, "training_loss": 328.1206908226013, "training_acc": 53.0, "val_loss": 18.13332736492157, "val_acc": 56.0}
{"epoch": 10, "training_loss": 143.1872444152832, "training_acc": 50.0, "val_loss": 45.96457481384277, "val_acc": 48.0}
{"epoch": 11, "training_loss": 167.98853182792664, "training_acc": 45.0, "val_loss": 45.33281624317169, "val_acc": 52.0}
{"epoch": 12, "training_loss": 146.25906610488892, "training_acc": 53.0, "val_loss": 18.284286558628082, "val_acc": 52.0}
{"epoch": 13, "training_loss": 84.46060681343079, "training_acc": 52.0, "val_loss": 19.819791615009308, "val_acc": 40.0}
{"epoch": 14, "training_loss": 77.11118268966675, "training_acc": 56.0, "val_loss": 31.004849076271057, "val_acc": 52.0}
{"epoch": 15, "training_loss": 91.53965425491333, "training_acc": 56.0, "val_loss": 21.429350972175598, "val_acc": 52.0}
{"epoch": 16, "training_loss": 84.67989087104797, "training_acc": 52.0, "val_loss": 23.971180617809296, "val_acc": 52.0}
{"epoch": 17, "training_loss": 83.44939470291138, "training_acc": 54.0, "val_loss": 16.693156957626343, "val_acc": 64.0}
{"epoch": 18, "training_loss": 91.93079280853271, "training_acc": 47.0, "val_loss": 22.49848246574402, "val_acc": 52.0}
{"epoch": 19, "training_loss": 92.70150423049927, "training_acc": 56.0, "val_loss": 18.403933942317963, "val_acc": 56.0}
{"epoch": 20, "training_loss": 66.04646682739258, "training_acc": 63.0, "val_loss": 21.10501378774643, "val_acc": 48.0}
{"epoch": 21, "training_loss": 89.49446845054626, "training_acc": 51.0, "val_loss": 27.375736832618713, "val_acc": 52.0}
{"epoch": 22, "training_loss": 80.08231806755066, "training_acc": 60.0, "val_loss": 18.993622064590454, "val_acc": 44.0}
{"epoch": 23, "training_loss": 72.59228992462158, "training_acc": 55.0, "val_loss": 20.15366703271866, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.17980742454529, "training_acc": 61.0, "val_loss": 17.464742064476013, "val_acc": 60.0}
{"epoch": 25, "training_loss": 63.067298889160156, "training_acc": 61.0, "val_loss": 20.034462213516235, "val_acc": 52.0}
{"epoch": 26, "training_loss": 72.70140099525452, "training_acc": 53.0, "val_loss": 17.83183068037033, "val_acc": 56.0}
{"epoch": 27, "training_loss": 64.09528756141663, "training_acc": 59.0, "val_loss": 17.108726501464844, "val_acc": 64.0}
{"epoch": 28, "training_loss": 62.659590005874634, "training_acc": 62.0, "val_loss": 17.316636443138123, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.17652654647827, "training_acc": 65.0, "val_loss": 23.807573318481445, "val_acc": 52.0}
{"epoch": 30, "training_loss": 77.77324151992798, "training_acc": 56.0, "val_loss": 18.380603194236755, "val_acc": 48.0}
{"epoch": 31, "training_loss": 65.65450406074524, "training_acc": 60.0, "val_loss": 25.473278760910034, "val_acc": 52.0}
{"epoch": 32, "training_loss": 77.92216086387634, "training_acc": 56.0, "val_loss": 22.625845670700073, "val_acc": 48.0}
{"epoch": 33, "training_loss": 84.41618061065674, "training_acc": 46.0, "val_loss": 21.118296682834625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 74.90365266799927, "training_acc": 56.0, "val_loss": 28.604882955551147, "val_acc": 48.0}
{"epoch": 35, "training_loss": 107.16662907600403, "training_acc": 47.0, "val_loss": 30.254900455474854, "val_acc": 52.0}
{"epoch": 36, "training_loss": 101.51675653457642, "training_acc": 53.0, "val_loss": 19.71818506717682, "val_acc": 44.0}
