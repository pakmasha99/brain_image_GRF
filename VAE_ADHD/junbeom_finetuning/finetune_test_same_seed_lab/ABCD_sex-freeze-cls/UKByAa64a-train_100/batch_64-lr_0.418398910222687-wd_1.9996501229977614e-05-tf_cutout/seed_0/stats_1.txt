"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 923.157657623291, "training_acc": 46.0, "val_loss": 183.53915214538574, "val_acc": 52.0}
{"epoch": 1, "training_loss": 892.1994590759277, "training_acc": 53.0, "val_loss": 475.80084800720215, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1790.3115539550781, "training_acc": 47.0, "val_loss": 131.96805715560913, "val_acc": 48.0}
{"epoch": 3, "training_loss": 623.7093753814697, "training_acc": 51.0, "val_loss": 347.2851276397705, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1320.0546226501465, "training_acc": 53.0, "val_loss": 309.89990234375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 920.2494297027588, "training_acc": 53.0, "val_loss": 54.33540344238281, "val_acc": 48.0}
{"epoch": 6, "training_loss": 499.7243118286133, "training_acc": 47.0, "val_loss": 161.92257404327393, "val_acc": 48.0}
{"epoch": 7, "training_loss": 551.4678869247437, "training_acc": 47.0, "val_loss": 109.6969485282898, "val_acc": 52.0}
{"epoch": 8, "training_loss": 428.1256504058838, "training_acc": 53.0, "val_loss": 190.53568840026855, "val_acc": 52.0}
{"epoch": 9, "training_loss": 612.0921144485474, "training_acc": 53.0, "val_loss": 20.7357719540596, "val_acc": 56.0}
{"epoch": 10, "training_loss": 229.49807167053223, "training_acc": 51.0, "val_loss": 127.81327962875366, "val_acc": 48.0}
{"epoch": 11, "training_loss": 447.63127040863037, "training_acc": 47.0, "val_loss": 65.79099893569946, "val_acc": 52.0}
{"epoch": 12, "training_loss": 283.437424659729, "training_acc": 53.0, "val_loss": 84.46781635284424, "val_acc": 52.0}
{"epoch": 13, "training_loss": 188.72957277297974, "training_acc": 60.0, "val_loss": 90.29546976089478, "val_acc": 48.0}
{"epoch": 14, "training_loss": 391.78966522216797, "training_acc": 47.0, "val_loss": 34.036436676979065, "val_acc": 48.0}
{"epoch": 15, "training_loss": 187.04098224639893, "training_acc": 53.0, "val_loss": 136.4431619644165, "val_acc": 52.0}
{"epoch": 16, "training_loss": 462.7196636199951, "training_acc": 53.0, "val_loss": 41.653212904930115, "val_acc": 52.0}
{"epoch": 17, "training_loss": 209.77582359313965, "training_acc": 52.0, "val_loss": 123.41176271438599, "val_acc": 48.0}
{"epoch": 18, "training_loss": 473.1215019226074, "training_acc": 47.0, "val_loss": 25.934845209121704, "val_acc": 56.0}
{"epoch": 19, "training_loss": 204.03310203552246, "training_acc": 56.0, "val_loss": 119.39980983734131, "val_acc": 52.0}
{"epoch": 20, "training_loss": 314.1642303466797, "training_acc": 53.0, "val_loss": 41.036880016326904, "val_acc": 48.0}
{"epoch": 21, "training_loss": 250.03455066680908, "training_acc": 47.0, "val_loss": 44.05374825000763, "val_acc": 48.0}
{"epoch": 22, "training_loss": 186.89051866531372, "training_acc": 50.0, "val_loss": 86.59643530845642, "val_acc": 52.0}
{"epoch": 23, "training_loss": 246.33357620239258, "training_acc": 53.0, "val_loss": 24.178212881088257, "val_acc": 36.0}
{"epoch": 24, "training_loss": 153.96427154541016, "training_acc": 53.0, "val_loss": 20.677481591701508, "val_acc": 44.0}
{"epoch": 25, "training_loss": 97.29175806045532, "training_acc": 64.0, "val_loss": 49.961888790130615, "val_acc": 52.0}
{"epoch": 26, "training_loss": 160.52397799491882, "training_acc": 51.0, "val_loss": 26.528090238571167, "val_acc": 44.0}
{"epoch": 27, "training_loss": 108.51815509796143, "training_acc": 49.0, "val_loss": 27.98822522163391, "val_acc": 56.0}
{"epoch": 28, "training_loss": 81.34723711013794, "training_acc": 60.0, "val_loss": 24.512076377868652, "val_acc": 40.0}
{"epoch": 29, "training_loss": 87.55510115623474, "training_acc": 57.0, "val_loss": 51.95268988609314, "val_acc": 52.0}
{"epoch": 30, "training_loss": 162.18080377578735, "training_acc": 51.0, "val_loss": 22.978591918945312, "val_acc": 36.0}
{"epoch": 31, "training_loss": 113.22349977493286, "training_acc": 56.0, "val_loss": 28.98348867893219, "val_acc": 56.0}
{"epoch": 32, "training_loss": 106.33431768417358, "training_acc": 56.0, "val_loss": 19.64379847049713, "val_acc": 64.0}
{"epoch": 33, "training_loss": 78.00560474395752, "training_acc": 68.0, "val_loss": 18.370114266872406, "val_acc": 60.0}
{"epoch": 34, "training_loss": 135.76049900054932, "training_acc": 45.0, "val_loss": 25.262758135795593, "val_acc": 56.0}
{"epoch": 35, "training_loss": 118.1453185081482, "training_acc": 55.0, "val_loss": 23.66930842399597, "val_acc": 44.0}
{"epoch": 36, "training_loss": 131.24294996261597, "training_acc": 52.0, "val_loss": 54.29973006248474, "val_acc": 52.0}
{"epoch": 37, "training_loss": 123.72234010696411, "training_acc": 56.0, "val_loss": 28.143975138664246, "val_acc": 44.0}
{"epoch": 38, "training_loss": 105.55450224876404, "training_acc": 49.0, "val_loss": 35.83010137081146, "val_acc": 52.0}
{"epoch": 39, "training_loss": 94.51145648956299, "training_acc": 58.0, "val_loss": 26.367080211639404, "val_acc": 44.0}
{"epoch": 40, "training_loss": 82.4365463256836, "training_acc": 62.0, "val_loss": 26.556235551834106, "val_acc": 52.0}
{"epoch": 41, "training_loss": 77.56955146789551, "training_acc": 63.0, "val_loss": 22.612234950065613, "val_acc": 40.0}
{"epoch": 42, "training_loss": 66.53579711914062, "training_acc": 64.0, "val_loss": 27.102789282798767, "val_acc": 52.0}
{"epoch": 43, "training_loss": 73.21410727500916, "training_acc": 61.0, "val_loss": 38.25242817401886, "val_acc": 48.0}
{"epoch": 44, "training_loss": 109.23103284835815, "training_acc": 56.0, "val_loss": 27.82878577709198, "val_acc": 52.0}
{"epoch": 45, "training_loss": 89.45990490913391, "training_acc": 48.0, "val_loss": 16.583959758281708, "val_acc": 60.0}
{"epoch": 46, "training_loss": 67.92827582359314, "training_acc": 59.0, "val_loss": 21.66890650987625, "val_acc": 48.0}
{"epoch": 47, "training_loss": 78.70946836471558, "training_acc": 52.0, "val_loss": 32.79753923416138, "val_acc": 52.0}
{"epoch": 48, "training_loss": 96.7477240562439, "training_acc": 55.0, "val_loss": 21.857555210590363, "val_acc": 48.0}
{"epoch": 49, "training_loss": 65.00755763053894, "training_acc": 65.0, "val_loss": 26.891106367111206, "val_acc": 52.0}
{"epoch": 50, "training_loss": 91.764230966568, "training_acc": 48.0, "val_loss": 15.673565864562988, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.61759853363037, "training_acc": 74.0, "val_loss": 16.4659321308136, "val_acc": 64.0}
{"epoch": 52, "training_loss": 62.98187208175659, "training_acc": 67.0, "val_loss": 20.906002819538116, "val_acc": 56.0}
{"epoch": 53, "training_loss": 74.16885113716125, "training_acc": 55.0, "val_loss": 16.571879386901855, "val_acc": 56.0}
{"epoch": 54, "training_loss": 57.446507930755615, "training_acc": 69.0, "val_loss": 16.33688658475876, "val_acc": 64.0}
{"epoch": 55, "training_loss": 55.25419092178345, "training_acc": 66.0, "val_loss": 24.670705199241638, "val_acc": 52.0}
{"epoch": 56, "training_loss": 76.448655128479, "training_acc": 55.0, "val_loss": 18.884563446044922, "val_acc": 56.0}
{"epoch": 57, "training_loss": 55.62705612182617, "training_acc": 67.0, "val_loss": 17.47434437274933, "val_acc": 64.0}
{"epoch": 58, "training_loss": 57.61725473403931, "training_acc": 74.0, "val_loss": 19.224579632282257, "val_acc": 56.0}
{"epoch": 59, "training_loss": 63.683520555496216, "training_acc": 65.0, "val_loss": 16.540557146072388, "val_acc": 64.0}
{"epoch": 60, "training_loss": 87.94907236099243, "training_acc": 56.0, "val_loss": 27.632713317871094, "val_acc": 48.0}
{"epoch": 61, "training_loss": 89.29257917404175, "training_acc": 52.0, "val_loss": 44.144248962402344, "val_acc": 52.0}
{"epoch": 62, "training_loss": 116.84392523765564, "training_acc": 54.0, "val_loss": 44.18843388557434, "val_acc": 48.0}
{"epoch": 63, "training_loss": 168.50983238220215, "training_acc": 47.0, "val_loss": 71.06261253356934, "val_acc": 52.0}
{"epoch": 64, "training_loss": 249.10920810699463, "training_acc": 53.0, "val_loss": 47.844237089157104, "val_acc": 52.0}
{"epoch": 65, "training_loss": 180.51362800598145, "training_acc": 51.0, "val_loss": 63.70150446891785, "val_acc": 48.0}
{"epoch": 66, "training_loss": 199.4936602115631, "training_acc": 53.0, "val_loss": 79.67543005943298, "val_acc": 52.0}
{"epoch": 67, "training_loss": 246.914288520813, "training_acc": 55.0, "val_loss": 18.12480539083481, "val_acc": 68.0}
{"epoch": 68, "training_loss": 120.75588750839233, "training_acc": 52.0, "val_loss": 17.324981093406677, "val_acc": 56.0}
{"epoch": 69, "training_loss": 108.29043292999268, "training_acc": 66.0, "val_loss": 20.385272800922394, "val_acc": 56.0}
