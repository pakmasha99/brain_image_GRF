"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 960.077392578125, "training_acc": 48.0, "val_loss": 210.83202362060547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1045.9947624206543, "training_acc": 47.0, "val_loss": 399.09939765930176, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1458.704231262207, "training_acc": 47.0, "val_loss": 43.465495109558105, "val_acc": 48.0}
{"epoch": 3, "training_loss": 429.10915756225586, "training_acc": 51.0, "val_loss": 380.59229850769043, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1486.287239074707, "training_acc": 53.0, "val_loss": 316.21501445770264, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1026.8350524902344, "training_acc": 53.0, "val_loss": 72.17835783958435, "val_acc": 48.0}
{"epoch": 6, "training_loss": 448.46429443359375, "training_acc": 47.0, "val_loss": 168.56526136398315, "val_acc": 48.0}
{"epoch": 7, "training_loss": 535.2345743179321, "training_acc": 47.0, "val_loss": 92.91101098060608, "val_acc": 52.0}
{"epoch": 8, "training_loss": 443.1335258483887, "training_acc": 53.0, "val_loss": 154.3747067451477, "val_acc": 52.0}
{"epoch": 9, "training_loss": 482.3980884552002, "training_acc": 53.0, "val_loss": 61.76648736000061, "val_acc": 48.0}
{"epoch": 10, "training_loss": 328.18292236328125, "training_acc": 47.0, "val_loss": 73.82442951202393, "val_acc": 48.0}
{"epoch": 11, "training_loss": 250.33063888549805, "training_acc": 46.0, "val_loss": 77.35674977302551, "val_acc": 52.0}
{"epoch": 12, "training_loss": 253.96296310424805, "training_acc": 53.0, "val_loss": 37.055784463882446, "val_acc": 48.0}
{"epoch": 13, "training_loss": 186.16756439208984, "training_acc": 46.0, "val_loss": 17.777684330940247, "val_acc": 60.0}
{"epoch": 14, "training_loss": 142.36207962036133, "training_acc": 50.0, "val_loss": 45.68459689617157, "val_acc": 52.0}
{"epoch": 15, "training_loss": 158.86681413650513, "training_acc": 45.0, "val_loss": 30.36702871322632, "val_acc": 48.0}
{"epoch": 16, "training_loss": 119.22418999671936, "training_acc": 50.0, "val_loss": 45.808035135269165, "val_acc": 52.0}
{"epoch": 17, "training_loss": 115.74662160873413, "training_acc": 56.0, "val_loss": 28.889402747154236, "val_acc": 48.0}
{"epoch": 18, "training_loss": 117.63277816772461, "training_acc": 54.0, "val_loss": 44.116514921188354, "val_acc": 52.0}
{"epoch": 19, "training_loss": 127.66278910636902, "training_acc": 52.0, "val_loss": 21.77974432706833, "val_acc": 56.0}
{"epoch": 20, "training_loss": 99.1516227722168, "training_acc": 52.0, "val_loss": 41.996943950653076, "val_acc": 52.0}
{"epoch": 21, "training_loss": 131.3795657157898, "training_acc": 53.0, "val_loss": 19.73118484020233, "val_acc": 56.0}
{"epoch": 22, "training_loss": 89.4829568862915, "training_acc": 54.0, "val_loss": 20.275363326072693, "val_acc": 52.0}
{"epoch": 23, "training_loss": 85.28960657119751, "training_acc": 54.0, "val_loss": 18.90064775943756, "val_acc": 56.0}
{"epoch": 24, "training_loss": 76.54777240753174, "training_acc": 59.0, "val_loss": 28.871139883995056, "val_acc": 52.0}
{"epoch": 25, "training_loss": 91.64589142799377, "training_acc": 58.0, "val_loss": 23.674041032791138, "val_acc": 44.0}
{"epoch": 26, "training_loss": 101.55763792991638, "training_acc": 52.0, "val_loss": 23.559588193893433, "val_acc": 52.0}
{"epoch": 27, "training_loss": 77.65603685379028, "training_acc": 56.0, "val_loss": 16.880451142787933, "val_acc": 52.0}
{"epoch": 28, "training_loss": 63.32303833961487, "training_acc": 66.0, "val_loss": 19.40166801214218, "val_acc": 52.0}
{"epoch": 29, "training_loss": 74.85653400421143, "training_acc": 57.0, "val_loss": 19.114695489406586, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.12909722328186, "training_acc": 61.0, "val_loss": 24.305324256420135, "val_acc": 48.0}
{"epoch": 31, "training_loss": 73.8367965221405, "training_acc": 58.0, "val_loss": 35.60502231121063, "val_acc": 52.0}
{"epoch": 32, "training_loss": 100.70486307144165, "training_acc": 59.0, "val_loss": 37.874624133110046, "val_acc": 48.0}
{"epoch": 33, "training_loss": 132.94434523582458, "training_acc": 42.0, "val_loss": 17.313048243522644, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.44562673568726, "training_acc": 62.0, "val_loss": 26.87067985534668, "val_acc": 52.0}
{"epoch": 35, "training_loss": 85.81321048736572, "training_acc": 60.0, "val_loss": 23.463426530361176, "val_acc": 48.0}
{"epoch": 36, "training_loss": 98.09814500808716, "training_acc": 45.0, "val_loss": 24.643629789352417, "val_acc": 48.0}
{"epoch": 37, "training_loss": 81.39357686042786, "training_acc": 51.0, "val_loss": 18.452945351600647, "val_acc": 64.0}
{"epoch": 38, "training_loss": 61.569382667541504, "training_acc": 65.0, "val_loss": 32.84386992454529, "val_acc": 52.0}
{"epoch": 39, "training_loss": 96.2942008972168, "training_acc": 58.0, "val_loss": 24.685759842395782, "val_acc": 40.0}
{"epoch": 40, "training_loss": 123.80228424072266, "training_acc": 45.0, "val_loss": 17.22218692302704, "val_acc": 52.0}
{"epoch": 41, "training_loss": 77.5979790687561, "training_acc": 54.0, "val_loss": 21.514807641506195, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.59389638900757, "training_acc": 62.0, "val_loss": 26.5150785446167, "val_acc": 48.0}
{"epoch": 43, "training_loss": 77.947669506073, "training_acc": 55.0, "val_loss": 38.62784504890442, "val_acc": 52.0}
{"epoch": 44, "training_loss": 114.78142094612122, "training_acc": 56.0, "val_loss": 54.147106409072876, "val_acc": 48.0}
{"epoch": 45, "training_loss": 163.61184930801392, "training_acc": 47.0, "val_loss": 59.25348997116089, "val_acc": 52.0}
{"epoch": 46, "training_loss": 234.13060474395752, "training_acc": 53.0, "val_loss": 16.85260683298111, "val_acc": 68.0}
{"epoch": 47, "training_loss": 123.8103380203247, "training_acc": 62.0, "val_loss": 25.722602009773254, "val_acc": 48.0}
{"epoch": 48, "training_loss": 149.04450225830078, "training_acc": 49.0, "val_loss": 70.88190913200378, "val_acc": 52.0}
{"epoch": 49, "training_loss": 162.5787010192871, "training_acc": 64.0, "val_loss": 80.12287616729736, "val_acc": 48.0}
{"epoch": 50, "training_loss": 282.3475008010864, "training_acc": 47.0, "val_loss": 31.870466470718384, "val_acc": 52.0}
{"epoch": 51, "training_loss": 125.93470859527588, "training_acc": 55.0, "val_loss": 20.02258598804474, "val_acc": 52.0}
{"epoch": 52, "training_loss": 145.98351764678955, "training_acc": 53.0, "val_loss": 28.605985641479492, "val_acc": 48.0}
{"epoch": 53, "training_loss": 144.9385108947754, "training_acc": 50.0, "val_loss": 59.68928337097168, "val_acc": 52.0}
{"epoch": 54, "training_loss": 178.48202872276306, "training_acc": 51.0, "val_loss": 35.75720191001892, "val_acc": 48.0}
{"epoch": 55, "training_loss": 104.55917048454285, "training_acc": 53.0, "val_loss": 37.744131684303284, "val_acc": 52.0}
{"epoch": 56, "training_loss": 113.9971821308136, "training_acc": 58.0, "val_loss": 22.367629408836365, "val_acc": 44.0}
{"epoch": 57, "training_loss": 67.08202815055847, "training_acc": 66.0, "val_loss": 22.07818627357483, "val_acc": 52.0}
{"epoch": 58, "training_loss": 81.01909923553467, "training_acc": 54.0, "val_loss": 19.65424120426178, "val_acc": 56.0}
{"epoch": 59, "training_loss": 70.60112881660461, "training_acc": 65.0, "val_loss": 19.40084397792816, "val_acc": 64.0}
{"epoch": 60, "training_loss": 61.55429792404175, "training_acc": 69.0, "val_loss": 19.37890648841858, "val_acc": 56.0}
{"epoch": 61, "training_loss": 51.915966153144836, "training_acc": 76.0, "val_loss": 17.26633459329605, "val_acc": 64.0}
{"epoch": 62, "training_loss": 54.22246551513672, "training_acc": 70.0, "val_loss": 17.768116295337677, "val_acc": 56.0}
{"epoch": 63, "training_loss": 51.16405653953552, "training_acc": 74.0, "val_loss": 18.28531175851822, "val_acc": 56.0}
{"epoch": 64, "training_loss": 57.44807422161102, "training_acc": 71.0, "val_loss": 16.52694344520569, "val_acc": 68.0}
{"epoch": 65, "training_loss": 57.554813861846924, "training_acc": 72.0, "val_loss": 22.50482141971588, "val_acc": 52.0}
{"epoch": 66, "training_loss": 62.15862846374512, "training_acc": 68.0, "val_loss": 29.82591688632965, "val_acc": 48.0}
{"epoch": 67, "training_loss": 76.55738532543182, "training_acc": 61.0, "val_loss": 34.983134269714355, "val_acc": 52.0}
{"epoch": 68, "training_loss": 84.3825032711029, "training_acc": 62.0, "val_loss": 29.47188913822174, "val_acc": 48.0}
{"epoch": 69, "training_loss": 87.48264074325562, "training_acc": 54.0, "val_loss": 22.86786437034607, "val_acc": 52.0}
{"epoch": 70, "training_loss": 74.59577870368958, "training_acc": 55.0, "val_loss": 16.62391871213913, "val_acc": 60.0}
{"epoch": 71, "training_loss": 68.17995309829712, "training_acc": 70.0, "val_loss": 16.533616185188293, "val_acc": 64.0}
{"epoch": 72, "training_loss": 61.254218339920044, "training_acc": 71.0, "val_loss": 25.0089168548584, "val_acc": 52.0}
{"epoch": 73, "training_loss": 62.789589524269104, "training_acc": 66.0, "val_loss": 24.6586874127388, "val_acc": 48.0}
{"epoch": 74, "training_loss": 76.40616869926453, "training_acc": 55.0, "val_loss": 17.043712735176086, "val_acc": 56.0}
{"epoch": 75, "training_loss": 49.200812578201294, "training_acc": 76.0, "val_loss": 18.47556382417679, "val_acc": 52.0}
{"epoch": 76, "training_loss": 48.89836573600769, "training_acc": 72.0, "val_loss": 21.544718742370605, "val_acc": 44.0}
{"epoch": 77, "training_loss": 59.46871995925903, "training_acc": 65.0, "val_loss": 24.41047579050064, "val_acc": 52.0}
{"epoch": 78, "training_loss": 60.2971568107605, "training_acc": 64.0, "val_loss": 18.32219660282135, "val_acc": 60.0}
{"epoch": 79, "training_loss": 75.87641954421997, "training_acc": 60.0, "val_loss": 16.528287529945374, "val_acc": 64.0}
{"epoch": 80, "training_loss": 59.19632577896118, "training_acc": 66.0, "val_loss": 34.90847051143646, "val_acc": 52.0}
{"epoch": 81, "training_loss": 82.38284993171692, "training_acc": 58.0, "val_loss": 35.11514067649841, "val_acc": 48.0}
{"epoch": 82, "training_loss": 87.21239972114563, "training_acc": 58.0, "val_loss": 44.307294487953186, "val_acc": 52.0}
{"epoch": 83, "training_loss": 118.56173384189606, "training_acc": 55.0, "val_loss": 23.21404218673706, "val_acc": 48.0}
