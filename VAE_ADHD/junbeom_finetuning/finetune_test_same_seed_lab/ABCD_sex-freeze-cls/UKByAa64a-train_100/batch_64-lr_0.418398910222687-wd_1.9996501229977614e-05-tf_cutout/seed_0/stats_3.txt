"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 315.39696502685547, "training_acc": 56.0, "val_loss": 251.49872303009033, "val_acc": 48.0}
{"epoch": 1, "training_loss": 820.9453983306885, "training_acc": 47.0, "val_loss": 119.83777284622192, "val_acc": 52.0}
{"epoch": 2, "training_loss": 619.1971778869629, "training_acc": 53.0, "val_loss": 78.18267941474915, "val_acc": 52.0}
{"epoch": 3, "training_loss": 317.9480609893799, "training_acc": 59.0, "val_loss": 180.58382272720337, "val_acc": 48.0}
{"epoch": 4, "training_loss": 582.998384475708, "training_acc": 47.0, "val_loss": 32.65780508518219, "val_acc": 52.0}
{"epoch": 5, "training_loss": 277.9174385070801, "training_acc": 50.0, "val_loss": 67.55995154380798, "val_acc": 52.0}
{"epoch": 6, "training_loss": 201.03172039985657, "training_acc": 59.0, "val_loss": 98.74746203422546, "val_acc": 48.0}
{"epoch": 7, "training_loss": 344.0240545272827, "training_acc": 49.0, "val_loss": 54.82030510902405, "val_acc": 52.0}
{"epoch": 8, "training_loss": 239.0581693649292, "training_acc": 55.0, "val_loss": 35.07881164550781, "val_acc": 48.0}
{"epoch": 9, "training_loss": 145.76882076263428, "training_acc": 57.0, "val_loss": 44.22904551029205, "val_acc": 48.0}
{"epoch": 10, "training_loss": 139.35433316230774, "training_acc": 58.0, "val_loss": 85.60656309127808, "val_acc": 52.0}
{"epoch": 11, "training_loss": 208.78838920593262, "training_acc": 52.0, "val_loss": 62.32534050941467, "val_acc": 48.0}
{"epoch": 12, "training_loss": 340.97875595092773, "training_acc": 47.0, "val_loss": 26.332661509513855, "val_acc": 44.0}
{"epoch": 13, "training_loss": 236.49123573303223, "training_acc": 46.0, "val_loss": 140.7101273536682, "val_acc": 52.0}
{"epoch": 14, "training_loss": 366.9582815170288, "training_acc": 53.0, "val_loss": 39.744049310684204, "val_acc": 48.0}
{"epoch": 15, "training_loss": 250.8926248550415, "training_acc": 47.0, "val_loss": 25.25840401649475, "val_acc": 40.0}
{"epoch": 16, "training_loss": 167.3916654586792, "training_acc": 52.0, "val_loss": 108.2991361618042, "val_acc": 52.0}
{"epoch": 17, "training_loss": 258.2572627067566, "training_acc": 56.0, "val_loss": 46.133628487586975, "val_acc": 48.0}
{"epoch": 18, "training_loss": 247.26042079925537, "training_acc": 47.0, "val_loss": 30.06642758846283, "val_acc": 52.0}
{"epoch": 19, "training_loss": 122.30196857452393, "training_acc": 53.0, "val_loss": 59.8145067691803, "val_acc": 52.0}
{"epoch": 20, "training_loss": 177.94792127609253, "training_acc": 47.0, "val_loss": 28.156349062919617, "val_acc": 52.0}
{"epoch": 21, "training_loss": 129.921555519104, "training_acc": 53.0, "val_loss": 50.26683807373047, "val_acc": 52.0}
{"epoch": 22, "training_loss": 110.61319351196289, "training_acc": 58.0, "val_loss": 46.99704945087433, "val_acc": 48.0}
{"epoch": 23, "training_loss": 206.40619468688965, "training_acc": 48.0, "val_loss": 51.11784338951111, "val_acc": 52.0}
{"epoch": 24, "training_loss": 182.59464645385742, "training_acc": 55.0, "val_loss": 31.48730993270874, "val_acc": 52.0}
{"epoch": 25, "training_loss": 125.84792423248291, "training_acc": 52.0, "val_loss": 51.29586458206177, "val_acc": 48.0}
{"epoch": 26, "training_loss": 156.98297667503357, "training_acc": 54.0, "val_loss": 73.70420694351196, "val_acc": 52.0}
{"epoch": 27, "training_loss": 213.6329345703125, "training_acc": 53.0, "val_loss": 22.759997844696045, "val_acc": 64.0}
{"epoch": 28, "training_loss": 130.53842782974243, "training_acc": 51.0, "val_loss": 21.649715304374695, "val_acc": 48.0}
{"epoch": 29, "training_loss": 124.40230655670166, "training_acc": 53.0, "val_loss": 41.654738783836365, "val_acc": 52.0}
{"epoch": 30, "training_loss": 104.29818153381348, "training_acc": 63.0, "val_loss": 31.75538182258606, "val_acc": 52.0}
{"epoch": 31, "training_loss": 143.39448475837708, "training_acc": 51.0, "val_loss": 58.23999643325806, "val_acc": 52.0}
{"epoch": 32, "training_loss": 119.9439594745636, "training_acc": 60.0, "val_loss": 23.39586168527603, "val_acc": 56.0}
{"epoch": 33, "training_loss": 102.59515476226807, "training_acc": 55.0, "val_loss": 45.73172330856323, "val_acc": 52.0}
{"epoch": 34, "training_loss": 91.40893566608429, "training_acc": 64.0, "val_loss": 19.293127954006195, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.81310749053955, "training_acc": 67.0, "val_loss": 25.738850235939026, "val_acc": 52.0}
{"epoch": 36, "training_loss": 72.8761682510376, "training_acc": 66.0, "val_loss": 20.418095588684082, "val_acc": 64.0}
{"epoch": 37, "training_loss": 79.57504272460938, "training_acc": 60.0, "val_loss": 23.44365268945694, "val_acc": 52.0}
{"epoch": 38, "training_loss": 75.95432591438293, "training_acc": 65.0, "val_loss": 17.375411093235016, "val_acc": 76.0}
{"epoch": 39, "training_loss": 75.86986970901489, "training_acc": 54.0, "val_loss": 18.073415756225586, "val_acc": 56.0}
{"epoch": 40, "training_loss": 59.98533082008362, "training_acc": 70.0, "val_loss": 16.134047508239746, "val_acc": 48.0}
{"epoch": 41, "training_loss": 78.92919874191284, "training_acc": 53.0, "val_loss": 18.032076954841614, "val_acc": 72.0}
{"epoch": 42, "training_loss": 65.32330298423767, "training_acc": 58.0, "val_loss": 36.89894676208496, "val_acc": 52.0}
{"epoch": 43, "training_loss": 83.78934144973755, "training_acc": 60.0, "val_loss": 43.869802355766296, "val_acc": 48.0}
{"epoch": 44, "training_loss": 146.54144430160522, "training_acc": 53.0, "val_loss": 44.50576305389404, "val_acc": 52.0}
{"epoch": 45, "training_loss": 99.60343217849731, "training_acc": 60.0, "val_loss": 27.35949158668518, "val_acc": 52.0}
{"epoch": 46, "training_loss": 95.7326648235321, "training_acc": 58.0, "val_loss": 43.73650252819061, "val_acc": 52.0}
{"epoch": 47, "training_loss": 101.82890248298645, "training_acc": 55.0, "val_loss": 17.69191473722458, "val_acc": 48.0}
{"epoch": 48, "training_loss": 64.1534960269928, "training_acc": 66.0, "val_loss": 19.539737701416016, "val_acc": 52.0}
{"epoch": 49, "training_loss": 53.186630964279175, "training_acc": 74.0, "val_loss": 18.544520437717438, "val_acc": 52.0}
{"epoch": 50, "training_loss": 49.69396662712097, "training_acc": 73.0, "val_loss": 16.44807606935501, "val_acc": 52.0}
{"epoch": 51, "training_loss": 55.224167585372925, "training_acc": 72.0, "val_loss": 22.554901242256165, "val_acc": 52.0}
{"epoch": 52, "training_loss": 66.5677011013031, "training_acc": 67.0, "val_loss": 17.708295583724976, "val_acc": 52.0}
{"epoch": 53, "training_loss": 49.17201519012451, "training_acc": 81.0, "val_loss": 19.709983468055725, "val_acc": 52.0}
{"epoch": 54, "training_loss": 54.918652296066284, "training_acc": 72.0, "val_loss": 23.787035048007965, "val_acc": 52.0}
{"epoch": 55, "training_loss": 58.42547583580017, "training_acc": 73.0, "val_loss": 20.322050154209137, "val_acc": 56.0}
{"epoch": 56, "training_loss": 71.03323781490326, "training_acc": 65.0, "val_loss": 39.78123664855957, "val_acc": 52.0}
{"epoch": 57, "training_loss": 89.61068058013916, "training_acc": 54.0, "val_loss": 18.16389113664627, "val_acc": 48.0}
{"epoch": 58, "training_loss": 54.2386314868927, "training_acc": 77.0, "val_loss": 16.558396816253662, "val_acc": 56.0}
{"epoch": 59, "training_loss": 52.62363612651825, "training_acc": 74.0, "val_loss": 21.707211434841156, "val_acc": 52.0}
