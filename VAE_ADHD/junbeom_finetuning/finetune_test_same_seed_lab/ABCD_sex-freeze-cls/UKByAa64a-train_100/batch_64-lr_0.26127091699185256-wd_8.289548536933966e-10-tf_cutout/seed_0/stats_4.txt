"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 614.0915184020996, "training_acc": 59.0, "val_loss": 103.4192442893982, "val_acc": 52.0}
{"epoch": 1, "training_loss": 606.4093475341797, "training_acc": 49.0, "val_loss": 300.83229541778564, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1150.0571784973145, "training_acc": 47.0, "val_loss": 97.67164587974548, "val_acc": 48.0}
{"epoch": 3, "training_loss": 382.49249362945557, "training_acc": 51.0, "val_loss": 188.78133296966553, "val_acc": 52.0}
{"epoch": 4, "training_loss": 733.5475444793701, "training_acc": 53.0, "val_loss": 164.72904682159424, "val_acc": 52.0}
{"epoch": 5, "training_loss": 500.86803436279297, "training_acc": 53.0, "val_loss": 61.47871017456055, "val_acc": 48.0}
{"epoch": 6, "training_loss": 346.1771583557129, "training_acc": 47.0, "val_loss": 114.46527242660522, "val_acc": 48.0}
{"epoch": 7, "training_loss": 376.3519334793091, "training_acc": 47.0, "val_loss": 52.053600549697876, "val_acc": 52.0}
{"epoch": 8, "training_loss": 248.74958992004395, "training_acc": 53.0, "val_loss": 95.3057050704956, "val_acc": 52.0}
{"epoch": 9, "training_loss": 289.69347381591797, "training_acc": 53.0, "val_loss": 31.91700577735901, "val_acc": 48.0}
{"epoch": 10, "training_loss": 161.90357446670532, "training_acc": 47.0, "val_loss": 40.986090898513794, "val_acc": 48.0}
{"epoch": 11, "training_loss": 146.39830422401428, "training_acc": 50.0, "val_loss": 49.86085295677185, "val_acc": 52.0}
{"epoch": 12, "training_loss": 159.53639459609985, "training_acc": 53.0, "val_loss": 18.603217601776123, "val_acc": 52.0}
{"epoch": 13, "training_loss": 92.44670915603638, "training_acc": 55.0, "val_loss": 23.1623575091362, "val_acc": 52.0}
{"epoch": 14, "training_loss": 110.82800388336182, "training_acc": 43.0, "val_loss": 28.417035937309265, "val_acc": 52.0}
{"epoch": 15, "training_loss": 88.41085934638977, "training_acc": 57.0, "val_loss": 22.557544708251953, "val_acc": 52.0}
{"epoch": 16, "training_loss": 82.77408695220947, "training_acc": 54.0, "val_loss": 25.72292983531952, "val_acc": 52.0}
{"epoch": 17, "training_loss": 85.00832796096802, "training_acc": 54.0, "val_loss": 18.669772148132324, "val_acc": 56.0}
{"epoch": 18, "training_loss": 87.51653480529785, "training_acc": 51.0, "val_loss": 21.300040185451508, "val_acc": 52.0}
{"epoch": 19, "training_loss": 78.94636106491089, "training_acc": 57.0, "val_loss": 17.61164218187332, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.97100138664246, "training_acc": 61.0, "val_loss": 17.559978365898132, "val_acc": 52.0}
{"epoch": 21, "training_loss": 80.52600169181824, "training_acc": 53.0, "val_loss": 17.526696622371674, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.86928081512451, "training_acc": 63.0, "val_loss": 17.517416179180145, "val_acc": 60.0}
{"epoch": 23, "training_loss": 62.17504572868347, "training_acc": 67.0, "val_loss": 20.050279796123505, "val_acc": 52.0}
{"epoch": 24, "training_loss": 62.909897804260254, "training_acc": 65.0, "val_loss": 22.706156969070435, "val_acc": 48.0}
{"epoch": 25, "training_loss": 75.88817596435547, "training_acc": 57.0, "val_loss": 24.49830025434494, "val_acc": 52.0}
{"epoch": 26, "training_loss": 86.68742370605469, "training_acc": 52.0, "val_loss": 17.288556694984436, "val_acc": 60.0}
{"epoch": 27, "training_loss": 63.201335191726685, "training_acc": 64.0, "val_loss": 17.72315204143524, "val_acc": 56.0}
{"epoch": 28, "training_loss": 61.306482791900635, "training_acc": 62.0, "val_loss": 18.46134513616562, "val_acc": 52.0}
{"epoch": 29, "training_loss": 64.11149525642395, "training_acc": 62.0, "val_loss": 18.366841971874237, "val_acc": 52.0}
{"epoch": 30, "training_loss": 62.289650201797485, "training_acc": 65.0, "val_loss": 17.714758217334747, "val_acc": 60.0}
{"epoch": 31, "training_loss": 63.274616956710815, "training_acc": 69.0, "val_loss": 18.14696490764618, "val_acc": 52.0}
{"epoch": 32, "training_loss": 60.88140273094177, "training_acc": 70.0, "val_loss": 19.32392418384552, "val_acc": 48.0}
{"epoch": 33, "training_loss": 64.64807462692261, "training_acc": 59.0, "val_loss": 21.855375170707703, "val_acc": 52.0}
{"epoch": 34, "training_loss": 72.62792706489563, "training_acc": 57.0, "val_loss": 17.285391688346863, "val_acc": 64.0}
{"epoch": 35, "training_loss": 61.73918104171753, "training_acc": 66.0, "val_loss": 17.230047285556793, "val_acc": 56.0}
{"epoch": 36, "training_loss": 59.01783752441406, "training_acc": 71.0, "val_loss": 17.215093970298767, "val_acc": 56.0}
{"epoch": 37, "training_loss": 58.548733711242676, "training_acc": 75.0, "val_loss": 17.162762582302094, "val_acc": 52.0}
{"epoch": 38, "training_loss": 56.84650409221649, "training_acc": 73.0, "val_loss": 17.12617129087448, "val_acc": 56.0}
{"epoch": 39, "training_loss": 60.20620083808899, "training_acc": 71.0, "val_loss": 17.10829883813858, "val_acc": 56.0}
{"epoch": 40, "training_loss": 60.48922801017761, "training_acc": 65.0, "val_loss": 18.726566433906555, "val_acc": 52.0}
{"epoch": 41, "training_loss": 58.10938382148743, "training_acc": 69.0, "val_loss": 17.154011130332947, "val_acc": 52.0}
{"epoch": 42, "training_loss": 60.61994004249573, "training_acc": 66.0, "val_loss": 17.661452293395996, "val_acc": 60.0}
{"epoch": 43, "training_loss": 58.02948045730591, "training_acc": 71.0, "val_loss": 20.56340128183365, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62.90420603752136, "training_acc": 61.0, "val_loss": 17.845459282398224, "val_acc": 72.0}
{"epoch": 45, "training_loss": 63.72685098648071, "training_acc": 59.0, "val_loss": 17.46879518032074, "val_acc": 52.0}
{"epoch": 46, "training_loss": 71.72261428833008, "training_acc": 56.0, "val_loss": 24.032168090343475, "val_acc": 52.0}
{"epoch": 47, "training_loss": 73.94791555404663, "training_acc": 56.0, "val_loss": 32.49907195568085, "val_acc": 48.0}
{"epoch": 48, "training_loss": 105.46034955978394, "training_acc": 50.0, "val_loss": 25.91494619846344, "val_acc": 52.0}
{"epoch": 49, "training_loss": 80.61466789245605, "training_acc": 60.0, "val_loss": 27.292701601982117, "val_acc": 44.0}
{"epoch": 50, "training_loss": 102.58525657653809, "training_acc": 45.0, "val_loss": 16.988682746887207, "val_acc": 52.0}
{"epoch": 51, "training_loss": 54.192551136016846, "training_acc": 76.0, "val_loss": 16.85197353363037, "val_acc": 56.0}
{"epoch": 52, "training_loss": 58.17850971221924, "training_acc": 73.0, "val_loss": 18.816573917865753, "val_acc": 52.0}
{"epoch": 53, "training_loss": 57.38322043418884, "training_acc": 64.0, "val_loss": 23.759889602661133, "val_acc": 44.0}
{"epoch": 54, "training_loss": 71.5671808719635, "training_acc": 58.0, "val_loss": 25.92601776123047, "val_acc": 52.0}
{"epoch": 55, "training_loss": 71.53094530105591, "training_acc": 61.0, "val_loss": 20.55775225162506, "val_acc": 52.0}
{"epoch": 56, "training_loss": 65.93149161338806, "training_acc": 57.0, "val_loss": 17.44096726179123, "val_acc": 56.0}
{"epoch": 57, "training_loss": 60.39887619018555, "training_acc": 65.0, "val_loss": 24.828974902629852, "val_acc": 52.0}
{"epoch": 58, "training_loss": 70.24390089511871, "training_acc": 59.0, "val_loss": 19.67763453722, "val_acc": 52.0}
{"epoch": 59, "training_loss": 63.09551215171814, "training_acc": 63.0, "val_loss": 17.010299861431122, "val_acc": 56.0}
{"epoch": 60, "training_loss": 55.783576250076294, "training_acc": 73.0, "val_loss": 24.246597290039062, "val_acc": 48.0}
{"epoch": 61, "training_loss": 73.8548469543457, "training_acc": 55.0, "val_loss": 18.963173031806946, "val_acc": 52.0}
{"epoch": 62, "training_loss": 52.51120913028717, "training_acc": 79.0, "val_loss": 24.967677891254425, "val_acc": 48.0}
{"epoch": 63, "training_loss": 100.2489013671875, "training_acc": 37.0, "val_loss": 17.61443465948105, "val_acc": 60.0}
{"epoch": 64, "training_loss": 61.049872636795044, "training_acc": 65.0, "val_loss": 18.665894865989685, "val_acc": 52.0}
{"epoch": 65, "training_loss": 56.69624352455139, "training_acc": 71.0, "val_loss": 17.014749348163605, "val_acc": 52.0}
{"epoch": 66, "training_loss": 51.32007074356079, "training_acc": 74.0, "val_loss": 19.542361795902252, "val_acc": 44.0}
{"epoch": 67, "training_loss": 56.953245759010315, "training_acc": 68.0, "val_loss": 24.991782009601593, "val_acc": 52.0}
{"epoch": 68, "training_loss": 62.36471509933472, "training_acc": 66.0, "val_loss": 32.73367881774902, "val_acc": 48.0}
{"epoch": 69, "training_loss": 87.19335293769836, "training_acc": 61.0, "val_loss": 34.333181381225586, "val_acc": 52.0}
{"epoch": 70, "training_loss": 95.17096388339996, "training_acc": 63.0, "val_loss": 29.332587122917175, "val_acc": 48.0}
