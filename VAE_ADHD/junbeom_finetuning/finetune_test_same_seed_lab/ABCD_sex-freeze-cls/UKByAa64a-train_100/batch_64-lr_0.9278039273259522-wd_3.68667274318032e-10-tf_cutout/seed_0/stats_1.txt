"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1993.036777496338, "training_acc": 46.0, "val_loss": 407.1763038635254, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1978.1273574829102, "training_acc": 53.0, "val_loss": 1054.9487113952637, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3969.9485626220703, "training_acc": 47.0, "val_loss": 292.5110340118408, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1383.2182235717773, "training_acc": 51.0, "val_loss": 770.2258110046387, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2926.8936920166016, "training_acc": 53.0, "val_loss": 687.2814178466797, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2040.2099494934082, "training_acc": 53.0, "val_loss": 119.55400705337524, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1101.0297927856445, "training_acc": 47.0, "val_loss": 352.27043628692627, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1193.6327571868896, "training_acc": 47.0, "val_loss": 254.87141609191895, "val_acc": 52.0}
{"epoch": 8, "training_loss": 993.9196243286133, "training_acc": 53.0, "val_loss": 441.2485122680664, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1431.9098587036133, "training_acc": 53.0, "val_loss": 54.91853356361389, "val_acc": 52.0}
{"epoch": 10, "training_loss": 573.1764907836914, "training_acc": 49.0, "val_loss": 399.3241548538208, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1522.86714553833, "training_acc": 47.0, "val_loss": 63.896530866622925, "val_acc": 48.0}
{"epoch": 12, "training_loss": 542.1511878967285, "training_acc": 49.0, "val_loss": 454.5088291168213, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1741.8616180419922, "training_acc": 53.0, "val_loss": 345.0043201446533, "val_acc": 52.0}
{"epoch": 14, "training_loss": 943.6786518096924, "training_acc": 53.0, "val_loss": 304.16691303253174, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1512.0172882080078, "training_acc": 47.0, "val_loss": 471.592378616333, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1604.8391647338867, "training_acc": 47.0, "val_loss": 39.80469107627869, "val_acc": 60.0}
{"epoch": 17, "training_loss": 418.9021110534668, "training_acc": 57.0, "val_loss": 313.0229949951172, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1042.5785789489746, "training_acc": 53.0, "val_loss": 34.055715799331665, "val_acc": 60.0}
{"epoch": 19, "training_loss": 308.17131996154785, "training_acc": 61.0, "val_loss": 245.32999992370605, "val_acc": 48.0}
{"epoch": 20, "training_loss": 842.4006357192993, "training_acc": 47.0, "val_loss": 132.965087890625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 499.7133388519287, "training_acc": 53.0, "val_loss": 142.37627983093262, "val_acc": 52.0}
{"epoch": 22, "training_loss": 384.3941173553467, "training_acc": 50.0, "val_loss": 85.75878143310547, "val_acc": 48.0}
{"epoch": 23, "training_loss": 301.5768475532532, "training_acc": 53.0, "val_loss": 98.96665811538696, "val_acc": 52.0}
{"epoch": 24, "training_loss": 206.45783805847168, "training_acc": 57.0, "val_loss": 34.075504541397095, "val_acc": 44.0}
{"epoch": 25, "training_loss": 135.50721788406372, "training_acc": 64.0, "val_loss": 89.53611850738525, "val_acc": 56.0}
{"epoch": 26, "training_loss": 206.10743761062622, "training_acc": 53.0, "val_loss": 29.718387126922607, "val_acc": 48.0}
{"epoch": 27, "training_loss": 154.5299367904663, "training_acc": 53.0, "val_loss": 30.506840348243713, "val_acc": 56.0}
{"epoch": 28, "training_loss": 88.29398965835571, "training_acc": 62.0, "val_loss": 28.653335571289062, "val_acc": 56.0}
{"epoch": 29, "training_loss": 84.75866174697876, "training_acc": 64.0, "val_loss": 57.55005478858948, "val_acc": 56.0}
{"epoch": 30, "training_loss": 174.073233127594, "training_acc": 55.0, "val_loss": 26.46336555480957, "val_acc": 60.0}
{"epoch": 31, "training_loss": 80.62198829650879, "training_acc": 70.0, "val_loss": 26.159313321113586, "val_acc": 64.0}
{"epoch": 32, "training_loss": 87.15925645828247, "training_acc": 63.0, "val_loss": 46.800291538238525, "val_acc": 56.0}
{"epoch": 33, "training_loss": 100.6816418170929, "training_acc": 65.0, "val_loss": 54.866355657577515, "val_acc": 48.0}
{"epoch": 34, "training_loss": 305.42371940612793, "training_acc": 37.0, "val_loss": 14.762340486049652, "val_acc": 72.0}
{"epoch": 35, "training_loss": 103.33696746826172, "training_acc": 58.0, "val_loss": 80.67854046821594, "val_acc": 52.0}
{"epoch": 36, "training_loss": 193.7927484512329, "training_acc": 56.0, "val_loss": 100.07498264312744, "val_acc": 48.0}
{"epoch": 37, "training_loss": 375.73771953582764, "training_acc": 47.0, "val_loss": 142.90353059768677, "val_acc": 52.0}
{"epoch": 38, "training_loss": 549.8538799285889, "training_acc": 53.0, "val_loss": 55.87192177772522, "val_acc": 52.0}
{"epoch": 39, "training_loss": 411.4832649230957, "training_acc": 49.0, "val_loss": 240.34788608551025, "val_acc": 48.0}
{"epoch": 40, "training_loss": 751.9460525512695, "training_acc": 47.0, "val_loss": 176.17255449295044, "val_acc": 52.0}
{"epoch": 41, "training_loss": 793.0285224914551, "training_acc": 53.0, "val_loss": 240.39344787597656, "val_acc": 52.0}
{"epoch": 42, "training_loss": 666.6480026245117, "training_acc": 53.0, "val_loss": 260.1001739501953, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1119.9351501464844, "training_acc": 47.0, "val_loss": 281.57331943511963, "val_acc": 48.0}
{"epoch": 44, "training_loss": 770.6557695865631, "training_acc": 50.0, "val_loss": 258.6052179336548, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1094.0452156066895, "training_acc": 53.0, "val_loss": 340.89787006378174, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1004.424877166748, "training_acc": 53.0, "val_loss": 115.83453416824341, "val_acc": 48.0}
{"epoch": 47, "training_loss": 675.2856788635254, "training_acc": 47.0, "val_loss": 182.96626806259155, "val_acc": 48.0}
{"epoch": 48, "training_loss": 435.9000709056854, "training_acc": 61.0, "val_loss": 162.03114986419678, "val_acc": 52.0}
{"epoch": 49, "training_loss": 538.1825637817383, "training_acc": 53.0, "val_loss": 15.14260470867157, "val_acc": 68.0}
{"epoch": 50, "training_loss": 249.4849967956543, "training_acc": 57.0, "val_loss": 25.441426038742065, "val_acc": 52.0}
{"epoch": 51, "training_loss": 247.72756385803223, "training_acc": 55.0, "val_loss": 147.42014408111572, "val_acc": 52.0}
{"epoch": 52, "training_loss": 340.9896796941757, "training_acc": 61.0, "val_loss": 121.58693075180054, "val_acc": 48.0}
{"epoch": 53, "training_loss": 435.9256315231323, "training_acc": 47.0, "val_loss": 116.47546291351318, "val_acc": 52.0}
