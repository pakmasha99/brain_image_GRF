"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2048.9485626220703, "training_acc": 53.0, "val_loss": 399.8049259185791, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2100.967414855957, "training_acc": 51.0, "val_loss": 1070.8984375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3928.64453125, "training_acc": 47.0, "val_loss": 332.96401500701904, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1369.3143501281738, "training_acc": 49.0, "val_loss": 716.7836666107178, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2846.1517486572266, "training_acc": 53.0, "val_loss": 618.211555480957, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2172.4435691833496, "training_acc": 53.0, "val_loss": 155.71017265319824, "val_acc": 48.0}
{"epoch": 6, "training_loss": 778.5205993652344, "training_acc": 49.0, "val_loss": 271.13094329833984, "val_acc": 48.0}
{"epoch": 7, "training_loss": 692.0919411182404, "training_acc": 48.0, "val_loss": 218.3732032775879, "val_acc": 52.0}
{"epoch": 8, "training_loss": 883.4522495269775, "training_acc": 53.0, "val_loss": 108.53445529937744, "val_acc": 52.0}
{"epoch": 9, "training_loss": 457.24513244628906, "training_acc": 53.0, "val_loss": 240.6062364578247, "val_acc": 48.0}
{"epoch": 10, "training_loss": 698.3953876495361, "training_acc": 47.0, "val_loss": 142.58276224136353, "val_acc": 52.0}
{"epoch": 11, "training_loss": 674.6281280517578, "training_acc": 53.0, "val_loss": 166.2158489227295, "val_acc": 52.0}
{"epoch": 12, "training_loss": 479.0393319129944, "training_acc": 49.0, "val_loss": 118.38724613189697, "val_acc": 48.0}
{"epoch": 13, "training_loss": 276.94702672958374, "training_acc": 50.0, "val_loss": 142.96356439590454, "val_acc": 52.0}
{"epoch": 14, "training_loss": 560.6093730926514, "training_acc": 53.0, "val_loss": 36.46379113197327, "val_acc": 56.0}
{"epoch": 15, "training_loss": 367.3750762939453, "training_acc": 50.0, "val_loss": 227.97284126281738, "val_acc": 48.0}
{"epoch": 16, "training_loss": 668.7802410125732, "training_acc": 47.0, "val_loss": 196.7018723487854, "val_acc": 52.0}
{"epoch": 17, "training_loss": 901.7854385375977, "training_acc": 53.0, "val_loss": 273.05846214294434, "val_acc": 52.0}
{"epoch": 18, "training_loss": 812.0617809295654, "training_acc": 53.0, "val_loss": 205.40573596954346, "val_acc": 48.0}
{"epoch": 19, "training_loss": 921.2590255737305, "training_acc": 47.0, "val_loss": 226.30062103271484, "val_acc": 48.0}
{"epoch": 20, "training_loss": 590.3416156768799, "training_acc": 58.0, "val_loss": 206.71095848083496, "val_acc": 52.0}
{"epoch": 21, "training_loss": 827.2062683105469, "training_acc": 53.0, "val_loss": 151.04565620422363, "val_acc": 52.0}
{"epoch": 22, "training_loss": 423.2610411643982, "training_acc": 55.0, "val_loss": 163.2794737815857, "val_acc": 48.0}
{"epoch": 23, "training_loss": 490.56429958343506, "training_acc": 48.0, "val_loss": 121.47643566131592, "val_acc": 52.0}
{"epoch": 24, "training_loss": 457.91736221313477, "training_acc": 53.0, "val_loss": 49.413129687309265, "val_acc": 56.0}
{"epoch": 25, "training_loss": 349.15599250793457, "training_acc": 52.0, "val_loss": 178.19647789001465, "val_acc": 48.0}
{"epoch": 26, "training_loss": 500.433180809021, "training_acc": 49.0, "val_loss": 160.36983728408813, "val_acc": 52.0}
{"epoch": 27, "training_loss": 638.5124225616455, "training_acc": 53.0, "val_loss": 69.07965540885925, "val_acc": 52.0}
{"epoch": 28, "training_loss": 356.9641227722168, "training_acc": 52.0, "val_loss": 204.29449081420898, "val_acc": 48.0}
{"epoch": 29, "training_loss": 656.748083114624, "training_acc": 48.0, "val_loss": 161.83171272277832, "val_acc": 52.0}
{"epoch": 30, "training_loss": 642.006326675415, "training_acc": 53.0, "val_loss": 169.33001279830933, "val_acc": 52.0}
{"epoch": 31, "training_loss": 376.99226999282837, "training_acc": 58.0, "val_loss": 148.39729070663452, "val_acc": 48.0}
{"epoch": 32, "training_loss": 543.6047382354736, "training_acc": 47.0, "val_loss": 79.0095865726471, "val_acc": 52.0}
{"epoch": 33, "training_loss": 295.60650062561035, "training_acc": 55.0, "val_loss": 38.88329863548279, "val_acc": 60.0}
