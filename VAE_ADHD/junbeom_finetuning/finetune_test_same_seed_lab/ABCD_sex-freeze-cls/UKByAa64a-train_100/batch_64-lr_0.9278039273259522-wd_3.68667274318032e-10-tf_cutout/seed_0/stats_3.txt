"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2175.342544555664, "training_acc": 45.0, "val_loss": 486.72189712524414, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2017.4936447143555, "training_acc": 53.0, "val_loss": 936.6215705871582, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3414.6427841186523, "training_acc": 47.0, "val_loss": 179.64962720870972, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1285.1333847045898, "training_acc": 45.0, "val_loss": 796.8031883239746, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3123.1021270751953, "training_acc": 53.0, "val_loss": 631.7334651947021, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1930.9966926574707, "training_acc": 53.0, "val_loss": 263.26904296875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1414.461280822754, "training_acc": 47.0, "val_loss": 518.0592060089111, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1729.4372863769531, "training_acc": 47.0, "val_loss": 35.73670983314514, "val_acc": 52.0}
{"epoch": 8, "training_loss": 474.2329216003418, "training_acc": 53.0, "val_loss": 210.51270961761475, "val_acc": 52.0}
{"epoch": 9, "training_loss": 646.809515953064, "training_acc": 53.0, "val_loss": 241.01073741912842, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1064.8726348876953, "training_acc": 45.0, "val_loss": 250.2251386642456, "val_acc": 48.0}
{"epoch": 11, "training_loss": 699.3322582244873, "training_acc": 51.0, "val_loss": 218.82643699645996, "val_acc": 52.0}
{"epoch": 12, "training_loss": 929.803840637207, "training_acc": 53.0, "val_loss": 179.01673316955566, "val_acc": 52.0}
{"epoch": 13, "training_loss": 648.5577526092529, "training_acc": 41.0, "val_loss": 108.719003200531, "val_acc": 48.0}
{"epoch": 14, "training_loss": 269.30594849586487, "training_acc": 58.0, "val_loss": 162.953519821167, "val_acc": 52.0}
{"epoch": 15, "training_loss": 477.1960144042969, "training_acc": 53.0, "val_loss": 33.933231234550476, "val_acc": 32.0}
{"epoch": 16, "training_loss": 154.1524806022644, "training_acc": 54.0, "val_loss": 61.23798489570618, "val_acc": 56.0}
{"epoch": 17, "training_loss": 125.32585906982422, "training_acc": 57.0, "val_loss": 35.074082016944885, "val_acc": 32.0}
{"epoch": 18, "training_loss": 115.98666143417358, "training_acc": 66.0, "val_loss": 64.1050636768341, "val_acc": 52.0}
{"epoch": 19, "training_loss": 146.673180103302, "training_acc": 53.0, "val_loss": 59.72139835357666, "val_acc": 52.0}
{"epoch": 20, "training_loss": 104.25816440582275, "training_acc": 60.0, "val_loss": 39.188700914382935, "val_acc": 52.0}
{"epoch": 21, "training_loss": 161.71293878555298, "training_acc": 54.0, "val_loss": 33.40960741043091, "val_acc": 52.0}
{"epoch": 22, "training_loss": 103.37212896347046, "training_acc": 62.0, "val_loss": 36.92542314529419, "val_acc": 52.0}
{"epoch": 23, "training_loss": 102.58028650283813, "training_acc": 56.0, "val_loss": 96.67682647705078, "val_acc": 48.0}
{"epoch": 24, "training_loss": 328.23967838287354, "training_acc": 47.0, "val_loss": 175.36678314208984, "val_acc": 52.0}
{"epoch": 25, "training_loss": 623.9321994781494, "training_acc": 53.0, "val_loss": 112.74707317352295, "val_acc": 52.0}
{"epoch": 26, "training_loss": 366.5632381439209, "training_acc": 55.0, "val_loss": 199.96623992919922, "val_acc": 48.0}
{"epoch": 27, "training_loss": 669.3297548294067, "training_acc": 47.0, "val_loss": 198.39693307876587, "val_acc": 52.0}
{"epoch": 28, "training_loss": 651.1451511383057, "training_acc": 53.0, "val_loss": 239.69416618347168, "val_acc": 52.0}
{"epoch": 29, "training_loss": 523.4354090690613, "training_acc": 55.0, "val_loss": 132.1883201599121, "val_acc": 48.0}
{"epoch": 30, "training_loss": 611.6156063079834, "training_acc": 47.0, "val_loss": 103.83973121643066, "val_acc": 52.0}
{"epoch": 31, "training_loss": 334.59058380126953, "training_acc": 55.0, "val_loss": 87.84292340278625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 248.5579319000244, "training_acc": 55.0, "val_loss": 79.06426787376404, "val_acc": 48.0}
{"epoch": 33, "training_loss": 268.36217498779297, "training_acc": 55.0, "val_loss": 122.35766649246216, "val_acc": 52.0}
{"epoch": 34, "training_loss": 230.69827270507812, "training_acc": 58.0, "val_loss": 26.630082726478577, "val_acc": 56.0}
{"epoch": 35, "training_loss": 134.1000633239746, "training_acc": 59.0, "val_loss": 26.58916711807251, "val_acc": 52.0}
{"epoch": 36, "training_loss": 123.55512237548828, "training_acc": 59.0, "val_loss": 54.99241352081299, "val_acc": 52.0}
{"epoch": 37, "training_loss": 138.9972710609436, "training_acc": 59.0, "val_loss": 66.11398458480835, "val_acc": 48.0}
{"epoch": 38, "training_loss": 208.72274827957153, "training_acc": 50.0, "val_loss": 152.79852151870728, "val_acc": 52.0}
{"epoch": 39, "training_loss": 490.5761013031006, "training_acc": 53.0, "val_loss": 26.433438062667847, "val_acc": 52.0}
{"epoch": 40, "training_loss": 137.72489738464355, "training_acc": 67.0, "val_loss": 58.13432335853577, "val_acc": 48.0}
{"epoch": 41, "training_loss": 294.68974018096924, "training_acc": 51.0, "val_loss": 170.2491283416748, "val_acc": 52.0}
{"epoch": 42, "training_loss": 348.3990671634674, "training_acc": 54.0, "val_loss": 84.05914306640625, "val_acc": 48.0}
{"epoch": 43, "training_loss": 328.70156049728394, "training_acc": 53.0, "val_loss": 111.43436431884766, "val_acc": 52.0}
{"epoch": 44, "training_loss": 175.95278310775757, "training_acc": 56.0, "val_loss": 73.34571480751038, "val_acc": 48.0}
{"epoch": 45, "training_loss": 278.56430292129517, "training_acc": 48.0, "val_loss": 173.6081838607788, "val_acc": 52.0}
{"epoch": 46, "training_loss": 507.2926368713379, "training_acc": 53.0, "val_loss": 59.972554445266724, "val_acc": 52.0}
{"epoch": 47, "training_loss": 418.7670593261719, "training_acc": 50.0, "val_loss": 203.3414602279663, "val_acc": 48.0}
{"epoch": 48, "training_loss": 622.1151052713394, "training_acc": 51.0, "val_loss": 193.4963822364807, "val_acc": 52.0}
{"epoch": 49, "training_loss": 624.3354740142822, "training_acc": 53.0, "val_loss": 94.33057904243469, "val_acc": 52.0}
{"epoch": 50, "training_loss": 304.37611198425293, "training_acc": 60.0, "val_loss": 208.66365432739258, "val_acc": 48.0}
{"epoch": 51, "training_loss": 687.6208896636963, "training_acc": 47.0, "val_loss": 165.410315990448, "val_acc": 52.0}
{"epoch": 52, "training_loss": 692.331226348877, "training_acc": 53.0, "val_loss": 191.9057846069336, "val_acc": 52.0}
{"epoch": 53, "training_loss": 444.29588985443115, "training_acc": 58.0, "val_loss": 113.52485418319702, "val_acc": 48.0}
{"epoch": 54, "training_loss": 350.4343857765198, "training_acc": 50.0, "val_loss": 158.0388903617859, "val_acc": 52.0}
{"epoch": 55, "training_loss": 469.36367416381836, "training_acc": 53.0, "val_loss": 58.96448493003845, "val_acc": 52.0}
{"epoch": 56, "training_loss": 251.4587516784668, "training_acc": 60.0, "val_loss": 106.40696287155151, "val_acc": 48.0}
{"epoch": 57, "training_loss": 316.004150390625, "training_acc": 58.0, "val_loss": 132.95069932937622, "val_acc": 52.0}
{"epoch": 58, "training_loss": 241.5390121936798, "training_acc": 60.0, "val_loss": 56.72888159751892, "val_acc": 52.0}
