"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 30575.943775177002, "training_acc": 46.0, "val_loss": 6381.733703613281, "val_acc": 52.0}
{"epoch": 1, "training_loss": 30989.734741210938, "training_acc": 53.0, "val_loss": 16527.572631835938, "val_acc": 48.0}
{"epoch": 2, "training_loss": 62201.322021484375, "training_acc": 47.0, "val_loss": 4581.49299621582, "val_acc": 48.0}
{"epoch": 3, "training_loss": 21674.135864257812, "training_acc": 51.0, "val_loss": 12070.093536376953, "val_acc": 52.0}
{"epoch": 4, "training_loss": 45858.27734375, "training_acc": 53.0, "val_loss": 10770.492553710938, "val_acc": 52.0}
{"epoch": 5, "training_loss": 31966.391845703125, "training_acc": 53.0, "val_loss": 1871.4908599853516, "val_acc": 48.0}
{"epoch": 6, "training_loss": 17248.426391601562, "training_acc": 47.0, "val_loss": 5516.741943359375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 18699.06787109375, "training_acc": 47.0, "val_loss": 3997.2145080566406, "val_acc": 52.0}
{"epoch": 8, "training_loss": 15586.674865722656, "training_acc": 53.0, "val_loss": 6931.0791015625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 22506.684509277344, "training_acc": 53.0, "val_loss": 873.3195304870605, "val_acc": 52.0}
{"epoch": 10, "training_loss": 9022.530395507812, "training_acc": 49.0, "val_loss": 6469.295501708984, "val_acc": 48.0}
{"epoch": 11, "training_loss": 24805.120849609375, "training_acc": 47.0, "val_loss": 1412.6626014709473, "val_acc": 48.0}
{"epoch": 12, "training_loss": 8992.366271972656, "training_acc": 49.0, "val_loss": 6724.507141113281, "val_acc": 52.0}
{"epoch": 13, "training_loss": 25836.369018554688, "training_acc": 53.0, "val_loss": 5015.397262573242, "val_acc": 52.0}
{"epoch": 14, "training_loss": 13387.769256591797, "training_acc": 52.0, "val_loss": 5068.773651123047, "val_acc": 48.0}
{"epoch": 15, "training_loss": 24630.320556640625, "training_acc": 47.0, "val_loss": 7504.206085205078, "val_acc": 48.0}
{"epoch": 16, "training_loss": 25383.38427734375, "training_acc": 47.0, "val_loss": 603.9819717407227, "val_acc": 60.0}
{"epoch": 17, "training_loss": 6376.558654785156, "training_acc": 56.0, "val_loss": 4699.2645263671875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 15524.051803588867, "training_acc": 53.0, "val_loss": 324.78628158569336, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4169.85693359375, "training_acc": 60.0, "val_loss": 2840.1973724365234, "val_acc": 48.0}
{"epoch": 20, "training_loss": 8728.22896194458, "training_acc": 46.0, "val_loss": 2735.285186767578, "val_acc": 52.0}
{"epoch": 21, "training_loss": 9280.877349853516, "training_acc": 53.0, "val_loss": 1397.1420288085938, "val_acc": 52.0}
{"epoch": 22, "training_loss": 5970.932769775391, "training_acc": 53.0, "val_loss": 2665.8037185668945, "val_acc": 48.0}
{"epoch": 23, "training_loss": 7948.315502166748, "training_acc": 52.0, "val_loss": 3206.5948486328125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11474.32470703125, "training_acc": 53.0, "val_loss": 3119.478988647461, "val_acc": 52.0}
{"epoch": 25, "training_loss": 7216.158744812012, "training_acc": 50.0, "val_loss": 1664.4020080566406, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5446.414825439453, "training_acc": 48.0, "val_loss": 2734.560203552246, "val_acc": 52.0}
{"epoch": 27, "training_loss": 9565.364868164062, "training_acc": 53.0, "val_loss": 2375.9889602661133, "val_acc": 52.0}
{"epoch": 28, "training_loss": 5544.541793823242, "training_acc": 55.0, "val_loss": 1675.5369186401367, "val_acc": 48.0}
{"epoch": 29, "training_loss": 5073.880241394043, "training_acc": 53.0, "val_loss": 3325.5985260009766, "val_acc": 52.0}
{"epoch": 30, "training_loss": 12501.086242675781, "training_acc": 53.0, "val_loss": 3084.451103210449, "val_acc": 52.0}
{"epoch": 31, "training_loss": 7663.95051574707, "training_acc": 52.0, "val_loss": 2115.3512954711914, "val_acc": 48.0}
{"epoch": 32, "training_loss": 7083.560089111328, "training_acc": 48.0, "val_loss": 1823.0888366699219, "val_acc": 52.0}
{"epoch": 33, "training_loss": 7554.403961181641, "training_acc": 55.0, "val_loss": 1187.7958297729492, "val_acc": 60.0}
{"epoch": 34, "training_loss": 3418.864700317383, "training_acc": 65.0, "val_loss": 2113.503837585449, "val_acc": 48.0}
{"epoch": 35, "training_loss": 6029.127700805664, "training_acc": 52.0, "val_loss": 2694.230079650879, "val_acc": 52.0}
{"epoch": 36, "training_loss": 9572.407836914062, "training_acc": 53.0, "val_loss": 1378.6436080932617, "val_acc": 52.0}
{"epoch": 37, "training_loss": 5654.4176025390625, "training_acc": 48.0, "val_loss": 2729.509162902832, "val_acc": 48.0}
