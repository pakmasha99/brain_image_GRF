"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 33282.428131103516, "training_acc": 45.0, "val_loss": 8073.200225830078, "val_acc": 52.0}
{"epoch": 1, "training_loss": 30063.102172851562, "training_acc": 55.0, "val_loss": 13963.386535644531, "val_acc": 48.0}
{"epoch": 2, "training_loss": 52040.045166015625, "training_acc": 47.0, "val_loss": 1986.612319946289, "val_acc": 48.0}
{"epoch": 3, "training_loss": 19026.822998046875, "training_acc": 47.0, "val_loss": 14345.884704589844, "val_acc": 52.0}
{"epoch": 4, "training_loss": 52384.417724609375, "training_acc": 53.0, "val_loss": 12340.636444091797, "val_acc": 52.0}
{"epoch": 5, "training_loss": 37345.10754394531, "training_acc": 53.0, "val_loss": 1000.4448890686035, "val_acc": 44.0}
{"epoch": 6, "training_loss": 11012.237426757812, "training_acc": 46.0, "val_loss": 4336.269378662109, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14099.51513671875, "training_acc": 48.0, "val_loss": 4761.93733215332, "val_acc": 52.0}
{"epoch": 8, "training_loss": 14853.602355957031, "training_acc": 55.0, "val_loss": 6218.93310546875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 13883.950775146484, "training_acc": 57.0, "val_loss": 1462.1247291564941, "val_acc": 44.0}
{"epoch": 10, "training_loss": 11351.340576171875, "training_acc": 46.0, "val_loss": 981.4105987548828, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5863.4718017578125, "training_acc": 59.0, "val_loss": 5183.494186401367, "val_acc": 52.0}
{"epoch": 12, "training_loss": 12654.586364746094, "training_acc": 52.0, "val_loss": 2125.673294067383, "val_acc": 52.0}
{"epoch": 13, "training_loss": 6738.212066650391, "training_acc": 50.0, "val_loss": 1687.1440887451172, "val_acc": 48.0}
{"epoch": 14, "training_loss": 6683.397109985352, "training_acc": 51.0, "val_loss": 2832.915496826172, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5733.565902709961, "training_acc": 52.0, "val_loss": 884.352970123291, "val_acc": 48.0}
{"epoch": 16, "training_loss": 4178.364013671875, "training_acc": 46.0, "val_loss": 2318.617630004883, "val_acc": 52.0}
{"epoch": 17, "training_loss": 6840.3809814453125, "training_acc": 53.0, "val_loss": 545.0336933135986, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3717.482940673828, "training_acc": 62.0, "val_loss": 2202.365493774414, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6687.428211212158, "training_acc": 58.0, "val_loss": 2064.0676498413086, "val_acc": 52.0}
{"epoch": 20, "training_loss": 6283.542083740234, "training_acc": 55.0, "val_loss": 1332.9051971435547, "val_acc": 48.0}
{"epoch": 21, "training_loss": 6002.3367919921875, "training_acc": 47.0, "val_loss": 1640.5977249145508, "val_acc": 52.0}
{"epoch": 22, "training_loss": 6233.071929931641, "training_acc": 53.0, "val_loss": 316.43004417419434, "val_acc": 48.0}
{"epoch": 23, "training_loss": 4494.466461181641, "training_acc": 53.0, "val_loss": 944.329833984375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 5476.826599121094, "training_acc": 49.0, "val_loss": 3070.71475982666, "val_acc": 52.0}
{"epoch": 25, "training_loss": 7076.663345336914, "training_acc": 52.0, "val_loss": 2245.9774017333984, "val_acc": 48.0}
{"epoch": 26, "training_loss": 12038.393676757812, "training_acc": 47.0, "val_loss": 1510.058307647705, "val_acc": 48.0}
{"epoch": 27, "training_loss": 8163.933502197266, "training_acc": 43.0, "val_loss": 4020.123291015625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 9954.029022216797, "training_acc": 53.0, "val_loss": 633.5545539855957, "val_acc": 48.0}
{"epoch": 29, "training_loss": 5212.2060546875, "training_acc": 48.0, "val_loss": 759.7148418426514, "val_acc": 48.0}
{"epoch": 30, "training_loss": 3090.8619079589844, "training_acc": 59.0, "val_loss": 2623.8969802856445, "val_acc": 52.0}
{"epoch": 31, "training_loss": 4284.6182861328125, "training_acc": 56.0, "val_loss": 731.9004535675049, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3832.8703384399414, "training_acc": 54.0, "val_loss": 2111.4452362060547, "val_acc": 52.0}
{"epoch": 33, "training_loss": 3168.8411827087402, "training_acc": 58.0, "val_loss": 722.5249290466309, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2483.599271774292, "training_acc": 58.0, "val_loss": 1540.2006149291992, "val_acc": 52.0}
{"epoch": 35, "training_loss": 2831.7111206054688, "training_acc": 57.0, "val_loss": 1014.6575927734375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 3266.9006938934326, "training_acc": 56.0, "val_loss": 1015.9494400024414, "val_acc": 52.0}
{"epoch": 37, "training_loss": 2331.0348739624023, "training_acc": 57.0, "val_loss": 216.0599946975708, "val_acc": 68.0}
{"epoch": 38, "training_loss": 1319.375862121582, "training_acc": 71.0, "val_loss": 313.00506591796875, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1699.448974609375, "training_acc": 60.0, "val_loss": 1687.2207641601562, "val_acc": 52.0}
{"epoch": 40, "training_loss": 3499.6785430908203, "training_acc": 56.0, "val_loss": 802.5029182434082, "val_acc": 48.0}
{"epoch": 41, "training_loss": 3568.8145866394043, "training_acc": 51.0, "val_loss": 1720.6695556640625, "val_acc": 52.0}
{"epoch": 42, "training_loss": 2751.50972366333, "training_acc": 57.0, "val_loss": 595.2304363250732, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2913.8872985839844, "training_acc": 58.0, "val_loss": 1258.5530281066895, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2323.58162689209, "training_acc": 53.0, "val_loss": 1303.2109260559082, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1907.3918266296387, "training_acc": 57.0, "val_loss": 386.9438648223877, "val_acc": 44.0}
{"epoch": 46, "training_loss": 2681.3719482421875, "training_acc": 53.0, "val_loss": 788.4301662445068, "val_acc": 52.0}
{"epoch": 47, "training_loss": 2012.4741821289062, "training_acc": 68.0, "val_loss": 229.3860673904419, "val_acc": 56.0}
{"epoch": 48, "training_loss": 2398.7247619628906, "training_acc": 60.0, "val_loss": 357.3939800262451, "val_acc": 52.0}
{"epoch": 49, "training_loss": 2483.0565032958984, "training_acc": 63.0, "val_loss": 404.6201229095459, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1680.9433898925781, "training_acc": 64.0, "val_loss": 153.98117303848267, "val_acc": 56.0}
{"epoch": 51, "training_loss": 633.9496078491211, "training_acc": 72.0, "val_loss": 1122.639274597168, "val_acc": 52.0}
{"epoch": 52, "training_loss": 2184.497917175293, "training_acc": 54.0, "val_loss": 270.13280391693115, "val_acc": 44.0}
{"epoch": 53, "training_loss": 489.6654758453369, "training_acc": 75.0, "val_loss": 329.2980670928955, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1749.070701599121, "training_acc": 58.0, "val_loss": 459.9645137786865, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1524.6988372802734, "training_acc": 66.0, "val_loss": 808.8947296142578, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1045.6004028320312, "training_acc": 68.0, "val_loss": 660.1936340332031, "val_acc": 48.0}
{"epoch": 57, "training_loss": 3105.3802490234375, "training_acc": 47.0, "val_loss": 527.6876926422119, "val_acc": 52.0}
{"epoch": 58, "training_loss": 2286.645065307617, "training_acc": 56.0, "val_loss": 1251.0388374328613, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1925.4924240112305, "training_acc": 59.0, "val_loss": 1517.5121307373047, "val_acc": 48.0}
{"epoch": 60, "training_loss": 4887.681976318359, "training_acc": 47.0, "val_loss": 2706.754493713379, "val_acc": 52.0}
{"epoch": 61, "training_loss": 8770.072631835938, "training_acc": 53.0, "val_loss": 1465.2392387390137, "val_acc": 52.0}
{"epoch": 62, "training_loss": 5938.5950927734375, "training_acc": 51.0, "val_loss": 3378.8330078125, "val_acc": 48.0}
{"epoch": 63, "training_loss": 9948.486770629883, "training_acc": 47.0, "val_loss": 3200.3631591796875, "val_acc": 52.0}
{"epoch": 64, "training_loss": 13168.087829589844, "training_acc": 53.0, "val_loss": 4173.253631591797, "val_acc": 52.0}
{"epoch": 65, "training_loss": 10110.9423828125, "training_acc": 53.0, "val_loss": 4153.206634521484, "val_acc": 48.0}
{"epoch": 66, "training_loss": 20171.81201171875, "training_acc": 47.0, "val_loss": 5861.413955688477, "val_acc": 48.0}
{"epoch": 67, "training_loss": 17604.996490478516, "training_acc": 47.0, "val_loss": 3448.8109588623047, "val_acc": 52.0}
{"epoch": 68, "training_loss": 17876.794311523438, "training_acc": 53.0, "val_loss": 6653.954315185547, "val_acc": 52.0}
{"epoch": 69, "training_loss": 18525.700134277344, "training_acc": 53.0, "val_loss": 445.1291561126709, "val_acc": 60.0}
