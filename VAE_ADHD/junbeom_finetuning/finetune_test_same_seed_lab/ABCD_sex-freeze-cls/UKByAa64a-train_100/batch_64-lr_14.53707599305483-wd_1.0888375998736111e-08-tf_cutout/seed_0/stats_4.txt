"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 36470.26402282715, "training_acc": 41.0, "val_loss": 8329.883575439453, "val_acc": 52.0}
{"epoch": 1, "training_loss": 33078.845703125, "training_acc": 51.0, "val_loss": 12664.5751953125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 46581.052978515625, "training_acc": 47.0, "val_loss": 1648.6780166625977, "val_acc": 48.0}
{"epoch": 3, "training_loss": 16754.67724609375, "training_acc": 49.0, "val_loss": 14099.4384765625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 55964.6611328125, "training_acc": 53.0, "val_loss": 12855.886840820312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 42055.267578125, "training_acc": 53.0, "val_loss": 880.1333427429199, "val_acc": 52.0}
{"epoch": 6, "training_loss": 15442.937133789062, "training_acc": 48.0, "val_loss": 13858.265686035156, "val_acc": 48.0}
{"epoch": 7, "training_loss": 58808.427001953125, "training_acc": 47.0, "val_loss": 13306.53076171875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 45879.335693359375, "training_acc": 47.0, "val_loss": 1518.6556816101074, "val_acc": 48.0}
{"epoch": 9, "training_loss": 13221.007446289062, "training_acc": 47.0, "val_loss": 11371.866607666016, "val_acc": 52.0}
{"epoch": 10, "training_loss": 47045.284423828125, "training_acc": 53.0, "val_loss": 12973.777770996094, "val_acc": 52.0}
{"epoch": 11, "training_loss": 47010.34948730469, "training_acc": 53.0, "val_loss": 5931.783676147461, "val_acc": 52.0}
{"epoch": 12, "training_loss": 16115.444854736328, "training_acc": 54.0, "val_loss": 5468.541717529297, "val_acc": 48.0}
{"epoch": 13, "training_loss": 24338.231811523438, "training_acc": 47.0, "val_loss": 6634.959411621094, "val_acc": 48.0}
{"epoch": 14, "training_loss": 20385.97052001953, "training_acc": 47.0, "val_loss": 2069.6340560913086, "val_acc": 52.0}
{"epoch": 15, "training_loss": 11851.594665527344, "training_acc": 53.0, "val_loss": 4906.138610839844, "val_acc": 52.0}
{"epoch": 16, "training_loss": 16182.546325683594, "training_acc": 53.0, "val_loss": 944.4700241088867, "val_acc": 48.0}
{"epoch": 17, "training_loss": 6490.487457275391, "training_acc": 49.0, "val_loss": 1513.0759239196777, "val_acc": 48.0}
{"epoch": 18, "training_loss": 6068.571975708008, "training_acc": 49.0, "val_loss": 2422.075653076172, "val_acc": 52.0}
{"epoch": 19, "training_loss": 7489.9912109375, "training_acc": 55.0, "val_loss": 1616.1821365356445, "val_acc": 48.0}
{"epoch": 20, "training_loss": 5232.227111816406, "training_acc": 50.0, "val_loss": 556.8196296691895, "val_acc": 56.0}
{"epoch": 21, "training_loss": 3639.1912384033203, "training_acc": 53.0, "val_loss": 394.1843271255493, "val_acc": 56.0}
{"epoch": 22, "training_loss": 2318.7010650634766, "training_acc": 61.0, "val_loss": 346.8691825866699, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3917.746124267578, "training_acc": 54.0, "val_loss": 982.7332496643066, "val_acc": 52.0}
{"epoch": 24, "training_loss": 4454.69660949707, "training_acc": 53.0, "val_loss": 1149.742031097412, "val_acc": 48.0}
{"epoch": 25, "training_loss": 4206.3123779296875, "training_acc": 51.0, "val_loss": 1990.835952758789, "val_acc": 52.0}
{"epoch": 26, "training_loss": 4978.546142578125, "training_acc": 57.0, "val_loss": 2736.9224548339844, "val_acc": 48.0}
{"epoch": 27, "training_loss": 11557.334655761719, "training_acc": 47.0, "val_loss": 1644.368553161621, "val_acc": 48.0}
{"epoch": 28, "training_loss": 6596.462188720703, "training_acc": 54.0, "val_loss": 3534.3765258789062, "val_acc": 52.0}
{"epoch": 29, "training_loss": 12320.339263916016, "training_acc": 53.0, "val_loss": 195.00443935394287, "val_acc": 56.0}
{"epoch": 30, "training_loss": 6410.750671386719, "training_acc": 52.0, "val_loss": 3126.685905456543, "val_acc": 48.0}
{"epoch": 31, "training_loss": 7577.507099151611, "training_acc": 54.0, "val_loss": 3522.482681274414, "val_acc": 52.0}
{"epoch": 32, "training_loss": 16162.3193359375, "training_acc": 53.0, "val_loss": 4465.495681762695, "val_acc": 52.0}
{"epoch": 33, "training_loss": 12601.138092041016, "training_acc": 53.0, "val_loss": 3203.528594970703, "val_acc": 48.0}
{"epoch": 34, "training_loss": 15162.639892578125, "training_acc": 47.0, "val_loss": 4665.829849243164, "val_acc": 48.0}
{"epoch": 35, "training_loss": 14167.613830566406, "training_acc": 47.0, "val_loss": 3313.937759399414, "val_acc": 52.0}
{"epoch": 36, "training_loss": 16945.306518554688, "training_acc": 53.0, "val_loss": 5258.405303955078, "val_acc": 52.0}
{"epoch": 37, "training_loss": 16473.274383544922, "training_acc": 53.0, "val_loss": 1804.9083709716797, "val_acc": 48.0}
{"epoch": 38, "training_loss": 10199.712463378906, "training_acc": 47.0, "val_loss": 2735.153579711914, "val_acc": 48.0}
{"epoch": 39, "training_loss": 8339.144119262695, "training_acc": 45.0, "val_loss": 1907.025146484375, "val_acc": 52.0}
{"epoch": 40, "training_loss": 5012.915912628174, "training_acc": 57.0, "val_loss": 1282.7841758728027, "val_acc": 48.0}
{"epoch": 41, "training_loss": 3712.3877029418945, "training_acc": 53.0, "val_loss": 1010.0723266601562, "val_acc": 52.0}
{"epoch": 42, "training_loss": 2813.670066833496, "training_acc": 56.0, "val_loss": 1017.6424026489258, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2591.514747619629, "training_acc": 56.0, "val_loss": 974.0290641784668, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2661.1927185058594, "training_acc": 57.0, "val_loss": 1258.6155891418457, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3420.402900695801, "training_acc": 54.0, "val_loss": 1344.76318359375, "val_acc": 52.0}
{"epoch": 46, "training_loss": 3864.7530670166016, "training_acc": 57.0, "val_loss": 1227.8695106506348, "val_acc": 48.0}
{"epoch": 47, "training_loss": 3879.830276489258, "training_acc": 48.0, "val_loss": 1204.3340682983398, "val_acc": 52.0}
{"epoch": 48, "training_loss": 3943.626174926758, "training_acc": 56.0, "val_loss": 358.51314067840576, "val_acc": 48.0}
