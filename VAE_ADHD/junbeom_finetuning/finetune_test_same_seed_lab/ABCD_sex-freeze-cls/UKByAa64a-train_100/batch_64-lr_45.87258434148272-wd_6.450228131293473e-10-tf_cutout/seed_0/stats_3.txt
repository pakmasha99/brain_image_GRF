"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 77556.50507354736, "training_acc": 50.0, "val_loss": 13558.323669433594, "val_acc": 52.0}
{"epoch": 1, "training_loss": 94057.04296875, "training_acc": 53.0, "val_loss": 60898.73046875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 230361.14892578125, "training_acc": 47.0, "val_loss": 20169.80743408203, "val_acc": 48.0}
{"epoch": 3, "training_loss": 64277.38708496094, "training_acc": 55.0, "val_loss": 34430.377197265625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 126258.654296875, "training_acc": 53.0, "val_loss": 30376.800537109375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 79666.75573730469, "training_acc": 53.0, "val_loss": 12083.321380615234, "val_acc": 48.0}
{"epoch": 6, "training_loss": 78881.53955078125, "training_acc": 47.0, "val_loss": 20777.020263671875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 74318.62353515625, "training_acc": 47.0, "val_loss": 12840.354919433594, "val_acc": 52.0}
{"epoch": 8, "training_loss": 52171.139892578125, "training_acc": 50.0, "val_loss": 24748.29559326172, "val_acc": 52.0}
{"epoch": 9, "training_loss": 73306.0234375, "training_acc": 53.0, "val_loss": 5227.681350708008, "val_acc": 52.0}
{"epoch": 10, "training_loss": 20335.746826171875, "training_acc": 59.0, "val_loss": 18222.55401611328, "val_acc": 48.0}
{"epoch": 11, "training_loss": 77409.78100585938, "training_acc": 47.0, "val_loss": 3837.002944946289, "val_acc": 48.0}
{"epoch": 12, "training_loss": 27034.108764648438, "training_acc": 54.0, "val_loss": 23618.07098388672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 79839.078125, "training_acc": 53.0, "val_loss": 18489.71405029297, "val_acc": 52.0}
{"epoch": 14, "training_loss": 38672.006103515625, "training_acc": 57.0, "val_loss": 12097.977447509766, "val_acc": 48.0}
{"epoch": 15, "training_loss": 70902.34399414062, "training_acc": 47.0, "val_loss": 15570.877075195312, "val_acc": 48.0}
{"epoch": 16, "training_loss": 53749.35021972656, "training_acc": 47.0, "val_loss": 13390.933227539062, "val_acc": 52.0}
{"epoch": 17, "training_loss": 45666.514892578125, "training_acc": 52.0, "val_loss": 21363.726806640625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 59329.024658203125, "training_acc": 53.0, "val_loss": 2908.308982849121, "val_acc": 44.0}
{"epoch": 19, "training_loss": 24417.845458984375, "training_acc": 55.0, "val_loss": 12881.158447265625, "val_acc": 48.0}
{"epoch": 20, "training_loss": 50029.766845703125, "training_acc": 47.0, "val_loss": 7322.161102294922, "val_acc": 52.0}
{"epoch": 21, "training_loss": 24803.0283203125, "training_acc": 53.0, "val_loss": 10149.52163696289, "val_acc": 52.0}
{"epoch": 22, "training_loss": 20799.263916015625, "training_acc": 57.0, "val_loss": 5252.192687988281, "val_acc": 48.0}
{"epoch": 23, "training_loss": 23623.85675048828, "training_acc": 47.0, "val_loss": 6705.3924560546875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 19303.383544921875, "training_acc": 53.0, "val_loss": 3060.831069946289, "val_acc": 52.0}
{"epoch": 25, "training_loss": 12728.329162597656, "training_acc": 54.0, "val_loss": 6003.688430786133, "val_acc": 48.0}
{"epoch": 26, "training_loss": 19927.29559326172, "training_acc": 52.0, "val_loss": 6390.698623657227, "val_acc": 52.0}
{"epoch": 27, "training_loss": 15970.089904785156, "training_acc": 51.0, "val_loss": 4135.8123779296875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 17159.10662841797, "training_acc": 48.0, "val_loss": 3983.2473754882812, "val_acc": 52.0}
{"epoch": 29, "training_loss": 16448.411010742188, "training_acc": 54.0, "val_loss": 953.6020278930664, "val_acc": 60.0}
{"epoch": 30, "training_loss": 10241.079467773438, "training_acc": 56.0, "val_loss": 1793.0404663085938, "val_acc": 52.0}
{"epoch": 31, "training_loss": 8231.914672851562, "training_acc": 63.0, "val_loss": 3255.710220336914, "val_acc": 48.0}
{"epoch": 32, "training_loss": 10917.939651489258, "training_acc": 48.0, "val_loss": 7098.954010009766, "val_acc": 52.0}
{"epoch": 33, "training_loss": 20039.513793945312, "training_acc": 53.0, "val_loss": 1586.5983963012695, "val_acc": 44.0}
{"epoch": 34, "training_loss": 8690.827270507812, "training_acc": 61.0, "val_loss": 1561.1088752746582, "val_acc": 44.0}
{"epoch": 35, "training_loss": 9722.510803222656, "training_acc": 64.0, "val_loss": 6679.392242431641, "val_acc": 52.0}
{"epoch": 36, "training_loss": 9893.962112426758, "training_acc": 61.0, "val_loss": 3233.120346069336, "val_acc": 52.0}
{"epoch": 37, "training_loss": 12011.013397216797, "training_acc": 51.0, "val_loss": 4478.854751586914, "val_acc": 52.0}
{"epoch": 38, "training_loss": 6974.165634155273, "training_acc": 62.0, "val_loss": 1784.950828552246, "val_acc": 48.0}
{"epoch": 39, "training_loss": 4434.104156494141, "training_acc": 64.0, "val_loss": 1352.003288269043, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3076.771484375, "training_acc": 62.0, "val_loss": 698.9452362060547, "val_acc": 44.0}
{"epoch": 41, "training_loss": 2496.4209518432617, "training_acc": 72.0, "val_loss": 1363.2678031921387, "val_acc": 56.0}
{"epoch": 42, "training_loss": 3054.7433166503906, "training_acc": 66.0, "val_loss": 908.8988304138184, "val_acc": 56.0}
{"epoch": 43, "training_loss": 2353.7179260253906, "training_acc": 72.0, "val_loss": 2961.1679077148438, "val_acc": 48.0}
{"epoch": 44, "training_loss": 8610.271961212158, "training_acc": 57.0, "val_loss": 5949.711227416992, "val_acc": 52.0}
{"epoch": 45, "training_loss": 14790.400787353516, "training_acc": 53.0, "val_loss": 6937.4420166015625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 27068.15167236328, "training_acc": 47.0, "val_loss": 1211.7039680480957, "val_acc": 52.0}
{"epoch": 47, "training_loss": 5025.522888183594, "training_acc": 67.0, "val_loss": 786.6927146911621, "val_acc": 52.0}
{"epoch": 48, "training_loss": 3548.832176208496, "training_acc": 57.0, "val_loss": 1303.8471221923828, "val_acc": 52.0}
{"epoch": 49, "training_loss": 5492.47314453125, "training_acc": 56.0, "val_loss": 533.1717014312744, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1705.6668319702148, "training_acc": 74.0, "val_loss": 2490.7487869262695, "val_acc": 52.0}
{"epoch": 51, "training_loss": 3154.393409729004, "training_acc": 66.0, "val_loss": 1074.3767738342285, "val_acc": 52.0}
{"epoch": 52, "training_loss": 7599.813293457031, "training_acc": 56.0, "val_loss": 3189.7233963012695, "val_acc": 52.0}
{"epoch": 53, "training_loss": 13289.717224121094, "training_acc": 51.0, "val_loss": 5528.644561767578, "val_acc": 48.0}
{"epoch": 54, "training_loss": 14301.077545166016, "training_acc": 59.0, "val_loss": 4474.252700805664, "val_acc": 52.0}
{"epoch": 55, "training_loss": 9280.866882324219, "training_acc": 58.0, "val_loss": 422.79391288757324, "val_acc": 56.0}
{"epoch": 56, "training_loss": 4698.032653808594, "training_acc": 62.0, "val_loss": 900.5859375, "val_acc": 56.0}
{"epoch": 57, "training_loss": 2906.584632873535, "training_acc": 66.0, "val_loss": 509.14578437805176, "val_acc": 52.0}
{"epoch": 58, "training_loss": 2020.3945083618164, "training_acc": 68.0, "val_loss": 915.5592918395996, "val_acc": 56.0}
{"epoch": 59, "training_loss": 2950.1554107666016, "training_acc": 68.0, "val_loss": 1202.0011901855469, "val_acc": 48.0}
{"epoch": 60, "training_loss": 3390.468231201172, "training_acc": 66.0, "val_loss": 5315.476989746094, "val_acc": 52.0}
{"epoch": 61, "training_loss": 14158.147583007812, "training_acc": 53.0, "val_loss": 4459.532928466797, "val_acc": 48.0}
{"epoch": 62, "training_loss": 14993.871337890625, "training_acc": 47.0, "val_loss": 6300.624847412109, "val_acc": 52.0}
{"epoch": 63, "training_loss": 20460.03143310547, "training_acc": 53.0, "val_loss": 476.6866683959961, "val_acc": 52.0}
{"epoch": 64, "training_loss": 10472.063842773438, "training_acc": 64.0, "val_loss": 1531.2162399291992, "val_acc": 52.0}
{"epoch": 65, "training_loss": 14202.92236328125, "training_acc": 54.0, "val_loss": 11341.975402832031, "val_acc": 52.0}
{"epoch": 66, "training_loss": 28788.19903564453, "training_acc": 53.0, "val_loss": 7626.6143798828125, "val_acc": 48.0}
{"epoch": 67, "training_loss": 33786.59826660156, "training_acc": 47.0, "val_loss": 5247.632598876953, "val_acc": 48.0}
{"epoch": 68, "training_loss": 21537.30450439453, "training_acc": 51.0, "val_loss": 12817.709350585938, "val_acc": 52.0}
{"epoch": 69, "training_loss": 38161.58044433594, "training_acc": 53.0, "val_loss": 1130.3959846496582, "val_acc": 60.0}
{"epoch": 70, "training_loss": 12628.750610351562, "training_acc": 56.0, "val_loss": 1218.1340217590332, "val_acc": 56.0}
{"epoch": 71, "training_loss": 8485.454772949219, "training_acc": 70.0, "val_loss": 8228.279113769531, "val_acc": 52.0}
{"epoch": 72, "training_loss": 15423.244171142578, "training_acc": 58.0, "val_loss": 7190.284729003906, "val_acc": 48.0}
{"epoch": 73, "training_loss": 26842.639770507812, "training_acc": 46.0, "val_loss": 3187.7262115478516, "val_acc": 48.0}
{"epoch": 74, "training_loss": 6604.797454833984, "training_acc": 62.0, "val_loss": 1342.3049926757812, "val_acc": 52.0}
