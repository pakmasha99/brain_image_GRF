"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2372.8948364257812, "training_acc": 45.0, "val_loss": 1484.8730087280273, "val_acc": 52.0}
{"epoch": 1, "training_loss": 6180.828826904297, "training_acc": 53.0, "val_loss": 325.6126642227173, "val_acc": 40.0}
{"epoch": 2, "training_loss": 2829.734848022461, "training_acc": 49.0, "val_loss": 1691.1808013916016, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4209.037956237793, "training_acc": 54.0, "val_loss": 751.8784999847412, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4029.291000366211, "training_acc": 53.0, "val_loss": 744.1993236541748, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2428.574951171875, "training_acc": 54.0, "val_loss": 879.3050765991211, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2526.8366775512695, "training_acc": 49.0, "val_loss": 162.98333406448364, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1776.924903869629, "training_acc": 52.0, "val_loss": 586.9760036468506, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1719.3953876495361, "training_acc": 49.0, "val_loss": 610.9292030334473, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2067.99210357666, "training_acc": 47.0, "val_loss": 317.65637397766113, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1354.8533096313477, "training_acc": 53.0, "val_loss": 67.0263946056366, "val_acc": 60.0}
{"epoch": 11, "training_loss": 789.7658462524414, "training_acc": 60.0, "val_loss": 183.88090133666992, "val_acc": 44.0}
{"epoch": 12, "training_loss": 1338.5605850219727, "training_acc": 48.0, "val_loss": 691.8357849121094, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1900.042552947998, "training_acc": 56.0, "val_loss": 229.64928150177002, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1650.3965759277344, "training_acc": 47.0, "val_loss": 103.2671570777893, "val_acc": 60.0}
{"epoch": 15, "training_loss": 735.6777191162109, "training_acc": 55.0, "val_loss": 303.9325714111328, "val_acc": 52.0}
{"epoch": 16, "training_loss": 940.508731842041, "training_acc": 53.0, "val_loss": 159.1680884361267, "val_acc": 44.0}
{"epoch": 17, "training_loss": 947.8059349060059, "training_acc": 49.0, "val_loss": 370.1476573944092, "val_acc": 52.0}
{"epoch": 18, "training_loss": 868.6522235870361, "training_acc": 57.0, "val_loss": 444.34356689453125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1276.406826019287, "training_acc": 47.0, "val_loss": 358.48350524902344, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1296.5823516845703, "training_acc": 53.0, "val_loss": 65.08460640907288, "val_acc": 44.0}
{"epoch": 21, "training_loss": 766.2194213867188, "training_acc": 57.0, "val_loss": 235.08455753326416, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1110.1516952514648, "training_acc": 51.0, "val_loss": 497.39394187927246, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1364.9372329711914, "training_acc": 54.0, "val_loss": 677.3102760314941, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2794.908966064453, "training_acc": 47.0, "val_loss": 582.3234558105469, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1510.8533515930176, "training_acc": 56.0, "val_loss": 612.3179912567139, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2123.0094299316406, "training_acc": 53.0, "val_loss": 87.02079653739929, "val_acc": 52.0}
{"epoch": 27, "training_loss": 775.4802474975586, "training_acc": 55.0, "val_loss": 519.9345588684082, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1314.123324394226, "training_acc": 57.0, "val_loss": 392.85359382629395, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1156.498987197876, "training_acc": 54.0, "val_loss": 301.79619789123535, "val_acc": 48.0}
{"epoch": 30, "training_loss": 928.0954933166504, "training_acc": 48.0, "val_loss": 264.98727798461914, "val_acc": 52.0}
{"epoch": 31, "training_loss": 847.1794700622559, "training_acc": 54.0, "val_loss": 148.45315217971802, "val_acc": 44.0}
{"epoch": 32, "training_loss": 541.8899078369141, "training_acc": 50.0, "val_loss": 380.75780868530273, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1326.780574798584, "training_acc": 53.0, "val_loss": 71.77362442016602, "val_acc": 56.0}
{"epoch": 34, "training_loss": 561.5616836547852, "training_acc": 66.0, "val_loss": 312.8124713897705, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1122.6703453063965, "training_acc": 48.0, "val_loss": 303.3897399902344, "val_acc": 52.0}
{"epoch": 36, "training_loss": 745.7317581176758, "training_acc": 53.0, "val_loss": 72.37064838409424, "val_acc": 52.0}
{"epoch": 37, "training_loss": 247.45970153808594, "training_acc": 60.0, "val_loss": 60.835641622543335, "val_acc": 56.0}
{"epoch": 38, "training_loss": 139.01000690460205, "training_acc": 77.0, "val_loss": 198.47062826156616, "val_acc": 52.0}
{"epoch": 39, "training_loss": 358.14454078674316, "training_acc": 66.0, "val_loss": 146.30706310272217, "val_acc": 48.0}
{"epoch": 40, "training_loss": 518.1902122497559, "training_acc": 53.0, "val_loss": 121.45715951919556, "val_acc": 52.0}
{"epoch": 41, "training_loss": 569.1703224182129, "training_acc": 55.0, "val_loss": 113.3516788482666, "val_acc": 44.0}
{"epoch": 42, "training_loss": 766.0601005554199, "training_acc": 53.0, "val_loss": 454.9987316131592, "val_acc": 52.0}
{"epoch": 43, "training_loss": 904.3981828689575, "training_acc": 58.0, "val_loss": 484.93504524230957, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1822.2052307128906, "training_acc": 47.0, "val_loss": 140.61474800109863, "val_acc": 52.0}
{"epoch": 45, "training_loss": 576.9507942199707, "training_acc": 56.0, "val_loss": 62.482017278671265, "val_acc": 68.0}
{"epoch": 46, "training_loss": 324.24445152282715, "training_acc": 61.0, "val_loss": 259.7238779067993, "val_acc": 52.0}
{"epoch": 47, "training_loss": 646.9209537506104, "training_acc": 55.0, "val_loss": 247.03021049499512, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1086.2887382507324, "training_acc": 47.0, "val_loss": 332.6829433441162, "val_acc": 52.0}
{"epoch": 49, "training_loss": 965.10888671875, "training_acc": 53.0, "val_loss": 60.41792035102844, "val_acc": 56.0}
{"epoch": 50, "training_loss": 294.40526008605957, "training_acc": 61.0, "val_loss": 204.09879684448242, "val_acc": 52.0}
{"epoch": 51, "training_loss": 454.325532913208, "training_acc": 57.0, "val_loss": 310.9185457229614, "val_acc": 48.0}
{"epoch": 52, "training_loss": 1048.5886306762695, "training_acc": 47.0, "val_loss": 348.5325336456299, "val_acc": 52.0}
{"epoch": 53, "training_loss": 1192.5043449401855, "training_acc": 53.0, "val_loss": 90.01221060752869, "val_acc": 56.0}
{"epoch": 54, "training_loss": 867.9777603149414, "training_acc": 57.0, "val_loss": 369.6057081222534, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1027.4118385314941, "training_acc": 53.0, "val_loss": 379.90002632141113, "val_acc": 52.0}
{"epoch": 56, "training_loss": 888.6903133392334, "training_acc": 60.0, "val_loss": 442.08717346191406, "val_acc": 48.0}
{"epoch": 57, "training_loss": 1487.4724502563477, "training_acc": 47.0, "val_loss": 136.23260259628296, "val_acc": 60.0}
{"epoch": 58, "training_loss": 579.8511619567871, "training_acc": 62.0, "val_loss": 89.47988152503967, "val_acc": 52.0}
{"epoch": 59, "training_loss": 449.81160736083984, "training_acc": 64.0, "val_loss": 79.23914790153503, "val_acc": 56.0}
{"epoch": 60, "training_loss": 497.7282371520996, "training_acc": 60.0, "val_loss": 68.17018985748291, "val_acc": 60.0}
{"epoch": 61, "training_loss": 273.1849193572998, "training_acc": 71.0, "val_loss": 100.37329196929932, "val_acc": 56.0}
{"epoch": 62, "training_loss": 120.26981592178345, "training_acc": 78.0, "val_loss": 67.18252301216125, "val_acc": 64.0}
{"epoch": 63, "training_loss": 89.56357479095459, "training_acc": 82.0, "val_loss": 120.99454402923584, "val_acc": 60.0}
{"epoch": 64, "training_loss": 277.18065547943115, "training_acc": 59.0, "val_loss": 79.411780834198, "val_acc": 60.0}
{"epoch": 65, "training_loss": 177.41524600982666, "training_acc": 72.0, "val_loss": 126.4545202255249, "val_acc": 44.0}
{"epoch": 66, "training_loss": 229.46442341804504, "training_acc": 70.0, "val_loss": 234.33194160461426, "val_acc": 52.0}
{"epoch": 67, "training_loss": 376.7721880674362, "training_acc": 72.0, "val_loss": 106.20077848434448, "val_acc": 44.0}
{"epoch": 68, "training_loss": 309.7055025100708, "training_acc": 58.0, "val_loss": 71.81930541992188, "val_acc": 56.0}
