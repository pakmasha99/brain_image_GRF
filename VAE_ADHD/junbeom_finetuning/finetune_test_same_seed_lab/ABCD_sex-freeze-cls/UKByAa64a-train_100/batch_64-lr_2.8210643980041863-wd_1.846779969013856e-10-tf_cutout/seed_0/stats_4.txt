"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1676.6031875610352, "training_acc": 53.0, "val_loss": 2011.5446090698242, "val_acc": 48.0}
{"epoch": 1, "training_loss": 7425.597610473633, "training_acc": 47.0, "val_loss": 316.5355443954468, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1744.814353942871, "training_acc": 59.0, "val_loss": 350.00970363616943, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2252.740234375, "training_acc": 50.0, "val_loss": 844.3904876708984, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2654.393756866455, "training_acc": 41.0, "val_loss": 289.8761034011841, "val_acc": 48.0}
{"epoch": 5, "training_loss": 985.6560020446777, "training_acc": 51.0, "val_loss": 113.1197452545166, "val_acc": 40.0}
{"epoch": 6, "training_loss": 561.4786949157715, "training_acc": 53.0, "val_loss": 103.96627187728882, "val_acc": 36.0}
{"epoch": 7, "training_loss": 523.4231605529785, "training_acc": 54.0, "val_loss": 107.60051012039185, "val_acc": 52.0}
{"epoch": 8, "training_loss": 387.1552791595459, "training_acc": 62.0, "val_loss": 209.24928188323975, "val_acc": 44.0}
{"epoch": 9, "training_loss": 604.5483989715576, "training_acc": 51.0, "val_loss": 111.93103790283203, "val_acc": 56.0}
{"epoch": 10, "training_loss": 305.00227546691895, "training_acc": 64.0, "val_loss": 93.47880482673645, "val_acc": 44.0}
{"epoch": 11, "training_loss": 297.3799991607666, "training_acc": 60.0, "val_loss": 103.822922706604, "val_acc": 56.0}
{"epoch": 12, "training_loss": 618.6044692993164, "training_acc": 50.0, "val_loss": 85.96819043159485, "val_acc": 60.0}
{"epoch": 13, "training_loss": 496.82312393188477, "training_acc": 58.0, "val_loss": 250.82907676696777, "val_acc": 48.0}
{"epoch": 14, "training_loss": 628.0594258308411, "training_acc": 56.0, "val_loss": 91.19020104408264, "val_acc": 60.0}
{"epoch": 15, "training_loss": 497.26455307006836, "training_acc": 51.0, "val_loss": 197.24420309066772, "val_acc": 52.0}
{"epoch": 16, "training_loss": 538.1302785873413, "training_acc": 56.0, "val_loss": 474.3501663208008, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1598.3122482299805, "training_acc": 47.0, "val_loss": 406.77714347839355, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1713.267723083496, "training_acc": 53.0, "val_loss": 209.83054637908936, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1328.1877670288086, "training_acc": 51.0, "val_loss": 863.4772300720215, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2656.312515258789, "training_acc": 49.0, "val_loss": 458.2252025604248, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2002.0375671386719, "training_acc": 53.0, "val_loss": 550.3553867340088, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1691.0490169525146, "training_acc": 50.0, "val_loss": 571.1402893066406, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1910.928482055664, "training_acc": 49.0, "val_loss": 210.23972034454346, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1111.6536254882812, "training_acc": 58.0, "val_loss": 74.91257190704346, "val_acc": 48.0}
{"epoch": 25, "training_loss": 641.5511856079102, "training_acc": 63.0, "val_loss": 318.0553436279297, "val_acc": 48.0}
{"epoch": 26, "training_loss": 922.9038238525391, "training_acc": 54.0, "val_loss": 297.46246337890625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 875.7099208831787, "training_acc": 47.0, "val_loss": 55.338311195373535, "val_acc": 52.0}
{"epoch": 28, "training_loss": 314.19249534606934, "training_acc": 57.0, "val_loss": 115.09923934936523, "val_acc": 52.0}
{"epoch": 29, "training_loss": 327.24205493927, "training_acc": 65.0, "val_loss": 149.9744415283203, "val_acc": 48.0}
{"epoch": 30, "training_loss": 347.945837020874, "training_acc": 59.0, "val_loss": 66.17489457130432, "val_acc": 64.0}
{"epoch": 31, "training_loss": 193.35128784179688, "training_acc": 63.0, "val_loss": 116.39975309371948, "val_acc": 48.0}
{"epoch": 32, "training_loss": 312.92302417755127, "training_acc": 58.0, "val_loss": 107.8208327293396, "val_acc": 44.0}
{"epoch": 33, "training_loss": 210.9208664894104, "training_acc": 67.0, "val_loss": 50.75250267982483, "val_acc": 48.0}
{"epoch": 34, "training_loss": 231.1925859451294, "training_acc": 71.0, "val_loss": 92.36646890640259, "val_acc": 56.0}
{"epoch": 35, "training_loss": 170.08167362213135, "training_acc": 65.0, "val_loss": 335.4311466217041, "val_acc": 48.0}
{"epoch": 36, "training_loss": 740.70237159729, "training_acc": 48.0, "val_loss": 488.08140754699707, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1916.7432022094727, "training_acc": 53.0, "val_loss": 175.68403482437134, "val_acc": 52.0}
{"epoch": 38, "training_loss": 871.5435791015625, "training_acc": 64.0, "val_loss": 885.6904983520508, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2830.675079345703, "training_acc": 47.0, "val_loss": 325.91631412506104, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1346.8842124938965, "training_acc": 53.0, "val_loss": 200.63469409942627, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1269.8505630493164, "training_acc": 47.0, "val_loss": 602.2006034851074, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1661.6454253196716, "training_acc": 51.0, "val_loss": 320.84033489227295, "val_acc": 52.0}
{"epoch": 43, "training_loss": 903.9702491760254, "training_acc": 52.0, "val_loss": 495.76687812805176, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1659.2438354492188, "training_acc": 47.0, "val_loss": 100.03268718719482, "val_acc": 56.0}
{"epoch": 45, "training_loss": 463.8675727844238, "training_acc": 59.0, "val_loss": 186.05992794036865, "val_acc": 48.0}
{"epoch": 46, "training_loss": 345.8916254043579, "training_acc": 57.0, "val_loss": 176.26268863677979, "val_acc": 52.0}
{"epoch": 47, "training_loss": 503.35346698760986, "training_acc": 57.0, "val_loss": 80.43230175971985, "val_acc": 44.0}
{"epoch": 48, "training_loss": 361.2469882965088, "training_acc": 61.0, "val_loss": 269.69847679138184, "val_acc": 48.0}
{"epoch": 49, "training_loss": 539.5674448013306, "training_acc": 55.0, "val_loss": 334.34553146362305, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1196.313648223877, "training_acc": 53.0, "val_loss": 272.75726795196533, "val_acc": 48.0}
{"epoch": 51, "training_loss": 723.6298007965088, "training_acc": 47.0, "val_loss": 273.66654872894287, "val_acc": 52.0}
{"epoch": 52, "training_loss": 874.4340209960938, "training_acc": 53.0, "val_loss": 202.34575271606445, "val_acc": 40.0}
