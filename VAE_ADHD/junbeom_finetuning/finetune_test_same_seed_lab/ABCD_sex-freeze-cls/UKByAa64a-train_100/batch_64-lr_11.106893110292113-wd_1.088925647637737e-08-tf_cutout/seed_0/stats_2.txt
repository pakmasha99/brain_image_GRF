"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 30616.020225524902, "training_acc": 53.0, "val_loss": 6012.958908081055, "val_acc": 52.0}
{"epoch": 1, "training_loss": 30709.57470703125, "training_acc": 41.0, "val_loss": 9943.740844726562, "val_acc": 48.0}
{"epoch": 2, "training_loss": 36265.97912597656, "training_acc": 47.0, "val_loss": 2073.1231689453125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 15538.227172851562, "training_acc": 41.0, "val_loss": 8721.58203125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 33432.967041015625, "training_acc": 53.0, "val_loss": 7148.760223388672, "val_acc": 52.0}
{"epoch": 5, "training_loss": 22162.587158203125, "training_acc": 53.0, "val_loss": 1584.0080261230469, "val_acc": 48.0}
{"epoch": 6, "training_loss": 10280.417724609375, "training_acc": 47.0, "val_loss": 3774.950408935547, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12235.27278137207, "training_acc": 47.0, "val_loss": 2742.009735107422, "val_acc": 52.0}
{"epoch": 8, "training_loss": 12379.675842285156, "training_acc": 53.0, "val_loss": 4097.4822998046875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 12867.669738769531, "training_acc": 53.0, "val_loss": 1339.460563659668, "val_acc": 48.0}
{"epoch": 10, "training_loss": 6816.105926513672, "training_acc": 47.0, "val_loss": 1557.9957962036133, "val_acc": 48.0}
{"epoch": 11, "training_loss": 4582.78702545166, "training_acc": 54.0, "val_loss": 1678.2533645629883, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5131.0642013549805, "training_acc": 51.0, "val_loss": 1698.9824295043945, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6753.136260986328, "training_acc": 47.0, "val_loss": 234.356951713562, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3410.9727478027344, "training_acc": 59.0, "val_loss": 1574.215030670166, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3978.270378112793, "training_acc": 55.0, "val_loss": 941.9610023498535, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2947.538055419922, "training_acc": 47.0, "val_loss": 813.4580612182617, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2205.9389972686768, "training_acc": 60.0, "val_loss": 254.6544313430786, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1237.1222610473633, "training_acc": 61.0, "val_loss": 190.03219604492188, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1167.865810394287, "training_acc": 60.0, "val_loss": 1343.2147979736328, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3673.5737838745117, "training_acc": 53.0, "val_loss": 543.4077739715576, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1921.9718952178955, "training_acc": 52.0, "val_loss": 771.0687160491943, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1548.0020904541016, "training_acc": 55.0, "val_loss": 504.55846786499023, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1688.8227920532227, "training_acc": 50.0, "val_loss": 750.2090930938721, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1743.035587310791, "training_acc": 63.0, "val_loss": 1214.240837097168, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3852.203567504883, "training_acc": 47.0, "val_loss": 1992.1194076538086, "val_acc": 52.0}
{"epoch": 26, "training_loss": 7764.101104736328, "training_acc": 53.0, "val_loss": 1584.7355842590332, "val_acc": 52.0}
{"epoch": 27, "training_loss": 5063.140563964844, "training_acc": 49.0, "val_loss": 1459.7859382629395, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3984.4662494659424, "training_acc": 58.0, "val_loss": 1957.8426361083984, "val_acc": 52.0}
{"epoch": 29, "training_loss": 6921.2265625, "training_acc": 53.0, "val_loss": 439.08677101135254, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4798.033599853516, "training_acc": 56.0, "val_loss": 3232.4668884277344, "val_acc": 48.0}
{"epoch": 31, "training_loss": 10806.244567871094, "training_acc": 47.0, "val_loss": 1466.8858528137207, "val_acc": 52.0}
{"epoch": 32, "training_loss": 6357.7003173828125, "training_acc": 53.0, "val_loss": 2119.2888259887695, "val_acc": 52.0}
{"epoch": 33, "training_loss": 5454.297496795654, "training_acc": 50.0, "val_loss": 1061.6119384765625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2825.072271347046, "training_acc": 53.0, "val_loss": 967.457103729248, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1693.4127006530762, "training_acc": 62.0, "val_loss": 747.808313369751, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2307.685104370117, "training_acc": 55.0, "val_loss": 260.451602935791, "val_acc": 60.0}
{"epoch": 37, "training_loss": 738.9768486022949, "training_acc": 60.0, "val_loss": 911.8931770324707, "val_acc": 52.0}
