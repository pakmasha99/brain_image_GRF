"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 11067.662551879883, "training_acc": 55.0, "val_loss": 1054.010009765625, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6313.45263671875, "training_acc": 47.0, "val_loss": 5236.279296875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 11874.185989379883, "training_acc": 54.0, "val_loss": 3084.0185165405273, "val_acc": 48.0}
{"epoch": 3, "training_loss": 13930.751892089844, "training_acc": 47.0, "val_loss": 2641.629981994629, "val_acc": 52.0}
{"epoch": 4, "training_loss": 8762.118713378906, "training_acc": 53.0, "val_loss": 1695.737075805664, "val_acc": 52.0}
{"epoch": 5, "training_loss": 6081.175567626953, "training_acc": 51.0, "val_loss": 2245.537567138672, "val_acc": 48.0}
{"epoch": 6, "training_loss": 6490.3563804626465, "training_acc": 55.0, "val_loss": 2058.5824966430664, "val_acc": 52.0}
{"epoch": 7, "training_loss": 4647.574020385742, "training_acc": 55.0, "val_loss": 504.38666343688965, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3929.0862579345703, "training_acc": 41.0, "val_loss": 329.4774055480957, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2455.1700897216797, "training_acc": 53.0, "val_loss": 137.10148334503174, "val_acc": 60.0}
{"epoch": 10, "training_loss": 3738.844024658203, "training_acc": 60.0, "val_loss": 2490.1235580444336, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5717.16731262207, "training_acc": 54.0, "val_loss": 3006.316566467285, "val_acc": 48.0}
{"epoch": 12, "training_loss": 14380.937683105469, "training_acc": 47.0, "val_loss": 3023.6207962036133, "val_acc": 48.0}
{"epoch": 13, "training_loss": 9724.489440917969, "training_acc": 50.0, "val_loss": 3190.049934387207, "val_acc": 52.0}
{"epoch": 14, "training_loss": 10923.376220703125, "training_acc": 53.0, "val_loss": 2402.9138565063477, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5339.006698608398, "training_acc": 57.0, "val_loss": 1702.0933151245117, "val_acc": 48.0}
{"epoch": 16, "training_loss": 6077.321807861328, "training_acc": 47.0, "val_loss": 2832.227325439453, "val_acc": 52.0}
{"epoch": 17, "training_loss": 10046.746154785156, "training_acc": 53.0, "val_loss": 3080.9268951416016, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6262.12007522583, "training_acc": 57.0, "val_loss": 2631.5908432006836, "val_acc": 48.0}
{"epoch": 19, "training_loss": 12158.29067993164, "training_acc": 47.0, "val_loss": 1703.329086303711, "val_acc": 48.0}
{"epoch": 20, "training_loss": 6765.088821411133, "training_acc": 49.0, "val_loss": 2886.4057540893555, "val_acc": 52.0}
{"epoch": 21, "training_loss": 7205.772506713867, "training_acc": 53.0, "val_loss": 473.0057716369629, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3613.4290161132812, "training_acc": 50.0, "val_loss": 791.6281700134277, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1821.9118423461914, "training_acc": 59.0, "val_loss": 669.2136287689209, "val_acc": 48.0}
{"epoch": 24, "training_loss": 3286.1705627441406, "training_acc": 48.0, "val_loss": 399.60780143737793, "val_acc": 40.0}
{"epoch": 25, "training_loss": 2203.893081665039, "training_acc": 62.0, "val_loss": 2403.97891998291, "val_acc": 52.0}
{"epoch": 26, "training_loss": 4457.970355987549, "training_acc": 52.0, "val_loss": 2301.053810119629, "val_acc": 48.0}
{"epoch": 27, "training_loss": 10155.612091064453, "training_acc": 47.0, "val_loss": 1660.5627059936523, "val_acc": 48.0}
{"epoch": 28, "training_loss": 5946.9505615234375, "training_acc": 45.0, "val_loss": 2387.9926681518555, "val_acc": 52.0}
