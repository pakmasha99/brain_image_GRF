"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38033175468445, "training_acc": 47.0, "val_loss": 17.341983318328857, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.42567324638367, "training_acc": 49.0, "val_loss": 17.335933446884155, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1665871143341, "training_acc": 54.0, "val_loss": 17.329837381839752, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.33915162086487, "training_acc": 51.0, "val_loss": 17.325709760189056, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13402485847473, "training_acc": 55.0, "val_loss": 17.32347309589386, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18539834022522, "training_acc": 53.0, "val_loss": 17.322897911071777, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22008919715881, "training_acc": 53.0, "val_loss": 17.323657870292664, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07338380813599, "training_acc": 53.0, "val_loss": 17.324399948120117, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22604036331177, "training_acc": 53.0, "val_loss": 17.325299978256226, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21249079704285, "training_acc": 53.0, "val_loss": 17.326174676418304, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12261986732483, "training_acc": 53.0, "val_loss": 17.326675355434418, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20503282546997, "training_acc": 53.0, "val_loss": 17.326465249061584, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07496380805969, "training_acc": 53.0, "val_loss": 17.326252162456512, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.84580683708191, "training_acc": 53.0, "val_loss": 17.32616424560547, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.99229311943054, "training_acc": 53.0, "val_loss": 17.326463758945465, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10814929008484, "training_acc": 53.0, "val_loss": 17.327529191970825, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17893576622009, "training_acc": 53.0, "val_loss": 17.32849031686783, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11108779907227, "training_acc": 53.0, "val_loss": 17.328841984272003, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.00641965866089, "training_acc": 53.0, "val_loss": 17.3286035656929, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19430184364319, "training_acc": 53.0, "val_loss": 17.32829213142395, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22236323356628, "training_acc": 53.0, "val_loss": 17.32839345932007, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12784767150879, "training_acc": 53.0, "val_loss": 17.327916622161865, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.88395166397095, "training_acc": 53.0, "val_loss": 17.327414453029633, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.94962787628174, "training_acc": 53.0, "val_loss": 17.328177392482758, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.90822386741638, "training_acc": 53.0, "val_loss": 17.32831597328186, "val_acc": 52.0}
