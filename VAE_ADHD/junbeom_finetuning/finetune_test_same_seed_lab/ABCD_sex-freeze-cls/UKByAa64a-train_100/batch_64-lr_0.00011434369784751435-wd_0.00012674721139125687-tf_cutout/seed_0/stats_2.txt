"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.14558815956116, "training_acc": 53.0, "val_loss": 17.343813180923462, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.07638144493103, "training_acc": 53.0, "val_loss": 17.34451651573181, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.25405740737915, "training_acc": 53.0, "val_loss": 17.344416677951813, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2926094532013, "training_acc": 53.0, "val_loss": 17.344215512275696, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18851065635681, "training_acc": 53.0, "val_loss": 17.343521118164062, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.08229875564575, "training_acc": 53.0, "val_loss": 17.343339323997498, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.0429277420044, "training_acc": 53.0, "val_loss": 17.343731224536896, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.06585240364075, "training_acc": 53.0, "val_loss": 17.344491183757782, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24764752388, "training_acc": 53.0, "val_loss": 17.345841228961945, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14263534545898, "training_acc": 53.0, "val_loss": 17.347003519535065, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1876335144043, "training_acc": 53.0, "val_loss": 17.348043620586395, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.06043982505798, "training_acc": 53.0, "val_loss": 17.34907627105713, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2037250995636, "training_acc": 53.0, "val_loss": 17.349593341350555, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.06001281738281, "training_acc": 53.0, "val_loss": 17.349550127983093, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23163294792175, "training_acc": 53.0, "val_loss": 17.349469661712646, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16398644447327, "training_acc": 53.0, "val_loss": 17.349597811698914, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17148399353027, "training_acc": 53.0, "val_loss": 17.349135875701904, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15468049049377, "training_acc": 53.0, "val_loss": 17.348487675189972, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.95349311828613, "training_acc": 53.0, "val_loss": 17.348434031009674, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13471674919128, "training_acc": 53.0, "val_loss": 17.348480224609375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.95976185798645, "training_acc": 53.0, "val_loss": 17.34888106584549, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.99614405632019, "training_acc": 53.0, "val_loss": 17.349305748939514, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.04380559921265, "training_acc": 53.0, "val_loss": 17.350146174430847, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.99008631706238, "training_acc": 53.0, "val_loss": 17.351306974887848, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.0855278968811, "training_acc": 53.0, "val_loss": 17.352324724197388, "val_acc": 52.0}
