"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 7881.252548217773, "training_acc": 47.0, "val_loss": 1239.7750854492188, "val_acc": 48.0}
{"epoch": 1, "training_loss": 7946.7921142578125, "training_acc": 45.0, "val_loss": 4162.978744506836, "val_acc": 52.0}
{"epoch": 2, "training_loss": 15086.740112304688, "training_acc": 53.0, "val_loss": 2719.2508697509766, "val_acc": 52.0}
{"epoch": 3, "training_loss": 7575.191741943359, "training_acc": 53.0, "val_loss": 1658.7886810302734, "val_acc": 48.0}
{"epoch": 4, "training_loss": 8704.162841796875, "training_acc": 47.0, "val_loss": 2889.991569519043, "val_acc": 48.0}
{"epoch": 5, "training_loss": 10576.364227294922, "training_acc": 47.0, "val_loss": 639.0931129455566, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3525.1459350585938, "training_acc": 47.0, "val_loss": 2335.5546951293945, "val_acc": 52.0}
{"epoch": 7, "training_loss": 8773.662078857422, "training_acc": 53.0, "val_loss": 2367.6401138305664, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7464.594757080078, "training_acc": 53.0, "val_loss": 231.99868202209473, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2192.5040435791016, "training_acc": 52.0, "val_loss": 1960.6073379516602, "val_acc": 48.0}
{"epoch": 10, "training_loss": 8039.719573974609, "training_acc": 47.0, "val_loss": 1276.4723777770996, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3491.615306854248, "training_acc": 49.0, "val_loss": 1461.2645149230957, "val_acc": 52.0}
{"epoch": 12, "training_loss": 6049.773132324219, "training_acc": 53.0, "val_loss": 2661.0633850097656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 9065.640747070312, "training_acc": 53.0, "val_loss": 1732.6486587524414, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4395.722145080566, "training_acc": 53.0, "val_loss": 915.5227661132812, "val_acc": 48.0}
{"epoch": 15, "training_loss": 4816.082763671875, "training_acc": 47.0, "val_loss": 1855.3955078125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 7166.3233642578125, "training_acc": 47.0, "val_loss": 532.5599193572998, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2478.520378112793, "training_acc": 53.0, "val_loss": 1589.8834228515625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 5915.143402099609, "training_acc": 53.0, "val_loss": 1479.4997215270996, "val_acc": 52.0}
{"epoch": 19, "training_loss": 3579.661865234375, "training_acc": 53.0, "val_loss": 615.447473526001, "val_acc": 48.0}
{"epoch": 20, "training_loss": 4049.7595977783203, "training_acc": 47.0, "val_loss": 1175.124740600586, "val_acc": 48.0}
{"epoch": 21, "training_loss": 4244.426536560059, "training_acc": 47.0, "val_loss": 582.2178840637207, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1733.7351455688477, "training_acc": 54.0, "val_loss": 1281.5678596496582, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3520.2400512695312, "training_acc": 53.0, "val_loss": 252.4657964706421, "val_acc": 36.0}
{"epoch": 24, "training_loss": 1522.5922622680664, "training_acc": 62.0, "val_loss": 609.5325946807861, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2320.044183731079, "training_acc": 52.0, "val_loss": 743.9586639404297, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1941.332389831543, "training_acc": 53.0, "val_loss": 556.6282749176025, "val_acc": 52.0}
{"epoch": 27, "training_loss": 813.903865814209, "training_acc": 65.0, "val_loss": 336.75169944763184, "val_acc": 56.0}
