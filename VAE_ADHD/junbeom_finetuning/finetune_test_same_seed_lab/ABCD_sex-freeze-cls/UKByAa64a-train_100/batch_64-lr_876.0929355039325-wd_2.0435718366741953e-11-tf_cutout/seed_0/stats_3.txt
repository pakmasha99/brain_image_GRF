"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 262356.01609039307, "training_acc": 53.0, "val_loss": 738339.599609375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2980736.09375, "training_acc": 47.0, "val_loss": 57905.804443359375, "val_acc": 44.0}
{"epoch": 2, "training_loss": 502345.30078125, "training_acc": 68.0, "val_loss": 719705.810546875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2239552.12890625, "training_acc": 53.0, "val_loss": 194735.1806640625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 961300.203125, "training_acc": 48.0, "val_loss": 559578.759765625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2269790.9609375, "training_acc": 47.0, "val_loss": 161516.95556640625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 784881.69140625, "training_acc": 51.0, "val_loss": 526992.236328125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1827933.82421875, "training_acc": 53.0, "val_loss": 407963.8671875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 997215.2783203125, "training_acc": 54.0, "val_loss": 266188.8671875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1363171.1953125, "training_acc": 47.0, "val_loss": 379759.326171875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1339102.814453125, "training_acc": 47.0, "val_loss": 172371.61865234375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 624697.796875, "training_acc": 55.0, "val_loss": 354126.0498046875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 985343.265625, "training_acc": 53.0, "val_loss": 46934.04235839844, "val_acc": 44.0}
{"epoch": 13, "training_loss": 328681.896484375, "training_acc": 58.0, "val_loss": 108364.8193359375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 501803.921875, "training_acc": 58.0, "val_loss": 194161.0595703125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 458665.8779296875, "training_acc": 55.0, "val_loss": 60743.975830078125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 242707.7431640625, "training_acc": 56.0, "val_loss": 70745.58715820312, "val_acc": 52.0}
{"epoch": 17, "training_loss": 300644.62158203125, "training_acc": 56.0, "val_loss": 145763.7451171875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 257906.4189453125, "training_acc": 58.0, "val_loss": 61930.46875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 324052.16015625, "training_acc": 52.0, "val_loss": 85683.203125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 271342.318359375, "training_acc": 53.0, "val_loss": 65672.998046875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 283707.9453125, "training_acc": 59.0, "val_loss": 60715.61279296875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 295741.9638671875, "training_acc": 54.0, "val_loss": 114874.951171875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 289956.2177734375, "training_acc": 50.0, "val_loss": 24089.6240234375, "val_acc": 56.0}
{"epoch": 24, "training_loss": 174208.46142578125, "training_acc": 60.0, "val_loss": 41949.761962890625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 113578.31298828125, "training_acc": 65.0, "val_loss": 37800.57373046875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 57804.15417480469, "training_acc": 70.0, "val_loss": 31762.738037109375, "val_acc": 36.0}
{"epoch": 27, "training_loss": 73406.17114257812, "training_acc": 69.0, "val_loss": 39301.23291015625, "val_acc": 44.0}
{"epoch": 28, "training_loss": 76338.47265625, "training_acc": 64.0, "val_loss": 76036.07788085938, "val_acc": 52.0}
{"epoch": 29, "training_loss": 195327.2978515625, "training_acc": 47.0, "val_loss": 76900.5126953125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 119910.76489257812, "training_acc": 60.0, "val_loss": 28468.414306640625, "val_acc": 44.0}
{"epoch": 31, "training_loss": 46599.97277832031, "training_acc": 69.0, "val_loss": 27703.720092773438, "val_acc": 52.0}
{"epoch": 32, "training_loss": 206635.2880859375, "training_acc": 45.0, "val_loss": 13957.672119140625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72870.16552734375, "training_acc": 68.0, "val_loss": 83407.80029296875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 199449.7247314453, "training_acc": 58.0, "val_loss": 66646.32568359375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 166681.4815673828, "training_acc": 64.0, "val_loss": 79605.36499023438, "val_acc": 52.0}
{"epoch": 36, "training_loss": 164308.99853515625, "training_acc": 55.0, "val_loss": 19754.08172607422, "val_acc": 52.0}
{"epoch": 37, "training_loss": 104547.3662109375, "training_acc": 59.0, "val_loss": 74208.74633789062, "val_acc": 52.0}
{"epoch": 38, "training_loss": 157696.271484375, "training_acc": 57.0, "val_loss": 116256.94580078125, "val_acc": 48.0}
{"epoch": 39, "training_loss": 445136.3798828125, "training_acc": 47.0, "val_loss": 106878.89404296875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 315133.7880859375, "training_acc": 53.0, "val_loss": 33977.66418457031, "val_acc": 48.0}
{"epoch": 41, "training_loss": 104832.39489746094, "training_acc": 56.0, "val_loss": 112285.498046875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 261104.97021484375, "training_acc": 53.0, "val_loss": 139886.65771484375, "val_acc": 48.0}
{"epoch": 43, "training_loss": 614348.96484375, "training_acc": 47.0, "val_loss": 9458.0078125, "val_acc": 64.0}
{"epoch": 44, "training_loss": 269547.23828125, "training_acc": 64.0, "val_loss": 306580.6396484375, "val_acc": 52.0}
{"epoch": 45, "training_loss": 938596.853515625, "training_acc": 53.0, "val_loss": 12423.948669433594, "val_acc": 56.0}
{"epoch": 46, "training_loss": 257344.228515625, "training_acc": 71.0, "val_loss": 143771.4599609375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 446606.6064453125, "training_acc": 52.0, "val_loss": 141297.66845703125, "val_acc": 52.0}
{"epoch": 48, "training_loss": 282894.21337890625, "training_acc": 54.0, "val_loss": 96085.99853515625, "val_acc": 48.0}
{"epoch": 49, "training_loss": 440086.97265625, "training_acc": 47.0, "val_loss": 88978.48510742188, "val_acc": 52.0}
{"epoch": 50, "training_loss": 227964.2822265625, "training_acc": 55.0, "val_loss": 14231.988525390625, "val_acc": 56.0}
{"epoch": 51, "training_loss": 135341.6025390625, "training_acc": 61.0, "val_loss": 68646.79565429688, "val_acc": 52.0}
{"epoch": 52, "training_loss": 112987.1826171875, "training_acc": 63.0, "val_loss": 12884.271240234375, "val_acc": 56.0}
{"epoch": 53, "training_loss": 67628.88793945312, "training_acc": 64.0, "val_loss": 12501.042938232422, "val_acc": 60.0}
{"epoch": 54, "training_loss": 30916.528259277344, "training_acc": 77.0, "val_loss": 38595.062255859375, "val_acc": 52.0}
{"epoch": 55, "training_loss": 128937.21533203125, "training_acc": 58.0, "val_loss": 22138.929748535156, "val_acc": 60.0}
{"epoch": 56, "training_loss": 42943.545654296875, "training_acc": 74.0, "val_loss": 47991.65954589844, "val_acc": 48.0}
{"epoch": 57, "training_loss": 129644.14770507812, "training_acc": 59.0, "val_loss": 42816.412353515625, "val_acc": 52.0}
{"epoch": 58, "training_loss": 138278.421875, "training_acc": 56.0, "val_loss": 45963.37890625, "val_acc": 52.0}
{"epoch": 59, "training_loss": 72387.74560546875, "training_acc": 65.0, "val_loss": 91341.9189453125, "val_acc": 48.0}
{"epoch": 60, "training_loss": 298387.52392578125, "training_acc": 49.0, "val_loss": 154213.90380859375, "val_acc": 52.0}
{"epoch": 61, "training_loss": 387507.52734375, "training_acc": 54.0, "val_loss": 51426.702880859375, "val_acc": 52.0}
{"epoch": 62, "training_loss": 260206.6953125, "training_acc": 60.0, "val_loss": 129934.033203125, "val_acc": 48.0}
