"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1994907.8497009277, "training_acc": 47.0, "val_loss": 301862.20703125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1810207.5859375, "training_acc": 49.0, "val_loss": 1138894.7265625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 4369786.71875, "training_acc": 53.0, "val_loss": 750790.380859375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2137250.625, "training_acc": 53.0, "val_loss": 453814.74609375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2198775.515625, "training_acc": 47.0, "val_loss": 839674.31640625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2851032.484375, "training_acc": 47.0, "val_loss": 288838.232421875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1047213.578125, "training_acc": 49.0, "val_loss": 454028.466796875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1981108.1015625, "training_acc": 53.0, "val_loss": 419202.24609375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1432521.9140625, "training_acc": 53.0, "val_loss": 190775.64697265625, "val_acc": 44.0}
{"epoch": 9, "training_loss": 939010.95703125, "training_acc": 51.0, "val_loss": 441015.576171875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1505234.98828125, "training_acc": 49.0, "val_loss": 74875.927734375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 607217.09765625, "training_acc": 56.0, "val_loss": 401853.41796875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1687648.5390625, "training_acc": 53.0, "val_loss": 257982.51953125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 694236.818359375, "training_acc": 53.0, "val_loss": 273025.732421875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1200349.3828125, "training_acc": 47.0, "val_loss": 278728.80859375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 683536.876953125, "training_acc": 47.0, "val_loss": 222654.443359375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1080289.58203125, "training_acc": 53.0, "val_loss": 308815.673828125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1041899.861328125, "training_acc": 53.0, "val_loss": 135739.17236328125, "val_acc": 48.0}
{"epoch": 18, "training_loss": 569884.5546875, "training_acc": 48.0, "val_loss": 160287.060546875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 537294.66796875, "training_acc": 46.0, "val_loss": 107741.44287109375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 294672.2548828125, "training_acc": 54.0, "val_loss": 138152.8564453125, "val_acc": 48.0}
{"epoch": 21, "training_loss": 500462.0302734375, "training_acc": 47.0, "val_loss": 20381.997680664062, "val_acc": 68.0}
{"epoch": 22, "training_loss": 190938.4931640625, "training_acc": 54.0, "val_loss": 82755.08422851562, "val_acc": 52.0}
{"epoch": 23, "training_loss": 227158.1982421875, "training_acc": 52.0, "val_loss": 55840.667724609375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 267591.626953125, "training_acc": 41.0, "val_loss": 41254.42810058594, "val_acc": 48.0}
{"epoch": 25, "training_loss": 253175.283203125, "training_acc": 52.0, "val_loss": 75898.05908203125, "val_acc": 48.0}
{"epoch": 26, "training_loss": 236436.7802734375, "training_acc": 58.0, "val_loss": 79130.84106445312, "val_acc": 52.0}
{"epoch": 27, "training_loss": 221234.20385742188, "training_acc": 58.0, "val_loss": 77274.609375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 149093.30908203125, "training_acc": 63.0, "val_loss": 50591.39099121094, "val_acc": 52.0}
{"epoch": 29, "training_loss": 170815.4384765625, "training_acc": 54.0, "val_loss": 22509.52911376953, "val_acc": 40.0}
{"epoch": 30, "training_loss": 125483.79296875, "training_acc": 61.0, "val_loss": 12073.593139648438, "val_acc": 60.0}
{"epoch": 31, "training_loss": 71626.95751953125, "training_acc": 57.0, "val_loss": 14842.861938476562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 103911.28369140625, "training_acc": 61.0, "val_loss": 11577.24609375, "val_acc": 64.0}
{"epoch": 33, "training_loss": 53106.081787109375, "training_acc": 61.0, "val_loss": 20537.66326904297, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64141.251220703125, "training_acc": 70.0, "val_loss": 81784.27734375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 205309.484375, "training_acc": 52.0, "val_loss": 50588.75427246094, "val_acc": 52.0}
{"epoch": 36, "training_loss": 186540.5673828125, "training_acc": 45.0, "val_loss": 59568.84765625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 134501.84228515625, "training_acc": 56.0, "val_loss": 116450.2685546875, "val_acc": 48.0}
{"epoch": 38, "training_loss": 433585.1953125, "training_acc": 47.0, "val_loss": 80188.17749023438, "val_acc": 52.0}
{"epoch": 39, "training_loss": 359002.5625, "training_acc": 53.0, "val_loss": 8961.158752441406, "val_acc": 60.0}
{"epoch": 40, "training_loss": 214427.888671875, "training_acc": 64.0, "val_loss": 78425.65307617188, "val_acc": 48.0}
{"epoch": 41, "training_loss": 306074.982421875, "training_acc": 52.0, "val_loss": 153294.873046875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 452616.68359375, "training_acc": 53.0, "val_loss": 170786.9384765625, "val_acc": 48.0}
{"epoch": 43, "training_loss": 668611.681640625, "training_acc": 47.0, "val_loss": 103498.486328125, "val_acc": 48.0}
{"epoch": 44, "training_loss": 472135.263671875, "training_acc": 45.0, "val_loss": 209458.740234375, "val_acc": 52.0}
{"epoch": 45, "training_loss": 673539.6552734375, "training_acc": 53.0, "val_loss": 62352.960205078125, "val_acc": 48.0}
{"epoch": 46, "training_loss": 242210.859375, "training_acc": 48.0, "val_loss": 30188.088989257812, "val_acc": 52.0}
{"epoch": 47, "training_loss": 111264.9775390625, "training_acc": 58.0, "val_loss": 83403.47290039062, "val_acc": 48.0}
{"epoch": 48, "training_loss": 214065.24768066406, "training_acc": 53.0, "val_loss": 49299.725341796875, "val_acc": 52.0}
{"epoch": 49, "training_loss": 143141.78369140625, "training_acc": 57.0, "val_loss": 25287.327575683594, "val_acc": 44.0}
{"epoch": 50, "training_loss": 94855.5849609375, "training_acc": 62.0, "val_loss": 15774.455261230469, "val_acc": 64.0}
{"epoch": 51, "training_loss": 128689.6689453125, "training_acc": 62.0, "val_loss": 19858.770751953125, "val_acc": 60.0}
{"epoch": 52, "training_loss": 76781.41162109375, "training_acc": 61.0, "val_loss": 66954.33959960938, "val_acc": 48.0}
{"epoch": 53, "training_loss": 171558.4599609375, "training_acc": 56.0, "val_loss": 105775.4638671875, "val_acc": 52.0}
{"epoch": 54, "training_loss": 332817.4501953125, "training_acc": 53.0, "val_loss": 68136.10229492188, "val_acc": 48.0}
{"epoch": 55, "training_loss": 252639.0498046875, "training_acc": 48.0, "val_loss": 90921.2158203125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 327913.7353515625, "training_acc": 54.0, "val_loss": 16634.060668945312, "val_acc": 60.0}
{"epoch": 57, "training_loss": 173844.923828125, "training_acc": 62.0, "val_loss": 43147.998046875, "val_acc": 44.0}
{"epoch": 58, "training_loss": 291572.650390625, "training_acc": 54.0, "val_loss": 166901.07421875, "val_acc": 52.0}
