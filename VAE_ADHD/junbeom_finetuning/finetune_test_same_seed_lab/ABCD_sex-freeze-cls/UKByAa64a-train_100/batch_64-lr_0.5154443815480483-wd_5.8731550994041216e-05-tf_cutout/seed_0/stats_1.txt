"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1126.977596282959, "training_acc": 46.0, "val_loss": 226.1253833770752, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1099.0693054199219, "training_acc": 53.0, "val_loss": 586.1489295959473, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2205.5843353271484, "training_acc": 47.0, "val_loss": 162.54225969314575, "val_acc": 48.0}
{"epoch": 3, "training_loss": 768.3894290924072, "training_acc": 51.0, "val_loss": 427.85773277282715, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1626.1484680175781, "training_acc": 53.0, "val_loss": 381.760311126709, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1133.4577522277832, "training_acc": 53.0, "val_loss": 66.6543185710907, "val_acc": 48.0}
{"epoch": 6, "training_loss": 613.3100624084473, "training_acc": 47.0, "val_loss": 197.20336198806763, "val_acc": 48.0}
{"epoch": 7, "training_loss": 669.4065742492676, "training_acc": 47.0, "val_loss": 139.0369176864624, "val_acc": 52.0}
{"epoch": 8, "training_loss": 542.2794151306152, "training_acc": 53.0, "val_loss": 240.57457447052002, "val_acc": 52.0}
{"epoch": 9, "training_loss": 777.1493530273438, "training_acc": 53.0, "val_loss": 27.562350034713745, "val_acc": 52.0}
{"epoch": 10, "training_loss": 298.637487411499, "training_acc": 52.0, "val_loss": 187.5174880027771, "val_acc": 48.0}
{"epoch": 11, "training_loss": 689.2329416275024, "training_acc": 47.0, "val_loss": 30.398452281951904, "val_acc": 52.0}
{"epoch": 12, "training_loss": 186.14373016357422, "training_acc": 55.0, "val_loss": 85.084068775177, "val_acc": 52.0}
{"epoch": 13, "training_loss": 185.68747568130493, "training_acc": 64.0, "val_loss": 91.22745394706726, "val_acc": 48.0}
{"epoch": 14, "training_loss": 367.2979335784912, "training_acc": 47.0, "val_loss": 24.015121161937714, "val_acc": 56.0}
{"epoch": 15, "training_loss": 138.3361692428589, "training_acc": 59.0, "val_loss": 66.40379428863525, "val_acc": 52.0}
{"epoch": 16, "training_loss": 174.1847767829895, "training_acc": 52.0, "val_loss": 37.49707639217377, "val_acc": 48.0}
{"epoch": 17, "training_loss": 154.64880847930908, "training_acc": 50.0, "val_loss": 49.62879717350006, "val_acc": 52.0}
{"epoch": 18, "training_loss": 160.64779615402222, "training_acc": 47.0, "val_loss": 18.44104379415512, "val_acc": 56.0}
{"epoch": 19, "training_loss": 94.54361915588379, "training_acc": 58.0, "val_loss": 16.71251207590103, "val_acc": 60.0}
{"epoch": 20, "training_loss": 74.39849877357483, "training_acc": 63.0, "val_loss": 16.7006254196167, "val_acc": 64.0}
{"epoch": 21, "training_loss": 79.98218154907227, "training_acc": 61.0, "val_loss": 16.93057417869568, "val_acc": 64.0}
{"epoch": 22, "training_loss": 68.72508692741394, "training_acc": 67.0, "val_loss": 28.24465036392212, "val_acc": 52.0}
{"epoch": 23, "training_loss": 83.23555111885071, "training_acc": 66.0, "val_loss": 34.85307693481445, "val_acc": 52.0}
{"epoch": 24, "training_loss": 105.98788523674011, "training_acc": 55.0, "val_loss": 44.01032030582428, "val_acc": 52.0}
{"epoch": 25, "training_loss": 132.66483783721924, "training_acc": 55.0, "val_loss": 43.50194334983826, "val_acc": 48.0}
{"epoch": 26, "training_loss": 124.33224511146545, "training_acc": 53.0, "val_loss": 74.43823218345642, "val_acc": 52.0}
{"epoch": 27, "training_loss": 248.394287109375, "training_acc": 53.0, "val_loss": 25.275444984436035, "val_acc": 44.0}
