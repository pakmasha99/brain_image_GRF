"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 528908.9144592285, "training_acc": 51.0, "val_loss": 109817.46826171875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 553638.029296875, "training_acc": 49.0, "val_loss": 237778.90625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 888545.6328125, "training_acc": 47.0, "val_loss": 57549.74365234375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 337763.474609375, "training_acc": 45.0, "val_loss": 186845.64208984375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 746024.72265625, "training_acc": 53.0, "val_loss": 157535.546875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 502156.1396484375, "training_acc": 53.0, "val_loss": 41037.87841796875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 240107.2861328125, "training_acc": 47.0, "val_loss": 92365.4052734375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 305114.2021484375, "training_acc": 47.0, "val_loss": 44771.71630859375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 203352.7978515625, "training_acc": 53.0, "val_loss": 72476.06201171875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 235288.61279296875, "training_acc": 53.0, "val_loss": 38508.27331542969, "val_acc": 48.0}
{"epoch": 10, "training_loss": 182689.0322265625, "training_acc": 47.0, "val_loss": 33502.61535644531, "val_acc": 48.0}
{"epoch": 11, "training_loss": 161130.42578125, "training_acc": 39.0, "val_loss": 45993.60046386719, "val_acc": 52.0}
{"epoch": 12, "training_loss": 147813.61767578125, "training_acc": 53.0, "val_loss": 31932.763671875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 157775.796875, "training_acc": 47.0, "val_loss": 17149.221801757812, "val_acc": 48.0}
{"epoch": 14, "training_loss": 98072.72998046875, "training_acc": 53.0, "val_loss": 70542.62084960938, "val_acc": 52.0}
{"epoch": 15, "training_loss": 261878.79296875, "training_acc": 53.0, "val_loss": 20204.79278564453, "val_acc": 52.0}
{"epoch": 16, "training_loss": 142409.099609375, "training_acc": 47.0, "val_loss": 81066.69921875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 306138.3310546875, "training_acc": 47.0, "val_loss": 11678.290557861328, "val_acc": 48.0}
{"epoch": 18, "training_loss": 167069.3837890625, "training_acc": 39.0, "val_loss": 105745.08056640625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 409826.845703125, "training_acc": 53.0, "val_loss": 71902.01416015625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 195493.64514160156, "training_acc": 53.0, "val_loss": 79345.8740234375, "val_acc": 48.0}
{"epoch": 21, "training_loss": 378815.251953125, "training_acc": 47.0, "val_loss": 125787.78076171875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 461503.625, "training_acc": 47.0, "val_loss": 22560.650634765625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 142909.8203125, "training_acc": 53.0, "val_loss": 124896.61865234375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 506859.771484375, "training_acc": 53.0, "val_loss": 127452.8076171875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 435814.5791015625, "training_acc": 53.0, "val_loss": 13777.995300292969, "val_acc": 52.0}
{"epoch": 26, "training_loss": 152434.7470703125, "training_acc": 53.0, "val_loss": 141964.61181640625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 590690.244140625, "training_acc": 47.0, "val_loss": 125040.576171875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 411271.2919921875, "training_acc": 47.0, "val_loss": 27302.44140625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 179289.9169921875, "training_acc": 53.0, "val_loss": 88911.22436523438, "val_acc": 52.0}
{"epoch": 30, "training_loss": 316328.857421875, "training_acc": 53.0, "val_loss": 18397.569274902344, "val_acc": 52.0}
{"epoch": 31, "training_loss": 160675.0078125, "training_acc": 45.0, "val_loss": 99119.45190429688, "val_acc": 48.0}
{"epoch": 32, "training_loss": 392418.017578125, "training_acc": 47.0, "val_loss": 45497.784423828125, "val_acc": 48.0}
{"epoch": 33, "training_loss": 147498.78637695312, "training_acc": 53.0, "val_loss": 65022.75390625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 253296.638671875, "training_acc": 53.0, "val_loss": 36453.118896484375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 94171.37133789062, "training_acc": 61.0, "val_loss": 42063.018798828125, "val_acc": 48.0}
{"epoch": 36, "training_loss": 147406.64794921875, "training_acc": 47.0, "val_loss": 26182.302856445312, "val_acc": 52.0}
