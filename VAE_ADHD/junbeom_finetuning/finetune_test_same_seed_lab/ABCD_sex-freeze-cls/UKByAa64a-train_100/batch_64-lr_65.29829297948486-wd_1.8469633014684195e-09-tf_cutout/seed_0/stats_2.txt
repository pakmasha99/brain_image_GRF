"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 639817.8628692627, "training_acc": 54.0, "val_loss": 128006.38427734375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 635814.5390625, "training_acc": 41.0, "val_loss": 192827.3193359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 714973.68359375, "training_acc": 47.0, "val_loss": 30357.199096679688, "val_acc": 48.0}
{"epoch": 3, "training_loss": 310314.681640625, "training_acc": 41.0, "val_loss": 191084.41162109375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 750344.880859375, "training_acc": 53.0, "val_loss": 159047.0947265625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 521153.794921875, "training_acc": 53.0, "val_loss": 19070.993041992188, "val_acc": 48.0}
{"epoch": 6, "training_loss": 149515.8349609375, "training_acc": 47.0, "val_loss": 63173.065185546875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 191499.39868164062, "training_acc": 47.0, "val_loss": 70456.82373046875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 319202.5009765625, "training_acc": 53.0, "val_loss": 98101.49536132812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 330024.3349609375, "training_acc": 53.0, "val_loss": 12589.269256591797, "val_acc": 48.0}
{"epoch": 10, "training_loss": 83545.81103515625, "training_acc": 47.0, "val_loss": 17087.5732421875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 86076.734375, "training_acc": 53.0, "val_loss": 51264.703369140625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 174303.44580078125, "training_acc": 53.0, "val_loss": 19488.980102539062, "val_acc": 48.0}
{"epoch": 13, "training_loss": 87018.23413085938, "training_acc": 47.0, "val_loss": 7615.377044677734, "val_acc": 52.0}
{"epoch": 14, "training_loss": 24756.339111328125, "training_acc": 53.0, "val_loss": 37255.45349121094, "val_acc": 48.0}
{"epoch": 15, "training_loss": 149788.70166015625, "training_acc": 47.0, "val_loss": 4395.372772216797, "val_acc": 52.0}
{"epoch": 16, "training_loss": 19139.915893554688, "training_acc": 53.0, "val_loss": 26640.609741210938, "val_acc": 48.0}
{"epoch": 17, "training_loss": 97526.24536132812, "training_acc": 47.0, "val_loss": 26789.16015625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 117174.12353515625, "training_acc": 53.0, "val_loss": 12054.588317871094, "val_acc": 52.0}
{"epoch": 19, "training_loss": 126656.6591796875, "training_acc": 41.0, "val_loss": 57571.356201171875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 188127.2587890625, "training_acc": 47.0, "val_loss": 34691.45202636719, "val_acc": 52.0}
{"epoch": 21, "training_loss": 172821.814453125, "training_acc": 53.0, "val_loss": 58730.7373046875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 178271.5859375, "training_acc": 53.0, "val_loss": 40557.867431640625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 212241.583984375, "training_acc": 47.0, "val_loss": 49785.546875, "val_acc": 48.0}
{"epoch": 24, "training_loss": 141534.49151611328, "training_acc": 47.0, "val_loss": 18309.384155273438, "val_acc": 52.0}
{"epoch": 25, "training_loss": 55916.02978515625, "training_acc": 45.0, "val_loss": 16814.952087402344, "val_acc": 52.0}
{"epoch": 26, "training_loss": 47561.28921508789, "training_acc": 53.0, "val_loss": 40651.3671875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 169847.2509765625, "training_acc": 47.0, "val_loss": 6505.992126464844, "val_acc": 48.0}
{"epoch": 28, "training_loss": 80524.25537109375, "training_acc": 55.0, "val_loss": 86706.50634765625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 337799.3125, "training_acc": 53.0, "val_loss": 50392.88024902344, "val_acc": 52.0}
{"epoch": 30, "training_loss": 151776.33984375, "training_acc": 49.0, "val_loss": 36733.343505859375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 124830.20434570312, "training_acc": 47.0, "val_loss": 30543.002319335938, "val_acc": 52.0}
{"epoch": 32, "training_loss": 140204.65087890625, "training_acc": 53.0, "val_loss": 28081.088256835938, "val_acc": 52.0}
{"epoch": 33, "training_loss": 115430.28662109375, "training_acc": 45.0, "val_loss": 27778.665161132812, "val_acc": 48.0}
{"epoch": 34, "training_loss": 83034.19744873047, "training_acc": 47.0, "val_loss": 1759.188461303711, "val_acc": 52.0}
{"epoch": 35, "training_loss": 54850.4853515625, "training_acc": 51.0, "val_loss": 31230.838012695312, "val_acc": 48.0}
{"epoch": 36, "training_loss": 89473.4267578125, "training_acc": 51.0, "val_loss": 12034.050750732422, "val_acc": 52.0}
{"epoch": 37, "training_loss": 48919.68896484375, "training_acc": 53.0, "val_loss": 4634.395217895508, "val_acc": 48.0}
{"epoch": 38, "training_loss": 77147.7509765625, "training_acc": 45.0, "val_loss": 47012.811279296875, "val_acc": 52.0}
{"epoch": 39, "training_loss": 147460.43383789062, "training_acc": 53.0, "val_loss": 33680.99670410156, "val_acc": 48.0}
{"epoch": 40, "training_loss": 165272.0810546875, "training_acc": 47.0, "val_loss": 25644.863891601562, "val_acc": 48.0}
{"epoch": 41, "training_loss": 117868.38720703125, "training_acc": 47.0, "val_loss": 51578.778076171875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 181676.85595703125, "training_acc": 53.0, "val_loss": 5981.6375732421875, "val_acc": 48.0}
{"epoch": 43, "training_loss": 30732.425537109375, "training_acc": 47.0, "val_loss": 20696.1669921875, "val_acc": 52.0}
{"epoch": 44, "training_loss": 77057.921875, "training_acc": 53.0, "val_loss": 17076.96990966797, "val_acc": 48.0}
{"epoch": 45, "training_loss": 66399.0517578125, "training_acc": 47.0, "val_loss": 25279.08477783203, "val_acc": 52.0}
{"epoch": 46, "training_loss": 107007.892578125, "training_acc": 53.0, "val_loss": 4046.825408935547, "val_acc": 52.0}
{"epoch": 47, "training_loss": 90295.7939453125, "training_acc": 51.0, "val_loss": 71755.09033203125, "val_acc": 48.0}
{"epoch": 48, "training_loss": 259248.0234375, "training_acc": 47.0, "val_loss": 8033.937072753906, "val_acc": 52.0}
{"epoch": 49, "training_loss": 59278.2919921875, "training_acc": 53.0, "val_loss": 12037.093353271484, "val_acc": 52.0}
{"epoch": 50, "training_loss": 75137.423828125, "training_acc": 53.0, "val_loss": 40859.9365234375, "val_acc": 48.0}
{"epoch": 51, "training_loss": 120369.74389648438, "training_acc": 47.0, "val_loss": 51749.835205078125, "val_acc": 52.0}
{"epoch": 52, "training_loss": 250736.138671875, "training_acc": 53.0, "val_loss": 66755.40771484375, "val_acc": 52.0}
{"epoch": 53, "training_loss": 196681.3212890625, "training_acc": 53.0, "val_loss": 48073.83117675781, "val_acc": 48.0}
