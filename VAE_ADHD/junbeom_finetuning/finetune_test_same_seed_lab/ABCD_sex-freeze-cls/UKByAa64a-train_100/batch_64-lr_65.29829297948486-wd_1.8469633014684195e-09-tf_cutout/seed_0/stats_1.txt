"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 193138.1576461792, "training_acc": 51.0, "val_loss": 101852.40478515625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 336065.2158203125, "training_acc": 47.0, "val_loss": 103528.515625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 471020.4453125, "training_acc": 53.0, "val_loss": 84641.83959960938, "val_acc": 52.0}
{"epoch": 3, "training_loss": 254880.21923828125, "training_acc": 51.0, "val_loss": 56618.353271484375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 166621.61163330078, "training_acc": 47.0, "val_loss": 81187.92114257812, "val_acc": 52.0}
{"epoch": 5, "training_loss": 345831.9072265625, "training_acc": 53.0, "val_loss": 81127.60009765625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 235201.72729492188, "training_acc": 53.0, "val_loss": 88235.07080078125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 412750.083984375, "training_acc": 47.0, "val_loss": 112911.43798828125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 365948.154296875, "training_acc": 47.0, "val_loss": 44015.673828125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 200947.17431640625, "training_acc": 53.0, "val_loss": 88184.03930664062, "val_acc": 52.0}
{"epoch": 10, "training_loss": 302989.541015625, "training_acc": 53.0, "val_loss": 1613.2970809936523, "val_acc": 24.0}
{"epoch": 11, "training_loss": 55089.9599609375, "training_acc": 54.0, "val_loss": 52658.349609375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 154710.6043701172, "training_acc": 47.0, "val_loss": 58574.609375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 260214.3583984375, "training_acc": 53.0, "val_loss": 75742.60864257812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 234905.0146484375, "training_acc": 53.0, "val_loss": 41971.97265625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 211357.6416015625, "training_acc": 47.0, "val_loss": 55410.19287109375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 140529.6103515625, "training_acc": 50.0, "val_loss": 36266.412353515625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 135541.36059570312, "training_acc": 53.0, "val_loss": 2039.5343780517578, "val_acc": 40.0}
{"epoch": 18, "training_loss": 18250.432250976562, "training_acc": 53.0, "val_loss": 15891.63818359375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 49299.92346191406, "training_acc": 53.0, "val_loss": 39806.640625, "val_acc": 48.0}
{"epoch": 20, "training_loss": 169597.685546875, "training_acc": 47.0, "val_loss": 1780.2490234375, "val_acc": 40.0}
{"epoch": 21, "training_loss": 67269.83972167969, "training_acc": 55.0, "val_loss": 62065.71044921875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 212704.27294921875, "training_acc": 53.0, "val_loss": 15493.435668945312, "val_acc": 48.0}
{"epoch": 23, "training_loss": 70108.85522460938, "training_acc": 47.0, "val_loss": 8349.504089355469, "val_acc": 52.0}
{"epoch": 24, "training_loss": 25729.11798095703, "training_acc": 53.0, "val_loss": 42283.721923828125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 161623.515625, "training_acc": 47.0, "val_loss": 2767.224884033203, "val_acc": 48.0}
{"epoch": 26, "training_loss": 92796.677734375, "training_acc": 51.0, "val_loss": 79674.98779296875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 290066.2001953125, "training_acc": 53.0, "val_loss": 17897.38311767578, "val_acc": 52.0}
{"epoch": 28, "training_loss": 133724.486328125, "training_acc": 51.0, "val_loss": 95658.74633789062, "val_acc": 48.0}
{"epoch": 29, "training_loss": 369775.3916015625, "training_acc": 47.0, "val_loss": 35057.00378417969, "val_acc": 48.0}
