"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4708.614669799805, "training_acc": 53.0, "val_loss": 161.793851852417, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2911.3938903808594, "training_acc": 51.0, "val_loss": 647.4775314331055, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3062.956268310547, "training_acc": 55.0, "val_loss": 2082.6051712036133, "val_acc": 52.0}
{"epoch": 3, "training_loss": 7442.443756103516, "training_acc": 53.0, "val_loss": 487.45718002319336, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3403.0020294189453, "training_acc": 49.0, "val_loss": 2114.9404525756836, "val_acc": 48.0}
{"epoch": 5, "training_loss": 8351.442016601562, "training_acc": 47.0, "val_loss": 951.9299507141113, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3202.3177947998047, "training_acc": 49.0, "val_loss": 1212.393856048584, "val_acc": 52.0}
{"epoch": 7, "training_loss": 4601.240295410156, "training_acc": 53.0, "val_loss": 743.5812950134277, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2007.3256874084473, "training_acc": 53.0, "val_loss": 482.47599601745605, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1601.850580215454, "training_acc": 48.0, "val_loss": 564.1085624694824, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2236.8563079833984, "training_acc": 53.0, "val_loss": 433.33234786987305, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1373.2962226867676, "training_acc": 54.0, "val_loss": 510.6433391571045, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1555.058069229126, "training_acc": 48.0, "val_loss": 540.2411937713623, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2215.6919021606445, "training_acc": 53.0, "val_loss": 303.20074558258057, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1588.726921081543, "training_acc": 48.0, "val_loss": 680.6485652923584, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2147.3888359069824, "training_acc": 48.0, "val_loss": 505.7690143585205, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2062.3028564453125, "training_acc": 53.0, "val_loss": 561.8724346160889, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1286.6426792144775, "training_acc": 53.0, "val_loss": 293.8354730606079, "val_acc": 44.0}
{"epoch": 18, "training_loss": 1052.0123872756958, "training_acc": 49.0, "val_loss": 399.3658781051636, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1205.7198371887207, "training_acc": 54.0, "val_loss": 86.36904954910278, "val_acc": 64.0}
{"epoch": 20, "training_loss": 524.3660869598389, "training_acc": 59.0, "val_loss": 130.7112455368042, "val_acc": 60.0}
{"epoch": 21, "training_loss": 415.4998664855957, "training_acc": 59.0, "val_loss": 132.53451585769653, "val_acc": 48.0}
{"epoch": 22, "training_loss": 591.2984418869019, "training_acc": 55.0, "val_loss": 61.992788314819336, "val_acc": 52.0}
{"epoch": 23, "training_loss": 210.63499927520752, "training_acc": 68.0, "val_loss": 78.03263664245605, "val_acc": 56.0}
{"epoch": 24, "training_loss": 333.03810024261475, "training_acc": 58.0, "val_loss": 81.48414492607117, "val_acc": 52.0}
{"epoch": 25, "training_loss": 178.80481958389282, "training_acc": 69.0, "val_loss": 105.12373447418213, "val_acc": 56.0}
{"epoch": 26, "training_loss": 181.04785776138306, "training_acc": 69.0, "val_loss": 183.6107611656189, "val_acc": 48.0}
{"epoch": 27, "training_loss": 745.6848697662354, "training_acc": 46.0, "val_loss": 63.797664642333984, "val_acc": 64.0}
{"epoch": 28, "training_loss": 293.32451820373535, "training_acc": 66.0, "val_loss": 216.74237251281738, "val_acc": 52.0}
{"epoch": 29, "training_loss": 524.9180784225464, "training_acc": 54.0, "val_loss": 159.72156524658203, "val_acc": 48.0}
{"epoch": 30, "training_loss": 703.9473972320557, "training_acc": 48.0, "val_loss": 104.22641038894653, "val_acc": 56.0}
{"epoch": 31, "training_loss": 499.7925453186035, "training_acc": 64.0, "val_loss": 269.05577182769775, "val_acc": 48.0}
{"epoch": 32, "training_loss": 761.3944091796875, "training_acc": 57.0, "val_loss": 389.24551010131836, "val_acc": 52.0}
{"epoch": 33, "training_loss": 963.201494216919, "training_acc": 57.0, "val_loss": 257.06028938293457, "val_acc": 48.0}
{"epoch": 34, "training_loss": 820.9679927825928, "training_acc": 42.0, "val_loss": 62.478071451187134, "val_acc": 60.0}
{"epoch": 35, "training_loss": 130.64640927314758, "training_acc": 67.0, "val_loss": 132.4363350868225, "val_acc": 52.0}
{"epoch": 36, "training_loss": 343.7436466217041, "training_acc": 55.0, "val_loss": 135.71425676345825, "val_acc": 52.0}
{"epoch": 37, "training_loss": 310.6542625427246, "training_acc": 52.0, "val_loss": 330.5682182312012, "val_acc": 52.0}
{"epoch": 38, "training_loss": 786.9474210739136, "training_acc": 54.0, "val_loss": 339.2080068588257, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1317.1787910461426, "training_acc": 47.0, "val_loss": 337.2176170349121, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1002.6732482910156, "training_acc": 53.0, "val_loss": 66.81771874427795, "val_acc": 56.0}
{"epoch": 41, "training_loss": 668.6124801635742, "training_acc": 61.0, "val_loss": 65.09928107261658, "val_acc": 52.0}
{"epoch": 42, "training_loss": 453.7735252380371, "training_acc": 64.0, "val_loss": 58.13550353050232, "val_acc": 56.0}
{"epoch": 43, "training_loss": 451.47128677368164, "training_acc": 69.0, "val_loss": 63.605958223342896, "val_acc": 56.0}
{"epoch": 44, "training_loss": 382.37937927246094, "training_acc": 69.0, "val_loss": 177.28334665298462, "val_acc": 52.0}
{"epoch": 45, "training_loss": 845.5790481567383, "training_acc": 53.0, "val_loss": 385.00804901123047, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1022.6890068054199, "training_acc": 51.0, "val_loss": 263.08791637420654, "val_acc": 52.0}
{"epoch": 47, "training_loss": 662.4431610107422, "training_acc": 55.0, "val_loss": 119.57724094390869, "val_acc": 40.0}
{"epoch": 48, "training_loss": 585.963264465332, "training_acc": 55.0, "val_loss": 295.78402042388916, "val_acc": 52.0}
{"epoch": 49, "training_loss": 771.7671756744385, "training_acc": 53.0, "val_loss": 129.9799919128418, "val_acc": 40.0}
{"epoch": 50, "training_loss": 752.0493812561035, "training_acc": 49.0, "val_loss": 319.4302558898926, "val_acc": 52.0}
{"epoch": 51, "training_loss": 713.2545280456543, "training_acc": 55.0, "val_loss": 125.87285041809082, "val_acc": 48.0}
{"epoch": 52, "training_loss": 605.07177734375, "training_acc": 52.0, "val_loss": 297.64842987060547, "val_acc": 52.0}
{"epoch": 53, "training_loss": 794.6807231903076, "training_acc": 55.0, "val_loss": 163.6730670928955, "val_acc": 44.0}
{"epoch": 54, "training_loss": 648.237117767334, "training_acc": 56.0, "val_loss": 310.05120277404785, "val_acc": 52.0}
{"epoch": 55, "training_loss": 572.4643082618713, "training_acc": 65.0, "val_loss": 177.92513370513916, "val_acc": 44.0}
{"epoch": 56, "training_loss": 464.2504549026489, "training_acc": 58.0, "val_loss": 205.20849227905273, "val_acc": 52.0}
{"epoch": 57, "training_loss": 666.7540378570557, "training_acc": 47.0, "val_loss": 70.1104998588562, "val_acc": 52.0}
{"epoch": 58, "training_loss": 325.34571075439453, "training_acc": 70.0, "val_loss": 123.08354377746582, "val_acc": 60.0}
{"epoch": 59, "training_loss": 556.1222229003906, "training_acc": 59.0, "val_loss": 275.2877712249756, "val_acc": 48.0}
{"epoch": 60, "training_loss": 846.9603424072266, "training_acc": 51.0, "val_loss": 366.4815664291382, "val_acc": 52.0}
{"epoch": 61, "training_loss": 850.30908203125, "training_acc": 56.0, "val_loss": 189.67602252960205, "val_acc": 44.0}
