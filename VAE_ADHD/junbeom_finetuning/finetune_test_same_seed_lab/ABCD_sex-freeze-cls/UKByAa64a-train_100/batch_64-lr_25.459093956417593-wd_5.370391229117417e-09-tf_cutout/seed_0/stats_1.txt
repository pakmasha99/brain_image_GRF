"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 53514.939868927, "training_acc": 46.0, "val_loss": 11176.573181152344, "val_acc": 52.0}
{"epoch": 1, "training_loss": 54272.7861328125, "training_acc": 53.0, "val_loss": 28945.00732421875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 108934.466796875, "training_acc": 47.0, "val_loss": 8023.585510253906, "val_acc": 48.0}
{"epoch": 3, "training_loss": 37958.45947265625, "training_acc": 51.0, "val_loss": 21138.714599609375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 80312.52416992188, "training_acc": 53.0, "val_loss": 18862.698364257812, "val_acc": 52.0}
{"epoch": 5, "training_loss": 55983.42614746094, "training_acc": 53.0, "val_loss": 3277.493667602539, "val_acc": 48.0}
{"epoch": 6, "training_loss": 30207.438232421875, "training_acc": 47.0, "val_loss": 9661.502838134766, "val_acc": 48.0}
{"epoch": 7, "training_loss": 32748.154418945312, "training_acc": 47.0, "val_loss": 7000.5126953125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 27297.292114257812, "training_acc": 53.0, "val_loss": 12138.652801513672, "val_acc": 52.0}
{"epoch": 9, "training_loss": 39416.42791748047, "training_acc": 53.0, "val_loss": 1529.5360565185547, "val_acc": 52.0}
{"epoch": 10, "training_loss": 15772.451904296875, "training_acc": 49.0, "val_loss": 11296.161651611328, "val_acc": 48.0}
{"epoch": 11, "training_loss": 43287.40441894531, "training_acc": 47.0, "val_loss": 2411.875343322754, "val_acc": 48.0}
{"epoch": 12, "training_loss": 15686.138549804688, "training_acc": 49.0, "val_loss": 11854.496765136719, "val_acc": 52.0}
{"epoch": 13, "training_loss": 45571.940185546875, "training_acc": 53.0, "val_loss": 8876.944732666016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 23802.17723083496, "training_acc": 52.0, "val_loss": 8768.36929321289, "val_acc": 48.0}
{"epoch": 15, "training_loss": 42694.359130859375, "training_acc": 47.0, "val_loss": 13034.356689453125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 44011.07702636719, "training_acc": 47.0, "val_loss": 1139.1630172729492, "val_acc": 60.0}
{"epoch": 17, "training_loss": 11072.666625976562, "training_acc": 56.0, "val_loss": 7805.945587158203, "val_acc": 52.0}
{"epoch": 18, "training_loss": 25447.41912841797, "training_acc": 53.0, "val_loss": 903.2782554626465, "val_acc": 44.0}
{"epoch": 19, "training_loss": 6458.876068115234, "training_acc": 57.0, "val_loss": 1401.1062622070312, "val_acc": 48.0}
{"epoch": 20, "training_loss": 10036.093872070312, "training_acc": 47.0, "val_loss": 4312.224578857422, "val_acc": 52.0}
{"epoch": 21, "training_loss": 9341.596168518066, "training_acc": 59.0, "val_loss": 4499.679946899414, "val_acc": 48.0}
{"epoch": 22, "training_loss": 19925.045166015625, "training_acc": 47.0, "val_loss": 1114.5378112792969, "val_acc": 40.0}
{"epoch": 23, "training_loss": 11888.514099121094, "training_acc": 49.0, "val_loss": 9187.921905517578, "val_acc": 52.0}
{"epoch": 24, "training_loss": 29944.360595703125, "training_acc": 53.0, "val_loss": 3353.584671020508, "val_acc": 52.0}
{"epoch": 25, "training_loss": 14122.943542480469, "training_acc": 51.0, "val_loss": 7489.916229248047, "val_acc": 48.0}
{"epoch": 26, "training_loss": 27279.934692382812, "training_acc": 47.0, "val_loss": 1012.6651763916016, "val_acc": 52.0}
{"epoch": 27, "training_loss": 10163.885498046875, "training_acc": 51.0, "val_loss": 8270.641326904297, "val_acc": 52.0}
{"epoch": 28, "training_loss": 25120.83123779297, "training_acc": 53.0, "val_loss": 876.4591217041016, "val_acc": 48.0}
{"epoch": 29, "training_loss": 11382.278686523438, "training_acc": 54.0, "val_loss": 3887.7227783203125, "val_acc": 48.0}
{"epoch": 30, "training_loss": 12087.543533325195, "training_acc": 50.0, "val_loss": 3666.9849395751953, "val_acc": 52.0}
{"epoch": 31, "training_loss": 8726.724090576172, "training_acc": 54.0, "val_loss": 1134.99116897583, "val_acc": 36.0}
{"epoch": 32, "training_loss": 5003.496841430664, "training_acc": 58.0, "val_loss": 2296.904754638672, "val_acc": 56.0}
{"epoch": 33, "training_loss": 7000.510162353516, "training_acc": 57.0, "val_loss": 1449.340534210205, "val_acc": 48.0}
{"epoch": 34, "training_loss": 6860.161842346191, "training_acc": 52.0, "val_loss": 1394.6239471435547, "val_acc": 60.0}
{"epoch": 35, "training_loss": 4114.495979309082, "training_acc": 54.0, "val_loss": 523.7057209014893, "val_acc": 60.0}
{"epoch": 36, "training_loss": 2817.7156524658203, "training_acc": 61.0, "val_loss": 443.30782890319824, "val_acc": 48.0}
{"epoch": 37, "training_loss": 3388.3812294006348, "training_acc": 66.0, "val_loss": 1488.3687019348145, "val_acc": 56.0}
{"epoch": 38, "training_loss": 3767.1031188964844, "training_acc": 55.0, "val_loss": 1006.9454193115234, "val_acc": 60.0}
{"epoch": 39, "training_loss": 2210.1731719970703, "training_acc": 64.0, "val_loss": 339.5840883255005, "val_acc": 44.0}
{"epoch": 40, "training_loss": 2372.1820220947266, "training_acc": 61.0, "val_loss": 292.9380416870117, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1054.3587608337402, "training_acc": 71.0, "val_loss": 419.77434158325195, "val_acc": 64.0}
{"epoch": 42, "training_loss": 2359.3531646728516, "training_acc": 60.0, "val_loss": 1896.8544006347656, "val_acc": 52.0}
{"epoch": 43, "training_loss": 4787.998809814453, "training_acc": 56.0, "val_loss": 3580.096435546875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 13508.373901367188, "training_acc": 47.0, "val_loss": 1134.4684600830078, "val_acc": 52.0}
{"epoch": 45, "training_loss": 2912.2130279541016, "training_acc": 52.0, "val_loss": 672.7030277252197, "val_acc": 52.0}
{"epoch": 46, "training_loss": 4754.331695556641, "training_acc": 40.0, "val_loss": 322.3095655441284, "val_acc": 60.0}
{"epoch": 47, "training_loss": 2663.5664672851562, "training_acc": 59.0, "val_loss": 2133.358383178711, "val_acc": 52.0}
{"epoch": 48, "training_loss": 6417.880577087402, "training_acc": 54.0, "val_loss": 3063.15860748291, "val_acc": 48.0}
{"epoch": 49, "training_loss": 10727.454498291016, "training_acc": 47.0, "val_loss": 2642.443084716797, "val_acc": 52.0}
{"epoch": 50, "training_loss": 10381.643951416016, "training_acc": 53.0, "val_loss": 324.11155700683594, "val_acc": 64.0}
{"epoch": 51, "training_loss": 7123.5850830078125, "training_acc": 59.0, "val_loss": 4635.047912597656, "val_acc": 48.0}
{"epoch": 52, "training_loss": 11486.033493041992, "training_acc": 55.0, "val_loss": 4025.6752014160156, "val_acc": 52.0}
{"epoch": 53, "training_loss": 16103.606994628906, "training_acc": 53.0, "val_loss": 174.14817810058594, "val_acc": 68.0}
{"epoch": 54, "training_loss": 6693.379577636719, "training_acc": 61.0, "val_loss": 3756.57958984375, "val_acc": 48.0}
{"epoch": 55, "training_loss": 8673.890213012695, "training_acc": 57.0, "val_loss": 2390.2631759643555, "val_acc": 52.0}
{"epoch": 56, "training_loss": 6779.194217681885, "training_acc": 56.0, "val_loss": 1776.2401580810547, "val_acc": 48.0}
{"epoch": 57, "training_loss": 5422.705123901367, "training_acc": 50.0, "val_loss": 224.788236618042, "val_acc": 60.0}
{"epoch": 58, "training_loss": 3776.3130798339844, "training_acc": 60.0, "val_loss": 1040.7299995422363, "val_acc": 60.0}
{"epoch": 59, "training_loss": 2617.7390747070312, "training_acc": 60.0, "val_loss": 2647.689628601074, "val_acc": 48.0}
{"epoch": 60, "training_loss": 8052.659236907959, "training_acc": 52.0, "val_loss": 2499.62158203125, "val_acc": 52.0}
{"epoch": 61, "training_loss": 6699.749122619629, "training_acc": 55.0, "val_loss": 3229.1820526123047, "val_acc": 48.0}
{"epoch": 62, "training_loss": 11517.144073486328, "training_acc": 47.0, "val_loss": 2272.343635559082, "val_acc": 52.0}
{"epoch": 63, "training_loss": 5945.920394897461, "training_acc": 55.0, "val_loss": 644.1025733947754, "val_acc": 40.0}
{"epoch": 64, "training_loss": 2203.5011711120605, "training_acc": 63.0, "val_loss": 693.9968109130859, "val_acc": 64.0}
{"epoch": 65, "training_loss": 1218.6423721313477, "training_acc": 73.0, "val_loss": 837.5572204589844, "val_acc": 48.0}
{"epoch": 66, "training_loss": 3235.6430053710938, "training_acc": 62.0, "val_loss": 394.956111907959, "val_acc": 56.0}
{"epoch": 67, "training_loss": 1878.3736572265625, "training_acc": 69.0, "val_loss": 601.7033576965332, "val_acc": 64.0}
{"epoch": 68, "training_loss": 1349.566650390625, "training_acc": 72.0, "val_loss": 1331.413745880127, "val_acc": 48.0}
{"epoch": 69, "training_loss": 5160.36653137207, "training_acc": 45.0, "val_loss": 252.37669944763184, "val_acc": 60.0}
{"epoch": 70, "training_loss": 2786.3455963134766, "training_acc": 64.0, "val_loss": 2871.376609802246, "val_acc": 52.0}
{"epoch": 71, "training_loss": 8226.837020874023, "training_acc": 55.0, "val_loss": 1018.5516357421875, "val_acc": 48.0}
{"epoch": 72, "training_loss": 4856.571044921875, "training_acc": 53.0, "val_loss": 3386.979293823242, "val_acc": 52.0}
