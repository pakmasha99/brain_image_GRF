"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72380.27456665039, "training_acc": 45.0, "val_loss": 10724.571228027344, "val_acc": 48.0}
{"epoch": 1, "training_loss": 54366.95361328125, "training_acc": 51.0, "val_loss": 32947.68981933594, "val_acc": 52.0}
{"epoch": 2, "training_loss": 128212.314453125, "training_acc": 53.0, "val_loss": 25425.755310058594, "val_acc": 52.0}
{"epoch": 3, "training_loss": 77043.94262695312, "training_acc": 53.0, "val_loss": 5537.215042114258, "val_acc": 48.0}
{"epoch": 4, "training_loss": 32542.138671875, "training_acc": 47.0, "val_loss": 14916.915893554688, "val_acc": 48.0}
{"epoch": 5, "training_loss": 51033.296630859375, "training_acc": 47.0, "val_loss": 834.1076850891113, "val_acc": 52.0}
{"epoch": 6, "training_loss": 9819.433410644531, "training_acc": 54.0, "val_loss": 4183.894348144531, "val_acc": 52.0}
{"epoch": 7, "training_loss": 11939.181365966797, "training_acc": 52.0, "val_loss": 1291.4158821105957, "val_acc": 48.0}
{"epoch": 8, "training_loss": 9799.617004394531, "training_acc": 39.0, "val_loss": 2985.626792907715, "val_acc": 52.0}
{"epoch": 9, "training_loss": 10214.95620727539, "training_acc": 50.0, "val_loss": 1785.0332260131836, "val_acc": 48.0}
{"epoch": 10, "training_loss": 5652.460876464844, "training_acc": 56.0, "val_loss": 2040.989875793457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 8850.642303466797, "training_acc": 47.0, "val_loss": 1026.2248039245605, "val_acc": 48.0}
{"epoch": 12, "training_loss": 10723.11962890625, "training_acc": 43.0, "val_loss": 4215.523529052734, "val_acc": 52.0}
{"epoch": 13, "training_loss": 11711.164558410645, "training_acc": 55.0, "val_loss": 5822.229385375977, "val_acc": 48.0}
{"epoch": 14, "training_loss": 23645.240234375, "training_acc": 47.0, "val_loss": 3362.915802001953, "val_acc": 48.0}
{"epoch": 15, "training_loss": 11081.051788330078, "training_acc": 55.0, "val_loss": 6359.638977050781, "val_acc": 52.0}
{"epoch": 16, "training_loss": 23105.998962402344, "training_acc": 53.0, "val_loss": 872.7473258972168, "val_acc": 48.0}
{"epoch": 17, "training_loss": 11569.87353515625, "training_acc": 52.0, "val_loss": 9611.048889160156, "val_acc": 48.0}
{"epoch": 18, "training_loss": 34694.002197265625, "training_acc": 47.0, "val_loss": 1358.0924987792969, "val_acc": 48.0}
{"epoch": 19, "training_loss": 11501.184143066406, "training_acc": 57.0, "val_loss": 10634.21859741211, "val_acc": 52.0}
{"epoch": 20, "training_loss": 39514.031005859375, "training_acc": 53.0, "val_loss": 6842.7886962890625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 16842.077308654785, "training_acc": 57.0, "val_loss": 7986.091613769531, "val_acc": 48.0}
{"epoch": 22, "training_loss": 34860.33557128906, "training_acc": 47.0, "val_loss": 9387.650299072266, "val_acc": 48.0}
{"epoch": 23, "training_loss": 27685.172790527344, "training_acc": 47.0, "val_loss": 5400.777053833008, "val_acc": 52.0}
{"epoch": 24, "training_loss": 28490.6640625, "training_acc": 53.0, "val_loss": 10367.139434814453, "val_acc": 52.0}
{"epoch": 25, "training_loss": 35662.35040283203, "training_acc": 53.0, "val_loss": 405.3785800933838, "val_acc": 60.0}
{"epoch": 26, "training_loss": 11035.135559082031, "training_acc": 50.0, "val_loss": 8547.806549072266, "val_acc": 48.0}
{"epoch": 27, "training_loss": 28716.973205566406, "training_acc": 47.0, "val_loss": 870.9235191345215, "val_acc": 48.0}
{"epoch": 28, "training_loss": 8510.533508300781, "training_acc": 58.0, "val_loss": 4216.174697875977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 12125.931800842285, "training_acc": 57.0, "val_loss": 2895.160675048828, "val_acc": 48.0}
{"epoch": 30, "training_loss": 9062.60415649414, "training_acc": 50.0, "val_loss": 3274.2782592773438, "val_acc": 52.0}
{"epoch": 31, "training_loss": 13266.65576171875, "training_acc": 53.0, "val_loss": 1801.0364532470703, "val_acc": 52.0}
{"epoch": 32, "training_loss": 6884.574401855469, "training_acc": 61.0, "val_loss": 5719.388580322266, "val_acc": 48.0}
{"epoch": 33, "training_loss": 17538.9931640625, "training_acc": 46.0, "val_loss": 3216.715621948242, "val_acc": 52.0}
{"epoch": 34, "training_loss": 13220.72802734375, "training_acc": 53.0, "val_loss": 2356.3358306884766, "val_acc": 52.0}
{"epoch": 35, "training_loss": 11209.165344238281, "training_acc": 48.0, "val_loss": 4485.681915283203, "val_acc": 48.0}
{"epoch": 36, "training_loss": 12304.150665283203, "training_acc": 48.0, "val_loss": 3356.354522705078, "val_acc": 52.0}
{"epoch": 37, "training_loss": 11945.792602539062, "training_acc": 54.0, "val_loss": 523.9123821258545, "val_acc": 64.0}
{"epoch": 38, "training_loss": 7380.080383300781, "training_acc": 54.0, "val_loss": 2109.194755554199, "val_acc": 48.0}
{"epoch": 39, "training_loss": 8513.845733642578, "training_acc": 49.0, "val_loss": 4376.788330078125, "val_acc": 52.0}
{"epoch": 40, "training_loss": 12192.304779052734, "training_acc": 54.0, "val_loss": 3497.857666015625, "val_acc": 48.0}
{"epoch": 41, "training_loss": 14255.717651367188, "training_acc": 47.0, "val_loss": 584.8953247070312, "val_acc": 64.0}
{"epoch": 42, "training_loss": 6332.459777832031, "training_acc": 65.0, "val_loss": 4316.550064086914, "val_acc": 52.0}
{"epoch": 43, "training_loss": 10799.50814819336, "training_acc": 56.0, "val_loss": 5482.799530029297, "val_acc": 48.0}
{"epoch": 44, "training_loss": 24198.797729492188, "training_acc": 47.0, "val_loss": 4957.397842407227, "val_acc": 48.0}
