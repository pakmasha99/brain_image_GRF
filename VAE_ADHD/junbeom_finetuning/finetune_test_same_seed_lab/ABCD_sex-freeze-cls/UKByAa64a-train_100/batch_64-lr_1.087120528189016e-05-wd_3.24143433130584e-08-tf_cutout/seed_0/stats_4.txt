"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25665163993835, "training_acc": 53.0, "val_loss": 17.308783531188965, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17915511131287, "training_acc": 53.0, "val_loss": 17.308801412582397, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.29633808135986, "training_acc": 53.0, "val_loss": 17.308612167835236, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20210337638855, "training_acc": 53.0, "val_loss": 17.3085018992424, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20115447044373, "training_acc": 53.0, "val_loss": 17.308399081230164, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.99575090408325, "training_acc": 53.0, "val_loss": 17.30828881263733, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09898114204407, "training_acc": 53.0, "val_loss": 17.308177053928375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11005067825317, "training_acc": 53.0, "val_loss": 17.30811595916748, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15764570236206, "training_acc": 53.0, "val_loss": 17.308105528354645, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22237467765808, "training_acc": 53.0, "val_loss": 17.30808913707733, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19332242012024, "training_acc": 53.0, "val_loss": 17.308145761489868, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.08882212638855, "training_acc": 53.0, "val_loss": 17.308124899864197, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22491025924683, "training_acc": 53.0, "val_loss": 17.308150231838226, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22787594795227, "training_acc": 53.0, "val_loss": 17.308223247528076, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15816831588745, "training_acc": 53.0, "val_loss": 17.308220267295837, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.25251364707947, "training_acc": 53.0, "val_loss": 17.308272421360016, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.94722867012024, "training_acc": 53.0, "val_loss": 17.30823814868927, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27907395362854, "training_acc": 53.0, "val_loss": 17.308230698108673, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29004430770874, "training_acc": 53.0, "val_loss": 17.308242619037628, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20114994049072, "training_acc": 53.0, "val_loss": 17.30828434228897, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2455108165741, "training_acc": 53.0, "val_loss": 17.308254539966583, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14555358886719, "training_acc": 53.0, "val_loss": 17.308177053928375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28487849235535, "training_acc": 53.0, "val_loss": 17.3081636428833, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20872473716736, "training_acc": 53.0, "val_loss": 17.308197915554047, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19304704666138, "training_acc": 53.0, "val_loss": 17.30823665857315, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.36034727096558, "training_acc": 53.0, "val_loss": 17.308257520198822, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18026566505432, "training_acc": 53.0, "val_loss": 17.308257520198822, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17611718177795, "training_acc": 53.0, "val_loss": 17.308254539966583, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15703463554382, "training_acc": 53.0, "val_loss": 17.308330535888672, "val_acc": 52.0}
