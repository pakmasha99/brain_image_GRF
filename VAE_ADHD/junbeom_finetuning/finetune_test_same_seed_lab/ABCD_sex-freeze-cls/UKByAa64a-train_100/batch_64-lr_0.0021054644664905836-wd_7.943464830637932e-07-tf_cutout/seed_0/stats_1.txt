"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.86094975471497, "training_acc": 59.0, "val_loss": 17.491446435451508, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.73482465744019, "training_acc": 49.0, "val_loss": 18.104854226112366, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.72762370109558, "training_acc": 47.0, "val_loss": 17.36658364534378, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.1640408039093, "training_acc": 53.0, "val_loss": 17.884154617786407, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.16409754753113, "training_acc": 53.0, "val_loss": 17.47771054506302, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.40014290809631, "training_acc": 53.0, "val_loss": 17.36387610435486, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.68832898139954, "training_acc": 42.0, "val_loss": 17.36842691898346, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.02904939651489, "training_acc": 53.0, "val_loss": 17.419078946113586, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12649488449097, "training_acc": 53.0, "val_loss": 17.58323311805725, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.99681973457336, "training_acc": 53.0, "val_loss": 17.503243684768677, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.30683398246765, "training_acc": 53.0, "val_loss": 17.379039525985718, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0197491645813, "training_acc": 58.0, "val_loss": 17.503148317337036, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.1925745010376, "training_acc": 47.0, "val_loss": 17.49531179666519, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.46562886238098, "training_acc": 48.0, "val_loss": 17.37941950559616, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23261189460754, "training_acc": 53.0, "val_loss": 17.672409117221832, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.15634870529175, "training_acc": 53.0, "val_loss": 17.579951882362366, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.98086285591125, "training_acc": 53.0, "val_loss": 17.3682764172554, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12539219856262, "training_acc": 53.0, "val_loss": 17.36491769552231, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.0688087940216, "training_acc": 53.0, "val_loss": 17.374320328235626, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.07599258422852, "training_acc": 56.0, "val_loss": 17.426899075508118, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.436856508255, "training_acc": 47.0, "val_loss": 17.3828125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26987195014954, "training_acc": 56.0, "val_loss": 17.408394813537598, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11370086669922, "training_acc": 53.0, "val_loss": 17.47177094221115, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.29756999015808, "training_acc": 53.0, "val_loss": 17.418548464775085, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.29163074493408, "training_acc": 53.0, "val_loss": 17.36707240343094, "val_acc": 52.0}
