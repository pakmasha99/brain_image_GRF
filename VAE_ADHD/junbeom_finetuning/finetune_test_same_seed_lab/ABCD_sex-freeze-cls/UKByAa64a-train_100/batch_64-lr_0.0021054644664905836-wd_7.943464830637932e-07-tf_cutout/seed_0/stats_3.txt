"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 77.51859307289124, "training_acc": 41.0, "val_loss": 17.661981284618378, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.10316896438599, "training_acc": 51.0, "val_loss": 18.529200553894043, "val_acc": 52.0}
{"epoch": 2, "training_loss": 75.0170464515686, "training_acc": 53.0, "val_loss": 19.091984629631042, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.70884418487549, "training_acc": 53.0, "val_loss": 17.502044141292572, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.37006068229675, "training_acc": 52.0, "val_loss": 17.4394428730011, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.48613286018372, "training_acc": 47.0, "val_loss": 17.644481360912323, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.95320868492126, "training_acc": 47.0, "val_loss": 17.351137101650238, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1197624206543, "training_acc": 56.0, "val_loss": 17.335446178913116, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.89767098426819, "training_acc": 53.0, "val_loss": 17.658719420433044, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.38304543495178, "training_acc": 53.0, "val_loss": 17.747725546360016, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.23515677452087, "training_acc": 53.0, "val_loss": 17.379944026470184, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.08761286735535, "training_acc": 53.0, "val_loss": 17.345847189426422, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.92064213752747, "training_acc": 47.0, "val_loss": 17.511485517024994, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.12696027755737, "training_acc": 47.0, "val_loss": 17.340660095214844, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18627095222473, "training_acc": 55.0, "val_loss": 17.358317971229553, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.00943994522095, "training_acc": 53.0, "val_loss": 17.700500786304474, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.49790501594543, "training_acc": 53.0, "val_loss": 17.78615117073059, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.38095164299011, "training_acc": 53.0, "val_loss": 17.39543527364731, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.98563623428345, "training_acc": 54.0, "val_loss": 17.402993142604828, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.34989094734192, "training_acc": 47.0, "val_loss": 17.48158484697342, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.24826216697693, "training_acc": 47.0, "val_loss": 17.297248542308807, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22952771186829, "training_acc": 53.0, "val_loss": 17.39746779203415, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.63307929039001, "training_acc": 53.0, "val_loss": 17.4567773938179, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.48713231086731, "training_acc": 53.0, "val_loss": 17.316845059394836, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.43585228919983, "training_acc": 52.0, "val_loss": 17.299453914165497, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14202499389648, "training_acc": 53.0, "val_loss": 17.301708459854126, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.0605878829956, "training_acc": 53.0, "val_loss": 17.313602566719055, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.08990454673767, "training_acc": 53.0, "val_loss": 17.358197271823883, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1783275604248, "training_acc": 53.0, "val_loss": 17.37554520368576, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.29197955131531, "training_acc": 53.0, "val_loss": 17.339028418064117, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12293219566345, "training_acc": 53.0, "val_loss": 17.314834892749786, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.18810534477234, "training_acc": 48.0, "val_loss": 17.349891364574432, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.09260630607605, "training_acc": 53.0, "val_loss": 17.34362691640854, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.0667953491211, "training_acc": 53.0, "val_loss": 17.644427716732025, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.96359586715698, "training_acc": 53.0, "val_loss": 17.62186735868454, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.06391501426697, "training_acc": 53.0, "val_loss": 17.427654564380646, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22801613807678, "training_acc": 53.0, "val_loss": 17.32509583234787, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.41028165817261, "training_acc": 53.0, "val_loss": 17.306049168109894, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1307647228241, "training_acc": 53.0, "val_loss": 17.31235831975937, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11698198318481, "training_acc": 53.0, "val_loss": 17.326486110687256, "val_acc": 52.0}
