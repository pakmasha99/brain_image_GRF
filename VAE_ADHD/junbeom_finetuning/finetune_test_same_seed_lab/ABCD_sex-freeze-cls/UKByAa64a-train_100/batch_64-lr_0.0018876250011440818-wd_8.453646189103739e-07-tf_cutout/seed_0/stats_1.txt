"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.66711902618408, "training_acc": 46.0, "val_loss": 17.303909361362457, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.20956873893738, "training_acc": 53.0, "val_loss": 17.275016009807587, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.45484590530396, "training_acc": 45.0, "val_loss": 17.2885000705719, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09655332565308, "training_acc": 56.0, "val_loss": 17.27050542831421, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15196943283081, "training_acc": 53.0, "val_loss": 17.312249541282654, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.35015535354614, "training_acc": 53.0, "val_loss": 17.324528098106384, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.33090162277222, "training_acc": 53.0, "val_loss": 17.27966070175171, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.03190970420837, "training_acc": 53.0, "val_loss": 17.27525442838669, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.99470853805542, "training_acc": 53.0, "val_loss": 17.27360486984253, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.93105387687683, "training_acc": 53.0, "val_loss": 17.28750616312027, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.80906391143799, "training_acc": 53.0, "val_loss": 17.304639518260956, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.05567264556885, "training_acc": 53.0, "val_loss": 17.31112450361252, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10020065307617, "training_acc": 53.0, "val_loss": 17.27544814348221, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.82510733604431, "training_acc": 53.0, "val_loss": 17.253895103931427, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.88565945625305, "training_acc": 52.0, "val_loss": 17.256323993206024, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.91172480583191, "training_acc": 59.0, "val_loss": 17.26464182138443, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.70625257492065, "training_acc": 60.0, "val_loss": 17.25117862224579, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.89853358268738, "training_acc": 53.0, "val_loss": 17.241504788398743, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.92763948440552, "training_acc": 54.0, "val_loss": 17.246916890144348, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.67084860801697, "training_acc": 53.0, "val_loss": 17.29864776134491, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.69381904602051, "training_acc": 53.0, "val_loss": 17.318060994148254, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.6593930721283, "training_acc": 53.0, "val_loss": 17.27771759033203, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.59757590293884, "training_acc": 53.0, "val_loss": 17.247207462787628, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.40047597885132, "training_acc": 54.0, "val_loss": 17.2464057803154, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.51496648788452, "training_acc": 56.0, "val_loss": 17.251715064048767, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.33137106895447, "training_acc": 54.0, "val_loss": 17.248988151550293, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.47138452529907, "training_acc": 60.0, "val_loss": 17.246635258197784, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.63061785697937, "training_acc": 55.0, "val_loss": 17.265750467777252, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.45423579216003, "training_acc": 54.0, "val_loss": 17.288072407245636, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.69876313209534, "training_acc": 53.0, "val_loss": 17.285077273845673, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.91392183303833, "training_acc": 53.0, "val_loss": 17.297227680683136, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.22841596603394, "training_acc": 53.0, "val_loss": 17.295178771018982, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.5802230834961, "training_acc": 53.0, "val_loss": 17.288753390312195, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.45776319503784, "training_acc": 52.0, "val_loss": 17.265693843364716, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.67217326164246, "training_acc": 51.0, "val_loss": 17.246772348880768, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.77356171607971, "training_acc": 57.0, "val_loss": 17.26459115743637, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.4461259841919, "training_acc": 60.0, "val_loss": 17.293861508369446, "val_acc": 52.0}
