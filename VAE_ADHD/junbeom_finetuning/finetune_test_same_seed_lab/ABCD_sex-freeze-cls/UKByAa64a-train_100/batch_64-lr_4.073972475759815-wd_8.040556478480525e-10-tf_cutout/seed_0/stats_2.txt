"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 9473.181869506836, "training_acc": 46.0, "val_loss": 2230.297088623047, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10223.116271972656, "training_acc": 47.0, "val_loss": 3671.086883544922, "val_acc": 48.0}
{"epoch": 2, "training_loss": 13259.042541503906, "training_acc": 47.0, "val_loss": 246.2371826171875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3661.537628173828, "training_acc": 55.0, "val_loss": 4190.638732910156, "val_acc": 52.0}
{"epoch": 4, "training_loss": 16488.629028320312, "training_acc": 53.0, "val_loss": 3954.5459747314453, "val_acc": 52.0}
{"epoch": 5, "training_loss": 13152.561492919922, "training_acc": 53.0, "val_loss": 524.2142200469971, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4411.766754150391, "training_acc": 50.0, "val_loss": 3480.3543090820312, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14900.253112792969, "training_acc": 47.0, "val_loss": 3130.60302734375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 11203.122024536133, "training_acc": 47.0, "val_loss": 192.66713857650757, "val_acc": 56.0}
{"epoch": 9, "training_loss": 2433.4070434570312, "training_acc": 55.0, "val_loss": 1733.207130432129, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5974.244110107422, "training_acc": 53.0, "val_loss": 446.50235176086426, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2399.4325103759766, "training_acc": 53.0, "val_loss": 1685.072135925293, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6427.137725830078, "training_acc": 47.0, "val_loss": 546.3997840881348, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2638.394271850586, "training_acc": 49.0, "val_loss": 1633.540916442871, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6297.158355712891, "training_acc": 53.0, "val_loss": 1064.7055625915527, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2878.8372898101807, "training_acc": 51.0, "val_loss": 764.8062705993652, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2945.827980041504, "training_acc": 47.0, "val_loss": 168.7345027923584, "val_acc": 60.0}
{"epoch": 17, "training_loss": 869.3143501281738, "training_acc": 58.0, "val_loss": 102.92527675628662, "val_acc": 52.0}
{"epoch": 18, "training_loss": 961.3960342407227, "training_acc": 58.0, "val_loss": 251.90188884735107, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1349.1054153442383, "training_acc": 50.0, "val_loss": 564.2370700836182, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1502.8013305664062, "training_acc": 52.0, "val_loss": 493.3220863342285, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1393.7804889678955, "training_acc": 51.0, "val_loss": 415.7024383544922, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1575.0673599243164, "training_acc": 53.0, "val_loss": 205.2088975906372, "val_acc": 48.0}
{"epoch": 23, "training_loss": 815.0166015625, "training_acc": 48.0, "val_loss": 257.214617729187, "val_acc": 52.0}
{"epoch": 24, "training_loss": 701.7300090789795, "training_acc": 60.0, "val_loss": 241.88148975372314, "val_acc": 44.0}
{"epoch": 25, "training_loss": 829.1291561126709, "training_acc": 49.0, "val_loss": 432.6998710632324, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1519.2919273376465, "training_acc": 53.0, "val_loss": 256.595516204834, "val_acc": 48.0}
{"epoch": 27, "training_loss": 814.4818286895752, "training_acc": 53.0, "val_loss": 317.38903522491455, "val_acc": 52.0}
{"epoch": 28, "training_loss": 722.0413208007812, "training_acc": 51.0, "val_loss": 251.36008262634277, "val_acc": 44.0}
{"epoch": 29, "training_loss": 905.504825592041, "training_acc": 55.0, "val_loss": 561.5311145782471, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1697.0272827148438, "training_acc": 53.0, "val_loss": 261.65130138397217, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1156.1855964660645, "training_acc": 47.0, "val_loss": 377.29814052581787, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1143.4222984313965, "training_acc": 56.0, "val_loss": 131.44265413284302, "val_acc": 52.0}
{"epoch": 33, "training_loss": 583.8968696594238, "training_acc": 52.0, "val_loss": 664.970588684082, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2419.1174697875977, "training_acc": 53.0, "val_loss": 367.9178476333618, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1990.7711563110352, "training_acc": 44.0, "val_loss": 886.9538307189941, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2544.347541809082, "training_acc": 47.0, "val_loss": 848.8934516906738, "val_acc": 52.0}
