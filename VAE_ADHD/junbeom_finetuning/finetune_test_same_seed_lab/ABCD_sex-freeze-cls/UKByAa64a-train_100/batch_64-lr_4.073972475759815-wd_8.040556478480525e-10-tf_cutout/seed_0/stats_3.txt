"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 6676.079544067383, "training_acc": 51.0, "val_loss": 1145.4959869384766, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9400.497009277344, "training_acc": 46.0, "val_loss": 5087.530517578125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 19242.42413330078, "training_acc": 47.0, "val_loss": 1164.5151138305664, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5532.691604614258, "training_acc": 53.0, "val_loss": 3896.930694580078, "val_acc": 52.0}
{"epoch": 4, "training_loss": 14004.111572265625, "training_acc": 53.0, "val_loss": 3761.6260528564453, "val_acc": 52.0}
{"epoch": 5, "training_loss": 10306.999298095703, "training_acc": 53.0, "val_loss": 364.2207622528076, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4018.997314453125, "training_acc": 47.0, "val_loss": 2947.317886352539, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12448.29995727539, "training_acc": 47.0, "val_loss": 1786.496925354004, "val_acc": 48.0}
{"epoch": 8, "training_loss": 5822.406078338623, "training_acc": 43.0, "val_loss": 1657.58056640625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5660.109405517578, "training_acc": 54.0, "val_loss": 2235.7728958129883, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5926.234680175781, "training_acc": 53.0, "val_loss": 273.9060878753662, "val_acc": 36.0}
{"epoch": 11, "training_loss": 2690.0311431884766, "training_acc": 50.0, "val_loss": 1330.442714691162, "val_acc": 48.0}
{"epoch": 12, "training_loss": 5144.704986572266, "training_acc": 47.0, "val_loss": 618.1427955627441, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2370.030548095703, "training_acc": 56.0, "val_loss": 1120.1278686523438, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2344.548511505127, "training_acc": 53.0, "val_loss": 718.7088012695312, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3706.577102661133, "training_acc": 47.0, "val_loss": 358.78422260284424, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2255.256019592285, "training_acc": 47.0, "val_loss": 1424.478530883789, "val_acc": 52.0}
{"epoch": 17, "training_loss": 4297.221450805664, "training_acc": 53.0, "val_loss": 449.27477836608887, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2301.81396484375, "training_acc": 48.0, "val_loss": 1142.0476913452148, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4382.944412231445, "training_acc": 47.0, "val_loss": 492.0458793640137, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1700.9945983886719, "training_acc": 58.0, "val_loss": 818.6502456665039, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1562.5565242767334, "training_acc": 54.0, "val_loss": 424.30734634399414, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1715.1793117523193, "training_acc": 52.0, "val_loss": 639.7943496704102, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1559.137954711914, "training_acc": 54.0, "val_loss": 78.34365963935852, "val_acc": 56.0}
{"epoch": 24, "training_loss": 889.6569976806641, "training_acc": 62.0, "val_loss": 168.69940757751465, "val_acc": 52.0}
{"epoch": 25, "training_loss": 795.9348831176758, "training_acc": 62.0, "val_loss": 59.643685817718506, "val_acc": 60.0}
{"epoch": 26, "training_loss": 508.11217308044434, "training_acc": 59.0, "val_loss": 267.30480194091797, "val_acc": 52.0}
{"epoch": 27, "training_loss": 706.214319229126, "training_acc": 57.0, "val_loss": 387.65881061553955, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1638.2502403259277, "training_acc": 43.0, "val_loss": 590.9457683563232, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1823.0594482421875, "training_acc": 53.0, "val_loss": 145.5666184425354, "val_acc": 52.0}
{"epoch": 30, "training_loss": 739.1134605407715, "training_acc": 64.0, "val_loss": 482.6694965362549, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1379.5757732391357, "training_acc": 56.0, "val_loss": 424.10736083984375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 625.9137773513794, "training_acc": 63.0, "val_loss": 449.0236759185791, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1683.925521850586, "training_acc": 47.0, "val_loss": 653.2039642333984, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2175.982322692871, "training_acc": 53.0, "val_loss": 408.5099697113037, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1357.7959289550781, "training_acc": 56.0, "val_loss": 733.5587501525879, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2263.5994911193848, "training_acc": 46.0, "val_loss": 1067.9221153259277, "val_acc": 52.0}
{"epoch": 37, "training_loss": 3787.981216430664, "training_acc": 53.0, "val_loss": 1300.69580078125, "val_acc": 52.0}
{"epoch": 38, "training_loss": 3113.593074798584, "training_acc": 54.0, "val_loss": 889.7523880004883, "val_acc": 48.0}
{"epoch": 39, "training_loss": 4808.855621337891, "training_acc": 47.0, "val_loss": 1124.5973587036133, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3214.914463043213, "training_acc": 51.0, "val_loss": 1337.7544403076172, "val_acc": 52.0}
{"epoch": 41, "training_loss": 5595.367431640625, "training_acc": 53.0, "val_loss": 2005.2614212036133, "val_acc": 52.0}
{"epoch": 42, "training_loss": 5736.199325561523, "training_acc": 53.0, "val_loss": 87.28938102722168, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1372.3354721069336, "training_acc": 58.0, "val_loss": 648.0916023254395, "val_acc": 48.0}
{"epoch": 44, "training_loss": 2258.562826156616, "training_acc": 53.0, "val_loss": 960.4496002197266, "val_acc": 52.0}
