"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1479.0933647155762, "training_acc": 50.0, "val_loss": 301.3383150100708, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1173.5050773620605, "training_acc": 53.0, "val_loss": 508.47668647766113, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1866.5594329833984, "training_acc": 47.0, "val_loss": 116.22684001922607, "val_acc": 48.0}
{"epoch": 3, "training_loss": 626.1375999450684, "training_acc": 51.0, "val_loss": 451.03259086608887, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1751.608699798584, "training_acc": 53.0, "val_loss": 383.0850124359131, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1242.0368728637695, "training_acc": 53.0, "val_loss": 66.67540073394775, "val_acc": 48.0}
{"epoch": 6, "training_loss": 376.8465633392334, "training_acc": 48.0, "val_loss": 170.72323560714722, "val_acc": 48.0}
{"epoch": 7, "training_loss": 475.97836685180664, "training_acc": 48.0, "val_loss": 147.49302864074707, "val_acc": 52.0}
{"epoch": 8, "training_loss": 699.301700592041, "training_acc": 53.0, "val_loss": 226.95019245147705, "val_acc": 52.0}
{"epoch": 9, "training_loss": 732.0137634277344, "training_acc": 53.0, "val_loss": 51.270079612731934, "val_acc": 44.0}
{"epoch": 10, "training_loss": 279.57107734680176, "training_acc": 48.0, "val_loss": 97.60816693305969, "val_acc": 48.0}
{"epoch": 11, "training_loss": 272.0065567493439, "training_acc": 52.0, "val_loss": 82.40443468093872, "val_acc": 52.0}
{"epoch": 12, "training_loss": 271.14186000823975, "training_acc": 53.0, "val_loss": 44.7712242603302, "val_acc": 48.0}
{"epoch": 13, "training_loss": 196.59884643554688, "training_acc": 49.0, "val_loss": 28.17455232143402, "val_acc": 56.0}
{"epoch": 14, "training_loss": 106.82063150405884, "training_acc": 55.0, "val_loss": 19.442981481552124, "val_acc": 56.0}
{"epoch": 15, "training_loss": 104.1442322731018, "training_acc": 62.0, "val_loss": 21.085047721862793, "val_acc": 56.0}
{"epoch": 16, "training_loss": 102.46969699859619, "training_acc": 56.0, "val_loss": 20.479238033294678, "val_acc": 60.0}
{"epoch": 17, "training_loss": 92.81514477729797, "training_acc": 52.0, "val_loss": 27.38097310066223, "val_acc": 52.0}
{"epoch": 18, "training_loss": 84.1093270778656, "training_acc": 60.0, "val_loss": 20.67699432373047, "val_acc": 56.0}
{"epoch": 19, "training_loss": 84.82815933227539, "training_acc": 56.0, "val_loss": 18.675346672534943, "val_acc": 64.0}
{"epoch": 20, "training_loss": 71.66989183425903, "training_acc": 63.0, "val_loss": 38.491591811180115, "val_acc": 52.0}
{"epoch": 21, "training_loss": 106.99960398674011, "training_acc": 59.0, "val_loss": 44.20704543590546, "val_acc": 48.0}
{"epoch": 22, "training_loss": 121.13152170181274, "training_acc": 53.0, "val_loss": 92.29434132575989, "val_acc": 52.0}
{"epoch": 23, "training_loss": 301.0045471191406, "training_acc": 53.0, "val_loss": 22.29117900133133, "val_acc": 52.0}
{"epoch": 24, "training_loss": 152.9526662826538, "training_acc": 61.0, "val_loss": 36.537280678749084, "val_acc": 44.0}
{"epoch": 25, "training_loss": 216.31825828552246, "training_acc": 45.0, "val_loss": 92.4642264842987, "val_acc": 52.0}
{"epoch": 26, "training_loss": 242.91353154182434, "training_acc": 54.0, "val_loss": 58.45652222633362, "val_acc": 48.0}
{"epoch": 27, "training_loss": 193.1248869895935, "training_acc": 54.0, "val_loss": 79.19991612434387, "val_acc": 52.0}
{"epoch": 28, "training_loss": 224.9448127746582, "training_acc": 55.0, "val_loss": 31.68116807937622, "val_acc": 40.0}
{"epoch": 29, "training_loss": 125.27833700180054, "training_acc": 49.0, "val_loss": 69.97419595718384, "val_acc": 52.0}
{"epoch": 30, "training_loss": 210.88025903701782, "training_acc": 53.0, "val_loss": 23.74327778816223, "val_acc": 52.0}
{"epoch": 31, "training_loss": 126.88630962371826, "training_acc": 49.0, "val_loss": 56.515175104141235, "val_acc": 52.0}
{"epoch": 32, "training_loss": 179.20025539398193, "training_acc": 54.0, "val_loss": 26.188039779663086, "val_acc": 52.0}
{"epoch": 33, "training_loss": 151.73394775390625, "training_acc": 46.0, "val_loss": 56.19686841964722, "val_acc": 52.0}
{"epoch": 34, "training_loss": 158.76439714431763, "training_acc": 54.0, "val_loss": 40.404143929481506, "val_acc": 44.0}
{"epoch": 35, "training_loss": 122.26245594024658, "training_acc": 50.0, "val_loss": 53.828686475753784, "val_acc": 52.0}
{"epoch": 36, "training_loss": 156.68456959724426, "training_acc": 55.0, "val_loss": 51.68781876564026, "val_acc": 48.0}
{"epoch": 37, "training_loss": 165.736976146698, "training_acc": 49.0, "val_loss": 35.58116555213928, "val_acc": 52.0}
{"epoch": 38, "training_loss": 99.68999791145325, "training_acc": 58.0, "val_loss": 38.623154163360596, "val_acc": 44.0}
