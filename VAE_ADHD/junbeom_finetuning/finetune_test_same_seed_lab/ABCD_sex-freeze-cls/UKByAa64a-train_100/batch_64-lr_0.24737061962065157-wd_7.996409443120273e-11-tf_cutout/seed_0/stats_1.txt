"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 563.9550247192383, "training_acc": 46.0, "val_loss": 108.46441984176636, "val_acc": 52.0}
{"epoch": 1, "training_loss": 527.6093101501465, "training_acc": 53.0, "val_loss": 281.2866687774658, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1058.1596870422363, "training_acc": 47.0, "val_loss": 77.9751718044281, "val_acc": 48.0}
{"epoch": 3, "training_loss": 368.52042865753174, "training_acc": 51.0, "val_loss": 205.3727388381958, "val_acc": 52.0}
{"epoch": 4, "training_loss": 780.9783477783203, "training_acc": 53.0, "val_loss": 183.23653936386108, "val_acc": 52.0}
{"epoch": 5, "training_loss": 544.5041494369507, "training_acc": 53.0, "val_loss": 33.93325209617615, "val_acc": 48.0}
{"epoch": 6, "training_loss": 306.01168060302734, "training_acc": 47.0, "val_loss": 104.2452335357666, "val_acc": 48.0}
{"epoch": 7, "training_loss": 363.19870471954346, "training_acc": 47.0, "val_loss": 51.810044050216675, "val_acc": 52.0}
{"epoch": 8, "training_loss": 206.87133502960205, "training_acc": 53.0, "val_loss": 98.86845350265503, "val_acc": 52.0}
{"epoch": 9, "training_loss": 310.59563302993774, "training_acc": 53.0, "val_loss": 18.20419281721115, "val_acc": 56.0}
{"epoch": 10, "training_loss": 139.010160446167, "training_acc": 48.0, "val_loss": 43.960583209991455, "val_acc": 48.0}
{"epoch": 11, "training_loss": 161.4368190765381, "training_acc": 44.0, "val_loss": 43.715694546699524, "val_acc": 52.0}
{"epoch": 12, "training_loss": 142.2582654953003, "training_acc": 53.0, "val_loss": 17.910577356815338, "val_acc": 52.0}
{"epoch": 13, "training_loss": 82.04877495765686, "training_acc": 51.0, "val_loss": 20.642143487930298, "val_acc": 48.0}
{"epoch": 14, "training_loss": 77.82647275924683, "training_acc": 56.0, "val_loss": 31.195572018623352, "val_acc": 52.0}
{"epoch": 15, "training_loss": 92.77246189117432, "training_acc": 55.0, "val_loss": 20.813648402690887, "val_acc": 48.0}
{"epoch": 16, "training_loss": 84.63085842132568, "training_acc": 49.0, "val_loss": 22.063101828098297, "val_acc": 52.0}
{"epoch": 17, "training_loss": 81.19196772575378, "training_acc": 55.0, "val_loss": 16.686779260635376, "val_acc": 56.0}
{"epoch": 18, "training_loss": 92.15411043167114, "training_acc": 50.0, "val_loss": 19.07522976398468, "val_acc": 56.0}
{"epoch": 19, "training_loss": 85.92652797698975, "training_acc": 57.0, "val_loss": 20.043975114822388, "val_acc": 52.0}
{"epoch": 20, "training_loss": 64.52786660194397, "training_acc": 64.0, "val_loss": 22.39324003458023, "val_acc": 48.0}
{"epoch": 21, "training_loss": 89.00209760665894, "training_acc": 53.0, "val_loss": 26.484930515289307, "val_acc": 52.0}
{"epoch": 22, "training_loss": 77.7462306022644, "training_acc": 58.0, "val_loss": 18.612700700759888, "val_acc": 48.0}
{"epoch": 23, "training_loss": 70.73646903038025, "training_acc": 60.0, "val_loss": 19.368942081928253, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.7050404548645, "training_acc": 60.0, "val_loss": 17.315414547920227, "val_acc": 64.0}
{"epoch": 25, "training_loss": 63.99120020866394, "training_acc": 66.0, "val_loss": 18.93579810857773, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.3538064956665, "training_acc": 57.0, "val_loss": 18.361131846904755, "val_acc": 56.0}
{"epoch": 27, "training_loss": 63.34436106681824, "training_acc": 61.0, "val_loss": 17.18059480190277, "val_acc": 64.0}
{"epoch": 28, "training_loss": 64.05699896812439, "training_acc": 56.0, "val_loss": 17.51312017440796, "val_acc": 56.0}
{"epoch": 29, "training_loss": 64.09578466415405, "training_acc": 63.0, "val_loss": 22.62006402015686, "val_acc": 52.0}
{"epoch": 30, "training_loss": 75.69046711921692, "training_acc": 55.0, "val_loss": 17.886817455291748, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.40480494499207, "training_acc": 62.0, "val_loss": 23.947517573833466, "val_acc": 52.0}
{"epoch": 32, "training_loss": 76.38379073143005, "training_acc": 54.0, "val_loss": 21.34128510951996, "val_acc": 48.0}
{"epoch": 33, "training_loss": 80.09476017951965, "training_acc": 45.0, "val_loss": 19.935359060764313, "val_acc": 52.0}
{"epoch": 34, "training_loss": 75.80707931518555, "training_acc": 56.0, "val_loss": 25.61935782432556, "val_acc": 48.0}
{"epoch": 35, "training_loss": 98.97488379478455, "training_acc": 47.0, "val_loss": 27.101144194602966, "val_acc": 52.0}
{"epoch": 36, "training_loss": 91.67561268806458, "training_acc": 53.0, "val_loss": 18.833139538764954, "val_acc": 48.0}
