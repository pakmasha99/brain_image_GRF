"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 31269.970123291016, "training_acc": 45.0, "val_loss": 7584.342956542969, "val_acc": 52.0}
{"epoch": 1, "training_loss": 28242.89892578125, "training_acc": 55.0, "val_loss": 13118.043518066406, "val_acc": 48.0}
{"epoch": 2, "training_loss": 48889.55041503906, "training_acc": 47.0, "val_loss": 1866.402816772461, "val_acc": 48.0}
{"epoch": 3, "training_loss": 17874.943969726562, "training_acc": 47.0, "val_loss": 13477.247619628906, "val_acc": 52.0}
{"epoch": 4, "training_loss": 49212.58801269531, "training_acc": 53.0, "val_loss": 11593.409729003906, "val_acc": 52.0}
{"epoch": 5, "training_loss": 35083.84582519531, "training_acc": 53.0, "val_loss": 939.9768829345703, "val_acc": 44.0}
{"epoch": 6, "training_loss": 10344.430603027344, "training_acc": 46.0, "val_loss": 4072.246551513672, "val_acc": 48.0}
{"epoch": 7, "training_loss": 13240.163818359375, "training_acc": 48.0, "val_loss": 4469.39582824707, "val_acc": 52.0}
{"epoch": 8, "training_loss": 13932.054504394531, "training_acc": 55.0, "val_loss": 5827.156066894531, "val_acc": 52.0}
{"epoch": 9, "training_loss": 12992.70620727539, "training_acc": 58.0, "val_loss": 1356.8790435791016, "val_acc": 44.0}
{"epoch": 10, "training_loss": 10521.081726074219, "training_acc": 46.0, "val_loss": 873.182201385498, "val_acc": 36.0}
{"epoch": 11, "training_loss": 5401.175384521484, "training_acc": 59.0, "val_loss": 4934.505844116211, "val_acc": 52.0}
{"epoch": 12, "training_loss": 12107.605102539062, "training_acc": 53.0, "val_loss": 1964.546775817871, "val_acc": 52.0}
{"epoch": 13, "training_loss": 6404.644348144531, "training_acc": 50.0, "val_loss": 1701.140022277832, "val_acc": 48.0}
{"epoch": 14, "training_loss": 6547.8896484375, "training_acc": 52.0, "val_loss": 2699.313735961914, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5597.515487670898, "training_acc": 52.0, "val_loss": 602.4209499359131, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3077.755096435547, "training_acc": 50.0, "val_loss": 2009.8701477050781, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5335.948638916016, "training_acc": 53.0, "val_loss": 346.756649017334, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1985.678352355957, "training_acc": 52.0, "val_loss": 1212.2995376586914, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2547.7105674743652, "training_acc": 62.0, "val_loss": 1008.2733154296875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3845.9022521972656, "training_acc": 50.0, "val_loss": 2370.258331298828, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6688.194534301758, "training_acc": 53.0, "val_loss": 232.0911407470703, "val_acc": 44.0}
{"epoch": 22, "training_loss": 1651.5244522094727, "training_acc": 63.0, "val_loss": 1131.2661170959473, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2232.280445098877, "training_acc": 55.0, "val_loss": 535.2460384368896, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2751.71231842041, "training_acc": 51.0, "val_loss": 641.6164398193359, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1543.6065521240234, "training_acc": 63.0, "val_loss": 393.9150094985962, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1973.223373413086, "training_acc": 56.0, "val_loss": 316.0050392150879, "val_acc": 36.0}
{"epoch": 27, "training_loss": 1398.3682556152344, "training_acc": 61.0, "val_loss": 786.5540027618408, "val_acc": 52.0}
{"epoch": 28, "training_loss": 963.8220653533936, "training_acc": 67.0, "val_loss": 516.444206237793, "val_acc": 52.0}
{"epoch": 29, "training_loss": 881.265079498291, "training_acc": 64.0, "val_loss": 199.8779535293579, "val_acc": 44.0}
{"epoch": 30, "training_loss": 755.0780792236328, "training_acc": 65.0, "val_loss": 467.7800178527832, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1823.4490966796875, "training_acc": 53.0, "val_loss": 150.9802222251892, "val_acc": 44.0}
{"epoch": 32, "training_loss": 939.6389541625977, "training_acc": 66.0, "val_loss": 132.8770875930786, "val_acc": 56.0}
{"epoch": 33, "training_loss": 2123.9832305908203, "training_acc": 52.0, "val_loss": 158.5265040397644, "val_acc": 60.0}
{"epoch": 34, "training_loss": 604.8627090454102, "training_acc": 67.0, "val_loss": 839.1998291015625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2881.0041732788086, "training_acc": 49.0, "val_loss": 114.258873462677, "val_acc": 64.0}
{"epoch": 36, "training_loss": 500.40277194976807, "training_acc": 71.0, "val_loss": 694.4485187530518, "val_acc": 52.0}
{"epoch": 37, "training_loss": 2249.7677688598633, "training_acc": 53.0, "val_loss": 410.5128288269043, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1268.11328125, "training_acc": 53.0, "val_loss": 1803.4976959228516, "val_acc": 52.0}
{"epoch": 39, "training_loss": 4999.785751342773, "training_acc": 53.0, "val_loss": 1155.2682876586914, "val_acc": 48.0}
{"epoch": 40, "training_loss": 4211.872428894043, "training_acc": 47.0, "val_loss": 2408.9956283569336, "val_acc": 52.0}
{"epoch": 41, "training_loss": 8165.953887939453, "training_acc": 53.0, "val_loss": 929.5969009399414, "val_acc": 52.0}
{"epoch": 42, "training_loss": 5161.941436767578, "training_acc": 60.0, "val_loss": 3774.7276306152344, "val_acc": 48.0}
{"epoch": 43, "training_loss": 13795.360229492188, "training_acc": 47.0, "val_loss": 2454.189872741699, "val_acc": 52.0}
{"epoch": 44, "training_loss": 8548.944854736328, "training_acc": 52.0, "val_loss": 3496.3573455810547, "val_acc": 52.0}
{"epoch": 45, "training_loss": 7124.367813110352, "training_acc": 49.0, "val_loss": 2718.183708190918, "val_acc": 48.0}
{"epoch": 46, "training_loss": 13054.7509765625, "training_acc": 47.0, "val_loss": 901.5149116516113, "val_acc": 48.0}
{"epoch": 47, "training_loss": 8538.233520507812, "training_acc": 45.0, "val_loss": 5576.698684692383, "val_acc": 52.0}
{"epoch": 48, "training_loss": 17820.61944580078, "training_acc": 53.0, "val_loss": 1970.8488464355469, "val_acc": 52.0}
{"epoch": 49, "training_loss": 9308.03173828125, "training_acc": 48.0, "val_loss": 5421.427536010742, "val_acc": 48.0}
{"epoch": 50, "training_loss": 21891.490783691406, "training_acc": 47.0, "val_loss": 1188.0471229553223, "val_acc": 48.0}
{"epoch": 51, "training_loss": 9401.439086914062, "training_acc": 45.0, "val_loss": 6713.316345214844, "val_acc": 52.0}
{"epoch": 52, "training_loss": 23664.50927734375, "training_acc": 53.0, "val_loss": 4576.416778564453, "val_acc": 52.0}
{"epoch": 53, "training_loss": 10393.751159667969, "training_acc": 60.0, "val_loss": 3730.4588317871094, "val_acc": 48.0}
{"epoch": 54, "training_loss": 17841.739318847656, "training_acc": 47.0, "val_loss": 3468.1121826171875, "val_acc": 48.0}
