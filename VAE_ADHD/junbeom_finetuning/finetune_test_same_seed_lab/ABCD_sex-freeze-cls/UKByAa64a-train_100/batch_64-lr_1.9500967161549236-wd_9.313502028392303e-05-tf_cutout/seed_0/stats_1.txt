"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4140.110126495361, "training_acc": 46.0, "val_loss": 855.4614067077637, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4157.194351196289, "training_acc": 53.0, "val_loss": 2217.6469802856445, "val_acc": 48.0}
{"epoch": 2, "training_loss": 8345.061126708984, "training_acc": 47.0, "val_loss": 614.394998550415, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2907.0492935180664, "training_acc": 51.0, "val_loss": 1619.251823425293, "val_acc": 52.0}
{"epoch": 4, "training_loss": 6152.498001098633, "training_acc": 53.0, "val_loss": 1444.3021774291992, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4286.5490646362305, "training_acc": 53.0, "val_loss": 252.0455837249756, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2316.747848510742, "training_acc": 47.0, "val_loss": 740.8487319946289, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2510.021598815918, "training_acc": 47.0, "val_loss": 535.63232421875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2089.5463638305664, "training_acc": 53.0, "val_loss": 928.7986755371094, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3016.3746185302734, "training_acc": 53.0, "val_loss": 116.27464294433594, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1222.0021667480469, "training_acc": 49.0, "val_loss": 877.4681091308594, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3370.399932861328, "training_acc": 47.0, "val_loss": 205.8501958847046, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1223.0500793457031, "training_acc": 49.0, "val_loss": 881.9631576538086, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3380.585647583008, "training_acc": 53.0, "val_loss": 648.5240459442139, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1709.5629625320435, "training_acc": 53.0, "val_loss": 631.8411350250244, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3011.956497192383, "training_acc": 47.0, "val_loss": 823.8753318786621, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2616.2946128845215, "training_acc": 47.0, "val_loss": 344.32432651519775, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1652.5824356079102, "training_acc": 53.0, "val_loss": 701.2557983398438, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2289.2467308044434, "training_acc": 53.0, "val_loss": 87.23427653312683, "val_acc": 44.0}
{"epoch": 19, "training_loss": 575.2305946350098, "training_acc": 54.0, "val_loss": 156.90183639526367, "val_acc": 48.0}
{"epoch": 20, "training_loss": 836.8101196289062, "training_acc": 45.0, "val_loss": 325.88322162628174, "val_acc": 52.0}
{"epoch": 21, "training_loss": 736.2891492843628, "training_acc": 60.0, "val_loss": 302.69243717193604, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1295.3327560424805, "training_acc": 47.0, "val_loss": 56.527912616729736, "val_acc": 44.0}
{"epoch": 23, "training_loss": 673.9022598266602, "training_acc": 51.0, "val_loss": 483.51597785949707, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1328.8840026855469, "training_acc": 53.0, "val_loss": 173.10770750045776, "val_acc": 48.0}
{"epoch": 25, "training_loss": 881.4876976013184, "training_acc": 50.0, "val_loss": 60.82507371902466, "val_acc": 52.0}
{"epoch": 26, "training_loss": 370.4964122772217, "training_acc": 66.0, "val_loss": 324.0424156188965, "val_acc": 52.0}
{"epoch": 27, "training_loss": 608.4387969970703, "training_acc": 54.0, "val_loss": 299.3314027786255, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1315.484462738037, "training_acc": 47.0, "val_loss": 66.32112264633179, "val_acc": 52.0}
{"epoch": 29, "training_loss": 387.5189952850342, "training_acc": 65.0, "val_loss": 434.94200706481934, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1143.6722965240479, "training_acc": 51.0, "val_loss": 215.79065322875977, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1124.6756134033203, "training_acc": 47.0, "val_loss": 57.801467180252075, "val_acc": 52.0}
{"epoch": 32, "training_loss": 705.0135917663574, "training_acc": 56.0, "val_loss": 480.3982734680176, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1148.3807792663574, "training_acc": 52.0, "val_loss": 233.30833911895752, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1289.0203170776367, "training_acc": 47.0, "val_loss": 131.2516450881958, "val_acc": 48.0}
{"epoch": 35, "training_loss": 834.8895645141602, "training_acc": 48.0, "val_loss": 463.662052154541, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1203.4635772705078, "training_acc": 54.0, "val_loss": 63.7723445892334, "val_acc": 48.0}
{"epoch": 37, "training_loss": 739.907341003418, "training_acc": 52.0, "val_loss": 108.33970308303833, "val_acc": 56.0}
{"epoch": 38, "training_loss": 437.2485656738281, "training_acc": 57.0, "val_loss": 157.1188449859619, "val_acc": 56.0}
{"epoch": 39, "training_loss": 495.4772891998291, "training_acc": 57.0, "val_loss": 61.240190267562866, "val_acc": 44.0}
{"epoch": 40, "training_loss": 479.70805740356445, "training_acc": 57.0, "val_loss": 266.47534370422363, "val_acc": 52.0}
{"epoch": 41, "training_loss": 602.6141571998596, "training_acc": 62.0, "val_loss": 197.62719869613647, "val_acc": 48.0}
