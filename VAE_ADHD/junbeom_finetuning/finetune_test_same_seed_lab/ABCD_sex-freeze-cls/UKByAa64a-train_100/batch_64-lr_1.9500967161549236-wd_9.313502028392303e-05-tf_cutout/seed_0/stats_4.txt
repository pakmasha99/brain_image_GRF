"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4024.7152214050293, "training_acc": 49.0, "val_loss": 958.9419364929199, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4446.682662963867, "training_acc": 51.0, "val_loss": 1973.5237121582031, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7222.303802490234, "training_acc": 47.0, "val_loss": 280.562949180603, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1895.2932586669922, "training_acc": 57.0, "val_loss": 2003.8141250610352, "val_acc": 52.0}
{"epoch": 4, "training_loss": 8013.9273681640625, "training_acc": 53.0, "val_loss": 1933.852767944336, "val_acc": 52.0}
{"epoch": 5, "training_loss": 6528.888977050781, "training_acc": 53.0, "val_loss": 310.1062536239624, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1991.3338165283203, "training_acc": 55.0, "val_loss": 1722.2492218017578, "val_acc": 48.0}
{"epoch": 7, "training_loss": 7230.066192626953, "training_acc": 47.0, "val_loss": 1653.4513473510742, "val_acc": 48.0}
{"epoch": 8, "training_loss": 5668.078857421875, "training_acc": 47.0, "val_loss": 54.4644296169281, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1795.3371124267578, "training_acc": 47.0, "val_loss": 1599.2382049560547, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6453.245513916016, "training_acc": 53.0, "val_loss": 1662.4326705932617, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5928.510711669922, "training_acc": 53.0, "val_loss": 531.0610294342041, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1555.0711860656738, "training_acc": 57.0, "val_loss": 870.8860397338867, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3690.052764892578, "training_acc": 47.0, "val_loss": 689.3760681152344, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1777.7346820831299, "training_acc": 49.0, "val_loss": 700.437593460083, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3270.882827758789, "training_acc": 53.0, "val_loss": 1248.079776763916, "val_acc": 52.0}
{"epoch": 16, "training_loss": 4524.424392700195, "training_acc": 53.0, "val_loss": 593.3631420135498, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1495.0975923538208, "training_acc": 55.0, "val_loss": 511.6898536682129, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1975.9321670532227, "training_acc": 47.0, "val_loss": 219.9972152709961, "val_acc": 48.0}
{"epoch": 19, "training_loss": 857.6348457336426, "training_acc": 57.0, "val_loss": 601.0983943939209, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2285.1737213134766, "training_acc": 53.0, "val_loss": 222.85640239715576, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1022.7239570617676, "training_acc": 54.0, "val_loss": 628.4026145935059, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2229.207260131836, "training_acc": 47.0, "val_loss": 64.24591541290283, "val_acc": 48.0}
{"epoch": 23, "training_loss": 810.0576095581055, "training_acc": 55.0, "val_loss": 735.5868816375732, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2652.858573913574, "training_acc": 53.0, "val_loss": 302.72607803344727, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1177.461036682129, "training_acc": 49.0, "val_loss": 538.0805492401123, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1892.3495178222656, "training_acc": 47.0, "val_loss": 89.25144672393799, "val_acc": 56.0}
{"epoch": 27, "training_loss": 691.6399345397949, "training_acc": 55.0, "val_loss": 310.0545644760132, "val_acc": 52.0}
