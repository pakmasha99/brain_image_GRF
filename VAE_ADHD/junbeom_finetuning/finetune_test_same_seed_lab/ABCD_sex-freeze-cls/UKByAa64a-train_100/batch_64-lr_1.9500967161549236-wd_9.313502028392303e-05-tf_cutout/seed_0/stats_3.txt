"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2210.8412857055664, "training_acc": 49.0, "val_loss": 1014.4841194152832, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2995.446487426758, "training_acc": 53.0, "val_loss": 229.51490879058838, "val_acc": 36.0}
{"epoch": 2, "training_loss": 1709.4082260131836, "training_acc": 46.0, "val_loss": 242.35496520996094, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1535.0793228149414, "training_acc": 50.0, "val_loss": 1005.5340766906738, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2693.503116607666, "training_acc": 53.0, "val_loss": 149.8299241065979, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1329.6184768676758, "training_acc": 50.0, "val_loss": 123.75338077545166, "val_acc": 44.0}
{"epoch": 6, "training_loss": 1241.3606414794922, "training_acc": 48.0, "val_loss": 727.9160976409912, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1743.5867919921875, "training_acc": 54.0, "val_loss": 214.76874351501465, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1391.1479721069336, "training_acc": 47.0, "val_loss": 98.82871508598328, "val_acc": 44.0}
{"epoch": 9, "training_loss": 657.9109497070312, "training_acc": 60.0, "val_loss": 637.8797054290771, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1606.5128135681152, "training_acc": 53.0, "val_loss": 112.73189783096313, "val_acc": 52.0}
{"epoch": 11, "training_loss": 923.4125556945801, "training_acc": 46.0, "val_loss": 73.63331913948059, "val_acc": 44.0}
{"epoch": 12, "training_loss": 696.3442802429199, "training_acc": 52.0, "val_loss": 549.6633052825928, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1238.5350227355957, "training_acc": 53.0, "val_loss": 235.67776679992676, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1416.2968978881836, "training_acc": 47.0, "val_loss": 173.22090864181519, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1116.5460090637207, "training_acc": 43.0, "val_loss": 557.9556941986084, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1151.2823753356934, "training_acc": 54.0, "val_loss": 118.08773279190063, "val_acc": 40.0}
{"epoch": 17, "training_loss": 851.8871650695801, "training_acc": 53.0, "val_loss": 129.687237739563, "val_acc": 40.0}
{"epoch": 18, "training_loss": 697.9204139709473, "training_acc": 49.0, "val_loss": 513.2655620574951, "val_acc": 52.0}
{"epoch": 19, "training_loss": 851.9179706573486, "training_acc": 59.0, "val_loss": 122.80442714691162, "val_acc": 40.0}
{"epoch": 20, "training_loss": 607.6786727905273, "training_acc": 55.0, "val_loss": 162.49920129776, "val_acc": 44.0}
{"epoch": 21, "training_loss": 491.0757427215576, "training_acc": 61.0, "val_loss": 200.13790130615234, "val_acc": 52.0}
{"epoch": 22, "training_loss": 461.17541122436523, "training_acc": 54.0, "val_loss": 57.394278049468994, "val_acc": 52.0}
{"epoch": 23, "training_loss": 486.9539451599121, "training_acc": 54.0, "val_loss": 283.39812755584717, "val_acc": 52.0}
{"epoch": 24, "training_loss": 760.1682987213135, "training_acc": 54.0, "val_loss": 74.26036596298218, "val_acc": 52.0}
{"epoch": 25, "training_loss": 503.28347969055176, "training_acc": 48.0, "val_loss": 191.07985496520996, "val_acc": 52.0}
{"epoch": 26, "training_loss": 643.1205940246582, "training_acc": 45.0, "val_loss": 40.359994769096375, "val_acc": 60.0}
{"epoch": 27, "training_loss": 365.27257347106934, "training_acc": 61.0, "val_loss": 329.28967475891113, "val_acc": 52.0}
{"epoch": 28, "training_loss": 594.2687811851501, "training_acc": 57.0, "val_loss": 174.9050736427307, "val_acc": 48.0}
{"epoch": 29, "training_loss": 653.5715174674988, "training_acc": 50.0, "val_loss": 283.78746509552, "val_acc": 52.0}
{"epoch": 30, "training_loss": 463.32849311828613, "training_acc": 55.0, "val_loss": 94.48174834251404, "val_acc": 60.0}
{"epoch": 31, "training_loss": 510.1978130340576, "training_acc": 51.0, "val_loss": 324.9501943588257, "val_acc": 52.0}
{"epoch": 32, "training_loss": 770.4844951629639, "training_acc": 52.0, "val_loss": 77.18947529792786, "val_acc": 36.0}
{"epoch": 33, "training_loss": 394.27616119384766, "training_acc": 68.0, "val_loss": 99.20046925544739, "val_acc": 52.0}
{"epoch": 34, "training_loss": 317.30359077453613, "training_acc": 63.0, "val_loss": 264.58892822265625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 512.2658939361572, "training_acc": 53.0, "val_loss": 81.71021342277527, "val_acc": 52.0}
{"epoch": 36, "training_loss": 682.4062576293945, "training_acc": 41.0, "val_loss": 239.3421173095703, "val_acc": 52.0}
{"epoch": 37, "training_loss": 600.8076705932617, "training_acc": 50.0, "val_loss": 96.05538845062256, "val_acc": 56.0}
{"epoch": 38, "training_loss": 602.5432834625244, "training_acc": 49.0, "val_loss": 329.1971445083618, "val_acc": 52.0}
{"epoch": 39, "training_loss": 523.0896866321564, "training_acc": 66.0, "val_loss": 124.40751791000366, "val_acc": 48.0}
{"epoch": 40, "training_loss": 485.80553340911865, "training_acc": 62.0, "val_loss": 301.975154876709, "val_acc": 52.0}
{"epoch": 41, "training_loss": 571.0529403686523, "training_acc": 55.0, "val_loss": 81.38052225112915, "val_acc": 56.0}
{"epoch": 42, "training_loss": 461.5979862213135, "training_acc": 53.0, "val_loss": 333.65979194641113, "val_acc": 52.0}
{"epoch": 43, "training_loss": 738.1895771026611, "training_acc": 54.0, "val_loss": 62.54286170005798, "val_acc": 40.0}
{"epoch": 44, "training_loss": 414.9032516479492, "training_acc": 60.0, "val_loss": 83.32734704017639, "val_acc": 48.0}
{"epoch": 45, "training_loss": 488.4275093078613, "training_acc": 53.0, "val_loss": 213.65818977355957, "val_acc": 52.0}
