"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3517.9380264282227, "training_acc": 53.0, "val_loss": 969.8104858398438, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5261.782073974609, "training_acc": 43.0, "val_loss": 1752.2066116333008, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6148.110580444336, "training_acc": 47.0, "val_loss": 99.41831827163696, "val_acc": 52.0}
{"epoch": 3, "training_loss": 881.2713088989258, "training_acc": 52.0, "val_loss": 332.1834325790405, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1001.5935440063477, "training_acc": 57.0, "val_loss": 286.4203453063965, "val_acc": 48.0}
{"epoch": 5, "training_loss": 904.5842132568359, "training_acc": 51.0, "val_loss": 113.68305683135986, "val_acc": 52.0}
{"epoch": 6, "training_loss": 624.9216804504395, "training_acc": 49.0, "val_loss": 114.32493925094604, "val_acc": 48.0}
{"epoch": 7, "training_loss": 896.0357284545898, "training_acc": 47.0, "val_loss": 496.5475559234619, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1479.2961082458496, "training_acc": 53.0, "val_loss": 325.1218795776367, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1672.412467956543, "training_acc": 47.0, "val_loss": 170.62647342681885, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1063.7654495239258, "training_acc": 47.0, "val_loss": 630.3024768829346, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2172.018997192383, "training_acc": 53.0, "val_loss": 117.2991394996643, "val_acc": 56.0}
{"epoch": 12, "training_loss": 978.3149642944336, "training_acc": 53.0, "val_loss": 684.6280574798584, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2544.953514099121, "training_acc": 47.0, "val_loss": 43.869441747665405, "val_acc": 56.0}
{"epoch": 14, "training_loss": 599.7505035400391, "training_acc": 62.0, "val_loss": 540.2150630950928, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1710.4240684509277, "training_acc": 53.0, "val_loss": 94.2573606967926, "val_acc": 44.0}
{"epoch": 16, "training_loss": 723.1081199645996, "training_acc": 50.0, "val_loss": 45.13878524303436, "val_acc": 56.0}
{"epoch": 17, "training_loss": 253.43736839294434, "training_acc": 71.0, "val_loss": 249.1060972213745, "val_acc": 52.0}
{"epoch": 18, "training_loss": 627.1796445846558, "training_acc": 50.0, "val_loss": 173.90704154968262, "val_acc": 48.0}
{"epoch": 19, "training_loss": 580.2995004653931, "training_acc": 51.0, "val_loss": 196.4752197265625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 554.3511276245117, "training_acc": 50.0, "val_loss": 171.8091368675232, "val_acc": 48.0}
{"epoch": 21, "training_loss": 519.6577634811401, "training_acc": 54.0, "val_loss": 198.52843284606934, "val_acc": 52.0}
{"epoch": 22, "training_loss": 566.146894454956, "training_acc": 53.0, "val_loss": 177.10713148117065, "val_acc": 48.0}
{"epoch": 23, "training_loss": 559.4176921844482, "training_acc": 50.0, "val_loss": 231.23571872711182, "val_acc": 52.0}
{"epoch": 24, "training_loss": 748.2207679748535, "training_acc": 53.0, "val_loss": 57.492995262145996, "val_acc": 52.0}
{"epoch": 25, "training_loss": 306.0665864944458, "training_acc": 49.0, "val_loss": 208.53345394134521, "val_acc": 52.0}
{"epoch": 26, "training_loss": 671.9422626495361, "training_acc": 53.0, "val_loss": 156.3184142112732, "val_acc": 48.0}
{"epoch": 27, "training_loss": 558.1008930206299, "training_acc": 48.0, "val_loss": 205.85474967956543, "val_acc": 52.0}
{"epoch": 28, "training_loss": 674.88401222229, "training_acc": 53.0, "val_loss": 58.58616232872009, "val_acc": 44.0}
{"epoch": 29, "training_loss": 233.96282577514648, "training_acc": 55.0, "val_loss": 172.3422408103943, "val_acc": 52.0}
{"epoch": 30, "training_loss": 398.3314652442932, "training_acc": 55.0, "val_loss": 100.62400102615356, "val_acc": 44.0}
{"epoch": 31, "training_loss": 343.01465034484863, "training_acc": 50.0, "val_loss": 59.01079177856445, "val_acc": 64.0}
{"epoch": 32, "training_loss": 244.09241676330566, "training_acc": 57.0, "val_loss": 70.28023600578308, "val_acc": 60.0}
