"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 867.6799659729004, "training_acc": 49.0, "val_loss": 166.49205684661865, "val_acc": 52.0}
{"epoch": 1, "training_loss": 813.6946144104004, "training_acc": 49.0, "val_loss": 354.64117527008057, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1310.8712425231934, "training_acc": 47.0, "val_loss": 97.56556749343872, "val_acc": 48.0}
{"epoch": 3, "training_loss": 459.8071537017822, "training_acc": 49.0, "val_loss": 264.5637512207031, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1043.1233253479004, "training_acc": 53.0, "val_loss": 220.89238166809082, "val_acc": 52.0}
{"epoch": 5, "training_loss": 690.0026569366455, "training_acc": 53.0, "val_loss": 63.674306869506836, "val_acc": 48.0}
{"epoch": 6, "training_loss": 349.492769241333, "training_acc": 47.0, "val_loss": 139.74075317382812, "val_acc": 48.0}
{"epoch": 7, "training_loss": 447.3139696121216, "training_acc": 47.0, "val_loss": 63.978129625320435, "val_acc": 52.0}
{"epoch": 8, "training_loss": 353.2462692260742, "training_acc": 53.0, "val_loss": 103.63616943359375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 312.29627418518066, "training_acc": 53.0, "val_loss": 85.06859540939331, "val_acc": 48.0}
{"epoch": 10, "training_loss": 379.57394218444824, "training_acc": 47.0, "val_loss": 96.54431939125061, "val_acc": 48.0}
{"epoch": 11, "training_loss": 309.01252341270447, "training_acc": 44.0, "val_loss": 61.06903553009033, "val_acc": 52.0}
{"epoch": 12, "training_loss": 234.9836883544922, "training_acc": 53.0, "val_loss": 19.740256667137146, "val_acc": 52.0}
{"epoch": 13, "training_loss": 142.74372673034668, "training_acc": 50.0, "val_loss": 61.16994619369507, "val_acc": 48.0}
{"epoch": 14, "training_loss": 173.43165469169617, "training_acc": 49.0, "val_loss": 43.775033950805664, "val_acc": 52.0}
{"epoch": 15, "training_loss": 159.46755719184875, "training_acc": 53.0, "val_loss": 22.832091152668, "val_acc": 48.0}
{"epoch": 16, "training_loss": 95.66514015197754, "training_acc": 50.0, "val_loss": 18.12901645898819, "val_acc": 52.0}
{"epoch": 17, "training_loss": 93.62612009048462, "training_acc": 54.0, "val_loss": 17.89051443338394, "val_acc": 64.0}
{"epoch": 18, "training_loss": 71.5636818408966, "training_acc": 60.0, "val_loss": 20.45261859893799, "val_acc": 48.0}
{"epoch": 19, "training_loss": 93.83729124069214, "training_acc": 48.0, "val_loss": 20.877934992313385, "val_acc": 52.0}
{"epoch": 20, "training_loss": 79.69440007209778, "training_acc": 60.0, "val_loss": 27.10099220275879, "val_acc": 44.0}
{"epoch": 21, "training_loss": 137.09541177749634, "training_acc": 38.0, "val_loss": 19.398215413093567, "val_acc": 52.0}
{"epoch": 22, "training_loss": 80.53940296173096, "training_acc": 55.0, "val_loss": 20.408552885055542, "val_acc": 48.0}
{"epoch": 23, "training_loss": 64.89042210578918, "training_acc": 67.0, "val_loss": 27.776122093200684, "val_acc": 52.0}
{"epoch": 24, "training_loss": 87.54301357269287, "training_acc": 57.0, "val_loss": 32.3957234621048, "val_acc": 48.0}
{"epoch": 25, "training_loss": 98.61494946479797, "training_acc": 55.0, "val_loss": 37.89212703704834, "val_acc": 52.0}
{"epoch": 26, "training_loss": 133.67392110824585, "training_acc": 53.0, "val_loss": 34.048086404800415, "val_acc": 48.0}
{"epoch": 27, "training_loss": 130.87867736816406, "training_acc": 48.0, "val_loss": 22.269916534423828, "val_acc": 52.0}
{"epoch": 28, "training_loss": 96.72682809829712, "training_acc": 52.0, "val_loss": 18.03888976573944, "val_acc": 52.0}
{"epoch": 29, "training_loss": 92.749427318573, "training_acc": 57.0, "val_loss": 25.488674640655518, "val_acc": 48.0}
{"epoch": 30, "training_loss": 129.7993302345276, "training_acc": 43.0, "val_loss": 33.27994346618652, "val_acc": 52.0}
{"epoch": 31, "training_loss": 92.67022395133972, "training_acc": 56.0, "val_loss": 38.76097500324249, "val_acc": 48.0}
{"epoch": 32, "training_loss": 105.02919006347656, "training_acc": 59.0, "val_loss": 45.00647783279419, "val_acc": 52.0}
{"epoch": 33, "training_loss": 144.24522352218628, "training_acc": 53.0, "val_loss": 30.71994185447693, "val_acc": 48.0}
{"epoch": 34, "training_loss": 124.47648239135742, "training_acc": 47.0, "val_loss": 25.11593997478485, "val_acc": 52.0}
{"epoch": 35, "training_loss": 102.34755086898804, "training_acc": 53.0, "val_loss": 20.141856372356415, "val_acc": 48.0}
{"epoch": 36, "training_loss": 89.44957208633423, "training_acc": 56.0, "val_loss": 17.005333304405212, "val_acc": 52.0}
{"epoch": 37, "training_loss": 71.10049748420715, "training_acc": 63.0, "val_loss": 19.71469521522522, "val_acc": 52.0}
{"epoch": 38, "training_loss": 89.35830640792847, "training_acc": 52.0, "val_loss": 17.32179969549179, "val_acc": 56.0}
{"epoch": 39, "training_loss": 96.9303617477417, "training_acc": 60.0, "val_loss": 16.82918518781662, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.29612588882446, "training_acc": 64.0, "val_loss": 16.7980894446373, "val_acc": 52.0}
{"epoch": 41, "training_loss": 72.22830176353455, "training_acc": 61.0, "val_loss": 16.730301082134247, "val_acc": 60.0}
{"epoch": 42, "training_loss": 70.59249877929688, "training_acc": 63.0, "val_loss": 19.795630872249603, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.95315098762512, "training_acc": 60.0, "val_loss": 18.75772476196289, "val_acc": 64.0}
{"epoch": 44, "training_loss": 69.39954686164856, "training_acc": 58.0, "val_loss": 20.613425970077515, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.01195192337036, "training_acc": 60.0, "val_loss": 20.805931091308594, "val_acc": 52.0}
{"epoch": 46, "training_loss": 72.16545057296753, "training_acc": 56.0, "val_loss": 27.37603783607483, "val_acc": 52.0}
{"epoch": 47, "training_loss": 84.09670186042786, "training_acc": 56.0, "val_loss": 19.61614191532135, "val_acc": 56.0}
{"epoch": 48, "training_loss": 63.474971294403076, "training_acc": 62.0, "val_loss": 20.885352790355682, "val_acc": 52.0}
{"epoch": 49, "training_loss": 59.88543438911438, "training_acc": 63.0, "val_loss": 19.069989025592804, "val_acc": 60.0}
{"epoch": 50, "training_loss": 61.15871548652649, "training_acc": 67.0, "val_loss": 18.2464137673378, "val_acc": 52.0}
{"epoch": 51, "training_loss": 56.69897437095642, "training_acc": 69.0, "val_loss": 23.54639768600464, "val_acc": 48.0}
{"epoch": 52, "training_loss": 66.51088547706604, "training_acc": 64.0, "val_loss": 26.66725218296051, "val_acc": 52.0}
{"epoch": 53, "training_loss": 80.90262150764465, "training_acc": 62.0, "val_loss": 21.95252925157547, "val_acc": 44.0}
{"epoch": 54, "training_loss": 77.05604314804077, "training_acc": 49.0, "val_loss": 16.832180321216583, "val_acc": 52.0}
{"epoch": 55, "training_loss": 57.98871183395386, "training_acc": 66.0, "val_loss": 17.1338751912117, "val_acc": 52.0}
{"epoch": 56, "training_loss": 53.46228885650635, "training_acc": 76.0, "val_loss": 16.95147156715393, "val_acc": 56.0}
{"epoch": 57, "training_loss": 60.081676721572876, "training_acc": 74.0, "val_loss": 25.481173396110535, "val_acc": 52.0}
{"epoch": 58, "training_loss": 73.39607167243958, "training_acc": 61.0, "val_loss": 23.32186847925186, "val_acc": 48.0}
{"epoch": 59, "training_loss": 81.37912344932556, "training_acc": 47.0, "val_loss": 16.86079502105713, "val_acc": 52.0}
{"epoch": 60, "training_loss": 53.789178133010864, "training_acc": 77.0, "val_loss": 18.278595805168152, "val_acc": 68.0}
