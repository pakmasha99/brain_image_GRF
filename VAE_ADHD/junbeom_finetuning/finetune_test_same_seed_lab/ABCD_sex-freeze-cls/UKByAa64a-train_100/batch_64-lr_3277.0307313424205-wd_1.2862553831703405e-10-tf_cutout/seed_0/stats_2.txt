"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 9019526.844688416, "training_acc": 53.0, "val_loss": 1773720.8984375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9060384.59375, "training_acc": 41.0, "val_loss": 2934224.0234375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 10701864.65625, "training_acc": 47.0, "val_loss": 612037.98828125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4585082.28125, "training_acc": 41.0, "val_loss": 2572886.71875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 9862640.96875, "training_acc": 53.0, "val_loss": 2108832.6171875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 6537467.828125, "training_acc": 53.0, "val_loss": 467730.46875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3034819.59375, "training_acc": 47.0, "val_loss": 1114156.0546875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3611728.14453125, "training_acc": 47.0, "val_loss": 808643.65234375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3651026.296875, "training_acc": 53.0, "val_loss": 1208568.359375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3795064.875, "training_acc": 53.0, "val_loss": 395578.41796875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2012787.0, "training_acc": 47.0, "val_loss": 460055.810546875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1352633.501953125, "training_acc": 54.0, "val_loss": 494787.109375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1512414.072265625, "training_acc": 51.0, "val_loss": 501664.84375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1994238.6484375, "training_acc": 47.0, "val_loss": 69009.36279296875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 982582.2265625, "training_acc": 59.0, "val_loss": 436277.783203125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1139211.9091796875, "training_acc": 53.0, "val_loss": 211222.3388671875, "val_acc": 44.0}
{"epoch": 16, "training_loss": 799838.947265625, "training_acc": 49.0, "val_loss": 103739.02587890625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 612574.36328125, "training_acc": 48.0, "val_loss": 127082.2021484375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 328662.0830078125, "training_acc": 60.0, "val_loss": 180712.34130859375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 639451.1630859375, "training_acc": 55.0, "val_loss": 430356.201171875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1217978.4189453125, "training_acc": 53.0, "val_loss": 109115.49072265625, "val_acc": 44.0}
{"epoch": 21, "training_loss": 468281.017578125, "training_acc": 54.0, "val_loss": 182284.1796875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 382546.751953125, "training_acc": 58.0, "val_loss": 161165.97900390625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 509914.935546875, "training_acc": 50.0, "val_loss": 233243.2373046875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 554165.1064453125, "training_acc": 61.0, "val_loss": 384216.4794921875, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1375946.3046875, "training_acc": 47.0, "val_loss": 429677.83203125, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1601871.5625, "training_acc": 53.0, "val_loss": 218236.1572265625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1253266.0859375, "training_acc": 49.0, "val_loss": 700646.97265625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 2219489.61328125, "training_acc": 47.0, "val_loss": 721440.72265625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3182256.46875, "training_acc": 53.0, "val_loss": 998665.234375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2746741.2578125, "training_acc": 53.0, "val_loss": 695072.4609375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 3543611.046875, "training_acc": 47.0, "val_loss": 870230.56640625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2473201.8427734375, "training_acc": 51.0, "val_loss": 980462.890625, "val_acc": 52.0}
