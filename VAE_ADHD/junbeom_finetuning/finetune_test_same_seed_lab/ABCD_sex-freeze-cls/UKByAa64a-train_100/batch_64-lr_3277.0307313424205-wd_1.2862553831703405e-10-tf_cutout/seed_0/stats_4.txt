"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 6341855.929016113, "training_acc": 53.0, "val_loss": 969861.81640625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7199552.25, "training_acc": 51.0, "val_loss": 4173341.015625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 15621311.0625, "training_acc": 47.0, "val_loss": 1525380.95703125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5747209.3125, "training_acc": 45.0, "val_loss": 2119278.7109375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 8320517.6875, "training_acc": 53.0, "val_loss": 1706567.7734375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5531806.5078125, "training_acc": 53.0, "val_loss": 1215569.43359375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 5392476.46875, "training_acc": 48.0, "val_loss": 1832558.3984375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5861100.59375, "training_acc": 48.0, "val_loss": 193806.65283203125, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1508338.1328125, "training_acc": 62.0, "val_loss": 1209090.625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 4338474.328125, "training_acc": 53.0, "val_loss": 121622.9248046875, "val_acc": 56.0}
{"epoch": 10, "training_loss": 1836872.2890625, "training_acc": 48.0, "val_loss": 965796.19140625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2943463.8828125, "training_acc": 46.0, "val_loss": 504260.05859375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2484883.7265625, "training_acc": 52.0, "val_loss": 570925.0, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2104363.66796875, "training_acc": 45.0, "val_loss": 475445.41015625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1404892.29296875, "training_acc": 56.0, "val_loss": 335341.2353515625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1070441.046875, "training_acc": 54.0, "val_loss": 329889.84375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1114984.87109375, "training_acc": 49.0, "val_loss": 223984.1552734375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 850404.986328125, "training_acc": 58.0, "val_loss": 179407.67822265625, "val_acc": 44.0}
{"epoch": 18, "training_loss": 665884.814453125, "training_acc": 54.0, "val_loss": 247672.7783203125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 695247.466796875, "training_acc": 58.0, "val_loss": 254955.1513671875, "val_acc": 44.0}
{"epoch": 20, "training_loss": 683421.59375, "training_acc": 56.0, "val_loss": 210875.87890625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 557456.0947265625, "training_acc": 62.0, "val_loss": 197305.4443359375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 475388.6181640625, "training_acc": 59.0, "val_loss": 373413.0615234375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1052721.337890625, "training_acc": 54.0, "val_loss": 415341.796875, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1402483.08203125, "training_acc": 47.0, "val_loss": 257761.71875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 869386.2265625, "training_acc": 53.0, "val_loss": 115945.49560546875, "val_acc": 44.0}
{"epoch": 26, "training_loss": 415027.302734375, "training_acc": 64.0, "val_loss": 221706.0302734375, "val_acc": 52.0}
{"epoch": 27, "training_loss": 555728.591796875, "training_acc": 61.0, "val_loss": 357738.8916015625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1083605.5546875, "training_acc": 47.0, "val_loss": 462499.12109375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2062575.7890625, "training_acc": 53.0, "val_loss": 112981.25, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1306464.5546875, "training_acc": 56.0, "val_loss": 857157.12890625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 2608315.546875, "training_acc": 47.0, "val_loss": 656265.625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3246764.59375, "training_acc": 53.0, "val_loss": 930008.3984375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2451202.009765625, "training_acc": 54.0, "val_loss": 956055.078125, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4579935.546875, "training_acc": 47.0, "val_loss": 1246749.70703125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 3876879.30859375, "training_acc": 47.0, "val_loss": 798835.7421875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3372406.453125, "training_acc": 53.0, "val_loss": 1405693.45703125, "val_acc": 52.0}
{"epoch": 37, "training_loss": 4716544.4921875, "training_acc": 53.0, "val_loss": 143747.79052734375, "val_acc": 56.0}
{"epoch": 38, "training_loss": 1594850.0625, "training_acc": 61.0, "val_loss": 1482981.25, "val_acc": 48.0}
{"epoch": 39, "training_loss": 5591902.75, "training_acc": 47.0, "val_loss": 562036.03515625, "val_acc": 48.0}
{"epoch": 40, "training_loss": 2227142.484375, "training_acc": 45.0, "val_loss": 1170037.5, "val_acc": 52.0}
{"epoch": 41, "training_loss": 4441221.53125, "training_acc": 53.0, "val_loss": 626093.798828125, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1315961.123046875, "training_acc": 65.0, "val_loss": 841625.0, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2854269.453125, "training_acc": 47.0, "val_loss": 93436.55395507812, "val_acc": 52.0}
{"epoch": 44, "training_loss": 674051.76171875, "training_acc": 62.0, "val_loss": 567345.99609375, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1668997.3515625, "training_acc": 56.0, "val_loss": 622677.978515625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 2513783.828125, "training_acc": 47.0, "val_loss": 364121.8017578125, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1818309.0, "training_acc": 43.0, "val_loss": 938415.33203125, "val_acc": 52.0}
{"epoch": 48, "training_loss": 2964010.265625, "training_acc": 53.0, "val_loss": 112138.671875, "val_acc": 64.0}
{"epoch": 49, "training_loss": 1008511.1953125, "training_acc": 58.0, "val_loss": 623943.06640625, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1460579.8798828125, "training_acc": 54.0, "val_loss": 461062.6953125, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1754741.671875, "training_acc": 53.0, "val_loss": 121279.74853515625, "val_acc": 44.0}
{"epoch": 52, "training_loss": 868991.109375, "training_acc": 60.0, "val_loss": 381999.70703125, "val_acc": 48.0}
{"epoch": 53, "training_loss": 962370.791015625, "training_acc": 58.0, "val_loss": 499878.173828125, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1464596.24609375, "training_acc": 55.0, "val_loss": 415699.951171875, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1430796.67578125, "training_acc": 48.0, "val_loss": 128993.4326171875, "val_acc": 68.0}
{"epoch": 56, "training_loss": 1278166.3203125, "training_acc": 45.0, "val_loss": 329417.3583984375, "val_acc": 52.0}
{"epoch": 57, "training_loss": 940635.1015625, "training_acc": 59.0, "val_loss": 233352.392578125, "val_acc": 40.0}
{"epoch": 58, "training_loss": 649575.9375, "training_acc": 61.0, "val_loss": 390836.2060546875, "val_acc": 52.0}
{"epoch": 59, "training_loss": 809758.517578125, "training_acc": 60.0, "val_loss": 381583.9599609375, "val_acc": 48.0}
{"epoch": 60, "training_loss": 1005620.98828125, "training_acc": 47.0, "val_loss": 262584.6923828125, "val_acc": 52.0}
{"epoch": 61, "training_loss": 666950.861328125, "training_acc": 57.0, "val_loss": 158976.6845703125, "val_acc": 44.0}
{"epoch": 62, "training_loss": 261685.7646484375, "training_acc": 67.0, "val_loss": 265456.0546875, "val_acc": 52.0}
