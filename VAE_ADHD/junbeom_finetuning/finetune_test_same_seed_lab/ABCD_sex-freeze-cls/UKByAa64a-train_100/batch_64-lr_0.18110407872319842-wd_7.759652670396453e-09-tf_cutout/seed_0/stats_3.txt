"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 437.49292755126953, "training_acc": 44.0, "val_loss": 91.65357947349548, "val_acc": 52.0}
{"epoch": 1, "training_loss": 318.28655433654785, "training_acc": 61.0, "val_loss": 202.23426818847656, "val_acc": 48.0}
{"epoch": 2, "training_loss": 780.0235595703125, "training_acc": 47.0, "val_loss": 57.76974558830261, "val_acc": 48.0}
{"epoch": 3, "training_loss": 270.84639072418213, "training_acc": 49.0, "val_loss": 153.56488227844238, "val_acc": 52.0}
{"epoch": 4, "training_loss": 550.3342704772949, "training_acc": 53.0, "val_loss": 130.08126020431519, "val_acc": 52.0}
{"epoch": 5, "training_loss": 334.49008417129517, "training_acc": 53.0, "val_loss": 45.618048310279846, "val_acc": 48.0}
{"epoch": 6, "training_loss": 309.00986099243164, "training_acc": 47.0, "val_loss": 86.1883819103241, "val_acc": 48.0}
{"epoch": 7, "training_loss": 320.226957321167, "training_acc": 47.0, "val_loss": 42.92127192020416, "val_acc": 52.0}
{"epoch": 8, "training_loss": 184.16222381591797, "training_acc": 49.0, "val_loss": 99.21951293945312, "val_acc": 52.0}
{"epoch": 9, "training_loss": 265.8798875808716, "training_acc": 53.0, "val_loss": 32.097327709198, "val_acc": 52.0}
{"epoch": 10, "training_loss": 112.83076620101929, "training_acc": 59.0, "val_loss": 61.130112409591675, "val_acc": 48.0}
{"epoch": 11, "training_loss": 263.3029508590698, "training_acc": 47.0, "val_loss": 20.353291928768158, "val_acc": 40.0}
{"epoch": 12, "training_loss": 116.05751657485962, "training_acc": 57.0, "val_loss": 71.835857629776, "val_acc": 52.0}
{"epoch": 13, "training_loss": 207.8748264312744, "training_acc": 53.0, "val_loss": 23.17279428243637, "val_acc": 52.0}
{"epoch": 14, "training_loss": 114.31130886077881, "training_acc": 48.0, "val_loss": 42.72518455982208, "val_acc": 48.0}
{"epoch": 15, "training_loss": 156.33055591583252, "training_acc": 47.0, "val_loss": 31.270039081573486, "val_acc": 52.0}
{"epoch": 16, "training_loss": 118.72593545913696, "training_acc": 53.0, "val_loss": 39.483070373535156, "val_acc": 52.0}
{"epoch": 17, "training_loss": 101.95553302764893, "training_acc": 56.0, "val_loss": 27.59292423725128, "val_acc": 48.0}
{"epoch": 18, "training_loss": 115.7715094089508, "training_acc": 48.0, "val_loss": 17.808818817138672, "val_acc": 60.0}
{"epoch": 19, "training_loss": 76.03721737861633, "training_acc": 55.0, "val_loss": 31.987351179122925, "val_acc": 52.0}
{"epoch": 20, "training_loss": 103.21010994911194, "training_acc": 52.0, "val_loss": 19.256968796253204, "val_acc": 44.0}
{"epoch": 21, "training_loss": 74.76570177078247, "training_acc": 54.0, "val_loss": 18.472640216350555, "val_acc": 40.0}
{"epoch": 22, "training_loss": 67.11521220207214, "training_acc": 61.0, "val_loss": 24.90766793489456, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.28173327445984, "training_acc": 61.0, "val_loss": 19.331899285316467, "val_acc": 44.0}
{"epoch": 24, "training_loss": 74.43896508216858, "training_acc": 61.0, "val_loss": 24.57791119813919, "val_acc": 52.0}
{"epoch": 25, "training_loss": 78.12804460525513, "training_acc": 56.0, "val_loss": 21.964889764785767, "val_acc": 52.0}
{"epoch": 26, "training_loss": 73.92329216003418, "training_acc": 54.0, "val_loss": 19.915664196014404, "val_acc": 40.0}
{"epoch": 27, "training_loss": 82.10383534431458, "training_acc": 55.0, "val_loss": 23.91858994960785, "val_acc": 52.0}
{"epoch": 28, "training_loss": 74.77090167999268, "training_acc": 60.0, "val_loss": 19.89307999610901, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.65658831596375, "training_acc": 59.0, "val_loss": 18.654681742191315, "val_acc": 40.0}
{"epoch": 30, "training_loss": 68.73811292648315, "training_acc": 60.0, "val_loss": 24.615010619163513, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.54117155075073, "training_acc": 53.0, "val_loss": 20.05675882101059, "val_acc": 56.0}
{"epoch": 32, "training_loss": 72.361985206604, "training_acc": 50.0, "val_loss": 23.487725853919983, "val_acc": 52.0}
{"epoch": 33, "training_loss": 73.06087875366211, "training_acc": 55.0, "val_loss": 19.100335240364075, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.28292441368103, "training_acc": 62.0, "val_loss": 18.551339209079742, "val_acc": 48.0}
{"epoch": 35, "training_loss": 60.82592034339905, "training_acc": 65.0, "val_loss": 25.50196349620819, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.85145497322083, "training_acc": 56.0, "val_loss": 19.082289934158325, "val_acc": 32.0}
{"epoch": 37, "training_loss": 74.45308685302734, "training_acc": 47.0, "val_loss": 18.372832238674164, "val_acc": 52.0}
