"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2061546.5395126343, "training_acc": 53.0, "val_loss": 374694.3603515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1773172.46875, "training_acc": 54.0, "val_loss": 1037680.76171875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3977846.578125, "training_acc": 47.0, "val_loss": 333087.79296875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1204738.5078125, "training_acc": 55.0, "val_loss": 684507.12890625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2618166.6484375, "training_acc": 53.0, "val_loss": 600515.380859375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1791538.95703125, "training_acc": 53.0, "val_loss": 221412.20703125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1340490.7109375, "training_acc": 47.0, "val_loss": 432693.359375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1618806.80859375, "training_acc": 47.0, "val_loss": 145105.5908203125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 768004.12109375, "training_acc": 55.0, "val_loss": 374773.2666015625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1198524.52734375, "training_acc": 53.0, "val_loss": 39306.976318359375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 597836.1484375, "training_acc": 47.0, "val_loss": 241554.0771484375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 761607.2373046875, "training_acc": 51.0, "val_loss": 212300.9765625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 951386.20703125, "training_acc": 53.0, "val_loss": 238407.2998046875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 670537.2641601562, "training_acc": 57.0, "val_loss": 249295.3125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1032704.1484375, "training_acc": 47.0, "val_loss": 239348.779296875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 528028.6687011719, "training_acc": 61.0, "val_loss": 191355.810546875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 858201.05078125, "training_acc": 53.0, "val_loss": 111981.640625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 466907.93359375, "training_acc": 55.0, "val_loss": 238295.849609375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 734298.658203125, "training_acc": 49.0, "val_loss": 47381.39343261719, "val_acc": 52.0}
{"epoch": 19, "training_loss": 384032.017578125, "training_acc": 53.0, "val_loss": 31744.25048828125, "val_acc": 44.0}
{"epoch": 20, "training_loss": 289110.626953125, "training_acc": 50.0, "val_loss": 67749.30419921875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 226276.6962890625, "training_acc": 54.0, "val_loss": 118950.57373046875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 283050.57177734375, "training_acc": 60.0, "val_loss": 192531.33544921875, "val_acc": 48.0}
{"epoch": 23, "training_loss": 712042.126953125, "training_acc": 47.0, "val_loss": 73604.26635742188, "val_acc": 44.0}
{"epoch": 24, "training_loss": 363756.64453125, "training_acc": 56.0, "val_loss": 270285.3759765625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 974645.875, "training_acc": 53.0, "val_loss": 39982.63854980469, "val_acc": 52.0}
{"epoch": 26, "training_loss": 596046.9140625, "training_acc": 41.0, "val_loss": 353593.06640625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1182518.5234375, "training_acc": 47.0, "val_loss": 24528.768920898438, "val_acc": 64.0}
{"epoch": 28, "training_loss": 463639.4609375, "training_acc": 58.0, "val_loss": 310300.927734375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1107376.79296875, "training_acc": 53.0, "val_loss": 35799.08752441406, "val_acc": 48.0}
{"epoch": 30, "training_loss": 387196.2109375, "training_acc": 55.0, "val_loss": 344653.955078125, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1184761.72265625, "training_acc": 47.0, "val_loss": 42263.616943359375, "val_acc": 40.0}
{"epoch": 32, "training_loss": 567082.5078125, "training_acc": 47.0, "val_loss": 328766.9189453125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1208719.49609375, "training_acc": 53.0, "val_loss": 70295.73364257812, "val_acc": 52.0}
{"epoch": 34, "training_loss": 713123.0703125, "training_acc": 41.0, "val_loss": 399149.0478515625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1338373.05078125, "training_acc": 47.0, "val_loss": 129333.6181640625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 413153.416015625, "training_acc": 58.0, "val_loss": 299152.294921875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1233662.8671875, "training_acc": 53.0, "val_loss": 161769.64111328125, "val_acc": 52.0}
{"epoch": 38, "training_loss": 581277.0634765625, "training_acc": 50.0, "val_loss": 225123.9990234375, "val_acc": 48.0}
{"epoch": 39, "training_loss": 661845.314453125, "training_acc": 49.0, "val_loss": 28736.09619140625, "val_acc": 60.0}
{"epoch": 40, "training_loss": 209996.869140625, "training_acc": 60.0, "val_loss": 38476.13830566406, "val_acc": 52.0}
{"epoch": 41, "training_loss": 177066.00048828125, "training_acc": 57.0, "val_loss": 103197.15576171875, "val_acc": 48.0}
{"epoch": 42, "training_loss": 222698.978515625, "training_acc": 54.0, "val_loss": 32242.019653320312, "val_acc": 56.0}
{"epoch": 43, "training_loss": 188844.43701171875, "training_acc": 56.0, "val_loss": 60082.71484375, "val_acc": 44.0}
{"epoch": 44, "training_loss": 217410.314453125, "training_acc": 58.0, "val_loss": 42405.914306640625, "val_acc": 56.0}
{"epoch": 45, "training_loss": 116483.36401367188, "training_acc": 68.0, "val_loss": 53613.8916015625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 158536.51318359375, "training_acc": 57.0, "val_loss": 23699.281311035156, "val_acc": 60.0}
{"epoch": 47, "training_loss": 108951.89892578125, "training_acc": 66.0, "val_loss": 29417.819213867188, "val_acc": 64.0}
{"epoch": 48, "training_loss": 127488.88330078125, "training_acc": 60.0, "val_loss": 35155.03845214844, "val_acc": 56.0}
{"epoch": 49, "training_loss": 126763.8330078125, "training_acc": 62.0, "val_loss": 21286.82403564453, "val_acc": 64.0}
{"epoch": 50, "training_loss": 89338.96044921875, "training_acc": 65.0, "val_loss": 28046.627807617188, "val_acc": 48.0}
{"epoch": 51, "training_loss": 109216.3037109375, "training_acc": 69.0, "val_loss": 33990.95153808594, "val_acc": 52.0}
{"epoch": 52, "training_loss": 164681.5810546875, "training_acc": 60.0, "val_loss": 51801.654052734375, "val_acc": 44.0}
{"epoch": 53, "training_loss": 184663.92919921875, "training_acc": 59.0, "val_loss": 103419.42138671875, "val_acc": 52.0}
{"epoch": 54, "training_loss": 243610.306640625, "training_acc": 57.0, "val_loss": 83842.38891601562, "val_acc": 48.0}
{"epoch": 55, "training_loss": 199516.19482421875, "training_acc": 54.0, "val_loss": 45507.32727050781, "val_acc": 52.0}
{"epoch": 56, "training_loss": 97249.5361328125, "training_acc": 63.0, "val_loss": 7588.043975830078, "val_acc": 64.0}
{"epoch": 57, "training_loss": 69563.19970703125, "training_acc": 71.0, "val_loss": 9730.211639404297, "val_acc": 60.0}
{"epoch": 58, "training_loss": 54905.940673828125, "training_acc": 66.0, "val_loss": 84312.82348632812, "val_acc": 52.0}
{"epoch": 59, "training_loss": 218166.0166015625, "training_acc": 55.0, "val_loss": 118918.64013671875, "val_acc": 48.0}
{"epoch": 60, "training_loss": 461837.939453125, "training_acc": 47.0, "val_loss": 78353.38134765625, "val_acc": 52.0}
{"epoch": 61, "training_loss": 239743.16015625, "training_acc": 54.0, "val_loss": 12149.125671386719, "val_acc": 48.0}
{"epoch": 62, "training_loss": 52384.871337890625, "training_acc": 69.0, "val_loss": 24866.85333251953, "val_acc": 52.0}
{"epoch": 63, "training_loss": 55618.21728515625, "training_acc": 65.0, "val_loss": 28053.152465820312, "val_acc": 52.0}
{"epoch": 64, "training_loss": 53467.95886230469, "training_acc": 69.0, "val_loss": 15275.166320800781, "val_acc": 60.0}
{"epoch": 65, "training_loss": 53268.4013671875, "training_acc": 65.0, "val_loss": 61071.282958984375, "val_acc": 52.0}
{"epoch": 66, "training_loss": 132759.7355041504, "training_acc": 67.0, "val_loss": 81963.05541992188, "val_acc": 48.0}
{"epoch": 67, "training_loss": 175347.55627441406, "training_acc": 60.0, "val_loss": 99012.36572265625, "val_acc": 52.0}
{"epoch": 68, "training_loss": 252982.72888183594, "training_acc": 59.0, "val_loss": 84013.15307617188, "val_acc": 48.0}
{"epoch": 69, "training_loss": 185133.75134277344, "training_acc": 59.0, "val_loss": 108238.36669921875, "val_acc": 52.0}
{"epoch": 70, "training_loss": 336764.171875, "training_acc": 53.0, "val_loss": 110459.9365234375, "val_acc": 48.0}
{"epoch": 71, "training_loss": 381713.248046875, "training_acc": 48.0, "val_loss": 24919.03533935547, "val_acc": 60.0}
{"epoch": 72, "training_loss": 108302.66943359375, "training_acc": 64.0, "val_loss": 75730.56640625, "val_acc": 48.0}
{"epoch": 73, "training_loss": 172526.08056640625, "training_acc": 52.0, "val_loss": 136888.0615234375, "val_acc": 52.0}
{"epoch": 74, "training_loss": 493690.37890625, "training_acc": 53.0, "val_loss": 12074.554443359375, "val_acc": 60.0}
{"epoch": 75, "training_loss": 311583.830078125, "training_acc": 61.0, "val_loss": 177060.5712890625, "val_acc": 48.0}
