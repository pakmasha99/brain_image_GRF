"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 272790.74265289307, "training_acc": 53.0, "val_loss": 767710.83984375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3099309.84375, "training_acc": 47.0, "val_loss": 60209.3017578125, "val_acc": 44.0}
{"epoch": 2, "training_loss": 522388.3828125, "training_acc": 68.0, "val_loss": 748459.814453125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2329155.2421875, "training_acc": 53.0, "val_loss": 202684.06982421875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 999643.625, "training_acc": 48.0, "val_loss": 581567.236328125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2358976.2265625, "training_acc": 47.0, "val_loss": 167631.75048828125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 815724.21484375, "training_acc": 51.0, "val_loss": 548273.681640625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1901860.1640625, "training_acc": 53.0, "val_loss": 424530.126953125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1038072.6318359375, "training_acc": 54.0, "val_loss": 276401.7333984375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1415895.21875, "training_acc": 47.0, "val_loss": 394476.8310546875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1390814.78125, "training_acc": 47.0, "val_loss": 179603.564453125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 650882.578125, "training_acc": 55.0, "val_loss": 368595.4833984375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1025969.5703125, "training_acc": 53.0, "val_loss": 48680.029296875, "val_acc": 44.0}
{"epoch": 13, "training_loss": 340574.357421875, "training_acc": 58.0, "val_loss": 112290.19775390625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 520848.36328125, "training_acc": 58.0, "val_loss": 202281.70166015625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 478279.111328125, "training_acc": 54.0, "val_loss": 59842.120361328125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 249326.8759765625, "training_acc": 57.0, "val_loss": 57682.3486328125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 279812.49072265625, "training_acc": 52.0, "val_loss": 159038.29345703125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 261488.0361328125, "training_acc": 55.0, "val_loss": 93611.30981445312, "val_acc": 52.0}
{"epoch": 19, "training_loss": 454615.150390625, "training_acc": 48.0, "val_loss": 88327.60009765625, "val_acc": 48.0}
{"epoch": 20, "training_loss": 320299.962890625, "training_acc": 53.0, "val_loss": 96509.46655273438, "val_acc": 52.0}
{"epoch": 21, "training_loss": 352651.2421875, "training_acc": 54.0, "val_loss": 102344.482421875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 364131.24072265625, "training_acc": 56.0, "val_loss": 130807.18994140625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 331171.447265625, "training_acc": 53.0, "val_loss": 91909.04541015625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 377117.2841796875, "training_acc": 51.0, "val_loss": 90452.1728515625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 238915.9189453125, "training_acc": 59.0, "val_loss": 33624.066162109375, "val_acc": 44.0}
{"epoch": 26, "training_loss": 158621.552734375, "training_acc": 60.0, "val_loss": 31662.139892578125, "val_acc": 40.0}
{"epoch": 27, "training_loss": 174598.4560546875, "training_acc": 63.0, "val_loss": 69042.73071289062, "val_acc": 52.0}
{"epoch": 28, "training_loss": 227804.1552734375, "training_acc": 58.0, "val_loss": 33261.138916015625, "val_acc": 60.0}
{"epoch": 29, "training_loss": 172030.49755859375, "training_acc": 67.0, "val_loss": 135807.861328125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 295459.5400390625, "training_acc": 48.0, "val_loss": 32947.015380859375, "val_acc": 36.0}
{"epoch": 31, "training_loss": 102702.01806640625, "training_acc": 61.0, "val_loss": 21266.6748046875, "val_acc": 60.0}
{"epoch": 32, "training_loss": 68520.19580078125, "training_acc": 64.0, "val_loss": 39220.47119140625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 61336.157470703125, "training_acc": 68.0, "val_loss": 68799.90234375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 129433.96923828125, "training_acc": 66.0, "val_loss": 27339.1357421875, "val_acc": 52.0}
{"epoch": 35, "training_loss": 133729.97119140625, "training_acc": 56.0, "val_loss": 40879.55627441406, "val_acc": 52.0}
{"epoch": 36, "training_loss": 191148.189453125, "training_acc": 61.0, "val_loss": 21623.74725341797, "val_acc": 56.0}
{"epoch": 37, "training_loss": 246797.146484375, "training_acc": 55.0, "val_loss": 205174.5849609375, "val_acc": 52.0}
{"epoch": 38, "training_loss": 542703.533203125, "training_acc": 53.0, "val_loss": 168848.4375, "val_acc": 48.0}
{"epoch": 39, "training_loss": 747785.728515625, "training_acc": 47.0, "val_loss": 123165.0390625, "val_acc": 48.0}
{"epoch": 40, "training_loss": 421024.2890625, "training_acc": 51.0, "val_loss": 186176.806640625, "val_acc": 52.0}
{"epoch": 41, "training_loss": 583892.23828125, "training_acc": 53.0, "val_loss": 108501.72119140625, "val_acc": 48.0}
{"epoch": 42, "training_loss": 464014.904296875, "training_acc": 48.0, "val_loss": 21270.941162109375, "val_acc": 60.0}
{"epoch": 43, "training_loss": 263415.939453125, "training_acc": 56.0, "val_loss": 171498.35205078125, "val_acc": 52.0}
{"epoch": 44, "training_loss": 449187.69140625, "training_acc": 57.0, "val_loss": 169132.2509765625, "val_acc": 48.0}
{"epoch": 45, "training_loss": 747924.21875, "training_acc": 47.0, "val_loss": 18751.214599609375, "val_acc": 52.0}
{"epoch": 46, "training_loss": 356518.896484375, "training_acc": 57.0, "val_loss": 344196.77734375, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1041151.875, "training_acc": 53.0, "val_loss": 69671.34399414062, "val_acc": 52.0}
{"epoch": 48, "training_loss": 352021.43359375, "training_acc": 65.0, "val_loss": 322183.642578125, "val_acc": 48.0}
{"epoch": 49, "training_loss": 1235552.9296875, "training_acc": 47.0, "val_loss": 28705.844116210938, "val_acc": 48.0}
{"epoch": 50, "training_loss": 337566.16796875, "training_acc": 70.0, "val_loss": 347794.23828125, "val_acc": 52.0}
{"epoch": 51, "training_loss": 974091.748046875, "training_acc": 53.0, "val_loss": 32590.545654296875, "val_acc": 44.0}
{"epoch": 52, "training_loss": 397936.91796875, "training_acc": 53.0, "val_loss": 142110.55908203125, "val_acc": 48.0}
{"epoch": 53, "training_loss": 476381.9133300781, "training_acc": 50.0, "val_loss": 135412.58544921875, "val_acc": 52.0}
{"epoch": 54, "training_loss": 237676.20568847656, "training_acc": 56.0, "val_loss": 82495.703125, "val_acc": 48.0}
{"epoch": 55, "training_loss": 302460.89111328125, "training_acc": 49.0, "val_loss": 159120.361328125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 538139.90234375, "training_acc": 53.0, "val_loss": 62766.54052734375, "val_acc": 52.0}
{"epoch": 57, "training_loss": 356245.623046875, "training_acc": 55.0, "val_loss": 204398.33984375, "val_acc": 48.0}
{"epoch": 58, "training_loss": 595975.7939453125, "training_acc": 47.0, "val_loss": 221253.515625, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1013965.7890625, "training_acc": 53.0, "val_loss": 312225.9033203125, "val_acc": 52.0}
{"epoch": 60, "training_loss": 745198.251953125, "training_acc": 53.0, "val_loss": 220433.7890625, "val_acc": 48.0}
{"epoch": 61, "training_loss": 1170604.2421875, "training_acc": 47.0, "val_loss": 324679.3701171875, "val_acc": 48.0}
{"epoch": 62, "training_loss": 1027783.666015625, "training_acc": 47.0, "val_loss": 238928.9306640625, "val_acc": 52.0}
{"epoch": 63, "training_loss": 864612.21875, "training_acc": 53.0, "val_loss": 409507.6171875, "val_acc": 52.0}
{"epoch": 64, "training_loss": 1214208.85546875, "training_acc": 53.0, "val_loss": 29794.512939453125, "val_acc": 44.0}
