"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1913256.8387947083, "training_acc": 46.0, "val_loss": 399909.9853515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1941907.8203125, "training_acc": 53.0, "val_loss": 1035668.5546875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3897748.625, "training_acc": 47.0, "val_loss": 287085.302734375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1358183.31640625, "training_acc": 51.0, "val_loss": 756362.646484375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2873635.609375, "training_acc": 53.0, "val_loss": 674925.0, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2003124.8046875, "training_acc": 53.0, "val_loss": 117267.48046875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1080840.28125, "training_acc": 47.0, "val_loss": 345691.6259765625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1171756.203125, "training_acc": 47.0, "val_loss": 250487.6953125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 976715.80859375, "training_acc": 53.0, "val_loss": 434333.740234375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1410344.81640625, "training_acc": 53.0, "val_loss": 54732.09228515625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 564071.53125, "training_acc": 49.0, "val_loss": 403840.4052734375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1547315.24609375, "training_acc": 47.0, "val_loss": 85664.99633789062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 560624.9609375, "training_acc": 49.0, "val_loss": 424951.3671875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1633813.78125, "training_acc": 53.0, "val_loss": 318570.6298828125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 855208.5341796875, "training_acc": 52.0, "val_loss": 312404.7119140625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1522029.921875, "training_acc": 47.0, "val_loss": 464649.169921875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1567655.4921875, "training_acc": 47.0, "val_loss": 42319.81201171875, "val_acc": 60.0}
{"epoch": 17, "training_loss": 389285.046875, "training_acc": 54.0, "val_loss": 264240.4541015625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 848270.12109375, "training_acc": 53.0, "val_loss": 59855.810546875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 263518.82421875, "training_acc": 50.0, "val_loss": 28619.869995117188, "val_acc": 56.0}
{"epoch": 20, "training_loss": 192458.81640625, "training_acc": 60.0, "val_loss": 44340.655517578125, "val_acc": 60.0}
{"epoch": 21, "training_loss": 165571.6015625, "training_acc": 55.0, "val_loss": 47615.728759765625, "val_acc": 44.0}
{"epoch": 22, "training_loss": 230258.9462890625, "training_acc": 55.0, "val_loss": 125697.65625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 235431.0819091797, "training_acc": 62.0, "val_loss": 123489.73388671875, "val_acc": 48.0}
{"epoch": 24, "training_loss": 456886.359375, "training_acc": 48.0, "val_loss": 100818.56079101562, "val_acc": 52.0}
{"epoch": 25, "training_loss": 326249.3515625, "training_acc": 55.0, "val_loss": 45001.171875, "val_acc": 60.0}
{"epoch": 26, "training_loss": 334133.6953125, "training_acc": 52.0, "val_loss": 110708.87451171875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 391222.86669921875, "training_acc": 49.0, "val_loss": 104180.74951171875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 208869.55810546875, "training_acc": 58.0, "val_loss": 67538.43383789062, "val_acc": 48.0}
{"epoch": 29, "training_loss": 214580.30126953125, "training_acc": 58.0, "val_loss": 169756.3232421875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 581600.751953125, "training_acc": 53.0, "val_loss": 78905.69458007812, "val_acc": 56.0}
{"epoch": 31, "training_loss": 378228.169921875, "training_acc": 52.0, "val_loss": 171675.40283203125, "val_acc": 48.0}
{"epoch": 32, "training_loss": 515293.11474609375, "training_acc": 51.0, "val_loss": 193241.2109375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 771304.01953125, "training_acc": 53.0, "val_loss": 176422.93701171875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 326687.55078125, "training_acc": 66.0, "val_loss": 146993.02978515625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 539894.779296875, "training_acc": 47.0, "val_loss": 92885.546875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 321304.8515625, "training_acc": 55.0, "val_loss": 52038.275146484375, "val_acc": 60.0}
{"epoch": 37, "training_loss": 234177.849609375, "training_acc": 49.0, "val_loss": 86844.73266601562, "val_acc": 48.0}
{"epoch": 38, "training_loss": 316248.6689453125, "training_acc": 48.0, "val_loss": 100612.13989257812, "val_acc": 52.0}
