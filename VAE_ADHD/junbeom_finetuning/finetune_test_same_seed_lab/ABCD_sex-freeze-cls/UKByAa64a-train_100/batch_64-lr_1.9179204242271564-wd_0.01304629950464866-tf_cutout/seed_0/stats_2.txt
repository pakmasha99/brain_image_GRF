"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 14758.021102905273, "training_acc": 53.0, "val_loss": 2541.413116455078, "val_acc": 52.0}
{"epoch": 1, "training_loss": 16203.918579101562, "training_acc": 49.0, "val_loss": 7978.6102294921875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 29912.78741455078, "training_acc": 47.0, "val_loss": 2238.65909576416, "val_acc": 48.0}
{"epoch": 3, "training_loss": 10240.338989257812, "training_acc": 47.0, "val_loss": 4925.420379638672, "val_acc": 52.0}
{"epoch": 4, "training_loss": 19536.320373535156, "training_acc": 53.0, "val_loss": 3742.361068725586, "val_acc": 52.0}
{"epoch": 5, "training_loss": 10509.019958496094, "training_acc": 53.0, "val_loss": 2405.6215286254883, "val_acc": 48.0}
{"epoch": 6, "training_loss": 11918.904602050781, "training_acc": 47.0, "val_loss": 4050.0858306884766, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14433.395324707031, "training_acc": 47.0, "val_loss": 25.704386830329895, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3405.5949172973633, "training_acc": 55.0, "val_loss": 4436.199951171875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 17802.808654785156, "training_acc": 53.0, "val_loss": 3785.6643676757812, "val_acc": 52.0}
{"epoch": 10, "training_loss": 11756.901947021484, "training_acc": 53.0, "val_loss": 852.9264450073242, "val_acc": 48.0}
{"epoch": 11, "training_loss": 6173.520568847656, "training_acc": 47.0, "val_loss": 2170.9285736083984, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6622.448501586914, "training_acc": 47.0, "val_loss": 1548.2670783996582, "val_acc": 52.0}
{"epoch": 13, "training_loss": 8147.235290527344, "training_acc": 53.0, "val_loss": 2544.3578720092773, "val_acc": 52.0}
{"epoch": 14, "training_loss": 8252.792266845703, "training_acc": 53.0, "val_loss": 628.2238006591797, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3640.7460174560547, "training_acc": 47.0, "val_loss": 852.455997467041, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2183.1262016296387, "training_acc": 63.0, "val_loss": 1058.890438079834, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3477.3181381225586, "training_acc": 53.0, "val_loss": 864.7886276245117, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3865.710723876953, "training_acc": 47.0, "val_loss": 80.62843680381775, "val_acc": 52.0}
{"epoch": 19, "training_loss": 323.1710891723633, "training_acc": 43.0, "val_loss": 1076.8308639526367, "val_acc": 52.0}
{"epoch": 20, "training_loss": 4140.4287109375, "training_acc": 53.0, "val_loss": 211.02478504180908, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2417.7977905273438, "training_acc": 55.0, "val_loss": 1942.9046630859375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 6820.978302001953, "training_acc": 47.0, "val_loss": 559.8905086517334, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2815.494583129883, "training_acc": 53.0, "val_loss": 540.8545970916748, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2655.091018676758, "training_acc": 51.0, "val_loss": 1039.8642539978027, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2738.2862470149994, "training_acc": 47.0, "val_loss": 1471.2831497192383, "val_acc": 52.0}
{"epoch": 26, "training_loss": 6294.309387207031, "training_acc": 53.0, "val_loss": 1212.9225730895996, "val_acc": 52.0}
