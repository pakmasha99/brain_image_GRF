"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 12305.441459655762, "training_acc": 53.0, "val_loss": 3168.820571899414, "val_acc": 52.0}
{"epoch": 1, "training_loss": 12892.795471191406, "training_acc": 59.0, "val_loss": 7209.8541259765625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 26337.825256347656, "training_acc": 47.0, "val_loss": 537.5613689422607, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6768.802062988281, "training_acc": 55.0, "val_loss": 7333.3038330078125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 29761.84765625, "training_acc": 53.0, "val_loss": 6359.38835144043, "val_acc": 52.0}
{"epoch": 5, "training_loss": 21085.83953857422, "training_acc": 53.0, "val_loss": 315.80564975738525, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4744.371978759766, "training_acc": 47.0, "val_loss": 1957.2967529296875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5234.479221343994, "training_acc": 47.0, "val_loss": 2568.8621520996094, "val_acc": 52.0}
{"epoch": 8, "training_loss": 11348.763671875, "training_acc": 53.0, "val_loss": 3687.4893188476562, "val_acc": 52.0}
{"epoch": 9, "training_loss": 12834.486907958984, "training_acc": 53.0, "val_loss": 457.47838020324707, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5024.376892089844, "training_acc": 51.0, "val_loss": 4062.9783630371094, "val_acc": 48.0}
{"epoch": 11, "training_loss": 16490.63604736328, "training_acc": 47.0, "val_loss": 2603.7851333618164, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6995.294589996338, "training_acc": 47.0, "val_loss": 3011.978530883789, "val_acc": 52.0}
{"epoch": 13, "training_loss": 13839.580383300781, "training_acc": 53.0, "val_loss": 5183.340835571289, "val_acc": 52.0}
{"epoch": 14, "training_loss": 19553.712524414062, "training_acc": 53.0, "val_loss": 3125.4135131835938, "val_acc": 52.0}
{"epoch": 15, "training_loss": 9104.010803222656, "training_acc": 53.0, "val_loss": 2181.455612182617, "val_acc": 48.0}
{"epoch": 16, "training_loss": 11714.612487792969, "training_acc": 47.0, "val_loss": 3901.517105102539, "val_acc": 48.0}
{"epoch": 17, "training_loss": 14315.90673828125, "training_acc": 47.0, "val_loss": 549.1058349609375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 6130.550598144531, "training_acc": 39.0, "val_loss": 3771.320343017578, "val_acc": 52.0}
{"epoch": 19, "training_loss": 15000.219116210938, "training_acc": 53.0, "val_loss": 3189.3301010131836, "val_acc": 52.0}
{"epoch": 20, "training_loss": 10108.499542236328, "training_acc": 53.0, "val_loss": 867.2045707702637, "val_acc": 48.0}
{"epoch": 21, "training_loss": 6082.515319824219, "training_acc": 47.0, "val_loss": 1837.260627746582, "val_acc": 48.0}
{"epoch": 22, "training_loss": 5348.179824829102, "training_acc": 47.0, "val_loss": 1884.9922180175781, "val_acc": 52.0}
{"epoch": 23, "training_loss": 8699.799713134766, "training_acc": 53.0, "val_loss": 2856.758689880371, "val_acc": 52.0}
{"epoch": 24, "training_loss": 9957.036865234375, "training_acc": 53.0, "val_loss": 108.69723558425903, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3209.627960205078, "training_acc": 57.0, "val_loss": 3672.1920013427734, "val_acc": 48.0}
{"epoch": 26, "training_loss": 14883.0107421875, "training_acc": 47.0, "val_loss": 2419.852638244629, "val_acc": 48.0}
{"epoch": 27, "training_loss": 7043.539670944214, "training_acc": 47.0, "val_loss": 2629.374885559082, "val_acc": 52.0}
{"epoch": 28, "training_loss": 11743.504974365234, "training_acc": 53.0, "val_loss": 4428.194427490234, "val_acc": 52.0}
{"epoch": 29, "training_loss": 16588.70050048828, "training_acc": 53.0, "val_loss": 2446.2997436523438, "val_acc": 52.0}
{"epoch": 30, "training_loss": 6390.549377441406, "training_acc": 53.0, "val_loss": 2740.862274169922, "val_acc": 48.0}
{"epoch": 31, "training_loss": 13451.145874023438, "training_acc": 47.0, "val_loss": 4515.184783935547, "val_acc": 48.0}
{"epoch": 32, "training_loss": 16945.72265625, "training_acc": 47.0, "val_loss": 1568.85986328125, "val_acc": 48.0}
{"epoch": 33, "training_loss": 5659.893493652344, "training_acc": 51.0, "val_loss": 2757.0716857910156, "val_acc": 52.0}
{"epoch": 34, "training_loss": 11245.40982055664, "training_acc": 53.0, "val_loss": 2514.389991760254, "val_acc": 52.0}
{"epoch": 35, "training_loss": 7506.513198852539, "training_acc": 53.0, "val_loss": 1240.1005744934082, "val_acc": 48.0}
{"epoch": 36, "training_loss": 6746.615814208984, "training_acc": 47.0, "val_loss": 2102.442169189453, "val_acc": 48.0}
{"epoch": 37, "training_loss": 6591.491943359375, "training_acc": 47.0, "val_loss": 1445.7260131835938, "val_acc": 52.0}
{"epoch": 38, "training_loss": 6869.837646484375, "training_acc": 53.0, "val_loss": 2278.7527084350586, "val_acc": 52.0}
{"epoch": 39, "training_loss": 7447.998519897461, "training_acc": 53.0, "val_loss": 592.8543567657471, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3520.866989135742, "training_acc": 47.0, "val_loss": 620.0374603271484, "val_acc": 48.0}
{"epoch": 41, "training_loss": 3039.0467071533203, "training_acc": 49.0, "val_loss": 1461.3947868347168, "val_acc": 52.0}
{"epoch": 42, "training_loss": 4951.667922973633, "training_acc": 53.0, "val_loss": 519.6359157562256, "val_acc": 48.0}
{"epoch": 43, "training_loss": 2541.877716064453, "training_acc": 47.0, "val_loss": 220.25985717773438, "val_acc": 52.0}
