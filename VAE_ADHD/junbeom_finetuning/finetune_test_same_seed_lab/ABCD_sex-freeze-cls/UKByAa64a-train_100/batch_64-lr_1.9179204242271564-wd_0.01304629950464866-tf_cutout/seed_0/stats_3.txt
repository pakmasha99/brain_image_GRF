"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 17164.873054504395, "training_acc": 47.0, "val_loss": 2598.5729217529297, "val_acc": 48.0}
{"epoch": 1, "training_loss": 16672.659423828125, "training_acc": 45.0, "val_loss": 8445.32241821289, "val_acc": 52.0}
{"epoch": 2, "training_loss": 32194.595458984375, "training_acc": 53.0, "val_loss": 5310.4705810546875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 15872.393280029297, "training_acc": 53.0, "val_loss": 3638.4410858154297, "val_acc": 48.0}
{"epoch": 4, "training_loss": 18582.525268554688, "training_acc": 47.0, "val_loss": 5850.67024230957, "val_acc": 48.0}
{"epoch": 5, "training_loss": 21240.974853515625, "training_acc": 47.0, "val_loss": 982.956600189209, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7012.747314453125, "training_acc": 47.0, "val_loss": 4883.918380737305, "val_acc": 52.0}
{"epoch": 7, "training_loss": 20024.175720214844, "training_acc": 53.0, "val_loss": 4666.628646850586, "val_acc": 52.0}
{"epoch": 8, "training_loss": 16016.3017578125, "training_acc": 53.0, "val_loss": 166.35888814926147, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5075.229309082031, "training_acc": 53.0, "val_loss": 5210.17951965332, "val_acc": 48.0}
{"epoch": 10, "training_loss": 21642.663940429688, "training_acc": 47.0, "val_loss": 4455.684280395508, "val_acc": 48.0}
{"epoch": 11, "training_loss": 14692.89535522461, "training_acc": 47.0, "val_loss": 718.531608581543, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5005.437255859375, "training_acc": 53.0, "val_loss": 2652.556800842285, "val_acc": 52.0}
{"epoch": 13, "training_loss": 9445.78286743164, "training_acc": 53.0, "val_loss": 399.6582508087158, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4004.6029052734375, "training_acc": 51.0, "val_loss": 3053.9073944091797, "val_acc": 48.0}
{"epoch": 15, "training_loss": 11911.155700683594, "training_acc": 47.0, "val_loss": 1245.1363563537598, "val_acc": 48.0}
{"epoch": 16, "training_loss": 4430.253753662109, "training_acc": 51.0, "val_loss": 1901.8781661987305, "val_acc": 52.0}
{"epoch": 17, "training_loss": 7170.398239135742, "training_acc": 53.0, "val_loss": 683.6824893951416, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2424.686393737793, "training_acc": 63.0, "val_loss": 1854.610252380371, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6840.148391723633, "training_acc": 47.0, "val_loss": 223.1961965560913, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1190.9609756469727, "training_acc": 53.0, "val_loss": 217.28918552398682, "val_acc": 48.0}
{"epoch": 21, "training_loss": 959.8612899780273, "training_acc": 49.0, "val_loss": 271.7082738876343, "val_acc": 48.0}
{"epoch": 22, "training_loss": 874.7686405181885, "training_acc": 57.0, "val_loss": 86.38646602630615, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2006.5610809326172, "training_acc": 37.0, "val_loss": 491.4705276489258, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2831.1598052978516, "training_acc": 47.0, "val_loss": 991.3177490234375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3293.995979309082, "training_acc": 41.0, "val_loss": 89.36144709587097, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1873.1751098632812, "training_acc": 49.0, "val_loss": 916.0232543945312, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3006.833507537842, "training_acc": 47.0, "val_loss": 442.3497676849365, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1742.134750366211, "training_acc": 51.0, "val_loss": 136.4258050918579, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1722.5607604980469, "training_acc": 53.0, "val_loss": 1377.4402618408203, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4390.996658325195, "training_acc": 53.0, "val_loss": 936.3803863525391, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4265.049423217773, "training_acc": 47.0, "val_loss": 376.56471729278564, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2416.6635131835938, "training_acc": 55.0, "val_loss": 1992.372703552246, "val_acc": 52.0}
{"epoch": 33, "training_loss": 7278.123336791992, "training_acc": 53.0, "val_loss": 428.80563735961914, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2303.028106689453, "training_acc": 63.0, "val_loss": 2375.444984436035, "val_acc": 48.0}
{"epoch": 35, "training_loss": 9256.56802368164, "training_acc": 47.0, "val_loss": 588.2288455963135, "val_acc": 48.0}
{"epoch": 36, "training_loss": 4497.901275634766, "training_acc": 45.0, "val_loss": 2835.557746887207, "val_acc": 52.0}
{"epoch": 37, "training_loss": 11051.981994628906, "training_acc": 53.0, "val_loss": 1821.6957092285156, "val_acc": 52.0}
{"epoch": 38, "training_loss": 4731.843981266022, "training_acc": 49.0, "val_loss": 775.9282112121582, "val_acc": 48.0}
{"epoch": 39, "training_loss": 2445.742416381836, "training_acc": 47.0, "val_loss": 1174.894142150879, "val_acc": 52.0}
{"epoch": 40, "training_loss": 4964.429214477539, "training_acc": 53.0, "val_loss": 765.5062198638916, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2451.6213150024414, "training_acc": 59.0, "val_loss": 1157.6875686645508, "val_acc": 48.0}
