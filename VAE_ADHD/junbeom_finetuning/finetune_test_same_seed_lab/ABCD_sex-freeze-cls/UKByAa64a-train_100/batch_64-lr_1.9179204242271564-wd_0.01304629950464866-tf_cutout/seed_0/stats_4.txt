"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 17208.645503997803, "training_acc": 53.0, "val_loss": 3174.148368835449, "val_acc": 52.0}
{"epoch": 1, "training_loss": 12542.930908203125, "training_acc": 59.0, "val_loss": 7519.639587402344, "val_acc": 48.0}
{"epoch": 2, "training_loss": 28659.0185546875, "training_acc": 47.0, "val_loss": 2488.6207580566406, "val_acc": 48.0}
{"epoch": 3, "training_loss": 9591.35107421875, "training_acc": 51.0, "val_loss": 4643.305969238281, "val_acc": 52.0}
{"epoch": 4, "training_loss": 19098.506713867188, "training_acc": 53.0, "val_loss": 3461.0218048095703, "val_acc": 52.0}
{"epoch": 5, "training_loss": 9568.049446105957, "training_acc": 53.0, "val_loss": 3318.2201385498047, "val_acc": 48.0}
{"epoch": 6, "training_loss": 16577.15118408203, "training_acc": 47.0, "val_loss": 5096.418380737305, "val_acc": 48.0}
{"epoch": 7, "training_loss": 18569.77032470703, "training_acc": 47.0, "val_loss": 795.3989505767822, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4284.503601074219, "training_acc": 59.0, "val_loss": 4538.325500488281, "val_acc": 52.0}
{"epoch": 9, "training_loss": 18366.36016845703, "training_acc": 53.0, "val_loss": 4588.665771484375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 15694.291320800781, "training_acc": 53.0, "val_loss": 719.1775798797607, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5060.422149658203, "training_acc": 55.0, "val_loss": 4375.260162353516, "val_acc": 48.0}
{"epoch": 12, "training_loss": 18087.92852783203, "training_acc": 47.0, "val_loss": 3600.558090209961, "val_acc": 48.0}
{"epoch": 13, "training_loss": 12119.229278564453, "training_acc": 47.0, "val_loss": 1417.516040802002, "val_acc": 52.0}
{"epoch": 14, "training_loss": 8526.948486328125, "training_acc": 53.0, "val_loss": 2964.236831665039, "val_acc": 52.0}
{"epoch": 15, "training_loss": 10143.899444580078, "training_acc": 53.0, "val_loss": 94.43484544754028, "val_acc": 52.0}
{"epoch": 16, "training_loss": 5650.956573486328, "training_acc": 41.0, "val_loss": 4042.2035217285156, "val_acc": 48.0}
{"epoch": 17, "training_loss": 16098.616271972656, "training_acc": 47.0, "val_loss": 2494.2323684692383, "val_acc": 48.0}
{"epoch": 18, "training_loss": 6509.487934112549, "training_acc": 47.0, "val_loss": 2652.809715270996, "val_acc": 52.0}
{"epoch": 19, "training_loss": 13297.905700683594, "training_acc": 53.0, "val_loss": 4807.232284545898, "val_acc": 52.0}
{"epoch": 20, "training_loss": 17995.702575683594, "training_acc": 53.0, "val_loss": 2731.275749206543, "val_acc": 52.0}
{"epoch": 21, "training_loss": 7731.724494934082, "training_acc": 53.0, "val_loss": 2523.6087799072266, "val_acc": 48.0}
{"epoch": 22, "training_loss": 12529.104858398438, "training_acc": 47.0, "val_loss": 4261.463928222656, "val_acc": 48.0}
{"epoch": 23, "training_loss": 16071.374145507812, "training_acc": 47.0, "val_loss": 1269.083023071289, "val_acc": 48.0}
{"epoch": 24, "training_loss": 5830.530853271484, "training_acc": 45.0, "val_loss": 2724.5067596435547, "val_acc": 52.0}
{"epoch": 25, "training_loss": 10759.703643798828, "training_acc": 53.0, "val_loss": 2103.682518005371, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5957.289817810059, "training_acc": 53.0, "val_loss": 1886.8688583374023, "val_acc": 48.0}
{"epoch": 27, "training_loss": 9244.208618164062, "training_acc": 47.0, "val_loss": 2746.3388442993164, "val_acc": 48.0}
{"epoch": 28, "training_loss": 9514.963088989258, "training_acc": 47.0, "val_loss": 805.9844970703125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 4340.048400878906, "training_acc": 53.0, "val_loss": 1432.8539848327637, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4215.261600494385, "training_acc": 53.0, "val_loss": 1725.4219055175781, "val_acc": 48.0}
{"epoch": 31, "training_loss": 8085.780334472656, "training_acc": 47.0, "val_loss": 1710.3286743164062, "val_acc": 48.0}
{"epoch": 32, "training_loss": 5420.438514709473, "training_acc": 39.0, "val_loss": 493.59445571899414, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1547.2598209381104, "training_acc": 49.0, "val_loss": 338.74096870422363, "val_acc": 52.0}
{"epoch": 34, "training_loss": 969.049409866333, "training_acc": 53.0, "val_loss": 485.3799343109131, "val_acc": 52.0}
