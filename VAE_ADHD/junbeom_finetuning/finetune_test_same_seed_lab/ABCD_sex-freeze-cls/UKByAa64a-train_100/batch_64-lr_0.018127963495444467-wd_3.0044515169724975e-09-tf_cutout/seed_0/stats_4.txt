"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 83.30444622039795, "training_acc": 47.0, "val_loss": 18.313990533351898, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.58251976966858, "training_acc": 57.0, "val_loss": 22.928927838802338, "val_acc": 48.0}
{"epoch": 2, "training_loss": 90.69392371177673, "training_acc": 47.0, "val_loss": 17.433807253837585, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.57063388824463, "training_acc": 45.0, "val_loss": 20.18488198518753, "val_acc": 52.0}
{"epoch": 4, "training_loss": 79.90365147590637, "training_acc": 53.0, "val_loss": 18.41413527727127, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.83698010444641, "training_acc": 54.0, "val_loss": 17.977622151374817, "val_acc": 48.0}
{"epoch": 6, "training_loss": 74.58748936653137, "training_acc": 47.0, "val_loss": 18.538546562194824, "val_acc": 52.0}
{"epoch": 7, "training_loss": 75.46828961372375, "training_acc": 47.0, "val_loss": 17.22627431154251, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.27211284637451, "training_acc": 57.0, "val_loss": 17.83718764781952, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.65086436271667, "training_acc": 53.0, "val_loss": 17.5495445728302, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.21930408477783, "training_acc": 54.0, "val_loss": 17.20695048570633, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.34579229354858, "training_acc": 47.0, "val_loss": 17.363567650318146, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11492848396301, "training_acc": 49.0, "val_loss": 17.26038008928299, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.4773166179657, "training_acc": 55.0, "val_loss": 17.777374386787415, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.80632615089417, "training_acc": 53.0, "val_loss": 17.247718572616577, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.36362361907959, "training_acc": 57.0, "val_loss": 17.521749436855316, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.90219950675964, "training_acc": 52.0, "val_loss": 17.516009509563446, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.34402918815613, "training_acc": 49.0, "val_loss": 17.21605807542801, "val_acc": 52.0}
{"epoch": 18, "training_loss": 66.09364676475525, "training_acc": 67.0, "val_loss": 17.198435962200165, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.72522950172424, "training_acc": 58.0, "val_loss": 17.21993237733841, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.81513953208923, "training_acc": 57.0, "val_loss": 17.309488356113434, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.87451958656311, "training_acc": 57.0, "val_loss": 17.191123962402344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24057507514954, "training_acc": 62.0, "val_loss": 17.189335823059082, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.0237398147583, "training_acc": 50.0, "val_loss": 17.190587520599365, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.91862559318542, "training_acc": 70.0, "val_loss": 17.20849573612213, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.18515992164612, "training_acc": 56.0, "val_loss": 17.28285253047943, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.66953587532043, "training_acc": 53.0, "val_loss": 17.171160876750946, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.39363145828247, "training_acc": 58.0, "val_loss": 17.39773452281952, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.79147458076477, "training_acc": 57.0, "val_loss": 17.238792777061462, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.62966203689575, "training_acc": 65.0, "val_loss": 17.510893940925598, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.0247573852539, "training_acc": 54.0, "val_loss": 17.458610236644745, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.07640600204468, "training_acc": 56.0, "val_loss": 17.224185168743134, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.94837427139282, "training_acc": 52.0, "val_loss": 17.67267882823944, "val_acc": 56.0}
{"epoch": 33, "training_loss": 67.99198985099792, "training_acc": 52.0, "val_loss": 17.18580424785614, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.87380576133728, "training_acc": 64.0, "val_loss": 17.996974289417267, "val_acc": 52.0}
{"epoch": 35, "training_loss": 71.20197033882141, "training_acc": 53.0, "val_loss": 17.426401376724243, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.30579113960266, "training_acc": 60.0, "val_loss": 17.850525677204132, "val_acc": 64.0}
{"epoch": 37, "training_loss": 69.0000069141388, "training_acc": 45.0, "val_loss": 17.53510981798172, "val_acc": 52.0}
{"epoch": 38, "training_loss": 67.7042224407196, "training_acc": 60.0, "val_loss": 17.386065423488617, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.21854901313782, "training_acc": 55.0, "val_loss": 18.382716178894043, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.11247563362122, "training_acc": 53.0, "val_loss": 17.212769389152527, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.410728931427, "training_acc": 67.0, "val_loss": 17.704829573631287, "val_acc": 56.0}
{"epoch": 42, "training_loss": 68.11016082763672, "training_acc": 55.0, "val_loss": 17.341558635234833, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.977996826171875, "training_acc": 67.0, "val_loss": 17.52837747335434, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13127899169922, "training_acc": 53.0, "val_loss": 17.667987942695618, "val_acc": 52.0}
{"epoch": 45, "training_loss": 64.4345531463623, "training_acc": 54.0, "val_loss": 17.224682867527008, "val_acc": 52.0}
