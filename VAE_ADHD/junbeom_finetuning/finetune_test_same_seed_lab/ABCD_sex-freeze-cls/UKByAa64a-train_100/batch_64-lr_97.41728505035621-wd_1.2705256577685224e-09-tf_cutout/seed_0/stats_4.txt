"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 217576.53535842896, "training_acc": 44.0, "val_loss": 16877.81982421875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 189362.3759765625, "training_acc": 49.0, "val_loss": 147323.93798828125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 558889.48046875, "training_acc": 53.0, "val_loss": 112570.54443359375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 366900.2802734375, "training_acc": 53.0, "val_loss": 10364.958953857422, "val_acc": 48.0}
{"epoch": 4, "training_loss": 95825.58740234375, "training_acc": 47.0, "val_loss": 47717.1875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 165735.50146484375, "training_acc": 47.0, "val_loss": 16873.6083984375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 84241.03515625, "training_acc": 53.0, "val_loss": 26554.55322265625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 74231.59698486328, "training_acc": 54.0, "val_loss": 28906.8603515625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 131397.7421875, "training_acc": 47.0, "val_loss": 25805.06591796875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 60732.07891845703, "training_acc": 61.0, "val_loss": 22667.828369140625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 93823.71728515625, "training_acc": 53.0, "val_loss": 11240.457153320312, "val_acc": 52.0}
{"epoch": 11, "training_loss": 44231.86572265625, "training_acc": 55.0, "val_loss": 27920.504760742188, "val_acc": 48.0}
{"epoch": 12, "training_loss": 96921.78662109375, "training_acc": 47.0, "val_loss": 7962.863922119141, "val_acc": 52.0}
{"epoch": 13, "training_loss": 44306.09130859375, "training_acc": 55.0, "val_loss": 7588.426971435547, "val_acc": 52.0}
{"epoch": 14, "training_loss": 42705.4306640625, "training_acc": 50.0, "val_loss": 20957.989501953125, "val_acc": 48.0}
{"epoch": 15, "training_loss": 61559.01007080078, "training_acc": 50.0, "val_loss": 18574.99237060547, "val_acc": 52.0}
{"epoch": 16, "training_loss": 91884.00732421875, "training_acc": 53.0, "val_loss": 21286.44256591797, "val_acc": 52.0}
{"epoch": 17, "training_loss": 54368.008697509766, "training_acc": 53.0, "val_loss": 19990.879821777344, "val_acc": 48.0}
{"epoch": 18, "training_loss": 80976.68676757812, "training_acc": 48.0, "val_loss": 3500.638961791992, "val_acc": 48.0}
{"epoch": 19, "training_loss": 36453.3447265625, "training_acc": 52.0, "val_loss": 29289.529418945312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 100162.32470703125, "training_acc": 53.0, "val_loss": 1762.5709533691406, "val_acc": 64.0}
{"epoch": 21, "training_loss": 33071.612060546875, "training_acc": 51.0, "val_loss": 13316.30859375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 43662.55029296875, "training_acc": 45.0, "val_loss": 12525.225067138672, "val_acc": 52.0}
{"epoch": 23, "training_loss": 31262.012268066406, "training_acc": 57.0, "val_loss": 15026.942443847656, "val_acc": 48.0}
{"epoch": 24, "training_loss": 60282.742919921875, "training_acc": 46.0, "val_loss": 1160.4714393615723, "val_acc": 60.0}
{"epoch": 25, "training_loss": 35561.74365234375, "training_acc": 54.0, "val_loss": 16943.307495117188, "val_acc": 52.0}
{"epoch": 26, "training_loss": 38475.29919433594, "training_acc": 57.0, "val_loss": 23526.318359375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 102355.638671875, "training_acc": 47.0, "val_loss": 23581.930541992188, "val_acc": 48.0}
{"epoch": 28, "training_loss": 52630.59210205078, "training_acc": 55.0, "val_loss": 25463.136291503906, "val_acc": 52.0}
{"epoch": 29, "training_loss": 115950.2119140625, "training_acc": 53.0, "val_loss": 30968.008422851562, "val_acc": 52.0}
{"epoch": 30, "training_loss": 90996.48071289062, "training_acc": 53.0, "val_loss": 22004.571533203125, "val_acc": 48.0}
{"epoch": 31, "training_loss": 99174.375, "training_acc": 47.0, "val_loss": 27931.1279296875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 74382.00012207031, "training_acc": 47.0, "val_loss": 25761.14501953125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 114413.8974609375, "training_acc": 53.0, "val_loss": 41318.780517578125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 135598.22802734375, "training_acc": 53.0, "val_loss": 1056.4559936523438, "val_acc": 64.0}
{"epoch": 35, "training_loss": 31203.283203125, "training_acc": 69.0, "val_loss": 34677.79541015625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 123768.72216796875, "training_acc": 47.0, "val_loss": 1466.6037559509277, "val_acc": 56.0}
{"epoch": 37, "training_loss": 33756.136474609375, "training_acc": 64.0, "val_loss": 38954.96826171875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 146668.04443359375, "training_acc": 53.0, "val_loss": 19779.6142578125, "val_acc": 52.0}
{"epoch": 39, "training_loss": 54097.013916015625, "training_acc": 51.0, "val_loss": 20871.507263183594, "val_acc": 48.0}
{"epoch": 40, "training_loss": 72671.86743164062, "training_acc": 47.0, "val_loss": 9034.915161132812, "val_acc": 52.0}
{"epoch": 41, "training_loss": 34607.63977050781, "training_acc": 53.0, "val_loss": 2876.7738342285156, "val_acc": 56.0}
{"epoch": 42, "training_loss": 35572.37939453125, "training_acc": 49.0, "val_loss": 15895.7763671875, "val_acc": 48.0}
{"epoch": 43, "training_loss": 37347.24673461914, "training_acc": 56.0, "val_loss": 14990.391540527344, "val_acc": 52.0}
{"epoch": 44, "training_loss": 53320.573486328125, "training_acc": 53.0, "val_loss": 1411.9853973388672, "val_acc": 60.0}
{"epoch": 45, "training_loss": 28832.31298828125, "training_acc": 60.0, "val_loss": 10585.808563232422, "val_acc": 48.0}
{"epoch": 46, "training_loss": 40144.98059082031, "training_acc": 48.0, "val_loss": 11815.06576538086, "val_acc": 52.0}
{"epoch": 47, "training_loss": 28380.442626953125, "training_acc": 55.0, "val_loss": 4295.044326782227, "val_acc": 48.0}
{"epoch": 48, "training_loss": 19444.63037109375, "training_acc": 56.0, "val_loss": 5459.675598144531, "val_acc": 52.0}
{"epoch": 49, "training_loss": 13379.341430664062, "training_acc": 62.0, "val_loss": 2943.979263305664, "val_acc": 48.0}
{"epoch": 50, "training_loss": 19326.391479492188, "training_acc": 57.0, "val_loss": 6328.24592590332, "val_acc": 52.0}
{"epoch": 51, "training_loss": 22056.385986328125, "training_acc": 54.0, "val_loss": 2467.7921295166016, "val_acc": 44.0}
{"epoch": 52, "training_loss": 17145.589233398438, "training_acc": 57.0, "val_loss": 10760.623168945312, "val_acc": 52.0}
{"epoch": 53, "training_loss": 23277.168975830078, "training_acc": 59.0, "val_loss": 6520.226287841797, "val_acc": 48.0}
