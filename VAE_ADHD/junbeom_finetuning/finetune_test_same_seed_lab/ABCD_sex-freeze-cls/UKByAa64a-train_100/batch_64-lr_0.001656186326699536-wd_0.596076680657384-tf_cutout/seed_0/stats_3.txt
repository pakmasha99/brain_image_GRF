"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.1729199886322, "training_acc": 47.0, "val_loss": 17.396624386310577, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.92946696281433, "training_acc": 53.0, "val_loss": 18.347616493701935, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.13273930549622, "training_acc": 53.0, "val_loss": 18.29800307750702, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.12710690498352, "training_acc": 53.0, "val_loss": 17.30639636516571, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.42222547531128, "training_acc": 49.0, "val_loss": 17.44411438703537, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.69702911376953, "training_acc": 47.0, "val_loss": 17.51239150762558, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.10291266441345, "training_acc": 47.0, "val_loss": 17.239531874656677, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.70391035079956, "training_acc": 53.0, "val_loss": 17.49865710735321, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.96899819374084, "training_acc": 53.0, "val_loss": 17.544634640216827, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.9351236820221, "training_acc": 53.0, "val_loss": 17.316514253616333, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.70330357551575, "training_acc": 53.0, "val_loss": 17.242713272571564, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25431084632874, "training_acc": 53.0, "val_loss": 17.24764257669449, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.309903383255, "training_acc": 46.0, "val_loss": 17.25826859474182, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.34300351142883, "training_acc": 49.0, "val_loss": 17.244818806648254, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.7181351184845, "training_acc": 53.0, "val_loss": 17.28791743516922, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.0447461605072, "training_acc": 53.0, "val_loss": 17.247578501701355, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.0249719619751, "training_acc": 53.0, "val_loss": 17.249858379364014, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10396337509155, "training_acc": 52.0, "val_loss": 17.28350967168808, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.54731798171997, "training_acc": 42.0, "val_loss": 17.27343648672104, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.31754755973816, "training_acc": 45.0, "val_loss": 17.249485850334167, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.02818655967712, "training_acc": 52.0, "val_loss": 17.27248728275299, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23334860801697, "training_acc": 53.0, "val_loss": 17.357659339904785, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.48017072677612, "training_acc": 53.0, "val_loss": 17.341403663158417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18739342689514, "training_acc": 53.0, "val_loss": 17.247004806995392, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.99486374855042, "training_acc": 54.0, "val_loss": 17.272135615348816, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.22593808174133, "training_acc": 52.0, "val_loss": 17.263080179691315, "val_acc": 52.0}
