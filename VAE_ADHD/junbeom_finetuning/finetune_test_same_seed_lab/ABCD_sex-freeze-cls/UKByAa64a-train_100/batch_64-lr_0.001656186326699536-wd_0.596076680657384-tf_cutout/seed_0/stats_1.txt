"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.9354202747345, "training_acc": 59.0, "val_loss": 17.441369593143463, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.14480876922607, "training_acc": 49.0, "val_loss": 17.73616224527359, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.4329686164856, "training_acc": 47.0, "val_loss": 17.381595075130463, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.92517113685608, "training_acc": 53.0, "val_loss": 17.684754729270935, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.61390089988708, "training_acc": 53.0, "val_loss": 17.40233600139618, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16920876502991, "training_acc": 53.0, "val_loss": 17.364251613616943, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.40996098518372, "training_acc": 54.0, "val_loss": 17.36384779214859, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.99754452705383, "training_acc": 53.0, "val_loss": 17.44125634431839, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22164273262024, "training_acc": 53.0, "val_loss": 17.544183135032654, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.7730062007904, "training_acc": 53.0, "val_loss": 17.468519508838654, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24119472503662, "training_acc": 53.0, "val_loss": 17.371048033237457, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.99465584754944, "training_acc": 55.0, "val_loss": 17.460693418979645, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.99043226242065, "training_acc": 47.0, "val_loss": 17.4857959151268, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.53074026107788, "training_acc": 47.0, "val_loss": 17.363370954990387, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1352767944336, "training_acc": 53.0, "val_loss": 17.55710244178772, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.82034039497375, "training_acc": 53.0, "val_loss": 17.590415477752686, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.63707518577576, "training_acc": 53.0, "val_loss": 17.403987050056458, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19062733650208, "training_acc": 53.0, "val_loss": 17.38014966249466, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.96397733688354, "training_acc": 53.0, "val_loss": 17.36922413110733, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.0653030872345, "training_acc": 53.0, "val_loss": 17.456932365894318, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.66227602958679, "training_acc": 47.0, "val_loss": 17.42265671491623, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.43422627449036, "training_acc": 47.0, "val_loss": 17.37213283777237, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.01946115493774, "training_acc": 53.0, "val_loss": 17.468982934951782, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.3190004825592, "training_acc": 53.0, "val_loss": 17.481765151023865, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.40132164955139, "training_acc": 53.0, "val_loss": 17.39688515663147, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.05226492881775, "training_acc": 53.0, "val_loss": 17.36627221107483, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.01463437080383, "training_acc": 53.0, "val_loss": 17.36599951982498, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.68215322494507, "training_acc": 41.0, "val_loss": 17.374324798583984, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.06974792480469, "training_acc": 50.0, "val_loss": 17.39690601825714, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.01027798652649, "training_acc": 53.0, "val_loss": 17.506882548332214, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.51693296432495, "training_acc": 53.0, "val_loss": 17.494289577007294, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.26377367973328, "training_acc": 53.0, "val_loss": 17.365409433841705, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.64201283454895, "training_acc": 53.0, "val_loss": 17.45266318321228, "val_acc": 52.0}
