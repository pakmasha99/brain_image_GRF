"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 299473.20207595825, "training_acc": 46.0, "val_loss": 62588.17138671875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 303920.0859375, "training_acc": 53.0, "val_loss": 162088.18359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 610020.193359375, "training_acc": 47.0, "val_loss": 44930.65490722656, "val_acc": 48.0}
{"epoch": 3, "training_loss": 212563.5, "training_acc": 51.0, "val_loss": 118375.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 449740.572265625, "training_acc": 53.0, "val_loss": 105629.58984375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 313500.794921875, "training_acc": 53.0, "val_loss": 18353.02734375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 169157.5146484375, "training_acc": 47.0, "val_loss": 54102.7587890625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 183386.330078125, "training_acc": 47.0, "val_loss": 39202.7099609375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 152861.79931640625, "training_acc": 53.0, "val_loss": 67975.72021484375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 220727.37646484375, "training_acc": 53.0, "val_loss": 8565.89126586914, "val_acc": 52.0}
{"epoch": 10, "training_loss": 88280.39453125, "training_acc": 49.0, "val_loss": 63203.338623046875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 242163.41748046875, "training_acc": 47.0, "val_loss": 13407.080078125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 87741.10009765625, "training_acc": 49.0, "val_loss": 66507.31201171875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 255701.55078125, "training_acc": 53.0, "val_loss": 49858.15124511719, "val_acc": 52.0}
{"epoch": 14, "training_loss": 133845.47094726562, "training_acc": 52.0, "val_loss": 48893.24951171875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 238207.1181640625, "training_acc": 47.0, "val_loss": 72720.73974609375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 245349.10205078125, "training_acc": 47.0, "val_loss": 6622.660064697266, "val_acc": 60.0}
{"epoch": 17, "training_loss": 61208.65283203125, "training_acc": 54.0, "val_loss": 41750.96740722656, "val_acc": 52.0}
{"epoch": 18, "training_loss": 134383.45874023438, "training_acc": 53.0, "val_loss": 8592.794799804688, "val_acc": 48.0}
{"epoch": 19, "training_loss": 40961.768798828125, "training_acc": 53.0, "val_loss": 3341.5977478027344, "val_acc": 52.0}
{"epoch": 20, "training_loss": 41426.1689453125, "training_acc": 56.0, "val_loss": 18843.06640625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 41107.72155761719, "training_acc": 57.0, "val_loss": 10082.904815673828, "val_acc": 48.0}
{"epoch": 22, "training_loss": 31677.18145751953, "training_acc": 54.0, "val_loss": 14006.0302734375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 27525.329132080078, "training_acc": 60.0, "val_loss": 17056.800842285156, "val_acc": 48.0}
{"epoch": 24, "training_loss": 59182.345703125, "training_acc": 48.0, "val_loss": 16882.501220703125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 59210.355224609375, "training_acc": 55.0, "val_loss": 7169.361877441406, "val_acc": 60.0}
{"epoch": 26, "training_loss": 55868.47900390625, "training_acc": 50.0, "val_loss": 21026.780700683594, "val_acc": 48.0}
{"epoch": 27, "training_loss": 60110.47833251953, "training_acc": 54.0, "val_loss": 14667.863464355469, "val_acc": 52.0}
{"epoch": 28, "training_loss": 32693.087890625, "training_acc": 55.0, "val_loss": 18773.046875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 70418.880859375, "training_acc": 49.0, "val_loss": 16000.401306152344, "val_acc": 52.0}
{"epoch": 30, "training_loss": 58785.843994140625, "training_acc": 53.0, "val_loss": 9839.157104492188, "val_acc": 56.0}
{"epoch": 31, "training_loss": 49350.633544921875, "training_acc": 54.0, "val_loss": 20006.92901611328, "val_acc": 48.0}
{"epoch": 32, "training_loss": 60464.654541015625, "training_acc": 51.0, "val_loss": 11736.040496826172, "val_acc": 56.0}
{"epoch": 33, "training_loss": 25175.40118408203, "training_acc": 60.0, "val_loss": 9114.659881591797, "val_acc": 48.0}
{"epoch": 34, "training_loss": 44195.69873046875, "training_acc": 44.0, "val_loss": 4672.3876953125, "val_acc": 64.0}
{"epoch": 35, "training_loss": 25592.640258789062, "training_acc": 57.0, "val_loss": 3903.105926513672, "val_acc": 60.0}
{"epoch": 36, "training_loss": 23585.340209960938, "training_acc": 57.0, "val_loss": 7565.748596191406, "val_acc": 56.0}
{"epoch": 37, "training_loss": 30217.5517578125, "training_acc": 55.0, "val_loss": 6211.464691162109, "val_acc": 48.0}
{"epoch": 38, "training_loss": 43467.882568359375, "training_acc": 50.0, "val_loss": 23806.553649902344, "val_acc": 52.0}
