"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1452.552833557129, "training_acc": 53.0, "val_loss": 392.23647117614746, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2134.223663330078, "training_acc": 43.0, "val_loss": 712.7374172210693, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2501.5143966674805, "training_acc": 47.0, "val_loss": 40.01578390598297, "val_acc": 52.0}
{"epoch": 3, "training_loss": 402.5316162109375, "training_acc": 52.0, "val_loss": 189.74143266677856, "val_acc": 52.0}
{"epoch": 4, "training_loss": 441.35562562942505, "training_acc": 55.0, "val_loss": 109.83880758285522, "val_acc": 48.0}
{"epoch": 5, "training_loss": 313.089218378067, "training_acc": 48.0, "val_loss": 80.30699491500854, "val_acc": 52.0}
{"epoch": 6, "training_loss": 229.14863538742065, "training_acc": 50.0, "val_loss": 28.398245573043823, "val_acc": 56.0}
{"epoch": 7, "training_loss": 81.17282342910767, "training_acc": 59.0, "val_loss": 19.737090170383453, "val_acc": 60.0}
{"epoch": 8, "training_loss": 76.52907490730286, "training_acc": 61.0, "val_loss": 66.88765287399292, "val_acc": 52.0}
{"epoch": 9, "training_loss": 209.36480903625488, "training_acc": 47.0, "val_loss": 39.71027433872223, "val_acc": 52.0}
{"epoch": 10, "training_loss": 104.19496273994446, "training_acc": 55.0, "val_loss": 18.31240803003311, "val_acc": 56.0}
{"epoch": 11, "training_loss": 103.28723382949829, "training_acc": 55.0, "val_loss": 77.43591666221619, "val_acc": 48.0}
{"epoch": 12, "training_loss": 234.66837430000305, "training_acc": 46.0, "val_loss": 128.2808542251587, "val_acc": 52.0}
{"epoch": 13, "training_loss": 433.9659118652344, "training_acc": 53.0, "val_loss": 83.77838134765625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 318.0978136062622, "training_acc": 47.0, "val_loss": 89.86098766326904, "val_acc": 52.0}
{"epoch": 15, "training_loss": 342.42941188812256, "training_acc": 53.0, "val_loss": 32.09696412086487, "val_acc": 44.0}
{"epoch": 16, "training_loss": 149.1680850982666, "training_acc": 52.0, "val_loss": 117.02722311019897, "val_acc": 52.0}
{"epoch": 17, "training_loss": 415.49503993988037, "training_acc": 53.0, "val_loss": 19.72598284482956, "val_acc": 60.0}
{"epoch": 18, "training_loss": 185.95577812194824, "training_acc": 64.0, "val_loss": 28.516289591789246, "val_acc": 44.0}
{"epoch": 19, "training_loss": 322.8716812133789, "training_acc": 45.0, "val_loss": 179.3123483657837, "val_acc": 52.0}
{"epoch": 20, "training_loss": 506.25874185562134, "training_acc": 53.0, "val_loss": 168.56119632720947, "val_acc": 48.0}
{"epoch": 21, "training_loss": 734.1174659729004, "training_acc": 47.0, "val_loss": 101.83026790618896, "val_acc": 48.0}
{"epoch": 22, "training_loss": 386.4136629104614, "training_acc": 55.0, "val_loss": 215.39888381958008, "val_acc": 52.0}
{"epoch": 23, "training_loss": 733.691520690918, "training_acc": 53.0, "val_loss": 21.650423109531403, "val_acc": 56.0}
{"epoch": 24, "training_loss": 268.2030601501465, "training_acc": 64.0, "val_loss": 130.88349103927612, "val_acc": 48.0}
{"epoch": 25, "training_loss": 329.63071370124817, "training_acc": 55.0, "val_loss": 98.0495035648346, "val_acc": 52.0}
{"epoch": 26, "training_loss": 260.8469934463501, "training_acc": 53.0, "val_loss": 152.99047231674194, "val_acc": 48.0}
{"epoch": 27, "training_loss": 581.5965576171875, "training_acc": 47.0, "val_loss": 35.505324602127075, "val_acc": 44.0}
{"epoch": 28, "training_loss": 265.55821228027344, "training_acc": 60.0, "val_loss": 235.94186305999756, "val_acc": 52.0}
{"epoch": 29, "training_loss": 785.582275390625, "training_acc": 53.0, "val_loss": 30.836984515190125, "val_acc": 48.0}
