"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1706.785800933838, "training_acc": 46.0, "val_loss": 347.3340034484863, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1687.5795135498047, "training_acc": 53.0, "val_loss": 900.001335144043, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3386.7906036376953, "training_acc": 47.0, "val_loss": 249.55284595489502, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1180.0030975341797, "training_acc": 51.0, "val_loss": 657.0641994476318, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2496.959701538086, "training_acc": 53.0, "val_loss": 586.2941741943359, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1740.481430053711, "training_acc": 53.0, "val_loss": 102.03386545181274, "val_acc": 48.0}
{"epoch": 6, "training_loss": 939.4842987060547, "training_acc": 47.0, "val_loss": 300.67687034606934, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1018.8561725616455, "training_acc": 47.0, "val_loss": 217.18437671661377, "val_acc": 52.0}
{"epoch": 8, "training_loss": 846.9259757995605, "training_acc": 53.0, "val_loss": 375.7925033569336, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1218.9168167114258, "training_acc": 53.0, "val_loss": 46.363818645477295, "val_acc": 52.0}
{"epoch": 10, "training_loss": 484.8044548034668, "training_acc": 50.0, "val_loss": 332.82952308654785, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1263.7811813354492, "training_acc": 47.0, "val_loss": 40.80786108970642, "val_acc": 48.0}
{"epoch": 12, "training_loss": 434.8713073730469, "training_acc": 49.0, "val_loss": 384.4935417175293, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1459.155632019043, "training_acc": 53.0, "val_loss": 275.15242099761963, "val_acc": 52.0}
{"epoch": 14, "training_loss": 731.8131265640259, "training_acc": 50.0, "val_loss": 255.9389352798462, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1230.5634765625, "training_acc": 47.0, "val_loss": 338.7929677963257, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1086.7031936645508, "training_acc": 47.0, "val_loss": 135.0727915763855, "val_acc": 52.0}
{"epoch": 17, "training_loss": 649.5752067565918, "training_acc": 53.0, "val_loss": 278.9719581604004, "val_acc": 52.0}
{"epoch": 18, "training_loss": 901.8353681564331, "training_acc": 53.0, "val_loss": 45.60525417327881, "val_acc": 48.0}
{"epoch": 19, "training_loss": 260.66496181488037, "training_acc": 53.0, "val_loss": 52.339041233062744, "val_acc": 48.0}
{"epoch": 20, "training_loss": 331.9227981567383, "training_acc": 46.0, "val_loss": 142.3325777053833, "val_acc": 52.0}
{"epoch": 21, "training_loss": 332.8108558654785, "training_acc": 60.0, "val_loss": 117.43829250335693, "val_acc": 48.0}
{"epoch": 22, "training_loss": 506.8174514770508, "training_acc": 47.0, "val_loss": 28.480812907218933, "val_acc": 40.0}
{"epoch": 23, "training_loss": 275.4729480743408, "training_acc": 50.0, "val_loss": 181.66565895080566, "val_acc": 52.0}
{"epoch": 24, "training_loss": 484.9907417297363, "training_acc": 53.0, "val_loss": 92.1341061592102, "val_acc": 48.0}
{"epoch": 25, "training_loss": 429.15395736694336, "training_acc": 48.0, "val_loss": 32.15650916099548, "val_acc": 40.0}
{"epoch": 26, "training_loss": 175.70810317993164, "training_acc": 63.0, "val_loss": 151.74105167388916, "val_acc": 52.0}
{"epoch": 27, "training_loss": 334.61522817611694, "training_acc": 55.0, "val_loss": 111.4586353302002, "val_acc": 48.0}
{"epoch": 28, "training_loss": 523.0955581665039, "training_acc": 47.0, "val_loss": 32.379257678985596, "val_acc": 48.0}
{"epoch": 29, "training_loss": 197.63970756530762, "training_acc": 60.0, "val_loss": 211.94875240325928, "val_acc": 52.0}
{"epoch": 30, "training_loss": 628.9040470123291, "training_acc": 53.0, "val_loss": 28.92448604106903, "val_acc": 48.0}
{"epoch": 31, "training_loss": 274.901029586792, "training_acc": 58.0, "val_loss": 33.6445689201355, "val_acc": 52.0}
{"epoch": 32, "training_loss": 304.8515224456787, "training_acc": 52.0, "val_loss": 164.7144079208374, "val_acc": 52.0}
{"epoch": 33, "training_loss": 363.6094036102295, "training_acc": 53.0, "val_loss": 101.52876377105713, "val_acc": 48.0}
{"epoch": 34, "training_loss": 535.6475467681885, "training_acc": 47.0, "val_loss": 35.5193555355072, "val_acc": 48.0}
{"epoch": 35, "training_loss": 296.7223377227783, "training_acc": 47.0, "val_loss": 180.41170835494995, "val_acc": 52.0}
{"epoch": 36, "training_loss": 448.94235134124756, "training_acc": 55.0, "val_loss": 53.02213430404663, "val_acc": 48.0}
{"epoch": 37, "training_loss": 385.65625381469727, "training_acc": 49.0, "val_loss": 40.37838578224182, "val_acc": 56.0}
{"epoch": 38, "training_loss": 203.3210620880127, "training_acc": 57.0, "val_loss": 83.92711281776428, "val_acc": 56.0}
{"epoch": 39, "training_loss": 235.5276231765747, "training_acc": 53.0, "val_loss": 39.85184729099274, "val_acc": 44.0}
{"epoch": 40, "training_loss": 192.9328179359436, "training_acc": 57.0, "val_loss": 80.53772449493408, "val_acc": 52.0}
{"epoch": 41, "training_loss": 191.20603227615356, "training_acc": 57.0, "val_loss": 39.845579862594604, "val_acc": 48.0}
