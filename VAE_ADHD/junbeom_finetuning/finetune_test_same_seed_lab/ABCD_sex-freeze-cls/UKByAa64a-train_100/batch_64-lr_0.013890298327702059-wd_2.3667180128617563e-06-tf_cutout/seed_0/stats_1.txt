"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.79246258735657, "training_acc": 53.0, "val_loss": 18.798263370990753, "val_acc": 44.0}
{"epoch": 1, "training_loss": 71.22421956062317, "training_acc": 50.0, "val_loss": 17.56199151277542, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.2415418624878, "training_acc": 53.0, "val_loss": 17.665477097034454, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.25915837287903, "training_acc": 57.0, "val_loss": 18.474186956882477, "val_acc": 40.0}
{"epoch": 4, "training_loss": 75.10894775390625, "training_acc": 46.0, "val_loss": 18.05964559316635, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25594782829285, "training_acc": 52.0, "val_loss": 18.410034477710724, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.22674226760864, "training_acc": 53.0, "val_loss": 18.558523058891296, "val_acc": 52.0}
{"epoch": 7, "training_loss": 72.44242572784424, "training_acc": 53.0, "val_loss": 17.416957020759583, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.56148409843445, "training_acc": 44.0, "val_loss": 17.752571403980255, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.37322878837585, "training_acc": 49.0, "val_loss": 17.428100109100342, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.4939546585083, "training_acc": 58.0, "val_loss": 17.397886514663696, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.77801156044006, "training_acc": 54.0, "val_loss": 17.45675653219223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.6651337146759, "training_acc": 51.0, "val_loss": 17.34974980354309, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66.5889241695404, "training_acc": 74.0, "val_loss": 17.324848473072052, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.48829650878906, "training_acc": 56.0, "val_loss": 17.48311221599579, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.67759561538696, "training_acc": 53.0, "val_loss": 17.445312440395355, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.82891702651978, "training_acc": 50.0, "val_loss": 17.300841212272644, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.38129734992981, "training_acc": 51.0, "val_loss": 17.520850896835327, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.47647070884705, "training_acc": 52.0, "val_loss": 17.30719655752182, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.92742919921875, "training_acc": 56.0, "val_loss": 17.44440346956253, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.00317072868347, "training_acc": 51.0, "val_loss": 17.3349991440773, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.66530728340149, "training_acc": 59.0, "val_loss": 17.608951032161713, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.07178902626038, "training_acc": 54.0, "val_loss": 17.629531025886536, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.03894758224487, "training_acc": 53.0, "val_loss": 17.30072796344757, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.59138417243958, "training_acc": 53.0, "val_loss": 17.329394817352295, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.54960656166077, "training_acc": 62.0, "val_loss": 17.385607957839966, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.46221446990967, "training_acc": 55.0, "val_loss": 17.444872856140137, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.04852318763733, "training_acc": 55.0, "val_loss": 17.30155199766159, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.10353088378906, "training_acc": 58.0, "val_loss": 17.353251576423645, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.21665382385254, "training_acc": 57.0, "val_loss": 17.44454652070999, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.13018155097961, "training_acc": 59.0, "val_loss": 17.410339415073395, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.8532304763794, "training_acc": 59.0, "val_loss": 17.289726436138153, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.61078977584839, "training_acc": 69.0, "val_loss": 17.35326498746872, "val_acc": 56.0}
{"epoch": 33, "training_loss": 67.22271013259888, "training_acc": 55.0, "val_loss": 17.34989434480667, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.50886106491089, "training_acc": 52.0, "val_loss": 17.4082413315773, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.77678608894348, "training_acc": 55.0, "val_loss": 17.60561764240265, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.21088099479675, "training_acc": 53.0, "val_loss": 17.34738051891327, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.885005235672, "training_acc": 63.0, "val_loss": 17.309339344501495, "val_acc": 56.0}
{"epoch": 38, "training_loss": 66.64515614509583, "training_acc": 63.0, "val_loss": 17.40247756242752, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.37023639678955, "training_acc": 60.0, "val_loss": 17.783091962337494, "val_acc": 52.0}
{"epoch": 40, "training_loss": 66.7233555316925, "training_acc": 55.0, "val_loss": 17.546239495277405, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.26534652709961, "training_acc": 60.0, "val_loss": 17.30460673570633, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.3186342716217, "training_acc": 64.0, "val_loss": 17.37244427204132, "val_acc": 56.0}
{"epoch": 43, "training_loss": 68.31393480300903, "training_acc": 55.0, "val_loss": 17.26030856370926, "val_acc": 56.0}
{"epoch": 44, "training_loss": 67.14765858650208, "training_acc": 59.0, "val_loss": 17.76220351457596, "val_acc": 52.0}
{"epoch": 45, "training_loss": 66.30416011810303, "training_acc": 55.0, "val_loss": 17.326445877552032, "val_acc": 52.0}
{"epoch": 46, "training_loss": 66.8099160194397, "training_acc": 67.0, "val_loss": 17.32325702905655, "val_acc": 56.0}
{"epoch": 47, "training_loss": 66.53861951828003, "training_acc": 59.0, "val_loss": 17.44016259908676, "val_acc": 52.0}
{"epoch": 48, "training_loss": 63.922662019729614, "training_acc": 61.0, "val_loss": 17.706100642681122, "val_acc": 52.0}
{"epoch": 49, "training_loss": 64.84795355796814, "training_acc": 57.0, "val_loss": 17.452560365200043, "val_acc": 52.0}
{"epoch": 50, "training_loss": 67.09372448921204, "training_acc": 62.0, "val_loss": 17.69763082265854, "val_acc": 60.0}
{"epoch": 51, "training_loss": 66.22499990463257, "training_acc": 64.0, "val_loss": 17.68152564764023, "val_acc": 60.0}
{"epoch": 52, "training_loss": 64.27142643928528, "training_acc": 72.0, "val_loss": 17.60816127061844, "val_acc": 52.0}
{"epoch": 53, "training_loss": 66.44509100914001, "training_acc": 55.0, "val_loss": 17.79540777206421, "val_acc": 52.0}
{"epoch": 54, "training_loss": 66.3934280872345, "training_acc": 58.0, "val_loss": 17.635619640350342, "val_acc": 52.0}
{"epoch": 55, "training_loss": 65.85076999664307, "training_acc": 57.0, "val_loss": 17.565368115901947, "val_acc": 52.0}
{"epoch": 56, "training_loss": 65.00039649009705, "training_acc": 60.0, "val_loss": 17.52915382385254, "val_acc": 52.0}
{"epoch": 57, "training_loss": 64.70007014274597, "training_acc": 65.0, "val_loss": 17.512507736682892, "val_acc": 52.0}
{"epoch": 58, "training_loss": 65.30106949806213, "training_acc": 66.0, "val_loss": 17.484937608242035, "val_acc": 56.0}
{"epoch": 59, "training_loss": 66.70902681350708, "training_acc": 62.0, "val_loss": 17.570151388645172, "val_acc": 60.0}
{"epoch": 60, "training_loss": 66.00700259208679, "training_acc": 63.0, "val_loss": 17.48528629541397, "val_acc": 52.0}
{"epoch": 61, "training_loss": 65.98800349235535, "training_acc": 58.0, "val_loss": 17.648540437221527, "val_acc": 52.0}
{"epoch": 62, "training_loss": 64.84441757202148, "training_acc": 60.0, "val_loss": 17.697398364543915, "val_acc": 52.0}
