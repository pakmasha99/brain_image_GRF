"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 988662.6790161133, "training_acc": 53.0, "val_loss": 151191.17431640625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1122330.6328125, "training_acc": 51.0, "val_loss": 650577.05078125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2435187.5859375, "training_acc": 47.0, "val_loss": 237789.892578125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 895925.939453125, "training_acc": 45.0, "val_loss": 330371.9970703125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1297076.5078125, "training_acc": 53.0, "val_loss": 266035.1806640625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 862348.1772460938, "training_acc": 53.0, "val_loss": 189493.3349609375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 840625.70703125, "training_acc": 48.0, "val_loss": 285675.244140625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 913679.349609375, "training_acc": 48.0, "val_loss": 30212.335205078125, "val_acc": 44.0}
{"epoch": 8, "training_loss": 235133.443359375, "training_acc": 62.0, "val_loss": 188483.87451171875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 676320.376953125, "training_acc": 53.0, "val_loss": 18959.664916992188, "val_acc": 56.0}
{"epoch": 10, "training_loss": 286348.25390625, "training_acc": 48.0, "val_loss": 150556.65283203125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 458852.466796875, "training_acc": 46.0, "val_loss": 78608.63647460938, "val_acc": 52.0}
{"epoch": 12, "training_loss": 387366.466796875, "training_acc": 52.0, "val_loss": 89001.03149414062, "val_acc": 52.0}
{"epoch": 13, "training_loss": 328047.64111328125, "training_acc": 45.0, "val_loss": 74116.38793945312, "val_acc": 48.0}
{"epoch": 14, "training_loss": 219006.77368164062, "training_acc": 56.0, "val_loss": 52276.123046875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 166870.34423828125, "training_acc": 54.0, "val_loss": 51425.87890625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 173812.798828125, "training_acc": 49.0, "val_loss": 34916.78771972656, "val_acc": 52.0}
{"epoch": 17, "training_loss": 132590.89111328125, "training_acc": 58.0, "val_loss": 27938.705444335938, "val_acc": 44.0}
{"epoch": 18, "training_loss": 103683.89819335938, "training_acc": 54.0, "val_loss": 38673.40393066406, "val_acc": 52.0}
{"epoch": 19, "training_loss": 108592.13208007812, "training_acc": 58.0, "val_loss": 39658.10546875, "val_acc": 44.0}
{"epoch": 20, "training_loss": 106276.19946289062, "training_acc": 56.0, "val_loss": 32979.38537597656, "val_acc": 52.0}
{"epoch": 21, "training_loss": 87171.72583007812, "training_acc": 62.0, "val_loss": 30626.187133789062, "val_acc": 48.0}
{"epoch": 22, "training_loss": 73734.87658691406, "training_acc": 59.0, "val_loss": 58345.56884765625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 164621.70532226562, "training_acc": 54.0, "val_loss": 64590.875244140625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 217995.96826171875, "training_acc": 47.0, "val_loss": 40335.23864746094, "val_acc": 52.0}
{"epoch": 25, "training_loss": 136095.41455078125, "training_acc": 53.0, "val_loss": 17915.00701904297, "val_acc": 44.0}
{"epoch": 26, "training_loss": 64301.60498046875, "training_acc": 64.0, "val_loss": 34726.654052734375, "val_acc": 52.0}
{"epoch": 27, "training_loss": 87134.78735351562, "training_acc": 61.0, "val_loss": 55584.271240234375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 168213.58227539062, "training_acc": 47.0, "val_loss": 72271.77124023438, "val_acc": 52.0}
{"epoch": 29, "training_loss": 322204.22265625, "training_acc": 53.0, "val_loss": 17760.061645507812, "val_acc": 52.0}
{"epoch": 30, "training_loss": 203665.564453125, "training_acc": 56.0, "val_loss": 133428.79638671875, "val_acc": 48.0}
{"epoch": 31, "training_loss": 405831.91015625, "training_acc": 47.0, "val_loss": 102484.9609375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 506833.5390625, "training_acc": 53.0, "val_loss": 145160.1806640625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 382806.9572753906, "training_acc": 54.0, "val_loss": 148840.75927734375, "val_acc": 48.0}
{"epoch": 34, "training_loss": 713164.84375, "training_acc": 47.0, "val_loss": 194156.0791015625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 603569.4208984375, "training_acc": 47.0, "val_loss": 124714.48974609375, "val_acc": 52.0}
{"epoch": 36, "training_loss": 526436.509765625, "training_acc": 53.0, "val_loss": 219317.919921875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 735968.146484375, "training_acc": 53.0, "val_loss": 22549.29656982422, "val_acc": 56.0}
{"epoch": 38, "training_loss": 248666.396484375, "training_acc": 61.0, "val_loss": 230979.2724609375, "val_acc": 48.0}
{"epoch": 39, "training_loss": 870904.962890625, "training_acc": 47.0, "val_loss": 87413.51318359375, "val_acc": 48.0}
{"epoch": 40, "training_loss": 346925.69140625, "training_acc": 45.0, "val_loss": 182583.04443359375, "val_acc": 52.0}
{"epoch": 41, "training_loss": 693063.3984375, "training_acc": 53.0, "val_loss": 97788.37280273438, "val_acc": 52.0}
{"epoch": 42, "training_loss": 205341.32275390625, "training_acc": 65.0, "val_loss": 130997.52197265625, "val_acc": 48.0}
{"epoch": 43, "training_loss": 444137.173828125, "training_acc": 47.0, "val_loss": 14535.812377929688, "val_acc": 52.0}
{"epoch": 44, "training_loss": 102677.265625, "training_acc": 63.0, "val_loss": 83625.0, "val_acc": 52.0}
{"epoch": 45, "training_loss": 240357.58447265625, "training_acc": 57.0, "val_loss": 101710.17456054688, "val_acc": 48.0}
{"epoch": 46, "training_loss": 405750.8828125, "training_acc": 47.0, "val_loss": 56286.688232421875, "val_acc": 48.0}
{"epoch": 47, "training_loss": 286479.40234375, "training_acc": 43.0, "val_loss": 150661.767578125, "val_acc": 52.0}
{"epoch": 48, "training_loss": 480911.0166015625, "training_acc": 53.0, "val_loss": 19564.36309814453, "val_acc": 56.0}
{"epoch": 49, "training_loss": 184274.8291015625, "training_acc": 58.0, "val_loss": 128676.3427734375, "val_acc": 48.0}
{"epoch": 50, "training_loss": 340969.95166015625, "training_acc": 48.0, "val_loss": 90424.76196289062, "val_acc": 52.0}
{"epoch": 51, "training_loss": 440882.03515625, "training_acc": 53.0, "val_loss": 105771.08154296875, "val_acc": 52.0}
{"epoch": 52, "training_loss": 265838.33251953125, "training_acc": 54.0, "val_loss": 128934.5947265625, "val_acc": 48.0}
{"epoch": 53, "training_loss": 488907.162109375, "training_acc": 47.0, "val_loss": 73667.13256835938, "val_acc": 48.0}
{"epoch": 54, "training_loss": 276687.1474609375, "training_acc": 47.0, "val_loss": 139234.27734375, "val_acc": 52.0}
{"epoch": 55, "training_loss": 444779.1279296875, "training_acc": 53.0, "val_loss": 26322.869873046875, "val_acc": 60.0}
{"epoch": 56, "training_loss": 133249.4208984375, "training_acc": 57.0, "val_loss": 102749.658203125, "val_acc": 48.0}
{"epoch": 57, "training_loss": 266184.57177734375, "training_acc": 50.0, "val_loss": 98931.79321289062, "val_acc": 52.0}
{"epoch": 58, "training_loss": 379937.2578125, "training_acc": 53.0, "val_loss": 90400.50048828125, "val_acc": 52.0}
{"epoch": 59, "training_loss": 215804.5205078125, "training_acc": 57.0, "val_loss": 79452.03857421875, "val_acc": 48.0}
{"epoch": 60, "training_loss": 227262.12451171875, "training_acc": 49.0, "val_loss": 55849.896240234375, "val_acc": 52.0}
{"epoch": 61, "training_loss": 177337.689453125, "training_acc": 52.0, "val_loss": 20760.65216064453, "val_acc": 64.0}
{"epoch": 62, "training_loss": 94364.35107421875, "training_acc": 64.0, "val_loss": 50006.634521484375, "val_acc": 48.0}
