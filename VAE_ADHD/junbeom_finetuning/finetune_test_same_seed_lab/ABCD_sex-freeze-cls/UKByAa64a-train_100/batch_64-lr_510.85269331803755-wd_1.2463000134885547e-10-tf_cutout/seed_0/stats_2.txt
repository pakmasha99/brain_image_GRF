"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1406082.7353134155, "training_acc": 53.0, "val_loss": 276504.6142578125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1412414.234375, "training_acc": 41.0, "val_loss": 457411.62109375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1668296.26953125, "training_acc": 47.0, "val_loss": 95408.91723632812, "val_acc": 48.0}
{"epoch": 3, "training_loss": 714761.67578125, "training_acc": 41.0, "val_loss": 401085.546875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1537480.9375, "training_acc": 53.0, "val_loss": 328744.970703125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1019124.078125, "training_acc": 53.0, "val_loss": 72912.43286132812, "val_acc": 48.0}
{"epoch": 6, "training_loss": 473088.1640625, "training_acc": 47.0, "val_loss": 173683.10546875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 563021.7646484375, "training_acc": 47.0, "val_loss": 126059.912109375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 569159.865234375, "training_acc": 53.0, "val_loss": 188403.80859375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 591614.1728515625, "training_acc": 53.0, "val_loss": 61664.678955078125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 313764.16015625, "training_acc": 47.0, "val_loss": 71716.02783203125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 210858.47509765625, "training_acc": 54.0, "val_loss": 77133.29467773438, "val_acc": 52.0}
{"epoch": 12, "training_loss": 235774.28759765625, "training_acc": 51.0, "val_loss": 78202.38647460938, "val_acc": 48.0}
{"epoch": 13, "training_loss": 310872.873046875, "training_acc": 47.0, "val_loss": 10757.303619384766, "val_acc": 52.0}
{"epoch": 14, "training_loss": 153175.419921875, "training_acc": 59.0, "val_loss": 68012.36572265625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 177592.53930664062, "training_acc": 53.0, "val_loss": 32925.70495605469, "val_acc": 44.0}
{"epoch": 16, "training_loss": 124684.47216796875, "training_acc": 49.0, "val_loss": 16173.043823242188, "val_acc": 60.0}
{"epoch": 17, "training_loss": 95493.06494140625, "training_acc": 48.0, "val_loss": 19811.993408203125, "val_acc": 60.0}
{"epoch": 18, "training_loss": 51238.57873535156, "training_acc": 60.0, "val_loss": 28169.882202148438, "val_acc": 48.0}
{"epoch": 19, "training_loss": 99679.72814941406, "training_acc": 55.0, "val_loss": 67088.0126953125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 189870.25805664062, "training_acc": 53.0, "val_loss": 17010.304260253906, "val_acc": 44.0}
{"epoch": 21, "training_loss": 73000.22998046875, "training_acc": 54.0, "val_loss": 28415.170288085938, "val_acc": 52.0}
{"epoch": 22, "training_loss": 59634.6572265625, "training_acc": 58.0, "val_loss": 25122.63946533203, "val_acc": 52.0}
{"epoch": 23, "training_loss": 79489.22705078125, "training_acc": 50.0, "val_loss": 36358.32824707031, "val_acc": 52.0}
{"epoch": 24, "training_loss": 86382.01049804688, "training_acc": 62.0, "val_loss": 57970.556640625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 204035.1943359375, "training_acc": 47.0, "val_loss": 71805.90209960938, "val_acc": 52.0}
{"epoch": 26, "training_loss": 269729.4365234375, "training_acc": 53.0, "val_loss": 41274.20349121094, "val_acc": 52.0}
{"epoch": 27, "training_loss": 208225.232421875, "training_acc": 49.0, "val_loss": 109938.61083984375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 355094.326171875, "training_acc": 47.0, "val_loss": 105178.3935546875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 463136.419921875, "training_acc": 53.0, "val_loss": 143147.900390625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 377357.7587890625, "training_acc": 54.0, "val_loss": 122193.71337890625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 603539.74609375, "training_acc": 47.0, "val_loss": 145539.36767578125, "val_acc": 48.0}
{"epoch": 32, "training_loss": 416821.1442871094, "training_acc": 48.0, "val_loss": 169103.6865234375, "val_acc": 52.0}
