"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1083259.2534942627, "training_acc": 54.0, "val_loss": 216730.2734375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1076512.1015625, "training_acc": 41.0, "val_loss": 326480.810546875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1210540.1171875, "training_acc": 47.0, "val_loss": 51398.907470703125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 525401.46875, "training_acc": 41.0, "val_loss": 323529.1259765625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1270425.11328125, "training_acc": 53.0, "val_loss": 269286.0595703125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 882376.640625, "training_acc": 53.0, "val_loss": 32289.804077148438, "val_acc": 48.0}
{"epoch": 6, "training_loss": 253149.7421875, "training_acc": 47.0, "val_loss": 106960.07080078125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 324233.1435546875, "training_acc": 47.0, "val_loss": 119291.845703125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 540448.212890625, "training_acc": 53.0, "val_loss": 166097.71728515625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 558770.91796875, "training_acc": 53.0, "val_loss": 21315.403747558594, "val_acc": 48.0}
{"epoch": 10, "training_loss": 141454.2275390625, "training_acc": 47.0, "val_loss": 28931.597900390625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 145738.7353515625, "training_acc": 53.0, "val_loss": 86797.265625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 295116.49267578125, "training_acc": 53.0, "val_loss": 32997.454833984375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 147333.32275390625, "training_acc": 47.0, "val_loss": 12893.582153320312, "val_acc": 52.0}
{"epoch": 14, "training_loss": 41914.765869140625, "training_acc": 53.0, "val_loss": 63078.2958984375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 253611.5478515625, "training_acc": 47.0, "val_loss": 7441.704559326172, "val_acc": 52.0}
{"epoch": 16, "training_loss": 32405.411499023438, "training_acc": 53.0, "val_loss": 45106.06994628906, "val_acc": 48.0}
{"epoch": 17, "training_loss": 165124.7861328125, "training_acc": 47.0, "val_loss": 45357.147216796875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 198389.4697265625, "training_acc": 53.0, "val_loss": 20409.71221923828, "val_acc": 52.0}
{"epoch": 19, "training_loss": 214445.06640625, "training_acc": 41.0, "val_loss": 97475.65307617188, "val_acc": 48.0}
{"epoch": 20, "training_loss": 318523.6064453125, "training_acc": 47.0, "val_loss": 58736.676025390625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 292607.7802734375, "training_acc": 53.0, "val_loss": 99438.18359375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 301835.017578125, "training_acc": 53.0, "val_loss": 68669.68383789062, "val_acc": 48.0}
{"epoch": 23, "training_loss": 359352.041015625, "training_acc": 47.0, "val_loss": 84293.29223632812, "val_acc": 48.0}
{"epoch": 24, "training_loss": 239635.60595703125, "training_acc": 47.0, "val_loss": 30999.838256835938, "val_acc": 52.0}
{"epoch": 25, "training_loss": 94672.36486816406, "training_acc": 45.0, "val_loss": 28469.580078125, "val_acc": 52.0}
{"epoch": 26, "training_loss": 80526.26080322266, "training_acc": 53.0, "val_loss": 68827.99682617188, "val_acc": 48.0}
{"epoch": 27, "training_loss": 287573.2548828125, "training_acc": 47.0, "val_loss": 11015.689849853516, "val_acc": 48.0}
{"epoch": 28, "training_loss": 136337.7451171875, "training_acc": 55.0, "val_loss": 146804.58984375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 571935.138671875, "training_acc": 53.0, "val_loss": 85321.19140625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 256975.9052734375, "training_acc": 49.0, "val_loss": 62194.281005859375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 211353.58056640625, "training_acc": 47.0, "val_loss": 51712.884521484375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 237382.8876953125, "training_acc": 53.0, "val_loss": 47544.56787109375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 195437.53369140625, "training_acc": 45.0, "val_loss": 47032.91931152344, "val_acc": 48.0}
{"epoch": 34, "training_loss": 140587.38439941406, "training_acc": 47.0, "val_loss": 2978.330421447754, "val_acc": 52.0}
{"epoch": 35, "training_loss": 92868.4306640625, "training_acc": 51.0, "val_loss": 52877.886962890625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 151489.68786621094, "training_acc": 51.0, "val_loss": 20374.929809570312, "val_acc": 52.0}
{"epoch": 37, "training_loss": 82826.89819335938, "training_acc": 53.0, "val_loss": 7846.830749511719, "val_acc": 48.0}
{"epoch": 38, "training_loss": 130620.990234375, "training_acc": 45.0, "val_loss": 79598.29711914062, "val_acc": 52.0}
{"epoch": 39, "training_loss": 249667.89794921875, "training_acc": 53.0, "val_loss": 57026.30615234375, "val_acc": 48.0}
{"epoch": 40, "training_loss": 279826.779296875, "training_acc": 47.0, "val_loss": 43420.147705078125, "val_acc": 48.0}
{"epoch": 41, "training_loss": 199565.8779296875, "training_acc": 47.0, "val_loss": 87329.0283203125, "val_acc": 52.0}
{"epoch": 42, "training_loss": 307600.6484375, "training_acc": 53.0, "val_loss": 10127.863311767578, "val_acc": 48.0}
{"epoch": 43, "training_loss": 52034.629638671875, "training_acc": 47.0, "val_loss": 35040.972900390625, "val_acc": 52.0}
{"epoch": 44, "training_loss": 130467.73681640625, "training_acc": 53.0, "val_loss": 28913.623046875, "val_acc": 48.0}
{"epoch": 45, "training_loss": 112422.66015625, "training_acc": 47.0, "val_loss": 42800.421142578125, "val_acc": 52.0}
{"epoch": 46, "training_loss": 181176.7822265625, "training_acc": 53.0, "val_loss": 6851.596832275391, "val_acc": 52.0}
{"epoch": 47, "training_loss": 152881.6435546875, "training_acc": 51.0, "val_loss": 121490.4541015625, "val_acc": 48.0}
{"epoch": 48, "training_loss": 438939.6689453125, "training_acc": 47.0, "val_loss": 13602.227783203125, "val_acc": 52.0}
{"epoch": 49, "training_loss": 100364.53271484375, "training_acc": 53.0, "val_loss": 20380.078125, "val_acc": 52.0}
{"epoch": 50, "training_loss": 127216.75, "training_acc": 53.0, "val_loss": 69181.14624023438, "val_acc": 48.0}
{"epoch": 51, "training_loss": 203801.65991210938, "training_acc": 47.0, "val_loss": 87618.64013671875, "val_acc": 52.0}
{"epoch": 52, "training_loss": 424526.380859375, "training_acc": 53.0, "val_loss": 113024.93896484375, "val_acc": 52.0}
{"epoch": 53, "training_loss": 333005.01806640625, "training_acc": 53.0, "val_loss": 81395.12329101562, "val_acc": 48.0}
