"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 895477.0511779785, "training_acc": 51.0, "val_loss": 185934.27734375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 937377.359375, "training_acc": 49.0, "val_loss": 402589.306640625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1504418.5703125, "training_acc": 47.0, "val_loss": 97439.11743164062, "val_acc": 48.0}
{"epoch": 3, "training_loss": 571875.66796875, "training_acc": 45.0, "val_loss": 316352.392578125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1263111.08203125, "training_acc": 53.0, "val_loss": 266726.8798828125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 850211.65234375, "training_acc": 53.0, "val_loss": 69482.3486328125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 406531.80859375, "training_acc": 47.0, "val_loss": 156386.181640625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 516596.6865234375, "training_acc": 47.0, "val_loss": 75803.80249023438, "val_acc": 52.0}
{"epoch": 8, "training_loss": 344300.6376953125, "training_acc": 53.0, "val_loss": 122710.68115234375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 398372.03662109375, "training_acc": 53.0, "val_loss": 65199.407958984375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 309315.5966796875, "training_acc": 47.0, "val_loss": 56724.237060546875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 272813.9345703125, "training_acc": 39.0, "val_loss": 77872.62573242188, "val_acc": 52.0}
{"epoch": 12, "training_loss": 250266.228515625, "training_acc": 53.0, "val_loss": 54066.259765625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 267134.474609375, "training_acc": 47.0, "val_loss": 29035.922241210938, "val_acc": 48.0}
{"epoch": 14, "training_loss": 166049.4560546875, "training_acc": 53.0, "val_loss": 119437.14599609375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 443392.6435546875, "training_acc": 53.0, "val_loss": 34209.02404785156, "val_acc": 52.0}
{"epoch": 16, "training_loss": 241115.9765625, "training_acc": 47.0, "val_loss": 137256.09130859375, "val_acc": 48.0}
{"epoch": 17, "training_loss": 518330.50390625, "training_acc": 47.0, "val_loss": 19772.959899902344, "val_acc": 48.0}
{"epoch": 18, "training_loss": 282869.375, "training_acc": 39.0, "val_loss": 179039.2578125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 693887.00390625, "training_acc": 53.0, "val_loss": 121738.83056640625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 330994.546875, "training_acc": 53.0, "val_loss": 134342.431640625, "val_acc": 48.0}
{"epoch": 21, "training_loss": 641381.09765625, "training_acc": 47.0, "val_loss": 212974.3896484375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 781383.150390625, "training_acc": 47.0, "val_loss": 38198.138427734375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 241964.060546875, "training_acc": 53.0, "val_loss": 211465.2099609375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 858175.671875, "training_acc": 53.0, "val_loss": 215793.1884765625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 737887.66796875, "training_acc": 53.0, "val_loss": 23327.745056152344, "val_acc": 52.0}
{"epoch": 26, "training_loss": 258090.826171875, "training_acc": 53.0, "val_loss": 240363.671875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1000111.68359375, "training_acc": 47.0, "val_loss": 211709.2529296875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 696333.412109375, "training_acc": 47.0, "val_loss": 46226.19323730469, "val_acc": 52.0}
{"epoch": 29, "training_loss": 303559.439453125, "training_acc": 53.0, "val_loss": 150537.4755859375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 535583.349609375, "training_acc": 53.0, "val_loss": 31149.1943359375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 272042.404296875, "training_acc": 45.0, "val_loss": 167821.56982421875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 664412.509765625, "training_acc": 47.0, "val_loss": 77033.51440429688, "val_acc": 48.0}
{"epoch": 33, "training_loss": 249733.80615234375, "training_acc": 53.0, "val_loss": 110091.357421875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 428862.091796875, "training_acc": 53.0, "val_loss": 61719.47021484375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 159443.53588867188, "training_acc": 61.0, "val_loss": 71217.9931640625, "val_acc": 48.0}
{"epoch": 36, "training_loss": 249577.89697265625, "training_acc": 47.0, "val_loss": 44329.69970703125, "val_acc": 52.0}
