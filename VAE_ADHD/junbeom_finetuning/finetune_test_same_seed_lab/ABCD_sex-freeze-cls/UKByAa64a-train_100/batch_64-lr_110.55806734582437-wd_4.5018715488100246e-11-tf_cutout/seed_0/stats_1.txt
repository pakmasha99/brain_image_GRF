"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 326976.0326461792, "training_acc": 51.0, "val_loss": 172448.57177734375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 568999.59765625, "training_acc": 47.0, "val_loss": 175286.60888671875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 797496.13671875, "training_acc": 53.0, "val_loss": 143309.2041015625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 431543.8125, "training_acc": 51.0, "val_loss": 95861.67602539062, "val_acc": 48.0}
{"epoch": 4, "training_loss": 282110.35595703125, "training_acc": 47.0, "val_loss": 137461.279296875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 585536.5390625, "training_acc": 53.0, "val_loss": 137359.2041015625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 398226.2858886719, "training_acc": 53.0, "val_loss": 149392.59033203125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 698835.90234375, "training_acc": 47.0, "val_loss": 191172.7783203125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 619594.830078125, "training_acc": 47.0, "val_loss": 74524.07836914062, "val_acc": 52.0}
{"epoch": 9, "training_loss": 340228.8359375, "training_acc": 53.0, "val_loss": 149306.60400390625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 512999.22265625, "training_acc": 53.0, "val_loss": 2731.0009002685547, "val_acc": 24.0}
{"epoch": 11, "training_loss": 93818.05859375, "training_acc": 54.0, "val_loss": 90043.65234375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 266055.09814453125, "training_acc": 47.0, "val_loss": 97737.48168945312, "val_acc": 52.0}
{"epoch": 13, "training_loss": 434616.603515625, "training_acc": 53.0, "val_loss": 126297.79052734375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 389771.146484375, "training_acc": 53.0, "val_loss": 73635.85815429688, "val_acc": 48.0}
{"epoch": 15, "training_loss": 368644.408203125, "training_acc": 47.0, "val_loss": 96745.37353515625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 246652.28631591797, "training_acc": 46.0, "val_loss": 118781.7626953125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 517804.845703125, "training_acc": 53.0, "val_loss": 159228.62548828125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 532611.26953125, "training_acc": 53.0, "val_loss": 17508.05206298828, "val_acc": 48.0}
{"epoch": 19, "training_loss": 121238.400390625, "training_acc": 47.0, "val_loss": 27625.201416015625, "val_acc": 48.0}
{"epoch": 20, "training_loss": 110815.15380859375, "training_acc": 59.0, "val_loss": 85541.44897460938, "val_acc": 52.0}
{"epoch": 21, "training_loss": 294509.759765625, "training_acc": 53.0, "val_loss": 28842.303466796875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 130308.57421875, "training_acc": 47.0, "val_loss": 20452.072143554688, "val_acc": 52.0}
{"epoch": 23, "training_loss": 76484.97192382812, "training_acc": 53.0, "val_loss": 46688.995361328125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 163648.51977539062, "training_acc": 47.0, "val_loss": 37407.537841796875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 170144.2978515625, "training_acc": 53.0, "val_loss": 12962.403869628906, "val_acc": 48.0}
{"epoch": 26, "training_loss": 31852.041748046875, "training_acc": 49.0, "val_loss": 51797.4853515625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 192511.25927734375, "training_acc": 53.0, "val_loss": 18494.314575195312, "val_acc": 48.0}
{"epoch": 28, "training_loss": 54326.35021972656, "training_acc": 47.0, "val_loss": 60203.656005859375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 243118.0283203125, "training_acc": 53.0, "val_loss": 17598.837280273438, "val_acc": 52.0}
