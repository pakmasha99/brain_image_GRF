"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1021.2117233276367, "training_acc": 54.0, "val_loss": 203.20258140563965, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1185.681137084961, "training_acc": 45.0, "val_loss": 477.6644706726074, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1731.3763122558594, "training_acc": 47.0, "val_loss": 92.32704639434814, "val_acc": 48.0}
{"epoch": 3, "training_loss": 587.2105102539062, "training_acc": 49.0, "val_loss": 430.7839870452881, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1588.2949409484863, "training_acc": 53.0, "val_loss": 401.2377738952637, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1207.4691772460938, "training_acc": 53.0, "val_loss": 40.6075119972229, "val_acc": 48.0}
{"epoch": 6, "training_loss": 309.26734352111816, "training_acc": 58.0, "val_loss": 341.32659435272217, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1424.7756958007812, "training_acc": 47.0, "val_loss": 257.2314739227295, "val_acc": 48.0}
{"epoch": 8, "training_loss": 860.4403285980225, "training_acc": 47.0, "val_loss": 175.89969635009766, "val_acc": 52.0}
{"epoch": 9, "training_loss": 743.7178115844727, "training_acc": 53.0, "val_loss": 351.44238471984863, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1129.718864440918, "training_acc": 54.0, "val_loss": 199.9099850654602, "val_acc": 52.0}
{"epoch": 11, "training_loss": 476.56552267074585, "training_acc": 53.0, "val_loss": 150.91495513916016, "val_acc": 48.0}
{"epoch": 12, "training_loss": 811.5860900878906, "training_acc": 47.0, "val_loss": 180.28712272644043, "val_acc": 48.0}
{"epoch": 13, "training_loss": 654.0854988098145, "training_acc": 47.0, "val_loss": 127.51153707504272, "val_acc": 52.0}
{"epoch": 14, "training_loss": 488.02795028686523, "training_acc": 53.0, "val_loss": 226.74641609191895, "val_acc": 52.0}
{"epoch": 15, "training_loss": 633.0712985992432, "training_acc": 53.0, "val_loss": 42.90478825569153, "val_acc": 52.0}
{"epoch": 16, "training_loss": 317.3622131347656, "training_acc": 47.0, "val_loss": 183.97884368896484, "val_acc": 48.0}
{"epoch": 17, "training_loss": 751.5381774902344, "training_acc": 47.0, "val_loss": 36.55880391597748, "val_acc": 48.0}
{"epoch": 18, "training_loss": 299.1366386413574, "training_acc": 49.0, "val_loss": 206.64713382720947, "val_acc": 52.0}
{"epoch": 19, "training_loss": 705.6839752197266, "training_acc": 53.0, "val_loss": 137.48440742492676, "val_acc": 52.0}
{"epoch": 20, "training_loss": 318.63410115242004, "training_acc": 54.0, "val_loss": 109.70237255096436, "val_acc": 48.0}
{"epoch": 21, "training_loss": 532.1191120147705, "training_acc": 47.0, "val_loss": 88.04442286491394, "val_acc": 48.0}
{"epoch": 22, "training_loss": 279.3423237800598, "training_acc": 50.0, "val_loss": 91.50651097297668, "val_acc": 52.0}
{"epoch": 23, "training_loss": 312.48341941833496, "training_acc": 53.0, "val_loss": 14.945325255393982, "val_acc": 80.0}
{"epoch": 24, "training_loss": 172.9670066833496, "training_acc": 51.0, "val_loss": 68.06060075759888, "val_acc": 48.0}
{"epoch": 25, "training_loss": 199.11199235916138, "training_acc": 55.0, "val_loss": 69.74133253097534, "val_acc": 52.0}
{"epoch": 26, "training_loss": 257.6066942214966, "training_acc": 53.0, "val_loss": 17.71916151046753, "val_acc": 68.0}
{"epoch": 27, "training_loss": 123.69346475601196, "training_acc": 56.0, "val_loss": 24.712634086608887, "val_acc": 52.0}
{"epoch": 28, "training_loss": 141.30885457992554, "training_acc": 51.0, "val_loss": 68.42474341392517, "val_acc": 52.0}
{"epoch": 29, "training_loss": 143.47856044769287, "training_acc": 58.0, "val_loss": 48.04482161998749, "val_acc": 48.0}
{"epoch": 30, "training_loss": 196.35477352142334, "training_acc": 47.0, "val_loss": 62.88798451423645, "val_acc": 52.0}
{"epoch": 31, "training_loss": 234.3314266204834, "training_acc": 53.0, "val_loss": 45.518991351127625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 167.57634449005127, "training_acc": 51.0, "val_loss": 54.90083694458008, "val_acc": 48.0}
{"epoch": 33, "training_loss": 213.5613830089569, "training_acc": 48.0, "val_loss": 67.72079467773438, "val_acc": 52.0}
{"epoch": 34, "training_loss": 138.8692169189453, "training_acc": 55.0, "val_loss": 29.402169585227966, "val_acc": 52.0}
{"epoch": 35, "training_loss": 126.60763025283813, "training_acc": 50.0, "val_loss": 44.43960785865784, "val_acc": 52.0}
{"epoch": 36, "training_loss": 111.9072380065918, "training_acc": 62.0, "val_loss": 17.9196834564209, "val_acc": 52.0}
{"epoch": 37, "training_loss": 102.38919830322266, "training_acc": 54.0, "val_loss": 21.332423388957977, "val_acc": 52.0}
{"epoch": 38, "training_loss": 76.17200469970703, "training_acc": 61.0, "val_loss": 22.333423793315887, "val_acc": 52.0}
{"epoch": 39, "training_loss": 86.50476121902466, "training_acc": 61.0, "val_loss": 17.52421408891678, "val_acc": 52.0}
{"epoch": 40, "training_loss": 63.049965620040894, "training_acc": 69.0, "val_loss": 31.53950572013855, "val_acc": 52.0}
{"epoch": 41, "training_loss": 75.46198201179504, "training_acc": 62.0, "val_loss": 19.177350401878357, "val_acc": 48.0}
{"epoch": 42, "training_loss": 118.25923109054565, "training_acc": 48.0, "val_loss": 20.624156296253204, "val_acc": 52.0}
