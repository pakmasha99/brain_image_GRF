"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1148.4782905578613, "training_acc": 49.0, "val_loss": 223.146653175354, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1091.4017448425293, "training_acc": 49.0, "val_loss": 475.98838806152344, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1759.3450164794922, "training_acc": 47.0, "val_loss": 131.10250234603882, "val_acc": 48.0}
{"epoch": 3, "training_loss": 617.3050632476807, "training_acc": 49.0, "val_loss": 355.02073764801025, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1399.941707611084, "training_acc": 53.0, "val_loss": 296.75915241241455, "val_acc": 52.0}
{"epoch": 5, "training_loss": 927.6439838409424, "training_acc": 53.0, "val_loss": 84.4172716140747, "val_acc": 48.0}
{"epoch": 6, "training_loss": 462.1701545715332, "training_acc": 47.0, "val_loss": 182.93710947036743, "val_acc": 48.0}
{"epoch": 7, "training_loss": 579.3413953781128, "training_acc": 47.0, "val_loss": 92.86572337150574, "val_acc": 52.0}
{"epoch": 8, "training_loss": 503.0611572265625, "training_acc": 53.0, "val_loss": 148.29269647598267, "val_acc": 52.0}
{"epoch": 9, "training_loss": 453.58607721328735, "training_acc": 53.0, "val_loss": 110.09020805358887, "val_acc": 48.0}
{"epoch": 10, "training_loss": 502.0447425842285, "training_acc": 47.0, "val_loss": 138.69569301605225, "val_acc": 48.0}
{"epoch": 11, "training_loss": 429.5762519836426, "training_acc": 47.0, "val_loss": 93.28377842903137, "val_acc": 52.0}
{"epoch": 12, "training_loss": 390.1207504272461, "training_acc": 53.0, "val_loss": 67.48161315917969, "val_acc": 52.0}
{"epoch": 13, "training_loss": 249.882887840271, "training_acc": 47.0, "val_loss": 78.4008800983429, "val_acc": 48.0}
{"epoch": 14, "training_loss": 217.81079983711243, "training_acc": 49.0, "val_loss": 57.739830017089844, "val_acc": 52.0}
{"epoch": 15, "training_loss": 222.46276140213013, "training_acc": 53.0, "val_loss": 18.399639427661896, "val_acc": 52.0}
{"epoch": 16, "training_loss": 126.65972423553467, "training_acc": 59.0, "val_loss": 28.026339411735535, "val_acc": 48.0}
{"epoch": 17, "training_loss": 146.31972980499268, "training_acc": 51.0, "val_loss": 43.937620520591736, "val_acc": 52.0}
{"epoch": 18, "training_loss": 130.94393944740295, "training_acc": 58.0, "val_loss": 51.21360421180725, "val_acc": 48.0}
{"epoch": 19, "training_loss": 157.72533702850342, "training_acc": 54.0, "val_loss": 31.554535031318665, "val_acc": 52.0}
{"epoch": 20, "training_loss": 101.1656141281128, "training_acc": 57.0, "val_loss": 42.603087425231934, "val_acc": 48.0}
{"epoch": 21, "training_loss": 155.05857849121094, "training_acc": 41.0, "val_loss": 18.57328712940216, "val_acc": 56.0}
{"epoch": 22, "training_loss": 64.88667249679565, "training_acc": 63.0, "val_loss": 17.981845140457153, "val_acc": 60.0}
{"epoch": 23, "training_loss": 65.99094080924988, "training_acc": 62.0, "val_loss": 23.580802977085114, "val_acc": 52.0}
{"epoch": 24, "training_loss": 81.64440250396729, "training_acc": 56.0, "val_loss": 31.830957531929016, "val_acc": 48.0}
{"epoch": 25, "training_loss": 92.5107753276825, "training_acc": 60.0, "val_loss": 38.473594188690186, "val_acc": 52.0}
{"epoch": 26, "training_loss": 113.32096791267395, "training_acc": 54.0, "val_loss": 60.08484363555908, "val_acc": 48.0}
{"epoch": 27, "training_loss": 197.08586168289185, "training_acc": 47.0, "val_loss": 50.60035586357117, "val_acc": 52.0}
{"epoch": 28, "training_loss": 198.4102783203125, "training_acc": 53.0, "val_loss": 18.557758629322052, "val_acc": 56.0}
{"epoch": 29, "training_loss": 139.71760177612305, "training_acc": 58.0, "val_loss": 62.12450861930847, "val_acc": 48.0}
{"epoch": 30, "training_loss": 230.35066890716553, "training_acc": 41.0, "val_loss": 49.2387980222702, "val_acc": 52.0}
{"epoch": 31, "training_loss": 120.45079112052917, "training_acc": 59.0, "val_loss": 55.86276650428772, "val_acc": 48.0}
{"epoch": 32, "training_loss": 151.84371972084045, "training_acc": 48.0, "val_loss": 69.23631429672241, "val_acc": 52.0}
{"epoch": 33, "training_loss": 263.7772054672241, "training_acc": 53.0, "val_loss": 19.280849397182465, "val_acc": 56.0}
{"epoch": 34, "training_loss": 141.62985038757324, "training_acc": 59.0, "val_loss": 61.68263554573059, "val_acc": 48.0}
{"epoch": 35, "training_loss": 215.9713306427002, "training_acc": 41.0, "val_loss": 48.18669855594635, "val_acc": 52.0}
{"epoch": 36, "training_loss": 140.50675106048584, "training_acc": 61.0, "val_loss": 44.877323508262634, "val_acc": 48.0}
{"epoch": 37, "training_loss": 110.25180792808533, "training_acc": 58.0, "val_loss": 43.18827688694, "val_acc": 52.0}
{"epoch": 38, "training_loss": 136.39771437644958, "training_acc": 54.0, "val_loss": 38.52013349533081, "val_acc": 48.0}
{"epoch": 39, "training_loss": 126.09911370277405, "training_acc": 47.0, "val_loss": 24.27406758069992, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.03474020957947, "training_acc": 68.0, "val_loss": 24.128232896327972, "val_acc": 52.0}
{"epoch": 41, "training_loss": 76.74259686470032, "training_acc": 59.0, "val_loss": 22.40481525659561, "val_acc": 52.0}
