"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 184.6038465499878, "training_acc": 50.0, "val_loss": 411.5865230560303, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1360.553237915039, "training_acc": 53.0, "val_loss": 143.8507080078125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 690.5451850891113, "training_acc": 47.0, "val_loss": 33.41820538043976, "val_acc": 52.0}
{"epoch": 3, "training_loss": 201.39763641357422, "training_acc": 66.0, "val_loss": 257.84997940063477, "val_acc": 52.0}
{"epoch": 4, "training_loss": 889.7097911834717, "training_acc": 53.0, "val_loss": 38.289594650268555, "val_acc": 52.0}
{"epoch": 5, "training_loss": 324.10591888427734, "training_acc": 56.0, "val_loss": 251.77388191223145, "val_acc": 48.0}
{"epoch": 6, "training_loss": 974.4708862304688, "training_acc": 47.0, "val_loss": 25.821411609649658, "val_acc": 48.0}
{"epoch": 7, "training_loss": 339.8466548919678, "training_acc": 50.0, "val_loss": 293.61720085144043, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1069.5535163879395, "training_acc": 53.0, "val_loss": 206.28206729888916, "val_acc": 52.0}
{"epoch": 9, "training_loss": 560.6871666908264, "training_acc": 52.0, "val_loss": 143.1311011314392, "val_acc": 48.0}
{"epoch": 10, "training_loss": 861.2185478210449, "training_acc": 47.0, "val_loss": 210.06686687469482, "val_acc": 48.0}
{"epoch": 11, "training_loss": 758.2244892120361, "training_acc": 47.0, "val_loss": 77.46086120605469, "val_acc": 52.0}
{"epoch": 12, "training_loss": 409.9332962036133, "training_acc": 52.0, "val_loss": 199.9508023262024, "val_acc": 52.0}
{"epoch": 13, "training_loss": 611.1889801025391, "training_acc": 53.0, "val_loss": 22.522439062595367, "val_acc": 64.0}
{"epoch": 14, "training_loss": 222.58956146240234, "training_acc": 55.0, "val_loss": 107.21086263656616, "val_acc": 48.0}
{"epoch": 15, "training_loss": 378.17634773254395, "training_acc": 49.0, "val_loss": 99.12068247795105, "val_acc": 52.0}
{"epoch": 16, "training_loss": 360.238881111145, "training_acc": 53.0, "val_loss": 117.98850297927856, "val_acc": 52.0}
{"epoch": 17, "training_loss": 290.63894987106323, "training_acc": 54.0, "val_loss": 73.27061891555786, "val_acc": 48.0}
{"epoch": 18, "training_loss": 367.241605758667, "training_acc": 47.0, "val_loss": 27.593201398849487, "val_acc": 56.0}
{"epoch": 19, "training_loss": 182.68239784240723, "training_acc": 55.0, "val_loss": 119.72012519836426, "val_acc": 52.0}
{"epoch": 20, "training_loss": 350.9050178527832, "training_acc": 52.0, "val_loss": 29.100605845451355, "val_acc": 52.0}
{"epoch": 21, "training_loss": 167.82741165161133, "training_acc": 51.0, "val_loss": 36.64616644382477, "val_acc": 52.0}
{"epoch": 22, "training_loss": 160.44699048995972, "training_acc": 50.0, "val_loss": 60.321974754333496, "val_acc": 52.0}
{"epoch": 23, "training_loss": 185.80187249183655, "training_acc": 50.0, "val_loss": 38.56576383113861, "val_acc": 44.0}
{"epoch": 24, "training_loss": 135.01997876167297, "training_acc": 53.0, "val_loss": 30.58605194091797, "val_acc": 56.0}
{"epoch": 25, "training_loss": 81.91744327545166, "training_acc": 63.0, "val_loss": 22.217024862766266, "val_acc": 52.0}
{"epoch": 26, "training_loss": 81.67547678947449, "training_acc": 59.0, "val_loss": 31.278586387634277, "val_acc": 52.0}
{"epoch": 27, "training_loss": 89.75369763374329, "training_acc": 60.0, "val_loss": 18.7917098402977, "val_acc": 60.0}
{"epoch": 28, "training_loss": 73.0032308101654, "training_acc": 70.0, "val_loss": 31.081092357635498, "val_acc": 52.0}
{"epoch": 29, "training_loss": 64.96677851676941, "training_acc": 70.0, "val_loss": 18.17847639322281, "val_acc": 64.0}
{"epoch": 30, "training_loss": 86.64542245864868, "training_acc": 64.0, "val_loss": 32.678043842315674, "val_acc": 52.0}
{"epoch": 31, "training_loss": 103.83612823486328, "training_acc": 55.0, "val_loss": 19.139422476291656, "val_acc": 64.0}
{"epoch": 32, "training_loss": 70.45788526535034, "training_acc": 66.0, "val_loss": 29.70154881477356, "val_acc": 52.0}
{"epoch": 33, "training_loss": 76.1880350112915, "training_acc": 56.0, "val_loss": 26.545017957687378, "val_acc": 48.0}
{"epoch": 34, "training_loss": 87.34867882728577, "training_acc": 59.0, "val_loss": 27.25028097629547, "val_acc": 48.0}
{"epoch": 35, "training_loss": 72.69104838371277, "training_acc": 66.0, "val_loss": 37.689971923828125, "val_acc": 44.0}
{"epoch": 36, "training_loss": 92.13648676872253, "training_acc": 60.0, "val_loss": 40.62286615371704, "val_acc": 52.0}
{"epoch": 37, "training_loss": 98.34468197822571, "training_acc": 56.0, "val_loss": 20.63429057598114, "val_acc": 52.0}
{"epoch": 38, "training_loss": 61.524986743927, "training_acc": 72.0, "val_loss": 28.123772144317627, "val_acc": 52.0}
{"epoch": 39, "training_loss": 71.44581151008606, "training_acc": 59.0, "val_loss": 20.99274843931198, "val_acc": 56.0}
{"epoch": 40, "training_loss": 112.1237645149231, "training_acc": 50.0, "val_loss": 20.88898867368698, "val_acc": 60.0}
{"epoch": 41, "training_loss": 79.88666105270386, "training_acc": 60.0, "val_loss": 42.357221245765686, "val_acc": 52.0}
{"epoch": 42, "training_loss": 108.08927011489868, "training_acc": 55.0, "val_loss": 36.30515933036804, "val_acc": 44.0}
{"epoch": 43, "training_loss": 100.69427514076233, "training_acc": 51.0, "val_loss": 24.88352656364441, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62.630677461624146, "training_acc": 63.0, "val_loss": 20.849265158176422, "val_acc": 60.0}
{"epoch": 45, "training_loss": 61.416162967681885, "training_acc": 63.0, "val_loss": 21.06115221977234, "val_acc": 52.0}
{"epoch": 46, "training_loss": 76.14451456069946, "training_acc": 57.0, "val_loss": 69.7527825832367, "val_acc": 52.0}
{"epoch": 47, "training_loss": 204.39222764968872, "training_acc": 53.0, "val_loss": 35.03849804401398, "val_acc": 44.0}
{"epoch": 48, "training_loss": 128.0914340019226, "training_acc": 49.0, "val_loss": 55.56104779243469, "val_acc": 52.0}
