"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1331887.0731697083, "training_acc": 46.0, "val_loss": 278388.818359375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1351818.4765625, "training_acc": 53.0, "val_loss": 720959.130859375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2713335.9140625, "training_acc": 47.0, "val_loss": 199848.388671875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 945470.7578125, "training_acc": 51.0, "val_loss": 526525.9765625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2000421.421875, "training_acc": 53.0, "val_loss": 469834.765625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1394433.14453125, "training_acc": 53.0, "val_loss": 81633.48388671875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 752404.7421875, "training_acc": 47.0, "val_loss": 240646.1181640625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 815693.6953125, "training_acc": 47.0, "val_loss": 174371.630859375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 679919.97265625, "training_acc": 53.0, "val_loss": 302352.1728515625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 981781.59765625, "training_acc": 53.0, "val_loss": 38100.3662109375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 392666.43359375, "training_acc": 49.0, "val_loss": 281125.244140625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1077131.509765625, "training_acc": 47.0, "val_loss": 59634.06982421875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 390267.58984375, "training_acc": 49.0, "val_loss": 295820.80078125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1137344.94921875, "training_acc": 53.0, "val_loss": 221765.9912109375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 595334.9267578125, "training_acc": 52.0, "val_loss": 217474.2431640625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1059529.9296875, "training_acc": 47.0, "val_loss": 323455.95703125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1091290.84765625, "training_acc": 47.0, "val_loss": 29459.890747070312, "val_acc": 60.0}
{"epoch": 17, "training_loss": 271025.919921875, "training_acc": 54.0, "val_loss": 183991.90673828125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 590696.5395507812, "training_acc": 53.0, "val_loss": 41576.373291015625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 183090.6376953125, "training_acc": 50.0, "val_loss": 19967.909240722656, "val_acc": 56.0}
{"epoch": 20, "training_loss": 134173.3779296875, "training_acc": 60.0, "val_loss": 30980.670166015625, "val_acc": 60.0}
{"epoch": 21, "training_loss": 115184.2275390625, "training_acc": 55.0, "val_loss": 32986.444091796875, "val_acc": 44.0}
{"epoch": 22, "training_loss": 160142.296875, "training_acc": 55.0, "val_loss": 87675.2685546875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 164341.1717529297, "training_acc": 62.0, "val_loss": 85759.5947265625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 317264.3271484375, "training_acc": 48.0, "val_loss": 70379.9072265625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 227831.2978515625, "training_acc": 55.0, "val_loss": 31497.238159179688, "val_acc": 60.0}
{"epoch": 26, "training_loss": 232523.34375, "training_acc": 52.0, "val_loss": 76833.45336914062, "val_acc": 48.0}
{"epoch": 27, "training_loss": 272031.78857421875, "training_acc": 49.0, "val_loss": 72741.63208007812, "val_acc": 52.0}
{"epoch": 28, "training_loss": 145850.56958007812, "training_acc": 58.0, "val_loss": 46769.89440917969, "val_acc": 48.0}
{"epoch": 29, "training_loss": 148613.21118164062, "training_acc": 58.0, "val_loss": 118095.3125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 404226.7626953125, "training_acc": 53.0, "val_loss": 54369.000244140625, "val_acc": 56.0}
{"epoch": 31, "training_loss": 258079.21484375, "training_acc": 53.0, "val_loss": 114032.6904296875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 337419.8239746094, "training_acc": 52.0, "val_loss": 138770.42236328125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 548364.44921875, "training_acc": 53.0, "val_loss": 121231.33544921875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 226874.66821289062, "training_acc": 66.0, "val_loss": 97527.10571289062, "val_acc": 48.0}
{"epoch": 35, "training_loss": 344679.7080078125, "training_acc": 48.0, "val_loss": 78896.74682617188, "val_acc": 52.0}
{"epoch": 36, "training_loss": 269581.7861328125, "training_acc": 54.0, "val_loss": 36085.90393066406, "val_acc": 60.0}
{"epoch": 37, "training_loss": 177193.8173828125, "training_acc": 50.0, "val_loss": 73304.53491210938, "val_acc": 48.0}
{"epoch": 38, "training_loss": 239585.49951171875, "training_acc": 46.0, "val_loss": 65156.195068359375, "val_acc": 52.0}
