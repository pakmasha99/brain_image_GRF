"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 189911.28952789307, "training_acc": 53.0, "val_loss": 534425.537109375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2157518.3046875, "training_acc": 47.0, "val_loss": 41913.44299316406, "val_acc": 44.0}
{"epoch": 2, "training_loss": 362984.2421875, "training_acc": 68.0, "val_loss": 519638.57421875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1615659.890625, "training_acc": 53.0, "val_loss": 138830.6640625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 688197.03515625, "training_acc": 47.0, "val_loss": 399596.923828125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1614246.26953125, "training_acc": 47.0, "val_loss": 103709.70458984375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 554756.46484375, "training_acc": 51.0, "val_loss": 399355.95703125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1396573.67578125, "training_acc": 53.0, "val_loss": 316581.3720703125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 805295.1357421875, "training_acc": 54.0, "val_loss": 179551.0009765625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 946460.62109375, "training_acc": 47.0, "val_loss": 281530.37109375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1011546.5078125, "training_acc": 47.0, "val_loss": 103806.26220703125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 373791.51171875, "training_acc": 54.0, "val_loss": 243238.427734375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 657807.1279296875, "training_acc": 53.0, "val_loss": 39275.15563964844, "val_acc": 56.0}
{"epoch": 13, "training_loss": 252780.5380859375, "training_acc": 56.0, "val_loss": 57981.92138671875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 319011.11865234375, "training_acc": 54.0, "val_loss": 163646.923828125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 389547.9873046875, "training_acc": 53.0, "val_loss": 41558.8623046875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 189859.28125, "training_acc": 57.0, "val_loss": 48891.34216308594, "val_acc": 52.0}
{"epoch": 17, "training_loss": 214593.52734375, "training_acc": 54.0, "val_loss": 104246.25244140625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 178367.33740234375, "training_acc": 58.0, "val_loss": 51726.922607421875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 259624.8916015625, "training_acc": 50.0, "val_loss": 69899.56665039062, "val_acc": 48.0}
{"epoch": 20, "training_loss": 217303.3251953125, "training_acc": 56.0, "val_loss": 57039.007568359375, "val_acc": 48.0}
{"epoch": 21, "training_loss": 237078.744140625, "training_acc": 54.0, "val_loss": 61755.035400390625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 247036.6298828125, "training_acc": 52.0, "val_loss": 102925.10986328125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 262010.62841796875, "training_acc": 51.0, "val_loss": 82130.45654296875, "val_acc": 48.0}
{"epoch": 24, "training_loss": 340581.0732421875, "training_acc": 48.0, "val_loss": 34092.1875, "val_acc": 44.0}
{"epoch": 25, "training_loss": 161076.2099609375, "training_acc": 63.0, "val_loss": 75988.95263671875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 181273.9130859375, "training_acc": 58.0, "val_loss": 40933.23669433594, "val_acc": 52.0}
{"epoch": 27, "training_loss": 204941.43115234375, "training_acc": 50.0, "val_loss": 84199.47509765625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 174363.1240234375, "training_acc": 57.0, "val_loss": 23059.22393798828, "val_acc": 48.0}
{"epoch": 29, "training_loss": 95793.46533203125, "training_acc": 66.0, "val_loss": 82046.71630859375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 152467.88012695312, "training_acc": 54.0, "val_loss": 26596.636962890625, "val_acc": 36.0}
{"epoch": 31, "training_loss": 74084.69091796875, "training_acc": 61.0, "val_loss": 15605.625915527344, "val_acc": 56.0}
{"epoch": 32, "training_loss": 51848.84362792969, "training_acc": 63.0, "val_loss": 34344.586181640625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 45827.61975097656, "training_acc": 69.0, "val_loss": 37139.019775390625, "val_acc": 52.0}
{"epoch": 34, "training_loss": 83864.83679199219, "training_acc": 66.0, "val_loss": 9721.112823486328, "val_acc": 56.0}
{"epoch": 35, "training_loss": 36842.2880859375, "training_acc": 80.0, "val_loss": 8074.736022949219, "val_acc": 60.0}
{"epoch": 36, "training_loss": 42717.872314453125, "training_acc": 67.0, "val_loss": 56715.386962890625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 104072.21112060547, "training_acc": 59.0, "val_loss": 60228.60107421875, "val_acc": 48.0}
{"epoch": 38, "training_loss": 193048.16302490234, "training_acc": 58.0, "val_loss": 45353.961181640625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65668.53674316406, "training_acc": 65.0, "val_loss": 20801.356506347656, "val_acc": 48.0}
{"epoch": 40, "training_loss": 113174.6865234375, "training_acc": 51.0, "val_loss": 39606.50634765625, "val_acc": 52.0}
{"epoch": 41, "training_loss": 155655.896484375, "training_acc": 57.0, "val_loss": 44063.970947265625, "val_acc": 48.0}
{"epoch": 42, "training_loss": 281104.8095703125, "training_acc": 45.0, "val_loss": 132542.236328125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 260163.90600585938, "training_acc": 61.0, "val_loss": 92394.20166015625, "val_acc": 48.0}
{"epoch": 44, "training_loss": 384893.90625, "training_acc": 47.0, "val_loss": 69672.05810546875, "val_acc": 52.0}
{"epoch": 45, "training_loss": 154360.890625, "training_acc": 56.0, "val_loss": 37187.030029296875, "val_acc": 52.0}
{"epoch": 46, "training_loss": 130828.7939453125, "training_acc": 59.0, "val_loss": 30439.138793945312, "val_acc": 48.0}
{"epoch": 47, "training_loss": 230368.1396484375, "training_acc": 49.0, "val_loss": 160268.4326171875, "val_acc": 52.0}
{"epoch": 48, "training_loss": 343363.71240234375, "training_acc": 53.0, "val_loss": 85975.25024414062, "val_acc": 48.0}
{"epoch": 49, "training_loss": 441541.349609375, "training_acc": 47.0, "val_loss": 14775.564575195312, "val_acc": 44.0}
{"epoch": 50, "training_loss": 220058.048828125, "training_acc": 61.0, "val_loss": 211924.609375, "val_acc": 52.0}
{"epoch": 51, "training_loss": 573824.494140625, "training_acc": 53.0, "val_loss": 31205.722045898438, "val_acc": 52.0}
{"epoch": 52, "training_loss": 276071.05859375, "training_acc": 50.0, "val_loss": 15626.220703125, "val_acc": 36.0}
{"epoch": 53, "training_loss": 209603.720703125, "training_acc": 62.0, "val_loss": 165505.57861328125, "val_acc": 52.0}
{"epoch": 54, "training_loss": 385918.82080078125, "training_acc": 54.0, "val_loss": 115259.85107421875, "val_acc": 48.0}
