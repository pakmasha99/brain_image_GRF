"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 953.4942893981934, "training_acc": 56.0, "val_loss": 181.0781478881836, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1102.9769592285156, "training_acc": 49.0, "val_loss": 532.7935695648193, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1951.0960540771484, "training_acc": 47.0, "val_loss": 136.11342906951904, "val_acc": 48.0}
{"epoch": 3, "training_loss": 630.5793914794922, "training_acc": 51.0, "val_loss": 407.7218532562256, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1667.5079803466797, "training_acc": 53.0, "val_loss": 396.86224460601807, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1347.3985576629639, "training_acc": 53.0, "val_loss": 17.647674679756165, "val_acc": 56.0}
{"epoch": 6, "training_loss": 371.7626724243164, "training_acc": 56.0, "val_loss": 319.4826602935791, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1264.4172248840332, "training_acc": 47.0, "val_loss": 178.84068489074707, "val_acc": 48.0}
{"epoch": 8, "training_loss": 555.8397064208984, "training_acc": 43.0, "val_loss": 123.2270359992981, "val_acc": 52.0}
{"epoch": 9, "training_loss": 473.90069580078125, "training_acc": 53.0, "val_loss": 69.71189975738525, "val_acc": 52.0}
{"epoch": 10, "training_loss": 282.82354831695557, "training_acc": 49.0, "val_loss": 99.8970091342926, "val_acc": 48.0}
{"epoch": 11, "training_loss": 293.08182668685913, "training_acc": 49.0, "val_loss": 71.85438275337219, "val_acc": 52.0}
{"epoch": 12, "training_loss": 299.8742837905884, "training_acc": 53.0, "val_loss": 57.290810346603394, "val_acc": 52.0}
{"epoch": 13, "training_loss": 190.07923364639282, "training_acc": 52.0, "val_loss": 94.6934163570404, "val_acc": 48.0}
{"epoch": 14, "training_loss": 315.0492115020752, "training_acc": 44.0, "val_loss": 47.74008095264435, "val_acc": 52.0}
{"epoch": 15, "training_loss": 222.81042385101318, "training_acc": 53.0, "val_loss": 22.471976280212402, "val_acc": 52.0}
{"epoch": 16, "training_loss": 155.86774921417236, "training_acc": 57.0, "val_loss": 78.14992070198059, "val_acc": 48.0}
{"epoch": 17, "training_loss": 214.92009210586548, "training_acc": 51.0, "val_loss": 76.74012780189514, "val_acc": 52.0}
{"epoch": 18, "training_loss": 282.3351287841797, "training_acc": 53.0, "val_loss": 19.657297432422638, "val_acc": 56.0}
{"epoch": 19, "training_loss": 147.85507202148438, "training_acc": 58.0, "val_loss": 69.22891736030579, "val_acc": 48.0}
{"epoch": 20, "training_loss": 175.00407934188843, "training_acc": 59.0, "val_loss": 89.66041207313538, "val_acc": 52.0}
{"epoch": 21, "training_loss": 321.3423762321472, "training_acc": 53.0, "val_loss": 33.03880989551544, "val_acc": 52.0}
{"epoch": 22, "training_loss": 175.59757041931152, "training_acc": 50.0, "val_loss": 79.2162835597992, "val_acc": 48.0}
{"epoch": 23, "training_loss": 232.80212426185608, "training_acc": 54.0, "val_loss": 82.24310278892517, "val_acc": 52.0}
{"epoch": 24, "training_loss": 278.0693187713623, "training_acc": 53.0, "val_loss": 23.394519090652466, "val_acc": 52.0}
