"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1017.2826805114746, "training_acc": 46.0, "val_loss": 203.21874618530273, "val_acc": 52.0}
{"epoch": 1, "training_loss": 987.7384757995605, "training_acc": 53.0, "val_loss": 526.7491340637207, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1982.0638580322266, "training_acc": 47.0, "val_loss": 146.09501361846924, "val_acc": 48.0}
{"epoch": 3, "training_loss": 690.533483505249, "training_acc": 51.0, "val_loss": 384.4874143600464, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1461.385181427002, "training_acc": 53.0, "val_loss": 343.093204498291, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1018.7391128540039, "training_acc": 53.0, "val_loss": 59.97825860977173, "val_acc": 48.0}
{"epoch": 6, "training_loss": 551.9519157409668, "training_acc": 47.0, "val_loss": 178.06042432785034, "val_acc": 48.0}
{"epoch": 7, "training_loss": 605.282322883606, "training_acc": 47.0, "val_loss": 123.47849607467651, "val_acc": 52.0}
{"epoch": 8, "training_loss": 481.692045211792, "training_acc": 53.0, "val_loss": 213.93628120422363, "val_acc": 52.0}
{"epoch": 9, "training_loss": 689.4263763427734, "training_acc": 53.0, "val_loss": 23.773278295993805, "val_acc": 56.0}
{"epoch": 10, "training_loss": 261.4795379638672, "training_acc": 49.0, "val_loss": 156.20075464248657, "val_acc": 48.0}
{"epoch": 11, "training_loss": 562.779803276062, "training_acc": 47.0, "val_loss": 47.861433029174805, "val_acc": 52.0}
{"epoch": 12, "training_loss": 223.28791904449463, "training_acc": 55.0, "val_loss": 72.56709337234497, "val_acc": 52.0}
{"epoch": 13, "training_loss": 161.59986519813538, "training_acc": 61.0, "val_loss": 69.43441033363342, "val_acc": 48.0}
{"epoch": 14, "training_loss": 245.51037693023682, "training_acc": 47.0, "val_loss": 62.88454532623291, "val_acc": 52.0}
{"epoch": 15, "training_loss": 233.2424602508545, "training_acc": 54.0, "val_loss": 46.54555320739746, "val_acc": 52.0}
{"epoch": 16, "training_loss": 168.5988006591797, "training_acc": 50.0, "val_loss": 60.23058295249939, "val_acc": 48.0}
{"epoch": 17, "training_loss": 204.3465394973755, "training_acc": 51.0, "val_loss": 68.76720786094666, "val_acc": 52.0}
{"epoch": 18, "training_loss": 194.5037658214569, "training_acc": 53.0, "val_loss": 16.357608139514923, "val_acc": 68.0}
{"epoch": 19, "training_loss": 87.29394960403442, "training_acc": 64.0, "val_loss": 23.79877418279648, "val_acc": 56.0}
{"epoch": 20, "training_loss": 91.86414623260498, "training_acc": 60.0, "val_loss": 16.524486243724823, "val_acc": 64.0}
{"epoch": 21, "training_loss": 78.57347583770752, "training_acc": 60.0, "val_loss": 21.313314139842987, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.36289167404175, "training_acc": 62.0, "val_loss": 17.437611520290375, "val_acc": 64.0}
{"epoch": 23, "training_loss": 68.6494607925415, "training_acc": 61.0, "val_loss": 18.63044649362564, "val_acc": 64.0}
{"epoch": 24, "training_loss": 69.97542905807495, "training_acc": 65.0, "val_loss": 20.147956907749176, "val_acc": 60.0}
{"epoch": 25, "training_loss": 74.5640516281128, "training_acc": 60.0, "val_loss": 20.66456973552704, "val_acc": 60.0}
{"epoch": 26, "training_loss": 81.58809185028076, "training_acc": 59.0, "val_loss": 31.34371042251587, "val_acc": 52.0}
{"epoch": 27, "training_loss": 79.45318651199341, "training_acc": 54.0, "val_loss": 26.323997974395752, "val_acc": 48.0}
{"epoch": 28, "training_loss": 104.12249684333801, "training_acc": 49.0, "val_loss": 21.090327203273773, "val_acc": 56.0}
{"epoch": 29, "training_loss": 88.6557559967041, "training_acc": 50.0, "val_loss": 39.869093894958496, "val_acc": 52.0}
{"epoch": 30, "training_loss": 112.57816624641418, "training_acc": 55.0, "val_loss": 33.77646803855896, "val_acc": 48.0}
{"epoch": 31, "training_loss": 109.28270673751831, "training_acc": 55.0, "val_loss": 58.60080122947693, "val_acc": 52.0}
{"epoch": 32, "training_loss": 177.23505449295044, "training_acc": 53.0, "val_loss": 53.38957905769348, "val_acc": 48.0}
{"epoch": 33, "training_loss": 211.55983591079712, "training_acc": 47.0, "val_loss": 44.960081577301025, "val_acc": 52.0}
{"epoch": 34, "training_loss": 180.97978687286377, "training_acc": 53.0, "val_loss": 30.225631594657898, "val_acc": 48.0}
{"epoch": 35, "training_loss": 140.8303780555725, "training_acc": 47.0, "val_loss": 36.569103598594666, "val_acc": 52.0}
{"epoch": 36, "training_loss": 114.48946380615234, "training_acc": 53.0, "val_loss": 33.15815627574921, "val_acc": 48.0}
{"epoch": 37, "training_loss": 122.31749320030212, "training_acc": 47.0, "val_loss": 51.55060291290283, "val_acc": 52.0}
