"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 438.78148651123047, "training_acc": 51.0, "val_loss": 24.693621695041656, "val_acc": 44.0}
{"epoch": 1, "training_loss": 388.1012649536133, "training_acc": 59.0, "val_loss": 210.7929229736328, "val_acc": 52.0}
{"epoch": 2, "training_loss": 697.5886154174805, "training_acc": 53.0, "val_loss": 59.62870717048645, "val_acc": 48.0}
{"epoch": 3, "training_loss": 274.20004081726074, "training_acc": 49.0, "val_loss": 79.13511395454407, "val_acc": 48.0}
{"epoch": 4, "training_loss": 224.18902492523193, "training_acc": 53.0, "val_loss": 68.94053220748901, "val_acc": 52.0}
{"epoch": 5, "training_loss": 252.5173797607422, "training_acc": 53.0, "val_loss": 18.42147409915924, "val_acc": 48.0}
{"epoch": 6, "training_loss": 154.37879085540771, "training_acc": 52.0, "val_loss": 46.20895981788635, "val_acc": 48.0}
{"epoch": 7, "training_loss": 106.11754274368286, "training_acc": 62.0, "val_loss": 57.82008171081543, "val_acc": 52.0}
{"epoch": 8, "training_loss": 212.10510206222534, "training_acc": 53.0, "val_loss": 19.35262680053711, "val_acc": 52.0}
{"epoch": 9, "training_loss": 105.02826166152954, "training_acc": 55.0, "val_loss": 49.36542510986328, "val_acc": 48.0}
{"epoch": 10, "training_loss": 137.8534426689148, "training_acc": 51.0, "val_loss": 44.02323365211487, "val_acc": 52.0}
{"epoch": 11, "training_loss": 174.24047946929932, "training_acc": 53.0, "val_loss": 23.05305451154709, "val_acc": 52.0}
{"epoch": 12, "training_loss": 124.30190467834473, "training_acc": 46.0, "val_loss": 45.52531838417053, "val_acc": 48.0}
{"epoch": 13, "training_loss": 133.82814764976501, "training_acc": 49.0, "val_loss": 46.310028433799744, "val_acc": 52.0}
{"epoch": 14, "training_loss": 176.34536600112915, "training_acc": 53.0, "val_loss": 24.3915393948555, "val_acc": 52.0}
{"epoch": 15, "training_loss": 115.59488153457642, "training_acc": 48.0, "val_loss": 40.728795528411865, "val_acc": 48.0}
{"epoch": 16, "training_loss": 139.77323865890503, "training_acc": 52.0, "val_loss": 39.435821771621704, "val_acc": 52.0}
{"epoch": 17, "training_loss": 139.23598766326904, "training_acc": 53.0, "val_loss": 17.548392713069916, "val_acc": 60.0}
{"epoch": 18, "training_loss": 92.09558486938477, "training_acc": 52.0, "val_loss": 21.13303691148758, "val_acc": 56.0}
{"epoch": 19, "training_loss": 88.15717720985413, "training_acc": 48.0, "val_loss": 33.032989501953125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 102.6321325302124, "training_acc": 58.0, "val_loss": 24.037115275859833, "val_acc": 48.0}
{"epoch": 21, "training_loss": 86.15604853630066, "training_acc": 48.0, "val_loss": 22.068744897842407, "val_acc": 52.0}
{"epoch": 22, "training_loss": 78.0398850440979, "training_acc": 57.0, "val_loss": 17.70516186952591, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.51033425331116, "training_acc": 63.0, "val_loss": 17.762649059295654, "val_acc": 56.0}
{"epoch": 24, "training_loss": 70.00259137153625, "training_acc": 67.0, "val_loss": 20.38124054670334, "val_acc": 52.0}
{"epoch": 25, "training_loss": 61.19438195228577, "training_acc": 67.0, "val_loss": 21.854540705680847, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.95114326477051, "training_acc": 55.0, "val_loss": 24.407076835632324, "val_acc": 52.0}
{"epoch": 27, "training_loss": 73.4332640171051, "training_acc": 57.0, "val_loss": 19.951951503753662, "val_acc": 56.0}
{"epoch": 28, "training_loss": 67.795893907547, "training_acc": 57.0, "val_loss": 19.984255731105804, "val_acc": 52.0}
{"epoch": 29, "training_loss": 62.96989059448242, "training_acc": 63.0, "val_loss": 18.138064444065094, "val_acc": 52.0}
{"epoch": 30, "training_loss": 62.54821157455444, "training_acc": 66.0, "val_loss": 20.204776525497437, "val_acc": 52.0}
{"epoch": 31, "training_loss": 60.52767992019653, "training_acc": 57.0, "val_loss": 18.51491630077362, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.15123009681702, "training_acc": 59.0, "val_loss": 24.914762377738953, "val_acc": 52.0}
{"epoch": 33, "training_loss": 76.16799473762512, "training_acc": 54.0, "val_loss": 20.59621810913086, "val_acc": 60.0}
{"epoch": 34, "training_loss": 76.72687983512878, "training_acc": 52.0, "val_loss": 22.417357563972473, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.81899547576904, "training_acc": 60.0, "val_loss": 18.581512570381165, "val_acc": 52.0}
{"epoch": 36, "training_loss": 63.707847118377686, "training_acc": 65.0, "val_loss": 18.61960142850876, "val_acc": 52.0}
