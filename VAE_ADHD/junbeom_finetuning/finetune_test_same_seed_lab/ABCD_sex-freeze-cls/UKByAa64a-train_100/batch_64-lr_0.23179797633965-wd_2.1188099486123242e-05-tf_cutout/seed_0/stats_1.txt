"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 518.0715217590332, "training_acc": 49.0, "val_loss": 125.85270404815674, "val_acc": 52.0}
{"epoch": 1, "training_loss": 607.3776607513428, "training_acc": 45.0, "val_loss": 200.50413608551025, "val_acc": 48.0}
{"epoch": 2, "training_loss": 695.1863250732422, "training_acc": 47.0, "val_loss": 19.31479722261429, "val_acc": 52.0}
{"epoch": 3, "training_loss": 187.75232982635498, "training_acc": 53.0, "val_loss": 100.08934736251831, "val_acc": 52.0}
{"epoch": 4, "training_loss": 328.53987884521484, "training_acc": 53.0, "val_loss": 51.48512125015259, "val_acc": 48.0}
{"epoch": 5, "training_loss": 234.87633991241455, "training_acc": 47.0, "val_loss": 32.74740278720856, "val_acc": 48.0}
{"epoch": 6, "training_loss": 137.4835262298584, "training_acc": 53.0, "val_loss": 72.84117937088013, "val_acc": 52.0}
{"epoch": 7, "training_loss": 259.075795173645, "training_acc": 53.0, "val_loss": 16.843020915985107, "val_acc": 56.0}
{"epoch": 8, "training_loss": 106.18909454345703, "training_acc": 45.0, "val_loss": 45.560985803604126, "val_acc": 48.0}
{"epoch": 9, "training_loss": 171.4749310016632, "training_acc": 37.0, "val_loss": 33.085817098617554, "val_acc": 52.0}
{"epoch": 10, "training_loss": 102.17895984649658, "training_acc": 53.0, "val_loss": 21.970832347869873, "val_acc": 48.0}
{"epoch": 11, "training_loss": 101.8667459487915, "training_acc": 47.0, "val_loss": 19.62743103504181, "val_acc": 52.0}
{"epoch": 12, "training_loss": 82.32014465332031, "training_acc": 52.0, "val_loss": 19.527961313724518, "val_acc": 52.0}
{"epoch": 13, "training_loss": 84.90005445480347, "training_acc": 51.0, "val_loss": 17.32473075389862, "val_acc": 60.0}
{"epoch": 14, "training_loss": 79.21391558647156, "training_acc": 50.0, "val_loss": 24.45804476737976, "val_acc": 52.0}
{"epoch": 15, "training_loss": 79.06537747383118, "training_acc": 54.0, "val_loss": 19.32481974363327, "val_acc": 48.0}
{"epoch": 16, "training_loss": 71.85400748252869, "training_acc": 56.0, "val_loss": 21.9578817486763, "val_acc": 52.0}
{"epoch": 17, "training_loss": 80.88960766792297, "training_acc": 53.0, "val_loss": 18.731288611888885, "val_acc": 40.0}
{"epoch": 18, "training_loss": 72.28492903709412, "training_acc": 49.0, "val_loss": 17.30133146047592, "val_acc": 56.0}
{"epoch": 19, "training_loss": 64.97330164909363, "training_acc": 61.0, "val_loss": 17.412976920604706, "val_acc": 60.0}
{"epoch": 20, "training_loss": 65.74968385696411, "training_acc": 57.0, "val_loss": 22.7751687169075, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.34942650794983, "training_acc": 56.0, "val_loss": 20.654529333114624, "val_acc": 44.0}
{"epoch": 22, "training_loss": 91.82070899009705, "training_acc": 47.0, "val_loss": 23.209744691848755, "val_acc": 52.0}
{"epoch": 23, "training_loss": 79.70155334472656, "training_acc": 56.0, "val_loss": 18.282176554203033, "val_acc": 52.0}
{"epoch": 24, "training_loss": 75.08765912055969, "training_acc": 54.0, "val_loss": 17.643176019191742, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.72293400764465, "training_acc": 52.0, "val_loss": 19.935832917690277, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.74403047561646, "training_acc": 52.0, "val_loss": 19.383300840854645, "val_acc": 40.0}
