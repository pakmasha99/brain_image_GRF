"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 405.9792289733887, "training_acc": 54.0, "val_loss": 20.1577827334404, "val_acc": 56.0}
{"epoch": 1, "training_loss": 404.81321716308594, "training_acc": 50.0, "val_loss": 288.5720491409302, "val_acc": 44.0}
{"epoch": 2, "training_loss": 871.3032627105713, "training_acc": 48.0, "val_loss": 33.25320482254028, "val_acc": 56.0}
{"epoch": 3, "training_loss": 249.4502716064453, "training_acc": 52.0, "val_loss": 88.97674083709717, "val_acc": 56.0}
{"epoch": 4, "training_loss": 275.2419214248657, "training_acc": 53.0, "val_loss": 91.23615622520447, "val_acc": 44.0}
{"epoch": 5, "training_loss": 341.1628751754761, "training_acc": 48.0, "val_loss": 71.69855237007141, "val_acc": 44.0}
{"epoch": 6, "training_loss": 187.5514841079712, "training_acc": 52.0, "val_loss": 61.640000343322754, "val_acc": 56.0}
{"epoch": 7, "training_loss": 235.6338505744934, "training_acc": 52.0, "val_loss": 21.632464230060577, "val_acc": 56.0}
{"epoch": 8, "training_loss": 83.24798679351807, "training_acc": 61.0, "val_loss": 48.605936765670776, "val_acc": 44.0}
{"epoch": 9, "training_loss": 134.87318634986877, "training_acc": 54.0, "val_loss": 37.739574909210205, "val_acc": 52.0}
{"epoch": 10, "training_loss": 134.63441848754883, "training_acc": 51.0, "val_loss": 24.279646575450897, "val_acc": 60.0}
{"epoch": 11, "training_loss": 87.22480773925781, "training_acc": 57.0, "val_loss": 25.87343156337738, "val_acc": 44.0}
{"epoch": 12, "training_loss": 88.7529673576355, "training_acc": 55.0, "val_loss": 31.31636679172516, "val_acc": 52.0}
{"epoch": 13, "training_loss": 93.73176169395447, "training_acc": 56.0, "val_loss": 31.31795823574066, "val_acc": 36.0}
{"epoch": 14, "training_loss": 88.47461032867432, "training_acc": 56.0, "val_loss": 26.253724098205566, "val_acc": 52.0}
{"epoch": 15, "training_loss": 87.34755682945251, "training_acc": 55.0, "val_loss": 22.763139009475708, "val_acc": 56.0}
{"epoch": 16, "training_loss": 76.90709781646729, "training_acc": 55.0, "val_loss": 21.404558420181274, "val_acc": 56.0}
{"epoch": 17, "training_loss": 64.71510314941406, "training_acc": 65.0, "val_loss": 22.943854331970215, "val_acc": 52.0}
{"epoch": 18, "training_loss": 81.48369884490967, "training_acc": 54.0, "val_loss": 23.79412353038788, "val_acc": 44.0}
{"epoch": 19, "training_loss": 79.23661255836487, "training_acc": 50.0, "val_loss": 21.085235476493835, "val_acc": 52.0}
{"epoch": 20, "training_loss": 74.2317762374878, "training_acc": 53.0, "val_loss": 19.196851551532745, "val_acc": 60.0}
{"epoch": 21, "training_loss": 59.103869676589966, "training_acc": 71.0, "val_loss": 18.799087405204773, "val_acc": 56.0}
{"epoch": 22, "training_loss": 57.96613073348999, "training_acc": 70.0, "val_loss": 23.273402452468872, "val_acc": 44.0}
{"epoch": 23, "training_loss": 77.18789315223694, "training_acc": 54.0, "val_loss": 17.817646265029907, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.9643337726593, "training_acc": 57.0, "val_loss": 19.540779292583466, "val_acc": 52.0}
{"epoch": 25, "training_loss": 58.85399293899536, "training_acc": 65.0, "val_loss": 17.03188717365265, "val_acc": 52.0}
{"epoch": 26, "training_loss": 63.95038938522339, "training_acc": 61.0, "val_loss": 28.81142795085907, "val_acc": 44.0}
{"epoch": 27, "training_loss": 89.88175654411316, "training_acc": 54.0, "val_loss": 24.82575625181198, "val_acc": 56.0}
{"epoch": 28, "training_loss": 84.18757677078247, "training_acc": 52.0, "val_loss": 20.596574246883392, "val_acc": 60.0}
{"epoch": 29, "training_loss": 68.33020567893982, "training_acc": 58.0, "val_loss": 21.032238006591797, "val_acc": 56.0}
{"epoch": 30, "training_loss": 75.93480253219604, "training_acc": 55.0, "val_loss": 31.163954734802246, "val_acc": 44.0}
{"epoch": 31, "training_loss": 104.84500360488892, "training_acc": 48.0, "val_loss": 34.00503993034363, "val_acc": 56.0}
{"epoch": 32, "training_loss": 138.1907343864441, "training_acc": 52.0, "val_loss": 18.96943300962448, "val_acc": 60.0}
{"epoch": 33, "training_loss": 105.71760129928589, "training_acc": 50.0, "val_loss": 19.313205778598785, "val_acc": 56.0}
{"epoch": 34, "training_loss": 104.28231477737427, "training_acc": 50.0, "val_loss": 31.347736716270447, "val_acc": 56.0}
{"epoch": 35, "training_loss": 115.46535205841064, "training_acc": 51.0, "val_loss": 37.48695254325867, "val_acc": 44.0}
{"epoch": 36, "training_loss": 102.93910908699036, "training_acc": 61.0, "val_loss": 35.29784381389618, "val_acc": 56.0}
{"epoch": 37, "training_loss": 125.59472346305847, "training_acc": 50.0, "val_loss": 25.971046090126038, "val_acc": 48.0}
{"epoch": 38, "training_loss": 89.23706912994385, "training_acc": 50.0, "val_loss": 33.191025257110596, "val_acc": 56.0}
{"epoch": 39, "training_loss": 124.40440607070923, "training_acc": 52.0, "val_loss": 19.679710268974304, "val_acc": 60.0}
{"epoch": 40, "training_loss": 97.84202480316162, "training_acc": 57.0, "val_loss": 19.423457980155945, "val_acc": 56.0}
{"epoch": 41, "training_loss": 93.01982498168945, "training_acc": 59.0, "val_loss": 27.62390375137329, "val_acc": 52.0}
{"epoch": 42, "training_loss": 87.56601333618164, "training_acc": 57.0, "val_loss": 34.14183855056763, "val_acc": 44.0}
{"epoch": 43, "training_loss": 101.9334328174591, "training_acc": 48.0, "val_loss": 21.189460158348083, "val_acc": 56.0}
{"epoch": 44, "training_loss": 70.90354657173157, "training_acc": 63.0, "val_loss": 21.388308703899384, "val_acc": 52.0}
