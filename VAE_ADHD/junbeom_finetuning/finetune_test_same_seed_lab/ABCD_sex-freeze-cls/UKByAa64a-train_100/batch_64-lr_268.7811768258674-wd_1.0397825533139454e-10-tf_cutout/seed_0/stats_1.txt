"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 564552.8036384583, "training_acc": 46.0, "val_loss": 117996.58203125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 572975.3515625, "training_acc": 53.0, "val_loss": 305582.1533203125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1150061.25390625, "training_acc": 47.0, "val_loss": 84706.93359375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 400742.7001953125, "training_acc": 51.0, "val_loss": 223170.60546875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 847888.67578125, "training_acc": 53.0, "val_loss": 199141.93115234375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 591038.119140625, "training_acc": 53.0, "val_loss": 34600.555419921875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 318909.779296875, "training_acc": 47.0, "val_loss": 101998.94409179688, "val_acc": 48.0}
{"epoch": 7, "training_loss": 345735.3740234375, "training_acc": 47.0, "val_loss": 73908.38012695312, "val_acc": 52.0}
{"epoch": 8, "training_loss": 288187.96875, "training_acc": 53.0, "val_loss": 128153.67431640625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 416133.8525390625, "training_acc": 53.0, "val_loss": 16149.275207519531, "val_acc": 52.0}
{"epoch": 10, "training_loss": 166433.7529296875, "training_acc": 49.0, "val_loss": 119156.1279296875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 456546.7841796875, "training_acc": 47.0, "val_loss": 25276.02996826172, "val_acc": 48.0}
{"epoch": 12, "training_loss": 165416.693359375, "training_acc": 49.0, "val_loss": 125385.3271484375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 482070.119140625, "training_acc": 53.0, "val_loss": 93996.92993164062, "val_acc": 52.0}
{"epoch": 14, "training_loss": 252336.78930664062, "training_acc": 52.0, "val_loss": 92177.20947265625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 449086.015625, "training_acc": 47.0, "val_loss": 137098.20556640625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 462548.515625, "training_acc": 47.0, "val_loss": 12486.83853149414, "val_acc": 60.0}
{"epoch": 17, "training_loss": 115081.7216796875, "training_acc": 54.0, "val_loss": 78272.14965820312, "val_acc": 52.0}
{"epoch": 18, "training_loss": 251543.63403320312, "training_acc": 53.0, "val_loss": 17062.33367919922, "val_acc": 48.0}
{"epoch": 19, "training_loss": 75508.6494140625, "training_acc": 50.0, "val_loss": 8698.564147949219, "val_acc": 56.0}
{"epoch": 20, "training_loss": 54335.84619140625, "training_acc": 63.0, "val_loss": 12018.5546875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 47013.128173828125, "training_acc": 54.0, "val_loss": 12131.861877441406, "val_acc": 44.0}
{"epoch": 22, "training_loss": 66146.00341796875, "training_acc": 56.0, "val_loss": 39143.505859375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 75447.07403564453, "training_acc": 62.0, "val_loss": 39365.65246582031, "val_acc": 48.0}
{"epoch": 24, "training_loss": 151652.22119140625, "training_acc": 48.0, "val_loss": 19765.87677001953, "val_acc": 56.0}
{"epoch": 25, "training_loss": 73594.9833984375, "training_acc": 59.0, "val_loss": 16055.171203613281, "val_acc": 60.0}
{"epoch": 26, "training_loss": 94156.86181640625, "training_acc": 49.0, "val_loss": 24588.17596435547, "val_acc": 48.0}
{"epoch": 27, "training_loss": 102148.80004882812, "training_acc": 51.0, "val_loss": 32016.082763671875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 64068.2177734375, "training_acc": 56.0, "val_loss": 21431.866455078125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 64155.89123535156, "training_acc": 59.0, "val_loss": 48933.990478515625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 161425.904296875, "training_acc": 53.0, "val_loss": 15910.780334472656, "val_acc": 56.0}
{"epoch": 31, "training_loss": 103570.9443359375, "training_acc": 53.0, "val_loss": 51984.796142578125, "val_acc": 48.0}
{"epoch": 32, "training_loss": 156938.99084472656, "training_acc": 50.0, "val_loss": 64807.391357421875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 262056.921875, "training_acc": 53.0, "val_loss": 68389.0380859375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 139890.72192382812, "training_acc": 56.0, "val_loss": 76028.65600585938, "val_acc": 48.0}
{"epoch": 35, "training_loss": 354373.58203125, "training_acc": 47.0, "val_loss": 92824.5849609375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 283293.109375, "training_acc": 47.0, "val_loss": 69975.3173828125, "val_acc": 52.0}
{"epoch": 37, "training_loss": 299643.814453125, "training_acc": 53.0, "val_loss": 122176.84326171875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 386914.294921875, "training_acc": 53.0, "val_loss": 13803.225708007812, "val_acc": 56.0}
