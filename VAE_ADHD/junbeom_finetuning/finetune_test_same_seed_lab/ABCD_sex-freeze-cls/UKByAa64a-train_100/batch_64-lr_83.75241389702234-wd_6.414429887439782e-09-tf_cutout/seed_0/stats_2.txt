"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 138804.65226745605, "training_acc": 53.0, "val_loss": 7902.430725097656, "val_acc": 52.0}
{"epoch": 1, "training_loss": 179316.662109375, "training_acc": 49.0, "val_loss": 128682.43408203125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 478482.353515625, "training_acc": 47.0, "val_loss": 61069.7998046875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 158852.01300048828, "training_acc": 49.0, "val_loss": 38747.23205566406, "val_acc": 52.0}
{"epoch": 4, "training_loss": 159445.9990234375, "training_acc": 53.0, "val_loss": 34091.28112792969, "val_acc": 52.0}
{"epoch": 5, "training_loss": 97746.18615722656, "training_acc": 52.0, "val_loss": 35065.76843261719, "val_acc": 48.0}
{"epoch": 6, "training_loss": 156773.16552734375, "training_acc": 47.0, "val_loss": 47035.60791015625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 145812.2421875, "training_acc": 47.0, "val_loss": 12821.926879882812, "val_acc": 52.0}
{"epoch": 8, "training_loss": 75525.31103515625, "training_acc": 53.0, "val_loss": 30178.555297851562, "val_acc": 52.0}
{"epoch": 9, "training_loss": 98195.35229492188, "training_acc": 53.0, "val_loss": 9955.813598632812, "val_acc": 48.0}
{"epoch": 10, "training_loss": 47197.217041015625, "training_acc": 47.0, "val_loss": 18110.818481445312, "val_acc": 48.0}
{"epoch": 11, "training_loss": 40937.981018066406, "training_acc": 49.0, "val_loss": 20726.593017578125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 86884.79931640625, "training_acc": 53.0, "val_loss": 16596.11358642578, "val_acc": 52.0}
{"epoch": 13, "training_loss": 46899.218200683594, "training_acc": 52.0, "val_loss": 11648.197174072266, "val_acc": 48.0}
{"epoch": 14, "training_loss": 32248.479248046875, "training_acc": 47.0, "val_loss": 14764.219665527344, "val_acc": 52.0}
{"epoch": 15, "training_loss": 57831.84619140625, "training_acc": 53.0, "val_loss": 7626.314544677734, "val_acc": 52.0}
{"epoch": 16, "training_loss": 43263.445556640625, "training_acc": 47.0, "val_loss": 20521.206665039062, "val_acc": 48.0}
{"epoch": 17, "training_loss": 67767.07678222656, "training_acc": 48.0, "val_loss": 12137.353515625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 48152.288818359375, "training_acc": 53.0, "val_loss": 13768.617248535156, "val_acc": 52.0}
{"epoch": 19, "training_loss": 34109.962890625, "training_acc": 52.0, "val_loss": 9180.187225341797, "val_acc": 48.0}
{"epoch": 20, "training_loss": 35338.321380615234, "training_acc": 55.0, "val_loss": 8935.041046142578, "val_acc": 52.0}
{"epoch": 21, "training_loss": 23702.40692138672, "training_acc": 58.0, "val_loss": 1560.22367477417, "val_acc": 52.0}
{"epoch": 22, "training_loss": 10069.192321777344, "training_acc": 63.0, "val_loss": 2736.5413665771484, "val_acc": 68.0}
{"epoch": 23, "training_loss": 16356.114196777344, "training_acc": 55.0, "val_loss": 1881.8920135498047, "val_acc": 56.0}
{"epoch": 24, "training_loss": 10519.369445800781, "training_acc": 57.0, "val_loss": 2012.932014465332, "val_acc": 52.0}
{"epoch": 25, "training_loss": 7357.851654052734, "training_acc": 65.0, "val_loss": 4552.157211303711, "val_acc": 60.0}
{"epoch": 26, "training_loss": 13829.232879638672, "training_acc": 52.0, "val_loss": 3673.740005493164, "val_acc": 60.0}
{"epoch": 27, "training_loss": 7380.828842163086, "training_acc": 66.0, "val_loss": 3717.87109375, "val_acc": 44.0}
{"epoch": 28, "training_loss": 21498.03515625, "training_acc": 41.0, "val_loss": 2805.8929443359375, "val_acc": 60.0}
{"epoch": 29, "training_loss": 22843.847412109375, "training_acc": 55.0, "val_loss": 3728.7803649902344, "val_acc": 44.0}
{"epoch": 30, "training_loss": 23637.403564453125, "training_acc": 56.0, "val_loss": 21087.43133544922, "val_acc": 52.0}
{"epoch": 31, "training_loss": 60830.25537109375, "training_acc": 53.0, "val_loss": 5902.094650268555, "val_acc": 48.0}
{"epoch": 32, "training_loss": 34226.48156738281, "training_acc": 47.0, "val_loss": 1381.9844245910645, "val_acc": 64.0}
{"epoch": 33, "training_loss": 21142.870239257812, "training_acc": 61.0, "val_loss": 15446.113586425781, "val_acc": 52.0}
{"epoch": 34, "training_loss": 42107.95349121094, "training_acc": 46.0, "val_loss": 5658.017349243164, "val_acc": 48.0}
{"epoch": 35, "training_loss": 21350.778762817383, "training_acc": 55.0, "val_loss": 4718.010711669922, "val_acc": 56.0}
{"epoch": 36, "training_loss": 12119.968444824219, "training_acc": 51.0, "val_loss": 5099.381637573242, "val_acc": 52.0}
{"epoch": 37, "training_loss": 10672.890823364258, "training_acc": 51.0, "val_loss": 8290.601348876953, "val_acc": 52.0}
{"epoch": 38, "training_loss": 16318.390937805176, "training_acc": 55.0, "val_loss": 5917.67578125, "val_acc": 44.0}
{"epoch": 39, "training_loss": 19342.28564453125, "training_acc": 48.0, "val_loss": 1888.6661529541016, "val_acc": 56.0}
{"epoch": 40, "training_loss": 4241.584930419922, "training_acc": 68.0, "val_loss": 2937.4792098999023, "val_acc": 56.0}
{"epoch": 41, "training_loss": 3893.0785751342773, "training_acc": 69.0, "val_loss": 3225.8621215820312, "val_acc": 60.0}
{"epoch": 42, "training_loss": 8065.462219238281, "training_acc": 61.0, "val_loss": 5812.923049926758, "val_acc": 52.0}
{"epoch": 43, "training_loss": 8325.450454711914, "training_acc": 60.0, "val_loss": 1270.5052375793457, "val_acc": 60.0}
{"epoch": 44, "training_loss": 5192.8214111328125, "training_acc": 68.0, "val_loss": 3085.4326248168945, "val_acc": 40.0}
{"epoch": 45, "training_loss": 14789.75375366211, "training_acc": 53.0, "val_loss": 1831.5847396850586, "val_acc": 56.0}
{"epoch": 46, "training_loss": 2800.141761779785, "training_acc": 73.0, "val_loss": 3331.2244415283203, "val_acc": 60.0}
{"epoch": 47, "training_loss": 7438.654296875, "training_acc": 63.0, "val_loss": 2316.603660583496, "val_acc": 52.0}
{"epoch": 48, "training_loss": 4597.736587524414, "training_acc": 68.0, "val_loss": 6399.507522583008, "val_acc": 44.0}
{"epoch": 49, "training_loss": 14049.42225265503, "training_acc": 60.0, "val_loss": 8446.007537841797, "val_acc": 52.0}
{"epoch": 50, "training_loss": 13787.17851638794, "training_acc": 61.0, "val_loss": 9228.972625732422, "val_acc": 48.0}
{"epoch": 51, "training_loss": 26140.21270751953, "training_acc": 48.0, "val_loss": 16791.1376953125, "val_acc": 52.0}
{"epoch": 52, "training_loss": 68587.6923828125, "training_acc": 53.0, "val_loss": 12735.24169921875, "val_acc": 52.0}
{"epoch": 53, "training_loss": 45408.784912109375, "training_acc": 47.0, "val_loss": 17217.250061035156, "val_acc": 48.0}
{"epoch": 54, "training_loss": 49047.59094238281, "training_acc": 47.0, "val_loss": 19334.976196289062, "val_acc": 52.0}
{"epoch": 55, "training_loss": 74357.27856445312, "training_acc": 53.0, "val_loss": 23654.214477539062, "val_acc": 52.0}
{"epoch": 56, "training_loss": 56456.2177734375, "training_acc": 53.0, "val_loss": 23837.762451171875, "val_acc": 48.0}
{"epoch": 57, "training_loss": 107342.67626953125, "training_acc": 47.0, "val_loss": 31583.428955078125, "val_acc": 48.0}
{"epoch": 58, "training_loss": 87429.12536621094, "training_acc": 47.0, "val_loss": 23240.838623046875, "val_acc": 52.0}
{"epoch": 59, "training_loss": 104881.40576171875, "training_acc": 53.0, "val_loss": 40280.74035644531, "val_acc": 52.0}
{"epoch": 60, "training_loss": 135950.09423828125, "training_acc": 53.0, "val_loss": 5765.6005859375, "val_acc": 52.0}
{"epoch": 61, "training_loss": 43859.795166015625, "training_acc": 60.0, "val_loss": 41388.89465332031, "val_acc": 48.0}
{"epoch": 62, "training_loss": 147040.7861328125, "training_acc": 47.0, "val_loss": 18485.72540283203, "val_acc": 48.0}
