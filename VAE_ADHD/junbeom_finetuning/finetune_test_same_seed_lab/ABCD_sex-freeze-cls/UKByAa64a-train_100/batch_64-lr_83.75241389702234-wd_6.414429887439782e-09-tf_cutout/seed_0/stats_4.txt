"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 160162.46102523804, "training_acc": 50.0, "val_loss": 29408.6669921875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 204655.2666015625, "training_acc": 47.0, "val_loss": 97381.3232421875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 360082.169921875, "training_acc": 47.0, "val_loss": 25497.169494628906, "val_acc": 48.0}
{"epoch": 3, "training_loss": 121865.84228515625, "training_acc": 49.0, "val_loss": 69174.95727539062, "val_acc": 52.0}
{"epoch": 4, "training_loss": 286165.8251953125, "training_acc": 53.0, "val_loss": 63745.5322265625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 199463.81298828125, "training_acc": 53.0, "val_loss": 7681.524658203125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 70710.8623046875, "training_acc": 47.0, "val_loss": 28490.725708007812, "val_acc": 48.0}
{"epoch": 7, "training_loss": 93562.900390625, "training_acc": 47.0, "val_loss": 22438.0859375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 103605.36962890625, "training_acc": 53.0, "val_loss": 34033.04748535156, "val_acc": 52.0}
{"epoch": 9, "training_loss": 104472.1171875, "training_acc": 53.0, "val_loss": 7269.004058837891, "val_acc": 48.0}
{"epoch": 10, "training_loss": 45813.501708984375, "training_acc": 48.0, "val_loss": 13117.503356933594, "val_acc": 48.0}
{"epoch": 11, "training_loss": 32021.921508789062, "training_acc": 54.0, "val_loss": 14505.461120605469, "val_acc": 52.0}
{"epoch": 12, "training_loss": 46144.30090332031, "training_acc": 53.0, "val_loss": 6308.707809448242, "val_acc": 52.0}
{"epoch": 13, "training_loss": 23892.07550048828, "training_acc": 48.0, "val_loss": 2117.884063720703, "val_acc": 56.0}
{"epoch": 14, "training_loss": 14170.673034667969, "training_acc": 56.0, "val_loss": 3678.6666870117188, "val_acc": 52.0}
{"epoch": 15, "training_loss": 16547.75665283203, "training_acc": 50.0, "val_loss": 5917.074203491211, "val_acc": 52.0}
{"epoch": 16, "training_loss": 21531.052154541016, "training_acc": 55.0, "val_loss": 2616.456413269043, "val_acc": 48.0}
{"epoch": 17, "training_loss": 15949.097961425781, "training_acc": 53.0, "val_loss": 2520.1189041137695, "val_acc": 56.0}
{"epoch": 18, "training_loss": 14622.2109375, "training_acc": 58.0, "val_loss": 1645.9768295288086, "val_acc": 64.0}
{"epoch": 19, "training_loss": 11341.125305175781, "training_acc": 62.0, "val_loss": 1668.9252853393555, "val_acc": 44.0}
{"epoch": 20, "training_loss": 7894.449432373047, "training_acc": 64.0, "val_loss": 7559.717559814453, "val_acc": 52.0}
{"epoch": 21, "training_loss": 19988.503814697266, "training_acc": 53.0, "val_loss": 12454.681396484375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 45832.29479980469, "training_acc": 47.0, "val_loss": 6091.41960144043, "val_acc": 52.0}
{"epoch": 23, "training_loss": 21873.051025390625, "training_acc": 53.0, "val_loss": 4726.902770996094, "val_acc": 48.0}
{"epoch": 24, "training_loss": 13451.73843383789, "training_acc": 51.0, "val_loss": 11686.577606201172, "val_acc": 52.0}
{"epoch": 25, "training_loss": 42354.17529296875, "training_acc": 53.0, "val_loss": 1726.0618209838867, "val_acc": 48.0}
{"epoch": 26, "training_loss": 17601.131469726562, "training_acc": 51.0, "val_loss": 4598.720932006836, "val_acc": 52.0}
{"epoch": 27, "training_loss": 12890.771118164062, "training_acc": 56.0, "val_loss": 6830.625152587891, "val_acc": 48.0}
{"epoch": 28, "training_loss": 18198.991989135742, "training_acc": 50.0, "val_loss": 14187.429809570312, "val_acc": 52.0}
{"epoch": 29, "training_loss": 51171.69873046875, "training_acc": 53.0, "val_loss": 4317.701721191406, "val_acc": 48.0}
{"epoch": 30, "training_loss": 35973.65625, "training_acc": 50.0, "val_loss": 20127.68096923828, "val_acc": 48.0}
{"epoch": 31, "training_loss": 62065.737060546875, "training_acc": 47.0, "val_loss": 17735.073852539062, "val_acc": 52.0}
{"epoch": 32, "training_loss": 80038.13037109375, "training_acc": 53.0, "val_loss": 26160.400390625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69266.03759765625, "training_acc": 53.0, "val_loss": 15305.580139160156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 73649.08422851562, "training_acc": 47.0, "val_loss": 21406.268310546875, "val_acc": 48.0}
{"epoch": 35, "training_loss": 58826.283203125, "training_acc": 54.0, "val_loss": 19440.505981445312, "val_acc": 52.0}
{"epoch": 36, "training_loss": 77039.47216796875, "training_acc": 53.0, "val_loss": 21856.15997314453, "val_acc": 52.0}
{"epoch": 37, "training_loss": 55773.09600830078, "training_acc": 56.0, "val_loss": 18697.499084472656, "val_acc": 48.0}
