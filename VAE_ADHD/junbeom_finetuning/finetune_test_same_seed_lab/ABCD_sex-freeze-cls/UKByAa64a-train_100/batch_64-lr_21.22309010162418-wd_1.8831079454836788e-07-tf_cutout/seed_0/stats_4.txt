"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 41746.89029312134, "training_acc": 47.0, "val_loss": 9837.149047851562, "val_acc": 52.0}
{"epoch": 1, "training_loss": 41039.148193359375, "training_acc": 57.0, "val_loss": 23064.190673828125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 87401.19653320312, "training_acc": 47.0, "val_loss": 4383.794784545898, "val_acc": 48.0}
{"epoch": 3, "training_loss": 31793.203735351562, "training_acc": 45.0, "val_loss": 19277.82745361328, "val_acc": 52.0}
{"epoch": 4, "training_loss": 75927.29809570312, "training_acc": 53.0, "val_loss": 16118.013000488281, "val_acc": 52.0}
{"epoch": 5, "training_loss": 49569.458923339844, "training_acc": 53.0, "val_loss": 4303.032302856445, "val_acc": 48.0}
{"epoch": 6, "training_loss": 29713.528930664062, "training_acc": 47.0, "val_loss": 10143.004608154297, "val_acc": 48.0}
{"epoch": 7, "training_loss": 37643.75994873047, "training_acc": 47.0, "val_loss": 2819.621467590332, "val_acc": 52.0}
{"epoch": 8, "training_loss": 13524.192504882812, "training_acc": 56.0, "val_loss": 6148.435974121094, "val_acc": 52.0}
{"epoch": 9, "training_loss": 17050.61541748047, "training_acc": 52.0, "val_loss": 4708.254623413086, "val_acc": 48.0}
{"epoch": 10, "training_loss": 21702.470703125, "training_acc": 47.0, "val_loss": 4345.705032348633, "val_acc": 48.0}
{"epoch": 11, "training_loss": 12222.70491027832, "training_acc": 53.0, "val_loss": 5471.21467590332, "val_acc": 52.0}
{"epoch": 12, "training_loss": 19872.80389404297, "training_acc": 53.0, "val_loss": 3363.1114959716797, "val_acc": 52.0}
{"epoch": 13, "training_loss": 9984.703643798828, "training_acc": 55.0, "val_loss": 3520.547866821289, "val_acc": 48.0}
{"epoch": 14, "training_loss": 10375.51303100586, "training_acc": 49.0, "val_loss": 3046.531867980957, "val_acc": 52.0}
{"epoch": 15, "training_loss": 11693.707214355469, "training_acc": 53.0, "val_loss": 445.1751232147217, "val_acc": 56.0}
{"epoch": 16, "training_loss": 3588.5166015625, "training_acc": 60.0, "val_loss": 1460.3290557861328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 8805.435485839844, "training_acc": 43.0, "val_loss": 1836.2367630004883, "val_acc": 52.0}
{"epoch": 18, "training_loss": 5345.512268066406, "training_acc": 57.0, "val_loss": 2044.5917129516602, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6113.533950805664, "training_acc": 59.0, "val_loss": 2733.126640319824, "val_acc": 52.0}
{"epoch": 20, "training_loss": 9136.641296386719, "training_acc": 53.0, "val_loss": 2893.3263778686523, "val_acc": 48.0}
{"epoch": 21, "training_loss": 11553.683654785156, "training_acc": 47.0, "val_loss": 396.4374542236328, "val_acc": 44.0}
{"epoch": 22, "training_loss": 6599.846435546875, "training_acc": 60.0, "val_loss": 2827.52685546875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 9152.172119140625, "training_acc": 48.0, "val_loss": 1273.159122467041, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4575.745620727539, "training_acc": 54.0, "val_loss": 1449.1965293884277, "val_acc": 52.0}
{"epoch": 25, "training_loss": 5371.652404785156, "training_acc": 55.0, "val_loss": 919.007396697998, "val_acc": 48.0}
{"epoch": 26, "training_loss": 6434.934631347656, "training_acc": 42.0, "val_loss": 2103.229522705078, "val_acc": 52.0}
{"epoch": 27, "training_loss": 6048.041275024414, "training_acc": 56.0, "val_loss": 1469.822597503662, "val_acc": 48.0}
{"epoch": 28, "training_loss": 4839.656448364258, "training_acc": 55.0, "val_loss": 1850.592041015625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 4882.552703857422, "training_acc": 56.0, "val_loss": 766.3502216339111, "val_acc": 44.0}
{"epoch": 30, "training_loss": 3756.5472259521484, "training_acc": 57.0, "val_loss": 1262.2414588928223, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3827.6763610839844, "training_acc": 62.0, "val_loss": 1560.208797454834, "val_acc": 48.0}
{"epoch": 32, "training_loss": 5696.902389526367, "training_acc": 49.0, "val_loss": 2225.322151184082, "val_acc": 52.0}
{"epoch": 33, "training_loss": 6886.428970336914, "training_acc": 48.0, "val_loss": 887.0122909545898, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4465.251373291016, "training_acc": 57.0, "val_loss": 1918.505859375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 4738.116676330566, "training_acc": 65.0, "val_loss": 1900.0616073608398, "val_acc": 48.0}
{"epoch": 36, "training_loss": 4234.86608505249, "training_acc": 58.0, "val_loss": 1193.1663513183594, "val_acc": 52.0}
{"epoch": 37, "training_loss": 3751.79386138916, "training_acc": 60.0, "val_loss": 404.76274490356445, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2405.1658477783203, "training_acc": 60.0, "val_loss": 318.5454845428467, "val_acc": 68.0}
{"epoch": 39, "training_loss": 2358.363723754883, "training_acc": 58.0, "val_loss": 956.4628601074219, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2577.8110275268555, "training_acc": 59.0, "val_loss": 1528.2255172729492, "val_acc": 48.0}
{"epoch": 41, "training_loss": 3911.389492034912, "training_acc": 58.0, "val_loss": 1469.780445098877, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3762.0544204711914, "training_acc": 54.0, "val_loss": 356.86028003692627, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2000.6140747070312, "training_acc": 63.0, "val_loss": 452.80566215515137, "val_acc": 56.0}
{"epoch": 44, "training_loss": 4112.876861572266, "training_acc": 63.0, "val_loss": 1752.2830963134766, "val_acc": 48.0}
{"epoch": 45, "training_loss": 7758.023620605469, "training_acc": 47.0, "val_loss": 3486.6424560546875, "val_acc": 52.0}
{"epoch": 46, "training_loss": 8868.46203994751, "training_acc": 57.0, "val_loss": 4334.673690795898, "val_acc": 48.0}
{"epoch": 47, "training_loss": 16185.867431640625, "training_acc": 47.0, "val_loss": 1125.2089500427246, "val_acc": 48.0}
{"epoch": 48, "training_loss": 7065.003479003906, "training_acc": 58.0, "val_loss": 7228.765106201172, "val_acc": 52.0}
{"epoch": 49, "training_loss": 25888.505737304688, "training_acc": 53.0, "val_loss": 1941.823959350586, "val_acc": 52.0}
{"epoch": 50, "training_loss": 11790.719299316406, "training_acc": 51.0, "val_loss": 8413.602447509766, "val_acc": 48.0}
{"epoch": 51, "training_loss": 30215.030517578125, "training_acc": 47.0, "val_loss": 1654.013442993164, "val_acc": 48.0}
{"epoch": 52, "training_loss": 10041.027893066406, "training_acc": 55.0, "val_loss": 10300.276947021484, "val_acc": 52.0}
{"epoch": 53, "training_loss": 39186.29150390625, "training_acc": 53.0, "val_loss": 7715.8782958984375, "val_acc": 52.0}
{"epoch": 54, "training_loss": 21741.333465576172, "training_acc": 53.0, "val_loss": 6640.773010253906, "val_acc": 48.0}
{"epoch": 55, "training_loss": 28135.590942382812, "training_acc": 47.0, "val_loss": 10362.060546875, "val_acc": 48.0}
{"epoch": 56, "training_loss": 35198.858947753906, "training_acc": 47.0, "val_loss": 937.9559516906738, "val_acc": 56.0}
{"epoch": 57, "training_loss": 6965.795471191406, "training_acc": 57.0, "val_loss": 3580.0804138183594, "val_acc": 52.0}
