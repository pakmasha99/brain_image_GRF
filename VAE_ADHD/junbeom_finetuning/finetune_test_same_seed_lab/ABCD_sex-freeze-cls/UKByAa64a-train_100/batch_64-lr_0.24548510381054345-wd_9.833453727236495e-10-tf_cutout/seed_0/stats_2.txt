"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 510.9059944152832, "training_acc": 52.0, "val_loss": 108.20186138153076, "val_acc": 52.0}
{"epoch": 1, "training_loss": 490.72600173950195, "training_acc": 57.0, "val_loss": 283.05675983428955, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1036.5988864898682, "training_acc": 47.0, "val_loss": 59.57984924316406, "val_acc": 48.0}
{"epoch": 3, "training_loss": 410.6985740661621, "training_acc": 41.0, "val_loss": 216.05451107025146, "val_acc": 52.0}
{"epoch": 4, "training_loss": 853.1116828918457, "training_acc": 53.0, "val_loss": 172.49730825424194, "val_acc": 52.0}
{"epoch": 5, "training_loss": 524.4194793701172, "training_acc": 53.0, "val_loss": 66.60938262939453, "val_acc": 48.0}
{"epoch": 6, "training_loss": 358.5178279876709, "training_acc": 47.0, "val_loss": 140.91918468475342, "val_acc": 48.0}
{"epoch": 7, "training_loss": 475.5960102081299, "training_acc": 47.0, "val_loss": 18.484388291835785, "val_acc": 52.0}
{"epoch": 8, "training_loss": 172.4254732131958, "training_acc": 56.0, "val_loss": 109.24012660980225, "val_acc": 52.0}
{"epoch": 9, "training_loss": 403.06936836242676, "training_acc": 53.0, "val_loss": 37.517234683036804, "val_acc": 52.0}
{"epoch": 10, "training_loss": 152.93253326416016, "training_acc": 52.0, "val_loss": 96.31531834602356, "val_acc": 48.0}
{"epoch": 11, "training_loss": 340.12353324890137, "training_acc": 47.0, "val_loss": 32.211533188819885, "val_acc": 48.0}
{"epoch": 12, "training_loss": 131.9404101371765, "training_acc": 52.0, "val_loss": 81.138676404953, "val_acc": 52.0}
{"epoch": 13, "training_loss": 298.9628391265869, "training_acc": 53.0, "val_loss": 29.086744785308838, "val_acc": 52.0}
{"epoch": 14, "training_loss": 117.99249839782715, "training_acc": 58.0, "val_loss": 68.61671805381775, "val_acc": 48.0}
{"epoch": 15, "training_loss": 219.4613480567932, "training_acc": 46.0, "val_loss": 20.187439024448395, "val_acc": 52.0}
{"epoch": 16, "training_loss": 119.18642377853394, "training_acc": 62.0, "val_loss": 44.84419226646423, "val_acc": 52.0}
{"epoch": 17, "training_loss": 135.58123803138733, "training_acc": 54.0, "val_loss": 41.815683245658875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 155.6448860168457, "training_acc": 51.0, "val_loss": 21.771173179149628, "val_acc": 52.0}
{"epoch": 19, "training_loss": 114.60315704345703, "training_acc": 44.0, "val_loss": 40.74512422084808, "val_acc": 52.0}
{"epoch": 20, "training_loss": 132.5394480228424, "training_acc": 54.0, "val_loss": 29.74027991294861, "val_acc": 48.0}
{"epoch": 21, "training_loss": 135.47155952453613, "training_acc": 47.0, "val_loss": 19.254501163959503, "val_acc": 52.0}
{"epoch": 22, "training_loss": 111.22003221511841, "training_acc": 55.0, "val_loss": 31.82910978794098, "val_acc": 52.0}
{"epoch": 23, "training_loss": 98.90915775299072, "training_acc": 53.0, "val_loss": 27.335983514785767, "val_acc": 44.0}
{"epoch": 24, "training_loss": 108.66906476020813, "training_acc": 50.0, "val_loss": 32.45415389537811, "val_acc": 52.0}
{"epoch": 25, "training_loss": 101.14807105064392, "training_acc": 53.0, "val_loss": 16.867010295391083, "val_acc": 52.0}
{"epoch": 26, "training_loss": 84.02335691452026, "training_acc": 58.0, "val_loss": 16.666564345359802, "val_acc": 52.0}
{"epoch": 27, "training_loss": 73.90304899215698, "training_acc": 54.0, "val_loss": 29.701098799705505, "val_acc": 52.0}
{"epoch": 28, "training_loss": 89.92617845535278, "training_acc": 56.0, "val_loss": 20.039884746074677, "val_acc": 56.0}
{"epoch": 29, "training_loss": 71.70162892341614, "training_acc": 53.0, "val_loss": 28.117486834526062, "val_acc": 52.0}
{"epoch": 30, "training_loss": 96.76570892333984, "training_acc": 52.0, "val_loss": 17.943869531154633, "val_acc": 52.0}
{"epoch": 31, "training_loss": 86.44568109512329, "training_acc": 54.0, "val_loss": 17.04588234424591, "val_acc": 56.0}
{"epoch": 32, "training_loss": 76.08846139907837, "training_acc": 67.0, "val_loss": 22.55329042673111, "val_acc": 52.0}
{"epoch": 33, "training_loss": 74.06990146636963, "training_acc": 57.0, "val_loss": 22.273758053779602, "val_acc": 56.0}
{"epoch": 34, "training_loss": 70.53762745857239, "training_acc": 59.0, "val_loss": 33.42929780483246, "val_acc": 52.0}
{"epoch": 35, "training_loss": 99.92034101486206, "training_acc": 53.0, "val_loss": 19.67470943927765, "val_acc": 60.0}
{"epoch": 36, "training_loss": 89.64327907562256, "training_acc": 49.0, "val_loss": 19.7381392121315, "val_acc": 52.0}
{"epoch": 37, "training_loss": 81.85038328170776, "training_acc": 56.0, "val_loss": 18.221086263656616, "val_acc": 56.0}
{"epoch": 38, "training_loss": 72.58402180671692, "training_acc": 58.0, "val_loss": 17.419131100177765, "val_acc": 56.0}
{"epoch": 39, "training_loss": 72.767746925354, "training_acc": 55.0, "val_loss": 22.987817227840424, "val_acc": 52.0}
{"epoch": 40, "training_loss": 70.80144333839417, "training_acc": 58.0, "val_loss": 21.05540782213211, "val_acc": 52.0}
{"epoch": 41, "training_loss": 71.98169326782227, "training_acc": 57.0, "val_loss": 27.941370010375977, "val_acc": 52.0}
{"epoch": 42, "training_loss": 86.82372379302979, "training_acc": 53.0, "val_loss": 26.153388619422913, "val_acc": 48.0}
{"epoch": 43, "training_loss": 92.06148886680603, "training_acc": 49.0, "val_loss": 18.940484523773193, "val_acc": 52.0}
{"epoch": 44, "training_loss": 66.17467904090881, "training_acc": 57.0, "val_loss": 17.70533323287964, "val_acc": 56.0}
{"epoch": 45, "training_loss": 64.01782155036926, "training_acc": 60.0, "val_loss": 17.71525889635086, "val_acc": 56.0}
