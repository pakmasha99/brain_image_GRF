"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 504.1098976135254, "training_acc": 51.0, "val_loss": 120.4994797706604, "val_acc": 52.0}
{"epoch": 1, "training_loss": 535.4590473175049, "training_acc": 53.0, "val_loss": 250.35240650177002, "val_acc": 48.0}
{"epoch": 2, "training_loss": 907.0388069152832, "training_acc": 47.0, "val_loss": 29.2624831199646, "val_acc": 48.0}
{"epoch": 3, "training_loss": 303.51864433288574, "training_acc": 49.0, "val_loss": 240.42646884918213, "val_acc": 52.0}
{"epoch": 4, "training_loss": 930.5087203979492, "training_acc": 53.0, "val_loss": 200.55267810821533, "val_acc": 52.0}
{"epoch": 5, "training_loss": 643.1661739349365, "training_acc": 53.0, "val_loss": 33.0036997795105, "val_acc": 48.0}
{"epoch": 6, "training_loss": 215.4908037185669, "training_acc": 47.0, "val_loss": 108.89633893966675, "val_acc": 48.0}
{"epoch": 7, "training_loss": 345.3296642303467, "training_acc": 47.0, "val_loss": 32.81959593296051, "val_acc": 52.0}
{"epoch": 8, "training_loss": 179.6514892578125, "training_acc": 53.0, "val_loss": 73.96796345710754, "val_acc": 52.0}
{"epoch": 9, "training_loss": 245.63476514816284, "training_acc": 53.0, "val_loss": 42.77680218219757, "val_acc": 48.0}
{"epoch": 10, "training_loss": 187.65049648284912, "training_acc": 47.0, "val_loss": 45.23851275444031, "val_acc": 48.0}
{"epoch": 11, "training_loss": 135.92564249038696, "training_acc": 48.0, "val_loss": 44.903987646102905, "val_acc": 52.0}
{"epoch": 12, "training_loss": 171.9790768623352, "training_acc": 53.0, "val_loss": 22.722768783569336, "val_acc": 52.0}
{"epoch": 13, "training_loss": 125.07148933410645, "training_acc": 54.0, "val_loss": 26.454970240592957, "val_acc": 52.0}
{"epoch": 14, "training_loss": 104.18640446662903, "training_acc": 46.0, "val_loss": 41.74603521823883, "val_acc": 52.0}
{"epoch": 15, "training_loss": 133.49574375152588, "training_acc": 51.0, "val_loss": 26.60701870918274, "val_acc": 48.0}
{"epoch": 16, "training_loss": 121.17804098129272, "training_acc": 46.0, "val_loss": 17.722873389720917, "val_acc": 56.0}
{"epoch": 17, "training_loss": 79.23365688323975, "training_acc": 59.0, "val_loss": 28.40898334980011, "val_acc": 52.0}
{"epoch": 18, "training_loss": 82.20903325080872, "training_acc": 52.0, "val_loss": 25.042912364006042, "val_acc": 48.0}
{"epoch": 19, "training_loss": 91.21782875061035, "training_acc": 53.0, "val_loss": 27.310845255851746, "val_acc": 52.0}
{"epoch": 20, "training_loss": 81.89899444580078, "training_acc": 54.0, "val_loss": 20.225924253463745, "val_acc": 44.0}
{"epoch": 21, "training_loss": 82.72698712348938, "training_acc": 50.0, "val_loss": 20.214375853538513, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72.59714245796204, "training_acc": 56.0, "val_loss": 18.28039437532425, "val_acc": 56.0}
{"epoch": 23, "training_loss": 66.72821879386902, "training_acc": 64.0, "val_loss": 18.72655302286148, "val_acc": 40.0}
{"epoch": 24, "training_loss": 83.07394051551819, "training_acc": 51.0, "val_loss": 19.316011667251587, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65.26471042633057, "training_acc": 55.0, "val_loss": 19.30219978094101, "val_acc": 40.0}
{"epoch": 26, "training_loss": 60.30397295951843, "training_acc": 57.0, "val_loss": 25.76538920402527, "val_acc": 52.0}
{"epoch": 27, "training_loss": 78.67965316772461, "training_acc": 61.0, "val_loss": 21.95870131254196, "val_acc": 40.0}
{"epoch": 28, "training_loss": 75.26869297027588, "training_acc": 50.0, "val_loss": 20.43875902891159, "val_acc": 52.0}
{"epoch": 29, "training_loss": 81.91434478759766, "training_acc": 52.0, "val_loss": 22.86992520093918, "val_acc": 44.0}
{"epoch": 30, "training_loss": 87.16487908363342, "training_acc": 49.0, "val_loss": 21.303942799568176, "val_acc": 52.0}
{"epoch": 31, "training_loss": 72.79407477378845, "training_acc": 54.0, "val_loss": 17.64928847551346, "val_acc": 68.0}
{"epoch": 32, "training_loss": 74.22132110595703, "training_acc": 57.0, "val_loss": 22.653120756149292, "val_acc": 52.0}
{"epoch": 33, "training_loss": 79.0653760433197, "training_acc": 51.0, "val_loss": 17.309817671775818, "val_acc": 68.0}
{"epoch": 34, "training_loss": 72.20591306686401, "training_acc": 61.0, "val_loss": 18.810446560382843, "val_acc": 52.0}
{"epoch": 35, "training_loss": 72.88812160491943, "training_acc": 51.0, "val_loss": 17.449674010276794, "val_acc": 68.0}
{"epoch": 36, "training_loss": 63.75666356086731, "training_acc": 63.0, "val_loss": 17.31376200914383, "val_acc": 64.0}
{"epoch": 37, "training_loss": 65.11142778396606, "training_acc": 63.0, "val_loss": 17.617620527744293, "val_acc": 52.0}
{"epoch": 38, "training_loss": 61.23701596260071, "training_acc": 64.0, "val_loss": 17.54976063966751, "val_acc": 64.0}
{"epoch": 39, "training_loss": 60.59080410003662, "training_acc": 64.0, "val_loss": 18.18852126598358, "val_acc": 56.0}
{"epoch": 40, "training_loss": 65.15850162506104, "training_acc": 67.0, "val_loss": 18.479716777801514, "val_acc": 48.0}
{"epoch": 41, "training_loss": 66.25671696662903, "training_acc": 55.0, "val_loss": 17.549113929271698, "val_acc": 56.0}
{"epoch": 42, "training_loss": 63.08594083786011, "training_acc": 64.0, "val_loss": 17.14867204427719, "val_acc": 60.0}
{"epoch": 43, "training_loss": 61.1869010925293, "training_acc": 66.0, "val_loss": 18.116895854473114, "val_acc": 52.0}
{"epoch": 44, "training_loss": 61.161487340927124, "training_acc": 67.0, "val_loss": 16.937431693077087, "val_acc": 68.0}
{"epoch": 45, "training_loss": 56.57946038246155, "training_acc": 74.0, "val_loss": 20.168006420135498, "val_acc": 52.0}
{"epoch": 46, "training_loss": 63.91380834579468, "training_acc": 61.0, "val_loss": 25.397607684135437, "val_acc": 48.0}
{"epoch": 47, "training_loss": 83.13237261772156, "training_acc": 56.0, "val_loss": 26.847374439239502, "val_acc": 52.0}
{"epoch": 48, "training_loss": 74.35858154296875, "training_acc": 62.0, "val_loss": 20.81424444913864, "val_acc": 44.0}
{"epoch": 49, "training_loss": 76.45179295539856, "training_acc": 53.0, "val_loss": 20.166420936584473, "val_acc": 52.0}
{"epoch": 50, "training_loss": 62.96614408493042, "training_acc": 62.0, "val_loss": 16.59122109413147, "val_acc": 68.0}
{"epoch": 51, "training_loss": 57.66100239753723, "training_acc": 74.0, "val_loss": 21.47005945444107, "val_acc": 52.0}
{"epoch": 52, "training_loss": 65.8288996219635, "training_acc": 62.0, "val_loss": 18.206264078617096, "val_acc": 52.0}
{"epoch": 53, "training_loss": 62.249289751052856, "training_acc": 57.0, "val_loss": 19.07304674386978, "val_acc": 52.0}
{"epoch": 54, "training_loss": 67.06201601028442, "training_acc": 53.0, "val_loss": 16.699157655239105, "val_acc": 60.0}
{"epoch": 55, "training_loss": 58.36533713340759, "training_acc": 76.0, "val_loss": 16.648538410663605, "val_acc": 64.0}
{"epoch": 56, "training_loss": 63.45118761062622, "training_acc": 68.0, "val_loss": 19.951653480529785, "val_acc": 52.0}
{"epoch": 57, "training_loss": 63.337525606155396, "training_acc": 59.0, "val_loss": 17.639078199863434, "val_acc": 48.0}
{"epoch": 58, "training_loss": 64.46681141853333, "training_acc": 57.0, "val_loss": 17.465366423130035, "val_acc": 56.0}
{"epoch": 59, "training_loss": 55.71460700035095, "training_acc": 72.0, "val_loss": 20.484769344329834, "val_acc": 40.0}
{"epoch": 60, "training_loss": 72.10840225219727, "training_acc": 56.0, "val_loss": 23.03543984889984, "val_acc": 52.0}
{"epoch": 61, "training_loss": 62.755879402160645, "training_acc": 64.0, "val_loss": 16.38593226671219, "val_acc": 68.0}
{"epoch": 62, "training_loss": 56.069634437561035, "training_acc": 70.0, "val_loss": 25.54807960987091, "val_acc": 52.0}
{"epoch": 63, "training_loss": 81.18410110473633, "training_acc": 50.0, "val_loss": 16.36708825826645, "val_acc": 64.0}
{"epoch": 64, "training_loss": 62.52811026573181, "training_acc": 67.0, "val_loss": 17.501139640808105, "val_acc": 52.0}
{"epoch": 65, "training_loss": 59.96906781196594, "training_acc": 63.0, "val_loss": 21.618980169296265, "val_acc": 52.0}
{"epoch": 66, "training_loss": 61.1275897026062, "training_acc": 64.0, "val_loss": 17.599602043628693, "val_acc": 52.0}
{"epoch": 67, "training_loss": 54.22361361980438, "training_acc": 73.0, "val_loss": 21.168014407157898, "val_acc": 52.0}
{"epoch": 68, "training_loss": 61.63312268257141, "training_acc": 61.0, "val_loss": 16.492076218128204, "val_acc": 68.0}
{"epoch": 69, "training_loss": 52.43853259086609, "training_acc": 76.0, "val_loss": 22.486430406570435, "val_acc": 52.0}
{"epoch": 70, "training_loss": 59.42122220993042, "training_acc": 63.0, "val_loss": 24.885539710521698, "val_acc": 48.0}
{"epoch": 71, "training_loss": 76.3923020362854, "training_acc": 59.0, "val_loss": 29.098963737487793, "val_acc": 52.0}
{"epoch": 72, "training_loss": 78.06566643714905, "training_acc": 61.0, "val_loss": 30.798503756523132, "val_acc": 48.0}
{"epoch": 73, "training_loss": 93.27748131752014, "training_acc": 55.0, "val_loss": 29.758399724960327, "val_acc": 52.0}
{"epoch": 74, "training_loss": 73.81573152542114, "training_acc": 60.0, "val_loss": 22.706927359104156, "val_acc": 40.0}
{"epoch": 75, "training_loss": 72.53897285461426, "training_acc": 61.0, "val_loss": 33.71226489543915, "val_acc": 52.0}
{"epoch": 76, "training_loss": 87.59222388267517, "training_acc": 54.0, "val_loss": 37.28860318660736, "val_acc": 48.0}
{"epoch": 77, "training_loss": 137.02561902999878, "training_acc": 47.0, "val_loss": 40.76149761676788, "val_acc": 52.0}
{"epoch": 78, "training_loss": 134.07738733291626, "training_acc": 52.0, "val_loss": 17.192915081977844, "val_acc": 68.0}
{"epoch": 79, "training_loss": 77.38299465179443, "training_acc": 66.0, "val_loss": 19.333727657794952, "val_acc": 56.0}
{"epoch": 80, "training_loss": 104.02758741378784, "training_acc": 50.0, "val_loss": 29.25657033920288, "val_acc": 52.0}
{"epoch": 81, "training_loss": 125.28619337081909, "training_acc": 46.0, "val_loss": 29.149505496025085, "val_acc": 48.0}
{"epoch": 82, "training_loss": 84.52128076553345, "training_acc": 53.0, "val_loss": 41.06194078922272, "val_acc": 52.0}
