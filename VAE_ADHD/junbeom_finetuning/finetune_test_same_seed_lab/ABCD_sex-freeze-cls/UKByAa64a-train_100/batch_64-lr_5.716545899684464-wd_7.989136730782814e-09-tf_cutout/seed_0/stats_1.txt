"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 12050.605030059814, "training_acc": 46.0, "val_loss": 2509.4655990600586, "val_acc": 52.0}
{"epoch": 1, "training_loss": 12186.543151855469, "training_acc": 53.0, "val_loss": 6499.353790283203, "val_acc": 48.0}
{"epoch": 2, "training_loss": 24460.02374267578, "training_acc": 47.0, "val_loss": 1801.6904830932617, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8523.05435180664, "training_acc": 51.0, "val_loss": 4746.349334716797, "val_acc": 52.0}
{"epoch": 4, "training_loss": 18033.30987548828, "training_acc": 53.0, "val_loss": 4235.296630859375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 12570.443267822266, "training_acc": 53.0, "val_loss": 736.0093593597412, "val_acc": 48.0}
{"epoch": 6, "training_loss": 6782.8179931640625, "training_acc": 47.0, "val_loss": 2169.4652557373047, "val_acc": 48.0}
{"epoch": 7, "training_loss": 7353.131256103516, "training_acc": 47.0, "val_loss": 1571.7795372009277, "val_acc": 52.0}
{"epoch": 8, "training_loss": 6129.286178588867, "training_acc": 53.0, "val_loss": 2725.489616394043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 8850.533386230469, "training_acc": 53.0, "val_loss": 343.5283660888672, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3573.3893127441406, "training_acc": 49.0, "val_loss": 2572.005271911621, "val_acc": 48.0}
{"epoch": 11, "training_loss": 9882.981048583984, "training_acc": 47.0, "val_loss": 607.3031902313232, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3588.0759887695312, "training_acc": 49.0, "val_loss": 2579.6512603759766, "val_acc": 52.0}
{"epoch": 13, "training_loss": 9888.951171875, "training_acc": 53.0, "val_loss": 1894.5436477661133, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4984.059162139893, "training_acc": 53.0, "val_loss": 1835.4421615600586, "val_acc": 48.0}
{"epoch": 15, "training_loss": 8724.718200683594, "training_acc": 47.0, "val_loss": 2357.1537017822266, "val_acc": 48.0}
{"epoch": 16, "training_loss": 7410.527587890625, "training_acc": 47.0, "val_loss": 1092.4434661865234, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5188.004486083984, "training_acc": 53.0, "val_loss": 2164.128875732422, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7144.440132141113, "training_acc": 53.0, "val_loss": 150.74032545089722, "val_acc": 40.0}
{"epoch": 19, "training_loss": 1623.5858306884766, "training_acc": 59.0, "val_loss": 853.6745071411133, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2880.7862548828125, "training_acc": 46.0, "val_loss": 660.8056545257568, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1355.5895977020264, "training_acc": 58.0, "val_loss": 764.1960144042969, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2920.5062408447266, "training_acc": 47.0, "val_loss": 485.97068786621094, "val_acc": 56.0}
{"epoch": 23, "training_loss": 1849.1866149902344, "training_acc": 58.0, "val_loss": 446.8627452850342, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1945.980941772461, "training_acc": 49.0, "val_loss": 842.144775390625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2112.0962677001953, "training_acc": 46.0, "val_loss": 962.1243476867676, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3022.8717041015625, "training_acc": 54.0, "val_loss": 184.3790888786316, "val_acc": 48.0}
{"epoch": 27, "training_loss": 805.4331398010254, "training_acc": 53.0, "val_loss": 232.0878028869629, "val_acc": 56.0}
{"epoch": 28, "training_loss": 840.4225578308105, "training_acc": 57.0, "val_loss": 213.32826614379883, "val_acc": 32.0}
{"epoch": 29, "training_loss": 1069.3843688964844, "training_acc": 55.0, "val_loss": 806.2996864318848, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2672.1259231567383, "training_acc": 53.0, "val_loss": 193.12516450881958, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1325.1468505859375, "training_acc": 61.0, "val_loss": 165.30402898788452, "val_acc": 32.0}
{"epoch": 32, "training_loss": 1784.1608581542969, "training_acc": 56.0, "val_loss": 1030.833339691162, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2281.0550804138184, "training_acc": 53.0, "val_loss": 1158.042812347412, "val_acc": 48.0}
{"epoch": 34, "training_loss": 5121.913116455078, "training_acc": 47.0, "val_loss": 676.2196063995361, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2816.4703216552734, "training_acc": 47.0, "val_loss": 1340.6935691833496, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3849.7917404174805, "training_acc": 54.0, "val_loss": 189.87209796905518, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1694.5773391723633, "training_acc": 49.0, "val_loss": 404.01225090026855, "val_acc": 56.0}
{"epoch": 38, "training_loss": 1195.0906944274902, "training_acc": 55.0, "val_loss": 115.87700843811035, "val_acc": 60.0}
{"epoch": 39, "training_loss": 809.222972869873, "training_acc": 56.0, "val_loss": 358.7353706359863, "val_acc": 56.0}
{"epoch": 40, "training_loss": 649.4031219482422, "training_acc": 61.0, "val_loss": 229.20355796813965, "val_acc": 48.0}
{"epoch": 41, "training_loss": 961.3326568603516, "training_acc": 53.0, "val_loss": 183.397376537323, "val_acc": 64.0}
{"epoch": 42, "training_loss": 1377.5940399169922, "training_acc": 52.0, "val_loss": 296.19548320770264, "val_acc": 52.0}
{"epoch": 43, "training_loss": 2225.4298248291016, "training_acc": 45.0, "val_loss": 953.0056953430176, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2453.5272941589355, "training_acc": 56.0, "val_loss": 1343.467903137207, "val_acc": 48.0}
{"epoch": 45, "training_loss": 5967.461608886719, "training_acc": 47.0, "val_loss": 1048.7885475158691, "val_acc": 48.0}
{"epoch": 46, "training_loss": 3982.48722076416, "training_acc": 41.0, "val_loss": 1138.3105278015137, "val_acc": 52.0}
{"epoch": 47, "training_loss": 3511.3774490356445, "training_acc": 53.0, "val_loss": 477.5199890136719, "val_acc": 48.0}
{"epoch": 48, "training_loss": 2383.379638671875, "training_acc": 46.0, "val_loss": 61.239707469940186, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1027.8771362304688, "training_acc": 70.0, "val_loss": 515.439510345459, "val_acc": 52.0}
{"epoch": 50, "training_loss": 2148.349624633789, "training_acc": 44.0, "val_loss": 349.38225746154785, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1466.762710571289, "training_acc": 55.0, "val_loss": 552.5938510894775, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1462.2811679840088, "training_acc": 54.0, "val_loss": 63.41975927352905, "val_acc": 60.0}
{"epoch": 53, "training_loss": 382.2579746246338, "training_acc": 66.0, "val_loss": 106.91401958465576, "val_acc": 68.0}
{"epoch": 54, "training_loss": 434.3545436859131, "training_acc": 67.0, "val_loss": 328.9243698120117, "val_acc": 56.0}
{"epoch": 55, "training_loss": 540.2893152236938, "training_acc": 65.0, "val_loss": 166.05796813964844, "val_acc": 48.0}
{"epoch": 56, "training_loss": 632.6439666748047, "training_acc": 59.0, "val_loss": 136.0689640045166, "val_acc": 64.0}
{"epoch": 57, "training_loss": 473.2457275390625, "training_acc": 65.0, "val_loss": 282.64334201812744, "val_acc": 56.0}
{"epoch": 58, "training_loss": 754.7436561584473, "training_acc": 53.0, "val_loss": 66.06386303901672, "val_acc": 64.0}
{"epoch": 59, "training_loss": 284.75391387939453, "training_acc": 74.0, "val_loss": 149.19344186782837, "val_acc": 64.0}
{"epoch": 60, "training_loss": 292.11907958984375, "training_acc": 74.0, "val_loss": 304.35118675231934, "val_acc": 48.0}
{"epoch": 61, "training_loss": 1035.1477241516113, "training_acc": 50.0, "val_loss": 111.39947175979614, "val_acc": 64.0}
{"epoch": 62, "training_loss": 475.2621955871582, "training_acc": 69.0, "val_loss": 293.15953254699707, "val_acc": 56.0}
{"epoch": 63, "training_loss": 600.4104442596436, "training_acc": 60.0, "val_loss": 44.087034463882446, "val_acc": 68.0}
{"epoch": 64, "training_loss": 590.5592308044434, "training_acc": 62.0, "val_loss": 121.56612873077393, "val_acc": 60.0}
{"epoch": 65, "training_loss": 584.895450592041, "training_acc": 64.0, "val_loss": 257.99896717071533, "val_acc": 52.0}
{"epoch": 66, "training_loss": 554.8659543991089, "training_acc": 57.0, "val_loss": 62.76158690452576, "val_acc": 68.0}
{"epoch": 67, "training_loss": 169.57587909698486, "training_acc": 77.0, "val_loss": 188.49587440490723, "val_acc": 56.0}
{"epoch": 68, "training_loss": 621.5437660217285, "training_acc": 56.0, "val_loss": 253.1975269317627, "val_acc": 52.0}
{"epoch": 69, "training_loss": 426.5024333000183, "training_acc": 66.0, "val_loss": 352.7130365371704, "val_acc": 48.0}
{"epoch": 70, "training_loss": 768.5387573242188, "training_acc": 64.0, "val_loss": 167.49976873397827, "val_acc": 60.0}
{"epoch": 71, "training_loss": 978.3796615600586, "training_acc": 51.0, "val_loss": 65.27010798454285, "val_acc": 68.0}
{"epoch": 72, "training_loss": 534.7388191223145, "training_acc": 67.0, "val_loss": 93.16911697387695, "val_acc": 48.0}
{"epoch": 73, "training_loss": 279.1046886444092, "training_acc": 74.0, "val_loss": 330.08673191070557, "val_acc": 52.0}
{"epoch": 74, "training_loss": 954.1392784118652, "training_acc": 47.0, "val_loss": 341.11530780792236, "val_acc": 52.0}
{"epoch": 75, "training_loss": 745.6879734992981, "training_acc": 61.0, "val_loss": 176.17651224136353, "val_acc": 52.0}
{"epoch": 76, "training_loss": 808.614559173584, "training_acc": 58.0, "val_loss": 169.86234188079834, "val_acc": 60.0}
{"epoch": 77, "training_loss": 905.756721496582, "training_acc": 64.0, "val_loss": 572.8404998779297, "val_acc": 48.0}
{"epoch": 78, "training_loss": 1710.6156005859375, "training_acc": 51.0, "val_loss": 618.9964294433594, "val_acc": 52.0}
{"epoch": 79, "training_loss": 1487.4757499694824, "training_acc": 56.0, "val_loss": 131.4336657524109, "val_acc": 44.0}
{"epoch": 80, "training_loss": 638.5585403442383, "training_acc": 64.0, "val_loss": 208.27767848968506, "val_acc": 60.0}
{"epoch": 81, "training_loss": 1164.5680847167969, "training_acc": 58.0, "val_loss": 531.8461894989014, "val_acc": 48.0}
{"epoch": 82, "training_loss": 1634.5320587158203, "training_acc": 53.0, "val_loss": 786.1502647399902, "val_acc": 52.0}
