"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 12323.62094116211, "training_acc": 47.0, "val_loss": 2908.925247192383, "val_acc": 52.0}
{"epoch": 1, "training_loss": 14314.754699707031, "training_acc": 47.0, "val_loss": 5419.093322753906, "val_acc": 48.0}
{"epoch": 2, "training_loss": 19696.18975830078, "training_acc": 47.0, "val_loss": 345.1939105987549, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6544.001708984375, "training_acc": 49.0, "val_loss": 5854.899215698242, "val_acc": 52.0}
{"epoch": 4, "training_loss": 22619.761596679688, "training_acc": 53.0, "val_loss": 5330.884170532227, "val_acc": 52.0}
{"epoch": 5, "training_loss": 17325.407104492188, "training_acc": 53.0, "val_loss": 574.0301609039307, "val_acc": 52.0}
{"epoch": 6, "training_loss": 5465.4754638671875, "training_acc": 52.0, "val_loss": 5067.215347290039, "val_acc": 48.0}
{"epoch": 7, "training_loss": 21656.508056640625, "training_acc": 47.0, "val_loss": 4735.351943969727, "val_acc": 48.0}
{"epoch": 8, "training_loss": 17261.26626586914, "training_acc": 47.0, "val_loss": 77.60992050170898, "val_acc": 60.0}
{"epoch": 9, "training_loss": 4902.244171142578, "training_acc": 56.0, "val_loss": 4395.9930419921875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 17215.06854248047, "training_acc": 53.0, "val_loss": 4369.647979736328, "val_acc": 52.0}
{"epoch": 11, "training_loss": 15017.07974243164, "training_acc": 53.0, "val_loss": 948.1743812561035, "val_acc": 52.0}
{"epoch": 12, "training_loss": 4515.615783691406, "training_acc": 53.0, "val_loss": 3375.213623046875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 13755.537200927734, "training_acc": 47.0, "val_loss": 2881.772232055664, "val_acc": 48.0}
{"epoch": 14, "training_loss": 8613.463882446289, "training_acc": 47.0, "val_loss": 1134.1997146606445, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5445.677001953125, "training_acc": 53.0, "val_loss": 2737.0912551879883, "val_acc": 52.0}
{"epoch": 16, "training_loss": 9821.996520996094, "training_acc": 53.0, "val_loss": 1009.645938873291, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3641.288619995117, "training_acc": 56.0, "val_loss": 2164.371109008789, "val_acc": 48.0}
{"epoch": 18, "training_loss": 8039.595275878906, "training_acc": 49.0, "val_loss": 1205.6859970092773, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2533.148941040039, "training_acc": 63.0, "val_loss": 1362.3053550720215, "val_acc": 52.0}
{"epoch": 20, "training_loss": 5213.855224609375, "training_acc": 53.0, "val_loss": 704.2325496673584, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3481.0006256103516, "training_acc": 45.0, "val_loss": 1307.4262619018555, "val_acc": 48.0}
{"epoch": 22, "training_loss": 4097.059295654297, "training_acc": 50.0, "val_loss": 715.5241012573242, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2577.5079650878906, "training_acc": 55.0, "val_loss": 831.8142890930176, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2109.448799133301, "training_acc": 54.0, "val_loss": 643.0088996887207, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1754.4766902923584, "training_acc": 53.0, "val_loss": 874.7689247131348, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2873.1638107299805, "training_acc": 53.0, "val_loss": 99.55369234085083, "val_acc": 48.0}
{"epoch": 27, "training_loss": 952.4696350097656, "training_acc": 65.0, "val_loss": 85.12223362922668, "val_acc": 52.0}
