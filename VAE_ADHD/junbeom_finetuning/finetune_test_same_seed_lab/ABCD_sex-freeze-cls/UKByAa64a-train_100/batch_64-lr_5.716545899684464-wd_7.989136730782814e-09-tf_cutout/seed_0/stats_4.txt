"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 13820.615001678467, "training_acc": 49.0, "val_loss": 2779.910659790039, "val_acc": 52.0}
{"epoch": 1, "training_loss": 13624.034484863281, "training_acc": 49.0, "val_loss": 5952.246475219727, "val_acc": 48.0}
{"epoch": 2, "training_loss": 21998.42547607422, "training_acc": 47.0, "val_loss": 1645.1824188232422, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7721.0079345703125, "training_acc": 49.0, "val_loss": 4427.396774291992, "val_acc": 52.0}
{"epoch": 4, "training_loss": 17458.395568847656, "training_acc": 53.0, "val_loss": 3700.4268646240234, "val_acc": 52.0}
{"epoch": 5, "training_loss": 11565.328643798828, "training_acc": 53.0, "val_loss": 1059.61275100708, "val_acc": 48.0}
{"epoch": 6, "training_loss": 5779.172760009766, "training_acc": 47.0, "val_loss": 2269.4990158081055, "val_acc": 48.0}
{"epoch": 7, "training_loss": 7153.229583740234, "training_acc": 47.0, "val_loss": 1201.3315200805664, "val_acc": 52.0}
{"epoch": 8, "training_loss": 6476.935974121094, "training_acc": 53.0, "val_loss": 1930.472183227539, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5991.940658569336, "training_acc": 53.0, "val_loss": 1279.4953346252441, "val_acc": 48.0}
{"epoch": 10, "training_loss": 5866.8134765625, "training_acc": 47.0, "val_loss": 1656.45751953125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 5002.71294593811, "training_acc": 45.0, "val_loss": 1260.8823776245117, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5294.686553955078, "training_acc": 53.0, "val_loss": 1003.5488128662109, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3205.228527069092, "training_acc": 47.0, "val_loss": 691.3881778717041, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1842.3321495056152, "training_acc": 49.0, "val_loss": 96.53081893920898, "val_acc": 56.0}
{"epoch": 15, "training_loss": 1527.654167175293, "training_acc": 45.0, "val_loss": 157.4434518814087, "val_acc": 44.0}
{"epoch": 16, "training_loss": 962.7914962768555, "training_acc": 60.0, "val_loss": 573.6443996429443, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1633.0681915283203, "training_acc": 54.0, "val_loss": 369.18933391571045, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1342.0596885681152, "training_acc": 49.0, "val_loss": 110.39586067199707, "val_acc": 56.0}
{"epoch": 19, "training_loss": 886.9791374206543, "training_acc": 57.0, "val_loss": 179.39656972885132, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1633.6345520019531, "training_acc": 51.0, "val_loss": 510.83359718322754, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1179.4821109771729, "training_acc": 63.0, "val_loss": 617.0610427856445, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1642.65966796875, "training_acc": 51.0, "val_loss": 113.37699890136719, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1383.598892211914, "training_acc": 47.0, "val_loss": 159.16506052017212, "val_acc": 40.0}
{"epoch": 24, "training_loss": 1264.9267349243164, "training_acc": 59.0, "val_loss": 382.9577445983887, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2281.2888793945312, "training_acc": 45.0, "val_loss": 765.9696102142334, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2301.963390350342, "training_acc": 42.0, "val_loss": 379.3932914733887, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1493.481819152832, "training_acc": 49.0, "val_loss": 224.6729612350464, "val_acc": 40.0}
{"epoch": 28, "training_loss": 1186.5457229614258, "training_acc": 58.0, "val_loss": 412.7737522125244, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1507.1152954101562, "training_acc": 52.0, "val_loss": 386.0279083251953, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1796.2011032104492, "training_acc": 44.0, "val_loss": 478.9447784423828, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1281.384635925293, "training_acc": 55.0, "val_loss": 604.3234348297119, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1407.532751083374, "training_acc": 57.0, "val_loss": 441.50562286376953, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1137.5459280014038, "training_acc": 60.0, "val_loss": 345.55749893188477, "val_acc": 48.0}
