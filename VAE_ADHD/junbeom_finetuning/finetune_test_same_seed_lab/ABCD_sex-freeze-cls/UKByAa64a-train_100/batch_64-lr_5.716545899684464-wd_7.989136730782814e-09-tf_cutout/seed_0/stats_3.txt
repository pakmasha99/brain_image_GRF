"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 12235.056186676025, "training_acc": 52.0, "val_loss": 2717.047882080078, "val_acc": 52.0}
{"epoch": 1, "training_loss": 13558.698303222656, "training_acc": 49.0, "val_loss": 6036.64436340332, "val_acc": 48.0}
{"epoch": 2, "training_loss": 22424.93438720703, "training_acc": 47.0, "val_loss": 1212.002944946289, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8234.176574707031, "training_acc": 45.0, "val_loss": 5182.997131347656, "val_acc": 52.0}
{"epoch": 4, "training_loss": 19393.12774658203, "training_acc": 53.0, "val_loss": 4479.335021972656, "val_acc": 52.0}
{"epoch": 5, "training_loss": 13511.070861816406, "training_acc": 53.0, "val_loss": 515.3721332550049, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4759.650817871094, "training_acc": 47.0, "val_loss": 1603.721809387207, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4986.504016876221, "training_acc": 51.0, "val_loss": 2029.440689086914, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7510.889953613281, "training_acc": 53.0, "val_loss": 2739.6183013916016, "val_acc": 52.0}
{"epoch": 9, "training_loss": 7330.148025512695, "training_acc": 53.0, "val_loss": 471.9849109649658, "val_acc": 44.0}
{"epoch": 10, "training_loss": 4506.244476318359, "training_acc": 46.0, "val_loss": 981.0092926025391, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3637.3684577941895, "training_acc": 52.0, "val_loss": 1295.323371887207, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2964.110122680664, "training_acc": 54.0, "val_loss": 462.11657524108887, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2172.752212524414, "training_acc": 53.0, "val_loss": 278.3254623413086, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1847.0140914916992, "training_acc": 56.0, "val_loss": 1321.7538833618164, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2705.4013595581055, "training_acc": 55.0, "val_loss": 481.1315059661865, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2487.8044662475586, "training_acc": 47.0, "val_loss": 668.553352355957, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2166.7818603515625, "training_acc": 53.0, "val_loss": 88.15795183181763, "val_acc": 60.0}
{"epoch": 18, "training_loss": 846.7323303222656, "training_acc": 50.0, "val_loss": 549.0034103393555, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1400.257495880127, "training_acc": 53.0, "val_loss": 503.6008834838867, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1834.063247680664, "training_acc": 47.0, "val_loss": 401.5239715576172, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1572.913589477539, "training_acc": 54.0, "val_loss": 481.08625411987305, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2370.5194396972656, "training_acc": 44.0, "val_loss": 498.5064506530762, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2117.1942138671875, "training_acc": 53.0, "val_loss": 97.24456071853638, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1232.101692199707, "training_acc": 52.0, "val_loss": 385.06600856781006, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1284.1996307373047, "training_acc": 52.0, "val_loss": 378.9421319961548, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1766.2761459350586, "training_acc": 47.0, "val_loss": 809.3367576599121, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2315.7559356689453, "training_acc": 56.0, "val_loss": 431.78439140319824, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1885.9420318603516, "training_acc": 50.0, "val_loss": 473.11768531799316, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2372.526397705078, "training_acc": 47.0, "val_loss": 1116.4525985717773, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2210.1107139587402, "training_acc": 54.0, "val_loss": 240.4071807861328, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1469.876350402832, "training_acc": 54.0, "val_loss": 708.1332683563232, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1514.0921211242676, "training_acc": 55.0, "val_loss": 164.59041833877563, "val_acc": 56.0}
{"epoch": 33, "training_loss": 1010.5421333312988, "training_acc": 56.0, "val_loss": 657.7290058135986, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1273.9114151000977, "training_acc": 54.0, "val_loss": 400.82459449768066, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1760.4991760253906, "training_acc": 48.0, "val_loss": 761.5490436553955, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2692.4663848876953, "training_acc": 53.0, "val_loss": 97.0842719078064, "val_acc": 52.0}
