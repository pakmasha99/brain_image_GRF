"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 119805.60495758057, "training_acc": 53.0, "val_loss": 337095.3125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1360880.74609375, "training_acc": 47.0, "val_loss": 26437.417602539062, "val_acc": 44.0}
{"epoch": 2, "training_loss": 228553.19921875, "training_acc": 68.0, "val_loss": 326927.9541015625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1015621.181640625, "training_acc": 53.0, "val_loss": 86197.37548828125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 433495.86328125, "training_acc": 47.0, "val_loss": 253891.4306640625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1025706.578125, "training_acc": 47.0, "val_loss": 67518.71948242188, "val_acc": 48.0}
{"epoch": 6, "training_loss": 352494.564453125, "training_acc": 51.0, "val_loss": 249745.2392578125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 872700.81640625, "training_acc": 53.0, "val_loss": 197397.6806640625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 499544.87841796875, "training_acc": 54.0, "val_loss": 115806.8115234375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 607186.4375, "training_acc": 47.0, "val_loss": 180219.287109375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 648602.462890625, "training_acc": 47.0, "val_loss": 62934.94873046875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 227325.732421875, "training_acc": 54.0, "val_loss": 150832.8125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 405235.1435546875, "training_acc": 53.0, "val_loss": 26369.448852539062, "val_acc": 48.0}
{"epoch": 13, "training_loss": 168295.779296875, "training_acc": 56.0, "val_loss": 38775.384521484375, "val_acc": 48.0}
{"epoch": 14, "training_loss": 206722.79711914062, "training_acc": 55.0, "val_loss": 104275.13427734375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 254329.7548828125, "training_acc": 53.0, "val_loss": 29249.508666992188, "val_acc": 52.0}
{"epoch": 16, "training_loss": 115803.7080078125, "training_acc": 57.0, "val_loss": 39988.031005859375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 160522.85595703125, "training_acc": 57.0, "val_loss": 83903.77807617188, "val_acc": 52.0}
{"epoch": 18, "training_loss": 196850.1875, "training_acc": 55.0, "val_loss": 24121.91619873047, "val_acc": 48.0}
{"epoch": 19, "training_loss": 121270.5654296875, "training_acc": 60.0, "val_loss": 30943.231201171875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 184913.4853515625, "training_acc": 44.0, "val_loss": 78824.52392578125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 161807.73071289062, "training_acc": 55.0, "val_loss": 18401.878356933594, "val_acc": 52.0}
{"epoch": 22, "training_loss": 96962.56591796875, "training_acc": 62.0, "val_loss": 32913.8671875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 79301.14135742188, "training_acc": 55.0, "val_loss": 22433.534240722656, "val_acc": 56.0}
{"epoch": 24, "training_loss": 95447.125, "training_acc": 59.0, "val_loss": 41759.619140625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 74492.77807617188, "training_acc": 59.0, "val_loss": 28310.269165039062, "val_acc": 48.0}
{"epoch": 26, "training_loss": 100359.19250488281, "training_acc": 54.0, "val_loss": 58017.48046875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 141153.017578125, "training_acc": 55.0, "val_loss": 22732.833862304688, "val_acc": 48.0}
{"epoch": 28, "training_loss": 104467.1015625, "training_acc": 48.0, "val_loss": 60690.10009765625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 161679.86547851562, "training_acc": 53.0, "val_loss": 11477.62451171875, "val_acc": 56.0}
{"epoch": 30, "training_loss": 67736.4384765625, "training_acc": 57.0, "val_loss": 68411.26708984375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 175010.236328125, "training_acc": 53.0, "val_loss": 16699.7802734375, "val_acc": 44.0}
{"epoch": 32, "training_loss": 84997.19384765625, "training_acc": 62.0, "val_loss": 19931.24542236328, "val_acc": 52.0}
{"epoch": 33, "training_loss": 133749.63037109375, "training_acc": 48.0, "val_loss": 91471.88720703125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 177179.193359375, "training_acc": 52.0, "val_loss": 61960.479736328125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 296336.8056640625, "training_acc": 47.0, "val_loss": 13844.680786132812, "val_acc": 40.0}
{"epoch": 36, "training_loss": 117042.6708984375, "training_acc": 60.0, "val_loss": 106755.74951171875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 248140.74291992188, "training_acc": 53.0, "val_loss": 66403.57666015625, "val_acc": 48.0}
{"epoch": 38, "training_loss": 328238.84765625, "training_acc": 47.0, "val_loss": 35274.615478515625, "val_acc": 48.0}
{"epoch": 39, "training_loss": 266063.2666015625, "training_acc": 39.0, "val_loss": 119753.90625, "val_acc": 52.0}
{"epoch": 40, "training_loss": 350146.7041015625, "training_acc": 53.0, "val_loss": 15312.59765625, "val_acc": 52.0}
{"epoch": 41, "training_loss": 108427.927734375, "training_acc": 50.0, "val_loss": 9754.389190673828, "val_acc": 52.0}
{"epoch": 42, "training_loss": 61829.171142578125, "training_acc": 58.0, "val_loss": 11650.09994506836, "val_acc": 56.0}
{"epoch": 43, "training_loss": 80403.4833984375, "training_acc": 65.0, "val_loss": 9262.648010253906, "val_acc": 52.0}
{"epoch": 44, "training_loss": 48608.386474609375, "training_acc": 65.0, "val_loss": 17685.256958007812, "val_acc": 52.0}
{"epoch": 45, "training_loss": 47593.101318359375, "training_acc": 61.0, "val_loss": 18488.108825683594, "val_acc": 56.0}
{"epoch": 46, "training_loss": 44080.47314453125, "training_acc": 69.0, "val_loss": 14737.251281738281, "val_acc": 44.0}
{"epoch": 47, "training_loss": 73212.734375, "training_acc": 58.0, "val_loss": 20869.08721923828, "val_acc": 52.0}
{"epoch": 48, "training_loss": 56568.077392578125, "training_acc": 61.0, "val_loss": 23704.57305908203, "val_acc": 52.0}
{"epoch": 49, "training_loss": 81621.85693359375, "training_acc": 60.0, "val_loss": 9293.0908203125, "val_acc": 48.0}
{"epoch": 50, "training_loss": 69085.27001953125, "training_acc": 71.0, "val_loss": 33690.3076171875, "val_acc": 52.0}
{"epoch": 51, "training_loss": 101506.04931640625, "training_acc": 54.0, "val_loss": 28126.840209960938, "val_acc": 48.0}
{"epoch": 52, "training_loss": 107021.45947265625, "training_acc": 55.0, "val_loss": 62280.76171875, "val_acc": 52.0}
{"epoch": 53, "training_loss": 104213.82794189453, "training_acc": 61.0, "val_loss": 50857.67822265625, "val_acc": 48.0}
{"epoch": 54, "training_loss": 189315.47265625, "training_acc": 47.0, "val_loss": 65553.4423828125, "val_acc": 52.0}
{"epoch": 55, "training_loss": 211353.04296875, "training_acc": 53.0, "val_loss": 43460.296630859375, "val_acc": 52.0}
{"epoch": 56, "training_loss": 97840.0810546875, "training_acc": 63.0, "val_loss": 73333.34350585938, "val_acc": 48.0}
{"epoch": 57, "training_loss": 246635.244140625, "training_acc": 50.0, "val_loss": 90310.7177734375, "val_acc": 52.0}
{"epoch": 58, "training_loss": 283275.517578125, "training_acc": 53.0, "val_loss": 88603.74755859375, "val_acc": 52.0}
{"epoch": 59, "training_loss": 133245.49084472656, "training_acc": 66.0, "val_loss": 61097.955322265625, "val_acc": 48.0}
{"epoch": 60, "training_loss": 248068.548828125, "training_acc": 47.0, "val_loss": 45688.006591796875, "val_acc": 52.0}
{"epoch": 61, "training_loss": 91271.0068359375, "training_acc": 60.0, "val_loss": 31826.30615234375, "val_acc": 52.0}
{"epoch": 62, "training_loss": 99257.087890625, "training_acc": 60.0, "val_loss": 37408.709716796875, "val_acc": 48.0}
