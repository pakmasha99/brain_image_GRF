"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 61496.069480895996, "training_acc": 47.0, "val_loss": 4518.223571777344, "val_acc": 48.0}
{"epoch": 1, "training_loss": 63370.10302734375, "training_acc": 46.0, "val_loss": 44184.83581542969, "val_acc": 52.0}
{"epoch": 2, "training_loss": 171464.2109375, "training_acc": 53.0, "val_loss": 32000.112915039062, "val_acc": 52.0}
{"epoch": 3, "training_loss": 96434.91796875, "training_acc": 53.0, "val_loss": 6995.81298828125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 35210.20300292969, "training_acc": 48.0, "val_loss": 20639.404296875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 74535.99169921875, "training_acc": 47.0, "val_loss": 5208.479690551758, "val_acc": 48.0}
{"epoch": 6, "training_loss": 19299.904907226562, "training_acc": 60.0, "val_loss": 16645.52459716797, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69460.84033203125, "training_acc": 53.0, "val_loss": 14734.001159667969, "val_acc": 52.0}
{"epoch": 8, "training_loss": 47316.60479736328, "training_acc": 53.0, "val_loss": 7388.194274902344, "val_acc": 48.0}
{"epoch": 9, "training_loss": 35484.720458984375, "training_acc": 47.0, "val_loss": 12294.985961914062, "val_acc": 48.0}
{"epoch": 10, "training_loss": 38469.553955078125, "training_acc": 47.0, "val_loss": 4199.016189575195, "val_acc": 52.0}
{"epoch": 11, "training_loss": 22043.71875, "training_acc": 54.0, "val_loss": 8805.07583618164, "val_acc": 52.0}
{"epoch": 12, "training_loss": 26636.021423339844, "training_acc": 54.0, "val_loss": 4422.562026977539, "val_acc": 48.0}
{"epoch": 13, "training_loss": 20013.300048828125, "training_acc": 48.0, "val_loss": 4923.406219482422, "val_acc": 48.0}
{"epoch": 14, "training_loss": 16658.691345214844, "training_acc": 47.0, "val_loss": 3383.6151123046875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 10684.871353149414, "training_acc": 47.0, "val_loss": 3744.7559356689453, "val_acc": 48.0}
{"epoch": 16, "training_loss": 11903.08349609375, "training_acc": 50.0, "val_loss": 2930.8311462402344, "val_acc": 52.0}
{"epoch": 17, "training_loss": 11687.366333007812, "training_acc": 54.0, "val_loss": 1115.5030250549316, "val_acc": 40.0}
{"epoch": 18, "training_loss": 4696.187850952148, "training_acc": 54.0, "val_loss": 935.6648445129395, "val_acc": 40.0}
{"epoch": 19, "training_loss": 3590.236801147461, "training_acc": 57.0, "val_loss": 822.9517936706543, "val_acc": 60.0}
{"epoch": 20, "training_loss": 6662.123840332031, "training_acc": 53.0, "val_loss": 636.8312835693359, "val_acc": 64.0}
{"epoch": 21, "training_loss": 4062.8809814453125, "training_acc": 59.0, "val_loss": 703.4239292144775, "val_acc": 64.0}
{"epoch": 22, "training_loss": 3493.932342529297, "training_acc": 63.0, "val_loss": 734.5822811126709, "val_acc": 48.0}
{"epoch": 23, "training_loss": 4297.677185058594, "training_acc": 60.0, "val_loss": 1445.5636024475098, "val_acc": 52.0}
{"epoch": 24, "training_loss": 8695.179992675781, "training_acc": 54.0, "val_loss": 3787.1292114257812, "val_acc": 48.0}
{"epoch": 25, "training_loss": 9988.722442626953, "training_acc": 57.0, "val_loss": 2216.66259765625, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5689.73095703125, "training_acc": 56.0, "val_loss": 322.97585010528564, "val_acc": 64.0}
{"epoch": 27, "training_loss": 2790.494155883789, "training_acc": 66.0, "val_loss": 724.1816997528076, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3844.138946533203, "training_acc": 56.0, "val_loss": 1155.9170722961426, "val_acc": 48.0}
{"epoch": 29, "training_loss": 4566.990798950195, "training_acc": 55.0, "val_loss": 213.66937160491943, "val_acc": 64.0}
{"epoch": 30, "training_loss": 2933.0030364990234, "training_acc": 60.0, "val_loss": 2611.834716796875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 7720.827056884766, "training_acc": 54.0, "val_loss": 3296.621322631836, "val_acc": 48.0}
{"epoch": 32, "training_loss": 11217.849487304688, "training_acc": 49.0, "val_loss": 2487.1206283569336, "val_acc": 52.0}
{"epoch": 33, "training_loss": 8393.574798583984, "training_acc": 53.0, "val_loss": 2165.0163650512695, "val_acc": 48.0}
{"epoch": 34, "training_loss": 6747.04426574707, "training_acc": 52.0, "val_loss": 2176.6836166381836, "val_acc": 52.0}
{"epoch": 35, "training_loss": 6461.753875732422, "training_acc": 58.0, "val_loss": 3149.8592376708984, "val_acc": 48.0}
{"epoch": 36, "training_loss": 9755.167037963867, "training_acc": 48.0, "val_loss": 4544.264602661133, "val_acc": 52.0}
{"epoch": 37, "training_loss": 17586.217041015625, "training_acc": 53.0, "val_loss": 1825.6877899169922, "val_acc": 52.0}
{"epoch": 38, "training_loss": 13289.666381835938, "training_acc": 49.0, "val_loss": 8456.06460571289, "val_acc": 48.0}
{"epoch": 39, "training_loss": 27616.13165283203, "training_acc": 47.0, "val_loss": 3824.680709838867, "val_acc": 52.0}
{"epoch": 40, "training_loss": 14556.163879394531, "training_acc": 53.0, "val_loss": 5330.209732055664, "val_acc": 52.0}
{"epoch": 41, "training_loss": 13954.327140808105, "training_acc": 60.0, "val_loss": 4240.457534790039, "val_acc": 48.0}
{"epoch": 42, "training_loss": 14107.066619873047, "training_acc": 49.0, "val_loss": 3295.0843811035156, "val_acc": 52.0}
{"epoch": 43, "training_loss": 12534.8837890625, "training_acc": 53.0, "val_loss": 551.2972354888916, "val_acc": 64.0}
{"epoch": 44, "training_loss": 7083.724060058594, "training_acc": 62.0, "val_loss": 1719.8368072509766, "val_acc": 48.0}
{"epoch": 45, "training_loss": 7828.535552978516, "training_acc": 57.0, "val_loss": 3575.033950805664, "val_acc": 52.0}
{"epoch": 46, "training_loss": 7613.03959274292, "training_acc": 65.0, "val_loss": 4378.3905029296875, "val_acc": 48.0}
{"epoch": 47, "training_loss": 15523.138793945312, "training_acc": 48.0, "val_loss": 3236.5440368652344, "val_acc": 52.0}
{"epoch": 48, "training_loss": 11369.67138671875, "training_acc": 55.0, "val_loss": 1547.4274635314941, "val_acc": 48.0}
