"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 61014.92678833008, "training_acc": 53.0, "val_loss": 11680.379486083984, "val_acc": 52.0}
{"epoch": 1, "training_loss": 60803.23828125, "training_acc": 55.0, "val_loss": 36630.950927734375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 137058.29833984375, "training_acc": 47.0, "val_loss": 12488.065338134766, "val_acc": 48.0}
{"epoch": 3, "training_loss": 43665.06896972656, "training_acc": 53.0, "val_loss": 21559.034729003906, "val_acc": 52.0}
{"epoch": 4, "training_loss": 84156.59301757812, "training_acc": 53.0, "val_loss": 18399.8779296875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 56450.411071777344, "training_acc": 53.0, "val_loss": 8650.03662109375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 45751.976318359375, "training_acc": 47.0, "val_loss": 14242.332458496094, "val_acc": 48.0}
{"epoch": 7, "training_loss": 48574.93225097656, "training_acc": 47.0, "val_loss": 5735.908126831055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 27602.431884765625, "training_acc": 53.0, "val_loss": 10750.843811035156, "val_acc": 52.0}
{"epoch": 9, "training_loss": 32240.305297851562, "training_acc": 53.0, "val_loss": 4258.625030517578, "val_acc": 48.0}
{"epoch": 10, "training_loss": 22067.694580078125, "training_acc": 47.0, "val_loss": 4857.809066772461, "val_acc": 48.0}
{"epoch": 11, "training_loss": 16750.44320678711, "training_acc": 47.0, "val_loss": 4732.901382446289, "val_acc": 52.0}
{"epoch": 12, "training_loss": 12723.010269165039, "training_acc": 52.0, "val_loss": 5811.827850341797, "val_acc": 48.0}
{"epoch": 13, "training_loss": 22969.701293945312, "training_acc": 47.0, "val_loss": 2296.5478897094727, "val_acc": 48.0}
{"epoch": 14, "training_loss": 13155.221496582031, "training_acc": 48.0, "val_loss": 7597.139739990234, "val_acc": 52.0}
{"epoch": 15, "training_loss": 24837.257446289062, "training_acc": 53.0, "val_loss": 1805.7458877563477, "val_acc": 44.0}
{"epoch": 16, "training_loss": 9842.563415527344, "training_acc": 53.0, "val_loss": 2950.455665588379, "val_acc": 48.0}
{"epoch": 17, "training_loss": 9135.475189208984, "training_acc": 56.0, "val_loss": 2974.93839263916, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7789.6365966796875, "training_acc": 58.0, "val_loss": 1284.7557067871094, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6508.008392333984, "training_acc": 52.0, "val_loss": 2190.976333618164, "val_acc": 52.0}
{"epoch": 20, "training_loss": 7227.428680419922, "training_acc": 48.0, "val_loss": 1023.7401962280273, "val_acc": 48.0}
{"epoch": 21, "training_loss": 9703.0146484375, "training_acc": 47.0, "val_loss": 5154.902267456055, "val_acc": 52.0}
{"epoch": 22, "training_loss": 10604.032455444336, "training_acc": 54.0, "val_loss": 3171.811866760254, "val_acc": 48.0}
{"epoch": 23, "training_loss": 15413.127410888672, "training_acc": 47.0, "val_loss": 2997.7724075317383, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11224.545715332031, "training_acc": 56.0, "val_loss": 1142.3670768737793, "val_acc": 56.0}
{"epoch": 25, "training_loss": 7724.304382324219, "training_acc": 54.0, "val_loss": 2877.1860122680664, "val_acc": 48.0}
{"epoch": 26, "training_loss": 10350.522171020508, "training_acc": 50.0, "val_loss": 3175.057029724121, "val_acc": 52.0}
{"epoch": 27, "training_loss": 6773.533477783203, "training_acc": 49.0, "val_loss": 594.399356842041, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3758.11962890625, "training_acc": 61.0, "val_loss": 556.6685676574707, "val_acc": 56.0}
{"epoch": 29, "training_loss": 1824.2129096984863, "training_acc": 71.0, "val_loss": 631.0388088226318, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1844.591625213623, "training_acc": 65.0, "val_loss": 947.9373931884766, "val_acc": 60.0}
{"epoch": 31, "training_loss": 3081.326889038086, "training_acc": 55.0, "val_loss": 2999.4070053100586, "val_acc": 52.0}
{"epoch": 32, "training_loss": 6535.995407104492, "training_acc": 56.0, "val_loss": 3590.030288696289, "val_acc": 48.0}
{"epoch": 33, "training_loss": 15590.140197753906, "training_acc": 47.0, "val_loss": 2064.120101928711, "val_acc": 52.0}
{"epoch": 34, "training_loss": 4826.155426025391, "training_acc": 56.0, "val_loss": 2139.712333679199, "val_acc": 44.0}
{"epoch": 35, "training_loss": 8157.196441650391, "training_acc": 49.0, "val_loss": 5134.745025634766, "val_acc": 52.0}
{"epoch": 36, "training_loss": 18982.6328125, "training_acc": 53.0, "val_loss": 4007.9410552978516, "val_acc": 52.0}
{"epoch": 37, "training_loss": 14238.999328613281, "training_acc": 45.0, "val_loss": 5102.217102050781, "val_acc": 48.0}
{"epoch": 38, "training_loss": 11003.547622680664, "training_acc": 58.0, "val_loss": 5156.121444702148, "val_acc": 52.0}
{"epoch": 39, "training_loss": 18608.076110839844, "training_acc": 53.0, "val_loss": 2407.982635498047, "val_acc": 52.0}
{"epoch": 40, "training_loss": 8101.5799560546875, "training_acc": 59.0, "val_loss": 5751.353454589844, "val_acc": 48.0}
{"epoch": 41, "training_loss": 15676.940780639648, "training_acc": 50.0, "val_loss": 6089.740753173828, "val_acc": 52.0}
{"epoch": 42, "training_loss": 22857.457641601562, "training_acc": 53.0, "val_loss": 5252.4627685546875, "val_acc": 52.0}
{"epoch": 43, "training_loss": 13861.607879638672, "training_acc": 51.0, "val_loss": 3111.3161087036133, "val_acc": 48.0}
{"epoch": 44, "training_loss": 7158.152473449707, "training_acc": 57.0, "val_loss": 3120.3311920166016, "val_acc": 52.0}
{"epoch": 45, "training_loss": 5722.909065246582, "training_acc": 55.0, "val_loss": 1524.2485046386719, "val_acc": 40.0}
{"epoch": 46, "training_loss": 5982.297943115234, "training_acc": 52.0, "val_loss": 1600.4384994506836, "val_acc": 52.0}
{"epoch": 47, "training_loss": 4730.650909423828, "training_acc": 56.0, "val_loss": 648.8951206207275, "val_acc": 52.0}
