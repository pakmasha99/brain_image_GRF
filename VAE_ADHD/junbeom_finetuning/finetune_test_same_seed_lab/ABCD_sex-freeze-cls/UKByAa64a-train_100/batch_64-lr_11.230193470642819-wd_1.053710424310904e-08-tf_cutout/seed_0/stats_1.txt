"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 23630.657398223877, "training_acc": 46.0, "val_loss": 4929.99267578125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 23940.279418945312, "training_acc": 53.0, "val_loss": 12767.91763305664, "val_acc": 48.0}
{"epoch": 2, "training_loss": 48051.82629394531, "training_acc": 47.0, "val_loss": 3539.3238067626953, "val_acc": 48.0}
{"epoch": 3, "training_loss": 16743.696838378906, "training_acc": 51.0, "val_loss": 9324.368286132812, "val_acc": 52.0}
{"epoch": 4, "training_loss": 35426.494140625, "training_acc": 53.0, "val_loss": 8320.40023803711, "val_acc": 52.0}
{"epoch": 5, "training_loss": 24694.712463378906, "training_acc": 53.0, "val_loss": 1445.7881927490234, "val_acc": 48.0}
{"epoch": 6, "training_loss": 13324.785400390625, "training_acc": 47.0, "val_loss": 4261.821746826172, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14445.387237548828, "training_acc": 47.0, "val_loss": 3087.9018783569336, "val_acc": 52.0}
{"epoch": 8, "training_loss": 12041.033294677734, "training_acc": 53.0, "val_loss": 5354.373931884766, "val_acc": 52.0}
{"epoch": 9, "training_loss": 17386.89859008789, "training_acc": 53.0, "val_loss": 674.6617317199707, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6980.478942871094, "training_acc": 49.0, "val_loss": 5009.444808959961, "val_acc": 48.0}
{"epoch": 11, "training_loss": 19216.74432373047, "training_acc": 47.0, "val_loss": 1113.0739212036133, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6968.633728027344, "training_acc": 49.0, "val_loss": 5167.60139465332, "val_acc": 52.0}
{"epoch": 13, "training_loss": 19844.874145507812, "training_acc": 53.0, "val_loss": 3841.7980194091797, "val_acc": 52.0}
{"epoch": 14, "training_loss": 10217.592597961426, "training_acc": 52.0, "val_loss": 3918.1365966796875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 18992.79150390625, "training_acc": 47.0, "val_loss": 5736.241912841797, "val_acc": 48.0}
{"epoch": 16, "training_loss": 19343.35723876953, "training_acc": 47.0, "val_loss": 552.9011249542236, "val_acc": 60.0}
{"epoch": 17, "training_loss": 4919.49560546875, "training_acc": 54.0, "val_loss": 3332.046890258789, "val_acc": 52.0}
{"epoch": 18, "training_loss": 10730.893783569336, "training_acc": 53.0, "val_loss": 627.0744323730469, "val_acc": 52.0}
{"epoch": 19, "training_loss": 3128.8727416992188, "training_acc": 54.0, "val_loss": 251.7033576965332, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3305.9556884765625, "training_acc": 54.0, "val_loss": 1509.0794563293457, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3235.355754852295, "training_acc": 58.0, "val_loss": 835.5686187744141, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2499.714069366455, "training_acc": 55.0, "val_loss": 985.227108001709, "val_acc": 56.0}
{"epoch": 23, "training_loss": 1979.357967376709, "training_acc": 62.0, "val_loss": 1252.0026206970215, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4123.0654296875, "training_acc": 49.0, "val_loss": 1361.0822677612305, "val_acc": 52.0}
{"epoch": 25, "training_loss": 4659.784164428711, "training_acc": 55.0, "val_loss": 411.9296073913574, "val_acc": 56.0}
{"epoch": 26, "training_loss": 4235.119354248047, "training_acc": 51.0, "val_loss": 1649.5759963989258, "val_acc": 48.0}
{"epoch": 27, "training_loss": 4846.380252838135, "training_acc": 51.0, "val_loss": 1077.0586013793945, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2401.6955642700195, "training_acc": 55.0, "val_loss": 1054.13179397583, "val_acc": 48.0}
{"epoch": 29, "training_loss": 2966.5350646972656, "training_acc": 54.0, "val_loss": 2169.0980911254883, "val_acc": 52.0}
{"epoch": 30, "training_loss": 7920.554779052734, "training_acc": 53.0, "val_loss": 1393.2185173034668, "val_acc": 52.0}
{"epoch": 31, "training_loss": 5211.132171630859, "training_acc": 49.0, "val_loss": 1927.5114059448242, "val_acc": 48.0}
{"epoch": 32, "training_loss": 5655.197956085205, "training_acc": 52.0, "val_loss": 2297.903823852539, "val_acc": 52.0}
{"epoch": 33, "training_loss": 9016.747680664062, "training_acc": 53.0, "val_loss": 1789.596939086914, "val_acc": 52.0}
{"epoch": 34, "training_loss": 3759.786262512207, "training_acc": 63.0, "val_loss": 1770.4704284667969, "val_acc": 48.0}
{"epoch": 35, "training_loss": 5677.498428344727, "training_acc": 48.0, "val_loss": 2054.9442291259766, "val_acc": 52.0}
{"epoch": 36, "training_loss": 7784.785400390625, "training_acc": 53.0, "val_loss": 1707.582664489746, "val_acc": 52.0}
{"epoch": 37, "training_loss": 4761.708297729492, "training_acc": 50.0, "val_loss": 1507.0683479309082, "val_acc": 48.0}
{"epoch": 38, "training_loss": 4311.188480377197, "training_acc": 50.0, "val_loss": 1745.3750610351562, "val_acc": 52.0}
