"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 11190.048049926758, "training_acc": 55.0, "val_loss": 1065.7028198242188, "val_acc": 40.0}
{"epoch": 1, "training_loss": 6383.572280883789, "training_acc": 47.0, "val_loss": 5296.226501464844, "val_acc": 52.0}
{"epoch": 2, "training_loss": 12013.462692260742, "training_acc": 54.0, "val_loss": 3112.8095626831055, "val_acc": 48.0}
{"epoch": 3, "training_loss": 14062.289245605469, "training_acc": 47.0, "val_loss": 2677.614212036133, "val_acc": 52.0}
{"epoch": 4, "training_loss": 8883.372528076172, "training_acc": 53.0, "val_loss": 1704.7346115112305, "val_acc": 52.0}
{"epoch": 5, "training_loss": 6152.705841064453, "training_acc": 51.0, "val_loss": 2280.623435974121, "val_acc": 48.0}
{"epoch": 6, "training_loss": 6588.580936431885, "training_acc": 55.0, "val_loss": 2079.0863037109375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 4680.496967315674, "training_acc": 55.0, "val_loss": 524.3930339813232, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3958.374496459961, "training_acc": 41.0, "val_loss": 309.7109079360962, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2333.1782836914062, "training_acc": 55.0, "val_loss": 143.68505477905273, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2919.132843017578, "training_acc": 65.0, "val_loss": 1464.940357208252, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3133.868995666504, "training_acc": 60.0, "val_loss": 1251.126480102539, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4198.211616516113, "training_acc": 48.0, "val_loss": 1105.7019233703613, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1919.4409103393555, "training_acc": 59.0, "val_loss": 206.76698684692383, "val_acc": 40.0}
{"epoch": 14, "training_loss": 2583.623062133789, "training_acc": 50.0, "val_loss": 603.4750461578369, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2327.932571411133, "training_acc": 59.0, "val_loss": 605.9481620788574, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3885.1026000976562, "training_acc": 51.0, "val_loss": 2413.5107040405273, "val_acc": 52.0}
{"epoch": 17, "training_loss": 6100.092933654785, "training_acc": 53.0, "val_loss": 2514.223098754883, "val_acc": 48.0}
{"epoch": 18, "training_loss": 11613.337524414062, "training_acc": 47.0, "val_loss": 1679.4464111328125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 7436.7843017578125, "training_acc": 45.0, "val_loss": 3172.3304748535156, "val_acc": 52.0}
{"epoch": 20, "training_loss": 9800.058715820312, "training_acc": 53.0, "val_loss": 182.2762131690979, "val_acc": 56.0}
{"epoch": 21, "training_loss": 2405.675994873047, "training_acc": 53.0, "val_loss": 281.9541931152344, "val_acc": 44.0}
{"epoch": 22, "training_loss": 2337.7515869140625, "training_acc": 58.0, "val_loss": 865.7191276550293, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3193.339797973633, "training_acc": 56.0, "val_loss": 971.8815803527832, "val_acc": 48.0}
{"epoch": 24, "training_loss": 3028.5987586975098, "training_acc": 61.0, "val_loss": 1935.2685928344727, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3737.302520751953, "training_acc": 59.0, "val_loss": 869.9666023254395, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3153.6861457824707, "training_acc": 49.0, "val_loss": 2363.020896911621, "val_acc": 52.0}
{"epoch": 27, "training_loss": 8315.807739257812, "training_acc": 53.0, "val_loss": 1232.4663162231445, "val_acc": 52.0}
{"epoch": 28, "training_loss": 4410.462860107422, "training_acc": 56.0, "val_loss": 3220.2171325683594, "val_acc": 48.0}
