"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 30955.383506774902, "training_acc": 53.0, "val_loss": 6079.695510864258, "val_acc": 52.0}
{"epoch": 1, "training_loss": 31050.476440429688, "training_acc": 41.0, "val_loss": 10054.141998291016, "val_acc": 48.0}
{"epoch": 2, "training_loss": 36668.64270019531, "training_acc": 47.0, "val_loss": 2096.152114868164, "val_acc": 48.0}
{"epoch": 3, "training_loss": 15710.745483398438, "training_acc": 41.0, "val_loss": 8818.387603759766, "val_acc": 52.0}
{"epoch": 4, "training_loss": 33804.054931640625, "training_acc": 53.0, "val_loss": 7228.105926513672, "val_acc": 52.0}
{"epoch": 5, "training_loss": 22408.561279296875, "training_acc": 53.0, "val_loss": 1601.6077041625977, "val_acc": 48.0}
{"epoch": 6, "training_loss": 10394.608703613281, "training_acc": 47.0, "val_loss": 3816.872024536133, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12371.169525146484, "training_acc": 47.0, "val_loss": 2772.4342346191406, "val_acc": 52.0}
{"epoch": 8, "training_loss": 12517.044250488281, "training_acc": 53.0, "val_loss": 4142.955017089844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 13010.458862304688, "training_acc": 53.0, "val_loss": 1354.345417022705, "val_acc": 48.0}
{"epoch": 10, "training_loss": 6891.843109130859, "training_acc": 47.0, "val_loss": 1575.3067016601562, "val_acc": 48.0}
{"epoch": 11, "training_loss": 4633.6820068359375, "training_acc": 54.0, "val_loss": 1696.8690872192383, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5187.96541595459, "training_acc": 51.0, "val_loss": 1717.8627014160156, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6828.193359375, "training_acc": 47.0, "val_loss": 236.94686889648438, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3447.89501953125, "training_acc": 59.0, "val_loss": 1590.595817565918, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4020.89302444458, "training_acc": 55.0, "val_loss": 947.7310180664062, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2970.7271728515625, "training_acc": 47.0, "val_loss": 816.7043685913086, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2222.6415119171143, "training_acc": 61.0, "val_loss": 235.1069688796997, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1211.2519226074219, "training_acc": 63.0, "val_loss": 190.35818576812744, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1215.5214729309082, "training_acc": 60.0, "val_loss": 1335.3464126586914, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3637.9251594543457, "training_acc": 53.0, "val_loss": 485.5185031890869, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1814.2801837921143, "training_acc": 50.0, "val_loss": 574.2343425750732, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1299.968734741211, "training_acc": 60.0, "val_loss": 521.1258411407471, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1668.6259078979492, "training_acc": 50.0, "val_loss": 820.8576202392578, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1918.2315635681152, "training_acc": 60.0, "val_loss": 1418.8339233398438, "val_acc": 48.0}
{"epoch": 25, "training_loss": 5112.388534545898, "training_acc": 47.0, "val_loss": 1391.1503791809082, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5202.000518798828, "training_acc": 53.0, "val_loss": 620.5178260803223, "val_acc": 52.0}
{"epoch": 27, "training_loss": 4166.720550537109, "training_acc": 50.0, "val_loss": 2475.23136138916, "val_acc": 48.0}
{"epoch": 28, "training_loss": 7725.580154418945, "training_acc": 47.0, "val_loss": 2583.814239501953, "val_acc": 52.0}
{"epoch": 29, "training_loss": 11466.138488769531, "training_acc": 53.0, "val_loss": 3625.6607055664062, "val_acc": 52.0}
{"epoch": 30, "training_loss": 10269.094284057617, "training_acc": 53.0, "val_loss": 2198.849105834961, "val_acc": 48.0}
{"epoch": 31, "training_loss": 11313.054016113281, "training_acc": 47.0, "val_loss": 2753.9154052734375, "val_acc": 48.0}
{"epoch": 32, "training_loss": 7513.211824417114, "training_acc": 58.0, "val_loss": 2592.584228515625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 9190.34359741211, "training_acc": 53.0, "val_loss": 2096.162796020508, "val_acc": 52.0}
{"epoch": 34, "training_loss": 5206.831436157227, "training_acc": 53.0, "val_loss": 803.707218170166, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2943.1783447265625, "training_acc": 50.0, "val_loss": 415.40307998657227, "val_acc": 56.0}
{"epoch": 36, "training_loss": 1694.0639953613281, "training_acc": 55.0, "val_loss": 233.6998462677002, "val_acc": 56.0}
{"epoch": 37, "training_loss": 1186.9138565063477, "training_acc": 60.0, "val_loss": 253.14812660217285, "val_acc": 48.0}
