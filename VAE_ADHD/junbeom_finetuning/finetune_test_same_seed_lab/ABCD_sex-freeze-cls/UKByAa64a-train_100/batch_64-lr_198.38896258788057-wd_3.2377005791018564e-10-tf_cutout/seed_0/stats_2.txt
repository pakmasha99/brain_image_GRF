"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 375415.89458084106, "training_acc": 51.0, "val_loss": 88520.23315429688, "val_acc": 52.0}
{"epoch": 1, "training_loss": 454395.666015625, "training_acc": 51.0, "val_loss": 214301.4892578125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 773371.751953125, "training_acc": 47.0, "val_loss": 35803.570556640625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 273647.82421875, "training_acc": 47.0, "val_loss": 195466.34521484375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 770805.970703125, "training_acc": 53.0, "val_loss": 179571.142578125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 602695.828125, "training_acc": 53.0, "val_loss": 11130.187225341797, "val_acc": 52.0}
{"epoch": 6, "training_loss": 183956.76171875, "training_acc": 54.0, "val_loss": 194379.296875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 783779.126953125, "training_acc": 47.0, "val_loss": 187281.75048828125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 638999.87109375, "training_acc": 47.0, "val_loss": 29677.24609375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 157890.880859375, "training_acc": 53.0, "val_loss": 146902.45361328125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 620437.974609375, "training_acc": 53.0, "val_loss": 166444.3115234375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 594365.18359375, "training_acc": 53.0, "val_loss": 61543.9453125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 194545.1484375, "training_acc": 51.0, "val_loss": 90117.73071289062, "val_acc": 48.0}
{"epoch": 13, "training_loss": 343625.1865234375, "training_acc": 47.0, "val_loss": 79200.59204101562, "val_acc": 48.0}
{"epoch": 14, "training_loss": 203287.31176757812, "training_acc": 47.0, "val_loss": 49114.92004394531, "val_acc": 52.0}
{"epoch": 15, "training_loss": 246428.2802734375, "training_acc": 53.0, "val_loss": 81141.10717773438, "val_acc": 52.0}
{"epoch": 16, "training_loss": 269945.06103515625, "training_acc": 53.0, "val_loss": 9694.649505615234, "val_acc": 56.0}
{"epoch": 17, "training_loss": 87059.7783203125, "training_acc": 48.0, "val_loss": 37908.59375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 98558.90942382812, "training_acc": 48.0, "val_loss": 33443.756103515625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 121087.83203125, "training_acc": 53.0, "val_loss": 4073.4546661376953, "val_acc": 56.0}
{"epoch": 20, "training_loss": 39315.65625, "training_acc": 54.0, "val_loss": 7241.148376464844, "val_acc": 52.0}
{"epoch": 21, "training_loss": 81664.19189453125, "training_acc": 47.0, "val_loss": 39811.614990234375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 98269.74584960938, "training_acc": 52.0, "val_loss": 38988.031005859375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 187761.9970703125, "training_acc": 47.0, "val_loss": 32647.769165039062, "val_acc": 48.0}
{"epoch": 24, "training_loss": 95622.80822753906, "training_acc": 55.0, "val_loss": 45377.22473144531, "val_acc": 52.0}
{"epoch": 25, "training_loss": 147173.89990234375, "training_acc": 53.0, "val_loss": 10826.702880859375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 51155.958251953125, "training_acc": 62.0, "val_loss": 41878.8818359375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 149707.18603515625, "training_acc": 47.0, "val_loss": 36720.35827636719, "val_acc": 52.0}
{"epoch": 28, "training_loss": 139257.8935546875, "training_acc": 53.0, "val_loss": 50737.591552734375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 118634.1025390625, "training_acc": 56.0, "val_loss": 39925.38146972656, "val_acc": 48.0}
{"epoch": 30, "training_loss": 197882.9560546875, "training_acc": 47.0, "val_loss": 45381.353759765625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 132980.51092529297, "training_acc": 52.0, "val_loss": 49320.233154296875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 169951.72021484375, "training_acc": 53.0, "val_loss": 49025.11291503906, "val_acc": 52.0}
{"epoch": 33, "training_loss": 116436.01977539062, "training_acc": 54.0, "val_loss": 40829.38232421875, "val_acc": 48.0}
{"epoch": 34, "training_loss": 187190.7060546875, "training_acc": 47.0, "val_loss": 28958.248901367188, "val_acc": 48.0}
{"epoch": 35, "training_loss": 92348.32971191406, "training_acc": 57.0, "val_loss": 47258.87756347656, "val_acc": 52.0}
{"epoch": 36, "training_loss": 148872.75317382812, "training_acc": 53.0, "val_loss": 5105.323791503906, "val_acc": 64.0}
{"epoch": 37, "training_loss": 37714.42138671875, "training_acc": 65.0, "val_loss": 14426.658630371094, "val_acc": 44.0}
{"epoch": 38, "training_loss": 67187.1611328125, "training_acc": 50.0, "val_loss": 26662.448120117188, "val_acc": 52.0}
