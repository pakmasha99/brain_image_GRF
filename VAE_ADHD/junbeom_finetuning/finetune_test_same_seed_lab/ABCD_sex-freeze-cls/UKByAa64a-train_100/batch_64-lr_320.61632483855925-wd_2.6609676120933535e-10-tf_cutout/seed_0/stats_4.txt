"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 639126.7837600708, "training_acc": 47.0, "val_loss": 7070.771026611328, "val_acc": 52.0}
{"epoch": 1, "training_loss": 331303.6640625, "training_acc": 56.0, "val_loss": 146345.32470703125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 366862.7401123047, "training_acc": 57.0, "val_loss": 128433.72802734375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 435451.0830078125, "training_acc": 47.0, "val_loss": 42536.041259765625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 198630.97265625, "training_acc": 53.0, "val_loss": 10294.709777832031, "val_acc": 44.0}
{"epoch": 5, "training_loss": 80391.89208984375, "training_acc": 48.0, "val_loss": 17446.859741210938, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69928.00122070312, "training_acc": 55.0, "val_loss": 58173.5595703125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 207235.7021484375, "training_acc": 47.0, "val_loss": 26847.821044921875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 105124.7890625, "training_acc": 54.0, "val_loss": 16385.472106933594, "val_acc": 48.0}
{"epoch": 9, "training_loss": 40545.86511230469, "training_acc": 61.0, "val_loss": 12719.015502929688, "val_acc": 52.0}
{"epoch": 10, "training_loss": 66629.55810546875, "training_acc": 48.0, "val_loss": 23414.845275878906, "val_acc": 52.0}
{"epoch": 11, "training_loss": 73876.39642333984, "training_acc": 58.0, "val_loss": 33580.87463378906, "val_acc": 48.0}
{"epoch": 12, "training_loss": 84847.34393310547, "training_acc": 54.0, "val_loss": 34822.30529785156, "val_acc": 52.0}
{"epoch": 13, "training_loss": 103538.93969726562, "training_acc": 54.0, "val_loss": 55989.239501953125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 214415.548828125, "training_acc": 47.0, "val_loss": 5023.495864868164, "val_acc": 56.0}
{"epoch": 15, "training_loss": 123050.0263671875, "training_acc": 59.0, "val_loss": 44523.18115234375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 94116.25817871094, "training_acc": 62.0, "val_loss": 50338.15612792969, "val_acc": 48.0}
{"epoch": 17, "training_loss": 164380.90600585938, "training_acc": 47.0, "val_loss": 53392.10205078125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 203374.84765625, "training_acc": 53.0, "val_loss": 34402.17590332031, "val_acc": 52.0}
{"epoch": 19, "training_loss": 114942.30859375, "training_acc": 57.0, "val_loss": 53726.641845703125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 141853.16430664062, "training_acc": 52.0, "val_loss": 72997.05200195312, "val_acc": 52.0}
{"epoch": 21, "training_loss": 317176.279296875, "training_acc": 53.0, "val_loss": 73637.35961914062, "val_acc": 52.0}
{"epoch": 22, "training_loss": 198736.0623779297, "training_acc": 51.0, "val_loss": 50033.99353027344, "val_acc": 48.0}
{"epoch": 23, "training_loss": 176054.1630859375, "training_acc": 47.0, "val_loss": 44156.75048828125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 179585.1298828125, "training_acc": 53.0, "val_loss": 28855.508422851562, "val_acc": 52.0}
{"epoch": 25, "training_loss": 101870.7744140625, "training_acc": 58.0, "val_loss": 66847.16796875, "val_acc": 48.0}
{"epoch": 26, "training_loss": 210277.36303710938, "training_acc": 47.0, "val_loss": 62738.76953125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 266324.0859375, "training_acc": 53.0, "val_loss": 67546.03271484375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 163080.51623535156, "training_acc": 57.0, "val_loss": 64752.72216796875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 258837.3798828125, "training_acc": 47.0, "val_loss": 8230.79833984375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 163909.4384765625, "training_acc": 49.0, "val_loss": 97500.01220703125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 303337.58984375, "training_acc": 53.0, "val_loss": 11081.23779296875, "val_acc": 40.0}
{"epoch": 32, "training_loss": 121089.564453125, "training_acc": 53.0, "val_loss": 17470.18280029297, "val_acc": 44.0}
{"epoch": 33, "training_loss": 103018.6904296875, "training_acc": 54.0, "val_loss": 65937.54272460938, "val_acc": 52.0}
