"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 418750.0994758606, "training_acc": 53.0, "val_loss": 13987.446594238281, "val_acc": 44.0}
{"epoch": 1, "training_loss": 509514.96484375, "training_acc": 53.0, "val_loss": 216939.55078125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 578224.0649414062, "training_acc": 44.0, "val_loss": 70261.07788085938, "val_acc": 52.0}
{"epoch": 3, "training_loss": 206149.84020996094, "training_acc": 53.0, "val_loss": 54834.014892578125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 157967.07006835938, "training_acc": 48.0, "val_loss": 15165.946960449219, "val_acc": 56.0}
{"epoch": 5, "training_loss": 107635.8271484375, "training_acc": 44.0, "val_loss": 5414.746856689453, "val_acc": 64.0}
{"epoch": 6, "training_loss": 62790.60888671875, "training_acc": 66.0, "val_loss": 14402.032470703125, "val_acc": 56.0}
{"epoch": 7, "training_loss": 148957.033203125, "training_acc": 48.0, "val_loss": 51818.71337890625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 157293.28540039062, "training_acc": 55.0, "val_loss": 39062.99133300781, "val_acc": 52.0}
{"epoch": 9, "training_loss": 94109.42980957031, "training_acc": 59.0, "val_loss": 25679.364013671875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 78972.09716796875, "training_acc": 55.0, "val_loss": 7986.674499511719, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68590.85546875, "training_acc": 52.0, "val_loss": 6802.288055419922, "val_acc": 52.0}
{"epoch": 12, "training_loss": 38266.024169921875, "training_acc": 62.0, "val_loss": 24953.707885742188, "val_acc": 48.0}
{"epoch": 13, "training_loss": 73555.72290039062, "training_acc": 50.0, "val_loss": 72744.84252929688, "val_acc": 52.0}
{"epoch": 14, "training_loss": 293399.34375, "training_acc": 53.0, "val_loss": 47030.17578125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 180548.5078125, "training_acc": 51.0, "val_loss": 71130.810546875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 234509.91357421875, "training_acc": 47.0, "val_loss": 64812.3046875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 281539.4697265625, "training_acc": 53.0, "val_loss": 77069.75708007812, "val_acc": 52.0}
{"epoch": 18, "training_loss": 168804.64459228516, "training_acc": 56.0, "val_loss": 102597.4609375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 459992.005859375, "training_acc": 47.0, "val_loss": 112259.033203125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 326031.42431640625, "training_acc": 46.0, "val_loss": 98444.81201171875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 458842.255859375, "training_acc": 53.0, "val_loss": 170534.0576171875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 579458.060546875, "training_acc": 53.0, "val_loss": 35859.53063964844, "val_acc": 52.0}
{"epoch": 23, "training_loss": 218399.595703125, "training_acc": 51.0, "val_loss": 165962.5, "val_acc": 48.0}
{"epoch": 24, "training_loss": 669457.126953125, "training_acc": 47.0, "val_loss": 103864.41650390625, "val_acc": 48.0}
