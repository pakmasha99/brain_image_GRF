"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 673419.7216072083, "training_acc": 46.0, "val_loss": 140752.5390625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 683475.17578125, "training_acc": 53.0, "val_loss": 364514.501953125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1371853.56640625, "training_acc": 47.0, "val_loss": 101042.84057617188, "val_acc": 48.0}
{"epoch": 3, "training_loss": 478026.939453125, "training_acc": 51.0, "val_loss": 266209.716796875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1011406.39453125, "training_acc": 53.0, "val_loss": 237546.97265625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 705021.259765625, "training_acc": 53.0, "val_loss": 41273.388671875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 380412.53515625, "training_acc": 47.0, "val_loss": 121669.7265625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 412411.435546875, "training_acc": 47.0, "val_loss": 88161.81030273438, "val_acc": 52.0}
{"epoch": 8, "training_loss": 343765.7216796875, "training_acc": 53.0, "val_loss": 152868.4326171875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 496386.21484375, "training_acc": 53.0, "val_loss": 19263.66424560547, "val_acc": 52.0}
{"epoch": 10, "training_loss": 198530.908203125, "training_acc": 49.0, "val_loss": 142135.7421875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 544593.2353515625, "training_acc": 47.0, "val_loss": 30150.601196289062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 197317.7548828125, "training_acc": 49.0, "val_loss": 149566.1865234375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 575038.447265625, "training_acc": 53.0, "val_loss": 112124.4140625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 301000.3173828125, "training_acc": 52.0, "val_loss": 109953.90625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 535693.7265625, "training_acc": 47.0, "val_loss": 163538.0126953125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 551752.3466796875, "training_acc": 47.0, "val_loss": 14894.944763183594, "val_acc": 60.0}
{"epoch": 17, "training_loss": 137196.765625, "training_acc": 54.0, "val_loss": 93257.63549804688, "val_acc": 52.0}
{"epoch": 18, "training_loss": 299605.37841796875, "training_acc": 53.0, "val_loss": 20567.095947265625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 90814.3759765625, "training_acc": 50.0, "val_loss": 10319.103240966797, "val_acc": 56.0}
{"epoch": 20, "training_loss": 66194.2666015625, "training_acc": 62.0, "val_loss": 15839.05029296875, "val_acc": 60.0}
{"epoch": 21, "training_loss": 58775.6611328125, "training_acc": 56.0, "val_loss": 17293.934631347656, "val_acc": 48.0}
{"epoch": 22, "training_loss": 81035.77661132812, "training_acc": 55.0, "val_loss": 43305.03845214844, "val_acc": 52.0}
{"epoch": 23, "training_loss": 80709.60363769531, "training_acc": 63.0, "val_loss": 35731.280517578125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 120477.99145507812, "training_acc": 51.0, "val_loss": 43302.66418457031, "val_acc": 52.0}
{"epoch": 25, "training_loss": 135963.8583984375, "training_acc": 55.0, "val_loss": 12333.53500366211, "val_acc": 56.0}
{"epoch": 26, "training_loss": 116097.61328125, "training_acc": 55.0, "val_loss": 39698.681640625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 140236.35498046875, "training_acc": 49.0, "val_loss": 40181.66198730469, "val_acc": 52.0}
{"epoch": 28, "training_loss": 85936.4169921875, "training_acc": 53.0, "val_loss": 45330.69763183594, "val_acc": 48.0}
{"epoch": 29, "training_loss": 182008.4677734375, "training_acc": 47.0, "val_loss": 29610.55908203125, "val_acc": 56.0}
{"epoch": 30, "training_loss": 110858.154296875, "training_acc": 54.0, "val_loss": 18874.038696289062, "val_acc": 60.0}
{"epoch": 31, "training_loss": 104565.2763671875, "training_acc": 52.0, "val_loss": 39359.04541015625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 130947.64819335938, "training_acc": 47.0, "val_loss": 27142.28515625, "val_acc": 56.0}
{"epoch": 33, "training_loss": 67518.19970703125, "training_acc": 64.0, "val_loss": 26886.859130859375, "val_acc": 48.0}
{"epoch": 34, "training_loss": 111803.45190429688, "training_acc": 43.0, "val_loss": 10059.577941894531, "val_acc": 64.0}
{"epoch": 35, "training_loss": 51841.079833984375, "training_acc": 59.0, "val_loss": 14954.278564453125, "val_acc": 56.0}
{"epoch": 36, "training_loss": 36961.61376953125, "training_acc": 60.0, "val_loss": 11139.230346679688, "val_acc": 44.0}
{"epoch": 37, "training_loss": 54648.37170410156, "training_acc": 59.0, "val_loss": 29628.372192382812, "val_acc": 52.0}
{"epoch": 38, "training_loss": 60807.06506347656, "training_acc": 55.0, "val_loss": 9729.273223876953, "val_acc": 44.0}
{"epoch": 39, "training_loss": 51680.638427734375, "training_acc": 53.0, "val_loss": 4617.054748535156, "val_acc": 60.0}
{"epoch": 40, "training_loss": 19172.421508789062, "training_acc": 65.0, "val_loss": 17122.581481933594, "val_acc": 56.0}
{"epoch": 41, "training_loss": 40944.146881103516, "training_acc": 61.0, "val_loss": 20890.835571289062, "val_acc": 48.0}
{"epoch": 42, "training_loss": 44137.728271484375, "training_acc": 56.0, "val_loss": 6150.375747680664, "val_acc": 64.0}
{"epoch": 43, "training_loss": 23206.176391601562, "training_acc": 67.0, "val_loss": 11607.418060302734, "val_acc": 56.0}
{"epoch": 44, "training_loss": 25694.47869873047, "training_acc": 63.0, "val_loss": 6362.443161010742, "val_acc": 64.0}
{"epoch": 45, "training_loss": 19371.076782226562, "training_acc": 65.0, "val_loss": 29508.493041992188, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68497.98657226562, "training_acc": 53.0, "val_loss": 55808.50830078125, "val_acc": 48.0}
{"epoch": 47, "training_loss": 240825.7822265625, "training_acc": 47.0, "val_loss": 11344.87075805664, "val_acc": 44.0}
{"epoch": 48, "training_loss": 111383.927734375, "training_acc": 57.0, "val_loss": 129531.75048828125, "val_acc": 52.0}
{"epoch": 49, "training_loss": 454813.1865234375, "training_acc": 53.0, "val_loss": 65526.69677734375, "val_acc": 52.0}
{"epoch": 50, "training_loss": 226874.07763671875, "training_acc": 45.0, "val_loss": 68270.37353515625, "val_acc": 48.0}
{"epoch": 51, "training_loss": 221244.43701171875, "training_acc": 47.0, "val_loss": 50211.58752441406, "val_acc": 52.0}
{"epoch": 52, "training_loss": 203902.4384765625, "training_acc": 53.0, "val_loss": 49560.23254394531, "val_acc": 52.0}
{"epoch": 53, "training_loss": 148763.9775390625, "training_acc": 49.0, "val_loss": 32540.335083007812, "val_acc": 48.0}
{"epoch": 54, "training_loss": 110581.33947753906, "training_acc": 52.0, "val_loss": 34179.522705078125, "val_acc": 52.0}
{"epoch": 55, "training_loss": 63997.81066894531, "training_acc": 56.0, "val_loss": 9152.413940429688, "val_acc": 56.0}
{"epoch": 56, "training_loss": 43878.23229980469, "training_acc": 58.0, "val_loss": 30270.596313476562, "val_acc": 52.0}
{"epoch": 57, "training_loss": 59082.79748535156, "training_acc": 59.0, "val_loss": 17179.812622070312, "val_acc": 44.0}
{"epoch": 58, "training_loss": 51869.517578125, "training_acc": 55.0, "val_loss": 7601.291656494141, "val_acc": 64.0}
