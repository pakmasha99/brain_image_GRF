"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 206.18959617614746, "training_acc": 48.0, "val_loss": 55.132120847702026, "val_acc": 52.0}
{"epoch": 1, "training_loss": 233.2776689529419, "training_acc": 53.0, "val_loss": 21.744881570339203, "val_acc": 44.0}
{"epoch": 2, "training_loss": 136.09446048736572, "training_acc": 55.0, "val_loss": 55.765748023986816, "val_acc": 48.0}
{"epoch": 3, "training_loss": 142.3090479373932, "training_acc": 51.0, "val_loss": 50.675082206726074, "val_acc": 52.0}
{"epoch": 4, "training_loss": 213.90631103515625, "training_acc": 53.0, "val_loss": 25.021114945411682, "val_acc": 52.0}
{"epoch": 5, "training_loss": 107.14468479156494, "training_acc": 56.0, "val_loss": 55.734461545944214, "val_acc": 48.0}
{"epoch": 6, "training_loss": 179.5620560646057, "training_acc": 47.0, "val_loss": 23.37753176689148, "val_acc": 52.0}
{"epoch": 7, "training_loss": 108.05382347106934, "training_acc": 52.0, "val_loss": 36.25383675098419, "val_acc": 52.0}
{"epoch": 8, "training_loss": 104.81913566589355, "training_acc": 61.0, "val_loss": 34.20567512512207, "val_acc": 48.0}
{"epoch": 9, "training_loss": 139.3478283882141, "training_acc": 47.0, "val_loss": 18.061725795269012, "val_acc": 60.0}
{"epoch": 10, "training_loss": 87.98159790039062, "training_acc": 56.0, "val_loss": 36.96991503238678, "val_acc": 52.0}
{"epoch": 11, "training_loss": 111.51410841941833, "training_acc": 52.0, "val_loss": 21.956731379032135, "val_acc": 44.0}
{"epoch": 12, "training_loss": 103.99102067947388, "training_acc": 47.0, "val_loss": 18.17498803138733, "val_acc": 60.0}
{"epoch": 13, "training_loss": 81.5721173286438, "training_acc": 50.0, "val_loss": 31.907138228416443, "val_acc": 52.0}
{"epoch": 14, "training_loss": 96.17331790924072, "training_acc": 55.0, "val_loss": 19.32905912399292, "val_acc": 56.0}
{"epoch": 15, "training_loss": 85.7387523651123, "training_acc": 49.0, "val_loss": 17.00286567211151, "val_acc": 64.0}
{"epoch": 16, "training_loss": 80.00155353546143, "training_acc": 52.0, "val_loss": 25.38733184337616, "val_acc": 52.0}
{"epoch": 17, "training_loss": 75.92017483711243, "training_acc": 55.0, "val_loss": 20.471781492233276, "val_acc": 40.0}
{"epoch": 18, "training_loss": 87.34304714202881, "training_acc": 51.0, "val_loss": 17.884421348571777, "val_acc": 52.0}
{"epoch": 19, "training_loss": 81.25073862075806, "training_acc": 55.0, "val_loss": 18.790939450263977, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.37491917610168, "training_acc": 51.0, "val_loss": 21.63957804441452, "val_acc": 44.0}
{"epoch": 21, "training_loss": 80.19971513748169, "training_acc": 52.0, "val_loss": 21.29901796579361, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.66090703010559, "training_acc": 54.0, "val_loss": 17.39029586315155, "val_acc": 56.0}
{"epoch": 23, "training_loss": 60.13097882270813, "training_acc": 66.0, "val_loss": 17.30542480945587, "val_acc": 56.0}
{"epoch": 24, "training_loss": 65.82434487342834, "training_acc": 55.0, "val_loss": 17.65381246805191, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.60593891143799, "training_acc": 55.0, "val_loss": 17.382138967514038, "val_acc": 52.0}
{"epoch": 26, "training_loss": 61.989116191864014, "training_acc": 65.0, "val_loss": 20.260608196258545, "val_acc": 52.0}
{"epoch": 27, "training_loss": 62.29103946685791, "training_acc": 61.0, "val_loss": 19.491760432720184, "val_acc": 52.0}
{"epoch": 28, "training_loss": 73.14178419113159, "training_acc": 49.0, "val_loss": 18.0744469165802, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.37634634971619, "training_acc": 63.0, "val_loss": 18.491487205028534, "val_acc": 52.0}
{"epoch": 30, "training_loss": 75.72362184524536, "training_acc": 46.0, "val_loss": 17.374320328235626, "val_acc": 60.0}
{"epoch": 31, "training_loss": 68.11530017852783, "training_acc": 60.0, "val_loss": 21.690724790096283, "val_acc": 52.0}
{"epoch": 32, "training_loss": 78.64820861816406, "training_acc": 48.0, "val_loss": 18.7066912651062, "val_acc": 60.0}
{"epoch": 33, "training_loss": 64.57249426841736, "training_acc": 60.0, "val_loss": 25.07450580596924, "val_acc": 52.0}
{"epoch": 34, "training_loss": 77.35860586166382, "training_acc": 54.0, "val_loss": 17.507602274417877, "val_acc": 56.0}
