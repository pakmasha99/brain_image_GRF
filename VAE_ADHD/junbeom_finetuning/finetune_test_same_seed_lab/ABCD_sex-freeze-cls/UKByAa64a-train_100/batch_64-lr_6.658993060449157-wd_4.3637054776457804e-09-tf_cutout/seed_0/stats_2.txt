"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 7525.211441040039, "training_acc": 48.0, "val_loss": 2504.109001159668, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10473.385833740234, "training_acc": 53.0, "val_loss": 513.045072555542, "val_acc": 44.0}
{"epoch": 2, "training_loss": 4857.739776611328, "training_acc": 54.0, "val_loss": 1762.1896743774414, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4395.28205871582, "training_acc": 56.0, "val_loss": 1526.5963554382324, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4885.055458068848, "training_acc": 53.0, "val_loss": 1766.581153869629, "val_acc": 48.0}
{"epoch": 5, "training_loss": 5585.99267578125, "training_acc": 48.0, "val_loss": 530.4905414581299, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2640.2971572875977, "training_acc": 52.0, "val_loss": 384.81059074401855, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1970.019142150879, "training_acc": 49.0, "val_loss": 940.0285720825195, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3185.8525390625, "training_acc": 53.0, "val_loss": 421.65355682373047, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1771.8150482177734, "training_acc": 49.0, "val_loss": 1055.1885604858398, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3381.160354614258, "training_acc": 53.0, "val_loss": 146.78221940994263, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1308.2075271606445, "training_acc": 54.0, "val_loss": 403.1620502471924, "val_acc": 52.0}
{"epoch": 12, "training_loss": 825.7555236816406, "training_acc": 56.0, "val_loss": 373.31647872924805, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1605.7136764526367, "training_acc": 50.0, "val_loss": 445.0070858001709, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1248.5310287475586, "training_acc": 55.0, "val_loss": 171.6892957687378, "val_acc": 56.0}
{"epoch": 15, "training_loss": 667.0570392608643, "training_acc": 60.0, "val_loss": 385.8088493347168, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1470.8563766479492, "training_acc": 47.0, "val_loss": 174.40422773361206, "val_acc": 44.0}
{"epoch": 17, "training_loss": 500.6930103302002, "training_acc": 66.0, "val_loss": 370.6655740737915, "val_acc": 52.0}
{"epoch": 18, "training_loss": 937.8636455535889, "training_acc": 57.0, "val_loss": 298.459529876709, "val_acc": 52.0}
{"epoch": 19, "training_loss": 751.5282096862793, "training_acc": 63.0, "val_loss": 319.85931396484375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 683.2217502593994, "training_acc": 59.0, "val_loss": 287.57054805755615, "val_acc": 52.0}
{"epoch": 21, "training_loss": 835.265064239502, "training_acc": 54.0, "val_loss": 515.3414249420166, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1037.4872274398804, "training_acc": 52.0, "val_loss": 179.90130186080933, "val_acc": 64.0}
{"epoch": 23, "training_loss": 305.66251945495605, "training_acc": 75.0, "val_loss": 142.5152063369751, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1388.0689086914062, "training_acc": 52.0, "val_loss": 122.61195182800293, "val_acc": 64.0}
{"epoch": 25, "training_loss": 1139.7646713256836, "training_acc": 62.0, "val_loss": 320.45748233795166, "val_acc": 52.0}
{"epoch": 26, "training_loss": 788.4690704345703, "training_acc": 64.0, "val_loss": 319.37146186828613, "val_acc": 44.0}
{"epoch": 27, "training_loss": 1325.891960144043, "training_acc": 47.0, "val_loss": 219.78812217712402, "val_acc": 44.0}
{"epoch": 28, "training_loss": 646.5437908172607, "training_acc": 52.0, "val_loss": 721.0209846496582, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1779.692008972168, "training_acc": 55.0, "val_loss": 1146.911334991455, "val_acc": 48.0}
{"epoch": 30, "training_loss": 4537.4871826171875, "training_acc": 47.0, "val_loss": 258.4141254425049, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1214.8835067749023, "training_acc": 59.0, "val_loss": 144.00323629379272, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1618.9307861328125, "training_acc": 54.0, "val_loss": 276.17316246032715, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1739.8128356933594, "training_acc": 59.0, "val_loss": 1794.4786071777344, "val_acc": 52.0}
{"epoch": 34, "training_loss": 5589.2027587890625, "training_acc": 53.0, "val_loss": 590.3826713562012, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2349.5409088134766, "training_acc": 49.0, "val_loss": 262.93318271636963, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1058.2399139404297, "training_acc": 61.0, "val_loss": 437.8486633300781, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1152.5147113800049, "training_acc": 51.0, "val_loss": 934.7367286682129, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2849.538444519043, "training_acc": 53.0, "val_loss": 377.4425983428955, "val_acc": 44.0}
{"epoch": 39, "training_loss": 1131.2361679077148, "training_acc": 51.0, "val_loss": 632.4840068817139, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1537.537223815918, "training_acc": 56.0, "val_loss": 752.8900623321533, "val_acc": 48.0}
{"epoch": 41, "training_loss": 2593.615020751953, "training_acc": 47.0, "val_loss": 928.147029876709, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3306.286392211914, "training_acc": 53.0, "val_loss": 268.48037242889404, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2203.7408142089844, "training_acc": 56.0, "val_loss": 1748.0899810791016, "val_acc": 48.0}
