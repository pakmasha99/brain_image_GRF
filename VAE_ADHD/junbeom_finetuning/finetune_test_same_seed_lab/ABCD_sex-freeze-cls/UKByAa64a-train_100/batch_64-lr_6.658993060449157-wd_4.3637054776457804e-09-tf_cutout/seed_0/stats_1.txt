"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 14029.981006622314, "training_acc": 46.0, "val_loss": 2923.20613861084, "val_acc": 52.0}
{"epoch": 1, "training_loss": 14195.607727050781, "training_acc": 53.0, "val_loss": 7570.839691162109, "val_acc": 48.0}
{"epoch": 2, "training_loss": 28492.570190429688, "training_acc": 47.0, "val_loss": 2098.705291748047, "val_acc": 48.0}
{"epoch": 3, "training_loss": 9928.20962524414, "training_acc": 51.0, "val_loss": 5528.868103027344, "val_acc": 52.0}
{"epoch": 4, "training_loss": 21006.317260742188, "training_acc": 53.0, "val_loss": 4933.562469482422, "val_acc": 52.0}
{"epoch": 5, "training_loss": 14642.840728759766, "training_acc": 53.0, "val_loss": 857.3311805725098, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7901.0345458984375, "training_acc": 47.0, "val_loss": 2527.1108627319336, "val_acc": 48.0}
{"epoch": 7, "training_loss": 8565.409942626953, "training_acc": 47.0, "val_loss": 1830.9301376342773, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7139.780242919922, "training_acc": 53.0, "val_loss": 3174.845314025879, "val_acc": 52.0}
{"epoch": 9, "training_loss": 10309.65444946289, "training_acc": 53.0, "val_loss": 400.1150608062744, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4156.485656738281, "training_acc": 49.0, "val_loss": 2989.5782470703125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 11482.832977294922, "training_acc": 47.0, "val_loss": 695.4939842224121, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4167.6617431640625, "training_acc": 49.0, "val_loss": 3019.828224182129, "val_acc": 52.0}
{"epoch": 13, "training_loss": 11581.365478515625, "training_acc": 53.0, "val_loss": 2224.7671127319336, "val_acc": 52.0}
{"epoch": 14, "training_loss": 5866.388786315918, "training_acc": 52.0, "val_loss": 2163.51318359375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 10323.833190917969, "training_acc": 47.0, "val_loss": 2851.9521713256836, "val_acc": 48.0}
{"epoch": 16, "training_loss": 9085.918594360352, "training_acc": 47.0, "val_loss": 1114.9765014648438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5415.829040527344, "training_acc": 53.0, "val_loss": 2315.2971267700195, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7535.290153503418, "training_acc": 53.0, "val_loss": 384.90843772888184, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2072.135383605957, "training_acc": 54.0, "val_loss": 334.5130920410156, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2700.754608154297, "training_acc": 47.0, "val_loss": 1296.0978507995605, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3134.5339393615723, "training_acc": 59.0, "val_loss": 948.6469268798828, "val_acc": 48.0}
{"epoch": 22, "training_loss": 4119.06022644043, "training_acc": 47.0, "val_loss": 217.43991374969482, "val_acc": 36.0}
{"epoch": 23, "training_loss": 2489.077407836914, "training_acc": 47.0, "val_loss": 1806.587791442871, "val_acc": 52.0}
{"epoch": 24, "training_loss": 5316.029998779297, "training_acc": 52.0, "val_loss": 263.4824275970459, "val_acc": 36.0}
{"epoch": 25, "training_loss": 2402.7283325195312, "training_acc": 57.0, "val_loss": 472.02415466308594, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1695.6249923706055, "training_acc": 58.0, "val_loss": 1302.1037101745605, "val_acc": 52.0}
{"epoch": 27, "training_loss": 3085.720458984375, "training_acc": 54.0, "val_loss": 692.338752746582, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3410.803482055664, "training_acc": 47.0, "val_loss": 231.35428428649902, "val_acc": 56.0}
{"epoch": 29, "training_loss": 1223.897201538086, "training_acc": 65.0, "val_loss": 1279.8559188842773, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3120.915958404541, "training_acc": 53.0, "val_loss": 865.3371810913086, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4219.261795043945, "training_acc": 47.0, "val_loss": 228.91638278961182, "val_acc": 52.0}
{"epoch": 32, "training_loss": 2405.207229614258, "training_acc": 58.0, "val_loss": 1646.5503692626953, "val_acc": 52.0}
{"epoch": 33, "training_loss": 3799.9034729003906, "training_acc": 52.0, "val_loss": 817.4167633056641, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4540.690246582031, "training_acc": 47.0, "val_loss": 495.3680992126465, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2927.764259338379, "training_acc": 48.0, "val_loss": 1559.7243309020996, "val_acc": 52.0}
{"epoch": 36, "training_loss": 3971.598129272461, "training_acc": 55.0, "val_loss": 208.81006717681885, "val_acc": 56.0}
{"epoch": 37, "training_loss": 2518.089096069336, "training_acc": 54.0, "val_loss": 378.65819931030273, "val_acc": 56.0}
{"epoch": 38, "training_loss": 1582.0195693969727, "training_acc": 56.0, "val_loss": 656.892204284668, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1819.175682067871, "training_acc": 54.0, "val_loss": 246.85754776000977, "val_acc": 44.0}
{"epoch": 40, "training_loss": 1614.928695678711, "training_acc": 56.0, "val_loss": 813.4114265441895, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1864.2972106933594, "training_acc": 58.0, "val_loss": 572.1982955932617, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1512.3069190979004, "training_acc": 59.0, "val_loss": 993.6267852783203, "val_acc": 52.0}
{"epoch": 43, "training_loss": 3457.2818450927734, "training_acc": 52.0, "val_loss": 119.81528997421265, "val_acc": 56.0}
{"epoch": 44, "training_loss": 1466.001350402832, "training_acc": 64.0, "val_loss": 769.2549228668213, "val_acc": 48.0}
{"epoch": 45, "training_loss": 2038.8144607543945, "training_acc": 56.0, "val_loss": 715.0424003601074, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1449.7827243804932, "training_acc": 63.0, "val_loss": 875.2841949462891, "val_acc": 48.0}
{"epoch": 47, "training_loss": 3338.489112854004, "training_acc": 47.0, "val_loss": 605.0931930541992, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1932.0517883300781, "training_acc": 53.0, "val_loss": 153.54207754135132, "val_acc": 64.0}
{"epoch": 49, "training_loss": 1325.5296096801758, "training_acc": 61.0, "val_loss": 124.03310537338257, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1403.7273635864258, "training_acc": 61.0, "val_loss": 1088.8690948486328, "val_acc": 52.0}
{"epoch": 51, "training_loss": 2482.3312377929688, "training_acc": 61.0, "val_loss": 1016.4201736450195, "val_acc": 48.0}
{"epoch": 52, "training_loss": 4562.409744262695, "training_acc": 48.0, "val_loss": 74.71580505371094, "val_acc": 72.0}
{"epoch": 53, "training_loss": 1296.5218505859375, "training_acc": 68.0, "val_loss": 870.804500579834, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1982.3313312530518, "training_acc": 56.0, "val_loss": 316.14952087402344, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1156.2054748535156, "training_acc": 59.0, "val_loss": 524.7711181640625, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1600.5892486572266, "training_acc": 46.0, "val_loss": 117.64452457427979, "val_acc": 64.0}
{"epoch": 57, "training_loss": 665.0287475585938, "training_acc": 63.0, "val_loss": 83.08639526367188, "val_acc": 52.0}
{"epoch": 58, "training_loss": 619.5853900909424, "training_acc": 61.0, "val_loss": 630.7684898376465, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1667.0061645507812, "training_acc": 54.0, "val_loss": 700.86669921875, "val_acc": 48.0}
{"epoch": 60, "training_loss": 2699.163303375244, "training_acc": 47.0, "val_loss": 531.1909198760986, "val_acc": 52.0}
{"epoch": 61, "training_loss": 1749.6239166259766, "training_acc": 55.0, "val_loss": 275.29003620147705, "val_acc": 52.0}
{"epoch": 62, "training_loss": 1052.8674411773682, "training_acc": 52.0, "val_loss": 200.12133121490479, "val_acc": 64.0}
{"epoch": 63, "training_loss": 554.0683479309082, "training_acc": 57.0, "val_loss": 501.5876293182373, "val_acc": 52.0}
{"epoch": 64, "training_loss": 1010.0406246185303, "training_acc": 58.0, "val_loss": 435.1724624633789, "val_acc": 48.0}
{"epoch": 65, "training_loss": 1365.269338607788, "training_acc": 53.0, "val_loss": 634.5208644866943, "val_acc": 52.0}
{"epoch": 66, "training_loss": 1268.992654800415, "training_acc": 55.0, "val_loss": 483.46872329711914, "val_acc": 48.0}
{"epoch": 67, "training_loss": 1529.3355731964111, "training_acc": 47.0, "val_loss": 237.386155128479, "val_acc": 60.0}
{"epoch": 68, "training_loss": 483.1289367675781, "training_acc": 67.0, "val_loss": 342.6349639892578, "val_acc": 56.0}
{"epoch": 69, "training_loss": 454.9738492965698, "training_acc": 64.0, "val_loss": 336.76936626434326, "val_acc": 48.0}
{"epoch": 70, "training_loss": 769.2507514953613, "training_acc": 60.0, "val_loss": 105.60760498046875, "val_acc": 60.0}
{"epoch": 71, "training_loss": 451.3673400878906, "training_acc": 69.0, "val_loss": 500.0980854034424, "val_acc": 52.0}
