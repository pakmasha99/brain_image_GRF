"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3894.9448471069336, "training_acc": 53.0, "val_loss": 4750.317764282227, "val_acc": 48.0}
{"epoch": 1, "training_loss": 17535.6435546875, "training_acc": 47.0, "val_loss": 745.1989650726318, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4098.283279418945, "training_acc": 59.0, "val_loss": 807.2715759277344, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5284.878692626953, "training_acc": 50.0, "val_loss": 1988.9411926269531, "val_acc": 48.0}
{"epoch": 4, "training_loss": 6270.3237228393555, "training_acc": 41.0, "val_loss": 646.0152626037598, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2317.2235412597656, "training_acc": 52.0, "val_loss": 259.96735095977783, "val_acc": 40.0}
{"epoch": 6, "training_loss": 1373.0440063476562, "training_acc": 55.0, "val_loss": 249.42800998687744, "val_acc": 40.0}
{"epoch": 7, "training_loss": 1261.1302032470703, "training_acc": 53.0, "val_loss": 268.04518699645996, "val_acc": 52.0}
{"epoch": 8, "training_loss": 949.3588352203369, "training_acc": 61.0, "val_loss": 564.3921375274658, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1480.203727722168, "training_acc": 50.0, "val_loss": 210.38854122161865, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1168.4455337524414, "training_acc": 51.0, "val_loss": 165.65691232681274, "val_acc": 48.0}
{"epoch": 11, "training_loss": 970.9560813903809, "training_acc": 63.0, "val_loss": 606.1801433563232, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1088.7810707092285, "training_acc": 58.0, "val_loss": 839.1913414001465, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2714.07706451416, "training_acc": 53.0, "val_loss": 1113.9660835266113, "val_acc": 48.0}
{"epoch": 14, "training_loss": 3917.2105102539062, "training_acc": 47.0, "val_loss": 300.6246328353882, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1634.757064819336, "training_acc": 55.0, "val_loss": 205.2527666091919, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1636.5654983520508, "training_acc": 59.0, "val_loss": 476.04331970214844, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1752.888786315918, "training_acc": 57.0, "val_loss": 1126.2840270996094, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2784.9732093811035, "training_acc": 58.0, "val_loss": 1531.4191818237305, "val_acc": 48.0}
{"epoch": 19, "training_loss": 5574.92707824707, "training_acc": 47.0, "val_loss": 403.50756645202637, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3016.850296020508, "training_acc": 56.0, "val_loss": 2454.4652938842773, "val_acc": 52.0}
{"epoch": 21, "training_loss": 8712.509765625, "training_acc": 53.0, "val_loss": 484.9930763244629, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4235.817718505859, "training_acc": 45.0, "val_loss": 2791.5721893310547, "val_acc": 48.0}
{"epoch": 23, "training_loss": 9458.570190429688, "training_acc": 47.0, "val_loss": 235.28196811676025, "val_acc": 52.0}
{"epoch": 24, "training_loss": 3989.0336303710938, "training_acc": 54.0, "val_loss": 2352.915382385254, "val_acc": 52.0}
{"epoch": 25, "training_loss": 8083.256530761719, "training_acc": 53.0, "val_loss": 213.6587381362915, "val_acc": 60.0}
{"epoch": 26, "training_loss": 3501.277099609375, "training_acc": 49.0, "val_loss": 2306.0760498046875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 6913.077224731445, "training_acc": 48.0, "val_loss": 426.902437210083, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2932.97216796875, "training_acc": 54.0, "val_loss": 925.5019187927246, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2613.909854888916, "training_acc": 57.0, "val_loss": 996.1742401123047, "val_acc": 48.0}
