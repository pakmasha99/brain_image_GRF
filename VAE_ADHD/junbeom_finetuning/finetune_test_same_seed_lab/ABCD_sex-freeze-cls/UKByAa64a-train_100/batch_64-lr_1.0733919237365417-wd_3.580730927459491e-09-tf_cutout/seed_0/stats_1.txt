"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2580.5846939086914, "training_acc": 53.0, "val_loss": 507.6777935028076, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2990.554397583008, "training_acc": 41.0, "val_loss": 1092.4710273742676, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4020.4943084716797, "training_acc": 47.0, "val_loss": 254.9262523651123, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1071.1477851867676, "training_acc": 59.0, "val_loss": 900.8475303649902, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3433.3373794555664, "training_acc": 53.0, "val_loss": 864.3148422241211, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2727.01668548584, "training_acc": 53.0, "val_loss": 53.29928994178772, "val_acc": 48.0}
{"epoch": 6, "training_loss": 714.2913818359375, "training_acc": 57.0, "val_loss": 720.0806617736816, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2886.4353637695312, "training_acc": 47.0, "val_loss": 404.793643951416, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1347.7912149429321, "training_acc": 42.0, "val_loss": 304.97190952301025, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1036.6762580871582, "training_acc": 55.0, "val_loss": 183.2855463027954, "val_acc": 52.0}
{"epoch": 10, "training_loss": 625.8816833496094, "training_acc": 45.0, "val_loss": 173.3959674835205, "val_acc": 48.0}
{"epoch": 11, "training_loss": 532.5044317245483, "training_acc": 56.0, "val_loss": 214.9106740951538, "val_acc": 52.0}
{"epoch": 12, "training_loss": 774.1015739440918, "training_acc": 53.0, "val_loss": 97.87219762802124, "val_acc": 52.0}
{"epoch": 13, "training_loss": 773.125431060791, "training_acc": 36.0, "val_loss": 300.10876655578613, "val_acc": 48.0}
{"epoch": 14, "training_loss": 992.1712169647217, "training_acc": 47.0, "val_loss": 174.70717430114746, "val_acc": 52.0}
{"epoch": 15, "training_loss": 915.65869140625, "training_acc": 53.0, "val_loss": 219.34823989868164, "val_acc": 52.0}
{"epoch": 16, "training_loss": 593.2375450134277, "training_acc": 57.0, "val_loss": 242.708420753479, "val_acc": 48.0}
{"epoch": 17, "training_loss": 887.2508697509766, "training_acc": 47.0, "val_loss": 82.98114538192749, "val_acc": 52.0}
{"epoch": 18, "training_loss": 439.9286308288574, "training_acc": 50.0, "val_loss": 265.70887565612793, "val_acc": 52.0}
{"epoch": 19, "training_loss": 943.9063911437988, "training_acc": 53.0, "val_loss": 76.1150062084198, "val_acc": 52.0}
{"epoch": 20, "training_loss": 384.85413551330566, "training_acc": 47.0, "val_loss": 91.69875979423523, "val_acc": 48.0}
{"epoch": 21, "training_loss": 287.9021158218384, "training_acc": 54.0, "val_loss": 157.26805925369263, "val_acc": 52.0}
{"epoch": 22, "training_loss": 427.8786187171936, "training_acc": 54.0, "val_loss": 208.74416828155518, "val_acc": 48.0}
{"epoch": 23, "training_loss": 866.415958404541, "training_acc": 47.0, "val_loss": 92.17098951339722, "val_acc": 48.0}
{"epoch": 24, "training_loss": 338.511700630188, "training_acc": 59.0, "val_loss": 320.92442512512207, "val_acc": 52.0}
