"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 485643.19426345825, "training_acc": 46.0, "val_loss": 101502.40478515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 492882.30078125, "training_acc": 53.0, "val_loss": 262866.552734375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 989300.75, "training_acc": 47.0, "val_loss": 72866.21704101562, "val_acc": 48.0}
{"epoch": 3, "training_loss": 344725.0224609375, "training_acc": 51.0, "val_loss": 191974.8046875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 729366.97265625, "training_acc": 53.0, "val_loss": 171304.87060546875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 508419.8603515625, "training_acc": 53.0, "val_loss": 29764.089965820312, "val_acc": 48.0}
{"epoch": 6, "training_loss": 274331.623046875, "training_acc": 47.0, "val_loss": 87741.19262695312, "val_acc": 48.0}
{"epoch": 7, "training_loss": 297407.23486328125, "training_acc": 47.0, "val_loss": 63577.032470703125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 247903.5146484375, "training_acc": 53.0, "val_loss": 110239.6484375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 357964.419921875, "training_acc": 53.0, "val_loss": 13891.691589355469, "val_acc": 52.0}
{"epoch": 10, "training_loss": 143168.8037109375, "training_acc": 49.0, "val_loss": 102500.10986328125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 392729.0791015625, "training_acc": 47.0, "val_loss": 21742.97637939453, "val_acc": 48.0}
{"epoch": 12, "training_loss": 142294.203125, "training_acc": 49.0, "val_loss": 107858.251953125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 414683.818359375, "training_acc": 53.0, "val_loss": 80857.43408203125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 217063.51000976562, "training_acc": 52.0, "val_loss": 79292.48046875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 386311.439453125, "training_acc": 47.0, "val_loss": 117934.1796875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 397891.8974609375, "training_acc": 47.0, "val_loss": 10741.239929199219, "val_acc": 60.0}
{"epoch": 17, "training_loss": 99050.8115234375, "training_acc": 54.0, "val_loss": 67408.63647460938, "val_acc": 52.0}
{"epoch": 18, "training_loss": 216700.8984375, "training_acc": 53.0, "val_loss": 14525.070190429688, "val_acc": 48.0}
{"epoch": 19, "training_loss": 65711.2626953125, "training_acc": 51.0, "val_loss": 6795.903015136719, "val_acc": 56.0}
{"epoch": 20, "training_loss": 53124.05029296875, "training_acc": 58.0, "val_loss": 16803.160095214844, "val_acc": 56.0}
{"epoch": 21, "training_loss": 56072.027099609375, "training_acc": 52.0, "val_loss": 24871.47216796875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 74707.369140625, "training_acc": 52.0, "val_loss": 31277.871704101562, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66817.56823730469, "training_acc": 58.0, "val_loss": 22272.425842285156, "val_acc": 48.0}
{"epoch": 24, "training_loss": 83915.50366210938, "training_acc": 49.0, "val_loss": 24806.09893798828, "val_acc": 52.0}
{"epoch": 25, "training_loss": 81565.67822265625, "training_acc": 56.0, "val_loss": 9435.381317138672, "val_acc": 56.0}
{"epoch": 26, "training_loss": 81083.7236328125, "training_acc": 54.0, "val_loss": 25834.707641601562, "val_acc": 48.0}
{"epoch": 27, "training_loss": 93178.60986328125, "training_acc": 50.0, "val_loss": 27798.6572265625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 58534.578186035156, "training_acc": 57.0, "val_loss": 21730.026245117188, "val_acc": 48.0}
{"epoch": 29, "training_loss": 66250.06030273438, "training_acc": 52.0, "val_loss": 46174.97863769531, "val_acc": 52.0}
{"epoch": 30, "training_loss": 169918.2822265625, "training_acc": 53.0, "val_loss": 35657.57751464844, "val_acc": 52.0}
{"epoch": 31, "training_loss": 108413.103515625, "training_acc": 48.0, "val_loss": 29497.933959960938, "val_acc": 48.0}
{"epoch": 32, "training_loss": 85085.91217041016, "training_acc": 52.0, "val_loss": 21788.4765625, "val_acc": 56.0}
{"epoch": 33, "training_loss": 52713.11291503906, "training_acc": 61.0, "val_loss": 22872.430419921875, "val_acc": 48.0}
{"epoch": 34, "training_loss": 82162.37603759766, "training_acc": 51.0, "val_loss": 21885.171508789062, "val_acc": 56.0}
{"epoch": 35, "training_loss": 60362.32653808594, "training_acc": 55.0, "val_loss": 18182.36083984375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 64230.05432128906, "training_acc": 51.0, "val_loss": 20946.800231933594, "val_acc": 56.0}
{"epoch": 37, "training_loss": 42573.98840332031, "training_acc": 55.0, "val_loss": 18897.10235595703, "val_acc": 48.0}
{"epoch": 38, "training_loss": 73684.9677734375, "training_acc": 49.0, "val_loss": 32043.002319335938, "val_acc": 52.0}
{"epoch": 39, "training_loss": 106571.6787109375, "training_acc": 54.0, "val_loss": 6490.580749511719, "val_acc": 64.0}
{"epoch": 40, "training_loss": 45370.8359375, "training_acc": 59.0, "val_loss": 7285.601043701172, "val_acc": 44.0}
{"epoch": 41, "training_loss": 66888.125, "training_acc": 53.0, "val_loss": 50796.30432128906, "val_acc": 52.0}
{"epoch": 42, "training_loss": 145560.99731445312, "training_acc": 53.0, "val_loss": 32458.816528320312, "val_acc": 48.0}
{"epoch": 43, "training_loss": 138483.31005859375, "training_acc": 47.0, "val_loss": 10640.200805664062, "val_acc": 48.0}
{"epoch": 44, "training_loss": 93881.49072265625, "training_acc": 47.0, "val_loss": 67262.255859375, "val_acc": 52.0}
{"epoch": 45, "training_loss": 213585.91357421875, "training_acc": 53.0, "val_loss": 3637.617874145508, "val_acc": 48.0}
{"epoch": 46, "training_loss": 45993.25, "training_acc": 61.0, "val_loss": 12287.96157836914, "val_acc": 48.0}
{"epoch": 47, "training_loss": 71010.14575195312, "training_acc": 51.0, "val_loss": 39731.93664550781, "val_acc": 52.0}
{"epoch": 48, "training_loss": 101720.65350341797, "training_acc": 53.0, "val_loss": 40034.320068359375, "val_acc": 48.0}
{"epoch": 49, "training_loss": 156797.53076171875, "training_acc": 47.0, "val_loss": 6465.325927734375, "val_acc": 40.0}
{"epoch": 50, "training_loss": 54320.45703125, "training_acc": 67.0, "val_loss": 47557.09228515625, "val_acc": 52.0}
{"epoch": 51, "training_loss": 140515.14379882812, "training_acc": 54.0, "val_loss": 32733.175659179688, "val_acc": 48.0}
{"epoch": 52, "training_loss": 144763.779296875, "training_acc": 47.0, "val_loss": 21263.755798339844, "val_acc": 52.0}
{"epoch": 53, "training_loss": 74363.35083007812, "training_acc": 51.0, "val_loss": 42900.74768066406, "val_acc": 52.0}
{"epoch": 54, "training_loss": 134529.59936523438, "training_acc": 53.0, "val_loss": 34028.03955078125, "val_acc": 48.0}
{"epoch": 55, "training_loss": 141522.13525390625, "training_acc": 47.0, "val_loss": 22293.9453125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 78284.03466796875, "training_acc": 59.0, "val_loss": 54527.069091796875, "val_acc": 52.0}
{"epoch": 57, "training_loss": 185789.587890625, "training_acc": 53.0, "val_loss": 5208.738327026367, "val_acc": 40.0}
{"epoch": 58, "training_loss": 73850.52294921875, "training_acc": 56.0, "val_loss": 18916.741943359375, "val_acc": 48.0}
{"epoch": 59, "training_loss": 89599.91259765625, "training_acc": 45.0, "val_loss": 47775.38146972656, "val_acc": 52.0}
{"epoch": 60, "training_loss": 131994.31494140625, "training_acc": 53.0, "val_loss": 31181.060791015625, "val_acc": 48.0}
{"epoch": 61, "training_loss": 149643.1015625, "training_acc": 47.0, "val_loss": 21108.749389648438, "val_acc": 48.0}
{"epoch": 62, "training_loss": 114862.5517578125, "training_acc": 48.0, "val_loss": 59849.90234375, "val_acc": 52.0}
{"epoch": 63, "training_loss": 160646.8330078125, "training_acc": 53.0, "val_loss": 6613.043975830078, "val_acc": 52.0}
{"epoch": 64, "training_loss": 77090.10205078125, "training_acc": 55.0, "val_loss": 5915.048599243164, "val_acc": 48.0}
