"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 322725.1454696655, "training_acc": 51.0, "val_loss": 9341.216278076172, "val_acc": 44.0}
{"epoch": 1, "training_loss": 35298.48864746094, "training_acc": 45.0, "val_loss": 111088.525390625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 388534.84716796875, "training_acc": 47.0, "val_loss": 44076.33361816406, "val_acc": 52.0}
{"epoch": 3, "training_loss": 185821.796875, "training_acc": 53.0, "val_loss": 3972.7745056152344, "val_acc": 52.0}
{"epoch": 4, "training_loss": 78146.22509765625, "training_acc": 51.0, "val_loss": 16664.886474609375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 58571.370361328125, "training_acc": 54.0, "val_loss": 39762.48474121094, "val_acc": 48.0}
{"epoch": 6, "training_loss": 151435.35400390625, "training_acc": 47.0, "val_loss": 23862.28790283203, "val_acc": 52.0}
{"epoch": 7, "training_loss": 107736.16455078125, "training_acc": 53.0, "val_loss": 3794.3531036376953, "val_acc": 56.0}
{"epoch": 8, "training_loss": 78807.2802734375, "training_acc": 52.0, "val_loss": 29505.731201171875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 107565.70361328125, "training_acc": 51.0, "val_loss": 40080.89904785156, "val_acc": 52.0}
{"epoch": 10, "training_loss": 115659.74536132812, "training_acc": 54.0, "val_loss": 51372.9736328125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 205929.0380859375, "training_acc": 47.0, "val_loss": 29231.93359375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 132017.7001953125, "training_acc": 45.0, "val_loss": 58849.188232421875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 200584.6796875, "training_acc": 53.0, "val_loss": 10852.375030517578, "val_acc": 44.0}
{"epoch": 14, "training_loss": 48663.38671875, "training_acc": 57.0, "val_loss": 4592.60139465332, "val_acc": 48.0}
{"epoch": 15, "training_loss": 44225.227783203125, "training_acc": 50.0, "val_loss": 10200.7568359375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 52311.708251953125, "training_acc": 60.0, "val_loss": 34058.85009765625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 88027.01123046875, "training_acc": 54.0, "val_loss": 25808.87451171875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 64629.96124267578, "training_acc": 56.0, "val_loss": 24771.124267578125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 69948.77587890625, "training_acc": 49.0, "val_loss": 37443.76220703125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 157632.529296875, "training_acc": 53.0, "val_loss": 20388.86260986328, "val_acc": 52.0}
{"epoch": 21, "training_loss": 110939.35205078125, "training_acc": 49.0, "val_loss": 65383.82568359375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 216914.67822265625, "training_acc": 47.0, "val_loss": 23142.901611328125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 95115.3232421875, "training_acc": 53.0, "val_loss": 24449.581909179688, "val_acc": 52.0}
{"epoch": 24, "training_loss": 80235.87329101562, "training_acc": 52.0, "val_loss": 25384.503173828125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 78895.09655761719, "training_acc": 54.0, "val_loss": 20004.005432128906, "val_acc": 52.0}
{"epoch": 26, "training_loss": 48657.231506347656, "training_acc": 57.0, "val_loss": 22815.203857421875, "val_acc": 48.0}
