"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 426.4423294067383, "training_acc": 53.0, "val_loss": 20.364390313625336, "val_acc": 56.0}
{"epoch": 1, "training_loss": 306.78715324401855, "training_acc": 52.0, "val_loss": 96.49165272712708, "val_acc": 48.0}
{"epoch": 2, "training_loss": 322.6756772994995, "training_acc": 51.0, "val_loss": 115.60237407684326, "val_acc": 52.0}
{"epoch": 3, "training_loss": 406.31817626953125, "training_acc": 53.0, "val_loss": 33.529892563819885, "val_acc": 48.0}
{"epoch": 4, "training_loss": 151.7451491355896, "training_acc": 47.0, "val_loss": 17.503219842910767, "val_acc": 56.0}
{"epoch": 5, "training_loss": 124.76568508148193, "training_acc": 56.0, "val_loss": 28.741472959518433, "val_acc": 52.0}
{"epoch": 6, "training_loss": 135.05301666259766, "training_acc": 45.0, "val_loss": 33.90846252441406, "val_acc": 48.0}
{"epoch": 7, "training_loss": 123.79972696304321, "training_acc": 49.0, "val_loss": 36.96908354759216, "val_acc": 52.0}
{"epoch": 8, "training_loss": 115.27235150337219, "training_acc": 54.0, "val_loss": 34.00743305683136, "val_acc": 48.0}
{"epoch": 9, "training_loss": 128.23218154907227, "training_acc": 48.0, "val_loss": 20.929019153118134, "val_acc": 52.0}
{"epoch": 10, "training_loss": 88.90866208076477, "training_acc": 57.0, "val_loss": 19.389431178569794, "val_acc": 56.0}
{"epoch": 11, "training_loss": 90.6011700630188, "training_acc": 51.0, "val_loss": 17.858248949050903, "val_acc": 56.0}
{"epoch": 12, "training_loss": 82.302241563797, "training_acc": 52.0, "val_loss": 20.554010570049286, "val_acc": 52.0}
{"epoch": 13, "training_loss": 80.37753033638, "training_acc": 49.0, "val_loss": 17.03300029039383, "val_acc": 60.0}
{"epoch": 14, "training_loss": 70.27126407623291, "training_acc": 59.0, "val_loss": 21.59361243247986, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.5632221698761, "training_acc": 57.0, "val_loss": 19.51327621936798, "val_acc": 56.0}
{"epoch": 16, "training_loss": 74.43748569488525, "training_acc": 59.0, "val_loss": 20.488429069519043, "val_acc": 52.0}
{"epoch": 17, "training_loss": 75.3727777004242, "training_acc": 58.0, "val_loss": 17.972691357135773, "val_acc": 56.0}
{"epoch": 18, "training_loss": 73.35344219207764, "training_acc": 56.0, "val_loss": 20.323936641216278, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.37477588653564, "training_acc": 62.0, "val_loss": 16.612263023853302, "val_acc": 64.0}
{"epoch": 20, "training_loss": 63.23030686378479, "training_acc": 66.0, "val_loss": 17.32790917158127, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.91186547279358, "training_acc": 53.0, "val_loss": 23.781612515449524, "val_acc": 52.0}
{"epoch": 22, "training_loss": 79.57746386528015, "training_acc": 49.0, "val_loss": 18.51419359445572, "val_acc": 52.0}
{"epoch": 23, "training_loss": 62.61819672584534, "training_acc": 64.0, "val_loss": 18.438240885734558, "val_acc": 52.0}
{"epoch": 24, "training_loss": 59.11021161079407, "training_acc": 62.0, "val_loss": 17.743632197380066, "val_acc": 60.0}
{"epoch": 25, "training_loss": 64.87473797798157, "training_acc": 57.0, "val_loss": 25.708436965942383, "val_acc": 52.0}
{"epoch": 26, "training_loss": 75.00505018234253, "training_acc": 60.0, "val_loss": 25.166425108909607, "val_acc": 48.0}
{"epoch": 27, "training_loss": 79.77948880195618, "training_acc": 51.0, "val_loss": 38.242536783218384, "val_acc": 52.0}
{"epoch": 28, "training_loss": 110.62083053588867, "training_acc": 54.0, "val_loss": 26.3895183801651, "val_acc": 48.0}
{"epoch": 29, "training_loss": 95.47137236595154, "training_acc": 47.0, "val_loss": 35.35001277923584, "val_acc": 52.0}
{"epoch": 30, "training_loss": 112.10397839546204, "training_acc": 53.0, "val_loss": 22.151008248329163, "val_acc": 44.0}
{"epoch": 31, "training_loss": 78.61458325386047, "training_acc": 52.0, "val_loss": 21.618835628032684, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.01306867599487, "training_acc": 59.0, "val_loss": 18.23788732290268, "val_acc": 52.0}
{"epoch": 33, "training_loss": 61.0994610786438, "training_acc": 64.0, "val_loss": 23.28275442123413, "val_acc": 52.0}
{"epoch": 34, "training_loss": 61.834789514541626, "training_acc": 67.0, "val_loss": 22.60444015264511, "val_acc": 44.0}
{"epoch": 35, "training_loss": 72.23720026016235, "training_acc": 58.0, "val_loss": 25.283610820770264, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.74183130264282, "training_acc": 65.0, "val_loss": 26.071158051490784, "val_acc": 48.0}
{"epoch": 37, "training_loss": 80.48873949050903, "training_acc": 54.0, "val_loss": 24.168770015239716, "val_acc": 52.0}
{"epoch": 38, "training_loss": 80.2911012172699, "training_acc": 50.0, "val_loss": 18.570037186145782, "val_acc": 52.0}
