"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.36455011367798, "training_acc": 52.0, "val_loss": 17.726202309131622, "val_acc": 56.0}
{"epoch": 1, "training_loss": 70.1573281288147, "training_acc": 48.0, "val_loss": 17.68055260181427, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.46258425712585, "training_acc": 46.0, "val_loss": 17.21195876598358, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.85631155967712, "training_acc": 52.0, "val_loss": 17.34720766544342, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.51700329780579, "training_acc": 51.0, "val_loss": 17.84394383430481, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.40702033042908, "training_acc": 49.0, "val_loss": 17.297084629535675, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.09100794792175, "training_acc": 52.0, "val_loss": 17.21232235431671, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.40045857429504, "training_acc": 52.0, "val_loss": 17.236411571502686, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.68796277046204, "training_acc": 52.0, "val_loss": 17.321692407131195, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24053597450256, "training_acc": 52.0, "val_loss": 17.7019402384758, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.70416259765625, "training_acc": 48.0, "val_loss": 17.413637042045593, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.49347805976868, "training_acc": 43.0, "val_loss": 17.200075089931488, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.58459663391113, "training_acc": 52.0, "val_loss": 17.219054698944092, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.46183609962463, "training_acc": 46.0, "val_loss": 17.537136375904083, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.50954174995422, "training_acc": 48.0, "val_loss": 17.381437122821808, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.03514695167542, "training_acc": 54.0, "val_loss": 17.201805114746094, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.79166340827942, "training_acc": 52.0, "val_loss": 17.208589613437653, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.54010486602783, "training_acc": 52.0, "val_loss": 17.402267456054688, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.38073444366455, "training_acc": 51.0, "val_loss": 17.610299587249756, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.46599745750427, "training_acc": 50.0, "val_loss": 17.28483885526657, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.9484031200409, "training_acc": 52.0, "val_loss": 17.206016182899475, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.3944776058197, "training_acc": 52.0, "val_loss": 17.212951183319092, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.56183624267578, "training_acc": 52.0, "val_loss": 17.294248938560486, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.92976832389832, "training_acc": 57.0, "val_loss": 17.710383236408234, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.81421780586243, "training_acc": 48.0, "val_loss": 17.559711635112762, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.21560549736023, "training_acc": 52.0, "val_loss": 17.232733964920044, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.20536017417908, "training_acc": 52.0, "val_loss": 17.206764221191406, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.26581931114197, "training_acc": 52.0, "val_loss": 17.693570256233215, "val_acc": 56.0}
{"epoch": 28, "training_loss": 70.3873519897461, "training_acc": 48.0, "val_loss": 17.82277673482895, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.514883518219, "training_acc": 48.0, "val_loss": 17.207078635692596, "val_acc": 56.0}
{"epoch": 30, "training_loss": 71.51749038696289, "training_acc": 52.0, "val_loss": 17.285922169685364, "val_acc": 56.0}
