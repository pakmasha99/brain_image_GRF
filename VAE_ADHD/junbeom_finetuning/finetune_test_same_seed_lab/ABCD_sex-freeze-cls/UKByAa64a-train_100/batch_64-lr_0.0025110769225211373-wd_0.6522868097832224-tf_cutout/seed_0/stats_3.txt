"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.59522199630737, "training_acc": 51.0, "val_loss": 17.555761337280273, "val_acc": 52.0}
{"epoch": 1, "training_loss": 67.98293495178223, "training_acc": 59.0, "val_loss": 18.865032494068146, "val_acc": 48.0}
{"epoch": 2, "training_loss": 75.74301290512085, "training_acc": 47.0, "val_loss": 17.557920515537262, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73.02182126045227, "training_acc": 39.0, "val_loss": 17.819678783416748, "val_acc": 52.0}
{"epoch": 4, "training_loss": 71.50500273704529, "training_acc": 53.0, "val_loss": 17.671257257461548, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.1315803527832, "training_acc": 53.0, "val_loss": 17.31896698474884, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.6069061756134, "training_acc": 54.0, "val_loss": 17.562900483608246, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.77502942085266, "training_acc": 47.0, "val_loss": 17.353500425815582, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.61156940460205, "training_acc": 47.0, "val_loss": 17.488883435726166, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.24306607246399, "training_acc": 53.0, "val_loss": 17.656852304935455, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.08380675315857, "training_acc": 53.0, "val_loss": 17.324264347553253, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.95666766166687, "training_acc": 53.0, "val_loss": 17.35984981060028, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.11000537872314, "training_acc": 47.0, "val_loss": 17.441608011722565, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.53952527046204, "training_acc": 47.0, "val_loss": 17.305655777454376, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1362566947937, "training_acc": 53.0, "val_loss": 17.638786137104034, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.4727942943573, "training_acc": 53.0, "val_loss": 17.619815468788147, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.30368041992188, "training_acc": 53.0, "val_loss": 17.30353832244873, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.74530720710754, "training_acc": 45.0, "val_loss": 17.354659736156464, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.41974306106567, "training_acc": 47.0, "val_loss": 17.3048734664917, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19095420837402, "training_acc": 53.0, "val_loss": 17.339804768562317, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24363303184509, "training_acc": 53.0, "val_loss": 17.324402928352356, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.05250358581543, "training_acc": 53.0, "val_loss": 17.307379841804504, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15277171134949, "training_acc": 53.0, "val_loss": 17.307986319065094, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1503803730011, "training_acc": 53.0, "val_loss": 17.33432114124298, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19296932220459, "training_acc": 53.0, "val_loss": 17.44452565908432, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.46143794059753, "training_acc": 53.0, "val_loss": 17.50752180814743, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.6816418170929, "training_acc": 53.0, "val_loss": 17.32366532087326, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.91073989868164, "training_acc": 45.0, "val_loss": 17.493896186351776, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.28219604492188, "training_acc": 47.0, "val_loss": 17.35093891620636, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.70956087112427, "training_acc": 45.0, "val_loss": 17.470665276050568, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.75162887573242, "training_acc": 53.0, "val_loss": 17.5234854221344, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.3722755908966, "training_acc": 53.0, "val_loss": 17.31560528278351, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.61281299591064, "training_acc": 47.0, "val_loss": 17.46089905500412, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.02586793899536, "training_acc": 47.0, "val_loss": 17.33921766281128, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.30104875564575, "training_acc": 51.0, "val_loss": 17.47676581144333, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.40974116325378, "training_acc": 53.0, "val_loss": 17.56090670824051, "val_acc": 52.0}
