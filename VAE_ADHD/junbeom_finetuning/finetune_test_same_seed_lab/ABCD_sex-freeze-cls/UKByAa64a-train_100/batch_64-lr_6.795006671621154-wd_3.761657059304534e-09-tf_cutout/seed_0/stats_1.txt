"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 14315.643115997314, "training_acc": 46.0, "val_loss": 2982.9179763793945, "val_acc": 52.0}
{"epoch": 1, "training_loss": 14485.556457519531, "training_acc": 53.0, "val_loss": 7725.474548339844, "val_acc": 48.0}
{"epoch": 2, "training_loss": 29074.542236328125, "training_acc": 47.0, "val_loss": 2141.5695190429688, "val_acc": 48.0}
{"epoch": 3, "training_loss": 10131.000579833984, "training_acc": 51.0, "val_loss": 5641.801452636719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 21435.38458251953, "training_acc": 53.0, "val_loss": 5034.336853027344, "val_acc": 52.0}
{"epoch": 5, "training_loss": 14941.932006835938, "training_acc": 53.0, "val_loss": 874.8394966125488, "val_acc": 48.0}
{"epoch": 6, "training_loss": 8062.412414550781, "training_acc": 47.0, "val_loss": 2578.7254333496094, "val_acc": 48.0}
{"epoch": 7, "training_loss": 8740.362121582031, "training_acc": 47.0, "val_loss": 1868.3317184448242, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7285.617279052734, "training_acc": 53.0, "val_loss": 3239.6968841552734, "val_acc": 52.0}
{"epoch": 9, "training_loss": 10520.236938476562, "training_acc": 53.0, "val_loss": 408.2829475402832, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4240.594909667969, "training_acc": 49.0, "val_loss": 3049.7867584228516, "val_acc": 48.0}
{"epoch": 11, "training_loss": 11713.463500976562, "training_acc": 47.0, "val_loss": 708.1194400787354, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4251.2042236328125, "training_acc": 49.0, "val_loss": 3083.481788635254, "val_acc": 52.0}
{"epoch": 13, "training_loss": 11826.158508300781, "training_acc": 53.0, "val_loss": 2272.5778579711914, "val_acc": 52.0}
{"epoch": 14, "training_loss": 5994.35143661499, "training_acc": 52.0, "val_loss": 2213.6104583740234, "val_acc": 48.0}
{"epoch": 15, "training_loss": 10569.302551269531, "training_acc": 47.0, "val_loss": 2931.233787536621, "val_acc": 48.0}
{"epoch": 16, "training_loss": 9360.92855834961, "training_acc": 47.0, "val_loss": 1107.2297096252441, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5404.8624267578125, "training_acc": 53.0, "val_loss": 2323.0688095092773, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7537.7255935668945, "training_acc": 53.0, "val_loss": 442.55456924438477, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2192.5641021728516, "training_acc": 51.0, "val_loss": 257.22715854644775, "val_acc": 44.0}
{"epoch": 20, "training_loss": 2678.9883728027344, "training_acc": 48.0, "val_loss": 1426.588249206543, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3561.6260147094727, "training_acc": 56.0, "val_loss": 1004.5431137084961, "val_acc": 48.0}
{"epoch": 22, "training_loss": 4546.17578125, "training_acc": 47.0, "val_loss": 480.18579483032227, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3136.0192108154297, "training_acc": 49.0, "val_loss": 1985.8978271484375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 6250.718002319336, "training_acc": 53.0, "val_loss": 309.5041751861572, "val_acc": 56.0}
{"epoch": 25, "training_loss": 3067.579071044922, "training_acc": 58.0, "val_loss": 1797.7485656738281, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5698.136260986328, "training_acc": 47.0, "val_loss": 1012.9743576049805, "val_acc": 52.0}
{"epoch": 27, "training_loss": 4033.8402709960938, "training_acc": 55.0, "val_loss": 1592.6864624023438, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3683.896354675293, "training_acc": 55.0, "val_loss": 1312.1612548828125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 6643.160217285156, "training_acc": 47.0, "val_loss": 963.2007598876953, "val_acc": 48.0}
{"epoch": 30, "training_loss": 3716.1186904907227, "training_acc": 49.0, "val_loss": 1795.4404830932617, "val_acc": 52.0}
{"epoch": 31, "training_loss": 5332.46174621582, "training_acc": 53.0, "val_loss": 473.907470703125, "val_acc": 56.0}
{"epoch": 32, "training_loss": 2323.6897735595703, "training_acc": 56.0, "val_loss": 1622.4002838134766, "val_acc": 48.0}
{"epoch": 33, "training_loss": 5376.529335021973, "training_acc": 47.0, "val_loss": 985.2130889892578, "val_acc": 52.0}
{"epoch": 34, "training_loss": 4662.815856933594, "training_acc": 53.0, "val_loss": 1275.688648223877, "val_acc": 52.0}
{"epoch": 35, "training_loss": 3598.780303955078, "training_acc": 56.0, "val_loss": 825.9805679321289, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2796.358211517334, "training_acc": 49.0, "val_loss": 847.5114822387695, "val_acc": 56.0}
{"epoch": 37, "training_loss": 2727.882125854492, "training_acc": 54.0, "val_loss": 404.1027545928955, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1952.680908203125, "training_acc": 56.0, "val_loss": 543.6476707458496, "val_acc": 48.0}
