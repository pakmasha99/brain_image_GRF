"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 15617.840950012207, "training_acc": 45.0, "val_loss": 3704.2369842529297, "val_acc": 52.0}
{"epoch": 1, "training_loss": 16219.975280761719, "training_acc": 49.0, "val_loss": 6296.226119995117, "val_acc": 48.0}
{"epoch": 2, "training_loss": 22883.119750976562, "training_acc": 47.0, "val_loss": 633.4392547607422, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8682.930969238281, "training_acc": 45.0, "val_loss": 6955.620574951172, "val_acc": 52.0}
{"epoch": 4, "training_loss": 26175.947265625, "training_acc": 53.0, "val_loss": 6297.013854980469, "val_acc": 52.0}
{"epoch": 5, "training_loss": 19794.390197753906, "training_acc": 53.0, "val_loss": 558.5285663604736, "val_acc": 52.0}
{"epoch": 6, "training_loss": 5933.357177734375, "training_acc": 49.0, "val_loss": 5935.592269897461, "val_acc": 48.0}
{"epoch": 7, "training_loss": 24569.024475097656, "training_acc": 47.0, "val_loss": 5230.694198608398, "val_acc": 48.0}
{"epoch": 8, "training_loss": 17722.974609375, "training_acc": 47.0, "val_loss": 578.8630962371826, "val_acc": 52.0}
{"epoch": 9, "training_loss": 4000.5485229492188, "training_acc": 50.0, "val_loss": 3995.435333251953, "val_acc": 52.0}
{"epoch": 10, "training_loss": 13943.998046875, "training_acc": 53.0, "val_loss": 2710.843276977539, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5827.874549865723, "training_acc": 54.0, "val_loss": 2607.4535369873047, "val_acc": 48.0}
{"epoch": 12, "training_loss": 12695.773864746094, "training_acc": 47.0, "val_loss": 4408.776092529297, "val_acc": 48.0}
{"epoch": 13, "training_loss": 16290.461547851562, "training_acc": 47.0, "val_loss": 1216.9808387756348, "val_acc": 48.0}
{"epoch": 14, "training_loss": 5217.95361328125, "training_acc": 53.0, "val_loss": 3681.3072204589844, "val_acc": 52.0}
{"epoch": 15, "training_loss": 13892.760803222656, "training_acc": 53.0, "val_loss": 3804.5181274414062, "val_acc": 52.0}
{"epoch": 16, "training_loss": 11356.468200683594, "training_acc": 53.0, "val_loss": 240.52019119262695, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2826.8729248046875, "training_acc": 62.0, "val_loss": 2045.6310272216797, "val_acc": 48.0}
{"epoch": 18, "training_loss": 7598.259559631348, "training_acc": 47.0, "val_loss": 842.1621322631836, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2719.2001190185547, "training_acc": 54.0, "val_loss": 1015.8374786376953, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2551.2622299194336, "training_acc": 51.0, "val_loss": 726.1600971221924, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2591.3392486572266, "training_acc": 51.0, "val_loss": 1046.4561462402344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2011.6569557189941, "training_acc": 56.0, "val_loss": 514.0379428863525, "val_acc": 44.0}
{"epoch": 23, "training_loss": 2429.4122619628906, "training_acc": 47.0, "val_loss": 768.4792518615723, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1848.5559158325195, "training_acc": 54.0, "val_loss": 307.57341384887695, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1051.855188369751, "training_acc": 54.0, "val_loss": 691.0796165466309, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1669.5204963684082, "training_acc": 54.0, "val_loss": 510.9464168548584, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1772.395643234253, "training_acc": 52.0, "val_loss": 587.2908592224121, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1309.808572769165, "training_acc": 54.0, "val_loss": 155.77163696289062, "val_acc": 56.0}
{"epoch": 29, "training_loss": 1081.5640296936035, "training_acc": 56.0, "val_loss": 104.00909185409546, "val_acc": 48.0}
{"epoch": 30, "training_loss": 924.2544631958008, "training_acc": 57.0, "val_loss": 577.5124549865723, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1034.2004919052124, "training_acc": 55.0, "val_loss": 457.979679107666, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1388.7501068115234, "training_acc": 57.0, "val_loss": 387.7057075500488, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1333.857078552246, "training_acc": 52.0, "val_loss": 200.6767749786377, "val_acc": 52.0}
{"epoch": 34, "training_loss": 369.79815101623535, "training_acc": 69.0, "val_loss": 266.349720954895, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1675.128318786621, "training_acc": 39.0, "val_loss": 72.1947968006134, "val_acc": 48.0}
{"epoch": 36, "training_loss": 304.8161325454712, "training_acc": 65.0, "val_loss": 507.4302673339844, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1290.6555976867676, "training_acc": 47.0, "val_loss": 372.11546897888184, "val_acc": 52.0}
{"epoch": 38, "training_loss": 614.5574617385864, "training_acc": 68.0, "val_loss": 438.1093502044678, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1526.4437637329102, "training_acc": 45.0, "val_loss": 53.47996950149536, "val_acc": 56.0}
{"epoch": 40, "training_loss": 196.76816534996033, "training_acc": 75.0, "val_loss": 277.1354675292969, "val_acc": 52.0}
{"epoch": 41, "training_loss": 786.5890083312988, "training_acc": 57.0, "val_loss": 239.5066261291504, "val_acc": 52.0}
{"epoch": 42, "training_loss": 529.2481498718262, "training_acc": 54.0, "val_loss": 579.6160697937012, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1440.3252029418945, "training_acc": 53.0, "val_loss": 1243.7458038330078, "val_acc": 48.0}
{"epoch": 44, "training_loss": 5462.817626953125, "training_acc": 47.0, "val_loss": 474.9959468841553, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3959.2845764160156, "training_acc": 41.0, "val_loss": 2488.720703125, "val_acc": 52.0}
{"epoch": 46, "training_loss": 8516.042083740234, "training_acc": 53.0, "val_loss": 691.9963836669922, "val_acc": 52.0}
{"epoch": 47, "training_loss": 3541.1001739501953, "training_acc": 53.0, "val_loss": 2563.039779663086, "val_acc": 48.0}
{"epoch": 48, "training_loss": 9492.462707519531, "training_acc": 47.0, "val_loss": 517.8475379943848, "val_acc": 48.0}
{"epoch": 49, "training_loss": 3440.2530059814453, "training_acc": 52.0, "val_loss": 3226.735305786133, "val_acc": 52.0}
{"epoch": 50, "training_loss": 11700.96060180664, "training_acc": 53.0, "val_loss": 2462.7214431762695, "val_acc": 52.0}
{"epoch": 51, "training_loss": 5977.143226623535, "training_acc": 53.0, "val_loss": 2235.72998046875, "val_acc": 48.0}
{"epoch": 52, "training_loss": 11303.087463378906, "training_acc": 47.0, "val_loss": 3527.410888671875, "val_acc": 48.0}
{"epoch": 53, "training_loss": 12271.448638916016, "training_acc": 47.0, "val_loss": 420.28326988220215, "val_acc": 48.0}
{"epoch": 54, "training_loss": 4370.656555175781, "training_acc": 55.0, "val_loss": 3003.62491607666, "val_acc": 52.0}
{"epoch": 55, "training_loss": 8930.283767700195, "training_acc": 53.0, "val_loss": 851.7705917358398, "val_acc": 52.0}
{"epoch": 56, "training_loss": 2592.4833984375, "training_acc": 56.0, "val_loss": 1976.0534286499023, "val_acc": 48.0}
{"epoch": 57, "training_loss": 7151.025146484375, "training_acc": 47.0, "val_loss": 528.6015510559082, "val_acc": 48.0}
{"epoch": 58, "training_loss": 2508.822021484375, "training_acc": 59.0, "val_loss": 2242.9365158081055, "val_acc": 52.0}
