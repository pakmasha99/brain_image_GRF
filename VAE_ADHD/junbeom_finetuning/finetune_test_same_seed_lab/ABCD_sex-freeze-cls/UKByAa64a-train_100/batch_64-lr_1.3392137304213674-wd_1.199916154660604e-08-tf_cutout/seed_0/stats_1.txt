"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2857.1011848449707, "training_acc": 46.0, "val_loss": 587.7880573272705, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2855.151641845703, "training_acc": 53.0, "val_loss": 1522.6877212524414, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5730.289016723633, "training_acc": 47.0, "val_loss": 422.1674919128418, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1996.6150131225586, "training_acc": 51.0, "val_loss": 1111.8218421936035, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4224.713836669922, "training_acc": 53.0, "val_loss": 992.0980453491211, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2944.881607055664, "training_acc": 53.0, "val_loss": 172.51052856445312, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1589.1011810302734, "training_acc": 47.0, "val_loss": 508.3298683166504, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1722.5478401184082, "training_acc": 47.0, "val_loss": 368.1098222732544, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1435.6428833007812, "training_acc": 53.0, "val_loss": 637.962818145752, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2071.3810386657715, "training_acc": 53.0, "val_loss": 80.19282221794128, "val_acc": 52.0}
{"epoch": 10, "training_loss": 836.7224731445312, "training_acc": 49.0, "val_loss": 594.8432922363281, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2280.966133117676, "training_acc": 47.0, "val_loss": 127.27644443511963, "val_acc": 48.0}
{"epoch": 12, "training_loss": 825.3502578735352, "training_acc": 49.0, "val_loss": 623.0358600616455, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2389.9887924194336, "training_acc": 53.0, "val_loss": 466.26038551330566, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1247.5859470367432, "training_acc": 52.0, "val_loss": 449.3250846862793, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2187.2478103637695, "training_acc": 47.0, "val_loss": 651.2314319610596, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2174.4530601501465, "training_acc": 47.0, "val_loss": 105.70027828216553, "val_acc": 52.0}
{"epoch": 17, "training_loss": 679.5023231506348, "training_acc": 55.0, "val_loss": 390.6985282897949, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1235.2241668701172, "training_acc": 53.0, "val_loss": 122.60051965713501, "val_acc": 48.0}
{"epoch": 19, "training_loss": 525.9171257019043, "training_acc": 47.0, "val_loss": 36.23924255371094, "val_acc": 48.0}
{"epoch": 20, "training_loss": 420.6081962585449, "training_acc": 55.0, "val_loss": 199.04226064682007, "val_acc": 52.0}
{"epoch": 21, "training_loss": 422.7407841682434, "training_acc": 58.0, "val_loss": 189.12475109100342, "val_acc": 48.0}
{"epoch": 22, "training_loss": 653.6423625946045, "training_acc": 47.0, "val_loss": 166.32035970687866, "val_acc": 52.0}
{"epoch": 23, "training_loss": 604.7993774414062, "training_acc": 55.0, "val_loss": 130.57022094726562, "val_acc": 52.0}
{"epoch": 24, "training_loss": 503.84460067749023, "training_acc": 52.0, "val_loss": 204.68106269836426, "val_acc": 48.0}
{"epoch": 25, "training_loss": 545.3985786437988, "training_acc": 48.0, "val_loss": 263.57033252716064, "val_acc": 52.0}
{"epoch": 26, "training_loss": 938.7641639709473, "training_acc": 53.0, "val_loss": 174.7869849205017, "val_acc": 52.0}
{"epoch": 27, "training_loss": 415.41065979003906, "training_acc": 56.0, "val_loss": 180.64038753509521, "val_acc": 48.0}
{"epoch": 28, "training_loss": 577.8904790878296, "training_acc": 48.0, "val_loss": 180.65340518951416, "val_acc": 52.0}
{"epoch": 29, "training_loss": 456.37879943847656, "training_acc": 53.0, "val_loss": 63.14656734466553, "val_acc": 48.0}
{"epoch": 30, "training_loss": 351.7464790344238, "training_acc": 54.0, "val_loss": 132.30782747268677, "val_acc": 56.0}
{"epoch": 31, "training_loss": 335.95527744293213, "training_acc": 59.0, "val_loss": 48.62590730190277, "val_acc": 60.0}
{"epoch": 32, "training_loss": 190.3963041305542, "training_acc": 60.0, "val_loss": 49.47332739830017, "val_acc": 56.0}
{"epoch": 33, "training_loss": 191.5315456390381, "training_acc": 64.0, "val_loss": 35.46775281429291, "val_acc": 48.0}
{"epoch": 34, "training_loss": 282.62055492401123, "training_acc": 47.0, "val_loss": 31.893810629844666, "val_acc": 48.0}
{"epoch": 35, "training_loss": 223.9012851715088, "training_acc": 62.0, "val_loss": 125.24999380111694, "val_acc": 56.0}
{"epoch": 36, "training_loss": 267.03152084350586, "training_acc": 58.0, "val_loss": 74.45572018623352, "val_acc": 48.0}
{"epoch": 37, "training_loss": 372.4132490158081, "training_acc": 53.0, "val_loss": 185.4439616203308, "val_acc": 52.0}
{"epoch": 38, "training_loss": 500.89533615112305, "training_acc": 54.0, "val_loss": 73.63525032997131, "val_acc": 48.0}
{"epoch": 39, "training_loss": 393.8806962966919, "training_acc": 48.0, "val_loss": 151.41040086746216, "val_acc": 52.0}
{"epoch": 40, "training_loss": 425.53453159332275, "training_acc": 53.0, "val_loss": 43.2171493768692, "val_acc": 48.0}
{"epoch": 41, "training_loss": 196.0330410003662, "training_acc": 55.0, "val_loss": 136.85206174850464, "val_acc": 52.0}
{"epoch": 42, "training_loss": 330.68565607070923, "training_acc": 54.0, "val_loss": 128.4842848777771, "val_acc": 48.0}
{"epoch": 43, "training_loss": 457.62253189086914, "training_acc": 48.0, "val_loss": 178.2117247581482, "val_acc": 52.0}
{"epoch": 44, "training_loss": 614.9878330230713, "training_acc": 53.0, "val_loss": 23.620997369289398, "val_acc": 52.0}
{"epoch": 45, "training_loss": 231.3451099395752, "training_acc": 57.0, "val_loss": 119.96842622756958, "val_acc": 52.0}
{"epoch": 46, "training_loss": 366.26493072509766, "training_acc": 53.0, "val_loss": 101.23227834701538, "val_acc": 48.0}
{"epoch": 47, "training_loss": 424.3193607330322, "training_acc": 47.0, "val_loss": 143.95349025726318, "val_acc": 52.0}
{"epoch": 48, "training_loss": 460.6151485443115, "training_acc": 53.0, "val_loss": 22.29757308959961, "val_acc": 52.0}
{"epoch": 49, "training_loss": 177.50020599365234, "training_acc": 62.0, "val_loss": 89.14419412612915, "val_acc": 52.0}
{"epoch": 50, "training_loss": 235.20780301094055, "training_acc": 57.0, "val_loss": 88.22835087776184, "val_acc": 48.0}
{"epoch": 51, "training_loss": 245.70384526252747, "training_acc": 60.0, "val_loss": 72.65417575836182, "val_acc": 52.0}
{"epoch": 52, "training_loss": 154.8783233165741, "training_acc": 69.0, "val_loss": 15.674823522567749, "val_acc": 68.0}
{"epoch": 53, "training_loss": 86.76015186309814, "training_acc": 72.0, "val_loss": 41.79714918136597, "val_acc": 56.0}
{"epoch": 54, "training_loss": 112.61654806137085, "training_acc": 60.0, "val_loss": 66.11301898956299, "val_acc": 56.0}
{"epoch": 55, "training_loss": 114.18904972076416, "training_acc": 67.0, "val_loss": 15.424525737762451, "val_acc": 72.0}
{"epoch": 56, "training_loss": 92.98326873779297, "training_acc": 67.0, "val_loss": 17.369720339775085, "val_acc": 64.0}
{"epoch": 57, "training_loss": 74.46121168136597, "training_acc": 75.0, "val_loss": 60.5913519859314, "val_acc": 52.0}
{"epoch": 58, "training_loss": 179.46804332733154, "training_acc": 49.0, "val_loss": 64.17587995529175, "val_acc": 52.0}
{"epoch": 59, "training_loss": 159.5825114250183, "training_acc": 60.0, "val_loss": 35.544776916503906, "val_acc": 52.0}
{"epoch": 60, "training_loss": 291.23390007019043, "training_acc": 50.0, "val_loss": 19.151945412158966, "val_acc": 56.0}
{"epoch": 61, "training_loss": 116.31230974197388, "training_acc": 61.0, "val_loss": 126.70314311981201, "val_acc": 52.0}
{"epoch": 62, "training_loss": 332.80608558654785, "training_acc": 54.0, "val_loss": 156.80025815963745, "val_acc": 48.0}
{"epoch": 63, "training_loss": 688.7785415649414, "training_acc": 47.0, "val_loss": 115.33962488174438, "val_acc": 52.0}
{"epoch": 64, "training_loss": 411.37919998168945, "training_acc": 52.0, "val_loss": 112.08878755569458, "val_acc": 52.0}
{"epoch": 65, "training_loss": 405.7800464630127, "training_acc": 52.0, "val_loss": 111.76631450653076, "val_acc": 48.0}
{"epoch": 66, "training_loss": 437.9603271484375, "training_acc": 54.0, "val_loss": 206.74493312835693, "val_acc": 52.0}
{"epoch": 67, "training_loss": 464.6894426345825, "training_acc": 56.0, "val_loss": 214.91093635559082, "val_acc": 48.0}
{"epoch": 68, "training_loss": 930.898307800293, "training_acc": 47.0, "val_loss": 35.45905947685242, "val_acc": 40.0}
{"epoch": 69, "training_loss": 638.9076499938965, "training_acc": 47.0, "val_loss": 450.89592933654785, "val_acc": 52.0}
{"epoch": 70, "training_loss": 1497.6265258789062, "training_acc": 53.0, "val_loss": 23.650959134101868, "val_acc": 56.0}
{"epoch": 71, "training_loss": 501.6195411682129, "training_acc": 60.0, "val_loss": 307.98141956329346, "val_acc": 48.0}
{"epoch": 72, "training_loss": 819.1199479103088, "training_acc": 54.0, "val_loss": 318.0881977081299, "val_acc": 52.0}
{"epoch": 73, "training_loss": 1279.43505859375, "training_acc": 53.0, "val_loss": 316.9771671295166, "val_acc": 52.0}
{"epoch": 74, "training_loss": 864.3509595394135, "training_acc": 60.0, "val_loss": 314.7643566131592, "val_acc": 48.0}
