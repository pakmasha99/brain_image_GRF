"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2861.8813400268555, "training_acc": 52.0, "val_loss": 555.155611038208, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2464.890609741211, "training_acc": 59.0, "val_loss": 1649.3227005004883, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6238.90185546875, "training_acc": 47.0, "val_loss": 569.2928314208984, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1893.0927200317383, "training_acc": 55.0, "val_loss": 933.2098007202148, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3739.467971801758, "training_acc": 53.0, "val_loss": 748.0814456939697, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2099.6711654663086, "training_acc": 53.0, "val_loss": 556.6868305206299, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2590.243865966797, "training_acc": 47.0, "val_loss": 873.4646797180176, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3130.2962036132812, "training_acc": 47.0, "val_loss": 41.51942431926727, "val_acc": 64.0}
{"epoch": 8, "training_loss": 717.9648666381836, "training_acc": 57.0, "val_loss": 827.7246475219727, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3163.15771484375, "training_acc": 53.0, "val_loss": 648.428201675415, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1802.412181854248, "training_acc": 53.0, "val_loss": 344.814395904541, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1941.0637512207031, "training_acc": 47.0, "val_loss": 676.839017868042, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2472.1108932495117, "training_acc": 47.0, "val_loss": 48.13638925552368, "val_acc": 56.0}
{"epoch": 13, "training_loss": 592.7390174865723, "training_acc": 56.0, "val_loss": 492.0636177062988, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1673.7689208984375, "training_acc": 53.0, "val_loss": 94.2146360874176, "val_acc": 52.0}
{"epoch": 15, "training_loss": 740.189208984375, "training_acc": 54.0, "val_loss": 567.3468589782715, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2187.048484802246, "training_acc": 47.0, "val_loss": 156.443190574646, "val_acc": 48.0}
{"epoch": 17, "training_loss": 839.1239128112793, "training_acc": 51.0, "val_loss": 578.8046836853027, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2206.042869567871, "training_acc": 53.0, "val_loss": 409.56196784973145, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1079.7060375213623, "training_acc": 57.0, "val_loss": 423.89698028564453, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1934.7607192993164, "training_acc": 47.0, "val_loss": 554.200553894043, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1676.425449371338, "training_acc": 47.0, "val_loss": 214.14990425109863, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1194.736312866211, "training_acc": 53.0, "val_loss": 442.1027660369873, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1407.0037937164307, "training_acc": 53.0, "val_loss": 162.44161128997803, "val_acc": 48.0}
{"epoch": 24, "training_loss": 834.7344932556152, "training_acc": 52.0, "val_loss": 230.65173625946045, "val_acc": 48.0}
{"epoch": 25, "training_loss": 674.3931436538696, "training_acc": 49.0, "val_loss": 255.0356149673462, "val_acc": 52.0}
{"epoch": 26, "training_loss": 923.7665996551514, "training_acc": 53.0, "val_loss": 37.80394196510315, "val_acc": 44.0}
{"epoch": 27, "training_loss": 593.6026954650879, "training_acc": 53.0, "val_loss": 187.0428442955017, "val_acc": 48.0}
{"epoch": 28, "training_loss": 473.7563648223877, "training_acc": 59.0, "val_loss": 196.96019887924194, "val_acc": 52.0}
{"epoch": 29, "training_loss": 593.5021686553955, "training_acc": 54.0, "val_loss": 111.4138126373291, "val_acc": 48.0}
{"epoch": 30, "training_loss": 445.47024631500244, "training_acc": 50.0, "val_loss": 83.29527974128723, "val_acc": 52.0}
{"epoch": 31, "training_loss": 309.6797790527344, "training_acc": 53.0, "val_loss": 90.17062187194824, "val_acc": 44.0}
{"epoch": 32, "training_loss": 325.61553859710693, "training_acc": 52.0, "val_loss": 122.31131792068481, "val_acc": 52.0}
{"epoch": 33, "training_loss": 338.0610246658325, "training_acc": 56.0, "val_loss": 54.12060618400574, "val_acc": 48.0}
{"epoch": 34, "training_loss": 213.83655166625977, "training_acc": 58.0, "val_loss": 102.33902931213379, "val_acc": 52.0}
{"epoch": 35, "training_loss": 280.8698887825012, "training_acc": 55.0, "val_loss": 95.03813982009888, "val_acc": 48.0}
{"epoch": 36, "training_loss": 228.74923634529114, "training_acc": 58.0, "val_loss": 126.53874158859253, "val_acc": 52.0}
{"epoch": 37, "training_loss": 351.5483183860779, "training_acc": 55.0, "val_loss": 175.78095197677612, "val_acc": 48.0}
{"epoch": 38, "training_loss": 592.4921932220459, "training_acc": 47.0, "val_loss": 115.82763195037842, "val_acc": 52.0}
{"epoch": 39, "training_loss": 413.9294624328613, "training_acc": 53.0, "val_loss": 34.404897689819336, "val_acc": 56.0}
{"epoch": 40, "training_loss": 134.3734040260315, "training_acc": 65.0, "val_loss": 37.53255307674408, "val_acc": 60.0}
{"epoch": 41, "training_loss": 231.8820037841797, "training_acc": 60.0, "val_loss": 120.48518657684326, "val_acc": 48.0}
{"epoch": 42, "training_loss": 387.0021858215332, "training_acc": 54.0, "val_loss": 112.48490810394287, "val_acc": 52.0}
{"epoch": 43, "training_loss": 383.45137119293213, "training_acc": 54.0, "val_loss": 60.878437757492065, "val_acc": 44.0}
{"epoch": 44, "training_loss": 161.40517354011536, "training_acc": 57.0, "val_loss": 47.61576056480408, "val_acc": 52.0}
{"epoch": 45, "training_loss": 110.9336462020874, "training_acc": 72.0, "val_loss": 85.3302001953125, "val_acc": 48.0}
{"epoch": 46, "training_loss": 198.1216778755188, "training_acc": 64.0, "val_loss": 91.93682670593262, "val_acc": 52.0}
{"epoch": 47, "training_loss": 263.23963356018066, "training_acc": 54.0, "val_loss": 30.001232028007507, "val_acc": 56.0}
{"epoch": 48, "training_loss": 159.95537948608398, "training_acc": 56.0, "val_loss": 94.08697485923767, "val_acc": 48.0}
{"epoch": 49, "training_loss": 211.4458191394806, "training_acc": 60.0, "val_loss": 62.849462032318115, "val_acc": 52.0}
{"epoch": 50, "training_loss": 193.08133935928345, "training_acc": 54.0, "val_loss": 20.782466232776642, "val_acc": 64.0}
{"epoch": 51, "training_loss": 120.03216123580933, "training_acc": 66.0, "val_loss": 30.4490864276886, "val_acc": 44.0}
{"epoch": 52, "training_loss": 62.72396969795227, "training_acc": 79.0, "val_loss": 19.324970245361328, "val_acc": 64.0}
{"epoch": 53, "training_loss": 54.67586159706116, "training_acc": 80.0, "val_loss": 21.72437012195587, "val_acc": 60.0}
{"epoch": 54, "training_loss": 92.10407257080078, "training_acc": 68.0, "val_loss": 106.31400346755981, "val_acc": 48.0}
{"epoch": 55, "training_loss": 278.5666115283966, "training_acc": 57.0, "val_loss": 125.16903877258301, "val_acc": 52.0}
{"epoch": 56, "training_loss": 247.04566621780396, "training_acc": 63.0, "val_loss": 154.2932391166687, "val_acc": 48.0}
{"epoch": 57, "training_loss": 444.29186964035034, "training_acc": 51.0, "val_loss": 193.62342357635498, "val_acc": 52.0}
{"epoch": 58, "training_loss": 638.411096572876, "training_acc": 53.0, "val_loss": 29.511383175849915, "val_acc": 48.0}
{"epoch": 59, "training_loss": 220.3894443511963, "training_acc": 62.0, "val_loss": 74.91068840026855, "val_acc": 52.0}
{"epoch": 60, "training_loss": 149.2365140914917, "training_acc": 60.0, "val_loss": 46.65115773677826, "val_acc": 48.0}
{"epoch": 61, "training_loss": 194.25143718719482, "training_acc": 51.0, "val_loss": 22.983619570732117, "val_acc": 56.0}
{"epoch": 62, "training_loss": 83.4503071308136, "training_acc": 71.0, "val_loss": 74.9329686164856, "val_acc": 52.0}
{"epoch": 63, "training_loss": 171.55756330490112, "training_acc": 54.0, "val_loss": 37.62158751487732, "val_acc": 52.0}
{"epoch": 64, "training_loss": 76.60805583000183, "training_acc": 69.0, "val_loss": 19.083067774772644, "val_acc": 68.0}
{"epoch": 65, "training_loss": 61.521881103515625, "training_acc": 79.0, "val_loss": 32.16069042682648, "val_acc": 56.0}
{"epoch": 66, "training_loss": 100.51217937469482, "training_acc": 70.0, "val_loss": 85.14068126678467, "val_acc": 52.0}
{"epoch": 67, "training_loss": 223.95322513580322, "training_acc": 55.0, "val_loss": 41.97582006454468, "val_acc": 52.0}
{"epoch": 68, "training_loss": 80.4469645023346, "training_acc": 71.0, "val_loss": 33.099982142448425, "val_acc": 52.0}
{"epoch": 69, "training_loss": 107.74509811401367, "training_acc": 69.0, "val_loss": 20.925839245319366, "val_acc": 64.0}
{"epoch": 70, "training_loss": 64.25134038925171, "training_acc": 76.0, "val_loss": 98.11447858810425, "val_acc": 52.0}
{"epoch": 71, "training_loss": 204.96613454818726, "training_acc": 63.0, "val_loss": 95.18644213676453, "val_acc": 48.0}
{"epoch": 72, "training_loss": 272.97851514816284, "training_acc": 49.0, "val_loss": 23.74383807182312, "val_acc": 56.0}
{"epoch": 73, "training_loss": 199.4228401184082, "training_acc": 68.0, "val_loss": 36.25644147396088, "val_acc": 60.0}
{"epoch": 74, "training_loss": 144.9730806350708, "training_acc": 62.0, "val_loss": 157.7561616897583, "val_acc": 48.0}
{"epoch": 75, "training_loss": 407.92010974884033, "training_acc": 47.0, "val_loss": 235.914945602417, "val_acc": 52.0}
{"epoch": 76, "training_loss": 927.1644172668457, "training_acc": 53.0, "val_loss": 123.89934062957764, "val_acc": 52.0}
{"epoch": 77, "training_loss": 578.1667060852051, "training_acc": 53.0, "val_loss": 374.8305082321167, "val_acc": 48.0}
{"epoch": 78, "training_loss": 1120.4333591461182, "training_acc": 47.0, "val_loss": 217.51573085784912, "val_acc": 52.0}
{"epoch": 79, "training_loss": 1009.4612045288086, "training_acc": 53.0, "val_loss": 257.3424816131592, "val_acc": 52.0}
{"epoch": 80, "training_loss": 621.2981419563293, "training_acc": 59.0, "val_loss": 230.85370063781738, "val_acc": 48.0}
{"epoch": 81, "training_loss": 657.1729125976562, "training_acc": 50.0, "val_loss": 196.7358946800232, "val_acc": 52.0}
{"epoch": 82, "training_loss": 792.898811340332, "training_acc": 53.0, "val_loss": 81.0268223285675, "val_acc": 52.0}
{"epoch": 83, "training_loss": 546.5716247558594, "training_acc": 52.0, "val_loss": 337.6241683959961, "val_acc": 48.0}
