"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2788.9460067749023, "training_acc": 49.0, "val_loss": 762.3040676116943, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2983.4290924072266, "training_acc": 53.0, "val_loss": 1173.5164642333984, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4201.115379333496, "training_acc": 47.0, "val_loss": 51.98315382003784, "val_acc": 52.0}
{"epoch": 3, "training_loss": 573.5683555603027, "training_acc": 53.0, "val_loss": 149.81237649917603, "val_acc": 52.0}
{"epoch": 4, "training_loss": 952.5918884277344, "training_acc": 47.0, "val_loss": 387.27052211761475, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1122.1791534423828, "training_acc": 48.0, "val_loss": 472.6766109466553, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2050.1496353149414, "training_acc": 53.0, "val_loss": 602.1085262298584, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1847.837574005127, "training_acc": 53.0, "val_loss": 219.89340782165527, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1201.0370025634766, "training_acc": 47.0, "val_loss": 310.575008392334, "val_acc": 48.0}
{"epoch": 9, "training_loss": 837.5192177295685, "training_acc": 53.0, "val_loss": 298.2753276824951, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1124.9816284179688, "training_acc": 53.0, "val_loss": 145.15914916992188, "val_acc": 52.0}
{"epoch": 11, "training_loss": 695.5616645812988, "training_acc": 51.0, "val_loss": 353.99913787841797, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1363.7336769104004, "training_acc": 47.0, "val_loss": 155.43334484100342, "val_acc": 52.0}
{"epoch": 13, "training_loss": 685.4922370910645, "training_acc": 53.0, "val_loss": 178.057062625885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 546.3684349060059, "training_acc": 53.0, "val_loss": 153.8979172706604, "val_acc": 48.0}
{"epoch": 15, "training_loss": 529.071183681488, "training_acc": 51.0, "val_loss": 183.27147960662842, "val_acc": 52.0}
{"epoch": 16, "training_loss": 564.9667816162109, "training_acc": 53.0, "val_loss": 127.74722576141357, "val_acc": 48.0}
{"epoch": 17, "training_loss": 570.1795043945312, "training_acc": 48.0, "val_loss": 24.435989558696747, "val_acc": 48.0}
{"epoch": 18, "training_loss": 271.88866996765137, "training_acc": 64.0, "val_loss": 103.43191623687744, "val_acc": 52.0}
{"epoch": 19, "training_loss": 467.2065086364746, "training_acc": 49.0, "val_loss": 149.2081880569458, "val_acc": 48.0}
{"epoch": 20, "training_loss": 524.4047546386719, "training_acc": 49.0, "val_loss": 122.55076169967651, "val_acc": 52.0}
{"epoch": 21, "training_loss": 283.9016571044922, "training_acc": 56.0, "val_loss": 109.69752073287964, "val_acc": 48.0}
{"epoch": 22, "training_loss": 341.68236780166626, "training_acc": 53.0, "val_loss": 239.7003412246704, "val_acc": 52.0}
{"epoch": 23, "training_loss": 785.6111278533936, "training_acc": 53.0, "val_loss": 87.44505643844604, "val_acc": 52.0}
{"epoch": 24, "training_loss": 377.56723976135254, "training_acc": 63.0, "val_loss": 278.188681602478, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1090.3086166381836, "training_acc": 47.0, "val_loss": 243.0777072906494, "val_acc": 52.0}
{"epoch": 26, "training_loss": 876.5783424377441, "training_acc": 53.0, "val_loss": 265.36924839019775, "val_acc": 52.0}
{"epoch": 27, "training_loss": 827.5544700622559, "training_acc": 38.0, "val_loss": 73.16939234733582, "val_acc": 48.0}
{"epoch": 28, "training_loss": 407.6439571380615, "training_acc": 48.0, "val_loss": 177.2419810295105, "val_acc": 52.0}
{"epoch": 29, "training_loss": 410.8002653121948, "training_acc": 50.0, "val_loss": 34.16629731655121, "val_acc": 64.0}
{"epoch": 30, "training_loss": 197.74528551101685, "training_acc": 64.0, "val_loss": 147.60226011276245, "val_acc": 52.0}
{"epoch": 31, "training_loss": 365.517569065094, "training_acc": 53.0, "val_loss": 67.63960123062134, "val_acc": 48.0}
{"epoch": 32, "training_loss": 245.413733959198, "training_acc": 52.0, "val_loss": 33.37416052818298, "val_acc": 52.0}
{"epoch": 33, "training_loss": 112.420982837677, "training_acc": 69.0, "val_loss": 62.16884255409241, "val_acc": 52.0}
{"epoch": 34, "training_loss": 186.60531854629517, "training_acc": 65.0, "val_loss": 36.935728788375854, "val_acc": 52.0}
{"epoch": 35, "training_loss": 124.31007242202759, "training_acc": 66.0, "val_loss": 69.30281519889832, "val_acc": 44.0}
{"epoch": 36, "training_loss": 183.0418508052826, "training_acc": 58.0, "val_loss": 43.6039000749588, "val_acc": 60.0}
