"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 166.28118801116943, "training_acc": 47.0, "val_loss": 29.447248578071594, "val_acc": 52.0}
{"epoch": 1, "training_loss": 141.33923387527466, "training_acc": 49.0, "val_loss": 55.40550351142883, "val_acc": 48.0}
{"epoch": 2, "training_loss": 197.98055839538574, "training_acc": 47.0, "val_loss": 17.540213465690613, "val_acc": 52.0}
{"epoch": 3, "training_loss": 93.61990165710449, "training_acc": 45.0, "val_loss": 39.75343704223633, "val_acc": 52.0}
{"epoch": 4, "training_loss": 145.77689218521118, "training_acc": 53.0, "val_loss": 21.379132568836212, "val_acc": 52.0}
{"epoch": 5, "training_loss": 85.54340744018555, "training_acc": 47.0, "val_loss": 27.854782342910767, "val_acc": 48.0}
{"epoch": 6, "training_loss": 113.06485605239868, "training_acc": 47.0, "val_loss": 20.95106840133667, "val_acc": 48.0}
{"epoch": 7, "training_loss": 80.1302592754364, "training_acc": 49.0, "val_loss": 22.205233573913574, "val_acc": 52.0}
{"epoch": 8, "training_loss": 89.38520836830139, "training_acc": 53.0, "val_loss": 22.33806550502777, "val_acc": 52.0}
{"epoch": 9, "training_loss": 79.24459719657898, "training_acc": 53.0, "val_loss": 18.32074671983719, "val_acc": 52.0}
{"epoch": 10, "training_loss": 79.83591413497925, "training_acc": 47.0, "val_loss": 20.85355520248413, "val_acc": 48.0}
{"epoch": 11, "training_loss": 79.89112091064453, "training_acc": 48.0, "val_loss": 17.960603535175323, "val_acc": 52.0}
{"epoch": 12, "training_loss": 73.09386038780212, "training_acc": 53.0, "val_loss": 20.16550451517105, "val_acc": 52.0}
{"epoch": 13, "training_loss": 75.79737830162048, "training_acc": 53.0, "val_loss": 17.211177945137024, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.75450348854065, "training_acc": 46.0, "val_loss": 18.633735179901123, "val_acc": 48.0}
{"epoch": 15, "training_loss": 73.47946953773499, "training_acc": 47.0, "val_loss": 17.162013053894043, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.98341870307922, "training_acc": 53.0, "val_loss": 18.0589497089386, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.41792607307434, "training_acc": 53.0, "val_loss": 17.24478155374527, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.02940726280212, "training_acc": 55.0, "val_loss": 18.539316952228546, "val_acc": 52.0}
{"epoch": 19, "training_loss": 73.24042844772339, "training_acc": 44.0, "val_loss": 17.14915931224823, "val_acc": 52.0}
{"epoch": 20, "training_loss": 66.02701234817505, "training_acc": 58.0, "val_loss": 18.514063954353333, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.720219373703, "training_acc": 54.0, "val_loss": 16.850779950618744, "val_acc": 52.0}
{"epoch": 22, "training_loss": 65.3965995311737, "training_acc": 62.0, "val_loss": 17.801280319690704, "val_acc": 56.0}
{"epoch": 23, "training_loss": 72.32127547264099, "training_acc": 48.0, "val_loss": 16.896167397499084, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.59190368652344, "training_acc": 54.0, "val_loss": 19.846731424331665, "val_acc": 52.0}
{"epoch": 25, "training_loss": 72.00127720832825, "training_acc": 53.0, "val_loss": 16.973768174648285, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.17894005775452, "training_acc": 54.0, "val_loss": 19.43305730819702, "val_acc": 44.0}
{"epoch": 27, "training_loss": 73.47755312919617, "training_acc": 52.0, "val_loss": 17.309413850307465, "val_acc": 52.0}
{"epoch": 28, "training_loss": 64.83593702316284, "training_acc": 60.0, "val_loss": 19.420602917671204, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.05116295814514, "training_acc": 53.0, "val_loss": 17.3479825258255, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.4242947101593, "training_acc": 55.0, "val_loss": 18.286773562431335, "val_acc": 48.0}
{"epoch": 31, "training_loss": 68.83036684989929, "training_acc": 51.0, "val_loss": 17.90030300617218, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.35533237457275, "training_acc": 57.0, "val_loss": 18.97609829902649, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.62323498725891, "training_acc": 54.0, "val_loss": 17.442451417446136, "val_acc": 56.0}
{"epoch": 34, "training_loss": 68.5814220905304, "training_acc": 55.0, "val_loss": 18.200358748435974, "val_acc": 48.0}
{"epoch": 35, "training_loss": 65.14261651039124, "training_acc": 59.0, "val_loss": 18.104222416877747, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.29026341438293, "training_acc": 55.0, "val_loss": 18.19809079170227, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.55845189094543, "training_acc": 61.0, "val_loss": 17.19847470521927, "val_acc": 60.0}
{"epoch": 38, "training_loss": 68.79787516593933, "training_acc": 50.0, "val_loss": 16.807246208190918, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.24095249176025, "training_acc": 62.0, "val_loss": 18.29916685819626, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.53188014030457, "training_acc": 53.0, "val_loss": 17.02304035425186, "val_acc": 52.0}
{"epoch": 41, "training_loss": 61.18383836746216, "training_acc": 72.0, "val_loss": 17.472797632217407, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.18845462799072, "training_acc": 51.0, "val_loss": 17.386436462402344, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.12974524497986, "training_acc": 64.0, "val_loss": 17.439326643943787, "val_acc": 52.0}
{"epoch": 44, "training_loss": 62.641019105911255, "training_acc": 69.0, "val_loss": 17.133423686027527, "val_acc": 56.0}
{"epoch": 45, "training_loss": 67.07470107078552, "training_acc": 64.0, "val_loss": 17.122283577919006, "val_acc": 52.0}
{"epoch": 46, "training_loss": 66.59836196899414, "training_acc": 64.0, "val_loss": 17.646674811840057, "val_acc": 52.0}
{"epoch": 47, "training_loss": 61.48075556755066, "training_acc": 70.0, "val_loss": 17.230959236621857, "val_acc": 56.0}
{"epoch": 48, "training_loss": 62.5372211933136, "training_acc": 69.0, "val_loss": 17.68561452627182, "val_acc": 52.0}
{"epoch": 49, "training_loss": 61.95858430862427, "training_acc": 65.0, "val_loss": 17.719438672065735, "val_acc": 52.0}
{"epoch": 50, "training_loss": 63.82452416419983, "training_acc": 59.0, "val_loss": 17.53208488225937, "val_acc": 52.0}
{"epoch": 51, "training_loss": 65.81564712524414, "training_acc": 61.0, "val_loss": 17.430400848388672, "val_acc": 52.0}
{"epoch": 52, "training_loss": 62.37895894050598, "training_acc": 71.0, "val_loss": 18.14088076353073, "val_acc": 52.0}
{"epoch": 53, "training_loss": 64.1102945804596, "training_acc": 61.0, "val_loss": 17.40262508392334, "val_acc": 52.0}
{"epoch": 54, "training_loss": 60.52596163749695, "training_acc": 70.0, "val_loss": 17.473413050174713, "val_acc": 52.0}
{"epoch": 55, "training_loss": 64.0663571357727, "training_acc": 61.0, "val_loss": 17.457957565784454, "val_acc": 52.0}
{"epoch": 56, "training_loss": 60.51489329338074, "training_acc": 74.0, "val_loss": 17.210064828395844, "val_acc": 60.0}
{"epoch": 57, "training_loss": 60.44684958457947, "training_acc": 68.0, "val_loss": 17.626914381980896, "val_acc": 52.0}
