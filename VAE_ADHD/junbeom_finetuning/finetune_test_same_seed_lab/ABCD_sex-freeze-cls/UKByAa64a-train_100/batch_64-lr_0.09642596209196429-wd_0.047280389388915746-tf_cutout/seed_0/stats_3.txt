"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 267.6403064727783, "training_acc": 49.0, "val_loss": 41.20757877826691, "val_acc": 48.0}
{"epoch": 1, "training_loss": 197.25005626678467, "training_acc": 53.0, "val_loss": 122.0075011253357, "val_acc": 52.0}
{"epoch": 2, "training_loss": 443.2724304199219, "training_acc": 53.0, "val_loss": 73.74488711357117, "val_acc": 52.0}
{"epoch": 3, "training_loss": 194.8658835887909, "training_acc": 53.0, "val_loss": 52.463072538375854, "val_acc": 48.0}
{"epoch": 4, "training_loss": 263.30437183380127, "training_acc": 47.0, "val_loss": 64.8783266544342, "val_acc": 48.0}
{"epoch": 5, "training_loss": 218.14386701583862, "training_acc": 47.0, "val_loss": 27.545756101608276, "val_acc": 52.0}
{"epoch": 6, "training_loss": 151.8870210647583, "training_acc": 53.0, "val_loss": 64.68945145606995, "val_acc": 52.0}
{"epoch": 7, "training_loss": 204.83548021316528, "training_acc": 53.0, "val_loss": 24.97074604034424, "val_acc": 52.0}
{"epoch": 8, "training_loss": 82.28981852531433, "training_acc": 55.0, "val_loss": 38.29580545425415, "val_acc": 48.0}
{"epoch": 9, "training_loss": 165.0293731689453, "training_acc": 47.0, "val_loss": 22.623616456985474, "val_acc": 48.0}
{"epoch": 10, "training_loss": 89.3076319694519, "training_acc": 50.0, "val_loss": 36.681073904037476, "val_acc": 52.0}
{"epoch": 11, "training_loss": 127.65197134017944, "training_acc": 53.0, "val_loss": 28.416121006011963, "val_acc": 52.0}
{"epoch": 12, "training_loss": 84.15858292579651, "training_acc": 54.0, "val_loss": 25.021904706954956, "val_acc": 48.0}
{"epoch": 13, "training_loss": 104.45525479316711, "training_acc": 47.0, "val_loss": 20.33955752849579, "val_acc": 48.0}
{"epoch": 14, "training_loss": 79.81264114379883, "training_acc": 47.0, "val_loss": 24.635237455368042, "val_acc": 52.0}
{"epoch": 15, "training_loss": 93.80261278152466, "training_acc": 53.0, "val_loss": 19.084130227565765, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.85199284553528, "training_acc": 53.0, "val_loss": 21.92627340555191, "val_acc": 48.0}
{"epoch": 17, "training_loss": 86.45264053344727, "training_acc": 47.0, "val_loss": 16.998067498207092, "val_acc": 52.0}
{"epoch": 18, "training_loss": 65.59843063354492, "training_acc": 65.0, "val_loss": 23.740077018737793, "val_acc": 52.0}
{"epoch": 19, "training_loss": 81.55972671508789, "training_acc": 53.0, "val_loss": 17.270955443382263, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.56881809234619, "training_acc": 60.0, "val_loss": 18.97536814212799, "val_acc": 52.0}
{"epoch": 21, "training_loss": 72.08075046539307, "training_acc": 52.0, "val_loss": 20.474471151828766, "val_acc": 52.0}
{"epoch": 22, "training_loss": 73.00546765327454, "training_acc": 54.0, "val_loss": 20.79072743654251, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.17763471603394, "training_acc": 54.0, "val_loss": 18.86170506477356, "val_acc": 44.0}
{"epoch": 24, "training_loss": 73.5304343700409, "training_acc": 48.0, "val_loss": 18.260011076927185, "val_acc": 52.0}
{"epoch": 25, "training_loss": 71.7927668094635, "training_acc": 56.0, "val_loss": 22.089549899101257, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.88333821296692, "training_acc": 58.0, "val_loss": 18.516601622104645, "val_acc": 44.0}
{"epoch": 27, "training_loss": 67.6761200428009, "training_acc": 61.0, "val_loss": 18.542788922786713, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.58718419075012, "training_acc": 55.0, "val_loss": 19.227507710456848, "val_acc": 52.0}
{"epoch": 29, "training_loss": 63.12736892700195, "training_acc": 65.0, "val_loss": 18.43879222869873, "val_acc": 52.0}
{"epoch": 30, "training_loss": 63.7240993976593, "training_acc": 67.0, "val_loss": 18.431363999843597, "val_acc": 52.0}
{"epoch": 31, "training_loss": 64.8086850643158, "training_acc": 67.0, "val_loss": 18.46977323293686, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.55999684333801, "training_acc": 63.0, "val_loss": 18.09656471014023, "val_acc": 52.0}
{"epoch": 33, "training_loss": 62.78364443778992, "training_acc": 74.0, "val_loss": 17.55847930908203, "val_acc": 52.0}
{"epoch": 34, "training_loss": 66.7569580078125, "training_acc": 59.0, "val_loss": 18.13110113143921, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.0443856716156, "training_acc": 64.0, "val_loss": 18.44203919172287, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.66943168640137, "training_acc": 53.0, "val_loss": 17.50265061855316, "val_acc": 52.0}
