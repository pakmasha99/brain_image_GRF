"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1508.389991760254, "training_acc": 53.0, "val_loss": 72.21572995185852, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2017.1187744140625, "training_acc": 47.0, "val_loss": 1359.3132019042969, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5203.305740356445, "training_acc": 47.0, "val_loss": 614.5963668823242, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1784.3594789505005, "training_acc": 47.0, "val_loss": 394.44127082824707, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1632.4270629882812, "training_acc": 53.0, "val_loss": 296.6803550720215, "val_acc": 52.0}
{"epoch": 5, "training_loss": 888.408504486084, "training_acc": 45.0, "val_loss": 125.2420425415039, "val_acc": 48.0}
{"epoch": 6, "training_loss": 365.1737229824066, "training_acc": 47.0, "val_loss": 51.62898898124695, "val_acc": 52.0}
{"epoch": 7, "training_loss": 233.41603565216064, "training_acc": 51.0, "val_loss": 18.893615901470184, "val_acc": 40.0}
{"epoch": 8, "training_loss": 149.99820804595947, "training_acc": 60.0, "val_loss": 53.598690032958984, "val_acc": 52.0}
{"epoch": 9, "training_loss": 326.3665943145752, "training_acc": 51.0, "val_loss": 134.5753788948059, "val_acc": 48.0}
{"epoch": 10, "training_loss": 378.05677032470703, "training_acc": 53.0, "val_loss": 71.23310565948486, "val_acc": 52.0}
{"epoch": 11, "training_loss": 237.27697944641113, "training_acc": 51.0, "val_loss": 20.17657458782196, "val_acc": 52.0}
{"epoch": 12, "training_loss": 132.58403301239014, "training_acc": 52.0, "val_loss": 94.400554895401, "val_acc": 48.0}
{"epoch": 13, "training_loss": 341.63926792144775, "training_acc": 47.0, "val_loss": 128.49727869033813, "val_acc": 52.0}
{"epoch": 14, "training_loss": 509.8999900817871, "training_acc": 53.0, "val_loss": 47.360759973526, "val_acc": 52.0}
{"epoch": 15, "training_loss": 248.61692810058594, "training_acc": 63.0, "val_loss": 236.31386756896973, "val_acc": 48.0}
{"epoch": 16, "training_loss": 819.6276817321777, "training_acc": 47.0, "val_loss": 110.45651435852051, "val_acc": 52.0}
{"epoch": 17, "training_loss": 501.73521614074707, "training_acc": 53.0, "val_loss": 104.73722219467163, "val_acc": 52.0}
{"epoch": 18, "training_loss": 396.23093605041504, "training_acc": 51.0, "val_loss": 129.78838682174683, "val_acc": 48.0}
{"epoch": 19, "training_loss": 331.5087740421295, "training_acc": 46.0, "val_loss": 190.17220735549927, "val_acc": 52.0}
{"epoch": 20, "training_loss": 861.5072326660156, "training_acc": 53.0, "val_loss": 146.40802145004272, "val_acc": 52.0}
{"epoch": 21, "training_loss": 557.2014865875244, "training_acc": 47.0, "val_loss": 169.12065744400024, "val_acc": 48.0}
{"epoch": 22, "training_loss": 550.5508561134338, "training_acc": 47.0, "val_loss": 172.14754819869995, "val_acc": 52.0}
{"epoch": 23, "training_loss": 728.7724990844727, "training_acc": 53.0, "val_loss": 154.39305305480957, "val_acc": 52.0}
{"epoch": 24, "training_loss": 421.09710693359375, "training_acc": 53.0, "val_loss": 90.04768133163452, "val_acc": 48.0}
{"epoch": 25, "training_loss": 271.8359456062317, "training_acc": 49.0, "val_loss": 33.311232924461365, "val_acc": 52.0}
{"epoch": 26, "training_loss": 204.44089603424072, "training_acc": 47.0, "val_loss": 19.813169538974762, "val_acc": 48.0}
