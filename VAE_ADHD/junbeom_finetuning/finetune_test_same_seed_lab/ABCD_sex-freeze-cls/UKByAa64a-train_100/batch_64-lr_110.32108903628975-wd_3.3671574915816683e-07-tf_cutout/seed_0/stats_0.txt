"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 421970.4845275879, "training_acc": 52.0, "val_loss": 140235.5224609375, "val_acc": 44.0}
{"epoch": 1, "training_loss": 430720.451171875, "training_acc": 48.0, "val_loss": 147491.9189453125, "val_acc": 56.0}
{"epoch": 2, "training_loss": 683464.2734375, "training_acc": 52.0, "val_loss": 62005.291748046875, "val_acc": 56.0}
{"epoch": 3, "training_loss": 352742.095703125, "training_acc": 54.0, "val_loss": 237204.2236328125, "val_acc": 44.0}
{"epoch": 4, "training_loss": 796638.451171875, "training_acc": 48.0, "val_loss": 20011.58905029297, "val_acc": 44.0}
{"epoch": 5, "training_loss": 370431.97265625, "training_acc": 44.0, "val_loss": 261645.166015625, "val_acc": 56.0}
{"epoch": 6, "training_loss": 1143991.59375, "training_acc": 52.0, "val_loss": 200790.49072265625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 698699.3330078125, "training_acc": 52.0, "val_loss": 112009.16748046875, "val_acc": 44.0}
{"epoch": 8, "training_loss": 507269.962890625, "training_acc": 48.0, "val_loss": 216094.970703125, "val_acc": 44.0}
{"epoch": 9, "training_loss": 705726.3828125, "training_acc": 48.0, "val_loss": 6381.412124633789, "val_acc": 44.0}
{"epoch": 10, "training_loss": 237026.666015625, "training_acc": 52.0, "val_loss": 226238.5986328125, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1012332.89453125, "training_acc": 52.0, "val_loss": 198383.87451171875, "val_acc": 56.0}
{"epoch": 12, "training_loss": 706920.28515625, "training_acc": 52.0, "val_loss": 43995.20263671875, "val_acc": 44.0}
{"epoch": 13, "training_loss": 281288.27734375, "training_acc": 48.0, "val_loss": 132539.22119140625, "val_acc": 44.0}
{"epoch": 14, "training_loss": 383562.9248046875, "training_acc": 48.0, "val_loss": 62197.75390625, "val_acc": 56.0}
{"epoch": 15, "training_loss": 329774.0009765625, "training_acc": 52.0, "val_loss": 97402.91748046875, "val_acc": 56.0}
{"epoch": 16, "training_loss": 330649.55615234375, "training_acc": 52.0, "val_loss": 84704.10766601562, "val_acc": 44.0}
{"epoch": 17, "training_loss": 375962.4921875, "training_acc": 48.0, "val_loss": 106668.5791015625, "val_acc": 44.0}
{"epoch": 18, "training_loss": 258947.7764892578, "training_acc": 48.0, "val_loss": 114961.474609375, "val_acc": 56.0}
{"epoch": 19, "training_loss": 597314.779296875, "training_acc": 52.0, "val_loss": 177335.44921875, "val_acc": 56.0}
{"epoch": 20, "training_loss": 694580.318359375, "training_acc": 52.0, "val_loss": 31851.214599609375, "val_acc": 56.0}
{"epoch": 21, "training_loss": 294254.98046875, "training_acc": 46.0, "val_loss": 217135.498046875, "val_acc": 44.0}
{"epoch": 22, "training_loss": 794116.90625, "training_acc": 48.0, "val_loss": 150883.55712890625, "val_acc": 44.0}
{"epoch": 23, "training_loss": 394257.6564941406, "training_acc": 48.0, "val_loss": 124709.814453125, "val_acc": 56.0}
{"epoch": 24, "training_loss": 680863.70703125, "training_acc": 52.0, "val_loss": 220143.3349609375, "val_acc": 56.0}
{"epoch": 25, "training_loss": 902551.59765625, "training_acc": 52.0, "val_loss": 101567.63916015625, "val_acc": 56.0}
{"epoch": 26, "training_loss": 242143.2205810547, "training_acc": 62.0, "val_loss": 99560.05859375, "val_acc": 44.0}
{"epoch": 27, "training_loss": 365138.8642578125, "training_acc": 48.0, "val_loss": 38217.584228515625, "val_acc": 44.0}
{"epoch": 28, "training_loss": 169311.9755859375, "training_acc": 54.0, "val_loss": 110477.08740234375, "val_acc": 56.0}
