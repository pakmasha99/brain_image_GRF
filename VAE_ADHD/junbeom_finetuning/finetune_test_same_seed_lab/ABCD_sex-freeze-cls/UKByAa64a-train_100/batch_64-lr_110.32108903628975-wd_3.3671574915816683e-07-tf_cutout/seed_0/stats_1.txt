"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 326275.3334274292, "training_acc": 51.0, "val_loss": 172089.34326171875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 567812.666015625, "training_acc": 47.0, "val_loss": 174910.2783203125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 795773.41015625, "training_acc": 53.0, "val_loss": 142986.02294921875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 430612.5712890625, "training_acc": 51.0, "val_loss": 95677.04467773438, "val_acc": 48.0}
{"epoch": 4, "training_loss": 281588.83166503906, "training_acc": 47.0, "val_loss": 137150.50048828125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 584211.6640625, "training_acc": 53.0, "val_loss": 137037.0849609375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 397258.20947265625, "training_acc": 53.0, "val_loss": 149108.1787109375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 697479.4765625, "training_acc": 47.0, "val_loss": 190785.29052734375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 618352.9794921875, "training_acc": 47.0, "val_loss": 74352.47192382812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 339451.3603515625, "training_acc": 53.0, "val_loss": 148966.9921875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 511815.779296875, "training_acc": 53.0, "val_loss": 2741.317367553711, "val_acc": 28.0}
{"epoch": 11, "training_loss": 90941.08349609375, "training_acc": 54.0, "val_loss": 85416.39404296875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 244915.05859375, "training_acc": 47.0, "val_loss": 104728.72314453125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 463553.796875, "training_acc": 53.0, "val_loss": 135769.22607421875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 428793.3173828125, "training_acc": 53.0, "val_loss": 60581.207275390625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 313755.529296875, "training_acc": 47.0, "val_loss": 81839.23950195312, "val_acc": 48.0}
{"epoch": 16, "training_loss": 220609.5213623047, "training_acc": 51.0, "val_loss": 35559.991455078125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 106810.06237792969, "training_acc": 46.0, "val_loss": 27997.705078125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72528.96270751953, "training_acc": 54.0, "val_loss": 81405.859375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 334337.580078125, "training_acc": 47.0, "val_loss": 27692.68798828125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 134671.03515625, "training_acc": 59.0, "val_loss": 131519.61669921875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 502812.962890625, "training_acc": 53.0, "val_loss": 60821.2646484375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 254748.0771484375, "training_acc": 47.0, "val_loss": 95426.2451171875, "val_acc": 48.0}
{"epoch": 23, "training_loss": 331137.7470703125, "training_acc": 47.0, "val_loss": 36129.57763671875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 192210.1669921875, "training_acc": 53.0, "val_loss": 29706.982421875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 108891.4345703125, "training_acc": 63.0, "val_loss": 83061.30981445312, "val_acc": 48.0}
{"epoch": 26, "training_loss": 270571.74755859375, "training_acc": 47.0, "val_loss": 57889.727783203125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 267932.9609375, "training_acc": 53.0, "val_loss": 59131.524658203125, "val_acc": 52.0}
{"epoch": 28, "training_loss": 179031.58520507812, "training_acc": 51.0, "val_loss": 36150.836181640625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 117058.2783203125, "training_acc": 49.0, "val_loss": 12349.79476928711, "val_acc": 52.0}
