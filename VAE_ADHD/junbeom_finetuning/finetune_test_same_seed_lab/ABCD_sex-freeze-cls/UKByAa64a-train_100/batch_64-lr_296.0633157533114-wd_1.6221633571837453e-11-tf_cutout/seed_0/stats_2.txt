"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 814910.9150009155, "training_acc": 53.0, "val_loss": 160248.05908203125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 818561.35546875, "training_acc": 41.0, "val_loss": 265091.11328125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 966854.1328125, "training_acc": 47.0, "val_loss": 55293.49365234375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 414237.412109375, "training_acc": 41.0, "val_loss": 232448.5595703125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 891045.095703125, "training_acc": 53.0, "val_loss": 190523.79150390625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 590632.8154296875, "training_acc": 53.0, "val_loss": 42255.62438964844, "val_acc": 48.0}
{"epoch": 6, "training_loss": 274174.486328125, "training_acc": 47.0, "val_loss": 100657.01293945312, "val_acc": 48.0}
{"epoch": 7, "training_loss": 326295.1416015625, "training_acc": 47.0, "val_loss": 73058.2275390625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 329857.328125, "training_acc": 53.0, "val_loss": 109189.4775390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 342870.63134765625, "training_acc": 53.0, "val_loss": 35737.00256347656, "val_acc": 48.0}
{"epoch": 10, "training_loss": 181838.5009765625, "training_acc": 47.0, "val_loss": 41562.25280761719, "val_acc": 48.0}
{"epoch": 11, "training_loss": 122201.67309570312, "training_acc": 54.0, "val_loss": 44702.960205078125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 136644.59741210938, "training_acc": 51.0, "val_loss": 45321.39892578125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 180162.93212890625, "training_acc": 47.0, "val_loss": 6234.164047241211, "val_acc": 52.0}
{"epoch": 14, "training_loss": 88775.0009765625, "training_acc": 59.0, "val_loss": 39419.281005859375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 102926.20886230469, "training_acc": 53.0, "val_loss": 19077.198791503906, "val_acc": 44.0}
{"epoch": 16, "training_loss": 72255.529296875, "training_acc": 49.0, "val_loss": 9378.285217285156, "val_acc": 60.0}
{"epoch": 17, "training_loss": 55338.83154296875, "training_acc": 48.0, "val_loss": 11488.27133178711, "val_acc": 60.0}
{"epoch": 18, "training_loss": 29713.041259765625, "training_acc": 60.0, "val_loss": 16343.290710449219, "val_acc": 48.0}
{"epoch": 19, "training_loss": 57831.4580078125, "training_acc": 55.0, "val_loss": 38822.71423339844, "val_acc": 52.0}
{"epoch": 20, "training_loss": 109829.33862304688, "training_acc": 53.0, "val_loss": 9950.764465332031, "val_acc": 44.0}
{"epoch": 21, "training_loss": 42525.81201171875, "training_acc": 54.0, "val_loss": 16348.908996582031, "val_acc": 52.0}
{"epoch": 22, "training_loss": 34519.552001953125, "training_acc": 58.0, "val_loss": 14418.318176269531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 45964.207763671875, "training_acc": 50.0, "val_loss": 20911.819458007812, "val_acc": 52.0}
{"epoch": 24, "training_loss": 49566.91955566406, "training_acc": 62.0, "val_loss": 32354.440307617188, "val_acc": 48.0}
{"epoch": 25, "training_loss": 111232.15283203125, "training_acc": 47.0, "val_loss": 45010.85205078125, "val_acc": 52.0}
{"epoch": 26, "training_loss": 170462.6318359375, "training_acc": 53.0, "val_loss": 29109.597778320312, "val_acc": 52.0}
{"epoch": 27, "training_loss": 124208.85400390625, "training_acc": 49.0, "val_loss": 56450.74462890625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 176325.73510742188, "training_acc": 47.0, "val_loss": 68782.67211914062, "val_acc": 52.0}
{"epoch": 29, "training_loss": 299255.12890625, "training_acc": 53.0, "val_loss": 91740.77758789062, "val_acc": 52.0}
{"epoch": 30, "training_loss": 252491.265625, "training_acc": 53.0, "val_loss": 62925.0, "val_acc": 48.0}
{"epoch": 31, "training_loss": 322182.666015625, "training_acc": 47.0, "val_loss": 80234.96704101562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 230075.93359375, "training_acc": 49.0, "val_loss": 91181.39038085938, "val_acc": 52.0}
