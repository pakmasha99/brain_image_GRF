"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 500691.5838508606, "training_acc": 53.0, "val_loss": 16724.73602294922, "val_acc": 44.0}
{"epoch": 1, "training_loss": 609160.78515625, "training_acc": 53.0, "val_loss": 259323.0224609375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 691300.5285644531, "training_acc": 44.0, "val_loss": 84106.25, "val_acc": 52.0}
{"epoch": 3, "training_loss": 246745.5487060547, "training_acc": 53.0, "val_loss": 65444.073486328125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 188629.96936035156, "training_acc": 48.0, "val_loss": 18247.328186035156, "val_acc": 56.0}
{"epoch": 5, "training_loss": 128734.1943359375, "training_acc": 44.0, "val_loss": 6551.619720458984, "val_acc": 64.0}
{"epoch": 6, "training_loss": 75257.18408203125, "training_acc": 66.0, "val_loss": 17350.149536132812, "val_acc": 52.0}
{"epoch": 7, "training_loss": 178133.134765625, "training_acc": 48.0, "val_loss": 61804.376220703125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 187880.16088867188, "training_acc": 55.0, "val_loss": 46854.69665527344, "val_acc": 52.0}
{"epoch": 9, "training_loss": 112799.5625, "training_acc": 59.0, "val_loss": 30542.987060546875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 94224.94067382812, "training_acc": 55.0, "val_loss": 9688.261413574219, "val_acc": 56.0}
{"epoch": 11, "training_loss": 89265.14501953125, "training_acc": 52.0, "val_loss": 3788.387680053711, "val_acc": 52.0}
{"epoch": 12, "training_loss": 86238.83056640625, "training_acc": 60.0, "val_loss": 35546.86584472656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 179410.5703125, "training_acc": 45.0, "val_loss": 52771.78955078125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 177436.41357421875, "training_acc": 46.0, "val_loss": 34999.00817871094, "val_acc": 52.0}
{"epoch": 15, "training_loss": 113037.60229492188, "training_acc": 51.0, "val_loss": 4117.018127441406, "val_acc": 56.0}
{"epoch": 16, "training_loss": 62947.10791015625, "training_acc": 63.0, "val_loss": 19748.01483154297, "val_acc": 52.0}
{"epoch": 17, "training_loss": 115401.8515625, "training_acc": 54.0, "val_loss": 62381.195068359375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 184656.0499267578, "training_acc": 47.0, "val_loss": 22072.169494628906, "val_acc": 52.0}
{"epoch": 19, "training_loss": 78129.72119140625, "training_acc": 56.0, "val_loss": 5875.284194946289, "val_acc": 56.0}
{"epoch": 20, "training_loss": 26822.582397460938, "training_acc": 65.0, "val_loss": 11707.798767089844, "val_acc": 48.0}
{"epoch": 21, "training_loss": 67532.61791992188, "training_acc": 47.0, "val_loss": 3569.7349548339844, "val_acc": 52.0}
{"epoch": 22, "training_loss": 23856.743530273438, "training_acc": 67.0, "val_loss": 12300.07553100586, "val_acc": 48.0}
{"epoch": 23, "training_loss": 63226.20068359375, "training_acc": 50.0, "val_loss": 5995.914840698242, "val_acc": 60.0}
{"epoch": 24, "training_loss": 50217.53857421875, "training_acc": 61.0, "val_loss": 9071.932220458984, "val_acc": 56.0}
{"epoch": 25, "training_loss": 17457.48992919922, "training_acc": 67.0, "val_loss": 6305.195999145508, "val_acc": 52.0}
{"epoch": 26, "training_loss": 30568.268798828125, "training_acc": 62.0, "val_loss": 27864.520263671875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 75251.86483764648, "training_acc": 55.0, "val_loss": 17798.28338623047, "val_acc": 52.0}
{"epoch": 28, "training_loss": 78989.5263671875, "training_acc": 50.0, "val_loss": 9871.578216552734, "val_acc": 40.0}
{"epoch": 29, "training_loss": 124018.6025390625, "training_acc": 49.0, "val_loss": 83292.41943359375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 218156.26245117188, "training_acc": 53.0, "val_loss": 85682.29370117188, "val_acc": 48.0}
{"epoch": 31, "training_loss": 388176.857421875, "training_acc": 47.0, "val_loss": 74444.41528320312, "val_acc": 48.0}
{"epoch": 32, "training_loss": 271766.46044921875, "training_acc": 41.0, "val_loss": 70100.27465820312, "val_acc": 52.0}
{"epoch": 33, "training_loss": 186853.28271484375, "training_acc": 53.0, "val_loss": 61262.322998046875, "val_acc": 48.0}
{"epoch": 34, "training_loss": 274404.8564453125, "training_acc": 47.0, "val_loss": 25129.653930664062, "val_acc": 48.0}
{"epoch": 35, "training_loss": 145404.9443359375, "training_acc": 55.0, "val_loss": 128746.2158203125, "val_acc": 52.0}
{"epoch": 36, "training_loss": 448206.248046875, "training_acc": 53.0, "val_loss": 36330.9326171875, "val_acc": 52.0}
{"epoch": 37, "training_loss": 158549.322265625, "training_acc": 59.0, "val_loss": 153269.921875, "val_acc": 48.0}
{"epoch": 38, "training_loss": 567021.185546875, "training_acc": 47.0, "val_loss": 50363.21716308594, "val_acc": 48.0}
{"epoch": 39, "training_loss": 191180.4140625, "training_acc": 58.0, "val_loss": 158364.4775390625, "val_acc": 52.0}
{"epoch": 40, "training_loss": 619460.921875, "training_acc": 53.0, "val_loss": 109810.595703125, "val_acc": 52.0}
