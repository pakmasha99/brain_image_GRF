"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 805200.0419197083, "training_acc": 46.0, "val_loss": 168294.47021484375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 817230.59375, "training_acc": 53.0, "val_loss": 435853.466796875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1640333.6953125, "training_acc": 47.0, "val_loss": 120815.0390625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 571574.8984375, "training_acc": 51.0, "val_loss": 318308.740234375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1209344.56640625, "training_acc": 53.0, "val_loss": 284032.3974609375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 842983.294921875, "training_acc": 53.0, "val_loss": 49356.91223144531, "val_acc": 48.0}
{"epoch": 6, "training_loss": 454879.6484375, "training_acc": 47.0, "val_loss": 145485.55908203125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 493133.0302734375, "training_acc": 47.0, "val_loss": 105411.9384765625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 411032.158203125, "training_acc": 53.0, "val_loss": 182779.96826171875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 593514.470703125, "training_acc": 53.0, "val_loss": 23026.593017578125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 237380.859375, "training_acc": 49.0, "val_loss": 169959.09423828125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 651191.744140625, "training_acc": 47.0, "val_loss": 36056.38122558594, "val_acc": 48.0}
{"epoch": 12, "training_loss": 235940.9462890625, "training_acc": 49.0, "val_loss": 178831.3720703125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 687561.484375, "training_acc": 53.0, "val_loss": 134059.8388671875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 359885.30322265625, "training_acc": 52.0, "val_loss": 131481.60400390625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 640558.703125, "training_acc": 47.0, "val_loss": 195550.03662109375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 659749.666015625, "training_acc": 47.0, "val_loss": 17805.64422607422, "val_acc": 60.0}
{"epoch": 17, "training_loss": 163991.072265625, "training_acc": 54.0, "val_loss": 111437.890625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 357961.6845703125, "training_acc": 53.0, "val_loss": 24726.795959472656, "val_acc": 48.0}
{"epoch": 19, "training_loss": 109099.6328125, "training_acc": 50.0, "val_loss": 12272.4853515625, "val_acc": 56.0}
{"epoch": 20, "training_loss": 78871.63671875, "training_acc": 62.0, "val_loss": 18779.788208007812, "val_acc": 60.0}
{"epoch": 21, "training_loss": 70362.15087890625, "training_acc": 56.0, "val_loss": 20913.043212890625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 97093.73193359375, "training_acc": 55.0, "val_loss": 51549.053955078125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 95970.41522216797, "training_acc": 63.0, "val_loss": 42938.043212890625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 144737.2001953125, "training_acc": 51.0, "val_loss": 51659.19189453125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 162193.595703125, "training_acc": 55.0, "val_loss": 14713.984680175781, "val_acc": 56.0}
{"epoch": 26, "training_loss": 138810.876953125, "training_acc": 55.0, "val_loss": 47475.347900390625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 167718.57348632812, "training_acc": 49.0, "val_loss": 48079.45251464844, "val_acc": 52.0}
{"epoch": 28, "training_loss": 102856.74987792969, "training_acc": 53.0, "val_loss": 54129.3212890625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 217320.6787109375, "training_acc": 47.0, "val_loss": 35491.748046875, "val_acc": 56.0}
{"epoch": 30, "training_loss": 132900.39501953125, "training_acc": 54.0, "val_loss": 22662.359619140625, "val_acc": 60.0}
{"epoch": 31, "training_loss": 125012.2841796875, "training_acc": 52.0, "val_loss": 46916.81823730469, "val_acc": 48.0}
{"epoch": 32, "training_loss": 156411.10668945312, "training_acc": 47.0, "val_loss": 32588.83056640625, "val_acc": 56.0}
{"epoch": 33, "training_loss": 80945.81713867188, "training_acc": 64.0, "val_loss": 31976.031494140625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 133409.64819335938, "training_acc": 43.0, "val_loss": 12151.612854003906, "val_acc": 64.0}
{"epoch": 35, "training_loss": 69756.568359375, "training_acc": 55.0, "val_loss": 11978.897094726562, "val_acc": 64.0}
{"epoch": 36, "training_loss": 54275.9111328125, "training_acc": 58.0, "val_loss": 13931.546020507812, "val_acc": 60.0}
{"epoch": 37, "training_loss": 46557.787353515625, "training_acc": 56.0, "val_loss": 21597.4853515625, "val_acc": 56.0}
{"epoch": 38, "training_loss": 45842.7734375, "training_acc": 53.0, "val_loss": 12198.859405517578, "val_acc": 44.0}
{"epoch": 39, "training_loss": 51698.94970703125, "training_acc": 54.0, "val_loss": 4074.2706298828125, "val_acc": 56.0}
{"epoch": 40, "training_loss": 18899.161865234375, "training_acc": 71.0, "val_loss": 6651.741027832031, "val_acc": 60.0}
{"epoch": 41, "training_loss": 24792.593688964844, "training_acc": 67.0, "val_loss": 12207.978057861328, "val_acc": 56.0}
{"epoch": 42, "training_loss": 58768.391357421875, "training_acc": 52.0, "val_loss": 10693.067932128906, "val_acc": 56.0}
{"epoch": 43, "training_loss": 21513.07159423828, "training_acc": 67.0, "val_loss": 30109.963989257812, "val_acc": 48.0}
{"epoch": 44, "training_loss": 92961.98809814453, "training_acc": 48.0, "val_loss": 6214.270401000977, "val_acc": 48.0}
{"epoch": 45, "training_loss": 45865.68408203125, "training_acc": 56.0, "val_loss": 19403.765869140625, "val_acc": 52.0}
{"epoch": 46, "training_loss": 54765.8974609375, "training_acc": 60.0, "val_loss": 4938.815689086914, "val_acc": 52.0}
{"epoch": 47, "training_loss": 99242.16748046875, "training_acc": 55.0, "val_loss": 57800.640869140625, "val_acc": 52.0}
{"epoch": 48, "training_loss": 154822.74633789062, "training_acc": 52.0, "val_loss": 23189.05029296875, "val_acc": 48.0}
{"epoch": 49, "training_loss": 78266.97631835938, "training_acc": 53.0, "val_loss": 7851.419830322266, "val_acc": 56.0}
{"epoch": 50, "training_loss": 84893.2685546875, "training_acc": 53.0, "val_loss": 9283.720397949219, "val_acc": 48.0}
{"epoch": 51, "training_loss": 98158.6728515625, "training_acc": 61.0, "val_loss": 58579.351806640625, "val_acc": 52.0}
{"epoch": 52, "training_loss": 152223.1026611328, "training_acc": 62.0, "val_loss": 69190.54565429688, "val_acc": 48.0}
{"epoch": 53, "training_loss": 247254.359375, "training_acc": 46.0, "val_loss": 13272.5830078125, "val_acc": 56.0}
{"epoch": 54, "training_loss": 78186.34716796875, "training_acc": 59.0, "val_loss": 7485.723114013672, "val_acc": 64.0}
{"epoch": 55, "training_loss": 85524.2919921875, "training_acc": 60.0, "val_loss": 20881.997680664062, "val_acc": 44.0}
{"epoch": 56, "training_loss": 94182.43017578125, "training_acc": 59.0, "val_loss": 84318.67065429688, "val_acc": 52.0}
{"epoch": 57, "training_loss": 239459.22705078125, "training_acc": 53.0, "val_loss": 48666.7724609375, "val_acc": 48.0}
{"epoch": 58, "training_loss": 245350.8681640625, "training_acc": 47.0, "val_loss": 11665.608978271484, "val_acc": 48.0}
