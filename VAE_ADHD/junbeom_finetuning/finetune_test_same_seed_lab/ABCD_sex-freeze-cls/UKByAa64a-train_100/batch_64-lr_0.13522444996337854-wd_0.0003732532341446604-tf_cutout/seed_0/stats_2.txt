"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1197.6133193969727, "training_acc": 53.0, "val_loss": 229.83191013336182, "val_acc": 52.0}
{"epoch": 1, "training_loss": 946.523365020752, "training_acc": 57.0, "val_loss": 528.1070232391357, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2019.7247161865234, "training_acc": 47.0, "val_loss": 182.1449875831604, "val_acc": 48.0}
{"epoch": 3, "training_loss": 686.0018138885498, "training_acc": 51.0, "val_loss": 329.9035310745239, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1331.3284225463867, "training_acc": 53.0, "val_loss": 263.72597217559814, "val_acc": 52.0}
{"epoch": 5, "training_loss": 801.4504833221436, "training_acc": 53.0, "val_loss": 182.13988542556763, "val_acc": 48.0}
{"epoch": 6, "training_loss": 941.9632911682129, "training_acc": 47.0, "val_loss": 291.3165330886841, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1023.2052555084229, "training_acc": 47.0, "val_loss": 27.405473589897156, "val_acc": 52.0}
{"epoch": 8, "training_loss": 274.45789527893066, "training_acc": 53.0, "val_loss": 138.0343198776245, "val_acc": 52.0}
{"epoch": 9, "training_loss": 436.3966875076294, "training_acc": 53.0, "val_loss": 84.4481348991394, "val_acc": 48.0}
{"epoch": 10, "training_loss": 407.6735153198242, "training_acc": 47.0, "val_loss": 75.30158758163452, "val_acc": 48.0}
{"epoch": 11, "training_loss": 249.95336246490479, "training_acc": 53.0, "val_loss": 97.31906056404114, "val_acc": 52.0}
{"epoch": 12, "training_loss": 335.99050998687744, "training_acc": 53.0, "val_loss": 39.68406319618225, "val_acc": 48.0}
{"epoch": 13, "training_loss": 215.71350574493408, "training_acc": 47.0, "val_loss": 19.319869577884674, "val_acc": 52.0}
{"epoch": 14, "training_loss": 85.64487195014954, "training_acc": 53.0, "val_loss": 25.480112433433533, "val_acc": 52.0}
{"epoch": 15, "training_loss": 137.23916816711426, "training_acc": 49.0, "val_loss": 26.063737273216248, "val_acc": 48.0}
{"epoch": 16, "training_loss": 167.68270301818848, "training_acc": 45.0, "val_loss": 55.57782053947449, "val_acc": 52.0}
{"epoch": 17, "training_loss": 204.30500650405884, "training_acc": 45.0, "val_loss": 28.58595848083496, "val_acc": 48.0}
{"epoch": 18, "training_loss": 139.60180521011353, "training_acc": 47.0, "val_loss": 32.24224150180817, "val_acc": 52.0}
{"epoch": 19, "training_loss": 173.64749717712402, "training_acc": 45.0, "val_loss": 32.33065605163574, "val_acc": 48.0}
{"epoch": 20, "training_loss": 141.56042432785034, "training_acc": 53.0, "val_loss": 60.37488579750061, "val_acc": 52.0}
{"epoch": 21, "training_loss": 181.09918332099915, "training_acc": 48.0, "val_loss": 49.69613254070282, "val_acc": 48.0}
{"epoch": 22, "training_loss": 154.47796821594238, "training_acc": 47.0, "val_loss": 70.17796635627747, "val_acc": 52.0}
{"epoch": 23, "training_loss": 293.2454719543457, "training_acc": 53.0, "val_loss": 20.74083238840103, "val_acc": 52.0}
{"epoch": 24, "training_loss": 194.41384887695312, "training_acc": 49.0, "val_loss": 98.6021101474762, "val_acc": 48.0}
{"epoch": 25, "training_loss": 284.1813507080078, "training_acc": 47.0, "val_loss": 106.60899877548218, "val_acc": 52.0}
{"epoch": 26, "training_loss": 480.4594478607178, "training_acc": 53.0, "val_loss": 121.61606550216675, "val_acc": 52.0}
{"epoch": 27, "training_loss": 362.2836022377014, "training_acc": 53.0, "val_loss": 116.20261669158936, "val_acc": 48.0}
{"epoch": 28, "training_loss": 517.3920021057129, "training_acc": 47.0, "val_loss": 97.51753211021423, "val_acc": 48.0}
{"epoch": 29, "training_loss": 301.3359475135803, "training_acc": 49.0, "val_loss": 80.50868511199951, "val_acc": 52.0}
{"epoch": 30, "training_loss": 277.69962453842163, "training_acc": 53.0, "val_loss": 41.640326380729675, "val_acc": 48.0}
{"epoch": 31, "training_loss": 175.51047658920288, "training_acc": 47.0, "val_loss": 25.840893387794495, "val_acc": 52.0}
{"epoch": 32, "training_loss": 118.55168581008911, "training_acc": 53.0, "val_loss": 28.661730885505676, "val_acc": 48.0}
