"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 562.3966407775879, "training_acc": 52.0, "val_loss": 171.3406801223755, "val_acc": 44.0}
{"epoch": 1, "training_loss": 525.1667261123657, "training_acc": 48.0, "val_loss": 180.87166547775269, "val_acc": 56.0}
{"epoch": 2, "training_loss": 837.4171524047852, "training_acc": 52.0, "val_loss": 75.15533566474915, "val_acc": 56.0}
{"epoch": 3, "training_loss": 431.9379825592041, "training_acc": 54.0, "val_loss": 292.3135280609131, "val_acc": 44.0}
{"epoch": 4, "training_loss": 981.673656463623, "training_acc": 48.0, "val_loss": 29.782989621162415, "val_acc": 44.0}
{"epoch": 5, "training_loss": 424.6639823913574, "training_acc": 44.0, "val_loss": 274.0617513656616, "val_acc": 56.0}
{"epoch": 6, "training_loss": 1164.893497467041, "training_acc": 52.0, "val_loss": 156.31144046783447, "val_acc": 56.0}
{"epoch": 7, "training_loss": 490.08048582077026, "training_acc": 48.0, "val_loss": 141.2793517112732, "val_acc": 44.0}
{"epoch": 8, "training_loss": 505.4080390930176, "training_acc": 48.0, "val_loss": 38.05162012577057, "val_acc": 44.0}
{"epoch": 9, "training_loss": 264.5406837463379, "training_acc": 48.0, "val_loss": 151.325523853302, "val_acc": 56.0}
{"epoch": 10, "training_loss": 608.665002822876, "training_acc": 52.0, "val_loss": 21.497011184692383, "val_acc": 56.0}
{"epoch": 11, "training_loss": 249.3842830657959, "training_acc": 52.0, "val_loss": 208.55581760406494, "val_acc": 44.0}
{"epoch": 12, "training_loss": 701.6383361816406, "training_acc": 48.0, "val_loss": 30.727961659431458, "val_acc": 44.0}
{"epoch": 13, "training_loss": 245.51895904541016, "training_acc": 52.0, "val_loss": 189.5963430404663, "val_acc": 56.0}
{"epoch": 14, "training_loss": 807.2934951782227, "training_acc": 52.0, "val_loss": 102.75176763534546, "val_acc": 56.0}
{"epoch": 15, "training_loss": 377.1198353767395, "training_acc": 46.0, "val_loss": 108.64406824111938, "val_acc": 44.0}
{"epoch": 16, "training_loss": 345.53777980804443, "training_acc": 48.0, "val_loss": 41.55808985233307, "val_acc": 56.0}
{"epoch": 17, "training_loss": 209.54171562194824, "training_acc": 52.0, "val_loss": 23.192231357097626, "val_acc": 56.0}
{"epoch": 18, "training_loss": 176.7269229888916, "training_acc": 50.0, "val_loss": 92.69903898239136, "val_acc": 44.0}
{"epoch": 19, "training_loss": 243.91275358200073, "training_acc": 50.0, "val_loss": 69.77036595344543, "val_acc": 56.0}
{"epoch": 20, "training_loss": 296.1476469039917, "training_acc": 52.0, "val_loss": 17.954494059085846, "val_acc": 56.0}
{"epoch": 21, "training_loss": 170.75829029083252, "training_acc": 47.0, "val_loss": 69.24859285354614, "val_acc": 44.0}
{"epoch": 22, "training_loss": 237.35466146469116, "training_acc": 44.0, "val_loss": 45.832714438438416, "val_acc": 56.0}
{"epoch": 23, "training_loss": 141.72241187095642, "training_acc": 56.0, "val_loss": 54.893529415130615, "val_acc": 44.0}
{"epoch": 24, "training_loss": 154.83246564865112, "training_acc": 47.0, "val_loss": 37.763071060180664, "val_acc": 56.0}
{"epoch": 25, "training_loss": 130.79433870315552, "training_acc": 52.0, "val_loss": 50.244808197021484, "val_acc": 44.0}
{"epoch": 26, "training_loss": 156.02465319633484, "training_acc": 50.0, "val_loss": 20.17701417207718, "val_acc": 56.0}
{"epoch": 27, "training_loss": 79.32766795158386, "training_acc": 52.0, "val_loss": 18.84233057498932, "val_acc": 48.0}
{"epoch": 28, "training_loss": 65.85219502449036, "training_acc": 58.0, "val_loss": 17.969384789466858, "val_acc": 56.0}
{"epoch": 29, "training_loss": 74.66050744056702, "training_acc": 60.0, "val_loss": 22.814105451107025, "val_acc": 56.0}
{"epoch": 30, "training_loss": 84.20523071289062, "training_acc": 52.0, "val_loss": 58.88410210609436, "val_acc": 44.0}
{"epoch": 31, "training_loss": 182.90468454360962, "training_acc": 48.0, "val_loss": 67.09626913070679, "val_acc": 56.0}
{"epoch": 32, "training_loss": 320.57977294921875, "training_acc": 52.0, "val_loss": 32.09816813468933, "val_acc": 56.0}
{"epoch": 33, "training_loss": 242.54362869262695, "training_acc": 48.0, "val_loss": 136.89364194869995, "val_acc": 44.0}
{"epoch": 34, "training_loss": 409.4702777862549, "training_acc": 48.0, "val_loss": 72.0467209815979, "val_acc": 56.0}
{"epoch": 35, "training_loss": 369.7847728729248, "training_acc": 52.0, "val_loss": 75.44682025909424, "val_acc": 56.0}
{"epoch": 36, "training_loss": 268.66550874710083, "training_acc": 48.0, "val_loss": 66.03630185127258, "val_acc": 44.0}
{"epoch": 37, "training_loss": 160.75978136062622, "training_acc": 48.0, "val_loss": 74.00714159011841, "val_acc": 56.0}
{"epoch": 38, "training_loss": 312.80705165863037, "training_acc": 52.0, "val_loss": 20.574796199798584, "val_acc": 56.0}
{"epoch": 39, "training_loss": 147.82636737823486, "training_acc": 56.0, "val_loss": 98.95526766777039, "val_acc": 44.0}
