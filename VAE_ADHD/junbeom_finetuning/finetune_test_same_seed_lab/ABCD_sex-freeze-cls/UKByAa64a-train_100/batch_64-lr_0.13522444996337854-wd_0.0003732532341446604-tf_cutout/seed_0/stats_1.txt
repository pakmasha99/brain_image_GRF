"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1021.9897537231445, "training_acc": 49.0, "val_loss": 232.59177207946777, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1054.8472938537598, "training_acc": 53.0, "val_loss": 487.56632804870605, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1800.0429458618164, "training_acc": 47.0, "val_loss": 82.75424838066101, "val_acc": 48.0}
{"epoch": 3, "training_loss": 650.8502464294434, "training_acc": 47.0, "val_loss": 454.00028228759766, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1813.545639038086, "training_acc": 53.0, "val_loss": 403.5900115966797, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1356.0748481750488, "training_acc": 53.0, "val_loss": 17.407622933387756, "val_acc": 52.0}
{"epoch": 6, "training_loss": 436.4688911437988, "training_acc": 49.0, "val_loss": 300.0375270843506, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1154.6002235412598, "training_acc": 47.0, "val_loss": 109.48556661605835, "val_acc": 48.0}
{"epoch": 8, "training_loss": 455.1426181793213, "training_acc": 47.0, "val_loss": 204.95669841766357, "val_acc": 52.0}
{"epoch": 9, "training_loss": 797.2351684570312, "training_acc": 53.0, "val_loss": 142.46134757995605, "val_acc": 52.0}
{"epoch": 10, "training_loss": 394.1716721057892, "training_acc": 53.0, "val_loss": 145.88260650634766, "val_acc": 48.0}
{"epoch": 11, "training_loss": 681.7910499572754, "training_acc": 47.0, "val_loss": 146.64016962051392, "val_acc": 48.0}
{"epoch": 12, "training_loss": 421.4825117588043, "training_acc": 47.0, "val_loss": 132.67356157302856, "val_acc": 52.0}
{"epoch": 13, "training_loss": 616.4927825927734, "training_acc": 53.0, "val_loss": 158.26826095581055, "val_acc": 52.0}
{"epoch": 14, "training_loss": 449.1890296936035, "training_acc": 53.0, "val_loss": 113.23895454406738, "val_acc": 48.0}
{"epoch": 15, "training_loss": 572.0075130462646, "training_acc": 47.0, "val_loss": 182.5013518333435, "val_acc": 48.0}
{"epoch": 16, "training_loss": 606.2694711685181, "training_acc": 47.0, "val_loss": 74.74586367607117, "val_acc": 52.0}
{"epoch": 17, "training_loss": 391.7130889892578, "training_acc": 53.0, "val_loss": 140.398108959198, "val_acc": 52.0}
{"epoch": 18, "training_loss": 443.3722906112671, "training_acc": 53.0, "val_loss": 74.24992322921753, "val_acc": 48.0}
{"epoch": 19, "training_loss": 380.70216941833496, "training_acc": 47.0, "val_loss": 81.38450384140015, "val_acc": 48.0}
{"epoch": 20, "training_loss": 243.6252303123474, "training_acc": 53.0, "val_loss": 78.7154495716095, "val_acc": 52.0}
{"epoch": 21, "training_loss": 267.8495192527771, "training_acc": 53.0, "val_loss": 42.93074607849121, "val_acc": 48.0}
{"epoch": 22, "training_loss": 196.25173377990723, "training_acc": 47.0, "val_loss": 24.87439066171646, "val_acc": 52.0}
{"epoch": 23, "training_loss": 139.9037961959839, "training_acc": 53.0, "val_loss": 19.106832146644592, "val_acc": 48.0}
{"epoch": 24, "training_loss": 90.84717321395874, "training_acc": 47.0, "val_loss": 20.20774781703949, "val_acc": 52.0}
