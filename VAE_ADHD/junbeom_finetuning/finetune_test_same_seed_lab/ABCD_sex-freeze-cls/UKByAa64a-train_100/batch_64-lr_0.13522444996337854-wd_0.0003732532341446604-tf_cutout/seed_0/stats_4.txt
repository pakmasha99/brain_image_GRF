"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1193.7465591430664, "training_acc": 43.0, "val_loss": 287.5659227371216, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1135.2181930541992, "training_acc": 49.0, "val_loss": 367.49415397644043, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1337.1029949188232, "training_acc": 47.0, "val_loss": 25.44862926006317, "val_acc": 52.0}
{"epoch": 3, "training_loss": 237.85061073303223, "training_acc": 53.0, "val_loss": 83.04345607757568, "val_acc": 52.0}
{"epoch": 4, "training_loss": 309.18253898620605, "training_acc": 51.0, "val_loss": 75.03719329833984, "val_acc": 48.0}
{"epoch": 5, "training_loss": 278.8024277687073, "training_acc": 45.0, "val_loss": 41.448745131492615, "val_acc": 52.0}
{"epoch": 6, "training_loss": 145.72057628631592, "training_acc": 57.0, "val_loss": 34.86408591270447, "val_acc": 48.0}
{"epoch": 7, "training_loss": 178.3712282180786, "training_acc": 49.0, "val_loss": 58.41398239135742, "val_acc": 52.0}
{"epoch": 8, "training_loss": 191.10793542861938, "training_acc": 51.0, "val_loss": 31.353282928466797, "val_acc": 48.0}
{"epoch": 9, "training_loss": 132.0995478630066, "training_acc": 53.0, "val_loss": 39.223501086235046, "val_acc": 52.0}
{"epoch": 10, "training_loss": 203.8106336593628, "training_acc": 43.0, "val_loss": 28.01700234413147, "val_acc": 48.0}
{"epoch": 11, "training_loss": 166.0271463394165, "training_acc": 49.0, "val_loss": 69.03814673423767, "val_acc": 52.0}
{"epoch": 12, "training_loss": 185.55000805854797, "training_acc": 53.0, "val_loss": 76.46819353103638, "val_acc": 48.0}
{"epoch": 13, "training_loss": 277.9742293357849, "training_acc": 47.0, "val_loss": 47.40625619888306, "val_acc": 52.0}
{"epoch": 14, "training_loss": 202.41955280303955, "training_acc": 53.0, "val_loss": 17.444026470184326, "val_acc": 52.0}
{"epoch": 15, "training_loss": 134.72728157043457, "training_acc": 47.0, "val_loss": 18.324409425258636, "val_acc": 64.0}
{"epoch": 16, "training_loss": 150.49250984191895, "training_acc": 45.0, "val_loss": 46.47780358791351, "val_acc": 52.0}
{"epoch": 17, "training_loss": 181.66124868392944, "training_acc": 51.0, "val_loss": 45.595377683639526, "val_acc": 48.0}
{"epoch": 18, "training_loss": 130.38694143295288, "training_acc": 59.0, "val_loss": 50.1015305519104, "val_acc": 52.0}
{"epoch": 19, "training_loss": 141.05254077911377, "training_acc": 53.0, "val_loss": 70.48214077949524, "val_acc": 48.0}
{"epoch": 20, "training_loss": 261.9457082748413, "training_acc": 47.0, "val_loss": 46.037134528160095, "val_acc": 52.0}
{"epoch": 21, "training_loss": 184.94703578948975, "training_acc": 53.0, "val_loss": 17.238697409629822, "val_acc": 52.0}
{"epoch": 22, "training_loss": 112.96753215789795, "training_acc": 51.0, "val_loss": 17.935986816883087, "val_acc": 52.0}
{"epoch": 23, "training_loss": 118.4155445098877, "training_acc": 49.0, "val_loss": 31.268149614334106, "val_acc": 52.0}
{"epoch": 24, "training_loss": 140.42289924621582, "training_acc": 55.0, "val_loss": 48.37577044963837, "val_acc": 48.0}
{"epoch": 25, "training_loss": 172.46828651428223, "training_acc": 51.0, "val_loss": 46.3080495595932, "val_acc": 52.0}
{"epoch": 26, "training_loss": 173.40099573135376, "training_acc": 45.0, "val_loss": 19.28074061870575, "val_acc": 48.0}
{"epoch": 27, "training_loss": 111.37339782714844, "training_acc": 47.0, "val_loss": 19.078248739242554, "val_acc": 52.0}
{"epoch": 28, "training_loss": 109.83873796463013, "training_acc": 53.0, "val_loss": 21.20237648487091, "val_acc": 48.0}
{"epoch": 29, "training_loss": 135.4339017868042, "training_acc": 49.0, "val_loss": 46.52906060218811, "val_acc": 52.0}
{"epoch": 30, "training_loss": 172.7000608444214, "training_acc": 51.0, "val_loss": 36.41909658908844, "val_acc": 48.0}
{"epoch": 31, "training_loss": 149.52872610092163, "training_acc": 51.0, "val_loss": 43.972885608673096, "val_acc": 52.0}
{"epoch": 32, "training_loss": 163.25664043426514, "training_acc": 49.0, "val_loss": 24.718089401721954, "val_acc": 48.0}
{"epoch": 33, "training_loss": 122.12273454666138, "training_acc": 51.0, "val_loss": 35.73870658874512, "val_acc": 52.0}
{"epoch": 34, "training_loss": 135.12953853607178, "training_acc": 55.0, "val_loss": 35.70272624492645, "val_acc": 48.0}
{"epoch": 35, "training_loss": 149.53447914123535, "training_acc": 51.0, "val_loss": 45.63702642917633, "val_acc": 52.0}
{"epoch": 36, "training_loss": 165.7413125038147, "training_acc": 49.0, "val_loss": 25.07319748401642, "val_acc": 48.0}
{"epoch": 37, "training_loss": 130.5018014907837, "training_acc": 49.0, "val_loss": 34.264326095581055, "val_acc": 52.0}
{"epoch": 38, "training_loss": 200.02238178253174, "training_acc": 43.0, "val_loss": 36.59219741821289, "val_acc": 48.0}
{"epoch": 39, "training_loss": 216.34071826934814, "training_acc": 43.0, "val_loss": 71.55144214630127, "val_acc": 52.0}
{"epoch": 40, "training_loss": 192.38134288787842, "training_acc": 53.0, "val_loss": 84.48157906532288, "val_acc": 48.0}
