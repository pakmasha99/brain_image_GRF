"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1978.422966003418, "training_acc": 43.0, "val_loss": 363.1159543991089, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1682.769271850586, "training_acc": 47.0, "val_loss": 785.1704120635986, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3005.241569519043, "training_acc": 53.0, "val_loss": 513.3697509765625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1452.886022567749, "training_acc": 53.0, "val_loss": 419.9954032897949, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1838.8557357788086, "training_acc": 47.0, "val_loss": 701.4812469482422, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2488.710189819336, "training_acc": 47.0, "val_loss": 259.9647045135498, "val_acc": 48.0}
{"epoch": 6, "training_loss": 819.8564147949219, "training_acc": 50.0, "val_loss": 350.23577213287354, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1536.002872467041, "training_acc": 53.0, "val_loss": 323.1925964355469, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1091.8462467193604, "training_acc": 53.0, "val_loss": 176.40113830566406, "val_acc": 48.0}
{"epoch": 9, "training_loss": 692.0510520935059, "training_acc": 48.0, "val_loss": 328.98058891296387, "val_acc": 48.0}
{"epoch": 10, "training_loss": 981.0877723693848, "training_acc": 49.0, "val_loss": 55.04230260848999, "val_acc": 52.0}
{"epoch": 11, "training_loss": 427.4411315917969, "training_acc": 58.0, "val_loss": 162.06285953521729, "val_acc": 52.0}
{"epoch": 12, "training_loss": 496.26646614074707, "training_acc": 53.0, "val_loss": 179.9662709236145, "val_acc": 48.0}
{"epoch": 13, "training_loss": 673.572437286377, "training_acc": 48.0, "val_loss": 239.76843357086182, "val_acc": 48.0}
{"epoch": 14, "training_loss": 620.951738357544, "training_acc": 48.0, "val_loss": 110.59244871139526, "val_acc": 52.0}
{"epoch": 15, "training_loss": 503.2025661468506, "training_acc": 53.0, "val_loss": 136.40801906585693, "val_acc": 52.0}
{"epoch": 16, "training_loss": 405.8756628036499, "training_acc": 58.0, "val_loss": 159.36710834503174, "val_acc": 48.0}
{"epoch": 17, "training_loss": 570.122428894043, "training_acc": 47.0, "val_loss": 76.66441202163696, "val_acc": 48.0}
{"epoch": 18, "training_loss": 232.45488834381104, "training_acc": 58.0, "val_loss": 137.28220462799072, "val_acc": 52.0}
{"epoch": 19, "training_loss": 425.46304512023926, "training_acc": 53.0, "val_loss": 77.67253518104553, "val_acc": 48.0}
{"epoch": 20, "training_loss": 285.8186664581299, "training_acc": 47.0, "val_loss": 22.90187180042267, "val_acc": 64.0}
{"epoch": 21, "training_loss": 142.23270511627197, "training_acc": 59.0, "val_loss": 21.39880359172821, "val_acc": 64.0}
{"epoch": 22, "training_loss": 140.2598581314087, "training_acc": 57.0, "val_loss": 19.48813945055008, "val_acc": 60.0}
{"epoch": 23, "training_loss": 92.0399808883667, "training_acc": 63.0, "val_loss": 57.8486442565918, "val_acc": 52.0}
{"epoch": 24, "training_loss": 196.15081691741943, "training_acc": 48.0, "val_loss": 27.472907304763794, "val_acc": 52.0}
{"epoch": 25, "training_loss": 112.11890840530396, "training_acc": 62.0, "val_loss": 41.467368602752686, "val_acc": 52.0}
{"epoch": 26, "training_loss": 234.59235382080078, "training_acc": 46.0, "val_loss": 42.83515810966492, "val_acc": 44.0}
{"epoch": 27, "training_loss": 123.57659196853638, "training_acc": 64.0, "val_loss": 70.7475483417511, "val_acc": 52.0}
{"epoch": 28, "training_loss": 168.93411231040955, "training_acc": 59.0, "val_loss": 72.12197184562683, "val_acc": 48.0}
{"epoch": 29, "training_loss": 199.59326267242432, "training_acc": 50.0, "val_loss": 58.60742926597595, "val_acc": 52.0}
{"epoch": 30, "training_loss": 143.8575301170349, "training_acc": 57.0, "val_loss": 36.33824586868286, "val_acc": 44.0}
{"epoch": 31, "training_loss": 113.13462805747986, "training_acc": 54.0, "val_loss": 22.238078713417053, "val_acc": 64.0}
{"epoch": 32, "training_loss": 70.5433578491211, "training_acc": 64.0, "val_loss": 34.60204303264618, "val_acc": 52.0}
{"epoch": 33, "training_loss": 75.69372510910034, "training_acc": 64.0, "val_loss": 35.910141468048096, "val_acc": 40.0}
{"epoch": 34, "training_loss": 114.75759816169739, "training_acc": 53.0, "val_loss": 26.509293913841248, "val_acc": 52.0}
{"epoch": 35, "training_loss": 97.67568969726562, "training_acc": 60.0, "val_loss": 26.577091217041016, "val_acc": 52.0}
{"epoch": 36, "training_loss": 73.01065421104431, "training_acc": 60.0, "val_loss": 35.899901390075684, "val_acc": 44.0}
{"epoch": 37, "training_loss": 134.15132117271423, "training_acc": 47.0, "val_loss": 22.045254707336426, "val_acc": 64.0}
{"epoch": 38, "training_loss": 83.9663257598877, "training_acc": 55.0, "val_loss": 46.80741727352142, "val_acc": 52.0}
{"epoch": 39, "training_loss": 108.46350359916687, "training_acc": 62.0, "val_loss": 47.00374901294708, "val_acc": 44.0}
{"epoch": 40, "training_loss": 136.8710161447525, "training_acc": 61.0, "val_loss": 52.49755382537842, "val_acc": 52.0}
{"epoch": 41, "training_loss": 100.99740481376648, "training_acc": 62.0, "val_loss": 38.57481777667999, "val_acc": 44.0}
