"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 778.5856590270996, "training_acc": 53.0, "val_loss": 232.57811069488525, "val_acc": 48.0}
{"epoch": 1, "training_loss": 797.3595523834229, "training_acc": 47.0, "val_loss": 308.74996185302734, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1225.4958877563477, "training_acc": 53.0, "val_loss": 158.23732614517212, "val_acc": 52.0}
{"epoch": 3, "training_loss": 804.3019104003906, "training_acc": 45.0, "val_loss": 283.02812576293945, "val_acc": 48.0}
{"epoch": 4, "training_loss": 986.275276184082, "training_acc": 47.0, "val_loss": 146.03551626205444, "val_acc": 52.0}
{"epoch": 5, "training_loss": 582.4566631317139, "training_acc": 53.0, "val_loss": 201.36632919311523, "val_acc": 52.0}
{"epoch": 6, "training_loss": 456.28454780578613, "training_acc": 55.0, "val_loss": 136.9221329689026, "val_acc": 48.0}
{"epoch": 7, "training_loss": 604.0647630691528, "training_acc": 47.0, "val_loss": 37.33234405517578, "val_acc": 52.0}
{"epoch": 8, "training_loss": 303.9419631958008, "training_acc": 51.0, "val_loss": 168.51457357406616, "val_acc": 52.0}
{"epoch": 9, "training_loss": 374.43101596832275, "training_acc": 52.0, "val_loss": 62.99952268600464, "val_acc": 56.0}
{"epoch": 10, "training_loss": 387.4099884033203, "training_acc": 42.0, "val_loss": 57.6465368270874, "val_acc": 48.0}
{"epoch": 11, "training_loss": 169.84749031066895, "training_acc": 61.0, "val_loss": 24.424119293689728, "val_acc": 60.0}
{"epoch": 12, "training_loss": 182.00388622283936, "training_acc": 59.0, "val_loss": 34.55837965011597, "val_acc": 48.0}
{"epoch": 13, "training_loss": 129.93755292892456, "training_acc": 63.0, "val_loss": 17.98643469810486, "val_acc": 76.0}
{"epoch": 14, "training_loss": 191.0554542541504, "training_acc": 48.0, "val_loss": 56.438422203063965, "val_acc": 52.0}
{"epoch": 15, "training_loss": 241.1842803955078, "training_acc": 55.0, "val_loss": 51.592808961868286, "val_acc": 48.0}
{"epoch": 16, "training_loss": 257.7931146621704, "training_acc": 49.0, "val_loss": 37.86475360393524, "val_acc": 52.0}
{"epoch": 17, "training_loss": 195.6504669189453, "training_acc": 59.0, "val_loss": 16.94490760564804, "val_acc": 72.0}
{"epoch": 18, "training_loss": 150.95230960845947, "training_acc": 54.0, "val_loss": 42.27119982242584, "val_acc": 52.0}
{"epoch": 19, "training_loss": 122.47534036636353, "training_acc": 58.0, "val_loss": 39.78893458843231, "val_acc": 48.0}
{"epoch": 20, "training_loss": 157.47973918914795, "training_acc": 51.0, "val_loss": 78.53753566741943, "val_acc": 52.0}
{"epoch": 21, "training_loss": 187.65587258338928, "training_acc": 60.0, "val_loss": 40.28127193450928, "val_acc": 52.0}
{"epoch": 22, "training_loss": 158.71286058425903, "training_acc": 53.0, "val_loss": 73.77066016197205, "val_acc": 52.0}
{"epoch": 23, "training_loss": 128.05402493476868, "training_acc": 63.0, "val_loss": 36.64364218711853, "val_acc": 52.0}
{"epoch": 24, "training_loss": 127.58108139038086, "training_acc": 58.0, "val_loss": 59.42522883415222, "val_acc": 52.0}
{"epoch": 25, "training_loss": 101.5086088180542, "training_acc": 64.0, "val_loss": 25.49211084842682, "val_acc": 40.0}
{"epoch": 26, "training_loss": 100.49033689498901, "training_acc": 62.0, "val_loss": 36.16078197956085, "val_acc": 52.0}
{"epoch": 27, "training_loss": 117.61995792388916, "training_acc": 58.0, "val_loss": 89.66214060783386, "val_acc": 52.0}
{"epoch": 28, "training_loss": 228.6317844390869, "training_acc": 54.0, "val_loss": 101.17168426513672, "val_acc": 48.0}
{"epoch": 29, "training_loss": 379.72453022003174, "training_acc": 47.0, "val_loss": 25.116154551506042, "val_acc": 60.0}
{"epoch": 30, "training_loss": 166.42800521850586, "training_acc": 60.0, "val_loss": 19.64736133813858, "val_acc": 60.0}
{"epoch": 31, "training_loss": 139.03136730194092, "training_acc": 62.0, "val_loss": 32.10061192512512, "val_acc": 48.0}
{"epoch": 32, "training_loss": 204.78790092468262, "training_acc": 53.0, "val_loss": 65.67021608352661, "val_acc": 52.0}
{"epoch": 33, "training_loss": 154.95449686050415, "training_acc": 61.0, "val_loss": 68.20089817047119, "val_acc": 48.0}
{"epoch": 34, "training_loss": 214.77056789398193, "training_acc": 50.0, "val_loss": 60.099244117736816, "val_acc": 52.0}
{"epoch": 35, "training_loss": 122.04399824142456, "training_acc": 59.0, "val_loss": 22.124989330768585, "val_acc": 56.0}
{"epoch": 36, "training_loss": 126.41413450241089, "training_acc": 58.0, "val_loss": 64.32465314865112, "val_acc": 52.0}
