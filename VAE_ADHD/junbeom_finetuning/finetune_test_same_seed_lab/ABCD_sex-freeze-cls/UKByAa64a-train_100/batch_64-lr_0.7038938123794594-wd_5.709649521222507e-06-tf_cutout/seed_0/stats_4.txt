"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1210.0456848144531, "training_acc": 53.0, "val_loss": 109.05730724334717, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1060.7915115356445, "training_acc": 62.0, "val_loss": 1106.6807746887207, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4191.04345703125, "training_acc": 47.0, "val_loss": 485.80613136291504, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1298.9432497024536, "training_acc": 53.0, "val_loss": 376.79736614227295, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1533.787612915039, "training_acc": 53.0, "val_loss": 292.35949516296387, "val_acc": 52.0}
{"epoch": 5, "training_loss": 885.5526113510132, "training_acc": 48.0, "val_loss": 214.21339511871338, "val_acc": 48.0}
{"epoch": 6, "training_loss": 846.8042297363281, "training_acc": 47.0, "val_loss": 41.147369146347046, "val_acc": 48.0}
{"epoch": 7, "training_loss": 475.43761825561523, "training_acc": 49.0, "val_loss": 328.644061088562, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1205.6576118469238, "training_acc": 53.0, "val_loss": 118.39295625686646, "val_acc": 52.0}
{"epoch": 9, "training_loss": 495.826135635376, "training_acc": 55.0, "val_loss": 284.97650623321533, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1034.675199508667, "training_acc": 47.0, "val_loss": 79.11512851715088, "val_acc": 48.0}
{"epoch": 11, "training_loss": 588.1522331237793, "training_acc": 37.0, "val_loss": 280.5635929107666, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1049.2366218566895, "training_acc": 53.0, "val_loss": 113.24845552444458, "val_acc": 52.0}
{"epoch": 13, "training_loss": 561.8422222137451, "training_acc": 41.0, "val_loss": 222.1992015838623, "val_acc": 48.0}
{"epoch": 14, "training_loss": 761.7178611755371, "training_acc": 47.0, "val_loss": 26.487812399864197, "val_acc": 60.0}
{"epoch": 15, "training_loss": 204.5992946624756, "training_acc": 57.0, "val_loss": 133.60050916671753, "val_acc": 52.0}
{"epoch": 16, "training_loss": 373.06573390960693, "training_acc": 55.0, "val_loss": 131.4664125442505, "val_acc": 48.0}
{"epoch": 17, "training_loss": 591.0838737487793, "training_acc": 47.0, "val_loss": 103.9926290512085, "val_acc": 48.0}
{"epoch": 18, "training_loss": 348.10588550567627, "training_acc": 51.0, "val_loss": 156.49057626724243, "val_acc": 52.0}
{"epoch": 19, "training_loss": 517.4142780303955, "training_acc": 53.0, "val_loss": 28.655073046684265, "val_acc": 64.0}
{"epoch": 20, "training_loss": 181.4951515197754, "training_acc": 55.0, "val_loss": 97.5482702255249, "val_acc": 48.0}
{"epoch": 21, "training_loss": 313.13186836242676, "training_acc": 44.0, "val_loss": 64.04337882995605, "val_acc": 52.0}
{"epoch": 22, "training_loss": 174.249596118927, "training_acc": 48.0, "val_loss": 48.96933734416962, "val_acc": 40.0}
{"epoch": 23, "training_loss": 171.0745084285736, "training_acc": 52.0, "val_loss": 27.51348912715912, "val_acc": 52.0}
{"epoch": 24, "training_loss": 91.60367846488953, "training_acc": 63.0, "val_loss": 30.178111791610718, "val_acc": 44.0}
{"epoch": 25, "training_loss": 131.94512176513672, "training_acc": 56.0, "val_loss": 21.037928760051727, "val_acc": 60.0}
{"epoch": 26, "training_loss": 103.77954053878784, "training_acc": 68.0, "val_loss": 20.055018365383148, "val_acc": 52.0}
{"epoch": 27, "training_loss": 89.43911671638489, "training_acc": 68.0, "val_loss": 20.002610981464386, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.86853098869324, "training_acc": 69.0, "val_loss": 18.583689630031586, "val_acc": 60.0}
{"epoch": 29, "training_loss": 65.94207501411438, "training_acc": 65.0, "val_loss": 31.023412942886353, "val_acc": 44.0}
{"epoch": 30, "training_loss": 95.79143023490906, "training_acc": 55.0, "val_loss": 29.754194617271423, "val_acc": 52.0}
{"epoch": 31, "training_loss": 112.61632871627808, "training_acc": 55.0, "val_loss": 17.335383594036102, "val_acc": 60.0}
{"epoch": 32, "training_loss": 63.830018520355225, "training_acc": 74.0, "val_loss": 17.280198633670807, "val_acc": 68.0}
{"epoch": 33, "training_loss": 53.37800443172455, "training_acc": 70.0, "val_loss": 24.494634568691254, "val_acc": 52.0}
{"epoch": 34, "training_loss": 101.46661520004272, "training_acc": 55.0, "val_loss": 29.747316241264343, "val_acc": 52.0}
{"epoch": 35, "training_loss": 79.31014132499695, "training_acc": 61.0, "val_loss": 23.006421327590942, "val_acc": 48.0}
{"epoch": 36, "training_loss": 92.61834955215454, "training_acc": 57.0, "val_loss": 15.96813052892685, "val_acc": 60.0}
{"epoch": 37, "training_loss": 106.76552486419678, "training_acc": 59.0, "val_loss": 61.70411705970764, "val_acc": 52.0}
{"epoch": 38, "training_loss": 169.2251491546631, "training_acc": 53.0, "val_loss": 97.49113321304321, "val_acc": 48.0}
{"epoch": 39, "training_loss": 374.4495735168457, "training_acc": 47.0, "val_loss": 66.70889258384705, "val_acc": 52.0}
{"epoch": 40, "training_loss": 227.71098518371582, "training_acc": 53.0, "val_loss": 25.020334124565125, "val_acc": 48.0}
{"epoch": 41, "training_loss": 83.8511860370636, "training_acc": 59.0, "val_loss": 30.782797932624817, "val_acc": 52.0}
{"epoch": 42, "training_loss": 97.74779629707336, "training_acc": 57.0, "val_loss": 17.111416161060333, "val_acc": 56.0}
{"epoch": 43, "training_loss": 72.22515511512756, "training_acc": 71.0, "val_loss": 29.949000477790833, "val_acc": 48.0}
{"epoch": 44, "training_loss": 95.97823572158813, "training_acc": 55.0, "val_loss": 17.524218559265137, "val_acc": 60.0}
{"epoch": 45, "training_loss": 50.9609317779541, "training_acc": 73.0, "val_loss": 21.76305651664734, "val_acc": 52.0}
{"epoch": 46, "training_loss": 67.07186126708984, "training_acc": 60.0, "val_loss": 32.499706745147705, "val_acc": 52.0}
{"epoch": 47, "training_loss": 120.28367567062378, "training_acc": 52.0, "val_loss": 18.488529324531555, "val_acc": 56.0}
{"epoch": 48, "training_loss": 62.27903389930725, "training_acc": 72.0, "val_loss": 21.665622293949127, "val_acc": 52.0}
{"epoch": 49, "training_loss": 86.95914125442505, "training_acc": 60.0, "val_loss": 48.51951003074646, "val_acc": 48.0}
{"epoch": 50, "training_loss": 132.58016967773438, "training_acc": 48.0, "val_loss": 21.134650707244873, "val_acc": 52.0}
{"epoch": 51, "training_loss": 59.569360971450806, "training_acc": 71.0, "val_loss": 23.00024777650833, "val_acc": 52.0}
{"epoch": 52, "training_loss": 92.48946905136108, "training_acc": 55.0, "val_loss": 36.16377115249634, "val_acc": 52.0}
{"epoch": 53, "training_loss": 98.45013952255249, "training_acc": 61.0, "val_loss": 58.09260606765747, "val_acc": 48.0}
{"epoch": 54, "training_loss": 138.98510766029358, "training_acc": 56.0, "val_loss": 24.229881167411804, "val_acc": 52.0}
{"epoch": 55, "training_loss": 156.91553783416748, "training_acc": 50.0, "val_loss": 18.047477304935455, "val_acc": 56.0}
