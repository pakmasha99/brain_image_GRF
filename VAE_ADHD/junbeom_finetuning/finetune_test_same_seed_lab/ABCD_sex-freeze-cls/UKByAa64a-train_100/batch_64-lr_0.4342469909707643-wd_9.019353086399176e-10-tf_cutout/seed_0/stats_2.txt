"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1240.6608428955078, "training_acc": 43.0, "val_loss": 222.5641965866089, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1084.5642890930176, "training_acc": 45.0, "val_loss": 473.9504814147949, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1811.0190200805664, "training_acc": 53.0, "val_loss": 296.2299108505249, "val_acc": 52.0}
{"epoch": 3, "training_loss": 863.1698045730591, "training_acc": 52.0, "val_loss": 283.08348655700684, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1272.2183418273926, "training_acc": 47.0, "val_loss": 431.37364387512207, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1439.1099891662598, "training_acc": 47.0, "val_loss": 141.71464443206787, "val_acc": 48.0}
{"epoch": 6, "training_loss": 422.25127601623535, "training_acc": 51.0, "val_loss": 226.9261360168457, "val_acc": 52.0}
{"epoch": 7, "training_loss": 951.112907409668, "training_acc": 53.0, "val_loss": 202.52749919891357, "val_acc": 52.0}
{"epoch": 8, "training_loss": 652.6013555526733, "training_acc": 54.0, "val_loss": 118.1937575340271, "val_acc": 48.0}
{"epoch": 9, "training_loss": 495.70044708251953, "training_acc": 51.0, "val_loss": 223.64904880523682, "val_acc": 48.0}
{"epoch": 10, "training_loss": 677.6401424407959, "training_acc": 46.0, "val_loss": 39.439406991004944, "val_acc": 40.0}
{"epoch": 11, "training_loss": 313.68540382385254, "training_acc": 53.0, "val_loss": 156.08941316604614, "val_acc": 52.0}
{"epoch": 12, "training_loss": 594.2794609069824, "training_acc": 53.0, "val_loss": 35.568639636039734, "val_acc": 44.0}
{"epoch": 13, "training_loss": 223.3490800857544, "training_acc": 55.0, "val_loss": 166.4366364479065, "val_acc": 48.0}
{"epoch": 14, "training_loss": 515.7943820953369, "training_acc": 47.0, "val_loss": 37.933334708213806, "val_acc": 44.0}
{"epoch": 15, "training_loss": 288.77344512939453, "training_acc": 49.0, "val_loss": 123.09523820877075, "val_acc": 52.0}
{"epoch": 16, "training_loss": 424.49694538116455, "training_acc": 53.0, "val_loss": 35.98757982254028, "val_acc": 44.0}
{"epoch": 17, "training_loss": 205.13784790039062, "training_acc": 52.0, "val_loss": 71.44351601600647, "val_acc": 48.0}
{"epoch": 18, "training_loss": 178.08542370796204, "training_acc": 57.0, "val_loss": 67.07199215888977, "val_acc": 52.0}
{"epoch": 19, "training_loss": 216.06851243972778, "training_acc": 53.0, "val_loss": 38.40424716472626, "val_acc": 48.0}
{"epoch": 20, "training_loss": 152.00244140625, "training_acc": 48.0, "val_loss": 20.44575810432434, "val_acc": 56.0}
{"epoch": 21, "training_loss": 76.03515696525574, "training_acc": 59.0, "val_loss": 19.022037088871002, "val_acc": 60.0}
{"epoch": 22, "training_loss": 92.76013422012329, "training_acc": 53.0, "val_loss": 22.22762107849121, "val_acc": 52.0}
{"epoch": 23, "training_loss": 83.62678670883179, "training_acc": 58.0, "val_loss": 27.858859300613403, "val_acc": 44.0}
{"epoch": 24, "training_loss": 92.56306719779968, "training_acc": 50.0, "val_loss": 31.402969360351562, "val_acc": 52.0}
{"epoch": 25, "training_loss": 98.85376334190369, "training_acc": 55.0, "val_loss": 37.02913224697113, "val_acc": 48.0}
{"epoch": 26, "training_loss": 138.01299476623535, "training_acc": 50.0, "val_loss": 55.97803592681885, "val_acc": 52.0}
{"epoch": 27, "training_loss": 216.46027755737305, "training_acc": 53.0, "val_loss": 22.44919091463089, "val_acc": 52.0}
{"epoch": 28, "training_loss": 153.64719772338867, "training_acc": 54.0, "val_loss": 60.75105667114258, "val_acc": 48.0}
{"epoch": 29, "training_loss": 151.57708859443665, "training_acc": 58.0, "val_loss": 65.8158540725708, "val_acc": 52.0}
{"epoch": 30, "training_loss": 194.11470317840576, "training_acc": 53.0, "val_loss": 42.0568585395813, "val_acc": 48.0}
{"epoch": 31, "training_loss": 140.2274363040924, "training_acc": 48.0, "val_loss": 39.12967145442963, "val_acc": 52.0}
{"epoch": 32, "training_loss": 121.52382612228394, "training_acc": 53.0, "val_loss": 37.896645069122314, "val_acc": 44.0}
{"epoch": 33, "training_loss": 122.00878477096558, "training_acc": 51.0, "val_loss": 33.221715688705444, "val_acc": 52.0}
{"epoch": 34, "training_loss": 112.2383508682251, "training_acc": 53.0, "val_loss": 25.999757647514343, "val_acc": 48.0}
{"epoch": 35, "training_loss": 93.41024017333984, "training_acc": 50.0, "val_loss": 35.4825884103775, "val_acc": 52.0}
{"epoch": 36, "training_loss": 103.44211149215698, "training_acc": 54.0, "val_loss": 27.696827054023743, "val_acc": 44.0}
{"epoch": 37, "training_loss": 99.86529231071472, "training_acc": 54.0, "val_loss": 44.78619396686554, "val_acc": 52.0}
{"epoch": 38, "training_loss": 121.63185548782349, "training_acc": 53.0, "val_loss": 32.87448287010193, "val_acc": 44.0}
{"epoch": 39, "training_loss": 118.09342956542969, "training_acc": 50.0, "val_loss": 39.61081504821777, "val_acc": 52.0}
{"epoch": 40, "training_loss": 104.16366577148438, "training_acc": 54.0, "val_loss": 33.822935819625854, "val_acc": 44.0}
