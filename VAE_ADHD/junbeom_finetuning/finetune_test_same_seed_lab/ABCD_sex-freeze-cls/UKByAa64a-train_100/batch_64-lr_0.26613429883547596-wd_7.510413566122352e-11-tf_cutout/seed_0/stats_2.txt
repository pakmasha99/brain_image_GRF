"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 455.42879486083984, "training_acc": 53.0, "val_loss": 20.81405520439148, "val_acc": 52.0}
{"epoch": 1, "training_loss": 321.06180000305176, "training_acc": 52.0, "val_loss": 97.32780456542969, "val_acc": 48.0}
{"epoch": 2, "training_loss": 340.52717208862305, "training_acc": 51.0, "val_loss": 132.09986686706543, "val_acc": 52.0}
{"epoch": 3, "training_loss": 465.96486377716064, "training_acc": 53.0, "val_loss": 28.404593467712402, "val_acc": 48.0}
{"epoch": 4, "training_loss": 145.79404163360596, "training_acc": 49.0, "val_loss": 18.485847115516663, "val_acc": 56.0}
{"epoch": 5, "training_loss": 136.71412563323975, "training_acc": 54.0, "val_loss": 35.91262996196747, "val_acc": 52.0}
{"epoch": 6, "training_loss": 150.62205266952515, "training_acc": 44.0, "val_loss": 35.87489128112793, "val_acc": 48.0}
{"epoch": 7, "training_loss": 128.99734234809875, "training_acc": 50.0, "val_loss": 37.0259165763855, "val_acc": 52.0}
{"epoch": 8, "training_loss": 114.64270901679993, "training_acc": 55.0, "val_loss": 35.48809289932251, "val_acc": 48.0}
{"epoch": 9, "training_loss": 131.29369974136353, "training_acc": 47.0, "val_loss": 24.012306332588196, "val_acc": 52.0}
{"epoch": 10, "training_loss": 96.49149656295776, "training_acc": 55.0, "val_loss": 17.80286729335785, "val_acc": 60.0}
{"epoch": 11, "training_loss": 90.98716592788696, "training_acc": 53.0, "val_loss": 16.99680984020233, "val_acc": 68.0}
{"epoch": 12, "training_loss": 82.54145765304565, "training_acc": 53.0, "val_loss": 18.73883605003357, "val_acc": 52.0}
{"epoch": 13, "training_loss": 81.8525619506836, "training_acc": 56.0, "val_loss": 16.76071733236313, "val_acc": 64.0}
{"epoch": 14, "training_loss": 71.51910901069641, "training_acc": 65.0, "val_loss": 20.4312801361084, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.10583233833313, "training_acc": 57.0, "val_loss": 18.986430764198303, "val_acc": 60.0}
{"epoch": 16, "training_loss": 74.92860317230225, "training_acc": 56.0, "val_loss": 19.952525198459625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 77.00520038604736, "training_acc": 54.0, "val_loss": 17.004820704460144, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72.57528638839722, "training_acc": 51.0, "val_loss": 18.564312160015106, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.96715903282166, "training_acc": 54.0, "val_loss": 17.652730643749237, "val_acc": 52.0}
{"epoch": 20, "training_loss": 65.62249827384949, "training_acc": 58.0, "val_loss": 16.72048568725586, "val_acc": 64.0}
{"epoch": 21, "training_loss": 73.21988296508789, "training_acc": 58.0, "val_loss": 29.72659170627594, "val_acc": 52.0}
{"epoch": 22, "training_loss": 94.02064967155457, "training_acc": 54.0, "val_loss": 17.303217947483063, "val_acc": 60.0}
{"epoch": 23, "training_loss": 61.18474054336548, "training_acc": 69.0, "val_loss": 22.380538284778595, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.12540531158447, "training_acc": 58.0, "val_loss": 20.671647787094116, "val_acc": 48.0}
{"epoch": 25, "training_loss": 72.34879422187805, "training_acc": 56.0, "val_loss": 31.20138943195343, "val_acc": 52.0}
{"epoch": 26, "training_loss": 87.44387102127075, "training_acc": 54.0, "val_loss": 31.782904267311096, "val_acc": 48.0}
{"epoch": 27, "training_loss": 101.66233396530151, "training_acc": 48.0, "val_loss": 47.38170504570007, "val_acc": 52.0}
{"epoch": 28, "training_loss": 151.6545753479004, "training_acc": 53.0, "val_loss": 19.21074688434601, "val_acc": 52.0}
{"epoch": 29, "training_loss": 93.42316341400146, "training_acc": 51.0, "val_loss": 21.055346727371216, "val_acc": 52.0}
{"epoch": 30, "training_loss": 73.25329852104187, "training_acc": 53.0, "val_loss": 17.030097544193268, "val_acc": 64.0}
{"epoch": 31, "training_loss": 60.423232316970825, "training_acc": 68.0, "val_loss": 17.01565533876419, "val_acc": 64.0}
{"epoch": 32, "training_loss": 57.224178314208984, "training_acc": 72.0, "val_loss": 17.36941933631897, "val_acc": 60.0}
{"epoch": 33, "training_loss": 60.69149875640869, "training_acc": 69.0, "val_loss": 20.526184141635895, "val_acc": 52.0}
{"epoch": 34, "training_loss": 57.389683961868286, "training_acc": 62.0, "val_loss": 22.19149023294449, "val_acc": 44.0}
{"epoch": 35, "training_loss": 72.14524507522583, "training_acc": 59.0, "val_loss": 25.470739603042603, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.28549313545227, "training_acc": 61.0, "val_loss": 27.947941422462463, "val_acc": 48.0}
{"epoch": 37, "training_loss": 84.35571241378784, "training_acc": 51.0, "val_loss": 26.242035627365112, "val_acc": 52.0}
{"epoch": 38, "training_loss": 84.99864482879639, "training_acc": 57.0, "val_loss": 20.279251039028168, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.16522908210754, "training_acc": 56.0, "val_loss": 18.374907970428467, "val_acc": 56.0}
