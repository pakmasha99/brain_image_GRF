"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 9392781.568450928, "training_acc": 47.0, "val_loss": 1421296.19140625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 8523278.75, "training_acc": 49.0, "val_loss": 5362438.28125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 20574938.0, "training_acc": 53.0, "val_loss": 3535038.28125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 10063038.046875, "training_acc": 53.0, "val_loss": 2136808.0078125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 10353006.9375, "training_acc": 47.0, "val_loss": 3953595.703125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 13424068.3125, "training_acc": 47.0, "val_loss": 1359988.96484375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4930765.140625, "training_acc": 49.0, "val_loss": 2137767.3828125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 9327914.4375, "training_acc": 53.0, "val_loss": 1973777.734375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 6744869.96875, "training_acc": 53.0, "val_loss": 898281.15234375, "val_acc": 44.0}
{"epoch": 9, "training_loss": 4421351.46875, "training_acc": 51.0, "val_loss": 2076522.65625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 7087415.75, "training_acc": 49.0, "val_loss": 352547.6806640625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2859013.609375, "training_acc": 56.0, "val_loss": 1892097.265625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 7946121.34375, "training_acc": 53.0, "val_loss": 1214677.34375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3268682.328125, "training_acc": 53.0, "val_loss": 1285557.51953125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 5651919.4375, "training_acc": 47.0, "val_loss": 1312402.24609375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3218442.662109375, "training_acc": 47.0, "val_loss": 1048344.62890625, "val_acc": 52.0}
{"epoch": 16, "training_loss": 5086385.8125, "training_acc": 53.0, "val_loss": 1454024.21875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 4905625.6015625, "training_acc": 53.0, "val_loss": 639151.123046875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2683490.484375, "training_acc": 48.0, "val_loss": 754729.345703125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2529923.25, "training_acc": 46.0, "val_loss": 507294.287109375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1387450.078125, "training_acc": 54.0, "val_loss": 650468.603515625, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2356405.0390625, "training_acc": 47.0, "val_loss": 95963.25073242188, "val_acc": 68.0}
{"epoch": 22, "training_loss": 898999.94921875, "training_acc": 54.0, "val_loss": 389679.2724609375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1069648.75, "training_acc": 52.0, "val_loss": 262887.255859375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1259908.8828125, "training_acc": 41.0, "val_loss": 194278.466796875, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1192070.7578125, "training_acc": 52.0, "val_loss": 357320.2392578125, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1113212.76953125, "training_acc": 58.0, "val_loss": 372626.8310546875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1041744.775390625, "training_acc": 58.0, "val_loss": 363798.2421875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 701973.3291015625, "training_acc": 63.0, "val_loss": 238253.4423828125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 804284.4375, "training_acc": 54.0, "val_loss": 105945.44677734375, "val_acc": 40.0}
{"epoch": 30, "training_loss": 590820.02734375, "training_acc": 61.0, "val_loss": 56825.140380859375, "val_acc": 60.0}
{"epoch": 31, "training_loss": 337155.125, "training_acc": 57.0, "val_loss": 69855.67016601562, "val_acc": 48.0}
{"epoch": 32, "training_loss": 489244.97265625, "training_acc": 61.0, "val_loss": 54493.255615234375, "val_acc": 64.0}
{"epoch": 33, "training_loss": 250016.3466796875, "training_acc": 61.0, "val_loss": 96734.35668945312, "val_acc": 52.0}
{"epoch": 34, "training_loss": 302033.83203125, "training_acc": 70.0, "val_loss": 385040.8935546875, "val_acc": 48.0}
{"epoch": 35, "training_loss": 966642.869140625, "training_acc": 52.0, "val_loss": 238230.76171875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 878365.80859375, "training_acc": 45.0, "val_loss": 280511.7431640625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 633410.4765625, "training_acc": 56.0, "val_loss": 548269.482421875, "val_acc": 48.0}
{"epoch": 38, "training_loss": 2041472.484375, "training_acc": 47.0, "val_loss": 377596.533203125, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1690464.0859375, "training_acc": 53.0, "val_loss": 42207.733154296875, "val_acc": 60.0}
{"epoch": 40, "training_loss": 1009595.75, "training_acc": 64.0, "val_loss": 369233.251953125, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1441152.3125, "training_acc": 52.0, "val_loss": 721813.037109375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 2131184.95703125, "training_acc": 53.0, "val_loss": 804116.845703125, "val_acc": 48.0}
{"epoch": 43, "training_loss": 3148126.65625, "training_acc": 47.0, "val_loss": 487287.79296875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 2223058.1171875, "training_acc": 45.0, "val_loss": 986258.69140625, "val_acc": 52.0}
{"epoch": 45, "training_loss": 3171443.7890625, "training_acc": 53.0, "val_loss": 293561.71875, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1140421.9453125, "training_acc": 48.0, "val_loss": 142167.88330078125, "val_acc": 52.0}
{"epoch": 47, "training_loss": 523926.3828125, "training_acc": 58.0, "val_loss": 392676.6357421875, "val_acc": 48.0}
{"epoch": 48, "training_loss": 1007883.9077148438, "training_acc": 53.0, "val_loss": 232154.39453125, "val_acc": 52.0}
{"epoch": 49, "training_loss": 673968.84375, "training_acc": 57.0, "val_loss": 119036.60888671875, "val_acc": 44.0}
{"epoch": 50, "training_loss": 446615.8046875, "training_acc": 62.0, "val_loss": 74286.5478515625, "val_acc": 64.0}
{"epoch": 51, "training_loss": 605954.08984375, "training_acc": 62.0, "val_loss": 93521.76513671875, "val_acc": 60.0}
{"epoch": 52, "training_loss": 361621.494140625, "training_acc": 61.0, "val_loss": 315227.24609375, "val_acc": 48.0}
{"epoch": 53, "training_loss": 807748.951171875, "training_acc": 56.0, "val_loss": 498068.212890625, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1567173.12890625, "training_acc": 53.0, "val_loss": 320793.4326171875, "val_acc": 48.0}
{"epoch": 55, "training_loss": 1189532.75390625, "training_acc": 48.0, "val_loss": 428126.953125, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1544036.734375, "training_acc": 54.0, "val_loss": 78311.083984375, "val_acc": 60.0}
{"epoch": 57, "training_loss": 818534.4296875, "training_acc": 62.0, "val_loss": 203138.18359375, "val_acc": 44.0}
{"epoch": 58, "training_loss": 1372847.3359375, "training_acc": 54.0, "val_loss": 785872.4609375, "val_acc": 52.0}
