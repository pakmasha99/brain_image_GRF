"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 8663682.370044708, "training_acc": 46.0, "val_loss": 1810907.421875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 8793573.53125, "training_acc": 53.0, "val_loss": 4689850.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 17650276.8125, "training_acc": 47.0, "val_loss": 1300005.46875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6150278.265625, "training_acc": 51.0, "val_loss": 3425058.59375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 13012762.125, "training_acc": 53.0, "val_loss": 3056266.015625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 9070746.96875, "training_acc": 53.0, "val_loss": 531047.998046875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4894464.8125, "training_acc": 47.0, "val_loss": 1565420.3125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5306131.375, "training_acc": 47.0, "val_loss": 1134276.953125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 4422849.515625, "training_acc": 53.0, "val_loss": 1966783.984375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 6386435.953125, "training_acc": 53.0, "val_loss": 247818.3349609375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2554285.921875, "training_acc": 49.0, "val_loss": 1828745.5078125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 7006816.734375, "training_acc": 47.0, "val_loss": 387937.8662109375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2538718.21875, "training_acc": 49.0, "val_loss": 1924297.0703125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 7398384.84375, "training_acc": 53.0, "val_loss": 1442561.71875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3872577.765625, "training_acc": 52.0, "val_loss": 1414704.4921875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 6892347.65625, "training_acc": 47.0, "val_loss": 2104107.6171875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 7098913.796875, "training_acc": 47.0, "val_loss": 191622.22900390625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1762745.578125, "training_acc": 54.0, "val_loss": 1196501.953125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3841022.5, "training_acc": 53.0, "val_loss": 271159.619140625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1193704.92578125, "training_acc": 50.0, "val_loss": 129545.12939453125, "val_acc": 56.0}
{"epoch": 20, "training_loss": 871302.9765625, "training_acc": 60.0, "val_loss": 200659.80224609375, "val_acc": 60.0}
{"epoch": 21, "training_loss": 749839.140625, "training_acc": 55.0, "val_loss": 215794.3115234375, "val_acc": 44.0}
{"epoch": 22, "training_loss": 1042835.75390625, "training_acc": 55.0, "val_loss": 569012.353515625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1065646.6186523438, "training_acc": 62.0, "val_loss": 559423.6328125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2069744.71875, "training_acc": 48.0, "val_loss": 456330.224609375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1476649.2421875, "training_acc": 55.0, "val_loss": 203594.59228515625, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1513135.4609375, "training_acc": 52.0, "val_loss": 501574.658203125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1771898.078125, "training_acc": 49.0, "val_loss": 471534.130859375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 945382.900390625, "training_acc": 58.0, "val_loss": 306096.8017578125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 972451.748046875, "training_acc": 58.0, "val_loss": 768472.900390625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2632805.4375, "training_acc": 53.0, "val_loss": 357082.4951171875, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1712662.25, "training_acc": 52.0, "val_loss": 777674.4140625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2334297.521484375, "training_acc": 51.0, "val_loss": 874811.71875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 3491849.828125, "training_acc": 53.0, "val_loss": 798646.923828125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1479000.349609375, "training_acc": 66.0, "val_loss": 665915.234375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2445873.015625, "training_acc": 47.0, "val_loss": 420361.474609375, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1454133.640625, "training_acc": 55.0, "val_loss": 235426.26953125, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1060476.4296875, "training_acc": 49.0, "val_loss": 393547.2412109375, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1432446.16015625, "training_acc": 48.0, "val_loss": 455346.09375, "val_acc": 52.0}
