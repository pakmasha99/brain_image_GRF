"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 148895.34465408325, "training_acc": 46.0, "val_loss": 31113.516235351562, "val_acc": 52.0}
{"epoch": 1, "training_loss": 151083.7236328125, "training_acc": 53.0, "val_loss": 80576.72729492188, "val_acc": 48.0}
{"epoch": 2, "training_loss": 303250.9697265625, "training_acc": 47.0, "val_loss": 22335.804748535156, "val_acc": 48.0}
{"epoch": 3, "training_loss": 105668.7119140625, "training_acc": 51.0, "val_loss": 58846.0693359375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 223573.40625, "training_acc": 53.0, "val_loss": 52510.113525390625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 155846.3447265625, "training_acc": 53.0, "val_loss": 9123.651123046875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 84091.021484375, "training_acc": 47.0, "val_loss": 26895.416259765625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 91164.25390625, "training_acc": 47.0, "val_loss": 19488.235473632812, "val_acc": 52.0}
{"epoch": 8, "training_loss": 75990.0830078125, "training_acc": 53.0, "val_loss": 33791.75720214844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 109727.17309570312, "training_acc": 53.0, "val_loss": 4258.16535949707, "val_acc": 52.0}
{"epoch": 10, "training_loss": 43885.587890625, "training_acc": 49.0, "val_loss": 31419.540405273438, "val_acc": 48.0}
{"epoch": 11, "training_loss": 120383.66674804688, "training_acc": 47.0, "val_loss": 6665.0665283203125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 43617.760986328125, "training_acc": 49.0, "val_loss": 33061.63330078125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 127112.80419921875, "training_acc": 53.0, "val_loss": 24785.02655029297, "val_acc": 52.0}
{"epoch": 14, "training_loss": 66536.0634765625, "training_acc": 52.0, "val_loss": 24313.37127685547, "val_acc": 48.0}
{"epoch": 15, "training_loss": 118457.6220703125, "training_acc": 47.0, "val_loss": 36171.57287597656, "val_acc": 48.0}
{"epoch": 16, "training_loss": 122056.94458007812, "training_acc": 47.0, "val_loss": 3267.935562133789, "val_acc": 60.0}
{"epoch": 17, "training_loss": 30930.75048828125, "training_acc": 56.0, "val_loss": 21539.764404296875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70034.49530029297, "training_acc": 53.0, "val_loss": 2882.742691040039, "val_acc": 48.0}
{"epoch": 19, "training_loss": 18877.520263671875, "training_acc": 56.0, "val_loss": 3745.0721740722656, "val_acc": 48.0}
{"epoch": 20, "training_loss": 28209.77978515625, "training_acc": 47.0, "val_loss": 12561.105346679688, "val_acc": 52.0}
{"epoch": 21, "training_loss": 28185.39321899414, "training_acc": 60.0, "val_loss": 12071.171569824219, "val_acc": 48.0}
{"epoch": 22, "training_loss": 54037.048095703125, "training_acc": 47.0, "val_loss": 3376.113510131836, "val_acc": 44.0}
{"epoch": 23, "training_loss": 33252.31884765625, "training_acc": 49.0, "val_loss": 24999.606323242188, "val_acc": 52.0}
{"epoch": 24, "training_loss": 81261.88623046875, "training_acc": 53.0, "val_loss": 8624.523162841797, "val_acc": 52.0}
{"epoch": 25, "training_loss": 38988.650390625, "training_acc": 51.0, "val_loss": 21623.741149902344, "val_acc": 48.0}
{"epoch": 26, "training_loss": 79234.8642578125, "training_acc": 47.0, "val_loss": 2371.399688720703, "val_acc": 52.0}
{"epoch": 27, "training_loss": 31631.8212890625, "training_acc": 51.0, "val_loss": 27192.111206054688, "val_acc": 52.0}
{"epoch": 28, "training_loss": 89151.74536132812, "training_acc": 53.0, "val_loss": 9219.685363769531, "val_acc": 52.0}
{"epoch": 29, "training_loss": 50271.63720703125, "training_acc": 42.0, "val_loss": 24736.378479003906, "val_acc": 48.0}
{"epoch": 30, "training_loss": 95046.63134765625, "training_acc": 47.0, "val_loss": 3074.7926712036133, "val_acc": 36.0}
{"epoch": 31, "training_loss": 28511.067626953125, "training_acc": 60.0, "val_loss": 30449.301147460938, "val_acc": 52.0}
{"epoch": 32, "training_loss": 106696.73095703125, "training_acc": 53.0, "val_loss": 20016.84112548828, "val_acc": 52.0}
{"epoch": 33, "training_loss": 41065.94714355469, "training_acc": 55.0, "val_loss": 15322.116088867188, "val_acc": 48.0}
{"epoch": 34, "training_loss": 69261.70092773438, "training_acc": 47.0, "val_loss": 7426.424407958984, "val_acc": 48.0}
{"epoch": 35, "training_loss": 34487.062255859375, "training_acc": 47.0, "val_loss": 19616.51153564453, "val_acc": 52.0}
{"epoch": 36, "training_loss": 56813.054931640625, "training_acc": 54.0, "val_loss": 5000.067138671875, "val_acc": 56.0}
{"epoch": 37, "training_loss": 20502.586791992188, "training_acc": 54.0, "val_loss": 4659.376907348633, "val_acc": 48.0}
{"epoch": 38, "training_loss": 23518.65313720703, "training_acc": 53.0, "val_loss": 12009.967803955078, "val_acc": 52.0}
{"epoch": 39, "training_loss": 27258.43133544922, "training_acc": 58.0, "val_loss": 3865.3099060058594, "val_acc": 44.0}
{"epoch": 40, "training_loss": 18608.588745117188, "training_acc": 53.0, "val_loss": 6335.476303100586, "val_acc": 56.0}
{"epoch": 41, "training_loss": 17712.82012939453, "training_acc": 56.0, "val_loss": 1883.9265823364258, "val_acc": 56.0}
{"epoch": 42, "training_loss": 14541.807861328125, "training_acc": 58.0, "val_loss": 1791.634750366211, "val_acc": 60.0}
{"epoch": 43, "training_loss": 20274.366577148438, "training_acc": 61.0, "val_loss": 8591.421508789062, "val_acc": 52.0}
{"epoch": 44, "training_loss": 21682.824157714844, "training_acc": 57.0, "val_loss": 6147.468566894531, "val_acc": 48.0}
{"epoch": 45, "training_loss": 15924.393539428711, "training_acc": 62.0, "val_loss": 5972.578048706055, "val_acc": 52.0}
{"epoch": 46, "training_loss": 10830.423843383789, "training_acc": 65.0, "val_loss": 7322.0458984375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 28354.318603515625, "training_acc": 47.0, "val_loss": 9682.171630859375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 32405.575805664062, "training_acc": 53.0, "val_loss": 4582.926559448242, "val_acc": 56.0}
{"epoch": 49, "training_loss": 24541.668823242188, "training_acc": 51.0, "val_loss": 10560.72998046875, "val_acc": 48.0}
{"epoch": 50, "training_loss": 29573.229202270508, "training_acc": 54.0, "val_loss": 16445.608520507812, "val_acc": 52.0}
{"epoch": 51, "training_loss": 63334.464111328125, "training_acc": 53.0, "val_loss": 15403.802490234375, "val_acc": 52.0}
{"epoch": 52, "training_loss": 35468.40188598633, "training_acc": 63.0, "val_loss": 10058.650970458984, "val_acc": 48.0}
{"epoch": 53, "training_loss": 40137.802490234375, "training_acc": 47.0, "val_loss": 6242.922592163086, "val_acc": 52.0}
{"epoch": 54, "training_loss": 24190.525024414062, "training_acc": 54.0, "val_loss": 3028.03955078125, "val_acc": 56.0}
{"epoch": 55, "training_loss": 19775.182373046875, "training_acc": 53.0, "val_loss": 7187.215423583984, "val_acc": 48.0}
{"epoch": 56, "training_loss": 21028.3916015625, "training_acc": 58.0, "val_loss": 8356.858825683594, "val_acc": 52.0}
{"epoch": 57, "training_loss": 18172.926483154297, "training_acc": 56.0, "val_loss": 7636.997222900391, "val_acc": 48.0}
{"epoch": 58, "training_loss": 33531.06872558594, "training_acc": 47.0, "val_loss": 7448.375701904297, "val_acc": 52.0}
{"epoch": 59, "training_loss": 25440.51025390625, "training_acc": 53.0, "val_loss": 2496.8666076660156, "val_acc": 56.0}
{"epoch": 60, "training_loss": 10336.491027832031, "training_acc": 64.0, "val_loss": 4836.857223510742, "val_acc": 48.0}
{"epoch": 61, "training_loss": 22190.085021972656, "training_acc": 52.0, "val_loss": 8375.249481201172, "val_acc": 52.0}
