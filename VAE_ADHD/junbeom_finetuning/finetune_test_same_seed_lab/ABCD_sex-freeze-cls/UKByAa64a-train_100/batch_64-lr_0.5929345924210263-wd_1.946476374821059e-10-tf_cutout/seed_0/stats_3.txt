"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1510.896800994873, "training_acc": 47.0, "val_loss": 291.1201000213623, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1249.5122261047363, "training_acc": 53.0, "val_loss": 725.096321105957, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2714.637077331543, "training_acc": 53.0, "val_loss": 483.54601860046387, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1406.757740020752, "training_acc": 53.0, "val_loss": 321.6886281967163, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1598.115852355957, "training_acc": 47.0, "val_loss": 532.5372695922852, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1875.3619232177734, "training_acc": 47.0, "val_loss": 107.29904174804688, "val_acc": 48.0}
{"epoch": 6, "training_loss": 556.0694885253906, "training_acc": 53.0, "val_loss": 457.3887348175049, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1865.1489486694336, "training_acc": 53.0, "val_loss": 490.54980278015137, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1640.5069770812988, "training_acc": 53.0, "val_loss": 110.13385057449341, "val_acc": 52.0}
{"epoch": 9, "training_loss": 582.3771820068359, "training_acc": 49.0, "val_loss": 371.040415763855, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1568.366844177246, "training_acc": 47.0, "val_loss": 309.5788240432739, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1017.2507076263428, "training_acc": 47.0, "val_loss": 179.27279472351074, "val_acc": 52.0}
{"epoch": 12, "training_loss": 744.0354804992676, "training_acc": 53.0, "val_loss": 364.3380641937256, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1205.0195426940918, "training_acc": 53.0, "val_loss": 180.26092052459717, "val_acc": 52.0}
{"epoch": 14, "training_loss": 338.65136098861694, "training_acc": 61.0, "val_loss": 158.40319395065308, "val_acc": 48.0}
{"epoch": 15, "training_loss": 725.2104053497314, "training_acc": 47.0, "val_loss": 68.60654950141907, "val_acc": 48.0}
{"epoch": 16, "training_loss": 399.6022300720215, "training_acc": 42.0, "val_loss": 217.41676330566406, "val_acc": 52.0}
{"epoch": 17, "training_loss": 635.706521987915, "training_acc": 53.0, "val_loss": 103.01024913787842, "val_acc": 52.0}
{"epoch": 18, "training_loss": 239.31448078155518, "training_acc": 57.0, "val_loss": 129.67394590377808, "val_acc": 48.0}
{"epoch": 19, "training_loss": 517.6160221099854, "training_acc": 47.0, "val_loss": 76.2045681476593, "val_acc": 52.0}
{"epoch": 20, "training_loss": 252.43022537231445, "training_acc": 54.0, "val_loss": 150.07991790771484, "val_acc": 52.0}
{"epoch": 21, "training_loss": 327.63391733169556, "training_acc": 50.0, "val_loss": 64.90234732627869, "val_acc": 48.0}
{"epoch": 22, "training_loss": 292.8182554244995, "training_acc": 48.0, "val_loss": 49.07897114753723, "val_acc": 52.0}
{"epoch": 23, "training_loss": 168.4018383026123, "training_acc": 57.0, "val_loss": 60.732561349868774, "val_acc": 52.0}
{"epoch": 24, "training_loss": 186.81891250610352, "training_acc": 54.0, "val_loss": 47.833251953125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 192.24887323379517, "training_acc": 49.0, "val_loss": 58.66432785987854, "val_acc": 52.0}
{"epoch": 26, "training_loss": 151.90306949615479, "training_acc": 53.0, "val_loss": 35.71375608444214, "val_acc": 52.0}
{"epoch": 27, "training_loss": 109.11450171470642, "training_acc": 59.0, "val_loss": 71.59931659698486, "val_acc": 52.0}
{"epoch": 28, "training_loss": 172.9731206893921, "training_acc": 56.0, "val_loss": 38.739222288131714, "val_acc": 52.0}
{"epoch": 29, "training_loss": 136.44413018226624, "training_acc": 50.0, "val_loss": 59.04954671859741, "val_acc": 52.0}
{"epoch": 30, "training_loss": 180.15742206573486, "training_acc": 52.0, "val_loss": 52.119892835617065, "val_acc": 48.0}
{"epoch": 31, "training_loss": 206.6292266845703, "training_acc": 48.0, "val_loss": 35.50449311733246, "val_acc": 52.0}
{"epoch": 32, "training_loss": 113.85479831695557, "training_acc": 54.0, "val_loss": 19.951219856739044, "val_acc": 52.0}
{"epoch": 33, "training_loss": 120.54246807098389, "training_acc": 60.0, "val_loss": 30.74154555797577, "val_acc": 52.0}
{"epoch": 34, "training_loss": 85.15778636932373, "training_acc": 64.0, "val_loss": 20.41885554790497, "val_acc": 48.0}
{"epoch": 35, "training_loss": 90.05571031570435, "training_acc": 61.0, "val_loss": 55.442190170288086, "val_acc": 52.0}
{"epoch": 36, "training_loss": 114.12794971466064, "training_acc": 57.0, "val_loss": 39.786094427108765, "val_acc": 48.0}
{"epoch": 37, "training_loss": 155.17262196540833, "training_acc": 51.0, "val_loss": 53.10046672821045, "val_acc": 52.0}
{"epoch": 38, "training_loss": 96.52169346809387, "training_acc": 58.0, "val_loss": 19.79428380727768, "val_acc": 44.0}
{"epoch": 39, "training_loss": 93.78215479850769, "training_acc": 57.0, "val_loss": 31.91642165184021, "val_acc": 52.0}
{"epoch": 40, "training_loss": 62.22504019737244, "training_acc": 70.0, "val_loss": 20.74144184589386, "val_acc": 52.0}
{"epoch": 41, "training_loss": 61.50971984863281, "training_acc": 67.0, "val_loss": 22.063501179218292, "val_acc": 56.0}
{"epoch": 42, "training_loss": 65.79017901420593, "training_acc": 68.0, "val_loss": 41.460031270980835, "val_acc": 52.0}
{"epoch": 43, "training_loss": 88.06392431259155, "training_acc": 61.0, "val_loss": 19.461864233016968, "val_acc": 64.0}
{"epoch": 44, "training_loss": 73.05358052253723, "training_acc": 64.0, "val_loss": 19.24683004617691, "val_acc": 48.0}
{"epoch": 45, "training_loss": 58.464770793914795, "training_acc": 72.0, "val_loss": 22.728022933006287, "val_acc": 52.0}
{"epoch": 46, "training_loss": 65.06574296951294, "training_acc": 72.0, "val_loss": 23.78763109445572, "val_acc": 52.0}
{"epoch": 47, "training_loss": 75.65973711013794, "training_acc": 61.0, "val_loss": 44.08499002456665, "val_acc": 52.0}
{"epoch": 48, "training_loss": 86.65374565124512, "training_acc": 63.0, "val_loss": 17.87329763174057, "val_acc": 52.0}
{"epoch": 49, "training_loss": 57.642082929611206, "training_acc": 74.0, "val_loss": 19.404204189777374, "val_acc": 52.0}
{"epoch": 50, "training_loss": 60.01879334449768, "training_acc": 68.0, "val_loss": 55.70986270904541, "val_acc": 52.0}
{"epoch": 51, "training_loss": 101.65501618385315, "training_acc": 57.0, "val_loss": 50.503307580947876, "val_acc": 48.0}
{"epoch": 52, "training_loss": 155.0239441394806, "training_acc": 54.0, "val_loss": 108.2276463508606, "val_acc": 52.0}
{"epoch": 53, "training_loss": 331.85435962677, "training_acc": 53.0, "val_loss": 18.565432727336884, "val_acc": 64.0}
{"epoch": 54, "training_loss": 93.30715131759644, "training_acc": 58.0, "val_loss": 24.490217864513397, "val_acc": 52.0}
{"epoch": 55, "training_loss": 72.80407857894897, "training_acc": 65.0, "val_loss": 18.516050279140472, "val_acc": 64.0}
{"epoch": 56, "training_loss": 73.80273866653442, "training_acc": 61.0, "val_loss": 69.75895762443542, "val_acc": 52.0}
{"epoch": 57, "training_loss": 161.9230408668518, "training_acc": 53.0, "val_loss": 90.99061489105225, "val_acc": 48.0}
{"epoch": 58, "training_loss": 374.3738679885864, "training_acc": 47.0, "val_loss": 19.89927887916565, "val_acc": 52.0}
{"epoch": 59, "training_loss": 131.82916450500488, "training_acc": 65.0, "val_loss": 74.94905591011047, "val_acc": 52.0}
{"epoch": 60, "training_loss": 214.7760190963745, "training_acc": 51.0, "val_loss": 46.94242775440216, "val_acc": 48.0}
{"epoch": 61, "training_loss": 148.82174110412598, "training_acc": 57.0, "val_loss": 86.88532710075378, "val_acc": 52.0}
{"epoch": 62, "training_loss": 139.5531587600708, "training_acc": 61.0, "val_loss": 90.91036915779114, "val_acc": 48.0}
{"epoch": 63, "training_loss": 373.53920459747314, "training_acc": 47.0, "val_loss": 66.55270457267761, "val_acc": 52.0}
{"epoch": 64, "training_loss": 224.76470375061035, "training_acc": 56.0, "val_loss": 47.495490312576294, "val_acc": 52.0}
{"epoch": 65, "training_loss": 177.96058177947998, "training_acc": 59.0, "val_loss": 67.0949399471283, "val_acc": 48.0}
{"epoch": 66, "training_loss": 260.58754205703735, "training_acc": 51.0, "val_loss": 108.41590166091919, "val_acc": 52.0}
{"epoch": 67, "training_loss": 212.66623711585999, "training_acc": 54.0, "val_loss": 64.15877938270569, "val_acc": 48.0}
