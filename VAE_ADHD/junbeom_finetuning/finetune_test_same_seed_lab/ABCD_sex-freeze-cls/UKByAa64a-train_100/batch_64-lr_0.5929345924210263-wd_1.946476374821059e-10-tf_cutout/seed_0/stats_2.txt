"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1313.774772644043, "training_acc": 46.0, "val_loss": 283.4573030471802, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1233.483055114746, "training_acc": 55.0, "val_loss": 644.0360069274902, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2391.8471908569336, "training_acc": 47.0, "val_loss": 149.7887134552002, "val_acc": 48.0}
{"epoch": 3, "training_loss": 654.6420745849609, "training_acc": 57.0, "val_loss": 515.1710033416748, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2057.7020721435547, "training_acc": 53.0, "val_loss": 455.7584762573242, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1390.5483016967773, "training_acc": 53.0, "val_loss": 95.40740847587585, "val_acc": 48.0}
{"epoch": 6, "training_loss": 597.4958076477051, "training_acc": 47.0, "val_loss": 251.49612426757812, "val_acc": 48.0}
{"epoch": 7, "training_loss": 815.97047996521, "training_acc": 47.0, "val_loss": 117.77182817459106, "val_acc": 52.0}
{"epoch": 8, "training_loss": 558.5620422363281, "training_acc": 53.0, "val_loss": 203.10425758361816, "val_acc": 52.0}
{"epoch": 9, "training_loss": 631.4274139404297, "training_acc": 54.0, "val_loss": 90.37716388702393, "val_acc": 48.0}
{"epoch": 10, "training_loss": 473.5657444000244, "training_acc": 47.0, "val_loss": 51.03145241737366, "val_acc": 48.0}
{"epoch": 11, "training_loss": 375.8084945678711, "training_acc": 40.0, "val_loss": 180.15213012695312, "val_acc": 52.0}
{"epoch": 12, "training_loss": 601.4924001693726, "training_acc": 53.0, "val_loss": 21.441970765590668, "val_acc": 56.0}
{"epoch": 13, "training_loss": 225.46986389160156, "training_acc": 51.0, "val_loss": 100.07280111312866, "val_acc": 48.0}
{"epoch": 14, "training_loss": 308.1829903125763, "training_acc": 52.0, "val_loss": 98.69617819786072, "val_acc": 52.0}
{"epoch": 15, "training_loss": 337.71826457977295, "training_acc": 54.0, "val_loss": 24.048472940921783, "val_acc": 52.0}
{"epoch": 16, "training_loss": 155.29050540924072, "training_acc": 54.0, "val_loss": 26.329252123832703, "val_acc": 44.0}
{"epoch": 17, "training_loss": 152.44209098815918, "training_acc": 58.0, "val_loss": 71.92002534866333, "val_acc": 52.0}
{"epoch": 18, "training_loss": 209.91927242279053, "training_acc": 50.0, "val_loss": 44.61396634578705, "val_acc": 48.0}
{"epoch": 19, "training_loss": 105.83095192909241, "training_acc": 64.0, "val_loss": 59.45197343826294, "val_acc": 52.0}
{"epoch": 20, "training_loss": 170.45801973342896, "training_acc": 52.0, "val_loss": 47.851917147636414, "val_acc": 44.0}
{"epoch": 21, "training_loss": 142.90877509117126, "training_acc": 42.0, "val_loss": 28.3803790807724, "val_acc": 52.0}
{"epoch": 22, "training_loss": 84.92568325996399, "training_acc": 58.0, "val_loss": 19.2913219332695, "val_acc": 48.0}
{"epoch": 23, "training_loss": 70.48526787757874, "training_acc": 62.0, "val_loss": 18.064071238040924, "val_acc": 48.0}
{"epoch": 24, "training_loss": 66.3545081615448, "training_acc": 59.0, "val_loss": 18.37972402572632, "val_acc": 60.0}
{"epoch": 25, "training_loss": 59.79010009765625, "training_acc": 70.0, "val_loss": 34.31629836559296, "val_acc": 52.0}
{"epoch": 26, "training_loss": 94.89929389953613, "training_acc": 53.0, "val_loss": 19.90932822227478, "val_acc": 56.0}
{"epoch": 27, "training_loss": 62.47074604034424, "training_acc": 61.0, "val_loss": 40.48061966896057, "val_acc": 52.0}
{"epoch": 28, "training_loss": 154.56237125396729, "training_acc": 37.0, "val_loss": 43.30005943775177, "val_acc": 52.0}
{"epoch": 29, "training_loss": 108.98660778999329, "training_acc": 54.0, "val_loss": 37.64973282814026, "val_acc": 48.0}
{"epoch": 30, "training_loss": 117.75064539909363, "training_acc": 52.0, "val_loss": 24.96308833360672, "val_acc": 52.0}
{"epoch": 31, "training_loss": 122.80982112884521, "training_acc": 54.0, "val_loss": 32.12851583957672, "val_acc": 52.0}
{"epoch": 32, "training_loss": 78.11919736862183, "training_acc": 58.0, "val_loss": 39.16750252246857, "val_acc": 48.0}
{"epoch": 33, "training_loss": 120.42604565620422, "training_acc": 54.0, "val_loss": 70.90794444084167, "val_acc": 52.0}
{"epoch": 34, "training_loss": 188.36578679084778, "training_acc": 55.0, "val_loss": 62.34947443008423, "val_acc": 48.0}
{"epoch": 35, "training_loss": 198.60433912277222, "training_acc": 49.0, "val_loss": 86.01502776145935, "val_acc": 52.0}
{"epoch": 36, "training_loss": 284.10191345214844, "training_acc": 53.0, "val_loss": 19.41053420305252, "val_acc": 60.0}
{"epoch": 37, "training_loss": 120.59584140777588, "training_acc": 64.0, "val_loss": 36.20935082435608, "val_acc": 48.0}
{"epoch": 38, "training_loss": 197.82717418670654, "training_acc": 51.0, "val_loss": 110.5888843536377, "val_acc": 52.0}
{"epoch": 39, "training_loss": 281.8718206882477, "training_acc": 54.0, "val_loss": 114.11845684051514, "val_acc": 48.0}
{"epoch": 40, "training_loss": 461.0359134674072, "training_acc": 47.0, "val_loss": 18.401840329170227, "val_acc": 48.0}
{"epoch": 41, "training_loss": 165.26284885406494, "training_acc": 63.0, "val_loss": 155.6801438331604, "val_acc": 52.0}
{"epoch": 42, "training_loss": 445.5300998687744, "training_acc": 53.0, "val_loss": 83.45832824707031, "val_acc": 48.0}
