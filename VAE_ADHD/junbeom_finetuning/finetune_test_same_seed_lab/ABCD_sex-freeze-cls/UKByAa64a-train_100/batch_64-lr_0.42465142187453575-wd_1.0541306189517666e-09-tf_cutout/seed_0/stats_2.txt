"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 966.5222702026367, "training_acc": 47.0, "val_loss": 221.2019681930542, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1061.944538116455, "training_acc": 47.0, "val_loss": 400.44169425964355, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1420.3842124938965, "training_acc": 47.0, "val_loss": 39.33227360248566, "val_acc": 48.0}
{"epoch": 3, "training_loss": 389.9143714904785, "training_acc": 52.0, "val_loss": 404.73947525024414, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1621.8723449707031, "training_acc": 53.0, "val_loss": 353.14958095550537, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1142.5328693389893, "training_acc": 53.0, "val_loss": 37.17895448207855, "val_acc": 48.0}
{"epoch": 6, "training_loss": 362.79687309265137, "training_acc": 47.0, "val_loss": 156.42980337142944, "val_acc": 48.0}
{"epoch": 7, "training_loss": 506.01215267181396, "training_acc": 47.0, "val_loss": 103.75816822052002, "val_acc": 52.0}
{"epoch": 8, "training_loss": 452.4686050415039, "training_acc": 53.0, "val_loss": 158.4294080734253, "val_acc": 52.0}
{"epoch": 9, "training_loss": 482.68221855163574, "training_acc": 53.0, "val_loss": 55.13898730278015, "val_acc": 48.0}
{"epoch": 10, "training_loss": 320.55237770080566, "training_acc": 47.0, "val_loss": 69.33512091636658, "val_acc": 48.0}
{"epoch": 11, "training_loss": 228.06755304336548, "training_acc": 51.0, "val_loss": 75.37501454353333, "val_acc": 52.0}
{"epoch": 12, "training_loss": 230.61596536636353, "training_acc": 53.0, "val_loss": 44.547972083091736, "val_acc": 48.0}
{"epoch": 13, "training_loss": 191.71419429779053, "training_acc": 47.0, "val_loss": 17.324675619602203, "val_acc": 56.0}
{"epoch": 14, "training_loss": 105.6957459449768, "training_acc": 63.0, "val_loss": 26.472628116607666, "val_acc": 52.0}
{"epoch": 15, "training_loss": 134.52054119110107, "training_acc": 49.0, "val_loss": 36.40218377113342, "val_acc": 48.0}
{"epoch": 16, "training_loss": 148.32692861557007, "training_acc": 46.0, "val_loss": 42.682063579559326, "val_acc": 52.0}
{"epoch": 17, "training_loss": 116.31776809692383, "training_acc": 55.0, "val_loss": 40.97946882247925, "val_acc": 48.0}
{"epoch": 18, "training_loss": 118.23373889923096, "training_acc": 54.0, "val_loss": 49.10060465335846, "val_acc": 52.0}
{"epoch": 19, "training_loss": 151.30627298355103, "training_acc": 53.0, "val_loss": 39.53205049037933, "val_acc": 48.0}
{"epoch": 20, "training_loss": 158.1888132095337, "training_acc": 51.0, "val_loss": 27.961695194244385, "val_acc": 52.0}
{"epoch": 21, "training_loss": 125.41851282119751, "training_acc": 53.0, "val_loss": 17.855170369148254, "val_acc": 48.0}
{"epoch": 22, "training_loss": 94.34227657318115, "training_acc": 60.0, "val_loss": 18.251454830169678, "val_acc": 64.0}
{"epoch": 23, "training_loss": 81.89007520675659, "training_acc": 64.0, "val_loss": 18.541593849658966, "val_acc": 64.0}
{"epoch": 24, "training_loss": 73.6951265335083, "training_acc": 60.0, "val_loss": 17.18633621931076, "val_acc": 60.0}
{"epoch": 25, "training_loss": 78.24749231338501, "training_acc": 65.0, "val_loss": 21.126556396484375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 79.38025951385498, "training_acc": 60.0, "val_loss": 17.122966051101685, "val_acc": 60.0}
{"epoch": 27, "training_loss": 99.10225248336792, "training_acc": 56.0, "val_loss": 17.28423982858658, "val_acc": 64.0}
{"epoch": 28, "training_loss": 71.97924017906189, "training_acc": 67.0, "val_loss": 20.488326251506805, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.71349358558655, "training_acc": 62.0, "val_loss": 19.921256601810455, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.99023914337158, "training_acc": 55.0, "val_loss": 31.808385252952576, "val_acc": 52.0}
{"epoch": 31, "training_loss": 80.74928665161133, "training_acc": 55.0, "val_loss": 41.14142656326294, "val_acc": 48.0}
{"epoch": 32, "training_loss": 121.05746483802795, "training_acc": 57.0, "val_loss": 36.387526988983154, "val_acc": 52.0}
{"epoch": 33, "training_loss": 103.37246990203857, "training_acc": 53.0, "val_loss": 21.813857555389404, "val_acc": 56.0}
{"epoch": 34, "training_loss": 66.69792199134827, "training_acc": 58.0, "val_loss": 27.120906114578247, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.98940658569336, "training_acc": 68.0, "val_loss": 31.983065605163574, "val_acc": 44.0}
{"epoch": 36, "training_loss": 90.14398241043091, "training_acc": 54.0, "val_loss": 27.570950984954834, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.56951546669006, "training_acc": 63.0, "val_loss": 19.543465971946716, "val_acc": 56.0}
{"epoch": 38, "training_loss": 53.27312088012695, "training_acc": 70.0, "val_loss": 48.41963052749634, "val_acc": 52.0}
{"epoch": 39, "training_loss": 121.21686148643494, "training_acc": 51.0, "val_loss": 42.41926372051239, "val_acc": 48.0}
{"epoch": 40, "training_loss": 129.46749424934387, "training_acc": 50.0, "val_loss": 69.77367401123047, "val_acc": 52.0}
{"epoch": 41, "training_loss": 216.82644605636597, "training_acc": 53.0, "val_loss": 19.336792826652527, "val_acc": 56.0}
{"epoch": 42, "training_loss": 110.30154705047607, "training_acc": 59.0, "val_loss": 19.94139850139618, "val_acc": 56.0}
{"epoch": 43, "training_loss": 102.09908390045166, "training_acc": 65.0, "val_loss": 24.661284685134888, "val_acc": 52.0}
{"epoch": 44, "training_loss": 108.1812744140625, "training_acc": 58.0, "val_loss": 34.46858823299408, "val_acc": 48.0}
{"epoch": 45, "training_loss": 135.0119128227234, "training_acc": 52.0, "val_loss": 61.60801649093628, "val_acc": 52.0}
