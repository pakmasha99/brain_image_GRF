"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 772.7268447875977, "training_acc": 54.0, "val_loss": 145.66445350646973, "val_acc": 52.0}
{"epoch": 1, "training_loss": 993.4330825805664, "training_acc": 49.0, "val_loss": 504.19015884399414, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1825.9968185424805, "training_acc": 47.0, "val_loss": 121.24085426330566, "val_acc": 48.0}
{"epoch": 3, "training_loss": 490.16149711608887, "training_acc": 57.0, "val_loss": 386.35809421539307, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1569.7557754516602, "training_acc": 53.0, "val_loss": 373.564076423645, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1222.4969291687012, "training_acc": 53.0, "val_loss": 25.86650848388672, "val_acc": 52.0}
{"epoch": 6, "training_loss": 330.6010551452637, "training_acc": 59.0, "val_loss": 375.54540634155273, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1534.993179321289, "training_acc": 47.0, "val_loss": 326.42223834991455, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1063.5647830963135, "training_acc": 47.0, "val_loss": 53.12175750732422, "val_acc": 52.0}
{"epoch": 9, "training_loss": 410.12440490722656, "training_acc": 53.0, "val_loss": 209.72235202789307, "val_acc": 52.0}
{"epoch": 10, "training_loss": 741.475305557251, "training_acc": 53.0, "val_loss": 61.75341010093689, "val_acc": 52.0}
{"epoch": 11, "training_loss": 351.75245666503906, "training_acc": 45.0, "val_loss": 171.66286706924438, "val_acc": 48.0}
{"epoch": 12, "training_loss": 650.0107269287109, "training_acc": 47.0, "val_loss": 46.41915261745453, "val_acc": 48.0}
{"epoch": 13, "training_loss": 248.5048713684082, "training_acc": 49.0, "val_loss": 178.1852126121521, "val_acc": 52.0}
{"epoch": 14, "training_loss": 673.873291015625, "training_acc": 53.0, "val_loss": 112.83997297286987, "val_acc": 52.0}
{"epoch": 15, "training_loss": 288.8068935871124, "training_acc": 58.0, "val_loss": 110.12458801269531, "val_acc": 48.0}
{"epoch": 16, "training_loss": 450.81946182250977, "training_acc": 47.0, "val_loss": 72.65915274620056, "val_acc": 48.0}
{"epoch": 17, "training_loss": 210.82162618637085, "training_acc": 55.0, "val_loss": 89.91005420684814, "val_acc": 52.0}
{"epoch": 18, "training_loss": 322.9105100631714, "training_acc": 53.0, "val_loss": 18.765750527381897, "val_acc": 60.0}
{"epoch": 19, "training_loss": 111.15393733978271, "training_acc": 53.0, "val_loss": 55.44903874397278, "val_acc": 48.0}
{"epoch": 20, "training_loss": 201.53157997131348, "training_acc": 40.0, "val_loss": 38.46389949321747, "val_acc": 52.0}
{"epoch": 21, "training_loss": 143.24977827072144, "training_acc": 52.0, "val_loss": 21.30197435617447, "val_acc": 48.0}
{"epoch": 22, "training_loss": 91.82330822944641, "training_acc": 55.0, "val_loss": 27.97175943851471, "val_acc": 52.0}
{"epoch": 23, "training_loss": 88.33874678611755, "training_acc": 56.0, "val_loss": 42.18253195285797, "val_acc": 48.0}
{"epoch": 24, "training_loss": 130.13127851486206, "training_acc": 50.0, "val_loss": 43.08150112628937, "val_acc": 52.0}
{"epoch": 25, "training_loss": 138.0786108970642, "training_acc": 53.0, "val_loss": 21.98912799358368, "val_acc": 48.0}
{"epoch": 26, "training_loss": 114.01388788223267, "training_acc": 50.0, "val_loss": 22.982273995876312, "val_acc": 52.0}
{"epoch": 27, "training_loss": 110.60591793060303, "training_acc": 56.0, "val_loss": 17.462116479873657, "val_acc": 52.0}
{"epoch": 28, "training_loss": 93.95023775100708, "training_acc": 55.0, "val_loss": 16.95341020822525, "val_acc": 60.0}
{"epoch": 29, "training_loss": 104.5603494644165, "training_acc": 56.0, "val_loss": 17.88390278816223, "val_acc": 56.0}
{"epoch": 30, "training_loss": 101.58084869384766, "training_acc": 56.0, "val_loss": 20.67418098449707, "val_acc": 48.0}
{"epoch": 31, "training_loss": 128.47311115264893, "training_acc": 54.0, "val_loss": 42.347320914268494, "val_acc": 52.0}
{"epoch": 32, "training_loss": 116.66498446464539, "training_acc": 59.0, "val_loss": 42.63240396976471, "val_acc": 48.0}
{"epoch": 33, "training_loss": 116.95726895332336, "training_acc": 55.0, "val_loss": 37.66561150550842, "val_acc": 52.0}
{"epoch": 34, "training_loss": 106.80915951728821, "training_acc": 57.0, "val_loss": 26.657533645629883, "val_acc": 48.0}
{"epoch": 35, "training_loss": 71.89536738395691, "training_acc": 62.0, "val_loss": 31.56316578388214, "val_acc": 52.0}
{"epoch": 36, "training_loss": 81.80121183395386, "training_acc": 56.0, "val_loss": 36.57703995704651, "val_acc": 48.0}
{"epoch": 37, "training_loss": 108.23616313934326, "training_acc": 56.0, "val_loss": 43.04768145084381, "val_acc": 52.0}
{"epoch": 38, "training_loss": 124.12553477287292, "training_acc": 53.0, "val_loss": 40.52678644657135, "val_acc": 48.0}
{"epoch": 39, "training_loss": 126.34700059890747, "training_acc": 46.0, "val_loss": 47.34090268611908, "val_acc": 52.0}
{"epoch": 40, "training_loss": 168.30238437652588, "training_acc": 53.0, "val_loss": 26.94118320941925, "val_acc": 48.0}
{"epoch": 41, "training_loss": 117.57504987716675, "training_acc": 49.0, "val_loss": 30.481189489364624, "val_acc": 52.0}
{"epoch": 42, "training_loss": 110.4213547706604, "training_acc": 54.0, "val_loss": 21.0382878780365, "val_acc": 56.0}
{"epoch": 43, "training_loss": 72.4001235961914, "training_acc": 55.0, "val_loss": 21.880511939525604, "val_acc": 52.0}
{"epoch": 44, "training_loss": 76.37353897094727, "training_acc": 61.0, "val_loss": 18.75672936439514, "val_acc": 56.0}
{"epoch": 45, "training_loss": 59.50979661941528, "training_acc": 69.0, "val_loss": 17.529897391796112, "val_acc": 56.0}
{"epoch": 46, "training_loss": 53.741612672805786, "training_acc": 75.0, "val_loss": 17.172256112098694, "val_acc": 68.0}
{"epoch": 47, "training_loss": 60.32706046104431, "training_acc": 73.0, "val_loss": 18.824829161167145, "val_acc": 52.0}
