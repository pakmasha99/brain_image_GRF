"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 290.63033294677734, "training_acc": 52.0, "val_loss": 55.25662302970886, "val_acc": 52.0}
{"epoch": 1, "training_loss": 274.4496908187866, "training_acc": 49.0, "val_loss": 120.4798698425293, "val_acc": 48.0}
{"epoch": 2, "training_loss": 445.64926624298096, "training_acc": 47.0, "val_loss": 25.41210949420929, "val_acc": 48.0}
{"epoch": 3, "training_loss": 163.64593505859375, "training_acc": 45.0, "val_loss": 96.48652672767639, "val_acc": 52.0}
{"epoch": 4, "training_loss": 352.144606590271, "training_acc": 53.0, "val_loss": 69.61598992347717, "val_acc": 52.0}
{"epoch": 5, "training_loss": 194.8883888721466, "training_acc": 53.0, "val_loss": 37.40265965461731, "val_acc": 48.0}
{"epoch": 6, "training_loss": 199.70278644561768, "training_acc": 47.0, "val_loss": 53.98254990577698, "val_acc": 48.0}
{"epoch": 7, "training_loss": 186.8809266090393, "training_acc": 47.0, "val_loss": 29.29028570652008, "val_acc": 52.0}
{"epoch": 8, "training_loss": 124.25032901763916, "training_acc": 53.0, "val_loss": 57.5480580329895, "val_acc": 52.0}
{"epoch": 9, "training_loss": 171.07862949371338, "training_acc": 53.0, "val_loss": 19.857817888259888, "val_acc": 52.0}
{"epoch": 10, "training_loss": 102.6023473739624, "training_acc": 49.0, "val_loss": 35.775595903396606, "val_acc": 48.0}
{"epoch": 11, "training_loss": 135.73009157180786, "training_acc": 47.0, "val_loss": 21.816809475421906, "val_acc": 52.0}
{"epoch": 12, "training_loss": 83.24195575714111, "training_acc": 55.0, "val_loss": 42.13905334472656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 120.02869009971619, "training_acc": 54.0, "val_loss": 19.718028604984283, "val_acc": 52.0}
{"epoch": 14, "training_loss": 82.57964944839478, "training_acc": 54.0, "val_loss": 22.441022098064423, "val_acc": 52.0}
{"epoch": 15, "training_loss": 85.1075496673584, "training_acc": 47.0, "val_loss": 25.572645664215088, "val_acc": 52.0}
{"epoch": 16, "training_loss": 84.69451808929443, "training_acc": 55.0, "val_loss": 28.955405950546265, "val_acc": 52.0}
{"epoch": 17, "training_loss": 77.58901619911194, "training_acc": 57.0, "val_loss": 21.54960036277771, "val_acc": 44.0}
{"epoch": 18, "training_loss": 102.89732122421265, "training_acc": 46.0, "val_loss": 19.078803062438965, "val_acc": 44.0}
{"epoch": 19, "training_loss": 72.09539794921875, "training_acc": 53.0, "val_loss": 28.842538595199585, "val_acc": 52.0}
{"epoch": 20, "training_loss": 101.49789905548096, "training_acc": 53.0, "val_loss": 17.48436540365219, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.52124118804932, "training_acc": 57.0, "val_loss": 26.366904377937317, "val_acc": 48.0}
{"epoch": 22, "training_loss": 100.184983253479, "training_acc": 46.0, "val_loss": 19.912591576576233, "val_acc": 52.0}
{"epoch": 23, "training_loss": 83.3593602180481, "training_acc": 53.0, "val_loss": 24.566929042339325, "val_acc": 52.0}
{"epoch": 24, "training_loss": 86.33627486228943, "training_acc": 53.0, "val_loss": 20.011574029922485, "val_acc": 52.0}
{"epoch": 25, "training_loss": 80.8458821773529, "training_acc": 47.0, "val_loss": 17.64875054359436, "val_acc": 52.0}
{"epoch": 26, "training_loss": 61.56186079978943, "training_acc": 72.0, "val_loss": 21.12869620323181, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.85945320129395, "training_acc": 55.0, "val_loss": 18.13138723373413, "val_acc": 60.0}
{"epoch": 28, "training_loss": 73.00720548629761, "training_acc": 53.0, "val_loss": 18.23771595954895, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.20006394386292, "training_acc": 55.0, "val_loss": 23.294955492019653, "val_acc": 52.0}
{"epoch": 30, "training_loss": 71.04172444343567, "training_acc": 54.0, "val_loss": 18.061023950576782, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.66947603225708, "training_acc": 60.0, "val_loss": 18.051621317863464, "val_acc": 52.0}
{"epoch": 32, "training_loss": 62.39833045005798, "training_acc": 66.0, "val_loss": 20.74699103832245, "val_acc": 52.0}
{"epoch": 33, "training_loss": 63.199554204940796, "training_acc": 57.0, "val_loss": 17.768779397010803, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.05469632148743, "training_acc": 65.0, "val_loss": 18.629027903079987, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.20071768760681, "training_acc": 59.0, "val_loss": 19.905704259872437, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.3252944946289, "training_acc": 57.0, "val_loss": 18.762747943401337, "val_acc": 64.0}
{"epoch": 37, "training_loss": 79.38452172279358, "training_acc": 47.0, "val_loss": 16.537313163280487, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.20031905174255, "training_acc": 59.0, "val_loss": 21.421557664871216, "val_acc": 52.0}
{"epoch": 39, "training_loss": 75.7456362247467, "training_acc": 59.0, "val_loss": 19.159388542175293, "val_acc": 60.0}
{"epoch": 40, "training_loss": 81.74098896980286, "training_acc": 49.0, "val_loss": 16.20066463947296, "val_acc": 52.0}
{"epoch": 41, "training_loss": 72.47282075881958, "training_acc": 56.0, "val_loss": 18.88788193464279, "val_acc": 52.0}
{"epoch": 42, "training_loss": 65.82325100898743, "training_acc": 57.0, "val_loss": 18.296650052070618, "val_acc": 60.0}
{"epoch": 43, "training_loss": 73.5238766670227, "training_acc": 49.0, "val_loss": 16.595493257045746, "val_acc": 52.0}
{"epoch": 44, "training_loss": 60.7804753780365, "training_acc": 67.0, "val_loss": 17.56328195333481, "val_acc": 52.0}
{"epoch": 45, "training_loss": 60.444443464279175, "training_acc": 67.0, "val_loss": 17.195361852645874, "val_acc": 52.0}
{"epoch": 46, "training_loss": 66.08478450775146, "training_acc": 59.0, "val_loss": 19.2094087600708, "val_acc": 52.0}
{"epoch": 47, "training_loss": 64.33982300758362, "training_acc": 62.0, "val_loss": 18.53039115667343, "val_acc": 52.0}
{"epoch": 48, "training_loss": 65.87062931060791, "training_acc": 63.0, "val_loss": 18.0087149143219, "val_acc": 52.0}
{"epoch": 49, "training_loss": 63.992491245269775, "training_acc": 67.0, "val_loss": 20.409542322158813, "val_acc": 52.0}
{"epoch": 50, "training_loss": 60.8463408946991, "training_acc": 62.0, "val_loss": 17.665746808052063, "val_acc": 52.0}
{"epoch": 51, "training_loss": 62.53556561470032, "training_acc": 70.0, "val_loss": 19.384025037288666, "val_acc": 52.0}
{"epoch": 52, "training_loss": 62.6254985332489, "training_acc": 61.0, "val_loss": 19.65067833662033, "val_acc": 52.0}
{"epoch": 53, "training_loss": 60.03931522369385, "training_acc": 71.0, "val_loss": 17.76624619960785, "val_acc": 52.0}
{"epoch": 54, "training_loss": 64.12360095977783, "training_acc": 53.0, "val_loss": 19.056302309036255, "val_acc": 52.0}
{"epoch": 55, "training_loss": 64.63928771018982, "training_acc": 62.0, "val_loss": 17.766040563583374, "val_acc": 52.0}
{"epoch": 56, "training_loss": 62.473097801208496, "training_acc": 66.0, "val_loss": 17.50882714986801, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.30446195602417, "training_acc": 56.0, "val_loss": 18.655629456043243, "val_acc": 52.0}
{"epoch": 58, "training_loss": 56.40803790092468, "training_acc": 82.0, "val_loss": 17.93387532234192, "val_acc": 44.0}
{"epoch": 59, "training_loss": 67.1634669303894, "training_acc": 54.0, "val_loss": 20.282380282878876, "val_acc": 52.0}
