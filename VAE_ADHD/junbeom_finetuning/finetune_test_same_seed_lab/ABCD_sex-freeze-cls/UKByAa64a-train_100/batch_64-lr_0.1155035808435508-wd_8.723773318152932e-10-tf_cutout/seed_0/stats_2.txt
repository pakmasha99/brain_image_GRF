"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 261.3531017303467, "training_acc": 51.0, "val_loss": 50.617021322250366, "val_acc": 52.0}
{"epoch": 1, "training_loss": 263.984974861145, "training_acc": 51.0, "val_loss": 124.45200681686401, "val_acc": 48.0}
{"epoch": 2, "training_loss": 446.7314701080322, "training_acc": 47.0, "val_loss": 23.344135284423828, "val_acc": 48.0}
{"epoch": 3, "training_loss": 158.2882318496704, "training_acc": 47.0, "val_loss": 100.07010698318481, "val_acc": 52.0}
{"epoch": 4, "training_loss": 383.25167751312256, "training_acc": 53.0, "val_loss": 73.34856986999512, "val_acc": 52.0}
{"epoch": 5, "training_loss": 222.97989654541016, "training_acc": 53.0, "val_loss": 40.36279916763306, "val_acc": 48.0}
{"epoch": 6, "training_loss": 192.45020008087158, "training_acc": 47.0, "val_loss": 69.37305331230164, "val_acc": 48.0}
{"epoch": 7, "training_loss": 234.16706800460815, "training_acc": 47.0, "val_loss": 18.144340813159943, "val_acc": 52.0}
{"epoch": 8, "training_loss": 102.37815046310425, "training_acc": 52.0, "val_loss": 48.1107234954834, "val_acc": 52.0}
{"epoch": 9, "training_loss": 173.13528299331665, "training_acc": 53.0, "val_loss": 19.391046464443207, "val_acc": 52.0}
{"epoch": 10, "training_loss": 85.47405242919922, "training_acc": 48.0, "val_loss": 41.659218072891235, "val_acc": 48.0}
{"epoch": 11, "training_loss": 144.24564170837402, "training_acc": 46.0, "val_loss": 19.190120697021484, "val_acc": 44.0}
{"epoch": 12, "training_loss": 85.25606775283813, "training_acc": 56.0, "val_loss": 31.846067309379578, "val_acc": 52.0}
{"epoch": 13, "training_loss": 117.01896858215332, "training_acc": 53.0, "val_loss": 17.87387877702713, "val_acc": 52.0}
{"epoch": 14, "training_loss": 81.08312463760376, "training_acc": 55.0, "val_loss": 26.500433683395386, "val_acc": 48.0}
{"epoch": 15, "training_loss": 96.57774090766907, "training_acc": 48.0, "val_loss": 20.93978524208069, "val_acc": 52.0}
{"epoch": 16, "training_loss": 83.26265025138855, "training_acc": 53.0, "val_loss": 20.70954442024231, "val_acc": 52.0}
{"epoch": 17, "training_loss": 77.47916913032532, "training_acc": 54.0, "val_loss": 19.32746320962906, "val_acc": 52.0}
{"epoch": 18, "training_loss": 79.01165103912354, "training_acc": 47.0, "val_loss": 16.959084570407867, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.6820912361145, "training_acc": 56.0, "val_loss": 19.53284442424774, "val_acc": 52.0}
{"epoch": 20, "training_loss": 73.79082822799683, "training_acc": 51.0, "val_loss": 17.299075424671173, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.8632402420044, "training_acc": 56.0, "val_loss": 16.803765296936035, "val_acc": 56.0}
{"epoch": 22, "training_loss": 64.60812377929688, "training_acc": 61.0, "val_loss": 17.434053122997284, "val_acc": 52.0}
{"epoch": 23, "training_loss": 65.85816597938538, "training_acc": 57.0, "val_loss": 16.837884485721588, "val_acc": 56.0}
{"epoch": 24, "training_loss": 63.415688276290894, "training_acc": 72.0, "val_loss": 17.18859076499939, "val_acc": 52.0}
{"epoch": 25, "training_loss": 64.33089876174927, "training_acc": 58.0, "val_loss": 17.413102090358734, "val_acc": 52.0}
{"epoch": 26, "training_loss": 61.71430015563965, "training_acc": 69.0, "val_loss": 17.719361186027527, "val_acc": 56.0}
{"epoch": 27, "training_loss": 73.20880246162415, "training_acc": 49.0, "val_loss": 17.86852478981018, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.3724615573883, "training_acc": 53.0, "val_loss": 19.720996916294098, "val_acc": 52.0}
{"epoch": 29, "training_loss": 63.92479753494263, "training_acc": 63.0, "val_loss": 19.194617867469788, "val_acc": 56.0}
{"epoch": 30, "training_loss": 75.60386443138123, "training_acc": 47.0, "val_loss": 16.880573332309723, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.65381264686584, "training_acc": 59.0, "val_loss": 19.55682784318924, "val_acc": 52.0}
{"epoch": 32, "training_loss": 76.04616856575012, "training_acc": 43.0, "val_loss": 16.899943351745605, "val_acc": 60.0}
{"epoch": 33, "training_loss": 64.58519315719604, "training_acc": 67.0, "val_loss": 18.441779911518097, "val_acc": 52.0}
{"epoch": 34, "training_loss": 61.70586705207825, "training_acc": 63.0, "val_loss": 16.833533346652985, "val_acc": 56.0}
{"epoch": 35, "training_loss": 65.3509795665741, "training_acc": 70.0, "val_loss": 17.928220331668854, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.62624740600586, "training_acc": 59.0, "val_loss": 17.99984723329544, "val_acc": 52.0}
{"epoch": 37, "training_loss": 60.748477935791016, "training_acc": 66.0, "val_loss": 17.301975190639496, "val_acc": 56.0}
{"epoch": 38, "training_loss": 65.72045469284058, "training_acc": 58.0, "val_loss": 17.009887099266052, "val_acc": 56.0}
{"epoch": 39, "training_loss": 62.05017805099487, "training_acc": 69.0, "val_loss": 18.38661879301071, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.85614109039307, "training_acc": 58.0, "val_loss": 17.085635662078857, "val_acc": 64.0}
