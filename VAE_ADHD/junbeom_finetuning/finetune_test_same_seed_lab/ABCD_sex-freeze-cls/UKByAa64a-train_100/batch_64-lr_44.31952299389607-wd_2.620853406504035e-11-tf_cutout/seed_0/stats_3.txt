"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 86087.20645141602, "training_acc": 53.0, "val_loss": 16835.90545654297, "val_acc": 52.0}
{"epoch": 1, "training_loss": 90365.30029296875, "training_acc": 55.0, "val_loss": 56501.336669921875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 215471.23681640625, "training_acc": 47.0, "val_loss": 20209.28497314453, "val_acc": 48.0}
{"epoch": 3, "training_loss": 83221.06811523438, "training_acc": 40.0, "val_loss": 31407.656860351562, "val_acc": 52.0}
{"epoch": 4, "training_loss": 114854.3779296875, "training_acc": 53.0, "val_loss": 24739.3798828125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 57865.07336425781, "training_acc": 54.0, "val_loss": 17286.827087402344, "val_acc": 48.0}
{"epoch": 6, "training_loss": 91832.06005859375, "training_acc": 47.0, "val_loss": 27776.779174804688, "val_acc": 48.0}
{"epoch": 7, "training_loss": 103134.39086914062, "training_acc": 47.0, "val_loss": 2165.081024169922, "val_acc": 36.0}
{"epoch": 8, "training_loss": 18997.320068359375, "training_acc": 57.0, "val_loss": 24952.801513671875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 82625.49609375, "training_acc": 53.0, "val_loss": 16532.777404785156, "val_acc": 52.0}
{"epoch": 10, "training_loss": 33431.534729003906, "training_acc": 54.0, "val_loss": 16157.441711425781, "val_acc": 48.0}
{"epoch": 11, "training_loss": 82209.048828125, "training_acc": 47.0, "val_loss": 20923.684692382812, "val_acc": 48.0}
{"epoch": 12, "training_loss": 71806.94909667969, "training_acc": 47.0, "val_loss": 8251.04751586914, "val_acc": 52.0}
{"epoch": 13, "training_loss": 36390.99951171875, "training_acc": 54.0, "val_loss": 17794.08416748047, "val_acc": 52.0}
{"epoch": 14, "training_loss": 47684.50183105469, "training_acc": 53.0, "val_loss": 2406.609344482422, "val_acc": 44.0}
{"epoch": 15, "training_loss": 17658.18536376953, "training_acc": 49.0, "val_loss": 2669.3613052368164, "val_acc": 44.0}
{"epoch": 16, "training_loss": 18319.274475097656, "training_acc": 52.0, "val_loss": 10397.241973876953, "val_acc": 52.0}
{"epoch": 17, "training_loss": 23650.11004638672, "training_acc": 53.0, "val_loss": 5344.178771972656, "val_acc": 48.0}
{"epoch": 18, "training_loss": 27526.401733398438, "training_acc": 47.0, "val_loss": 2978.644371032715, "val_acc": 44.0}
{"epoch": 19, "training_loss": 19079.380859375, "training_acc": 51.0, "val_loss": 12595.44906616211, "val_acc": 52.0}
{"epoch": 20, "training_loss": 29417.38201904297, "training_acc": 53.0, "val_loss": 1882.835578918457, "val_acc": 40.0}
{"epoch": 21, "training_loss": 17381.4833984375, "training_acc": 51.0, "val_loss": 2215.80753326416, "val_acc": 44.0}
{"epoch": 22, "training_loss": 9966.5498046875, "training_acc": 51.0, "val_loss": 9971.878814697266, "val_acc": 52.0}
{"epoch": 23, "training_loss": 17064.272003173828, "training_acc": 57.0, "val_loss": 5391.78352355957, "val_acc": 48.0}
{"epoch": 24, "training_loss": 28410.146850585938, "training_acc": 47.0, "val_loss": 1748.065185546875, "val_acc": 48.0}
{"epoch": 25, "training_loss": 15102.239990234375, "training_acc": 54.0, "val_loss": 9851.403045654297, "val_acc": 52.0}
{"epoch": 26, "training_loss": 18280.521614074707, "training_acc": 54.0, "val_loss": 5749.627304077148, "val_acc": 48.0}
{"epoch": 27, "training_loss": 28150.89501953125, "training_acc": 47.0, "val_loss": 2379.1454315185547, "val_acc": 52.0}
{"epoch": 28, "training_loss": 10770.503662109375, "training_acc": 70.0, "val_loss": 9230.06591796875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 18436.221160888672, "training_acc": 60.0, "val_loss": 5439.850997924805, "val_acc": 48.0}
{"epoch": 30, "training_loss": 27364.284423828125, "training_acc": 48.0, "val_loss": 2163.6308670043945, "val_acc": 48.0}
{"epoch": 31, "training_loss": 9329.290954589844, "training_acc": 55.0, "val_loss": 5011.370468139648, "val_acc": 52.0}
{"epoch": 32, "training_loss": 11616.436584472656, "training_acc": 57.0, "val_loss": 2481.597328186035, "val_acc": 52.0}
{"epoch": 33, "training_loss": 13135.23046875, "training_acc": 50.0, "val_loss": 3024.3637084960938, "val_acc": 52.0}
{"epoch": 34, "training_loss": 5226.948638916016, "training_acc": 61.0, "val_loss": 1275.5176544189453, "val_acc": 40.0}
{"epoch": 35, "training_loss": 7454.766067504883, "training_acc": 59.0, "val_loss": 3373.516082763672, "val_acc": 52.0}
{"epoch": 36, "training_loss": 7759.450744628906, "training_acc": 55.0, "val_loss": 1122.4365234375, "val_acc": 48.0}
{"epoch": 37, "training_loss": 5993.818328857422, "training_acc": 63.0, "val_loss": 4504.587936401367, "val_acc": 52.0}
{"epoch": 38, "training_loss": 16104.883666992188, "training_acc": 44.0, "val_loss": 2100.8480072021484, "val_acc": 52.0}
{"epoch": 39, "training_loss": 13297.778625488281, "training_acc": 50.0, "val_loss": 8144.803619384766, "val_acc": 52.0}
{"epoch": 40, "training_loss": 15321.464904785156, "training_acc": 57.0, "val_loss": 7538.395690917969, "val_acc": 48.0}
{"epoch": 41, "training_loss": 35549.922119140625, "training_acc": 47.0, "val_loss": 2143.680191040039, "val_acc": 52.0}
{"epoch": 42, "training_loss": 17327.05322265625, "training_acc": 56.0, "val_loss": 16272.743225097656, "val_acc": 52.0}
{"epoch": 43, "training_loss": 54449.828369140625, "training_acc": 53.0, "val_loss": 6078.200912475586, "val_acc": 52.0}
{"epoch": 44, "training_loss": 23123.412475585938, "training_acc": 53.0, "val_loss": 14855.911254882812, "val_acc": 48.0}
{"epoch": 45, "training_loss": 52782.21350097656, "training_acc": 47.0, "val_loss": 1249.2816925048828, "val_acc": 56.0}
{"epoch": 46, "training_loss": 19401.238647460938, "training_acc": 57.0, "val_loss": 18370.132446289062, "val_acc": 52.0}
{"epoch": 47, "training_loss": 66594.41979980469, "training_acc": 53.0, "val_loss": 9746.61865234375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 24740.75390625, "training_acc": 54.0, "val_loss": 8259.699249267578, "val_acc": 48.0}
{"epoch": 49, "training_loss": 27383.67578125, "training_acc": 47.0, "val_loss": 6142.376708984375, "val_acc": 52.0}
{"epoch": 50, "training_loss": 20129.08428955078, "training_acc": 54.0, "val_loss": 5976.023483276367, "val_acc": 52.0}
{"epoch": 51, "training_loss": 15808.333068847656, "training_acc": 48.0, "val_loss": 5292.205047607422, "val_acc": 48.0}
{"epoch": 52, "training_loss": 19398.474029541016, "training_acc": 47.0, "val_loss": 5114.076232910156, "val_acc": 52.0}
{"epoch": 53, "training_loss": 8255.971298217773, "training_acc": 60.0, "val_loss": 1234.980583190918, "val_acc": 44.0}
{"epoch": 54, "training_loss": 3565.39884185791, "training_acc": 69.0, "val_loss": 3734.717559814453, "val_acc": 52.0}
{"epoch": 55, "training_loss": 7819.246063232422, "training_acc": 55.0, "val_loss": 1559.30814743042, "val_acc": 48.0}
{"epoch": 56, "training_loss": 3015.764877319336, "training_acc": 71.0, "val_loss": 654.7885417938232, "val_acc": 72.0}
{"epoch": 57, "training_loss": 4175.048599243164, "training_acc": 71.0, "val_loss": 3417.937469482422, "val_acc": 52.0}
{"epoch": 58, "training_loss": 7475.055389404297, "training_acc": 54.0, "val_loss": 807.695198059082, "val_acc": 48.0}
{"epoch": 59, "training_loss": 3334.85888671875, "training_acc": 72.0, "val_loss": 1566.822338104248, "val_acc": 48.0}
{"epoch": 60, "training_loss": 5231.841339111328, "training_acc": 64.0, "val_loss": 3133.3261489868164, "val_acc": 52.0}
{"epoch": 61, "training_loss": 6490.833084106445, "training_acc": 56.0, "val_loss": 675.6889343261719, "val_acc": 48.0}
{"epoch": 62, "training_loss": 4938.472961425781, "training_acc": 73.0, "val_loss": 1272.2867965698242, "val_acc": 56.0}
{"epoch": 63, "training_loss": 5141.0887451171875, "training_acc": 67.0, "val_loss": 577.1072864532471, "val_acc": 52.0}
{"epoch": 64, "training_loss": 5704.0009765625, "training_acc": 68.0, "val_loss": 520.355749130249, "val_acc": 64.0}
{"epoch": 65, "training_loss": 2955.547752380371, "training_acc": 69.0, "val_loss": 2301.9697189331055, "val_acc": 52.0}
{"epoch": 66, "training_loss": 3765.5273056030273, "training_acc": 64.0, "val_loss": 3636.417770385742, "val_acc": 48.0}
{"epoch": 67, "training_loss": 9324.871158599854, "training_acc": 62.0, "val_loss": 4082.8357696533203, "val_acc": 52.0}
{"epoch": 68, "training_loss": 7078.144929885864, "training_acc": 64.0, "val_loss": 2297.4193572998047, "val_acc": 48.0}
{"epoch": 69, "training_loss": 7636.407073974609, "training_acc": 55.0, "val_loss": 2350.8188247680664, "val_acc": 52.0}
{"epoch": 70, "training_loss": 7069.687316894531, "training_acc": 59.0, "val_loss": 626.5755653381348, "val_acc": 64.0}
{"epoch": 71, "training_loss": 8661.988159179688, "training_acc": 62.0, "val_loss": 6752.649688720703, "val_acc": 52.0}
{"epoch": 72, "training_loss": 10674.581184387207, "training_acc": 64.0, "val_loss": 2987.8725051879883, "val_acc": 48.0}
{"epoch": 73, "training_loss": 9067.765369415283, "training_acc": 58.0, "val_loss": 3248.561477661133, "val_acc": 52.0}
{"epoch": 74, "training_loss": 4477.204856872559, "training_acc": 67.0, "val_loss": 695.4849720001221, "val_acc": 56.0}
{"epoch": 75, "training_loss": 2309.438720703125, "training_acc": 76.0, "val_loss": 1312.4893188476562, "val_acc": 48.0}
{"epoch": 76, "training_loss": 3966.0052795410156, "training_acc": 68.0, "val_loss": 1959.1909408569336, "val_acc": 52.0}
{"epoch": 77, "training_loss": 3922.302520751953, "training_acc": 64.0, "val_loss": 6137.08381652832, "val_acc": 48.0}
{"epoch": 78, "training_loss": 20390.02130126953, "training_acc": 47.0, "val_loss": 3658.92333984375, "val_acc": 52.0}
{"epoch": 79, "training_loss": 11599.761322021484, "training_acc": 53.0, "val_loss": 2498.5336303710938, "val_acc": 48.0}
{"epoch": 80, "training_loss": 8040.573486328125, "training_acc": 52.0, "val_loss": 4408.479309082031, "val_acc": 52.0}
{"epoch": 81, "training_loss": 10938.9345703125, "training_acc": 56.0, "val_loss": 3452.085494995117, "val_acc": 48.0}
{"epoch": 82, "training_loss": 9423.999298095703, "training_acc": 52.0, "val_loss": 5128.275299072266, "val_acc": 52.0}
{"epoch": 83, "training_loss": 11356.294036865234, "training_acc": 53.0, "val_loss": 6314.603424072266, "val_acc": 48.0}
