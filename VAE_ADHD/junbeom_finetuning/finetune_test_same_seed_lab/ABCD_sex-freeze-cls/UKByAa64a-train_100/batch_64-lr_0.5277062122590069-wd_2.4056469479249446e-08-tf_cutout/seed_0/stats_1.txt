"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1152.7303733825684, "training_acc": 46.0, "val_loss": 231.53076171875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1125.2177200317383, "training_acc": 53.0, "val_loss": 600.0705242156982, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2258.009834289551, "training_acc": 47.0, "val_loss": 166.41961336135864, "val_acc": 48.0}
{"epoch": 3, "training_loss": 786.6877841949463, "training_acc": 51.0, "val_loss": 438.02857398986816, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1664.7927703857422, "training_acc": 53.0, "val_loss": 390.86079597473145, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1160.4831733703613, "training_acc": 53.0, "val_loss": 68.17899942398071, "val_acc": 48.0}
{"epoch": 6, "training_loss": 627.6060371398926, "training_acc": 47.0, "val_loss": 201.70133113861084, "val_acc": 48.0}
{"epoch": 7, "training_loss": 684.5535869598389, "training_acc": 47.0, "val_loss": 142.64538288116455, "val_acc": 52.0}
{"epoch": 8, "training_loss": 556.3135604858398, "training_acc": 53.0, "val_loss": 246.78175449371338, "val_acc": 52.0}
{"epoch": 9, "training_loss": 797.5339851379395, "training_acc": 53.0, "val_loss": 28.493189811706543, "val_acc": 52.0}
{"epoch": 10, "training_loss": 307.3872299194336, "training_acc": 53.0, "val_loss": 194.71471309661865, "val_acc": 48.0}
{"epoch": 11, "training_loss": 718.2618942260742, "training_acc": 47.0, "val_loss": 27.14502513408661, "val_acc": 52.0}
{"epoch": 12, "training_loss": 185.66138458251953, "training_acc": 54.0, "val_loss": 95.33289074897766, "val_acc": 52.0}
{"epoch": 13, "training_loss": 214.94312715530396, "training_acc": 58.0, "val_loss": 111.13134622573853, "val_acc": 48.0}
{"epoch": 14, "training_loss": 491.3518524169922, "training_acc": 47.0, "val_loss": 48.06608557701111, "val_acc": 48.0}
{"epoch": 15, "training_loss": 245.08429336547852, "training_acc": 53.0, "val_loss": 172.12514877319336, "val_acc": 52.0}
{"epoch": 16, "training_loss": 588.6639728546143, "training_acc": 53.0, "val_loss": 57.08773732185364, "val_acc": 52.0}
{"epoch": 17, "training_loss": 272.3453998565674, "training_acc": 52.0, "val_loss": 161.08728647232056, "val_acc": 48.0}
{"epoch": 18, "training_loss": 626.7999572753906, "training_acc": 47.0, "val_loss": 21.36703133583069, "val_acc": 56.0}
{"epoch": 19, "training_loss": 253.8474998474121, "training_acc": 60.0, "val_loss": 170.58154344558716, "val_acc": 52.0}
{"epoch": 20, "training_loss": 500.658145904541, "training_acc": 53.0, "val_loss": 18.321597576141357, "val_acc": 60.0}
{"epoch": 21, "training_loss": 192.46513748168945, "training_acc": 52.0, "val_loss": 70.83069682121277, "val_acc": 48.0}
{"epoch": 22, "training_loss": 237.1465401649475, "training_acc": 51.0, "val_loss": 87.53362894058228, "val_acc": 52.0}
{"epoch": 23, "training_loss": 253.8085765838623, "training_acc": 53.0, "val_loss": 28.103145956993103, "val_acc": 44.0}
{"epoch": 24, "training_loss": 161.84607410430908, "training_acc": 53.0, "val_loss": 21.301282942295074, "val_acc": 60.0}
{"epoch": 25, "training_loss": 105.5090160369873, "training_acc": 67.0, "val_loss": 31.609615683555603, "val_acc": 60.0}
{"epoch": 26, "training_loss": 174.03149318695068, "training_acc": 46.0, "val_loss": 30.3716778755188, "val_acc": 44.0}
{"epoch": 27, "training_loss": 160.52302265167236, "training_acc": 49.0, "val_loss": 53.864771127700806, "val_acc": 52.0}
{"epoch": 28, "training_loss": 139.82339477539062, "training_acc": 58.0, "val_loss": 45.612066984176636, "val_acc": 48.0}
{"epoch": 29, "training_loss": 133.01019668579102, "training_acc": 57.0, "val_loss": 83.80792737007141, "val_acc": 52.0}
{"epoch": 30, "training_loss": 282.6974220275879, "training_acc": 53.0, "val_loss": 21.088150143623352, "val_acc": 64.0}
{"epoch": 31, "training_loss": 150.71512031555176, "training_acc": 59.0, "val_loss": 27.129685878753662, "val_acc": 44.0}
{"epoch": 32, "training_loss": 187.86561679840088, "training_acc": 49.0, "val_loss": 90.5955970287323, "val_acc": 52.0}
{"epoch": 33, "training_loss": 195.29281091690063, "training_acc": 55.0, "val_loss": 78.4087061882019, "val_acc": 48.0}
{"epoch": 34, "training_loss": 343.1796712875366, "training_acc": 47.0, "val_loss": 23.5060915350914, "val_acc": 56.0}
{"epoch": 35, "training_loss": 132.830472946167, "training_acc": 58.0, "val_loss": 53.98319363594055, "val_acc": 52.0}
{"epoch": 36, "training_loss": 142.88586711883545, "training_acc": 53.0, "val_loss": 33.48352015018463, "val_acc": 44.0}
{"epoch": 37, "training_loss": 153.75262832641602, "training_acc": 53.0, "val_loss": 58.08718204498291, "val_acc": 52.0}
{"epoch": 38, "training_loss": 135.80095386505127, "training_acc": 57.0, "val_loss": 33.2341343164444, "val_acc": 48.0}
{"epoch": 39, "training_loss": 119.61065006256104, "training_acc": 54.0, "val_loss": 35.165923833847046, "val_acc": 52.0}
