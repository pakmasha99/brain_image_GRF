"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.23547768592834, "training_acc": 46.0, "val_loss": 17.39853173494339, "val_acc": 52.0}
{"epoch": 1, "training_loss": 72.54799747467041, "training_acc": 43.0, "val_loss": 18.628406524658203, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.57565498352051, "training_acc": 53.0, "val_loss": 17.780013382434845, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.01515817642212, "training_acc": 53.0, "val_loss": 17.30101704597473, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.37589359283447, "training_acc": 47.0, "val_loss": 17.501220107078552, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.32043290138245, "training_acc": 47.0, "val_loss": 17.38300621509552, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.53915476799011, "training_acc": 51.0, "val_loss": 17.337486147880554, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.36982846260071, "training_acc": 53.0, "val_loss": 17.605747282505035, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.65062546730042, "training_acc": 53.0, "val_loss": 17.506015300750732, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.47734570503235, "training_acc": 53.0, "val_loss": 17.300033569335938, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.959792137146, "training_acc": 40.0, "val_loss": 17.49565154314041, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.02353763580322, "training_acc": 47.0, "val_loss": 17.298701405525208, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10726189613342, "training_acc": 54.0, "val_loss": 17.478108406066895, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.65606951713562, "training_acc": 53.0, "val_loss": 17.688804864883423, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.44933724403381, "training_acc": 53.0, "val_loss": 17.573577165603638, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.8395369052887, "training_acc": 53.0, "val_loss": 17.354971170425415, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.48888421058655, "training_acc": 53.0, "val_loss": 17.296817898750305, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17143726348877, "training_acc": 53.0, "val_loss": 17.304979264736176, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26323771476746, "training_acc": 53.0, "val_loss": 17.293377220630646, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17653965950012, "training_acc": 53.0, "val_loss": 17.33148992061615, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.48116278648376, "training_acc": 53.0, "val_loss": 17.3703134059906, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.46725964546204, "training_acc": 53.0, "val_loss": 17.294849455356598, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15256261825562, "training_acc": 51.0, "val_loss": 17.42616444826126, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.05819702148438, "training_acc": 47.0, "val_loss": 17.41141527891159, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.54396152496338, "training_acc": 46.0, "val_loss": 17.303308844566345, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.2967300415039, "training_acc": 53.0, "val_loss": 17.5155907869339, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.85935139656067, "training_acc": 53.0, "val_loss": 17.456939816474915, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.58097195625305, "training_acc": 53.0, "val_loss": 17.2962948679924, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.99083399772644, "training_acc": 53.0, "val_loss": 17.32065975666046, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.44613766670227, "training_acc": 49.0, "val_loss": 17.354005575180054, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.53333353996277, "training_acc": 45.0, "val_loss": 17.297403514385223, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15410017967224, "training_acc": 53.0, "val_loss": 17.345191538333893, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.29112768173218, "training_acc": 53.0, "val_loss": 17.42965877056122, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.65539240837097, "training_acc": 53.0, "val_loss": 17.326711118221283, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.73426723480225, "training_acc": 53.0, "val_loss": 17.384910583496094, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.7725121974945, "training_acc": 47.0, "val_loss": 17.532962560653687, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.16164898872375, "training_acc": 47.0, "val_loss": 17.321273684501648, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.95768713951111, "training_acc": 67.0, "val_loss": 17.376355826854706, "val_acc": 52.0}
