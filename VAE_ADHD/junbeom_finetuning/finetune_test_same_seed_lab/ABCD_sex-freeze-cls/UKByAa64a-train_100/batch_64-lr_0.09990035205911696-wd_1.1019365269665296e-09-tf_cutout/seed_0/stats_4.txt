"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 270.0090160369873, "training_acc": 46.0, "val_loss": 49.7756689786911, "val_acc": 52.0}
{"epoch": 1, "training_loss": 228.74954414367676, "training_acc": 51.0, "val_loss": 102.52581834793091, "val_acc": 48.0}
{"epoch": 2, "training_loss": 380.73779487609863, "training_acc": 47.0, "val_loss": 24.732379615306854, "val_acc": 48.0}
{"epoch": 3, "training_loss": 138.60876750946045, "training_acc": 45.0, "val_loss": 69.80941891670227, "val_acc": 52.0}
{"epoch": 4, "training_loss": 264.0011739730835, "training_acc": 53.0, "val_loss": 38.693252205848694, "val_acc": 52.0}
{"epoch": 5, "training_loss": 120.71224331855774, "training_acc": 51.0, "val_loss": 43.1720107793808, "val_acc": 48.0}
{"epoch": 6, "training_loss": 179.63355922698975, "training_acc": 47.0, "val_loss": 38.503798842430115, "val_acc": 48.0}
{"epoch": 7, "training_loss": 128.37678980827332, "training_acc": 50.0, "val_loss": 28.741326928138733, "val_acc": 52.0}
{"epoch": 8, "training_loss": 126.33635330200195, "training_acc": 53.0, "val_loss": 29.106110334396362, "val_acc": 52.0}
{"epoch": 9, "training_loss": 105.79384160041809, "training_acc": 54.0, "val_loss": 24.00941103696823, "val_acc": 48.0}
{"epoch": 10, "training_loss": 102.77180337905884, "training_acc": 46.0, "val_loss": 21.56710922718048, "val_acc": 44.0}
{"epoch": 11, "training_loss": 88.58098936080933, "training_acc": 40.0, "val_loss": 22.357170283794403, "val_acc": 52.0}
{"epoch": 12, "training_loss": 83.19708442687988, "training_acc": 53.0, "val_loss": 17.212297022342682, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.5058491230011, "training_acc": 61.0, "val_loss": 20.539039373397827, "val_acc": 44.0}
{"epoch": 14, "training_loss": 73.17318034172058, "training_acc": 49.0, "val_loss": 18.056578934192657, "val_acc": 52.0}
{"epoch": 15, "training_loss": 77.86105680465698, "training_acc": 53.0, "val_loss": 18.84559839963913, "val_acc": 52.0}
{"epoch": 16, "training_loss": 71.63553595542908, "training_acc": 55.0, "val_loss": 19.744841754436493, "val_acc": 48.0}
{"epoch": 17, "training_loss": 76.30616521835327, "training_acc": 46.0, "val_loss": 17.148903012275696, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.79838061332703, "training_acc": 64.0, "val_loss": 18.9455583691597, "val_acc": 52.0}
{"epoch": 19, "training_loss": 72.83726072311401, "training_acc": 54.0, "val_loss": 17.31579154729843, "val_acc": 48.0}
{"epoch": 20, "training_loss": 67.7927017211914, "training_acc": 56.0, "val_loss": 17.126522958278656, "val_acc": 52.0}
{"epoch": 21, "training_loss": 66.5335590839386, "training_acc": 61.0, "val_loss": 17.409420013427734, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.50733947753906, "training_acc": 60.0, "val_loss": 17.02815592288971, "val_acc": 52.0}
{"epoch": 23, "training_loss": 65.40055584907532, "training_acc": 66.0, "val_loss": 17.00342148542404, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.54236698150635, "training_acc": 62.0, "val_loss": 17.054182291030884, "val_acc": 52.0}
{"epoch": 25, "training_loss": 64.81535339355469, "training_acc": 57.0, "val_loss": 17.27559268474579, "val_acc": 52.0}
{"epoch": 26, "training_loss": 65.39505386352539, "training_acc": 56.0, "val_loss": 17.219223082065582, "val_acc": 52.0}
{"epoch": 27, "training_loss": 64.51817440986633, "training_acc": 65.0, "val_loss": 17.20535457134247, "val_acc": 52.0}
{"epoch": 28, "training_loss": 64.8916130065918, "training_acc": 55.0, "val_loss": 17.304740846157074, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.34451198577881, "training_acc": 64.0, "val_loss": 16.921086609363556, "val_acc": 52.0}
{"epoch": 30, "training_loss": 64.17062759399414, "training_acc": 64.0, "val_loss": 17.338167130947113, "val_acc": 52.0}
{"epoch": 31, "training_loss": 63.89198446273804, "training_acc": 59.0, "val_loss": 17.132528126239777, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.31368613243103, "training_acc": 65.0, "val_loss": 17.27302372455597, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.58306074142456, "training_acc": 66.0, "val_loss": 17.74880588054657, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.14206218719482, "training_acc": 55.0, "val_loss": 16.959497332572937, "val_acc": 52.0}
{"epoch": 35, "training_loss": 67.32716631889343, "training_acc": 57.0, "val_loss": 16.93194955587387, "val_acc": 52.0}
{"epoch": 36, "training_loss": 65.44749927520752, "training_acc": 61.0, "val_loss": 17.157486081123352, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.50474286079407, "training_acc": 67.0, "val_loss": 16.943487524986267, "val_acc": 52.0}
{"epoch": 38, "training_loss": 64.61003708839417, "training_acc": 63.0, "val_loss": 16.87105894088745, "val_acc": 52.0}
{"epoch": 39, "training_loss": 64.35468220710754, "training_acc": 66.0, "val_loss": 16.793178021907806, "val_acc": 52.0}
{"epoch": 40, "training_loss": 62.78217625617981, "training_acc": 67.0, "val_loss": 17.15085804462433, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.65533399581909, "training_acc": 62.0, "val_loss": 16.767701506614685, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.08598446846008, "training_acc": 76.0, "val_loss": 17.825821042060852, "val_acc": 60.0}
{"epoch": 43, "training_loss": 63.21313524246216, "training_acc": 55.0, "val_loss": 18.073101341724396, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.37280058860779, "training_acc": 54.0, "val_loss": 16.94035530090332, "val_acc": 52.0}
{"epoch": 45, "training_loss": 59.390334367752075, "training_acc": 75.0, "val_loss": 19.753043353557587, "val_acc": 48.0}
{"epoch": 46, "training_loss": 75.02863383293152, "training_acc": 50.0, "val_loss": 16.927078366279602, "val_acc": 52.0}
{"epoch": 47, "training_loss": 66.03784608840942, "training_acc": 58.0, "val_loss": 18.114930391311646, "val_acc": 52.0}
{"epoch": 48, "training_loss": 65.89835405349731, "training_acc": 56.0, "val_loss": 16.87614768743515, "val_acc": 52.0}
{"epoch": 49, "training_loss": 61.97622609138489, "training_acc": 66.0, "val_loss": 17.986059188842773, "val_acc": 56.0}
{"epoch": 50, "training_loss": 62.147969245910645, "training_acc": 59.0, "val_loss": 17.48936027288437, "val_acc": 52.0}
{"epoch": 51, "training_loss": 62.54852366447449, "training_acc": 63.0, "val_loss": 16.947010159492493, "val_acc": 52.0}
{"epoch": 52, "training_loss": 62.98005771636963, "training_acc": 64.0, "val_loss": 17.159557342529297, "val_acc": 60.0}
{"epoch": 53, "training_loss": 61.83803129196167, "training_acc": 67.0, "val_loss": 17.202720046043396, "val_acc": 52.0}
{"epoch": 54, "training_loss": 61.39037847518921, "training_acc": 69.0, "val_loss": 17.423327267169952, "val_acc": 64.0}
{"epoch": 55, "training_loss": 66.65802383422852, "training_acc": 56.0, "val_loss": 16.897954046726227, "val_acc": 52.0}
{"epoch": 56, "training_loss": 61.13409876823425, "training_acc": 70.0, "val_loss": 16.911253333091736, "val_acc": 52.0}
{"epoch": 57, "training_loss": 60.99053621292114, "training_acc": 69.0, "val_loss": 16.918154060840607, "val_acc": 52.0}
{"epoch": 58, "training_loss": 60.25685238838196, "training_acc": 70.0, "val_loss": 17.861147224903107, "val_acc": 56.0}
{"epoch": 59, "training_loss": 61.92330598831177, "training_acc": 63.0, "val_loss": 17.190085351467133, "val_acc": 52.0}
{"epoch": 60, "training_loss": 63.287821769714355, "training_acc": 61.0, "val_loss": 16.984184086322784, "val_acc": 52.0}
