"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3231.893569946289, "training_acc": 55.0, "val_loss": 911.494255065918, "val_acc": 52.0}
{"epoch": 1, "training_loss": 5392.424468994141, "training_acc": 41.0, "val_loss": 1733.615493774414, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6039.039367675781, "training_acc": 47.0, "val_loss": 85.82837581634521, "val_acc": 56.0}
{"epoch": 3, "training_loss": 1147.2942276000977, "training_acc": 51.0, "val_loss": 829.1651725769043, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2552.9321212768555, "training_acc": 53.0, "val_loss": 281.65905475616455, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1675.6843566894531, "training_acc": 47.0, "val_loss": 233.87954235076904, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1275.0723190307617, "training_acc": 47.0, "val_loss": 634.7100734710693, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2159.9926109313965, "training_acc": 53.0, "val_loss": 44.73400115966797, "val_acc": 56.0}
{"epoch": 8, "training_loss": 824.3311767578125, "training_acc": 51.0, "val_loss": 428.8395404815674, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1139.5239925384521, "training_acc": 52.0, "val_loss": 452.67038345336914, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1784.727180480957, "training_acc": 53.0, "val_loss": 368.1500196456909, "val_acc": 52.0}
{"epoch": 11, "training_loss": 957.1882162094116, "training_acc": 55.0, "val_loss": 325.2190589904785, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1011.7676429748535, "training_acc": 48.0, "val_loss": 268.61720085144043, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1029.798542022705, "training_acc": 54.0, "val_loss": 164.2850637435913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 689.6432342529297, "training_acc": 52.0, "val_loss": 406.3549518585205, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1181.314266204834, "training_acc": 52.0, "val_loss": 314.443302154541, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1334.0632934570312, "training_acc": 53.0, "val_loss": 265.53587913513184, "val_acc": 52.0}
{"epoch": 17, "training_loss": 857.4105014801025, "training_acc": 55.0, "val_loss": 353.6388158798218, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1120.306770324707, "training_acc": 49.0, "val_loss": 280.96818923950195, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1198.9051666259766, "training_acc": 53.0, "val_loss": 216.13233089447021, "val_acc": 52.0}
{"epoch": 20, "training_loss": 700.8050174713135, "training_acc": 55.0, "val_loss": 351.8824100494385, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1090.8758335113525, "training_acc": 48.0, "val_loss": 372.2809314727783, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1513.3838348388672, "training_acc": 53.0, "val_loss": 346.2469816207886, "val_acc": 52.0}
{"epoch": 23, "training_loss": 955.1905174255371, "training_acc": 55.0, "val_loss": 157.34139680862427, "val_acc": 48.0}
{"epoch": 24, "training_loss": 551.8079404830933, "training_acc": 48.0, "val_loss": 136.07953786849976, "val_acc": 56.0}
{"epoch": 25, "training_loss": 337.76588916778564, "training_acc": 56.0, "val_loss": 50.96713304519653, "val_acc": 52.0}
{"epoch": 26, "training_loss": 260.00133419036865, "training_acc": 64.0, "val_loss": 53.36446762084961, "val_acc": 56.0}
