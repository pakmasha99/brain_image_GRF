"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 6853.313095092773, "training_acc": 53.0, "val_loss": 630.3600311279297, "val_acc": 56.0}
{"epoch": 1, "training_loss": 12599.84326171875, "training_acc": 45.0, "val_loss": 6309.741973876953, "val_acc": 48.0}
{"epoch": 2, "training_loss": 22754.350219726562, "training_acc": 47.0, "val_loss": 1008.9309692382812, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6757.353302001953, "training_acc": 49.0, "val_loss": 5114.270782470703, "val_acc": 52.0}
{"epoch": 4, "training_loss": 21096.529663085938, "training_acc": 53.0, "val_loss": 5076.088714599609, "val_acc": 52.0}
{"epoch": 5, "training_loss": 17041.928802490234, "training_acc": 53.0, "val_loss": 1082.7926635742188, "val_acc": 52.0}
{"epoch": 6, "training_loss": 6153.617095947266, "training_acc": 45.0, "val_loss": 3602.592086791992, "val_acc": 48.0}
{"epoch": 7, "training_loss": 14786.015686035156, "training_acc": 47.0, "val_loss": 3043.338394165039, "val_acc": 48.0}
{"epoch": 8, "training_loss": 10214.102813720703, "training_acc": 47.0, "val_loss": 1023.0942726135254, "val_acc": 52.0}
{"epoch": 9, "training_loss": 5450.115753173828, "training_acc": 52.0, "val_loss": 2579.2245864868164, "val_acc": 52.0}
{"epoch": 10, "training_loss": 8911.03286743164, "training_acc": 53.0, "val_loss": 883.1173896789551, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3597.5579223632812, "training_acc": 46.0, "val_loss": 1744.5049285888672, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6595.784332275391, "training_acc": 47.0, "val_loss": 445.483922958374, "val_acc": 40.0}
{"epoch": 13, "training_loss": 2365.4007720947266, "training_acc": 54.0, "val_loss": 1800.7257461547852, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6300.213897705078, "training_acc": 53.0, "val_loss": 870.0047492980957, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3341.6663970947266, "training_acc": 49.0, "val_loss": 1222.8752136230469, "val_acc": 48.0}
{"epoch": 16, "training_loss": 4435.876449584961, "training_acc": 48.0, "val_loss": 344.1164255142212, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2091.31103515625, "training_acc": 56.0, "val_loss": 884.3977928161621, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2179.6528244018555, "training_acc": 52.0, "val_loss": 630.4511547088623, "val_acc": 44.0}
{"epoch": 19, "training_loss": 2004.334873199463, "training_acc": 51.0, "val_loss": 438.0756378173828, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1744.0640487670898, "training_acc": 52.0, "val_loss": 151.64400339126587, "val_acc": 64.0}
{"epoch": 21, "training_loss": 1118.0599746704102, "training_acc": 56.0, "val_loss": 420.59173583984375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2118.74356842041, "training_acc": 44.0, "val_loss": 415.87252616882324, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1178.9919509887695, "training_acc": 57.0, "val_loss": 544.0014362335205, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1641.5624923706055, "training_acc": 50.0, "val_loss": 233.9747190475464, "val_acc": 56.0}
{"epoch": 25, "training_loss": 714.9504280090332, "training_acc": 69.0, "val_loss": 519.669771194458, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1408.0125007629395, "training_acc": 51.0, "val_loss": 473.38900566101074, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1544.2239303588867, "training_acc": 52.0, "val_loss": 402.9067039489746, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1292.1290702819824, "training_acc": 50.0, "val_loss": 383.67953300476074, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1223.6209812164307, "training_acc": 57.0, "val_loss": 304.96673583984375, "val_acc": 48.0}
{"epoch": 30, "training_loss": 886.5986938476562, "training_acc": 57.0, "val_loss": 486.9711399078369, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1395.9734992980957, "training_acc": 56.0, "val_loss": 503.76858711242676, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1613.7084884643555, "training_acc": 48.0, "val_loss": 320.5650568008423, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1203.1692085266113, "training_acc": 54.0, "val_loss": 337.19584941864014, "val_acc": 48.0}
{"epoch": 34, "training_loss": 869.0452289581299, "training_acc": 55.0, "val_loss": 333.3867311477661, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1052.8915481567383, "training_acc": 55.0, "val_loss": 789.1868591308594, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2934.5553283691406, "training_acc": 48.0, "val_loss": 82.38871097564697, "val_acc": 60.0}
{"epoch": 37, "training_loss": 871.5248718261719, "training_acc": 66.0, "val_loss": 779.08935546875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1857.1229496002197, "training_acc": 55.0, "val_loss": 1149.3741035461426, "val_acc": 48.0}
{"epoch": 39, "training_loss": 5076.985748291016, "training_acc": 47.0, "val_loss": 916.3314819335938, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3422.6496505737305, "training_acc": 43.0, "val_loss": 1050.0788688659668, "val_acc": 52.0}
{"epoch": 41, "training_loss": 3404.892349243164, "training_acc": 53.0, "val_loss": 331.65693283081055, "val_acc": 48.0}
{"epoch": 42, "training_loss": 1350.8060684204102, "training_acc": 48.0, "val_loss": 341.55986309051514, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1119.8050575256348, "training_acc": 54.0, "val_loss": 416.52350425720215, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1255.9065437316895, "training_acc": 51.0, "val_loss": 530.5192947387695, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1493.7037315368652, "training_acc": 53.0, "val_loss": 429.38232421875, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1741.8763122558594, "training_acc": 47.0, "val_loss": 445.847225189209, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1493.5405807495117, "training_acc": 55.0, "val_loss": 99.73921179771423, "val_acc": 64.0}
{"epoch": 48, "training_loss": 761.6291389465332, "training_acc": 55.0, "val_loss": 90.19688963890076, "val_acc": 60.0}
{"epoch": 49, "training_loss": 1025.3740234375, "training_acc": 59.0, "val_loss": 158.13146829605103, "val_acc": 56.0}
{"epoch": 50, "training_loss": 1178.4180374145508, "training_acc": 58.0, "val_loss": 521.8929290771484, "val_acc": 48.0}
{"epoch": 51, "training_loss": 1241.8019695281982, "training_acc": 60.0, "val_loss": 529.4987201690674, "val_acc": 52.0}
{"epoch": 52, "training_loss": 1327.0405521392822, "training_acc": 59.0, "val_loss": 303.92537117004395, "val_acc": 48.0}
{"epoch": 53, "training_loss": 1338.0332565307617, "training_acc": 45.0, "val_loss": 99.49610829353333, "val_acc": 60.0}
{"epoch": 54, "training_loss": 438.7417526245117, "training_acc": 70.0, "val_loss": 202.45013236999512, "val_acc": 52.0}
{"epoch": 55, "training_loss": 545.8590602874756, "training_acc": 63.0, "val_loss": 145.97374200820923, "val_acc": 44.0}
