"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 10054.403709411621, "training_acc": 49.0, "val_loss": 2516.027069091797, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10474.088989257812, "training_acc": 55.0, "val_loss": 5216.779327392578, "val_acc": 48.0}
{"epoch": 2, "training_loss": 19073.76776123047, "training_acc": 47.0, "val_loss": 977.0500183105469, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5853.179382324219, "training_acc": 53.0, "val_loss": 4988.67073059082, "val_acc": 52.0}
{"epoch": 4, "training_loss": 19238.28778076172, "training_acc": 53.0, "val_loss": 4719.051742553711, "val_acc": 52.0}
{"epoch": 5, "training_loss": 15333.363342285156, "training_acc": 53.0, "val_loss": 400.3791809082031, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4255.506408691406, "training_acc": 54.0, "val_loss": 4438.266372680664, "val_acc": 48.0}
{"epoch": 7, "training_loss": 18306.10467529297, "training_acc": 47.0, "val_loss": 3862.266159057617, "val_acc": 48.0}
{"epoch": 8, "training_loss": 13168.854370117188, "training_acc": 47.0, "val_loss": 339.7432804107666, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2840.3062286376953, "training_acc": 54.0, "val_loss": 1943.247413635254, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6229.909408569336, "training_acc": 53.0, "val_loss": 122.70127534866333, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2242.702178955078, "training_acc": 60.0, "val_loss": 1495.1244354248047, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4985.217758178711, "training_acc": 47.0, "val_loss": 871.6140747070312, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3461.285675048828, "training_acc": 53.0, "val_loss": 1336.0305786132812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3066.560089111328, "training_acc": 54.0, "val_loss": 1207.2465896606445, "val_acc": 48.0}
{"epoch": 15, "training_loss": 5993.746124267578, "training_acc": 47.0, "val_loss": 1321.4862823486328, "val_acc": 48.0}
{"epoch": 16, "training_loss": 4184.450958251953, "training_acc": 49.0, "val_loss": 1518.5453414916992, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5303.771286010742, "training_acc": 53.0, "val_loss": 1758.1031799316406, "val_acc": 52.0}
{"epoch": 18, "training_loss": 4139.00715637207, "training_acc": 53.0, "val_loss": 882.9293251037598, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4760.538970947266, "training_acc": 47.0, "val_loss": 1184.3046188354492, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3577.250659942627, "training_acc": 52.0, "val_loss": 1656.9705963134766, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6187.53662109375, "training_acc": 53.0, "val_loss": 2346.8061447143555, "val_acc": 52.0}
{"epoch": 22, "training_loss": 6454.477279663086, "training_acc": 53.0, "val_loss": 216.4881944656372, "val_acc": 44.0}
{"epoch": 23, "training_loss": 2310.958984375, "training_acc": 54.0, "val_loss": 1192.2236442565918, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4327.098400115967, "training_acc": 47.0, "val_loss": 1091.4868354797363, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3620.530303955078, "training_acc": 53.0, "val_loss": 1193.7932014465332, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2480.5797481536865, "training_acc": 51.0, "val_loss": 669.2514419555664, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2777.261707305908, "training_acc": 45.0, "val_loss": 472.730016708374, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1408.8305435180664, "training_acc": 56.0, "val_loss": 171.86654806137085, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1024.504783630371, "training_acc": 58.0, "val_loss": 180.80517053604126, "val_acc": 52.0}
