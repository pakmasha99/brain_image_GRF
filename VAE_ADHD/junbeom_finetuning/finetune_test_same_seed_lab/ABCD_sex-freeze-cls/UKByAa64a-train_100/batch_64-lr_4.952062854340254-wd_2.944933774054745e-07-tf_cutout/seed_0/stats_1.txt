"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 10444.997119903564, "training_acc": 46.0, "val_loss": 2173.843002319336, "val_acc": 52.0}
{"epoch": 1, "training_loss": 10556.849731445312, "training_acc": 53.0, "val_loss": 5630.207824707031, "val_acc": 48.0}
{"epoch": 2, "training_loss": 21188.969482421875, "training_acc": 47.0, "val_loss": 1560.7563972473145, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7383.231384277344, "training_acc": 51.0, "val_loss": 4111.598587036133, "val_acc": 52.0}
{"epoch": 4, "training_loss": 15621.710571289062, "training_acc": 53.0, "val_loss": 3668.8777923583984, "val_acc": 52.0}
{"epoch": 5, "training_loss": 10889.348663330078, "training_acc": 53.0, "val_loss": 637.6131534576416, "val_acc": 48.0}
{"epoch": 6, "training_loss": 5875.808807373047, "training_acc": 47.0, "val_loss": 1879.3668746948242, "val_acc": 48.0}
{"epoch": 7, "training_loss": 6369.800750732422, "training_acc": 47.0, "val_loss": 1361.5565299987793, "val_acc": 52.0}
{"epoch": 8, "training_loss": 5309.582809448242, "training_acc": 53.0, "val_loss": 2360.9743118286133, "val_acc": 52.0}
{"epoch": 9, "training_loss": 7666.902816772461, "training_acc": 53.0, "val_loss": 297.6160764694214, "val_acc": 52.0}
{"epoch": 10, "training_loss": 3099.7437744140625, "training_acc": 49.0, "val_loss": 2232.472801208496, "val_acc": 48.0}
{"epoch": 11, "training_loss": 8581.456756591797, "training_acc": 47.0, "val_loss": 534.2468738555908, "val_acc": 48.0}
{"epoch": 12, "training_loss": 3116.419952392578, "training_acc": 49.0, "val_loss": 2224.4930267333984, "val_acc": 52.0}
{"epoch": 13, "training_loss": 8524.149932861328, "training_acc": 53.0, "val_loss": 1628.9558410644531, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4276.779823303223, "training_acc": 53.0, "val_loss": 1582.6618194580078, "val_acc": 48.0}
{"epoch": 15, "training_loss": 7500.968597412109, "training_acc": 47.0, "val_loss": 1997.0598220825195, "val_acc": 48.0}
{"epoch": 16, "training_loss": 6225.853805541992, "training_acc": 47.0, "val_loss": 1015.6448364257812, "val_acc": 52.0}
{"epoch": 17, "training_loss": 4770.436126708984, "training_acc": 53.0, "val_loss": 1966.364860534668, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6539.488136291504, "training_acc": 53.0, "val_loss": 117.75798797607422, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1656.3311920166016, "training_acc": 59.0, "val_loss": 1351.1427879333496, "val_acc": 48.0}
{"epoch": 20, "training_loss": 4580.352920532227, "training_acc": 47.0, "val_loss": 728.152322769165, "val_acc": 52.0}
{"epoch": 21, "training_loss": 2769.251251220703, "training_acc": 53.0, "val_loss": 811.651611328125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2060.5880165100098, "training_acc": 51.0, "val_loss": 423.94933700561523, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1490.6601734161377, "training_acc": 53.0, "val_loss": 532.3331356048584, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1080.9295349121094, "training_acc": 58.0, "val_loss": 150.3609538078308, "val_acc": 48.0}
{"epoch": 25, "training_loss": 649.7961540222168, "training_acc": 63.0, "val_loss": 529.4257640838623, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1186.6322078704834, "training_acc": 54.0, "val_loss": 150.32583475112915, "val_acc": 32.0}
{"epoch": 27, "training_loss": 900.0374183654785, "training_acc": 52.0, "val_loss": 158.66448879241943, "val_acc": 60.0}
{"epoch": 28, "training_loss": 358.2611789703369, "training_acc": 63.0, "val_loss": 115.14779329299927, "val_acc": 44.0}
{"epoch": 29, "training_loss": 379.3855743408203, "training_acc": 66.0, "val_loss": 337.61253356933594, "val_acc": 56.0}
{"epoch": 30, "training_loss": 1055.145076751709, "training_acc": 53.0, "val_loss": 119.95275020599365, "val_acc": 64.0}
{"epoch": 31, "training_loss": 369.45263290405273, "training_acc": 71.0, "val_loss": 81.76013827323914, "val_acc": 56.0}
{"epoch": 32, "training_loss": 372.92435455322266, "training_acc": 66.0, "val_loss": 382.535457611084, "val_acc": 52.0}
{"epoch": 33, "training_loss": 925.6037712097168, "training_acc": 57.0, "val_loss": 676.3471126556396, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2684.4074211120605, "training_acc": 47.0, "val_loss": 394.907808303833, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1137.3961372375488, "training_acc": 53.0, "val_loss": 310.56792736053467, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1276.4479751586914, "training_acc": 49.0, "val_loss": 667.8531169891357, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1951.102294921875, "training_acc": 53.0, "val_loss": 100.43824911117554, "val_acc": 52.0}
{"epoch": 38, "training_loss": 918.2975311279297, "training_acc": 49.0, "val_loss": 585.1687908172607, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1820.6487197875977, "training_acc": 53.0, "val_loss": 183.4940791130066, "val_acc": 48.0}
{"epoch": 40, "training_loss": 929.6466960906982, "training_acc": 49.0, "val_loss": 659.3300819396973, "val_acc": 52.0}
{"epoch": 41, "training_loss": 2215.4826736450195, "training_acc": 53.0, "val_loss": 62.936365604400635, "val_acc": 56.0}
{"epoch": 42, "training_loss": 540.7825469970703, "training_acc": 58.0, "val_loss": 426.8509864807129, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1324.9593505859375, "training_acc": 54.0, "val_loss": 503.86314392089844, "val_acc": 48.0}
{"epoch": 44, "training_loss": 1755.4658241271973, "training_acc": 46.0, "val_loss": 347.43545055389404, "val_acc": 52.0}
{"epoch": 45, "training_loss": 1054.2531700134277, "training_acc": 55.0, "val_loss": 354.7159433364868, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1084.1539759635925, "training_acc": 57.0, "val_loss": 349.8936176300049, "val_acc": 52.0}
{"epoch": 47, "training_loss": 883.8377571105957, "training_acc": 56.0, "val_loss": 123.92845153808594, "val_acc": 48.0}
{"epoch": 48, "training_loss": 642.4432373046875, "training_acc": 59.0, "val_loss": 247.20616340637207, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1218.97265625, "training_acc": 51.0, "val_loss": 126.93392038345337, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1075.6044311523438, "training_acc": 60.0, "val_loss": 736.3658428192139, "val_acc": 52.0}
{"epoch": 51, "training_loss": 1641.7181787490845, "training_acc": 59.0, "val_loss": 844.6196556091309, "val_acc": 48.0}
{"epoch": 52, "training_loss": 3358.2668533325195, "training_acc": 47.0, "val_loss": 195.5178141593933, "val_acc": 56.0}
{"epoch": 53, "training_loss": 969.7562942504883, "training_acc": 63.0, "val_loss": 121.97843790054321, "val_acc": 64.0}
{"epoch": 54, "training_loss": 898.1476974487305, "training_acc": 62.0, "val_loss": 170.35222053527832, "val_acc": 52.0}
{"epoch": 55, "training_loss": 958.7833557128906, "training_acc": 62.0, "val_loss": 605.8653831481934, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1754.9665412902832, "training_acc": 44.0, "val_loss": 64.15476202964783, "val_acc": 56.0}
{"epoch": 57, "training_loss": 562.5005531311035, "training_acc": 70.0, "val_loss": 70.87467908859253, "val_acc": 56.0}
{"epoch": 58, "training_loss": 916.2860488891602, "training_acc": 64.0, "val_loss": 110.67012548446655, "val_acc": 68.0}
{"epoch": 59, "training_loss": 470.6986618041992, "training_acc": 68.0, "val_loss": 255.4631233215332, "val_acc": 48.0}
{"epoch": 60, "training_loss": 913.6725444793701, "training_acc": 46.0, "val_loss": 254.96182441711426, "val_acc": 48.0}
