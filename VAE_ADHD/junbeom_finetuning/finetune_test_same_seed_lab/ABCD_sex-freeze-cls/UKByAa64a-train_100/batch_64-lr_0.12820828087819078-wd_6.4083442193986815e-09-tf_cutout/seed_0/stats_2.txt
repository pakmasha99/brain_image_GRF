"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 288.1149311065674, "training_acc": 47.0, "val_loss": 26.944950222969055, "val_acc": 40.0}
{"epoch": 1, "training_loss": 186.86383819580078, "training_acc": 54.0, "val_loss": 153.48201990127563, "val_acc": 52.0}
{"epoch": 2, "training_loss": 563.2818298339844, "training_acc": 53.0, "val_loss": 51.91287398338318, "val_acc": 52.0}
{"epoch": 3, "training_loss": 178.04155778884888, "training_acc": 57.0, "val_loss": 103.86019945144653, "val_acc": 48.0}
{"epoch": 4, "training_loss": 384.7838945388794, "training_acc": 47.0, "val_loss": 62.38758563995361, "val_acc": 48.0}
{"epoch": 5, "training_loss": 166.2425925731659, "training_acc": 51.0, "val_loss": 54.04486656188965, "val_acc": 52.0}
{"epoch": 6, "training_loss": 230.04829788208008, "training_acc": 53.0, "val_loss": 50.503647327423096, "val_acc": 52.0}
{"epoch": 7, "training_loss": 170.2494888305664, "training_acc": 49.0, "val_loss": 36.35796904563904, "val_acc": 48.0}
{"epoch": 8, "training_loss": 142.3249650001526, "training_acc": 48.0, "val_loss": 31.099453568458557, "val_acc": 48.0}
{"epoch": 9, "training_loss": 112.37422180175781, "training_acc": 44.0, "val_loss": 30.190056562423706, "val_acc": 52.0}
{"epoch": 10, "training_loss": 108.86669516563416, "training_acc": 53.0, "val_loss": 17.82134920358658, "val_acc": 52.0}
{"epoch": 11, "training_loss": 77.72426247596741, "training_acc": 52.0, "val_loss": 22.517898678779602, "val_acc": 48.0}
{"epoch": 12, "training_loss": 78.74661231040955, "training_acc": 52.0, "val_loss": 21.866172552108765, "val_acc": 52.0}
{"epoch": 13, "training_loss": 82.47544836997986, "training_acc": 53.0, "val_loss": 17.035704851150513, "val_acc": 52.0}
{"epoch": 14, "training_loss": 75.66735816001892, "training_acc": 56.0, "val_loss": 19.357337057590485, "val_acc": 40.0}
{"epoch": 15, "training_loss": 73.6543436050415, "training_acc": 49.0, "val_loss": 24.04211014509201, "val_acc": 52.0}
{"epoch": 16, "training_loss": 86.41758012771606, "training_acc": 53.0, "val_loss": 16.770511865615845, "val_acc": 56.0}
{"epoch": 17, "training_loss": 75.6317868232727, "training_acc": 58.0, "val_loss": 17.83670336008072, "val_acc": 60.0}
{"epoch": 18, "training_loss": 68.29267001152039, "training_acc": 54.0, "val_loss": 23.17657768726349, "val_acc": 52.0}
{"epoch": 19, "training_loss": 79.51793050765991, "training_acc": 53.0, "val_loss": 17.311546206474304, "val_acc": 60.0}
{"epoch": 20, "training_loss": 70.95724129676819, "training_acc": 53.0, "val_loss": 18.276092410087585, "val_acc": 64.0}
{"epoch": 21, "training_loss": 69.40397667884827, "training_acc": 55.0, "val_loss": 20.73894441127777, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72.7417664527893, "training_acc": 52.0, "val_loss": 18.18736344575882, "val_acc": 56.0}
{"epoch": 23, "training_loss": 70.99345755577087, "training_acc": 52.0, "val_loss": 17.506954073905945, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.78227353096008, "training_acc": 63.0, "val_loss": 18.890555202960968, "val_acc": 52.0}
{"epoch": 25, "training_loss": 77.92011260986328, "training_acc": 43.0, "val_loss": 18.217040598392487, "val_acc": 56.0}
{"epoch": 26, "training_loss": 65.09335279464722, "training_acc": 60.0, "val_loss": 21.916314959526062, "val_acc": 52.0}
{"epoch": 27, "training_loss": 77.6424560546875, "training_acc": 53.0, "val_loss": 17.02434867620468, "val_acc": 60.0}
{"epoch": 28, "training_loss": 66.09440922737122, "training_acc": 60.0, "val_loss": 17.28438287973404, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.41026043891907, "training_acc": 64.0, "val_loss": 20.66013216972351, "val_acc": 52.0}
{"epoch": 30, "training_loss": 76.75223112106323, "training_acc": 54.0, "val_loss": 17.215172946453094, "val_acc": 60.0}
{"epoch": 31, "training_loss": 70.70132827758789, "training_acc": 52.0, "val_loss": 17.201296985149384, "val_acc": 52.0}
{"epoch": 32, "training_loss": 63.462997913360596, "training_acc": 64.0, "val_loss": 20.39996236562729, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.02163982391357, "training_acc": 56.0, "val_loss": 18.059399724006653, "val_acc": 60.0}
{"epoch": 34, "training_loss": 70.44978308677673, "training_acc": 54.0, "val_loss": 21.271559596061707, "val_acc": 52.0}
{"epoch": 35, "training_loss": 74.38745188713074, "training_acc": 53.0, "val_loss": 17.43602454662323, "val_acc": 60.0}
