"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 313.68401527404785, "training_acc": 46.0, "val_loss": 56.37041926383972, "val_acc": 52.0}
{"epoch": 1, "training_loss": 273.90088653564453, "training_acc": 53.0, "val_loss": 144.24139261245728, "val_acc": 48.0}
{"epoch": 2, "training_loss": 540.0324649810791, "training_acc": 47.0, "val_loss": 37.92935013771057, "val_acc": 48.0}
{"epoch": 3, "training_loss": 187.82845211029053, "training_acc": 51.0, "val_loss": 108.7189793586731, "val_acc": 52.0}
{"epoch": 4, "training_loss": 413.15187644958496, "training_acc": 53.0, "val_loss": 95.31733393669128, "val_acc": 52.0}
{"epoch": 5, "training_loss": 283.5159101486206, "training_acc": 53.0, "val_loss": 23.430217802524567, "val_acc": 48.0}
{"epoch": 6, "training_loss": 182.97908782958984, "training_acc": 47.0, "val_loss": 66.91115498542786, "val_acc": 48.0}
{"epoch": 7, "training_loss": 242.95457315444946, "training_acc": 47.0, "val_loss": 18.45790445804596, "val_acc": 52.0}
{"epoch": 8, "training_loss": 87.22482013702393, "training_acc": 53.0, "val_loss": 60.798341035842896, "val_acc": 52.0}
{"epoch": 9, "training_loss": 213.29109382629395, "training_acc": 53.0, "val_loss": 28.856471180915833, "val_acc": 52.0}
{"epoch": 10, "training_loss": 104.22631192207336, "training_acc": 47.0, "val_loss": 38.34643363952637, "val_acc": 48.0}
{"epoch": 11, "training_loss": 148.46780729293823, "training_acc": 47.0, "val_loss": 17.973892390727997, "val_acc": 52.0}
{"epoch": 12, "training_loss": 79.10707592964172, "training_acc": 49.0, "val_loss": 33.01697373390198, "val_acc": 52.0}
{"epoch": 13, "training_loss": 113.8087830543518, "training_acc": 53.0, "val_loss": 17.23158210515976, "val_acc": 60.0}
{"epoch": 14, "training_loss": 88.75423622131348, "training_acc": 54.0, "val_loss": 27.76075303554535, "val_acc": 48.0}
{"epoch": 15, "training_loss": 93.47258043289185, "training_acc": 50.0, "val_loss": 24.731740355491638, "val_acc": 52.0}
{"epoch": 16, "training_loss": 96.77895832061768, "training_acc": 53.0, "val_loss": 24.479009211063385, "val_acc": 52.0}
{"epoch": 17, "training_loss": 80.35374808311462, "training_acc": 57.0, "val_loss": 23.464706540107727, "val_acc": 48.0}
{"epoch": 18, "training_loss": 101.93071031570435, "training_acc": 47.0, "val_loss": 17.45159476995468, "val_acc": 52.0}
{"epoch": 19, "training_loss": 83.7237000465393, "training_acc": 56.0, "val_loss": 30.71194887161255, "val_acc": 52.0}
{"epoch": 20, "training_loss": 87.09900331497192, "training_acc": 56.0, "val_loss": 20.13419270515442, "val_acc": 48.0}
{"epoch": 21, "training_loss": 91.80383253097534, "training_acc": 47.0, "val_loss": 20.44816166162491, "val_acc": 48.0}
{"epoch": 22, "training_loss": 77.12007427215576, "training_acc": 51.0, "val_loss": 28.152477741241455, "val_acc": 52.0}
{"epoch": 23, "training_loss": 95.60251307487488, "training_acc": 53.0, "val_loss": 17.987540364265442, "val_acc": 52.0}
{"epoch": 24, "training_loss": 73.92154693603516, "training_acc": 54.0, "val_loss": 23.442329466342926, "val_acc": 48.0}
{"epoch": 25, "training_loss": 80.39518737792969, "training_acc": 51.0, "val_loss": 22.075437009334564, "val_acc": 52.0}
{"epoch": 26, "training_loss": 82.26841759681702, "training_acc": 53.0, "val_loss": 20.23741900920868, "val_acc": 52.0}
{"epoch": 27, "training_loss": 65.46844959259033, "training_acc": 64.0, "val_loss": 20.788799226284027, "val_acc": 44.0}
{"epoch": 28, "training_loss": 79.40055298805237, "training_acc": 49.0, "val_loss": 17.958568036556244, "val_acc": 56.0}
{"epoch": 29, "training_loss": 63.81219005584717, "training_acc": 61.0, "val_loss": 21.362370252609253, "val_acc": 52.0}
{"epoch": 30, "training_loss": 75.10958576202393, "training_acc": 52.0, "val_loss": 17.687660455703735, "val_acc": 64.0}
{"epoch": 31, "training_loss": 68.63137674331665, "training_acc": 59.0, "val_loss": 17.530131340026855, "val_acc": 56.0}
{"epoch": 32, "training_loss": 68.6562569141388, "training_acc": 55.0, "val_loss": 19.386789202690125, "val_acc": 52.0}
