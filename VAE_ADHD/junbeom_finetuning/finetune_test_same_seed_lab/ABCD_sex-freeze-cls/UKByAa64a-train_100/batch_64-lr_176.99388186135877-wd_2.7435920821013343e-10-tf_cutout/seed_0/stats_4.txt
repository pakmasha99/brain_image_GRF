"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 318003.04081726074, "training_acc": 51.0, "val_loss": 59622.625732421875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 351071.14453125, "training_acc": 55.0, "val_loss": 223171.337890625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 846900.892578125, "training_acc": 47.0, "val_loss": 67532.33642578125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 251759.0751953125, "training_acc": 53.0, "val_loss": 140709.77783203125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 558049.83203125, "training_acc": 53.0, "val_loss": 125456.62841796875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 380511.5634765625, "training_acc": 53.0, "val_loss": 37343.572998046875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 246571.740234375, "training_acc": 47.0, "val_loss": 78827.60620117188, "val_acc": 48.0}
{"epoch": 7, "training_loss": 261178.98510742188, "training_acc": 47.0, "val_loss": 43634.771728515625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 201952.1611328125, "training_acc": 53.0, "val_loss": 72783.03833007812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 229329.98291015625, "training_acc": 53.0, "val_loss": 17159.535217285156, "val_acc": 48.0}
{"epoch": 10, "training_loss": 95982.7392578125, "training_acc": 48.0, "val_loss": 20030.860900878906, "val_acc": 48.0}
{"epoch": 11, "training_loss": 93330.31665039062, "training_acc": 48.0, "val_loss": 39512.91198730469, "val_acc": 52.0}
{"epoch": 12, "training_loss": 122169.07788085938, "training_acc": 52.0, "val_loss": 15164.494323730469, "val_acc": 48.0}
{"epoch": 13, "training_loss": 89284.6689453125, "training_acc": 49.0, "val_loss": 8060.639190673828, "val_acc": 44.0}
{"epoch": 14, "training_loss": 38106.199951171875, "training_acc": 61.0, "val_loss": 35532.21435546875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 101676.75439453125, "training_acc": 53.0, "val_loss": 26073.080444335938, "val_acc": 48.0}
{"epoch": 16, "training_loss": 111572.5322265625, "training_acc": 48.0, "val_loss": 13076.632690429688, "val_acc": 48.0}
{"epoch": 17, "training_loss": 61730.471923828125, "training_acc": 57.0, "val_loss": 36450.885009765625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 104290.12097167969, "training_acc": 57.0, "val_loss": 20057.269287109375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 90000.01611328125, "training_acc": 49.0, "val_loss": 5508.974456787109, "val_acc": 44.0}
{"epoch": 20, "training_loss": 48046.8515625, "training_acc": 57.0, "val_loss": 23133.416748046875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67468.64123535156, "training_acc": 51.0, "val_loss": 18199.224853515625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 56668.18054199219, "training_acc": 53.0, "val_loss": 10164.545440673828, "val_acc": 48.0}
{"epoch": 23, "training_loss": 29133.85675048828, "training_acc": 62.0, "val_loss": 4775.297927856445, "val_acc": 52.0}
{"epoch": 24, "training_loss": 18464.62109375, "training_acc": 60.0, "val_loss": 6425.738525390625, "val_acc": 56.0}
{"epoch": 25, "training_loss": 24996.69140625, "training_acc": 56.0, "val_loss": 6259.499740600586, "val_acc": 44.0}
{"epoch": 26, "training_loss": 18115.112426757812, "training_acc": 66.0, "val_loss": 8559.473419189453, "val_acc": 52.0}
{"epoch": 27, "training_loss": 28335.76611328125, "training_acc": 62.0, "val_loss": 1782.840347290039, "val_acc": 60.0}
{"epoch": 28, "training_loss": 22205.536499023438, "training_acc": 62.0, "val_loss": 5664.513397216797, "val_acc": 44.0}
{"epoch": 29, "training_loss": 17793.34439086914, "training_acc": 61.0, "val_loss": 1700.9716033935547, "val_acc": 52.0}
{"epoch": 30, "training_loss": 11394.773406982422, "training_acc": 63.0, "val_loss": 8591.065979003906, "val_acc": 48.0}
{"epoch": 31, "training_loss": 30858.585571289062, "training_acc": 53.0, "val_loss": 1842.1606063842773, "val_acc": 64.0}
{"epoch": 32, "training_loss": 11439.037292480469, "training_acc": 64.0, "val_loss": 21472.027587890625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 74713.24291992188, "training_acc": 53.0, "val_loss": 15603.517150878906, "val_acc": 48.0}
{"epoch": 34, "training_loss": 60490.313720703125, "training_acc": 47.0, "val_loss": 14743.760681152344, "val_acc": 52.0}
{"epoch": 35, "training_loss": 43649.709228515625, "training_acc": 58.0, "val_loss": 3493.896484375, "val_acc": 64.0}
{"epoch": 36, "training_loss": 21886.092163085938, "training_acc": 57.0, "val_loss": 11293.245697021484, "val_acc": 52.0}
{"epoch": 37, "training_loss": 29892.933502197266, "training_acc": 53.0, "val_loss": 2699.622917175293, "val_acc": 60.0}
{"epoch": 38, "training_loss": 13893.477172851562, "training_acc": 64.0, "val_loss": 18955.035400390625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 59031.7001953125, "training_acc": 53.0, "val_loss": 20127.105712890625, "val_acc": 48.0}
{"epoch": 40, "training_loss": 67140.49462890625, "training_acc": 48.0, "val_loss": 13149.734497070312, "val_acc": 52.0}
{"epoch": 41, "training_loss": 45178.640869140625, "training_acc": 54.0, "val_loss": 16827.639770507812, "val_acc": 48.0}
{"epoch": 42, "training_loss": 51424.51934814453, "training_acc": 48.0, "val_loss": 16954.603576660156, "val_acc": 52.0}
{"epoch": 43, "training_loss": 62630.2509765625, "training_acc": 55.0, "val_loss": 15943.171691894531, "val_acc": 48.0}
{"epoch": 44, "training_loss": 54081.09411621094, "training_acc": 47.0, "val_loss": 9534.434509277344, "val_acc": 52.0}
{"epoch": 45, "training_loss": 27011.26287841797, "training_acc": 56.0, "val_loss": 11810.29281616211, "val_acc": 48.0}
{"epoch": 46, "training_loss": 24954.850524902344, "training_acc": 54.0, "val_loss": 9357.498931884766, "val_acc": 52.0}
{"epoch": 47, "training_loss": 37190.200927734375, "training_acc": 50.0, "val_loss": 5933.716583251953, "val_acc": 52.0}
{"epoch": 48, "training_loss": 19248.024169921875, "training_acc": 68.0, "val_loss": 3388.9404296875, "val_acc": 60.0}
