"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 405722.9112625122, "training_acc": 45.0, "val_loss": 96511.4990234375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 422509.900390625, "training_acc": 49.0, "val_loss": 163976.89208984375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 595952.5625, "training_acc": 47.0, "val_loss": 16474.644470214844, "val_acc": 48.0}
{"epoch": 3, "training_loss": 226136.400390625, "training_acc": 45.0, "val_loss": 181202.40478515625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 681905.119140625, "training_acc": 53.0, "val_loss": 164047.18017578125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 515677.998046875, "training_acc": 53.0, "val_loss": 14573.185729980469, "val_acc": 52.0}
{"epoch": 6, "training_loss": 154389.19140625, "training_acc": 49.0, "val_loss": 154356.6650390625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 638803.181640625, "training_acc": 47.0, "val_loss": 135798.79150390625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 459660.7265625, "training_acc": 47.0, "val_loss": 15649.200439453125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 103881.482421875, "training_acc": 49.0, "val_loss": 101695.20263671875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 352482.345703125, "training_acc": 53.0, "val_loss": 66044.45190429688, "val_acc": 52.0}
{"epoch": 11, "training_loss": 134377.1182861328, "training_acc": 56.0, "val_loss": 66025.44555664062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 313147.673828125, "training_acc": 47.0, "val_loss": 98758.84399414062, "val_acc": 48.0}
{"epoch": 13, "training_loss": 348232.6650390625, "training_acc": 47.0, "val_loss": 5145.135116577148, "val_acc": 44.0}
{"epoch": 14, "training_loss": 98863.5595703125, "training_acc": 56.0, "val_loss": 114149.15771484375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 429923.109375, "training_acc": 53.0, "val_loss": 108765.78369140625, "val_acc": 52.0}
{"epoch": 16, "training_loss": 334555.01611328125, "training_acc": 53.0, "val_loss": 5333.792877197266, "val_acc": 48.0}
{"epoch": 17, "training_loss": 75941.80322265625, "training_acc": 65.0, "val_loss": 66663.48266601562, "val_acc": 48.0}
{"epoch": 18, "training_loss": 253008.8388671875, "training_acc": 47.0, "val_loss": 5437.903213500977, "val_acc": 40.0}
{"epoch": 19, "training_loss": 74887.1181640625, "training_acc": 54.0, "val_loss": 75946.93603515625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 262654.1103515625, "training_acc": 53.0, "val_loss": 37974.1943359375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 94613.54028320312, "training_acc": 55.0, "val_loss": 40815.93017578125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 152922.09228515625, "training_acc": 47.0, "val_loss": 13828.425598144531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 44091.62646484375, "training_acc": 59.0, "val_loss": 19517.710876464844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 71964.79345703125, "training_acc": 47.0, "val_loss": 21377.01873779297, "val_acc": 48.0}
{"epoch": 25, "training_loss": 66686.82745361328, "training_acc": 52.0, "val_loss": 20683.123779296875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 41258.56658935547, "training_acc": 51.0, "val_loss": 13319.290161132812, "val_acc": 48.0}
{"epoch": 27, "training_loss": 48247.43524169922, "training_acc": 48.0, "val_loss": 11817.121124267578, "val_acc": 52.0}
{"epoch": 28, "training_loss": 35183.81604003906, "training_acc": 48.0, "val_loss": 9180.640411376953, "val_acc": 52.0}
{"epoch": 29, "training_loss": 19061.915893554688, "training_acc": 64.0, "val_loss": 10870.1904296875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 34243.567291259766, "training_acc": 53.0, "val_loss": 23379.37469482422, "val_acc": 52.0}
{"epoch": 31, "training_loss": 59236.92858886719, "training_acc": 53.0, "val_loss": 16931.99920654297, "val_acc": 48.0}
{"epoch": 32, "training_loss": 65092.200439453125, "training_acc": 46.0, "val_loss": 17747.879028320312, "val_acc": 52.0}
