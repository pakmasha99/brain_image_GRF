"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 290954.41929626465, "training_acc": 55.0, "val_loss": 83369.18334960938, "val_acc": 52.0}
{"epoch": 1, "training_loss": 491902.171875, "training_acc": 41.0, "val_loss": 157800.47607421875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 549615.25, "training_acc": 47.0, "val_loss": 8039.096832275391, "val_acc": 56.0}
{"epoch": 3, "training_loss": 103621.064453125, "training_acc": 51.0, "val_loss": 73779.4677734375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 224556.2197265625, "training_acc": 53.0, "val_loss": 28987.808227539062, "val_acc": 48.0}
{"epoch": 5, "training_loss": 167274.921875, "training_acc": 47.0, "val_loss": 25703.176879882812, "val_acc": 48.0}
{"epoch": 6, "training_loss": 121276.6396484375, "training_acc": 47.0, "val_loss": 53021.59423828125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 177744.47021484375, "training_acc": 53.0, "val_loss": 5451.530075073242, "val_acc": 56.0}
{"epoch": 8, "training_loss": 53812.375, "training_acc": 50.0, "val_loss": 7547.557067871094, "val_acc": 44.0}
{"epoch": 9, "training_loss": 60565.65283203125, "training_acc": 54.0, "val_loss": 39673.56872558594, "val_acc": 52.0}
{"epoch": 10, "training_loss": 118244.2421875, "training_acc": 55.0, "val_loss": 27114.02587890625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 110678.9130859375, "training_acc": 47.0, "val_loss": 6269.950103759766, "val_acc": 56.0}
{"epoch": 12, "training_loss": 56467.2451171875, "training_acc": 55.0, "val_loss": 42793.00537109375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 126448.37182617188, "training_acc": 53.0, "val_loss": 20860.89630126953, "val_acc": 48.0}
{"epoch": 14, "training_loss": 94734.376953125, "training_acc": 49.0, "val_loss": 8880.382537841797, "val_acc": 40.0}
{"epoch": 15, "training_loss": 52906.17919921875, "training_acc": 56.0, "val_loss": 49009.16748046875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 164909.28857421875, "training_acc": 53.0, "val_loss": 4839.713287353516, "val_acc": 60.0}
{"epoch": 17, "training_loss": 63275.54638671875, "training_acc": 55.0, "val_loss": 40795.220947265625, "val_acc": 48.0}
{"epoch": 18, "training_loss": 120836.86010742188, "training_acc": 47.0, "val_loss": 38602.09655761719, "val_acc": 52.0}
{"epoch": 19, "training_loss": 175374.3115234375, "training_acc": 53.0, "val_loss": 49709.64660644531, "val_acc": 52.0}
{"epoch": 20, "training_loss": 134543.63989257812, "training_acc": 54.0, "val_loss": 43485.50720214844, "val_acc": 48.0}
{"epoch": 21, "training_loss": 203540.6923828125, "training_acc": 47.0, "val_loss": 56904.376220703125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 161459.27270507812, "training_acc": 49.0, "val_loss": 44173.80676269531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 210814.1171875, "training_acc": 53.0, "val_loss": 74263.4521484375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 235999.0947265625, "training_acc": 53.0, "val_loss": 4934.8968505859375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 75380.71044921875, "training_acc": 55.0, "val_loss": 46228.50341796875, "val_acc": 48.0}
{"epoch": 26, "training_loss": 155106.00073242188, "training_acc": 47.0, "val_loss": 32851.678466796875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 132556.10009765625, "training_acc": 53.0, "val_loss": 44808.123779296875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 108085.25451660156, "training_acc": 54.0, "val_loss": 40236.1083984375, "val_acc": 48.0}
{"epoch": 29, "training_loss": 197133.9951171875, "training_acc": 47.0, "val_loss": 46388.43688964844, "val_acc": 48.0}
{"epoch": 30, "training_loss": 134988.46990966797, "training_acc": 52.0, "val_loss": 40880.46875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 155343.0029296875, "training_acc": 53.0, "val_loss": 45784.83581542969, "val_acc": 52.0}
{"epoch": 32, "training_loss": 109646.60632324219, "training_acc": 56.0, "val_loss": 32173.956298828125, "val_acc": 48.0}
{"epoch": 33, "training_loss": 156472.2353515625, "training_acc": 47.0, "val_loss": 20531.1767578125, "val_acc": 48.0}
{"epoch": 34, "training_loss": 109473.76293945312, "training_acc": 42.0, "val_loss": 42814.75830078125, "val_acc": 52.0}
{"epoch": 35, "training_loss": 122308.2744140625, "training_acc": 53.0, "val_loss": 6715.8538818359375, "val_acc": 56.0}
