"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 371776.28410720825, "training_acc": 46.0, "val_loss": 77701.3427734375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 377307.533203125, "training_acc": 53.0, "val_loss": 201227.57568359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 757321.724609375, "training_acc": 47.0, "val_loss": 55780.0048828125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 263891.2001953125, "training_acc": 51.0, "val_loss": 146959.04541015625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 558339.404296875, "training_acc": 53.0, "val_loss": 131135.986328125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 389201.80078125, "training_acc": 53.0, "val_loss": 22784.732055664062, "val_acc": 48.0}
{"epoch": 6, "training_loss": 210004.03515625, "training_acc": 47.0, "val_loss": 67166.93725585938, "val_acc": 48.0}
{"epoch": 7, "training_loss": 227668.705078125, "training_acc": 47.0, "val_loss": 48669.00939941406, "val_acc": 52.0}
{"epoch": 8, "training_loss": 189773.30712890625, "training_acc": 53.0, "val_loss": 84389.8193359375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 274026.32763671875, "training_acc": 53.0, "val_loss": 10634.29183959961, "val_acc": 52.0}
{"epoch": 10, "training_loss": 109597.470703125, "training_acc": 49.0, "val_loss": 78465.04516601562, "val_acc": 48.0}
{"epoch": 11, "training_loss": 300638.6904296875, "training_acc": 47.0, "val_loss": 16644.483947753906, "val_acc": 48.0}
{"epoch": 12, "training_loss": 108927.919921875, "training_acc": 49.0, "val_loss": 82566.83959960938, "val_acc": 52.0}
{"epoch": 13, "training_loss": 317445.73046875, "training_acc": 53.0, "val_loss": 61897.39990234375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 166165.02795410156, "training_acc": 52.0, "val_loss": 60699.32861328125, "val_acc": 48.0}
{"epoch": 15, "training_loss": 295726.03515625, "training_acc": 47.0, "val_loss": 90280.09033203125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 304591.2509765625, "training_acc": 47.0, "val_loss": 8222.48306274414, "val_acc": 60.0}
{"epoch": 17, "training_loss": 75906.4658203125, "training_acc": 54.0, "val_loss": 51716.070556640625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 166354.67797851562, "training_acc": 53.0, "val_loss": 10896.180725097656, "val_acc": 48.0}
{"epoch": 19, "training_loss": 49457.585693359375, "training_acc": 51.0, "val_loss": 5310.166549682617, "val_acc": 56.0}
{"epoch": 20, "training_loss": 39834.288330078125, "training_acc": 57.0, "val_loss": 11837.744140625, "val_acc": 56.0}
{"epoch": 21, "training_loss": 40871.2880859375, "training_acc": 52.0, "val_loss": 17919.45037841797, "val_acc": 48.0}
{"epoch": 22, "training_loss": 55652.00427246094, "training_acc": 51.0, "val_loss": 25241.2109375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 54964.66955566406, "training_acc": 54.0, "val_loss": 23395.327758789062, "val_acc": 48.0}
{"epoch": 24, "training_loss": 97459.3349609375, "training_acc": 47.0, "val_loss": 6961.474609375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 37553.146484375, "training_acc": 62.0, "val_loss": 14517.056274414062, "val_acc": 56.0}
{"epoch": 26, "training_loss": 65353.319580078125, "training_acc": 44.0, "val_loss": 13585.157775878906, "val_acc": 48.0}
{"epoch": 27, "training_loss": 60452.914306640625, "training_acc": 52.0, "val_loss": 20490.65704345703, "val_acc": 52.0}
{"epoch": 28, "training_loss": 42867.35729980469, "training_acc": 57.0, "val_loss": 16042.919921875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 45741.16290283203, "training_acc": 58.0, "val_loss": 32732.33642578125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 110921.5595703125, "training_acc": 53.0, "val_loss": 14158.711242675781, "val_acc": 56.0}
{"epoch": 31, "training_loss": 71608.27587890625, "training_acc": 53.0, "val_loss": 34683.59375, "val_acc": 48.0}
{"epoch": 32, "training_loss": 103573.74737548828, "training_acc": 50.0, "val_loss": 38712.95166015625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 156066.0322265625, "training_acc": 53.0, "val_loss": 38301.48010253906, "val_acc": 52.0}
{"epoch": 34, "training_loss": 72289.32781982422, "training_acc": 59.0, "val_loss": 44385.302734375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 190069.2666015625, "training_acc": 47.0, "val_loss": 30684.0576171875, "val_acc": 48.0}
{"epoch": 36, "training_loss": 103884.91796875, "training_acc": 51.0, "val_loss": 39419.81506347656, "val_acc": 52.0}
{"epoch": 37, "training_loss": 115736.67211914062, "training_acc": 53.0, "val_loss": 4053.466796875, "val_acc": 40.0}
{"epoch": 38, "training_loss": 50083.065673828125, "training_acc": 61.0, "val_loss": 7588.836669921875, "val_acc": 40.0}
{"epoch": 39, "training_loss": 52605.396240234375, "training_acc": 52.0, "val_loss": 31738.967895507812, "val_acc": 52.0}
{"epoch": 40, "training_loss": 76478.97869873047, "training_acc": 57.0, "val_loss": 31748.031616210938, "val_acc": 48.0}
{"epoch": 41, "training_loss": 133888.0615234375, "training_acc": 47.0, "val_loss": 8389.325714111328, "val_acc": 40.0}
{"epoch": 42, "training_loss": 56971.8671875, "training_acc": 59.0, "val_loss": 56549.42626953125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 187610.5810546875, "training_acc": 53.0, "val_loss": 11850.73471069336, "val_acc": 56.0}
{"epoch": 44, "training_loss": 77183.482421875, "training_acc": 59.0, "val_loss": 73733.1298828125, "val_acc": 48.0}
{"epoch": 45, "training_loss": 277783.478515625, "training_acc": 47.0, "val_loss": 23551.42364501953, "val_acc": 48.0}
{"epoch": 46, "training_loss": 138919.52978515625, "training_acc": 41.0, "val_loss": 74580.94482421875, "val_acc": 52.0}
{"epoch": 47, "training_loss": 266276.5341796875, "training_acc": 53.0, "val_loss": 47431.88171386719, "val_acc": 52.0}
{"epoch": 48, "training_loss": 131357.15551757812, "training_acc": 54.0, "val_loss": 43045.71838378906, "val_acc": 48.0}
{"epoch": 49, "training_loss": 151880.4697265625, "training_acc": 48.0, "val_loss": 17661.846923828125, "val_acc": 52.0}
{"epoch": 50, "training_loss": 61743.399658203125, "training_acc": 57.0, "val_loss": 50041.546630859375, "val_acc": 52.0}
{"epoch": 51, "training_loss": 177019.95068359375, "training_acc": 53.0, "val_loss": 10179.546356201172, "val_acc": 64.0}
{"epoch": 52, "training_loss": 78402.42041015625, "training_acc": 57.0, "val_loss": 50608.062744140625, "val_acc": 48.0}
{"epoch": 53, "training_loss": 151667.13720703125, "training_acc": 48.0, "val_loss": 15564.044189453125, "val_acc": 56.0}
{"epoch": 54, "training_loss": 94498.5185546875, "training_acc": 55.0, "val_loss": 29102.182006835938, "val_acc": 52.0}
{"epoch": 55, "training_loss": 81781.99114990234, "training_acc": 59.0, "val_loss": 28127.91748046875, "val_acc": 48.0}
{"epoch": 56, "training_loss": 82030.56591796875, "training_acc": 48.0, "val_loss": 16747.72186279297, "val_acc": 52.0}
