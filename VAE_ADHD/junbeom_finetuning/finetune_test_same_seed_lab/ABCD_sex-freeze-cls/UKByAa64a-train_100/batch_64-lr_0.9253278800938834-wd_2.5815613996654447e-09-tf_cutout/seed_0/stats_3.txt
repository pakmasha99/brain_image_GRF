"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2169.6543731689453, "training_acc": 45.0, "val_loss": 485.4220390319824, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2012.1085891723633, "training_acc": 53.0, "val_loss": 934.1231346130371, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3405.5348892211914, "training_acc": 47.0, "val_loss": 179.17126417160034, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1281.7051467895508, "training_acc": 45.0, "val_loss": 794.6759700775146, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3114.7626190185547, "training_acc": 53.0, "val_loss": 630.0464153289795, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1925.8382148742676, "training_acc": 53.0, "val_loss": 262.5678300857544, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1410.692642211914, "training_acc": 47.0, "val_loss": 516.6781425476074, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1724.828296661377, "training_acc": 47.0, "val_loss": 35.65269410610199, "val_acc": 52.0}
{"epoch": 8, "training_loss": 473.1598930358887, "training_acc": 53.0, "val_loss": 210.14816761016846, "val_acc": 52.0}
{"epoch": 9, "training_loss": 645.9052286148071, "training_acc": 53.0, "val_loss": 240.17295837402344, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1061.4116134643555, "training_acc": 45.0, "val_loss": 249.5359182357788, "val_acc": 48.0}
{"epoch": 11, "training_loss": 697.4568824768066, "training_acc": 51.0, "val_loss": 218.2624101638794, "val_acc": 52.0}
{"epoch": 12, "training_loss": 927.503776550293, "training_acc": 53.0, "val_loss": 178.6967158317566, "val_acc": 52.0}
{"epoch": 13, "training_loss": 646.8496131896973, "training_acc": 41.0, "val_loss": 108.16102027893066, "val_acc": 48.0}
{"epoch": 14, "training_loss": 267.94132900238037, "training_acc": 58.0, "val_loss": 161.85027360916138, "val_acc": 52.0}
{"epoch": 15, "training_loss": 472.14650535583496, "training_acc": 53.0, "val_loss": 34.011757373809814, "val_acc": 36.0}
{"epoch": 16, "training_loss": 156.38873529434204, "training_acc": 51.0, "val_loss": 64.62736129760742, "val_acc": 56.0}
{"epoch": 17, "training_loss": 127.86601877212524, "training_acc": 58.0, "val_loss": 35.314878821372986, "val_acc": 36.0}
{"epoch": 18, "training_loss": 117.59021782875061, "training_acc": 67.0, "val_loss": 63.61854076385498, "val_acc": 52.0}
{"epoch": 19, "training_loss": 145.43580865859985, "training_acc": 52.0, "val_loss": 59.938448667526245, "val_acc": 52.0}
{"epoch": 20, "training_loss": 104.37857246398926, "training_acc": 60.0, "val_loss": 40.300944447517395, "val_acc": 52.0}
{"epoch": 21, "training_loss": 162.823992729187, "training_acc": 54.0, "val_loss": 33.18387269973755, "val_acc": 52.0}
{"epoch": 22, "training_loss": 101.23672389984131, "training_acc": 63.0, "val_loss": 37.08726763725281, "val_acc": 52.0}
{"epoch": 23, "training_loss": 101.6684262752533, "training_acc": 56.0, "val_loss": 94.4464385509491, "val_acc": 48.0}
{"epoch": 24, "training_loss": 314.05072689056396, "training_acc": 47.0, "val_loss": 178.17095518112183, "val_acc": 52.0}
{"epoch": 25, "training_loss": 633.33713722229, "training_acc": 53.0, "val_loss": 111.69247627258301, "val_acc": 52.0}
{"epoch": 26, "training_loss": 367.9610233306885, "training_acc": 55.0, "val_loss": 203.9273977279663, "val_acc": 48.0}
{"epoch": 27, "training_loss": 687.4003219604492, "training_acc": 47.0, "val_loss": 192.29573011398315, "val_acc": 52.0}
{"epoch": 28, "training_loss": 627.2790927886963, "training_acc": 53.0, "val_loss": 232.5624942779541, "val_acc": 52.0}
{"epoch": 29, "training_loss": 507.3497176170349, "training_acc": 56.0, "val_loss": 127.58883237838745, "val_acc": 48.0}
{"epoch": 30, "training_loss": 579.2264614105225, "training_acc": 46.0, "val_loss": 123.74370098114014, "val_acc": 52.0}
{"epoch": 31, "training_loss": 385.4643669128418, "training_acc": 54.0, "val_loss": 87.57368922233582, "val_acc": 52.0}
{"epoch": 32, "training_loss": 262.4842948913574, "training_acc": 54.0, "val_loss": 95.53577303886414, "val_acc": 48.0}
{"epoch": 33, "training_loss": 290.94686222076416, "training_acc": 57.0, "val_loss": 133.9452028274536, "val_acc": 52.0}
{"epoch": 34, "training_loss": 253.56166100502014, "training_acc": 57.0, "val_loss": 81.15564584732056, "val_acc": 48.0}
{"epoch": 35, "training_loss": 296.5609726905823, "training_acc": 47.0, "val_loss": 164.70931768417358, "val_acc": 52.0}
{"epoch": 36, "training_loss": 519.3176460266113, "training_acc": 53.0, "val_loss": 67.97602772712708, "val_acc": 52.0}
{"epoch": 37, "training_loss": 335.73764991760254, "training_acc": 54.0, "val_loss": 185.15781164169312, "val_acc": 48.0}
{"epoch": 38, "training_loss": 539.0773010253906, "training_acc": 48.0, "val_loss": 235.1076364517212, "val_acc": 52.0}
{"epoch": 39, "training_loss": 952.2119941711426, "training_acc": 53.0, "val_loss": 298.81718158721924, "val_acc": 52.0}
{"epoch": 40, "training_loss": 720.4671783447266, "training_acc": 53.0, "val_loss": 210.34114360809326, "val_acc": 48.0}
