"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 38536.278133392334, "training_acc": 47.0, "val_loss": 9642.146301269531, "val_acc": 52.0}
{"epoch": 1, "training_loss": 43024.01965332031, "training_acc": 49.0, "val_loss": 16116.819763183594, "val_acc": 48.0}
{"epoch": 2, "training_loss": 58095.89892578125, "training_acc": 47.0, "val_loss": 570.7816123962402, "val_acc": 48.0}
{"epoch": 3, "training_loss": 17179.07958984375, "training_acc": 51.0, "val_loss": 18456.94122314453, "val_acc": 52.0}
{"epoch": 4, "training_loss": 72834.7197265625, "training_acc": 53.0, "val_loss": 16202.073669433594, "val_acc": 52.0}
{"epoch": 5, "training_loss": 53935.55432128906, "training_acc": 53.0, "val_loss": 487.6725196838379, "val_acc": 48.0}
{"epoch": 6, "training_loss": 21865.134643554688, "training_acc": 42.0, "val_loss": 17108.19091796875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 69146.21435546875, "training_acc": 47.0, "val_loss": 14758.668518066406, "val_acc": 48.0}
{"epoch": 8, "training_loss": 50542.36328125, "training_acc": 47.0, "val_loss": 321.0129737854004, "val_acc": 52.0}
{"epoch": 9, "training_loss": 12242.074096679688, "training_acc": 53.0, "val_loss": 9409.017181396484, "val_acc": 52.0}
{"epoch": 10, "training_loss": 36130.279052734375, "training_acc": 53.0, "val_loss": 5488.357162475586, "val_acc": 52.0}
{"epoch": 11, "training_loss": 15273.011047363281, "training_acc": 49.0, "val_loss": 4558.428573608398, "val_acc": 48.0}
{"epoch": 12, "training_loss": 17198.26953125, "training_acc": 47.0, "val_loss": 1341.4142608642578, "val_acc": 48.0}
{"epoch": 13, "training_loss": 12624.024658203125, "training_acc": 38.0, "val_loss": 6338.0828857421875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 23132.01171875, "training_acc": 53.0, "val_loss": 1601.6115188598633, "val_acc": 52.0}
{"epoch": 15, "training_loss": 11514.607177734375, "training_acc": 48.0, "val_loss": 6908.922576904297, "val_acc": 48.0}
{"epoch": 16, "training_loss": 24745.594116210938, "training_acc": 47.0, "val_loss": 1645.5625534057617, "val_acc": 48.0}
{"epoch": 17, "training_loss": 6887.587493896484, "training_acc": 62.0, "val_loss": 7244.511413574219, "val_acc": 52.0}
{"epoch": 18, "training_loss": 26593.15985107422, "training_acc": 53.0, "val_loss": 5327.05078125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 13620.71369934082, "training_acc": 50.0, "val_loss": 5154.555511474609, "val_acc": 48.0}
{"epoch": 20, "training_loss": 24023.008422851562, "training_acc": 47.0, "val_loss": 7021.030426025391, "val_acc": 48.0}
{"epoch": 21, "training_loss": 22278.975952148438, "training_acc": 47.0, "val_loss": 2772.5101470947266, "val_acc": 52.0}
{"epoch": 22, "training_loss": 15134.684631347656, "training_acc": 54.0, "val_loss": 5444.926071166992, "val_acc": 52.0}
{"epoch": 23, "training_loss": 16432.56280517578, "training_acc": 53.0, "val_loss": 2660.319709777832, "val_acc": 48.0}
{"epoch": 24, "training_loss": 13012.670104980469, "training_acc": 48.0, "val_loss": 4183.795928955078, "val_acc": 48.0}
{"epoch": 25, "training_loss": 10960.930633544922, "training_acc": 53.0, "val_loss": 3363.589096069336, "val_acc": 52.0}
{"epoch": 26, "training_loss": 14114.619506835938, "training_acc": 53.0, "val_loss": 3206.109619140625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 10110.429153442383, "training_acc": 51.0, "val_loss": 3080.1870346069336, "val_acc": 48.0}
