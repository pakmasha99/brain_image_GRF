"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 37526.98918533325, "training_acc": 46.0, "val_loss": 7834.615325927734, "val_acc": 52.0}
{"epoch": 1, "training_loss": 38045.0087890625, "training_acc": 53.0, "val_loss": 20290.396118164062, "val_acc": 48.0}
{"epoch": 2, "training_loss": 76362.6669921875, "training_acc": 47.0, "val_loss": 5624.489974975586, "val_acc": 48.0}
{"epoch": 3, "training_loss": 26608.615600585938, "training_acc": 51.0, "val_loss": 14818.121337890625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 56298.793701171875, "training_acc": 53.0, "val_loss": 13222.566223144531, "val_acc": 52.0}
{"epoch": 5, "training_loss": 39243.900634765625, "training_acc": 53.0, "val_loss": 2297.653579711914, "val_acc": 48.0}
{"epoch": 6, "training_loss": 21175.65673828125, "training_acc": 47.0, "val_loss": 6772.786712646484, "val_acc": 48.0}
{"epoch": 7, "training_loss": 22956.478393554688, "training_acc": 47.0, "val_loss": 4907.225036621094, "val_acc": 52.0}
{"epoch": 8, "training_loss": 19135.103576660156, "training_acc": 53.0, "val_loss": 8509.003448486328, "val_acc": 52.0}
{"epoch": 9, "training_loss": 27630.45782470703, "training_acc": 53.0, "val_loss": 1072.0373153686523, "val_acc": 52.0}
{"epoch": 10, "training_loss": 11066.614013671875, "training_acc": 49.0, "val_loss": 7930.72509765625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 30399.73663330078, "training_acc": 47.0, "val_loss": 1713.0456924438477, "val_acc": 48.0}
{"epoch": 12, "training_loss": 11018.363525390625, "training_acc": 49.0, "val_loss": 8282.050323486328, "val_acc": 52.0}
{"epoch": 13, "training_loss": 31829.824462890625, "training_acc": 53.0, "val_loss": 6189.162063598633, "val_acc": 52.0}
{"epoch": 14, "training_loss": 16557.73960876465, "training_acc": 52.0, "val_loss": 6185.356903076172, "val_acc": 48.0}
{"epoch": 15, "training_loss": 30084.845458984375, "training_acc": 47.0, "val_loss": 9174.979400634766, "val_acc": 48.0}
{"epoch": 16, "training_loss": 31006.339233398438, "training_acc": 47.0, "val_loss": 770.2956199645996, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7735.887390136719, "training_acc": 56.0, "val_loss": 5539.240264892578, "val_acc": 52.0}
{"epoch": 18, "training_loss": 18113.733459472656, "training_acc": 53.0, "val_loss": 515.5592918395996, "val_acc": 44.0}
{"epoch": 19, "training_loss": 4195.059783935547, "training_acc": 58.0, "val_loss": 974.0018844604492, "val_acc": 48.0}
{"epoch": 20, "training_loss": 6935.951141357422, "training_acc": 47.0, "val_loss": 2922.781753540039, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6180.502197265625, "training_acc": 60.0, "val_loss": 3249.428939819336, "val_acc": 48.0}
{"epoch": 22, "training_loss": 14249.469909667969, "training_acc": 47.0, "val_loss": 749.6703147888184, "val_acc": 40.0}
{"epoch": 23, "training_loss": 8245.409912109375, "training_acc": 49.0, "val_loss": 6398.502349853516, "val_acc": 52.0}
{"epoch": 24, "training_loss": 20794.12615966797, "training_acc": 53.0, "val_loss": 2225.9878158569336, "val_acc": 52.0}
{"epoch": 25, "training_loss": 9875.102355957031, "training_acc": 51.0, "val_loss": 5481.797409057617, "val_acc": 48.0}
{"epoch": 26, "training_loss": 19987.01788330078, "training_acc": 47.0, "val_loss": 613.2116794586182, "val_acc": 52.0}
{"epoch": 27, "training_loss": 7905.036376953125, "training_acc": 51.0, "val_loss": 6827.565002441406, "val_acc": 52.0}
{"epoch": 28, "training_loss": 22377.71954345703, "training_acc": 53.0, "val_loss": 2255.5397033691406, "val_acc": 52.0}
{"epoch": 29, "training_loss": 12632.144836425781, "training_acc": 42.0, "val_loss": 6409.38720703125, "val_acc": 48.0}
{"epoch": 30, "training_loss": 24427.960876464844, "training_acc": 47.0, "val_loss": 916.0324096679688, "val_acc": 36.0}
{"epoch": 31, "training_loss": 7515.673156738281, "training_acc": 60.0, "val_loss": 7824.833679199219, "val_acc": 52.0}
{"epoch": 32, "training_loss": 27667.538208007812, "training_acc": 53.0, "val_loss": 5404.585647583008, "val_acc": 52.0}
{"epoch": 33, "training_loss": 11331.954330444336, "training_acc": 56.0, "val_loss": 4801.24397277832, "val_acc": 48.0}
{"epoch": 34, "training_loss": 22162.34783935547, "training_acc": 47.0, "val_loss": 5145.212936401367, "val_acc": 48.0}
{"epoch": 35, "training_loss": 16751.846466064453, "training_acc": 48.0, "val_loss": 4995.641326904297, "val_acc": 52.0}
{"epoch": 36, "training_loss": 19237.642211914062, "training_acc": 53.0, "val_loss": 7705.133819580078, "val_acc": 52.0}
{"epoch": 37, "training_loss": 20773.615295410156, "training_acc": 53.0, "val_loss": 657.5843334197998, "val_acc": 44.0}
