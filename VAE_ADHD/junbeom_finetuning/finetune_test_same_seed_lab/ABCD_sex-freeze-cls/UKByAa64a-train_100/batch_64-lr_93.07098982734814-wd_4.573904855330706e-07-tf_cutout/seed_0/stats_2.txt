"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 911926.2534942627, "training_acc": 54.0, "val_loss": 182429.6875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 906236.203125, "training_acc": 41.0, "val_loss": 274862.6708984375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1019138.06640625, "training_acc": 47.0, "val_loss": 43270.15380859375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 442302.56640625, "training_acc": 41.0, "val_loss": 272349.267578125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1069440.953125, "training_acc": 53.0, "val_loss": 226662.59765625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 742678.05859375, "training_acc": 53.0, "val_loss": 27231.463623046875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 213306.65625, "training_acc": 47.0, "val_loss": 90085.77880859375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 273122.19470214844, "training_acc": 47.0, "val_loss": 100387.09716796875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 454817.427734375, "training_acc": 53.0, "val_loss": 139779.1259765625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 470198.6728515625, "training_acc": 53.0, "val_loss": 18004.856872558594, "val_acc": 48.0}
{"epoch": 10, "training_loss": 119327.51416015625, "training_acc": 47.0, "val_loss": 24413.45977783203, "val_acc": 48.0}
{"epoch": 11, "training_loss": 122764.1435546875, "training_acc": 53.0, "val_loss": 73013.81225585938, "val_acc": 52.0}
{"epoch": 12, "training_loss": 248219.93212890625, "training_acc": 53.0, "val_loss": 27842.855834960938, "val_acc": 48.0}
{"epoch": 13, "training_loss": 124291.033203125, "training_acc": 47.0, "val_loss": 10797.100067138672, "val_acc": 52.0}
{"epoch": 14, "training_loss": 35061.03356933594, "training_acc": 53.0, "val_loss": 53163.897705078125, "val_acc": 48.0}
{"epoch": 15, "training_loss": 213749.7490234375, "training_acc": 47.0, "val_loss": 6210.903167724609, "val_acc": 52.0}
{"epoch": 16, "training_loss": 27069.329956054688, "training_acc": 53.0, "val_loss": 38030.621337890625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 139244.4931640625, "training_acc": 47.0, "val_loss": 38131.21032714844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 166805.580078125, "training_acc": 53.0, "val_loss": 17125.936889648438, "val_acc": 52.0}
{"epoch": 19, "training_loss": 180477.0166015625, "training_acc": 41.0, "val_loss": 82115.93627929688, "val_acc": 48.0}
{"epoch": 20, "training_loss": 268372.1240234375, "training_acc": 47.0, "val_loss": 49397.88818359375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 246134.2041015625, "training_acc": 53.0, "val_loss": 83655.69458007812, "val_acc": 52.0}
{"epoch": 22, "training_loss": 253876.0625, "training_acc": 53.0, "val_loss": 57872.662353515625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 302771.318359375, "training_acc": 47.0, "val_loss": 71018.46923828125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 201812.19140625, "training_acc": 47.0, "val_loss": 26045.73974609375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 79654.45922851562, "training_acc": 45.0, "val_loss": 23914.796447753906, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67586.22256469727, "training_acc": 53.0, "val_loss": 57998.9013671875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 242317.5908203125, "training_acc": 47.0, "val_loss": 9325.718688964844, "val_acc": 48.0}
{"epoch": 28, "training_loss": 114842.5302734375, "training_acc": 55.0, "val_loss": 123533.1787109375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 481263.810546875, "training_acc": 53.0, "val_loss": 71764.19067382812, "val_acc": 52.0}
{"epoch": 30, "training_loss": 216279.09057617188, "training_acc": 49.0, "val_loss": 52426.40380859375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 178203.46484375, "training_acc": 47.0, "val_loss": 43472.772216796875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 199597.103515625, "training_acc": 53.0, "val_loss": 39959.16442871094, "val_acc": 52.0}
{"epoch": 33, "training_loss": 164470.07421875, "training_acc": 45.0, "val_loss": 39665.0390625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 118447.30200195312, "training_acc": 47.0, "val_loss": 2442.8075790405273, "val_acc": 52.0}
{"epoch": 35, "training_loss": 78122.41162109375, "training_acc": 51.0, "val_loss": 44582.18688964844, "val_acc": 48.0}
{"epoch": 36, "training_loss": 127620.25305175781, "training_acc": 51.0, "val_loss": 17090.919494628906, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69672.88354492188, "training_acc": 53.0, "val_loss": 6672.2412109375, "val_acc": 48.0}
{"epoch": 38, "training_loss": 110048.568359375, "training_acc": 45.0, "val_loss": 66944.78149414062, "val_acc": 52.0}
{"epoch": 39, "training_loss": 209927.2412109375, "training_acc": 53.0, "val_loss": 48079.9560546875, "val_acc": 48.0}
{"epoch": 40, "training_loss": 235862.9853515625, "training_acc": 47.0, "val_loss": 36620.758056640625, "val_acc": 48.0}
{"epoch": 41, "training_loss": 168093.61865234375, "training_acc": 47.0, "val_loss": 73452.69165039062, "val_acc": 52.0}
{"epoch": 42, "training_loss": 258696.83203125, "training_acc": 53.0, "val_loss": 8600.822448730469, "val_acc": 48.0}
{"epoch": 43, "training_loss": 44109.531982421875, "training_acc": 47.0, "val_loss": 29430.615234375, "val_acc": 52.0}
{"epoch": 44, "training_loss": 109566.47021484375, "training_acc": 53.0, "val_loss": 24416.799926757812, "val_acc": 48.0}
{"epoch": 45, "training_loss": 94951.34350585938, "training_acc": 47.0, "val_loss": 35962.19787597656, "val_acc": 52.0}
{"epoch": 46, "training_loss": 152252.19384765625, "training_acc": 53.0, "val_loss": 5696.008682250977, "val_acc": 52.0}
{"epoch": 47, "training_loss": 128636.806640625, "training_acc": 51.0, "val_loss": 102349.31640625, "val_acc": 48.0}
{"epoch": 48, "training_loss": 369811.572265625, "training_acc": 47.0, "val_loss": 11388.578033447266, "val_acc": 52.0}
{"epoch": 49, "training_loss": 84248.56982421875, "training_acc": 53.0, "val_loss": 17092.225646972656, "val_acc": 52.0}
{"epoch": 50, "training_loss": 107039.64013671875, "training_acc": 53.0, "val_loss": 58307.501220703125, "val_acc": 48.0}
{"epoch": 51, "training_loss": 171843.68872070312, "training_acc": 47.0, "val_loss": 73699.609375, "val_acc": 52.0}
{"epoch": 52, "training_loss": 357139.90234375, "training_acc": 53.0, "val_loss": 95079.38842773438, "val_acc": 52.0}
{"epoch": 53, "training_loss": 280062.4462890625, "training_acc": 53.0, "val_loss": 68601.30615234375, "val_acc": 48.0}
