"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 355997.1095275879, "training_acc": 52.0, "val_loss": 118309.423828125, "val_acc": 44.0}
{"epoch": 1, "training_loss": 363376.5654296875, "training_acc": 48.0, "val_loss": 124429.296875, "val_acc": 56.0}
{"epoch": 2, "training_loss": 576593.08984375, "training_acc": 52.0, "val_loss": 52308.11767578125, "val_acc": 56.0}
{"epoch": 3, "training_loss": 297584.927734375, "training_acc": 54.0, "val_loss": 200116.27197265625, "val_acc": 44.0}
{"epoch": 4, "training_loss": 672079.94140625, "training_acc": 48.0, "val_loss": 16882.577514648438, "val_acc": 44.0}
{"epoch": 5, "training_loss": 312510.6015625, "training_acc": 44.0, "val_loss": 220732.8125, "val_acc": 56.0}
{"epoch": 6, "training_loss": 965108.67578125, "training_acc": 52.0, "val_loss": 169391.1376953125, "val_acc": 56.0}
{"epoch": 7, "training_loss": 589433.41796875, "training_acc": 52.0, "val_loss": 94500.79345703125, "val_acc": 44.0}
{"epoch": 8, "training_loss": 427972.712890625, "training_acc": 48.0, "val_loss": 182310.02197265625, "val_acc": 44.0}
{"epoch": 9, "training_loss": 595391.943359375, "training_acc": 48.0, "val_loss": 5386.185836791992, "val_acc": 44.0}
{"epoch": 10, "training_loss": 199966.9150390625, "training_acc": 52.0, "val_loss": 190860.58349609375, "val_acc": 56.0}
{"epoch": 11, "training_loss": 854028.19921875, "training_acc": 52.0, "val_loss": 167359.1552734375, "val_acc": 56.0}
{"epoch": 12, "training_loss": 596361.59375, "training_acc": 52.0, "val_loss": 37123.89831542969, "val_acc": 44.0}
{"epoch": 13, "training_loss": 237335.177734375, "training_acc": 48.0, "val_loss": 111822.119140625, "val_acc": 44.0}
{"epoch": 14, "training_loss": 323614.3359375, "training_acc": 48.0, "val_loss": 52467.39501953125, "val_acc": 56.0}
{"epoch": 15, "training_loss": 278187.5400390625, "training_acc": 52.0, "val_loss": 82167.0166015625, "val_acc": 56.0}
{"epoch": 16, "training_loss": 278922.61767578125, "training_acc": 52.0, "val_loss": 71467.49877929688, "val_acc": 44.0}
{"epoch": 17, "training_loss": 317205.783203125, "training_acc": 48.0, "val_loss": 89996.54541015625, "val_acc": 44.0}
{"epoch": 18, "training_loss": 218484.296875, "training_acc": 48.0, "val_loss": 96980.63354492188, "val_acc": 56.0}
{"epoch": 19, "training_loss": 503894.232421875, "training_acc": 52.0, "val_loss": 149600.30517578125, "val_acc": 56.0}
{"epoch": 20, "training_loss": 585944.962890625, "training_acc": 52.0, "val_loss": 26863.003540039062, "val_acc": 56.0}
{"epoch": 21, "training_loss": 248237.130859375, "training_acc": 46.0, "val_loss": 183193.02978515625, "val_acc": 44.0}
{"epoch": 22, "training_loss": 669981.93359375, "training_acc": 48.0, "val_loss": 127298.4375, "val_acc": 44.0}
{"epoch": 23, "training_loss": 332639.0098876953, "training_acc": 48.0, "val_loss": 105204.4677734375, "val_acc": 56.0}
{"epoch": 24, "training_loss": 574377.5078125, "training_acc": 52.0, "val_loss": 185714.24560546875, "val_acc": 56.0}
{"epoch": 25, "training_loss": 761395.123046875, "training_acc": 52.0, "val_loss": 85677.52685546875, "val_acc": 56.0}
{"epoch": 26, "training_loss": 204272.72436523438, "training_acc": 62.0, "val_loss": 84003.96728515625, "val_acc": 44.0}
{"epoch": 27, "training_loss": 308088.2998046875, "training_acc": 48.0, "val_loss": 32252.230834960938, "val_acc": 44.0}
{"epoch": 28, "training_loss": 142851.33984375, "training_acc": 54.0, "val_loss": 93194.00634765625, "val_acc": 56.0}
