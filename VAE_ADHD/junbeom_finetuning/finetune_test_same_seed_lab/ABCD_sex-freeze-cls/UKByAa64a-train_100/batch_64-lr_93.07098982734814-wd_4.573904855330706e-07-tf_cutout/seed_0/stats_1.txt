"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 275264.9506149292, "training_acc": 51.0, "val_loss": 145182.28759765625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 479032.0302734375, "training_acc": 47.0, "val_loss": 147560.7666015625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 671342.44921875, "training_acc": 53.0, "val_loss": 120626.35498046875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 363280.0234375, "training_acc": 51.0, "val_loss": 80719.3115234375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 237569.13104248047, "training_acc": 47.0, "val_loss": 115703.2958984375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 492854.189453125, "training_acc": 53.0, "val_loss": 115606.18896484375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 335127.76220703125, "training_acc": 53.0, "val_loss": 125797.65625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 588437.12109375, "training_acc": 47.0, "val_loss": 160956.33544921875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 521676.2841796875, "training_acc": 47.0, "val_loss": 62725.06103515625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 286367.8896484375, "training_acc": 53.0, "val_loss": 125671.71630859375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 431776.5703125, "training_acc": 53.0, "val_loss": 2314.8706436157227, "val_acc": 28.0}
{"epoch": 11, "training_loss": 76582.91748046875, "training_acc": 54.0, "val_loss": 71824.73754882812, "val_acc": 48.0}
{"epoch": 12, "training_loss": 205525.41040039062, "training_acc": 47.0, "val_loss": 88737.03002929688, "val_acc": 52.0}
{"epoch": 13, "training_loss": 392663.96484375, "training_acc": 53.0, "val_loss": 115059.38720703125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 363870.9755859375, "training_acc": 53.0, "val_loss": 50420.68786621094, "val_acc": 48.0}
{"epoch": 15, "training_loss": 261810.5087890625, "training_acc": 47.0, "val_loss": 68257.8125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 185134.34106445312, "training_acc": 51.0, "val_loss": 30791.915893554688, "val_acc": 52.0}
{"epoch": 17, "training_loss": 90872.40557861328, "training_acc": 47.0, "val_loss": 21720.559692382812, "val_acc": 52.0}
{"epoch": 18, "training_loss": 53128.88186645508, "training_acc": 56.0, "val_loss": 28002.127075195312, "val_acc": 48.0}
{"epoch": 19, "training_loss": 86106.48217773438, "training_acc": 47.0, "val_loss": 12327.706909179688, "val_acc": 48.0}
{"epoch": 20, "training_loss": 40603.176025390625, "training_acc": 59.0, "val_loss": 9203.298950195312, "val_acc": 52.0}
{"epoch": 21, "training_loss": 103545.0390625, "training_acc": 49.0, "val_loss": 46838.2568359375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 125379.02819824219, "training_acc": 53.0, "val_loss": 20326.6357421875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 76749.703125, "training_acc": 53.0, "val_loss": 4445.443344116211, "val_acc": 48.0}
{"epoch": 24, "training_loss": 105376.3134765625, "training_acc": 49.0, "val_loss": 58839.398193359375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 155482.67138671875, "training_acc": 53.0, "val_loss": 83350.75073242188, "val_acc": 48.0}
{"epoch": 26, "training_loss": 382089.533203125, "training_acc": 47.0, "val_loss": 97317.87109375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 277800.2624511719, "training_acc": 47.0, "val_loss": 96947.01538085938, "val_acc": 52.0}
{"epoch": 28, "training_loss": 460117.462890625, "training_acc": 53.0, "val_loss": 159748.0712890625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 565351.580078125, "training_acc": 53.0, "val_loss": 34237.42980957031, "val_acc": 52.0}
