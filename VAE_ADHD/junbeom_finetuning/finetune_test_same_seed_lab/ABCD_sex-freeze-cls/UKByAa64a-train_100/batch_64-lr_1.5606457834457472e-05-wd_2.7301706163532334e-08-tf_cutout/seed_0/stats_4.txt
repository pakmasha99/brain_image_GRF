"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.12180066108704, "training_acc": 57.0, "val_loss": 17.33970195055008, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16764187812805, "training_acc": 55.0, "val_loss": 17.33904480934143, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.34865617752075, "training_acc": 47.0, "val_loss": 17.338569462299347, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10930943489075, "training_acc": 54.0, "val_loss": 17.338286340236664, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15029644966125, "training_acc": 53.0, "val_loss": 17.337913811206818, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06327366828918, "training_acc": 55.0, "val_loss": 17.33754128217697, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24119973182678, "training_acc": 51.0, "val_loss": 17.33725666999817, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.04046773910522, "training_acc": 52.0, "val_loss": 17.337028682231903, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.9553120136261, "training_acc": 56.0, "val_loss": 17.336764931678772, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.40493750572205, "training_acc": 49.0, "val_loss": 17.336484789848328, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24700856208801, "training_acc": 51.0, "val_loss": 17.336268723011017, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15623831748962, "training_acc": 54.0, "val_loss": 17.33601838350296, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.36215615272522, "training_acc": 48.0, "val_loss": 17.335809767246246, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.04161953926086, "training_acc": 55.0, "val_loss": 17.335601150989532, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.0276825428009, "training_acc": 56.0, "val_loss": 17.335422337055206, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.07254767417908, "training_acc": 55.0, "val_loss": 17.33521670103073, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19319915771484, "training_acc": 52.0, "val_loss": 17.335040867328644, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20649838447571, "training_acc": 52.0, "val_loss": 17.334850132465363, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.04111814498901, "training_acc": 53.0, "val_loss": 17.334719002246857, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20375752449036, "training_acc": 51.0, "val_loss": 17.334596812725067, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19736552238464, "training_acc": 49.0, "val_loss": 17.33449697494507, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1169810295105, "training_acc": 54.0, "val_loss": 17.334355413913727, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.22364735603333, "training_acc": 52.0, "val_loss": 17.334239184856415, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.28150296211243, "training_acc": 51.0, "val_loss": 17.334136366844177, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13983225822449, "training_acc": 53.0, "val_loss": 17.33406037092209, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19379830360413, "training_acc": 52.0, "val_loss": 17.33398586511612, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22406888008118, "training_acc": 53.0, "val_loss": 17.333923280239105, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.95678400993347, "training_acc": 56.0, "val_loss": 17.3338383436203, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.01828479766846, "training_acc": 52.0, "val_loss": 17.33376234769821, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17083811759949, "training_acc": 52.0, "val_loss": 17.333687841892242, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.30957078933716, "training_acc": 53.0, "val_loss": 17.333629727363586, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.30673933029175, "training_acc": 50.0, "val_loss": 17.33357012271881, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.29494905471802, "training_acc": 52.0, "val_loss": 17.3335000872612, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1262788772583, "training_acc": 54.0, "val_loss": 17.33342707157135, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12075781822205, "training_acc": 55.0, "val_loss": 17.333364486694336, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15469288825989, "training_acc": 51.0, "val_loss": 17.33330488204956, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12547135353088, "training_acc": 52.0, "val_loss": 17.333270609378815, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15845584869385, "training_acc": 54.0, "val_loss": 17.333243787288666, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.97336673736572, "training_acc": 54.0, "val_loss": 17.333228886127472, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19264674186707, "training_acc": 52.0, "val_loss": 17.333224415779114, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.01377844810486, "training_acc": 53.0, "val_loss": 17.333224415779114, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15981411933899, "training_acc": 53.0, "val_loss": 17.33323037624359, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.24983215332031, "training_acc": 52.0, "val_loss": 17.33323484659195, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.07771396636963, "training_acc": 54.0, "val_loss": 17.333243787288666, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.18034839630127, "training_acc": 53.0, "val_loss": 17.33325719833374, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.23536968231201, "training_acc": 52.0, "val_loss": 17.333276569843292, "val_acc": 52.0}
{"epoch": 46, "training_loss": 68.93964338302612, "training_acc": 53.0, "val_loss": 17.333313822746277, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.18236112594604, "training_acc": 53.0, "val_loss": 17.33335852622986, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.0495274066925, "training_acc": 53.0, "val_loss": 17.3334002494812, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.31737518310547, "training_acc": 53.0, "val_loss": 17.333468794822693, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.23885035514832, "training_acc": 53.0, "val_loss": 17.33352392911911, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.90495705604553, "training_acc": 53.0, "val_loss": 17.333586513996124, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.22047448158264, "training_acc": 53.0, "val_loss": 17.333640158176422, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.99720025062561, "training_acc": 53.0, "val_loss": 17.333701252937317, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.02898144721985, "training_acc": 53.0, "val_loss": 17.333747446537018, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.20282769203186, "training_acc": 53.0, "val_loss": 17.333781719207764, "val_acc": 52.0}
{"epoch": 56, "training_loss": 68.99831485748291, "training_acc": 53.0, "val_loss": 17.33381599187851, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.1502525806427, "training_acc": 53.0, "val_loss": 17.333830893039703, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.06193780899048, "training_acc": 53.0, "val_loss": 17.33386069536209, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.27409029006958, "training_acc": 53.0, "val_loss": 17.333903908729553, "val_acc": 52.0}
