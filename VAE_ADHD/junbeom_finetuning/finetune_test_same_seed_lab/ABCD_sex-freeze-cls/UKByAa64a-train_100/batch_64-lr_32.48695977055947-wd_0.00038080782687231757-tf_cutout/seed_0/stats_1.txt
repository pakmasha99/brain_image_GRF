"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 68275.238697052, "training_acc": 46.0, "val_loss": 13685.0830078125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69006.779296875, "training_acc": 53.0, "val_loss": 37411.87438964844, "val_acc": 48.0}
{"epoch": 2, "training_loss": 139977.7890625, "training_acc": 47.0, "val_loss": 9881.876373291016, "val_acc": 48.0}
{"epoch": 3, "training_loss": 47984.44104003906, "training_acc": 51.0, "val_loss": 27224.1943359375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 103322.94384765625, "training_acc": 53.0, "val_loss": 23621.57440185547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69612.16430664062, "training_acc": 53.0, "val_loss": 5171.116256713867, "val_acc": 48.0}
{"epoch": 6, "training_loss": 41670.431884765625, "training_acc": 47.0, "val_loss": 13073.310852050781, "val_acc": 48.0}
{"epoch": 7, "training_loss": 43573.25549316406, "training_acc": 47.0, "val_loss": 8468.143463134766, "val_acc": 52.0}
{"epoch": 8, "training_loss": 33431.739990234375, "training_acc": 52.0, "val_loss": 14432.408142089844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 46566.126708984375, "training_acc": 53.0, "val_loss": 495.86987495422363, "val_acc": 52.0}
{"epoch": 10, "training_loss": 15307.015502929688, "training_acc": 53.0, "val_loss": 9135.9375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 30172.596923828125, "training_acc": 47.0, "val_loss": 7073.600769042969, "val_acc": 52.0}
{"epoch": 12, "training_loss": 30839.964599609375, "training_acc": 53.0, "val_loss": 9050.109100341797, "val_acc": 52.0}
{"epoch": 13, "training_loss": 23724.453979492188, "training_acc": 53.0, "val_loss": 8431.375122070312, "val_acc": 48.0}
{"epoch": 14, "training_loss": 41432.269775390625, "training_acc": 47.0, "val_loss": 11347.461700439453, "val_acc": 48.0}
{"epoch": 15, "training_loss": 33501.12890625, "training_acc": 47.0, "val_loss": 8104.8126220703125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 37476.817138671875, "training_acc": 53.0, "val_loss": 14330.497741699219, "val_acc": 52.0}
{"epoch": 17, "training_loss": 47637.06652832031, "training_acc": 53.0, "val_loss": 1427.1223068237305, "val_acc": 56.0}
{"epoch": 18, "training_loss": 25973.9462890625, "training_acc": 43.0, "val_loss": 15380.534362792969, "val_acc": 48.0}
{"epoch": 19, "training_loss": 57887.2353515625, "training_acc": 47.0, "val_loss": 5428.933334350586, "val_acc": 48.0}
{"epoch": 20, "training_loss": 25606.158447265625, "training_acc": 41.0, "val_loss": 10896.715545654297, "val_acc": 52.0}
{"epoch": 21, "training_loss": 39288.33557128906, "training_acc": 53.0, "val_loss": 5444.240188598633, "val_acc": 52.0}
{"epoch": 22, "training_loss": 18420.88800048828, "training_acc": 47.0, "val_loss": 7203.937530517578, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24577.194885253906, "training_acc": 47.0, "val_loss": 3289.2433166503906, "val_acc": 52.0}
{"epoch": 24, "training_loss": 13195.992248535156, "training_acc": 54.0, "val_loss": 2928.51619720459, "val_acc": 52.0}
{"epoch": 25, "training_loss": 12499.957397460938, "training_acc": 51.0, "val_loss": 4059.43603515625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 9753.986671447754, "training_acc": 55.0, "val_loss": 5268.837738037109, "val_acc": 52.0}
{"epoch": 27, "training_loss": 17011.230529785156, "training_acc": 53.0, "val_loss": 829.2538642883301, "val_acc": 64.0}
{"epoch": 28, "training_loss": 7629.492614746094, "training_acc": 60.0, "val_loss": 3378.5877227783203, "val_acc": 48.0}
