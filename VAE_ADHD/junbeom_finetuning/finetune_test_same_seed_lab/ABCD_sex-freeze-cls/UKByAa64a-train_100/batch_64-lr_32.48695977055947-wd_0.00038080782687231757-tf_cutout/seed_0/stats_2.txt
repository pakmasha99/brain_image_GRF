"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 43736.44218826294, "training_acc": 53.0, "val_loss": 7764.8590087890625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 24410.088256835938, "training_acc": 47.0, "val_loss": 10310.323333740234, "val_acc": 52.0}
{"epoch": 2, "training_loss": 40177.244140625, "training_acc": 53.0, "val_loss": 2362.679862976074, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8319.996856689453, "training_acc": 57.0, "val_loss": 2346.0277557373047, "val_acc": 52.0}
{"epoch": 4, "training_loss": 7904.658752441406, "training_acc": 55.0, "val_loss": 6270.912933349609, "val_acc": 48.0}
{"epoch": 5, "training_loss": 20440.353942871094, "training_acc": 49.0, "val_loss": 5115.103530883789, "val_acc": 52.0}
{"epoch": 6, "training_loss": 23764.364868164062, "training_acc": 53.0, "val_loss": 1914.5709991455078, "val_acc": 56.0}
{"epoch": 7, "training_loss": 13268.989135742188, "training_acc": 62.0, "val_loss": 9316.880798339844, "val_acc": 48.0}
{"epoch": 8, "training_loss": 29482.22576904297, "training_acc": 49.0, "val_loss": 6759.891510009766, "val_acc": 52.0}
{"epoch": 9, "training_loss": 30415.82763671875, "training_acc": 53.0, "val_loss": 7152.919006347656, "val_acc": 52.0}
{"epoch": 10, "training_loss": 18481.370193481445, "training_acc": 53.0, "val_loss": 3320.323944091797, "val_acc": 48.0}
{"epoch": 11, "training_loss": 8187.554710388184, "training_acc": 55.0, "val_loss": 6263.512420654297, "val_acc": 52.0}
{"epoch": 12, "training_loss": 23696.94659423828, "training_acc": 53.0, "val_loss": 2084.883499145508, "val_acc": 52.0}
{"epoch": 13, "training_loss": 11259.018432617188, "training_acc": 59.0, "val_loss": 9247.10693359375, "val_acc": 48.0}
{"epoch": 14, "training_loss": 31503.127319335938, "training_acc": 47.0, "val_loss": 3636.304473876953, "val_acc": 52.0}
{"epoch": 15, "training_loss": 17112.312438964844, "training_acc": 53.0, "val_loss": 4718.724822998047, "val_acc": 52.0}
{"epoch": 16, "training_loss": 13729.12484741211, "training_acc": 53.0, "val_loss": 4105.401611328125, "val_acc": 48.0}
{"epoch": 17, "training_loss": 11534.003288269043, "training_acc": 55.0, "val_loss": 4148.748016357422, "val_acc": 52.0}
{"epoch": 18, "training_loss": 13700.966827392578, "training_acc": 53.0, "val_loss": 3615.117645263672, "val_acc": 48.0}
{"epoch": 19, "training_loss": 14861.573547363281, "training_acc": 47.0, "val_loss": 1759.3269348144531, "val_acc": 52.0}
{"epoch": 20, "training_loss": 5914.158538818359, "training_acc": 55.0, "val_loss": 1496.4970588684082, "val_acc": 44.0}
{"epoch": 21, "training_loss": 5107.625305175781, "training_acc": 52.0, "val_loss": 4078.0960083007812, "val_acc": 52.0}
{"epoch": 22, "training_loss": 13102.72378540039, "training_acc": 53.0, "val_loss": 1583.9229583740234, "val_acc": 44.0}
{"epoch": 23, "training_loss": 4960.950626373291, "training_acc": 58.0, "val_loss": 2129.9421310424805, "val_acc": 52.0}
{"epoch": 24, "training_loss": 5305.780204772949, "training_acc": 57.0, "val_loss": 1462.3663902282715, "val_acc": 44.0}
{"epoch": 25, "training_loss": 5848.77522277832, "training_acc": 52.0, "val_loss": 716.948127746582, "val_acc": 64.0}
{"epoch": 26, "training_loss": 4850.6141357421875, "training_acc": 62.0, "val_loss": 349.89354610443115, "val_acc": 52.0}
{"epoch": 27, "training_loss": 3977.6957092285156, "training_acc": 65.0, "val_loss": 789.2579078674316, "val_acc": 60.0}
{"epoch": 28, "training_loss": 6880.361877441406, "training_acc": 61.0, "val_loss": 2441.5510177612305, "val_acc": 48.0}
{"epoch": 29, "training_loss": 8520.066802978516, "training_acc": 59.0, "val_loss": 6060.6689453125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 17589.758666992188, "training_acc": 53.0, "val_loss": 5849.485778808594, "val_acc": 48.0}
{"epoch": 31, "training_loss": 24161.815063476562, "training_acc": 47.0, "val_loss": 584.7924709320068, "val_acc": 52.0}
{"epoch": 32, "training_loss": 11902.282958984375, "training_acc": 60.0, "val_loss": 9247.6806640625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 28085.56072998047, "training_acc": 53.0, "val_loss": 3128.616714477539, "val_acc": 48.0}
{"epoch": 34, "training_loss": 14403.628723144531, "training_acc": 47.0, "val_loss": 419.42334175109863, "val_acc": 48.0}
{"epoch": 35, "training_loss": 4791.846252441406, "training_acc": 72.0, "val_loss": 3291.56494140625, "val_acc": 52.0}
{"epoch": 36, "training_loss": 11016.568298339844, "training_acc": 47.0, "val_loss": 2065.0712966918945, "val_acc": 48.0}
{"epoch": 37, "training_loss": 9831.779113769531, "training_acc": 53.0, "val_loss": 4729.652786254883, "val_acc": 52.0}
{"epoch": 38, "training_loss": 11931.685409545898, "training_acc": 51.0, "val_loss": 3742.852783203125, "val_acc": 48.0}
{"epoch": 39, "training_loss": 9850.105445861816, "training_acc": 53.0, "val_loss": 5678.961944580078, "val_acc": 52.0}
{"epoch": 40, "training_loss": 19509.82489013672, "training_acc": 53.0, "val_loss": 1179.0206909179688, "val_acc": 52.0}
{"epoch": 41, "training_loss": 14007.337890625, "training_acc": 52.0, "val_loss": 8762.580108642578, "val_acc": 48.0}
{"epoch": 42, "training_loss": 28414.494140625, "training_acc": 47.0, "val_loss": 6326.383209228516, "val_acc": 52.0}
{"epoch": 43, "training_loss": 25781.990356445312, "training_acc": 53.0, "val_loss": 8192.060089111328, "val_acc": 52.0}
{"epoch": 44, "training_loss": 19776.14305114746, "training_acc": 56.0, "val_loss": 8211.524963378906, "val_acc": 48.0}
{"epoch": 45, "training_loss": 37180.9765625, "training_acc": 47.0, "val_loss": 8603.7109375, "val_acc": 48.0}
