"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1001.4399871826172, "training_acc": 53.0, "val_loss": 174.52642917633057, "val_acc": 52.0}
{"epoch": 1, "training_loss": 983.3422431945801, "training_acc": 53.0, "val_loss": 568.5512542724609, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2135.071792602539, "training_acc": 47.0, "val_loss": 210.61558723449707, "val_acc": 48.0}
{"epoch": 3, "training_loss": 855.0930824279785, "training_acc": 43.0, "val_loss": 291.6285037994385, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1137.5560607910156, "training_acc": 53.0, "val_loss": 217.36743450164795, "val_acc": 52.0}
{"epoch": 5, "training_loss": 585.9548954963684, "training_acc": 53.0, "val_loss": 194.71713304519653, "val_acc": 48.0}
{"epoch": 6, "training_loss": 888.189037322998, "training_acc": 47.0, "val_loss": 292.42804050445557, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1019.0829563140869, "training_acc": 47.0, "val_loss": 22.592103481292725, "val_acc": 56.0}
{"epoch": 8, "training_loss": 255.87033653259277, "training_acc": 60.0, "val_loss": 251.90229415893555, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1006.0961608886719, "training_acc": 53.0, "val_loss": 171.9486951828003, "val_acc": 52.0}
{"epoch": 10, "training_loss": 458.9913868904114, "training_acc": 54.0, "val_loss": 162.05387115478516, "val_acc": 48.0}
{"epoch": 11, "training_loss": 745.3232460021973, "training_acc": 48.0, "val_loss": 255.0654649734497, "val_acc": 48.0}
{"epoch": 12, "training_loss": 846.5942039489746, "training_acc": 47.0, "val_loss": 20.888055860996246, "val_acc": 48.0}
{"epoch": 13, "training_loss": 259.33537673950195, "training_acc": 57.0, "val_loss": 202.98612117767334, "val_acc": 52.0}
{"epoch": 14, "training_loss": 739.1601161956787, "training_acc": 53.0, "val_loss": 96.7061996459961, "val_acc": 52.0}
{"epoch": 15, "training_loss": 381.7198314666748, "training_acc": 45.0, "val_loss": 126.64103507995605, "val_acc": 48.0}
{"epoch": 16, "training_loss": 436.33530044555664, "training_acc": 50.0, "val_loss": 25.206461548805237, "val_acc": 52.0}
{"epoch": 17, "training_loss": 230.73495292663574, "training_acc": 46.0, "val_loss": 125.49868822097778, "val_acc": 52.0}
{"epoch": 18, "training_loss": 431.98783111572266, "training_acc": 53.0, "val_loss": 29.430723190307617, "val_acc": 44.0}
{"epoch": 19, "training_loss": 180.16664695739746, "training_acc": 51.0, "val_loss": 54.882168769836426, "val_acc": 48.0}
{"epoch": 20, "training_loss": 185.63346147537231, "training_acc": 51.0, "val_loss": 69.80070471763611, "val_acc": 52.0}
{"epoch": 21, "training_loss": 207.33316731452942, "training_acc": 54.0, "val_loss": 51.66912078857422, "val_acc": 48.0}
{"epoch": 22, "training_loss": 205.38822555541992, "training_acc": 47.0, "val_loss": 26.616597175598145, "val_acc": 48.0}
{"epoch": 23, "training_loss": 145.6638708114624, "training_acc": 59.0, "val_loss": 32.87914991378784, "val_acc": 48.0}
{"epoch": 24, "training_loss": 132.55052137374878, "training_acc": 54.0, "val_loss": 48.82517755031586, "val_acc": 48.0}
{"epoch": 25, "training_loss": 142.6549186706543, "training_acc": 51.0, "val_loss": 51.516008377075195, "val_acc": 52.0}
{"epoch": 26, "training_loss": 151.8278968334198, "training_acc": 54.0, "val_loss": 63.916969299316406, "val_acc": 48.0}
{"epoch": 27, "training_loss": 221.5107879638672, "training_acc": 48.0, "val_loss": 32.86042809486389, "val_acc": 52.0}
{"epoch": 28, "training_loss": 144.62944078445435, "training_acc": 53.0, "val_loss": 20.41752189397812, "val_acc": 56.0}
{"epoch": 29, "training_loss": 121.9158296585083, "training_acc": 60.0, "val_loss": 47.12885320186615, "val_acc": 48.0}
{"epoch": 30, "training_loss": 151.7057647705078, "training_acc": 51.0, "val_loss": 47.618597745895386, "val_acc": 52.0}
{"epoch": 31, "training_loss": 148.11873722076416, "training_acc": 60.0, "val_loss": 54.98652458190918, "val_acc": 48.0}
{"epoch": 32, "training_loss": 154.58725929260254, "training_acc": 48.0, "val_loss": 36.85413300991058, "val_acc": 52.0}
{"epoch": 33, "training_loss": 156.8480453491211, "training_acc": 53.0, "val_loss": 30.41183650493622, "val_acc": 44.0}
{"epoch": 34, "training_loss": 133.31028175354004, "training_acc": 51.0, "val_loss": 18.250304460525513, "val_acc": 68.0}
{"epoch": 35, "training_loss": 102.2353401184082, "training_acc": 59.0, "val_loss": 22.79779016971588, "val_acc": 44.0}
{"epoch": 36, "training_loss": 78.8747353553772, "training_acc": 62.0, "val_loss": 19.405299425125122, "val_acc": 64.0}
{"epoch": 37, "training_loss": 69.87656426429749, "training_acc": 64.0, "val_loss": 20.905701816082, "val_acc": 56.0}
{"epoch": 38, "training_loss": 82.93428993225098, "training_acc": 62.0, "val_loss": 21.003134548664093, "val_acc": 56.0}
{"epoch": 39, "training_loss": 87.86702489852905, "training_acc": 63.0, "val_loss": 20.604510605335236, "val_acc": 64.0}
{"epoch": 40, "training_loss": 91.26879835128784, "training_acc": 58.0, "val_loss": 35.187435150146484, "val_acc": 52.0}
{"epoch": 41, "training_loss": 114.36809134483337, "training_acc": 55.0, "val_loss": 34.37161445617676, "val_acc": 48.0}
{"epoch": 42, "training_loss": 95.15815615653992, "training_acc": 51.0, "val_loss": 35.94886064529419, "val_acc": 52.0}
{"epoch": 43, "training_loss": 114.11649656295776, "training_acc": 55.0, "val_loss": 55.95734119415283, "val_acc": 48.0}
{"epoch": 44, "training_loss": 171.49498891830444, "training_acc": 48.0, "val_loss": 38.49844932556152, "val_acc": 52.0}
{"epoch": 45, "training_loss": 138.80707025527954, "training_acc": 53.0, "val_loss": 26.53426229953766, "val_acc": 44.0}
{"epoch": 46, "training_loss": 88.47509813308716, "training_acc": 55.0, "val_loss": 28.790494799613953, "val_acc": 52.0}
{"epoch": 47, "training_loss": 100.08361196517944, "training_acc": 54.0, "val_loss": 51.44776701927185, "val_acc": 48.0}
{"epoch": 48, "training_loss": 180.79013776779175, "training_acc": 47.0, "val_loss": 54.26822900772095, "val_acc": 52.0}
{"epoch": 49, "training_loss": 196.21242237091064, "training_acc": 53.0, "val_loss": 17.0126810669899, "val_acc": 60.0}
{"epoch": 50, "training_loss": 113.52824306488037, "training_acc": 72.0, "val_loss": 23.51543754339218, "val_acc": 48.0}
{"epoch": 51, "training_loss": 131.03740119934082, "training_acc": 55.0, "val_loss": 72.93816804885864, "val_acc": 52.0}
{"epoch": 52, "training_loss": 190.73806405067444, "training_acc": 55.0, "val_loss": 49.58682656288147, "val_acc": 48.0}
{"epoch": 53, "training_loss": 152.06792545318604, "training_acc": 53.0, "val_loss": 58.05153250694275, "val_acc": 52.0}
{"epoch": 54, "training_loss": 171.86398243904114, "training_acc": 53.0, "val_loss": 29.78743314743042, "val_acc": 48.0}
{"epoch": 55, "training_loss": 119.5426573753357, "training_acc": 49.0, "val_loss": 49.644824862480164, "val_acc": 52.0}
{"epoch": 56, "training_loss": 154.71503400802612, "training_acc": 53.0, "val_loss": 31.282976269721985, "val_acc": 48.0}
{"epoch": 57, "training_loss": 122.59623384475708, "training_acc": 49.0, "val_loss": 45.11677324771881, "val_acc": 52.0}
{"epoch": 58, "training_loss": 142.15335941314697, "training_acc": 53.0, "val_loss": 21.560882031917572, "val_acc": 48.0}
{"epoch": 59, "training_loss": 79.84821271896362, "training_acc": 53.0, "val_loss": 26.03546977043152, "val_acc": 52.0}
{"epoch": 60, "training_loss": 80.18362045288086, "training_acc": 60.0, "val_loss": 23.670002818107605, "val_acc": 48.0}
{"epoch": 61, "training_loss": 68.94394779205322, "training_acc": 61.0, "val_loss": 31.901583075523376, "val_acc": 52.0}
{"epoch": 62, "training_loss": 83.93951153755188, "training_acc": 64.0, "val_loss": 31.379950046539307, "val_acc": 48.0}
{"epoch": 63, "training_loss": 97.99322581291199, "training_acc": 56.0, "val_loss": 38.463038206100464, "val_acc": 52.0}
{"epoch": 64, "training_loss": 94.87374210357666, "training_acc": 61.0, "val_loss": 31.567001342773438, "val_acc": 48.0}
{"epoch": 65, "training_loss": 88.6589983701706, "training_acc": 57.0, "val_loss": 32.6008141040802, "val_acc": 52.0}
{"epoch": 66, "training_loss": 89.49631929397583, "training_acc": 63.0, "val_loss": 32.42552876472473, "val_acc": 48.0}
{"epoch": 67, "training_loss": 91.79499554634094, "training_acc": 59.0, "val_loss": 25.297212600708008, "val_acc": 52.0}
{"epoch": 68, "training_loss": 61.539541602134705, "training_acc": 66.0, "val_loss": 27.49812602996826, "val_acc": 48.0}
