"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 67130.92031860352, "training_acc": 51.0, "val_loss": 13930.723571777344, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70229.04638671875, "training_acc": 49.0, "val_loss": 30161.727905273438, "val_acc": 48.0}
{"epoch": 2, "training_loss": 112709.92309570312, "training_acc": 47.0, "val_loss": 7299.760437011719, "val_acc": 48.0}
{"epoch": 3, "training_loss": 42844.588623046875, "training_acc": 45.0, "val_loss": 23701.69677734375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 94634.02685546875, "training_acc": 53.0, "val_loss": 19983.734130859375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 63699.53369140625, "training_acc": 53.0, "val_loss": 5205.228424072266, "val_acc": 48.0}
{"epoch": 6, "training_loss": 30455.950805664062, "training_acc": 47.0, "val_loss": 11716.096496582031, "val_acc": 48.0}
{"epoch": 7, "training_loss": 38701.97674560547, "training_acc": 47.0, "val_loss": 5679.707717895508, "val_acc": 52.0}
{"epoch": 8, "training_loss": 25796.62548828125, "training_acc": 53.0, "val_loss": 9193.990325927734, "val_acc": 52.0}
{"epoch": 9, "training_loss": 29847.638793945312, "training_acc": 53.0, "val_loss": 4884.348678588867, "val_acc": 48.0}
{"epoch": 10, "training_loss": 23172.516235351562, "training_acc": 47.0, "val_loss": 4249.385833740234, "val_acc": 48.0}
{"epoch": 11, "training_loss": 20438.70733642578, "training_acc": 39.0, "val_loss": 5834.705352783203, "val_acc": 52.0}
{"epoch": 12, "training_loss": 18751.34014892578, "training_acc": 53.0, "val_loss": 4050.250244140625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 20012.168212890625, "training_acc": 47.0, "val_loss": 2174.967575073242, "val_acc": 48.0}
{"epoch": 14, "training_loss": 12439.940551757812, "training_acc": 53.0, "val_loss": 8948.734283447266, "val_acc": 52.0}
{"epoch": 15, "training_loss": 33220.47033691406, "training_acc": 53.0, "val_loss": 2563.411331176758, "val_acc": 52.0}
{"epoch": 16, "training_loss": 18064.988159179688, "training_acc": 47.0, "val_loss": 10282.862854003906, "val_acc": 48.0}
{"epoch": 17, "training_loss": 38831.985107421875, "training_acc": 47.0, "val_loss": 1480.9840202331543, "val_acc": 48.0}
{"epoch": 18, "training_loss": 21192.10302734375, "training_acc": 39.0, "val_loss": 13414.144897460938, "val_acc": 52.0}
{"epoch": 19, "training_loss": 51987.60986328125, "training_acc": 53.0, "val_loss": 9121.175384521484, "val_acc": 52.0}
{"epoch": 20, "training_loss": 24799.58641052246, "training_acc": 53.0, "val_loss": 10064.572143554688, "val_acc": 48.0}
{"epoch": 21, "training_loss": 48051.084228515625, "training_acc": 47.0, "val_loss": 15955.706787109375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 58539.94934082031, "training_acc": 47.0, "val_loss": 2861.404228210449, "val_acc": 48.0}
{"epoch": 23, "training_loss": 18127.632446289062, "training_acc": 53.0, "val_loss": 15843.510437011719, "val_acc": 52.0}
{"epoch": 24, "training_loss": 64296.315673828125, "training_acc": 53.0, "val_loss": 16167.764282226562, "val_acc": 52.0}
{"epoch": 25, "training_loss": 55284.19091796875, "training_acc": 53.0, "val_loss": 1748.1809616088867, "val_acc": 52.0}
{"epoch": 26, "training_loss": 19336.578369140625, "training_acc": 53.0, "val_loss": 18007.72247314453, "val_acc": 48.0}
{"epoch": 27, "training_loss": 74927.21020507812, "training_acc": 47.0, "val_loss": 15860.922241210938, "val_acc": 48.0}
{"epoch": 28, "training_loss": 52168.1044921875, "training_acc": 47.0, "val_loss": 3463.742446899414, "val_acc": 52.0}
{"epoch": 29, "training_loss": 22744.171264648438, "training_acc": 53.0, "val_loss": 11278.784942626953, "val_acc": 52.0}
{"epoch": 30, "training_loss": 40127.5361328125, "training_acc": 53.0, "val_loss": 2334.1686248779297, "val_acc": 52.0}
{"epoch": 31, "training_loss": 20381.9677734375, "training_acc": 45.0, "val_loss": 12572.840881347656, "val_acc": 48.0}
{"epoch": 32, "training_loss": 49776.48046875, "training_acc": 47.0, "val_loss": 5770.963668823242, "val_acc": 48.0}
{"epoch": 33, "training_loss": 18709.640563964844, "training_acc": 53.0, "val_loss": 8248.545837402344, "val_acc": 52.0}
{"epoch": 34, "training_loss": 32131.836547851562, "training_acc": 53.0, "val_loss": 4624.505233764648, "val_acc": 52.0}
{"epoch": 35, "training_loss": 11946.046478271484, "training_acc": 61.0, "val_loss": 5335.2630615234375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 18697.05206298828, "training_acc": 47.0, "val_loss": 3321.6567993164062, "val_acc": 52.0}
