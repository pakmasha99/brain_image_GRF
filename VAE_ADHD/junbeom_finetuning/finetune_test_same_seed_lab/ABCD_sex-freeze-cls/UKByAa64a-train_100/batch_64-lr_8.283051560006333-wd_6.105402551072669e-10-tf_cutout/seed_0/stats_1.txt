"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 24538.110038757324, "training_acc": 51.0, "val_loss": 12920.042419433594, "val_acc": 48.0}
{"epoch": 1, "training_loss": 42629.908203125, "training_acc": 47.0, "val_loss": 13132.467651367188, "val_acc": 52.0}
{"epoch": 2, "training_loss": 59748.315673828125, "training_acc": 53.0, "val_loss": 10736.709594726562, "val_acc": 52.0}
{"epoch": 3, "training_loss": 32331.291748046875, "training_acc": 51.0, "val_loss": 7182.125091552734, "val_acc": 48.0}
{"epoch": 4, "training_loss": 21136.157356262207, "training_acc": 47.0, "val_loss": 10298.580169677734, "val_acc": 52.0}
{"epoch": 5, "training_loss": 43868.37939453125, "training_acc": 53.0, "val_loss": 10290.933227539062, "val_acc": 52.0}
{"epoch": 6, "training_loss": 29834.953247070312, "training_acc": 53.0, "val_loss": 11192.680358886719, "val_acc": 48.0}
{"epoch": 7, "training_loss": 52357.313720703125, "training_acc": 47.0, "val_loss": 14322.868347167969, "val_acc": 48.0}
{"epoch": 8, "training_loss": 46420.4755859375, "training_acc": 47.0, "val_loss": 5583.301544189453, "val_acc": 52.0}
{"epoch": 9, "training_loss": 25489.77459716797, "training_acc": 53.0, "val_loss": 11186.036682128906, "val_acc": 52.0}
{"epoch": 10, "training_loss": 38433.92492675781, "training_acc": 53.0, "val_loss": 205.98602294921875, "val_acc": 24.0}
{"epoch": 11, "training_loss": 7092.545593261719, "training_acc": 54.0, "val_loss": 6845.056915283203, "val_acc": 48.0}
{"epoch": 12, "training_loss": 20391.906188964844, "training_acc": 47.0, "val_loss": 7162.2955322265625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 31896.723754882812, "training_acc": 53.0, "val_loss": 9245.497131347656, "val_acc": 52.0}
{"epoch": 14, "training_loss": 28314.58758544922, "training_acc": 53.0, "val_loss": 5803.652191162109, "val_acc": 48.0}
{"epoch": 15, "training_loss": 28822.467041015625, "training_acc": 47.0, "val_loss": 7574.797821044922, "val_acc": 48.0}
{"epoch": 16, "training_loss": 19781.475219726562, "training_acc": 47.0, "val_loss": 10220.503997802734, "val_acc": 52.0}
{"epoch": 17, "training_loss": 45748.42822265625, "training_acc": 53.0, "val_loss": 16182.366943359375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 58536.65673828125, "training_acc": 53.0, "val_loss": 5672.086715698242, "val_acc": 52.0}
{"epoch": 19, "training_loss": 21225.104125976562, "training_acc": 53.0, "val_loss": 11025.259399414062, "val_acc": 48.0}
{"epoch": 20, "training_loss": 45307.300048828125, "training_acc": 47.0, "val_loss": 5756.217575073242, "val_acc": 48.0}
{"epoch": 21, "training_loss": 19707.095703125, "training_acc": 51.0, "val_loss": 8707.653045654297, "val_acc": 52.0}
{"epoch": 22, "training_loss": 33678.82666015625, "training_acc": 53.0, "val_loss": 4440.724945068359, "val_acc": 52.0}
{"epoch": 23, "training_loss": 15400.393188476562, "training_acc": 53.0, "val_loss": 6065.970993041992, "val_acc": 48.0}
{"epoch": 24, "training_loss": 20210.45639038086, "training_acc": 47.0, "val_loss": 3944.8036193847656, "val_acc": 52.0}
{"epoch": 25, "training_loss": 20153.802001953125, "training_acc": 53.0, "val_loss": 3285.470199584961, "val_acc": 52.0}
{"epoch": 26, "training_loss": 13277.517578125, "training_acc": 53.0, "val_loss": 5990.392303466797, "val_acc": 48.0}
{"epoch": 27, "training_loss": 19012.91128540039, "training_acc": 47.0, "val_loss": 4818.268966674805, "val_acc": 52.0}
{"epoch": 28, "training_loss": 22242.423950195312, "training_acc": 53.0, "val_loss": 5399.869155883789, "val_acc": 52.0}
{"epoch": 29, "training_loss": 13947.040214538574, "training_acc": 51.0, "val_loss": 1295.2719688415527, "val_acc": 48.0}
