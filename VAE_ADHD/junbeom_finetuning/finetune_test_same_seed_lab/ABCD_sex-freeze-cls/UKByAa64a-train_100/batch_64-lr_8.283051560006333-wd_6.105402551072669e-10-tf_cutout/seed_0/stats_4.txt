"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 26226.90270614624, "training_acc": 44.0, "val_loss": 16400.1708984375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 67058.31762695312, "training_acc": 53.0, "val_loss": 6620.957183837891, "val_acc": 52.0}
{"epoch": 2, "training_loss": 47296.8544921875, "training_acc": 41.0, "val_loss": 18372.34649658203, "val_acc": 48.0}
{"epoch": 3, "training_loss": 65748.41076660156, "training_acc": 47.0, "val_loss": 1844.1959381103516, "val_acc": 52.0}
{"epoch": 4, "training_loss": 12735.738098144531, "training_acc": 53.0, "val_loss": 2746.63028717041, "val_acc": 52.0}
{"epoch": 5, "training_loss": 19562.069702148438, "training_acc": 43.0, "val_loss": 6957.161712646484, "val_acc": 48.0}
{"epoch": 6, "training_loss": 19306.409225463867, "training_acc": 47.0, "val_loss": 9638.048553466797, "val_acc": 52.0}
{"epoch": 7, "training_loss": 44050.487548828125, "training_acc": 53.0, "val_loss": 13053.404235839844, "val_acc": 52.0}
{"epoch": 8, "training_loss": 43115.89489746094, "training_acc": 53.0, "val_loss": 2031.6625595092773, "val_acc": 48.0}
{"epoch": 9, "training_loss": 14163.058349609375, "training_acc": 47.0, "val_loss": 3837.720489501953, "val_acc": 48.0}
{"epoch": 10, "training_loss": 12083.940368652344, "training_acc": 55.0, "val_loss": 4724.602508544922, "val_acc": 52.0}
{"epoch": 11, "training_loss": 15189.251892089844, "training_acc": 53.0, "val_loss": 4623.031234741211, "val_acc": 48.0}
{"epoch": 12, "training_loss": 20100.28009033203, "training_acc": 47.0, "val_loss": 1821.920394897461, "val_acc": 48.0}
{"epoch": 13, "training_loss": 13375.688049316406, "training_acc": 49.0, "val_loss": 9111.697387695312, "val_acc": 52.0}
{"epoch": 14, "training_loss": 33697.98596191406, "training_acc": 53.0, "val_loss": 2082.958984375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 16977.687744140625, "training_acc": 49.0, "val_loss": 11288.29345703125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 43462.70910644531, "training_acc": 47.0, "val_loss": 3128.618049621582, "val_acc": 48.0}
{"epoch": 17, "training_loss": 17246.466796875, "training_acc": 51.0, "val_loss": 12021.219635009766, "val_acc": 52.0}
{"epoch": 18, "training_loss": 48678.706298828125, "training_acc": 53.0, "val_loss": 9047.711944580078, "val_acc": 52.0}
{"epoch": 19, "training_loss": 25607.100158691406, "training_acc": 53.0, "val_loss": 9818.946838378906, "val_acc": 48.0}
{"epoch": 20, "training_loss": 48355.64306640625, "training_acc": 47.0, "val_loss": 15212.992858886719, "val_acc": 48.0}
{"epoch": 21, "training_loss": 54381.74621582031, "training_acc": 47.0, "val_loss": 819.3870544433594, "val_acc": 48.0}
{"epoch": 22, "training_loss": 13485.481079101562, "training_acc": 57.0, "val_loss": 18506.800842285156, "val_acc": 52.0}
{"epoch": 23, "training_loss": 77905.76171875, "training_acc": 53.0, "val_loss": 19870.93963623047, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69507.60961914062, "training_acc": 53.0, "val_loss": 5116.897964477539, "val_acc": 52.0}
{"epoch": 25, "training_loss": 21869.398559570312, "training_acc": 55.0, "val_loss": 15058.279418945312, "val_acc": 48.0}
{"epoch": 26, "training_loss": 62560.7626953125, "training_acc": 47.0, "val_loss": 13588.804626464844, "val_acc": 48.0}
{"epoch": 27, "training_loss": 44024.50354003906, "training_acc": 47.0, "val_loss": 4717.915344238281, "val_acc": 52.0}
{"epoch": 28, "training_loss": 25953.633666992188, "training_acc": 53.0, "val_loss": 11398.804473876953, "val_acc": 52.0}
{"epoch": 29, "training_loss": 40645.23059082031, "training_acc": 53.0, "val_loss": 1916.2361145019531, "val_acc": 52.0}
{"epoch": 30, "training_loss": 18418.708618164062, "training_acc": 51.0, "val_loss": 14796.975708007812, "val_acc": 48.0}
{"epoch": 31, "training_loss": 60493.2275390625, "training_acc": 47.0, "val_loss": 10060.072326660156, "val_acc": 48.0}
{"epoch": 32, "training_loss": 27561.75926208496, "training_acc": 47.0, "val_loss": 11620.84732055664, "val_acc": 52.0}
{"epoch": 33, "training_loss": 51925.314697265625, "training_acc": 53.0, "val_loss": 20809.70458984375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 79479.498046875, "training_acc": 53.0, "val_loss": 14136.672973632812, "val_acc": 52.0}
{"epoch": 35, "training_loss": 42644.96252441406, "training_acc": 53.0, "val_loss": 6211.93733215332, "val_acc": 48.0}
{"epoch": 36, "training_loss": 33250.86755371094, "training_acc": 47.0, "val_loss": 13870.1416015625, "val_acc": 48.0}
{"epoch": 37, "training_loss": 51062.267333984375, "training_acc": 47.0, "val_loss": 2027.374267578125, "val_acc": 48.0}
{"epoch": 38, "training_loss": 22710.617797851562, "training_acc": 41.0, "val_loss": 15080.574035644531, "val_acc": 52.0}
{"epoch": 39, "training_loss": 62565.848876953125, "training_acc": 53.0, "val_loss": 13034.861755371094, "val_acc": 52.0}
{"epoch": 40, "training_loss": 40300.17297363281, "training_acc": 53.0, "val_loss": 5288.834762573242, "val_acc": 48.0}
