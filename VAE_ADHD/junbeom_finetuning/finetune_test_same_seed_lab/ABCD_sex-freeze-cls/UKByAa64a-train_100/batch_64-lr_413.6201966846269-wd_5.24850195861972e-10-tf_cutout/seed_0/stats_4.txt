"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 800495.4602661133, "training_acc": 53.0, "val_loss": 122414.404296875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 908713.3515625, "training_acc": 51.0, "val_loss": 526750.244140625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1971688.7421875, "training_acc": 47.0, "val_loss": 192530.2490234375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 725400.78125, "training_acc": 45.0, "val_loss": 267491.2353515625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1050199.69140625, "training_acc": 53.0, "val_loss": 215399.8291015625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 698214.6352539062, "training_acc": 53.0, "val_loss": 153426.28173828125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 680625.94140625, "training_acc": 48.0, "val_loss": 231301.46484375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 739774.7578125, "training_acc": 48.0, "val_loss": 24462.046813964844, "val_acc": 44.0}
{"epoch": 8, "training_loss": 190380.0283203125, "training_acc": 62.0, "val_loss": 152609.2041015625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 547594.31640625, "training_acc": 53.0, "val_loss": 15350.946044921875, "val_acc": 56.0}
{"epoch": 10, "training_loss": 231846.1943359375, "training_acc": 48.0, "val_loss": 121900.50048828125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 371516.83544921875, "training_acc": 46.0, "val_loss": 63646.905517578125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 313638.0673828125, "training_acc": 52.0, "val_loss": 72061.24267578125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 265609.15869140625, "training_acc": 45.0, "val_loss": 60009.41162109375, "val_acc": 48.0}
{"epoch": 14, "training_loss": 177321.87915039062, "training_acc": 56.0, "val_loss": 42326.33361816406, "val_acc": 52.0}
{"epoch": 15, "training_loss": 135109.791015625, "training_acc": 54.0, "val_loss": 41637.68005371094, "val_acc": 48.0}
{"epoch": 16, "training_loss": 140729.908203125, "training_acc": 49.0, "val_loss": 28271.063232421875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 107380.44482421875, "training_acc": 58.0, "val_loss": 22585.952758789062, "val_acc": 44.0}
{"epoch": 18, "training_loss": 83804.3388671875, "training_acc": 54.0, "val_loss": 31390.19775390625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 88179.53369140625, "training_acc": 58.0, "val_loss": 32004.84619140625, "val_acc": 44.0}
{"epoch": 20, "training_loss": 85731.275390625, "training_acc": 56.0, "val_loss": 26831.155395507812, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70908.23010253906, "training_acc": 62.0, "val_loss": 24637.56561279297, "val_acc": 48.0}
{"epoch": 22, "training_loss": 59248.564208984375, "training_acc": 59.0, "val_loss": 47403.67431640625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 133912.09033203125, "training_acc": 54.0, "val_loss": 52107.7392578125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 175735.201171875, "training_acc": 47.0, "val_loss": 32843.597412109375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 110879.84838867188, "training_acc": 53.0, "val_loss": 14324.908447265625, "val_acc": 40.0}
{"epoch": 26, "training_loss": 53545.33837890625, "training_acc": 62.0, "val_loss": 28421.902465820312, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71629.8017578125, "training_acc": 61.0, "val_loss": 47711.810302734375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 151542.048828125, "training_acc": 47.0, "val_loss": 50072.296142578125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 222716.294921875, "training_acc": 53.0, "val_loss": 6704.106903076172, "val_acc": 60.0}
{"epoch": 30, "training_loss": 87022.369140625, "training_acc": 58.0, "val_loss": 11179.29458618164, "val_acc": 52.0}
{"epoch": 31, "training_loss": 108806.1953125, "training_acc": 58.0, "val_loss": 66108.24584960938, "val_acc": 52.0}
{"epoch": 32, "training_loss": 141242.08618164062, "training_acc": 58.0, "val_loss": 83330.88989257812, "val_acc": 48.0}
{"epoch": 33, "training_loss": 353411.1708984375, "training_acc": 47.0, "val_loss": 31265.841674804688, "val_acc": 48.0}
{"epoch": 34, "training_loss": 184980.5556640625, "training_acc": 53.0, "val_loss": 145465.185546875, "val_acc": 52.0}
{"epoch": 35, "training_loss": 515078.744140625, "training_acc": 53.0, "val_loss": 48794.647216796875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 289494.173828125, "training_acc": 41.0, "val_loss": 149265.2099609375, "val_acc": 48.0}
{"epoch": 37, "training_loss": 551161.52734375, "training_acc": 47.0, "val_loss": 9266.297912597656, "val_acc": 60.0}
{"epoch": 38, "training_loss": 171715.9423828125, "training_acc": 60.0, "val_loss": 134547.74169921875, "val_acc": 52.0}
{"epoch": 39, "training_loss": 420133.2216796875, "training_acc": 53.0, "val_loss": 7994.139099121094, "val_acc": 60.0}
{"epoch": 40, "training_loss": 132367.6943359375, "training_acc": 62.0, "val_loss": 97768.31665039062, "val_acc": 48.0}
{"epoch": 41, "training_loss": 287551.86669921875, "training_acc": 48.0, "val_loss": 93842.1630859375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 449785.578125, "training_acc": 53.0, "val_loss": 111491.29638671875, "val_acc": 52.0}
{"epoch": 43, "training_loss": 289802.34423828125, "training_acc": 56.0, "val_loss": 129848.52294921875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 605952.78515625, "training_acc": 47.0, "val_loss": 166446.37451171875, "val_acc": 48.0}
{"epoch": 45, "training_loss": 488802.5068359375, "training_acc": 43.0, "val_loss": 88171.6552734375, "val_acc": 52.0}
{"epoch": 46, "training_loss": 390880.966796875, "training_acc": 53.0, "val_loss": 146245.5322265625, "val_acc": 52.0}
{"epoch": 47, "training_loss": 495166.251953125, "training_acc": 53.0, "val_loss": 32471.246337890625, "val_acc": 44.0}
{"epoch": 48, "training_loss": 181954.33984375, "training_acc": 48.0, "val_loss": 52420.61767578125, "val_acc": 48.0}
