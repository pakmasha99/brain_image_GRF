"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 123887.12253570557, "training_acc": 53.0, "val_loss": 348583.8134765625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1407260.76171875, "training_acc": 47.0, "val_loss": 27338.424682617188, "val_acc": 44.0}
{"epoch": 2, "training_loss": 236363.751953125, "training_acc": 68.0, "val_loss": 338114.1845703125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1050417.494140625, "training_acc": 53.0, "val_loss": 89207.25708007812, "val_acc": 52.0}
{"epoch": 4, "training_loss": 448300.98828125, "training_acc": 47.0, "val_loss": 262447.3388671875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1060268.3046875, "training_acc": 47.0, "val_loss": 69709.01489257812, "val_acc": 48.0}
{"epoch": 6, "training_loss": 364372.134765625, "training_acc": 51.0, "val_loss": 258370.1416015625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 902875.40234375, "training_acc": 53.0, "val_loss": 204245.654296875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 517012.36474609375, "training_acc": 54.0, "val_loss": 119619.22607421875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 627343.009765625, "training_acc": 47.0, "val_loss": 186222.265625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 670151.291015625, "training_acc": 47.0, "val_loss": 65213.65966796875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 235518.31640625, "training_acc": 54.0, "val_loss": 156109.814453125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 419556.029296875, "training_acc": 53.0, "val_loss": 27167.510986328125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 173565.3251953125, "training_acc": 56.0, "val_loss": 39971.46911621094, "val_acc": 48.0}
{"epoch": 14, "training_loss": 213474.06958007812, "training_acc": 55.0, "val_loss": 107970.59326171875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 263505.5625, "training_acc": 53.0, "val_loss": 30319.528198242188, "val_acc": 52.0}
{"epoch": 16, "training_loss": 119645.3701171875, "training_acc": 57.0, "val_loss": 41374.847412109375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 166086.20971679688, "training_acc": 57.0, "val_loss": 86984.9365234375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 204660.1767578125, "training_acc": 55.0, "val_loss": 25275.69122314453, "val_acc": 48.0}
{"epoch": 19, "training_loss": 123844.6728515625, "training_acc": 60.0, "val_loss": 31049.017333984375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 189857.275390625, "training_acc": 43.0, "val_loss": 79101.99584960938, "val_acc": 52.0}
{"epoch": 21, "training_loss": 162073.92211914062, "training_acc": 56.0, "val_loss": 17585.2783203125, "val_acc": 44.0}
{"epoch": 22, "training_loss": 92761.5234375, "training_acc": 64.0, "val_loss": 33007.635498046875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 78963.14794921875, "training_acc": 58.0, "val_loss": 18539.022827148438, "val_acc": 56.0}
{"epoch": 24, "training_loss": 87566.11767578125, "training_acc": 58.0, "val_loss": 23802.468872070312, "val_acc": 52.0}
{"epoch": 25, "training_loss": 42760.921875, "training_acc": 64.0, "val_loss": 8952.529907226562, "val_acc": 48.0}
{"epoch": 26, "training_loss": 43627.37158203125, "training_acc": 64.0, "val_loss": 15723.927307128906, "val_acc": 52.0}
{"epoch": 27, "training_loss": 48802.96826171875, "training_acc": 62.0, "val_loss": 26571.316528320312, "val_acc": 52.0}
{"epoch": 28, "training_loss": 48068.94641113281, "training_acc": 62.0, "val_loss": 12720.98617553711, "val_acc": 44.0}
{"epoch": 29, "training_loss": 35081.86181640625, "training_acc": 54.0, "val_loss": 69773.50463867188, "val_acc": 52.0}
{"epoch": 30, "training_loss": 182986.36865234375, "training_acc": 53.0, "val_loss": 20186.70196533203, "val_acc": 48.0}
{"epoch": 31, "training_loss": 74312.45947265625, "training_acc": 55.0, "val_loss": 50998.80676269531, "val_acc": 52.0}
{"epoch": 32, "training_loss": 107551.07275390625, "training_acc": 52.0, "val_loss": 71039.90478515625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 303905.2841796875, "training_acc": 47.0, "val_loss": 9976.52816772461, "val_acc": 64.0}
{"epoch": 34, "training_loss": 133428.7841796875, "training_acc": 58.0, "val_loss": 143746.4599609375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 433370.8544921875, "training_acc": 53.0, "val_loss": 7676.544952392578, "val_acc": 52.0}
{"epoch": 36, "training_loss": 150862.2734375, "training_acc": 65.0, "val_loss": 100009.66796875, "val_acc": 48.0}
{"epoch": 37, "training_loss": 277291.36376953125, "training_acc": 47.0, "val_loss": 120763.22021484375, "val_acc": 52.0}
{"epoch": 38, "training_loss": 555805.9453125, "training_acc": 53.0, "val_loss": 173984.9609375, "val_acc": 52.0}
{"epoch": 39, "training_loss": 521796.96484375, "training_acc": 53.0, "val_loss": 48476.324462890625, "val_acc": 48.0}
{"epoch": 40, "training_loss": 288361.361328125, "training_acc": 48.0, "val_loss": 110969.66552734375, "val_acc": 48.0}
{"epoch": 41, "training_loss": 300587.20166015625, "training_acc": 48.0, "val_loss": 119123.71826171875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 556592.150390625, "training_acc": 53.0, "val_loss": 162721.533203125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 511160.86328125, "training_acc": 53.0, "val_loss": 65840.185546875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 359986.705078125, "training_acc": 47.0, "val_loss": 90532.3486328125, "val_acc": 48.0}
{"epoch": 45, "training_loss": 240414.63842773438, "training_acc": 56.0, "val_loss": 74377.31323242188, "val_acc": 52.0}
{"epoch": 46, "training_loss": 213061.1328125, "training_acc": 53.0, "val_loss": 12247.228240966797, "val_acc": 60.0}
{"epoch": 47, "training_loss": 88271.68115234375, "training_acc": 54.0, "val_loss": 47358.935546875, "val_acc": 52.0}
{"epoch": 48, "training_loss": 82970.28491210938, "training_acc": 57.0, "val_loss": 20053.794860839844, "val_acc": 52.0}
{"epoch": 49, "training_loss": 98717.55126953125, "training_acc": 53.0, "val_loss": 66021.37451171875, "val_acc": 52.0}
{"epoch": 50, "training_loss": 142961.68310546875, "training_acc": 54.0, "val_loss": 13739.584350585938, "val_acc": 40.0}
{"epoch": 51, "training_loss": 93319.45751953125, "training_acc": 61.0, "val_loss": 24774.832153320312, "val_acc": 52.0}
{"epoch": 52, "training_loss": 71631.57055664062, "training_acc": 62.0, "val_loss": 45813.16833496094, "val_acc": 52.0}
{"epoch": 53, "training_loss": 63366.737548828125, "training_acc": 61.0, "val_loss": 8862.554168701172, "val_acc": 48.0}
{"epoch": 54, "training_loss": 33065.14416503906, "training_acc": 72.0, "val_loss": 10561.024475097656, "val_acc": 52.0}
