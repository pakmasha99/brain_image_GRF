"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 101844.5658493042, "training_acc": 51.0, "val_loss": 53697.283935546875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 177175.7666015625, "training_acc": 47.0, "val_loss": 54580.853271484375, "val_acc": 52.0}
{"epoch": 2, "training_loss": 248324.779296875, "training_acc": 53.0, "val_loss": 44623.69079589844, "val_acc": 52.0}
{"epoch": 3, "training_loss": 134374.38745117188, "training_acc": 51.0, "val_loss": 29849.59716796875, "val_acc": 48.0}
{"epoch": 4, "training_loss": 87844.05130004883, "training_acc": 47.0, "val_loss": 42802.752685546875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 182324.68994140625, "training_acc": 53.0, "val_loss": 42770.96862792969, "val_acc": 52.0}
{"epoch": 6, "training_loss": 123999.78002929688, "training_acc": 53.0, "val_loss": 46518.109130859375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 217604.4189453125, "training_acc": 47.0, "val_loss": 59527.655029296875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 192930.1640625, "training_acc": 47.0, "val_loss": 23205.322265625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 105940.53955078125, "training_acc": 53.0, "val_loss": 46491.168212890625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 159738.01416015625, "training_acc": 53.0, "val_loss": 850.8706092834473, "val_acc": 24.0}
{"epoch": 11, "training_loss": 28942.375, "training_acc": 54.0, "val_loss": 27595.785522460938, "val_acc": 48.0}
{"epoch": 12, "training_loss": 80794.70245361328, "training_acc": 47.0, "val_loss": 31149.853515625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 138302.0009765625, "training_acc": 53.0, "val_loss": 40295.91369628906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 125332.0419921875, "training_acc": 53.0, "val_loss": 21646.258544921875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 109408.935546875, "training_acc": 47.0, "val_loss": 28664.144897460938, "val_acc": 48.0}
{"epoch": 16, "training_loss": 73042.02709960938, "training_acc": 51.0, "val_loss": 14412.541198730469, "val_acc": 52.0}
{"epoch": 17, "training_loss": 47624.84753417969, "training_acc": 53.0, "val_loss": 15614.596557617188, "val_acc": 48.0}
{"epoch": 18, "training_loss": 58032.68359375, "training_acc": 47.0, "val_loss": 7818.1671142578125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 32215.949829101562, "training_acc": 53.0, "val_loss": 9739.077758789062, "val_acc": 48.0}
{"epoch": 20, "training_loss": 34394.30822753906, "training_acc": 47.0, "val_loss": 18109.68475341797, "val_acc": 52.0}
{"epoch": 21, "training_loss": 77833.96118164062, "training_acc": 53.0, "val_loss": 11507.61489868164, "val_acc": 52.0}
{"epoch": 22, "training_loss": 61010.094970703125, "training_acc": 47.0, "val_loss": 24300.0244140625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 73132.33618164062, "training_acc": 47.0, "val_loss": 26236.160278320312, "val_acc": 52.0}
{"epoch": 24, "training_loss": 125690.45458984375, "training_acc": 53.0, "val_loss": 32322.8271484375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 85943.0966796875, "training_acc": 53.0, "val_loss": 32893.05725097656, "val_acc": 48.0}
{"epoch": 26, "training_loss": 157716.19482421875, "training_acc": 47.0, "val_loss": 49539.04113769531, "val_acc": 48.0}
{"epoch": 27, "training_loss": 165594.509765625, "training_acc": 47.0, "val_loss": 13728.973388671875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 77884.80322265625, "training_acc": 53.0, "val_loss": 29642.791748046875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 89969.70129394531, "training_acc": 53.0, "val_loss": 24024.729919433594, "val_acc": 48.0}
