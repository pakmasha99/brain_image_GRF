"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 131706.9142150879, "training_acc": 52.0, "val_loss": 43756.060791015625, "val_acc": 44.0}
{"epoch": 1, "training_loss": 134391.28149414062, "training_acc": 48.0, "val_loss": 46026.373291015625, "val_acc": 56.0}
{"epoch": 2, "training_loss": 213284.5986328125, "training_acc": 52.0, "val_loss": 19353.98406982422, "val_acc": 56.0}
{"epoch": 3, "training_loss": 110077.47119140625, "training_acc": 54.0, "val_loss": 74013.90380859375, "val_acc": 44.0}
{"epoch": 4, "training_loss": 248572.6787109375, "training_acc": 48.0, "val_loss": 6243.818283081055, "val_acc": 44.0}
{"epoch": 5, "training_loss": 115591.2919921875, "training_acc": 44.0, "val_loss": 81648.94409179688, "val_acc": 56.0}
{"epoch": 6, "training_loss": 356998.4384765625, "training_acc": 52.0, "val_loss": 62665.33203125, "val_acc": 56.0}
{"epoch": 7, "training_loss": 218070.52392578125, "training_acc": 52.0, "val_loss": 34937.445068359375, "val_acc": 44.0}
{"epoch": 8, "training_loss": 158237.939453125, "training_acc": 48.0, "val_loss": 67421.03271484375, "val_acc": 44.0}
{"epoch": 9, "training_loss": 220181.36083984375, "training_acc": 48.0, "val_loss": 1984.2174530029297, "val_acc": 44.0}
{"epoch": 10, "training_loss": 73957.11108398438, "training_acc": 52.0, "val_loss": 70604.93774414062, "val_acc": 56.0}
{"epoch": 11, "training_loss": 315934.0986328125, "training_acc": 52.0, "val_loss": 61918.060302734375, "val_acc": 56.0}
{"epoch": 12, "training_loss": 220652.13330078125, "training_acc": 52.0, "val_loss": 13708.966064453125, "val_acc": 44.0}
{"epoch": 13, "training_loss": 87700.841796875, "training_acc": 48.0, "val_loss": 41341.33605957031, "val_acc": 44.0}
{"epoch": 14, "training_loss": 119625.29345703125, "training_acc": 48.0, "val_loss": 19420.96405029297, "val_acc": 56.0}
{"epoch": 15, "training_loss": 102960.48681640625, "training_acc": 52.0, "val_loss": 30408.566284179688, "val_acc": 56.0}
{"epoch": 16, "training_loss": 103242.27734375, "training_acc": 52.0, "val_loss": 26412.579345703125, "val_acc": 44.0}
{"epoch": 17, "training_loss": 117246.00244140625, "training_acc": 48.0, "val_loss": 33269.19860839844, "val_acc": 44.0}
{"epoch": 18, "training_loss": 80740.92944335938, "training_acc": 48.0, "val_loss": 35886.090087890625, "val_acc": 56.0}
{"epoch": 19, "training_loss": 186446.984375, "training_acc": 52.0, "val_loss": 55353.204345703125, "val_acc": 56.0}
{"epoch": 20, "training_loss": 216813.88720703125, "training_acc": 52.0, "val_loss": 9958.344268798828, "val_acc": 56.0}
{"epoch": 21, "training_loss": 91840.21875, "training_acc": 46.0, "val_loss": 67734.375, "val_acc": 44.0}
{"epoch": 22, "training_loss": 247718.12109375, "training_acc": 48.0, "val_loss": 47065.47546386719, "val_acc": 44.0}
{"epoch": 23, "training_loss": 122959.064453125, "training_acc": 48.0, "val_loss": 38928.47595214844, "val_acc": 56.0}
{"epoch": 24, "training_loss": 212522.275390625, "training_acc": 52.0, "val_loss": 68712.2802734375, "val_acc": 56.0}
{"epoch": 25, "training_loss": 281716.36328125, "training_acc": 52.0, "val_loss": 31715.402221679688, "val_acc": 56.0}
{"epoch": 26, "training_loss": 75580.89862060547, "training_acc": 62.0, "val_loss": 31040.060424804688, "val_acc": 44.0}
{"epoch": 27, "training_loss": 113835.1015625, "training_acc": 48.0, "val_loss": 11900.495910644531, "val_acc": 44.0}
{"epoch": 28, "training_loss": 52800.812255859375, "training_acc": 54.0, "val_loss": 34495.220947265625, "val_acc": 56.0}
