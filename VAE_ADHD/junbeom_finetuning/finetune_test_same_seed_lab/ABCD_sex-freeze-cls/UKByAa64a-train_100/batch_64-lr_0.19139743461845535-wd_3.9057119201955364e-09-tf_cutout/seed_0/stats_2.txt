"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 362.9493942260742, "training_acc": 53.0, "val_loss": 23.83418381214142, "val_acc": 52.0}
{"epoch": 1, "training_loss": 410.2929229736328, "training_acc": 49.0, "val_loss": 256.2875032424927, "val_acc": 48.0}
{"epoch": 2, "training_loss": 900.5419921875, "training_acc": 47.0, "val_loss": 51.13311409950256, "val_acc": 48.0}
{"epoch": 3, "training_loss": 274.6273727416992, "training_acc": 49.0, "val_loss": 190.90427160263062, "val_acc": 52.0}
{"epoch": 4, "training_loss": 759.6340351104736, "training_acc": 53.0, "val_loss": 181.8063259124756, "val_acc": 52.0}
{"epoch": 5, "training_loss": 618.737096786499, "training_acc": 53.0, "val_loss": 30.11995553970337, "val_acc": 52.0}
{"epoch": 6, "training_loss": 214.38304042816162, "training_acc": 51.0, "val_loss": 155.4808259010315, "val_acc": 48.0}
{"epoch": 7, "training_loss": 618.3604068756104, "training_acc": 47.0, "val_loss": 128.76144647598267, "val_acc": 48.0}
{"epoch": 8, "training_loss": 392.1091718673706, "training_acc": 47.0, "val_loss": 43.34375560283661, "val_acc": 52.0}
{"epoch": 9, "training_loss": 255.85980033874512, "training_acc": 53.0, "val_loss": 110.07356643676758, "val_acc": 52.0}
{"epoch": 10, "training_loss": 398.14256381988525, "training_acc": 53.0, "val_loss": 42.15424954891205, "val_acc": 52.0}
{"epoch": 11, "training_loss": 177.41230630874634, "training_acc": 47.0, "val_loss": 72.93944954872131, "val_acc": 48.0}
{"epoch": 12, "training_loss": 271.66993522644043, "training_acc": 47.0, "val_loss": 32.06011950969696, "val_acc": 48.0}
{"epoch": 13, "training_loss": 110.72149133682251, "training_acc": 50.0, "val_loss": 54.56794500350952, "val_acc": 52.0}
{"epoch": 14, "training_loss": 197.31288385391235, "training_acc": 53.0, "val_loss": 22.611266374588013, "val_acc": 52.0}
{"epoch": 15, "training_loss": 94.06369495391846, "training_acc": 53.0, "val_loss": 48.353561758995056, "val_acc": 48.0}
{"epoch": 16, "training_loss": 159.09059238433838, "training_acc": 47.0, "val_loss": 20.32886892557144, "val_acc": 52.0}
{"epoch": 17, "training_loss": 111.43999719619751, "training_acc": 51.0, "val_loss": 36.75468862056732, "val_acc": 52.0}
{"epoch": 18, "training_loss": 110.19746375083923, "training_acc": 59.0, "val_loss": 29.83071804046631, "val_acc": 48.0}
{"epoch": 19, "training_loss": 119.50232648849487, "training_acc": 47.0, "val_loss": 17.302386462688446, "val_acc": 48.0}
{"epoch": 20, "training_loss": 81.06328296661377, "training_acc": 55.0, "val_loss": 31.100603938102722, "val_acc": 52.0}
{"epoch": 21, "training_loss": 88.1903166770935, "training_acc": 60.0, "val_loss": 21.601876616477966, "val_acc": 44.0}
{"epoch": 22, "training_loss": 92.9351658821106, "training_acc": 48.0, "val_loss": 16.165857017040253, "val_acc": 64.0}
{"epoch": 23, "training_loss": 92.48637294769287, "training_acc": 45.0, "val_loss": 24.753987789154053, "val_acc": 52.0}
{"epoch": 24, "training_loss": 73.77967500686646, "training_acc": 61.0, "val_loss": 18.19145530462265, "val_acc": 64.0}
{"epoch": 25, "training_loss": 87.58729362487793, "training_acc": 52.0, "val_loss": 20.76551765203476, "val_acc": 52.0}
{"epoch": 26, "training_loss": 79.44862461090088, "training_acc": 55.0, "val_loss": 23.361945152282715, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.95547032356262, "training_acc": 56.0, "val_loss": 20.09105384349823, "val_acc": 48.0}
{"epoch": 28, "training_loss": 82.81060075759888, "training_acc": 51.0, "val_loss": 19.117064774036407, "val_acc": 52.0}
{"epoch": 29, "training_loss": 61.76031994819641, "training_acc": 62.0, "val_loss": 18.468263745307922, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.37513136863708, "training_acc": 63.0, "val_loss": 17.83713549375534, "val_acc": 52.0}
{"epoch": 31, "training_loss": 62.812294483184814, "training_acc": 67.0, "val_loss": 17.81182289123535, "val_acc": 52.0}
{"epoch": 32, "training_loss": 61.815961599349976, "training_acc": 67.0, "val_loss": 17.617344856262207, "val_acc": 60.0}
{"epoch": 33, "training_loss": 64.1160626411438, "training_acc": 64.0, "val_loss": 17.271606624126434, "val_acc": 60.0}
{"epoch": 34, "training_loss": 71.91102933883667, "training_acc": 59.0, "val_loss": 18.91890913248062, "val_acc": 52.0}
{"epoch": 35, "training_loss": 65.84198808670044, "training_acc": 61.0, "val_loss": 18.84627938270569, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.08442044258118, "training_acc": 50.0, "val_loss": 16.622844338417053, "val_acc": 60.0}
{"epoch": 37, "training_loss": 60.20317029953003, "training_acc": 69.0, "val_loss": 24.665561318397522, "val_acc": 52.0}
{"epoch": 38, "training_loss": 71.68845748901367, "training_acc": 58.0, "val_loss": 16.644969582557678, "val_acc": 64.0}
{"epoch": 39, "training_loss": 61.95198106765747, "training_acc": 70.0, "val_loss": 16.873161494731903, "val_acc": 60.0}
{"epoch": 40, "training_loss": 60.77350354194641, "training_acc": 74.0, "val_loss": 17.06937700510025, "val_acc": 60.0}
{"epoch": 41, "training_loss": 56.6416916847229, "training_acc": 80.0, "val_loss": 17.737600207328796, "val_acc": 56.0}
