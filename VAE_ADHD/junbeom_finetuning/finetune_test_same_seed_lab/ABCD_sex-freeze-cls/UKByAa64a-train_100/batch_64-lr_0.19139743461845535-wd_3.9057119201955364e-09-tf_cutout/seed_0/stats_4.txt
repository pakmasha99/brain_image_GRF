"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 506.6446418762207, "training_acc": 49.0, "val_loss": 93.65894794464111, "val_acc": 52.0}
{"epoch": 1, "training_loss": 456.63121223449707, "training_acc": 49.0, "val_loss": 198.5464096069336, "val_acc": 48.0}
{"epoch": 2, "training_loss": 733.864688873291, "training_acc": 47.0, "val_loss": 54.62198257446289, "val_acc": 48.0}
{"epoch": 3, "training_loss": 256.8231086730957, "training_acc": 49.0, "val_loss": 146.48815393447876, "val_acc": 52.0}
{"epoch": 4, "training_loss": 576.3494930267334, "training_acc": 53.0, "val_loss": 119.5664644241333, "val_acc": 52.0}
{"epoch": 5, "training_loss": 368.45305824279785, "training_acc": 53.0, "val_loss": 43.193069100379944, "val_acc": 48.0}
{"epoch": 6, "training_loss": 229.77546405792236, "training_acc": 47.0, "val_loss": 90.94850420951843, "val_acc": 48.0}
{"epoch": 7, "training_loss": 305.38088846206665, "training_acc": 47.0, "val_loss": 24.618777632713318, "val_acc": 52.0}
{"epoch": 8, "training_loss": 163.08094692230225, "training_acc": 53.0, "val_loss": 58.08738470077515, "val_acc": 52.0}
{"epoch": 9, "training_loss": 185.56277918815613, "training_acc": 53.0, "val_loss": 34.646326303482056, "val_acc": 48.0}
{"epoch": 10, "training_loss": 156.4239330291748, "training_acc": 47.0, "val_loss": 36.23031675815582, "val_acc": 48.0}
{"epoch": 11, "training_loss": 145.32290697097778, "training_acc": 37.0, "val_loss": 34.793663024902344, "val_acc": 52.0}
{"epoch": 12, "training_loss": 119.31760358810425, "training_acc": 53.0, "val_loss": 20.517897605895996, "val_acc": 48.0}
{"epoch": 13, "training_loss": 96.05236577987671, "training_acc": 48.0, "val_loss": 20.379407703876495, "val_acc": 48.0}
{"epoch": 14, "training_loss": 84.7410957813263, "training_acc": 45.0, "val_loss": 25.36788582801819, "val_acc": 52.0}
{"epoch": 15, "training_loss": 94.83343052864075, "training_acc": 53.0, "val_loss": 20.340245962142944, "val_acc": 48.0}
{"epoch": 16, "training_loss": 72.14801049232483, "training_acc": 51.0, "val_loss": 18.488509953022003, "val_acc": 52.0}
{"epoch": 17, "training_loss": 78.48349857330322, "training_acc": 54.0, "val_loss": 17.471206188201904, "val_acc": 52.0}
{"epoch": 18, "training_loss": 65.56306076049805, "training_acc": 59.0, "val_loss": 20.967207849025726, "val_acc": 44.0}
{"epoch": 19, "training_loss": 77.51525950431824, "training_acc": 50.0, "val_loss": 19.952566921710968, "val_acc": 52.0}
{"epoch": 20, "training_loss": 74.30949640274048, "training_acc": 54.0, "val_loss": 20.8369180560112, "val_acc": 40.0}
{"epoch": 21, "training_loss": 79.24262118339539, "training_acc": 53.0, "val_loss": 18.119609355926514, "val_acc": 60.0}
{"epoch": 22, "training_loss": 66.41927242279053, "training_acc": 62.0, "val_loss": 18.00238788127899, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.75859785079956, "training_acc": 52.0, "val_loss": 17.290271818637848, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.05354499816895, "training_acc": 56.0, "val_loss": 17.31679141521454, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.30394530296326, "training_acc": 54.0, "val_loss": 17.28202849626541, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.83320546150208, "training_acc": 62.0, "val_loss": 17.241641879081726, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.7856912612915, "training_acc": 55.0, "val_loss": 17.720133066177368, "val_acc": 60.0}
{"epoch": 28, "training_loss": 67.24738264083862, "training_acc": 61.0, "val_loss": 20.586499571800232, "val_acc": 52.0}
{"epoch": 29, "training_loss": 71.66307425498962, "training_acc": 57.0, "val_loss": 22.001150250434875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 79.1872251033783, "training_acc": 52.0, "val_loss": 18.085426092147827, "val_acc": 52.0}
{"epoch": 31, "training_loss": 62.943652391433716, "training_acc": 60.0, "val_loss": 19.34788078069687, "val_acc": 48.0}
{"epoch": 32, "training_loss": 69.26431608200073, "training_acc": 48.0, "val_loss": 19.677354395389557, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.19032740592957, "training_acc": 52.0, "val_loss": 17.267686128616333, "val_acc": 56.0}
{"epoch": 34, "training_loss": 67.62277340888977, "training_acc": 55.0, "val_loss": 16.982467472553253, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.65700507164001, "training_acc": 64.0, "val_loss": 17.00742542743683, "val_acc": 56.0}
{"epoch": 36, "training_loss": 66.48206448554993, "training_acc": 66.0, "val_loss": 17.69016534090042, "val_acc": 60.0}
{"epoch": 37, "training_loss": 60.673056840896606, "training_acc": 70.0, "val_loss": 20.366235077381134, "val_acc": 52.0}
{"epoch": 38, "training_loss": 72.63650250434875, "training_acc": 56.0, "val_loss": 18.178969621658325, "val_acc": 52.0}
{"epoch": 39, "training_loss": 72.15947818756104, "training_acc": 46.0, "val_loss": 16.862523555755615, "val_acc": 52.0}
{"epoch": 40, "training_loss": 57.75582671165466, "training_acc": 70.0, "val_loss": 17.002061009407043, "val_acc": 52.0}
{"epoch": 41, "training_loss": 60.6095917224884, "training_acc": 68.0, "val_loss": 16.857993602752686, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.40209698677063, "training_acc": 69.0, "val_loss": 18.44220757484436, "val_acc": 52.0}
{"epoch": 43, "training_loss": 63.046268701553345, "training_acc": 60.0, "val_loss": 17.195163667201996, "val_acc": 60.0}
{"epoch": 44, "training_loss": 63.808552980422974, "training_acc": 63.0, "val_loss": 17.235393822193146, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.663288593292236, "training_acc": 63.0, "val_loss": 16.86207950115204, "val_acc": 52.0}
{"epoch": 46, "training_loss": 64.91577243804932, "training_acc": 66.0, "val_loss": 17.024172842502594, "val_acc": 52.0}
{"epoch": 47, "training_loss": 60.626763582229614, "training_acc": 66.0, "val_loss": 17.897243797779083, "val_acc": 52.0}
{"epoch": 48, "training_loss": 59.25454020500183, "training_acc": 69.0, "val_loss": 17.503748834133148, "val_acc": 68.0}
{"epoch": 49, "training_loss": 62.97165250778198, "training_acc": 62.0, "val_loss": 18.12625825405121, "val_acc": 52.0}
{"epoch": 50, "training_loss": 61.94289803504944, "training_acc": 64.0, "val_loss": 17.94799417257309, "val_acc": 68.0}
{"epoch": 51, "training_loss": 71.11422562599182, "training_acc": 63.0, "val_loss": 16.9284850358963, "val_acc": 56.0}
{"epoch": 52, "training_loss": 63.79888367652893, "training_acc": 60.0, "val_loss": 16.984866559505463, "val_acc": 52.0}
{"epoch": 53, "training_loss": 60.8631317615509, "training_acc": 65.0, "val_loss": 16.681835055351257, "val_acc": 52.0}
{"epoch": 54, "training_loss": 61.35659456253052, "training_acc": 70.0, "val_loss": 17.287829518318176, "val_acc": 72.0}
{"epoch": 55, "training_loss": 61.099807024002075, "training_acc": 67.0, "val_loss": 17.351020872592926, "val_acc": 52.0}
{"epoch": 56, "training_loss": 61.93481993675232, "training_acc": 67.0, "val_loss": 16.702933609485626, "val_acc": 52.0}
{"epoch": 57, "training_loss": 53.76773238182068, "training_acc": 83.0, "val_loss": 18.19002479314804, "val_acc": 52.0}
{"epoch": 58, "training_loss": 59.07642865180969, "training_acc": 69.0, "val_loss": 16.932834684848785, "val_acc": 64.0}
{"epoch": 59, "training_loss": 59.66735124588013, "training_acc": 69.0, "val_loss": 16.731345653533936, "val_acc": 56.0}
{"epoch": 60, "training_loss": 60.95853042602539, "training_acc": 67.0, "val_loss": 17.106132209300995, "val_acc": 60.0}
{"epoch": 61, "training_loss": 58.61488914489746, "training_acc": 70.0, "val_loss": 17.737217247486115, "val_acc": 52.0}
{"epoch": 62, "training_loss": 59.53227090835571, "training_acc": 67.0, "val_loss": 16.968661546707153, "val_acc": 52.0}
{"epoch": 63, "training_loss": 56.40587067604065, "training_acc": 70.0, "val_loss": 17.055001854896545, "val_acc": 60.0}
{"epoch": 64, "training_loss": 54.83143353462219, "training_acc": 72.0, "val_loss": 19.853320717811584, "val_acc": 52.0}
{"epoch": 65, "training_loss": 59.10584092140198, "training_acc": 66.0, "val_loss": 16.65666103363037, "val_acc": 56.0}
{"epoch": 66, "training_loss": 58.83963370323181, "training_acc": 73.0, "val_loss": 17.111900448799133, "val_acc": 52.0}
{"epoch": 67, "training_loss": 54.83350396156311, "training_acc": 70.0, "val_loss": 16.606245934963226, "val_acc": 56.0}
{"epoch": 68, "training_loss": 55.90149712562561, "training_acc": 75.0, "val_loss": 18.05993765592575, "val_acc": 52.0}
{"epoch": 69, "training_loss": 57.95431995391846, "training_acc": 67.0, "val_loss": 17.444156110286713, "val_acc": 60.0}
{"epoch": 70, "training_loss": 67.58982396125793, "training_acc": 55.0, "val_loss": 17.98616200685501, "val_acc": 60.0}
{"epoch": 71, "training_loss": 60.11835598945618, "training_acc": 65.0, "val_loss": 22.877074778079987, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.88202238082886, "training_acc": 56.0, "val_loss": 19.08423900604248, "val_acc": 48.0}
{"epoch": 73, "training_loss": 68.7899866104126, "training_acc": 49.0, "val_loss": 16.807088255882263, "val_acc": 60.0}
{"epoch": 74, "training_loss": 57.910102128982544, "training_acc": 72.0, "val_loss": 18.180175125598907, "val_acc": 60.0}
{"epoch": 75, "training_loss": 61.772950649261475, "training_acc": 62.0, "val_loss": 27.76971459388733, "val_acc": 52.0}
{"epoch": 76, "training_loss": 81.54127216339111, "training_acc": 55.0, "val_loss": 19.9552983045578, "val_acc": 48.0}
{"epoch": 77, "training_loss": 65.03067064285278, "training_acc": 58.0, "val_loss": 16.872721910476685, "val_acc": 56.0}
{"epoch": 78, "training_loss": 54.210355043411255, "training_acc": 74.0, "val_loss": 16.547369956970215, "val_acc": 56.0}
{"epoch": 79, "training_loss": 55.2389452457428, "training_acc": 73.0, "val_loss": 16.89169704914093, "val_acc": 52.0}
{"epoch": 80, "training_loss": 55.02439904212952, "training_acc": 73.0, "val_loss": 16.564330458641052, "val_acc": 56.0}
{"epoch": 81, "training_loss": 52.45378136634827, "training_acc": 76.0, "val_loss": 16.53551757335663, "val_acc": 56.0}
{"epoch": 82, "training_loss": 51.868141174316406, "training_acc": 78.0, "val_loss": 17.391934990882874, "val_acc": 52.0}
{"epoch": 83, "training_loss": 56.64433836936951, "training_acc": 68.0, "val_loss": 20.89114785194397, "val_acc": 44.0}
{"epoch": 84, "training_loss": 65.24636030197144, "training_acc": 60.0, "val_loss": 23.689858615398407, "val_acc": 52.0}
{"epoch": 85, "training_loss": 67.78090786933899, "training_acc": 57.0, "val_loss": 22.483691573143005, "val_acc": 48.0}
{"epoch": 86, "training_loss": 71.08665204048157, "training_acc": 60.0, "val_loss": 18.545886874198914, "val_acc": 52.0}
{"epoch": 87, "training_loss": 56.49570083618164, "training_acc": 70.0, "val_loss": 18.470004200935364, "val_acc": 56.0}
{"epoch": 88, "training_loss": 54.3785765171051, "training_acc": 75.0, "val_loss": 22.971558570861816, "val_acc": 52.0}
{"epoch": 89, "training_loss": 70.42328691482544, "training_acc": 60.0, "val_loss": 17.054155468940735, "val_acc": 64.0}
{"epoch": 90, "training_loss": 52.2889244556427, "training_acc": 76.0, "val_loss": 16.73029065132141, "val_acc": 56.0}
{"epoch": 91, "training_loss": 50.95468831062317, "training_acc": 77.0, "val_loss": 18.206290900707245, "val_acc": 52.0}
{"epoch": 92, "training_loss": 49.88242185115814, "training_acc": 77.0, "val_loss": 16.713295876979828, "val_acc": 56.0}
{"epoch": 93, "training_loss": 51.74232280254364, "training_acc": 81.0, "val_loss": 18.936973810195923, "val_acc": 52.0}
{"epoch": 94, "training_loss": 54.13465142250061, "training_acc": 71.0, "val_loss": 18.736153841018677, "val_acc": 60.0}
{"epoch": 95, "training_loss": 52.16966128349304, "training_acc": 72.0, "val_loss": 25.031977891921997, "val_acc": 52.0}
{"epoch": 96, "training_loss": 67.16370177268982, "training_acc": 62.0, "val_loss": 19.64922845363617, "val_acc": 44.0}
{"epoch": 97, "training_loss": 60.507000207901, "training_acc": 67.0, "val_loss": 19.011330604553223, "val_acc": 52.0}
{"epoch": 98, "training_loss": 60.981689453125, "training_acc": 67.0, "val_loss": 16.457505524158478, "val_acc": 64.0}
{"epoch": 99, "training_loss": 54.3179976940155, "training_acc": 72.0, "val_loss": 16.986478865146637, "val_acc": 56.0}
{"epoch": 100, "training_loss": 52.78269171714783, "training_acc": 69.0, "val_loss": 16.9320210814476, "val_acc": 64.0}
{"epoch": 101, "training_loss": 50.67549526691437, "training_acc": 78.0, "val_loss": 17.06114411354065, "val_acc": 52.0}
{"epoch": 102, "training_loss": 52.92718172073364, "training_acc": 76.0, "val_loss": 17.736516892910004, "val_acc": 56.0}
{"epoch": 103, "training_loss": 56.21510624885559, "training_acc": 73.0, "val_loss": 19.242511689662933, "val_acc": 52.0}
{"epoch": 104, "training_loss": 61.76511836051941, "training_acc": 61.0, "val_loss": 24.602293968200684, "val_acc": 52.0}
{"epoch": 105, "training_loss": 70.89461326599121, "training_acc": 58.0, "val_loss": 27.84714698791504, "val_acc": 48.0}
{"epoch": 106, "training_loss": 82.24845480918884, "training_acc": 54.0, "val_loss": 27.075785398483276, "val_acc": 52.0}
{"epoch": 107, "training_loss": 75.99910712242126, "training_acc": 55.0, "val_loss": 23.902906477451324, "val_acc": 48.0}
{"epoch": 108, "training_loss": 73.52094268798828, "training_acc": 54.0, "val_loss": 23.359397053718567, "val_acc": 52.0}
{"epoch": 109, "training_loss": 63.103764057159424, "training_acc": 61.0, "val_loss": 23.128363490104675, "val_acc": 48.0}
{"epoch": 110, "training_loss": 67.50326406955719, "training_acc": 62.0, "val_loss": 23.777413368225098, "val_acc": 52.0}
{"epoch": 111, "training_loss": 64.57157945632935, "training_acc": 59.0, "val_loss": 21.13306373357773, "val_acc": 48.0}
{"epoch": 112, "training_loss": 64.28014183044434, "training_acc": 58.0, "val_loss": 23.42274785041809, "val_acc": 52.0}
{"epoch": 113, "training_loss": 67.05928063392639, "training_acc": 59.0, "val_loss": 22.695665061473846, "val_acc": 48.0}
{"epoch": 114, "training_loss": 64.06691288948059, "training_acc": 57.0, "val_loss": 25.00189244747162, "val_acc": 52.0}
{"epoch": 115, "training_loss": 72.30748510360718, "training_acc": 59.0, "val_loss": 24.54424947500229, "val_acc": 48.0}
{"epoch": 116, "training_loss": 72.41047286987305, "training_acc": 59.0, "val_loss": 23.248274624347687, "val_acc": 52.0}
{"epoch": 117, "training_loss": 68.06072354316711, "training_acc": 59.0, "val_loss": 19.587033987045288, "val_acc": 52.0}
