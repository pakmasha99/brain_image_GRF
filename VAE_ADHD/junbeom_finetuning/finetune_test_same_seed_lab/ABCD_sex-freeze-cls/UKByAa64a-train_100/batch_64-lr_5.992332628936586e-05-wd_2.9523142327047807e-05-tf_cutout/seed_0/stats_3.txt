"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.22349667549133, "training_acc": 55.0, "val_loss": 17.25456267595291, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.29496765136719, "training_acc": 53.0, "val_loss": 17.252907156944275, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.243891954422, "training_acc": 53.0, "val_loss": 17.252501845359802, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32823634147644, "training_acc": 53.0, "val_loss": 17.252151668071747, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14478635787964, "training_acc": 53.0, "val_loss": 17.252475023269653, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2130081653595, "training_acc": 53.0, "val_loss": 17.252768576145172, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12306237220764, "training_acc": 53.0, "val_loss": 17.25325882434845, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16749119758606, "training_acc": 53.0, "val_loss": 17.253616452217102, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16513323783875, "training_acc": 53.0, "val_loss": 17.254212498664856, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.27986979484558, "training_acc": 53.0, "val_loss": 17.25582778453827, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16419172286987, "training_acc": 53.0, "val_loss": 17.258411645889282, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1384630203247, "training_acc": 53.0, "val_loss": 17.26030707359314, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19134855270386, "training_acc": 53.0, "val_loss": 17.26178675889969, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.22980093955994, "training_acc": 53.0, "val_loss": 17.2612264752388, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.05770063400269, "training_acc": 53.0, "val_loss": 17.261947691440582, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20219802856445, "training_acc": 53.0, "val_loss": 17.26498007774353, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14813685417175, "training_acc": 53.0, "val_loss": 17.268182337284088, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12572407722473, "training_acc": 53.0, "val_loss": 17.271430790424347, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.09620404243469, "training_acc": 53.0, "val_loss": 17.273913323879242, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12678861618042, "training_acc": 53.0, "val_loss": 17.275431752204895, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23721075057983, "training_acc": 53.0, "val_loss": 17.2766774892807, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26948380470276, "training_acc": 53.0, "val_loss": 17.277827858924866, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.23985004425049, "training_acc": 53.0, "val_loss": 17.275837063789368, "val_acc": 52.0}
