"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.27814793586731, "training_acc": 53.0, "val_loss": 17.26129651069641, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.12620830535889, "training_acc": 53.0, "val_loss": 17.26382225751877, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15597176551819, "training_acc": 53.0, "val_loss": 17.26449579000473, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1518383026123, "training_acc": 53.0, "val_loss": 17.268286645412445, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.09219765663147, "training_acc": 53.0, "val_loss": 17.270122468471527, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13557553291321, "training_acc": 53.0, "val_loss": 17.271365225315094, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12815189361572, "training_acc": 53.0, "val_loss": 17.272883653640747, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.29527378082275, "training_acc": 53.0, "val_loss": 17.272695899009705, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.08500409126282, "training_acc": 53.0, "val_loss": 17.269954085350037, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19117832183838, "training_acc": 53.0, "val_loss": 17.26641356945038, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.24333190917969, "training_acc": 53.0, "val_loss": 17.262813448905945, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12148237228394, "training_acc": 53.0, "val_loss": 17.261695861816406, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16085410118103, "training_acc": 53.0, "val_loss": 17.2602578997612, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15471863746643, "training_acc": 53.0, "val_loss": 17.258501052856445, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.08499240875244, "training_acc": 53.0, "val_loss": 17.257186770439148, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22511315345764, "training_acc": 53.0, "val_loss": 17.256568372249603, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.3008074760437, "training_acc": 53.0, "val_loss": 17.256297171115875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11614203453064, "training_acc": 53.0, "val_loss": 17.256872355937958, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16607236862183, "training_acc": 53.0, "val_loss": 17.25778579711914, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20747494697571, "training_acc": 53.0, "val_loss": 17.257846891880035, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16689682006836, "training_acc": 53.0, "val_loss": 17.258793115615845, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.2830822467804, "training_acc": 53.0, "val_loss": 17.259742319583893, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16931676864624, "training_acc": 53.0, "val_loss": 17.260660231113434, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16628384590149, "training_acc": 53.0, "val_loss": 17.26052016019821, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21533465385437, "training_acc": 53.0, "val_loss": 17.260612547397614, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13963294029236, "training_acc": 53.0, "val_loss": 17.260943353176117, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2627158164978, "training_acc": 53.0, "val_loss": 17.26076900959015, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.06768941879272, "training_acc": 53.0, "val_loss": 17.261146008968353, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12397718429565, "training_acc": 53.0, "val_loss": 17.26204603910446, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1277813911438, "training_acc": 53.0, "val_loss": 17.262396216392517, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14179801940918, "training_acc": 53.0, "val_loss": 17.26183146238327, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.217524766922, "training_acc": 53.0, "val_loss": 17.2612726688385, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.04932618141174, "training_acc": 53.0, "val_loss": 17.260709404945374, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.22181105613708, "training_acc": 53.0, "val_loss": 17.260822653770447, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1969826221466, "training_acc": 53.0, "val_loss": 17.260701954364777, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.19738388061523, "training_acc": 53.0, "val_loss": 17.261867225170135, "val_acc": 52.0}
