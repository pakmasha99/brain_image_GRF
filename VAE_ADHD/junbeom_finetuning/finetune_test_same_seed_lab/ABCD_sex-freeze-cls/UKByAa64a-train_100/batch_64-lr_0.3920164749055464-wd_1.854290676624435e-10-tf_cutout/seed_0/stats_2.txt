"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 895.537956237793, "training_acc": 47.0, "val_loss": 204.10072803497314, "val_acc": 52.0}
{"epoch": 1, "training_loss": 980.2360992431641, "training_acc": 47.0, "val_loss": 369.7766065597534, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1311.6632118225098, "training_acc": 47.0, "val_loss": 36.85567378997803, "val_acc": 48.0}
{"epoch": 3, "training_loss": 359.2688274383545, "training_acc": 52.0, "val_loss": 369.7469711303711, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1479.4709548950195, "training_acc": 53.0, "val_loss": 318.62804889678955, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1024.2740840911865, "training_acc": 53.0, "val_loss": 45.075881481170654, "val_acc": 48.0}
{"epoch": 6, "training_loss": 374.10984802246094, "training_acc": 47.0, "val_loss": 150.39275884628296, "val_acc": 48.0}
{"epoch": 7, "training_loss": 488.2395544052124, "training_acc": 47.0, "val_loss": 93.41718554496765, "val_acc": 52.0}
{"epoch": 8, "training_loss": 410.1563415527344, "training_acc": 53.0, "val_loss": 146.55660390853882, "val_acc": 52.0}
{"epoch": 9, "training_loss": 448.65875148773193, "training_acc": 53.0, "val_loss": 48.14705550670624, "val_acc": 48.0}
{"epoch": 10, "training_loss": 284.28947830200195, "training_acc": 47.0, "val_loss": 61.30363941192627, "val_acc": 48.0}
{"epoch": 11, "training_loss": 206.57684326171875, "training_acc": 51.0, "val_loss": 71.29114866256714, "val_acc": 52.0}
{"epoch": 12, "training_loss": 219.54355478286743, "training_acc": 53.0, "val_loss": 39.779579639434814, "val_acc": 48.0}
{"epoch": 13, "training_loss": 172.64163064956665, "training_acc": 47.0, "val_loss": 17.100395262241364, "val_acc": 64.0}
{"epoch": 14, "training_loss": 102.57558822631836, "training_acc": 64.0, "val_loss": 28.279170393943787, "val_acc": 52.0}
{"epoch": 15, "training_loss": 129.1478271484375, "training_acc": 48.0, "val_loss": 34.330686926841736, "val_acc": 48.0}
{"epoch": 16, "training_loss": 133.88485717773438, "training_acc": 46.0, "val_loss": 36.29457354545593, "val_acc": 52.0}
{"epoch": 17, "training_loss": 101.67493605613708, "training_acc": 55.0, "val_loss": 35.639914870262146, "val_acc": 48.0}
{"epoch": 18, "training_loss": 105.5720956325531, "training_acc": 55.0, "val_loss": 42.204996943473816, "val_acc": 52.0}
{"epoch": 19, "training_loss": 125.77883768081665, "training_acc": 53.0, "val_loss": 39.08323645591736, "val_acc": 48.0}
{"epoch": 20, "training_loss": 149.93218183517456, "training_acc": 50.0, "val_loss": 30.469238758087158, "val_acc": 52.0}
{"epoch": 21, "training_loss": 129.31528759002686, "training_acc": 53.0, "val_loss": 17.662201821804047, "val_acc": 48.0}
{"epoch": 22, "training_loss": 93.70887994766235, "training_acc": 60.0, "val_loss": 17.374499142169952, "val_acc": 64.0}
{"epoch": 23, "training_loss": 83.06046104431152, "training_acc": 65.0, "val_loss": 22.333605587482452, "val_acc": 52.0}
{"epoch": 24, "training_loss": 82.38058233261108, "training_acc": 58.0, "val_loss": 18.943583965301514, "val_acc": 60.0}
{"epoch": 25, "training_loss": 94.38299942016602, "training_acc": 54.0, "val_loss": 32.60006010532379, "val_acc": 52.0}
{"epoch": 26, "training_loss": 96.52577829360962, "training_acc": 55.0, "val_loss": 21.194711327552795, "val_acc": 56.0}
{"epoch": 27, "training_loss": 120.64495801925659, "training_acc": 46.0, "val_loss": 25.480371713638306, "val_acc": 52.0}
{"epoch": 28, "training_loss": 80.63096952438354, "training_acc": 58.0, "val_loss": 18.95843893289566, "val_acc": 60.0}
{"epoch": 29, "training_loss": 91.93981122970581, "training_acc": 56.0, "val_loss": 27.231094241142273, "val_acc": 52.0}
{"epoch": 30, "training_loss": 96.94315576553345, "training_acc": 49.0, "val_loss": 18.430057168006897, "val_acc": 52.0}
{"epoch": 31, "training_loss": 102.65508508682251, "training_acc": 56.0, "val_loss": 28.485602140426636, "val_acc": 52.0}
{"epoch": 32, "training_loss": 79.02632784843445, "training_acc": 60.0, "val_loss": 33.09224247932434, "val_acc": 48.0}
