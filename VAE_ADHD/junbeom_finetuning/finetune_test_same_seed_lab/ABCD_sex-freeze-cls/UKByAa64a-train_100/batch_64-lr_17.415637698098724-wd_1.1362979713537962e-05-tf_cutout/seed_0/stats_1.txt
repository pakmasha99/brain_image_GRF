"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 36621.65202713013, "training_acc": 46.0, "val_loss": 7640.4998779296875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 37124.08544921875, "training_acc": 53.0, "val_loss": 19804.498291015625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 74527.10888671875, "training_acc": 47.0, "val_loss": 5485.823440551758, "val_acc": 48.0}
{"epoch": 3, "training_loss": 25962.368896484375, "training_acc": 51.0, "val_loss": 14462.223815917969, "val_acc": 52.0}
{"epoch": 4, "training_loss": 54945.8330078125, "training_acc": 53.0, "val_loss": 12899.31640625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 38280.31396484375, "training_acc": 53.0, "val_loss": 2250.7577896118164, "val_acc": 48.0}
{"epoch": 6, "training_loss": 20691.4111328125, "training_acc": 47.0, "val_loss": 6615.9332275390625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 22418.370361328125, "training_acc": 47.0, "val_loss": 4784.255599975586, "val_acc": 52.0}
{"epoch": 8, "training_loss": 18660.854553222656, "training_acc": 53.0, "val_loss": 8296.599578857422, "val_acc": 52.0}
{"epoch": 9, "training_loss": 26942.492248535156, "training_acc": 53.0, "val_loss": 1036.5345001220703, "val_acc": 52.0}
{"epoch": 10, "training_loss": 10780.411254882812, "training_acc": 49.0, "val_loss": 7730.254364013672, "val_acc": 48.0}
{"epoch": 11, "training_loss": 29610.586791992188, "training_acc": 47.0, "val_loss": 1644.0839767456055, "val_acc": 48.0}
{"epoch": 12, "training_loss": 10728.15234375, "training_acc": 49.0, "val_loss": 8118.338775634766, "val_acc": 52.0}
{"epoch": 13, "training_loss": 31217.459228515625, "training_acc": 53.0, "val_loss": 6081.452560424805, "val_acc": 52.0}
{"epoch": 14, "training_loss": 16321.29923248291, "training_acc": 52.0, "val_loss": 6007.902145385742, "val_acc": 48.0}
{"epoch": 15, "training_loss": 29266.9423828125, "training_acc": 47.0, "val_loss": 8957.485961914062, "val_acc": 48.0}
{"epoch": 16, "training_loss": 30283.415954589844, "training_acc": 47.0, "val_loss": 727.6391983032227, "val_acc": 60.0}
{"epoch": 17, "training_loss": 7604.953674316406, "training_acc": 56.0, "val_loss": 5550.944137573242, "val_acc": 52.0}
{"epoch": 18, "training_loss": 18289.304321289062, "training_acc": 53.0, "val_loss": 363.9341115951538, "val_acc": 40.0}
{"epoch": 19, "training_loss": 4658.310150146484, "training_acc": 62.0, "val_loss": 2636.6127014160156, "val_acc": 48.0}
{"epoch": 20, "training_loss": 8811.480247497559, "training_acc": 46.0, "val_loss": 1836.0971450805664, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3509.680404663086, "training_acc": 58.0, "val_loss": 1766.1981582641602, "val_acc": 48.0}
{"epoch": 22, "training_loss": 5907.978988647461, "training_acc": 50.0, "val_loss": 2973.379898071289, "val_acc": 52.0}
{"epoch": 23, "training_loss": 10221.562744140625, "training_acc": 53.0, "val_loss": 1711.788558959961, "val_acc": 52.0}
{"epoch": 24, "training_loss": 7078.588836669922, "training_acc": 51.0, "val_loss": 3405.2913665771484, "val_acc": 48.0}
{"epoch": 25, "training_loss": 9699.660675048828, "training_acc": 48.0, "val_loss": 4001.6403198242188, "val_acc": 52.0}
{"epoch": 26, "training_loss": 15471.884887695312, "training_acc": 53.0, "val_loss": 4992.43049621582, "val_acc": 52.0}
{"epoch": 27, "training_loss": 12033.134338378906, "training_acc": 54.0, "val_loss": 3688.8572692871094, "val_acc": 48.0}
{"epoch": 28, "training_loss": 17732.326782226562, "training_acc": 47.0, "val_loss": 4388.150405883789, "val_acc": 48.0}
{"epoch": 29, "training_loss": 11581.22981262207, "training_acc": 50.0, "val_loss": 5726.55029296875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 23760.665771484375, "training_acc": 53.0, "val_loss": 8985.787963867188, "val_acc": 52.0}
{"epoch": 31, "training_loss": 28579.55926513672, "training_acc": 53.0, "val_loss": 2139.442825317383, "val_acc": 56.0}
{"epoch": 32, "training_loss": 9421.574157714844, "training_acc": 54.0, "val_loss": 7357.382965087891, "val_acc": 48.0}
{"epoch": 33, "training_loss": 27909.92218017578, "training_acc": 47.0, "val_loss": 3481.4815521240234, "val_acc": 48.0}
{"epoch": 34, "training_loss": 15468.52734375, "training_acc": 37.0, "val_loss": 4758.576202392578, "val_acc": 52.0}
{"epoch": 35, "training_loss": 16049.138488769531, "training_acc": 52.0, "val_loss": 1132.6037406921387, "val_acc": 60.0}
{"epoch": 36, "training_loss": 5968.170501708984, "training_acc": 56.0, "val_loss": 4022.275161743164, "val_acc": 48.0}
{"epoch": 37, "training_loss": 13298.030792236328, "training_acc": 47.0, "val_loss": 3039.348602294922, "val_acc": 52.0}
