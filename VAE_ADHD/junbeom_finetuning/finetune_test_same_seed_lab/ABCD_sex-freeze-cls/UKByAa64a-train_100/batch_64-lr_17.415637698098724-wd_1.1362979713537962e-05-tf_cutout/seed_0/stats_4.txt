"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 20548.70599746704, "training_acc": 53.0, "val_loss": 4408.853912353516, "val_acc": 48.0}
{"epoch": 1, "training_loss": 16913.242431640625, "training_acc": 47.0, "val_loss": 8567.131805419922, "val_acc": 52.0}
{"epoch": 2, "training_loss": 31848.594116210938, "training_acc": 53.0, "val_loss": 5644.337844848633, "val_acc": 52.0}
{"epoch": 3, "training_loss": 17007.683563232422, "training_acc": 51.0, "val_loss": 4013.8229370117188, "val_acc": 48.0}
{"epoch": 4, "training_loss": 13159.79613494873, "training_acc": 47.0, "val_loss": 3066.8067932128906, "val_acc": 52.0}
{"epoch": 5, "training_loss": 8378.360321044922, "training_acc": 54.0, "val_loss": 2865.519905090332, "val_acc": 48.0}
{"epoch": 6, "training_loss": 12668.589294433594, "training_acc": 47.0, "val_loss": 585.6560707092285, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3989.297637939453, "training_acc": 58.0, "val_loss": 801.3272285461426, "val_acc": 52.0}
{"epoch": 8, "training_loss": 5481.074554443359, "training_acc": 58.0, "val_loss": 3259.5333099365234, "val_acc": 48.0}
{"epoch": 9, "training_loss": 9014.98860168457, "training_acc": 53.0, "val_loss": 2362.60986328125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6558.88081741333, "training_acc": 55.0, "val_loss": 2682.549285888672, "val_acc": 48.0}
{"epoch": 11, "training_loss": 9214.671371459961, "training_acc": 47.0, "val_loss": 1644.1143035888672, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5914.049407958984, "training_acc": 54.0, "val_loss": 692.7368640899658, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3451.618118286133, "training_acc": 50.0, "val_loss": 2223.9267349243164, "val_acc": 52.0}
{"epoch": 14, "training_loss": 8080.625061035156, "training_acc": 53.0, "val_loss": 538.0029201507568, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2066.875877380371, "training_acc": 56.0, "val_loss": 1276.7013549804688, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3174.552894592285, "training_acc": 60.0, "val_loss": 2177.9415130615234, "val_acc": 48.0}
{"epoch": 17, "training_loss": 8192.558044433594, "training_acc": 47.0, "val_loss": 2093.617630004883, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7464.466979980469, "training_acc": 53.0, "val_loss": 440.3846263885498, "val_acc": 60.0}
{"epoch": 19, "training_loss": 4127.7750244140625, "training_acc": 65.0, "val_loss": 1962.2936248779297, "val_acc": 48.0}
{"epoch": 20, "training_loss": 7354.107879638672, "training_acc": 48.0, "val_loss": 2190.4787063598633, "val_acc": 52.0}
{"epoch": 21, "training_loss": 4966.3903884887695, "training_acc": 54.0, "val_loss": 1475.960922241211, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3931.804401397705, "training_acc": 55.0, "val_loss": 885.0058555603027, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3206.252716064453, "training_acc": 50.0, "val_loss": 412.7225875854492, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1260.303020477295, "training_acc": 66.0, "val_loss": 328.26571464538574, "val_acc": 48.0}
{"epoch": 25, "training_loss": 954.9552574157715, "training_acc": 62.0, "val_loss": 224.38442707061768, "val_acc": 48.0}
{"epoch": 26, "training_loss": 865.2494621276855, "training_acc": 69.0, "val_loss": 314.5750045776367, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1561.036262512207, "training_acc": 56.0, "val_loss": 1611.5503311157227, "val_acc": 52.0}
{"epoch": 28, "training_loss": 3976.7429580688477, "training_acc": 54.0, "val_loss": 2403.0956268310547, "val_acc": 48.0}
{"epoch": 29, "training_loss": 8793.23373413086, "training_acc": 47.0, "val_loss": 1881.9005966186523, "val_acc": 52.0}
{"epoch": 30, "training_loss": 6085.612197875977, "training_acc": 53.0, "val_loss": 240.42580127716064, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1941.5675811767578, "training_acc": 73.0, "val_loss": 409.91153717041016, "val_acc": 56.0}
{"epoch": 32, "training_loss": 2687.9391326904297, "training_acc": 61.0, "val_loss": 312.07714080810547, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1051.631031036377, "training_acc": 65.0, "val_loss": 1266.8333053588867, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2300.481023788452, "training_acc": 61.0, "val_loss": 1996.560287475586, "val_acc": 48.0}
{"epoch": 35, "training_loss": 5106.268257141113, "training_acc": 50.0, "val_loss": 3141.737747192383, "val_acc": 52.0}
{"epoch": 36, "training_loss": 11852.232971191406, "training_acc": 53.0, "val_loss": 1116.4643287658691, "val_acc": 52.0}
{"epoch": 37, "training_loss": 4359.3662109375, "training_acc": 64.0, "val_loss": 5721.643447875977, "val_acc": 48.0}
{"epoch": 38, "training_loss": 18950.774475097656, "training_acc": 49.0, "val_loss": 261.8696928024292, "val_acc": 56.0}
{"epoch": 39, "training_loss": 5461.128601074219, "training_acc": 69.0, "val_loss": 3105.451011657715, "val_acc": 52.0}
{"epoch": 40, "training_loss": 8886.49732208252, "training_acc": 58.0, "val_loss": 4131.759262084961, "val_acc": 48.0}
{"epoch": 41, "training_loss": 17412.376220703125, "training_acc": 46.0, "val_loss": 2192.9779052734375, "val_acc": 48.0}
{"epoch": 42, "training_loss": 7983.02880859375, "training_acc": 55.0, "val_loss": 5905.378341674805, "val_acc": 52.0}
{"epoch": 43, "training_loss": 22707.878051757812, "training_acc": 53.0, "val_loss": 1994.2939758300781, "val_acc": 52.0}
{"epoch": 44, "training_loss": 8827.73095703125, "training_acc": 55.0, "val_loss": 6623.884582519531, "val_acc": 48.0}
