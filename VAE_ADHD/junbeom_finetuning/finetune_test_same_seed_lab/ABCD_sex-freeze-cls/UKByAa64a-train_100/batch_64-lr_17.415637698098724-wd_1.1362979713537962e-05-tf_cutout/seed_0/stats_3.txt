"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 39864.29556274414, "training_acc": 45.0, "val_loss": 9666.902160644531, "val_acc": 52.0}
{"epoch": 1, "training_loss": 36014.439697265625, "training_acc": 55.0, "val_loss": 16733.38623046875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 62359.77490234375, "training_acc": 47.0, "val_loss": 2379.25968170166, "val_acc": 48.0}
{"epoch": 3, "training_loss": 22793.862182617188, "training_acc": 47.0, "val_loss": 17185.31951904297, "val_acc": 52.0}
{"epoch": 4, "training_loss": 62751.039794921875, "training_acc": 53.0, "val_loss": 14776.06201171875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 44709.658935546875, "training_acc": 53.0, "val_loss": 1211.070728302002, "val_acc": 48.0}
{"epoch": 6, "training_loss": 13186.772583007812, "training_acc": 46.0, "val_loss": 5145.091247558594, "val_acc": 48.0}
{"epoch": 7, "training_loss": 16694.66958618164, "training_acc": 49.0, "val_loss": 5656.048583984375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 17485.875061035156, "training_acc": 55.0, "val_loss": 7190.910339355469, "val_acc": 52.0}
{"epoch": 9, "training_loss": 15786.445343017578, "training_acc": 57.0, "val_loss": 1923.5734939575195, "val_acc": 48.0}
{"epoch": 10, "training_loss": 13901.548889160156, "training_acc": 46.0, "val_loss": 1062.1390342712402, "val_acc": 36.0}
{"epoch": 11, "training_loss": 6771.2471923828125, "training_acc": 60.0, "val_loss": 6471.295928955078, "val_acc": 52.0}
{"epoch": 12, "training_loss": 16299.3037109375, "training_acc": 53.0, "val_loss": 2634.1787338256836, "val_acc": 52.0}
{"epoch": 13, "training_loss": 8259.049285888672, "training_acc": 49.0, "val_loss": 2356.4233779907227, "val_acc": 48.0}
{"epoch": 14, "training_loss": 8655.576217651367, "training_acc": 51.0, "val_loss": 3478.246307373047, "val_acc": 52.0}
{"epoch": 15, "training_loss": 7703.541275024414, "training_acc": 53.0, "val_loss": 435.96744537353516, "val_acc": 40.0}
{"epoch": 16, "training_loss": 2651.758071899414, "training_acc": 55.0, "val_loss": 2304.1208267211914, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5418.401672363281, "training_acc": 54.0, "val_loss": 1281.9355010986328, "val_acc": 48.0}
{"epoch": 18, "training_loss": 4875.568466186523, "training_acc": 47.0, "val_loss": 2292.91934967041, "val_acc": 52.0}
{"epoch": 19, "training_loss": 6695.229797363281, "training_acc": 52.0, "val_loss": 714.7315979003906, "val_acc": 52.0}
{"epoch": 20, "training_loss": 4150.98371887207, "training_acc": 46.0, "val_loss": 2432.199478149414, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6866.45198059082, "training_acc": 53.0, "val_loss": 407.16686248779297, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2614.7577514648438, "training_acc": 50.0, "val_loss": 552.2618293762207, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3384.8121185302734, "training_acc": 51.0, "val_loss": 1468.9035415649414, "val_acc": 52.0}
{"epoch": 24, "training_loss": 3485.8031005859375, "training_acc": 52.0, "val_loss": 638.3020401000977, "val_acc": 36.0}
{"epoch": 25, "training_loss": 3989.0580139160156, "training_acc": 55.0, "val_loss": 1071.3380813598633, "val_acc": 52.0}
{"epoch": 26, "training_loss": 3069.5824279785156, "training_acc": 58.0, "val_loss": 565.9465312957764, "val_acc": 32.0}
{"epoch": 27, "training_loss": 3573.8565979003906, "training_acc": 52.0, "val_loss": 1517.3837661743164, "val_acc": 52.0}
{"epoch": 28, "training_loss": 4779.342468261719, "training_acc": 58.0, "val_loss": 2393.9037322998047, "val_acc": 48.0}
{"epoch": 29, "training_loss": 8319.819450378418, "training_acc": 47.0, "val_loss": 2096.002960205078, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3469.9028396606445, "training_acc": 55.0, "val_loss": 606.1381816864014, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1054.7192573547363, "training_acc": 72.0, "val_loss": 395.1486825942993, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1891.612907409668, "training_acc": 59.0, "val_loss": 271.25189304351807, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1863.0809326171875, "training_acc": 51.0, "val_loss": 510.97211837768555, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1556.9784355163574, "training_acc": 59.0, "val_loss": 210.9553575515747, "val_acc": 52.0}
{"epoch": 35, "training_loss": 768.5568866729736, "training_acc": 75.0, "val_loss": 907.8769683837891, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1162.3194618225098, "training_acc": 66.0, "val_loss": 403.8586139678955, "val_acc": 52.0}
{"epoch": 37, "training_loss": 781.3828163146973, "training_acc": 69.0, "val_loss": 231.43575191497803, "val_acc": 56.0}
{"epoch": 38, "training_loss": 1563.3687896728516, "training_acc": 64.0, "val_loss": 540.7456398010254, "val_acc": 52.0}
{"epoch": 39, "training_loss": 3646.297607421875, "training_acc": 61.0, "val_loss": 161.0696315765381, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3222.827880859375, "training_acc": 66.0, "val_loss": 1465.7654762268066, "val_acc": 52.0}
{"epoch": 41, "training_loss": 4325.786682128906, "training_acc": 61.0, "val_loss": 2457.298469543457, "val_acc": 48.0}
{"epoch": 42, "training_loss": 7209.651203155518, "training_acc": 50.0, "val_loss": 1208.7838172912598, "val_acc": 52.0}
{"epoch": 43, "training_loss": 4736.607879638672, "training_acc": 45.0, "val_loss": 210.73029041290283, "val_acc": 48.0}
{"epoch": 44, "training_loss": 2367.764846801758, "training_acc": 64.0, "val_loss": 1523.1764793395996, "val_acc": 52.0}
{"epoch": 45, "training_loss": 5492.354888916016, "training_acc": 53.0, "val_loss": 1696.1355209350586, "val_acc": 48.0}
{"epoch": 46, "training_loss": 5850.569000244141, "training_acc": 54.0, "val_loss": 2457.682228088379, "val_acc": 52.0}
{"epoch": 47, "training_loss": 3939.920991897583, "training_acc": 64.0, "val_loss": 2251.833724975586, "val_acc": 48.0}
{"epoch": 48, "training_loss": 7663.628910064697, "training_acc": 48.0, "val_loss": 3298.1075286865234, "val_acc": 52.0}
{"epoch": 49, "training_loss": 10214.05517578125, "training_acc": 53.0, "val_loss": 1131.0917854309082, "val_acc": 52.0}
{"epoch": 50, "training_loss": 6576.928283691406, "training_acc": 51.0, "val_loss": 3868.050765991211, "val_acc": 48.0}
{"epoch": 51, "training_loss": 11696.669715881348, "training_acc": 47.0, "val_loss": 5165.601348876953, "val_acc": 52.0}
{"epoch": 52, "training_loss": 19444.849487304688, "training_acc": 53.0, "val_loss": 6606.9122314453125, "val_acc": 52.0}
{"epoch": 53, "training_loss": 16852.089416503906, "training_acc": 53.0, "val_loss": 3149.6288299560547, "val_acc": 48.0}
{"epoch": 54, "training_loss": 17182.027282714844, "training_acc": 47.0, "val_loss": 3761.459732055664, "val_acc": 48.0}
{"epoch": 55, "training_loss": 11019.373062133789, "training_acc": 53.0, "val_loss": 4309.69123840332, "val_acc": 52.0}
{"epoch": 56, "training_loss": 11915.298461914062, "training_acc": 53.0, "val_loss": 1221.4767456054688, "val_acc": 52.0}
{"epoch": 57, "training_loss": 4388.240173339844, "training_acc": 62.0, "val_loss": 2717.5121307373047, "val_acc": 48.0}
{"epoch": 58, "training_loss": 8095.31436920166, "training_acc": 60.0, "val_loss": 4401.661682128906, "val_acc": 52.0}
