"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 577.7502822875977, "training_acc": 46.0, "val_loss": 111.34545803070068, "val_acc": 52.0}
{"epoch": 1, "training_loss": 541.6107139587402, "training_acc": 53.0, "val_loss": 288.76702785491943, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1086.3264541625977, "training_acc": 47.0, "val_loss": 80.06176352500916, "val_acc": 48.0}
{"epoch": 3, "training_loss": 378.34236240386963, "training_acc": 51.0, "val_loss": 210.81316471099854, "val_acc": 52.0}
{"epoch": 4, "training_loss": 801.6446685791016, "training_acc": 53.0, "val_loss": 188.10065984725952, "val_acc": 52.0}
{"epoch": 5, "training_loss": 558.932222366333, "training_acc": 53.0, "val_loss": 34.650346636772156, "val_acc": 48.0}
{"epoch": 6, "training_loss": 313.18181800842285, "training_acc": 47.0, "val_loss": 106.3145399093628, "val_acc": 48.0}
{"epoch": 7, "training_loss": 369.80224609375, "training_acc": 47.0, "val_loss": 54.175132513046265, "val_acc": 52.0}
{"epoch": 8, "training_loss": 215.60426425933838, "training_acc": 53.0, "val_loss": 102.13607549667358, "val_acc": 52.0}
{"epoch": 9, "training_loss": 320.91747999191284, "training_acc": 53.0, "val_loss": 18.174941837787628, "val_acc": 56.0}
{"epoch": 10, "training_loss": 141.5196704864502, "training_acc": 50.0, "val_loss": 45.082589983940125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 165.2115330696106, "training_acc": 45.0, "val_loss": 44.673773646354675, "val_acc": 52.0}
{"epoch": 12, "training_loss": 144.51696968078613, "training_acc": 53.0, "val_loss": 18.16318780183792, "val_acc": 52.0}
{"epoch": 13, "training_loss": 83.60999083518982, "training_acc": 51.0, "val_loss": 20.077064633369446, "val_acc": 44.0}
{"epoch": 14, "training_loss": 77.24936628341675, "training_acc": 57.0, "val_loss": 31.036829948425293, "val_acc": 52.0}
{"epoch": 15, "training_loss": 91.8425121307373, "training_acc": 55.0, "val_loss": 21.226313710212708, "val_acc": 52.0}
{"epoch": 16, "training_loss": 84.69234585762024, "training_acc": 51.0, "val_loss": 23.291262984275818, "val_acc": 52.0}
{"epoch": 17, "training_loss": 82.713223695755, "training_acc": 55.0, "val_loss": 16.577960550785065, "val_acc": 64.0}
{"epoch": 18, "training_loss": 91.94059753417969, "training_acc": 47.0, "val_loss": 20.991402864456177, "val_acc": 52.0}
{"epoch": 19, "training_loss": 89.59588384628296, "training_acc": 56.0, "val_loss": 18.987499177455902, "val_acc": 56.0}
{"epoch": 20, "training_loss": 65.25611567497253, "training_acc": 64.0, "val_loss": 21.620143949985504, "val_acc": 48.0}
{"epoch": 21, "training_loss": 89.1887092590332, "training_acc": 53.0, "val_loss": 26.996532082557678, "val_acc": 52.0}
{"epoch": 22, "training_loss": 78.92646884918213, "training_acc": 61.0, "val_loss": 18.874137103557587, "val_acc": 48.0}
{"epoch": 23, "training_loss": 71.7933657169342, "training_acc": 58.0, "val_loss": 19.882260262966156, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.55674576759338, "training_acc": 59.0, "val_loss": 17.39005595445633, "val_acc": 64.0}
{"epoch": 25, "training_loss": 63.32288455963135, "training_acc": 63.0, "val_loss": 19.67523843050003, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.05996656417847, "training_acc": 59.0, "val_loss": 17.955787479877472, "val_acc": 56.0}
{"epoch": 27, "training_loss": 63.64203357696533, "training_acc": 61.0, "val_loss": 17.112162709236145, "val_acc": 64.0}
{"epoch": 28, "training_loss": 62.99779939651489, "training_acc": 60.0, "val_loss": 17.346279323101044, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.895562410354614, "training_acc": 63.0, "val_loss": 23.488135635852814, "val_acc": 52.0}
{"epoch": 30, "training_loss": 77.28646183013916, "training_acc": 56.0, "val_loss": 18.277278542518616, "val_acc": 48.0}
{"epoch": 31, "training_loss": 65.88544392585754, "training_acc": 61.0, "val_loss": 25.06462037563324, "val_acc": 52.0}
{"epoch": 32, "training_loss": 77.92937397956848, "training_acc": 54.0, "val_loss": 22.275598347187042, "val_acc": 48.0}
{"epoch": 33, "training_loss": 83.22900772094727, "training_acc": 44.0, "val_loss": 20.823009312152863, "val_acc": 52.0}
{"epoch": 34, "training_loss": 75.92240118980408, "training_acc": 56.0, "val_loss": 27.505171298980713, "val_acc": 48.0}
{"epoch": 35, "training_loss": 104.63274788856506, "training_acc": 47.0, "val_loss": 28.78752052783966, "val_acc": 52.0}
{"epoch": 36, "training_loss": 97.28136968612671, "training_acc": 53.0, "val_loss": 19.154146313667297, "val_acc": 48.0}
