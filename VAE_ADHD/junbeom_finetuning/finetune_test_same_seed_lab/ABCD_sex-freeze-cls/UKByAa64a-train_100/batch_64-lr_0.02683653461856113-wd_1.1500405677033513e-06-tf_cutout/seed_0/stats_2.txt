"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 117.36083984375, "training_acc": 43.0, "val_loss": 20.680072903633118, "val_acc": 48.0}
{"epoch": 1, "training_loss": 89.24635434150696, "training_acc": 45.0, "val_loss": 30.241599678993225, "val_acc": 52.0}
{"epoch": 2, "training_loss": 115.68914365768433, "training_acc": 53.0, "val_loss": 21.912585198879242, "val_acc": 52.0}
{"epoch": 3, "training_loss": 81.32177186012268, "training_acc": 51.0, "val_loss": 20.903317630290985, "val_acc": 48.0}
{"epoch": 4, "training_loss": 86.70453572273254, "training_acc": 48.0, "val_loss": 23.864170908927917, "val_acc": 48.0}
{"epoch": 5, "training_loss": 85.82087278366089, "training_acc": 50.0, "val_loss": 17.95763373374939, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.56841278076172, "training_acc": 50.0, "val_loss": 20.070412755012512, "val_acc": 52.0}
{"epoch": 7, "training_loss": 79.40361905097961, "training_acc": 53.0, "val_loss": 19.528646767139435, "val_acc": 52.0}
{"epoch": 8, "training_loss": 74.35646414756775, "training_acc": 54.0, "val_loss": 17.931614816188812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.09782814979553, "training_acc": 46.0, "val_loss": 19.6207195520401, "val_acc": 40.0}
{"epoch": 10, "training_loss": 75.40964531898499, "training_acc": 46.0, "val_loss": 18.07994842529297, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.7873923778534, "training_acc": 53.0, "val_loss": 18.022963404655457, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.72694063186646, "training_acc": 53.0, "val_loss": 18.458503484725952, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.90145826339722, "training_acc": 54.0, "val_loss": 17.415407299995422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 67.80441308021545, "training_acc": 56.0, "val_loss": 18.218615651130676, "val_acc": 48.0}
{"epoch": 15, "training_loss": 71.20988535881042, "training_acc": 50.0, "val_loss": 17.60774552822113, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.34117102622986, "training_acc": 55.0, "val_loss": 17.309626936912537, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.0458607673645, "training_acc": 55.0, "val_loss": 17.45646595954895, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.80013370513916, "training_acc": 55.0, "val_loss": 17.267614603042603, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.49077701568604, "training_acc": 60.0, "val_loss": 17.255063354969025, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.37319302558899, "training_acc": 62.0, "val_loss": 17.285382747650146, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.77025532722473, "training_acc": 57.0, "val_loss": 17.273172736167908, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.7168562412262, "training_acc": 62.0, "val_loss": 17.47005432844162, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.31184101104736, "training_acc": 53.0, "val_loss": 17.55261719226837, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.63671588897705, "training_acc": 56.0, "val_loss": 17.440028488636017, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.14142155647278, "training_acc": 52.0, "val_loss": 17.759297788143158, "val_acc": 60.0}
{"epoch": 26, "training_loss": 68.94657635688782, "training_acc": 52.0, "val_loss": 17.339488863945007, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.25940775871277, "training_acc": 58.0, "val_loss": 18.92494559288025, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.97030329704285, "training_acc": 53.0, "val_loss": 17.366690933704376, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.88666653633118, "training_acc": 50.0, "val_loss": 17.56332367658615, "val_acc": 56.0}
{"epoch": 30, "training_loss": 67.35499310493469, "training_acc": 56.0, "val_loss": 17.29329824447632, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.35110592842102, "training_acc": 53.0, "val_loss": 17.977042496204376, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.16834378242493, "training_acc": 54.0, "val_loss": 17.363575100898743, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.46833300590515, "training_acc": 64.0, "val_loss": 17.948399484157562, "val_acc": 48.0}
{"epoch": 34, "training_loss": 68.31369638442993, "training_acc": 58.0, "val_loss": 17.461664974689484, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.81309223175049, "training_acc": 56.0, "val_loss": 17.605461180210114, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.02357602119446, "training_acc": 53.0, "val_loss": 17.50483214855194, "val_acc": 52.0}
{"epoch": 37, "training_loss": 67.94565653800964, "training_acc": 58.0, "val_loss": 17.172768712043762, "val_acc": 52.0}
{"epoch": 38, "training_loss": 66.62479329109192, "training_acc": 61.0, "val_loss": 17.070002853870392, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.00002312660217, "training_acc": 67.0, "val_loss": 17.03541874885559, "val_acc": 52.0}
{"epoch": 40, "training_loss": 64.7524106502533, "training_acc": 62.0, "val_loss": 17.10781455039978, "val_acc": 52.0}
{"epoch": 41, "training_loss": 64.19937586784363, "training_acc": 66.0, "val_loss": 16.899237036705017, "val_acc": 52.0}
{"epoch": 42, "training_loss": 66.4943859577179, "training_acc": 58.0, "val_loss": 16.910453140735626, "val_acc": 52.0}
{"epoch": 43, "training_loss": 65.36729788780212, "training_acc": 65.0, "val_loss": 17.09192246198654, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.02084589004517, "training_acc": 63.0, "val_loss": 17.173786461353302, "val_acc": 52.0}
{"epoch": 45, "training_loss": 67.09069442749023, "training_acc": 57.0, "val_loss": 17.097747325897217, "val_acc": 56.0}
{"epoch": 46, "training_loss": 65.23225140571594, "training_acc": 57.0, "val_loss": 17.06359088420868, "val_acc": 52.0}
{"epoch": 47, "training_loss": 63.52734589576721, "training_acc": 67.0, "val_loss": 17.61493980884552, "val_acc": 52.0}
{"epoch": 48, "training_loss": 64.37824702262878, "training_acc": 57.0, "val_loss": 17.31962114572525, "val_acc": 52.0}
{"epoch": 49, "training_loss": 64.84974789619446, "training_acc": 66.0, "val_loss": 17.3446923494339, "val_acc": 60.0}
{"epoch": 50, "training_loss": 66.68982338905334, "training_acc": 61.0, "val_loss": 17.18709170818329, "val_acc": 52.0}
{"epoch": 51, "training_loss": 64.12530016899109, "training_acc": 75.0, "val_loss": 17.742566764354706, "val_acc": 52.0}
{"epoch": 52, "training_loss": 67.89781093597412, "training_acc": 52.0, "val_loss": 17.526575922966003, "val_acc": 52.0}
{"epoch": 53, "training_loss": 65.55031681060791, "training_acc": 58.0, "val_loss": 17.218483984470367, "val_acc": 56.0}
{"epoch": 54, "training_loss": 63.320231437683105, "training_acc": 73.0, "val_loss": 17.180001735687256, "val_acc": 56.0}
{"epoch": 55, "training_loss": 63.374247789382935, "training_acc": 73.0, "val_loss": 17.34209805727005, "val_acc": 52.0}
{"epoch": 56, "training_loss": 62.88509392738342, "training_acc": 64.0, "val_loss": 17.808009684085846, "val_acc": 52.0}
{"epoch": 57, "training_loss": 66.09477066993713, "training_acc": 58.0, "val_loss": 17.14865267276764, "val_acc": 52.0}
{"epoch": 58, "training_loss": 64.625333070755, "training_acc": 69.0, "val_loss": 17.711295187473297, "val_acc": 48.0}
{"epoch": 59, "training_loss": 67.2383201122284, "training_acc": 55.0, "val_loss": 17.141814529895782, "val_acc": 52.0}
{"epoch": 60, "training_loss": 62.8456974029541, "training_acc": 66.0, "val_loss": 19.305945932865143, "val_acc": 52.0}
