"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2286.6388778686523, "training_acc": 49.0, "val_loss": 497.88169860839844, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2638.818832397461, "training_acc": 49.0, "val_loss": 1147.210693359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4245.670959472656, "training_acc": 47.0, "val_loss": 218.68207454681396, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1127.2352981567383, "training_acc": 57.0, "val_loss": 1013.6233329772949, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4132.713180541992, "training_acc": 53.0, "val_loss": 954.8135757446289, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3155.1098251342773, "training_acc": 53.0, "val_loss": 30.715471506118774, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1151.9474639892578, "training_acc": 49.0, "val_loss": 1058.7905883789062, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4386.986068725586, "training_acc": 47.0, "val_loss": 951.4819145202637, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3283.050765991211, "training_acc": 47.0, "val_loss": 40.44708013534546, "val_acc": 48.0}
{"epoch": 9, "training_loss": 786.7469863891602, "training_acc": 55.0, "val_loss": 1004.4845581054688, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4173.963943481445, "training_acc": 53.0, "val_loss": 1193.7748908996582, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4418.827667236328, "training_acc": 53.0, "val_loss": 705.5110931396484, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2197.767358779907, "training_acc": 53.0, "val_loss": 368.65837574005127, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2118.4344329833984, "training_acc": 47.0, "val_loss": 824.7735023498535, "val_acc": 48.0}
{"epoch": 14, "training_loss": 3198.8451080322266, "training_acc": 47.0, "val_loss": 409.3667984008789, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1219.3556985855103, "training_acc": 45.0, "val_loss": 267.59254932403564, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1098.516658782959, "training_acc": 53.0, "val_loss": 175.2507448196411, "val_acc": 52.0}
{"epoch": 17, "training_loss": 622.7772617340088, "training_acc": 49.0, "val_loss": 185.30385494232178, "val_acc": 48.0}
{"epoch": 18, "training_loss": 573.5489320755005, "training_acc": 47.0, "val_loss": 219.80421543121338, "val_acc": 52.0}
{"epoch": 19, "training_loss": 948.0091781616211, "training_acc": 53.0, "val_loss": 248.58293533325195, "val_acc": 52.0}
{"epoch": 20, "training_loss": 728.2070686817169, "training_acc": 53.0, "val_loss": 279.7776460647583, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1270.888011932373, "training_acc": 47.0, "val_loss": 259.37371253967285, "val_acc": 48.0}
{"epoch": 22, "training_loss": 866.2916898727417, "training_acc": 39.0, "val_loss": 114.98836278915405, "val_acc": 52.0}
{"epoch": 23, "training_loss": 332.0551075935364, "training_acc": 53.0, "val_loss": 104.50944900512695, "val_acc": 48.0}
{"epoch": 24, "training_loss": 316.7724208831787, "training_acc": 47.0, "val_loss": 205.69052696228027, "val_acc": 52.0}
