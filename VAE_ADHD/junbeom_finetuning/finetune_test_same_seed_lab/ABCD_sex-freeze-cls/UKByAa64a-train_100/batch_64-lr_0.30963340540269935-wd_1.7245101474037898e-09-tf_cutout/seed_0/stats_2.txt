"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2813.1853523254395, "training_acc": 47.0, "val_loss": 509.79743003845215, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2416.77978515625, "training_acc": 51.0, "val_loss": 1320.7507133483887, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5117.079788208008, "training_acc": 53.0, "val_loss": 896.3370323181152, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2766.352123260498, "training_acc": 53.0, "val_loss": 560.667085647583, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2870.172653198242, "training_acc": 47.0, "val_loss": 946.1689949035645, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3468.6259231567383, "training_acc": 47.0, "val_loss": 178.25210094451904, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1169.0540237426758, "training_acc": 47.0, "val_loss": 790.9060001373291, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3193.7409591674805, "training_acc": 53.0, "val_loss": 784.4075679779053, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2752.6469955444336, "training_acc": 53.0, "val_loss": 111.01046800613403, "val_acc": 52.0}
{"epoch": 9, "training_loss": 789.2543411254883, "training_acc": 57.0, "val_loss": 751.5541076660156, "val_acc": 48.0}
{"epoch": 10, "training_loss": 3128.2585372924805, "training_acc": 47.0, "val_loss": 661.1778259277344, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2145.790786743164, "training_acc": 47.0, "val_loss": 151.44225358963013, "val_acc": 52.0}
{"epoch": 12, "training_loss": 879.5254364013672, "training_acc": 53.0, "val_loss": 478.81436347961426, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1753.0472412109375, "training_acc": 53.0, "val_loss": 150.3703474998474, "val_acc": 52.0}
{"epoch": 14, "training_loss": 657.6119346618652, "training_acc": 55.0, "val_loss": 415.8808708190918, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1644.3079795837402, "training_acc": 47.0, "val_loss": 158.94051790237427, "val_acc": 48.0}
{"epoch": 16, "training_loss": 795.4006500244141, "training_acc": 45.0, "val_loss": 382.2748899459839, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1478.0172233581543, "training_acc": 53.0, "val_loss": 198.76149892807007, "val_acc": 52.0}
{"epoch": 18, "training_loss": 702.3072261810303, "training_acc": 49.0, "val_loss": 227.9923915863037, "val_acc": 48.0}
{"epoch": 19, "training_loss": 802.5742378234863, "training_acc": 47.0, "val_loss": 122.8935718536377, "val_acc": 52.0}
{"epoch": 20, "training_loss": 597.6035556793213, "training_acc": 53.0, "val_loss": 143.88995170593262, "val_acc": 52.0}
{"epoch": 21, "training_loss": 441.62085151672363, "training_acc": 53.0, "val_loss": 95.27262449264526, "val_acc": 48.0}
{"epoch": 22, "training_loss": 395.6834936141968, "training_acc": 43.0, "val_loss": 45.224106311798096, "val_acc": 52.0}
{"epoch": 23, "training_loss": 314.0082130432129, "training_acc": 51.0, "val_loss": 121.23292684555054, "val_acc": 48.0}
{"epoch": 24, "training_loss": 394.08306884765625, "training_acc": 51.0, "val_loss": 87.21240758895874, "val_acc": 52.0}
{"epoch": 25, "training_loss": 415.12652015686035, "training_acc": 39.0, "val_loss": 17.319659888744354, "val_acc": 52.0}
{"epoch": 26, "training_loss": 173.16744804382324, "training_acc": 57.0, "val_loss": 22.05333709716797, "val_acc": 48.0}
{"epoch": 27, "training_loss": 81.01454854011536, "training_acc": 47.0, "val_loss": 51.20345950126648, "val_acc": 52.0}
{"epoch": 28, "training_loss": 182.70025205612183, "training_acc": 53.0, "val_loss": 31.55842423439026, "val_acc": 52.0}
{"epoch": 29, "training_loss": 114.00803279876709, "training_acc": 55.0, "val_loss": 43.61152648925781, "val_acc": 52.0}
{"epoch": 30, "training_loss": 201.63037109375, "training_acc": 47.0, "val_loss": 52.737510204315186, "val_acc": 52.0}
{"epoch": 31, "training_loss": 150.4680416584015, "training_acc": 53.0, "val_loss": 152.27138996124268, "val_acc": 48.0}
{"epoch": 32, "training_loss": 566.351598739624, "training_acc": 47.0, "val_loss": 95.82928419113159, "val_acc": 52.0}
{"epoch": 33, "training_loss": 383.56437397003174, "training_acc": 53.0, "val_loss": 17.346131801605225, "val_acc": 52.0}
{"epoch": 34, "training_loss": 255.0098361968994, "training_acc": 46.0, "val_loss": 28.909677267074585, "val_acc": 48.0}
{"epoch": 35, "training_loss": 274.20617866516113, "training_acc": 55.0, "val_loss": 231.67500495910645, "val_acc": 52.0}
{"epoch": 36, "training_loss": 760.9495515823364, "training_acc": 53.0, "val_loss": 138.35232257843018, "val_acc": 48.0}
{"epoch": 37, "training_loss": 626.2789897918701, "training_acc": 47.0, "val_loss": 39.53477144241333, "val_acc": 48.0}
{"epoch": 38, "training_loss": 359.1873321533203, "training_acc": 55.0, "val_loss": 339.26939964294434, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1267.778995513916, "training_acc": 53.0, "val_loss": 80.10708689689636, "val_acc": 52.0}
{"epoch": 40, "training_loss": 527.6404609680176, "training_acc": 57.0, "val_loss": 456.0460567474365, "val_acc": 48.0}
{"epoch": 41, "training_loss": 1796.3746376037598, "training_acc": 47.0, "val_loss": 201.22978687286377, "val_acc": 48.0}
{"epoch": 42, "training_loss": 910.5552864074707, "training_acc": 41.0, "val_loss": 330.8025360107422, "val_acc": 52.0}
{"epoch": 43, "training_loss": 1280.842643737793, "training_acc": 53.0, "val_loss": 130.9741735458374, "val_acc": 52.0}
{"epoch": 44, "training_loss": 631.6410598754883, "training_acc": 51.0, "val_loss": 339.90328311920166, "val_acc": 48.0}
