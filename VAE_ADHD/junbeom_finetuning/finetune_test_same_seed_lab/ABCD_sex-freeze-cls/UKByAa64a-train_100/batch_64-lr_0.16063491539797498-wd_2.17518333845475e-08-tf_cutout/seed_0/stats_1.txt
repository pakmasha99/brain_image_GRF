"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 381.7881088256836, "training_acc": 46.0, "val_loss": 70.45158743858337, "val_acc": 52.0}
{"epoch": 1, "training_loss": 342.7816276550293, "training_acc": 53.0, "val_loss": 182.03426599502563, "val_acc": 48.0}
{"epoch": 2, "training_loss": 683.643705368042, "training_acc": 47.0, "val_loss": 49.553072452545166, "val_acc": 48.0}
{"epoch": 3, "training_loss": 237.77374172210693, "training_acc": 51.0, "val_loss": 134.36336517333984, "val_acc": 52.0}
{"epoch": 4, "training_loss": 511.0929355621338, "training_acc": 53.0, "val_loss": 119.28185224533081, "val_acc": 52.0}
{"epoch": 5, "training_loss": 354.91279315948486, "training_acc": 53.0, "val_loss": 25.49664080142975, "val_acc": 48.0}
{"epoch": 6, "training_loss": 214.25227165222168, "training_acc": 47.0, "val_loss": 77.40721106529236, "val_acc": 48.0}
{"epoch": 7, "training_loss": 277.682297706604, "training_acc": 47.0, "val_loss": 23.72748553752899, "val_acc": 52.0}
{"epoch": 8, "training_loss": 108.02207279205322, "training_acc": 52.0, "val_loss": 68.00952553749084, "val_acc": 52.0}
{"epoch": 9, "training_loss": 226.93758630752563, "training_acc": 53.0, "val_loss": 20.080937445163727, "val_acc": 52.0}
{"epoch": 10, "training_loss": 106.73477172851562, "training_acc": 48.0, "val_loss": 46.90682888031006, "val_acc": 48.0}
{"epoch": 11, "training_loss": 168.03188753128052, "training_acc": 47.0, "val_loss": 21.562422811985016, "val_acc": 52.0}
{"epoch": 12, "training_loss": 99.77881669998169, "training_acc": 55.0, "val_loss": 32.24562406539917, "val_acc": 52.0}
{"epoch": 13, "training_loss": 93.25532674789429, "training_acc": 56.0, "val_loss": 29.661980271339417, "val_acc": 48.0}
{"epoch": 14, "training_loss": 131.01766538619995, "training_acc": 47.0, "val_loss": 19.893042743206024, "val_acc": 48.0}
{"epoch": 15, "training_loss": 79.67076468467712, "training_acc": 53.0, "val_loss": 38.45950961112976, "val_acc": 52.0}
{"epoch": 16, "training_loss": 124.29368495941162, "training_acc": 53.0, "val_loss": 16.796870529651642, "val_acc": 56.0}
{"epoch": 17, "training_loss": 83.84710836410522, "training_acc": 54.0, "val_loss": 23.34272712469101, "val_acc": 48.0}
{"epoch": 18, "training_loss": 80.37006163597107, "training_acc": 61.0, "val_loss": 34.44340527057648, "val_acc": 52.0}
{"epoch": 19, "training_loss": 125.80487537384033, "training_acc": 53.0, "val_loss": 26.429912447929382, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.24737763404846, "training_acc": 61.0, "val_loss": 30.890005826950073, "val_acc": 48.0}
{"epoch": 21, "training_loss": 129.8730845451355, "training_acc": 47.0, "val_loss": 18.632742762565613, "val_acc": 52.0}
{"epoch": 22, "training_loss": 83.69508743286133, "training_acc": 56.0, "val_loss": 33.993834257125854, "val_acc": 52.0}
{"epoch": 23, "training_loss": 93.40184926986694, "training_acc": 57.0, "val_loss": 22.754622995853424, "val_acc": 48.0}
{"epoch": 24, "training_loss": 103.41453504562378, "training_acc": 47.0, "val_loss": 17.217761278152466, "val_acc": 64.0}
{"epoch": 25, "training_loss": 69.19284772872925, "training_acc": 69.0, "val_loss": 29.152387380599976, "val_acc": 52.0}
{"epoch": 26, "training_loss": 96.9093062877655, "training_acc": 55.0, "val_loss": 19.44020837545395, "val_acc": 36.0}
{"epoch": 27, "training_loss": 74.65464425086975, "training_acc": 51.0, "val_loss": 17.314693331718445, "val_acc": 60.0}
{"epoch": 28, "training_loss": 71.54664134979248, "training_acc": 57.0, "val_loss": 19.469425082206726, "val_acc": 52.0}
{"epoch": 29, "training_loss": 75.20265626907349, "training_acc": 54.0, "val_loss": 17.62588769197464, "val_acc": 60.0}
{"epoch": 30, "training_loss": 67.8556776046753, "training_acc": 61.0, "val_loss": 19.372940063476562, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.35619139671326, "training_acc": 60.0, "val_loss": 17.272958159446716, "val_acc": 60.0}
{"epoch": 32, "training_loss": 63.80907416343689, "training_acc": 70.0, "val_loss": 17.230580747127533, "val_acc": 64.0}
{"epoch": 33, "training_loss": 64.95916080474854, "training_acc": 63.0, "val_loss": 17.123813927173615, "val_acc": 60.0}
{"epoch": 34, "training_loss": 70.39282083511353, "training_acc": 57.0, "val_loss": 17.120906710624695, "val_acc": 68.0}
{"epoch": 35, "training_loss": 70.05918908119202, "training_acc": 57.0, "val_loss": 17.10449308156967, "val_acc": 56.0}
