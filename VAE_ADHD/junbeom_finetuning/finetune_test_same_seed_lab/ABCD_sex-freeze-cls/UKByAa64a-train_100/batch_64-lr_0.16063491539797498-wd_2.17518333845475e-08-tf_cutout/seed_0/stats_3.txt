"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 152.83343410491943, "training_acc": 53.0, "val_loss": 67.91722774505615, "val_acc": 48.0}
{"epoch": 1, "training_loss": 271.3852515220642, "training_acc": 46.0, "val_loss": 78.86239290237427, "val_acc": 52.0}
{"epoch": 2, "training_loss": 228.27928018569946, "training_acc": 57.0, "val_loss": 60.96562147140503, "val_acc": 52.0}
{"epoch": 3, "training_loss": 193.13734579086304, "training_acc": 49.0, "val_loss": 35.218945145606995, "val_acc": 44.0}
{"epoch": 4, "training_loss": 158.4842712879181, "training_acc": 49.0, "val_loss": 42.80087947845459, "val_acc": 52.0}
{"epoch": 5, "training_loss": 118.65486717224121, "training_acc": 54.0, "val_loss": 21.47102653980255, "val_acc": 36.0}
{"epoch": 6, "training_loss": 93.25027704238892, "training_acc": 53.0, "val_loss": 20.421192049980164, "val_acc": 56.0}
{"epoch": 7, "training_loss": 72.96721744537354, "training_acc": 57.0, "val_loss": 31.73508048057556, "val_acc": 52.0}
{"epoch": 8, "training_loss": 101.58031010627747, "training_acc": 58.0, "val_loss": 24.96519535779953, "val_acc": 48.0}
{"epoch": 9, "training_loss": 90.9043984413147, "training_acc": 49.0, "val_loss": 19.42499428987503, "val_acc": 52.0}
{"epoch": 10, "training_loss": 84.32632780075073, "training_acc": 53.0, "val_loss": 16.52665287256241, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.69357705116272, "training_acc": 58.0, "val_loss": 18.483376502990723, "val_acc": 68.0}
{"epoch": 12, "training_loss": 83.73985004425049, "training_acc": 41.0, "val_loss": 18.174412846565247, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.23704624176025, "training_acc": 55.0, "val_loss": 17.24773794412613, "val_acc": 48.0}
{"epoch": 14, "training_loss": 67.5131688117981, "training_acc": 55.0, "val_loss": 19.945409893989563, "val_acc": 52.0}
{"epoch": 15, "training_loss": 61.82735466957092, "training_acc": 69.0, "val_loss": 18.47895234823227, "val_acc": 48.0}
{"epoch": 16, "training_loss": 75.19475483894348, "training_acc": 51.0, "val_loss": 22.67540544271469, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.99924182891846, "training_acc": 51.0, "val_loss": 17.69915372133255, "val_acc": 48.0}
{"epoch": 18, "training_loss": 70.60616612434387, "training_acc": 59.0, "val_loss": 21.436822414398193, "val_acc": 52.0}
{"epoch": 19, "training_loss": 73.34762668609619, "training_acc": 56.0, "val_loss": 17.24766492843628, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.30295491218567, "training_acc": 56.0, "val_loss": 17.03582853078842, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.64514017105103, "training_acc": 59.0, "val_loss": 16.382227838039398, "val_acc": 60.0}
{"epoch": 22, "training_loss": 73.34243583679199, "training_acc": 64.0, "val_loss": 18.15285086631775, "val_acc": 52.0}
{"epoch": 23, "training_loss": 73.74446940422058, "training_acc": 57.0, "val_loss": 16.722804307937622, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.30721664428711, "training_acc": 65.0, "val_loss": 16.815681755542755, "val_acc": 52.0}
{"epoch": 25, "training_loss": 61.15700078010559, "training_acc": 68.0, "val_loss": 21.809005737304688, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.74942016601562, "training_acc": 56.0, "val_loss": 17.534658312797546, "val_acc": 52.0}
{"epoch": 27, "training_loss": 63.5998113155365, "training_acc": 58.0, "val_loss": 23.922546207904816, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.75991368293762, "training_acc": 55.0, "val_loss": 18.10927987098694, "val_acc": 56.0}
{"epoch": 29, "training_loss": 75.49100112915039, "training_acc": 50.0, "val_loss": 17.374993860721588, "val_acc": 52.0}
{"epoch": 30, "training_loss": 61.757617473602295, "training_acc": 66.0, "val_loss": 17.385585606098175, "val_acc": 52.0}
{"epoch": 31, "training_loss": 60.079445123672485, "training_acc": 67.0, "val_loss": 17.478424310684204, "val_acc": 52.0}
{"epoch": 32, "training_loss": 62.303990602493286, "training_acc": 64.0, "val_loss": 21.16815894842148, "val_acc": 48.0}
{"epoch": 33, "training_loss": 78.88578128814697, "training_acc": 52.0, "val_loss": 19.332942366600037, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.10355687141418, "training_acc": 60.0, "val_loss": 17.250289022922516, "val_acc": 56.0}
{"epoch": 35, "training_loss": 61.48857593536377, "training_acc": 63.0, "val_loss": 20.33645212650299, "val_acc": 52.0}
{"epoch": 36, "training_loss": 62.93136286735535, "training_acc": 59.0, "val_loss": 18.665607273578644, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.24177622795105, "training_acc": 60.0, "val_loss": 19.376182556152344, "val_acc": 56.0}
{"epoch": 38, "training_loss": 77.63607835769653, "training_acc": 52.0, "val_loss": 27.197447419166565, "val_acc": 52.0}
{"epoch": 39, "training_loss": 83.60007500648499, "training_acc": 53.0, "val_loss": 22.42078334093094, "val_acc": 48.0}
{"epoch": 40, "training_loss": 89.9258303642273, "training_acc": 47.0, "val_loss": 23.504333198070526, "val_acc": 52.0}
