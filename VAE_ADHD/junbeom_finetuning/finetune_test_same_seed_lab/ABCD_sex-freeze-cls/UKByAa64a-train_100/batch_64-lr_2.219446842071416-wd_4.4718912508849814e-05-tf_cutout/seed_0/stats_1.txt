"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4705.812915802002, "training_acc": 46.0, "val_loss": 973.900032043457, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4731.461029052734, "training_acc": 53.0, "val_loss": 2523.711395263672, "val_acc": 48.0}
{"epoch": 2, "training_loss": 9497.20751953125, "training_acc": 47.0, "val_loss": 699.3919372558594, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3308.780014038086, "training_acc": 51.0, "val_loss": 1842.8155899047852, "val_acc": 52.0}
{"epoch": 4, "training_loss": 7001.912567138672, "training_acc": 53.0, "val_loss": 1644.0185546875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4879.457382202148, "training_acc": 53.0, "val_loss": 286.3806486129761, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2635.2601470947266, "training_acc": 47.0, "val_loss": 842.7984237670898, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2855.8433685302734, "training_acc": 47.0, "val_loss": 609.8721027374268, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2378.858139038086, "training_acc": 53.0, "val_loss": 1057.5614929199219, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3434.520149230957, "training_acc": 53.0, "val_loss": 132.9089879989624, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1393.1225280761719, "training_acc": 49.0, "val_loss": 1002.065372467041, "val_acc": 48.0}
{"epoch": 11, "training_loss": 3852.0551376342773, "training_acc": 47.0, "val_loss": 241.32771492004395, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1398.859603881836, "training_acc": 49.0, "val_loss": 994.8196411132812, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3810.848648071289, "training_acc": 53.0, "val_loss": 727.4011135101318, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1909.5652961730957, "training_acc": 53.0, "val_loss": 701.1693954467773, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3315.860122680664, "training_acc": 47.0, "val_loss": 867.1259880065918, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2673.0968132019043, "training_acc": 47.0, "val_loss": 495.5342769622803, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2297.1807250976562, "training_acc": 53.0, "val_loss": 933.1633567810059, "val_acc": 52.0}
{"epoch": 18, "training_loss": 3127.5284538269043, "training_acc": 53.0, "val_loss": 80.62559366226196, "val_acc": 60.0}
{"epoch": 19, "training_loss": 863.9904098510742, "training_acc": 59.0, "val_loss": 818.5273170471191, "val_acc": 48.0}
{"epoch": 20, "training_loss": 3027.838165283203, "training_acc": 47.0, "val_loss": 81.57731294631958, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1107.482032775879, "training_acc": 53.0, "val_loss": 950.9231567382812, "val_acc": 52.0}
{"epoch": 22, "training_loss": 3221.782485961914, "training_acc": 53.0, "val_loss": 522.9790687561035, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1185.9288730621338, "training_acc": 55.0, "val_loss": 420.6019401550293, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1609.0639038085938, "training_acc": 47.0, "val_loss": 196.23559713363647, "val_acc": 56.0}
{"epoch": 25, "training_loss": 701.1329689025879, "training_acc": 60.0, "val_loss": 288.00694942474365, "val_acc": 52.0}
{"epoch": 26, "training_loss": 943.126106262207, "training_acc": 45.0, "val_loss": 159.95490550994873, "val_acc": 48.0}
{"epoch": 27, "training_loss": 753.1309909820557, "training_acc": 50.0, "val_loss": 207.8458547592163, "val_acc": 56.0}
{"epoch": 28, "training_loss": 356.2028293609619, "training_acc": 60.0, "val_loss": 100.56039094924927, "val_acc": 40.0}
{"epoch": 29, "training_loss": 344.99144172668457, "training_acc": 61.0, "val_loss": 271.0803747177124, "val_acc": 52.0}
{"epoch": 30, "training_loss": 699.9999723434448, "training_acc": 54.0, "val_loss": 212.50436305999756, "val_acc": 48.0}
{"epoch": 31, "training_loss": 796.7382698059082, "training_acc": 51.0, "val_loss": 258.875036239624, "val_acc": 52.0}
{"epoch": 32, "training_loss": 872.6787796020508, "training_acc": 52.0, "val_loss": 91.26291275024414, "val_acc": 64.0}
{"epoch": 33, "training_loss": 497.47169494628906, "training_acc": 67.0, "val_loss": 288.4627342224121, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1182.9072647094727, "training_acc": 39.0, "val_loss": 235.94186305999756, "val_acc": 52.0}
{"epoch": 35, "training_loss": 552.8463315963745, "training_acc": 61.0, "val_loss": 64.96496200561523, "val_acc": 40.0}
{"epoch": 36, "training_loss": 448.446081161499, "training_acc": 56.0, "val_loss": 146.36260271072388, "val_acc": 56.0}
{"epoch": 37, "training_loss": 380.8272876739502, "training_acc": 56.0, "val_loss": 51.16716027259827, "val_acc": 64.0}
{"epoch": 38, "training_loss": 311.5767288208008, "training_acc": 63.0, "val_loss": 68.78719925880432, "val_acc": 64.0}
{"epoch": 39, "training_loss": 336.5499744415283, "training_acc": 58.0, "val_loss": 59.99545454978943, "val_acc": 64.0}
{"epoch": 40, "training_loss": 185.29908752441406, "training_acc": 65.0, "val_loss": 118.74569654464722, "val_acc": 52.0}
{"epoch": 41, "training_loss": 293.7632131576538, "training_acc": 55.0, "val_loss": 55.96702694892883, "val_acc": 64.0}
{"epoch": 42, "training_loss": 408.6260242462158, "training_acc": 51.0, "val_loss": 31.362006068229675, "val_acc": 56.0}
{"epoch": 43, "training_loss": 374.4516143798828, "training_acc": 59.0, "val_loss": 44.5329874753952, "val_acc": 52.0}
{"epoch": 44, "training_loss": 102.81197333335876, "training_acc": 64.0, "val_loss": 90.86224436759949, "val_acc": 52.0}
{"epoch": 45, "training_loss": 400.336332321167, "training_acc": 46.0, "val_loss": 100.24430751800537, "val_acc": 52.0}
{"epoch": 46, "training_loss": 193.5550937652588, "training_acc": 65.0, "val_loss": 207.6777696609497, "val_acc": 48.0}
{"epoch": 47, "training_loss": 672.101658821106, "training_acc": 49.0, "val_loss": 367.1490430831909, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1348.9416465759277, "training_acc": 53.0, "val_loss": 171.88771963119507, "val_acc": 52.0}
{"epoch": 49, "training_loss": 989.3289566040039, "training_acc": 47.0, "val_loss": 464.924955368042, "val_acc": 48.0}
{"epoch": 50, "training_loss": 1381.0740299224854, "training_acc": 47.0, "val_loss": 509.77635383605957, "val_acc": 52.0}
{"epoch": 51, "training_loss": 2288.328887939453, "training_acc": 53.0, "val_loss": 706.226921081543, "val_acc": 52.0}
{"epoch": 52, "training_loss": 2105.7310066223145, "training_acc": 53.0, "val_loss": 432.6724052429199, "val_acc": 48.0}
{"epoch": 53, "training_loss": 2190.8818969726562, "training_acc": 47.0, "val_loss": 569.254732131958, "val_acc": 48.0}
{"epoch": 54, "training_loss": 1499.1656012535095, "training_acc": 55.0, "val_loss": 608.4855079650879, "val_acc": 52.0}
{"epoch": 55, "training_loss": 2526.655113220215, "training_acc": 53.0, "val_loss": 736.540937423706, "val_acc": 52.0}
{"epoch": 56, "training_loss": 2247.3675479888916, "training_acc": 53.0, "val_loss": 410.0381851196289, "val_acc": 48.0}
{"epoch": 57, "training_loss": 2045.1299667358398, "training_acc": 47.0, "val_loss": 473.51555824279785, "val_acc": 48.0}
{"epoch": 58, "training_loss": 1229.544602394104, "training_acc": 54.0, "val_loss": 426.2105464935303, "val_acc": 52.0}
{"epoch": 59, "training_loss": 1533.5274505615234, "training_acc": 53.0, "val_loss": 129.707133769989, "val_acc": 56.0}
{"epoch": 60, "training_loss": 590.4269027709961, "training_acc": 65.0, "val_loss": 644.0537452697754, "val_acc": 48.0}
{"epoch": 61, "training_loss": 2291.309066772461, "training_acc": 47.0, "val_loss": 131.88647031784058, "val_acc": 56.0}
