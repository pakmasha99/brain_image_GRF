"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4469.590553283691, "training_acc": 47.0, "val_loss": 52.16622352600098, "val_acc": 56.0}
{"epoch": 1, "training_loss": 2237.435501098633, "training_acc": 56.0, "val_loss": 953.7079811096191, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2472.644317626953, "training_acc": 56.0, "val_loss": 361.7540121078491, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1491.7462882995605, "training_acc": 42.0, "val_loss": 104.06137704849243, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1069.7183074951172, "training_acc": 52.0, "val_loss": 462.26840019226074, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1305.9967632293701, "training_acc": 52.0, "val_loss": 250.46312808990479, "val_acc": 52.0}
{"epoch": 6, "training_loss": 602.5118112564087, "training_acc": 61.0, "val_loss": 412.5761032104492, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1254.0667114257812, "training_acc": 49.0, "val_loss": 282.7800750732422, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1183.4027061462402, "training_acc": 53.0, "val_loss": 37.96077370643616, "val_acc": 60.0}
{"epoch": 9, "training_loss": 480.2243843078613, "training_acc": 59.0, "val_loss": 234.75146293640137, "val_acc": 48.0}
{"epoch": 10, "training_loss": 673.4835834503174, "training_acc": 59.0, "val_loss": 368.5802221298218, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1160.8031482696533, "training_acc": 51.0, "val_loss": 461.58204078674316, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1693.8385124206543, "training_acc": 47.0, "val_loss": 66.2391185760498, "val_acc": 52.0}
{"epoch": 13, "training_loss": 954.8898468017578, "training_acc": 55.0, "val_loss": 549.3317604064941, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1655.564868927002, "training_acc": 53.0, "val_loss": 384.6980094909668, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1609.2492904663086, "training_acc": 47.0, "val_loss": 300.87695121765137, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1542.9221267700195, "training_acc": 38.0, "val_loss": 437.1551990509033, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1230.3825035095215, "training_acc": 55.0, "val_loss": 315.0053024291992, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1420.5134658813477, "training_acc": 48.0, "val_loss": 83.38749408721924, "val_acc": 56.0}
{"epoch": 19, "training_loss": 850.0875930786133, "training_acc": 55.0, "val_loss": 477.606201171875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1308.7066688537598, "training_acc": 53.0, "val_loss": 346.8221426010132, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1375.972801208496, "training_acc": 47.0, "val_loss": 88.51329684257507, "val_acc": 48.0}
{"epoch": 22, "training_loss": 711.2602119445801, "training_acc": 51.0, "val_loss": 422.83453941345215, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1155.498254776001, "training_acc": 50.0, "val_loss": 288.9681100845337, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1223.927131652832, "training_acc": 46.0, "val_loss": 56.8652868270874, "val_acc": 52.0}
{"epoch": 25, "training_loss": 740.2977600097656, "training_acc": 52.0, "val_loss": 207.20911026000977, "val_acc": 52.0}
{"epoch": 26, "training_loss": 670.358118057251, "training_acc": 57.0, "val_loss": 247.82075881958008, "val_acc": 48.0}
{"epoch": 27, "training_loss": 794.3168716430664, "training_acc": 54.0, "val_loss": 138.53819370269775, "val_acc": 52.0}
