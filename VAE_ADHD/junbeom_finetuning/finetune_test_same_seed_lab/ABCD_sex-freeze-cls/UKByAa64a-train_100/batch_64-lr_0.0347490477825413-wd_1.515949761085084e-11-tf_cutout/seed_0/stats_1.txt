"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 118.0581865310669, "training_acc": 46.0, "val_loss": 21.35404497385025, "val_acc": 52.0}
{"epoch": 1, "training_loss": 90.47886991500854, "training_acc": 53.0, "val_loss": 35.662099719047546, "val_acc": 48.0}
{"epoch": 2, "training_loss": 131.93049573898315, "training_acc": 47.0, "val_loss": 17.39346534013748, "val_acc": 52.0}
{"epoch": 3, "training_loss": 76.81079339981079, "training_acc": 51.0, "val_loss": 31.520864367485046, "val_acc": 52.0}
{"epoch": 4, "training_loss": 118.07539558410645, "training_acc": 53.0, "val_loss": 24.058234691619873, "val_acc": 52.0}
{"epoch": 5, "training_loss": 82.35589861869812, "training_acc": 51.0, "val_loss": 19.47779655456543, "val_acc": 48.0}
{"epoch": 6, "training_loss": 91.88445615768433, "training_acc": 47.0, "val_loss": 24.5477095246315, "val_acc": 48.0}
{"epoch": 7, "training_loss": 91.64826703071594, "training_acc": 47.0, "val_loss": 17.29085147380829, "val_acc": 52.0}
{"epoch": 8, "training_loss": 66.92695546150208, "training_acc": 57.0, "val_loss": 23.6697718501091, "val_acc": 52.0}
{"epoch": 9, "training_loss": 91.71060013771057, "training_acc": 53.0, "val_loss": 21.562469005584717, "val_acc": 52.0}
{"epoch": 10, "training_loss": 79.9953556060791, "training_acc": 53.0, "val_loss": 17.539528012275696, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.4979555606842, "training_acc": 48.0, "val_loss": 20.739345252513885, "val_acc": 48.0}
{"epoch": 12, "training_loss": 81.44998335838318, "training_acc": 47.0, "val_loss": 17.870694398880005, "val_acc": 56.0}
{"epoch": 13, "training_loss": 72.45868039131165, "training_acc": 41.0, "val_loss": 18.509671092033386, "val_acc": 52.0}
{"epoch": 14, "training_loss": 72.43844962120056, "training_acc": 53.0, "val_loss": 18.241026997566223, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.92316174507141, "training_acc": 54.0, "val_loss": 17.23516434431076, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.83469080924988, "training_acc": 63.0, "val_loss": 17.544157803058624, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.30711054801941, "training_acc": 52.0, "val_loss": 17.21636801958084, "val_acc": 52.0}
{"epoch": 18, "training_loss": 66.85070323944092, "training_acc": 61.0, "val_loss": 18.050548434257507, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.05049586296082, "training_acc": 54.0, "val_loss": 18.469122052192688, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.23933577537537, "training_acc": 60.0, "val_loss": 17.240223288536072, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.90572023391724, "training_acc": 53.0, "val_loss": 18.00374537706375, "val_acc": 60.0}
{"epoch": 22, "training_loss": 72.98638248443604, "training_acc": 46.0, "val_loss": 17.307738959789276, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.40905690193176, "training_acc": 58.0, "val_loss": 19.00343894958496, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.90267729759216, "training_acc": 52.0, "val_loss": 17.597252130508423, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.51384282112122, "training_acc": 53.0, "val_loss": 17.493051290512085, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.56105327606201, "training_acc": 51.0, "val_loss": 17.288848757743835, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.91756105422974, "training_acc": 55.0, "val_loss": 18.138574063777924, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.73696827888489, "training_acc": 54.0, "val_loss": 17.5296813249588, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15568828582764, "training_acc": 51.0, "val_loss": 17.419052124023438, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.57467031478882, "training_acc": 60.0, "val_loss": 17.360326647758484, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.63548278808594, "training_acc": 60.0, "val_loss": 17.886123061180115, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.66400456428528, "training_acc": 54.0, "val_loss": 17.35340505838394, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.80707597732544, "training_acc": 66.0, "val_loss": 17.612391710281372, "val_acc": 60.0}
{"epoch": 34, "training_loss": 70.8586528301239, "training_acc": 51.0, "val_loss": 17.359763383865356, "val_acc": 60.0}
{"epoch": 35, "training_loss": 68.83086585998535, "training_acc": 56.0, "val_loss": 17.217379808425903, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.05460667610168, "training_acc": 63.0, "val_loss": 17.643271386623383, "val_acc": 52.0}
