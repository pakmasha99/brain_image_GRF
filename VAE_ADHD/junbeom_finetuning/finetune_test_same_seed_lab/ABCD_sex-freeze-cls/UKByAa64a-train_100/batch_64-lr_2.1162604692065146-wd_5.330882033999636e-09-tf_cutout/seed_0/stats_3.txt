"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1492.0429382324219, "training_acc": 52.0, "val_loss": 1158.4687232971191, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4302.144485473633, "training_acc": 47.0, "val_loss": 1086.2130165100098, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3643.8011322021484, "training_acc": 53.0, "val_loss": 1170.4258918762207, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2034.8904972076416, "training_acc": 63.0, "val_loss": 941.5328025817871, "val_acc": 48.0}
{"epoch": 4, "training_loss": 4334.145584106445, "training_acc": 47.0, "val_loss": 726.0195732116699, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2344.1055870056152, "training_acc": 55.0, "val_loss": 1097.323989868164, "val_acc": 52.0}
{"epoch": 6, "training_loss": 3745.854263305664, "training_acc": 53.0, "val_loss": 1092.6658630371094, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2393.899929046631, "training_acc": 51.0, "val_loss": 488.7007713317871, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2927.7689208984375, "training_acc": 47.0, "val_loss": 568.2545185089111, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1796.4579467773438, "training_acc": 47.0, "val_loss": 826.4918327331543, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2961.897903442383, "training_acc": 53.0, "val_loss": 813.0252838134766, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1857.5727548599243, "training_acc": 53.0, "val_loss": 542.9210662841797, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2650.989616394043, "training_acc": 47.0, "val_loss": 490.67349433898926, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1602.425952911377, "training_acc": 46.0, "val_loss": 545.805549621582, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1547.6557998657227, "training_acc": 53.0, "val_loss": 137.09173202514648, "val_acc": 44.0}
{"epoch": 15, "training_loss": 889.9026260375977, "training_acc": 54.0, "val_loss": 326.4842987060547, "val_acc": 48.0}
{"epoch": 16, "training_loss": 859.3509888648987, "training_acc": 54.0, "val_loss": 445.41711807250977, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1455.4978065490723, "training_acc": 53.0, "val_loss": 75.60432553291321, "val_acc": 48.0}
{"epoch": 18, "training_loss": 597.0522422790527, "training_acc": 59.0, "val_loss": 332.59599208831787, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1159.2272357940674, "training_acc": 47.0, "val_loss": 172.34679460525513, "val_acc": 52.0}
{"epoch": 20, "training_loss": 760.0893573760986, "training_acc": 45.0, "val_loss": 40.947821736335754, "val_acc": 52.0}
{"epoch": 21, "training_loss": 366.53951263427734, "training_acc": 63.0, "val_loss": 66.18232727050781, "val_acc": 52.0}
{"epoch": 22, "training_loss": 324.1357126235962, "training_acc": 58.0, "val_loss": 284.4583034515381, "val_acc": 52.0}
{"epoch": 23, "training_loss": 872.632776260376, "training_acc": 53.0, "val_loss": 88.46009373664856, "val_acc": 52.0}
{"epoch": 24, "training_loss": 465.33770751953125, "training_acc": 51.0, "val_loss": 294.6490526199341, "val_acc": 52.0}
{"epoch": 25, "training_loss": 715.9628353118896, "training_acc": 53.0, "val_loss": 87.1267020702362, "val_acc": 48.0}
{"epoch": 26, "training_loss": 360.51741886138916, "training_acc": 51.0, "val_loss": 303.72586250305176, "val_acc": 52.0}
{"epoch": 27, "training_loss": 718.5151176452637, "training_acc": 55.0, "val_loss": 176.03574991226196, "val_acc": 48.0}
{"epoch": 28, "training_loss": 791.5261497497559, "training_acc": 47.0, "val_loss": 239.74673748016357, "val_acc": 52.0}
{"epoch": 29, "training_loss": 555.4622325897217, "training_acc": 58.0, "val_loss": 74.57491755485535, "val_acc": 36.0}
{"epoch": 30, "training_loss": 233.1537799835205, "training_acc": 63.0, "val_loss": 200.30925273895264, "val_acc": 52.0}
{"epoch": 31, "training_loss": 277.0222463607788, "training_acc": 61.0, "val_loss": 162.39711046218872, "val_acc": 48.0}
{"epoch": 32, "training_loss": 534.6650485992432, "training_acc": 52.0, "val_loss": 319.4587707519531, "val_acc": 52.0}
{"epoch": 33, "training_loss": 723.036283493042, "training_acc": 53.0, "val_loss": 139.38546180725098, "val_acc": 48.0}
{"epoch": 34, "training_loss": 624.1801338195801, "training_acc": 49.0, "val_loss": 283.2947254180908, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1065.3008422851562, "training_acc": 53.0, "val_loss": 69.22057867050171, "val_acc": 52.0}
{"epoch": 36, "training_loss": 677.3193511962891, "training_acc": 59.0, "val_loss": 293.82243156433105, "val_acc": 48.0}
{"epoch": 37, "training_loss": 1118.2148609161377, "training_acc": 41.0, "val_loss": 219.33810710906982, "val_acc": 52.0}
{"epoch": 38, "training_loss": 497.33033180236816, "training_acc": 52.0, "val_loss": 49.890607595443726, "val_acc": 36.0}
{"epoch": 39, "training_loss": 453.1577911376953, "training_acc": 56.0, "val_loss": 236.89241409301758, "val_acc": 52.0}
