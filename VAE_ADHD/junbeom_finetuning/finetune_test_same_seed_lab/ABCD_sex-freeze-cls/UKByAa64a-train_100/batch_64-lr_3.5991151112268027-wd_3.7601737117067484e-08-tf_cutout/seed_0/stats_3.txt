"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 9971.609359741211, "training_acc": 43.0, "val_loss": 2086.9977951049805, "val_acc": 48.0}
{"epoch": 1, "training_loss": 7721.0701904296875, "training_acc": 53.0, "val_loss": 3897.2850799560547, "val_acc": 52.0}
{"epoch": 2, "training_loss": 14710.6103515625, "training_acc": 53.0, "val_loss": 2542.5933837890625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 6253.7534255981445, "training_acc": 53.0, "val_loss": 2268.2634353637695, "val_acc": 48.0}
{"epoch": 4, "training_loss": 10604.985290527344, "training_acc": 47.0, "val_loss": 3853.139114379883, "val_acc": 48.0}
{"epoch": 5, "training_loss": 14250.02944946289, "training_acc": 47.0, "val_loss": 1657.8256607055664, "val_acc": 48.0}
{"epoch": 6, "training_loss": 5209.962478637695, "training_acc": 45.0, "val_loss": 1331.6288948059082, "val_acc": 52.0}
{"epoch": 7, "training_loss": 5708.095428466797, "training_acc": 53.0, "val_loss": 1099.2321968078613, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3100.4451179504395, "training_acc": 54.0, "val_loss": 1303.162670135498, "val_acc": 48.0}
{"epoch": 9, "training_loss": 5888.499664306641, "training_acc": 46.0, "val_loss": 1545.409107208252, "val_acc": 48.0}
{"epoch": 10, "training_loss": 4673.594482421875, "training_acc": 48.0, "val_loss": 831.3555717468262, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4328.196685791016, "training_acc": 53.0, "val_loss": 1609.950065612793, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5354.619033813477, "training_acc": 53.0, "val_loss": 101.33417844772339, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1664.7662811279297, "training_acc": 56.0, "val_loss": 1360.9821319580078, "val_acc": 48.0}
{"epoch": 14, "training_loss": 4912.778305053711, "training_acc": 47.0, "val_loss": 104.54831123352051, "val_acc": 44.0}
{"epoch": 15, "training_loss": 1808.2288818359375, "training_acc": 55.0, "val_loss": 1579.6391487121582, "val_acc": 52.0}
{"epoch": 16, "training_loss": 5225.104164123535, "training_acc": 53.0, "val_loss": 758.1372737884521, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2368.998680114746, "training_acc": 47.0, "val_loss": 832.5152397155762, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2979.971778869629, "training_acc": 47.0, "val_loss": 372.15447425842285, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1428.1008834838867, "training_acc": 54.0, "val_loss": 363.81001472473145, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1095.5607795715332, "training_acc": 58.0, "val_loss": 478.8642883300781, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1545.9998779296875, "training_acc": 52.0, "val_loss": 766.4834022521973, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2147.314582824707, "training_acc": 53.0, "val_loss": 379.04412746429443, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1173.7851028442383, "training_acc": 55.0, "val_loss": 570.805549621582, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1914.600872039795, "training_acc": 49.0, "val_loss": 827.7844429016113, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2910.194549560547, "training_acc": 53.0, "val_loss": 776.2034893035889, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1346.9881267547607, "training_acc": 63.0, "val_loss": 471.7395782470703, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1857.9268379211426, "training_acc": 49.0, "val_loss": 500.8701801300049, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1563.5363540649414, "training_acc": 53.0, "val_loss": 237.4073028564453, "val_acc": 52.0}
{"epoch": 29, "training_loss": 936.2278594970703, "training_acc": 59.0, "val_loss": 597.7989196777344, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1749.8396701812744, "training_acc": 51.0, "val_loss": 780.3526401519775, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2729.464584350586, "training_acc": 53.0, "val_loss": 630.5200576782227, "val_acc": 52.0}
