"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4954.9173583984375, "training_acc": 43.0, "val_loss": 1190.9075736999512, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4209.234130859375, "training_acc": 55.0, "val_loss": 1789.7224426269531, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6478.089874267578, "training_acc": 47.0, "val_loss": 186.09445095062256, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2486.9752502441406, "training_acc": 47.0, "val_loss": 2031.6097259521484, "val_acc": 52.0}
{"epoch": 4, "training_loss": 7931.374481201172, "training_acc": 53.0, "val_loss": 1777.950096130371, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5976.956756591797, "training_acc": 53.0, "val_loss": 78.84872555732727, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2089.6370849609375, "training_acc": 49.0, "val_loss": 1948.164939880371, "val_acc": 48.0}
{"epoch": 7, "training_loss": 8030.220367431641, "training_acc": 47.0, "val_loss": 1797.0972061157227, "val_acc": 48.0}
{"epoch": 8, "training_loss": 6141.315231323242, "training_acc": 47.0, "val_loss": 59.97024178504944, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1447.2552947998047, "training_acc": 56.0, "val_loss": 1592.406177520752, "val_acc": 52.0}
{"epoch": 10, "training_loss": 6362.151809692383, "training_acc": 53.0, "val_loss": 1672.2095489501953, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5823.650482177734, "training_acc": 53.0, "val_loss": 558.3512306213379, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2177.4159545898438, "training_acc": 45.0, "val_loss": 927.0195960998535, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3723.2964935302734, "training_acc": 47.0, "val_loss": 664.663553237915, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1697.5458283424377, "training_acc": 51.0, "val_loss": 578.5649299621582, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2452.949806213379, "training_acc": 53.0, "val_loss": 715.1193618774414, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2128.352642059326, "training_acc": 53.0, "val_loss": 317.9677724838257, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1447.1976852416992, "training_acc": 46.0, "val_loss": 466.21689796447754, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1141.6614837646484, "training_acc": 47.0, "val_loss": 488.70954513549805, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2012.6493301391602, "training_acc": 53.0, "val_loss": 483.06078910827637, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1153.14936876297, "training_acc": 59.0, "val_loss": 518.7004089355469, "val_acc": 48.0}
{"epoch": 21, "training_loss": 2231.969139099121, "training_acc": 47.0, "val_loss": 479.3837547302246, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1170.5688014030457, "training_acc": 58.0, "val_loss": 414.4601345062256, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1558.4767227172852, "training_acc": 53.0, "val_loss": 172.86579608917236, "val_acc": 52.0}
{"epoch": 24, "training_loss": 933.9535140991211, "training_acc": 49.0, "val_loss": 484.615421295166, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1518.49192237854, "training_acc": 50.0, "val_loss": 292.4672842025757, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1141.1379928588867, "training_acc": 53.0, "val_loss": 282.2658061981201, "val_acc": 52.0}
{"epoch": 27, "training_loss": 992.5357074737549, "training_acc": 51.0, "val_loss": 260.8915090560913, "val_acc": 48.0}
