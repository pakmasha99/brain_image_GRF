"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4703.47819519043, "training_acc": 45.0, "val_loss": 1064.426612854004, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4410.797958374023, "training_acc": 53.0, "val_loss": 2046.9980239868164, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7462.309524536133, "training_acc": 47.0, "val_loss": 392.21606254577637, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2808.6587829589844, "training_acc": 45.0, "val_loss": 1742.289924621582, "val_acc": 52.0}
{"epoch": 4, "training_loss": 6829.436096191406, "training_acc": 53.0, "val_loss": 1381.4471244812012, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4223.396629333496, "training_acc": 53.0, "val_loss": 574.9846458435059, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3089.718460083008, "training_acc": 47.0, "val_loss": 1131.9619178771973, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3778.301010131836, "training_acc": 47.0, "val_loss": 75.75182914733887, "val_acc": 52.0}
{"epoch": 8, "training_loss": 966.8984985351562, "training_acc": 53.0, "val_loss": 385.0250720977783, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1135.6765899658203, "training_acc": 60.0, "val_loss": 373.5117435455322, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1401.5998802185059, "training_acc": 45.0, "val_loss": 43.70957612991333, "val_acc": 52.0}
{"epoch": 11, "training_loss": 607.383617401123, "training_acc": 51.0, "val_loss": 101.91650390625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 707.8916091918945, "training_acc": 52.0, "val_loss": 413.5128974914551, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1201.2435894012451, "training_acc": 47.0, "val_loss": 547.2038269042969, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2159.192901611328, "training_acc": 53.0, "val_loss": 793.2681560516357, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2310.18514251709, "training_acc": 53.0, "val_loss": 152.37892866134644, "val_acc": 48.0}
{"epoch": 16, "training_loss": 887.9486618041992, "training_acc": 47.0, "val_loss": 181.72425031661987, "val_acc": 48.0}
{"epoch": 17, "training_loss": 897.4069671630859, "training_acc": 45.0, "val_loss": 408.91098976135254, "val_acc": 52.0}
{"epoch": 18, "training_loss": 898.6710376739502, "training_acc": 55.0, "val_loss": 279.0120840072632, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1280.9443855285645, "training_acc": 47.0, "val_loss": 116.13268852233887, "val_acc": 44.0}
{"epoch": 20, "training_loss": 552.9314994812012, "training_acc": 62.0, "val_loss": 347.7053642272949, "val_acc": 52.0}
{"epoch": 21, "training_loss": 716.7172946929932, "training_acc": 50.0, "val_loss": 97.03789949417114, "val_acc": 44.0}
{"epoch": 22, "training_loss": 565.1752662658691, "training_acc": 45.0, "val_loss": 181.7368745803833, "val_acc": 52.0}
{"epoch": 23, "training_loss": 290.71910572052, "training_acc": 61.0, "val_loss": 85.46791672706604, "val_acc": 44.0}
{"epoch": 24, "training_loss": 451.57433891296387, "training_acc": 52.0, "val_loss": 285.08989810943604, "val_acc": 52.0}
{"epoch": 25, "training_loss": 554.3585138320923, "training_acc": 53.0, "val_loss": 89.03256058692932, "val_acc": 40.0}
{"epoch": 26, "training_loss": 546.2417373657227, "training_acc": 50.0, "val_loss": 197.34727144241333, "val_acc": 52.0}
{"epoch": 27, "training_loss": 445.08543586730957, "training_acc": 55.0, "val_loss": 73.02237749099731, "val_acc": 36.0}
{"epoch": 28, "training_loss": 428.9972610473633, "training_acc": 59.0, "val_loss": 308.09288024902344, "val_acc": 52.0}
{"epoch": 29, "training_loss": 627.3649187088013, "training_acc": 56.0, "val_loss": 92.35947132110596, "val_acc": 52.0}
