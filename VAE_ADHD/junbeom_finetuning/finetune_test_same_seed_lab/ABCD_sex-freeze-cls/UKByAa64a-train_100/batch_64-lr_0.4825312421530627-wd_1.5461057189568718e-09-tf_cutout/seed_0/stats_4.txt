"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1083.7968711853027, "training_acc": 47.0, "val_loss": 243.1870937347412, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1111.4711380004883, "training_acc": 51.0, "val_loss": 475.69971084594727, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1745.9114303588867, "training_acc": 47.0, "val_loss": 73.26037287712097, "val_acc": 48.0}
{"epoch": 3, "training_loss": 703.7332344055176, "training_acc": 43.0, "val_loss": 466.42932891845703, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1857.3096008300781, "training_acc": 53.0, "val_loss": 419.30694580078125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1361.3022003173828, "training_acc": 53.0, "val_loss": 20.770972967147827, "val_acc": 48.0}
{"epoch": 6, "training_loss": 325.5691261291504, "training_acc": 64.0, "val_loss": 387.6046419143677, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1574.2825012207031, "training_acc": 47.0, "val_loss": 311.8342161178589, "val_acc": 48.0}
{"epoch": 8, "training_loss": 981.0418376922607, "training_acc": 47.0, "val_loss": 117.34788417816162, "val_acc": 52.0}
{"epoch": 9, "training_loss": 743.4443473815918, "training_acc": 53.0, "val_loss": 296.813440322876, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1071.4238357543945, "training_acc": 53.0, "val_loss": 126.1770248413086, "val_acc": 52.0}
{"epoch": 11, "training_loss": 412.0047607421875, "training_acc": 47.0, "val_loss": 147.09306955337524, "val_acc": 48.0}
{"epoch": 12, "training_loss": 554.0584049224854, "training_acc": 47.0, "val_loss": 37.189292907714844, "val_acc": 48.0}
{"epoch": 13, "training_loss": 155.56380081176758, "training_acc": 64.0, "val_loss": 155.14971017837524, "val_acc": 52.0}
{"epoch": 14, "training_loss": 549.9859600067139, "training_acc": 53.0, "val_loss": 54.59478497505188, "val_acc": 52.0}
{"epoch": 15, "training_loss": 218.98151397705078, "training_acc": 55.0, "val_loss": 131.71329498291016, "val_acc": 48.0}
{"epoch": 16, "training_loss": 446.2872714996338, "training_acc": 47.0, "val_loss": 36.65067255496979, "val_acc": 52.0}
{"epoch": 17, "training_loss": 211.73629570007324, "training_acc": 54.0, "val_loss": 77.66417264938354, "val_acc": 52.0}
{"epoch": 18, "training_loss": 170.7254719734192, "training_acc": 58.0, "val_loss": 87.29565143585205, "val_acc": 48.0}
{"epoch": 19, "training_loss": 355.98635053634644, "training_acc": 48.0, "val_loss": 24.943986535072327, "val_acc": 60.0}
{"epoch": 20, "training_loss": 172.48950862884521, "training_acc": 45.0, "val_loss": 68.97472739219666, "val_acc": 52.0}
{"epoch": 21, "training_loss": 220.53606605529785, "training_acc": 48.0, "val_loss": 55.19784688949585, "val_acc": 48.0}
{"epoch": 22, "training_loss": 159.95013785362244, "training_acc": 55.0, "val_loss": 47.1128910779953, "val_acc": 52.0}
{"epoch": 23, "training_loss": 148.28310227394104, "training_acc": 55.0, "val_loss": 27.302783727645874, "val_acc": 48.0}
{"epoch": 24, "training_loss": 84.4373049736023, "training_acc": 61.0, "val_loss": 22.619526088237762, "val_acc": 60.0}
{"epoch": 25, "training_loss": 83.71399545669556, "training_acc": 63.0, "val_loss": 19.374507665634155, "val_acc": 60.0}
{"epoch": 26, "training_loss": 62.13295316696167, "training_acc": 64.0, "val_loss": 18.80233734846115, "val_acc": 60.0}
{"epoch": 27, "training_loss": 76.94386911392212, "training_acc": 60.0, "val_loss": 19.430014491081238, "val_acc": 56.0}
{"epoch": 28, "training_loss": 70.46451783180237, "training_acc": 66.0, "val_loss": 30.0667405128479, "val_acc": 48.0}
{"epoch": 29, "training_loss": 94.07985711097717, "training_acc": 58.0, "val_loss": 33.287736773490906, "val_acc": 52.0}
{"epoch": 30, "training_loss": 104.41093826293945, "training_acc": 51.0, "val_loss": 18.098163604736328, "val_acc": 60.0}
{"epoch": 31, "training_loss": 78.99483489990234, "training_acc": 61.0, "val_loss": 19.183585047721863, "val_acc": 48.0}
{"epoch": 32, "training_loss": 79.68129420280457, "training_acc": 55.0, "val_loss": 23.11761826276779, "val_acc": 52.0}
{"epoch": 33, "training_loss": 81.32607316970825, "training_acc": 57.0, "val_loss": 42.87678897380829, "val_acc": 48.0}
{"epoch": 34, "training_loss": 140.3891773223877, "training_acc": 48.0, "val_loss": 66.68637990951538, "val_acc": 52.0}
{"epoch": 35, "training_loss": 208.29197645187378, "training_acc": 53.0, "val_loss": 32.96291530132294, "val_acc": 48.0}
{"epoch": 36, "training_loss": 128.08645009994507, "training_acc": 48.0, "val_loss": 58.21274518966675, "val_acc": 52.0}
{"epoch": 37, "training_loss": 229.33077716827393, "training_acc": 53.0, "val_loss": 23.6887127161026, "val_acc": 48.0}
{"epoch": 38, "training_loss": 125.52040147781372, "training_acc": 49.0, "val_loss": 26.554331183433533, "val_acc": 52.0}
{"epoch": 39, "training_loss": 91.43200016021729, "training_acc": 55.0, "val_loss": 31.95490837097168, "val_acc": 48.0}
{"epoch": 40, "training_loss": 99.64049172401428, "training_acc": 51.0, "val_loss": 50.42765140533447, "val_acc": 52.0}
{"epoch": 41, "training_loss": 151.23639011383057, "training_acc": 53.0, "val_loss": 51.63226127624512, "val_acc": 48.0}
{"epoch": 42, "training_loss": 167.38058805465698, "training_acc": 49.0, "val_loss": 52.841222286224365, "val_acc": 52.0}
{"epoch": 43, "training_loss": 179.3914704322815, "training_acc": 53.0, "val_loss": 24.761806428432465, "val_acc": 44.0}
{"epoch": 44, "training_loss": 102.16513776779175, "training_acc": 51.0, "val_loss": 33.73241722583771, "val_acc": 52.0}
{"epoch": 45, "training_loss": 99.86433839797974, "training_acc": 56.0, "val_loss": 24.681609869003296, "val_acc": 44.0}
{"epoch": 46, "training_loss": 81.75178289413452, "training_acc": 63.0, "val_loss": 25.28725564479828, "val_acc": 48.0}
{"epoch": 47, "training_loss": 69.4676423072815, "training_acc": 68.0, "val_loss": 29.58388924598694, "val_acc": 44.0}
{"epoch": 48, "training_loss": 75.55862820148468, "training_acc": 59.0, "val_loss": 30.22317886352539, "val_acc": 52.0}
{"epoch": 49, "training_loss": 76.20730185508728, "training_acc": 63.0, "val_loss": 28.462669253349304, "val_acc": 48.0}
