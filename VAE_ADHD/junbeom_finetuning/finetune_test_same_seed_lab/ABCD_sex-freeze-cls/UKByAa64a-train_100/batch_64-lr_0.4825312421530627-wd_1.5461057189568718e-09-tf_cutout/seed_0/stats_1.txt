"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1057.8517570495605, "training_acc": 46.0, "val_loss": 211.69872283935547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1028.9159126281738, "training_acc": 53.0, "val_loss": 548.7101554870605, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2064.71435546875, "training_acc": 47.0, "val_loss": 152.18255519866943, "val_acc": 48.0}
{"epoch": 3, "training_loss": 719.3334121704102, "training_acc": 51.0, "val_loss": 400.52356719970703, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1522.3072395324707, "training_acc": 53.0, "val_loss": 357.399582862854, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1061.1896343231201, "training_acc": 53.0, "val_loss": 62.4278724193573, "val_acc": 48.0}
{"epoch": 6, "training_loss": 574.5642433166504, "training_acc": 47.0, "val_loss": 185.0978970527649, "val_acc": 48.0}
{"epoch": 7, "training_loss": 628.8332538604736, "training_acc": 47.0, "val_loss": 129.29071187973022, "val_acc": 52.0}
{"epoch": 8, "training_loss": 504.30986976623535, "training_acc": 53.0, "val_loss": 223.86672496795654, "val_acc": 52.0}
{"epoch": 9, "training_loss": 722.1650638580322, "training_acc": 53.0, "val_loss": 25.172272324562073, "val_acc": 56.0}
{"epoch": 10, "training_loss": 275.3131675720215, "training_acc": 49.0, "val_loss": 168.03884506225586, "val_acc": 48.0}
{"epoch": 11, "training_loss": 610.7325773239136, "training_acc": 47.0, "val_loss": 40.64135551452637, "val_acc": 52.0}
{"epoch": 12, "training_loss": 203.32572078704834, "training_acc": 55.0, "val_loss": 72.3397433757782, "val_acc": 52.0}
{"epoch": 13, "training_loss": 160.89859986305237, "training_acc": 61.0, "val_loss": 67.959064245224, "val_acc": 48.0}
{"epoch": 14, "training_loss": 232.65016078948975, "training_acc": 47.0, "val_loss": 73.50573539733887, "val_acc": 52.0}
{"epoch": 15, "training_loss": 269.90637588500977, "training_acc": 53.0, "val_loss": 51.89233422279358, "val_acc": 52.0}
{"epoch": 16, "training_loss": 184.85275745391846, "training_acc": 50.0, "val_loss": 67.79943704605103, "val_acc": 48.0}
{"epoch": 17, "training_loss": 225.93800473213196, "training_acc": 51.0, "val_loss": 77.33555436134338, "val_acc": 52.0}
{"epoch": 18, "training_loss": 225.42535495758057, "training_acc": 54.0, "val_loss": 18.14921200275421, "val_acc": 56.0}
{"epoch": 19, "training_loss": 91.68354558944702, "training_acc": 63.0, "val_loss": 17.13852882385254, "val_acc": 64.0}
{"epoch": 20, "training_loss": 120.63455581665039, "training_acc": 60.0, "val_loss": 31.152084469795227, "val_acc": 56.0}
{"epoch": 21, "training_loss": 98.57759189605713, "training_acc": 54.0, "val_loss": 20.486044883728027, "val_acc": 44.0}
{"epoch": 22, "training_loss": 115.31346225738525, "training_acc": 55.0, "val_loss": 47.34238386154175, "val_acc": 52.0}
{"epoch": 23, "training_loss": 109.87954354286194, "training_acc": 62.0, "val_loss": 30.62155842781067, "val_acc": 48.0}
{"epoch": 24, "training_loss": 104.97978782653809, "training_acc": 55.0, "val_loss": 43.07447373867035, "val_acc": 52.0}
{"epoch": 25, "training_loss": 124.27999114990234, "training_acc": 49.0, "val_loss": 26.984211802482605, "val_acc": 52.0}
{"epoch": 26, "training_loss": 92.31855320930481, "training_acc": 57.0, "val_loss": 49.35221076011658, "val_acc": 52.0}
{"epoch": 27, "training_loss": 127.92232894897461, "training_acc": 55.0, "val_loss": 48.46121072769165, "val_acc": 48.0}
{"epoch": 28, "training_loss": 181.00047540664673, "training_acc": 47.0, "val_loss": 55.53056001663208, "val_acc": 52.0}
{"epoch": 29, "training_loss": 157.23041105270386, "training_acc": 53.0, "val_loss": 19.688555598258972, "val_acc": 52.0}
{"epoch": 30, "training_loss": 102.35254430770874, "training_acc": 51.0, "val_loss": 44.77006494998932, "val_acc": 52.0}
{"epoch": 31, "training_loss": 112.09991383552551, "training_acc": 55.0, "val_loss": 20.13257145881653, "val_acc": 52.0}
{"epoch": 32, "training_loss": 89.15723872184753, "training_acc": 55.0, "val_loss": 28.04829478263855, "val_acc": 56.0}
{"epoch": 33, "training_loss": 74.41862630844116, "training_acc": 66.0, "val_loss": 23.256786167621613, "val_acc": 48.0}
{"epoch": 34, "training_loss": 145.63821649551392, "training_acc": 42.0, "val_loss": 16.422981023788452, "val_acc": 64.0}
{"epoch": 35, "training_loss": 91.41467666625977, "training_acc": 59.0, "val_loss": 29.473543167114258, "val_acc": 52.0}
{"epoch": 36, "training_loss": 83.90641832351685, "training_acc": 58.0, "val_loss": 28.612402081489563, "val_acc": 48.0}
{"epoch": 37, "training_loss": 113.60898804664612, "training_acc": 56.0, "val_loss": 44.4021075963974, "val_acc": 52.0}
{"epoch": 38, "training_loss": 109.06120562553406, "training_acc": 55.0, "val_loss": 31.903740763664246, "val_acc": 48.0}
{"epoch": 39, "training_loss": 110.48636245727539, "training_acc": 53.0, "val_loss": 32.98337459564209, "val_acc": 52.0}
{"epoch": 40, "training_loss": 100.07949090003967, "training_acc": 50.0, "val_loss": 16.0003662109375, "val_acc": 56.0}
{"epoch": 41, "training_loss": 65.99988675117493, "training_acc": 67.0, "val_loss": 16.956737637519836, "val_acc": 64.0}
{"epoch": 42, "training_loss": 65.84523868560791, "training_acc": 67.0, "val_loss": 38.30125033855438, "val_acc": 52.0}
{"epoch": 43, "training_loss": 103.53937602043152, "training_acc": 55.0, "val_loss": 63.15228343009949, "val_acc": 48.0}
{"epoch": 44, "training_loss": 210.63963270187378, "training_acc": 47.0, "val_loss": 59.126633405685425, "val_acc": 52.0}
{"epoch": 45, "training_loss": 194.103675365448, "training_acc": 53.0, "val_loss": 18.701907992362976, "val_acc": 56.0}
{"epoch": 46, "training_loss": 78.8863365650177, "training_acc": 52.0, "val_loss": 26.618248224258423, "val_acc": 52.0}
{"epoch": 47, "training_loss": 74.54151558876038, "training_acc": 64.0, "val_loss": 18.585284054279327, "val_acc": 56.0}
{"epoch": 48, "training_loss": 64.3902485370636, "training_acc": 62.0, "val_loss": 25.938841700553894, "val_acc": 52.0}
{"epoch": 49, "training_loss": 84.73535180091858, "training_acc": 53.0, "val_loss": 19.21277642250061, "val_acc": 56.0}
{"epoch": 50, "training_loss": 62.87746834754944, "training_acc": 61.0, "val_loss": 17.076376080513, "val_acc": 64.0}
{"epoch": 51, "training_loss": 56.39321947097778, "training_acc": 74.0, "val_loss": 16.397210955619812, "val_acc": 68.0}
{"epoch": 52, "training_loss": 59.9592981338501, "training_acc": 66.0, "val_loss": 16.72104299068451, "val_acc": 64.0}
{"epoch": 53, "training_loss": 64.0317280292511, "training_acc": 59.0, "val_loss": 36.68700456619263, "val_acc": 52.0}
{"epoch": 54, "training_loss": 87.73421001434326, "training_acc": 61.0, "val_loss": 32.35020339488983, "val_acc": 48.0}
{"epoch": 55, "training_loss": 93.67286968231201, "training_acc": 59.0, "val_loss": 36.770179867744446, "val_acc": 52.0}
{"epoch": 56, "training_loss": 117.30047798156738, "training_acc": 44.0, "val_loss": 21.38378918170929, "val_acc": 60.0}
{"epoch": 57, "training_loss": 58.40424656867981, "training_acc": 63.0, "val_loss": 22.94514775276184, "val_acc": 48.0}
{"epoch": 58, "training_loss": 63.50212502479553, "training_acc": 65.0, "val_loss": 24.013543128967285, "val_acc": 56.0}
{"epoch": 59, "training_loss": 76.57371854782104, "training_acc": 60.0, "val_loss": 17.200160026550293, "val_acc": 68.0}
