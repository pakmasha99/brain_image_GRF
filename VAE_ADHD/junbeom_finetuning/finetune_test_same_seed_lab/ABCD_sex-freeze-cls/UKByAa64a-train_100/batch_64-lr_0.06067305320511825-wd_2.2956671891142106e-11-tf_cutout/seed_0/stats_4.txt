"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 196.86194229125977, "training_acc": 48.0, "val_loss": 34.630587697029114, "val_acc": 52.0}
{"epoch": 1, "training_loss": 117.67044496536255, "training_acc": 59.0, "val_loss": 61.00143790245056, "val_acc": 48.0}
{"epoch": 2, "training_loss": 232.12533283233643, "training_acc": 47.0, "val_loss": 22.76831567287445, "val_acc": 48.0}
{"epoch": 3, "training_loss": 91.57972645759583, "training_acc": 51.0, "val_loss": 44.048574566841125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 178.38546180725098, "training_acc": 53.0, "val_loss": 34.032222628593445, "val_acc": 52.0}
{"epoch": 5, "training_loss": 106.47449922561646, "training_acc": 52.0, "val_loss": 25.493532419204712, "val_acc": 48.0}
{"epoch": 6, "training_loss": 123.99019718170166, "training_acc": 47.0, "val_loss": 33.04787278175354, "val_acc": 48.0}
{"epoch": 7, "training_loss": 119.76035356521606, "training_acc": 47.0, "val_loss": 18.353089690208435, "val_acc": 52.0}
{"epoch": 8, "training_loss": 76.19011569023132, "training_acc": 54.0, "val_loss": 31.191566586494446, "val_acc": 52.0}
{"epoch": 9, "training_loss": 114.30385208129883, "training_acc": 53.0, "val_loss": 20.5311119556427, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.97958374023438, "training_acc": 55.0, "val_loss": 22.169257700443268, "val_acc": 48.0}
{"epoch": 11, "training_loss": 90.49841904640198, "training_acc": 47.0, "val_loss": 21.162329614162445, "val_acc": 48.0}
{"epoch": 12, "training_loss": 79.6961407661438, "training_acc": 48.0, "val_loss": 19.02856081724167, "val_acc": 52.0}
{"epoch": 13, "training_loss": 79.4178524017334, "training_acc": 53.0, "val_loss": 20.08475661277771, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.9908983707428, "training_acc": 53.0, "val_loss": 18.844859302043915, "val_acc": 56.0}
{"epoch": 15, "training_loss": 78.4620053768158, "training_acc": 49.0, "val_loss": 21.55681550502777, "val_acc": 48.0}
{"epoch": 16, "training_loss": 78.4726824760437, "training_acc": 47.0, "val_loss": 18.130378425121307, "val_acc": 52.0}
{"epoch": 17, "training_loss": 77.54948854446411, "training_acc": 53.0, "val_loss": 22.97721952199936, "val_acc": 52.0}
{"epoch": 18, "training_loss": 82.87537813186646, "training_acc": 53.0, "val_loss": 17.321620881557465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.46353197097778, "training_acc": 57.0, "val_loss": 20.104902982711792, "val_acc": 52.0}
{"epoch": 20, "training_loss": 77.06325149536133, "training_acc": 48.0, "val_loss": 17.224492132663727, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.45204615592957, "training_acc": 54.0, "val_loss": 20.323048532009125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 74.63610363006592, "training_acc": 52.0, "val_loss": 17.21278727054596, "val_acc": 52.0}
{"epoch": 23, "training_loss": 64.44684290885925, "training_acc": 58.0, "val_loss": 19.37565803527832, "val_acc": 48.0}
{"epoch": 24, "training_loss": 73.53316235542297, "training_acc": 47.0, "val_loss": 17.269332706928253, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65.3495602607727, "training_acc": 63.0, "val_loss": 18.548594415187836, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.89896893501282, "training_acc": 52.0, "val_loss": 17.39785224199295, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.25611138343811, "training_acc": 58.0, "val_loss": 18.29281598329544, "val_acc": 64.0}
{"epoch": 28, "training_loss": 69.76109218597412, "training_acc": 50.0, "val_loss": 17.24090576171875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 66.33008408546448, "training_acc": 61.0, "val_loss": 17.395497858524323, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.00835514068604, "training_acc": 59.0, "val_loss": 17.167015373706818, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.36763000488281, "training_acc": 61.0, "val_loss": 17.11859107017517, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.70483207702637, "training_acc": 57.0, "val_loss": 17.10560917854309, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.09651398658752, "training_acc": 69.0, "val_loss": 17.390693724155426, "val_acc": 56.0}
{"epoch": 34, "training_loss": 66.84011054039001, "training_acc": 59.0, "val_loss": 17.121750116348267, "val_acc": 52.0}
{"epoch": 35, "training_loss": 62.87500810623169, "training_acc": 68.0, "val_loss": 17.2452375292778, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.2551543712616, "training_acc": 56.0, "val_loss": 17.137672007083893, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.94205856323242, "training_acc": 63.0, "val_loss": 17.31368601322174, "val_acc": 56.0}
{"epoch": 38, "training_loss": 63.86712288856506, "training_acc": 69.0, "val_loss": 17.08209365606308, "val_acc": 52.0}
{"epoch": 39, "training_loss": 64.87274217605591, "training_acc": 68.0, "val_loss": 17.168959975242615, "val_acc": 52.0}
{"epoch": 40, "training_loss": 63.989086866378784, "training_acc": 66.0, "val_loss": 17.07817018032074, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.16512179374695, "training_acc": 53.0, "val_loss": 17.108936607837677, "val_acc": 52.0}
{"epoch": 42, "training_loss": 63.46930241584778, "training_acc": 67.0, "val_loss": 17.18173176050186, "val_acc": 56.0}
{"epoch": 43, "training_loss": 65.3714325428009, "training_acc": 65.0, "val_loss": 17.20612347126007, "val_acc": 52.0}
{"epoch": 44, "training_loss": 66.74943923950195, "training_acc": 59.0, "val_loss": 17.248263955116272, "val_acc": 52.0}
{"epoch": 45, "training_loss": 64.20281529426575, "training_acc": 66.0, "val_loss": 17.350110411643982, "val_acc": 52.0}
{"epoch": 46, "training_loss": 64.59813618659973, "training_acc": 69.0, "val_loss": 17.817671597003937, "val_acc": 52.0}
{"epoch": 47, "training_loss": 65.07624888420105, "training_acc": 65.0, "val_loss": 17.174579203128815, "val_acc": 52.0}
{"epoch": 48, "training_loss": 65.0202944278717, "training_acc": 58.0, "val_loss": 17.42701828479767, "val_acc": 52.0}
{"epoch": 49, "training_loss": 60.210164308547974, "training_acc": 68.0, "val_loss": 17.93249100446701, "val_acc": 52.0}
{"epoch": 50, "training_loss": 63.186535358428955, "training_acc": 60.0, "val_loss": 17.722150683403015, "val_acc": 52.0}
{"epoch": 51, "training_loss": 66.46483159065247, "training_acc": 58.0, "val_loss": 17.276020348072052, "val_acc": 56.0}
{"epoch": 52, "training_loss": 65.08941078186035, "training_acc": 61.0, "val_loss": 17.12566316127777, "val_acc": 52.0}
{"epoch": 53, "training_loss": 63.32265901565552, "training_acc": 63.0, "val_loss": 17.021846771240234, "val_acc": 52.0}
{"epoch": 54, "training_loss": 62.84956693649292, "training_acc": 68.0, "val_loss": 17.04157590866089, "val_acc": 52.0}
{"epoch": 55, "training_loss": 63.55987858772278, "training_acc": 69.0, "val_loss": 17.076191306114197, "val_acc": 52.0}
{"epoch": 56, "training_loss": 65.16906261444092, "training_acc": 60.0, "val_loss": 17.11941659450531, "val_acc": 52.0}
{"epoch": 57, "training_loss": 65.16314888000488, "training_acc": 58.0, "val_loss": 17.09265112876892, "val_acc": 56.0}
{"epoch": 58, "training_loss": 63.368884563446045, "training_acc": 70.0, "val_loss": 18.118613958358765, "val_acc": 52.0}
{"epoch": 59, "training_loss": 66.85514879226685, "training_acc": 60.0, "val_loss": 17.257778346538544, "val_acc": 52.0}
{"epoch": 60, "training_loss": 60.21401929855347, "training_acc": 75.0, "val_loss": 17.5016850233078, "val_acc": 56.0}
{"epoch": 61, "training_loss": 62.677290201187134, "training_acc": 71.0, "val_loss": 17.746680974960327, "val_acc": 52.0}
{"epoch": 62, "training_loss": 65.92302370071411, "training_acc": 55.0, "val_loss": 17.61309951543808, "val_acc": 52.0}
{"epoch": 63, "training_loss": 62.8988356590271, "training_acc": 62.0, "val_loss": 18.88461261987686, "val_acc": 52.0}
{"epoch": 64, "training_loss": 70.64470863342285, "training_acc": 51.0, "val_loss": 17.01200008392334, "val_acc": 56.0}
{"epoch": 65, "training_loss": 61.760130643844604, "training_acc": 66.0, "val_loss": 20.52093893289566, "val_acc": 52.0}
{"epoch": 66, "training_loss": 67.68743634223938, "training_acc": 55.0, "val_loss": 18.64517480134964, "val_acc": 48.0}
{"epoch": 67, "training_loss": 67.80037355422974, "training_acc": 52.0, "val_loss": 20.808877050876617, "val_acc": 48.0}
{"epoch": 68, "training_loss": 65.42424702644348, "training_acc": 56.0, "val_loss": 21.067804098129272, "val_acc": 52.0}
{"epoch": 69, "training_loss": 79.25690460205078, "training_acc": 53.0, "val_loss": 19.443252682685852, "val_acc": 52.0}
{"epoch": 70, "training_loss": 63.570720911026, "training_acc": 67.0, "val_loss": 23.32635074853897, "val_acc": 48.0}
{"epoch": 71, "training_loss": 81.56633806228638, "training_acc": 47.0, "val_loss": 17.232489585876465, "val_acc": 64.0}
{"epoch": 72, "training_loss": 66.2679398059845, "training_acc": 65.0, "val_loss": 21.66917324066162, "val_acc": 52.0}
{"epoch": 73, "training_loss": 72.360515832901, "training_acc": 58.0, "val_loss": 18.016229569911957, "val_acc": 64.0}
{"epoch": 74, "training_loss": 62.05781579017639, "training_acc": 58.0, "val_loss": 18.101665377616882, "val_acc": 60.0}
{"epoch": 75, "training_loss": 61.35713291168213, "training_acc": 65.0, "val_loss": 18.117380142211914, "val_acc": 52.0}
{"epoch": 76, "training_loss": 65.38792133331299, "training_acc": 59.0, "val_loss": 17.13714897632599, "val_acc": 56.0}
{"epoch": 77, "training_loss": 62.03054404258728, "training_acc": 60.0, "val_loss": 18.555819988250732, "val_acc": 56.0}
{"epoch": 78, "training_loss": 66.10410737991333, "training_acc": 56.0, "val_loss": 18.213897943496704, "val_acc": 52.0}
{"epoch": 79, "training_loss": 65.93203234672546, "training_acc": 59.0, "val_loss": 17.152631282806396, "val_acc": 56.0}
{"epoch": 80, "training_loss": 64.19506192207336, "training_acc": 63.0, "val_loss": 18.90321671962738, "val_acc": 56.0}
{"epoch": 81, "training_loss": 61.1716730594635, "training_acc": 62.0, "val_loss": 18.945877254009247, "val_acc": 52.0}
{"epoch": 82, "training_loss": 68.63283729553223, "training_acc": 57.0, "val_loss": 17.693598568439484, "val_acc": 52.0}
{"epoch": 83, "training_loss": 62.130024671554565, "training_acc": 65.0, "val_loss": 19.275909662246704, "val_acc": 56.0}
