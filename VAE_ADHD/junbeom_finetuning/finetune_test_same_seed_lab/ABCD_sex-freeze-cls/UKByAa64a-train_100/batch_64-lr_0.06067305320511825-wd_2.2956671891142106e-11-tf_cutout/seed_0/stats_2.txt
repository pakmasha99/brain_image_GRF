"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 201.14287757873535, "training_acc": 45.0, "val_loss": 29.31043803691864, "val_acc": 48.0}
{"epoch": 1, "training_loss": 122.81916284561157, "training_acc": 55.0, "val_loss": 73.75492453575134, "val_acc": 52.0}
{"epoch": 2, "training_loss": 280.01026916503906, "training_acc": 53.0, "val_loss": 45.377638936042786, "val_acc": 52.0}
{"epoch": 3, "training_loss": 139.0661964416504, "training_acc": 53.0, "val_loss": 35.254594683647156, "val_acc": 48.0}
{"epoch": 4, "training_loss": 163.3559513092041, "training_acc": 47.0, "val_loss": 46.24694287776947, "val_acc": 48.0}
{"epoch": 5, "training_loss": 159.9427409172058, "training_acc": 47.0, "val_loss": 17.59262979030609, "val_acc": 52.0}
{"epoch": 6, "training_loss": 90.05531978607178, "training_acc": 53.0, "val_loss": 37.45920956134796, "val_acc": 52.0}
{"epoch": 7, "training_loss": 139.4094042778015, "training_acc": 53.0, "val_loss": 22.42230772972107, "val_acc": 52.0}
{"epoch": 8, "training_loss": 83.97123003005981, "training_acc": 49.0, "val_loss": 25.705567002296448, "val_acc": 48.0}
{"epoch": 9, "training_loss": 104.108314037323, "training_acc": 48.0, "val_loss": 24.01214987039566, "val_acc": 48.0}
{"epoch": 10, "training_loss": 84.5602560043335, "training_acc": 48.0, "val_loss": 19.389256834983826, "val_acc": 52.0}
{"epoch": 11, "training_loss": 81.06571960449219, "training_acc": 53.0, "val_loss": 23.28868806362152, "val_acc": 52.0}
{"epoch": 12, "training_loss": 84.74678325653076, "training_acc": 53.0, "val_loss": 17.255626618862152, "val_acc": 52.0}
{"epoch": 13, "training_loss": 77.01647210121155, "training_acc": 47.0, "val_loss": 21.497592329978943, "val_acc": 48.0}
{"epoch": 14, "training_loss": 80.89774870872498, "training_acc": 47.0, "val_loss": 16.989101469516754, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.82162165641785, "training_acc": 55.0, "val_loss": 19.9462890625, "val_acc": 52.0}
{"epoch": 16, "training_loss": 76.59504628181458, "training_acc": 53.0, "val_loss": 16.938918828964233, "val_acc": 52.0}
{"epoch": 17, "training_loss": 64.50255107879639, "training_acc": 66.0, "val_loss": 18.401633203029633, "val_acc": 60.0}
{"epoch": 18, "training_loss": 73.35917615890503, "training_acc": 46.0, "val_loss": 16.87384694814682, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.36410665512085, "training_acc": 57.0, "val_loss": 18.10334175825119, "val_acc": 52.0}
{"epoch": 20, "training_loss": 71.65891313552856, "training_acc": 53.0, "val_loss": 16.922375559806824, "val_acc": 52.0}
{"epoch": 21, "training_loss": 66.25185871124268, "training_acc": 58.0, "val_loss": 18.64960491657257, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72.34641861915588, "training_acc": 50.0, "val_loss": 16.90438836812973, "val_acc": 52.0}
{"epoch": 23, "training_loss": 62.968119382858276, "training_acc": 73.0, "val_loss": 19.113755226135254, "val_acc": 52.0}
{"epoch": 24, "training_loss": 76.19109177589417, "training_acc": 53.0, "val_loss": 17.083589732646942, "val_acc": 52.0}
{"epoch": 25, "training_loss": 64.32022213935852, "training_acc": 60.0, "val_loss": 18.511962890625, "val_acc": 56.0}
{"epoch": 26, "training_loss": 75.30736184120178, "training_acc": 48.0, "val_loss": 16.850650310516357, "val_acc": 52.0}
{"epoch": 27, "training_loss": 64.45092463493347, "training_acc": 64.0, "val_loss": 20.64232975244522, "val_acc": 52.0}
{"epoch": 28, "training_loss": 75.48276162147522, "training_acc": 53.0, "val_loss": 17.038841545581818, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.61370420455933, "training_acc": 57.0, "val_loss": 19.94471251964569, "val_acc": 44.0}
{"epoch": 30, "training_loss": 77.43185186386108, "training_acc": 49.0, "val_loss": 16.94999635219574, "val_acc": 52.0}
{"epoch": 31, "training_loss": 63.71023106575012, "training_acc": 72.0, "val_loss": 20.555098354816437, "val_acc": 52.0}
{"epoch": 32, "training_loss": 74.18334221839905, "training_acc": 53.0, "val_loss": 17.48598963022232, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.57899594306946, "training_acc": 48.0, "val_loss": 18.520893156528473, "val_acc": 60.0}
{"epoch": 34, "training_loss": 67.32647490501404, "training_acc": 53.0, "val_loss": 17.511913180351257, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.89001774787903, "training_acc": 59.0, "val_loss": 19.855645298957825, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.79616856575012, "training_acc": 55.0, "val_loss": 17.100198566913605, "val_acc": 56.0}
{"epoch": 37, "training_loss": 65.41749215126038, "training_acc": 59.0, "val_loss": 18.111972510814667, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.65297722816467, "training_acc": 51.0, "val_loss": 18.35165172815323, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.95765924453735, "training_acc": 56.0, "val_loss": 18.448597192764282, "val_acc": 52.0}
{"epoch": 40, "training_loss": 65.2848961353302, "training_acc": 61.0, "val_loss": 17.486131191253662, "val_acc": 52.0}
{"epoch": 41, "training_loss": 66.1066164970398, "training_acc": 55.0, "val_loss": 16.911843419075012, "val_acc": 52.0}
{"epoch": 42, "training_loss": 64.31301879882812, "training_acc": 66.0, "val_loss": 18.173064291477203, "val_acc": 52.0}
{"epoch": 43, "training_loss": 65.32562232017517, "training_acc": 57.0, "val_loss": 16.915231943130493, "val_acc": 52.0}
{"epoch": 44, "training_loss": 63.48463487625122, "training_acc": 70.0, "val_loss": 17.14007556438446, "val_acc": 56.0}
{"epoch": 45, "training_loss": 67.67153787612915, "training_acc": 55.0, "val_loss": 17.35745221376419, "val_acc": 52.0}
