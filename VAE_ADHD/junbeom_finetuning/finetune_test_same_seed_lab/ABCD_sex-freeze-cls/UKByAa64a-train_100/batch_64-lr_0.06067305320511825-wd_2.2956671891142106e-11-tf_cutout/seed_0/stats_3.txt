"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 217.7689266204834, "training_acc": 42.0, "val_loss": 31.358209252357483, "val_acc": 48.0}
{"epoch": 1, "training_loss": 143.74062204360962, "training_acc": 49.0, "val_loss": 70.4792857170105, "val_acc": 52.0}
{"epoch": 2, "training_loss": 263.0586156845093, "training_acc": 53.0, "val_loss": 46.3330864906311, "val_acc": 52.0}
{"epoch": 3, "training_loss": 133.036780834198, "training_acc": 53.0, "val_loss": 31.459036469459534, "val_acc": 48.0}
{"epoch": 4, "training_loss": 157.70037269592285, "training_acc": 47.0, "val_loss": 46.89880609512329, "val_acc": 48.0}
{"epoch": 5, "training_loss": 167.5597596168518, "training_acc": 47.0, "val_loss": 17.654940485954285, "val_acc": 52.0}
{"epoch": 6, "training_loss": 80.9360899925232, "training_acc": 56.0, "val_loss": 39.2657071352005, "val_acc": 52.0}
{"epoch": 7, "training_loss": 138.16815853118896, "training_acc": 53.0, "val_loss": 29.56523299217224, "val_acc": 52.0}
{"epoch": 8, "training_loss": 92.58035206794739, "training_acc": 54.0, "val_loss": 20.616115629673004, "val_acc": 48.0}
{"epoch": 9, "training_loss": 96.51898288726807, "training_acc": 47.0, "val_loss": 26.43442451953888, "val_acc": 48.0}
{"epoch": 10, "training_loss": 98.85243630409241, "training_acc": 47.0, "val_loss": 18.721911311149597, "val_acc": 52.0}
{"epoch": 11, "training_loss": 83.84631872177124, "training_acc": 53.0, "val_loss": 27.82805860042572, "val_acc": 52.0}
{"epoch": 12, "training_loss": 93.04230046272278, "training_acc": 53.0, "val_loss": 18.53458732366562, "val_acc": 52.0}
{"epoch": 13, "training_loss": 72.18076157569885, "training_acc": 47.0, "val_loss": 20.512355864048004, "val_acc": 48.0}
{"epoch": 14, "training_loss": 82.25127267837524, "training_acc": 47.0, "val_loss": 17.719528079032898, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10412573814392, "training_acc": 50.0, "val_loss": 19.3275049328804, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.01970338821411, "training_acc": 53.0, "val_loss": 18.20506751537323, "val_acc": 52.0}
{"epoch": 17, "training_loss": 66.9814224243164, "training_acc": 57.0, "val_loss": 17.582133412361145, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.55620956420898, "training_acc": 49.0, "val_loss": 17.41032600402832, "val_acc": 52.0}
{"epoch": 19, "training_loss": 73.43673801422119, "training_acc": 47.0, "val_loss": 18.854613602161407, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.65163922309875, "training_acc": 52.0, "val_loss": 17.47957617044449, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.31753611564636, "training_acc": 59.0, "val_loss": 17.60694831609726, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.9071877002716, "training_acc": 49.0, "val_loss": 17.60665625333786, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.60231709480286, "training_acc": 53.0, "val_loss": 19.190819561481476, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.1760802268982, "training_acc": 53.0, "val_loss": 18.15866231918335, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.44062304496765, "training_acc": 68.0, "val_loss": 17.90744811296463, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.77350163459778, "training_acc": 56.0, "val_loss": 18.46754103899002, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.51604533195496, "training_acc": 58.0, "val_loss": 19.062411785125732, "val_acc": 52.0}
{"epoch": 28, "training_loss": 67.0266375541687, "training_acc": 55.0, "val_loss": 17.93682873249054, "val_acc": 52.0}
{"epoch": 29, "training_loss": 64.79040169715881, "training_acc": 69.0, "val_loss": 18.111373484134674, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.32689356803894, "training_acc": 57.0, "val_loss": 18.041248619556427, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.95338082313538, "training_acc": 64.0, "val_loss": 17.65730232000351, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.06771779060364, "training_acc": 60.0, "val_loss": 18.231108784675598, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.75706791877747, "training_acc": 60.0, "val_loss": 17.695175111293793, "val_acc": 52.0}
{"epoch": 34, "training_loss": 65.57893824577332, "training_acc": 59.0, "val_loss": 17.563891410827637, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64.11264204978943, "training_acc": 66.0, "val_loss": 18.054573237895966, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.60425758361816, "training_acc": 65.0, "val_loss": 17.772293090820312, "val_acc": 52.0}
{"epoch": 37, "training_loss": 63.72192192077637, "training_acc": 71.0, "val_loss": 17.67352819442749, "val_acc": 52.0}
