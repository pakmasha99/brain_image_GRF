"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 130270.67429351807, "training_acc": 49.0, "val_loss": 33678.50646972656, "val_acc": 52.0}
{"epoch": 1, "training_loss": 155001.01611328125, "training_acc": 49.0, "val_loss": 61462.59765625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 222375.7666015625, "training_acc": 47.0, "val_loss": 4261.65771484375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 67976.41552734375, "training_acc": 53.0, "val_loss": 71945.45288085938, "val_acc": 52.0}
{"epoch": 4, "training_loss": 267760.53515625, "training_acc": 53.0, "val_loss": 69176.92260742188, "val_acc": 52.0}
{"epoch": 5, "training_loss": 219752.0361328125, "training_acc": 53.0, "val_loss": 15128.166198730469, "val_acc": 52.0}
{"epoch": 6, "training_loss": 63673.41650390625, "training_acc": 55.0, "val_loss": 51859.295654296875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 229814.0439453125, "training_acc": 47.0, "val_loss": 49599.86572265625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 177569.7900390625, "training_acc": 47.0, "val_loss": 6017.2698974609375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 52470.521484375, "training_acc": 45.0, "val_loss": 41265.45104980469, "val_acc": 52.0}
{"epoch": 10, "training_loss": 137065.404296875, "training_acc": 53.0, "val_loss": 28396.19140625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 62963.59503173828, "training_acc": 53.0, "val_loss": 20594.107055664062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 112673.3486328125, "training_acc": 47.0, "val_loss": 33772.70202636719, "val_acc": 48.0}
{"epoch": 13, "training_loss": 123976.666015625, "training_acc": 47.0, "val_loss": 3163.1383895874023, "val_acc": 48.0}
{"epoch": 14, "training_loss": 44027.21337890625, "training_acc": 52.0, "val_loss": 28577.731323242188, "val_acc": 52.0}
{"epoch": 15, "training_loss": 88399.06103515625, "training_acc": 53.0, "val_loss": 9021.470642089844, "val_acc": 52.0}
{"epoch": 16, "training_loss": 45510.771728515625, "training_acc": 46.0, "val_loss": 23957.215881347656, "val_acc": 48.0}
{"epoch": 17, "training_loss": 96743.86328125, "training_acc": 47.0, "val_loss": 5648.2269287109375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 42263.894287109375, "training_acc": 45.0, "val_loss": 25432.02362060547, "val_acc": 52.0}
{"epoch": 19, "training_loss": 89860.05102539062, "training_acc": 53.0, "val_loss": 13501.8798828125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 38029.55029296875, "training_acc": 51.0, "val_loss": 11115.182495117188, "val_acc": 48.0}
{"epoch": 21, "training_loss": 37868.43591308594, "training_acc": 47.0, "val_loss": 8713.651275634766, "val_acc": 52.0}
{"epoch": 22, "training_loss": 44610.1953125, "training_acc": 53.0, "val_loss": 9643.01528930664, "val_acc": 52.0}
{"epoch": 23, "training_loss": 30655.371337890625, "training_acc": 48.0, "val_loss": 8027.934265136719, "val_acc": 48.0}
{"epoch": 24, "training_loss": 24221.595443725586, "training_acc": 49.0, "val_loss": 8437.908935546875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 23413.30303955078, "training_acc": 53.0, "val_loss": 3753.1494140625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 19782.98291015625, "training_acc": 48.0, "val_loss": 6094.174575805664, "val_acc": 52.0}
{"epoch": 27, "training_loss": 16528.665649414062, "training_acc": 53.0, "val_loss": 3151.127815246582, "val_acc": 48.0}
{"epoch": 28, "training_loss": 14117.476257324219, "training_acc": 51.0, "val_loss": 7436.611175537109, "val_acc": 52.0}
{"epoch": 29, "training_loss": 18823.932739257812, "training_acc": 54.0, "val_loss": 1742.8449630737305, "val_acc": 52.0}
{"epoch": 30, "training_loss": 13832.1552734375, "training_acc": 59.0, "val_loss": 5911.847686767578, "val_acc": 52.0}
{"epoch": 31, "training_loss": 10257.800231933594, "training_acc": 56.0, "val_loss": 2096.8353271484375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 8489.31689453125, "training_acc": 64.0, "val_loss": 3812.171173095703, "val_acc": 52.0}
{"epoch": 33, "training_loss": 6467.861236572266, "training_acc": 62.0, "val_loss": 2680.1225662231445, "val_acc": 52.0}
{"epoch": 34, "training_loss": 8334.437614440918, "training_acc": 61.0, "val_loss": 3106.5988540649414, "val_acc": 52.0}
{"epoch": 35, "training_loss": 10479.5419921875, "training_acc": 57.0, "val_loss": 578.5947322845459, "val_acc": 76.0}
{"epoch": 36, "training_loss": 12463.6591796875, "training_acc": 56.0, "val_loss": 2394.021987915039, "val_acc": 52.0}
{"epoch": 37, "training_loss": 16713.825561523438, "training_acc": 56.0, "val_loss": 4738.579559326172, "val_acc": 48.0}
{"epoch": 38, "training_loss": 21856.156860351562, "training_acc": 46.0, "val_loss": 10444.37255859375, "val_acc": 52.0}
{"epoch": 39, "training_loss": 23515.438110351562, "training_acc": 59.0, "val_loss": 8902.957916259766, "val_acc": 48.0}
{"epoch": 40, "training_loss": 31186.518920898438, "training_acc": 47.0, "val_loss": 6152.569198608398, "val_acc": 52.0}
{"epoch": 41, "training_loss": 17375.866149902344, "training_acc": 53.0, "val_loss": 2958.232307434082, "val_acc": 52.0}
{"epoch": 42, "training_loss": 10394.588439941406, "training_acc": 51.0, "val_loss": 7238.465118408203, "val_acc": 52.0}
{"epoch": 43, "training_loss": 15670.414642333984, "training_acc": 54.0, "val_loss": 8352.592468261719, "val_acc": 48.0}
{"epoch": 44, "training_loss": 32506.731079101562, "training_acc": 47.0, "val_loss": 4040.4312133789062, "val_acc": 52.0}
{"epoch": 45, "training_loss": 9615.885284423828, "training_acc": 60.0, "val_loss": 1047.9571342468262, "val_acc": 40.0}
{"epoch": 46, "training_loss": 3633.616241455078, "training_acc": 72.0, "val_loss": 3904.509735107422, "val_acc": 52.0}
{"epoch": 47, "training_loss": 5514.918853759766, "training_acc": 71.0, "val_loss": 4505.226516723633, "val_acc": 48.0}
{"epoch": 48, "training_loss": 12786.229202270508, "training_acc": 54.0, "val_loss": 3071.8549728393555, "val_acc": 52.0}
{"epoch": 49, "training_loss": 10269.869445800781, "training_acc": 56.0, "val_loss": 1719.5003509521484, "val_acc": 56.0}
{"epoch": 50, "training_loss": 4356.044403076172, "training_acc": 66.0, "val_loss": 5468.108367919922, "val_acc": 48.0}
{"epoch": 51, "training_loss": 15390.639694213867, "training_acc": 51.0, "val_loss": 10714.411926269531, "val_acc": 52.0}
{"epoch": 52, "training_loss": 35865.72033691406, "training_acc": 53.0, "val_loss": 1811.334228515625, "val_acc": 52.0}
{"epoch": 53, "training_loss": 21238.22119140625, "training_acc": 65.0, "val_loss": 14175.498962402344, "val_acc": 48.0}
{"epoch": 54, "training_loss": 43167.13539123535, "training_acc": 50.0, "val_loss": 16047.349548339844, "val_acc": 52.0}
