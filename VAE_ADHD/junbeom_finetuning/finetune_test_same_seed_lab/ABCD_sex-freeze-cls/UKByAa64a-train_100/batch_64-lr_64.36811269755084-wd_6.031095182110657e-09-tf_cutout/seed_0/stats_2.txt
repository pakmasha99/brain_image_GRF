"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 110511.05521011353, "training_acc": 51.0, "val_loss": 5240.77033996582, "val_acc": 40.0}
{"epoch": 1, "training_loss": 113917.6455078125, "training_acc": 57.0, "val_loss": 71846.56372070312, "val_acc": 52.0}
{"epoch": 2, "training_loss": 250829.05712890625, "training_acc": 53.0, "val_loss": 8221.287536621094, "val_acc": 52.0}
{"epoch": 3, "training_loss": 84150.7998046875, "training_acc": 51.0, "val_loss": 71920.55053710938, "val_acc": 48.0}
{"epoch": 4, "training_loss": 283676.0458984375, "training_acc": 47.0, "val_loss": 52149.212646484375, "val_acc": 48.0}
{"epoch": 5, "training_loss": 151662.41479492188, "training_acc": 47.0, "val_loss": 24698.50311279297, "val_acc": 52.0}
{"epoch": 6, "training_loss": 117011.83544921875, "training_acc": 53.0, "val_loss": 54938.76953125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 210871.48193359375, "training_acc": 53.0, "val_loss": 36263.61999511719, "val_acc": 52.0}
{"epoch": 8, "training_loss": 109705.91809082031, "training_acc": 53.0, "val_loss": 19072.589111328125, "val_acc": 48.0}
{"epoch": 9, "training_loss": 85959.12451171875, "training_acc": 47.0, "val_loss": 36012.25280761719, "val_acc": 48.0}
{"epoch": 10, "training_loss": 113548.34838867188, "training_acc": 47.0, "val_loss": 3330.3993225097656, "val_acc": 52.0}
{"epoch": 11, "training_loss": 45792.189697265625, "training_acc": 53.0, "val_loss": 34336.78894042969, "val_acc": 52.0}
{"epoch": 12, "training_loss": 131310.19677734375, "training_acc": 53.0, "val_loss": 23699.29656982422, "val_acc": 52.0}
{"epoch": 13, "training_loss": 75747.33642578125, "training_acc": 54.0, "val_loss": 23012.420654296875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 98847.75537109375, "training_acc": 46.0, "val_loss": 36178.97644042969, "val_acc": 48.0}
{"epoch": 15, "training_loss": 114323.71899414062, "training_acc": 47.0, "val_loss": 3054.7523498535156, "val_acc": 52.0}
{"epoch": 16, "training_loss": 42497.2568359375, "training_acc": 53.0, "val_loss": 32349.844360351562, "val_acc": 52.0}
{"epoch": 17, "training_loss": 123582.49267578125, "training_acc": 53.0, "val_loss": 21904.861450195312, "val_acc": 52.0}
{"epoch": 18, "training_loss": 59317.00192260742, "training_acc": 56.0, "val_loss": 22688.661193847656, "val_acc": 48.0}
{"epoch": 19, "training_loss": 99307.41064453125, "training_acc": 47.0, "val_loss": 32888.11340332031, "val_acc": 48.0}
{"epoch": 20, "training_loss": 103968.39770507812, "training_acc": 47.0, "val_loss": 2766.763687133789, "val_acc": 44.0}
{"epoch": 21, "training_loss": 31394.5498046875, "training_acc": 54.0, "val_loss": 19026.64337158203, "val_acc": 52.0}
{"epoch": 22, "training_loss": 63102.812255859375, "training_acc": 53.0, "val_loss": 4354.675674438477, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24123.602783203125, "training_acc": 56.0, "val_loss": 8863.816833496094, "val_acc": 48.0}
{"epoch": 24, "training_loss": 25957.651489257812, "training_acc": 52.0, "val_loss": 8654.206085205078, "val_acc": 52.0}
{"epoch": 25, "training_loss": 20060.05419921875, "training_acc": 55.0, "val_loss": 7862.120819091797, "val_acc": 48.0}
{"epoch": 26, "training_loss": 28881.929077148438, "training_acc": 50.0, "val_loss": 2612.472343444824, "val_acc": 56.0}
{"epoch": 27, "training_loss": 15208.070556640625, "training_acc": 62.0, "val_loss": 6427.638244628906, "val_acc": 52.0}
{"epoch": 28, "training_loss": 17589.685119628906, "training_acc": 58.0, "val_loss": 6737.009429931641, "val_acc": 48.0}
{"epoch": 29, "training_loss": 22987.731323242188, "training_acc": 50.0, "val_loss": 6634.806823730469, "val_acc": 52.0}
{"epoch": 30, "training_loss": 12268.753356933594, "training_acc": 58.0, "val_loss": 4719.365310668945, "val_acc": 44.0}
{"epoch": 31, "training_loss": 14464.625946044922, "training_acc": 56.0, "val_loss": 8418.040466308594, "val_acc": 52.0}
{"epoch": 32, "training_loss": 21971.668334960938, "training_acc": 54.0, "val_loss": 1862.2203826904297, "val_acc": 60.0}
{"epoch": 33, "training_loss": 10725.277465820312, "training_acc": 58.0, "val_loss": 4232.456588745117, "val_acc": 52.0}
{"epoch": 34, "training_loss": 10838.74331665039, "training_acc": 58.0, "val_loss": 3759.1323852539062, "val_acc": 44.0}
{"epoch": 35, "training_loss": 12613.694732666016, "training_acc": 55.0, "val_loss": 7357.942962646484, "val_acc": 52.0}
{"epoch": 36, "training_loss": 20269.00115966797, "training_acc": 57.0, "val_loss": 3591.194534301758, "val_acc": 44.0}
{"epoch": 37, "training_loss": 15090.328369140625, "training_acc": 48.0, "val_loss": 6089.195251464844, "val_acc": 52.0}
{"epoch": 38, "training_loss": 16372.887817382812, "training_acc": 57.0, "val_loss": 3432.0972442626953, "val_acc": 44.0}
{"epoch": 39, "training_loss": 10498.411697387695, "training_acc": 58.0, "val_loss": 6616.815185546875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 11908.399002075195, "training_acc": 56.0, "val_loss": 7930.316925048828, "val_acc": 48.0}
{"epoch": 41, "training_loss": 36526.30822753906, "training_acc": 47.0, "val_loss": 4705.242156982422, "val_acc": 52.0}
{"epoch": 42, "training_loss": 12225.372863769531, "training_acc": 60.0, "val_loss": 1541.221809387207, "val_acc": 52.0}
{"epoch": 43, "training_loss": 5528.991500854492, "training_acc": 68.0, "val_loss": 3477.3880004882812, "val_acc": 56.0}
{"epoch": 44, "training_loss": 6513.974105834961, "training_acc": 60.0, "val_loss": 3853.8646697998047, "val_acc": 40.0}
{"epoch": 45, "training_loss": 10791.662063598633, "training_acc": 58.0, "val_loss": 7402.989959716797, "val_acc": 52.0}
{"epoch": 46, "training_loss": 15650.482482910156, "training_acc": 53.0, "val_loss": 6305.170440673828, "val_acc": 48.0}
{"epoch": 47, "training_loss": 19466.2802734375, "training_acc": 48.0, "val_loss": 10440.921020507812, "val_acc": 52.0}
{"epoch": 48, "training_loss": 34532.63879394531, "training_acc": 53.0, "val_loss": 2297.319221496582, "val_acc": 56.0}
{"epoch": 49, "training_loss": 16418.112182617188, "training_acc": 68.0, "val_loss": 11583.724212646484, "val_acc": 48.0}
{"epoch": 50, "training_loss": 25316.533935546875, "training_acc": 51.0, "val_loss": 17103.456115722656, "val_acc": 52.0}
{"epoch": 51, "training_loss": 65405.147216796875, "training_acc": 53.0, "val_loss": 20115.45867919922, "val_acc": 52.0}
{"epoch": 52, "training_loss": 54097.58251953125, "training_acc": 56.0, "val_loss": 15034.542846679688, "val_acc": 48.0}
{"epoch": 53, "training_loss": 71698.78857421875, "training_acc": 47.0, "val_loss": 15478.302001953125, "val_acc": 48.0}
{"epoch": 54, "training_loss": 34439.72317504883, "training_acc": 60.0, "val_loss": 15896.180725097656, "val_acc": 52.0}
{"epoch": 55, "training_loss": 55599.66552734375, "training_acc": 53.0, "val_loss": 10141.358947753906, "val_acc": 52.0}
{"epoch": 56, "training_loss": 29171.4091796875, "training_acc": 54.0, "val_loss": 16822.308349609375, "val_acc": 48.0}
{"epoch": 57, "training_loss": 52034.78173828125, "training_acc": 47.0, "val_loss": 3687.78076171875, "val_acc": 56.0}
{"epoch": 58, "training_loss": 15814.316650390625, "training_acc": 57.0, "val_loss": 6786.676788330078, "val_acc": 52.0}
{"epoch": 59, "training_loss": 22880.42510986328, "training_acc": 54.0, "val_loss": 7283.431243896484, "val_acc": 48.0}
{"epoch": 60, "training_loss": 16032.076171875, "training_acc": 59.0, "val_loss": 7051.62353515625, "val_acc": 52.0}
{"epoch": 61, "training_loss": 16139.708892822266, "training_acc": 56.0, "val_loss": 5072.327041625977, "val_acc": 48.0}
