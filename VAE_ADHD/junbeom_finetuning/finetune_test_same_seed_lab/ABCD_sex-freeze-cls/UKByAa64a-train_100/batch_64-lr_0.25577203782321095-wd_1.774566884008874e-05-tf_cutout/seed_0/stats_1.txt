"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 581.60009765625, "training_acc": 46.0, "val_loss": 112.15029954910278, "val_acc": 52.0}
{"epoch": 1, "training_loss": 545.518424987793, "training_acc": 53.0, "val_loss": 290.85350036621094, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1094.1836547851562, "training_acc": 47.0, "val_loss": 80.64392805099487, "val_acc": 48.0}
{"epoch": 3, "training_loss": 381.0830545425415, "training_acc": 51.0, "val_loss": 212.33158111572266, "val_acc": 52.0}
{"epoch": 4, "training_loss": 807.4127464294434, "training_acc": 53.0, "val_loss": 189.4588589668274, "val_acc": 52.0}
{"epoch": 5, "training_loss": 562.9616813659668, "training_acc": 53.0, "val_loss": 34.85073447227478, "val_acc": 48.0}
{"epoch": 6, "training_loss": 315.1845016479492, "training_acc": 47.0, "val_loss": 106.89383745193481, "val_acc": 48.0}
{"epoch": 7, "training_loss": 371.65472316741943, "training_acc": 47.0, "val_loss": 54.83430624008179, "val_acc": 52.0}
{"epoch": 8, "training_loss": 218.046781539917, "training_acc": 53.0, "val_loss": 103.06097269058228, "val_acc": 52.0}
{"epoch": 9, "training_loss": 323.8560185432434, "training_acc": 53.0, "val_loss": 18.159739673137665, "val_acc": 56.0}
{"epoch": 10, "training_loss": 142.20720195770264, "training_acc": 50.0, "val_loss": 45.432883501052856, "val_acc": 48.0}
{"epoch": 11, "training_loss": 166.33079648017883, "training_acc": 45.0, "val_loss": 44.943296909332275, "val_acc": 52.0}
{"epoch": 12, "training_loss": 145.21038055419922, "training_acc": 53.0, "val_loss": 18.218544125556946, "val_acc": 56.0}
{"epoch": 13, "training_loss": 83.98133492469788, "training_acc": 51.0, "val_loss": 19.959701597690582, "val_acc": 44.0}
{"epoch": 14, "training_loss": 77.16919875144958, "training_acc": 57.0, "val_loss": 31.015545129776, "val_acc": 52.0}
{"epoch": 15, "training_loss": 91.6873984336853, "training_acc": 55.0, "val_loss": 21.315063536167145, "val_acc": 52.0}
{"epoch": 16, "training_loss": 84.68573331832886, "training_acc": 52.0, "val_loss": 23.584114015102386, "val_acc": 52.0}
{"epoch": 17, "training_loss": 83.04032492637634, "training_acc": 55.0, "val_loss": 16.61076694726944, "val_acc": 64.0}
{"epoch": 18, "training_loss": 91.92390060424805, "training_acc": 47.0, "val_loss": 21.595634520053864, "val_acc": 52.0}
{"epoch": 19, "training_loss": 90.81506252288818, "training_acc": 56.0, "val_loss": 18.731677532196045, "val_acc": 56.0}
{"epoch": 20, "training_loss": 65.55362391471863, "training_acc": 63.0, "val_loss": 21.401646733283997, "val_acc": 48.0}
{"epoch": 21, "training_loss": 89.28930020332336, "training_acc": 53.0, "val_loss": 27.146273851394653, "val_acc": 52.0}
{"epoch": 22, "training_loss": 79.36806917190552, "training_acc": 62.0, "val_loss": 18.925906717777252, "val_acc": 48.0}
{"epoch": 23, "training_loss": 72.10852861404419, "training_acc": 58.0, "val_loss": 19.997742772102356, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.80494499206543, "training_acc": 59.0, "val_loss": 17.420175671577454, "val_acc": 64.0}
{"epoch": 25, "training_loss": 63.19826626777649, "training_acc": 61.0, "val_loss": 19.834773242473602, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.75484418869019, "training_acc": 58.0, "val_loss": 17.89485514163971, "val_acc": 56.0}
{"epoch": 27, "training_loss": 63.81337785720825, "training_acc": 61.0, "val_loss": 17.108646035194397, "val_acc": 64.0}
{"epoch": 28, "training_loss": 62.82997679710388, "training_acc": 63.0, "val_loss": 17.328985035419464, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.585415840148926, "training_acc": 64.0, "val_loss": 23.640593886375427, "val_acc": 52.0}
{"epoch": 30, "training_loss": 77.52841377258301, "training_acc": 56.0, "val_loss": 18.334151804447174, "val_acc": 48.0}
{"epoch": 31, "training_loss": 65.82971930503845, "training_acc": 60.0, "val_loss": 25.264093279838562, "val_acc": 52.0}
{"epoch": 32, "training_loss": 78.00920724868774, "training_acc": 54.0, "val_loss": 22.449061274528503, "val_acc": 48.0}
{"epoch": 33, "training_loss": 83.80883741378784, "training_acc": 45.0, "val_loss": 20.979243516921997, "val_acc": 52.0}
{"epoch": 34, "training_loss": 75.60621285438538, "training_acc": 56.0, "val_loss": 27.989375591278076, "val_acc": 48.0}
{"epoch": 35, "training_loss": 105.84853339195251, "training_acc": 47.0, "val_loss": 29.364311695098877, "val_acc": 52.0}
{"epoch": 36, "training_loss": 99.00397729873657, "training_acc": 53.0, "val_loss": 19.344787299633026, "val_acc": 48.0}
