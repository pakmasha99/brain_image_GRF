"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 439.4976234436035, "training_acc": 53.0, "val_loss": 20.56405246257782, "val_acc": 52.0}
{"epoch": 1, "training_loss": 313.27942276000977, "training_acc": 52.0, "val_loss": 96.93606495857239, "val_acc": 48.0}
{"epoch": 2, "training_loss": 330.78322982788086, "training_acc": 51.0, "val_loss": 122.91743755340576, "val_acc": 52.0}
{"epoch": 3, "training_loss": 432.70640087127686, "training_acc": 53.0, "val_loss": 31.326156854629517, "val_acc": 48.0}
{"epoch": 4, "training_loss": 148.6297698020935, "training_acc": 47.0, "val_loss": 17.70593672990799, "val_acc": 56.0}
{"epoch": 5, "training_loss": 128.3322238922119, "training_acc": 56.0, "val_loss": 30.364850163459778, "val_acc": 52.0}
{"epoch": 6, "training_loss": 140.36139726638794, "training_acc": 45.0, "val_loss": 34.8686546087265, "val_acc": 48.0}
{"epoch": 7, "training_loss": 127.30519104003906, "training_acc": 49.0, "val_loss": 37.757959961891174, "val_acc": 52.0}
{"epoch": 8, "training_loss": 116.70617032051086, "training_acc": 54.0, "val_loss": 35.34380495548248, "val_acc": 48.0}
{"epoch": 9, "training_loss": 132.26551389694214, "training_acc": 48.0, "val_loss": 22.02715128660202, "val_acc": 52.0}
{"epoch": 10, "training_loss": 92.18633246421814, "training_acc": 56.0, "val_loss": 18.910042941570282, "val_acc": 60.0}
{"epoch": 11, "training_loss": 91.55072021484375, "training_acc": 51.0, "val_loss": 17.604979872703552, "val_acc": 56.0}
{"epoch": 12, "training_loss": 83.22533059120178, "training_acc": 55.0, "val_loss": 20.407380163669586, "val_acc": 52.0}
{"epoch": 13, "training_loss": 81.96292901039124, "training_acc": 48.0, "val_loss": 16.99548363685608, "val_acc": 60.0}
{"epoch": 14, "training_loss": 70.96727108955383, "training_acc": 61.0, "val_loss": 21.751968562602997, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.77856040000916, "training_acc": 58.0, "val_loss": 19.75693851709366, "val_acc": 56.0}
{"epoch": 16, "training_loss": 75.65285062789917, "training_acc": 59.0, "val_loss": 20.7885280251503, "val_acc": 52.0}
{"epoch": 17, "training_loss": 76.38266921043396, "training_acc": 58.0, "val_loss": 17.919164896011353, "val_acc": 56.0}
{"epoch": 18, "training_loss": 73.76699376106262, "training_acc": 57.0, "val_loss": 20.18389105796814, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.27155780792236, "training_acc": 62.0, "val_loss": 16.68289601802826, "val_acc": 60.0}
{"epoch": 20, "training_loss": 63.74313950538635, "training_acc": 63.0, "val_loss": 17.06109642982483, "val_acc": 52.0}
{"epoch": 21, "training_loss": 71.99743294715881, "training_acc": 53.0, "val_loss": 25.287726521492004, "val_acc": 52.0}
{"epoch": 22, "training_loss": 82.89047622680664, "training_acc": 53.0, "val_loss": 17.946510016918182, "val_acc": 52.0}
{"epoch": 23, "training_loss": 61.808329820632935, "training_acc": 63.0, "val_loss": 19.379602372646332, "val_acc": 52.0}
{"epoch": 24, "training_loss": 60.20316195487976, "training_acc": 63.0, "val_loss": 18.381720781326294, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.46832013130188, "training_acc": 58.0, "val_loss": 27.307844161987305, "val_acc": 52.0}
{"epoch": 26, "training_loss": 78.08033752441406, "training_acc": 60.0, "val_loss": 26.845073699951172, "val_acc": 48.0}
{"epoch": 27, "training_loss": 84.18726849555969, "training_acc": 50.0, "val_loss": 40.82110822200775, "val_acc": 52.0}
{"epoch": 28, "training_loss": 119.57876539230347, "training_acc": 53.0, "val_loss": 26.758071780204773, "val_acc": 48.0}
{"epoch": 29, "training_loss": 99.88830971717834, "training_acc": 47.0, "val_loss": 35.3005588054657, "val_acc": 52.0}
{"epoch": 30, "training_loss": 113.2438097000122, "training_acc": 53.0, "val_loss": 21.132782101631165, "val_acc": 48.0}
{"epoch": 31, "training_loss": 76.20492911338806, "training_acc": 52.0, "val_loss": 21.029096841812134, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.71848249435425, "training_acc": 61.0, "val_loss": 17.981955409049988, "val_acc": 52.0}
{"epoch": 33, "training_loss": 60.506545305252075, "training_acc": 66.0, "val_loss": 23.245377838611603, "val_acc": 52.0}
{"epoch": 34, "training_loss": 61.45972013473511, "training_acc": 66.0, "val_loss": 22.767673432826996, "val_acc": 44.0}
{"epoch": 35, "training_loss": 72.55513310432434, "training_acc": 58.0, "val_loss": 25.361919403076172, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.60564732551575, "training_acc": 65.0, "val_loss": 26.224756240844727, "val_acc": 48.0}
{"epoch": 37, "training_loss": 80.69660258293152, "training_acc": 54.0, "val_loss": 24.005141854286194, "val_acc": 52.0}
{"epoch": 38, "training_loss": 80.43359327316284, "training_acc": 50.0, "val_loss": 18.331952393054962, "val_acc": 52.0}
