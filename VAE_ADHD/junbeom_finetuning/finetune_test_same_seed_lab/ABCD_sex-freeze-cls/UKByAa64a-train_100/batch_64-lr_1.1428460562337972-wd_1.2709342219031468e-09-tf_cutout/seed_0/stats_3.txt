"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2776.5817489624023, "training_acc": 53.0, "val_loss": 563.5683059692383, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2723.3296813964844, "training_acc": 49.0, "val_loss": 1157.371997833252, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4272.766738891602, "training_acc": 47.0, "val_loss": 252.9139280319214, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1454.0043182373047, "training_acc": 49.0, "val_loss": 952.025032043457, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3604.975387573242, "training_acc": 53.0, "val_loss": 780.087423324585, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2263.0776329040527, "training_acc": 53.0, "val_loss": 263.3185386657715, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1465.7969131469727, "training_acc": 47.0, "val_loss": 542.4135684967041, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1823.4983139038086, "training_acc": 47.0, "val_loss": 129.5445203781128, "val_acc": 52.0}
{"epoch": 8, "training_loss": 634.1294136047363, "training_acc": 53.0, "val_loss": 309.89623069763184, "val_acc": 52.0}
{"epoch": 9, "training_loss": 882.3755874633789, "training_acc": 53.0, "val_loss": 237.17079162597656, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1073.8075714111328, "training_acc": 47.0, "val_loss": 231.693696975708, "val_acc": 48.0}
{"epoch": 11, "training_loss": 700.5406131744385, "training_acc": 45.0, "val_loss": 137.31248378753662, "val_acc": 52.0}
{"epoch": 12, "training_loss": 475.6323308944702, "training_acc": 56.0, "val_loss": 141.86235666275024, "val_acc": 48.0}
{"epoch": 13, "training_loss": 537.9115886688232, "training_acc": 47.0, "val_loss": 140.2051329612732, "val_acc": 52.0}
{"epoch": 14, "training_loss": 553.1704502105713, "training_acc": 53.0, "val_loss": 65.74797034263611, "val_acc": 52.0}
{"epoch": 15, "training_loss": 457.3684844970703, "training_acc": 48.0, "val_loss": 217.20666885375977, "val_acc": 48.0}
{"epoch": 16, "training_loss": 681.7967510223389, "training_acc": 51.0, "val_loss": 271.6693162918091, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1061.081901550293, "training_acc": 53.0, "val_loss": 265.9590482711792, "val_acc": 52.0}
{"epoch": 18, "training_loss": 593.8289651870728, "training_acc": 50.0, "val_loss": 142.18897819519043, "val_acc": 48.0}
{"epoch": 19, "training_loss": 486.21095085144043, "training_acc": 46.0, "val_loss": 218.3551549911499, "val_acc": 52.0}
{"epoch": 20, "training_loss": 762.3730163574219, "training_acc": 53.0, "val_loss": 172.38163948059082, "val_acc": 52.0}
{"epoch": 21, "training_loss": 534.3286323547363, "training_acc": 49.0, "val_loss": 182.65459537506104, "val_acc": 48.0}
{"epoch": 22, "training_loss": 603.0139675140381, "training_acc": 47.0, "val_loss": 271.39570713043213, "val_acc": 52.0}
{"epoch": 23, "training_loss": 939.6312713623047, "training_acc": 53.0, "val_loss": 309.89580154418945, "val_acc": 52.0}
{"epoch": 24, "training_loss": 659.6059265136719, "training_acc": 53.0, "val_loss": 258.86566638946533, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1281.883316040039, "training_acc": 47.0, "val_loss": 272.93758392333984, "val_acc": 48.0}
{"epoch": 26, "training_loss": 831.6416211128235, "training_acc": 50.0, "val_loss": 330.31301498413086, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1108.3503074645996, "training_acc": 53.0, "val_loss": 358.23278427124023, "val_acc": 52.0}
{"epoch": 28, "training_loss": 809.7102432250977, "training_acc": 53.0, "val_loss": 218.43721866607666, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1113.8284339904785, "training_acc": 47.0, "val_loss": 260.08098125457764, "val_acc": 48.0}
{"epoch": 30, "training_loss": 703.1747283935547, "training_acc": 53.0, "val_loss": 355.1272392272949, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1300.0011978149414, "training_acc": 53.0, "val_loss": 475.80509185791016, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1318.8660736083984, "training_acc": 53.0, "val_loss": 68.12592148780823, "val_acc": 52.0}
{"epoch": 33, "training_loss": 556.6697463989258, "training_acc": 48.0, "val_loss": 130.60177564620972, "val_acc": 48.0}
