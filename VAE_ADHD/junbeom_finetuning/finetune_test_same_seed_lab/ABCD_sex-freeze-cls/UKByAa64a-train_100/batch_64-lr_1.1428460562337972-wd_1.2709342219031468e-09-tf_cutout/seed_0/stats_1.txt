"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2744.631172180176, "training_acc": 53.0, "val_loss": 540.464973449707, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3184.001922607422, "training_acc": 41.0, "val_loss": 1163.226318359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4280.887664794922, "training_acc": 47.0, "val_loss": 271.4879035949707, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1140.5329513549805, "training_acc": 59.0, "val_loss": 959.0747833251953, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3655.2746963500977, "training_acc": 53.0, "val_loss": 920.1783180236816, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2903.261589050293, "training_acc": 53.0, "val_loss": 56.50716423988342, "val_acc": 48.0}
{"epoch": 6, "training_loss": 760.8393783569336, "training_acc": 57.0, "val_loss": 768.6901569366455, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3082.1350173950195, "training_acc": 47.0, "val_loss": 434.53516960144043, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1439.361605644226, "training_acc": 42.0, "val_loss": 324.3903636932373, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1106.3388557434082, "training_acc": 54.0, "val_loss": 199.15423393249512, "val_acc": 52.0}
{"epoch": 10, "training_loss": 669.5771427154541, "training_acc": 45.0, "val_loss": 181.10079765319824, "val_acc": 48.0}
{"epoch": 11, "training_loss": 555.0667014122009, "training_acc": 55.0, "val_loss": 224.25682544708252, "val_acc": 52.0}
{"epoch": 12, "training_loss": 796.9445686340332, "training_acc": 53.0, "val_loss": 86.5077018737793, "val_acc": 52.0}
{"epoch": 13, "training_loss": 806.574047088623, "training_acc": 35.0, "val_loss": 337.28909492492676, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1120.7855854034424, "training_acc": 47.0, "val_loss": 173.34444522857666, "val_acc": 52.0}
{"epoch": 15, "training_loss": 933.9997863769531, "training_acc": 53.0, "val_loss": 222.8473663330078, "val_acc": 52.0}
{"epoch": 16, "training_loss": 612.2606081962585, "training_acc": 57.0, "val_loss": 243.88635158538818, "val_acc": 48.0}
{"epoch": 17, "training_loss": 843.5730857849121, "training_acc": 47.0, "val_loss": 41.81939661502838, "val_acc": 32.0}
{"epoch": 18, "training_loss": 370.4619026184082, "training_acc": 57.0, "val_loss": 176.9276261329651, "val_acc": 52.0}
{"epoch": 19, "training_loss": 540.1245803833008, "training_acc": 52.0, "val_loss": 189.9597406387329, "val_acc": 48.0}
{"epoch": 20, "training_loss": 583.4047889709473, "training_acc": 49.0, "val_loss": 64.58555459976196, "val_acc": 52.0}
{"epoch": 21, "training_loss": 328.5208282470703, "training_acc": 55.0, "val_loss": 35.12106537818909, "val_acc": 32.0}
{"epoch": 22, "training_loss": 158.74274158477783, "training_acc": 55.0, "val_loss": 46.259552240371704, "val_acc": 56.0}
{"epoch": 23, "training_loss": 133.14264726638794, "training_acc": 59.0, "val_loss": 104.43412065505981, "val_acc": 48.0}
{"epoch": 24, "training_loss": 314.3850431442261, "training_acc": 48.0, "val_loss": 205.73036670684814, "val_acc": 52.0}
{"epoch": 25, "training_loss": 755.6724166870117, "training_acc": 53.0, "val_loss": 150.75302124023438, "val_acc": 52.0}
{"epoch": 26, "training_loss": 596.6779460906982, "training_acc": 46.0, "val_loss": 178.2021403312683, "val_acc": 48.0}
{"epoch": 27, "training_loss": 534.855776309967, "training_acc": 49.0, "val_loss": 174.44673776626587, "val_acc": 52.0}
{"epoch": 28, "training_loss": 546.7734451293945, "training_acc": 53.0, "val_loss": 33.65843594074249, "val_acc": 48.0}
{"epoch": 29, "training_loss": 165.33317041397095, "training_acc": 57.0, "val_loss": 32.21561014652252, "val_acc": 60.0}
{"epoch": 30, "training_loss": 94.059730052948, "training_acc": 68.0, "val_loss": 42.25924611091614, "val_acc": 48.0}
{"epoch": 31, "training_loss": 161.64874505996704, "training_acc": 53.0, "val_loss": 41.3196861743927, "val_acc": 48.0}
{"epoch": 32, "training_loss": 133.6950387954712, "training_acc": 58.0, "val_loss": 57.50631093978882, "val_acc": 52.0}
{"epoch": 33, "training_loss": 159.58496284484863, "training_acc": 56.0, "val_loss": 35.31959354877472, "val_acc": 40.0}
{"epoch": 34, "training_loss": 155.76481437683105, "training_acc": 59.0, "val_loss": 26.292431354522705, "val_acc": 48.0}
{"epoch": 35, "training_loss": 75.1231300830841, "training_acc": 65.0, "val_loss": 87.21177577972412, "val_acc": 52.0}
{"epoch": 36, "training_loss": 193.11359190940857, "training_acc": 58.0, "val_loss": 33.75498950481415, "val_acc": 48.0}
{"epoch": 37, "training_loss": 159.1686635017395, "training_acc": 59.0, "val_loss": 45.0009822845459, "val_acc": 56.0}
{"epoch": 38, "training_loss": 146.03450107574463, "training_acc": 63.0, "val_loss": 22.46284782886505, "val_acc": 44.0}
{"epoch": 39, "training_loss": 268.3322696685791, "training_acc": 57.0, "val_loss": 86.34922504425049, "val_acc": 52.0}
{"epoch": 40, "training_loss": 490.54864501953125, "training_acc": 45.0, "val_loss": 165.60113430023193, "val_acc": 48.0}
{"epoch": 41, "training_loss": 565.9622020721436, "training_acc": 42.0, "val_loss": 89.95421528816223, "val_acc": 52.0}
{"epoch": 42, "training_loss": 291.83824253082275, "training_acc": 50.0, "val_loss": 27.27625072002411, "val_acc": 52.0}
{"epoch": 43, "training_loss": 170.57186889648438, "training_acc": 65.0, "val_loss": 124.97646808624268, "val_acc": 52.0}
{"epoch": 44, "training_loss": 396.8730344772339, "training_acc": 47.0, "val_loss": 26.700714230537415, "val_acc": 56.0}
{"epoch": 45, "training_loss": 208.47026252746582, "training_acc": 60.0, "val_loss": 140.9032106399536, "val_acc": 52.0}
{"epoch": 46, "training_loss": 354.2397675514221, "training_acc": 52.0, "val_loss": 29.962259531021118, "val_acc": 52.0}
{"epoch": 47, "training_loss": 210.47757625579834, "training_acc": 55.0, "val_loss": 92.35265851020813, "val_acc": 52.0}
{"epoch": 48, "training_loss": 389.19054222106934, "training_acc": 49.0, "val_loss": 93.23276281356812, "val_acc": 48.0}
{"epoch": 49, "training_loss": 393.8941659927368, "training_acc": 49.0, "val_loss": 151.61172151565552, "val_acc": 52.0}
{"epoch": 50, "training_loss": 379.8499450683594, "training_acc": 52.0, "val_loss": 42.222681641578674, "val_acc": 48.0}
{"epoch": 51, "training_loss": 125.46382999420166, "training_acc": 62.0, "val_loss": 68.16480159759521, "val_acc": 52.0}
{"epoch": 52, "training_loss": 276.9976215362549, "training_acc": 53.0, "val_loss": 45.798128843307495, "val_acc": 48.0}
{"epoch": 53, "training_loss": 243.94510078430176, "training_acc": 56.0, "val_loss": 180.58239221572876, "val_acc": 52.0}
{"epoch": 54, "training_loss": 404.4096257686615, "training_acc": 59.0, "val_loss": 199.91332292556763, "val_acc": 48.0}
{"epoch": 55, "training_loss": 727.6810970306396, "training_acc": 47.0, "val_loss": 27.97810435295105, "val_acc": 64.0}
{"epoch": 56, "training_loss": 199.34480476379395, "training_acc": 71.0, "val_loss": 97.09162712097168, "val_acc": 52.0}
{"epoch": 57, "training_loss": 350.88677406311035, "training_acc": 54.0, "val_loss": 114.0992283821106, "val_acc": 48.0}
