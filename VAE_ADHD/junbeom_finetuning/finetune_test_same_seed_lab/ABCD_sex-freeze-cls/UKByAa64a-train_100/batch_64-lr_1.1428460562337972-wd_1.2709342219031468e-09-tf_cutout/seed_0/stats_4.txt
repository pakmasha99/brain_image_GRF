"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2649.2619247436523, "training_acc": 53.0, "val_loss": 418.5194492340088, "val_acc": 52.0}
{"epoch": 1, "training_loss": 2776.487747192383, "training_acc": 47.0, "val_loss": 1358.046817779541, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5131.740707397461, "training_acc": 47.0, "val_loss": 472.3911762237549, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1724.6701049804688, "training_acc": 49.0, "val_loss": 724.799919128418, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2796.281204223633, "training_acc": 53.0, "val_loss": 564.4608020782471, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1576.6642379760742, "training_acc": 53.0, "val_loss": 397.99644947052, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1976.1365814208984, "training_acc": 47.0, "val_loss": 647.385835647583, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2191.46728515625, "training_acc": 47.0, "val_loss": 65.6148374080658, "val_acc": 52.0}
{"epoch": 8, "training_loss": 541.1177673339844, "training_acc": 53.0, "val_loss": 306.16655349731445, "val_acc": 52.0}
{"epoch": 9, "training_loss": 964.3904151916504, "training_acc": 53.0, "val_loss": 214.8667335510254, "val_acc": 48.0}
{"epoch": 10, "training_loss": 902.6892433166504, "training_acc": 47.0, "val_loss": 189.01269435882568, "val_acc": 48.0}
{"epoch": 11, "training_loss": 578.0219745635986, "training_acc": 52.0, "val_loss": 184.46383476257324, "val_acc": 52.0}
{"epoch": 12, "training_loss": 578.5586919784546, "training_acc": 53.0, "val_loss": 180.70693016052246, "val_acc": 48.0}
{"epoch": 13, "training_loss": 630.7839031219482, "training_acc": 48.0, "val_loss": 50.67346692085266, "val_acc": 44.0}
{"epoch": 14, "training_loss": 431.00870513916016, "training_acc": 51.0, "val_loss": 229.8625946044922, "val_acc": 52.0}
{"epoch": 15, "training_loss": 694.6227626800537, "training_acc": 55.0, "val_loss": 203.8020372390747, "val_acc": 48.0}
{"epoch": 16, "training_loss": 791.8062629699707, "training_acc": 49.0, "val_loss": 170.88489532470703, "val_acc": 48.0}
{"epoch": 17, "training_loss": 568.5116233825684, "training_acc": 52.0, "val_loss": 214.03350830078125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 721.848970413208, "training_acc": 54.0, "val_loss": 108.02265405654907, "val_acc": 44.0}
{"epoch": 19, "training_loss": 472.1650104522705, "training_acc": 50.0, "val_loss": 96.70302867889404, "val_acc": 48.0}
{"epoch": 20, "training_loss": 515.6702671051025, "training_acc": 45.0, "val_loss": 198.25176000595093, "val_acc": 52.0}
{"epoch": 21, "training_loss": 614.4591369628906, "training_acc": 53.0, "val_loss": 183.36719274520874, "val_acc": 48.0}
{"epoch": 22, "training_loss": 678.2152671813965, "training_acc": 49.0, "val_loss": 74.67003464698792, "val_acc": 44.0}
{"epoch": 23, "training_loss": 462.4380073547363, "training_acc": 51.0, "val_loss": 276.8718719482422, "val_acc": 52.0}
{"epoch": 24, "training_loss": 950.9521560668945, "training_acc": 53.0, "val_loss": 79.21279668807983, "val_acc": 48.0}
{"epoch": 25, "training_loss": 323.19336318969727, "training_acc": 53.0, "val_loss": 42.545631527900696, "val_acc": 56.0}
{"epoch": 26, "training_loss": 211.02956008911133, "training_acc": 60.0, "val_loss": 62.84797787666321, "val_acc": 52.0}
{"epoch": 27, "training_loss": 217.47402954101562, "training_acc": 56.0, "val_loss": 86.17017269134521, "val_acc": 44.0}
{"epoch": 28, "training_loss": 345.98023414611816, "training_acc": 43.0, "val_loss": 70.50160765647888, "val_acc": 52.0}
{"epoch": 29, "training_loss": 257.801700592041, "training_acc": 55.0, "val_loss": 62.126755714416504, "val_acc": 44.0}
{"epoch": 30, "training_loss": 289.65617656707764, "training_acc": 55.0, "val_loss": 74.23235774040222, "val_acc": 52.0}
{"epoch": 31, "training_loss": 181.43907690048218, "training_acc": 69.0, "val_loss": 82.4899435043335, "val_acc": 48.0}
{"epoch": 32, "training_loss": 232.59987354278564, "training_acc": 49.0, "val_loss": 59.97815728187561, "val_acc": 52.0}
{"epoch": 33, "training_loss": 206.2379035949707, "training_acc": 57.0, "val_loss": 51.91863775253296, "val_acc": 44.0}
{"epoch": 34, "training_loss": 265.87785243988037, "training_acc": 50.0, "val_loss": 71.5634822845459, "val_acc": 52.0}
{"epoch": 35, "training_loss": 387.0224895477295, "training_acc": 46.0, "val_loss": 60.26330590248108, "val_acc": 44.0}
{"epoch": 36, "training_loss": 235.64869689941406, "training_acc": 62.0, "val_loss": 128.22222709655762, "val_acc": 52.0}
{"epoch": 37, "training_loss": 281.20185804367065, "training_acc": 57.0, "val_loss": 75.818932056427, "val_acc": 48.0}
{"epoch": 38, "training_loss": 266.33931827545166, "training_acc": 52.0, "val_loss": 69.03138756752014, "val_acc": 52.0}
{"epoch": 39, "training_loss": 170.43864679336548, "training_acc": 61.0, "val_loss": 22.125983238220215, "val_acc": 56.0}
{"epoch": 40, "training_loss": 187.21247577667236, "training_acc": 62.0, "val_loss": 38.476747274398804, "val_acc": 48.0}
{"epoch": 41, "training_loss": 213.29555082321167, "training_acc": 45.0, "val_loss": 45.80265283584595, "val_acc": 44.0}
{"epoch": 42, "training_loss": 170.3206639289856, "training_acc": 57.0, "val_loss": 29.483357071876526, "val_acc": 60.0}
{"epoch": 43, "training_loss": 208.83882522583008, "training_acc": 51.0, "val_loss": 72.85974621772766, "val_acc": 52.0}
{"epoch": 44, "training_loss": 217.6251621246338, "training_acc": 56.0, "val_loss": 91.34310483932495, "val_acc": 48.0}
{"epoch": 45, "training_loss": 299.4366292953491, "training_acc": 51.0, "val_loss": 133.08197259902954, "val_acc": 52.0}
{"epoch": 46, "training_loss": 486.3491897583008, "training_acc": 53.0, "val_loss": 23.746608197689056, "val_acc": 56.0}
{"epoch": 47, "training_loss": 267.7273292541504, "training_acc": 58.0, "val_loss": 52.60275602340698, "val_acc": 44.0}
{"epoch": 48, "training_loss": 291.1070957183838, "training_acc": 58.0, "val_loss": 179.34428453445435, "val_acc": 52.0}
{"epoch": 49, "training_loss": 453.0940508842468, "training_acc": 54.0, "val_loss": 180.10008335113525, "val_acc": 48.0}
{"epoch": 50, "training_loss": 633.2240009307861, "training_acc": 47.0, "val_loss": 60.02073287963867, "val_acc": 52.0}
{"epoch": 51, "training_loss": 232.5703639984131, "training_acc": 56.0, "val_loss": 46.82020545005798, "val_acc": 48.0}
{"epoch": 52, "training_loss": 157.88417673110962, "training_acc": 55.0, "val_loss": 139.82946872711182, "val_acc": 52.0}
{"epoch": 53, "training_loss": 418.22889518737793, "training_acc": 53.0, "val_loss": 62.347644567489624, "val_acc": 48.0}
{"epoch": 54, "training_loss": 223.678946018219, "training_acc": 49.0, "val_loss": 113.02100419998169, "val_acc": 52.0}
{"epoch": 55, "training_loss": 360.7985534667969, "training_acc": 54.0, "val_loss": 82.82774686813354, "val_acc": 48.0}
{"epoch": 56, "training_loss": 313.61473274230957, "training_acc": 48.0, "val_loss": 108.52059125900269, "val_acc": 52.0}
{"epoch": 57, "training_loss": 298.40797424316406, "training_acc": 54.0, "val_loss": 32.967132329940796, "val_acc": 52.0}
{"epoch": 58, "training_loss": 170.395263671875, "training_acc": 57.0, "val_loss": 83.90377759933472, "val_acc": 52.0}
