"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 604111.5087509155, "training_acc": 53.0, "val_loss": 118793.408203125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 606805.84375, "training_acc": 41.0, "val_loss": 196513.68408203125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 716734.501953125, "training_acc": 47.0, "val_loss": 40989.10827636719, "val_acc": 48.0}
{"epoch": 3, "training_loss": 307076.666015625, "training_acc": 41.0, "val_loss": 172316.1865234375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 660539.853515625, "training_acc": 53.0, "val_loss": 141237.060546875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 437841.91015625, "training_acc": 53.0, "val_loss": 31324.0478515625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 203246.0205078125, "training_acc": 47.0, "val_loss": 74617.41943359375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 241883.29663085938, "training_acc": 47.0, "val_loss": 54158.966064453125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 244527.1640625, "training_acc": 53.0, "val_loss": 80943.34106445312, "val_acc": 52.0}
{"epoch": 9, "training_loss": 254173.97802734375, "training_acc": 53.0, "val_loss": 26491.738891601562, "val_acc": 48.0}
{"epoch": 10, "training_loss": 134796.56494140625, "training_acc": 47.0, "val_loss": 30810.0341796875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 90588.51416015625, "training_acc": 54.0, "val_loss": 33138.99841308594, "val_acc": 52.0}
{"epoch": 12, "training_loss": 101297.078125, "training_acc": 51.0, "val_loss": 33596.71936035156, "val_acc": 48.0}
{"epoch": 13, "training_loss": 133554.46337890625, "training_acc": 47.0, "val_loss": 4621.299743652344, "val_acc": 52.0}
{"epoch": 14, "training_loss": 65817.10888671875, "training_acc": 59.0, "val_loss": 29230.795288085938, "val_acc": 52.0}
{"epoch": 15, "training_loss": 76308.36120605469, "training_acc": 53.0, "val_loss": 14125.886535644531, "val_acc": 44.0}
{"epoch": 16, "training_loss": 53546.555908203125, "training_acc": 49.0, "val_loss": 6970.262908935547, "val_acc": 60.0}
{"epoch": 17, "training_loss": 41009.16943359375, "training_acc": 48.0, "val_loss": 8538.257598876953, "val_acc": 60.0}
{"epoch": 18, "training_loss": 22088.85089111328, "training_acc": 60.0, "val_loss": 12577.143096923828, "val_acc": 48.0}
{"epoch": 19, "training_loss": 44458.49200439453, "training_acc": 54.0, "val_loss": 29455.984497070312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 84711.4423828125, "training_acc": 53.0, "val_loss": 7641.764831542969, "val_acc": 48.0}
{"epoch": 21, "training_loss": 33025.00720214844, "training_acc": 54.0, "val_loss": 23035.77880859375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 49255.9765625, "training_acc": 55.0, "val_loss": 33746.246337890625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 149817.4619140625, "training_acc": 47.0, "val_loss": 3320.3914642333984, "val_acc": 48.0}
{"epoch": 24, "training_loss": 79157.94921875, "training_acc": 54.0, "val_loss": 61743.621826171875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 193540.61572265625, "training_acc": 53.0, "val_loss": 14890.631103515625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 71169.28930664062, "training_acc": 48.0, "val_loss": 5148.185348510742, "val_acc": 44.0}
{"epoch": 27, "training_loss": 42151.075927734375, "training_acc": 62.0, "val_loss": 5600.328826904297, "val_acc": 44.0}
{"epoch": 28, "training_loss": 51093.26416015625, "training_acc": 53.0, "val_loss": 6458.174896240234, "val_acc": 56.0}
{"epoch": 29, "training_loss": 67815.18603515625, "training_acc": 53.0, "val_loss": 40855.517578125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 99974.46264648438, "training_acc": 55.0, "val_loss": 44196.392822265625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 199781.8017578125, "training_acc": 47.0, "val_loss": 21332.972717285156, "val_acc": 48.0}
{"epoch": 32, "training_loss": 118301.818359375, "training_acc": 49.0, "val_loss": 69762.17041015625, "val_acc": 52.0}
{"epoch": 33, "training_loss": 221576.611328125, "training_acc": 53.0, "val_loss": 19772.06268310547, "val_acc": 52.0}
{"epoch": 34, "training_loss": 103952.30322265625, "training_acc": 53.0, "val_loss": 68918.07861328125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 274149.810546875, "training_acc": 47.0, "val_loss": 3273.715591430664, "val_acc": 60.0}
{"epoch": 36, "training_loss": 89504.1123046875, "training_acc": 64.0, "val_loss": 81789.6484375, "val_acc": 52.0}
{"epoch": 37, "training_loss": 273374.826171875, "training_acc": 53.0, "val_loss": 23672.05352783203, "val_acc": 52.0}
{"epoch": 38, "training_loss": 104042.23681640625, "training_acc": 55.0, "val_loss": 87135.1318359375, "val_acc": 48.0}
{"epoch": 39, "training_loss": 320689.6142578125, "training_acc": 47.0, "val_loss": 32388.800048828125, "val_acc": 48.0}
{"epoch": 40, "training_loss": 121543.68603515625, "training_acc": 54.0, "val_loss": 74466.36352539062, "val_acc": 52.0}
{"epoch": 41, "training_loss": 264161.39453125, "training_acc": 53.0, "val_loss": 37590.39001464844, "val_acc": 52.0}
{"epoch": 42, "training_loss": 133735.4072265625, "training_acc": 51.0, "val_loss": 63196.30126953125, "val_acc": 48.0}
{"epoch": 43, "training_loss": 213895.9208984375, "training_acc": 46.0, "val_loss": 13681.170654296875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 130485.1064453125, "training_acc": 49.0, "val_loss": 70436.38916015625, "val_acc": 52.0}
{"epoch": 45, "training_loss": 233472.080078125, "training_acc": 53.0, "val_loss": 9090.892028808594, "val_acc": 48.0}
{"epoch": 46, "training_loss": 78619.7138671875, "training_acc": 62.0, "val_loss": 55412.548828125, "val_acc": 48.0}
{"epoch": 47, "training_loss": 174190.95263671875, "training_acc": 47.0, "val_loss": 36981.2255859375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 136055.39794921875, "training_acc": 53.0, "val_loss": 43585.7421875, "val_acc": 52.0}
{"epoch": 49, "training_loss": 96668.59002685547, "training_acc": 59.0, "val_loss": 25097.586059570312, "val_acc": 48.0}
{"epoch": 50, "training_loss": 99310.24340820312, "training_acc": 48.0, "val_loss": 33678.40270996094, "val_acc": 52.0}
{"epoch": 51, "training_loss": 105145.6181640625, "training_acc": 54.0, "val_loss": 19417.86651611328, "val_acc": 52.0}
{"epoch": 52, "training_loss": 57342.710693359375, "training_acc": 62.0, "val_loss": 29470.458984375, "val_acc": 48.0}
{"epoch": 53, "training_loss": 118621.82238769531, "training_acc": 52.0, "val_loss": 45206.292724609375, "val_acc": 52.0}
{"epoch": 54, "training_loss": 141379.43017578125, "training_acc": 55.0, "val_loss": 34373.553466796875, "val_acc": 52.0}
