"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 524680.004234314, "training_acc": 53.0, "val_loss": 108137.09716796875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 523014.6015625, "training_acc": 49.0, "val_loss": 222338.5009765625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 820785.46875, "training_acc": 47.0, "val_loss": 48644.9951171875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 279264.1865234375, "training_acc": 49.0, "val_loss": 182736.9140625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 692108.953125, "training_acc": 53.0, "val_loss": 149717.7734375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 434425.67578125, "training_acc": 53.0, "val_loss": 50643.09997558594, "val_acc": 48.0}
{"epoch": 6, "training_loss": 281745.4697265625, "training_acc": 47.0, "val_loss": 104240.95458984375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 350358.4970703125, "training_acc": 47.0, "val_loss": 24786.328125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 121604.865234375, "training_acc": 53.0, "val_loss": 59389.093017578125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 169085.65673828125, "training_acc": 53.0, "val_loss": 45759.24072265625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 207153.734375, "training_acc": 47.0, "val_loss": 44873.50769042969, "val_acc": 48.0}
{"epoch": 11, "training_loss": 135314.13647460938, "training_acc": 45.0, "val_loss": 25088.255310058594, "val_acc": 52.0}
{"epoch": 12, "training_loss": 86736.34228515625, "training_acc": 55.0, "val_loss": 27740.457153320312, "val_acc": 48.0}
{"epoch": 13, "training_loss": 102119.3408203125, "training_acc": 47.0, "val_loss": 29589.480590820312, "val_acc": 52.0}
{"epoch": 14, "training_loss": 118763.2333984375, "training_acc": 53.0, "val_loss": 18055.24139404297, "val_acc": 52.0}
{"epoch": 15, "training_loss": 99791.59814453125, "training_acc": 46.0, "val_loss": 47733.544921875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 159241.53149414062, "training_acc": 48.0, "val_loss": 45869.183349609375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 186972.9892578125, "training_acc": 53.0, "val_loss": 53692.254638671875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 113472.70858764648, "training_acc": 60.0, "val_loss": 39072.93395996094, "val_acc": 48.0}
{"epoch": 19, "training_loss": 164822.9384765625, "training_acc": 47.0, "val_loss": 6940.367126464844, "val_acc": 48.0}
{"epoch": 20, "training_loss": 65985.84912109375, "training_acc": 60.0, "val_loss": 43584.722900390625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 97292.98114013672, "training_acc": 58.0, "val_loss": 26221.142578125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 106827.150390625, "training_acc": 47.0, "val_loss": 22491.110229492188, "val_acc": 52.0}
{"epoch": 23, "training_loss": 60277.00732421875, "training_acc": 53.0, "val_loss": 5313.951110839844, "val_acc": 40.0}
{"epoch": 24, "training_loss": 19709.89111328125, "training_acc": 57.0, "val_loss": 19473.765563964844, "val_acc": 52.0}
{"epoch": 25, "training_loss": 41583.26721191406, "training_acc": 58.0, "val_loss": 18845.823669433594, "val_acc": 48.0}
{"epoch": 26, "training_loss": 70560.66516113281, "training_acc": 50.0, "val_loss": 32908.18786621094, "val_acc": 52.0}
{"epoch": 27, "training_loss": 86972.94604492188, "training_acc": 53.0, "val_loss": 6419.527435302734, "val_acc": 44.0}
{"epoch": 28, "training_loss": 32366.028564453125, "training_acc": 62.0, "val_loss": 17336.827087402344, "val_acc": 52.0}
{"epoch": 29, "training_loss": 30599.514892578125, "training_acc": 60.0, "val_loss": 10860.2294921875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 44509.0654296875, "training_acc": 50.0, "val_loss": 41928.955078125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 128506.8359375, "training_acc": 53.0, "val_loss": 23794.764709472656, "val_acc": 52.0}
{"epoch": 32, "training_loss": 108200.21533203125, "training_acc": 47.0, "val_loss": 48823.86474609375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 168611.5546875, "training_acc": 47.0, "val_loss": 43076.26953125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 175182.8720703125, "training_acc": 53.0, "val_loss": 54439.849853515625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 120528.78674316406, "training_acc": 51.0, "val_loss": 30583.709716796875, "val_acc": 48.0}
{"epoch": 36, "training_loss": 132051.79833984375, "training_acc": 47.0, "val_loss": 20179.144287109375, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70297.27001953125, "training_acc": 54.0, "val_loss": 4801.355361938477, "val_acc": 56.0}
{"epoch": 38, "training_loss": 29647.9140625, "training_acc": 62.0, "val_loss": 3238.2461547851562, "val_acc": 64.0}
{"epoch": 39, "training_loss": 42743.978515625, "training_acc": 62.0, "val_loss": 24150.881958007812, "val_acc": 52.0}
{"epoch": 40, "training_loss": 61776.26916503906, "training_acc": 53.0, "val_loss": 10875.599670410156, "val_acc": 48.0}
{"epoch": 41, "training_loss": 39520.094970703125, "training_acc": 60.0, "val_loss": 24156.92596435547, "val_acc": 52.0}
{"epoch": 42, "training_loss": 41321.781311035156, "training_acc": 64.0, "val_loss": 25837.811279296875, "val_acc": 48.0}
{"epoch": 43, "training_loss": 88101.81591796875, "training_acc": 47.0, "val_loss": 36170.43762207031, "val_acc": 52.0}
{"epoch": 44, "training_loss": 129995.53955078125, "training_acc": 53.0, "val_loss": 28995.10498046875, "val_acc": 52.0}
{"epoch": 45, "training_loss": 102408.4296875, "training_acc": 49.0, "val_loss": 40204.156494140625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 129648.60180664062, "training_acc": 49.0, "val_loss": 47774.530029296875, "val_acc": 52.0}
{"epoch": 47, "training_loss": 162996.1376953125, "training_acc": 53.0, "val_loss": 50721.84753417969, "val_acc": 52.0}
{"epoch": 48, "training_loss": 112959.79931640625, "training_acc": 52.0, "val_loss": 27207.50732421875, "val_acc": 48.0}
{"epoch": 49, "training_loss": 103400.7080078125, "training_acc": 48.0, "val_loss": 34331.085205078125, "val_acc": 52.0}
{"epoch": 50, "training_loss": 89723.5732421875, "training_acc": 54.0, "val_loss": 18072.62420654297, "val_acc": 52.0}
{"epoch": 51, "training_loss": 51080.4345703125, "training_acc": 59.0, "val_loss": 9615.779876708984, "val_acc": 52.0}
{"epoch": 52, "training_loss": 67771.939453125, "training_acc": 56.0, "val_loss": 40975.909423828125, "val_acc": 52.0}
{"epoch": 53, "training_loss": 61412.40979003906, "training_acc": 57.0, "val_loss": 33373.98681640625, "val_acc": 48.0}
{"epoch": 54, "training_loss": 173574.03515625, "training_acc": 47.0, "val_loss": 12656.15234375, "val_acc": 52.0}
{"epoch": 55, "training_loss": 102325.171875, "training_acc": 48.0, "val_loss": 75291.15600585938, "val_acc": 52.0}
{"epoch": 56, "training_loss": 212403.6474609375, "training_acc": 53.0, "val_loss": 16764.657592773438, "val_acc": 52.0}
{"epoch": 57, "training_loss": 94114.32421875, "training_acc": 58.0, "val_loss": 64538.677978515625, "val_acc": 48.0}
