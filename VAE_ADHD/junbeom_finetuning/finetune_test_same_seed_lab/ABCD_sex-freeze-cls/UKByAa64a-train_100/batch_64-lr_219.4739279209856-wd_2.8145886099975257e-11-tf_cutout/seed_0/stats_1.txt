"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 460995.07707595825, "training_acc": 46.0, "val_loss": 96350.37231445312, "val_acc": 52.0}
{"epoch": 1, "training_loss": 467864.494140625, "training_acc": 53.0, "val_loss": 249523.876953125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 939085.33203125, "training_acc": 47.0, "val_loss": 69167.68798828125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 327227.412109375, "training_acc": 51.0, "val_loss": 182230.48095703125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 692345.587890625, "training_acc": 53.0, "val_loss": 162609.814453125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 482613.6103515625, "training_acc": 53.0, "val_loss": 28253.195190429688, "val_acc": 48.0}
{"epoch": 6, "training_loss": 260406.642578125, "training_acc": 47.0, "val_loss": 83287.51220703125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 282311.09033203125, "training_acc": 47.0, "val_loss": 60350.042724609375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 235320.5888671875, "training_acc": 53.0, "val_loss": 104644.1650390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 339795.1220703125, "training_acc": 53.0, "val_loss": 13186.698913574219, "val_acc": 52.0}
{"epoch": 10, "training_loss": 135901.8515625, "training_acc": 49.0, "val_loss": 97297.24731445312, "val_acc": 48.0}
{"epoch": 11, "training_loss": 372794.4404296875, "training_acc": 47.0, "val_loss": 20639.2333984375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 135071.4462890625, "training_acc": 49.0, "val_loss": 102383.65478515625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 393635.51953125, "training_acc": 53.0, "val_loss": 76753.38745117188, "val_acc": 52.0}
{"epoch": 14, "training_loss": 206046.16857910156, "training_acc": 52.0, "val_loss": 75267.55981445312, "val_acc": 48.0}
{"epoch": 15, "training_loss": 366702.37890625, "training_acc": 47.0, "val_loss": 111947.93701171875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 377695.2255859375, "training_acc": 47.0, "val_loss": 10196.10824584961, "val_acc": 60.0}
{"epoch": 17, "training_loss": 94041.15869140625, "training_acc": 54.0, "val_loss": 64011.95068359375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 205803.32836914062, "training_acc": 53.0, "val_loss": 13739.230346679688, "val_acc": 48.0}
{"epoch": 19, "training_loss": 62191.997802734375, "training_acc": 51.0, "val_loss": 6474.382019042969, "val_acc": 56.0}
{"epoch": 20, "training_loss": 50510.345703125, "training_acc": 58.0, "val_loss": 16015.458679199219, "val_acc": 56.0}
{"epoch": 21, "training_loss": 53251.8330078125, "training_acc": 52.0, "val_loss": 23520.30792236328, "val_acc": 48.0}
{"epoch": 22, "training_loss": 70756.43505859375, "training_acc": 52.0, "val_loss": 29778.924560546875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 63716.57604980469, "training_acc": 57.0, "val_loss": 23114.556884765625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 89542.35083007812, "training_acc": 48.0, "val_loss": 20522.967529296875, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70356.26245117188, "training_acc": 56.0, "val_loss": 9887.41226196289, "val_acc": 56.0}
{"epoch": 26, "training_loss": 78912.71630859375, "training_acc": 52.0, "val_loss": 25896.408081054688, "val_acc": 48.0}
{"epoch": 27, "training_loss": 89736.51745605469, "training_acc": 50.0, "val_loss": 26630.6884765625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 55999.91143798828, "training_acc": 55.0, "val_loss": 29915.408325195312, "val_acc": 48.0}
{"epoch": 29, "training_loss": 115127.587890625, "training_acc": 49.0, "val_loss": 23175.196838378906, "val_acc": 56.0}
{"epoch": 30, "training_loss": 83905.23974609375, "training_acc": 54.0, "val_loss": 15268.995666503906, "val_acc": 56.0}
{"epoch": 31, "training_loss": 71276.20166015625, "training_acc": 52.0, "val_loss": 25247.77069091797, "val_acc": 48.0}
{"epoch": 32, "training_loss": 88123.92602539062, "training_acc": 47.0, "val_loss": 20412.213134765625, "val_acc": 56.0}
{"epoch": 33, "training_loss": 44989.31579589844, "training_acc": 60.0, "val_loss": 13631.312561035156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 73599.71362304688, "training_acc": 43.0, "val_loss": 10643.476104736328, "val_acc": 56.0}
{"epoch": 35, "training_loss": 49874.68359375, "training_acc": 53.0, "val_loss": 6616.304016113281, "val_acc": 44.0}
{"epoch": 36, "training_loss": 58839.304931640625, "training_acc": 58.0, "val_loss": 33579.20227050781, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64248.388916015625, "training_acc": 56.0, "val_loss": 11262.953186035156, "val_acc": 44.0}
{"epoch": 38, "training_loss": 48670.26208496094, "training_acc": 53.0, "val_loss": 21785.44158935547, "val_acc": 52.0}
