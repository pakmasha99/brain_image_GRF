"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 251.21680641174316, "training_acc": 54.0, "val_loss": 1572.747802734375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 5712.382568359375, "training_acc": 47.0, "val_loss": 192.90317296981812, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1905.392318725586, "training_acc": 48.0, "val_loss": 1481.256103515625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 5652.139953613281, "training_acc": 53.0, "val_loss": 890.740966796875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2483.7428646087646, "training_acc": 53.0, "val_loss": 893.6986923217773, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3920.204315185547, "training_acc": 47.0, "val_loss": 1412.5874519348145, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4978.895004272461, "training_acc": 47.0, "val_loss": 515.33203125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1643.0328521728516, "training_acc": 55.0, "val_loss": 775.0558853149414, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3452.8438415527344, "training_acc": 53.0, "val_loss": 837.0390892028809, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2535.960060119629, "training_acc": 53.0, "val_loss": 102.48359441757202, "val_acc": 52.0}
{"epoch": 10, "training_loss": 932.2803497314453, "training_acc": 51.0, "val_loss": 421.87347412109375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1390.9487571716309, "training_acc": 49.0, "val_loss": 282.6305389404297, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1318.930320739746, "training_acc": 52.0, "val_loss": 526.1294841766357, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1758.6327934265137, "training_acc": 53.0, "val_loss": 103.29346656799316, "val_acc": 52.0}
{"epoch": 14, "training_loss": 803.4802551269531, "training_acc": 52.0, "val_loss": 179.78668212890625, "val_acc": 44.0}
{"epoch": 15, "training_loss": 611.8197374343872, "training_acc": 57.0, "val_loss": 317.5314664840698, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1110.4344367980957, "training_acc": 53.0, "val_loss": 70.11351585388184, "val_acc": 68.0}
{"epoch": 17, "training_loss": 483.70249366760254, "training_acc": 51.0, "val_loss": 126.52775049209595, "val_acc": 52.0}
{"epoch": 18, "training_loss": 535.0417528152466, "training_acc": 51.0, "val_loss": 274.31178092956543, "val_acc": 52.0}
{"epoch": 19, "training_loss": 905.4657592773438, "training_acc": 53.0, "val_loss": 52.60462760925293, "val_acc": 64.0}
{"epoch": 20, "training_loss": 599.8314399719238, "training_acc": 54.0, "val_loss": 120.93347311019897, "val_acc": 52.0}
{"epoch": 21, "training_loss": 721.5688667297363, "training_acc": 51.0, "val_loss": 275.5960941314697, "val_acc": 52.0}
{"epoch": 22, "training_loss": 713.2412157058716, "training_acc": 56.0, "val_loss": 51.5163779258728, "val_acc": 64.0}
{"epoch": 23, "training_loss": 385.44763565063477, "training_acc": 52.0, "val_loss": 61.49696111679077, "val_acc": 68.0}
{"epoch": 24, "training_loss": 236.37277698516846, "training_acc": 63.0, "val_loss": 42.094406485557556, "val_acc": 68.0}
{"epoch": 25, "training_loss": 271.65077209472656, "training_acc": 63.0, "val_loss": 63.63086700439453, "val_acc": 64.0}
{"epoch": 26, "training_loss": 219.66724348068237, "training_acc": 55.0, "val_loss": 32.01249539852142, "val_acc": 56.0}
{"epoch": 27, "training_loss": 209.21832275390625, "training_acc": 59.0, "val_loss": 53.90489101409912, "val_acc": 64.0}
{"epoch": 28, "training_loss": 121.34041261672974, "training_acc": 66.0, "val_loss": 31.79306983947754, "val_acc": 68.0}
{"epoch": 29, "training_loss": 201.2834939956665, "training_acc": 54.0, "val_loss": 35.04425585269928, "val_acc": 56.0}
{"epoch": 30, "training_loss": 142.84005784988403, "training_acc": 70.0, "val_loss": 93.99964809417725, "val_acc": 52.0}
{"epoch": 31, "training_loss": 212.98433113098145, "training_acc": 57.0, "val_loss": 46.19246423244476, "val_acc": 60.0}
{"epoch": 32, "training_loss": 77.66851782798767, "training_acc": 66.0, "val_loss": 33.42397212982178, "val_acc": 64.0}
{"epoch": 33, "training_loss": 73.15793919563293, "training_acc": 77.0, "val_loss": 56.00736141204834, "val_acc": 56.0}
{"epoch": 34, "training_loss": 218.85180377960205, "training_acc": 55.0, "val_loss": 98.89549016952515, "val_acc": 52.0}
{"epoch": 35, "training_loss": 171.58758020401, "training_acc": 60.0, "val_loss": 52.4858295917511, "val_acc": 48.0}
{"epoch": 36, "training_loss": 174.62774276733398, "training_acc": 61.0, "val_loss": 43.651050329208374, "val_acc": 52.0}
{"epoch": 37, "training_loss": 228.96965217590332, "training_acc": 60.0, "val_loss": 52.241677045822144, "val_acc": 56.0}
{"epoch": 38, "training_loss": 121.31218719482422, "training_acc": 63.0, "val_loss": 122.37025499343872, "val_acc": 44.0}
{"epoch": 39, "training_loss": 353.61044001579285, "training_acc": 56.0, "val_loss": 94.71006393432617, "val_acc": 52.0}
{"epoch": 40, "training_loss": 374.16866874694824, "training_acc": 46.0, "val_loss": 47.68897891044617, "val_acc": 56.0}
{"epoch": 41, "training_loss": 103.72098660469055, "training_acc": 62.0, "val_loss": 65.9612774848938, "val_acc": 52.0}
{"epoch": 42, "training_loss": 178.5771837234497, "training_acc": 59.0, "val_loss": 36.420488357543945, "val_acc": 56.0}
{"epoch": 43, "training_loss": 90.82580375671387, "training_acc": 76.0, "val_loss": 145.81533670425415, "val_acc": 48.0}
{"epoch": 44, "training_loss": 333.910671710968, "training_acc": 54.0, "val_loss": 271.6116666793823, "val_acc": 52.0}
{"epoch": 45, "training_loss": 959.5514793395996, "training_acc": 53.0, "val_loss": 37.60716915130615, "val_acc": 52.0}
{"epoch": 46, "training_loss": 474.79366302490234, "training_acc": 65.0, "val_loss": 304.0130615234375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 860.9060530662537, "training_acc": 48.0, "val_loss": 108.16720724105835, "val_acc": 52.0}
