"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3825.89510345459, "training_acc": 41.0, "val_loss": 689.2434120178223, "val_acc": 48.0}
{"epoch": 1, "training_loss": 3185.4363555908203, "training_acc": 47.0, "val_loss": 1492.708683013916, "val_acc": 52.0}
{"epoch": 2, "training_loss": 5797.702941894531, "training_acc": 53.0, "val_loss": 1030.9184074401855, "val_acc": 52.0}
{"epoch": 3, "training_loss": 2890.219825744629, "training_acc": 53.0, "val_loss": 647.3907470703125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3049.6597595214844, "training_acc": 47.0, "val_loss": 1169.7236061096191, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4154.702209472656, "training_acc": 47.0, "val_loss": 359.3761444091797, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1232.9052352905273, "training_acc": 54.0, "val_loss": 761.1059188842773, "val_acc": 52.0}
{"epoch": 7, "training_loss": 3129.885009765625, "training_acc": 53.0, "val_loss": 758.6038112640381, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2431.690055847168, "training_acc": 53.0, "val_loss": 94.01240944862366, "val_acc": 48.0}
{"epoch": 9, "training_loss": 876.203239440918, "training_acc": 49.0, "val_loss": 341.0895109176636, "val_acc": 48.0}
{"epoch": 10, "training_loss": 966.9979381561279, "training_acc": 49.0, "val_loss": 393.5229778289795, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1813.5778884887695, "training_acc": 53.0, "val_loss": 610.8605861663818, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1892.529899597168, "training_acc": 53.0, "val_loss": 33.33122134208679, "val_acc": 68.0}
{"epoch": 13, "training_loss": 638.8922271728516, "training_acc": 51.0, "val_loss": 335.68055629730225, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1162.8882331848145, "training_acc": 47.0, "val_loss": 233.1960916519165, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1032.475456237793, "training_acc": 53.0, "val_loss": 399.3384838104248, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1181.2320308685303, "training_acc": 53.0, "val_loss": 161.1253023147583, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1014.4321212768555, "training_acc": 47.0, "val_loss": 141.60888195037842, "val_acc": 44.0}
{"epoch": 18, "training_loss": 539.8345651626587, "training_acc": 57.0, "val_loss": 302.79855728149414, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1038.6402130126953, "training_acc": 53.0, "val_loss": 37.03055381774902, "val_acc": 64.0}
{"epoch": 20, "training_loss": 349.52660179138184, "training_acc": 55.0, "val_loss": 165.3225064277649, "val_acc": 48.0}
{"epoch": 21, "training_loss": 488.8734745979309, "training_acc": 51.0, "val_loss": 224.71864223480225, "val_acc": 52.0}
{"epoch": 22, "training_loss": 844.1496505737305, "training_acc": 53.0, "val_loss": 49.61433708667755, "val_acc": 56.0}
{"epoch": 23, "training_loss": 281.8206214904785, "training_acc": 57.0, "val_loss": 38.17662000656128, "val_acc": 60.0}
{"epoch": 24, "training_loss": 321.3858242034912, "training_acc": 53.0, "val_loss": 149.72326755523682, "val_acc": 52.0}
{"epoch": 25, "training_loss": 462.1380395889282, "training_acc": 50.0, "val_loss": 58.896732330322266, "val_acc": 44.0}
{"epoch": 26, "training_loss": 384.643892288208, "training_acc": 53.0, "val_loss": 115.5538558959961, "val_acc": 52.0}
{"epoch": 27, "training_loss": 330.07514476776123, "training_acc": 54.0, "val_loss": 67.8888201713562, "val_acc": 44.0}
{"epoch": 28, "training_loss": 362.34574127197266, "training_acc": 54.0, "val_loss": 109.35529470443726, "val_acc": 52.0}
{"epoch": 29, "training_loss": 346.3677005767822, "training_acc": 51.0, "val_loss": 90.7907485961914, "val_acc": 48.0}
{"epoch": 30, "training_loss": 355.00793838500977, "training_acc": 48.0, "val_loss": 112.26972341537476, "val_acc": 52.0}
{"epoch": 31, "training_loss": 391.12610626220703, "training_acc": 47.0, "val_loss": 61.3916277885437, "val_acc": 48.0}
