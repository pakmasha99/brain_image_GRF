"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 566.6966743469238, "training_acc": 49.0, "val_loss": 134.67079401016235, "val_acc": 52.0}
{"epoch": 1, "training_loss": 615.102954864502, "training_acc": 49.0, "val_loss": 242.21365451812744, "val_acc": 48.0}
{"epoch": 2, "training_loss": 873.3809585571289, "training_acc": 47.0, "val_loss": 20.30199021100998, "val_acc": 44.0}
{"epoch": 3, "training_loss": 224.0159149169922, "training_acc": 56.0, "val_loss": 229.56311702728271, "val_acc": 52.0}
{"epoch": 4, "training_loss": 815.1110858917236, "training_acc": 53.0, "val_loss": 154.2819380760193, "val_acc": 52.0}
{"epoch": 5, "training_loss": 368.3538393974304, "training_acc": 54.0, "val_loss": 108.94790887832642, "val_acc": 48.0}
{"epoch": 6, "training_loss": 567.2245807647705, "training_acc": 47.0, "val_loss": 163.02393674850464, "val_acc": 48.0}
{"epoch": 7, "training_loss": 573.3188438415527, "training_acc": 47.0, "val_loss": 33.18692743778229, "val_acc": 52.0}
{"epoch": 8, "training_loss": 153.11731147766113, "training_acc": 58.0, "val_loss": 143.54455471038818, "val_acc": 52.0}
{"epoch": 9, "training_loss": 455.00595474243164, "training_acc": 53.0, "val_loss": 70.65804600715637, "val_acc": 52.0}
{"epoch": 10, "training_loss": 207.92518520355225, "training_acc": 46.0, "val_loss": 80.07522225379944, "val_acc": 48.0}
{"epoch": 11, "training_loss": 345.17168045043945, "training_acc": 47.0, "val_loss": 23.95857125520706, "val_acc": 36.0}
{"epoch": 12, "training_loss": 190.78256034851074, "training_acc": 42.0, "val_loss": 94.68128681182861, "val_acc": 52.0}
{"epoch": 13, "training_loss": 240.410231590271, "training_acc": 53.0, "val_loss": 21.731369197368622, "val_acc": 40.0}
{"epoch": 14, "training_loss": 118.87773036956787, "training_acc": 52.0, "val_loss": 39.805686473846436, "val_acc": 48.0}
{"epoch": 15, "training_loss": 157.02815961837769, "training_acc": 50.0, "val_loss": 51.76023840904236, "val_acc": 52.0}
{"epoch": 16, "training_loss": 152.68734788894653, "training_acc": 53.0, "val_loss": 19.1225603222847, "val_acc": 48.0}
{"epoch": 17, "training_loss": 112.59684944152832, "training_acc": 58.0, "val_loss": 31.271716952323914, "val_acc": 48.0}
{"epoch": 18, "training_loss": 119.93205714225769, "training_acc": 54.0, "val_loss": 47.71789908409119, "val_acc": 52.0}
{"epoch": 19, "training_loss": 137.73340606689453, "training_acc": 53.0, "val_loss": 18.88989955186844, "val_acc": 52.0}
{"epoch": 20, "training_loss": 85.62009739875793, "training_acc": 54.0, "val_loss": 18.022693693637848, "val_acc": 52.0}
{"epoch": 21, "training_loss": 72.12652444839478, "training_acc": 58.0, "val_loss": 30.54048717021942, "val_acc": 52.0}
{"epoch": 22, "training_loss": 77.76570439338684, "training_acc": 63.0, "val_loss": 19.07670944929123, "val_acc": 44.0}
{"epoch": 23, "training_loss": 75.12234139442444, "training_acc": 55.0, "val_loss": 23.068051040172577, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.06664395332336, "training_acc": 58.0, "val_loss": 19.046172499656677, "val_acc": 44.0}
{"epoch": 25, "training_loss": 72.23138976097107, "training_acc": 60.0, "val_loss": 31.021305918693542, "val_acc": 52.0}
{"epoch": 26, "training_loss": 82.98792767524719, "training_acc": 55.0, "val_loss": 20.398543775081635, "val_acc": 56.0}
{"epoch": 27, "training_loss": 66.22499513626099, "training_acc": 64.0, "val_loss": 19.99344527721405, "val_acc": 56.0}
{"epoch": 28, "training_loss": 76.38162231445312, "training_acc": 53.0, "val_loss": 20.585669577121735, "val_acc": 56.0}
{"epoch": 29, "training_loss": 60.026195764541626, "training_acc": 72.0, "val_loss": 21.766307950019836, "val_acc": 52.0}
{"epoch": 30, "training_loss": 60.1513729095459, "training_acc": 66.0, "val_loss": 23.817826807498932, "val_acc": 52.0}
{"epoch": 31, "training_loss": 65.98152256011963, "training_acc": 69.0, "val_loss": 20.373116433620453, "val_acc": 52.0}
{"epoch": 32, "training_loss": 64.8036379814148, "training_acc": 65.0, "val_loss": 21.303385496139526, "val_acc": 52.0}
{"epoch": 33, "training_loss": 64.58637928962708, "training_acc": 59.0, "val_loss": 18.46025288105011, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.8526382446289, "training_acc": 55.0, "val_loss": 18.28075796365738, "val_acc": 52.0}
{"epoch": 35, "training_loss": 56.15161895751953, "training_acc": 78.0, "val_loss": 18.488845229148865, "val_acc": 44.0}
{"epoch": 36, "training_loss": 61.46057987213135, "training_acc": 62.0, "val_loss": 25.521251559257507, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.72035551071167, "training_acc": 56.0, "val_loss": 18.052728474140167, "val_acc": 52.0}
{"epoch": 38, "training_loss": 60.244038581848145, "training_acc": 64.0, "val_loss": 18.868504464626312, "val_acc": 52.0}
{"epoch": 39, "training_loss": 58.36938166618347, "training_acc": 69.0, "val_loss": 20.154520869255066, "val_acc": 52.0}
