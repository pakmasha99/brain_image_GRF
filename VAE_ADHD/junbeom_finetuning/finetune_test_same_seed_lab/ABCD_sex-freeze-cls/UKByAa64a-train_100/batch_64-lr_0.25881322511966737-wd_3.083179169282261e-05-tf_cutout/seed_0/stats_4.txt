"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 695.7958488464355, "training_acc": 41.0, "val_loss": 164.28438425064087, "val_acc": 52.0}
{"epoch": 1, "training_loss": 584.0255088806152, "training_acc": 51.0, "val_loss": 191.13080501556396, "val_acc": 48.0}
{"epoch": 2, "training_loss": 681.9619464874268, "training_acc": 47.0, "val_loss": 21.701431274414062, "val_acc": 52.0}
{"epoch": 3, "training_loss": 209.91375923156738, "training_acc": 49.0, "val_loss": 90.08151292800903, "val_acc": 52.0}
{"epoch": 4, "training_loss": 245.263605594635, "training_acc": 53.0, "val_loss": 89.73858952522278, "val_acc": 48.0}
{"epoch": 5, "training_loss": 395.01675033569336, "training_acc": 47.0, "val_loss": 83.94792079925537, "val_acc": 48.0}
{"epoch": 6, "training_loss": 239.15978622436523, "training_acc": 48.0, "val_loss": 68.91790628433228, "val_acc": 52.0}
{"epoch": 7, "training_loss": 273.88682746887207, "training_acc": 53.0, "val_loss": 31.030195951461792, "val_acc": 52.0}
{"epoch": 8, "training_loss": 189.48287677764893, "training_acc": 43.0, "val_loss": 70.98121643066406, "val_acc": 48.0}
{"epoch": 9, "training_loss": 214.96895933151245, "training_acc": 47.0, "val_loss": 42.85516142845154, "val_acc": 52.0}
{"epoch": 10, "training_loss": 217.7196044921875, "training_acc": 53.0, "val_loss": 43.50866973400116, "val_acc": 52.0}
{"epoch": 11, "training_loss": 123.59361290931702, "training_acc": 56.0, "val_loss": 54.90347743034363, "val_acc": 48.0}
{"epoch": 12, "training_loss": 191.88163328170776, "training_acc": 47.0, "val_loss": 19.812853634357452, "val_acc": 52.0}
{"epoch": 13, "training_loss": 96.00095224380493, "training_acc": 54.0, "val_loss": 28.778603672981262, "val_acc": 52.0}
{"epoch": 14, "training_loss": 91.23044323921204, "training_acc": 53.0, "val_loss": 42.88699924945831, "val_acc": 48.0}
{"epoch": 15, "training_loss": 136.4631519317627, "training_acc": 48.0, "val_loss": 27.44743824005127, "val_acc": 52.0}
{"epoch": 16, "training_loss": 110.08308911323547, "training_acc": 54.0, "val_loss": 19.499343633651733, "val_acc": 48.0}
{"epoch": 17, "training_loss": 66.02457046508789, "training_acc": 64.0, "val_loss": 26.777419447898865, "val_acc": 44.0}
{"epoch": 18, "training_loss": 86.03927707672119, "training_acc": 53.0, "val_loss": 22.44529277086258, "val_acc": 52.0}
{"epoch": 19, "training_loss": 81.77687644958496, "training_acc": 58.0, "val_loss": 18.85543018579483, "val_acc": 60.0}
{"epoch": 20, "training_loss": 67.6351490020752, "training_acc": 61.0, "val_loss": 17.873263359069824, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21646189689636, "training_acc": 55.0, "val_loss": 17.293651401996613, "val_acc": 52.0}
{"epoch": 22, "training_loss": 66.46447777748108, "training_acc": 60.0, "val_loss": 17.181579768657684, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.65247821807861, "training_acc": 60.0, "val_loss": 16.87278300523758, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.69221544265747, "training_acc": 64.0, "val_loss": 16.842463612556458, "val_acc": 52.0}
{"epoch": 25, "training_loss": 61.34769558906555, "training_acc": 71.0, "val_loss": 17.73209124803543, "val_acc": 64.0}
{"epoch": 26, "training_loss": 66.34733891487122, "training_acc": 58.0, "val_loss": 16.938811540603638, "val_acc": 52.0}
{"epoch": 27, "training_loss": 63.234829902648926, "training_acc": 65.0, "val_loss": 16.617703437805176, "val_acc": 48.0}
{"epoch": 28, "training_loss": 62.14340162277222, "training_acc": 70.0, "val_loss": 16.928301751613617, "val_acc": 52.0}
{"epoch": 29, "training_loss": 60.02054166793823, "training_acc": 71.0, "val_loss": 17.390689253807068, "val_acc": 52.0}
{"epoch": 30, "training_loss": 63.643646240234375, "training_acc": 65.0, "val_loss": 16.887103021144867, "val_acc": 48.0}
{"epoch": 31, "training_loss": 60.181307315826416, "training_acc": 73.0, "val_loss": 17.617875337600708, "val_acc": 52.0}
{"epoch": 32, "training_loss": 62.43210983276367, "training_acc": 68.0, "val_loss": 17.198586463928223, "val_acc": 68.0}
{"epoch": 33, "training_loss": 62.50241208076477, "training_acc": 62.0, "val_loss": 21.902282536029816, "val_acc": 52.0}
{"epoch": 34, "training_loss": 67.87730574607849, "training_acc": 61.0, "val_loss": 19.539596140384674, "val_acc": 44.0}
{"epoch": 35, "training_loss": 69.74090623855591, "training_acc": 55.0, "val_loss": 17.86724478006363, "val_acc": 52.0}
{"epoch": 36, "training_loss": 72.68567991256714, "training_acc": 52.0, "val_loss": 17.1330526471138, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70.63482356071472, "training_acc": 60.0, "val_loss": 21.068507432937622, "val_acc": 44.0}
{"epoch": 38, "training_loss": 76.3722734451294, "training_acc": 52.0, "val_loss": 18.838752806186676, "val_acc": 52.0}
{"epoch": 39, "training_loss": 64.18153715133667, "training_acc": 60.0, "val_loss": 22.061355412006378, "val_acc": 48.0}
{"epoch": 40, "training_loss": 82.86494851112366, "training_acc": 48.0, "val_loss": 16.9442281126976, "val_acc": 56.0}
{"epoch": 41, "training_loss": 59.019405364990234, "training_acc": 71.0, "val_loss": 17.871233820915222, "val_acc": 52.0}
{"epoch": 42, "training_loss": 57.924277544021606, "training_acc": 65.0, "val_loss": 17.222198843955994, "val_acc": 52.0}
{"epoch": 43, "training_loss": 61.743457078933716, "training_acc": 61.0, "val_loss": 23.26844036579132, "val_acc": 48.0}
{"epoch": 44, "training_loss": 71.87016797065735, "training_acc": 55.0, "val_loss": 23.102430999279022, "val_acc": 52.0}
{"epoch": 45, "training_loss": 71.74026226997375, "training_acc": 59.0, "val_loss": 17.81095117330551, "val_acc": 64.0}
{"epoch": 46, "training_loss": 59.665522813797, "training_acc": 67.0, "val_loss": 16.987434029579163, "val_acc": 56.0}
