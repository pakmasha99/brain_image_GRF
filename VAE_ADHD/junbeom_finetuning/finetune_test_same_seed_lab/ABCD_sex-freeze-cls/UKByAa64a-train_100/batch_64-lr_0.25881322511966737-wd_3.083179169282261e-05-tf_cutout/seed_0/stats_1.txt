"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 587.9873428344727, "training_acc": 46.0, "val_loss": 113.48385810852051, "val_acc": 52.0}
{"epoch": 1, "training_loss": 552.0009536743164, "training_acc": 53.0, "val_loss": 294.3164348602295, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1107.2210578918457, "training_acc": 47.0, "val_loss": 81.60829544067383, "val_acc": 48.0}
{"epoch": 3, "training_loss": 385.6282072067261, "training_acc": 51.0, "val_loss": 214.8519515991211, "val_acc": 52.0}
{"epoch": 4, "training_loss": 816.9865798950195, "training_acc": 53.0, "val_loss": 191.7108416557312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 569.6413059234619, "training_acc": 53.0, "val_loss": 35.18730103969574, "val_acc": 48.0}
{"epoch": 6, "training_loss": 318.51941108703613, "training_acc": 47.0, "val_loss": 107.85723924636841, "val_acc": 48.0}
{"epoch": 7, "training_loss": 374.73306465148926, "training_acc": 47.0, "val_loss": 55.9289813041687, "val_acc": 52.0}
{"epoch": 8, "training_loss": 222.11230182647705, "training_acc": 53.0, "val_loss": 104.60741519927979, "val_acc": 52.0}
{"epoch": 9, "training_loss": 328.7867579460144, "training_acc": 53.0, "val_loss": 18.128839135169983, "val_acc": 56.0}
{"epoch": 10, "training_loss": 143.33827304840088, "training_acc": 50.0, "val_loss": 46.049970388412476, "val_acc": 48.0}
{"epoch": 11, "training_loss": 168.25044131278992, "training_acc": 45.0, "val_loss": 45.39319574832916, "val_acc": 52.0}
{"epoch": 12, "training_loss": 146.42653560638428, "training_acc": 53.0, "val_loss": 18.293121457099915, "val_acc": 52.0}
{"epoch": 13, "training_loss": 84.52942681312561, "training_acc": 52.0, "val_loss": 19.80070471763611, "val_acc": 40.0}
{"epoch": 14, "training_loss": 77.10733151435852, "training_acc": 55.0, "val_loss": 31.00484311580658, "val_acc": 52.0}
{"epoch": 15, "training_loss": 91.52339100837708, "training_acc": 56.0, "val_loss": 21.44579291343689, "val_acc": 52.0}
{"epoch": 16, "training_loss": 84.6789927482605, "training_acc": 52.0, "val_loss": 24.02796894311905, "val_acc": 52.0}
{"epoch": 17, "training_loss": 83.5064811706543, "training_acc": 54.0, "val_loss": 16.709239780902863, "val_acc": 64.0}
{"epoch": 18, "training_loss": 91.93402338027954, "training_acc": 47.0, "val_loss": 22.642408311367035, "val_acc": 52.0}
{"epoch": 19, "training_loss": 93.00913524627686, "training_acc": 56.0, "val_loss": 18.356841802597046, "val_acc": 56.0}
{"epoch": 20, "training_loss": 66.12968945503235, "training_acc": 63.0, "val_loss": 21.06090486049652, "val_acc": 48.0}
{"epoch": 21, "training_loss": 89.532719373703, "training_acc": 51.0, "val_loss": 27.412888407707214, "val_acc": 52.0}
{"epoch": 22, "training_loss": 80.20124459266663, "training_acc": 60.0, "val_loss": 19.00380253791809, "val_acc": 44.0}
{"epoch": 23, "training_loss": 72.67111563682556, "training_acc": 55.0, "val_loss": 20.17720937728882, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.24045395851135, "training_acc": 61.0, "val_loss": 17.47172474861145, "val_acc": 60.0}
{"epoch": 25, "training_loss": 63.05177617073059, "training_acc": 61.0, "val_loss": 20.062856376171112, "val_acc": 52.0}
{"epoch": 26, "training_loss": 72.84400939941406, "training_acc": 53.0, "val_loss": 17.823965847492218, "val_acc": 56.0}
{"epoch": 27, "training_loss": 64.1422483921051, "training_acc": 59.0, "val_loss": 17.109090089797974, "val_acc": 64.0}
{"epoch": 28, "training_loss": 62.639397859573364, "training_acc": 62.0, "val_loss": 17.315681278705597, "val_acc": 60.0}
{"epoch": 29, "training_loss": 62.1170699596405, "training_acc": 65.0, "val_loss": 23.828890919685364, "val_acc": 52.0}
{"epoch": 30, "training_loss": 77.80299878120422, "training_acc": 57.0, "val_loss": 18.38463991880417, "val_acc": 48.0}
{"epoch": 31, "training_loss": 65.61974668502808, "training_acc": 60.0, "val_loss": 25.49840211868286, "val_acc": 52.0}
{"epoch": 32, "training_loss": 77.8912079334259, "training_acc": 56.0, "val_loss": 22.645972669124603, "val_acc": 48.0}
{"epoch": 33, "training_loss": 84.48872876167297, "training_acc": 47.0, "val_loss": 21.13071233034134, "val_acc": 52.0}
{"epoch": 34, "training_loss": 74.77072954177856, "training_acc": 56.0, "val_loss": 28.690189123153687, "val_acc": 48.0}
{"epoch": 35, "training_loss": 107.320796251297, "training_acc": 47.0, "val_loss": 30.398020148277283, "val_acc": 52.0}
{"epoch": 36, "training_loss": 101.90482950210571, "training_acc": 53.0, "val_loss": 19.78830248117447, "val_acc": 44.0}
