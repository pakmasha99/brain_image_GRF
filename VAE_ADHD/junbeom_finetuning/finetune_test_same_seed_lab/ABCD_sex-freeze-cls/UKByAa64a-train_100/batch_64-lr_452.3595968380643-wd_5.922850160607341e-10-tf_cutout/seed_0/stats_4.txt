"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 812681.5017547607, "training_acc": 51.0, "val_loss": 152383.45947265625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 897265.42578125, "training_acc": 55.0, "val_loss": 570379.150390625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2164500.0390625, "training_acc": 47.0, "val_loss": 172598.046875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 643442.775390625, "training_acc": 53.0, "val_loss": 359625.5615234375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1426262.1015625, "training_acc": 53.0, "val_loss": 320641.552734375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 972510.58984375, "training_acc": 53.0, "val_loss": 95442.02880859375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 630183.48046875, "training_acc": 47.0, "val_loss": 201466.5771484375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 667516.5458984375, "training_acc": 47.0, "val_loss": 111521.8994140625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 516150.216796875, "training_acc": 53.0, "val_loss": 186018.7744140625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 586121.96484375, "training_acc": 53.0, "val_loss": 43855.81970214844, "val_acc": 48.0}
{"epoch": 10, "training_loss": 245309.5224609375, "training_acc": 48.0, "val_loss": 51194.39697265625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 238531.9970703125, "training_acc": 48.0, "val_loss": 100987.07885742188, "val_acc": 52.0}
{"epoch": 12, "training_loss": 312240.2783203125, "training_acc": 52.0, "val_loss": 38757.1044921875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 228191.8291015625, "training_acc": 49.0, "val_loss": 20601.16424560547, "val_acc": 44.0}
{"epoch": 14, "training_loss": 97384.9267578125, "training_acc": 61.0, "val_loss": 90820.54443359375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 259915.66455078125, "training_acc": 53.0, "val_loss": 66603.86352539062, "val_acc": 48.0}
{"epoch": 16, "training_loss": 284999.9091796875, "training_acc": 48.0, "val_loss": 33374.00817871094, "val_acc": 48.0}
{"epoch": 17, "training_loss": 157156.16796875, "training_acc": 57.0, "val_loss": 92413.0126953125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 263513.3359375, "training_acc": 57.0, "val_loss": 52809.417724609375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 236181.869140625, "training_acc": 49.0, "val_loss": 15191.423034667969, "val_acc": 48.0}
{"epoch": 20, "training_loss": 132762.3486328125, "training_acc": 59.0, "val_loss": 73097.66845703125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 203874.4580078125, "training_acc": 51.0, "val_loss": 61335.198974609375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 209887.9072265625, "training_acc": 50.0, "val_loss": 37632.87048339844, "val_acc": 52.0}
{"epoch": 23, "training_loss": 133912.40478515625, "training_acc": 56.0, "val_loss": 11638.706970214844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 83606.85302734375, "training_acc": 54.0, "val_loss": 16983.724975585938, "val_acc": 56.0}
{"epoch": 25, "training_loss": 102300.47705078125, "training_acc": 55.0, "val_loss": 10882.112121582031, "val_acc": 56.0}
{"epoch": 26, "training_loss": 112389.5625, "training_acc": 54.0, "val_loss": 12249.32861328125, "val_acc": 60.0}
{"epoch": 27, "training_loss": 79621.046875, "training_acc": 58.0, "val_loss": 10838.24462890625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 45041.56896972656, "training_acc": 62.0, "val_loss": 43863.03405761719, "val_acc": 52.0}
{"epoch": 29, "training_loss": 113317.50512695312, "training_acc": 56.0, "val_loss": 45534.4482421875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 153994.4375, "training_acc": 49.0, "val_loss": 24793.739318847656, "val_acc": 52.0}
{"epoch": 31, "training_loss": 63746.083251953125, "training_acc": 58.0, "val_loss": 25219.7265625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 71349.00415039062, "training_acc": 54.0, "val_loss": 5832.733917236328, "val_acc": 56.0}
{"epoch": 33, "training_loss": 36643.791748046875, "training_acc": 61.0, "val_loss": 29913.400268554688, "val_acc": 48.0}
{"epoch": 34, "training_loss": 71432.47393798828, "training_acc": 57.0, "val_loss": 24965.460205078125, "val_acc": 48.0}
{"epoch": 35, "training_loss": 59937.030029296875, "training_acc": 61.0, "val_loss": 7212.630462646484, "val_acc": 68.0}
{"epoch": 36, "training_loss": 26632.353393554688, "training_acc": 62.0, "val_loss": 31261.24267578125, "val_acc": 48.0}
{"epoch": 37, "training_loss": 64534.20812988281, "training_acc": 61.0, "val_loss": 43902.60925292969, "val_acc": 52.0}
{"epoch": 38, "training_loss": 120002.09631347656, "training_acc": 55.0, "val_loss": 58072.76611328125, "val_acc": 48.0}
{"epoch": 39, "training_loss": 180698.32470703125, "training_acc": 49.0, "val_loss": 60823.13232421875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 224465.9990234375, "training_acc": 53.0, "val_loss": 5507.754135131836, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70602.41162109375, "training_acc": 65.0, "val_loss": 28588.58642578125, "val_acc": 48.0}
{"epoch": 42, "training_loss": 201434.650390625, "training_acc": 43.0, "val_loss": 90892.67578125, "val_acc": 52.0}
{"epoch": 43, "training_loss": 241119.03173828125, "training_acc": 53.0, "val_loss": 104788.0859375, "val_acc": 48.0}
{"epoch": 44, "training_loss": 453226.068359375, "training_acc": 47.0, "val_loss": 112495.7275390625, "val_acc": 48.0}
{"epoch": 45, "training_loss": 234911.23834228516, "training_acc": 55.0, "val_loss": 101456.67114257812, "val_acc": 52.0}
{"epoch": 46, "training_loss": 431831.06640625, "training_acc": 53.0, "val_loss": 78879.01611328125, "val_acc": 52.0}
{"epoch": 47, "training_loss": 283447.20947265625, "training_acc": 44.0, "val_loss": 78151.85546875, "val_acc": 48.0}
{"epoch": 48, "training_loss": 193261.2198486328, "training_acc": 56.0, "val_loss": 67516.74194335938, "val_acc": 52.0}
{"epoch": 49, "training_loss": 266039.4033203125, "training_acc": 53.0, "val_loss": 7929.47998046875, "val_acc": 52.0}
{"epoch": 50, "training_loss": 107845.5146484375, "training_acc": 63.0, "val_loss": 45931.085205078125, "val_acc": 48.0}
{"epoch": 51, "training_loss": 153108.09521484375, "training_acc": 50.0, "val_loss": 55246.337890625, "val_acc": 52.0}
{"epoch": 52, "training_loss": 114478.73999023438, "training_acc": 63.0, "val_loss": 77487.15209960938, "val_acc": 48.0}
{"epoch": 53, "training_loss": 243280.59375, "training_acc": 47.0, "val_loss": 25877.615356445312, "val_acc": 52.0}
{"epoch": 54, "training_loss": 85741.73413085938, "training_acc": 57.0, "val_loss": 18437.5732421875, "val_acc": 40.0}
{"epoch": 55, "training_loss": 51739.424072265625, "training_acc": 63.0, "val_loss": 27195.025634765625, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70750.52355957031, "training_acc": 56.0, "val_loss": 39080.328369140625, "val_acc": 48.0}
{"epoch": 57, "training_loss": 94478.111328125, "training_acc": 55.0, "val_loss": 8175.434875488281, "val_acc": 68.0}
{"epoch": 58, "training_loss": 51160.977294921875, "training_acc": 58.0, "val_loss": 18798.634338378906, "val_acc": 52.0}
{"epoch": 59, "training_loss": 53386.29089355469, "training_acc": 60.0, "val_loss": 12878.863525390625, "val_acc": 40.0}
