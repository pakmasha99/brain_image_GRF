"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 135486.08347320557, "training_acc": 53.0, "val_loss": 381232.03125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1539064.1640625, "training_acc": 47.0, "val_loss": 29898.92578125, "val_acc": 44.0}
{"epoch": 2, "training_loss": 258585.796875, "training_acc": 68.0, "val_loss": 369957.4951171875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1149525.65234375, "training_acc": 53.0, "val_loss": 97849.169921875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 490412.55859375, "training_acc": 47.0, "val_loss": 286643.1396484375, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1158004.33984375, "training_acc": 47.0, "val_loss": 75798.37036132812, "val_acc": 48.0}
{"epoch": 6, "training_loss": 397960.724609375, "training_acc": 51.0, "val_loss": 283019.140625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 989153.51953125, "training_acc": 53.0, "val_loss": 223853.955078125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 567192.7182617188, "training_acc": 54.0, "val_loss": 130288.9404296875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 683968.140625, "training_acc": 47.0, "val_loss": 203111.63330078125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 730710.125, "training_acc": 47.0, "val_loss": 71853.02734375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 259343.03515625, "training_acc": 54.0, "val_loss": 171273.05908203125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 460876.267578125, "training_acc": 53.0, "val_loss": 29348.797607421875, "val_acc": 52.0}
{"epoch": 13, "training_loss": 187970.7607421875, "training_acc": 56.0, "val_loss": 43228.369140625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 232301.71411132812, "training_acc": 55.0, "val_loss": 118645.99609375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 290202.111328125, "training_acc": 53.0, "val_loss": 33450.32653808594, "val_acc": 52.0}
{"epoch": 16, "training_loss": 130112.72412109375, "training_acc": 57.0, "val_loss": 44787.225341796875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 180247.00756835938, "training_acc": 57.0, "val_loss": 95294.34204101562, "val_acc": 52.0}
{"epoch": 18, "training_loss": 223754.548828125, "training_acc": 55.0, "val_loss": 27415.249633789062, "val_acc": 48.0}
{"epoch": 19, "training_loss": 136811.7001953125, "training_acc": 60.0, "val_loss": 34858.77685546875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 208884.1279296875, "training_acc": 44.0, "val_loss": 89262.35961914062, "val_acc": 52.0}
{"epoch": 21, "training_loss": 183211.13208007812, "training_acc": 55.0, "val_loss": 20810.940551757812, "val_acc": 52.0}
{"epoch": 22, "training_loss": 109631.40942382812, "training_acc": 62.0, "val_loss": 37228.00598144531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 89875.21850585938, "training_acc": 54.0, "val_loss": 26838.070678710938, "val_acc": 52.0}
{"epoch": 24, "training_loss": 113232.84582519531, "training_acc": 58.0, "val_loss": 54961.761474609375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 105511.76293945312, "training_acc": 57.0, "val_loss": 41036.39831542969, "val_acc": 48.0}
{"epoch": 26, "training_loss": 158983.66748046875, "training_acc": 47.0, "val_loss": 71190.69213867188, "val_acc": 52.0}
{"epoch": 27, "training_loss": 211404.1220703125, "training_acc": 54.0, "val_loss": 21592.3095703125, "val_acc": 52.0}
{"epoch": 28, "training_loss": 144945.0546875, "training_acc": 61.0, "val_loss": 75982.09228515625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 195185.07421875, "training_acc": 54.0, "val_loss": 110991.40625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 365101.4990234375, "training_acc": 53.0, "val_loss": 83813.73291015625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 192476.9541015625, "training_acc": 53.0, "val_loss": 52419.7509765625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 183693.79272460938, "training_acc": 44.0, "val_loss": 33023.77624511719, "val_acc": 52.0}
{"epoch": 33, "training_loss": 53497.73876953125, "training_acc": 66.0, "val_loss": 16848.715209960938, "val_acc": 48.0}
{"epoch": 34, "training_loss": 37333.852783203125, "training_acc": 65.0, "val_loss": 8312.590026855469, "val_acc": 48.0}
{"epoch": 35, "training_loss": 28938.125366210938, "training_acc": 71.0, "val_loss": 30191.952514648438, "val_acc": 52.0}
{"epoch": 36, "training_loss": 48924.32263183594, "training_acc": 69.0, "val_loss": 11320.21484375, "val_acc": 44.0}
{"epoch": 37, "training_loss": 29869.959106445312, "training_acc": 65.0, "val_loss": 30179.019165039062, "val_acc": 52.0}
{"epoch": 38, "training_loss": 58829.07263183594, "training_acc": 65.0, "val_loss": 40102.31018066406, "val_acc": 48.0}
{"epoch": 39, "training_loss": 143464.22106933594, "training_acc": 48.0, "val_loss": 48721.014404296875, "val_acc": 52.0}
{"epoch": 40, "training_loss": 110208.60540771484, "training_acc": 60.0, "val_loss": 40677.38342285156, "val_acc": 48.0}
{"epoch": 41, "training_loss": 111826.20050048828, "training_acc": 57.0, "val_loss": 64872.4365234375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 166176.96728515625, "training_acc": 53.0, "val_loss": 57110.540771484375, "val_acc": 48.0}
{"epoch": 43, "training_loss": 251036.001953125, "training_acc": 47.0, "val_loss": 21991.693115234375, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68636.0185546875, "training_acc": 63.0, "val_loss": 20629.10919189453, "val_acc": 52.0}
{"epoch": 45, "training_loss": 100573.826171875, "training_acc": 61.0, "val_loss": 14762.193298339844, "val_acc": 52.0}
{"epoch": 46, "training_loss": 152145.1181640625, "training_acc": 52.0, "val_loss": 116941.63818359375, "val_acc": 52.0}
{"epoch": 47, "training_loss": 288039.85693359375, "training_acc": 54.0, "val_loss": 66780.57861328125, "val_acc": 48.0}
{"epoch": 48, "training_loss": 322837.47265625, "training_acc": 47.0, "val_loss": 27752.029418945312, "val_acc": 48.0}
{"epoch": 49, "training_loss": 166464.056640625, "training_acc": 55.0, "val_loss": 158762.34130859375, "val_acc": 52.0}
{"epoch": 50, "training_loss": 483706.67578125, "training_acc": 53.0, "val_loss": 35558.209228515625, "val_acc": 52.0}
{"epoch": 51, "training_loss": 214105.494140625, "training_acc": 57.0, "val_loss": 167433.87451171875, "val_acc": 48.0}
{"epoch": 52, "training_loss": 645714.96484375, "training_acc": 47.0, "val_loss": 12460.147094726562, "val_acc": 44.0}
{"epoch": 53, "training_loss": 207493.12109375, "training_acc": 62.0, "val_loss": 206645.068359375, "val_acc": 52.0}
