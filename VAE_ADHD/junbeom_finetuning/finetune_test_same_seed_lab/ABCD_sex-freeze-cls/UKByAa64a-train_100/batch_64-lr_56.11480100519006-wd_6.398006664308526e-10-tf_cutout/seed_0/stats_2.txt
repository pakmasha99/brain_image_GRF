"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 135959.3628540039, "training_acc": 43.0, "val_loss": 32996.53015136719, "val_acc": 52.0}
{"epoch": 1, "training_loss": 116490.306640625, "training_acc": 55.0, "val_loss": 49462.5, "val_acc": 48.0}
{"epoch": 2, "training_loss": 179033.33447265625, "training_acc": 47.0, "val_loss": 5095.112228393555, "val_acc": 48.0}
{"epoch": 3, "training_loss": 68747.6845703125, "training_acc": 47.0, "val_loss": 56256.280517578125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 219612.29150390625, "training_acc": 53.0, "val_loss": 49238.433837890625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 165536.06372070312, "training_acc": 53.0, "val_loss": 2227.3502349853516, "val_acc": 52.0}
{"epoch": 6, "training_loss": 58380.3046875, "training_acc": 49.0, "val_loss": 54595.73974609375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 225496.7294921875, "training_acc": 47.0, "val_loss": 51119.720458984375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 175760.29541015625, "training_acc": 47.0, "val_loss": 3618.3162689208984, "val_acc": 48.0}
{"epoch": 9, "training_loss": 45162.79736328125, "training_acc": 50.0, "val_loss": 47944.8974609375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 194655.2958984375, "training_acc": 53.0, "val_loss": 55269.921875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 199494.82421875, "training_acc": 53.0, "val_loss": 28997.262573242188, "val_acc": 52.0}
{"epoch": 12, "training_loss": 85061.39141845703, "training_acc": 54.0, "val_loss": 26654.16259765625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 126652.05908203125, "training_acc": 47.0, "val_loss": 49095.71838378906, "val_acc": 48.0}
{"epoch": 14, "training_loss": 180203.3779296875, "training_acc": 47.0, "val_loss": 28948.455810546875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 75686.11535644531, "training_acc": 47.0, "val_loss": 22722.95684814453, "val_acc": 52.0}
{"epoch": 16, "training_loss": 111078.2353515625, "training_acc": 53.0, "val_loss": 46693.017578125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 180529.5009765625, "training_acc": 53.0, "val_loss": 34957.879638671875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 109272.16357421875, "training_acc": 53.0, "val_loss": 6877.556610107422, "val_acc": 48.0}
{"epoch": 19, "training_loss": 47721.43359375, "training_acc": 48.0, "val_loss": 24171.145629882812, "val_acc": 48.0}
{"epoch": 20, "training_loss": 79638.28686523438, "training_acc": 47.0, "val_loss": 1482.1813583374023, "val_acc": 44.0}
{"epoch": 21, "training_loss": 26292.597412109375, "training_acc": 54.0, "val_loss": 21872.959899902344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 77811.09423828125, "training_acc": 53.0, "val_loss": 8771.053314208984, "val_acc": 52.0}
{"epoch": 23, "training_loss": 31105.923583984375, "training_acc": 53.0, "val_loss": 16333.773803710938, "val_acc": 48.0}
{"epoch": 24, "training_loss": 61974.2109375, "training_acc": 47.0, "val_loss": 1703.3447265625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 26176.57861328125, "training_acc": 55.0, "val_loss": 21573.092651367188, "val_acc": 52.0}
{"epoch": 26, "training_loss": 73687.65966796875, "training_acc": 53.0, "val_loss": 9067.425537109375, "val_acc": 52.0}
{"epoch": 27, "training_loss": 34645.65808105469, "training_acc": 49.0, "val_loss": 14890.8203125, "val_acc": 48.0}
