"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 307.93748664855957, "training_acc": 55.0, "val_loss": 33.41584801673889, "val_acc": 36.0}
{"epoch": 1, "training_loss": 197.4662322998047, "training_acc": 48.0, "val_loss": 136.68049573898315, "val_acc": 52.0}
{"epoch": 2, "training_loss": 355.1716003417969, "training_acc": 53.0, "val_loss": 28.773176670074463, "val_acc": 36.0}
{"epoch": 3, "training_loss": 173.38475704193115, "training_acc": 50.0, "val_loss": 43.43458712100983, "val_acc": 52.0}
{"epoch": 4, "training_loss": 141.4456672668457, "training_acc": 51.0, "val_loss": 27.724039554595947, "val_acc": 52.0}
{"epoch": 5, "training_loss": 99.22366762161255, "training_acc": 58.0, "val_loss": 28.86245548725128, "val_acc": 52.0}
{"epoch": 6, "training_loss": 72.36350870132446, "training_acc": 62.0, "val_loss": 20.462696254253387, "val_acc": 48.0}
{"epoch": 7, "training_loss": 85.14598107337952, "training_acc": 55.0, "val_loss": 45.18832266330719, "val_acc": 52.0}
{"epoch": 8, "training_loss": 159.3936038017273, "training_acc": 53.0, "val_loss": 37.939512729644775, "val_acc": 48.0}
{"epoch": 9, "training_loss": 165.51099586486816, "training_acc": 48.0, "val_loss": 16.037875413894653, "val_acc": 56.0}
{"epoch": 10, "training_loss": 129.19436645507812, "training_acc": 58.0, "val_loss": 48.640838265419006, "val_acc": 52.0}
{"epoch": 11, "training_loss": 127.41912269592285, "training_acc": 64.0, "val_loss": 64.33995962142944, "val_acc": 48.0}
{"epoch": 12, "training_loss": 252.6469898223877, "training_acc": 48.0, "val_loss": 22.022615373134613, "val_acc": 52.0}
{"epoch": 13, "training_loss": 137.2123565673828, "training_acc": 57.0, "val_loss": 55.95378875732422, "val_acc": 52.0}
{"epoch": 14, "training_loss": 124.31647992134094, "training_acc": 59.0, "val_loss": 40.60259461402893, "val_acc": 48.0}
{"epoch": 15, "training_loss": 166.60396528244019, "training_acc": 51.0, "val_loss": 52.3027777671814, "val_acc": 52.0}
{"epoch": 16, "training_loss": 126.5901198387146, "training_acc": 53.0, "val_loss": 23.542092740535736, "val_acc": 56.0}
{"epoch": 17, "training_loss": 96.02269411087036, "training_acc": 55.0, "val_loss": 22.185710072517395, "val_acc": 52.0}
{"epoch": 18, "training_loss": 87.17920541763306, "training_acc": 58.0, "val_loss": 41.317397356033325, "val_acc": 52.0}
{"epoch": 19, "training_loss": 84.13539028167725, "training_acc": 60.0, "val_loss": 25.05250573158264, "val_acc": 48.0}
{"epoch": 20, "training_loss": 102.41982626914978, "training_acc": 56.0, "val_loss": 36.56727373600006, "val_acc": 52.0}
{"epoch": 21, "training_loss": 82.94466066360474, "training_acc": 55.0, "val_loss": 21.688899397850037, "val_acc": 56.0}
{"epoch": 22, "training_loss": 81.98868131637573, "training_acc": 56.0, "val_loss": 28.836092352867126, "val_acc": 52.0}
{"epoch": 23, "training_loss": 76.88759446144104, "training_acc": 58.0, "val_loss": 19.443289935588837, "val_acc": 60.0}
{"epoch": 24, "training_loss": 84.18655204772949, "training_acc": 51.0, "val_loss": 40.07765352725983, "val_acc": 52.0}
{"epoch": 25, "training_loss": 107.87542057037354, "training_acc": 54.0, "val_loss": 17.87939816713333, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.84064173698425, "training_acc": 57.0, "val_loss": 22.199229896068573, "val_acc": 52.0}
{"epoch": 27, "training_loss": 78.79665470123291, "training_acc": 59.0, "val_loss": 19.23094093799591, "val_acc": 40.0}
{"epoch": 28, "training_loss": 66.89393591880798, "training_acc": 58.0, "val_loss": 26.196476817131042, "val_acc": 52.0}
