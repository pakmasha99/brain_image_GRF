"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 456.43297958374023, "training_acc": 53.0, "val_loss": 20.830093324184418, "val_acc": 52.0}
{"epoch": 1, "training_loss": 321.54602813720703, "training_acc": 52.0, "val_loss": 97.34559655189514, "val_acc": 48.0}
{"epoch": 2, "training_loss": 341.134313583374, "training_acc": 51.0, "val_loss": 132.68886804580688, "val_acc": 52.0}
{"epoch": 3, "training_loss": 468.10226917266846, "training_acc": 53.0, "val_loss": 28.215834498405457, "val_acc": 48.0}
{"epoch": 4, "training_loss": 145.68203926086426, "training_acc": 49.0, "val_loss": 18.57426017522812, "val_acc": 56.0}
{"epoch": 5, "training_loss": 137.466290473938, "training_acc": 54.0, "val_loss": 36.45631670951843, "val_acc": 52.0}
{"epoch": 6, "training_loss": 151.41502046585083, "training_acc": 44.0, "val_loss": 35.88261008262634, "val_acc": 48.0}
{"epoch": 7, "training_loss": 128.87917637825012, "training_acc": 50.0, "val_loss": 36.877769231796265, "val_acc": 52.0}
{"epoch": 8, "training_loss": 114.26084446907043, "training_acc": 55.0, "val_loss": 35.42434275150299, "val_acc": 48.0}
{"epoch": 9, "training_loss": 130.90999841690063, "training_acc": 47.0, "val_loss": 24.194717407226562, "val_acc": 52.0}
{"epoch": 10, "training_loss": 96.82336759567261, "training_acc": 55.0, "val_loss": 17.714105546474457, "val_acc": 64.0}
{"epoch": 11, "training_loss": 90.8654932975769, "training_acc": 52.0, "val_loss": 16.975049674510956, "val_acc": 68.0}
{"epoch": 12, "training_loss": 82.42352485656738, "training_acc": 52.0, "val_loss": 18.550916016101837, "val_acc": 52.0}
{"epoch": 13, "training_loss": 81.69866275787354, "training_acc": 56.0, "val_loss": 16.76962971687317, "val_acc": 68.0}
{"epoch": 14, "training_loss": 71.56859636306763, "training_acc": 65.0, "val_loss": 20.214545726776123, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.85115766525269, "training_acc": 59.0, "val_loss": 18.83886158466339, "val_acc": 60.0}
{"epoch": 16, "training_loss": 74.63560605049133, "training_acc": 55.0, "val_loss": 19.789062440395355, "val_acc": 52.0}
{"epoch": 17, "training_loss": 76.97689390182495, "training_acc": 54.0, "val_loss": 16.921938955783844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 72.41489505767822, "training_acc": 53.0, "val_loss": 18.386633694171906, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.91445016860962, "training_acc": 54.0, "val_loss": 17.815953493118286, "val_acc": 52.0}
{"epoch": 20, "training_loss": 65.81827569007874, "training_acc": 56.0, "val_loss": 16.73930734395981, "val_acc": 64.0}
{"epoch": 21, "training_loss": 73.18108296394348, "training_acc": 59.0, "val_loss": 30.235648155212402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 95.38691735267639, "training_acc": 53.0, "val_loss": 17.315684258937836, "val_acc": 56.0}
{"epoch": 23, "training_loss": 61.24126148223877, "training_acc": 69.0, "val_loss": 22.712019085884094, "val_acc": 52.0}
{"epoch": 24, "training_loss": 65.72088980674744, "training_acc": 58.0, "val_loss": 20.936033129692078, "val_acc": 48.0}
{"epoch": 25, "training_loss": 73.0025372505188, "training_acc": 56.0, "val_loss": 31.58993422985077, "val_acc": 52.0}
{"epoch": 26, "training_loss": 88.49823331832886, "training_acc": 54.0, "val_loss": 32.3063999414444, "val_acc": 48.0}
{"epoch": 27, "training_loss": 103.84507346153259, "training_acc": 48.0, "val_loss": 47.82901704311371, "val_acc": 52.0}
{"epoch": 28, "training_loss": 154.52378273010254, "training_acc": 53.0, "val_loss": 18.479259312152863, "val_acc": 60.0}
{"epoch": 29, "training_loss": 93.67100954055786, "training_acc": 52.0, "val_loss": 19.293008744716644, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.92655301094055, "training_acc": 54.0, "val_loss": 17.541567981243134, "val_acc": 56.0}
{"epoch": 31, "training_loss": 62.03390049934387, "training_acc": 65.0, "val_loss": 17.153064906597137, "val_acc": 64.0}
{"epoch": 32, "training_loss": 60.955833435058594, "training_acc": 68.0, "val_loss": 18.13281923532486, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.0891387462616, "training_acc": 58.0, "val_loss": 19.438357651233673, "val_acc": 52.0}
{"epoch": 34, "training_loss": 59.592350482940674, "training_acc": 62.0, "val_loss": 21.00396454334259, "val_acc": 48.0}
{"epoch": 35, "training_loss": 72.2767186164856, "training_acc": 54.0, "val_loss": 24.985569715499878, "val_acc": 52.0}
{"epoch": 36, "training_loss": 71.90417838096619, "training_acc": 55.0, "val_loss": 27.924853563308716, "val_acc": 48.0}
{"epoch": 37, "training_loss": 85.47268605232239, "training_acc": 50.0, "val_loss": 27.441027760505676, "val_acc": 52.0}
{"epoch": 38, "training_loss": 88.71101307868958, "training_acc": 59.0, "val_loss": 23.588979244232178, "val_acc": 48.0}
{"epoch": 39, "training_loss": 71.51458716392517, "training_acc": 57.0, "val_loss": 22.025956213474274, "val_acc": 52.0}
