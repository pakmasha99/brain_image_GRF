"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.99764657020569, "training_acc": 46.0, "val_loss": 17.33050048351288, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.12395405769348, "training_acc": 53.0, "val_loss": 17.312373220920563, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.92098593711853, "training_acc": 47.0, "val_loss": 17.342983186244965, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.28800892829895, "training_acc": 49.0, "val_loss": 17.28939712047577, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25923204421997, "training_acc": 53.0, "val_loss": 17.464107275009155, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.8890483379364, "training_acc": 53.0, "val_loss": 17.423583567142487, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.7112329006195, "training_acc": 53.0, "val_loss": 17.275886237621307, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.08023834228516, "training_acc": 53.0, "val_loss": 17.263595759868622, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.04704356193542, "training_acc": 54.0, "val_loss": 17.263802886009216, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.81762528419495, "training_acc": 52.0, "val_loss": 17.27341115474701, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.59697651863098, "training_acc": 53.0, "val_loss": 17.31879413127899, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15354347229004, "training_acc": 53.0, "val_loss": 17.34887808561325, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18916440010071, "training_acc": 53.0, "val_loss": 17.2800213098526, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.69805455207825, "training_acc": 53.0, "val_loss": 17.243365943431854, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.81909537315369, "training_acc": 56.0, "val_loss": 17.273660004138947, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.90970659255981, "training_acc": 51.0, "val_loss": 17.280422151088715, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.60759854316711, "training_acc": 63.0, "val_loss": 17.237834632396698, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.7629063129425, "training_acc": 53.0, "val_loss": 17.24066287279129, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.77821803092957, "training_acc": 53.0, "val_loss": 17.277918756008148, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.65989804267883, "training_acc": 53.0, "val_loss": 17.388568818569183, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.62828755378723, "training_acc": 53.0, "val_loss": 17.353977262973785, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.44132351875305, "training_acc": 53.0, "val_loss": 17.24429279565811, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.419997215271, "training_acc": 54.0, "val_loss": 17.243774235248566, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.28474164009094, "training_acc": 64.0, "val_loss": 17.270082235336304, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.50831127166748, "training_acc": 59.0, "val_loss": 17.259903252124786, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.07645440101624, "training_acc": 61.0, "val_loss": 17.239558696746826, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.07208347320557, "training_acc": 58.0, "val_loss": 17.281527817249298, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.49818801879883, "training_acc": 54.0, "val_loss": 17.380517721176147, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.44242548942566, "training_acc": 54.0, "val_loss": 17.38315522670746, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.88684558868408, "training_acc": 52.0, "val_loss": 17.295345664024353, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.85854578018188, "training_acc": 52.0, "val_loss": 17.266732454299927, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.88068890571594, "training_acc": 56.0, "val_loss": 17.250680923461914, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.20861029624939, "training_acc": 53.0, "val_loss": 17.249616980552673, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.11382412910461, "training_acc": 59.0, "val_loss": 17.245016992092133, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.65956425666809, "training_acc": 56.0, "val_loss": 17.24001318216324, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.69941926002502, "training_acc": 54.0, "val_loss": 17.26299673318863, "val_acc": 52.0}
