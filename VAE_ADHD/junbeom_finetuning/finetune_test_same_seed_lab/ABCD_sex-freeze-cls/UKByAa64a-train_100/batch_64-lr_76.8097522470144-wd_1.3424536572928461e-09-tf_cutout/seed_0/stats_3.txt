"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 622142.6214904785, "training_acc": 51.0, "val_loss": 129177.197265625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 651239.1328125, "training_acc": 49.0, "val_loss": 279697.119140625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1045187.88671875, "training_acc": 47.0, "val_loss": 67695.2392578125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 397308.00390625, "training_acc": 45.0, "val_loss": 219784.6923828125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 877541.6875, "training_acc": 53.0, "val_loss": 185307.53173828125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 590681.39453125, "training_acc": 53.0, "val_loss": 48272.4609375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 282435.875, "training_acc": 47.0, "val_loss": 108648.5107421875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 358902.8525390625, "training_acc": 47.0, "val_loss": 52664.5263671875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 239201.9189453125, "training_acc": 53.0, "val_loss": 85252.86254882812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 276767.72314453125, "training_acc": 53.0, "val_loss": 45296.90856933594, "val_acc": 48.0}
{"epoch": 10, "training_loss": 214895.3212890625, "training_acc": 47.0, "val_loss": 39408.80432128906, "val_acc": 48.0}
{"epoch": 11, "training_loss": 189536.16455078125, "training_acc": 39.0, "val_loss": 54101.812744140625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 173871.759765625, "training_acc": 53.0, "val_loss": 37562.20703125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 185590.1259765625, "training_acc": 47.0, "val_loss": 20172.46856689453, "val_acc": 48.0}
{"epoch": 14, "training_loss": 115362.0068359375, "training_acc": 53.0, "val_loss": 82978.57666015625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 308045.53125, "training_acc": 53.0, "val_loss": 23766.68243408203, "val_acc": 52.0}
{"epoch": 16, "training_loss": 167514.423828125, "training_acc": 47.0, "val_loss": 95357.99560546875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 360107.5966796875, "training_acc": 47.0, "val_loss": 13737.069702148438, "val_acc": 48.0}
{"epoch": 18, "training_loss": 196522.154296875, "training_acc": 39.0, "val_loss": 124386.8896484375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 482075.37890625, "training_acc": 53.0, "val_loss": 84577.63061523438, "val_acc": 52.0}
{"epoch": 20, "training_loss": 229957.27514648438, "training_acc": 53.0, "val_loss": 93333.77685546875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 445596.650390625, "training_acc": 47.0, "val_loss": 147962.9638671875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 542862.24609375, "training_acc": 47.0, "val_loss": 26537.875366210938, "val_acc": 48.0}
{"epoch": 23, "training_loss": 168103.4140625, "training_acc": 53.0, "val_loss": 146914.697265625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 596214.2890625, "training_acc": 53.0, "val_loss": 149921.49658203125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 512644.5439453125, "training_acc": 53.0, "val_loss": 16206.912231445312, "val_acc": 52.0}
{"epoch": 26, "training_loss": 179307.55078125, "training_acc": 53.0, "val_loss": 166991.58935546875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 694823.197265625, "training_acc": 47.0, "val_loss": 147084.033203125, "val_acc": 48.0}
{"epoch": 28, "training_loss": 483774.439453125, "training_acc": 47.0, "val_loss": 32115.579223632812, "val_acc": 52.0}
{"epoch": 29, "training_loss": 210896.9970703125, "training_acc": 53.0, "val_loss": 104585.400390625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 372094.5888671875, "training_acc": 53.0, "val_loss": 21640.870666503906, "val_acc": 52.0}
{"epoch": 31, "training_loss": 189000.4365234375, "training_acc": 45.0, "val_loss": 116593.26171875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 461597.5078125, "training_acc": 47.0, "val_loss": 53518.597412109375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 173501.3916015625, "training_acc": 53.0, "val_loss": 76485.63842773438, "val_acc": 52.0}
{"epoch": 34, "training_loss": 297950.443359375, "training_acc": 53.0, "val_loss": 42879.443359375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 110772.84057617188, "training_acc": 61.0, "val_loss": 49478.314208984375, "val_acc": 48.0}
{"epoch": 36, "training_loss": 173392.94580078125, "training_acc": 47.0, "val_loss": 30797.982788085938, "val_acc": 52.0}
