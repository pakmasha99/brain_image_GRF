"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 752603.6128692627, "training_acc": 54.0, "val_loss": 150572.607421875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 747902.41015625, "training_acc": 41.0, "val_loss": 226821.0205078125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 841017.00390625, "training_acc": 47.0, "val_loss": 35708.9599609375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 365020.244140625, "training_acc": 41.0, "val_loss": 224770.703125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 882623.134765625, "training_acc": 53.0, "val_loss": 187085.51025390625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 613028.0048828125, "training_acc": 53.0, "val_loss": 22433.065795898438, "val_acc": 48.0}
{"epoch": 6, "training_loss": 175874.1806640625, "training_acc": 47.0, "val_loss": 74309.90600585938, "val_acc": 48.0}
{"epoch": 7, "training_loss": 225259.0096435547, "training_acc": 47.0, "val_loss": 82877.65502929688, "val_acc": 52.0}
{"epoch": 8, "training_loss": 375474.6796875, "training_acc": 53.0, "val_loss": 115395.80078125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 388204.2490234375, "training_acc": 53.0, "val_loss": 14808.676147460938, "val_acc": 48.0}
{"epoch": 10, "training_loss": 98274.2998046875, "training_acc": 47.0, "val_loss": 20099.99237060547, "val_acc": 48.0}
{"epoch": 11, "training_loss": 101251.26611328125, "training_acc": 53.0, "val_loss": 60302.130126953125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 205031.330078125, "training_acc": 53.0, "val_loss": 22924.74365234375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 102358.85009765625, "training_acc": 47.0, "val_loss": 8957.857513427734, "val_acc": 52.0}
{"epoch": 14, "training_loss": 29120.490295410156, "training_acc": 53.0, "val_loss": 43823.27880859375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 176195.1650390625, "training_acc": 47.0, "val_loss": 5170.196533203125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 22513.939697265625, "training_acc": 53.0, "val_loss": 31337.136840820312, "val_acc": 48.0}
{"epoch": 17, "training_loss": 114719.31884765625, "training_acc": 47.0, "val_loss": 31511.795043945312, "val_acc": 52.0}
{"epoch": 18, "training_loss": 137830.650390625, "training_acc": 53.0, "val_loss": 14179.661560058594, "val_acc": 52.0}
{"epoch": 19, "training_loss": 148984.9423828125, "training_acc": 41.0, "val_loss": 67720.6787109375, "val_acc": 48.0}
{"epoch": 20, "training_loss": 221292.4580078125, "training_acc": 47.0, "val_loss": 40807.17468261719, "val_acc": 52.0}
{"epoch": 21, "training_loss": 203288.474609375, "training_acc": 53.0, "val_loss": 69084.36279296875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 209698.99951171875, "training_acc": 53.0, "val_loss": 47707.87353515625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 249657.9091796875, "training_acc": 47.0, "val_loss": 58562.29248046875, "val_acc": 48.0}
{"epoch": 24, "training_loss": 166485.70684814453, "training_acc": 47.0, "val_loss": 21537.112426757812, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65773.40576171875, "training_acc": 45.0, "val_loss": 19779.226684570312, "val_acc": 52.0}
{"epoch": 26, "training_loss": 55945.71987915039, "training_acc": 53.0, "val_loss": 47817.85583496094, "val_acc": 48.0}
{"epoch": 27, "training_loss": 199789.861328125, "training_acc": 47.0, "val_loss": 7652.978515625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 94719.939453125, "training_acc": 55.0, "val_loss": 101991.97998046875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 397349.931640625, "training_acc": 53.0, "val_loss": 59276.62353515625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 178533.01196289062, "training_acc": 49.0, "val_loss": 43209.124755859375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 146836.71728515625, "training_acc": 47.0, "val_loss": 35927.398681640625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 164921.1708984375, "training_acc": 53.0, "val_loss": 33031.46667480469, "val_acc": 52.0}
{"epoch": 33, "training_loss": 135779.48486328125, "training_acc": 45.0, "val_loss": 32675.836181640625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 97672.40307617188, "training_acc": 47.0, "val_loss": 2069.2670822143555, "val_acc": 52.0}
{"epoch": 35, "training_loss": 64520.0419921875, "training_acc": 51.0, "val_loss": 36736.58752441406, "val_acc": 48.0}
{"epoch": 36, "training_loss": 105246.76745605469, "training_acc": 51.0, "val_loss": 14155.491638183594, "val_acc": 52.0}
{"epoch": 37, "training_loss": 57543.72314453125, "training_acc": 53.0, "val_loss": 5451.446151733398, "val_acc": 48.0}
{"epoch": 38, "training_loss": 90748.2373046875, "training_acc": 45.0, "val_loss": 55300.67138671875, "val_acc": 52.0}
{"epoch": 39, "training_loss": 173456.07373046875, "training_acc": 53.0, "val_loss": 39618.68591308594, "val_acc": 48.0}
{"epoch": 40, "training_loss": 194408.1435546875, "training_acc": 47.0, "val_loss": 30165.863037109375, "val_acc": 48.0}
{"epoch": 41, "training_loss": 138647.50244140625, "training_acc": 47.0, "val_loss": 60671.56982421875, "val_acc": 52.0}
{"epoch": 42, "training_loss": 213704.5791015625, "training_acc": 53.0, "val_loss": 7036.19384765625, "val_acc": 48.0}
{"epoch": 43, "training_loss": 36150.45690917969, "training_acc": 47.0, "val_loss": 24344.65789794922, "val_acc": 52.0}
{"epoch": 44, "training_loss": 90642.29541015625, "training_acc": 53.0, "val_loss": 20087.527465820312, "val_acc": 48.0}
{"epoch": 45, "training_loss": 78104.78051757812, "training_acc": 47.0, "val_loss": 29735.501098632812, "val_acc": 52.0}
{"epoch": 46, "training_loss": 125872.16650390625, "training_acc": 53.0, "val_loss": 4760.198211669922, "val_acc": 52.0}
{"epoch": 47, "training_loss": 106214.0107421875, "training_acc": 51.0, "val_loss": 84404.88891601562, "val_acc": 48.0}
{"epoch": 48, "training_loss": 304951.1171875, "training_acc": 47.0, "val_loss": 9450.193786621094, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69728.28515625, "training_acc": 53.0, "val_loss": 14159.071350097656, "val_acc": 52.0}
{"epoch": 50, "training_loss": 88383.39501953125, "training_acc": 53.0, "val_loss": 48063.201904296875, "val_acc": 48.0}
{"epoch": 51, "training_loss": 141589.96923828125, "training_acc": 47.0, "val_loss": 60872.7783203125, "val_acc": 52.0}
{"epoch": 52, "training_loss": 294938.296875, "training_acc": 53.0, "val_loss": 78523.67553710938, "val_acc": 52.0}
{"epoch": 53, "training_loss": 231354.13525390625, "training_acc": 53.0, "val_loss": 56548.84033203125, "val_acc": 48.0}
