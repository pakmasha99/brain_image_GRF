"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 275333.97160720825, "training_acc": 46.0, "val_loss": 57542.44384765625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 279418.771484375, "training_acc": 53.0, "val_loss": 149021.00830078125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 560841.787109375, "training_acc": 47.0, "val_loss": 41308.46252441406, "val_acc": 48.0}
{"epoch": 3, "training_loss": 195427.14306640625, "training_acc": 51.0, "val_loss": 108831.87255859375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 413483.53515625, "training_acc": 53.0, "val_loss": 97113.96484375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 288227.1171875, "training_acc": 53.0, "val_loss": 16873.458862304688, "val_acc": 48.0}
{"epoch": 6, "training_loss": 155520.4384765625, "training_acc": 47.0, "val_loss": 49741.12243652344, "val_acc": 48.0}
{"epoch": 7, "training_loss": 168602.14501953125, "training_acc": 47.0, "val_loss": 36042.27294921875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 140538.4453125, "training_acc": 53.0, "val_loss": 62495.660400390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 202932.888671875, "training_acc": 53.0, "val_loss": 7875.321960449219, "val_acc": 52.0}
{"epoch": 10, "training_loss": 81163.42236328125, "training_acc": 49.0, "val_loss": 58108.038330078125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 222640.74755859375, "training_acc": 47.0, "val_loss": 12326.235961914062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 80667.62939453125, "training_acc": 49.0, "val_loss": 61145.648193359375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 235087.5458984375, "training_acc": 53.0, "val_loss": 45838.70544433594, "val_acc": 52.0}
{"epoch": 14, "training_loss": 123055.20715332031, "training_acc": 52.0, "val_loss": 44951.763916015625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 219004.32421875, "training_acc": 47.0, "val_loss": 66858.64868164062, "val_acc": 48.0}
{"epoch": 16, "training_loss": 225571.68896484375, "training_acc": 47.0, "val_loss": 6088.198089599609, "val_acc": 60.0}
{"epoch": 17, "training_loss": 56305.330078125, "training_acc": 54.0, "val_loss": 38430.37109375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 123735.79113769531, "training_acc": 53.0, "val_loss": 7810.9832763671875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 38106.865234375, "training_acc": 54.0, "val_loss": 2882.7857971191406, "val_acc": 36.0}
{"epoch": 20, "training_loss": 39080.809326171875, "training_acc": 54.0, "val_loss": 17808.743286132812, "val_acc": 52.0}
{"epoch": 21, "training_loss": 37848.657653808594, "training_acc": 60.0, "val_loss": 11096.599578857422, "val_acc": 48.0}
{"epoch": 22, "training_loss": 31686.56021118164, "training_acc": 60.0, "val_loss": 15578.173828125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 35920.570068359375, "training_acc": 56.0, "val_loss": 12746.439361572266, "val_acc": 48.0}
{"epoch": 24, "training_loss": 48314.87927246094, "training_acc": 48.0, "val_loss": 12411.978149414062, "val_acc": 52.0}
{"epoch": 25, "training_loss": 45068.036865234375, "training_acc": 56.0, "val_loss": 5586.430358886719, "val_acc": 60.0}
{"epoch": 26, "training_loss": 48740.63427734375, "training_acc": 51.0, "val_loss": 17360.45684814453, "val_acc": 48.0}
{"epoch": 27, "training_loss": 54652.00323486328, "training_acc": 50.0, "val_loss": 12501.364135742188, "val_acc": 52.0}
{"epoch": 28, "training_loss": 27459.702087402344, "training_acc": 55.0, "val_loss": 9387.093353271484, "val_acc": 48.0}
{"epoch": 29, "training_loss": 26176.455169677734, "training_acc": 61.0, "val_loss": 20621.725463867188, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65025.43701171875, "training_acc": 52.0, "val_loss": 3012.784194946289, "val_acc": 40.0}
{"epoch": 31, "training_loss": 25675.141357421875, "training_acc": 57.0, "val_loss": 7562.384796142578, "val_acc": 56.0}
{"epoch": 32, "training_loss": 19179.146484375, "training_acc": 60.0, "val_loss": 5309.485244750977, "val_acc": 40.0}
{"epoch": 33, "training_loss": 23676.646118164062, "training_acc": 50.0, "val_loss": 9277.35595703125, "val_acc": 56.0}
{"epoch": 34, "training_loss": 16851.10479736328, "training_acc": 57.0, "val_loss": 11694.364166259766, "val_acc": 48.0}
{"epoch": 35, "training_loss": 40982.92102050781, "training_acc": 53.0, "val_loss": 19820.46661376953, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64800.020263671875, "training_acc": 53.0, "val_loss": 1943.790054321289, "val_acc": 52.0}
{"epoch": 37, "training_loss": 23331.715576171875, "training_acc": 56.0, "val_loss": 1894.114875793457, "val_acc": 52.0}
{"epoch": 38, "training_loss": 21515.378784179688, "training_acc": 64.0, "val_loss": 3168.966293334961, "val_acc": 64.0}
{"epoch": 39, "training_loss": 30573.994384765625, "training_acc": 60.0, "val_loss": 8738.414001464844, "val_acc": 48.0}
{"epoch": 40, "training_loss": 40104.262939453125, "training_acc": 54.0, "val_loss": 24218.83544921875, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65933.59191894531, "training_acc": 53.0, "val_loss": 25005.357360839844, "val_acc": 48.0}
{"epoch": 42, "training_loss": 109756.58251953125, "training_acc": 47.0, "val_loss": 14216.557312011719, "val_acc": 48.0}
{"epoch": 43, "training_loss": 83251.35693359375, "training_acc": 41.0, "val_loss": 39298.455810546875, "val_acc": 52.0}
{"epoch": 44, "training_loss": 134722.0302734375, "training_acc": 53.0, "val_loss": 3243.125534057617, "val_acc": 64.0}
{"epoch": 45, "training_loss": 65340.345703125, "training_acc": 56.0, "val_loss": 46052.81066894531, "val_acc": 48.0}
{"epoch": 46, "training_loss": 158686.58178710938, "training_acc": 47.0, "val_loss": 7486.859893798828, "val_acc": 52.0}
{"epoch": 47, "training_loss": 36571.79052734375, "training_acc": 55.0, "val_loss": 9359.308624267578, "val_acc": 52.0}
{"epoch": 48, "training_loss": 53900.881103515625, "training_acc": 42.0, "val_loss": 20602.862548828125, "val_acc": 48.0}
{"epoch": 49, "training_loss": 42410.270584106445, "training_acc": 58.0, "val_loss": 16890.475463867188, "val_acc": 52.0}
{"epoch": 50, "training_loss": 56369.51794433594, "training_acc": 53.0, "val_loss": 10857.683563232422, "val_acc": 48.0}
{"epoch": 51, "training_loss": 33335.65234375, "training_acc": 50.0, "val_loss": 9868.209075927734, "val_acc": 52.0}
{"epoch": 52, "training_loss": 33804.929443359375, "training_acc": 53.0, "val_loss": 9145.633697509766, "val_acc": 48.0}
{"epoch": 53, "training_loss": 29808.625366210938, "training_acc": 49.0, "val_loss": 16251.754760742188, "val_acc": 52.0}
{"epoch": 54, "training_loss": 60525.5595703125, "training_acc": 53.0, "val_loss": 3154.141044616699, "val_acc": 64.0}
{"epoch": 55, "training_loss": 25457.419921875, "training_acc": 60.0, "val_loss": 3648.3192443847656, "val_acc": 48.0}
{"epoch": 56, "training_loss": 24835.519653320312, "training_acc": 61.0, "val_loss": 21618.063354492188, "val_acc": 52.0}
