"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 300473.1495437622, "training_acc": 45.0, "val_loss": 71472.265625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 312893.546875, "training_acc": 49.0, "val_loss": 121434.89990234375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 441339.357421875, "training_acc": 47.0, "val_loss": 12200.724029541016, "val_acc": 48.0}
{"epoch": 3, "training_loss": 167467.837890625, "training_acc": 45.0, "val_loss": 134190.90576171875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 504990.462890625, "training_acc": 53.0, "val_loss": 121486.46240234375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 381889.51171875, "training_acc": 53.0, "val_loss": 10792.093658447266, "val_acc": 52.0}
{"epoch": 6, "training_loss": 114334.3310546875, "training_acc": 49.0, "val_loss": 114310.51025390625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 473072.642578125, "training_acc": 47.0, "val_loss": 100567.31567382812, "val_acc": 48.0}
{"epoch": 8, "training_loss": 340407.00390625, "training_acc": 47.0, "val_loss": 11588.919067382812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 76929.83740234375, "training_acc": 49.0, "val_loss": 75311.22436523438, "val_acc": 52.0}
{"epoch": 10, "training_loss": 261033.91796875, "training_acc": 53.0, "val_loss": 48909.84191894531, "val_acc": 52.0}
{"epoch": 11, "training_loss": 99514.33923339844, "training_acc": 56.0, "val_loss": 48895.67565917969, "val_acc": 48.0}
{"epoch": 12, "training_loss": 231904.0029296875, "training_acc": 47.0, "val_loss": 73136.63940429688, "val_acc": 48.0}
{"epoch": 13, "training_loss": 257886.3603515625, "training_acc": 47.0, "val_loss": 3810.3240966796875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 73214.87109375, "training_acc": 56.0, "val_loss": 84535.50415039062, "val_acc": 52.0}
{"epoch": 15, "training_loss": 318389.1123046875, "training_acc": 53.0, "val_loss": 80549.71923828125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 247766.55322265625, "training_acc": 53.0, "val_loss": 3950.788116455078, "val_acc": 48.0}
{"epoch": 17, "training_loss": 56232.64111328125, "training_acc": 65.0, "val_loss": 49364.46838378906, "val_acc": 48.0}
{"epoch": 18, "training_loss": 187352.7158203125, "training_acc": 47.0, "val_loss": 4025.5287170410156, "val_acc": 40.0}
{"epoch": 19, "training_loss": 55457.32421875, "training_acc": 54.0, "val_loss": 56247.528076171875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 194527.30712890625, "training_acc": 53.0, "val_loss": 28126.727294921875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70070.76489257812, "training_acc": 55.0, "val_loss": 30221.52099609375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 113227.50366210938, "training_acc": 47.0, "val_loss": 10245.726013183594, "val_acc": 52.0}
{"epoch": 23, "training_loss": 32667.9169921875, "training_acc": 59.0, "val_loss": 14459.117126464844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 53298.697509765625, "training_acc": 47.0, "val_loss": 15825.416564941406, "val_acc": 48.0}
{"epoch": 25, "training_loss": 49375.789489746094, "training_acc": 52.0, "val_loss": 15262.649536132812, "val_acc": 52.0}
{"epoch": 26, "training_loss": 30414.706115722656, "training_acc": 51.0, "val_loss": 10036.824035644531, "val_acc": 48.0}
{"epoch": 27, "training_loss": 36115.674865722656, "training_acc": 48.0, "val_loss": 8524.076843261719, "val_acc": 52.0}
{"epoch": 28, "training_loss": 25058.9814453125, "training_acc": 49.0, "val_loss": 7537.92724609375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 14434.022521972656, "training_acc": 60.0, "val_loss": 9722.097778320312, "val_acc": 48.0}
{"epoch": 30, "training_loss": 31001.05682373047, "training_acc": 47.0, "val_loss": 21938.66729736328, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68045.76220703125, "training_acc": 53.0, "val_loss": 4067.584991455078, "val_acc": 52.0}
{"epoch": 32, "training_loss": 34265.9658203125, "training_acc": 61.0, "val_loss": 19021.36688232422, "val_acc": 48.0}
