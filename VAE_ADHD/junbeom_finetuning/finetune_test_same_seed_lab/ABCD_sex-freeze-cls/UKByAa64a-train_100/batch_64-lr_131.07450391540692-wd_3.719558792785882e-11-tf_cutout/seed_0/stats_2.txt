"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 215479.82164001465, "training_acc": 55.0, "val_loss": 61739.117431640625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 364282.275390625, "training_acc": 41.0, "val_loss": 116861.4501953125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 407025.845703125, "training_acc": 47.0, "val_loss": 5952.732467651367, "val_acc": 56.0}
{"epoch": 3, "training_loss": 76735.29150390625, "training_acc": 51.0, "val_loss": 54637.347412109375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 166294.5244140625, "training_acc": 53.0, "val_loss": 21467.991638183594, "val_acc": 48.0}
{"epoch": 5, "training_loss": 123880.04931640625, "training_acc": 47.0, "val_loss": 19035.53466796875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 89813.5625, "training_acc": 47.0, "val_loss": 39264.91394042969, "val_acc": 52.0}
{"epoch": 7, "training_loss": 131627.64135742188, "training_acc": 53.0, "val_loss": 4037.6026153564453, "val_acc": 56.0}
{"epoch": 8, "training_loss": 39824.536865234375, "training_acc": 50.0, "val_loss": 5564.385223388672, "val_acc": 44.0}
{"epoch": 9, "training_loss": 44849.2060546875, "training_acc": 54.0, "val_loss": 29434.219360351562, "val_acc": 52.0}
{"epoch": 10, "training_loss": 87775.26037597656, "training_acc": 55.0, "val_loss": 19999.44610595703, "val_acc": 48.0}
{"epoch": 11, "training_loss": 81632.78344726562, "training_acc": 47.0, "val_loss": 4592.251968383789, "val_acc": 60.0}
{"epoch": 12, "training_loss": 41803.871337890625, "training_acc": 55.0, "val_loss": 31789.886474609375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 94031.14892578125, "training_acc": 53.0, "val_loss": 15330.38330078125, "val_acc": 48.0}
{"epoch": 14, "training_loss": 69697.48095703125, "training_acc": 49.0, "val_loss": 6470.143127441406, "val_acc": 40.0}
{"epoch": 15, "training_loss": 39066.7197265625, "training_acc": 56.0, "val_loss": 36411.84997558594, "val_acc": 52.0}
{"epoch": 16, "training_loss": 122581.24365234375, "training_acc": 53.0, "val_loss": 3606.055450439453, "val_acc": 56.0}
{"epoch": 17, "training_loss": 46711.4423828125, "training_acc": 55.0, "val_loss": 30083.270263671875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 88999.01306152344, "training_acc": 47.0, "val_loss": 28702.294921875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 130317.234375, "training_acc": 53.0, "val_loss": 36926.43127441406, "val_acc": 52.0}
{"epoch": 20, "training_loss": 100065.16857910156, "training_acc": 54.0, "val_loss": 32080.975341796875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 150242.67041015625, "training_acc": 47.0, "val_loss": 42019.52209472656, "val_acc": 48.0}
{"epoch": 22, "training_loss": 119100.45239257812, "training_acc": 49.0, "val_loss": 32823.71826171875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 156545.3134765625, "training_acc": 53.0, "val_loss": 55106.0791015625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 175194.79931640625, "training_acc": 53.0, "val_loss": 3618.845748901367, "val_acc": 52.0}
{"epoch": 25, "training_loss": 55596.0888671875, "training_acc": 55.0, "val_loss": 34135.284423828125, "val_acc": 48.0}
{"epoch": 26, "training_loss": 114476.41333007812, "training_acc": 47.0, "val_loss": 24405.848693847656, "val_acc": 52.0}
{"epoch": 27, "training_loss": 98456.45361328125, "training_acc": 53.0, "val_loss": 33248.71826171875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 80285.57373046875, "training_acc": 54.0, "val_loss": 29736.163330078125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 145746.2724609375, "training_acc": 47.0, "val_loss": 34300.60119628906, "val_acc": 48.0}
{"epoch": 30, "training_loss": 99806.07342529297, "training_acc": 52.0, "val_loss": 30316.995239257812, "val_acc": 52.0}
{"epoch": 31, "training_loss": 115203.65478515625, "training_acc": 53.0, "val_loss": 33943.99108886719, "val_acc": 52.0}
{"epoch": 32, "training_loss": 81312.4556274414, "training_acc": 56.0, "val_loss": 23990.10467529297, "val_acc": 48.0}
{"epoch": 33, "training_loss": 116768.12109375, "training_acc": 47.0, "val_loss": 15716.261291503906, "val_acc": 48.0}
{"epoch": 34, "training_loss": 81512.8203125, "training_acc": 42.0, "val_loss": 30981.277465820312, "val_acc": 52.0}
{"epoch": 35, "training_loss": 87588.59594726562, "training_acc": 53.0, "val_loss": 5544.614028930664, "val_acc": 60.0}
