"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.4415373802185, "training_acc": 45.0, "val_loss": 17.267344892024994, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.25211000442505, "training_acc": 53.0, "val_loss": 17.280565202236176, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2396125793457, "training_acc": 53.0, "val_loss": 17.272213101387024, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.25767540931702, "training_acc": 53.0, "val_loss": 17.277155816555023, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15352368354797, "training_acc": 53.0, "val_loss": 17.281383275985718, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15602087974548, "training_acc": 53.0, "val_loss": 17.27968156337738, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.34548878669739, "training_acc": 53.0, "val_loss": 17.26934015750885, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11730623245239, "training_acc": 53.0, "val_loss": 17.27127432823181, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21831560134888, "training_acc": 53.0, "val_loss": 17.274120450019836, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.25355076789856, "training_acc": 53.0, "val_loss": 17.284688353538513, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21548795700073, "training_acc": 53.0, "val_loss": 17.29893386363983, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24490451812744, "training_acc": 53.0, "val_loss": 17.311517894268036, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.39992070198059, "training_acc": 53.0, "val_loss": 17.302459478378296, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2705512046814, "training_acc": 53.0, "val_loss": 17.28990525007248, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27161860466003, "training_acc": 53.0, "val_loss": 17.271967232227325, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.23245573043823, "training_acc": 53.0, "val_loss": 17.26546287536621, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16239309310913, "training_acc": 53.0, "val_loss": 17.264007031917572, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19039988517761, "training_acc": 53.0, "val_loss": 17.263659834861755, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.45154118537903, "training_acc": 53.0, "val_loss": 17.263637483119965, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.31461143493652, "training_acc": 53.0, "val_loss": 17.265629768371582, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.22426629066467, "training_acc": 53.0, "val_loss": 17.26834625005722, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17199540138245, "training_acc": 53.0, "val_loss": 17.267534136772156, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13036942481995, "training_acc": 53.0, "val_loss": 17.26619303226471, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.05879712104797, "training_acc": 53.0, "val_loss": 17.266681790351868, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16659927368164, "training_acc": 53.0, "val_loss": 17.266453802585602, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13594388961792, "training_acc": 53.0, "val_loss": 17.267094552516937, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.26152968406677, "training_acc": 53.0, "val_loss": 17.26837158203125, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23396587371826, "training_acc": 53.0, "val_loss": 17.27285385131836, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17957806587219, "training_acc": 53.0, "val_loss": 17.275047302246094, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1791923046112, "training_acc": 53.0, "val_loss": 17.273685336112976, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10670590400696, "training_acc": 53.0, "val_loss": 17.27849394083023, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12646508216858, "training_acc": 53.0, "val_loss": 17.28236675262451, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.27099967002869, "training_acc": 53.0, "val_loss": 17.286907136440277, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.23847198486328, "training_acc": 53.0, "val_loss": 17.285552620887756, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.24679684638977, "training_acc": 53.0, "val_loss": 17.277267575263977, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.11396908760071, "training_acc": 53.0, "val_loss": 17.265920341014862, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13222622871399, "training_acc": 53.0, "val_loss": 17.26435124874115, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.05768156051636, "training_acc": 53.0, "val_loss": 17.26754605770111, "val_acc": 52.0}
