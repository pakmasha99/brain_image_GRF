"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 796.4814109802246, "training_acc": 44.0, "val_loss": 58.14931392669678, "val_acc": 48.0}
{"epoch": 1, "training_loss": 654.4348564147949, "training_acc": 49.0, "val_loss": 505.4755210876465, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1910.841796875, "training_acc": 53.0, "val_loss": 376.0880708694458, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1211.5796604156494, "training_acc": 53.0, "val_loss": 59.80871915817261, "val_acc": 48.0}
{"epoch": 4, "training_loss": 430.081636428833, "training_acc": 47.0, "val_loss": 191.38985872268677, "val_acc": 48.0}
{"epoch": 5, "training_loss": 678.8831310272217, "training_acc": 47.0, "val_loss": 35.91425120830536, "val_acc": 52.0}
{"epoch": 6, "training_loss": 235.38735580444336, "training_acc": 54.0, "val_loss": 105.62803745269775, "val_acc": 52.0}
{"epoch": 7, "training_loss": 326.91789197921753, "training_acc": 53.0, "val_loss": 69.07709836959839, "val_acc": 48.0}
{"epoch": 8, "training_loss": 325.7963743209839, "training_acc": 47.0, "val_loss": 55.84656596183777, "val_acc": 48.0}
{"epoch": 9, "training_loss": 164.34464025497437, "training_acc": 57.0, "val_loss": 80.87837100028992, "val_acc": 52.0}
{"epoch": 10, "training_loss": 292.9992036819458, "training_acc": 53.0, "val_loss": 18.11539977788925, "val_acc": 64.0}
{"epoch": 11, "training_loss": 113.03114557266235, "training_acc": 59.0, "val_loss": 49.1983026266098, "val_acc": 48.0}
{"epoch": 12, "training_loss": 166.567946434021, "training_acc": 46.0, "val_loss": 43.4368759393692, "val_acc": 52.0}
{"epoch": 13, "training_loss": 124.6096739768982, "training_acc": 54.0, "val_loss": 48.60410690307617, "val_acc": 48.0}
{"epoch": 14, "training_loss": 199.35284900665283, "training_acc": 48.0, "val_loss": 17.61057823896408, "val_acc": 56.0}
{"epoch": 15, "training_loss": 114.99365997314453, "training_acc": 54.0, "val_loss": 41.22866690158844, "val_acc": 52.0}
{"epoch": 16, "training_loss": 98.22684359550476, "training_acc": 62.0, "val_loss": 55.534934997558594, "val_acc": 48.0}
{"epoch": 17, "training_loss": 197.3582410812378, "training_acc": 47.0, "val_loss": 30.51486313343048, "val_acc": 52.0}
{"epoch": 18, "training_loss": 123.30979013442993, "training_acc": 53.0, "val_loss": 26.5862375497818, "val_acc": 52.0}
{"epoch": 19, "training_loss": 103.2659502029419, "training_acc": 54.0, "val_loss": 33.73958468437195, "val_acc": 48.0}
{"epoch": 20, "training_loss": 101.19323134422302, "training_acc": 59.0, "val_loss": 48.91630411148071, "val_acc": 52.0}
{"epoch": 21, "training_loss": 148.03910732269287, "training_acc": 53.0, "val_loss": 26.30508840084076, "val_acc": 48.0}
{"epoch": 22, "training_loss": 112.72212982177734, "training_acc": 47.0, "val_loss": 22.69929200410843, "val_acc": 52.0}
{"epoch": 23, "training_loss": 91.6416654586792, "training_acc": 60.0, "val_loss": 17.062097787857056, "val_acc": 64.0}
{"epoch": 24, "training_loss": 74.42516660690308, "training_acc": 55.0, "val_loss": 17.094607651233673, "val_acc": 52.0}
{"epoch": 25, "training_loss": 82.63649892807007, "training_acc": 66.0, "val_loss": 17.955277860164642, "val_acc": 64.0}
{"epoch": 26, "training_loss": 71.20422720909119, "training_acc": 56.0, "val_loss": 16.76698327064514, "val_acc": 60.0}
{"epoch": 27, "training_loss": 61.64450216293335, "training_acc": 66.0, "val_loss": 17.25938618183136, "val_acc": 52.0}
{"epoch": 28, "training_loss": 76.20339179039001, "training_acc": 57.0, "val_loss": 20.761258900165558, "val_acc": 52.0}
{"epoch": 29, "training_loss": 79.33892560005188, "training_acc": 56.0, "val_loss": 23.564036190509796, "val_acc": 44.0}
{"epoch": 30, "training_loss": 88.36447143554688, "training_acc": 49.0, "val_loss": 36.82167828083038, "val_acc": 52.0}
{"epoch": 31, "training_loss": 123.39905977249146, "training_acc": 53.0, "val_loss": 25.393769145011902, "val_acc": 48.0}
{"epoch": 32, "training_loss": 110.50492715835571, "training_acc": 47.0, "val_loss": 26.143676042556763, "val_acc": 52.0}
{"epoch": 33, "training_loss": 92.10900163650513, "training_acc": 55.0, "val_loss": 17.061753571033478, "val_acc": 72.0}
{"epoch": 34, "training_loss": 75.24114179611206, "training_acc": 66.0, "val_loss": 20.626144111156464, "val_acc": 52.0}
{"epoch": 35, "training_loss": 84.27730369567871, "training_acc": 55.0, "val_loss": 21.92441076040268, "val_acc": 48.0}
{"epoch": 36, "training_loss": 82.43317532539368, "training_acc": 50.0, "val_loss": 21.560144424438477, "val_acc": 52.0}
{"epoch": 37, "training_loss": 65.91971969604492, "training_acc": 62.0, "val_loss": 17.182302474975586, "val_acc": 68.0}
{"epoch": 38, "training_loss": 59.579068422317505, "training_acc": 69.0, "val_loss": 16.490107774734497, "val_acc": 52.0}
{"epoch": 39, "training_loss": 55.309975147247314, "training_acc": 72.0, "val_loss": 16.369378566741943, "val_acc": 56.0}
{"epoch": 40, "training_loss": 58.21430516242981, "training_acc": 66.0, "val_loss": 17.97667294740677, "val_acc": 68.0}
{"epoch": 41, "training_loss": 61.332945346832275, "training_acc": 63.0, "val_loss": 20.58723419904709, "val_acc": 52.0}
{"epoch": 42, "training_loss": 73.61290431022644, "training_acc": 56.0, "val_loss": 17.18202531337738, "val_acc": 52.0}
{"epoch": 43, "training_loss": 55.19444417953491, "training_acc": 75.0, "val_loss": 16.59165918827057, "val_acc": 52.0}
{"epoch": 44, "training_loss": 56.84020948410034, "training_acc": 73.0, "val_loss": 24.580931663513184, "val_acc": 48.0}
{"epoch": 45, "training_loss": 76.8128514289856, "training_acc": 59.0, "val_loss": 28.62035036087036, "val_acc": 52.0}
{"epoch": 46, "training_loss": 76.94766736030579, "training_acc": 65.0, "val_loss": 27.078968286514282, "val_acc": 48.0}
{"epoch": 47, "training_loss": 76.23186731338501, "training_acc": 62.0, "val_loss": 30.971255898475647, "val_acc": 52.0}
{"epoch": 48, "training_loss": 81.46344530582428, "training_acc": 66.0, "val_loss": 27.504703402519226, "val_acc": 48.0}
{"epoch": 49, "training_loss": 90.30159091949463, "training_acc": 54.0, "val_loss": 23.971731960773468, "val_acc": 52.0}
{"epoch": 50, "training_loss": 68.74325966835022, "training_acc": 59.0, "val_loss": 18.771259486675262, "val_acc": 56.0}
{"epoch": 51, "training_loss": 59.80371856689453, "training_acc": 62.0, "val_loss": 18.00890862941742, "val_acc": 52.0}
{"epoch": 52, "training_loss": 73.78924679756165, "training_acc": 56.0, "val_loss": 18.341179192066193, "val_acc": 52.0}
{"epoch": 53, "training_loss": 63.08181071281433, "training_acc": 62.0, "val_loss": 21.974654495716095, "val_acc": 44.0}
{"epoch": 54, "training_loss": 68.42764973640442, "training_acc": 62.0, "val_loss": 19.63689923286438, "val_acc": 52.0}
{"epoch": 55, "training_loss": 62.384552240371704, "training_acc": 65.0, "val_loss": 17.181594669818878, "val_acc": 52.0}
{"epoch": 56, "training_loss": 56.370649099349976, "training_acc": 68.0, "val_loss": 22.985683381557465, "val_acc": 48.0}
{"epoch": 57, "training_loss": 64.46427202224731, "training_acc": 62.0, "val_loss": 28.856760263442993, "val_acc": 52.0}
{"epoch": 58, "training_loss": 81.8015364408493, "training_acc": 65.0, "val_loss": 19.89925354719162, "val_acc": 48.0}
