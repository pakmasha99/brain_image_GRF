"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 75620.65142059326, "training_acc": 53.0, "val_loss": 3188.8784408569336, "val_acc": 56.0}
{"epoch": 1, "training_loss": 93087.5673828125, "training_acc": 57.0, "val_loss": 43754.76989746094, "val_acc": 48.0}
{"epoch": 2, "training_loss": 146183.42895507812, "training_acc": 47.0, "val_loss": 24788.113403320312, "val_acc": 52.0}
{"epoch": 3, "training_loss": 117246.9677734375, "training_acc": 51.0, "val_loss": 42371.31042480469, "val_acc": 52.0}
{"epoch": 4, "training_loss": 140391.09814453125, "training_acc": 53.0, "val_loss": 6127.494430541992, "val_acc": 56.0}
{"epoch": 5, "training_loss": 40413.08642578125, "training_acc": 57.0, "val_loss": 35692.388916015625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 153664.9072265625, "training_acc": 47.0, "val_loss": 22285.44158935547, "val_acc": 48.0}
{"epoch": 7, "training_loss": 64327.10430908203, "training_acc": 49.0, "val_loss": 20675.9033203125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 87465.22290039062, "training_acc": 53.0, "val_loss": 28416.9921875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 96395.04223632812, "training_acc": 53.0, "val_loss": 1623.3598709106445, "val_acc": 56.0}
{"epoch": 10, "training_loss": 27519.773193359375, "training_acc": 64.0, "val_loss": 31147.857666015625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 119258.119140625, "training_acc": 47.0, "val_loss": 18956.82373046875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 43775.7705078125, "training_acc": 57.0, "val_loss": 14680.8837890625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66371.64379882812, "training_acc": 53.0, "val_loss": 12991.506958007812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 33486.7409362793, "training_acc": 55.0, "val_loss": 8460.00747680664, "val_acc": 48.0}
{"epoch": 15, "training_loss": 26110.413146972656, "training_acc": 52.0, "val_loss": 2753.919792175293, "val_acc": 52.0}
{"epoch": 16, "training_loss": 11413.179763793945, "training_acc": 52.0, "val_loss": 1707.3650360107422, "val_acc": 52.0}
{"epoch": 17, "training_loss": 6426.930450439453, "training_acc": 57.0, "val_loss": 751.9333362579346, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2856.891128540039, "training_acc": 63.0, "val_loss": 2121.4881896972656, "val_acc": 60.0}
{"epoch": 19, "training_loss": 12119.750793457031, "training_acc": 43.0, "val_loss": 2411.8783950805664, "val_acc": 56.0}
{"epoch": 20, "training_loss": 7044.0612716674805, "training_acc": 56.0, "val_loss": 1160.715675354004, "val_acc": 56.0}
{"epoch": 21, "training_loss": 10497.744934082031, "training_acc": 51.0, "val_loss": 793.3732032775879, "val_acc": 64.0}
{"epoch": 22, "training_loss": 5281.550018310547, "training_acc": 60.0, "val_loss": 2382.781410217285, "val_acc": 52.0}
{"epoch": 23, "training_loss": 8215.117736816406, "training_acc": 53.0, "val_loss": 3152.786636352539, "val_acc": 52.0}
{"epoch": 24, "training_loss": 8497.070411682129, "training_acc": 55.0, "val_loss": 780.279016494751, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2692.5113525390625, "training_acc": 64.0, "val_loss": 3923.862838745117, "val_acc": 48.0}
{"epoch": 26, "training_loss": 10130.590431213379, "training_acc": 56.0, "val_loss": 904.0771484375, "val_acc": 56.0}
{"epoch": 27, "training_loss": 6521.920166015625, "training_acc": 57.0, "val_loss": 1687.4364852905273, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2875.781608581543, "training_acc": 68.0, "val_loss": 1293.695068359375, "val_acc": 48.0}
{"epoch": 29, "training_loss": 6834.0709228515625, "training_acc": 59.0, "val_loss": 831.9229125976562, "val_acc": 60.0}
{"epoch": 30, "training_loss": 5664.1280517578125, "training_acc": 64.0, "val_loss": 3805.648422241211, "val_acc": 48.0}
{"epoch": 31, "training_loss": 9756.552856445312, "training_acc": 53.0, "val_loss": 5284.8724365234375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 12726.371536254883, "training_acc": 53.0, "val_loss": 10536.769104003906, "val_acc": 48.0}
{"epoch": 33, "training_loss": 43792.0205078125, "training_acc": 47.0, "val_loss": 2308.597755432129, "val_acc": 44.0}
{"epoch": 34, "training_loss": 33465.874267578125, "training_acc": 41.0, "val_loss": 22872.760009765625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 80051.6005859375, "training_acc": 53.0, "val_loss": 9640.4052734375, "val_acc": 52.0}
{"epoch": 36, "training_loss": 36523.842529296875, "training_acc": 47.0, "val_loss": 15147.108459472656, "val_acc": 48.0}
