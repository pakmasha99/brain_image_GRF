"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 560182.3696899414, "training_acc": 43.0, "val_loss": 135990.58837890625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 480082.7265625, "training_acc": 55.0, "val_loss": 203838.12255859375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 737807.58203125, "training_acc": 47.0, "val_loss": 20991.67938232422, "val_acc": 48.0}
{"epoch": 3, "training_loss": 283315.375, "training_acc": 47.0, "val_loss": 231848.4375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 905084.6015625, "training_acc": 53.0, "val_loss": 202926.57470703125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 682225.82421875, "training_acc": 53.0, "val_loss": 9184.996032714844, "val_acc": 52.0}
{"epoch": 6, "training_loss": 240601.341796875, "training_acc": 49.0, "val_loss": 224993.0908203125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 929291.8828125, "training_acc": 47.0, "val_loss": 210667.7978515625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 724319.6015625, "training_acc": 47.0, "val_loss": 14905.520629882812, "val_acc": 48.0}
{"epoch": 9, "training_loss": 186117.599609375, "training_acc": 50.0, "val_loss": 197595.61767578125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 802232.478515625, "training_acc": 53.0, "val_loss": 227783.49609375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 822176.904296875, "training_acc": 53.0, "val_loss": 119508.89892578125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 350574.54736328125, "training_acc": 54.0, "val_loss": 109840.5029296875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 521933.65234375, "training_acc": 47.0, "val_loss": 202326.46484375, "val_acc": 48.0}
{"epoch": 14, "training_loss": 742629.71484375, "training_acc": 47.0, "val_loss": 119295.7763671875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 311894.1728515625, "training_acc": 47.0, "val_loss": 93651.25732421875, "val_acc": 52.0}
{"epoch": 16, "training_loss": 457794.728515625, "training_acc": 53.0, "val_loss": 192436.4501953125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 744017.09375, "training_acc": 53.0, "val_loss": 144073.76708984375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 450351.8564453125, "training_acc": 53.0, "val_loss": 28337.3291015625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 196640.322265625, "training_acc": 48.0, "val_loss": 99600.76293945312, "val_acc": 48.0}
{"epoch": 20, "training_loss": 328148.916015625, "training_acc": 47.0, "val_loss": 6106.520462036133, "val_acc": 44.0}
{"epoch": 21, "training_loss": 108316.533203125, "training_acc": 55.0, "val_loss": 90087.5732421875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 320419.8798828125, "training_acc": 53.0, "val_loss": 36033.35876464844, "val_acc": 52.0}
{"epoch": 23, "training_loss": 128121.822265625, "training_acc": 53.0, "val_loss": 67494.75708007812, "val_acc": 48.0}
{"epoch": 24, "training_loss": 256137.880859375, "training_acc": 47.0, "val_loss": 7124.262237548828, "val_acc": 56.0}
{"epoch": 25, "training_loss": 109409.28515625, "training_acc": 54.0, "val_loss": 90652.18505859375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 311532.9072265625, "training_acc": 53.0, "val_loss": 40742.46520996094, "val_acc": 52.0}
{"epoch": 27, "training_loss": 144689.0849609375, "training_acc": 50.0, "val_loss": 58371.97265625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 211122.41259765625, "training_acc": 47.0, "val_loss": 7329.18701171875, "val_acc": 60.0}
{"epoch": 29, "training_loss": 61625.5234375, "training_acc": 61.0, "val_loss": 38442.388916015625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 83026.94836425781, "training_acc": 59.0, "val_loss": 39460.05859375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 151072.0078125, "training_acc": 48.0, "val_loss": 5905.90705871582, "val_acc": 56.0}
{"epoch": 32, "training_loss": 48229.177001953125, "training_acc": 60.0, "val_loss": 24133.24432373047, "val_acc": 52.0}
{"epoch": 33, "training_loss": 61770.71728515625, "training_acc": 57.0, "val_loss": 15255.415344238281, "val_acc": 48.0}
{"epoch": 34, "training_loss": 53216.08459472656, "training_acc": 55.0, "val_loss": 24597.0947265625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 48608.58380126953, "training_acc": 61.0, "val_loss": 12168.86215209961, "val_acc": 44.0}
{"epoch": 36, "training_loss": 59297.42965698242, "training_acc": 58.0, "val_loss": 20506.405639648438, "val_acc": 52.0}
{"epoch": 37, "training_loss": 39667.22131347656, "training_acc": 59.0, "val_loss": 4657.625198364258, "val_acc": 52.0}
{"epoch": 38, "training_loss": 30121.408203125, "training_acc": 64.0, "val_loss": 8292.373657226562, "val_acc": 64.0}
{"epoch": 39, "training_loss": 18735.28204345703, "training_acc": 66.0, "val_loss": 6032.49397277832, "val_acc": 52.0}
{"epoch": 40, "training_loss": 35469.08850097656, "training_acc": 54.0, "val_loss": 14674.241638183594, "val_acc": 52.0}
{"epoch": 41, "training_loss": 34501.41760253906, "training_acc": 56.0, "val_loss": 7169.108581542969, "val_acc": 48.0}
{"epoch": 42, "training_loss": 29832.854736328125, "training_acc": 68.0, "val_loss": 26207.80029296875, "val_acc": 52.0}
{"epoch": 43, "training_loss": 65900.46520996094, "training_acc": 53.0, "val_loss": 11832.21435546875, "val_acc": 44.0}
{"epoch": 44, "training_loss": 32156.414794921875, "training_acc": 62.0, "val_loss": 16357.450866699219, "val_acc": 52.0}
{"epoch": 45, "training_loss": 59362.441650390625, "training_acc": 51.0, "val_loss": 14773.634338378906, "val_acc": 44.0}
{"epoch": 46, "training_loss": 48690.01794433594, "training_acc": 60.0, "val_loss": 28207.418823242188, "val_acc": 52.0}
{"epoch": 47, "training_loss": 52128.03332519531, "training_acc": 63.0, "val_loss": 16422.82257080078, "val_acc": 48.0}
{"epoch": 48, "training_loss": 51832.08184814453, "training_acc": 51.0, "val_loss": 8153.8482666015625, "val_acc": 64.0}
{"epoch": 49, "training_loss": 27589.489013671875, "training_acc": 59.0, "val_loss": 8876.199340820312, "val_acc": 64.0}
{"epoch": 50, "training_loss": 12358.608642578125, "training_acc": 71.0, "val_loss": 5580.162048339844, "val_acc": 48.0}
{"epoch": 51, "training_loss": 32380.681762695312, "training_acc": 56.0, "val_loss": 8856.304168701172, "val_acc": 60.0}
{"epoch": 52, "training_loss": 45889.130859375, "training_acc": 58.0, "val_loss": 14211.203002929688, "val_acc": 44.0}
{"epoch": 53, "training_loss": 69338.84301757812, "training_acc": 52.0, "val_loss": 47188.38195800781, "val_acc": 52.0}
{"epoch": 54, "training_loss": 118049.82958984375, "training_acc": 53.0, "val_loss": 46661.474609375, "val_acc": 48.0}
{"epoch": 55, "training_loss": 186382.1103515625, "training_acc": 47.0, "val_loss": 34617.041015625, "val_acc": 48.0}
{"epoch": 56, "training_loss": 117945.55712890625, "training_acc": 46.0, "val_loss": 52830.718994140625, "val_acc": 52.0}
