"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 201091.24895095825, "training_acc": 46.0, "val_loss": 42023.81591796875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 204062.53125, "training_acc": 53.0, "val_loss": 108831.65283203125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 409588.69140625, "training_acc": 47.0, "val_loss": 30168.035888671875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 142722.474609375, "training_acc": 51.0, "val_loss": 79481.01196289062, "val_acc": 52.0}
{"epoch": 4, "training_loss": 301971.3642578125, "training_acc": 53.0, "val_loss": 70923.30932617188, "val_acc": 52.0}
{"epoch": 5, "training_loss": 210495.2646484375, "training_acc": 53.0, "val_loss": 12322.893524169922, "val_acc": 48.0}
{"epoch": 6, "training_loss": 113578.244140625, "training_acc": 47.0, "val_loss": 36326.495361328125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 123131.88842773438, "training_acc": 47.0, "val_loss": 26322.012329101562, "val_acc": 52.0}
{"epoch": 8, "training_loss": 102636.69165039062, "training_acc": 53.0, "val_loss": 45641.204833984375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 148204.01489257812, "training_acc": 53.0, "val_loss": 5751.3916015625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 59274.458984375, "training_acc": 49.0, "val_loss": 42436.944580078125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 162596.884765625, "training_acc": 47.0, "val_loss": 9002.019500732422, "val_acc": 48.0}
{"epoch": 12, "training_loss": 58912.475341796875, "training_acc": 49.0, "val_loss": 44655.25817871094, "val_acc": 52.0}
{"epoch": 13, "training_loss": 171686.8681640625, "training_acc": 53.0, "val_loss": 33476.43737792969, "val_acc": 52.0}
{"epoch": 14, "training_loss": 89868.46667480469, "training_acc": 52.0, "val_loss": 32830.755615234375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 159951.8115234375, "training_acc": 47.0, "val_loss": 48833.056640625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 164760.94921875, "training_acc": 47.0, "val_loss": 4439.868545532227, "val_acc": 60.0}
{"epoch": 17, "training_loss": 41299.673583984375, "training_acc": 55.0, "val_loss": 28338.229370117188, "val_acc": 52.0}
{"epoch": 18, "training_loss": 91484.70629882812, "training_acc": 53.0, "val_loss": 5195.468521118164, "val_acc": 52.0}
{"epoch": 19, "training_loss": 25934.384399414062, "training_acc": 54.0, "val_loss": 2200.3429412841797, "val_acc": 48.0}
{"epoch": 20, "training_loss": 27267.376953125, "training_acc": 56.0, "val_loss": 11992.522430419922, "val_acc": 52.0}
{"epoch": 21, "training_loss": 27134.29119873047, "training_acc": 56.0, "val_loss": 7079.930877685547, "val_acc": 48.0}
{"epoch": 22, "training_loss": 22250.059173583984, "training_acc": 54.0, "val_loss": 10179.493713378906, "val_acc": 52.0}
{"epoch": 23, "training_loss": 20000.11978149414, "training_acc": 60.0, "val_loss": 11543.157958984375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 41109.65856933594, "training_acc": 48.0, "val_loss": 10496.974182128906, "val_acc": 52.0}
{"epoch": 25, "training_loss": 36482.45349121094, "training_acc": 56.0, "val_loss": 4451.995849609375, "val_acc": 56.0}
{"epoch": 26, "training_loss": 36426.544677734375, "training_acc": 51.0, "val_loss": 13338.545227050781, "val_acc": 48.0}
{"epoch": 27, "training_loss": 40174.226013183594, "training_acc": 51.0, "val_loss": 8908.448791503906, "val_acc": 56.0}
{"epoch": 28, "training_loss": 19238.332122802734, "training_acc": 56.0, "val_loss": 5473.195266723633, "val_acc": 48.0}
{"epoch": 29, "training_loss": 15694.60073852539, "training_acc": 60.0, "val_loss": 12502.124786376953, "val_acc": 52.0}
{"epoch": 30, "training_loss": 34371.81085205078, "training_acc": 51.0, "val_loss": 7560.265350341797, "val_acc": 48.0}
{"epoch": 31, "training_loss": 30690.2841796875, "training_acc": 48.0, "val_loss": 12626.995086669922, "val_acc": 52.0}
{"epoch": 32, "training_loss": 41723.41015625, "training_acc": 51.0, "val_loss": 5526.804733276367, "val_acc": 56.0}
{"epoch": 33, "training_loss": 21972.806762695312, "training_acc": 67.0, "val_loss": 10020.44448852539, "val_acc": 48.0}
{"epoch": 34, "training_loss": 48442.52575683594, "training_acc": 40.0, "val_loss": 10933.86001586914, "val_acc": 52.0}
{"epoch": 35, "training_loss": 23428.014556884766, "training_acc": 60.0, "val_loss": 3007.8569412231445, "val_acc": 40.0}
{"epoch": 36, "training_loss": 21177.180908203125, "training_acc": 54.0, "val_loss": 5101.047897338867, "val_acc": 56.0}
{"epoch": 37, "training_loss": 13810.063537597656, "training_acc": 56.0, "val_loss": 2680.5843353271484, "val_acc": 64.0}
{"epoch": 38, "training_loss": 9649.822937011719, "training_acc": 59.0, "val_loss": 5248.442077636719, "val_acc": 48.0}
