"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 219964.14115905762, "training_acc": 45.0, "val_loss": 50253.7109375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 208191.12109375, "training_acc": 53.0, "val_loss": 96591.0888671875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 352104.873046875, "training_acc": 47.0, "val_loss": 18491.400146484375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 132530.5546875, "training_acc": 45.0, "val_loss": 82246.38671875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 322407.3720703125, "training_acc": 53.0, "val_loss": 65215.93017578125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 199409.30395507812, "training_acc": 53.0, "val_loss": 27117.379760742188, "val_acc": 48.0}
{"epoch": 6, "training_loss": 145735.806640625, "training_acc": 47.0, "val_loss": 53404.693603515625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 178236.60791015625, "training_acc": 47.0, "val_loss": 3588.2827758789062, "val_acc": 52.0}
{"epoch": 8, "training_loss": 44493.042236328125, "training_acc": 53.0, "val_loss": 16788.705444335938, "val_acc": 52.0}
{"epoch": 9, "training_loss": 50879.700775146484, "training_acc": 55.0, "val_loss": 7331.145477294922, "val_acc": 48.0}
{"epoch": 10, "training_loss": 23492.160446166992, "training_acc": 54.0, "val_loss": 3014.9213790893555, "val_acc": 52.0}
{"epoch": 11, "training_loss": 16053.345886230469, "training_acc": 51.0, "val_loss": 1508.5257530212402, "val_acc": 32.0}
{"epoch": 12, "training_loss": 13664.436157226562, "training_acc": 59.0, "val_loss": 3649.4705200195312, "val_acc": 40.0}
{"epoch": 13, "training_loss": 16338.993774414062, "training_acc": 48.0, "val_loss": 12673.717498779297, "val_acc": 52.0}
{"epoch": 14, "training_loss": 25705.315368652344, "training_acc": 51.0, "val_loss": 4491.7724609375, "val_acc": 32.0}
{"epoch": 15, "training_loss": 13820.724212646484, "training_acc": 59.0, "val_loss": 5864.345550537109, "val_acc": 40.0}
{"epoch": 16, "training_loss": 10782.606353759766, "training_acc": 57.0, "val_loss": 2817.6454544067383, "val_acc": 44.0}
{"epoch": 17, "training_loss": 14605.90396118164, "training_acc": 49.0, "val_loss": 2879.245376586914, "val_acc": 52.0}
{"epoch": 18, "training_loss": 13150.346740722656, "training_acc": 55.0, "val_loss": 867.1360969543457, "val_acc": 44.0}
{"epoch": 19, "training_loss": 9346.15219116211, "training_acc": 54.0, "val_loss": 9150.67367553711, "val_acc": 52.0}
{"epoch": 20, "training_loss": 22016.998565673828, "training_acc": 56.0, "val_loss": 14681.144714355469, "val_acc": 48.0}
{"epoch": 21, "training_loss": 56670.6484375, "training_acc": 47.0, "val_loss": 9087.15591430664, "val_acc": 52.0}
{"epoch": 22, "training_loss": 32920.69689941406, "training_acc": 53.0, "val_loss": 862.5029563903809, "val_acc": 44.0}
{"epoch": 23, "training_loss": 9393.59765625, "training_acc": 56.0, "val_loss": 5901.30729675293, "val_acc": 52.0}
{"epoch": 24, "training_loss": 9857.287399291992, "training_acc": 57.0, "val_loss": 6820.291900634766, "val_acc": 52.0}
{"epoch": 25, "training_loss": 15519.648498535156, "training_acc": 52.0, "val_loss": 5937.109375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 10341.183837890625, "training_acc": 58.0, "val_loss": 7910.46142578125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 25144.78564453125, "training_acc": 52.0, "val_loss": 16278.939819335938, "val_acc": 52.0}
{"epoch": 28, "training_loss": 48562.56579589844, "training_acc": 53.0, "val_loss": 1194.776725769043, "val_acc": 52.0}
{"epoch": 29, "training_loss": 17252.947387695312, "training_acc": 57.0, "val_loss": 2386.575126647949, "val_acc": 52.0}
{"epoch": 30, "training_loss": 9328.938110351562, "training_acc": 64.0, "val_loss": 5803.478240966797, "val_acc": 48.0}
{"epoch": 31, "training_loss": 14870.834846496582, "training_acc": 53.0, "val_loss": 7755.735778808594, "val_acc": 52.0}
{"epoch": 32, "training_loss": 14596.873565673828, "training_acc": 63.0, "val_loss": 775.7674217224121, "val_acc": 68.0}
{"epoch": 33, "training_loss": 9721.212585449219, "training_acc": 67.0, "val_loss": 723.3846664428711, "val_acc": 56.0}
{"epoch": 34, "training_loss": 7314.553771972656, "training_acc": 68.0, "val_loss": 10848.859405517578, "val_acc": 52.0}
{"epoch": 35, "training_loss": 27657.42645263672, "training_acc": 54.0, "val_loss": 12567.697143554688, "val_acc": 48.0}
{"epoch": 36, "training_loss": 51450.5830078125, "training_acc": 47.0, "val_loss": 7824.739837646484, "val_acc": 52.0}
{"epoch": 37, "training_loss": 24856.710327148438, "training_acc": 53.0, "val_loss": 3139.017677307129, "val_acc": 48.0}
{"epoch": 38, "training_loss": 9310.218322753906, "training_acc": 56.0, "val_loss": 9316.780090332031, "val_acc": 52.0}
{"epoch": 39, "training_loss": 17222.103630065918, "training_acc": 62.0, "val_loss": 10876.602935791016, "val_acc": 48.0}
{"epoch": 40, "training_loss": 34713.70523071289, "training_acc": 54.0, "val_loss": 14280.499267578125, "val_acc": 52.0}
{"epoch": 41, "training_loss": 40424.416015625, "training_acc": 53.0, "val_loss": 5564.997100830078, "val_acc": 48.0}
{"epoch": 42, "training_loss": 21078.06072998047, "training_acc": 46.0, "val_loss": 16636.02294921875, "val_acc": 52.0}
{"epoch": 43, "training_loss": 59394.2607421875, "training_acc": 53.0, "val_loss": 5173.191452026367, "val_acc": 52.0}
{"epoch": 44, "training_loss": 26445.55419921875, "training_acc": 64.0, "val_loss": 21299.581909179688, "val_acc": 48.0}
{"epoch": 45, "training_loss": 65188.80725097656, "training_acc": 47.0, "val_loss": 25536.460876464844, "val_acc": 52.0}
{"epoch": 46, "training_loss": 99793.61181640625, "training_acc": 53.0, "val_loss": 33170.599365234375, "val_acc": 52.0}
{"epoch": 47, "training_loss": 94092.22131347656, "training_acc": 53.0, "val_loss": 21341.297912597656, "val_acc": 48.0}
{"epoch": 48, "training_loss": 92405.59838867188, "training_acc": 47.0, "val_loss": 23556.58721923828, "val_acc": 48.0}
{"epoch": 49, "training_loss": 60164.594665527344, "training_acc": 55.0, "val_loss": 27975.820922851562, "val_acc": 52.0}
{"epoch": 50, "training_loss": 116914.77587890625, "training_acc": 53.0, "val_loss": 33295.269775390625, "val_acc": 52.0}
{"epoch": 51, "training_loss": 82877.35668945312, "training_acc": 53.0, "val_loss": 25381.495666503906, "val_acc": 48.0}
{"epoch": 52, "training_loss": 122531.41357421875, "training_acc": 47.0, "val_loss": 35086.627197265625, "val_acc": 48.0}
