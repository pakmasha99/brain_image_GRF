"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 263513.4345321655, "training_acc": 53.0, "val_loss": 51813.28125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 264663.2314453125, "training_acc": 41.0, "val_loss": 85710.08911132812, "val_acc": 48.0}
{"epoch": 2, "training_loss": 312605.349609375, "training_acc": 47.0, "val_loss": 17876.976013183594, "val_acc": 48.0}
{"epoch": 3, "training_loss": 133932.4736328125, "training_acc": 41.0, "val_loss": 75157.60498046875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 288102.072265625, "training_acc": 53.0, "val_loss": 61602.227783203125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 190970.61669921875, "training_acc": 53.0, "val_loss": 13661.48681640625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 88644.060546875, "training_acc": 47.0, "val_loss": 32544.189453125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 105495.70715332031, "training_acc": 47.0, "val_loss": 23622.51739501953, "val_acc": 52.0}
{"epoch": 8, "training_loss": 106655.13916015625, "training_acc": 53.0, "val_loss": 35304.70886230469, "val_acc": 52.0}
{"epoch": 9, "training_loss": 110862.54614257812, "training_acc": 53.0, "val_loss": 11553.841400146484, "val_acc": 48.0}
{"epoch": 10, "training_loss": 58789.17919921875, "training_acc": 47.0, "val_loss": 13437.298583984375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 39509.853759765625, "training_acc": 54.0, "val_loss": 14454.510498046875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 44184.22003173828, "training_acc": 51.0, "val_loss": 14652.728271484375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 58247.483154296875, "training_acc": 47.0, "val_loss": 2015.3608322143555, "val_acc": 52.0}
{"epoch": 14, "training_loss": 28766.322021484375, "training_acc": 59.0, "val_loss": 12821.171569824219, "val_acc": 52.0}
{"epoch": 15, "training_loss": 33348.5908203125, "training_acc": 53.0, "val_loss": 6127.74772644043, "val_acc": 44.0}
{"epoch": 16, "training_loss": 23235.64630126953, "training_acc": 49.0, "val_loss": 3000.1020431518555, "val_acc": 60.0}
{"epoch": 17, "training_loss": 17663.40234375, "training_acc": 48.0, "val_loss": 3926.5533447265625, "val_acc": 60.0}
{"epoch": 18, "training_loss": 10297.374633789062, "training_acc": 61.0, "val_loss": 5656.162643432617, "val_acc": 48.0}
{"epoch": 19, "training_loss": 20444.0263671875, "training_acc": 53.0, "val_loss": 15822.128295898438, "val_acc": 52.0}
{"epoch": 20, "training_loss": 50804.44396972656, "training_acc": 53.0, "val_loss": 3867.197799682617, "val_acc": 60.0}
{"epoch": 21, "training_loss": 30717.814208984375, "training_acc": 46.0, "val_loss": 13739.900207519531, "val_acc": 48.0}
{"epoch": 22, "training_loss": 42553.98937988281, "training_acc": 47.0, "val_loss": 7828.80859375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 25106.206115722656, "training_acc": 46.0, "val_loss": 3058.7682723999023, "val_acc": 56.0}
{"epoch": 24, "training_loss": 6425.71760559082, "training_acc": 60.0, "val_loss": 5604.694366455078, "val_acc": 48.0}
{"epoch": 25, "training_loss": 16020.313461303711, "training_acc": 56.0, "val_loss": 2865.747833251953, "val_acc": 56.0}
{"epoch": 26, "training_loss": 8220.695709228516, "training_acc": 58.0, "val_loss": 6893.489837646484, "val_acc": 52.0}
{"epoch": 27, "training_loss": 12525.78197479248, "training_acc": 55.0, "val_loss": 7958.786773681641, "val_acc": 48.0}
{"epoch": 28, "training_loss": 23266.970825195312, "training_acc": 54.0, "val_loss": 14842.385864257812, "val_acc": 52.0}
{"epoch": 29, "training_loss": 50760.948486328125, "training_acc": 53.0, "val_loss": 1369.8759078979492, "val_acc": 52.0}
{"epoch": 30, "training_loss": 17811.499267578125, "training_acc": 59.0, "val_loss": 1705.09033203125, "val_acc": 56.0}
{"epoch": 31, "training_loss": 8841.92431640625, "training_acc": 72.0, "val_loss": 1619.6523666381836, "val_acc": 52.0}
{"epoch": 32, "training_loss": 8176.159973144531, "training_acc": 70.0, "val_loss": 4436.931610107422, "val_acc": 52.0}
{"epoch": 33, "training_loss": 10429.896514892578, "training_acc": 55.0, "val_loss": 3369.1707611083984, "val_acc": 52.0}
{"epoch": 34, "training_loss": 13152.338195800781, "training_acc": 56.0, "val_loss": 1531.1201095581055, "val_acc": 56.0}
{"epoch": 35, "training_loss": 6099.149719238281, "training_acc": 76.0, "val_loss": 5313.386535644531, "val_acc": 44.0}
{"epoch": 36, "training_loss": 12860.640182495117, "training_acc": 61.0, "val_loss": 2921.905517578125, "val_acc": 56.0}
{"epoch": 37, "training_loss": 15417.269409179688, "training_acc": 57.0, "val_loss": 3165.8126831054688, "val_acc": 44.0}
{"epoch": 38, "training_loss": 34424.692626953125, "training_acc": 48.0, "val_loss": 21298.57635498047, "val_acc": 52.0}
{"epoch": 39, "training_loss": 56370.25061035156, "training_acc": 53.0, "val_loss": 18831.117248535156, "val_acc": 48.0}
{"epoch": 40, "training_loss": 89554.28857421875, "training_acc": 47.0, "val_loss": 16417.09747314453, "val_acc": 48.0}
{"epoch": 41, "training_loss": 53757.238525390625, "training_acc": 47.0, "val_loss": 19715.109252929688, "val_acc": 52.0}
{"epoch": 42, "training_loss": 58883.678466796875, "training_acc": 53.0, "val_loss": 9402.375030517578, "val_acc": 48.0}
{"epoch": 43, "training_loss": 37755.430908203125, "training_acc": 47.0, "val_loss": 3622.049331665039, "val_acc": 52.0}
{"epoch": 44, "training_loss": 16108.31103515625, "training_acc": 58.0, "val_loss": 2701.4495849609375, "val_acc": 48.0}
{"epoch": 45, "training_loss": 8978.543334960938, "training_acc": 62.0, "val_loss": 12427.286529541016, "val_acc": 52.0}
{"epoch": 46, "training_loss": 38309.40075683594, "training_acc": 53.0, "val_loss": 2552.68497467041, "val_acc": 44.0}
{"epoch": 47, "training_loss": 11793.78091430664, "training_acc": 53.0, "val_loss": 13511.953735351562, "val_acc": 52.0}
{"epoch": 48, "training_loss": 35692.168212890625, "training_acc": 53.0, "val_loss": 1558.9386940002441, "val_acc": 48.0}
