"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 159.97662448883057, "training_acc": 46.0, "val_loss": 27.12930738925934, "val_acc": 52.0}
{"epoch": 1, "training_loss": 124.09048700332642, "training_acc": 53.0, "val_loss": 56.43202066421509, "val_acc": 48.0}
{"epoch": 2, "training_loss": 204.900972366333, "training_acc": 47.0, "val_loss": 17.63109564781189, "val_acc": 52.0}
{"epoch": 3, "training_loss": 89.63507890701294, "training_acc": 51.0, "val_loss": 47.39677309989929, "val_acc": 52.0}
{"epoch": 4, "training_loss": 174.40462684631348, "training_acc": 53.0, "val_loss": 32.45424926280975, "val_acc": 52.0}
{"epoch": 5, "training_loss": 100.03328680992126, "training_acc": 51.0, "val_loss": 24.15064126253128, "val_acc": 48.0}
{"epoch": 6, "training_loss": 122.54769659042358, "training_acc": 47.0, "val_loss": 32.33681321144104, "val_acc": 48.0}
{"epoch": 7, "training_loss": 114.59091186523438, "training_acc": 47.0, "val_loss": 18.15773695707321, "val_acc": 52.0}
{"epoch": 8, "training_loss": 73.72537064552307, "training_acc": 53.0, "val_loss": 32.1929007768631, "val_acc": 52.0}
{"epoch": 9, "training_loss": 119.43431949615479, "training_acc": 53.0, "val_loss": 22.38735854625702, "val_acc": 52.0}
{"epoch": 10, "training_loss": 81.27152585983276, "training_acc": 56.0, "val_loss": 21.191218495368958, "val_acc": 48.0}
{"epoch": 11, "training_loss": 86.71785020828247, "training_acc": 47.0, "val_loss": 22.426870465278625, "val_acc": 48.0}
{"epoch": 12, "training_loss": 83.15845227241516, "training_acc": 46.0, "val_loss": 17.818862199783325, "val_acc": 52.0}
{"epoch": 13, "training_loss": 78.03966641426086, "training_acc": 53.0, "val_loss": 21.772636473178864, "val_acc": 52.0}
{"epoch": 14, "training_loss": 80.52712559700012, "training_acc": 53.0, "val_loss": 17.23816841840744, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.48612880706787, "training_acc": 58.0, "val_loss": 19.093208014965057, "val_acc": 48.0}
{"epoch": 16, "training_loss": 73.37708401679993, "training_acc": 47.0, "val_loss": 17.35384166240692, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.79603290557861, "training_acc": 55.0, "val_loss": 19.53454166650772, "val_acc": 52.0}
{"epoch": 18, "training_loss": 73.91538429260254, "training_acc": 53.0, "val_loss": 17.478005588054657, "val_acc": 52.0}
{"epoch": 19, "training_loss": 65.62081265449524, "training_acc": 54.0, "val_loss": 17.257338762283325, "val_acc": 52.0}
{"epoch": 20, "training_loss": 66.52993130683899, "training_acc": 60.0, "val_loss": 17.308606207370758, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.34585928916931, "training_acc": 61.0, "val_loss": 17.35919862985611, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.1227536201477, "training_acc": 55.0, "val_loss": 17.85343885421753, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.10467720031738, "training_acc": 59.0, "val_loss": 17.526941001415253, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.16090416908264, "training_acc": 57.0, "val_loss": 17.428767681121826, "val_acc": 56.0}
{"epoch": 25, "training_loss": 65.82438802719116, "training_acc": 63.0, "val_loss": 17.47507005929947, "val_acc": 52.0}
{"epoch": 26, "training_loss": 65.94604587554932, "training_acc": 61.0, "val_loss": 17.94671267271042, "val_acc": 52.0}
{"epoch": 27, "training_loss": 66.1328239440918, "training_acc": 57.0, "val_loss": 17.53419041633606, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.19594120979309, "training_acc": 60.0, "val_loss": 17.583473026752472, "val_acc": 60.0}
{"epoch": 29, "training_loss": 68.87510395050049, "training_acc": 55.0, "val_loss": 17.44326949119568, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.22177982330322, "training_acc": 53.0, "val_loss": 19.07045543193817, "val_acc": 52.0}
{"epoch": 31, "training_loss": 68.70217800140381, "training_acc": 55.0, "val_loss": 17.349807918071747, "val_acc": 52.0}
{"epoch": 32, "training_loss": 65.32761001586914, "training_acc": 62.0, "val_loss": 17.585502564907074, "val_acc": 64.0}
{"epoch": 33, "training_loss": 67.33699464797974, "training_acc": 56.0, "val_loss": 17.24976748228073, "val_acc": 56.0}
