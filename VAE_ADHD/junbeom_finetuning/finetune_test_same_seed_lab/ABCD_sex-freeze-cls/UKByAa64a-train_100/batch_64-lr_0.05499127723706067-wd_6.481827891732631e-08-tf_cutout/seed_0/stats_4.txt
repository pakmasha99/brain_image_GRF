"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.5007426738739, "training_acc": 57.0, "val_loss": 46.80410921573639, "val_acc": 48.0}
{"epoch": 1, "training_loss": 146.5335283279419, "training_acc": 47.0, "val_loss": 36.23879253864288, "val_acc": 52.0}
{"epoch": 2, "training_loss": 138.24485063552856, "training_acc": 53.0, "val_loss": 20.88910937309265, "val_acc": 52.0}
{"epoch": 3, "training_loss": 85.61024498939514, "training_acc": 49.0, "val_loss": 29.168352484703064, "val_acc": 48.0}
{"epoch": 4, "training_loss": 106.33791279792786, "training_acc": 46.0, "val_loss": 17.463237047195435, "val_acc": 52.0}
{"epoch": 5, "training_loss": 68.64229655265808, "training_acc": 55.0, "val_loss": 23.919479548931122, "val_acc": 52.0}
{"epoch": 6, "training_loss": 87.4359278678894, "training_acc": 53.0, "val_loss": 17.62140393257141, "val_acc": 52.0}
{"epoch": 7, "training_loss": 78.09632802009583, "training_acc": 52.0, "val_loss": 23.64143133163452, "val_acc": 48.0}
{"epoch": 8, "training_loss": 88.18481469154358, "training_acc": 47.0, "val_loss": 18.026728928089142, "val_acc": 52.0}
{"epoch": 9, "training_loss": 75.04319357872009, "training_acc": 53.0, "val_loss": 19.58824098110199, "val_acc": 52.0}
{"epoch": 10, "training_loss": 74.80151557922363, "training_acc": 51.0, "val_loss": 18.288980424404144, "val_acc": 60.0}
{"epoch": 11, "training_loss": 69.27929759025574, "training_acc": 51.0, "val_loss": 17.626972496509552, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.20925498008728, "training_acc": 46.0, "val_loss": 18.309643864631653, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.16909885406494, "training_acc": 58.0, "val_loss": 17.34371781349182, "val_acc": 52.0}
{"epoch": 14, "training_loss": 65.3427345752716, "training_acc": 66.0, "val_loss": 17.34013259410858, "val_acc": 52.0}
{"epoch": 15, "training_loss": 66.61031794548035, "training_acc": 66.0, "val_loss": 17.393577098846436, "val_acc": 52.0}
{"epoch": 16, "training_loss": 66.25301456451416, "training_acc": 62.0, "val_loss": 17.515628039836884, "val_acc": 52.0}
{"epoch": 17, "training_loss": 66.22302746772766, "training_acc": 60.0, "val_loss": 17.355620861053467, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.30556845664978, "training_acc": 54.0, "val_loss": 17.274177074432373, "val_acc": 52.0}
{"epoch": 19, "training_loss": 63.039597034454346, "training_acc": 74.0, "val_loss": 17.310495674610138, "val_acc": 52.0}
{"epoch": 20, "training_loss": 63.382702350616455, "training_acc": 67.0, "val_loss": 17.20970720052719, "val_acc": 52.0}
{"epoch": 21, "training_loss": 66.47219157218933, "training_acc": 61.0, "val_loss": 17.178508639335632, "val_acc": 52.0}
{"epoch": 22, "training_loss": 64.6570885181427, "training_acc": 66.0, "val_loss": 17.26457327604294, "val_acc": 52.0}
{"epoch": 23, "training_loss": 64.97321343421936, "training_acc": 58.0, "val_loss": 17.161113023757935, "val_acc": 52.0}
{"epoch": 24, "training_loss": 64.93461894989014, "training_acc": 65.0, "val_loss": 17.160186171531677, "val_acc": 52.0}
{"epoch": 25, "training_loss": 67.154705286026, "training_acc": 64.0, "val_loss": 17.11803376674652, "val_acc": 52.0}
{"epoch": 26, "training_loss": 63.9033317565918, "training_acc": 64.0, "val_loss": 17.22579151391983, "val_acc": 52.0}
{"epoch": 27, "training_loss": 65.132159948349, "training_acc": 54.0, "val_loss": 17.109450697898865, "val_acc": 52.0}
{"epoch": 28, "training_loss": 65.17396020889282, "training_acc": 59.0, "val_loss": 17.144647240638733, "val_acc": 52.0}
{"epoch": 29, "training_loss": 62.24111366271973, "training_acc": 67.0, "val_loss": 17.21099764108658, "val_acc": 52.0}
{"epoch": 30, "training_loss": 65.574467420578, "training_acc": 56.0, "val_loss": 17.168372869491577, "val_acc": 52.0}
{"epoch": 31, "training_loss": 63.741973638534546, "training_acc": 64.0, "val_loss": 17.132362723350525, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.26467442512512, "training_acc": 68.0, "val_loss": 17.68440157175064, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.58503603935242, "training_acc": 50.0, "val_loss": 17.028504610061646, "val_acc": 56.0}
{"epoch": 34, "training_loss": 64.61548686027527, "training_acc": 67.0, "val_loss": 17.86096841096878, "val_acc": 60.0}
{"epoch": 35, "training_loss": 69.15047407150269, "training_acc": 52.0, "val_loss": 17.44322031736374, "val_acc": 52.0}
{"epoch": 36, "training_loss": 66.74382066726685, "training_acc": 62.0, "val_loss": 16.94902777671814, "val_acc": 52.0}
{"epoch": 37, "training_loss": 64.91251707077026, "training_acc": 62.0, "val_loss": 16.957946121692657, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.47791266441345, "training_acc": 61.0, "val_loss": 18.674273788928986, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.29299068450928, "training_acc": 57.0, "val_loss": 16.995935142040253, "val_acc": 52.0}
{"epoch": 40, "training_loss": 62.971789836883545, "training_acc": 67.0, "val_loss": 17.742036283016205, "val_acc": 64.0}
{"epoch": 41, "training_loss": 69.05712389945984, "training_acc": 57.0, "val_loss": 17.776495218276978, "val_acc": 52.0}
{"epoch": 42, "training_loss": 67.50681400299072, "training_acc": 54.0, "val_loss": 17.01643317937851, "val_acc": 52.0}
{"epoch": 43, "training_loss": 64.28236794471741, "training_acc": 68.0, "val_loss": 16.822858154773712, "val_acc": 52.0}
{"epoch": 44, "training_loss": 61.47616696357727, "training_acc": 65.0, "val_loss": 17.157815396785736, "val_acc": 52.0}
{"epoch": 45, "training_loss": 61.74763107299805, "training_acc": 71.0, "val_loss": 16.96344017982483, "val_acc": 52.0}
{"epoch": 46, "training_loss": 63.36155986785889, "training_acc": 64.0, "val_loss": 17.688661813735962, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.83115887641907, "training_acc": 58.0, "val_loss": 17.205792665481567, "val_acc": 52.0}
{"epoch": 48, "training_loss": 64.40740871429443, "training_acc": 61.0, "val_loss": 18.714086711406708, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.75882411003113, "training_acc": 55.0, "val_loss": 19.40222531557083, "val_acc": 52.0}
{"epoch": 50, "training_loss": 70.17745351791382, "training_acc": 54.0, "val_loss": 17.474646866321564, "val_acc": 52.0}
{"epoch": 51, "training_loss": 62.18886661529541, "training_acc": 62.0, "val_loss": 19.344840943813324, "val_acc": 44.0}
{"epoch": 52, "training_loss": 67.73395609855652, "training_acc": 57.0, "val_loss": 17.634007334709167, "val_acc": 52.0}
{"epoch": 53, "training_loss": 64.47068357467651, "training_acc": 62.0, "val_loss": 17.312242090702057, "val_acc": 52.0}
{"epoch": 54, "training_loss": 65.09471821784973, "training_acc": 57.0, "val_loss": 17.35079139471054, "val_acc": 64.0}
{"epoch": 55, "training_loss": 59.965590953826904, "training_acc": 67.0, "val_loss": 17.427200078964233, "val_acc": 52.0}
{"epoch": 56, "training_loss": 62.83088970184326, "training_acc": 61.0, "val_loss": 16.87852293252945, "val_acc": 56.0}
{"epoch": 57, "training_loss": 60.09018921852112, "training_acc": 69.0, "val_loss": 16.844016313552856, "val_acc": 56.0}
{"epoch": 58, "training_loss": 56.500258445739746, "training_acc": 77.0, "val_loss": 17.24812537431717, "val_acc": 52.0}
{"epoch": 59, "training_loss": 62.05944871902466, "training_acc": 66.0, "val_loss": 16.86347872018814, "val_acc": 56.0}
{"epoch": 60, "training_loss": 64.57401776313782, "training_acc": 66.0, "val_loss": 17.125453054904938, "val_acc": 52.0}
{"epoch": 61, "training_loss": 62.201582193374634, "training_acc": 64.0, "val_loss": 16.92933589220047, "val_acc": 56.0}
{"epoch": 62, "training_loss": 59.83348536491394, "training_acc": 72.0, "val_loss": 16.89387857913971, "val_acc": 56.0}
