"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 103206.44799041748, "training_acc": 49.0, "val_loss": 169257.421875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 653559.748046875, "training_acc": 53.0, "val_loss": 72093.64013671875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 249350.6240234375, "training_acc": 57.0, "val_loss": 121043.71337890625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 384151.78515625, "training_acc": 47.0, "val_loss": 31140.618896484375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 198492.0478515625, "training_acc": 53.0, "val_loss": 31686.834716796875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 106609.87036132812, "training_acc": 60.0, "val_loss": 68212.76245117188, "val_acc": 48.0}
{"epoch": 6, "training_loss": 193666.20361328125, "training_acc": 49.0, "val_loss": 26528.863525390625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 153688.2958984375, "training_acc": 54.0, "val_loss": 26212.68310546875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 64434.330078125, "training_acc": 63.0, "val_loss": 53048.870849609375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 151373.38623046875, "training_acc": 49.0, "val_loss": 18023.927307128906, "val_acc": 52.0}
{"epoch": 10, "training_loss": 90582.80834960938, "training_acc": 58.0, "val_loss": 8017.704772949219, "val_acc": 52.0}
{"epoch": 11, "training_loss": 61710.58056640625, "training_acc": 57.0, "val_loss": 28234.36279296875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 52690.38195800781, "training_acc": 60.0, "val_loss": 20029.550170898438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66411.00378417969, "training_acc": 51.0, "val_loss": 11805.252838134766, "val_acc": 44.0}
{"epoch": 14, "training_loss": 58374.884033203125, "training_acc": 59.0, "val_loss": 11682.392120361328, "val_acc": 60.0}
{"epoch": 15, "training_loss": 51116.519287109375, "training_acc": 57.0, "val_loss": 17702.38800048828, "val_acc": 44.0}
{"epoch": 16, "training_loss": 68835.27905273438, "training_acc": 51.0, "val_loss": 18961.077880859375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 46009.91906738281, "training_acc": 61.0, "val_loss": 19918.592834472656, "val_acc": 48.0}
{"epoch": 18, "training_loss": 86910.6943359375, "training_acc": 40.0, "val_loss": 13644.406127929688, "val_acc": 52.0}
{"epoch": 19, "training_loss": 55724.390380859375, "training_acc": 55.0, "val_loss": 16993.74237060547, "val_acc": 48.0}
{"epoch": 20, "training_loss": 56745.00439453125, "training_acc": 59.0, "val_loss": 34851.59606933594, "val_acc": 52.0}
{"epoch": 21, "training_loss": 90061.84008789062, "training_acc": 54.0, "val_loss": 51573.42529296875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 225222.099609375, "training_acc": 47.0, "val_loss": 36564.111328125, "val_acc": 48.0}
{"epoch": 23, "training_loss": 148953.365234375, "training_acc": 43.0, "val_loss": 58507.867431640625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 196608.04638671875, "training_acc": 53.0, "val_loss": 4572.279357910156, "val_acc": 56.0}
{"epoch": 25, "training_loss": 66576.18994140625, "training_acc": 62.0, "val_loss": 21826.034545898438, "val_acc": 48.0}
{"epoch": 26, "training_loss": 81749.75390625, "training_acc": 49.0, "val_loss": 41487.225341796875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 115151.6416015625, "training_acc": 53.0, "val_loss": 38718.475341796875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 165454.3984375, "training_acc": 47.0, "val_loss": 27613.858032226562, "val_acc": 48.0}
{"epoch": 29, "training_loss": 80265.83471679688, "training_acc": 57.0, "val_loss": 54000.897216796875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 183785.73828125, "training_acc": 53.0, "val_loss": 5095.0164794921875, "val_acc": 56.0}
{"epoch": 31, "training_loss": 63480.51806640625, "training_acc": 59.0, "val_loss": 31356.103515625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 114358.7890625, "training_acc": 42.0, "val_loss": 25062.19024658203, "val_acc": 52.0}
{"epoch": 33, "training_loss": 61706.87512207031, "training_acc": 57.0, "val_loss": 20057.923889160156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 48560.677307128906, "training_acc": 58.0, "val_loss": 28344.772338867188, "val_acc": 52.0}
{"epoch": 35, "training_loss": 86834.3291015625, "training_acc": 52.0, "val_loss": 7300.447082519531, "val_acc": 44.0}
{"epoch": 36, "training_loss": 33147.98205566406, "training_acc": 64.0, "val_loss": 6099.642562866211, "val_acc": 60.0}
{"epoch": 37, "training_loss": 24043.009155273438, "training_acc": 66.0, "val_loss": 6866.2139892578125, "val_acc": 52.0}
{"epoch": 38, "training_loss": 30310.817626953125, "training_acc": 59.0, "val_loss": 5351.3916015625, "val_acc": 56.0}
{"epoch": 39, "training_loss": 27701.112243652344, "training_acc": 56.0, "val_loss": 5928.318405151367, "val_acc": 64.0}
{"epoch": 40, "training_loss": 16736.49380493164, "training_acc": 68.0, "val_loss": 20441.19415283203, "val_acc": 48.0}
{"epoch": 41, "training_loss": 54676.27062988281, "training_acc": 57.0, "val_loss": 25527.716064453125, "val_acc": 52.0}
{"epoch": 42, "training_loss": 73801.51611328125, "training_acc": 55.0, "val_loss": 24418.875122070312, "val_acc": 48.0}
{"epoch": 43, "training_loss": 90609.75317382812, "training_acc": 47.0, "val_loss": 21926.312255859375, "val_acc": 52.0}
{"epoch": 44, "training_loss": 63060.96875, "training_acc": 53.0, "val_loss": 3928.35693359375, "val_acc": 52.0}
{"epoch": 45, "training_loss": 18818.48779296875, "training_acc": 62.0, "val_loss": 14519.195556640625, "val_acc": 52.0}
{"epoch": 46, "training_loss": 28671.686096191406, "training_acc": 60.0, "val_loss": 7723.150634765625, "val_acc": 48.0}
{"epoch": 47, "training_loss": 30889.214721679688, "training_acc": 59.0, "val_loss": 10110.997009277344, "val_acc": 52.0}
{"epoch": 48, "training_loss": 25211.837158203125, "training_acc": 66.0, "val_loss": 6050.441360473633, "val_acc": 48.0}
{"epoch": 49, "training_loss": 42845.884765625, "training_acc": 60.0, "val_loss": 36002.55432128906, "val_acc": 52.0}
{"epoch": 50, "training_loss": 79706.08294677734, "training_acc": 59.0, "val_loss": 29669.650268554688, "val_acc": 48.0}
{"epoch": 51, "training_loss": 110495.5908203125, "training_acc": 47.0, "val_loss": 27516.305541992188, "val_acc": 52.0}
{"epoch": 52, "training_loss": 91416.76904296875, "training_acc": 53.0, "val_loss": 5958.259201049805, "val_acc": 56.0}
{"epoch": 53, "training_loss": 65093.50390625, "training_acc": 57.0, "val_loss": 30130.55419921875, "val_acc": 48.0}
{"epoch": 54, "training_loss": 73349.68939208984, "training_acc": 58.0, "val_loss": 24775.439453125, "val_acc": 52.0}
{"epoch": 55, "training_loss": 54854.01333618164, "training_acc": 60.0, "val_loss": 17295.49560546875, "val_acc": 48.0}
{"epoch": 56, "training_loss": 58117.41467285156, "training_acc": 46.0, "val_loss": 3525.3929138183594, "val_acc": 64.0}
{"epoch": 57, "training_loss": 12670.325256347656, "training_acc": 72.0, "val_loss": 7815.859222412109, "val_acc": 56.0}
{"epoch": 58, "training_loss": 12039.451950073242, "training_acc": 74.0, "val_loss": 3452.146530151367, "val_acc": 56.0}
{"epoch": 59, "training_loss": 11119.42025756836, "training_acc": 75.0, "val_loss": 4458.145523071289, "val_acc": 64.0}
{"epoch": 60, "training_loss": 13836.16845703125, "training_acc": 66.0, "val_loss": 6046.64306640625, "val_acc": 56.0}
{"epoch": 61, "training_loss": 12918.859344482422, "training_acc": 67.0, "val_loss": 5778.993988037109, "val_acc": 60.0}
{"epoch": 62, "training_loss": 18426.09259033203, "training_acc": 61.0, "val_loss": 8631.739044189453, "val_acc": 56.0}
{"epoch": 63, "training_loss": 16055.992645263672, "training_acc": 63.0, "val_loss": 4657.633590698242, "val_acc": 60.0}
{"epoch": 64, "training_loss": 7187.030029296875, "training_acc": 74.0, "val_loss": 11740.771484375, "val_acc": 48.0}
{"epoch": 65, "training_loss": 27711.049072265625, "training_acc": 57.0, "val_loss": 6853.541564941406, "val_acc": 56.0}
{"epoch": 66, "training_loss": 29468.896484375, "training_acc": 66.0, "val_loss": 1970.235824584961, "val_acc": 64.0}
{"epoch": 67, "training_loss": 37587.509765625, "training_acc": 65.0, "val_loss": 4291.626739501953, "val_acc": 48.0}
{"epoch": 68, "training_loss": 22545.069580078125, "training_acc": 64.0, "val_loss": 25028.91387939453, "val_acc": 52.0}
{"epoch": 69, "training_loss": 75474.423828125, "training_acc": 53.0, "val_loss": 16445.753479003906, "val_acc": 48.0}
{"epoch": 70, "training_loss": 45166.356788635254, "training_acc": 57.0, "val_loss": 12681.591796875, "val_acc": 52.0}
{"epoch": 71, "training_loss": 18906.719146728516, "training_acc": 68.0, "val_loss": 16826.266479492188, "val_acc": 48.0}
{"epoch": 72, "training_loss": 29127.813636779785, "training_acc": 69.0, "val_loss": 18762.17498779297, "val_acc": 52.0}
{"epoch": 73, "training_loss": 48202.23712158203, "training_acc": 52.0, "val_loss": 6291.059112548828, "val_acc": 60.0}
{"epoch": 74, "training_loss": 8850.122833251953, "training_acc": 76.0, "val_loss": 13715.415954589844, "val_acc": 48.0}
{"epoch": 75, "training_loss": 32165.5107421875, "training_acc": 54.0, "val_loss": 2717.1737670898438, "val_acc": 60.0}
{"epoch": 76, "training_loss": 14593.952392578125, "training_acc": 72.0, "val_loss": 18954.249572753906, "val_acc": 52.0}
{"epoch": 77, "training_loss": 43834.01803588867, "training_acc": 61.0, "val_loss": 18804.710388183594, "val_acc": 48.0}
{"epoch": 78, "training_loss": 44355.202545166016, "training_acc": 55.0, "val_loss": 16075.743103027344, "val_acc": 52.0}
{"epoch": 79, "training_loss": 37072.23699951172, "training_acc": 59.0, "val_loss": 2677.034378051758, "val_acc": 60.0}
{"epoch": 80, "training_loss": 26938.2294921875, "training_acc": 64.0, "val_loss": 4009.115982055664, "val_acc": 48.0}
{"epoch": 81, "training_loss": 11537.32421875, "training_acc": 69.0, "val_loss": 18320.8251953125, "val_acc": 52.0}
{"epoch": 82, "training_loss": 35386.55140686035, "training_acc": 66.0, "val_loss": 12359.56039428711, "val_acc": 48.0}
{"epoch": 83, "training_loss": 41604.507080078125, "training_acc": 50.0, "val_loss": 7601.7852783203125, "val_acc": 56.0}
{"epoch": 84, "training_loss": 42992.827880859375, "training_acc": 61.0, "val_loss": 10623.841857910156, "val_acc": 44.0}
{"epoch": 85, "training_loss": 62099.46240234375, "training_acc": 56.0, "val_loss": 46840.97595214844, "val_acc": 52.0}
