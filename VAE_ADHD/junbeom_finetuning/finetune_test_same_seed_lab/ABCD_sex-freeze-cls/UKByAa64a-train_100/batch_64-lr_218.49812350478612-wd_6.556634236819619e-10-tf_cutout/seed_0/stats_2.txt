"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 413464.55473709106, "training_acc": 51.0, "val_loss": 97492.95043945312, "val_acc": 52.0}
{"epoch": 1, "training_loss": 500454.3515625, "training_acc": 51.0, "val_loss": 236023.4130859375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 851761.90625, "training_acc": 47.0, "val_loss": 39432.537841796875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 301385.16015625, "training_acc": 47.0, "val_loss": 215279.4189453125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 848937.23828125, "training_acc": 53.0, "val_loss": 197772.998046875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 663787.046875, "training_acc": 53.0, "val_loss": 12258.511352539062, "val_acc": 52.0}
{"epoch": 6, "training_loss": 202603.140625, "training_acc": 54.0, "val_loss": 214081.8603515625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 863224.119140625, "training_acc": 47.0, "val_loss": 206264.84375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 703769.62890625, "training_acc": 47.0, "val_loss": 32685.226440429688, "val_acc": 48.0}
{"epoch": 9, "training_loss": 173894.92578125, "training_acc": 53.0, "val_loss": 161792.96875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 683327.5625, "training_acc": 53.0, "val_loss": 183315.63720703125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 654611.982421875, "training_acc": 53.0, "val_loss": 67782.31201171875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 214264.85693359375, "training_acc": 51.0, "val_loss": 99252.13623046875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 378455.26953125, "training_acc": 47.0, "val_loss": 87228.3935546875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 223892.455078125, "training_acc": 47.0, "val_loss": 54093.463134765625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 271407.3583984375, "training_acc": 53.0, "val_loss": 89365.88745117188, "val_acc": 52.0}
{"epoch": 16, "training_loss": 297307.849609375, "training_acc": 53.0, "val_loss": 10677.220153808594, "val_acc": 56.0}
{"epoch": 17, "training_loss": 95883.89599609375, "training_acc": 48.0, "val_loss": 41750.90026855469, "val_acc": 48.0}
{"epoch": 18, "training_loss": 108548.58947753906, "training_acc": 48.0, "val_loss": 36833.905029296875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 133362.46142578125, "training_acc": 53.0, "val_loss": 4486.223602294922, "val_acc": 56.0}
{"epoch": 20, "training_loss": 43300.169189453125, "training_acc": 54.0, "val_loss": 7974.9053955078125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 89941.6240234375, "training_acc": 47.0, "val_loss": 43847.29309082031, "val_acc": 52.0}
{"epoch": 22, "training_loss": 108231.68518066406, "training_acc": 52.0, "val_loss": 42939.63928222656, "val_acc": 48.0}
{"epoch": 23, "training_loss": 206792.7177734375, "training_acc": 47.0, "val_loss": 35956.70166015625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 105314.79748535156, "training_acc": 55.0, "val_loss": 49977.07214355469, "val_acc": 52.0}
{"epoch": 25, "training_loss": 162092.99609375, "training_acc": 53.0, "val_loss": 11924.429321289062, "val_acc": 52.0}
{"epoch": 26, "training_loss": 56341.13232421875, "training_acc": 62.0, "val_loss": 46123.486328125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 164880.466796875, "training_acc": 47.0, "val_loss": 40442.73376464844, "val_acc": 52.0}
{"epoch": 28, "training_loss": 153374.66748046875, "training_acc": 53.0, "val_loss": 55880.7861328125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 130660.30053710938, "training_acc": 56.0, "val_loss": 43971.978759765625, "val_acc": 48.0}
{"epoch": 30, "training_loss": 217939.435546875, "training_acc": 47.0, "val_loss": 49980.975341796875, "val_acc": 48.0}
{"epoch": 31, "training_loss": 146458.62603759766, "training_acc": 52.0, "val_loss": 54310.247802734375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 187136.3759765625, "training_acc": 53.0, "val_loss": 53968.829345703125, "val_acc": 52.0}
{"epoch": 33, "training_loss": 128150.41198730469, "training_acc": 54.0, "val_loss": 44561.86218261719, "val_acc": 48.0}
{"epoch": 34, "training_loss": 203728.8427734375, "training_acc": 47.0, "val_loss": 30722.10693359375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 100437.67895507812, "training_acc": 57.0, "val_loss": 53751.6357421875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 171098.88916015625, "training_acc": 53.0, "val_loss": 7092.668914794922, "val_acc": 64.0}
{"epoch": 37, "training_loss": 50187.36865234375, "training_acc": 65.0, "val_loss": 31011.767578125, "val_acc": 48.0}
{"epoch": 38, "training_loss": 95375.95684814453, "training_acc": 50.0, "val_loss": 33290.31066894531, "val_acc": 52.0}
