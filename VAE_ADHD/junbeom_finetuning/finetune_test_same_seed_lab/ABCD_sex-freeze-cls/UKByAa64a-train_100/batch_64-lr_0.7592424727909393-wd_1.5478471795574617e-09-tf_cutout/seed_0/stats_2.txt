"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1034.6670188903809, "training_acc": 53.0, "val_loss": 37.17253804206848, "val_acc": 44.0}
{"epoch": 1, "training_loss": 1206.2809448242188, "training_acc": 53.0, "val_loss": 505.1888942718506, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1362.7315702438354, "training_acc": 44.0, "val_loss": 197.99758195877075, "val_acc": 52.0}
{"epoch": 3, "training_loss": 602.8760170936584, "training_acc": 53.0, "val_loss": 222.33493328094482, "val_acc": 48.0}
{"epoch": 4, "training_loss": 865.8602066040039, "training_acc": 47.0, "val_loss": 31.98016583919525, "val_acc": 60.0}
{"epoch": 5, "training_loss": 240.4141616821289, "training_acc": 55.0, "val_loss": 97.08293080329895, "val_acc": 52.0}
{"epoch": 6, "training_loss": 444.0846710205078, "training_acc": 47.0, "val_loss": 108.17805528640747, "val_acc": 48.0}
{"epoch": 7, "training_loss": 381.78699588775635, "training_acc": 51.0, "val_loss": 96.51408195495605, "val_acc": 52.0}
{"epoch": 8, "training_loss": 276.4421601295471, "training_acc": 49.0, "val_loss": 33.98188054561615, "val_acc": 60.0}
{"epoch": 9, "training_loss": 173.72470569610596, "training_acc": 56.0, "val_loss": 28.100988268852234, "val_acc": 60.0}
{"epoch": 10, "training_loss": 196.80299377441406, "training_acc": 56.0, "val_loss": 22.280307114124298, "val_acc": 56.0}
{"epoch": 11, "training_loss": 163.10440921783447, "training_acc": 61.0, "val_loss": 63.96138072013855, "val_acc": 52.0}
{"epoch": 12, "training_loss": 264.749719619751, "training_acc": 52.0, "val_loss": 71.20610475540161, "val_acc": 48.0}
{"epoch": 13, "training_loss": 236.40515184402466, "training_acc": 57.0, "val_loss": 100.20601749420166, "val_acc": 52.0}
{"epoch": 14, "training_loss": 267.0263686180115, "training_acc": 57.0, "val_loss": 89.96055126190186, "val_acc": 48.0}
{"epoch": 15, "training_loss": 259.0101227760315, "training_acc": 51.0, "val_loss": 115.92508554458618, "val_acc": 52.0}
{"epoch": 16, "training_loss": 398.1532144546509, "training_acc": 53.0, "val_loss": 23.33216220140457, "val_acc": 60.0}
{"epoch": 17, "training_loss": 137.04846477508545, "training_acc": 52.0, "val_loss": 38.64273726940155, "val_acc": 52.0}
{"epoch": 18, "training_loss": 121.64464569091797, "training_acc": 58.0, "val_loss": 68.44486594200134, "val_acc": 48.0}
{"epoch": 19, "training_loss": 227.30569553375244, "training_acc": 46.0, "val_loss": 118.3047890663147, "val_acc": 52.0}
{"epoch": 20, "training_loss": 393.87321376800537, "training_acc": 53.0, "val_loss": 18.565943837165833, "val_acc": 52.0}
{"epoch": 21, "training_loss": 160.5821475982666, "training_acc": 61.0, "val_loss": 20.14659494161606, "val_acc": 56.0}
{"epoch": 22, "training_loss": 189.31892585754395, "training_acc": 58.0, "val_loss": 99.19782876968384, "val_acc": 52.0}
{"epoch": 23, "training_loss": 268.0701289176941, "training_acc": 51.0, "val_loss": 36.590346693992615, "val_acc": 52.0}
{"epoch": 24, "training_loss": 215.25304889678955, "training_acc": 50.0, "val_loss": 60.661494731903076, "val_acc": 52.0}
{"epoch": 25, "training_loss": 263.90105152130127, "training_acc": 48.0, "val_loss": 54.74132299423218, "val_acc": 48.0}
{"epoch": 26, "training_loss": 280.5657548904419, "training_acc": 47.0, "val_loss": 119.47429180145264, "val_acc": 52.0}
{"epoch": 27, "training_loss": 276.7352294921875, "training_acc": 55.0, "val_loss": 102.98010110855103, "val_acc": 48.0}
{"epoch": 28, "training_loss": 372.83702754974365, "training_acc": 47.0, "val_loss": 88.58332633972168, "val_acc": 52.0}
{"epoch": 29, "training_loss": 349.1176223754883, "training_acc": 53.0, "val_loss": 27.92547345161438, "val_acc": 64.0}
{"epoch": 30, "training_loss": 225.57756996154785, "training_acc": 60.0, "val_loss": 101.68566703796387, "val_acc": 48.0}
{"epoch": 31, "training_loss": 311.1254811286926, "training_acc": 50.0, "val_loss": 66.47237539291382, "val_acc": 52.0}
{"epoch": 32, "training_loss": 145.5445272922516, "training_acc": 63.0, "val_loss": 64.54901099205017, "val_acc": 48.0}
{"epoch": 33, "training_loss": 177.3842270374298, "training_acc": 54.0, "val_loss": 50.16867518424988, "val_acc": 52.0}
{"epoch": 34, "training_loss": 166.64440965652466, "training_acc": 54.0, "val_loss": 23.280218243598938, "val_acc": 60.0}
{"epoch": 35, "training_loss": 91.02493095397949, "training_acc": 56.0, "val_loss": 22.031116485595703, "val_acc": 56.0}
{"epoch": 36, "training_loss": 70.93825101852417, "training_acc": 70.0, "val_loss": 35.09184122085571, "val_acc": 52.0}
{"epoch": 37, "training_loss": 75.81071305274963, "training_acc": 67.0, "val_loss": 58.562171459198, "val_acc": 48.0}
{"epoch": 38, "training_loss": 136.19870805740356, "training_acc": 60.0, "val_loss": 96.78269028663635, "val_acc": 52.0}
{"epoch": 39, "training_loss": 271.81524419784546, "training_acc": 53.0, "val_loss": 99.04237389564514, "val_acc": 48.0}
