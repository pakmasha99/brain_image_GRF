"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 551.2869300842285, "training_acc": 53.0, "val_loss": 320.9017038345337, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1268.116205215454, "training_acc": 46.0, "val_loss": 394.5497989654541, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1129.5641708374023, "training_acc": 57.0, "val_loss": 326.1478900909424, "val_acc": 52.0}
{"epoch": 3, "training_loss": 911.253231048584, "training_acc": 49.0, "val_loss": 134.04537439346313, "val_acc": 40.0}
{"epoch": 4, "training_loss": 661.064450263977, "training_acc": 52.0, "val_loss": 147.30782508850098, "val_acc": 48.0}
{"epoch": 5, "training_loss": 356.10384941101074, "training_acc": 51.0, "val_loss": 66.88157320022583, "val_acc": 48.0}
{"epoch": 6, "training_loss": 294.78153944015503, "training_acc": 52.0, "val_loss": 102.36423015594482, "val_acc": 52.0}
{"epoch": 7, "training_loss": 212.38070058822632, "training_acc": 58.0, "val_loss": 79.49126958847046, "val_acc": 48.0}
{"epoch": 8, "training_loss": 238.19246697425842, "training_acc": 56.0, "val_loss": 47.558557987213135, "val_acc": 52.0}
{"epoch": 9, "training_loss": 211.60978841781616, "training_acc": 54.0, "val_loss": 19.46985572576523, "val_acc": 64.0}
{"epoch": 10, "training_loss": 168.50944137573242, "training_acc": 53.0, "val_loss": 14.95116800069809, "val_acc": 68.0}
{"epoch": 11, "training_loss": 128.80795240402222, "training_acc": 58.0, "val_loss": 51.58456563949585, "val_acc": 52.0}
{"epoch": 12, "training_loss": 135.3494212627411, "training_acc": 59.0, "val_loss": 98.12028408050537, "val_acc": 48.0}
{"epoch": 13, "training_loss": 314.65870904922485, "training_acc": 49.0, "val_loss": 180.59111833572388, "val_acc": 52.0}
{"epoch": 14, "training_loss": 628.136962890625, "training_acc": 53.0, "val_loss": 102.85093784332275, "val_acc": 52.0}
{"epoch": 15, "training_loss": 322.0331630706787, "training_acc": 55.0, "val_loss": 179.93465662002563, "val_acc": 48.0}
{"epoch": 16, "training_loss": 665.6910514831543, "training_acc": 47.0, "val_loss": 210.5116844177246, "val_acc": 52.0}
{"epoch": 17, "training_loss": 681.9569129943848, "training_acc": 55.0, "val_loss": 259.66808795928955, "val_acc": 52.0}
{"epoch": 18, "training_loss": 606.0403089523315, "training_acc": 49.0, "val_loss": 119.5366382598877, "val_acc": 48.0}
{"epoch": 19, "training_loss": 621.9063377380371, "training_acc": 47.0, "val_loss": 50.89544653892517, "val_acc": 44.0}
{"epoch": 20, "training_loss": 293.2943344116211, "training_acc": 57.0, "val_loss": 147.14624881744385, "val_acc": 52.0}
{"epoch": 21, "training_loss": 319.2877035140991, "training_acc": 59.0, "val_loss": 62.505584955215454, "val_acc": 48.0}
{"epoch": 22, "training_loss": 195.14061999320984, "training_acc": 54.0, "val_loss": 101.5790581703186, "val_acc": 52.0}
{"epoch": 23, "training_loss": 258.76379776000977, "training_acc": 54.0, "val_loss": 109.91477966308594, "val_acc": 48.0}
{"epoch": 24, "training_loss": 435.6700744628906, "training_acc": 47.0, "val_loss": 36.56598627567291, "val_acc": 52.0}
{"epoch": 25, "training_loss": 167.10392093658447, "training_acc": 58.0, "val_loss": 17.170490324497223, "val_acc": 68.0}
{"epoch": 26, "training_loss": 202.03759956359863, "training_acc": 52.0, "val_loss": 15.115433931350708, "val_acc": 76.0}
{"epoch": 27, "training_loss": 152.69614505767822, "training_acc": 61.0, "val_loss": 16.75509214401245, "val_acc": 60.0}
{"epoch": 28, "training_loss": 165.209490776062, "training_acc": 58.0, "val_loss": 15.738588571548462, "val_acc": 64.0}
{"epoch": 29, "training_loss": 226.03232383728027, "training_acc": 55.0, "val_loss": 51.33494734764099, "val_acc": 52.0}
