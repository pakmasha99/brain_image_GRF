"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 400.60304260253906, "training_acc": 51.0, "val_loss": 83.1063449382782, "val_acc": 52.0}
{"epoch": 1, "training_loss": 431.8539066314697, "training_acc": 51.0, "val_loss": 205.43570518493652, "val_acc": 48.0}
{"epoch": 2, "training_loss": 741.7862892150879, "training_acc": 47.0, "val_loss": 36.59213185310364, "val_acc": 48.0}
{"epoch": 3, "training_loss": 260.25278663635254, "training_acc": 47.0, "val_loss": 176.87160968780518, "val_acc": 52.0}
{"epoch": 4, "training_loss": 691.5422420501709, "training_acc": 53.0, "val_loss": 152.38299369812012, "val_acc": 52.0}
{"epoch": 5, "training_loss": 495.44586753845215, "training_acc": 53.0, "val_loss": 23.955945670604706, "val_acc": 48.0}
{"epoch": 6, "training_loss": 167.33208751678467, "training_acc": 48.0, "val_loss": 100.98577737808228, "val_acc": 48.0}
{"epoch": 7, "training_loss": 349.0822420120239, "training_acc": 47.0, "val_loss": 19.30028647184372, "val_acc": 44.0}
{"epoch": 8, "training_loss": 122.83471488952637, "training_acc": 54.0, "val_loss": 67.2536551952362, "val_acc": 52.0}
{"epoch": 9, "training_loss": 235.63226318359375, "training_acc": 53.0, "val_loss": 19.615447521209717, "val_acc": 48.0}
{"epoch": 10, "training_loss": 107.30743980407715, "training_acc": 54.0, "val_loss": 55.66885471343994, "val_acc": 48.0}
{"epoch": 11, "training_loss": 167.02522706985474, "training_acc": 47.0, "val_loss": 28.415116667747498, "val_acc": 52.0}
{"epoch": 12, "training_loss": 141.72733545303345, "training_acc": 53.0, "val_loss": 33.48097205162048, "val_acc": 52.0}
{"epoch": 13, "training_loss": 110.3078224658966, "training_acc": 52.0, "val_loss": 38.32392692565918, "val_acc": 48.0}
{"epoch": 14, "training_loss": 138.692729473114, "training_acc": 47.0, "val_loss": 18.08193027973175, "val_acc": 56.0}
{"epoch": 15, "training_loss": 98.42796468734741, "training_acc": 48.0, "val_loss": 35.30099391937256, "val_acc": 52.0}
{"epoch": 16, "training_loss": 104.56848096847534, "training_acc": 56.0, "val_loss": 27.141809463500977, "val_acc": 48.0}
{"epoch": 17, "training_loss": 124.71513748168945, "training_acc": 47.0, "val_loss": 17.890413105487823, "val_acc": 52.0}
{"epoch": 18, "training_loss": 89.07994890213013, "training_acc": 54.0, "val_loss": 27.877452969551086, "val_acc": 52.0}
{"epoch": 19, "training_loss": 83.13347935676575, "training_acc": 59.0, "val_loss": 23.878011107444763, "val_acc": 48.0}
{"epoch": 20, "training_loss": 100.54266381263733, "training_acc": 47.0, "val_loss": 21.918797492980957, "val_acc": 52.0}
{"epoch": 21, "training_loss": 92.04212379455566, "training_acc": 54.0, "val_loss": 17.58587956428528, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.58390688896179, "training_acc": 65.0, "val_loss": 22.55670726299286, "val_acc": 48.0}
{"epoch": 23, "training_loss": 82.44382762908936, "training_acc": 53.0, "val_loss": 25.964602828025818, "val_acc": 52.0}
{"epoch": 24, "training_loss": 81.73149847984314, "training_acc": 55.0, "val_loss": 17.583701014518738, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65.82597851753235, "training_acc": 58.0, "val_loss": 17.05213189125061, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.16648077964783, "training_acc": 59.0, "val_loss": 17.25023090839386, "val_acc": 52.0}
{"epoch": 27, "training_loss": 75.83523511886597, "training_acc": 50.0, "val_loss": 17.015548050403595, "val_acc": 56.0}
{"epoch": 28, "training_loss": 63.09005665779114, "training_acc": 66.0, "val_loss": 21.435250341892242, "val_acc": 52.0}
{"epoch": 29, "training_loss": 63.10821533203125, "training_acc": 67.0, "val_loss": 21.13935351371765, "val_acc": 48.0}
{"epoch": 30, "training_loss": 80.41477155685425, "training_acc": 49.0, "val_loss": 20.17671912908554, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.92398428916931, "training_acc": 56.0, "val_loss": 16.85425192117691, "val_acc": 60.0}
{"epoch": 32, "training_loss": 79.94527626037598, "training_acc": 61.0, "val_loss": 18.505093455314636, "val_acc": 52.0}
{"epoch": 33, "training_loss": 73.19038510322571, "training_acc": 57.0, "val_loss": 20.29053568840027, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.13799524307251, "training_acc": 47.0, "val_loss": 18.985043466091156, "val_acc": 56.0}
{"epoch": 35, "training_loss": 66.7516827583313, "training_acc": 58.0, "val_loss": 29.73000705242157, "val_acc": 52.0}
{"epoch": 36, "training_loss": 93.48318719863892, "training_acc": 53.0, "val_loss": 17.75251030921936, "val_acc": 56.0}
{"epoch": 37, "training_loss": 64.04691290855408, "training_acc": 57.0, "val_loss": 17.600519955158234, "val_acc": 52.0}
{"epoch": 38, "training_loss": 62.732539653778076, "training_acc": 66.0, "val_loss": 17.021235823631287, "val_acc": 60.0}
{"epoch": 39, "training_loss": 62.691773891448975, "training_acc": 64.0, "val_loss": 17.621484398841858, "val_acc": 56.0}
{"epoch": 40, "training_loss": 62.56317186355591, "training_acc": 57.0, "val_loss": 17.355547845363617, "val_acc": 56.0}
{"epoch": 41, "training_loss": 61.45891833305359, "training_acc": 68.0, "val_loss": 17.516067624092102, "val_acc": 56.0}
{"epoch": 42, "training_loss": 57.729551553726196, "training_acc": 68.0, "val_loss": 17.79119223356247, "val_acc": 56.0}
{"epoch": 43, "training_loss": 58.15508580207825, "training_acc": 71.0, "val_loss": 18.009039759635925, "val_acc": 52.0}
{"epoch": 44, "training_loss": 59.3602659702301, "training_acc": 70.0, "val_loss": 19.010159373283386, "val_acc": 52.0}
{"epoch": 45, "training_loss": 62.16000747680664, "training_acc": 60.0, "val_loss": 19.24290806055069, "val_acc": 56.0}
{"epoch": 46, "training_loss": 60.063862562179565, "training_acc": 65.0, "val_loss": 18.668708205223083, "val_acc": 52.0}
{"epoch": 47, "training_loss": 60.690372705459595, "training_acc": 71.0, "val_loss": 17.84527152776718, "val_acc": 56.0}
{"epoch": 48, "training_loss": 56.97019124031067, "training_acc": 75.0, "val_loss": 17.770278453826904, "val_acc": 60.0}
{"epoch": 49, "training_loss": 55.198519468307495, "training_acc": 81.0, "val_loss": 18.06306540966034, "val_acc": 52.0}
{"epoch": 50, "training_loss": 59.968364238739014, "training_acc": 68.0, "val_loss": 17.896535992622375, "val_acc": 60.0}
