"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1325725.7228012085, "training_acc": 45.0, "val_loss": 206841.2353515625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1273174.140625, "training_acc": 45.0, "val_loss": 654462.59765625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 2504285.734375, "training_acc": 53.0, "val_loss": 461125.48828125, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1312803.90234375, "training_acc": 53.0, "val_loss": 212380.37109375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1062384.59375, "training_acc": 47.0, "val_loss": 420331.884765625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1596980.30078125, "training_acc": 47.0, "val_loss": 116005.419921875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 540660.4609375, "training_acc": 47.0, "val_loss": 279825.3173828125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1055990.744140625, "training_acc": 53.0, "val_loss": 228203.271484375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 638637.8828125, "training_acc": 53.0, "val_loss": 125987.5244140625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 719375.0625, "training_acc": 47.0, "val_loss": 221317.0654296875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 751784.21875, "training_acc": 47.0, "val_loss": 82536.38305664062, "val_acc": 52.0}
{"epoch": 11, "training_loss": 395029.837890625, "training_acc": 53.0, "val_loss": 148433.056640625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 443846.78125, "training_acc": 53.0, "val_loss": 92273.35205078125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 450690.630859375, "training_acc": 47.0, "val_loss": 95332.46459960938, "val_acc": 48.0}
{"epoch": 14, "training_loss": 336696.60498046875, "training_acc": 42.0, "val_loss": 76593.359375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 214786.892578125, "training_acc": 56.0, "val_loss": 76811.0595703125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 288121.189453125, "training_acc": 47.0, "val_loss": 20461.82403564453, "val_acc": 56.0}
{"epoch": 17, "training_loss": 181094.9814453125, "training_acc": 57.0, "val_loss": 119563.17138671875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 367493.783203125, "training_acc": 55.0, "val_loss": 48343.78356933594, "val_acc": 44.0}
{"epoch": 19, "training_loss": 205557.2021484375, "training_acc": 48.0, "val_loss": 36722.61962890625, "val_acc": 44.0}
{"epoch": 20, "training_loss": 153251.4306640625, "training_acc": 58.0, "val_loss": 64658.43505859375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 213233.328125, "training_acc": 52.0, "val_loss": 39179.65393066406, "val_acc": 48.0}
{"epoch": 22, "training_loss": 128589.3525390625, "training_acc": 52.0, "val_loss": 57478.753662109375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 202511.21484375, "training_acc": 53.0, "val_loss": 33424.86572265625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 129691.10400390625, "training_acc": 52.0, "val_loss": 25926.303100585938, "val_acc": 48.0}
{"epoch": 25, "training_loss": 109247.98681640625, "training_acc": 57.0, "val_loss": 17538.674926757812, "val_acc": 56.0}
{"epoch": 26, "training_loss": 148337.5771484375, "training_acc": 51.0, "val_loss": 17253.28826904297, "val_acc": 64.0}
{"epoch": 27, "training_loss": 134394.1845703125, "training_acc": 58.0, "val_loss": 41937.21008300781, "val_acc": 52.0}
{"epoch": 28, "training_loss": 152592.77587890625, "training_acc": 56.0, "val_loss": 49976.52282714844, "val_acc": 48.0}
{"epoch": 29, "training_loss": 193483.2421875, "training_acc": 48.0, "val_loss": 45022.979736328125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 132080.08032226562, "training_acc": 50.0, "val_loss": 11404.862976074219, "val_acc": 52.0}
{"epoch": 31, "training_loss": 46851.551025390625, "training_acc": 65.0, "val_loss": 11401.300811767578, "val_acc": 60.0}
{"epoch": 32, "training_loss": 71107.13525390625, "training_acc": 57.0, "val_loss": 14692.864990234375, "val_acc": 56.0}
{"epoch": 33, "training_loss": 43365.90185546875, "training_acc": 62.0, "val_loss": 36807.55920410156, "val_acc": 48.0}
{"epoch": 34, "training_loss": 94797.87854003906, "training_acc": 57.0, "val_loss": 22691.986083984375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 53365.249267578125, "training_acc": 61.0, "val_loss": 6947.691345214844, "val_acc": 44.0}
{"epoch": 36, "training_loss": 48613.361083984375, "training_acc": 64.0, "val_loss": 6629.328918457031, "val_acc": 68.0}
{"epoch": 37, "training_loss": 61895.447265625, "training_acc": 60.0, "val_loss": 8238.707733154297, "val_acc": 60.0}
{"epoch": 38, "training_loss": 27589.414428710938, "training_acc": 67.0, "val_loss": 43305.413818359375, "val_acc": 48.0}
{"epoch": 39, "training_loss": 97003.03814697266, "training_acc": 58.0, "val_loss": 50586.48986816406, "val_acc": 52.0}
{"epoch": 40, "training_loss": 131934.7198486328, "training_acc": 57.0, "val_loss": 74428.39965820312, "val_acc": 48.0}
{"epoch": 41, "training_loss": 258450.7060546875, "training_acc": 47.0, "val_loss": 50487.786865234375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 200615.9560546875, "training_acc": 53.0, "val_loss": 11454.330444335938, "val_acc": 56.0}
{"epoch": 43, "training_loss": 115594.1767578125, "training_acc": 64.0, "val_loss": 107167.24853515625, "val_acc": 48.0}
{"epoch": 44, "training_loss": 307283.9748535156, "training_acc": 51.0, "val_loss": 119697.83935546875, "val_acc": 52.0}
{"epoch": 45, "training_loss": 495284.41796875, "training_acc": 53.0, "val_loss": 110981.48193359375, "val_acc": 52.0}
{"epoch": 46, "training_loss": 290917.6462402344, "training_acc": 55.0, "val_loss": 84655.36499023438, "val_acc": 48.0}
{"epoch": 47, "training_loss": 244816.69091796875, "training_acc": 48.0, "val_loss": 72344.1650390625, "val_acc": 52.0}
{"epoch": 48, "training_loss": 273773.23046875, "training_acc": 53.0, "val_loss": 28611.550903320312, "val_acc": 52.0}
{"epoch": 49, "training_loss": 241743.185546875, "training_acc": 47.0, "val_loss": 132873.54736328125, "val_acc": 48.0}
{"epoch": 50, "training_loss": 369548.19384765625, "training_acc": 48.0, "val_loss": 92650.12817382812, "val_acc": 52.0}
{"epoch": 51, "training_loss": 406955.44140625, "training_acc": 53.0, "val_loss": 109453.80859375, "val_acc": 52.0}
{"epoch": 52, "training_loss": 296184.04260253906, "training_acc": 57.0, "val_loss": 103549.27978515625, "val_acc": 48.0}
{"epoch": 53, "training_loss": 312959.6279296875, "training_acc": 48.0, "val_loss": 12166.487884521484, "val_acc": 48.0}
{"epoch": 54, "training_loss": 214508.7734375, "training_acc": 59.0, "val_loss": 72030.5908203125, "val_acc": 52.0}
{"epoch": 55, "training_loss": 251806.12255859375, "training_acc": 46.0, "val_loss": 48010.577392578125, "val_acc": 48.0}
