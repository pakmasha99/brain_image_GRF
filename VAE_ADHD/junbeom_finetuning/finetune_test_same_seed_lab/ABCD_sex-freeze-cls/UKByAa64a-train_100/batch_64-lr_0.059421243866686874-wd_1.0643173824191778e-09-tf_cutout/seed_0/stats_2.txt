"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 172.19432163238525, "training_acc": 47.0, "val_loss": 30.51796853542328, "val_acc": 52.0}
{"epoch": 1, "training_loss": 147.25376892089844, "training_acc": 49.0, "val_loss": 58.245670795440674, "val_acc": 48.0}
{"epoch": 2, "training_loss": 208.068781375885, "training_acc": 47.0, "val_loss": 17.605291306972504, "val_acc": 52.0}
{"epoch": 3, "training_loss": 95.6991195678711, "training_acc": 44.0, "val_loss": 41.58584475517273, "val_acc": 52.0}
{"epoch": 4, "training_loss": 152.40976762771606, "training_acc": 53.0, "val_loss": 21.88439965248108, "val_acc": 52.0}
{"epoch": 5, "training_loss": 87.30395531654358, "training_acc": 47.0, "val_loss": 28.843730688095093, "val_acc": 48.0}
{"epoch": 6, "training_loss": 116.98472452163696, "training_acc": 47.0, "val_loss": 21.174652874469757, "val_acc": 48.0}
{"epoch": 7, "training_loss": 80.87429165840149, "training_acc": 49.0, "val_loss": 22.895632684230804, "val_acc": 52.0}
{"epoch": 8, "training_loss": 91.9213490486145, "training_acc": 53.0, "val_loss": 22.542506456375122, "val_acc": 52.0}
{"epoch": 9, "training_loss": 79.48512959480286, "training_acc": 53.0, "val_loss": 18.71524602174759, "val_acc": 44.0}
{"epoch": 10, "training_loss": 81.77272129058838, "training_acc": 47.0, "val_loss": 20.952457189559937, "val_acc": 48.0}
{"epoch": 11, "training_loss": 80.00942730903625, "training_acc": 49.0, "val_loss": 18.356558680534363, "val_acc": 52.0}
{"epoch": 12, "training_loss": 74.66305446624756, "training_acc": 53.0, "val_loss": 20.242370665073395, "val_acc": 52.0}
{"epoch": 13, "training_loss": 75.77996826171875, "training_acc": 53.0, "val_loss": 17.4213245511055, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.93383765220642, "training_acc": 46.0, "val_loss": 18.647967278957367, "val_acc": 48.0}
{"epoch": 15, "training_loss": 73.34258341789246, "training_acc": 49.0, "val_loss": 17.32950508594513, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.58889746665955, "training_acc": 54.0, "val_loss": 18.013885617256165, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.72639107704163, "training_acc": 53.0, "val_loss": 17.449381947517395, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.0267550945282, "training_acc": 49.0, "val_loss": 18.44150722026825, "val_acc": 56.0}
{"epoch": 19, "training_loss": 72.66259002685547, "training_acc": 45.0, "val_loss": 17.353293299674988, "val_acc": 52.0}
{"epoch": 20, "training_loss": 66.72927904129028, "training_acc": 54.0, "val_loss": 18.341591954231262, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.83198595046997, "training_acc": 53.0, "val_loss": 16.84267222881317, "val_acc": 52.0}
{"epoch": 22, "training_loss": 65.91715168952942, "training_acc": 67.0, "val_loss": 17.590975761413574, "val_acc": 60.0}
{"epoch": 23, "training_loss": 70.94813871383667, "training_acc": 49.0, "val_loss": 17.049625515937805, "val_acc": 52.0}
{"epoch": 24, "training_loss": 67.18466448783875, "training_acc": 52.0, "val_loss": 19.50308531522751, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.1380136013031, "training_acc": 53.0, "val_loss": 16.993127763271332, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.75394010543823, "training_acc": 57.0, "val_loss": 18.99970918893814, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.71339464187622, "training_acc": 51.0, "val_loss": 17.55433827638626, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.12717914581299, "training_acc": 57.0, "val_loss": 18.875713646411896, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.94381737709045, "training_acc": 53.0, "val_loss": 17.281021177768707, "val_acc": 52.0}
{"epoch": 30, "training_loss": 66.80730748176575, "training_acc": 62.0, "val_loss": 17.884747684001923, "val_acc": 52.0}
{"epoch": 31, "training_loss": 67.22943902015686, "training_acc": 59.0, "val_loss": 18.169422447681427, "val_acc": 52.0}
{"epoch": 32, "training_loss": 68.16620659828186, "training_acc": 56.0, "val_loss": 18.359370529651642, "val_acc": 52.0}
{"epoch": 33, "training_loss": 66.59379696846008, "training_acc": 56.0, "val_loss": 17.563582956790924, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.49072027206421, "training_acc": 53.0, "val_loss": 17.631345987319946, "val_acc": 56.0}
{"epoch": 35, "training_loss": 63.399418592453, "training_acc": 58.0, "val_loss": 18.22616010904312, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.77455568313599, "training_acc": 55.0, "val_loss": 17.565104365348816, "val_acc": 52.0}
{"epoch": 37, "training_loss": 63.55472183227539, "training_acc": 66.0, "val_loss": 17.11075007915497, "val_acc": 64.0}
{"epoch": 38, "training_loss": 68.01905751228333, "training_acc": 52.0, "val_loss": 16.91628247499466, "val_acc": 52.0}
{"epoch": 39, "training_loss": 66.134432554245, "training_acc": 59.0, "val_loss": 17.888295650482178, "val_acc": 52.0}
{"epoch": 40, "training_loss": 67.07681441307068, "training_acc": 56.0, "val_loss": 16.967445611953735, "val_acc": 52.0}
