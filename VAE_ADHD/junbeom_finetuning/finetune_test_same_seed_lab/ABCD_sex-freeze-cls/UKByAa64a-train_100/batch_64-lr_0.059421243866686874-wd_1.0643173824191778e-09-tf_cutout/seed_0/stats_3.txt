"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.79902005195618, "training_acc": 51.0, "val_loss": 57.655149698257446, "val_acc": 52.0}
{"epoch": 1, "training_loss": 174.74934840202332, "training_acc": 53.0, "val_loss": 31.07011616230011, "val_acc": 48.0}
{"epoch": 2, "training_loss": 132.20516777038574, "training_acc": 47.0, "val_loss": 20.78848034143448, "val_acc": 52.0}
{"epoch": 3, "training_loss": 87.44370245933533, "training_acc": 50.0, "val_loss": 32.170429825782776, "val_acc": 52.0}
{"epoch": 4, "training_loss": 115.40148067474365, "training_acc": 53.0, "val_loss": 17.434056103229523, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.03938221931458, "training_acc": 57.0, "val_loss": 27.36869752407074, "val_acc": 48.0}
{"epoch": 6, "training_loss": 102.98543691635132, "training_acc": 47.0, "val_loss": 17.03951358795166, "val_acc": 52.0}
{"epoch": 7, "training_loss": 77.66339159011841, "training_acc": 49.0, "val_loss": 27.06552743911743, "val_acc": 52.0}
{"epoch": 8, "training_loss": 97.74246573448181, "training_acc": 53.0, "val_loss": 17.5443097949028, "val_acc": 52.0}
{"epoch": 9, "training_loss": 77.00247526168823, "training_acc": 56.0, "val_loss": 22.235456109046936, "val_acc": 48.0}
{"epoch": 10, "training_loss": 86.36066031455994, "training_acc": 46.0, "val_loss": 18.572261929512024, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13228583335876, "training_acc": 55.0, "val_loss": 24.163608253002167, "val_acc": 52.0}
{"epoch": 12, "training_loss": 77.90068936347961, "training_acc": 53.0, "val_loss": 18.16335767507553, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66.66295456886292, "training_acc": 60.0, "val_loss": 19.935351610183716, "val_acc": 52.0}
{"epoch": 14, "training_loss": 78.42484211921692, "training_acc": 47.0, "val_loss": 18.216051161289215, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.82673048973083, "training_acc": 59.0, "val_loss": 23.541131615638733, "val_acc": 52.0}
{"epoch": 16, "training_loss": 77.72404909133911, "training_acc": 53.0, "val_loss": 18.213799595832825, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.79035305976868, "training_acc": 58.0, "val_loss": 20.0531005859375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 76.28662419319153, "training_acc": 47.0, "val_loss": 18.528784811496735, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.79133343696594, "training_acc": 57.0, "val_loss": 22.784723341464996, "val_acc": 52.0}
{"epoch": 20, "training_loss": 79.28018617630005, "training_acc": 56.0, "val_loss": 17.643004655838013, "val_acc": 52.0}
{"epoch": 21, "training_loss": 63.917400598526, "training_acc": 69.0, "val_loss": 18.067115545272827, "val_acc": 56.0}
{"epoch": 22, "training_loss": 71.69759368896484, "training_acc": 52.0, "val_loss": 17.825938761234283, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.87871623039246, "training_acc": 55.0, "val_loss": 19.36883181333542, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.0426812171936, "training_acc": 52.0, "val_loss": 17.675168812274933, "val_acc": 48.0}
{"epoch": 25, "training_loss": 66.55070042610168, "training_acc": 60.0, "val_loss": 17.70988255739212, "val_acc": 52.0}
