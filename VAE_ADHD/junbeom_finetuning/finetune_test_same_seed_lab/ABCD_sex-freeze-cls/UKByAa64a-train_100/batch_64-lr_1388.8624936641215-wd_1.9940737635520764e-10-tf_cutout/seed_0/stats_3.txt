"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 415884.30905914307, "training_acc": 53.0, "val_loss": 1170484.08203125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 4725336.734375, "training_acc": 47.0, "val_loss": 91797.58911132812, "val_acc": 44.0}
{"epoch": 2, "training_loss": 798074.109375, "training_acc": 68.0, "val_loss": 1144505.37109375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 3565077.234375, "training_acc": 53.0, "val_loss": 314531.34765625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1526893.7890625, "training_acc": 48.0, "val_loss": 879290.13671875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 3566477.40625, "training_acc": 47.0, "val_loss": 247139.3310546875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1233349.95703125, "training_acc": 51.0, "val_loss": 844562.59765625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2932579.5390625, "training_acc": 53.0, "val_loss": 656446.2890625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1615013.244140625, "training_acc": 54.0, "val_loss": 411167.041015625, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2117814.8203125, "training_acc": 47.0, "val_loss": 590836.23046875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 2078119.390625, "training_acc": 47.0, "val_loss": 284036.0595703125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1018808.9375, "training_acc": 54.0, "val_loss": 558850.9765625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1543537.06640625, "training_acc": 53.0, "val_loss": 81242.5537109375, "val_acc": 56.0}
{"epoch": 13, "training_loss": 543863.654296875, "training_acc": 57.0, "val_loss": 149927.99072265625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 749609.8935546875, "training_acc": 57.0, "val_loss": 343387.5244140625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 838175.814453125, "training_acc": 53.0, "val_loss": 103690.31982421875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 392841.24609375, "training_acc": 56.0, "val_loss": 130627.47802734375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 536236.9814453125, "training_acc": 58.0, "val_loss": 289792.1142578125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 666534.32421875, "training_acc": 55.0, "val_loss": 80265.46630859375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 431335.958984375, "training_acc": 58.0, "val_loss": 99876.82495117188, "val_acc": 52.0}
{"epoch": 20, "training_loss": 637167.064453125, "training_acc": 44.0, "val_loss": 272894.482421875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 560001.052734375, "training_acc": 55.0, "val_loss": 62553.253173828125, "val_acc": 44.0}
{"epoch": 22, "training_loss": 324751.37890625, "training_acc": 62.0, "val_loss": 122570.39794921875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 278974.5205078125, "training_acc": 55.0, "val_loss": 55777.813720703125, "val_acc": 60.0}
{"epoch": 24, "training_loss": 277747.4521484375, "training_acc": 60.0, "val_loss": 76352.63671875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 142978.7578125, "training_acc": 63.0, "val_loss": 27759.393310546875, "val_acc": 56.0}
{"epoch": 26, "training_loss": 125596.78173828125, "training_acc": 64.0, "val_loss": 26978.375244140625, "val_acc": 44.0}
{"epoch": 27, "training_loss": 125074.00830078125, "training_acc": 67.0, "val_loss": 46002.52685546875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 120494.10986328125, "training_acc": 64.0, "val_loss": 98713.97705078125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 310543.8125, "training_acc": 46.0, "val_loss": 118220.32470703125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 196155.0009765625, "training_acc": 56.0, "val_loss": 32173.40087890625, "val_acc": 48.0}
{"epoch": 31, "training_loss": 75260.74047851562, "training_acc": 70.0, "val_loss": 37227.490234375, "val_acc": 56.0}
{"epoch": 32, "training_loss": 384811.404296875, "training_acc": 44.0, "val_loss": 38980.94482421875, "val_acc": 56.0}
{"epoch": 33, "training_loss": 298887.798828125, "training_acc": 67.0, "val_loss": 144992.9931640625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 449838.482421875, "training_acc": 55.0, "val_loss": 185749.32861328125, "val_acc": 52.0}
{"epoch": 35, "training_loss": 476986.69873046875, "training_acc": 56.0, "val_loss": 64864.678955078125, "val_acc": 48.0}
{"epoch": 36, "training_loss": 230884.7158203125, "training_acc": 57.0, "val_loss": 30118.93310546875, "val_acc": 64.0}
{"epoch": 37, "training_loss": 252145.306640625, "training_acc": 61.0, "val_loss": 18712.155151367188, "val_acc": 64.0}
{"epoch": 38, "training_loss": 229327.962890625, "training_acc": 61.0, "val_loss": 17889.767456054688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 110510.37475585938, "training_acc": 60.0, "val_loss": 40878.56140136719, "val_acc": 56.0}
{"epoch": 40, "training_loss": 215879.072265625, "training_acc": 53.0, "val_loss": 59409.991455078125, "val_acc": 52.0}
{"epoch": 41, "training_loss": 252771.626953125, "training_acc": 61.0, "val_loss": 27041.787719726562, "val_acc": 56.0}
{"epoch": 42, "training_loss": 454401.93359375, "training_acc": 52.0, "val_loss": 261997.119140625, "val_acc": 52.0}
{"epoch": 43, "training_loss": 534276.1088867188, "training_acc": 59.0, "val_loss": 149161.0107421875, "val_acc": 48.0}
{"epoch": 44, "training_loss": 435224.99169921875, "training_acc": 54.0, "val_loss": 261911.71875, "val_acc": 52.0}
{"epoch": 45, "training_loss": 795697.130859375, "training_acc": 53.0, "val_loss": 55909.43603515625, "val_acc": 52.0}
{"epoch": 46, "training_loss": 397046.474609375, "training_acc": 66.0, "val_loss": 236502.1484375, "val_acc": 48.0}
{"epoch": 47, "training_loss": 709409.9223632812, "training_acc": 55.0, "val_loss": 247444.7021484375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 522306.783203125, "training_acc": 55.0, "val_loss": 135726.513671875, "val_acc": 48.0}
{"epoch": 49, "training_loss": 667055.5, "training_acc": 47.0, "val_loss": 144524.49951171875, "val_acc": 52.0}
{"epoch": 50, "training_loss": 335090.470703125, "training_acc": 59.0, "val_loss": 45986.89880371094, "val_acc": 48.0}
{"epoch": 51, "training_loss": 197826.4892578125, "training_acc": 62.0, "val_loss": 124201.7578125, "val_acc": 52.0}
{"epoch": 52, "training_loss": 205760.40625, "training_acc": 59.0, "val_loss": 26754.034423828125, "val_acc": 44.0}
{"epoch": 53, "training_loss": 150281.09326171875, "training_acc": 64.0, "val_loss": 22285.646057128906, "val_acc": 56.0}
{"epoch": 54, "training_loss": 93475.92138671875, "training_acc": 69.0, "val_loss": 147242.4072265625, "val_acc": 52.0}
{"epoch": 55, "training_loss": 365435.173828125, "training_acc": 53.0, "val_loss": 188857.9345703125, "val_acc": 48.0}
{"epoch": 56, "training_loss": 644577.474609375, "training_acc": 47.0, "val_loss": 114170.83740234375, "val_acc": 52.0}
{"epoch": 57, "training_loss": 370449.076171875, "training_acc": 54.0, "val_loss": 72056.86645507812, "val_acc": 48.0}
