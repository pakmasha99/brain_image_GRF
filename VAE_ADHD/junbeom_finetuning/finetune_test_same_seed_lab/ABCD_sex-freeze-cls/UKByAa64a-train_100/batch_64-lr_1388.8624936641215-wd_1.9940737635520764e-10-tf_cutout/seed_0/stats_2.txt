"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3822657.9696884155, "training_acc": 53.0, "val_loss": 751734.619140625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3839948.890625, "training_acc": 41.0, "val_loss": 1243573.92578125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4535631.828125, "training_acc": 47.0, "val_loss": 259391.552734375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1943236.171875, "training_acc": 41.0, "val_loss": 1090434.9609375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4179962.640625, "training_acc": 53.0, "val_loss": 893761.1328125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2770696.78125, "training_acc": 53.0, "val_loss": 198230.96923828125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1286203.6640625, "training_acc": 47.0, "val_loss": 472197.36328125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1530707.453125, "training_acc": 47.0, "val_loss": 342718.3349609375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1547372.6328125, "training_acc": 53.0, "val_loss": 512213.4765625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1608419.1875, "training_acc": 53.0, "val_loss": 167651.611328125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 853048.15234375, "training_acc": 47.0, "val_loss": 194978.271484375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 573267.7978515625, "training_acc": 54.0, "val_loss": 209700.6103515625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 640992.142578125, "training_acc": 51.0, "val_loss": 212612.8662109375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 845187.11328125, "training_acc": 47.0, "val_loss": 29246.957397460938, "val_acc": 52.0}
{"epoch": 14, "training_loss": 416436.86328125, "training_acc": 59.0, "val_loss": 184903.35693359375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 482819.48828125, "training_acc": 53.0, "val_loss": 89518.4326171875, "val_acc": 44.0}
{"epoch": 16, "training_loss": 338984.3017578125, "training_acc": 49.0, "val_loss": 43967.44689941406, "val_acc": 60.0}
{"epoch": 17, "training_loss": 259619.3017578125, "training_acc": 48.0, "val_loss": 53860.687255859375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 139295.748046875, "training_acc": 60.0, "val_loss": 76587.6708984375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 271006.296875, "training_acc": 55.0, "val_loss": 182393.65234375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 516204.84814453125, "training_acc": 53.0, "val_loss": 46243.756103515625, "val_acc": 44.0}
{"epoch": 21, "training_loss": 198462.20629882812, "training_acc": 54.0, "val_loss": 77256.48193359375, "val_acc": 52.0}
{"epoch": 22, "training_loss": 162130.53857421875, "training_acc": 58.0, "val_loss": 68306.23168945312, "val_acc": 52.0}
{"epoch": 23, "training_loss": 216111.8798828125, "training_acc": 50.0, "val_loss": 98853.82080078125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 234869.4453125, "training_acc": 61.0, "val_loss": 160610.04638671875, "val_acc": 48.0}
{"epoch": 25, "training_loss": 571051.779296875, "training_acc": 47.0, "val_loss": 187680.029296875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 702031.62109375, "training_acc": 53.0, "val_loss": 100872.50366210938, "val_acc": 52.0}
{"epoch": 27, "training_loss": 547090.12109375, "training_acc": 48.0, "val_loss": 299686.9384765625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 960508.05078125, "training_acc": 47.0, "val_loss": 294098.876953125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1296727.234375, "training_acc": 53.0, "val_loss": 404359.2041015625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1086988.7470703125, "training_acc": 53.0, "val_loss": 321394.23828125, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1613503.453125, "training_acc": 47.0, "val_loss": 400747.607421875, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1171449.1494140625, "training_acc": 48.0, "val_loss": 441769.62890625, "val_acc": 52.0}
