"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3110336.9845352173, "training_acc": 47.0, "val_loss": 406169.921875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 2977560.484375, "training_acc": 49.0, "val_loss": 1941886.1328125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 7458773.984375, "training_acc": 53.0, "val_loss": 1385164.74609375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 4251364.734375, "training_acc": 53.0, "val_loss": 342069.62890625, "val_acc": 48.0}
{"epoch": 4, "training_loss": 2020285.078125, "training_acc": 48.0, "val_loss": 876746.58203125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 2933545.2109375, "training_acc": 47.0, "val_loss": 28918.069458007812, "val_acc": 48.0}
{"epoch": 6, "training_loss": 868366.7421875, "training_acc": 47.0, "val_loss": 657633.251953125, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2402164.1640625, "training_acc": 53.0, "val_loss": 190697.35107421875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 908889.88671875, "training_acc": 55.0, "val_loss": 613939.74609375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 2331409.8203125, "training_acc": 47.0, "val_loss": 217648.2666015625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 779469.8125, "training_acc": 55.0, "val_loss": 576377.24609375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2267712.6015625, "training_acc": 53.0, "val_loss": 401697.2412109375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1035349.2885742188, "training_acc": 53.0, "val_loss": 460855.810546875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2019134.765625, "training_acc": 47.0, "val_loss": 491626.123046875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1388471.5947265625, "training_acc": 48.0, "val_loss": 385428.61328125, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1792807.109375, "training_acc": 53.0, "val_loss": 634493.115234375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2200031.1015625, "training_acc": 53.0, "val_loss": 55078.41796875, "val_acc": 56.0}
{"epoch": 17, "training_loss": 867257.34375, "training_acc": 49.0, "val_loss": 652860.546875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2398044.3828125, "training_acc": 47.0, "val_loss": 253119.8486328125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 855667.32421875, "training_acc": 51.0, "val_loss": 484277.587890625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1919754.2890625, "training_acc": 53.0, "val_loss": 303435.4248046875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 790127.7373046875, "training_acc": 57.0, "val_loss": 317206.1767578125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1161162.30859375, "training_acc": 47.0, "val_loss": 43720.24230957031, "val_acc": 48.0}
{"epoch": 23, "training_loss": 610450.69140625, "training_acc": 53.0, "val_loss": 369795.80078125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1213507.3125, "training_acc": 53.0, "val_loss": 114102.69775390625, "val_acc": 52.0}
