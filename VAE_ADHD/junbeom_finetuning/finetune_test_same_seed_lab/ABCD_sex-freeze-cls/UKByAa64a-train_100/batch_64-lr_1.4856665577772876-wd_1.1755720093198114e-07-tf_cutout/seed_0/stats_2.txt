"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3602.750701904297, "training_acc": 46.0, "val_loss": 789.4155502319336, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3227.301742553711, "training_acc": 53.0, "val_loss": 1476.8938064575195, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5305.896514892578, "training_acc": 47.0, "val_loss": 341.9599771499634, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1941.0790252685547, "training_acc": 48.0, "val_loss": 1256.6633224487305, "val_acc": 52.0}
{"epoch": 4, "training_loss": 4921.354537963867, "training_acc": 53.0, "val_loss": 1041.098690032959, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3261.80517578125, "training_acc": 53.0, "val_loss": 324.264121055603, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1553.3171920776367, "training_acc": 47.0, "val_loss": 697.3579406738281, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2132.560592651367, "training_acc": 48.0, "val_loss": 205.09865283966064, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1240.682144165039, "training_acc": 53.0, "val_loss": 407.3007583618164, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1103.1610164642334, "training_acc": 57.0, "val_loss": 352.2042751312256, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1574.5629653930664, "training_acc": 46.0, "val_loss": 355.25100231170654, "val_acc": 48.0}
{"epoch": 11, "training_loss": 995.7994232177734, "training_acc": 48.0, "val_loss": 288.69125843048096, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1096.4314804077148, "training_acc": 53.0, "val_loss": 48.738276958465576, "val_acc": 40.0}
{"epoch": 13, "training_loss": 434.90554428100586, "training_acc": 53.0, "val_loss": 170.8798885345459, "val_acc": 48.0}
{"epoch": 14, "training_loss": 664.8867893218994, "training_acc": 47.0, "val_loss": 128.07824611663818, "val_acc": 52.0}
{"epoch": 15, "training_loss": 424.2559938430786, "training_acc": 55.0, "val_loss": 23.942485451698303, "val_acc": 52.0}
{"epoch": 16, "training_loss": 226.40135097503662, "training_acc": 59.0, "val_loss": 108.65331888198853, "val_acc": 52.0}
{"epoch": 17, "training_loss": 515.3302764892578, "training_acc": 49.0, "val_loss": 48.5694944858551, "val_acc": 56.0}
{"epoch": 18, "training_loss": 500.3049564361572, "training_acc": 55.0, "val_loss": 255.5006742477417, "val_acc": 52.0}
{"epoch": 19, "training_loss": 554.1433753967285, "training_acc": 60.0, "val_loss": 163.13592195510864, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1092.5102043151855, "training_acc": 47.0, "val_loss": 58.59619379043579, "val_acc": 60.0}
{"epoch": 21, "training_loss": 350.6733055114746, "training_acc": 59.0, "val_loss": 171.62615060806274, "val_acc": 52.0}
{"epoch": 22, "training_loss": 364.2293453216553, "training_acc": 62.0, "val_loss": 99.76853728294373, "val_acc": 48.0}
{"epoch": 23, "training_loss": 464.77274990081787, "training_acc": 47.0, "val_loss": 57.16807246208191, "val_acc": 56.0}
{"epoch": 24, "training_loss": 270.64786529541016, "training_acc": 55.0, "val_loss": 34.761813282966614, "val_acc": 60.0}
{"epoch": 25, "training_loss": 209.41848850250244, "training_acc": 61.0, "val_loss": 107.19892978668213, "val_acc": 52.0}
{"epoch": 26, "training_loss": 259.0171937942505, "training_acc": 55.0, "val_loss": 61.66353225708008, "val_acc": 52.0}
{"epoch": 27, "training_loss": 276.9037628173828, "training_acc": 60.0, "val_loss": 70.2177882194519, "val_acc": 56.0}
{"epoch": 28, "training_loss": 357.90375328063965, "training_acc": 48.0, "val_loss": 41.20159149169922, "val_acc": 56.0}
{"epoch": 29, "training_loss": 272.8658752441406, "training_acc": 57.0, "val_loss": 197.36666679382324, "val_acc": 52.0}
{"epoch": 30, "training_loss": 403.7906413078308, "training_acc": 62.0, "val_loss": 135.66787242889404, "val_acc": 48.0}
{"epoch": 31, "training_loss": 419.5726592540741, "training_acc": 54.0, "val_loss": 142.579185962677, "val_acc": 52.0}
{"epoch": 32, "training_loss": 331.0423855781555, "training_acc": 55.0, "val_loss": 36.72594428062439, "val_acc": 60.0}
{"epoch": 33, "training_loss": 238.76944065093994, "training_acc": 53.0, "val_loss": 44.14113461971283, "val_acc": 64.0}
{"epoch": 34, "training_loss": 245.7889518737793, "training_acc": 59.0, "val_loss": 30.515584349632263, "val_acc": 60.0}
