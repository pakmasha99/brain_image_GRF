"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3232.0890922546387, "training_acc": 53.0, "val_loss": 598.002290725708, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3314.128631591797, "training_acc": 51.0, "val_loss": 1804.0483474731445, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6852.449279785156, "training_acc": 47.0, "val_loss": 610.7982158660889, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2204.130470275879, "training_acc": 51.0, "val_loss": 1050.3642082214355, "val_acc": 52.0}
{"epoch": 4, "training_loss": 3617.033233642578, "training_acc": 53.0, "val_loss": 854.2511940002441, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2181.230884552002, "training_acc": 54.0, "val_loss": 529.0507316589355, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2728.128616333008, "training_acc": 47.0, "val_loss": 764.8419857025146, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2671.81339263916, "training_acc": 47.0, "val_loss": 345.5510139465332, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1415.1807403564453, "training_acc": 54.0, "val_loss": 757.6509952545166, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2051.1419639587402, "training_acc": 54.0, "val_loss": 135.77451705932617, "val_acc": 40.0}
{"epoch": 10, "training_loss": 710.6567153930664, "training_acc": 57.0, "val_loss": 410.64319610595703, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1567.2972831726074, "training_acc": 48.0, "val_loss": 351.6374111175537, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1063.3880233764648, "training_acc": 55.0, "val_loss": 506.7014217376709, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1178.0676555633545, "training_acc": 50.0, "val_loss": 253.60090732574463, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1449.0732421875, "training_acc": 46.0, "val_loss": 239.27628993988037, "val_acc": 48.0}
{"epoch": 15, "training_loss": 825.5813465118408, "training_acc": 49.0, "val_loss": 357.03251361846924, "val_acc": 52.0}
{"epoch": 16, "training_loss": 933.0045166015625, "training_acc": 53.0, "val_loss": 89.91054892539978, "val_acc": 44.0}
{"epoch": 17, "training_loss": 582.5309715270996, "training_acc": 47.0, "val_loss": 64.27387595176697, "val_acc": 44.0}
{"epoch": 18, "training_loss": 267.90063285827637, "training_acc": 68.0, "val_loss": 194.01742219924927, "val_acc": 52.0}
{"epoch": 19, "training_loss": 325.6000428199768, "training_acc": 63.0, "val_loss": 86.66101694107056, "val_acc": 48.0}
{"epoch": 20, "training_loss": 435.9940013885498, "training_acc": 47.0, "val_loss": 91.24577045440674, "val_acc": 52.0}
{"epoch": 21, "training_loss": 248.25897026062012, "training_acc": 60.0, "val_loss": 37.430885434150696, "val_acc": 52.0}
{"epoch": 22, "training_loss": 215.49936485290527, "training_acc": 64.0, "val_loss": 76.34451985359192, "val_acc": 52.0}
{"epoch": 23, "training_loss": 469.22875213623047, "training_acc": 49.0, "val_loss": 79.57586646080017, "val_acc": 48.0}
{"epoch": 24, "training_loss": 673.1350440979004, "training_acc": 41.0, "val_loss": 301.3375520706177, "val_acc": 52.0}
{"epoch": 25, "training_loss": 731.2353563308716, "training_acc": 57.0, "val_loss": 269.81847286224365, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1188.1003379821777, "training_acc": 47.0, "val_loss": 76.023268699646, "val_acc": 52.0}
{"epoch": 27, "training_loss": 550.1742553710938, "training_acc": 53.0, "val_loss": 481.14895820617676, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1424.8604698181152, "training_acc": 53.0, "val_loss": 83.89424085617065, "val_acc": 52.0}
{"epoch": 29, "training_loss": 509.2691116333008, "training_acc": 57.0, "val_loss": 310.07673740386963, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1017.146614074707, "training_acc": 46.0, "val_loss": 379.5173168182373, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1363.4316940307617, "training_acc": 53.0, "val_loss": 506.93302154541016, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1239.520420074463, "training_acc": 53.0, "val_loss": 263.31796646118164, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1519.7319564819336, "training_acc": 47.0, "val_loss": 337.86702156066895, "val_acc": 48.0}
{"epoch": 34, "training_loss": 965.731080532074, "training_acc": 55.0, "val_loss": 378.6310911178589, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1314.0634536743164, "training_acc": 53.0, "val_loss": 296.9219923019409, "val_acc": 52.0}
{"epoch": 36, "training_loss": 741.1341648101807, "training_acc": 46.0, "val_loss": 233.94508361816406, "val_acc": 48.0}
{"epoch": 37, "training_loss": 910.7036228179932, "training_acc": 48.0, "val_loss": 328.65278720855713, "val_acc": 52.0}
{"epoch": 38, "training_loss": 987.2656898498535, "training_acc": 53.0, "val_loss": 270.0374126434326, "val_acc": 52.0}
{"epoch": 39, "training_loss": 607.7537631988525, "training_acc": 49.0, "val_loss": 181.42261505126953, "val_acc": 48.0}
{"epoch": 40, "training_loss": 612.6770858764648, "training_acc": 53.0, "val_loss": 261.69841289520264, "val_acc": 52.0}
