"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.12230086326599, "training_acc": 53.0, "val_loss": 17.816796898841858, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.01933026313782, "training_acc": 53.0, "val_loss": 17.504359781742096, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.986736536026, "training_acc": 53.0, "val_loss": 17.451682686805725, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.99419808387756, "training_acc": 57.0, "val_loss": 17.959895730018616, "val_acc": 52.0}
{"epoch": 4, "training_loss": 72.61867189407349, "training_acc": 46.0, "val_loss": 17.858588695526123, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15353465080261, "training_acc": 52.0, "val_loss": 17.768219113349915, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.72550940513611, "training_acc": 53.0, "val_loss": 18.20080280303955, "val_acc": 52.0}
{"epoch": 7, "training_loss": 71.4899537563324, "training_acc": 53.0, "val_loss": 17.58958250284195, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.81665539741516, "training_acc": 55.0, "val_loss": 17.447546124458313, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.29687166213989, "training_acc": 57.0, "val_loss": 17.57408231496811, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18992829322815, "training_acc": 50.0, "val_loss": 17.468897998332977, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.02614521980286, "training_acc": 49.0, "val_loss": 17.360641062259674, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.5579845905304, "training_acc": 57.0, "val_loss": 17.382250726222992, "val_acc": 52.0}
{"epoch": 13, "training_loss": 66.89561223983765, "training_acc": 57.0, "val_loss": 17.41270422935486, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.61801075935364, "training_acc": 54.0, "val_loss": 17.383113503456116, "val_acc": 52.0}
{"epoch": 15, "training_loss": 67.81913375854492, "training_acc": 52.0, "val_loss": 17.306743562221527, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.35575556755066, "training_acc": 46.0, "val_loss": 17.28839874267578, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.44713163375854, "training_acc": 55.0, "val_loss": 17.469680309295654, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.88541793823242, "training_acc": 52.0, "val_loss": 17.426496744155884, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.20713806152344, "training_acc": 53.0, "val_loss": 17.297187447547913, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.58320164680481, "training_acc": 53.0, "val_loss": 17.399276793003082, "val_acc": 52.0}
{"epoch": 21, "training_loss": 68.17923402786255, "training_acc": 61.0, "val_loss": 17.295418679714203, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.48268461227417, "training_acc": 59.0, "val_loss": 17.451266944408417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.17080330848694, "training_acc": 54.0, "val_loss": 17.46515780687332, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.58403515815735, "training_acc": 54.0, "val_loss": 17.332446575164795, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.61052775382996, "training_acc": 59.0, "val_loss": 17.304733395576477, "val_acc": 52.0}
{"epoch": 26, "training_loss": 66.61831974983215, "training_acc": 62.0, "val_loss": 17.296233773231506, "val_acc": 52.0}
{"epoch": 27, "training_loss": 67.92853903770447, "training_acc": 57.0, "val_loss": 17.299331724643707, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.25385785102844, "training_acc": 58.0, "val_loss": 17.427481710910797, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.67259812355042, "training_acc": 53.0, "val_loss": 17.57197380065918, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.00949454307556, "training_acc": 55.0, "val_loss": 17.43268519639969, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.35692238807678, "training_acc": 61.0, "val_loss": 17.30416715145111, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.80943655967712, "training_acc": 69.0, "val_loss": 17.42306500673294, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.04682660102844, "training_acc": 54.0, "val_loss": 17.444640398025513, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.09243774414062, "training_acc": 51.0, "val_loss": 17.31937825679779, "val_acc": 52.0}
{"epoch": 35, "training_loss": 66.97933220863342, "training_acc": 56.0, "val_loss": 17.575298249721527, "val_acc": 52.0}
