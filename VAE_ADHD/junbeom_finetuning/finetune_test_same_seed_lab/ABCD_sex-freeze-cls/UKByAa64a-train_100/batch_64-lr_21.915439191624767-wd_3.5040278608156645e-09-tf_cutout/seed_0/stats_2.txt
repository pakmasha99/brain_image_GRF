"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 214765.9331817627, "training_acc": 54.0, "val_loss": 42961.944580078125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 213392.6767578125, "training_acc": 41.0, "val_loss": 64716.351318359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 239958.138671875, "training_acc": 47.0, "val_loss": 10188.063049316406, "val_acc": 48.0}
{"epoch": 3, "training_loss": 104147.54296875, "training_acc": 41.0, "val_loss": 64132.220458984375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 251832.52490234375, "training_acc": 53.0, "val_loss": 53379.840087890625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 174911.427734375, "training_acc": 53.0, "val_loss": 6400.1739501953125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 50178.834228515625, "training_acc": 47.0, "val_loss": 21201.730346679688, "val_acc": 48.0}
{"epoch": 7, "training_loss": 64269.41567993164, "training_acc": 47.0, "val_loss": 23647.14813232422, "val_acc": 52.0}
{"epoch": 8, "training_loss": 107132.46728515625, "training_acc": 53.0, "val_loss": 32925.26550292969, "val_acc": 52.0}
{"epoch": 9, "training_loss": 110764.61206054688, "training_acc": 53.0, "val_loss": 4224.771499633789, "val_acc": 48.0}
{"epoch": 10, "training_loss": 28037.89794921875, "training_acc": 47.0, "val_loss": 5734.495162963867, "val_acc": 48.0}
{"epoch": 11, "training_loss": 28888.610717773438, "training_acc": 53.0, "val_loss": 17205.882263183594, "val_acc": 52.0}
{"epoch": 12, "training_loss": 58501.36535644531, "training_acc": 53.0, "val_loss": 6540.4541015625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 29203.406372070312, "training_acc": 47.0, "val_loss": 2556.279754638672, "val_acc": 52.0}
{"epoch": 14, "training_loss": 8310.334381103516, "training_acc": 53.0, "val_loss": 12503.245544433594, "val_acc": 48.0}
{"epoch": 15, "training_loss": 50270.4140625, "training_acc": 47.0, "val_loss": 1475.5796432495117, "val_acc": 52.0}
{"epoch": 16, "training_loss": 6425.3525390625, "training_acc": 53.0, "val_loss": 8940.68832397461, "val_acc": 48.0}
{"epoch": 17, "training_loss": 32730.090087890625, "training_acc": 47.0, "val_loss": 8991.392517089844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 39327.59631347656, "training_acc": 53.0, "val_loss": 4046.168899536133, "val_acc": 52.0}
{"epoch": 19, "training_loss": 42509.061767578125, "training_acc": 41.0, "val_loss": 19321.6796875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 63137.563720703125, "training_acc": 47.0, "val_loss": 11643.558502197266, "val_acc": 52.0}
{"epoch": 21, "training_loss": 58004.091064453125, "training_acc": 53.0, "val_loss": 19711.636352539062, "val_acc": 52.0}
{"epoch": 22, "training_loss": 59833.16394042969, "training_acc": 53.0, "val_loss": 13611.602783203125, "val_acc": 48.0}
{"epoch": 23, "training_loss": 71230.865234375, "training_acc": 47.0, "val_loss": 16708.599853515625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 47501.32534790039, "training_acc": 47.0, "val_loss": 6145.405197143555, "val_acc": 52.0}
{"epoch": 25, "training_loss": 18767.08332824707, "training_acc": 45.0, "val_loss": 5643.843078613281, "val_acc": 52.0}
{"epoch": 26, "training_loss": 15964.161231994629, "training_acc": 53.0, "val_loss": 13642.982482910156, "val_acc": 48.0}
{"epoch": 27, "training_loss": 57002.425048828125, "training_acc": 47.0, "val_loss": 2183.1003189086914, "val_acc": 48.0}
{"epoch": 28, "training_loss": 27025.0517578125, "training_acc": 55.0, "val_loss": 29100.875854492188, "val_acc": 52.0}
{"epoch": 29, "training_loss": 113373.876953125, "training_acc": 53.0, "val_loss": 16913.284301757812, "val_acc": 52.0}
{"epoch": 30, "training_loss": 50939.599060058594, "training_acc": 49.0, "val_loss": 12328.01513671875, "val_acc": 48.0}
{"epoch": 31, "training_loss": 41893.927734375, "training_acc": 47.0, "val_loss": 10251.25732421875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 47057.214599609375, "training_acc": 53.0, "val_loss": 9424.98779296875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 38741.14367675781, "training_acc": 45.0, "val_loss": 9322.645568847656, "val_acc": 48.0}
{"epoch": 34, "training_loss": 27867.414154052734, "training_acc": 47.0, "val_loss": 590.819787979126, "val_acc": 52.0}
{"epoch": 35, "training_loss": 18409.343383789062, "training_acc": 51.0, "val_loss": 10481.265258789062, "val_acc": 48.0}
{"epoch": 36, "training_loss": 30028.661163330078, "training_acc": 51.0, "val_loss": 4039.272689819336, "val_acc": 52.0}
{"epoch": 37, "training_loss": 16418.793884277344, "training_acc": 53.0, "val_loss": 1554.9562454223633, "val_acc": 48.0}
{"epoch": 38, "training_loss": 25891.7548828125, "training_acc": 45.0, "val_loss": 15778.858947753906, "val_acc": 52.0}
{"epoch": 39, "training_loss": 49492.34130859375, "training_acc": 53.0, "val_loss": 11303.589630126953, "val_acc": 48.0}
{"epoch": 40, "training_loss": 55467.029296875, "training_acc": 47.0, "val_loss": 8606.501007080078, "val_acc": 48.0}
{"epoch": 41, "training_loss": 39558.57824707031, "training_acc": 47.0, "val_loss": 17311.288452148438, "val_acc": 52.0}
{"epoch": 42, "training_loss": 60975.90295410156, "training_acc": 53.0, "val_loss": 2007.1189880371094, "val_acc": 48.0}
{"epoch": 43, "training_loss": 10312.658813476562, "training_acc": 47.0, "val_loss": 6946.453857421875, "val_acc": 52.0}
{"epoch": 44, "training_loss": 25863.84619140625, "training_acc": 53.0, "val_loss": 5730.938720703125, "val_acc": 48.0}
{"epoch": 45, "training_loss": 22283.05987548828, "training_acc": 47.0, "val_loss": 8484.575653076172, "val_acc": 52.0}
{"epoch": 46, "training_loss": 35915.62756347656, "training_acc": 53.0, "val_loss": 1358.5973739624023, "val_acc": 52.0}
{"epoch": 47, "training_loss": 30305.55712890625, "training_acc": 51.0, "val_loss": 24082.034301757812, "val_acc": 48.0}
{"epoch": 48, "training_loss": 87007.244140625, "training_acc": 47.0, "val_loss": 2696.750259399414, "val_acc": 52.0}
{"epoch": 49, "training_loss": 19896.6279296875, "training_acc": 53.0, "val_loss": 4040.291976928711, "val_acc": 52.0}
{"epoch": 50, "training_loss": 25217.994506835938, "training_acc": 53.0, "val_loss": 13712.98828125, "val_acc": 48.0}
{"epoch": 51, "training_loss": 40396.89651489258, "training_acc": 47.0, "val_loss": 17368.69659423828, "val_acc": 52.0}
{"epoch": 52, "training_loss": 84153.72509765625, "training_acc": 53.0, "val_loss": 22404.87060546875, "val_acc": 52.0}
{"epoch": 53, "training_loss": 66011.81274414062, "training_acc": 53.0, "val_loss": 16134.117126464844, "val_acc": 48.0}
