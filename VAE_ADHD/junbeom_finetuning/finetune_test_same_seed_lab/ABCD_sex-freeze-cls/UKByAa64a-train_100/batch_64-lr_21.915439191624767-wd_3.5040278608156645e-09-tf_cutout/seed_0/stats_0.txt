"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 83861.27066040039, "training_acc": 52.0, "val_loss": 27854.98046875, "val_acc": 44.0}
{"epoch": 1, "training_loss": 85552.68969726562, "training_acc": 48.0, "val_loss": 29300.64697265625, "val_acc": 56.0}
{"epoch": 2, "training_loss": 135778.17919921875, "training_acc": 52.0, "val_loss": 12320.956420898438, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70075.74072265625, "training_acc": 54.0, "val_loss": 47117.17224121094, "val_acc": 44.0}
{"epoch": 4, "training_loss": 158240.8515625, "training_acc": 48.0, "val_loss": 3974.626922607422, "val_acc": 44.0}
{"epoch": 5, "training_loss": 73585.318359375, "training_acc": 44.0, "val_loss": 51978.033447265625, "val_acc": 56.0}
{"epoch": 6, "training_loss": 227266.6376953125, "training_acc": 52.0, "val_loss": 39893.02978515625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 138824.90649414062, "training_acc": 52.0, "val_loss": 22241.038513183594, "val_acc": 44.0}
{"epoch": 8, "training_loss": 100733.62841796875, "training_acc": 48.0, "val_loss": 42920.147705078125, "val_acc": 44.0}
{"epoch": 9, "training_loss": 140166.89135742188, "training_acc": 48.0, "val_loss": 1263.0956649780273, "val_acc": 44.0}
{"epoch": 10, "training_loss": 47078.1259765625, "training_acc": 52.0, "val_loss": 44943.78356933594, "val_acc": 56.0}
{"epoch": 11, "training_loss": 201106.607421875, "training_acc": 52.0, "val_loss": 39410.50720214844, "val_acc": 56.0}
{"epoch": 12, "training_loss": 140436.1337890625, "training_acc": 52.0, "val_loss": 8739.222717285156, "val_acc": 44.0}
{"epoch": 13, "training_loss": 55877.20751953125, "training_acc": 48.0, "val_loss": 26332.684326171875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 76209.58752441406, "training_acc": 48.0, "val_loss": 12350.46615600586, "val_acc": 56.0}
{"epoch": 15, "training_loss": 65487.5732421875, "training_acc": 52.0, "val_loss": 19343.95294189453, "val_acc": 56.0}
{"epoch": 16, "training_loss": 65661.42663574219, "training_acc": 52.0, "val_loss": 16833.888244628906, "val_acc": 44.0}
{"epoch": 17, "training_loss": 74712.44262695312, "training_acc": 48.0, "val_loss": 21199.896240234375, "val_acc": 44.0}
{"epoch": 18, "training_loss": 51476.9443359375, "training_acc": 48.0, "val_loss": 22828.428649902344, "val_acc": 56.0}
{"epoch": 19, "training_loss": 118619.2353515625, "training_acc": 52.0, "val_loss": 35220.74279785156, "val_acc": 56.0}
{"epoch": 20, "training_loss": 137948.70434570312, "training_acc": 52.0, "val_loss": 6321.747970581055, "val_acc": 56.0}
{"epoch": 21, "training_loss": 58446.88330078125, "training_acc": 46.0, "val_loss": 43143.06945800781, "val_acc": 44.0}
{"epoch": 22, "training_loss": 157784.18896484375, "training_acc": 48.0, "val_loss": 29985.519409179688, "val_acc": 44.0}
{"epoch": 23, "training_loss": 78363.33108520508, "training_acc": 48.0, "val_loss": 24763.37432861328, "val_acc": 56.0}
{"epoch": 24, "training_loss": 135211.095703125, "training_acc": 52.0, "val_loss": 43723.66943359375, "val_acc": 56.0}
{"epoch": 25, "training_loss": 179259.529296875, "training_acc": 52.0, "val_loss": 20171.173095703125, "val_acc": 56.0}
{"epoch": 26, "training_loss": 48094.412506103516, "training_acc": 62.0, "val_loss": 19784.523010253906, "val_acc": 44.0}
{"epoch": 27, "training_loss": 72558.02856445312, "training_acc": 48.0, "val_loss": 7600.334167480469, "val_acc": 44.0}
{"epoch": 28, "training_loss": 33640.99645996094, "training_acc": 54.0, "val_loss": 21940.516662597656, "val_acc": 56.0}
