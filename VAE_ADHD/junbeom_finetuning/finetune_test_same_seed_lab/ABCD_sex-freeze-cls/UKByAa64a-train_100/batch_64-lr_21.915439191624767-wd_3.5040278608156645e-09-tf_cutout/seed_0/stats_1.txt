"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 64850.50969696045, "training_acc": 51.0, "val_loss": 34183.83483886719, "val_acc": 48.0}
{"epoch": 1, "training_loss": 112790.50024414062, "training_acc": 47.0, "val_loss": 34746.234130859375, "val_acc": 52.0}
{"epoch": 2, "training_loss": 158083.814453125, "training_acc": 53.0, "val_loss": 28407.489013671875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 85542.91418457031, "training_acc": 51.0, "val_loss": 19002.359008789062, "val_acc": 48.0}
{"epoch": 4, "training_loss": 55921.82162475586, "training_acc": 47.0, "val_loss": 27248.281860351562, "val_acc": 52.0}
{"epoch": 5, "training_loss": 116068.11181640625, "training_acc": 53.0, "val_loss": 27228.033447265625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 78938.31243896484, "training_acc": 53.0, "val_loss": 29613.571166992188, "val_acc": 48.0}
{"epoch": 7, "training_loss": 138527.47802734375, "training_acc": 47.0, "val_loss": 37895.46813964844, "val_acc": 48.0}
{"epoch": 8, "training_loss": 122819.77490234375, "training_acc": 47.0, "val_loss": 14772.515869140625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 67441.78491210938, "training_acc": 53.0, "val_loss": 29596.319580078125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 101689.39135742188, "training_acc": 53.0, "val_loss": 541.9976711273193, "val_acc": 24.0}
{"epoch": 11, "training_loss": 18455.73486328125, "training_acc": 54.0, "val_loss": 17616.647338867188, "val_acc": 48.0}
{"epoch": 12, "training_loss": 51661.8994140625, "training_acc": 47.0, "val_loss": 19750.546264648438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 87713.35180664062, "training_acc": 53.0, "val_loss": 25544.874572753906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 79346.25048828125, "training_acc": 53.0, "val_loss": 13922.413635253906, "val_acc": 48.0}
{"epoch": 15, "training_loss": 70247.4150390625, "training_acc": 47.0, "val_loss": 18409.754943847656, "val_acc": 48.0}
{"epoch": 16, "training_loss": 46791.093254089355, "training_acc": 50.0, "val_loss": 9760.187530517578, "val_acc": 52.0}
{"epoch": 17, "training_loss": 33371.78729248047, "training_acc": 53.0, "val_loss": 7974.285888671875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 28128.536071777344, "training_acc": 47.0, "val_loss": 7807.093811035156, "val_acc": 52.0}
{"epoch": 19, "training_loss": 32237.999267578125, "training_acc": 53.0, "val_loss": 2265.5651092529297, "val_acc": 48.0}
{"epoch": 20, "training_loss": 5185.292068481445, "training_acc": 47.0, "val_loss": 14379.116821289062, "val_acc": 52.0}
{"epoch": 21, "training_loss": 59295.243408203125, "training_acc": 53.0, "val_loss": 8092.512512207031, "val_acc": 52.0}
{"epoch": 22, "training_loss": 41236.124267578125, "training_acc": 47.0, "val_loss": 16548.928833007812, "val_acc": 48.0}
{"epoch": 23, "training_loss": 51955.90606689453, "training_acc": 47.0, "val_loss": 14502.362060546875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70506.32275390625, "training_acc": 53.0, "val_loss": 17312.139892578125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 40927.18957519531, "training_acc": 53.0, "val_loss": 25596.206665039062, "val_acc": 48.0}
{"epoch": 26, "training_loss": 120039.3369140625, "training_acc": 47.0, "val_loss": 36996.55456542969, "val_acc": 48.0}
{"epoch": 27, "training_loss": 128092.64404296875, "training_acc": 47.0, "val_loss": 3269.196319580078, "val_acc": 52.0}
{"epoch": 28, "training_loss": 27856.64892578125, "training_acc": 53.0, "val_loss": 12976.98974609375, "val_acc": 52.0}
{"epoch": 29, "training_loss": 33849.56132507324, "training_acc": 53.0, "val_loss": 22202.71453857422, "val_acc": 48.0}
