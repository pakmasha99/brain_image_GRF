"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1834.8460121154785, "training_acc": 46.0, "val_loss": 374.11041259765625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1817.56396484375, "training_acc": 53.0, "val_loss": 969.3161964416504, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3647.6699829101562, "training_acc": 47.0, "val_loss": 268.77379417419434, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1270.9189567565918, "training_acc": 51.0, "val_loss": 707.6873779296875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2689.292655944824, "training_acc": 53.0, "val_loss": 631.4765453338623, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1874.5859298706055, "training_acc": 53.0, "val_loss": 109.86208915710449, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1011.7135467529297, "training_acc": 47.0, "val_loss": 323.7372875213623, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1096.9663124084473, "training_acc": 47.0, "val_loss": 234.07421112060547, "val_acc": 52.0}
{"epoch": 8, "training_loss": 912.7957191467285, "training_acc": 53.0, "val_loss": 405.12189865112305, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1314.3809776306152, "training_acc": 53.0, "val_loss": 50.22537112236023, "val_acc": 52.0}
{"epoch": 10, "training_loss": 524.4925155639648, "training_acc": 50.0, "val_loss": 362.78624534606934, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1380.6728973388672, "training_acc": 47.0, "val_loss": 51.253700256347656, "val_acc": 48.0}
{"epoch": 12, "training_loss": 485.06622314453125, "training_acc": 49.0, "val_loss": 418.7480926513672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 1599.3995361328125, "training_acc": 53.0, "val_loss": 312.2741222381592, "val_acc": 52.0}
{"epoch": 14, "training_loss": 847.0039610862732, "training_acc": 53.0, "val_loss": 283.18514823913574, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1398.0002212524414, "training_acc": 47.0, "val_loss": 427.9545307159424, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1449.1512603759766, "training_acc": 47.0, "val_loss": 46.876826882362366, "val_acc": 56.0}
{"epoch": 17, "training_loss": 394.98187255859375, "training_acc": 53.0, "val_loss": 268.34001541137695, "val_acc": 52.0}
{"epoch": 18, "training_loss": 872.5635852813721, "training_acc": 53.0, "val_loss": 31.484124064445496, "val_acc": 40.0}
{"epoch": 19, "training_loss": 230.28615188598633, "training_acc": 57.0, "val_loss": 66.16596579551697, "val_acc": 48.0}
{"epoch": 20, "training_loss": 361.2829647064209, "training_acc": 45.0, "val_loss": 137.8225326538086, "val_acc": 52.0}
{"epoch": 21, "training_loss": 301.7640645503998, "training_acc": 59.0, "val_loss": 129.15191650390625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 553.8936557769775, "training_acc": 47.0, "val_loss": 31.59521520137787, "val_acc": 56.0}
{"epoch": 23, "training_loss": 248.0479564666748, "training_acc": 56.0, "val_loss": 139.11751508712769, "val_acc": 52.0}
{"epoch": 24, "training_loss": 329.42299461364746, "training_acc": 56.0, "val_loss": 88.7845516204834, "val_acc": 48.0}
{"epoch": 25, "training_loss": 273.85486125946045, "training_acc": 51.0, "val_loss": 136.3181471824646, "val_acc": 52.0}
{"epoch": 26, "training_loss": 443.0140075683594, "training_acc": 53.0, "val_loss": 58.64829421043396, "val_acc": 56.0}
{"epoch": 27, "training_loss": 198.7891321182251, "training_acc": 59.0, "val_loss": 85.70183515548706, "val_acc": 48.0}
{"epoch": 28, "training_loss": 335.56743717193604, "training_acc": 48.0, "val_loss": 95.04717588424683, "val_acc": 52.0}
{"epoch": 29, "training_loss": 265.94191455841064, "training_acc": 45.0, "val_loss": 30.682915449142456, "val_acc": 52.0}
{"epoch": 30, "training_loss": 141.12755823135376, "training_acc": 56.0, "val_loss": 33.2707941532135, "val_acc": 60.0}
{"epoch": 31, "training_loss": 123.79718971252441, "training_acc": 69.0, "val_loss": 42.77515709400177, "val_acc": 60.0}
{"epoch": 32, "training_loss": 115.47023248672485, "training_acc": 56.0, "val_loss": 48.33601415157318, "val_acc": 48.0}
{"epoch": 33, "training_loss": 173.02283143997192, "training_acc": 49.0, "val_loss": 46.51082158088684, "val_acc": 56.0}
{"epoch": 34, "training_loss": 117.03243350982666, "training_acc": 58.0, "val_loss": 69.96550559997559, "val_acc": 48.0}
{"epoch": 35, "training_loss": 253.48164415359497, "training_acc": 54.0, "val_loss": 128.00793647766113, "val_acc": 52.0}
{"epoch": 36, "training_loss": 394.06970024108887, "training_acc": 53.0, "val_loss": 18.35331618785858, "val_acc": 52.0}
{"epoch": 37, "training_loss": 166.42261409759521, "training_acc": 56.0, "val_loss": 68.83653402328491, "val_acc": 52.0}
{"epoch": 38, "training_loss": 178.39182472229004, "training_acc": 55.0, "val_loss": 49.88888502120972, "val_acc": 48.0}
{"epoch": 39, "training_loss": 205.39403676986694, "training_acc": 52.0, "val_loss": 105.66830635070801, "val_acc": 52.0}
{"epoch": 40, "training_loss": 309.1970615386963, "training_acc": 53.0, "val_loss": 57.165032625198364, "val_acc": 48.0}
{"epoch": 41, "training_loss": 207.67000770568848, "training_acc": 47.0, "val_loss": 106.28162622451782, "val_acc": 52.0}
{"epoch": 42, "training_loss": 357.90788650512695, "training_acc": 53.0, "val_loss": 20.07462829351425, "val_acc": 52.0}
{"epoch": 43, "training_loss": 95.5809257030487, "training_acc": 62.0, "val_loss": 41.40831232070923, "val_acc": 52.0}
{"epoch": 44, "training_loss": 85.85979056358337, "training_acc": 67.0, "val_loss": 50.09945034980774, "val_acc": 48.0}
{"epoch": 45, "training_loss": 139.66754794120789, "training_acc": 57.0, "val_loss": 55.25059103965759, "val_acc": 52.0}
{"epoch": 46, "training_loss": 103.70784044265747, "training_acc": 66.0, "val_loss": 24.193936586380005, "val_acc": 52.0}
{"epoch": 47, "training_loss": 147.2490940093994, "training_acc": 53.0, "val_loss": 38.24092745780945, "val_acc": 52.0}
{"epoch": 48, "training_loss": 254.5041103363037, "training_acc": 44.0, "val_loss": 53.459638357162476, "val_acc": 48.0}
{"epoch": 49, "training_loss": 238.89497756958008, "training_acc": 56.0, "val_loss": 152.48323678970337, "val_acc": 52.0}
{"epoch": 50, "training_loss": 425.6794581413269, "training_acc": 54.0, "val_loss": 157.22862482070923, "val_acc": 48.0}
{"epoch": 51, "training_loss": 594.5495834350586, "training_acc": 47.0, "val_loss": 26.875793933868408, "val_acc": 48.0}
{"epoch": 52, "training_loss": 291.975679397583, "training_acc": 56.0, "val_loss": 210.4877471923828, "val_acc": 52.0}
{"epoch": 53, "training_loss": 647.1544399261475, "training_acc": 53.0, "val_loss": 114.68071937561035, "val_acc": 48.0}
{"epoch": 54, "training_loss": 493.32815742492676, "training_acc": 47.0, "val_loss": 50.793492794036865, "val_acc": 48.0}
{"epoch": 55, "training_loss": 263.5246524810791, "training_acc": 55.0, "val_loss": 207.0941925048828, "val_acc": 52.0}
