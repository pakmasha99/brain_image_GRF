"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 297.62044525146484, "training_acc": 52.0, "val_loss": 50.418126583099365, "val_acc": 52.0}
{"epoch": 1, "training_loss": 221.6949977874756, "training_acc": 59.0, "val_loss": 145.6467866897583, "val_acc": 48.0}
{"epoch": 2, "training_loss": 547.8040790557861, "training_acc": 47.0, "val_loss": 46.37647569179535, "val_acc": 48.0}
{"epoch": 3, "training_loss": 165.29246377944946, "training_acc": 55.0, "val_loss": 89.8557186126709, "val_acc": 52.0}
{"epoch": 4, "training_loss": 360.2034168243408, "training_acc": 53.0, "val_loss": 73.68334531784058, "val_acc": 52.0}
{"epoch": 5, "training_loss": 217.26227569580078, "training_acc": 53.0, "val_loss": 40.03125727176666, "val_acc": 48.0}
{"epoch": 6, "training_loss": 187.9577989578247, "training_acc": 47.0, "val_loss": 63.36223483085632, "val_acc": 48.0}
{"epoch": 7, "training_loss": 218.64941835403442, "training_acc": 47.0, "val_loss": 20.78614830970764, "val_acc": 52.0}
{"epoch": 8, "training_loss": 101.36099147796631, "training_acc": 53.0, "val_loss": 52.18566060066223, "val_acc": 52.0}
{"epoch": 9, "training_loss": 180.14344215393066, "training_acc": 53.0, "val_loss": 18.537338078022003, "val_acc": 52.0}
{"epoch": 10, "training_loss": 75.44564366340637, "training_acc": 61.0, "val_loss": 39.79019820690155, "val_acc": 48.0}
{"epoch": 11, "training_loss": 155.52324151992798, "training_acc": 47.0, "val_loss": 17.471885681152344, "val_acc": 48.0}
{"epoch": 12, "training_loss": 92.56821298599243, "training_acc": 47.0, "val_loss": 39.75438177585602, "val_acc": 52.0}
{"epoch": 13, "training_loss": 139.13760781288147, "training_acc": 53.0, "val_loss": 17.214560508728027, "val_acc": 52.0}
{"epoch": 14, "training_loss": 81.10249471664429, "training_acc": 59.0, "val_loss": 26.774588227272034, "val_acc": 48.0}
{"epoch": 15, "training_loss": 95.02432751655579, "training_acc": 49.0, "val_loss": 21.43404930830002, "val_acc": 52.0}
{"epoch": 16, "training_loss": 86.22512769699097, "training_acc": 54.0, "val_loss": 21.16205543279648, "val_acc": 52.0}
{"epoch": 17, "training_loss": 79.63416910171509, "training_acc": 50.0, "val_loss": 22.366660833358765, "val_acc": 48.0}
{"epoch": 18, "training_loss": 85.73512244224548, "training_acc": 49.0, "val_loss": 17.483384907245636, "val_acc": 52.0}
{"epoch": 19, "training_loss": 76.01069760322571, "training_acc": 54.0, "val_loss": 20.930202305316925, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.92236542701721, "training_acc": 57.0, "val_loss": 20.10011225938797, "val_acc": 48.0}
{"epoch": 21, "training_loss": 77.18612623214722, "training_acc": 48.0, "val_loss": 17.050254344940186, "val_acc": 52.0}
{"epoch": 22, "training_loss": 78.27304005622864, "training_acc": 56.0, "val_loss": 20.522110164165497, "val_acc": 52.0}
{"epoch": 23, "training_loss": 76.93494582176208, "training_acc": 54.0, "val_loss": 18.707163631916046, "val_acc": 52.0}
{"epoch": 24, "training_loss": 72.2950336933136, "training_acc": 53.0, "val_loss": 18.228957056999207, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.07168507575989, "training_acc": 52.0, "val_loss": 17.98935979604721, "val_acc": 52.0}
{"epoch": 26, "training_loss": 67.77835464477539, "training_acc": 55.0, "val_loss": 17.64148622751236, "val_acc": 60.0}
{"epoch": 27, "training_loss": 69.37454390525818, "training_acc": 59.0, "val_loss": 18.339934945106506, "val_acc": 52.0}
{"epoch": 28, "training_loss": 66.27908444404602, "training_acc": 57.0, "val_loss": 17.809435725212097, "val_acc": 52.0}
{"epoch": 29, "training_loss": 65.12469220161438, "training_acc": 62.0, "val_loss": 17.381608486175537, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.42277479171753, "training_acc": 52.0, "val_loss": 17.18645691871643, "val_acc": 52.0}
{"epoch": 31, "training_loss": 63.95996594429016, "training_acc": 63.0, "val_loss": 17.46010184288025, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.15795183181763, "training_acc": 57.0, "val_loss": 17.143632471561432, "val_acc": 52.0}
{"epoch": 33, "training_loss": 62.361183404922485, "training_acc": 69.0, "val_loss": 18.345800042152405, "val_acc": 52.0}
{"epoch": 34, "training_loss": 64.45191025733948, "training_acc": 56.0, "val_loss": 17.82538890838623, "val_acc": 72.0}
{"epoch": 35, "training_loss": 68.65677309036255, "training_acc": 54.0, "val_loss": 17.402644455432892, "val_acc": 52.0}
{"epoch": 36, "training_loss": 63.4766001701355, "training_acc": 64.0, "val_loss": 18.92111599445343, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.81156897544861, "training_acc": 56.0, "val_loss": 17.840157449245453, "val_acc": 72.0}
{"epoch": 38, "training_loss": 65.38399338722229, "training_acc": 60.0, "val_loss": 17.701347172260284, "val_acc": 52.0}
{"epoch": 39, "training_loss": 67.03256583213806, "training_acc": 56.0, "val_loss": 17.294257879257202, "val_acc": 52.0}
{"epoch": 40, "training_loss": 61.60737228393555, "training_acc": 70.0, "val_loss": 17.322154343128204, "val_acc": 60.0}
