"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 906294.4886779785, "training_acc": 51.0, "val_loss": 188180.46875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 948701.546875, "training_acc": 49.0, "val_loss": 407452.9296875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1522593.203125, "training_acc": 47.0, "val_loss": 98616.27807617188, "val_acc": 48.0}
{"epoch": 3, "training_loss": 578784.3515625, "training_acc": 45.0, "val_loss": 320174.12109375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1278370.31640625, "training_acc": 53.0, "val_loss": 269949.12109375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 860482.822265625, "training_acc": 53.0, "val_loss": 70321.76513671875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 411443.1015625, "training_acc": 47.0, "val_loss": 158275.4638671875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 522837.6533203125, "training_acc": 47.0, "val_loss": 76719.54345703125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 348459.9501953125, "training_acc": 53.0, "val_loss": 124193.10302734375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 403184.61767578125, "training_acc": 53.0, "val_loss": 65987.09106445312, "val_acc": 48.0}
{"epoch": 10, "training_loss": 313052.42578125, "training_acc": 47.0, "val_loss": 57409.527587890625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 276109.7861328125, "training_acc": 39.0, "val_loss": 78813.36059570312, "val_acc": 52.0}
{"epoch": 12, "training_loss": 253289.56298828125, "training_acc": 53.0, "val_loss": 54719.44580078125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 270361.7529296875, "training_acc": 47.0, "val_loss": 29386.71875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 168055.47265625, "training_acc": 53.0, "val_loss": 120880.01708984375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 448749.095703125, "training_acc": 53.0, "val_loss": 34622.271728515625, "val_acc": 52.0}
{"epoch": 16, "training_loss": 244028.8125, "training_acc": 47.0, "val_loss": 138914.24560546875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 524592.376953125, "training_acc": 47.0, "val_loss": 20011.85302734375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 286286.671875, "training_acc": 39.0, "val_loss": 181202.1728515625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 702269.580078125, "training_acc": 53.0, "val_loss": 123209.4970703125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 334993.1103515625, "training_acc": 53.0, "val_loss": 135965.4052734375, "val_acc": 48.0}
{"epoch": 21, "training_loss": 649129.560546875, "training_acc": 47.0, "val_loss": 215547.2900390625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 790822.80078125, "training_acc": 47.0, "val_loss": 38659.60998535156, "val_acc": 48.0}
{"epoch": 23, "training_loss": 244887.166015625, "training_acc": 53.0, "val_loss": 214019.8486328125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 868542.91796875, "training_acc": 53.0, "val_loss": 218400.1220703125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 746801.896484375, "training_acc": 53.0, "val_loss": 23609.542846679688, "val_acc": 52.0}
{"epoch": 26, "training_loss": 261208.763671875, "training_acc": 53.0, "val_loss": 243267.4560546875, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1012193.88671875, "training_acc": 47.0, "val_loss": 214266.8701171875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 704745.7109375, "training_acc": 47.0, "val_loss": 46784.619140625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 307226.59375, "training_acc": 53.0, "val_loss": 152356.0791015625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 542053.537109375, "training_acc": 53.0, "val_loss": 31525.482177734375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 275328.896484375, "training_acc": 45.0, "val_loss": 169849.0234375, "val_acc": 48.0}
{"epoch": 32, "training_loss": 672439.216796875, "training_acc": 47.0, "val_loss": 77964.15405273438, "val_acc": 48.0}
{"epoch": 33, "training_loss": 252750.79931640625, "training_acc": 53.0, "val_loss": 111421.32568359375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 434042.9296875, "training_acc": 53.0, "val_loss": 62465.057373046875, "val_acc": 52.0}
{"epoch": 35, "training_loss": 161369.71069335938, "training_acc": 61.0, "val_loss": 72078.38745117188, "val_acc": 48.0}
{"epoch": 36, "training_loss": 252593.119140625, "training_acc": 47.0, "val_loss": 44865.19775390625, "val_acc": 52.0}
