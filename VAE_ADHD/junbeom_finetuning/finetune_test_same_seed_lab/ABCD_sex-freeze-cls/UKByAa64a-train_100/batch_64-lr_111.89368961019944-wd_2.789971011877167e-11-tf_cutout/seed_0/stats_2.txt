"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1096345.2534942627, "training_acc": 54.0, "val_loss": 219348.53515625, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1089517.125, "training_acc": 41.0, "val_loss": 330424.951171875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1225164.4296875, "training_acc": 47.0, "val_loss": 52019.866943359375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 531748.69921875, "training_acc": 41.0, "val_loss": 327437.6220703125, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1285772.67578125, "training_acc": 53.0, "val_loss": 272539.208984375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 893036.318359375, "training_acc": 53.0, "val_loss": 32679.910278320312, "val_acc": 48.0}
{"epoch": 6, "training_loss": 256208.064453125, "training_acc": 47.0, "val_loss": 108252.24609375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 328150.1745605469, "training_acc": 47.0, "val_loss": 120732.958984375, "val_acc": 52.0}
{"epoch": 8, "training_loss": 546977.08984375, "training_acc": 53.0, "val_loss": 168104.2724609375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 565521.185546875, "training_acc": 53.0, "val_loss": 21572.930908203125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 143163.205078125, "training_acc": 47.0, "val_loss": 29281.137084960938, "val_acc": 48.0}
{"epoch": 11, "training_loss": 147499.3916015625, "training_acc": 53.0, "val_loss": 87845.81298828125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 298681.6201171875, "training_acc": 53.0, "val_loss": 33396.112060546875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 149113.31689453125, "training_acc": 47.0, "val_loss": 13049.325561523438, "val_acc": 52.0}
{"epoch": 14, "training_loss": 42421.04113769531, "training_acc": 53.0, "val_loss": 63840.350341796875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 256675.4658203125, "training_acc": 47.0, "val_loss": 7531.584167480469, "val_acc": 52.0}
{"epoch": 16, "training_loss": 32796.80578613281, "training_acc": 53.0, "val_loss": 45651.007080078125, "val_acc": 48.0}
{"epoch": 17, "training_loss": 167119.705078125, "training_acc": 47.0, "val_loss": 45905.078125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 200786.0546875, "training_acc": 53.0, "val_loss": 20656.25, "val_acc": 52.0}
{"epoch": 19, "training_loss": 217035.6640625, "training_acc": 41.0, "val_loss": 98653.2470703125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 322371.7080078125, "training_acc": 47.0, "val_loss": 59446.234130859375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 296142.61328125, "training_acc": 53.0, "val_loss": 100639.453125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 305481.29541015625, "training_acc": 53.0, "val_loss": 69499.29809570312, "val_acc": 48.0}
{"epoch": 23, "training_loss": 363693.333984375, "training_acc": 47.0, "val_loss": 85311.65161132812, "val_acc": 48.0}
{"epoch": 24, "training_loss": 242530.62719726562, "training_acc": 47.0, "val_loss": 31374.313354492188, "val_acc": 52.0}
{"epoch": 25, "training_loss": 95816.05822753906, "training_acc": 45.0, "val_loss": 28813.48876953125, "val_acc": 52.0}
{"epoch": 26, "training_loss": 81498.98010253906, "training_acc": 53.0, "val_loss": 69659.52758789062, "val_acc": 48.0}
{"epoch": 27, "training_loss": 291047.4716796875, "training_acc": 47.0, "val_loss": 11148.796844482422, "val_acc": 48.0}
{"epoch": 28, "training_loss": 137984.86328125, "training_acc": 55.0, "val_loss": 148578.08837890625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 578844.451171875, "training_acc": 53.0, "val_loss": 86351.92260742188, "val_acc": 52.0}
{"epoch": 30, "training_loss": 260080.3486328125, "training_acc": 49.0, "val_loss": 62945.648193359375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 213906.97021484375, "training_acc": 47.0, "val_loss": 52337.59765625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 240250.5947265625, "training_acc": 53.0, "val_loss": 48118.93005371094, "val_acc": 52.0}
{"epoch": 33, "training_loss": 197798.54638671875, "training_acc": 45.0, "val_loss": 47601.129150390625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 142285.80029296875, "training_acc": 47.0, "val_loss": 3014.2948150634766, "val_acc": 52.0}
{"epoch": 35, "training_loss": 93990.3232421875, "training_acc": 51.0, "val_loss": 53516.71142578125, "val_acc": 48.0}
{"epoch": 36, "training_loss": 153319.82055664062, "training_acc": 51.0, "val_loss": 20621.058654785156, "val_acc": 52.0}
{"epoch": 37, "training_loss": 83827.4931640625, "training_acc": 53.0, "val_loss": 7941.642761230469, "val_acc": 48.0}
{"epoch": 38, "training_loss": 132199.0068359375, "training_acc": 45.0, "val_loss": 80559.8876953125, "val_acc": 52.0}
{"epoch": 39, "training_loss": 252683.9951171875, "training_acc": 53.0, "val_loss": 57715.234375, "val_acc": 48.0}
{"epoch": 40, "training_loss": 283207.3759765625, "training_acc": 47.0, "val_loss": 43944.71740722656, "val_acc": 48.0}
{"epoch": 41, "training_loss": 201976.8232421875, "training_acc": 47.0, "val_loss": 88384.02099609375, "val_acc": 52.0}
{"epoch": 42, "training_loss": 311316.6435546875, "training_acc": 53.0, "val_loss": 10250.228118896484, "val_acc": 48.0}
{"epoch": 43, "training_loss": 52663.29296875, "training_acc": 47.0, "val_loss": 35464.27917480469, "val_acc": 52.0}
{"epoch": 44, "training_loss": 132043.830078125, "training_acc": 53.0, "val_loss": 29262.936401367188, "val_acc": 48.0}
{"epoch": 45, "training_loss": 113780.859375, "training_acc": 47.0, "val_loss": 43317.47131347656, "val_acc": 52.0}
{"epoch": 46, "training_loss": 183365.4814453125, "training_acc": 53.0, "val_loss": 6934.358215332031, "val_acc": 52.0}
{"epoch": 47, "training_loss": 154728.5546875, "training_acc": 51.0, "val_loss": 122958.154296875, "val_acc": 48.0}
{"epoch": 48, "training_loss": 444242.3779296875, "training_acc": 47.0, "val_loss": 13766.551208496094, "val_acc": 52.0}
{"epoch": 49, "training_loss": 101577.00244140625, "training_acc": 53.0, "val_loss": 20626.280212402344, "val_acc": 52.0}
{"epoch": 50, "training_loss": 128753.626953125, "training_acc": 53.0, "val_loss": 70016.91284179688, "val_acc": 48.0}
{"epoch": 51, "training_loss": 206263.74267578125, "training_acc": 47.0, "val_loss": 88677.13623046875, "val_acc": 52.0}
{"epoch": 52, "training_loss": 429654.947265625, "training_acc": 53.0, "val_loss": 114390.3564453125, "val_acc": 52.0}
{"epoch": 53, "training_loss": 337027.9365234375, "training_acc": 53.0, "val_loss": 82378.43627929688, "val_acc": 48.0}
