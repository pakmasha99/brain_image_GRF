"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 330925.6263961792, "training_acc": 51.0, "val_loss": 174531.89697265625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 575873.55859375, "training_acc": 47.0, "val_loss": 177404.18701171875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 807130.390625, "training_acc": 53.0, "val_loss": 145040.478515625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 436757.1552734375, "training_acc": 51.0, "val_loss": 97019.76928710938, "val_acc": 48.0}
{"epoch": 4, "training_loss": 285518.49670410156, "training_acc": 47.0, "val_loss": 139121.875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 592610.185546875, "training_acc": 53.0, "val_loss": 139018.5791015625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 403037.0275878906, "training_acc": 53.0, "val_loss": 151197.3876953125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 707278.4453125, "training_acc": 47.0, "val_loss": 193482.32421875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 627080.1142578125, "training_acc": 47.0, "val_loss": 75424.35913085938, "val_acc": 52.0}
{"epoch": 9, "training_loss": 344338.9462890625, "training_acc": 53.0, "val_loss": 151110.31494140625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 519196.537109375, "training_acc": 53.0, "val_loss": 2764.006805419922, "val_acc": 24.0}
{"epoch": 11, "training_loss": 94962.80297851562, "training_acc": 54.0, "val_loss": 91149.85961914062, "val_acc": 48.0}
{"epoch": 12, "training_loss": 269354.5529785156, "training_acc": 47.0, "val_loss": 98888.42163085938, "val_acc": 52.0}
{"epoch": 13, "training_loss": 439743.46484375, "training_acc": 53.0, "val_loss": 127783.2275390625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 394314.9208984375, "training_acc": 53.0, "val_loss": 74578.79028320312, "val_acc": 48.0}
{"epoch": 15, "training_loss": 373321.685546875, "training_acc": 47.0, "val_loss": 97974.87182617188, "val_acc": 48.0}
{"epoch": 16, "training_loss": 249849.9086303711, "training_acc": 46.0, "val_loss": 120182.99560546875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 523955.005859375, "training_acc": 53.0, "val_loss": 161162.65869140625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 539115.94921875, "training_acc": 53.0, "val_loss": 17667.587280273438, "val_acc": 48.0}
{"epoch": 19, "training_loss": 122467.556640625, "training_acc": 47.0, "val_loss": 27875.527954101562, "val_acc": 48.0}
{"epoch": 20, "training_loss": 112056.3203125, "training_acc": 59.0, "val_loss": 86674.45068359375, "val_acc": 52.0}
{"epoch": 21, "training_loss": 298471.90625, "training_acc": 53.0, "val_loss": 29061.361694335938, "val_acc": 48.0}
{"epoch": 22, "training_loss": 131340.43017578125, "training_acc": 47.0, "val_loss": 20833.58154296875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 77945.62353515625, "training_acc": 53.0, "val_loss": 47093.53942871094, "val_acc": 48.0}
{"epoch": 24, "training_loss": 164967.69384765625, "training_acc": 47.0, "val_loss": 38016.11633300781, "val_acc": 52.0}
{"epoch": 25, "training_loss": 172822.107421875, "training_acc": 53.0, "val_loss": 12940.219116210938, "val_acc": 48.0}
{"epoch": 26, "training_loss": 31566.343536376953, "training_acc": 49.0, "val_loss": 45215.61584472656, "val_acc": 52.0}
{"epoch": 27, "training_loss": 157062.951171875, "training_acc": 53.0, "val_loss": 40519.91271972656, "val_acc": 48.0}
{"epoch": 28, "training_loss": 152505.44775390625, "training_acc": 47.0, "val_loss": 30613.796997070312, "val_acc": 52.0}
{"epoch": 29, "training_loss": 121076.599609375, "training_acc": 53.0, "val_loss": 24102.9052734375, "val_acc": 48.0}
