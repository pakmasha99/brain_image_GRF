"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 427984.8751525879, "training_acc": 52.0, "val_loss": 142221.5087890625, "val_acc": 44.0}
{"epoch": 1, "training_loss": 436818.29296875, "training_acc": 48.0, "val_loss": 149598.291015625, "val_acc": 56.0}
{"epoch": 2, "training_loss": 693233.26171875, "training_acc": 52.0, "val_loss": 62905.096435546875, "val_acc": 56.0}
{"epoch": 3, "training_loss": 357783.134765625, "training_acc": 54.0, "val_loss": 240568.505859375, "val_acc": 44.0}
{"epoch": 4, "training_loss": 807941.259765625, "training_acc": 48.0, "val_loss": 20295.578002929688, "val_acc": 44.0}
{"epoch": 5, "training_loss": 375708.05859375, "training_acc": 44.0, "val_loss": 265382.2509765625, "val_acc": 56.0}
{"epoch": 6, "training_loss": 1160345.9296875, "training_acc": 52.0, "val_loss": 203679.9072265625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 708788.875, "training_acc": 52.0, "val_loss": 113558.31298828125, "val_acc": 44.0}
{"epoch": 8, "training_loss": 514326.05078125, "training_acc": 48.0, "val_loss": 219139.6728515625, "val_acc": 44.0}
{"epoch": 9, "training_loss": 715660.779296875, "training_acc": 48.0, "val_loss": 6450.325775146484, "val_acc": 44.0}
{"epoch": 10, "training_loss": 240384.806640625, "training_acc": 52.0, "val_loss": 229486.81640625, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1026878.51953125, "training_acc": 52.0, "val_loss": 201252.64892578125, "val_acc": 56.0}
{"epoch": 12, "training_loss": 717187.595703125, "training_acc": 52.0, "val_loss": 44556.57958984375, "val_acc": 44.0}
{"epoch": 13, "training_loss": 285048.62109375, "training_acc": 48.0, "val_loss": 134369.4091796875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 388810.25, "training_acc": 48.0, "val_loss": 63125.87890625, "val_acc": 56.0}
{"epoch": 15, "training_loss": 334660.31640625, "training_acc": 52.0, "val_loss": 98839.17236328125, "val_acc": 56.0}
{"epoch": 16, "training_loss": 335577.703125, "training_acc": 52.0, "val_loss": 85845.34301757812, "val_acc": 44.0}
{"epoch": 17, "training_loss": 381072.90625, "training_acc": 48.0, "val_loss": 108131.16455078125, "val_acc": 44.0}
{"epoch": 18, "training_loss": 262419.2861328125, "training_acc": 48.0, "val_loss": 116643.32275390625, "val_acc": 56.0}
{"epoch": 19, "training_loss": 606020.25, "training_acc": 52.0, "val_loss": 179917.37060546875, "val_acc": 56.0}
{"epoch": 20, "training_loss": 704722.447265625, "training_acc": 52.0, "val_loss": 32370.709228515625, "val_acc": 56.0}
{"epoch": 21, "training_loss": 298511.0859375, "training_acc": 46.0, "val_loss": 220152.6123046875, "val_acc": 44.0}
{"epoch": 22, "training_loss": 805142.904296875, "training_acc": 48.0, "val_loss": 152972.509765625, "val_acc": 44.0}
{"epoch": 23, "training_loss": 399639.0871582031, "training_acc": 48.0, "val_loss": 126532.421875, "val_acc": 56.0}
{"epoch": 24, "training_loss": 690774.58203125, "training_acc": 52.0, "val_loss": 223338.720703125, "val_acc": 56.0}
{"epoch": 25, "training_loss": 915676.439453125, "training_acc": 52.0, "val_loss": 103087.9150390625, "val_acc": 56.0}
{"epoch": 26, "training_loss": 245664.12231445312, "training_acc": 62.0, "val_loss": 100884.8388671875, "val_acc": 44.0}
{"epoch": 27, "training_loss": 369982.1259765625, "training_acc": 48.0, "val_loss": 38675.55236816406, "val_acc": 44.0}
{"epoch": 28, "training_loss": 171613.6767578125, "training_acc": 54.0, "val_loss": 112123.2421875, "val_acc": 56.0}
