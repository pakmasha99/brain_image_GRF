"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1195.442470550537, "training_acc": 45.0, "val_loss": 40.49614369869232, "val_acc": 36.0}
{"epoch": 1, "training_loss": 654.1864242553711, "training_acc": 54.0, "val_loss": 190.92990159988403, "val_acc": 52.0}
{"epoch": 2, "training_loss": 600.8011131286621, "training_acc": 59.0, "val_loss": 300.3300428390503, "val_acc": 48.0}
{"epoch": 3, "training_loss": 736.393009185791, "training_acc": 52.0, "val_loss": 222.50676155090332, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1048.643352508545, "training_acc": 53.0, "val_loss": 207.76610374450684, "val_acc": 52.0}
{"epoch": 5, "training_loss": 604.5670075416565, "training_acc": 51.0, "val_loss": 201.847243309021, "val_acc": 48.0}
{"epoch": 6, "training_loss": 577.6499557495117, "training_acc": 44.0, "val_loss": 44.16857957839966, "val_acc": 52.0}
{"epoch": 7, "training_loss": 240.27893161773682, "training_acc": 53.0, "val_loss": 73.88343811035156, "val_acc": 48.0}
{"epoch": 8, "training_loss": 217.32404470443726, "training_acc": 53.0, "val_loss": 82.89210200309753, "val_acc": 52.0}
{"epoch": 9, "training_loss": 345.8509187698364, "training_acc": 53.0, "val_loss": 53.22293043136597, "val_acc": 44.0}
{"epoch": 10, "training_loss": 216.7853889465332, "training_acc": 48.0, "val_loss": 89.80605602264404, "val_acc": 52.0}
{"epoch": 11, "training_loss": 341.8662357330322, "training_acc": 55.0, "val_loss": 20.921538770198822, "val_acc": 60.0}
{"epoch": 12, "training_loss": 158.03821182250977, "training_acc": 58.0, "val_loss": 27.006009221076965, "val_acc": 60.0}
{"epoch": 13, "training_loss": 150.7614769935608, "training_acc": 52.0, "val_loss": 25.13469159603119, "val_acc": 60.0}
{"epoch": 14, "training_loss": 114.7722635269165, "training_acc": 53.0, "val_loss": 34.3439906835556, "val_acc": 52.0}
{"epoch": 15, "training_loss": 130.5259552001953, "training_acc": 47.0, "val_loss": 28.65157127380371, "val_acc": 52.0}
{"epoch": 16, "training_loss": 114.39448738098145, "training_acc": 57.0, "val_loss": 23.907116055488586, "val_acc": 56.0}
{"epoch": 17, "training_loss": 99.86208820343018, "training_acc": 58.0, "val_loss": 24.36096966266632, "val_acc": 48.0}
{"epoch": 18, "training_loss": 90.32688069343567, "training_acc": 63.0, "val_loss": 29.691067337989807, "val_acc": 52.0}
{"epoch": 19, "training_loss": 176.0931911468506, "training_acc": 39.0, "val_loss": 48.93282353878021, "val_acc": 52.0}
{"epoch": 20, "training_loss": 140.15164184570312, "training_acc": 54.0, "val_loss": 67.92262196540833, "val_acc": 48.0}
{"epoch": 21, "training_loss": 211.31613540649414, "training_acc": 50.0, "val_loss": 90.5920147895813, "val_acc": 52.0}
{"epoch": 22, "training_loss": 264.5780110359192, "training_acc": 52.0, "val_loss": 64.62591886520386, "val_acc": 48.0}
{"epoch": 23, "training_loss": 249.61775398254395, "training_acc": 47.0, "val_loss": 100.72251558303833, "val_acc": 52.0}
{"epoch": 24, "training_loss": 332.50282192230225, "training_acc": 53.0, "val_loss": 22.76223748922348, "val_acc": 60.0}
{"epoch": 25, "training_loss": 123.12444019317627, "training_acc": 54.0, "val_loss": 56.84604048728943, "val_acc": 52.0}
{"epoch": 26, "training_loss": 161.94063806533813, "training_acc": 53.0, "val_loss": 69.10088062286377, "val_acc": 48.0}
{"epoch": 27, "training_loss": 217.07212686538696, "training_acc": 47.0, "val_loss": 119.99560594558716, "val_acc": 52.0}
{"epoch": 28, "training_loss": 471.85723304748535, "training_acc": 53.0, "val_loss": 54.298919439315796, "val_acc": 52.0}
{"epoch": 29, "training_loss": 332.19812202453613, "training_acc": 49.0, "val_loss": 208.96666049957275, "val_acc": 48.0}
{"epoch": 30, "training_loss": 620.8369750976562, "training_acc": 47.0, "val_loss": 94.68103051185608, "val_acc": 52.0}
