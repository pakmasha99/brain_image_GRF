"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76143.74797821045, "training_acc": 56.0, "val_loss": 10988.308715820312, "val_acc": 52.0}
{"epoch": 1, "training_loss": 88148.49609375, "training_acc": 53.0, "val_loss": 57407.183837890625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 216233.2041015625, "training_acc": 47.0, "val_loss": 22154.457092285156, "val_acc": 48.0}
{"epoch": 3, "training_loss": 73808.87805175781, "training_acc": 49.0, "val_loss": 25240.426635742188, "val_acc": 52.0}
{"epoch": 4, "training_loss": 100426.31396484375, "training_acc": 53.0, "val_loss": 19816.563415527344, "val_acc": 52.0}
{"epoch": 5, "training_loss": 50575.41174316406, "training_acc": 52.0, "val_loss": 20920.997619628906, "val_acc": 48.0}
{"epoch": 6, "training_loss": 100146.99658203125, "training_acc": 47.0, "val_loss": 32732.882690429688, "val_acc": 48.0}
{"epoch": 7, "training_loss": 115470.64111328125, "training_acc": 47.0, "val_loss": 7224.872589111328, "val_acc": 48.0}
{"epoch": 8, "training_loss": 38827.023681640625, "training_acc": 47.0, "val_loss": 28115.719604492188, "val_acc": 52.0}
{"epoch": 9, "training_loss": 117732.3349609375, "training_acc": 53.0, "val_loss": 29063.1591796875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 100813.46130371094, "training_acc": 53.0, "val_loss": 3429.5833587646484, "val_acc": 48.0}
{"epoch": 11, "training_loss": 33103.8525390625, "training_acc": 42.0, "val_loss": 25158.477783203125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 90890.35498046875, "training_acc": 47.0, "val_loss": 16129.995727539062, "val_acc": 48.0}
{"epoch": 13, "training_loss": 40798.48889160156, "training_acc": 47.0, "val_loss": 12067.388153076172, "val_acc": 52.0}
{"epoch": 14, "training_loss": 57721.351318359375, "training_acc": 53.0, "val_loss": 15722.489929199219, "val_acc": 52.0}
{"epoch": 15, "training_loss": 55577.00085449219, "training_acc": 55.0, "val_loss": 5554.090881347656, "val_acc": 44.0}
{"epoch": 16, "training_loss": 25921.128540039062, "training_acc": 54.0, "val_loss": 9514.26773071289, "val_acc": 48.0}
{"epoch": 17, "training_loss": 24721.114990234375, "training_acc": 50.0, "val_loss": 7956.352233886719, "val_acc": 52.0}
{"epoch": 18, "training_loss": 32517.014038085938, "training_acc": 55.0, "val_loss": 6224.67155456543, "val_acc": 52.0}
{"epoch": 19, "training_loss": 24694.051879882812, "training_acc": 43.0, "val_loss": 4441.324234008789, "val_acc": 48.0}
{"epoch": 20, "training_loss": 14229.774505615234, "training_acc": 47.0, "val_loss": 2803.683853149414, "val_acc": 52.0}
{"epoch": 21, "training_loss": 7236.351135253906, "training_acc": 58.0, "val_loss": 947.041130065918, "val_acc": 48.0}
{"epoch": 22, "training_loss": 6561.318695068359, "training_acc": 57.0, "val_loss": 2532.7733993530273, "val_acc": 60.0}
{"epoch": 23, "training_loss": 9464.6376953125, "training_acc": 50.0, "val_loss": 1151.0724067687988, "val_acc": 56.0}
{"epoch": 24, "training_loss": 10747.473449707031, "training_acc": 56.0, "val_loss": 5186.196136474609, "val_acc": 52.0}
{"epoch": 25, "training_loss": 11111.443603515625, "training_acc": 56.0, "val_loss": 2064.781951904297, "val_acc": 44.0}
{"epoch": 26, "training_loss": 11321.235260009766, "training_acc": 54.0, "val_loss": 5361.562728881836, "val_acc": 52.0}
{"epoch": 27, "training_loss": 9973.046585083008, "training_acc": 61.0, "val_loss": 5459.833526611328, "val_acc": 48.0}
{"epoch": 28, "training_loss": 23229.005859375, "training_acc": 47.0, "val_loss": 2619.71378326416, "val_acc": 52.0}
{"epoch": 29, "training_loss": 9443.302429199219, "training_acc": 55.0, "val_loss": 1010.8222961425781, "val_acc": 52.0}
{"epoch": 30, "training_loss": 6140.019287109375, "training_acc": 65.0, "val_loss": 973.1185913085938, "val_acc": 52.0}
{"epoch": 31, "training_loss": 6847.230133056641, "training_acc": 67.0, "val_loss": 967.4680709838867, "val_acc": 52.0}
{"epoch": 32, "training_loss": 4375.62385559082, "training_acc": 54.0, "val_loss": 1475.4645347595215, "val_acc": 56.0}
{"epoch": 33, "training_loss": 4943.165344238281, "training_acc": 64.0, "val_loss": 2412.3016357421875, "val_acc": 48.0}
{"epoch": 34, "training_loss": 7554.232757568359, "training_acc": 54.0, "val_loss": 3929.736328125, "val_acc": 52.0}
{"epoch": 35, "training_loss": 9512.100357055664, "training_acc": 54.0, "val_loss": 4450.572967529297, "val_acc": 48.0}
{"epoch": 36, "training_loss": 17190.495483398438, "training_acc": 48.0, "val_loss": 5951.077651977539, "val_acc": 52.0}
{"epoch": 37, "training_loss": 22130.605834960938, "training_acc": 53.0, "val_loss": 3264.322280883789, "val_acc": 52.0}
{"epoch": 38, "training_loss": 17136.521484375, "training_acc": 51.0, "val_loss": 8903.95278930664, "val_acc": 48.0}
{"epoch": 39, "training_loss": 29447.373443603516, "training_acc": 47.0, "val_loss": 9659.552764892578, "val_acc": 52.0}
{"epoch": 40, "training_loss": 36276.06994628906, "training_acc": 53.0, "val_loss": 12223.787689208984, "val_acc": 52.0}
