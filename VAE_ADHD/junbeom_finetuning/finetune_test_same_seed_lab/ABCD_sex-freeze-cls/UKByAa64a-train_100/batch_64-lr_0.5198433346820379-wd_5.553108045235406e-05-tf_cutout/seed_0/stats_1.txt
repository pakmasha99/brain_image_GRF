"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1136.216480255127, "training_acc": 46.0, "val_loss": 228.05745601654053, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1108.4473037719727, "training_acc": 53.0, "val_loss": 591.1495208740234, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2224.4051361083984, "training_acc": 47.0, "val_loss": 163.9291286468506, "val_acc": 48.0}
{"epoch": 3, "training_loss": 774.9487686157227, "training_acc": 51.0, "val_loss": 431.5094470977783, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1640.0221328735352, "training_acc": 53.0, "val_loss": 385.0193977355957, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1143.1299438476562, "training_acc": 53.0, "val_loss": 67.21355319023132, "val_acc": 48.0}
{"epoch": 6, "training_loss": 618.4758262634277, "training_acc": 47.0, "val_loss": 198.82420301437378, "val_acc": 48.0}
{"epoch": 7, "training_loss": 674.852786064148, "training_acc": 47.0, "val_loss": 140.32940864562988, "val_acc": 52.0}
{"epoch": 8, "training_loss": 547.3126316070557, "training_acc": 53.0, "val_loss": 242.79580116271973, "val_acc": 52.0}
{"epoch": 9, "training_loss": 784.4481315612793, "training_acc": 53.0, "val_loss": 27.88664996623993, "val_acc": 52.0}
{"epoch": 10, "training_loss": 301.74987602233887, "training_acc": 52.0, "val_loss": 190.08089303970337, "val_acc": 48.0}
{"epoch": 11, "training_loss": 699.5474491119385, "training_acc": 47.0, "val_loss": 29.222843050956726, "val_acc": 52.0}
{"epoch": 12, "training_loss": 185.59767150878906, "training_acc": 55.0, "val_loss": 88.29749822616577, "val_acc": 52.0}
{"epoch": 13, "training_loss": 193.94731211662292, "training_acc": 61.0, "val_loss": 98.19157123565674, "val_acc": 48.0}
{"epoch": 14, "training_loss": 409.5636215209961, "training_acc": 47.0, "val_loss": 17.7274227142334, "val_acc": 60.0}
{"epoch": 15, "training_loss": 162.3548641204834, "training_acc": 62.0, "val_loss": 128.9035201072693, "val_acc": 52.0}
{"epoch": 16, "training_loss": 370.5408601760864, "training_acc": 53.0, "val_loss": 55.84641098976135, "val_acc": 48.0}
{"epoch": 17, "training_loss": 300.5724973678589, "training_acc": 47.0, "val_loss": 21.138370037078857, "val_acc": 48.0}
{"epoch": 18, "training_loss": 119.12669801712036, "training_acc": 59.0, "val_loss": 136.12868785858154, "val_acc": 52.0}
{"epoch": 19, "training_loss": 388.18723487854004, "training_acc": 53.0, "val_loss": 17.029471695423126, "val_acc": 64.0}
{"epoch": 20, "training_loss": 163.96024703979492, "training_acc": 60.0, "val_loss": 38.45432698726654, "val_acc": 48.0}
{"epoch": 21, "training_loss": 238.3424859046936, "training_acc": 50.0, "val_loss": 86.57114505767822, "val_acc": 52.0}
{"epoch": 22, "training_loss": 226.46043252944946, "training_acc": 49.0, "val_loss": 24.16084259748459, "val_acc": 40.0}
{"epoch": 23, "training_loss": 135.11864495277405, "training_acc": 52.0, "val_loss": 44.415098428726196, "val_acc": 52.0}
{"epoch": 24, "training_loss": 115.16358375549316, "training_acc": 56.0, "val_loss": 18.440480530261993, "val_acc": 56.0}
{"epoch": 25, "training_loss": 101.6072564125061, "training_acc": 66.0, "val_loss": 32.56179690361023, "val_acc": 52.0}
{"epoch": 26, "training_loss": 111.84137082099915, "training_acc": 56.0, "val_loss": 19.893847405910492, "val_acc": 48.0}
{"epoch": 27, "training_loss": 77.89923977851868, "training_acc": 65.0, "val_loss": 18.69564801454544, "val_acc": 60.0}
{"epoch": 28, "training_loss": 77.31951832771301, "training_acc": 59.0, "val_loss": 18.978919088840485, "val_acc": 60.0}
{"epoch": 29, "training_loss": 70.3965973854065, "training_acc": 62.0, "val_loss": 52.689534425735474, "val_acc": 52.0}
{"epoch": 30, "training_loss": 141.8248143196106, "training_acc": 53.0, "val_loss": 38.437628746032715, "val_acc": 48.0}
{"epoch": 31, "training_loss": 131.90829062461853, "training_acc": 55.0, "val_loss": 73.56483340263367, "val_acc": 52.0}
{"epoch": 32, "training_loss": 211.2882843017578, "training_acc": 54.0, "val_loss": 26.708519458770752, "val_acc": 44.0}
{"epoch": 33, "training_loss": 142.99790716171265, "training_acc": 46.0, "val_loss": 48.90141189098358, "val_acc": 52.0}
{"epoch": 34, "training_loss": 147.60754013061523, "training_acc": 53.0, "val_loss": 40.45594334602356, "val_acc": 48.0}
{"epoch": 35, "training_loss": 189.65690660476685, "training_acc": 47.0, "val_loss": 56.15577697753906, "val_acc": 52.0}
{"epoch": 36, "training_loss": 166.72460794448853, "training_acc": 54.0, "val_loss": 22.679392993450165, "val_acc": 48.0}
{"epoch": 37, "training_loss": 108.499436378479, "training_acc": 49.0, "val_loss": 48.71016442775726, "val_acc": 52.0}
{"epoch": 38, "training_loss": 133.36651468276978, "training_acc": 55.0, "val_loss": 51.94263458251953, "val_acc": 48.0}
