"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 6045.526287078857, "training_acc": 47.0, "val_loss": 1465.1500701904297, "val_acc": 52.0}
{"epoch": 1, "training_loss": 6402.188903808594, "training_acc": 51.0, "val_loss": 2647.59521484375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 9640.61441040039, "training_acc": 47.0, "val_loss": 313.7716054916382, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2863.5863037109375, "training_acc": 53.0, "val_loss": 2825.650405883789, "val_acc": 52.0}
{"epoch": 4, "training_loss": 11162.54946899414, "training_acc": 53.0, "val_loss": 2590.242576599121, "val_acc": 52.0}
{"epoch": 5, "training_loss": 8762.732543945312, "training_acc": 53.0, "val_loss": 331.01274967193604, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2441.061752319336, "training_acc": 59.0, "val_loss": 2481.142234802246, "val_acc": 48.0}
{"epoch": 7, "training_loss": 10174.95962524414, "training_acc": 47.0, "val_loss": 2360.2453231811523, "val_acc": 48.0}
{"epoch": 8, "training_loss": 8073.867935180664, "training_acc": 47.0, "val_loss": 154.4598937034607, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1964.5025787353516, "training_acc": 58.0, "val_loss": 2175.788116455078, "val_acc": 52.0}
{"epoch": 10, "training_loss": 9045.119537353516, "training_acc": 53.0, "val_loss": 2311.977005004883, "val_acc": 52.0}
{"epoch": 11, "training_loss": 8085.932479858398, "training_acc": 53.0, "val_loss": 661.5083694458008, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2979.5843048095703, "training_acc": 45.0, "val_loss": 1433.719539642334, "val_acc": 48.0}
{"epoch": 13, "training_loss": 5651.548645019531, "training_acc": 47.0, "val_loss": 1109.614372253418, "val_acc": 48.0}
{"epoch": 14, "training_loss": 3036.532688140869, "training_acc": 46.0, "val_loss": 898.1770515441895, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4139.016571044922, "training_acc": 53.0, "val_loss": 1575.4799842834473, "val_acc": 52.0}
{"epoch": 16, "training_loss": 5731.079544067383, "training_acc": 53.0, "val_loss": 620.4402923583984, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1534.6215362548828, "training_acc": 61.0, "val_loss": 915.7635688781738, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3696.461959838867, "training_acc": 47.0, "val_loss": 428.28569412231445, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1491.314640045166, "training_acc": 52.0, "val_loss": 851.7560005187988, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3340.999465942383, "training_acc": 53.0, "val_loss": 369.60911750793457, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1150.9439392089844, "training_acc": 60.0, "val_loss": 886.8447303771973, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3447.3184509277344, "training_acc": 47.0, "val_loss": 221.12109661102295, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1276.129035949707, "training_acc": 54.0, "val_loss": 1105.340576171875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 4190.141204833984, "training_acc": 53.0, "val_loss": 703.6532878875732, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1842.5911560058594, "training_acc": 55.0, "val_loss": 671.5452671051025, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2939.01806640625, "training_acc": 47.0, "val_loss": 244.80254650115967, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1248.6626510620117, "training_acc": 58.0, "val_loss": 802.3595809936523, "val_acc": 52.0}
