"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 7319.839225769043, "training_acc": 45.0, "val_loss": 1264.6367073059082, "val_acc": 48.0}
{"epoch": 1, "training_loss": 5443.180328369141, "training_acc": 55.0, "val_loss": 3590.1962280273438, "val_acc": 52.0}
{"epoch": 2, "training_loss": 13956.236389160156, "training_acc": 53.0, "val_loss": 2656.092643737793, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8148.241653442383, "training_acc": 53.0, "val_loss": 1034.4715118408203, "val_acc": 48.0}
{"epoch": 4, "training_loss": 5583.306854248047, "training_acc": 47.0, "val_loss": 2090.6105041503906, "val_acc": 48.0}
{"epoch": 5, "training_loss": 7361.822738647461, "training_acc": 47.0, "val_loss": 122.33102321624756, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2540.0281677246094, "training_acc": 47.0, "val_loss": 2245.4879760742188, "val_acc": 52.0}
{"epoch": 7, "training_loss": 8998.912109375, "training_acc": 53.0, "val_loss": 2134.072685241699, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7214.701904296875, "training_acc": 53.0, "val_loss": 241.1536455154419, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2188.8214721679688, "training_acc": 53.0, "val_loss": 2113.1982803344727, "val_acc": 48.0}
{"epoch": 10, "training_loss": 8590.229919433594, "training_acc": 47.0, "val_loss": 1932.2273254394531, "val_acc": 48.0}
{"epoch": 11, "training_loss": 6122.73127746582, "training_acc": 47.0, "val_loss": 160.03063917160034, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1642.0537414550781, "training_acc": 53.0, "val_loss": 944.8732376098633, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3406.9066467285156, "training_acc": 53.0, "val_loss": 67.17770099639893, "val_acc": 60.0}
{"epoch": 14, "training_loss": 812.9112930297852, "training_acc": 54.0, "val_loss": 540.9056663513184, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1360.8917903900146, "training_acc": 54.0, "val_loss": 492.64612197875977, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2161.0990447998047, "training_acc": 53.0, "val_loss": 294.6671962738037, "val_acc": 52.0}
{"epoch": 17, "training_loss": 958.3504524230957, "training_acc": 55.0, "val_loss": 572.730016708374, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1841.4991607666016, "training_acc": 46.0, "val_loss": 398.97093772888184, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1761.0379257202148, "training_acc": 53.0, "val_loss": 347.91204929351807, "val_acc": 52.0}
{"epoch": 20, "training_loss": 934.43577003479, "training_acc": 58.0, "val_loss": 433.5789680480957, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1403.4028339385986, "training_acc": 53.0, "val_loss": 309.78236198425293, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1220.1027793884277, "training_acc": 53.0, "val_loss": 82.11014866828918, "val_acc": 64.0}
{"epoch": 23, "training_loss": 692.6530380249023, "training_acc": 60.0, "val_loss": 96.05891108512878, "val_acc": 56.0}
{"epoch": 24, "training_loss": 756.738452911377, "training_acc": 57.0, "val_loss": 207.55984783172607, "val_acc": 52.0}
{"epoch": 25, "training_loss": 572.8365936279297, "training_acc": 61.0, "val_loss": 264.29688930511475, "val_acc": 44.0}
{"epoch": 26, "training_loss": 815.4832706451416, "training_acc": 55.0, "val_loss": 407.2868824005127, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1351.4580879211426, "training_acc": 54.0, "val_loss": 65.8401608467102, "val_acc": 56.0}
{"epoch": 28, "training_loss": 311.67762565612793, "training_acc": 67.0, "val_loss": 65.69295525550842, "val_acc": 56.0}
{"epoch": 29, "training_loss": 541.1265716552734, "training_acc": 54.0, "val_loss": 104.5177698135376, "val_acc": 56.0}
{"epoch": 30, "training_loss": 636.8868103027344, "training_acc": 54.0, "val_loss": 265.17412662506104, "val_acc": 48.0}
{"epoch": 31, "training_loss": 667.3709297180176, "training_acc": 60.0, "val_loss": 262.4969482421875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 534.2258539199829, "training_acc": 56.0, "val_loss": 212.15949058532715, "val_acc": 48.0}
{"epoch": 33, "training_loss": 600.9582347869873, "training_acc": 57.0, "val_loss": 211.28270626068115, "val_acc": 52.0}
{"epoch": 34, "training_loss": 556.1449546813965, "training_acc": 49.0, "val_loss": 102.7405858039856, "val_acc": 56.0}
{"epoch": 35, "training_loss": 182.04167127609253, "training_acc": 67.0, "val_loss": 104.42553758621216, "val_acc": 48.0}
{"epoch": 36, "training_loss": 524.9195594787598, "training_acc": 47.0, "val_loss": 62.48800754547119, "val_acc": 60.0}
{"epoch": 37, "training_loss": 335.5875720977783, "training_acc": 62.0, "val_loss": 57.93607831001282, "val_acc": 52.0}
{"epoch": 38, "training_loss": 312.446382522583, "training_acc": 67.0, "val_loss": 37.7652108669281, "val_acc": 60.0}
{"epoch": 39, "training_loss": 163.90925550460815, "training_acc": 67.0, "val_loss": 259.45024490356445, "val_acc": 52.0}
{"epoch": 40, "training_loss": 542.2400040626526, "training_acc": 61.0, "val_loss": 245.68612575531006, "val_acc": 48.0}
{"epoch": 41, "training_loss": 774.9678792953491, "training_acc": 56.0, "val_loss": 389.76454734802246, "val_acc": 52.0}
{"epoch": 42, "training_loss": 1203.9731330871582, "training_acc": 54.0, "val_loss": 129.41662073135376, "val_acc": 48.0}
{"epoch": 43, "training_loss": 462.7083740234375, "training_acc": 50.0, "val_loss": 396.8322992324829, "val_acc": 52.0}
{"epoch": 44, "training_loss": 1256.4273567199707, "training_acc": 53.0, "val_loss": 105.05615472793579, "val_acc": 52.0}
{"epoch": 45, "training_loss": 399.02992725372314, "training_acc": 47.0, "val_loss": 403.5162925720215, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1234.7111549377441, "training_acc": 53.0, "val_loss": 131.4117193222046, "val_acc": 44.0}
{"epoch": 47, "training_loss": 407.7920923233032, "training_acc": 53.0, "val_loss": 239.87047672271729, "val_acc": 52.0}
{"epoch": 48, "training_loss": 655.8568353652954, "training_acc": 58.0, "val_loss": 297.76344299316406, "val_acc": 48.0}
{"epoch": 49, "training_loss": 846.882312297821, "training_acc": 49.0, "val_loss": 340.21239280700684, "val_acc": 52.0}
{"epoch": 50, "training_loss": 869.2472305297852, "training_acc": 53.0, "val_loss": 337.5617504119873, "val_acc": 48.0}
{"epoch": 51, "training_loss": 1265.0429496765137, "training_acc": 47.0, "val_loss": 241.0843849182129, "val_acc": 52.0}
{"epoch": 52, "training_loss": 682.802059173584, "training_acc": 52.0, "val_loss": 40.35422503948212, "val_acc": 56.0}
{"epoch": 53, "training_loss": 291.35431385040283, "training_acc": 67.0, "val_loss": 159.99526977539062, "val_acc": 52.0}
{"epoch": 54, "training_loss": 236.04360628128052, "training_acc": 63.0, "val_loss": 83.32276940345764, "val_acc": 56.0}
{"epoch": 55, "training_loss": 503.0558052062988, "training_acc": 53.0, "val_loss": 143.07966232299805, "val_acc": 52.0}
{"epoch": 56, "training_loss": 715.4021072387695, "training_acc": 53.0, "val_loss": 154.040265083313, "val_acc": 48.0}
{"epoch": 57, "training_loss": 773.5252532958984, "training_acc": 54.0, "val_loss": 526.7673015594482, "val_acc": 52.0}
