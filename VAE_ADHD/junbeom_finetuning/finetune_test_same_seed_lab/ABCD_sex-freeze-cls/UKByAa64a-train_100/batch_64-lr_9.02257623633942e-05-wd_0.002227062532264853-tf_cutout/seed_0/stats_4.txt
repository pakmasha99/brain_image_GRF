"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.22257328033447, "training_acc": 47.0, "val_loss": 17.465758323669434, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.15607619285583, "training_acc": 47.0, "val_loss": 17.443111538887024, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.96268486976624, "training_acc": 47.0, "val_loss": 17.42188036441803, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.82013821601868, "training_acc": 47.0, "val_loss": 17.403967678546906, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.79690551757812, "training_acc": 47.0, "val_loss": 17.388145625591278, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.67912793159485, "training_acc": 47.0, "val_loss": 17.37263947725296, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.57372784614563, "training_acc": 47.0, "val_loss": 17.358896136283875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.59634327888489, "training_acc": 47.0, "val_loss": 17.346900701522827, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.37050271034241, "training_acc": 47.0, "val_loss": 17.336975038051605, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.4201123714447, "training_acc": 48.0, "val_loss": 17.328421771526337, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.10236835479736, "training_acc": 57.0, "val_loss": 17.320656776428223, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.45710682868958, "training_acc": 46.0, "val_loss": 17.314544320106506, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25440669059753, "training_acc": 49.0, "val_loss": 17.30983704328537, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.44575905799866, "training_acc": 47.0, "val_loss": 17.306233942508698, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19491600990295, "training_acc": 57.0, "val_loss": 17.303569614887238, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.04190301895142, "training_acc": 57.0, "val_loss": 17.30165183544159, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1338062286377, "training_acc": 55.0, "val_loss": 17.3004150390625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.0427176952362, "training_acc": 54.0, "val_loss": 17.29978173971176, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2091634273529, "training_acc": 54.0, "val_loss": 17.299671471118927, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.23186182975769, "training_acc": 52.0, "val_loss": 17.299911379814148, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21365404129028, "training_acc": 53.0, "val_loss": 17.300456762313843, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26119995117188, "training_acc": 52.0, "val_loss": 17.30111539363861, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.31868243217468, "training_acc": 53.0, "val_loss": 17.302168905735016, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.03983759880066, "training_acc": 53.0, "val_loss": 17.30305254459381, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.27924132347107, "training_acc": 53.0, "val_loss": 17.30370670557022, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20282292366028, "training_acc": 53.0, "val_loss": 17.30406880378723, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2428092956543, "training_acc": 53.0, "val_loss": 17.303988337516785, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.036616563797, "training_acc": 53.0, "val_loss": 17.304059863090515, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27076292037964, "training_acc": 53.0, "val_loss": 17.304274439811707, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.90025782585144, "training_acc": 53.0, "val_loss": 17.303837835788727, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19881939888, "training_acc": 53.0, "val_loss": 17.30344146490097, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.22192335128784, "training_acc": 53.0, "val_loss": 17.303316295146942, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.04799795150757, "training_acc": 53.0, "val_loss": 17.30307787656784, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19795322418213, "training_acc": 53.0, "val_loss": 17.303340137004852, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.98498511314392, "training_acc": 53.0, "val_loss": 17.303940653800964, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.35303378105164, "training_acc": 53.0, "val_loss": 17.30424612760544, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.07578992843628, "training_acc": 53.0, "val_loss": 17.304232716560364, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.10454034805298, "training_acc": 53.0, "val_loss": 17.304058372974396, "val_acc": 52.0}
