"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.18768095970154, "training_acc": 47.0, "val_loss": 17.65230894088745, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.89372873306274, "training_acc": 47.0, "val_loss": 17.61651784181595, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.64588761329651, "training_acc": 47.0, "val_loss": 17.58008748292923, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.56282830238342, "training_acc": 47.0, "val_loss": 17.54510849714279, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.2274522781372, "training_acc": 47.0, "val_loss": 17.512759566307068, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.22243094444275, "training_acc": 47.0, "val_loss": 17.48385727405548, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.20092988014221, "training_acc": 47.0, "val_loss": 17.457443475723267, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.96959638595581, "training_acc": 47.0, "val_loss": 17.433714866638184, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.76906204223633, "training_acc": 47.0, "val_loss": 17.41306483745575, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.7286868095398, "training_acc": 47.0, "val_loss": 17.39613264799118, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.60448026657104, "training_acc": 47.0, "val_loss": 17.38045960664749, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.5898220539093, "training_acc": 47.0, "val_loss": 17.36653298139572, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.58044409751892, "training_acc": 47.0, "val_loss": 17.355503141880035, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.361661195755, "training_acc": 47.0, "val_loss": 17.347684502601624, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.37241005897522, "training_acc": 47.0, "val_loss": 17.341776192188263, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21359729766846, "training_acc": 51.0, "val_loss": 17.336739599704742, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14861631393433, "training_acc": 59.0, "val_loss": 17.332595586776733, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2084424495697, "training_acc": 54.0, "val_loss": 17.329658567905426, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.21473240852356, "training_acc": 53.0, "val_loss": 17.32756346464157, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14404773712158, "training_acc": 53.0, "val_loss": 17.326755821704865, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.20509886741638, "training_acc": 52.0, "val_loss": 17.326968908309937, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.30616807937622, "training_acc": 53.0, "val_loss": 17.327380180358887, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17077326774597, "training_acc": 52.0, "val_loss": 17.32816994190216, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13517498970032, "training_acc": 53.0, "val_loss": 17.32906997203827, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.04866528511047, "training_acc": 53.0, "val_loss": 17.329993844032288, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.99514484405518, "training_acc": 53.0, "val_loss": 17.331083118915558, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.98316884040833, "training_acc": 53.0, "val_loss": 17.332221567630768, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20707821846008, "training_acc": 53.0, "val_loss": 17.333461344242096, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14548063278198, "training_acc": 53.0, "val_loss": 17.33444780111313, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.0337450504303, "training_acc": 53.0, "val_loss": 17.33551323413849, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.92994999885559, "training_acc": 53.0, "val_loss": 17.337316274642944, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1069233417511, "training_acc": 53.0, "val_loss": 17.33890473842621, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.04942011833191, "training_acc": 53.0, "val_loss": 17.34038144350052, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.01864838600159, "training_acc": 53.0, "val_loss": 17.34205186367035, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12398266792297, "training_acc": 53.0, "val_loss": 17.343193292617798, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16922426223755, "training_acc": 53.0, "val_loss": 17.344318330287933, "val_acc": 52.0}
{"epoch": 36, "training_loss": 68.99068808555603, "training_acc": 53.0, "val_loss": 17.345695197582245, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.89246702194214, "training_acc": 53.0, "val_loss": 17.346173524856567, "val_acc": 52.0}
{"epoch": 38, "training_loss": 68.90821981430054, "training_acc": 53.0, "val_loss": 17.346909642219543, "val_acc": 52.0}
