"main_optuna_fix.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23760318756104, "training_acc": 54.0, "val_loss": 17.394548654556274, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.3662531375885, "training_acc": 53.0, "val_loss": 17.370043694972992, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.44605755805969, "training_acc": 45.0, "val_loss": 17.353156208992004, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.14475131034851, "training_acc": 55.0, "val_loss": 17.34205335378647, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.15596461296082, "training_acc": 52.0, "val_loss": 17.33476221561432, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.37714624404907, "training_acc": 51.0, "val_loss": 17.327140271663666, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27081751823425, "training_acc": 51.0, "val_loss": 17.323680222034454, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.34156370162964, "training_acc": 50.0, "val_loss": 17.319385707378387, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.28450107574463, "training_acc": 51.0, "val_loss": 17.313864827156067, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2768657207489, "training_acc": 52.0, "val_loss": 17.31223315000534, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.24507904052734, "training_acc": 51.0, "val_loss": 17.310824990272522, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.37827658653259, "training_acc": 51.0, "val_loss": 17.308373749256134, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.1725857257843, "training_acc": 52.0, "val_loss": 17.306527495384216, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.28579258918762, "training_acc": 52.0, "val_loss": 17.30605661869049, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.13349199295044, "training_acc": 52.0, "val_loss": 17.304551601409912, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.23896479606628, "training_acc": 53.0, "val_loss": 17.30206608772278, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25680088996887, "training_acc": 52.0, "val_loss": 17.29777753353119, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.40458679199219, "training_acc": 52.0, "val_loss": 17.294849455356598, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2597439289093, "training_acc": 52.0, "val_loss": 17.292174696922302, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.01286435127258, "training_acc": 52.0, "val_loss": 17.289458215236664, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.215571641922, "training_acc": 52.0, "val_loss": 17.28850156068802, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21075940132141, "training_acc": 52.0, "val_loss": 17.28728860616684, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.30302834510803, "training_acc": 52.0, "val_loss": 17.285071313381195, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.133469581604, "training_acc": 52.0, "val_loss": 17.28517711162567, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.34053778648376, "training_acc": 52.0, "val_loss": 17.286765575408936, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.27533841133118, "training_acc": 52.0, "val_loss": 17.289699614048004, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.94445872306824, "training_acc": 52.0, "val_loss": 17.290519177913666, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.31612181663513, "training_acc": 52.0, "val_loss": 17.295067012310028, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.11273908615112, "training_acc": 52.0, "val_loss": 17.299804091453552, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.22675371170044, "training_acc": 52.0, "val_loss": 17.302711308002472, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.11521100997925, "training_acc": 52.0, "val_loss": 17.30387508869171, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27223658561707, "training_acc": 52.0, "val_loss": 17.30770766735077, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.3279116153717, "training_acc": 52.0, "val_loss": 17.308497428894043, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.87638878822327, "training_acc": 52.0, "val_loss": 17.309489846229553, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.1608898639679, "training_acc": 52.0, "val_loss": 17.30940192937851, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23305058479309, "training_acc": 52.0, "val_loss": 17.310327291488647, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.14642286300659, "training_acc": 52.0, "val_loss": 17.310696840286255, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.21454548835754, "training_acc": 52.0, "val_loss": 17.310041189193726, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.11626029014587, "training_acc": 52.0, "val_loss": 17.307159304618835, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.10716104507446, "training_acc": 52.0, "val_loss": 17.302532494068146, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.09511160850525, "training_acc": 52.0, "val_loss": 17.30043888092041, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.11020135879517, "training_acc": 52.0, "val_loss": 17.299284040927887, "val_acc": 56.0}
