"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.42798638343811, "training_acc": 50.0, "val_loss": 17.51839369535446, "val_acc": 56.0}
{"epoch": 1, "training_loss": 70.27593636512756, "training_acc": 48.0, "val_loss": 17.458397150039673, "val_acc": 56.0}
{"epoch": 2, "training_loss": 72.0071918964386, "training_acc": 52.0, "val_loss": 17.169971764087677, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.35689854621887, "training_acc": 52.0, "val_loss": 17.664897441864014, "val_acc": 56.0}
{"epoch": 4, "training_loss": 70.51377940177917, "training_acc": 48.0, "val_loss": 18.231788277626038, "val_acc": 56.0}
{"epoch": 5, "training_loss": 71.43467450141907, "training_acc": 48.0, "val_loss": 17.530860006809235, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.50550889968872, "training_acc": 50.0, "val_loss": 17.15957671403885, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.3642270565033, "training_acc": 52.0, "val_loss": 17.17572510242462, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.42114448547363, "training_acc": 52.0, "val_loss": 17.1535924077034, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.51461029052734, "training_acc": 52.0, "val_loss": 17.330922186374664, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.49852108955383, "training_acc": 46.0, "val_loss": 17.724303901195526, "val_acc": 56.0}
{"epoch": 11, "training_loss": 70.12345266342163, "training_acc": 48.0, "val_loss": 17.56647378206253, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.78113102912903, "training_acc": 48.0, "val_loss": 17.24069118499756, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.16251516342163, "training_acc": 52.0, "val_loss": 17.152942717075348, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.42137455940247, "training_acc": 52.0, "val_loss": 17.14784801006317, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.6312038898468, "training_acc": 52.0, "val_loss": 17.16107279062271, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.32286429405212, "training_acc": 52.0, "val_loss": 17.21564084291458, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.26113247871399, "training_acc": 52.0, "val_loss": 17.33408272266388, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.34319257736206, "training_acc": 44.0, "val_loss": 17.336007952690125, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.3440408706665, "training_acc": 46.0, "val_loss": 17.23591238260269, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.18525910377502, "training_acc": 52.0, "val_loss": 17.18876361846924, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.25943088531494, "training_acc": 52.0, "val_loss": 17.166371643543243, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.59787464141846, "training_acc": 52.0, "val_loss": 17.163395881652832, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.24364495277405, "training_acc": 52.0, "val_loss": 17.30181872844696, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24852395057678, "training_acc": 54.0, "val_loss": 17.509086430072784, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.73968195915222, "training_acc": 48.0, "val_loss": 17.4568310379982, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.48825931549072, "training_acc": 38.0, "val_loss": 17.206493020057678, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23710131645203, "training_acc": 52.0, "val_loss": 17.228882014751434, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.36660623550415, "training_acc": 52.0, "val_loss": 17.266827821731567, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.24126029014587, "training_acc": 52.0, "val_loss": 17.20491796731949, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.85743808746338, "training_acc": 52.0, "val_loss": 17.171137034893036, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.88969922065735, "training_acc": 52.0, "val_loss": 17.29818880558014, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.2795627117157, "training_acc": 52.0, "val_loss": 17.248761653900146, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24975752830505, "training_acc": 52.0, "val_loss": 17.215843498706818, "val_acc": 56.0}
