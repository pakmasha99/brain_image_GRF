"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.98503637313843, "training_acc": 43.0, "val_loss": 17.51634180545807, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15357661247253, "training_acc": 53.0, "val_loss": 17.99542009830475, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.38680028915405, "training_acc": 53.0, "val_loss": 18.41869354248047, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.14017629623413, "training_acc": 53.0, "val_loss": 17.47065633535385, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.39713263511658, "training_acc": 53.0, "val_loss": 17.49774068593979, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.53218817710876, "training_acc": 47.0, "val_loss": 17.83328950405121, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.44024872779846, "training_acc": 47.0, "val_loss": 17.491979897022247, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.80672478675842, "training_acc": 49.0, "val_loss": 17.35553741455078, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.85478472709656, "training_acc": 53.0, "val_loss": 17.688342928886414, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.26873660087585, "training_acc": 53.0, "val_loss": 17.878970503807068, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.98741173744202, "training_acc": 53.0, "val_loss": 17.764265835285187, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.22169065475464, "training_acc": 53.0, "val_loss": 17.39606261253357, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.78552269935608, "training_acc": 53.0, "val_loss": 17.36106127500534, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.50362873077393, "training_acc": 47.0, "val_loss": 17.45087057352066, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.00400590896606, "training_acc": 47.0, "val_loss": 17.38494783639908, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31101727485657, "training_acc": 53.0, "val_loss": 17.32792854309082, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12505078315735, "training_acc": 53.0, "val_loss": 17.518514394760132, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.69999408721924, "training_acc": 53.0, "val_loss": 17.592082917690277, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.99843168258667, "training_acc": 53.0, "val_loss": 17.471669614315033, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.54322075843811, "training_acc": 53.0, "val_loss": 17.316238582134247, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.40874409675598, "training_acc": 47.0, "val_loss": 17.36588627099991, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.49347138404846, "training_acc": 47.0, "val_loss": 17.346283793449402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.27624845504761, "training_acc": 56.0, "val_loss": 17.31635183095932, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2767562866211, "training_acc": 53.0, "val_loss": 17.412154376506805, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.41079759597778, "training_acc": 53.0, "val_loss": 17.43718534708023, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.44947791099548, "training_acc": 53.0, "val_loss": 17.35217571258545, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1343834400177, "training_acc": 53.0, "val_loss": 17.315757274627686, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11059641838074, "training_acc": 53.0, "val_loss": 17.335176467895508, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.32049250602722, "training_acc": 49.0, "val_loss": 17.35018491744995, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.40457701683044, "training_acc": 47.0, "val_loss": 17.321419715881348, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.30436372756958, "training_acc": 53.0, "val_loss": 17.350155115127563, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20744228363037, "training_acc": 53.0, "val_loss": 17.392173409461975, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.31599450111389, "training_acc": 53.0, "val_loss": 17.353728413581848, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15847253799438, "training_acc": 53.0, "val_loss": 17.31650084257126, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.3150680065155, "training_acc": 53.0, "val_loss": 17.32843518257141, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.29227876663208, "training_acc": 53.0, "val_loss": 17.31601655483246, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17785978317261, "training_acc": 53.0, "val_loss": 17.323023080825806, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13895511627197, "training_acc": 53.0, "val_loss": 17.34052449464798, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.20462417602539, "training_acc": 53.0, "val_loss": 17.348073422908783, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.12997102737427, "training_acc": 53.0, "val_loss": 17.319771647453308, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16061878204346, "training_acc": 53.0, "val_loss": 17.32059270143509, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.39128184318542, "training_acc": 53.0, "val_loss": 17.32189953327179, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.23361587524414, "training_acc": 53.0, "val_loss": 17.33420640230179, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.3132631778717, "training_acc": 48.0, "val_loss": 17.325298488140106, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.21614861488342, "training_acc": 53.0, "val_loss": 17.321334779262543, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.29018068313599, "training_acc": 53.0, "val_loss": 17.423319816589355, "val_acc": 52.0}
