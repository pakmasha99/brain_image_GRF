"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 50243043.972969055, "training_acc": 49.0, "val_loss": 29320950.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 86362504.375, "training_acc": 49.0, "val_loss": 9628983.59375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 27861837.0, "training_acc": 55.0, "val_loss": 4793763.28125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 17875840.125, "training_acc": 53.0, "val_loss": 2821856.640625, "val_acc": 48.0}
{"epoch": 4, "training_loss": 19703501.5, "training_acc": 39.0, "val_loss": 2880001.171875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 12573373.375, "training_acc": 51.0, "val_loss": 1846351.171875, "val_acc": 48.0}
{"epoch": 6, "training_loss": 11486927.25, "training_acc": 47.0, "val_loss": 1583238.4765625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 8006209.90625, "training_acc": 55.0, "val_loss": 789949.21875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 8263229.875, "training_acc": 49.0, "val_loss": 699743.75, "val_acc": 48.0}
{"epoch": 9, "training_loss": 7928607.5625, "training_acc": 49.0, "val_loss": 575226.66015625, "val_acc": 48.0}
{"epoch": 10, "training_loss": 7515988.5, "training_acc": 49.0, "val_loss": 481235.498046875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 6660369.3125, "training_acc": 51.0, "val_loss": 278458.30078125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 5722385.5625, "training_acc": 53.0, "val_loss": 10273.086547851562, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6822121.9375, "training_acc": 47.0, "val_loss": 193807.32421875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 7063055.0625, "training_acc": 47.0, "val_loss": 287215.771484375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 6055414.625, "training_acc": 51.0, "val_loss": 115886.0107421875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 7860386.3125, "training_acc": 43.0, "val_loss": 497748.681640625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 5317199.53125, "training_acc": 55.0, "val_loss": 16423.362731933594, "val_acc": 48.0}
{"epoch": 18, "training_loss": 5943183.84375, "training_acc": 49.0, "val_loss": 87264.35546875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 6092488.03125, "training_acc": 49.0, "val_loss": 95403.01513671875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 5581657.375, "training_acc": 51.0, "val_loss": 16298.869323730469, "val_acc": 52.0}
{"epoch": 21, "training_loss": 5860145.3359375, "training_acc": 47.0, "val_loss": 1536259.47265625, "val_acc": 52.0}
{"epoch": 22, "training_loss": 9806235.0, "training_acc": 43.0, "val_loss": 2399585.7421875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 8569880.8125, "training_acc": 51.0, "val_loss": 2640427.1484375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 6823062.53125, "training_acc": 59.0, "val_loss": 2479734.375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 6586188.59375, "training_acc": 59.0, "val_loss": 2409447.8515625, "val_acc": 52.0}
{"epoch": 26, "training_loss": 8401203.65625, "training_acc": 51.0, "val_loss": 2774966.40625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 9960746.09375, "training_acc": 47.0, "val_loss": 3218051.171875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 8408004.8984375, "training_acc": 55.0, "val_loss": 3130881.25, "val_acc": 52.0}
{"epoch": 29, "training_loss": 10274044.078125, "training_acc": 47.0, "val_loss": 3532969.921875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 11376388.71875, "training_acc": 45.0, "val_loss": 3896771.484375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 10654600.24609375, "training_acc": 49.0, "val_loss": 3970828.90625, "val_acc": 52.0}
