"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 56247348.82878113, "training_acc": 50.0, "val_loss": 26768868.75, "val_acc": 56.0}
{"epoch": 1, "training_loss": 76664977.0625, "training_acc": 52.0, "val_loss": 11165955.46875, "val_acc": 56.0}
{"epoch": 2, "training_loss": 30958495.640625, "training_acc": 54.0, "val_loss": 7468214.0625, "val_acc": 56.0}
{"epoch": 3, "training_loss": 21318216.5, "training_acc": 54.0, "val_loss": 5775976.5625, "val_acc": 56.0}
{"epoch": 4, "training_loss": 18818435.15625, "training_acc": 50.0, "val_loss": 5043053.90625, "val_acc": 56.0}
{"epoch": 5, "training_loss": 13914715.859375, "training_acc": 56.0, "val_loss": 4207902.34375, "val_acc": 56.0}
{"epoch": 6, "training_loss": 14260725.59375, "training_acc": 50.0, "val_loss": 4026295.3125, "val_acc": 56.0}
{"epoch": 7, "training_loss": 14137885.875, "training_acc": 48.0, "val_loss": 3948621.484375, "val_acc": 56.0}
{"epoch": 8, "training_loss": 10306120.7421875, "training_acc": 58.0, "val_loss": 3354022.265625, "val_acc": 56.0}
{"epoch": 9, "training_loss": 10996395.21875, "training_acc": 52.0, "val_loss": 3302310.546875, "val_acc": 56.0}
{"epoch": 10, "training_loss": 11394437.546875, "training_acc": 50.0, "val_loss": 3315846.484375, "val_acc": 56.0}
{"epoch": 11, "training_loss": 10622876.78125, "training_acc": 52.0, "val_loss": 3209986.1328125, "val_acc": 56.0}
{"epoch": 12, "training_loss": 9762698.96875, "training_acc": 54.0, "val_loss": 3043143.359375, "val_acc": 56.0}
{"epoch": 13, "training_loss": 11138870.328125, "training_acc": 48.0, "val_loss": 3221764.2578125, "val_acc": 56.0}
{"epoch": 14, "training_loss": 11312608.703125, "training_acc": 48.0, "val_loss": 3314734.375, "val_acc": 56.0}
{"epoch": 15, "training_loss": 11898577.34375, "training_acc": 46.0, "val_loss": 3480224.609375, "val_acc": 56.0}
{"epoch": 16, "training_loss": 10305774.53125, "training_acc": 52.0, "val_loss": 3311801.171875, "val_acc": 56.0}
{"epoch": 17, "training_loss": 10511279.15625, "training_acc": 50.0, "val_loss": 3313267.96875, "val_acc": 56.0}
{"epoch": 18, "training_loss": 10491317.4765625, "training_acc": 50.0, "val_loss": 3300706.25, "val_acc": 56.0}
{"epoch": 19, "training_loss": 9902360.0703125, "training_acc": 52.0, "val_loss": 3194784.9609375, "val_acc": 56.0}
{"epoch": 20, "training_loss": 10799663.796875, "training_acc": 48.0, "val_loss": 3312114.84375, "val_acc": 56.0}
{"epoch": 21, "training_loss": 11528258.1875, "training_acc": 46.0, "val_loss": 3470810.546875, "val_acc": 56.0}
{"epoch": 22, "training_loss": 9061613.439453125, "training_acc": 56.0, "val_loss": 3114217.3828125, "val_acc": 56.0}
{"epoch": 23, "training_loss": 8994069.578125, "training_acc": 54.0, "val_loss": 2987110.3515625, "val_acc": 56.0}
{"epoch": 24, "training_loss": 8866200.234375, "training_acc": 54.0, "val_loss": 2873063.671875, "val_acc": 56.0}
{"epoch": 25, "training_loss": 10285520.0, "training_acc": 48.0, "val_loss": 3067741.6015625, "val_acc": 56.0}
{"epoch": 26, "training_loss": 7197198.681640625, "training_acc": 62.0, "val_loss": 2509086.9140625, "val_acc": 56.0}
{"epoch": 27, "training_loss": 8676657.78125, "training_acc": 52.0, "val_loss": 2638627.9296875, "val_acc": 56.0}
{"epoch": 28, "training_loss": 10587087.65625, "training_acc": 46.0, "val_loss": 2964682.421875, "val_acc": 56.0}
{"epoch": 29, "training_loss": 10502371.765625, "training_acc": 48.0, "val_loss": 3088092.96875, "val_acc": 56.0}
{"epoch": 30, "training_loss": 7640518.0234375, "training_acc": 60.0, "val_loss": 2621304.1015625, "val_acc": 56.0}
{"epoch": 31, "training_loss": 11567480.28125, "training_acc": 42.0, "val_loss": 3193358.3984375, "val_acc": 56.0}
{"epoch": 32, "training_loss": 9738624.859375, "training_acc": 52.0, "val_loss": 3053346.875, "val_acc": 56.0}
{"epoch": 33, "training_loss": 10482057.6875, "training_acc": 48.0, "val_loss": 3197512.890625, "val_acc": 56.0}
{"epoch": 34, "training_loss": 9148124.9140625, "training_acc": 54.0, "val_loss": 2999010.7421875, "val_acc": 56.0}
{"epoch": 35, "training_loss": 9845568.0, "training_acc": 50.0, "val_loss": 3071478.125, "val_acc": 56.0}
{"epoch": 36, "training_loss": 10526196.953125, "training_acc": 48.0, "val_loss": 3199461.1328125, "val_acc": 56.0}
{"epoch": 37, "training_loss": 12427907.546875, "training_acc": 42.0, "val_loss": 3570826.5625, "val_acc": 56.0}
{"epoch": 38, "training_loss": 12962118.875, "training_acc": 42.0, "val_loss": 3825319.53125, "val_acc": 56.0}
{"epoch": 39, "training_loss": 10101734.92578125, "training_acc": 52.0, "val_loss": 4040932.03125, "val_acc": 44.0}
{"epoch": 40, "training_loss": 10755241.703125, "training_acc": 50.0, "val_loss": 3410341.796875, "val_acc": 44.0}
{"epoch": 41, "training_loss": 9962070.71875, "training_acc": 50.0, "val_loss": 2896378.515625, "val_acc": 44.0}
{"epoch": 42, "training_loss": 10924430.53125, "training_acc": 44.0, "val_loss": 2846600.0, "val_acc": 44.0}
{"epoch": 43, "training_loss": 12099627.9375, "training_acc": 40.0, "val_loss": 2995458.3984375, "val_acc": 44.0}
{"epoch": 44, "training_loss": 9014215.53125, "training_acc": 52.0, "val_loss": 2353371.6796875, "val_acc": 44.0}
{"epoch": 45, "training_loss": 9604903.84375, "training_acc": 46.0, "val_loss": 2300277.9296875, "val_acc": 44.0}
{"epoch": 46, "training_loss": 9073637.65625, "training_acc": 48.0, "val_loss": 2086359.1796875, "val_acc": 44.0}
{"epoch": 47, "training_loss": 7295660.59375, "training_acc": 54.0, "val_loss": 1558933.30078125, "val_acc": 44.0}
{"epoch": 48, "training_loss": 8034796.21875, "training_acc": 48.0, "val_loss": 1551530.76171875, "val_acc": 44.0}
{"epoch": 49, "training_loss": 9167599.75, "training_acc": 44.0, "val_loss": 1741116.796875, "val_acc": 44.0}
{"epoch": 50, "training_loss": 8908596.96875, "training_acc": 46.0, "val_loss": 1737562.6953125, "val_acc": 44.0}
{"epoch": 51, "training_loss": 8339200.5, "training_acc": 48.0, "val_loss": 1627676.953125, "val_acc": 44.0}
{"epoch": 52, "training_loss": 8695801.53125, "training_acc": 46.0, "val_loss": 1678743.5546875, "val_acc": 44.0}
{"epoch": 53, "training_loss": 8255454.125, "training_acc": 48.0, "val_loss": 1580096.875, "val_acc": 44.0}
{"epoch": 54, "training_loss": 7109971.90625, "training_acc": 52.0, "val_loss": 1272608.88671875, "val_acc": 44.0}
{"epoch": 55, "training_loss": 8717373.125, "training_acc": 44.0, "val_loss": 1546506.93359375, "val_acc": 44.0}
{"epoch": 56, "training_loss": 8630354.4375, "training_acc": 46.0, "val_loss": 1579028.22265625, "val_acc": 44.0}
{"epoch": 57, "training_loss": 7120245.71875, "training_acc": 52.0, "val_loss": 1254851.5625, "val_acc": 44.0}
{"epoch": 58, "training_loss": 7629067.15625, "training_acc": 48.0, "val_loss": 1286618.45703125, "val_acc": 44.0}
{"epoch": 59, "training_loss": 6268693.5625, "training_acc": 54.0, "val_loss": 912647.265625, "val_acc": 44.0}
{"epoch": 60, "training_loss": 8221612.5, "training_acc": 44.0, "val_loss": 1273046.58203125, "val_acc": 44.0}
{"epoch": 61, "training_loss": 7250997.75, "training_acc": 50.0, "val_loss": 1112587.59765625, "val_acc": 44.0}
{"epoch": 62, "training_loss": 6974571.21875, "training_acc": 50.0, "val_loss": 1032735.83984375, "val_acc": 44.0}
{"epoch": 63, "training_loss": 5489482.65625, "training_acc": 56.0, "val_loss": 598765.380859375, "val_acc": 44.0}
{"epoch": 64, "training_loss": 6264292.3125, "training_acc": 50.0, "val_loss": 665493.603515625, "val_acc": 44.0}
{"epoch": 65, "training_loss": 5947228.21875, "training_acc": 52.0, "val_loss": 547456.494140625, "val_acc": 44.0}
{"epoch": 66, "training_loss": 5782304.125, "training_acc": 52.0, "val_loss": 468981.73828125, "val_acc": 44.0}
{"epoch": 67, "training_loss": 8250952.1875, "training_acc": 42.0, "val_loss": 1023261.42578125, "val_acc": 44.0}
{"epoch": 68, "training_loss": 9102558.125, "training_acc": 42.0, "val_loss": 1385262.01171875, "val_acc": 44.0}
{"epoch": 69, "training_loss": 8450155.125, "training_acc": 46.0, "val_loss": 1432511.71875, "val_acc": 44.0}
{"epoch": 70, "training_loss": 8451089.0, "training_acc": 46.0, "val_loss": 1502548.73046875, "val_acc": 44.0}
{"epoch": 71, "training_loss": 11409990.9375, "training_acc": 36.0, "val_loss": 2167366.9921875, "val_acc": 44.0}
{"epoch": 72, "training_loss": 10605346.625, "training_acc": 42.0, "val_loss": 2254991.015625, "val_acc": 44.0}
{"epoch": 73, "training_loss": 10048705.125, "training_acc": 44.0, "val_loss": 2253169.7265625, "val_acc": 44.0}
{"epoch": 74, "training_loss": 9465662.71875, "training_acc": 46.0, "val_loss": 2147192.1875, "val_acc": 44.0}
{"epoch": 75, "training_loss": 7785355.9375, "training_acc": 52.0, "val_loss": 1716720.1171875, "val_acc": 44.0}
{"epoch": 76, "training_loss": 7657850.6875, "training_acc": 50.0, "val_loss": 1537996.484375, "val_acc": 44.0}
{"epoch": 77, "training_loss": 7956352.46875, "training_acc": 48.0, "val_loss": 1498225.09765625, "val_acc": 44.0}
{"epoch": 78, "training_loss": 5618035.78125, "training_acc": 58.0, "val_loss": 841347.36328125, "val_acc": 44.0}
{"epoch": 79, "training_loss": 6980766.375, "training_acc": 48.0, "val_loss": 1000583.7890625, "val_acc": 44.0}
{"epoch": 80, "training_loss": 7312839.75, "training_acc": 48.0, "val_loss": 1047226.953125, "val_acc": 44.0}
{"epoch": 81, "training_loss": 7370843.125, "training_acc": 48.0, "val_loss": 1084184.08203125, "val_acc": 44.0}
{"epoch": 82, "training_loss": 7934505.9375, "training_acc": 46.0, "val_loss": 1236792.48046875, "val_acc": 44.0}
{"epoch": 83, "training_loss": 6653880.0, "training_acc": 52.0, "val_loss": 976933.59375, "val_acc": 44.0}
{"epoch": 84, "training_loss": 7741708.25, "training_acc": 46.0, "val_loss": 1181269.82421875, "val_acc": 44.0}
{"epoch": 85, "training_loss": 8078392.6875, "training_acc": 46.0, "val_loss": 1297464.74609375, "val_acc": 44.0}
