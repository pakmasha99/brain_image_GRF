"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 44337235.221572876, "training_acc": 53.0, "val_loss": 28435075.0, "val_acc": 48.0}
{"epoch": 1, "training_loss": 97659062.5, "training_acc": 43.0, "val_loss": 9182996.875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 31057130.0, "training_acc": 49.0, "val_loss": 5084455.46875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 23046186.875, "training_acc": 43.0, "val_loss": 3875649.609375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 12377196.5, "training_acc": 57.0, "val_loss": 2028931.640625, "val_acc": 48.0}
{"epoch": 5, "training_loss": 10179675.0625, "training_acc": 53.0, "val_loss": 1294422.36328125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 10631463.125, "training_acc": 47.0, "val_loss": 1196062.20703125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 9290488.8125, "training_acc": 49.0, "val_loss": 922382.32421875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 6728782.59375, "training_acc": 55.0, "val_loss": 326014.794921875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 6725086.4375, "training_acc": 51.0, "val_loss": 203557.89794921875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 6424839.125, "training_acc": 51.0, "val_loss": 73686.60888671875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 9000185.5625, "training_acc": 41.0, "val_loss": 617051.46484375, "val_acc": 48.0}
{"epoch": 12, "training_loss": 6797373.25, "training_acc": 51.0, "val_loss": 320771.3134765625, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6679221.1875, "training_acc": 49.0, "val_loss": 300751.123046875, "val_acc": 48.0}
{"epoch": 14, "training_loss": 6075905.5625, "training_acc": 51.0, "val_loss": 143607.43408203125, "val_acc": 48.0}
{"epoch": 15, "training_loss": 6818463.0, "training_acc": 47.0, "val_loss": 280091.796875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 5474190.5, "training_acc": 53.0, "val_loss": 7987.720489501953, "val_acc": 52.0}
{"epoch": 17, "training_loss": 5049798.375, "training_acc": 51.0, "val_loss": 1321588.96484375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7459192.46875, "training_acc": 51.0, "val_loss": 1848102.34375, "val_acc": 52.0}
{"epoch": 19, "training_loss": 9060398.25, "training_acc": 47.0, "val_loss": 2475026.7578125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 7683504.421875, "training_acc": 55.0, "val_loss": 2529225.390625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 11416125.65625, "training_acc": 41.0, "val_loss": 3351991.796875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 10709154.328125, "training_acc": 47.0, "val_loss": 3598212.890625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 11407355.96875, "training_acc": 45.0, "val_loss": 3936952.34375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11759900.9765625, "training_acc": 45.0, "val_loss": 4188766.796875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 10404060.974609375, "training_acc": 53.0, "val_loss": 3302253.515625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 10440671.203125, "training_acc": 49.0, "val_loss": 2731674.609375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 7331064.984375, "training_acc": 59.0, "val_loss": 1672237.3046875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 7568173.78125, "training_acc": 51.0, "val_loss": 1339785.44921875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 7682254.09375, "training_acc": 49.0, "val_loss": 1126122.94921875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 7910166.0, "training_acc": 47.0, "val_loss": 1050691.2109375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 7304305.1875, "training_acc": 49.0, "val_loss": 860106.15234375, "val_acc": 48.0}
{"epoch": 32, "training_loss": 7001531.4375, "training_acc": 49.0, "val_loss": 721571.875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 7308240.8125, "training_acc": 47.0, "val_loss": 722423.974609375, "val_acc": 48.0}
{"epoch": 34, "training_loss": 7853576.875, "training_acc": 45.0, "val_loss": 822244.43359375, "val_acc": 48.0}
{"epoch": 35, "training_loss": 7482363.1875, "training_acc": 47.0, "val_loss": 773730.224609375, "val_acc": 48.0}
