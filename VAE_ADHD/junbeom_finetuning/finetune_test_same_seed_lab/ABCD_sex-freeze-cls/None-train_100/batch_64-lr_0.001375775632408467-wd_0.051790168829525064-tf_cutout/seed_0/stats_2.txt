"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.85225939750671, "training_acc": 53.0, "val_loss": 17.64570027589798, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.10469913482666, "training_acc": 53.0, "val_loss": 17.713363468647003, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.1589527130127, "training_acc": 47.0, "val_loss": 18.10382455587387, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.45343732833862, "training_acc": 47.0, "val_loss": 17.35728830099106, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.05987477302551, "training_acc": 43.0, "val_loss": 17.477019131183624, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.84542489051819, "training_acc": 53.0, "val_loss": 17.69532859325409, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.21659588813782, "training_acc": 53.0, "val_loss": 17.514733970165253, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.59165263175964, "training_acc": 53.0, "val_loss": 17.32648015022278, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.82629418373108, "training_acc": 53.0, "val_loss": 17.321130633354187, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.28788495063782, "training_acc": 56.0, "val_loss": 17.313073575496674, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.50993084907532, "training_acc": 53.0, "val_loss": 17.312103509902954, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22870945930481, "training_acc": 53.0, "val_loss": 17.314136028289795, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14793992042542, "training_acc": 53.0, "val_loss": 17.346392571926117, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16503286361694, "training_acc": 53.0, "val_loss": 17.35888570547104, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.25284934043884, "training_acc": 53.0, "val_loss": 17.335444688796997, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21837162971497, "training_acc": 53.0, "val_loss": 17.308004200458527, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22707462310791, "training_acc": 53.0, "val_loss": 17.313943803310394, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24356770515442, "training_acc": 53.0, "val_loss": 17.308005690574646, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16181588172913, "training_acc": 53.0, "val_loss": 17.312148213386536, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11885786056519, "training_acc": 53.0, "val_loss": 17.347519099712372, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.27468347549438, "training_acc": 53.0, "val_loss": 17.39457994699478, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.3296205997467, "training_acc": 53.0, "val_loss": 17.350097000598907, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14709615707397, "training_acc": 53.0, "val_loss": 17.3082634806633, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1858184337616, "training_acc": 53.0, "val_loss": 17.325784265995026, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.35319304466248, "training_acc": 55.0, "val_loss": 17.31715351343155, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.24355030059814, "training_acc": 53.0, "val_loss": 17.321492731571198, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13983178138733, "training_acc": 53.0, "val_loss": 17.377936840057373, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.32741856575012, "training_acc": 53.0, "val_loss": 17.48843342065811, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.65910911560059, "training_acc": 53.0, "val_loss": 17.617599666118622, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.96220564842224, "training_acc": 53.0, "val_loss": 17.466197907924652, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.77248096466064, "training_acc": 53.0, "val_loss": 17.309024930000305, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.11625027656555, "training_acc": 53.0, "val_loss": 17.339594662189484, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.60774540901184, "training_acc": 47.0, "val_loss": 17.3463374376297, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2852234840393, "training_acc": 53.0, "val_loss": 17.312869429588318, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.07901978492737, "training_acc": 53.0, "val_loss": 17.430123686790466, "val_acc": 52.0}
