"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.7663643360138, "training_acc": 41.0, "val_loss": 17.49279350042343, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.50722146034241, "training_acc": 53.0, "val_loss": 17.410053312778473, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.89895725250244, "training_acc": 47.0, "val_loss": 17.402072250843048, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.55977010726929, "training_acc": 48.0, "val_loss": 17.301322519779205, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.49467396736145, "training_acc": 53.0, "val_loss": 17.416900396347046, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.78642964363098, "training_acc": 53.0, "val_loss": 17.370693385601044, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32467722892761, "training_acc": 53.0, "val_loss": 17.35677868127823, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.5750572681427, "training_acc": 53.0, "val_loss": 17.32458621263504, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.27644753456116, "training_acc": 53.0, "val_loss": 17.33662039041519, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19429326057434, "training_acc": 53.0, "val_loss": 17.35280603170395, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41096925735474, "training_acc": 53.0, "val_loss": 17.344149947166443, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20415043830872, "training_acc": 53.0, "val_loss": 17.29940176010132, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17810988426208, "training_acc": 53.0, "val_loss": 17.321957647800446, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.53658366203308, "training_acc": 44.0, "val_loss": 17.366622388362885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.44584679603577, "training_acc": 47.0, "val_loss": 17.30547994375229, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19807481765747, "training_acc": 53.0, "val_loss": 17.350883781909943, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.34466934204102, "training_acc": 53.0, "val_loss": 17.427214980125427, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.01049971580505, "training_acc": 53.0, "val_loss": 17.37143248319626, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.51968502998352, "training_acc": 53.0, "val_loss": 17.378990352153778, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.27252125740051, "training_acc": 53.0, "val_loss": 17.303572595119476, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10301184654236, "training_acc": 53.0, "val_loss": 17.368707060813904, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.80637860298157, "training_acc": 47.0, "val_loss": 17.41866022348404, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.70935797691345, "training_acc": 47.0, "val_loss": 17.309771478176117, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16325545310974, "training_acc": 53.0, "val_loss": 17.333821952342987, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18529152870178, "training_acc": 53.0, "val_loss": 17.42623895406723, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.49498724937439, "training_acc": 53.0, "val_loss": 17.413653433322906, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.4313395023346, "training_acc": 53.0, "val_loss": 17.355354130268097, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15743660926819, "training_acc": 53.0, "val_loss": 17.302629351615906, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.87307715415955, "training_acc": 41.0, "val_loss": 17.34003722667694, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.3082845211029, "training_acc": 51.0, "val_loss": 17.30286031961441, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.05590867996216, "training_acc": 53.0, "val_loss": 17.35609620809555, "val_acc": 52.0}
