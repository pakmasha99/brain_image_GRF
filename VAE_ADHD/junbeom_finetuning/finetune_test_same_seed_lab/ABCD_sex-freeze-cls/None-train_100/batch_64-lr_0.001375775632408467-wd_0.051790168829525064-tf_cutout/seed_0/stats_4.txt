"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.59343409538269, "training_acc": 51.0, "val_loss": 17.857520282268524, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.89606428146362, "training_acc": 53.0, "val_loss": 17.308132350444794, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.06350445747375, "training_acc": 53.0, "val_loss": 17.3741415143013, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.6114764213562, "training_acc": 47.0, "val_loss": 17.32713431119919, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22305917739868, "training_acc": 51.0, "val_loss": 17.34137088060379, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19946885108948, "training_acc": 53.0, "val_loss": 17.45661348104477, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5554871559143, "training_acc": 53.0, "val_loss": 17.378760874271393, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.27608561515808, "training_acc": 53.0, "val_loss": 17.295512557029724, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.30355548858643, "training_acc": 47.0, "val_loss": 17.32417196035385, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30550765991211, "training_acc": 48.0, "val_loss": 17.295511066913605, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17688417434692, "training_acc": 53.0, "val_loss": 17.338021099567413, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.23006892204285, "training_acc": 53.0, "val_loss": 17.340606451034546, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.24923872947693, "training_acc": 53.0, "val_loss": 17.30751395225525, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.41548538208008, "training_acc": 53.0, "val_loss": 17.296841740608215, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15990424156189, "training_acc": 53.0, "val_loss": 17.342345416545868, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.4303731918335, "training_acc": 47.0, "val_loss": 17.3167422413826, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.46819686889648, "training_acc": 56.0, "val_loss": 17.30654537677765, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.4016923904419, "training_acc": 53.0, "val_loss": 17.318640649318695, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14148426055908, "training_acc": 53.0, "val_loss": 17.29710102081299, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18732213973999, "training_acc": 53.0, "val_loss": 17.306716740131378, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.28593158721924, "training_acc": 53.0, "val_loss": 17.295730113983154, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12242531776428, "training_acc": 53.0, "val_loss": 17.349140346050262, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.36325001716614, "training_acc": 53.0, "val_loss": 17.49248206615448, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.76993227005005, "training_acc": 53.0, "val_loss": 17.371028661727905, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.07434487342834, "training_acc": 53.0, "val_loss": 17.317330837249756, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.4376859664917, "training_acc": 55.0, "val_loss": 17.454276978969574, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.97009992599487, "training_acc": 47.0, "val_loss": 17.338742315769196, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.65113282203674, "training_acc": 45.0, "val_loss": 17.355240881443024, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.34023666381836, "training_acc": 53.0, "val_loss": 17.432330548763275, "val_acc": 52.0}
