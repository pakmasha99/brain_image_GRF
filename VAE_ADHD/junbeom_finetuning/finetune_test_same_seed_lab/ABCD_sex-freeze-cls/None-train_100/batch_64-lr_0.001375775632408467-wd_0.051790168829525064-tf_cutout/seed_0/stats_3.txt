"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.49487829208374, "training_acc": 45.0, "val_loss": 17.473357915878296, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.93049955368042, "training_acc": 55.0, "val_loss": 17.76604801416397, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.8303108215332, "training_acc": 53.0, "val_loss": 17.973430454730988, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.90352630615234, "training_acc": 53.0, "val_loss": 17.334792017936707, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30294013023376, "training_acc": 51.0, "val_loss": 17.575803399086, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.35389113426208, "training_acc": 47.0, "val_loss": 17.536398768424988, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.06495308876038, "training_acc": 47.0, "val_loss": 17.307236790657043, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.50090050697327, "training_acc": 53.0, "val_loss": 17.625442147254944, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.29065275192261, "training_acc": 53.0, "val_loss": 18.050207197666168, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.63065910339355, "training_acc": 53.0, "val_loss": 17.598256468772888, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.95298719406128, "training_acc": 53.0, "val_loss": 17.306922376155853, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.45744943618774, "training_acc": 49.0, "val_loss": 17.457838356494904, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.0181815624237, "training_acc": 47.0, "val_loss": 17.3763245344162, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21889972686768, "training_acc": 53.0, "val_loss": 17.340441048145294, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.72044062614441, "training_acc": 53.0, "val_loss": 17.57397949695587, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.97107458114624, "training_acc": 53.0, "val_loss": 17.409899830818176, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.40688943862915, "training_acc": 53.0, "val_loss": 17.306460440158844, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.76992344856262, "training_acc": 43.0, "val_loss": 17.343230545520782, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.8411180973053, "training_acc": 41.0, "val_loss": 17.30719953775406, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16866612434387, "training_acc": 53.0, "val_loss": 17.311130464076996, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13754963874817, "training_acc": 53.0, "val_loss": 17.333218455314636, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.69405674934387, "training_acc": 53.0, "val_loss": 17.325416207313538, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.05986332893372, "training_acc": 53.0, "val_loss": 17.33732521533966, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.32389163970947, "training_acc": 47.0, "val_loss": 17.395107448101044, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.65577816963196, "training_acc": 47.0, "val_loss": 17.364563047885895, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.68526530265808, "training_acc": 43.0, "val_loss": 17.308585345745087, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19879865646362, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12055897712708, "training_acc": 53.0, "val_loss": 17.347002029418945, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.23791241645813, "training_acc": 53.0, "val_loss": 17.355220019817352, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.29140853881836, "training_acc": 53.0, "val_loss": 17.32206642627716, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13637566566467, "training_acc": 53.0, "val_loss": 17.32136309146881, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.28272557258606, "training_acc": 50.0, "val_loss": 17.332732677459717, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.32793521881104, "training_acc": 46.0, "val_loss": 17.307431995868683, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19680094718933, "training_acc": 53.0, "val_loss": 17.32414960861206, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.54825234413147, "training_acc": 53.0, "val_loss": 17.323249578475952, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1060745716095, "training_acc": 53.0, "val_loss": 17.400123178958893, "val_acc": 52.0}
