"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 8424.342269897461, "training_acc": 50.0, "val_loss": 1624.711799621582, "val_acc": 44.0}
{"epoch": 1, "training_loss": 8642.775817871094, "training_acc": 48.0, "val_loss": 4129.037094116211, "val_acc": 56.0}
{"epoch": 2, "training_loss": 17601.82208251953, "training_acc": 52.0, "val_loss": 2526.59912109375, "val_acc": 56.0}
{"epoch": 3, "training_loss": 7547.009712219238, "training_acc": 52.0, "val_loss": 2637.7296447753906, "val_acc": 44.0}
{"epoch": 4, "training_loss": 12008.532592773438, "training_acc": 48.0, "val_loss": 4597.661590576172, "val_acc": 44.0}
{"epoch": 5, "training_loss": 16205.100158691406, "training_acc": 48.0, "val_loss": 2395.1045989990234, "val_acc": 44.0}
{"epoch": 6, "training_loss": 6016.896831512451, "training_acc": 48.0, "val_loss": 1898.3402252197266, "val_acc": 56.0}
{"epoch": 7, "training_loss": 10068.449188232422, "training_acc": 52.0, "val_loss": 3664.883041381836, "val_acc": 56.0}
{"epoch": 8, "training_loss": 15942.431518554688, "training_acc": 52.0, "val_loss": 2937.1517181396484, "val_acc": 56.0}
{"epoch": 9, "training_loss": 10923.643127441406, "training_acc": 52.0, "val_loss": 191.74126386642456, "val_acc": 56.0}
{"epoch": 10, "training_loss": 3574.0958251953125, "training_acc": 50.0, "val_loss": 3699.535369873047, "val_acc": 44.0}
{"epoch": 11, "training_loss": 14465.946228027344, "training_acc": 48.0, "val_loss": 4095.977020263672, "val_acc": 44.0}
{"epoch": 12, "training_loss": 14132.645874023438, "training_acc": 48.0, "val_loss": 1787.4794006347656, "val_acc": 44.0}
{"epoch": 13, "training_loss": 4249.30885887146, "training_acc": 52.0, "val_loss": 1015.9297943115234, "val_acc": 56.0}
{"epoch": 14, "training_loss": 4857.929168701172, "training_acc": 52.0, "val_loss": 1112.4687194824219, "val_acc": 56.0}
{"epoch": 15, "training_loss": 3897.7361946105957, "training_acc": 52.0, "val_loss": 824.8311996459961, "val_acc": 44.0}
{"epoch": 16, "training_loss": 3726.6849060058594, "training_acc": 48.0, "val_loss": 1160.9682083129883, "val_acc": 44.0}
{"epoch": 17, "training_loss": 3190.3634719848633, "training_acc": 48.0, "val_loss": 846.2332725524902, "val_acc": 56.0}
{"epoch": 18, "training_loss": 4484.107131958008, "training_acc": 52.0, "val_loss": 1345.250415802002, "val_acc": 56.0}
{"epoch": 19, "training_loss": 5083.987014770508, "training_acc": 52.0, "val_loss": 85.55943369865417, "val_acc": 44.0}
{"epoch": 20, "training_loss": 934.6591644287109, "training_acc": 48.0, "val_loss": 205.17404079437256, "val_acc": 44.0}
{"epoch": 21, "training_loss": 1191.1211624145508, "training_acc": 54.0, "val_loss": 760.2272033691406, "val_acc": 56.0}
{"epoch": 22, "training_loss": 2884.370719909668, "training_acc": 52.0, "val_loss": 308.9111566543579, "val_acc": 44.0}
{"epoch": 23, "training_loss": 1369.157241821289, "training_acc": 48.0, "val_loss": 66.07204079627991, "val_acc": 44.0}
{"epoch": 24, "training_loss": 1511.504898071289, "training_acc": 46.0, "val_loss": 1008.0084800720215, "val_acc": 56.0}
{"epoch": 25, "training_loss": 3980.870620727539, "training_acc": 52.0, "val_loss": 27.074480056762695, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1121.8290176391602, "training_acc": 62.0, "val_loss": 1744.5188522338867, "val_acc": 44.0}
{"epoch": 27, "training_loss": 6306.788650512695, "training_acc": 48.0, "val_loss": 865.3389930725098, "val_acc": 44.0}
{"epoch": 28, "training_loss": 2364.3606758117676, "training_acc": 54.0, "val_loss": 827.0301818847656, "val_acc": 56.0}
{"epoch": 29, "training_loss": 3535.4109115600586, "training_acc": 52.0, "val_loss": 289.28866386413574, "val_acc": 56.0}
{"epoch": 30, "training_loss": 1390.5256805419922, "training_acc": 60.0, "val_loss": 1183.7868690490723, "val_acc": 44.0}
{"epoch": 31, "training_loss": 4148.860580444336, "training_acc": 48.0, "val_loss": 91.93044900894165, "val_acc": 44.0}
{"epoch": 32, "training_loss": 2054.1481323242188, "training_acc": 48.0, "val_loss": 1695.6039428710938, "val_acc": 56.0}
{"epoch": 33, "training_loss": 7429.948272705078, "training_acc": 52.0, "val_loss": 1294.4860458374023, "val_acc": 56.0}
{"epoch": 34, "training_loss": 4212.327583312988, "training_acc": 52.0, "val_loss": 1030.3791046142578, "val_acc": 44.0}
{"epoch": 35, "training_loss": 4913.829528808594, "training_acc": 48.0, "val_loss": 1891.4752960205078, "val_acc": 44.0}
{"epoch": 36, "training_loss": 6192.802032470703, "training_acc": 48.0, "val_loss": 90.86616039276123, "val_acc": 44.0}
{"epoch": 37, "training_loss": 1652.2388458251953, "training_acc": 58.0, "val_loss": 2064.7768020629883, "val_acc": 56.0}
{"epoch": 38, "training_loss": 9244.848754882812, "training_acc": 52.0, "val_loss": 2083.8674545288086, "val_acc": 56.0}
{"epoch": 39, "training_loss": 8006.795135498047, "training_acc": 52.0, "val_loss": 397.32110500335693, "val_acc": 56.0}
{"epoch": 40, "training_loss": 2956.4083709716797, "training_acc": 50.0, "val_loss": 2361.423683166504, "val_acc": 44.0}
{"epoch": 41, "training_loss": 9107.316986083984, "training_acc": 48.0, "val_loss": 2176.675796508789, "val_acc": 44.0}
{"epoch": 42, "training_loss": 6819.141571044922, "training_acc": 48.0, "val_loss": 376.02484226226807, "val_acc": 56.0}
{"epoch": 43, "training_loss": 3034.0521850585938, "training_acc": 52.0, "val_loss": 1093.7217712402344, "val_acc": 56.0}
{"epoch": 44, "training_loss": 4080.668815612793, "training_acc": 52.0, "val_loss": 318.99569034576416, "val_acc": 44.0}
