"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 7534.10440826416, "training_acc": 49.0, "val_loss": 1800.8445739746094, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9553.307739257812, "training_acc": 45.0, "val_loss": 3412.4507904052734, "val_acc": 48.0}
{"epoch": 2, "training_loss": 12420.951721191406, "training_acc": 47.0, "val_loss": 233.00447463989258, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4292.701873779297, "training_acc": 47.0, "val_loss": 3695.2468872070312, "val_acc": 52.0}
{"epoch": 4, "training_loss": 14571.910186767578, "training_acc": 53.0, "val_loss": 3315.915298461914, "val_acc": 52.0}
{"epoch": 5, "training_loss": 11427.904205322266, "training_acc": 53.0, "val_loss": 453.1527519226074, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4252.692230224609, "training_acc": 47.0, "val_loss": 3039.0365600585938, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12679.1162109375, "training_acc": 47.0, "val_loss": 2720.0685501098633, "val_acc": 48.0}
{"epoch": 8, "training_loss": 9552.364929199219, "training_acc": 47.0, "val_loss": 221.59950733184814, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2684.383758544922, "training_acc": 53.0, "val_loss": 1227.7050971984863, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4079.359275817871, "training_acc": 53.0, "val_loss": 302.066707611084, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1691.1628112792969, "training_acc": 47.0, "val_loss": 240.69256782531738, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1604.4145202636719, "training_acc": 49.0, "val_loss": 970.3776359558105, "val_acc": 52.0}
{"epoch": 13, "training_loss": 3415.0333099365234, "training_acc": 53.0, "val_loss": 78.96426320075989, "val_acc": 48.0}
{"epoch": 14, "training_loss": 522.7406692504883, "training_acc": 47.0, "val_loss": 311.03947162628174, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1098.1473407745361, "training_acc": 53.0, "val_loss": 354.9330949783325, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1320.812370300293, "training_acc": 47.0, "val_loss": 418.2892322540283, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1714.5110549926758, "training_acc": 53.0, "val_loss": 83.00651907920837, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1072.7591552734375, "training_acc": 59.0, "val_loss": 1061.6254806518555, "val_acc": 48.0}
{"epoch": 19, "training_loss": 3803.9438095092773, "training_acc": 47.0, "val_loss": 234.08448696136475, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1151.1274604797363, "training_acc": 53.0, "val_loss": 196.6380000114441, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1000.2725830078125, "training_acc": 59.0, "val_loss": 648.4621524810791, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1920.210210800171, "training_acc": 47.0, "val_loss": 825.9414672851562, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3577.0283966064453, "training_acc": 53.0, "val_loss": 1036.8176460266113, "val_acc": 52.0}
{"epoch": 24, "training_loss": 3266.6489219665527, "training_acc": 53.0, "val_loss": 675.1465797424316, "val_acc": 48.0}
{"epoch": 25, "training_loss": 3482.631057739258, "training_acc": 47.0, "val_loss": 777.0332336425781, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2211.3588008880615, "training_acc": 49.0, "val_loss": 377.656888961792, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1084.186490058899, "training_acc": 53.0, "val_loss": 713.703727722168, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3122.7745056152344, "training_acc": 47.0, "val_loss": 329.7987222671509, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1850.3951797485352, "training_acc": 49.0, "val_loss": 1093.453598022461, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4058.4358291625977, "training_acc": 53.0, "val_loss": 305.53131103515625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2419.8426513671875, "training_acc": 43.0, "val_loss": 1223.5156059265137, "val_acc": 48.0}
{"epoch": 32, "training_loss": 4546.067611694336, "training_acc": 47.0, "val_loss": 41.43736958503723, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1459.1112823486328, "training_acc": 55.0, "val_loss": 1836.3506317138672, "val_acc": 52.0}
{"epoch": 34, "training_loss": 7408.316314697266, "training_acc": 53.0, "val_loss": 1531.2783241271973, "val_acc": 52.0}
{"epoch": 35, "training_loss": 4499.519805908203, "training_acc": 53.0, "val_loss": 726.0684490203857, "val_acc": 48.0}
{"epoch": 36, "training_loss": 4119.333557128906, "training_acc": 47.0, "val_loss": 1514.86234664917, "val_acc": 48.0}
{"epoch": 37, "training_loss": 5348.734313964844, "training_acc": 47.0, "val_loss": 181.94706439971924, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1011.0941543579102, "training_acc": 53.0, "val_loss": 478.4492492675781, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1272.7850980758667, "training_acc": 51.0, "val_loss": 25.492438673973083, "val_acc": 52.0}
{"epoch": 40, "training_loss": 532.5823554992676, "training_acc": 49.0, "val_loss": 42.496904730796814, "val_acc": 52.0}
{"epoch": 41, "training_loss": 457.25678634643555, "training_acc": 45.0, "val_loss": 259.6217393875122, "val_acc": 52.0}
{"epoch": 42, "training_loss": 936.550235748291, "training_acc": 53.0, "val_loss": 457.9245090484619, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1875.0074310302734, "training_acc": 47.0, "val_loss": 128.2004952430725, "val_acc": 52.0}
{"epoch": 44, "training_loss": 588.1265335083008, "training_acc": 53.0, "val_loss": 393.8410520553589, "val_acc": 48.0}
{"epoch": 45, "training_loss": 1588.0871200561523, "training_acc": 47.0, "val_loss": 330.7676315307617, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1403.1199989318848, "training_acc": 53.0, "val_loss": 53.52129936218262, "val_acc": 52.0}
{"epoch": 47, "training_loss": 1244.9556121826172, "training_acc": 53.0, "val_loss": 1007.7047348022461, "val_acc": 48.0}
{"epoch": 48, "training_loss": 3480.1557998657227, "training_acc": 47.0, "val_loss": 383.8076591491699, "val_acc": 52.0}
{"epoch": 49, "training_loss": 1826.2020416259766, "training_acc": 53.0, "val_loss": 498.862361907959, "val_acc": 52.0}
{"epoch": 50, "training_loss": 1559.223382949829, "training_acc": 49.0, "val_loss": 181.65220022201538, "val_acc": 48.0}
{"epoch": 51, "training_loss": 960.6470527648926, "training_acc": 51.0, "val_loss": 392.69425868988037, "val_acc": 52.0}
{"epoch": 52, "training_loss": 884.7508771419525, "training_acc": 59.0, "val_loss": 84.92088317871094, "val_acc": 48.0}
{"epoch": 53, "training_loss": 776.9773139953613, "training_acc": 51.0, "val_loss": 398.341965675354, "val_acc": 52.0}
{"epoch": 54, "training_loss": 1191.548734664917, "training_acc": 51.0, "val_loss": 35.16242206096649, "val_acc": 48.0}
{"epoch": 55, "training_loss": 793.2206573486328, "training_acc": 51.0, "val_loss": 556.5200805664062, "val_acc": 52.0}
{"epoch": 56, "training_loss": 1488.3884105682373, "training_acc": 53.0, "val_loss": 924.1738319396973, "val_acc": 48.0}
{"epoch": 57, "training_loss": 4325.187271118164, "training_acc": 47.0, "val_loss": 904.3420791625977, "val_acc": 48.0}
{"epoch": 58, "training_loss": 2417.2103819847107, "training_acc": 49.0, "val_loss": 366.80846214294434, "val_acc": 52.0}
