"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 8431.335861206055, "training_acc": 53.0, "val_loss": 1569.2510604858398, "val_acc": 52.0}
{"epoch": 1, "training_loss": 8024.723480224609, "training_acc": 53.0, "val_loss": 4274.508285522461, "val_acc": 48.0}
{"epoch": 2, "training_loss": 16291.00390625, "training_acc": 47.0, "val_loss": 1517.6345825195312, "val_acc": 48.0}
{"epoch": 3, "training_loss": 5402.015670776367, "training_acc": 51.0, "val_loss": 2409.6065521240234, "val_acc": 52.0}
{"epoch": 4, "training_loss": 9749.10610961914, "training_acc": 53.0, "val_loss": 1930.6638717651367, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5557.6201171875, "training_acc": 53.0, "val_loss": 1440.5753135681152, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7230.687103271484, "training_acc": 47.0, "val_loss": 2355.8990478515625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 8577.172317504883, "training_acc": 47.0, "val_loss": 73.07521104812622, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3018.967971801758, "training_acc": 45.0, "val_loss": 2732.137680053711, "val_acc": 52.0}
{"epoch": 9, "training_loss": 11067.641632080078, "training_acc": 53.0, "val_loss": 2640.0184631347656, "val_acc": 52.0}
{"epoch": 10, "training_loss": 9245.627410888672, "training_acc": 53.0, "val_loss": 395.2390670776367, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2929.088912963867, "training_acc": 53.0, "val_loss": 2434.3135833740234, "val_acc": 48.0}
{"epoch": 12, "training_loss": 10087.844055175781, "training_acc": 47.0, "val_loss": 2181.829071044922, "val_acc": 48.0}
{"epoch": 13, "training_loss": 7231.197723388672, "training_acc": 47.0, "val_loss": 343.3985471725464, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2221.3968505859375, "training_acc": 53.0, "val_loss": 1334.4416618347168, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4801.609100341797, "training_acc": 53.0, "val_loss": 226.21560096740723, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2001.6342010498047, "training_acc": 55.0, "val_loss": 1790.8170700073242, "val_acc": 48.0}
{"epoch": 17, "training_loss": 7237.958068847656, "training_acc": 47.0, "val_loss": 1080.018138885498, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2267.85604429245, "training_acc": 63.0, "val_loss": 775.6747722625732, "val_acc": 52.0}
{"epoch": 19, "training_loss": 3219.654083251953, "training_acc": 53.0, "val_loss": 541.3664817810059, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2154.102066040039, "training_acc": 45.0, "val_loss": 540.167760848999, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1448.3784198760986, "training_acc": 47.0, "val_loss": 940.7933235168457, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4075.5943298339844, "training_acc": 53.0, "val_loss": 1236.5368843078613, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3991.037971496582, "training_acc": 53.0, "val_loss": 388.00854682922363, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2113.89640045166, "training_acc": 47.0, "val_loss": 530.6811809539795, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1704.7332000732422, "training_acc": 51.0, "val_loss": 470.8807945251465, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1381.1114540100098, "training_acc": 53.0, "val_loss": 717.266321182251, "val_acc": 48.0}
