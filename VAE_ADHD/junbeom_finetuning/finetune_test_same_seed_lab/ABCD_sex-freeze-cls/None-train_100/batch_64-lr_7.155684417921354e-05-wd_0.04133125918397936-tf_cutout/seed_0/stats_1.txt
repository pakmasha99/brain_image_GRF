"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.3925392627716, "training_acc": 47.0, "val_loss": 17.473483085632324, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.13294577598572, "training_acc": 47.0, "val_loss": 17.410199344158173, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.74296498298645, "training_acc": 47.0, "val_loss": 17.369762063026428, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.50314092636108, "training_acc": 47.0, "val_loss": 17.341572046279907, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.47366642951965, "training_acc": 47.0, "val_loss": 17.32063591480255, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25944447517395, "training_acc": 52.0, "val_loss": 17.309848964214325, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16304469108582, "training_acc": 53.0, "val_loss": 17.304177582263947, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1734185218811, "training_acc": 53.0, "val_loss": 17.30274111032486, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12738919258118, "training_acc": 53.0, "val_loss": 17.30552315711975, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17052435874939, "training_acc": 53.0, "val_loss": 17.311879992485046, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16505312919617, "training_acc": 53.0, "val_loss": 17.319507896900177, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1472065448761, "training_acc": 53.0, "val_loss": 17.326559126377106, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17865109443665, "training_acc": 53.0, "val_loss": 17.332611978054047, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16423439979553, "training_acc": 53.0, "val_loss": 17.336085438728333, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18389511108398, "training_acc": 53.0, "val_loss": 17.33829826116562, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21797013282776, "training_acc": 53.0, "val_loss": 17.341329157352448, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21522068977356, "training_acc": 53.0, "val_loss": 17.341259121894836, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20862698554993, "training_acc": 53.0, "val_loss": 17.341478168964386, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20217657089233, "training_acc": 53.0, "val_loss": 17.3381969332695, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21020245552063, "training_acc": 53.0, "val_loss": 17.330096662044525, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17965984344482, "training_acc": 53.0, "val_loss": 17.323529720306396, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22530674934387, "training_acc": 53.0, "val_loss": 17.31739342212677, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1620078086853, "training_acc": 53.0, "val_loss": 17.315340042114258, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18534970283508, "training_acc": 53.0, "val_loss": 17.31330007314682, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1486074924469, "training_acc": 53.0, "val_loss": 17.31174886226654, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15410304069519, "training_acc": 53.0, "val_loss": 17.311541736125946, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1305775642395, "training_acc": 53.0, "val_loss": 17.310035228729248, "val_acc": 52.0}
