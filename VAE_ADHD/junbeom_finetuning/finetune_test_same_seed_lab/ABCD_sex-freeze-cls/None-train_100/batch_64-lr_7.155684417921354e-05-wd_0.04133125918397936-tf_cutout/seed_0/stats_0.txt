"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24027371406555, "training_acc": 52.0, "val_loss": 17.241178452968597, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23653268814087, "training_acc": 52.0, "val_loss": 17.221207916736603, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25515127182007, "training_acc": 52.0, "val_loss": 17.219319939613342, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26375126838684, "training_acc": 52.0, "val_loss": 17.229461669921875, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2404522895813, "training_acc": 52.0, "val_loss": 17.24584549665451, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22626233100891, "training_acc": 52.0, "val_loss": 17.2517791390419, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26012921333313, "training_acc": 52.0, "val_loss": 17.26401299238205, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25957155227661, "training_acc": 52.0, "val_loss": 17.269179224967957, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27326846122742, "training_acc": 52.0, "val_loss": 17.26316809654236, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25699257850647, "training_acc": 52.0, "val_loss": 17.26609766483307, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2338171005249, "training_acc": 52.0, "val_loss": 17.26708561182022, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2642297744751, "training_acc": 52.0, "val_loss": 17.263461649417877, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23420977592468, "training_acc": 52.0, "val_loss": 17.259040474891663, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23916363716125, "training_acc": 52.0, "val_loss": 17.257575690746307, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24745750427246, "training_acc": 52.0, "val_loss": 17.250773310661316, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25080800056458, "training_acc": 52.0, "val_loss": 17.241133749485016, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25145363807678, "training_acc": 52.0, "val_loss": 17.22751557826996, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23341774940491, "training_acc": 52.0, "val_loss": 17.218680679798126, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24180293083191, "training_acc": 52.0, "val_loss": 17.21200942993164, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.2589476108551, "training_acc": 52.0, "val_loss": 17.20746159553528, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20842289924622, "training_acc": 52.0, "val_loss": 17.20714271068573, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22942399978638, "training_acc": 52.0, "val_loss": 17.206451296806335, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28999280929565, "training_acc": 52.0, "val_loss": 17.20288246870041, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26202654838562, "training_acc": 52.0, "val_loss": 17.2067791223526, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25895643234253, "training_acc": 52.0, "val_loss": 17.214760184288025, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24990010261536, "training_acc": 52.0, "val_loss": 17.22644567489624, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.2789375782013, "training_acc": 52.0, "val_loss": 17.231586575508118, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22719645500183, "training_acc": 52.0, "val_loss": 17.24703162908554, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24921584129333, "training_acc": 52.0, "val_loss": 17.26100742816925, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26353549957275, "training_acc": 52.0, "val_loss": 17.265717685222626, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27860569953918, "training_acc": 52.0, "val_loss": 17.263278365135193, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28310871124268, "training_acc": 52.0, "val_loss": 17.269335687160492, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25145292282104, "training_acc": 52.0, "val_loss": 17.26308912038803, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25760817527771, "training_acc": 52.0, "val_loss": 17.25739687681198, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26086902618408, "training_acc": 52.0, "val_loss": 17.24856197834015, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24001407623291, "training_acc": 52.0, "val_loss": 17.243435978889465, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23738098144531, "training_acc": 52.0, "val_loss": 17.238089442253113, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23714351654053, "training_acc": 52.0, "val_loss": 17.23191738128662, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2288556098938, "training_acc": 52.0, "val_loss": 17.221125960350037, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25234317779541, "training_acc": 52.0, "val_loss": 17.207416892051697, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23259329795837, "training_acc": 52.0, "val_loss": 17.201723158359528, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25814962387085, "training_acc": 52.0, "val_loss": 17.198310792446136, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27147245407104, "training_acc": 52.0, "val_loss": 17.19658374786377, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24193835258484, "training_acc": 52.0, "val_loss": 17.199549078941345, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25572943687439, "training_acc": 52.0, "val_loss": 17.209626734256744, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24123358726501, "training_acc": 52.0, "val_loss": 17.217643558979034, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25457382202148, "training_acc": 52.0, "val_loss": 17.227689921855927, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23967027664185, "training_acc": 52.0, "val_loss": 17.237812280654907, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22528052330017, "training_acc": 52.0, "val_loss": 17.242078483104706, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23232245445251, "training_acc": 52.0, "val_loss": 17.245684564113617, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25383567810059, "training_acc": 52.0, "val_loss": 17.252111434936523, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25229835510254, "training_acc": 52.0, "val_loss": 17.25902259349823, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25848722457886, "training_acc": 52.0, "val_loss": 17.2640323638916, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26775479316711, "training_acc": 52.0, "val_loss": 17.269113659858704, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22435355186462, "training_acc": 52.0, "val_loss": 17.272284626960754, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25992512702942, "training_acc": 52.0, "val_loss": 17.269232869148254, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24945878982544, "training_acc": 52.0, "val_loss": 17.269156873226166, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24769520759583, "training_acc": 52.0, "val_loss": 17.269977927207947, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23859977722168, "training_acc": 52.0, "val_loss": 17.265422642230988, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26111245155334, "training_acc": 52.0, "val_loss": 17.261116206645966, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28195691108704, "training_acc": 52.0, "val_loss": 17.25127398967743, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23974180221558, "training_acc": 52.0, "val_loss": 17.246998846530914, "val_acc": 56.0}
