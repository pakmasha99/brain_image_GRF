"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 17593292.714424133, "training_acc": 49.0, "val_loss": 2780825.390625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 14904673.4375, "training_acc": 53.0, "val_loss": 9697753.90625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 37142496.375, "training_acc": 53.0, "val_loss": 6335130.859375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 18469031.40625, "training_acc": 53.0, "val_loss": 3580852.734375, "val_acc": 48.0}
{"epoch": 4, "training_loss": 17669086.0, "training_acc": 47.0, "val_loss": 6057575.0, "val_acc": 48.0}
{"epoch": 5, "training_loss": 22051902.25, "training_acc": 47.0, "val_loss": 971707.51953125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7081276.96875, "training_acc": 49.0, "val_loss": 5331525.0, "val_acc": 52.0}
{"epoch": 7, "training_loss": 21382311.9375, "training_acc": 53.0, "val_loss": 4938873.046875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 16581545.9375, "training_acc": 53.0, "val_loss": 76535.85815429688, "val_acc": 52.0}
{"epoch": 9, "training_loss": 7831001.8125, "training_acc": 41.0, "val_loss": 5893382.03125, "val_acc": 48.0}
{"epoch": 10, "training_loss": 24852753.0, "training_acc": 47.0, "val_loss": 4812208.984375, "val_acc": 48.0}
{"epoch": 11, "training_loss": 15611202.625, "training_acc": 47.0, "val_loss": 1302595.21484375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 8154057.125, "training_acc": 53.0, "val_loss": 3712905.859375, "val_acc": 52.0}
{"epoch": 13, "training_loss": 13675463.53125, "training_acc": 53.0, "val_loss": 1450946.19140625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4845231.8125, "training_acc": 53.0, "val_loss": 1983757.2265625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 7620506.46875, "training_acc": 47.0, "val_loss": 24257.937622070312, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3087918.859375, "training_acc": 53.0, "val_loss": 3659350.0, "val_acc": 52.0}
{"epoch": 17, "training_loss": 14357668.75, "training_acc": 53.0, "val_loss": 2725498.6328125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 8386846.75, "training_acc": 53.0, "val_loss": 1951664.84375, "val_acc": 48.0}
{"epoch": 19, "training_loss": 9401028.84375, "training_acc": 47.0, "val_loss": 2918038.8671875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 9841955.0, "training_acc": 47.0, "val_loss": 806100.29296875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 4300562.46875, "training_acc": 53.0, "val_loss": 1629394.7265625, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4834508.28125, "training_acc": 53.0, "val_loss": 1554561.71875, "val_acc": 48.0}
{"epoch": 23, "training_loss": 7594278.03125, "training_acc": 47.0, "val_loss": 1529662.109375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4679483.64453125, "training_acc": 47.0, "val_loss": 879004.296875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2652974.05078125, "training_acc": 53.0, "val_loss": 1270746.19140625, "val_acc": 48.0}
{"epoch": 26, "training_loss": 5529206.046875, "training_acc": 47.0, "val_loss": 419397.314453125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 3593406.1875, "training_acc": 47.0, "val_loss": 2362108.984375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 8772545.125, "training_acc": 53.0, "val_loss": 675348.486328125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3885933.90625, "training_acc": 53.0, "val_loss": 2547953.515625, "val_acc": 48.0}
{"epoch": 30, "training_loss": 9821153.21875, "training_acc": 47.0, "val_loss": 556562.060546875, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4450567.46875, "training_acc": 47.0, "val_loss": 3087475.0, "val_acc": 52.0}
{"epoch": 32, "training_loss": 12067769.4375, "training_acc": 53.0, "val_loss": 2056417.7734375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 5378490.80859375, "training_acc": 53.0, "val_loss": 2696132.6171875, "val_acc": 48.0}
{"epoch": 34, "training_loss": 12740136.3125, "training_acc": 47.0, "val_loss": 3912760.15625, "val_acc": 48.0}
