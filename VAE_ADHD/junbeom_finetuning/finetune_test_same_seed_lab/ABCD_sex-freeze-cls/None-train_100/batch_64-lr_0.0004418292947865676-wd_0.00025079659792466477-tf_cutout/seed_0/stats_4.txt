"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.05915951728821, "training_acc": 47.0, "val_loss": 17.322593927383423, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.001389503479, "training_acc": 53.0, "val_loss": 17.40562468767166, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.38985133171082, "training_acc": 53.0, "val_loss": 17.457547783851624, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.60532879829407, "training_acc": 53.0, "val_loss": 17.432372272014618, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33876729011536, "training_acc": 53.0, "val_loss": 17.34490543603897, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.47247982025146, "training_acc": 53.0, "val_loss": 17.308330535888672, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.23697209358215, "training_acc": 53.0, "val_loss": 17.312784492969513, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.30959963798523, "training_acc": 53.0, "val_loss": 17.312003672122955, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.32334876060486, "training_acc": 53.0, "val_loss": 17.31579601764679, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22512555122375, "training_acc": 53.0, "val_loss": 17.308935523033142, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13377165794373, "training_acc": 53.0, "val_loss": 17.310312390327454, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09759902954102, "training_acc": 53.0, "val_loss": 17.324410378932953, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13100385665894, "training_acc": 53.0, "val_loss": 17.358382046222687, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2261438369751, "training_acc": 53.0, "val_loss": 17.385022342205048, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.33119320869446, "training_acc": 53.0, "val_loss": 17.394694685935974, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.31787848472595, "training_acc": 53.0, "val_loss": 17.366614937782288, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.26528930664062, "training_acc": 53.0, "val_loss": 17.332357168197632, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20464086532593, "training_acc": 53.0, "val_loss": 17.313650250434875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15824604034424, "training_acc": 53.0, "val_loss": 17.309066653251648, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15845537185669, "training_acc": 53.0, "val_loss": 17.308446764945984, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16397857666016, "training_acc": 53.0, "val_loss": 17.308509349822998, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14803075790405, "training_acc": 53.0, "val_loss": 17.310266196727753, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13276791572571, "training_acc": 53.0, "val_loss": 17.313872277736664, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11560463905334, "training_acc": 53.0, "val_loss": 17.317771911621094, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14352440834045, "training_acc": 53.0, "val_loss": 17.322853207588196, "val_acc": 52.0}
