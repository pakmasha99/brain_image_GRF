"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23881602287292, "training_acc": 53.0, "val_loss": 17.308077216148376, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21746349334717, "training_acc": 53.0, "val_loss": 17.308254539966583, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.21393513679504, "training_acc": 53.0, "val_loss": 17.307893931865692, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20869493484497, "training_acc": 53.0, "val_loss": 17.30746477842331, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18296813964844, "training_acc": 53.0, "val_loss": 17.3072412610054, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16146039962769, "training_acc": 53.0, "val_loss": 17.306846380233765, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16364693641663, "training_acc": 53.0, "val_loss": 17.306463420391083, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16912055015564, "training_acc": 53.0, "val_loss": 17.30610430240631, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17766189575195, "training_acc": 53.0, "val_loss": 17.305850982666016, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21541953086853, "training_acc": 53.0, "val_loss": 17.30557382106781, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15633726119995, "training_acc": 53.0, "val_loss": 17.305289208889008, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16314363479614, "training_acc": 53.0, "val_loss": 17.305056750774384, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1623284816742, "training_acc": 53.0, "val_loss": 17.304816842079163, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18687844276428, "training_acc": 53.0, "val_loss": 17.30457991361618, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20056200027466, "training_acc": 53.0, "val_loss": 17.304405570030212, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14705610275269, "training_acc": 53.0, "val_loss": 17.30429083108902, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14726948738098, "training_acc": 53.0, "val_loss": 17.3041969537735, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16163301467896, "training_acc": 53.0, "val_loss": 17.304128408432007, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13449597358704, "training_acc": 53.0, "val_loss": 17.30407476425171, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17964100837708, "training_acc": 53.0, "val_loss": 17.304055392742157, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10346937179565, "training_acc": 53.0, "val_loss": 17.304065823554993, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16543197631836, "training_acc": 53.0, "val_loss": 17.304137349128723, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1341347694397, "training_acc": 53.0, "val_loss": 17.304272949695587, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16894555091858, "training_acc": 53.0, "val_loss": 17.30441451072693, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15983557701111, "training_acc": 53.0, "val_loss": 17.304614186286926, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14561080932617, "training_acc": 53.0, "val_loss": 17.304804921150208, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15104842185974, "training_acc": 53.0, "val_loss": 17.305053770542145, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12536454200745, "training_acc": 53.0, "val_loss": 17.305341362953186, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.10516285896301, "training_acc": 53.0, "val_loss": 17.305639386177063, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16463971138, "training_acc": 53.0, "val_loss": 17.30600744485855, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14057469367981, "training_acc": 53.0, "val_loss": 17.306290566921234, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12319350242615, "training_acc": 53.0, "val_loss": 17.306579649448395, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1456880569458, "training_acc": 53.0, "val_loss": 17.306910455226898, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1263997554779, "training_acc": 53.0, "val_loss": 17.30719953775406, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14965844154358, "training_acc": 53.0, "val_loss": 17.307573556900024, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15184497833252, "training_acc": 53.0, "val_loss": 17.307864129543304, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15149641036987, "training_acc": 53.0, "val_loss": 17.30811297893524, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14406561851501, "training_acc": 53.0, "val_loss": 17.308375239372253, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15480589866638, "training_acc": 53.0, "val_loss": 17.308562994003296, "val_acc": 52.0}
