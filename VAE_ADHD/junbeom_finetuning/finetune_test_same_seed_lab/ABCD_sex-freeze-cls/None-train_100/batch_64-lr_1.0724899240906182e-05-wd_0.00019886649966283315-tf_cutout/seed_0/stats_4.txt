"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.76039934158325, "training_acc": 47.0, "val_loss": 17.417922616004944, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.73647809028625, "training_acc": 47.0, "val_loss": 17.407917976379395, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.6776807308197, "training_acc": 47.0, "val_loss": 17.398974299430847, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.60547137260437, "training_acc": 47.0, "val_loss": 17.39162653684616, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58203172683716, "training_acc": 47.0, "val_loss": 17.384475469589233, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.54637813568115, "training_acc": 47.0, "val_loss": 17.377924919128418, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.54743695259094, "training_acc": 47.0, "val_loss": 17.372219264507294, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.5038423538208, "training_acc": 47.0, "val_loss": 17.36709326505661, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.44739055633545, "training_acc": 47.0, "val_loss": 17.362256348133087, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.44834876060486, "training_acc": 47.0, "val_loss": 17.35750585794449, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41719603538513, "training_acc": 47.0, "val_loss": 17.353317141532898, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.38995027542114, "training_acc": 47.0, "val_loss": 17.34970211982727, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.39092183113098, "training_acc": 47.0, "val_loss": 17.34600067138672, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.37239050865173, "training_acc": 47.0, "val_loss": 17.34292358160019, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.32550287246704, "training_acc": 51.0, "val_loss": 17.34018623828888, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.28789353370667, "training_acc": 52.0, "val_loss": 17.337359488010406, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.28798961639404, "training_acc": 55.0, "val_loss": 17.334802448749542, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2747733592987, "training_acc": 52.0, "val_loss": 17.33250319957733, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.30089902877808, "training_acc": 53.0, "val_loss": 17.330586910247803, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.27920126914978, "training_acc": 53.0, "val_loss": 17.328816652297974, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23991847038269, "training_acc": 53.0, "val_loss": 17.327050864696503, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21882963180542, "training_acc": 53.0, "val_loss": 17.32555478811264, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.24565625190735, "training_acc": 53.0, "val_loss": 17.324289679527283, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22145581245422, "training_acc": 53.0, "val_loss": 17.323163151741028, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20715260505676, "training_acc": 53.0, "val_loss": 17.322172224521637, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19450044631958, "training_acc": 53.0, "val_loss": 17.321263253688812, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2136013507843, "training_acc": 53.0, "val_loss": 17.32044816017151, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2258653640747, "training_acc": 53.0, "val_loss": 17.319726943969727, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1832344532013, "training_acc": 53.0, "val_loss": 17.319196462631226, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20674157142639, "training_acc": 53.0, "val_loss": 17.31872707605362, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17377495765686, "training_acc": 53.0, "val_loss": 17.318324744701385, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18238520622253, "training_acc": 53.0, "val_loss": 17.31802374124527, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18968987464905, "training_acc": 53.0, "val_loss": 17.317743599414825, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.16787981987, "training_acc": 53.0, "val_loss": 17.31758862733841, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16794610023499, "training_acc": 53.0, "val_loss": 17.317500710487366, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1502616405487, "training_acc": 53.0, "val_loss": 17.317453026771545, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14937949180603, "training_acc": 53.0, "val_loss": 17.317435145378113, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11172032356262, "training_acc": 53.0, "val_loss": 17.31742024421692, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.11978960037231, "training_acc": 53.0, "val_loss": 17.31741726398468, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16040349006653, "training_acc": 53.0, "val_loss": 17.31742024421692, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13819026947021, "training_acc": 53.0, "val_loss": 17.317423224449158, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.14692711830139, "training_acc": 53.0, "val_loss": 17.317435145378113, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12491989135742, "training_acc": 53.0, "val_loss": 17.317451536655426, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.12850618362427, "training_acc": 53.0, "val_loss": 17.317499220371246, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17388343811035, "training_acc": 53.0, "val_loss": 17.31758862733841, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15058493614197, "training_acc": 53.0, "val_loss": 17.317679524421692, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.12857818603516, "training_acc": 53.0, "val_loss": 17.3177570104599, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16698408126831, "training_acc": 53.0, "val_loss": 17.317816615104675, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.17671513557434, "training_acc": 53.0, "val_loss": 17.317834496498108, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.15460085868835, "training_acc": 53.0, "val_loss": 17.317785322666168, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13682866096497, "training_acc": 53.0, "val_loss": 17.317740619182587, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.12446141242981, "training_acc": 53.0, "val_loss": 17.31778085231781, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.16495871543884, "training_acc": 53.0, "val_loss": 17.317786812782288, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.13621401786804, "training_acc": 53.0, "val_loss": 17.317846417427063, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.11448001861572, "training_acc": 53.0, "val_loss": 17.317864298820496, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.18990707397461, "training_acc": 53.0, "val_loss": 17.31792241334915, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.1655113697052, "training_acc": 53.0, "val_loss": 17.31799989938736, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15003395080566, "training_acc": 53.0, "val_loss": 17.318090796470642, "val_acc": 52.0}
