"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26051259040833, "training_acc": 52.0, "val_loss": 17.25294142961502, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2582700252533, "training_acc": 52.0, "val_loss": 17.205432057380676, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.28147077560425, "training_acc": 52.0, "val_loss": 17.20409393310547, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26216411590576, "training_acc": 52.0, "val_loss": 17.22937375307083, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24503827095032, "training_acc": 52.0, "val_loss": 17.2680526971817, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.24137854576111, "training_acc": 52.0, "val_loss": 17.28070229291916, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.28418731689453, "training_acc": 52.0, "val_loss": 17.300251126289368, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.29244542121887, "training_acc": 52.0, "val_loss": 17.297358810901642, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.33778119087219, "training_acc": 52.0, "val_loss": 17.27190762758255, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26449823379517, "training_acc": 52.0, "val_loss": 17.26689636707306, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23252320289612, "training_acc": 52.0, "val_loss": 17.259982228279114, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26210403442383, "training_acc": 52.0, "val_loss": 17.247574031352997, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23399472236633, "training_acc": 52.0, "val_loss": 17.237907648086548, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.2327663898468, "training_acc": 52.0, "val_loss": 17.237167060375214, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24070978164673, "training_acc": 52.0, "val_loss": 17.229735851287842, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24908137321472, "training_acc": 52.0, "val_loss": 17.219291627407074, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25508522987366, "training_acc": 52.0, "val_loss": 17.204008996486664, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24345374107361, "training_acc": 52.0, "val_loss": 17.19864308834076, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25488185882568, "training_acc": 52.0, "val_loss": 17.19781458377838, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.2671959400177, "training_acc": 52.0, "val_loss": 17.200736701488495, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22159886360168, "training_acc": 52.0, "val_loss": 17.210783064365387, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24282836914062, "training_acc": 52.0, "val_loss": 17.217689752578735, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.2917308807373, "training_acc": 52.0, "val_loss": 17.21491366624832, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25172066688538, "training_acc": 52.0, "val_loss": 17.225608229637146, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24844670295715, "training_acc": 52.0, "val_loss": 17.242684960365295, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25962805747986, "training_acc": 52.0, "val_loss": 17.264267802238464, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.33151912689209, "training_acc": 52.0, "val_loss": 17.266422510147095, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24206972122192, "training_acc": 52.0, "val_loss": 17.28958636522293, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.28900814056396, "training_acc": 52.0, "val_loss": 17.304491996765137, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.29559922218323, "training_acc": 52.0, "val_loss": 17.29423701763153, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.35741710662842, "training_acc": 52.0, "val_loss": 17.270489037036896, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29111456871033, "training_acc": 52.0, "val_loss": 17.268118262290955, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25388431549072, "training_acc": 52.0, "val_loss": 17.245417833328247, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24198389053345, "training_acc": 52.0, "val_loss": 17.229224741458893, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26531887054443, "training_acc": 52.0, "val_loss": 17.21309870481491, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23927021026611, "training_acc": 52.0, "val_loss": 17.207644879817963, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.2432930469513, "training_acc": 52.0, "val_loss": 17.205145955085754, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.26604104042053, "training_acc": 52.0, "val_loss": 17.20321625471115, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.25267362594604, "training_acc": 52.0, "val_loss": 17.194533348083496, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.28729748725891, "training_acc": 52.0, "val_loss": 17.181876301765442, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.2659752368927, "training_acc": 52.0, "val_loss": 17.182093858718872, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28565382957458, "training_acc": 52.0, "val_loss": 17.186114192008972, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27938604354858, "training_acc": 52.0, "val_loss": 17.19280183315277, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22755408287048, "training_acc": 52.0, "val_loss": 17.208096385002136, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26302218437195, "training_acc": 52.0, "val_loss": 17.238938808441162, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.22868728637695, "training_acc": 52.0, "val_loss": 17.262564599514008, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.26347088813782, "training_acc": 52.0, "val_loss": 17.286041378974915, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.2838728427887, "training_acc": 52.0, "val_loss": 17.302623391151428, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.27243375778198, "training_acc": 52.0, "val_loss": 17.297084629535675, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.28740668296814, "training_acc": 52.0, "val_loss": 17.286263406276703, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2886164188385, "training_acc": 52.0, "val_loss": 17.280791699886322, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.27341389656067, "training_acc": 52.0, "val_loss": 17.276324331760406, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.27877426147461, "training_acc": 52.0, "val_loss": 17.26921945810318, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27209544181824, "training_acc": 52.0, "val_loss": 17.264840006828308, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21692204475403, "training_acc": 52.0, "val_loss": 17.259812355041504, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26852464675903, "training_acc": 52.0, "val_loss": 17.247049510478973, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24127745628357, "training_acc": 52.0, "val_loss": 17.243899405002594, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23524212837219, "training_acc": 52.0, "val_loss": 17.245717346668243, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2249505519867, "training_acc": 52.0, "val_loss": 17.24064350128174, "val_acc": 56.0}
