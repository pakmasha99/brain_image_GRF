"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.27528834342957, "training_acc": 47.0, "val_loss": 17.379310727119446, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.50230145454407, "training_acc": 47.0, "val_loss": 17.304474115371704, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.17489981651306, "training_acc": 53.0, "val_loss": 17.302420735359192, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10241651535034, "training_acc": 53.0, "val_loss": 17.34135001897812, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4391770362854, "training_acc": 53.0, "val_loss": 17.385871708393097, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.37229895591736, "training_acc": 53.0, "val_loss": 17.38801896572113, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.3862955570221, "training_acc": 53.0, "val_loss": 17.36779808998108, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.27129697799683, "training_acc": 53.0, "val_loss": 17.35265851020813, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24013662338257, "training_acc": 53.0, "val_loss": 17.327973246574402, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.25927019119263, "training_acc": 53.0, "val_loss": 17.311587929725647, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19350528717041, "training_acc": 53.0, "val_loss": 17.30472892522812, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.179612159729, "training_acc": 53.0, "val_loss": 17.301371693611145, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15593409538269, "training_acc": 53.0, "val_loss": 17.30082631111145, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14862775802612, "training_acc": 53.0, "val_loss": 17.300359904766083, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1360936164856, "training_acc": 53.0, "val_loss": 17.299972474575043, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15302586555481, "training_acc": 53.0, "val_loss": 17.30029433965683, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16368198394775, "training_acc": 53.0, "val_loss": 17.300502955913544, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13582992553711, "training_acc": 53.0, "val_loss": 17.30179190635681, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12610960006714, "training_acc": 53.0, "val_loss": 17.306260764598846, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13625764846802, "training_acc": 53.0, "val_loss": 17.309750616550446, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18780565261841, "training_acc": 53.0, "val_loss": 17.315490543842316, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.19752216339111, "training_acc": 53.0, "val_loss": 17.316581308841705, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15996670722961, "training_acc": 53.0, "val_loss": 17.309612035751343, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14745712280273, "training_acc": 53.0, "val_loss": 17.30491667985916, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22874593734741, "training_acc": 53.0, "val_loss": 17.30058044195175, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16022562980652, "training_acc": 53.0, "val_loss": 17.30126142501831, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.136723279953, "training_acc": 53.0, "val_loss": 17.30174571275711, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12638473510742, "training_acc": 53.0, "val_loss": 17.30256974697113, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.21240043640137, "training_acc": 53.0, "val_loss": 17.305564880371094, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16664695739746, "training_acc": 53.0, "val_loss": 17.305122315883636, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17899012565613, "training_acc": 53.0, "val_loss": 17.304441332817078, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1671690940857, "training_acc": 53.0, "val_loss": 17.30124205350876, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14512991905212, "training_acc": 53.0, "val_loss": 17.301322519779205, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12584662437439, "training_acc": 53.0, "val_loss": 17.30269342660904, "val_acc": 52.0}
