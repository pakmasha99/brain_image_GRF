"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 15034064.853786469, "training_acc": 53.0, "val_loss": 3062960.9375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 11117532.625, "training_acc": 57.0, "val_loss": 5557144.53125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 21222425.625, "training_acc": 47.0, "val_loss": 1692124.4140625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7354021.8125, "training_acc": 51.0, "val_loss": 4151101.5625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 16502744.3125, "training_acc": 53.0, "val_loss": 3306764.453125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 9783925.46875, "training_acc": 53.0, "val_loss": 1805870.703125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 9467188.125, "training_acc": 47.0, "val_loss": 3231509.375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 11366009.6875, "training_acc": 47.0, "val_loss": 241310.546875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2329835.203125, "training_acc": 53.0, "val_loss": 989349.31640625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2467570.6064453125, "training_acc": 53.0, "val_loss": 14023.599243164062, "val_acc": 48.0}
{"epoch": 10, "training_loss": 913422.12890625, "training_acc": 59.0, "val_loss": 1054847.265625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3182084.556640625, "training_acc": 53.0, "val_loss": 1315277.05078125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 5788662.546875, "training_acc": 47.0, "val_loss": 911099.0234375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 4257042.0, "training_acc": 39.0, "val_loss": 1235895.99609375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 4195309.734375, "training_acc": 53.0, "val_loss": 491187.59765625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2568760.734375, "training_acc": 47.0, "val_loss": 12546.620178222656, "val_acc": 52.0}
{"epoch": 16, "training_loss": 291480.173828125, "training_acc": 47.0, "val_loss": 697305.46875, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2681801.0, "training_acc": 53.0, "val_loss": 178198.193359375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 552921.720703125, "training_acc": 47.0, "val_loss": 1000073.92578125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 4272955.953125, "training_acc": 53.0, "val_loss": 548207.470703125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1979876.125, "training_acc": 61.0, "val_loss": 1310124.8046875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 4632891.40625, "training_acc": 47.0, "val_loss": 524700.0, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2612565.71875, "training_acc": 53.0, "val_loss": 485829.541015625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2036019.2265625, "training_acc": 55.0, "val_loss": 930660.3515625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2688775.203125, "training_acc": 47.0, "val_loss": 1325141.30859375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 5855563.8125, "training_acc": 53.0, "val_loss": 1647980.46875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5170663.953125, "training_acc": 53.0, "val_loss": 1081797.4609375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 5312380.6875, "training_acc": 47.0, "val_loss": 1301747.265625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3558897.0073242188, "training_acc": 47.0, "val_loss": 320695.6298828125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 962710.37109375, "training_acc": 55.0, "val_loss": 208821.1181640625, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1168165.8515625, "training_acc": 45.0, "val_loss": 209183.69140625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 596068.2607421875, "training_acc": 53.0, "val_loss": 524545.60546875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1697714.70703125, "training_acc": 53.0, "val_loss": 795888.232421875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3434801.125, "training_acc": 47.0, "val_loss": 77804.33959960938, "val_acc": 52.0}
{"epoch": 34, "training_loss": 372747.7578125, "training_acc": 53.0, "val_loss": 660198.779296875, "val_acc": 48.0}
