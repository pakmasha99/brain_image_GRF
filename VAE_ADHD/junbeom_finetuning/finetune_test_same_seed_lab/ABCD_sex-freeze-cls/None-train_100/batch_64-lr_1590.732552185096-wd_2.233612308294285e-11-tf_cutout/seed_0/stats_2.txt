"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 14990128.450256348, "training_acc": 45.0, "val_loss": 2715611.5234375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 10184967.9375, "training_acc": 59.0, "val_loss": 7195487.5, "val_acc": 52.0}
{"epoch": 2, "training_loss": 27834253.75, "training_acc": 53.0, "val_loss": 5298382.421875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 16872346.625, "training_acc": 53.0, "val_loss": 1581960.25390625, "val_acc": 48.0}
{"epoch": 4, "training_loss": 8512208.09375, "training_acc": 47.0, "val_loss": 3077688.0859375, "val_acc": 48.0}
{"epoch": 5, "training_loss": 10122167.875, "training_acc": 47.0, "val_loss": 1057776.46484375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 5917892.59375, "training_acc": 53.0, "val_loss": 2147794.7265625, "val_acc": 52.0}
{"epoch": 7, "training_loss": 7016970.7421875, "training_acc": 53.0, "val_loss": 1014497.94921875, "val_acc": 48.0}
{"epoch": 8, "training_loss": 5218310.9375, "training_acc": 47.0, "val_loss": 1000762.5, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3398667.2265625, "training_acc": 51.0, "val_loss": 1176212.59765625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4010135.1484375, "training_acc": 53.0, "val_loss": 576072.119140625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2361822.640625, "training_acc": 47.0, "val_loss": 321937.7685546875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1106130.197265625, "training_acc": 53.0, "val_loss": 765575.732421875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2967397.2578125, "training_acc": 47.0, "val_loss": 496490.380859375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2184599.6796875, "training_acc": 53.0, "val_loss": 16761.964416503906, "val_acc": 48.0}
{"epoch": 15, "training_loss": 301717.064453125, "training_acc": 55.0, "val_loss": 262917.5537109375, "val_acc": 48.0}
{"epoch": 16, "training_loss": 1148779.5546875, "training_acc": 47.0, "val_loss": 101232.86743164062, "val_acc": 48.0}
{"epoch": 17, "training_loss": 940862.6640625, "training_acc": 49.0, "val_loss": 176083.09326171875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 2001170.390625, "training_acc": 49.0, "val_loss": 1045928.41796875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2918891.7353515625, "training_acc": 47.0, "val_loss": 1584628.80859375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 7387793.09375, "training_acc": 53.0, "val_loss": 2107145.703125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 6798815.796875, "training_acc": 53.0, "val_loss": 626486.1328125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3775396.546875, "training_acc": 47.0, "val_loss": 998646.19140625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3155373.57421875, "training_acc": 47.0, "val_loss": 584208.10546875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1525587.0, "training_acc": 53.0, "val_loss": 1330480.17578125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 5832066.03125, "training_acc": 47.0, "val_loss": 908314.84375, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3422248.9921875, "training_acc": 47.0, "val_loss": 1161058.984375, "val_acc": 52.0}
{"epoch": 27, "training_loss": 4083503.859375, "training_acc": 53.0, "val_loss": 257890.4541015625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1074029.1171875, "training_acc": 47.0, "val_loss": 561754.19921875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 2138357.0390625, "training_acc": 53.0, "val_loss": 331185.6201171875, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1158417.83984375, "training_acc": 47.0, "val_loss": 831506.4453125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3512120.640625, "training_acc": 53.0, "val_loss": 327135.64453125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 2339020.859375, "training_acc": 53.0, "val_loss": 1545183.59375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 5467083.65625, "training_acc": 47.0, "val_loss": 443823.486328125, "val_acc": 52.0}
