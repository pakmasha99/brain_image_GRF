"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.44560194015503, "training_acc": 47.0, "val_loss": 17.45162606239319, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.88957262039185, "training_acc": 47.0, "val_loss": 17.375347018241882, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.49652791023254, "training_acc": 47.0, "val_loss": 17.328523099422455, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2963764667511, "training_acc": 52.0, "val_loss": 17.310436069965363, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18318152427673, "training_acc": 53.0, "val_loss": 17.316894233226776, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11752367019653, "training_acc": 53.0, "val_loss": 17.336755990982056, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17409348487854, "training_acc": 53.0, "val_loss": 17.360012233257294, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.24322485923767, "training_acc": 53.0, "val_loss": 17.37573593854904, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.28425908088684, "training_acc": 53.0, "val_loss": 17.379528284072876, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30940246582031, "training_acc": 53.0, "val_loss": 17.374829947948456, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.27910280227661, "training_acc": 53.0, "val_loss": 17.36694723367691, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27395963668823, "training_acc": 53.0, "val_loss": 17.348074913024902, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20032930374146, "training_acc": 53.0, "val_loss": 17.332030832767487, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13897347450256, "training_acc": 53.0, "val_loss": 17.32088029384613, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.10740280151367, "training_acc": 53.0, "val_loss": 17.313608527183533, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14102053642273, "training_acc": 53.0, "val_loss": 17.310184240341187, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1848030090332, "training_acc": 53.0, "val_loss": 17.310455441474915, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21925044059753, "training_acc": 53.0, "val_loss": 17.31175035238266, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19689893722534, "training_acc": 53.0, "val_loss": 17.31182634830475, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17998266220093, "training_acc": 53.0, "val_loss": 17.31037348508835, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19184994697571, "training_acc": 53.0, "val_loss": 17.31007993221283, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1470787525177, "training_acc": 53.0, "val_loss": 17.3107773065567, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16503262519836, "training_acc": 53.0, "val_loss": 17.311587929725647, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10462093353271, "training_acc": 53.0, "val_loss": 17.31267124414444, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15967535972595, "training_acc": 53.0, "val_loss": 17.31502264738083, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14122080802917, "training_acc": 53.0, "val_loss": 17.316199839115143, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16183567047119, "training_acc": 53.0, "val_loss": 17.316780984401703, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16566300392151, "training_acc": 53.0, "val_loss": 17.320694029331207, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11883234977722, "training_acc": 53.0, "val_loss": 17.321456968784332, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11370205879211, "training_acc": 53.0, "val_loss": 17.32124239206314, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17951965332031, "training_acc": 53.0, "val_loss": 17.323623597621918, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15633344650269, "training_acc": 53.0, "val_loss": 17.32485592365265, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16356301307678, "training_acc": 53.0, "val_loss": 17.325004935264587, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15106654167175, "training_acc": 53.0, "val_loss": 17.322400212287903, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.18926048278809, "training_acc": 53.0, "val_loss": 17.32039451599121, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18005633354187, "training_acc": 53.0, "val_loss": 17.320595681667328, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14698052406311, "training_acc": 53.0, "val_loss": 17.31954962015152, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14887976646423, "training_acc": 53.0, "val_loss": 17.317649722099304, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1700701713562, "training_acc": 53.0, "val_loss": 17.316024005413055, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1408965587616, "training_acc": 53.0, "val_loss": 17.314715683460236, "val_acc": 52.0}
