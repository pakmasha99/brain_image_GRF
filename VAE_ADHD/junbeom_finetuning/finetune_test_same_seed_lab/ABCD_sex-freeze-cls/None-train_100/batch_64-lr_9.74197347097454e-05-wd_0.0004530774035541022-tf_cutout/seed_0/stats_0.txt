"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24647068977356, "training_acc": 52.0, "val_loss": 17.24563241004944, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2438657283783, "training_acc": 52.0, "val_loss": 17.2160342335701, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.26365828514099, "training_acc": 52.0, "val_loss": 17.21382886171341, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26337170600891, "training_acc": 52.0, "val_loss": 17.228759825229645, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24177169799805, "training_acc": 52.0, "val_loss": 17.252379655838013, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23012042045593, "training_acc": 52.0, "val_loss": 17.26081073284149, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.266526222229, "training_acc": 52.0, "val_loss": 17.276637256145477, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.27042484283447, "training_acc": 52.0, "val_loss": 17.2808438539505, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.29515290260315, "training_acc": 52.0, "val_loss": 17.26929098367691, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26153540611267, "training_acc": 52.0, "val_loss": 17.270225286483765, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23622393608093, "training_acc": 52.0, "val_loss": 17.26856231689453, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26600742340088, "training_acc": 52.0, "val_loss": 17.26113110780716, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23591637611389, "training_acc": 52.0, "val_loss": 17.253585159778595, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23615717887878, "training_acc": 52.0, "val_loss": 17.250922322273254, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24343490600586, "training_acc": 52.0, "val_loss": 17.24221408367157, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2471513748169, "training_acc": 52.0, "val_loss": 17.23078489303589, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25177121162415, "training_acc": 52.0, "val_loss": 17.21538007259369, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23630976676941, "training_acc": 52.0, "val_loss": 17.207029461860657, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24761509895325, "training_acc": 52.0, "val_loss": 17.20205247402191, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26529431343079, "training_acc": 52.0, "val_loss": 17.2000914812088, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21710443496704, "training_acc": 52.0, "val_loss": 17.20358282327652, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23812484741211, "training_acc": 52.0, "val_loss": 17.206229269504547, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29112935066223, "training_acc": 52.0, "val_loss": 17.20423400402069, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25818181037903, "training_acc": 52.0, "val_loss": 17.211821675300598, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25278902053833, "training_acc": 52.0, "val_loss": 17.224572598934174, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25216221809387, "training_acc": 52.0, "val_loss": 17.24173277616501, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.29002118110657, "training_acc": 52.0, "val_loss": 17.247964441776276, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23120450973511, "training_acc": 52.0, "val_loss": 17.26817637681961, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.26657509803772, "training_acc": 52.0, "val_loss": 17.28452444076538, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.28061413764954, "training_acc": 52.0, "val_loss": 17.285434901714325, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.31265139579773, "training_acc": 52.0, "val_loss": 17.27568805217743, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29333829879761, "training_acc": 52.0, "val_loss": 17.2784686088562, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25943636894226, "training_acc": 52.0, "val_loss": 17.264583706855774, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25478053092957, "training_acc": 52.0, "val_loss": 17.252741754055023, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26374650001526, "training_acc": 52.0, "val_loss": 17.238394916057587, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23626065254211, "training_acc": 52.0, "val_loss": 17.23051369190216, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23413825035095, "training_acc": 52.0, "val_loss": 17.223773896694183, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23934650421143, "training_acc": 52.0, "val_loss": 17.21714735031128, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2316963672638, "training_acc": 52.0, "val_loss": 17.205755412578583, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.26801323890686, "training_acc": 52.0, "val_loss": 17.19178557395935, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.24888563156128, "training_acc": 52.0, "val_loss": 17.18795895576477, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.27542161941528, "training_acc": 52.0, "val_loss": 17.187166213989258, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2840359210968, "training_acc": 52.0, "val_loss": 17.18854457139969, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24492740631104, "training_acc": 52.0, "val_loss": 17.19583123922348, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26421022415161, "training_acc": 52.0, "val_loss": 17.2128826379776, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23430228233337, "training_acc": 52.0, "val_loss": 17.227187752723694, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25116086006165, "training_acc": 52.0, "val_loss": 17.243775725364685, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.25005006790161, "training_acc": 52.0, "val_loss": 17.259235680103302, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.23404741287231, "training_acc": 52.0, "val_loss": 17.264172434806824, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.24571251869202, "training_acc": 52.0, "val_loss": 17.266589403152466, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.26634192466736, "training_acc": 52.0, "val_loss": 17.2719806432724, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.26528143882751, "training_acc": 52.0, "val_loss": 17.27706640958786, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.27356600761414, "training_acc": 52.0, "val_loss": 17.27869212627411, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27905750274658, "training_acc": 52.0, "val_loss": 17.28014498949051, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.23093438148499, "training_acc": 52.0, "val_loss": 17.278972268104553, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27263808250427, "training_acc": 52.0, "val_loss": 17.269834876060486, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25265169143677, "training_acc": 52.0, "val_loss": 17.26580709218979, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24385476112366, "training_acc": 52.0, "val_loss": 17.26401150226593, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23484349250793, "training_acc": 52.0, "val_loss": 17.25621372461319, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25446367263794, "training_acc": 52.0, "val_loss": 17.24991500377655, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28280639648438, "training_acc": 52.0, "val_loss": 17.23768264055252, "val_acc": 56.0}
