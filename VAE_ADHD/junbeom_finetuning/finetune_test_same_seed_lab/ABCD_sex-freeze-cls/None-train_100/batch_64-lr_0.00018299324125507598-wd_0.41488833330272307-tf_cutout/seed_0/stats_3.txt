"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.53683567047119, "training_acc": 45.0, "val_loss": 17.326612770557404, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30222058296204, "training_acc": 53.0, "val_loss": 17.31172204017639, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18644618988037, "training_acc": 53.0, "val_loss": 17.327743768692017, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16738438606262, "training_acc": 53.0, "val_loss": 17.342330515384674, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20981478691101, "training_acc": 53.0, "val_loss": 17.340682446956635, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1791512966156, "training_acc": 53.0, "val_loss": 17.34273135662079, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15601372718811, "training_acc": 53.0, "val_loss": 17.334212362766266, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16349840164185, "training_acc": 53.0, "val_loss": 17.322883009910583, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.123286485672, "training_acc": 53.0, "val_loss": 17.313426733016968, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13388347625732, "training_acc": 53.0, "val_loss": 17.311187088489532, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19676637649536, "training_acc": 53.0, "val_loss": 17.311179637908936, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15432691574097, "training_acc": 53.0, "val_loss": 17.312750220298767, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22547507286072, "training_acc": 53.0, "val_loss": 17.314667999744415, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21108841896057, "training_acc": 53.0, "val_loss": 17.31724888086319, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23192596435547, "training_acc": 53.0, "val_loss": 17.314089834690094, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1785843372345, "training_acc": 53.0, "val_loss": 17.311663925647736, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20374703407288, "training_acc": 53.0, "val_loss": 17.311912775039673, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14455842971802, "training_acc": 53.0, "val_loss": 17.315146327018738, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.197274684906, "training_acc": 53.0, "val_loss": 17.322689294815063, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18729019165039, "training_acc": 53.0, "val_loss": 17.326262593269348, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15709352493286, "training_acc": 53.0, "val_loss": 17.323732376098633, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13991498947144, "training_acc": 53.0, "val_loss": 17.320461571216583, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15483498573303, "training_acc": 53.0, "val_loss": 17.316192388534546, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19486165046692, "training_acc": 53.0, "val_loss": 17.31427311897278, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1396849155426, "training_acc": 53.0, "val_loss": 17.315703630447388, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14845967292786, "training_acc": 53.0, "val_loss": 17.31967329978943, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17223286628723, "training_acc": 53.0, "val_loss": 17.321354150772095, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14718747138977, "training_acc": 53.0, "val_loss": 17.32185184955597, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19447040557861, "training_acc": 53.0, "val_loss": 17.31797307729721, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1758201122284, "training_acc": 53.0, "val_loss": 17.318999767303467, "val_acc": 52.0}
