"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.45599055290222, "training_acc": 47.0, "val_loss": 17.71203577518463, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.70079684257507, "training_acc": 47.0, "val_loss": 17.452454566955566, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.64576268196106, "training_acc": 47.0, "val_loss": 17.327257990837097, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.08993148803711, "training_acc": 56.0, "val_loss": 17.308898270130157, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07748031616211, "training_acc": 53.0, "val_loss": 17.360322177410126, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3859932422638, "training_acc": 53.0, "val_loss": 17.43779331445694, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5168924331665, "training_acc": 53.0, "val_loss": 17.48483031988144, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.64047741889954, "training_acc": 53.0, "val_loss": 17.493660748004913, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.70247220993042, "training_acc": 53.0, "val_loss": 17.47252196073532, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.55955147743225, "training_acc": 53.0, "val_loss": 17.441116273403168, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4570050239563, "training_acc": 53.0, "val_loss": 17.395268380641937, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29358720779419, "training_acc": 53.0, "val_loss": 17.353953421115875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22152733802795, "training_acc": 53.0, "val_loss": 17.322131991386414, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.20937728881836, "training_acc": 53.0, "val_loss": 17.30763167142868, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1435010433197, "training_acc": 53.0, "val_loss": 17.305298149585724, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13269472122192, "training_acc": 53.0, "val_loss": 17.306174337863922, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.23163676261902, "training_acc": 53.0, "val_loss": 17.308159172534943, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23525381088257, "training_acc": 53.0, "val_loss": 17.30678081512451, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16080117225647, "training_acc": 53.0, "val_loss": 17.30653941631317, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19710278511047, "training_acc": 53.0, "val_loss": 17.305557429790497, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15634274482727, "training_acc": 53.0, "val_loss": 17.30533242225647, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17842888832092, "training_acc": 53.0, "val_loss": 17.305295169353485, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14540600776672, "training_acc": 53.0, "val_loss": 17.30610430240631, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24591565132141, "training_acc": 53.0, "val_loss": 17.30991303920746, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14681196212769, "training_acc": 53.0, "val_loss": 17.31075793504715, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12958264350891, "training_acc": 53.0, "val_loss": 17.314743995666504, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15903782844543, "training_acc": 53.0, "val_loss": 17.318005859851837, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13492894172668, "training_acc": 53.0, "val_loss": 17.321941256523132, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13924074172974, "training_acc": 53.0, "val_loss": 17.3293337225914, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17779541015625, "training_acc": 53.0, "val_loss": 17.334680259227753, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15906095504761, "training_acc": 53.0, "val_loss": 17.339131236076355, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20133543014526, "training_acc": 53.0, "val_loss": 17.33645796775818, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18422770500183, "training_acc": 53.0, "val_loss": 17.330355942249298, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19557666778564, "training_acc": 53.0, "val_loss": 17.3243448138237, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13372087478638, "training_acc": 53.0, "val_loss": 17.320595681667328, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13824391365051, "training_acc": 53.0, "val_loss": 17.317596077919006, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12472200393677, "training_acc": 53.0, "val_loss": 17.314328253269196, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14452338218689, "training_acc": 53.0, "val_loss": 17.31237918138504, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12602496147156, "training_acc": 53.0, "val_loss": 17.31065660715103, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13490796089172, "training_acc": 53.0, "val_loss": 17.309290170669556, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13017439842224, "training_acc": 53.0, "val_loss": 17.308993637561798, "val_acc": 52.0}
