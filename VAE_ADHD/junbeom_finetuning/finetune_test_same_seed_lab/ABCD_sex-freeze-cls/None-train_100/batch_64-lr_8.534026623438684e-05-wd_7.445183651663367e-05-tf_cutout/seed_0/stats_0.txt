"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24344086647034, "training_acc": 52.0, "val_loss": 17.243605852127075, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24038481712341, "training_acc": 52.0, "val_loss": 17.218557000160217, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2595682144165, "training_acc": 52.0, "val_loss": 17.216424643993378, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26356935501099, "training_acc": 52.0, "val_loss": 17.229022085666656, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24112057685852, "training_acc": 52.0, "val_loss": 17.249158024787903, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22819519042969, "training_acc": 52.0, "val_loss": 17.25640594959259, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26325583457947, "training_acc": 52.0, "val_loss": 17.27064549922943, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26515221595764, "training_acc": 52.0, "val_loss": 17.275534570217133, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.28463435173035, "training_acc": 52.0, "val_loss": 17.266790568828583, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25957798957825, "training_acc": 52.0, "val_loss": 17.268824577331543, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23549580574036, "training_acc": 52.0, "val_loss": 17.268510162830353, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26560235023499, "training_acc": 52.0, "val_loss": 17.262862622737885, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23551273345947, "training_acc": 52.0, "val_loss": 17.256683111190796, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.237717628479, "training_acc": 52.0, "val_loss": 17.25442111492157, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24528479576111, "training_acc": 52.0, "val_loss": 17.246365547180176, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24848961830139, "training_acc": 52.0, "val_loss": 17.23550409078598, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25135469436646, "training_acc": 52.0, "val_loss": 17.22065657377243, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23450469970703, "training_acc": 52.0, "val_loss": 17.211852967739105, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24463891983032, "training_acc": 52.0, "val_loss": 17.20590889453888, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26257038116455, "training_acc": 52.0, "val_loss": 17.202621698379517, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21346426010132, "training_acc": 52.0, "val_loss": 17.2042578458786, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23468351364136, "training_acc": 52.0, "val_loss": 17.205333709716797, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29130101203918, "training_acc": 52.0, "val_loss": 17.202700674533844, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26055932044983, "training_acc": 52.0, "val_loss": 17.208656668663025, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25574827194214, "training_acc": 52.0, "val_loss": 17.219318449497223, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25099873542786, "training_acc": 52.0, "val_loss": 17.23414808511734, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28313040733337, "training_acc": 52.0, "val_loss": 17.240238189697266, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22849249839783, "training_acc": 52.0, "val_loss": 17.25859045982361, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25822567939758, "training_acc": 52.0, "val_loss": 17.27430373430252, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.27271962165833, "training_acc": 52.0, "val_loss": 17.277519404888153, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.29664254188538, "training_acc": 52.0, "val_loss": 17.271576821804047, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29009580612183, "training_acc": 52.0, "val_loss": 17.276152968406677, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25709581375122, "training_acc": 52.0, "val_loss": 17.265841364860535, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2573390007019, "training_acc": 52.0, "val_loss": 17.25669801235199, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26328587532043, "training_acc": 52.0, "val_loss": 17.244558036327362, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23809027671814, "training_acc": 52.0, "val_loss": 17.237533628940582, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23510003089905, "training_acc": 52.0, "val_loss": 17.230966687202454, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.2368278503418, "training_acc": 52.0, "val_loss": 17.224082350730896, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22871351242065, "training_acc": 52.0, "val_loss": 17.21252053976059, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.26042222976685, "training_acc": 52.0, "val_loss": 17.198295891284943, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.24066853523254, "training_acc": 52.0, "val_loss": 17.1933650970459, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2674331665039, "training_acc": 52.0, "val_loss": 17.191191017627716, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27945041656494, "training_acc": 52.0, "val_loss": 17.19100922346115, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24539351463318, "training_acc": 52.0, "val_loss": 17.196159064769745, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26159191131592, "training_acc": 52.0, "val_loss": 17.20975786447525, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23820948600769, "training_acc": 52.0, "val_loss": 17.221032083034515, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25253295898438, "training_acc": 52.0, "val_loss": 17.23458468914032, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24445271492004, "training_acc": 52.0, "val_loss": 17.247767746448517, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22819828987122, "training_acc": 52.0, "val_loss": 17.252904176712036, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23739385604858, "training_acc": 52.0, "val_loss": 17.256508767604828, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25912594795227, "training_acc": 52.0, "val_loss": 17.263033986091614, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25865912437439, "training_acc": 52.0, "val_loss": 17.269618809223175, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.26644492149353, "training_acc": 52.0, "val_loss": 17.273391783237457, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27461194992065, "training_acc": 52.0, "val_loss": 17.276977002620697, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22950768470764, "training_acc": 52.0, "val_loss": 17.278093099594116, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.2683527469635, "training_acc": 52.0, "val_loss": 17.27180778980255, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25285339355469, "training_acc": 52.0, "val_loss": 17.26948320865631, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24699330329895, "training_acc": 52.0, "val_loss": 17.268629372119904, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23782658576965, "training_acc": 52.0, "val_loss": 17.26190149784088, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25778675079346, "training_acc": 52.0, "val_loss": 17.256034910678864, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28300499916077, "training_acc": 52.0, "val_loss": 17.2443687915802, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23678517341614, "training_acc": 52.0, "val_loss": 17.23971962928772, "val_acc": 56.0}
