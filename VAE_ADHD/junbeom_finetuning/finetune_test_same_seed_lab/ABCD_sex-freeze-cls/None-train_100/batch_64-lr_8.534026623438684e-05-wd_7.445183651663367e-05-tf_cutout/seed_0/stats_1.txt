"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.36539101600647, "training_acc": 47.0, "val_loss": 17.457106709480286, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.07112073898315, "training_acc": 47.0, "val_loss": 17.388102412223816, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.64079976081848, "training_acc": 47.0, "val_loss": 17.34825074672699, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.39035511016846, "training_acc": 47.0, "val_loss": 17.3237144947052, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.3890688419342, "training_acc": 47.0, "val_loss": 17.308366298675537, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18205642700195, "training_acc": 53.0, "val_loss": 17.303283512592316, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11013770103455, "training_acc": 53.0, "val_loss": 17.303064465522766, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14205861091614, "training_acc": 53.0, "val_loss": 17.30724722146988, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11979031562805, "training_acc": 53.0, "val_loss": 17.314709722995758, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18039679527283, "training_acc": 53.0, "val_loss": 17.324866354465485, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18984723091125, "training_acc": 53.0, "val_loss": 17.3339381814003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18197631835938, "training_acc": 53.0, "val_loss": 17.34006702899933, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21093511581421, "training_acc": 53.0, "val_loss": 17.34362542629242, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19672989845276, "training_acc": 53.0, "val_loss": 17.343275249004364, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21347498893738, "training_acc": 53.0, "val_loss": 17.341725528240204, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22520565986633, "training_acc": 53.0, "val_loss": 17.34173148870468, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22242045402527, "training_acc": 53.0, "val_loss": 17.33863651752472, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19800114631653, "training_acc": 53.0, "val_loss": 17.336665093898773, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18389940261841, "training_acc": 53.0, "val_loss": 17.331600189208984, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19553685188293, "training_acc": 53.0, "val_loss": 17.322321236133575, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16110920906067, "training_acc": 53.0, "val_loss": 17.315684258937836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22382855415344, "training_acc": 53.0, "val_loss": 17.31029450893402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15245723724365, "training_acc": 53.0, "val_loss": 17.30899214744568, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1779625415802, "training_acc": 53.0, "val_loss": 17.30787307024002, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14293336868286, "training_acc": 53.0, "val_loss": 17.307239770889282, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1567542552948, "training_acc": 53.0, "val_loss": 17.307808995246887, "val_acc": 52.0}
