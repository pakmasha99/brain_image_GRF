"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 12940812.228786469, "training_acc": 53.0, "val_loss": 2636491.2109375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 9569590.0625, "training_acc": 57.0, "val_loss": 4783399.21875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 18267535.0625, "training_acc": 47.0, "val_loss": 1456522.4609375, "val_acc": 48.0}
{"epoch": 3, "training_loss": 6330089.125, "training_acc": 51.0, "val_loss": 3573125.390625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 14204994.0, "training_acc": 53.0, "val_loss": 2846349.0234375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 8421665.453125, "training_acc": 53.0, "val_loss": 1554431.73828125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 8149030.5, "training_acc": 47.0, "val_loss": 2781572.4609375, "val_acc": 48.0}
{"epoch": 7, "training_loss": 9783470.71875, "training_acc": 47.0, "val_loss": 207711.5966796875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 2005440.984375, "training_acc": 53.0, "val_loss": 851597.55859375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2123999.6958007812, "training_acc": 53.0, "val_loss": 12071.35238647461, "val_acc": 48.0}
{"epoch": 10, "training_loss": 786242.82421875, "training_acc": 59.0, "val_loss": 907975.9765625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 2739027.427734375, "training_acc": 53.0, "val_loss": 1132145.703125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 4982683.3125, "training_acc": 47.0, "val_loss": 784243.115234375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3664316.3125, "training_acc": 39.0, "val_loss": 1063816.2109375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3611177.140625, "training_acc": 53.0, "val_loss": 422797.75390625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2211102.3125, "training_acc": 47.0, "val_loss": 10799.407196044922, "val_acc": 52.0}
{"epoch": 16, "training_loss": 250895.814453125, "training_acc": 47.0, "val_loss": 600216.259765625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 2308401.0625, "training_acc": 53.0, "val_loss": 153387.1826171875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 475937.2783203125, "training_acc": 47.0, "val_loss": 860829.00390625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 3678012.578125, "training_acc": 53.0, "val_loss": 471877.880859375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1704208.9609375, "training_acc": 61.0, "val_loss": 1127710.7421875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3987834.7734375, "training_acc": 47.0, "val_loss": 451643.45703125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2248805.78125, "training_acc": 53.0, "val_loss": 418185.009765625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1752535.15625, "training_acc": 55.0, "val_loss": 801080.712890625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2314406.66015625, "training_acc": 47.0, "val_loss": 1140635.83984375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 5040267.09375, "training_acc": 53.0, "val_loss": 1418524.51171875, "val_acc": 52.0}
{"epoch": 26, "training_loss": 4450729.3203125, "training_acc": 53.0, "val_loss": 931174.4140625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 4572716.03125, "training_acc": 47.0, "val_loss": 1120499.609375, "val_acc": 48.0}
{"epoch": 28, "training_loss": 3063376.486328125, "training_acc": 47.0, "val_loss": 276043.45703125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 828667.69140625, "training_acc": 55.0, "val_loss": 179745.751953125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1005516.70703125, "training_acc": 45.0, "val_loss": 180057.8369140625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 513074.7998046875, "training_acc": 53.0, "val_loss": 451510.595703125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1461333.55078125, "training_acc": 53.0, "val_loss": 685073.53515625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2956559.921875, "training_acc": 47.0, "val_loss": 66971.05102539062, "val_acc": 52.0}
{"epoch": 34, "training_loss": 320847.40625, "training_acc": 53.0, "val_loss": 568276.7578125, "val_acc": 48.0}
