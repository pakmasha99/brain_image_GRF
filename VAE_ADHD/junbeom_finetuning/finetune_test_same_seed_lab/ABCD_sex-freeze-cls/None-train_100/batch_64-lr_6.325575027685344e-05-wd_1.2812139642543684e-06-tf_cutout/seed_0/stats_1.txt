"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.40905094146729, "training_acc": 47.0, "val_loss": 17.483733594417572, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.17245721817017, "training_acc": 47.0, "val_loss": 17.424863576889038, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.81061673164368, "training_acc": 47.0, "val_loss": 17.38516539335251, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.58280277252197, "training_acc": 47.0, "val_loss": 17.3557311296463, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.53911137580872, "training_acc": 47.0, "val_loss": 17.332252860069275, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3250801563263, "training_acc": 50.0, "val_loss": 17.31823831796646, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21648383140564, "training_acc": 53.0, "val_loss": 17.309078574180603, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21274542808533, "training_acc": 53.0, "val_loss": 17.303748428821564, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15130734443665, "training_acc": 53.0, "val_loss": 17.302784323692322, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17956638336182, "training_acc": 53.0, "val_loss": 17.30559915304184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16070508956909, "training_acc": 53.0, "val_loss": 17.31080710887909, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13148784637451, "training_acc": 53.0, "val_loss": 17.316800355911255, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15830588340759, "training_acc": 53.0, "val_loss": 17.322906851768494, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13899540901184, "training_acc": 53.0, "val_loss": 17.32763946056366, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1567165851593, "training_acc": 53.0, "val_loss": 17.33156144618988, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20205450057983, "training_acc": 53.0, "val_loss": 17.33618676662445, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19772601127625, "training_acc": 53.0, "val_loss": 17.338217794895172, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20386791229248, "training_acc": 53.0, "val_loss": 17.34027862548828, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20501756668091, "training_acc": 53.0, "val_loss": 17.338943481445312, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21141934394836, "training_acc": 53.0, "val_loss": 17.332789301872253, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18808484077454, "training_acc": 53.0, "val_loss": 17.327411472797394, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.2232391834259, "training_acc": 53.0, "val_loss": 17.321817576885223, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1704969406128, "training_acc": 53.0, "val_loss": 17.31984317302704, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19292879104614, "training_acc": 53.0, "val_loss": 17.317645251750946, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15445065498352, "training_acc": 53.0, "val_loss": 17.31577068567276, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15779948234558, "training_acc": 53.0, "val_loss": 17.31519252061844, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13537406921387, "training_acc": 53.0, "val_loss": 17.313197255134583, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13938093185425, "training_acc": 53.0, "val_loss": 17.311500012874603, "val_acc": 52.0}
