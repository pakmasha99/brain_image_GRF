"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.14859414100647, "training_acc": 47.0, "val_loss": 17.4339160323143, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.84460949897766, "training_acc": 47.0, "val_loss": 17.398351430892944, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.6742582321167, "training_acc": 47.0, "val_loss": 17.363250255584717, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.52402424812317, "training_acc": 47.0, "val_loss": 17.335723340511322, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.43962550163269, "training_acc": 47.0, "val_loss": 17.3186793923378, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2714536190033, "training_acc": 52.0, "val_loss": 17.309188842773438, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.20657682418823, "training_acc": 53.0, "val_loss": 17.303985357284546, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13834762573242, "training_acc": 53.0, "val_loss": 17.302779853343964, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11779642105103, "training_acc": 53.0, "val_loss": 17.304618656635284, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12521743774414, "training_acc": 53.0, "val_loss": 17.30964034795761, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13916373252869, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15201139450073, "training_acc": 53.0, "val_loss": 17.320674657821655, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15816235542297, "training_acc": 53.0, "val_loss": 17.322802543640137, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17856168746948, "training_acc": 53.0, "val_loss": 17.3234686255455, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16328382492065, "training_acc": 53.0, "val_loss": 17.324355244636536, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15112733840942, "training_acc": 53.0, "val_loss": 17.32257753610611, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19474029541016, "training_acc": 53.0, "val_loss": 17.32002943754196, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14627528190613, "training_acc": 53.0, "val_loss": 17.32032746076584, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14398527145386, "training_acc": 53.0, "val_loss": 17.31814593076706, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14471411705017, "training_acc": 53.0, "val_loss": 17.31574833393097, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11468982696533, "training_acc": 53.0, "val_loss": 17.315326631069183, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12860918045044, "training_acc": 53.0, "val_loss": 17.314524948596954, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14046025276184, "training_acc": 53.0, "val_loss": 17.3135444521904, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13202214241028, "training_acc": 53.0, "val_loss": 17.31155812740326, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13273310661316, "training_acc": 53.0, "val_loss": 17.310155928134918, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13135123252869, "training_acc": 53.0, "val_loss": 17.310066521167755, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14403772354126, "training_acc": 53.0, "val_loss": 17.30949431657791, "val_acc": 52.0}
