"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2385184764862, "training_acc": 52.0, "val_loss": 17.239633202552795, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23428702354431, "training_acc": 52.0, "val_loss": 17.222638428211212, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25261807441711, "training_acc": 52.0, "val_loss": 17.22097098827362, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26383018493652, "training_acc": 52.0, "val_loss": 17.22974330186844, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24008226394653, "training_acc": 52.0, "val_loss": 17.243991792201996, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22516560554504, "training_acc": 52.0, "val_loss": 17.249174416065216, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25851631164551, "training_acc": 52.0, "val_loss": 17.260128259658813, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25646686553955, "training_acc": 52.0, "val_loss": 17.265234887599945, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26681447029114, "training_acc": 52.0, "val_loss": 17.260627448558807, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25532937049866, "training_acc": 52.0, "val_loss": 17.26388931274414, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23242688179016, "training_acc": 52.0, "val_loss": 17.265495657920837, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26293563842773, "training_acc": 52.0, "val_loss": 17.263011634349823, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23294067382812, "training_acc": 52.0, "val_loss": 17.259681224822998, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23965001106262, "training_acc": 52.0, "val_loss": 17.25880801677704, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24857330322266, "training_acc": 52.0, "val_loss": 17.252983152866364, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25240969657898, "training_acc": 52.0, "val_loss": 17.24436581134796, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2517614364624, "training_acc": 52.0, "val_loss": 17.23184585571289, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23342108726501, "training_acc": 52.0, "val_loss": 17.22331792116165, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.240718126297, "training_acc": 52.0, "val_loss": 17.216497659683228, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.256915807724, "training_acc": 52.0, "val_loss": 17.211422324180603, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20537662506104, "training_acc": 52.0, "val_loss": 17.210105061531067, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22588276863098, "training_acc": 52.0, "val_loss": 17.20845252275467, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28816342353821, "training_acc": 52.0, "val_loss": 17.20431298017502, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26186299324036, "training_acc": 52.0, "val_loss": 17.20694899559021, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.2602379322052, "training_acc": 52.0, "val_loss": 17.21326857805252, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24897456169128, "training_acc": 52.0, "val_loss": 17.22293645143509, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27798438072205, "training_acc": 52.0, "val_loss": 17.227187752723694, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22743606567383, "training_acc": 52.0, "val_loss": 17.24056601524353, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24457931518555, "training_acc": 52.0, "val_loss": 17.252999544143677, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25882506370544, "training_acc": 52.0, "val_loss": 17.257918417453766, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26921081542969, "training_acc": 52.0, "val_loss": 17.256934940814972, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.2776575088501, "training_acc": 52.0, "val_loss": 17.26336032152176, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24714016914368, "training_acc": 52.0, "val_loss": 17.25921779870987, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25635886192322, "training_acc": 52.0, "val_loss": 17.255470156669617, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2582700252533, "training_acc": 52.0, "val_loss": 17.24874973297119, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24043607711792, "training_acc": 52.0, "val_loss": 17.245034873485565, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23859906196594, "training_acc": 52.0, "val_loss": 17.24083721637726, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.2382128238678, "training_acc": 52.0, "val_loss": 17.235592007637024, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23045539855957, "training_acc": 52.0, "val_loss": 17.22584366798401, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24808549880981, "training_acc": 52.0, "val_loss": 17.21305102109909, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22932124137878, "training_acc": 52.0, "val_loss": 17.20733344554901, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25372123718262, "training_acc": 52.0, "val_loss": 17.203527688980103, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26633739471436, "training_acc": 52.0, "val_loss": 17.201152443885803, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23837614059448, "training_acc": 52.0, "val_loss": 17.203032970428467, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25141382217407, "training_acc": 52.0, "val_loss": 17.211276292800903, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24199485778809, "training_acc": 52.0, "val_loss": 17.217564582824707, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25541067123413, "training_acc": 52.0, "val_loss": 17.2256737947464, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23715901374817, "training_acc": 52.0, "val_loss": 17.233963310718536, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22486996650696, "training_acc": 52.0, "val_loss": 17.237403988838196, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23119807243347, "training_acc": 52.0, "val_loss": 17.240537703037262, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2524254322052, "training_acc": 52.0, "val_loss": 17.246349155902863, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24985361099243, "training_acc": 52.0, "val_loss": 17.25282073020935, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.2549557685852, "training_acc": 52.0, "val_loss": 17.2578826546669, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26399970054626, "training_acc": 52.0, "val_loss": 17.263206839561462, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22046232223511, "training_acc": 52.0, "val_loss": 17.26703643798828, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25418281555176, "training_acc": 52.0, "val_loss": 17.265525460243225, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24609446525574, "training_acc": 52.0, "val_loss": 17.266568541526794, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2463448047638, "training_acc": 52.0, "val_loss": 17.268337309360504, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23729801177979, "training_acc": 52.0, "val_loss": 17.2652468085289, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.2618670463562, "training_acc": 52.0, "val_loss": 17.262180149555206, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28008556365967, "training_acc": 52.0, "val_loss": 17.253920435905457, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24127578735352, "training_acc": 52.0, "val_loss": 17.250357568264008, "val_acc": 56.0}
