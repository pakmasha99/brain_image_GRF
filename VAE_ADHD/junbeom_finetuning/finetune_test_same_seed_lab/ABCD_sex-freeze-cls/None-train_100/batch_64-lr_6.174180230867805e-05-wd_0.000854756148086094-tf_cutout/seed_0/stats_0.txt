"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23820948600769, "training_acc": 52.0, "val_loss": 17.239342629909515, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23388314247131, "training_acc": 52.0, "val_loss": 17.22288429737091, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25215983390808, "training_acc": 52.0, "val_loss": 17.22126305103302, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.2638463973999, "training_acc": 52.0, "val_loss": 17.22979247570038, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24001717567444, "training_acc": 52.0, "val_loss": 17.243659496307373, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2249710559845, "training_acc": 52.0, "val_loss": 17.248710989952087, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25824856758118, "training_acc": 52.0, "val_loss": 17.259429395198822, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25592088699341, "training_acc": 52.0, "val_loss": 17.264506220817566, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26567029953003, "training_acc": 52.0, "val_loss": 17.26013720035553, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25502467155457, "training_acc": 52.0, "val_loss": 17.263442277908325, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23214721679688, "training_acc": 52.0, "val_loss": 17.265143990516663, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26266288757324, "training_acc": 52.0, "val_loss": 17.262859642505646, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23266768455505, "training_acc": 52.0, "val_loss": 17.2597274184227, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.2397027015686, "training_acc": 52.0, "val_loss": 17.258964478969574, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24874424934387, "training_acc": 52.0, "val_loss": 17.2533318400383, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25270366668701, "training_acc": 52.0, "val_loss": 17.244921624660492, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25183033943176, "training_acc": 52.0, "val_loss": 17.232631146907806, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.2334794998169, "training_acc": 52.0, "val_loss": 17.22419261932373, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24058437347412, "training_acc": 52.0, "val_loss": 17.217372357845306, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25658345222473, "training_acc": 52.0, "val_loss": 17.21222698688507, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20485353469849, "training_acc": 52.0, "val_loss": 17.21074879169464, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22524619102478, "training_acc": 52.0, "val_loss": 17.20893383026123, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28774213790894, "training_acc": 52.0, "val_loss": 17.20469892024994, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26173543930054, "training_acc": 52.0, "val_loss": 17.207111418247223, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26039385795593, "training_acc": 52.0, "val_loss": 17.21312701702118, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24876165390015, "training_acc": 52.0, "val_loss": 17.22242683172226, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27789616584778, "training_acc": 52.0, "val_loss": 17.22649335861206, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22755002975464, "training_acc": 52.0, "val_loss": 17.239481210708618, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24381279945374, "training_acc": 52.0, "val_loss": 17.251597344875336, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25807046890259, "training_acc": 52.0, "val_loss": 17.25650131702423, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26769042015076, "training_acc": 52.0, "val_loss": 17.255721986293793, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27660870552063, "training_acc": 52.0, "val_loss": 17.262162268161774, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24634647369385, "training_acc": 52.0, "val_loss": 17.258359491825104, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25604605674744, "training_acc": 52.0, "val_loss": 17.254935204982758, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25772833824158, "training_acc": 52.0, "val_loss": 17.248590290546417, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2404351234436, "training_acc": 52.0, "val_loss": 17.245136201381683, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23877048492432, "training_acc": 52.0, "val_loss": 17.241165041923523, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23842072486877, "training_acc": 52.0, "val_loss": 17.236118018627167, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23082327842712, "training_acc": 52.0, "val_loss": 17.226603627204895, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24735569953918, "training_acc": 52.0, "val_loss": 17.214031517505646, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22887015342712, "training_acc": 52.0, "val_loss": 17.20835119485855, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25306057929993, "training_acc": 52.0, "val_loss": 17.204509675502777, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26543593406677, "training_acc": 52.0, "val_loss": 17.20205247402191, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23767042160034, "training_acc": 52.0, "val_loss": 17.203761637210846, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25063347816467, "training_acc": 52.0, "val_loss": 17.21169501543045, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24205756187439, "training_acc": 52.0, "val_loss": 17.217692732810974, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25551986694336, "training_acc": 52.0, "val_loss": 17.225469648838043, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23671650886536, "training_acc": 52.0, "val_loss": 17.233440279960632, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22485375404358, "training_acc": 52.0, "val_loss": 17.236720025539398, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23110008239746, "training_acc": 52.0, "val_loss": 17.239749431610107, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25228333473206, "training_acc": 52.0, "val_loss": 17.245417833328247, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24953198432922, "training_acc": 52.0, "val_loss": 17.251771688461304, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25444149971008, "training_acc": 52.0, "val_loss": 17.25679337978363, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26340246200562, "training_acc": 52.0, "val_loss": 17.262111604213715, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21976089477539, "training_acc": 52.0, "val_loss": 17.266008257865906, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25316882133484, "training_acc": 52.0, "val_loss": 17.264729738235474, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24544095993042, "training_acc": 52.0, "val_loss": 17.265941202640533, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2459831237793, "training_acc": 52.0, "val_loss": 17.267856001853943, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23693537712097, "training_acc": 52.0, "val_loss": 17.265023291110992, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26187658309937, "training_acc": 52.0, "val_loss": 17.262187600135803, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.27963042259216, "training_acc": 52.0, "val_loss": 17.254237830638885, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24149250984192, "training_acc": 52.0, "val_loss": 17.25083440542221, "val_acc": 56.0}
