"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.33345985412598, "training_acc": 53.0, "val_loss": 17.310386896133423, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18179488182068, "training_acc": 53.0, "val_loss": 17.31049120426178, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15574407577515, "training_acc": 53.0, "val_loss": 17.31085032224655, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18700861930847, "training_acc": 53.0, "val_loss": 17.31037050485611, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15902042388916, "training_acc": 53.0, "val_loss": 17.30961501598358, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18790316581726, "training_acc": 53.0, "val_loss": 17.30920970439911, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14760231971741, "training_acc": 53.0, "val_loss": 17.309364676475525, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14659595489502, "training_acc": 53.0, "val_loss": 17.309926450252533, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13027119636536, "training_acc": 53.0, "val_loss": 17.310893535614014, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13601803779602, "training_acc": 53.0, "val_loss": 17.311881482601166, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14681911468506, "training_acc": 53.0, "val_loss": 17.31233149766922, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10959982872009, "training_acc": 53.0, "val_loss": 17.314225435256958, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13107633590698, "training_acc": 53.0, "val_loss": 17.31724441051483, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16922092437744, "training_acc": 53.0, "val_loss": 17.319659888744354, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14461064338684, "training_acc": 53.0, "val_loss": 17.31927841901779, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1296055316925, "training_acc": 53.0, "val_loss": 17.317870259284973, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12852048873901, "training_acc": 53.0, "val_loss": 17.317630350589752, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11736392974854, "training_acc": 53.0, "val_loss": 17.317982017993927, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11255407333374, "training_acc": 53.0, "val_loss": 17.318007349967957, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14378237724304, "training_acc": 53.0, "val_loss": 17.318645119667053, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14642381668091, "training_acc": 53.0, "val_loss": 17.318345606327057, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12091946601868, "training_acc": 53.0, "val_loss": 17.3161119222641, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14295887947083, "training_acc": 53.0, "val_loss": 17.314696311950684, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1162600517273, "training_acc": 53.0, "val_loss": 17.313657701015472, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10519480705261, "training_acc": 53.0, "val_loss": 17.31240451335907, "val_acc": 52.0}
