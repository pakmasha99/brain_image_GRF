"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.41207218170166, "training_acc": 47.0, "val_loss": 17.485633492469788, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.17984175682068, "training_acc": 47.0, "val_loss": 17.427648603916168, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.82345271110535, "training_acc": 47.0, "val_loss": 17.388179898262024, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.59831643104553, "training_acc": 47.0, "val_loss": 17.358611524105072, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.5523202419281, "training_acc": 47.0, "val_loss": 17.33475774526596, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.338782787323, "training_acc": 48.0, "val_loss": 17.32020080089569, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22828841209412, "training_acc": 54.0, "val_loss": 17.31041520833969, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22200036048889, "training_acc": 53.0, "val_loss": 17.30436235666275, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15779280662537, "training_acc": 53.0, "val_loss": 17.30266511440277, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18307495117188, "training_acc": 53.0, "val_loss": 17.30475425720215, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1614944934845, "training_acc": 53.0, "val_loss": 17.309395968914032, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12978458404541, "training_acc": 53.0, "val_loss": 17.31504797935486, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15518951416016, "training_acc": 53.0, "val_loss": 17.321006953716278, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1344940662384, "training_acc": 53.0, "val_loss": 17.325831949710846, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15139174461365, "training_acc": 53.0, "val_loss": 17.32996106147766, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19834303855896, "training_acc": 53.0, "val_loss": 17.334797978401184, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19341206550598, "training_acc": 53.0, "val_loss": 17.33718067407608, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20179557800293, "training_acc": 53.0, "val_loss": 17.339572310447693, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20440220832825, "training_acc": 53.0, "val_loss": 17.33863353729248, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21051859855652, "training_acc": 53.0, "val_loss": 17.332930862903595, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18887996673584, "training_acc": 53.0, "val_loss": 17.327868938446045, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22216725349426, "training_acc": 53.0, "val_loss": 17.32247918844223, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1718978881836, "training_acc": 53.0, "val_loss": 17.32059121131897, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19429469108582, "training_acc": 53.0, "val_loss": 17.318426072597504, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15553140640259, "training_acc": 53.0, "val_loss": 17.3165425658226, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15888714790344, "training_acc": 53.0, "val_loss": 17.315931618213654, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13653683662415, "training_acc": 53.0, "val_loss": 17.313872277736664, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14009690284729, "training_acc": 53.0, "val_loss": 17.312100529670715, "val_acc": 52.0}
