"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.1474289894104, "training_acc": 47.0, "val_loss": 17.435020208358765, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.85035276412964, "training_acc": 47.0, "val_loss": 17.399993538856506, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.6827130317688, "training_acc": 47.0, "val_loss": 17.365211248397827, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.53341102600098, "training_acc": 47.0, "val_loss": 17.337636649608612, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.44901394844055, "training_acc": 47.0, "val_loss": 17.320245504379272, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.280752658844, "training_acc": 52.0, "val_loss": 17.310267686843872, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21411538124084, "training_acc": 53.0, "val_loss": 17.304500937461853, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14368009567261, "training_acc": 53.0, "val_loss": 17.302745580673218, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12057447433472, "training_acc": 53.0, "val_loss": 17.30409562587738, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12637066841125, "training_acc": 53.0, "val_loss": 17.308616638183594, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13842344284058, "training_acc": 53.0, "val_loss": 17.314597964286804, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15017056465149, "training_acc": 53.0, "val_loss": 17.319312691688538, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15570998191833, "training_acc": 53.0, "val_loss": 17.321670055389404, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17570424079895, "training_acc": 53.0, "val_loss": 17.322658002376556, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1622667312622, "training_acc": 53.0, "val_loss": 17.323844134807587, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15022730827332, "training_acc": 53.0, "val_loss": 17.322425544261932, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1925368309021, "training_acc": 53.0, "val_loss": 17.320166528224945, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1469566822052, "training_acc": 53.0, "val_loss": 17.320625483989716, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14462971687317, "training_acc": 53.0, "val_loss": 17.318591475486755, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14458990097046, "training_acc": 53.0, "val_loss": 17.31628328561783, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11554312705994, "training_acc": 53.0, "val_loss": 17.31589287519455, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12948727607727, "training_acc": 53.0, "val_loss": 17.31509417295456, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1412205696106, "training_acc": 53.0, "val_loss": 17.314088344573975, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13268685340881, "training_acc": 53.0, "val_loss": 17.312057316303253, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1331377029419, "training_acc": 53.0, "val_loss": 17.310598492622375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13158059120178, "training_acc": 53.0, "val_loss": 17.31044501066208, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1442198753357, "training_acc": 53.0, "val_loss": 17.309805750846863, "val_acc": 52.0}
