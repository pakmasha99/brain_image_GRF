"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.97562527656555, "training_acc": 47.0, "val_loss": 17.83275306224823, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.64890766143799, "training_acc": 47.0, "val_loss": 17.75461584329605, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.2721905708313, "training_acc": 47.0, "val_loss": 17.68708825111389, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.01866507530212, "training_acc": 47.0, "val_loss": 17.624276876449585, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.72520542144775, "training_acc": 47.0, "val_loss": 17.569659650325775, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.41299772262573, "training_acc": 47.0, "val_loss": 17.522674798965454, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.21995544433594, "training_acc": 47.0, "val_loss": 17.478887736797333, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.12450790405273, "training_acc": 47.0, "val_loss": 17.44125187397003, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.82632827758789, "training_acc": 47.0, "val_loss": 17.41267740726471, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.73489713668823, "training_acc": 47.0, "val_loss": 17.386682331562042, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.57794666290283, "training_acc": 47.0, "val_loss": 17.36530065536499, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.46452021598816, "training_acc": 47.0, "val_loss": 17.347876727581024, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.39902973175049, "training_acc": 47.0, "val_loss": 17.333537340164185, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.32764053344727, "training_acc": 45.0, "val_loss": 17.32298582792282, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.28379440307617, "training_acc": 53.0, "val_loss": 17.315539717674255, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2252266407013, "training_acc": 53.0, "val_loss": 17.31112450361252, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19713544845581, "training_acc": 53.0, "val_loss": 17.30889081954956, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14664387702942, "training_acc": 53.0, "val_loss": 17.30828434228897, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15228867530823, "training_acc": 53.0, "val_loss": 17.30896532535553, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15834021568298, "training_acc": 53.0, "val_loss": 17.31061190366745, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14204907417297, "training_acc": 53.0, "val_loss": 17.312762141227722, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13757419586182, "training_acc": 53.0, "val_loss": 17.315229773521423, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1320412158966, "training_acc": 53.0, "val_loss": 17.31761544942856, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11899185180664, "training_acc": 53.0, "val_loss": 17.319703102111816, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14714431762695, "training_acc": 53.0, "val_loss": 17.32160747051239, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16321539878845, "training_acc": 53.0, "val_loss": 17.323337495326996, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13722729682922, "training_acc": 53.0, "val_loss": 17.32347011566162, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18228459358215, "training_acc": 53.0, "val_loss": 17.3232764005661, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1245584487915, "training_acc": 53.0, "val_loss": 17.322856187820435, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16889905929565, "training_acc": 53.0, "val_loss": 17.321786284446716, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12167811393738, "training_acc": 53.0, "val_loss": 17.319980263710022, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13353180885315, "training_acc": 53.0, "val_loss": 17.318399250507355, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14850187301636, "training_acc": 53.0, "val_loss": 17.317011952400208, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.16467452049255, "training_acc": 53.0, "val_loss": 17.316192388534546, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14509415626526, "training_acc": 53.0, "val_loss": 17.31625199317932, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15561389923096, "training_acc": 53.0, "val_loss": 17.316240072250366, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15637588500977, "training_acc": 53.0, "val_loss": 17.31576919555664, "val_acc": 52.0}
