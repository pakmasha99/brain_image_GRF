"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.44561696052551, "training_acc": 47.0, "val_loss": 17.45169758796692, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.88997340202332, "training_acc": 47.0, "val_loss": 17.375440895557404, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.49703812599182, "training_acc": 47.0, "val_loss": 17.328593134880066, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.29679822921753, "training_acc": 53.0, "val_loss": 17.310450971126556, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18337082862854, "training_acc": 53.0, "val_loss": 17.316834628582, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1174545288086, "training_acc": 53.0, "val_loss": 17.336642742156982, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.173823595047, "training_acc": 53.0, "val_loss": 17.359882593154907, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.24287819862366, "training_acc": 53.0, "val_loss": 17.375633120536804, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.28396320343018, "training_acc": 53.0, "val_loss": 17.379477620124817, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.30926561355591, "training_acc": 53.0, "val_loss": 17.374838888645172, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.27923917770386, "training_acc": 53.0, "val_loss": 17.36699789762497, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27411818504333, "training_acc": 53.0, "val_loss": 17.34814941883087, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20051884651184, "training_acc": 53.0, "val_loss": 17.332105338573456, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13914203643799, "training_acc": 53.0, "val_loss": 17.320939898490906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.10746431350708, "training_acc": 53.0, "val_loss": 17.313644289970398, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14096903800964, "training_acc": 53.0, "val_loss": 17.310191690921783, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.184650182724, "training_acc": 53.0, "val_loss": 17.31044352054596, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21905970573425, "training_acc": 53.0, "val_loss": 17.311732470989227, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19677710533142, "training_acc": 53.0, "val_loss": 17.311814427375793, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17987942695618, "training_acc": 53.0, "val_loss": 17.31037050485611, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19177961349487, "training_acc": 53.0, "val_loss": 17.31007695198059, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14706516265869, "training_acc": 53.0, "val_loss": 17.310771346092224, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16506958007812, "training_acc": 53.0, "val_loss": 17.311576008796692, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10466885566711, "training_acc": 53.0, "val_loss": 17.312654852867126, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15968346595764, "training_acc": 53.0, "val_loss": 17.31499880552292, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14121770858765, "training_acc": 53.0, "val_loss": 17.316173017024994, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16177749633789, "training_acc": 53.0, "val_loss": 17.316758632659912, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.16565179824829, "training_acc": 53.0, "val_loss": 17.32066571712494, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11880207061768, "training_acc": 53.0, "val_loss": 17.32143759727478, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11362767219543, "training_acc": 53.0, "val_loss": 17.321228981018066, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17950558662415, "training_acc": 53.0, "val_loss": 17.32361614704132, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15632748603821, "training_acc": 53.0, "val_loss": 17.32485294342041, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16357231140137, "training_acc": 53.0, "val_loss": 17.325006425380707, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15106725692749, "training_acc": 53.0, "val_loss": 17.32241064310074, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.18924450874329, "training_acc": 53.0, "val_loss": 17.320407927036285, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18006873130798, "training_acc": 53.0, "val_loss": 17.320609092712402, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14699506759644, "training_acc": 53.0, "val_loss": 17.319563031196594, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14889216423035, "training_acc": 53.0, "val_loss": 17.31766313314438, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17007875442505, "training_acc": 53.0, "val_loss": 17.31603592634201, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14089608192444, "training_acc": 53.0, "val_loss": 17.314723134040833, "val_acc": 52.0}
