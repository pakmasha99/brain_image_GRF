"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24645352363586, "training_acc": 52.0, "val_loss": 17.245620489120483, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24384951591492, "training_acc": 52.0, "val_loss": 17.216049134731293, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.26363730430603, "training_acc": 52.0, "val_loss": 17.213843762874603, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26337051391602, "training_acc": 52.0, "val_loss": 17.228759825229645, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24176740646362, "training_acc": 52.0, "val_loss": 17.25235879421234, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23010778427124, "training_acc": 52.0, "val_loss": 17.260782420635223, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26650142669678, "training_acc": 52.0, "val_loss": 17.276600003242493, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.27039241790771, "training_acc": 52.0, "val_loss": 17.280811071395874, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.29508519172668, "training_acc": 52.0, "val_loss": 17.269274592399597, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26152443885803, "training_acc": 52.0, "val_loss": 17.270220816135406, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23622179031372, "training_acc": 52.0, "val_loss": 17.26856231689453, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26600694656372, "training_acc": 52.0, "val_loss": 17.261146008968353, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23591732978821, "training_acc": 52.0, "val_loss": 17.253609001636505, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23616766929626, "training_acc": 52.0, "val_loss": 17.250946164131165, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24344205856323, "training_acc": 52.0, "val_loss": 17.24224090576172, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2471570968628, "training_acc": 52.0, "val_loss": 17.230813205242157, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2517683506012, "training_acc": 52.0, "val_loss": 17.215409874916077, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23629879951477, "training_acc": 52.0, "val_loss": 17.207056283950806, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24759602546692, "training_acc": 52.0, "val_loss": 17.202073335647583, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26528263092041, "training_acc": 52.0, "val_loss": 17.200101912021637, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21708798408508, "training_acc": 52.0, "val_loss": 17.20358282327652, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2381055355072, "training_acc": 52.0, "val_loss": 17.20621883869171, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.2911365032196, "training_acc": 52.0, "val_loss": 17.204223573207855, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25819754600525, "training_acc": 52.0, "val_loss": 17.211799323558807, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25280237197876, "training_acc": 52.0, "val_loss": 17.22453683614731, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25215220451355, "training_acc": 52.0, "val_loss": 17.241688072681427, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28997159004211, "training_acc": 52.0, "val_loss": 17.247918248176575, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23118996620178, "training_acc": 52.0, "val_loss": 17.268122732639313, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.26652646064758, "training_acc": 52.0, "val_loss": 17.284464836120605, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.28057217597961, "training_acc": 52.0, "val_loss": 17.285391688346863, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.31255269050598, "training_acc": 52.0, "val_loss": 17.275673151016235, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.2933304309845, "training_acc": 52.0, "val_loss": 17.278465628623962, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25943422317505, "training_acc": 52.0, "val_loss": 17.264598608016968, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25479912757874, "training_acc": 52.0, "val_loss": 17.25277453660965, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26374793052673, "training_acc": 52.0, "val_loss": 17.23843663930893, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23627185821533, "training_acc": 52.0, "val_loss": 17.230558395385742, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23414492607117, "training_acc": 52.0, "val_loss": 17.223815619945526, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23931813240051, "training_acc": 52.0, "val_loss": 17.217189073562622, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2316734790802, "training_acc": 52.0, "val_loss": 17.205795645713806, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.26796770095825, "training_acc": 52.0, "val_loss": 17.191821336746216, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.24883937835693, "training_acc": 52.0, "val_loss": 17.18798726797104, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.27537536621094, "training_acc": 52.0, "val_loss": 17.18718558549881, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28401851654053, "training_acc": 52.0, "val_loss": 17.188552021980286, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24493837356567, "training_acc": 52.0, "val_loss": 17.195825278759003, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26419854164124, "training_acc": 52.0, "val_loss": 17.21285581588745, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23432898521423, "training_acc": 52.0, "val_loss": 17.227141559123993, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25116467475891, "training_acc": 52.0, "val_loss": 17.24371165037155, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.2500069141388, "training_acc": 52.0, "val_loss": 17.259158194065094, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.23400068283081, "training_acc": 52.0, "val_loss": 17.264100909233093, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.24565052986145, "training_acc": 52.0, "val_loss": 17.26652830839157, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2662935256958, "training_acc": 52.0, "val_loss": 17.27192997932434, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.26524090766907, "training_acc": 52.0, "val_loss": 17.277029156684875, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.27352142333984, "training_acc": 52.0, "val_loss": 17.278671264648438, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.2790367603302, "training_acc": 52.0, "val_loss": 17.280137538909912, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2309398651123, "training_acc": 52.0, "val_loss": 17.27897822856903, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27261686325073, "training_acc": 52.0, "val_loss": 17.269858717918396, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.2526593208313, "training_acc": 52.0, "val_loss": 17.265839874744415, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24387860298157, "training_acc": 52.0, "val_loss": 17.264045774936676, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23486280441284, "training_acc": 52.0, "val_loss": 17.256252467632294, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25448417663574, "training_acc": 52.0, "val_loss": 17.249953746795654, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28281235694885, "training_acc": 52.0, "val_loss": 17.237719893455505, "val_acc": 56.0}
