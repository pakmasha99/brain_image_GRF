"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1050.2038192749023, "training_acc": 50.0, "val_loss": 194.25686597824097, "val_acc": 44.0}
{"epoch": 1, "training_loss": 1037.6631507873535, "training_acc": 48.0, "val_loss": 497.13430404663086, "val_acc": 56.0}
{"epoch": 2, "training_loss": 2119.383316040039, "training_acc": 52.0, "val_loss": 304.5214891433716, "val_acc": 56.0}
{"epoch": 3, "training_loss": 910.9358577728271, "training_acc": 52.0, "val_loss": 315.4712438583374, "val_acc": 44.0}
{"epoch": 4, "training_loss": 1436.6959381103516, "training_acc": 48.0, "val_loss": 549.8274326324463, "val_acc": 44.0}
{"epoch": 5, "training_loss": 1936.670524597168, "training_acc": 48.0, "val_loss": 283.87722969055176, "val_acc": 44.0}
{"epoch": 6, "training_loss": 711.9363708496094, "training_acc": 48.0, "val_loss": 218.4335470199585, "val_acc": 56.0}
{"epoch": 7, "training_loss": 1148.7198486328125, "training_acc": 52.0, "val_loss": 405.08270263671875, "val_acc": 56.0}
{"epoch": 8, "training_loss": 1738.6170959472656, "training_acc": 52.0, "val_loss": 293.9365863800049, "val_acc": 56.0}
{"epoch": 9, "training_loss": 1037.0820865631104, "training_acc": 52.0, "val_loss": 73.43935370445251, "val_acc": 44.0}
{"epoch": 10, "training_loss": 461.5262565612793, "training_acc": 48.0, "val_loss": 247.22063541412354, "val_acc": 44.0}
{"epoch": 11, "training_loss": 843.5410842895508, "training_acc": 48.0, "val_loss": 56.301116943359375, "val_acc": 44.0}
{"epoch": 12, "training_loss": 342.7006416320801, "training_acc": 46.0, "val_loss": 193.5611128807068, "val_acc": 56.0}
{"epoch": 13, "training_loss": 853.0330047607422, "training_acc": 52.0, "val_loss": 148.82867336273193, "val_acc": 56.0}
{"epoch": 14, "training_loss": 494.3106908798218, "training_acc": 52.0, "val_loss": 136.7634892463684, "val_acc": 44.0}
{"epoch": 15, "training_loss": 648.1917152404785, "training_acc": 48.0, "val_loss": 222.96206951141357, "val_acc": 44.0}
{"epoch": 16, "training_loss": 713.3901844024658, "training_acc": 48.0, "val_loss": 22.57656455039978, "val_acc": 56.0}
{"epoch": 17, "training_loss": 202.06389808654785, "training_acc": 52.0, "val_loss": 97.63825535774231, "val_acc": 56.0}
{"epoch": 18, "training_loss": 345.90093898773193, "training_acc": 52.0, "val_loss": 72.87353277206421, "val_acc": 44.0}
{"epoch": 19, "training_loss": 316.4345064163208, "training_acc": 48.0, "val_loss": 64.46479558944702, "val_acc": 44.0}
{"epoch": 20, "training_loss": 206.4625153541565, "training_acc": 52.0, "val_loss": 71.08543515205383, "val_acc": 56.0}
{"epoch": 21, "training_loss": 264.78709268569946, "training_acc": 52.0, "val_loss": 51.9146203994751, "val_acc": 44.0}
{"epoch": 22, "training_loss": 198.9140181541443, "training_acc": 48.0, "val_loss": 17.16674417257309, "val_acc": 56.0}
{"epoch": 23, "training_loss": 120.53656005859375, "training_acc": 52.0, "val_loss": 22.831256687641144, "val_acc": 56.0}
{"epoch": 24, "training_loss": 123.6102442741394, "training_acc": 54.0, "val_loss": 50.65739154815674, "val_acc": 44.0}
{"epoch": 25, "training_loss": 150.30070805549622, "training_acc": 52.0, "val_loss": 36.97827160358429, "val_acc": 56.0}
{"epoch": 26, "training_loss": 113.98850083351135, "training_acc": 52.0, "val_loss": 70.93929648399353, "val_acc": 44.0}
{"epoch": 27, "training_loss": 248.49547290802002, "training_acc": 48.0, "val_loss": 25.170782208442688, "val_acc": 56.0}
{"epoch": 28, "training_loss": 122.58062076568604, "training_acc": 52.0, "val_loss": 17.513801157474518, "val_acc": 56.0}
{"epoch": 29, "training_loss": 101.73295736312866, "training_acc": 48.0, "val_loss": 17.37453192472458, "val_acc": 56.0}
{"epoch": 30, "training_loss": 113.44334602355957, "training_acc": 52.0, "val_loss": 22.271403670310974, "val_acc": 44.0}
{"epoch": 31, "training_loss": 111.79407453536987, "training_acc": 48.0, "val_loss": 30.09617328643799, "val_acc": 56.0}
{"epoch": 32, "training_loss": 131.82158613204956, "training_acc": 52.0, "val_loss": 34.37041640281677, "val_acc": 44.0}
{"epoch": 33, "training_loss": 123.96618556976318, "training_acc": 48.0, "val_loss": 36.84752583503723, "val_acc": 56.0}
{"epoch": 34, "training_loss": 159.62769556045532, "training_acc": 52.0, "val_loss": 36.61101460456848, "val_acc": 44.0}
{"epoch": 35, "training_loss": 137.4755711555481, "training_acc": 48.0, "val_loss": 30.816859006881714, "val_acc": 56.0}
{"epoch": 36, "training_loss": 129.22467136383057, "training_acc": 52.0, "val_loss": 32.402241230010986, "val_acc": 44.0}
{"epoch": 37, "training_loss": 120.35575914382935, "training_acc": 48.0, "val_loss": 45.11979818344116, "val_acc": 56.0}
{"epoch": 38, "training_loss": 189.17034244537354, "training_acc": 52.0, "val_loss": 21.47197276353836, "val_acc": 44.0}
{"epoch": 39, "training_loss": 87.39810276031494, "training_acc": 48.0, "val_loss": 19.020356237888336, "val_acc": 56.0}
{"epoch": 40, "training_loss": 78.61596727371216, "training_acc": 52.0, "val_loss": 24.717898666858673, "val_acc": 44.0}
{"epoch": 41, "training_loss": 84.38887095451355, "training_acc": 50.0, "val_loss": 19.690024852752686, "val_acc": 56.0}
