"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 98225.40623474121, "training_acc": 53.0, "val_loss": 19475.96435546875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 122624.0537109375, "training_acc": 49.0, "val_loss": 59358.33740234375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 221022.8681640625, "training_acc": 47.0, "val_loss": 15623.789978027344, "val_acc": 48.0}
{"epoch": 3, "training_loss": 96069.4150390625, "training_acc": 37.0, "val_loss": 40132.87658691406, "val_acc": 52.0}
{"epoch": 4, "training_loss": 160902.40869140625, "training_acc": 53.0, "val_loss": 32753.738403320312, "val_acc": 52.0}
{"epoch": 5, "training_loss": 103490.97387695312, "training_acc": 53.0, "val_loss": 11895.943450927734, "val_acc": 48.0}
{"epoch": 6, "training_loss": 66182.63623046875, "training_acc": 47.0, "val_loss": 23641.27655029297, "val_acc": 48.0}
{"epoch": 7, "training_loss": 79276.80346679688, "training_acc": 47.0, "val_loss": 5986.070251464844, "val_acc": 52.0}
{"epoch": 8, "training_loss": 43029.382568359375, "training_acc": 53.0, "val_loss": 14269.296264648438, "val_acc": 52.0}
{"epoch": 9, "training_loss": 43380.48986816406, "training_acc": 53.0, "val_loss": 12431.391143798828, "val_acc": 48.0}
{"epoch": 10, "training_loss": 55951.503173828125, "training_acc": 47.0, "val_loss": 13854.966735839844, "val_acc": 48.0}
{"epoch": 11, "training_loss": 38560.86178588867, "training_acc": 47.0, "val_loss": 16141.610717773438, "val_acc": 52.0}
{"epoch": 12, "training_loss": 76920.50634765625, "training_acc": 53.0, "val_loss": 25676.425170898438, "val_acc": 52.0}
{"epoch": 13, "training_loss": 90798.78930664062, "training_acc": 53.0, "val_loss": 5406.704330444336, "val_acc": 52.0}
{"epoch": 14, "training_loss": 39170.27685546875, "training_acc": 47.0, "val_loss": 24546.893310546875, "val_acc": 48.0}
{"epoch": 15, "training_loss": 99742.73046875, "training_acc": 47.0, "val_loss": 15196.055603027344, "val_acc": 48.0}
{"epoch": 16, "training_loss": 41729.06004333496, "training_acc": 49.0, "val_loss": 8200.083923339844, "val_acc": 52.0}
{"epoch": 17, "training_loss": 30283.16192626953, "training_acc": 53.0, "val_loss": 600.2272605895996, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2014.0120735168457, "training_acc": 53.0, "val_loss": 5277.025604248047, "val_acc": 48.0}
{"epoch": 19, "training_loss": 16642.828910827637, "training_acc": 47.0, "val_loss": 9010.70327758789, "val_acc": 52.0}
{"epoch": 20, "training_loss": 36183.69934082031, "training_acc": 53.0, "val_loss": 4706.014633178711, "val_acc": 52.0}
{"epoch": 21, "training_loss": 19955.46759033203, "training_acc": 55.0, "val_loss": 9981.0546875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 32395.802795410156, "training_acc": 47.0, "val_loss": 8655.027770996094, "val_acc": 52.0}
{"epoch": 23, "training_loss": 39066.027587890625, "training_acc": 53.0, "val_loss": 9430.783081054688, "val_acc": 52.0}
{"epoch": 24, "training_loss": 22239.22230911255, "training_acc": 53.0, "val_loss": 17286.300659179688, "val_acc": 48.0}
{"epoch": 25, "training_loss": 80810.6064453125, "training_acc": 47.0, "val_loss": 22238.784790039062, "val_acc": 48.0}
{"epoch": 26, "training_loss": 77561.3427734375, "training_acc": 47.0, "val_loss": 5507.254409790039, "val_acc": 52.0}
{"epoch": 27, "training_loss": 32448.976318359375, "training_acc": 53.0, "val_loss": 11873.989868164062, "val_acc": 52.0}
{"epoch": 28, "training_loss": 34992.69989013672, "training_acc": 53.0, "val_loss": 10488.400268554688, "val_acc": 48.0}
{"epoch": 29, "training_loss": 50568.98193359375, "training_acc": 47.0, "val_loss": 12202.828979492188, "val_acc": 48.0}
{"epoch": 30, "training_loss": 33178.7440032959, "training_acc": 47.0, "val_loss": 17009.14764404297, "val_acc": 52.0}
{"epoch": 31, "training_loss": 74824.38793945312, "training_acc": 53.0, "val_loss": 26115.460205078125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 94515.14453125, "training_acc": 53.0, "val_loss": 8531.853485107422, "val_acc": 52.0}
{"epoch": 33, "training_loss": 33693.30078125, "training_acc": 53.0, "val_loss": 18176.116943359375, "val_acc": 48.0}
{"epoch": 34, "training_loss": 73394.51611328125, "training_acc": 47.0, "val_loss": 8438.739776611328, "val_acc": 48.0}
{"epoch": 35, "training_loss": 31393.086181640625, "training_acc": 51.0, "val_loss": 14612.773132324219, "val_acc": 52.0}
{"epoch": 36, "training_loss": 57467.736328125, "training_acc": 53.0, "val_loss": 6691.017150878906, "val_acc": 52.0}
