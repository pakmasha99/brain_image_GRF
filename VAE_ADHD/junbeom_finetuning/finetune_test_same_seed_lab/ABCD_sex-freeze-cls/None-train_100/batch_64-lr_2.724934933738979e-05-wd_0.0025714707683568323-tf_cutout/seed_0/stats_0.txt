"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23221635818481, "training_acc": 52.0, "val_loss": 17.231780290603638, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22540640830994, "training_acc": 52.0, "val_loss": 17.22628027200699, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2426769733429, "training_acc": 52.0, "val_loss": 17.22595989704132, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26397681236267, "training_acc": 52.0, "val_loss": 17.229647934436798, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2386224269867, "training_acc": 52.0, "val_loss": 17.235632240772247, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22035002708435, "training_acc": 52.0, "val_loss": 17.237989604473114, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25329685211182, "training_acc": 52.0, "val_loss": 17.2431081533432, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24506711959839, "training_acc": 52.0, "val_loss": 17.24640280008316, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.24259209632874, "training_acc": 52.0, "val_loss": 17.245912551879883, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.248126745224, "training_acc": 52.0, "val_loss": 17.248745262622833, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22412133216858, "training_acc": 52.0, "val_loss": 17.251133918762207, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.25407218933105, "training_acc": 52.0, "val_loss": 17.25200265645981, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.22318410873413, "training_acc": 52.0, "val_loss": 17.252467572689056, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23590970039368, "training_acc": 52.0, "val_loss": 17.25383698940277, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24788355827332, "training_acc": 52.0, "val_loss": 17.252902686595917, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25585579872131, "training_acc": 52.0, "val_loss": 17.250341176986694, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25148034095764, "training_acc": 52.0, "val_loss": 17.24538505077362, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23699283599854, "training_acc": 52.0, "val_loss": 17.24150776863098, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24242901802063, "training_acc": 52.0, "val_loss": 17.237690091133118, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25384163856506, "training_acc": 52.0, "val_loss": 17.234012484550476, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20034408569336, "training_acc": 52.0, "val_loss": 17.231634259223938, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21734619140625, "training_acc": 52.0, "val_loss": 17.228728532791138, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27502369880676, "training_acc": 52.0, "val_loss": 17.224392294883728, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.254873752594, "training_acc": 52.0, "val_loss": 17.223268747329712, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25818157196045, "training_acc": 52.0, "val_loss": 17.223796248435974, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24052500724792, "training_acc": 52.0, "val_loss": 17.225833237171173, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27330899238586, "training_acc": 52.0, "val_loss": 17.22584068775177, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23064875602722, "training_acc": 52.0, "val_loss": 17.230068147182465, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23052597045898, "training_acc": 52.0, "val_loss": 17.23417192697525, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.249507188797, "training_acc": 52.0, "val_loss": 17.235836386680603, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.2500970363617, "training_acc": 52.0, "val_loss": 17.235729098320007, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.25360250473022, "training_acc": 52.0, "val_loss": 17.238911986351013, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23579788208008, "training_acc": 52.0, "val_loss": 17.23838746547699, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24945092201233, "training_acc": 52.0, "val_loss": 17.238254845142365, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24754691123962, "training_acc": 52.0, "val_loss": 17.23700612783432, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23783898353577, "training_acc": 52.0, "val_loss": 17.23693758249283, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23837304115295, "training_acc": 52.0, "val_loss": 17.236560583114624, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23767971992493, "training_acc": 52.0, "val_loss": 17.235510051250458, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23699116706848, "training_acc": 52.0, "val_loss": 17.232127487659454, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.23250269889832, "training_acc": 52.0, "val_loss": 17.226767539978027, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22637939453125, "training_acc": 52.0, "val_loss": 17.224137485027313, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24772000312805, "training_acc": 52.0, "val_loss": 17.22196340560913, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.25152230262756, "training_acc": 52.0, "val_loss": 17.22009778022766, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.2230658531189, "training_acc": 52.0, "val_loss": 17.220063507556915, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.23920106887817, "training_acc": 52.0, "val_loss": 17.222878336906433, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24202871322632, "training_acc": 52.0, "val_loss": 17.224551737308502, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25648665428162, "training_acc": 52.0, "val_loss": 17.226983606815338, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22844552993774, "training_acc": 52.0, "val_loss": 17.22954660654068, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22558879852295, "training_acc": 52.0, "val_loss": 17.23025292158127, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2307140827179, "training_acc": 52.0, "val_loss": 17.2310933470726, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25283718109131, "training_acc": 52.0, "val_loss": 17.233286798000336, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24763059616089, "training_acc": 52.0, "val_loss": 17.23601520061493, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25036644935608, "training_acc": 52.0, "val_loss": 17.23847985267639, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.25707173347473, "training_acc": 52.0, "val_loss": 17.2413632273674, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.20847344398499, "training_acc": 52.0, "val_loss": 17.24398583173752, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.23754596710205, "training_acc": 52.0, "val_loss": 17.244789004325867, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23406934738159, "training_acc": 52.0, "val_loss": 17.246779799461365, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23543691635132, "training_acc": 52.0, "val_loss": 17.249217629432678, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2261016368866, "training_acc": 52.0, "val_loss": 17.249809205532074, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25489473342896, "training_acc": 52.0, "val_loss": 17.25039631128311, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.2645366191864, "training_acc": 52.0, "val_loss": 17.248666286468506, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24016165733337, "training_acc": 52.0, "val_loss": 17.24865436553955, "val_acc": 56.0}
{"epoch": 62, "training_loss": 69.2218885421753, "training_acc": 52.0, "val_loss": 17.247985303401947, "val_acc": 56.0}
