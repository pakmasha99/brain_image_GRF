"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2113447189331, "training_acc": 53.0, "val_loss": 17.309901118278503, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18738532066345, "training_acc": 53.0, "val_loss": 17.309823632240295, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16489338874817, "training_acc": 53.0, "val_loss": 17.30954647064209, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15658783912659, "training_acc": 53.0, "val_loss": 17.309287190437317, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1464011669159, "training_acc": 53.0, "val_loss": 17.309202253818512, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14876651763916, "training_acc": 53.0, "val_loss": 17.309285700321198, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16198301315308, "training_acc": 53.0, "val_loss": 17.309577763080597, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.10457229614258, "training_acc": 53.0, "val_loss": 17.310050129890442, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13283610343933, "training_acc": 53.0, "val_loss": 17.310824990272522, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14120411872864, "training_acc": 53.0, "val_loss": 17.311546206474304, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14242911338806, "training_acc": 53.0, "val_loss": 17.312097549438477, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14590620994568, "training_acc": 53.0, "val_loss": 17.312683165073395, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15034556388855, "training_acc": 53.0, "val_loss": 17.31245070695877, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1315689086914, "training_acc": 53.0, "val_loss": 17.311981320381165, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14423418045044, "training_acc": 53.0, "val_loss": 17.31162667274475, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.0965485572815, "training_acc": 53.0, "val_loss": 17.311812937259674, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12387084960938, "training_acc": 53.0, "val_loss": 17.311927676200867, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14960527420044, "training_acc": 53.0, "val_loss": 17.311514914035797, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13513898849487, "training_acc": 53.0, "val_loss": 17.311641573905945, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15288662910461, "training_acc": 53.0, "val_loss": 17.312145233154297, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13522052764893, "training_acc": 53.0, "val_loss": 17.312155663967133, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12130689620972, "training_acc": 53.0, "val_loss": 17.31196939945221, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17757773399353, "training_acc": 53.0, "val_loss": 17.311763763427734, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13503456115723, "training_acc": 53.0, "val_loss": 17.312312126159668, "val_acc": 52.0}
