"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23961973190308, "training_acc": 53.0, "val_loss": 17.30729043483734, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18532299995422, "training_acc": 53.0, "val_loss": 17.307010293006897, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22085285186768, "training_acc": 53.0, "val_loss": 17.30596125125885, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17350840568542, "training_acc": 53.0, "val_loss": 17.305363714694977, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18682527542114, "training_acc": 53.0, "val_loss": 17.30503737926483, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14119172096252, "training_acc": 53.0, "val_loss": 17.304641008377075, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15614438056946, "training_acc": 53.0, "val_loss": 17.30455756187439, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14432787895203, "training_acc": 53.0, "val_loss": 17.304599285125732, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1268675327301, "training_acc": 53.0, "val_loss": 17.304863035678864, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15263748168945, "training_acc": 53.0, "val_loss": 17.305313050746918, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14813923835754, "training_acc": 53.0, "val_loss": 17.305888235569, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12007212638855, "training_acc": 53.0, "val_loss": 17.306362092494965, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15513396263123, "training_acc": 53.0, "val_loss": 17.3069030046463, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11887335777283, "training_acc": 53.0, "val_loss": 17.307765781879425, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13386464118958, "training_acc": 53.0, "val_loss": 17.308486998081207, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1123960018158, "training_acc": 53.0, "val_loss": 17.30901300907135, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14526224136353, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14864373207092, "training_acc": 53.0, "val_loss": 17.309848964214325, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14167809486389, "training_acc": 53.0, "val_loss": 17.31029450893402, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13765811920166, "training_acc": 53.0, "val_loss": 17.310796678066254, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09638953208923, "training_acc": 53.0, "val_loss": 17.311377823352814, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10668206214905, "training_acc": 53.0, "val_loss": 17.311419546604156, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13187098503113, "training_acc": 53.0, "val_loss": 17.311561107635498, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13052201271057, "training_acc": 53.0, "val_loss": 17.3117995262146, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13893461227417, "training_acc": 53.0, "val_loss": 17.311833798885345, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12887954711914, "training_acc": 53.0, "val_loss": 17.312602698802948, "val_acc": 52.0}
