"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.57050704956055, "training_acc": 45.0, "val_loss": 17.32794940471649, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.31196761131287, "training_acc": 52.0, "val_loss": 17.312362790107727, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18916749954224, "training_acc": 53.0, "val_loss": 17.332588136196136, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17918491363525, "training_acc": 53.0, "val_loss": 17.348143458366394, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.23017907142639, "training_acc": 53.0, "val_loss": 17.343543469905853, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18358302116394, "training_acc": 53.0, "val_loss": 17.343179881572723, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15369772911072, "training_acc": 53.0, "val_loss": 17.332148551940918, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15538096427917, "training_acc": 53.0, "val_loss": 17.320026457309723, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12337183952332, "training_acc": 53.0, "val_loss": 17.31192320585251, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13963675498962, "training_acc": 53.0, "val_loss": 17.3110693693161, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21150231361389, "training_acc": 53.0, "val_loss": 17.31172949075699, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1675763130188, "training_acc": 53.0, "val_loss": 17.313602566719055, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2396502494812, "training_acc": 53.0, "val_loss": 17.315109074115753, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21273398399353, "training_acc": 53.0, "val_loss": 17.317049205303192, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23130393028259, "training_acc": 53.0, "val_loss": 17.313235998153687, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16735529899597, "training_acc": 53.0, "val_loss": 17.311173677444458, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19905185699463, "training_acc": 53.0, "val_loss": 17.31337010860443, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14071989059448, "training_acc": 53.0, "val_loss": 17.317873239517212, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20007467269897, "training_acc": 53.0, "val_loss": 17.326602339744568, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1914312839508, "training_acc": 53.0, "val_loss": 17.329013347625732, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16088104248047, "training_acc": 53.0, "val_loss": 17.324116826057434, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1376121044159, "training_acc": 53.0, "val_loss": 17.319218814373016, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15622854232788, "training_acc": 53.0, "val_loss": 17.314448952674866, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20170569419861, "training_acc": 53.0, "val_loss": 17.31271743774414, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14226627349854, "training_acc": 53.0, "val_loss": 17.314094305038452, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15093922615051, "training_acc": 53.0, "val_loss": 17.318415641784668, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17150115966797, "training_acc": 53.0, "val_loss": 17.320983111858368, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15072536468506, "training_acc": 53.0, "val_loss": 17.322325706481934, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19717454910278, "training_acc": 53.0, "val_loss": 17.31850355863571, "val_acc": 52.0}
