"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.09528112411499, "training_acc": 47.0, "val_loss": 17.646919190883636, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.82966566085815, "training_acc": 47.0, "val_loss": 17.41199493408203, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50541877746582, "training_acc": 47.0, "val_loss": 17.322255671024323, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.08882880210876, "training_acc": 53.0, "val_loss": 17.3192098736763, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.04549813270569, "training_acc": 53.0, "val_loss": 17.372611165046692, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24984788894653, "training_acc": 53.0, "val_loss": 17.445166409015656, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.58601713180542, "training_acc": 53.0, "val_loss": 17.501437664031982, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.66918206214905, "training_acc": 53.0, "val_loss": 17.502184212207794, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.65583896636963, "training_acc": 53.0, "val_loss": 17.46724247932434, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.57896375656128, "training_acc": 53.0, "val_loss": 17.41955578327179, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.3698787689209, "training_acc": 53.0, "val_loss": 17.37983077764511, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25623893737793, "training_acc": 53.0, "val_loss": 17.343248426914215, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1422004699707, "training_acc": 53.0, "val_loss": 17.320945858955383, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13650727272034, "training_acc": 53.0, "val_loss": 17.311644554138184, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23927354812622, "training_acc": 53.0, "val_loss": 17.31337457895279, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20867943763733, "training_acc": 53.0, "val_loss": 17.315463721752167, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21586227416992, "training_acc": 53.0, "val_loss": 17.3146590590477, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23388695716858, "training_acc": 53.0, "val_loss": 17.31388419866562, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.25797057151794, "training_acc": 53.0, "val_loss": 17.311424016952515, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17953610420227, "training_acc": 53.0, "val_loss": 17.311595380306244, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19223380088806, "training_acc": 53.0, "val_loss": 17.31341779232025, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16312885284424, "training_acc": 53.0, "val_loss": 17.314565181732178, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21643018722534, "training_acc": 53.0, "val_loss": 17.314328253269196, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12715291976929, "training_acc": 53.0, "val_loss": 17.317144572734833, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22911953926086, "training_acc": 53.0, "val_loss": 17.32243299484253, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18850564956665, "training_acc": 53.0, "val_loss": 17.320533096790314, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13911557197571, "training_acc": 53.0, "val_loss": 17.32267290353775, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14308762550354, "training_acc": 53.0, "val_loss": 17.323467135429382, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1580765247345, "training_acc": 53.0, "val_loss": 17.325203120708466, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16031265258789, "training_acc": 53.0, "val_loss": 17.330873012542725, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13892102241516, "training_acc": 53.0, "val_loss": 17.335130274295807, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17208576202393, "training_acc": 53.0, "val_loss": 17.339320480823517, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17079567909241, "training_acc": 53.0, "val_loss": 17.337070405483246, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19664597511292, "training_acc": 53.0, "val_loss": 17.331840097904205, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17622399330139, "training_acc": 53.0, "val_loss": 17.32696294784546, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.17047166824341, "training_acc": 53.0, "val_loss": 17.324449121952057, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14510655403137, "training_acc": 53.0, "val_loss": 17.322564125061035, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13432049751282, "training_acc": 53.0, "val_loss": 17.320144176483154, "val_acc": 52.0}
