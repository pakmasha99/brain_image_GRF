"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2385094165802, "training_acc": 53.0, "val_loss": 17.310266196727753, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.26373624801636, "training_acc": 53.0, "val_loss": 17.316997051239014, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12247443199158, "training_acc": 53.0, "val_loss": 17.311991751194, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18464016914368, "training_acc": 53.0, "val_loss": 17.30915755033493, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30658435821533, "training_acc": 53.0, "val_loss": 17.310352623462677, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16457414627075, "training_acc": 53.0, "val_loss": 17.309169471263885, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15270447731018, "training_acc": 53.0, "val_loss": 17.31126308441162, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12264204025269, "training_acc": 53.0, "val_loss": 17.316512763500214, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17488980293274, "training_acc": 53.0, "val_loss": 17.326068878173828, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18889808654785, "training_acc": 53.0, "val_loss": 17.33129918575287, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16206860542297, "training_acc": 53.0, "val_loss": 17.325863242149353, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12523818016052, "training_acc": 53.0, "val_loss": 17.317287623882294, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23647546768188, "training_acc": 53.0, "val_loss": 17.31075644493103, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1353223323822, "training_acc": 53.0, "val_loss": 17.31017529964447, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13444948196411, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14746165275574, "training_acc": 53.0, "val_loss": 17.309176921844482, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14327383041382, "training_acc": 53.0, "val_loss": 17.309680581092834, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16058301925659, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18549489974976, "training_acc": 53.0, "val_loss": 17.309165000915527, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14130878448486, "training_acc": 53.0, "val_loss": 17.312423884868622, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24862122535706, "training_acc": 53.0, "val_loss": 17.321498692035675, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.151780128479, "training_acc": 53.0, "val_loss": 17.323802411556244, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13369011878967, "training_acc": 53.0, "val_loss": 17.330600321292877, "val_acc": 52.0}
