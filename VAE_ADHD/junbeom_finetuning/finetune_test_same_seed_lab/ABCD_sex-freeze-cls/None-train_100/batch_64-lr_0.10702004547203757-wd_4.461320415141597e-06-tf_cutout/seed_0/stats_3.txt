"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 870.460262298584, "training_acc": 53.0, "val_loss": 170.32493352890015, "val_acc": 52.0}
{"epoch": 1, "training_loss": 915.8682746887207, "training_acc": 49.0, "val_loss": 409.3726634979248, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1531.7056694030762, "training_acc": 47.0, "val_loss": 102.19060182571411, "val_acc": 48.0}
{"epoch": 3, "training_loss": 570.8055419921875, "training_acc": 45.0, "val_loss": 303.80303859710693, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1208.5777587890625, "training_acc": 53.0, "val_loss": 252.91738510131836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 818.9078407287598, "training_acc": 53.0, "val_loss": 75.87534785270691, "val_acc": 48.0}
{"epoch": 6, "training_loss": 457.5097599029541, "training_acc": 47.0, "val_loss": 154.5548677444458, "val_acc": 48.0}
{"epoch": 7, "training_loss": 496.21533584594727, "training_acc": 47.0, "val_loss": 86.94573640823364, "val_acc": 52.0}
{"epoch": 8, "training_loss": 441.85093116760254, "training_acc": 53.0, "val_loss": 148.70272874832153, "val_acc": 52.0}
{"epoch": 9, "training_loss": 484.54822063446045, "training_acc": 53.0, "val_loss": 38.851410150527954, "val_acc": 48.0}
{"epoch": 10, "training_loss": 255.71097564697266, "training_acc": 47.0, "val_loss": 66.51389002799988, "val_acc": 48.0}
{"epoch": 11, "training_loss": 225.1638731956482, "training_acc": 47.0, "val_loss": 59.23696756362915, "val_acc": 52.0}
{"epoch": 12, "training_loss": 194.49561262130737, "training_acc": 53.0, "val_loss": 46.6573566198349, "val_acc": 48.0}
{"epoch": 13, "training_loss": 210.4040412902832, "training_acc": 47.0, "val_loss": 18.00525039434433, "val_acc": 52.0}
{"epoch": 14, "training_loss": 116.13176345825195, "training_acc": 53.0, "val_loss": 35.0534588098526, "val_acc": 52.0}
{"epoch": 15, "training_loss": 153.15212869644165, "training_acc": 47.0, "val_loss": 35.33402979373932, "val_acc": 48.0}
{"epoch": 16, "training_loss": 131.86960220336914, "training_acc": 49.0, "val_loss": 34.49629843235016, "val_acc": 52.0}
{"epoch": 17, "training_loss": 97.88611936569214, "training_acc": 53.0, "val_loss": 48.16175699234009, "val_acc": 48.0}
{"epoch": 18, "training_loss": 169.42072248458862, "training_acc": 47.0, "val_loss": 44.8240727186203, "val_acc": 52.0}
{"epoch": 19, "training_loss": 183.17635202407837, "training_acc": 53.0, "val_loss": 18.518874049186707, "val_acc": 52.0}
{"epoch": 20, "training_loss": 82.59927415847778, "training_acc": 63.0, "val_loss": 41.33062660694122, "val_acc": 48.0}
{"epoch": 21, "training_loss": 156.4311661720276, "training_acc": 45.0, "val_loss": 31.58131241798401, "val_acc": 52.0}
{"epoch": 22, "training_loss": 114.72343873977661, "training_acc": 49.0, "val_loss": 22.390781342983246, "val_acc": 48.0}
{"epoch": 23, "training_loss": 94.65699243545532, "training_acc": 49.0, "val_loss": 20.910698175430298, "val_acc": 52.0}
{"epoch": 24, "training_loss": 116.65632152557373, "training_acc": 43.0, "val_loss": 17.322005331516266, "val_acc": 52.0}
{"epoch": 25, "training_loss": 125.94626331329346, "training_acc": 53.0, "val_loss": 17.622753977775574, "val_acc": 52.0}
{"epoch": 26, "training_loss": 118.81147766113281, "training_acc": 47.0, "val_loss": 22.243860363960266, "val_acc": 48.0}
{"epoch": 27, "training_loss": 158.28064918518066, "training_acc": 41.0, "val_loss": 46.525660157203674, "val_acc": 52.0}
{"epoch": 28, "training_loss": 157.82707262039185, "training_acc": 49.0, "val_loss": 34.45679545402527, "val_acc": 48.0}
{"epoch": 29, "training_loss": 126.04418587684631, "training_acc": 47.0, "val_loss": 25.760963559150696, "val_acc": 52.0}
{"epoch": 30, "training_loss": 96.95409369468689, "training_acc": 51.0, "val_loss": 20.118753612041473, "val_acc": 48.0}
{"epoch": 31, "training_loss": 80.73293399810791, "training_acc": 53.0, "val_loss": 21.212665736675262, "val_acc": 52.0}
{"epoch": 32, "training_loss": 96.03600931167603, "training_acc": 49.0, "val_loss": 17.517276108264923, "val_acc": 52.0}
{"epoch": 33, "training_loss": 84.75403213500977, "training_acc": 49.0, "val_loss": 17.45109111070633, "val_acc": 52.0}
{"epoch": 34, "training_loss": 99.09239101409912, "training_acc": 45.0, "val_loss": 19.535045325756073, "val_acc": 52.0}
{"epoch": 35, "training_loss": 81.01479244232178, "training_acc": 53.0, "val_loss": 18.397235870361328, "val_acc": 48.0}
{"epoch": 36, "training_loss": 77.99263429641724, "training_acc": 37.0, "val_loss": 23.12733083963394, "val_acc": 48.0}
{"epoch": 37, "training_loss": 80.73427200317383, "training_acc": 55.0, "val_loss": 30.052295327186584, "val_acc": 52.0}
{"epoch": 38, "training_loss": 96.83018064498901, "training_acc": 53.0, "val_loss": 37.31690049171448, "val_acc": 48.0}
{"epoch": 39, "training_loss": 125.41277432441711, "training_acc": 47.0, "val_loss": 33.9859277009964, "val_acc": 52.0}
{"epoch": 40, "training_loss": 113.1047375202179, "training_acc": 53.0, "val_loss": 32.59551227092743, "val_acc": 48.0}
{"epoch": 41, "training_loss": 115.43312001228333, "training_acc": 45.0, "val_loss": 23.323163390159607, "val_acc": 52.0}
{"epoch": 42, "training_loss": 85.88838601112366, "training_acc": 51.0, "val_loss": 18.519099056720734, "val_acc": 48.0}
{"epoch": 43, "training_loss": 98.38641023635864, "training_acc": 41.0, "val_loss": 20.179229974746704, "val_acc": 48.0}
