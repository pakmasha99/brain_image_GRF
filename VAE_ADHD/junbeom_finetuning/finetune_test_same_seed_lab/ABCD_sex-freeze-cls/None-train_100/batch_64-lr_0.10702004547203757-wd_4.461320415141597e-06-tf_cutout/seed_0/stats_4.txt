"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1008.9068603515625, "training_acc": 53.0, "val_loss": 186.74441576004028, "val_acc": 52.0}
{"epoch": 1, "training_loss": 710.8656730651855, "training_acc": 59.0, "val_loss": 421.699857711792, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1626.5583000183105, "training_acc": 47.0, "val_loss": 162.22416162490845, "val_acc": 48.0}
{"epoch": 3, "training_loss": 561.9920616149902, "training_acc": 51.0, "val_loss": 237.80286312103271, "val_acc": 52.0}
{"epoch": 4, "training_loss": 994.0638313293457, "training_acc": 53.0, "val_loss": 183.77301692962646, "val_acc": 52.0}
{"epoch": 5, "training_loss": 505.38693380355835, "training_acc": 53.0, "val_loss": 182.14035034179688, "val_acc": 48.0}
{"epoch": 6, "training_loss": 905.4507827758789, "training_acc": 47.0, "val_loss": 275.5131244659424, "val_acc": 48.0}
{"epoch": 7, "training_loss": 997.2426738739014, "training_acc": 47.0, "val_loss": 32.199689745903015, "val_acc": 48.0}
{"epoch": 8, "training_loss": 222.18161964416504, "training_acc": 59.0, "val_loss": 262.53678798675537, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1063.6051712036133, "training_acc": 53.0, "val_loss": 268.5567617416382, "val_acc": 52.0}
{"epoch": 10, "training_loss": 926.2644577026367, "training_acc": 53.0, "val_loss": 51.4911413192749, "val_acc": 52.0}
{"epoch": 11, "training_loss": 299.70687675476074, "training_acc": 55.0, "val_loss": 244.0218210220337, "val_acc": 48.0}
{"epoch": 12, "training_loss": 1018.7293853759766, "training_acc": 47.0, "val_loss": 215.47963619232178, "val_acc": 48.0}
{"epoch": 13, "training_loss": 740.1887445449829, "training_acc": 47.0, "val_loss": 61.7842972278595, "val_acc": 52.0}
{"epoch": 14, "training_loss": 414.5848731994629, "training_acc": 53.0, "val_loss": 155.21612167358398, "val_acc": 52.0}
{"epoch": 15, "training_loss": 531.319429397583, "training_acc": 53.0, "val_loss": 17.3644557595253, "val_acc": 52.0}
{"epoch": 16, "training_loss": 244.4819850921631, "training_acc": 47.0, "val_loss": 118.61580610275269, "val_acc": 48.0}
{"epoch": 17, "training_loss": 405.25209283828735, "training_acc": 47.0, "val_loss": 53.41999530792236, "val_acc": 52.0}
{"epoch": 18, "training_loss": 248.6112060546875, "training_acc": 53.0, "val_loss": 72.79598712921143, "val_acc": 52.0}
{"epoch": 19, "training_loss": 193.85248184204102, "training_acc": 53.0, "val_loss": 83.12157392501831, "val_acc": 48.0}
{"epoch": 20, "training_loss": 373.6237277984619, "training_acc": 47.0, "val_loss": 50.716185569763184, "val_acc": 48.0}
{"epoch": 21, "training_loss": 204.12320709228516, "training_acc": 51.0, "val_loss": 98.11394810676575, "val_acc": 52.0}
{"epoch": 22, "training_loss": 360.2591438293457, "training_acc": 53.0, "val_loss": 19.506987929344177, "val_acc": 52.0}
{"epoch": 23, "training_loss": 129.33979034423828, "training_acc": 59.0, "val_loss": 96.32502794265747, "val_acc": 48.0}
{"epoch": 24, "training_loss": 328.48520135879517, "training_acc": 47.0, "val_loss": 51.101845502853394, "val_acc": 52.0}
{"epoch": 25, "training_loss": 229.34214305877686, "training_acc": 53.0, "val_loss": 54.17846441268921, "val_acc": 52.0}
{"epoch": 26, "training_loss": 165.17389678955078, "training_acc": 53.0, "val_loss": 49.98804032802582, "val_acc": 48.0}
{"epoch": 27, "training_loss": 159.9742555618286, "training_acc": 47.0, "val_loss": 49.43996071815491, "val_acc": 52.0}
{"epoch": 28, "training_loss": 206.38034057617188, "training_acc": 53.0, "val_loss": 17.986080050468445, "val_acc": 52.0}
{"epoch": 29, "training_loss": 118.37542152404785, "training_acc": 47.0, "val_loss": 26.930662989616394, "val_acc": 48.0}
{"epoch": 30, "training_loss": 113.45005130767822, "training_acc": 55.0, "val_loss": 54.1525661945343, "val_acc": 52.0}
{"epoch": 31, "training_loss": 169.10761189460754, "training_acc": 53.0, "val_loss": 46.88687026500702, "val_acc": 48.0}
{"epoch": 32, "training_loss": 168.42644476890564, "training_acc": 47.0, "val_loss": 31.409326195716858, "val_acc": 52.0}
{"epoch": 33, "training_loss": 116.52821350097656, "training_acc": 53.0, "val_loss": 26.826944947242737, "val_acc": 48.0}
{"epoch": 34, "training_loss": 101.11097073554993, "training_acc": 47.0, "val_loss": 27.553224563598633, "val_acc": 52.0}
