"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1050.2289428710938, "training_acc": 47.0, "val_loss": 157.5627088546753, "val_acc": 48.0}
{"epoch": 1, "training_loss": 865.2218818664551, "training_acc": 49.0, "val_loss": 488.3766174316406, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1903.3330078125, "training_acc": 53.0, "val_loss": 358.71522426605225, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1220.8125171661377, "training_acc": 53.0, "val_loss": 119.24759149551392, "val_acc": 48.0}
{"epoch": 4, "training_loss": 610.5920162200928, "training_acc": 47.0, "val_loss": 221.41742706298828, "val_acc": 48.0}
{"epoch": 5, "training_loss": 781.8458261489868, "training_acc": 47.0, "val_loss": 42.911359667778015, "val_acc": 52.0}
{"epoch": 6, "training_loss": 265.79412269592285, "training_acc": 53.0, "val_loss": 90.9789502620697, "val_acc": 52.0}
{"epoch": 7, "training_loss": 267.0649673938751, "training_acc": 53.0, "val_loss": 81.39622807502747, "val_acc": 48.0}
{"epoch": 8, "training_loss": 321.24119567871094, "training_acc": 47.0, "val_loss": 17.871853709220886, "val_acc": 52.0}
{"epoch": 9, "training_loss": 123.96019554138184, "training_acc": 53.0, "val_loss": 45.93671262264252, "val_acc": 52.0}
{"epoch": 10, "training_loss": 168.86206912994385, "training_acc": 49.0, "val_loss": 35.86094677448273, "val_acc": 48.0}
{"epoch": 11, "training_loss": 115.58168339729309, "training_acc": 55.0, "val_loss": 37.496545910835266, "val_acc": 52.0}
{"epoch": 12, "training_loss": 116.01116943359375, "training_acc": 53.0, "val_loss": 35.038161277770996, "val_acc": 48.0}
{"epoch": 13, "training_loss": 120.59061884880066, "training_acc": 47.0, "val_loss": 25.736111402511597, "val_acc": 52.0}
{"epoch": 14, "training_loss": 118.69101047515869, "training_acc": 41.0, "val_loss": 18.867003917694092, "val_acc": 52.0}
{"epoch": 15, "training_loss": 76.13189315795898, "training_acc": 53.0, "val_loss": 19.641947746276855, "val_acc": 48.0}
{"epoch": 16, "training_loss": 75.74075698852539, "training_acc": 47.0, "val_loss": 26.948529481887817, "val_acc": 52.0}
{"epoch": 17, "training_loss": 90.94053316116333, "training_acc": 53.0, "val_loss": 29.986673593521118, "val_acc": 48.0}
{"epoch": 18, "training_loss": 117.15633893013, "training_acc": 43.0, "val_loss": 17.734943330287933, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.25721859931946, "training_acc": 63.0, "val_loss": 29.421180486679077, "val_acc": 48.0}
{"epoch": 20, "training_loss": 109.67337799072266, "training_acc": 47.0, "val_loss": 19.651296734809875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 85.7444519996643, "training_acc": 51.0, "val_loss": 17.578406631946564, "val_acc": 52.0}
{"epoch": 22, "training_loss": 76.21567106246948, "training_acc": 53.0, "val_loss": 20.65780907869339, "val_acc": 48.0}
{"epoch": 23, "training_loss": 78.4575023651123, "training_acc": 49.0, "val_loss": 21.06679528951645, "val_acc": 52.0}
{"epoch": 24, "training_loss": 83.83338189125061, "training_acc": 49.0, "val_loss": 17.69275665283203, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.24712085723877, "training_acc": 53.0, "val_loss": 17.54498779773712, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.82641577720642, "training_acc": 49.0, "val_loss": 19.697679579257965, "val_acc": 52.0}
{"epoch": 27, "training_loss": 80.23032331466675, "training_acc": 47.0, "val_loss": 19.606497883796692, "val_acc": 52.0}
{"epoch": 28, "training_loss": 75.01597332954407, "training_acc": 53.0, "val_loss": 38.28764259815216, "val_acc": 48.0}
{"epoch": 29, "training_loss": 132.55542182922363, "training_acc": 45.0, "val_loss": 22.990506887435913, "val_acc": 52.0}
{"epoch": 30, "training_loss": 110.66591835021973, "training_acc": 45.0, "val_loss": 21.26140147447586, "val_acc": 52.0}
{"epoch": 31, "training_loss": 91.84442186355591, "training_acc": 53.0, "val_loss": 45.24746537208557, "val_acc": 48.0}
{"epoch": 32, "training_loss": 157.15673208236694, "training_acc": 47.0, "val_loss": 59.28742289543152, "val_acc": 52.0}
{"epoch": 33, "training_loss": 224.58448314666748, "training_acc": 53.0, "val_loss": 18.894687294960022, "val_acc": 48.0}
{"epoch": 34, "training_loss": 115.50786828994751, "training_acc": 47.0, "val_loss": 22.594711184501648, "val_acc": 52.0}
{"epoch": 35, "training_loss": 89.26635670661926, "training_acc": 53.0, "val_loss": 21.34319692850113, "val_acc": 48.0}
{"epoch": 36, "training_loss": 80.19849061965942, "training_acc": 49.0, "val_loss": 20.600280165672302, "val_acc": 52.0}
{"epoch": 37, "training_loss": 81.13274312019348, "training_acc": 51.0, "val_loss": 17.541995644569397, "val_acc": 52.0}
{"epoch": 38, "training_loss": 70.08015441894531, "training_acc": 53.0, "val_loss": 17.767474055290222, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.70368838310242, "training_acc": 49.0, "val_loss": 17.3692986369133, "val_acc": 52.0}
{"epoch": 40, "training_loss": 72.75308966636658, "training_acc": 47.0, "val_loss": 24.75457936525345, "val_acc": 52.0}
{"epoch": 41, "training_loss": 107.61010932922363, "training_acc": 43.0, "val_loss": 24.35317486524582, "val_acc": 52.0}
{"epoch": 42, "training_loss": 86.01598834991455, "training_acc": 53.0, "val_loss": 23.91105145215988, "val_acc": 48.0}
{"epoch": 43, "training_loss": 83.23570251464844, "training_acc": 55.0, "val_loss": 23.360247910022736, "val_acc": 52.0}
{"epoch": 44, "training_loss": 88.76460194587708, "training_acc": 55.0, "val_loss": 17.77024418115616, "val_acc": 52.0}
{"epoch": 45, "training_loss": 121.39611625671387, "training_acc": 39.0, "val_loss": 22.487443685531616, "val_acc": 48.0}
{"epoch": 46, "training_loss": 93.28163480758667, "training_acc": 47.0, "val_loss": 40.40772020816803, "val_acc": 52.0}
{"epoch": 47, "training_loss": 136.84056043624878, "training_acc": 53.0, "val_loss": 56.63289427757263, "val_acc": 48.0}
{"epoch": 48, "training_loss": 227.77068042755127, "training_acc": 47.0, "val_loss": 58.61433744430542, "val_acc": 52.0}
{"epoch": 49, "training_loss": 264.60741996765137, "training_acc": 53.0, "val_loss": 33.299610018730164, "val_acc": 52.0}
{"epoch": 50, "training_loss": 219.8272008895874, "training_acc": 49.0, "val_loss": 101.93296670913696, "val_acc": 48.0}
{"epoch": 51, "training_loss": 302.88252210617065, "training_acc": 47.0, "val_loss": 108.23750495910645, "val_acc": 52.0}
{"epoch": 52, "training_loss": 524.8044109344482, "training_acc": 53.0, "val_loss": 138.20958137512207, "val_acc": 52.0}
{"epoch": 53, "training_loss": 402.7234959602356, "training_acc": 53.0, "val_loss": 124.88429546356201, "val_acc": 48.0}
{"epoch": 54, "training_loss": 577.2837028503418, "training_acc": 47.0, "val_loss": 157.93856382369995, "val_acc": 48.0}
{"epoch": 55, "training_loss": 473.71982860565186, "training_acc": 47.0, "val_loss": 115.65241813659668, "val_acc": 52.0}
{"epoch": 56, "training_loss": 553.8983287811279, "training_acc": 53.0, "val_loss": 207.79564380645752, "val_acc": 52.0}
{"epoch": 57, "training_loss": 728.6803855895996, "training_acc": 53.0, "val_loss": 29.532259702682495, "val_acc": 52.0}
{"epoch": 58, "training_loss": 294.74559211730957, "training_acc": 51.0, "val_loss": 229.33154106140137, "val_acc": 48.0}
