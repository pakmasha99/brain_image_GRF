"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.36767244338989, "training_acc": 53.0, "val_loss": 17.773178219795227, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.7133572101593, "training_acc": 51.0, "val_loss": 19.906188547611237, "val_acc": 48.0}
{"epoch": 2, "training_loss": 79.01847219467163, "training_acc": 47.0, "val_loss": 17.54937469959259, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.4892795085907, "training_acc": 45.0, "val_loss": 18.55245530605316, "val_acc": 52.0}
{"epoch": 4, "training_loss": 75.65703558921814, "training_acc": 53.0, "val_loss": 18.46795380115509, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.24640989303589, "training_acc": 53.0, "val_loss": 17.339038848876953, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.00455784797668, "training_acc": 47.0, "val_loss": 18.141749501228333, "val_acc": 52.0}
{"epoch": 7, "training_loss": 72.8405454158783, "training_acc": 47.0, "val_loss": 17.67071932554245, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.2614848613739, "training_acc": 47.0, "val_loss": 17.341896891593933, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.0475218296051, "training_acc": 53.0, "val_loss": 17.892959713935852, "val_acc": 52.0}
{"epoch": 10, "training_loss": 71.03291249275208, "training_acc": 53.0, "val_loss": 17.789945006370544, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.33168053627014, "training_acc": 53.0, "val_loss": 17.328980565071106, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.04202580451965, "training_acc": 54.0, "val_loss": 17.466990649700165, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.99870681762695, "training_acc": 47.0, "val_loss": 17.503972351551056, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.02899980545044, "training_acc": 47.0, "val_loss": 17.31277108192444, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.50562047958374, "training_acc": 53.0, "val_loss": 17.58141666650772, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.04436421394348, "training_acc": 53.0, "val_loss": 17.54457652568817, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.07629895210266, "training_acc": 53.0, "val_loss": 17.311246693134308, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15838575363159, "training_acc": 53.0, "val_loss": 17.329546809196472, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.42737364768982, "training_acc": 42.0, "val_loss": 17.31327921152115, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16926312446594, "training_acc": 53.0, "val_loss": 17.371520400047302, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.1765205860138, "training_acc": 53.0, "val_loss": 17.385347187519073, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.37573456764221, "training_acc": 53.0, "val_loss": 17.35115349292755, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.71743130683899, "training_acc": 47.0, "val_loss": 17.364729940891266, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.75098299980164, "training_acc": 37.0, "val_loss": 17.328807711601257, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12372708320618, "training_acc": 53.0, "val_loss": 17.30978786945343, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25750422477722, "training_acc": 53.0, "val_loss": 17.32824742794037, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24845504760742, "training_acc": 52.0, "val_loss": 17.310050129890442, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.22245216369629, "training_acc": 53.0, "val_loss": 17.360731959342957, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.93259644508362, "training_acc": 53.0, "val_loss": 17.474959790706635, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.766526222229, "training_acc": 53.0, "val_loss": 17.3325777053833, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.37315392494202, "training_acc": 43.0, "val_loss": 17.3898383975029, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.73780822753906, "training_acc": 47.0, "val_loss": 17.359068989753723, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.46872019767761, "training_acc": 47.0, "val_loss": 17.349907755851746, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.26379919052124, "training_acc": 53.0, "val_loss": 17.42074191570282, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.48329877853394, "training_acc": 53.0, "val_loss": 17.33204871416092, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.18602323532104, "training_acc": 53.0, "val_loss": 17.310579121112823, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1336817741394, "training_acc": 53.0, "val_loss": 17.31090545654297, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.28514409065247, "training_acc": 53.0, "val_loss": 17.319898307323456, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.07882809638977, "training_acc": 53.0, "val_loss": 17.40874946117401, "val_acc": 52.0}
{"epoch": 40, "training_loss": 70.6905448436737, "training_acc": 53.0, "val_loss": 17.384426295757294, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.09197306632996, "training_acc": 45.0, "val_loss": 17.430591583251953, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.82278180122375, "training_acc": 47.0, "val_loss": 17.35030859708786, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.38722348213196, "training_acc": 47.0, "val_loss": 17.320744693279266, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.10226464271545, "training_acc": 53.0, "val_loss": 17.373524606227875, "val_acc": 52.0}
