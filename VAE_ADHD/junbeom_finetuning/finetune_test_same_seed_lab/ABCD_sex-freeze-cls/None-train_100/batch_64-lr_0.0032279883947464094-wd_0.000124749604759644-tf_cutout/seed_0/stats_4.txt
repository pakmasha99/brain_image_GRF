"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 75.87758922576904, "training_acc": 51.0, "val_loss": 17.413952946662903, "val_acc": 52.0}
{"epoch": 1, "training_loss": 75.70361709594727, "training_acc": 43.0, "val_loss": 20.053058862686157, "val_acc": 52.0}
{"epoch": 2, "training_loss": 77.18237900733948, "training_acc": 53.0, "val_loss": 17.48241037130356, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.7641088962555, "training_acc": 55.0, "val_loss": 18.45802217721939, "val_acc": 48.0}
{"epoch": 4, "training_loss": 74.45696091651917, "training_acc": 47.0, "val_loss": 18.485261499881744, "val_acc": 48.0}
{"epoch": 5, "training_loss": 73.31529903411865, "training_acc": 47.0, "val_loss": 17.324692010879517, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12595915794373, "training_acc": 51.0, "val_loss": 18.078330159187317, "val_acc": 52.0}
{"epoch": 7, "training_loss": 74.10897326469421, "training_acc": 53.0, "val_loss": 18.25721710920334, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.45824122428894, "training_acc": 53.0, "val_loss": 17.30564832687378, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.25631976127625, "training_acc": 47.0, "val_loss": 17.885231971740723, "val_acc": 52.0}
{"epoch": 10, "training_loss": 71.83268666267395, "training_acc": 47.0, "val_loss": 17.583537101745605, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.77361297607422, "training_acc": 47.0, "val_loss": 17.330636084079742, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.83875870704651, "training_acc": 53.0, "val_loss": 18.056802451610565, "val_acc": 52.0}
{"epoch": 13, "training_loss": 72.32401418685913, "training_acc": 53.0, "val_loss": 18.071769177913666, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.78952765464783, "training_acc": 53.0, "val_loss": 17.311991751194, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.85616731643677, "training_acc": 55.0, "val_loss": 17.772004008293152, "val_acc": 52.0}
{"epoch": 16, "training_loss": 71.39502310752869, "training_acc": 47.0, "val_loss": 17.843569815158844, "val_acc": 52.0}
{"epoch": 17, "training_loss": 72.294189453125, "training_acc": 47.0, "val_loss": 17.3726424574852, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.56827664375305, "training_acc": 47.0, "val_loss": 17.32749491930008, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14235806465149, "training_acc": 53.0, "val_loss": 17.451390624046326, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.16637539863586, "training_acc": 53.0, "val_loss": 17.557650804519653, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.11391544342041, "training_acc": 53.0, "val_loss": 17.31010526418686, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.03152513504028, "training_acc": 53.0, "val_loss": 17.330142855644226, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.65295147895813, "training_acc": 47.0, "val_loss": 17.376510798931122, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.42031192779541, "training_acc": 48.0, "val_loss": 17.309829592704773, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19192266464233, "training_acc": 53.0, "val_loss": 17.45995730161667, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.03424119949341, "training_acc": 53.0, "val_loss": 17.406508326530457, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.03837180137634, "training_acc": 53.0, "val_loss": 17.346566915512085, "val_acc": 52.0}
