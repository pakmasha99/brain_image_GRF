"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 76.37146043777466, "training_acc": 53.0, "val_loss": 17.76733696460724, "val_acc": 52.0}
{"epoch": 1, "training_loss": 72.92503619194031, "training_acc": 49.0, "val_loss": 19.691447913646698, "val_acc": 48.0}
{"epoch": 2, "training_loss": 78.67210698127747, "training_acc": 47.0, "val_loss": 17.546778917312622, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.68130850791931, "training_acc": 51.0, "val_loss": 18.831320106983185, "val_acc": 52.0}
{"epoch": 4, "training_loss": 77.3812825679779, "training_acc": 53.0, "val_loss": 19.32540535926819, "val_acc": 52.0}
{"epoch": 5, "training_loss": 75.97297382354736, "training_acc": 53.0, "val_loss": 17.351356148719788, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.36985635757446, "training_acc": 51.0, "val_loss": 17.83873289823532, "val_acc": 52.0}
{"epoch": 7, "training_loss": 72.09742283821106, "training_acc": 47.0, "val_loss": 17.93225407600403, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72.04602384567261, "training_acc": 47.0, "val_loss": 17.31697767972946, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.10340619087219, "training_acc": 53.0, "val_loss": 17.530015110969543, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.92958545684814, "training_acc": 53.0, "val_loss": 17.72146373987198, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.29420828819275, "training_acc": 53.0, "val_loss": 17.403224110603333, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.6953501701355, "training_acc": 53.0, "val_loss": 17.35231578350067, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.78611326217651, "training_acc": 47.0, "val_loss": 17.391258478164673, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.6610255241394, "training_acc": 47.0, "val_loss": 17.308999598026276, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.45002722740173, "training_acc": 53.0, "val_loss": 17.400728166103363, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.33351969718933, "training_acc": 53.0, "val_loss": 17.33466237783432, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18030381202698, "training_acc": 53.0, "val_loss": 17.30598360300064, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.38635206222534, "training_acc": 47.0, "val_loss": 17.314618825912476, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24131345748901, "training_acc": 53.0, "val_loss": 17.319785058498383, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.36137056350708, "training_acc": 53.0, "val_loss": 17.380517721176147, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.61405396461487, "training_acc": 53.0, "val_loss": 17.529861629009247, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.88276052474976, "training_acc": 53.0, "val_loss": 17.651306092739105, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.02384114265442, "training_acc": 53.0, "val_loss": 17.340920865535736, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.00844550132751, "training_acc": 45.0, "val_loss": 17.426735162734985, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.81221008300781, "training_acc": 47.0, "val_loss": 17.345111072063446, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25268888473511, "training_acc": 56.0, "val_loss": 17.33248084783554, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.06856155395508, "training_acc": 53.0, "val_loss": 17.59151667356491, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.01505398750305, "training_acc": 53.0, "val_loss": 17.50521957874298, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.98756909370422, "training_acc": 53.0, "val_loss": 17.30554550886154, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13792371749878, "training_acc": 53.0, "val_loss": 17.317335307598114, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.40266919136047, "training_acc": 49.0, "val_loss": 17.32497364282608, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.21480703353882, "training_acc": 54.0, "val_loss": 17.324353754520416, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.23957371711731, "training_acc": 53.0, "val_loss": 17.468154430389404, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.72441864013672, "training_acc": 53.0, "val_loss": 17.368896305561066, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2458963394165, "training_acc": 53.0, "val_loss": 17.310768365859985, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15936589241028, "training_acc": 53.0, "val_loss": 17.323215305805206, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.35457730293274, "training_acc": 46.0, "val_loss": 17.308345437049866, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.28915095329285, "training_acc": 53.0, "val_loss": 17.346084117889404, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.401123046875, "training_acc": 53.0, "val_loss": 17.335014045238495, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.08131051063538, "training_acc": 53.0, "val_loss": 17.318101227283478, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.61374616622925, "training_acc": 47.0, "val_loss": 17.33449101448059, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.44509625434875, "training_acc": 47.0, "val_loss": 17.343227565288544, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.25097727775574, "training_acc": 53.0, "val_loss": 17.3776313662529, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.24051642417908, "training_acc": 53.0, "val_loss": 17.309120297431946, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.08500647544861, "training_acc": 53.0, "val_loss": 17.31661558151245, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.46354913711548, "training_acc": 47.0, "val_loss": 17.31008142232895, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.36749935150146, "training_acc": 53.0, "val_loss": 17.37118810415268, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.29515075683594, "training_acc": 53.0, "val_loss": 17.34950542449951, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.25268268585205, "training_acc": 53.0, "val_loss": 17.304305732250214, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.16358351707458, "training_acc": 53.0, "val_loss": 17.305360734462738, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.19071388244629, "training_acc": 53.0, "val_loss": 17.304319143295288, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.15861439704895, "training_acc": 53.0, "val_loss": 17.30625331401825, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.6989073753357, "training_acc": 53.0, "val_loss": 17.30855405330658, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.02909111976624, "training_acc": 53.0, "val_loss": 17.354999482631683, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.53959703445435, "training_acc": 47.0, "val_loss": 17.34684556722641, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.31424474716187, "training_acc": 48.0, "val_loss": 17.352111637592316, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.69872331619263, "training_acc": 53.0, "val_loss": 17.612987756729126, "val_acc": 52.0}
{"epoch": 58, "training_loss": 70.08362483978271, "training_acc": 53.0, "val_loss": 17.306818068027496, "val_acc": 52.0}
{"epoch": 59, "training_loss": 71.1181538105011, "training_acc": 43.0, "val_loss": 17.633970081806183, "val_acc": 52.0}
{"epoch": 60, "training_loss": 70.390944480896, "training_acc": 47.0, "val_loss": 17.313815653324127, "val_acc": 52.0}
{"epoch": 61, "training_loss": 71.31049036979675, "training_acc": 53.0, "val_loss": 17.882204055786133, "val_acc": 52.0}
{"epoch": 62, "training_loss": 70.56159043312073, "training_acc": 53.0, "val_loss": 17.315112054347992, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.37338709831238, "training_acc": 51.0, "val_loss": 17.6858052611351, "val_acc": 52.0}
{"epoch": 64, "training_loss": 72.64914274215698, "training_acc": 47.0, "val_loss": 17.370884120464325, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.22779440879822, "training_acc": 51.0, "val_loss": 18.14263164997101, "val_acc": 52.0}
{"epoch": 66, "training_loss": 72.01688265800476, "training_acc": 53.0, "val_loss": 18.12528371810913, "val_acc": 52.0}
{"epoch": 67, "training_loss": 72.21582865715027, "training_acc": 53.0, "val_loss": 17.314355075359344, "val_acc": 52.0}
{"epoch": 68, "training_loss": 70.34298133850098, "training_acc": 43.0, "val_loss": 17.396889626979828, "val_acc": 52.0}
