"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2379858493805, "training_acc": 53.0, "val_loss": 17.31370836496353, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21699070930481, "training_acc": 53.0, "val_loss": 17.313575744628906, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22214221954346, "training_acc": 53.0, "val_loss": 17.312519252300262, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18464970588684, "training_acc": 53.0, "val_loss": 17.311321198940277, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20122838020325, "training_acc": 53.0, "val_loss": 17.310237884521484, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20182037353516, "training_acc": 53.0, "val_loss": 17.309625446796417, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1841037273407, "training_acc": 53.0, "val_loss": 17.30882227420807, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17847442626953, "training_acc": 53.0, "val_loss": 17.30818748474121, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16845536231995, "training_acc": 53.0, "val_loss": 17.30760484933853, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14911580085754, "training_acc": 53.0, "val_loss": 17.307189106941223, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16224217414856, "training_acc": 53.0, "val_loss": 17.30695813894272, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1461889743805, "training_acc": 53.0, "val_loss": 17.30690598487854, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17193531990051, "training_acc": 53.0, "val_loss": 17.306944727897644, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15101933479309, "training_acc": 53.0, "val_loss": 17.307011783123016, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13701057434082, "training_acc": 53.0, "val_loss": 17.30712801218033, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15126514434814, "training_acc": 53.0, "val_loss": 17.307311296463013, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1207582950592, "training_acc": 53.0, "val_loss": 17.307525873184204, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13790822029114, "training_acc": 53.0, "val_loss": 17.307718098163605, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13854646682739, "training_acc": 53.0, "val_loss": 17.308111488819122, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14710283279419, "training_acc": 53.0, "val_loss": 17.308419942855835, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12188196182251, "training_acc": 53.0, "val_loss": 17.308582365512848, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12689232826233, "training_acc": 53.0, "val_loss": 17.30870008468628, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14713954925537, "training_acc": 53.0, "val_loss": 17.308898270130157, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13251757621765, "training_acc": 53.0, "val_loss": 17.309047281742096, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10893559455872, "training_acc": 53.0, "val_loss": 17.30923056602478, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12755727767944, "training_acc": 53.0, "val_loss": 17.309436202049255, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13869857788086, "training_acc": 53.0, "val_loss": 17.309775948524475, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13555264472961, "training_acc": 53.0, "val_loss": 17.310039699077606, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1221251487732, "training_acc": 53.0, "val_loss": 17.310191690921783, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13385725021362, "training_acc": 53.0, "val_loss": 17.310598492622375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13148379325867, "training_acc": 53.0, "val_loss": 17.31100082397461, "val_acc": 52.0}
