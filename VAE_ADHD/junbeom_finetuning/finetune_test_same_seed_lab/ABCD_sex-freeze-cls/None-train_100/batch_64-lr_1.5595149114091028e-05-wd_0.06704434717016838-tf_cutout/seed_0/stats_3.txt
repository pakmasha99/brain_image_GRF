"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2442364692688, "training_acc": 53.0, "val_loss": 17.313188314437866, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2009539604187, "training_acc": 53.0, "val_loss": 17.31260120868683, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20841932296753, "training_acc": 53.0, "val_loss": 17.31230467557907, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2179491519928, "training_acc": 53.0, "val_loss": 17.31170266866684, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2012779712677, "training_acc": 53.0, "val_loss": 17.311324179172516, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17253804206848, "training_acc": 53.0, "val_loss": 17.31107085943222, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16077733039856, "training_acc": 53.0, "val_loss": 17.310820519924164, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18345212936401, "training_acc": 53.0, "val_loss": 17.310647666454315, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16076374053955, "training_acc": 53.0, "val_loss": 17.310519516468048, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14168643951416, "training_acc": 53.0, "val_loss": 17.310458421707153, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16950154304504, "training_acc": 53.0, "val_loss": 17.310546338558197, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15510201454163, "training_acc": 53.0, "val_loss": 17.310751974582672, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1611557006836, "training_acc": 53.0, "val_loss": 17.311057448387146, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16757535934448, "training_acc": 53.0, "val_loss": 17.31128692626953, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17199373245239, "training_acc": 53.0, "val_loss": 17.311617732048035, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1246690750122, "training_acc": 53.0, "val_loss": 17.31221377849579, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14135789871216, "training_acc": 53.0, "val_loss": 17.31291562318802, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12973380088806, "training_acc": 53.0, "val_loss": 17.313727736473083, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14543271064758, "training_acc": 53.0, "val_loss": 17.314569652080536, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13882732391357, "training_acc": 53.0, "val_loss": 17.31541007757187, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1448986530304, "training_acc": 53.0, "val_loss": 17.316314578056335, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15096020698547, "training_acc": 53.0, "val_loss": 17.31729507446289, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14849758148193, "training_acc": 53.0, "val_loss": 17.317920923233032, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1448290348053, "training_acc": 53.0, "val_loss": 17.318516969680786, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1480348110199, "training_acc": 53.0, "val_loss": 17.319032549858093, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1716456413269, "training_acc": 53.0, "val_loss": 17.319869995117188, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1487648487091, "training_acc": 53.0, "val_loss": 17.320048809051514, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12866544723511, "training_acc": 53.0, "val_loss": 17.320355772972107, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14462208747864, "training_acc": 53.0, "val_loss": 17.32059121131897, "val_acc": 52.0}
