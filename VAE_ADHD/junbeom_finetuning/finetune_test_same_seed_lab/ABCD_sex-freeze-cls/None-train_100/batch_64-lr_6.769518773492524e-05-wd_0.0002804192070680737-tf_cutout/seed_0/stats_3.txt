"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34519934654236, "training_acc": 53.0, "val_loss": 17.31014996767044, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17926478385925, "training_acc": 53.0, "val_loss": 17.310282588005066, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1537721157074, "training_acc": 53.0, "val_loss": 17.31068789958954, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18535923957825, "training_acc": 53.0, "val_loss": 17.310231924057007, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15714263916016, "training_acc": 53.0, "val_loss": 17.309509217739105, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1868245601654, "training_acc": 53.0, "val_loss": 17.309215664863586, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14540028572083, "training_acc": 53.0, "val_loss": 17.30949729681015, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14458560943604, "training_acc": 53.0, "val_loss": 17.31022447347641, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12889647483826, "training_acc": 53.0, "val_loss": 17.31136292219162, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13499569892883, "training_acc": 53.0, "val_loss": 17.312438786029816, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14910912513733, "training_acc": 53.0, "val_loss": 17.31284111738205, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10947299003601, "training_acc": 53.0, "val_loss": 17.31492131948471, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13163685798645, "training_acc": 53.0, "val_loss": 17.318248748779297, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1724750995636, "training_acc": 53.0, "val_loss": 17.320820689201355, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14562034606934, "training_acc": 53.0, "val_loss": 17.320145666599274, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13251876831055, "training_acc": 53.0, "val_loss": 17.318330705165863, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1297538280487, "training_acc": 53.0, "val_loss": 17.31787472963333, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11754155158997, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11326146125793, "training_acc": 53.0, "val_loss": 17.317983508110046, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387106895447, "training_acc": 53.0, "val_loss": 17.318563163280487, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14704537391663, "training_acc": 53.0, "val_loss": 17.318148910999298, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1211588382721, "training_acc": 53.0, "val_loss": 17.31569617986679, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14273142814636, "training_acc": 53.0, "val_loss": 17.314185202121735, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11605429649353, "training_acc": 53.0, "val_loss": 17.313113808631897, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1057960987091, "training_acc": 53.0, "val_loss": 17.31186956167221, "val_acc": 52.0}
