"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15202951431274, "training_acc": 47.0, "val_loss": 17.43072122335434, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.82798051834106, "training_acc": 47.0, "val_loss": 17.393650114536285, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.65004324913025, "training_acc": 47.0, "val_loss": 17.357738316059113, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.49758791923523, "training_acc": 47.0, "val_loss": 17.33049899339676, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.41376900672913, "training_acc": 44.0, "val_loss": 17.314593493938446, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24644041061401, "training_acc": 53.0, "val_loss": 17.306573688983917, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18700861930847, "training_acc": 53.0, "val_loss": 17.303012311458588, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12543106079102, "training_acc": 53.0, "val_loss": 17.30334311723709, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11229348182678, "training_acc": 53.0, "val_loss": 17.306479811668396, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12379884719849, "training_acc": 53.0, "val_loss": 17.312797904014587, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14258980751038, "training_acc": 53.0, "val_loss": 17.31981486082077, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15794110298157, "training_acc": 53.0, "val_loss": 17.324401438236237, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16526889801025, "training_acc": 53.0, "val_loss": 17.325694859027863, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1863055229187, "training_acc": 53.0, "val_loss": 17.32531487941742, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16525959968567, "training_acc": 53.0, "val_loss": 17.325280606746674, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1526050567627, "training_acc": 53.0, "val_loss": 17.322492599487305, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19998502731323, "training_acc": 53.0, "val_loss": 17.31918454170227, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14365744590759, "training_acc": 53.0, "val_loss": 17.31908917427063, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14153981208801, "training_acc": 53.0, "val_loss": 17.316588759422302, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14449667930603, "training_acc": 53.0, "val_loss": 17.314045131206512, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11220169067383, "training_acc": 53.0, "val_loss": 17.313610017299652, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1262035369873, "training_acc": 53.0, "val_loss": 17.312881350517273, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13865637779236, "training_acc": 53.0, "val_loss": 17.312034964561462, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1303219795227, "training_acc": 53.0, "val_loss": 17.31022596359253, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13169598579407, "training_acc": 53.0, "val_loss": 17.309024930000305, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1310887336731, "training_acc": 53.0, "val_loss": 17.30913370847702, "val_acc": 52.0}
