"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23944115638733, "training_acc": 52.0, "val_loss": 17.24046617746353, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23547792434692, "training_acc": 52.0, "val_loss": 17.22189337015152, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25395941734314, "training_acc": 52.0, "val_loss": 17.22009778022766, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26379466056824, "training_acc": 52.0, "val_loss": 17.22959131002426, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24027967453003, "training_acc": 52.0, "val_loss": 17.24497228860855, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.225745677948, "training_acc": 52.0, "val_loss": 17.250551283359528, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25935482978821, "training_acc": 52.0, "val_loss": 17.2621950507164, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25810360908508, "training_acc": 52.0, "val_loss": 17.26735532283783, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27022385597229, "training_acc": 52.0, "val_loss": 17.262019217014313, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25622200965881, "training_acc": 52.0, "val_loss": 17.26512312889099, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23320031166077, "training_acc": 52.0, "val_loss": 17.26641356945038, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26366758346558, "training_acc": 52.0, "val_loss": 17.26333200931549, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.2336699962616, "training_acc": 52.0, "val_loss": 17.259417474269867, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.2394335269928, "training_acc": 52.0, "val_loss": 17.25822240114212, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2480058670044, "training_acc": 52.0, "val_loss": 17.251858115196228, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25154995918274, "training_acc": 52.0, "val_loss": 17.242667078971863, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25158047676086, "training_acc": 52.0, "val_loss": 17.22952574491501, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23335886001587, "training_acc": 52.0, "val_loss": 17.220798134803772, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24122500419617, "training_acc": 52.0, "val_loss": 17.214027047157288, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25796842575073, "training_acc": 52.0, "val_loss": 17.20920503139496, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2069776058197, "training_acc": 52.0, "val_loss": 17.20840185880661, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22778534889221, "training_acc": 52.0, "val_loss": 17.207248508930206, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28924512863159, "training_acc": 52.0, "val_loss": 17.20340847969055, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26206064224243, "training_acc": 52.0, "val_loss": 17.206716537475586, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25964426994324, "training_acc": 52.0, "val_loss": 17.213919758796692, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24951958656311, "training_acc": 52.0, "val_loss": 17.22467541694641, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27838182449341, "training_acc": 52.0, "val_loss": 17.22942292690277, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22722315788269, "training_acc": 52.0, "val_loss": 17.24393218755722, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24697232246399, "training_acc": 52.0, "val_loss": 17.25722998380661, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26122856140137, "training_acc": 52.0, "val_loss": 17.262104153633118, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27403688430786, "training_acc": 52.0, "val_loss": 17.260409891605377, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28065752983093, "training_acc": 52.0, "val_loss": 17.26669669151306, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24948000907898, "training_acc": 52.0, "val_loss": 17.261478304862976, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25714063644409, "training_acc": 52.0, "val_loss": 17.25671738386154, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25975918769836, "training_acc": 52.0, "val_loss": 17.24887490272522, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24029994010925, "training_acc": 52.0, "val_loss": 17.24439561367035, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23799872398376, "training_acc": 52.0, "val_loss": 17.239557206630707, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23761177062988, "training_acc": 52.0, "val_loss": 17.233775556087494, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22950029373169, "training_acc": 52.0, "val_loss": 17.22341626882553, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25030589103699, "training_acc": 52.0, "val_loss": 17.21007078886032, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23090076446533, "training_acc": 52.0, "val_loss": 17.204320430755615, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25593304634094, "training_acc": 52.0, "val_loss": 17.200683057308197, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26905798912048, "training_acc": 52.0, "val_loss": 17.19862073659897, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24037075042725, "training_acc": 52.0, "val_loss": 17.201052606105804, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25374412536621, "training_acc": 52.0, "val_loss": 17.210248112678528, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24168038368225, "training_acc": 52.0, "val_loss": 17.2174334526062, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25501561164856, "training_acc": 52.0, "val_loss": 17.226554453372955, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23847937583923, "training_acc": 52.0, "val_loss": 17.235811054706573, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22499775886536, "training_acc": 52.0, "val_loss": 17.239706218242645, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2316563129425, "training_acc": 52.0, "val_loss": 17.243123054504395, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2530403137207, "training_acc": 52.0, "val_loss": 17.249301075935364, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25102233886719, "training_acc": 52.0, "val_loss": 17.256061732769012, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25669240951538, "training_acc": 52.0, "val_loss": 17.26115196943283, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26591563224792, "training_acc": 52.0, "val_loss": 17.26641058921814, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22254967689514, "training_acc": 52.0, "val_loss": 17.26994663476944, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25724077224731, "training_acc": 52.0, "val_loss": 17.267663776874542, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.2479600906372, "training_acc": 52.0, "val_loss": 17.268146574497223, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24721646308899, "training_acc": 52.0, "val_loss": 17.26943403482437, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2381432056427, "training_acc": 52.0, "val_loss": 17.26556420326233, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26161646842957, "training_acc": 52.0, "val_loss": 17.261825501918793, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28121519088745, "training_acc": 52.0, "val_loss": 17.252689599990845, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24052023887634, "training_acc": 52.0, "val_loss": 17.248710989952087, "val_acc": 56.0}
