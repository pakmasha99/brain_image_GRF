"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.40020823478699, "training_acc": 47.0, "val_loss": 17.47821718454361, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.151118516922, "training_acc": 47.0, "val_loss": 17.416895925998688, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.77385830879211, "training_acc": 47.0, "val_loss": 17.376692593097687, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.53907704353333, "training_acc": 47.0, "val_loss": 17.347820103168488, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.50266742706299, "training_acc": 47.0, "val_loss": 17.325611412525177, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.28803992271423, "training_acc": 55.0, "val_loss": 17.31327623128891, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18562269210815, "training_acc": 53.0, "val_loss": 17.305979132652283, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18944644927979, "training_acc": 53.0, "val_loss": 17.302753031253815, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13623380661011, "training_acc": 53.0, "val_loss": 17.30385720729828, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17279052734375, "training_acc": 53.0, "val_loss": 17.30867177248001, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16144680976868, "training_acc": 53.0, "val_loss": 17.315322160720825, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13880586624146, "training_acc": 53.0, "val_loss": 17.322050034999847, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16875171661377, "training_acc": 53.0, "val_loss": 17.328299582004547, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15261149406433, "training_acc": 53.0, "val_loss": 17.33250319957733, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17186093330383, "training_acc": 53.0, "val_loss": 17.335616052150726, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2116072177887, "training_acc": 53.0, "val_loss": 17.33945608139038, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20841670036316, "training_acc": 53.0, "val_loss": 17.340382933616638, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20775604248047, "training_acc": 53.0, "val_loss": 17.34144240617752, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2046856880188, "training_acc": 53.0, "val_loss": 17.339004576206207, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21191716194153, "training_acc": 53.0, "val_loss": 17.331695556640625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18426489830017, "training_acc": 53.0, "val_loss": 17.325560748577118, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22499394416809, "training_acc": 53.0, "val_loss": 17.319557070732117, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16596984863281, "training_acc": 53.0, "val_loss": 17.31746643781662, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18877339363098, "training_acc": 53.0, "val_loss": 17.31528788805008, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15120124816895, "training_acc": 53.0, "val_loss": 17.31353849172592, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15529561042786, "training_acc": 53.0, "val_loss": 17.31313318014145, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13245010375977, "training_acc": 53.0, "val_loss": 17.311376333236694, "val_acc": 52.0}
