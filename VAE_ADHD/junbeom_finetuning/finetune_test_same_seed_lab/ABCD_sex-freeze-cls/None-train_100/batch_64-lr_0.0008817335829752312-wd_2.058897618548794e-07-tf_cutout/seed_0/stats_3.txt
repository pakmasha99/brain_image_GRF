"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.40946745872498, "training_acc": 53.0, "val_loss": 17.404931783676147, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.99020314216614, "training_acc": 53.0, "val_loss": 17.38712638616562, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.58847236633301, "training_acc": 47.0, "val_loss": 17.48485118150711, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.0551028251648, "training_acc": 47.0, "val_loss": 17.366398870944977, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30552411079407, "training_acc": 51.0, "val_loss": 17.334605753421783, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16822457313538, "training_acc": 53.0, "val_loss": 17.514385282993317, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.91310167312622, "training_acc": 53.0, "val_loss": 17.51106232404709, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.5730631351471, "training_acc": 53.0, "val_loss": 17.325080931186676, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16185736656189, "training_acc": 53.0, "val_loss": 17.335087060928345, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.3656735420227, "training_acc": 47.0, "val_loss": 17.376302182674408, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.55948758125305, "training_acc": 47.0, "val_loss": 17.33265072107315, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.36027145385742, "training_acc": 47.0, "val_loss": 17.307059466838837, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.94310569763184, "training_acc": 53.0, "val_loss": 17.410525679588318, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.62496757507324, "training_acc": 53.0, "val_loss": 17.566725611686707, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.13801264762878, "training_acc": 53.0, "val_loss": 17.477256059646606, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29423499107361, "training_acc": 53.0, "val_loss": 17.308738827705383, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.60667729377747, "training_acc": 45.0, "val_loss": 17.391681671142578, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.79846501350403, "training_acc": 47.0, "val_loss": 17.40768253803253, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.6297492980957, "training_acc": 47.0, "val_loss": 17.318740487098694, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10297203063965, "training_acc": 53.0, "val_loss": 17.329026758670807, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.41318607330322, "training_acc": 53.0, "val_loss": 17.439863085746765, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.80721282958984, "training_acc": 53.0, "val_loss": 17.433318495750427, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.42816090583801, "training_acc": 53.0, "val_loss": 17.317260801792145, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12681174278259, "training_acc": 53.0, "val_loss": 17.317679524421692, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21798419952393, "training_acc": 54.0, "val_loss": 17.343193292617798, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.43570351600647, "training_acc": 47.0, "val_loss": 17.340774834156036, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.30978846549988, "training_acc": 49.0, "val_loss": 17.308232188224792, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.04859495162964, "training_acc": 53.0, "val_loss": 17.341531813144684, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.2245979309082, "training_acc": 53.0, "val_loss": 17.43234246969223, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.505366563797, "training_acc": 53.0, "val_loss": 17.429420351982117, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.36058282852173, "training_acc": 53.0, "val_loss": 17.340129613876343, "val_acc": 52.0}
