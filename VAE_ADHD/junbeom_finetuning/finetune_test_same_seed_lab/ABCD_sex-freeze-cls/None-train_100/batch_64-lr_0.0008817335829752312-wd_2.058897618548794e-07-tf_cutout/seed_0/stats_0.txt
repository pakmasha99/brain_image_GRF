"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.95750498771667, "training_acc": 50.0, "val_loss": 17.370933294296265, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.6405189037323, "training_acc": 48.0, "val_loss": 17.174525558948517, "val_acc": 56.0}
{"epoch": 2, "training_loss": 70.10186910629272, "training_acc": 52.0, "val_loss": 17.148074507713318, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.23268437385559, "training_acc": 52.0, "val_loss": 17.408721148967743, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.64889407157898, "training_acc": 48.0, "val_loss": 17.713968455791473, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.13508725166321, "training_acc": 48.0, "val_loss": 17.46954321861267, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.47905850410461, "training_acc": 48.0, "val_loss": 17.245319485664368, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.172358751297, "training_acc": 52.0, "val_loss": 17.153114080429077, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.87141513824463, "training_acc": 52.0, "val_loss": 17.14772880077362, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.50467371940613, "training_acc": 52.0, "val_loss": 17.197193205356598, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.26181030273438, "training_acc": 52.0, "val_loss": 17.37784892320633, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.41063809394836, "training_acc": 48.0, "val_loss": 17.462818324565887, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.5332179069519, "training_acc": 48.0, "val_loss": 17.377078533172607, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.33151340484619, "training_acc": 49.0, "val_loss": 17.26406067609787, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.19125390052795, "training_acc": 52.0, "val_loss": 17.17078685760498, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.29165863990784, "training_acc": 52.0, "val_loss": 17.14947521686554, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.53085064888, "training_acc": 52.0, "val_loss": 17.149116098880768, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.44699096679688, "training_acc": 52.0, "val_loss": 17.194414138793945, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.27055859565735, "training_acc": 52.0, "val_loss": 17.308631539344788, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.30133938789368, "training_acc": 52.0, "val_loss": 17.367351055145264, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.35758233070374, "training_acc": 48.0, "val_loss": 17.326220870018005, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22557091712952, "training_acc": 54.0, "val_loss": 17.209307849407196, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.59556865692139, "training_acc": 52.0, "val_loss": 17.15182512998581, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.465252161026, "training_acc": 52.0, "val_loss": 17.17049777507782, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.231271982193, "training_acc": 52.0, "val_loss": 17.283625900745392, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.42502665519714, "training_acc": 48.0, "val_loss": 17.446112632751465, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.85078692436218, "training_acc": 42.0, "val_loss": 17.38124042749405, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.3854672908783, "training_acc": 48.0, "val_loss": 17.38428771495819, "val_acc": 56.0}
