"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.3707275390625, "training_acc": 47.0, "val_loss": 17.460280656814575, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.08296155929565, "training_acc": 47.0, "val_loss": 17.392253875732422, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.66002225875854, "training_acc": 47.0, "val_loss": 17.35212355852127, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.41082811355591, "training_acc": 47.0, "val_loss": 17.326731979846954, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.40361166000366, "training_acc": 39.0, "val_loss": 17.31017976999283, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19460105895996, "training_acc": 53.0, "val_loss": 17.30397343635559, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11761784553528, "training_acc": 53.0, "val_loss": 17.302748560905457, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14558053016663, "training_acc": 53.0, "val_loss": 17.3059344291687, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11895442008972, "training_acc": 53.0, "val_loss": 17.312641441822052, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17684698104858, "training_acc": 53.0, "val_loss": 17.322249710559845, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18408250808716, "training_acc": 53.0, "val_loss": 17.331263422966003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17506837844849, "training_acc": 53.0, "val_loss": 17.33778268098831, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20529246330261, "training_acc": 53.0, "val_loss": 17.34199821949005, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19161629676819, "training_acc": 53.0, "val_loss": 17.34248250722885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20925378799438, "training_acc": 53.0, "val_loss": 17.34168529510498, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22534322738647, "training_acc": 53.0, "val_loss": 17.342248558998108, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22262120246887, "training_acc": 53.0, "val_loss": 17.33964830636978, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20114827156067, "training_acc": 53.0, "val_loss": 17.337986826896667, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18795275688171, "training_acc": 53.0, "val_loss": 17.333123087882996, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19880032539368, "training_acc": 53.0, "val_loss": 17.32390522956848, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.164466381073, "training_acc": 53.0, "val_loss": 17.317146062850952, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22399187088013, "training_acc": 53.0, "val_loss": 17.3115074634552, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1535370349884, "training_acc": 53.0, "val_loss": 17.310020327568054, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17865943908691, "training_acc": 53.0, "val_loss": 17.308707535266876, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14361834526062, "training_acc": 53.0, "val_loss": 17.30789691209793, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15553212165833, "training_acc": 53.0, "val_loss": 17.308323085308075, "val_acc": 52.0}
