"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2427864074707, "training_acc": 52.0, "val_loss": 17.243139445781708, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23960280418396, "training_acc": 52.0, "val_loss": 17.219117283821106, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25866436958313, "training_acc": 52.0, "val_loss": 17.21702516078949, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26359105110168, "training_acc": 52.0, "val_loss": 17.229121923446655, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24098467826843, "training_acc": 52.0, "val_loss": 17.2484889626503, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22781276702881, "training_acc": 52.0, "val_loss": 17.255470156669617, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26258420944214, "training_acc": 52.0, "val_loss": 17.269320785999298, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26400876045227, "training_acc": 52.0, "val_loss": 17.27430373430252, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.2823269367218, "training_acc": 52.0, "val_loss": 17.26613938808441, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25908374786377, "training_acc": 52.0, "val_loss": 17.268386483192444, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23524641990662, "training_acc": 52.0, "val_loss": 17.268352210521698, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26540017127991, "training_acc": 52.0, "val_loss": 17.26311445236206, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23535513877869, "training_acc": 52.0, "val_loss": 17.257270216941833, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23806357383728, "training_acc": 52.0, "val_loss": 17.25514382123947, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24572324752808, "training_acc": 52.0, "val_loss": 17.24729835987091, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24887800216675, "training_acc": 52.0, "val_loss": 17.236635088920593, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25130915641785, "training_acc": 52.0, "val_loss": 17.221976816654205, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23418378829956, "training_acc": 52.0, "val_loss": 17.21312254667282, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24398159980774, "training_acc": 52.0, "val_loss": 17.20699965953827, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26182103157043, "training_acc": 52.0, "val_loss": 17.20343381166458, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21255707740784, "training_acc": 52.0, "val_loss": 17.204661667346954, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23375487327576, "training_acc": 52.0, "val_loss": 17.20537692308426, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.2911102771759, "training_acc": 52.0, "val_loss": 17.202569544315338, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26093459129333, "training_acc": 52.0, "val_loss": 17.208129167556763, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25637793540955, "training_acc": 52.0, "val_loss": 17.218276858329773, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25076675415039, "training_acc": 52.0, "val_loss": 17.232513427734375, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28193402290344, "training_acc": 52.0, "val_loss": 17.238473892211914, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22807908058167, "training_acc": 52.0, "val_loss": 17.25630760192871, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25638508796692, "training_acc": 52.0, "val_loss": 17.27175861597061, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2708089351654, "training_acc": 52.0, "val_loss": 17.27537512779236, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.29293823242188, "training_acc": 52.0, "val_loss": 17.270217835903168, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.2889564037323, "training_acc": 52.0, "val_loss": 17.27515161037445, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25620746612549, "training_acc": 52.0, "val_loss": 17.265674471855164, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25760269165039, "training_acc": 52.0, "val_loss": 17.2572061419487, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26295971870422, "training_acc": 52.0, "val_loss": 17.2456756234169, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23853707313538, "training_acc": 52.0, "val_loss": 17.23896414041519, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23549199104309, "training_acc": 52.0, "val_loss": 17.232556641101837, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23667192459106, "training_acc": 52.0, "val_loss": 17.225728929042816, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22843527793884, "training_acc": 52.0, "val_loss": 17.214232683181763, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25875425338745, "training_acc": 52.0, "val_loss": 17.20002293586731, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23887848854065, "training_acc": 52.0, "val_loss": 17.19489097595215, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2654275894165, "training_acc": 52.0, "val_loss": 17.192432284355164, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27793860435486, "training_acc": 52.0, "val_loss": 17.191913723945618, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24505734443665, "training_acc": 52.0, "val_loss": 17.19660460948944, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26060390472412, "training_acc": 52.0, "val_loss": 17.20946431159973, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23892259597778, "training_acc": 52.0, "val_loss": 17.220064997673035, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25285243988037, "training_acc": 52.0, "val_loss": 17.232908308506012, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24344444274902, "training_acc": 52.0, "val_loss": 17.245502769947052, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22737979888916, "training_acc": 52.0, "val_loss": 17.250534892082214, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23605346679688, "training_acc": 52.0, "val_loss": 17.254237830638885, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25770616531372, "training_acc": 52.0, "val_loss": 17.260850965976715, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25716090202332, "training_acc": 52.0, "val_loss": 17.267611622810364, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.2646837234497, "training_acc": 52.0, "val_loss": 17.271743714809418, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27320218086243, "training_acc": 52.0, "val_loss": 17.275722324848175, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22888684272766, "training_acc": 52.0, "val_loss": 17.277316749095917, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26692628860474, "training_acc": 52.0, "val_loss": 17.271706461906433, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25248694419861, "training_acc": 52.0, "val_loss": 17.269830405712128, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24745750427246, "training_acc": 52.0, "val_loss": 17.269285023212433, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2383325099945, "training_acc": 52.0, "val_loss": 17.262928187847137, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25850629806519, "training_acc": 52.0, "val_loss": 17.257297039031982, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28283929824829, "training_acc": 52.0, "val_loss": 17.24589765071869, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23733758926392, "training_acc": 52.0, "val_loss": 17.241233587265015, "val_acc": 56.0}
