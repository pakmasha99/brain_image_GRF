"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 101.68087816238403, "training_acc": 53.0, "val_loss": 19.73067820072174, "val_acc": 52.0}
{"epoch": 1, "training_loss": 98.52929496765137, "training_acc": 45.0, "val_loss": 29.76386845111847, "val_acc": 48.0}
{"epoch": 2, "training_loss": 109.10698413848877, "training_acc": 47.0, "val_loss": 17.315737903118134, "val_acc": 52.0}
{"epoch": 3, "training_loss": 73.90036344528198, "training_acc": 53.0, "val_loss": 25.967642664909363, "val_acc": 52.0}
{"epoch": 4, "training_loss": 100.07499027252197, "training_acc": 53.0, "val_loss": 20.157060027122498, "val_acc": 52.0}
{"epoch": 5, "training_loss": 74.17360234260559, "training_acc": 53.0, "val_loss": 18.869774043560028, "val_acc": 48.0}
{"epoch": 6, "training_loss": 80.8401370048523, "training_acc": 47.0, "val_loss": 21.30815088748932, "val_acc": 48.0}
{"epoch": 7, "training_loss": 81.8997893333435, "training_acc": 47.0, "val_loss": 17.31177121400833, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.11564636230469, "training_acc": 53.0, "val_loss": 20.754562318325043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 81.35705280303955, "training_acc": 53.0, "val_loss": 18.82377415895462, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.21581196784973, "training_acc": 53.0, "val_loss": 17.607708275318146, "val_acc": 52.0}
{"epoch": 11, "training_loss": 72.35557675361633, "training_acc": 47.0, "val_loss": 18.940483033657074, "val_acc": 48.0}
{"epoch": 12, "training_loss": 75.00139713287354, "training_acc": 47.0, "val_loss": 17.32345223426819, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.31419014930725, "training_acc": 54.0, "val_loss": 18.592633306980133, "val_acc": 52.0}
{"epoch": 14, "training_loss": 73.9157383441925, "training_acc": 53.0, "val_loss": 17.77469962835312, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.67897439002991, "training_acc": 53.0, "val_loss": 17.756710946559906, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.83377242088318, "training_acc": 47.0, "val_loss": 17.964908480644226, "val_acc": 52.0}
{"epoch": 17, "training_loss": 71.61322379112244, "training_acc": 47.0, "val_loss": 17.49456375837326, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.30759692192078, "training_acc": 53.0, "val_loss": 18.055760860443115, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.13552570343018, "training_acc": 53.0, "val_loss": 17.318052053451538, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.09209108352661, "training_acc": 53.0, "val_loss": 17.66328513622284, "val_acc": 52.0}
{"epoch": 21, "training_loss": 71.14243531227112, "training_acc": 47.0, "val_loss": 17.35471487045288, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.82935047149658, "training_acc": 47.0, "val_loss": 17.751877009868622, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.54997253417969, "training_acc": 53.0, "val_loss": 17.467403411865234, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.67257022857666, "training_acc": 53.0, "val_loss": 17.408248782157898, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.74735188484192, "training_acc": 47.0, "val_loss": 17.36120879650116, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.5508303642273, "training_acc": 47.0, "val_loss": 17.354488372802734, "val_acc": 52.0}
