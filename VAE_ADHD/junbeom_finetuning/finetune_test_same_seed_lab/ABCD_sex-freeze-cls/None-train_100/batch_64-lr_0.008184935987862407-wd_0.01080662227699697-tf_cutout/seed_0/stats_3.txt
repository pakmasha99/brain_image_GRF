"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 113.1678295135498, "training_acc": 53.0, "val_loss": 20.92042714357376, "val_acc": 52.0}
{"epoch": 1, "training_loss": 81.76202821731567, "training_acc": 55.0, "val_loss": 32.65621364116669, "val_acc": 48.0}
{"epoch": 2, "training_loss": 126.20460820198059, "training_acc": 47.0, "val_loss": 18.94155591726303, "val_acc": 48.0}
{"epoch": 3, "training_loss": 73.88237476348877, "training_acc": 51.0, "val_loss": 23.8184854388237, "val_acc": 52.0}
{"epoch": 4, "training_loss": 95.58638119697571, "training_acc": 53.0, "val_loss": 22.369325160980225, "val_acc": 52.0}
{"epoch": 5, "training_loss": 83.01248049736023, "training_acc": 53.0, "val_loss": 17.70949512720108, "val_acc": 52.0}
{"epoch": 6, "training_loss": 73.3077142238617, "training_acc": 47.0, "val_loss": 21.22074067592621, "val_acc": 48.0}
{"epoch": 7, "training_loss": 83.73184156417847, "training_acc": 47.0, "val_loss": 17.630264163017273, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.64325332641602, "training_acc": 49.0, "val_loss": 19.31212544441223, "val_acc": 52.0}
{"epoch": 9, "training_loss": 77.72121834754944, "training_acc": 53.0, "val_loss": 19.005142152309418, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.8306052684784, "training_acc": 53.0, "val_loss": 17.51098334789276, "val_acc": 52.0}
{"epoch": 11, "training_loss": 75.24117136001587, "training_acc": 47.0, "val_loss": 18.797984719276428, "val_acc": 48.0}
{"epoch": 12, "training_loss": 73.53522109985352, "training_acc": 47.0, "val_loss": 17.36442595720291, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.27591705322266, "training_acc": 53.0, "val_loss": 19.254329800605774, "val_acc": 52.0}
{"epoch": 14, "training_loss": 76.12825798988342, "training_acc": 53.0, "val_loss": 17.585955560207367, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.87946796417236, "training_acc": 55.0, "val_loss": 18.67658793926239, "val_acc": 48.0}
{"epoch": 16, "training_loss": 77.33921766281128, "training_acc": 47.0, "val_loss": 18.33612024784088, "val_acc": 52.0}
{"epoch": 17, "training_loss": 71.34452700614929, "training_acc": 47.0, "val_loss": 17.960521578788757, "val_acc": 52.0}
{"epoch": 18, "training_loss": 73.09966588020325, "training_acc": 53.0, "val_loss": 19.385769963264465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 75.4814624786377, "training_acc": 53.0, "val_loss": 17.337344586849213, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.80340766906738, "training_acc": 55.0, "val_loss": 18.145857751369476, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.08448910713196, "training_acc": 47.0, "val_loss": 17.698532342910767, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.36278128623962, "training_acc": 47.0, "val_loss": 17.37227588891983, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.73397183418274, "training_acc": 53.0, "val_loss": 17.908912897109985, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.7739737033844, "training_acc": 53.0, "val_loss": 17.32451170682907, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.80273389816284, "training_acc": 49.0, "val_loss": 17.712874710559845, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.96997213363647, "training_acc": 47.0, "val_loss": 17.31264442205429, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.81166338920593, "training_acc": 53.0, "val_loss": 17.950977385044098, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.37854504585266, "training_acc": 53.0, "val_loss": 17.60668158531189, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.4283812046051, "training_acc": 53.0, "val_loss": 17.499282956123352, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.21697735786438, "training_acc": 47.0, "val_loss": 17.61685162782669, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.24221420288086, "training_acc": 47.0, "val_loss": 17.370329797267914, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.34415221214294, "training_acc": 53.0, "val_loss": 18.033963441848755, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.95645904541016, "training_acc": 53.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.85608768463135, "training_acc": 45.0, "val_loss": 17.582614719867706, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.10192513465881, "training_acc": 49.0, "val_loss": 17.421764135360718, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.38497948646545, "training_acc": 53.0, "val_loss": 17.702555656433105, "val_acc": 52.0}
{"epoch": 37, "training_loss": 70.14347243309021, "training_acc": 53.0, "val_loss": 17.317290604114532, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.0074257850647, "training_acc": 53.0, "val_loss": 17.573168873786926, "val_acc": 52.0}
{"epoch": 39, "training_loss": 71.15057682991028, "training_acc": 47.0, "val_loss": 17.507432401180267, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.32035565376282, "training_acc": 53.0, "val_loss": 17.734454572200775, "val_acc": 52.0}
{"epoch": 41, "training_loss": 74.26636624336243, "training_acc": 53.0, "val_loss": 17.67577826976776, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.00745725631714, "training_acc": 55.0, "val_loss": 18.254749476909637, "val_acc": 52.0}
{"epoch": 43, "training_loss": 74.28130078315735, "training_acc": 47.0, "val_loss": 17.688468098640442, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.41868329048157, "training_acc": 49.0, "val_loss": 18.22849065065384, "val_acc": 52.0}
{"epoch": 45, "training_loss": 72.23768544197083, "training_acc": 53.0, "val_loss": 17.93065220117569, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.67011594772339, "training_acc": 53.0, "val_loss": 17.449919879436493, "val_acc": 52.0}
{"epoch": 47, "training_loss": 72.94008040428162, "training_acc": 47.0, "val_loss": 18.4574156999588, "val_acc": 48.0}
{"epoch": 48, "training_loss": 74.78930187225342, "training_acc": 41.0, "val_loss": 17.50965416431427, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.87355899810791, "training_acc": 53.0, "val_loss": 17.73524582386017, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.9575023651123, "training_acc": 53.0, "val_loss": 17.331504821777344, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.72175359725952, "training_acc": 46.0, "val_loss": 17.572417855262756, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.99265003204346, "training_acc": 47.0, "val_loss": 17.40025281906128, "val_acc": 52.0}
