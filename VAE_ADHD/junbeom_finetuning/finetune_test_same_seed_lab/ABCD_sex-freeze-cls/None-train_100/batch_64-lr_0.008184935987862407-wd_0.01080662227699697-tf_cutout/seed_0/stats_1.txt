"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 103.76948928833008, "training_acc": 49.0, "val_loss": 20.355841517448425, "val_acc": 52.0}
{"epoch": 1, "training_loss": 84.06446123123169, "training_acc": 53.0, "val_loss": 30.507653951644897, "val_acc": 48.0}
{"epoch": 2, "training_loss": 114.52263498306274, "training_acc": 47.0, "val_loss": 17.49487668275833, "val_acc": 52.0}
{"epoch": 3, "training_loss": 76.26805925369263, "training_acc": 47.0, "val_loss": 25.527524948120117, "val_acc": 52.0}
{"epoch": 4, "training_loss": 98.80243229866028, "training_acc": 53.0, "val_loss": 20.109708607196808, "val_acc": 52.0}
{"epoch": 5, "training_loss": 76.56866812705994, "training_acc": 53.0, "val_loss": 19.010666012763977, "val_acc": 48.0}
{"epoch": 6, "training_loss": 82.02544355392456, "training_acc": 47.0, "val_loss": 20.4550638794899, "val_acc": 48.0}
{"epoch": 7, "training_loss": 79.53099036216736, "training_acc": 47.0, "val_loss": 17.451997101306915, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72.30432176589966, "training_acc": 53.0, "val_loss": 20.026519894599915, "val_acc": 52.0}
{"epoch": 9, "training_loss": 78.65963864326477, "training_acc": 53.0, "val_loss": 17.84074306488037, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.60412812232971, "training_acc": 53.0, "val_loss": 17.612528800964355, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.87360119819641, "training_acc": 47.0, "val_loss": 17.787307500839233, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.0560998916626, "training_acc": 47.0, "val_loss": 17.42521822452545, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.95169067382812, "training_acc": 53.0, "val_loss": 17.81105250120163, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.37440013885498, "training_acc": 53.0, "val_loss": 17.331691086292267, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.81621956825256, "training_acc": 48.0, "val_loss": 18.31154227256775, "val_acc": 52.0}
{"epoch": 16, "training_loss": 73.22517895698547, "training_acc": 47.0, "val_loss": 17.385701835155487, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.6041328907013, "training_acc": 49.0, "val_loss": 17.957934737205505, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.4996325969696, "training_acc": 53.0, "val_loss": 17.716437578201294, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.2199387550354, "training_acc": 53.0, "val_loss": 17.410606145858765, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.54654002189636, "training_acc": 47.0, "val_loss": 17.48289316892624, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.57723927497864, "training_acc": 51.0, "val_loss": 17.483070492744446, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.62357449531555, "training_acc": 53.0, "val_loss": 17.764808237552643, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.63267374038696, "training_acc": 53.0, "val_loss": 17.311324179172516, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.94604802131653, "training_acc": 55.0, "val_loss": 17.96882450580597, "val_acc": 52.0}
{"epoch": 25, "training_loss": 72.58615612983704, "training_acc": 47.0, "val_loss": 17.360225319862366, "val_acc": 52.0}
{"epoch": 26, "training_loss": 72.23220562934875, "training_acc": 41.0, "val_loss": 18.112224340438843, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.43281102180481, "training_acc": 53.0, "val_loss": 17.338496446609497, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.08542370796204, "training_acc": 43.0, "val_loss": 17.493201792240143, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.67493557929993, "training_acc": 47.0, "val_loss": 17.39620417356491, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1764497756958, "training_acc": 53.0, "val_loss": 17.865337431430817, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.76789212226868, "training_acc": 53.0, "val_loss": 17.37813502550125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.29307222366333, "training_acc": 51.0, "val_loss": 17.528964579105377, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.35297107696533, "training_acc": 47.0, "val_loss": 17.325904965400696, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.33882856369019, "training_acc": 53.0, "val_loss": 17.642749845981598, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.14690375328064, "training_acc": 53.0, "val_loss": 17.404823005199432, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.40419602394104, "training_acc": 43.0, "val_loss": 17.313528060913086, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18855023384094, "training_acc": 53.0, "val_loss": 17.375531792640686, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.48522853851318, "training_acc": 53.0, "val_loss": 17.36976057291031, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.6027762889862, "training_acc": 53.0, "val_loss": 17.336109280586243, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.28203964233398, "training_acc": 53.0, "val_loss": 17.48688966035843, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.88125610351562, "training_acc": 47.0, "val_loss": 17.53747910261154, "val_acc": 52.0}
{"epoch": 42, "training_loss": 70.28529381752014, "training_acc": 47.0, "val_loss": 17.607492208480835, "val_acc": 52.0}
