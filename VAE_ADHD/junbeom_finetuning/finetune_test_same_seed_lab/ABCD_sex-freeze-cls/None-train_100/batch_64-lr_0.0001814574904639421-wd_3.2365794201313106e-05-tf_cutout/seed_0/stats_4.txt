"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.46027135848999, "training_acc": 47.0, "val_loss": 17.715121805667877, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.71701860427856, "training_acc": 47.0, "val_loss": 17.45593100786209, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.6628155708313, "training_acc": 47.0, "val_loss": 17.32911467552185, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09996843338013, "training_acc": 55.0, "val_loss": 17.30809509754181, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07658267021179, "training_acc": 53.0, "val_loss": 17.35699474811554, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.3754506111145, "training_acc": 53.0, "val_loss": 17.43319034576416, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.50224423408508, "training_acc": 53.0, "val_loss": 17.481036484241486, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.6283860206604, "training_acc": 53.0, "val_loss": 17.49180555343628, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.6955726146698, "training_acc": 53.0, "val_loss": 17.472727596759796, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.56188559532166, "training_acc": 53.0, "val_loss": 17.442868649959564, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4632716178894, "training_acc": 53.0, "val_loss": 17.39780753850937, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.30215787887573, "training_acc": 53.0, "val_loss": 17.356418073177338, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22773933410645, "training_acc": 53.0, "val_loss": 17.323802411556244, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.211177110672, "training_acc": 53.0, "val_loss": 17.308279871940613, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14218091964722, "training_acc": 53.0, "val_loss": 17.305301129817963, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12876558303833, "training_acc": 53.0, "val_loss": 17.30593889951706, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22968339920044, "training_acc": 53.0, "val_loss": 17.30787754058838, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2307825088501, "training_acc": 53.0, "val_loss": 17.30671226978302, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16063594818115, "training_acc": 53.0, "val_loss": 17.306575179100037, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1964704990387, "training_acc": 53.0, "val_loss": 17.305612564086914, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1570975780487, "training_acc": 53.0, "val_loss": 17.305362224578857, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1804141998291, "training_acc": 53.0, "val_loss": 17.305301129817963, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14721322059631, "training_acc": 53.0, "val_loss": 17.305922508239746, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24626898765564, "training_acc": 53.0, "val_loss": 17.309485375881195, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14612293243408, "training_acc": 53.0, "val_loss": 17.310377955436707, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12944555282593, "training_acc": 53.0, "val_loss": 17.314355075359344, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15833449363708, "training_acc": 53.0, "val_loss": 17.317713797092438, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13357353210449, "training_acc": 53.0, "val_loss": 17.321783304214478, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13885545730591, "training_acc": 53.0, "val_loss": 17.329303920269012, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17760419845581, "training_acc": 53.0, "val_loss": 17.33480840921402, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1594295501709, "training_acc": 53.0, "val_loss": 17.339402437210083, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20220136642456, "training_acc": 53.0, "val_loss": 17.336852848529816, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18513059616089, "training_acc": 53.0, "val_loss": 17.330804467201233, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19650101661682, "training_acc": 53.0, "val_loss": 17.324770987033844, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13443160057068, "training_acc": 53.0, "val_loss": 17.320959270000458, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13882231712341, "training_acc": 53.0, "val_loss": 17.317870259284973, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12505459785461, "training_acc": 53.0, "val_loss": 17.314505577087402, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14475274085999, "training_acc": 53.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1260347366333, "training_acc": 53.0, "val_loss": 17.31068342924118, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13495588302612, "training_acc": 53.0, "val_loss": 17.309269309043884, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13020825386047, "training_acc": 53.0, "val_loss": 17.308935523033142, "val_acc": 52.0}
