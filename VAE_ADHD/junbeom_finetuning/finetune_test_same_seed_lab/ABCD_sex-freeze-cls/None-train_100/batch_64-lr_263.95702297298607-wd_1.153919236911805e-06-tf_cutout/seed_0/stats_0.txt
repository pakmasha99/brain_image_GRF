"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1925096.4079208374, "training_acc": 50.0, "val_loss": 490420.41015625, "val_acc": 44.0}
{"epoch": 1, "training_loss": 2034422.125, "training_acc": 48.0, "val_loss": 777688.232421875, "val_acc": 56.0}
{"epoch": 2, "training_loss": 3220292.671875, "training_acc": 52.0, "val_loss": 367339.35546875, "val_acc": 56.0}
{"epoch": 3, "training_loss": 1128488.615234375, "training_acc": 54.0, "val_loss": 380737.6220703125, "val_acc": 44.0}
{"epoch": 4, "training_loss": 1346380.24609375, "training_acc": 48.0, "val_loss": 40589.02282714844, "val_acc": 44.0}
{"epoch": 5, "training_loss": 730765.5859375, "training_acc": 44.0, "val_loss": 494589.84375, "val_acc": 56.0}
{"epoch": 6, "training_loss": 2100391.2578125, "training_acc": 52.0, "val_loss": 313858.9111328125, "val_acc": 56.0}
{"epoch": 7, "training_loss": 947144.1313476562, "training_acc": 52.0, "val_loss": 432038.037109375, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1838420.1171875, "training_acc": 48.0, "val_loss": 687778.369140625, "val_acc": 44.0}
{"epoch": 9, "training_loss": 2390478.3984375, "training_acc": 48.0, "val_loss": 266076.0009765625, "val_acc": 44.0}
{"epoch": 10, "training_loss": 811866.6953125, "training_acc": 50.0, "val_loss": 297157.03125, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1345447.3125, "training_acc": 52.0, "val_loss": 248916.7236328125, "val_acc": 56.0}
{"epoch": 12, "training_loss": 748311.7626953125, "training_acc": 52.0, "val_loss": 302205.4931640625, "val_acc": 44.0}
{"epoch": 13, "training_loss": 1387459.671875, "training_acc": 48.0, "val_loss": 478632.763671875, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1562695.0234375, "training_acc": 48.0, "val_loss": 19774.557495117188, "val_acc": 44.0}
{"epoch": 15, "training_loss": 466905.609375, "training_acc": 54.0, "val_loss": 516443.798828125, "val_acc": 56.0}
{"epoch": 16, "training_loss": 2339284.8359375, "training_acc": 52.0, "val_loss": 532573.6328125, "val_acc": 56.0}
{"epoch": 17, "training_loss": 2048611.9921875, "training_acc": 52.0, "val_loss": 115947.5341796875, "val_acc": 56.0}
{"epoch": 18, "training_loss": 709467.796875, "training_acc": 50.0, "val_loss": 515976.3671875, "val_acc": 44.0}
{"epoch": 19, "training_loss": 1989530.21875, "training_acc": 48.0, "val_loss": 471880.76171875, "val_acc": 44.0}
{"epoch": 20, "training_loss": 1423321.2578125, "training_acc": 48.0, "val_loss": 101937.90283203125, "val_acc": 56.0}
{"epoch": 21, "training_loss": 635109.83203125, "training_acc": 52.0, "val_loss": 283123.974609375, "val_acc": 56.0}
{"epoch": 22, "training_loss": 1097579.14453125, "training_acc": 52.0, "val_loss": 27141.56494140625, "val_acc": 56.0}
{"epoch": 23, "training_loss": 447548.68359375, "training_acc": 54.0, "val_loss": 480892.236328125, "val_acc": 44.0}
{"epoch": 24, "training_loss": 1788963.55078125, "training_acc": 48.0, "val_loss": 339392.7490234375, "val_acc": 44.0}
{"epoch": 25, "training_loss": 878633.763671875, "training_acc": 48.0, "val_loss": 261828.9794921875, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1535365.3046875, "training_acc": 52.0, "val_loss": 492851.46484375, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1999932.1328125, "training_acc": 52.0, "val_loss": 233877.6123046875, "val_acc": 56.0}
{"epoch": 28, "training_loss": 783395.400390625, "training_acc": 46.0, "val_loss": 210233.0810546875, "val_acc": 44.0}
{"epoch": 29, "training_loss": 770920.09765625, "training_acc": 48.0, "val_loss": 40165.521240234375, "val_acc": 44.0}
{"epoch": 30, "training_loss": 536268.015625, "training_acc": 40.0, "val_loss": 306513.76953125, "val_acc": 56.0}
{"epoch": 31, "training_loss": 1270651.671875, "training_acc": 52.0, "val_loss": 144440.6494140625, "val_acc": 56.0}
{"epoch": 32, "training_loss": 496931.8564453125, "training_acc": 52.0, "val_loss": 184445.8740234375, "val_acc": 44.0}
{"epoch": 33, "training_loss": 609485.861328125, "training_acc": 48.0, "val_loss": 57170.404052734375, "val_acc": 56.0}
