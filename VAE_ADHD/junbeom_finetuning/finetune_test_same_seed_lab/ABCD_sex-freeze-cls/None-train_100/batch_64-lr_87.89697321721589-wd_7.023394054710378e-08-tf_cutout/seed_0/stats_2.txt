"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 828329.2002563477, "training_acc": 45.0, "val_loss": 150048.486328125, "val_acc": 48.0}
{"epoch": 1, "training_loss": 562772.166015625, "training_acc": 59.0, "val_loss": 397594.921875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1538011.76953125, "training_acc": 53.0, "val_loss": 292764.4287109375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 932285.615234375, "training_acc": 53.0, "val_loss": 87416.33911132812, "val_acc": 48.0}
{"epoch": 4, "training_loss": 470363.525390625, "training_acc": 47.0, "val_loss": 170062.1826171875, "val_acc": 48.0}
{"epoch": 5, "training_loss": 559315.4453125, "training_acc": 47.0, "val_loss": 58447.314453125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 326993.240234375, "training_acc": 53.0, "val_loss": 118675.86669921875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 387718.86865234375, "training_acc": 53.0, "val_loss": 56059.99755859375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 288353.869140625, "training_acc": 47.0, "val_loss": 55300.13427734375, "val_acc": 48.0}
{"epoch": 9, "training_loss": 187799.033203125, "training_acc": 51.0, "val_loss": 64990.34423828125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 221574.15625, "training_acc": 53.0, "val_loss": 31834.14306640625, "val_acc": 48.0}
{"epoch": 11, "training_loss": 130515.60546875, "training_acc": 47.0, "val_loss": 17786.569213867188, "val_acc": 52.0}
{"epoch": 12, "training_loss": 61110.76477050781, "training_acc": 53.0, "val_loss": 42305.09338378906, "val_acc": 48.0}
{"epoch": 13, "training_loss": 163976.05322265625, "training_acc": 47.0, "val_loss": 27431.854248046875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 120703.2353515625, "training_acc": 53.0, "val_loss": 928.8406372070312, "val_acc": 48.0}
{"epoch": 15, "training_loss": 16675.030029296875, "training_acc": 55.0, "val_loss": 14530.406188964844, "val_acc": 48.0}
{"epoch": 16, "training_loss": 63480.22314453125, "training_acc": 47.0, "val_loss": 5596.4324951171875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 51991.59130859375, "training_acc": 49.0, "val_loss": 9726.927185058594, "val_acc": 52.0}
{"epoch": 18, "training_loss": 110573.623046875, "training_acc": 49.0, "val_loss": 57796.075439453125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 161295.37615966797, "training_acc": 47.0, "val_loss": 87557.6416015625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 408208.416015625, "training_acc": 53.0, "val_loss": 116428.33251953125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 375658.6767578125, "training_acc": 53.0, "val_loss": 34621.7529296875, "val_acc": 48.0}
{"epoch": 22, "training_loss": 208631.42578125, "training_acc": 47.0, "val_loss": 55185.02197265625, "val_acc": 48.0}
{"epoch": 23, "training_loss": 174358.09936523438, "training_acc": 47.0, "val_loss": 32277.16064453125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 84282.75875854492, "training_acc": 53.0, "val_loss": 73520.73364257812, "val_acc": 48.0}
{"epoch": 25, "training_loss": 322271.0166015625, "training_acc": 47.0, "val_loss": 50192.72155761719, "val_acc": 48.0}
{"epoch": 26, "training_loss": 189103.197265625, "training_acc": 47.0, "val_loss": 64152.197265625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 225624.93115234375, "training_acc": 53.0, "val_loss": 14253.744506835938, "val_acc": 48.0}
{"epoch": 28, "training_loss": 59361.66650390625, "training_acc": 47.0, "val_loss": 31036.724853515625, "val_acc": 52.0}
{"epoch": 29, "training_loss": 118142.85400390625, "training_acc": 53.0, "val_loss": 18303.929138183594, "val_acc": 48.0}
{"epoch": 30, "training_loss": 64025.45275878906, "training_acc": 47.0, "val_loss": 45941.86706542969, "val_acc": 52.0}
{"epoch": 31, "training_loss": 194050.16015625, "training_acc": 53.0, "val_loss": 18071.905517578125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 129240.4814453125, "training_acc": 53.0, "val_loss": 85384.41162109375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 302103.95703125, "training_acc": 47.0, "val_loss": 24520.59783935547, "val_acc": 52.0}
