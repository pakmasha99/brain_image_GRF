"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 564115.4534301758, "training_acc": 53.0, "val_loss": 146658.67919921875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 754545.18359375, "training_acc": 49.0, "val_loss": 307244.1162109375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 1109481.12890625, "training_acc": 47.0, "val_loss": 19231.370544433594, "val_acc": 48.0}
{"epoch": 3, "training_loss": 298287.3046875, "training_acc": 55.0, "val_loss": 346073.6572265625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1408586.62109375, "training_acc": 53.0, "val_loss": 336704.3701171875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1163870.734375, "training_acc": 53.0, "val_loss": 77726.26953125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 477484.54296875, "training_acc": 41.0, "val_loss": 234247.9248046875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 987300.140625, "training_acc": 47.0, "val_loss": 205906.640625, "val_acc": 48.0}
{"epoch": 8, "training_loss": 673902.556640625, "training_acc": 47.0, "val_loss": 49266.19567871094, "val_acc": 52.0}
{"epoch": 9, "training_loss": 314424.23046875, "training_acc": 53.0, "val_loss": 150440.68603515625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 547130.291015625, "training_acc": 53.0, "val_loss": 47044.671630859375, "val_acc": 52.0}
{"epoch": 11, "training_loss": 160080.73583984375, "training_acc": 63.0, "val_loss": 131950.8056640625, "val_acc": 48.0}
{"epoch": 12, "training_loss": 537738.958984375, "training_acc": 47.0, "val_loss": 78352.87475585938, "val_acc": 48.0}
{"epoch": 13, "training_loss": 237963.08618164062, "training_acc": 49.0, "val_loss": 63233.7890625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 234250.9814453125, "training_acc": 53.0, "val_loss": 91.02734327316284, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2077.5309295654297, "training_acc": 50.0, "val_loss": 45952.05383300781, "val_acc": 48.0}
{"epoch": 16, "training_loss": 171180.9462890625, "training_acc": 47.0, "val_loss": 28229.550170898438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 120225.53076171875, "training_acc": 53.0, "val_loss": 3894.7513580322266, "val_acc": 52.0}
{"epoch": 18, "training_loss": 127335.0263671875, "training_acc": 49.0, "val_loss": 92125.59204101562, "val_acc": 48.0}
{"epoch": 19, "training_loss": 317319.984375, "training_acc": 47.0, "val_loss": 31936.892700195312, "val_acc": 52.0}
{"epoch": 20, "training_loss": 191329.4345703125, "training_acc": 53.0, "val_loss": 49991.71447753906, "val_acc": 52.0}
{"epoch": 21, "training_loss": 128223.44580078125, "training_acc": 55.0, "val_loss": 18472.927856445312, "val_acc": 48.0}
{"epoch": 22, "training_loss": 66915.92114257812, "training_acc": 55.0, "val_loss": 16784.744262695312, "val_acc": 52.0}
{"epoch": 23, "training_loss": 65623.84106445312, "training_acc": 59.0, "val_loss": 22762.710571289062, "val_acc": 48.0}
{"epoch": 24, "training_loss": 96398.53857421875, "training_acc": 51.0, "val_loss": 32786.04736328125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 117761.98413085938, "training_acc": 43.0, "val_loss": 4830.467987060547, "val_acc": 52.0}
{"epoch": 26, "training_loss": 56717.75244140625, "training_acc": 47.0, "val_loss": 1512.3286247253418, "val_acc": 52.0}
{"epoch": 27, "training_loss": 43926.27880859375, "training_acc": 45.0, "val_loss": 13050.677490234375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 34946.454650878906, "training_acc": 53.0, "val_loss": 55781.3720703125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 226643.71875, "training_acc": 47.0, "val_loss": 2857.9145431518555, "val_acc": 48.0}
{"epoch": 30, "training_loss": 124106.89208984375, "training_acc": 51.0, "val_loss": 128654.38232421875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 495625.10546875, "training_acc": 53.0, "val_loss": 74843.67065429688, "val_acc": 52.0}
{"epoch": 32, "training_loss": 223924.82763671875, "training_acc": 47.0, "val_loss": 44064.16015625, "val_acc": 48.0}
{"epoch": 33, "training_loss": 144276.49267578125, "training_acc": 47.0, "val_loss": 52082.073974609375, "val_acc": 52.0}
