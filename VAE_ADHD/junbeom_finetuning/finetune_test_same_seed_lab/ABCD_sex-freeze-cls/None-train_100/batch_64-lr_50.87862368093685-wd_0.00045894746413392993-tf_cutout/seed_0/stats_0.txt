"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 371100.0876083374, "training_acc": 50.0, "val_loss": 88256.95190429688, "val_acc": 44.0}
{"epoch": 1, "training_loss": 387501.16015625, "training_acc": 48.0, "val_loss": 154061.181640625, "val_acc": 56.0}
{"epoch": 2, "training_loss": 632579.021484375, "training_acc": 52.0, "val_loss": 68291.9189453125, "val_acc": 56.0}
{"epoch": 3, "training_loss": 217307.78271484375, "training_acc": 54.0, "val_loss": 77773.24829101562, "val_acc": 44.0}
{"epoch": 4, "training_loss": 273462.8330078125, "training_acc": 48.0, "val_loss": 8905.833435058594, "val_acc": 44.0}
{"epoch": 5, "training_loss": 142396.466796875, "training_acc": 44.0, "val_loss": 93101.45263671875, "val_acc": 56.0}
{"epoch": 6, "training_loss": 391947.154296875, "training_acc": 52.0, "val_loss": 54121.099853515625, "val_acc": 56.0}
{"epoch": 7, "training_loss": 158684.1773071289, "training_acc": 48.0, "val_loss": 24373.741149902344, "val_acc": 44.0}
{"epoch": 8, "training_loss": 70256.4912109375, "training_acc": 48.0, "val_loss": 30340.121459960938, "val_acc": 56.0}
{"epoch": 9, "training_loss": 140876.59765625, "training_acc": 52.0, "val_loss": 16974.642944335938, "val_acc": 56.0}
{"epoch": 10, "training_loss": 88286.57080078125, "training_acc": 50.0, "val_loss": 42027.081298828125, "val_acc": 44.0}
{"epoch": 11, "training_loss": 128681.76293945312, "training_acc": 48.0, "val_loss": 22593.939208984375, "val_acc": 56.0}
{"epoch": 12, "training_loss": 118638.4853515625, "training_acc": 52.0, "val_loss": 21418.50128173828, "val_acc": 56.0}
{"epoch": 13, "training_loss": 86201.20703125, "training_acc": 48.0, "val_loss": 23425.588989257812, "val_acc": 44.0}
{"epoch": 14, "training_loss": 53768.961166381836, "training_acc": 50.0, "val_loss": 36721.429443359375, "val_acc": 56.0}
{"epoch": 15, "training_loss": 170039.443359375, "training_acc": 52.0, "val_loss": 34500.37841796875, "val_acc": 56.0}
{"epoch": 16, "training_loss": 98654.22735595703, "training_acc": 52.0, "val_loss": 57762.738037109375, "val_acc": 44.0}
{"epoch": 17, "training_loss": 249586.8798828125, "training_acc": 48.0, "val_loss": 75363.28125, "val_acc": 44.0}
{"epoch": 18, "training_loss": 232476.36328125, "training_acc": 48.0, "val_loss": 16869.705200195312, "val_acc": 56.0}
{"epoch": 19, "training_loss": 107514.203125, "training_acc": 52.0, "val_loss": 35497.25646972656, "val_acc": 56.0}
{"epoch": 20, "training_loss": 117303.248046875, "training_acc": 52.0, "val_loss": 38587.63122558594, "val_acc": 44.0}
{"epoch": 21, "training_loss": 172017.302734375, "training_acc": 48.0, "val_loss": 41264.63317871094, "val_acc": 44.0}
{"epoch": 22, "training_loss": 112339.65045166016, "training_acc": 44.0, "val_loss": 10455.662536621094, "val_acc": 56.0}
{"epoch": 23, "training_loss": 31518.91552734375, "training_acc": 54.0, "val_loss": 6156.912994384766, "val_acc": 56.0}
{"epoch": 24, "training_loss": 24712.138671875, "training_acc": 54.0, "val_loss": 4615.964889526367, "val_acc": 56.0}
{"epoch": 25, "training_loss": 27908.579711914062, "training_acc": 48.0, "val_loss": 4875.1953125, "val_acc": 56.0}
{"epoch": 26, "training_loss": 11585.83391571045, "training_acc": 62.0, "val_loss": 10356.050872802734, "val_acc": 56.0}
{"epoch": 27, "training_loss": 28657.07332611084, "training_acc": 52.0, "val_loss": 11754.764556884766, "val_acc": 56.0}
{"epoch": 28, "training_loss": 35117.18724822998, "training_acc": 48.0, "val_loss": 12337.632751464844, "val_acc": 56.0}
{"epoch": 29, "training_loss": 37365.57099914551, "training_acc": 52.0, "val_loss": 34874.06921386719, "val_acc": 44.0}
{"epoch": 30, "training_loss": 129153.36450195312, "training_acc": 48.0, "val_loss": 12154.222106933594, "val_acc": 44.0}
{"epoch": 31, "training_loss": 55036.3681640625, "training_acc": 58.0, "val_loss": 41145.660400390625, "val_acc": 56.0}
{"epoch": 32, "training_loss": 165574.86669921875, "training_acc": 52.0, "val_loss": 5638.246154785156, "val_acc": 56.0}
{"epoch": 33, "training_loss": 90504.1259765625, "training_acc": 48.0, "val_loss": 72834.66186523438, "val_acc": 44.0}
{"epoch": 34, "training_loss": 256893.4677734375, "training_acc": 48.0, "val_loss": 24144.943237304688, "val_acc": 44.0}
{"epoch": 35, "training_loss": 101783.15966796875, "training_acc": 50.0, "val_loss": 50934.295654296875, "val_acc": 56.0}
{"epoch": 36, "training_loss": 215169.69580078125, "training_acc": 52.0, "val_loss": 25825.234985351562, "val_acc": 56.0}
{"epoch": 37, "training_loss": 117774.92578125, "training_acc": 42.0, "val_loss": 34685.784912109375, "val_acc": 44.0}
{"epoch": 38, "training_loss": 106122.43310546875, "training_acc": 48.0, "val_loss": 21136.148071289062, "val_acc": 56.0}
{"epoch": 39, "training_loss": 115974.04541015625, "training_acc": 52.0, "val_loss": 23352.9052734375, "val_acc": 56.0}
{"epoch": 40, "training_loss": 78689.39306640625, "training_acc": 50.0, "val_loss": 16012.150573730469, "val_acc": 44.0}
{"epoch": 41, "training_loss": 46373.06329345703, "training_acc": 50.0, "val_loss": 1388.9357566833496, "val_acc": 56.0}
{"epoch": 42, "training_loss": 34008.115966796875, "training_acc": 56.0, "val_loss": 27883.291625976562, "val_acc": 44.0}
{"epoch": 43, "training_loss": 82332.94787597656, "training_acc": 40.0, "val_loss": 1422.2758293151855, "val_acc": 44.0}
{"epoch": 44, "training_loss": 27121.232177734375, "training_acc": 52.0, "val_loss": 13390.245056152344, "val_acc": 56.0}
{"epoch": 45, "training_loss": 49247.343994140625, "training_acc": 54.0, "val_loss": 11097.126770019531, "val_acc": 44.0}
{"epoch": 46, "training_loss": 50922.023193359375, "training_acc": 48.0, "val_loss": 14020.811462402344, "val_acc": 56.0}
{"epoch": 47, "training_loss": 58774.58557128906, "training_acc": 46.0, "val_loss": 5402.3895263671875, "val_acc": 44.0}
{"epoch": 48, "training_loss": 50332.43505859375, "training_acc": 48.0, "val_loss": 25862.744140625, "val_acc": 56.0}
{"epoch": 49, "training_loss": 81280.26354980469, "training_acc": 52.0, "val_loss": 37169.82421875, "val_acc": 44.0}
{"epoch": 50, "training_loss": 154147.421875, "training_acc": 48.0, "val_loss": 35338.10729980469, "val_acc": 44.0}
{"epoch": 51, "training_loss": 94259.70904541016, "training_acc": 48.0, "val_loss": 12921.971130371094, "val_acc": 56.0}
{"epoch": 52, "training_loss": 33684.769948005676, "training_acc": 54.0, "val_loss": 26065.142822265625, "val_acc": 44.0}
{"epoch": 53, "training_loss": 88944.0546875, "training_acc": 48.0, "val_loss": 10290.890502929688, "val_acc": 56.0}
{"epoch": 54, "training_loss": 45939.644775390625, "training_acc": 52.0, "val_loss": 8373.484802246094, "val_acc": 44.0}
{"epoch": 55, "training_loss": 24794.70733642578, "training_acc": 44.0, "val_loss": 18508.189392089844, "val_acc": 44.0}
{"epoch": 56, "training_loss": 54675.44561767578, "training_acc": 48.0, "val_loss": 23214.22576904297, "val_acc": 56.0}
{"epoch": 57, "training_loss": 104904.31689453125, "training_acc": 52.0, "val_loss": 10361.542510986328, "val_acc": 56.0}
{"epoch": 58, "training_loss": 67310.52587890625, "training_acc": 52.0, "val_loss": 41830.02624511719, "val_acc": 44.0}
{"epoch": 59, "training_loss": 130446.8505859375, "training_acc": 48.0, "val_loss": 17220.448303222656, "val_acc": 56.0}
{"epoch": 60, "training_loss": 98577.95751953125, "training_acc": 52.0, "val_loss": 18640.187072753906, "val_acc": 56.0}
