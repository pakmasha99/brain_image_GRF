"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.02090954780579, "training_acc": 47.0, "val_loss": 17.322711646556854, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.86858034133911, "training_acc": 53.0, "val_loss": 17.44246631860733, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.77613472938538, "training_acc": 53.0, "val_loss": 17.648513615131378, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.13672685623169, "training_acc": 53.0, "val_loss": 17.55039244890213, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.66352200508118, "training_acc": 53.0, "val_loss": 17.386211454868317, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23764085769653, "training_acc": 53.0, "val_loss": 17.313283681869507, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.42426657676697, "training_acc": 53.0, "val_loss": 17.349474132061005, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4621171951294, "training_acc": 47.0, "val_loss": 17.357903718948364, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.47552466392517, "training_acc": 47.0, "val_loss": 17.330150306224823, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.2636330127716, "training_acc": 54.0, "val_loss": 17.315112054347992, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42232537269592, "training_acc": 53.0, "val_loss": 17.324508726596832, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.136399269104, "training_acc": 53.0, "val_loss": 17.34011024236679, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.251460313797, "training_acc": 53.0, "val_loss": 17.35307425260544, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21056151390076, "training_acc": 53.0, "val_loss": 17.33812540769577, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.30793118476868, "training_acc": 53.0, "val_loss": 17.318952083587646, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18350553512573, "training_acc": 53.0, "val_loss": 17.316173017024994, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.24439573287964, "training_acc": 53.0, "val_loss": 17.317698895931244, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.25621962547302, "training_acc": 53.0, "val_loss": 17.313605546951294, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15138292312622, "training_acc": 53.0, "val_loss": 17.314453423023224, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1385748386383, "training_acc": 53.0, "val_loss": 17.316268384456635, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1640465259552, "training_acc": 53.0, "val_loss": 17.322181165218353, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12648010253906, "training_acc": 53.0, "val_loss": 17.340649664402008, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16051840782166, "training_acc": 53.0, "val_loss": 17.35759675502777, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26026797294617, "training_acc": 53.0, "val_loss": 17.368751764297485, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.26110744476318, "training_acc": 53.0, "val_loss": 17.35406070947647, "val_acc": 52.0}
