"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3975236415863, "training_acc": 49.0, "val_loss": 17.31044352054596, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.52362322807312, "training_acc": 53.0, "val_loss": 17.331376671791077, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18718433380127, "training_acc": 53.0, "val_loss": 17.318011820316315, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20995354652405, "training_acc": 53.0, "val_loss": 17.310485243797302, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4770233631134, "training_acc": 53.0, "val_loss": 17.31616109609604, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22063970565796, "training_acc": 53.0, "val_loss": 17.30964183807373, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13507556915283, "training_acc": 53.0, "val_loss": 17.320723831653595, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12053751945496, "training_acc": 53.0, "val_loss": 17.340068519115448, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2424464225769, "training_acc": 53.0, "val_loss": 17.360298335552216, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.27296900749207, "training_acc": 53.0, "val_loss": 17.350676655769348, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15904712677002, "training_acc": 53.0, "val_loss": 17.31938123703003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0716540813446, "training_acc": 53.0, "val_loss": 17.30957180261612, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.4166100025177, "training_acc": 53.0, "val_loss": 17.324241995811462, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2897686958313, "training_acc": 52.0, "val_loss": 17.318181693553925, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.28290343284607, "training_acc": 53.0, "val_loss": 17.312057316303253, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20625615119934, "training_acc": 53.0, "val_loss": 17.309890687465668, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1397590637207, "training_acc": 53.0, "val_loss": 17.309291660785675, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12468338012695, "training_acc": 53.0, "val_loss": 17.313624918460846, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1497528553009, "training_acc": 53.0, "val_loss": 17.32371896505356, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13660049438477, "training_acc": 53.0, "val_loss": 17.355279624462128, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.41757321357727, "training_acc": 53.0, "val_loss": 17.379727959632874, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.38234329223633, "training_acc": 53.0, "val_loss": 17.349378764629364, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18237829208374, "training_acc": 53.0, "val_loss": 17.335326969623566, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16847586631775, "training_acc": 53.0, "val_loss": 17.319999635219574, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12853360176086, "training_acc": 53.0, "val_loss": 17.31151193380356, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18919277191162, "training_acc": 53.0, "val_loss": 17.310452461242676, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18740248680115, "training_acc": 53.0, "val_loss": 17.312969267368317, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20323872566223, "training_acc": 53.0, "val_loss": 17.310497164726257, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18326020240784, "training_acc": 53.0, "val_loss": 17.309318482875824, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12304663658142, "training_acc": 53.0, "val_loss": 17.314624786376953, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16336560249329, "training_acc": 53.0, "val_loss": 17.33398735523224, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20354342460632, "training_acc": 53.0, "val_loss": 17.34396368265152, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17343783378601, "training_acc": 53.0, "val_loss": 17.330871522426605, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1635890007019, "training_acc": 53.0, "val_loss": 17.317485809326172, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19842958450317, "training_acc": 53.0, "val_loss": 17.31061488389969, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14120435714722, "training_acc": 53.0, "val_loss": 17.310155928134918, "val_acc": 52.0}
