"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23079752922058, "training_acc": 53.0, "val_loss": 17.314301431179047, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21983790397644, "training_acc": 53.0, "val_loss": 17.31419712305069, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2275459766388, "training_acc": 53.0, "val_loss": 17.313426733016968, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19193816184998, "training_acc": 53.0, "val_loss": 17.312514781951904, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20942711830139, "training_acc": 53.0, "val_loss": 17.311643064022064, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2145733833313, "training_acc": 53.0, "val_loss": 17.311111092567444, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.198650598526, "training_acc": 53.0, "val_loss": 17.310380935668945, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1955988407135, "training_acc": 53.0, "val_loss": 17.309746146202087, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18678331375122, "training_acc": 53.0, "val_loss": 17.3090860247612, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16796088218689, "training_acc": 53.0, "val_loss": 17.308489978313446, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17767429351807, "training_acc": 53.0, "val_loss": 17.30799227952957, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16486740112305, "training_acc": 53.0, "val_loss": 17.307670414447784, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18786787986755, "training_acc": 53.0, "val_loss": 17.30741858482361, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16969776153564, "training_acc": 53.0, "val_loss": 17.307278513908386, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15483331680298, "training_acc": 53.0, "val_loss": 17.30714589357376, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16802501678467, "training_acc": 53.0, "val_loss": 17.307032644748688, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13734793663025, "training_acc": 53.0, "val_loss": 17.3069566488266, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15201878547668, "training_acc": 53.0, "val_loss": 17.306919395923615, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1517264842987, "training_acc": 53.0, "val_loss": 17.30690747499466, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15992283821106, "training_acc": 53.0, "val_loss": 17.30692833662033, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13495326042175, "training_acc": 53.0, "val_loss": 17.30695515871048, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13874363899231, "training_acc": 53.0, "val_loss": 17.306987941265106, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1588966846466, "training_acc": 53.0, "val_loss": 17.307038605213165, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14361119270325, "training_acc": 53.0, "val_loss": 17.307090759277344, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1193573474884, "training_acc": 53.0, "val_loss": 17.307162284851074, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13689160346985, "training_acc": 53.0, "val_loss": 17.30724722146988, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14771938323975, "training_acc": 53.0, "val_loss": 17.307376861572266, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14370512962341, "training_acc": 53.0, "val_loss": 17.307502031326294, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12768483161926, "training_acc": 53.0, "val_loss": 17.307601869106293, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14068961143494, "training_acc": 53.0, "val_loss": 17.307792603969574, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13770651817322, "training_acc": 53.0, "val_loss": 17.30799376964569, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14585614204407, "training_acc": 53.0, "val_loss": 17.30823665857315, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14037871360779, "training_acc": 53.0, "val_loss": 17.308449745178223, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14787983894348, "training_acc": 53.0, "val_loss": 17.308585345745087, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12857556343079, "training_acc": 53.0, "val_loss": 17.308564484119415, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14297461509705, "training_acc": 53.0, "val_loss": 17.308537662029266, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13259530067444, "training_acc": 53.0, "val_loss": 17.30852872133255, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12615633010864, "training_acc": 53.0, "val_loss": 17.308536171913147, "val_acc": 52.0}
