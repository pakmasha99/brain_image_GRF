"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.73035144805908, "training_acc": 47.0, "val_loss": 17.408211529254913, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.68355870246887, "training_acc": 47.0, "val_loss": 17.399759590625763, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.67027282714844, "training_acc": 47.0, "val_loss": 17.391616106033325, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.59516334533691, "training_acc": 47.0, "val_loss": 17.38416701555252, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.5751736164093, "training_acc": 47.0, "val_loss": 17.377738654613495, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.56505990028381, "training_acc": 47.0, "val_loss": 17.371465265750885, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52427697181702, "training_acc": 47.0, "val_loss": 17.365752160549164, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.47622609138489, "training_acc": 47.0, "val_loss": 17.36081838607788, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.43326783180237, "training_acc": 47.0, "val_loss": 17.35643744468689, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.4262330532074, "training_acc": 47.0, "val_loss": 17.352335155010223, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41069555282593, "training_acc": 47.0, "val_loss": 17.3483207821846, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.40373635292053, "training_acc": 47.0, "val_loss": 17.344819009304047, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.37906813621521, "training_acc": 47.0, "val_loss": 17.341814935207367, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.32702302932739, "training_acc": 50.0, "val_loss": 17.338714003562927, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31962609291077, "training_acc": 45.0, "val_loss": 17.336173355579376, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.3139922618866, "training_acc": 54.0, "val_loss": 17.333926260471344, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.28920030593872, "training_acc": 52.0, "val_loss": 17.331603169441223, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24825620651245, "training_acc": 54.0, "val_loss": 17.329521477222443, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2578980922699, "training_acc": 53.0, "val_loss": 17.327669262886047, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.2561686038971, "training_acc": 53.0, "val_loss": 17.326146364212036, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25277638435364, "training_acc": 53.0, "val_loss": 17.324750125408173, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25037813186646, "training_acc": 53.0, "val_loss": 17.323358356952667, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26016592979431, "training_acc": 53.0, "val_loss": 17.322196066379547, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22833585739136, "training_acc": 53.0, "val_loss": 17.321227490901947, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22795462608337, "training_acc": 53.0, "val_loss": 17.32037663459778, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18899869918823, "training_acc": 53.0, "val_loss": 17.319640517234802, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17095589637756, "training_acc": 53.0, "val_loss": 17.318972945213318, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18850874900818, "training_acc": 53.0, "val_loss": 17.31838583946228, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18632483482361, "training_acc": 53.0, "val_loss": 17.31788069009781, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17726635932922, "training_acc": 53.0, "val_loss": 17.317526042461395, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15651798248291, "training_acc": 53.0, "val_loss": 17.31722205877304, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17908596992493, "training_acc": 53.0, "val_loss": 17.316976189613342, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15958738327026, "training_acc": 53.0, "val_loss": 17.31681078672409, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17964124679565, "training_acc": 53.0, "val_loss": 17.316676676273346, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16986060142517, "training_acc": 53.0, "val_loss": 17.316624522209167, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18752694129944, "training_acc": 53.0, "val_loss": 17.31661558151245, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13840961456299, "training_acc": 53.0, "val_loss": 17.316623032093048, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14784097671509, "training_acc": 53.0, "val_loss": 17.316634953022003, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15257859230042, "training_acc": 53.0, "val_loss": 17.316655814647675, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1613838672638, "training_acc": 53.0, "val_loss": 17.31669157743454, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.1555724143982, "training_acc": 53.0, "val_loss": 17.316699028015137, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16118001937866, "training_acc": 53.0, "val_loss": 17.31671243906021, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15387320518494, "training_acc": 53.0, "val_loss": 17.316749691963196, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14391684532166, "training_acc": 53.0, "val_loss": 17.316779494285583, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.15895915031433, "training_acc": 53.0, "val_loss": 17.316867411136627, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.13114523887634, "training_acc": 53.0, "val_loss": 17.31700450181961, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.1358540058136, "training_acc": 53.0, "val_loss": 17.31712818145752, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.2022340297699, "training_acc": 53.0, "val_loss": 17.31722801923752, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.16545104980469, "training_acc": 53.0, "val_loss": 17.31729805469513, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.140056848526, "training_acc": 53.0, "val_loss": 17.317314445972443, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.12984704971313, "training_acc": 53.0, "val_loss": 17.317241430282593, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.1501681804657, "training_acc": 53.0, "val_loss": 17.31717884540558, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.17637300491333, "training_acc": 53.0, "val_loss": 17.31722354888916, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.15724229812622, "training_acc": 53.0, "val_loss": 17.3172265291214, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.1472978591919, "training_acc": 53.0, "val_loss": 17.31729507446289, "val_acc": 52.0}
