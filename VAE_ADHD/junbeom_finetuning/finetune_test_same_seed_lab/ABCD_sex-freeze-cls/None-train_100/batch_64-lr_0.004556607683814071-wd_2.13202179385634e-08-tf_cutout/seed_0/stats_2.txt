"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.55984497070312, "training_acc": 53.0, "val_loss": 18.385930359363556, "val_acc": 52.0}
{"epoch": 1, "training_loss": 77.51032757759094, "training_acc": 47.0, "val_loss": 21.592672169208527, "val_acc": 48.0}
{"epoch": 2, "training_loss": 85.01931285858154, "training_acc": 47.0, "val_loss": 17.658959329128265, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.70397543907166, "training_acc": 55.0, "val_loss": 19.526542723178864, "val_acc": 52.0}
{"epoch": 4, "training_loss": 79.73104524612427, "training_acc": 53.0, "val_loss": 19.91066336631775, "val_acc": 52.0}
{"epoch": 5, "training_loss": 76.50750517845154, "training_acc": 53.0, "val_loss": 17.305323481559753, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.29354190826416, "training_acc": 47.0, "val_loss": 18.701063096523285, "val_acc": 48.0}
{"epoch": 7, "training_loss": 75.14056873321533, "training_acc": 47.0, "val_loss": 17.779216170310974, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.87009119987488, "training_acc": 47.0, "val_loss": 17.57587343454361, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.36852884292603, "training_acc": 53.0, "val_loss": 18.696488440036774, "val_acc": 52.0}
{"epoch": 10, "training_loss": 73.47128486633301, "training_acc": 53.0, "val_loss": 17.60382205247879, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.01421332359314, "training_acc": 53.0, "val_loss": 17.527957260608673, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.52848768234253, "training_acc": 47.0, "val_loss": 17.77355968952179, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.25081968307495, "training_acc": 47.0, "val_loss": 17.31816828250885, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.4891357421875, "training_acc": 53.0, "val_loss": 17.496362328529358, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.6897931098938, "training_acc": 53.0, "val_loss": 17.49449521303177, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.5426983833313, "training_acc": 53.0, "val_loss": 17.32008308172226, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18260264396667, "training_acc": 53.0, "val_loss": 17.372865974903107, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.58934783935547, "training_acc": 47.0, "val_loss": 17.33941286802292, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.4423611164093, "training_acc": 47.0, "val_loss": 17.335006594657898, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16661739349365, "training_acc": 53.0, "val_loss": 17.391015589237213, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.41782093048096, "training_acc": 53.0, "val_loss": 17.356576025485992, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19594025611877, "training_acc": 53.0, "val_loss": 17.31472909450531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.36488771438599, "training_acc": 49.0, "val_loss": 17.324864864349365, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.38133263587952, "training_acc": 51.0, "val_loss": 17.328713834285736, "val_acc": 52.0}
