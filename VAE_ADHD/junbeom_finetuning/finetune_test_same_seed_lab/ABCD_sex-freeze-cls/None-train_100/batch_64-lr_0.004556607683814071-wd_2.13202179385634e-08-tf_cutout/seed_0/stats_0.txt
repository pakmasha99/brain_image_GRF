"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 84.96552658081055, "training_acc": 50.0, "val_loss": 18.564388155937195, "val_acc": 56.0}
{"epoch": 1, "training_loss": 76.18137288093567, "training_acc": 48.0, "val_loss": 21.55798226594925, "val_acc": 56.0}
{"epoch": 2, "training_loss": 90.2320396900177, "training_acc": 52.0, "val_loss": 17.758066952228546, "val_acc": 56.0}
{"epoch": 3, "training_loss": 71.00286102294922, "training_acc": 54.0, "val_loss": 19.94905024766922, "val_acc": 44.0}
{"epoch": 4, "training_loss": 79.50476384162903, "training_acc": 48.0, "val_loss": 21.366439759731293, "val_acc": 44.0}
{"epoch": 5, "training_loss": 79.92766642570496, "training_acc": 48.0, "val_loss": 17.437954246997833, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.70504808425903, "training_acc": 50.0, "val_loss": 17.799878120422363, "val_acc": 56.0}
{"epoch": 7, "training_loss": 74.43062448501587, "training_acc": 52.0, "val_loss": 17.801116406917572, "val_acc": 56.0}
{"epoch": 8, "training_loss": 72.51805758476257, "training_acc": 52.0, "val_loss": 17.194312810897827, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.47388744354248, "training_acc": 52.0, "val_loss": 18.897755444049835, "val_acc": 44.0}
{"epoch": 10, "training_loss": 73.92190313339233, "training_acc": 48.0, "val_loss": 18.615753948688507, "val_acc": 56.0}
{"epoch": 11, "training_loss": 71.90573358535767, "training_acc": 48.0, "val_loss": 17.17822402715683, "val_acc": 56.0}
{"epoch": 12, "training_loss": 70.30316495895386, "training_acc": 52.0, "val_loss": 17.410393059253693, "val_acc": 56.0}
{"epoch": 13, "training_loss": 71.63608908653259, "training_acc": 52.0, "val_loss": 17.17814952135086, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.07173037528992, "training_acc": 52.0, "val_loss": 17.41405874490738, "val_acc": 56.0}
{"epoch": 15, "training_loss": 70.12397885322571, "training_acc": 48.0, "val_loss": 17.7133247256279, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.9804060459137, "training_acc": 48.0, "val_loss": 17.245401442050934, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24710655212402, "training_acc": 52.0, "val_loss": 17.150092124938965, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.68158435821533, "training_acc": 52.0, "val_loss": 17.148946225643158, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.39930415153503, "training_acc": 52.0, "val_loss": 17.285029590129852, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.49799299240112, "training_acc": 48.0, "val_loss": 17.49718487262726, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.55468702316284, "training_acc": 48.0, "val_loss": 17.243237793445587, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.97894024848938, "training_acc": 52.0, "val_loss": 17.15327799320221, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.66479706764221, "training_acc": 52.0, "val_loss": 17.209702730178833, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.10119581222534, "training_acc": 53.0, "val_loss": 17.61189103126526, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.11619877815247, "training_acc": 48.0, "val_loss": 17.552947998046875, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.28296637535095, "training_acc": 38.0, "val_loss": 17.166392505168915, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.29169535636902, "training_acc": 52.0, "val_loss": 17.239707708358765, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.55880045890808, "training_acc": 46.0, "val_loss": 17.34616607427597, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2702898979187, "training_acc": 52.0, "val_loss": 17.18451827764511, "val_acc": 56.0}
{"epoch": 30, "training_loss": 70.42774295806885, "training_acc": 52.0, "val_loss": 17.154529690742493, "val_acc": 56.0}
{"epoch": 31, "training_loss": 70.5549247264862, "training_acc": 42.0, "val_loss": 17.430904507637024, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.45207929611206, "training_acc": 48.0, "val_loss": 17.240509390830994, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.20785617828369, "training_acc": 52.0, "val_loss": 17.166048288345337, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.54443836212158, "training_acc": 52.0, "val_loss": 17.1669140458107, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.32320880889893, "training_acc": 52.0, "val_loss": 17.36350953578949, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.5080029964447, "training_acc": 48.0, "val_loss": 17.35643744468689, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.38699769973755, "training_acc": 48.0, "val_loss": 17.15475022792816, "val_acc": 56.0}
