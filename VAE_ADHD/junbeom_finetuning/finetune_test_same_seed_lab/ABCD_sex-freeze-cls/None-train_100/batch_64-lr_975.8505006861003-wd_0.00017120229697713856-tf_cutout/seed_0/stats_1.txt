"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 9219860.344367981, "training_acc": 47.0, "val_loss": 532870.556640625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 7974730.125, "training_acc": 43.0, "val_loss": 4544266.40625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 16477052.1875, "training_acc": 53.0, "val_loss": 1917884.1796875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 5081111.53125, "training_acc": 53.0, "val_loss": 997402.83203125, "val_acc": 48.0}
{"epoch": 4, "training_loss": 3337308.8125, "training_acc": 47.0, "val_loss": 687529.345703125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 2960045.78125, "training_acc": 53.0, "val_loss": 275315.625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2061396.296875, "training_acc": 49.0, "val_loss": 925754.00390625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2720573.4296875, "training_acc": 47.0, "val_loss": 915528.41796875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3823058.296875, "training_acc": 53.0, "val_loss": 792966.162109375, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1931600.9106445312, "training_acc": 53.0, "val_loss": 1233898.33984375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 5345520.34375, "training_acc": 47.0, "val_loss": 1001358.88671875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 2418777.830078125, "training_acc": 47.0, "val_loss": 1233558.49609375, "val_acc": 52.0}
{"epoch": 12, "training_loss": 5428814.0625, "training_acc": 53.0, "val_loss": 1515838.4765625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 5087090.859375, "training_acc": 53.0, "val_loss": 137027.5634765625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 769744.46875, "training_acc": 47.0, "val_loss": 153646.96044921875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 390147.75048828125, "training_acc": 53.0, "val_loss": 696734.814453125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2672671.765625, "training_acc": 47.0, "val_loss": 7073.004913330078, "val_acc": 52.0}
{"epoch": 17, "training_loss": 147842.451171875, "training_acc": 53.0, "val_loss": 356104.248046875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1176461.275390625, "training_acc": 53.0, "val_loss": 433247.265625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1609639.8046875, "training_acc": 47.0, "val_loss": 315007.4951171875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1204937.046875, "training_acc": 53.0, "val_loss": 222705.46875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 653639.8564453125, "training_acc": 47.0, "val_loss": 623797.216796875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2431718.484375, "training_acc": 53.0, "val_loss": 176231.884765625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1531832.875, "training_acc": 49.0, "val_loss": 746294.7265625, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2195491.625, "training_acc": 47.0, "val_loss": 746513.37890625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 3437192.015625, "training_acc": 53.0, "val_loss": 655728.369140625, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1648833.5009765625, "training_acc": 55.0, "val_loss": 175291.8212890625, "val_acc": 48.0}
{"epoch": 27, "training_loss": 732971.0390625, "training_acc": 55.0, "val_loss": 197684.99755859375, "val_acc": 52.0}
{"epoch": 28, "training_loss": 767806.0, "training_acc": 59.0, "val_loss": 213011.328125, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1055242.22265625, "training_acc": 51.0, "val_loss": 365359.521484375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1408935.87109375, "training_acc": 43.0, "val_loss": 35007.391357421875, "val_acc": 52.0}
{"epoch": 31, "training_loss": 613740.2578125, "training_acc": 47.0, "val_loss": 46080.40771484375, "val_acc": 52.0}
{"epoch": 32, "training_loss": 522225.203125, "training_acc": 45.0, "val_loss": 204482.99560546875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 577084.1328125, "training_acc": 53.0, "val_loss": 591700.87890625, "val_acc": 48.0}
{"epoch": 34, "training_loss": 2257588.59375, "training_acc": 47.0, "val_loss": 160412.56103515625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 586764.21875, "training_acc": 53.0, "val_loss": 370484.27734375, "val_acc": 48.0}
