"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 7109965.505809784, "training_acc": 53.0, "val_loss": 538912.109375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7744775.3125, "training_acc": 49.0, "val_loss": 4354858.984375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 15234690.25, "training_acc": 47.0, "val_loss": 347919.4580078125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 4383322.125, "training_acc": 47.0, "val_loss": 3125811.9140625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 11843354.65625, "training_acc": 53.0, "val_loss": 1812751.7578125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4976636.1640625, "training_acc": 53.0, "val_loss": 1570876.7578125, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7190908.65625, "training_acc": 47.0, "val_loss": 1693643.1640625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5283063.9375, "training_acc": 47.0, "val_loss": 815678.61328125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3764925.265625, "training_acc": 53.0, "val_loss": 1006000.390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2919456.8125, "training_acc": 53.0, "val_loss": 917738.96484375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 3941173.078125, "training_acc": 47.0, "val_loss": 587923.046875, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1986816.71875, "training_acc": 51.0, "val_loss": 553986.03515625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1627854.103515625, "training_acc": 53.0, "val_loss": 697631.005859375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2844712.375, "training_acc": 47.0, "val_loss": 72744.45190429688, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1106191.9765625, "training_acc": 57.0, "val_loss": 1167256.0546875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4159986.6875, "training_acc": 53.0, "val_loss": 130296.0693359375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1619544.171875, "training_acc": 55.0, "val_loss": 1305005.859375, "val_acc": 48.0}
{"epoch": 17, "training_loss": 4741695.5, "training_acc": 47.0, "val_loss": 17975.631713867188, "val_acc": 52.0}
{"epoch": 18, "training_loss": 392493.46875, "training_acc": 53.0, "val_loss": 296298.9501953125, "val_acc": 48.0}
{"epoch": 19, "training_loss": 898013.69140625, "training_acc": 47.0, "val_loss": 627399.853515625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2488602.9765625, "training_acc": 53.0, "val_loss": 198653.86962890625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 976436.4375, "training_acc": 63.0, "val_loss": 759971.09375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2401622.83203125, "training_acc": 47.0, "val_loss": 618884.375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2586803.0, "training_acc": 53.0, "val_loss": 403601.4892578125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1475233.3671875, "training_acc": 53.0, "val_loss": 391154.39453125, "val_acc": 48.0}
{"epoch": 25, "training_loss": 966893.8095703125, "training_acc": 59.0, "val_loss": 88625.78735351562, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1076457.171875, "training_acc": 45.0, "val_loss": 236428.02734375, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1512588.90625, "training_acc": 45.0, "val_loss": 558467.48046875, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1477362.884765625, "training_acc": 53.0, "val_loss": 834347.75390625, "val_acc": 48.0}
{"epoch": 29, "training_loss": 3496792.953125, "training_acc": 47.0, "val_loss": 422214.990234375, "val_acc": 48.0}
{"epoch": 30, "training_loss": 2211116.7734375, "training_acc": 41.0, "val_loss": 662981.15234375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1991060.625, "training_acc": 53.0, "val_loss": 588441.259765625, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2552313.078125, "training_acc": 47.0, "val_loss": 221316.943359375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 1083795.984375, "training_acc": 59.0, "val_loss": 839289.55078125, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2856306.5390625, "training_acc": 53.0, "val_loss": 203257.1044921875, "val_acc": 48.0}
{"epoch": 35, "training_loss": 974515.94921875, "training_acc": 47.0, "val_loss": 298772.216796875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1154665.578125, "training_acc": 53.0, "val_loss": 310339.6728515625, "val_acc": 48.0}
