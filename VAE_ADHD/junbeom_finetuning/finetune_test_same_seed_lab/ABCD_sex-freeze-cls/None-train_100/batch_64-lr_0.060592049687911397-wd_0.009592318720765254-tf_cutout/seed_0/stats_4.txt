"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 588.5831565856934, "training_acc": 47.0, "val_loss": 89.56269025802612, "val_acc": 48.0}
{"epoch": 1, "training_loss": 446.38978004455566, "training_acc": 53.0, "val_loss": 283.88357162475586, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1110.1472663879395, "training_acc": 53.0, "val_loss": 208.26246738433838, "val_acc": 52.0}
{"epoch": 3, "training_loss": 687.1775245666504, "training_acc": 53.0, "val_loss": 75.5743682384491, "val_acc": 48.0}
{"epoch": 4, "training_loss": 436.70230865478516, "training_acc": 47.0, "val_loss": 146.46450281143188, "val_acc": 48.0}
{"epoch": 5, "training_loss": 516.3362522125244, "training_acc": 47.0, "val_loss": 20.485717058181763, "val_acc": 52.0}
{"epoch": 6, "training_loss": 173.3460454940796, "training_acc": 53.0, "val_loss": 88.79928588867188, "val_acc": 52.0}
{"epoch": 7, "training_loss": 304.586275100708, "training_acc": 53.0, "val_loss": 18.044288456439972, "val_acc": 52.0}
{"epoch": 8, "training_loss": 109.79344511032104, "training_acc": 47.0, "val_loss": 60.64176559448242, "val_acc": 48.0}
{"epoch": 9, "training_loss": 211.41420722007751, "training_acc": 47.0, "val_loss": 34.91460084915161, "val_acc": 52.0}
{"epoch": 10, "training_loss": 153.43173456192017, "training_acc": 53.0, "val_loss": 23.954539000988007, "val_acc": 52.0}
{"epoch": 11, "training_loss": 135.9754557609558, "training_acc": 41.0, "val_loss": 37.926945090293884, "val_acc": 48.0}
{"epoch": 12, "training_loss": 133.3847301006317, "training_acc": 43.0, "val_loss": 30.151817202568054, "val_acc": 52.0}
{"epoch": 13, "training_loss": 111.06362533569336, "training_acc": 53.0, "val_loss": 18.2809516787529, "val_acc": 52.0}
{"epoch": 14, "training_loss": 76.40997648239136, "training_acc": 47.0, "val_loss": 18.143749237060547, "val_acc": 52.0}
{"epoch": 15, "training_loss": 71.3663010597229, "training_acc": 53.0, "val_loss": 21.375972032546997, "val_acc": 52.0}
{"epoch": 16, "training_loss": 80.19568705558777, "training_acc": 49.0, "val_loss": 19.70776468515396, "val_acc": 48.0}
{"epoch": 17, "training_loss": 76.00872802734375, "training_acc": 47.0, "val_loss": 19.373637437820435, "val_acc": 52.0}
{"epoch": 18, "training_loss": 77.15352296829224, "training_acc": 53.0, "val_loss": 21.214179694652557, "val_acc": 48.0}
{"epoch": 19, "training_loss": 84.25221657752991, "training_acc": 47.0, "val_loss": 17.93343275785446, "val_acc": 52.0}
{"epoch": 20, "training_loss": 71.55015921592712, "training_acc": 53.0, "val_loss": 17.801594734191895, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.00818991661072, "training_acc": 53.0, "val_loss": 18.27130615711212, "val_acc": 52.0}
{"epoch": 22, "training_loss": 72.37792634963989, "training_acc": 49.0, "val_loss": 18.41188371181488, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.9223644733429, "training_acc": 53.0, "val_loss": 22.13001251220703, "val_acc": 48.0}
{"epoch": 24, "training_loss": 83.77611422538757, "training_acc": 47.0, "val_loss": 21.31434977054596, "val_acc": 52.0}
{"epoch": 25, "training_loss": 81.57765984535217, "training_acc": 53.0, "val_loss": 17.662368714809418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 72.80075979232788, "training_acc": 47.0, "val_loss": 19.067420065402985, "val_acc": 52.0}
{"epoch": 27, "training_loss": 82.96655654907227, "training_acc": 53.0, "val_loss": 22.60429561138153, "val_acc": 48.0}
{"epoch": 28, "training_loss": 93.54544496536255, "training_acc": 47.0, "val_loss": 21.017825603485107, "val_acc": 52.0}
{"epoch": 29, "training_loss": 90.3506908416748, "training_acc": 53.0, "val_loss": 17.93452799320221, "val_acc": 52.0}
{"epoch": 30, "training_loss": 90.1789722442627, "training_acc": 47.0, "val_loss": 17.925536632537842, "val_acc": 52.0}
{"epoch": 31, "training_loss": 82.5728850364685, "training_acc": 53.0, "val_loss": 17.763522267341614, "val_acc": 52.0}
{"epoch": 32, "training_loss": 80.4188539981842, "training_acc": 51.0, "val_loss": 18.53322684764862, "val_acc": 48.0}
{"epoch": 33, "training_loss": 81.32551693916321, "training_acc": 49.0, "val_loss": 20.524127781391144, "val_acc": 52.0}
{"epoch": 34, "training_loss": 85.92799496650696, "training_acc": 49.0, "val_loss": 19.27541047334671, "val_acc": 48.0}
{"epoch": 35, "training_loss": 74.9583637714386, "training_acc": 53.0, "val_loss": 22.278258204460144, "val_acc": 52.0}
{"epoch": 36, "training_loss": 80.03715825080872, "training_acc": 53.0, "val_loss": 22.441188991069794, "val_acc": 48.0}
{"epoch": 37, "training_loss": 85.76281547546387, "training_acc": 47.0, "val_loss": 20.262323319911957, "val_acc": 52.0}
{"epoch": 38, "training_loss": 78.1221535205841, "training_acc": 49.0, "val_loss": 18.31512153148651, "val_acc": 52.0}
{"epoch": 39, "training_loss": 79.5190212726593, "training_acc": 43.0, "val_loss": 17.34413504600525, "val_acc": 52.0}
{"epoch": 40, "training_loss": 77.5753562450409, "training_acc": 47.0, "val_loss": 19.54048126935959, "val_acc": 52.0}
{"epoch": 41, "training_loss": 78.64049911499023, "training_acc": 53.0, "val_loss": 18.71425211429596, "val_acc": 48.0}
{"epoch": 42, "training_loss": 76.03940153121948, "training_acc": 47.0, "val_loss": 19.058051705360413, "val_acc": 52.0}
{"epoch": 43, "training_loss": 74.65391278266907, "training_acc": 53.0, "val_loss": 17.976661026477814, "val_acc": 52.0}
{"epoch": 44, "training_loss": 73.38782477378845, "training_acc": 47.0, "val_loss": 20.678813755512238, "val_acc": 52.0}
{"epoch": 45, "training_loss": 80.8425190448761, "training_acc": 53.0, "val_loss": 17.313408851623535, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.07868981361389, "training_acc": 53.0, "val_loss": 17.318320274353027, "val_acc": 52.0}
{"epoch": 47, "training_loss": 73.12980723381042, "training_acc": 53.0, "val_loss": 20.68679630756378, "val_acc": 48.0}
{"epoch": 48, "training_loss": 83.66286516189575, "training_acc": 41.0, "val_loss": 17.311973869800568, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.22548079490662, "training_acc": 50.0, "val_loss": 17.342805862426758, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.70427823066711, "training_acc": 47.0, "val_loss": 18.125203251838684, "val_acc": 52.0}
{"epoch": 51, "training_loss": 71.00961375236511, "training_acc": 53.0, "val_loss": 20.397058129310608, "val_acc": 48.0}
{"epoch": 52, "training_loss": 76.7458508014679, "training_acc": 47.0, "val_loss": 24.32660013437271, "val_acc": 52.0}
{"epoch": 53, "training_loss": 90.5221757888794, "training_acc": 53.0, "val_loss": 18.518197536468506, "val_acc": 48.0}
{"epoch": 54, "training_loss": 71.93996143341064, "training_acc": 51.0, "val_loss": 19.43824738264084, "val_acc": 52.0}
{"epoch": 55, "training_loss": 74.17839741706848, "training_acc": 51.0, "val_loss": 18.472667038440704, "val_acc": 48.0}
{"epoch": 56, "training_loss": 70.51608872413635, "training_acc": 55.0, "val_loss": 22.673647105693817, "val_acc": 52.0}
{"epoch": 57, "training_loss": 80.60187888145447, "training_acc": 53.0, "val_loss": 23.586411774158478, "val_acc": 48.0}
{"epoch": 58, "training_loss": 101.8497097492218, "training_acc": 39.0, "val_loss": 17.351527512073517, "val_acc": 52.0}
{"epoch": 59, "training_loss": 78.33699893951416, "training_acc": 47.0, "val_loss": 21.659237146377563, "val_acc": 52.0}
{"epoch": 60, "training_loss": 82.50971961021423, "training_acc": 53.0, "val_loss": 20.300614833831787, "val_acc": 48.0}
{"epoch": 61, "training_loss": 87.49824070930481, "training_acc": 37.0, "val_loss": 19.11187320947647, "val_acc": 48.0}
{"epoch": 62, "training_loss": 82.89387607574463, "training_acc": 39.0, "val_loss": 18.979060649871826, "val_acc": 48.0}
{"epoch": 63, "training_loss": 81.30155038833618, "training_acc": 47.0, "val_loss": 33.42519402503967, "val_acc": 52.0}
{"epoch": 64, "training_loss": 122.36296772956848, "training_acc": 53.0, "val_loss": 23.833684623241425, "val_acc": 48.0}
{"epoch": 65, "training_loss": 92.7234570980072, "training_acc": 47.0, "val_loss": 19.826997816562653, "val_acc": 52.0}
{"epoch": 66, "training_loss": 76.60718107223511, "training_acc": 53.0, "val_loss": 18.775703012943268, "val_acc": 48.0}
{"epoch": 67, "training_loss": 73.56786108016968, "training_acc": 47.0, "val_loss": 19.14764940738678, "val_acc": 52.0}
