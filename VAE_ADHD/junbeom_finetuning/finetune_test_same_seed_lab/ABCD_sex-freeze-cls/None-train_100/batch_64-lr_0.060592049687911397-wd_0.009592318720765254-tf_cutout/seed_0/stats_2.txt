"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 458.16703033447266, "training_acc": 54.0, "val_loss": 87.64943480491638, "val_acc": 52.0}
{"epoch": 1, "training_loss": 495.815881729126, "training_acc": 51.0, "val_loss": 245.6249237060547, "val_acc": 48.0}
{"epoch": 2, "training_loss": 914.8369255065918, "training_acc": 47.0, "val_loss": 63.387417793273926, "val_acc": 48.0}
{"epoch": 3, "training_loss": 327.313570022583, "training_acc": 47.0, "val_loss": 181.16369247436523, "val_acc": 52.0}
{"epoch": 4, "training_loss": 730.3801898956299, "training_acc": 53.0, "val_loss": 161.1124873161316, "val_acc": 52.0}
{"epoch": 5, "training_loss": 530.6427907943726, "training_acc": 53.0, "val_loss": 25.849369168281555, "val_acc": 48.0}
{"epoch": 6, "training_loss": 186.31161499023438, "training_acc": 47.0, "val_loss": 93.42483282089233, "val_acc": 48.0}
{"epoch": 7, "training_loss": 326.11378383636475, "training_acc": 47.0, "val_loss": 26.685044169425964, "val_acc": 52.0}
{"epoch": 8, "training_loss": 155.6992893218994, "training_acc": 53.0, "val_loss": 54.764920473098755, "val_acc": 52.0}
{"epoch": 9, "training_loss": 172.35922598838806, "training_acc": 53.0, "val_loss": 42.01318919658661, "val_acc": 48.0}
{"epoch": 10, "training_loss": 179.53148555755615, "training_acc": 47.0, "val_loss": 21.883952617645264, "val_acc": 48.0}
{"epoch": 11, "training_loss": 108.0741114616394, "training_acc": 49.0, "val_loss": 47.73549139499664, "val_acc": 52.0}
{"epoch": 12, "training_loss": 159.43678379058838, "training_acc": 53.0, "val_loss": 26.85682475566864, "val_acc": 48.0}
{"epoch": 13, "training_loss": 124.02921676635742, "training_acc": 47.0, "val_loss": 21.079714596271515, "val_acc": 48.0}
{"epoch": 14, "training_loss": 87.2307779788971, "training_acc": 53.0, "val_loss": 36.45191192626953, "val_acc": 52.0}
{"epoch": 15, "training_loss": 120.33034586906433, "training_acc": 53.0, "val_loss": 28.622791171073914, "val_acc": 48.0}
{"epoch": 16, "training_loss": 122.61415147781372, "training_acc": 47.0, "val_loss": 17.34682470560074, "val_acc": 52.0}
{"epoch": 17, "training_loss": 83.71273851394653, "training_acc": 51.0, "val_loss": 28.063613176345825, "val_acc": 52.0}
{"epoch": 18, "training_loss": 93.28830480575562, "training_acc": 53.0, "val_loss": 28.846493363380432, "val_acc": 48.0}
{"epoch": 19, "training_loss": 105.73400521278381, "training_acc": 47.0, "val_loss": 22.237978875637054, "val_acc": 52.0}
{"epoch": 20, "training_loss": 91.61165165901184, "training_acc": 53.0, "val_loss": 17.33025312423706, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.50011372566223, "training_acc": 58.0, "val_loss": 20.572945475578308, "val_acc": 48.0}
{"epoch": 22, "training_loss": 84.9796781539917, "training_acc": 45.0, "val_loss": 19.973649084568024, "val_acc": 52.0}
{"epoch": 23, "training_loss": 75.95139074325562, "training_acc": 51.0, "val_loss": 19.764883816242218, "val_acc": 48.0}
{"epoch": 24, "training_loss": 74.18610143661499, "training_acc": 47.0, "val_loss": 22.775496542453766, "val_acc": 52.0}
{"epoch": 25, "training_loss": 85.78927540779114, "training_acc": 53.0, "val_loss": 20.615726709365845, "val_acc": 48.0}
{"epoch": 26, "training_loss": 81.96040749549866, "training_acc": 47.0, "val_loss": 17.331553995609283, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.5507321357727, "training_acc": 53.0, "val_loss": 19.31971311569214, "val_acc": 52.0}
{"epoch": 28, "training_loss": 77.67335844039917, "training_acc": 45.0, "val_loss": 17.3716738820076, "val_acc": 52.0}
{"epoch": 29, "training_loss": 75.60520935058594, "training_acc": 41.0, "val_loss": 17.980769276618958, "val_acc": 52.0}
{"epoch": 30, "training_loss": 72.21218609809875, "training_acc": 47.0, "val_loss": 17.317430675029755, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.07312560081482, "training_acc": 53.0, "val_loss": 17.339183390140533, "val_acc": 52.0}
{"epoch": 32, "training_loss": 84.59338808059692, "training_acc": 37.0, "val_loss": 21.49246037006378, "val_acc": 52.0}
{"epoch": 33, "training_loss": 86.12720894813538, "training_acc": 53.0, "val_loss": 17.81054139137268, "val_acc": 52.0}
{"epoch": 34, "training_loss": 84.05478858947754, "training_acc": 47.0, "val_loss": 18.523822724819183, "val_acc": 52.0}
{"epoch": 35, "training_loss": 74.52674055099487, "training_acc": 53.0, "val_loss": 18.169794976711273, "val_acc": 52.0}
{"epoch": 36, "training_loss": 85.95791101455688, "training_acc": 43.0, "val_loss": 17.41969585418701, "val_acc": 52.0}
{"epoch": 37, "training_loss": 80.73958826065063, "training_acc": 53.0, "val_loss": 17.324596643447876, "val_acc": 52.0}
{"epoch": 38, "training_loss": 74.19591999053955, "training_acc": 53.0, "val_loss": 17.523208260536194, "val_acc": 52.0}
{"epoch": 39, "training_loss": 72.7133641242981, "training_acc": 51.0, "val_loss": 18.571248650550842, "val_acc": 52.0}
{"epoch": 40, "training_loss": 75.11001992225647, "training_acc": 51.0, "val_loss": 18.18360537290573, "val_acc": 52.0}
{"epoch": 41, "training_loss": 74.58457899093628, "training_acc": 49.0, "val_loss": 18.34774613380432, "val_acc": 52.0}
{"epoch": 42, "training_loss": 73.69602942466736, "training_acc": 51.0, "val_loss": 17.88603514432907, "val_acc": 52.0}
{"epoch": 43, "training_loss": 71.36981248855591, "training_acc": 51.0, "val_loss": 18.579234182834625, "val_acc": 52.0}
{"epoch": 44, "training_loss": 71.67878699302673, "training_acc": 53.0, "val_loss": 18.814988434314728, "val_acc": 48.0}
{"epoch": 45, "training_loss": 76.30209851264954, "training_acc": 47.0, "val_loss": 17.84338653087616, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.20067930221558, "training_acc": 55.0, "val_loss": 18.938495218753815, "val_acc": 48.0}
{"epoch": 47, "training_loss": 74.49271440505981, "training_acc": 49.0, "val_loss": 18.58140528202057, "val_acc": 52.0}
{"epoch": 48, "training_loss": 71.34497499465942, "training_acc": 53.0, "val_loss": 18.84065717458725, "val_acc": 48.0}
{"epoch": 49, "training_loss": 71.79705119132996, "training_acc": 53.0, "val_loss": 21.054038405418396, "val_acc": 52.0}
