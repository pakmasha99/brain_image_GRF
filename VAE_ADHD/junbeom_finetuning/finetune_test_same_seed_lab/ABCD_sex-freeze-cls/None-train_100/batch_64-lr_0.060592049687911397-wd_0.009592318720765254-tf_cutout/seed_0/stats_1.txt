"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 664.8596649169922, "training_acc": 35.0, "val_loss": 139.33786153793335, "val_acc": 52.0}
{"epoch": 1, "training_loss": 497.75842571258545, "training_acc": 49.0, "val_loss": 146.1229681968689, "val_acc": 48.0}
{"epoch": 2, "training_loss": 532.8937549591064, "training_acc": 47.0, "val_loss": 17.43806004524231, "val_acc": 52.0}
{"epoch": 3, "training_loss": 178.8004331588745, "training_acc": 53.0, "val_loss": 103.90479564666748, "val_acc": 52.0}
{"epoch": 4, "training_loss": 351.8202714920044, "training_acc": 53.0, "val_loss": 20.501689612865448, "val_acc": 48.0}
{"epoch": 5, "training_loss": 113.52322101593018, "training_acc": 47.0, "val_loss": 56.14267587661743, "val_acc": 48.0}
{"epoch": 6, "training_loss": 176.91059112548828, "training_acc": 47.0, "val_loss": 46.559324860572815, "val_acc": 52.0}
{"epoch": 7, "training_loss": 190.77928066253662, "training_acc": 53.0, "val_loss": 23.577898740768433, "val_acc": 52.0}
{"epoch": 8, "training_loss": 117.72289180755615, "training_acc": 51.0, "val_loss": 48.934996128082275, "val_acc": 48.0}
{"epoch": 9, "training_loss": 158.03527545928955, "training_acc": 47.0, "val_loss": 39.24560546875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 165.3479142189026, "training_acc": 53.0, "val_loss": 26.05743110179901, "val_acc": 52.0}
{"epoch": 11, "training_loss": 122.06727027893066, "training_acc": 47.0, "val_loss": 39.662280678749084, "val_acc": 48.0}
{"epoch": 12, "training_loss": 127.93662977218628, "training_acc": 47.0, "val_loss": 35.57754456996918, "val_acc": 52.0}
{"epoch": 13, "training_loss": 142.081440448761, "training_acc": 53.0, "val_loss": 19.26395744085312, "val_acc": 52.0}
{"epoch": 14, "training_loss": 77.72283148765564, "training_acc": 59.0, "val_loss": 34.20214354991913, "val_acc": 48.0}
{"epoch": 15, "training_loss": 119.24798703193665, "training_acc": 45.0, "val_loss": 27.89938747882843, "val_acc": 52.0}
{"epoch": 16, "training_loss": 103.2881510257721, "training_acc": 53.0, "val_loss": 18.374525010585785, "val_acc": 48.0}
{"epoch": 17, "training_loss": 74.63102054595947, "training_acc": 47.0, "val_loss": 17.878958582878113, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.36146354675293, "training_acc": 51.0, "val_loss": 19.306103885173798, "val_acc": 52.0}
{"epoch": 19, "training_loss": 81.52967405319214, "training_acc": 43.0, "val_loss": 17.33722984790802, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.92872643470764, "training_acc": 57.0, "val_loss": 18.45206767320633, "val_acc": 52.0}
{"epoch": 21, "training_loss": 76.17871165275574, "training_acc": 45.0, "val_loss": 17.316551506519318, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.24819850921631, "training_acc": 53.0, "val_loss": 17.376242578029633, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.98939776420593, "training_acc": 51.0, "val_loss": 17.349331080913544, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23634004592896, "training_acc": 51.0, "val_loss": 17.761744558811188, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.2102210521698, "training_acc": 51.0, "val_loss": 17.57102906703949, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.35895490646362, "training_acc": 53.0, "val_loss": 19.020892679691315, "val_acc": 52.0}
{"epoch": 27, "training_loss": 78.10345554351807, "training_acc": 43.0, "val_loss": 17.54806786775589, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.14910507202148, "training_acc": 53.0, "val_loss": 17.445121705532074, "val_acc": 52.0}
{"epoch": 29, "training_loss": 72.83797597885132, "training_acc": 47.0, "val_loss": 20.05864977836609, "val_acc": 52.0}
{"epoch": 30, "training_loss": 79.21812224388123, "training_acc": 53.0, "val_loss": 21.66628986597061, "val_acc": 48.0}
{"epoch": 31, "training_loss": 86.36476469039917, "training_acc": 47.0, "val_loss": 17.326903343200684, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.08047866821289, "training_acc": 53.0, "val_loss": 17.483025789260864, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20583128929138, "training_acc": 53.0, "val_loss": 17.786727845668793, "val_acc": 52.0}
{"epoch": 34, "training_loss": 74.5555579662323, "training_acc": 47.0, "val_loss": 27.353790402412415, "val_acc": 52.0}
{"epoch": 35, "training_loss": 100.16257452964783, "training_acc": 53.0, "val_loss": 24.424506723880768, "val_acc": 48.0}
{"epoch": 36, "training_loss": 96.35346698760986, "training_acc": 47.0, "val_loss": 25.138476490974426, "val_acc": 52.0}
{"epoch": 37, "training_loss": 95.69852876663208, "training_acc": 53.0, "val_loss": 18.58752816915512, "val_acc": 48.0}
{"epoch": 38, "training_loss": 74.63176679611206, "training_acc": 47.0, "val_loss": 17.32647716999054, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.50306630134583, "training_acc": 53.0, "val_loss": 17.337022721767426, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.39398980140686, "training_acc": 54.0, "val_loss": 18.39519441127777, "val_acc": 48.0}
