"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 376.73834228515625, "training_acc": 49.0, "val_loss": 58.983826637268066, "val_acc": 48.0}
{"epoch": 1, "training_loss": 317.8711338043213, "training_acc": 49.0, "val_loss": 172.04608917236328, "val_acc": 52.0}
{"epoch": 2, "training_loss": 657.7168254852295, "training_acc": 53.0, "val_loss": 110.6077790260315, "val_acc": 52.0}
{"epoch": 3, "training_loss": 297.8730516433716, "training_acc": 53.0, "val_loss": 67.70734190940857, "val_acc": 48.0}
{"epoch": 4, "training_loss": 362.8050117492676, "training_acc": 47.0, "val_loss": 125.12102127075195, "val_acc": 48.0}
{"epoch": 5, "training_loss": 469.5762815475464, "training_acc": 47.0, "val_loss": 35.07773578166962, "val_acc": 48.0}
{"epoch": 6, "training_loss": 143.315532207489, "training_acc": 51.0, "val_loss": 79.30530905723572, "val_acc": 52.0}
{"epoch": 7, "training_loss": 326.59497356414795, "training_acc": 53.0, "val_loss": 73.501056432724, "val_acc": 52.0}
{"epoch": 8, "training_loss": 235.59778451919556, "training_acc": 53.0, "val_loss": 25.70105791091919, "val_acc": 48.0}
{"epoch": 9, "training_loss": 155.33604049682617, "training_acc": 47.0, "val_loss": 57.68471956253052, "val_acc": 48.0}
{"epoch": 10, "training_loss": 198.99469661712646, "training_acc": 47.0, "val_loss": 20.413684844970703, "val_acc": 52.0}
{"epoch": 11, "training_loss": 111.86143589019775, "training_acc": 53.0, "val_loss": 47.19686806201935, "val_acc": 52.0}
{"epoch": 12, "training_loss": 165.66290974617004, "training_acc": 53.0, "val_loss": 17.62845814228058, "val_acc": 52.0}
{"epoch": 13, "training_loss": 97.39768981933594, "training_acc": 47.0, "val_loss": 32.271239161491394, "val_acc": 48.0}
{"epoch": 14, "training_loss": 122.2010657787323, "training_acc": 47.0, "val_loss": 22.04362452030182, "val_acc": 52.0}
{"epoch": 15, "training_loss": 88.23580265045166, "training_acc": 53.0, "val_loss": 19.299980998039246, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.0055820941925, "training_acc": 55.0, "val_loss": 22.158458828926086, "val_acc": 48.0}
{"epoch": 17, "training_loss": 86.14927768707275, "training_acc": 47.0, "val_loss": 17.625758051872253, "val_acc": 52.0}
{"epoch": 18, "training_loss": 73.13358926773071, "training_acc": 53.0, "val_loss": 19.41988170146942, "val_acc": 52.0}
{"epoch": 19, "training_loss": 72.33563947677612, "training_acc": 53.0, "val_loss": 19.945712387561798, "val_acc": 48.0}
{"epoch": 20, "training_loss": 79.78389549255371, "training_acc": 47.0, "val_loss": 17.391183972358704, "val_acc": 52.0}
{"epoch": 21, "training_loss": 79.078617811203, "training_acc": 53.0, "val_loss": 18.21460872888565, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.35783886909485, "training_acc": 53.0, "val_loss": 20.325197279453278, "val_acc": 48.0}
{"epoch": 23, "training_loss": 79.41023516654968, "training_acc": 47.0, "val_loss": 18.177171051502228, "val_acc": 52.0}
{"epoch": 24, "training_loss": 72.76467275619507, "training_acc": 53.0, "val_loss": 17.34001189470291, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.51095271110535, "training_acc": 53.0, "val_loss": 18.05073469877243, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.74031519889832, "training_acc": 47.0, "val_loss": 19.403280317783356, "val_acc": 52.0}
{"epoch": 27, "training_loss": 76.81249666213989, "training_acc": 53.0, "val_loss": 17.339178919792175, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.1530110836029, "training_acc": 53.0, "val_loss": 18.41861754655838, "val_acc": 48.0}
{"epoch": 29, "training_loss": 71.74562692642212, "training_acc": 51.0, "val_loss": 19.137145578861237, "val_acc": 52.0}
{"epoch": 30, "training_loss": 74.38089108467102, "training_acc": 53.0, "val_loss": 17.43454486131668, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.76645469665527, "training_acc": 47.0, "val_loss": 17.737315595149994, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.5020341873169, "training_acc": 49.0, "val_loss": 17.845088243484497, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.29554295539856, "training_acc": 53.0, "val_loss": 18.198472261428833, "val_acc": 52.0}
{"epoch": 34, "training_loss": 75.80509996414185, "training_acc": 47.0, "val_loss": 17.34272539615631, "val_acc": 52.0}
{"epoch": 35, "training_loss": 82.34862899780273, "training_acc": 53.0, "val_loss": 17.494285106658936, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.19332432746887, "training_acc": 57.0, "val_loss": 20.890861749649048, "val_acc": 48.0}
{"epoch": 37, "training_loss": 78.12834143638611, "training_acc": 51.0, "val_loss": 21.182076632976532, "val_acc": 52.0}
{"epoch": 38, "training_loss": 81.55050086975098, "training_acc": 53.0, "val_loss": 17.795203626155853, "val_acc": 52.0}
{"epoch": 39, "training_loss": 82.31509351730347, "training_acc": 47.0, "val_loss": 17.343971133232117, "val_acc": 52.0}
{"epoch": 40, "training_loss": 78.0960123538971, "training_acc": 53.0, "val_loss": 19.480618834495544, "val_acc": 52.0}
{"epoch": 41, "training_loss": 72.60927700996399, "training_acc": 55.0, "val_loss": 22.35245853662491, "val_acc": 48.0}
{"epoch": 42, "training_loss": 83.05788493156433, "training_acc": 47.0, "val_loss": 21.207094192504883, "val_acc": 52.0}
{"epoch": 43, "training_loss": 86.38975238800049, "training_acc": 53.0, "val_loss": 17.579074203968048, "val_acc": 52.0}
{"epoch": 44, "training_loss": 85.27684211730957, "training_acc": 47.0, "val_loss": 17.75236874818802, "val_acc": 52.0}
{"epoch": 45, "training_loss": 70.81554388999939, "training_acc": 55.0, "val_loss": 23.953384160995483, "val_acc": 52.0}
{"epoch": 46, "training_loss": 86.4799280166626, "training_acc": 53.0, "val_loss": 20.99626660346985, "val_acc": 48.0}
