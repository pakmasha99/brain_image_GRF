"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 365.50849533081055, "training_acc": 53.0, "val_loss": 60.35574674606323, "val_acc": 52.0}
{"epoch": 1, "training_loss": 379.6880798339844, "training_acc": 43.0, "val_loss": 149.18285608291626, "val_acc": 48.0}
{"epoch": 2, "training_loss": 559.5553035736084, "training_acc": 47.0, "val_loss": 44.28736865520477, "val_acc": 48.0}
{"epoch": 3, "training_loss": 213.85446643829346, "training_acc": 45.0, "val_loss": 102.42246389389038, "val_acc": 52.0}
{"epoch": 4, "training_loss": 414.51952171325684, "training_acc": 53.0, "val_loss": 88.50675821304321, "val_acc": 52.0}
{"epoch": 5, "training_loss": 284.3439245223999, "training_acc": 53.0, "val_loss": 28.979700803756714, "val_acc": 48.0}
{"epoch": 6, "training_loss": 167.906400680542, "training_acc": 47.0, "val_loss": 65.58933854103088, "val_acc": 48.0}
{"epoch": 7, "training_loss": 229.80018520355225, "training_acc": 47.0, "val_loss": 18.99063140153885, "val_acc": 52.0}
{"epoch": 8, "training_loss": 109.790518283844, "training_acc": 53.0, "val_loss": 50.63191056251526, "val_acc": 52.0}
{"epoch": 9, "training_loss": 178.13238525390625, "training_acc": 53.0, "val_loss": 17.30642020702362, "val_acc": 52.0}
{"epoch": 10, "training_loss": 89.50329875946045, "training_acc": 53.0, "val_loss": 38.0144327878952, "val_acc": 48.0}
{"epoch": 11, "training_loss": 134.23386311531067, "training_acc": 47.0, "val_loss": 21.084284782409668, "val_acc": 52.0}
{"epoch": 12, "training_loss": 103.49532508850098, "training_acc": 53.0, "val_loss": 28.027930855751038, "val_acc": 52.0}
{"epoch": 13, "training_loss": 95.12430930137634, "training_acc": 53.0, "val_loss": 25.831767916679382, "val_acc": 48.0}
{"epoch": 14, "training_loss": 105.93115663528442, "training_acc": 47.0, "val_loss": 17.9739773273468, "val_acc": 52.0}
{"epoch": 15, "training_loss": 73.1436665058136, "training_acc": 53.0, "val_loss": 26.318037509918213, "val_acc": 52.0}
{"epoch": 16, "training_loss": 95.42642831802368, "training_acc": 53.0, "val_loss": 19.05907392501831, "val_acc": 48.0}
{"epoch": 17, "training_loss": 92.2171483039856, "training_acc": 47.0, "val_loss": 21.20847851037979, "val_acc": 48.0}
{"epoch": 18, "training_loss": 77.9186224937439, "training_acc": 53.0, "val_loss": 26.501813530921936, "val_acc": 52.0}
{"epoch": 19, "training_loss": 99.78287482261658, "training_acc": 53.0, "val_loss": 17.3095241189003, "val_acc": 52.0}
{"epoch": 20, "training_loss": 71.69732689857483, "training_acc": 55.0, "val_loss": 21.061605215072632, "val_acc": 48.0}
{"epoch": 21, "training_loss": 78.7031819820404, "training_acc": 47.0, "val_loss": 20.72307914495468, "val_acc": 52.0}
{"epoch": 22, "training_loss": 82.28157019615173, "training_acc": 53.0, "val_loss": 17.343463003635406, "val_acc": 52.0}
{"epoch": 23, "training_loss": 78.50421190261841, "training_acc": 45.0, "val_loss": 18.574213981628418, "val_acc": 48.0}
{"epoch": 24, "training_loss": 72.64616751670837, "training_acc": 51.0, "val_loss": 21.037383377552032, "val_acc": 52.0}
{"epoch": 25, "training_loss": 79.2595865726471, "training_acc": 53.0, "val_loss": 18.29761266708374, "val_acc": 52.0}
{"epoch": 26, "training_loss": 75.71612977981567, "training_acc": 47.0, "val_loss": 17.598457634449005, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.60477566719055, "training_acc": 55.0, "val_loss": 20.534612238407135, "val_acc": 52.0}
{"epoch": 28, "training_loss": 79.18968296051025, "training_acc": 53.0, "val_loss": 17.597027122974396, "val_acc": 52.0}
