"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.98378539085388, "training_acc": 47.0, "val_loss": 17.652276158332825, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.81511998176575, "training_acc": 47.0, "val_loss": 17.619243264198303, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.68772196769714, "training_acc": 47.0, "val_loss": 17.587901651859283, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.53307628631592, "training_acc": 47.0, "val_loss": 17.558574676513672, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.39491271972656, "training_acc": 47.0, "val_loss": 17.53094494342804, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.28399586677551, "training_acc": 47.0, "val_loss": 17.505280673503876, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.16563820838928, "training_acc": 47.0, "val_loss": 17.481596767902374, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.04179382324219, "training_acc": 47.0, "val_loss": 17.459632456302643, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.96839213371277, "training_acc": 47.0, "val_loss": 17.44011640548706, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.84651494026184, "training_acc": 47.0, "val_loss": 17.423664033412933, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.74400568008423, "training_acc": 47.0, "val_loss": 17.408473789691925, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.74458312988281, "training_acc": 47.0, "val_loss": 17.394672334194183, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.63777208328247, "training_acc": 47.0, "val_loss": 17.382800579071045, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.59543371200562, "training_acc": 47.0, "val_loss": 17.372697591781616, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.54859757423401, "training_acc": 47.0, "val_loss": 17.363406717777252, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.49582099914551, "training_acc": 47.0, "val_loss": 17.355044186115265, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.44623160362244, "training_acc": 47.0, "val_loss": 17.347446084022522, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.38067531585693, "training_acc": 47.0, "val_loss": 17.340217530727386, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.36860203742981, "training_acc": 47.0, "val_loss": 17.33407974243164, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.33405995368958, "training_acc": 44.0, "val_loss": 17.32918471097946, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.29455304145813, "training_acc": 54.0, "val_loss": 17.325279116630554, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.27183604240417, "training_acc": 53.0, "val_loss": 17.321982979774475, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.2588300704956, "training_acc": 53.0, "val_loss": 17.319032549858093, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.25369596481323, "training_acc": 53.0, "val_loss": 17.31681376695633, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21233296394348, "training_acc": 53.0, "val_loss": 17.3150897026062, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.2068223953247, "training_acc": 53.0, "val_loss": 17.31344908475876, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.20916485786438, "training_acc": 53.0, "val_loss": 17.312397062778473, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17742276191711, "training_acc": 53.0, "val_loss": 17.311644554138184, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17128252983093, "training_acc": 53.0, "val_loss": 17.311029136180878, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19181847572327, "training_acc": 53.0, "val_loss": 17.31068640947342, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16503024101257, "training_acc": 53.0, "val_loss": 17.310556769371033, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15581250190735, "training_acc": 53.0, "val_loss": 17.310577630996704, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17555499076843, "training_acc": 53.0, "val_loss": 17.310702800750732, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12239241600037, "training_acc": 53.0, "val_loss": 17.310969531536102, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15069651603699, "training_acc": 53.0, "val_loss": 17.31129288673401, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14906620979309, "training_acc": 53.0, "val_loss": 17.311616241931915, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12032341957092, "training_acc": 53.0, "val_loss": 17.311960458755493, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12522435188293, "training_acc": 53.0, "val_loss": 17.31230467557907, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14823579788208, "training_acc": 53.0, "val_loss": 17.31269359588623, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11083650588989, "training_acc": 53.0, "val_loss": 17.313125729560852, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14222359657288, "training_acc": 53.0, "val_loss": 17.313605546951294, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12586212158203, "training_acc": 53.0, "val_loss": 17.313899099826813, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12663507461548, "training_acc": 53.0, "val_loss": 17.314229905605316, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.10030436515808, "training_acc": 53.0, "val_loss": 17.314600944519043, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.12469863891602, "training_acc": 53.0, "val_loss": 17.314893007278442, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12276697158813, "training_acc": 53.0, "val_loss": 17.315493524074554, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15334749221802, "training_acc": 53.0, "val_loss": 17.31574982404709, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.14217495918274, "training_acc": 53.0, "val_loss": 17.315784096717834, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.15171718597412, "training_acc": 53.0, "val_loss": 17.315655946731567, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12746834754944, "training_acc": 53.0, "val_loss": 17.315199971199036, "val_acc": 52.0}
