"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24274563789368, "training_acc": 53.0, "val_loss": 17.347651720046997, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1849148273468, "training_acc": 53.0, "val_loss": 17.343468964099884, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16711926460266, "training_acc": 53.0, "val_loss": 17.338821291923523, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2003743648529, "training_acc": 53.0, "val_loss": 17.334432899951935, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2107629776001, "training_acc": 53.0, "val_loss": 17.33049303293228, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.151447057724, "training_acc": 53.0, "val_loss": 17.328263819217682, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12686657905579, "training_acc": 53.0, "val_loss": 17.32601672410965, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15661549568176, "training_acc": 53.0, "val_loss": 17.323581874370575, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15035629272461, "training_acc": 53.0, "val_loss": 17.321354150772095, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.163165807724, "training_acc": 53.0, "val_loss": 17.31961965560913, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16096639633179, "training_acc": 53.0, "val_loss": 17.31831282377243, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1033627986908, "training_acc": 53.0, "val_loss": 17.31785237789154, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13161873817444, "training_acc": 53.0, "val_loss": 17.317569255828857, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14312815666199, "training_acc": 53.0, "val_loss": 17.31678694486618, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1175286769867, "training_acc": 53.0, "val_loss": 17.316527664661407, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12719392776489, "training_acc": 53.0, "val_loss": 17.316249012947083, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13006138801575, "training_acc": 53.0, "val_loss": 17.31598973274231, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14270496368408, "training_acc": 53.0, "val_loss": 17.315398156642914, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12195992469788, "training_acc": 53.0, "val_loss": 17.31497198343277, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13540744781494, "training_acc": 53.0, "val_loss": 17.314687371253967, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14163064956665, "training_acc": 53.0, "val_loss": 17.314304411411285, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13873767852783, "training_acc": 53.0, "val_loss": 17.31414496898651, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1526927947998, "training_acc": 53.0, "val_loss": 17.314185202121735, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11264181137085, "training_acc": 53.0, "val_loss": 17.31410026550293, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10606122016907, "training_acc": 53.0, "val_loss": 17.313794791698456, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15583038330078, "training_acc": 53.0, "val_loss": 17.31352061033249, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14084196090698, "training_acc": 53.0, "val_loss": 17.313258349895477, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11693477630615, "training_acc": 53.0, "val_loss": 17.313221096992493, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12518262863159, "training_acc": 53.0, "val_loss": 17.313125729560852, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1192319393158, "training_acc": 53.0, "val_loss": 17.313414812088013, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.09309124946594, "training_acc": 53.0, "val_loss": 17.314285039901733, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12246251106262, "training_acc": 53.0, "val_loss": 17.31511801481247, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.09766507148743, "training_acc": 53.0, "val_loss": 17.315547168254852, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.09036254882812, "training_acc": 53.0, "val_loss": 17.31618344783783, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16163372993469, "training_acc": 53.0, "val_loss": 17.316512763500214, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.12115168571472, "training_acc": 53.0, "val_loss": 17.317038774490356, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12698602676392, "training_acc": 53.0, "val_loss": 17.317628860473633, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11577367782593, "training_acc": 53.0, "val_loss": 17.31812208890915, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14220261573792, "training_acc": 53.0, "val_loss": 17.318828403949738, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14084959030151, "training_acc": 53.0, "val_loss": 17.319034039974213, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13424396514893, "training_acc": 53.0, "val_loss": 17.319194972515106, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13762092590332, "training_acc": 53.0, "val_loss": 17.319467663764954, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14244079589844, "training_acc": 53.0, "val_loss": 17.319530248641968, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16564559936523, "training_acc": 53.0, "val_loss": 17.319871485233307, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1287739276886, "training_acc": 53.0, "val_loss": 17.319875955581665, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.13854956626892, "training_acc": 53.0, "val_loss": 17.319723963737488, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13748931884766, "training_acc": 53.0, "val_loss": 17.31961816549301, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13528203964233, "training_acc": 53.0, "val_loss": 17.319269478321075, "val_acc": 52.0}
