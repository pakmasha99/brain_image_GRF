"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31620860099792, "training_acc": 46.0, "val_loss": 17.330874502658844, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30690002441406, "training_acc": 47.0, "val_loss": 17.324727773666382, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23719358444214, "training_acc": 53.0, "val_loss": 17.31983721256256, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22307395935059, "training_acc": 53.0, "val_loss": 17.316752672195435, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16171884536743, "training_acc": 53.0, "val_loss": 17.31559783220291, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17358136177063, "training_acc": 53.0, "val_loss": 17.3144668340683, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14026379585266, "training_acc": 53.0, "val_loss": 17.313793301582336, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14090847969055, "training_acc": 53.0, "val_loss": 17.313386499881744, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14386677742004, "training_acc": 53.0, "val_loss": 17.313331365585327, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16563105583191, "training_acc": 53.0, "val_loss": 17.313610017299652, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12690615653992, "training_acc": 53.0, "val_loss": 17.314012348651886, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13353776931763, "training_acc": 53.0, "val_loss": 17.314502596855164, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10275268554688, "training_acc": 53.0, "val_loss": 17.314818501472473, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12375712394714, "training_acc": 53.0, "val_loss": 17.31523424386978, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13633131980896, "training_acc": 53.0, "val_loss": 17.315766215324402, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11927127838135, "training_acc": 53.0, "val_loss": 17.316286265850067, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14019417762756, "training_acc": 53.0, "val_loss": 17.316660284996033, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14535117149353, "training_acc": 53.0, "val_loss": 17.31748878955841, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1470115184784, "training_acc": 53.0, "val_loss": 17.318029701709747, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12392449378967, "training_acc": 53.0, "val_loss": 17.31819361448288, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1217873096466, "training_acc": 53.0, "val_loss": 17.318245768547058, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1122100353241, "training_acc": 53.0, "val_loss": 17.318446934223175, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11652779579163, "training_acc": 53.0, "val_loss": 17.318527400493622, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.128751039505, "training_acc": 53.0, "val_loss": 17.318667471408844, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12932324409485, "training_acc": 53.0, "val_loss": 17.318840324878693, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11593627929688, "training_acc": 53.0, "val_loss": 17.319244146347046, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11917614936829, "training_acc": 53.0, "val_loss": 17.319488525390625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11059522628784, "training_acc": 53.0, "val_loss": 17.319531738758087, "val_acc": 52.0}
