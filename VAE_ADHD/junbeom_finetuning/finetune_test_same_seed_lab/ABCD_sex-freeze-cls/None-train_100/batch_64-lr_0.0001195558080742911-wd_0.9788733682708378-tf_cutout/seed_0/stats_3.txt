"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24660229682922, "training_acc": 53.0, "val_loss": 17.307700216770172, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.28183031082153, "training_acc": 53.0, "val_loss": 17.31078326702118, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14546084403992, "training_acc": 53.0, "val_loss": 17.310409247875214, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1341347694397, "training_acc": 53.0, "val_loss": 17.31206476688385, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18745279312134, "training_acc": 53.0, "val_loss": 17.31417179107666, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1311399936676, "training_acc": 53.0, "val_loss": 17.31170415878296, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12502217292786, "training_acc": 53.0, "val_loss": 17.30991005897522, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15744709968567, "training_acc": 53.0, "val_loss": 17.308244109153748, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14341402053833, "training_acc": 53.0, "val_loss": 17.30768233537674, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14169049263, "training_acc": 53.0, "val_loss": 17.308203876018524, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1742742061615, "training_acc": 53.0, "val_loss": 17.30867475271225, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17789602279663, "training_acc": 53.0, "val_loss": 17.308354377746582, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1778404712677, "training_acc": 53.0, "val_loss": 17.30775386095047, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14334845542908, "training_acc": 53.0, "val_loss": 17.307700216770172, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13555598258972, "training_acc": 53.0, "val_loss": 17.308102548122406, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14087772369385, "training_acc": 53.0, "val_loss": 17.309169471263885, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14519095420837, "training_acc": 53.0, "val_loss": 17.31036752462387, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16460299491882, "training_acc": 53.0, "val_loss": 17.310895025730133, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13643717765808, "training_acc": 53.0, "val_loss": 17.31434017419815, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16792702674866, "training_acc": 53.0, "val_loss": 17.320483922958374, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23487520217896, "training_acc": 53.0, "val_loss": 17.325100302696228, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15929555892944, "training_acc": 53.0, "val_loss": 17.32262223958969, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17204356193542, "training_acc": 53.0, "val_loss": 17.31797605752945, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13202595710754, "training_acc": 53.0, "val_loss": 17.31628328561783, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12348890304565, "training_acc": 53.0, "val_loss": 17.31598675251007, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15726828575134, "training_acc": 53.0, "val_loss": 17.315298318862915, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16127324104309, "training_acc": 53.0, "val_loss": 17.315921187400818, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14993596076965, "training_acc": 53.0, "val_loss": 17.315012216567993, "val_acc": 52.0}
