"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25266337394714, "training_acc": 52.0, "val_loss": 17.249183356761932, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2505111694336, "training_acc": 52.0, "val_loss": 17.21113920211792, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.27166891098022, "training_acc": 52.0, "val_loss": 17.209134995937347, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26284408569336, "training_acc": 52.0, "val_loss": 17.228733003139496, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24315309524536, "training_acc": 52.0, "val_loss": 17.25919246673584, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23460340499878, "training_acc": 52.0, "val_loss": 17.269743978977203, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27389526367188, "training_acc": 52.0, "val_loss": 17.287880182266235, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.28073215484619, "training_acc": 52.0, "val_loss": 17.2896146774292, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.31526374816895, "training_acc": 52.0, "val_loss": 17.271998524665833, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26394653320312, "training_acc": 52.0, "val_loss": 17.270323634147644, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23570370674133, "training_acc": 52.0, "val_loss": 17.26602017879486, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26495742797852, "training_acc": 52.0, "val_loss": 17.25570112466812, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23546624183655, "training_acc": 52.0, "val_loss": 17.246443033218384, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23369789123535, "training_acc": 52.0, "val_loss": 17.243987321853638, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24109482765198, "training_acc": 52.0, "val_loss": 17.235206067562103, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24677681922913, "training_acc": 52.0, "val_loss": 17.223773896694183, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25329899787903, "training_acc": 52.0, "val_loss": 17.20820516347885, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24026942253113, "training_acc": 52.0, "val_loss": 17.20123589038849, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2523238658905, "training_acc": 52.0, "val_loss": 17.19832569360733, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26775336265564, "training_acc": 52.0, "val_loss": 17.198878526687622, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22099184989929, "training_acc": 52.0, "val_loss": 17.205744981765747, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2415726184845, "training_acc": 52.0, "val_loss": 17.210906744003296, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29004406929016, "training_acc": 52.0, "val_loss": 17.20925271511078, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25378775596619, "training_acc": 52.0, "val_loss": 17.218993604183197, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24909210205078, "training_acc": 52.0, "val_loss": 17.234523594379425, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25543308258057, "training_acc": 52.0, "val_loss": 17.25456267595291, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.30840277671814, "training_acc": 52.0, "val_loss": 17.25945770740509, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23740482330322, "training_acc": 52.0, "val_loss": 17.281562089920044, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.27972722053528, "training_acc": 52.0, "val_loss": 17.29751229286194, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.29082584381104, "training_acc": 52.0, "val_loss": 17.29302704334259, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.33740043640137, "training_acc": 52.0, "val_loss": 17.276057600975037, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29353952407837, "training_acc": 52.0, "val_loss": 17.27573126554489, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.2582368850708, "training_acc": 52.0, "val_loss": 17.25658029317856, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24774599075317, "training_acc": 52.0, "val_loss": 17.241565883159637, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26354336738586, "training_acc": 52.0, "val_loss": 17.225326597690582, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23559331893921, "training_acc": 52.0, "val_loss": 17.21782088279724, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23663115501404, "training_acc": 52.0, "val_loss": 17.212527990341187, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.25032687187195, "training_acc": 52.0, "val_loss": 17.20779985189438, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.24169635772705, "training_acc": 52.0, "val_loss": 17.197689414024353, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.27988147735596, "training_acc": 52.0, "val_loss": 17.184633016586304, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.26078128814697, "training_acc": 52.0, "val_loss": 17.182965576648712, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2841694355011, "training_acc": 52.0, "val_loss": 17.184700071811676, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28462672233582, "training_acc": 52.0, "val_loss": 17.188861966133118, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23765659332275, "training_acc": 52.0, "val_loss": 17.2001451253891, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.2641453742981, "training_acc": 52.0, "val_loss": 17.22389906644821, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.22849655151367, "training_acc": 52.0, "val_loss": 17.243333160877228, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25321793556213, "training_acc": 52.0, "val_loss": 17.264342308044434, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.26483607292175, "training_acc": 52.0, "val_loss": 17.28188544511795, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.25155758857727, "training_acc": 52.0, "val_loss": 17.283473908901215, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.26648139953613, "training_acc": 52.0, "val_loss": 17.28076934814453, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.27998042106628, "training_acc": 52.0, "val_loss": 17.281582951545715, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.27353930473328, "training_acc": 52.0, "val_loss": 17.282085120677948, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.28051376342773, "training_acc": 52.0, "val_loss": 17.278864979743958, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27918195724487, "training_acc": 52.0, "val_loss": 17.27641671895981, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22625660896301, "training_acc": 52.0, "val_loss": 17.271974682807922, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27278113365173, "training_acc": 52.0, "val_loss": 17.25950986146927, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.2474091053009, "training_acc": 52.0, "val_loss": 17.254504561424255, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2376024723053, "training_acc": 52.0, "val_loss": 17.253242433071136, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22891187667847, "training_acc": 52.0, "val_loss": 17.245857417583466, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25191450119019, "training_acc": 52.0, "val_loss": 17.240823805332184, "val_acc": 56.0}
