"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 162.96320915222168, "training_acc": 53.0, "val_loss": 32.84922242164612, "val_acc": 52.0}
{"epoch": 1, "training_loss": 130.359637260437, "training_acc": 59.0, "val_loss": 68.90929341316223, "val_acc": 48.0}
{"epoch": 2, "training_loss": 249.72790622711182, "training_acc": 47.0, "val_loss": 17.346739768981934, "val_acc": 52.0}
{"epoch": 3, "training_loss": 86.54122161865234, "training_acc": 55.0, "val_loss": 48.3028769493103, "val_acc": 52.0}
{"epoch": 4, "training_loss": 179.92923259735107, "training_acc": 53.0, "val_loss": 22.1535786986351, "val_acc": 52.0}
{"epoch": 5, "training_loss": 92.60721921920776, "training_acc": 49.0, "val_loss": 36.68200969696045, "val_acc": 48.0}
{"epoch": 6, "training_loss": 149.21531915664673, "training_acc": 47.0, "val_loss": 21.92949801683426, "val_acc": 48.0}
{"epoch": 7, "training_loss": 80.32086443901062, "training_acc": 53.0, "val_loss": 30.92433214187622, "val_acc": 52.0}
{"epoch": 8, "training_loss": 124.0262804031372, "training_acc": 53.0, "val_loss": 27.387413382530212, "val_acc": 52.0}
{"epoch": 9, "training_loss": 94.79006791114807, "training_acc": 53.0, "val_loss": 20.59043049812317, "val_acc": 48.0}
{"epoch": 10, "training_loss": 92.40188646316528, "training_acc": 47.0, "val_loss": 24.66508597135544, "val_acc": 48.0}
{"epoch": 11, "training_loss": 89.68673944473267, "training_acc": 47.0, "val_loss": 19.179415702819824, "val_acc": 52.0}
{"epoch": 12, "training_loss": 83.15935468673706, "training_acc": 53.0, "val_loss": 23.928973078727722, "val_acc": 52.0}
{"epoch": 13, "training_loss": 88.55022883415222, "training_acc": 53.0, "val_loss": 17.707473039627075, "val_acc": 52.0}
{"epoch": 14, "training_loss": 80.33144736289978, "training_acc": 47.0, "val_loss": 20.19788920879364, "val_acc": 48.0}
{"epoch": 15, "training_loss": 77.44338274002075, "training_acc": 47.0, "val_loss": 18.737289309501648, "val_acc": 52.0}
{"epoch": 16, "training_loss": 75.22586607933044, "training_acc": 53.0, "val_loss": 19.624502956867218, "val_acc": 52.0}
{"epoch": 17, "training_loss": 74.08013129234314, "training_acc": 53.0, "val_loss": 17.872577905654907, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.83330774307251, "training_acc": 47.0, "val_loss": 19.228316843509674, "val_acc": 48.0}
{"epoch": 19, "training_loss": 75.1522011756897, "training_acc": 47.0, "val_loss": 17.5811767578125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.86529159545898, "training_acc": 53.0, "val_loss": 18.848800659179688, "val_acc": 52.0}
{"epoch": 21, "training_loss": 77.34961676597595, "training_acc": 53.0, "val_loss": 17.50616729259491, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.11224389076233, "training_acc": 47.0, "val_loss": 17.306338250637054, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.09875822067261, "training_acc": 53.0, "val_loss": 17.609350383281708, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.32903218269348, "training_acc": 53.0, "val_loss": 17.34735071659088, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.57160186767578, "training_acc": 53.0, "val_loss": 17.333097755908966, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.63808870315552, "training_acc": 47.0, "val_loss": 17.421744763851166, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.82430243492126, "training_acc": 43.0, "val_loss": 17.38584041595459, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.60966110229492, "training_acc": 43.0, "val_loss": 17.316560447216034, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.03761792182922, "training_acc": 53.0, "val_loss": 17.584168910980225, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.967205286026, "training_acc": 53.0, "val_loss": 17.30753928422928, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.46888661384583, "training_acc": 51.0, "val_loss": 17.48107075691223, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.66479635238647, "training_acc": 47.0, "val_loss": 17.67553985118866, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.66382050514221, "training_acc": 53.0, "val_loss": 17.6960289478302, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.38897347450256, "training_acc": 52.0, "val_loss": 17.57841259241104, "val_acc": 52.0}
{"epoch": 35, "training_loss": 71.30098819732666, "training_acc": 41.0, "val_loss": 17.323945462703705, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.3628945350647, "training_acc": 49.0, "val_loss": 17.327220737934113, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.28380966186523, "training_acc": 53.0, "val_loss": 17.40596294403076, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.5192642211914, "training_acc": 53.0, "val_loss": 17.32179820537567, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.33534145355225, "training_acc": 53.0, "val_loss": 17.3151895403862, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.44170355796814, "training_acc": 48.0, "val_loss": 17.347031831741333, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.31813764572144, "training_acc": 53.0, "val_loss": 17.38048642873764, "val_acc": 52.0}
