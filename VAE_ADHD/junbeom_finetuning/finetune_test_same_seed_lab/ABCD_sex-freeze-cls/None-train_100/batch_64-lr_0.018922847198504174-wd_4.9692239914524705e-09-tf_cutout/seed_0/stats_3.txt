"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 230.69297409057617, "training_acc": 37.0, "val_loss": 40.22684097290039, "val_acc": 52.0}
{"epoch": 1, "training_loss": 154.13653087615967, "training_acc": 51.0, "val_loss": 58.58196020126343, "val_acc": 48.0}
{"epoch": 2, "training_loss": 223.84792041778564, "training_acc": 47.0, "val_loss": 21.810385584831238, "val_acc": 48.0}
{"epoch": 3, "training_loss": 96.1233925819397, "training_acc": 49.0, "val_loss": 44.38110888004303, "val_acc": 52.0}
{"epoch": 4, "training_loss": 172.80200815200806, "training_acc": 53.0, "val_loss": 31.032410264015198, "val_acc": 52.0}
{"epoch": 5, "training_loss": 102.92860889434814, "training_acc": 53.0, "val_loss": 25.65912902355194, "val_acc": 48.0}
{"epoch": 6, "training_loss": 109.70739817619324, "training_acc": 47.0, "val_loss": 29.100435972213745, "val_acc": 48.0}
{"epoch": 7, "training_loss": 103.5081512928009, "training_acc": 47.0, "val_loss": 19.02003437280655, "val_acc": 52.0}
{"epoch": 8, "training_loss": 82.6923611164093, "training_acc": 53.0, "val_loss": 27.769461274147034, "val_acc": 52.0}
{"epoch": 9, "training_loss": 101.08833456039429, "training_acc": 53.0, "val_loss": 17.31104850769043, "val_acc": 52.0}
{"epoch": 10, "training_loss": 73.64454698562622, "training_acc": 55.0, "val_loss": 26.987561583518982, "val_acc": 48.0}
{"epoch": 11, "training_loss": 104.90941905975342, "training_acc": 47.0, "val_loss": 17.68854409456253, "val_acc": 52.0}
{"epoch": 12, "training_loss": 73.88638257980347, "training_acc": 49.0, "val_loss": 24.50886219739914, "val_acc": 52.0}
{"epoch": 13, "training_loss": 94.39719414710999, "training_acc": 53.0, "val_loss": 18.643584847450256, "val_acc": 52.0}
{"epoch": 14, "training_loss": 67.75852704048157, "training_acc": 53.0, "val_loss": 20.763148367404938, "val_acc": 48.0}
{"epoch": 15, "training_loss": 88.38773965835571, "training_acc": 47.0, "val_loss": 19.34679001569748, "val_acc": 48.0}
{"epoch": 16, "training_loss": 80.32686161994934, "training_acc": 41.0, "val_loss": 20.21831125020981, "val_acc": 52.0}
{"epoch": 17, "training_loss": 79.63039040565491, "training_acc": 53.0, "val_loss": 18.038858473300934, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.18269658088684, "training_acc": 53.0, "val_loss": 18.92544776201248, "val_acc": 48.0}
{"epoch": 19, "training_loss": 76.41893696784973, "training_acc": 47.0, "val_loss": 17.53433495759964, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.08188247680664, "training_acc": 53.0, "val_loss": 19.074374437332153, "val_acc": 52.0}
{"epoch": 21, "training_loss": 75.18910932540894, "training_acc": 53.0, "val_loss": 17.610259354114532, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.00157284736633, "training_acc": 51.0, "val_loss": 18.23917329311371, "val_acc": 52.0}
{"epoch": 23, "training_loss": 73.46231007575989, "training_acc": 47.0, "val_loss": 17.31957197189331, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.26502203941345, "training_acc": 53.0, "val_loss": 19.097240269184113, "val_acc": 52.0}
{"epoch": 25, "training_loss": 75.61801171302795, "training_acc": 53.0, "val_loss": 17.415259778499603, "val_acc": 52.0}
{"epoch": 26, "training_loss": 76.96168446540833, "training_acc": 47.0, "val_loss": 19.458772242069244, "val_acc": 48.0}
{"epoch": 27, "training_loss": 76.93672776222229, "training_acc": 45.0, "val_loss": 18.61511319875717, "val_acc": 52.0}
{"epoch": 28, "training_loss": 75.09547734260559, "training_acc": 53.0, "val_loss": 17.784468829631805, "val_acc": 52.0}
