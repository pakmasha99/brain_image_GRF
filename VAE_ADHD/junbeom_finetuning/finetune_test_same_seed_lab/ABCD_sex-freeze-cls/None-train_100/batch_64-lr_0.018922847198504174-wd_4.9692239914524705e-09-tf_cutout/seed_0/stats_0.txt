"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 196.69286155700684, "training_acc": 50.0, "val_loss": 31.71657919883728, "val_acc": 44.0}
{"epoch": 1, "training_loss": 163.77994346618652, "training_acc": 48.0, "val_loss": 71.72739505767822, "val_acc": 56.0}
{"epoch": 2, "training_loss": 297.52124404907227, "training_acc": 52.0, "val_loss": 34.47224497795105, "val_acc": 56.0}
{"epoch": 3, "training_loss": 116.80366444587708, "training_acc": 54.0, "val_loss": 48.11255931854248, "val_acc": 44.0}
{"epoch": 4, "training_loss": 192.52057266235352, "training_acc": 48.0, "val_loss": 46.70226871967316, "val_acc": 44.0}
{"epoch": 5, "training_loss": 148.19551491737366, "training_acc": 48.0, "val_loss": 20.309169590473175, "val_acc": 56.0}
{"epoch": 6, "training_loss": 104.68203115463257, "training_acc": 52.0, "val_loss": 33.89006853103638, "val_acc": 56.0}
{"epoch": 7, "training_loss": 135.41244745254517, "training_acc": 52.0, "val_loss": 17.27357655763626, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.50236868858337, "training_acc": 58.0, "val_loss": 32.0463627576828, "val_acc": 44.0}
{"epoch": 9, "training_loss": 117.92112112045288, "training_acc": 48.0, "val_loss": 21.39541804790497, "val_acc": 44.0}
{"epoch": 10, "training_loss": 77.70109486579895, "training_acc": 50.0, "val_loss": 22.24932760000229, "val_acc": 56.0}
{"epoch": 11, "training_loss": 98.72975444793701, "training_acc": 52.0, "val_loss": 19.951215386390686, "val_acc": 56.0}
{"epoch": 12, "training_loss": 77.24661755561829, "training_acc": 52.0, "val_loss": 22.058987617492676, "val_acc": 44.0}
{"epoch": 13, "training_loss": 89.70948696136475, "training_acc": 48.0, "val_loss": 22.066834568977356, "val_acc": 44.0}
{"epoch": 14, "training_loss": 77.53443646430969, "training_acc": 48.0, "val_loss": 18.93044263124466, "val_acc": 56.0}
{"epoch": 15, "training_loss": 82.13336682319641, "training_acc": 52.0, "val_loss": 19.573913514614105, "val_acc": 56.0}
{"epoch": 16, "training_loss": 77.94060945510864, "training_acc": 52.0, "val_loss": 19.007323682308197, "val_acc": 44.0}
{"epoch": 17, "training_loss": 77.54140496253967, "training_acc": 48.0, "val_loss": 20.45697420835495, "val_acc": 44.0}
{"epoch": 18, "training_loss": 75.13837051391602, "training_acc": 48.0, "val_loss": 17.771756649017334, "val_acc": 56.0}
{"epoch": 19, "training_loss": 76.47799229621887, "training_acc": 52.0, "val_loss": 17.890551686286926, "val_acc": 56.0}
{"epoch": 20, "training_loss": 73.558922290802, "training_acc": 51.0, "val_loss": 18.994373083114624, "val_acc": 44.0}
{"epoch": 21, "training_loss": 75.26371502876282, "training_acc": 48.0, "val_loss": 17.73272156715393, "val_acc": 56.0}
{"epoch": 22, "training_loss": 72.99092483520508, "training_acc": 44.0, "val_loss": 17.878776788711548, "val_acc": 56.0}
{"epoch": 23, "training_loss": 73.12973427772522, "training_acc": 52.0, "val_loss": 17.49763786792755, "val_acc": 56.0}
{"epoch": 24, "training_loss": 70.14354681968689, "training_acc": 48.0, "val_loss": 19.1346675157547, "val_acc": 44.0}
{"epoch": 25, "training_loss": 72.58902311325073, "training_acc": 48.0, "val_loss": 17.187976837158203, "val_acc": 56.0}
{"epoch": 26, "training_loss": 76.80471730232239, "training_acc": 52.0, "val_loss": 17.332656681537628, "val_acc": 56.0}
{"epoch": 27, "training_loss": 70.39353537559509, "training_acc": 52.0, "val_loss": 19.819030165672302, "val_acc": 44.0}
{"epoch": 28, "training_loss": 76.42166495323181, "training_acc": 48.0, "val_loss": 17.274917662143707, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.98427319526672, "training_acc": 52.0, "val_loss": 18.52719485759735, "val_acc": 56.0}
{"epoch": 30, "training_loss": 76.2672393321991, "training_acc": 52.0, "val_loss": 17.838458716869354, "val_acc": 56.0}
{"epoch": 31, "training_loss": 79.98529171943665, "training_acc": 48.0, "val_loss": 20.148946344852448, "val_acc": 44.0}
{"epoch": 32, "training_loss": 75.31695938110352, "training_acc": 48.0, "val_loss": 18.538272380828857, "val_acc": 56.0}
{"epoch": 33, "training_loss": 77.7835841178894, "training_acc": 52.0, "val_loss": 17.247653007507324, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.42176914215088, "training_acc": 54.0, "val_loss": 19.871388375759125, "val_acc": 44.0}
{"epoch": 35, "training_loss": 75.84035754203796, "training_acc": 48.0, "val_loss": 17.264524102211, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.66311383247375, "training_acc": 52.0, "val_loss": 18.0462583899498, "val_acc": 56.0}
{"epoch": 37, "training_loss": 75.5975353717804, "training_acc": 52.0, "val_loss": 17.352482676506042, "val_acc": 56.0}
{"epoch": 38, "training_loss": 71.7838134765625, "training_acc": 47.0, "val_loss": 17.2903835773468, "val_acc": 56.0}
{"epoch": 39, "training_loss": 71.80079245567322, "training_acc": 52.0, "val_loss": 17.270633578300476, "val_acc": 56.0}
{"epoch": 40, "training_loss": 70.35470771789551, "training_acc": 52.0, "val_loss": 18.04901510477066, "val_acc": 56.0}
{"epoch": 41, "training_loss": 70.9097068309784, "training_acc": 48.0, "val_loss": 17.266172170639038, "val_acc": 56.0}
{"epoch": 42, "training_loss": 71.34574937820435, "training_acc": 52.0, "val_loss": 17.17887967824936, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.14630913734436, "training_acc": 52.0, "val_loss": 18.673767149448395, "val_acc": 56.0}
{"epoch": 44, "training_loss": 74.29153656959534, "training_acc": 48.0, "val_loss": 17.59296804666519, "val_acc": 56.0}
{"epoch": 45, "training_loss": 72.20720314979553, "training_acc": 46.0, "val_loss": 17.786327004432678, "val_acc": 56.0}
{"epoch": 46, "training_loss": 72.17519402503967, "training_acc": 52.0, "val_loss": 18.142448365688324, "val_acc": 56.0}
{"epoch": 47, "training_loss": 73.67949748039246, "training_acc": 48.0, "val_loss": 17.587810754776, "val_acc": 56.0}
{"epoch": 48, "training_loss": 71.11268949508667, "training_acc": 48.0, "val_loss": 17.84229278564453, "val_acc": 56.0}
{"epoch": 49, "training_loss": 72.41398334503174, "training_acc": 52.0, "val_loss": 18.263480067253113, "val_acc": 56.0}
{"epoch": 50, "training_loss": 72.47433805465698, "training_acc": 48.0, "val_loss": 18.595191836357117, "val_acc": 56.0}
{"epoch": 51, "training_loss": 71.92974042892456, "training_acc": 48.0, "val_loss": 17.599095404148102, "val_acc": 56.0}
{"epoch": 52, "training_loss": 72.80909752845764, "training_acc": 52.0, "val_loss": 17.386598885059357, "val_acc": 56.0}
{"epoch": 53, "training_loss": 70.35290884971619, "training_acc": 48.0, "val_loss": 18.6703160405159, "val_acc": 56.0}
{"epoch": 54, "training_loss": 70.97212338447571, "training_acc": 48.0, "val_loss": 17.496006190776825, "val_acc": 56.0}
{"epoch": 55, "training_loss": 74.43720436096191, "training_acc": 52.0, "val_loss": 17.18013286590576, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.42569398880005, "training_acc": 54.0, "val_loss": 19.800765812397003, "val_acc": 44.0}
{"epoch": 57, "training_loss": 73.91374230384827, "training_acc": 48.0, "val_loss": 17.403316497802734, "val_acc": 56.0}
{"epoch": 58, "training_loss": 74.01745700836182, "training_acc": 52.0, "val_loss": 17.31058806180954, "val_acc": 56.0}
{"epoch": 59, "training_loss": 73.5276792049408, "training_acc": 46.0, "val_loss": 18.979163467884064, "val_acc": 44.0}
{"epoch": 60, "training_loss": 73.77599787712097, "training_acc": 44.0, "val_loss": 17.19595342874527, "val_acc": 56.0}
{"epoch": 61, "training_loss": 70.05469417572021, "training_acc": 52.0, "val_loss": 17.22719669342041, "val_acc": 56.0}
