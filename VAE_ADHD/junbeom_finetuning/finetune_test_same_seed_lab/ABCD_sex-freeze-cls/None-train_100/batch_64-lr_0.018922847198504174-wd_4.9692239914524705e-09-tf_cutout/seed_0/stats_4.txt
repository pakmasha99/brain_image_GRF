"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 203.6207447052002, "training_acc": 49.0, "val_loss": 28.77768576145172, "val_acc": 48.0}
{"epoch": 1, "training_loss": 128.81394910812378, "training_acc": 57.0, "val_loss": 87.51954436302185, "val_acc": 52.0}
{"epoch": 2, "training_loss": 337.015061378479, "training_acc": 53.0, "val_loss": 54.11018133163452, "val_acc": 52.0}
{"epoch": 3, "training_loss": 155.4060022830963, "training_acc": 53.0, "val_loss": 41.12744331359863, "val_acc": 48.0}
{"epoch": 4, "training_loss": 192.2463026046753, "training_acc": 47.0, "val_loss": 58.8468074798584, "val_acc": 48.0}
{"epoch": 5, "training_loss": 216.6865315437317, "training_acc": 47.0, "val_loss": 18.196332454681396, "val_acc": 52.0}
{"epoch": 6, "training_loss": 83.34007549285889, "training_acc": 51.0, "val_loss": 41.37812256813049, "val_acc": 52.0}
{"epoch": 7, "training_loss": 162.91322946548462, "training_acc": 53.0, "val_loss": 31.803429126739502, "val_acc": 52.0}
{"epoch": 8, "training_loss": 97.9863634109497, "training_acc": 53.0, "val_loss": 22.923675179481506, "val_acc": 48.0}
{"epoch": 9, "training_loss": 110.60934972763062, "training_acc": 47.0, "val_loss": 35.53292751312256, "val_acc": 48.0}
{"epoch": 10, "training_loss": 128.902437210083, "training_acc": 47.0, "val_loss": 17.31002777814865, "val_acc": 52.0}
{"epoch": 11, "training_loss": 81.40808439254761, "training_acc": 53.0, "val_loss": 31.449779868125916, "val_acc": 52.0}
{"epoch": 12, "training_loss": 119.86813306808472, "training_acc": 53.0, "val_loss": 20.905837416648865, "val_acc": 52.0}
{"epoch": 13, "training_loss": 82.2168869972229, "training_acc": 45.0, "val_loss": 21.541041135787964, "val_acc": 48.0}
{"epoch": 14, "training_loss": 88.1889476776123, "training_acc": 47.0, "val_loss": 19.5185124874115, "val_acc": 48.0}
{"epoch": 15, "training_loss": 77.36813020706177, "training_acc": 45.0, "val_loss": 19.30016279220581, "val_acc": 52.0}
{"epoch": 16, "training_loss": 79.16701054573059, "training_acc": 53.0, "val_loss": 18.79037469625473, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.09010767936707, "training_acc": 53.0, "val_loss": 18.974784016609192, "val_acc": 48.0}
{"epoch": 18, "training_loss": 76.64037275314331, "training_acc": 47.0, "val_loss": 19.353221356868744, "val_acc": 48.0}
{"epoch": 19, "training_loss": 75.90895009040833, "training_acc": 47.0, "val_loss": 17.671485245227814, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.98375082015991, "training_acc": 53.0, "val_loss": 18.978263437747955, "val_acc": 52.0}
{"epoch": 21, "training_loss": 74.25923085212708, "training_acc": 53.0, "val_loss": 17.31012314558029, "val_acc": 52.0}
{"epoch": 22, "training_loss": 73.62337040901184, "training_acc": 45.0, "val_loss": 18.62080693244934, "val_acc": 48.0}
{"epoch": 23, "training_loss": 74.77101111412048, "training_acc": 43.0, "val_loss": 17.654281854629517, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.2686915397644, "training_acc": 53.0, "val_loss": 17.77709722518921, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.37884855270386, "training_acc": 53.0, "val_loss": 17.364270985126495, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.66980862617493, "training_acc": 47.0, "val_loss": 17.365717887878418, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.07564973831177, "training_acc": 41.0, "val_loss": 17.363503575325012, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.04479622840881, "training_acc": 53.0, "val_loss": 17.413905262947083, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.8636269569397, "training_acc": 47.0, "val_loss": 17.310145497322083, "val_acc": 52.0}
