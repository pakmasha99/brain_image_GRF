"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 679672.8955688477, "training_acc": 45.0, "val_loss": 123117.4560546875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 461767.69140625, "training_acc": 59.0, "val_loss": 326237.744140625, "val_acc": 52.0}
{"epoch": 2, "training_loss": 1261980.974609375, "training_acc": 53.0, "val_loss": 240220.1904296875, "val_acc": 52.0}
{"epoch": 3, "training_loss": 764961.4716796875, "training_acc": 53.0, "val_loss": 71728.77807617188, "val_acc": 48.0}
{"epoch": 4, "training_loss": 385950.962890625, "training_acc": 47.0, "val_loss": 139541.30859375, "val_acc": 48.0}
{"epoch": 5, "training_loss": 458935.955078125, "training_acc": 47.0, "val_loss": 47957.09228515625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 268304.51171875, "training_acc": 53.0, "val_loss": 97375.82397460938, "val_acc": 52.0}
{"epoch": 7, "training_loss": 318130.02978515625, "training_acc": 53.0, "val_loss": 45999.83825683594, "val_acc": 48.0}
{"epoch": 8, "training_loss": 236606.3544921875, "training_acc": 47.0, "val_loss": 45376.07421875, "val_acc": 48.0}
{"epoch": 9, "training_loss": 154095.21728515625, "training_acc": 51.0, "val_loss": 53325.45166015625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 181804.00903320312, "training_acc": 53.0, "val_loss": 26121.804809570312, "val_acc": 48.0}
{"epoch": 11, "training_loss": 107095.69897460938, "training_acc": 47.0, "val_loss": 14593.45703125, "val_acc": 52.0}
{"epoch": 12, "training_loss": 50139.45544433594, "training_acc": 53.0, "val_loss": 34713.427734375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 134550.56640625, "training_acc": 47.0, "val_loss": 22507.742309570312, "val_acc": 52.0}
{"epoch": 14, "training_loss": 99036.896484375, "training_acc": 53.0, "val_loss": 763.1341934204102, "val_acc": 48.0}
{"epoch": 15, "training_loss": 13683.593139648438, "training_acc": 55.0, "val_loss": 11923.593139648438, "val_acc": 48.0}
{"epoch": 16, "training_loss": 52088.524169921875, "training_acc": 47.0, "val_loss": 4593.042373657227, "val_acc": 48.0}
{"epoch": 17, "training_loss": 42661.786376953125, "training_acc": 49.0, "val_loss": 7980.207824707031, "val_acc": 52.0}
{"epoch": 18, "training_loss": 90727.609375, "training_acc": 49.0, "val_loss": 47424.14855957031, "val_acc": 48.0}
{"epoch": 19, "training_loss": 132350.8680419922, "training_acc": 47.0, "val_loss": 71842.49267578125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 334942.08984375, "training_acc": 53.0, "val_loss": 95531.23168945312, "val_acc": 52.0}
{"epoch": 21, "training_loss": 308232.53125, "training_acc": 53.0, "val_loss": 28409.710693359375, "val_acc": 48.0}
{"epoch": 22, "training_loss": 171194.150390625, "training_acc": 47.0, "val_loss": 45282.19299316406, "val_acc": 48.0}
{"epoch": 23, "training_loss": 143067.34301757812, "training_acc": 47.0, "val_loss": 26482.94677734375, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69151.02252197266, "training_acc": 53.0, "val_loss": 60327.1240234375, "val_acc": 48.0}
{"epoch": 25, "training_loss": 264437.4248046875, "training_acc": 47.0, "val_loss": 41185.59265136719, "val_acc": 48.0}
{"epoch": 26, "training_loss": 155165.6943359375, "training_acc": 47.0, "val_loss": 52637.457275390625, "val_acc": 52.0}
{"epoch": 27, "training_loss": 185126.732421875, "training_acc": 53.0, "val_loss": 11696.929168701172, "val_acc": 48.0}
{"epoch": 28, "training_loss": 48713.31286621094, "training_acc": 47.0, "val_loss": 25465.216064453125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 96934.41479492188, "training_acc": 53.0, "val_loss": 15020.277404785156, "val_acc": 48.0}
{"epoch": 30, "training_loss": 52540.31701660156, "training_acc": 47.0, "val_loss": 37695.208740234375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 159218.02197265625, "training_acc": 53.0, "val_loss": 14827.001953125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 106043.84521484375, "training_acc": 53.0, "val_loss": 70061.60888671875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 247889.953125, "training_acc": 47.0, "val_loss": 20118.62030029297, "val_acc": 52.0}
