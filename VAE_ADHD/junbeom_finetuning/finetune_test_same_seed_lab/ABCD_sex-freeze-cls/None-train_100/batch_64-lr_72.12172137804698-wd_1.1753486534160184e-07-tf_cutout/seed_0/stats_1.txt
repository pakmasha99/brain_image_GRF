"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 462878.7424926758, "training_acc": 53.0, "val_loss": 120336.02294921875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 619123.0, "training_acc": 49.0, "val_loss": 252102.8076171875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 910361.40625, "training_acc": 47.0, "val_loss": 15779.975891113281, "val_acc": 48.0}
{"epoch": 3, "training_loss": 244752.580078125, "training_acc": 55.0, "val_loss": 283961.81640625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1155778.48828125, "training_acc": 53.0, "val_loss": 276272.75390625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 954977.685546875, "training_acc": 53.0, "val_loss": 63773.47412109375, "val_acc": 52.0}
{"epoch": 6, "training_loss": 391785.94140625, "training_acc": 41.0, "val_loss": 192209.4970703125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 810116.953125, "training_acc": 47.0, "val_loss": 168953.84521484375, "val_acc": 48.0}
{"epoch": 8, "training_loss": 552962.4658203125, "training_acc": 47.0, "val_loss": 40422.71728515625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 257987.337890625, "training_acc": 53.0, "val_loss": 123438.63525390625, "val_acc": 52.0}
{"epoch": 10, "training_loss": 448926.9765625, "training_acc": 53.0, "val_loss": 38599.05090332031, "val_acc": 52.0}
{"epoch": 11, "training_loss": 131348.33544921875, "training_acc": 63.0, "val_loss": 108271.49658203125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 441238.3515625, "training_acc": 47.0, "val_loss": 64292.523193359375, "val_acc": 48.0}
{"epoch": 13, "training_loss": 195257.59130859375, "training_acc": 49.0, "val_loss": 51883.209228515625, "val_acc": 52.0}
{"epoch": 14, "training_loss": 192201.96923828125, "training_acc": 53.0, "val_loss": 76.9389271736145, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1431.5874481201172, "training_acc": 50.0, "val_loss": 38114.29748535156, "val_acc": 48.0}
{"epoch": 16, "training_loss": 142386.89697265625, "training_acc": 47.0, "val_loss": 22497.518920898438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 95885.83227539062, "training_acc": 53.0, "val_loss": 2288.1948471069336, "val_acc": 52.0}
{"epoch": 18, "training_loss": 103833.91796875, "training_acc": 49.0, "val_loss": 76794.50073242188, "val_acc": 48.0}
{"epoch": 19, "training_loss": 265410.7080078125, "training_acc": 47.0, "val_loss": 24952.532958984375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 151977.05078125, "training_acc": 53.0, "val_loss": 39643.865966796875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 104033.6640625, "training_acc": 55.0, "val_loss": 16764.259338378906, "val_acc": 48.0}
{"epoch": 22, "training_loss": 56961.08984375, "training_acc": 55.0, "val_loss": 12210.245513916016, "val_acc": 52.0}
{"epoch": 23, "training_loss": 52462.7080078125, "training_acc": 59.0, "val_loss": 20445.350646972656, "val_acc": 48.0}
{"epoch": 24, "training_loss": 81378.07788085938, "training_acc": 51.0, "val_loss": 25220.335388183594, "val_acc": 52.0}
{"epoch": 25, "training_loss": 95138.5205078125, "training_acc": 43.0, "val_loss": 2236.0286712646484, "val_acc": 52.0}
{"epoch": 26, "training_loss": 44991.4267578125, "training_acc": 47.0, "val_loss": 578.0824661254883, "val_acc": 48.0}
{"epoch": 27, "training_loss": 66065.45385742188, "training_acc": 55.0, "val_loss": 76711.60278320312, "val_acc": 52.0}
{"epoch": 28, "training_loss": 277379.357421875, "training_acc": 53.0, "val_loss": 10329.701232910156, "val_acc": 52.0}
{"epoch": 29, "training_loss": 136992.8671875, "training_acc": 51.0, "val_loss": 111443.408203125, "val_acc": 48.0}
{"epoch": 30, "training_loss": 438682.123046875, "training_acc": 47.0, "val_loss": 46804.425048828125, "val_acc": 48.0}
{"epoch": 31, "training_loss": 181587.59228515625, "training_acc": 49.0, "val_loss": 82846.06323242188, "val_acc": 52.0}
{"epoch": 32, "training_loss": 323683.125, "training_acc": 53.0, "val_loss": 50526.3671875, "val_acc": 52.0}
{"epoch": 33, "training_loss": 177469.3837890625, "training_acc": 43.0, "val_loss": 34119.44580078125, "val_acc": 48.0}
