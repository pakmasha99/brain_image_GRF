"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 80.99935340881348, "training_acc": 51.0, "val_loss": 18.171237409114838, "val_acc": 52.0}
{"epoch": 1, "training_loss": 87.95069169998169, "training_acc": 37.0, "val_loss": 20.78561782836914, "val_acc": 48.0}
{"epoch": 2, "training_loss": 81.55791807174683, "training_acc": 47.0, "val_loss": 17.304250597953796, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.91558814048767, "training_acc": 53.0, "val_loss": 18.90985816717148, "val_acc": 52.0}
{"epoch": 4, "training_loss": 74.29388403892517, "training_acc": 53.0, "val_loss": 17.61564612388611, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.6119270324707, "training_acc": 50.0, "val_loss": 17.69019216299057, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.18716168403625, "training_acc": 47.0, "val_loss": 17.803579568862915, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.8039448261261, "training_acc": 47.0, "val_loss": 17.303413152694702, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10291743278503, "training_acc": 53.0, "val_loss": 17.809459567070007, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.81213092803955, "training_acc": 53.0, "val_loss": 17.693451046943665, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.06180572509766, "training_acc": 53.0, "val_loss": 17.308296263217926, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.07954716682434, "training_acc": 53.0, "val_loss": 17.545069754123688, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.40047121047974, "training_acc": 47.0, "val_loss": 17.420700192451477, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.29861903190613, "training_acc": 51.0, "val_loss": 17.619679868221283, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.2355728149414, "training_acc": 53.0, "val_loss": 17.89686381816864, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.75103378295898, "training_acc": 53.0, "val_loss": 17.34464466571808, "val_acc": 52.0}
{"epoch": 16, "training_loss": 68.6834716796875, "training_acc": 53.0, "val_loss": 17.606063187122345, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.67227149009705, "training_acc": 47.0, "val_loss": 17.744971811771393, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.97322869300842, "training_acc": 47.0, "val_loss": 17.378009855747223, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.3799319267273, "training_acc": 49.0, "val_loss": 17.45862513780594, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.77032017707825, "training_acc": 53.0, "val_loss": 17.558377981185913, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.67419385910034, "training_acc": 53.0, "val_loss": 17.305462062358856, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.4521062374115, "training_acc": 49.0, "val_loss": 17.41204410791397, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.64544320106506, "training_acc": 47.0, "val_loss": 17.30552315711975, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.06857657432556, "training_acc": 53.0, "val_loss": 17.54511445760727, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.8921811580658, "training_acc": 53.0, "val_loss": 17.460449039936066, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.6220018863678, "training_acc": 53.0, "val_loss": 17.310410737991333, "val_acc": 52.0}
