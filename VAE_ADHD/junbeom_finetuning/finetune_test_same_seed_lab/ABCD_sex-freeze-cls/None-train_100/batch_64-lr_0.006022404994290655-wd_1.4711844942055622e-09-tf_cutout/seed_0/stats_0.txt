"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 87.00343990325928, "training_acc": 50.0, "val_loss": 18.939979374408722, "val_acc": 44.0}
{"epoch": 1, "training_loss": 77.25270652770996, "training_acc": 48.0, "val_loss": 21.936683356761932, "val_acc": 56.0}
{"epoch": 2, "training_loss": 90.36710739135742, "training_acc": 52.0, "val_loss": 17.46138334274292, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.07273054122925, "training_acc": 54.0, "val_loss": 21.121130883693695, "val_acc": 44.0}
{"epoch": 4, "training_loss": 82.62362718582153, "training_acc": 48.0, "val_loss": 20.41410058736801, "val_acc": 44.0}
{"epoch": 5, "training_loss": 77.22749042510986, "training_acc": 48.0, "val_loss": 17.19152480363846, "val_acc": 56.0}
{"epoch": 6, "training_loss": 71.20570874214172, "training_acc": 52.0, "val_loss": 18.30802857875824, "val_acc": 56.0}
{"epoch": 7, "training_loss": 75.61645269393921, "training_acc": 52.0, "val_loss": 17.289811372756958, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.06925249099731, "training_acc": 52.0, "val_loss": 17.981572449207306, "val_acc": 56.0}
{"epoch": 9, "training_loss": 71.74144434928894, "training_acc": 48.0, "val_loss": 19.111545383930206, "val_acc": 44.0}
{"epoch": 10, "training_loss": 73.40765428543091, "training_acc": 48.0, "val_loss": 17.447420954704285, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.88340830802917, "training_acc": 48.0, "val_loss": 17.438507080078125, "val_acc": 56.0}
{"epoch": 12, "training_loss": 72.18990063667297, "training_acc": 52.0, "val_loss": 17.33585000038147, "val_acc": 56.0}
{"epoch": 13, "training_loss": 70.72941875457764, "training_acc": 52.0, "val_loss": 17.493942379951477, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.32837772369385, "training_acc": 48.0, "val_loss": 17.96862781047821, "val_acc": 56.0}
{"epoch": 15, "training_loss": 70.35788369178772, "training_acc": 48.0, "val_loss": 17.247556149959564, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.70916700363159, "training_acc": 52.0, "val_loss": 17.332017421722412, "val_acc": 56.0}
{"epoch": 17, "training_loss": 70.80821108818054, "training_acc": 52.0, "val_loss": 17.18292534351349, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.52691769599915, "training_acc": 52.0, "val_loss": 17.539450526237488, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.746666431427, "training_acc": 48.0, "val_loss": 17.659270763397217, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.69199299812317, "training_acc": 48.0, "val_loss": 17.228423058986664, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.02380466461182, "training_acc": 52.0, "val_loss": 17.236699163913727, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.71765327453613, "training_acc": 52.0, "val_loss": 17.186184227466583, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.12160205841064, "training_acc": 52.0, "val_loss": 17.737799882888794, "val_acc": 56.0}
{"epoch": 24, "training_loss": 70.21626305580139, "training_acc": 48.0, "val_loss": 17.937244474887848, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.2441771030426, "training_acc": 48.0, "val_loss": 17.226609587669373, "val_acc": 56.0}
{"epoch": 26, "training_loss": 72.10179376602173, "training_acc": 52.0, "val_loss": 17.26658046245575, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.87505912780762, "training_acc": 52.0, "val_loss": 17.467790842056274, "val_acc": 56.0}
{"epoch": 28, "training_loss": 70.56844425201416, "training_acc": 48.0, "val_loss": 17.889298498630524, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.9691321849823, "training_acc": 48.0, "val_loss": 17.190319299697876, "val_acc": 56.0}
{"epoch": 30, "training_loss": 71.67581152915955, "training_acc": 52.0, "val_loss": 17.28959232568741, "val_acc": 56.0}
{"epoch": 31, "training_loss": 71.60437655448914, "training_acc": 52.0, "val_loss": 17.427638173103333, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.41634106636047, "training_acc": 48.0, "val_loss": 17.437520623207092, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2825698852539, "training_acc": 48.0, "val_loss": 17.227424681186676, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.5947916507721, "training_acc": 52.0, "val_loss": 17.19142496585846, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.4578685760498, "training_acc": 52.0, "val_loss": 17.31151193380356, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.44746279716492, "training_acc": 48.0, "val_loss": 17.425502836704254, "val_acc": 56.0}
