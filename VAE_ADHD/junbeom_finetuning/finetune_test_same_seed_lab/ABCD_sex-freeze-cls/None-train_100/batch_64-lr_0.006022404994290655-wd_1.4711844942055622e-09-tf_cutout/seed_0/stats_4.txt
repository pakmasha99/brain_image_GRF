"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 87.45195865631104, "training_acc": 49.0, "val_loss": 18.34426075220108, "val_acc": 44.0}
{"epoch": 1, "training_loss": 78.93422389030457, "training_acc": 45.0, "val_loss": 23.10204803943634, "val_acc": 52.0}
{"epoch": 2, "training_loss": 88.03374433517456, "training_acc": 53.0, "val_loss": 18.18048506975174, "val_acc": 52.0}
{"epoch": 3, "training_loss": 72.95001983642578, "training_acc": 47.0, "val_loss": 19.06808465719223, "val_acc": 48.0}
{"epoch": 4, "training_loss": 77.06857967376709, "training_acc": 47.0, "val_loss": 18.66438239812851, "val_acc": 48.0}
{"epoch": 5, "training_loss": 73.4096519947052, "training_acc": 47.0, "val_loss": 17.411136627197266, "val_acc": 52.0}
{"epoch": 6, "training_loss": 68.74525189399719, "training_acc": 53.0, "val_loss": 18.864238262176514, "val_acc": 52.0}
{"epoch": 7, "training_loss": 75.47046208381653, "training_acc": 53.0, "val_loss": 18.20891499519348, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.07582092285156, "training_acc": 53.0, "val_loss": 17.534466087818146, "val_acc": 52.0}
{"epoch": 9, "training_loss": 73.11629152297974, "training_acc": 47.0, "val_loss": 18.293868005275726, "val_acc": 52.0}
{"epoch": 10, "training_loss": 72.54904913902283, "training_acc": 47.0, "val_loss": 17.306090891361237, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.5363495349884, "training_acc": 53.0, "val_loss": 18.13049614429474, "val_acc": 52.0}
{"epoch": 12, "training_loss": 72.22843289375305, "training_acc": 53.0, "val_loss": 17.743881046772003, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.31831407546997, "training_acc": 53.0, "val_loss": 17.41994470357895, "val_acc": 52.0}
{"epoch": 14, "training_loss": 71.07123565673828, "training_acc": 47.0, "val_loss": 17.67013370990753, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.61684036254883, "training_acc": 47.0, "val_loss": 17.327961325645447, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.63483548164368, "training_acc": 53.0, "val_loss": 17.663046717643738, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.08562445640564, "training_acc": 53.0, "val_loss": 17.368796467781067, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20328497886658, "training_acc": 53.0, "val_loss": 17.376916110515594, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.77933621406555, "training_acc": 47.0, "val_loss": 17.373599112033844, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.32902240753174, "training_acc": 51.0, "val_loss": 17.364047467708588, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29588627815247, "training_acc": 53.0, "val_loss": 17.555740475654602, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.85083079338074, "training_acc": 53.0, "val_loss": 17.336834967136383, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.46150135993958, "training_acc": 49.0, "val_loss": 17.43924617767334, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.93358516693115, "training_acc": 47.0, "val_loss": 17.32269674539566, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.25854277610779, "training_acc": 53.0, "val_loss": 17.47165620326996, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.75412392616272, "training_acc": 53.0, "val_loss": 17.48426705598831, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.97742486000061, "training_acc": 53.0, "val_loss": 17.337295413017273, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.8530044555664, "training_acc": 53.0, "val_loss": 17.505420744419098, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.1510055065155, "training_acc": 47.0, "val_loss": 17.46392548084259, "val_acc": 52.0}
