"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.53675842285156, "training_acc": 45.0, "val_loss": 17.326609790325165, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30220532417297, "training_acc": 53.0, "val_loss": 17.311719059944153, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1864550113678, "training_acc": 53.0, "val_loss": 17.327746748924255, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16739010810852, "training_acc": 53.0, "val_loss": 17.342345416545868, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20980954170227, "training_acc": 53.0, "val_loss": 17.340710759162903, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17922186851501, "training_acc": 53.0, "val_loss": 17.342767119407654, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15608549118042, "training_acc": 53.0, "val_loss": 17.33425110578537, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1635890007019, "training_acc": 53.0, "val_loss": 17.32291430234909, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12326383590698, "training_acc": 53.0, "val_loss": 17.31344163417816, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13386106491089, "training_acc": 53.0, "val_loss": 17.31119453907013, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19677734375, "training_acc": 53.0, "val_loss": 17.311181128025055, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15428590774536, "training_acc": 53.0, "val_loss": 17.312753200531006, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22551989555359, "training_acc": 53.0, "val_loss": 17.314675450325012, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21106719970703, "training_acc": 53.0, "val_loss": 17.317257821559906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2319815158844, "training_acc": 53.0, "val_loss": 17.31410175561905, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17860746383667, "training_acc": 53.0, "val_loss": 17.311671376228333, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20377731323242, "training_acc": 53.0, "val_loss": 17.31191575527191, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1445906162262, "training_acc": 53.0, "val_loss": 17.315150797367096, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19735288619995, "training_acc": 53.0, "val_loss": 17.32269823551178, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18739151954651, "training_acc": 53.0, "val_loss": 17.32628643512726, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1571626663208, "training_acc": 53.0, "val_loss": 17.3237606883049, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1399564743042, "training_acc": 53.0, "val_loss": 17.32049286365509, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15488076210022, "training_acc": 53.0, "val_loss": 17.316219210624695, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19494652748108, "training_acc": 53.0, "val_loss": 17.31429398059845, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13968753814697, "training_acc": 53.0, "val_loss": 17.31572300195694, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14846158027649, "training_acc": 53.0, "val_loss": 17.31969267129898, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17237854003906, "training_acc": 53.0, "val_loss": 17.32136905193329, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14715933799744, "training_acc": 53.0, "val_loss": 17.321865260601044, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19445013999939, "training_acc": 53.0, "val_loss": 17.317984998226166, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17569589614868, "training_acc": 53.0, "val_loss": 17.319011688232422, "val_acc": 52.0}
