"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.45628452301025, "training_acc": 47.0, "val_loss": 17.71223396062851, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.70180583000183, "training_acc": 47.0, "val_loss": 17.452652752399445, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.64670205116272, "training_acc": 47.0, "val_loss": 17.32734888792038, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.09037137031555, "training_acc": 55.0, "val_loss": 17.308862507343292, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07742428779602, "training_acc": 53.0, "val_loss": 17.360210418701172, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.38573384284973, "training_acc": 53.0, "val_loss": 17.437703907489777, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.51667356491089, "training_acc": 53.0, "val_loss": 17.48485118150711, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.64060950279236, "training_acc": 53.0, "val_loss": 17.49381273984909, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.70297074317932, "training_acc": 53.0, "val_loss": 17.47276782989502, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.56043481826782, "training_acc": 53.0, "val_loss": 17.44140535593033, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.45794653892517, "training_acc": 53.0, "val_loss": 17.395538091659546, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29441046714783, "training_acc": 53.0, "val_loss": 17.35415607690811, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22206163406372, "training_acc": 53.0, "val_loss": 17.32223927974701, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2095239162445, "training_acc": 53.0, "val_loss": 17.307662963867188, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14341425895691, "training_acc": 53.0, "val_loss": 17.305289208889008, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1324417591095, "training_acc": 53.0, "val_loss": 17.306160926818848, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.23163032531738, "training_acc": 53.0, "val_loss": 17.308147251605988, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23512363433838, "training_acc": 53.0, "val_loss": 17.30678081512451, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16083812713623, "training_acc": 53.0, "val_loss": 17.30654090642929, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19715976715088, "training_acc": 53.0, "val_loss": 17.30555146932602, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15640544891357, "training_acc": 53.0, "val_loss": 17.305323481559753, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17850685119629, "training_acc": 53.0, "val_loss": 17.30528473854065, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14548969268799, "training_acc": 53.0, "val_loss": 17.30608344078064, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24601650238037, "training_acc": 53.0, "val_loss": 17.30988919734955, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.146719455719, "training_acc": 53.0, "val_loss": 17.310738563537598, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.12956285476685, "training_acc": 53.0, "val_loss": 17.314736545085907, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15911436080933, "training_acc": 53.0, "val_loss": 17.318007349967957, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1348602771759, "training_acc": 53.0, "val_loss": 17.321957647800446, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13927555084229, "training_acc": 53.0, "val_loss": 17.329367995262146, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.17797493934631, "training_acc": 53.0, "val_loss": 17.334723472595215, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15908336639404, "training_acc": 53.0, "val_loss": 17.339183390140533, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20158314704895, "training_acc": 53.0, "val_loss": 17.336505651474, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1843831539154, "training_acc": 53.0, "val_loss": 17.330394685268402, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19578242301941, "training_acc": 53.0, "val_loss": 17.32436716556549, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13369154930115, "training_acc": 53.0, "val_loss": 17.32061207294464, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13826322555542, "training_acc": 53.0, "val_loss": 17.317600548267365, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12464475631714, "training_acc": 53.0, "val_loss": 17.314323782920837, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14458560943604, "training_acc": 53.0, "val_loss": 17.312365770339966, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12598133087158, "training_acc": 53.0, "val_loss": 17.3106387257576, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13488626480103, "training_acc": 53.0, "val_loss": 17.309269309043884, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13013362884521, "training_acc": 53.0, "val_loss": 17.308971285820007, "val_acc": 52.0}
