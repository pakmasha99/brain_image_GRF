"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23157858848572, "training_acc": 53.0, "val_loss": 17.314235866069794, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21951580047607, "training_acc": 53.0, "val_loss": 17.31412708759308, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22694444656372, "training_acc": 53.0, "val_loss": 17.31332242488861, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19111347198486, "training_acc": 53.0, "val_loss": 17.3123762011528, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20848202705383, "training_acc": 53.0, "val_loss": 17.311474680900574, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2130856513977, "training_acc": 53.0, "val_loss": 17.31092780828476, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19695520401001, "training_acc": 53.0, "val_loss": 17.310182750225067, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19356274604797, "training_acc": 53.0, "val_loss": 17.309539020061493, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18458151817322, "training_acc": 53.0, "val_loss": 17.308877408504486, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16566205024719, "training_acc": 53.0, "val_loss": 17.30829030275345, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17570424079895, "training_acc": 53.0, "val_loss": 17.307808995246887, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16247296333313, "training_acc": 53.0, "val_loss": 17.307505011558533, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1857500076294, "training_acc": 53.0, "val_loss": 17.307281494140625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16718626022339, "training_acc": 53.0, "val_loss": 17.307159304618835, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15239453315735, "training_acc": 53.0, "val_loss": 17.307049036026, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1656882762909, "training_acc": 53.0, "val_loss": 17.306962609291077, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13499450683594, "training_acc": 53.0, "val_loss": 17.306916415691376, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14983177185059, "training_acc": 53.0, "val_loss": 17.30690598487854, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14971709251404, "training_acc": 53.0, "val_loss": 17.30693280696869, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15792512893677, "training_acc": 53.0, "val_loss": 17.306984961032867, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13289713859558, "training_acc": 53.0, "val_loss": 17.30703115463257, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13678407669067, "training_acc": 53.0, "val_loss": 17.30707883834839, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.156982421875, "training_acc": 53.0, "val_loss": 17.30715185403824, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1417396068573, "training_acc": 53.0, "val_loss": 17.30722039937973, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11756634712219, "training_acc": 53.0, "val_loss": 17.307309806346893, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13520741462708, "training_acc": 53.0, "val_loss": 17.30741411447525, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14611053466797, "training_acc": 53.0, "val_loss": 17.307573556900024, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14220309257507, "training_acc": 53.0, "val_loss": 17.307719588279724, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12641906738281, "training_acc": 53.0, "val_loss": 17.307834327220917, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13933897018433, "training_acc": 53.0, "val_loss": 17.308051884174347, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13641285896301, "training_acc": 53.0, "val_loss": 17.30828434228897, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14470314979553, "training_acc": 53.0, "val_loss": 17.308561503887177, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13938164710999, "training_acc": 53.0, "val_loss": 17.308799922466278, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14702653884888, "training_acc": 53.0, "val_loss": 17.30894297361374, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12761569023132, "training_acc": 53.0, "val_loss": 17.308904230594635, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1420636177063, "training_acc": 53.0, "val_loss": 17.308861017227173, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13174080848694, "training_acc": 53.0, "val_loss": 17.308837175369263, "val_acc": 52.0}
