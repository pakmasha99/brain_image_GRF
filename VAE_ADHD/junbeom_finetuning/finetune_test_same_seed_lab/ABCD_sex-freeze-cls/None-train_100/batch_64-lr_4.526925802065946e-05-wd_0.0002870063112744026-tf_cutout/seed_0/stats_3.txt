"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.05302262306213, "training_acc": 47.0, "val_loss": 17.851607501506805, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.58350968360901, "training_acc": 47.0, "val_loss": 17.766505479812622, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.27879095077515, "training_acc": 47.0, "val_loss": 17.685744166374207, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.93588328361511, "training_acc": 47.0, "val_loss": 17.61493682861328, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.5869026184082, "training_acc": 47.0, "val_loss": 17.55271703004837, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.34054684638977, "training_acc": 47.0, "val_loss": 17.497555911540985, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.06525707244873, "training_acc": 47.0, "val_loss": 17.45065301656723, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.85998249053955, "training_acc": 47.0, "val_loss": 17.411355674266815, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.70094394683838, "training_acc": 47.0, "val_loss": 17.378626763820648, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.5589919090271, "training_acc": 47.0, "val_loss": 17.352765798568726, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42596769332886, "training_acc": 47.0, "val_loss": 17.334285378456116, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.35236668586731, "training_acc": 44.0, "val_loss": 17.32165813446045, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.21435642242432, "training_acc": 53.0, "val_loss": 17.31436848640442, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18865251541138, "training_acc": 53.0, "val_loss": 17.310267686843872, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16383361816406, "training_acc": 53.0, "val_loss": 17.30884462594986, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.0935697555542, "training_acc": 53.0, "val_loss": 17.309987545013428, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17597532272339, "training_acc": 53.0, "val_loss": 17.31303036212921, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1303722858429, "training_acc": 53.0, "val_loss": 17.317187786102295, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12704491615295, "training_acc": 53.0, "val_loss": 17.321769893169403, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10310387611389, "training_acc": 53.0, "val_loss": 17.32654869556427, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1134045124054, "training_acc": 53.0, "val_loss": 17.331336438655853, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1550920009613, "training_acc": 53.0, "val_loss": 17.334292829036713, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19170475006104, "training_acc": 53.0, "val_loss": 17.336422204971313, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14981436729431, "training_acc": 53.0, "val_loss": 17.337584495544434, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17761278152466, "training_acc": 53.0, "val_loss": 17.339354753494263, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17879128456116, "training_acc": 53.0, "val_loss": 17.338168621063232, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.23392033576965, "training_acc": 53.0, "val_loss": 17.337065935134888, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24008584022522, "training_acc": 53.0, "val_loss": 17.33548641204834, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18300557136536, "training_acc": 53.0, "val_loss": 17.331649363040924, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19987845420837, "training_acc": 53.0, "val_loss": 17.32785701751709, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18538784980774, "training_acc": 53.0, "val_loss": 17.323659360408783, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15003538131714, "training_acc": 53.0, "val_loss": 17.319849133491516, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15731072425842, "training_acc": 53.0, "val_loss": 17.316317558288574, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15212225914001, "training_acc": 53.0, "val_loss": 17.313994467258453, "val_acc": 52.0}
