"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24483561515808, "training_acc": 52.0, "val_loss": 17.244574427604675, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24200391769409, "training_acc": 52.0, "val_loss": 17.21741110086441, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.26144528388977, "training_acc": 52.0, "val_loss": 17.21523255109787, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26345562934875, "training_acc": 52.0, "val_loss": 17.228911817073822, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24141836166382, "training_acc": 52.0, "val_loss": 17.250660061836243, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2290997505188, "training_acc": 52.0, "val_loss": 17.258456349372864, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26472210884094, "training_acc": 52.0, "val_loss": 17.27345585823059, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26759028434753, "training_acc": 52.0, "val_loss": 17.278073728084564, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.28952813148499, "training_acc": 52.0, "val_loss": 17.26805418729782, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26053166389465, "training_acc": 52.0, "val_loss": 17.269611358642578, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23595952987671, "training_acc": 52.0, "val_loss": 17.268677055835724, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26586437225342, "training_acc": 52.0, "val_loss": 17.26219207048416, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23582100868225, "training_acc": 52.0, "val_loss": 17.25534349679947, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23702311515808, "training_acc": 52.0, "val_loss": 17.252856492996216, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24438452720642, "training_acc": 52.0, "val_loss": 17.24444180727005, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24774050712585, "training_acc": 52.0, "val_loss": 17.233264446258545, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.251460313797, "training_acc": 52.0, "val_loss": 17.218105494976044, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23526859283447, "training_acc": 52.0, "val_loss": 17.209476232528687, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24597477912903, "training_acc": 52.0, "val_loss": 17.203964293003082, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26385378837585, "training_acc": 52.0, "val_loss": 17.20128357410431, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21538043022156, "training_acc": 52.0, "val_loss": 17.203783988952637, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23647904396057, "training_acc": 52.0, "val_loss": 17.205600440502167, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29118800163269, "training_acc": 52.0, "val_loss": 17.203298211097717, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25941944122314, "training_acc": 52.0, "val_loss": 17.21004694700241, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25421643257141, "training_acc": 52.0, "val_loss": 17.22172647714615, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25146889686584, "training_acc": 52.0, "val_loss": 17.23770648241043, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28590822219849, "training_acc": 52.0, "val_loss": 17.243942618370056, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22964596748352, "training_acc": 52.0, "val_loss": 17.263244092464447, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.26222109794617, "training_acc": 52.0, "val_loss": 17.27934181690216, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2764790058136, "training_acc": 52.0, "val_loss": 17.281566560268402, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.30424475669861, "training_acc": 52.0, "val_loss": 17.273889482021332, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29193258285522, "training_acc": 52.0, "val_loss": 17.27764904499054, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25852179527283, "training_acc": 52.0, "val_loss": 17.26563274860382, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25628972053528, "training_acc": 52.0, "val_loss": 17.255160212516785, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26358461380005, "training_acc": 52.0, "val_loss": 17.241893708705902, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23716330528259, "training_acc": 52.0, "val_loss": 17.23436862230301, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23445105552673, "training_acc": 52.0, "val_loss": 17.227624356746674, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23767447471619, "training_acc": 52.0, "val_loss": 17.22077578306198, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2297682762146, "training_acc": 52.0, "val_loss": 17.209218442440033, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.26401877403259, "training_acc": 52.0, "val_loss": 17.19506084918976, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.24452257156372, "training_acc": 52.0, "val_loss": 17.19062626361847, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.27118229866028, "training_acc": 52.0, "val_loss": 17.189083993434906, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28180313110352, "training_acc": 52.0, "val_loss": 17.18963086605072, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24564790725708, "training_acc": 52.0, "val_loss": 17.195771634578705, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26305484771729, "training_acc": 52.0, "val_loss": 17.210960388183594, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23636293411255, "training_acc": 52.0, "val_loss": 17.223651707172394, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.2515811920166, "training_acc": 52.0, "val_loss": 17.238649725914, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24695324897766, "training_acc": 52.0, "val_loss": 17.25296378135681, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.23063373565674, "training_acc": 52.0, "val_loss": 17.2581285238266, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2409508228302, "training_acc": 52.0, "val_loss": 17.261317372322083, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.26216340065002, "training_acc": 52.0, "val_loss": 17.267446219921112, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.26167416572571, "training_acc": 52.0, "val_loss": 17.273448407649994, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.26979422569275, "training_acc": 52.0, "val_loss": 17.276307940483093, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27682495117188, "training_acc": 52.0, "val_loss": 17.278946936130524, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2308657169342, "training_acc": 52.0, "val_loss": 17.278999090194702, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27078986167908, "training_acc": 52.0, "val_loss": 17.271333932876587, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.2531361579895, "training_acc": 52.0, "val_loss": 17.268140614032745, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24577355384827, "training_acc": 52.0, "val_loss": 17.266753315925598, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23672747612, "training_acc": 52.0, "val_loss": 17.25941002368927, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25604343414307, "training_acc": 52.0, "val_loss": 17.25323051214218, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28276920318604, "training_acc": 52.0, "val_loss": 17.241191864013672, "val_acc": 56.0}
