"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.788733959198, "training_acc": 45.0, "val_loss": 17.326167225837708, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.08004355430603, "training_acc": 53.0, "val_loss": 17.323796451091766, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.07405591011047, "training_acc": 53.0, "val_loss": 17.41643100976944, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51591444015503, "training_acc": 53.0, "val_loss": 17.480456829071045, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.57438230514526, "training_acc": 53.0, "val_loss": 17.42035299539566, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.30163097381592, "training_acc": 53.0, "val_loss": 17.343394458293915, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.45496726036072, "training_acc": 53.0, "val_loss": 17.309068143367767, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.42237401008606, "training_acc": 53.0, "val_loss": 17.31167733669281, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18483090400696, "training_acc": 53.0, "val_loss": 17.30893701314926, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13225150108337, "training_acc": 53.0, "val_loss": 17.313548922538757, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11151194572449, "training_acc": 53.0, "val_loss": 17.331263422966003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.18068623542786, "training_acc": 53.0, "val_loss": 17.352168262004852, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22290921211243, "training_acc": 53.0, "val_loss": 17.36329197883606, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24243354797363, "training_acc": 53.0, "val_loss": 17.364798486232758, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2746787071228, "training_acc": 53.0, "val_loss": 17.358556389808655, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.23488211631775, "training_acc": 53.0, "val_loss": 17.33195334672928, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1693160533905, "training_acc": 53.0, "val_loss": 17.315872013568878, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.25294160842896, "training_acc": 53.0, "val_loss": 17.310039699077606, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23703503608704, "training_acc": 53.0, "val_loss": 17.311297357082367, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16440153121948, "training_acc": 53.0, "val_loss": 17.30934828519821, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1358962059021, "training_acc": 53.0, "val_loss": 17.30983257293701, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.28719830513, "training_acc": 53.0, "val_loss": 17.31136292219162, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12053346633911, "training_acc": 53.0, "val_loss": 17.309170961380005, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1484010219574, "training_acc": 53.0, "val_loss": 17.309103906154633, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14976811408997, "training_acc": 53.0, "val_loss": 17.311139404773712, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19341683387756, "training_acc": 53.0, "val_loss": 17.313815653324127, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25050354003906, "training_acc": 53.0, "val_loss": 17.31712818145752, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.22585797309875, "training_acc": 53.0, "val_loss": 17.312590777873993, "val_acc": 52.0}
