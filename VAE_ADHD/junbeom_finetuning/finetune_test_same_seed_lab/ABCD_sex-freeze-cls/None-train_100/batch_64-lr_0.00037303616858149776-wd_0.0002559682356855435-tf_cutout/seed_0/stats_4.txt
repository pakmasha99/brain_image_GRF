"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.27525281906128, "training_acc": 47.0, "val_loss": 17.450232803821564, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.63570499420166, "training_acc": 47.0, "val_loss": 17.31962561607361, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.10900545120239, "training_acc": 53.0, "val_loss": 17.328952252864838, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.6848132610321, "training_acc": 53.0, "val_loss": 17.434053122997284, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.45852279663086, "training_acc": 53.0, "val_loss": 17.448875308036804, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.51465845108032, "training_acc": 53.0, "val_loss": 17.442581057548523, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5291018486023, "training_acc": 53.0, "val_loss": 17.396998405456543, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.48061418533325, "training_acc": 53.0, "val_loss": 17.353780567646027, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22153973579407, "training_acc": 53.0, "val_loss": 17.330680787563324, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20948648452759, "training_acc": 53.0, "val_loss": 17.314918339252472, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11690258979797, "training_acc": 53.0, "val_loss": 17.308619618415833, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13915467262268, "training_acc": 53.0, "val_loss": 17.30482280254364, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17103314399719, "training_acc": 53.0, "val_loss": 17.304053902626038, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17258548736572, "training_acc": 53.0, "val_loss": 17.304065823554993, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14170479774475, "training_acc": 53.0, "val_loss": 17.305538058280945, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12404370307922, "training_acc": 53.0, "val_loss": 17.311011254787445, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12697458267212, "training_acc": 53.0, "val_loss": 17.317697405815125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1460530757904, "training_acc": 53.0, "val_loss": 17.32475310564041, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13278293609619, "training_acc": 53.0, "val_loss": 17.326200008392334, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19511532783508, "training_acc": 53.0, "val_loss": 17.321892082691193, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1646945476532, "training_acc": 53.0, "val_loss": 17.31756031513214, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21171188354492, "training_acc": 53.0, "val_loss": 17.314979434013367, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12104392051697, "training_acc": 53.0, "val_loss": 17.305690050125122, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1151750087738, "training_acc": 53.0, "val_loss": 17.304059863090515, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14387965202332, "training_acc": 53.0, "val_loss": 17.30463355779648, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1856484413147, "training_acc": 53.0, "val_loss": 17.30557531118393, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18337225914001, "training_acc": 53.0, "val_loss": 17.307649552822113, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.21633553504944, "training_acc": 53.0, "val_loss": 17.30606108903885, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15500617027283, "training_acc": 53.0, "val_loss": 17.304041981697083, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12042212486267, "training_acc": 53.0, "val_loss": 17.308467626571655, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15650629997253, "training_acc": 53.0, "val_loss": 17.33400672674179, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.23766446113586, "training_acc": 53.0, "val_loss": 17.358916997909546, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.24129033088684, "training_acc": 53.0, "val_loss": 17.351901531219482, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20837712287903, "training_acc": 53.0, "val_loss": 17.324699461460114, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.22047019004822, "training_acc": 53.0, "val_loss": 17.30787456035614, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13282704353333, "training_acc": 53.0, "val_loss": 17.304502427577972, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17966818809509, "training_acc": 53.0, "val_loss": 17.30455309152603, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.31800484657288, "training_acc": 53.0, "val_loss": 17.30561852455139, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.28254389762878, "training_acc": 53.0, "val_loss": 17.305241525173187, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11712646484375, "training_acc": 53.0, "val_loss": 17.308799922466278, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.15759873390198, "training_acc": 53.0, "val_loss": 17.312879860401154, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12360763549805, "training_acc": 53.0, "val_loss": 17.328180372714996, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1659586429596, "training_acc": 53.0, "val_loss": 17.337703704833984, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.21819615364075, "training_acc": 53.0, "val_loss": 17.335669696331024, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.18777394294739, "training_acc": 53.0, "val_loss": 17.318551242351532, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.20870447158813, "training_acc": 53.0, "val_loss": 17.30910986661911, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14789319038391, "training_acc": 53.0, "val_loss": 17.308570444583893, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.15046954154968, "training_acc": 53.0, "val_loss": 17.30675846338272, "val_acc": 52.0}
