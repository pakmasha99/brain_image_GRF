"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.87508702278137, "training_acc": 52.0, "val_loss": 17.217446863651276, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.17713570594788, "training_acc": 52.0, "val_loss": 17.412486672401428, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.4723892211914, "training_acc": 48.0, "val_loss": 17.43357479572296, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.52172088623047, "training_acc": 48.0, "val_loss": 17.360061407089233, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.29149174690247, "training_acc": 54.0, "val_loss": 17.275357246398926, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.37156367301941, "training_acc": 52.0, "val_loss": 17.212073504924774, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.21882963180542, "training_acc": 52.0, "val_loss": 17.204783856868744, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25532150268555, "training_acc": 52.0, "val_loss": 17.20670610666275, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.32696270942688, "training_acc": 52.0, "val_loss": 17.20418483018875, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25624394416809, "training_acc": 52.0, "val_loss": 17.237059772014618, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.200923204422, "training_acc": 52.0, "val_loss": 17.27733165025711, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26708936691284, "training_acc": 52.0, "val_loss": 17.296096682548523, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.29563522338867, "training_acc": 52.0, "val_loss": 17.29651540517807, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.25745892524719, "training_acc": 52.0, "val_loss": 17.292630672454834, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.25243330001831, "training_acc": 52.0, "val_loss": 17.257601022720337, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.19121718406677, "training_acc": 52.0, "val_loss": 17.219039797782898, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.26919627189636, "training_acc": 52.0, "val_loss": 17.188215255737305, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.28481793403625, "training_acc": 52.0, "val_loss": 17.182189226150513, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.270503282547, "training_acc": 52.0, "val_loss": 17.187312245368958, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26535367965698, "training_acc": 52.0, "val_loss": 17.203395068645477, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.24600267410278, "training_acc": 52.0, "val_loss": 17.236171662807465, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2647225856781, "training_acc": 52.0, "val_loss": 17.258231341838837, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28904294967651, "training_acc": 52.0, "val_loss": 17.248214781284332, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.2240400314331, "training_acc": 52.0, "val_loss": 17.258445918560028, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21908521652222, "training_acc": 52.0, "val_loss": 17.2739639878273, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.26661372184753, "training_acc": 52.0, "val_loss": 17.290838062763214, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.43002653121948, "training_acc": 52.0, "val_loss": 17.27040857076645, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23818922042847, "training_acc": 52.0, "val_loss": 17.29378253221512, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25340008735657, "training_acc": 52.0, "val_loss": 17.3044815659523, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2543294429779, "training_acc": 52.0, "val_loss": 17.273500561714172, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.3957211971283, "training_acc": 52.0, "val_loss": 17.233806848526, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.3107533454895, "training_acc": 52.0, "val_loss": 17.236003279685974, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23350644111633, "training_acc": 52.0, "val_loss": 17.214469611644745, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.17608046531677, "training_acc": 52.0, "val_loss": 17.207390069961548, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.223060131073, "training_acc": 52.0, "val_loss": 17.202086746692657, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2526969909668, "training_acc": 52.0, "val_loss": 17.212268710136414, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.22721362113953, "training_acc": 52.0, "val_loss": 17.226378619670868, "val_acc": 56.0}
