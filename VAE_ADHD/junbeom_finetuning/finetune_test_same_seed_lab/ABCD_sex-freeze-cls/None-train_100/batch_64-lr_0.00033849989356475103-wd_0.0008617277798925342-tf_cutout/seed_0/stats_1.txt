"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.45243716239929, "training_acc": 51.0, "val_loss": 17.308248579502106, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.23687052726746, "training_acc": 53.0, "val_loss": 17.319579422473907, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.33961606025696, "training_acc": 53.0, "val_loss": 17.36256033182144, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.38036060333252, "training_acc": 53.0, "val_loss": 17.368480563163757, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.26332306861877, "training_acc": 53.0, "val_loss": 17.339076101779938, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23263549804688, "training_acc": 53.0, "val_loss": 17.313215136528015, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13230013847351, "training_acc": 53.0, "val_loss": 17.303508520126343, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15225172042847, "training_acc": 53.0, "val_loss": 17.301401495933533, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17171025276184, "training_acc": 53.0, "val_loss": 17.30295568704605, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21286749839783, "training_acc": 53.0, "val_loss": 17.30301082134247, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.2100305557251, "training_acc": 53.0, "val_loss": 17.301341891288757, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17307424545288, "training_acc": 53.0, "val_loss": 17.302455008029938, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18545460700989, "training_acc": 53.0, "val_loss": 17.30390191078186, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.0892562866211, "training_acc": 53.0, "val_loss": 17.312318086624146, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11612796783447, "training_acc": 53.0, "val_loss": 17.32284277677536, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1795802116394, "training_acc": 53.0, "val_loss": 17.334142327308655, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22521901130676, "training_acc": 53.0, "val_loss": 17.333851754665375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.22130227088928, "training_acc": 53.0, "val_loss": 17.321476340293884, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11975359916687, "training_acc": 53.0, "val_loss": 17.304079234600067, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10022306442261, "training_acc": 53.0, "val_loss": 17.302466928958893, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18446040153503, "training_acc": 53.0, "val_loss": 17.30886399745941, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20719528198242, "training_acc": 53.0, "val_loss": 17.313113808631897, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26435875892639, "training_acc": 53.0, "val_loss": 17.311425507068634, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1954231262207, "training_acc": 53.0, "val_loss": 17.305190861225128, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1797845363617, "training_acc": 53.0, "val_loss": 17.30162352323532, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14010262489319, "training_acc": 53.0, "val_loss": 17.307528853416443, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.30168151855469, "training_acc": 53.0, "val_loss": 17.323318123817444, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.19528889656067, "training_acc": 53.0, "val_loss": 17.326022684574127, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18070244789124, "training_acc": 53.0, "val_loss": 17.318111658096313, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.18703150749207, "training_acc": 53.0, "val_loss": 17.315714061260223, "val_acc": 52.0}
