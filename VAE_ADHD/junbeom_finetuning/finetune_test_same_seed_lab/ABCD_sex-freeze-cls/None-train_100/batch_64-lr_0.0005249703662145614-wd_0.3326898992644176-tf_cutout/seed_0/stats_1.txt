"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.25640988349915, "training_acc": 45.0, "val_loss": 17.30821579694748, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17765760421753, "training_acc": 53.0, "val_loss": 17.347978055477142, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.78525352478027, "training_acc": 53.0, "val_loss": 17.31945425271988, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.35538029670715, "training_acc": 53.0, "val_loss": 17.350997030735016, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.31427764892578, "training_acc": 53.0, "val_loss": 17.332126200199127, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1549768447876, "training_acc": 53.0, "val_loss": 17.30055958032608, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.27281332015991, "training_acc": 53.0, "val_loss": 17.305518686771393, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22188687324524, "training_acc": 53.0, "val_loss": 17.310500144958496, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.24533438682556, "training_acc": 53.0, "val_loss": 17.30763465166092, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20628428459167, "training_acc": 53.0, "val_loss": 17.299312353134155, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.0834698677063, "training_acc": 53.0, "val_loss": 17.30554550886154, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.20060729980469, "training_acc": 53.0, "val_loss": 17.340047657489777, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25416541099548, "training_acc": 53.0, "val_loss": 17.356063425540924, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.41751837730408, "training_acc": 53.0, "val_loss": 17.335693538188934, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20120978355408, "training_acc": 53.0, "val_loss": 17.33427345752716, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22858428955078, "training_acc": 53.0, "val_loss": 17.323970794677734, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20349788665771, "training_acc": 53.0, "val_loss": 17.31608361005783, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1459436416626, "training_acc": 53.0, "val_loss": 17.304034531116486, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12900257110596, "training_acc": 53.0, "val_loss": 17.299696803092957, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14204335212708, "training_acc": 53.0, "val_loss": 17.32284277677536, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.33020806312561, "training_acc": 55.0, "val_loss": 17.345702648162842, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.40724039077759, "training_acc": 47.0, "val_loss": 17.33299195766449, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.35465931892395, "training_acc": 50.0, "val_loss": 17.306455969810486, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1637487411499, "training_acc": 53.0, "val_loss": 17.301425337791443, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.07966351509094, "training_acc": 53.0, "val_loss": 17.327389121055603, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16259098052979, "training_acc": 53.0, "val_loss": 17.369571328163147, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.3190860748291, "training_acc": 53.0, "val_loss": 17.3848494887352, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.434077501297, "training_acc": 53.0, "val_loss": 17.373603582382202, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.2384045124054, "training_acc": 53.0, "val_loss": 17.31528490781784, "val_acc": 52.0}
