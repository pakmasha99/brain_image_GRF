"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.82988858222961, "training_acc": 52.0, "val_loss": 17.341428995132446, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.33375263214111, "training_acc": 49.0, "val_loss": 17.4527570605278, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.59033942222595, "training_acc": 48.0, "val_loss": 17.313091456890106, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.37426686286926, "training_acc": 52.0, "val_loss": 17.22918301820755, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.17677998542786, "training_acc": 52.0, "val_loss": 17.211341857910156, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.33470487594604, "training_acc": 52.0, "val_loss": 17.204272747039795, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.22944951057434, "training_acc": 52.0, "val_loss": 17.256860435009003, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.29072451591492, "training_acc": 52.0, "val_loss": 17.293445765972137, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.39695191383362, "training_acc": 52.0, "val_loss": 17.264728248119354, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26761960983276, "training_acc": 52.0, "val_loss": 17.282874882221222, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2210168838501, "training_acc": 52.0, "val_loss": 17.284217476844788, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.28000593185425, "training_acc": 52.0, "val_loss": 17.255546152591705, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.29016351699829, "training_acc": 52.0, "val_loss": 17.23426729440689, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.21796011924744, "training_acc": 52.0, "val_loss": 17.23790317773819, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.22599339485168, "training_acc": 52.0, "val_loss": 17.223888635635376, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2183187007904, "training_acc": 52.0, "val_loss": 17.206399142742157, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.27888488769531, "training_acc": 52.0, "val_loss": 17.188173532485962, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.28322315216064, "training_acc": 52.0, "val_loss": 17.196297645568848, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.22778654098511, "training_acc": 52.0, "val_loss": 17.21968799829483, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21144819259644, "training_acc": 52.0, "val_loss": 17.25020557641983, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.24239826202393, "training_acc": 52.0, "val_loss": 17.283128201961517, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.26806402206421, "training_acc": 52.0, "val_loss": 17.26682186126709, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.38397979736328, "training_acc": 52.0, "val_loss": 17.21588522195816, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25030565261841, "training_acc": 52.0, "val_loss": 17.217355966567993, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.2089912891388, "training_acc": 52.0, "val_loss": 17.24584996700287, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.27402067184448, "training_acc": 52.0, "val_loss": 17.294059693813324, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.47360706329346, "training_acc": 52.0, "val_loss": 17.283402383327484, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24210023880005, "training_acc": 52.0, "val_loss": 17.33657568693161, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.33601093292236, "training_acc": 53.0, "val_loss": 17.350050806999207, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.28943204879761, "training_acc": 52.0, "val_loss": 17.278659343719482, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.52934193611145, "training_acc": 52.0, "val_loss": 17.212501168251038, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.35164666175842, "training_acc": 52.0, "val_loss": 17.215703427791595, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25006151199341, "training_acc": 52.0, "val_loss": 17.197078466415405, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.21157789230347, "training_acc": 52.0, "val_loss": 17.199543118476868, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.23028230667114, "training_acc": 52.0, "val_loss": 17.20547378063202, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24788308143616, "training_acc": 52.0, "val_loss": 17.236153781414032, "val_acc": 56.0}
