"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23786115646362, "training_acc": 53.0, "val_loss": 17.308108508586884, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2174117565155, "training_acc": 53.0, "val_loss": 17.308278381824493, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2141900062561, "training_acc": 53.0, "val_loss": 17.307931184768677, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20882606506348, "training_acc": 53.0, "val_loss": 17.30751395225525, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18343019485474, "training_acc": 53.0, "val_loss": 17.30729788541794, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16199159622192, "training_acc": 53.0, "val_loss": 17.306913435459137, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16429471969604, "training_acc": 53.0, "val_loss": 17.30653941631317, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16973948478699, "training_acc": 53.0, "val_loss": 17.306186258792877, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17854332923889, "training_acc": 53.0, "val_loss": 17.30593591928482, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.21636629104614, "training_acc": 53.0, "val_loss": 17.305661737918854, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15729641914368, "training_acc": 53.0, "val_loss": 17.30537712574005, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16424536705017, "training_acc": 53.0, "val_loss": 17.305144667625427, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16350984573364, "training_acc": 53.0, "val_loss": 17.30489730834961, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18800473213196, "training_acc": 53.0, "val_loss": 17.30465590953827, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20171284675598, "training_acc": 53.0, "val_loss": 17.304474115371704, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14832258224487, "training_acc": 53.0, "val_loss": 17.304348945617676, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14855980873108, "training_acc": 53.0, "val_loss": 17.30424463748932, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16295313835144, "training_acc": 53.0, "val_loss": 17.304164171218872, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13577461242676, "training_acc": 53.0, "val_loss": 17.3040971159935, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18091535568237, "training_acc": 53.0, "val_loss": 17.304065823554993, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10479497909546, "training_acc": 53.0, "val_loss": 17.304053902626038, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1667377948761, "training_acc": 53.0, "val_loss": 17.30410009622574, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13526272773743, "training_acc": 53.0, "val_loss": 17.304202914237976, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17020726203918, "training_acc": 53.0, "val_loss": 17.304320633411407, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16094493865967, "training_acc": 53.0, "val_loss": 17.304489016532898, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14672923088074, "training_acc": 53.0, "val_loss": 17.30465590953827, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15212988853455, "training_acc": 53.0, "val_loss": 17.3048734664917, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12637495994568, "training_acc": 53.0, "val_loss": 17.305132746696472, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.10609364509583, "training_acc": 53.0, "val_loss": 17.30540245771408, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16538262367249, "training_acc": 53.0, "val_loss": 17.305736243724823, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14132404327393, "training_acc": 53.0, "val_loss": 17.305999994277954, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12384533882141, "training_acc": 53.0, "val_loss": 17.306266725063324, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14627957344055, "training_acc": 53.0, "val_loss": 17.306575179100037, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12687873840332, "training_acc": 53.0, "val_loss": 17.306846380233765, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15010833740234, "training_acc": 53.0, "val_loss": 17.30719655752182, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15220999717712, "training_acc": 53.0, "val_loss": 17.307473719120026, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15179181098938, "training_acc": 53.0, "val_loss": 17.307713627815247, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14432692527771, "training_acc": 53.0, "val_loss": 17.3079714179039, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15500998497009, "training_acc": 53.0, "val_loss": 17.308154702186584, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14026212692261, "training_acc": 53.0, "val_loss": 17.308230698108673, "val_acc": 52.0}
