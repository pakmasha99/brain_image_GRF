"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.76073837280273, "training_acc": 47.0, "val_loss": 17.41831749677658, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.73870086669922, "training_acc": 47.0, "val_loss": 17.408667504787445, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.68194508552551, "training_acc": 47.0, "val_loss": 17.400015890598297, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.61136817932129, "training_acc": 47.0, "val_loss": 17.39288717508316, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58856463432312, "training_acc": 47.0, "val_loss": 17.38593876361847, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.55361676216125, "training_acc": 47.0, "val_loss": 17.379550635814667, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.55562448501587, "training_acc": 47.0, "val_loss": 17.373962700366974, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.51293611526489, "training_acc": 47.0, "val_loss": 17.368926107883453, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.45726013183594, "training_acc": 47.0, "val_loss": 17.364154756069183, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.45826768875122, "training_acc": 47.0, "val_loss": 17.359456419944763, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42773175239563, "training_acc": 47.0, "val_loss": 17.355291545391083, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.40106320381165, "training_acc": 47.0, "val_loss": 17.351680994033813, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.40153169631958, "training_acc": 47.0, "val_loss": 17.347972095012665, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.38344645500183, "training_acc": 47.0, "val_loss": 17.344875633716583, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.33675503730774, "training_acc": 48.0, "val_loss": 17.34209954738617, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29897928237915, "training_acc": 50.0, "val_loss": 17.339226603507996, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29907512664795, "training_acc": 54.0, "val_loss": 17.336612939834595, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.28550362586975, "training_acc": 57.0, "val_loss": 17.334245145320892, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.31167960166931, "training_acc": 52.0, "val_loss": 17.332254350185394, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.28977632522583, "training_acc": 53.0, "val_loss": 17.330402135849, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25003147125244, "training_acc": 53.0, "val_loss": 17.328545451164246, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22878289222717, "training_acc": 53.0, "val_loss": 17.32695996761322, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25531053543091, "training_acc": 53.0, "val_loss": 17.325599491596222, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.23073053359985, "training_acc": 53.0, "val_loss": 17.324376106262207, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21609854698181, "training_acc": 53.0, "val_loss": 17.323289811611176, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.2031626701355, "training_acc": 53.0, "val_loss": 17.322281002998352, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2218976020813, "training_acc": 53.0, "val_loss": 17.32136160135269, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23374128341675, "training_acc": 53.0, "val_loss": 17.320534586906433, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19069266319275, "training_acc": 53.0, "val_loss": 17.31991171836853, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.2138786315918, "training_acc": 53.0, "val_loss": 17.319346964359283, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18056917190552, "training_acc": 53.0, "val_loss": 17.31884777545929, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18860363960266, "training_acc": 53.0, "val_loss": 17.31846034526825, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19547820091248, "training_acc": 53.0, "val_loss": 17.318078875541687, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17343640327454, "training_acc": 53.0, "val_loss": 17.317843437194824, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17316174507141, "training_acc": 53.0, "val_loss": 17.317691445350647, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15515971183777, "training_acc": 53.0, "val_loss": 17.317594587802887, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15383458137512, "training_acc": 53.0, "val_loss": 17.317548394203186, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1160237789154, "training_acc": 53.0, "val_loss": 17.317499220371246, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12391710281372, "training_acc": 53.0, "val_loss": 17.317454516887665, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16425657272339, "training_acc": 53.0, "val_loss": 17.31744557619095, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14166688919067, "training_acc": 53.0, "val_loss": 17.317433655261993, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15048265457153, "training_acc": 53.0, "val_loss": 17.31742024421692, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1278305053711, "training_acc": 53.0, "val_loss": 17.31741726398468, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1314766407013, "training_acc": 53.0, "val_loss": 17.317427694797516, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17679286003113, "training_acc": 53.0, "val_loss": 17.317470908164978, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15333390235901, "training_acc": 53.0, "val_loss": 17.317527532577515, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13115811347961, "training_acc": 53.0, "val_loss": 17.317582666873932, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16945958137512, "training_acc": 53.0, "val_loss": 17.317630350589752, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.17913103103638, "training_acc": 53.0, "val_loss": 17.317649722099304, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.15680432319641, "training_acc": 53.0, "val_loss": 17.317618429660797, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13841605186462, "training_acc": 53.0, "val_loss": 17.317596077919006, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.12653255462646, "training_acc": 53.0, "val_loss": 17.317628860473633, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.16664552688599, "training_acc": 53.0, "val_loss": 17.31763780117035, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.13808155059814, "training_acc": 53.0, "val_loss": 17.31768548488617, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.1160933971405, "training_acc": 53.0, "val_loss": 17.31770932674408, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.19150280952454, "training_acc": 53.0, "val_loss": 17.31775999069214, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.16705369949341, "training_acc": 53.0, "val_loss": 17.31782704591751, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15154600143433, "training_acc": 53.0, "val_loss": 17.31790453195572, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.16045928001404, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.14439558982849, "training_acc": 53.0, "val_loss": 17.317935824394226, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.1559944152832, "training_acc": 53.0, "val_loss": 17.31799691915512, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.13438081741333, "training_acc": 53.0, "val_loss": 17.31804609298706, "val_acc": 52.0}
