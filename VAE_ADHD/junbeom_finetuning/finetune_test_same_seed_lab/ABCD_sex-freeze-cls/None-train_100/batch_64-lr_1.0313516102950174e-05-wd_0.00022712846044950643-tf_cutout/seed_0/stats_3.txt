"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26533889770508, "training_acc": 53.0, "val_loss": 17.31797754764557, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2525908946991, "training_acc": 53.0, "val_loss": 17.31589138507843, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23172116279602, "training_acc": 53.0, "val_loss": 17.314140498638153, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.20751142501831, "training_acc": 53.0, "val_loss": 17.312921583652496, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.24037289619446, "training_acc": 53.0, "val_loss": 17.311730980873108, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18539118766785, "training_acc": 53.0, "val_loss": 17.3108771443367, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17537069320679, "training_acc": 53.0, "val_loss": 17.310087382793427, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19144058227539, "training_acc": 53.0, "val_loss": 17.30964034795761, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17305541038513, "training_acc": 53.0, "val_loss": 17.309188842773438, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17225003242493, "training_acc": 53.0, "val_loss": 17.308837175369263, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17099022865295, "training_acc": 53.0, "val_loss": 17.308664321899414, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16941428184509, "training_acc": 53.0, "val_loss": 17.308516800403595, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17252826690674, "training_acc": 53.0, "val_loss": 17.308422923088074, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14893078804016, "training_acc": 53.0, "val_loss": 17.308352887630463, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18092679977417, "training_acc": 53.0, "val_loss": 17.308315634727478, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15601849555969, "training_acc": 53.0, "val_loss": 17.308250069618225, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14191174507141, "training_acc": 53.0, "val_loss": 17.308172583580017, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18116116523743, "training_acc": 53.0, "val_loss": 17.30808913707733, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17312002182007, "training_acc": 53.0, "val_loss": 17.308039963245392, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14976215362549, "training_acc": 53.0, "val_loss": 17.30799674987793, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1594500541687, "training_acc": 53.0, "val_loss": 17.30796843767166, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16250133514404, "training_acc": 53.0, "val_loss": 17.307952046394348, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1588819026947, "training_acc": 53.0, "val_loss": 17.30795055627823, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1384699344635, "training_acc": 53.0, "val_loss": 17.30796843767166, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13403367996216, "training_acc": 53.0, "val_loss": 17.308029532432556, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13203358650208, "training_acc": 53.0, "val_loss": 17.30811297893524, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1406261920929, "training_acc": 53.0, "val_loss": 17.30816662311554, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13602805137634, "training_acc": 53.0, "val_loss": 17.308197915554047, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13153958320618, "training_acc": 53.0, "val_loss": 17.308276891708374, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12448620796204, "training_acc": 53.0, "val_loss": 17.30838716030121, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.15626668930054, "training_acc": 53.0, "val_loss": 17.308509349822998, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15307188034058, "training_acc": 53.0, "val_loss": 17.30867326259613, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15300726890564, "training_acc": 53.0, "val_loss": 17.308804392814636, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12385296821594, "training_acc": 53.0, "val_loss": 17.308829724788666, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1346161365509, "training_acc": 53.0, "val_loss": 17.30889081954956, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16164708137512, "training_acc": 53.0, "val_loss": 17.308959364891052, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14123558998108, "training_acc": 53.0, "val_loss": 17.30899065732956, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13457822799683, "training_acc": 53.0, "val_loss": 17.309051752090454, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17219543457031, "training_acc": 53.0, "val_loss": 17.309165000915527, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14335656166077, "training_acc": 53.0, "val_loss": 17.309334874153137, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.12292122840881, "training_acc": 53.0, "val_loss": 17.30950176715851, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15339064598083, "training_acc": 53.0, "val_loss": 17.309634387493134, "val_acc": 52.0}
