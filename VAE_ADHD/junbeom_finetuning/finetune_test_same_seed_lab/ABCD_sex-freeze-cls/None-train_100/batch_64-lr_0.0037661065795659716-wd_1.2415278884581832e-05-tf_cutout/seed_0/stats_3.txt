"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.97057938575745, "training_acc": 49.0, "val_loss": 17.583590745925903, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.13267374038696, "training_acc": 53.0, "val_loss": 19.24445331096649, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.25886702537537, "training_acc": 53.0, "val_loss": 17.515365779399872, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.84238147735596, "training_acc": 47.0, "val_loss": 18.724974989891052, "val_acc": 48.0}
{"epoch": 4, "training_loss": 74.67352294921875, "training_acc": 47.0, "val_loss": 17.395611107349396, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.73898696899414, "training_acc": 49.0, "val_loss": 18.316692113876343, "val_acc": 52.0}
{"epoch": 6, "training_loss": 73.20843601226807, "training_acc": 53.0, "val_loss": 17.90827512741089, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.70646786689758, "training_acc": 53.0, "val_loss": 17.499549686908722, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.31925582885742, "training_acc": 47.0, "val_loss": 17.787061631679535, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.56537699699402, "training_acc": 47.0, "val_loss": 17.35589951276779, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.66818070411682, "training_acc": 53.0, "val_loss": 18.090495467185974, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.57080578804016, "training_acc": 53.0, "val_loss": 17.52803325653076, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.05406284332275, "training_acc": 53.0, "val_loss": 17.519569396972656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.61339449882507, "training_acc": 47.0, "val_loss": 17.739826440811157, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.82612895965576, "training_acc": 47.0, "val_loss": 17.379726469516754, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.55504202842712, "training_acc": 53.0, "val_loss": 17.811216413974762, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.7471616268158, "training_acc": 53.0, "val_loss": 17.431867122650146, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.31595349311829, "training_acc": 53.0, "val_loss": 17.3313707113266, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.61945652961731, "training_acc": 47.0, "val_loss": 17.370668053627014, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.38935708999634, "training_acc": 49.0, "val_loss": 17.357589304447174, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.52807712554932, "training_acc": 53.0, "val_loss": 17.430178821086884, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.45935940742493, "training_acc": 53.0, "val_loss": 17.3660546541214, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.79042363166809, "training_acc": 47.0, "val_loss": 17.36213117837906, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.11091637611389, "training_acc": 37.0, "val_loss": 17.373237013816833, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1318736076355, "training_acc": 53.0, "val_loss": 17.32160896062851, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.36914110183716, "training_acc": 49.0, "val_loss": 17.378810048103333, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.4448766708374, "training_acc": 49.0, "val_loss": 17.32463389635086, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.10909008979797, "training_acc": 53.0, "val_loss": 17.45612621307373, "val_acc": 52.0}
{"epoch": 28, "training_loss": 71.52615308761597, "training_acc": 53.0, "val_loss": 17.523063719272614, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.08109974861145, "training_acc": 53.0, "val_loss": 17.442096769809723, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.91379380226135, "training_acc": 47.0, "val_loss": 17.458514869213104, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.87169766426086, "training_acc": 47.0, "val_loss": 17.325858771800995, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.43397235870361, "training_acc": 53.0, "val_loss": 17.489157617092133, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.5878427028656, "training_acc": 53.0, "val_loss": 17.407549917697906, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.52324295043945, "training_acc": 53.0, "val_loss": 17.325647175312042, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.25334548950195, "training_acc": 56.0, "val_loss": 17.32139140367508, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.10927748680115, "training_acc": 53.0, "val_loss": 17.36394464969635, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.33229494094849, "training_acc": 53.0, "val_loss": 17.385102808475494, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.29452347755432, "training_acc": 53.0, "val_loss": 17.39812046289444, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.32139611244202, "training_acc": 53.0, "val_loss": 17.328710854053497, "val_acc": 52.0}
{"epoch": 40, "training_loss": 70.38132929801941, "training_acc": 45.0, "val_loss": 17.55126267671585, "val_acc": 52.0}
{"epoch": 41, "training_loss": 70.31577920913696, "training_acc": 47.0, "val_loss": 17.320598661899567, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.33200931549072, "training_acc": 53.0, "val_loss": 17.427709698677063, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.34294581413269, "training_acc": 53.0, "val_loss": 17.357338964939117, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1265618801117, "training_acc": 53.0, "val_loss": 17.32231080532074, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.25515842437744, "training_acc": 51.0, "val_loss": 17.369620501995087, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.02532887458801, "training_acc": 41.0, "val_loss": 17.320816218852997, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.1381254196167, "training_acc": 53.0, "val_loss": 17.321914434432983, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.2726821899414, "training_acc": 53.0, "val_loss": 17.320747673511505, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.17880725860596, "training_acc": 53.0, "val_loss": 17.321254312992096, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.18311285972595, "training_acc": 53.0, "val_loss": 17.327602207660675, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.55595302581787, "training_acc": 53.0, "val_loss": 17.338155210018158, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.11142158508301, "training_acc": 53.0, "val_loss": 17.48119294643402, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.5504264831543, "training_acc": 53.0, "val_loss": 17.360755801200867, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.35298991203308, "training_acc": 53.0, "val_loss": 17.368245124816895, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.47569012641907, "training_acc": 47.0, "val_loss": 17.322498559951782, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.9381411075592, "training_acc": 53.0, "val_loss": 17.410975694656372, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.20390629768372, "training_acc": 53.0, "val_loss": 17.321063578128815, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.333003282547, "training_acc": 53.0, "val_loss": 17.361444234848022, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.69879198074341, "training_acc": 47.0, "val_loss": 17.38772541284561, "val_acc": 52.0}
{"epoch": 60, "training_loss": 70.90004277229309, "training_acc": 39.0, "val_loss": 17.3550084233284, "val_acc": 52.0}
