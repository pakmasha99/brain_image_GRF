"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.75548243522644, "training_acc": 47.0, "val_loss": 17.767292261123657, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.43141555786133, "training_acc": 47.0, "val_loss": 17.70484149456024, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.05668377876282, "training_acc": 47.0, "val_loss": 17.652064561843872, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.83010172843933, "training_acc": 47.0, "val_loss": 17.594966292381287, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.54940152168274, "training_acc": 47.0, "val_loss": 17.541764676570892, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.2734625339508, "training_acc": 47.0, "val_loss": 17.493854463100433, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.08749890327454, "training_acc": 47.0, "val_loss": 17.450258135795593, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.90604138374329, "training_acc": 47.0, "val_loss": 17.413264513015747, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.74806594848633, "training_acc": 47.0, "val_loss": 17.38223284482956, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.60163617134094, "training_acc": 47.0, "val_loss": 17.358146607875824, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.47198748588562, "training_acc": 47.0, "val_loss": 17.33977347612381, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.32819080352783, "training_acc": 47.0, "val_loss": 17.326240241527557, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.29522395133972, "training_acc": 49.0, "val_loss": 17.31678694486618, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21758842468262, "training_acc": 53.0, "val_loss": 17.311130464076996, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18591690063477, "training_acc": 53.0, "val_loss": 17.30865091085434, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16065049171448, "training_acc": 53.0, "val_loss": 17.308513820171356, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16891384124756, "training_acc": 53.0, "val_loss": 17.310048639774323, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13720703125, "training_acc": 53.0, "val_loss": 17.31255352497101, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14401006698608, "training_acc": 53.0, "val_loss": 17.315658926963806, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17453122138977, "training_acc": 53.0, "val_loss": 17.319025099277496, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1242744922638, "training_acc": 53.0, "val_loss": 17.32099950313568, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16628193855286, "training_acc": 53.0, "val_loss": 17.322498559951782, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15666246414185, "training_acc": 53.0, "val_loss": 17.323528230190277, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15212273597717, "training_acc": 53.0, "val_loss": 17.323531210422516, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14229607582092, "training_acc": 53.0, "val_loss": 17.32233464717865, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14464735984802, "training_acc": 53.0, "val_loss": 17.321084439754486, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14134526252747, "training_acc": 53.0, "val_loss": 17.31981933116913, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15438413619995, "training_acc": 53.0, "val_loss": 17.319069802761078, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15660452842712, "training_acc": 53.0, "val_loss": 17.319317162036896, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15264940261841, "training_acc": 53.0, "val_loss": 17.31935143470764, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16093921661377, "training_acc": 53.0, "val_loss": 17.318686842918396, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13486814498901, "training_acc": 53.0, "val_loss": 17.317485809326172, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12695574760437, "training_acc": 53.0, "val_loss": 17.316390573978424, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.11318564414978, "training_acc": 53.0, "val_loss": 17.315922677516937, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16310906410217, "training_acc": 53.0, "val_loss": 17.315027117729187, "val_acc": 52.0}
