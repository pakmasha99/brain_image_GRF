"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31661415100098, "training_acc": 46.0, "val_loss": 17.33105629682541, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30831336975098, "training_acc": 47.0, "val_loss": 17.325004935264587, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23913788795471, "training_acc": 53.0, "val_loss": 17.320144176483154, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2250862121582, "training_acc": 53.0, "val_loss": 17.317035794258118, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1642234325409, "training_acc": 53.0, "val_loss": 17.31584370136261, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17613077163696, "training_acc": 53.0, "val_loss": 17.3146590590477, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14276194572449, "training_acc": 53.0, "val_loss": 17.31393039226532, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14326214790344, "training_acc": 53.0, "val_loss": 17.313452064990997, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14601421356201, "training_acc": 53.0, "val_loss": 17.313311994075775, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16725015640259, "training_acc": 53.0, "val_loss": 17.313501238822937, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12847185134888, "training_acc": 53.0, "val_loss": 17.3138365149498, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13471913337708, "training_acc": 53.0, "val_loss": 17.31426566839218, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1038248538971, "training_acc": 53.0, "val_loss": 17.3145592212677, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12467527389526, "training_acc": 53.0, "val_loss": 17.31494516134262, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1371374130249, "training_acc": 53.0, "val_loss": 17.315442860126495, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11992239952087, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14025616645813, "training_acc": 53.0, "val_loss": 17.31630265712738, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14569592475891, "training_acc": 53.0, "val_loss": 17.317090928554535, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14726257324219, "training_acc": 53.0, "val_loss": 17.31761544942856, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12411212921143, "training_acc": 53.0, "val_loss": 17.317794263362885, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12178421020508, "training_acc": 53.0, "val_loss": 17.317867279052734, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11232876777649, "training_acc": 53.0, "val_loss": 17.318080365657806, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11654591560364, "training_acc": 53.0, "val_loss": 17.318183183670044, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1287407875061, "training_acc": 53.0, "val_loss": 17.31833964586258, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12918400764465, "training_acc": 53.0, "val_loss": 17.318527400493622, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.11594367027283, "training_acc": 53.0, "val_loss": 17.318935692310333, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1191475391388, "training_acc": 53.0, "val_loss": 17.319190502166748, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11021184921265, "training_acc": 53.0, "val_loss": 17.319256067276, "val_acc": 52.0}
