"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24178433418274, "training_acc": 53.0, "val_loss": 17.347581684589386, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18491411209106, "training_acc": 53.0, "val_loss": 17.34350174665451, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16740012168884, "training_acc": 53.0, "val_loss": 17.338959872722626, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2009129524231, "training_acc": 53.0, "val_loss": 17.3346608877182, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.21089243888855, "training_acc": 53.0, "val_loss": 17.33079105615616, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15219187736511, "training_acc": 53.0, "val_loss": 17.328591644763947, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12766575813293, "training_acc": 53.0, "val_loss": 17.326369881629944, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15739130973816, "training_acc": 53.0, "val_loss": 17.32395589351654, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1510112285614, "training_acc": 53.0, "val_loss": 17.321740090847015, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16380047798157, "training_acc": 53.0, "val_loss": 17.32000559568405, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16130590438843, "training_acc": 53.0, "val_loss": 17.318692803382874, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1039068698883, "training_acc": 53.0, "val_loss": 17.31821745634079, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13197445869446, "training_acc": 53.0, "val_loss": 17.317917943000793, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14348077774048, "training_acc": 53.0, "val_loss": 17.31712371110916, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11792993545532, "training_acc": 53.0, "val_loss": 17.316848039627075, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12756443023682, "training_acc": 53.0, "val_loss": 17.316554486751556, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13029885292053, "training_acc": 53.0, "val_loss": 17.31627583503723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1430172920227, "training_acc": 53.0, "val_loss": 17.315673828125, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12222743034363, "training_acc": 53.0, "val_loss": 17.315229773521423, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13560557365417, "training_acc": 53.0, "val_loss": 17.314930260181427, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1418297290802, "training_acc": 53.0, "val_loss": 17.31453239917755, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13892483711243, "training_acc": 53.0, "val_loss": 17.314358055591583, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1528012752533, "training_acc": 53.0, "val_loss": 17.314380407333374, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11270546913147, "training_acc": 53.0, "val_loss": 17.314279079437256, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10617208480835, "training_acc": 53.0, "val_loss": 17.313960194587708, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15592122077942, "training_acc": 53.0, "val_loss": 17.313674092292786, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14093327522278, "training_acc": 53.0, "val_loss": 17.31340140104294, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11699318885803, "training_acc": 53.0, "val_loss": 17.313352227211, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12519145011902, "training_acc": 53.0, "val_loss": 17.31324791908264, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11929655075073, "training_acc": 53.0, "val_loss": 17.31352210044861, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.0931875705719, "training_acc": 53.0, "val_loss": 17.31436550617218, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12237858772278, "training_acc": 53.0, "val_loss": 17.315173149108887, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.09777045249939, "training_acc": 53.0, "val_loss": 17.315581440925598, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.09035181999207, "training_acc": 53.0, "val_loss": 17.316195368766785, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16167879104614, "training_acc": 53.0, "val_loss": 17.316511273384094, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.12118864059448, "training_acc": 53.0, "val_loss": 17.317017912864685, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12698173522949, "training_acc": 53.0, "val_loss": 17.31758862733841, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11575245857239, "training_acc": 53.0, "val_loss": 17.318065464496613, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14203691482544, "training_acc": 53.0, "val_loss": 17.31875240802765, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14074087142944, "training_acc": 53.0, "val_loss": 17.318950593471527, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.13410878181458, "training_acc": 53.0, "val_loss": 17.319107055664062, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13748526573181, "training_acc": 53.0, "val_loss": 17.319373786449432, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14226174354553, "training_acc": 53.0, "val_loss": 17.319434881210327, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16548418998718, "training_acc": 53.0, "val_loss": 17.319771647453308, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1286301612854, "training_acc": 53.0, "val_loss": 17.319780588150024, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1383888721466, "training_acc": 53.0, "val_loss": 17.319639027118683, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.1373598575592, "training_acc": 53.0, "val_loss": 17.319537699222565, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13517332077026, "training_acc": 53.0, "val_loss": 17.319203913211823, "val_acc": 52.0}
