"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.9846544265747, "training_acc": 47.0, "val_loss": 17.653103172779083, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.81960415840149, "training_acc": 47.0, "val_loss": 17.6208034157753, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.69527816772461, "training_acc": 47.0, "val_loss": 17.59011447429657, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.5437400341034, "training_acc": 47.0, "val_loss": 17.56134331226349, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.40794491767883, "training_acc": 47.0, "val_loss": 17.53418892621994, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.29924726486206, "training_acc": 47.0, "val_loss": 17.508915066719055, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.18291187286377, "training_acc": 47.0, "val_loss": 17.48553067445755, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.06057286262512, "training_acc": 47.0, "val_loss": 17.46378242969513, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.98741149902344, "training_acc": 47.0, "val_loss": 17.44440048933029, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.86707186698914, "training_acc": 47.0, "val_loss": 17.427991330623627, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.76494336128235, "training_acc": 47.0, "val_loss": 17.412789165973663, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.76540112495422, "training_acc": 47.0, "val_loss": 17.39891916513443, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.65840983390808, "training_acc": 47.0, "val_loss": 17.3869326710701, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.61612248420715, "training_acc": 47.0, "val_loss": 17.376670241355896, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.56881260871887, "training_acc": 47.0, "val_loss": 17.36719459295273, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.51548051834106, "training_acc": 47.0, "val_loss": 17.358623445034027, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.4652328491211, "training_acc": 47.0, "val_loss": 17.35079139471054, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.39863991737366, "training_acc": 47.0, "val_loss": 17.343303561210632, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.385502576828, "training_acc": 47.0, "val_loss": 17.33689308166504, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.35003685951233, "training_acc": 48.0, "val_loss": 17.33172833919525, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30963492393494, "training_acc": 50.0, "val_loss": 17.327556014060974, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.28585934638977, "training_acc": 54.0, "val_loss": 17.323993146419525, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.27171516418457, "training_acc": 53.0, "val_loss": 17.320775985717773, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26560378074646, "training_acc": 53.0, "val_loss": 17.318305373191833, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22280073165894, "training_acc": 53.0, "val_loss": 17.316356301307678, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.21660590171814, "training_acc": 53.0, "val_loss": 17.314468324184418, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21797966957092, "training_acc": 53.0, "val_loss": 17.313209176063538, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18504571914673, "training_acc": 53.0, "val_loss": 17.312274873256683, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17838406562805, "training_acc": 53.0, "val_loss": 17.31145828962326, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19805693626404, "training_acc": 53.0, "val_loss": 17.310939729213715, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17049789428711, "training_acc": 53.0, "val_loss": 17.310653626918793, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.16043448448181, "training_acc": 53.0, "val_loss": 17.310558259487152, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17942595481873, "training_acc": 53.0, "val_loss": 17.310577630996704, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12594795227051, "training_acc": 53.0, "val_loss": 17.31072962284088, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1536934375763, "training_acc": 53.0, "val_loss": 17.310966551303864, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.151535987854, "training_acc": 53.0, "val_loss": 17.311233282089233, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12243580818176, "training_acc": 53.0, "val_loss": 17.31153130531311, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12692403793335, "training_acc": 53.0, "val_loss": 17.3118457198143, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14957284927368, "training_acc": 53.0, "val_loss": 17.31220781803131, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11191701889038, "training_acc": 53.0, "val_loss": 17.312616109848022, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14324903488159, "training_acc": 53.0, "val_loss": 17.313075065612793, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12645268440247, "training_acc": 53.0, "val_loss": 17.313377559185028, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12704706192017, "training_acc": 53.0, "val_loss": 17.31371581554413, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.10072994232178, "training_acc": 53.0, "val_loss": 17.31409579515457, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.12454724311829, "training_acc": 53.0, "val_loss": 17.314405739307404, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12303566932678, "training_acc": 53.0, "val_loss": 17.31499880552292, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15349006652832, "training_acc": 53.0, "val_loss": 17.315277457237244, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.14229154586792, "training_acc": 53.0, "val_loss": 17.315350472927094, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.15198278427124, "training_acc": 53.0, "val_loss": 17.315271496772766, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12738847732544, "training_acc": 53.0, "val_loss": 17.314879596233368, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.14965081214905, "training_acc": 53.0, "val_loss": 17.314645648002625, "val_acc": 52.0}
