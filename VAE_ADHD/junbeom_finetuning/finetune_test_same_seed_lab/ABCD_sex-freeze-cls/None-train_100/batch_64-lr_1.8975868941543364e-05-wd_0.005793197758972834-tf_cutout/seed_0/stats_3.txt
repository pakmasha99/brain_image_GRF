"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26431441307068, "training_acc": 53.0, "val_loss": 17.31296181678772, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21687126159668, "training_acc": 53.0, "val_loss": 17.313064634799957, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20487022399902, "training_acc": 53.0, "val_loss": 17.31256991624832, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18920946121216, "training_acc": 53.0, "val_loss": 17.311793565750122, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22436189651489, "training_acc": 53.0, "val_loss": 17.311249673366547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18383860588074, "training_acc": 53.0, "val_loss": 17.310677468776703, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16725373268127, "training_acc": 53.0, "val_loss": 17.31022000312805, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1833872795105, "training_acc": 53.0, "val_loss": 17.30979084968567, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16650199890137, "training_acc": 53.0, "val_loss": 17.30961501598358, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16921210289001, "training_acc": 53.0, "val_loss": 17.30949729681015, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17144989967346, "training_acc": 53.0, "val_loss": 17.30947643518448, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13340353965759, "training_acc": 53.0, "val_loss": 17.30949729681015, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1643648147583, "training_acc": 53.0, "val_loss": 17.309531569480896, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14975333213806, "training_acc": 53.0, "val_loss": 17.309555411338806, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16562223434448, "training_acc": 53.0, "val_loss": 17.30956733226776, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18571209907532, "training_acc": 53.0, "val_loss": 17.309558391571045, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17254090309143, "training_acc": 53.0, "val_loss": 17.30957329273224, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16436314582825, "training_acc": 53.0, "val_loss": 17.30961948633194, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12750959396362, "training_acc": 53.0, "val_loss": 17.309699952602386, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1981246471405, "training_acc": 53.0, "val_loss": 17.309758067131042, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16269326210022, "training_acc": 53.0, "val_loss": 17.30983853340149, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15667772293091, "training_acc": 53.0, "val_loss": 17.309939861297607, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14140558242798, "training_acc": 53.0, "val_loss": 17.31003373861313, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.126638174057, "training_acc": 53.0, "val_loss": 17.310091853141785, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16333770751953, "training_acc": 53.0, "val_loss": 17.310333251953125, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16345071792603, "training_acc": 53.0, "val_loss": 17.310722172260284, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13572239875793, "training_acc": 53.0, "val_loss": 17.311084270477295, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12428784370422, "training_acc": 53.0, "val_loss": 17.311185598373413, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15543341636658, "training_acc": 53.0, "val_loss": 17.311184108257294, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16109776496887, "training_acc": 53.0, "val_loss": 17.311351001262665, "val_acc": 52.0}
