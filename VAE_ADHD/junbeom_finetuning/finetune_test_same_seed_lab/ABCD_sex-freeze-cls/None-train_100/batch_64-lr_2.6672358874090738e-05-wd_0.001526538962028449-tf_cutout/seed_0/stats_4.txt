"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.15533018112183, "training_acc": 53.0, "val_loss": 17.315252125263214, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13318610191345, "training_acc": 53.0, "val_loss": 17.316707968711853, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1169810295105, "training_acc": 53.0, "val_loss": 17.316827178001404, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15963673591614, "training_acc": 53.0, "val_loss": 17.316195368766785, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15579533576965, "training_acc": 53.0, "val_loss": 17.315728962421417, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13140225410461, "training_acc": 53.0, "val_loss": 17.3153817653656, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09023714065552, "training_acc": 53.0, "val_loss": 17.31560081243515, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16518425941467, "training_acc": 53.0, "val_loss": 17.31622666120529, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1627357006073, "training_acc": 53.0, "val_loss": 17.317214608192444, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1411600112915, "training_acc": 53.0, "val_loss": 17.317114770412445, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13548398017883, "training_acc": 53.0, "val_loss": 17.31732189655304, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12910199165344, "training_acc": 53.0, "val_loss": 17.317813634872437, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17065167427063, "training_acc": 53.0, "val_loss": 17.317816615104675, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16049599647522, "training_acc": 53.0, "val_loss": 17.318977415561676, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13852906227112, "training_acc": 53.0, "val_loss": 17.319083213806152, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13638591766357, "training_acc": 53.0, "val_loss": 17.318645119667053, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13843512535095, "training_acc": 53.0, "val_loss": 17.317964136600494, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14135837554932, "training_acc": 53.0, "val_loss": 17.31666773557663, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1595561504364, "training_acc": 53.0, "val_loss": 17.315849661827087, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15633869171143, "training_acc": 53.0, "val_loss": 17.31557548046112, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14248561859131, "training_acc": 53.0, "val_loss": 17.314639687538147, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14860129356384, "training_acc": 53.0, "val_loss": 17.313984036445618, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12334656715393, "training_acc": 53.0, "val_loss": 17.313741147518158, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.150475025177, "training_acc": 53.0, "val_loss": 17.31346845626831, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11596965789795, "training_acc": 53.0, "val_loss": 17.31371432542801, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15115737915039, "training_acc": 53.0, "val_loss": 17.31426566839218, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12702250480652, "training_acc": 53.0, "val_loss": 17.314612865447998, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15342402458191, "training_acc": 53.0, "val_loss": 17.314746975898743, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13481831550598, "training_acc": 53.0, "val_loss": 17.314712703227997, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15340399742126, "training_acc": 53.0, "val_loss": 17.314396798610687, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12028622627258, "training_acc": 53.0, "val_loss": 17.313693463802338, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15730786323547, "training_acc": 53.0, "val_loss": 17.313146591186523, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13339900970459, "training_acc": 53.0, "val_loss": 17.313122749328613, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13648700714111, "training_acc": 53.0, "val_loss": 17.312949895858765, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14607810974121, "training_acc": 53.0, "val_loss": 17.313045263290405, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18257355690002, "training_acc": 53.0, "val_loss": 17.312976717948914, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1544086933136, "training_acc": 53.0, "val_loss": 17.313075065612793, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15357637405396, "training_acc": 53.0, "val_loss": 17.31327176094055, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17543339729309, "training_acc": 53.0, "val_loss": 17.313504219055176, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16815757751465, "training_acc": 53.0, "val_loss": 17.313461005687714, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14942169189453, "training_acc": 53.0, "val_loss": 17.313311994075775, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.14985466003418, "training_acc": 53.0, "val_loss": 17.31344163417816, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.16688346862793, "training_acc": 53.0, "val_loss": 17.313523590564728, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.11465072631836, "training_acc": 53.0, "val_loss": 17.313656210899353, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.14487075805664, "training_acc": 53.0, "val_loss": 17.313502728939056, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.13097405433655, "training_acc": 53.0, "val_loss": 17.313407361507416, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14435982704163, "training_acc": 53.0, "val_loss": 17.313577234745026, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16344785690308, "training_acc": 53.0, "val_loss": 17.313945293426514, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.14114093780518, "training_acc": 53.0, "val_loss": 17.313888669013977, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.15203189849854, "training_acc": 53.0, "val_loss": 17.313963174819946, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.14158987998962, "training_acc": 53.0, "val_loss": 17.313960194587708, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.134437084198, "training_acc": 53.0, "val_loss": 17.31424629688263, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.15713572502136, "training_acc": 53.0, "val_loss": 17.314524948596954, "val_acc": 52.0}
