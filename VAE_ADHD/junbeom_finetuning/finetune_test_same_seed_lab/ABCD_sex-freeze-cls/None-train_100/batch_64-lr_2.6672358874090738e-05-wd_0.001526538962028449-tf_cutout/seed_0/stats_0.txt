"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23213481903076, "training_acc": 52.0, "val_loss": 17.2316312789917, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22527265548706, "training_acc": 52.0, "val_loss": 17.226286232471466, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24253344535828, "training_acc": 52.0, "val_loss": 17.22598671913147, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26397752761841, "training_acc": 52.0, "val_loss": 17.229601740837097, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23859524726868, "training_acc": 52.0, "val_loss": 17.235462367534637, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22027325630188, "training_acc": 52.0, "val_loss": 17.23777949810028, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.2532308101654, "training_acc": 52.0, "val_loss": 17.242801189422607, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24490547180176, "training_acc": 52.0, "val_loss": 17.246049642562866, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.24226117134094, "training_acc": 52.0, "val_loss": 17.245598137378693, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2480194568634, "training_acc": 52.0, "val_loss": 17.248398065567017, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22396779060364, "training_acc": 52.0, "val_loss": 17.250770330429077, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.25389957427979, "training_acc": 52.0, "val_loss": 17.25166290998459, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.2229814529419, "training_acc": 52.0, "val_loss": 17.252160608768463, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23574995994568, "training_acc": 52.0, "val_loss": 17.25354790687561, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2477605342865, "training_acc": 52.0, "val_loss": 17.25267916917801, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25579452514648, "training_acc": 52.0, "val_loss": 17.250218987464905, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25138735771179, "training_acc": 52.0, "val_loss": 17.24540740251541, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23701906204224, "training_acc": 52.0, "val_loss": 17.241637408733368, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24248147010803, "training_acc": 52.0, "val_loss": 17.237916588783264, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25384879112244, "training_acc": 52.0, "val_loss": 17.23432093858719, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20039701461792, "training_acc": 52.0, "val_loss": 17.231984436511993, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21737718582153, "training_acc": 52.0, "val_loss": 17.229121923446655, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27482676506042, "training_acc": 52.0, "val_loss": 17.2248438000679, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25479221343994, "training_acc": 52.0, "val_loss": 17.22370833158493, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25813746452332, "training_acc": 52.0, "val_loss": 17.224185168743134, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24041676521301, "training_acc": 52.0, "val_loss": 17.226143181324005, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.273108959198, "training_acc": 52.0, "val_loss": 17.226111888885498, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23067903518677, "training_acc": 52.0, "val_loss": 17.230217158794403, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23034477233887, "training_acc": 52.0, "val_loss": 17.234201729297638, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.24945735931396, "training_acc": 52.0, "val_loss": 17.235800623893738, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.24997448921204, "training_acc": 52.0, "val_loss": 17.23567396402359, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.25326681137085, "training_acc": 52.0, "val_loss": 17.23877340555191, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23577046394348, "training_acc": 52.0, "val_loss": 17.238250374794006, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2494113445282, "training_acc": 52.0, "val_loss": 17.238113284111023, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24748682975769, "training_acc": 52.0, "val_loss": 17.236892879009247, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23781943321228, "training_acc": 52.0, "val_loss": 17.236827313899994, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23835682868958, "training_acc": 52.0, "val_loss": 17.236460745334625, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23758268356323, "training_acc": 52.0, "val_loss": 17.235437035560608, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2370195388794, "training_acc": 52.0, "val_loss": 17.23213493824005, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2322907447815, "training_acc": 52.0, "val_loss": 17.226889729499817, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22638630867004, "training_acc": 52.0, "val_loss": 17.22431182861328, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24770832061768, "training_acc": 52.0, "val_loss": 17.22217947244644, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.25137329101562, "training_acc": 52.0, "val_loss": 17.22034364938736, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22287201881409, "training_acc": 52.0, "val_loss": 17.220298945903778, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.2391049861908, "training_acc": 52.0, "val_loss": 17.223043739795685, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24203419685364, "training_acc": 52.0, "val_loss": 17.224666476249695, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25650405883789, "training_acc": 52.0, "val_loss": 17.227035760879517, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22833371162415, "training_acc": 52.0, "val_loss": 17.229531705379486, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22559404373169, "training_acc": 52.0, "val_loss": 17.230212688446045, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23070335388184, "training_acc": 52.0, "val_loss": 17.23102480173111, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25286555290222, "training_acc": 52.0, "val_loss": 17.233166098594666, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24764370918274, "training_acc": 52.0, "val_loss": 17.235833406448364, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25036215782166, "training_acc": 52.0, "val_loss": 17.238245904445648, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.25704312324524, "training_acc": 52.0, "val_loss": 17.241071164608, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.20835041999817, "training_acc": 52.0, "val_loss": 17.2436460852623, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.23739290237427, "training_acc": 52.0, "val_loss": 17.244447767734528, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23396134376526, "training_acc": 52.0, "val_loss": 17.246417701244354, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23527431488037, "training_acc": 52.0, "val_loss": 17.24882274866104, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22593688964844, "training_acc": 52.0, "val_loss": 17.24943071603775, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25471949577332, "training_acc": 52.0, "val_loss": 17.25003719329834, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.26426601409912, "training_acc": 52.0, "val_loss": 17.248381674289703, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24006247520447, "training_acc": 52.0, "val_loss": 17.248405516147614, "val_acc": 56.0}
{"epoch": 62, "training_loss": 69.22180438041687, "training_acc": 52.0, "val_loss": 17.24778264760971, "val_acc": 56.0}
