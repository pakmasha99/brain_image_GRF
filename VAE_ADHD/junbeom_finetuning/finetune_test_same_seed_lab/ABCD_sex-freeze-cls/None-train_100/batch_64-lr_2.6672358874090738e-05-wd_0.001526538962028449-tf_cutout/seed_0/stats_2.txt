"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.1324782371521, "training_acc": 53.0, "val_loss": 17.31097251176834, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.15237355232239, "training_acc": 53.0, "val_loss": 17.31310784816742, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14008903503418, "training_acc": 53.0, "val_loss": 17.3140287399292, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16188645362854, "training_acc": 53.0, "val_loss": 17.312461137771606, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13295340538025, "training_acc": 53.0, "val_loss": 17.312709987163544, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15278387069702, "training_acc": 53.0, "val_loss": 17.31223613023758, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14189505577087, "training_acc": 53.0, "val_loss": 17.31172651052475, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.10813069343567, "training_acc": 53.0, "val_loss": 17.311738431453705, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13684415817261, "training_acc": 53.0, "val_loss": 17.31131076812744, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17123103141785, "training_acc": 53.0, "val_loss": 17.31056421995163, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13690495491028, "training_acc": 53.0, "val_loss": 17.31039583683014, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12507939338684, "training_acc": 53.0, "val_loss": 17.309436202049255, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15016484260559, "training_acc": 53.0, "val_loss": 17.3084557056427, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12580513954163, "training_acc": 53.0, "val_loss": 17.307819426059723, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14522552490234, "training_acc": 53.0, "val_loss": 17.30780303478241, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16057205200195, "training_acc": 53.0, "val_loss": 17.30780154466629, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18287944793701, "training_acc": 53.0, "val_loss": 17.30741411447525, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13663005828857, "training_acc": 53.0, "val_loss": 17.30751246213913, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1380124092102, "training_acc": 53.0, "val_loss": 17.307937145233154, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13016819953918, "training_acc": 53.0, "val_loss": 17.307990789413452, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14245986938477, "training_acc": 53.0, "val_loss": 17.30789542198181, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16377639770508, "training_acc": 53.0, "val_loss": 17.30778068304062, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15124130249023, "training_acc": 53.0, "val_loss": 17.308315634727478, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1544759273529, "training_acc": 53.0, "val_loss": 17.308908700942993, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12497043609619, "training_acc": 53.0, "val_loss": 17.309728264808655, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13904142379761, "training_acc": 53.0, "val_loss": 17.310887575149536, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11951494216919, "training_acc": 53.0, "val_loss": 17.3124760389328, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1188097000122, "training_acc": 53.0, "val_loss": 17.31361746788025, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12496995925903, "training_acc": 53.0, "val_loss": 17.31438785791397, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15153956413269, "training_acc": 53.0, "val_loss": 17.315129935741425, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13182377815247, "training_acc": 53.0, "val_loss": 17.315658926963806, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13998007774353, "training_acc": 53.0, "val_loss": 17.31598675251007, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12550663948059, "training_acc": 53.0, "val_loss": 17.316119372844696, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.13800859451294, "training_acc": 53.0, "val_loss": 17.316290736198425, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.13633918762207, "training_acc": 53.0, "val_loss": 17.316126823425293, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.11877918243408, "training_acc": 53.0, "val_loss": 17.315703630447388, "val_acc": 52.0}
