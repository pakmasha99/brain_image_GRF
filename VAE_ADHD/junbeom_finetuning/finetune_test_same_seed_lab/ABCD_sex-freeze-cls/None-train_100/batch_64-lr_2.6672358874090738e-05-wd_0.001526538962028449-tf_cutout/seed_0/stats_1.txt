"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.49529933929443, "training_acc": 47.0, "val_loss": 17.53264218568802, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.33358311653137, "training_acc": 47.0, "val_loss": 17.49851554632187, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.1144688129425, "training_acc": 47.0, "val_loss": 17.4701988697052, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.04876661300659, "training_acc": 47.0, "val_loss": 17.445220053195953, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.88832473754883, "training_acc": 47.0, "val_loss": 17.42468923330307, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.74862599372864, "training_acc": 47.0, "val_loss": 17.406143248081207, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.66981506347656, "training_acc": 47.0, "val_loss": 17.38848239183426, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.60335111618042, "training_acc": 47.0, "val_loss": 17.372767627239227, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.54018187522888, "training_acc": 47.0, "val_loss": 17.358584702014923, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.47887825965881, "training_acc": 47.0, "val_loss": 17.346663773059845, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4265525341034, "training_acc": 47.0, "val_loss": 17.336837947368622, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.38774871826172, "training_acc": 47.0, "val_loss": 17.328691482543945, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.31073713302612, "training_acc": 51.0, "val_loss": 17.322349548339844, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24501776695251, "training_acc": 53.0, "val_loss": 17.317451536655426, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23200058937073, "training_acc": 53.0, "val_loss": 17.313584685325623, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1999785900116, "training_acc": 53.0, "val_loss": 17.311109602451324, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18849992752075, "training_acc": 53.0, "val_loss": 17.3095703125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2152931690216, "training_acc": 53.0, "val_loss": 17.308993637561798, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15656781196594, "training_acc": 53.0, "val_loss": 17.3089399933815, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16148734092712, "training_acc": 53.0, "val_loss": 17.309150099754333, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18181300163269, "training_acc": 53.0, "val_loss": 17.309477925300598, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13618469238281, "training_acc": 53.0, "val_loss": 17.310161888599396, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17151379585266, "training_acc": 53.0, "val_loss": 17.310966551303864, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.09402513504028, "training_acc": 53.0, "val_loss": 17.31187254190445, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14720177650452, "training_acc": 53.0, "val_loss": 17.31303185224533, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13172101974487, "training_acc": 53.0, "val_loss": 17.313842475414276, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16181945800781, "training_acc": 53.0, "val_loss": 17.314578592777252, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14271283149719, "training_acc": 53.0, "val_loss": 17.314831912517548, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13202285766602, "training_acc": 53.0, "val_loss": 17.31545180082321, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15598011016846, "training_acc": 53.0, "val_loss": 17.316199839115143, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14503812789917, "training_acc": 53.0, "val_loss": 17.316676676273346, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15571904182434, "training_acc": 53.0, "val_loss": 17.316994071006775, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12320280075073, "training_acc": 53.0, "val_loss": 17.31758862733841, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12920117378235, "training_acc": 53.0, "val_loss": 17.318156361579895, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.11900448799133, "training_acc": 53.0, "val_loss": 17.318740487098694, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1284863948822, "training_acc": 53.0, "val_loss": 17.31852889060974, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14287638664246, "training_acc": 53.0, "val_loss": 17.31841415166855, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13886451721191, "training_acc": 53.0, "val_loss": 17.318221926689148, "val_acc": 52.0}
