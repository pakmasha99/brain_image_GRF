"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.93314266204834, "training_acc": 47.0, "val_loss": 17.318792641162872, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.01301956176758, "training_acc": 54.0, "val_loss": 17.35832542181015, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.70452189445496, "training_acc": 53.0, "val_loss": 17.549116909503937, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.90811800956726, "training_acc": 53.0, "val_loss": 17.45736598968506, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.39439988136292, "training_acc": 53.0, "val_loss": 17.312267422676086, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25064539909363, "training_acc": 53.0, "val_loss": 17.330177128314972, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.49665808677673, "training_acc": 47.0, "val_loss": 17.368680238723755, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.7064368724823, "training_acc": 47.0, "val_loss": 17.339007556438446, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3168077468872, "training_acc": 51.0, "val_loss": 17.304113507270813, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.54473829269409, "training_acc": 53.0, "val_loss": 17.367397248744965, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28589367866516, "training_acc": 53.0, "val_loss": 17.387332022190094, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.34339904785156, "training_acc": 53.0, "val_loss": 17.399121820926666, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.34408950805664, "training_acc": 53.0, "val_loss": 17.363376915454865, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21522235870361, "training_acc": 53.0, "val_loss": 17.321094870567322, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19866895675659, "training_acc": 53.0, "val_loss": 17.30284094810486, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.23196339607239, "training_acc": 53.0, "val_loss": 17.314380407333374, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.27331686019897, "training_acc": 53.0, "val_loss": 17.31264442205429, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.24902272224426, "training_acc": 53.0, "val_loss": 17.305046319961548, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15909504890442, "training_acc": 53.0, "val_loss": 17.30632185935974, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19715929031372, "training_acc": 53.0, "val_loss": 17.34035760164261, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.27487969398499, "training_acc": 53.0, "val_loss": 17.359985411167145, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26393556594849, "training_acc": 53.0, "val_loss": 17.334453761577606, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18502140045166, "training_acc": 53.0, "val_loss": 17.31003224849701, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21876907348633, "training_acc": 53.0, "val_loss": 17.30232536792755, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15333652496338, "training_acc": 53.0, "val_loss": 17.30230748653412, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.3372118473053, "training_acc": 53.0, "val_loss": 17.30252206325531, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21741342544556, "training_acc": 53.0, "val_loss": 17.31792539358139, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12482953071594, "training_acc": 53.0, "val_loss": 17.398643493652344, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.53761625289917, "training_acc": 53.0, "val_loss": 17.458708584308624, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.61079263687134, "training_acc": 53.0, "val_loss": 17.40425080060959, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.36341571807861, "training_acc": 53.0, "val_loss": 17.35081970691681, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.38671588897705, "training_acc": 53.0, "val_loss": 17.30722337961197, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.20868396759033, "training_acc": 53.0, "val_loss": 17.302332818508148, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.18058133125305, "training_acc": 53.0, "val_loss": 17.30234920978546, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.18627858161926, "training_acc": 53.0, "val_loss": 17.303550243377686, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.20973706245422, "training_acc": 53.0, "val_loss": 17.31957197189331, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16532921791077, "training_acc": 53.0, "val_loss": 17.325682938098907, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20181965827942, "training_acc": 53.0, "val_loss": 17.326730489730835, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14707517623901, "training_acc": 53.0, "val_loss": 17.32848286628723, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.2179958820343, "training_acc": 53.0, "val_loss": 17.319530248641968, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.18363285064697, "training_acc": 53.0, "val_loss": 17.320850491523743, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.17799687385559, "training_acc": 53.0, "val_loss": 17.31167733669281, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14816331863403, "training_acc": 53.0, "val_loss": 17.305217683315277, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16361141204834, "training_acc": 53.0, "val_loss": 17.304126918315887, "val_acc": 52.0}
