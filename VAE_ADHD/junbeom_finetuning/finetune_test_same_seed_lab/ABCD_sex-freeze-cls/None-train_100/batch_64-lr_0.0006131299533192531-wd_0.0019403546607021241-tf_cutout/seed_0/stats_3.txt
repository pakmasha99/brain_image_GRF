"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.6072747707367, "training_acc": 45.0, "val_loss": 17.387689650058746, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.28106594085693, "training_acc": 51.0, "val_loss": 17.40325838327408, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.30499362945557, "training_acc": 53.0, "val_loss": 17.637167870998383, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.12057137489319, "training_acc": 53.0, "val_loss": 17.59556531906128, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.85819602012634, "training_acc": 53.0, "val_loss": 17.41974949836731, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.38890647888184, "training_acc": 53.0, "val_loss": 17.312030494213104, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.27543234825134, "training_acc": 53.0, "val_loss": 17.3531636595726, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.73729538917542, "training_acc": 47.0, "val_loss": 17.367781698703766, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.6976068019867, "training_acc": 41.0, "val_loss": 17.316757142543793, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15402913093567, "training_acc": 53.0, "val_loss": 17.313888669013977, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11822438240051, "training_acc": 53.0, "val_loss": 17.3438623547554, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.5003011226654, "training_acc": 53.0, "val_loss": 17.37506091594696, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22882008552551, "training_acc": 53.0, "val_loss": 17.33783483505249, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08209657669067, "training_acc": 53.0, "val_loss": 17.31368601322174, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.08526730537415, "training_acc": 53.0, "val_loss": 17.321497201919556, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21707963943481, "training_acc": 53.0, "val_loss": 17.346040904521942, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.46658706665039, "training_acc": 47.0, "val_loss": 17.36004799604416, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.44309782981873, "training_acc": 47.0, "val_loss": 17.329461872577667, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.22662568092346, "training_acc": 54.0, "val_loss": 17.31279343366623, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.28228878974915, "training_acc": 53.0, "val_loss": 17.347069084644318, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21352887153625, "training_acc": 53.0, "val_loss": 17.369946837425232, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23566818237305, "training_acc": 53.0, "val_loss": 17.36079603433609, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20666527748108, "training_acc": 53.0, "val_loss": 17.333760857582092, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.10686874389648, "training_acc": 53.0, "val_loss": 17.313598096370697, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.48840951919556, "training_acc": 53.0, "val_loss": 17.315642535686493, "val_acc": 52.0}
