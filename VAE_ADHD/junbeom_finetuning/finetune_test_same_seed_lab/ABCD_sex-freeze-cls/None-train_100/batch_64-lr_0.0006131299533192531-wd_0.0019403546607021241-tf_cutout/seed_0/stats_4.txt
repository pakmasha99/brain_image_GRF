"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.68857145309448, "training_acc": 53.0, "val_loss": 17.441995441913605, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.58134174346924, "training_acc": 53.0, "val_loss": 17.6291361451149, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.10969185829163, "training_acc": 53.0, "val_loss": 17.409522831439972, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.24302244186401, "training_acc": 53.0, "val_loss": 17.3088476061821, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19041514396667, "training_acc": 53.0, "val_loss": 17.352457344532013, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.53257775306702, "training_acc": 47.0, "val_loss": 17.350131273269653, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32525587081909, "training_acc": 47.0, "val_loss": 17.308402061462402, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.08369779586792, "training_acc": 53.0, "val_loss": 17.372359335422516, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.32270836830139, "training_acc": 53.0, "val_loss": 17.454981803894043, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.48847150802612, "training_acc": 53.0, "val_loss": 17.40427166223526, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.34158682823181, "training_acc": 53.0, "val_loss": 17.328359186649323, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14814352989197, "training_acc": 53.0, "val_loss": 17.309878766536713, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.24348711967468, "training_acc": 53.0, "val_loss": 17.32388585805893, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.27450609207153, "training_acc": 53.0, "val_loss": 17.311109602451324, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.51342821121216, "training_acc": 53.0, "val_loss": 17.317195236682892, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13674259185791, "training_acc": 53.0, "val_loss": 17.316851019859314, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12675452232361, "training_acc": 53.0, "val_loss": 17.314375936985016, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14375138282776, "training_acc": 53.0, "val_loss": 17.312005162239075, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16033935546875, "training_acc": 53.0, "val_loss": 17.308309674263, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17506527900696, "training_acc": 53.0, "val_loss": 17.3158660531044, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.23570680618286, "training_acc": 53.0, "val_loss": 17.314496636390686, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21499371528625, "training_acc": 53.0, "val_loss": 17.308330535888672, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13260912895203, "training_acc": 53.0, "val_loss": 17.33081042766571, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21024751663208, "training_acc": 53.0, "val_loss": 17.4126073718071, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.50111865997314, "training_acc": 53.0, "val_loss": 17.422927916049957, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.3641893863678, "training_acc": 53.0, "val_loss": 17.33820140361786, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15055179595947, "training_acc": 53.0, "val_loss": 17.31191575527191, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.39130473136902, "training_acc": 47.0, "val_loss": 17.34325736761093, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.45204973220825, "training_acc": 45.0, "val_loss": 17.322134971618652, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.25990009307861, "training_acc": 53.0, "val_loss": 17.308571934700012, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17118716239929, "training_acc": 53.0, "val_loss": 17.31804609298706, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.43784213066101, "training_acc": 53.0, "val_loss": 17.391437292099, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.34759712219238, "training_acc": 53.0, "val_loss": 17.384900152683258, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.49927878379822, "training_acc": 53.0, "val_loss": 17.339076101779938, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17279362678528, "training_acc": 53.0, "val_loss": 17.32560098171234, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1521909236908, "training_acc": 53.0, "val_loss": 17.312800884246826, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12876534461975, "training_acc": 53.0, "val_loss": 17.308524250984192, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.186527967453, "training_acc": 53.0, "val_loss": 17.310482263565063, "val_acc": 52.0}
