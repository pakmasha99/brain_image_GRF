"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.35000157356262, "training_acc": 53.0, "val_loss": 17.310062050819397, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17824673652649, "training_acc": 53.0, "val_loss": 17.31020361185074, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15301442146301, "training_acc": 53.0, "val_loss": 17.310626804828644, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1847472190857, "training_acc": 53.0, "val_loss": 17.310182750225067, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15645980834961, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18645811080933, "training_acc": 53.0, "val_loss": 17.309226095676422, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1446008682251, "training_acc": 53.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14387083053589, "training_acc": 53.0, "val_loss": 17.31034815311432, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12843036651611, "training_acc": 53.0, "val_loss": 17.3115536570549, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13467144966125, "training_acc": 53.0, "val_loss": 17.312657833099365, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15015435218811, "training_acc": 53.0, "val_loss": 17.31303334236145, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1094868183136, "training_acc": 53.0, "val_loss": 17.315182089805603, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13189601898193, "training_acc": 53.0, "val_loss": 17.3186257481575, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17379426956177, "training_acc": 53.0, "val_loss": 17.321255803108215, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1460120677948, "training_acc": 53.0, "val_loss": 17.320449650287628, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13366889953613, "training_acc": 53.0, "val_loss": 17.318469285964966, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13021159172058, "training_acc": 53.0, "val_loss": 17.31792390346527, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1175696849823, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11349296569824, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387631416321, "training_acc": 53.0, "val_loss": 17.318490147590637, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14730501174927, "training_acc": 53.0, "val_loss": 17.318038642406464, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12122535705566, "training_acc": 53.0, "val_loss": 17.315509915351868, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14265251159668, "training_acc": 53.0, "val_loss": 17.313970625400543, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11603498458862, "training_acc": 53.0, "val_loss": 17.312900722026825, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1060700416565, "training_acc": 53.0, "val_loss": 17.311669886112213, "val_acc": 52.0}
