"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.73361539840698, "training_acc": 45.0, "val_loss": 17.509828507900238, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.11392450332642, "training_acc": 53.0, "val_loss": 17.451763153076172, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.92237186431885, "training_acc": 47.0, "val_loss": 17.5550177693367, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.24948453903198, "training_acc": 47.0, "val_loss": 17.317603528499603, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.26546263694763, "training_acc": 53.0, "val_loss": 17.459815740585327, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.52780985832214, "training_acc": 53.0, "val_loss": 17.504291236400604, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.98367643356323, "training_acc": 53.0, "val_loss": 17.360635101795197, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1825704574585, "training_acc": 53.0, "val_loss": 17.315806448459625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13153839111328, "training_acc": 53.0, "val_loss": 17.30859875679016, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15574193000793, "training_acc": 53.0, "val_loss": 17.332908511161804, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.3479745388031, "training_acc": 47.0, "val_loss": 17.323848605155945, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.228346824646, "training_acc": 54.0, "val_loss": 17.314495146274567, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.49285817146301, "training_acc": 53.0, "val_loss": 17.418426275253296, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.36125135421753, "training_acc": 53.0, "val_loss": 17.339298129081726, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.95926880836487, "training_acc": 53.0, "val_loss": 17.30726659297943, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.44672083854675, "training_acc": 53.0, "val_loss": 17.316649854183197, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1072199344635, "training_acc": 53.0, "val_loss": 17.308852076530457, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.45247721672058, "training_acc": 53.0, "val_loss": 17.307300865650177, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1625509262085, "training_acc": 53.0, "val_loss": 17.354144155979156, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21841788291931, "training_acc": 53.0, "val_loss": 17.36452877521515, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24277853965759, "training_acc": 53.0, "val_loss": 17.316561937332153, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.23840260505676, "training_acc": 53.0, "val_loss": 17.322513461112976, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.50784111022949, "training_acc": 45.0, "val_loss": 17.314185202121735, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.29151105880737, "training_acc": 53.0, "val_loss": 17.350491881370544, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.31459474563599, "training_acc": 53.0, "val_loss": 17.384470999240875, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.30019688606262, "training_acc": 53.0, "val_loss": 17.316195368766785, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11875653266907, "training_acc": 53.0, "val_loss": 17.312519252300262, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.26701664924622, "training_acc": 53.0, "val_loss": 17.313610017299652, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18038964271545, "training_acc": 53.0, "val_loss": 17.316779494285583, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.10391616821289, "training_acc": 53.0, "val_loss": 17.381568253040314, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.45289945602417, "training_acc": 53.0, "val_loss": 17.372344434261322, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.26166653633118, "training_acc": 53.0, "val_loss": 17.30729192495346, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.25935864448547, "training_acc": 52.0, "val_loss": 17.32078492641449, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.24137091636658, "training_acc": 54.0, "val_loss": 17.30780601501465, "val_acc": 52.0}
