"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.03526616096497, "training_acc": 45.0, "val_loss": 17.464634776115417, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.28091788291931, "training_acc": 47.0, "val_loss": 17.922906577587128, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.20173716545105, "training_acc": 53.0, "val_loss": 17.90979355573654, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.97468709945679, "training_acc": 53.0, "val_loss": 17.37070232629776, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.07951283454895, "training_acc": 53.0, "val_loss": 17.36774742603302, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.53193521499634, "training_acc": 47.0, "val_loss": 17.485429346561432, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.04711842536926, "training_acc": 47.0, "val_loss": 17.3697829246521, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.4194586277008, "training_acc": 49.0, "val_loss": 17.329981923103333, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.0968177318573, "training_acc": 53.0, "val_loss": 17.472974956035614, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.6433973312378, "training_acc": 53.0, "val_loss": 17.486804723739624, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.09732031822205, "training_acc": 53.0, "val_loss": 17.338143289089203, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.95297646522522, "training_acc": 53.0, "val_loss": 17.315927147865295, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1260335445404, "training_acc": 53.0, "val_loss": 17.370663583278656, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.4059841632843, "training_acc": 53.0, "val_loss": 17.392055690288544, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.50887274742126, "training_acc": 53.0, "val_loss": 17.319832742214203, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11158490180969, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.34539747238159, "training_acc": 53.0, "val_loss": 17.310218513011932, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13543248176575, "training_acc": 53.0, "val_loss": 17.316672205924988, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08474278450012, "training_acc": 53.0, "val_loss": 17.37096905708313, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.2563226222992, "training_acc": 53.0, "val_loss": 17.391715943813324, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.43314981460571, "training_acc": 53.0, "val_loss": 17.377443611621857, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.33090710639954, "training_acc": 53.0, "val_loss": 17.309319972991943, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.32103705406189, "training_acc": 53.0, "val_loss": 17.318345606327057, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21937823295593, "training_acc": 53.0, "val_loss": 17.30872243642807, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1719479560852, "training_acc": 53.0, "val_loss": 17.327846586704254, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.26307249069214, "training_acc": 53.0, "val_loss": 17.4020916223526, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.3300244808197, "training_acc": 53.0, "val_loss": 17.35568642616272, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23483991622925, "training_acc": 53.0, "val_loss": 17.309440672397614, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11831212043762, "training_acc": 53.0, "val_loss": 17.31255054473877, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20539593696594, "training_acc": 53.0, "val_loss": 17.31466054916382, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18030524253845, "training_acc": 53.0, "val_loss": 17.312099039554596, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.21886444091797, "training_acc": 53.0, "val_loss": 17.309416830539703, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.20525455474854, "training_acc": 53.0, "val_loss": 17.351971566677094, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2016270160675, "training_acc": 53.0, "val_loss": 17.34645366668701, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17865037918091, "training_acc": 53.0, "val_loss": 17.314182221889496, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.09760642051697, "training_acc": 53.0, "val_loss": 17.310070991516113, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.32478785514832, "training_acc": 52.0, "val_loss": 17.314033210277557, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.27007484436035, "training_acc": 53.0, "val_loss": 17.319762706756592, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14424228668213, "training_acc": 53.0, "val_loss": 17.3375204205513, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19088649749756, "training_acc": 53.0, "val_loss": 17.326122522354126, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.158278465271, "training_acc": 53.0, "val_loss": 17.31564700603485, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.10268425941467, "training_acc": 53.0, "val_loss": 17.30940043926239, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15055251121521, "training_acc": 53.0, "val_loss": 17.314371466636658, "val_acc": 52.0}
