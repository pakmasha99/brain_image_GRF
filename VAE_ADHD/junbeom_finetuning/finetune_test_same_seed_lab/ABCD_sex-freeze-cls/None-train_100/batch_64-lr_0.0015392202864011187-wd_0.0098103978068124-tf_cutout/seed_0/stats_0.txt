"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.31852221488953, "training_acc": 50.0, "val_loss": 17.50863343477249, "val_acc": 56.0}
{"epoch": 1, "training_loss": 70.23031187057495, "training_acc": 48.0, "val_loss": 17.43302494287491, "val_acc": 56.0}
{"epoch": 2, "training_loss": 71.8634033203125, "training_acc": 52.0, "val_loss": 17.166903614997864, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.34543347358704, "training_acc": 52.0, "val_loss": 17.647385597229004, "val_acc": 56.0}
{"epoch": 4, "training_loss": 70.45031094551086, "training_acc": 48.0, "val_loss": 18.198148906230927, "val_acc": 56.0}
{"epoch": 5, "training_loss": 71.34741687774658, "training_acc": 48.0, "val_loss": 17.528076469898224, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.50442814826965, "training_acc": 50.0, "val_loss": 17.162345349788666, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.34218525886536, "training_acc": 52.0, "val_loss": 17.171671986579895, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.38849687576294, "training_acc": 52.0, "val_loss": 17.153462767601013, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.51876020431519, "training_acc": 52.0, "val_loss": 17.32025146484375, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.4737389087677, "training_acc": 50.0, "val_loss": 17.704756557941437, "val_acc": 56.0}
{"epoch": 11, "training_loss": 70.08078098297119, "training_acc": 48.0, "val_loss": 17.56654530763626, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.77742314338684, "training_acc": 48.0, "val_loss": 17.24858582019806, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.16200590133667, "training_acc": 52.0, "val_loss": 17.1548992395401, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.3989052772522, "training_acc": 52.0, "val_loss": 17.147837579250336, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.6231415271759, "training_acc": 52.0, "val_loss": 17.158836126327515, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.33764004707336, "training_acc": 52.0, "val_loss": 17.209558188915253, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.26161932945251, "training_acc": 52.0, "val_loss": 17.330770194530487, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.34238791465759, "training_acc": 47.0, "val_loss": 17.34260469675064, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.35075330734253, "training_acc": 49.0, "val_loss": 17.242945730686188, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.18389868736267, "training_acc": 52.0, "val_loss": 17.190618813037872, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.25014519691467, "training_acc": 52.0, "val_loss": 17.16500073671341, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.61030530929565, "training_acc": 52.0, "val_loss": 17.161205410957336, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25353384017944, "training_acc": 52.0, "val_loss": 17.29576885700226, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.23857426643372, "training_acc": 54.0, "val_loss": 17.509517073631287, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.74849033355713, "training_acc": 48.0, "val_loss": 17.467457056045532, "val_acc": 56.0}
{"epoch": 26, "training_loss": 70.48168897628784, "training_acc": 38.0, "val_loss": 17.21232235431671, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.2362208366394, "training_acc": 52.0, "val_loss": 17.22825914621353, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.35476613044739, "training_acc": 52.0, "val_loss": 17.259471118450165, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.23743748664856, "training_acc": 52.0, "val_loss": 17.201678454875946, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.8408899307251, "training_acc": 52.0, "val_loss": 17.171595990657806, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.88543772697449, "training_acc": 52.0, "val_loss": 17.300225794315338, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.28081965446472, "training_acc": 52.0, "val_loss": 17.252260446548462, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25041007995605, "training_acc": 52.0, "val_loss": 17.217563092708588, "val_acc": 56.0}
