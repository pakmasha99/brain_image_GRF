"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.00924754142761, "training_acc": 53.0, "val_loss": 17.598077654838562, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.86401152610779, "training_acc": 53.0, "val_loss": 17.550170421600342, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.2334930896759, "training_acc": 47.0, "val_loss": 17.971542477607727, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.75796484947205, "training_acc": 47.0, "val_loss": 17.394927144050598, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27179479598999, "training_acc": 51.0, "val_loss": 17.48157888650894, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.371013879776, "training_acc": 53.0, "val_loss": 17.880848050117493, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.85767459869385, "training_acc": 53.0, "val_loss": 17.554762959480286, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.6305136680603, "training_acc": 53.0, "val_loss": 17.30932593345642, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10949373245239, "training_acc": 53.0, "val_loss": 17.439299821853638, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.90645241737366, "training_acc": 47.0, "val_loss": 17.470641434192657, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.05388379096985, "training_acc": 47.0, "val_loss": 17.335990071296692, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.9119827747345, "training_acc": 55.0, "val_loss": 17.422209680080414, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.80995202064514, "training_acc": 53.0, "val_loss": 17.748409509658813, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.8889012336731, "training_acc": 53.0, "val_loss": 17.596042156219482, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.5070424079895, "training_acc": 53.0, "val_loss": 17.309463024139404, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.8859543800354, "training_acc": 45.0, "val_loss": 17.513200640678406, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.38693594932556, "training_acc": 47.0, "val_loss": 17.482341825962067, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.8712785243988, "training_acc": 47.0, "val_loss": 17.310908436775208, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.95811939239502, "training_acc": 53.0, "val_loss": 17.42519587278366, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.82767605781555, "training_acc": 53.0, "val_loss": 17.60021597146988, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.14298629760742, "training_acc": 53.0, "val_loss": 17.436857521533966, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.45885825157166, "training_acc": 53.0, "val_loss": 17.322589457035065, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.39288353919983, "training_acc": 51.0, "val_loss": 17.44019091129303, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.86232805252075, "training_acc": 47.0, "val_loss": 17.39918440580368, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.54169845581055, "training_acc": 47.0, "val_loss": 17.315588891506195, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.04395031929016, "training_acc": 53.0, "val_loss": 17.36282855272293, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18029522895813, "training_acc": 53.0, "val_loss": 17.505376040935516, "val_acc": 52.0}
