"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.41702604293823, "training_acc": 43.0, "val_loss": 17.517457902431488, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.15433049201965, "training_acc": 53.0, "val_loss": 17.412732541561127, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.7736394405365, "training_acc": 47.0, "val_loss": 17.37465411424637, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.42041492462158, "training_acc": 49.0, "val_loss": 17.33602285385132, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4382815361023, "training_acc": 53.0, "val_loss": 17.428721487522125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.13513684272766, "training_acc": 53.0, "val_loss": 17.625591158866882, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.94759702682495, "training_acc": 53.0, "val_loss": 17.382675409317017, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.07498455047607, "training_acc": 53.0, "val_loss": 17.374545335769653, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.03408527374268, "training_acc": 47.0, "val_loss": 17.541199922561646, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.25591111183167, "training_acc": 47.0, "val_loss": 17.364464700222015, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.294273853302, "training_acc": 51.0, "val_loss": 17.33498126268387, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15326714515686, "training_acc": 53.0, "val_loss": 17.502771317958832, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.67065238952637, "training_acc": 53.0, "val_loss": 17.519794404506683, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.68354511260986, "training_acc": 53.0, "val_loss": 17.40535944700241, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19695329666138, "training_acc": 53.0, "val_loss": 17.313793301582336, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.05013799667358, "training_acc": 41.0, "val_loss": 17.377746105194092, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.4511923789978, "training_acc": 47.0, "val_loss": 17.31504201889038, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.03990483283997, "training_acc": 53.0, "val_loss": 17.373694479465485, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.45050811767578, "training_acc": 53.0, "val_loss": 17.492733895778656, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.68756699562073, "training_acc": 53.0, "val_loss": 17.393366992473602, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05435633659363, "training_acc": 53.0, "val_loss": 17.31981188058853, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.24859690666199, "training_acc": 53.0, "val_loss": 17.539893090724945, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.3671805858612, "training_acc": 47.0, "val_loss": 17.525845766067505, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.0711784362793, "training_acc": 47.0, "val_loss": 17.320868372917175, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19903564453125, "training_acc": 53.0, "val_loss": 17.421939969062805, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.43389987945557, "training_acc": 53.0, "val_loss": 17.55060851573944, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.83253121376038, "training_acc": 53.0, "val_loss": 17.44244694709778, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.4319679737091, "training_acc": 53.0, "val_loss": 17.32737272977829, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.3213529586792, "training_acc": 53.0, "val_loss": 17.319804430007935, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.39844870567322, "training_acc": 53.0, "val_loss": 17.317937314510345, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20395588874817, "training_acc": 53.0, "val_loss": 17.324864864349365, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.43898320198059, "training_acc": 45.0, "val_loss": 17.319825291633606, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.67763090133667, "training_acc": 53.0, "val_loss": 17.33730435371399, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1463315486908, "training_acc": 53.0, "val_loss": 17.33200252056122, "val_acc": 52.0}
