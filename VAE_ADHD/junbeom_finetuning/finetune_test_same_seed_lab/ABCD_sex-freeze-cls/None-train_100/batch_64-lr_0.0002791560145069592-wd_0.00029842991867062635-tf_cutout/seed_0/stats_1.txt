"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38745427131653, "training_acc": 53.0, "val_loss": 17.347590625286102, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1464684009552, "training_acc": 53.0, "val_loss": 17.315082252025604, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.42908835411072, "training_acc": 45.0, "val_loss": 17.344562709331512, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32908630371094, "training_acc": 48.0, "val_loss": 17.320291697978973, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16694593429565, "training_acc": 53.0, "val_loss": 17.31485277414322, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2244131565094, "training_acc": 53.0, "val_loss": 17.3353910446167, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22771859169006, "training_acc": 53.0, "val_loss": 17.33778715133667, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09868621826172, "training_acc": 53.0, "val_loss": 17.351123690605164, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22033452987671, "training_acc": 53.0, "val_loss": 17.355868220329285, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20265316963196, "training_acc": 53.0, "val_loss": 17.36665368080139, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23469185829163, "training_acc": 53.0, "val_loss": 17.37208515405655, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.33056163787842, "training_acc": 53.0, "val_loss": 17.369456589221954, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25440764427185, "training_acc": 53.0, "val_loss": 17.34302043914795, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19108486175537, "training_acc": 53.0, "val_loss": 17.323870956897736, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23177456855774, "training_acc": 53.0, "val_loss": 17.31315553188324, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24989748001099, "training_acc": 53.0, "val_loss": 17.31589436531067, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14193725585938, "training_acc": 53.0, "val_loss": 17.317111790180206, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18678784370422, "training_acc": 53.0, "val_loss": 17.315708100795746, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29734444618225, "training_acc": 53.0, "val_loss": 17.31407344341278, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.208411693573, "training_acc": 53.0, "val_loss": 17.316821217536926, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21913266181946, "training_acc": 53.0, "val_loss": 17.324788868427277, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13630723953247, "training_acc": 53.0, "val_loss": 17.3248291015625, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11879014968872, "training_acc": 53.0, "val_loss": 17.321404814720154, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12749791145325, "training_acc": 53.0, "val_loss": 17.320720851421356, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12546110153198, "training_acc": 53.0, "val_loss": 17.318160831928253, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09901881217957, "training_acc": 53.0, "val_loss": 17.31705814599991, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.20698046684265, "training_acc": 53.0, "val_loss": 17.316968739032745, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11974287033081, "training_acc": 53.0, "val_loss": 17.32027381658554, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15077662467957, "training_acc": 53.0, "val_loss": 17.32134521007538, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19798421859741, "training_acc": 53.0, "val_loss": 17.31933206319809, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.11348795890808, "training_acc": 53.0, "val_loss": 17.32408106327057, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1038327217102, "training_acc": 53.0, "val_loss": 17.3288494348526, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17384457588196, "training_acc": 53.0, "val_loss": 17.334921658039093, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2052071094513, "training_acc": 53.0, "val_loss": 17.33362525701523, "val_acc": 52.0}
