"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2393445968628, "training_acc": 52.0, "val_loss": 17.240378260612488, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23535561561584, "training_acc": 52.0, "val_loss": 17.221972346305847, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25381398200989, "training_acc": 52.0, "val_loss": 17.220191657543182, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26379704475403, "training_acc": 52.0, "val_loss": 17.229610681533813, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2402548789978, "training_acc": 52.0, "val_loss": 17.244869470596313, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22568988800049, "training_acc": 52.0, "val_loss": 17.25040376186371, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25926518440247, "training_acc": 52.0, "val_loss": 17.26197749376297, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2579288482666, "training_acc": 52.0, "val_loss": 17.267131805419922, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26986479759216, "training_acc": 52.0, "val_loss": 17.261874675750732, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25613021850586, "training_acc": 52.0, "val_loss": 17.264999449253082, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23312163352966, "training_acc": 52.0, "val_loss": 17.266327142715454, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26359534263611, "training_acc": 52.0, "val_loss": 17.263305187225342, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23359417915344, "training_acc": 52.0, "val_loss": 17.25945472717285, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23946261405945, "training_acc": 52.0, "val_loss": 17.25829243659973, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24807000160217, "training_acc": 52.0, "val_loss": 17.251983284950256, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25164103507996, "training_acc": 52.0, "val_loss": 17.242850363254547, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25159692764282, "training_acc": 52.0, "val_loss": 17.229770123958588, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23336052894592, "training_acc": 52.0, "val_loss": 17.221061885356903, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24116539955139, "training_acc": 52.0, "val_loss": 17.214278876781464, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25785732269287, "training_acc": 52.0, "val_loss": 17.209428548812866, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20680165290833, "training_acc": 52.0, "val_loss": 17.20856875181198, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22758603096008, "training_acc": 52.0, "val_loss": 17.20735877752304, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28914213180542, "training_acc": 52.0, "val_loss": 17.203488945961, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.262051820755, "training_acc": 52.0, "val_loss": 17.206725478172302, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25971913337708, "training_acc": 52.0, "val_loss": 17.213836312294006, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24946546554565, "training_acc": 52.0, "val_loss": 17.224477231502533, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27833247184753, "training_acc": 52.0, "val_loss": 17.229175567626953, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22723817825317, "training_acc": 52.0, "val_loss": 17.24356859922409, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24670886993408, "training_acc": 52.0, "val_loss": 17.256779968738556, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26096296310425, "training_acc": 52.0, "val_loss": 17.2616645693779, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27350664138794, "training_acc": 52.0, "val_loss": 17.260053753852844, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28035092353821, "training_acc": 52.0, "val_loss": 17.2663614153862, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24923157691956, "training_acc": 52.0, "val_loss": 17.261256277561188, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25707268714905, "training_acc": 52.0, "val_loss": 17.256610095500946, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25960755348206, "training_acc": 52.0, "val_loss": 17.248885333538055, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24032306671143, "training_acc": 52.0, "val_loss": 17.24448800086975, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23806715011597, "training_acc": 52.0, "val_loss": 17.239713668823242, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.2376720905304, "training_acc": 52.0, "val_loss": 17.233985662460327, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22959494590759, "training_acc": 52.0, "val_loss": 17.22368448972702, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2500684261322, "training_acc": 52.0, "val_loss": 17.21039116382599, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23071122169495, "training_acc": 52.0, "val_loss": 17.204637825489044, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25568866729736, "training_acc": 52.0, "val_loss": 17.200976610183716, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26876592636108, "training_acc": 52.0, "val_loss": 17.198878526687622, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24016833305359, "training_acc": 52.0, "val_loss": 17.201247811317444, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25349926948547, "training_acc": 52.0, "val_loss": 17.21034198999405, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24172520637512, "training_acc": 52.0, "val_loss": 17.217427492141724, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25506448745728, "training_acc": 52.0, "val_loss": 17.226439714431763, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23833870887756, "training_acc": 52.0, "val_loss": 17.235594987869263, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22497749328613, "training_acc": 52.0, "val_loss": 17.239442467689514, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23158955574036, "training_acc": 52.0, "val_loss": 17.242832481861115, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25295615196228, "training_acc": 52.0, "val_loss": 17.248977720737457, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25088310241699, "training_acc": 52.0, "val_loss": 17.255710065364838, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25649642944336, "training_acc": 52.0, "val_loss": 17.260806262493134, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26570272445679, "training_acc": 52.0, "val_loss": 17.266075313091278, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22232866287231, "training_acc": 52.0, "val_loss": 17.2696515917778, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25691628456116, "training_acc": 52.0, "val_loss": 17.26745367050171, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.2477695941925, "training_acc": 52.0, "val_loss": 17.268000543117523, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24713468551636, "training_acc": 52.0, "val_loss": 17.26934164762497, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23807263374329, "training_acc": 52.0, "val_loss": 17.265555262565613, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26166343688965, "training_acc": 52.0, "val_loss": 17.261886596679688, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28111600875854, "training_acc": 52.0, "val_loss": 17.252840101718903, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24060845375061, "training_acc": 52.0, "val_loss": 17.248903214931488, "val_acc": 56.0}
