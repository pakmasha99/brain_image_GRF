"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34427881240845, "training_acc": 53.0, "val_loss": 17.310166358947754, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1794593334198, "training_acc": 53.0, "val_loss": 17.31029897928238, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1539158821106, "training_acc": 53.0, "val_loss": 17.310699820518494, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18548274040222, "training_acc": 53.0, "val_loss": 17.310240864753723, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15727996826172, "training_acc": 53.0, "val_loss": 17.309516668319702, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1868953704834, "training_acc": 53.0, "val_loss": 17.309212684631348, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14555764198303, "training_acc": 53.0, "val_loss": 17.309485375881195, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14472842216492, "training_acc": 53.0, "val_loss": 17.31019914150238, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12899136543274, "training_acc": 53.0, "val_loss": 17.311327159404755, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13506627082825, "training_acc": 53.0, "val_loss": 17.312397062778473, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1489188671112, "training_acc": 53.0, "val_loss": 17.312802374362946, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10946774482727, "training_acc": 53.0, "val_loss": 17.31487065553665, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13158798217773, "training_acc": 53.0, "val_loss": 17.318175733089447, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1722195148468, "training_acc": 53.0, "val_loss": 17.32073575258255, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14554333686829, "training_acc": 53.0, "val_loss": 17.32008308172226, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13229036331177, "training_acc": 53.0, "val_loss": 17.318302392959595, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12965750694275, "training_acc": 53.0, "val_loss": 17.317861318588257, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11753511428833, "training_acc": 53.0, "val_loss": 17.31809377670288, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1132140159607, "training_acc": 53.0, "val_loss": 17.317990958690643, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14386773109436, "training_acc": 53.0, "val_loss": 17.318572103977203, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1469955444336, "training_acc": 53.0, "val_loss": 17.31816828250885, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12114381790161, "training_acc": 53.0, "val_loss": 17.315731942653656, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14274644851685, "training_acc": 53.0, "val_loss": 17.31422394514084, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11607098579407, "training_acc": 53.0, "val_loss": 17.31315702199936, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10574173927307, "training_acc": 53.0, "val_loss": 17.311912775039673, "val_acc": 52.0}
