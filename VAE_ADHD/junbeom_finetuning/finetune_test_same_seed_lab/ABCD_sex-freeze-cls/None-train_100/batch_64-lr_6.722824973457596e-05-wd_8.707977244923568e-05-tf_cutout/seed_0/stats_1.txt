"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.40113735198975, "training_acc": 47.0, "val_loss": 17.47879385948181, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.15333890914917, "training_acc": 47.0, "val_loss": 17.417719960212708, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.77766680717468, "training_acc": 47.0, "val_loss": 17.37755686044693, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.54354882240295, "training_acc": 47.0, "val_loss": 17.34861582517624, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.50634384155273, "training_acc": 47.0, "val_loss": 17.32625961303711, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.29172205924988, "training_acc": 55.0, "val_loss": 17.313745617866516, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.18861699104309, "training_acc": 53.0, "val_loss": 17.30624884366989, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19163608551025, "training_acc": 53.0, "val_loss": 17.302806675434113, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1375617980957, "training_acc": 53.0, "val_loss": 17.303699254989624, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17327928543091, "training_acc": 53.0, "val_loss": 17.30831265449524, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16118097305298, "training_acc": 53.0, "val_loss": 17.31482595205307, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13790082931519, "training_acc": 53.0, "val_loss": 17.321498692035675, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16758465766907, "training_acc": 53.0, "val_loss": 17.327751219272614, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15116930007935, "training_acc": 53.0, "val_loss": 17.33202636241913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17032194137573, "training_acc": 53.0, "val_loss": 17.335237562656403, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2107081413269, "training_acc": 53.0, "val_loss": 17.33916997909546, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20743560791016, "training_acc": 53.0, "val_loss": 17.340214550495148, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2074978351593, "training_acc": 53.0, "val_loss": 17.341381311416626, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2048602104187, "training_acc": 53.0, "val_loss": 17.339052259922028, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21199774742126, "training_acc": 53.0, "val_loss": 17.33185350894928, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18476057052612, "training_acc": 53.0, "val_loss": 17.325784265995026, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22488737106323, "training_acc": 53.0, "val_loss": 17.319810390472412, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16645741462708, "training_acc": 53.0, "val_loss": 17.317724227905273, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.189204454422, "training_acc": 53.0, "val_loss": 17.315536737442017, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15153956413269, "training_acc": 53.0, "val_loss": 17.313766479492188, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15550351142883, "training_acc": 53.0, "val_loss": 17.313338816165924, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13272166252136, "training_acc": 53.0, "val_loss": 17.3115536570549, "val_acc": 52.0}
