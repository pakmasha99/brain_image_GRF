"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15166902542114, "training_acc": 47.0, "val_loss": 17.431055009365082, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.8297188282013, "training_acc": 47.0, "val_loss": 17.394135892391205, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.65255427360535, "training_acc": 47.0, "val_loss": 17.35830307006836, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.50029301643372, "training_acc": 47.0, "val_loss": 17.331023514270782, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.41637110710144, "training_acc": 44.0, "val_loss": 17.314988374710083, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24891352653503, "training_acc": 53.0, "val_loss": 17.30681210756302, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1888952255249, "training_acc": 53.0, "val_loss": 17.30307936668396, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12660956382751, "training_acc": 53.0, "val_loss": 17.30325222015381, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11270642280579, "training_acc": 53.0, "val_loss": 17.306266725063324, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1238272190094, "training_acc": 53.0, "val_loss": 17.312459647655487, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14216351509094, "training_acc": 53.0, "val_loss": 17.319414019584656, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15730404853821, "training_acc": 53.0, "val_loss": 17.32403188943863, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16453576087952, "training_acc": 53.0, "val_loss": 17.325423657894135, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18554782867432, "training_acc": 53.0, "val_loss": 17.325156927108765, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16512322425842, "training_acc": 53.0, "val_loss": 17.325221002101898, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15252661705017, "training_acc": 53.0, "val_loss": 17.322535812854767, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19951248168945, "training_acc": 53.0, "val_loss": 17.319300770759583, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1439642906189, "training_acc": 53.0, "val_loss": 17.319242656230927, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14181995391846, "training_acc": 53.0, "val_loss": 17.31676608324051, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14455199241638, "training_acc": 53.0, "val_loss": 17.314228415489197, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11245036125183, "training_acc": 53.0, "val_loss": 17.313790321350098, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12644243240356, "training_acc": 53.0, "val_loss": 17.313051223754883, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13881421089172, "training_acc": 53.0, "val_loss": 17.31218248605728, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13047862052917, "training_acc": 53.0, "val_loss": 17.310355603694916, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13179731369019, "training_acc": 53.0, "val_loss": 17.30913072824478, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13109087944031, "training_acc": 53.0, "val_loss": 17.309218645095825, "val_acc": 52.0}
