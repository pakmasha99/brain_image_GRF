"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 82.37390756607056, "training_acc": 50.0, "val_loss": 18.367354571819305, "val_acc": 56.0}
{"epoch": 1, "training_loss": 74.96401596069336, "training_acc": 48.0, "val_loss": 20.712852478027344, "val_acc": 56.0}
{"epoch": 2, "training_loss": 86.74233937263489, "training_acc": 52.0, "val_loss": 17.65056550502777, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.71922945976257, "training_acc": 53.0, "val_loss": 19.45098042488098, "val_acc": 44.0}
{"epoch": 4, "training_loss": 77.56926393508911, "training_acc": 48.0, "val_loss": 20.863479375839233, "val_acc": 44.0}
{"epoch": 5, "training_loss": 78.57066702842712, "training_acc": 48.0, "val_loss": 17.498880624771118, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.62160873413086, "training_acc": 50.0, "val_loss": 17.584654688835144, "val_acc": 56.0}
{"epoch": 7, "training_loss": 73.23376107215881, "training_acc": 52.0, "val_loss": 17.711177468299866, "val_acc": 56.0}
{"epoch": 8, "training_loss": 72.40297365188599, "training_acc": 52.0, "val_loss": 17.16209053993225, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.34523868560791, "training_acc": 52.0, "val_loss": 18.55841428041458, "val_acc": 56.0}
{"epoch": 10, "training_loss": 72.98556804656982, "training_acc": 48.0, "val_loss": 18.591482937335968, "val_acc": 56.0}
{"epoch": 11, "training_loss": 71.91959524154663, "training_acc": 48.0, "val_loss": 17.238515615463257, "val_acc": 56.0}
{"epoch": 12, "training_loss": 70.03097367286682, "training_acc": 52.0, "val_loss": 17.31273978948593, "val_acc": 56.0}
{"epoch": 13, "training_loss": 71.10176181793213, "training_acc": 52.0, "val_loss": 17.192408442497253, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.15266847610474, "training_acc": 52.0, "val_loss": 17.296895384788513, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.88073062896729, "training_acc": 46.0, "val_loss": 17.627371847629547, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.82818698883057, "training_acc": 48.0, "val_loss": 17.30046421289444, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23833084106445, "training_acc": 52.0, "val_loss": 17.1526238322258, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.46775197982788, "training_acc": 52.0, "val_loss": 17.149028182029724, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.44440817832947, "training_acc": 52.0, "val_loss": 17.22472906112671, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.40757870674133, "training_acc": 48.0, "val_loss": 17.42653399705887, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.52693367004395, "training_acc": 48.0, "val_loss": 17.27554351091385, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.8539445400238, "training_acc": 52.0, "val_loss": 17.149199545383453, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.51875686645508, "training_acc": 52.0, "val_loss": 17.208224534988403, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.13005089759827, "training_acc": 52.0, "val_loss": 17.512057721614838, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.87815475463867, "training_acc": 48.0, "val_loss": 17.511966824531555, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.02933979034424, "training_acc": 38.0, "val_loss": 17.183028161525726, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23939228057861, "training_acc": 52.0, "val_loss": 17.26582944393158, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.52572178840637, "training_acc": 46.0, "val_loss": 17.329223453998566, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.23656296730042, "training_acc": 47.0, "val_loss": 17.1733096241951, "val_acc": 56.0}
{"epoch": 30, "training_loss": 70.41074395179749, "training_acc": 52.0, "val_loss": 17.15341955423355, "val_acc": 56.0}
{"epoch": 31, "training_loss": 70.55244994163513, "training_acc": 42.0, "val_loss": 17.43807941675186, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.46312308311462, "training_acc": 46.0, "val_loss": 17.259210348129272, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.20604300498962, "training_acc": 52.0, "val_loss": 17.16868132352829, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.55384016036987, "training_acc": 52.0, "val_loss": 17.160989344120026, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.34067559242249, "training_acc": 52.0, "val_loss": 17.334778606891632, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.48254823684692, "training_acc": 53.0, "val_loss": 17.37005263566971, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.45816278457642, "training_acc": 48.0, "val_loss": 17.16390699148178, "val_acc": 56.0}
