"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 86.9865951538086, "training_acc": 45.0, "val_loss": 18.19760799407959, "val_acc": 52.0}
{"epoch": 1, "training_loss": 76.40978646278381, "training_acc": 45.0, "val_loss": 21.73905521631241, "val_acc": 52.0}
{"epoch": 2, "training_loss": 86.66180896759033, "training_acc": 53.0, "val_loss": 19.47152614593506, "val_acc": 52.0}
{"epoch": 3, "training_loss": 74.86541795730591, "training_acc": 53.0, "val_loss": 17.752163112163544, "val_acc": 52.0}
{"epoch": 4, "training_loss": 73.93231511116028, "training_acc": 47.0, "val_loss": 19.66002583503723, "val_acc": 48.0}
{"epoch": 5, "training_loss": 79.21207118034363, "training_acc": 47.0, "val_loss": 17.815139889717102, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.79376101493835, "training_acc": 47.0, "val_loss": 17.462535202503204, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.66743779182434, "training_acc": 53.0, "val_loss": 18.298926949501038, "val_acc": 52.0}
{"epoch": 8, "training_loss": 72.61712336540222, "training_acc": 53.0, "val_loss": 17.87247359752655, "val_acc": 52.0}
{"epoch": 9, "training_loss": 71.88096570968628, "training_acc": 53.0, "val_loss": 17.314986884593964, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.99401926994324, "training_acc": 45.0, "val_loss": 17.46037006378174, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.97225666046143, "training_acc": 47.0, "val_loss": 17.316371202468872, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.43020486831665, "training_acc": 53.0, "val_loss": 17.349277436733246, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.36001133918762, "training_acc": 53.0, "val_loss": 17.351698875427246, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.21699619293213, "training_acc": 53.0, "val_loss": 17.310138046741486, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1197521686554, "training_acc": 53.0, "val_loss": 17.44076907634735, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.02235913276672, "training_acc": 47.0, "val_loss": 17.563971877098083, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.50780916213989, "training_acc": 47.0, "val_loss": 17.314869165420532, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.28767037391663, "training_acc": 53.0, "val_loss": 17.72788017988205, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.44587683677673, "training_acc": 53.0, "val_loss": 17.588303983211517, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.76588106155396, "training_acc": 53.0, "val_loss": 17.318789660930634, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.73560404777527, "training_acc": 47.0, "val_loss": 17.493969202041626, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.12668538093567, "training_acc": 47.0, "val_loss": 17.362843453884125, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.38493371009827, "training_acc": 49.0, "val_loss": 17.398959398269653, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.36677575111389, "training_acc": 53.0, "val_loss": 17.52273291349411, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.3881950378418, "training_acc": 53.0, "val_loss": 17.312638461589813, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.19649505615234, "training_acc": 45.0, "val_loss": 17.505168914794922, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.08649039268494, "training_acc": 47.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18053483963013, "training_acc": 53.0, "val_loss": 17.437651753425598, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.14584565162659, "training_acc": 53.0, "val_loss": 17.41218864917755, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.24738216400146, "training_acc": 53.0, "val_loss": 17.361310124397278, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.17037534713745, "training_acc": 47.0, "val_loss": 17.41059571504593, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.3613212108612, "training_acc": 53.0, "val_loss": 17.36999899148941, "val_acc": 52.0}
{"epoch": 33, "training_loss": 71.11045384407043, "training_acc": 53.0, "val_loss": 17.647579312324524, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.00786972045898, "training_acc": 53.0, "val_loss": 17.30930656194687, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1734778881073, "training_acc": 53.0, "val_loss": 17.443087697029114, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.20136189460754, "training_acc": 47.0, "val_loss": 17.33715534210205, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.32782745361328, "training_acc": 49.0, "val_loss": 17.515738308429718, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.88211679458618, "training_acc": 53.0, "val_loss": 17.559409141540527, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.65726017951965, "training_acc": 53.0, "val_loss": 17.308935523033142, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.42341327667236, "training_acc": 49.0, "val_loss": 17.405390739440918, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.68528151512146, "training_acc": 47.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.42567801475525, "training_acc": 53.0, "val_loss": 17.498835921287537, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.73691773414612, "training_acc": 53.0, "val_loss": 17.38569289445877, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.35313725471497, "training_acc": 53.0, "val_loss": 17.338992655277252, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.45859932899475, "training_acc": 43.0, "val_loss": 17.34926551580429, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.70414423942566, "training_acc": 47.0, "val_loss": 17.311154305934906, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.21192836761475, "training_acc": 53.0, "val_loss": 17.488715052604675, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.64792966842651, "training_acc": 53.0, "val_loss": 17.429614067077637, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.44149518013, "training_acc": 53.0, "val_loss": 17.313815653324127, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.49607801437378, "training_acc": 47.0, "val_loss": 17.328456044197083, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.26800560951233, "training_acc": 55.0, "val_loss": 17.377083003520966, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.5189859867096, "training_acc": 53.0, "val_loss": 17.67474263906479, "val_acc": 52.0}
{"epoch": 53, "training_loss": 70.36375904083252, "training_acc": 53.0, "val_loss": 17.326579988002777, "val_acc": 52.0}
{"epoch": 54, "training_loss": 68.52182459831238, "training_acc": 59.0, "val_loss": 17.74814873933792, "val_acc": 52.0}
{"epoch": 55, "training_loss": 71.61299443244934, "training_acc": 47.0, "val_loss": 17.68658608198166, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.06295156478882, "training_acc": 47.0, "val_loss": 17.436353862285614, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.87907767295837, "training_acc": 53.0, "val_loss": 18.074890971183777, "val_acc": 52.0}
{"epoch": 58, "training_loss": 71.47316002845764, "training_acc": 53.0, "val_loss": 17.323359847068787, "val_acc": 52.0}
