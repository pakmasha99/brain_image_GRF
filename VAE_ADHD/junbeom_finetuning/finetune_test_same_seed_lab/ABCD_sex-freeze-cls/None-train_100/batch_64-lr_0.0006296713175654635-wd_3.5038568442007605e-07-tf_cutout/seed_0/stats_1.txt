"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.41963195800781, "training_acc": 53.0, "val_loss": 17.358653247356415, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55304789543152, "training_acc": 53.0, "val_loss": 17.308393120765686, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.21244478225708, "training_acc": 53.0, "val_loss": 17.309796810150146, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15305471420288, "training_acc": 53.0, "val_loss": 17.307963967323303, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22197413444519, "training_acc": 53.0, "val_loss": 17.32058674097061, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.35318875312805, "training_acc": 53.0, "val_loss": 17.316757142543793, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.10963010787964, "training_acc": 53.0, "val_loss": 17.339299619197845, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.235924243927, "training_acc": 53.0, "val_loss": 17.35973358154297, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21234202384949, "training_acc": 53.0, "val_loss": 17.39586740732193, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.32280492782593, "training_acc": 53.0, "val_loss": 17.41013079881668, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.4382438659668, "training_acc": 53.0, "val_loss": 17.388568818569183, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.26374864578247, "training_acc": 53.0, "val_loss": 17.323003709316254, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.06410002708435, "training_acc": 53.0, "val_loss": 17.3075333237648, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.33695888519287, "training_acc": 53.0, "val_loss": 17.337989807128906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.4342451095581, "training_acc": 47.0, "val_loss": 17.340900003910065, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.36350703239441, "training_acc": 49.0, "val_loss": 17.3117995262146, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16846656799316, "training_acc": 53.0, "val_loss": 17.313025891780853, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17250370979309, "training_acc": 53.0, "val_loss": 17.338337004184723, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.44080781936646, "training_acc": 53.0, "val_loss": 17.41786301136017, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.5575225353241, "training_acc": 53.0, "val_loss": 17.415547370910645, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.30878520011902, "training_acc": 53.0, "val_loss": 17.340199649333954, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.27212119102478, "training_acc": 53.0, "val_loss": 17.307329177856445, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14247393608093, "training_acc": 53.0, "val_loss": 17.314572632312775, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26810097694397, "training_acc": 54.0, "val_loss": 17.323443293571472, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.25413942337036, "training_acc": 54.0, "val_loss": 17.313681542873383, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17389345169067, "training_acc": 53.0, "val_loss": 17.307907342910767, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19784832000732, "training_acc": 53.0, "val_loss": 17.33713150024414, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2279326915741, "training_acc": 53.0, "val_loss": 17.36576408147812, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.36275148391724, "training_acc": 53.0, "val_loss": 17.35522747039795, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.22126817703247, "training_acc": 53.0, "val_loss": 17.360325157642365, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.25113224983215, "training_acc": 53.0, "val_loss": 17.347022891044617, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20031595230103, "training_acc": 53.0, "val_loss": 17.33337789773941, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14922642707825, "training_acc": 53.0, "val_loss": 17.31405258178711, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12960004806519, "training_acc": 53.0, "val_loss": 17.308509349822998, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14971685409546, "training_acc": 53.0, "val_loss": 17.343269288539886, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.44214749336243, "training_acc": 47.0, "val_loss": 17.367568612098694, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.50904560089111, "training_acc": 47.0, "val_loss": 17.340533435344696, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.33627247810364, "training_acc": 49.0, "val_loss": 17.309291660785675, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13705849647522, "training_acc": 53.0, "val_loss": 17.31971651315689, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.07649278640747, "training_acc": 53.0, "val_loss": 17.36355572938919, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.25831127166748, "training_acc": 53.0, "val_loss": 17.405427992343903, "val_acc": 52.0}
