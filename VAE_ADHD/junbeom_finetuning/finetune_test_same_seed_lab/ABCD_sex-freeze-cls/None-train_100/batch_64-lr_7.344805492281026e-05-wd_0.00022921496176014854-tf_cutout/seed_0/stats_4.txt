"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15653133392334, "training_acc": 47.0, "val_loss": 17.426657676696777, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.80687665939331, "training_acc": 47.0, "val_loss": 17.3878014087677, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.61989998817444, "training_acc": 47.0, "val_loss": 17.35110431909561, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.4656708240509, "training_acc": 47.0, "val_loss": 17.32453852891922, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38378977775574, "training_acc": 40.0, "val_loss": 17.310336232185364, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21871209144592, "training_acc": 53.0, "val_loss": 17.30428636074066, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16676259040833, "training_acc": 53.0, "val_loss": 17.30278581380844, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11399912834167, "training_acc": 53.0, "val_loss": 17.30487048625946, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11004948616028, "training_acc": 53.0, "val_loss": 17.309366166591644, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12519955635071, "training_acc": 53.0, "val_loss": 17.316976189613342, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1487078666687, "training_acc": 53.0, "val_loss": 17.324484884738922, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1658022403717, "training_acc": 53.0, "val_loss": 17.328479886054993, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17347455024719, "training_acc": 53.0, "val_loss": 17.328418791294098, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19441151618958, "training_acc": 53.0, "val_loss": 17.326565086841583, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16552782058716, "training_acc": 53.0, "val_loss": 17.32533872127533, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.152170419693, "training_acc": 53.0, "val_loss": 17.32141226530075, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20448303222656, "training_acc": 53.0, "val_loss": 17.317375540733337, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13958311080933, "training_acc": 53.0, "val_loss": 17.31695532798767, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13774108886719, "training_acc": 53.0, "val_loss": 17.31429100036621, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14356255531311, "training_acc": 53.0, "val_loss": 17.311786115169525, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10949444770813, "training_acc": 53.0, "val_loss": 17.311477661132812, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12377572059631, "training_acc": 53.0, "val_loss": 17.310960590839386, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13744735717773, "training_acc": 53.0, "val_loss": 17.310376465320587, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1287522315979, "training_acc": 53.0, "val_loss": 17.30886548757553, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13067150115967, "training_acc": 53.0, "val_loss": 17.30794906616211, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13140106201172, "training_acc": 53.0, "val_loss": 17.308326065540314, "val_acc": 52.0}
