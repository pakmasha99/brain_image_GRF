"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24068784713745, "training_acc": 52.0, "val_loss": 17.241519689559937, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23705053329468, "training_acc": 52.0, "val_loss": 17.220863699913025, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25574088096619, "training_acc": 52.0, "val_loss": 17.218929529190063, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26372504234314, "training_acc": 52.0, "val_loss": 17.229396104812622, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24054050445557, "training_acc": 52.0, "val_loss": 17.24627912044525, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22651052474976, "training_acc": 52.0, "val_loss": 17.25239008665085, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26051807403564, "training_acc": 52.0, "val_loss": 17.26490706205368, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26030731201172, "training_acc": 52.0, "val_loss": 17.27006435394287, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27477765083313, "training_acc": 52.0, "val_loss": 17.263709008693695, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25735878944397, "training_acc": 52.0, "val_loss": 17.266541719436646, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2340931892395, "training_acc": 52.0, "val_loss": 17.267367243766785, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26447248458862, "training_acc": 52.0, "val_loss": 17.263473570346832, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23444604873657, "training_acc": 52.0, "val_loss": 17.25880354642868, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23900318145752, "training_acc": 52.0, "val_loss": 17.257213592529297, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24717736244202, "training_acc": 52.0, "val_loss": 17.250213027000427, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25045895576477, "training_acc": 52.0, "val_loss": 17.24036931991577, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25140810012817, "training_acc": 52.0, "val_loss": 17.22654104232788, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23349452018738, "training_acc": 52.0, "val_loss": 17.217670381069183, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24213075637817, "training_acc": 52.0, "val_loss": 17.21106618642807, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25945019721985, "training_acc": 52.0, "val_loss": 17.206664383411407, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20913171768188, "training_acc": 52.0, "val_loss": 17.206600308418274, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2302017211914, "training_acc": 52.0, "val_loss": 17.206139862537384, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29029417037964, "training_acc": 52.0, "val_loss": 17.202705144882202, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26194500923157, "training_acc": 52.0, "val_loss": 17.206889390945435, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25857639312744, "training_acc": 52.0, "val_loss": 17.215247452259064, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25006294250488, "training_acc": 52.0, "val_loss": 17.227385938167572, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27929997444153, "training_acc": 52.0, "val_loss": 17.232701182365417, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.2272424697876, "training_acc": 52.0, "val_loss": 17.248588800430298, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25036978721619, "training_acc": 52.0, "val_loss": 17.262867093086243, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26472449302673, "training_acc": 52.0, "val_loss": 17.26745516061783, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.28094959259033, "training_acc": 52.0, "val_loss": 17.264612019062042, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28424501419067, "training_acc": 52.0, "val_loss": 17.27052479982376, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25237441062927, "training_acc": 52.0, "val_loss": 17.2637477517128, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25775647163391, "training_acc": 52.0, "val_loss": 17.257584631443024, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26135325431824, "training_acc": 52.0, "val_loss": 17.24826991558075, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2398190498352, "training_acc": 52.0, "val_loss": 17.24283993244171, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23705506324768, "training_acc": 52.0, "val_loss": 17.237266898155212, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23695755004883, "training_acc": 52.0, "val_loss": 17.23092943429947, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22862648963928, "training_acc": 52.0, "val_loss": 17.219962179660797, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25337600708008, "training_acc": 52.0, "val_loss": 17.206110060214996, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23353219032288, "training_acc": 52.0, "val_loss": 17.200472950935364, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25932765007019, "training_acc": 52.0, "val_loss": 17.197193205356598, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2726571559906, "training_acc": 52.0, "val_loss": 17.195650935173035, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24262285232544, "training_acc": 52.0, "val_loss": 17.198890447616577, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25667262077332, "training_acc": 52.0, "val_loss": 17.20941960811615, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24095511436462, "training_acc": 52.0, "val_loss": 17.217856645584106, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25433087348938, "training_acc": 52.0, "val_loss": 17.228370904922485, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24026536941528, "training_acc": 52.0, "val_loss": 17.23892241716385, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22547817230225, "training_acc": 52.0, "val_loss": 17.2433540225029, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23275113105774, "training_acc": 52.0, "val_loss": 17.24703013896942, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25434494018555, "training_acc": 52.0, "val_loss": 17.25354790687561, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25301122665405, "training_acc": 52.0, "val_loss": 17.26050078868866, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25946044921875, "training_acc": 52.0, "val_loss": 17.265428602695465, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.2686984539032, "training_acc": 52.0, "val_loss": 17.27038472890854, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22519755363464, "training_acc": 52.0, "val_loss": 17.27333813905716, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.2612156867981, "training_acc": 52.0, "val_loss": 17.269882559776306, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25012135505676, "training_acc": 52.0, "val_loss": 17.26951152086258, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24782419204712, "training_acc": 52.0, "val_loss": 17.270095646381378, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23870849609375, "training_acc": 52.0, "val_loss": 17.265206575393677, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.2607889175415, "training_acc": 52.0, "val_loss": 17.260634899139404, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28224325180054, "training_acc": 52.0, "val_loss": 17.25047677755356, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.2393388748169, "training_acc": 52.0, "val_loss": 17.24608540534973, "val_acc": 56.0}
