"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.35659766197205, "training_acc": 53.0, "val_loss": 17.309947311878204, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17687964439392, "training_acc": 53.0, "val_loss": 17.31010377407074, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15202832221985, "training_acc": 53.0, "val_loss": 17.310550808906555, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1839644908905, "training_acc": 53.0, "val_loss": 17.310118675231934, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15558171272278, "training_acc": 53.0, "val_loss": 17.30942875146866, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18602705001831, "training_acc": 53.0, "val_loss": 17.309249937534332, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1435854434967, "training_acc": 53.0, "val_loss": 17.309650778770447, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14297890663147, "training_acc": 53.0, "val_loss": 17.310523986816406, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12787222862244, "training_acc": 53.0, "val_loss": 17.311808466911316, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13429164886475, "training_acc": 53.0, "val_loss": 17.312945425510406, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15165543556213, "training_acc": 53.0, "val_loss": 17.31327772140503, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10955500602722, "training_acc": 53.0, "val_loss": 17.315511405467987, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13227081298828, "training_acc": 53.0, "val_loss": 17.31911450624466, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17558312416077, "training_acc": 53.0, "val_loss": 17.321813106536865, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14651536941528, "training_acc": 53.0, "val_loss": 17.32082962989807, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13521242141724, "training_acc": 53.0, "val_loss": 17.318618297576904, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13079571723938, "training_acc": 53.0, "val_loss": 17.317955195903778, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11757302284241, "training_acc": 53.0, "val_loss": 17.318059504032135, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11376523971558, "training_acc": 53.0, "val_loss": 17.31782704591751, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387822151184, "training_acc": 53.0, "val_loss": 17.31836646795273, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14767861366272, "training_acc": 53.0, "val_loss": 17.317867279052734, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1213047504425, "training_acc": 53.0, "val_loss": 17.315250635147095, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14256358146667, "training_acc": 53.0, "val_loss": 17.313681542873383, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11606097221375, "training_acc": 53.0, "val_loss": 17.312616109848022, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10648345947266, "training_acc": 53.0, "val_loss": 17.31141060590744, "val_acc": 52.0}
