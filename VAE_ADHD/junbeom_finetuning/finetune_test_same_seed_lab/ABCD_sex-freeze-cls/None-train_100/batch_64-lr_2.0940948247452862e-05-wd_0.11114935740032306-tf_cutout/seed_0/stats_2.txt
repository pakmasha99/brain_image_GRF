"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.42325568199158, "training_acc": 47.0, "val_loss": 17.33543574810028, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.35714530944824, "training_acc": 42.0, "val_loss": 17.32673943042755, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.29148817062378, "training_acc": 50.0, "val_loss": 17.32323467731476, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2503821849823, "training_acc": 53.0, "val_loss": 17.320673167705536, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27599453926086, "training_acc": 53.0, "val_loss": 17.318010330200195, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2716133594513, "training_acc": 53.0, "val_loss": 17.315959930419922, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21908950805664, "training_acc": 53.0, "val_loss": 17.314647138118744, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19350028038025, "training_acc": 53.0, "val_loss": 17.313604056835175, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15664410591125, "training_acc": 53.0, "val_loss": 17.31300950050354, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16219639778137, "training_acc": 53.0, "val_loss": 17.312675714492798, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20381379127502, "training_acc": 53.0, "val_loss": 17.312651872634888, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17991232872009, "training_acc": 53.0, "val_loss": 17.31290966272354, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15808892250061, "training_acc": 53.0, "val_loss": 17.31346696615219, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18984174728394, "training_acc": 53.0, "val_loss": 17.31410175561905, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12969827651978, "training_acc": 53.0, "val_loss": 17.314858734607697, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11774921417236, "training_acc": 53.0, "val_loss": 17.31579154729843, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15181541442871, "training_acc": 53.0, "val_loss": 17.316696047782898, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17349576950073, "training_acc": 53.0, "val_loss": 17.31783300638199, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15097498893738, "training_acc": 53.0, "val_loss": 17.31879711151123, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16319251060486, "training_acc": 53.0, "val_loss": 17.31964200735092, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14317798614502, "training_acc": 53.0, "val_loss": 17.32049584388733, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1838731765747, "training_acc": 53.0, "val_loss": 17.321112751960754, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19027614593506, "training_acc": 53.0, "val_loss": 17.321351170539856, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15245771408081, "training_acc": 53.0, "val_loss": 17.321372032165527, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14487385749817, "training_acc": 53.0, "val_loss": 17.321643233299255, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14559626579285, "training_acc": 53.0, "val_loss": 17.321692407131195, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14480519294739, "training_acc": 53.0, "val_loss": 17.321684956550598, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14891529083252, "training_acc": 53.0, "val_loss": 17.321662604808807, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15348696708679, "training_acc": 53.0, "val_loss": 17.3214390873909, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.10909700393677, "training_acc": 53.0, "val_loss": 17.321518063545227, "val_acc": 52.0}
