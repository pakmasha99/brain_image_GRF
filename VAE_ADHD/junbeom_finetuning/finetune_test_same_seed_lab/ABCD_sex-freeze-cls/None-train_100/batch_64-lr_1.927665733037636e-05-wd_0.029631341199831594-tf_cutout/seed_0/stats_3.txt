"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26488518714905, "training_acc": 53.0, "val_loss": 17.31293797492981, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21673679351807, "training_acc": 53.0, "val_loss": 17.313045263290405, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20468521118164, "training_acc": 53.0, "val_loss": 17.31254607439041, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18904042243958, "training_acc": 53.0, "val_loss": 17.311763763427734, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2240219116211, "training_acc": 53.0, "val_loss": 17.3112154006958, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18344140052795, "training_acc": 53.0, "val_loss": 17.310641705989838, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16677713394165, "training_acc": 53.0, "val_loss": 17.310187220573425, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18312454223633, "training_acc": 53.0, "val_loss": 17.30976402759552, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16597032546997, "training_acc": 53.0, "val_loss": 17.30959713459015, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16870760917664, "training_acc": 53.0, "val_loss": 17.309489846229553, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17112946510315, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13290119171143, "training_acc": 53.0, "val_loss": 17.309507727622986, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16391658782959, "training_acc": 53.0, "val_loss": 17.30954647064209, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1492874622345, "training_acc": 53.0, "val_loss": 17.3095703125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16517734527588, "training_acc": 53.0, "val_loss": 17.309585213661194, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18532252311707, "training_acc": 53.0, "val_loss": 17.309576272964478, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1721682548523, "training_acc": 53.0, "val_loss": 17.30959266424179, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16401624679565, "training_acc": 53.0, "val_loss": 17.30963885784149, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12718486785889, "training_acc": 53.0, "val_loss": 17.309722304344177, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1978087425232, "training_acc": 53.0, "val_loss": 17.309783399105072, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16238927841187, "training_acc": 53.0, "val_loss": 17.309865355491638, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15641188621521, "training_acc": 53.0, "val_loss": 17.309971153736115, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14115405082703, "training_acc": 53.0, "val_loss": 17.310066521167755, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12653708457947, "training_acc": 53.0, "val_loss": 17.31012314558029, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16312050819397, "training_acc": 53.0, "val_loss": 17.31037050485611, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16327786445618, "training_acc": 53.0, "val_loss": 17.310771346092224, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1356692314148, "training_acc": 53.0, "val_loss": 17.31114536523819, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1241226196289, "training_acc": 53.0, "val_loss": 17.31124520301819, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15535831451416, "training_acc": 53.0, "val_loss": 17.311236262321472, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16098403930664, "training_acc": 53.0, "val_loss": 17.311404645442963, "val_acc": 52.0}
