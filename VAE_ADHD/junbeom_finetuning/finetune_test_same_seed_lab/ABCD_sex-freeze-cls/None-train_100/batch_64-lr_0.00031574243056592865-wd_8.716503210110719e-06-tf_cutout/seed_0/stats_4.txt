"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.05541563034058, "training_acc": 47.0, "val_loss": 17.366091907024384, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.68872213363647, "training_acc": 45.0, "val_loss": 17.32463389635086, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.25175046920776, "training_acc": 53.0, "val_loss": 17.415767908096313, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.41129159927368, "training_acc": 53.0, "val_loss": 17.438098788261414, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4549126625061, "training_acc": 53.0, "val_loss": 17.40235835313797, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.32800483703613, "training_acc": 53.0, "val_loss": 17.354844510555267, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.40388607978821, "training_acc": 53.0, "val_loss": 17.312757670879364, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12108945846558, "training_acc": 53.0, "val_loss": 17.306478321552277, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.26063656806946, "training_acc": 53.0, "val_loss": 17.308692634105682, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.22805762290955, "training_acc": 53.0, "val_loss": 17.30864644050598, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19083976745605, "training_acc": 53.0, "val_loss": 17.308154702186584, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24314475059509, "training_acc": 53.0, "val_loss": 17.306122183799744, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17489123344421, "training_acc": 53.0, "val_loss": 17.30615645647049, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13119220733643, "training_acc": 53.0, "val_loss": 17.309734225273132, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.08007526397705, "training_acc": 53.0, "val_loss": 17.323078215122223, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14495873451233, "training_acc": 53.0, "val_loss": 17.347007989883423, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.25271320343018, "training_acc": 53.0, "val_loss": 17.370566725730896, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.27716541290283, "training_acc": 53.0, "val_loss": 17.36331582069397, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.25068235397339, "training_acc": 53.0, "val_loss": 17.342734336853027, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24978590011597, "training_acc": 53.0, "val_loss": 17.324474453926086, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14340209960938, "training_acc": 53.0, "val_loss": 17.317214608192444, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13455700874329, "training_acc": 53.0, "val_loss": 17.30998456478119, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14049625396729, "training_acc": 53.0, "val_loss": 17.306913435459137, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12426972389221, "training_acc": 53.0, "val_loss": 17.306193709373474, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.20140314102173, "training_acc": 53.0, "val_loss": 17.306827008724213, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16509366035461, "training_acc": 53.0, "val_loss": 17.30620563030243, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21414184570312, "training_acc": 53.0, "val_loss": 17.310547828674316, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14618587493896, "training_acc": 53.0, "val_loss": 17.313916981220245, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.26995015144348, "training_acc": 53.0, "val_loss": 17.326895892620087, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13867235183716, "training_acc": 53.0, "val_loss": 17.323535680770874, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18139314651489, "training_acc": 53.0, "val_loss": 17.320546507835388, "val_acc": 52.0}
