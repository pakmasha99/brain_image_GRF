"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.47193264961243, "training_acc": 47.0, "val_loss": 17.52472221851349, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.33559155464172, "training_acc": 47.0, "val_loss": 17.48911291360855, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.10678291320801, "training_acc": 47.0, "val_loss": 17.46077537536621, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.9670763015747, "training_acc": 47.0, "val_loss": 17.43578314781189, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.900723695755, "training_acc": 47.0, "val_loss": 17.412154376506805, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.73368167877197, "training_acc": 47.0, "val_loss": 17.392945289611816, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.61985683441162, "training_acc": 47.0, "val_loss": 17.375652492046356, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.58155751228333, "training_acc": 47.0, "val_loss": 17.359313368797302, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.48496651649475, "training_acc": 47.0, "val_loss": 17.345161736011505, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.45577192306519, "training_acc": 47.0, "val_loss": 17.332850396633148, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.38404202461243, "training_acc": 46.0, "val_loss": 17.323121428489685, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29658102989197, "training_acc": 52.0, "val_loss": 17.315706610679626, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.27030682563782, "training_acc": 53.0, "val_loss": 17.310144007205963, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19907069206238, "training_acc": 53.0, "val_loss": 17.30639934539795, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17002367973328, "training_acc": 53.0, "val_loss": 17.30404794216156, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20078229904175, "training_acc": 53.0, "val_loss": 17.302820086479187, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15211009979248, "training_acc": 53.0, "val_loss": 17.302730679512024, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16267132759094, "training_acc": 53.0, "val_loss": 17.303521931171417, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1633722782135, "training_acc": 53.0, "val_loss": 17.304714024066925, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14949917793274, "training_acc": 53.0, "val_loss": 17.305614054203033, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15322256088257, "training_acc": 53.0, "val_loss": 17.30661392211914, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14117813110352, "training_acc": 53.0, "val_loss": 17.307329177856445, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15166592597961, "training_acc": 53.0, "val_loss": 17.30867773294449, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17375421524048, "training_acc": 53.0, "val_loss": 17.309871315956116, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1301052570343, "training_acc": 53.0, "val_loss": 17.31097549200058, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15732860565186, "training_acc": 53.0, "val_loss": 17.312362790107727, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1323881149292, "training_acc": 53.0, "val_loss": 17.312929034233093, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14603161811829, "training_acc": 53.0, "val_loss": 17.313304543495178, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13980078697205, "training_acc": 53.0, "val_loss": 17.312893271446228, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16079878807068, "training_acc": 53.0, "val_loss": 17.313088476657867, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14429140090942, "training_acc": 53.0, "val_loss": 17.31346994638443, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14484000205994, "training_acc": 53.0, "val_loss": 17.31344759464264, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14634323120117, "training_acc": 53.0, "val_loss": 17.313235998153687, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1392912864685, "training_acc": 53.0, "val_loss": 17.31344610452652, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14450192451477, "training_acc": 53.0, "val_loss": 17.313632369041443, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16862916946411, "training_acc": 53.0, "val_loss": 17.313872277736664, "val_acc": 52.0}
