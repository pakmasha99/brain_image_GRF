"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23294591903687, "training_acc": 52.0, "val_loss": 17.232997715473175, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22650098800659, "training_acc": 52.0, "val_loss": 17.22613424062729, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24391388893127, "training_acc": 52.0, "val_loss": 17.225632071495056, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26397395133972, "training_acc": 52.0, "val_loss": 17.229947447776794, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23881649971008, "training_acc": 52.0, "val_loss": 17.236976325511932, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22102427482605, "training_acc": 52.0, "val_loss": 17.239685356616974, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25388050079346, "training_acc": 52.0, "val_loss": 17.245620489120483, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2464370727539, "training_acc": 52.0, "val_loss": 17.249292135238647, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.2454981803894, "training_acc": 52.0, "val_loss": 17.248427867889404, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24905729293823, "training_acc": 52.0, "val_loss": 17.251498997211456, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22540378570557, "training_acc": 52.0, "val_loss": 17.25398749113083, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.25550961494446, "training_acc": 52.0, "val_loss": 17.25461184978485, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.22487044334412, "training_acc": 52.0, "val_loss": 17.25473403930664, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23711085319519, "training_acc": 52.0, "val_loss": 17.255929112434387, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24874997138977, "training_acc": 52.0, "val_loss": 17.254385352134705, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25614738464355, "training_acc": 52.0, "val_loss": 17.25096106529236, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25207161903381, "training_acc": 52.0, "val_loss": 17.244796454906464, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23660397529602, "training_acc": 52.0, "val_loss": 17.24001318216324, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24189805984497, "training_acc": 52.0, "val_loss": 17.235423624515533, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25375533103943, "training_acc": 52.0, "val_loss": 17.231136560440063, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.1999933719635, "training_acc": 52.0, "val_loss": 17.2284796833992, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21728253364563, "training_acc": 52.0, "val_loss": 17.225314676761627, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27674889564514, "training_acc": 52.0, "val_loss": 17.220592498779297, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25571465492249, "training_acc": 52.0, "val_loss": 17.219646275043488, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25868153572083, "training_acc": 52.0, "val_loss": 17.220667004585266, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24161100387573, "training_acc": 52.0, "val_loss": 17.22346842288971, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27478885650635, "training_acc": 52.0, "val_loss": 17.223888635635376, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23037838935852, "training_acc": 52.0, "val_loss": 17.229197919368744, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23209190368652, "training_acc": 52.0, "val_loss": 17.234361171722412, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2500114440918, "training_acc": 52.0, "val_loss": 17.236603796482086, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.25120258331299, "training_acc": 52.0, "val_loss": 17.236672341823578, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.25653624534607, "training_acc": 52.0, "val_loss": 17.240573465824127, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23619842529297, "training_acc": 52.0, "val_loss": 17.24000871181488, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2498927116394, "training_acc": 52.0, "val_loss": 17.239850759506226, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24822402000427, "training_acc": 52.0, "val_loss": 17.238330841064453, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2380518913269, "training_acc": 52.0, "val_loss": 17.238177359104156, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23859858512878, "training_acc": 52.0, "val_loss": 17.23763644695282, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23844313621521, "training_acc": 52.0, "val_loss": 17.236287891864777, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23665976524353, "training_acc": 52.0, "val_loss": 17.232196033000946, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.23438096046448, "training_acc": 52.0, "val_loss": 17.225824296474457, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22633004188538, "training_acc": 52.0, "val_loss": 17.22271293401718, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24782657623291, "training_acc": 52.0, "val_loss": 17.220187187194824, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2528338432312, "training_acc": 52.0, "val_loss": 17.218074202537537, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22474026679993, "training_acc": 52.0, "val_loss": 17.218127846717834, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.24010515213013, "training_acc": 52.0, "val_loss": 17.22153127193451, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.2419867515564, "training_acc": 52.0, "val_loss": 17.223624885082245, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25636219978333, "training_acc": 52.0, "val_loss": 17.22662001848221, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22940063476562, "training_acc": 52.0, "val_loss": 17.22976267337799, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22549748420715, "training_acc": 52.0, "val_loss": 17.230696976184845, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23080587387085, "training_acc": 52.0, "val_loss": 17.231757938861847, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2526285648346, "training_acc": 52.0, "val_loss": 17.234396934509277, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24759840965271, "training_acc": 52.0, "val_loss": 17.23763942718506, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25045108795166, "training_acc": 52.0, "val_loss": 17.240534722805023, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.2573926448822, "training_acc": 52.0, "val_loss": 17.24388897418976, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2095844745636, "training_acc": 52.0, "val_loss": 17.246881127357483, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.23895573616028, "training_acc": 52.0, "val_loss": 17.247651517391205, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23514294624329, "training_acc": 52.0, "val_loss": 17.249804735183716, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23687529563904, "training_acc": 52.0, "val_loss": 17.252446711063385, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22755527496338, "training_acc": 52.0, "val_loss": 17.25284606218338, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25635695457458, "training_acc": 52.0, "val_loss": 17.25321114063263, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.26684999465942, "training_acc": 52.0, "val_loss": 17.25080907344818, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24095606803894, "training_acc": 52.0, "val_loss": 17.250461876392365, "val_acc": 56.0}
