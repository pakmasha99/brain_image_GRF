"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 116766.66510009766, "training_acc": 45.0, "val_loss": 21140.155029296875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 79301.86303710938, "training_acc": 59.0, "val_loss": 56034.259033203125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 216754.26416015625, "training_acc": 53.0, "val_loss": 41255.20324707031, "val_acc": 52.0}
{"epoch": 3, "training_loss": 131369.48950195312, "training_acc": 53.0, "val_loss": 12324.746704101562, "val_acc": 48.0}
{"epoch": 4, "training_loss": 66307.59985351562, "training_acc": 47.0, "val_loss": 23969.38934326172, "val_acc": 48.0}
{"epoch": 5, "training_loss": 78833.29516601562, "training_acc": 47.0, "val_loss": 8235.009765625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 46074.032470703125, "training_acc": 53.0, "val_loss": 16721.1669921875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 54625.69073486328, "training_acc": 53.0, "val_loss": 7904.821014404297, "val_acc": 48.0}
{"epoch": 8, "training_loss": 40654.025390625, "training_acc": 47.0, "val_loss": 7796.571350097656, "val_acc": 48.0}
{"epoch": 9, "training_loss": 26470.280700683594, "training_acc": 51.0, "val_loss": 9155.50765991211, "val_acc": 52.0}
{"epoch": 10, "training_loss": 31212.076293945312, "training_acc": 53.0, "val_loss": 4490.407180786133, "val_acc": 48.0}
{"epoch": 11, "training_loss": 18409.596313476562, "training_acc": 47.0, "val_loss": 2503.083038330078, "val_acc": 52.0}
{"epoch": 12, "training_loss": 8598.211471557617, "training_acc": 53.0, "val_loss": 5965.74821472168, "val_acc": 48.0}
{"epoch": 13, "training_loss": 23123.701171875, "training_acc": 47.0, "val_loss": 3862.6697540283203, "val_acc": 52.0}
{"epoch": 14, "training_loss": 16997.37384033203, "training_acc": 53.0, "val_loss": 134.80886220932007, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2354.4871978759766, "training_acc": 55.0, "val_loss": 2052.613067626953, "val_acc": 48.0}
{"epoch": 16, "training_loss": 8951.886627197266, "training_acc": 47.0, "val_loss": 794.3791389465332, "val_acc": 48.0}
{"epoch": 17, "training_loss": 7333.915832519531, "training_acc": 49.0, "val_loss": 1364.7615432739258, "val_acc": 52.0}
{"epoch": 18, "training_loss": 15577.39306640625, "training_acc": 49.0, "val_loss": 8151.426696777344, "val_acc": 48.0}
{"epoch": 19, "training_loss": 22756.863052368164, "training_acc": 47.0, "val_loss": 12332.879638671875, "val_acc": 52.0}
{"epoch": 20, "training_loss": 57501.114501953125, "training_acc": 53.0, "val_loss": 16399.449157714844, "val_acc": 52.0}
{"epoch": 21, "training_loss": 52906.11267089844, "training_acc": 53.0, "val_loss": 4889.443588256836, "val_acc": 48.0}
{"epoch": 22, "training_loss": 29443.251831054688, "training_acc": 47.0, "val_loss": 7786.619567871094, "val_acc": 48.0}
{"epoch": 23, "training_loss": 24584.30532836914, "training_acc": 47.0, "val_loss": 4539.692687988281, "val_acc": 52.0}
{"epoch": 24, "training_loss": 11842.065826416016, "training_acc": 53.0, "val_loss": 10370.84732055664, "val_acc": 48.0}
{"epoch": 25, "training_loss": 45455.71081542969, "training_acc": 47.0, "val_loss": 7082.228088378906, "val_acc": 48.0}
{"epoch": 26, "training_loss": 26661.138732910156, "training_acc": 47.0, "val_loss": 9032.301330566406, "val_acc": 52.0}
{"epoch": 27, "training_loss": 31762.880432128906, "training_acc": 53.0, "val_loss": 2018.575096130371, "val_acc": 48.0}
{"epoch": 28, "training_loss": 8405.62173461914, "training_acc": 47.0, "val_loss": 4364.821624755859, "val_acc": 52.0}
{"epoch": 29, "training_loss": 16613.555603027344, "training_acc": 53.0, "val_loss": 2589.715003967285, "val_acc": 48.0}
{"epoch": 30, "training_loss": 9064.317810058594, "training_acc": 47.0, "val_loss": 6464.974212646484, "val_acc": 52.0}
{"epoch": 31, "training_loss": 27309.184204101562, "training_acc": 53.0, "val_loss": 2536.6342544555664, "val_acc": 52.0}
{"epoch": 32, "training_loss": 18203.934692382812, "training_acc": 53.0, "val_loss": 12043.284606933594, "val_acc": 48.0}
{"epoch": 33, "training_loss": 42615.84375, "training_acc": 47.0, "val_loss": 3446.6747283935547, "val_acc": 52.0}
