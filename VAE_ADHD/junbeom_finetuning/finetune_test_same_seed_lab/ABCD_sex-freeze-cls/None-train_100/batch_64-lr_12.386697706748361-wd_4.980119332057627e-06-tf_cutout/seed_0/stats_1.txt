"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 79532.97100830078, "training_acc": 53.0, "val_loss": 20662.34588623047, "val_acc": 52.0}
{"epoch": 1, "training_loss": 106329.802734375, "training_acc": 49.0, "val_loss": 43302.72521972656, "val_acc": 48.0}
{"epoch": 2, "training_loss": 156367.94384765625, "training_acc": 47.0, "val_loss": 2711.04736328125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 42036.865966796875, "training_acc": 55.0, "val_loss": 48767.30651855469, "val_acc": 52.0}
{"epoch": 4, "training_loss": 198488.748046875, "training_acc": 53.0, "val_loss": 47441.27502441406, "val_acc": 52.0}
{"epoch": 5, "training_loss": 163980.4765625, "training_acc": 53.0, "val_loss": 10940.865325927734, "val_acc": 52.0}
{"epoch": 6, "training_loss": 67278.2548828125, "training_acc": 41.0, "val_loss": 33024.078369140625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 139184.125, "training_acc": 47.0, "val_loss": 29026.315307617188, "val_acc": 48.0}
{"epoch": 8, "training_loss": 95003.7880859375, "training_acc": 47.0, "val_loss": 6936.332702636719, "val_acc": 52.0}
{"epoch": 9, "training_loss": 44283.954345703125, "training_acc": 53.0, "val_loss": 21192.733764648438, "val_acc": 52.0}
{"epoch": 10, "training_loss": 77070.71411132812, "training_acc": 53.0, "val_loss": 6619.710540771484, "val_acc": 52.0}
{"epoch": 11, "training_loss": 22550.335571289062, "training_acc": 63.0, "val_loss": 18605.555725097656, "val_acc": 48.0}
{"epoch": 12, "training_loss": 75821.7802734375, "training_acc": 47.0, "val_loss": 11050.3173828125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 33546.508728027344, "training_acc": 49.0, "val_loss": 8903.52783203125, "val_acc": 52.0}
{"epoch": 14, "training_loss": 32981.057373046875, "training_acc": 53.0, "val_loss": 26.60304605960846, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2994.872657775879, "training_acc": 47.0, "val_loss": 3639.9044036865234, "val_acc": 52.0}
{"epoch": 16, "training_loss": 12128.176574707031, "training_acc": 53.0, "val_loss": 5806.050109863281, "val_acc": 48.0}
{"epoch": 17, "training_loss": 23577.44873046875, "training_acc": 47.0, "val_loss": 2488.12255859375, "val_acc": 52.0}
{"epoch": 18, "training_loss": 10511.43685913086, "training_acc": 53.0, "val_loss": 2490.974807739258, "val_acc": 48.0}
{"epoch": 19, "training_loss": 7019.843612670898, "training_acc": 47.0, "val_loss": 8753.55224609375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 39540.6201171875, "training_acc": 53.0, "val_loss": 6821.630096435547, "val_acc": 52.0}
{"epoch": 21, "training_loss": 20668.377990722656, "training_acc": 55.0, "val_loss": 6863.462066650391, "val_acc": 48.0}
{"epoch": 22, "training_loss": 21277.38116455078, "training_acc": 47.0, "val_loss": 8531.169128417969, "val_acc": 52.0}
{"epoch": 23, "training_loss": 41833.80712890625, "training_acc": 53.0, "val_loss": 10110.282897949219, "val_acc": 52.0}
{"epoch": 24, "training_loss": 27323.53175354004, "training_acc": 53.0, "val_loss": 14227.450561523438, "val_acc": 48.0}
{"epoch": 25, "training_loss": 70607.8203125, "training_acc": 47.0, "val_loss": 18771.115112304688, "val_acc": 48.0}
{"epoch": 26, "training_loss": 61541.640625, "training_acc": 47.0, "val_loss": 6409.339904785156, "val_acc": 52.0}
{"epoch": 27, "training_loss": 33284.42346191406, "training_acc": 53.0, "val_loss": 14779.244995117188, "val_acc": 52.0}
{"epoch": 28, "training_loss": 51032.50817871094, "training_acc": 53.0, "val_loss": 501.9239902496338, "val_acc": 48.0}
{"epoch": 29, "training_loss": 6055.553405761719, "training_acc": 47.0, "val_loss": 1502.6650428771973, "val_acc": 52.0}
{"epoch": 30, "training_loss": 4987.801300048828, "training_acc": 49.0, "val_loss": 4499.963760375977, "val_acc": 52.0}
{"epoch": 31, "training_loss": 15689.128021240234, "training_acc": 53.0, "val_loss": 4476.760482788086, "val_acc": 48.0}
{"epoch": 32, "training_loss": 18495.10333251953, "training_acc": 47.0, "val_loss": 3072.256851196289, "val_acc": 52.0}
{"epoch": 33, "training_loss": 11814.063598632812, "training_acc": 53.0, "val_loss": 2075.5130767822266, "val_acc": 48.0}
