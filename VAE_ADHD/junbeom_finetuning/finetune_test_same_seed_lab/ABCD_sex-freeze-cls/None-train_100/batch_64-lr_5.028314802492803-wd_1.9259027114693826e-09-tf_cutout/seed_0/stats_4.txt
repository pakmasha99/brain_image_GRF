"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 36679.30844116211, "training_acc": 49.0, "val_loss": 9669.050598144531, "val_acc": 52.0}
{"epoch": 1, "training_loss": 34163.19201660156, "training_acc": 59.0, "val_loss": 17393.995666503906, "val_acc": 48.0}
{"epoch": 2, "training_loss": 64028.593505859375, "training_acc": 47.0, "val_loss": 1889.9824142456055, "val_acc": 48.0}
{"epoch": 3, "training_loss": 21811.400146484375, "training_acc": 49.0, "val_loss": 18332.672119140625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 73881.58276367188, "training_acc": 53.0, "val_loss": 16142.684936523438, "val_acc": 52.0}
{"epoch": 5, "training_loss": 52415.48449707031, "training_acc": 53.0, "val_loss": 146.8733787536621, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7658.660430908203, "training_acc": 47.0, "val_loss": 5098.544692993164, "val_acc": 48.0}
{"epoch": 7, "training_loss": 15217.799942016602, "training_acc": 47.0, "val_loss": 5351.617050170898, "val_acc": 52.0}
{"epoch": 8, "training_loss": 24124.100463867188, "training_acc": 53.0, "val_loss": 7485.987091064453, "val_acc": 52.0}
{"epoch": 9, "training_loss": 25382.18765258789, "training_acc": 53.0, "val_loss": 1783.6345672607422, "val_acc": 48.0}
{"epoch": 10, "training_loss": 9856.127868652344, "training_acc": 47.0, "val_loss": 1709.8697662353516, "val_acc": 48.0}
{"epoch": 11, "training_loss": 9812.864074707031, "training_acc": 45.0, "val_loss": 4415.571594238281, "val_acc": 52.0}
{"epoch": 12, "training_loss": 15038.229431152344, "training_acc": 53.0, "val_loss": 1381.2905311584473, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6921.572357177734, "training_acc": 47.0, "val_loss": 118.75835657119751, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1488.8701629638672, "training_acc": 47.0, "val_loss": 1815.3823852539062, "val_acc": 52.0}
{"epoch": 15, "training_loss": 6866.248840332031, "training_acc": 53.0, "val_loss": 1447.3947525024414, "val_acc": 48.0}
{"epoch": 16, "training_loss": 5612.028274536133, "training_acc": 47.0, "val_loss": 1839.2528533935547, "val_acc": 52.0}
{"epoch": 17, "training_loss": 6967.794189453125, "training_acc": 53.0, "val_loss": 434.7914218902588, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2712.339309692383, "training_acc": 43.0, "val_loss": 976.9811630249023, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2975.3996772766113, "training_acc": 49.0, "val_loss": 1206.5014839172363, "val_acc": 48.0}
{"epoch": 20, "training_loss": 2878.5497131347656, "training_acc": 57.0, "val_loss": 795.9285736083984, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3967.9781036376953, "training_acc": 49.0, "val_loss": 698.7987041473389, "val_acc": 52.0}
{"epoch": 22, "training_loss": 5462.691589355469, "training_acc": 51.0, "val_loss": 2492.3091888427734, "val_acc": 48.0}
{"epoch": 23, "training_loss": 7992.972785949707, "training_acc": 45.0, "val_loss": 614.0507221221924, "val_acc": 52.0}
{"epoch": 24, "training_loss": 4901.584259033203, "training_acc": 49.0, "val_loss": 1545.6896781921387, "val_acc": 48.0}
{"epoch": 25, "training_loss": 5560.143646240234, "training_acc": 55.0, "val_loss": 2309.897232055664, "val_acc": 52.0}
{"epoch": 26, "training_loss": 6434.430763244629, "training_acc": 53.0, "val_loss": 3918.644332885742, "val_acc": 48.0}
{"epoch": 27, "training_loss": 17324.33612060547, "training_acc": 47.0, "val_loss": 2942.3158645629883, "val_acc": 48.0}
{"epoch": 28, "training_loss": 10063.93618774414, "training_acc": 49.0, "val_loss": 3161.8730545043945, "val_acc": 52.0}
{"epoch": 29, "training_loss": 10815.545318603516, "training_acc": 53.0, "val_loss": 1528.2240867614746, "val_acc": 48.0}
{"epoch": 30, "training_loss": 6934.776550292969, "training_acc": 47.0, "val_loss": 679.7394275665283, "val_acc": 52.0}
{"epoch": 31, "training_loss": 2314.1251335144043, "training_acc": 53.0, "val_loss": 2314.51358795166, "val_acc": 48.0}
{"epoch": 32, "training_loss": 8782.077392578125, "training_acc": 47.0, "val_loss": 1498.5380172729492, "val_acc": 52.0}
{"epoch": 33, "training_loss": 6889.8673095703125, "training_acc": 53.0, "val_loss": 33.0949991941452, "val_acc": 48.0}
{"epoch": 34, "training_loss": 397.87546157836914, "training_acc": 51.0, "val_loss": 2000.5792617797852, "val_acc": 48.0}
{"epoch": 35, "training_loss": 6790.26594543457, "training_acc": 47.0, "val_loss": 2601.0332107543945, "val_acc": 52.0}
{"epoch": 36, "training_loss": 11353.909606933594, "training_acc": 53.0, "val_loss": 1705.0735473632812, "val_acc": 52.0}
{"epoch": 37, "training_loss": 9832.667114257812, "training_acc": 43.0, "val_loss": 3424.5750427246094, "val_acc": 48.0}
{"epoch": 38, "training_loss": 10629.801078796387, "training_acc": 47.0, "val_loss": 3891.1956787109375, "val_acc": 52.0}
{"epoch": 39, "training_loss": 18146.2119140625, "training_acc": 53.0, "val_loss": 4636.466598510742, "val_acc": 52.0}
{"epoch": 40, "training_loss": 13005.372589111328, "training_acc": 53.0, "val_loss": 4639.798736572266, "val_acc": 48.0}
{"epoch": 41, "training_loss": 21430.99444580078, "training_acc": 47.0, "val_loss": 6441.313934326172, "val_acc": 48.0}
{"epoch": 42, "training_loss": 21286.35235595703, "training_acc": 47.0, "val_loss": 2600.8529663085938, "val_acc": 52.0}
{"epoch": 43, "training_loss": 13516.849975585938, "training_acc": 53.0, "val_loss": 5043.839645385742, "val_acc": 52.0}
{"epoch": 44, "training_loss": 15927.959533691406, "training_acc": 53.0, "val_loss": 2226.201629638672, "val_acc": 48.0}
{"epoch": 45, "training_loss": 11983.895935058594, "training_acc": 47.0, "val_loss": 3050.0892639160156, "val_acc": 48.0}
{"epoch": 46, "training_loss": 8431.530883789062, "training_acc": 53.0, "val_loss": 1786.087417602539, "val_acc": 52.0}
{"epoch": 47, "training_loss": 4884.4601974487305, "training_acc": 53.0, "val_loss": 3769.6189880371094, "val_acc": 48.0}
{"epoch": 48, "training_loss": 17620.61846923828, "training_acc": 47.0, "val_loss": 2344.942092895508, "val_acc": 48.0}
{"epoch": 49, "training_loss": 8550.025085449219, "training_acc": 55.0, "val_loss": 4759.683609008789, "val_acc": 52.0}
{"epoch": 50, "training_loss": 18223.183532714844, "training_acc": 53.0, "val_loss": 1519.8190689086914, "val_acc": 52.0}
{"epoch": 51, "training_loss": 8408.739074707031, "training_acc": 55.0, "val_loss": 5890.7928466796875, "val_acc": 48.0}
{"epoch": 52, "training_loss": 22436.321899414062, "training_acc": 47.0, "val_loss": 945.1225280761719, "val_acc": 48.0}
