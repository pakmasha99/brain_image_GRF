"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 36457.27339172363, "training_acc": 49.0, "val_loss": 10225.88882446289, "val_acc": 52.0}
{"epoch": 1, "training_loss": 41079.99011230469, "training_acc": 51.0, "val_loss": 14587.59765625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 51915.30432128906, "training_acc": 47.0, "val_loss": 1202.0522117614746, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8483.170166015625, "training_acc": 53.0, "val_loss": 2060.077667236328, "val_acc": 52.0}
{"epoch": 4, "training_loss": 12591.902038574219, "training_acc": 47.0, "val_loss": 4671.156692504883, "val_acc": 48.0}
{"epoch": 5, "training_loss": 12759.317840576172, "training_acc": 47.0, "val_loss": 6717.890167236328, "val_acc": 52.0}
{"epoch": 6, "training_loss": 29769.668212890625, "training_acc": 53.0, "val_loss": 9067.742156982422, "val_acc": 52.0}
{"epoch": 7, "training_loss": 30080.553466796875, "training_acc": 53.0, "val_loss": 523.4763145446777, "val_acc": 48.0}
{"epoch": 8, "training_loss": 5114.662750244141, "training_acc": 47.0, "val_loss": 1670.4601287841797, "val_acc": 48.0}
{"epoch": 9, "training_loss": 6677.783843994141, "training_acc": 55.0, "val_loss": 3419.0052032470703, "val_acc": 52.0}
{"epoch": 10, "training_loss": 10877.408081054688, "training_acc": 53.0, "val_loss": 2904.5583724975586, "val_acc": 48.0}
{"epoch": 11, "training_loss": 13800.8515625, "training_acc": 47.0, "val_loss": 1890.5946731567383, "val_acc": 48.0}
{"epoch": 12, "training_loss": 7376.964782714844, "training_acc": 57.0, "val_loss": 4824.077987670898, "val_acc": 52.0}
{"epoch": 13, "training_loss": 17672.96661376953, "training_acc": 53.0, "val_loss": 647.0024108886719, "val_acc": 52.0}
{"epoch": 14, "training_loss": 11081.849487304688, "training_acc": 45.0, "val_loss": 7372.954559326172, "val_acc": 48.0}
{"epoch": 15, "training_loss": 27947.18536376953, "training_acc": 47.0, "val_loss": 1555.5490493774414, "val_acc": 48.0}
{"epoch": 16, "training_loss": 11186.786193847656, "training_acc": 49.0, "val_loss": 8301.612854003906, "val_acc": 52.0}
{"epoch": 17, "training_loss": 32985.48645019531, "training_acc": 53.0, "val_loss": 6607.189178466797, "val_acc": 52.0}
{"epoch": 18, "training_loss": 19718.365997314453, "training_acc": 53.0, "val_loss": 4504.457092285156, "val_acc": 48.0}
{"epoch": 19, "training_loss": 23804.001342773438, "training_acc": 47.0, "val_loss": 7544.1131591796875, "val_acc": 48.0}
{"epoch": 20, "training_loss": 25495.820251464844, "training_acc": 47.0, "val_loss": 1567.5792694091797, "val_acc": 52.0}
{"epoch": 21, "training_loss": 10041.441040039062, "training_acc": 53.0, "val_loss": 4340.201568603516, "val_acc": 52.0}
{"epoch": 22, "training_loss": 13869.45068359375, "training_acc": 53.0, "val_loss": 3026.166343688965, "val_acc": 48.0}
{"epoch": 23, "training_loss": 13838.212097167969, "training_acc": 47.0, "val_loss": 2538.235855102539, "val_acc": 48.0}
{"epoch": 24, "training_loss": 11590.81216430664, "training_acc": 39.0, "val_loss": 3055.2202224731445, "val_acc": 52.0}
{"epoch": 25, "training_loss": 9694.892852783203, "training_acc": 53.0, "val_loss": 2680.7565689086914, "val_acc": 48.0}
{"epoch": 26, "training_loss": 11857.107299804688, "training_acc": 47.0, "val_loss": 1163.8659477233887, "val_acc": 48.0}
