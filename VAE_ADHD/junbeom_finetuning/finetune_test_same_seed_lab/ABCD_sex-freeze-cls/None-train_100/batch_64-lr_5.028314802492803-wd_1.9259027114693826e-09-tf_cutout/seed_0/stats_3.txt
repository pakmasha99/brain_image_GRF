"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 40897.891120910645, "training_acc": 53.0, "val_loss": 8368.265533447266, "val_acc": 52.0}
{"epoch": 1, "training_loss": 39103.689697265625, "training_acc": 53.0, "val_loss": 19269.554138183594, "val_acc": 48.0}
{"epoch": 2, "training_loss": 72944.21057128906, "training_acc": 47.0, "val_loss": 5312.936019897461, "val_acc": 48.0}
{"epoch": 3, "training_loss": 26915.013305664062, "training_acc": 45.0, "val_loss": 13003.225708007812, "val_acc": 52.0}
{"epoch": 4, "training_loss": 52202.575439453125, "training_acc": 53.0, "val_loss": 9863.042449951172, "val_acc": 52.0}
{"epoch": 5, "training_loss": 29178.715270996094, "training_acc": 53.0, "val_loss": 7246.946716308594, "val_acc": 48.0}
{"epoch": 6, "training_loss": 36991.299560546875, "training_acc": 47.0, "val_loss": 12133.960723876953, "val_acc": 48.0}
{"epoch": 7, "training_loss": 43865.88427734375, "training_acc": 47.0, "val_loss": 1470.0553894042969, "val_acc": 48.0}
{"epoch": 8, "training_loss": 16383.377807617188, "training_acc": 45.0, "val_loss": 12618.563842773438, "val_acc": 52.0}
{"epoch": 9, "training_loss": 51554.441162109375, "training_acc": 53.0, "val_loss": 12668.016052246094, "val_acc": 52.0}
{"epoch": 10, "training_loss": 43923.37060546875, "training_acc": 53.0, "val_loss": 2339.5116806030273, "val_acc": 52.0}
{"epoch": 11, "training_loss": 14494.963928222656, "training_acc": 53.0, "val_loss": 11255.753326416016, "val_acc": 48.0}
{"epoch": 12, "training_loss": 47295.24768066406, "training_acc": 47.0, "val_loss": 10166.706848144531, "val_acc": 48.0}
{"epoch": 13, "training_loss": 32959.39343261719, "training_acc": 47.0, "val_loss": 2216.287612915039, "val_acc": 52.0}
{"epoch": 14, "training_loss": 13117.132629394531, "training_acc": 53.0, "val_loss": 7347.425842285156, "val_acc": 52.0}
{"epoch": 15, "training_loss": 26911.234436035156, "training_acc": 53.0, "val_loss": 2306.058120727539, "val_acc": 52.0}
{"epoch": 16, "training_loss": 8560.80191040039, "training_acc": 61.0, "val_loss": 6618.670654296875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 26380.27703857422, "training_acc": 47.0, "val_loss": 3004.3798446655273, "val_acc": 48.0}
{"epoch": 18, "training_loss": 9991.853820800781, "training_acc": 55.0, "val_loss": 5033.469009399414, "val_acc": 52.0}
{"epoch": 19, "training_loss": 19310.748046875, "training_acc": 53.0, "val_loss": 2186.6004943847656, "val_acc": 52.0}
{"epoch": 20, "training_loss": 9563.021453857422, "training_acc": 51.0, "val_loss": 4397.185516357422, "val_acc": 48.0}
{"epoch": 21, "training_loss": 15583.282409667969, "training_acc": 47.0, "val_loss": 1560.64453125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 8553.444396972656, "training_acc": 53.0, "val_loss": 1699.216651916504, "val_acc": 52.0}
{"epoch": 23, "training_loss": 5451.515884399414, "training_acc": 61.0, "val_loss": 2799.5040893554688, "val_acc": 48.0}
{"epoch": 24, "training_loss": 8271.127883911133, "training_acc": 47.0, "val_loss": 3932.3158264160156, "val_acc": 52.0}
{"epoch": 25, "training_loss": 17794.961853027344, "training_acc": 53.0, "val_loss": 4643.500900268555, "val_acc": 52.0}
{"epoch": 26, "training_loss": 13119.902359008789, "training_acc": 53.0, "val_loss": 4572.786331176758, "val_acc": 48.0}
