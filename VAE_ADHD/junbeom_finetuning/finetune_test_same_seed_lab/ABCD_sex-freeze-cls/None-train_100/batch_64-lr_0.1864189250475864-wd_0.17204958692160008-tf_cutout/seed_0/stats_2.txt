"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1873.586036682129, "training_acc": 43.0, "val_loss": 272.11592197418213, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1278.0758361816406, "training_acc": 55.0, "val_loss": 857.0568084716797, "val_acc": 52.0}
{"epoch": 2, "training_loss": 3338.733612060547, "training_acc": 53.0, "val_loss": 607.9021453857422, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1926.3057041168213, "training_acc": 53.0, "val_loss": 261.93830966949463, "val_acc": 48.0}
{"epoch": 4, "training_loss": 1415.5928344726562, "training_acc": 47.0, "val_loss": 450.9075164794922, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1551.842544555664, "training_acc": 47.0, "val_loss": 50.098419189453125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 329.0124740600586, "training_acc": 53.0, "val_loss": 161.11663579940796, "val_acc": 52.0}
{"epoch": 7, "training_loss": 452.12650775909424, "training_acc": 53.0, "val_loss": 186.8864893913269, "val_acc": 48.0}
{"epoch": 8, "training_loss": 867.8124694824219, "training_acc": 47.0, "val_loss": 174.13151264190674, "val_acc": 48.0}
{"epoch": 9, "training_loss": 458.01506757736206, "training_acc": 53.0, "val_loss": 121.56031131744385, "val_acc": 52.0}
{"epoch": 10, "training_loss": 452.8817825317383, "training_acc": 53.0, "val_loss": 21.937210857868195, "val_acc": 48.0}
{"epoch": 11, "training_loss": 169.67234134674072, "training_acc": 47.0, "val_loss": 29.661506414413452, "val_acc": 52.0}
{"epoch": 12, "training_loss": 116.78743267059326, "training_acc": 53.0, "val_loss": 66.2533700466156, "val_acc": 48.0}
{"epoch": 13, "training_loss": 216.14865684509277, "training_acc": 47.0, "val_loss": 95.97512483596802, "val_acc": 52.0}
{"epoch": 14, "training_loss": 376.4127035140991, "training_acc": 53.0, "val_loss": 17.341800034046173, "val_acc": 52.0}
{"epoch": 15, "training_loss": 164.93945217132568, "training_acc": 53.0, "val_loss": 49.67758357524872, "val_acc": 48.0}
{"epoch": 16, "training_loss": 295.1429691314697, "training_acc": 45.0, "val_loss": 113.74613046646118, "val_acc": 52.0}
{"epoch": 17, "training_loss": 323.34410285949707, "training_acc": 53.0, "val_loss": 142.52456426620483, "val_acc": 48.0}
{"epoch": 18, "training_loss": 643.611644744873, "training_acc": 47.0, "val_loss": 83.47288370132446, "val_acc": 48.0}
{"epoch": 19, "training_loss": 394.9503002166748, "training_acc": 47.0, "val_loss": 176.23014450073242, "val_acc": 52.0}
{"epoch": 20, "training_loss": 630.6525783538818, "training_acc": 53.0, "val_loss": 17.309600114822388, "val_acc": 52.0}
{"epoch": 21, "training_loss": 224.64299201965332, "training_acc": 51.0, "val_loss": 113.38118314743042, "val_acc": 48.0}
{"epoch": 22, "training_loss": 337.1938102245331, "training_acc": 47.0, "val_loss": 62.28218674659729, "val_acc": 52.0}
{"epoch": 23, "training_loss": 190.8264923095703, "training_acc": 53.0, "val_loss": 43.51435899734497, "val_acc": 48.0}
{"epoch": 24, "training_loss": 166.82887744903564, "training_acc": 47.0, "val_loss": 17.468570172786713, "val_acc": 52.0}
{"epoch": 25, "training_loss": 95.16298913955688, "training_acc": 51.0, "val_loss": 36.35343015193939, "val_acc": 52.0}
{"epoch": 26, "training_loss": 118.63135123252869, "training_acc": 53.0, "val_loss": 27.728354930877686, "val_acc": 48.0}
{"epoch": 27, "training_loss": 141.36170959472656, "training_acc": 47.0, "val_loss": 17.31807291507721, "val_acc": 52.0}
{"epoch": 28, "training_loss": 95.86524772644043, "training_acc": 53.0, "val_loss": 32.47413635253906, "val_acc": 52.0}
{"epoch": 29, "training_loss": 106.15667295455933, "training_acc": 53.0, "val_loss": 29.831302165985107, "val_acc": 48.0}
{"epoch": 30, "training_loss": 184.09300327301025, "training_acc": 41.0, "val_loss": 17.388783395290375, "val_acc": 52.0}
{"epoch": 31, "training_loss": 105.83652591705322, "training_acc": 55.0, "val_loss": 20.228049159049988, "val_acc": 52.0}
{"epoch": 32, "training_loss": 81.7468581199646, "training_acc": 53.0, "val_loss": 42.400333285331726, "val_acc": 48.0}
{"epoch": 33, "training_loss": 126.52432894706726, "training_acc": 55.0, "val_loss": 31.7929744720459, "val_acc": 52.0}
{"epoch": 34, "training_loss": 134.55849409103394, "training_acc": 53.0, "val_loss": 17.614878714084625, "val_acc": 52.0}
{"epoch": 35, "training_loss": 115.72635078430176, "training_acc": 53.0, "val_loss": 53.87148857116699, "val_acc": 48.0}
{"epoch": 36, "training_loss": 181.52288722991943, "training_acc": 47.0, "val_loss": 111.0041618347168, "val_acc": 52.0}
{"epoch": 37, "training_loss": 443.98784351348877, "training_acc": 53.0, "val_loss": 41.31447374820709, "val_acc": 52.0}
{"epoch": 38, "training_loss": 227.07536697387695, "training_acc": 59.0, "val_loss": 161.6663932800293, "val_acc": 48.0}
{"epoch": 39, "training_loss": 533.0476503372192, "training_acc": 47.0, "val_loss": 119.03773546218872, "val_acc": 52.0}
