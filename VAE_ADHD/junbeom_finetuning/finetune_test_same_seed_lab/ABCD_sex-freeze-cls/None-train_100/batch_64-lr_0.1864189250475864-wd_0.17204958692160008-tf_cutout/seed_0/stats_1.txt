"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1325.0799255371094, "training_acc": 51.0, "val_loss": 274.52032566070557, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1658.9864044189453, "training_acc": 47.0, "val_loss": 689.9575233459473, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2504.309959411621, "training_acc": 47.0, "val_loss": 60.48849821090698, "val_acc": 48.0}
{"epoch": 3, "training_loss": 727.7735557556152, "training_acc": 51.0, "val_loss": 661.1804485321045, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2619.7764892578125, "training_acc": 53.0, "val_loss": 559.9387645721436, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1894.2655639648438, "training_acc": 53.0, "val_loss": 29.73383665084839, "val_acc": 48.0}
{"epoch": 6, "training_loss": 352.34993171691895, "training_acc": 47.0, "val_loss": 194.78296041488647, "val_acc": 48.0}
{"epoch": 7, "training_loss": 582.7927069664001, "training_acc": 47.0, "val_loss": 197.46264219284058, "val_acc": 52.0}
{"epoch": 8, "training_loss": 839.07297706604, "training_acc": 53.0, "val_loss": 239.36326503753662, "val_acc": 52.0}
{"epoch": 9, "training_loss": 756.8912506103516, "training_acc": 53.0, "val_loss": 125.75465440750122, "val_acc": 48.0}
{"epoch": 10, "training_loss": 641.9036407470703, "training_acc": 47.0, "val_loss": 131.85399770736694, "val_acc": 48.0}
{"epoch": 11, "training_loss": 440.79685401916504, "training_acc": 47.0, "val_loss": 104.22111749649048, "val_acc": 52.0}
{"epoch": 12, "training_loss": 324.3368806838989, "training_acc": 53.0, "val_loss": 114.83756303787231, "val_acc": 48.0}
{"epoch": 13, "training_loss": 473.9575996398926, "training_acc": 47.0, "val_loss": 44.209229946136475, "val_acc": 48.0}
{"epoch": 14, "training_loss": 311.5298099517822, "training_acc": 47.0, "val_loss": 170.4989790916443, "val_acc": 52.0}
{"epoch": 15, "training_loss": 581.7577209472656, "training_acc": 53.0, "val_loss": 44.41022872924805, "val_acc": 48.0}
{"epoch": 16, "training_loss": 224.62050437927246, "training_acc": 47.0, "val_loss": 20.79980820417404, "val_acc": 52.0}
{"epoch": 17, "training_loss": 108.8871865272522, "training_acc": 53.0, "val_loss": 33.21535289287567, "val_acc": 48.0}
{"epoch": 18, "training_loss": 109.1457679271698, "training_acc": 51.0, "val_loss": 35.52801012992859, "val_acc": 52.0}
{"epoch": 19, "training_loss": 149.24905586242676, "training_acc": 47.0, "val_loss": 24.10869151353836, "val_acc": 52.0}
{"epoch": 20, "training_loss": 88.23829889297485, "training_acc": 49.0, "val_loss": 17.585304379463196, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.98951697349548, "training_acc": 47.0, "val_loss": 33.78770649433136, "val_acc": 52.0}
{"epoch": 22, "training_loss": 98.44087600708008, "training_acc": 59.0, "val_loss": 33.94806981086731, "val_acc": 48.0}
{"epoch": 23, "training_loss": 181.50985717773438, "training_acc": 45.0, "val_loss": 22.57314622402191, "val_acc": 52.0}
{"epoch": 24, "training_loss": 218.81712532043457, "training_acc": 45.0, "val_loss": 48.55982959270477, "val_acc": 48.0}
{"epoch": 25, "training_loss": 339.8703022003174, "training_acc": 41.0, "val_loss": 125.9564995765686, "val_acc": 52.0}
{"epoch": 26, "training_loss": 373.01962423324585, "training_acc": 53.0, "val_loss": 138.96925449371338, "val_acc": 48.0}
{"epoch": 27, "training_loss": 647.310375213623, "training_acc": 47.0, "val_loss": 78.45904231071472, "val_acc": 48.0}
{"epoch": 28, "training_loss": 339.4872703552246, "training_acc": 53.0, "val_loss": 194.88095045089722, "val_acc": 52.0}
{"epoch": 29, "training_loss": 715.5391693115234, "training_acc": 53.0, "val_loss": 37.8448486328125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 339.44663429260254, "training_acc": 51.0, "val_loss": 227.58867740631104, "val_acc": 48.0}
{"epoch": 31, "training_loss": 827.8589725494385, "training_acc": 47.0, "val_loss": 23.156343400478363, "val_acc": 52.0}
{"epoch": 32, "training_loss": 191.7453441619873, "training_acc": 53.0, "val_loss": 76.61201357841492, "val_acc": 52.0}
{"epoch": 33, "training_loss": 257.345422744751, "training_acc": 51.0, "val_loss": 43.72556209564209, "val_acc": 48.0}
{"epoch": 34, "training_loss": 181.19286918640137, "training_acc": 53.0, "val_loss": 58.68405103683472, "val_acc": 52.0}
{"epoch": 35, "training_loss": 264.0299348831177, "training_acc": 43.0, "val_loss": 23.193354904651642, "val_acc": 48.0}
{"epoch": 36, "training_loss": 175.8348045349121, "training_acc": 49.0, "val_loss": 68.53416562080383, "val_acc": 52.0}
{"epoch": 37, "training_loss": 279.62247943878174, "training_acc": 45.0, "val_loss": 33.28269422054291, "val_acc": 48.0}
{"epoch": 38, "training_loss": 231.4960651397705, "training_acc": 45.0, "val_loss": 81.24180436134338, "val_acc": 52.0}
{"epoch": 39, "training_loss": 193.24053931236267, "training_acc": 61.0, "val_loss": 87.43212223052979, "val_acc": 48.0}
