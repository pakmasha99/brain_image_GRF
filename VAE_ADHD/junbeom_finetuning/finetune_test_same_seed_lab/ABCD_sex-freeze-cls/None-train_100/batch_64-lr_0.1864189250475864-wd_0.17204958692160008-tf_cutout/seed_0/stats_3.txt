"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1402.1204376220703, "training_acc": 49.0, "val_loss": 257.61117935180664, "val_acc": 52.0}
{"epoch": 1, "training_loss": 1720.414535522461, "training_acc": 45.0, "val_loss": 716.9904708862305, "val_acc": 48.0}
{"epoch": 2, "training_loss": 2632.741371154785, "training_acc": 47.0, "val_loss": 117.04891920089722, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1057.5458450317383, "training_acc": 39.0, "val_loss": 567.5346374511719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 2244.901710510254, "training_acc": 53.0, "val_loss": 437.5842571258545, "val_acc": 52.0}
{"epoch": 5, "training_loss": 1409.8203430175781, "training_acc": 53.0, "val_loss": 160.83284616470337, "val_acc": 48.0}
{"epoch": 6, "training_loss": 908.5030288696289, "training_acc": 47.0, "val_loss": 292.04680919647217, "val_acc": 48.0}
{"epoch": 7, "training_loss": 959.0676021575928, "training_acc": 47.0, "val_loss": 122.1763014793396, "val_acc": 52.0}
{"epoch": 8, "training_loss": 599.343469619751, "training_acc": 53.0, "val_loss": 208.49826335906982, "val_acc": 52.0}
{"epoch": 9, "training_loss": 649.1212120056152, "training_acc": 53.0, "val_loss": 110.97439527511597, "val_acc": 48.0}
{"epoch": 10, "training_loss": 505.3511447906494, "training_acc": 47.0, "val_loss": 113.63226175308228, "val_acc": 48.0}
{"epoch": 11, "training_loss": 342.5734796524048, "training_acc": 51.0, "val_loss": 80.23254871368408, "val_acc": 52.0}
{"epoch": 12, "training_loss": 233.93609261512756, "training_acc": 53.0, "val_loss": 105.08137941360474, "val_acc": 48.0}
{"epoch": 13, "training_loss": 405.78679275512695, "training_acc": 47.0, "val_loss": 31.25268816947937, "val_acc": 52.0}
{"epoch": 14, "training_loss": 138.67438745498657, "training_acc": 53.0, "val_loss": 34.92998778820038, "val_acc": 48.0}
{"epoch": 15, "training_loss": 114.48980736732483, "training_acc": 47.0, "val_loss": 60.45314073562622, "val_acc": 52.0}
{"epoch": 16, "training_loss": 190.5864224433899, "training_acc": 53.0, "val_loss": 72.89221286773682, "val_acc": 48.0}
{"epoch": 17, "training_loss": 243.79085540771484, "training_acc": 47.0, "val_loss": 93.51812601089478, "val_acc": 52.0}
{"epoch": 18, "training_loss": 390.68512535095215, "training_acc": 53.0, "val_loss": 25.407519936561584, "val_acc": 52.0}
{"epoch": 19, "training_loss": 225.17225456237793, "training_acc": 55.0, "val_loss": 150.95146894454956, "val_acc": 48.0}
{"epoch": 20, "training_loss": 469.57023906707764, "training_acc": 47.0, "val_loss": 131.94713592529297, "val_acc": 52.0}
{"epoch": 21, "training_loss": 628.6556282043457, "training_acc": 53.0, "val_loss": 169.46526765823364, "val_acc": 52.0}
{"epoch": 22, "training_loss": 484.0500154495239, "training_acc": 53.0, "val_loss": 172.3780632019043, "val_acc": 48.0}
{"epoch": 23, "training_loss": 842.8795852661133, "training_acc": 47.0, "val_loss": 193.03475618362427, "val_acc": 48.0}
{"epoch": 24, "training_loss": 544.4199132919312, "training_acc": 47.0, "val_loss": 192.70614385604858, "val_acc": 52.0}
{"epoch": 25, "training_loss": 861.7294960021973, "training_acc": 53.0, "val_loss": 268.21510791778564, "val_acc": 52.0}
{"epoch": 26, "training_loss": 903.814661026001, "training_acc": 53.0, "val_loss": 26.82918608188629, "val_acc": 48.0}
{"epoch": 27, "training_loss": 183.6436996459961, "training_acc": 47.0, "val_loss": 77.66811847686768, "val_acc": 48.0}
{"epoch": 28, "training_loss": 261.4055027961731, "training_acc": 51.0, "val_loss": 65.98674058914185, "val_acc": 52.0}
{"epoch": 29, "training_loss": 215.01097679138184, "training_acc": 47.0, "val_loss": 19.926150143146515, "val_acc": 48.0}
{"epoch": 30, "training_loss": 177.09159183502197, "training_acc": 37.0, "val_loss": 17.49044805765152, "val_acc": 52.0}
{"epoch": 31, "training_loss": 100.48039770126343, "training_acc": 47.0, "val_loss": 23.220504820346832, "val_acc": 52.0}
{"epoch": 32, "training_loss": 84.74911260604858, "training_acc": 53.0, "val_loss": 23.71061146259308, "val_acc": 48.0}
{"epoch": 33, "training_loss": 110.36419153213501, "training_acc": 49.0, "val_loss": 19.423820078372955, "val_acc": 48.0}
{"epoch": 34, "training_loss": 84.861572265625, "training_acc": 47.0, "val_loss": 66.42624735832214, "val_acc": 52.0}
{"epoch": 35, "training_loss": 247.3443021774292, "training_acc": 53.0, "val_loss": 84.10010933876038, "val_acc": 48.0}
{"epoch": 36, "training_loss": 370.391321182251, "training_acc": 47.0, "val_loss": 20.52457630634308, "val_acc": 52.0}
{"epoch": 37, "training_loss": 176.21387195587158, "training_acc": 53.0, "val_loss": 17.74917244911194, "val_acc": 52.0}
{"epoch": 38, "training_loss": 169.48800945281982, "training_acc": 49.0, "val_loss": 33.192840218544006, "val_acc": 48.0}
{"epoch": 39, "training_loss": 249.98314666748047, "training_acc": 47.0, "val_loss": 121.5860366821289, "val_acc": 52.0}
{"epoch": 40, "training_loss": 357.392023563385, "training_acc": 53.0, "val_loss": 136.84033155441284, "val_acc": 48.0}
{"epoch": 41, "training_loss": 623.824764251709, "training_acc": 47.0, "val_loss": 82.12898969650269, "val_acc": 48.0}
{"epoch": 42, "training_loss": 351.3788757324219, "training_acc": 51.0, "val_loss": 174.59733486175537, "val_acc": 52.0}
{"epoch": 43, "training_loss": 629.4954490661621, "training_acc": 53.0, "val_loss": 17.629463970661163, "val_acc": 52.0}
{"epoch": 44, "training_loss": 291.49349212646484, "training_acc": 45.0, "val_loss": 138.1500244140625, "val_acc": 48.0}
{"epoch": 45, "training_loss": 379.3897352218628, "training_acc": 47.0, "val_loss": 160.70804595947266, "val_acc": 52.0}
{"epoch": 46, "training_loss": 779.4922637939453, "training_acc": 53.0, "val_loss": 174.5361328125, "val_acc": 52.0}
{"epoch": 47, "training_loss": 505.17022466659546, "training_acc": 53.0, "val_loss": 167.9048776626587, "val_acc": 48.0}
{"epoch": 48, "training_loss": 724.9039096832275, "training_acc": 47.0, "val_loss": 119.66148614883423, "val_acc": 48.0}
{"epoch": 49, "training_loss": 421.18217277526855, "training_acc": 47.0, "val_loss": 117.2628402709961, "val_acc": 52.0}
