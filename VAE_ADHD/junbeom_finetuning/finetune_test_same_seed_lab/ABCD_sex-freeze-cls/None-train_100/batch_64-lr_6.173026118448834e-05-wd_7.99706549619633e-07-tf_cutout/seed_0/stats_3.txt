"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.33343625068665, "training_acc": 53.0, "val_loss": 17.310386896133423, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1818015575409, "training_acc": 53.0, "val_loss": 17.3104926943779, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15575051307678, "training_acc": 53.0, "val_loss": 17.31085032224655, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1870129108429, "training_acc": 53.0, "val_loss": 17.31037050485611, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15902423858643, "training_acc": 53.0, "val_loss": 17.30961501598358, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18790054321289, "training_acc": 53.0, "val_loss": 17.30920970439911, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14760613441467, "training_acc": 53.0, "val_loss": 17.309361696243286, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14659595489502, "training_acc": 53.0, "val_loss": 17.309926450252533, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13028049468994, "training_acc": 53.0, "val_loss": 17.310893535614014, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13601756095886, "training_acc": 53.0, "val_loss": 17.311879992485046, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14681220054626, "training_acc": 53.0, "val_loss": 17.3123300075531, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10959577560425, "training_acc": 53.0, "val_loss": 17.31422394514084, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13107967376709, "training_acc": 53.0, "val_loss": 17.317242920398712, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16921281814575, "training_acc": 53.0, "val_loss": 17.319655418395996, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14460706710815, "training_acc": 53.0, "val_loss": 17.319276928901672, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1296010017395, "training_acc": 53.0, "val_loss": 17.317868769168854, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12852096557617, "training_acc": 53.0, "val_loss": 17.317630350589752, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11736392974854, "training_acc": 53.0, "val_loss": 17.317982017993927, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11255621910095, "training_acc": 53.0, "val_loss": 17.318005859851837, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14378237724304, "training_acc": 53.0, "val_loss": 17.318645119667053, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1464216709137, "training_acc": 53.0, "val_loss": 17.318345606327057, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12091946601868, "training_acc": 53.0, "val_loss": 17.31611341238022, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14295887947083, "training_acc": 53.0, "val_loss": 17.314696311950684, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11626100540161, "training_acc": 53.0, "val_loss": 17.313659191131592, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10519433021545, "training_acc": 53.0, "val_loss": 17.31240600347519, "val_acc": 52.0}
