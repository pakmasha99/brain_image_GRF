"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23820948600769, "training_acc": 52.0, "val_loss": 17.239341139793396, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23388314247131, "training_acc": 52.0, "val_loss": 17.22288429737091, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25215888023376, "training_acc": 52.0, "val_loss": 17.22126305103302, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26385188102722, "training_acc": 52.0, "val_loss": 17.22979247570038, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24001932144165, "training_acc": 52.0, "val_loss": 17.243659496307373, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2249698638916, "training_acc": 52.0, "val_loss": 17.24870651960373, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25824642181396, "training_acc": 52.0, "val_loss": 17.259423434734344, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25591611862183, "training_acc": 52.0, "val_loss": 17.264501750469208, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26565980911255, "training_acc": 52.0, "val_loss": 17.26013273000717, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25501704216003, "training_acc": 52.0, "val_loss": 17.263439297676086, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23214340209961, "training_acc": 52.0, "val_loss": 17.265139520168304, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26265692710876, "training_acc": 52.0, "val_loss": 17.262856662273407, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23266172409058, "training_acc": 52.0, "val_loss": 17.25972592830658, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23970103263855, "training_acc": 52.0, "val_loss": 17.258964478969574, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.2487485408783, "training_acc": 52.0, "val_loss": 17.25333333015442, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25270414352417, "training_acc": 52.0, "val_loss": 17.24493056535721, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25182819366455, "training_acc": 52.0, "val_loss": 17.232638597488403, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.2334816455841, "training_acc": 52.0, "val_loss": 17.224198579788208, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2405903339386, "training_acc": 52.0, "val_loss": 17.217379808425903, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25658464431763, "training_acc": 52.0, "val_loss": 17.212234437465668, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20485234260559, "training_acc": 52.0, "val_loss": 17.21075177192688, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22524166107178, "training_acc": 52.0, "val_loss": 17.20893830060959, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28773474693298, "training_acc": 52.0, "val_loss": 17.20470041036606, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26173496246338, "training_acc": 52.0, "val_loss": 17.207111418247223, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26039552688599, "training_acc": 52.0, "val_loss": 17.21312701702118, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24875950813293, "training_acc": 52.0, "val_loss": 17.22242385149002, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.2778947353363, "training_acc": 52.0, "val_loss": 17.226487398147583, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.2275505065918, "training_acc": 52.0, "val_loss": 17.239472270011902, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24380445480347, "training_acc": 52.0, "val_loss": 17.25158989429474, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25806522369385, "training_acc": 52.0, "val_loss": 17.256492376327515, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.2676773071289, "training_acc": 52.0, "val_loss": 17.255714535713196, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27659845352173, "training_acc": 52.0, "val_loss": 17.262153327465057, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24633717536926, "training_acc": 52.0, "val_loss": 17.258353531360626, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25604343414307, "training_acc": 52.0, "val_loss": 17.25493222475052, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25772500038147, "training_acc": 52.0, "val_loss": 17.248588800430298, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24043297767639, "training_acc": 52.0, "val_loss": 17.245136201381683, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23877048492432, "training_acc": 52.0, "val_loss": 17.241166532039642, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23841404914856, "training_acc": 52.0, "val_loss": 17.236122488975525, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23082518577576, "training_acc": 52.0, "val_loss": 17.226609587669373, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24734950065613, "training_acc": 52.0, "val_loss": 17.214038968086243, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22887229919434, "training_acc": 52.0, "val_loss": 17.208358645439148, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2530529499054, "training_acc": 52.0, "val_loss": 17.204517126083374, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26543307304382, "training_acc": 52.0, "val_loss": 17.20205843448639, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.2376639842987, "training_acc": 52.0, "val_loss": 17.203766107559204, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25062680244446, "training_acc": 52.0, "val_loss": 17.21169650554657, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.2420608997345, "training_acc": 52.0, "val_loss": 17.217697203159332, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25551986694336, "training_acc": 52.0, "val_loss": 17.225466668605804, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23671174049377, "training_acc": 52.0, "val_loss": 17.233434319496155, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.224858045578, "training_acc": 52.0, "val_loss": 17.23671704530716, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2310938835144, "training_acc": 52.0, "val_loss": 17.23974347114563, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2522804737091, "training_acc": 52.0, "val_loss": 17.24541038274765, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.2495265007019, "training_acc": 52.0, "val_loss": 17.251764237880707, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25443696975708, "training_acc": 52.0, "val_loss": 17.256785929203033, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26339530944824, "training_acc": 52.0, "val_loss": 17.262104153633118, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2197539806366, "training_acc": 52.0, "val_loss": 17.26600080728531, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25315880775452, "training_acc": 52.0, "val_loss": 17.264723777770996, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24543809890747, "training_acc": 52.0, "val_loss": 17.265936732292175, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24598050117493, "training_acc": 52.0, "val_loss": 17.267853021621704, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23693585395813, "training_acc": 52.0, "val_loss": 17.265021800994873, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26187443733215, "training_acc": 52.0, "val_loss": 17.262187600135803, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.27962446212769, "training_acc": 52.0, "val_loss": 17.254239320755005, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24149250984192, "training_acc": 52.0, "val_loss": 17.25083738565445, "val_acc": 56.0}
