"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.14741826057434, "training_acc": 47.0, "val_loss": 17.43502765893936, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.85039281845093, "training_acc": 47.0, "val_loss": 17.40000545978546, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.68277859687805, "training_acc": 47.0, "val_loss": 17.36522614955902, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.53347826004028, "training_acc": 47.0, "val_loss": 17.337651550769806, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.44908499717712, "training_acc": 47.0, "val_loss": 17.320257425308228, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.28082585334778, "training_acc": 52.0, "val_loss": 17.31027513742447, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21417236328125, "training_acc": 53.0, "val_loss": 17.304503917694092, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1437258720398, "training_acc": 53.0, "val_loss": 17.302745580673218, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12059926986694, "training_acc": 53.0, "val_loss": 17.30409264564514, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12638211250305, "training_acc": 53.0, "val_loss": 17.308609187602997, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13842058181763, "training_acc": 53.0, "val_loss": 17.31458604335785, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15015625953674, "training_acc": 53.0, "val_loss": 17.319300770759583, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15568995475769, "training_acc": 53.0, "val_loss": 17.321661114692688, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17568635940552, "training_acc": 53.0, "val_loss": 17.32265055179596, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16225790977478, "training_acc": 53.0, "val_loss": 17.323841154575348, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15021920204163, "training_acc": 53.0, "val_loss": 17.322424054145813, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19251942634583, "training_acc": 53.0, "val_loss": 17.320169508457184, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14696145057678, "training_acc": 53.0, "val_loss": 17.320626974105835, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14463186264038, "training_acc": 53.0, "val_loss": 17.318595945835114, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1445882320404, "training_acc": 53.0, "val_loss": 17.316287755966187, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11555123329163, "training_acc": 53.0, "val_loss": 17.315898835659027, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12948727607727, "training_acc": 53.0, "val_loss": 17.315097153186798, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14123106002808, "training_acc": 53.0, "val_loss": 17.314092814922333, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13269352912903, "training_acc": 53.0, "val_loss": 17.312060296535492, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13314151763916, "training_acc": 53.0, "val_loss": 17.310601472854614, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13158369064331, "training_acc": 53.0, "val_loss": 17.310447990894318, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14422297477722, "training_acc": 53.0, "val_loss": 17.3098087310791, "val_acc": 52.0}
