"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.41209363937378, "training_acc": 47.0, "val_loss": 17.48564839363098, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.17990207672119, "training_acc": 47.0, "val_loss": 17.42766946554184, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.82355189323425, "training_acc": 47.0, "val_loss": 17.388202250003815, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.59843564033508, "training_acc": 47.0, "val_loss": 17.358633875846863, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.55242609977722, "training_acc": 47.0, "val_loss": 17.334777116775513, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33889126777649, "training_acc": 48.0, "val_loss": 17.320214211940765, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22838282585144, "training_acc": 54.0, "val_loss": 17.310425639152527, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22207355499268, "training_acc": 53.0, "val_loss": 17.30436682701111, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1578426361084, "training_acc": 53.0, "val_loss": 17.30266511440277, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18311405181885, "training_acc": 53.0, "val_loss": 17.30474829673767, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16150379180908, "training_acc": 53.0, "val_loss": 17.309385538101196, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12977385520935, "training_acc": 53.0, "val_loss": 17.315033078193665, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1551673412323, "training_acc": 53.0, "val_loss": 17.320993542671204, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1344530582428, "training_acc": 53.0, "val_loss": 17.32581853866577, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1513512134552, "training_acc": 53.0, "val_loss": 17.329947650432587, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19831323623657, "training_acc": 53.0, "val_loss": 17.33478456735611, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1933798789978, "training_acc": 53.0, "val_loss": 17.337173223495483, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20177912712097, "training_acc": 53.0, "val_loss": 17.339566349983215, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20439577102661, "training_acc": 53.0, "val_loss": 17.33863055706024, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21051526069641, "training_acc": 53.0, "val_loss": 17.332930862903595, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18888807296753, "training_acc": 53.0, "val_loss": 17.327870428562164, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22215819358826, "training_acc": 53.0, "val_loss": 17.322485148906708, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17191195487976, "training_acc": 53.0, "val_loss": 17.320598661899567, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19430136680603, "training_acc": 53.0, "val_loss": 17.31843203306198, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15553641319275, "training_acc": 53.0, "val_loss": 17.31654703617096, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1588945388794, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13654327392578, "training_acc": 53.0, "val_loss": 17.31387823820114, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14010167121887, "training_acc": 53.0, "val_loss": 17.312106490135193, "val_acc": 52.0}
