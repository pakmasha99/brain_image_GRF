"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.18792653083801, "training_acc": 53.0, "val_loss": 17.311283946037292, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.11894297599792, "training_acc": 53.0, "val_loss": 17.317137122154236, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.092928647995, "training_acc": 53.0, "val_loss": 17.329134047031403, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15145802497864, "training_acc": 53.0, "val_loss": 17.342621088027954, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19965481758118, "training_acc": 53.0, "val_loss": 17.348726093769073, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21929478645325, "training_acc": 53.0, "val_loss": 17.355166375637054, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19913244247437, "training_acc": 53.0, "val_loss": 17.34757572412491, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2295572757721, "training_acc": 53.0, "val_loss": 17.338615655899048, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14257907867432, "training_acc": 53.0, "val_loss": 17.332004010677338, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17976880073547, "training_acc": 53.0, "val_loss": 17.324870824813843, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13995003700256, "training_acc": 53.0, "val_loss": 17.322351038455963, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16485905647278, "training_acc": 53.0, "val_loss": 17.318466305732727, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15297746658325, "training_acc": 53.0, "val_loss": 17.315302789211273, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11049032211304, "training_acc": 53.0, "val_loss": 17.313823103904724, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12669110298157, "training_acc": 53.0, "val_loss": 17.31232851743698, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13261866569519, "training_acc": 53.0, "val_loss": 17.31068044900894, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15390133857727, "training_acc": 53.0, "val_loss": 17.309793829917908, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.161785364151, "training_acc": 53.0, "val_loss": 17.309890687465668, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16657757759094, "training_acc": 53.0, "val_loss": 17.309994995594025, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18415760993958, "training_acc": 53.0, "val_loss": 17.310382425785065, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13651394844055, "training_acc": 53.0, "val_loss": 17.31117218732834, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.18766474723816, "training_acc": 53.0, "val_loss": 17.311713099479675, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14941120147705, "training_acc": 53.0, "val_loss": 17.313861846923828, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14340996742249, "training_acc": 53.0, "val_loss": 17.315341532230377, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14688968658447, "training_acc": 53.0, "val_loss": 17.31652468442917, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15689945220947, "training_acc": 53.0, "val_loss": 17.31835901737213, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15903186798096, "training_acc": 53.0, "val_loss": 17.318297922611237, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1559464931488, "training_acc": 53.0, "val_loss": 17.316649854183197, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18422651290894, "training_acc": 53.0, "val_loss": 17.31559783220291, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13539814949036, "training_acc": 53.0, "val_loss": 17.312045395374298, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14728593826294, "training_acc": 53.0, "val_loss": 17.309871315956116, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1673104763031, "training_acc": 53.0, "val_loss": 17.309510707855225, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15626978874207, "training_acc": 53.0, "val_loss": 17.30954945087433, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.18964099884033, "training_acc": 53.0, "val_loss": 17.30976104736328, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.21369981765747, "training_acc": 53.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.17041516304016, "training_acc": 53.0, "val_loss": 17.310117185115814, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22912764549255, "training_acc": 53.0, "val_loss": 17.312808334827423, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18033766746521, "training_acc": 53.0, "val_loss": 17.314058542251587, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1753625869751, "training_acc": 53.0, "val_loss": 17.31397956609726, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19594740867615, "training_acc": 53.0, "val_loss": 17.313510179519653, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16321110725403, "training_acc": 53.0, "val_loss": 17.317554354667664, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.07455945014954, "training_acc": 53.0, "val_loss": 17.322181165218353, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.17148900032043, "training_acc": 53.0, "val_loss": 17.32848733663559, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1730785369873, "training_acc": 53.0, "val_loss": 17.337195575237274, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.22003173828125, "training_acc": 53.0, "val_loss": 17.34846979379654, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.19126987457275, "training_acc": 53.0, "val_loss": 17.351478338241577, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.21337389945984, "training_acc": 53.0, "val_loss": 17.34784245491028, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.20956540107727, "training_acc": 53.0, "val_loss": 17.342495918273926, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.19389319419861, "training_acc": 53.0, "val_loss": 17.335303127765656, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.17110514640808, "training_acc": 53.0, "val_loss": 17.327895760536194, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.1648759841919, "training_acc": 53.0, "val_loss": 17.321430146694183, "val_acc": 52.0}
