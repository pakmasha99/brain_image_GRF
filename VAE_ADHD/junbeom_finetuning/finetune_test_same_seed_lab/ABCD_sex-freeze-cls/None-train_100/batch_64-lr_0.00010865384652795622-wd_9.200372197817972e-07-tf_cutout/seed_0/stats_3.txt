"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2270119190216, "training_acc": 53.0, "val_loss": 17.308227717876434, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13334727287292, "training_acc": 53.0, "val_loss": 17.323854565620422, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16270852088928, "training_acc": 53.0, "val_loss": 17.331258952617645, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17106032371521, "training_acc": 53.0, "val_loss": 17.33621209859848, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.17805814743042, "training_acc": 53.0, "val_loss": 17.33940690755844, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19255828857422, "training_acc": 53.0, "val_loss": 17.333678901195526, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15922570228577, "training_acc": 53.0, "val_loss": 17.323018610477448, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19849824905396, "training_acc": 53.0, "val_loss": 17.312489449977875, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13390469551086, "training_acc": 53.0, "val_loss": 17.309775948524475, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14898228645325, "training_acc": 53.0, "val_loss": 17.307591438293457, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.194260597229, "training_acc": 53.0, "val_loss": 17.306606471538544, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13662362098694, "training_acc": 53.0, "val_loss": 17.307303845882416, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1379656791687, "training_acc": 53.0, "val_loss": 17.30830669403076, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15068411827087, "training_acc": 53.0, "val_loss": 17.311085760593414, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.2099871635437, "training_acc": 53.0, "val_loss": 17.314331233501434, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14948272705078, "training_acc": 53.0, "val_loss": 17.312172055244446, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12477159500122, "training_acc": 53.0, "val_loss": 17.31105148792267, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1952133178711, "training_acc": 53.0, "val_loss": 17.311950027942657, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13094401359558, "training_acc": 53.0, "val_loss": 17.309236526489258, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15557527542114, "training_acc": 53.0, "val_loss": 17.30709820985794, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15114617347717, "training_acc": 53.0, "val_loss": 17.306408286094666, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.18665361404419, "training_acc": 53.0, "val_loss": 17.30615347623825, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20103764533997, "training_acc": 53.0, "val_loss": 17.306742072105408, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15194654464722, "training_acc": 53.0, "val_loss": 17.306408286094666, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17871499061584, "training_acc": 53.0, "val_loss": 17.306655645370483, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.143798828125, "training_acc": 53.0, "val_loss": 17.3063725233078, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15387272834778, "training_acc": 53.0, "val_loss": 17.30644702911377, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14153742790222, "training_acc": 53.0, "val_loss": 17.306514084339142, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16708827018738, "training_acc": 53.0, "val_loss": 17.30671226978302, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14399766921997, "training_acc": 53.0, "val_loss": 17.3075869679451, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16282391548157, "training_acc": 53.0, "val_loss": 17.309173941612244, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.16750049591064, "training_acc": 53.0, "val_loss": 17.310871183872223, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.11759400367737, "training_acc": 53.0, "val_loss": 17.31426566839218, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2265076637268, "training_acc": 53.0, "val_loss": 17.31913387775421, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16555404663086, "training_acc": 53.0, "val_loss": 17.317718267440796, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16626048088074, "training_acc": 53.0, "val_loss": 17.318257689476013, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14321660995483, "training_acc": 53.0, "val_loss": 17.3165962100029, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1412615776062, "training_acc": 53.0, "val_loss": 17.314136028289795, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13734364509583, "training_acc": 53.0, "val_loss": 17.31271743774414, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.13982105255127, "training_acc": 53.0, "val_loss": 17.310497164726257, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14068555831909, "training_acc": 53.0, "val_loss": 17.309147119522095, "val_acc": 52.0}
