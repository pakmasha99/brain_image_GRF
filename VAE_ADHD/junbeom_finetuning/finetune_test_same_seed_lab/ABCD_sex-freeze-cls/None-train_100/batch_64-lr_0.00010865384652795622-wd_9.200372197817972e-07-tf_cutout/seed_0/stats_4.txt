"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34224319458008, "training_acc": 53.0, "val_loss": 17.318078875541687, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13427376747131, "training_acc": 53.0, "val_loss": 17.313016951084137, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15103483200073, "training_acc": 53.0, "val_loss": 17.307986319065094, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13715505599976, "training_acc": 53.0, "val_loss": 17.306944727897644, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.17545819282532, "training_acc": 53.0, "val_loss": 17.306916415691376, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14479565620422, "training_acc": 53.0, "val_loss": 17.307056486606598, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17851090431213, "training_acc": 53.0, "val_loss": 17.307452857494354, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18818783760071, "training_acc": 53.0, "val_loss": 17.307206988334656, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19225120544434, "training_acc": 53.0, "val_loss": 17.307046055793762, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11862444877625, "training_acc": 53.0, "val_loss": 17.3070028424263, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18143963813782, "training_acc": 53.0, "val_loss": 17.30886548757553, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15001010894775, "training_acc": 53.0, "val_loss": 17.31143146753311, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11709451675415, "training_acc": 53.0, "val_loss": 17.31334626674652, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15647435188293, "training_acc": 53.0, "val_loss": 17.314082384109497, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1652684211731, "training_acc": 53.0, "val_loss": 17.312903702259064, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11522030830383, "training_acc": 53.0, "val_loss": 17.30983257293701, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19694185256958, "training_acc": 53.0, "val_loss": 17.30794459581375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15300703048706, "training_acc": 53.0, "val_loss": 17.30787754058838, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1602463722229, "training_acc": 53.0, "val_loss": 17.30746477842331, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13201856613159, "training_acc": 53.0, "val_loss": 17.307744920253754, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15129828453064, "training_acc": 53.0, "val_loss": 17.30763167142868, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1276261806488, "training_acc": 53.0, "val_loss": 17.308005690574646, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17250776290894, "training_acc": 53.0, "val_loss": 17.308776080608368, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14549946784973, "training_acc": 53.0, "val_loss": 17.30979084968567, "val_acc": 52.0}
