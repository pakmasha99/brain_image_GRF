"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25192260742188, "training_acc": 53.0, "val_loss": 17.30966567993164, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.28952956199646, "training_acc": 53.0, "val_loss": 17.317453026771545, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12758755683899, "training_acc": 53.0, "val_loss": 17.31211245059967, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18725776672363, "training_acc": 53.0, "val_loss": 17.309264838695526, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.32412385940552, "training_acc": 53.0, "val_loss": 17.310796678066254, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17064952850342, "training_acc": 53.0, "val_loss": 17.309212684631348, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15015697479248, "training_acc": 53.0, "val_loss": 17.312072217464447, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12007713317871, "training_acc": 53.0, "val_loss": 17.318835854530334, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18050360679626, "training_acc": 53.0, "val_loss": 17.330314218997955, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20047783851624, "training_acc": 53.0, "val_loss": 17.33533889055252, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16689038276672, "training_acc": 53.0, "val_loss": 17.327137291431427, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12186789512634, "training_acc": 53.0, "val_loss": 17.316356301307678, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25284504890442, "training_acc": 53.0, "val_loss": 17.309793829917908, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1390609741211, "training_acc": 53.0, "val_loss": 17.30940192937851, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14179539680481, "training_acc": 53.0, "val_loss": 17.309150099754333, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15529608726501, "training_acc": 53.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15233182907104, "training_acc": 53.0, "val_loss": 17.3103004693985, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16653060913086, "training_acc": 53.0, "val_loss": 17.309637367725372, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18257927894592, "training_acc": 53.0, "val_loss": 17.309199273586273, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13606357574463, "training_acc": 53.0, "val_loss": 17.314347624778748, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.26553845405579, "training_acc": 53.0, "val_loss": 17.32691526412964, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16455864906311, "training_acc": 53.0, "val_loss": 17.32928454875946, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14490008354187, "training_acc": 53.0, "val_loss": 17.336465418338776, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18108034133911, "training_acc": 53.0, "val_loss": 17.33795553445816, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19533634185791, "training_acc": 53.0, "val_loss": 17.33442097902298, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19443869590759, "training_acc": 53.0, "val_loss": 17.322276532649994, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14250659942627, "training_acc": 53.0, "val_loss": 17.315122485160828, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1286392211914, "training_acc": 53.0, "val_loss": 17.31187403202057, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16952466964722, "training_acc": 53.0, "val_loss": 17.309825122356415, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15229511260986, "training_acc": 53.0, "val_loss": 17.30974167585373, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1406877040863, "training_acc": 53.0, "val_loss": 17.31109619140625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13627743721008, "training_acc": 53.0, "val_loss": 17.312411963939667, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12401270866394, "training_acc": 53.0, "val_loss": 17.312052845954895, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14703345298767, "training_acc": 53.0, "val_loss": 17.31196939945221, "val_acc": 52.0}
