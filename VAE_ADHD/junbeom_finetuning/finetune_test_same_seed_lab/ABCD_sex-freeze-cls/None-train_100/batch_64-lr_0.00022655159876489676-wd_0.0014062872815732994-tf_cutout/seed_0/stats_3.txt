"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.38579678535461, "training_acc": 53.0, "val_loss": 17.31756627559662, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.19498801231384, "training_acc": 53.0, "val_loss": 17.312797904014587, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20010614395142, "training_acc": 53.0, "val_loss": 17.30833202600479, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15287470817566, "training_acc": 53.0, "val_loss": 17.308399081230164, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18623423576355, "training_acc": 53.0, "val_loss": 17.308302223682404, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20235180854797, "training_acc": 53.0, "val_loss": 17.309613525867462, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15854597091675, "training_acc": 53.0, "val_loss": 17.31141060590744, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16842198371887, "training_acc": 53.0, "val_loss": 17.317426204681396, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14956998825073, "training_acc": 53.0, "val_loss": 17.31843203306198, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1256251335144, "training_acc": 53.0, "val_loss": 17.31419563293457, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11868977546692, "training_acc": 53.0, "val_loss": 17.311345040798187, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17081189155579, "training_acc": 53.0, "val_loss": 17.309115827083588, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17019605636597, "training_acc": 53.0, "val_loss": 17.308834195137024, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14546251296997, "training_acc": 53.0, "val_loss": 17.3115536570549, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17013335227966, "training_acc": 53.0, "val_loss": 17.319464683532715, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14114689826965, "training_acc": 53.0, "val_loss": 17.32458472251892, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15890598297119, "training_acc": 53.0, "val_loss": 17.326150834560394, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2259111404419, "training_acc": 53.0, "val_loss": 17.31896996498108, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2333767414093, "training_acc": 53.0, "val_loss": 17.31896549463272, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10506415367126, "training_acc": 53.0, "val_loss": 17.329375445842743, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13218379020691, "training_acc": 53.0, "val_loss": 17.341041564941406, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1895523071289, "training_acc": 53.0, "val_loss": 17.350883781909943, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20157670974731, "training_acc": 53.0, "val_loss": 17.35284775495529, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21203207969666, "training_acc": 53.0, "val_loss": 17.347250878810883, "val_acc": 52.0}
