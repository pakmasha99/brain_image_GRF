"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.60428166389465, "training_acc": 47.0, "val_loss": 17.490556836128235, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.95332336425781, "training_acc": 47.0, "val_loss": 17.320893704891205, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1715772151947, "training_acc": 53.0, "val_loss": 17.327937483787537, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.05571365356445, "training_acc": 53.0, "val_loss": 17.410846054553986, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.49497103691101, "training_acc": 53.0, "val_loss": 17.492252588272095, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.69784140586853, "training_acc": 53.0, "val_loss": 17.48984307050705, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.6148579120636, "training_acc": 53.0, "val_loss": 17.436841130256653, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.42766308784485, "training_acc": 53.0, "val_loss": 17.363958060741425, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.36081218719482, "training_acc": 53.0, "val_loss": 17.319664359092712, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1621584892273, "training_acc": 53.0, "val_loss": 17.30746030807495, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.10525560379028, "training_acc": 53.0, "val_loss": 17.30719953775406, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.2960467338562, "training_acc": 53.0, "val_loss": 17.311440408229828, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.28035116195679, "training_acc": 53.0, "val_loss": 17.30920821428299, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19634914398193, "training_acc": 53.0, "val_loss": 17.308835685253143, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23515772819519, "training_acc": 53.0, "val_loss": 17.306961119174957, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18570756912231, "training_acc": 53.0, "val_loss": 17.30661690235138, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20342564582825, "training_acc": 53.0, "val_loss": 17.306619882583618, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12897849082947, "training_acc": 53.0, "val_loss": 17.308658361434937, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29735207557678, "training_acc": 53.0, "val_loss": 17.31601059436798, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15273785591125, "training_acc": 53.0, "val_loss": 17.31647402048111, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14373350143433, "training_acc": 53.0, "val_loss": 17.321640253067017, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16591286659241, "training_acc": 53.0, "val_loss": 17.324455082416534, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16662240028381, "training_acc": 53.0, "val_loss": 17.327535152435303, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14164781570435, "training_acc": 53.0, "val_loss": 17.33509749174118, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16586923599243, "training_acc": 53.0, "val_loss": 17.339184880256653, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19981288909912, "training_acc": 53.0, "val_loss": 17.34185516834259, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18490672111511, "training_acc": 53.0, "val_loss": 17.335452139377594, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15865445137024, "training_acc": 53.0, "val_loss": 17.326219379901886, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14815521240234, "training_acc": 53.0, "val_loss": 17.318961024284363, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15091252326965, "training_acc": 53.0, "val_loss": 17.315560579299927, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1222288608551, "training_acc": 53.0, "val_loss": 17.313671112060547, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13743376731873, "training_acc": 53.0, "val_loss": 17.311854660511017, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13291025161743, "training_acc": 53.0, "val_loss": 17.311429977416992, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12312436103821, "training_acc": 53.0, "val_loss": 17.311054468154907, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12667489051819, "training_acc": 53.0, "val_loss": 17.31073707342148, "val_acc": 52.0}
