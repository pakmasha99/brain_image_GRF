"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23992395401001, "training_acc": 52.0, "val_loss": 17.24088191986084, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23609328269958, "training_acc": 52.0, "val_loss": 17.221495509147644, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2546534538269, "training_acc": 52.0, "val_loss": 17.219646275043488, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26376724243164, "training_acc": 52.0, "val_loss": 17.229515314102173, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24037861824036, "training_acc": 52.0, "val_loss": 17.245477437973022, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22604250907898, "training_acc": 52.0, "val_loss": 17.251262068748474, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25979948043823, "training_acc": 52.0, "val_loss": 17.263251543045044, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25895428657532, "training_acc": 52.0, "val_loss": 17.26842075586319, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27198910713196, "training_acc": 52.0, "val_loss": 17.262694239616394, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25667023658752, "training_acc": 52.0, "val_loss": 17.265702784061432, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23356366157532, "training_acc": 52.0, "val_loss": 17.26681888103485, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2640061378479, "training_acc": 52.0, "val_loss": 17.263421416282654, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23399209976196, "training_acc": 52.0, "val_loss": 17.25921332836151, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23928618431091, "training_acc": 52.0, "val_loss": 17.25786030292511, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24769353866577, "training_acc": 52.0, "val_loss": 17.251238226890564, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25111699104309, "training_acc": 52.0, "val_loss": 17.24177896976471, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2515025138855, "training_acc": 52.0, "val_loss": 17.228353023529053, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23338389396667, "training_acc": 52.0, "val_loss": 17.219553887844086, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24154782295227, "training_acc": 52.0, "val_loss": 17.21283346414566, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25853776931763, "training_acc": 52.0, "val_loss": 17.208166420459747, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20781350135803, "training_acc": 52.0, "val_loss": 17.207643389701843, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22874402999878, "training_acc": 52.0, "val_loss": 17.20675379037857, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28970718383789, "training_acc": 52.0, "val_loss": 17.20307171344757, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26206707954407, "training_acc": 52.0, "val_loss": 17.206722497940063, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25926327705383, "training_acc": 52.0, "val_loss": 17.2143816947937, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24974846839905, "training_acc": 52.0, "val_loss": 17.225681245326996, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27868390083313, "training_acc": 52.0, "val_loss": 17.2306627035141, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22718596458435, "training_acc": 52.0, "val_loss": 17.2457218170166, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24826169013977, "training_acc": 52.0, "val_loss": 17.259423434734344, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26255011558533, "training_acc": 52.0, "val_loss": 17.264217138290405, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27666592597961, "training_acc": 52.0, "val_loss": 17.262104153633118, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28210759162903, "training_acc": 52.0, "val_loss": 17.268270254135132, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25063800811768, "training_acc": 52.0, "val_loss": 17.26245880126953, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25744199752808, "training_acc": 52.0, "val_loss": 17.257159948349, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26042914390564, "training_acc": 52.0, "val_loss": 17.248739302158356, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24014782905579, "training_acc": 52.0, "val_loss": 17.243878543376923, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23764848709106, "training_acc": 52.0, "val_loss": 17.238739132881165, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23732876777649, "training_acc": 52.0, "val_loss": 17.23271906375885, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22909951210022, "training_acc": 52.0, "val_loss": 17.222097516059875, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2514796257019, "training_acc": 52.0, "val_loss": 17.20852553844452, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23184990882874, "training_acc": 52.0, "val_loss": 17.202800512313843, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25719904899597, "training_acc": 52.0, "val_loss": 17.199283838272095, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27046990394592, "training_acc": 52.0, "val_loss": 17.197412252426147, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24130296707153, "training_acc": 52.0, "val_loss": 17.20014661550522, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25491571426392, "training_acc": 52.0, "val_loss": 17.20985174179077, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24144434928894, "training_acc": 52.0, "val_loss": 17.217515408992767, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25477147102356, "training_acc": 52.0, "val_loss": 17.22716987133026, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23916816711426, "training_acc": 52.0, "val_loss": 17.23693013191223, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22513890266418, "training_acc": 52.0, "val_loss": 17.24104881286621, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2320065498352, "training_acc": 52.0, "val_loss": 17.24458336830139, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2534761428833, "training_acc": 52.0, "val_loss": 17.250914871692657, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25173616409302, "training_acc": 52.0, "val_loss": 17.257773876190186, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25770902633667, "training_acc": 52.0, "val_loss": 17.262832820415497, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26697158813477, "training_acc": 52.0, "val_loss": 17.268000543117523, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22360253334045, "training_acc": 52.0, "val_loss": 17.271336913108826, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25880932807922, "training_acc": 52.0, "val_loss": 17.26861596107483, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24885201454163, "training_acc": 52.0, "val_loss": 17.26877987384796, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2475278377533, "training_acc": 52.0, "val_loss": 17.26979911327362, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23844647407532, "training_acc": 52.0, "val_loss": 17.265529930591583, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26136016845703, "training_acc": 52.0, "val_loss": 17.261454463005066, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28167867660522, "training_acc": 52.0, "val_loss": 17.25189983844757, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24008107185364, "training_acc": 52.0, "val_loss": 17.247740924358368, "val_acc": 56.0}
