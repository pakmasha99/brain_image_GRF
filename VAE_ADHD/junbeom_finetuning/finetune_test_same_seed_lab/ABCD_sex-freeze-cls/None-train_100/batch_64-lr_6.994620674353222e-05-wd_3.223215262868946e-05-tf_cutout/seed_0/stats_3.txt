"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3496561050415, "training_acc": 53.0, "val_loss": 17.310069501399994, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17832350730896, "training_acc": 53.0, "val_loss": 17.310209572315216, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15306806564331, "training_acc": 53.0, "val_loss": 17.310629785060883, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18478798866272, "training_acc": 53.0, "val_loss": 17.310184240341187, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1565010547638, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18648529052734, "training_acc": 53.0, "val_loss": 17.309226095676422, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1446578502655, "training_acc": 53.0, "val_loss": 17.309556901454926, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1439197063446, "training_acc": 53.0, "val_loss": 17.310340702533722, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12845993041992, "training_acc": 53.0, "val_loss": 17.311538755893707, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13469290733337, "training_acc": 53.0, "val_loss": 17.312641441822052, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15007138252258, "training_acc": 53.0, "val_loss": 17.313018441200256, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10948514938354, "training_acc": 53.0, "val_loss": 17.31516271829605, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13187456130981, "training_acc": 53.0, "val_loss": 17.318598926067352, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17369771003723, "training_acc": 53.0, "val_loss": 17.32122451066971, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14598035812378, "training_acc": 53.0, "val_loss": 17.320430278778076, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13359045982361, "training_acc": 53.0, "val_loss": 17.31846034526825, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13018012046814, "training_acc": 53.0, "val_loss": 17.317920923233032, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1175696849823, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11347532272339, "training_acc": 53.0, "val_loss": 17.317935824394226, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387536048889, "training_acc": 53.0, "val_loss": 17.318496108055115, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14728379249573, "training_acc": 53.0, "val_loss": 17.31804609298706, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12122368812561, "training_acc": 53.0, "val_loss": 17.31552481651306, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14265513420105, "training_acc": 53.0, "val_loss": 17.313987016677856, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11603283882141, "training_acc": 53.0, "val_loss": 17.31291562318802, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1060516834259, "training_acc": 53.0, "val_loss": 17.311684787273407, "val_acc": 52.0}
