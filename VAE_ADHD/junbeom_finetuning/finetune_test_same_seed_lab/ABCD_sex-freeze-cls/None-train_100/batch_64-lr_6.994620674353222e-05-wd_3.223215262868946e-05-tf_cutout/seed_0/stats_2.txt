"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31164121627808, "training_acc": 53.0, "val_loss": 17.310510575771332, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.19849371910095, "training_acc": 53.0, "val_loss": 17.30886846780777, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16546821594238, "training_acc": 53.0, "val_loss": 17.308135330677032, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14071321487427, "training_acc": 53.0, "val_loss": 17.309878766536713, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15393042564392, "training_acc": 53.0, "val_loss": 17.314712703227997, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14835977554321, "training_acc": 53.0, "val_loss": 17.319373786449432, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13963747024536, "training_acc": 53.0, "val_loss": 17.32301414012909, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1822521686554, "training_acc": 53.0, "val_loss": 17.32618659734726, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15616607666016, "training_acc": 53.0, "val_loss": 17.326299846172333, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17890906333923, "training_acc": 53.0, "val_loss": 17.32289046049118, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17265629768372, "training_acc": 53.0, "val_loss": 17.31855571269989, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16133546829224, "training_acc": 53.0, "val_loss": 17.316491901874542, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1513364315033, "training_acc": 53.0, "val_loss": 17.314007878303528, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12933039665222, "training_acc": 53.0, "val_loss": 17.312155663967133, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16764640808105, "training_acc": 53.0, "val_loss": 17.31095016002655, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12185192108154, "training_acc": 53.0, "val_loss": 17.309823632240295, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16839241981506, "training_acc": 53.0, "val_loss": 17.30990707874298, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15844678878784, "training_acc": 53.0, "val_loss": 17.30981022119522, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17958855628967, "training_acc": 53.0, "val_loss": 17.309892177581787, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13961410522461, "training_acc": 53.0, "val_loss": 17.310568690299988, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16482734680176, "training_acc": 53.0, "val_loss": 17.310939729213715, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16116666793823, "training_acc": 53.0, "val_loss": 17.31092780828476, "val_acc": 52.0}
