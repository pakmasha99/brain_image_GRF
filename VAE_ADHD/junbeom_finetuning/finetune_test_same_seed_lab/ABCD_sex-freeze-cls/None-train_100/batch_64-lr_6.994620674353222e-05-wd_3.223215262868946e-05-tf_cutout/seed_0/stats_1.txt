"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.39573860168457, "training_acc": 47.0, "val_loss": 17.47545152902603, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.14048719406128, "training_acc": 47.0, "val_loss": 17.41296797990799, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.7557327747345, "training_acc": 47.0, "val_loss": 17.372603714466095, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51789903640747, "training_acc": 47.0, "val_loss": 17.3441082239151, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.48547625541687, "training_acc": 47.0, "val_loss": 17.32262223958969, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.27097773551941, "training_acc": 50.0, "val_loss": 17.311181128025055, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1720039844513, "training_acc": 53.0, "val_loss": 17.304834723472595, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17965245246887, "training_acc": 53.0, "val_loss": 17.302659153938293, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13063216209412, "training_acc": 53.0, "val_loss": 17.304755747318268, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17111134529114, "training_acc": 53.0, "val_loss": 17.3104926943779, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16326594352722, "training_acc": 53.0, "val_loss": 17.317746579647064, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14353203773499, "training_acc": 53.0, "val_loss": 17.324699461460114, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1744818687439, "training_acc": 53.0, "val_loss": 17.330867052078247, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15945720672607, "training_acc": 53.0, "val_loss": 17.334672808647156, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17904090881348, "training_acc": 53.0, "val_loss": 17.33728051185608, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21555709838867, "training_acc": 53.0, "val_loss": 17.340655624866486, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21267366409302, "training_acc": 53.0, "val_loss": 17.341001331806183, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20853519439697, "training_acc": 53.0, "val_loss": 17.34156310558319, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20344710350037, "training_acc": 53.0, "val_loss": 17.338618636131287, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21112966537476, "training_acc": 53.0, "val_loss": 17.330825328826904, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1816942691803, "training_acc": 53.0, "val_loss": 17.32441335916519, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22527742385864, "training_acc": 53.0, "val_loss": 17.318305373191833, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16363430023193, "training_acc": 53.0, "val_loss": 17.316222190856934, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18673634529114, "training_acc": 53.0, "val_loss": 17.314115166664124, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1496467590332, "training_acc": 53.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15448451042175, "training_acc": 53.0, "val_loss": 17.312179505825043, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1312804222107, "training_acc": 53.0, "val_loss": 17.31056571006775, "val_acc": 52.0}
