"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23255920410156, "training_acc": 53.0, "val_loss": 17.314153909683228, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2191150188446, "training_acc": 53.0, "val_loss": 17.314040660858154, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2261917591095, "training_acc": 53.0, "val_loss": 17.313194274902344, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19009590148926, "training_acc": 53.0, "val_loss": 17.312201857566833, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2073221206665, "training_acc": 53.0, "val_loss": 17.3112690448761, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21126437187195, "training_acc": 53.0, "val_loss": 17.31070727109909, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19486451148987, "training_acc": 53.0, "val_loss": 17.309944331645966, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19108724594116, "training_acc": 53.0, "val_loss": 17.309293150901794, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18190908432007, "training_acc": 53.0, "val_loss": 17.308636009693146, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16287875175476, "training_acc": 53.0, "val_loss": 17.308060824871063, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17335081100464, "training_acc": 53.0, "val_loss": 17.30760484933853, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15961360931396, "training_acc": 53.0, "val_loss": 17.307330667972565, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18324327468872, "training_acc": 53.0, "val_loss": 17.307138442993164, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16423869132996, "training_acc": 53.0, "val_loss": 17.307043075561523, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14953303337097, "training_acc": 53.0, "val_loss": 17.306964099407196, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16295647621155, "training_acc": 53.0, "val_loss": 17.306914925575256, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13225674629211, "training_acc": 53.0, "val_loss": 17.30690747499466, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14735126495361, "training_acc": 53.0, "val_loss": 17.30692833662033, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14743208885193, "training_acc": 53.0, "val_loss": 17.30700582265854, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15566563606262, "training_acc": 53.0, "val_loss": 17.30709969997406, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13056540489197, "training_acc": 53.0, "val_loss": 17.30716824531555, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13460302352905, "training_acc": 53.0, "val_loss": 17.307230830192566, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15484642982483, "training_acc": 53.0, "val_loss": 17.307330667972565, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13968300819397, "training_acc": 53.0, "val_loss": 17.307420074939728, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1156005859375, "training_acc": 53.0, "val_loss": 17.307528853416443, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13337874412537, "training_acc": 53.0, "val_loss": 17.30765849351883, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14437103271484, "training_acc": 53.0, "val_loss": 17.30784922838211, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14058995246887, "training_acc": 53.0, "val_loss": 17.30802357196808, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12512111663818, "training_acc": 53.0, "val_loss": 17.308153212070465, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13791418075562, "training_acc": 53.0, "val_loss": 17.30840653181076, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1350691318512, "training_acc": 53.0, "val_loss": 17.30867326259613, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14352822303772, "training_acc": 53.0, "val_loss": 17.3089861869812, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13838195800781, "training_acc": 53.0, "val_loss": 17.30925291776657, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14619517326355, "training_acc": 53.0, "val_loss": 17.30940341949463, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1266610622406, "training_acc": 53.0, "val_loss": 17.309342324733734, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14115762710571, "training_acc": 53.0, "val_loss": 17.309272289276123, "val_acc": 52.0}
