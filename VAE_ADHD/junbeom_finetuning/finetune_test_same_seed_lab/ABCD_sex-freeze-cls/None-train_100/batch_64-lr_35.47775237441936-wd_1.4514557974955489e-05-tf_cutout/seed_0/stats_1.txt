"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 227718.37530517578, "training_acc": 53.0, "val_loss": 59101.837158203125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 304520.220703125, "training_acc": 49.0, "val_loss": 124096.56982421875, "val_acc": 48.0}
{"epoch": 2, "training_loss": 448063.8935546875, "training_acc": 47.0, "val_loss": 7739.222717285156, "val_acc": 48.0}
{"epoch": 3, "training_loss": 120371.3642578125, "training_acc": 55.0, "val_loss": 139665.80810546875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 568363.408203125, "training_acc": 53.0, "val_loss": 135734.7412109375, "val_acc": 52.0}
{"epoch": 5, "training_loss": 469006.9248046875, "training_acc": 53.0, "val_loss": 31086.807250976562, "val_acc": 52.0}
{"epoch": 6, "training_loss": 192496.40234375, "training_acc": 41.0, "val_loss": 94847.77221679688, "val_acc": 48.0}
{"epoch": 7, "training_loss": 399645.916015625, "training_acc": 47.0, "val_loss": 83307.64770507812, "val_acc": 48.0}
{"epoch": 8, "training_loss": 272744.5390625, "training_acc": 47.0, "val_loss": 19761.41815185547, "val_acc": 52.0}
{"epoch": 9, "training_loss": 126410.6513671875, "training_acc": 53.0, "val_loss": 60561.62109375, "val_acc": 52.0}
{"epoch": 10, "training_loss": 220157.474609375, "training_acc": 53.0, "val_loss": 18771.588134765625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 64424.71484375, "training_acc": 63.0, "val_loss": 53490.8203125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 217953.9150390625, "training_acc": 47.0, "val_loss": 31802.774047851562, "val_acc": 48.0}
{"epoch": 13, "training_loss": 96301.81164550781, "training_acc": 49.0, "val_loss": 25369.483947753906, "val_acc": 52.0}
{"epoch": 14, "training_loss": 93931.11889648438, "training_acc": 53.0, "val_loss": 228.75244617462158, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1770.4974517822266, "training_acc": 49.0, "val_loss": 17735.206604003906, "val_acc": 48.0}
{"epoch": 16, "training_loss": 65128.280517578125, "training_acc": 47.0, "val_loss": 12867.843627929688, "val_acc": 52.0}
{"epoch": 17, "training_loss": 54673.604736328125, "training_acc": 53.0, "val_loss": 3627.4673461914062, "val_acc": 52.0}
{"epoch": 18, "training_loss": 52828.84228515625, "training_acc": 49.0, "val_loss": 34402.20947265625, "val_acc": 48.0}
{"epoch": 19, "training_loss": 116370.34765625, "training_acc": 47.0, "val_loss": 15834.635925292969, "val_acc": 52.0}
{"epoch": 20, "training_loss": 89009.58837890625, "training_acc": 53.0, "val_loss": 23401.287841796875, "val_acc": 52.0}
{"epoch": 21, "training_loss": 54641.97118520737, "training_acc": 53.0, "val_loss": 42006.66809082031, "val_acc": 48.0}
{"epoch": 22, "training_loss": 202269.1396484375, "training_acc": 47.0, "val_loss": 52264.92919921875, "val_acc": 48.0}
{"epoch": 23, "training_loss": 177540.927734375, "training_acc": 47.0, "val_loss": 21197.000122070312, "val_acc": 52.0}
{"epoch": 24, "training_loss": 108372.009765625, "training_acc": 53.0, "val_loss": 41030.511474609375, "val_acc": 52.0}
{"epoch": 25, "training_loss": 140246.58325195312, "training_acc": 53.0, "val_loss": 8846.50650024414, "val_acc": 48.0}
{"epoch": 26, "training_loss": 51534.81787109375, "training_acc": 47.0, "val_loss": 3758.975601196289, "val_acc": 48.0}
{"epoch": 27, "training_loss": 39890.969482421875, "training_acc": 55.0, "val_loss": 39227.252197265625, "val_acc": 52.0}
{"epoch": 28, "training_loss": 145270.07080078125, "training_acc": 53.0, "val_loss": 10646.102905273438, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69552.48095703125, "training_acc": 51.0, "val_loss": 45044.53125, "val_acc": 48.0}
{"epoch": 30, "training_loss": 173645.953125, "training_acc": 47.0, "val_loss": 10522.380828857422, "val_acc": 48.0}
{"epoch": 31, "training_loss": 74312.498046875, "training_acc": 49.0, "val_loss": 54135.357666015625, "val_acc": 52.0}
{"epoch": 32, "training_loss": 212716.5537109375, "training_acc": 53.0, "val_loss": 39943.40515136719, "val_acc": 52.0}
{"epoch": 33, "training_loss": 120820.76684570312, "training_acc": 53.0, "val_loss": 38855.706787109375, "val_acc": 48.0}
