"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 335345.2912864685, "training_acc": 53.0, "val_loss": 68218.80493164062, "val_acc": 52.0}
{"epoch": 1, "training_loss": 247912.7529296875, "training_acc": 57.0, "val_loss": 124039.8193359375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 473628.58984375, "training_acc": 47.0, "val_loss": 37722.10998535156, "val_acc": 48.0}
{"epoch": 3, "training_loss": 164016.81298828125, "training_acc": 51.0, "val_loss": 92588.31176757812, "val_acc": 52.0}
{"epoch": 4, "training_loss": 368021.697265625, "training_acc": 53.0, "val_loss": 73659.82055664062, "val_acc": 52.0}
{"epoch": 5, "training_loss": 217795.42822265625, "training_acc": 53.0, "val_loss": 40430.92956542969, "val_acc": 48.0}
{"epoch": 6, "training_loss": 211745.9423828125, "training_acc": 47.0, "val_loss": 72168.45703125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 253833.9619140625, "training_acc": 47.0, "val_loss": 5347.976303100586, "val_acc": 52.0}
{"epoch": 8, "training_loss": 51824.876953125, "training_acc": 53.0, "val_loss": 22015.200805664062, "val_acc": 52.0}
{"epoch": 9, "training_loss": 55004.84939575195, "training_acc": 53.0, "val_loss": 378.56223583221436, "val_acc": 48.0}
{"epoch": 10, "training_loss": 20458.052673339844, "training_acc": 59.0, "val_loss": 23455.35430908203, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70678.58264160156, "training_acc": 53.0, "val_loss": 29426.922607421875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 129459.67041015625, "training_acc": 47.0, "val_loss": 20378.794860839844, "val_acc": 48.0}
{"epoch": 13, "training_loss": 95038.39819335938, "training_acc": 39.0, "val_loss": 27509.811401367188, "val_acc": 52.0}
{"epoch": 14, "training_loss": 93333.08325195312, "training_acc": 53.0, "val_loss": 11039.056396484375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 57624.02294921875, "training_acc": 47.0, "val_loss": 216.1008596420288, "val_acc": 52.0}
{"epoch": 16, "training_loss": 6442.6875, "training_acc": 47.0, "val_loss": 15489.743041992188, "val_acc": 52.0}
{"epoch": 17, "training_loss": 59557.38232421875, "training_acc": 53.0, "val_loss": 4058.413314819336, "val_acc": 48.0}
{"epoch": 18, "training_loss": 12670.97329711914, "training_acc": 47.0, "val_loss": 22229.47540283203, "val_acc": 52.0}
{"epoch": 19, "training_loss": 94987.64892578125, "training_acc": 53.0, "val_loss": 12126.117706298828, "val_acc": 52.0}
{"epoch": 20, "training_loss": 44072.210205078125, "training_acc": 61.0, "val_loss": 29325.933837890625, "val_acc": 48.0}
{"epoch": 21, "training_loss": 103737.01220703125, "training_acc": 47.0, "val_loss": 11626.888275146484, "val_acc": 52.0}
{"epoch": 22, "training_loss": 57964.2744140625, "training_acc": 53.0, "val_loss": 10743.464660644531, "val_acc": 52.0}
{"epoch": 23, "training_loss": 45332.682373046875, "training_acc": 55.0, "val_loss": 20853.790283203125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 60347.747131347656, "training_acc": 47.0, "val_loss": 29476.486206054688, "val_acc": 52.0}
{"epoch": 25, "training_loss": 130272.06201171875, "training_acc": 53.0, "val_loss": 36640.20080566406, "val_acc": 52.0}
{"epoch": 26, "training_loss": 114849.55114746094, "training_acc": 53.0, "val_loss": 24278.985595703125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 119081.25732421875, "training_acc": 47.0, "val_loss": 29152.392578125, "val_acc": 48.0}
{"epoch": 28, "training_loss": 79550.88491821289, "training_acc": 47.0, "val_loss": 7055.207824707031, "val_acc": 52.0}
{"epoch": 29, "training_loss": 21387.30157470703, "training_acc": 55.0, "val_loss": 4558.258819580078, "val_acc": 52.0}
{"epoch": 30, "training_loss": 25967.193115234375, "training_acc": 45.0, "val_loss": 4567.778396606445, "val_acc": 52.0}
{"epoch": 31, "training_loss": 13208.332015991211, "training_acc": 53.0, "val_loss": 11599.626922607422, "val_acc": 52.0}
{"epoch": 32, "training_loss": 37467.511962890625, "training_acc": 53.0, "val_loss": 17867.697143554688, "val_acc": 48.0}
{"epoch": 33, "training_loss": 77067.48510742188, "training_acc": 47.0, "val_loss": 1645.1576232910156, "val_acc": 52.0}
{"epoch": 34, "training_loss": 7960.323547363281, "training_acc": 53.0, "val_loss": 14824.203491210938, "val_acc": 48.0}
