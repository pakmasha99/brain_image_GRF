"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 334362.61822509766, "training_acc": 45.0, "val_loss": 60462.48779296875, "val_acc": 48.0}
{"epoch": 1, "training_loss": 227046.8095703125, "training_acc": 59.0, "val_loss": 160555.908203125, "val_acc": 52.0}
{"epoch": 2, "training_loss": 621012.087890625, "training_acc": 53.0, "val_loss": 118084.72900390625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 375890.501953125, "training_acc": 53.0, "val_loss": 35468.49060058594, "val_acc": 48.0}
{"epoch": 4, "training_loss": 190581.8408203125, "training_acc": 47.0, "val_loss": 68772.76611328125, "val_acc": 48.0}
{"epoch": 5, "training_loss": 226229.73388671875, "training_acc": 47.0, "val_loss": 23519.873046875, "val_acc": 52.0}
{"epoch": 6, "training_loss": 131687.32421875, "training_acc": 53.0, "val_loss": 47792.498779296875, "val_acc": 52.0}
{"epoch": 7, "training_loss": 156041.1572265625, "training_acc": 53.0, "val_loss": 22782.925415039062, "val_acc": 48.0}
{"epoch": 8, "training_loss": 117003.181640625, "training_acc": 47.0, "val_loss": 22445.44219970703, "val_acc": 48.0}
{"epoch": 9, "training_loss": 75978.22192382812, "training_acc": 51.0, "val_loss": 26120.135498046875, "val_acc": 52.0}
{"epoch": 10, "training_loss": 88980.17041015625, "training_acc": 53.0, "val_loss": 12992.820739746094, "val_acc": 48.0}
{"epoch": 11, "training_loss": 53256.832275390625, "training_acc": 47.0, "val_loss": 7058.873748779297, "val_acc": 52.0}
{"epoch": 12, "training_loss": 24190.16796875, "training_acc": 53.0, "val_loss": 17212.216186523438, "val_acc": 48.0}
{"epoch": 13, "training_loss": 66728.515625, "training_acc": 47.0, "val_loss": 10961.29379272461, "val_acc": 52.0}
{"epoch": 14, "training_loss": 48276.657470703125, "training_acc": 53.0, "val_loss": 509.2939853668213, "val_acc": 48.0}
{"epoch": 15, "training_loss": 6906.647155761719, "training_acc": 55.0, "val_loss": 6001.71012878418, "val_acc": 48.0}
{"epoch": 16, "training_loss": 25805.605834960938, "training_acc": 47.0, "val_loss": 2396.1917877197266, "val_acc": 48.0}
{"epoch": 17, "training_loss": 21166.483154296875, "training_acc": 49.0, "val_loss": 3795.077896118164, "val_acc": 52.0}
{"epoch": 18, "training_loss": 44513.882568359375, "training_acc": 49.0, "val_loss": 23460.659790039062, "val_acc": 48.0}
{"epoch": 19, "training_loss": 65627.23901367188, "training_acc": 47.0, "val_loss": 35230.33142089844, "val_acc": 52.0}
{"epoch": 20, "training_loss": 164303.76953125, "training_acc": 53.0, "val_loss": 46839.068603515625, "val_acc": 52.0}
{"epoch": 21, "training_loss": 150984.84521484375, "training_acc": 53.0, "val_loss": 14181.674194335938, "val_acc": 48.0}
{"epoch": 22, "training_loss": 85043.43701171875, "training_acc": 47.0, "val_loss": 22458.59375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 70632.96252441406, "training_acc": 47.0, "val_loss": 12864.920043945312, "val_acc": 52.0}
{"epoch": 24, "training_loss": 33371.02639770508, "training_acc": 53.0, "val_loss": 29859.283447265625, "val_acc": 48.0}
{"epoch": 25, "training_loss": 130806.74853515625, "training_acc": 47.0, "val_loss": 20409.88311767578, "val_acc": 48.0}
{"epoch": 26, "training_loss": 76539.04736328125, "training_acc": 47.0, "val_loss": 25756.854248046875, "val_acc": 52.0}
{"epoch": 27, "training_loss": 90516.53833007812, "training_acc": 53.0, "val_loss": 5925.234603881836, "val_acc": 48.0}
{"epoch": 28, "training_loss": 24657.439453125, "training_acc": 47.0, "val_loss": 12374.250793457031, "val_acc": 52.0}
{"epoch": 29, "training_loss": 47077.39416503906, "training_acc": 53.0, "val_loss": 7566.880035400391, "val_acc": 48.0}
{"epoch": 30, "training_loss": 26566.15106201172, "training_acc": 47.0, "val_loss": 18384.11102294922, "val_acc": 52.0}
{"epoch": 31, "training_loss": 77686.13208007812, "training_acc": 53.0, "val_loss": 7114.360046386719, "val_acc": 52.0}
{"epoch": 32, "training_loss": 52005.758544921875, "training_acc": 53.0, "val_loss": 34649.6826171875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 122670.99267578125, "training_acc": 47.0, "val_loss": 9752.006530761719, "val_acc": 52.0}
