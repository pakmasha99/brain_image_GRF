"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.08759379386902, "training_acc": 53.0, "val_loss": 17.648881673812866, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.40601587295532, "training_acc": 53.0, "val_loss": 17.9666668176651, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.24111533164978, "training_acc": 47.0, "val_loss": 17.86830723285675, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.56382417678833, "training_acc": 47.0, "val_loss": 17.3373281955719, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.87886309623718, "training_acc": 55.0, "val_loss": 17.496411502361298, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.66039204597473, "training_acc": 53.0, "val_loss": 17.80734956264496, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.63700890541077, "training_acc": 53.0, "val_loss": 17.517440021038055, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.8436644077301, "training_acc": 53.0, "val_loss": 17.317691445350647, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14724969863892, "training_acc": 55.0, "val_loss": 17.40296334028244, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.8921434879303, "training_acc": 47.0, "val_loss": 17.3822283744812, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.57019233703613, "training_acc": 47.0, "val_loss": 17.3389732837677, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25376391410828, "training_acc": 49.0, "val_loss": 17.337127029895782, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.47142815589905, "training_acc": 53.0, "val_loss": 17.42575764656067, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.40797877311707, "training_acc": 53.0, "val_loss": 17.339490354061127, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31198596954346, "training_acc": 53.0, "val_loss": 17.31230914592743, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.2576494216919, "training_acc": 53.0, "val_loss": 17.312276363372803, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15065574645996, "training_acc": 53.0, "val_loss": 17.340993881225586, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23837733268738, "training_acc": 53.0, "val_loss": 17.353181540966034, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15740513801575, "training_acc": 53.0, "val_loss": 17.314545810222626, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.55340886116028, "training_acc": 45.0, "val_loss": 17.332780361175537, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.3384096622467, "training_acc": 53.0, "val_loss": 17.31383055448532, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11722874641418, "training_acc": 53.0, "val_loss": 17.340271174907684, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26847887039185, "training_acc": 53.0, "val_loss": 17.348159849643707, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20088601112366, "training_acc": 53.0, "val_loss": 17.367728054523468, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.3133385181427, "training_acc": 53.0, "val_loss": 17.326131463050842, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13947224617004, "training_acc": 53.0, "val_loss": 17.317478358745575, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.53083205223083, "training_acc": 53.0, "val_loss": 17.312656342983246, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.32379102706909, "training_acc": 49.0, "val_loss": 17.365379631519318, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.51095962524414, "training_acc": 47.0, "val_loss": 17.31760948896408, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.55233502388, "training_acc": 53.0, "val_loss": 17.382296919822693, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.22760725021362, "training_acc": 53.0, "val_loss": 17.31477677822113, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.29606580734253, "training_acc": 53.0, "val_loss": 17.35418140888214, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.41168284416199, "training_acc": 47.0, "val_loss": 17.32286661863327, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.22038698196411, "training_acc": 53.0, "val_loss": 17.33786314725876, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.79667592048645, "training_acc": 53.0, "val_loss": 17.517127096652985, "val_acc": 52.0}
