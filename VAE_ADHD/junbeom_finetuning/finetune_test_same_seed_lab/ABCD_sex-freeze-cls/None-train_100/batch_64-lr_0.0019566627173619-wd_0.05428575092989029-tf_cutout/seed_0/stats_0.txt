"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.52669429779053, "training_acc": 50.0, "val_loss": 17.61300265789032, "val_acc": 56.0}
{"epoch": 1, "training_loss": 70.72994589805603, "training_acc": 48.0, "val_loss": 17.732977867126465, "val_acc": 56.0}
{"epoch": 2, "training_loss": 73.47133755683899, "training_acc": 52.0, "val_loss": 17.208023369312286, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.4889063835144, "training_acc": 52.0, "val_loss": 17.833663523197174, "val_acc": 56.0}
{"epoch": 4, "training_loss": 71.1510260105133, "training_acc": 48.0, "val_loss": 18.55694204568863, "val_acc": 56.0}
{"epoch": 5, "training_loss": 72.29056191444397, "training_acc": 48.0, "val_loss": 17.5578311085701, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.5230872631073, "training_acc": 50.0, "val_loss": 17.147435247898102, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.61583065986633, "training_acc": 52.0, "val_loss": 17.224547266960144, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.74231004714966, "training_acc": 52.0, "val_loss": 17.154502868652344, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.48149466514587, "training_acc": 52.0, "val_loss": 17.43568778038025, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.76652932167053, "training_acc": 48.0, "val_loss": 17.895986139774323, "val_acc": 56.0}
{"epoch": 11, "training_loss": 70.50489139556885, "training_acc": 48.0, "val_loss": 17.557328939437866, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.80370020866394, "training_acc": 46.0, "val_loss": 17.186273634433746, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.22476363182068, "training_acc": 52.0, "val_loss": 17.148441076278687, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.62586688995361, "training_acc": 52.0, "val_loss": 17.14790314435959, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.67274594306946, "training_acc": 52.0, "val_loss": 17.19055324792862, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2383942604065, "training_acc": 52.0, "val_loss": 17.269010841846466, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.28071570396423, "training_acc": 49.0, "val_loss": 17.341439425945282, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.32490062713623, "training_acc": 50.0, "val_loss": 17.27685183286667, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.3039562702179, "training_acc": 52.0, "val_loss": 17.19406545162201, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22720074653625, "training_acc": 52.0, "val_loss": 17.18539148569107, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.3155255317688, "training_acc": 52.0, "val_loss": 17.18563437461853, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.51834392547607, "training_acc": 52.0, "val_loss": 17.182548344135284, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.209233045578, "training_acc": 52.0, "val_loss": 17.325668036937714, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.29538059234619, "training_acc": 53.0, "val_loss": 17.479079961776733, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.64065670967102, "training_acc": 48.0, "val_loss": 17.389114201068878, "val_acc": 56.0}
