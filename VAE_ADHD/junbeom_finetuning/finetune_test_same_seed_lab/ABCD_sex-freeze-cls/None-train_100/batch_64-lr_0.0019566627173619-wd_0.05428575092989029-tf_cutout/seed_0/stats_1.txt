"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.05133008956909, "training_acc": 45.0, "val_loss": 17.59655326604843, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.85556292533875, "training_acc": 47.0, "val_loss": 17.69738793373108, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.01481413841248, "training_acc": 47.0, "val_loss": 17.459262907505035, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.98625588417053, "training_acc": 55.0, "val_loss": 17.593921720981598, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.15747332572937, "training_acc": 53.0, "val_loss": 18.2313472032547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.31755566596985, "training_acc": 53.0, "val_loss": 17.740298807621002, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.05492734909058, "training_acc": 53.0, "val_loss": 17.33180582523346, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.08090662956238, "training_acc": 47.0, "val_loss": 17.721182107925415, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.6098861694336, "training_acc": 47.0, "val_loss": 17.726294696331024, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.57850432395935, "training_acc": 47.0, "val_loss": 17.31090098619461, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.27189755439758, "training_acc": 53.0, "val_loss": 17.654991149902344, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.49247097969055, "training_acc": 53.0, "val_loss": 17.849601805210114, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.58596515655518, "training_acc": 53.0, "val_loss": 17.472629249095917, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.41133046150208, "training_acc": 53.0, "val_loss": 17.327754199504852, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.90779280662537, "training_acc": 53.0, "val_loss": 17.36224740743637, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.59386014938354, "training_acc": 47.0, "val_loss": 17.523738741874695, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.34755182266235, "training_acc": 47.0, "val_loss": 17.403285205364227, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.66602540016174, "training_acc": 47.0, "val_loss": 17.332763969898224, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12755703926086, "training_acc": 53.0, "val_loss": 17.504321038722992, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.70562148094177, "training_acc": 53.0, "val_loss": 17.504100501537323, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.8397376537323, "training_acc": 53.0, "val_loss": 17.35256165266037, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14944577217102, "training_acc": 53.0, "val_loss": 17.308789491653442, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13154768943787, "training_acc": 53.0, "val_loss": 17.327086627483368, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.8868055343628, "training_acc": 41.0, "val_loss": 17.32679158449173, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12423491477966, "training_acc": 57.0, "val_loss": 17.35684424638748, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1374843120575, "training_acc": 53.0, "val_loss": 17.50006675720215, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.74032926559448, "training_acc": 53.0, "val_loss": 17.471210658550262, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.35709762573242, "training_acc": 53.0, "val_loss": 17.31293499469757, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.85493421554565, "training_acc": 53.0, "val_loss": 17.419052124023438, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.90371918678284, "training_acc": 47.0, "val_loss": 17.639142274856567, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.66695523262024, "training_acc": 47.0, "val_loss": 17.399825155735016, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.49549651145935, "training_acc": 49.0, "val_loss": 17.35607534646988, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.34634137153625, "training_acc": 53.0, "val_loss": 17.58260726928711, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.90853643417358, "training_acc": 53.0, "val_loss": 17.477519810199738, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.69450116157532, "training_acc": 53.0, "val_loss": 17.316365242004395, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.2327926158905, "training_acc": 53.0, "val_loss": 17.320524156093597, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.38343548774719, "training_acc": 47.0, "val_loss": 17.313897609710693, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.72072553634644, "training_acc": 53.0, "val_loss": 17.330601811408997, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.18499541282654, "training_acc": 53.0, "val_loss": 17.316174507141113, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.45114254951477, "training_acc": 53.0, "val_loss": 17.311854660511017, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.55255818367004, "training_acc": 53.0, "val_loss": 17.311710119247437, "val_acc": 52.0}
