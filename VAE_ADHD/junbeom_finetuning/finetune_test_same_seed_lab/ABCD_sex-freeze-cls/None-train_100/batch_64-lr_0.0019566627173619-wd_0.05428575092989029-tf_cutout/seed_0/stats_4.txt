"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.33918452262878, "training_acc": 53.0, "val_loss": 17.665548622608185, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.03105974197388, "training_acc": 55.0, "val_loss": 18.100029230117798, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.61996579170227, "training_acc": 47.0, "val_loss": 18.066154420375824, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.191739320755, "training_acc": 47.0, "val_loss": 17.323078215122223, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.99925398826599, "training_acc": 53.0, "val_loss": 18.19853186607361, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.40223693847656, "training_acc": 53.0, "val_loss": 17.99618750810623, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.8866970539093, "training_acc": 53.0, "val_loss": 17.324958741664886, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.25315070152283, "training_acc": 51.0, "val_loss": 17.555715143680573, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.72794032096863, "training_acc": 47.0, "val_loss": 17.629016935825348, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.40933609008789, "training_acc": 47.0, "val_loss": 17.32034981250763, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07811856269836, "training_acc": 53.0, "val_loss": 17.50337779521942, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.21566033363342, "training_acc": 53.0, "val_loss": 17.71308332681656, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.28845691680908, "training_acc": 53.0, "val_loss": 17.395448684692383, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.38587284088135, "training_acc": 53.0, "val_loss": 17.32468605041504, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38142728805542, "training_acc": 51.0, "val_loss": 17.38845407962799, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.81483936309814, "training_acc": 47.0, "val_loss": 17.326335608959198, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.79493713378906, "training_acc": 53.0, "val_loss": 17.39439368247986, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.53211998939514, "training_acc": 53.0, "val_loss": 17.42485612630844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.32354974746704, "training_acc": 53.0, "val_loss": 17.31606274843216, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.96670961380005, "training_acc": 53.0, "val_loss": 17.361384630203247, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.75363850593567, "training_acc": 47.0, "val_loss": 17.471258342266083, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.87579321861267, "training_acc": 47.0, "val_loss": 17.325299978256226, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.5506980419159, "training_acc": 53.0, "val_loss": 17.38303154706955, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.273104429245, "training_acc": 53.0, "val_loss": 17.34757125377655, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.32056021690369, "training_acc": 53.0, "val_loss": 17.310595512390137, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1716377735138, "training_acc": 53.0, "val_loss": 17.309361696243286, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.59516525268555, "training_acc": 51.0, "val_loss": 17.30934828519821, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.03435897827148, "training_acc": 53.0, "val_loss": 17.375217378139496, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.63669157028198, "training_acc": 53.0, "val_loss": 17.491763830184937, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.55465078353882, "training_acc": 53.0, "val_loss": 17.34551638364792, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.99999284744263, "training_acc": 53.0, "val_loss": 17.34648048877716, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.35054445266724, "training_acc": 47.0, "val_loss": 17.456817626953125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.24187421798706, "training_acc": 47.0, "val_loss": 17.43110418319702, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.7986900806427, "training_acc": 47.0, "val_loss": 17.361415922641754, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.43997263908386, "training_acc": 47.0, "val_loss": 17.315372824668884, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.87375688552856, "training_acc": 53.0, "val_loss": 17.565149068832397, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.92094826698303, "training_acc": 53.0, "val_loss": 17.462831735610962, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.50452923774719, "training_acc": 53.0, "val_loss": 17.331989109516144, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.50107598304749, "training_acc": 53.0, "val_loss": 17.362089455127716, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.57761073112488, "training_acc": 47.0, "val_loss": 17.355498671531677, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.36846709251404, "training_acc": 49.0, "val_loss": 17.31414943933487, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.7775354385376, "training_acc": 53.0, "val_loss": 17.391201853752136, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.28185296058655, "training_acc": 53.0, "val_loss": 17.32203960418701, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.56872177124023, "training_acc": 53.0, "val_loss": 17.329269647598267, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.3332142829895, "training_acc": 47.0, "val_loss": 17.31235235929489, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17348217964172, "training_acc": 53.0, "val_loss": 17.315146327018738, "val_acc": 52.0}
