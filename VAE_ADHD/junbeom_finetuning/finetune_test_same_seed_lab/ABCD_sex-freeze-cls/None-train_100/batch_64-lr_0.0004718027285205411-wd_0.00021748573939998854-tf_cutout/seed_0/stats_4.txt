"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.52470898628235, "training_acc": 47.0, "val_loss": 17.32880175113678, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.99205017089844, "training_acc": 53.0, "val_loss": 17.477986216545105, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.08756303787231, "training_acc": 53.0, "val_loss": 17.719054222106934, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.34507417678833, "training_acc": 53.0, "val_loss": 17.56318211555481, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.79604029655457, "training_acc": 53.0, "val_loss": 17.370374500751495, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.49612832069397, "training_acc": 53.0, "val_loss": 17.310933768749237, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1345329284668, "training_acc": 53.0, "val_loss": 17.32487678527832, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26987051963806, "training_acc": 51.0, "val_loss": 17.33938902616501, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.34511137008667, "training_acc": 51.0, "val_loss": 17.327886819839478, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29178667068481, "training_acc": 54.0, "val_loss": 17.315055429935455, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15320992469788, "training_acc": 53.0, "val_loss": 17.31182485818863, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10163807868958, "training_acc": 53.0, "val_loss": 17.338384687900543, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2804217338562, "training_acc": 53.0, "val_loss": 17.379209399223328, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.34845209121704, "training_acc": 53.0, "val_loss": 17.370213568210602, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38173413276672, "training_acc": 53.0, "val_loss": 17.368340492248535, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24141025543213, "training_acc": 53.0, "val_loss": 17.327556014060974, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.0538284778595, "training_acc": 53.0, "val_loss": 17.312335968017578, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.08694052696228, "training_acc": 53.0, "val_loss": 17.31574982404709, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.49056696891785, "training_acc": 42.0, "val_loss": 17.331969738006592, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.31481647491455, "training_acc": 55.0, "val_loss": 17.318999767303467, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.48502683639526, "training_acc": 53.0, "val_loss": 17.311643064022064, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21605682373047, "training_acc": 53.0, "val_loss": 17.3148974776268, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12456893920898, "training_acc": 53.0, "val_loss": 17.332223057746887, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12356901168823, "training_acc": 53.0, "val_loss": 17.348037660121918, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17575454711914, "training_acc": 53.0, "val_loss": 17.359694838523865, "val_acc": 52.0}
