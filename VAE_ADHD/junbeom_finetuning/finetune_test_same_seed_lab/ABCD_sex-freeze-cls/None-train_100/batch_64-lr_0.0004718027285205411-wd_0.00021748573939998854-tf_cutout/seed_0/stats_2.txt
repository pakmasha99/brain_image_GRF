"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.43575692176819, "training_acc": 49.0, "val_loss": 17.31131076812744, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.57593965530396, "training_acc": 53.0, "val_loss": 17.33662188053131, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20512747764587, "training_acc": 53.0, "val_loss": 17.320159077644348, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2166337966919, "training_acc": 53.0, "val_loss": 17.310932278633118, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.51323819160461, "training_acc": 43.0, "val_loss": 17.318134009838104, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23439908027649, "training_acc": 53.0, "val_loss": 17.309637367725372, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1328797340393, "training_acc": 53.0, "val_loss": 17.3226460814476, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1226863861084, "training_acc": 53.0, "val_loss": 17.344750463962555, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.25724720954895, "training_acc": 53.0, "val_loss": 17.365626990795135, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.28367495536804, "training_acc": 53.0, "val_loss": 17.351317405700684, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15093994140625, "training_acc": 53.0, "val_loss": 17.31678992509842, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.0646984577179, "training_acc": 53.0, "val_loss": 17.311236262321472, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.45978569984436, "training_acc": 48.0, "val_loss": 17.331594228744507, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.33701539039612, "training_acc": 47.0, "val_loss": 17.32047200202942, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.31133770942688, "training_acc": 53.0, "val_loss": 17.311474680900574, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20331692695618, "training_acc": 53.0, "val_loss": 17.309291660785675, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12609457969666, "training_acc": 53.0, "val_loss": 17.310206592082977, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11714911460876, "training_acc": 53.0, "val_loss": 17.317138612270355, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16654658317566, "training_acc": 53.0, "val_loss": 17.32805222272873, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1473400592804, "training_acc": 53.0, "val_loss": 17.36038476228714, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.42948746681213, "training_acc": 53.0, "val_loss": 17.380714416503906, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.40561270713806, "training_acc": 53.0, "val_loss": 17.343589663505554, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16640090942383, "training_acc": 53.0, "val_loss": 17.32836812734604, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1546380519867, "training_acc": 53.0, "val_loss": 17.315377295017242, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13046503067017, "training_acc": 53.0, "val_loss": 17.309999465942383, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1959879398346, "training_acc": 53.0, "val_loss": 17.31162667274475, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.19554114341736, "training_acc": 53.0, "val_loss": 17.31307804584503, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20656371116638, "training_acc": 53.0, "val_loss": 17.309729754924774, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.1667411327362, "training_acc": 53.0, "val_loss": 17.30993688106537, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11175107955933, "training_acc": 53.0, "val_loss": 17.31954962015152, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17253112792969, "training_acc": 53.0, "val_loss": 17.34253019094467, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.21953129768372, "training_acc": 53.0, "val_loss": 17.34827756881714, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1803023815155, "training_acc": 53.0, "val_loss": 17.3282653093338, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15728116035461, "training_acc": 53.0, "val_loss": 17.31359511613846, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.20677828788757, "training_acc": 53.0, "val_loss": 17.309395968914032, "val_acc": 52.0}
