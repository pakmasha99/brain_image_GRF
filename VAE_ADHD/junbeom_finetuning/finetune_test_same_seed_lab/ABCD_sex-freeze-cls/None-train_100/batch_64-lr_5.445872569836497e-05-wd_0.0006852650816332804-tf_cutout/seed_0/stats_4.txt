"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.89203214645386, "training_acc": 47.0, "val_loss": 17.393481731414795, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.6891872882843, "training_acc": 47.0, "val_loss": 17.362618446350098, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.52636313438416, "training_acc": 47.0, "val_loss": 17.341667413711548, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3990330696106, "training_acc": 47.0, "val_loss": 17.327405512332916, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33117818832397, "training_acc": 52.0, "val_loss": 17.316125333309174, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20517539978027, "training_acc": 53.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16165590286255, "training_acc": 53.0, "val_loss": 17.306233942508698, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12808799743652, "training_acc": 53.0, "val_loss": 17.306701838970184, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18291711807251, "training_acc": 53.0, "val_loss": 17.310063540935516, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14163303375244, "training_acc": 53.0, "val_loss": 17.313992977142334, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11994242668152, "training_acc": 53.0, "val_loss": 17.317016422748566, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13196897506714, "training_acc": 53.0, "val_loss": 17.31935441493988, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16381669044495, "training_acc": 53.0, "val_loss": 17.321990430355072, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12952160835266, "training_acc": 53.0, "val_loss": 17.32245236635208, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19012832641602, "training_acc": 53.0, "val_loss": 17.32184886932373, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17309355735779, "training_acc": 53.0, "val_loss": 17.323413491249084, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12165975570679, "training_acc": 53.0, "val_loss": 17.32252836227417, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17027759552002, "training_acc": 53.0, "val_loss": 17.32107847929001, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15836691856384, "training_acc": 53.0, "val_loss": 17.321227490901947, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1229829788208, "training_acc": 53.0, "val_loss": 17.320798337459564, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14462971687317, "training_acc": 53.0, "val_loss": 17.319998145103455, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14182901382446, "training_acc": 53.0, "val_loss": 17.31799989938736, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15452647209167, "training_acc": 53.0, "val_loss": 17.316444218158722, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12018895149231, "training_acc": 53.0, "val_loss": 17.316150665283203, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13140869140625, "training_acc": 53.0, "val_loss": 17.315272986888885, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16898679733276, "training_acc": 53.0, "val_loss": 17.313989996910095, "val_acc": 52.0}
