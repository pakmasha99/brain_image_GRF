"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31724500656128, "training_acc": 53.0, "val_loss": 17.309898138046265, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22346472740173, "training_acc": 53.0, "val_loss": 17.308562994003296, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20454573631287, "training_acc": 53.0, "val_loss": 17.306552827358246, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15270590782166, "training_acc": 53.0, "val_loss": 17.305831611156464, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.17993664741516, "training_acc": 53.0, "val_loss": 17.305757105350494, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18696856498718, "training_acc": 53.0, "val_loss": 17.306511104106903, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15461444854736, "training_acc": 53.0, "val_loss": 17.30763018131256, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11332154273987, "training_acc": 53.0, "val_loss": 17.30806678533554, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10670471191406, "training_acc": 53.0, "val_loss": 17.309917509555817, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15015983581543, "training_acc": 53.0, "val_loss": 17.312902212142944, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18970823287964, "training_acc": 53.0, "val_loss": 17.315322160720825, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14013600349426, "training_acc": 53.0, "val_loss": 17.315107583999634, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15109634399414, "training_acc": 53.0, "val_loss": 17.31392592191696, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14481401443481, "training_acc": 53.0, "val_loss": 17.31378883123398, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14820599555969, "training_acc": 53.0, "val_loss": 17.3141747713089, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12072730064392, "training_acc": 53.0, "val_loss": 17.31424331665039, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16049122810364, "training_acc": 53.0, "val_loss": 17.3148512840271, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14581727981567, "training_acc": 53.0, "val_loss": 17.314620316028595, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15377712249756, "training_acc": 53.0, "val_loss": 17.31261909008026, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15347480773926, "training_acc": 53.0, "val_loss": 17.311321198940277, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14001798629761, "training_acc": 53.0, "val_loss": 17.310340702533722, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16438364982605, "training_acc": 53.0, "val_loss": 17.30913519859314, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13719701766968, "training_acc": 53.0, "val_loss": 17.308469116687775, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14252877235413, "training_acc": 53.0, "val_loss": 17.308375239372253, "val_acc": 52.0}
