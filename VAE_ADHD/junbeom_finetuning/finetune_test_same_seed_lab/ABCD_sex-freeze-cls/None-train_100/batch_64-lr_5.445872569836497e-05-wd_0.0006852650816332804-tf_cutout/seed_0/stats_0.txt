"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23678255081177, "training_acc": 52.0, "val_loss": 17.237912118434906, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2319724559784, "training_acc": 52.0, "val_loss": 17.2239750623703, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25002241134644, "training_acc": 52.0, "val_loss": 17.22259819507599, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.2639012336731, "training_acc": 52.0, "val_loss": 17.23000556230545, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2397096157074, "training_acc": 52.0, "val_loss": 17.24209189414978, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22402787208557, "training_acc": 52.0, "val_loss": 17.246517539024353, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25701642036438, "training_acc": 52.0, "val_loss": 17.256084084510803, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25338673591614, "training_acc": 52.0, "val_loss": 17.26096272468567, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26032662391663, "training_acc": 52.0, "val_loss": 17.257651686668396, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2535412311554, "training_acc": 52.0, "val_loss": 17.261089384555817, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2306969165802, "training_acc": 52.0, "val_loss": 17.26318746805191, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26120972633362, "training_acc": 52.0, "val_loss": 17.261798679828644, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23118090629578, "training_acc": 52.0, "val_loss": 17.259591817855835, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23972082138062, "training_acc": 52.0, "val_loss": 17.259375751018524, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24940538406372, "training_acc": 52.0, "val_loss": 17.25471466779709, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25404167175293, "training_acc": 52.0, "val_loss": 17.24739670753479, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25216221809387, "training_acc": 52.0, "val_loss": 17.236335575580597, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23396968841553, "training_acc": 52.0, "val_loss": 17.228449881076813, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24025344848633, "training_acc": 52.0, "val_loss": 17.221781611442566, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25519895553589, "training_acc": 52.0, "val_loss": 17.216429114341736, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20261335372925, "training_acc": 52.0, "val_loss": 17.214277386665344, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2223014831543, "training_acc": 52.0, "val_loss": 17.211779952049255, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28539204597473, "training_acc": 52.0, "val_loss": 17.207127809524536, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26073908805847, "training_acc": 52.0, "val_loss": 17.208491265773773, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26073288917542, "training_acc": 52.0, "val_loss": 17.213088274002075, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24747943878174, "training_acc": 52.0, "val_loss": 17.220626771450043, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27761173248291, "training_acc": 52.0, "val_loss": 17.223769426345825, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22827935218811, "training_acc": 52.0, "val_loss": 17.23482459783554, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.2404363155365, "training_acc": 52.0, "val_loss": 17.245322465896606, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25497174263, "training_acc": 52.0, "val_loss": 17.249925434589386, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26134014129639, "training_acc": 52.0, "val_loss": 17.249873280525208, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27146124839783, "training_acc": 52.0, "val_loss": 17.256160080432892, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24268841743469, "training_acc": 52.0, "val_loss": 17.253756523132324, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25432324409485, "training_acc": 52.0, "val_loss": 17.25170612335205, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25494289398193, "training_acc": 52.0, "val_loss": 17.247042059898376, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24011707305908, "training_acc": 52.0, "val_loss": 17.24478155374527, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23928380012512, "training_acc": 52.0, "val_loss": 17.241916060447693, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23923945426941, "training_acc": 52.0, "val_loss": 17.237897217273712, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23268222808838, "training_acc": 52.0, "val_loss": 17.229655385017395, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24397730827332, "training_acc": 52.0, "val_loss": 17.218348383903503, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22732090950012, "training_acc": 52.0, "val_loss": 17.21302717924118, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.2505145072937, "training_acc": 52.0, "val_loss": 17.209193110466003, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26141667366028, "training_acc": 52.0, "val_loss": 17.206475138664246, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23418259620667, "training_acc": 52.0, "val_loss": 17.207486927509308, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.24707674980164, "training_acc": 52.0, "val_loss": 17.214052379131317, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24214696884155, "training_acc": 52.0, "val_loss": 17.218786478042603, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25586652755737, "training_acc": 52.0, "val_loss": 17.225085198879242, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23464584350586, "training_acc": 52.0, "val_loss": 17.23160147666931, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.224942445755, "training_acc": 52.0, "val_loss": 17.234142124652863, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2309000492096, "training_acc": 52.0, "val_loss": 17.236614227294922, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2519760131836, "training_acc": 52.0, "val_loss": 17.24153161048889, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.2484085559845, "training_acc": 52.0, "val_loss": 17.24720001220703, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25253582000732, "training_acc": 52.0, "val_loss": 17.25188046693802, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26098370552063, "training_acc": 52.0, "val_loss": 17.256972193717957, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21658635139465, "training_acc": 52.0, "val_loss": 17.26098656654358, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.24861145019531, "training_acc": 52.0, "val_loss": 17.26062297821045, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24233293533325, "training_acc": 52.0, "val_loss": 17.26246178150177, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24392747879028, "training_acc": 52.0, "val_loss": 17.26493090391159, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23484706878662, "training_acc": 52.0, "val_loss": 17.263232171535492, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26137924194336, "training_acc": 52.0, "val_loss": 17.261452972888947, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.277019739151, "training_acc": 52.0, "val_loss": 17.255017161369324, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24217343330383, "training_acc": 52.0, "val_loss": 17.252425849437714, "val_acc": 56.0}
