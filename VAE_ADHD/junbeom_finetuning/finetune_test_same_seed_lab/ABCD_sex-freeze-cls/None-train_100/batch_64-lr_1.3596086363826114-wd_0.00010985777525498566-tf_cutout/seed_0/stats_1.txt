"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 14614.96314239502, "training_acc": 47.0, "val_loss": 2029.8559188842773, "val_acc": 48.0}
{"epoch": 1, "training_loss": 10952.959411621094, "training_acc": 49.0, "val_loss": 6270.36018371582, "val_acc": 52.0}
{"epoch": 2, "training_loss": 24653.01171875, "training_acc": 53.0, "val_loss": 5023.936080932617, "val_acc": 52.0}
{"epoch": 3, "training_loss": 16647.355377197266, "training_acc": 53.0, "val_loss": 547.4636554718018, "val_acc": 48.0}
{"epoch": 4, "training_loss": 4495.496826171875, "training_acc": 47.0, "val_loss": 1928.3763885498047, "val_acc": 48.0}
{"epoch": 5, "training_loss": 5931.540512084961, "training_acc": 47.0, "val_loss": 1393.4877395629883, "val_acc": 52.0}
{"epoch": 6, "training_loss": 7288.828765869141, "training_acc": 53.0, "val_loss": 2279.8871994018555, "val_acc": 52.0}
{"epoch": 7, "training_loss": 7484.0537109375, "training_acc": 53.0, "val_loss": 370.22979259490967, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2772.400924682617, "training_acc": 47.0, "val_loss": 686.8250370025635, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3151.7200775146484, "training_acc": 41.0, "val_loss": 882.2824478149414, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2738.847480773926, "training_acc": 53.0, "val_loss": 879.6749114990234, "val_acc": 48.0}
{"epoch": 11, "training_loss": 4211.420120239258, "training_acc": 47.0, "val_loss": 520.1672077178955, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2330.5985107421875, "training_acc": 53.0, "val_loss": 1415.9740447998047, "val_acc": 52.0}
{"epoch": 13, "training_loss": 5272.230407714844, "training_acc": 53.0, "val_loss": 403.1941890716553, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2552.7631225585938, "training_acc": 51.0, "val_loss": 1566.8136596679688, "val_acc": 48.0}
{"epoch": 15, "training_loss": 5850.822723388672, "training_acc": 47.0, "val_loss": 53.20001244544983, "val_acc": 48.0}
{"epoch": 16, "training_loss": 2280.585891723633, "training_acc": 51.0, "val_loss": 2469.002914428711, "val_acc": 52.0}
{"epoch": 17, "training_loss": 9823.113189697266, "training_acc": 53.0, "val_loss": 2001.704216003418, "val_acc": 52.0}
{"epoch": 18, "training_loss": 6310.829231262207, "training_acc": 53.0, "val_loss": 994.8921203613281, "val_acc": 48.0}
{"epoch": 19, "training_loss": 5706.247619628906, "training_acc": 47.0, "val_loss": 1783.4503173828125, "val_acc": 48.0}
{"epoch": 20, "training_loss": 5906.020050048828, "training_acc": 47.0, "val_loss": 730.3310394287109, "val_acc": 52.0}
{"epoch": 21, "training_loss": 3606.7348022460938, "training_acc": 53.0, "val_loss": 1402.0818710327148, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4565.216201782227, "training_acc": 53.0, "val_loss": 485.6692314147949, "val_acc": 48.0}
{"epoch": 23, "training_loss": 2310.1433715820312, "training_acc": 47.0, "val_loss": 479.7804355621338, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1932.8803939819336, "training_acc": 51.0, "val_loss": 797.1840858459473, "val_acc": 52.0}
{"epoch": 25, "training_loss": 2521.3969955444336, "training_acc": 53.0, "val_loss": 717.0737743377686, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3635.4093170166016, "training_acc": 47.0, "val_loss": 370.80254554748535, "val_acc": 48.0}
{"epoch": 27, "training_loss": 2371.7279510498047, "training_acc": 49.0, "val_loss": 1532.5589179992676, "val_acc": 52.0}
{"epoch": 28, "training_loss": 5755.645156860352, "training_acc": 53.0, "val_loss": 563.2675647735596, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3125.467971801758, "training_acc": 45.0, "val_loss": 1396.3438034057617, "val_acc": 48.0}
{"epoch": 30, "training_loss": 5142.531387329102, "training_acc": 47.0, "val_loss": 114.25527334213257, "val_acc": 52.0}
{"epoch": 31, "training_loss": 788.7580413818359, "training_acc": 53.0, "val_loss": 89.60037231445312, "val_acc": 48.0}
{"epoch": 32, "training_loss": 792.922306060791, "training_acc": 43.0, "val_loss": 86.82458400726318, "val_acc": 48.0}
{"epoch": 33, "training_loss": 420.3560161590576, "training_acc": 57.0, "val_loss": 46.11135125160217, "val_acc": 48.0}
{"epoch": 34, "training_loss": 602.1666450500488, "training_acc": 53.0, "val_loss": 201.6805648803711, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1387.3634414672852, "training_acc": 53.0, "val_loss": 677.7503967285156, "val_acc": 48.0}
{"epoch": 36, "training_loss": 1902.6482591629028, "training_acc": 49.0, "val_loss": 80.85320591926575, "val_acc": 52.0}
{"epoch": 37, "training_loss": 1405.4506072998047, "training_acc": 45.0, "val_loss": 486.3508701324463, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1825.829086303711, "training_acc": 51.0, "val_loss": 631.3703060150146, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1797.9050636291504, "training_acc": 53.0, "val_loss": 1027.0569801330566, "val_acc": 48.0}
{"epoch": 40, "training_loss": 4361.267059326172, "training_acc": 47.0, "val_loss": 685.8126163482666, "val_acc": 48.0}
{"epoch": 41, "training_loss": 2396.9510955810547, "training_acc": 51.0, "val_loss": 888.834285736084, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3059.261329650879, "training_acc": 53.0, "val_loss": 363.1727933883667, "val_acc": 48.0}
{"epoch": 43, "training_loss": 1670.7941665649414, "training_acc": 47.0, "val_loss": 222.07586765289307, "val_acc": 52.0}
{"epoch": 44, "training_loss": 827.8647575378418, "training_acc": 53.0, "val_loss": 570.5869674682617, "val_acc": 48.0}
{"epoch": 45, "training_loss": 2240.9940490722656, "training_acc": 47.0, "val_loss": 376.68511867523193, "val_acc": 52.0}
{"epoch": 46, "training_loss": 1640.0481262207031, "training_acc": 53.0, "val_loss": 64.15629386901855, "val_acc": 48.0}
{"epoch": 47, "training_loss": 412.49950218200684, "training_acc": 49.0, "val_loss": 297.741436958313, "val_acc": 48.0}
{"epoch": 48, "training_loss": 761.5886075496674, "training_acc": 53.0, "val_loss": 54.14828658103943, "val_acc": 48.0}
{"epoch": 49, "training_loss": 1183.0414657592773, "training_acc": 45.0, "val_loss": 548.344087600708, "val_acc": 52.0}
{"epoch": 50, "training_loss": 2217.653106689453, "training_acc": 41.0, "val_loss": 164.98870849609375, "val_acc": 48.0}
{"epoch": 51, "training_loss": 1260.8548126220703, "training_acc": 53.0, "val_loss": 859.974479675293, "val_acc": 52.0}
{"epoch": 52, "training_loss": 2712.18656539917, "training_acc": 53.0, "val_loss": 811.7879867553711, "val_acc": 48.0}
