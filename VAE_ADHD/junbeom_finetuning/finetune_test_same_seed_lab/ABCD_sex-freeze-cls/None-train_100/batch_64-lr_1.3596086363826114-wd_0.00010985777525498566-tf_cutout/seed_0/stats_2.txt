"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 11090.270965576172, "training_acc": 51.0, "val_loss": 2066.093635559082, "val_acc": 48.0}
{"epoch": 1, "training_loss": 13091.615844726562, "training_acc": 41.0, "val_loss": 5543.016052246094, "val_acc": 52.0}
{"epoch": 2, "training_loss": 21116.98370361328, "training_acc": 53.0, "val_loss": 3274.8287200927734, "val_acc": 52.0}
{"epoch": 3, "training_loss": 8824.190086364746, "training_acc": 53.0, "val_loss": 3339.6488189697266, "val_acc": 48.0}
{"epoch": 4, "training_loss": 16952.889526367188, "training_acc": 47.0, "val_loss": 5507.291793823242, "val_acc": 48.0}
{"epoch": 5, "training_loss": 21033.6240234375, "training_acc": 47.0, "val_loss": 2548.8325119018555, "val_acc": 48.0}
{"epoch": 6, "training_loss": 7896.858474731445, "training_acc": 41.0, "val_loss": 1477.5785446166992, "val_acc": 52.0}
{"epoch": 7, "training_loss": 5966.560806274414, "training_acc": 53.0, "val_loss": 1182.2619438171387, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3379.208173751831, "training_acc": 45.0, "val_loss": 209.24606323242188, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1695.9023818969727, "training_acc": 41.0, "val_loss": 450.0300884246826, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1561.9431343078613, "training_acc": 55.0, "val_loss": 410.7093334197998, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1627.3060836791992, "training_acc": 49.0, "val_loss": 384.7684860229492, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2178.0282440185547, "training_acc": 37.0, "val_loss": 191.53692722320557, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1550.0226821899414, "training_acc": 51.0, "val_loss": 1051.2718200683594, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3542.999038696289, "training_acc": 53.0, "val_loss": 466.28971099853516, "val_acc": 48.0}
{"epoch": 15, "training_loss": 2348.3162689208984, "training_acc": 47.0, "val_loss": 19.114109873771667, "val_acc": 52.0}
{"epoch": 16, "training_loss": 368.0447692871094, "training_acc": 53.0, "val_loss": 42.27723479270935, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1169.7593612670898, "training_acc": 55.0, "val_loss": 878.8264274597168, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2511.850778579712, "training_acc": 47.0, "val_loss": 1241.1896705627441, "val_acc": 52.0}
{"epoch": 19, "training_loss": 5567.044830322266, "training_acc": 53.0, "val_loss": 1626.4411926269531, "val_acc": 52.0}
{"epoch": 20, "training_loss": 5261.037658691406, "training_acc": 53.0, "val_loss": 564.6984577178955, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3069.518020629883, "training_acc": 47.0, "val_loss": 767.1840667724609, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2425.8001594543457, "training_acc": 49.0, "val_loss": 545.3794956207275, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1539.0035982131958, "training_acc": 53.0, "val_loss": 1000.6171226501465, "val_acc": 48.0}
{"epoch": 24, "training_loss": 4316.6119384765625, "training_acc": 47.0, "val_loss": 575.1140117645264, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2628.3794326782227, "training_acc": 47.0, "val_loss": 1154.5119285583496, "val_acc": 52.0}
{"epoch": 26, "training_loss": 4182.825134277344, "training_acc": 53.0, "val_loss": 21.898014843463898, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1935.202075958252, "training_acc": 51.0, "val_loss": 1662.8875732421875, "val_acc": 48.0}
{"epoch": 28, "training_loss": 6107.529937744141, "training_acc": 47.0, "val_loss": 18.772658705711365, "val_acc": 52.0}
{"epoch": 29, "training_loss": 976.2948303222656, "training_acc": 53.0, "val_loss": 818.0181503295898, "val_acc": 52.0}
{"epoch": 30, "training_loss": 2325.1911697387695, "training_acc": 53.0, "val_loss": 1031.4892768859863, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4974.903564453125, "training_acc": 47.0, "val_loss": 1053.4822463989258, "val_acc": 48.0}
{"epoch": 32, "training_loss": 2723.748046875, "training_acc": 53.0, "val_loss": 491.384220123291, "val_acc": 52.0}
{"epoch": 33, "training_loss": 1490.0746431350708, "training_acc": 53.0, "val_loss": 826.9253730773926, "val_acc": 48.0}
{"epoch": 34, "training_loss": 3376.718849182129, "training_acc": 47.0, "val_loss": 119.24523115158081, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1905.8906707763672, "training_acc": 51.0, "val_loss": 1763.2015228271484, "val_acc": 52.0}
{"epoch": 36, "training_loss": 6689.213363647461, "training_acc": 53.0, "val_loss": 808.6605072021484, "val_acc": 52.0}
{"epoch": 37, "training_loss": 3388.432662963867, "training_acc": 45.0, "val_loss": 1165.8156394958496, "val_acc": 48.0}
{"epoch": 38, "training_loss": 4211.046829223633, "training_acc": 47.0, "val_loss": 314.9793863296509, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1726.0185775756836, "training_acc": 53.0, "val_loss": 239.58876132965088, "val_acc": 52.0}
{"epoch": 40, "training_loss": 1714.9885635375977, "training_acc": 53.0, "val_loss": 1035.2178573608398, "val_acc": 48.0}
{"epoch": 41, "training_loss": 3303.7018432617188, "training_acc": 47.0, "val_loss": 844.4173812866211, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3833.891387939453, "training_acc": 53.0, "val_loss": 1158.5372924804688, "val_acc": 52.0}
{"epoch": 43, "training_loss": 3348.5773696899414, "training_acc": 53.0, "val_loss": 1054.7516822814941, "val_acc": 48.0}
{"epoch": 44, "training_loss": 4991.603744506836, "training_acc": 47.0, "val_loss": 1347.0847129821777, "val_acc": 48.0}
{"epoch": 45, "training_loss": 3857.7256088256836, "training_acc": 47.0, "val_loss": 1263.1318092346191, "val_acc": 52.0}
{"epoch": 46, "training_loss": 5846.699066162109, "training_acc": 53.0, "val_loss": 2185.64453125, "val_acc": 52.0}
{"epoch": 47, "training_loss": 7828.4991455078125, "training_acc": 53.0, "val_loss": 542.7468299865723, "val_acc": 52.0}
