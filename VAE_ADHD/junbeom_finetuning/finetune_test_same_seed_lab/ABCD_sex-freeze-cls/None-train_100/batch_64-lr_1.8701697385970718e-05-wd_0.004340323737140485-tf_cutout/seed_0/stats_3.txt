"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2637951374054, "training_acc": 53.0, "val_loss": 17.312979698181152, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21699237823486, "training_acc": 53.0, "val_loss": 17.31308400630951, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20503759384155, "training_acc": 53.0, "val_loss": 17.31259375810623, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18935322761536, "training_acc": 53.0, "val_loss": 17.31182485818863, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22467231750488, "training_acc": 53.0, "val_loss": 17.311282455921173, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18420147895813, "training_acc": 53.0, "val_loss": 17.31071025133133, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16769504547119, "training_acc": 53.0, "val_loss": 17.310252785682678, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18363499641418, "training_acc": 53.0, "val_loss": 17.30981469154358, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16700005531311, "training_acc": 53.0, "val_loss": 17.309634387493134, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16969323158264, "training_acc": 53.0, "val_loss": 17.309504747390747, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17175555229187, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13386392593384, "training_acc": 53.0, "val_loss": 17.309489846229553, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16478276252747, "training_acc": 53.0, "val_loss": 17.30951964855194, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15018963813782, "training_acc": 53.0, "val_loss": 17.309539020061493, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16604399681091, "training_acc": 53.0, "val_loss": 17.309552431106567, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18606925010681, "training_acc": 53.0, "val_loss": 17.30954498052597, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17289400100708, "training_acc": 53.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16469264030457, "training_acc": 53.0, "val_loss": 17.309603095054626, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12781929969788, "training_acc": 53.0, "val_loss": 17.309679090976715, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19841885566711, "training_acc": 53.0, "val_loss": 17.30973571538925, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1629798412323, "training_acc": 53.0, "val_loss": 17.30981469154358, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1569344997406, "training_acc": 53.0, "val_loss": 17.30991303920746, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14164805412292, "training_acc": 53.0, "val_loss": 17.31000542640686, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12673878669739, "training_acc": 53.0, "val_loss": 17.310062050819397, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16353249549866, "training_acc": 53.0, "val_loss": 17.31029897928238, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16362595558167, "training_acc": 53.0, "val_loss": 17.310675978660583, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13577675819397, "training_acc": 53.0, "val_loss": 17.311030626296997, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12443923950195, "training_acc": 53.0, "val_loss": 17.311131954193115, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15551495552063, "training_acc": 53.0, "val_loss": 17.311133444309235, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16121745109558, "training_acc": 53.0, "val_loss": 17.311297357082367, "val_acc": 52.0}
