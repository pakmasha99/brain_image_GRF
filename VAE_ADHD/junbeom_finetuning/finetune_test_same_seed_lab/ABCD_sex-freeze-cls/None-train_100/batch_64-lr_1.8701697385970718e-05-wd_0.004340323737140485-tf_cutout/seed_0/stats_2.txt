"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24122214317322, "training_acc": 53.0, "val_loss": 17.347536981105804, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18490290641785, "training_acc": 53.0, "val_loss": 17.343521118164062, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16756868362427, "training_acc": 53.0, "val_loss": 17.339041829109192, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.2012288570404, "training_acc": 53.0, "val_loss": 17.334794998168945, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.21097159385681, "training_acc": 53.0, "val_loss": 17.330966889858246, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15263414382935, "training_acc": 53.0, "val_loss": 17.328783869743347, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12813377380371, "training_acc": 53.0, "val_loss": 17.32657551765442, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15784955024719, "training_acc": 53.0, "val_loss": 17.32417792081833, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15140676498413, "training_acc": 53.0, "val_loss": 17.3219695687294, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16417622566223, "training_acc": 53.0, "val_loss": 17.320236563682556, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16152024269104, "training_acc": 53.0, "val_loss": 17.31891930103302, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10423612594604, "training_acc": 53.0, "val_loss": 17.31843501329422, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13219785690308, "training_acc": 53.0, "val_loss": 17.318126559257507, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14370274543762, "training_acc": 53.0, "val_loss": 17.31732487678528, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11817622184753, "training_acc": 53.0, "val_loss": 17.317043244838715, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12779235839844, "training_acc": 53.0, "val_loss": 17.31673628091812, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13044357299805, "training_acc": 53.0, "val_loss": 17.3164501786232, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1432158946991, "training_acc": 53.0, "val_loss": 17.315837740898132, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12239718437195, "training_acc": 53.0, "val_loss": 17.315387725830078, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13573408126831, "training_acc": 53.0, "val_loss": 17.315077781677246, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14195489883423, "training_acc": 53.0, "val_loss": 17.314669489860535, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13904666900635, "training_acc": 53.0, "val_loss": 17.31448769569397, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15287017822266, "training_acc": 53.0, "val_loss": 17.314501106739044, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11274409294128, "training_acc": 53.0, "val_loss": 17.31438785791397, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10624098777771, "training_acc": 53.0, "val_loss": 17.314065992832184, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15598034858704, "training_acc": 53.0, "val_loss": 17.313772439956665, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14098858833313, "training_acc": 53.0, "val_loss": 17.3134908080101, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11703181266785, "training_acc": 53.0, "val_loss": 17.313434183597565, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12520146369934, "training_acc": 53.0, "val_loss": 17.313319444656372, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1193413734436, "training_acc": 53.0, "val_loss": 17.313586175441742, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.093252658844, "training_acc": 53.0, "val_loss": 17.31441617012024, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.12234616279602, "training_acc": 53.0, "val_loss": 17.31521040201187, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.0978364944458, "training_acc": 53.0, "val_loss": 17.315608263015747, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.09034848213196, "training_acc": 53.0, "val_loss": 17.316211760044098, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16170978546143, "training_acc": 53.0, "val_loss": 17.316514253616333, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.12121915817261, "training_acc": 53.0, "val_loss": 17.317011952400208, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12698674201965, "training_acc": 53.0, "val_loss": 17.317570745944977, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11574387550354, "training_acc": 53.0, "val_loss": 17.318038642406464, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1419403553009, "training_acc": 53.0, "val_loss": 17.318710684776306, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14068722724915, "training_acc": 53.0, "val_loss": 17.318908870220184, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.134042263031, "training_acc": 53.0, "val_loss": 17.319059371948242, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13741612434387, "training_acc": 53.0, "val_loss": 17.319324612617493, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14215922355652, "training_acc": 53.0, "val_loss": 17.319385707378387, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.1653950214386, "training_acc": 53.0, "val_loss": 17.31971651315689, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.12854313850403, "training_acc": 53.0, "val_loss": 17.319726943969727, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1383056640625, "training_acc": 53.0, "val_loss": 17.319591343402863, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13728833198547, "training_acc": 53.0, "val_loss": 17.319494485855103, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13511204719543, "training_acc": 53.0, "val_loss": 17.319169640541077, "val_acc": 52.0}
