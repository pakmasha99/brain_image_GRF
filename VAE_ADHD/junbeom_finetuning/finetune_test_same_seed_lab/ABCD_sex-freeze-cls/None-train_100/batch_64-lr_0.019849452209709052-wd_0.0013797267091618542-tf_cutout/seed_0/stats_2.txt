"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 171.50572967529297, "training_acc": 53.0, "val_loss": 29.714903235435486, "val_acc": 52.0}
{"epoch": 1, "training_loss": 168.3139476776123, "training_acc": 51.0, "val_loss": 76.53201818466187, "val_acc": 48.0}
{"epoch": 2, "training_loss": 274.1616678237915, "training_acc": 47.0, "val_loss": 17.752942442893982, "val_acc": 52.0}
{"epoch": 3, "training_loss": 107.77562284469604, "training_acc": 47.0, "val_loss": 55.98629713058472, "val_acc": 52.0}
{"epoch": 4, "training_loss": 212.51028442382812, "training_acc": 53.0, "val_loss": 30.945470929145813, "val_acc": 52.0}
{"epoch": 5, "training_loss": 100.50206685066223, "training_acc": 53.0, "val_loss": 34.718555212020874, "val_acc": 48.0}
{"epoch": 6, "training_loss": 154.72242212295532, "training_acc": 47.0, "val_loss": 33.17747712135315, "val_acc": 48.0}
{"epoch": 7, "training_loss": 114.87736821174622, "training_acc": 47.0, "val_loss": 23.420096933841705, "val_acc": 52.0}
{"epoch": 8, "training_loss": 105.80743646621704, "training_acc": 53.0, "val_loss": 32.33758509159088, "val_acc": 52.0}
{"epoch": 9, "training_loss": 113.85855412483215, "training_acc": 53.0, "val_loss": 17.456360161304474, "val_acc": 52.0}
{"epoch": 10, "training_loss": 78.18527317047119, "training_acc": 47.0, "val_loss": 27.507930994033813, "val_acc": 48.0}
{"epoch": 11, "training_loss": 104.11671876907349, "training_acc": 47.0, "val_loss": 17.31933504343033, "val_acc": 52.0}
{"epoch": 12, "training_loss": 77.08162999153137, "training_acc": 53.0, "val_loss": 25.69715678691864, "val_acc": 52.0}
{"epoch": 13, "training_loss": 96.70419645309448, "training_acc": 53.0, "val_loss": 17.634974420070648, "val_acc": 52.0}
{"epoch": 14, "training_loss": 74.17163515090942, "training_acc": 49.0, "val_loss": 22.27741628885269, "val_acc": 48.0}
{"epoch": 15, "training_loss": 87.08891749382019, "training_acc": 47.0, "val_loss": 17.340512573719025, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.63971781730652, "training_acc": 46.0, "val_loss": 20.65267264842987, "val_acc": 52.0}
{"epoch": 17, "training_loss": 79.0974018573761, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.40629553794861, "training_acc": 59.0, "val_loss": 19.62900459766388, "val_acc": 48.0}
{"epoch": 19, "training_loss": 77.88244342803955, "training_acc": 47.0, "val_loss": 17.323753237724304, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.09472584724426, "training_acc": 53.0, "val_loss": 18.675608932971954, "val_acc": 52.0}
{"epoch": 21, "training_loss": 73.54477405548096, "training_acc": 53.0, "val_loss": 17.31647402048111, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13730335235596, "training_acc": 53.0, "val_loss": 17.58100986480713, "val_acc": 52.0}
{"epoch": 23, "training_loss": 71.35911202430725, "training_acc": 41.0, "val_loss": 17.316097021102905, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.01292014122009, "training_acc": 43.0, "val_loss": 17.375464737415314, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.08675789833069, "training_acc": 53.0, "val_loss": 17.806236445903778, "val_acc": 52.0}
{"epoch": 26, "training_loss": 71.43098425865173, "training_acc": 53.0, "val_loss": 17.346075177192688, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.56415295600891, "training_acc": 47.0, "val_loss": 18.26625019311905, "val_acc": 52.0}
{"epoch": 28, "training_loss": 72.23943638801575, "training_acc": 47.0, "val_loss": 17.575033009052277, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.27965807914734, "training_acc": 53.0, "val_loss": 18.439865112304688, "val_acc": 52.0}
{"epoch": 30, "training_loss": 72.64436936378479, "training_acc": 53.0, "val_loss": 17.35956221818924, "val_acc": 52.0}
{"epoch": 31, "training_loss": 71.76668882369995, "training_acc": 45.0, "val_loss": 17.581307888031006, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.34695553779602, "training_acc": 46.0, "val_loss": 18.23285222053528, "val_acc": 52.0}
{"epoch": 33, "training_loss": 72.23449110984802, "training_acc": 53.0, "val_loss": 18.01542639732361, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.14716506004333, "training_acc": 53.0, "val_loss": 17.79746562242508, "val_acc": 52.0}
{"epoch": 35, "training_loss": 71.75289463996887, "training_acc": 47.0, "val_loss": 17.508462071418762, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.49764680862427, "training_acc": 51.0, "val_loss": 18.16737651824951, "val_acc": 52.0}
