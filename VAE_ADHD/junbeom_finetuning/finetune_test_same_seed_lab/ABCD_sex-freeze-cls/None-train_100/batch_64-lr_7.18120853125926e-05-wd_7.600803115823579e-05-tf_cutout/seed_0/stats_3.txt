"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.35335111618042, "training_acc": 53.0, "val_loss": 17.31000244617462, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17755103111267, "training_acc": 53.0, "val_loss": 17.31015294790268, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1525046825409, "training_acc": 53.0, "val_loss": 17.31058657169342, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18434572219849, "training_acc": 53.0, "val_loss": 17.31014996767044, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15600275993347, "training_acc": 53.0, "val_loss": 17.30944812297821, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1862301826477, "training_acc": 53.0, "val_loss": 17.309238016605377, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14407444000244, "training_acc": 53.0, "val_loss": 17.309606075286865, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14340257644653, "training_acc": 53.0, "val_loss": 17.310437560081482, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12813544273376, "training_acc": 53.0, "val_loss": 17.311684787273407, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13446974754333, "training_acc": 53.0, "val_loss": 17.312805354595184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15090537071228, "training_acc": 53.0, "val_loss": 17.313160002231598, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10951495170593, "training_acc": 53.0, "val_loss": 17.315350472927094, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13208889961243, "training_acc": 53.0, "val_loss": 17.318877577781677, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17470479011536, "training_acc": 53.0, "val_loss": 17.321544885635376, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14626741409302, "training_acc": 53.0, "val_loss": 17.320647835731506, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13445663452148, "training_acc": 53.0, "val_loss": 17.318549752235413, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13051724433899, "training_acc": 53.0, "val_loss": 17.317943274974823, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11757731437683, "training_acc": 53.0, "val_loss": 17.318080365657806, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11363625526428, "training_acc": 53.0, "val_loss": 17.317882180213928, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14388179779053, "training_acc": 53.0, "val_loss": 17.31843203306198, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14749121665955, "training_acc": 53.0, "val_loss": 17.317955195903778, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12126588821411, "training_acc": 53.0, "val_loss": 17.31538027524948, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1426031589508, "training_acc": 53.0, "val_loss": 17.313823103904724, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11603689193726, "training_acc": 53.0, "val_loss": 17.312754690647125, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1062822341919, "training_acc": 53.0, "val_loss": 17.31153577566147, "val_acc": 52.0}
