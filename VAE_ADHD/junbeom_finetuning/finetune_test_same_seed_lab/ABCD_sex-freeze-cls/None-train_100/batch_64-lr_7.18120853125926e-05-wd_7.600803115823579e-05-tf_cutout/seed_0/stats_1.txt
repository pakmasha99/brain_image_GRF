"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.39204144477844, "training_acc": 47.0, "val_loss": 17.47317463159561, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.13176727294922, "training_acc": 47.0, "val_loss": 17.40976721048355, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.74096751213074, "training_acc": 47.0, "val_loss": 17.36931949853897, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.50084686279297, "training_acc": 47.0, "val_loss": 17.34118014574051, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.47184467315674, "training_acc": 47.0, "val_loss": 17.320334911346436, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.25767588615417, "training_acc": 53.0, "val_loss": 17.309647798538208, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16168928146362, "training_acc": 53.0, "val_loss": 17.304086685180664, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1724922657013, "training_acc": 53.0, "val_loss": 17.30276644229889, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12692189216614, "training_acc": 53.0, "val_loss": 17.3056498169899, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17047667503357, "training_acc": 53.0, "val_loss": 17.312105000019073, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16536712646484, "training_acc": 53.0, "val_loss": 17.31978803873062, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1478054523468, "training_acc": 53.0, "val_loss": 17.326854169368744, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17931365966797, "training_acc": 53.0, "val_loss": 17.332883179187775, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16497850418091, "training_acc": 53.0, "val_loss": 17.336301505565643, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18465113639832, "training_acc": 53.0, "val_loss": 17.338450253009796, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21833419799805, "training_acc": 53.0, "val_loss": 17.341424524784088, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2156035900116, "training_acc": 53.0, "val_loss": 17.341288924217224, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20861554145813, "training_acc": 53.0, "val_loss": 17.341457307338715, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20196223258972, "training_acc": 53.0, "val_loss": 17.33812242746353, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21004891395569, "training_acc": 53.0, "val_loss": 17.329978942871094, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17934131622314, "training_acc": 53.0, "val_loss": 17.323391139507294, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22530794143677, "training_acc": 53.0, "val_loss": 17.31724888086319, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16176319122314, "training_acc": 53.0, "val_loss": 17.315202951431274, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18515062332153, "training_acc": 53.0, "val_loss": 17.31317490339279, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14845275878906, "training_acc": 53.0, "val_loss": 17.311637103557587, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1540596485138, "training_acc": 53.0, "val_loss": 17.311444878578186, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13047814369202, "training_acc": 53.0, "val_loss": 17.30995774269104, "val_acc": 52.0}
