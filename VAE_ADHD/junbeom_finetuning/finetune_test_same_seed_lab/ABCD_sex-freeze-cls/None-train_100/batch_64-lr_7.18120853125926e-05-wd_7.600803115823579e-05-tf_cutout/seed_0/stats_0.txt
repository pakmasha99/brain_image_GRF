"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24032950401306, "training_acc": 52.0, "val_loss": 17.24122166633606, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23660683631897, "training_acc": 52.0, "val_loss": 17.221160233020782, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25523376464844, "training_acc": 52.0, "val_loss": 17.219264805316925, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.263747215271, "training_acc": 52.0, "val_loss": 17.22944974899292, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24046468734741, "training_acc": 52.0, "val_loss": 17.245902121067047, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22629475593567, "training_acc": 52.0, "val_loss": 17.251861095428467, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26017642021179, "training_acc": 52.0, "val_loss": 17.26413071155548, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25967121124268, "training_acc": 52.0, "val_loss": 17.269298434257507, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27347016334534, "training_acc": 52.0, "val_loss": 17.26324111223221, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25704145431519, "training_acc": 52.0, "val_loss": 17.266158759593964, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23384833335876, "training_acc": 52.0, "val_loss": 17.267124354839325, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2642593383789, "training_acc": 52.0, "val_loss": 17.263463139533997, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23424100875854, "training_acc": 52.0, "val_loss": 17.259010672569275, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.2391414642334, "training_acc": 52.0, "val_loss": 17.257528007030487, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24741673469543, "training_acc": 52.0, "val_loss": 17.250700294971466, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2507655620575, "training_acc": 52.0, "val_loss": 17.24103093147278, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25144529342651, "training_acc": 52.0, "val_loss": 17.227384448051453, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.2334291934967, "training_acc": 52.0, "val_loss": 17.218542098999023, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2418441772461, "training_acc": 52.0, "val_loss": 17.211879789829254, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25901746749878, "training_acc": 52.0, "val_loss": 17.207349836826324, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2085108757019, "training_acc": 52.0, "val_loss": 17.20706671476364, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22952961921692, "training_acc": 52.0, "val_loss": 17.206405103206635, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29004287719727, "training_acc": 52.0, "val_loss": 17.20285415649414, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.2620210647583, "training_acc": 52.0, "val_loss": 17.206788063049316, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25891542434692, "training_acc": 52.0, "val_loss": 17.2148197889328, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24992322921753, "training_acc": 52.0, "val_loss": 17.22656935453415, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27898716926575, "training_acc": 52.0, "val_loss": 17.231731116771698, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22719645500183, "training_acc": 52.0, "val_loss": 17.247237265110016, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24936771392822, "training_acc": 52.0, "val_loss": 17.261256277561188, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26369428634644, "training_acc": 52.0, "val_loss": 17.26595312356949, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27891325950623, "training_acc": 52.0, "val_loss": 17.263461649417877, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28326725959778, "training_acc": 52.0, "val_loss": 17.269501090049744, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25157570838928, "training_acc": 52.0, "val_loss": 17.263182997703552, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25763297080994, "training_acc": 52.0, "val_loss": 17.25742667913437, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26094126701355, "training_acc": 52.0, "val_loss": 17.248527705669403, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23998665809631, "training_acc": 52.0, "val_loss": 17.243359982967377, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23734021186829, "training_acc": 52.0, "val_loss": 17.237983644008636, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23711848258972, "training_acc": 52.0, "val_loss": 17.231787741184235, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22882556915283, "training_acc": 52.0, "val_loss": 17.2209694981575, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2524802684784, "training_acc": 52.0, "val_loss": 17.20723807811737, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23271441459656, "training_acc": 52.0, "val_loss": 17.201553285121918, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25830435752869, "training_acc": 52.0, "val_loss": 17.19815582036972, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27163314819336, "training_acc": 52.0, "val_loss": 17.196454107761383, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24203038215637, "training_acc": 52.0, "val_loss": 17.199455201625824, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25586795806885, "training_acc": 52.0, "val_loss": 17.209592461586, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24120211601257, "training_acc": 52.0, "val_loss": 17.217665910720825, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25454664230347, "training_acc": 52.0, "val_loss": 17.227773368358612, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23974609375, "training_acc": 52.0, "val_loss": 17.237955331802368, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22530102729797, "training_acc": 52.0, "val_loss": 17.242243885993958, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23236799240112, "training_acc": 52.0, "val_loss": 17.245860397815704, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25390553474426, "training_acc": 52.0, "val_loss": 17.252299189567566, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25239610671997, "training_acc": 52.0, "val_loss": 17.259222269058228, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25862169265747, "training_acc": 52.0, "val_loss": 17.264220118522644, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26788115501404, "training_acc": 52.0, "val_loss": 17.269286513328552, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22446179389954, "training_acc": 52.0, "val_loss": 17.272430658340454, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26009678840637, "training_acc": 52.0, "val_loss": 17.269325256347656, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24955248832703, "training_acc": 52.0, "val_loss": 17.269209027290344, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.247718334198, "training_acc": 52.0, "val_loss": 17.270000278949738, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23861718177795, "training_acc": 52.0, "val_loss": 17.265400290489197, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26107978820801, "training_acc": 52.0, "val_loss": 17.26105511188507, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28199934959412, "training_acc": 52.0, "val_loss": 17.251168191432953, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23968815803528, "training_acc": 52.0, "val_loss": 17.246876657009125, "val_acc": 56.0}
