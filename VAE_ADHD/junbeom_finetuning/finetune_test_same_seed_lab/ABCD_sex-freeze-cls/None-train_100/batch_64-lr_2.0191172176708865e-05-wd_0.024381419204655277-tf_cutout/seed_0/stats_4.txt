"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.50769543647766, "training_acc": 47.0, "val_loss": 17.764930427074432, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.37734961509705, "training_acc": 47.0, "val_loss": 17.730121314525604, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.21426129341125, "training_acc": 47.0, "val_loss": 17.695434391498566, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.0985541343689, "training_acc": 47.0, "val_loss": 17.66223907470703, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.88232707977295, "training_acc": 47.0, "val_loss": 17.632369697093964, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.8091733455658, "training_acc": 47.0, "val_loss": 17.60370284318924, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.66703510284424, "training_acc": 47.0, "val_loss": 17.57805645465851, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.56022763252258, "training_acc": 47.0, "val_loss": 17.553454637527466, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.42961716651917, "training_acc": 47.0, "val_loss": 17.531096935272217, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.32503056526184, "training_acc": 47.0, "val_loss": 17.51072257757187, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.2351176738739, "training_acc": 47.0, "val_loss": 17.490434646606445, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.19917464256287, "training_acc": 47.0, "val_loss": 17.471328377723694, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.05331921577454, "training_acc": 47.0, "val_loss": 17.455239593982697, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.9824914932251, "training_acc": 47.0, "val_loss": 17.439189553260803, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.88792014122009, "training_acc": 47.0, "val_loss": 17.42434650659561, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.82799983024597, "training_acc": 47.0, "val_loss": 17.410434782505035, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.7620439529419, "training_acc": 47.0, "val_loss": 17.39698350429535, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.68742728233337, "training_acc": 47.0, "val_loss": 17.384721338748932, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.67020893096924, "training_acc": 47.0, "val_loss": 17.373374104499817, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.60121846199036, "training_acc": 47.0, "val_loss": 17.363466322422028, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.54510498046875, "training_acc": 47.0, "val_loss": 17.354650795459747, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.48520016670227, "training_acc": 47.0, "val_loss": 17.346705496311188, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.45577239990234, "training_acc": 47.0, "val_loss": 17.33943521976471, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.41860699653625, "training_acc": 47.0, "val_loss": 17.33297109603882, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.37916922569275, "training_acc": 47.0, "val_loss": 17.32739955186844, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.32506585121155, "training_acc": 47.0, "val_loss": 17.322492599487305, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.33019018173218, "training_acc": 48.0, "val_loss": 17.31831580400467, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.28160786628723, "training_acc": 53.0, "val_loss": 17.314788699150085, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.29072666168213, "training_acc": 53.0, "val_loss": 17.311744391918182, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.25532984733582, "training_acc": 53.0, "val_loss": 17.309148609638214, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.20370078086853, "training_acc": 53.0, "val_loss": 17.307324707508087, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.21964764595032, "training_acc": 53.0, "val_loss": 17.30579286813736, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.20673847198486, "training_acc": 53.0, "val_loss": 17.304518818855286, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20471906661987, "training_acc": 53.0, "val_loss": 17.303571105003357, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.20542502403259, "training_acc": 53.0, "val_loss": 17.302915453910828, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16348576545715, "training_acc": 53.0, "val_loss": 17.3023521900177, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15581107139587, "training_acc": 53.0, "val_loss": 17.30189025402069, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.14512228965759, "training_acc": 53.0, "val_loss": 17.30147898197174, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1656277179718, "training_acc": 53.0, "val_loss": 17.301112413406372, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.18098902702332, "training_acc": 53.0, "val_loss": 17.30090230703354, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17168116569519, "training_acc": 53.0, "val_loss": 17.30082929134369, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.14895868301392, "training_acc": 53.0, "val_loss": 17.30082631111145, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15174865722656, "training_acc": 53.0, "val_loss": 17.30087101459503, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13512754440308, "training_acc": 53.0, "val_loss": 17.300979793071747, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13659811019897, "training_acc": 53.0, "val_loss": 17.301101982593536, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.14766836166382, "training_acc": 53.0, "val_loss": 17.30123907327652, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.14471507072449, "training_acc": 53.0, "val_loss": 17.30152517557144, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.15218710899353, "training_acc": 53.0, "val_loss": 17.30174720287323, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13092541694641, "training_acc": 53.0, "val_loss": 17.3019677400589, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12345838546753, "training_acc": 53.0, "val_loss": 17.302344739437103, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.1425392627716, "training_acc": 53.0, "val_loss": 17.302723228931427, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14286398887634, "training_acc": 53.0, "val_loss": 17.303094267845154, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.12989830970764, "training_acc": 53.0, "val_loss": 17.303337156772614, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.14937257766724, "training_acc": 53.0, "val_loss": 17.303606867790222, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.14719319343567, "training_acc": 53.0, "val_loss": 17.304036021232605, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.10826826095581, "training_acc": 53.0, "val_loss": 17.304368317127228, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.13163304328918, "training_acc": 53.0, "val_loss": 17.304599285125732, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.11170768737793, "training_acc": 53.0, "val_loss": 17.304804921150208, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13344955444336, "training_acc": 53.0, "val_loss": 17.304980754852295, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.12737989425659, "training_acc": 53.0, "val_loss": 17.305202782154083, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.1305787563324, "training_acc": 53.0, "val_loss": 17.305459082126617, "val_acc": 52.0}
