"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24707746505737, "training_acc": 53.0, "val_loss": 17.31281876564026, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.19854283332825, "training_acc": 53.0, "val_loss": 17.312148213386536, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20390391349792, "training_acc": 53.0, "val_loss": 17.311839759349823, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21392011642456, "training_acc": 53.0, "val_loss": 17.31122136116028, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19573187828064, "training_acc": 53.0, "val_loss": 17.31088012456894, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16541028022766, "training_acc": 53.0, "val_loss": 17.31068789958954, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1538200378418, "training_acc": 53.0, "val_loss": 17.310531437397003, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17591595649719, "training_acc": 53.0, "val_loss": 17.31046289205551, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15330624580383, "training_acc": 53.0, "val_loss": 17.310477793216705, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13364624977112, "training_acc": 53.0, "val_loss": 17.310649156570435, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16290640830994, "training_acc": 53.0, "val_loss": 17.31107234954834, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14826488494873, "training_acc": 53.0, "val_loss": 17.311599850654602, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15566825866699, "training_acc": 53.0, "val_loss": 17.312221229076385, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.163076877594, "training_acc": 53.0, "val_loss": 17.31259822845459, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16806197166443, "training_acc": 53.0, "val_loss": 17.313162982463837, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11989426612854, "training_acc": 53.0, "val_loss": 17.314182221889496, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13771176338196, "training_acc": 53.0, "val_loss": 17.31533259153366, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12743496894836, "training_acc": 53.0, "val_loss": 17.316608130931854, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14462184906006, "training_acc": 53.0, "val_loss": 17.317864298820496, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13906407356262, "training_acc": 53.0, "val_loss": 17.319054901599884, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14631223678589, "training_acc": 53.0, "val_loss": 17.320291697978973, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15414023399353, "training_acc": 53.0, "val_loss": 17.321601510047913, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15243220329285, "training_acc": 53.0, "val_loss": 17.32226461172104, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14939022064209, "training_acc": 53.0, "val_loss": 17.3228457570076, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15414071083069, "training_acc": 53.0, "val_loss": 17.32327789068222, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17707133293152, "training_acc": 53.0, "val_loss": 17.324218153953552, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15485000610352, "training_acc": 53.0, "val_loss": 17.324110865592957, "val_acc": 52.0}
