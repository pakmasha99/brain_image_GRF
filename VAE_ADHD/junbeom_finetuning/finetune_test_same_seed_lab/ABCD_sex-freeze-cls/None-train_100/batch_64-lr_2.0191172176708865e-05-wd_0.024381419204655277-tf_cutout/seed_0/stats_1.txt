"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31555843353271, "training_acc": 48.0, "val_loss": 17.330588400363922, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.30465292930603, "training_acc": 49.0, "val_loss": 17.32429265975952, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23412752151489, "training_acc": 53.0, "val_loss": 17.31935888528824, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.21992421150208, "training_acc": 53.0, "val_loss": 17.31632649898529, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15783452987671, "training_acc": 53.0, "val_loss": 17.315232753753662, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16964673995972, "training_acc": 53.0, "val_loss": 17.314189672470093, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13643407821655, "training_acc": 53.0, "val_loss": 17.313610017299652, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13732624053955, "training_acc": 53.0, "val_loss": 17.31332540512085, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14064145088196, "training_acc": 53.0, "val_loss": 17.313407361507416, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1632649898529, "training_acc": 53.0, "val_loss": 17.31383055448532, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12464189529419, "training_acc": 53.0, "val_loss": 17.31434017419815, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13187599182129, "training_acc": 53.0, "val_loss": 17.31492131948471, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.10128903388977, "training_acc": 53.0, "val_loss": 17.315277457237244, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12252116203308, "training_acc": 53.0, "val_loss": 17.315734922885895, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13525772094727, "training_acc": 53.0, "val_loss": 17.316314578056335, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11844754219055, "training_acc": 53.0, "val_loss": 17.316865921020508, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1403226852417, "training_acc": 53.0, "val_loss": 17.31725037097931, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14496636390686, "training_acc": 53.0, "val_loss": 17.318139970302582, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1467638015747, "training_acc": 53.0, "val_loss": 17.31869876384735, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.123779296875, "training_acc": 53.0, "val_loss": 17.318837344646454, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12193632125854, "training_acc": 53.0, "val_loss": 17.31884926557541, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11213207244873, "training_acc": 53.0, "val_loss": 17.319025099277496, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11660361289978, "training_acc": 53.0, "val_loss": 17.31906831264496, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12885975837708, "training_acc": 53.0, "val_loss": 17.319175601005554, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12961959838867, "training_acc": 53.0, "val_loss": 17.319320142269135, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1159884929657, "training_acc": 53.0, "val_loss": 17.319713532924652, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11926603317261, "training_acc": 53.0, "val_loss": 17.31993407011032, "val_acc": 52.0}
