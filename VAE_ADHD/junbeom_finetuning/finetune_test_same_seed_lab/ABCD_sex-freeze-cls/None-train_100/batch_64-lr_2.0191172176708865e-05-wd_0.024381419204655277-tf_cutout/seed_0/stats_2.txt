"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.15433979034424, "training_acc": 53.0, "val_loss": 17.32598841190338, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.14965224266052, "training_acc": 53.0, "val_loss": 17.322710156440735, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18306684494019, "training_acc": 53.0, "val_loss": 17.32047200202942, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1347234249115, "training_acc": 53.0, "val_loss": 17.317938804626465, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14264559745789, "training_acc": 53.0, "val_loss": 17.315684258937836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16592240333557, "training_acc": 53.0, "val_loss": 17.31376200914383, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1634430885315, "training_acc": 53.0, "val_loss": 17.313070595264435, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12500429153442, "training_acc": 53.0, "val_loss": 17.312324047088623, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1434371471405, "training_acc": 53.0, "val_loss": 17.311418056488037, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11779856681824, "training_acc": 53.0, "val_loss": 17.310625314712524, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14517951011658, "training_acc": 53.0, "val_loss": 17.310121655464172, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14568781852722, "training_acc": 53.0, "val_loss": 17.309805750846863, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16440200805664, "training_acc": 53.0, "val_loss": 17.309996485710144, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.138108253479, "training_acc": 53.0, "val_loss": 17.310279607772827, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13779282569885, "training_acc": 53.0, "val_loss": 17.310169339179993, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14459824562073, "training_acc": 53.0, "val_loss": 17.310401797294617, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12631916999817, "training_acc": 53.0, "val_loss": 17.31060892343521, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.167804479599, "training_acc": 53.0, "val_loss": 17.310810089111328, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1334638595581, "training_acc": 53.0, "val_loss": 17.310720682144165, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12374520301819, "training_acc": 53.0, "val_loss": 17.310728132724762, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13409352302551, "training_acc": 53.0, "val_loss": 17.31083393096924, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13234424591064, "training_acc": 53.0, "val_loss": 17.310823500156403, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11945033073425, "training_acc": 53.0, "val_loss": 17.310985922813416, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13224625587463, "training_acc": 53.0, "val_loss": 17.31131672859192, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16134572029114, "training_acc": 53.0, "val_loss": 17.311513423919678, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14446306228638, "training_acc": 53.0, "val_loss": 17.311465740203857, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16403651237488, "training_acc": 53.0, "val_loss": 17.311422526836395, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14873003959656, "training_acc": 53.0, "val_loss": 17.31136441230774, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15588188171387, "training_acc": 53.0, "val_loss": 17.311519384384155, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16048860549927, "training_acc": 53.0, "val_loss": 17.31158047914505, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12385964393616, "training_acc": 53.0, "val_loss": 17.312024533748627, "val_acc": 52.0}
