"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 29348.448936462402, "training_acc": 50.0, "val_loss": 7415.5548095703125, "val_acc": 44.0}
{"epoch": 1, "training_loss": 30936.421630859375, "training_acc": 48.0, "val_loss": 11877.180480957031, "val_acc": 56.0}
{"epoch": 2, "training_loss": 49143.84387207031, "training_acc": 52.0, "val_loss": 5580.437469482422, "val_acc": 56.0}
{"epoch": 3, "training_loss": 17187.491943359375, "training_acc": 54.0, "val_loss": 5823.099517822266, "val_acc": 44.0}
{"epoch": 4, "training_loss": 20579.823486328125, "training_acc": 48.0, "val_loss": 620.683479309082, "val_acc": 44.0}
{"epoch": 5, "training_loss": 11131.325073242188, "training_acc": 44.0, "val_loss": 7517.783355712891, "val_acc": 56.0}
{"epoch": 6, "training_loss": 31900.31689453125, "training_acc": 52.0, "val_loss": 4734.165954589844, "val_acc": 56.0}
{"epoch": 7, "training_loss": 14214.426773071289, "training_acc": 52.0, "val_loss": 6647.813415527344, "val_acc": 44.0}
{"epoch": 8, "training_loss": 28236.21044921875, "training_acc": 48.0, "val_loss": 10505.753326416016, "val_acc": 44.0}
{"epoch": 9, "training_loss": 36494.266357421875, "training_acc": 48.0, "val_loss": 4044.0540313720703, "val_acc": 44.0}
{"epoch": 10, "training_loss": 12363.784271240234, "training_acc": 50.0, "val_loss": 4532.888412475586, "val_acc": 56.0}
{"epoch": 11, "training_loss": 20505.85137939453, "training_acc": 52.0, "val_loss": 3777.4120330810547, "val_acc": 56.0}
{"epoch": 12, "training_loss": 11325.769744873047, "training_acc": 52.0, "val_loss": 4629.338455200195, "val_acc": 44.0}
{"epoch": 13, "training_loss": 21216.241943359375, "training_acc": 48.0, "val_loss": 7289.4134521484375, "val_acc": 44.0}
{"epoch": 14, "training_loss": 23778.601318359375, "training_acc": 48.0, "val_loss": 276.5491247177124, "val_acc": 44.0}
{"epoch": 15, "training_loss": 7081.6597900390625, "training_acc": 54.0, "val_loss": 7872.422027587891, "val_acc": 56.0}
{"epoch": 16, "training_loss": 35629.20361328125, "training_acc": 52.0, "val_loss": 8081.531524658203, "val_acc": 56.0}
{"epoch": 17, "training_loss": 31047.359497070312, "training_acc": 52.0, "val_loss": 1708.4680557250977, "val_acc": 56.0}
{"epoch": 18, "training_loss": 10746.496154785156, "training_acc": 50.0, "val_loss": 7922.102355957031, "val_acc": 44.0}
{"epoch": 19, "training_loss": 30517.83154296875, "training_acc": 48.0, "val_loss": 7214.5660400390625, "val_acc": 44.0}
{"epoch": 20, "training_loss": 21762.307495117188, "training_acc": 48.0, "val_loss": 1546.6729164123535, "val_acc": 56.0}
{"epoch": 21, "training_loss": 9642.195617675781, "training_acc": 52.0, "val_loss": 4293.811416625977, "val_acc": 56.0}
{"epoch": 22, "training_loss": 16621.60723876953, "training_acc": 52.0, "val_loss": 379.9725294113159, "val_acc": 56.0}
{"epoch": 23, "training_loss": 6780.396484375, "training_acc": 54.0, "val_loss": 7353.7139892578125, "val_acc": 44.0}
{"epoch": 24, "training_loss": 27340.29803466797, "training_acc": 48.0, "val_loss": 5167.484283447266, "val_acc": 44.0}
{"epoch": 25, "training_loss": 13364.781845092773, "training_acc": 48.0, "val_loss": 3996.670913696289, "val_acc": 56.0}
{"epoch": 26, "training_loss": 23402.743286132812, "training_acc": 52.0, "val_loss": 7490.2130126953125, "val_acc": 56.0}
{"epoch": 27, "training_loss": 30364.945434570312, "training_acc": 52.0, "val_loss": 3517.2435760498047, "val_acc": 56.0}
{"epoch": 28, "training_loss": 11895.461990356445, "training_acc": 46.0, "val_loss": 3262.332534790039, "val_acc": 44.0}
{"epoch": 29, "training_loss": 11960.499908447266, "training_acc": 48.0, "val_loss": 659.0067386627197, "val_acc": 44.0}
{"epoch": 30, "training_loss": 8223.814208984375, "training_acc": 40.0, "val_loss": 4622.294998168945, "val_acc": 56.0}
{"epoch": 31, "training_loss": 19143.075775146484, "training_acc": 52.0, "val_loss": 2136.0395431518555, "val_acc": 56.0}
{"epoch": 32, "training_loss": 7506.227340698242, "training_acc": 52.0, "val_loss": 2889.267921447754, "val_acc": 44.0}
{"epoch": 33, "training_loss": 9577.872985839844, "training_acc": 48.0, "val_loss": 813.683032989502, "val_acc": 56.0}
