"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 42303.321559906006, "training_acc": 49.0, "val_loss": 12416.50390625, "val_acc": 48.0}
{"epoch": 1, "training_loss": 41274.42736816406, "training_acc": 51.0, "val_loss": 13715.238952636719, "val_acc": 52.0}
{"epoch": 2, "training_loss": 50339.08850097656, "training_acc": 53.0, "val_loss": 4213.502502441406, "val_acc": 52.0}
{"epoch": 3, "training_loss": 22712.851196289062, "training_acc": 47.0, "val_loss": 10483.443450927734, "val_acc": 48.0}
{"epoch": 4, "training_loss": 38892.88818359375, "training_acc": 47.0, "val_loss": 1523.45552444458, "val_acc": 48.0}
{"epoch": 5, "training_loss": 14821.3515625, "training_acc": 49.0, "val_loss": 12013.526916503906, "val_acc": 52.0}
{"epoch": 6, "training_loss": 47860.15771484375, "training_acc": 53.0, "val_loss": 9635.743713378906, "val_acc": 52.0}
{"epoch": 7, "training_loss": 30894.133361816406, "training_acc": 53.0, "val_loss": 4660.808181762695, "val_acc": 48.0}
{"epoch": 8, "training_loss": 27212.105590820312, "training_acc": 47.0, "val_loss": 8297.438049316406, "val_acc": 48.0}
{"epoch": 9, "training_loss": 27143.747192382812, "training_acc": 47.0, "val_loss": 2622.556495666504, "val_acc": 52.0}
{"epoch": 10, "training_loss": 13913.098205566406, "training_acc": 53.0, "val_loss": 5837.812423706055, "val_acc": 52.0}
{"epoch": 11, "training_loss": 19408.074127197266, "training_acc": 53.0, "val_loss": 1574.5084762573242, "val_acc": 48.0}
{"epoch": 12, "training_loss": 8589.025634765625, "training_acc": 47.0, "val_loss": 1016.2127494812012, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6783.917633056641, "training_acc": 53.0, "val_loss": 5141.363143920898, "val_acc": 52.0}
{"epoch": 14, "training_loss": 18517.75604248047, "training_acc": 53.0, "val_loss": 545.164155960083, "val_acc": 52.0}
{"epoch": 15, "training_loss": 8100.1336669921875, "training_acc": 55.0, "val_loss": 7735.002136230469, "val_acc": 48.0}
{"epoch": 16, "training_loss": 29964.968383789062, "training_acc": 47.0, "val_loss": 2940.7737731933594, "val_acc": 48.0}
{"epoch": 17, "training_loss": 11783.721282958984, "training_acc": 51.0, "val_loss": 6328.453063964844, "val_acc": 52.0}
{"epoch": 18, "training_loss": 24537.200439453125, "training_acc": 53.0, "val_loss": 4175.568389892578, "val_acc": 52.0}
{"epoch": 19, "training_loss": 9274.67707824707, "training_acc": 53.0, "val_loss": 7046.822357177734, "val_acc": 48.0}
{"epoch": 20, "training_loss": 34178.367431640625, "training_acc": 47.0, "val_loss": 10542.61703491211, "val_acc": 48.0}
{"epoch": 21, "training_loss": 38054.02990722656, "training_acc": 47.0, "val_loss": 1604.3895721435547, "val_acc": 48.0}
{"epoch": 22, "training_loss": 16477.7197265625, "training_acc": 39.0, "val_loss": 10333.734130859375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 41896.508056640625, "training_acc": 53.0, "val_loss": 9971.845245361328, "val_acc": 52.0}
{"epoch": 24, "training_loss": 32880.99279785156, "training_acc": 53.0, "val_loss": 369.9263572692871, "val_acc": 52.0}
{"epoch": 25, "training_loss": 11179.360534667969, "training_acc": 55.0, "val_loss": 12852.023315429688, "val_acc": 48.0}
{"epoch": 26, "training_loss": 53191.35534667969, "training_acc": 47.0, "val_loss": 12485.143280029297, "val_acc": 48.0}
{"epoch": 27, "training_loss": 43909.16162109375, "training_acc": 47.0, "val_loss": 1378.5347938537598, "val_acc": 48.0}
{"epoch": 28, "training_loss": 12771.25244140625, "training_acc": 51.0, "val_loss": 12242.131805419922, "val_acc": 52.0}
{"epoch": 29, "training_loss": 50435.873779296875, "training_acc": 53.0, "val_loss": 14079.458618164062, "val_acc": 52.0}
{"epoch": 30, "training_loss": 50711.39831542969, "training_acc": 53.0, "val_loss": 6512.046051025391, "val_acc": 52.0}
{"epoch": 31, "training_loss": 16830.845932006836, "training_acc": 51.0, "val_loss": 4261.843490600586, "val_acc": 48.0}
{"epoch": 32, "training_loss": 17835.095703125, "training_acc": 47.0, "val_loss": 2156.7840576171875, "val_acc": 48.0}
{"epoch": 33, "training_loss": 10113.845153808594, "training_acc": 47.0, "val_loss": 4773.078155517578, "val_acc": 52.0}
{"epoch": 34, "training_loss": 17544.22833251953, "training_acc": 53.0, "val_loss": 920.4727172851562, "val_acc": 52.0}
{"epoch": 35, "training_loss": 12061.376220703125, "training_acc": 41.0, "val_loss": 6958.676910400391, "val_acc": 48.0}
{"epoch": 36, "training_loss": 26278.90869140625, "training_acc": 47.0, "val_loss": 1551.0541915893555, "val_acc": 48.0}
{"epoch": 37, "training_loss": 11470.736389160156, "training_acc": 47.0, "val_loss": 8098.783111572266, "val_acc": 52.0}
{"epoch": 38, "training_loss": 33051.02014160156, "training_acc": 53.0, "val_loss": 6616.5191650390625, "val_acc": 52.0}
{"epoch": 39, "training_loss": 18842.400909423828, "training_acc": 53.0, "val_loss": 4651.298904418945, "val_acc": 48.0}
{"epoch": 40, "training_loss": 25028.519653320312, "training_acc": 47.0, "val_loss": 8374.488067626953, "val_acc": 48.0}
{"epoch": 41, "training_loss": 29406.605529785156, "training_acc": 47.0, "val_loss": 102.16317176818848, "val_acc": 52.0}
{"epoch": 42, "training_loss": 3653.0975036621094, "training_acc": 53.0, "val_loss": 2166.2309646606445, "val_acc": 52.0}
{"epoch": 43, "training_loss": 6836.1103591918945, "training_acc": 47.0, "val_loss": 224.51481819152832, "val_acc": 48.0}
{"epoch": 44, "training_loss": 5406.201965332031, "training_acc": 45.0, "val_loss": 3243.1957244873047, "val_acc": 52.0}
{"epoch": 45, "training_loss": 9289.791900634766, "training_acc": 53.0, "val_loss": 3509.479522705078, "val_acc": 48.0}
{"epoch": 46, "training_loss": 16836.084838867188, "training_acc": 47.0, "val_loss": 3765.4029846191406, "val_acc": 48.0}
{"epoch": 47, "training_loss": 10401.401176452637, "training_acc": 49.0, "val_loss": 1566.7580604553223, "val_acc": 52.0}
{"epoch": 48, "training_loss": 4112.382892608643, "training_acc": 53.0, "val_loss": 3692.522430419922, "val_acc": 48.0}
{"epoch": 49, "training_loss": 16189.478149414062, "training_acc": 47.0, "val_loss": 2228.685188293457, "val_acc": 48.0}
{"epoch": 50, "training_loss": 8342.733520507812, "training_acc": 53.0, "val_loss": 4241.315841674805, "val_acc": 52.0}
{"epoch": 51, "training_loss": 15352.708526611328, "training_acc": 53.0, "val_loss": 533.2802772521973, "val_acc": 52.0}
{"epoch": 52, "training_loss": 8226.908386230469, "training_acc": 51.0, "val_loss": 6744.81201171875, "val_acc": 48.0}
{"epoch": 53, "training_loss": 25547.579833984375, "training_acc": 47.0, "val_loss": 1543.6762809753418, "val_acc": 48.0}
{"epoch": 54, "training_loss": 11534.171569824219, "training_acc": 45.0, "val_loss": 7412.571716308594, "val_acc": 52.0}
{"epoch": 55, "training_loss": 28662.29522705078, "training_acc": 53.0, "val_loss": 5197.885513305664, "val_acc": 52.0}
{"epoch": 56, "training_loss": 13951.609588623047, "training_acc": 53.0, "val_loss": 5726.968765258789, "val_acc": 48.0}
{"epoch": 57, "training_loss": 27744.768310546875, "training_acc": 47.0, "val_loss": 8921.42562866211, "val_acc": 48.0}
{"epoch": 58, "training_loss": 31521.119018554688, "training_acc": 47.0, "val_loss": 473.8726615905762, "val_acc": 48.0}
{"epoch": 59, "training_loss": 11051.888427734375, "training_acc": 49.0, "val_loss": 11300.960540771484, "val_acc": 52.0}
{"epoch": 60, "training_loss": 45484.90393066406, "training_acc": 53.0, "val_loss": 11721.568298339844, "val_acc": 52.0}
