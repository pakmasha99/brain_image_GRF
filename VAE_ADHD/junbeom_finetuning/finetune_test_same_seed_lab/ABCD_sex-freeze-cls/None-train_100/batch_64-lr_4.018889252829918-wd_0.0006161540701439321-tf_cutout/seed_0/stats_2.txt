"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 33701.80101776123, "training_acc": 53.0, "val_loss": 6936.293792724609, "val_acc": 52.0}
{"epoch": 1, "training_loss": 27512.192016601562, "training_acc": 53.0, "val_loss": 11989.37759399414, "val_acc": 48.0}
{"epoch": 2, "training_loss": 45071.10900878906, "training_acc": 47.0, "val_loss": 2946.270179748535, "val_acc": 48.0}
{"epoch": 3, "training_loss": 15282.043151855469, "training_acc": 51.0, "val_loss": 10241.970825195312, "val_acc": 52.0}
{"epoch": 4, "training_loss": 39797.52355957031, "training_acc": 53.0, "val_loss": 8528.18603515625, "val_acc": 52.0}
{"epoch": 5, "training_loss": 27341.375366210938, "training_acc": 53.0, "val_loss": 2100.812530517578, "val_acc": 48.0}
{"epoch": 6, "training_loss": 11199.516723632812, "training_acc": 47.0, "val_loss": 4217.654037475586, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12426.272003173828, "training_acc": 47.0, "val_loss": 3591.514205932617, "val_acc": 52.0}
{"epoch": 8, "training_loss": 17152.64453125, "training_acc": 53.0, "val_loss": 5856.02912902832, "val_acc": 52.0}
{"epoch": 9, "training_loss": 19720.26641845703, "training_acc": 53.0, "val_loss": 176.4210820198059, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1998.2000885009766, "training_acc": 47.0, "val_loss": 165.97927808761597, "val_acc": 48.0}
{"epoch": 11, "training_loss": 4206.486236572266, "training_acc": 51.0, "val_loss": 3711.4013671875, "val_acc": 52.0}
{"epoch": 12, "training_loss": 12750.932739257812, "training_acc": 53.0, "val_loss": 434.66200828552246, "val_acc": 48.0}
{"epoch": 13, "training_loss": 2298.334976196289, "training_acc": 47.0, "val_loss": 894.5000648498535, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2849.716205596924, "training_acc": 53.0, "val_loss": 1838.0632400512695, "val_acc": 48.0}
{"epoch": 15, "training_loss": 7258.183135986328, "training_acc": 47.0, "val_loss": 774.8456954956055, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3543.7374114990234, "training_acc": 53.0, "val_loss": 523.3056545257568, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1816.9684448242188, "training_acc": 45.0, "val_loss": 1221.3903427124023, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3675.861095428467, "training_acc": 47.0, "val_loss": 2396.318244934082, "val_acc": 52.0}
{"epoch": 19, "training_loss": 10206.73257446289, "training_acc": 53.0, "val_loss": 1858.0482482910156, "val_acc": 52.0}
{"epoch": 20, "training_loss": 6838.375076293945, "training_acc": 47.0, "val_loss": 1700.3459930419922, "val_acc": 48.0}
{"epoch": 21, "training_loss": 4447.918097734451, "training_acc": 49.0, "val_loss": 202.81546115875244, "val_acc": 52.0}
{"epoch": 22, "training_loss": 3935.3667907714844, "training_acc": 41.0, "val_loss": 956.8805694580078, "val_acc": 48.0}
{"epoch": 23, "training_loss": 3131.2334594726562, "training_acc": 63.0, "val_loss": 2463.076400756836, "val_acc": 52.0}
{"epoch": 24, "training_loss": 8374.398498535156, "training_acc": 53.0, "val_loss": 980.3571701049805, "val_acc": 48.0}
{"epoch": 25, "training_loss": 4099.347259521484, "training_acc": 47.0, "val_loss": 661.0519886016846, "val_acc": 52.0}
{"epoch": 26, "training_loss": 2069.0152015686035, "training_acc": 53.0, "val_loss": 1753.299903869629, "val_acc": 48.0}
{"epoch": 27, "training_loss": 6489.029083251953, "training_acc": 47.0, "val_loss": 1013.0834579467773, "val_acc": 52.0}
{"epoch": 28, "training_loss": 4011.688766479492, "training_acc": 53.0, "val_loss": 344.53086853027344, "val_acc": 48.0}
{"epoch": 29, "training_loss": 1213.025894165039, "training_acc": 53.0, "val_loss": 759.3125820159912, "val_acc": 48.0}
