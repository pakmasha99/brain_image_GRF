"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25669527053833, "training_acc": 52.0, "val_loss": 17.251186072826385, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.25458073616028, "training_acc": 52.0, "val_loss": 17.208118736743927, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2767722606659, "training_acc": 52.0, "val_loss": 17.206409573554993, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26253247261047, "training_acc": 52.0, "val_loss": 17.228952050209045, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.2441029548645, "training_acc": 52.0, "val_loss": 17.26369857788086, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23788547515869, "training_acc": 52.0, "val_loss": 17.27542132139206, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27909016609192, "training_acc": 52.0, "val_loss": 17.294487357139587, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.28697967529297, "training_acc": 52.0, "val_loss": 17.294026911258698, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.3272590637207, "training_acc": 52.0, "val_loss": 17.27236956357956, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2645492553711, "training_acc": 52.0, "val_loss": 17.268943786621094, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2342677116394, "training_acc": 52.0, "val_loss": 17.26316213607788, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26360559463501, "training_acc": 52.0, "val_loss": 17.251548171043396, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23470044136047, "training_acc": 52.0, "val_loss": 17.241859436035156, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23287892341614, "training_acc": 52.0, "val_loss": 17.240121960639954, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24060487747192, "training_acc": 52.0, "val_loss": 17.23189502954483, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24775886535645, "training_acc": 52.0, "val_loss": 17.220905423164368, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25436878204346, "training_acc": 52.0, "val_loss": 17.205484211444855, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24226307868958, "training_acc": 52.0, "val_loss": 17.199401557445526, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25412011146545, "training_acc": 52.0, "val_loss": 17.197662591934204, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26786756515503, "training_acc": 52.0, "val_loss": 17.1995609998703, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22156620025635, "training_acc": 52.0, "val_loss": 17.208224534988403, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2423837184906, "training_acc": 52.0, "val_loss": 17.214477062225342, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29055666923523, "training_acc": 52.0, "val_loss": 17.21242368221283, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25235509872437, "training_acc": 52.0, "val_loss": 17.222844064235687, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24850153923035, "training_acc": 52.0, "val_loss": 17.239360511302948, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25772881507874, "training_acc": 52.0, "val_loss": 17.260366678237915, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.32085752487183, "training_acc": 52.0, "val_loss": 17.26386994123459, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.2402970790863, "training_acc": 52.0, "val_loss": 17.286571860313416, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.28521275520325, "training_acc": 52.0, "val_loss": 17.301936447620392, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.29407215118408, "training_acc": 52.0, "val_loss": 17.294272780418396, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.3488118648529, "training_acc": 52.0, "val_loss": 17.273496091365814, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29221200942993, "training_acc": 52.0, "val_loss": 17.27188527584076, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25595808029175, "training_acc": 52.0, "val_loss": 17.250588536262512, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2442843914032, "training_acc": 52.0, "val_loss": 17.234714329242706, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2642114162445, "training_acc": 52.0, "val_loss": 17.218343913555145, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.237149477005, "training_acc": 52.0, "val_loss": 17.211806774139404, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.2399833202362, "training_acc": 52.0, "val_loss": 17.207928001880646, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.25863647460938, "training_acc": 52.0, "val_loss": 17.204666137695312, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2479407787323, "training_acc": 52.0, "val_loss": 17.19537526369095, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.28449368476868, "training_acc": 52.0, "val_loss": 17.18265563249588, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.26450109481812, "training_acc": 52.0, "val_loss": 17.18207150697708, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28589987754822, "training_acc": 52.0, "val_loss": 17.185096442699432, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28227472305298, "training_acc": 52.0, "val_loss": 17.190687358379364, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23196721076965, "training_acc": 52.0, "val_loss": 17.204178869724274, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26339340209961, "training_acc": 52.0, "val_loss": 17.231787741184235, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.22775650024414, "training_acc": 52.0, "val_loss": 17.253677546977997, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.2580337524414, "training_acc": 52.0, "val_loss": 17.276324331760406, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.27489638328552, "training_acc": 52.0, "val_loss": 17.293745279312134, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.2629611492157, "training_acc": 52.0, "val_loss": 17.291873693466187, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2783613204956, "training_acc": 52.0, "val_loss": 17.28500872850418, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.28580975532532, "training_acc": 52.0, "val_loss": 17.282462120056152, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.27468800544739, "training_acc": 52.0, "val_loss": 17.28013902902603, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.28064012527466, "training_acc": 52.0, "val_loss": 17.274528741836548, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27602338790894, "training_acc": 52.0, "val_loss": 17.270663380622864, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22093319892883, "training_acc": 52.0, "val_loss": 17.265504598617554, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27060747146606, "training_acc": 52.0, "val_loss": 17.252500355243683, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24386310577393, "training_acc": 52.0, "val_loss": 17.248190939426422, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23563885688782, "training_acc": 52.0, "val_loss": 17.248351871967316, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22630047798157, "training_acc": 52.0, "val_loss": 17.24209487438202, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25298810005188, "training_acc": 52.0, "val_loss": 17.23838597536087, "val_acc": 56.0}
