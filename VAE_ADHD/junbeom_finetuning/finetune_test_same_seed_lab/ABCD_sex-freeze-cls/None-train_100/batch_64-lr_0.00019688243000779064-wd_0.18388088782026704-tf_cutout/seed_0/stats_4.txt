"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.10775232315063, "training_acc": 47.0, "val_loss": 17.654167115688324, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.8587715625763, "training_acc": 47.0, "val_loss": 17.419232428073883, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.54059648513794, "training_acc": 47.0, "val_loss": 17.32536107301712, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.10669732093811, "training_acc": 53.0, "val_loss": 17.316730320453644, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.0406391620636, "training_acc": 53.0, "val_loss": 17.365482449531555, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22665858268738, "training_acc": 53.0, "val_loss": 17.436160147190094, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.55873203277588, "training_acc": 53.0, "val_loss": 17.493999004364014, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.6470537185669, "training_acc": 53.0, "val_loss": 17.499373853206635, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.64798474311829, "training_acc": 53.0, "val_loss": 17.46915727853775, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.58264064788818, "training_acc": 53.0, "val_loss": 17.424462735652924, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.38707280158997, "training_acc": 53.0, "val_loss": 17.385680973529816, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27279758453369, "training_acc": 53.0, "val_loss": 17.348194122314453, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15369081497192, "training_acc": 53.0, "val_loss": 17.32390969991684, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13860249519348, "training_acc": 53.0, "val_loss": 17.312270402908325, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23358583450317, "training_acc": 53.0, "val_loss": 17.312489449977875, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19974446296692, "training_acc": 53.0, "val_loss": 17.314571142196655, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20631766319275, "training_acc": 53.0, "val_loss": 17.314346134662628, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23573231697083, "training_acc": 53.0, "val_loss": 17.314013838768005, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2542154788971, "training_acc": 53.0, "val_loss": 17.311514914035797, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18366813659668, "training_acc": 53.0, "val_loss": 17.311424016952515, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19363141059875, "training_acc": 53.0, "val_loss": 17.312699556350708, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16478037834167, "training_acc": 53.0, "val_loss": 17.313678562641144, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21581196784973, "training_acc": 53.0, "val_loss": 17.31361150741577, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12729358673096, "training_acc": 53.0, "val_loss": 17.31632798910141, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22953462600708, "training_acc": 53.0, "val_loss": 17.321595549583435, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18445706367493, "training_acc": 53.0, "val_loss": 17.320209741592407, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13889050483704, "training_acc": 53.0, "val_loss": 17.32267588376999, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14217615127563, "training_acc": 53.0, "val_loss": 17.323799431324005, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15682983398438, "training_acc": 53.0, "val_loss": 17.325778305530548, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16123938560486, "training_acc": 53.0, "val_loss": 17.33158975839615, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14034843444824, "training_acc": 53.0, "val_loss": 17.335881292819977, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17356634140015, "training_acc": 53.0, "val_loss": 17.33999401330948, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1723301410675, "training_acc": 53.0, "val_loss": 17.337650060653687, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19785237312317, "training_acc": 53.0, "val_loss": 17.33231693506241, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1770646572113, "training_acc": 53.0, "val_loss": 17.32732206583023, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.17107462882996, "training_acc": 53.0, "val_loss": 17.324668169021606, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14538621902466, "training_acc": 53.0, "val_loss": 17.322658002376556, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13453412055969, "training_acc": 53.0, "val_loss": 17.32015609741211, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.09739542007446, "training_acc": 53.0, "val_loss": 17.318789660930634, "val_acc": 52.0}
