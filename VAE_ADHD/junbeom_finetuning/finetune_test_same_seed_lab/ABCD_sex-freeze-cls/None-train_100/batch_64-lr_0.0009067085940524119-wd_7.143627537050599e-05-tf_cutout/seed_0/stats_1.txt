"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.19172406196594, "training_acc": 51.0, "val_loss": 17.386576533317566, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.57522010803223, "training_acc": 49.0, "val_loss": 17.335598170757294, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.25337409973145, "training_acc": 50.0, "val_loss": 17.342408001422882, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.52311873435974, "training_acc": 53.0, "val_loss": 17.377890646457672, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.00767612457275, "training_acc": 53.0, "val_loss": 17.313528060913086, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15321278572083, "training_acc": 53.0, "val_loss": 17.319637537002563, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1819531917572, "training_acc": 53.0, "val_loss": 17.350514233112335, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.10704350471497, "training_acc": 53.0, "val_loss": 17.44050234556198, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.44020462036133, "training_acc": 53.0, "val_loss": 17.480261623859406, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.66207599639893, "training_acc": 53.0, "val_loss": 17.41669476032257, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.28228616714478, "training_acc": 53.0, "val_loss": 17.314742505550385, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.99406409263611, "training_acc": 53.0, "val_loss": 17.34498143196106, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.6148464679718, "training_acc": 47.0, "val_loss": 17.415741086006165, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.6978805065155, "training_acc": 47.0, "val_loss": 17.347028851509094, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.32239842414856, "training_acc": 49.0, "val_loss": 17.32531636953354, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16353607177734, "training_acc": 53.0, "val_loss": 17.42100417613983, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.59733319282532, "training_acc": 53.0, "val_loss": 17.446506023406982, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.73689341545105, "training_acc": 53.0, "val_loss": 17.489871382713318, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.53982496261597, "training_acc": 53.0, "val_loss": 17.37121194601059, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.10223841667175, "training_acc": 53.0, "val_loss": 17.3190176486969, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.47822594642639, "training_acc": 47.0, "val_loss": 17.395587265491486, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.62114763259888, "training_acc": 47.0, "val_loss": 17.37627387046814, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.46149373054504, "training_acc": 47.0, "val_loss": 17.32238680124283, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14862561225891, "training_acc": 53.0, "val_loss": 17.33238250017166, "val_acc": 52.0}
