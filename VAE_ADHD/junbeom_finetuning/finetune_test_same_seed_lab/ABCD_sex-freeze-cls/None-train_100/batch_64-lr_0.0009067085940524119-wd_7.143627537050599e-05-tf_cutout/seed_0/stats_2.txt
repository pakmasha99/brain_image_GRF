"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.83100485801697, "training_acc": 45.0, "val_loss": 17.347092926502228, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.55461096763611, "training_acc": 47.0, "val_loss": 17.451341450214386, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.53879523277283, "training_acc": 53.0, "val_loss": 17.499838769435883, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.69524049758911, "training_acc": 53.0, "val_loss": 17.357689142227173, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16094923019409, "training_acc": 53.0, "val_loss": 17.30613261461258, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.09838056564331, "training_acc": 53.0, "val_loss": 17.329470813274384, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28960061073303, "training_acc": 52.0, "val_loss": 17.361126840114594, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.48237204551697, "training_acc": 47.0, "val_loss": 17.33410209417343, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.40187311172485, "training_acc": 46.0, "val_loss": 17.307519912719727, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.38097190856934, "training_acc": 53.0, "val_loss": 17.363114655017853, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.50317478179932, "training_acc": 53.0, "val_loss": 17.400118708610535, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.2808849811554, "training_acc": 53.0, "val_loss": 17.32659488916397, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22209477424622, "training_acc": 53.0, "val_loss": 17.30969399213791, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.28584790229797, "training_acc": 52.0, "val_loss": 17.322692275047302, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.48287773132324, "training_acc": 42.0, "val_loss": 17.30925887823105, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.10866951942444, "training_acc": 53.0, "val_loss": 17.34551191329956, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.69363903999329, "training_acc": 53.0, "val_loss": 17.43677854537964, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.61154675483704, "training_acc": 53.0, "val_loss": 17.36576408147812, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.26530122756958, "training_acc": 53.0, "val_loss": 17.329999804496765, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15276789665222, "training_acc": 53.0, "val_loss": 17.307257652282715, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10866212844849, "training_acc": 53.0, "val_loss": 17.30836033821106, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.25420045852661, "training_acc": 53.0, "val_loss": 17.32366681098938, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.29610514640808, "training_acc": 49.0, "val_loss": 17.31134057044983, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.24214339256287, "training_acc": 53.0, "val_loss": 17.31170415878296, "val_acc": 52.0}
