"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.39554977416992, "training_acc": 47.0, "val_loss": 17.4753338098526, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.14004278182983, "training_acc": 47.0, "val_loss": 17.412802577018738, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.75497794151306, "training_acc": 47.0, "val_loss": 17.372436821460724, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51702499389648, "training_acc": 47.0, "val_loss": 17.343957722187042, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.48476529121399, "training_acc": 47.0, "val_loss": 17.32250154018402, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.27028203010559, "training_acc": 50.0, "val_loss": 17.31109917163849, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17145848274231, "training_acc": 53.0, "val_loss": 17.304791510105133, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17926716804504, "training_acc": 53.0, "val_loss": 17.302662134170532, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13042283058167, "training_acc": 53.0, "val_loss": 17.30479747056961, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17105865478516, "training_acc": 53.0, "val_loss": 17.310573160648346, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16336560249329, "training_acc": 53.0, "val_loss": 17.317847907543182, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14374279975891, "training_acc": 53.0, "val_loss": 17.324809730052948, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17473030090332, "training_acc": 53.0, "val_loss": 17.330972850322723, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15973973274231, "training_acc": 53.0, "val_loss": 17.33475774526596, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17933630943298, "training_acc": 53.0, "val_loss": 17.337344586849213, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21570658683777, "training_acc": 53.0, "val_loss": 17.340701818466187, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21283435821533, "training_acc": 53.0, "val_loss": 17.341020703315735, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20854711532593, "training_acc": 53.0, "val_loss": 17.34156310558319, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20338177680969, "training_acc": 53.0, "val_loss": 17.338597774505615, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21108412742615, "training_acc": 53.0, "val_loss": 17.33078360557556, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18157696723938, "training_acc": 53.0, "val_loss": 17.324362695217133, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22528123855591, "training_acc": 53.0, "val_loss": 17.318251729011536, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16353964805603, "training_acc": 53.0, "val_loss": 17.316171526908875, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1866569519043, "training_acc": 53.0, "val_loss": 17.314065992832184, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14958596229553, "training_acc": 53.0, "val_loss": 17.31242686510086, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1544599533081, "training_acc": 53.0, "val_loss": 17.31214076280594, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13123440742493, "training_acc": 53.0, "val_loss": 17.310532927513123, "val_acc": 52.0}
