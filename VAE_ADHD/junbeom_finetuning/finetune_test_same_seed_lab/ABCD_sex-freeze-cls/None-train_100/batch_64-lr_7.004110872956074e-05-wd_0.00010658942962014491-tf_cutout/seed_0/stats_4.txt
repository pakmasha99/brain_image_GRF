"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.1538577079773, "training_acc": 47.0, "val_loss": 17.429053783416748, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.8193154335022, "training_acc": 47.0, "val_loss": 17.391231656074524, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.63758206367493, "training_acc": 47.0, "val_loss": 17.354965209960938, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.48426103591919, "training_acc": 47.0, "val_loss": 17.327961325645447, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.40107750892639, "training_acc": 43.0, "val_loss": 17.312723398208618, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23452305793762, "training_acc": 53.0, "val_loss": 17.30549931526184, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1780936717987, "training_acc": 53.0, "val_loss": 17.302793264389038, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12010407447815, "training_acc": 53.0, "val_loss": 17.303872108459473, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1107907295227, "training_acc": 53.0, "val_loss": 17.30761080980301, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12400794029236, "training_acc": 53.0, "val_loss": 17.31451004743576, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14493179321289, "training_acc": 53.0, "val_loss": 17.321784794330597, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16119742393494, "training_acc": 53.0, "val_loss": 17.326179146766663, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16880440711975, "training_acc": 53.0, "val_loss": 17.326949536800385, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18990087509155, "training_acc": 53.0, "val_loss": 17.325975000858307, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1656744480133, "training_acc": 53.0, "val_loss": 17.325446009635925, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15271759033203, "training_acc": 53.0, "val_loss": 17.32216626405716, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20209550857544, "training_acc": 53.0, "val_loss": 17.318522930145264, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14203405380249, "training_acc": 53.0, "val_loss": 17.318271100521088, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1400215625763, "training_acc": 53.0, "val_loss": 17.315669357776642, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14416480064392, "training_acc": 53.0, "val_loss": 17.313113808631897, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11099362373352, "training_acc": 53.0, "val_loss": 17.312714457511902, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12510442733765, "training_acc": 53.0, "val_loss": 17.312060296535492, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13800144195557, "training_acc": 53.0, "val_loss": 17.31131076812744, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12959218025208, "training_acc": 53.0, "val_loss": 17.30961948633194, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1312415599823, "training_acc": 53.0, "val_loss": 17.308534681797028, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13114643096924, "training_acc": 53.0, "val_loss": 17.308752238750458, "val_acc": 52.0}
