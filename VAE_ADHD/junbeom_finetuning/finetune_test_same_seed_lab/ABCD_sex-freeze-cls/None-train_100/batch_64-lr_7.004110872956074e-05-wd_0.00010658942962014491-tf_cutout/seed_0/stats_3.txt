"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.34984278678894, "training_acc": 53.0, "val_loss": 17.310066521167755, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17828392982483, "training_acc": 53.0, "val_loss": 17.310206592082977, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15303635597229, "training_acc": 53.0, "val_loss": 17.310628294944763, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1847665309906, "training_acc": 53.0, "val_loss": 17.310184240341187, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15647745132446, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18647027015686, "training_acc": 53.0, "val_loss": 17.309226095676422, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14462637901306, "training_acc": 53.0, "val_loss": 17.309558391571045, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14389038085938, "training_acc": 53.0, "val_loss": 17.31034368276596, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12844181060791, "training_acc": 53.0, "val_loss": 17.311546206474304, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13468074798584, "training_acc": 53.0, "val_loss": 17.312651872634888, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15011358261108, "training_acc": 53.0, "val_loss": 17.313025891780853, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10948443412781, "training_acc": 53.0, "val_loss": 17.315170168876648, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13188362121582, "training_acc": 53.0, "val_loss": 17.318615317344666, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1737470626831, "training_acc": 53.0, "val_loss": 17.32124090194702, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14599585533142, "training_acc": 53.0, "val_loss": 17.32044219970703, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13363003730774, "training_acc": 53.0, "val_loss": 17.31846332550049, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13019180297852, "training_acc": 53.0, "val_loss": 17.31792241334915, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1175696849823, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1134843826294, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14388370513916, "training_acc": 53.0, "val_loss": 17.318494617938995, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14729309082031, "training_acc": 53.0, "val_loss": 17.318043112754822, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12121963500977, "training_acc": 53.0, "val_loss": 17.315517365932465, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14265465736389, "training_acc": 53.0, "val_loss": 17.31397807598114, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11603617668152, "training_acc": 53.0, "val_loss": 17.312908172607422, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10606408119202, "training_acc": 53.0, "val_loss": 17.31167733669281, "val_acc": 52.0}
