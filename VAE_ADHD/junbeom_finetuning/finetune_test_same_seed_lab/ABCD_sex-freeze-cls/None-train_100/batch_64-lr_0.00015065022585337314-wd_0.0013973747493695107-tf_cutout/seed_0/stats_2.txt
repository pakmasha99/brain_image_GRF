"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.57138848304749, "training_acc": 45.0, "val_loss": 17.33824759721756, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.25419807434082, "training_acc": 55.0, "val_loss": 17.311011254787445, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.21139740943909, "training_acc": 53.0, "val_loss": 17.315053939819336, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1374580860138, "training_acc": 53.0, "val_loss": 17.335902154445648, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.199214220047, "training_acc": 53.0, "val_loss": 17.354167997837067, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24837589263916, "training_acc": 53.0, "val_loss": 17.364013195037842, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24499034881592, "training_acc": 53.0, "val_loss": 17.35699772834778, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16292881965637, "training_acc": 53.0, "val_loss": 17.338000237941742, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.26338505744934, "training_acc": 53.0, "val_loss": 17.32087880373001, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13326501846313, "training_acc": 53.0, "val_loss": 17.31332689523697, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14601492881775, "training_acc": 53.0, "val_loss": 17.30937659740448, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12275004386902, "training_acc": 53.0, "val_loss": 17.308713495731354, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18791794776917, "training_acc": 53.0, "val_loss": 17.308993637561798, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14936423301697, "training_acc": 53.0, "val_loss": 17.309284210205078, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17597937583923, "training_acc": 53.0, "val_loss": 17.308717966079712, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16373920440674, "training_acc": 53.0, "val_loss": 17.309066653251648, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1186408996582, "training_acc": 53.0, "val_loss": 17.310534417629242, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17548370361328, "training_acc": 53.0, "val_loss": 17.314045131206512, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12402820587158, "training_acc": 53.0, "val_loss": 17.316707968711853, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11707425117493, "training_acc": 53.0, "val_loss": 17.31705367565155, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19501852989197, "training_acc": 53.0, "val_loss": 17.317141592502594, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.10419535636902, "training_acc": 53.0, "val_loss": 17.31240302324295, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11312937736511, "training_acc": 53.0, "val_loss": 17.309221625328064, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18929266929626, "training_acc": 53.0, "val_loss": 17.308753728866577, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15672302246094, "training_acc": 53.0, "val_loss": 17.308756709098816, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.17556405067444, "training_acc": 53.0, "val_loss": 17.30899214744568, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22060132026672, "training_acc": 53.0, "val_loss": 17.30874925851822, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15486145019531, "training_acc": 53.0, "val_loss": 17.309333384037018, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.22497892379761, "training_acc": 53.0, "val_loss": 17.312853038311005, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12117910385132, "training_acc": 53.0, "val_loss": 17.314167320728302, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12212681770325, "training_acc": 53.0, "val_loss": 17.313480377197266, "val_acc": 52.0}
