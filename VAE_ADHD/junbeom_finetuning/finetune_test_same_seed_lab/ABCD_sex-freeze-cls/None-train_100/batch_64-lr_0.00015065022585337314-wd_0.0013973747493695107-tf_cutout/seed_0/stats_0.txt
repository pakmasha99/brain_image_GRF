"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26270341873169, "training_acc": 52.0, "val_loss": 17.25389212369919, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.260333776474, "training_acc": 52.0, "val_loss": 17.203953862190247, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2841432094574, "training_acc": 52.0, "val_loss": 17.202861607074738, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26193594932556, "training_acc": 52.0, "val_loss": 17.229680716991425, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24559545516968, "training_acc": 52.0, "val_loss": 17.270565032958984, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2435314655304, "training_acc": 52.0, "val_loss": 17.283672094345093, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.28716373443604, "training_acc": 52.0, "val_loss": 17.30334460735321, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2953782081604, "training_acc": 52.0, "val_loss": 17.29893386363983, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.34344744682312, "training_acc": 52.0, "val_loss": 17.27134734392166, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26426243782043, "training_acc": 52.0, "val_loss": 17.265479266643524, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23140954971313, "training_acc": 52.0, "val_loss": 17.25803315639496, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26122307777405, "training_acc": 52.0, "val_loss": 17.2453373670578, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23361992835999, "training_acc": 52.0, "val_loss": 17.2358438372612, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23294043540955, "training_acc": 52.0, "val_loss": 17.235778272151947, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24094295501709, "training_acc": 52.0, "val_loss": 17.228874564170837, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24992442131042, "training_acc": 52.0, "val_loss": 17.21876561641693, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25536966323853, "training_acc": 52.0, "val_loss": 17.203521728515625, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24385929107666, "training_acc": 52.0, "val_loss": 17.19849407672882, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25502038002014, "training_acc": 52.0, "val_loss": 17.198093235492706, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26667523384094, "training_acc": 52.0, "val_loss": 17.201492190361023, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22149395942688, "training_acc": 52.0, "val_loss": 17.21220314502716, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24302792549133, "training_acc": 52.0, "val_loss": 17.219342291355133, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29270124435425, "training_acc": 52.0, "val_loss": 17.21605807542801, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25161242485046, "training_acc": 52.0, "val_loss": 17.22680628299713, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24854350090027, "training_acc": 52.0, "val_loss": 17.244113981723785, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.26058316230774, "training_acc": 52.0, "val_loss": 17.265963554382324, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.33708620071411, "training_acc": 52.0, "val_loss": 17.267394065856934, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.24275159835815, "training_acc": 52.0, "val_loss": 17.29084551334381, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.29079341888428, "training_acc": 52.0, "val_loss": 17.305561900138855, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.29614639282227, "training_acc": 52.0, "val_loss": 17.293991148471832, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.36176538467407, "training_acc": 52.0, "val_loss": 17.268753051757812, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29069757461548, "training_acc": 52.0, "val_loss": 17.266082763671875, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25285005569458, "training_acc": 52.0, "val_loss": 17.242752015590668, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24105787277222, "training_acc": 52.0, "val_loss": 17.22649782896042, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26611685752869, "training_acc": 52.0, "val_loss": 17.21058189868927, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24060416221619, "training_acc": 52.0, "val_loss": 17.20576286315918, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.24510884284973, "training_acc": 52.0, "val_loss": 17.204035818576813, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.26995491981506, "training_acc": 52.0, "val_loss": 17.202821373939514, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.25490975379944, "training_acc": 52.0, "val_loss": 17.194415628910065, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.28845310211182, "training_acc": 52.0, "val_loss": 17.181698977947235, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.26625895500183, "training_acc": 52.0, "val_loss": 17.18229502439499, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28513789176941, "training_acc": 52.0, "val_loss": 17.18679815530777, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27780270576477, "training_acc": 52.0, "val_loss": 17.194022238254547, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22548651695251, "training_acc": 52.0, "val_loss": 17.21023917198181, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26303887367249, "training_acc": 52.0, "val_loss": 17.24276840686798, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.22972989082336, "training_acc": 52.0, "val_loss": 17.267189919948578, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.26678133010864, "training_acc": 52.0, "val_loss": 17.290915548801422, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.28858280181885, "training_acc": 52.0, "val_loss": 17.306819558143616, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.2771372795105, "training_acc": 52.0, "val_loss": 17.299124598503113, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.29164743423462, "training_acc": 52.0, "val_loss": 17.28612929582596, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.28939533233643, "training_acc": 52.0, "val_loss": 17.279154062271118, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.27211380004883, "training_acc": 52.0, "val_loss": 17.273709177970886, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.2773449420929, "training_acc": 52.0, "val_loss": 17.26604551076889, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26990556716919, "training_acc": 52.0, "val_loss": 17.261654138565063, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21510720252991, "training_acc": 52.0, "val_loss": 17.256954312324524, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26747488975525, "training_acc": 52.0, "val_loss": 17.244523763656616, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24008536338806, "training_acc": 52.0, "val_loss": 17.24214106798172, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23540806770325, "training_acc": 52.0, "val_loss": 17.24494844675064, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22445487976074, "training_acc": 52.0, "val_loss": 17.24051982164383, "val_acc": 56.0}
