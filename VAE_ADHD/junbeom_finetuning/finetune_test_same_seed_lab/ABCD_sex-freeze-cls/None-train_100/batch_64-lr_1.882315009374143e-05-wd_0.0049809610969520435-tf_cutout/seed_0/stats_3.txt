"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26402473449707, "training_acc": 53.0, "val_loss": 17.312972247600555, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2169349193573, "training_acc": 53.0, "val_loss": 17.313075065612793, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2049629688263, "training_acc": 53.0, "val_loss": 17.312583327293396, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18928837776184, "training_acc": 53.0, "val_loss": 17.311811447143555, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22453808784485, "training_acc": 53.0, "val_loss": 17.3112690448761, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1840431690216, "training_acc": 53.0, "val_loss": 17.310696840286255, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16750001907349, "training_acc": 53.0, "val_loss": 17.310237884521484, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18352484703064, "training_acc": 53.0, "val_loss": 17.309802770614624, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1667788028717, "training_acc": 53.0, "val_loss": 17.309625446796417, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16948223114014, "training_acc": 53.0, "val_loss": 17.30950176715851, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17161870002747, "training_acc": 53.0, "val_loss": 17.30947494506836, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13365912437439, "training_acc": 53.0, "val_loss": 17.30949431657791, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16459631919861, "training_acc": 53.0, "val_loss": 17.3095241189003, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14999485015869, "training_acc": 53.0, "val_loss": 17.30954647064209, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16585850715637, "training_acc": 53.0, "val_loss": 17.309558391571045, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18590903282166, "training_acc": 53.0, "val_loss": 17.309550940990448, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17273259162903, "training_acc": 53.0, "val_loss": 17.30956733226776, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16454410552979, "training_acc": 53.0, "val_loss": 17.309610545635223, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12767791748047, "training_acc": 53.0, "val_loss": 17.30968803167343, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19828915596008, "training_acc": 53.0, "val_loss": 17.309746146202087, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16285228729248, "training_acc": 53.0, "val_loss": 17.309825122356415, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15682220458984, "training_acc": 53.0, "val_loss": 17.309924960136414, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14154124259949, "training_acc": 53.0, "val_loss": 17.310015857219696, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12669086456299, "training_acc": 53.0, "val_loss": 17.31007546186447, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16344404220581, "training_acc": 53.0, "val_loss": 17.310313880443573, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16354298591614, "training_acc": 53.0, "val_loss": 17.310695350170135, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13575100898743, "training_acc": 53.0, "val_loss": 17.311055958271027, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12437510490417, "training_acc": 53.0, "val_loss": 17.311154305934906, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15548276901245, "training_acc": 53.0, "val_loss": 17.311157286167145, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16116571426392, "training_acc": 53.0, "val_loss": 17.311321198940277, "val_acc": 52.0}
