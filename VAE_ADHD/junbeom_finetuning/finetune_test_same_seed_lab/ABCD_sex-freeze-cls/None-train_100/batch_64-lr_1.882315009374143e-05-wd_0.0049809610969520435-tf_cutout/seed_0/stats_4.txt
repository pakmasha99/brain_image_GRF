"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.98493766784668, "training_acc": 47.0, "val_loss": 17.653372883796692, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.8210756778717, "training_acc": 47.0, "val_loss": 17.62131303548813, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.69774866104126, "training_acc": 47.0, "val_loss": 17.590835690498352, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.54723858833313, "training_acc": 47.0, "val_loss": 17.562252283096313, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.41221570968628, "training_acc": 47.0, "val_loss": 17.53525733947754, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.3042504787445, "training_acc": 47.0, "val_loss": 17.510107159614563, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.18858075141907, "training_acc": 47.0, "val_loss": 17.486824095249176, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.06674575805664, "training_acc": 47.0, "val_loss": 17.465151846408844, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.99368023872375, "training_acc": 47.0, "val_loss": 17.445817589759827, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.87385821342468, "training_acc": 47.0, "val_loss": 17.429423332214355, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.7718665599823, "training_acc": 47.0, "val_loss": 17.414219677448273, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.77229905128479, "training_acc": 47.0, "val_loss": 17.400334775447845, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.66526293754578, "training_acc": 47.0, "val_loss": 17.38831102848053, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.62300491333008, "training_acc": 47.0, "val_loss": 17.378003895282745, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.57554745674133, "training_acc": 47.0, "val_loss": 17.368468642234802, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.52205204963684, "training_acc": 47.0, "val_loss": 17.35982596874237, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.4716112613678, "training_acc": 47.0, "val_loss": 17.351923882961273, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.40468192100525, "training_acc": 47.0, "val_loss": 17.34435260295868, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.3912000656128, "training_acc": 47.0, "val_loss": 17.33785569667816, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.3554368019104, "training_acc": 47.0, "val_loss": 17.33260303735733, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.31475877761841, "training_acc": 48.0, "val_loss": 17.32834428548813, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29063010215759, "training_acc": 55.0, "val_loss": 17.324694991111755, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.276127576828, "training_acc": 53.0, "val_loss": 17.32138842344284, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.26969981193542, "training_acc": 53.0, "val_loss": 17.318835854530334, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22642588615417, "training_acc": 53.0, "val_loss": 17.31681078672409, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.21999096870422, "training_acc": 53.0, "val_loss": 17.314842343330383, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2210476398468, "training_acc": 53.0, "val_loss": 17.313510179519653, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18772602081299, "training_acc": 53.0, "val_loss": 17.312514781951904, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.18088293075562, "training_acc": 53.0, "val_loss": 17.311634123325348, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.20026898384094, "training_acc": 53.0, "val_loss": 17.311054468154907, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17244124412537, "training_acc": 53.0, "val_loss": 17.310714721679688, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.16209745407104, "training_acc": 53.0, "val_loss": 17.310577630996704, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18083548545837, "training_acc": 53.0, "val_loss": 17.310558259487152, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.12724161148071, "training_acc": 53.0, "val_loss": 17.310670018196106, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15479350090027, "training_acc": 53.0, "val_loss": 17.3108771443367, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15245318412781, "training_acc": 53.0, "val_loss": 17.3111230134964, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.12323522567749, "training_acc": 53.0, "val_loss": 17.311403155326843, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12758159637451, "training_acc": 53.0, "val_loss": 17.31170415878296, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15009093284607, "training_acc": 53.0, "val_loss": 17.312055826187134, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.11234593391418, "training_acc": 53.0, "val_loss": 17.31245368719101, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14365983009338, "training_acc": 53.0, "val_loss": 17.312903702259064, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12670755386353, "training_acc": 53.0, "val_loss": 17.31320470571518, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12723445892334, "training_acc": 53.0, "val_loss": 17.313547432422638, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.10090565681458, "training_acc": 53.0, "val_loss": 17.3139289021492, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.12453436851501, "training_acc": 53.0, "val_loss": 17.31424331665039, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.12315440177917, "training_acc": 53.0, "val_loss": 17.314831912517548, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15355610847473, "training_acc": 53.0, "val_loss": 17.31511652469635, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.1423487663269, "training_acc": 53.0, "val_loss": 17.315202951431274, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.15209078788757, "training_acc": 53.0, "val_loss": 17.31513738632202, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.12737965583801, "training_acc": 53.0, "val_loss": 17.314767837524414, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.1496570110321, "training_acc": 53.0, "val_loss": 17.314550280570984, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.15419054031372, "training_acc": 53.0, "val_loss": 17.314498126506805, "val_acc": 52.0}
