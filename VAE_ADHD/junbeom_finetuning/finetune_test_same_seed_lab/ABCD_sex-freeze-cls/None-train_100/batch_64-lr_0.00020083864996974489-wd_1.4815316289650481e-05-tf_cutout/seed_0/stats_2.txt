"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23836994171143, "training_acc": 53.0, "val_loss": 17.31027513742447, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.26346135139465, "training_acc": 53.0, "val_loss": 17.316994071006775, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12242341041565, "training_acc": 53.0, "val_loss": 17.31199026107788, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18460249900818, "training_acc": 53.0, "val_loss": 17.30915755033493, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.3063895702362, "training_acc": 53.0, "val_loss": 17.31034815311432, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16450047492981, "training_acc": 53.0, "val_loss": 17.309169471263885, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15273070335388, "training_acc": 53.0, "val_loss": 17.311255633831024, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12267398834229, "training_acc": 53.0, "val_loss": 17.316490411758423, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1748297214508, "training_acc": 53.0, "val_loss": 17.326022684574127, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18877696990967, "training_acc": 53.0, "val_loss": 17.331252992153168, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16201090812683, "training_acc": 53.0, "val_loss": 17.3258438706398, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12526106834412, "training_acc": 53.0, "val_loss": 17.31729507446289, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23629927635193, "training_acc": 53.0, "val_loss": 17.310768365859985, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13529634475708, "training_acc": 53.0, "val_loss": 17.310184240341187, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13439154624939, "training_acc": 53.0, "val_loss": 17.309480905532837, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14738965034485, "training_acc": 53.0, "val_loss": 17.309173941612244, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14317440986633, "training_acc": 53.0, "val_loss": 17.309676110744476, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16050696372986, "training_acc": 53.0, "val_loss": 17.309477925300598, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18550491333008, "training_acc": 53.0, "val_loss": 17.309165000915527, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14135384559631, "training_acc": 53.0, "val_loss": 17.31240749359131, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.24844861030579, "training_acc": 53.0, "val_loss": 17.321449518203735, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15167951583862, "training_acc": 53.0, "val_loss": 17.323748767375946, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13359069824219, "training_acc": 53.0, "val_loss": 17.330539226531982, "val_acc": 52.0}
