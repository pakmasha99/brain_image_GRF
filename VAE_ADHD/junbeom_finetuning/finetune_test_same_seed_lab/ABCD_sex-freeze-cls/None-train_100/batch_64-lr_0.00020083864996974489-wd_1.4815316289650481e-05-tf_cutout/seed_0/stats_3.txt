"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.56999635696411, "training_acc": 45.0, "val_loss": 17.32793003320694, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.31182026863098, "training_acc": 52.0, "val_loss": 17.31235235929489, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18911838531494, "training_acc": 53.0, "val_loss": 17.332512140274048, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17899489402771, "training_acc": 53.0, "val_loss": 17.34805703163147, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22986578941345, "training_acc": 53.0, "val_loss": 17.34350174665451, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18352890014648, "training_acc": 53.0, "val_loss": 17.343181371688843, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15374708175659, "training_acc": 53.0, "val_loss": 17.332185804843903, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1555027961731, "training_acc": 53.0, "val_loss": 17.320068180561066, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12336015701294, "training_acc": 53.0, "val_loss": 17.311939597129822, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13952684402466, "training_acc": 53.0, "val_loss": 17.311064898967743, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21126174926758, "training_acc": 53.0, "val_loss": 17.31172204017639, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1673858165741, "training_acc": 53.0, "val_loss": 17.3135906457901, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.23947262763977, "training_acc": 53.0, "val_loss": 17.315104603767395, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21275019645691, "training_acc": 53.0, "val_loss": 17.31705665588379, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23135113716125, "training_acc": 53.0, "val_loss": 17.31325089931488, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16753339767456, "training_acc": 53.0, "val_loss": 17.311179637908936, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1991195678711, "training_acc": 53.0, "val_loss": 17.3133447766304, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14075660705566, "training_acc": 53.0, "val_loss": 17.31783002614975, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2000298500061, "training_acc": 53.0, "val_loss": 17.32654869556427, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19137859344482, "training_acc": 53.0, "val_loss": 17.328983545303345, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16084361076355, "training_acc": 53.0, "val_loss": 17.32412278652191, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13766026496887, "training_acc": 53.0, "val_loss": 17.319244146347046, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15620732307434, "training_acc": 53.0, "val_loss": 17.314475774765015, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.20159816741943, "training_acc": 53.0, "val_loss": 17.312738299369812, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14222383499146, "training_acc": 53.0, "val_loss": 17.314115166664124, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15088725090027, "training_acc": 53.0, "val_loss": 17.31843203306198, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17151141166687, "training_acc": 53.0, "val_loss": 17.320983111858368, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15066170692444, "training_acc": 53.0, "val_loss": 17.32231080532074, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19712090492249, "training_acc": 53.0, "val_loss": 17.318493127822876, "val_acc": 52.0}
