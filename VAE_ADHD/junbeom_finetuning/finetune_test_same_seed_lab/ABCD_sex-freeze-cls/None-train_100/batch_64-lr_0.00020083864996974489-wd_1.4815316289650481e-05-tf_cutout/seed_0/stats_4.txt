"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.0960943698883, "training_acc": 47.0, "val_loss": 17.647390067577362, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.83155179023743, "training_acc": 47.0, "val_loss": 17.41245537996292, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.50766491889954, "training_acc": 47.0, "val_loss": 17.322444915771484, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.08993458747864, "training_acc": 53.0, "val_loss": 17.319034039974213, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.04512429237366, "training_acc": 53.0, "val_loss": 17.372146248817444, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2483217716217, "training_acc": 53.0, "val_loss": 17.444591224193573, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.58428907394409, "training_acc": 53.0, "val_loss": 17.500978708267212, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.6678237915039, "training_acc": 53.0, "val_loss": 17.502030730247498, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.65542578697205, "training_acc": 53.0, "val_loss": 17.4673929810524, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.57928586006165, "training_acc": 53.0, "val_loss": 17.419886589050293, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.37103295326233, "training_acc": 53.0, "val_loss": 17.380213737487793, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25731015205383, "training_acc": 53.0, "val_loss": 17.343562841415405, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14290428161621, "training_acc": 53.0, "val_loss": 17.32112467288971, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1365966796875, "training_acc": 53.0, "val_loss": 17.31167584657669, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23888444900513, "training_acc": 53.0, "val_loss": 17.313311994075775, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20810151100159, "training_acc": 53.0, "val_loss": 17.31540709733963, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21526455879211, "training_acc": 53.0, "val_loss": 17.314641177654266, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.23404550552368, "training_acc": 53.0, "val_loss": 17.313896119594574, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.25776100158691, "training_acc": 53.0, "val_loss": 17.311426997184753, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17981815338135, "training_acc": 53.0, "val_loss": 17.31158047914505, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.19233250617981, "training_acc": 53.0, "val_loss": 17.313364148139954, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16322755813599, "training_acc": 53.0, "val_loss": 17.314505577087402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21636581420898, "training_acc": 53.0, "val_loss": 17.314280569553375, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12714719772339, "training_acc": 53.0, "val_loss": 17.317092418670654, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22915172576904, "training_acc": 53.0, "val_loss": 17.32238382101059, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18824696540833, "training_acc": 53.0, "val_loss": 17.32051819562912, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1391134262085, "training_acc": 53.0, "val_loss": 17.322680354118347, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1430356502533, "training_acc": 53.0, "val_loss": 17.32349395751953, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15800881385803, "training_acc": 53.0, "val_loss": 17.32524484395981, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1603856086731, "training_acc": 53.0, "val_loss": 17.330925166606903, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13902759552002, "training_acc": 53.0, "val_loss": 17.335182428359985, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17217969894409, "training_acc": 53.0, "val_loss": 17.3393651843071, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17089319229126, "training_acc": 53.0, "val_loss": 17.33710616827011, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.19672274589539, "training_acc": 53.0, "val_loss": 17.331866919994354, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17627453804016, "training_acc": 53.0, "val_loss": 17.32698380947113, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.17051029205322, "training_acc": 53.0, "val_loss": 17.32446253299713, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14511847496033, "training_acc": 53.0, "val_loss": 17.322570085525513, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13432717323303, "training_acc": 53.0, "val_loss": 17.320144176483154, "val_acc": 52.0}
