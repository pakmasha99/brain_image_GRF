"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24176025390625, "training_acc": 53.0, "val_loss": 17.310091853141785, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.27007246017456, "training_acc": 53.0, "val_loss": 17.317083477973938, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1237142086029, "training_acc": 53.0, "val_loss": 17.312003672122955, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18531155586243, "training_acc": 53.0, "val_loss": 17.30918288230896, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.31098508834839, "training_acc": 53.0, "val_loss": 17.31046289205551, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16614890098572, "training_acc": 53.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15207242965698, "training_acc": 53.0, "val_loss": 17.311450839042664, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12191653251648, "training_acc": 53.0, "val_loss": 17.317073047161102, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17619705200195, "training_acc": 53.0, "val_loss": 17.327120900154114, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19179964065552, "training_acc": 53.0, "val_loss": 17.332348227500916, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16338157653809, "training_acc": 53.0, "val_loss": 17.32625961303711, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12456583976746, "training_acc": 53.0, "val_loss": 17.317111790180206, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.24055051803589, "training_acc": 53.0, "val_loss": 17.310498654842377, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13596653938293, "training_acc": 53.0, "val_loss": 17.309944331645966, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.13591885566711, "training_acc": 53.0, "val_loss": 17.30934828519821, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14920139312744, "training_acc": 53.0, "val_loss": 17.309238016605377, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14558696746826, "training_acc": 53.0, "val_loss": 17.30983257293701, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16232776641846, "training_acc": 53.0, "val_loss": 17.309536039829254, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1852114200592, "training_acc": 53.0, "val_loss": 17.309169471263885, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14019322395325, "training_acc": 53.0, "val_loss": 17.312806844711304, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2527506351471, "training_acc": 53.0, "val_loss": 17.322686314582825, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15430092811584, "training_acc": 53.0, "val_loss": 17.32506901025772, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13615989685059, "training_acc": 53.0, "val_loss": 17.332051694393158, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17150235176086, "training_acc": 53.0, "val_loss": 17.33485758304596, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.19176602363586, "training_acc": 53.0, "val_loss": 17.333395779132843, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19087171554565, "training_acc": 53.0, "val_loss": 17.323443293571472, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14256954193115, "training_acc": 53.0, "val_loss": 17.316962778568268, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1307110786438, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16587829589844, "training_acc": 53.0, "val_loss": 17.310798168182373, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14832663536072, "training_acc": 53.0, "val_loss": 17.310434579849243, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13567686080933, "training_acc": 53.0, "val_loss": 17.3116534948349, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13147830963135, "training_acc": 53.0, "val_loss": 17.31247305870056, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12398552894592, "training_acc": 53.0, "val_loss": 17.31175184249878, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14752316474915, "training_acc": 53.0, "val_loss": 17.311424016952515, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15995764732361, "training_acc": 53.0, "val_loss": 17.311343550682068, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13951063156128, "training_acc": 53.0, "val_loss": 17.313162982463837, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17669010162354, "training_acc": 53.0, "val_loss": 17.314666509628296, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15580105781555, "training_acc": 53.0, "val_loss": 17.321382462978363, "val_acc": 52.0}
