"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.38439393043518, "training_acc": 47.0, "val_loss": 17.499850690364838, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.76084065437317, "training_acc": 47.0, "val_loss": 17.33671873807907, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.36194229125977, "training_acc": 51.0, "val_loss": 17.322373390197754, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.15848135948181, "training_acc": 53.0, "val_loss": 17.38540381193161, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4405255317688, "training_acc": 53.0, "val_loss": 17.44602918624878, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.49156785011292, "training_acc": 53.0, "val_loss": 17.449679970741272, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.50443530082703, "training_acc": 53.0, "val_loss": 17.418862879276276, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.40621566772461, "training_acc": 53.0, "val_loss": 17.386901378631592, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.26411318778992, "training_acc": 53.0, "val_loss": 17.355479300022125, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.3207278251648, "training_acc": 53.0, "val_loss": 17.327716946601868, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12685346603394, "training_acc": 53.0, "val_loss": 17.318980395793915, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16181063652039, "training_acc": 53.0, "val_loss": 17.31344163417816, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11700940132141, "training_acc": 53.0, "val_loss": 17.313823103904724, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16968417167664, "training_acc": 53.0, "val_loss": 17.31676459312439, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27902913093567, "training_acc": 53.0, "val_loss": 17.320621013641357, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24866104125977, "training_acc": 53.0, "val_loss": 17.317359149456024, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2962486743927, "training_acc": 53.0, "val_loss": 17.313586175441742, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17635464668274, "training_acc": 53.0, "val_loss": 17.313285171985626, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15827679634094, "training_acc": 53.0, "val_loss": 17.315128445625305, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11740183830261, "training_acc": 53.0, "val_loss": 17.319872975349426, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13382458686829, "training_acc": 53.0, "val_loss": 17.327655851840973, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13977241516113, "training_acc": 53.0, "val_loss": 17.341309785842896, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16434955596924, "training_acc": 53.0, "val_loss": 17.35297292470932, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.2385048866272, "training_acc": 53.0, "val_loss": 17.362011969089508, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.24830365180969, "training_acc": 53.0, "val_loss": 17.358727753162384, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.23463559150696, "training_acc": 53.0, "val_loss": 17.348583042621613, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21599698066711, "training_acc": 53.0, "val_loss": 17.337900400161743, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20554614067078, "training_acc": 53.0, "val_loss": 17.330554127693176, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14431476593018, "training_acc": 53.0, "val_loss": 17.324939370155334, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16084289550781, "training_acc": 53.0, "val_loss": 17.320135235786438, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13177561759949, "training_acc": 53.0, "val_loss": 17.31768250465393, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15584111213684, "training_acc": 53.0, "val_loss": 17.316068708896637, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.15590691566467, "training_acc": 53.0, "val_loss": 17.315156757831573, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15795230865479, "training_acc": 53.0, "val_loss": 17.315325140953064, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.19914555549622, "training_acc": 53.0, "val_loss": 17.316657304763794, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16826272010803, "training_acc": 53.0, "val_loss": 17.315112054347992, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16104626655579, "training_acc": 53.0, "val_loss": 17.31441020965576, "val_acc": 52.0}
