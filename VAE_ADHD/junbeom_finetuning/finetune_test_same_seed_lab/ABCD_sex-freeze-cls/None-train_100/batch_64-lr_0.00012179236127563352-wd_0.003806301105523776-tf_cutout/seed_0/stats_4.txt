"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 74.7204852104187, "training_acc": 47.0, "val_loss": 18.334880471229553, "val_acc": 44.0}
{"epoch": 1, "training_loss": 73.3543655872345, "training_acc": 47.0, "val_loss": 18.006503582000732, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.20485234260559, "training_acc": 47.0, "val_loss": 17.748118937015533, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.93401598930359, "training_acc": 47.0, "val_loss": 17.562678456306458, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.1014711856842, "training_acc": 47.0, "val_loss": 17.43055433034897, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.58992099761963, "training_acc": 47.0, "val_loss": 17.349284887313843, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.29835724830627, "training_acc": 53.0, "val_loss": 17.312195897102356, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2643494606018, "training_acc": 53.0, "val_loss": 17.310436069965363, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14083075523376, "training_acc": 53.0, "val_loss": 17.329677939414978, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14011740684509, "training_acc": 53.0, "val_loss": 17.35696792602539, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.19219064712524, "training_acc": 53.0, "val_loss": 17.38368719816208, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.35774540901184, "training_acc": 53.0, "val_loss": 17.407383024692535, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.38741135597229, "training_acc": 53.0, "val_loss": 17.41834580898285, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.44797468185425, "training_acc": 53.0, "val_loss": 17.41788685321808, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.41455507278442, "training_acc": 53.0, "val_loss": 17.404620349407196, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.4062271118164, "training_acc": 53.0, "val_loss": 17.386144399642944, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.30321550369263, "training_acc": 53.0, "val_loss": 17.370164394378662, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.25016188621521, "training_acc": 53.0, "val_loss": 17.354951798915863, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2630205154419, "training_acc": 53.0, "val_loss": 17.33856499195099, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19451928138733, "training_acc": 53.0, "val_loss": 17.329373955726624, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1644127368927, "training_acc": 53.0, "val_loss": 17.31930822134018, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12584257125854, "training_acc": 53.0, "val_loss": 17.313440144062042, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12212300300598, "training_acc": 53.0, "val_loss": 17.30930358171463, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17451167106628, "training_acc": 53.0, "val_loss": 17.30768233537674, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18981504440308, "training_acc": 53.0, "val_loss": 17.307697236537933, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16049981117249, "training_acc": 53.0, "val_loss": 17.30770617723465, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.21920990943909, "training_acc": 53.0, "val_loss": 17.308010160923004, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14413452148438, "training_acc": 53.0, "val_loss": 17.307807505130768, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14069128036499, "training_acc": 53.0, "val_loss": 17.307664453983307, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14129710197449, "training_acc": 53.0, "val_loss": 17.30782240629196, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13260221481323, "training_acc": 53.0, "val_loss": 17.30932891368866, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.08120727539062, "training_acc": 53.0, "val_loss": 17.31218546628952, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13593792915344, "training_acc": 53.0, "val_loss": 17.316657304763794, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14146137237549, "training_acc": 53.0, "val_loss": 17.320305109024048, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1370017528534, "training_acc": 53.0, "val_loss": 17.322780191898346, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13197135925293, "training_acc": 53.0, "val_loss": 17.32453852891922, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1404218673706, "training_acc": 53.0, "val_loss": 17.326463758945465, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.18764996528625, "training_acc": 53.0, "val_loss": 17.327594757080078, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.16952443122864, "training_acc": 53.0, "val_loss": 17.32693463563919, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.16134572029114, "training_acc": 53.0, "val_loss": 17.325879633426666, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.11613178253174, "training_acc": 53.0, "val_loss": 17.32373833656311, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.1608898639679, "training_acc": 53.0, "val_loss": 17.321081459522247, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.14407968521118, "training_acc": 53.0, "val_loss": 17.319011688232422, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.14663052558899, "training_acc": 53.0, "val_loss": 17.317740619182587, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13915634155273, "training_acc": 53.0, "val_loss": 17.313936352729797, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.14775776863098, "training_acc": 53.0, "val_loss": 17.311367392539978, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.10422539710999, "training_acc": 53.0, "val_loss": 17.30985939502716, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.13171529769897, "training_acc": 53.0, "val_loss": 17.308589816093445, "val_acc": 52.0}
