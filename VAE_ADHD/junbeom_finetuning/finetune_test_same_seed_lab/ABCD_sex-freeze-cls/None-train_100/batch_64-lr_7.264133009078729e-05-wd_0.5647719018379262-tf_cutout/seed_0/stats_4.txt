"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.1559112071991, "training_acc": 47.0, "val_loss": 17.42720901966095, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.80973172187805, "training_acc": 47.0, "val_loss": 17.388588190078735, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.62394118309021, "training_acc": 47.0, "val_loss": 17.35198348760605, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.46990537643433, "training_acc": 47.0, "val_loss": 17.32531189918518, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38768458366394, "training_acc": 38.0, "val_loss": 17.310863733291626, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22225975990295, "training_acc": 53.0, "val_loss": 17.304539680480957, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16926693916321, "training_acc": 53.0, "val_loss": 17.30276048183441, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11529684066772, "training_acc": 53.0, "val_loss": 17.304614186286926, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11010456085205, "training_acc": 53.0, "val_loss": 17.30894297361374, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12484002113342, "training_acc": 53.0, "val_loss": 17.316390573978424, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14776659011841, "training_acc": 53.0, "val_loss": 17.323851585388184, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16468119621277, "training_acc": 53.0, "val_loss": 17.327943444252014, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17235589027405, "training_acc": 53.0, "val_loss": 17.328082025051117, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19333600997925, "training_acc": 53.0, "val_loss": 17.326435446739197, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16555404663086, "training_acc": 53.0, "val_loss": 17.325370013713837, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15230298042297, "training_acc": 53.0, "val_loss": 17.321589589118958, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20390462875366, "training_acc": 53.0, "val_loss": 17.31763929128647, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14013767242432, "training_acc": 53.0, "val_loss": 17.317254841327667, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13824367523193, "training_acc": 53.0, "val_loss": 17.314600944519043, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14370679855347, "training_acc": 53.0, "val_loss": 17.312084138393402, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1098415851593, "training_acc": 53.0, "val_loss": 17.31175184249878, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12405776977539, "training_acc": 53.0, "val_loss": 17.311204969882965, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13752675056458, "training_acc": 53.0, "val_loss": 17.310580611228943, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12893033027649, "training_acc": 53.0, "val_loss": 17.309032380580902, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13082242012024, "training_acc": 53.0, "val_loss": 17.308074235916138, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13133692741394, "training_acc": 53.0, "val_loss": 17.308418452739716, "val_acc": 52.0}
