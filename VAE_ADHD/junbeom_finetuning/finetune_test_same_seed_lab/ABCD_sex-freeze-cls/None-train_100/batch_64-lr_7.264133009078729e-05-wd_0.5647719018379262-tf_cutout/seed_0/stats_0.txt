"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24051403999329, "training_acc": 52.0, "val_loss": 17.241378128528595, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23682713508606, "training_acc": 52.0, "val_loss": 17.22101867198944, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25548267364502, "training_acc": 52.0, "val_loss": 17.21910834312439, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26372265815735, "training_acc": 52.0, "val_loss": 17.229437828063965, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24050068855286, "training_acc": 52.0, "val_loss": 17.24611073732376, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22642207145691, "training_acc": 52.0, "val_loss": 17.25214719772339, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26035141944885, "training_acc": 52.0, "val_loss": 17.26454198360443, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26000189781189, "training_acc": 52.0, "val_loss": 17.26970225572586, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27414655685425, "training_acc": 52.0, "val_loss": 17.263492941856384, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25720143318176, "training_acc": 52.0, "val_loss": 17.266365885734558, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23399448394775, "training_acc": 52.0, "val_loss": 17.26726144552231, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2643666267395, "training_acc": 52.0, "val_loss": 17.26348102092743, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23437190055847, "training_acc": 52.0, "val_loss": 17.258916795253754, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23908710479736, "training_acc": 52.0, "val_loss": 17.257380485534668, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24729442596436, "training_acc": 52.0, "val_loss": 17.250461876392365, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25059509277344, "training_acc": 52.0, "val_loss": 17.240703105926514, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25141453742981, "training_acc": 52.0, "val_loss": 17.226967215538025, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23345923423767, "training_acc": 52.0, "val_loss": 17.218109965324402, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24197459220886, "training_acc": 52.0, "val_loss": 17.21147894859314, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25919771194458, "training_acc": 52.0, "val_loss": 17.207016050815582, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20887279510498, "training_acc": 52.0, "val_loss": 17.206844687461853, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22989201545715, "training_acc": 52.0, "val_loss": 17.206287384033203, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29010486602783, "training_acc": 52.0, "val_loss": 17.202794551849365, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.2619354724884, "training_acc": 52.0, "val_loss": 17.206856608390808, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25868701934814, "training_acc": 52.0, "val_loss": 17.215056717395782, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24998331069946, "training_acc": 52.0, "val_loss": 17.22700297832489, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27908682823181, "training_acc": 52.0, "val_loss": 17.232243716716766, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22722792625427, "training_acc": 52.0, "val_loss": 17.247943580150604, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.2499053478241, "training_acc": 52.0, "val_loss": 17.262093722820282, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26419401168823, "training_acc": 52.0, "val_loss": 17.266735434532166, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27994537353516, "training_acc": 52.0, "val_loss": 17.26406216621399, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28375744819641, "training_acc": 52.0, "val_loss": 17.270036041736603, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.2519919872284, "training_acc": 52.0, "val_loss": 17.263486981391907, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25767302513123, "training_acc": 52.0, "val_loss": 17.25752204656601, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26112699508667, "training_acc": 52.0, "val_loss": 17.24841296672821, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23990631103516, "training_acc": 52.0, "val_loss": 17.24310964345932, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23718643188477, "training_acc": 52.0, "val_loss": 17.23763644695282, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23704075813293, "training_acc": 52.0, "val_loss": 17.231369018554688, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22871470451355, "training_acc": 52.0, "val_loss": 17.220473289489746, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25295805931091, "training_acc": 52.0, "val_loss": 17.20668226480484, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23313498497009, "training_acc": 52.0, "val_loss": 17.201022803783417, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25875949859619, "training_acc": 52.0, "val_loss": 17.197686433792114, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27208971977234, "training_acc": 52.0, "val_loss": 17.196068167686462, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24237513542175, "training_acc": 52.0, "val_loss": 17.199191451072693, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25624442100525, "training_acc": 52.0, "val_loss": 17.209529876708984, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24103736877441, "training_acc": 52.0, "val_loss": 17.217789590358734, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25434494018555, "training_acc": 52.0, "val_loss": 17.228102684020996, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24004864692688, "training_acc": 52.0, "val_loss": 17.238470911979675, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22542953491211, "training_acc": 52.0, "val_loss": 17.242832481861115, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23259162902832, "training_acc": 52.0, "val_loss": 17.24647879600525, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25406074523926, "training_acc": 52.0, "val_loss": 17.252951860427856, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25265860557556, "training_acc": 52.0, "val_loss": 17.25989133119583, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25898909568787, "training_acc": 52.0, "val_loss": 17.264850437641144, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26821231842041, "training_acc": 52.0, "val_loss": 17.269858717918396, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22497606277466, "training_acc": 52.0, "val_loss": 17.2729030251503, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26068472862244, "training_acc": 52.0, "val_loss": 17.269618809223175, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24986600875854, "training_acc": 52.0, "val_loss": 17.269372940063477, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24780702590942, "training_acc": 52.0, "val_loss": 17.270056903362274, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23873472213745, "training_acc": 52.0, "val_loss": 17.265309393405914, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26087951660156, "training_acc": 52.0, "val_loss": 17.260852456092834, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28203129768372, "training_acc": 52.0, "val_loss": 17.250825464725494, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23950982093811, "training_acc": 52.0, "val_loss": 17.246484756469727, "val_acc": 56.0}
