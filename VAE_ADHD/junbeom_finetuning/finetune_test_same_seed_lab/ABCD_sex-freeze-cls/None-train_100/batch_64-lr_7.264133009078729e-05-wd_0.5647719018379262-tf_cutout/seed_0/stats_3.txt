"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.35499048233032, "training_acc": 53.0, "val_loss": 17.309974133968353, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1772108078003, "training_acc": 53.0, "val_loss": 17.31012910604477, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15228366851807, "training_acc": 53.0, "val_loss": 17.310571670532227, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18417286872864, "training_acc": 53.0, "val_loss": 17.310135066509247, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15581727027893, "training_acc": 53.0, "val_loss": 17.309440672397614, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18613910675049, "training_acc": 53.0, "val_loss": 17.309242486953735, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14384603500366, "training_acc": 53.0, "val_loss": 17.309626936912537, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14320278167725, "training_acc": 53.0, "val_loss": 17.310477793216705, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12801909446716, "training_acc": 53.0, "val_loss": 17.311742901802063, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1343879699707, "training_acc": 53.0, "val_loss": 17.312870919704437, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15129685401917, "training_acc": 53.0, "val_loss": 17.313210666179657, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10955739021301, "training_acc": 53.0, "val_loss": 17.315421998500824, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13218283653259, "training_acc": 53.0, "val_loss": 17.318984866142273, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17513275146484, "training_acc": 53.0, "val_loss": 17.321662604808807, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14636325836182, "training_acc": 53.0, "val_loss": 17.320723831653595, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13485431671143, "training_acc": 53.0, "val_loss": 17.318569123744965, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13065648078918, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11758732795715, "training_acc": 53.0, "val_loss": 17.318053543567657, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11372399330139, "training_acc": 53.0, "val_loss": 17.317838966846466, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14386010169983, "training_acc": 53.0, "val_loss": 17.318381369113922, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14757919311523, "training_acc": 53.0, "val_loss": 17.317894101142883, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12130784988403, "training_acc": 53.0, "val_loss": 17.315299808979034, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14256310462952, "training_acc": 53.0, "val_loss": 17.31373965740204, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1160831451416, "training_acc": 53.0, "val_loss": 17.31267124414444, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10645604133606, "training_acc": 53.0, "val_loss": 17.311465740203857, "val_acc": 52.0}
