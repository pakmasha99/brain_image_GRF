"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.43202257156372, "training_acc": 47.0, "val_loss": 17.905902862548828, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.93770337104797, "training_acc": 47.0, "val_loss": 17.798709869384766, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.39098811149597, "training_acc": 47.0, "val_loss": 17.708486318588257, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.15838360786438, "training_acc": 47.0, "val_loss": 17.629356682300568, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.70901989936829, "training_acc": 47.0, "val_loss": 17.563487589359283, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.49928164482117, "training_acc": 47.0, "val_loss": 17.505404353141785, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.20930528640747, "training_acc": 47.0, "val_loss": 17.457790672779083, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.93212556838989, "training_acc": 47.0, "val_loss": 17.419320344924927, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.77079701423645, "training_acc": 47.0, "val_loss": 17.385531961917877, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.71340012550354, "training_acc": 47.0, "val_loss": 17.35852211713791, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42829155921936, "training_acc": 47.0, "val_loss": 17.340250313282013, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.42138838768005, "training_acc": 47.0, "val_loss": 17.325207591056824, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.29520916938782, "training_acc": 52.0, "val_loss": 17.31463521718979, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21272206306458, "training_acc": 53.0, "val_loss": 17.30760931968689, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20099115371704, "training_acc": 53.0, "val_loss": 17.303459346294403, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14098024368286, "training_acc": 53.0, "val_loss": 17.302151024341583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15601372718811, "training_acc": 53.0, "val_loss": 17.30302721261978, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13374638557434, "training_acc": 53.0, "val_loss": 17.3052579164505, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14575052261353, "training_acc": 53.0, "val_loss": 17.30816215276718, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13691449165344, "training_acc": 53.0, "val_loss": 17.311397194862366, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14096856117249, "training_acc": 53.0, "val_loss": 17.314907908439636, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13677167892456, "training_acc": 53.0, "val_loss": 17.318230867385864, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12652254104614, "training_acc": 53.0, "val_loss": 17.32083410024643, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16317582130432, "training_acc": 53.0, "val_loss": 17.322959005832672, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15996861457825, "training_acc": 53.0, "val_loss": 17.32420325279236, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1650607585907, "training_acc": 53.0, "val_loss": 17.32458472251892, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16694569587708, "training_acc": 53.0, "val_loss": 17.324577271938324, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15806221961975, "training_acc": 53.0, "val_loss": 17.324399948120117, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16647005081177, "training_acc": 53.0, "val_loss": 17.322151362895966, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15898180007935, "training_acc": 53.0, "val_loss": 17.31984317302704, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13928246498108, "training_acc": 53.0, "val_loss": 17.317643761634827, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13813042640686, "training_acc": 53.0, "val_loss": 17.315056920051575, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13985872268677, "training_acc": 53.0, "val_loss": 17.31204241514206, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15980267524719, "training_acc": 53.0, "val_loss": 17.30969250202179, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15836668014526, "training_acc": 53.0, "val_loss": 17.307887971401215, "val_acc": 52.0}
