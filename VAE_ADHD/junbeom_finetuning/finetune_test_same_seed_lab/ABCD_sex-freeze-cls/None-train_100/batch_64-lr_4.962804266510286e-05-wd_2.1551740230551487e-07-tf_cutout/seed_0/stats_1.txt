"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.18671774864197, "training_acc": 47.0, "val_loss": 17.459246516227722, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.93938183784485, "training_acc": 47.0, "val_loss": 17.42236316204071, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.68733954429626, "training_acc": 47.0, "val_loss": 17.388945817947388, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.55228805541992, "training_acc": 47.0, "val_loss": 17.3601895570755, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.42660808563232, "training_acc": 47.0, "val_loss": 17.339307069778442, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33787298202515, "training_acc": 47.0, "val_loss": 17.32458770275116, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.25925087928772, "training_acc": 53.0, "val_loss": 17.316821217536926, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15348839759827, "training_acc": 53.0, "val_loss": 17.314313352108, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16057872772217, "training_acc": 53.0, "val_loss": 17.314818501472473, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11515617370605, "training_acc": 53.0, "val_loss": 17.317935824394226, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15479016304016, "training_acc": 53.0, "val_loss": 17.322993278503418, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14765095710754, "training_acc": 53.0, "val_loss": 17.32805371284485, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1905300617218, "training_acc": 53.0, "val_loss": 17.331214249134064, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13329243659973, "training_acc": 53.0, "val_loss": 17.330989241600037, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1501693725586, "training_acc": 53.0, "val_loss": 17.32996106147766, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14640736579895, "training_acc": 53.0, "val_loss": 17.328692972660065, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13850164413452, "training_acc": 53.0, "val_loss": 17.327284812927246, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14498805999756, "training_acc": 53.0, "val_loss": 17.325806617736816, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19213557243347, "training_acc": 53.0, "val_loss": 17.32465773820877, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16894268989563, "training_acc": 53.0, "val_loss": 17.324115335941315, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15941333770752, "training_acc": 53.0, "val_loss": 17.323726415634155, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14477324485779, "training_acc": 53.0, "val_loss": 17.323945462703705, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12824130058289, "training_acc": 53.0, "val_loss": 17.322738468647003, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17451190948486, "training_acc": 53.0, "val_loss": 17.321090400218964, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14853692054749, "training_acc": 53.0, "val_loss": 17.320622503757477, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13882422447205, "training_acc": 53.0, "val_loss": 17.31925755739212, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.15098595619202, "training_acc": 53.0, "val_loss": 17.318393290042877, "val_acc": 52.0}
