"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 91.94134712219238, "training_acc": 50.0, "val_loss": 19.111540913581848, "val_acc": 44.0}
{"epoch": 1, "training_loss": 79.7110698223114, "training_acc": 48.0, "val_loss": 23.90475571155548, "val_acc": 56.0}
{"epoch": 2, "training_loss": 99.67554903030396, "training_acc": 52.0, "val_loss": 18.017251789569855, "val_acc": 56.0}
{"epoch": 3, "training_loss": 71.7222352027893, "training_acc": 54.0, "val_loss": 21.44065946340561, "val_acc": 44.0}
{"epoch": 4, "training_loss": 85.16123914718628, "training_acc": 48.0, "val_loss": 22.574105858802795, "val_acc": 44.0}
{"epoch": 5, "training_loss": 83.12007474899292, "training_acc": 48.0, "val_loss": 17.269176244735718, "val_acc": 56.0}
{"epoch": 6, "training_loss": 70.2344605922699, "training_acc": 52.0, "val_loss": 18.50452423095703, "val_acc": 56.0}
{"epoch": 7, "training_loss": 77.86355495452881, "training_acc": 52.0, "val_loss": 17.935551702976227, "val_acc": 56.0}
{"epoch": 8, "training_loss": 72.31080794334412, "training_acc": 52.0, "val_loss": 17.41648018360138, "val_acc": 56.0}
{"epoch": 9, "training_loss": 70.38426113128662, "training_acc": 48.0, "val_loss": 19.797110557556152, "val_acc": 44.0}
{"epoch": 10, "training_loss": 76.23939037322998, "training_acc": 48.0, "val_loss": 18.44819188117981, "val_acc": 56.0}
{"epoch": 11, "training_loss": 71.43575024604797, "training_acc": 48.0, "val_loss": 17.18468815088272, "val_acc": 56.0}
{"epoch": 12, "training_loss": 71.60712099075317, "training_acc": 52.0, "val_loss": 17.646987736225128, "val_acc": 56.0}
{"epoch": 13, "training_loss": 72.6663293838501, "training_acc": 52.0, "val_loss": 17.1492338180542, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.87924575805664, "training_acc": 48.0, "val_loss": 17.87239760160446, "val_acc": 56.0}
{"epoch": 15, "training_loss": 71.0695149898529, "training_acc": 48.0, "val_loss": 17.76197701692581, "val_acc": 56.0}
{"epoch": 16, "training_loss": 70.05664873123169, "training_acc": 48.0, "val_loss": 17.14882403612137, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.72431182861328, "training_acc": 52.0, "val_loss": 17.212435603141785, "val_acc": 56.0}
{"epoch": 18, "training_loss": 70.22864937782288, "training_acc": 52.0, "val_loss": 17.170825600624084, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.21259760856628, "training_acc": 52.0, "val_loss": 17.559203505516052, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.97106957435608, "training_acc": 48.0, "val_loss": 17.55019724369049, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.34827089309692, "training_acc": 48.0, "val_loss": 17.15492606163025, "val_acc": 56.0}
{"epoch": 22, "training_loss": 70.47832155227661, "training_acc": 52.0, "val_loss": 17.20288246870041, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.90701508522034, "training_acc": 52.0, "val_loss": 17.299042642116547, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21206212043762, "training_acc": 54.0, "val_loss": 17.960333824157715, "val_acc": 56.0}
{"epoch": 25, "training_loss": 70.8183982372284, "training_acc": 48.0, "val_loss": 17.511485517024994, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.86522555351257, "training_acc": 38.0, "val_loss": 17.156872153282166, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.64962720870972, "training_acc": 52.0, "val_loss": 17.220397293567657, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.8071014881134, "training_acc": 46.0, "val_loss": 17.51408278942108, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.53110241889954, "training_acc": 48.0, "val_loss": 17.21639335155487, "val_acc": 56.0}
{"epoch": 30, "training_loss": 70.7593686580658, "training_acc": 52.0, "val_loss": 17.150089144706726, "val_acc": 56.0}
{"epoch": 31, "training_loss": 70.65951204299927, "training_acc": 42.0, "val_loss": 17.368251085281372, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.36146903038025, "training_acc": 48.0, "val_loss": 17.243392765522003, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2343590259552, "training_acc": 52.0, "val_loss": 17.182546854019165, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.49249863624573, "training_acc": 52.0, "val_loss": 17.175574600696564, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.30103349685669, "training_acc": 52.0, "val_loss": 17.355887591838837, "val_acc": 56.0}
