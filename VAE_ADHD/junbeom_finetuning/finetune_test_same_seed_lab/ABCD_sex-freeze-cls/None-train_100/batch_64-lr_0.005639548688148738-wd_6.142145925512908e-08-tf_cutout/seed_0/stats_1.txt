"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 93.21022605895996, "training_acc": 54.0, "val_loss": 19.13156509399414, "val_acc": 52.0}
{"epoch": 1, "training_loss": 77.00761222839355, "training_acc": 51.0, "val_loss": 24.277091026306152, "val_acc": 48.0}
{"epoch": 2, "training_loss": 98.14324951171875, "training_acc": 47.0, "val_loss": 18.6479389667511, "val_acc": 48.0}
{"epoch": 3, "training_loss": 76.82501196861267, "training_acc": 43.0, "val_loss": 20.629961788654327, "val_acc": 52.0}
{"epoch": 4, "training_loss": 86.05647373199463, "training_acc": 53.0, "val_loss": 21.478068828582764, "val_acc": 52.0}
{"epoch": 5, "training_loss": 80.6076967716217, "training_acc": 53.0, "val_loss": 17.33262836933136, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.86149573326111, "training_acc": 47.0, "val_loss": 19.5926696062088, "val_acc": 48.0}
{"epoch": 7, "training_loss": 79.3076012134552, "training_acc": 47.0, "val_loss": 18.785591423511505, "val_acc": 48.0}
{"epoch": 8, "training_loss": 73.67852520942688, "training_acc": 47.0, "val_loss": 17.356275022029877, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.78696751594543, "training_acc": 53.0, "val_loss": 18.97399127483368, "val_acc": 52.0}
{"epoch": 10, "training_loss": 74.99320340156555, "training_acc": 53.0, "val_loss": 18.44794750213623, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.91908574104309, "training_acc": 53.0, "val_loss": 17.31153428554535, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2372419834137, "training_acc": 53.0, "val_loss": 17.99445152282715, "val_acc": 52.0}
{"epoch": 13, "training_loss": 73.73088073730469, "training_acc": 47.0, "val_loss": 17.744292318820953, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.26194763183594, "training_acc": 51.0, "val_loss": 17.55758821964264, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.07224035263062, "training_acc": 53.0, "val_loss": 18.43654215335846, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.84005069732666, "training_acc": 53.0, "val_loss": 17.673976719379425, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14293098449707, "training_acc": 53.0, "val_loss": 17.48882681131363, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.80669784545898, "training_acc": 47.0, "val_loss": 18.18046122789383, "val_acc": 52.0}
{"epoch": 19, "training_loss": 73.05814814567566, "training_acc": 47.0, "val_loss": 17.66093075275421, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.35159802436829, "training_acc": 49.0, "val_loss": 17.44692772626877, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.98535251617432, "training_acc": 53.0, "val_loss": 17.978103458881378, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.06061005592346, "training_acc": 53.0, "val_loss": 17.420442402362823, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.57409596443176, "training_acc": 53.0, "val_loss": 17.445804178714752, "val_acc": 52.0}
{"epoch": 24, "training_loss": 70.357342004776, "training_acc": 47.0, "val_loss": 17.42893010377884, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.46722388267517, "training_acc": 51.0, "val_loss": 17.403937876224518, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.32031226158142, "training_acc": 53.0, "val_loss": 17.707015573978424, "val_acc": 52.0}
{"epoch": 27, "training_loss": 70.77661180496216, "training_acc": 53.0, "val_loss": 17.397937178611755, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.86367511749268, "training_acc": 53.0, "val_loss": 17.60009676218033, "val_acc": 52.0}
{"epoch": 29, "training_loss": 71.77771067619324, "training_acc": 47.0, "val_loss": 17.62121319770813, "val_acc": 52.0}
{"epoch": 30, "training_loss": 71.65988063812256, "training_acc": 41.0, "val_loss": 17.44854748249054, "val_acc": 52.0}
