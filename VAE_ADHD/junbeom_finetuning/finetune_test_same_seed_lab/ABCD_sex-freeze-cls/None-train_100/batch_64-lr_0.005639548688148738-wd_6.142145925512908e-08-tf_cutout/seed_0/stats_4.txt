"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 99.61605501174927, "training_acc": 45.0, "val_loss": 18.98082345724106, "val_acc": 48.0}
{"epoch": 1, "training_loss": 78.15369129180908, "training_acc": 49.0, "val_loss": 26.48930549621582, "val_acc": 52.0}
{"epoch": 2, "training_loss": 104.22956418991089, "training_acc": 53.0, "val_loss": 21.62957787513733, "val_acc": 52.0}
{"epoch": 3, "training_loss": 80.60390853881836, "training_acc": 53.0, "val_loss": 18.30383837223053, "val_acc": 52.0}
{"epoch": 4, "training_loss": 80.32522916793823, "training_acc": 47.0, "val_loss": 21.804244816303253, "val_acc": 48.0}
{"epoch": 5, "training_loss": 85.63125228881836, "training_acc": 47.0, "val_loss": 17.739994823932648, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.30789637565613, "training_acc": 47.0, "val_loss": 18.75101774930954, "val_acc": 52.0}
{"epoch": 7, "training_loss": 75.73179173469543, "training_acc": 53.0, "val_loss": 19.65242773294449, "val_acc": 52.0}
{"epoch": 8, "training_loss": 76.12806820869446, "training_acc": 53.0, "val_loss": 17.497237026691437, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.10039472579956, "training_acc": 49.0, "val_loss": 18.016083538532257, "val_acc": 52.0}
{"epoch": 10, "training_loss": 73.28103947639465, "training_acc": 47.0, "val_loss": 18.137164413928986, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.84319853782654, "training_acc": 47.0, "val_loss": 17.315416038036346, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.37408661842346, "training_acc": 53.0, "val_loss": 18.148942291736603, "val_acc": 52.0}
{"epoch": 13, "training_loss": 71.89807486534119, "training_acc": 53.0, "val_loss": 17.705805599689484, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.19613480567932, "training_acc": 53.0, "val_loss": 17.329494655132294, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.52164578437805, "training_acc": 52.0, "val_loss": 17.56126433610916, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.60375905036926, "training_acc": 47.0, "val_loss": 17.328718304634094, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.34240078926086, "training_acc": 50.0, "val_loss": 17.655563354492188, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.45049786567688, "training_acc": 53.0, "val_loss": 17.480966448783875, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13276767730713, "training_acc": 53.0, "val_loss": 17.377446591854095, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.46428227424622, "training_acc": 47.0, "val_loss": 17.65451729297638, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.88746380805969, "training_acc": 47.0, "val_loss": 17.407923936843872, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.31894421577454, "training_acc": 51.0, "val_loss": 17.499902844429016, "val_acc": 52.0}
{"epoch": 23, "training_loss": 72.10914754867554, "training_acc": 53.0, "val_loss": 17.693080008029938, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.93533444404602, "training_acc": 53.0, "val_loss": 17.383381724357605, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.54143857955933, "training_acc": 47.0, "val_loss": 17.637206614017487, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.53601622581482, "training_acc": 47.0, "val_loss": 17.31727570295334, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.87917065620422, "training_acc": 53.0, "val_loss": 17.6508828997612, "val_acc": 52.0}
{"epoch": 28, "training_loss": 70.2012050151825, "training_acc": 53.0, "val_loss": 17.785456776618958, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.39939570426941, "training_acc": 53.0, "val_loss": 17.33551323413849, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.83851671218872, "training_acc": 55.0, "val_loss": 17.616035044193268, "val_acc": 52.0}
