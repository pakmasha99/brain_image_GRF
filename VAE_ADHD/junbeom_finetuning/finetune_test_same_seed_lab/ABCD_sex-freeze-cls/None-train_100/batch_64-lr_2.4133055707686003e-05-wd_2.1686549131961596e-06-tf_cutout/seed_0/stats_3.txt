"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.45594882965088, "training_acc": 47.0, "val_loss": 17.562241852283478, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.39492845535278, "training_acc": 47.0, "val_loss": 17.530642449855804, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.24594593048096, "training_acc": 47.0, "val_loss": 17.50059872865677, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.11143064498901, "training_acc": 47.0, "val_loss": 17.47324764728546, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.01311993598938, "training_acc": 47.0, "val_loss": 17.44941622018814, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.87434196472168, "training_acc": 47.0, "val_loss": 17.426319420337677, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.79072499275208, "training_acc": 47.0, "val_loss": 17.405717074871063, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.66446614265442, "training_acc": 47.0, "val_loss": 17.387594282627106, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.62244868278503, "training_acc": 47.0, "val_loss": 17.370779812335968, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.54579567909241, "training_acc": 47.0, "val_loss": 17.356418073177338, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.45495986938477, "training_acc": 47.0, "val_loss": 17.34374910593033, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.40655827522278, "training_acc": 49.0, "val_loss": 17.33367145061493, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.34214806556702, "training_acc": 47.0, "val_loss": 17.32662171125412, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.2804524898529, "training_acc": 54.0, "val_loss": 17.320573329925537, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.27147006988525, "training_acc": 53.0, "val_loss": 17.315515875816345, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29079532623291, "training_acc": 53.0, "val_loss": 17.31235831975937, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19392132759094, "training_acc": 53.0, "val_loss": 17.309953272342682, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20325064659119, "training_acc": 53.0, "val_loss": 17.307832837104797, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20504784584045, "training_acc": 53.0, "val_loss": 17.306165397167206, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21737337112427, "training_acc": 53.0, "val_loss": 17.304638028144836, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16793417930603, "training_acc": 53.0, "val_loss": 17.303889989852905, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20674180984497, "training_acc": 53.0, "val_loss": 17.3032209277153, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14056038856506, "training_acc": 53.0, "val_loss": 17.302879691123962, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1731686592102, "training_acc": 53.0, "val_loss": 17.302601039409637, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12334179878235, "training_acc": 53.0, "val_loss": 17.302438616752625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14829564094543, "training_acc": 53.0, "val_loss": 17.30235666036606, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1692168712616, "training_acc": 53.0, "val_loss": 17.302343249320984, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.17027401924133, "training_acc": 53.0, "val_loss": 17.302434146404266, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16980814933777, "training_acc": 53.0, "val_loss": 17.302601039409637, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16630101203918, "training_acc": 53.0, "val_loss": 17.30291098356247, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14038825035095, "training_acc": 53.0, "val_loss": 17.303378880023956, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13458585739136, "training_acc": 53.0, "val_loss": 17.303554713726044, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13833975791931, "training_acc": 53.0, "val_loss": 17.30388253927231, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17073488235474, "training_acc": 53.0, "val_loss": 17.30407625436783, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15974712371826, "training_acc": 53.0, "val_loss": 17.30419099330902, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13765501976013, "training_acc": 53.0, "val_loss": 17.304374277591705, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15381526947021, "training_acc": 53.0, "val_loss": 17.30441302061081, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.15694880485535, "training_acc": 53.0, "val_loss": 17.304469645023346, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.14113235473633, "training_acc": 53.0, "val_loss": 17.30426698923111, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14233112335205, "training_acc": 53.0, "val_loss": 17.30406880378723, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.12644958496094, "training_acc": 53.0, "val_loss": 17.303815484046936, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16985869407654, "training_acc": 53.0, "val_loss": 17.303647100925446, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13999104499817, "training_acc": 53.0, "val_loss": 17.30346828699112, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.16971802711487, "training_acc": 53.0, "val_loss": 17.303547263145447, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.11763453483582, "training_acc": 53.0, "val_loss": 17.30368733406067, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.14392805099487, "training_acc": 53.0, "val_loss": 17.303775250911713, "val_acc": 52.0}
