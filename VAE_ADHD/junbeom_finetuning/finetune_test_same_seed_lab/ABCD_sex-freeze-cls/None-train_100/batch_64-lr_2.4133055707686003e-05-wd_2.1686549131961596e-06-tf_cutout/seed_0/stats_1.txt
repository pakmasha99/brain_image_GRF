"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 71.41489171981812, "training_acc": 47.0, "val_loss": 17.77227371931076, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.24941730499268, "training_acc": 47.0, "val_loss": 17.736536264419556, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.06021547317505, "training_acc": 47.0, "val_loss": 17.704100906848907, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.91954278945923, "training_acc": 47.0, "val_loss": 17.67284721136093, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.8202383518219, "training_acc": 47.0, "val_loss": 17.642512917518616, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.72738695144653, "training_acc": 47.0, "val_loss": 17.61375069618225, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.54799604415894, "training_acc": 47.0, "val_loss": 17.587706446647644, "val_acc": 52.0}
{"epoch": 7, "training_loss": 70.50834560394287, "training_acc": 47.0, "val_loss": 17.563506960868835, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.34501123428345, "training_acc": 47.0, "val_loss": 17.542020976543427, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.24957466125488, "training_acc": 47.0, "val_loss": 17.521056532859802, "val_acc": 52.0}
{"epoch": 10, "training_loss": 70.17290878295898, "training_acc": 47.0, "val_loss": 17.500747740268707, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.10807943344116, "training_acc": 47.0, "val_loss": 17.481723427772522, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.96636462211609, "training_acc": 47.0, "val_loss": 17.464980483055115, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.95903778076172, "training_acc": 47.0, "val_loss": 17.448274791240692, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.89017605781555, "training_acc": 47.0, "val_loss": 17.43389666080475, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.79365611076355, "training_acc": 47.0, "val_loss": 17.421574890613556, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.7318332195282, "training_acc": 47.0, "val_loss": 17.41034686565399, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.66800308227539, "training_acc": 47.0, "val_loss": 17.399485409259796, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.60212898254395, "training_acc": 47.0, "val_loss": 17.389707267284393, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.57542014122009, "training_acc": 47.0, "val_loss": 17.380546033382416, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.5302357673645, "training_acc": 47.0, "val_loss": 17.372077703475952, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.5334267616272, "training_acc": 47.0, "val_loss": 17.363932728767395, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.46591234207153, "training_acc": 47.0, "val_loss": 17.356865108013153, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.43081712722778, "training_acc": 47.0, "val_loss": 17.35088676214218, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.34912729263306, "training_acc": 47.0, "val_loss": 17.344899475574493, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.34031391143799, "training_acc": 47.0, "val_loss": 17.33960509300232, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.31632804870605, "training_acc": 46.0, "val_loss": 17.33480840921402, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.31914687156677, "training_acc": 54.0, "val_loss": 17.330844700336456, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.32042169570923, "training_acc": 52.0, "val_loss": 17.327795922756195, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.26018929481506, "training_acc": 53.0, "val_loss": 17.32572764158249, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.25936079025269, "training_acc": 53.0, "val_loss": 17.32390969991684, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.24635052680969, "training_acc": 53.0, "val_loss": 17.32223927974701, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.24626016616821, "training_acc": 53.0, "val_loss": 17.320720851421356, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.23112201690674, "training_acc": 53.0, "val_loss": 17.31935143470764, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.22482943534851, "training_acc": 53.0, "val_loss": 17.318086326122284, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18799304962158, "training_acc": 53.0, "val_loss": 17.31688678264618, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.22536587715149, "training_acc": 53.0, "val_loss": 17.315852642059326, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.19556927680969, "training_acc": 53.0, "val_loss": 17.31492578983307, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.16081190109253, "training_acc": 53.0, "val_loss": 17.314349114894867, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.20193195343018, "training_acc": 53.0, "val_loss": 17.31395274400711, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17005276679993, "training_acc": 53.0, "val_loss": 17.313537001609802, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.16027069091797, "training_acc": 53.0, "val_loss": 17.313316464424133, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.18211436271667, "training_acc": 53.0, "val_loss": 17.313121259212494, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.19895052909851, "training_acc": 53.0, "val_loss": 17.312930524349213, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.20314335823059, "training_acc": 53.0, "val_loss": 17.31281280517578, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.1573212146759, "training_acc": 53.0, "val_loss": 17.312780022621155, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.18473529815674, "training_acc": 53.0, "val_loss": 17.31284260749817, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16200613975525, "training_acc": 53.0, "val_loss": 17.312969267368317, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.1644287109375, "training_acc": 53.0, "val_loss": 17.31315702199936, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.11132097244263, "training_acc": 53.0, "val_loss": 17.31337457895279, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.16137766838074, "training_acc": 53.0, "val_loss": 17.313651740550995, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.14831209182739, "training_acc": 53.0, "val_loss": 17.31407195329666, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1273889541626, "training_acc": 53.0, "val_loss": 17.314478754997253, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.13809156417847, "training_acc": 53.0, "val_loss": 17.315009236335754, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.10363960266113, "training_acc": 53.0, "val_loss": 17.31543242931366, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.13534617424011, "training_acc": 53.0, "val_loss": 17.31555163860321, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.13855147361755, "training_acc": 53.0, "val_loss": 17.315708100795746, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.16150307655334, "training_acc": 53.0, "val_loss": 17.315761744976044, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.16071200370789, "training_acc": 53.0, "val_loss": 17.31613129377365, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.1567051410675, "training_acc": 53.0, "val_loss": 17.316436767578125, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.14279556274414, "training_acc": 53.0, "val_loss": 17.316749691963196, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.14254760742188, "training_acc": 53.0, "val_loss": 17.317214608192444, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.14745759963989, "training_acc": 53.0, "val_loss": 17.317403852939606, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.15432453155518, "training_acc": 53.0, "val_loss": 17.317557334899902, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.11460423469543, "training_acc": 53.0, "val_loss": 17.31744408607483, "val_acc": 52.0}
