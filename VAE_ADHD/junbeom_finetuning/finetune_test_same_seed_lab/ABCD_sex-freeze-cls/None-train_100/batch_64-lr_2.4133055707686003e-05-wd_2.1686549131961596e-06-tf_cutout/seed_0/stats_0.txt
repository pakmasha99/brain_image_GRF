"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.05450105667114, "training_acc": 52.0, "val_loss": 17.194876074790955, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.92929577827454, "training_acc": 52.0, "val_loss": 17.18491017818451, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.84220743179321, "training_acc": 52.0, "val_loss": 17.17725843191147, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.72656035423279, "training_acc": 52.0, "val_loss": 17.171630263328552, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.60844492912292, "training_acc": 52.0, "val_loss": 17.16778725385666, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.55163478851318, "training_acc": 52.0, "val_loss": 17.165814340114594, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.5195722579956, "training_acc": 52.0, "val_loss": 17.16533601284027, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.49002170562744, "training_acc": 52.0, "val_loss": 17.16628670692444, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.39019846916199, "training_acc": 52.0, "val_loss": 17.168189585208893, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.41059923171997, "training_acc": 52.0, "val_loss": 17.17120260000229, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.31857800483704, "training_acc": 52.0, "val_loss": 17.175117135047913, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.3342649936676, "training_acc": 52.0, "val_loss": 17.179614305496216, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.3148136138916, "training_acc": 52.0, "val_loss": 17.184635996818542, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.26527786254883, "training_acc": 52.0, "val_loss": 17.19028800725937, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.26742315292358, "training_acc": 52.0, "val_loss": 17.195704579353333, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24886631965637, "training_acc": 52.0, "val_loss": 17.200681567192078, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25317478179932, "training_acc": 52.0, "val_loss": 17.204782366752625, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.24556541442871, "training_acc": 52.0, "val_loss": 17.209000885486603, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.20944905281067, "training_acc": 52.0, "val_loss": 17.212939262390137, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.22771668434143, "training_acc": 52.0, "val_loss": 17.216524481773376, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20807695388794, "training_acc": 52.0, "val_loss": 17.220142483711243, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21768379211426, "training_acc": 52.0, "val_loss": 17.22291111946106, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.23660612106323, "training_acc": 52.0, "val_loss": 17.224296927452087, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.21978545188904, "training_acc": 52.0, "val_loss": 17.226630449295044, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.21536183357239, "training_acc": 52.0, "val_loss": 17.229312658309937, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.22966432571411, "training_acc": 52.0, "val_loss": 17.232370376586914, "val_acc": 56.0}
