"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.25163340568542, "training_acc": 52.0, "val_loss": 17.248624563217163, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24944758415222, "training_acc": 52.0, "val_loss": 17.211908102035522, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.27038884162903, "training_acc": 52.0, "val_loss": 17.209838330745697, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26297378540039, "training_acc": 52.0, "val_loss": 17.228664457798004, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24291658401489, "training_acc": 52.0, "val_loss": 17.258013784885406, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.23375630378723, "training_acc": 52.0, "val_loss": 17.26825088262558, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.27261710166931, "training_acc": 52.0, "val_loss": 17.286095023155212, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.27908062934875, "training_acc": 52.0, "val_loss": 17.288339138031006, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.31205630302429, "training_acc": 52.0, "val_loss": 17.271745204925537, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.26370215415955, "training_acc": 52.0, "val_loss": 17.270518839359283, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.2359070777893, "training_acc": 52.0, "val_loss": 17.266622185707092, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2652759552002, "training_acc": 52.0, "val_loss": 17.256702482700348, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23556470870972, "training_acc": 52.0, "val_loss": 17.247623205184937, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23397541046143, "training_acc": 52.0, "val_loss": 17.24504381418228, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24134826660156, "training_acc": 52.0, "val_loss": 17.23617911338806, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24668788909912, "training_acc": 52.0, "val_loss": 17.224667966365814, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25307178497314, "training_acc": 52.0, "val_loss": 17.209075391292572, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23969554901123, "training_acc": 52.0, "val_loss": 17.20186322927475, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.25177836418152, "training_acc": 52.0, "val_loss": 17.198625206947327, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26770091056824, "training_acc": 52.0, "val_loss": 17.198795080184937, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.22052431106567, "training_acc": 52.0, "val_loss": 17.205150425434113, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.24119114875793, "training_acc": 52.0, "val_loss": 17.209969460964203, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29028391838074, "training_acc": 52.0, "val_loss": 17.20835417509079, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25445222854614, "training_acc": 52.0, "val_loss": 17.217841744422913, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.24957299232483, "training_acc": 52.0, "val_loss": 17.233039438724518, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25485920906067, "training_acc": 52.0, "val_loss": 17.25275367498398, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.30531358718872, "training_acc": 52.0, "val_loss": 17.257973551750183, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23645877838135, "training_acc": 52.0, "val_loss": 17.279884219169617, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.27791428565979, "training_acc": 52.0, "val_loss": 17.29598343372345, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.28974390029907, "training_acc": 52.0, "val_loss": 17.292380332946777, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.33404588699341, "training_acc": 52.0, "val_loss": 17.276497185230255, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29385161399841, "training_acc": 52.0, "val_loss": 17.276588082313538, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.2587399482727, "training_acc": 52.0, "val_loss": 17.258109152317047, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24891495704651, "training_acc": 52.0, "val_loss": 17.24342703819275, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26358532905579, "training_acc": 52.0, "val_loss": 17.227309942245483, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2354166507721, "training_acc": 52.0, "val_loss": 17.219600081443787, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.2359402179718, "training_acc": 52.0, "val_loss": 17.21397042274475, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.24821925163269, "training_acc": 52.0, "val_loss": 17.20886528491974, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.24002075195312, "training_acc": 52.0, "val_loss": 17.19852387905121, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.27830934524536, "training_acc": 52.0, "val_loss": 17.18534082174301, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.25941061973572, "training_acc": 52.0, "val_loss": 17.183348536491394, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.28357434272766, "training_acc": 52.0, "val_loss": 17.184707522392273, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28527092933655, "training_acc": 52.0, "val_loss": 17.188453674316406, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23900604248047, "training_acc": 52.0, "val_loss": 17.199119925498962, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26443004608154, "training_acc": 52.0, "val_loss": 17.22182035446167, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.22914028167725, "training_acc": 52.0, "val_loss": 17.240531742572784, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25257611274719, "training_acc": 52.0, "val_loss": 17.260999977588654, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.26210403442383, "training_acc": 52.0, "val_loss": 17.278438806533813, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.24838423728943, "training_acc": 52.0, "val_loss": 17.280812561511993, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2630341053009, "training_acc": 52.0, "val_loss": 17.27912873029709, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.27829694747925, "training_acc": 52.0, "val_loss": 17.280811071395874, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.27294540405273, "training_acc": 52.0, "val_loss": 17.282100021839142, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.28024983406067, "training_acc": 52.0, "val_loss": 17.27961003780365, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.28003811836243, "training_acc": 52.0, "val_loss": 17.27766990661621, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22711324691772, "training_acc": 52.0, "val_loss": 17.273570597171783, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27321791648865, "training_acc": 52.0, "val_loss": 17.261405289173126, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24836778640747, "training_acc": 52.0, "val_loss": 17.256344854831696, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2382972240448, "training_acc": 52.0, "val_loss": 17.254801094532013, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22953820228577, "training_acc": 52.0, "val_loss": 17.2471821308136, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.2520534992218, "training_acc": 52.0, "val_loss": 17.24182516336441, "val_acc": 56.0}
