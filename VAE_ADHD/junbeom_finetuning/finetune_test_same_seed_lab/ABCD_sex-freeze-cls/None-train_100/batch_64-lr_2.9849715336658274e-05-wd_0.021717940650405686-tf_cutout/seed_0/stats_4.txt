"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.45368814468384, "training_acc": 47.0, "val_loss": 17.34565943479538, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.39496278762817, "training_acc": 47.0, "val_loss": 17.331308126449585, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.35298299789429, "training_acc": 43.0, "val_loss": 17.321892082691193, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.26324319839478, "training_acc": 53.0, "val_loss": 17.31647253036499, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25274991989136, "training_acc": 53.0, "val_loss": 17.31312721967697, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2159354686737, "training_acc": 53.0, "val_loss": 17.31099635362625, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.20393228530884, "training_acc": 53.0, "val_loss": 17.309841513633728, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16264295578003, "training_acc": 53.0, "val_loss": 17.30971485376358, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15322518348694, "training_acc": 53.0, "val_loss": 17.31002926826477, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13477206230164, "training_acc": 53.0, "val_loss": 17.310945689678192, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15594458580017, "training_acc": 53.0, "val_loss": 17.311832308769226, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14102673530579, "training_acc": 53.0, "val_loss": 17.312678694725037, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13349866867065, "training_acc": 53.0, "val_loss": 17.314061522483826, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15955018997192, "training_acc": 53.0, "val_loss": 17.315414547920227, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14865493774414, "training_acc": 53.0, "val_loss": 17.316649854183197, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14435172080994, "training_acc": 53.0, "val_loss": 17.317263782024384, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12452793121338, "training_acc": 53.0, "val_loss": 17.317843437194824, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.129807472229, "training_acc": 53.0, "val_loss": 17.318883538246155, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1423647403717, "training_acc": 53.0, "val_loss": 17.319433391094208, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14722967147827, "training_acc": 53.0, "val_loss": 17.319509387016296, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12629771232605, "training_acc": 53.0, "val_loss": 17.319412529468536, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12352013587952, "training_acc": 53.0, "val_loss": 17.319156229496002, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15993189811707, "training_acc": 53.0, "val_loss": 17.319022119045258, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1293032169342, "training_acc": 53.0, "val_loss": 17.31898784637451, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13712310791016, "training_acc": 53.0, "val_loss": 17.31909215450287, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13939785957336, "training_acc": 53.0, "val_loss": 17.318519949913025, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.10800194740295, "training_acc": 53.0, "val_loss": 17.318148910999298, "val_acc": 52.0}
