"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23260045051575, "training_acc": 52.0, "val_loss": 17.232437431812286, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22597885131836, "training_acc": 52.0, "val_loss": 17.226219177246094, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24333310127258, "training_acc": 52.0, "val_loss": 17.225804924964905, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26397371292114, "training_acc": 52.0, "val_loss": 17.229825258255005, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23872470855713, "training_acc": 52.0, "val_loss": 17.236365377902985, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22071123123169, "training_acc": 52.0, "val_loss": 17.238910496234894, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25360298156738, "training_acc": 52.0, "val_loss": 17.24446713924408, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24578976631165, "training_acc": 52.0, "val_loss": 17.247965931892395, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.24412536621094, "training_acc": 52.0, "val_loss": 17.247283458709717, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24861979484558, "training_acc": 52.0, "val_loss": 17.25025177001953, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22480750083923, "training_acc": 52.0, "val_loss": 17.25270450115204, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2548406124115, "training_acc": 52.0, "val_loss": 17.25345253944397, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.22409272193909, "training_acc": 52.0, "val_loss": 17.25374609231949, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23657965660095, "training_acc": 52.0, "val_loss": 17.255030572414398, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24838352203369, "training_acc": 52.0, "val_loss": 17.253780364990234, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25605893135071, "training_acc": 52.0, "val_loss": 17.250758409500122, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25183606147766, "training_acc": 52.0, "val_loss": 17.245158553123474, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23681259155273, "training_acc": 52.0, "val_loss": 17.240792512893677, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2421567440033, "training_acc": 52.0, "val_loss": 17.236553132534027, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25378966331482, "training_acc": 52.0, "val_loss": 17.232532799243927, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20012593269348, "training_acc": 52.0, "val_loss": 17.229987680912018, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21725845336914, "training_acc": 52.0, "val_loss": 17.226924002170563, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27592396736145, "training_acc": 52.0, "val_loss": 17.222358286380768, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25529217720032, "training_acc": 52.0, "val_loss": 17.22130924463272, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25843000411987, "training_acc": 52.0, "val_loss": 17.222081124782562, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.2410659790039, "training_acc": 52.0, "val_loss": 17.22451001405716, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27413725852966, "training_acc": 52.0, "val_loss": 17.22472310066223, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23050260543823, "training_acc": 52.0, "val_loss": 17.229515314102173, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23133873939514, "training_acc": 52.0, "val_loss": 17.23417192697525, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.24975967407227, "training_acc": 52.0, "val_loss": 17.236138880252838, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.25067162513733, "training_acc": 52.0, "val_loss": 17.236125469207764, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.25514364242554, "training_acc": 52.0, "val_loss": 17.23969280719757, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23597812652588, "training_acc": 52.0, "val_loss": 17.239154875278473, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24965977668762, "training_acc": 52.0, "val_loss": 17.23901927471161, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24787640571594, "training_acc": 52.0, "val_loss": 17.23763793706894, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23793768882751, "training_acc": 52.0, "val_loss": 17.23753660917282, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23848390579224, "training_acc": 52.0, "val_loss": 17.237086594104767, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23810505867004, "training_acc": 52.0, "val_loss": 17.23589152097702, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23683094978333, "training_acc": 52.0, "val_loss": 17.232145369052887, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.23349094390869, "training_acc": 52.0, "val_loss": 17.22625344991684, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22635221481323, "training_acc": 52.0, "val_loss": 17.22337156534195, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24776816368103, "training_acc": 52.0, "val_loss": 17.221015691757202, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.25220847129822, "training_acc": 52.0, "val_loss": 17.219015955924988, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22394680976868, "training_acc": 52.0, "val_loss": 17.219027876853943, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.23967409133911, "training_acc": 52.0, "val_loss": 17.22215563058853, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24200129508972, "training_acc": 52.0, "val_loss": 17.22405254840851, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25642108917236, "training_acc": 52.0, "val_loss": 17.226779460906982, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22895169258118, "training_acc": 52.0, "val_loss": 17.229652404785156, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.2255368232727, "training_acc": 52.0, "val_loss": 17.230476438999176, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23076343536377, "training_acc": 52.0, "val_loss": 17.23143309354782, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25272226333618, "training_acc": 52.0, "val_loss": 17.233863472938538, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24760937690735, "training_acc": 52.0, "val_loss": 17.236866056919098, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25039982795715, "training_acc": 52.0, "val_loss": 17.239563167095184, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.25722908973694, "training_acc": 52.0, "val_loss": 17.24269837141037, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.20905447006226, "training_acc": 52.0, "val_loss": 17.245525121688843, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.23826265335083, "training_acc": 52.0, "val_loss": 17.246320843696594, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23462009429932, "training_acc": 52.0, "val_loss": 17.248408496379852, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23619198799133, "training_acc": 52.0, "val_loss": 17.250962555408478, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22686314582825, "training_acc": 52.0, "val_loss": 17.25146323442459, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.2556824684143, "training_acc": 52.0, "val_loss": 17.251943051815033, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.26576161384583, "training_acc": 52.0, "val_loss": 17.24986732006073, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24060440063477, "training_acc": 52.0, "val_loss": 17.249687016010284, "val_acc": 56.0}
