"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.47660183906555, "training_acc": 47.0, "val_loss": 17.527882754802704, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.34846615791321, "training_acc": 47.0, "val_loss": 17.494405806064606, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.13118147850037, "training_acc": 47.0, "val_loss": 17.46748685836792, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.00084376335144, "training_acc": 47.0, "val_loss": 17.44350790977478, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.93530654907227, "training_acc": 47.0, "val_loss": 17.4206405878067, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.77533769607544, "training_acc": 47.0, "val_loss": 17.401766777038574, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.66485142707825, "training_acc": 47.0, "val_loss": 17.38456040620804, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.62672352790833, "training_acc": 47.0, "val_loss": 17.368094623088837, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.53086018562317, "training_acc": 47.0, "val_loss": 17.35355705022812, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.49951982498169, "training_acc": 47.0, "val_loss": 17.34062135219574, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42619276046753, "training_acc": 47.0, "val_loss": 17.330050468444824, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.3360710144043, "training_acc": 47.0, "val_loss": 17.321640253067017, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.30600786209106, "training_acc": 51.0, "val_loss": 17.31496900320053, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.23108839988708, "training_acc": 53.0, "val_loss": 17.31008142232895, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1978371143341, "training_acc": 53.0, "val_loss": 17.306579649448395, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22402548789978, "training_acc": 53.0, "val_loss": 17.304134368896484, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17024946212769, "training_acc": 53.0, "val_loss": 17.302951216697693, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17648339271545, "training_acc": 53.0, "val_loss": 17.30267107486725, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17300534248352, "training_acc": 53.0, "val_loss": 17.30307787656784, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15579581260681, "training_acc": 53.0, "val_loss": 17.303599417209625, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15796661376953, "training_acc": 53.0, "val_loss": 17.304299771785736, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14050889015198, "training_acc": 53.0, "val_loss": 17.304913699626923, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15299654006958, "training_acc": 53.0, "val_loss": 17.30601042509079, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17313003540039, "training_acc": 53.0, "val_loss": 17.307083308696747, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12753081321716, "training_acc": 53.0, "val_loss": 17.308150231838226, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1558563709259, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12943243980408, "training_acc": 53.0, "val_loss": 17.310214042663574, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14402318000793, "training_acc": 53.0, "val_loss": 17.31080561876297, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13470888137817, "training_acc": 53.0, "val_loss": 17.310750484466553, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15741300582886, "training_acc": 53.0, "val_loss": 17.31117218732834, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14224696159363, "training_acc": 53.0, "val_loss": 17.311744391918182, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14263224601746, "training_acc": 53.0, "val_loss": 17.31196492910385, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14331793785095, "training_acc": 53.0, "val_loss": 17.312003672122955, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.137455701828, "training_acc": 53.0, "val_loss": 17.312391102313995, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14290714263916, "training_acc": 53.0, "val_loss": 17.31274724006653, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.16790580749512, "training_acc": 53.0, "val_loss": 17.31313169002533, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15622687339783, "training_acc": 53.0, "val_loss": 17.3126220703125, "val_acc": 52.0}
