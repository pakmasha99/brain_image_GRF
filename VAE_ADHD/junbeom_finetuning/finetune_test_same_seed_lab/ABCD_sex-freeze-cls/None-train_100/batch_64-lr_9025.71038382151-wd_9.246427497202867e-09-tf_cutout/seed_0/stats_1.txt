"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 57921974.566711426, "training_acc": 53.0, "val_loss": 15056284.375, "val_acc": 52.0}
{"epoch": 1, "training_loss": 77479391.0, "training_acc": 49.0, "val_loss": 31552378.125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 113935593.0, "training_acc": 47.0, "val_loss": 1973621.6796875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 30628315.5, "training_acc": 55.0, "val_loss": 35536100.0, "val_acc": 52.0}
{"epoch": 4, "training_loss": 144634750.5, "training_acc": 53.0, "val_loss": 34568246.875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 119483579.25, "training_acc": 53.0, "val_loss": 7970524.21875, "val_acc": 52.0}
{"epoch": 6, "training_loss": 49021885.25, "training_acc": 41.0, "val_loss": 24065065.625, "val_acc": 48.0}
{"epoch": 7, "training_loss": 101424206.5, "training_acc": 47.0, "val_loss": 21150957.8125, "val_acc": 48.0}
{"epoch": 8, "training_loss": 69227325.625, "training_acc": 47.0, "val_loss": 5054330.46875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 32268187.75, "training_acc": 53.0, "val_loss": 15442020.3125, "val_acc": 52.0}
{"epoch": 10, "training_loss": 56156654.0, "training_acc": 53.0, "val_loss": 4822603.90625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 16430810.1875, "training_acc": 63.0, "val_loss": 13558125.0, "val_acc": 48.0}
{"epoch": 12, "training_loss": 55251980.25, "training_acc": 47.0, "val_loss": 8052321.875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 24444775.625, "training_acc": 49.0, "val_loss": 6487419.921875, "val_acc": 52.0}
{"epoch": 14, "training_loss": 24030860.6875, "training_acc": 53.0, "val_loss": 16564.642333984375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 395918.24609375, "training_acc": 49.0, "val_loss": 4470223.046875, "val_acc": 48.0}
{"epoch": 16, "training_loss": 16401919.75, "training_acc": 47.0, "val_loss": 3309023.4375, "val_acc": 52.0}
{"epoch": 17, "training_loss": 14049499.125, "training_acc": 53.0, "val_loss": 961424.51171875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 13474630.875, "training_acc": 49.0, "val_loss": 8712992.96875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 29451895.9375, "training_acc": 47.0, "val_loss": 4059038.28125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 22767434.375, "training_acc": 53.0, "val_loss": 5989195.703125, "val_acc": 52.0}
{"epoch": 21, "training_loss": 14044870.560546875, "training_acc": 53.0, "val_loss": 11113014.0625, "val_acc": 48.0}
{"epoch": 22, "training_loss": 53936062.75, "training_acc": 47.0, "val_loss": 14566809.375, "val_acc": 48.0}
{"epoch": 23, "training_loss": 50781641.125, "training_acc": 47.0, "val_loss": 3553064.0625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 20002102.25, "training_acc": 53.0, "val_loss": 8090225.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 26265173.5625, "training_acc": 53.0, "val_loss": 5203518.359375, "val_acc": 48.0}
{"epoch": 26, "training_loss": 25451085.875, "training_acc": 47.0, "val_loss": 4273375.0, "val_acc": 48.0}
{"epoch": 27, "training_loss": 14304796.125, "training_acc": 55.0, "val_loss": 6631875.0, "val_acc": 52.0}
{"epoch": 28, "training_loss": 23694957.8125, "training_acc": 53.0, "val_loss": 907276.3671875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 4169449.71875, "training_acc": 47.0, "val_loss": 3534129.296875, "val_acc": 52.0}
{"epoch": 30, "training_loss": 13390269.65625, "training_acc": 53.0, "val_loss": 1361847.4609375, "val_acc": 48.0}
{"epoch": 31, "training_loss": 4035978.8125, "training_acc": 47.0, "val_loss": 5503392.1875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 22225686.75, "training_acc": 53.0, "val_loss": 2640248.4375, "val_acc": 52.0}
{"epoch": 33, "training_loss": 17812408.0, "training_acc": 43.0, "val_loss": 7190318.75, "val_acc": 48.0}
