"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 85302062.10378647, "training_acc": 53.0, "val_loss": 17375153.125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 63078508.75, "training_acc": 57.0, "val_loss": 31535015.625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 120427483.5, "training_acc": 47.0, "val_loss": 9600328.125, "val_acc": 48.0}
{"epoch": 3, "training_loss": 41726330.125, "training_acc": 51.0, "val_loss": 23553346.875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 93633912.25, "training_acc": 53.0, "val_loss": 18758620.3125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 55496210.375, "training_acc": 53.0, "val_loss": 10252810.15625, "val_acc": 48.0}
{"epoch": 6, "training_loss": 53741102.75, "training_acc": 47.0, "val_loss": 18339395.3125, "val_acc": 48.0}
{"epoch": 7, "training_loss": 64504161.375, "training_acc": 47.0, "val_loss": 1367744.23828125, "val_acc": 52.0}
{"epoch": 8, "training_loss": 13213540.125, "training_acc": 53.0, "val_loss": 5611401.5625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 13999607.4140625, "training_acc": 53.0, "val_loss": 82324.6826171875, "val_acc": 48.0}
{"epoch": 10, "training_loss": 5186306.40625, "training_acc": 59.0, "val_loss": 5982178.90625, "val_acc": 52.0}
{"epoch": 11, "training_loss": 18042786.578125, "training_acc": 53.0, "val_loss": 7466657.8125, "val_acc": 48.0}
{"epoch": 12, "training_loss": 32859373.875, "training_acc": 47.0, "val_loss": 5171988.28125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 24158136.25, "training_acc": 39.0, "val_loss": 7010110.9375, "val_acc": 52.0}
{"epoch": 14, "training_loss": 23794069.375, "training_acc": 53.0, "val_loss": 2790491.6015625, "val_acc": 48.0}
{"epoch": 15, "training_loss": 14588952.125, "training_acc": 47.0, "val_loss": 68508.203125, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1651397.171875, "training_acc": 47.0, "val_loss": 3953848.828125, "val_acc": 52.0}
{"epoch": 17, "training_loss": 15205662.125, "training_acc": 53.0, "val_loss": 1014613.8671875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 3151485.3671875, "training_acc": 47.0, "val_loss": 5671201.5625, "val_acc": 52.0}
{"epoch": 19, "training_loss": 24231402.625, "training_acc": 53.0, "val_loss": 3106289.453125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 11230145.875, "training_acc": 61.0, "val_loss": 7438024.21875, "val_acc": 48.0}
{"epoch": 21, "training_loss": 26303944.3125, "training_acc": 47.0, "val_loss": 2973935.15625, "val_acc": 52.0}
{"epoch": 22, "training_loss": 14810746.875, "training_acc": 53.0, "val_loss": 2752703.90625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 11549032.125, "training_acc": 55.0, "val_loss": 5284605.859375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 15271962.28125, "training_acc": 47.0, "val_loss": 7515475.0, "val_acc": 52.0}
{"epoch": 25, "training_loss": 33210441.75, "training_acc": 53.0, "val_loss": 9345735.9375, "val_acc": 52.0}
{"epoch": 26, "training_loss": 29318284.46875, "training_acc": 53.0, "val_loss": 6144400.0, "val_acc": 48.0}
{"epoch": 27, "training_loss": 30167222.625, "training_acc": 47.0, "val_loss": 7391064.0625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 20200389.97265625, "training_acc": 47.0, "val_loss": 1815504.296875, "val_acc": 52.0}
{"epoch": 29, "training_loss": 5458815.109375, "training_acc": 55.0, "val_loss": 1180656.4453125, "val_acc": 52.0}
{"epoch": 30, "training_loss": 6624456.90625, "training_acc": 45.0, "val_loss": 1182769.23828125, "val_acc": 52.0}
{"epoch": 31, "training_loss": 3378431.18359375, "training_acc": 53.0, "val_loss": 2972042.96875, "val_acc": 52.0}
{"epoch": 32, "training_loss": 9615975.53125, "training_acc": 53.0, "val_loss": 4520764.84375, "val_acc": 48.0}
{"epoch": 33, "training_loss": 19508355.125, "training_acc": 47.0, "val_loss": 437630.029296875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2099952.90625, "training_acc": 53.0, "val_loss": 3750169.53125, "val_acc": 48.0}
