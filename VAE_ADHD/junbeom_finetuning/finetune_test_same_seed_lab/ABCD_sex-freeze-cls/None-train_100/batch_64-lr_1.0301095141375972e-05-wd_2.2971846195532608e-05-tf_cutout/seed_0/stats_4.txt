"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.7607491016388, "training_acc": 47.0, "val_loss": 17.418329417705536, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.73876309394836, "training_acc": 47.0, "val_loss": 17.408691346645355, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.68208026885986, "training_acc": 47.0, "val_loss": 17.400048673152924, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.61154699325562, "training_acc": 47.0, "val_loss": 17.392927408218384, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58876132965088, "training_acc": 47.0, "val_loss": 17.38598197698593, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.55383729934692, "training_acc": 47.0, "val_loss": 17.379599809646606, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.5558750629425, "training_acc": 47.0, "val_loss": 17.374014854431152, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.51321792602539, "training_acc": 47.0, "val_loss": 17.36898124217987, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.45756244659424, "training_acc": 47.0, "val_loss": 17.36421138048172, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.45856881141663, "training_acc": 47.0, "val_loss": 17.35951602458954, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.42805695533752, "training_acc": 47.0, "val_loss": 17.355352640151978, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.40140414237976, "training_acc": 47.0, "val_loss": 17.35174208879471, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.40185928344727, "training_acc": 47.0, "val_loss": 17.34803318977356, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.38378310203552, "training_acc": 47.0, "val_loss": 17.34493374824524, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.33710026741028, "training_acc": 48.0, "val_loss": 17.342159152030945, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.29932355880737, "training_acc": 50.0, "val_loss": 17.33928620815277, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.29941391944885, "training_acc": 53.0, "val_loss": 17.33666956424713, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.28583145141602, "training_acc": 57.0, "val_loss": 17.33429878950119, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.31201219558716, "training_acc": 52.0, "val_loss": 17.332307994365692, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.29010128974915, "training_acc": 53.0, "val_loss": 17.33045130968094, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.25034785270691, "training_acc": 53.0, "val_loss": 17.328593134880066, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22909665107727, "training_acc": 53.0, "val_loss": 17.327003180980682, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.25561141967773, "training_acc": 53.0, "val_loss": 17.325641214847565, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.23102116584778, "training_acc": 53.0, "val_loss": 17.32441484928131, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.21637678146362, "training_acc": 53.0, "val_loss": 17.32332557439804, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.20343494415283, "training_acc": 53.0, "val_loss": 17.322315275669098, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.22216010093689, "training_acc": 53.0, "val_loss": 17.32139140367508, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.2339928150177, "training_acc": 53.0, "val_loss": 17.32056438922882, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.19092535972595, "training_acc": 53.0, "val_loss": 17.31993407011032, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21410703659058, "training_acc": 53.0, "val_loss": 17.319369316101074, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18079042434692, "training_acc": 53.0, "val_loss": 17.318865656852722, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1888017654419, "training_acc": 53.0, "val_loss": 17.318475246429443, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.19566464424133, "training_acc": 53.0, "val_loss": 17.31809228658676, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17361688613892, "training_acc": 53.0, "val_loss": 17.31785535812378, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17332434654236, "training_acc": 53.0, "val_loss": 17.317700386047363, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15531659126282, "training_acc": 53.0, "val_loss": 17.317600548267365, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15398120880127, "training_acc": 53.0, "val_loss": 17.317554354667664, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.11616611480713, "training_acc": 53.0, "val_loss": 17.317502200603485, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1240496635437, "training_acc": 53.0, "val_loss": 17.317458987236023, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.1643807888031, "training_acc": 53.0, "val_loss": 17.317447066307068, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.14177989959717, "training_acc": 53.0, "val_loss": 17.317435145378113, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.1506016254425, "training_acc": 53.0, "val_loss": 17.317424714565277, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.12792563438416, "training_acc": 53.0, "val_loss": 17.3174187541008, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.13157200813293, "training_acc": 53.0, "val_loss": 17.317426204681396, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.1768889427185, "training_acc": 53.0, "val_loss": 17.31746792793274, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15342831611633, "training_acc": 53.0, "val_loss": 17.317523062229156, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.13124704360962, "training_acc": 53.0, "val_loss": 17.317578196525574, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.16954183578491, "training_acc": 53.0, "val_loss": 17.317625880241394, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.17921018600464, "training_acc": 53.0, "val_loss": 17.317643761634827, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.15687417984009, "training_acc": 53.0, "val_loss": 17.31761544942856, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.13846564292908, "training_acc": 53.0, "val_loss": 17.317591607570648, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.12660551071167, "training_acc": 53.0, "val_loss": 17.317622900009155, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.16670298576355, "training_acc": 53.0, "val_loss": 17.31763482093811, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.13814282417297, "training_acc": 53.0, "val_loss": 17.31768250465393, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.11614203453064, "training_acc": 53.0, "val_loss": 17.317703366279602, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.19155645370483, "training_acc": 53.0, "val_loss": 17.31775254011154, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.16709876060486, "training_acc": 53.0, "val_loss": 17.317821085453033, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.15159606933594, "training_acc": 53.0, "val_loss": 17.31790155172348, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.16050815582275, "training_acc": 53.0, "val_loss": 17.31792837381363, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.14443588256836, "training_acc": 53.0, "val_loss": 17.317931354045868, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.1560378074646, "training_acc": 53.0, "val_loss": 17.317990958690643, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.13441777229309, "training_acc": 53.0, "val_loss": 17.318043112754822, "val_acc": 52.0}
