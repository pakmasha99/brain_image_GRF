"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.16541624069214, "training_acc": 53.0, "val_loss": 17.304585874080658, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18395566940308, "training_acc": 53.0, "val_loss": 17.30407327413559, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18760395050049, "training_acc": 53.0, "val_loss": 17.30399876832962, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16331911087036, "training_acc": 53.0, "val_loss": 17.303895950317383, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1656756401062, "training_acc": 53.0, "val_loss": 17.30387508869171, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13919496536255, "training_acc": 53.0, "val_loss": 17.303888499736786, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12305188179016, "training_acc": 53.0, "val_loss": 17.303937673568726, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15832853317261, "training_acc": 53.0, "val_loss": 17.304015159606934, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16176247596741, "training_acc": 53.0, "val_loss": 17.30411946773529, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16609287261963, "training_acc": 53.0, "val_loss": 17.30419099330902, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16952228546143, "training_acc": 53.0, "val_loss": 17.30429083108902, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.152592420578, "training_acc": 53.0, "val_loss": 17.304416000843048, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16328001022339, "training_acc": 53.0, "val_loss": 17.304526269435883, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1289975643158, "training_acc": 53.0, "val_loss": 17.304687201976776, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.164710521698, "training_acc": 53.0, "val_loss": 17.304904758930206, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13883662223816, "training_acc": 53.0, "val_loss": 17.305094003677368, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13610696792603, "training_acc": 53.0, "val_loss": 17.305225133895874, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16381025314331, "training_acc": 53.0, "val_loss": 17.30535924434662, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14072036743164, "training_acc": 53.0, "val_loss": 17.305488884449005, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15952396392822, "training_acc": 53.0, "val_loss": 17.30569452047348, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15558242797852, "training_acc": 53.0, "val_loss": 17.305853962898254, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16141772270203, "training_acc": 53.0, "val_loss": 17.306126654148102, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14481830596924, "training_acc": 53.0, "val_loss": 17.30661690235138, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15598607063293, "training_acc": 53.0, "val_loss": 17.307110130786896, "val_acc": 52.0}
