"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.20924592018127, "training_acc": 53.0, "val_loss": 17.31480360031128, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22540354728699, "training_acc": 53.0, "val_loss": 17.314791679382324, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.19622015953064, "training_acc": 53.0, "val_loss": 17.31472611427307, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19796061515808, "training_acc": 53.0, "val_loss": 17.31463074684143, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19970560073853, "training_acc": 53.0, "val_loss": 17.31439232826233, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19354128837585, "training_acc": 53.0, "val_loss": 17.31411963701248, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19788002967834, "training_acc": 53.0, "val_loss": 17.313769459724426, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17756652832031, "training_acc": 53.0, "val_loss": 17.313295602798462, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18451428413391, "training_acc": 53.0, "val_loss": 17.312799394130707, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17159271240234, "training_acc": 53.0, "val_loss": 17.31240451335907, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17409873008728, "training_acc": 53.0, "val_loss": 17.312073707580566, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15947842597961, "training_acc": 53.0, "val_loss": 17.31187254190445, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16096019744873, "training_acc": 53.0, "val_loss": 17.31167733669281, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12314319610596, "training_acc": 53.0, "val_loss": 17.31148362159729, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14871621131897, "training_acc": 53.0, "val_loss": 17.31136441230774, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13384938240051, "training_acc": 53.0, "val_loss": 17.311324179172516, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13586497306824, "training_acc": 53.0, "val_loss": 17.31136292219162, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12777900695801, "training_acc": 53.0, "val_loss": 17.311470210552216, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1482183933258, "training_acc": 53.0, "val_loss": 17.311640083789825, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15462160110474, "training_acc": 53.0, "val_loss": 17.311878502368927, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13694167137146, "training_acc": 53.0, "val_loss": 17.312106490135193, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13854670524597, "training_acc": 53.0, "val_loss": 17.312364280223846, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13629651069641, "training_acc": 53.0, "val_loss": 17.312632501125336, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12250876426697, "training_acc": 53.0, "val_loss": 17.3130065202713, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09650754928589, "training_acc": 53.0, "val_loss": 17.313235998153687, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1181571483612, "training_acc": 53.0, "val_loss": 17.31351464986801, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13103151321411, "training_acc": 53.0, "val_loss": 17.31378138065338, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1294469833374, "training_acc": 53.0, "val_loss": 17.313846945762634, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14017462730408, "training_acc": 53.0, "val_loss": 17.313888669013977, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13694047927856, "training_acc": 53.0, "val_loss": 17.3138365149498, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13018488883972, "training_acc": 53.0, "val_loss": 17.313748598098755, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14522290229797, "training_acc": 53.0, "val_loss": 17.3135906457901, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13348126411438, "training_acc": 53.0, "val_loss": 17.313510179519653, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15630841255188, "training_acc": 53.0, "val_loss": 17.3134908080101, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.09930205345154, "training_acc": 53.0, "val_loss": 17.313529551029205, "val_acc": 52.0}
