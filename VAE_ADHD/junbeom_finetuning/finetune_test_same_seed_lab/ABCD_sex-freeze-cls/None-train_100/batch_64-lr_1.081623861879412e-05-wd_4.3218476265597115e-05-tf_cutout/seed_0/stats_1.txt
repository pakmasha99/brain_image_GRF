"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23122882843018, "training_acc": 53.0, "val_loss": 17.31426566839218, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21965885162354, "training_acc": 53.0, "val_loss": 17.314158380031586, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.22721457481384, "training_acc": 53.0, "val_loss": 17.31337010860443, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19148302078247, "training_acc": 53.0, "val_loss": 17.312438786029816, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20890402793884, "training_acc": 53.0, "val_loss": 17.311549186706543, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21374845504761, "training_acc": 53.0, "val_loss": 17.311008274555206, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19770860671997, "training_acc": 53.0, "val_loss": 17.310267686843872, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.19446539878845, "training_acc": 53.0, "val_loss": 17.309628427028656, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18556523323059, "training_acc": 53.0, "val_loss": 17.30896681547165, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16668629646301, "training_acc": 53.0, "val_loss": 17.308378219604492, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17658185958862, "training_acc": 53.0, "val_loss": 17.307889461517334, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16353487968445, "training_acc": 53.0, "val_loss": 17.307576537132263, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18668866157532, "training_acc": 53.0, "val_loss": 17.30733811855316, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16829633712769, "training_acc": 53.0, "val_loss": 17.307209968566895, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1534686088562, "training_acc": 53.0, "val_loss": 17.307090759277344, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16671347618103, "training_acc": 53.0, "val_loss": 17.306990921497345, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13603234291077, "training_acc": 53.0, "val_loss": 17.30692982673645, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1507921218872, "training_acc": 53.0, "val_loss": 17.30690896511078, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15059399604797, "training_acc": 53.0, "val_loss": 17.306916415691376, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15879940986633, "training_acc": 53.0, "val_loss": 17.3069566488266, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13379216194153, "training_acc": 53.0, "val_loss": 17.306992411613464, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13763928413391, "training_acc": 53.0, "val_loss": 17.307032644748688, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15781784057617, "training_acc": 53.0, "val_loss": 17.30709820985794, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14256024360657, "training_acc": 53.0, "val_loss": 17.307159304618835, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.11834263801575, "training_acc": 53.0, "val_loss": 17.307239770889282, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13593626022339, "training_acc": 53.0, "val_loss": 17.307336628437042, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14680814743042, "training_acc": 53.0, "val_loss": 17.307482659816742, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1428575515747, "training_acc": 53.0, "val_loss": 17.307621240615845, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.12696385383606, "training_acc": 53.0, "val_loss": 17.30772703886032, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13992404937744, "training_acc": 53.0, "val_loss": 17.307934165000916, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13697004318237, "training_acc": 53.0, "val_loss": 17.308150231838226, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14519572257996, "training_acc": 53.0, "val_loss": 17.308412492275238, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13980436325073, "training_acc": 53.0, "val_loss": 17.308640480041504, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14738917350769, "training_acc": 53.0, "val_loss": 17.308780550956726, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12802124023438, "training_acc": 53.0, "val_loss": 17.30874925851822, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1424458026886, "training_acc": 53.0, "val_loss": 17.308713495731354, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.13210773468018, "training_acc": 53.0, "val_loss": 17.30870008468628, "val_acc": 52.0}
