"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.42548108100891, "training_acc": 47.0, "val_loss": 17.49415099620819, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.21318101882935, "training_acc": 47.0, "val_loss": 17.440374195575714, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.88212180137634, "training_acc": 47.0, "val_loss": 17.402297258377075, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.67069220542908, "training_acc": 47.0, "val_loss": 17.37251579761505, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.61576557159424, "training_acc": 47.0, "val_loss": 17.34737604856491, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.40627598762512, "training_acc": 47.0, "val_loss": 17.330653965473175, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2889175415039, "training_acc": 53.0, "val_loss": 17.318245768547058, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.2718231678009, "training_acc": 53.0, "val_loss": 17.309054732322693, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19594621658325, "training_acc": 53.0, "val_loss": 17.304039001464844, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20751881599426, "training_acc": 53.0, "val_loss": 17.302684485912323, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17321348190308, "training_acc": 53.0, "val_loss": 17.304427921772003, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12923908233643, "training_acc": 53.0, "val_loss": 17.308025062084198, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14630460739136, "training_acc": 53.0, "val_loss": 17.31272041797638, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.11753392219543, "training_acc": 53.0, "val_loss": 17.31732189655304, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12878775596619, "training_acc": 53.0, "val_loss": 17.321811616420746, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18048405647278, "training_acc": 53.0, "val_loss": 17.327125370502472, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17128014564514, "training_acc": 53.0, "val_loss": 17.33074188232422, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18829154968262, "training_acc": 53.0, "val_loss": 17.334407567977905, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1968195438385, "training_acc": 53.0, "val_loss": 17.33521670103073, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20147633552551, "training_acc": 53.0, "val_loss": 17.331719398498535, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18824863433838, "training_acc": 53.0, "val_loss": 17.328377068042755, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.21336317062378, "training_acc": 53.0, "val_loss": 17.32427626848221, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17603468894958, "training_acc": 53.0, "val_loss": 17.323043942451477, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19883108139038, "training_acc": 53.0, "val_loss": 17.32132136821747, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15919589996338, "training_acc": 53.0, "val_loss": 17.319664359092712, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16438293457031, "training_acc": 53.0, "val_loss": 17.31908768415451, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14210820198059, "training_acc": 53.0, "val_loss": 17.316964268684387, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14465308189392, "training_acc": 53.0, "val_loss": 17.315013706684113, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15816974639893, "training_acc": 53.0, "val_loss": 17.312216758728027, "val_acc": 52.0}
