"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.89205145835876, "training_acc": 47.0, "val_loss": 17.39306151866913, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.68724918365479, "training_acc": 47.0, "val_loss": 17.362014949321747, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.52360391616821, "training_acc": 47.0, "val_loss": 17.34102964401245, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.39552760124207, "training_acc": 47.0, "val_loss": 17.326828837394714, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.32780957221985, "training_acc": 50.0, "val_loss": 17.31567680835724, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2021427154541, "training_acc": 53.0, "val_loss": 17.308910191059113, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15927815437317, "training_acc": 53.0, "val_loss": 17.30615645647049, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12647271156311, "training_acc": 53.0, "val_loss": 17.30685830116272, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18223643302917, "training_acc": 53.0, "val_loss": 17.310424149036407, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14163136482239, "training_acc": 53.0, "val_loss": 17.31446385383606, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12041926383972, "training_acc": 53.0, "val_loss": 17.317499220371246, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13287425041199, "training_acc": 53.0, "val_loss": 17.31979101896286, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16436743736267, "training_acc": 53.0, "val_loss": 17.322373390197754, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13017773628235, "training_acc": 53.0, "val_loss": 17.32272505760193, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19137287139893, "training_acc": 53.0, "val_loss": 17.322005331516266, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17319059371948, "training_acc": 53.0, "val_loss": 17.323504388332367, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12178778648376, "training_acc": 53.0, "val_loss": 17.322532832622528, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17070865631104, "training_acc": 53.0, "val_loss": 17.321014404296875, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15823125839233, "training_acc": 53.0, "val_loss": 17.32112020254135, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12278461456299, "training_acc": 53.0, "val_loss": 17.320656776428223, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14434027671814, "training_acc": 53.0, "val_loss": 17.319831252098083, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14161419868469, "training_acc": 53.0, "val_loss": 17.317816615104675, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15441370010376, "training_acc": 53.0, "val_loss": 17.316259443759918, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11997652053833, "training_acc": 53.0, "val_loss": 17.315970361232758, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13120794296265, "training_acc": 53.0, "val_loss": 17.315109074115753, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16881656646729, "training_acc": 53.0, "val_loss": 17.313838005065918, "val_acc": 52.0}
