"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23689198493958, "training_acc": 52.0, "val_loss": 17.238031327724457, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23212575912476, "training_acc": 52.0, "val_loss": 17.223891615867615, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25019407272339, "training_acc": 52.0, "val_loss": 17.22249537706375, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26389694213867, "training_acc": 52.0, "val_loss": 17.229989171028137, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23973488807678, "training_acc": 52.0, "val_loss": 17.24221706390381, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22410178184509, "training_acc": 52.0, "val_loss": 17.24669486284256, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25711512565613, "training_acc": 52.0, "val_loss": 17.25635528564453, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25358200073242, "training_acc": 52.0, "val_loss": 17.26125329732895, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26074528694153, "training_acc": 52.0, "val_loss": 17.25786179304123, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.253657579422, "training_acc": 52.0, "val_loss": 17.261290550231934, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23081541061401, "training_acc": 52.0, "val_loss": 17.26336032152176, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26133966445923, "training_acc": 52.0, "val_loss": 17.26190596818924, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23130941390991, "training_acc": 52.0, "val_loss": 17.25962609052658, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23973441123962, "training_acc": 52.0, "val_loss": 17.25936532020569, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24936366081238, "training_acc": 52.0, "val_loss": 17.254623770713806, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25394320487976, "training_acc": 52.0, "val_loss": 17.247210443019867, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25213599205017, "training_acc": 52.0, "val_loss": 17.236043512821198, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23391461372375, "training_acc": 52.0, "val_loss": 17.228107154369354, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24026465415955, "training_acc": 52.0, "val_loss": 17.221416532993317, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25529026985168, "training_acc": 52.0, "val_loss": 17.216071486473083, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20277738571167, "training_acc": 52.0, "val_loss": 17.213965952396393, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22252464294434, "training_acc": 52.0, "val_loss": 17.211517691612244, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28560185432434, "training_acc": 52.0, "val_loss": 17.206895351409912, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26084232330322, "training_acc": 52.0, "val_loss": 17.208340764045715, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26073122024536, "training_acc": 52.0, "val_loss": 17.21305102109909, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24760174751282, "training_acc": 52.0, "val_loss": 17.22072809934616, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27763104438782, "training_acc": 52.0, "val_loss": 17.22394973039627, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22821354866028, "training_acc": 52.0, "val_loss": 17.235159873962402, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.2406952381134, "training_acc": 52.0, "val_loss": 17.24579632282257, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25518798828125, "training_acc": 52.0, "val_loss": 17.250435054302216, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26179218292236, "training_acc": 52.0, "val_loss": 17.250339686870575, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.2718768119812, "training_acc": 52.0, "val_loss": 17.25665181875229, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24296879768372, "training_acc": 52.0, "val_loss": 17.25415140390396, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.2544674873352, "training_acc": 52.0, "val_loss": 17.25200265645981, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25517654418945, "training_acc": 52.0, "val_loss": 17.247210443019867, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24015831947327, "training_acc": 52.0, "val_loss": 17.244859039783478, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23925733566284, "training_acc": 52.0, "val_loss": 17.241904139518738, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.239187002182, "training_acc": 52.0, "val_loss": 17.23780184984207, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23252606391907, "training_acc": 52.0, "val_loss": 17.22945123910904, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2442409992218, "training_acc": 52.0, "val_loss": 17.218030989170074, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22740960121155, "training_acc": 52.0, "val_loss": 17.212671041488647, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25068688392639, "training_acc": 52.0, "val_loss": 17.208823561668396, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26172709465027, "training_acc": 52.0, "val_loss": 17.206119000911713, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23446130752563, "training_acc": 52.0, "val_loss": 17.207175493240356, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.2473418712616, "training_acc": 52.0, "val_loss": 17.213843762874603, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24215245246887, "training_acc": 52.0, "val_loss": 17.21867322921753, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25584721565247, "training_acc": 52.0, "val_loss": 17.225085198879242, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23480892181396, "training_acc": 52.0, "val_loss": 17.231711745262146, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22493290901184, "training_acc": 52.0, "val_loss": 17.234310507774353, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23090481758118, "training_acc": 52.0, "val_loss": 17.236827313899994, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2519838809967, "training_acc": 52.0, "val_loss": 17.241808772087097, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24847221374512, "training_acc": 52.0, "val_loss": 17.24753975868225, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25266218185425, "training_acc": 52.0, "val_loss": 17.252254486083984, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.2611472606659, "training_acc": 52.0, "val_loss": 17.25737303495407, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21682405471802, "training_acc": 52.0, "val_loss": 17.261390388011932, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.24895215034485, "training_acc": 52.0, "val_loss": 17.260965704917908, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24258089065552, "training_acc": 52.0, "val_loss": 17.262764275074005, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24410438537598, "training_acc": 52.0, "val_loss": 17.26519912481308, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23503041267395, "training_acc": 52.0, "val_loss": 17.263418436050415, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.2614483833313, "training_acc": 52.0, "val_loss": 17.261558771133423, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.27725672721863, "training_acc": 52.0, "val_loss": 17.25500077009201, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24213790893555, "training_acc": 52.0, "val_loss": 17.25233942270279, "val_acc": 56.0}
