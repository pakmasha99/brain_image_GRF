"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2655417919159, "training_acc": 53.0, "val_loss": 17.31291115283966, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21658539772034, "training_acc": 53.0, "val_loss": 17.313022911548615, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20447516441345, "training_acc": 53.0, "val_loss": 17.312514781951904, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18886089324951, "training_acc": 53.0, "val_loss": 17.31172502040863, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.22363305091858, "training_acc": 53.0, "val_loss": 17.311176657676697, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18298673629761, "training_acc": 53.0, "val_loss": 17.310604453086853, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16623759269714, "training_acc": 53.0, "val_loss": 17.31015145778656, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18282961845398, "training_acc": 53.0, "val_loss": 17.30973571538925, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16536736488342, "training_acc": 53.0, "val_loss": 17.309577763080597, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16812825202942, "training_acc": 53.0, "val_loss": 17.309482395648956, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17076849937439, "training_acc": 53.0, "val_loss": 17.309489846229553, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13234829902649, "training_acc": 53.0, "val_loss": 17.30952262878418, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16341161727905, "training_acc": 53.0, "val_loss": 17.30956733226776, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14876985549927, "training_acc": 53.0, "val_loss": 17.30959266424179, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16468143463135, "training_acc": 53.0, "val_loss": 17.309607565402985, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1848931312561, "training_acc": 53.0, "val_loss": 17.30959415435791, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1717574596405, "training_acc": 53.0, "val_loss": 17.309612035751343, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16363215446472, "training_acc": 53.0, "val_loss": 17.309661209583282, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12681603431702, "training_acc": 53.0, "val_loss": 17.309749126434326, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19746351242065, "training_acc": 53.0, "val_loss": 17.30981469154358, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16205978393555, "training_acc": 53.0, "val_loss": 17.309898138046265, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15611267089844, "training_acc": 53.0, "val_loss": 17.31000542640686, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14087462425232, "training_acc": 53.0, "val_loss": 17.31010228395462, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1264271736145, "training_acc": 53.0, "val_loss": 17.310161888599396, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1628954410553, "training_acc": 53.0, "val_loss": 17.31041669845581, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16308259963989, "training_acc": 53.0, "val_loss": 17.31082946062088, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13561654090881, "training_acc": 53.0, "val_loss": 17.311210930347443, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12394499778748, "training_acc": 53.0, "val_loss": 17.311309278011322, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15527653694153, "training_acc": 53.0, "val_loss": 17.311297357082367, "val_acc": 52.0}
