"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.33556485176086, "training_acc": 53.0, "val_loss": 17.310340702533722, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18133664131165, "training_acc": 53.0, "val_loss": 17.310450971126556, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15537905693054, "training_acc": 53.0, "val_loss": 17.310819029808044, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18669557571411, "training_acc": 53.0, "val_loss": 17.31034368276596, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15866255760193, "training_acc": 53.0, "val_loss": 17.30959415435791, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18768978118896, "training_acc": 53.0, "val_loss": 17.30920821428299, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14717960357666, "training_acc": 53.0, "val_loss": 17.309385538101196, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14620065689087, "training_acc": 53.0, "val_loss": 17.30997860431671, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13000297546387, "training_acc": 53.0, "val_loss": 17.310979962348938, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13580751419067, "training_acc": 53.0, "val_loss": 17.311981320381165, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14719867706299, "training_acc": 53.0, "val_loss": 17.31242686510086, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1095552444458, "training_acc": 53.0, "val_loss": 17.314358055591583, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13116192817688, "training_acc": 53.0, "val_loss": 17.317435145378113, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1698009967804, "training_acc": 53.0, "val_loss": 17.319878935813904, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1447982788086, "training_acc": 53.0, "val_loss": 17.319446802139282, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13013434410095, "training_acc": 53.0, "val_loss": 17.317965626716614, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12875652313232, "training_acc": 53.0, "val_loss": 17.31768697500229, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1174087524414, "training_acc": 53.0, "val_loss": 17.318016290664673, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11270070075989, "training_acc": 53.0, "val_loss": 17.318013310432434, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1438090801239, "training_acc": 53.0, "val_loss": 17.318640649318695, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14653730392456, "training_acc": 53.0, "val_loss": 17.318320274353027, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12097549438477, "training_acc": 53.0, "val_loss": 17.316043376922607, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1429169178009, "training_acc": 53.0, "val_loss": 17.31460690498352, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11620783805847, "training_acc": 53.0, "val_loss": 17.313560843467712, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10529255867004, "training_acc": 53.0, "val_loss": 17.31230467557907, "val_acc": 52.0}
