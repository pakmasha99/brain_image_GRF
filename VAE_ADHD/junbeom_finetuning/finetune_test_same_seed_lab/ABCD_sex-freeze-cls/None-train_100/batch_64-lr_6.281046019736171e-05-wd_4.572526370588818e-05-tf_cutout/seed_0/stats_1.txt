"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.4099371433258, "training_acc": 47.0, "val_loss": 17.484290897846222, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.17461967468262, "training_acc": 47.0, "val_loss": 17.425677180290222, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.81437253952026, "training_acc": 47.0, "val_loss": 17.386043071746826, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.58733320236206, "training_acc": 47.0, "val_loss": 17.356568574905396, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.54295635223389, "training_acc": 47.0, "val_loss": 17.332977056503296, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.32905340194702, "training_acc": 49.0, "val_loss": 17.31880158185959, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.21988797187805, "training_acc": 53.0, "val_loss": 17.309457063674927, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21539735794067, "training_acc": 53.0, "val_loss": 17.303912341594696, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15313458442688, "training_acc": 53.0, "val_loss": 17.302733659744263, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18053150177002, "training_acc": 53.0, "val_loss": 17.305339872837067, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16087293624878, "training_acc": 53.0, "val_loss": 17.310383915901184, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13093543052673, "training_acc": 53.0, "val_loss": 17.31628179550171, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15735650062561, "training_acc": 53.0, "val_loss": 17.322349548339844, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13765406608582, "training_acc": 53.0, "val_loss": 17.327114939689636, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15515065193176, "training_acc": 53.0, "val_loss": 17.33110249042511, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20098567008972, "training_acc": 53.0, "val_loss": 17.335790395736694, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.19648861885071, "training_acc": 53.0, "val_loss": 17.33792871236801, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20329689979553, "training_acc": 53.0, "val_loss": 17.340087890625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20487642288208, "training_acc": 53.0, "val_loss": 17.338868975639343, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21119427680969, "training_acc": 53.0, "val_loss": 17.33284741640091, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18834805488586, "training_acc": 53.0, "val_loss": 17.327556014060974, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22295784950256, "training_acc": 53.0, "val_loss": 17.32201874256134, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1709201335907, "training_acc": 53.0, "val_loss": 17.320068180561066, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.19333386421204, "training_acc": 53.0, "val_loss": 17.31787621974945, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15476751327515, "training_acc": 53.0, "val_loss": 17.315997183322906, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15810823440552, "training_acc": 53.0, "val_loss": 17.31541007757187, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1357057094574, "training_acc": 53.0, "val_loss": 17.31339395046234, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13958024978638, "training_acc": 53.0, "val_loss": 17.311671376228333, "val_acc": 52.0}
