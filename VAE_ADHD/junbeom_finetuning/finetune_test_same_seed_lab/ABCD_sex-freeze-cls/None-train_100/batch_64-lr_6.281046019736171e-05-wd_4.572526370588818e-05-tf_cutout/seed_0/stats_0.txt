"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2384262084961, "training_acc": 52.0, "val_loss": 17.23954677581787, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23416900634766, "training_acc": 52.0, "val_loss": 17.22271293401718, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25247883796692, "training_acc": 52.0, "val_loss": 17.221057415008545, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26383566856384, "training_acc": 52.0, "val_loss": 17.229758203029633, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24006342887878, "training_acc": 52.0, "val_loss": 17.243894934654236, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22510838508606, "training_acc": 52.0, "val_loss": 17.249035835266113, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25843906402588, "training_acc": 52.0, "val_loss": 17.259924113750458, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2563054561615, "training_acc": 52.0, "val_loss": 17.265020310878754, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.26647448539734, "training_acc": 52.0, "val_loss": 17.260484397411346, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25524139404297, "training_acc": 52.0, "val_loss": 17.263759672641754, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23234224319458, "training_acc": 52.0, "val_loss": 17.26539134979248, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.2628583908081, "training_acc": 52.0, "val_loss": 17.26296842098236, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23286008834839, "training_acc": 52.0, "val_loss": 17.259696125984192, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23966646194458, "training_acc": 52.0, "val_loss": 17.25885570049286, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24862313270569, "training_acc": 52.0, "val_loss": 17.25308746099472, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25249600410461, "training_acc": 52.0, "val_loss": 17.244532704353333, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.251779794693, "training_acc": 52.0, "val_loss": 17.232078313827515, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23344016075134, "training_acc": 52.0, "val_loss": 17.223575711250305, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24068236351013, "training_acc": 52.0, "val_loss": 17.21675395965576, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25681829452515, "training_acc": 52.0, "val_loss": 17.211656272411346, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20522427558899, "training_acc": 52.0, "val_loss": 17.21028983592987, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22569727897644, "training_acc": 52.0, "val_loss": 17.208591103553772, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28804063796997, "training_acc": 52.0, "val_loss": 17.204421758651733, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26183128356934, "training_acc": 52.0, "val_loss": 17.206992208957672, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26029109954834, "training_acc": 52.0, "val_loss": 17.2132208943367, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24891901016235, "training_acc": 52.0, "val_loss": 17.222781479358673, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27795815467834, "training_acc": 52.0, "val_loss": 17.22697764635086, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22747039794922, "training_acc": 52.0, "val_loss": 17.240241169929504, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.2443482875824, "training_acc": 52.0, "val_loss": 17.252585291862488, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25859475135803, "training_acc": 52.0, "val_loss": 17.257501184940338, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26875638961792, "training_acc": 52.0, "val_loss": 17.25658029317856, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27735185623169, "training_acc": 52.0, "val_loss": 17.263011634349823, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24690294265747, "training_acc": 52.0, "val_loss": 17.258967459201813, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25626826286316, "training_acc": 52.0, "val_loss": 17.25531965494156, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.25811290740967, "training_acc": 52.0, "val_loss": 17.248710989952087, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24043393135071, "training_acc": 52.0, "val_loss": 17.24506914615631, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23865604400635, "training_acc": 52.0, "val_loss": 17.240940034389496, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23827862739563, "training_acc": 52.0, "val_loss": 17.23574995994568, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23056507110596, "training_acc": 52.0, "val_loss": 17.226070165634155, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24787425994873, "training_acc": 52.0, "val_loss": 17.21334010362625, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22918224334717, "training_acc": 52.0, "val_loss": 17.207632958889008, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25352144241333, "training_acc": 52.0, "val_loss": 17.203816771507263, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26607298851013, "training_acc": 52.0, "val_loss": 17.201416194438934, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23817014694214, "training_acc": 52.0, "val_loss": 17.20324456691742, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25118708610535, "training_acc": 52.0, "val_loss": 17.211395502090454, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24201560020447, "training_acc": 52.0, "val_loss": 17.217598855495453, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25544810295105, "training_acc": 52.0, "val_loss": 17.225608229637146, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23702621459961, "training_acc": 52.0, "val_loss": 17.233802378177643, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22486114501953, "training_acc": 52.0, "val_loss": 17.2371968626976, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23116374015808, "training_acc": 52.0, "val_loss": 17.24030077457428, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25237655639648, "training_acc": 52.0, "val_loss": 17.246070504188538, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24975323677063, "training_acc": 52.0, "val_loss": 17.2525092959404, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25480008125305, "training_acc": 52.0, "val_loss": 17.257560789585114, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26381778717041, "training_acc": 52.0, "val_loss": 17.262883484363556, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22025322914124, "training_acc": 52.0, "val_loss": 17.266735434532166, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.2538812160492, "training_acc": 52.0, "val_loss": 17.26529449224472, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24590277671814, "training_acc": 52.0, "val_loss": 17.26638972759247, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24624419212341, "training_acc": 52.0, "val_loss": 17.26820021867752, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23719501495361, "training_acc": 52.0, "val_loss": 17.265185713768005, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26187491416931, "training_acc": 52.0, "val_loss": 17.262189090251923, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.27995085716248, "training_acc": 52.0, "val_loss": 17.254020273685455, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24134516716003, "training_acc": 52.0, "val_loss": 17.250503599643707, "val_acc": 56.0}
