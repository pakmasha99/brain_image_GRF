"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.89201068878174, "training_acc": 47.0, "val_loss": 17.39395707845688, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.69137597084045, "training_acc": 47.0, "val_loss": 17.363305389881134, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.52949237823486, "training_acc": 47.0, "val_loss": 17.34239310026169, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.40300679206848, "training_acc": 47.0, "val_loss": 17.328064143657684, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.33502221107483, "training_acc": 49.0, "val_loss": 17.3166424036026, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20865821838379, "training_acc": 53.0, "val_loss": 17.309504747390747, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1644058227539, "training_acc": 53.0, "val_loss": 17.306336760520935, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12999629974365, "training_acc": 53.0, "val_loss": 17.30654239654541, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.18376231193542, "training_acc": 53.0, "val_loss": 17.309673130512238, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14170289039612, "training_acc": 53.0, "val_loss": 17.31346845626831, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11946487426758, "training_acc": 53.0, "val_loss": 17.31647253036499, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13099408149719, "training_acc": 53.0, "val_loss": 17.31885075569153, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16320538520813, "training_acc": 53.0, "val_loss": 17.321546375751495, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.12876749038696, "training_acc": 53.0, "val_loss": 17.322131991386414, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18869829177856, "training_acc": 53.0, "val_loss": 17.32165664434433, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.1729507446289, "training_acc": 53.0, "val_loss": 17.323291301727295, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1214759349823, "training_acc": 53.0, "val_loss": 17.32250154018402, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16975021362305, "training_acc": 53.0, "val_loss": 17.321139574050903, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15848302841187, "training_acc": 53.0, "val_loss": 17.321334779262543, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12318515777588, "training_acc": 53.0, "val_loss": 17.320947349071503, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14494395256042, "training_acc": 53.0, "val_loss": 17.32017546892166, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14206600189209, "training_acc": 53.0, "val_loss": 17.318201065063477, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15464973449707, "training_acc": 53.0, "val_loss": 17.316654324531555, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12043619155884, "training_acc": 53.0, "val_loss": 17.3163503408432, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13163876533508, "training_acc": 53.0, "val_loss": 17.315463721752167, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.169189453125, "training_acc": 53.0, "val_loss": 17.314162850379944, "val_acc": 52.0}
