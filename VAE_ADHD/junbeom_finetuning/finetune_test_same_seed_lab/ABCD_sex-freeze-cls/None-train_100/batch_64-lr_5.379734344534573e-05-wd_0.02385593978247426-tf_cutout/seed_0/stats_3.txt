"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.31656694412231, "training_acc": 53.0, "val_loss": 17.30995923280716, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22394871711731, "training_acc": 53.0, "val_loss": 17.308619618415833, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20489120483398, "training_acc": 53.0, "val_loss": 17.306596040725708, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1532793045044, "training_acc": 53.0, "val_loss": 17.305852472782135, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18045115470886, "training_acc": 53.0, "val_loss": 17.30574369430542, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18733048439026, "training_acc": 53.0, "val_loss": 17.306457459926605, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15486931800842, "training_acc": 53.0, "val_loss": 17.307554185390472, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11300659179688, "training_acc": 53.0, "val_loss": 17.30799376964569, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10677337646484, "training_acc": 53.0, "val_loss": 17.3098161816597, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15012097358704, "training_acc": 53.0, "val_loss": 17.312757670879364, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18931365013123, "training_acc": 53.0, "val_loss": 17.315152287483215, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14000201225281, "training_acc": 53.0, "val_loss": 17.31497198343277, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15071129798889, "training_acc": 53.0, "val_loss": 17.313840985298157, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14463400840759, "training_acc": 53.0, "val_loss": 17.31373220682144, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14816284179688, "training_acc": 53.0, "val_loss": 17.314133048057556, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12060451507568, "training_acc": 53.0, "val_loss": 17.31422245502472, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16046738624573, "training_acc": 53.0, "val_loss": 17.314839363098145, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.145756483078, "training_acc": 53.0, "val_loss": 17.314627766609192, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15373349189758, "training_acc": 53.0, "val_loss": 17.312657833099365, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15350818634033, "training_acc": 53.0, "val_loss": 17.311376333236694, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14007306098938, "training_acc": 53.0, "val_loss": 17.310404777526855, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16433215141296, "training_acc": 53.0, "val_loss": 17.30920374393463, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13708639144897, "training_acc": 53.0, "val_loss": 17.308536171913147, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14243197441101, "training_acc": 53.0, "val_loss": 17.308436334133148, "val_acc": 52.0}
