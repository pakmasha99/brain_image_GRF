"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23665595054626, "training_acc": 52.0, "val_loss": 17.2377809882164, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23180341720581, "training_acc": 52.0, "val_loss": 17.224067449569702, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24982953071594, "training_acc": 52.0, "val_loss": 17.2227144241333, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26390480995178, "training_acc": 52.0, "val_loss": 17.230021953582764, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23968601226807, "training_acc": 52.0, "val_loss": 17.24195033311844, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22393822669983, "training_acc": 52.0, "val_loss": 17.246322333812714, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25691080093384, "training_acc": 52.0, "val_loss": 17.255783081054688, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.25316715240479, "training_acc": 52.0, "val_loss": 17.260636389255524, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.25985288619995, "training_acc": 52.0, "val_loss": 17.257419228553772, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25340414047241, "training_acc": 52.0, "val_loss": 17.26085990667343, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23055577278137, "training_acc": 52.0, "val_loss": 17.262986302375793, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26107144355774, "training_acc": 52.0, "val_loss": 17.261676490306854, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23103260993958, "training_acc": 52.0, "val_loss": 17.25955158472061, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23970460891724, "training_acc": 52.0, "val_loss": 17.25938320159912, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24944877624512, "training_acc": 52.0, "val_loss": 17.254814505577087, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25415825843811, "training_acc": 52.0, "val_loss": 17.247597873210907, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25219082832336, "training_acc": 52.0, "val_loss": 17.236661911010742, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23402786254883, "training_acc": 52.0, "val_loss": 17.228838801383972, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2402491569519, "training_acc": 52.0, "val_loss": 17.222194373607635, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25509142875671, "training_acc": 52.0, "val_loss": 17.216835916042328, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20243906974792, "training_acc": 52.0, "val_loss": 17.214632034301758, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2220528125763, "training_acc": 52.0, "val_loss": 17.21208095550537, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.285151720047, "training_acc": 52.0, "val_loss": 17.207397520542145, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26061964035034, "training_acc": 52.0, "val_loss": 17.20867156982422, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.26073098182678, "training_acc": 52.0, "val_loss": 17.213141918182373, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.2473406791687, "training_acc": 52.0, "val_loss": 17.220523953437805, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.2775890827179, "training_acc": 52.0, "val_loss": 17.223581671714783, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22835636138916, "training_acc": 52.0, "val_loss": 17.234455049037933, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24015712738037, "training_acc": 52.0, "val_loss": 17.244800925254822, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25473046302795, "training_acc": 52.0, "val_loss": 17.24936068058014, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.26084446907043, "training_acc": 52.0, "val_loss": 17.24935472011566, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.27099561691284, "training_acc": 52.0, "val_loss": 17.2556072473526, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.24238419532776, "training_acc": 52.0, "val_loss": 17.253310978412628, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.254154920578, "training_acc": 52.0, "val_loss": 17.25136786699295, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2546877861023, "training_acc": 52.0, "val_loss": 17.24684238433838, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24006676673889, "training_acc": 52.0, "val_loss": 17.24468618631363, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23930406570435, "training_acc": 52.0, "val_loss": 17.241916060447693, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23929238319397, "training_acc": 52.0, "val_loss": 17.237994074821472, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23284459114075, "training_acc": 52.0, "val_loss": 17.229878902435303, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.24368000030518, "training_acc": 52.0, "val_loss": 17.218704521656036, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22722172737122, "training_acc": 52.0, "val_loss": 17.213428020477295, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25033974647522, "training_acc": 52.0, "val_loss": 17.209605872631073, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.26108622550964, "training_acc": 52.0, "val_loss": 17.2068789601326, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.23386597633362, "training_acc": 52.0, "val_loss": 17.207835614681244, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.24677610397339, "training_acc": 52.0, "val_loss": 17.21428781747818, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24214887619019, "training_acc": 52.0, "val_loss": 17.21891760826111, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25588655471802, "training_acc": 52.0, "val_loss": 17.225095629692078, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23446750640869, "training_acc": 52.0, "val_loss": 17.23148673772812, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22495889663696, "training_acc": 52.0, "val_loss": 17.233960330486298, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23089528083801, "training_acc": 52.0, "val_loss": 17.236383259296417, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25197148323059, "training_acc": 52.0, "val_loss": 17.241229116916656, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24833703041077, "training_acc": 52.0, "val_loss": 17.246828973293304, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25240540504456, "training_acc": 52.0, "val_loss": 17.25146472454071, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26079535484314, "training_acc": 52.0, "val_loss": 17.25652515888214, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21632242202759, "training_acc": 52.0, "val_loss": 17.260533571243286, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.24823117256165, "training_acc": 52.0, "val_loss": 17.26023703813553, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24206781387329, "training_acc": 52.0, "val_loss": 17.262117564678192, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.2437219619751, "training_acc": 52.0, "val_loss": 17.264623939990997, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23463797569275, "training_acc": 52.0, "val_loss": 17.26301908493042, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26129579544067, "training_acc": 52.0, "val_loss": 17.261329293251038, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.2767584323883, "training_acc": 52.0, "val_loss": 17.25502908229828, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24221110343933, "training_acc": 52.0, "val_loss": 17.252513766288757, "val_acc": 56.0}
