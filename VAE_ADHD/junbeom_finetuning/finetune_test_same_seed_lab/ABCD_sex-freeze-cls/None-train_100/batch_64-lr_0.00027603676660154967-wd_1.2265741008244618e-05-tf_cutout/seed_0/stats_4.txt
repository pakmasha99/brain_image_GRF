"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.87506818771362, "training_acc": 47.0, "val_loss": 17.302951216697693, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.53679203987122, "training_acc": 53.0, "val_loss": 17.412611842155457, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.41525053977966, "training_acc": 53.0, "val_loss": 17.35661029815674, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.4733715057373, "training_acc": 53.0, "val_loss": 17.3057958483696, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18774485588074, "training_acc": 53.0, "val_loss": 17.29791611433029, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1452898979187, "training_acc": 53.0, "val_loss": 17.297019064426422, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2632782459259, "training_acc": 53.0, "val_loss": 17.297305166721344, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26330947875977, "training_acc": 53.0, "val_loss": 17.297954857349396, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.20840573310852, "training_acc": 53.0, "val_loss": 17.29777157306671, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20299196243286, "training_acc": 53.0, "val_loss": 17.299285531044006, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.11684012413025, "training_acc": 53.0, "val_loss": 17.297597229480743, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24850964546204, "training_acc": 53.0, "val_loss": 17.296786606311798, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13156175613403, "training_acc": 53.0, "val_loss": 17.297373712062836, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.33312606811523, "training_acc": 53.0, "val_loss": 17.303811013698578, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17471289634705, "training_acc": 53.0, "val_loss": 17.301258444786072, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.16153740882874, "training_acc": 53.0, "val_loss": 17.305466532707214, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13679242134094, "training_acc": 53.0, "val_loss": 17.307916283607483, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.17520093917847, "training_acc": 53.0, "val_loss": 17.31211245059967, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14278674125671, "training_acc": 53.0, "val_loss": 17.324596643447876, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.18947863578796, "training_acc": 53.0, "val_loss": 17.33177900314331, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21030855178833, "training_acc": 53.0, "val_loss": 17.335398495197296, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.16963386535645, "training_acc": 53.0, "val_loss": 17.32264906167984, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18671131134033, "training_acc": 53.0, "val_loss": 17.308196425437927, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17865252494812, "training_acc": 53.0, "val_loss": 17.30046421289444, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.16052341461182, "training_acc": 53.0, "val_loss": 17.29874312877655, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14512348175049, "training_acc": 53.0, "val_loss": 17.29884445667267, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16036677360535, "training_acc": 53.0, "val_loss": 17.299029231071472, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14328098297119, "training_acc": 53.0, "val_loss": 17.300790548324585, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14207911491394, "training_acc": 53.0, "val_loss": 17.30240434408188, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1126184463501, "training_acc": 53.0, "val_loss": 17.303039133548737, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.13654470443726, "training_acc": 53.0, "val_loss": 17.304694652557373, "val_acc": 52.0}
