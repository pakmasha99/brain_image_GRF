"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3841905593872, "training_acc": 53.0, "val_loss": 17.347314953804016, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.14691972732544, "training_acc": 53.0, "val_loss": 17.314860224723816, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.42328763008118, "training_acc": 45.0, "val_loss": 17.343522608280182, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.32502055168152, "training_acc": 48.0, "val_loss": 17.320148646831512, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.16636681556702, "training_acc": 53.0, "val_loss": 17.31470823287964, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22268629074097, "training_acc": 53.0, "val_loss": 17.334531247615814, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22509002685547, "training_acc": 53.0, "val_loss": 17.336955666542053, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.09617161750793, "training_acc": 53.0, "val_loss": 17.35028773546219, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.21635437011719, "training_acc": 53.0, "val_loss": 17.355352640151978, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20058822631836, "training_acc": 53.0, "val_loss": 17.366425693035126, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23374509811401, "training_acc": 53.0, "val_loss": 17.372220754623413, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.33140993118286, "training_acc": 53.0, "val_loss": 17.36992746591568, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.25593900680542, "training_acc": 53.0, "val_loss": 17.343711853027344, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19323468208313, "training_acc": 53.0, "val_loss": 17.324422299861908, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.23192405700684, "training_acc": 53.0, "val_loss": 17.31318235397339, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.24799370765686, "training_acc": 53.0, "val_loss": 17.31560528278351, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1398229598999, "training_acc": 53.0, "val_loss": 17.316913604736328, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18558669090271, "training_acc": 53.0, "val_loss": 17.315693199634552, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.29877805709839, "training_acc": 53.0, "val_loss": 17.314136028289795, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20738172531128, "training_acc": 53.0, "val_loss": 17.31649339199066, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.21741843223572, "training_acc": 53.0, "val_loss": 17.32408255338669, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13510799407959, "training_acc": 53.0, "val_loss": 17.32422560453415, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11713480949402, "training_acc": 53.0, "val_loss": 17.321081459522247, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12745714187622, "training_acc": 53.0, "val_loss": 17.320582270622253, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12505006790161, "training_acc": 53.0, "val_loss": 17.318198084831238, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09881901741028, "training_acc": 53.0, "val_loss": 17.317181825637817, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.2062885761261, "training_acc": 53.0, "val_loss": 17.317138612270355, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11978077888489, "training_acc": 53.0, "val_loss": 17.320482432842255, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15094447135925, "training_acc": 53.0, "val_loss": 17.321525514125824, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.19777798652649, "training_acc": 53.0, "val_loss": 17.31944978237152, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.11380434036255, "training_acc": 53.0, "val_loss": 17.32410043478012, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.10414671897888, "training_acc": 53.0, "val_loss": 17.328724265098572, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.17331385612488, "training_acc": 53.0, "val_loss": 17.33464002609253, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20417618751526, "training_acc": 53.0, "val_loss": 17.33335703611374, "val_acc": 52.0}
