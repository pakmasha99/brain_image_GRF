"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.10369396209717, "training_acc": 41.0, "val_loss": 17.51730740070343, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.65485310554504, "training_acc": 47.0, "val_loss": 17.443053424358368, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.06767582893372, "training_acc": 47.0, "val_loss": 17.42544323205948, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.63624691963196, "training_acc": 46.0, "val_loss": 17.30319708585739, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.54113125801086, "training_acc": 53.0, "val_loss": 17.44549125432968, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.88391423225403, "training_acc": 53.0, "val_loss": 17.383460700511932, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.36971306800842, "training_acc": 53.0, "val_loss": 17.353850603103638, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.61010026931763, "training_acc": 53.0, "val_loss": 17.317046225070953, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2620587348938, "training_acc": 53.0, "val_loss": 17.32948273420334, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1692054271698, "training_acc": 53.0, "val_loss": 17.352697253227234, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.43822455406189, "training_acc": 53.0, "val_loss": 17.349964380264282, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21630811691284, "training_acc": 53.0, "val_loss": 17.29939877986908, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17115449905396, "training_acc": 53.0, "val_loss": 17.322540283203125, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.55388379096985, "training_acc": 48.0, "val_loss": 17.370839416980743, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.45921850204468, "training_acc": 47.0, "val_loss": 17.305034399032593, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19711756706238, "training_acc": 53.0, "val_loss": 17.35866367816925, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.37171053886414, "training_acc": 53.0, "val_loss": 17.435236275196075, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.08342862129211, "training_acc": 53.0, "val_loss": 17.367924749851227, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.50582885742188, "training_acc": 53.0, "val_loss": 17.371828854084015, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.24700832366943, "training_acc": 53.0, "val_loss": 17.30189621448517, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11470866203308, "training_acc": 53.0, "val_loss": 17.379729449748993, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.8487229347229, "training_acc": 47.0, "val_loss": 17.417030036449432, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.69994854927063, "training_acc": 47.0, "val_loss": 17.304904758930206, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13650465011597, "training_acc": 53.0, "val_loss": 17.34965294599533, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.23716878890991, "training_acc": 53.0, "val_loss": 17.43701845407486, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.54803395271301, "training_acc": 53.0, "val_loss": 17.399610579013824, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.37100481987, "training_acc": 53.0, "val_loss": 17.338329553604126, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1205062866211, "training_acc": 53.0, "val_loss": 17.304950952529907, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.89181995391846, "training_acc": 41.0, "val_loss": 17.341867089271545, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.29256129264832, "training_acc": 51.0, "val_loss": 17.30485111474991, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.04484248161316, "training_acc": 53.0, "val_loss": 17.38317757844925, "val_acc": 52.0}
