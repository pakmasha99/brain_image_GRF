"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 257.54220390319824, "training_acc": 53.0, "val_loss": 52.56088376045227, "val_acc": 52.0}
{"epoch": 1, "training_loss": 286.85340690612793, "training_acc": 49.0, "val_loss": 121.7279314994812, "val_acc": 48.0}
{"epoch": 2, "training_loss": 439.30554389953613, "training_acc": 47.0, "val_loss": 20.234987139701843, "val_acc": 48.0}
{"epoch": 3, "training_loss": 172.3152256011963, "training_acc": 43.0, "val_loss": 98.7781286239624, "val_acc": 52.0}
{"epoch": 4, "training_loss": 380.1433153152466, "training_acc": 53.0, "val_loss": 63.353848457336426, "val_acc": 52.0}
{"epoch": 5, "training_loss": 175.46935629844666, "training_acc": 53.0, "val_loss": 50.871968269348145, "val_acc": 48.0}
{"epoch": 6, "training_loss": 262.6588382720947, "training_acc": 47.0, "val_loss": 75.46871304512024, "val_acc": 48.0}
{"epoch": 7, "training_loss": 259.0942106246948, "training_acc": 47.0, "val_loss": 18.357695639133453, "val_acc": 52.0}
{"epoch": 8, "training_loss": 117.69804382324219, "training_acc": 53.0, "val_loss": 61.23262047767639, "val_acc": 52.0}
{"epoch": 9, "training_loss": 228.67676734924316, "training_acc": 53.0, "val_loss": 29.124510288238525, "val_acc": 52.0}
{"epoch": 10, "training_loss": 115.8232069015503, "training_acc": 45.0, "val_loss": 39.808204770088196, "val_acc": 48.0}
{"epoch": 11, "training_loss": 160.98058414459229, "training_acc": 47.0, "val_loss": 21.673744916915894, "val_acc": 48.0}
{"epoch": 12, "training_loss": 85.47411561012268, "training_acc": 51.0, "val_loss": 35.527387261390686, "val_acc": 52.0}
{"epoch": 13, "training_loss": 140.8979196548462, "training_acc": 53.0, "val_loss": 21.0230752825737, "val_acc": 52.0}
{"epoch": 14, "training_loss": 87.9040756225586, "training_acc": 49.0, "val_loss": 32.21825361251831, "val_acc": 48.0}
{"epoch": 15, "training_loss": 123.21049356460571, "training_acc": 47.0, "val_loss": 17.32221394777298, "val_acc": 52.0}
{"epoch": 16, "training_loss": 77.37175488471985, "training_acc": 53.0, "val_loss": 28.850814700126648, "val_acc": 52.0}
{"epoch": 17, "training_loss": 103.31452631950378, "training_acc": 53.0, "val_loss": 17.87358671426773, "val_acc": 52.0}
{"epoch": 18, "training_loss": 86.11992311477661, "training_acc": 47.0, "val_loss": 23.10573011636734, "val_acc": 48.0}
{"epoch": 19, "training_loss": 85.01377654075623, "training_acc": 49.0, "val_loss": 22.330693900585175, "val_acc": 52.0}
{"epoch": 20, "training_loss": 90.04886293411255, "training_acc": 53.0, "val_loss": 18.48045289516449, "val_acc": 52.0}
{"epoch": 21, "training_loss": 77.74729204177856, "training_acc": 47.0, "val_loss": 21.41377329826355, "val_acc": 48.0}
{"epoch": 22, "training_loss": 82.77419257164001, "training_acc": 47.0, "val_loss": 18.22526454925537, "val_acc": 52.0}
{"epoch": 23, "training_loss": 72.19579720497131, "training_acc": 53.0, "val_loss": 18.703341484069824, "val_acc": 52.0}
{"epoch": 24, "training_loss": 73.46668195724487, "training_acc": 53.0, "val_loss": 17.642077803611755, "val_acc": 52.0}
{"epoch": 25, "training_loss": 71.9289436340332, "training_acc": 47.0, "val_loss": 17.426390945911407, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.31710910797119, "training_acc": 53.0, "val_loss": 18.578769266605377, "val_acc": 52.0}
{"epoch": 27, "training_loss": 71.82389426231384, "training_acc": 53.0, "val_loss": 17.818187177181244, "val_acc": 52.0}
{"epoch": 28, "training_loss": 72.3761568069458, "training_acc": 47.0, "val_loss": 17.35944300889969, "val_acc": 52.0}
{"epoch": 29, "training_loss": 68.05271649360657, "training_acc": 59.0, "val_loss": 19.450494647026062, "val_acc": 52.0}
{"epoch": 30, "training_loss": 75.80068230628967, "training_acc": 53.0, "val_loss": 17.318245768547058, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.75747346878052, "training_acc": 51.0, "val_loss": 17.856720089912415, "val_acc": 52.0}
{"epoch": 32, "training_loss": 71.77720522880554, "training_acc": 47.0, "val_loss": 18.156222999095917, "val_acc": 52.0}
{"epoch": 33, "training_loss": 71.09433364868164, "training_acc": 53.0, "val_loss": 17.491446435451508, "val_acc": 52.0}
{"epoch": 34, "training_loss": 70.4705240726471, "training_acc": 47.0, "val_loss": 17.319999635219574, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.28136539459229, "training_acc": 53.0, "val_loss": 17.56582409143448, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.05402493476868, "training_acc": 53.0, "val_loss": 17.942799627780914, "val_acc": 52.0}
{"epoch": 37, "training_loss": 71.64442801475525, "training_acc": 47.0, "val_loss": 17.366433143615723, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.12876534461975, "training_acc": 53.0, "val_loss": 17.70312786102295, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.92403554916382, "training_acc": 53.0, "val_loss": 17.713233828544617, "val_acc": 52.0}
{"epoch": 40, "training_loss": 71.11632657051086, "training_acc": 47.0, "val_loss": 17.424747347831726, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.5826404094696, "training_acc": 49.0, "val_loss": 17.57311522960663, "val_acc": 52.0}
{"epoch": 42, "training_loss": 71.48387479782104, "training_acc": 43.0, "val_loss": 17.47053861618042, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.7950394153595, "training_acc": 53.0, "val_loss": 17.33468323945999, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.36403226852417, "training_acc": 51.0, "val_loss": 17.398016154766083, "val_acc": 52.0}
{"epoch": 45, "training_loss": 74.05352091789246, "training_acc": 39.0, "val_loss": 17.390114068984985, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.1607358455658, "training_acc": 47.0, "val_loss": 17.507560551166534, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.06856179237366, "training_acc": 53.0, "val_loss": 18.579968810081482, "val_acc": 52.0}
{"epoch": 48, "training_loss": 75.33544325828552, "training_acc": 53.0, "val_loss": 17.390437424182892, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.28940606117249, "training_acc": 53.0, "val_loss": 17.36070215702057, "val_acc": 52.0}
