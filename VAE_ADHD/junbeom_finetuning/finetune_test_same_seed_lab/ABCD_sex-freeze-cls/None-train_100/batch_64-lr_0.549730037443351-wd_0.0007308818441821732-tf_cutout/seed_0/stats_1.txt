"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3795.295455932617, "training_acc": 51.0, "val_loss": 1022.9543685913086, "val_acc": 52.0}
{"epoch": 1, "training_loss": 4897.327392578125, "training_acc": 47.0, "val_loss": 1696.2993621826172, "val_acc": 48.0}
{"epoch": 2, "training_loss": 6028.756057739258, "training_acc": 47.0, "val_loss": 69.54902410507202, "val_acc": 52.0}
{"epoch": 3, "training_loss": 681.3077201843262, "training_acc": 53.0, "val_loss": 235.40489673614502, "val_acc": 52.0}
{"epoch": 4, "training_loss": 888.0137748718262, "training_acc": 59.0, "val_loss": 402.8719902038574, "val_acc": 48.0}
{"epoch": 5, "training_loss": 1210.9971590042114, "training_acc": 45.0, "val_loss": 17.48315989971161, "val_acc": 52.0}
{"epoch": 6, "training_loss": 118.95542049407959, "training_acc": 47.0, "val_loss": 378.72111797332764, "val_acc": 52.0}
{"epoch": 7, "training_loss": 1583.292350769043, "training_acc": 53.0, "val_loss": 58.056819438934326, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1176.5175170898438, "training_acc": 49.0, "val_loss": 886.0329627990723, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3340.345657348633, "training_acc": 47.0, "val_loss": 141.96964502334595, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1195.3360443115234, "training_acc": 53.0, "val_loss": 1130.0504684448242, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4510.395935058594, "training_acc": 53.0, "val_loss": 1022.2521781921387, "val_acc": 52.0}
{"epoch": 12, "training_loss": 3354.260414123535, "training_acc": 53.0, "val_loss": 152.0584225654602, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1091.47998046875, "training_acc": 47.0, "val_loss": 411.29302978515625, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1076.4929280281067, "training_acc": 47.0, "val_loss": 507.3746681213379, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2242.4076080322266, "training_acc": 53.0, "val_loss": 563.2652282714844, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1687.168981552124, "training_acc": 53.0, "val_loss": 515.8601760864258, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2635.685272216797, "training_acc": 47.0, "val_loss": 671.9963073730469, "val_acc": 48.0}
{"epoch": 18, "training_loss": 2051.682476043701, "training_acc": 47.0, "val_loss": 515.1310443878174, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2395.3536834716797, "training_acc": 53.0, "val_loss": 904.0688514709473, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3221.390899658203, "training_acc": 53.0, "val_loss": 213.19329738616943, "val_acc": 52.0}
{"epoch": 21, "training_loss": 980.1167678833008, "training_acc": 61.0, "val_loss": 906.2901496887207, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3751.521194458008, "training_acc": 47.0, "val_loss": 622.6813793182373, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1704.2107734680176, "training_acc": 47.0, "val_loss": 424.83415603637695, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1700.084976196289, "training_acc": 53.0, "val_loss": 322.18170166015625, "val_acc": 52.0}
