"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4515.682754516602, "training_acc": 50.0, "val_loss": 865.1895523071289, "val_acc": 44.0}
{"epoch": 1, "training_loss": 4610.634368896484, "training_acc": 48.0, "val_loss": 2204.6377182006836, "val_acc": 56.0}
{"epoch": 2, "training_loss": 9396.855377197266, "training_acc": 52.0, "val_loss": 1347.7761268615723, "val_acc": 56.0}
{"epoch": 3, "training_loss": 4024.1551399230957, "training_acc": 52.0, "val_loss": 1409.213924407959, "val_acc": 44.0}
{"epoch": 4, "training_loss": 6413.512878417969, "training_acc": 48.0, "val_loss": 2453.693389892578, "val_acc": 44.0}
{"epoch": 5, "training_loss": 8647.266906738281, "training_acc": 48.0, "val_loss": 1276.4822959899902, "val_acc": 44.0}
{"epoch": 6, "training_loss": 3204.002618789673, "training_acc": 48.0, "val_loss": 1014.8351669311523, "val_acc": 56.0}
{"epoch": 7, "training_loss": 5380.265899658203, "training_acc": 52.0, "val_loss": 1956.4783096313477, "val_acc": 56.0}
{"epoch": 8, "training_loss": 8509.305145263672, "training_acc": 52.0, "val_loss": 1566.538143157959, "val_acc": 56.0}
{"epoch": 9, "training_loss": 5824.561233520508, "training_acc": 52.0, "val_loss": 100.3907561302185, "val_acc": 56.0}
{"epoch": 10, "training_loss": 1905.2571258544922, "training_acc": 50.0, "val_loss": 1976.2435913085938, "val_acc": 44.0}
{"epoch": 11, "training_loss": 7726.051849365234, "training_acc": 48.0, "val_loss": 2186.0193252563477, "val_acc": 44.0}
{"epoch": 12, "training_loss": 7541.484420776367, "training_acc": 48.0, "val_loss": 952.4138450622559, "val_acc": 44.0}
{"epoch": 13, "training_loss": 2266.5789375305176, "training_acc": 52.0, "val_loss": 545.662784576416, "val_acc": 56.0}
{"epoch": 14, "training_loss": 2610.002410888672, "training_acc": 52.0, "val_loss": 599.9287128448486, "val_acc": 56.0}
{"epoch": 15, "training_loss": 2108.7810707092285, "training_acc": 52.0, "val_loss": 429.5872688293457, "val_acc": 44.0}
{"epoch": 16, "training_loss": 1947.4941711425781, "training_acc": 48.0, "val_loss": 605.8975219726562, "val_acc": 44.0}
{"epoch": 17, "training_loss": 1649.8448429107666, "training_acc": 48.0, "val_loss": 464.42389488220215, "val_acc": 56.0}
{"epoch": 18, "training_loss": 2449.858741760254, "training_acc": 52.0, "val_loss": 731.646203994751, "val_acc": 56.0}
{"epoch": 19, "training_loss": 2773.508155822754, "training_acc": 52.0, "val_loss": 30.816355347633362, "val_acc": 44.0}
{"epoch": 20, "training_loss": 559.5051307678223, "training_acc": 48.0, "val_loss": 247.90997505187988, "val_acc": 44.0}
{"epoch": 21, "training_loss": 725.4957466125488, "training_acc": 54.0, "val_loss": 200.44302940368652, "val_acc": 56.0}
{"epoch": 22, "training_loss": 567.4185862541199, "training_acc": 52.0, "val_loss": 492.81225204467773, "val_acc": 44.0}
{"epoch": 23, "training_loss": 1957.2309036254883, "training_acc": 48.0, "val_loss": 374.5729684829712, "val_acc": 44.0}
{"epoch": 24, "training_loss": 1200.7010536193848, "training_acc": 46.0, "val_loss": 276.49943828582764, "val_acc": 56.0}
{"epoch": 25, "training_loss": 982.6537647247314, "training_acc": 52.0, "val_loss": 319.8230504989624, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1202.7275161743164, "training_acc": 48.0, "val_loss": 110.00829935073853, "val_acc": 44.0}
{"epoch": 27, "training_loss": 845.2314682006836, "training_acc": 48.0, "val_loss": 486.1663818359375, "val_acc": 56.0}
{"epoch": 28, "training_loss": 1913.4665794372559, "training_acc": 52.0, "val_loss": 33.41995179653168, "val_acc": 44.0}
{"epoch": 29, "training_loss": 323.09675788879395, "training_acc": 48.0, "val_loss": 57.2687566280365, "val_acc": 56.0}
{"epoch": 30, "training_loss": 179.30208015441895, "training_acc": 52.0, "val_loss": 330.69255352020264, "val_acc": 44.0}
{"epoch": 31, "training_loss": 1249.1121826171875, "training_acc": 48.0, "val_loss": 57.08310604095459, "val_acc": 56.0}
{"epoch": 32, "training_loss": 331.1758213043213, "training_acc": 52.0, "val_loss": 141.80736541748047, "val_acc": 44.0}
{"epoch": 33, "training_loss": 403.59433460235596, "training_acc": 48.0, "val_loss": 299.0150451660156, "val_acc": 56.0}
{"epoch": 34, "training_loss": 1425.9924774169922, "training_acc": 52.0, "val_loss": 154.69648838043213, "val_acc": 56.0}
{"epoch": 35, "training_loss": 942.1695747375488, "training_acc": 50.0, "val_loss": 533.0916404724121, "val_acc": 44.0}
{"epoch": 36, "training_loss": 1704.966251373291, "training_acc": 48.0, "val_loss": 158.06490182876587, "val_acc": 56.0}
{"epoch": 37, "training_loss": 803.8442573547363, "training_acc": 52.0, "val_loss": 152.06316709518433, "val_acc": 56.0}
{"epoch": 38, "training_loss": 957.5893936157227, "training_acc": 42.0, "val_loss": 296.55542373657227, "val_acc": 44.0}
{"epoch": 39, "training_loss": 861.5981636047363, "training_acc": 44.0, "val_loss": 30.05794882774353, "val_acc": 56.0}
{"epoch": 40, "training_loss": 448.50231552124023, "training_acc": 50.0, "val_loss": 193.51660013198853, "val_acc": 44.0}
{"epoch": 41, "training_loss": 717.909761428833, "training_acc": 50.0, "val_loss": 214.27321434020996, "val_acc": 56.0}
{"epoch": 42, "training_loss": 595.0838394165039, "training_acc": 52.0, "val_loss": 493.88818740844727, "val_acc": 44.0}
{"epoch": 43, "training_loss": 1910.348030090332, "training_acc": 48.0, "val_loss": 384.2338562011719, "val_acc": 44.0}
{"epoch": 44, "training_loss": 1010.8741188049316, "training_acc": 52.0, "val_loss": 214.75584506988525, "val_acc": 56.0}
{"epoch": 45, "training_loss": 717.9172973632812, "training_acc": 52.0, "val_loss": 384.40587520599365, "val_acc": 44.0}
{"epoch": 46, "training_loss": 1544.5849685668945, "training_acc": 48.0, "val_loss": 228.2184362411499, "val_acc": 44.0}
{"epoch": 47, "training_loss": 844.1657180786133, "training_acc": 54.0, "val_loss": 418.60785484313965, "val_acc": 56.0}
{"epoch": 48, "training_loss": 1673.3121223449707, "training_acc": 52.0, "val_loss": 30.415141582489014, "val_acc": 44.0}
{"epoch": 49, "training_loss": 231.61899757385254, "training_acc": 48.0, "val_loss": 49.772825837135315, "val_acc": 56.0}
{"epoch": 50, "training_loss": 196.50726175308228, "training_acc": 54.0, "val_loss": 112.17726469039917, "val_acc": 56.0}
{"epoch": 51, "training_loss": 331.3357720375061, "training_acc": 52.0, "val_loss": 187.27608919143677, "val_acc": 44.0}
{"epoch": 52, "training_loss": 493.1277210712433, "training_acc": 46.0, "val_loss": 61.223894357681274, "val_acc": 56.0}
{"epoch": 53, "training_loss": 388.14726638793945, "training_acc": 52.0, "val_loss": 61.35079860687256, "val_acc": 44.0}
{"epoch": 54, "training_loss": 560.0328521728516, "training_acc": 52.0, "val_loss": 357.543683052063, "val_acc": 56.0}
{"epoch": 55, "training_loss": 1248.3692779541016, "training_acc": 52.0, "val_loss": 334.39364433288574, "val_acc": 44.0}
{"epoch": 56, "training_loss": 1414.6224746704102, "training_acc": 48.0, "val_loss": 289.81738090515137, "val_acc": 44.0}
{"epoch": 57, "training_loss": 908.8340225219727, "training_acc": 52.0, "val_loss": 293.9274787902832, "val_acc": 56.0}
{"epoch": 58, "training_loss": 1056.3046607971191, "training_acc": 52.0, "val_loss": 297.70586490631104, "val_acc": 44.0}
