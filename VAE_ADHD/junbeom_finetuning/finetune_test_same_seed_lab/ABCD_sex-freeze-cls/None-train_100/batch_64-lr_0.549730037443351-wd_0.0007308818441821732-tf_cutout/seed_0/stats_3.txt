"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 4054.1578216552734, "training_acc": 53.0, "val_loss": 839.389705657959, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3905.2930603027344, "training_acc": 57.0, "val_loss": 2321.533203125, "val_acc": 48.0}
{"epoch": 2, "training_loss": 8790.12222290039, "training_acc": 47.0, "val_loss": 696.2064743041992, "val_acc": 48.0}
{"epoch": 3, "training_loss": 3358.2538146972656, "training_acc": 43.0, "val_loss": 1417.093849182129, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5579.18782043457, "training_acc": 53.0, "val_loss": 1044.8334693908691, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3082.8506393432617, "training_acc": 53.0, "val_loss": 803.166675567627, "val_acc": 48.0}
{"epoch": 6, "training_loss": 4057.923538208008, "training_acc": 47.0, "val_loss": 1288.7486457824707, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4643.711196899414, "training_acc": 47.0, "val_loss": 45.16822695732117, "val_acc": 48.0}
{"epoch": 8, "training_loss": 1447.0076904296875, "training_acc": 49.0, "val_loss": 1478.3923149108887, "val_acc": 52.0}
{"epoch": 9, "training_loss": 6020.690185546875, "training_acc": 53.0, "val_loss": 1469.3163871765137, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5079.05940246582, "training_acc": 53.0, "val_loss": 293.654727935791, "val_acc": 52.0}
{"epoch": 11, "training_loss": 1677.7060317993164, "training_acc": 53.0, "val_loss": 1258.4935188293457, "val_acc": 48.0}
{"epoch": 12, "training_loss": 5481.431304931641, "training_acc": 47.0, "val_loss": 1167.5549507141113, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3791.964469909668, "training_acc": 47.0, "val_loss": 287.51721382141113, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1843.172264099121, "training_acc": 53.0, "val_loss": 893.6223030090332, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3282.626907348633, "training_acc": 53.0, "val_loss": 307.25178718566895, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1244.7127571105957, "training_acc": 55.0, "val_loss": 762.0662689208984, "val_acc": 48.0}
{"epoch": 17, "training_loss": 3128.238998413086, "training_acc": 47.0, "val_loss": 398.9875793457031, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1274.2623901367188, "training_acc": 53.0, "val_loss": 533.4163665771484, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2084.3498458862305, "training_acc": 53.0, "val_loss": 250.73840618133545, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1176.810302734375, "training_acc": 47.0, "val_loss": 473.3302116394043, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1657.487117767334, "training_acc": 47.0, "val_loss": 200.5194902420044, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1108.2273788452148, "training_acc": 53.0, "val_loss": 183.50815773010254, "val_acc": 52.0}
{"epoch": 23, "training_loss": 920.467113494873, "training_acc": 49.0, "val_loss": 384.86058712005615, "val_acc": 48.0}
{"epoch": 24, "training_loss": 1213.466360092163, "training_acc": 47.0, "val_loss": 371.3982343673706, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1776.0963516235352, "training_acc": 53.0, "val_loss": 456.2455654144287, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1277.5218086242676, "training_acc": 53.0, "val_loss": 566.220760345459, "val_acc": 48.0}
