"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 19846029.60378647, "training_acc": 53.0, "val_loss": 4043123.828125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 14675856.125, "training_acc": 57.0, "val_loss": 7336050.0, "val_acc": 48.0}
{"epoch": 2, "training_loss": 28015809.875, "training_acc": 47.0, "val_loss": 2233691.40625, "val_acc": 48.0}
{"epoch": 3, "training_loss": 9707844.5625, "training_acc": 51.0, "val_loss": 5479766.015625, "val_acc": 52.0}
{"epoch": 4, "training_loss": 21784721.125, "training_acc": 53.0, "val_loss": 4364969.53125, "val_acc": 52.0}
{"epoch": 5, "training_loss": 12914580.53125, "training_acc": 53.0, "val_loss": 2384217.7734375, "val_acc": 48.0}
{"epoch": 6, "training_loss": 12498680.8125, "training_acc": 47.0, "val_loss": 4266037.5, "val_acc": 48.0}
{"epoch": 7, "training_loss": 15004700.21875, "training_acc": 47.0, "val_loss": 318470.3369140625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 3075239.578125, "training_acc": 53.0, "val_loss": 1305900.390625, "val_acc": 52.0}
{"epoch": 9, "training_loss": 3257304.9423828125, "training_acc": 53.0, "val_loss": 18658.587646484375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1205974.6484375, "training_acc": 59.0, "val_loss": 1392317.48046875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4199935.671875, "training_acc": 53.0, "val_loss": 1736465.0390625, "val_acc": 48.0}
{"epoch": 12, "training_loss": 7642240.0, "training_acc": 47.0, "val_loss": 1202847.94921875, "val_acc": 48.0}
{"epoch": 13, "training_loss": 5619812.328125, "training_acc": 39.0, "val_loss": 1631350.0, "val_acc": 52.0}
{"epoch": 14, "training_loss": 5537587.21875, "training_acc": 53.0, "val_loss": 648589.990234375, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3391690.5625, "training_acc": 47.0, "val_loss": 16419.888305664062, "val_acc": 52.0}
{"epoch": 16, "training_loss": 384644.91796875, "training_acc": 47.0, "val_loss": 920354.00390625, "val_acc": 52.0}
{"epoch": 17, "training_loss": 3539600.953125, "training_acc": 53.0, "val_loss": 235421.7529296875, "val_acc": 48.0}
{"epoch": 18, "training_loss": 730652.53515625, "training_acc": 47.0, "val_loss": 1320001.953125, "val_acc": 52.0}
{"epoch": 19, "training_loss": 5639915.84375, "training_acc": 53.0, "val_loss": 723450.5859375, "val_acc": 52.0}
{"epoch": 20, "training_loss": 2613391.2734375, "training_acc": 61.0, "val_loss": 1729695.3125, "val_acc": 48.0}
{"epoch": 21, "training_loss": 6116662.625, "training_acc": 47.0, "val_loss": 692472.998046875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 3448096.296875, "training_acc": 53.0, "val_loss": 641125.244140625, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2687521.71875, "training_acc": 55.0, "val_loss": 1228755.95703125, "val_acc": 48.0}
{"epoch": 24, "training_loss": 3550227.13671875, "training_acc": 47.0, "val_loss": 1749107.2265625, "val_acc": 52.0}
{"epoch": 25, "training_loss": 7729041.15625, "training_acc": 53.0, "val_loss": 2175198.6328125, "val_acc": 52.0}
{"epoch": 26, "training_loss": 6824605.515625, "training_acc": 53.0, "val_loss": 1428386.1328125, "val_acc": 48.0}
{"epoch": 27, "training_loss": 7014052.5, "training_acc": 47.0, "val_loss": 1718666.6015625, "val_acc": 48.0}
{"epoch": 28, "training_loss": 4698393.759765625, "training_acc": 47.0, "val_loss": 423123.876953125, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1270659.283203125, "training_acc": 55.0, "val_loss": 275437.255859375, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1541870.0, "training_acc": 45.0, "val_loss": 275918.7744140625, "val_acc": 52.0}
{"epoch": 31, "training_loss": 786660.896484375, "training_acc": 53.0, "val_loss": 692215.673828125, "val_acc": 52.0}
{"epoch": 32, "training_loss": 2240218.13671875, "training_acc": 53.0, "val_loss": 1050891.89453125, "val_acc": 48.0}
{"epoch": 33, "training_loss": 4535219.421875, "training_acc": 47.0, "val_loss": 102504.1748046875, "val_acc": 52.0}
{"epoch": 34, "training_loss": 491257.81640625, "training_acc": 53.0, "val_loss": 871735.25390625, "val_acc": 48.0}
