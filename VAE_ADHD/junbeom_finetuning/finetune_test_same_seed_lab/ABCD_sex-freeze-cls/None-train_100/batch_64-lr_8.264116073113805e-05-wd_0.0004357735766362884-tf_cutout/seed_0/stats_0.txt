"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24279499053955, "training_acc": 52.0, "val_loss": 17.243142426013947, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23961734771729, "training_acc": 52.0, "val_loss": 17.219099402427673, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25868153572083, "training_acc": 52.0, "val_loss": 17.21699833869934, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26361203193665, "training_acc": 52.0, "val_loss": 17.229101061820984, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24098515510559, "training_acc": 52.0, "val_loss": 17.248481512069702, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22780108451843, "training_acc": 52.0, "val_loss": 17.25546568632126, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26259183883667, "training_acc": 52.0, "val_loss": 17.269326746463776, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26401948928833, "training_acc": 52.0, "val_loss": 17.274311184883118, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.28235197067261, "training_acc": 52.0, "val_loss": 17.26614087820053, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25909233093262, "training_acc": 52.0, "val_loss": 17.268386483192444, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23522973060608, "training_acc": 52.0, "val_loss": 17.26834774017334, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26541090011597, "training_acc": 52.0, "val_loss": 17.263102531433105, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23532938957214, "training_acc": 52.0, "val_loss": 17.25725531578064, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23804569244385, "training_acc": 52.0, "val_loss": 17.25512444972992, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24572038650513, "training_acc": 52.0, "val_loss": 17.247274518013, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.2488899230957, "training_acc": 52.0, "val_loss": 17.236606776714325, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25132393836975, "training_acc": 52.0, "val_loss": 17.22194254398346, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23419570922852, "training_acc": 52.0, "val_loss": 17.213085293769836, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24400758743286, "training_acc": 52.0, "val_loss": 17.206963896751404, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26187682151794, "training_acc": 52.0, "val_loss": 17.203399538993835, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21252536773682, "training_acc": 52.0, "val_loss": 17.204633355140686, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2337543964386, "training_acc": 52.0, "val_loss": 17.20535308122635, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29119825363159, "training_acc": 52.0, "val_loss": 17.202548682689667, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26097798347473, "training_acc": 52.0, "val_loss": 17.20811426639557, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25643157958984, "training_acc": 52.0, "val_loss": 17.218269407749176, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25078129768372, "training_acc": 52.0, "val_loss": 17.232516407966614, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28200244903564, "training_acc": 52.0, "val_loss": 17.23848134279251, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22806906700134, "training_acc": 52.0, "val_loss": 17.256326973438263, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25637602806091, "training_acc": 52.0, "val_loss": 17.27178543806076, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.2708671092987, "training_acc": 52.0, "val_loss": 17.275401949882507, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.29300045967102, "training_acc": 52.0, "val_loss": 17.27023720741272, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28898811340332, "training_acc": 52.0, "val_loss": 17.275166511535645, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25621795654297, "training_acc": 52.0, "val_loss": 17.265675961971283, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25763249397278, "training_acc": 52.0, "val_loss": 17.257198691368103, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26299953460693, "training_acc": 52.0, "val_loss": 17.24565327167511, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23853421211243, "training_acc": 52.0, "val_loss": 17.238932847976685, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23549365997314, "training_acc": 52.0, "val_loss": 17.232520878314972, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23665738105774, "training_acc": 52.0, "val_loss": 17.225687205791473, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22844386100769, "training_acc": 52.0, "val_loss": 17.21418797969818, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.2587559223175, "training_acc": 52.0, "val_loss": 17.19997376203537, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.2389030456543, "training_acc": 52.0, "val_loss": 17.19484031200409, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.265540599823, "training_acc": 52.0, "val_loss": 17.192383110523224, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27805256843567, "training_acc": 52.0, "val_loss": 17.191867530345917, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24502968788147, "training_acc": 52.0, "val_loss": 17.196562886238098, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.26066470146179, "training_acc": 52.0, "val_loss": 17.209430038928986, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23896527290344, "training_acc": 52.0, "val_loss": 17.220042645931244, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25294828414917, "training_acc": 52.0, "val_loss": 17.232894897460938, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24340987205505, "training_acc": 52.0, "val_loss": 17.245502769947052, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22732949256897, "training_acc": 52.0, "val_loss": 17.25054532289505, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.2360270023346, "training_acc": 52.0, "val_loss": 17.25425273180008, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25779747962952, "training_acc": 52.0, "val_loss": 17.26086735725403, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25723600387573, "training_acc": 52.0, "val_loss": 17.267635464668274, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.26477861404419, "training_acc": 52.0, "val_loss": 17.27176457643509, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27332878112793, "training_acc": 52.0, "val_loss": 17.275741696357727, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22873902320862, "training_acc": 52.0, "val_loss": 17.27733314037323, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26693725585938, "training_acc": 52.0, "val_loss": 17.27171540260315, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25248217582703, "training_acc": 52.0, "val_loss": 17.269831895828247, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24742078781128, "training_acc": 52.0, "val_loss": 17.269279062747955, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23825740814209, "training_acc": 52.0, "val_loss": 17.262914776802063, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25855588912964, "training_acc": 52.0, "val_loss": 17.25727468729019, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.282954454422, "training_acc": 52.0, "val_loss": 17.245866358280182, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23733019828796, "training_acc": 52.0, "val_loss": 17.24119931459427, "val_acc": 56.0}
