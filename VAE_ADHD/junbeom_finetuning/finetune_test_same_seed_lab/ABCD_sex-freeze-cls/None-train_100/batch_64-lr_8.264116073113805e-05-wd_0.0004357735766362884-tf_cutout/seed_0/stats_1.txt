"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.37068247795105, "training_acc": 47.0, "val_loss": 17.460252344608307, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.0828607082367, "training_acc": 47.0, "val_loss": 17.39221215248108, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.65982794761658, "training_acc": 47.0, "val_loss": 17.35208034515381, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.41060304641724, "training_acc": 47.0, "val_loss": 17.32669472694397, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.40345311164856, "training_acc": 39.0, "val_loss": 17.31015145778656, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19441747665405, "training_acc": 53.0, "val_loss": 17.303958535194397, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11747288703918, "training_acc": 53.0, "val_loss": 17.302747070789337, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14552068710327, "training_acc": 53.0, "val_loss": 17.305952310562134, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11894965171814, "training_acc": 53.0, "val_loss": 17.312675714492798, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17694425582886, "training_acc": 53.0, "val_loss": 17.322304844856262, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.18424654006958, "training_acc": 53.0, "val_loss": 17.331333458423615, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17525219917297, "training_acc": 53.0, "val_loss": 17.33785718679428, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20551562309265, "training_acc": 53.0, "val_loss": 17.3420712351799, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19182467460632, "training_acc": 53.0, "val_loss": 17.342551052570343, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20946502685547, "training_acc": 53.0, "val_loss": 17.341740429401398, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22554898262024, "training_acc": 53.0, "val_loss": 17.342297732830048, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22280836105347, "training_acc": 53.0, "val_loss": 17.339687049388885, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20127034187317, "training_acc": 53.0, "val_loss": 17.338018119335175, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.18802762031555, "training_acc": 53.0, "val_loss": 17.333145439624786, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19891023635864, "training_acc": 53.0, "val_loss": 17.32391268014908, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16453075408936, "training_acc": 53.0, "val_loss": 17.317141592502594, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22407627105713, "training_acc": 53.0, "val_loss": 17.311500012874603, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15358185768127, "training_acc": 53.0, "val_loss": 17.31000989675522, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17875242233276, "training_acc": 53.0, "val_loss": 17.308692634105682, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14361882209778, "training_acc": 53.0, "val_loss": 17.307883501052856, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15557050704956, "training_acc": 53.0, "val_loss": 17.30831116437912, "val_acc": 52.0}
