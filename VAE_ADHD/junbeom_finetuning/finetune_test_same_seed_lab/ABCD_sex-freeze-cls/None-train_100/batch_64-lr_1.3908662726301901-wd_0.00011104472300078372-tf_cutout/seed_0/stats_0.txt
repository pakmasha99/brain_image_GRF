"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 11359.727096557617, "training_acc": 50.0, "val_loss": 2192.879295349121, "val_acc": 44.0}
{"epoch": 1, "training_loss": 11669.103271484375, "training_acc": 48.0, "val_loss": 5575.42724609375, "val_acc": 56.0}
{"epoch": 2, "training_loss": 23766.264892578125, "training_acc": 52.0, "val_loss": 3410.169219970703, "val_acc": 56.0}
{"epoch": 3, "training_loss": 10183.573181152344, "training_acc": 52.0, "val_loss": 3563.926315307617, "val_acc": 44.0}
{"epoch": 4, "training_loss": 16222.393859863281, "training_acc": 48.0, "val_loss": 6208.8623046875, "val_acc": 44.0}
{"epoch": 5, "training_loss": 21883.151428222656, "training_acc": 48.0, "val_loss": 3233.2290649414062, "val_acc": 44.0}
{"epoch": 6, "training_loss": 8120.936664581299, "training_acc": 48.0, "val_loss": 2564.1292572021484, "val_acc": 56.0}
{"epoch": 7, "training_loss": 13598.190307617188, "training_acc": 52.0, "val_loss": 4948.329925537109, "val_acc": 56.0}
{"epoch": 8, "training_loss": 21524.059326171875, "training_acc": 52.0, "val_loss": 3964.2593383789062, "val_acc": 56.0}
{"epoch": 9, "training_loss": 14741.602478027344, "training_acc": 52.0, "val_loss": 256.4086437225342, "val_acc": 56.0}
{"epoch": 10, "training_loss": 4823.159759521484, "training_acc": 50.0, "val_loss": 4997.932434082031, "val_acc": 44.0}
{"epoch": 11, "training_loss": 19541.455993652344, "training_acc": 48.0, "val_loss": 5531.605529785156, "val_acc": 44.0}
{"epoch": 12, "training_loss": 19085.415405273438, "training_acc": 48.0, "val_loss": 2413.1568908691406, "val_acc": 44.0}
{"epoch": 13, "training_loss": 5737.540241241455, "training_acc": 52.0, "val_loss": 1372.1977233886719, "val_acc": 56.0}
{"epoch": 14, "training_loss": 6560.942108154297, "training_acc": 52.0, "val_loss": 1502.0039558410645, "val_acc": 56.0}
{"epoch": 15, "training_loss": 5262.121139526367, "training_acc": 52.0, "val_loss": 1114.249610900879, "val_acc": 44.0}
{"epoch": 16, "training_loss": 5033.7059326171875, "training_acc": 48.0, "val_loss": 1567.7285194396973, "val_acc": 44.0}
{"epoch": 17, "training_loss": 4308.056427001953, "training_acc": 48.0, "val_loss": 1142.6606178283691, "val_acc": 56.0}
{"epoch": 18, "training_loss": 6054.4808349609375, "training_acc": 52.0, "val_loss": 1815.9650802612305, "val_acc": 56.0}
{"epoch": 19, "training_loss": 6862.188247680664, "training_acc": 52.0, "val_loss": 116.57660007476807, "val_acc": 44.0}
{"epoch": 20, "training_loss": 1260.9741592407227, "training_acc": 48.0, "val_loss": 271.46270275115967, "val_acc": 44.0}
{"epoch": 21, "training_loss": 1604.8204498291016, "training_acc": 54.0, "val_loss": 1034.800910949707, "val_acc": 56.0}
{"epoch": 22, "training_loss": 3933.8538208007812, "training_acc": 52.0, "val_loss": 402.36992835998535, "val_acc": 44.0}
{"epoch": 23, "training_loss": 1791.6949768066406, "training_acc": 48.0, "val_loss": 70.75217366218567, "val_acc": 44.0}
{"epoch": 24, "training_loss": 2027.0992431640625, "training_acc": 46.0, "val_loss": 1383.6731910705566, "val_acc": 56.0}
{"epoch": 25, "training_loss": 5479.039596557617, "training_acc": 52.0, "val_loss": 62.708038091659546, "val_acc": 56.0}
{"epoch": 26, "training_loss": 1678.9796447753906, "training_acc": 62.0, "val_loss": 2607.5984954833984, "val_acc": 44.0}
{"epoch": 27, "training_loss": 9614.259521484375, "training_acc": 48.0, "val_loss": 1663.045883178711, "val_acc": 44.0}
{"epoch": 28, "training_loss": 3731.479552268982, "training_acc": 48.0, "val_loss": 1788.5723114013672, "val_acc": 56.0}
{"epoch": 29, "training_loss": 9206.944244384766, "training_acc": 52.0, "val_loss": 3028.1307220458984, "val_acc": 56.0}
{"epoch": 30, "training_loss": 12621.792602539062, "training_acc": 52.0, "val_loss": 1651.4253616333008, "val_acc": 56.0}
{"epoch": 31, "training_loss": 5352.435302734375, "training_acc": 42.0, "val_loss": 942.8614616394043, "val_acc": 44.0}
{"epoch": 32, "training_loss": 3367.308349609375, "training_acc": 48.0, "val_loss": 72.06312417984009, "val_acc": 56.0}
{"epoch": 33, "training_loss": 314.3327693939209, "training_acc": 52.0, "val_loss": 655.6205749511719, "val_acc": 44.0}
{"epoch": 34, "training_loss": 2127.496326446533, "training_acc": 48.0, "val_loss": 482.2507381439209, "val_acc": 56.0}
{"epoch": 35, "training_loss": 2227.578140258789, "training_acc": 52.0, "val_loss": 18.359793722629547, "val_acc": 56.0}
{"epoch": 36, "training_loss": 1417.0111465454102, "training_acc": 48.0, "val_loss": 888.3909225463867, "val_acc": 44.0}
{"epoch": 37, "training_loss": 1931.4077892303467, "training_acc": 48.0, "val_loss": 1363.4739875793457, "val_acc": 56.0}
{"epoch": 38, "training_loss": 6589.929260253906, "training_acc": 52.0, "val_loss": 1915.3059005737305, "val_acc": 56.0}
{"epoch": 39, "training_loss": 7316.88232421875, "training_acc": 52.0, "val_loss": 91.5777862071991, "val_acc": 56.0}
{"epoch": 40, "training_loss": 3152.606170654297, "training_acc": 50.0, "val_loss": 3269.6365356445312, "val_acc": 44.0}
{"epoch": 41, "training_loss": 12337.494506835938, "training_acc": 48.0, "val_loss": 2664.8691177368164, "val_acc": 44.0}
{"epoch": 42, "training_loss": 8033.873107910156, "training_acc": 48.0, "val_loss": 920.2969551086426, "val_acc": 56.0}
{"epoch": 43, "training_loss": 6070.6954345703125, "training_acc": 52.0, "val_loss": 2062.606430053711, "val_acc": 56.0}
{"epoch": 44, "training_loss": 8189.37532043457, "training_acc": 52.0, "val_loss": 414.76101875305176, "val_acc": 56.0}
{"epoch": 45, "training_loss": 2896.6520080566406, "training_acc": 54.0, "val_loss": 2504.02774810791, "val_acc": 44.0}
{"epoch": 46, "training_loss": 9317.255737304688, "training_acc": 48.0, "val_loss": 1698.2210159301758, "val_acc": 44.0}
{"epoch": 47, "training_loss": 3961.7797985076904, "training_acc": 48.0, "val_loss": 1761.1679077148438, "val_acc": 56.0}
{"epoch": 48, "training_loss": 9426.182922363281, "training_acc": 52.0, "val_loss": 3121.7897415161133, "val_acc": 56.0}
{"epoch": 49, "training_loss": 13055.076477050781, "training_acc": 52.0, "val_loss": 1796.1708068847656, "val_acc": 56.0}
{"epoch": 50, "training_loss": 5225.433540344238, "training_acc": 52.0, "val_loss": 2259.3568801879883, "val_acc": 44.0}
{"epoch": 51, "training_loss": 10263.753234863281, "training_acc": 48.0, "val_loss": 4197.188949584961, "val_acc": 44.0}
{"epoch": 52, "training_loss": 14983.614807128906, "training_acc": 48.0, "val_loss": 2470.6018447875977, "val_acc": 44.0}
{"epoch": 53, "training_loss": 6593.5687255859375, "training_acc": 48.0, "val_loss": 1708.132553100586, "val_acc": 56.0}
{"epoch": 54, "training_loss": 9209.878875732422, "training_acc": 52.0, "val_loss": 3416.949462890625, "val_acc": 56.0}
