"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 8903.54050064087, "training_acc": 53.0, "val_loss": 1343.455982208252, "val_acc": 52.0}
{"epoch": 1, "training_loss": 7809.467590332031, "training_acc": 63.0, "val_loss": 7327.5238037109375, "val_acc": 48.0}
{"epoch": 2, "training_loss": 28240.147583007812, "training_acc": 47.0, "val_loss": 3282.9635620117188, "val_acc": 48.0}
{"epoch": 3, "training_loss": 8939.642929077148, "training_acc": 53.0, "val_loss": 2531.512451171875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 10375.284301757812, "training_acc": 53.0, "val_loss": 1834.0402603149414, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5886.982372283936, "training_acc": 41.0, "val_loss": 632.8118801116943, "val_acc": 48.0}
{"epoch": 6, "training_loss": 1659.0551471710205, "training_acc": 55.0, "val_loss": 24.76559430360794, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1006.9697113037109, "training_acc": 45.0, "val_loss": 129.88173961639404, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1841.3184509277344, "training_acc": 55.0, "val_loss": 1414.069652557373, "val_acc": 48.0}
{"epoch": 9, "training_loss": 4633.234046936035, "training_acc": 47.0, "val_loss": 1015.6021118164062, "val_acc": 52.0}
{"epoch": 10, "training_loss": 5136.195617675781, "training_acc": 53.0, "val_loss": 1284.0238571166992, "val_acc": 52.0}
{"epoch": 11, "training_loss": 3152.5492248535156, "training_acc": 53.0, "val_loss": 1725.473403930664, "val_acc": 48.0}
{"epoch": 12, "training_loss": 8245.847778320312, "training_acc": 47.0, "val_loss": 2517.702865600586, "val_acc": 48.0}
{"epoch": 13, "training_loss": 8701.678649902344, "training_acc": 47.0, "val_loss": 174.53380823135376, "val_acc": 52.0}
{"epoch": 14, "training_loss": 2172.6345825195312, "training_acc": 53.0, "val_loss": 1015.4101371765137, "val_acc": 52.0}
{"epoch": 15, "training_loss": 3016.190450668335, "training_acc": 53.0, "val_loss": 1246.4642524719238, "val_acc": 48.0}
{"epoch": 16, "training_loss": 5510.158233642578, "training_acc": 47.0, "val_loss": 1185.455322265625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2944.8937723636627, "training_acc": 47.0, "val_loss": 1272.018814086914, "val_acc": 52.0}
{"epoch": 18, "training_loss": 5537.746643066406, "training_acc": 53.0, "val_loss": 1391.8571472167969, "val_acc": 52.0}
{"epoch": 19, "training_loss": 4074.499542236328, "training_acc": 53.0, "val_loss": 1263.5197639465332, "val_acc": 48.0}
{"epoch": 20, "training_loss": 5811.620834350586, "training_acc": 47.0, "val_loss": 1677.065086364746, "val_acc": 48.0}
{"epoch": 21, "training_loss": 5467.984550476074, "training_acc": 47.0, "val_loss": 994.2785263061523, "val_acc": 52.0}
{"epoch": 22, "training_loss": 4649.86799621582, "training_acc": 53.0, "val_loss": 1647.6722717285156, "val_acc": 52.0}
{"epoch": 23, "training_loss": 5451.2550048828125, "training_acc": 53.0, "val_loss": 397.5670099258423, "val_acc": 48.0}
{"epoch": 24, "training_loss": 2285.9716796875, "training_acc": 47.0, "val_loss": 413.5890483856201, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2705.638717651367, "training_acc": 41.0, "val_loss": 1106.0601234436035, "val_acc": 52.0}
