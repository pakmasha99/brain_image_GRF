"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 11356.713939666748, "training_acc": 53.0, "val_loss": 2331.9061279296875, "val_acc": 52.0}
{"epoch": 1, "training_loss": 8789.333892822266, "training_acc": 61.0, "val_loss": 5715.898132324219, "val_acc": 48.0}
{"epoch": 2, "training_loss": 21899.03790283203, "training_acc": 47.0, "val_loss": 2042.7589416503906, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7767.780822753906, "training_acc": 49.0, "val_loss": 3362.093734741211, "val_acc": 52.0}
{"epoch": 4, "training_loss": 13589.866149902344, "training_acc": 53.0, "val_loss": 2594.815444946289, "val_acc": 52.0}
{"epoch": 5, "training_loss": 7545.29630279541, "training_acc": 53.0, "val_loss": 2189.215850830078, "val_acc": 48.0}
{"epoch": 6, "training_loss": 11120.606689453125, "training_acc": 47.0, "val_loss": 3471.8387603759766, "val_acc": 48.0}
{"epoch": 7, "training_loss": 12402.055084228516, "training_acc": 47.0, "val_loss": 301.72619819641113, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4102.285461425781, "training_acc": 49.0, "val_loss": 3834.1140747070312, "val_acc": 52.0}
{"epoch": 9, "training_loss": 15852.325988769531, "training_acc": 53.0, "val_loss": 4042.751693725586, "val_acc": 52.0}
{"epoch": 10, "training_loss": 14197.211059570312, "training_acc": 53.0, "val_loss": 1229.708480834961, "val_acc": 52.0}
{"epoch": 11, "training_loss": 5542.467727661133, "training_acc": 45.0, "val_loss": 2531.18839263916, "val_acc": 48.0}
{"epoch": 12, "training_loss": 10589.928955078125, "training_acc": 47.0, "val_loss": 2059.4282150268555, "val_acc": 48.0}
{"epoch": 13, "training_loss": 6247.940605163574, "training_acc": 47.0, "val_loss": 1467.4174308776855, "val_acc": 52.0}
{"epoch": 14, "training_loss": 6938.492340087891, "training_acc": 53.0, "val_loss": 2823.423194885254, "val_acc": 52.0}
{"epoch": 15, "training_loss": 10485.19692993164, "training_acc": 53.0, "val_loss": 1349.014663696289, "val_acc": 52.0}
{"epoch": 16, "training_loss": 4222.108787536621, "training_acc": 47.0, "val_loss": 1100.3536224365234, "val_acc": 48.0}
{"epoch": 17, "training_loss": 4182.906799316406, "training_acc": 47.0, "val_loss": 123.01487922668457, "val_acc": 52.0}
{"epoch": 18, "training_loss": 992.5070114135742, "training_acc": 53.0, "val_loss": 259.13543701171875, "val_acc": 48.0}
{"epoch": 19, "training_loss": 768.1736068725586, "training_acc": 47.0, "val_loss": 887.6949310302734, "val_acc": 52.0}
{"epoch": 20, "training_loss": 3643.588836669922, "training_acc": 53.0, "val_loss": 539.603853225708, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1557.2802810668945, "training_acc": 63.0, "val_loss": 868.1485176086426, "val_acc": 48.0}
{"epoch": 22, "training_loss": 2838.538341522217, "training_acc": 47.0, "val_loss": 827.394962310791, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3659.1797790527344, "training_acc": 53.0, "val_loss": 779.0208339691162, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2311.9888305664062, "training_acc": 51.0, "val_loss": 401.0976314544678, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1126.3345279693604, "training_acc": 57.0, "val_loss": 160.80056428909302, "val_acc": 52.0}
{"epoch": 26, "training_loss": 766.6940803527832, "training_acc": 63.0, "val_loss": 430.0652027130127, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1497.669563293457, "training_acc": 53.0, "val_loss": 412.03479766845703, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1058.5379123687744, "training_acc": 59.0, "val_loss": 19.116507470607758, "val_acc": 48.0}
{"epoch": 29, "training_loss": 553.1784629821777, "training_acc": 51.0, "val_loss": 63.84669542312622, "val_acc": 52.0}
{"epoch": 30, "training_loss": 1487.6172943115234, "training_acc": 53.0, "val_loss": 1083.494758605957, "val_acc": 48.0}
{"epoch": 31, "training_loss": 3322.784885406494, "training_acc": 47.0, "val_loss": 1097.791576385498, "val_acc": 52.0}
{"epoch": 32, "training_loss": 4950.185546875, "training_acc": 53.0, "val_loss": 1469.0011978149414, "val_acc": 52.0}
{"epoch": 33, "training_loss": 4611.016227722168, "training_acc": 53.0, "val_loss": 887.9971504211426, "val_acc": 48.0}
{"epoch": 34, "training_loss": 4408.341552734375, "training_acc": 47.0, "val_loss": 1062.1252059936523, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2582.5099635124207, "training_acc": 55.0, "val_loss": 432.03840255737305, "val_acc": 52.0}
{"epoch": 36, "training_loss": 1199.8908152580261, "training_acc": 53.0, "val_loss": 953.4322738647461, "val_acc": 48.0}
{"epoch": 37, "training_loss": 3774.735641479492, "training_acc": 47.0, "val_loss": 154.72588539123535, "val_acc": 48.0}
{"epoch": 38, "training_loss": 1707.5182647705078, "training_acc": 55.0, "val_loss": 1730.7975769042969, "val_acc": 52.0}
{"epoch": 39, "training_loss": 6576.34423828125, "training_acc": 53.0, "val_loss": 700.0754356384277, "val_acc": 52.0}
{"epoch": 40, "training_loss": 2875.2515258789062, "training_acc": 53.0, "val_loss": 1498.1761932373047, "val_acc": 48.0}
{"epoch": 41, "training_loss": 5718.012924194336, "training_acc": 47.0, "val_loss": 120.56102752685547, "val_acc": 48.0}
{"epoch": 42, "training_loss": 2952.367889404297, "training_acc": 45.0, "val_loss": 2458.736228942871, "val_acc": 52.0}
{"epoch": 43, "training_loss": 9671.01919555664, "training_acc": 53.0, "val_loss": 1814.4277572631836, "val_acc": 52.0}
{"epoch": 44, "training_loss": 4986.564002990723, "training_acc": 53.0, "val_loss": 1458.8994026184082, "val_acc": 48.0}
{"epoch": 45, "training_loss": 7365.9012451171875, "training_acc": 47.0, "val_loss": 2599.6734619140625, "val_acc": 48.0}
{"epoch": 46, "training_loss": 9563.728149414062, "training_acc": 47.0, "val_loss": 339.47715759277344, "val_acc": 48.0}
{"epoch": 47, "training_loss": 3278.405059814453, "training_acc": 49.0, "val_loss": 2791.9897079467773, "val_acc": 52.0}
