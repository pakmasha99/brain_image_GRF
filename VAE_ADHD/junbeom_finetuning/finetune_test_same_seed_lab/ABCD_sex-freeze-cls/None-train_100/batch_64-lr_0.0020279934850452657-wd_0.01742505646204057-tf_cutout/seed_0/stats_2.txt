"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 75.84734725952148, "training_acc": 53.0, "val_loss": 17.771758139133453, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.77566266059875, "training_acc": 49.0, "val_loss": 18.024738132953644, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.76005434989929, "training_acc": 47.0, "val_loss": 17.992231249809265, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.37738108634949, "training_acc": 47.0, "val_loss": 17.30646640062332, "val_acc": 52.0}
{"epoch": 4, "training_loss": 68.86288452148438, "training_acc": 53.0, "val_loss": 17.895150184631348, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.65699458122253, "training_acc": 53.0, "val_loss": 18.098224699497223, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.19730710983276, "training_acc": 53.0, "val_loss": 17.401684820652008, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.30603742599487, "training_acc": 53.0, "val_loss": 17.48708486557007, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.43753838539124, "training_acc": 47.0, "val_loss": 17.715735733509064, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.91041374206543, "training_acc": 47.0, "val_loss": 17.380662262439728, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.45464324951172, "training_acc": 49.0, "val_loss": 17.43272989988327, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.29897046089172, "training_acc": 53.0, "val_loss": 17.7328959107399, "val_acc": 52.0}
{"epoch": 12, "training_loss": 70.72328209877014, "training_acc": 53.0, "val_loss": 17.734643816947937, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.47325420379639, "training_acc": 53.0, "val_loss": 17.544113099575043, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.52116990089417, "training_acc": 53.0, "val_loss": 17.311793565750122, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.78719854354858, "training_acc": 45.0, "val_loss": 17.416967451572418, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.77256226539612, "training_acc": 47.0, "val_loss": 17.376914620399475, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.46811032295227, "training_acc": 47.0, "val_loss": 17.305763065814972, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.98605918884277, "training_acc": 53.0, "val_loss": 17.455898225307465, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.58479881286621, "training_acc": 53.0, "val_loss": 17.590472102165222, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.06690526008606, "training_acc": 53.0, "val_loss": 17.42195636034012, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.29899072647095, "training_acc": 53.0, "val_loss": 17.311817407608032, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.29386115074158, "training_acc": 53.0, "val_loss": 17.35604852437973, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.6259355545044, "training_acc": 47.0, "val_loss": 17.3435777425766, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.3471827507019, "training_acc": 49.0, "val_loss": 17.320601642131805, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.07458472251892, "training_acc": 53.0, "val_loss": 17.42304414510727, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.62326550483704, "training_acc": 53.0, "val_loss": 17.477303743362427, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.50898861885071, "training_acc": 53.0, "val_loss": 17.32538938522339, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.27206063270569, "training_acc": 53.0, "val_loss": 17.327232658863068, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.32814645767212, "training_acc": 46.0, "val_loss": 17.33115315437317, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.43333745002747, "training_acc": 45.0, "val_loss": 17.306457459926605, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.20793199539185, "training_acc": 53.0, "val_loss": 17.311233282089233, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.18176293373108, "training_acc": 53.0, "val_loss": 17.317670583724976, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.24249267578125, "training_acc": 53.0, "val_loss": 17.339734733104706, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17956161499023, "training_acc": 53.0, "val_loss": 17.314189672470093, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.13650274276733, "training_acc": 53.0, "val_loss": 17.305988073349, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.15869879722595, "training_acc": 53.0, "val_loss": 17.30661541223526, "val_acc": 52.0}
