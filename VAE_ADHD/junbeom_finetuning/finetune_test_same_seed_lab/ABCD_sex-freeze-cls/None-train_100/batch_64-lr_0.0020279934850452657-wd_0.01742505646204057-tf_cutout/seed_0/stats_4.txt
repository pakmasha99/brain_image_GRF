"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.27554869651794, "training_acc": 49.0, "val_loss": 17.46002584695816, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.93202543258667, "training_acc": 47.0, "val_loss": 18.600425124168396, "val_acc": 52.0}
{"epoch": 2, "training_loss": 73.54620361328125, "training_acc": 53.0, "val_loss": 17.8180992603302, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.20248532295227, "training_acc": 53.0, "val_loss": 17.422227561473846, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.32604169845581, "training_acc": 47.0, "val_loss": 17.863576114177704, "val_acc": 52.0}
{"epoch": 5, "training_loss": 71.46711802482605, "training_acc": 47.0, "val_loss": 17.40429699420929, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.26490616798401, "training_acc": 51.0, "val_loss": 17.495329678058624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.84779381752014, "training_acc": 53.0, "val_loss": 17.867442965507507, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.91230797767639, "training_acc": 53.0, "val_loss": 17.526184022426605, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.71812510490417, "training_acc": 53.0, "val_loss": 17.345090210437775, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.75125551223755, "training_acc": 47.0, "val_loss": 17.51478463411331, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.10113024711609, "training_acc": 47.0, "val_loss": 17.343318462371826, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.07418894767761, "training_acc": 57.0, "val_loss": 17.381858825683594, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.20435690879822, "training_acc": 53.0, "val_loss": 17.689651250839233, "val_acc": 52.0}
{"epoch": 14, "training_loss": 70.18050456047058, "training_acc": 53.0, "val_loss": 17.411723732948303, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.01417183876038, "training_acc": 53.0, "val_loss": 17.362289130687714, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.35522699356079, "training_acc": 47.0, "val_loss": 17.575080692768097, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.63264584541321, "training_acc": 47.0, "val_loss": 17.492642998695374, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.77906918525696, "training_acc": 47.0, "val_loss": 17.32313483953476, "val_acc": 52.0}
{"epoch": 19, "training_loss": 70.92912268638611, "training_acc": 53.0, "val_loss": 17.590828239917755, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.84686374664307, "training_acc": 53.0, "val_loss": 17.37547069787979, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.4979088306427, "training_acc": 53.0, "val_loss": 17.325744032859802, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.26316165924072, "training_acc": 53.0, "val_loss": 17.348161339759827, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.75849604606628, "training_acc": 47.0, "val_loss": 17.316757142543793, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.90439796447754, "training_acc": 53.0, "val_loss": 17.43738353252411, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.99554538726807, "training_acc": 53.0, "val_loss": 17.651301622390747, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.99375557899475, "training_acc": 53.0, "val_loss": 17.38307476043701, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.98730969429016, "training_acc": 53.0, "val_loss": 17.371581494808197, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.42350888252258, "training_acc": 47.0, "val_loss": 17.55511462688446, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.69187688827515, "training_acc": 47.0, "val_loss": 17.48182326555252, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.99651837348938, "training_acc": 47.0, "val_loss": 17.351847887039185, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.25716662406921, "training_acc": 47.0, "val_loss": 17.338529229164124, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.00335836410522, "training_acc": 53.0, "val_loss": 17.63930916786194, "val_acc": 52.0}
{"epoch": 33, "training_loss": 70.16996884346008, "training_acc": 53.0, "val_loss": 17.46278703212738, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.40005040168762, "training_acc": 53.0, "val_loss": 17.32058674097061, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.56653380393982, "training_acc": 47.0, "val_loss": 17.393401265144348, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.71078896522522, "training_acc": 47.0, "val_loss": 17.35936552286148, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.3903477191925, "training_acc": 49.0, "val_loss": 17.325465381145477, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.87387442588806, "training_acc": 53.0, "val_loss": 17.424647510051727, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.37138772010803, "training_acc": 53.0, "val_loss": 17.326535284519196, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.61914110183716, "training_acc": 54.0, "val_loss": 17.342044413089752, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.38009262084961, "training_acc": 47.0, "val_loss": 17.319776117801666, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.237060546875, "training_acc": 53.0, "val_loss": 17.317229509353638, "val_acc": 52.0}
