"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 73.2903299331665, "training_acc": 45.0, "val_loss": 17.613478004932404, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.96433281898499, "training_acc": 47.0, "val_loss": 17.747382819652557, "val_acc": 52.0}
{"epoch": 2, "training_loss": 72.23417234420776, "training_acc": 47.0, "val_loss": 17.471882700920105, "val_acc": 52.0}
{"epoch": 3, "training_loss": 68.98864841461182, "training_acc": 55.0, "val_loss": 17.621131241321564, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.27893543243408, "training_acc": 53.0, "val_loss": 18.290767073631287, "val_acc": 52.0}
{"epoch": 5, "training_loss": 72.49240255355835, "training_acc": 53.0, "val_loss": 17.745235562324524, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.05836176872253, "training_acc": 53.0, "val_loss": 17.34115779399872, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1483097076416, "training_acc": 47.0, "val_loss": 17.759986221790314, "val_acc": 52.0}
{"epoch": 8, "training_loss": 71.75874280929565, "training_acc": 47.0, "val_loss": 17.73134171962738, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.55674839019775, "training_acc": 47.0, "val_loss": 17.308683693408966, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.2831482887268, "training_acc": 53.0, "val_loss": 17.699038982391357, "val_acc": 52.0}
{"epoch": 11, "training_loss": 70.64312982559204, "training_acc": 53.0, "val_loss": 17.865808308124542, "val_acc": 52.0}
{"epoch": 12, "training_loss": 71.69283294677734, "training_acc": 53.0, "val_loss": 17.455025017261505, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.33808422088623, "training_acc": 53.0, "val_loss": 17.31926053762436, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.91531705856323, "training_acc": 53.0, "val_loss": 17.3738956451416, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.65534281730652, "training_acc": 47.0, "val_loss": 17.520812153816223, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.29726815223694, "training_acc": 47.0, "val_loss": 17.38574206829071, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.60276103019714, "training_acc": 47.0, "val_loss": 17.34573394060135, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17164921760559, "training_acc": 53.0, "val_loss": 17.516450583934784, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.73628640174866, "training_acc": 53.0, "val_loss": 17.48649924993515, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.80637168884277, "training_acc": 53.0, "val_loss": 17.3381969332695, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1248779296875, "training_acc": 53.0, "val_loss": 17.30833798646927, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.150958776474, "training_acc": 53.0, "val_loss": 17.325152456760406, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.8327305316925, "training_acc": 39.0, "val_loss": 17.31969863176346, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.08895945549011, "training_acc": 53.0, "val_loss": 17.372111976146698, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.19174313545227, "training_acc": 53.0, "val_loss": 17.50689297914505, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.73591589927673, "training_acc": 53.0, "val_loss": 17.452868819236755, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.28136491775513, "training_acc": 53.0, "val_loss": 17.309346795082092, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.89525938034058, "training_acc": 53.0, "val_loss": 17.435573041439056, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.9792058467865, "training_acc": 47.0, "val_loss": 17.62957274913788, "val_acc": 52.0}
{"epoch": 30, "training_loss": 70.59766697883606, "training_acc": 47.0, "val_loss": 17.37729012966156, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.41097378730774, "training_acc": 49.0, "val_loss": 17.37562119960785, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.40714955329895, "training_acc": 53.0, "val_loss": 17.587868869304657, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.91024112701416, "training_acc": 53.0, "val_loss": 17.447975277900696, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.63001751899719, "training_acc": 53.0, "val_loss": 17.310401797294617, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.24304986000061, "training_acc": 53.0, "val_loss": 17.32340157032013, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.36381816864014, "training_acc": 47.0, "val_loss": 17.31037348508835, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.75225448608398, "training_acc": 53.0, "val_loss": 17.346085608005524, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.20370364189148, "training_acc": 53.0, "val_loss": 17.31797903776169, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.50099205970764, "training_acc": 53.0, "val_loss": 17.31591373682022, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.56780743598938, "training_acc": 53.0, "val_loss": 17.309489846229553, "val_acc": 52.0}
