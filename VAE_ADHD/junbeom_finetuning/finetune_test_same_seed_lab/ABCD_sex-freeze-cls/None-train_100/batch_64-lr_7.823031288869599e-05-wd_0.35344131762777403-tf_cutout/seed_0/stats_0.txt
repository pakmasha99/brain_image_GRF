"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24176716804504, "training_acc": 52.0, "val_loss": 17.242376506328583, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2383770942688, "training_acc": 52.0, "val_loss": 17.219966650009155, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.25725293159485, "training_acc": 52.0, "val_loss": 17.21794158220291, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.2636570930481, "training_acc": 52.0, "val_loss": 17.229247093200684, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24076581001282, "training_acc": 52.0, "val_loss": 17.24741756916046, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22718262672424, "training_acc": 52.0, "val_loss": 17.253980040550232, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26156735420227, "training_acc": 52.0, "val_loss": 17.267203330993652, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26221489906311, "training_acc": 52.0, "val_loss": 17.27229654788971, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27868247032166, "training_acc": 52.0, "val_loss": 17.265023291110992, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25827860832214, "training_acc": 52.0, "val_loss": 17.26757436990738, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23474359512329, "training_acc": 52.0, "val_loss": 17.267964780330658, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26501369476318, "training_acc": 52.0, "val_loss": 17.263373732566833, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23497343063354, "training_acc": 52.0, "val_loss": 17.258082330226898, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23854565620422, "training_acc": 52.0, "val_loss": 17.256197333335876, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24642634391785, "training_acc": 52.0, "val_loss": 17.2487273812294, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24959540367126, "training_acc": 52.0, "val_loss": 17.238420248031616, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25132131576538, "training_acc": 52.0, "val_loss": 17.22412109375, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23378825187683, "training_acc": 52.0, "val_loss": 17.215220630168915, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24303817749023, "training_acc": 52.0, "val_loss": 17.208842933177948, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26068949699402, "training_acc": 52.0, "val_loss": 17.204856872558594, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21095371246338, "training_acc": 52.0, "val_loss": 17.205452919006348, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.2321264743805, "training_acc": 52.0, "val_loss": 17.205600440502167, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29083251953125, "training_acc": 52.0, "val_loss": 17.202500998973846, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26151967048645, "training_acc": 52.0, "val_loss": 17.20740795135498, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25747036933899, "training_acc": 52.0, "val_loss": 17.216715216636658, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.25043988227844, "training_acc": 52.0, "val_loss": 17.229971289634705, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28046417236328, "training_acc": 52.0, "val_loss": 17.235663533210754, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22755837440491, "training_acc": 52.0, "val_loss": 17.252612113952637, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25344395637512, "training_acc": 52.0, "val_loss": 17.267566919326782, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26785349845886, "training_acc": 52.0, "val_loss": 17.271722853183746, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.28711652755737, "training_acc": 52.0, "val_loss": 17.267733812332153, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28688502311707, "training_acc": 52.0, "val_loss": 17.273184657096863, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25452876091003, "training_acc": 52.0, "val_loss": 17.265020310878754, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25785183906555, "training_acc": 52.0, "val_loss": 17.257651686668396, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.2623245716095, "training_acc": 52.0, "val_loss": 17.247144877910614, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2392065525055, "training_acc": 52.0, "val_loss": 17.24100112915039, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23621702194214, "training_acc": 52.0, "val_loss": 17.234934866428375, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23665428161621, "training_acc": 52.0, "val_loss": 17.228278517723083, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.2283182144165, "training_acc": 52.0, "val_loss": 17.216968536376953, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25612568855286, "training_acc": 52.0, "val_loss": 17.202867567539215, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.23617577552795, "training_acc": 52.0, "val_loss": 17.19745248556137, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.26243495941162, "training_acc": 52.0, "val_loss": 17.194567620754242, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27551198005676, "training_acc": 52.0, "val_loss": 17.193540930747986, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24411392211914, "training_acc": 52.0, "val_loss": 17.197516560554504, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25886988639832, "training_acc": 52.0, "val_loss": 17.209236323833466, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.2400131225586, "training_acc": 52.0, "val_loss": 17.218783497810364, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25357556343079, "training_acc": 52.0, "val_loss": 17.230504751205444, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24186706542969, "training_acc": 52.0, "val_loss": 17.242133617401123, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.2262806892395, "training_acc": 52.0, "val_loss": 17.246928811073303, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23422050476074, "training_acc": 52.0, "val_loss": 17.25068837404251, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.2558867931366, "training_acc": 52.0, "val_loss": 17.25732982158661, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25504326820374, "training_acc": 52.0, "val_loss": 17.264264822006226, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.26208806037903, "training_acc": 52.0, "val_loss": 17.26885586977005, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27106976509094, "training_acc": 52.0, "val_loss": 17.273372411727905, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22728419303894, "training_acc": 52.0, "val_loss": 17.275673151016235, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.26435399055481, "training_acc": 52.0, "val_loss": 17.271119356155396, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25155591964722, "training_acc": 52.0, "val_loss": 17.26996898651123, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24784684181213, "training_acc": 52.0, "val_loss": 17.269952595233917, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23872065544128, "training_acc": 52.0, "val_loss": 17.264258861541748, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25969743728638, "training_acc": 52.0, "val_loss": 17.259082198143005, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28267312049866, "training_acc": 52.0, "val_loss": 17.248202860355377, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23828077316284, "training_acc": 52.0, "val_loss": 17.243610322475433, "val_acc": 56.0}
