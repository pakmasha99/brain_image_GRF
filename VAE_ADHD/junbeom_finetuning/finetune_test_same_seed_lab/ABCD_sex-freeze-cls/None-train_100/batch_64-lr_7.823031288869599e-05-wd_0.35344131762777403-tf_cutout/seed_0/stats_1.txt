"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.37933206558228, "training_acc": 47.0, "val_loss": 17.465440928936005, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.10237097740173, "training_acc": 47.0, "val_loss": 17.39913523197174, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.69185900688171, "training_acc": 47.0, "val_loss": 17.358718812465668, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.44550561904907, "training_acc": 47.0, "val_loss": 17.332080006599426, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.42912030220032, "training_acc": 41.0, "val_loss": 17.31368601322174, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21740746498108, "training_acc": 53.0, "val_loss": 17.305660247802734, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13245439529419, "training_acc": 53.0, "val_loss": 17.30273813009262, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15375924110413, "training_acc": 53.0, "val_loss": 17.304205894470215, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11974620819092, "training_acc": 53.0, "val_loss": 17.309528589248657, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17258381843567, "training_acc": 53.0, "val_loss": 17.318065464496613, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17554593086243, "training_acc": 53.0, "val_loss": 17.326773703098297, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16387867927551, "training_acc": 53.0, "val_loss": 17.333735525608063, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19545674324036, "training_acc": 53.0, "val_loss": 17.338864505290985, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18212056159973, "training_acc": 53.0, "val_loss": 17.34064072370529, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20097279548645, "training_acc": 53.0, "val_loss": 17.341063916683197, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22425889968872, "training_acc": 53.0, "val_loss": 17.34258234500885, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.22162795066833, "training_acc": 53.0, "val_loss": 17.34088808298111, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2055025100708, "training_acc": 53.0, "val_loss": 17.339856922626495, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19436979293823, "training_acc": 53.0, "val_loss": 17.33546406030655, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20402455329895, "training_acc": 53.0, "val_loss": 17.326495051383972, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17044568061829, "training_acc": 53.0, "val_loss": 17.3196479678154, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22459483146667, "training_acc": 53.0, "val_loss": 17.31368601322174, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15619349479675, "training_acc": 53.0, "val_loss": 17.31192171573639, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18065524101257, "training_acc": 53.0, "val_loss": 17.310291528701782, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14512944221497, "training_acc": 53.0, "val_loss": 17.309178411960602, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15420770645142, "training_acc": 53.0, "val_loss": 17.309358716011047, "val_acc": 52.0}
