"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3559045791626, "training_acc": 53.0, "val_loss": 17.30995923280716, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17702054977417, "training_acc": 53.0, "val_loss": 17.310114204883575, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15213131904602, "training_acc": 53.0, "val_loss": 17.310558259487152, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18404722213745, "training_acc": 53.0, "val_loss": 17.31012463569641, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1556658744812, "training_acc": 53.0, "val_loss": 17.309433221817017, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18606925010681, "training_acc": 53.0, "val_loss": 17.309245467185974, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14368748664856, "training_acc": 53.0, "val_loss": 17.30964183807373, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14306688308716, "training_acc": 53.0, "val_loss": 17.310504615306854, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12792468070984, "training_acc": 53.0, "val_loss": 17.311784625053406, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13432621955872, "training_acc": 53.0, "val_loss": 17.31291562318802, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15149211883545, "training_acc": 53.0, "val_loss": 17.313252389431, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10954689979553, "training_acc": 53.0, "val_loss": 17.31547862291336, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13222813606262, "training_acc": 53.0, "val_loss": 17.31906533241272, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17539691925049, "training_acc": 53.0, "val_loss": 17.32175648212433, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14646339416504, "training_acc": 53.0, "val_loss": 17.320790886878967, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13505673408508, "training_acc": 53.0, "val_loss": 17.31860339641571, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13073325157166, "training_acc": 53.0, "val_loss": 17.31795221567154, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11757302284241, "training_acc": 53.0, "val_loss": 17.318063974380493, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11373686790466, "training_acc": 53.0, "val_loss": 17.317840456962585, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387488365173, "training_acc": 53.0, "val_loss": 17.318381369113922, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1476399898529, "training_acc": 53.0, "val_loss": 17.317888140678406, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12129282951355, "training_acc": 53.0, "val_loss": 17.315277457237244, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14257431030273, "training_acc": 53.0, "val_loss": 17.31371283531189, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.11605405807495, "training_acc": 53.0, "val_loss": 17.31264442205429, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.106440782547, "training_acc": 53.0, "val_loss": 17.31143891811371, "val_acc": 52.0}
