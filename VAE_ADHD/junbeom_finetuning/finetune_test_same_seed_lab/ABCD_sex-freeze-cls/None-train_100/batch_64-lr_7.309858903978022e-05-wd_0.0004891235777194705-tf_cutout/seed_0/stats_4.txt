"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15625667572021, "training_acc": 47.0, "val_loss": 17.426902055740356, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.80814552307129, "training_acc": 47.0, "val_loss": 17.388148605823517, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.6216938495636, "training_acc": 47.0, "val_loss": 17.35149174928665, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.46753454208374, "training_acc": 47.0, "val_loss": 17.32487678527832, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.38550138473511, "training_acc": 39.0, "val_loss": 17.31056421995163, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2202570438385, "training_acc": 53.0, "val_loss": 17.304393649101257, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1678421497345, "training_acc": 53.0, "val_loss": 17.302770912647247, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11454677581787, "training_acc": 53.0, "val_loss": 17.304757237434387, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11005330085754, "training_acc": 53.0, "val_loss": 17.30918139219284, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12503790855408, "training_acc": 53.0, "val_loss": 17.316724359989166, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1483085155487, "training_acc": 53.0, "val_loss": 17.32421964406967, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16533970832825, "training_acc": 53.0, "val_loss": 17.328259348869324, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17302656173706, "training_acc": 53.0, "val_loss": 17.32828915119171, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19399333000183, "training_acc": 53.0, "val_loss": 17.32652485370636, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16558361053467, "training_acc": 53.0, "val_loss": 17.325367033481598, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15226435661316, "training_acc": 53.0, "val_loss": 17.321504652500153, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20427012443542, "training_acc": 53.0, "val_loss": 17.317500710487366, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13983392715454, "training_acc": 53.0, "val_loss": 17.317092418670654, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1379747390747, "training_acc": 53.0, "val_loss": 17.314434051513672, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14362668991089, "training_acc": 53.0, "val_loss": 17.31192022562027, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10963106155396, "training_acc": 53.0, "val_loss": 17.311599850654602, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12390208244324, "training_acc": 53.0, "val_loss": 17.3110693693161, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13748526573181, "training_acc": 53.0, "val_loss": 17.31046587228775, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12882685661316, "training_acc": 53.0, "val_loss": 17.30893701314926, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13072800636292, "training_acc": 53.0, "val_loss": 17.308002710342407, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13136649131775, "training_acc": 53.0, "val_loss": 17.308364808559418, "val_acc": 52.0}
