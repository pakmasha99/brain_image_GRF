"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.38949227333069, "training_acc": 47.0, "val_loss": 17.471614480018616, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.12580919265747, "training_acc": 47.0, "val_loss": 17.40759164094925, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.73092579841614, "training_acc": 47.0, "val_loss": 17.367111146450043, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.48935723304749, "training_acc": 47.0, "val_loss": 17.33923703432083, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.46277904510498, "training_acc": 49.0, "val_loss": 17.318853735923767, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24893760681152, "training_acc": 53.0, "val_loss": 17.3086941242218, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.15506482124329, "training_acc": 53.0, "val_loss": 17.303667962551117, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.16802549362183, "training_acc": 53.0, "val_loss": 17.302928864955902, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12481760978699, "training_acc": 53.0, "val_loss": 17.306336760520935, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17040634155273, "training_acc": 53.0, "val_loss": 17.31325536966324, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16708016395569, "training_acc": 53.0, "val_loss": 17.321202158927917, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15089774131775, "training_acc": 53.0, "val_loss": 17.328304052352905, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.18264389038086, "training_acc": 53.0, "val_loss": 17.33420640230179, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16868138313293, "training_acc": 53.0, "val_loss": 17.337331175804138, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18830943107605, "training_acc": 53.0, "val_loss": 17.339153587818146, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21997928619385, "training_acc": 53.0, "val_loss": 17.341838777065277, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21730923652649, "training_acc": 53.0, "val_loss": 17.341376841068268, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20840239524841, "training_acc": 53.0, "val_loss": 17.341279983520508, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2007246017456, "training_acc": 53.0, "val_loss": 17.337703704833984, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.20910024642944, "training_acc": 53.0, "val_loss": 17.329345643520355, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1776351928711, "training_acc": 53.0, "val_loss": 17.322659492492676, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22525000572205, "training_acc": 53.0, "val_loss": 17.31652021408081, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16052627563477, "training_acc": 53.0, "val_loss": 17.31451004743576, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18412899971008, "training_acc": 53.0, "val_loss": 17.31254905462265, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14768195152283, "training_acc": 53.0, "val_loss": 17.311091721057892, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1538999080658, "training_acc": 53.0, "val_loss": 17.31097251176834, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13000416755676, "training_acc": 53.0, "val_loss": 17.30957329273224, "val_acc": 52.0}
