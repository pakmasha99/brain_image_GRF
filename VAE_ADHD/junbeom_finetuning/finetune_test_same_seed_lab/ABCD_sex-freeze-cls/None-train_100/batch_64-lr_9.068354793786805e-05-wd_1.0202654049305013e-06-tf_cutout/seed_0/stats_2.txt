"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.20150351524353, "training_acc": 53.0, "val_loss": 17.303088307380676, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1439859867096, "training_acc": 53.0, "val_loss": 17.303264141082764, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.20727467536926, "training_acc": 53.0, "val_loss": 17.309477925300598, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12653851509094, "training_acc": 53.0, "val_loss": 17.314228415489197, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1275224685669, "training_acc": 53.0, "val_loss": 17.318545281887054, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.14435291290283, "training_acc": 53.0, "val_loss": 17.323748767375946, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16268634796143, "training_acc": 53.0, "val_loss": 17.324912548065186, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14464116096497, "training_acc": 53.0, "val_loss": 17.328056693077087, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14081978797913, "training_acc": 53.0, "val_loss": 17.326167225837708, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16911387443542, "training_acc": 53.0, "val_loss": 17.32209026813507, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14468693733215, "training_acc": 53.0, "val_loss": 17.318500578403473, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1064031124115, "training_acc": 53.0, "val_loss": 17.313773930072784, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11662125587463, "training_acc": 53.0, "val_loss": 17.308463156223297, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15348529815674, "training_acc": 53.0, "val_loss": 17.30485111474991, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11566805839539, "training_acc": 53.0, "val_loss": 17.30388253927231, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12471151351929, "training_acc": 53.0, "val_loss": 17.303241789340973, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14106273651123, "training_acc": 53.0, "val_loss": 17.303048074245453, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14979290962219, "training_acc": 53.0, "val_loss": 17.303118109703064, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14796805381775, "training_acc": 53.0, "val_loss": 17.303146421909332, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17318677902222, "training_acc": 53.0, "val_loss": 17.30404645204544, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.13568568229675, "training_acc": 53.0, "val_loss": 17.305006086826324, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14355874061584, "training_acc": 53.0, "val_loss": 17.306208610534668, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13709998130798, "training_acc": 53.0, "val_loss": 17.30828583240509, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16262149810791, "training_acc": 53.0, "val_loss": 17.309413850307465, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14726614952087, "training_acc": 53.0, "val_loss": 17.309284210205078, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18663096427917, "training_acc": 53.0, "val_loss": 17.309345304965973, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13898205757141, "training_acc": 53.0, "val_loss": 17.306537926197052, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.12357449531555, "training_acc": 53.0, "val_loss": 17.30409264564514, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.15580081939697, "training_acc": 53.0, "val_loss": 17.30307787656784, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.12249374389648, "training_acc": 53.0, "val_loss": 17.303268611431122, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1633722782135, "training_acc": 53.0, "val_loss": 17.30351746082306, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.2089695930481, "training_acc": 53.0, "val_loss": 17.303000390529633, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1591911315918, "training_acc": 53.0, "val_loss": 17.30349361896515, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.188321352005, "training_acc": 53.0, "val_loss": 17.305442690849304, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15646457672119, "training_acc": 53.0, "val_loss": 17.30610430240631, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.14211010932922, "training_acc": 53.0, "val_loss": 17.30589270591736, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.19961762428284, "training_acc": 53.0, "val_loss": 17.305506765842438, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1304132938385, "training_acc": 53.0, "val_loss": 17.308391630649567, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1298565864563, "training_acc": 53.0, "val_loss": 17.311860620975494, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.15752911567688, "training_acc": 53.0, "val_loss": 17.316798865795135, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.11760663986206, "training_acc": 53.0, "val_loss": 17.323847115039825, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.18310499191284, "training_acc": 53.0, "val_loss": 17.333266139030457, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.1652672290802, "training_acc": 53.0, "val_loss": 17.337065935134888, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.19127678871155, "training_acc": 53.0, "val_loss": 17.336051166057587, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.16968846321106, "training_acc": 53.0, "val_loss": 17.333586513996124, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17221450805664, "training_acc": 53.0, "val_loss": 17.32916235923767, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.17438983917236, "training_acc": 53.0, "val_loss": 17.323823273181915, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.15973973274231, "training_acc": 53.0, "val_loss": 17.31846034526825, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.12440896034241, "training_acc": 53.0, "val_loss": 17.314545810222626, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.13133573532104, "training_acc": 53.0, "val_loss": 17.3106387257576, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.11920976638794, "training_acc": 53.0, "val_loss": 17.307397723197937, "val_acc": 52.0}
