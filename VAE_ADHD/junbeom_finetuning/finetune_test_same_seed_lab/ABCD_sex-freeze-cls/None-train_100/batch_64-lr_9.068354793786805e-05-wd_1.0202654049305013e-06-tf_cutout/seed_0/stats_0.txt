"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.24475193023682, "training_acc": 52.0, "val_loss": 17.2445148229599, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.24191403388977, "training_acc": 52.0, "val_loss": 17.21746027469635, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2613537311554, "training_acc": 52.0, "val_loss": 17.21527874469757, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26348423957825, "training_acc": 52.0, "val_loss": 17.22888946533203, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24140167236328, "training_acc": 52.0, "val_loss": 17.25054532289505, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22901320457458, "training_acc": 52.0, "val_loss": 17.258313298225403, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.26463627815247, "training_acc": 52.0, "val_loss": 17.273277044296265, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.26744651794434, "training_acc": 52.0, "val_loss": 17.277918756008148, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.28922772407532, "training_acc": 52.0, "val_loss": 17.267978191375732, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.2604820728302, "training_acc": 52.0, "val_loss": 17.26956069469452, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23590016365051, "training_acc": 52.0, "val_loss": 17.268666625022888, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26587629318237, "training_acc": 52.0, "val_loss": 17.262226343154907, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23576807975769, "training_acc": 52.0, "val_loss": 17.25541204214096, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23704242706299, "training_acc": 52.0, "val_loss": 17.252932488918304, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24443793296814, "training_acc": 52.0, "val_loss": 17.24453568458557, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.24780297279358, "training_acc": 52.0, "val_loss": 17.233367264270782, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25148391723633, "training_acc": 52.0, "val_loss": 17.218218743801117, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23522663116455, "training_acc": 52.0, "val_loss": 17.209574580192566, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24593663215637, "training_acc": 52.0, "val_loss": 17.204035818576813, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.26386046409607, "training_acc": 52.0, "val_loss": 17.201316356658936, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.21519899368286, "training_acc": 52.0, "val_loss": 17.203763127326965, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.23635482788086, "training_acc": 52.0, "val_loss": 17.205539345741272, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.29132843017578, "training_acc": 52.0, "val_loss": 17.20322072505951, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.2595784664154, "training_acc": 52.0, "val_loss": 17.20992773771286, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.2544014453888, "training_acc": 52.0, "val_loss": 17.2215536236763, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.2514591217041, "training_acc": 52.0, "val_loss": 17.237475514411926, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.28581643104553, "training_acc": 52.0, "val_loss": 17.24371165037155, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22955751419067, "training_acc": 52.0, "val_loss": 17.26296842098236, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.26194047927856, "training_acc": 52.0, "val_loss": 17.279058694839478, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.27632212638855, "training_acc": 52.0, "val_loss": 17.281349003314972, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.30383348464966, "training_acc": 52.0, "val_loss": 17.273779213428497, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.29186677932739, "training_acc": 52.0, "val_loss": 17.277587950229645, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25845646858215, "training_acc": 52.0, "val_loss": 17.265664041042328, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25642418861389, "training_acc": 52.0, "val_loss": 17.255260050296783, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26362347602844, "training_acc": 52.0, "val_loss": 17.24204570055008, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23722505569458, "training_acc": 52.0, "val_loss": 17.23453849554062, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23448872566223, "training_acc": 52.0, "val_loss": 17.227789759635925, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23758006095886, "training_acc": 52.0, "val_loss": 17.220929265022278, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22970008850098, "training_acc": 52.0, "val_loss": 17.209365963935852, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.26377964019775, "training_acc": 52.0, "val_loss": 17.195196449756622, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.24430108070374, "training_acc": 52.0, "val_loss": 17.19072461128235, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.27112174034119, "training_acc": 52.0, "val_loss": 17.1891450881958, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.28183770179749, "training_acc": 52.0, "val_loss": 17.189645767211914, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24560260772705, "training_acc": 52.0, "val_loss": 17.195725440979004, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.2630603313446, "training_acc": 52.0, "val_loss": 17.210817337036133, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.23654890060425, "training_acc": 52.0, "val_loss": 17.223429679870605, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25179123878479, "training_acc": 52.0, "val_loss": 17.238350212574005, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.24671673774719, "training_acc": 52.0, "val_loss": 17.252612113952637, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.23038601875305, "training_acc": 52.0, "val_loss": 17.257794737815857, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.24065279960632, "training_acc": 52.0, "val_loss": 17.261023819446564, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.26210069656372, "training_acc": 52.0, "val_loss": 17.267194390296936, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.26159524917603, "training_acc": 52.0, "val_loss": 17.273244261741638, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.26972699165344, "training_acc": 52.0, "val_loss": 17.27616786956787, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.27688980102539, "training_acc": 52.0, "val_loss": 17.278870940208435, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.23056769371033, "training_acc": 52.0, "val_loss": 17.278987169265747, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.27067637443542, "training_acc": 52.0, "val_loss": 17.2713965177536, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.25312542915344, "training_acc": 52.0, "val_loss": 17.26824790239334, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24580383300781, "training_acc": 52.0, "val_loss": 17.266881465911865, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23668384552002, "training_acc": 52.0, "val_loss": 17.259563505649567, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25624132156372, "training_acc": 52.0, "val_loss": 17.253386974334717, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28297352790833, "training_acc": 52.0, "val_loss": 17.241354286670685, "val_acc": 56.0}
