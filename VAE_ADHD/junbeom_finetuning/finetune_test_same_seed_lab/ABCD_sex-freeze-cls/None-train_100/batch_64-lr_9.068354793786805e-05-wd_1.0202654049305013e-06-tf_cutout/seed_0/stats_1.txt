"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.60732984542847, "training_acc": 47.0, "val_loss": 17.49485284090042, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.00096893310547, "training_acc": 47.0, "val_loss": 17.399807274341583, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.7918872833252, "training_acc": 47.0, "val_loss": 17.344821989536285, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.44105195999146, "training_acc": 49.0, "val_loss": 17.319372296333313, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14676690101624, "training_acc": 53.0, "val_loss": 17.30906218290329, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.30704617500305, "training_acc": 53.0, "val_loss": 17.307819426059723, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.12910008430481, "training_acc": 53.0, "val_loss": 17.311565577983856, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.10808610916138, "training_acc": 53.0, "val_loss": 17.317302525043488, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14583992958069, "training_acc": 53.0, "val_loss": 17.325839400291443, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12126469612122, "training_acc": 53.0, "val_loss": 17.33485907316208, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.17483854293823, "training_acc": 53.0, "val_loss": 17.34447032213211, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1853928565979, "training_acc": 53.0, "val_loss": 17.35045462846756, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.20687890052795, "training_acc": 53.0, "val_loss": 17.352114617824554, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.24201965332031, "training_acc": 53.0, "val_loss": 17.351044714450836, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.19751214981079, "training_acc": 53.0, "val_loss": 17.346596717834473, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.20631861686707, "training_acc": 53.0, "val_loss": 17.342109978199005, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18452858924866, "training_acc": 53.0, "val_loss": 17.340178787708282, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.21479749679565, "training_acc": 53.0, "val_loss": 17.336127161979675, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19238710403442, "training_acc": 53.0, "val_loss": 17.3339381814003, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15498781204224, "training_acc": 53.0, "val_loss": 17.32940673828125, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.17828583717346, "training_acc": 53.0, "val_loss": 17.321383953094482, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14312434196472, "training_acc": 53.0, "val_loss": 17.31610894203186, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.19282102584839, "training_acc": 53.0, "val_loss": 17.312057316303253, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.14111948013306, "training_acc": 53.0, "val_loss": 17.311514914035797, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15163350105286, "training_acc": 53.0, "val_loss": 17.311103641986847, "val_acc": 52.0}
