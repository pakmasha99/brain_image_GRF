"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.15155029296875, "training_acc": 53.0, "val_loss": 17.320503294467926, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16107153892517, "training_acc": 53.0, "val_loss": 17.321129143238068, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.19684171676636, "training_acc": 53.0, "val_loss": 17.320071160793304, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14729690551758, "training_acc": 53.0, "val_loss": 17.325203120708466, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15699791908264, "training_acc": 53.0, "val_loss": 17.325489223003387, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13077187538147, "training_acc": 53.0, "val_loss": 17.321990430355072, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14274334907532, "training_acc": 53.0, "val_loss": 17.318318784236908, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14320421218872, "training_acc": 53.0, "val_loss": 17.315340042114258, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12580275535583, "training_acc": 53.0, "val_loss": 17.314188182353973, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1466372013092, "training_acc": 53.0, "val_loss": 17.31422245502472, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16167187690735, "training_acc": 53.0, "val_loss": 17.315377295017242, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14392137527466, "training_acc": 53.0, "val_loss": 17.31446087360382, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14406633377075, "training_acc": 53.0, "val_loss": 17.31455773115158, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15564680099487, "training_acc": 53.0, "val_loss": 17.315533757209778, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.17125630378723, "training_acc": 53.0, "val_loss": 17.315684258937836, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17515993118286, "training_acc": 53.0, "val_loss": 17.319373786449432, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13134098052979, "training_acc": 53.0, "val_loss": 17.319568991661072, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15924072265625, "training_acc": 53.0, "val_loss": 17.317727208137512, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12532162666321, "training_acc": 53.0, "val_loss": 17.315292358398438, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13470888137817, "training_acc": 53.0, "val_loss": 17.31208711862564, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.1211085319519, "training_acc": 53.0, "val_loss": 17.31097251176834, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.19472146034241, "training_acc": 53.0, "val_loss": 17.310844361782074, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.16859173774719, "training_acc": 53.0, "val_loss": 17.31051653623581, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16623377799988, "training_acc": 53.0, "val_loss": 17.31073409318924, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17564082145691, "training_acc": 53.0, "val_loss": 17.310653626918793, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.18318176269531, "training_acc": 53.0, "val_loss": 17.310594022274017, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16169667243958, "training_acc": 53.0, "val_loss": 17.31071174144745, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.14483308792114, "training_acc": 53.0, "val_loss": 17.312683165073395, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16531729698181, "training_acc": 53.0, "val_loss": 17.31516569852829, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.13907361030579, "training_acc": 53.0, "val_loss": 17.316855490207672, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.16531109809875, "training_acc": 53.0, "val_loss": 17.3173189163208, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.17010879516602, "training_acc": 53.0, "val_loss": 17.315907776355743, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.12205481529236, "training_acc": 53.0, "val_loss": 17.31281876564026, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.20427823066711, "training_acc": 53.0, "val_loss": 17.311125993728638, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14479684829712, "training_acc": 53.0, "val_loss": 17.3110693693161, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15577793121338, "training_acc": 53.0, "val_loss": 17.310772836208344, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.17282485961914, "training_acc": 53.0, "val_loss": 17.31099635362625, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.12920784950256, "training_acc": 53.0, "val_loss": 17.310939729213715, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.13482427597046, "training_acc": 53.0, "val_loss": 17.311283946037292, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.14558720588684, "training_acc": 53.0, "val_loss": 17.31201857328415, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.15252232551575, "training_acc": 53.0, "val_loss": 17.31303334236145, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.13596296310425, "training_acc": 53.0, "val_loss": 17.312945425510406, "val_acc": 52.0}
