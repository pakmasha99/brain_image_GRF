"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 1145102.8297958374, "training_acc": 50.0, "val_loss": 291815.7958984375, "val_acc": 44.0}
{"epoch": 1, "training_loss": 1210188.9375, "training_acc": 48.0, "val_loss": 462512.158203125, "val_acc": 56.0}
{"epoch": 2, "training_loss": 1915281.875, "training_acc": 52.0, "val_loss": 218538.6474609375, "val_acc": 56.0}
{"epoch": 3, "training_loss": 671245.498046875, "training_acc": 54.0, "val_loss": 226399.5361328125, "val_acc": 44.0}
{"epoch": 4, "training_loss": 800627.87890625, "training_acc": 48.0, "val_loss": 24124.989318847656, "val_acc": 44.0}
{"epoch": 5, "training_loss": 434649.20703125, "training_acc": 44.0, "val_loss": 294230.46875, "val_acc": 56.0}
{"epoch": 6, "training_loss": 1249577.50390625, "training_acc": 52.0, "val_loss": 186800.32958984375, "val_acc": 56.0}
{"epoch": 7, "training_loss": 563891.0202636719, "training_acc": 52.0, "val_loss": 256814.208984375, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1092926.30078125, "training_acc": 48.0, "val_loss": 409014.3310546875, "val_acc": 44.0}
{"epoch": 9, "training_loss": 1421633.08203125, "training_acc": 48.0, "val_loss": 158269.68994140625, "val_acc": 44.0}
{"epoch": 10, "training_loss": 482892.9033203125, "training_acc": 50.0, "val_loss": 176746.8505859375, "val_acc": 56.0}
{"epoch": 11, "training_loss": 800300.59375, "training_acc": 52.0, "val_loss": 148099.96337890625, "val_acc": 56.0}
{"epoch": 12, "training_loss": 445311.9990234375, "training_acc": 52.0, "val_loss": 179680.5908203125, "val_acc": 44.0}
{"epoch": 13, "training_loss": 825030.46875, "training_acc": 48.0, "val_loss": 284682.0556640625, "val_acc": 44.0}
{"epoch": 14, "training_loss": 929502.68359375, "training_acc": 48.0, "val_loss": 11803.718566894531, "val_acc": 44.0}
{"epoch": 15, "training_loss": 277770.212890625, "training_acc": 54.0, "val_loss": 307181.494140625, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1391474.74609375, "training_acc": 52.0, "val_loss": 316858.3740234375, "val_acc": 56.0}
{"epoch": 17, "training_loss": 1218930.25, "training_acc": 52.0, "val_loss": 69108.09936523438, "val_acc": 56.0}
{"epoch": 18, "training_loss": 422143.560546875, "training_acc": 50.0, "val_loss": 306748.9013671875, "val_acc": 44.0}
{"epoch": 19, "training_loss": 1182845.30859375, "training_acc": 48.0, "val_loss": 280601.123046875, "val_acc": 44.0}
{"epoch": 20, "training_loss": 846355.0078125, "training_acc": 48.0, "val_loss": 60659.60693359375, "val_acc": 56.0}
{"epoch": 21, "training_loss": 377893.8984375, "training_acc": 52.0, "val_loss": 168458.9599609375, "val_acc": 56.0}
{"epoch": 22, "training_loss": 653120.732421875, "training_acc": 52.0, "val_loss": 16232.586669921875, "val_acc": 56.0}
{"epoch": 23, "training_loss": 266301.2265625, "training_acc": 54.0, "val_loss": 285955.9326171875, "val_acc": 44.0}
{"epoch": 24, "training_loss": 1063818.2109375, "training_acc": 48.0, "val_loss": 201860.85205078125, "val_acc": 44.0}
{"epoch": 25, "training_loss": 522595.31005859375, "training_acc": 48.0, "val_loss": 155731.7138671875, "val_acc": 56.0}
{"epoch": 26, "training_loss": 913266.3203125, "training_acc": 52.0, "val_loss": 293202.685546875, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1189851.609375, "training_acc": 52.0, "val_loss": 139227.63671875, "val_acc": 56.0}
{"epoch": 28, "training_loss": 466066.68994140625, "training_acc": 46.0, "val_loss": 124894.44580078125, "val_acc": 44.0}
{"epoch": 29, "training_loss": 457988.37890625, "training_acc": 48.0, "val_loss": 23765.71044921875, "val_acc": 44.0}
{"epoch": 30, "training_loss": 318829.203125, "training_acc": 40.0, "val_loss": 182436.474609375, "val_acc": 56.0}
{"epoch": 31, "training_loss": 756334.798828125, "training_acc": 52.0, "val_loss": 86074.62158203125, "val_acc": 56.0}
{"epoch": 32, "training_loss": 295736.80224609375, "training_acc": 52.0, "val_loss": 109508.88671875, "val_acc": 44.0}
{"epoch": 33, "training_loss": 361783.62890625, "training_acc": 48.0, "val_loss": 34151.336669921875, "val_acc": 56.0}
