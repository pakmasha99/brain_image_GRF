"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.26973056793213, "training_acc": 53.0, "val_loss": 17.319980263710022, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.22226905822754, "training_acc": 53.0, "val_loss": 17.317992448806763, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23785281181335, "training_acc": 53.0, "val_loss": 17.316195368766785, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.19840335845947, "training_acc": 53.0, "val_loss": 17.315764725208282, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.203284740448, "training_acc": 53.0, "val_loss": 17.31540709733963, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18818593025208, "training_acc": 53.0, "val_loss": 17.31429696083069, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19125294685364, "training_acc": 53.0, "val_loss": 17.313086986541748, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15662693977356, "training_acc": 53.0, "val_loss": 17.312295734882355, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16339564323425, "training_acc": 53.0, "val_loss": 17.311879992485046, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17070126533508, "training_acc": 53.0, "val_loss": 17.311926186084747, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.118079662323, "training_acc": 53.0, "val_loss": 17.312030494213104, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10830974578857, "training_acc": 53.0, "val_loss": 17.312246561050415, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.15243268013, "training_acc": 53.0, "val_loss": 17.312556505203247, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.14193391799927, "training_acc": 53.0, "val_loss": 17.31279492378235, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.12656903266907, "training_acc": 53.0, "val_loss": 17.313152551651, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15066933631897, "training_acc": 53.0, "val_loss": 17.313742637634277, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14087104797363, "training_acc": 53.0, "val_loss": 17.314626276493073, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13543748855591, "training_acc": 53.0, "val_loss": 17.315545678138733, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.10817289352417, "training_acc": 53.0, "val_loss": 17.316272854804993, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12197232246399, "training_acc": 53.0, "val_loss": 17.316517233848572, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14331150054932, "training_acc": 53.0, "val_loss": 17.31727123260498, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11086368560791, "training_acc": 53.0, "val_loss": 17.317713797092438, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13563776016235, "training_acc": 53.0, "val_loss": 17.31799691915512, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12509512901306, "training_acc": 53.0, "val_loss": 17.31882095336914, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12335157394409, "training_acc": 53.0, "val_loss": 17.31942594051361, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13888502120972, "training_acc": 53.0, "val_loss": 17.32032001018524, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13613247871399, "training_acc": 53.0, "val_loss": 17.321063578128815, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13018846511841, "training_acc": 53.0, "val_loss": 17.320281267166138, "val_acc": 52.0}
