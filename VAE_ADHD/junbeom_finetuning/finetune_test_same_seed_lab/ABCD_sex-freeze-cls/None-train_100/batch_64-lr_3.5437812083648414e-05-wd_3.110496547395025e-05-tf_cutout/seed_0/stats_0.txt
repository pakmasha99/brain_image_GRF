"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23346304893494, "training_acc": 52.0, "val_loss": 17.23378747701645, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22726941108704, "training_acc": 52.0, "val_loss": 17.22595989704132, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2447738647461, "training_acc": 52.0, "val_loss": 17.225323617458344, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26397061347961, "training_acc": 52.0, "val_loss": 17.230069637298584, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23894953727722, "training_acc": 52.0, "val_loss": 17.237815260887146, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22148060798645, "training_acc": 52.0, "val_loss": 17.24076420068741, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25429511070251, "training_acc": 52.0, "val_loss": 17.24724769592285, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.247398853302, "training_acc": 52.0, "val_loss": 17.25115180015564, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.24754643440247, "training_acc": 52.0, "val_loss": 17.249999940395355, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24970817565918, "training_acc": 52.0, "val_loss": 17.253200709819794, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22624969482422, "training_acc": 52.0, "val_loss": 17.255714535713196, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.25645804405212, "training_acc": 52.0, "val_loss": 17.256125807762146, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.22596192359924, "training_acc": 52.0, "val_loss": 17.25597381591797, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23778462409973, "training_acc": 52.0, "val_loss": 17.25701242685318, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24917125701904, "training_acc": 52.0, "val_loss": 17.25502759218216, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25614976882935, "training_acc": 52.0, "val_loss": 17.25100427865982, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.2523124217987, "training_acc": 52.0, "val_loss": 17.244037985801697, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23624014854431, "training_acc": 52.0, "val_loss": 17.23867356777191, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.2415041923523, "training_acc": 52.0, "val_loss": 17.233620584011078, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25372743606567, "training_acc": 52.0, "val_loss": 17.228995263576508, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.19991421699524, "training_acc": 52.0, "val_loss": 17.226232588291168, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21748089790344, "training_acc": 52.0, "val_loss": 17.222987115383148, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27799010276794, "training_acc": 52.0, "val_loss": 17.218101024627686, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25641345977783, "training_acc": 52.0, "val_loss": 17.21736341714859, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25909924507141, "training_acc": 52.0, "val_loss": 17.2187939286232, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24248099327087, "training_acc": 52.0, "val_loss": 17.222188413143158, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.2756073474884, "training_acc": 52.0, "val_loss": 17.222942411899567, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23017859458923, "training_acc": 52.0, "val_loss": 17.22903847694397, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23321771621704, "training_acc": 52.0, "val_loss": 17.234961688518524, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25043821334839, "training_acc": 52.0, "val_loss": 17.23761260509491, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.2520592212677, "training_acc": 52.0, "val_loss": 17.237794399261475, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.25859475135803, "training_acc": 52.0, "val_loss": 17.24216789007187, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23663830757141, "training_acc": 52.0, "val_loss": 17.241525650024414, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25030255317688, "training_acc": 52.0, "val_loss": 17.24129468202591, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24884796142578, "training_acc": 52.0, "val_loss": 17.239518463611603, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.23828172683716, "training_acc": 52.0, "val_loss": 17.239242792129517, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23877382278442, "training_acc": 52.0, "val_loss": 17.238521575927734, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.2388756275177, "training_acc": 52.0, "val_loss": 17.23690629005432, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23633241653442, "training_acc": 52.0, "val_loss": 17.232276499271393, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.23571062088013, "training_acc": 52.0, "val_loss": 17.225177586078644, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22631168365479, "training_acc": 52.0, "val_loss": 17.221717536449432, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24794411659241, "training_acc": 52.0, "val_loss": 17.218944430351257, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.25381207466125, "training_acc": 52.0, "val_loss": 17.21666306257248, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22594881057739, "training_acc": 52.0, "val_loss": 17.21678376197815, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.24079489707947, "training_acc": 52.0, "val_loss": 17.220592498779297, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24197459220886, "training_acc": 52.0, "val_loss": 17.222987115383148, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25628232955933, "training_acc": 52.0, "val_loss": 17.226381599903107, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23007011413574, "training_acc": 52.0, "val_loss": 17.22993403673172, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22542309761047, "training_acc": 52.0, "val_loss": 17.231035232543945, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23085737228394, "training_acc": 52.0, "val_loss": 17.23225712776184, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25249862670898, "training_acc": 52.0, "val_loss": 17.235206067562103, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24759984016418, "training_acc": 52.0, "val_loss": 17.23880022764206, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25056910514832, "training_acc": 52.0, "val_loss": 17.241978645324707, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.25768208503723, "training_acc": 52.0, "val_loss": 17.245635390281677, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.21040058135986, "training_acc": 52.0, "val_loss": 17.248855531215668, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.24003100395203, "training_acc": 52.0, "val_loss": 17.249569296836853, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23596143722534, "training_acc": 52.0, "val_loss": 17.251786589622498, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23787355422974, "training_acc": 52.0, "val_loss": 17.254523932933807, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.2285807132721, "training_acc": 52.0, "val_loss": 17.25473701953888, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25729990005493, "training_acc": 52.0, "val_loss": 17.25490093231201, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.26843214035034, "training_acc": 52.0, "val_loss": 17.25199520587921, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.24139428138733, "training_acc": 52.0, "val_loss": 17.251381278038025, "val_acc": 56.0}
