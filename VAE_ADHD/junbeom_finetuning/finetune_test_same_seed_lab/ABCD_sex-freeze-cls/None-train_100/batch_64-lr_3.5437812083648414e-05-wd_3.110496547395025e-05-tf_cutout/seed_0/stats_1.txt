"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.46517133712769, "training_acc": 47.0, "val_loss": 17.520175874233246, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.31713199615479, "training_acc": 47.0, "val_loss": 17.481575906276703, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.07203722000122, "training_acc": 47.0, "val_loss": 17.45132803916931, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.91947913169861, "training_acc": 47.0, "val_loss": 17.42505431175232, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.85264611244202, "training_acc": 47.0, "val_loss": 17.40054041147232, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.6763334274292, "training_acc": 47.0, "val_loss": 17.381061613559723, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.55874562263489, "training_acc": 47.0, "val_loss": 17.36387461423874, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.52114367485046, "training_acc": 47.0, "val_loss": 17.347964644432068, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.42462468147278, "training_acc": 47.0, "val_loss": 17.33461022377014, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.39946293830872, "training_acc": 47.0, "val_loss": 17.32344776391983, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.33110046386719, "training_acc": 48.0, "val_loss": 17.31514185667038, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24846649169922, "training_acc": 53.0, "val_loss": 17.309314012527466, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.22833228111267, "training_acc": 53.0, "val_loss": 17.305462062358856, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16313052177429, "training_acc": 53.0, "val_loss": 17.30339378118515, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14064073562622, "training_acc": 53.0, "val_loss": 17.30266958475113, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17764377593994, "training_acc": 53.0, "val_loss": 17.303122580051422, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13645505905151, "training_acc": 53.0, "val_loss": 17.304447293281555, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15229725837708, "training_acc": 53.0, "val_loss": 17.306581139564514, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.15805077552795, "training_acc": 53.0, "val_loss": 17.308643460273743, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14869022369385, "training_acc": 53.0, "val_loss": 17.309755086898804, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.15332436561584, "training_acc": 53.0, "val_loss": 17.31085181236267, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.14854454994202, "training_acc": 53.0, "val_loss": 17.311403155326843, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1545660495758, "training_acc": 53.0, "val_loss": 17.312833666801453, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17850613594055, "training_acc": 53.0, "val_loss": 17.31393039226532, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13681507110596, "training_acc": 53.0, "val_loss": 17.314837872982025, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16132497787476, "training_acc": 53.0, "val_loss": 17.31608808040619, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13778305053711, "training_acc": 53.0, "val_loss": 17.31623411178589, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.149409532547, "training_acc": 53.0, "val_loss": 17.31615960597992, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14710211753845, "training_acc": 53.0, "val_loss": 17.315152287483215, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16519570350647, "training_acc": 53.0, "val_loss": 17.3149511218071, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.14654183387756, "training_acc": 53.0, "val_loss": 17.315009236335754, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.14703488349915, "training_acc": 53.0, "val_loss": 17.314621806144714, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14950203895569, "training_acc": 53.0, "val_loss": 17.314060032367706, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.14072346687317, "training_acc": 53.0, "val_loss": 17.314033210277557, "val_acc": 52.0}
