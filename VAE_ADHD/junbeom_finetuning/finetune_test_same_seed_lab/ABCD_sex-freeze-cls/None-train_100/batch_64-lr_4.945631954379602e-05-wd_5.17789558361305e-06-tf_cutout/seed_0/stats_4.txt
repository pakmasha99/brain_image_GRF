"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 72.43234658241272, "training_acc": 47.0, "val_loss": 17.906305193901062, "val_acc": 52.0}
{"epoch": 1, "training_loss": 71.93957257270813, "training_acc": 47.0, "val_loss": 17.79942512512207, "val_acc": 52.0}
{"epoch": 2, "training_loss": 71.39455366134644, "training_acc": 47.0, "val_loss": 17.70941913127899, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.16240239143372, "training_acc": 47.0, "val_loss": 17.63043999671936, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.71400570869446, "training_acc": 47.0, "val_loss": 17.564646899700165, "val_acc": 52.0}
{"epoch": 5, "training_loss": 70.50441789627075, "training_acc": 47.0, "val_loss": 17.506587505340576, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.21467113494873, "training_acc": 47.0, "val_loss": 17.458944022655487, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.93763422966003, "training_acc": 47.0, "val_loss": 17.42040365934372, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.77601289749146, "training_acc": 47.0, "val_loss": 17.38651394844055, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.71798658370972, "training_acc": 47.0, "val_loss": 17.359380424022675, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.43265986442566, "training_acc": 47.0, "val_loss": 17.340974509716034, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.42519783973694, "training_acc": 47.0, "val_loss": 17.325784265995026, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.29846692085266, "training_acc": 54.0, "val_loss": 17.31506437063217, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21539521217346, "training_acc": 53.0, "val_loss": 17.30789542198181, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.20307517051697, "training_acc": 53.0, "val_loss": 17.303599417209625, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.14247918128967, "training_acc": 53.0, "val_loss": 17.30216145515442, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15699315071106, "training_acc": 53.0, "val_loss": 17.302924394607544, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13427066802979, "training_acc": 53.0, "val_loss": 17.30506867170334, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1458694934845, "training_acc": 53.0, "val_loss": 17.307914793491364, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13670468330383, "training_acc": 53.0, "val_loss": 17.311112582683563, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14059495925903, "training_acc": 53.0, "val_loss": 17.31460392475128, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13628506660461, "training_acc": 53.0, "val_loss": 17.31792390346527, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1259195804596, "training_acc": 53.0, "val_loss": 17.32054501771927, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16260862350464, "training_acc": 53.0, "val_loss": 17.32269674539566, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1594500541687, "training_acc": 53.0, "val_loss": 17.32397973537445, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16456341743469, "training_acc": 53.0, "val_loss": 17.324407398700714, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1665461063385, "training_acc": 53.0, "val_loss": 17.324447631835938, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15792870521545, "training_acc": 53.0, "val_loss": 17.324310541152954, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16630148887634, "training_acc": 53.0, "val_loss": 17.322108149528503, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.15891671180725, "training_acc": 53.0, "val_loss": 17.31984317302704, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1393609046936, "training_acc": 53.0, "val_loss": 17.317672073841095, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.13827633857727, "training_acc": 53.0, "val_loss": 17.315109074115753, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13994193077087, "training_acc": 53.0, "val_loss": 17.31211096048355, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.15987777709961, "training_acc": 53.0, "val_loss": 17.30976700782776, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15837550163269, "training_acc": 53.0, "val_loss": 17.307959496974945, "val_acc": 52.0}
