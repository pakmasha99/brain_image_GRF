"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 2585.433868408203, "training_acc": 53.0, "val_loss": 659.312915802002, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3400.3052673339844, "training_acc": 49.0, "val_loss": 1387.4238014221191, "val_acc": 48.0}
{"epoch": 2, "training_loss": 5011.106506347656, "training_acc": 47.0, "val_loss": 88.85955810546875, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1347.153465270996, "training_acc": 55.0, "val_loss": 1557.3229789733887, "val_acc": 52.0}
{"epoch": 4, "training_loss": 6338.286590576172, "training_acc": 53.0, "val_loss": 1513.9296531677246, "val_acc": 52.0}
{"epoch": 5, "training_loss": 5230.404739379883, "training_acc": 53.0, "val_loss": 345.16584873199463, "val_acc": 52.0}
{"epoch": 6, "training_loss": 2149.0600814819336, "training_acc": 41.0, "val_loss": 1062.8210067749023, "val_acc": 48.0}
{"epoch": 7, "training_loss": 4479.047409057617, "training_acc": 47.0, "val_loss": 935.5220794677734, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3067.752212524414, "training_acc": 47.0, "val_loss": 215.32869338989258, "val_acc": 52.0}
{"epoch": 9, "training_loss": 1390.9141998291016, "training_acc": 53.0, "val_loss": 671.2923526763916, "val_acc": 52.0}
{"epoch": 10, "training_loss": 2439.277168273926, "training_acc": 53.0, "val_loss": 204.84373569488525, "val_acc": 52.0}
{"epoch": 11, "training_loss": 715.2850875854492, "training_acc": 63.0, "val_loss": 603.0807971954346, "val_acc": 48.0}
{"epoch": 12, "training_loss": 2457.8351974487305, "training_acc": 47.0, "val_loss": 361.5509510040283, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1083.7341499328613, "training_acc": 49.0, "val_loss": 277.5433301925659, "val_acc": 52.0}
{"epoch": 14, "training_loss": 1026.7041511535645, "training_acc": 53.0, "val_loss": 18.979986011981964, "val_acc": 48.0}
{"epoch": 15, "training_loss": 279.9812870025635, "training_acc": 47.0, "val_loss": 44.01872158050537, "val_acc": 48.0}
{"epoch": 16, "training_loss": 463.19332122802734, "training_acc": 51.0, "val_loss": 343.9992904663086, "val_acc": 52.0}
{"epoch": 17, "training_loss": 1167.524850845337, "training_acc": 53.0, "val_loss": 117.84800291061401, "val_acc": 48.0}
{"epoch": 18, "training_loss": 573.0544834136963, "training_acc": 47.0, "val_loss": 26.749342679977417, "val_acc": 52.0}
{"epoch": 19, "training_loss": 113.2571816444397, "training_acc": 53.0, "val_loss": 120.86619138717651, "val_acc": 48.0}
{"epoch": 20, "training_loss": 387.32788157463074, "training_acc": 41.0, "val_loss": 25.870296359062195, "val_acc": 48.0}
{"epoch": 21, "training_loss": 264.76598930358887, "training_acc": 45.0, "val_loss": 27.427583932876587, "val_acc": 52.0}
{"epoch": 22, "training_loss": 506.8904838562012, "training_acc": 45.0, "val_loss": 224.80597496032715, "val_acc": 48.0}
{"epoch": 23, "training_loss": 778.1601943969727, "training_acc": 41.0, "val_loss": 72.56497740745544, "val_acc": 52.0}
{"epoch": 24, "training_loss": 399.792573928833, "training_acc": 49.0, "val_loss": 79.9331784248352, "val_acc": 48.0}
{"epoch": 25, "training_loss": 369.21951484680176, "training_acc": 57.0, "val_loss": 239.01715278625488, "val_acc": 52.0}
{"epoch": 26, "training_loss": 749.8335704803467, "training_acc": 53.0, "val_loss": 237.89994716644287, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1106.410472869873, "training_acc": 47.0, "val_loss": 113.2084608078003, "val_acc": 48.0}
{"epoch": 28, "training_loss": 703.9075317382812, "training_acc": 49.0, "val_loss": 443.7600612640381, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1658.3739128112793, "training_acc": 53.0, "val_loss": 139.48452472686768, "val_acc": 52.0}
{"epoch": 30, "training_loss": 837.9299812316895, "training_acc": 49.0, "val_loss": 473.66137504577637, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1794.932788848877, "training_acc": 47.0, "val_loss": 58.43480825424194, "val_acc": 48.0}
{"epoch": 32, "training_loss": 665.257568359375, "training_acc": 53.0, "val_loss": 668.3844566345215, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2622.008071899414, "training_acc": 53.0, "val_loss": 525.6030559539795, "val_acc": 52.0}
