"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 3095.783981323242, "training_acc": 47.0, "val_loss": 707.7717304229736, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3667.218536376953, "training_acc": 45.0, "val_loss": 1302.7193069458008, "val_acc": 48.0}
{"epoch": 2, "training_loss": 4765.525863647461, "training_acc": 47.0, "val_loss": 120.87870836257935, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1572.1436920166016, "training_acc": 49.0, "val_loss": 1372.5756645202637, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5612.701904296875, "training_acc": 53.0, "val_loss": 1252.5534629821777, "val_acc": 52.0}
{"epoch": 5, "training_loss": 4195.135726928711, "training_acc": 53.0, "val_loss": 45.98042964935303, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1665.2052154541016, "training_acc": 45.0, "val_loss": 1378.9019584655762, "val_acc": 48.0}
{"epoch": 7, "training_loss": 5837.174957275391, "training_acc": 47.0, "val_loss": 1316.225814819336, "val_acc": 48.0}
{"epoch": 8, "training_loss": 4844.559196472168, "training_acc": 47.0, "val_loss": 200.1803159713745, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1267.1996841430664, "training_acc": 51.0, "val_loss": 1037.6773834228516, "val_acc": 52.0}
{"epoch": 10, "training_loss": 4380.931930541992, "training_acc": 53.0, "val_loss": 1212.2098922729492, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4441.9255447387695, "training_acc": 53.0, "val_loss": 542.4349308013916, "val_acc": 52.0}
{"epoch": 12, "training_loss": 1405.0955600738525, "training_acc": 51.0, "val_loss": 373.9210844039917, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1604.8192520141602, "training_acc": 47.0, "val_loss": 230.90949058532715, "val_acc": 48.0}
{"epoch": 14, "training_loss": 854.8717288970947, "training_acc": 49.0, "val_loss": 325.95183849334717, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1179.4698486328125, "training_acc": 53.0, "val_loss": 17.369836568832397, "val_acc": 52.0}
{"epoch": 16, "training_loss": 441.11959075927734, "training_acc": 47.0, "val_loss": 195.0217604637146, "val_acc": 48.0}
{"epoch": 17, "training_loss": 664.9689064025879, "training_acc": 47.0, "val_loss": 127.55146026611328, "val_acc": 52.0}
{"epoch": 18, "training_loss": 359.2737555503845, "training_acc": 53.0, "val_loss": 18.469588458538055, "val_acc": 52.0}
{"epoch": 19, "training_loss": 84.34654760360718, "training_acc": 49.0, "val_loss": 117.86608695983887, "val_acc": 52.0}
{"epoch": 20, "training_loss": 363.7576160430908, "training_acc": 53.0, "val_loss": 245.8360195159912, "val_acc": 48.0}
{"epoch": 21, "training_loss": 1095.938678741455, "training_acc": 47.0, "val_loss": 70.70106267929077, "val_acc": 48.0}
{"epoch": 22, "training_loss": 677.6319770812988, "training_acc": 49.0, "val_loss": 520.4108715057373, "val_acc": 52.0}
{"epoch": 23, "training_loss": 1977.9783096313477, "training_acc": 53.0, "val_loss": 241.58759117126465, "val_acc": 52.0}
{"epoch": 24, "training_loss": 915.9032821655273, "training_acc": 49.0, "val_loss": 342.3954963684082, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1251.0786933898926, "training_acc": 47.0, "val_loss": 84.55018401145935, "val_acc": 52.0}
{"epoch": 26, "training_loss": 400.2722339630127, "training_acc": 53.0, "val_loss": 56.677281856536865, "val_acc": 52.0}
{"epoch": 27, "training_loss": 488.29519271850586, "training_acc": 51.0, "val_loss": 266.94817543029785, "val_acc": 48.0}
{"epoch": 28, "training_loss": 815.356495141983, "training_acc": 47.0, "val_loss": 302.136492729187, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1400.0395126342773, "training_acc": 53.0, "val_loss": 294.39525604248047, "val_acc": 52.0}
{"epoch": 30, "training_loss": 773.4307780265808, "training_acc": 51.0, "val_loss": 161.25303506851196, "val_acc": 48.0}
{"epoch": 31, "training_loss": 494.81902503967285, "training_acc": 47.0, "val_loss": 267.6405668258667, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1218.876220703125, "training_acc": 53.0, "val_loss": 253.4095048904419, "val_acc": 52.0}
{"epoch": 33, "training_loss": 789.9580736160278, "training_acc": 47.0, "val_loss": 120.02372741699219, "val_acc": 48.0}
{"epoch": 34, "training_loss": 345.1538004875183, "training_acc": 55.0, "val_loss": 40.01883864402771, "val_acc": 52.0}
