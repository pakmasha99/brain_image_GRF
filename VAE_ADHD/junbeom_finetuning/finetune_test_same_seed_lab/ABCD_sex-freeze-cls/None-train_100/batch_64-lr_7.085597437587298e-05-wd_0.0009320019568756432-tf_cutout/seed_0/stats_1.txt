"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.39393401145935, "training_acc": 47.0, "val_loss": 17.47434139251709, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.13622713088989, "training_acc": 47.0, "val_loss": 17.411398887634277, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.74850606918335, "training_acc": 47.0, "val_loss": 17.37099289894104, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.50953030586243, "training_acc": 47.0, "val_loss": 17.342664301395416, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4787585735321, "training_acc": 47.0, "val_loss": 17.32148677110672, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.26440119743347, "training_acc": 53.0, "val_loss": 17.310413718223572, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1668655872345, "training_acc": 53.0, "val_loss": 17.304448783397675, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17605447769165, "training_acc": 53.0, "val_loss": 17.30269193649292, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12872338294983, "training_acc": 53.0, "val_loss": 17.305175960063934, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17072010040283, "training_acc": 53.0, "val_loss": 17.31126755475998, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1642279624939, "training_acc": 53.0, "val_loss": 17.318740487098694, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14557981491089, "training_acc": 53.0, "val_loss": 17.325755953788757, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.17683458328247, "training_acc": 53.0, "val_loss": 17.331862449645996, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1621744632721, "training_acc": 53.0, "val_loss": 17.33548641204834, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18181681632996, "training_acc": 53.0, "val_loss": 17.337875068187714, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.21696782112122, "training_acc": 53.0, "val_loss": 17.3410564661026, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.21416854858398, "training_acc": 53.0, "val_loss": 17.341165244579315, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20863747596741, "training_acc": 53.0, "val_loss": 17.341533303260803, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20277285575867, "training_acc": 53.0, "val_loss": 17.338398098945618, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.21064758300781, "training_acc": 53.0, "val_loss": 17.33042448759079, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.18056583404541, "training_acc": 53.0, "val_loss": 17.323920130729675, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.22531175613403, "training_acc": 53.0, "val_loss": 17.317791283130646, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.1627128124237, "training_acc": 53.0, "val_loss": 17.31572300195694, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.18595242500305, "training_acc": 53.0, "val_loss": 17.313651740550995, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.14905095100403, "training_acc": 53.0, "val_loss": 17.312058806419373, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15425062179565, "training_acc": 53.0, "val_loss": 17.311814427375793, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.13087058067322, "training_acc": 53.0, "val_loss": 17.310260236263275, "val_acc": 52.0}
