"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 70.15449714660645, "training_acc": 47.0, "val_loss": 17.428475618362427, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.81632614135742, "training_acc": 47.0, "val_loss": 17.390403151512146, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.63330912590027, "training_acc": 47.0, "val_loss": 17.354024946689606, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.47973299026489, "training_acc": 47.0, "val_loss": 17.327113449573517, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.39682102203369, "training_acc": 41.0, "val_loss": 17.31211692094803, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.23057866096497, "training_acc": 53.0, "val_loss": 17.305172979831696, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.175213098526, "training_acc": 53.0, "val_loss": 17.302758991718292, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11847281455994, "training_acc": 53.0, "val_loss": 17.304088175296783, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11046195030212, "training_acc": 53.0, "val_loss": 17.30802059173584, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.12420630455017, "training_acc": 53.0, "val_loss": 17.315103113651276, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1458089351654, "training_acc": 53.0, "val_loss": 17.322450876235962, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.16231989860535, "training_acc": 53.0, "val_loss": 17.326760292053223, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16997480392456, "training_acc": 53.0, "val_loss": 17.327338457107544, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19106149673462, "training_acc": 53.0, "val_loss": 17.326156795024872, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1657178401947, "training_acc": 53.0, "val_loss": 17.32545793056488, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15266418457031, "training_acc": 53.0, "val_loss": 17.322012782096863, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.2027370929718, "training_acc": 53.0, "val_loss": 17.31826514005661, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14145398139954, "training_acc": 53.0, "val_loss": 17.317965626716614, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13947629928589, "training_acc": 53.0, "val_loss": 17.315341532230377, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.1440327167511, "training_acc": 53.0, "val_loss": 17.31279343366623, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11061000823975, "training_acc": 53.0, "val_loss": 17.312411963939667, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12475323677063, "training_acc": 53.0, "val_loss": 17.311786115169525, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13782906532288, "training_acc": 53.0, "val_loss": 17.31107532978058, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12936854362488, "training_acc": 53.0, "val_loss": 17.3094242811203, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13110041618347, "training_acc": 53.0, "val_loss": 17.30837970972061, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1311867237091, "training_acc": 53.0, "val_loss": 17.308636009693146, "val_acc": 52.0}
