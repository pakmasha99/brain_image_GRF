"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.3514564037323, "training_acc": 53.0, "val_loss": 17.310035228729248, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17794632911682, "training_acc": 53.0, "val_loss": 17.310182750225067, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15279173851013, "training_acc": 53.0, "val_loss": 17.31060892343521, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18457007408142, "training_acc": 53.0, "val_loss": 17.310166358947754, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.15625429153442, "training_acc": 53.0, "val_loss": 17.309463024139404, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.18636059761047, "training_acc": 53.0, "val_loss": 17.30923056602478, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.144366979599, "training_acc": 53.0, "val_loss": 17.309580743312836, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14366602897644, "training_acc": 53.0, "val_loss": 17.310388386249542, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12829566001892, "training_acc": 53.0, "val_loss": 17.311610281467438, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1345784664154, "training_acc": 53.0, "val_loss": 17.31272041797638, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15047264099121, "training_acc": 53.0, "val_loss": 17.313086986541748, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10949802398682, "training_acc": 53.0, "val_loss": 17.315255105495453, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.13197636604309, "training_acc": 53.0, "val_loss": 17.318736016750336, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17419004440308, "training_acc": 53.0, "val_loss": 17.321382462978363, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14612293243408, "training_acc": 53.0, "val_loss": 17.320537567138672, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13401865959167, "training_acc": 53.0, "val_loss": 17.31850653886795, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13034391403198, "training_acc": 53.0, "val_loss": 17.317935824394226, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11757349967957, "training_acc": 53.0, "val_loss": 17.31809228658676, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.11355352401733, "training_acc": 53.0, "val_loss": 17.317910492420197, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14387488365173, "training_acc": 53.0, "val_loss": 17.318466305732727, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14738464355469, "training_acc": 53.0, "val_loss": 17.318004369735718, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12124490737915, "training_acc": 53.0, "val_loss": 17.31545478105545, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.14263105392456, "training_acc": 53.0, "val_loss": 17.31390655040741, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1160340309143, "training_acc": 53.0, "val_loss": 17.312835156917572, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.10616278648376, "training_acc": 53.0, "val_loss": 17.311610281467438, "val_acc": 52.0}
