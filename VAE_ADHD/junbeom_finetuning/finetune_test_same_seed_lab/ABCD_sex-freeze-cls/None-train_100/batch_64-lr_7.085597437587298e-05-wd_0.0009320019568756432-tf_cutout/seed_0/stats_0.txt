"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2401192188263, "training_acc": 52.0, "val_loss": 17.24104881286621, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.23634219169617, "training_acc": 52.0, "val_loss": 17.22133457660675, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.2549340724945, "training_acc": 52.0, "val_loss": 17.219461500644684, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.26375603675842, "training_acc": 52.0, "val_loss": 17.229484021663666, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.24041676521301, "training_acc": 52.0, "val_loss": 17.245683073997498, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.22616815567017, "training_acc": 52.0, "val_loss": 17.251552641391754, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25997877120972, "training_acc": 52.0, "val_loss": 17.263679206371307, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.2593002319336, "training_acc": 52.0, "val_loss": 17.268848419189453, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.27270817756653, "training_acc": 52.0, "val_loss": 17.262963950634003, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.25684714317322, "training_acc": 52.0, "val_loss": 17.26592779159546, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.23370599746704, "training_acc": 52.0, "val_loss": 17.26697087287903, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.26413464546204, "training_acc": 52.0, "val_loss": 17.263446748256683, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.23411393165588, "training_acc": 52.0, "val_loss": 17.25911796092987, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23921370506287, "training_acc": 52.0, "val_loss": 17.257700860500336, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24756121635437, "training_acc": 52.0, "val_loss": 17.25097745656967, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25094151496887, "training_acc": 52.0, "val_loss": 17.24141538143158, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25147294998169, "training_acc": 52.0, "val_loss": 17.22787767648697, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23340320587158, "training_acc": 52.0, "val_loss": 17.21905916929245, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24168753623962, "training_acc": 52.0, "val_loss": 17.212364077568054, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25876903533936, "training_acc": 52.0, "val_loss": 17.207762598991394, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.20815587043762, "training_acc": 52.0, "val_loss": 17.207355797290802, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.22912788391113, "training_acc": 52.0, "val_loss": 17.206576466560364, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.28987383842468, "training_acc": 52.0, "val_loss": 17.202958464622498, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.26204824447632, "training_acc": 52.0, "val_loss": 17.206749320030212, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25909805297852, "training_acc": 52.0, "val_loss": 17.214587330818176, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24983477592468, "training_acc": 52.0, "val_loss": 17.22610592842102, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.27881622314453, "training_acc": 52.0, "val_loss": 17.231179773807526, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.22718858718872, "training_acc": 52.0, "val_loss": 17.246459424495697, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.24879860877991, "training_acc": 52.0, "val_loss": 17.260316014289856, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.26310467720032, "training_acc": 52.0, "val_loss": 17.265066504478455, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.27774858474731, "training_acc": 52.0, "val_loss": 17.262771725654602, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.28268146514893, "training_acc": 52.0, "val_loss": 17.26887822151184, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.25109839439392, "training_acc": 52.0, "val_loss": 17.26282089948654, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.25754117965698, "training_acc": 52.0, "val_loss": 17.25730150938034, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.26068139076233, "training_acc": 52.0, "val_loss": 17.248646914958954, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.24007153511047, "training_acc": 52.0, "val_loss": 17.243637144565582, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23749589920044, "training_acc": 52.0, "val_loss": 17.238378524780273, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23722195625305, "training_acc": 52.0, "val_loss": 17.232272028923035, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.22895836830139, "training_acc": 52.0, "val_loss": 17.22155213356018, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.25196433067322, "training_acc": 52.0, "val_loss": 17.207898199558258, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.2322609424591, "training_acc": 52.0, "val_loss": 17.202189564704895, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.25773429870605, "training_acc": 52.0, "val_loss": 17.198729515075684, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.27103447914124, "training_acc": 52.0, "val_loss": 17.196938395500183, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.24166488647461, "training_acc": 52.0, "val_loss": 17.19980239868164, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.25537610054016, "training_acc": 52.0, "val_loss": 17.209716141223907, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.24133253097534, "training_acc": 52.0, "val_loss": 17.21757799386978, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25466132164001, "training_acc": 52.0, "val_loss": 17.227454483509064, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.23944807052612, "training_acc": 52.0, "val_loss": 17.23741888999939, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22521567344666, "training_acc": 52.0, "val_loss": 17.241622507572174, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23217797279358, "training_acc": 52.0, "val_loss": 17.245197296142578, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25368189811707, "training_acc": 52.0, "val_loss": 17.25158393383026, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.25205159187317, "training_acc": 52.0, "val_loss": 17.258477210998535, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25814461708069, "training_acc": 52.0, "val_loss": 17.263509333133698, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.26741456985474, "training_acc": 52.0, "val_loss": 17.268630862236023, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.22401928901672, "training_acc": 52.0, "val_loss": 17.271876335144043, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.25944209098816, "training_acc": 52.0, "val_loss": 17.268970608711243, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.24919581413269, "training_acc": 52.0, "val_loss": 17.26900041103363, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.24763298034668, "training_acc": 52.0, "val_loss": 17.269907891750336, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.23853707313538, "training_acc": 52.0, "val_loss": 17.265476286411285, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.26122498512268, "training_acc": 52.0, "val_loss": 17.261269688606262, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.28184509277344, "training_acc": 52.0, "val_loss": 17.251552641391754, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.23989510536194, "training_acc": 52.0, "val_loss": 17.2473281621933, "val_acc": 56.0}
