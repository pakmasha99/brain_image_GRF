"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.2462637424469, "training_acc": 53.0, "val_loss": 17.3105850815773, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.17621350288391, "training_acc": 53.0, "val_loss": 17.310260236263275, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1793110370636, "training_acc": 53.0, "val_loss": 17.309947311878204, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16937232017517, "training_acc": 53.0, "val_loss": 17.309321463108063, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13272786140442, "training_acc": 53.0, "val_loss": 17.309081554412842, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.15829539299011, "training_acc": 53.0, "val_loss": 17.309167981147766, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17586946487427, "training_acc": 53.0, "val_loss": 17.30961799621582, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13218975067139, "training_acc": 53.0, "val_loss": 17.310169339179993, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13213205337524, "training_acc": 53.0, "val_loss": 17.311224341392517, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.13703846931458, "training_acc": 53.0, "val_loss": 17.312221229076385, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14906024932861, "training_acc": 53.0, "val_loss": 17.313221096992493, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.11938714981079, "training_acc": 53.0, "val_loss": 17.3144668340683, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12015557289124, "training_acc": 53.0, "val_loss": 17.315250635147095, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.15916037559509, "training_acc": 53.0, "val_loss": 17.315512895584106, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11650824546814, "training_acc": 53.0, "val_loss": 17.315830290317535, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11463522911072, "training_acc": 53.0, "val_loss": 17.314890027046204, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.13594388961792, "training_acc": 53.0, "val_loss": 17.313668131828308, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11914825439453, "training_acc": 53.0, "val_loss": 17.31274724006653, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.13342595100403, "training_acc": 53.0, "val_loss": 17.312683165073395, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15641379356384, "training_acc": 53.0, "val_loss": 17.312566936016083, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16534900665283, "training_acc": 53.0, "val_loss": 17.311812937259674, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.12739944458008, "training_acc": 53.0, "val_loss": 17.311839759349823, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13894367218018, "training_acc": 53.0, "val_loss": 17.312371730804443, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12678599357605, "training_acc": 53.0, "val_loss": 17.312294244766235, "val_acc": 52.0}
