"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.23298025131226, "training_acc": 52.0, "val_loss": 17.233052849769592, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.22655367851257, "training_acc": 52.0, "val_loss": 17.226125299930573, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.24397373199463, "training_acc": 52.0, "val_loss": 17.225612699985504, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.2639696598053, "training_acc": 52.0, "val_loss": 17.22995787858963, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.23882174491882, "training_acc": 52.0, "val_loss": 17.23703294992447, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.2210578918457, "training_acc": 52.0, "val_loss": 17.239758372306824, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.25390720367432, "training_acc": 52.0, "val_loss": 17.245730757713318, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24650192260742, "training_acc": 52.0, "val_loss": 17.249420285224915, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.24564051628113, "training_acc": 52.0, "val_loss": 17.24853664636612, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.24910283088684, "training_acc": 52.0, "val_loss": 17.251619696617126, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.22546291351318, "training_acc": 52.0, "val_loss": 17.254111170768738, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.25557041168213, "training_acc": 52.0, "val_loss": 17.254720628261566, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.22494435310364, "training_acc": 52.0, "val_loss": 17.254824936389923, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.23715853691101, "training_acc": 52.0, "val_loss": 17.256011068820953, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.24878334999084, "training_acc": 52.0, "val_loss": 17.254436016082764, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.25614976882935, "training_acc": 52.0, "val_loss": 17.250972986221313, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.25208783149719, "training_acc": 52.0, "val_loss": 17.244753241539, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.23658037185669, "training_acc": 52.0, "val_loss": 17.239928245544434, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.24187135696411, "training_acc": 52.0, "val_loss": 17.23530739545822, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.25375390052795, "training_acc": 52.0, "val_loss": 17.230993509292603, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.1999864578247, "training_acc": 52.0, "val_loss": 17.228326201438904, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.21728849411011, "training_acc": 52.0, "val_loss": 17.225155234336853, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.27683115005493, "training_acc": 52.0, "val_loss": 17.22041815519333, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.25575685501099, "training_acc": 52.0, "val_loss": 17.219483852386475, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.25870895385742, "training_acc": 52.0, "val_loss": 17.220531404018402, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.24166774749756, "training_acc": 52.0, "val_loss": 17.22337305545807, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.2748486995697, "training_acc": 52.0, "val_loss": 17.223811149597168, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.23036527633667, "training_acc": 52.0, "val_loss": 17.229172587394714, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.23216509819031, "training_acc": 52.0, "val_loss": 17.23438948392868, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.25003933906555, "training_acc": 52.0, "val_loss": 17.236658930778503, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.25125312805176, "training_acc": 52.0, "val_loss": 17.23673790693283, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.2566728591919, "training_acc": 52.0, "val_loss": 17.240673303604126, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.23622107505798, "training_acc": 52.0, "val_loss": 17.240101099014282, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.24991369247437, "training_acc": 52.0, "val_loss": 17.23994016647339, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.24826073646545, "training_acc": 52.0, "val_loss": 17.238402366638184, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.2380678653717, "training_acc": 52.0, "val_loss": 17.23824441432953, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.23860597610474, "training_acc": 52.0, "val_loss": 17.237693071365356, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.23847889900208, "training_acc": 52.0, "val_loss": 17.236328125, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.23663687705994, "training_acc": 52.0, "val_loss": 17.232201993465424, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.23446583747864, "training_acc": 52.0, "val_loss": 17.225779592990875, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.22632646560669, "training_acc": 52.0, "val_loss": 17.22264438867569, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24783396720886, "training_acc": 52.0, "val_loss": 17.22010374069214, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.2528989315033, "training_acc": 52.0, "val_loss": 17.217978835105896, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.22481989860535, "training_acc": 52.0, "val_loss": 17.218036949634552, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.24014806747437, "training_acc": 52.0, "val_loss": 17.221465706825256, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.2419855594635, "training_acc": 52.0, "val_loss": 17.223581671714783, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.25635528564453, "training_acc": 52.0, "val_loss": 17.226603627204895, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.22944355010986, "training_acc": 52.0, "val_loss": 17.229774594306946, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.22548842430115, "training_acc": 52.0, "val_loss": 17.230716347694397, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.23081541061401, "training_acc": 52.0, "val_loss": 17.231792211532593, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.25262188911438, "training_acc": 52.0, "val_loss": 17.234450578689575, "val_acc": 56.0}
{"epoch": 51, "training_loss": 69.24759793281555, "training_acc": 52.0, "val_loss": 17.237718403339386, "val_acc": 56.0}
{"epoch": 52, "training_loss": 69.25046014785767, "training_acc": 52.0, "val_loss": 17.240633070468903, "val_acc": 56.0}
{"epoch": 53, "training_loss": 69.25741267204285, "training_acc": 52.0, "val_loss": 17.24400520324707, "val_acc": 56.0}
{"epoch": 54, "training_loss": 69.2096357345581, "training_acc": 52.0, "val_loss": 17.247015237808228, "val_acc": 56.0}
{"epoch": 55, "training_loss": 69.23902130126953, "training_acc": 52.0, "val_loss": 17.24778264760971, "val_acc": 56.0}
{"epoch": 56, "training_loss": 69.23519587516785, "training_acc": 52.0, "val_loss": 17.2499418258667, "val_acc": 56.0}
{"epoch": 57, "training_loss": 69.23693776130676, "training_acc": 52.0, "val_loss": 17.252589762210846, "val_acc": 56.0}
{"epoch": 58, "training_loss": 69.22761845588684, "training_acc": 52.0, "val_loss": 17.252977192401886, "val_acc": 56.0}
{"epoch": 59, "training_loss": 69.25641942024231, "training_acc": 52.0, "val_loss": 17.25333034992218, "val_acc": 56.0}
{"epoch": 60, "training_loss": 69.26696443557739, "training_acc": 52.0, "val_loss": 17.250895500183105, "val_acc": 56.0}
{"epoch": 61, "training_loss": 69.2409839630127, "training_acc": 52.0, "val_loss": 17.250530421733856, "val_acc": 56.0}
