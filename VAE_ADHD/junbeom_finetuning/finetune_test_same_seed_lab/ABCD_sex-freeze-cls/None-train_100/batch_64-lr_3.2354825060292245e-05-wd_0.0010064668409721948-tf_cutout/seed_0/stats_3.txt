"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab"
{"epoch": 0, "training_loss": 69.30237030982971, "training_acc": 49.0, "val_loss": 17.314228415489197, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.23603200912476, "training_acc": 53.0, "val_loss": 17.31048673391342, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.21700835227966, "training_acc": 53.0, "val_loss": 17.307399213314056, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22032880783081, "training_acc": 53.0, "val_loss": 17.306312918663025, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.20349216461182, "training_acc": 53.0, "val_loss": 17.30610430240631, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.17074513435364, "training_acc": 53.0, "val_loss": 17.3060342669487, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.14223790168762, "training_acc": 53.0, "val_loss": 17.306017875671387, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.14521861076355, "training_acc": 53.0, "val_loss": 17.306235432624817, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.14719414710999, "training_acc": 53.0, "val_loss": 17.30666309595108, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.16092300415039, "training_acc": 53.0, "val_loss": 17.30741858482361, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1625828742981, "training_acc": 53.0, "val_loss": 17.308081686496735, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15752053260803, "training_acc": 53.0, "val_loss": 17.308175563812256, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.1600387096405, "training_acc": 53.0, "val_loss": 17.308402061462402, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13506388664246, "training_acc": 53.0, "val_loss": 17.30865240097046, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.125736951828, "training_acc": 53.0, "val_loss": 17.308661341667175, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.15298652648926, "training_acc": 53.0, "val_loss": 17.308804392814636, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.12090015411377, "training_acc": 53.0, "val_loss": 17.309188842773438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.125727891922, "training_acc": 53.0, "val_loss": 17.309825122356415, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.1397168636322, "training_acc": 53.0, "val_loss": 17.31042116880417, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.13239765167236, "training_acc": 53.0, "val_loss": 17.310796678066254, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14872360229492, "training_acc": 53.0, "val_loss": 17.310725152492523, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11532258987427, "training_acc": 53.0, "val_loss": 17.31116473674774, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13136529922485, "training_acc": 53.0, "val_loss": 17.311343550682068, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1528332233429, "training_acc": 53.0, "val_loss": 17.311416566371918, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.13518047332764, "training_acc": 53.0, "val_loss": 17.311991751194, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14739632606506, "training_acc": 53.0, "val_loss": 17.31240749359131, "val_acc": 52.0}
