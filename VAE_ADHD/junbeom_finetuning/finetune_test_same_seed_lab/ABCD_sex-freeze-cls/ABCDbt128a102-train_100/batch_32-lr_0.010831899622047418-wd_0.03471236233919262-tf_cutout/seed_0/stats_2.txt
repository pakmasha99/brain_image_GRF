"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 77.17457103729248, "training_acc": 50.0, "val_loss": 23.31467568874359, "val_acc": 48.0}
{"epoch": 1, "training_loss": 74.5288896560669, "training_acc": 58.0, "val_loss": 23.955994844436646, "val_acc": 52.0}
{"epoch": 2, "training_loss": 65.64670097827911, "training_acc": 68.0, "val_loss": 28.35237979888916, "val_acc": 56.0}
{"epoch": 3, "training_loss": 70.74637579917908, "training_acc": 69.0, "val_loss": 27.513176202774048, "val_acc": 44.0}
{"epoch": 4, "training_loss": 61.58945941925049, "training_acc": 68.0, "val_loss": 27.56865918636322, "val_acc": 48.0}
{"epoch": 5, "training_loss": 56.95252048969269, "training_acc": 72.0, "val_loss": 26.780778169631958, "val_acc": 48.0}
{"epoch": 6, "training_loss": 51.790276527404785, "training_acc": 73.0, "val_loss": 27.745825052261353, "val_acc": 52.0}
{"epoch": 7, "training_loss": 58.82946678996086, "training_acc": 71.0, "val_loss": 29.07104790210724, "val_acc": 48.0}
{"epoch": 8, "training_loss": 56.91167378425598, "training_acc": 71.0, "val_loss": 28.15655767917633, "val_acc": 56.0}
{"epoch": 9, "training_loss": 54.60188043117523, "training_acc": 65.0, "val_loss": 28.80154848098755, "val_acc": 56.0}
{"epoch": 10, "training_loss": 50.147939920425415, "training_acc": 72.0, "val_loss": 32.07712471485138, "val_acc": 48.0}
{"epoch": 11, "training_loss": 46.057722091674805, "training_acc": 78.0, "val_loss": 30.717867612838745, "val_acc": 40.0}
{"epoch": 12, "training_loss": 48.34304594993591, "training_acc": 73.0, "val_loss": 31.14880919456482, "val_acc": 48.0}
{"epoch": 13, "training_loss": 41.349138021469116, "training_acc": 80.0, "val_loss": 32.33349025249481, "val_acc": 48.0}
{"epoch": 14, "training_loss": 46.9298432469368, "training_acc": 76.0, "val_loss": 32.24453032016754, "val_acc": 48.0}
{"epoch": 15, "training_loss": 45.55268335342407, "training_acc": 79.0, "val_loss": 31.121569871902466, "val_acc": 48.0}
{"epoch": 16, "training_loss": 43.34064197540283, "training_acc": 79.0, "val_loss": 30.095160007476807, "val_acc": 44.0}
{"epoch": 17, "training_loss": 38.29123377799988, "training_acc": 83.0, "val_loss": 30.431392788887024, "val_acc": 48.0}
{"epoch": 18, "training_loss": 42.09692716598511, "training_acc": 81.0, "val_loss": 31.732988357543945, "val_acc": 48.0}
{"epoch": 19, "training_loss": 38.990363359451294, "training_acc": 84.0, "val_loss": 32.72790312767029, "val_acc": 48.0}
