"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.17937517166138, "training_acc": 53.0, "val_loss": 17.296969890594482, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16241979598999, "training_acc": 53.0, "val_loss": 17.29777455329895, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14405632019043, "training_acc": 53.0, "val_loss": 17.296786606311798, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12673711776733, "training_acc": 53.0, "val_loss": 17.295852303504944, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.1439561843872, "training_acc": 53.0, "val_loss": 17.295080423355103, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11954593658447, "training_acc": 53.0, "val_loss": 17.293749749660492, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.11319875717163, "training_acc": 53.0, "val_loss": 17.292290925979614, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1240906715393, "training_acc": 53.0, "val_loss": 17.29140877723694, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1280026435852, "training_acc": 53.0, "val_loss": 17.290928959846497, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.06390953063965, "training_acc": 53.0, "val_loss": 17.290647327899933, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.09515619277954, "training_acc": 53.0, "val_loss": 17.290443181991577, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09310126304626, "training_acc": 53.0, "val_loss": 17.290213704109192, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09475493431091, "training_acc": 53.0, "val_loss": 17.290136218070984, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08748888969421, "training_acc": 53.0, "val_loss": 17.29033887386322, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.08995223045349, "training_acc": 53.0, "val_loss": 17.291034758090973, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.06427049636841, "training_acc": 53.0, "val_loss": 17.291535437107086, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.04525303840637, "training_acc": 53.0, "val_loss": 17.291773855686188, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.01649165153503, "training_acc": 53.0, "val_loss": 17.292357981204987, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08837461471558, "training_acc": 53.0, "val_loss": 17.292888462543488, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08446907997131, "training_acc": 53.0, "val_loss": 17.29256808757782, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.06180810928345, "training_acc": 53.0, "val_loss": 17.292296886444092, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.03234124183655, "training_acc": 53.0, "val_loss": 17.292198538780212, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.04889225959778, "training_acc": 53.0, "val_loss": 17.292451858520508, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.07367897033691, "training_acc": 53.0, "val_loss": 17.292562127113342, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.0642397403717, "training_acc": 53.0, "val_loss": 17.292802035808563, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.04711365699768, "training_acc": 53.0, "val_loss": 17.293840646743774, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12370014190674, "training_acc": 53.0, "val_loss": 17.29547530412674, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.091876745224, "training_acc": 53.0, "val_loss": 17.29661077260971, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.06709671020508, "training_acc": 53.0, "val_loss": 17.29697585105896, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.09296941757202, "training_acc": 53.0, "val_loss": 17.297226190567017, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.1012110710144, "training_acc": 53.0, "val_loss": 17.297419905662537, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.05439805984497, "training_acc": 53.0, "val_loss": 17.297260463237762, "val_acc": 52.0}
