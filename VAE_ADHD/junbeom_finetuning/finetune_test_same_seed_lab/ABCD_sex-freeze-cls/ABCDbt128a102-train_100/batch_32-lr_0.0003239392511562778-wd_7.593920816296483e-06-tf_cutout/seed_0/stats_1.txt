"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.10232090950012, "training_acc": 45.0, "val_loss": 17.307914793491364, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.45071840286255, "training_acc": 48.0, "val_loss": 17.30741113424301, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.29499125480652, "training_acc": 51.0, "val_loss": 17.2802597284317, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1551468372345, "training_acc": 53.0, "val_loss": 17.379359900951385, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.4698224067688, "training_acc": 53.0, "val_loss": 17.45700240135193, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.7891116142273, "training_acc": 53.0, "val_loss": 17.387989163398743, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.29898071289062, "training_acc": 53.0, "val_loss": 17.327329516410828, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12332272529602, "training_acc": 53.0, "val_loss": 17.292870581150055, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13094472885132, "training_acc": 53.0, "val_loss": 17.29709953069687, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.1467227935791, "training_acc": 53.0, "val_loss": 17.306701838970184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16280055046082, "training_acc": 53.0, "val_loss": 17.32507050037384, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21035385131836, "training_acc": 53.0, "val_loss": 17.326898872852325, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.3133008480072, "training_acc": 53.0, "val_loss": 17.28987842798233, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.09885740280151, "training_acc": 53.0, "val_loss": 17.289046943187714, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18359136581421, "training_acc": 53.0, "val_loss": 17.286279797554016, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.28761410713196, "training_acc": 53.0, "val_loss": 17.2848179936409, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.16784715652466, "training_acc": 53.0, "val_loss": 17.28329062461853, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16281747817993, "training_acc": 53.0, "val_loss": 17.283177375793457, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.30337476730347, "training_acc": 54.0, "val_loss": 17.329788208007812, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.54350280761719, "training_acc": 47.0, "val_loss": 17.36501306295395, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.52718353271484, "training_acc": 50.0, "val_loss": 17.28624701499939, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.55991911888123, "training_acc": 53.0, "val_loss": 17.32291728258133, "val_acc": 52.0}
