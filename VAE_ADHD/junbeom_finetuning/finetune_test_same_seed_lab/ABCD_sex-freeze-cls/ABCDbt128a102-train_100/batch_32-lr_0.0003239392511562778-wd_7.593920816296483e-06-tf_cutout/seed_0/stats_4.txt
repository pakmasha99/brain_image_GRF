"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.60229253768921, "training_acc": 42.0, "val_loss": 17.28033423423767, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.57302331924438, "training_acc": 53.0, "val_loss": 17.29751229286194, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.15480470657349, "training_acc": 53.0, "val_loss": 17.279864847660065, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13516640663147, "training_acc": 53.0, "val_loss": 17.305688560009003, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13063836097717, "training_acc": 53.0, "val_loss": 17.31845885515213, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20386695861816, "training_acc": 53.0, "val_loss": 17.300626635551453, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13032579421997, "training_acc": 53.0, "val_loss": 17.286548018455505, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13397669792175, "training_acc": 53.0, "val_loss": 17.28416085243225, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15674877166748, "training_acc": 53.0, "val_loss": 17.29821115732193, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.10882997512817, "training_acc": 53.0, "val_loss": 17.304831743240356, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12823629379272, "training_acc": 53.0, "val_loss": 17.32940375804901, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.22166275978088, "training_acc": 53.0, "val_loss": 17.309531569480896, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.0465726852417, "training_acc": 53.0, "val_loss": 17.277273535728455, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.49099683761597, "training_acc": 44.0, "val_loss": 17.2975555062294, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.40049767494202, "training_acc": 44.0, "val_loss": 17.278239130973816, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.26749515533447, "training_acc": 53.0, "val_loss": 17.315669357776642, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17913579940796, "training_acc": 53.0, "val_loss": 17.297062277793884, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12729549407959, "training_acc": 53.0, "val_loss": 17.3257514834404, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.24468469619751, "training_acc": 53.0, "val_loss": 17.3886701464653, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.50716018676758, "training_acc": 53.0, "val_loss": 17.43762195110321, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.47612643241882, "training_acc": 53.0, "val_loss": 17.382194101810455, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.32507109642029, "training_acc": 53.0, "val_loss": 17.3654705286026, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.41156244277954, "training_acc": 53.0, "val_loss": 17.33875274658203, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15058898925781, "training_acc": 53.0, "val_loss": 17.275138199329376, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09786057472229, "training_acc": 53.0, "val_loss": 17.279040813446045, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.0951771736145, "training_acc": 53.0, "val_loss": 17.2743558883667, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11760807037354, "training_acc": 53.0, "val_loss": 17.277199029922485, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13448667526245, "training_acc": 53.0, "val_loss": 17.273952066898346, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.00528526306152, "training_acc": 53.0, "val_loss": 17.33972877264023, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.38139510154724, "training_acc": 53.0, "val_loss": 17.511235177516937, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.75537443161011, "training_acc": 53.0, "val_loss": 17.629538476467133, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.28839015960693, "training_acc": 53.0, "val_loss": 17.62559413909912, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.00874042510986, "training_acc": 53.0, "val_loss": 17.46646910905838, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.62279033660889, "training_acc": 53.0, "val_loss": 17.349834740161896, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.11272025108337, "training_acc": 53.0, "val_loss": 17.29135513305664, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.8882908821106, "training_acc": 53.0, "val_loss": 17.27355122566223, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.08031129837036, "training_acc": 54.0, "val_loss": 17.328883707523346, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.39246368408203, "training_acc": 47.0, "val_loss": 17.363139986991882, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.67954468727112, "training_acc": 47.0, "val_loss": 17.384925484657288, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.50764584541321, "training_acc": 47.0, "val_loss": 17.307773232460022, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.43004393577576, "training_acc": 46.0, "val_loss": 17.292529344558716, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.35181140899658, "training_acc": 51.0, "val_loss": 17.320212721824646, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.26043391227722, "training_acc": 51.0, "val_loss": 17.274756729602814, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.07878041267395, "training_acc": 53.0, "val_loss": 17.273280024528503, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.82764959335327, "training_acc": 53.0, "val_loss": 17.3012837767601, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.06104063987732, "training_acc": 53.0, "val_loss": 17.394191026687622, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.44413042068481, "training_acc": 53.0, "val_loss": 17.461474239826202, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.42861223220825, "training_acc": 53.0, "val_loss": 17.35391616821289, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.06712460517883, "training_acc": 53.0, "val_loss": 17.293646931648254, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.0397458076477, "training_acc": 53.0, "val_loss": 17.28164851665497, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.04315900802612, "training_acc": 53.0, "val_loss": 17.27292239665985, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.9698896408081, "training_acc": 53.0, "val_loss": 17.27053076028824, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.31928586959839, "training_acc": 53.0, "val_loss": 17.27091372013092, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.08500671386719, "training_acc": 53.0, "val_loss": 17.321142554283142, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.10102486610413, "training_acc": 53.0, "val_loss": 17.485952377319336, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.1875069141388, "training_acc": 53.0, "val_loss": 17.74217188358307, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.57605266571045, "training_acc": 53.0, "val_loss": 17.649291455745697, "val_acc": 52.0}
{"epoch": 57, "training_loss": 70.00398850440979, "training_acc": 53.0, "val_loss": 17.424173653125763, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.241295337677, "training_acc": 53.0, "val_loss": 17.29966253042221, "val_acc": 52.0}
{"epoch": 59, "training_loss": 68.99628233909607, "training_acc": 53.0, "val_loss": 17.2843337059021, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.98819041252136, "training_acc": 53.0, "val_loss": 17.291633784770966, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.97544741630554, "training_acc": 53.0, "val_loss": 17.315901815891266, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.10211157798767, "training_acc": 53.0, "val_loss": 17.369839549064636, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.1926941871643, "training_acc": 53.0, "val_loss": 17.372220754623413, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.40053582191467, "training_acc": 53.0, "val_loss": 17.42721199989319, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.47949504852295, "training_acc": 53.0, "val_loss": 17.469100654125214, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.44403624534607, "training_acc": 53.0, "val_loss": 17.319661378860474, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.09372663497925, "training_acc": 53.0, "val_loss": 17.27624088525772, "val_acc": 52.0}
{"epoch": 68, "training_loss": 68.95303583145142, "training_acc": 62.0, "val_loss": 17.34587252140045, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.48264527320862, "training_acc": 47.0, "val_loss": 17.370067536830902, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.79264044761658, "training_acc": 47.0, "val_loss": 17.440935969352722, "val_acc": 52.0}
