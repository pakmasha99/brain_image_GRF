"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.17959880828857, "training_acc": 53.0, "val_loss": 17.29697585105896, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16263628005981, "training_acc": 53.0, "val_loss": 17.297789454460144, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14413952827454, "training_acc": 53.0, "val_loss": 17.296788096427917, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.12677001953125, "training_acc": 53.0, "val_loss": 17.295844852924347, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14387059211731, "training_acc": 53.0, "val_loss": 17.295067012310028, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.11934661865234, "training_acc": 53.0, "val_loss": 17.293725907802582, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1129539012909, "training_acc": 53.0, "val_loss": 17.292261123657227, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12384533882141, "training_acc": 53.0, "val_loss": 17.29137748479843, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12763810157776, "training_acc": 53.0, "val_loss": 17.29090064764023, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.06350874900818, "training_acc": 53.0, "val_loss": 17.290621995925903, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.09473466873169, "training_acc": 53.0, "val_loss": 17.290420830249786, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.09265565872192, "training_acc": 53.0, "val_loss": 17.290204763412476, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09425449371338, "training_acc": 53.0, "val_loss": 17.290137708187103, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08705735206604, "training_acc": 53.0, "val_loss": 17.29036271572113, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.08975315093994, "training_acc": 53.0, "val_loss": 17.291095852851868, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.06393122673035, "training_acc": 53.0, "val_loss": 17.291615903377533, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.0450086593628, "training_acc": 53.0, "val_loss": 17.29186177253723, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.016268491745, "training_acc": 53.0, "val_loss": 17.292462289333344, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.08823037147522, "training_acc": 53.0, "val_loss": 17.2930046916008, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08428835868835, "training_acc": 53.0, "val_loss": 17.292675375938416, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.06162691116333, "training_acc": 53.0, "val_loss": 17.292390763759613, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.0321671962738, "training_acc": 53.0, "val_loss": 17.292284965515137, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.04869985580444, "training_acc": 53.0, "val_loss": 17.29254424571991, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.07352185249329, "training_acc": 53.0, "val_loss": 17.292653024196625, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.06410813331604, "training_acc": 53.0, "val_loss": 17.292900383472443, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.04696989059448, "training_acc": 53.0, "val_loss": 17.293959856033325, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12373995780945, "training_acc": 53.0, "val_loss": 17.295633256435394, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.09196758270264, "training_acc": 53.0, "val_loss": 17.296794056892395, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.06723189353943, "training_acc": 53.0, "val_loss": 17.297162115573883, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.09311485290527, "training_acc": 53.0, "val_loss": 17.29741245508194, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.10132074356079, "training_acc": 53.0, "val_loss": 17.29760468006134, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.05457806587219, "training_acc": 53.0, "val_loss": 17.29743480682373, "val_acc": 52.0}
