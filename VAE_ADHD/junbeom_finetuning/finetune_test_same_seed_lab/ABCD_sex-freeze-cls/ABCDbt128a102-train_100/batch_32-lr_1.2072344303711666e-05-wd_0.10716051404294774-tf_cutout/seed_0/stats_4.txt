"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.14923620223999, "training_acc": 53.0, "val_loss": 17.379966378211975, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16807723045349, "training_acc": 53.0, "val_loss": 17.38259494304657, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14189672470093, "training_acc": 53.0, "val_loss": 17.38322079181671, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.17594194412231, "training_acc": 53.0, "val_loss": 17.38496720790863, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18287420272827, "training_acc": 53.0, "val_loss": 17.382827401161194, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13520312309265, "training_acc": 53.0, "val_loss": 17.380793392658234, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13157939910889, "training_acc": 53.0, "val_loss": 17.379362881183624, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1746392250061, "training_acc": 53.0, "val_loss": 17.378203570842743, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.11585903167725, "training_acc": 53.0, "val_loss": 17.378218472003937, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18526220321655, "training_acc": 53.0, "val_loss": 17.378799617290497, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.15190935134888, "training_acc": 53.0, "val_loss": 17.381539940834045, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14278864860535, "training_acc": 53.0, "val_loss": 17.381973564624786, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09734678268433, "training_acc": 53.0, "val_loss": 17.380261421203613, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1238260269165, "training_acc": 53.0, "val_loss": 17.377759516239166, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.14242696762085, "training_acc": 53.0, "val_loss": 17.3743337392807, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.12973308563232, "training_acc": 53.0, "val_loss": 17.371590435504913, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15999150276184, "training_acc": 53.0, "val_loss": 17.370818555355072, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.11624646186829, "training_acc": 53.0, "val_loss": 17.37137883901596, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.16304326057434, "training_acc": 53.0, "val_loss": 17.37194061279297, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08152318000793, "training_acc": 53.0, "val_loss": 17.371322214603424, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.06846952438354, "training_acc": 53.0, "val_loss": 17.37055480480194, "val_acc": 52.0}
