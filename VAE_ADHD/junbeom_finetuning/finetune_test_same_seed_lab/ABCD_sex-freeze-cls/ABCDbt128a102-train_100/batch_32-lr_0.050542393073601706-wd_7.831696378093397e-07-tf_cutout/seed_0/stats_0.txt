"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 192.1454315185547, "training_acc": 49.0, "val_loss": 49.47953820228577, "val_acc": 48.0}
{"epoch": 1, "training_loss": 97.28919091820717, "training_acc": 66.0, "val_loss": 51.87100172042847, "val_acc": 56.0}
{"epoch": 2, "training_loss": 193.75139713287354, "training_acc": 65.0, "val_loss": 109.44406986236572, "val_acc": 60.0}
{"epoch": 3, "training_loss": 248.62057161331177, "training_acc": 61.0, "val_loss": 64.78375196456909, "val_acc": 48.0}
{"epoch": 4, "training_loss": 164.28912115097046, "training_acc": 63.0, "val_loss": 80.84499835968018, "val_acc": 48.0}
{"epoch": 5, "training_loss": 146.49205780029297, "training_acc": 71.0, "val_loss": 95.52904963493347, "val_acc": 48.0}
{"epoch": 6, "training_loss": 103.5617767572403, "training_acc": 71.0, "val_loss": 88.64642977714539, "val_acc": 44.0}
{"epoch": 7, "training_loss": 138.21543502807617, "training_acc": 64.0, "val_loss": 113.74889612197876, "val_acc": 52.0}
{"epoch": 8, "training_loss": 164.06108856201172, "training_acc": 69.0, "val_loss": 111.21135950088501, "val_acc": 48.0}
{"epoch": 9, "training_loss": 94.79366445541382, "training_acc": 75.0, "val_loss": 137.65015602111816, "val_acc": 36.0}
{"epoch": 10, "training_loss": 226.91259126737714, "training_acc": 64.0, "val_loss": 123.90813827514648, "val_acc": 28.0}
{"epoch": 11, "training_loss": 76.60087375715375, "training_acc": 76.0, "val_loss": 139.62857723236084, "val_acc": 32.0}
{"epoch": 12, "training_loss": 121.44547271728516, "training_acc": 72.0, "val_loss": 118.16421747207642, "val_acc": 40.0}
{"epoch": 13, "training_loss": 134.03921699523926, "training_acc": 70.0, "val_loss": 110.5257511138916, "val_acc": 36.0}
{"epoch": 14, "training_loss": 94.06228637695312, "training_acc": 74.0, "val_loss": 131.15041255950928, "val_acc": 52.0}
{"epoch": 15, "training_loss": 186.23066580295563, "training_acc": 68.0, "val_loss": 114.33694362640381, "val_acc": 36.0}
{"epoch": 16, "training_loss": 72.09379458427429, "training_acc": 75.0, "val_loss": 112.870192527771, "val_acc": 36.0}
{"epoch": 17, "training_loss": 92.01327276229858, "training_acc": 70.0, "val_loss": 104.16663885116577, "val_acc": 48.0}
{"epoch": 18, "training_loss": 73.95946550369263, "training_acc": 77.0, "val_loss": 105.5100679397583, "val_acc": 48.0}
{"epoch": 19, "training_loss": 73.5063304901123, "training_acc": 78.0, "val_loss": 104.80514764785767, "val_acc": 44.0}
