"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.21885585784912, "training_acc": 53.0, "val_loss": 17.282062768936157, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.13252568244934, "training_acc": 53.0, "val_loss": 17.282187938690186, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.16417717933655, "training_acc": 53.0, "val_loss": 17.2828808426857, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.23797869682312, "training_acc": 53.0, "val_loss": 17.284728586673737, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.2038426399231, "training_acc": 53.0, "val_loss": 17.284469306468964, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1510922908783, "training_acc": 53.0, "val_loss": 17.284414172172546, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.19884967803955, "training_acc": 53.0, "val_loss": 17.28353053331375, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.18772506713867, "training_acc": 53.0, "val_loss": 17.2830268740654, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16906404495239, "training_acc": 53.0, "val_loss": 17.282649874687195, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15419483184814, "training_acc": 53.0, "val_loss": 17.282214760780334, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13298988342285, "training_acc": 53.0, "val_loss": 17.2821044921875, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.13258457183838, "training_acc": 53.0, "val_loss": 17.28222221136093, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.11436700820923, "training_acc": 53.0, "val_loss": 17.28328913450241, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17559742927551, "training_acc": 53.0, "val_loss": 17.284604907035828, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11344528198242, "training_acc": 53.0, "val_loss": 17.28404611349106, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.13353705406189, "training_acc": 53.0, "val_loss": 17.28322207927704, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.10748386383057, "training_acc": 53.0, "val_loss": 17.282740771770477, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.15576457977295, "training_acc": 53.0, "val_loss": 17.28254407644272, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.12975883483887, "training_acc": 53.0, "val_loss": 17.282965779304504, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12104058265686, "training_acc": 53.0, "val_loss": 17.284056544303894, "val_acc": 52.0}
