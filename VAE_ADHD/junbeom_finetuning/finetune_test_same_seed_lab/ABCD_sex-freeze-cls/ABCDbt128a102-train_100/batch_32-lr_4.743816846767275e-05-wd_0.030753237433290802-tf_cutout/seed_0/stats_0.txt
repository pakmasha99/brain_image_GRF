"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 71.3905942440033, "training_acc": 52.0, "val_loss": 18.32616627216339, "val_acc": 56.0}
{"epoch": 1, "training_loss": 71.30288577079773, "training_acc": 51.0, "val_loss": 18.282553553581238, "val_acc": 56.0}
{"epoch": 2, "training_loss": 71.367422580719, "training_acc": 52.0, "val_loss": 18.263578414916992, "val_acc": 56.0}
{"epoch": 3, "training_loss": 71.28913354873657, "training_acc": 53.0, "val_loss": 18.24537068605423, "val_acc": 56.0}
{"epoch": 4, "training_loss": 70.92021942138672, "training_acc": 50.0, "val_loss": 18.226979672908783, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.84937024116516, "training_acc": 50.0, "val_loss": 18.20880025625229, "val_acc": 56.0}
{"epoch": 6, "training_loss": 71.01988744735718, "training_acc": 50.0, "val_loss": 18.192361295223236, "val_acc": 56.0}
{"epoch": 7, "training_loss": 70.134840965271, "training_acc": 53.0, "val_loss": 18.1708961725235, "val_acc": 56.0}
{"epoch": 8, "training_loss": 70.45912218093872, "training_acc": 50.0, "val_loss": 18.146830797195435, "val_acc": 56.0}
{"epoch": 9, "training_loss": 70.83733034133911, "training_acc": 49.0, "val_loss": 18.136346340179443, "val_acc": 56.0}
{"epoch": 10, "training_loss": 70.4615707397461, "training_acc": 49.0, "val_loss": 18.126821517944336, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.93641543388367, "training_acc": 50.0, "val_loss": 18.11574101448059, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.21016073226929, "training_acc": 53.0, "val_loss": 18.10629665851593, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.98290729522705, "training_acc": 53.0, "val_loss": 18.101617693901062, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.92389726638794, "training_acc": 50.0, "val_loss": 18.094758689403534, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.50666236877441, "training_acc": 52.0, "val_loss": 18.087880313396454, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.23051166534424, "training_acc": 53.0, "val_loss": 18.07055175304413, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.31155228614807, "training_acc": 55.0, "val_loss": 18.055255711078644, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.22886943817139, "training_acc": 53.0, "val_loss": 18.04174780845642, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.17309856414795, "training_acc": 52.0, "val_loss": 18.026484549045563, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.2711124420166, "training_acc": 54.0, "val_loss": 18.0118590593338, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.1174705028534, "training_acc": 53.0, "val_loss": 17.999500036239624, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.56658911705017, "training_acc": 55.0, "val_loss": 17.987661063671112, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.81792116165161, "training_acc": 54.0, "val_loss": 17.979566752910614, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.11531734466553, "training_acc": 53.0, "val_loss": 17.967864871025085, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.438649892807, "training_acc": 60.0, "val_loss": 17.95114129781723, "val_acc": 56.0}
{"epoch": 26, "training_loss": 68.42977905273438, "training_acc": 56.0, "val_loss": 17.940653860569, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.48569512367249, "training_acc": 57.0, "val_loss": 17.931318283081055, "val_acc": 56.0}
{"epoch": 28, "training_loss": 67.89679670333862, "training_acc": 60.0, "val_loss": 17.91665107011795, "val_acc": 56.0}
{"epoch": 29, "training_loss": 68.12117052078247, "training_acc": 54.0, "val_loss": 17.90807843208313, "val_acc": 56.0}
{"epoch": 30, "training_loss": 68.62636089324951, "training_acc": 52.0, "val_loss": 17.889931797981262, "val_acc": 56.0}
{"epoch": 31, "training_loss": 67.72598314285278, "training_acc": 56.0, "val_loss": 17.878860235214233, "val_acc": 56.0}
{"epoch": 32, "training_loss": 67.96146988868713, "training_acc": 57.0, "val_loss": 17.87859946489334, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.49538850784302, "training_acc": 54.0, "val_loss": 17.875054478645325, "val_acc": 56.0}
{"epoch": 34, "training_loss": 67.28701400756836, "training_acc": 56.0, "val_loss": 17.873458564281464, "val_acc": 56.0}
{"epoch": 35, "training_loss": 67.20677614212036, "training_acc": 53.0, "val_loss": 17.879369854927063, "val_acc": 56.0}
{"epoch": 36, "training_loss": 67.29028701782227, "training_acc": 55.0, "val_loss": 17.883488535881042, "val_acc": 56.0}
{"epoch": 37, "training_loss": 67.71270370483398, "training_acc": 53.0, "val_loss": 17.88557916879654, "val_acc": 56.0}
{"epoch": 38, "training_loss": 67.56754350662231, "training_acc": 54.0, "val_loss": 17.889411747455597, "val_acc": 56.0}
{"epoch": 39, "training_loss": 67.18487691879272, "training_acc": 58.0, "val_loss": 17.886994779109955, "val_acc": 56.0}
{"epoch": 40, "training_loss": 66.78811645507812, "training_acc": 54.0, "val_loss": 17.87937432527542, "val_acc": 56.0}
{"epoch": 41, "training_loss": 67.01967597007751, "training_acc": 52.0, "val_loss": 17.873375117778778, "val_acc": 56.0}
{"epoch": 42, "training_loss": 67.26336431503296, "training_acc": 54.0, "val_loss": 17.87191927433014, "val_acc": 56.0}
{"epoch": 43, "training_loss": 66.9490315914154, "training_acc": 59.0, "val_loss": 17.86811053752899, "val_acc": 56.0}
{"epoch": 44, "training_loss": 67.27799367904663, "training_acc": 55.0, "val_loss": 17.86557286977768, "val_acc": 56.0}
{"epoch": 45, "training_loss": 66.88118934631348, "training_acc": 59.0, "val_loss": 17.857180535793304, "val_acc": 56.0}
{"epoch": 46, "training_loss": 66.22864723205566, "training_acc": 62.0, "val_loss": 17.851869761943817, "val_acc": 56.0}
{"epoch": 47, "training_loss": 67.07379364967346, "training_acc": 57.0, "val_loss": 17.852237820625305, "val_acc": 56.0}
{"epoch": 48, "training_loss": 66.42256736755371, "training_acc": 62.0, "val_loss": 17.854808270931244, "val_acc": 56.0}
{"epoch": 49, "training_loss": 66.61492419242859, "training_acc": 60.0, "val_loss": 17.85557121038437, "val_acc": 56.0}
{"epoch": 50, "training_loss": 66.34431791305542, "training_acc": 62.0, "val_loss": 17.852436006069183, "val_acc": 52.0}
{"epoch": 51, "training_loss": 66.45716142654419, "training_acc": 63.0, "val_loss": 17.854033410549164, "val_acc": 52.0}
{"epoch": 52, "training_loss": 66.51317501068115, "training_acc": 63.0, "val_loss": 17.857758700847626, "val_acc": 52.0}
{"epoch": 53, "training_loss": 66.04125833511353, "training_acc": 65.0, "val_loss": 17.865848541259766, "val_acc": 52.0}
{"epoch": 54, "training_loss": 66.40472388267517, "training_acc": 63.0, "val_loss": 17.873044312000275, "val_acc": 52.0}
{"epoch": 55, "training_loss": 66.1195182800293, "training_acc": 64.0, "val_loss": 17.874884605407715, "val_acc": 52.0}
{"epoch": 56, "training_loss": 66.10425043106079, "training_acc": 62.0, "val_loss": 17.87770390510559, "val_acc": 52.0}
{"epoch": 57, "training_loss": 65.97923946380615, "training_acc": 63.0, "val_loss": 17.870016396045685, "val_acc": 52.0}
{"epoch": 58, "training_loss": 65.9082179069519, "training_acc": 60.0, "val_loss": 17.858532071113586, "val_acc": 52.0}
{"epoch": 59, "training_loss": 65.65138936042786, "training_acc": 63.0, "val_loss": 17.84704029560089, "val_acc": 52.0}
{"epoch": 60, "training_loss": 65.57673954963684, "training_acc": 65.0, "val_loss": 17.834487557411194, "val_acc": 52.0}
{"epoch": 61, "training_loss": 65.60307598114014, "training_acc": 64.0, "val_loss": 17.829714715480804, "val_acc": 52.0}
{"epoch": 62, "training_loss": 65.83754086494446, "training_acc": 60.0, "val_loss": 17.83132553100586, "val_acc": 52.0}
{"epoch": 63, "training_loss": 65.5551176071167, "training_acc": 64.0, "val_loss": 17.830221354961395, "val_acc": 52.0}
{"epoch": 64, "training_loss": 65.22488045692444, "training_acc": 68.0, "val_loss": 17.824403941631317, "val_acc": 52.0}
{"epoch": 65, "training_loss": 65.11387872695923, "training_acc": 66.0, "val_loss": 17.81744956970215, "val_acc": 52.0}
{"epoch": 66, "training_loss": 65.16824102401733, "training_acc": 66.0, "val_loss": 17.805388569831848, "val_acc": 52.0}
{"epoch": 67, "training_loss": 64.97295618057251, "training_acc": 68.0, "val_loss": 17.79457777738571, "val_acc": 52.0}
{"epoch": 68, "training_loss": 64.98198914527893, "training_acc": 67.0, "val_loss": 17.79206097126007, "val_acc": 52.0}
{"epoch": 69, "training_loss": 65.26554775238037, "training_acc": 62.0, "val_loss": 17.791885137557983, "val_acc": 52.0}
{"epoch": 70, "training_loss": 64.62865400314331, "training_acc": 65.0, "val_loss": 17.798656225204468, "val_acc": 52.0}
{"epoch": 71, "training_loss": 65.05839490890503, "training_acc": 62.0, "val_loss": 17.807714641094208, "val_acc": 52.0}
{"epoch": 72, "training_loss": 64.5917763710022, "training_acc": 66.0, "val_loss": 17.81308948993683, "val_acc": 52.0}
{"epoch": 73, "training_loss": 64.78878116607666, "training_acc": 64.0, "val_loss": 17.809054255485535, "val_acc": 52.0}
{"epoch": 74, "training_loss": 64.9942831993103, "training_acc": 65.0, "val_loss": 17.797812819480896, "val_acc": 52.0}
{"epoch": 75, "training_loss": 64.56807708740234, "training_acc": 64.0, "val_loss": 17.79354065656662, "val_acc": 52.0}
{"epoch": 76, "training_loss": 64.63124942779541, "training_acc": 66.0, "val_loss": 17.78949350118637, "val_acc": 52.0}
{"epoch": 77, "training_loss": 64.03137683868408, "training_acc": 64.0, "val_loss": 17.789828777313232, "val_acc": 52.0}
{"epoch": 78, "training_loss": 64.39491677284241, "training_acc": 65.0, "val_loss": 17.794562876224518, "val_acc": 52.0}
{"epoch": 79, "training_loss": 64.6719446182251, "training_acc": 64.0, "val_loss": 17.805933952331543, "val_acc": 52.0}
{"epoch": 80, "training_loss": 64.02196168899536, "training_acc": 65.0, "val_loss": 17.818474769592285, "val_acc": 52.0}
{"epoch": 81, "training_loss": 64.42600727081299, "training_acc": 65.0, "val_loss": 17.832492291927338, "val_acc": 52.0}
{"epoch": 82, "training_loss": 64.22907280921936, "training_acc": 64.0, "val_loss": 17.842839658260345, "val_acc": 52.0}
{"epoch": 83, "training_loss": 64.26270198822021, "training_acc": 63.0, "val_loss": 17.850391566753387, "val_acc": 52.0}
{"epoch": 84, "training_loss": 64.32459807395935, "training_acc": 65.0, "val_loss": 17.85742938518524, "val_acc": 52.0}
{"epoch": 85, "training_loss": 63.718260288238525, "training_acc": 66.0, "val_loss": 17.861631512641907, "val_acc": 52.0}
{"epoch": 86, "training_loss": 64.29559564590454, "training_acc": 60.0, "val_loss": 17.8602933883667, "val_acc": 52.0}
{"epoch": 87, "training_loss": 64.26630234718323, "training_acc": 63.0, "val_loss": 17.85736382007599, "val_acc": 52.0}
{"epoch": 88, "training_loss": 63.82562279701233, "training_acc": 63.0, "val_loss": 17.85418838262558, "val_acc": 52.0}
{"epoch": 89, "training_loss": 63.79747414588928, "training_acc": 66.0, "val_loss": 17.854732275009155, "val_acc": 52.0}
{"epoch": 90, "training_loss": 64.04937267303467, "training_acc": 66.0, "val_loss": 17.85328984260559, "val_acc": 52.0}
{"epoch": 91, "training_loss": 63.608394384384155, "training_acc": 64.0, "val_loss": 17.851263284683228, "val_acc": 52.0}
{"epoch": 92, "training_loss": 63.905465841293335, "training_acc": 63.0, "val_loss": 17.848297953605652, "val_acc": 52.0}
{"epoch": 93, "training_loss": 63.34757661819458, "training_acc": 65.0, "val_loss": 17.853355407714844, "val_acc": 52.0}
{"epoch": 94, "training_loss": 63.22807431221008, "training_acc": 64.0, "val_loss": 17.86201000213623, "val_acc": 52.0}
{"epoch": 95, "training_loss": 63.11933922767639, "training_acc": 65.0, "val_loss": 17.859630286693573, "val_acc": 52.0}
