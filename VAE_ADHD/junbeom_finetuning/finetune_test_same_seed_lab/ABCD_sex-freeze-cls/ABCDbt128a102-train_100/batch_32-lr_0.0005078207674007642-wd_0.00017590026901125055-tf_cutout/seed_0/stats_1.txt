"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.72746419906616, "training_acc": 43.0, "val_loss": 17.27912127971649, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.18650364875793, "training_acc": 53.0, "val_loss": 17.31233298778534, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.03396487236023, "training_acc": 53.0, "val_loss": 17.445877194404602, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.68606519699097, "training_acc": 53.0, "val_loss": 17.36348271369934, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.58203887939453, "training_acc": 53.0, "val_loss": 17.287562787532806, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.37086153030396, "training_acc": 48.0, "val_loss": 17.29952245950699, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.274489402771, "training_acc": 51.0, "val_loss": 17.295755445957184, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.46498346328735, "training_acc": 45.0, "val_loss": 17.423903942108154, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.96162557601929, "training_acc": 47.0, "val_loss": 17.43847280740738, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.62009692192078, "training_acc": 50.0, "val_loss": 17.282529175281525, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.78780722618103, "training_acc": 53.0, "val_loss": 17.431220412254333, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.46042084693909, "training_acc": 53.0, "val_loss": 17.427730560302734, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.44927167892456, "training_acc": 53.0, "val_loss": 17.360995709896088, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.09633874893188, "training_acc": 53.0, "val_loss": 17.284348607063293, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.26306390762329, "training_acc": 54.0, "val_loss": 17.29796528816223, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.139155626297, "training_acc": 51.0, "val_loss": 17.291204631328583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.31173419952393, "training_acc": 49.0, "val_loss": 17.297008633613586, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.07685399055481, "training_acc": 52.0, "val_loss": 17.285318672657013, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.27002143859863, "training_acc": 53.0, "val_loss": 17.28609949350357, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.09398245811462, "training_acc": 53.0, "val_loss": 17.285755276679993, "val_acc": 52.0}
