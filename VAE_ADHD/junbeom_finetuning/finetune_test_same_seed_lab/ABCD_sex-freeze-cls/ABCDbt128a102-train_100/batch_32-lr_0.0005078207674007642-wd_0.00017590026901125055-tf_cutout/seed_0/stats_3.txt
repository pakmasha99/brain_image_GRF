"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.11602354049683, "training_acc": 45.0, "val_loss": 17.327338457107544, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.94337558746338, "training_acc": 53.0, "val_loss": 17.354735732078552, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.13859391212463, "training_acc": 53.0, "val_loss": 17.326633632183075, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1129539012909, "training_acc": 53.0, "val_loss": 17.327900230884552, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.10849666595459, "training_acc": 53.0, "val_loss": 17.327389121055603, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.09179091453552, "training_acc": 53.0, "val_loss": 17.413724958896637, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.09756827354431, "training_acc": 53.0, "val_loss": 17.57371723651886, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.78735756874084, "training_acc": 53.0, "val_loss": 17.714564502239227, "val_acc": 52.0}
{"epoch": 8, "training_loss": 70.4660894870758, "training_acc": 53.0, "val_loss": 17.861734330654144, "val_acc": 52.0}
{"epoch": 9, "training_loss": 70.66720533370972, "training_acc": 53.0, "val_loss": 17.60120987892151, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.71368956565857, "training_acc": 53.0, "val_loss": 17.3525333404541, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.03944516181946, "training_acc": 53.0, "val_loss": 17.363902926445007, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.56824016571045, "training_acc": 46.0, "val_loss": 17.53593236207962, "val_acc": 52.0}
{"epoch": 13, "training_loss": 70.24932813644409, "training_acc": 47.0, "val_loss": 17.515607178211212, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.9140055179596, "training_acc": 47.0, "val_loss": 17.37990975379944, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.23725271224976, "training_acc": 47.0, "val_loss": 17.33023077249527, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.33447694778442, "training_acc": 53.0, "val_loss": 17.462141811847687, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.41355514526367, "training_acc": 53.0, "val_loss": 17.487062513828278, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.19852638244629, "training_acc": 53.0, "val_loss": 17.34784245491028, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.08747577667236, "training_acc": 52.0, "val_loss": 17.387180030345917, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.55695962905884, "training_acc": 47.0, "val_loss": 17.51212626695633, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.95560884475708, "training_acc": 47.0, "val_loss": 17.51985251903534, "val_acc": 52.0}
