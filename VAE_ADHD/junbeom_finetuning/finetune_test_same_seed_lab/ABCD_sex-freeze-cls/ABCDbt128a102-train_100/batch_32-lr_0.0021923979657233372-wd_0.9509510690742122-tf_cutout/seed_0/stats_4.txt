"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 73.28854322433472, "training_acc": 47.0, "val_loss": 17.577071487903595, "val_acc": 52.0}
{"epoch": 1, "training_loss": 76.40481090545654, "training_acc": 47.0, "val_loss": 19.79139596223831, "val_acc": 48.0}
{"epoch": 2, "training_loss": 76.61198210716248, "training_acc": 47.0, "val_loss": 17.290036380290985, "val_acc": 52.0}
{"epoch": 3, "training_loss": 70.82742547988892, "training_acc": 53.0, "val_loss": 17.531314492225647, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.30814790725708, "training_acc": 49.0, "val_loss": 17.285653948783875, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.0703444480896, "training_acc": 53.0, "val_loss": 17.41059273481369, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.28884649276733, "training_acc": 53.0, "val_loss": 17.318929731845856, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.50608158111572, "training_acc": 53.0, "val_loss": 17.307889461517334, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.2409098148346, "training_acc": 50.0, "val_loss": 17.282207310199738, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.14470529556274, "training_acc": 53.0, "val_loss": 17.39656627178192, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.73430609703064, "training_acc": 53.0, "val_loss": 17.5456240773201, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.6066460609436, "training_acc": 53.0, "val_loss": 17.281542718410492, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.89741015434265, "training_acc": 53.0, "val_loss": 17.295554280281067, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.03550457954407, "training_acc": 53.0, "val_loss": 17.28176474571228, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.22374200820923, "training_acc": 53.0, "val_loss": 17.541110515594482, "val_acc": 52.0}
{"epoch": 15, "training_loss": 70.46031618118286, "training_acc": 47.0, "val_loss": 17.285773158073425, "val_acc": 52.0}
{"epoch": 16, "training_loss": 72.42051339149475, "training_acc": 53.0, "val_loss": 18.838094174861908, "val_acc": 52.0}
{"epoch": 17, "training_loss": 74.15559005737305, "training_acc": 53.0, "val_loss": 17.36200600862503, "val_acc": 52.0}
{"epoch": 18, "training_loss": 71.85513162612915, "training_acc": 49.0, "val_loss": 18.43939572572708, "val_acc": 48.0}
{"epoch": 19, "training_loss": 72.13138389587402, "training_acc": 48.0, "val_loss": 17.37467497587204, "val_acc": 52.0}
{"epoch": 20, "training_loss": 71.67797327041626, "training_acc": 53.0, "val_loss": 19.100165367126465, "val_acc": 52.0}
{"epoch": 21, "training_loss": 74.8244116306305, "training_acc": 53.0, "val_loss": 17.56918728351593, "val_acc": 52.0}
{"epoch": 22, "training_loss": 70.01742243766785, "training_acc": 49.0, "val_loss": 17.691604793071747, "val_acc": 52.0}
{"epoch": 23, "training_loss": 70.16238069534302, "training_acc": 47.0, "val_loss": 17.292501032352448, "val_acc": 52.0}
{"epoch": 24, "training_loss": 71.42726278305054, "training_acc": 53.0, "val_loss": 17.718039453029633, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.62033081054688, "training_acc": 54.0, "val_loss": 17.65234023332596, "val_acc": 52.0}
{"epoch": 26, "training_loss": 70.42773628234863, "training_acc": 47.0, "val_loss": 17.26529449224472, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23285341262817, "training_acc": 53.0, "val_loss": 17.734821140766144, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.60929536819458, "training_acc": 53.0, "val_loss": 17.30615943670273, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.84124088287354, "training_acc": 48.0, "val_loss": 17.28195548057556, "val_acc": 52.0}
{"epoch": 30, "training_loss": 68.9844183921814, "training_acc": 55.0, "val_loss": 18.495097756385803, "val_acc": 52.0}
{"epoch": 31, "training_loss": 74.22535037994385, "training_acc": 53.0, "val_loss": 18.352767825126648, "val_acc": 52.0}
{"epoch": 32, "training_loss": 71.42829585075378, "training_acc": 53.0, "val_loss": 17.271459102630615, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.76139903068542, "training_acc": 54.0, "val_loss": 17.292051017284393, "val_acc": 52.0}
{"epoch": 34, "training_loss": 68.96394062042236, "training_acc": 59.0, "val_loss": 17.26720929145813, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.62943935394287, "training_acc": 53.0, "val_loss": 17.527751624584198, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.15662240982056, "training_acc": 53.0, "val_loss": 17.323414981365204, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.26506614685059, "training_acc": 55.0, "val_loss": 17.553608119487762, "val_acc": 52.0}
{"epoch": 38, "training_loss": 71.12266159057617, "training_acc": 47.0, "val_loss": 17.855945229530334, "val_acc": 52.0}
{"epoch": 39, "training_loss": 71.87036466598511, "training_acc": 49.0, "val_loss": 17.26745069026947, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.67957878112793, "training_acc": 53.0, "val_loss": 17.275136709213257, "val_acc": 52.0}
{"epoch": 41, "training_loss": 68.76659488677979, "training_acc": 53.0, "val_loss": 17.306029796600342, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.32624530792236, "training_acc": 54.0, "val_loss": 17.66413450241089, "val_acc": 52.0}
{"epoch": 43, "training_loss": 74.1381893157959, "training_acc": 47.0, "val_loss": 18.051105737686157, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.92505550384521, "training_acc": 53.0, "val_loss": 18.006974458694458, "val_acc": 52.0}
{"epoch": 45, "training_loss": 71.6150951385498, "training_acc": 53.0, "val_loss": 17.700879275798798, "val_acc": 52.0}
{"epoch": 46, "training_loss": 70.45311999320984, "training_acc": 53.0, "val_loss": 17.26064831018448, "val_acc": 52.0}
{"epoch": 47, "training_loss": 68.6738510131836, "training_acc": 53.0, "val_loss": 17.331187427043915, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.20197820663452, "training_acc": 53.0, "val_loss": 17.38966852426529, "val_acc": 52.0}
{"epoch": 49, "training_loss": 68.39447593688965, "training_acc": 54.0, "val_loss": 17.441143095493317, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.57211303710938, "training_acc": 47.0, "val_loss": 17.274776101112366, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.83909440040588, "training_acc": 52.0, "val_loss": 17.65713095664978, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.9093267917633, "training_acc": 53.0, "val_loss": 17.31252670288086, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.541916847229, "training_acc": 57.0, "val_loss": 17.443305253982544, "val_acc": 52.0}
{"epoch": 54, "training_loss": 70.82161235809326, "training_acc": 47.0, "val_loss": 17.254944145679474, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.41515350341797, "training_acc": 53.0, "val_loss": 19.544486701488495, "val_acc": 52.0}
{"epoch": 56, "training_loss": 77.18122088909149, "training_acc": 53.0, "val_loss": 18.524901568889618, "val_acc": 52.0}
{"epoch": 57, "training_loss": 71.84729504585266, "training_acc": 53.0, "val_loss": 17.316028475761414, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.24617528915405, "training_acc": 52.0, "val_loss": 17.837682366371155, "val_acc": 52.0}
{"epoch": 59, "training_loss": 71.09219884872437, "training_acc": 47.0, "val_loss": 17.334528267383575, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.06180548667908, "training_acc": 47.0, "val_loss": 17.689351737499237, "val_acc": 52.0}
{"epoch": 61, "training_loss": 73.00354528427124, "training_acc": 53.0, "val_loss": 18.20797324180603, "val_acc": 52.0}
{"epoch": 62, "training_loss": 70.77886176109314, "training_acc": 53.0, "val_loss": 17.31870174407959, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.34182929992676, "training_acc": 49.0, "val_loss": 17.255355417728424, "val_acc": 52.0}
{"epoch": 64, "training_loss": 68.8329906463623, "training_acc": 55.0, "val_loss": 17.41444617509842, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.01276063919067, "training_acc": 53.0, "val_loss": 17.34059900045395, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.46890830993652, "training_acc": 53.0, "val_loss": 17.616643011569977, "val_acc": 52.0}
{"epoch": 67, "training_loss": 70.14094829559326, "training_acc": 53.0, "val_loss": 17.485342919826508, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.47063732147217, "training_acc": 45.0, "val_loss": 18.004992604255676, "val_acc": 52.0}
{"epoch": 69, "training_loss": 74.04065942764282, "training_acc": 47.0, "val_loss": 18.295226991176605, "val_acc": 56.0}
{"epoch": 70, "training_loss": 72.66357660293579, "training_acc": 48.0, "val_loss": 17.338082194328308, "val_acc": 52.0}
{"epoch": 71, "training_loss": 70.11752367019653, "training_acc": 53.0, "val_loss": 17.70305335521698, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.74555230140686, "training_acc": 54.0, "val_loss": 17.855869233608246, "val_acc": 52.0}
{"epoch": 73, "training_loss": 73.1638560295105, "training_acc": 47.0, "val_loss": 17.628338932991028, "val_acc": 52.0}
