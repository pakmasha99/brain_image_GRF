"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 439.5482179168612, "training_acc": 51.0, "val_loss": 224.35152530670166, "val_acc": 48.0}
{"epoch": 1, "training_loss": 866.2676391601562, "training_acc": 47.0, "val_loss": 47.763389348983765, "val_acc": 52.0}
{"epoch": 2, "training_loss": 399.7796096801758, "training_acc": 53.0, "val_loss": 48.60105812549591, "val_acc": 52.0}
{"epoch": 3, "training_loss": 192.74558544158936, "training_acc": 57.0, "val_loss": 80.2903413772583, "val_acc": 48.0}
{"epoch": 4, "training_loss": 207.38124256581068, "training_acc": 49.0, "val_loss": 83.9919924736023, "val_acc": 52.0}
{"epoch": 5, "training_loss": 265.5618875026703, "training_acc": 53.0, "val_loss": 52.14195251464844, "val_acc": 48.0}
{"epoch": 6, "training_loss": 199.21901845932007, "training_acc": 47.0, "val_loss": 42.391639947891235, "val_acc": 52.0}
{"epoch": 7, "training_loss": 144.51233530044556, "training_acc": 53.0, "val_loss": 33.19958448410034, "val_acc": 48.0}
{"epoch": 8, "training_loss": 104.08111333847046, "training_acc": 49.0, "val_loss": 23.37392419576645, "val_acc": 52.0}
{"epoch": 9, "training_loss": 83.04503440856934, "training_acc": 51.0, "val_loss": 23.00197035074234, "val_acc": 52.0}
{"epoch": 10, "training_loss": 101.72118735313416, "training_acc": 53.0, "val_loss": 30.295932292938232, "val_acc": 48.0}
{"epoch": 11, "training_loss": 100.3429811000824, "training_acc": 49.0, "val_loss": 35.27915179729462, "val_acc": 52.0}
{"epoch": 12, "training_loss": 113.03164863586426, "training_acc": 47.0, "val_loss": 18.79081279039383, "val_acc": 44.0}
{"epoch": 13, "training_loss": 93.41274070739746, "training_acc": 51.0, "val_loss": 33.5686981678009, "val_acc": 48.0}
{"epoch": 14, "training_loss": 131.30564880371094, "training_acc": 47.0, "val_loss": 34.717389941215515, "val_acc": 52.0}
{"epoch": 15, "training_loss": 124.04265880584717, "training_acc": 41.0, "val_loss": 19.924362003803253, "val_acc": 52.0}
{"epoch": 16, "training_loss": 125.95852994918823, "training_acc": 51.0, "val_loss": 23.4447181224823, "val_acc": 48.0}
{"epoch": 17, "training_loss": 82.34843254089355, "training_acc": 49.0, "val_loss": 19.938156008720398, "val_acc": 48.0}
{"epoch": 18, "training_loss": 83.27956509590149, "training_acc": 49.0, "val_loss": 38.54845464229584, "val_acc": 52.0}
{"epoch": 19, "training_loss": 124.55377340316772, "training_acc": 51.0, "val_loss": 26.358631253242493, "val_acc": 48.0}
{"epoch": 20, "training_loss": 102.69934678077698, "training_acc": 47.0, "val_loss": 17.193114757537842, "val_acc": 52.0}
{"epoch": 21, "training_loss": 70.14774417877197, "training_acc": 52.0, "val_loss": 17.499344050884247, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.07995772361755, "training_acc": 58.0, "val_loss": 21.5867280960083, "val_acc": 52.0}
{"epoch": 23, "training_loss": 84.60330867767334, "training_acc": 45.0, "val_loss": 19.69655603170395, "val_acc": 52.0}
{"epoch": 24, "training_loss": 87.31182980537415, "training_acc": 57.0, "val_loss": 55.44925928115845, "val_acc": 48.0}
{"epoch": 25, "training_loss": 194.14968276023865, "training_acc": 49.0, "val_loss": 61.858391761779785, "val_acc": 52.0}
{"epoch": 26, "training_loss": 213.6168212890625, "training_acc": 51.0, "val_loss": 33.746808767318726, "val_acc": 48.0}
{"epoch": 27, "training_loss": 106.76965618133545, "training_acc": 49.0, "val_loss": 17.72906482219696, "val_acc": 52.0}
{"epoch": 28, "training_loss": 97.8841164112091, "training_acc": 51.0, "val_loss": 25.895056128501892, "val_acc": 52.0}
{"epoch": 29, "training_loss": 92.00335597991943, "training_acc": 53.0, "val_loss": 20.392155647277832, "val_acc": 52.0}
{"epoch": 30, "training_loss": 98.7164375782013, "training_acc": 51.0, "val_loss": 18.841703236103058, "val_acc": 52.0}
{"epoch": 31, "training_loss": 78.42381501197815, "training_acc": 51.0, "val_loss": 17.16398596763611, "val_acc": 52.0}
{"epoch": 32, "training_loss": 67.28900790214539, "training_acc": 60.0, "val_loss": 24.233950674533844, "val_acc": 52.0}
{"epoch": 33, "training_loss": 86.60710501670837, "training_acc": 49.0, "val_loss": 19.346052408218384, "val_acc": 52.0}
{"epoch": 34, "training_loss": 78.80082035064697, "training_acc": 51.0, "val_loss": 17.02975630760193, "val_acc": 52.0}
{"epoch": 35, "training_loss": 70.08904957771301, "training_acc": 54.0, "val_loss": 19.932495057582855, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.526362657547, "training_acc": 57.0, "val_loss": 18.986445665359497, "val_acc": 52.0}
{"epoch": 37, "training_loss": 108.01526403427124, "training_acc": 40.0, "val_loss": 44.12029981613159, "val_acc": 48.0}
{"epoch": 38, "training_loss": 149.06705856323242, "training_acc": 47.0, "val_loss": 37.25487291812897, "val_acc": 52.0}
{"epoch": 39, "training_loss": 90.26010060310364, "training_acc": 59.0, "val_loss": 45.67897617816925, "val_acc": 48.0}
{"epoch": 40, "training_loss": 124.51502561569214, "training_acc": 51.0, "val_loss": 36.660945415496826, "val_acc": 52.0}
{"epoch": 41, "training_loss": 116.94336414337158, "training_acc": 54.0, "val_loss": 20.2859029173851, "val_acc": 52.0}
{"epoch": 42, "training_loss": 112.37326908111572, "training_acc": 47.0, "val_loss": 56.715673208236694, "val_acc": 48.0}
{"epoch": 43, "training_loss": 292.0641965866089, "training_acc": 47.0, "val_loss": 58.046406507492065, "val_acc": 52.0}
{"epoch": 44, "training_loss": 387.15176010131836, "training_acc": 53.0, "val_loss": 65.37505984306335, "val_acc": 52.0}
{"epoch": 45, "training_loss": 194.7891731262207, "training_acc": 53.0, "val_loss": 67.44889616966248, "val_acc": 48.0}
{"epoch": 46, "training_loss": 144.20862531661987, "training_acc": 59.0, "val_loss": 91.0837471485138, "val_acc": 52.0}
{"epoch": 47, "training_loss": 262.75926971435547, "training_acc": 51.0, "val_loss": 54.387933015823364, "val_acc": 48.0}
{"epoch": 48, "training_loss": 158.53747749328613, "training_acc": 45.0, "val_loss": 27.823343873023987, "val_acc": 52.0}
{"epoch": 49, "training_loss": 96.69720411300659, "training_acc": 51.0, "val_loss": 17.97461211681366, "val_acc": 52.0}
{"epoch": 50, "training_loss": 104.37007236480713, "training_acc": 51.0, "val_loss": 19.79198455810547, "val_acc": 52.0}
{"epoch": 51, "training_loss": 83.22996425628662, "training_acc": 51.0, "val_loss": 20.745088160037994, "val_acc": 48.0}
{"epoch": 52, "training_loss": 91.3008804321289, "training_acc": 37.0, "val_loss": 16.994816064834595, "val_acc": 52.0}
{"epoch": 53, "training_loss": 68.95306873321533, "training_acc": 57.0, "val_loss": 18.24295222759247, "val_acc": 52.0}
{"epoch": 54, "training_loss": 75.91207695007324, "training_acc": 43.0, "val_loss": 43.84840428829193, "val_acc": 52.0}
{"epoch": 55, "training_loss": 150.83345365524292, "training_acc": 51.0, "val_loss": 30.407461524009705, "val_acc": 48.0}
{"epoch": 56, "training_loss": 82.00377863645554, "training_acc": 55.0, "val_loss": 39.46160674095154, "val_acc": 52.0}
{"epoch": 57, "training_loss": 103.13256645202637, "training_acc": 57.0, "val_loss": 36.80926561355591, "val_acc": 48.0}
{"epoch": 58, "training_loss": 102.68876647949219, "training_acc": 54.0, "val_loss": 19.925425946712494, "val_acc": 52.0}
{"epoch": 59, "training_loss": 92.49449586868286, "training_acc": 50.0, "val_loss": 22.272805869579315, "val_acc": 52.0}
{"epoch": 60, "training_loss": 86.03447532653809, "training_acc": 55.0, "val_loss": 17.980660498142242, "val_acc": 68.0}
{"epoch": 61, "training_loss": 109.05703115463257, "training_acc": 42.0, "val_loss": 20.216526091098785, "val_acc": 52.0}
{"epoch": 62, "training_loss": 75.98952734470367, "training_acc": 48.0, "val_loss": 18.707676231861115, "val_acc": 52.0}
{"epoch": 63, "training_loss": 74.42834091186523, "training_acc": 49.0, "val_loss": 30.147045850753784, "val_acc": 52.0}
{"epoch": 64, "training_loss": 95.35820436477661, "training_acc": 56.0, "val_loss": 28.0196875333786, "val_acc": 48.0}
{"epoch": 65, "training_loss": 94.40562677383423, "training_acc": 51.0, "val_loss": 17.164717614650726, "val_acc": 52.0}
{"epoch": 66, "training_loss": 64.32545471191406, "training_acc": 62.0, "val_loss": 32.3908269405365, "val_acc": 52.0}
{"epoch": 67, "training_loss": 112.11164712905884, "training_acc": 55.0, "val_loss": 48.04072976112366, "val_acc": 48.0}
{"epoch": 68, "training_loss": 140.48395156860352, "training_acc": 45.0, "val_loss": 36.93939745426178, "val_acc": 52.0}
{"epoch": 69, "training_loss": 119.6648018360138, "training_acc": 50.0, "val_loss": 21.161383390426636, "val_acc": 48.0}
{"epoch": 70, "training_loss": 118.98310327529907, "training_acc": 43.0, "val_loss": 18.260444700717926, "val_acc": 68.0}
{"epoch": 71, "training_loss": 72.27664852142334, "training_acc": 50.0, "val_loss": 21.281161904335022, "val_acc": 48.0}
