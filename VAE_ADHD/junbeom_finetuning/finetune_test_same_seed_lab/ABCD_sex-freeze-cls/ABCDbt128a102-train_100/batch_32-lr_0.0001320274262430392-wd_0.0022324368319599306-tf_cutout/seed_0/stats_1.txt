"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.5223879814148, "training_acc": 47.0, "val_loss": 17.446942627429962, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.72893857955933, "training_acc": 47.0, "val_loss": 17.33047515153885, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.2419261932373, "training_acc": 55.0, "val_loss": 17.308279871940613, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.33145761489868, "training_acc": 53.0, "val_loss": 17.34336167573929, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.19807600975037, "training_acc": 53.0, "val_loss": 17.366279661655426, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.21422481536865, "training_acc": 53.0, "val_loss": 17.37797111272812, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.2444097995758, "training_acc": 53.0, "val_loss": 17.36397296190262, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.26962113380432, "training_acc": 53.0, "val_loss": 17.349092662334442, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.17820048332214, "training_acc": 53.0, "val_loss": 17.341266572475433, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20651459693909, "training_acc": 53.0, "val_loss": 17.324604094028473, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.13608980178833, "training_acc": 53.0, "val_loss": 17.319941520690918, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21187448501587, "training_acc": 53.0, "val_loss": 17.309968173503876, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.08308935165405, "training_acc": 53.0, "val_loss": 17.30741411447525, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.00579929351807, "training_acc": 53.0, "val_loss": 17.308175563812256, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.18789196014404, "training_acc": 53.0, "val_loss": 17.312975227832794, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18081760406494, "training_acc": 53.0, "val_loss": 17.313483357429504, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20526933670044, "training_acc": 53.0, "val_loss": 17.311622202396393, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.14965438842773, "training_acc": 53.0, "val_loss": 17.307743430137634, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.07527828216553, "training_acc": 53.0, "val_loss": 17.307841777801514, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.04256319999695, "training_acc": 53.0, "val_loss": 17.3169806599617, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.05933094024658, "training_acc": 53.0, "val_loss": 17.340204119682312, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.17498207092285, "training_acc": 53.0, "val_loss": 17.350856959819794, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13007259368896, "training_acc": 53.0, "val_loss": 17.33483523130417, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.12885665893555, "training_acc": 53.0, "val_loss": 17.32231229543686, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.08379673957825, "training_acc": 53.0, "val_loss": 17.315207421779633, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.08648180961609, "training_acc": 53.0, "val_loss": 17.31392592191696, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.08751583099365, "training_acc": 53.0, "val_loss": 17.30942726135254, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.13187217712402, "training_acc": 53.0, "val_loss": 17.30826497077942, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.07630825042725, "training_acc": 53.0, "val_loss": 17.31051206588745, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.11431646347046, "training_acc": 53.0, "val_loss": 17.312145233154297, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.05620789527893, "training_acc": 53.0, "val_loss": 17.308518290519714, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.10685682296753, "training_acc": 53.0, "val_loss": 17.308373749256134, "val_acc": 52.0}
