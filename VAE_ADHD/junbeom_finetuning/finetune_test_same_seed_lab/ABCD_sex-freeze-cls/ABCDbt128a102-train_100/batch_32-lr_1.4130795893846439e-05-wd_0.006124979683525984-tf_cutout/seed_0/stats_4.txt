"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.14163136482239, "training_acc": 53.0, "val_loss": 17.30111986398697, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.1467936038971, "training_acc": 53.0, "val_loss": 17.300471663475037, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.12712955474854, "training_acc": 53.0, "val_loss": 17.300422489643097, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13657021522522, "training_acc": 53.0, "val_loss": 17.299993336200714, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.12642574310303, "training_acc": 53.0, "val_loss": 17.299823462963104, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.16555547714233, "training_acc": 53.0, "val_loss": 17.299681901931763, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.16355514526367, "training_acc": 53.0, "val_loss": 17.299647629261017, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.12971067428589, "training_acc": 53.0, "val_loss": 17.299646139144897, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15207815170288, "training_acc": 53.0, "val_loss": 17.299719154834747, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.15793561935425, "training_acc": 53.0, "val_loss": 17.29968786239624, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.14199447631836, "training_acc": 53.0, "val_loss": 17.29966849088669, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.14777708053589, "training_acc": 53.0, "val_loss": 17.299674451351166, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.09499073028564, "training_acc": 53.0, "val_loss": 17.299705743789673, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.08653807640076, "training_acc": 53.0, "val_loss": 17.299850285053253, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1456127166748, "training_acc": 53.0, "val_loss": 17.300143837928772, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.147376537323, "training_acc": 53.0, "val_loss": 17.301003634929657, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.15805315971375, "training_acc": 53.0, "val_loss": 17.301471531391144, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.13512921333313, "training_acc": 53.0, "val_loss": 17.301306128501892, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.097083568573, "training_acc": 53.0, "val_loss": 17.300841212272644, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.11341333389282, "training_acc": 53.0, "val_loss": 17.30014830827713, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.11690902709961, "training_acc": 53.0, "val_loss": 17.299754917621613, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.13655877113342, "training_acc": 53.0, "val_loss": 17.299726605415344, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.09646940231323, "training_acc": 53.0, "val_loss": 17.299935221672058, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15524911880493, "training_acc": 53.0, "val_loss": 17.300209403038025, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15037393569946, "training_acc": 53.0, "val_loss": 17.30019301176071, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.15121340751648, "training_acc": 53.0, "val_loss": 17.300131916999817, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.14895391464233, "training_acc": 53.0, "val_loss": 17.299866676330566, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.15772581100464, "training_acc": 53.0, "val_loss": 17.299577593803406, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14324021339417, "training_acc": 53.0, "val_loss": 17.299464344978333, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.1617078781128, "training_acc": 53.0, "val_loss": 17.29956567287445, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17430591583252, "training_acc": 53.0, "val_loss": 17.29959100484848, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.15839910507202, "training_acc": 53.0, "val_loss": 17.29957014322281, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.14131450653076, "training_acc": 53.0, "val_loss": 17.299571633338928, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.1355471611023, "training_acc": 53.0, "val_loss": 17.299610376358032, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.16005063056946, "training_acc": 53.0, "val_loss": 17.299801111221313, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.15551996231079, "training_acc": 53.0, "val_loss": 17.30005294084549, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.16218662261963, "training_acc": 53.0, "val_loss": 17.300234735012054, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13974189758301, "training_acc": 53.0, "val_loss": 17.300182580947876, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.11719703674316, "training_acc": 53.0, "val_loss": 17.300307750701904, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.20290780067444, "training_acc": 53.0, "val_loss": 17.300212383270264, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.17819786071777, "training_acc": 53.0, "val_loss": 17.29995161294937, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.14643716812134, "training_acc": 53.0, "val_loss": 17.299766838550568, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15633916854858, "training_acc": 53.0, "val_loss": 17.299601435661316, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.17431306838989, "training_acc": 53.0, "val_loss": 17.299485206604004, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.13275218009949, "training_acc": 53.0, "val_loss": 17.299363017082214, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.10861778259277, "training_acc": 53.0, "val_loss": 17.299342155456543, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.1343343257904, "training_acc": 53.0, "val_loss": 17.299319803714752, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17781114578247, "training_acc": 53.0, "val_loss": 17.299315333366394, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.16710162162781, "training_acc": 53.0, "val_loss": 17.299313843250275, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.17879486083984, "training_acc": 53.0, "val_loss": 17.299385368824005, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.15463256835938, "training_acc": 53.0, "val_loss": 17.299531400203705, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.12903332710266, "training_acc": 53.0, "val_loss": 17.299480736255646, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.1444718837738, "training_acc": 53.0, "val_loss": 17.299337685108185, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.14263439178467, "training_acc": 53.0, "val_loss": 17.299339175224304, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.16464376449585, "training_acc": 53.0, "val_loss": 17.299655079841614, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.19784998893738, "training_acc": 53.0, "val_loss": 17.300285398960114, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.1235671043396, "training_acc": 53.0, "val_loss": 17.300887405872345, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.14597392082214, "training_acc": 53.0, "val_loss": 17.30148047208786, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.13228511810303, "training_acc": 53.0, "val_loss": 17.302502691745758, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.1384027004242, "training_acc": 53.0, "val_loss": 17.303746938705444, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.12142086029053, "training_acc": 53.0, "val_loss": 17.304326593875885, "val_acc": 52.0}
