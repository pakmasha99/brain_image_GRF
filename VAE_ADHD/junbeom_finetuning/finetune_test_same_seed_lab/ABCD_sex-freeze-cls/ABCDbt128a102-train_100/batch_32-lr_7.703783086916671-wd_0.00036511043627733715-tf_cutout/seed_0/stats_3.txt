"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 64815.25997543335, "training_acc": 54.0, "val_loss": 29412.686157226562, "val_acc": 48.0}
{"epoch": 1, "training_loss": 84495.53979492188, "training_acc": 47.0, "val_loss": 20298.500061035156, "val_acc": 52.0}
{"epoch": 2, "training_loss": 75340.93090820312, "training_acc": 53.0, "val_loss": 6304.832458496094, "val_acc": 48.0}
{"epoch": 3, "training_loss": 42029.619140625, "training_acc": 47.0, "val_loss": 2762.240982055664, "val_acc": 52.0}
{"epoch": 4, "training_loss": 24198.77197265625, "training_acc": 53.0, "val_loss": 2696.9423294067383, "val_acc": 48.0}
{"epoch": 5, "training_loss": 13324.660278320312, "training_acc": 47.0, "val_loss": 6261.602020263672, "val_acc": 52.0}
{"epoch": 6, "training_loss": 17056.8359375, "training_acc": 47.0, "val_loss": 3362.1082305908203, "val_acc": 52.0}
{"epoch": 7, "training_loss": 16506.95972442627, "training_acc": 53.0, "val_loss": 943.1241035461426, "val_acc": 48.0}
{"epoch": 8, "training_loss": 14006.130157470703, "training_acc": 37.0, "val_loss": 8569.461822509766, "val_acc": 48.0}
{"epoch": 9, "training_loss": 49586.99658203125, "training_acc": 47.0, "val_loss": 3400.531005859375, "val_acc": 48.0}
{"epoch": 10, "training_loss": 26169.912109375, "training_acc": 49.0, "val_loss": 7745.574188232422, "val_acc": 52.0}
{"epoch": 11, "training_loss": 22670.922729492188, "training_acc": 55.0, "val_loss": 11588.397216796875, "val_acc": 48.0}
{"epoch": 12, "training_loss": 26593.368713378906, "training_acc": 49.0, "val_loss": 15892.179870605469, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69680.912109375, "training_acc": 53.0, "val_loss": 8866.02554321289, "val_acc": 52.0}
{"epoch": 14, "training_loss": 32887.410736083984, "training_acc": 47.0, "val_loss": 17985.110473632812, "val_acc": 48.0}
{"epoch": 15, "training_loss": 50929.27746582031, "training_acc": 45.0, "val_loss": 8729.04052734375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 32207.623262405396, "training_acc": 53.0, "val_loss": 7525.506591796875, "val_acc": 48.0}
{"epoch": 17, "training_loss": 33826.50018310547, "training_acc": 47.0, "val_loss": 2978.6779403686523, "val_acc": 52.0}
{"epoch": 18, "training_loss": 13002.578033447266, "training_acc": 53.0, "val_loss": 2461.954116821289, "val_acc": 48.0}
{"epoch": 19, "training_loss": 4713.843978881836, "training_acc": 55.0, "val_loss": 4229.274368286133, "val_acc": 48.0}
{"epoch": 20, "training_loss": 14496.62548828125, "training_acc": 49.0, "val_loss": 2427.1059036254883, "val_acc": 52.0}
{"epoch": 21, "training_loss": 28000.919555664062, "training_acc": 43.0, "val_loss": 2447.8710174560547, "val_acc": 48.0}
{"epoch": 22, "training_loss": 29488.35595703125, "training_acc": 49.0, "val_loss": 10558.866119384766, "val_acc": 52.0}
{"epoch": 23, "training_loss": 30140.51873779297, "training_acc": 47.0, "val_loss": 9717.372131347656, "val_acc": 48.0}
{"epoch": 24, "training_loss": 23940.093139648438, "training_acc": 47.0, "val_loss": 13316.902160644531, "val_acc": 52.0}
{"epoch": 25, "training_loss": 52921.64794921875, "training_acc": 53.0, "val_loss": 1793.501853942871, "val_acc": 48.0}
{"epoch": 26, "training_loss": 22513.358032226562, "training_acc": 47.0, "val_loss": 850.3491401672363, "val_acc": 52.0}
{"epoch": 27, "training_loss": 7481.7347412109375, "training_acc": 51.0, "val_loss": 2698.347282409668, "val_acc": 48.0}
{"epoch": 28, "training_loss": 17121.639709472656, "training_acc": 41.0, "val_loss": 5044.4549560546875, "val_acc": 48.0}
{"epoch": 29, "training_loss": 27375.040954589844, "training_acc": 47.0, "val_loss": 5527.594757080078, "val_acc": 52.0}
{"epoch": 30, "training_loss": 32356.229461669922, "training_acc": 53.0, "val_loss": 708.2494735717773, "val_acc": 52.0}
{"epoch": 31, "training_loss": 22934.157165527344, "training_acc": 55.0, "val_loss": 3775.5325317382812, "val_acc": 48.0}
{"epoch": 32, "training_loss": 20147.51171875, "training_acc": 55.0, "val_loss": 7063.661193847656, "val_acc": 52.0}
{"epoch": 33, "training_loss": 13313.28857421875, "training_acc": 63.0, "val_loss": 12065.158081054688, "val_acc": 48.0}
{"epoch": 34, "training_loss": 37951.99249267578, "training_acc": 47.0, "val_loss": 5216.481781005859, "val_acc": 52.0}
{"epoch": 35, "training_loss": 16294.59765625, "training_acc": 55.0, "val_loss": 7695.606994628906, "val_acc": 48.0}
{"epoch": 36, "training_loss": 22866.737274169922, "training_acc": 49.0, "val_loss": 8796.062469482422, "val_acc": 52.0}
{"epoch": 37, "training_loss": 30497.81756591797, "training_acc": 53.0, "val_loss": 9302.362060546875, "val_acc": 48.0}
{"epoch": 38, "training_loss": 52798.12255859375, "training_acc": 47.0, "val_loss": 5105.482482910156, "val_acc": 48.0}
{"epoch": 39, "training_loss": 24796.01513671875, "training_acc": 57.0, "val_loss": 11496.941375732422, "val_acc": 52.0}
{"epoch": 40, "training_loss": 23888.09796142578, "training_acc": 49.0, "val_loss": 6208.238220214844, "val_acc": 48.0}
{"epoch": 41, "training_loss": 14870.917259216309, "training_acc": 49.0, "val_loss": 1166.9588088989258, "val_acc": 52.0}
{"epoch": 42, "training_loss": 14155.388672113419, "training_acc": 42.0, "val_loss": 3895.518112182617, "val_acc": 52.0}
{"epoch": 43, "training_loss": 9733.24267578125, "training_acc": 48.0, "val_loss": 379.2637348175049, "val_acc": 52.0}
{"epoch": 44, "training_loss": 7493.654678344727, "training_acc": 49.0, "val_loss": 4037.2425079345703, "val_acc": 48.0}
{"epoch": 45, "training_loss": 10673.566528320312, "training_acc": 55.0, "val_loss": 404.9609184265137, "val_acc": 48.0}
{"epoch": 46, "training_loss": 12585.351119995117, "training_acc": 60.0, "val_loss": 3464.3787384033203, "val_acc": 52.0}
{"epoch": 47, "training_loss": 18226.34538269043, "training_acc": 52.0, "val_loss": 1380.435848236084, "val_acc": 48.0}
{"epoch": 48, "training_loss": 4694.9306640625, "training_acc": 51.0, "val_loss": 3587.4317169189453, "val_acc": 48.0}
{"epoch": 49, "training_loss": 8700.398246765137, "training_acc": 47.0, "val_loss": 2956.068992614746, "val_acc": 48.0}
{"epoch": 50, "training_loss": 10867.525634765625, "training_acc": 53.0, "val_loss": 4195.71533203125, "val_acc": 52.0}
{"epoch": 51, "training_loss": 7659.005172729492, "training_acc": 53.0, "val_loss": 1803.3851623535156, "val_acc": 52.0}
{"epoch": 52, "training_loss": 3599.138313293457, "training_acc": 54.0, "val_loss": 5885.592269897461, "val_acc": 52.0}
{"epoch": 53, "training_loss": 27733.291748046875, "training_acc": 53.0, "val_loss": 6374.208831787109, "val_acc": 48.0}
{"epoch": 54, "training_loss": 36825.529052734375, "training_acc": 47.0, "val_loss": 1311.0644340515137, "val_acc": 52.0}
{"epoch": 55, "training_loss": 19904.287841796875, "training_acc": 53.0, "val_loss": 2655.9877395629883, "val_acc": 48.0}
{"epoch": 56, "training_loss": 15110.184265136719, "training_acc": 47.0, "val_loss": 3929.7264099121094, "val_acc": 52.0}
{"epoch": 57, "training_loss": 12730.61328125, "training_acc": 49.0, "val_loss": 290.96696376800537, "val_acc": 48.0}
{"epoch": 58, "training_loss": 13911.93539428711, "training_acc": 58.0, "val_loss": 4729.670333862305, "val_acc": 48.0}
{"epoch": 59, "training_loss": 27250.886840820312, "training_acc": 47.0, "val_loss": 6982.439422607422, "val_acc": 52.0}
{"epoch": 60, "training_loss": 44774.99853515625, "training_acc": 53.0, "val_loss": 7379.109954833984, "val_acc": 52.0}
{"epoch": 61, "training_loss": 18965.475952148438, "training_acc": 57.0, "val_loss": 16281.156921386719, "val_acc": 48.0}
{"epoch": 62, "training_loss": 51656.30628967285, "training_acc": 45.0, "val_loss": 3255.35888671875, "val_acc": 52.0}
{"epoch": 63, "training_loss": 7068.203727722168, "training_acc": 59.0, "val_loss": 841.1615371704102, "val_acc": 52.0}
{"epoch": 64, "training_loss": 3419.219504583918, "training_acc": 51.0, "val_loss": 1764.5124435424805, "val_acc": 48.0}
{"epoch": 65, "training_loss": 7129.424011230469, "training_acc": 45.0, "val_loss": 1474.9926567077637, "val_acc": 48.0}
{"epoch": 66, "training_loss": 16542.398559570312, "training_acc": 45.0, "val_loss": 2462.8395080566406, "val_acc": 48.0}
{"epoch": 67, "training_loss": 8656.367736816406, "training_acc": 47.0, "val_loss": 6885.569000244141, "val_acc": 52.0}
{"epoch": 68, "training_loss": 15918.620849609375, "training_acc": 60.0, "val_loss": 8495.472717285156, "val_acc": 48.0}
{"epoch": 69, "training_loss": 18560.351684570312, "training_acc": 51.0, "val_loss": 14879.707336425781, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69690.81982421875, "training_acc": 53.0, "val_loss": 8388.548278808594, "val_acc": 52.0}
{"epoch": 71, "training_loss": 20856.148986816406, "training_acc": 47.0, "val_loss": 4853.347396850586, "val_acc": 48.0}
{"epoch": 72, "training_loss": 8515.228641923517, "training_acc": 55.0, "val_loss": 1557.8371047973633, "val_acc": 48.0}
{"epoch": 73, "training_loss": 4381.630767822266, "training_acc": 53.0, "val_loss": 321.3237762451172, "val_acc": 48.0}
{"epoch": 74, "training_loss": 3662.7875366210938, "training_acc": 53.0, "val_loss": 2986.3197326660156, "val_acc": 48.0}
{"epoch": 75, "training_loss": 8808.528076171875, "training_acc": 53.0, "val_loss": 6481.2713623046875, "val_acc": 52.0}
{"epoch": 76, "training_loss": 15436.110290527344, "training_acc": 56.0, "val_loss": 8159.601593017578, "val_acc": 48.0}
