"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 70.0357437133789, "training_acc": 47.0, "val_loss": 17.303530871868134, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.34127187728882, "training_acc": 50.0, "val_loss": 17.298991978168488, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1127450466156, "training_acc": 53.0, "val_loss": 17.336152493953705, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.22784328460693, "training_acc": 53.0, "val_loss": 17.357787489891052, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27033948898315, "training_acc": 53.0, "val_loss": 17.32967346906662, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.19678401947021, "training_acc": 53.0, "val_loss": 17.304755747318268, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1560730934143, "training_acc": 53.0, "val_loss": 17.288310825824738, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13260078430176, "training_acc": 53.0, "val_loss": 17.2883540391922, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13662934303284, "training_acc": 53.0, "val_loss": 17.289365828037262, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.10531640052795, "training_acc": 53.0, "val_loss": 17.298242449760437, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.23971271514893, "training_acc": 49.0, "val_loss": 17.3105850815773, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.24958682060242, "training_acc": 51.0, "val_loss": 17.292514443397522, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.112863779068, "training_acc": 53.0, "val_loss": 17.287765443325043, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.1170015335083, "training_acc": 53.0, "val_loss": 17.288924753665924, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.10016250610352, "training_acc": 53.0, "val_loss": 17.29239672422409, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.11939764022827, "training_acc": 53.0, "val_loss": 17.29906052350998, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.08344793319702, "training_acc": 53.0, "val_loss": 17.313838005065918, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10756516456604, "training_acc": 53.0, "val_loss": 17.32151061296463, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.20931673049927, "training_acc": 53.0, "val_loss": 17.334918677806854, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.19070243835449, "training_acc": 53.0, "val_loss": 17.326490581035614, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.14678287506104, "training_acc": 53.0, "val_loss": 17.2970250248909, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.27462124824524, "training_acc": 53.0, "val_loss": 17.28692799806595, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18172860145569, "training_acc": 53.0, "val_loss": 17.29079633951187, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16456651687622, "training_acc": 53.0, "val_loss": 17.299029231071472, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12872409820557, "training_acc": 53.0, "val_loss": 17.292432487010956, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.10891270637512, "training_acc": 53.0, "val_loss": 17.301739752292633, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17508912086487, "training_acc": 53.0, "val_loss": 17.32754111289978, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.20288133621216, "training_acc": 53.0, "val_loss": 17.361648380756378, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.29582071304321, "training_acc": 53.0, "val_loss": 17.366206645965576, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.27761793136597, "training_acc": 53.0, "val_loss": 17.38027185201645, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.40069079399109, "training_acc": 53.0, "val_loss": 17.37934499979019, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.24643015861511, "training_acc": 53.0, "val_loss": 17.314346134662628, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1413369178772, "training_acc": 53.0, "val_loss": 17.299363017082214, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.04676413536072, "training_acc": 53.0, "val_loss": 17.294907569885254, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.10117745399475, "training_acc": 53.0, "val_loss": 17.285913228988647, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1137900352478, "training_acc": 53.0, "val_loss": 17.28539764881134, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.03092908859253, "training_acc": 53.0, "val_loss": 17.29564666748047, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13113951683044, "training_acc": 53.0, "val_loss": 17.335838079452515, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15778303146362, "training_acc": 53.0, "val_loss": 17.391331493854523, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.43812274932861, "training_acc": 53.0, "val_loss": 17.442691326141357, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.50717067718506, "training_acc": 53.0, "val_loss": 17.442093789577484, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.52292823791504, "training_acc": 53.0, "val_loss": 17.422404885292053, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.40260100364685, "training_acc": 53.0, "val_loss": 17.388316988945007, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.25821733474731, "training_acc": 53.0, "val_loss": 17.33376681804657, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.0445032119751, "training_acc": 53.0, "val_loss": 17.288772761821747, "val_acc": 52.0}
{"epoch": 45, "training_loss": 68.98207569122314, "training_acc": 53.0, "val_loss": 17.28767305612564, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.16122341156006, "training_acc": 53.0, "val_loss": 17.313575744628906, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.26435327529907, "training_acc": 49.0, "val_loss": 17.319907248020172, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.29772448539734, "training_acc": 48.0, "val_loss": 17.335034906864166, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.53467679023743, "training_acc": 47.0, "val_loss": 17.36833155155182, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.49948263168335, "training_acc": 47.0, "val_loss": 17.32826977968216, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.39564561843872, "training_acc": 48.0, "val_loss": 17.30429232120514, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.09281349182129, "training_acc": 54.0, "val_loss": 17.285272479057312, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.01873302459717, "training_acc": 53.0, "val_loss": 17.297326028347015, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.09827327728271, "training_acc": 53.0, "val_loss": 17.337583005428314, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.13192653656006, "training_acc": 53.0, "val_loss": 17.338386178016663, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.18885707855225, "training_acc": 53.0, "val_loss": 17.332889139652252, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.18421649932861, "training_acc": 53.0, "val_loss": 17.334292829036713, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.15733194351196, "training_acc": 53.0, "val_loss": 17.32201725244522, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.08091402053833, "training_acc": 53.0, "val_loss": 17.302636802196503, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.23140621185303, "training_acc": 53.0, "val_loss": 17.291635274887085, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.08875513076782, "training_acc": 53.0, "val_loss": 17.314288020133972, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.12788152694702, "training_acc": 53.0, "val_loss": 17.35810488462448, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.41874837875366, "training_acc": 53.0, "val_loss": 17.443549633026123, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.53733825683594, "training_acc": 53.0, "val_loss": 17.45431423187256, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.49611020088196, "training_acc": 53.0, "val_loss": 17.4136221408844, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.34602975845337, "training_acc": 53.0, "val_loss": 17.369502782821655, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.27789449691772, "training_acc": 53.0, "val_loss": 17.361144721508026, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.253977060318, "training_acc": 53.0, "val_loss": 17.359481751918793, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.24211072921753, "training_acc": 53.0, "val_loss": 17.360922694206238, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.27303671836853, "training_acc": 53.0, "val_loss": 17.373527586460114, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.27413153648376, "training_acc": 53.0, "val_loss": 17.364436388015747, "val_acc": 52.0}
