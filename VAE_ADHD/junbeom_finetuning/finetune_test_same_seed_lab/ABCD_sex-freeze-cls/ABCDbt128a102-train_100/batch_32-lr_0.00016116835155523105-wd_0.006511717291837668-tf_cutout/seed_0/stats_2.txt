"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.27897548675537, "training_acc": 53.0, "val_loss": 17.307208478450775, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.3192720413208, "training_acc": 53.0, "val_loss": 17.33871102333069, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.39674949645996, "training_acc": 53.0, "val_loss": 17.324206233024597, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1853985786438, "training_acc": 53.0, "val_loss": 17.33829230070114, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.23950099945068, "training_acc": 53.0, "val_loss": 17.340266704559326, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.24198961257935, "training_acc": 53.0, "val_loss": 17.335695028305054, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.27885913848877, "training_acc": 53.0, "val_loss": 17.31732487678528, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.17158913612366, "training_acc": 53.0, "val_loss": 17.31204390525818, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10118675231934, "training_acc": 53.0, "val_loss": 17.305287718772888, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18381118774414, "training_acc": 53.0, "val_loss": 17.304280400276184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.20268511772156, "training_acc": 53.0, "val_loss": 17.304310202598572, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21612191200256, "training_acc": 53.0, "val_loss": 17.304441332817078, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19461607933044, "training_acc": 53.0, "val_loss": 17.30426400899887, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.17735385894775, "training_acc": 53.0, "val_loss": 17.30615794658661, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.1476321220398, "training_acc": 53.0, "val_loss": 17.30930358171463, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18323302268982, "training_acc": 53.0, "val_loss": 17.313414812088013, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18238830566406, "training_acc": 53.0, "val_loss": 17.32771247625351, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.2048089504242, "training_acc": 53.0, "val_loss": 17.338374257087708, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14475727081299, "training_acc": 53.0, "val_loss": 17.37292855978012, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.29883003234863, "training_acc": 53.0, "val_loss": 17.392200231552124, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.34377598762512, "training_acc": 53.0, "val_loss": 17.378588020801544, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.34802889823914, "training_acc": 53.0, "val_loss": 17.332638800144196, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.21755409240723, "training_acc": 53.0, "val_loss": 17.31416881084442, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17273354530334, "training_acc": 53.0, "val_loss": 17.31019914150238, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17060780525208, "training_acc": 53.0, "val_loss": 17.30809211730957, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16255211830139, "training_acc": 53.0, "val_loss": 17.30438321828842, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.32763290405273, "training_acc": 53.0, "val_loss": 17.310985922813416, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.23646593093872, "training_acc": 53.0, "val_loss": 17.309841513633728, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.24695825576782, "training_acc": 53.0, "val_loss": 17.30635017156601, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.21568298339844, "training_acc": 53.0, "val_loss": 17.30443388223648, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.12447547912598, "training_acc": 53.0, "val_loss": 17.31284260749817, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.10980129241943, "training_acc": 53.0, "val_loss": 17.33114719390869, "val_acc": 52.0}
