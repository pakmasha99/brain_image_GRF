"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.23651504516602, "training_acc": 53.0, "val_loss": 17.33965277671814, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.21015310287476, "training_acc": 53.0, "val_loss": 17.341133952140808, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.18358325958252, "training_acc": 53.0, "val_loss": 17.340847849845886, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.18970370292664, "training_acc": 53.0, "val_loss": 17.338591814041138, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.18872213363647, "training_acc": 53.0, "val_loss": 17.336955666542053, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.13989496231079, "training_acc": 53.0, "val_loss": 17.335128784179688, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.17217016220093, "training_acc": 53.0, "val_loss": 17.335955798625946, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.15785503387451, "training_acc": 53.0, "val_loss": 17.336589097976685, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.15136623382568, "training_acc": 53.0, "val_loss": 17.336364090442657, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.18879556655884, "training_acc": 53.0, "val_loss": 17.337295413017273, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.16587495803833, "training_acc": 53.0, "val_loss": 17.3379048705101, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.15161871910095, "training_acc": 53.0, "val_loss": 17.336055636405945, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.16655468940735, "training_acc": 53.0, "val_loss": 17.333951592445374, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.13358902931213, "training_acc": 53.0, "val_loss": 17.33202636241913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15926027297974, "training_acc": 53.0, "val_loss": 17.330402135849, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18178081512451, "training_acc": 53.0, "val_loss": 17.328399419784546, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.20581769943237, "training_acc": 53.0, "val_loss": 17.32754409313202, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.16215801239014, "training_acc": 53.0, "val_loss": 17.326602339744568, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2126305103302, "training_acc": 53.0, "val_loss": 17.325782775878906, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.16136574745178, "training_acc": 53.0, "val_loss": 17.325225472450256, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16706204414368, "training_acc": 53.0, "val_loss": 17.32497811317444, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.137131690979, "training_acc": 53.0, "val_loss": 17.325137555599213, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.15682888031006, "training_acc": 53.0, "val_loss": 17.325320839881897, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.13829231262207, "training_acc": 53.0, "val_loss": 17.32477843761444, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17077922821045, "training_acc": 53.0, "val_loss": 17.324340343475342, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1694393157959, "training_acc": 53.0, "val_loss": 17.32405573129654, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.16547322273254, "training_acc": 53.0, "val_loss": 17.323806881904602, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.18744969367981, "training_acc": 53.0, "val_loss": 17.323704063892365, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.13086104393005, "training_acc": 53.0, "val_loss": 17.323748767375946, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.16632771492004, "training_acc": 53.0, "val_loss": 17.323917150497437, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.17589092254639, "training_acc": 53.0, "val_loss": 17.32424646615982, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.18592262268066, "training_acc": 53.0, "val_loss": 17.324259877204895, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16591930389404, "training_acc": 53.0, "val_loss": 17.32405126094818, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.18917465209961, "training_acc": 53.0, "val_loss": 17.323780059814453, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.15776777267456, "training_acc": 53.0, "val_loss": 17.323581874370575, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.1584985256195, "training_acc": 53.0, "val_loss": 17.323529720306396, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.14419150352478, "training_acc": 53.0, "val_loss": 17.32354313135147, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.1830940246582, "training_acc": 53.0, "val_loss": 17.323599755764008, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.20007848739624, "training_acc": 53.0, "val_loss": 17.323555052280426, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.20879769325256, "training_acc": 53.0, "val_loss": 17.32354313135147, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.19561767578125, "training_acc": 53.0, "val_loss": 17.323651909828186, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.17874455451965, "training_acc": 53.0, "val_loss": 17.32383668422699, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.13127732276917, "training_acc": 53.0, "val_loss": 17.324167490005493, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.19955968856812, "training_acc": 53.0, "val_loss": 17.32497811317444, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.20630550384521, "training_acc": 53.0, "val_loss": 17.326320707798004, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.14593267440796, "training_acc": 53.0, "val_loss": 17.327506840229034, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.19273662567139, "training_acc": 53.0, "val_loss": 17.328761518001556, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.17067050933838, "training_acc": 53.0, "val_loss": 17.32872873544693, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.14636087417603, "training_acc": 53.0, "val_loss": 17.32763946056366, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.17758321762085, "training_acc": 53.0, "val_loss": 17.327137291431427, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.16609239578247, "training_acc": 53.0, "val_loss": 17.32724756002426, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.1554524898529, "training_acc": 53.0, "val_loss": 17.327876389026642, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.12660646438599, "training_acc": 53.0, "val_loss": 17.32855886220932, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.15916538238525, "training_acc": 53.0, "val_loss": 17.328429222106934, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.16432642936707, "training_acc": 53.0, "val_loss": 17.328619956970215, "val_acc": 52.0}
