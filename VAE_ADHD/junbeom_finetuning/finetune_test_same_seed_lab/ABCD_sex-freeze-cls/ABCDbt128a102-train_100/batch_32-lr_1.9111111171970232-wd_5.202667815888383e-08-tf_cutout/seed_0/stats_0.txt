"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 5764.992042541504, "training_acc": 51.0, "val_loss": 1733.0617904663086, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3760.757080078125, "training_acc": 64.0, "val_loss": 1868.6588287353516, "val_acc": 48.0}
{"epoch": 2, "training_loss": 7631.97444152832, "training_acc": 63.0, "val_loss": 3786.724090576172, "val_acc": 68.0}
{"epoch": 3, "training_loss": 12400.553283691406, "training_acc": 60.0, "val_loss": 2581.97021484375, "val_acc": 60.0}
{"epoch": 4, "training_loss": 6557.946228027344, "training_acc": 65.0, "val_loss": 2862.0519638061523, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4569.241516113281, "training_acc": 61.0, "val_loss": 3788.041305541992, "val_acc": 40.0}
{"epoch": 6, "training_loss": 4045.162841796875, "training_acc": 68.0, "val_loss": 3590.211868286133, "val_acc": 32.0}
{"epoch": 7, "training_loss": 5490.64501953125, "training_acc": 62.0, "val_loss": 4150.769424438477, "val_acc": 36.0}
{"epoch": 8, "training_loss": 4749.140686035156, "training_acc": 68.0, "val_loss": 4929.129409790039, "val_acc": 48.0}
{"epoch": 9, "training_loss": 3580.9765625, "training_acc": 71.0, "val_loss": 5225.575256347656, "val_acc": 32.0}
{"epoch": 10, "training_loss": 8616.44580078125, "training_acc": 64.0, "val_loss": 5444.215393066406, "val_acc": 16.0}
{"epoch": 11, "training_loss": 3520.5335693359375, "training_acc": 75.0, "val_loss": 5696.211624145508, "val_acc": 32.0}
{"epoch": 12, "training_loss": 5643.363311767578, "training_acc": 64.0, "val_loss": 4810.664367675781, "val_acc": 32.0}
{"epoch": 13, "training_loss": 4100.2220458984375, "training_acc": 67.0, "val_loss": 4257.568359375, "val_acc": 36.0}
{"epoch": 14, "training_loss": 3351.676727294922, "training_acc": 71.0, "val_loss": 4719.46907043457, "val_acc": 52.0}
{"epoch": 15, "training_loss": 5756.60546875, "training_acc": 69.0, "val_loss": 5094.114303588867, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3366.702606201172, "training_acc": 73.0, "val_loss": 4284.006118774414, "val_acc": 36.0}
{"epoch": 17, "training_loss": 2838.765655517578, "training_acc": 73.0, "val_loss": 4307.332992553711, "val_acc": 40.0}
{"epoch": 18, "training_loss": 2240.8168182373047, "training_acc": 76.0, "val_loss": 4466.5863037109375, "val_acc": 44.0}
{"epoch": 19, "training_loss": 3323.5023193359375, "training_acc": 75.0, "val_loss": 4549.949645996094, "val_acc": 40.0}
