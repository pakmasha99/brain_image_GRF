"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 46559.76778793335, "training_acc": 53.0, "val_loss": 21124.148559570312, "val_acc": 48.0}
{"epoch": 1, "training_loss": 53563.02520751953, "training_acc": 49.0, "val_loss": 22097.718811035156, "val_acc": 52.0}
{"epoch": 2, "training_loss": 84761.17236328125, "training_acc": 53.0, "val_loss": 4226.963424682617, "val_acc": 52.0}
{"epoch": 3, "training_loss": 44591.172607421875, "training_acc": 51.0, "val_loss": 18830.636596679688, "val_acc": 48.0}
{"epoch": 4, "training_loss": 50798.867919921875, "training_acc": 45.0, "val_loss": 13634.584045410156, "val_acc": 52.0}
{"epoch": 5, "training_loss": 52056.74572753906, "training_acc": 53.0, "val_loss": 1007.2380065917969, "val_acc": 52.0}
{"epoch": 6, "training_loss": 30683.742919921875, "training_acc": 49.0, "val_loss": 10200.837707519531, "val_acc": 48.0}
{"epoch": 7, "training_loss": 28862.1435546875, "training_acc": 45.0, "val_loss": 9770.16372680664, "val_acc": 52.0}
{"epoch": 8, "training_loss": 22535.79946899414, "training_acc": 55.0, "val_loss": 11882.808685302734, "val_acc": 48.0}
{"epoch": 9, "training_loss": 47648.436279296875, "training_acc": 47.0, "val_loss": 3135.651206970215, "val_acc": 52.0}
{"epoch": 10, "training_loss": 31059.13427734375, "training_acc": 53.0, "val_loss": 7605.38330078125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 23690.477783203125, "training_acc": 47.0, "val_loss": 11661.981964111328, "val_acc": 48.0}
{"epoch": 12, "training_loss": 31791.967834472656, "training_acc": 47.0, "val_loss": 8159.395599365234, "val_acc": 52.0}
{"epoch": 13, "training_loss": 31207.07733154297, "training_acc": 53.0, "val_loss": 3755.7743072509766, "val_acc": 48.0}
{"epoch": 14, "training_loss": 21388.234252929688, "training_acc": 47.0, "val_loss": 4854.380798339844, "val_acc": 52.0}
{"epoch": 15, "training_loss": 29460.048583984375, "training_acc": 53.0, "val_loss": 2624.234390258789, "val_acc": 52.0}
{"epoch": 16, "training_loss": 23344.77197265625, "training_acc": 45.0, "val_loss": 3772.884750366211, "val_acc": 48.0}
{"epoch": 17, "training_loss": 16916.110595703125, "training_acc": 53.0, "val_loss": 4512.312316894531, "val_acc": 52.0}
{"epoch": 18, "training_loss": 7793.1744384765625, "training_acc": 47.0, "val_loss": 1811.008071899414, "val_acc": 48.0}
{"epoch": 19, "training_loss": 7690.924987792969, "training_acc": 49.0, "val_loss": 1536.2263679504395, "val_acc": 52.0}
{"epoch": 20, "training_loss": 18485.255920410156, "training_acc": 41.0, "val_loss": 2015.9753799438477, "val_acc": 52.0}
{"epoch": 21, "training_loss": 18128.67660522461, "training_acc": 53.0, "val_loss": 1799.9340057373047, "val_acc": 48.0}
{"epoch": 22, "training_loss": 5184.022584915161, "training_acc": 51.0, "val_loss": 320.7502603530884, "val_acc": 48.0}
{"epoch": 23, "training_loss": 6056.9210205078125, "training_acc": 49.0, "val_loss": 305.2837371826172, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2604.567371368408, "training_acc": 55.0, "val_loss": 2403.0345916748047, "val_acc": 48.0}
{"epoch": 25, "training_loss": 8363.435150146484, "training_acc": 49.0, "val_loss": 2178.8354873657227, "val_acc": 52.0}
{"epoch": 26, "training_loss": 5649.76904296875, "training_acc": 51.0, "val_loss": 1495.653247833252, "val_acc": 52.0}
{"epoch": 27, "training_loss": 6175.676223754883, "training_acc": 49.0, "val_loss": 3295.286178588867, "val_acc": 52.0}
{"epoch": 28, "training_loss": 11546.558715820312, "training_acc": 45.0, "val_loss": 602.6557445526123, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3246.233465194702, "training_acc": 58.0, "val_loss": 1729.4624328613281, "val_acc": 48.0}
{"epoch": 30, "training_loss": 6822.806922912598, "training_acc": 56.0, "val_loss": 1343.461513519287, "val_acc": 52.0}
{"epoch": 31, "training_loss": 11051.653137207031, "training_acc": 47.0, "val_loss": 5083.549880981445, "val_acc": 52.0}
{"epoch": 32, "training_loss": 26439.55126953125, "training_acc": 53.0, "val_loss": 1235.617446899414, "val_acc": 48.0}
{"epoch": 33, "training_loss": 12350.455955505371, "training_acc": 47.0, "val_loss": 5830.580902099609, "val_acc": 52.0}
{"epoch": 34, "training_loss": 28632.2216796875, "training_acc": 53.0, "val_loss": 1736.941146850586, "val_acc": 52.0}
{"epoch": 35, "training_loss": 15524.937255859375, "training_acc": 49.0, "val_loss": 1394.903564453125, "val_acc": 52.0}
{"epoch": 36, "training_loss": 10627.208724021912, "training_acc": 52.0, "val_loss": 562.7223968505859, "val_acc": 48.0}
{"epoch": 37, "training_loss": 4624.0897216796875, "training_acc": 53.0, "val_loss": 254.23316955566406, "val_acc": 52.0}
{"epoch": 38, "training_loss": 10077.314804077148, "training_acc": 53.0, "val_loss": 3884.3666076660156, "val_acc": 48.0}
{"epoch": 39, "training_loss": 16311.317054748535, "training_acc": 49.0, "val_loss": 3850.826644897461, "val_acc": 52.0}
{"epoch": 40, "training_loss": 10577.81860923767, "training_acc": 42.0, "val_loss": 1873.7371444702148, "val_acc": 52.0}
{"epoch": 41, "training_loss": 5748.119537353516, "training_acc": 57.0, "val_loss": 1015.8987998962402, "val_acc": 52.0}
{"epoch": 42, "training_loss": 4581.582164764404, "training_acc": 55.0, "val_loss": 1130.6303024291992, "val_acc": 52.0}
{"epoch": 43, "training_loss": 5160.485305786133, "training_acc": 57.0, "val_loss": 178.88823747634888, "val_acc": 52.0}
{"epoch": 44, "training_loss": 2110.111005783081, "training_acc": 64.0, "val_loss": 785.6252193450928, "val_acc": 52.0}
{"epoch": 45, "training_loss": 2541.459114074707, "training_acc": 53.0, "val_loss": 2437.5890731811523, "val_acc": 52.0}
{"epoch": 46, "training_loss": 6789.356823921204, "training_acc": 48.0, "val_loss": 2456.5176010131836, "val_acc": 48.0}
{"epoch": 47, "training_loss": 12744.764404296875, "training_acc": 37.0, "val_loss": 188.98128271102905, "val_acc": 52.0}
{"epoch": 48, "training_loss": 10165.977081298828, "training_acc": 54.0, "val_loss": 7537.602233886719, "val_acc": 52.0}
{"epoch": 49, "training_loss": 43030.5361328125, "training_acc": 53.0, "val_loss": 7030.944061279297, "val_acc": 52.0}
{"epoch": 50, "training_loss": 16992.725982666016, "training_acc": 58.0, "val_loss": 6720.30029296875, "val_acc": 48.0}
{"epoch": 51, "training_loss": 14522.636840820312, "training_acc": 59.0, "val_loss": 11057.16552734375, "val_acc": 52.0}
{"epoch": 52, "training_loss": 35843.18997192383, "training_acc": 53.0, "val_loss": 6818.192291259766, "val_acc": 48.0}
{"epoch": 53, "training_loss": 36544.17855834961, "training_acc": 47.0, "val_loss": 479.79493141174316, "val_acc": 48.0}
{"epoch": 54, "training_loss": 26373.820373535156, "training_acc": 49.0, "val_loss": 9533.536529541016, "val_acc": 52.0}
{"epoch": 55, "training_loss": 18923.810546875, "training_acc": 55.0, "val_loss": 3841.5653228759766, "val_acc": 48.0}
{"epoch": 56, "training_loss": 9879.980155944824, "training_acc": 49.0, "val_loss": 4245.357513427734, "val_acc": 48.0}
{"epoch": 57, "training_loss": 16825.192993164062, "training_acc": 47.0, "val_loss": 4643.522262573242, "val_acc": 52.0}
{"epoch": 58, "training_loss": 10044.428405761719, "training_acc": 53.0, "val_loss": 1259.270191192627, "val_acc": 52.0}
{"epoch": 59, "training_loss": 3005.6017150878906, "training_acc": 50.0, "val_loss": 3715.948486328125, "val_acc": 52.0}
{"epoch": 60, "training_loss": 14942.35033416748, "training_acc": 51.0, "val_loss": 122.10801839828491, "val_acc": 48.0}
{"epoch": 61, "training_loss": 1890.464207649231, "training_acc": 59.0, "val_loss": 2060.724639892578, "val_acc": 52.0}
{"epoch": 62, "training_loss": 5650.769226074219, "training_acc": 57.0, "val_loss": 1134.571647644043, "val_acc": 52.0}
{"epoch": 63, "training_loss": 6353.2659912109375, "training_acc": 47.0, "val_loss": 1517.4365043640137, "val_acc": 52.0}
{"epoch": 64, "training_loss": 5090.747501373291, "training_acc": 50.0, "val_loss": 769.1131591796875, "val_acc": 48.0}
{"epoch": 65, "training_loss": 6198.623474121094, "training_acc": 45.0, "val_loss": 548.6082553863525, "val_acc": 48.0}
{"epoch": 66, "training_loss": 17536.881072998047, "training_acc": 41.0, "val_loss": 890.3499603271484, "val_acc": 52.0}
{"epoch": 67, "training_loss": 17128.54150390625, "training_acc": 49.0, "val_loss": 219.7322130203247, "val_acc": 52.0}
{"epoch": 68, "training_loss": 17051.296012878418, "training_acc": 61.0, "val_loss": 7186.949920654297, "val_acc": 52.0}
{"epoch": 69, "training_loss": 16636.7685546875, "training_acc": 53.0, "val_loss": 5074.733352661133, "val_acc": 48.0}
{"epoch": 70, "training_loss": 15924.081787109375, "training_acc": 49.0, "val_loss": 9222.47085571289, "val_acc": 52.0}
{"epoch": 71, "training_loss": 26445.149169921875, "training_acc": 49.0, "val_loss": 3737.7246856689453, "val_acc": 48.0}
{"epoch": 72, "training_loss": 12488.56884765625, "training_acc": 49.0, "val_loss": 4253.132629394531, "val_acc": 52.0}
{"epoch": 73, "training_loss": 9556.002484436365, "training_acc": 50.0, "val_loss": 1678.9108276367188, "val_acc": 52.0}
{"epoch": 74, "training_loss": 8445.524597167969, "training_acc": 47.0, "val_loss": 1907.798957824707, "val_acc": 48.0}
{"epoch": 75, "training_loss": 16217.198181152344, "training_acc": 43.0, "val_loss": 303.4593343734741, "val_acc": 52.0}
{"epoch": 76, "training_loss": 19163.847290039062, "training_acc": 49.0, "val_loss": 4298.102951049805, "val_acc": 48.0}
{"epoch": 77, "training_loss": 11853.032592773438, "training_acc": 53.0, "val_loss": 4481.570816040039, "val_acc": 52.0}
{"epoch": 78, "training_loss": 10836.08219909668, "training_acc": 43.0, "val_loss": 565.1544570922852, "val_acc": 52.0}
{"epoch": 79, "training_loss": 4198.636932373047, "training_acc": 49.0, "val_loss": 5277.24494934082, "val_acc": 52.0}
