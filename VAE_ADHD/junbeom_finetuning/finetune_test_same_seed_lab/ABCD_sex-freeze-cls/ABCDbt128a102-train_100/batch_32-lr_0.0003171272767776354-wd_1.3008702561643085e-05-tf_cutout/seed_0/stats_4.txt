"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 69.60101532936096, "training_acc": 41.0, "val_loss": 17.28055030107498, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.56796836853027, "training_acc": 53.0, "val_loss": 17.296671867370605, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1549003124237, "training_acc": 53.0, "val_loss": 17.279992997646332, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.13518333435059, "training_acc": 53.0, "val_loss": 17.30577051639557, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.13078188896179, "training_acc": 53.0, "val_loss": 17.31848269701004, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.20283770561218, "training_acc": 53.0, "val_loss": 17.301036417484283, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.13129949569702, "training_acc": 53.0, "val_loss": 17.28697568178177, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.13427972793579, "training_acc": 53.0, "val_loss": 17.284423112869263, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.1564519405365, "training_acc": 53.0, "val_loss": 17.29799658060074, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.10874557495117, "training_acc": 53.0, "val_loss": 17.304280400276184, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.12702131271362, "training_acc": 53.0, "val_loss": 17.328208684921265, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.21922135353088, "training_acc": 53.0, "val_loss": 17.309381067752838, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.04881000518799, "training_acc": 53.0, "val_loss": 17.277199029922485, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.47845697402954, "training_acc": 46.0, "val_loss": 17.295975983142853, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.38966608047485, "training_acc": 46.0, "val_loss": 17.27827936410904, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.26263070106506, "training_acc": 53.0, "val_loss": 17.313838005065918, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.17402696609497, "training_acc": 53.0, "val_loss": 17.296220362186432, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.12512731552124, "training_acc": 53.0, "val_loss": 17.324399948120117, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23982858657837, "training_acc": 53.0, "val_loss": 17.386528849601746, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.49996709823608, "training_acc": 53.0, "val_loss": 17.43604689836502, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.47313189506531, "training_acc": 53.0, "val_loss": 17.383429408073425, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.32933020591736, "training_acc": 53.0, "val_loss": 17.367492616176605, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.41679215431213, "training_acc": 53.0, "val_loss": 17.340782284736633, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1545135974884, "training_acc": 53.0, "val_loss": 17.274945974349976, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.09273767471313, "training_acc": 53.0, "val_loss": 17.278476059436798, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.09290981292725, "training_acc": 53.0, "val_loss": 17.274467647075653, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.1194372177124, "training_acc": 53.0, "val_loss": 17.277492582798004, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1382827758789, "training_acc": 53.0, "val_loss": 17.274104058742523, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.00723791122437, "training_acc": 53.0, "val_loss": 17.335502803325653, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.36256551742554, "training_acc": 53.0, "val_loss": 17.50149130821228, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.72104692459106, "training_acc": 53.0, "val_loss": 17.62092411518097, "val_acc": 52.0}
{"epoch": 31, "training_loss": 70.26273226737976, "training_acc": 53.0, "val_loss": 17.623642086982727, "val_acc": 52.0}
{"epoch": 32, "training_loss": 70.01031398773193, "training_acc": 53.0, "val_loss": 17.4714595079422, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.63857412338257, "training_acc": 53.0, "val_loss": 17.355486750602722, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.12953329086304, "training_acc": 53.0, "val_loss": 17.294391989707947, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.89075231552124, "training_acc": 53.0, "val_loss": 17.273230850696564, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.07071852684021, "training_acc": 54.0, "val_loss": 17.325706779956818, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.37242436408997, "training_acc": 47.0, "val_loss": 17.361894249916077, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.67706871032715, "training_acc": 47.0, "val_loss": 17.38622486591339, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.51998949050903, "training_acc": 47.0, "val_loss": 17.310672998428345, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.4416229724884, "training_acc": 43.0, "val_loss": 17.29484498500824, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.36290454864502, "training_acc": 48.0, "val_loss": 17.32179820537567, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.26908588409424, "training_acc": 50.0, "val_loss": 17.27534979581833, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.08414363861084, "training_acc": 53.0, "val_loss": 17.273232340812683, "val_acc": 52.0}
{"epoch": 44, "training_loss": 68.82849454879761, "training_acc": 53.0, "val_loss": 17.300498485565186, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.05948901176453, "training_acc": 53.0, "val_loss": 17.391736805438995, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.43610692024231, "training_acc": 53.0, "val_loss": 17.45932698249817, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.42978072166443, "training_acc": 53.0, "val_loss": 17.35578179359436, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.0778865814209, "training_acc": 53.0, "val_loss": 17.295856773853302, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.04568862915039, "training_acc": 53.0, "val_loss": 17.283163964748383, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.04409575462341, "training_acc": 53.0, "val_loss": 17.273589968681335, "val_acc": 52.0}
{"epoch": 51, "training_loss": 68.9710853099823, "training_acc": 53.0, "val_loss": 17.270635068416595, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.31988835334778, "training_acc": 53.0, "val_loss": 17.2711119055748, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.0864474773407, "training_acc": 53.0, "val_loss": 17.318180203437805, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.09071493148804, "training_acc": 53.0, "val_loss": 17.47596710920334, "val_acc": 52.0}
{"epoch": 55, "training_loss": 70.14116668701172, "training_acc": 53.0, "val_loss": 17.726267874240875, "val_acc": 52.0}
{"epoch": 56, "training_loss": 70.52718782424927, "training_acc": 53.0, "val_loss": 17.643751204013824, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.99679398536682, "training_acc": 53.0, "val_loss": 17.42825210094452, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.2597861289978, "training_acc": 53.0, "val_loss": 17.303943634033203, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.0081615447998, "training_acc": 53.0, "val_loss": 17.28723496198654, "val_acc": 52.0}
{"epoch": 60, "training_loss": 68.99504661560059, "training_acc": 53.0, "val_loss": 17.293544113636017, "val_acc": 52.0}
{"epoch": 61, "training_loss": 68.98624062538147, "training_acc": 53.0, "val_loss": 17.315974831581116, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.09949731826782, "training_acc": 53.0, "val_loss": 17.366783320903778, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.18372535705566, "training_acc": 53.0, "val_loss": 17.36886352300644, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.38946413993835, "training_acc": 53.0, "val_loss": 17.42297112941742, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.46658134460449, "training_acc": 53.0, "val_loss": 17.46577024459839, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.43865966796875, "training_acc": 53.0, "val_loss": 17.321398854255676, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.09672689437866, "training_acc": 53.0, "val_loss": 17.274631559848785, "val_acc": 52.0}
{"epoch": 68, "training_loss": 68.9392740726471, "training_acc": 61.0, "val_loss": 17.33963191509247, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.4550108909607, "training_acc": 47.0, "val_loss": 17.36549735069275, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.7717113494873, "training_acc": 47.0, "val_loss": 17.43784248828888, "val_acc": 52.0}
