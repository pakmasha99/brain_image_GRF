"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 72.64219522476196, "training_acc": 48.0, "val_loss": 18.429775536060333, "val_acc": 52.0}
{"epoch": 1, "training_loss": 67.88380146026611, "training_acc": 59.0, "val_loss": 18.45952570438385, "val_acc": 52.0}
{"epoch": 2, "training_loss": 65.57674157619476, "training_acc": 61.0, "val_loss": 18.49673241376877, "val_acc": 52.0}
{"epoch": 3, "training_loss": 63.30392074584961, "training_acc": 64.0, "val_loss": 18.608075380325317, "val_acc": 56.0}
{"epoch": 4, "training_loss": 62.08193635940552, "training_acc": 63.0, "val_loss": 18.753094971179962, "val_acc": 56.0}
{"epoch": 5, "training_loss": 61.22516202926636, "training_acc": 66.0, "val_loss": 18.81481111049652, "val_acc": 56.0}
{"epoch": 6, "training_loss": 60.68016958236694, "training_acc": 64.0, "val_loss": 19.009509682655334, "val_acc": 52.0}
{"epoch": 7, "training_loss": 59.56780815124512, "training_acc": 71.0, "val_loss": 19.10446137189865, "val_acc": 52.0}
{"epoch": 8, "training_loss": 58.95380926132202, "training_acc": 73.0, "val_loss": 19.18542832136154, "val_acc": 52.0}
{"epoch": 9, "training_loss": 57.89958429336548, "training_acc": 73.0, "val_loss": 19.473211467266083, "val_acc": 48.0}
{"epoch": 10, "training_loss": 58.15205717086792, "training_acc": 70.0, "val_loss": 19.695213437080383, "val_acc": 48.0}
{"epoch": 11, "training_loss": 56.23698353767395, "training_acc": 71.0, "val_loss": 19.95433419942856, "val_acc": 48.0}
{"epoch": 12, "training_loss": 56.393999099731445, "training_acc": 68.0, "val_loss": 20.11876255273819, "val_acc": 48.0}
{"epoch": 13, "training_loss": 56.02653884887695, "training_acc": 70.0, "val_loss": 20.227953791618347, "val_acc": 52.0}
{"epoch": 14, "training_loss": 55.32920289039612, "training_acc": 73.0, "val_loss": 20.421189069747925, "val_acc": 56.0}
{"epoch": 15, "training_loss": 55.78248405456543, "training_acc": 73.0, "val_loss": 20.48298567533493, "val_acc": 56.0}
{"epoch": 16, "training_loss": 54.72541689872742, "training_acc": 73.0, "val_loss": 20.57812511920929, "val_acc": 56.0}
{"epoch": 17, "training_loss": 53.7559210062027, "training_acc": 76.0, "val_loss": 20.72925567626953, "val_acc": 48.0}
{"epoch": 18, "training_loss": 53.856045722961426, "training_acc": 75.0, "val_loss": 20.893405377864838, "val_acc": 52.0}
{"epoch": 19, "training_loss": 53.59535264968872, "training_acc": 75.0, "val_loss": 21.106979250907898, "val_acc": 48.0}
