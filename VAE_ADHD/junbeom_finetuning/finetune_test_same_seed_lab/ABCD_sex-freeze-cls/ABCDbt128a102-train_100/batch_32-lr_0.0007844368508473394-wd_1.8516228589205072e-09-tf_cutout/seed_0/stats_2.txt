"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 68.52958965301514, "training_acc": 54.0, "val_loss": 17.228516936302185, "val_acc": 60.0}
{"epoch": 1, "training_loss": 64.46595907211304, "training_acc": 64.0, "val_loss": 17.615310847759247, "val_acc": 60.0}
{"epoch": 2, "training_loss": 62.62334871292114, "training_acc": 69.0, "val_loss": 17.9677352309227, "val_acc": 56.0}
{"epoch": 3, "training_loss": 61.75168585777283, "training_acc": 70.0, "val_loss": 18.283894658088684, "val_acc": 56.0}
{"epoch": 4, "training_loss": 60.459057569503784, "training_acc": 74.0, "val_loss": 18.827514350414276, "val_acc": 56.0}
{"epoch": 5, "training_loss": 60.49823975563049, "training_acc": 70.0, "val_loss": 19.43957805633545, "val_acc": 60.0}
{"epoch": 6, "training_loss": 60.62493181228638, "training_acc": 69.0, "val_loss": 19.803611934185028, "val_acc": 60.0}
{"epoch": 7, "training_loss": 60.55801868438721, "training_acc": 68.0, "val_loss": 19.97154951095581, "val_acc": 60.0}
{"epoch": 8, "training_loss": 58.89477729797363, "training_acc": 69.0, "val_loss": 19.721820950508118, "val_acc": 56.0}
{"epoch": 9, "training_loss": 57.79375457763672, "training_acc": 66.0, "val_loss": 19.549329578876495, "val_acc": 52.0}
{"epoch": 10, "training_loss": 56.61947226524353, "training_acc": 70.0, "val_loss": 19.55888718366623, "val_acc": 48.0}
{"epoch": 11, "training_loss": 57.22029650211334, "training_acc": 73.0, "val_loss": 19.755147397518158, "val_acc": 48.0}
{"epoch": 12, "training_loss": 56.84522843360901, "training_acc": 76.0, "val_loss": 19.89879161119461, "val_acc": 52.0}
{"epoch": 13, "training_loss": 56.58210575580597, "training_acc": 75.0, "val_loss": 20.00061422586441, "val_acc": 52.0}
{"epoch": 14, "training_loss": 57.05100393295288, "training_acc": 74.0, "val_loss": 20.14538198709488, "val_acc": 52.0}
{"epoch": 15, "training_loss": 55.84830164909363, "training_acc": 77.0, "val_loss": 20.262344181537628, "val_acc": 52.0}
{"epoch": 16, "training_loss": 55.86913728713989, "training_acc": 74.0, "val_loss": 20.36285400390625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 55.278621196746826, "training_acc": 77.0, "val_loss": 20.530124008655548, "val_acc": 52.0}
{"epoch": 18, "training_loss": 55.228718757629395, "training_acc": 77.0, "val_loss": 20.862852036952972, "val_acc": 52.0}
{"epoch": 19, "training_loss": 54.766401529312134, "training_acc": 71.0, "val_loss": 21.115823090076447, "val_acc": 52.0}
