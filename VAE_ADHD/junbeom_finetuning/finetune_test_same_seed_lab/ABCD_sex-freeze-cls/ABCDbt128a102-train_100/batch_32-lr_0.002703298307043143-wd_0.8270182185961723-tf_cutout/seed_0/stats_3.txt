"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 75.00573396682739, "training_acc": 47.0, "val_loss": 17.585907876491547, "val_acc": 52.0}
{"epoch": 1, "training_loss": 68.43445611000061, "training_acc": 55.0, "val_loss": 19.030286371707916, "val_acc": 56.0}
{"epoch": 2, "training_loss": 66.05663871765137, "training_acc": 59.0, "val_loss": 18.64287555217743, "val_acc": 44.0}
{"epoch": 3, "training_loss": 65.53443026542664, "training_acc": 64.0, "val_loss": 19.202254712581635, "val_acc": 56.0}
{"epoch": 4, "training_loss": 63.46257972717285, "training_acc": 61.0, "val_loss": 18.336467444896698, "val_acc": 52.0}
{"epoch": 5, "training_loss": 59.34841299057007, "training_acc": 65.0, "val_loss": 19.325824081897736, "val_acc": 48.0}
{"epoch": 6, "training_loss": 61.63680386543274, "training_acc": 66.0, "val_loss": 19.32530552148819, "val_acc": 56.0}
{"epoch": 7, "training_loss": 61.29762530326843, "training_acc": 69.0, "val_loss": 18.013350665569305, "val_acc": 60.0}
{"epoch": 8, "training_loss": 57.40316438674927, "training_acc": 71.0, "val_loss": 18.30230802297592, "val_acc": 60.0}
{"epoch": 9, "training_loss": 56.97835969924927, "training_acc": 72.0, "val_loss": 18.774986267089844, "val_acc": 64.0}
{"epoch": 10, "training_loss": 58.706870317459106, "training_acc": 68.0, "val_loss": 19.220852851867676, "val_acc": 64.0}
{"epoch": 11, "training_loss": 56.94428491592407, "training_acc": 70.0, "val_loss": 19.452102482318878, "val_acc": 64.0}
{"epoch": 12, "training_loss": 56.63060688972473, "training_acc": 69.0, "val_loss": 19.470736384391785, "val_acc": 60.0}
{"epoch": 13, "training_loss": 56.54624927043915, "training_acc": 71.0, "val_loss": 19.76439207792282, "val_acc": 52.0}
{"epoch": 14, "training_loss": 58.1453332901001, "training_acc": 70.0, "val_loss": 19.608139991760254, "val_acc": 52.0}
{"epoch": 15, "training_loss": 53.29230213165283, "training_acc": 74.0, "val_loss": 21.304717659950256, "val_acc": 44.0}
{"epoch": 16, "training_loss": 57.730961322784424, "training_acc": 68.0, "val_loss": 23.545463383197784, "val_acc": 40.0}
{"epoch": 17, "training_loss": 62.84312582015991, "training_acc": 63.0, "val_loss": 22.582511603832245, "val_acc": 40.0}
{"epoch": 18, "training_loss": 56.58509039878845, "training_acc": 73.0, "val_loss": 22.335660457611084, "val_acc": 44.0}
{"epoch": 19, "training_loss": 54.74700164794922, "training_acc": 72.0, "val_loss": 23.181097209453583, "val_acc": 44.0}
