"main_optuna.py --pretrained_path /scratch/connectome/dyhan316/VAE_ADHD/barlowtwins/pretrain_results/ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option BT_org --batch_size 32 --save_path finetune_test_same_seed_lab --binary_class True --run_where lab --eval_mode False"
{"epoch": 0, "training_loss": 73.0126564502716, "training_acc": 45.0, "val_loss": 17.889659106731415, "val_acc": 60.0}
{"epoch": 1, "training_loss": 63.15356683731079, "training_acc": 63.0, "val_loss": 16.96949303150177, "val_acc": 68.0}
{"epoch": 2, "training_loss": 61.216001749038696, "training_acc": 65.0, "val_loss": 17.87548065185547, "val_acc": 60.0}
{"epoch": 3, "training_loss": 59.72808623313904, "training_acc": 66.0, "val_loss": 19.24833208322525, "val_acc": 60.0}
{"epoch": 4, "training_loss": 59.944783210754395, "training_acc": 66.0, "val_loss": 20.00849097967148, "val_acc": 56.0}
{"epoch": 5, "training_loss": 57.31205987930298, "training_acc": 67.0, "val_loss": 20.6598699092865, "val_acc": 56.0}
{"epoch": 6, "training_loss": 55.57004725933075, "training_acc": 71.0, "val_loss": 21.172139048576355, "val_acc": 56.0}
{"epoch": 7, "training_loss": 54.414185523986816, "training_acc": 69.0, "val_loss": 21.840612590312958, "val_acc": 60.0}
{"epoch": 8, "training_loss": 54.37353515625, "training_acc": 68.0, "val_loss": 22.471389174461365, "val_acc": 56.0}
{"epoch": 9, "training_loss": 53.08244228363037, "training_acc": 65.0, "val_loss": 22.440055012702942, "val_acc": 52.0}
{"epoch": 10, "training_loss": 52.265597105026245, "training_acc": 69.0, "val_loss": 23.142115771770477, "val_acc": 52.0}
{"epoch": 11, "training_loss": 53.55726075172424, "training_acc": 69.0, "val_loss": 23.93246740102768, "val_acc": 56.0}
{"epoch": 12, "training_loss": 51.61674499511719, "training_acc": 66.0, "val_loss": 25.771522521972656, "val_acc": 48.0}
{"epoch": 13, "training_loss": 52.99889135360718, "training_acc": 70.0, "val_loss": 26.653671264648438, "val_acc": 52.0}
{"epoch": 14, "training_loss": 53.55232083797455, "training_acc": 68.0, "val_loss": 26.44255757331848, "val_acc": 52.0}
{"epoch": 15, "training_loss": 51.389663338661194, "training_acc": 73.0, "val_loss": 25.910547375679016, "val_acc": 48.0}
{"epoch": 16, "training_loss": 50.900667667388916, "training_acc": 70.0, "val_loss": 26.05520188808441, "val_acc": 48.0}
{"epoch": 17, "training_loss": 49.878437757492065, "training_acc": 69.0, "val_loss": 25.868502259254456, "val_acc": 40.0}
{"epoch": 18, "training_loss": 51.579097270965576, "training_acc": 72.0, "val_loss": 25.915613770484924, "val_acc": 36.0}
{"epoch": 19, "training_loss": 49.415677070617676, "training_acc": 72.0, "val_loss": 25.995731353759766, "val_acc": 40.0}
{"epoch": 20, "training_loss": 48.668033599853516, "training_acc": 71.0, "val_loss": 26.076337695121765, "val_acc": 48.0}
