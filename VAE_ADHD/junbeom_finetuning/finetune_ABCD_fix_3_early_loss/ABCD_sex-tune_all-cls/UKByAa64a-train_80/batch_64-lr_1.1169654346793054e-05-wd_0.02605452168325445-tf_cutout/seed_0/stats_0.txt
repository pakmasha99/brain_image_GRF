"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.4555025100708, "training_acc": 52.5, "val_loss": 13.932323455810547, "val_acc": 50.0, "val_auroc": 0.31, "time": 18.48}
{"epoch": 1, "training_loss": 55.35257339477539, "training_acc": 52.5, "val_loss": 13.933109045028687, "val_acc": 50.0, "val_auroc": 0.3, "time": 35.64}
{"epoch": 2, "training_loss": 55.1069917678833, "training_acc": 52.5, "val_loss": 13.935343027114868, "val_acc": 50.0, "val_auroc": 0.35, "time": 53.39}
{"epoch": 3, "training_loss": 55.02155876159668, "training_acc": 52.5, "val_loss": 13.894428014755249, "val_acc": 50.0, "val_auroc": 0.49, "time": 71.21}
{"epoch": 4, "training_loss": 54.87252426147461, "training_acc": 52.5, "val_loss": 13.886526823043823, "val_acc": 50.0, "val_auroc": 0.47, "time": 88.03}
{"epoch": 5, "training_loss": 54.72704887390137, "training_acc": 52.5, "val_loss": 13.955506086349487, "val_acc": 50.0, "val_auroc": 0.38, "time": 105.71}
{"epoch": 6, "training_loss": 54.82371139526367, "training_acc": 52.5, "val_loss": 13.938112258911133, "val_acc": 50.0, "val_auroc": 0.39, "time": 125.05}
{"epoch": 7, "training_loss": 54.5716552734375, "training_acc": 52.5, "val_loss": 13.936986923217773, "val_acc": 50.0, "val_auroc": 0.4, "time": 144.47}
{"epoch": 8, "training_loss": 54.79773807525635, "training_acc": 52.5, "val_loss": 13.927816152572632, "val_acc": 50.0, "val_auroc": 0.4, "time": 161.16}
{"epoch": 9, "training_loss": 54.68483924865723, "training_acc": 53.75, "val_loss": 13.88074517250061, "val_acc": 50.0, "val_auroc": 0.51, "time": 180.78}
{"epoch": 10, "training_loss": 54.13463020324707, "training_acc": 60.0, "val_loss": 13.919072151184082, "val_acc": 50.0, "val_auroc": 0.43, "time": 199.94}
{"epoch": 11, "training_loss": 54.159860610961914, "training_acc": 63.75, "val_loss": 13.85230541229248, "val_acc": 50.0, "val_auroc": 0.56, "time": 218.7}
{"epoch": 12, "training_loss": 54.16783142089844, "training_acc": 62.5, "val_loss": 13.845958709716797, "val_acc": 50.0, "val_auroc": 0.61, "time": 236.87}
{"epoch": 13, "training_loss": 53.89031410217285, "training_acc": 60.0, "val_loss": 13.911064863204956, "val_acc": 50.0, "val_auroc": 0.44, "time": 253.56}
{"epoch": 14, "training_loss": 53.980600357055664, "training_acc": 58.75, "val_loss": 13.892457485198975, "val_acc": 50.0, "val_auroc": 0.54, "time": 273.32}
{"epoch": 15, "training_loss": 53.79880905151367, "training_acc": 55.0, "val_loss": 13.87259840965271, "val_acc": 50.0, "val_auroc": 0.56, "time": 291.13}
{"epoch": 16, "training_loss": 53.78620529174805, "training_acc": 55.0, "val_loss": 14.033571481704712, "val_acc": 50.0, "val_auroc": 0.41, "time": 307.98}
{"epoch": 17, "training_loss": 53.694732666015625, "training_acc": 52.5, "val_loss": 14.077857732772827, "val_acc": 50.0, "val_auroc": 0.34, "time": 326.28}
{"epoch": 18, "training_loss": 53.44187355041504, "training_acc": 53.75, "val_loss": 13.949141502380371, "val_acc": 50.0, "val_auroc": 0.58, "time": 344.59}
{"epoch": 19, "training_loss": 53.62623405456543, "training_acc": 53.75, "val_loss": 13.908237218856812, "val_acc": 50.0, "val_auroc": 0.57, "time": 364.29}
{"epoch": 20, "training_loss": 53.3749885559082, "training_acc": 55.0, "val_loss": 14.05984878540039, "val_acc": 50.0, "val_auroc": 0.35, "time": 381.8}
{"epoch": 21, "training_loss": 54.15052318572998, "training_acc": 55.0, "val_loss": 14.030932188034058, "val_acc": 50.0, "val_auroc": 0.38, "time": 400.89}
{"epoch": 22, "training_loss": 53.59543418884277, "training_acc": 58.75, "val_loss": 13.902503252029419, "val_acc": 50.0, "val_auroc": 0.53, "time": 420.94}
{"epoch": 23, "training_loss": 53.401031494140625, "training_acc": 57.5, "val_loss": 13.935060501098633, "val_acc": 50.0, "val_auroc": 0.54, "time": 440.41}
{"epoch": 24, "training_loss": 53.20269203186035, "training_acc": 60.0, "val_loss": 14.116557836532593, "val_acc": 50.0, "val_auroc": 0.31, "time": 457.57}
{"epoch": 25, "training_loss": 52.998802185058594, "training_acc": 73.75, "val_loss": 14.053722620010376, "val_acc": 50.0, "val_auroc": 0.36, "time": 475.5}
{"epoch": 26, "training_loss": 54.1711483001709, "training_acc": 73.75, "val_loss": 14.069563150405884, "val_acc": 50.0, "val_auroc": 0.35, "time": 494.11}
{"epoch": 27, "training_loss": 53.6043701171875, "training_acc": 77.5, "val_loss": 14.062988758087158, "val_acc": 50.0, "val_auroc": 0.31, "time": 513.4}
{"epoch": 28, "training_loss": 52.68291091918945, "training_acc": 68.75, "val_loss": 13.928518295288086, "val_acc": 50.0, "val_auroc": 0.56, "time": 530.34}
{"epoch": 29, "training_loss": 52.51779365539551, "training_acc": 65.0, "val_loss": 13.969050645828247, "val_acc": 50.0, "val_auroc": 0.47, "time": 548.85}
{"epoch": 30, "training_loss": 52.379791259765625, "training_acc": 67.5, "val_loss": 14.06265377998352, "val_acc": 50.0, "val_auroc": 0.35, "time": 567.1}
{"epoch": 31, "training_loss": 52.45708465576172, "training_acc": 68.75, "val_loss": 14.014134407043457, "val_acc": 50.0, "val_auroc": 0.38, "time": 584.58}
