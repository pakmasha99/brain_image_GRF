"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.66716957092285, "training_acc": 52.5, "val_loss": 13.867753744125366, "val_acc": 50.0, "val_auroc": 0.66, "time": 18.93}
{"epoch": 1, "training_loss": 55.44070911407471, "training_acc": 52.5, "val_loss": 13.872549533843994, "val_acc": 50.0, "val_auroc": 0.56, "time": 36.15}
{"epoch": 2, "training_loss": 55.33210468292236, "training_acc": 52.5, "val_loss": 13.906693458557129, "val_acc": 50.0, "val_auroc": 0.54, "time": 53.04}
{"epoch": 3, "training_loss": 55.46651649475098, "training_acc": 52.5, "val_loss": 13.968029022216797, "val_acc": 50.0, "val_auroc": 0.36, "time": 70.36}
{"epoch": 4, "training_loss": 55.42497539520264, "training_acc": 52.5, "val_loss": 13.897348642349243, "val_acc": 50.0, "val_auroc": 0.23, "time": 87.73}
{"epoch": 5, "training_loss": 55.34516716003418, "training_acc": 52.5, "val_loss": 13.90623688697815, "val_acc": 50.0, "val_auroc": 0.43, "time": 104.36}
{"epoch": 6, "training_loss": 55.46005630493164, "training_acc": 52.5, "val_loss": 14.040565490722656, "val_acc": 50.0, "val_auroc": 0.69, "time": 121.01}
{"epoch": 7, "training_loss": 55.6270809173584, "training_acc": 52.5, "val_loss": 14.049485921859741, "val_acc": 50.0, "val_auroc": 0.44, "time": 137.26}
{"epoch": 8, "training_loss": 55.65068435668945, "training_acc": 52.5, "val_loss": 13.892954587936401, "val_acc": 50.0, "val_auroc": 0.35, "time": 153.34}
{"epoch": 9, "training_loss": 55.334280014038086, "training_acc": 52.5, "val_loss": 13.86179804801941, "val_acc": 50.0, "val_auroc": 0.65, "time": 169.79}
{"epoch": 10, "training_loss": 55.44287300109863, "training_acc": 60.0, "val_loss": 13.874444961547852, "val_acc": 50.0, "val_auroc": 0.61, "time": 185.93}
{"epoch": 11, "training_loss": 55.32114028930664, "training_acc": 52.5, "val_loss": 13.95328402519226, "val_acc": 50.0, "val_auroc": 0.63, "time": 202.06}
{"epoch": 12, "training_loss": 55.47315979003906, "training_acc": 52.5, "val_loss": 13.967229127883911, "val_acc": 50.0, "val_auroc": 0.28, "time": 218.33}
{"epoch": 13, "training_loss": 55.4310302734375, "training_acc": 52.5, "val_loss": 13.8917875289917, "val_acc": 50.0, "val_auroc": 0.3, "time": 234.87}
{"epoch": 14, "training_loss": 55.33275032043457, "training_acc": 52.5, "val_loss": 13.8682222366333, "val_acc": 50.0, "val_auroc": 0.34, "time": 250.78}
{"epoch": 15, "training_loss": 55.54927444458008, "training_acc": 45.0, "val_loss": 13.882306814193726, "val_acc": 50.0, "val_auroc": 0.72, "time": 267.41}
{"epoch": 16, "training_loss": 55.227806091308594, "training_acc": 52.5, "val_loss": 14.032305479049683, "val_acc": 50.0, "val_auroc": 0.79, "time": 284.97}
{"epoch": 17, "training_loss": 55.69602966308594, "training_acc": 52.5, "val_loss": 14.109997749328613, "val_acc": 50.0, "val_auroc": 0.67, "time": 302.62}
{"epoch": 18, "training_loss": 55.76072883605957, "training_acc": 52.5, "val_loss": 13.962293863296509, "val_acc": 50.0, "val_auroc": 0.58, "time": 320.03}
{"epoch": 19, "training_loss": 55.3346004486084, "training_acc": 52.5, "val_loss": 13.86642336845398, "val_acc": 50.0, "val_auroc": 0.58, "time": 336.89}
{"epoch": 20, "training_loss": 55.44615840911865, "training_acc": 50.0, "val_loss": 13.864961862564087, "val_acc": 50.0, "val_auroc": 0.34, "time": 354.55}
{"epoch": 21, "training_loss": 55.47395706176758, "training_acc": 47.5, "val_loss": 13.868106603622437, "val_acc": 50.0, "val_auroc": 0.51, "time": 371.86}
{"epoch": 22, "training_loss": 55.35465621948242, "training_acc": 52.5, "val_loss": 13.903675079345703, "val_acc": 50.0, "val_auroc": 0.74, "time": 389.6}
{"epoch": 23, "training_loss": 55.341129302978516, "training_acc": 52.5, "val_loss": 13.968592882156372, "val_acc": 50.0, "val_auroc": 0.54, "time": 407.17}
{"epoch": 24, "training_loss": 55.44551467895508, "training_acc": 52.5, "val_loss": 14.045066833496094, "val_acc": 50.0, "val_auroc": 0.62, "time": 424.28}
{"epoch": 25, "training_loss": 55.64247131347656, "training_acc": 52.5, "val_loss": 14.064728021621704, "val_acc": 50.0, "val_auroc": 0.54, "time": 441.71}
{"epoch": 26, "training_loss": 55.77927207946777, "training_acc": 52.5, "val_loss": 14.047266244888306, "val_acc": 50.0, "val_auroc": 0.54, "time": 459.3}
{"epoch": 27, "training_loss": 55.6398868560791, "training_acc": 52.5, "val_loss": 14.042171239852905, "val_acc": 50.0, "val_auroc": 0.49, "time": 476.82}
{"epoch": 28, "training_loss": 55.644601821899414, "training_acc": 52.5, "val_loss": 13.928396701812744, "val_acc": 50.0, "val_auroc": 0.46, "time": 494.41}
