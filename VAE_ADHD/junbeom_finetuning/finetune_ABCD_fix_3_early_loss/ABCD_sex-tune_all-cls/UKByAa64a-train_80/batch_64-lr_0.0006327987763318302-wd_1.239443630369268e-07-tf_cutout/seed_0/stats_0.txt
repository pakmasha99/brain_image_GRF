"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.26218509674072, "training_acc": 52.5, "val_loss": 13.95799994468689, "val_acc": 50.0, "val_auroc": 0.4, "time": 19.19}
{"epoch": 1, "training_loss": 56.41084671020508, "training_acc": 45.0, "val_loss": 13.875778913497925, "val_acc": 50.0, "val_auroc": 0.69, "time": 37.33}
{"epoch": 2, "training_loss": 55.409250259399414, "training_acc": 52.5, "val_loss": 13.864907026290894, "val_acc": 50.0, "val_auroc": 0.53, "time": 55.01}
{"epoch": 3, "training_loss": 55.41711139678955, "training_acc": 52.5, "val_loss": 13.86921763420105, "val_acc": 50.0, "val_auroc": 0.27, "time": 72.52}
{"epoch": 4, "training_loss": 55.40815258026123, "training_acc": 52.5, "val_loss": 13.86552095413208, "val_acc": 50.0, "val_auroc": 0.6, "time": 89.74}
{"epoch": 5, "training_loss": 55.51111698150635, "training_acc": 52.5, "val_loss": 13.86588454246521, "val_acc": 50.0, "val_auroc": 0.27, "time": 107.01}
{"epoch": 6, "training_loss": 55.52125835418701, "training_acc": 47.5, "val_loss": 13.866113424301147, "val_acc": 50.0, "val_auroc": 0.3, "time": 124.49}
{"epoch": 7, "training_loss": 55.636677742004395, "training_acc": 45.0, "val_loss": 13.86391282081604, "val_acc": 50.0, "val_auroc": 0.35, "time": 142.07}
{"epoch": 8, "training_loss": 55.449687004089355, "training_acc": 56.25, "val_loss": 13.86340618133545, "val_acc": 50.0, "val_auroc": 0.36, "time": 159.49}
{"epoch": 9, "training_loss": 55.46532440185547, "training_acc": 47.5, "val_loss": 13.87425184249878, "val_acc": 50.0, "val_auroc": 0.33, "time": 176.73}
{"epoch": 10, "training_loss": 55.35157871246338, "training_acc": 52.5, "val_loss": 13.926013708114624, "val_acc": 50.0, "val_auroc": 0.4, "time": 193.88}
{"epoch": 11, "training_loss": 55.38262462615967, "training_acc": 52.5, "val_loss": 14.045077562332153, "val_acc": 50.0, "val_auroc": 0.45, "time": 210.89}
{"epoch": 12, "training_loss": 55.63736152648926, "training_acc": 52.5, "val_loss": 14.15265440940857, "val_acc": 50.0, "val_auroc": 0.49, "time": 227.76}
{"epoch": 13, "training_loss": 56.0262508392334, "training_acc": 52.5, "val_loss": 14.192707538604736, "val_acc": 50.0, "val_auroc": 0.51, "time": 244.95}
{"epoch": 14, "training_loss": 56.18880367279053, "training_acc": 52.5, "val_loss": 14.288862943649292, "val_acc": 50.0, "val_auroc": 0.46, "time": 262.18}
{"epoch": 15, "training_loss": 56.32913017272949, "training_acc": 52.5, "val_loss": 14.30854082107544, "val_acc": 50.0, "val_auroc": 0.51, "time": 279.18}
{"epoch": 16, "training_loss": 56.42013740539551, "training_acc": 52.5, "val_loss": 14.127734899520874, "val_acc": 50.0, "val_auroc": 0.59, "time": 296.03}
{"epoch": 17, "training_loss": 55.783721923828125, "training_acc": 52.5, "val_loss": 13.924564123153687, "val_acc": 50.0, "val_auroc": 0.68, "time": 312.99}
{"epoch": 18, "training_loss": 55.44495964050293, "training_acc": 52.5, "val_loss": 13.863248825073242, "val_acc": 50.0, "val_auroc": 0.45, "time": 330.64}
{"epoch": 19, "training_loss": 55.504730224609375, "training_acc": 52.5, "val_loss": 13.885506391525269, "val_acc": 50.0, "val_auroc": 0.57, "time": 347.78}
{"epoch": 20, "training_loss": 55.70707321166992, "training_acc": 47.5, "val_loss": 13.975834846496582, "val_acc": 50.0, "val_auroc": 0.54, "time": 364.58}
{"epoch": 21, "training_loss": 56.364484786987305, "training_acc": 47.5, "val_loss": 13.891960382461548, "val_acc": 50.0, "val_auroc": 0.72, "time": 381.57}
{"epoch": 22, "training_loss": 55.55643081665039, "training_acc": 47.5, "val_loss": 13.924703598022461, "val_acc": 50.0, "val_auroc": 0.49, "time": 396.42}
{"epoch": 23, "training_loss": 55.4909610748291, "training_acc": 52.5, "val_loss": 14.143509864807129, "val_acc": 50.0, "val_auroc": 0.66, "time": 413.1}
{"epoch": 24, "training_loss": 55.964332580566406, "training_acc": 52.5, "val_loss": 14.065577983856201, "val_acc": 50.0, "val_auroc": 0.41, "time": 430.38}
{"epoch": 25, "training_loss": 55.61095142364502, "training_acc": 52.5, "val_loss": 13.890379667282104, "val_acc": 50.0, "val_auroc": 0.56, "time": 447.16}
{"epoch": 26, "training_loss": 55.41757774353027, "training_acc": 52.5, "val_loss": 13.863189220428467, "val_acc": 50.0, "val_auroc": 0.62, "time": 463.15}
{"epoch": 27, "training_loss": 55.53672790527344, "training_acc": 47.5, "val_loss": 13.863608837127686, "val_acc": 50.0, "val_auroc": 0.42, "time": 479.64}
{"epoch": 28, "training_loss": 55.60965156555176, "training_acc": 52.5, "val_loss": 13.878320455551147, "val_acc": 50.0, "val_auroc": 0.16, "time": 496.47}
{"epoch": 29, "training_loss": 55.3697452545166, "training_acc": 52.5, "val_loss": 13.876570463180542, "val_acc": 50.0, "val_auroc": 0.42, "time": 513.75}
{"epoch": 30, "training_loss": 55.35227012634277, "training_acc": 52.5, "val_loss": 13.896135091781616, "val_acc": 50.0, "val_auroc": 0.3, "time": 530.45}
{"epoch": 31, "training_loss": 55.36832046508789, "training_acc": 52.5, "val_loss": 13.916447162628174, "val_acc": 50.0, "val_auroc": 0.37, "time": 547.47}
{"epoch": 32, "training_loss": 55.385769844055176, "training_acc": 52.5, "val_loss": 13.89075756072998, "val_acc": 50.0, "val_auroc": 0.4, "time": 564.55}
{"epoch": 33, "training_loss": 55.4471435546875, "training_acc": 52.5, "val_loss": 13.87477159500122, "val_acc": 50.0, "val_auroc": 0.41, "time": 581.34}
{"epoch": 34, "training_loss": 55.36034965515137, "training_acc": 52.5, "val_loss": 13.904250860214233, "val_acc": 50.0, "val_auroc": 0.52, "time": 598.43}
{"epoch": 35, "training_loss": 55.53984260559082, "training_acc": 52.5, "val_loss": 13.926550149917603, "val_acc": 50.0, "val_auroc": 0.58, "time": 615.4}
{"epoch": 36, "training_loss": 55.370245933532715, "training_acc": 52.5, "val_loss": 13.882355690002441, "val_acc": 50.0, "val_auroc": 0.56, "time": 632.18}
{"epoch": 37, "training_loss": 55.32033157348633, "training_acc": 52.5, "val_loss": 13.863842487335205, "val_acc": 50.0, "val_auroc": 0.53, "time": 649.16}
{"epoch": 38, "training_loss": 55.56635284423828, "training_acc": 47.5, "val_loss": 13.88567328453064, "val_acc": 50.0, "val_auroc": 0.47, "time": 666.07}
{"epoch": 39, "training_loss": 55.72812461853027, "training_acc": 47.5, "val_loss": 13.87058973312378, "val_acc": 50.0, "val_auroc": 0.44, "time": 682.83}
{"epoch": 40, "training_loss": 55.55051136016846, "training_acc": 47.5, "val_loss": 13.868293762207031, "val_acc": 50.0, "val_auroc": 0.56, "time": 699.67}
{"epoch": 41, "training_loss": 55.56599044799805, "training_acc": 52.5, "val_loss": 13.893288373947144, "val_acc": 50.0, "val_auroc": 0.39, "time": 716.95}
{"epoch": 42, "training_loss": 55.36123275756836, "training_acc": 52.5, "val_loss": 13.889092206954956, "val_acc": 50.0, "val_auroc": 0.34, "time": 733.77}
{"epoch": 43, "training_loss": 55.36712646484375, "training_acc": 52.5, "val_loss": 13.91021728515625, "val_acc": 50.0, "val_auroc": 0.38, "time": 750.27}
{"epoch": 44, "training_loss": 55.51051139831543, "training_acc": 52.5, "val_loss": 13.922336101531982, "val_acc": 50.0, "val_auroc": 0.21, "time": 766.76}
{"epoch": 45, "training_loss": 55.400007247924805, "training_acc": 52.5, "val_loss": 13.88336181640625, "val_acc": 50.0, "val_auroc": 0.47, "time": 784.12}
