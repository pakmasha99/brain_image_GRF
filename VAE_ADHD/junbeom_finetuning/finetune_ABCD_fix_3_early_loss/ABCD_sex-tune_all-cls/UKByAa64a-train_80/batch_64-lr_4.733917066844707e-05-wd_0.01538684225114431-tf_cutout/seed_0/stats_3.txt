"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.394670486450195, "training_acc": 51.25, "val_loss": 13.795675039291382, "val_acc": 55.0, "val_auroc": 0.606, "time": 19.68}
{"epoch": 1, "training_loss": 55.45755672454834, "training_acc": 50.0, "val_loss": 13.75207781791687, "val_acc": 55.0, "val_auroc": 0.727, "time": 37.58}
{"epoch": 2, "training_loss": 55.2965784072876, "training_acc": 51.25, "val_loss": 13.800262212753296, "val_acc": 55.0, "val_auroc": 0.556, "time": 61.52}
{"epoch": 3, "training_loss": 55.236433029174805, "training_acc": 51.25, "val_loss": 13.85218620300293, "val_acc": 55.0, "val_auroc": 0.434, "time": 86.72}
{"epoch": 4, "training_loss": 55.42080879211426, "training_acc": 52.5, "val_loss": 13.794708251953125, "val_acc": 55.0, "val_auroc": 0.596, "time": 105.02}
{"epoch": 5, "training_loss": 55.19913578033447, "training_acc": 51.25, "val_loss": 13.797990083694458, "val_acc": 55.0, "val_auroc": 0.475, "time": 123.85}
{"epoch": 6, "training_loss": 55.15219211578369, "training_acc": 51.25, "val_loss": 13.802622556686401, "val_acc": 55.0, "val_auroc": 0.475, "time": 145.27}
{"epoch": 7, "training_loss": 55.05747413635254, "training_acc": 51.25, "val_loss": 13.824774026870728, "val_acc": 55.0, "val_auroc": 0.394, "time": 168.49}
{"epoch": 8, "training_loss": 54.97287464141846, "training_acc": 51.25, "val_loss": 13.843787908554077, "val_acc": 55.0, "val_auroc": 0.444, "time": 185.01}
{"epoch": 9, "training_loss": 54.76018714904785, "training_acc": 53.75, "val_loss": 13.896392583847046, "val_acc": 55.0, "val_auroc": 0.455, "time": 203.27}
{"epoch": 10, "training_loss": 54.85982799530029, "training_acc": 66.25, "val_loss": 13.893409967422485, "val_acc": 55.0, "val_auroc": 0.424, "time": 223.24}
{"epoch": 11, "training_loss": 54.34796714782715, "training_acc": 78.75, "val_loss": 13.851237297058105, "val_acc": 55.0, "val_auroc": 0.384, "time": 242.43}
{"epoch": 12, "training_loss": 54.93144130706787, "training_acc": 51.25, "val_loss": 13.837834596633911, "val_acc": 55.0, "val_auroc": 0.465, "time": 261.14}
{"epoch": 13, "training_loss": 54.70328330993652, "training_acc": 51.25, "val_loss": 13.829379081726074, "val_acc": 55.0, "val_auroc": 0.485, "time": 280.74}
{"epoch": 14, "training_loss": 54.68140506744385, "training_acc": 68.75, "val_loss": 13.91855239868164, "val_acc": 55.0, "val_auroc": 0.444, "time": 301.31}
{"epoch": 15, "training_loss": 54.32147979736328, "training_acc": 68.75, "val_loss": 13.858935832977295, "val_acc": 55.0, "val_auroc": 0.465, "time": 323.38}
{"epoch": 16, "training_loss": 54.67230033874512, "training_acc": 53.75, "val_loss": 13.793108463287354, "val_acc": 55.0, "val_auroc": 0.374, "time": 340.56}
{"epoch": 17, "training_loss": 55.323699951171875, "training_acc": 51.25, "val_loss": 13.812165260314941, "val_acc": 55.0, "val_auroc": 0.434, "time": 358.82}
{"epoch": 18, "training_loss": 54.93939399719238, "training_acc": 51.25, "val_loss": 13.781436681747437, "val_acc": 55.0, "val_auroc": 0.535, "time": 379.02}
{"epoch": 19, "training_loss": 54.502634048461914, "training_acc": 51.25, "val_loss": 13.84165644645691, "val_acc": 55.0, "val_auroc": 0.515, "time": 401.09}
{"epoch": 20, "training_loss": 54.8056697845459, "training_acc": 71.25, "val_loss": 13.932428359985352, "val_acc": 55.0, "val_auroc": 0.434, "time": 423.99}
