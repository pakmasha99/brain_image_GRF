"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.67844009399414, "training_acc": 40.0, "val_loss": 13.819483518600464, "val_acc": 50.0, "val_auroc": 0.69, "time": 19.57}
{"epoch": 1, "training_loss": 55.53223419189453, "training_acc": 48.75, "val_loss": 13.88429045677185, "val_acc": 50.0, "val_auroc": 0.33, "time": 37.96}
{"epoch": 2, "training_loss": 55.2312126159668, "training_acc": 58.75, "val_loss": 13.890557289123535, "val_acc": 50.0, "val_auroc": 0.42, "time": 62.24}
{"epoch": 3, "training_loss": 55.136030197143555, "training_acc": 52.5, "val_loss": 13.893730640411377, "val_acc": 50.0, "val_auroc": 0.55, "time": 86.2}
{"epoch": 4, "training_loss": 55.07076072692871, "training_acc": 52.5, "val_loss": 13.896416425704956, "val_acc": 50.0, "val_auroc": 0.5, "time": 104.85}
{"epoch": 5, "training_loss": 54.94386291503906, "training_acc": 52.5, "val_loss": 13.919696807861328, "val_acc": 50.0, "val_auroc": 0.53, "time": 122.01}
{"epoch": 6, "training_loss": 54.80455017089844, "training_acc": 52.5, "val_loss": 13.990625143051147, "val_acc": 50.0, "val_auroc": 0.55, "time": 142.55}
{"epoch": 7, "training_loss": 54.80132865905762, "training_acc": 52.5, "val_loss": 13.99717926979065, "val_acc": 50.0, "val_auroc": 0.49, "time": 164.22}
{"epoch": 8, "training_loss": 54.22796630859375, "training_acc": 52.5, "val_loss": 13.807181119918823, "val_acc": 50.0, "val_auroc": 0.71, "time": 181.36}
{"epoch": 9, "training_loss": 54.8178768157959, "training_acc": 53.75, "val_loss": 13.802045583724976, "val_acc": 50.0, "val_auroc": 0.74, "time": 198.49}
{"epoch": 10, "training_loss": 55.05963325500488, "training_acc": 67.5, "val_loss": 13.807915449142456, "val_acc": 50.0, "val_auroc": 0.69, "time": 217.15}
{"epoch": 11, "training_loss": 54.7337703704834, "training_acc": 63.75, "val_loss": 13.839976787567139, "val_acc": 50.0, "val_auroc": 0.59, "time": 234.71}
{"epoch": 12, "training_loss": 54.53549575805664, "training_acc": 52.5, "val_loss": 13.875447511672974, "val_acc": 50.0, "val_auroc": 0.61, "time": 254.18}
{"epoch": 13, "training_loss": 54.443108558654785, "training_acc": 52.5, "val_loss": 13.89443039894104, "val_acc": 50.0, "val_auroc": 0.53, "time": 272.43}
{"epoch": 14, "training_loss": 54.03360176086426, "training_acc": 52.5, "val_loss": 13.882646560668945, "val_acc": 50.0, "val_auroc": 0.5, "time": 292.6}
{"epoch": 15, "training_loss": 53.88091564178467, "training_acc": 55.0, "val_loss": 13.95290732383728, "val_acc": 50.0, "val_auroc": 0.45, "time": 312.15}
{"epoch": 16, "training_loss": 53.55623817443848, "training_acc": 52.5, "val_loss": 14.048283100128174, "val_acc": 50.0, "val_auroc": 0.51, "time": 333.4}
{"epoch": 17, "training_loss": 54.0546760559082, "training_acc": 52.5, "val_loss": 13.963855504989624, "val_acc": 50.0, "val_auroc": 0.47, "time": 352.75}
{"epoch": 18, "training_loss": 52.887821197509766, "training_acc": 53.75, "val_loss": 13.870840072631836, "val_acc": 50.0, "val_auroc": 0.46, "time": 369.14}
{"epoch": 19, "training_loss": 53.18171977996826, "training_acc": 76.25, "val_loss": 13.876746892929077, "val_acc": 50.0, "val_auroc": 0.48, "time": 389.18}
{"epoch": 20, "training_loss": 52.58674621582031, "training_acc": 66.25, "val_loss": 13.88973355293274, "val_acc": 50.0, "val_auroc": 0.45, "time": 412.38}
{"epoch": 21, "training_loss": 51.76384735107422, "training_acc": 78.75, "val_loss": 13.934837579727173, "val_acc": 50.0, "val_auroc": 0.48, "time": 431.36}
{"epoch": 22, "training_loss": 51.35708141326904, "training_acc": 68.75, "val_loss": 13.899902105331421, "val_acc": 50.0, "val_auroc": 0.5, "time": 449.89}
{"epoch": 23, "training_loss": 50.23273181915283, "training_acc": 86.25, "val_loss": 14.266730546951294, "val_acc": 50.0, "val_auroc": 0.52, "time": 467.26}
{"epoch": 24, "training_loss": 52.35272026062012, "training_acc": 52.5, "val_loss": 13.854901790618896, "val_acc": 50.0, "val_auroc": 0.52, "time": 485.39}
{"epoch": 25, "training_loss": 50.07393550872803, "training_acc": 80.0, "val_loss": 13.819431066513062, "val_acc": 50.0, "val_auroc": 0.52, "time": 505.78}
{"epoch": 26, "training_loss": 49.02073669433594, "training_acc": 81.25, "val_loss": 14.31250810623169, "val_acc": 50.0, "val_auroc": 0.61, "time": 522.48}
{"epoch": 27, "training_loss": 52.101806640625, "training_acc": 52.5, "val_loss": 13.760095834732056, "val_acc": 50.0, "val_auroc": 0.56, "time": 542.47}
{"epoch": 28, "training_loss": 47.91972732543945, "training_acc": 83.75, "val_loss": 14.058060646057129, "val_acc": 50.0, "val_auroc": 0.48, "time": 561.77}
{"epoch": 29, "training_loss": 49.37967777252197, "training_acc": 71.25, "val_loss": 14.227020740509033, "val_acc": 50.0, "val_auroc": 0.53, "time": 580.44}
{"epoch": 30, "training_loss": 47.82061576843262, "training_acc": 66.25, "val_loss": 13.801259994506836, "val_acc": 50.0, "val_auroc": 0.57, "time": 598.32}
{"epoch": 31, "training_loss": 45.21957778930664, "training_acc": 91.25, "val_loss": 13.719602823257446, "val_acc": 50.0, "val_auroc": 0.55, "time": 617.75}
{"epoch": 32, "training_loss": 43.61233997344971, "training_acc": 85.0, "val_loss": 13.993408679962158, "val_acc": 55.0, "val_auroc": 0.57, "time": 637.06}
{"epoch": 33, "training_loss": 45.0126953125, "training_acc": 82.5, "val_loss": 13.960695266723633, "val_acc": 50.0, "val_auroc": 0.57, "time": 653.64}
{"epoch": 34, "training_loss": 42.82235336303711, "training_acc": 83.75, "val_loss": 13.981541395187378, "val_acc": 50.0, "val_auroc": 0.59, "time": 670.37}
{"epoch": 35, "training_loss": 40.592312812805176, "training_acc": 87.5, "val_loss": 14.510061740875244, "val_acc": 55.0, "val_auroc": 0.53, "time": 689.08}
{"epoch": 36, "training_loss": 48.681386947631836, "training_acc": 68.75, "val_loss": 13.661879301071167, "val_acc": 50.0, "val_auroc": 0.6, "time": 708.99}
{"epoch": 37, "training_loss": 41.177796363830566, "training_acc": 82.5, "val_loss": 13.932770490646362, "val_acc": 50.0, "val_auroc": 0.6, "time": 727.78}
{"epoch": 38, "training_loss": 39.558488845825195, "training_acc": 88.75, "val_loss": 14.262634515762329, "val_acc": 70.0, "val_auroc": 0.6, "time": 745.91}
{"epoch": 39, "training_loss": 40.30390548706055, "training_acc": 87.5, "val_loss": 13.778669834136963, "val_acc": 55.0, "val_auroc": 0.59, "time": 763.03}
{"epoch": 40, "training_loss": 35.90585422515869, "training_acc": 92.5, "val_loss": 14.08226490020752, "val_acc": 70.0, "val_auroc": 0.62, "time": 780.97}
{"epoch": 41, "training_loss": 36.08237981796265, "training_acc": 90.0, "val_loss": 13.471945524215698, "val_acc": 55.0, "val_auroc": 0.62, "time": 798.3}
{"epoch": 42, "training_loss": 32.88691997528076, "training_acc": 98.75, "val_loss": 13.623151779174805, "val_acc": 60.0, "val_auroc": 0.6, "time": 815.08}
{"epoch": 43, "training_loss": 31.61142921447754, "training_acc": 97.5, "val_loss": 13.691657781600952, "val_acc": 65.0, "val_auroc": 0.61, "time": 832.77}
{"epoch": 44, "training_loss": 30.746402740478516, "training_acc": 98.75, "val_loss": 13.647817373275757, "val_acc": 65.0, "val_auroc": 0.64, "time": 852.4}
{"epoch": 45, "training_loss": 30.161275386810303, "training_acc": 98.75, "val_loss": 14.403151273727417, "val_acc": 55.0, "val_auroc": 0.68, "time": 870.43}
{"epoch": 46, "training_loss": 32.417484283447266, "training_acc": 95.0, "val_loss": 14.126640558242798, "val_acc": 60.0, "val_auroc": 0.65, "time": 888.87}
{"epoch": 47, "training_loss": 29.63509702682495, "training_acc": 100.0, "val_loss": 14.576108455657959, "val_acc": 55.0, "val_auroc": 0.69, "time": 907.71}
{"epoch": 48, "training_loss": 30.995473384857178, "training_acc": 97.5, "val_loss": 13.971295356750488, "val_acc": 60.0, "val_auroc": 0.64, "time": 924.25}
{"epoch": 49, "training_loss": 27.052026748657227, "training_acc": 100.0, "val_loss": 13.681350946426392, "val_acc": 55.0, "val_auroc": 0.66, "time": 941.85}
{"epoch": 50, "training_loss": 26.50318431854248, "training_acc": 98.75, "val_loss": 13.80888819694519, "val_acc": 65.0, "val_auroc": 0.67, "time": 959.7}
{"epoch": 51, "training_loss": 25.552651405334473, "training_acc": 100.0, "val_loss": 13.349452018737793, "val_acc": 65.0, "val_auroc": 0.66, "time": 978.5}
{"epoch": 52, "training_loss": 24.177653312683105, "training_acc": 100.0, "val_loss": 13.645646572113037, "val_acc": 60.0, "val_auroc": 0.66, "time": 997.72}
{"epoch": 53, "training_loss": 23.43080997467041, "training_acc": 100.0, "val_loss": 14.233850240707397, "val_acc": 55.0, "val_auroc": 0.65, "time": 1016.37}
{"epoch": 54, "training_loss": 25.562487602233887, "training_acc": 98.75, "val_loss": 15.083993673324585, "val_acc": 55.0, "val_auroc": 0.66, "time": 1035.27}
{"epoch": 55, "training_loss": 25.62495708465576, "training_acc": 98.75, "val_loss": 14.244298934936523, "val_acc": 55.0, "val_auroc": 0.64, "time": 1053.2}
{"epoch": 56, "training_loss": 22.898015022277832, "training_acc": 100.0, "val_loss": 13.817347288131714, "val_acc": 60.0, "val_auroc": 0.65, "time": 1072.76}
{"epoch": 57, "training_loss": 21.4722843170166, "training_acc": 100.0, "val_loss": 13.808103799819946, "val_acc": 55.0, "val_auroc": 0.66, "time": 1089.94}
{"epoch": 58, "training_loss": 21.578110694885254, "training_acc": 100.0, "val_loss": 14.782291650772095, "val_acc": 55.0, "val_auroc": 0.65, "time": 1108.32}
{"epoch": 59, "training_loss": 22.047729015350342, "training_acc": 98.75, "val_loss": 14.47513461112976, "val_acc": 55.0, "val_auroc": 0.66, "time": 1126.25}
{"epoch": 60, "training_loss": 21.21713876724243, "training_acc": 100.0, "val_loss": 13.6458420753479, "val_acc": 55.0, "val_auroc": 0.65, "time": 1145.43}
{"epoch": 61, "training_loss": 19.914456844329834, "training_acc": 100.0, "val_loss": 14.853905439376831, "val_acc": 55.0, "val_auroc": 0.64, "time": 1164.97}
{"epoch": 62, "training_loss": 20.4464111328125, "training_acc": 100.0, "val_loss": 13.645880222320557, "val_acc": 60.0, "val_auroc": 0.66, "time": 1184.33}
{"epoch": 63, "training_loss": 19.277735233306885, "training_acc": 100.0, "val_loss": 13.628214597702026, "val_acc": 65.0, "val_auroc": 0.67, "time": 1201.15}
{"epoch": 64, "training_loss": 18.54915165901184, "training_acc": 100.0, "val_loss": 14.428200721740723, "val_acc": 60.0, "val_auroc": 0.64, "time": 1220.7}
{"epoch": 65, "training_loss": 18.410932064056396, "training_acc": 100.0, "val_loss": 13.574936389923096, "val_acc": 65.0, "val_auroc": 0.67, "time": 1238.11}
{"epoch": 66, "training_loss": 18.024763345718384, "training_acc": 100.0, "val_loss": 13.758586645126343, "val_acc": 70.0, "val_auroc": 0.67, "time": 1255.22}
{"epoch": 67, "training_loss": 17.638540506362915, "training_acc": 100.0, "val_loss": 14.105479717254639, "val_acc": 65.0, "val_auroc": 0.65, "time": 1274.88}
{"epoch": 68, "training_loss": 17.203452348709106, "training_acc": 100.0, "val_loss": 13.696740865707397, "val_acc": 65.0, "val_auroc": 0.65, "time": 1294.0}
{"epoch": 69, "training_loss": 17.08368468284607, "training_acc": 100.0, "val_loss": 13.798377513885498, "val_acc": 65.0, "val_auroc": 0.65, "time": 1312.55}
{"epoch": 70, "training_loss": 16.825259685516357, "training_acc": 100.0, "val_loss": 14.063551425933838, "val_acc": 65.0, "val_auroc": 0.65, "time": 1330.08}
