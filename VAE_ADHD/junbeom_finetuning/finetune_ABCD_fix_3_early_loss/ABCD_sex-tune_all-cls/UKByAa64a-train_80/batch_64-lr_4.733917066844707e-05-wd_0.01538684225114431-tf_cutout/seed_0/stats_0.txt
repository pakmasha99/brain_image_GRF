"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5328483581543, "training_acc": 52.5, "val_loss": 13.925856351852417, "val_acc": 50.0, "val_auroc": 0.28, "time": 19.19}
{"epoch": 1, "training_loss": 55.280208587646484, "training_acc": 52.5, "val_loss": 13.909081220626831, "val_acc": 50.0, "val_auroc": 0.43, "time": 36.59}
{"epoch": 2, "training_loss": 55.27983283996582, "training_acc": 52.5, "val_loss": 13.886305093765259, "val_acc": 50.0, "val_auroc": 0.35, "time": 55.94}
{"epoch": 3, "training_loss": 55.37352752685547, "training_acc": 52.5, "val_loss": 13.887943029403687, "val_acc": 50.0, "val_auroc": 0.39, "time": 74.63}
{"epoch": 4, "training_loss": 55.24627113342285, "training_acc": 52.5, "val_loss": 13.902921676635742, "val_acc": 50.0, "val_auroc": 0.41, "time": 91.35}
{"epoch": 5, "training_loss": 55.24561786651611, "training_acc": 52.5, "val_loss": 13.909504413604736, "val_acc": 50.0, "val_auroc": 0.41, "time": 109.85}
{"epoch": 6, "training_loss": 55.18859004974365, "training_acc": 53.75, "val_loss": 13.896663188934326, "val_acc": 50.0, "val_auroc": 0.45, "time": 128.82}
{"epoch": 7, "training_loss": 55.04683876037598, "training_acc": 56.25, "val_loss": 13.883068561553955, "val_acc": 50.0, "val_auroc": 0.49, "time": 146.18}
{"epoch": 8, "training_loss": 55.01679801940918, "training_acc": 68.75, "val_loss": 13.886991739273071, "val_acc": 50.0, "val_auroc": 0.5, "time": 162.34}
{"epoch": 9, "training_loss": 55.13758087158203, "training_acc": 58.75, "val_loss": 13.892431259155273, "val_acc": 50.0, "val_auroc": 0.47, "time": 178.77}
{"epoch": 10, "training_loss": 54.56719970703125, "training_acc": 68.75, "val_loss": 13.909075260162354, "val_acc": 50.0, "val_auroc": 0.48, "time": 195.61}
{"epoch": 11, "training_loss": 54.099549293518066, "training_acc": 61.25, "val_loss": 13.945724964141846, "val_acc": 50.0, "val_auroc": 0.48, "time": 212.29}
{"epoch": 12, "training_loss": 54.19472312927246, "training_acc": 53.75, "val_loss": 13.977018594741821, "val_acc": 50.0, "val_auroc": 0.47, "time": 228.65}
{"epoch": 13, "training_loss": 53.28153038024902, "training_acc": 52.5, "val_loss": 14.159882068634033, "val_acc": 50.0, "val_auroc": 0.45, "time": 244.72}
{"epoch": 14, "training_loss": 54.47993755340576, "training_acc": 52.5, "val_loss": 14.191404581069946, "val_acc": 50.0, "val_auroc": 0.52, "time": 261.34}
{"epoch": 15, "training_loss": 53.931711196899414, "training_acc": 52.5, "val_loss": 14.002634286880493, "val_acc": 50.0, "val_auroc": 0.53, "time": 278.44}
{"epoch": 16, "training_loss": 52.55356788635254, "training_acc": 52.5, "val_loss": 14.215372800827026, "val_acc": 50.0, "val_auroc": 0.47, "time": 295.29}
{"epoch": 17, "training_loss": 51.91066360473633, "training_acc": 52.5, "val_loss": 13.972499370574951, "val_acc": 50.0, "val_auroc": 0.5, "time": 311.58}
{"epoch": 18, "training_loss": 50.32632255554199, "training_acc": 70.0, "val_loss": 13.943136930465698, "val_acc": 50.0, "val_auroc": 0.5, "time": 328.01}
{"epoch": 19, "training_loss": 50.99489688873291, "training_acc": 80.0, "val_loss": 13.912324905395508, "val_acc": 50.0, "val_auroc": 0.53, "time": 344.92}
{"epoch": 20, "training_loss": 49.018781661987305, "training_acc": 81.25, "val_loss": 13.929390907287598, "val_acc": 50.0, "val_auroc": 0.55, "time": 362.03}
{"epoch": 21, "training_loss": 47.87491989135742, "training_acc": 86.25, "val_loss": 14.22191858291626, "val_acc": 50.0, "val_auroc": 0.52, "time": 378.36}
{"epoch": 22, "training_loss": 49.46977138519287, "training_acc": 68.75, "val_loss": 14.16896104812622, "val_acc": 50.0, "val_auroc": 0.5, "time": 394.73}
{"epoch": 23, "training_loss": 47.7885856628418, "training_acc": 80.0, "val_loss": 14.121496677398682, "val_acc": 50.0, "val_auroc": 0.5, "time": 412.2}
{"epoch": 24, "training_loss": 45.36203861236572, "training_acc": 78.75, "val_loss": 14.020541906356812, "val_acc": 50.0, "val_auroc": 0.53, "time": 429.7}
{"epoch": 25, "training_loss": 43.96896839141846, "training_acc": 85.0, "val_loss": 13.917587995529175, "val_acc": 55.0, "val_auroc": 0.55, "time": 446.28}
{"epoch": 26, "training_loss": 42.3477144241333, "training_acc": 90.0, "val_loss": 14.125279188156128, "val_acc": 50.0, "val_auroc": 0.5, "time": 464.02}
{"epoch": 27, "training_loss": 43.10489845275879, "training_acc": 82.5, "val_loss": 13.881375789642334, "val_acc": 55.0, "val_auroc": 0.57, "time": 480.88}
{"epoch": 28, "training_loss": 37.716217041015625, "training_acc": 93.75, "val_loss": 14.02855634689331, "val_acc": 70.0, "val_auroc": 0.57, "time": 498.97}
{"epoch": 29, "training_loss": 37.382880210876465, "training_acc": 92.5, "val_loss": 14.382941722869873, "val_acc": 50.0, "val_auroc": 0.46, "time": 515.86}
{"epoch": 30, "training_loss": 38.91934776306152, "training_acc": 87.5, "val_loss": 14.181016683578491, "val_acc": 65.0, "val_auroc": 0.56, "time": 533.81}
{"epoch": 31, "training_loss": 34.651737689971924, "training_acc": 93.75, "val_loss": 14.394121170043945, "val_acc": 60.0, "val_auroc": 0.56, "time": 551.18}
{"epoch": 32, "training_loss": 32.988057136535645, "training_acc": 96.25, "val_loss": 14.250787496566772, "val_acc": 50.0, "val_auroc": 0.54, "time": 569.29}
{"epoch": 33, "training_loss": 34.954739570617676, "training_acc": 93.75, "val_loss": 14.240784645080566, "val_acc": 65.0, "val_auroc": 0.58, "time": 585.88}
{"epoch": 34, "training_loss": 30.820457458496094, "training_acc": 96.25, "val_loss": 14.401651620864868, "val_acc": 50.0, "val_auroc": 0.53, "time": 602.67}
{"epoch": 35, "training_loss": 32.58544158935547, "training_acc": 93.75, "val_loss": 14.642924070358276, "val_acc": 40.0, "val_auroc": 0.56, "time": 618.73}
{"epoch": 36, "training_loss": 32.05930519104004, "training_acc": 95.0, "val_loss": 14.307445287704468, "val_acc": 65.0, "val_auroc": 0.57, "time": 636.17}
{"epoch": 37, "training_loss": 29.24217987060547, "training_acc": 96.25, "val_loss": 14.394234418869019, "val_acc": 60.0, "val_auroc": 0.53, "time": 652.79}
{"epoch": 38, "training_loss": 28.480834007263184, "training_acc": 96.25, "val_loss": 14.762896299362183, "val_acc": 60.0, "val_auroc": 0.51, "time": 669.19}
{"epoch": 39, "training_loss": 27.62804937362671, "training_acc": 96.25, "val_loss": 14.860376119613647, "val_acc": 60.0, "val_auroc": 0.5, "time": 686.14}
{"epoch": 40, "training_loss": 27.60446262359619, "training_acc": 96.25, "val_loss": 15.03325343132019, "val_acc": 55.0, "val_auroc": 0.5, "time": 703.18}
{"epoch": 41, "training_loss": 27.888383865356445, "training_acc": 96.25, "val_loss": 14.75611686706543, "val_acc": 55.0, "val_auroc": 0.53, "time": 719.44}
{"epoch": 42, "training_loss": 25.92028522491455, "training_acc": 96.25, "val_loss": 14.48415756225586, "val_acc": 60.0, "val_auroc": 0.55, "time": 737.51}
{"epoch": 43, "training_loss": 24.9829044342041, "training_acc": 96.25, "val_loss": 14.440387487411499, "val_acc": 55.0, "val_auroc": 0.56, "time": 753.72}
{"epoch": 44, "training_loss": 25.00947618484497, "training_acc": 96.25, "val_loss": 14.14366602897644, "val_acc": 65.0, "val_auroc": 0.59, "time": 771.32}
{"epoch": 45, "training_loss": 24.180266857147217, "training_acc": 96.25, "val_loss": 16.154507398605347, "val_acc": 50.0, "val_auroc": 0.43, "time": 787.88}
{"epoch": 46, "training_loss": 30.431920051574707, "training_acc": 92.5, "val_loss": 14.770174026489258, "val_acc": 45.0, "val_auroc": 0.58, "time": 804.31}
