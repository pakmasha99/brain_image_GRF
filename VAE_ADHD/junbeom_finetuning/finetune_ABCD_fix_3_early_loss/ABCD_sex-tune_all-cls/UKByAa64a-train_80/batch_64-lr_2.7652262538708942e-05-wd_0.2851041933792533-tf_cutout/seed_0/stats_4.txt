"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.44636249542236, "training_acc": 50.0, "val_loss": 13.82854700088501, "val_acc": 55.0, "val_auroc": 0.515, "time": 19.43}
{"epoch": 1, "training_loss": 55.37744617462158, "training_acc": 50.0, "val_loss": 13.818652629852295, "val_acc": 55.0, "val_auroc": 0.465, "time": 37.51}
{"epoch": 2, "training_loss": 55.4160270690918, "training_acc": 51.25, "val_loss": 13.786133527755737, "val_acc": 55.0, "val_auroc": 0.525, "time": 56.01}
{"epoch": 3, "training_loss": 55.23820877075195, "training_acc": 51.25, "val_loss": 13.803764581680298, "val_acc": 55.0, "val_auroc": 0.485, "time": 74.06}
{"epoch": 4, "training_loss": 55.140642166137695, "training_acc": 51.25, "val_loss": 13.890632390975952, "val_acc": 55.0, "val_auroc": 0.354, "time": 92.69}
{"epoch": 5, "training_loss": 55.20316028594971, "training_acc": 51.25, "val_loss": 13.861356973648071, "val_acc": 55.0, "val_auroc": 0.475, "time": 112.49}
{"epoch": 6, "training_loss": 54.88347911834717, "training_acc": 60.0, "val_loss": 13.896797895431519, "val_acc": 55.0, "val_auroc": 0.424, "time": 130.54}
{"epoch": 7, "training_loss": 54.76571750640869, "training_acc": 66.25, "val_loss": 13.95369291305542, "val_acc": 55.0, "val_auroc": 0.374, "time": 149.03}
{"epoch": 8, "training_loss": 54.409393310546875, "training_acc": 72.5, "val_loss": 13.959702253341675, "val_acc": 55.0, "val_auroc": 0.434, "time": 167.67}
{"epoch": 9, "training_loss": 54.38237762451172, "training_acc": 63.75, "val_loss": 13.992098569869995, "val_acc": 55.0, "val_auroc": 0.444, "time": 185.76}
{"epoch": 10, "training_loss": 54.07865905761719, "training_acc": 65.0, "val_loss": 13.96997332572937, "val_acc": 55.0, "val_auroc": 0.434, "time": 203.83}
{"epoch": 11, "training_loss": 53.565672874450684, "training_acc": 72.5, "val_loss": 13.790020942687988, "val_acc": 55.0, "val_auroc": 0.465, "time": 220.84}
{"epoch": 12, "training_loss": 53.94088554382324, "training_acc": 56.25, "val_loss": 13.939235210418701, "val_acc": 55.0, "val_auroc": 0.485, "time": 238.84}
{"epoch": 13, "training_loss": 53.166046142578125, "training_acc": 75.0, "val_loss": 14.070991277694702, "val_acc": 55.0, "val_auroc": 0.444, "time": 258.32}
{"epoch": 14, "training_loss": 53.232627868652344, "training_acc": 72.5, "val_loss": 13.940744400024414, "val_acc": 55.0, "val_auroc": 0.424, "time": 276.18}
{"epoch": 15, "training_loss": 53.05316925048828, "training_acc": 67.5, "val_loss": 14.053179025650024, "val_acc": 55.0, "val_auroc": 0.465, "time": 293.53}
{"epoch": 16, "training_loss": 52.07895278930664, "training_acc": 85.0, "val_loss": 13.712902069091797, "val_acc": 55.0, "val_auroc": 0.515, "time": 310.12}
{"epoch": 17, "training_loss": 53.978628158569336, "training_acc": 52.5, "val_loss": 13.732836246490479, "val_acc": 55.0, "val_auroc": 0.505, "time": 329.16}
{"epoch": 18, "training_loss": 54.61726188659668, "training_acc": 51.25, "val_loss": 13.793429136276245, "val_acc": 55.0, "val_auroc": 0.465, "time": 346.36}
{"epoch": 19, "training_loss": 54.00870704650879, "training_acc": 51.25, "val_loss": 13.935593366622925, "val_acc": 55.0, "val_auroc": 0.444, "time": 364.93}
{"epoch": 20, "training_loss": 53.92374610900879, "training_acc": 78.75, "val_loss": 13.95750880241394, "val_acc": 55.0, "val_auroc": 0.434, "time": 381.98}
{"epoch": 21, "training_loss": 52.727234840393066, "training_acc": 76.25, "val_loss": 13.847723007202148, "val_acc": 55.0, "val_auroc": 0.444, "time": 400.94}
{"epoch": 22, "training_loss": 52.128546714782715, "training_acc": 68.75, "val_loss": 14.035259485244751, "val_acc": 55.0, "val_auroc": 0.485, "time": 418.38}
{"epoch": 23, "training_loss": 51.22611904144287, "training_acc": 81.25, "val_loss": 13.771933317184448, "val_acc": 55.0, "val_auroc": 0.485, "time": 436.07}
{"epoch": 24, "training_loss": 50.84950542449951, "training_acc": 71.25, "val_loss": 14.192606210708618, "val_acc": 55.0, "val_auroc": 0.505, "time": 453.55}
{"epoch": 25, "training_loss": 51.9126091003418, "training_acc": 73.75, "val_loss": 13.684715032577515, "val_acc": 55.0, "val_auroc": 0.525, "time": 473.86}
{"epoch": 26, "training_loss": 50.257463455200195, "training_acc": 65.0, "val_loss": 13.747886419296265, "val_acc": 55.0, "val_auroc": 0.525, "time": 490.93}
{"epoch": 27, "training_loss": 48.879655838012695, "training_acc": 78.75, "val_loss": 14.07186508178711, "val_acc": 55.0, "val_auroc": 0.535, "time": 507.92}
{"epoch": 28, "training_loss": 48.805460929870605, "training_acc": 78.75, "val_loss": 13.845275640487671, "val_acc": 55.0, "val_auroc": 0.525, "time": 524.81}
{"epoch": 29, "training_loss": 47.17625045776367, "training_acc": 81.25, "val_loss": 13.979898691177368, "val_acc": 55.0, "val_auroc": 0.525, "time": 543.0}
{"epoch": 30, "training_loss": 45.52576446533203, "training_acc": 86.25, "val_loss": 14.036881923675537, "val_acc": 55.0, "val_auroc": 0.525, "time": 560.46}
{"epoch": 31, "training_loss": 43.572264671325684, "training_acc": 91.25, "val_loss": 13.956083059310913, "val_acc": 60.0, "val_auroc": 0.525, "time": 578.27}
{"epoch": 32, "training_loss": 42.10825729370117, "training_acc": 91.25, "val_loss": 14.010528326034546, "val_acc": 55.0, "val_auroc": 0.545, "time": 594.64}
{"epoch": 33, "training_loss": 41.330196380615234, "training_acc": 90.0, "val_loss": 14.523028135299683, "val_acc": 50.0, "val_auroc": 0.515, "time": 614.45}
{"epoch": 34, "training_loss": 43.82949256896973, "training_acc": 81.25, "val_loss": 13.7602698802948, "val_acc": 60.0, "val_auroc": 0.515, "time": 632.66}
{"epoch": 35, "training_loss": 42.55038833618164, "training_acc": 85.0, "val_loss": 14.52983021736145, "val_acc": 60.0, "val_auroc": 0.545, "time": 649.3}
{"epoch": 36, "training_loss": 42.68096160888672, "training_acc": 85.0, "val_loss": 13.847264051437378, "val_acc": 55.0, "val_auroc": 0.566, "time": 665.96}
{"epoch": 37, "training_loss": 45.09739875793457, "training_acc": 70.0, "val_loss": 14.726982116699219, "val_acc": 50.0, "val_auroc": 0.556, "time": 684.82}
{"epoch": 38, "training_loss": 43.41154670715332, "training_acc": 86.25, "val_loss": 13.885250091552734, "val_acc": 60.0, "val_auroc": 0.525, "time": 706.07}
{"epoch": 39, "training_loss": 40.45083999633789, "training_acc": 86.25, "val_loss": 14.33820366859436, "val_acc": 55.0, "val_auroc": 0.545, "time": 724.29}
{"epoch": 40, "training_loss": 36.8908109664917, "training_acc": 95.0, "val_loss": 14.149245023727417, "val_acc": 55.0, "val_auroc": 0.566, "time": 741.28}
{"epoch": 41, "training_loss": 34.78840684890747, "training_acc": 96.25, "val_loss": 14.16045069694519, "val_acc": 55.0, "val_auroc": 0.556, "time": 760.71}
{"epoch": 42, "training_loss": 34.62483882904053, "training_acc": 96.25, "val_loss": 14.300390481948853, "val_acc": 60.0, "val_auroc": 0.556, "time": 778.79}
{"epoch": 43, "training_loss": 32.616722106933594, "training_acc": 96.25, "val_loss": 13.72751235961914, "val_acc": 65.0, "val_auroc": 0.586, "time": 795.56}
{"epoch": 44, "training_loss": 35.01181221008301, "training_acc": 90.0, "val_loss": 14.998353719711304, "val_acc": 50.0, "val_auroc": 0.566, "time": 812.9}
