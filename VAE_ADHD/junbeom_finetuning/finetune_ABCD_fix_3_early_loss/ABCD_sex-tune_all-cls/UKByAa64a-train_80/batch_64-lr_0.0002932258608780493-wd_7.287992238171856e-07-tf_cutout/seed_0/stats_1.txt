"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 59.42714500427246, "training_acc": 41.25, "val_loss": 14.055718183517456, "val_acc": 50.0, "val_auroc": 0.46, "time": 17.71}
{"epoch": 1, "training_loss": 60.111313819885254, "training_acc": 47.5, "val_loss": 14.222747087478638, "val_acc": 50.0, "val_auroc": 0.59, "time": 34.0}
{"epoch": 2, "training_loss": 58.360575675964355, "training_acc": 50.0, "val_loss": 24.905173778533936, "val_acc": 50.0, "val_auroc": 0.49, "time": 50.27}
{"epoch": 3, "training_loss": 84.9435806274414, "training_acc": 52.5, "val_loss": 13.890726566314697, "val_acc": 50.0, "val_auroc": 0.65, "time": 66.5}
{"epoch": 4, "training_loss": 55.81130027770996, "training_acc": 47.5, "val_loss": 13.849023580551147, "val_acc": 50.0, "val_auroc": 0.66, "time": 83.69}
{"epoch": 5, "training_loss": 55.27814865112305, "training_acc": 52.5, "val_loss": 17.126377820968628, "val_acc": 50.0, "val_auroc": 0.52, "time": 99.66}
{"epoch": 6, "training_loss": 64.18588256835938, "training_acc": 52.5, "val_loss": 14.140180349349976, "val_acc": 50.0, "val_auroc": 0.54, "time": 118.24}
{"epoch": 7, "training_loss": 56.4248046875, "training_acc": 50.0, "val_loss": 14.153732061386108, "val_acc": 50.0, "val_auroc": 0.6, "time": 134.35}
{"epoch": 8, "training_loss": 55.93330669403076, "training_acc": 52.5, "val_loss": 13.903000354766846, "val_acc": 50.0, "val_auroc": 0.58, "time": 150.41}
{"epoch": 9, "training_loss": 55.152456283569336, "training_acc": 56.25, "val_loss": 14.037429094314575, "val_acc": 50.0, "val_auroc": 0.51, "time": 167.43}
{"epoch": 10, "training_loss": 56.59527778625488, "training_acc": 47.5, "val_loss": 13.872278928756714, "val_acc": 50.0, "val_auroc": 0.49, "time": 182.96}
{"epoch": 11, "training_loss": 55.40165328979492, "training_acc": 50.0, "val_loss": 14.097503423690796, "val_acc": 50.0, "val_auroc": 0.57, "time": 198.4}
{"epoch": 12, "training_loss": 55.77845287322998, "training_acc": 52.5, "val_loss": 14.162954092025757, "val_acc": 50.0, "val_auroc": 0.64, "time": 215.29}
{"epoch": 13, "training_loss": 56.021493911743164, "training_acc": 52.5, "val_loss": 13.97494912147522, "val_acc": 50.0, "val_auroc": 0.67, "time": 231.87}
{"epoch": 14, "training_loss": 55.654677391052246, "training_acc": 52.5, "val_loss": 13.964592218399048, "val_acc": 50.0, "val_auroc": 0.64, "time": 247.86}
{"epoch": 15, "training_loss": 55.427717208862305, "training_acc": 52.5, "val_loss": 14.076184034347534, "val_acc": 50.0, "val_auroc": 0.64, "time": 264.15}
{"epoch": 16, "training_loss": 55.74087047576904, "training_acc": 52.5, "val_loss": 14.121675491333008, "val_acc": 50.0, "val_auroc": 0.63, "time": 280.47}
{"epoch": 17, "training_loss": 55.854896545410156, "training_acc": 52.5, "val_loss": 13.96639108657837, "val_acc": 50.0, "val_auroc": 0.61, "time": 296.86}
{"epoch": 18, "training_loss": 55.38268280029297, "training_acc": 52.5, "val_loss": 13.851665258407593, "val_acc": 50.0, "val_auroc": 0.59, "time": 312.9}
{"epoch": 19, "training_loss": 55.30669021606445, "training_acc": 57.5, "val_loss": 13.923642635345459, "val_acc": 50.0, "val_auroc": 0.6, "time": 329.49}
{"epoch": 20, "training_loss": 56.03826332092285, "training_acc": 47.5, "val_loss": 13.950283527374268, "val_acc": 50.0, "val_auroc": 0.58, "time": 346.59}
{"epoch": 21, "training_loss": 56.04095458984375, "training_acc": 47.5, "val_loss": 13.854013681411743, "val_acc": 50.0, "val_auroc": 0.69, "time": 362.43}
{"epoch": 22, "training_loss": 55.380794525146484, "training_acc": 50.0, "val_loss": 13.943005800247192, "val_acc": 50.0, "val_auroc": 0.6, "time": 378.59}
{"epoch": 23, "training_loss": 55.34914207458496, "training_acc": 52.5, "val_loss": 14.102442264556885, "val_acc": 50.0, "val_auroc": 0.62, "time": 396.34}
