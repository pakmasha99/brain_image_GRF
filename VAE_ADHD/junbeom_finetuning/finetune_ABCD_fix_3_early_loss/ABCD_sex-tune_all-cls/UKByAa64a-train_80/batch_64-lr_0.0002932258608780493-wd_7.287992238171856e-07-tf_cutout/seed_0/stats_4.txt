"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 58.71142292022705, "training_acc": 41.25, "val_loss": 13.913193941116333, "val_acc": 55.0, "val_auroc": 0.495, "time": 19.96}
{"epoch": 1, "training_loss": 164.7353973388672, "training_acc": 42.5, "val_loss": 14.701937437057495, "val_acc": 55.0, "val_auroc": 0.505, "time": 36.74}
{"epoch": 2, "training_loss": 55.458173751831055, "training_acc": 56.25, "val_loss": 25.188426971435547, "val_acc": 55.0, "val_auroc": 0.444, "time": 52.89}
{"epoch": 3, "training_loss": 95.87794589996338, "training_acc": 51.25, "val_loss": 14.153722524642944, "val_acc": 55.0, "val_auroc": 0.424, "time": 69.1}
{"epoch": 4, "training_loss": 56.325931549072266, "training_acc": 48.75, "val_loss": 18.223484754562378, "val_acc": 55.0, "val_auroc": 0.455, "time": 85.09}
{"epoch": 5, "training_loss": 74.53481388092041, "training_acc": 51.25, "val_loss": 14.524606466293335, "val_acc": 55.0, "val_auroc": 0.535, "time": 101.08}
{"epoch": 6, "training_loss": 56.46412658691406, "training_acc": 48.75, "val_loss": 14.19957160949707, "val_acc": 55.0, "val_auroc": 0.414, "time": 117.08}
{"epoch": 7, "training_loss": 58.0623664855957, "training_acc": 51.25, "val_loss": 14.175212383270264, "val_acc": 55.0, "val_auroc": 0.485, "time": 134.52}
{"epoch": 8, "training_loss": 55.936577796936035, "training_acc": 48.75, "val_loss": 15.105165243148804, "val_acc": 50.0, "val_auroc": 0.515, "time": 150.87}
{"epoch": 9, "training_loss": 57.95415496826172, "training_acc": 48.75, "val_loss": 13.998922109603882, "val_acc": 55.0, "val_auroc": 0.444, "time": 167.1}
{"epoch": 10, "training_loss": 57.76336669921875, "training_acc": 51.25, "val_loss": 13.882020711898804, "val_acc": 55.0, "val_auroc": 0.455, "time": 183.59}
{"epoch": 11, "training_loss": 56.859951972961426, "training_acc": 51.25, "val_loss": 13.819512128829956, "val_acc": 55.0, "val_auroc": 0.545, "time": 199.28}
{"epoch": 12, "training_loss": 55.324764251708984, "training_acc": 53.75, "val_loss": 13.88850212097168, "val_acc": 55.0, "val_auroc": 0.535, "time": 216.42}
{"epoch": 13, "training_loss": 55.458889961242676, "training_acc": 48.75, "val_loss": 13.895972967147827, "val_acc": 55.0, "val_auroc": 0.545, "time": 234.29}
{"epoch": 14, "training_loss": 55.61850833892822, "training_acc": 46.25, "val_loss": 13.845586776733398, "val_acc": 55.0, "val_auroc": 0.545, "time": 251.0}
{"epoch": 15, "training_loss": 55.488624572753906, "training_acc": 56.25, "val_loss": 13.815969228744507, "val_acc": 55.0, "val_auroc": 0.545, "time": 269.28}
{"epoch": 16, "training_loss": 55.17236804962158, "training_acc": 52.5, "val_loss": 13.748403787612915, "val_acc": 55.0, "val_auroc": 0.545, "time": 285.7}
{"epoch": 17, "training_loss": 55.96682548522949, "training_acc": 51.25, "val_loss": 13.891690969467163, "val_acc": 55.0, "val_auroc": 0.545, "time": 304.67}
{"epoch": 18, "training_loss": 56.734039306640625, "training_acc": 51.25, "val_loss": 13.767684698104858, "val_acc": 55.0, "val_auroc": 0.535, "time": 321.63}
{"epoch": 19, "training_loss": 55.609416007995605, "training_acc": 51.25, "val_loss": 13.874653577804565, "val_acc": 55.0, "val_auroc": 0.545, "time": 337.88}
{"epoch": 20, "training_loss": 55.45221138000488, "training_acc": 48.75, "val_loss": 14.160735607147217, "val_acc": 55.0, "val_auroc": 0.535, "time": 355.1}
{"epoch": 21, "training_loss": 56.04885673522949, "training_acc": 48.75, "val_loss": 14.120079278945923, "val_acc": 55.0, "val_auroc": 0.535, "time": 370.72}
{"epoch": 22, "training_loss": 55.858795166015625, "training_acc": 48.75, "val_loss": 13.909322023391724, "val_acc": 55.0, "val_auroc": 0.535, "time": 387.56}
{"epoch": 23, "training_loss": 55.39953136444092, "training_acc": 52.5, "val_loss": 13.774223327636719, "val_acc": 55.0, "val_auroc": 0.545, "time": 403.87}
{"epoch": 24, "training_loss": 55.48374557495117, "training_acc": 51.25, "val_loss": 13.748763799667358, "val_acc": 55.0, "val_auroc": 0.535, "time": 419.46}
{"epoch": 25, "training_loss": 55.529741287231445, "training_acc": 51.25, "val_loss": 13.753575086593628, "val_acc": 55.0, "val_auroc": 0.556, "time": 436.36}
{"epoch": 26, "training_loss": 55.43002891540527, "training_acc": 51.25, "val_loss": 13.753798007965088, "val_acc": 55.0, "val_auroc": 0.545, "time": 453.99}
{"epoch": 27, "training_loss": 55.38727569580078, "training_acc": 51.25, "val_loss": 13.75969409942627, "val_acc": 55.0, "val_auroc": 0.545, "time": 469.67}
{"epoch": 28, "training_loss": 55.3432559967041, "training_acc": 51.25, "val_loss": 13.809750080108643, "val_acc": 55.0, "val_auroc": 0.535, "time": 486.79}
{"epoch": 29, "training_loss": 55.51968574523926, "training_acc": 45.0, "val_loss": 13.851889371871948, "val_acc": 55.0, "val_auroc": 0.556, "time": 502.89}
{"epoch": 30, "training_loss": 55.304731369018555, "training_acc": 60.0, "val_loss": 13.800572156906128, "val_acc": 55.0, "val_auroc": 0.545, "time": 519.07}
{"epoch": 31, "training_loss": 55.326284408569336, "training_acc": 52.5, "val_loss": 13.783019781112671, "val_acc": 55.0, "val_auroc": 0.535, "time": 536.56}
{"epoch": 32, "training_loss": 55.23843574523926, "training_acc": 51.25, "val_loss": 13.784492015838623, "val_acc": 55.0, "val_auroc": 0.535, "time": 552.72}
{"epoch": 33, "training_loss": 55.23635959625244, "training_acc": 52.5, "val_loss": 13.778825998306274, "val_acc": 55.0, "val_auroc": 0.535, "time": 568.69}
{"epoch": 34, "training_loss": 55.2403678894043, "training_acc": 53.75, "val_loss": 13.773620128631592, "val_acc": 55.0, "val_auroc": 0.556, "time": 586.4}
{"epoch": 35, "training_loss": 55.216909408569336, "training_acc": 53.75, "val_loss": 13.767380714416504, "val_acc": 55.0, "val_auroc": 0.556, "time": 603.43}
