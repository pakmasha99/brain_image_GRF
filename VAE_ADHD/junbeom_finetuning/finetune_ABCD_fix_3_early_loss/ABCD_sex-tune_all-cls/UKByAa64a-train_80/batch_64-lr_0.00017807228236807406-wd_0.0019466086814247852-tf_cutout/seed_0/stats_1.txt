"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.49396514892578, "training_acc": 52.5, "val_loss": 13.992676734924316, "val_acc": 50.0, "val_auroc": 0.21, "time": 19.61}
{"epoch": 1, "training_loss": 55.47206115722656, "training_acc": 52.5, "val_loss": 13.95272970199585, "val_acc": 50.0, "val_auroc": 0.46, "time": 37.82}
{"epoch": 2, "training_loss": 55.511775970458984, "training_acc": 52.5, "val_loss": 13.929226398468018, "val_acc": 50.0, "val_auroc": 0.69, "time": 56.44}
{"epoch": 3, "training_loss": 55.417236328125, "training_acc": 52.5, "val_loss": 13.86975646018982, "val_acc": 50.0, "val_auroc": 0.55, "time": 74.86}
{"epoch": 4, "training_loss": 55.37448501586914, "training_acc": 52.5, "val_loss": 13.866249322891235, "val_acc": 50.0, "val_auroc": 0.41, "time": 92.68}
{"epoch": 5, "training_loss": 55.42675018310547, "training_acc": 52.5, "val_loss": 13.896180391311646, "val_acc": 50.0, "val_auroc": 0.61, "time": 110.39}
{"epoch": 6, "training_loss": 55.38652038574219, "training_acc": 52.5, "val_loss": 13.917888402938843, "val_acc": 50.0, "val_auroc": 0.53, "time": 127.7}
{"epoch": 7, "training_loss": 55.39619159698486, "training_acc": 52.5, "val_loss": 13.900768756866455, "val_acc": 50.0, "val_auroc": 0.53, "time": 144.89}
{"epoch": 8, "training_loss": 55.34706974029541, "training_acc": 52.5, "val_loss": 13.8914155960083, "val_acc": 50.0, "val_auroc": 0.5, "time": 162.5}
{"epoch": 9, "training_loss": 55.35361099243164, "training_acc": 52.5, "val_loss": 13.864177465438843, "val_acc": 50.0, "val_auroc": 0.51, "time": 179.48}
{"epoch": 10, "training_loss": 55.530341148376465, "training_acc": 47.5, "val_loss": 13.863312005996704, "val_acc": 50.0, "val_auroc": 0.57, "time": 196.58}
{"epoch": 11, "training_loss": 55.42470359802246, "training_acc": 50.0, "val_loss": 13.903334140777588, "val_acc": 50.0, "val_auroc": 0.64, "time": 214.41}
{"epoch": 12, "training_loss": 55.33445358276367, "training_acc": 52.5, "val_loss": 13.995693922042847, "val_acc": 50.0, "val_auroc": 0.77, "time": 231.83}
{"epoch": 13, "training_loss": 55.555076599121094, "training_acc": 52.5, "val_loss": 14.03410792350769, "val_acc": 50.0, "val_auroc": 0.66, "time": 248.69}
{"epoch": 14, "training_loss": 55.68651008605957, "training_acc": 52.5, "val_loss": 14.100030660629272, "val_acc": 50.0, "val_auroc": 0.71, "time": 265.85}
{"epoch": 15, "training_loss": 55.77872657775879, "training_acc": 52.5, "val_loss": 14.161258935928345, "val_acc": 50.0, "val_auroc": 0.72, "time": 283.37}
{"epoch": 16, "training_loss": 55.988285064697266, "training_acc": 52.5, "val_loss": 14.102175235748291, "val_acc": 50.0, "val_auroc": 0.74, "time": 300.33}
{"epoch": 17, "training_loss": 55.755027770996094, "training_acc": 52.5, "val_loss": 13.943703174591064, "val_acc": 50.0, "val_auroc": 0.7, "time": 317.58}
{"epoch": 18, "training_loss": 55.36382865905762, "training_acc": 52.5, "val_loss": 13.863319158554077, "val_acc": 50.0, "val_auroc": 0.4, "time": 335.24}
{"epoch": 19, "training_loss": 55.40547752380371, "training_acc": 57.5, "val_loss": 13.89405608177185, "val_acc": 50.0, "val_auroc": 0.4, "time": 352.39}
{"epoch": 20, "training_loss": 55.80378341674805, "training_acc": 47.5, "val_loss": 13.912326097488403, "val_acc": 50.0, "val_auroc": 0.42, "time": 369.5}
{"epoch": 21, "training_loss": 55.86654472351074, "training_acc": 47.5, "val_loss": 13.862614631652832, "val_acc": 50.0, "val_auroc": 0.56, "time": 386.85}
{"epoch": 22, "training_loss": 55.38984680175781, "training_acc": 50.0, "val_loss": 13.932937383651733, "val_acc": 50.0, "val_auroc": 0.73, "time": 403.64}
{"epoch": 23, "training_loss": 55.345787048339844, "training_acc": 52.5, "val_loss": 14.056570529937744, "val_acc": 50.0, "val_auroc": 0.79, "time": 421.09}
{"epoch": 24, "training_loss": 55.66850185394287, "training_acc": 52.5, "val_loss": 14.088109731674194, "val_acc": 50.0, "val_auroc": 0.72, "time": 438.26}
{"epoch": 25, "training_loss": 55.752458572387695, "training_acc": 52.5, "val_loss": 13.993014097213745, "val_acc": 50.0, "val_auroc": 0.77, "time": 455.21}
{"epoch": 26, "training_loss": 55.5302791595459, "training_acc": 52.5, "val_loss": 13.919739723205566, "val_acc": 50.0, "val_auroc": 0.69, "time": 472.5}
{"epoch": 27, "training_loss": 55.39460372924805, "training_acc": 52.5, "val_loss": 13.891725540161133, "val_acc": 50.0, "val_auroc": 0.56, "time": 489.31}
{"epoch": 28, "training_loss": 55.452714920043945, "training_acc": 52.5, "val_loss": 13.86584997177124, "val_acc": 50.0, "val_auroc": 0.51, "time": 506.37}
{"epoch": 29, "training_loss": 55.47464179992676, "training_acc": 50.0, "val_loss": 13.872976303100586, "val_acc": 50.0, "val_auroc": 0.42, "time": 523.14}
{"epoch": 30, "training_loss": 55.623169898986816, "training_acc": 47.5, "val_loss": 13.863394260406494, "val_acc": 50.0, "val_auroc": 0.34, "time": 540.34}
{"epoch": 31, "training_loss": 55.39847373962402, "training_acc": 52.5, "val_loss": 13.9054274559021, "val_acc": 50.0, "val_auroc": 0.51, "time": 557.37}
{"epoch": 32, "training_loss": 55.5429105758667, "training_acc": 52.5, "val_loss": 13.938782215118408, "val_acc": 50.0, "val_auroc": 0.71, "time": 574.43}
{"epoch": 33, "training_loss": 55.4183874130249, "training_acc": 52.5, "val_loss": 13.904322385787964, "val_acc": 50.0, "val_auroc": 0.39, "time": 591.41}
{"epoch": 34, "training_loss": 55.37051963806152, "training_acc": 52.5, "val_loss": 13.893077373504639, "val_acc": 50.0, "val_auroc": 0.43, "time": 608.28}
{"epoch": 35, "training_loss": 55.430152893066406, "training_acc": 52.5, "val_loss": 13.872613906860352, "val_acc": 50.0, "val_auroc": 0.52, "time": 625.22}
{"epoch": 36, "training_loss": 55.27906799316406, "training_acc": 52.5, "val_loss": 13.869508504867554, "val_acc": 50.0, "val_auroc": 0.67, "time": 641.51}
{"epoch": 37, "training_loss": 55.526588439941406, "training_acc": 47.5, "val_loss": 13.921650648117065, "val_acc": 50.0, "val_auroc": 0.35, "time": 657.0}
{"epoch": 38, "training_loss": 56.05009174346924, "training_acc": 47.5, "val_loss": 13.936848640441895, "val_acc": 50.0, "val_auroc": 0.47, "time": 674.1}
{"epoch": 39, "training_loss": 56.07218837738037, "training_acc": 47.5, "val_loss": 13.884642124176025, "val_acc": 50.0, "val_auroc": 0.36, "time": 691.34}
{"epoch": 40, "training_loss": 55.710103034973145, "training_acc": 47.5, "val_loss": 13.863205909729004, "val_acc": 50.0, "val_auroc": 0.35, "time": 708.34}
