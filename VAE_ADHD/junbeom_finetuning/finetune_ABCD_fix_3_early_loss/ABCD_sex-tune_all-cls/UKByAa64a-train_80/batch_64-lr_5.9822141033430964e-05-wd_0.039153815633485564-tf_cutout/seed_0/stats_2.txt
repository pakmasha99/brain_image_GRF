"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.53495788574219, "training_acc": 52.5, "val_loss": 14.003546237945557, "val_acc": 50.0, "val_auroc": 0.36, "time": 19.22}
{"epoch": 1, "training_loss": 55.571044921875, "training_acc": 52.5, "val_loss": 13.904961347579956, "val_acc": 50.0, "val_auroc": 0.62, "time": 37.03}
{"epoch": 2, "training_loss": 55.40823936462402, "training_acc": 52.5, "val_loss": 13.89262080192566, "val_acc": 50.0, "val_auroc": 0.54, "time": 57.39}
{"epoch": 3, "training_loss": 55.41791534423828, "training_acc": 52.5, "val_loss": 13.891147375106812, "val_acc": 50.0, "val_auroc": 0.5, "time": 80.51}
{"epoch": 4, "training_loss": 55.31730365753174, "training_acc": 52.5, "val_loss": 13.964990377426147, "val_acc": 50.0, "val_auroc": 0.21, "time": 97.8}
{"epoch": 5, "training_loss": 55.326393127441406, "training_acc": 52.5, "val_loss": 13.992798328399658, "val_acc": 50.0, "val_auroc": 0.15, "time": 115.77}
{"epoch": 6, "training_loss": 55.344032287597656, "training_acc": 52.5, "val_loss": 13.980541229248047, "val_acc": 50.0, "val_auroc": 0.24, "time": 133.31}
{"epoch": 7, "training_loss": 55.21729850769043, "training_acc": 52.5, "val_loss": 13.984674215316772, "val_acc": 50.0, "val_auroc": 0.33, "time": 152.53}
{"epoch": 8, "training_loss": 55.375365257263184, "training_acc": 52.5, "val_loss": 13.909145593643188, "val_acc": 50.0, "val_auroc": 0.49, "time": 169.13}
{"epoch": 9, "training_loss": 55.25645637512207, "training_acc": 52.5, "val_loss": 13.838919401168823, "val_acc": 50.0, "val_auroc": 0.72, "time": 186.77}
{"epoch": 10, "training_loss": 55.30283451080322, "training_acc": 52.5, "val_loss": 13.86942982673645, "val_acc": 50.0, "val_auroc": 0.54, "time": 204.79}
{"epoch": 11, "training_loss": 55.33039093017578, "training_acc": 52.5, "val_loss": 13.890109062194824, "val_acc": 50.0, "val_auroc": 0.59, "time": 222.84}
{"epoch": 12, "training_loss": 55.35873603820801, "training_acc": 52.5, "val_loss": 13.942841291427612, "val_acc": 50.0, "val_auroc": 0.59, "time": 239.45}
{"epoch": 13, "training_loss": 55.406707763671875, "training_acc": 52.5, "val_loss": 13.926085233688354, "val_acc": 50.0, "val_auroc": 0.56, "time": 256.91}
{"epoch": 14, "training_loss": 55.35122871398926, "training_acc": 52.5, "val_loss": 13.909921646118164, "val_acc": 50.0, "val_auroc": 0.28, "time": 274.01}
{"epoch": 15, "training_loss": 55.43081283569336, "training_acc": 52.5, "val_loss": 13.927537202835083, "val_acc": 50.0, "val_auroc": 0.29, "time": 291.49}
{"epoch": 16, "training_loss": 55.259521484375, "training_acc": 52.5, "val_loss": 13.98226261138916, "val_acc": 50.0, "val_auroc": 0.3, "time": 308.78}
{"epoch": 17, "training_loss": 55.49868965148926, "training_acc": 52.5, "val_loss": 14.012035131454468, "val_acc": 50.0, "val_auroc": 0.61, "time": 325.26}
{"epoch": 18, "training_loss": 55.562896728515625, "training_acc": 52.5, "val_loss": 13.960565328598022, "val_acc": 50.0, "val_auroc": 0.6, "time": 343.26}
{"epoch": 19, "training_loss": 55.36386299133301, "training_acc": 52.5, "val_loss": 13.88706922531128, "val_acc": 50.0, "val_auroc": 0.6, "time": 360.27}
{"epoch": 20, "training_loss": 55.36316108703613, "training_acc": 52.5, "val_loss": 13.86812686920166, "val_acc": 50.0, "val_auroc": 0.41, "time": 376.9}
{"epoch": 21, "training_loss": 55.36758804321289, "training_acc": 52.5, "val_loss": 13.86986494064331, "val_acc": 50.0, "val_auroc": 0.45, "time": 392.97}
{"epoch": 22, "training_loss": 55.34713077545166, "training_acc": 52.5, "val_loss": 13.887078762054443, "val_acc": 50.0, "val_auroc": 0.44, "time": 409.7}
{"epoch": 23, "training_loss": 55.24687957763672, "training_acc": 52.5, "val_loss": 13.919899463653564, "val_acc": 50.0, "val_auroc": 0.51, "time": 427.01}
{"epoch": 24, "training_loss": 55.28573131561279, "training_acc": 52.5, "val_loss": 13.976153135299683, "val_acc": 50.0, "val_auroc": 0.61, "time": 445.17}
{"epoch": 25, "training_loss": 55.44507026672363, "training_acc": 52.5, "val_loss": 14.021167755126953, "val_acc": 50.0, "val_auroc": 0.61, "time": 464.94}
{"epoch": 26, "training_loss": 55.58937740325928, "training_acc": 52.5, "val_loss": 14.053146839141846, "val_acc": 50.0, "val_auroc": 0.4, "time": 481.68}
{"epoch": 27, "training_loss": 55.587082862854004, "training_acc": 52.5, "val_loss": 14.070754051208496, "val_acc": 50.0, "val_auroc": 0.38, "time": 498.08}
{"epoch": 28, "training_loss": 55.64370059967041, "training_acc": 52.5, "val_loss": 13.977125883102417, "val_acc": 50.0, "val_auroc": 0.44, "time": 514.59}
