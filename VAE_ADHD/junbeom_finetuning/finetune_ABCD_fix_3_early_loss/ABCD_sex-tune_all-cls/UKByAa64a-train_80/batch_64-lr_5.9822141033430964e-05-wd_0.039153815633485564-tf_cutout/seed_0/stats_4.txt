"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.49861526489258, "training_acc": 51.25, "val_loss": 13.748258352279663, "val_acc": 55.0, "val_auroc": 0.626, "time": 19.59}
{"epoch": 1, "training_loss": 55.77290153503418, "training_acc": 51.25, "val_loss": 13.756183385848999, "val_acc": 55.0, "val_auroc": 0.626, "time": 36.96}
{"epoch": 2, "training_loss": 55.63224220275879, "training_acc": 51.25, "val_loss": 13.750498294830322, "val_acc": 55.0, "val_auroc": 0.596, "time": 54.22}
{"epoch": 3, "training_loss": 55.65669822692871, "training_acc": 51.25, "val_loss": 13.744865655899048, "val_acc": 55.0, "val_auroc": 0.646, "time": 72.05}
{"epoch": 4, "training_loss": 55.40484809875488, "training_acc": 51.25, "val_loss": 13.801645040512085, "val_acc": 55.0, "val_auroc": 0.657, "time": 89.36}
{"epoch": 5, "training_loss": 55.25443077087402, "training_acc": 51.25, "val_loss": 13.84494423866272, "val_acc": 55.0, "val_auroc": 0.424, "time": 107.7}
{"epoch": 6, "training_loss": 55.2778434753418, "training_acc": 51.25, "val_loss": 13.831619024276733, "val_acc": 55.0, "val_auroc": 0.515, "time": 126.51}
{"epoch": 7, "training_loss": 55.230682373046875, "training_acc": 51.25, "val_loss": 13.795081377029419, "val_acc": 55.0, "val_auroc": 0.606, "time": 146.2}
{"epoch": 8, "training_loss": 55.11688995361328, "training_acc": 51.25, "val_loss": 13.826810121536255, "val_acc": 55.0, "val_auroc": 0.566, "time": 163.35}
{"epoch": 9, "training_loss": 55.180312156677246, "training_acc": 55.0, "val_loss": 13.88479232788086, "val_acc": 55.0, "val_auroc": 0.545, "time": 180.36}
{"epoch": 10, "training_loss": 55.100446701049805, "training_acc": 62.5, "val_loss": 13.814157247543335, "val_acc": 55.0, "val_auroc": 0.556, "time": 198.21}
{"epoch": 11, "training_loss": 54.85987091064453, "training_acc": 55.0, "val_loss": 13.737337589263916, "val_acc": 55.0, "val_auroc": 0.586, "time": 215.77}
{"epoch": 12, "training_loss": 55.07236862182617, "training_acc": 51.25, "val_loss": 13.736238479614258, "val_acc": 55.0, "val_auroc": 0.576, "time": 233.1}
{"epoch": 13, "training_loss": 54.904236793518066, "training_acc": 51.25, "val_loss": 13.777636289596558, "val_acc": 55.0, "val_auroc": 0.596, "time": 251.63}
{"epoch": 14, "training_loss": 54.69191932678223, "training_acc": 52.5, "val_loss": 13.824988603591919, "val_acc": 55.0, "val_auroc": 0.586, "time": 272.49}
{"epoch": 15, "training_loss": 54.79761028289795, "training_acc": 77.5, "val_loss": 13.79065752029419, "val_acc": 55.0, "val_auroc": 0.545, "time": 291.0}
{"epoch": 16, "training_loss": 54.317416191101074, "training_acc": 67.5, "val_loss": 13.705123662948608, "val_acc": 55.0, "val_auroc": 0.606, "time": 308.26}
{"epoch": 17, "training_loss": 55.02843761444092, "training_acc": 51.25, "val_loss": 13.731640577316284, "val_acc": 55.0, "val_auroc": 0.566, "time": 327.64}
{"epoch": 18, "training_loss": 55.10136795043945, "training_acc": 51.25, "val_loss": 13.77242922782898, "val_acc": 55.0, "val_auroc": 0.566, "time": 345.54}
{"epoch": 19, "training_loss": 54.811081886291504, "training_acc": 51.25, "val_loss": 13.864309787750244, "val_acc": 55.0, "val_auroc": 0.667, "time": 362.5}
{"epoch": 20, "training_loss": 54.90845775604248, "training_acc": 63.75, "val_loss": 13.882567882537842, "val_acc": 55.0, "val_auroc": 0.636, "time": 379.63}
{"epoch": 21, "training_loss": 54.573570251464844, "training_acc": 56.25, "val_loss": 13.780254125595093, "val_acc": 55.0, "val_auroc": 0.586, "time": 398.45}
{"epoch": 22, "training_loss": 54.34517860412598, "training_acc": 72.5, "val_loss": 13.73111367225647, "val_acc": 55.0, "val_auroc": 0.566, "time": 417.31}
{"epoch": 23, "training_loss": 53.78307914733887, "training_acc": 66.25, "val_loss": 13.720158338546753, "val_acc": 55.0, "val_auroc": 0.576, "time": 437.06}
{"epoch": 24, "training_loss": 53.31418991088867, "training_acc": 66.25, "val_loss": 13.844285011291504, "val_acc": 55.0, "val_auroc": 0.586, "time": 454.99}
{"epoch": 25, "training_loss": 53.310044288635254, "training_acc": 70.0, "val_loss": 13.655054569244385, "val_acc": 55.0, "val_auroc": 0.566, "time": 473.5}
{"epoch": 26, "training_loss": 52.38400840759277, "training_acc": 68.75, "val_loss": 13.61275315284729, "val_acc": 55.0, "val_auroc": 0.606, "time": 490.48}
{"epoch": 27, "training_loss": 51.8869514465332, "training_acc": 67.5, "val_loss": 13.742389678955078, "val_acc": 55.0, "val_auroc": 0.626, "time": 508.53}
{"epoch": 28, "training_loss": 51.23871994018555, "training_acc": 83.75, "val_loss": 13.78502368927002, "val_acc": 55.0, "val_auroc": 0.606, "time": 525.09}
{"epoch": 29, "training_loss": 51.24312973022461, "training_acc": 83.75, "val_loss": 13.667242527008057, "val_acc": 55.0, "val_auroc": 0.586, "time": 543.14}
{"epoch": 30, "training_loss": 51.85788345336914, "training_acc": 53.75, "val_loss": 13.913538455963135, "val_acc": 55.0, "val_auroc": 0.596, "time": 564.92}
{"epoch": 31, "training_loss": 49.22701168060303, "training_acc": 83.75, "val_loss": 13.525842428207397, "val_acc": 55.0, "val_auroc": 0.586, "time": 585.13}
{"epoch": 32, "training_loss": 46.74020862579346, "training_acc": 86.25, "val_loss": 13.50706934928894, "val_acc": 55.0, "val_auroc": 0.596, "time": 602.6}
{"epoch": 33, "training_loss": 45.05898857116699, "training_acc": 90.0, "val_loss": 13.535493612289429, "val_acc": 55.0, "val_auroc": 0.586, "time": 620.91}
{"epoch": 34, "training_loss": 46.16320037841797, "training_acc": 82.5, "val_loss": 13.530844449996948, "val_acc": 55.0, "val_auroc": 0.596, "time": 639.75}
{"epoch": 35, "training_loss": 46.57841491699219, "training_acc": 87.5, "val_loss": 13.761974573135376, "val_acc": 60.0, "val_auroc": 0.606, "time": 658.89}
{"epoch": 36, "training_loss": 42.68287658691406, "training_acc": 92.5, "val_loss": 13.615082502365112, "val_acc": 55.0, "val_auroc": 0.556, "time": 675.53}
{"epoch": 37, "training_loss": 46.1557674407959, "training_acc": 78.75, "val_loss": 13.822482824325562, "val_acc": 60.0, "val_auroc": 0.586, "time": 693.43}
{"epoch": 38, "training_loss": 43.6299991607666, "training_acc": 91.25, "val_loss": 13.485803604125977, "val_acc": 65.0, "val_auroc": 0.606, "time": 712.73}
{"epoch": 39, "training_loss": 40.778414726257324, "training_acc": 91.25, "val_loss": 13.444796800613403, "val_acc": 65.0, "val_auroc": 0.596, "time": 734.09}
{"epoch": 40, "training_loss": 38.74021339416504, "training_acc": 92.5, "val_loss": 13.519705533981323, "val_acc": 65.0, "val_auroc": 0.606, "time": 750.7}
{"epoch": 41, "training_loss": 35.914398193359375, "training_acc": 96.25, "val_loss": 14.864681959152222, "val_acc": 60.0, "val_auroc": 0.616, "time": 768.31}
{"epoch": 42, "training_loss": 42.977566719055176, "training_acc": 78.75, "val_loss": 13.674052953720093, "val_acc": 55.0, "val_auroc": 0.636, "time": 787.91}
{"epoch": 43, "training_loss": 39.61103010177612, "training_acc": 82.5, "val_loss": 14.56009030342102, "val_acc": 60.0, "val_auroc": 0.576, "time": 806.5}
{"epoch": 44, "training_loss": 36.14555263519287, "training_acc": 92.5, "val_loss": 13.692270517349243, "val_acc": 65.0, "val_auroc": 0.667, "time": 823.83}
{"epoch": 45, "training_loss": 35.2111291885376, "training_acc": 92.5, "val_loss": 14.354199171066284, "val_acc": 50.0, "val_auroc": 0.626, "time": 841.67}
{"epoch": 46, "training_loss": 33.482845306396484, "training_acc": 96.25, "val_loss": 13.549697399139404, "val_acc": 60.0, "val_auroc": 0.636, "time": 862.41}
{"epoch": 47, "training_loss": 30.070122718811035, "training_acc": 95.0, "val_loss": 13.768310546875, "val_acc": 50.0, "val_auroc": 0.616, "time": 881.26}
{"epoch": 48, "training_loss": 27.745826244354248, "training_acc": 98.75, "val_loss": 13.671329021453857, "val_acc": 55.0, "val_auroc": 0.626, "time": 899.15}
{"epoch": 49, "training_loss": 27.02841281890869, "training_acc": 98.75, "val_loss": 14.208457469940186, "val_acc": 60.0, "val_auroc": 0.606, "time": 917.76}
{"epoch": 50, "training_loss": 27.541699409484863, "training_acc": 98.75, "val_loss": 14.338277578353882, "val_acc": 60.0, "val_auroc": 0.636, "time": 936.44}
{"epoch": 51, "training_loss": 24.71418523788452, "training_acc": 100.0, "val_loss": 13.920223712921143, "val_acc": 50.0, "val_auroc": 0.646, "time": 954.96}
{"epoch": 52, "training_loss": 23.9705491065979, "training_acc": 98.75, "val_loss": 13.830838203430176, "val_acc": 55.0, "val_auroc": 0.646, "time": 971.97}
{"epoch": 53, "training_loss": 23.13541841506958, "training_acc": 100.0, "val_loss": 15.250972509384155, "val_acc": 60.0, "val_auroc": 0.566, "time": 989.86}
{"epoch": 54, "training_loss": 24.047001838684082, "training_acc": 100.0, "val_loss": 14.081228971481323, "val_acc": 60.0, "val_auroc": 0.687, "time": 1009.49}
{"epoch": 55, "training_loss": 23.634643077850342, "training_acc": 98.75, "val_loss": 14.282238483428955, "val_acc": 55.0, "val_auroc": 0.616, "time": 1028.31}
{"epoch": 56, "training_loss": 21.267030715942383, "training_acc": 100.0, "val_loss": 14.056732654571533, "val_acc": 50.0, "val_auroc": 0.616, "time": 1045.65}
{"epoch": 57, "training_loss": 20.829047441482544, "training_acc": 100.0, "val_loss": 14.717406034469604, "val_acc": 45.0, "val_auroc": 0.616, "time": 1063.37}
{"epoch": 58, "training_loss": 20.183157444000244, "training_acc": 100.0, "val_loss": 14.212329387664795, "val_acc": 55.0, "val_auroc": 0.616, "time": 1084.11}
