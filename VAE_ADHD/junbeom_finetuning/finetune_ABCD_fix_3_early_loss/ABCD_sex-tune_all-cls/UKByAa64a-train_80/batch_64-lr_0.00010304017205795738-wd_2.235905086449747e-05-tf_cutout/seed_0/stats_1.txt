"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.2227840423584, "training_acc": 45.0, "val_loss": 13.804796934127808, "val_acc": 50.0, "val_auroc": 0.57, "time": 21.35}
{"epoch": 1, "training_loss": 55.49697494506836, "training_acc": 46.25, "val_loss": 77.71553039550781, "val_acc": 50.0, "val_auroc": 0.36, "time": 37.65}
{"epoch": 2, "training_loss": 248.61933135986328, "training_acc": 52.5, "val_loss": 13.8437020778656, "val_acc": 50.0, "val_auroc": 0.57, "time": 54.12}
{"epoch": 3, "training_loss": 55.28728485107422, "training_acc": 51.25, "val_loss": 13.845678567886353, "val_acc": 50.0, "val_auroc": 0.57, "time": 71.97}
{"epoch": 4, "training_loss": 55.175251960754395, "training_acc": 52.5, "val_loss": 13.84770154953003, "val_acc": 50.0, "val_auroc": 0.67, "time": 88.25}
{"epoch": 5, "training_loss": 55.261844635009766, "training_acc": 57.5, "val_loss": 13.829666376113892, "val_acc": 50.0, "val_auroc": 0.73, "time": 104.52}
{"epoch": 6, "training_loss": 55.0984411239624, "training_acc": 52.5, "val_loss": 13.790773153305054, "val_acc": 50.0, "val_auroc": 0.8, "time": 121.16}
{"epoch": 7, "training_loss": 55.092384338378906, "training_acc": 53.75, "val_loss": 13.750437498092651, "val_acc": 50.0, "val_auroc": 0.81, "time": 142.46}
{"epoch": 8, "training_loss": 54.99666881561279, "training_acc": 52.5, "val_loss": 13.73618483543396, "val_acc": 50.0, "val_auroc": 0.78, "time": 161.19}
{"epoch": 9, "training_loss": 54.68707847595215, "training_acc": 55.0, "val_loss": 13.903864622116089, "val_acc": 50.0, "val_auroc": 0.74, "time": 178.3}
{"epoch": 10, "training_loss": 55.94814109802246, "training_acc": 47.5, "val_loss": 13.735620975494385, "val_acc": 50.0, "val_auroc": 0.75, "time": 196.4}
{"epoch": 11, "training_loss": 54.60676383972168, "training_acc": 52.5, "val_loss": 14.259514808654785, "val_acc": 50.0, "val_auroc": 0.76, "time": 213.47}
{"epoch": 12, "training_loss": 55.955535888671875, "training_acc": 52.5, "val_loss": 13.747035264968872, "val_acc": 50.0, "val_auroc": 0.75, "time": 231.23}
{"epoch": 13, "training_loss": 55.095821380615234, "training_acc": 48.75, "val_loss": 13.703510761260986, "val_acc": 50.0, "val_auroc": 0.74, "time": 249.18}
{"epoch": 14, "training_loss": 54.457990646362305, "training_acc": 67.5, "val_loss": 14.145463705062866, "val_acc": 50.0, "val_auroc": 0.72, "time": 265.89}
{"epoch": 15, "training_loss": 55.805355072021484, "training_acc": 52.5, "val_loss": 14.379050731658936, "val_acc": 50.0, "val_auroc": 0.69, "time": 283.36}
{"epoch": 16, "training_loss": 56.838523864746094, "training_acc": 52.5, "val_loss": 13.744392395019531, "val_acc": 50.0, "val_auroc": 0.69, "time": 301.76}
{"epoch": 17, "training_loss": 54.29345893859863, "training_acc": 52.5, "val_loss": 13.846430778503418, "val_acc": 50.0, "val_auroc": 0.68, "time": 318.46}
{"epoch": 18, "training_loss": 55.24273204803467, "training_acc": 47.5, "val_loss": 13.71761679649353, "val_acc": 50.0, "val_auroc": 0.71, "time": 335.3}
{"epoch": 19, "training_loss": 55.0802583694458, "training_acc": 53.75, "val_loss": 13.662556409835815, "val_acc": 50.0, "val_auroc": 0.74, "time": 354.45}
{"epoch": 20, "training_loss": 54.175490379333496, "training_acc": 62.5, "val_loss": 13.628681898117065, "val_acc": 50.0, "val_auroc": 0.75, "time": 371.35}
{"epoch": 21, "training_loss": 54.22665023803711, "training_acc": 71.25, "val_loss": 13.615295886993408, "val_acc": 50.0, "val_auroc": 0.75, "time": 388.03}
{"epoch": 22, "training_loss": 53.93111991882324, "training_acc": 62.5, "val_loss": 13.8873291015625, "val_acc": 50.0, "val_auroc": 0.75, "time": 403.74}
{"epoch": 23, "training_loss": 54.45862579345703, "training_acc": 52.5, "val_loss": 13.705214262008667, "val_acc": 50.0, "val_auroc": 0.75, "time": 420.57}
{"epoch": 24, "training_loss": 53.756927490234375, "training_acc": 53.75, "val_loss": 13.501836061477661, "val_acc": 50.0, "val_auroc": 0.75, "time": 439.79}
{"epoch": 25, "training_loss": 53.41934585571289, "training_acc": 62.5, "val_loss": 13.443365097045898, "val_acc": 50.0, "val_auroc": 0.75, "time": 455.75}
{"epoch": 26, "training_loss": 53.35252666473389, "training_acc": 56.25, "val_loss": 13.452138900756836, "val_acc": 50.0, "val_auroc": 0.75, "time": 471.6}
{"epoch": 27, "training_loss": 52.5952033996582, "training_acc": 61.25, "val_loss": 13.291221857070923, "val_acc": 50.0, "val_auroc": 0.74, "time": 487.83}
{"epoch": 28, "training_loss": 53.579933166503906, "training_acc": 56.25, "val_loss": 15.398085117340088, "val_acc": 50.0, "val_auroc": 0.8, "time": 503.0}
{"epoch": 29, "training_loss": 61.32562732696533, "training_acc": 47.5, "val_loss": 13.697317838668823, "val_acc": 50.0, "val_auroc": 0.8, "time": 518.53}
{"epoch": 30, "training_loss": 53.536888122558594, "training_acc": 55.0, "val_loss": 14.490548372268677, "val_acc": 50.0, "val_auroc": 0.77, "time": 535.62}
{"epoch": 31, "training_loss": 56.71921920776367, "training_acc": 52.5, "val_loss": 14.589189291000366, "val_acc": 50.0, "val_auroc": 0.7, "time": 551.43}
{"epoch": 32, "training_loss": 56.30793762207031, "training_acc": 52.5, "val_loss": 13.838354349136353, "val_acc": 50.0, "val_auroc": 0.67, "time": 567.73}
{"epoch": 33, "training_loss": 55.252848625183105, "training_acc": 50.0, "val_loss": 13.961899280548096, "val_acc": 50.0, "val_auroc": 0.61, "time": 584.34}
{"epoch": 34, "training_loss": 56.18859386444092, "training_acc": 47.5, "val_loss": 13.901618719100952, "val_acc": 50.0, "val_auroc": 0.62, "time": 601.32}
{"epoch": 35, "training_loss": 56.21285438537598, "training_acc": 50.0, "val_loss": 13.810142278671265, "val_acc": 50.0, "val_auroc": 0.66, "time": 618.24}
{"epoch": 36, "training_loss": 55.25691032409668, "training_acc": 55.0, "val_loss": 13.808279037475586, "val_acc": 50.0, "val_auroc": 0.63, "time": 635.7}
{"epoch": 37, "training_loss": 55.26515197753906, "training_acc": 55.0, "val_loss": 13.846186399459839, "val_acc": 50.0, "val_auroc": 0.63, "time": 651.74}
{"epoch": 38, "training_loss": 55.45762062072754, "training_acc": 47.5, "val_loss": 13.843164443969727, "val_acc": 50.0, "val_auroc": 0.62, "time": 668.3}
{"epoch": 39, "training_loss": 55.42725944519043, "training_acc": 46.25, "val_loss": 13.777987957000732, "val_acc": 50.0, "val_auroc": 0.62, "time": 685.25}
{"epoch": 40, "training_loss": 54.9132022857666, "training_acc": 56.25, "val_loss": 13.825294971466064, "val_acc": 50.0, "val_auroc": 0.64, "time": 701.83}
{"epoch": 41, "training_loss": 55.07830333709717, "training_acc": 52.5, "val_loss": 13.799782991409302, "val_acc": 50.0, "val_auroc": 0.64, "time": 718.03}
{"epoch": 42, "training_loss": 54.957566261291504, "training_acc": 51.25, "val_loss": 13.75354290008545, "val_acc": 50.0, "val_auroc": 0.64, "time": 734.57}
{"epoch": 43, "training_loss": 54.742950439453125, "training_acc": 60.0, "val_loss": 13.746507167816162, "val_acc": 50.0, "val_auroc": 0.67, "time": 752.74}
{"epoch": 44, "training_loss": 54.81158447265625, "training_acc": 70.0, "val_loss": 13.727577924728394, "val_acc": 50.0, "val_auroc": 0.67, "time": 770.31}
{"epoch": 45, "training_loss": 54.81576919555664, "training_acc": 55.0, "val_loss": 13.710988759994507, "val_acc": 50.0, "val_auroc": 0.68, "time": 786.29}
{"epoch": 46, "training_loss": 54.630332946777344, "training_acc": 57.5, "val_loss": 13.71760368347168, "val_acc": 50.0, "val_auroc": 0.68, "time": 802.83}
