"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.13269805908203, "training_acc": 51.25, "val_loss": 13.919941186904907, "val_acc": 50.0, "val_auroc": 0.45, "time": 19.7}
{"epoch": 1, "training_loss": 55.21010684967041, "training_acc": 52.5, "val_loss": 14.752098321914673, "val_acc": 50.0, "val_auroc": 0.75, "time": 35.57}
{"epoch": 2, "training_loss": 57.81657314300537, "training_acc": 52.5, "val_loss": 13.906035423278809, "val_acc": 50.0, "val_auroc": 0.35, "time": 52.7}
{"epoch": 3, "training_loss": 55.663174629211426, "training_acc": 47.5, "val_loss": 13.959347009658813, "val_acc": 50.0, "val_auroc": 0.26, "time": 68.87}
{"epoch": 4, "training_loss": 55.37337589263916, "training_acc": 52.5, "val_loss": 14.11508321762085, "val_acc": 50.0, "val_auroc": 0.26, "time": 84.19}
{"epoch": 5, "training_loss": 55.47009754180908, "training_acc": 52.5, "val_loss": 13.922326564788818, "val_acc": 50.0, "val_auroc": 0.24, "time": 100.41}
{"epoch": 6, "training_loss": 55.403592109680176, "training_acc": 45.0, "val_loss": 13.978809118270874, "val_acc": 50.0, "val_auroc": 0.29, "time": 115.75}
{"epoch": 7, "training_loss": 55.16366195678711, "training_acc": 52.5, "val_loss": 14.293746948242188, "val_acc": 50.0, "val_auroc": 0.3, "time": 131.57}
{"epoch": 8, "training_loss": 56.04306221008301, "training_acc": 52.5, "val_loss": 13.98617148399353, "val_acc": 50.0, "val_auroc": 0.21, "time": 147.16}
{"epoch": 9, "training_loss": 55.125826835632324, "training_acc": 52.5, "val_loss": 13.888237476348877, "val_acc": 50.0, "val_auroc": 0.52, "time": 163.9}
{"epoch": 10, "training_loss": 55.653544425964355, "training_acc": 47.5, "val_loss": 13.881216049194336, "val_acc": 50.0, "val_auroc": 0.59, "time": 180.25}
{"epoch": 11, "training_loss": 55.359439849853516, "training_acc": 48.75, "val_loss": 13.936671018600464, "val_acc": 50.0, "val_auroc": 0.33, "time": 195.17}
{"epoch": 12, "training_loss": 55.37925624847412, "training_acc": 52.5, "val_loss": 14.123482704162598, "val_acc": 50.0, "val_auroc": 0.29, "time": 210.66}
{"epoch": 13, "training_loss": 55.56883907318115, "training_acc": 52.5, "val_loss": 13.987919092178345, "val_acc": 50.0, "val_auroc": 0.35, "time": 228.18}
{"epoch": 14, "training_loss": 55.24275779724121, "training_acc": 52.5, "val_loss": 13.873289823532104, "val_acc": 50.0, "val_auroc": 0.39, "time": 244.27}
{"epoch": 15, "training_loss": 55.506022453308105, "training_acc": 45.0, "val_loss": 13.86159896850586, "val_acc": 50.0, "val_auroc": 0.48, "time": 259.84}
{"epoch": 16, "training_loss": 55.03254699707031, "training_acc": 56.25, "val_loss": 13.956881761550903, "val_acc": 50.0, "val_auroc": 0.54, "time": 276.04}
{"epoch": 17, "training_loss": 55.24293613433838, "training_acc": 52.5, "val_loss": 14.128566980361938, "val_acc": 50.0, "val_auroc": 0.47, "time": 291.59}
{"epoch": 18, "training_loss": 55.517234802246094, "training_acc": 52.5, "val_loss": 14.053627252578735, "val_acc": 50.0, "val_auroc": 0.36, "time": 308.79}
{"epoch": 19, "training_loss": 55.14365196228027, "training_acc": 52.5, "val_loss": 13.887767791748047, "val_acc": 50.0, "val_auroc": 0.37, "time": 324.46}
{"epoch": 20, "training_loss": 55.17487621307373, "training_acc": 50.0, "val_loss": 13.883389234542847, "val_acc": 50.0, "val_auroc": 0.45, "time": 339.29}
{"epoch": 21, "training_loss": 55.3780403137207, "training_acc": 47.5, "val_loss": 13.874393701553345, "val_acc": 50.0, "val_auroc": 0.45, "time": 354.73}
{"epoch": 22, "training_loss": 55.19478988647461, "training_acc": 56.25, "val_loss": 13.885644674301147, "val_acc": 50.0, "val_auroc": 0.46, "time": 372.0}
{"epoch": 23, "training_loss": 54.883216857910156, "training_acc": 52.5, "val_loss": 13.98642897605896, "val_acc": 50.0, "val_auroc": 0.42, "time": 387.41}
{"epoch": 24, "training_loss": 54.96962547302246, "training_acc": 52.5, "val_loss": 14.14709210395813, "val_acc": 50.0, "val_auroc": 0.39, "time": 403.09}
{"epoch": 25, "training_loss": 55.345683097839355, "training_acc": 52.5, "val_loss": 14.186357259750366, "val_acc": 50.0, "val_auroc": 0.38, "time": 418.79}
{"epoch": 26, "training_loss": 55.54788780212402, "training_acc": 52.5, "val_loss": 14.125312566757202, "val_acc": 50.0, "val_auroc": 0.36, "time": 434.28}
{"epoch": 27, "training_loss": 54.93095397949219, "training_acc": 52.5, "val_loss": 14.106321334838867, "val_acc": 50.0, "val_auroc": 0.31, "time": 449.57}
{"epoch": 28, "training_loss": 54.79154014587402, "training_acc": 52.5, "val_loss": 13.91460657119751, "val_acc": 50.0, "val_auroc": 0.35, "time": 466.13}
{"epoch": 29, "training_loss": 54.76580333709717, "training_acc": 50.0, "val_loss": 13.920485973358154, "val_acc": 50.0, "val_auroc": 0.45, "time": 482.83}
{"epoch": 30, "training_loss": 55.2990837097168, "training_acc": 47.5, "val_loss": 13.90679121017456, "val_acc": 50.0, "val_auroc": 0.45, "time": 499.38}
{"epoch": 31, "training_loss": 55.03801918029785, "training_acc": 55.0, "val_loss": 13.91677737236023, "val_acc": 50.0, "val_auroc": 0.39, "time": 514.59}
{"epoch": 32, "training_loss": 54.45242881774902, "training_acc": 63.75, "val_loss": 13.977431058883667, "val_acc": 50.0, "val_auroc": 0.36, "time": 533.8}
{"epoch": 33, "training_loss": 54.179123878479004, "training_acc": 52.5, "val_loss": 14.017460346221924, "val_acc": 50.0, "val_auroc": 0.33, "time": 550.24}
{"epoch": 34, "training_loss": 54.01747703552246, "training_acc": 55.0, "val_loss": 14.114298820495605, "val_acc": 50.0, "val_auroc": 0.3, "time": 566.81}
