"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.13258457183838, "training_acc": 38.75, "val_loss": 13.882969617843628, "val_acc": 55.0, "val_auroc": 0.535, "time": 19.51}
{"epoch": 1, "training_loss": 57.72425842285156, "training_acc": 53.75, "val_loss": 18.135976791381836, "val_acc": 55.0, "val_auroc": 0.434, "time": 35.34}
{"epoch": 2, "training_loss": 74.06830406188965, "training_acc": 51.25, "val_loss": 14.285014867782593, "val_acc": 55.0, "val_auroc": 0.566, "time": 50.59}
{"epoch": 3, "training_loss": 57.92868995666504, "training_acc": 51.25, "val_loss": 14.076427221298218, "val_acc": 55.0, "val_auroc": 0.394, "time": 65.94}
{"epoch": 4, "training_loss": 56.14289379119873, "training_acc": 48.75, "val_loss": 14.208612442016602, "val_acc": 55.0, "val_auroc": 0.495, "time": 80.81}
{"epoch": 5, "training_loss": 55.959280014038086, "training_acc": 50.0, "val_loss": 13.763355016708374, "val_acc": 55.0, "val_auroc": 0.515, "time": 95.96}
{"epoch": 6, "training_loss": 55.524545669555664, "training_acc": 51.25, "val_loss": 13.755056858062744, "val_acc": 55.0, "val_auroc": 0.586, "time": 110.85}
{"epoch": 7, "training_loss": 55.57375526428223, "training_acc": 51.25, "val_loss": 14.05056118965149, "val_acc": 55.0, "val_auroc": 0.525, "time": 125.31}
{"epoch": 8, "training_loss": 56.198689460754395, "training_acc": 43.75, "val_loss": 14.244433641433716, "val_acc": 55.0, "val_auroc": 0.465, "time": 140.85}
{"epoch": 9, "training_loss": 56.529839515686035, "training_acc": 48.75, "val_loss": 13.800445795059204, "val_acc": 55.0, "val_auroc": 0.465, "time": 156.72}
{"epoch": 10, "training_loss": 55.47126865386963, "training_acc": 51.25, "val_loss": 13.869870901107788, "val_acc": 55.0, "val_auroc": 0.525, "time": 172.27}
{"epoch": 11, "training_loss": 56.62308979034424, "training_acc": 51.25, "val_loss": 13.759759664535522, "val_acc": 55.0, "val_auroc": 0.576, "time": 187.79}
{"epoch": 12, "training_loss": 55.492295265197754, "training_acc": 51.25, "val_loss": 13.861831426620483, "val_acc": 55.0, "val_auroc": 0.566, "time": 203.08}
{"epoch": 13, "training_loss": 55.511932373046875, "training_acc": 57.5, "val_loss": 14.03464674949646, "val_acc": 55.0, "val_auroc": 0.596, "time": 218.75}
{"epoch": 14, "training_loss": 55.76664447784424, "training_acc": 48.75, "val_loss": 13.95323634147644, "val_acc": 55.0, "val_auroc": 0.535, "time": 236.68}
{"epoch": 15, "training_loss": 55.459567070007324, "training_acc": 48.75, "val_loss": 13.842648267745972, "val_acc": 55.0, "val_auroc": 0.525, "time": 252.72}
{"epoch": 16, "training_loss": 54.999671936035156, "training_acc": 66.25, "val_loss": 13.750050067901611, "val_acc": 55.0, "val_auroc": 0.566, "time": 269.55}
{"epoch": 17, "training_loss": 55.71294403076172, "training_acc": 51.25, "val_loss": 13.85799765586853, "val_acc": 55.0, "val_auroc": 0.545, "time": 285.95}
{"epoch": 18, "training_loss": 56.46621894836426, "training_acc": 51.25, "val_loss": 13.77504825592041, "val_acc": 55.0, "val_auroc": 0.596, "time": 302.36}
{"epoch": 19, "training_loss": 55.63047122955322, "training_acc": 51.25, "val_loss": 13.815644979476929, "val_acc": 55.0, "val_auroc": 0.586, "time": 318.63}
{"epoch": 20, "training_loss": 55.30522060394287, "training_acc": 51.25, "val_loss": 14.098200798034668, "val_acc": 55.0, "val_auroc": 0.657, "time": 334.98}
{"epoch": 21, "training_loss": 55.7899112701416, "training_acc": 48.75, "val_loss": 14.1555917263031, "val_acc": 55.0, "val_auroc": 0.677, "time": 354.07}
{"epoch": 22, "training_loss": 55.86884689331055, "training_acc": 48.75, "val_loss": 13.963199853897095, "val_acc": 55.0, "val_auroc": 0.616, "time": 370.57}
{"epoch": 23, "training_loss": 55.37302017211914, "training_acc": 48.75, "val_loss": 13.805850744247437, "val_acc": 55.0, "val_auroc": 0.596, "time": 386.34}
{"epoch": 24, "training_loss": 55.32028865814209, "training_acc": 51.25, "val_loss": 13.763231039047241, "val_acc": 55.0, "val_auroc": 0.576, "time": 402.25}
{"epoch": 25, "training_loss": 55.30218696594238, "training_acc": 51.25, "val_loss": 13.761857748031616, "val_acc": 55.0, "val_auroc": 0.556, "time": 417.88}
{"epoch": 26, "training_loss": 55.21810531616211, "training_acc": 51.25, "val_loss": 13.758126497268677, "val_acc": 55.0, "val_auroc": 0.556, "time": 433.86}
{"epoch": 27, "training_loss": 55.218379974365234, "training_acc": 51.25, "val_loss": 13.769912719726562, "val_acc": 55.0, "val_auroc": 0.556, "time": 449.74}
{"epoch": 28, "training_loss": 55.02054214477539, "training_acc": 51.25, "val_loss": 13.842986822128296, "val_acc": 55.0, "val_auroc": 0.556, "time": 465.24}
{"epoch": 29, "training_loss": 55.33973693847656, "training_acc": 61.25, "val_loss": 13.884843587875366, "val_acc": 55.0, "val_auroc": 0.535, "time": 481.58}
{"epoch": 30, "training_loss": 55.0234956741333, "training_acc": 56.25, "val_loss": 13.776408433914185, "val_acc": 55.0, "val_auroc": 0.545, "time": 497.49}
{"epoch": 31, "training_loss": 54.9634485244751, "training_acc": 51.25, "val_loss": 13.758739233016968, "val_acc": 55.0, "val_auroc": 0.545, "time": 513.79}
{"epoch": 32, "training_loss": 54.921884536743164, "training_acc": 51.25, "val_loss": 13.779754638671875, "val_acc": 55.0, "val_auroc": 0.545, "time": 530.16}
{"epoch": 33, "training_loss": 54.736968994140625, "training_acc": 51.25, "val_loss": 13.790421485900879, "val_acc": 55.0, "val_auroc": 0.556, "time": 547.5}
{"epoch": 34, "training_loss": 54.64638900756836, "training_acc": 56.25, "val_loss": 13.776873350143433, "val_acc": 55.0, "val_auroc": 0.556, "time": 563.32}
{"epoch": 35, "training_loss": 54.45644283294678, "training_acc": 56.25, "val_loss": 13.786851167678833, "val_acc": 55.0, "val_auroc": 0.576, "time": 579.79}
