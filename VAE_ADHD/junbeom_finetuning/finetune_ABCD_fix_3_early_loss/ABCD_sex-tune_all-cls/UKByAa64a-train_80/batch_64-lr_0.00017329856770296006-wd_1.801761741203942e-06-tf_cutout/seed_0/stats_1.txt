"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5962553024292, "training_acc": 52.5, "val_loss": 13.847278356552124, "val_acc": 50.0, "val_auroc": 0.73, "time": 18.35}
{"epoch": 1, "training_loss": 55.37130260467529, "training_acc": 52.5, "val_loss": 13.931068181991577, "val_acc": 50.0, "val_auroc": 0.54, "time": 35.75}
{"epoch": 2, "training_loss": 55.44273376464844, "training_acc": 52.5, "val_loss": 13.91221284866333, "val_acc": 50.0, "val_auroc": 0.75, "time": 51.75}
{"epoch": 3, "training_loss": 55.389665603637695, "training_acc": 52.5, "val_loss": 13.872637748718262, "val_acc": 50.0, "val_auroc": 0.59, "time": 66.6}
{"epoch": 4, "training_loss": 55.324490547180176, "training_acc": 52.5, "val_loss": 13.860199451446533, "val_acc": 50.0, "val_auroc": 0.6, "time": 83.04}
{"epoch": 5, "training_loss": 55.40251922607422, "training_acc": 52.5, "val_loss": 13.870099782943726, "val_acc": 50.0, "val_auroc": 0.61, "time": 100.47}
{"epoch": 6, "training_loss": 55.32176208496094, "training_acc": 52.5, "val_loss": 13.88919711112976, "val_acc": 50.0, "val_auroc": 0.65, "time": 116.82}
{"epoch": 7, "training_loss": 55.3376579284668, "training_acc": 52.5, "val_loss": 13.888276815414429, "val_acc": 50.0, "val_auroc": 0.66, "time": 132.91}
{"epoch": 8, "training_loss": 55.326239585876465, "training_acc": 52.5, "val_loss": 13.878649473190308, "val_acc": 50.0, "val_auroc": 0.7, "time": 149.86}
{"epoch": 9, "training_loss": 55.30001354217529, "training_acc": 52.5, "val_loss": 13.845819234848022, "val_acc": 50.0, "val_auroc": 0.85, "time": 166.77}
{"epoch": 10, "training_loss": 55.4769229888916, "training_acc": 57.5, "val_loss": 13.847905397415161, "val_acc": 50.0, "val_auroc": 0.77, "time": 182.29}
{"epoch": 11, "training_loss": 55.379693031311035, "training_acc": 50.0, "val_loss": 13.881261348724365, "val_acc": 50.0, "val_auroc": 0.71, "time": 197.59}
{"epoch": 12, "training_loss": 55.278282165527344, "training_acc": 52.5, "val_loss": 13.989953994750977, "val_acc": 50.0, "val_auroc": 0.74, "time": 212.85}
{"epoch": 13, "training_loss": 55.52005577087402, "training_acc": 52.5, "val_loss": 14.043328762054443, "val_acc": 50.0, "val_auroc": 0.78, "time": 227.84}
{"epoch": 14, "training_loss": 55.71040344238281, "training_acc": 52.5, "val_loss": 14.111016988754272, "val_acc": 50.0, "val_auroc": 0.73, "time": 243.49}
{"epoch": 15, "training_loss": 55.828956604003906, "training_acc": 52.5, "val_loss": 14.152319431304932, "val_acc": 50.0, "val_auroc": 0.8, "time": 259.32}
{"epoch": 16, "training_loss": 55.97345733642578, "training_acc": 52.5, "val_loss": 14.08599853515625, "val_acc": 50.0, "val_auroc": 0.77, "time": 277.02}
{"epoch": 17, "training_loss": 55.68658638000488, "training_acc": 52.5, "val_loss": 13.933830261230469, "val_acc": 50.0, "val_auroc": 0.79, "time": 292.02}
{"epoch": 18, "training_loss": 55.3217830657959, "training_acc": 52.5, "val_loss": 13.856912851333618, "val_acc": 50.0, "val_auroc": 0.7, "time": 308.36}
{"epoch": 19, "training_loss": 55.33505439758301, "training_acc": 57.5, "val_loss": 13.884646892547607, "val_acc": 50.0, "val_auroc": 0.68, "time": 324.01}
{"epoch": 20, "training_loss": 55.792508125305176, "training_acc": 47.5, "val_loss": 13.907952308654785, "val_acc": 50.0, "val_auroc": 0.75, "time": 339.73}
{"epoch": 21, "training_loss": 55.89777088165283, "training_acc": 47.5, "val_loss": 13.848153352737427, "val_acc": 50.0, "val_auroc": 0.75, "time": 356.24}
{"epoch": 22, "training_loss": 55.38425827026367, "training_acc": 52.5, "val_loss": 13.93871784210205, "val_acc": 50.0, "val_auroc": 0.74, "time": 372.09}
{"epoch": 23, "training_loss": 55.37297248840332, "training_acc": 52.5, "val_loss": 14.060068130493164, "val_acc": 50.0, "val_auroc": 0.37, "time": 387.92}
{"epoch": 24, "training_loss": 55.67740058898926, "training_acc": 52.5, "val_loss": 14.079535007476807, "val_acc": 50.0, "val_auroc": 0.41, "time": 404.03}
{"epoch": 25, "training_loss": 55.72466850280762, "training_acc": 52.5, "val_loss": 13.992236852645874, "val_acc": 50.0, "val_auroc": 0.39, "time": 420.33}
{"epoch": 26, "training_loss": 55.508480072021484, "training_acc": 52.5, "val_loss": 13.917397260665894, "val_acc": 50.0, "val_auroc": 0.45, "time": 436.01}
{"epoch": 27, "training_loss": 55.374887466430664, "training_acc": 52.5, "val_loss": 13.895992040634155, "val_acc": 50.0, "val_auroc": 0.7, "time": 450.88}
{"epoch": 28, "training_loss": 55.47799301147461, "training_acc": 52.5, "val_loss": 13.866357803344727, "val_acc": 50.0, "val_auroc": 0.64, "time": 466.45}
