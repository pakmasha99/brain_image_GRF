"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.53927803039551, "training_acc": 52.5, "val_loss": 13.908675909042358, "val_acc": 50.0, "val_auroc": 0.44, "time": 15.66}
{"epoch": 1, "training_loss": 55.55584239959717, "training_acc": 52.5, "val_loss": 13.90459656715393, "val_acc": 50.0, "val_auroc": 0.45, "time": 28.57}
{"epoch": 2, "training_loss": 55.291099548339844, "training_acc": 52.5, "val_loss": 13.867008686065674, "val_acc": 50.0, "val_auroc": 0.59, "time": 41.51}
{"epoch": 3, "training_loss": 55.329468727111816, "training_acc": 52.5, "val_loss": 13.867849111557007, "val_acc": 50.0, "val_auroc": 0.69, "time": 54.54}
{"epoch": 4, "training_loss": 55.23638343811035, "training_acc": 52.5, "val_loss": 13.853943347930908, "val_acc": 50.0, "val_auroc": 0.69, "time": 67.46}
{"epoch": 5, "training_loss": 55.175357818603516, "training_acc": 52.5, "val_loss": 13.813318014144897, "val_acc": 50.0, "val_auroc": 0.78, "time": 80.45}
{"epoch": 6, "training_loss": 55.11997985839844, "training_acc": 52.5, "val_loss": 13.833392858505249, "val_acc": 50.0, "val_auroc": 0.65, "time": 93.55}
{"epoch": 7, "training_loss": 55.034257888793945, "training_acc": 52.5, "val_loss": 13.805055618286133, "val_acc": 50.0, "val_auroc": 0.67, "time": 106.88}
{"epoch": 8, "training_loss": 54.77226638793945, "training_acc": 53.75, "val_loss": 13.781808614730835, "val_acc": 50.0, "val_auroc": 0.73, "time": 120.33}
{"epoch": 9, "training_loss": 54.74897861480713, "training_acc": 52.5, "val_loss": 13.759936094284058, "val_acc": 50.0, "val_auroc": 0.75, "time": 133.67}
{"epoch": 10, "training_loss": 54.78326416015625, "training_acc": 60.0, "val_loss": 13.707854747772217, "val_acc": 50.0, "val_auroc": 0.77, "time": 146.86}
{"epoch": 11, "training_loss": 54.08633232116699, "training_acc": 60.0, "val_loss": 13.813809156417847, "val_acc": 50.0, "val_auroc": 0.8, "time": 162.62}
{"epoch": 12, "training_loss": 54.606374740600586, "training_acc": 52.5, "val_loss": 13.635479211807251, "val_acc": 50.0, "val_auroc": 0.79, "time": 176.12}
{"epoch": 13, "training_loss": 53.93421459197998, "training_acc": 60.0, "val_loss": 13.615745306015015, "val_acc": 50.0, "val_auroc": 0.79, "time": 189.55}
{"epoch": 14, "training_loss": 53.86140251159668, "training_acc": 56.25, "val_loss": 14.099481105804443, "val_acc": 50.0, "val_auroc": 0.81, "time": 202.42}
{"epoch": 15, "training_loss": 55.2492733001709, "training_acc": 52.5, "val_loss": 13.679561614990234, "val_acc": 50.0, "val_auroc": 0.84, "time": 215.03}
{"epoch": 16, "training_loss": 54.265228271484375, "training_acc": 57.5, "val_loss": 13.538259267807007, "val_acc": 50.0, "val_auroc": 0.88, "time": 228.54}
{"epoch": 17, "training_loss": 53.65293884277344, "training_acc": 72.5, "val_loss": 13.338569402694702, "val_acc": 50.0, "val_auroc": 0.89, "time": 241.89}
{"epoch": 18, "training_loss": 52.27883529663086, "training_acc": 70.0, "val_loss": 13.199018239974976, "val_acc": 50.0, "val_auroc": 0.89, "time": 255.32}
{"epoch": 19, "training_loss": 51.42147636413574, "training_acc": 75.0, "val_loss": 13.614178895950317, "val_acc": 50.0, "val_auroc": 0.83, "time": 268.32}
{"epoch": 20, "training_loss": 53.896005630493164, "training_acc": 60.0, "val_loss": 13.38252305984497, "val_acc": 50.0, "val_auroc": 0.86, "time": 280.6}
{"epoch": 21, "training_loss": 52.29608631134033, "training_acc": 75.0, "val_loss": 13.45278024673462, "val_acc": 50.0, "val_auroc": 0.85, "time": 293.37}
{"epoch": 22, "training_loss": 51.93147945404053, "training_acc": 58.75, "val_loss": 12.973408699035645, "val_acc": 50.0, "val_auroc": 0.86, "time": 306.22}
{"epoch": 23, "training_loss": 49.68039131164551, "training_acc": 85.0, "val_loss": 13.688570261001587, "val_acc": 50.0, "val_auroc": 0.85, "time": 319.07}
{"epoch": 24, "training_loss": 51.45792293548584, "training_acc": 60.0, "val_loss": 12.501996755599976, "val_acc": 50.0, "val_auroc": 0.88, "time": 332.38}
{"epoch": 25, "training_loss": 48.11279487609863, "training_acc": 81.25, "val_loss": 13.197836875915527, "val_acc": 50.0, "val_auroc": 0.8, "time": 345.1}
{"epoch": 26, "training_loss": 50.9176025390625, "training_acc": 65.0, "val_loss": 12.240126132965088, "val_acc": 50.0, "val_auroc": 0.89, "time": 358.24}
{"epoch": 27, "training_loss": 44.01937484741211, "training_acc": 85.0, "val_loss": 13.050254583358765, "val_acc": 50.0, "val_auroc": 0.82, "time": 370.35}
{"epoch": 28, "training_loss": 46.749916076660156, "training_acc": 71.25, "val_loss": 14.30616021156311, "val_acc": 55.0, "val_auroc": 0.53, "time": 382.7}
{"epoch": 29, "training_loss": 56.28223419189453, "training_acc": 50.0, "val_loss": 14.104229211807251, "val_acc": 50.0, "val_auroc": 0.41, "time": 395.34}
{"epoch": 30, "training_loss": 56.77224922180176, "training_acc": 47.5, "val_loss": 13.76116156578064, "val_acc": 50.0, "val_auroc": 0.79, "time": 408.14}
{"epoch": 31, "training_loss": 55.139142990112305, "training_acc": 56.25, "val_loss": 13.852227926254272, "val_acc": 50.0, "val_auroc": 0.84, "time": 421.15}
{"epoch": 32, "training_loss": 55.27073383331299, "training_acc": 52.5, "val_loss": 13.92673373222351, "val_acc": 50.0, "val_auroc": 0.81, "time": 434.48}
{"epoch": 33, "training_loss": 55.29094886779785, "training_acc": 52.5, "val_loss": 13.852682113647461, "val_acc": 50.0, "val_auroc": 0.82, "time": 447.19}
{"epoch": 34, "training_loss": 54.98290157318115, "training_acc": 52.5, "val_loss": 13.780549764633179, "val_acc": 50.0, "val_auroc": 0.85, "time": 460.59}
{"epoch": 35, "training_loss": 54.73156547546387, "training_acc": 52.5, "val_loss": 13.727331161499023, "val_acc": 50.0, "val_auroc": 0.84, "time": 475.6}
{"epoch": 36, "training_loss": 54.75922775268555, "training_acc": 55.0, "val_loss": 13.767718076705933, "val_acc": 50.0, "val_auroc": 0.83, "time": 488.95}
{"epoch": 37, "training_loss": 55.0440034866333, "training_acc": 48.75, "val_loss": 13.764376640319824, "val_acc": 50.0, "val_auroc": 0.84, "time": 502.32}
{"epoch": 38, "training_loss": 55.250423431396484, "training_acc": 47.5, "val_loss": 13.667887449264526, "val_acc": 50.0, "val_auroc": 0.83, "time": 515.14}
{"epoch": 39, "training_loss": 54.3803596496582, "training_acc": 66.25, "val_loss": 13.659738302230835, "val_acc": 50.0, "val_auroc": 0.83, "time": 527.93}
{"epoch": 40, "training_loss": 54.433167457580566, "training_acc": 60.0, "val_loss": 13.656435012817383, "val_acc": 50.0, "val_auroc": 0.83, "time": 541.09}
{"epoch": 41, "training_loss": 54.12667369842529, "training_acc": 55.0, "val_loss": 13.488049507141113, "val_acc": 50.0, "val_auroc": 0.83, "time": 553.92}
{"epoch": 42, "training_loss": 54.025169372558594, "training_acc": 72.5, "val_loss": 13.489518165588379, "val_acc": 50.0, "val_auroc": 0.84, "time": 566.99}
{"epoch": 43, "training_loss": 53.137939453125, "training_acc": 67.5, "val_loss": 13.318514823913574, "val_acc": 50.0, "val_auroc": 0.82, "time": 579.6}
{"epoch": 44, "training_loss": 53.12650394439697, "training_acc": 70.0, "val_loss": 13.400474786758423, "val_acc": 50.0, "val_auroc": 0.82, "time": 592.11}
{"epoch": 45, "training_loss": 53.15681457519531, "training_acc": 61.25, "val_loss": 13.060649633407593, "val_acc": 50.0, "val_auroc": 0.83, "time": 605.28}
