"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.38655471801758, "training_acc": 61.25, "val_loss": 13.835887908935547, "val_acc": 55.0, "val_auroc": 0.485, "time": 15.0}
{"epoch": 1, "training_loss": 55.39760208129883, "training_acc": 51.25, "val_loss": 13.813804388046265, "val_acc": 55.0, "val_auroc": 0.444, "time": 28.64}
{"epoch": 2, "training_loss": 55.22189140319824, "training_acc": 51.25, "val_loss": 13.802272081375122, "val_acc": 55.0, "val_auroc": 0.495, "time": 42.03}
{"epoch": 3, "training_loss": 55.26121711730957, "training_acc": 51.25, "val_loss": 13.801053762435913, "val_acc": 55.0, "val_auroc": 0.535, "time": 55.33}
{"epoch": 4, "training_loss": 55.138771057128906, "training_acc": 51.25, "val_loss": 13.804771900177002, "val_acc": 55.0, "val_auroc": 0.515, "time": 68.48}
{"epoch": 5, "training_loss": 54.88803577423096, "training_acc": 51.25, "val_loss": 13.809540271759033, "val_acc": 55.0, "val_auroc": 0.455, "time": 81.04}
{"epoch": 6, "training_loss": 54.97154998779297, "training_acc": 51.25, "val_loss": 13.802540302276611, "val_acc": 55.0, "val_auroc": 0.475, "time": 94.21}
{"epoch": 7, "training_loss": 54.767520904541016, "training_acc": 51.25, "val_loss": 13.80990743637085, "val_acc": 55.0, "val_auroc": 0.535, "time": 106.39}
{"epoch": 8, "training_loss": 54.59422302246094, "training_acc": 51.25, "val_loss": 13.842705488204956, "val_acc": 55.0, "val_auroc": 0.515, "time": 119.45}
{"epoch": 9, "training_loss": 54.45408058166504, "training_acc": 63.75, "val_loss": 13.866236209869385, "val_acc": 55.0, "val_auroc": 0.495, "time": 132.02}
{"epoch": 10, "training_loss": 54.381226539611816, "training_acc": 81.25, "val_loss": 13.825355768203735, "val_acc": 55.0, "val_auroc": 0.505, "time": 145.14}
{"epoch": 11, "training_loss": 54.17747688293457, "training_acc": 73.75, "val_loss": 13.803659677505493, "val_acc": 55.0, "val_auroc": 0.505, "time": 157.33}
{"epoch": 12, "training_loss": 54.27384662628174, "training_acc": 53.75, "val_loss": 13.794865608215332, "val_acc": 55.0, "val_auroc": 0.495, "time": 170.09}
{"epoch": 13, "training_loss": 53.98464584350586, "training_acc": 52.5, "val_loss": 13.842027187347412, "val_acc": 55.0, "val_auroc": 0.465, "time": 182.47}
{"epoch": 14, "training_loss": 53.75859260559082, "training_acc": 63.75, "val_loss": 13.901340961456299, "val_acc": 55.0, "val_auroc": 0.475, "time": 194.88}
{"epoch": 15, "training_loss": 53.80765628814697, "training_acc": 77.5, "val_loss": 13.845487833023071, "val_acc": 55.0, "val_auroc": 0.505, "time": 207.67}
{"epoch": 16, "training_loss": 53.07383155822754, "training_acc": 70.0, "val_loss": 13.820571899414062, "val_acc": 55.0, "val_auroc": 0.525, "time": 222.58}
{"epoch": 17, "training_loss": 53.7776985168457, "training_acc": 52.5, "val_loss": 13.820347785949707, "val_acc": 55.0, "val_auroc": 0.475, "time": 235.27}
{"epoch": 18, "training_loss": 53.33985614776611, "training_acc": 55.0, "val_loss": 13.8408362865448, "val_acc": 55.0, "val_auroc": 0.495, "time": 247.58}
{"epoch": 19, "training_loss": 53.40707778930664, "training_acc": 76.25, "val_loss": 13.873261213302612, "val_acc": 55.0, "val_auroc": 0.556, "time": 260.12}
{"epoch": 20, "training_loss": 53.251102447509766, "training_acc": 80.0, "val_loss": 13.825632333755493, "val_acc": 55.0, "val_auroc": 0.505, "time": 272.91}
{"epoch": 21, "training_loss": 52.5568323135376, "training_acc": 76.25, "val_loss": 13.79624605178833, "val_acc": 55.0, "val_auroc": 0.495, "time": 285.46}
{"epoch": 22, "training_loss": 52.80452919006348, "training_acc": 61.25, "val_loss": 13.856805562973022, "val_acc": 55.0, "val_auroc": 0.515, "time": 298.18}
{"epoch": 23, "training_loss": 52.21674346923828, "training_acc": 68.75, "val_loss": 13.9022696018219, "val_acc": 55.0, "val_auroc": 0.535, "time": 310.35}
{"epoch": 24, "training_loss": 51.33466339111328, "training_acc": 85.0, "val_loss": 13.850408792495728, "val_acc": 55.0, "val_auroc": 0.515, "time": 323.32}
{"epoch": 25, "training_loss": 50.89742565155029, "training_acc": 78.75, "val_loss": 13.858336210250854, "val_acc": 55.0, "val_auroc": 0.515, "time": 335.79}
{"epoch": 26, "training_loss": 51.54300498962402, "training_acc": 60.0, "val_loss": 13.825691938400269, "val_acc": 55.0, "val_auroc": 0.525, "time": 348.87}
{"epoch": 27, "training_loss": 50.082411766052246, "training_acc": 75.0, "val_loss": 13.822317123413086, "val_acc": 55.0, "val_auroc": 0.535, "time": 361.38}
{"epoch": 28, "training_loss": 50.63008499145508, "training_acc": 78.75, "val_loss": 13.814517259597778, "val_acc": 55.0, "val_auroc": 0.545, "time": 373.7}
{"epoch": 29, "training_loss": 49.56021499633789, "training_acc": 90.0, "val_loss": 13.808403015136719, "val_acc": 55.0, "val_auroc": 0.545, "time": 386.28}
{"epoch": 30, "training_loss": 48.61007213592529, "training_acc": 80.0, "val_loss": 13.800691366195679, "val_acc": 55.0, "val_auroc": 0.556, "time": 398.68}
{"epoch": 31, "training_loss": 48.154733657836914, "training_acc": 77.5, "val_loss": 13.846429586410522, "val_acc": 55.0, "val_auroc": 0.545, "time": 411.6}
