"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.02045822143555, "training_acc": 42.5, "val_loss": 13.856043815612793, "val_acc": 50.0, "val_auroc": 0.42, "time": 16.05}
{"epoch": 1, "training_loss": 56.395965576171875, "training_acc": 47.5, "val_loss": 13.826656341552734, "val_acc": 50.0, "val_auroc": 0.87, "time": 31.06}
{"epoch": 2, "training_loss": 55.218454360961914, "training_acc": 52.5, "val_loss": 14.705771207809448, "val_acc": 50.0, "val_auroc": 0.33, "time": 45.34}
{"epoch": 3, "training_loss": 57.405123710632324, "training_acc": 51.25, "val_loss": 13.967722654342651, "val_acc": 50.0, "val_auroc": 0.4, "time": 59.79}
{"epoch": 4, "training_loss": 55.26696300506592, "training_acc": 52.5, "val_loss": 13.895373344421387, "val_acc": 50.0, "val_auroc": 0.38, "time": 74.15}
{"epoch": 5, "training_loss": 55.3464937210083, "training_acc": 50.0, "val_loss": 13.895539045333862, "val_acc": 50.0, "val_auroc": 0.38, "time": 88.57}
{"epoch": 6, "training_loss": 54.57133483886719, "training_acc": 53.75, "val_loss": 15.644409656524658, "val_acc": 50.0, "val_auroc": 0.34, "time": 102.59}
{"epoch": 7, "training_loss": 59.411105155944824, "training_acc": 52.5, "val_loss": 14.08103346824646, "val_acc": 50.0, "val_auroc": 0.34, "time": 117.21}
{"epoch": 8, "training_loss": 54.62044334411621, "training_acc": 52.5, "val_loss": 14.022886753082275, "val_acc": 50.0, "val_auroc": 0.32, "time": 131.78}
{"epoch": 9, "training_loss": 56.14565086364746, "training_acc": 47.5, "val_loss": 14.059433937072754, "val_acc": 50.0, "val_auroc": 0.33, "time": 147.09}
{"epoch": 10, "training_loss": 56.159101486206055, "training_acc": 47.5, "val_loss": 13.907793760299683, "val_acc": 50.0, "val_auroc": 0.37, "time": 162.25}
{"epoch": 11, "training_loss": 54.905160903930664, "training_acc": 52.5, "val_loss": 14.435170888900757, "val_acc": 50.0, "val_auroc": 0.47, "time": 177.66}
{"epoch": 12, "training_loss": 56.65796661376953, "training_acc": 52.5, "val_loss": 14.138730764389038, "val_acc": 50.0, "val_auroc": 0.64, "time": 194.31}
{"epoch": 13, "training_loss": 55.40102958679199, "training_acc": 52.5, "val_loss": 13.820794820785522, "val_acc": 50.0, "val_auroc": 0.75, "time": 209.08}
{"epoch": 14, "training_loss": 55.16170883178711, "training_acc": 62.5, "val_loss": 13.83005142211914, "val_acc": 50.0, "val_auroc": 0.79, "time": 223.42}
{"epoch": 15, "training_loss": 55.60048294067383, "training_acc": 47.5, "val_loss": 13.878647089004517, "val_acc": 50.0, "val_auroc": 0.59, "time": 237.99}
{"epoch": 16, "training_loss": 54.90569019317627, "training_acc": 52.5, "val_loss": 14.1510009765625, "val_acc": 50.0, "val_auroc": 0.26, "time": 251.91}
{"epoch": 17, "training_loss": 55.7426061630249, "training_acc": 52.5, "val_loss": 14.189831018447876, "val_acc": 50.0, "val_auroc": 0.43, "time": 266.26}
{"epoch": 18, "training_loss": 55.6296968460083, "training_acc": 52.5, "val_loss": 13.91202449798584, "val_acc": 50.0, "val_auroc": 0.38, "time": 282.74}
{"epoch": 19, "training_loss": 55.043907165527344, "training_acc": 53.75, "val_loss": 13.926745653152466, "val_acc": 50.0, "val_auroc": 0.35, "time": 296.89}
{"epoch": 20, "training_loss": 55.86878204345703, "training_acc": 47.5, "val_loss": 13.931373357772827, "val_acc": 50.0, "val_auroc": 0.38, "time": 311.23}
{"epoch": 21, "training_loss": 55.5445442199707, "training_acc": 47.5, "val_loss": 13.976010084152222, "val_acc": 50.0, "val_auroc": 0.36, "time": 326.3}
{"epoch": 22, "training_loss": 55.33358383178711, "training_acc": 52.5, "val_loss": 14.314179420471191, "val_acc": 50.0, "val_auroc": 0.36, "time": 342.1}
{"epoch": 23, "training_loss": 56.18967533111572, "training_acc": 52.5, "val_loss": 14.038820266723633, "val_acc": 50.0, "val_auroc": 0.52, "time": 357.38}
{"epoch": 24, "training_loss": 55.49648857116699, "training_acc": 52.5, "val_loss": 13.948942422866821, "val_acc": 50.0, "val_auroc": 0.65, "time": 372.73}
{"epoch": 25, "training_loss": 55.208736419677734, "training_acc": 52.5, "val_loss": 13.939417600631714, "val_acc": 50.0, "val_auroc": 0.49, "time": 387.24}
{"epoch": 26, "training_loss": 55.295066833496094, "training_acc": 52.5, "val_loss": 13.981801271438599, "val_acc": 50.0, "val_auroc": 0.36, "time": 402.78}
{"epoch": 27, "training_loss": 55.05004692077637, "training_acc": 52.5, "val_loss": 14.105300903320312, "val_acc": 50.0, "val_auroc": 0.36, "time": 417.24}
{"epoch": 28, "training_loss": 55.551358222961426, "training_acc": 52.5, "val_loss": 13.919374942779541, "val_acc": 50.0, "val_auroc": 0.39, "time": 431.92}
{"epoch": 29, "training_loss": 55.081655502319336, "training_acc": 53.75, "val_loss": 13.892488479614258, "val_acc": 50.0, "val_auroc": 0.41, "time": 447.24}
{"epoch": 30, "training_loss": 55.47692680358887, "training_acc": 47.5, "val_loss": 13.897655010223389, "val_acc": 50.0, "val_auroc": 0.42, "time": 461.92}
{"epoch": 31, "training_loss": 55.52484321594238, "training_acc": 47.5, "val_loss": 13.866636753082275, "val_acc": 50.0, "val_auroc": 0.46, "time": 478.03}
{"epoch": 32, "training_loss": 55.244324684143066, "training_acc": 47.5, "val_loss": 13.858402967453003, "val_acc": 50.0, "val_auroc": 0.58, "time": 494.25}
