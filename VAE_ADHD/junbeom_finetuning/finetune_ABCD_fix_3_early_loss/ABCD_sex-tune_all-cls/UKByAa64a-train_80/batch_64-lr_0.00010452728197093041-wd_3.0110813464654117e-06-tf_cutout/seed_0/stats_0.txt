"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.04672431945801, "training_acc": 42.5, "val_loss": 13.867435455322266, "val_acc": 50.0, "val_auroc": 0.52, "time": 16.58}
{"epoch": 1, "training_loss": 56.63563060760498, "training_acc": 45.0, "val_loss": 16.252702474594116, "val_acc": 50.0, "val_auroc": 0.3, "time": 31.17}
{"epoch": 2, "training_loss": 59.56946563720703, "training_acc": 52.5, "val_loss": 13.916991949081421, "val_acc": 50.0, "val_auroc": 0.59, "time": 46.41}
{"epoch": 3, "training_loss": 55.868510246276855, "training_acc": 47.5, "val_loss": 13.89399766921997, "val_acc": 50.0, "val_auroc": 0.59, "time": 62.08}
{"epoch": 4, "training_loss": 55.205604553222656, "training_acc": 52.5, "val_loss": 13.907519578933716, "val_acc": 50.0, "val_auroc": 0.53, "time": 77.51}
{"epoch": 5, "training_loss": 55.945152282714844, "training_acc": 45.0, "val_loss": 13.90238642692566, "val_acc": 50.0, "val_auroc": 0.47, "time": 95.23}
{"epoch": 6, "training_loss": 55.41419792175293, "training_acc": 47.5, "val_loss": 13.871777057647705, "val_acc": 50.0, "val_auroc": 0.53, "time": 110.5}
{"epoch": 7, "training_loss": 55.3797550201416, "training_acc": 52.5, "val_loss": 13.859766721725464, "val_acc": 50.0, "val_auroc": 0.55, "time": 127.04}
{"epoch": 8, "training_loss": 54.95527935028076, "training_acc": 47.5, "val_loss": 13.889870643615723, "val_acc": 50.0, "val_auroc": 0.53, "time": 141.9}
{"epoch": 9, "training_loss": 54.98697376251221, "training_acc": 47.5, "val_loss": 14.042986631393433, "val_acc": 50.0, "val_auroc": 0.52, "time": 157.24}
{"epoch": 10, "training_loss": 54.92238140106201, "training_acc": 52.5, "val_loss": 13.88129711151123, "val_acc": 50.0, "val_auroc": 0.56, "time": 173.21}
{"epoch": 11, "training_loss": 54.73110485076904, "training_acc": 48.75, "val_loss": 14.025945663452148, "val_acc": 50.0, "val_auroc": 0.56, "time": 188.53}
{"epoch": 12, "training_loss": 54.680097579956055, "training_acc": 52.5, "val_loss": 14.376839399337769, "val_acc": 50.0, "val_auroc": 0.53, "time": 203.61}
{"epoch": 13, "training_loss": 55.78177833557129, "training_acc": 52.5, "val_loss": 14.156506061553955, "val_acc": 50.0, "val_auroc": 0.52, "time": 219.59}
{"epoch": 14, "training_loss": 55.40287780761719, "training_acc": 52.5, "val_loss": 14.446419477462769, "val_acc": 50.0, "val_auroc": 0.54, "time": 234.52}
{"epoch": 15, "training_loss": 55.35342884063721, "training_acc": 52.5, "val_loss": 14.591906070709229, "val_acc": 50.0, "val_auroc": 0.51, "time": 249.56}
{"epoch": 16, "training_loss": 55.8485050201416, "training_acc": 52.5, "val_loss": 13.929258584976196, "val_acc": 50.0, "val_auroc": 0.5, "time": 264.76}
{"epoch": 17, "training_loss": 53.70636177062988, "training_acc": 62.5, "val_loss": 13.925331830978394, "val_acc": 50.0, "val_auroc": 0.51, "time": 282.04}
{"epoch": 18, "training_loss": 54.09965515136719, "training_acc": 53.75, "val_loss": 14.085222482681274, "val_acc": 50.0, "val_auroc": 0.52, "time": 297.26}
{"epoch": 19, "training_loss": 54.44914436340332, "training_acc": 53.75, "val_loss": 13.899768590927124, "val_acc": 50.0, "val_auroc": 0.53, "time": 312.36}
{"epoch": 20, "training_loss": 52.756330490112305, "training_acc": 65.0, "val_loss": 14.938150644302368, "val_acc": 55.0, "val_auroc": 0.56, "time": 327.24}
{"epoch": 21, "training_loss": 57.30665588378906, "training_acc": 47.5, "val_loss": 14.006298780441284, "val_acc": 50.0, "val_auroc": 0.51, "time": 341.87}
{"epoch": 22, "training_loss": 53.58888530731201, "training_acc": 53.75, "val_loss": 14.683847427368164, "val_acc": 50.0, "val_auroc": 0.54, "time": 356.56}
{"epoch": 23, "training_loss": 56.58337593078613, "training_acc": 52.5, "val_loss": 14.28061842918396, "val_acc": 50.0, "val_auroc": 0.53, "time": 371.19}
{"epoch": 24, "training_loss": 55.46044158935547, "training_acc": 52.5, "val_loss": 13.883427381515503, "val_acc": 50.0, "val_auroc": 0.48, "time": 385.98}
{"epoch": 25, "training_loss": 55.0421142578125, "training_acc": 52.5, "val_loss": 13.937114477157593, "val_acc": 50.0, "val_auroc": 0.54, "time": 402.18}
{"epoch": 26, "training_loss": 55.809959411621094, "training_acc": 47.5, "val_loss": 13.853151798248291, "val_acc": 50.0, "val_auroc": 0.62, "time": 417.51}
{"epoch": 27, "training_loss": 55.039902687072754, "training_acc": 52.5, "val_loss": 14.045888185501099, "val_acc": 50.0, "val_auroc": 0.68, "time": 433.38}
{"epoch": 28, "training_loss": 56.1909294128418, "training_acc": 52.5, "val_loss": 14.071238040924072, "val_acc": 50.0, "val_auroc": 0.68, "time": 448.34}
{"epoch": 29, "training_loss": 55.45138168334961, "training_acc": 52.5, "val_loss": 13.841164112091064, "val_acc": 50.0, "val_auroc": 0.64, "time": 463.39}
{"epoch": 30, "training_loss": 54.99789047241211, "training_acc": 52.5, "val_loss": 13.860056400299072, "val_acc": 50.0, "val_auroc": 0.54, "time": 478.12}
{"epoch": 31, "training_loss": 55.0254602432251, "training_acc": 56.25, "val_loss": 13.871763944625854, "val_acc": 50.0, "val_auroc": 0.53, "time": 493.66}
{"epoch": 32, "training_loss": 54.98639678955078, "training_acc": 65.0, "val_loss": 13.87938380241394, "val_acc": 50.0, "val_auroc": 0.52, "time": 509.12}
{"epoch": 33, "training_loss": 54.73272895812988, "training_acc": 70.0, "val_loss": 13.891394138336182, "val_acc": 50.0, "val_auroc": 0.52, "time": 524.35}
{"epoch": 34, "training_loss": 54.439462661743164, "training_acc": 57.5, "val_loss": 14.0172278881073, "val_acc": 50.0, "val_auroc": 0.51, "time": 539.89}
{"epoch": 35, "training_loss": 55.02792549133301, "training_acc": 52.5, "val_loss": 14.010937213897705, "val_acc": 50.0, "val_auroc": 0.49, "time": 554.73}
{"epoch": 36, "training_loss": 54.1374568939209, "training_acc": 51.25, "val_loss": 13.961657285690308, "val_acc": 50.0, "val_auroc": 0.45, "time": 570.31}
{"epoch": 37, "training_loss": 54.949604988098145, "training_acc": 48.75, "val_loss": 14.06886100769043, "val_acc": 50.0, "val_auroc": 0.44, "time": 587.54}
{"epoch": 38, "training_loss": 55.36744976043701, "training_acc": 47.5, "val_loss": 13.896692991256714, "val_acc": 50.0, "val_auroc": 0.53, "time": 604.82}
{"epoch": 39, "training_loss": 54.282596588134766, "training_acc": 58.75, "val_loss": 14.01455044746399, "val_acc": 50.0, "val_auroc": 0.5, "time": 620.31}
{"epoch": 40, "training_loss": 54.07554340362549, "training_acc": 52.5, "val_loss": 14.077574014663696, "val_acc": 50.0, "val_auroc": 0.48, "time": 635.0}
{"epoch": 41, "training_loss": 54.13694763183594, "training_acc": 52.5, "val_loss": 13.881828784942627, "val_acc": 50.0, "val_auroc": 0.47, "time": 650.05}
{"epoch": 42, "training_loss": 53.90509605407715, "training_acc": 67.5, "val_loss": 13.917287588119507, "val_acc": 50.0, "val_auroc": 0.47, "time": 665.53}
{"epoch": 43, "training_loss": 54.12779998779297, "training_acc": 51.25, "val_loss": 13.888839483261108, "val_acc": 50.0, "val_auroc": 0.48, "time": 679.86}
{"epoch": 44, "training_loss": 54.00935363769531, "training_acc": 61.25, "val_loss": 14.054020643234253, "val_acc": 50.0, "val_auroc": 0.46, "time": 695.48}
{"epoch": 45, "training_loss": 53.542757987976074, "training_acc": 52.5, "val_loss": 13.904958963394165, "val_acc": 50.0, "val_auroc": 0.46, "time": 709.8}
{"epoch": 46, "training_loss": 53.31040668487549, "training_acc": 72.5, "val_loss": 13.935123682022095, "val_acc": 50.0, "val_auroc": 0.47, "time": 725.14}
{"epoch": 47, "training_loss": 52.23739242553711, "training_acc": 66.25, "val_loss": 14.035776853561401, "val_acc": 50.0, "val_auroc": 0.46, "time": 741.43}
{"epoch": 48, "training_loss": 51.688026428222656, "training_acc": 66.25, "val_loss": 13.902024030685425, "val_acc": 50.0, "val_auroc": 0.46, "time": 758.27}
