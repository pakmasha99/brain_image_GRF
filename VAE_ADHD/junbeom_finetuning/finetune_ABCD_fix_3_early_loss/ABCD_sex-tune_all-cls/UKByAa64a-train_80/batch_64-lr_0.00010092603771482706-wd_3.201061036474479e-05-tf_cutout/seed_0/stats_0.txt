"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5755615234375, "training_acc": 52.5, "val_loss": 13.949061632156372, "val_acc": 50.0, "val_auroc": 0.28, "time": 19.69}
{"epoch": 1, "training_loss": 55.41966438293457, "training_acc": 52.5, "val_loss": 13.862420320510864, "val_acc": 50.0, "val_auroc": 0.73, "time": 35.28}
{"epoch": 2, "training_loss": 55.24161338806152, "training_acc": 52.5, "val_loss": 13.871945142745972, "val_acc": 50.0, "val_auroc": 0.63, "time": 53.15}
{"epoch": 3, "training_loss": 55.21404838562012, "training_acc": 52.5, "val_loss": 13.85628342628479, "val_acc": 50.0, "val_auroc": 0.66, "time": 69.58}
{"epoch": 4, "training_loss": 55.186445236206055, "training_acc": 52.5, "val_loss": 13.88667345046997, "val_acc": 50.0, "val_auroc": 0.43, "time": 87.14}
{"epoch": 5, "training_loss": 55.20957374572754, "training_acc": 52.5, "val_loss": 13.872846364974976, "val_acc": 50.0, "val_auroc": 0.45, "time": 103.17}
{"epoch": 6, "training_loss": 55.15878200531006, "training_acc": 65.0, "val_loss": 13.864444494247437, "val_acc": 50.0, "val_auroc": 0.46, "time": 118.82}
{"epoch": 7, "training_loss": 55.23222255706787, "training_acc": 60.0, "val_loss": 13.86467695236206, "val_acc": 50.0, "val_auroc": 0.49, "time": 133.94}
{"epoch": 8, "training_loss": 55.04110527038574, "training_acc": 73.75, "val_loss": 13.873357772827148, "val_acc": 50.0, "val_auroc": 0.5, "time": 149.21}
{"epoch": 9, "training_loss": 54.96764945983887, "training_acc": 67.5, "val_loss": 13.878859281539917, "val_acc": 50.0, "val_auroc": 0.54, "time": 164.21}
{"epoch": 10, "training_loss": 54.7349271774292, "training_acc": 52.5, "val_loss": 13.909138441085815, "val_acc": 50.0, "val_auroc": 0.53, "time": 179.93}
{"epoch": 11, "training_loss": 54.78404998779297, "training_acc": 52.5, "val_loss": 14.016709327697754, "val_acc": 50.0, "val_auroc": 0.57, "time": 194.93}
{"epoch": 12, "training_loss": 54.783626556396484, "training_acc": 52.5, "val_loss": 14.067857265472412, "val_acc": 50.0, "val_auroc": 0.51, "time": 209.86}
{"epoch": 13, "training_loss": 54.83575630187988, "training_acc": 52.5, "val_loss": 14.050155878067017, "val_acc": 50.0, "val_auroc": 0.54, "time": 225.59}
{"epoch": 14, "training_loss": 54.47741222381592, "training_acc": 52.5, "val_loss": 14.292402267456055, "val_acc": 50.0, "val_auroc": 0.54, "time": 240.69}
{"epoch": 15, "training_loss": 55.02364730834961, "training_acc": 52.5, "val_loss": 14.30065393447876, "val_acc": 50.0, "val_auroc": 0.52, "time": 256.01}
{"epoch": 16, "training_loss": 54.7501277923584, "training_acc": 52.5, "val_loss": 14.020370244979858, "val_acc": 50.0, "val_auroc": 0.5, "time": 271.05}
{"epoch": 17, "training_loss": 53.84982872009277, "training_acc": 52.5, "val_loss": 13.969181776046753, "val_acc": 50.0, "val_auroc": 0.51, "time": 286.74}
{"epoch": 18, "training_loss": 53.38302135467529, "training_acc": 53.75, "val_loss": 13.957326412200928, "val_acc": 50.0, "val_auroc": 0.56, "time": 303.8}
{"epoch": 19, "training_loss": 52.95048999786377, "training_acc": 58.75, "val_loss": 13.864015340805054, "val_acc": 50.0, "val_auroc": 0.57, "time": 318.96}
{"epoch": 20, "training_loss": 54.564011573791504, "training_acc": 56.25, "val_loss": 13.871809244155884, "val_acc": 50.0, "val_auroc": 0.56, "time": 334.62}
{"epoch": 21, "training_loss": 55.00528049468994, "training_acc": 51.25, "val_loss": 13.920546770095825, "val_acc": 50.0, "val_auroc": 0.43, "time": 350.94}
{"epoch": 22, "training_loss": 54.876766204833984, "training_acc": 52.5, "val_loss": 13.972538709640503, "val_acc": 50.0, "val_auroc": 0.58, "time": 366.88}
