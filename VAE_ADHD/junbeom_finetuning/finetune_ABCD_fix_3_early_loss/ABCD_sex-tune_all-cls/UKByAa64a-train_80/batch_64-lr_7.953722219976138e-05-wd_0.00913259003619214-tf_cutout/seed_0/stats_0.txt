"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.55014991760254, "training_acc": 52.5, "val_loss": 13.932722806930542, "val_acc": 50.0, "val_auroc": 0.26, "time": 19.41}
{"epoch": 1, "training_loss": 55.32040500640869, "training_acc": 52.5, "val_loss": 13.814241886138916, "val_acc": 50.0, "val_auroc": 0.76, "time": 36.82}
{"epoch": 2, "training_loss": 55.27260875701904, "training_acc": 52.5, "val_loss": 13.881317377090454, "val_acc": 50.0, "val_auroc": 0.49, "time": 55.97}
{"epoch": 3, "training_loss": 55.05467224121094, "training_acc": 52.5, "val_loss": 13.898285627365112, "val_acc": 50.0, "val_auroc": 0.45, "time": 78.76}
{"epoch": 4, "training_loss": 55.14053440093994, "training_acc": 53.75, "val_loss": 13.907241821289062, "val_acc": 50.0, "val_auroc": 0.36, "time": 97.01}
{"epoch": 5, "training_loss": 55.05307197570801, "training_acc": 52.5, "val_loss": 13.91150712966919, "val_acc": 50.0, "val_auroc": 0.31, "time": 114.83}
{"epoch": 6, "training_loss": 55.07660484313965, "training_acc": 61.25, "val_loss": 13.908886909484863, "val_acc": 50.0, "val_auroc": 0.31, "time": 134.88}
{"epoch": 7, "training_loss": 55.03862762451172, "training_acc": 67.5, "val_loss": 13.907805681228638, "val_acc": 50.0, "val_auroc": 0.32, "time": 156.97}
{"epoch": 8, "training_loss": 54.77957534790039, "training_acc": 61.25, "val_loss": 13.919166326522827, "val_acc": 50.0, "val_auroc": 0.34, "time": 174.3}
{"epoch": 9, "training_loss": 54.66394329071045, "training_acc": 71.25, "val_loss": 13.91658902168274, "val_acc": 50.0, "val_auroc": 0.4, "time": 190.83}
{"epoch": 10, "training_loss": 54.200321197509766, "training_acc": 77.5, "val_loss": 14.001364707946777, "val_acc": 50.0, "val_auroc": 0.34, "time": 208.91}
{"epoch": 11, "training_loss": 54.29072952270508, "training_acc": 56.25, "val_loss": 14.10645842552185, "val_acc": 50.0, "val_auroc": 0.27, "time": 228.47}
{"epoch": 12, "training_loss": 54.37987518310547, "training_acc": 52.5, "val_loss": 13.992071151733398, "val_acc": 50.0, "val_auroc": 0.42, "time": 245.8}
{"epoch": 13, "training_loss": 53.96255302429199, "training_acc": 50.0, "val_loss": 13.993955850601196, "val_acc": 50.0, "val_auroc": 0.43, "time": 265.56}
{"epoch": 14, "training_loss": 53.310441970825195, "training_acc": 53.75, "val_loss": 14.441019296646118, "val_acc": 50.0, "val_auroc": 0.32, "time": 282.43}
{"epoch": 15, "training_loss": 55.82024097442627, "training_acc": 52.5, "val_loss": 14.051951169967651, "val_acc": 50.0, "val_auroc": 0.37, "time": 303.08}
{"epoch": 16, "training_loss": 55.50917434692383, "training_acc": 52.5, "val_loss": 14.075092077255249, "val_acc": 50.0, "val_auroc": 0.39, "time": 319.62}
{"epoch": 17, "training_loss": 55.28182792663574, "training_acc": 52.5, "val_loss": 14.057455062866211, "val_acc": 50.0, "val_auroc": 0.36, "time": 335.85}
{"epoch": 18, "training_loss": 55.01724433898926, "training_acc": 52.5, "val_loss": 13.965885639190674, "val_acc": 50.0, "val_auroc": 0.35, "time": 353.68}
{"epoch": 19, "training_loss": 54.89738655090332, "training_acc": 52.5, "val_loss": 13.91486644744873, "val_acc": 50.0, "val_auroc": 0.38, "time": 371.88}
{"epoch": 20, "training_loss": 54.65539836883545, "training_acc": 55.0, "val_loss": 13.934074640274048, "val_acc": 50.0, "val_auroc": 0.31, "time": 391.01}
