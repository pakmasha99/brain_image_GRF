"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.48877716064453, "training_acc": 51.25, "val_loss": 13.82351279258728, "val_acc": 55.0, "val_auroc": 0.263, "time": 19.68}
{"epoch": 1, "training_loss": 55.37124443054199, "training_acc": 51.25, "val_loss": 13.804184198379517, "val_acc": 55.0, "val_auroc": 0.515, "time": 37.88}
{"epoch": 2, "training_loss": 55.40691375732422, "training_acc": 51.25, "val_loss": 13.797166347503662, "val_acc": 55.0, "val_auroc": 0.485, "time": 56.9}
{"epoch": 3, "training_loss": 55.33804512023926, "training_acc": 51.25, "val_loss": 13.798121213912964, "val_acc": 55.0, "val_auroc": 0.545, "time": 77.49}
{"epoch": 4, "training_loss": 55.43967819213867, "training_acc": 51.25, "val_loss": 13.78230333328247, "val_acc": 55.0, "val_auroc": 0.606, "time": 95.8}
{"epoch": 5, "training_loss": 55.35219955444336, "training_acc": 51.25, "val_loss": 13.77960205078125, "val_acc": 55.0, "val_auroc": 0.444, "time": 116.38}
{"epoch": 6, "training_loss": 55.31194305419922, "training_acc": 51.25, "val_loss": 13.793613910675049, "val_acc": 55.0, "val_auroc": 0.434, "time": 133.92}
{"epoch": 7, "training_loss": 55.16688919067383, "training_acc": 51.25, "val_loss": 13.84259819984436, "val_acc": 55.0, "val_auroc": 0.455, "time": 154.79}
{"epoch": 8, "training_loss": 55.2339448928833, "training_acc": 52.5, "val_loss": 13.945330381393433, "val_acc": 55.0, "val_auroc": 0.424, "time": 171.9}
{"epoch": 9, "training_loss": 55.24017906188965, "training_acc": 48.75, "val_loss": 13.959472179412842, "val_acc": 55.0, "val_auroc": 0.485, "time": 190.33}
{"epoch": 10, "training_loss": 55.17324924468994, "training_acc": 48.75, "val_loss": 13.812965154647827, "val_acc": 55.0, "val_auroc": 0.434, "time": 206.74}
{"epoch": 11, "training_loss": 54.98519515991211, "training_acc": 51.25, "val_loss": 13.757494688034058, "val_acc": 55.0, "val_auroc": 0.576, "time": 224.1}
{"epoch": 12, "training_loss": 55.61309623718262, "training_acc": 51.25, "val_loss": 13.766437768936157, "val_acc": 55.0, "val_auroc": 0.556, "time": 242.19}
{"epoch": 13, "training_loss": 55.62624263763428, "training_acc": 51.25, "val_loss": 13.794933557510376, "val_acc": 55.0, "val_auroc": 0.384, "time": 261.87}
{"epoch": 14, "training_loss": 55.11028480529785, "training_acc": 51.25, "val_loss": 13.900766372680664, "val_acc": 55.0, "val_auroc": 0.354, "time": 281.91}
{"epoch": 15, "training_loss": 55.37507629394531, "training_acc": 57.5, "val_loss": 13.879122734069824, "val_acc": 55.0, "val_auroc": 0.404, "time": 300.37}
{"epoch": 16, "training_loss": 54.73482036590576, "training_acc": 72.5, "val_loss": 13.767603635787964, "val_acc": 55.0, "val_auroc": 0.485, "time": 317.7}
{"epoch": 17, "training_loss": 55.34155082702637, "training_acc": 51.25, "val_loss": 13.760538101196289, "val_acc": 55.0, "val_auroc": 0.495, "time": 335.59}
{"epoch": 18, "training_loss": 55.16245079040527, "training_acc": 51.25, "val_loss": 13.813978433609009, "val_acc": 55.0, "val_auroc": 0.444, "time": 353.03}
{"epoch": 19, "training_loss": 54.76248741149902, "training_acc": 56.25, "val_loss": 13.972880840301514, "val_acc": 55.0, "val_auroc": 0.384, "time": 369.55}
{"epoch": 20, "training_loss": 55.15061283111572, "training_acc": 48.75, "val_loss": 14.001305103302002, "val_acc": 55.0, "val_auroc": 0.515, "time": 388.87}
{"epoch": 21, "training_loss": 54.78513526916504, "training_acc": 52.5, "val_loss": 13.804410696029663, "val_acc": 55.0, "val_auroc": 0.505, "time": 407.56}
{"epoch": 22, "training_loss": 54.64700698852539, "training_acc": 55.0, "val_loss": 13.77351999282837, "val_acc": 55.0, "val_auroc": 0.525, "time": 427.38}
{"epoch": 23, "training_loss": 54.40855121612549, "training_acc": 53.75, "val_loss": 13.844586610794067, "val_acc": 55.0, "val_auroc": 0.465, "time": 445.58}
{"epoch": 24, "training_loss": 53.663564682006836, "training_acc": 66.25, "val_loss": 13.851648569107056, "val_acc": 55.0, "val_auroc": 0.485, "time": 462.73}
{"epoch": 25, "training_loss": 53.26670455932617, "training_acc": 60.0, "val_loss": 13.856891393661499, "val_acc": 55.0, "val_auroc": 0.495, "time": 479.14}
{"epoch": 26, "training_loss": 53.41264343261719, "training_acc": 56.25, "val_loss": 13.875261545181274, "val_acc": 55.0, "val_auroc": 0.475, "time": 497.19}
{"epoch": 27, "training_loss": 50.740614891052246, "training_acc": 75.0, "val_loss": 14.022749662399292, "val_acc": 55.0, "val_auroc": 0.616, "time": 513.68}
{"epoch": 28, "training_loss": 52.89728260040283, "training_acc": 60.0, "val_loss": 14.300024509429932, "val_acc": 55.0, "val_auroc": 0.414, "time": 532.62}
{"epoch": 29, "training_loss": 56.4290075302124, "training_acc": 48.75, "val_loss": 14.039547443389893, "val_acc": 55.0, "val_auroc": 0.354, "time": 549.44}
{"epoch": 30, "training_loss": 55.802348136901855, "training_acc": 48.75, "val_loss": 13.853530883789062, "val_acc": 55.0, "val_auroc": 0.485, "time": 566.09}
