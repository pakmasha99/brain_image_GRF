"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.546512603759766, "training_acc": 52.5, "val_loss": 13.888721466064453, "val_acc": 50.0, "val_auroc": 0.57, "time": 19.97}
{"epoch": 1, "training_loss": 55.31203842163086, "training_acc": 52.5, "val_loss": 13.905987739562988, "val_acc": 50.0, "val_auroc": 0.59, "time": 37.42}
{"epoch": 2, "training_loss": 55.3576078414917, "training_acc": 52.5, "val_loss": 13.87597918510437, "val_acc": 50.0, "val_auroc": 0.67, "time": 60.27}
{"epoch": 3, "training_loss": 55.30707550048828, "training_acc": 52.5, "val_loss": 13.863283395767212, "val_acc": 50.0, "val_auroc": 0.64, "time": 84.61}
{"epoch": 4, "training_loss": 55.27389144897461, "training_acc": 52.5, "val_loss": 13.842939138412476, "val_acc": 50.0, "val_auroc": 0.73, "time": 102.49}
{"epoch": 5, "training_loss": 55.334421157836914, "training_acc": 52.5, "val_loss": 13.852494955062866, "val_acc": 50.0, "val_auroc": 0.75, "time": 119.53}
{"epoch": 6, "training_loss": 55.28787803649902, "training_acc": 52.5, "val_loss": 13.881596326828003, "val_acc": 50.0, "val_auroc": 0.77, "time": 136.51}
{"epoch": 7, "training_loss": 55.264994621276855, "training_acc": 52.5, "val_loss": 13.87912392616272, "val_acc": 50.0, "val_auroc": 0.75, "time": 154.57}
{"epoch": 8, "training_loss": 55.19999980926514, "training_acc": 52.5, "val_loss": 13.866175413131714, "val_acc": 50.0, "val_auroc": 0.71, "time": 171.65}
{"epoch": 9, "training_loss": 55.13029861450195, "training_acc": 52.5, "val_loss": 13.822121620178223, "val_acc": 50.0, "val_auroc": 0.84, "time": 189.38}
{"epoch": 10, "training_loss": 55.277408599853516, "training_acc": 50.0, "val_loss": 13.81889820098877, "val_acc": 50.0, "val_auroc": 0.85, "time": 207.5}
{"epoch": 11, "training_loss": 55.217132568359375, "training_acc": 67.5, "val_loss": 13.832741975784302, "val_acc": 50.0, "val_auroc": 0.78, "time": 228.63}
{"epoch": 12, "training_loss": 55.070363998413086, "training_acc": 52.5, "val_loss": 13.903146982192993, "val_acc": 50.0, "val_auroc": 0.8, "time": 245.41}
{"epoch": 13, "training_loss": 55.139150619506836, "training_acc": 52.5, "val_loss": 13.936614990234375, "val_acc": 50.0, "val_auroc": 0.82, "time": 262.53}
{"epoch": 14, "training_loss": 55.30831241607666, "training_acc": 52.5, "val_loss": 13.978179693222046, "val_acc": 50.0, "val_auroc": 0.81, "time": 280.98}
{"epoch": 15, "training_loss": 55.29429626464844, "training_acc": 52.5, "val_loss": 14.042274951934814, "val_acc": 50.0, "val_auroc": 0.81, "time": 298.81}
{"epoch": 16, "training_loss": 55.36724281311035, "training_acc": 52.5, "val_loss": 13.94730806350708, "val_acc": 50.0, "val_auroc": 0.82, "time": 316.96}
{"epoch": 17, "training_loss": 54.96060371398926, "training_acc": 52.5, "val_loss": 13.796142339706421, "val_acc": 50.0, "val_auroc": 0.82, "time": 334.95}
{"epoch": 18, "training_loss": 54.84299659729004, "training_acc": 52.5, "val_loss": 13.789052963256836, "val_acc": 50.0, "val_auroc": 0.83, "time": 353.87}
{"epoch": 19, "training_loss": 55.08543109893799, "training_acc": 70.0, "val_loss": 13.743776082992554, "val_acc": 50.0, "val_auroc": 0.78, "time": 374.9}
{"epoch": 20, "training_loss": 54.741065979003906, "training_acc": 73.75, "val_loss": 13.684191703796387, "val_acc": 50.0, "val_auroc": 0.8, "time": 393.34}
{"epoch": 21, "training_loss": 54.28285503387451, "training_acc": 70.0, "val_loss": 13.798836469650269, "val_acc": 50.0, "val_auroc": 0.81, "time": 410.36}
{"epoch": 22, "training_loss": 54.653334617614746, "training_acc": 52.5, "val_loss": 13.732370138168335, "val_acc": 50.0, "val_auroc": 0.83, "time": 429.44}
{"epoch": 23, "training_loss": 54.39045715332031, "training_acc": 53.75, "val_loss": 13.656821250915527, "val_acc": 50.0, "val_auroc": 0.82, "time": 451.56}
{"epoch": 24, "training_loss": 53.82819938659668, "training_acc": 61.25, "val_loss": 13.721219301223755, "val_acc": 50.0, "val_auroc": 0.81, "time": 469.87}
{"epoch": 25, "training_loss": 53.605164527893066, "training_acc": 52.5, "val_loss": 13.552665710449219, "val_acc": 50.0, "val_auroc": 0.81, "time": 487.1}
{"epoch": 26, "training_loss": 53.160765647888184, "training_acc": 77.5, "val_loss": 13.640822172164917, "val_acc": 50.0, "val_auroc": 0.79, "time": 504.8}
{"epoch": 27, "training_loss": 52.45981025695801, "training_acc": 58.75, "val_loss": 13.397473096847534, "val_acc": 50.0, "val_auroc": 0.79, "time": 526.24}
{"epoch": 28, "training_loss": 51.49992847442627, "training_acc": 61.25, "val_loss": 13.932546377182007, "val_acc": 50.0, "val_auroc": 0.53, "time": 543.99}
{"epoch": 29, "training_loss": 56.04145526885986, "training_acc": 47.5, "val_loss": 13.842390775680542, "val_acc": 50.0, "val_auroc": 0.66, "time": 560.6}
{"epoch": 30, "training_loss": 55.210147857666016, "training_acc": 52.5, "val_loss": 13.910373449325562, "val_acc": 50.0, "val_auroc": 0.64, "time": 577.98}
{"epoch": 31, "training_loss": 55.33566665649414, "training_acc": 52.5, "val_loss": 13.916161060333252, "val_acc": 50.0, "val_auroc": 0.85, "time": 596.6}
{"epoch": 32, "training_loss": 55.432485580444336, "training_acc": 52.5, "val_loss": 13.876104354858398, "val_acc": 50.0, "val_auroc": 0.72, "time": 614.64}
{"epoch": 33, "training_loss": 55.3277473449707, "training_acc": 52.5, "val_loss": 13.845394849777222, "val_acc": 50.0, "val_auroc": 0.74, "time": 631.21}
{"epoch": 34, "training_loss": 55.30711364746094, "training_acc": 52.5, "val_loss": 13.851420879364014, "val_acc": 50.0, "val_auroc": 0.84, "time": 648.75}
{"epoch": 35, "training_loss": 55.557735443115234, "training_acc": 52.5, "val_loss": 13.848856687545776, "val_acc": 50.0, "val_auroc": 0.87, "time": 668.55}
{"epoch": 36, "training_loss": 55.23470878601074, "training_acc": 52.5, "val_loss": 13.855060338973999, "val_acc": 50.0, "val_auroc": 0.89, "time": 686.42}
{"epoch": 37, "training_loss": 55.53662300109863, "training_acc": 47.5, "val_loss": 13.905279636383057, "val_acc": 50.0, "val_auroc": 0.8, "time": 703.03}
{"epoch": 38, "training_loss": 55.94309043884277, "training_acc": 47.5, "val_loss": 13.889545202255249, "val_acc": 50.0, "val_auroc": 0.75, "time": 720.48}
{"epoch": 39, "training_loss": 55.78268241882324, "training_acc": 47.5, "val_loss": 13.853548765182495, "val_acc": 50.0, "val_auroc": 0.81, "time": 740.49}
{"epoch": 40, "training_loss": 55.46135330200195, "training_acc": 47.5, "val_loss": 13.86318564414978, "val_acc": 50.0, "val_auroc": 0.85, "time": 757.68}
{"epoch": 41, "training_loss": 55.443203926086426, "training_acc": 52.5, "val_loss": 13.869255781173706, "val_acc": 50.0, "val_auroc": 0.84, "time": 775.18}
{"epoch": 42, "training_loss": 55.3577995300293, "training_acc": 52.5, "val_loss": 13.856912851333618, "val_acc": 50.0, "val_auroc": 0.9, "time": 793.8}
{"epoch": 43, "training_loss": 55.34207725524902, "training_acc": 52.5, "val_loss": 13.86606216430664, "val_acc": 50.0, "val_auroc": 0.85, "time": 815.13}
{"epoch": 44, "training_loss": 55.3271427154541, "training_acc": 52.5, "val_loss": 13.879939317703247, "val_acc": 50.0, "val_auroc": 0.8, "time": 831.84}
{"epoch": 45, "training_loss": 55.30788230895996, "training_acc": 52.5, "val_loss": 13.88020396232605, "val_acc": 50.0, "val_auroc": 0.8, "time": 848.86}
{"epoch": 46, "training_loss": 55.32429122924805, "training_acc": 52.5, "val_loss": 13.883768320083618, "val_acc": 50.0, "val_auroc": 0.82, "time": 866.02}
