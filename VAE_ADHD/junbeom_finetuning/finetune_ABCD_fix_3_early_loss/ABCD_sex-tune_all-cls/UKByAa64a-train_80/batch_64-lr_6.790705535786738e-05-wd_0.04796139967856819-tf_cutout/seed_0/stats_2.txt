"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.46491527557373, "training_acc": 51.25, "val_loss": 13.892608880996704, "val_acc": 50.0, "val_auroc": 0.46, "time": 18.94}
{"epoch": 1, "training_loss": 55.32907581329346, "training_acc": 52.5, "val_loss": 13.913085460662842, "val_acc": 50.0, "val_auroc": 0.29, "time": 35.87}
{"epoch": 2, "training_loss": 55.33296585083008, "training_acc": 52.5, "val_loss": 13.91139030456543, "val_acc": 50.0, "val_auroc": 0.58, "time": 53.1}
{"epoch": 3, "training_loss": 55.36672496795654, "training_acc": 52.5, "val_loss": 13.934993743896484, "val_acc": 50.0, "val_auroc": 0.43, "time": 73.32}
{"epoch": 4, "training_loss": 55.24298286437988, "training_acc": 52.5, "val_loss": 13.891427516937256, "val_acc": 50.0, "val_auroc": 0.52, "time": 92.52}
{"epoch": 5, "training_loss": 55.08848857879639, "training_acc": 52.5, "val_loss": 13.882845640182495, "val_acc": 50.0, "val_auroc": 0.51, "time": 110.23}
{"epoch": 6, "training_loss": 55.10200214385986, "training_acc": 52.5, "val_loss": 13.935699462890625, "val_acc": 50.0, "val_auroc": 0.5, "time": 127.8}
{"epoch": 7, "training_loss": 55.06889629364014, "training_acc": 52.5, "val_loss": 14.043892621994019, "val_acc": 50.0, "val_auroc": 0.41, "time": 146.29}
{"epoch": 8, "training_loss": 55.338815689086914, "training_acc": 52.5, "val_loss": 13.95739197731018, "val_acc": 50.0, "val_auroc": 0.42, "time": 164.31}
{"epoch": 9, "training_loss": 55.0903377532959, "training_acc": 52.5, "val_loss": 13.883293867111206, "val_acc": 50.0, "val_auroc": 0.44, "time": 181.66}
{"epoch": 10, "training_loss": 55.14130401611328, "training_acc": 52.5, "val_loss": 13.885527849197388, "val_acc": 50.0, "val_auroc": 0.45, "time": 198.3}
{"epoch": 11, "training_loss": 55.02711296081543, "training_acc": 52.5, "val_loss": 13.94973874092102, "val_acc": 50.0, "val_auroc": 0.27, "time": 215.06}
{"epoch": 12, "training_loss": 55.039188385009766, "training_acc": 52.5, "val_loss": 13.966472148895264, "val_acc": 50.0, "val_auroc": 0.42, "time": 233.45}
{"epoch": 13, "training_loss": 54.9786319732666, "training_acc": 52.5, "val_loss": 13.876770734786987, "val_acc": 50.0, "val_auroc": 0.6, "time": 252.35}
{"epoch": 14, "training_loss": 54.75075912475586, "training_acc": 52.5, "val_loss": 13.844428062438965, "val_acc": 50.0, "val_auroc": 0.59, "time": 269.15}
{"epoch": 15, "training_loss": 54.65537643432617, "training_acc": 53.75, "val_loss": 13.920756578445435, "val_acc": 50.0, "val_auroc": 0.5, "time": 287.46}
{"epoch": 16, "training_loss": 54.63192367553711, "training_acc": 52.5, "val_loss": 14.04772400856018, "val_acc": 50.0, "val_auroc": 0.42, "time": 304.38}
{"epoch": 17, "training_loss": 55.120619773864746, "training_acc": 52.5, "val_loss": 14.000301361083984, "val_acc": 50.0, "val_auroc": 0.41, "time": 323.32}
{"epoch": 18, "training_loss": 54.66280746459961, "training_acc": 52.5, "val_loss": 13.835875988006592, "val_acc": 50.0, "val_auroc": 0.51, "time": 342.8}
{"epoch": 19, "training_loss": 54.78990459442139, "training_acc": 56.25, "val_loss": 13.817956447601318, "val_acc": 50.0, "val_auroc": 0.59, "time": 361.81}
{"epoch": 20, "training_loss": 54.48446083068848, "training_acc": 68.75, "val_loss": 13.875306844711304, "val_acc": 50.0, "val_auroc": 0.48, "time": 378.99}
{"epoch": 21, "training_loss": 54.222275733947754, "training_acc": 52.5, "val_loss": 13.923705816268921, "val_acc": 50.0, "val_auroc": 0.59, "time": 397.75}
{"epoch": 22, "training_loss": 54.24985313415527, "training_acc": 52.5, "val_loss": 13.828091621398926, "val_acc": 50.0, "val_auroc": 0.54, "time": 415.75}
{"epoch": 23, "training_loss": 53.66641807556152, "training_acc": 53.75, "val_loss": 13.76582145690918, "val_acc": 50.0, "val_auroc": 0.55, "time": 434.47}
{"epoch": 24, "training_loss": 53.00975036621094, "training_acc": 65.0, "val_loss": 13.99862289428711, "val_acc": 50.0, "val_auroc": 0.63, "time": 452.34}
{"epoch": 25, "training_loss": 53.708513259887695, "training_acc": 52.5, "val_loss": 13.68441104888916, "val_acc": 50.0, "val_auroc": 0.63, "time": 471.85}
{"epoch": 26, "training_loss": 53.36152362823486, "training_acc": 66.25, "val_loss": 13.74666690826416, "val_acc": 50.0, "val_auroc": 0.59, "time": 489.65}
{"epoch": 27, "training_loss": 51.723257064819336, "training_acc": 63.75, "val_loss": 14.070767164230347, "val_acc": 50.0, "val_auroc": 0.51, "time": 508.92}
{"epoch": 28, "training_loss": 52.03036880493164, "training_acc": 55.0, "val_loss": 13.855226039886475, "val_acc": 50.0, "val_auroc": 0.54, "time": 527.05}
{"epoch": 29, "training_loss": 54.92647361755371, "training_acc": 51.25, "val_loss": 13.866487741470337, "val_acc": 50.0, "val_auroc": 0.27, "time": 548.75}
{"epoch": 30, "training_loss": 55.2161865234375, "training_acc": 52.5, "val_loss": 13.884059190750122, "val_acc": 50.0, "val_auroc": 0.54, "time": 566.83}
{"epoch": 31, "training_loss": 54.9692440032959, "training_acc": 52.5, "val_loss": 13.861048221588135, "val_acc": 50.0, "val_auroc": 0.63, "time": 584.05}
{"epoch": 32, "training_loss": 54.526079177856445, "training_acc": 52.5, "val_loss": 13.812941312789917, "val_acc": 50.0, "val_auroc": 0.63, "time": 601.27}
{"epoch": 33, "training_loss": 54.39355659484863, "training_acc": 70.0, "val_loss": 13.803119659423828, "val_acc": 50.0, "val_auroc": 0.67, "time": 622.64}
{"epoch": 34, "training_loss": 54.068735122680664, "training_acc": 75.0, "val_loss": 13.912773132324219, "val_acc": 50.0, "val_auroc": 0.55, "time": 641.02}
{"epoch": 35, "training_loss": 54.21559715270996, "training_acc": 52.5, "val_loss": 13.83327841758728, "val_acc": 50.0, "val_auroc": 0.58, "time": 658.85}
{"epoch": 36, "training_loss": 53.22149658203125, "training_acc": 66.25, "val_loss": 13.793379068374634, "val_acc": 50.0, "val_auroc": 0.61, "time": 677.38}
{"epoch": 37, "training_loss": 53.63646411895752, "training_acc": 68.75, "val_loss": 13.752824068069458, "val_acc": 50.0, "val_auroc": 0.58, "time": 694.51}
{"epoch": 38, "training_loss": 51.91718673706055, "training_acc": 75.0, "val_loss": 13.870820999145508, "val_acc": 50.0, "val_auroc": 0.62, "time": 711.68}
{"epoch": 39, "training_loss": 51.74665069580078, "training_acc": 60.0, "val_loss": 13.801803588867188, "val_acc": 50.0, "val_auroc": 0.55, "time": 728.59}
{"epoch": 40, "training_loss": 51.36911392211914, "training_acc": 77.5, "val_loss": 13.791556358337402, "val_acc": 50.0, "val_auroc": 0.53, "time": 747.72}
{"epoch": 41, "training_loss": 49.01247215270996, "training_acc": 82.5, "val_loss": 13.837982416152954, "val_acc": 50.0, "val_auroc": 0.57, "time": 763.92}
{"epoch": 42, "training_loss": 48.237064361572266, "training_acc": 80.0, "val_loss": 14.37503457069397, "val_acc": 50.0, "val_auroc": 0.46, "time": 780.57}
{"epoch": 43, "training_loss": 51.10954475402832, "training_acc": 56.25, "val_loss": 13.72728705406189, "val_acc": 50.0, "val_auroc": 0.6, "time": 797.0}
{"epoch": 44, "training_loss": 52.37199115753174, "training_acc": 67.5, "val_loss": 13.746012449264526, "val_acc": 55.0, "val_auroc": 0.57, "time": 813.77}
