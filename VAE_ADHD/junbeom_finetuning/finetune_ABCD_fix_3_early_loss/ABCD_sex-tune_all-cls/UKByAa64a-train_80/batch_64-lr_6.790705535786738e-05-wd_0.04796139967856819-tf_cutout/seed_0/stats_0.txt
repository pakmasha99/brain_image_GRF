"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.54469871520996, "training_acc": 52.5, "val_loss": 13.940647840499878, "val_acc": 50.0, "val_auroc": 0.27, "time": 18.84}
{"epoch": 1, "training_loss": 55.29025459289551, "training_acc": 52.5, "val_loss": 13.876171112060547, "val_acc": 50.0, "val_auroc": 0.48, "time": 39.16}
{"epoch": 2, "training_loss": 55.181846618652344, "training_acc": 52.5, "val_loss": 13.885108232498169, "val_acc": 50.0, "val_auroc": 0.42, "time": 61.76}
{"epoch": 3, "training_loss": 55.19256019592285, "training_acc": 52.5, "val_loss": 13.876012563705444, "val_acc": 50.0, "val_auroc": 0.42, "time": 84.89}
{"epoch": 4, "training_loss": 54.98766326904297, "training_acc": 52.5, "val_loss": 13.885661363601685, "val_acc": 50.0, "val_auroc": 0.45, "time": 103.53}
{"epoch": 5, "training_loss": 55.143428802490234, "training_acc": 57.5, "val_loss": 13.917540311813354, "val_acc": 50.0, "val_auroc": 0.38, "time": 122.48}
{"epoch": 6, "training_loss": 55.07485866546631, "training_acc": 52.5, "val_loss": 13.930410146713257, "val_acc": 50.0, "val_auroc": 0.41, "time": 143.57}
{"epoch": 7, "training_loss": 54.91123008728027, "training_acc": 56.25, "val_loss": 13.942621946334839, "val_acc": 50.0, "val_auroc": 0.42, "time": 164.02}
{"epoch": 8, "training_loss": 54.682838439941406, "training_acc": 66.25, "val_loss": 13.962403535842896, "val_acc": 50.0, "val_auroc": 0.4, "time": 181.8}
{"epoch": 9, "training_loss": 54.99421310424805, "training_acc": 57.5, "val_loss": 13.956187963485718, "val_acc": 50.0, "val_auroc": 0.39, "time": 199.74}
{"epoch": 10, "training_loss": 54.21933555603027, "training_acc": 67.5, "val_loss": 14.002050161361694, "val_acc": 50.0, "val_auroc": 0.4, "time": 220.28}
{"epoch": 11, "training_loss": 53.740549087524414, "training_acc": 62.5, "val_loss": 14.07544732093811, "val_acc": 50.0, "val_auroc": 0.39, "time": 239.99}
{"epoch": 12, "training_loss": 53.927077293395996, "training_acc": 55.0, "val_loss": 14.009703397750854, "val_acc": 50.0, "val_auroc": 0.43, "time": 257.08}
{"epoch": 13, "training_loss": 52.86518478393555, "training_acc": 62.5, "val_loss": 14.344062805175781, "val_acc": 50.0, "val_auroc": 0.48, "time": 273.9}
{"epoch": 14, "training_loss": 54.60421180725098, "training_acc": 52.5, "val_loss": 14.36368703842163, "val_acc": 50.0, "val_auroc": 0.48, "time": 294.66}
{"epoch": 15, "training_loss": 53.8037109375, "training_acc": 53.75, "val_loss": 14.093102216720581, "val_acc": 50.0, "val_auroc": 0.47, "time": 313.76}
{"epoch": 16, "training_loss": 52.1055965423584, "training_acc": 60.0, "val_loss": 14.461660385131836, "val_acc": 50.0, "val_auroc": 0.47, "time": 331.22}
{"epoch": 17, "training_loss": 50.98200798034668, "training_acc": 60.0, "val_loss": 14.178528785705566, "val_acc": 50.0, "val_auroc": 0.45, "time": 348.85}
{"epoch": 18, "training_loss": 49.729376792907715, "training_acc": 72.5, "val_loss": 14.186662435531616, "val_acc": 50.0, "val_auroc": 0.42, "time": 369.18}
{"epoch": 19, "training_loss": 51.524502754211426, "training_acc": 78.75, "val_loss": 14.213413000106812, "val_acc": 50.0, "val_auroc": 0.49, "time": 391.04}
{"epoch": 20, "training_loss": 47.96210861206055, "training_acc": 80.0, "val_loss": 14.353264570236206, "val_acc": 50.0, "val_auroc": 0.42, "time": 407.66}
{"epoch": 21, "training_loss": 49.666316986083984, "training_acc": 73.75, "val_loss": 14.495071172714233, "val_acc": 50.0, "val_auroc": 0.44, "time": 424.29}
{"epoch": 22, "training_loss": 49.77277755737305, "training_acc": 66.25, "val_loss": 14.63192343711853, "val_acc": 50.0, "val_auroc": 0.41, "time": 443.07}
