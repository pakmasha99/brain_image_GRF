"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.44075393676758, "training_acc": 52.5, "val_loss": 13.925358057022095, "val_acc": 50.0, "val_auroc": 0.57, "time": 18.94}
{"epoch": 1, "training_loss": 55.53526306152344, "training_acc": 52.5, "val_loss": 13.983230590820312, "val_acc": 50.0, "val_auroc": 0.24, "time": 36.37}
{"epoch": 2, "training_loss": 55.155832290649414, "training_acc": 52.5, "val_loss": 13.960455656051636, "val_acc": 50.0, "val_auroc": 0.42, "time": 53.47}
{"epoch": 3, "training_loss": 55.33514213562012, "training_acc": 52.5, "val_loss": 13.978335857391357, "val_acc": 50.0, "val_auroc": 0.3, "time": 70.78}
{"epoch": 4, "training_loss": 55.321682929992676, "training_acc": 52.5, "val_loss": 14.006803035736084, "val_acc": 50.0, "val_auroc": 0.28, "time": 87.19}
{"epoch": 5, "training_loss": 55.15230464935303, "training_acc": 52.5, "val_loss": 13.928792476654053, "val_acc": 50.0, "val_auroc": 0.34, "time": 103.94}
{"epoch": 6, "training_loss": 55.04331970214844, "training_acc": 52.5, "val_loss": 13.948249816894531, "val_acc": 50.0, "val_auroc": 0.41, "time": 120.37}
{"epoch": 7, "training_loss": 55.015265464782715, "training_acc": 52.5, "val_loss": 14.006017446517944, "val_acc": 50.0, "val_auroc": 0.39, "time": 137.18}
{"epoch": 8, "training_loss": 55.134552001953125, "training_acc": 52.5, "val_loss": 14.006638526916504, "val_acc": 50.0, "val_auroc": 0.37, "time": 153.61}
{"epoch": 9, "training_loss": 54.898508071899414, "training_acc": 52.5, "val_loss": 13.87734055519104, "val_acc": 50.0, "val_auroc": 0.57, "time": 170.89}
{"epoch": 10, "training_loss": 54.948659896850586, "training_acc": 52.5, "val_loss": 13.870891332626343, "val_acc": 50.0, "val_auroc": 0.51, "time": 187.82}
{"epoch": 11, "training_loss": 54.98891639709473, "training_acc": 52.5, "val_loss": 13.91050934791565, "val_acc": 50.0, "val_auroc": 0.38, "time": 205.71}
{"epoch": 12, "training_loss": 54.85759162902832, "training_acc": 52.5, "val_loss": 13.925666809082031, "val_acc": 50.0, "val_auroc": 0.41, "time": 222.2}
{"epoch": 13, "training_loss": 54.90350151062012, "training_acc": 52.5, "val_loss": 13.904094696044922, "val_acc": 50.0, "val_auroc": 0.53, "time": 240.48}
{"epoch": 14, "training_loss": 54.81188106536865, "training_acc": 52.5, "val_loss": 13.873475790023804, "val_acc": 50.0, "val_auroc": 0.59, "time": 257.61}
{"epoch": 15, "training_loss": 54.656084060668945, "training_acc": 52.5, "val_loss": 13.899973630905151, "val_acc": 50.0, "val_auroc": 0.51, "time": 275.58}
{"epoch": 16, "training_loss": 54.41800022125244, "training_acc": 52.5, "val_loss": 14.017752408981323, "val_acc": 50.0, "val_auroc": 0.4, "time": 293.53}
{"epoch": 17, "training_loss": 54.78388214111328, "training_acc": 52.5, "val_loss": 13.969863653182983, "val_acc": 50.0, "val_auroc": 0.5, "time": 310.45}
{"epoch": 18, "training_loss": 54.13542079925537, "training_acc": 52.5, "val_loss": 13.844387531280518, "val_acc": 50.0, "val_auroc": 0.58, "time": 326.8}
{"epoch": 19, "training_loss": 54.44367218017578, "training_acc": 57.5, "val_loss": 13.81609320640564, "val_acc": 50.0, "val_auroc": 0.61, "time": 344.71}
{"epoch": 20, "training_loss": 54.309112548828125, "training_acc": 85.0, "val_loss": 13.829947710037231, "val_acc": 50.0, "val_auroc": 0.56, "time": 361.87}
{"epoch": 21, "training_loss": 53.72052574157715, "training_acc": 61.25, "val_loss": 13.909465074539185, "val_acc": 50.0, "val_auroc": 0.6, "time": 377.83}
{"epoch": 22, "training_loss": 54.008904457092285, "training_acc": 52.5, "val_loss": 13.885377645492554, "val_acc": 50.0, "val_auroc": 0.57, "time": 394.2}
{"epoch": 23, "training_loss": 53.18141746520996, "training_acc": 55.0, "val_loss": 13.80914568901062, "val_acc": 50.0, "val_auroc": 0.59, "time": 411.02}
{"epoch": 24, "training_loss": 52.842857360839844, "training_acc": 71.25, "val_loss": 13.931208848953247, "val_acc": 50.0, "val_auroc": 0.56, "time": 427.21}
{"epoch": 25, "training_loss": 53.2256555557251, "training_acc": 52.5, "val_loss": 13.905423879623413, "val_acc": 50.0, "val_auroc": 0.55, "time": 443.45}
{"epoch": 26, "training_loss": 53.053879737854004, "training_acc": 55.0, "val_loss": 13.847026824951172, "val_acc": 50.0, "val_auroc": 0.55, "time": 459.75}
{"epoch": 27, "training_loss": 51.31782531738281, "training_acc": 68.75, "val_loss": 13.883317708969116, "val_acc": 50.0, "val_auroc": 0.56, "time": 477.23}
{"epoch": 28, "training_loss": 51.19505596160889, "training_acc": 62.5, "val_loss": 13.764756917953491, "val_acc": 50.0, "val_auroc": 0.63, "time": 494.52}
{"epoch": 29, "training_loss": 53.38412857055664, "training_acc": 62.5, "val_loss": 13.730558156967163, "val_acc": 50.0, "val_auroc": 0.71, "time": 512.05}
{"epoch": 30, "training_loss": 52.99700927734375, "training_acc": 76.25, "val_loss": 13.812204599380493, "val_acc": 50.0, "val_auroc": 0.62, "time": 528.09}
{"epoch": 31, "training_loss": 51.57321643829346, "training_acc": 66.25, "val_loss": 13.768779039382935, "val_acc": 50.0, "val_auroc": 0.61, "time": 544.03}
{"epoch": 32, "training_loss": 51.10844421386719, "training_acc": 81.25, "val_loss": 13.728563785552979, "val_acc": 50.0, "val_auroc": 0.59, "time": 561.03}
{"epoch": 33, "training_loss": 49.64606857299805, "training_acc": 83.75, "val_loss": 13.685319423675537, "val_acc": 50.0, "val_auroc": 0.59, "time": 579.82}
{"epoch": 34, "training_loss": 48.541839599609375, "training_acc": 86.25, "val_loss": 14.012531042098999, "val_acc": 50.0, "val_auroc": 0.65, "time": 595.84}
{"epoch": 35, "training_loss": 50.032155990600586, "training_acc": 60.0, "val_loss": 14.024741649627686, "val_acc": 50.0, "val_auroc": 0.61, "time": 612.86}
{"epoch": 36, "training_loss": 53.41750621795654, "training_acc": 51.25, "val_loss": 13.827680349349976, "val_acc": 50.0, "val_auroc": 0.63, "time": 629.16}
{"epoch": 37, "training_loss": 54.35456085205078, "training_acc": 55.0, "val_loss": 13.77440094947815, "val_acc": 50.0, "val_auroc": 0.62, "time": 645.81}
{"epoch": 38, "training_loss": 53.73257827758789, "training_acc": 66.25, "val_loss": 13.822649717330933, "val_acc": 50.0, "val_auroc": 0.61, "time": 661.87}
{"epoch": 39, "training_loss": 53.525794982910156, "training_acc": 52.5, "val_loss": 13.790243864059448, "val_acc": 50.0, "val_auroc": 0.61, "time": 678.34}
{"epoch": 40, "training_loss": 52.246238708496094, "training_acc": 56.25, "val_loss": 13.758420944213867, "val_acc": 50.0, "val_auroc": 0.55, "time": 695.14}
{"epoch": 41, "training_loss": 51.35586357116699, "training_acc": 80.0, "val_loss": 13.77057671546936, "val_acc": 50.0, "val_auroc": 0.54, "time": 711.87}
{"epoch": 42, "training_loss": 49.984352111816406, "training_acc": 78.75, "val_loss": 13.766508102416992, "val_acc": 50.0, "val_auroc": 0.61, "time": 728.09}
{"epoch": 43, "training_loss": 50.05360794067383, "training_acc": 61.25, "val_loss": 13.463194370269775, "val_acc": 50.0, "val_auroc": 0.63, "time": 745.95}
{"epoch": 44, "training_loss": 46.48814010620117, "training_acc": 90.0, "val_loss": 13.514822721481323, "val_acc": 50.0, "val_auroc": 0.6, "time": 762.09}
{"epoch": 45, "training_loss": 45.21887016296387, "training_acc": 91.25, "val_loss": 13.662986755371094, "val_acc": 50.0, "val_auroc": 0.65, "time": 779.18}
{"epoch": 46, "training_loss": 44.59656620025635, "training_acc": 82.5, "val_loss": 13.466145992279053, "val_acc": 50.0, "val_auroc": 0.61, "time": 796.34}
{"epoch": 47, "training_loss": 41.42294692993164, "training_acc": 95.0, "val_loss": 13.612552881240845, "val_acc": 50.0, "val_auroc": 0.65, "time": 813.21}
{"epoch": 48, "training_loss": 43.18393421173096, "training_acc": 85.0, "val_loss": 13.502371311187744, "val_acc": 50.0, "val_auroc": 0.63, "time": 829.72}
{"epoch": 49, "training_loss": 38.57460403442383, "training_acc": 91.25, "val_loss": 13.51730227470398, "val_acc": 60.0, "val_auroc": 0.63, "time": 846.16}
{"epoch": 50, "training_loss": 36.66996765136719, "training_acc": 97.5, "val_loss": 13.336938619613647, "val_acc": 55.0, "val_auroc": 0.65, "time": 862.98}
{"epoch": 51, "training_loss": 34.030303955078125, "training_acc": 98.75, "val_loss": 14.14842963218689, "val_acc": 60.0, "val_auroc": 0.59, "time": 880.48}
{"epoch": 52, "training_loss": 36.497272968292236, "training_acc": 92.5, "val_loss": 13.834741115570068, "val_acc": 55.0, "val_auroc": 0.64, "time": 896.97}
{"epoch": 53, "training_loss": 35.545220375061035, "training_acc": 91.25, "val_loss": 13.514569997787476, "val_acc": 55.0, "val_auroc": 0.64, "time": 913.21}
{"epoch": 54, "training_loss": 31.65165424346924, "training_acc": 98.75, "val_loss": 13.590072393417358, "val_acc": 55.0, "val_auroc": 0.61, "time": 930.8}
{"epoch": 55, "training_loss": 31.93777322769165, "training_acc": 98.75, "val_loss": 13.810665607452393, "val_acc": 55.0, "val_auroc": 0.64, "time": 947.99}
{"epoch": 56, "training_loss": 30.82001495361328, "training_acc": 96.25, "val_loss": 14.073511362075806, "val_acc": 65.0, "val_auroc": 0.61, "time": 964.91}
{"epoch": 57, "training_loss": 29.824507236480713, "training_acc": 98.75, "val_loss": 13.954187631607056, "val_acc": 65.0, "val_auroc": 0.59, "time": 981.26}
{"epoch": 58, "training_loss": 28.68525266647339, "training_acc": 97.5, "val_loss": 14.544967412948608, "val_acc": 55.0, "val_auroc": 0.59, "time": 997.74}
{"epoch": 59, "training_loss": 27.886695861816406, "training_acc": 98.75, "val_loss": 14.623271226882935, "val_acc": 60.0, "val_auroc": 0.58, "time": 1014.18}
{"epoch": 60, "training_loss": 27.12886667251587, "training_acc": 100.0, "val_loss": 14.367095232009888, "val_acc": 55.0, "val_auroc": 0.63, "time": 1030.5}
{"epoch": 61, "training_loss": 26.6541805267334, "training_acc": 98.75, "val_loss": 14.249831438064575, "val_acc": 60.0, "val_auroc": 0.59, "time": 1047.01}
{"epoch": 62, "training_loss": 25.299869537353516, "training_acc": 100.0, "val_loss": 14.253450632095337, "val_acc": 55.0, "val_auroc": 0.59, "time": 1064.16}
{"epoch": 63, "training_loss": 23.931998252868652, "training_acc": 100.0, "val_loss": 14.236923456192017, "val_acc": 55.0, "val_auroc": 0.62, "time": 1081.1}
{"epoch": 64, "training_loss": 23.1957426071167, "training_acc": 100.0, "val_loss": 14.3398118019104, "val_acc": 60.0, "val_auroc": 0.63, "time": 1098.53}
{"epoch": 65, "training_loss": 22.00795841217041, "training_acc": 100.0, "val_loss": 14.281696081161499, "val_acc": 55.0, "val_auroc": 0.62, "time": 1115.55}
{"epoch": 66, "training_loss": 21.986942291259766, "training_acc": 100.0, "val_loss": 14.675401449203491, "val_acc": 60.0, "val_auroc": 0.61, "time": 1131.75}
{"epoch": 67, "training_loss": 21.477837085723877, "training_acc": 100.0, "val_loss": 14.218075275421143, "val_acc": 60.0, "val_auroc": 0.61, "time": 1148.42}
{"epoch": 68, "training_loss": 21.172970294952393, "training_acc": 100.0, "val_loss": 14.677146673202515, "val_acc": 60.0, "val_auroc": 0.6, "time": 1164.47}
{"epoch": 69, "training_loss": 20.193938732147217, "training_acc": 100.0, "val_loss": 14.582207202911377, "val_acc": 65.0, "val_auroc": 0.6, "time": 1181.27}
