"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5865535736084, "training_acc": 42.5, "val_loss": 13.831207752227783, "val_acc": 55.0, "val_auroc": 0.576, "time": 19.35}
{"epoch": 1, "training_loss": 55.38222694396973, "training_acc": 51.25, "val_loss": 13.842337131500244, "val_acc": 55.0, "val_auroc": 0.495, "time": 36.49}
{"epoch": 2, "training_loss": 55.3069953918457, "training_acc": 50.0, "val_loss": 13.844846487045288, "val_acc": 55.0, "val_auroc": 0.485, "time": 53.48}
{"epoch": 3, "training_loss": 55.26863098144531, "training_acc": 51.25, "val_loss": 13.849037885665894, "val_acc": 55.0, "val_auroc": 0.303, "time": 70.38}
{"epoch": 4, "training_loss": 55.10620403289795, "training_acc": 55.0, "val_loss": 13.8267183303833, "val_acc": 55.0, "val_auroc": 0.364, "time": 86.9}
{"epoch": 5, "training_loss": 55.01890468597412, "training_acc": 51.25, "val_loss": 13.793728351593018, "val_acc": 55.0, "val_auroc": 0.465, "time": 104.01}
{"epoch": 6, "training_loss": 54.796730041503906, "training_acc": 51.25, "val_loss": 13.791685104370117, "val_acc": 55.0, "val_auroc": 0.505, "time": 121.56}
{"epoch": 7, "training_loss": 54.72264385223389, "training_acc": 51.25, "val_loss": 13.786579370498657, "val_acc": 55.0, "val_auroc": 0.576, "time": 138.13}
{"epoch": 8, "training_loss": 54.65402793884277, "training_acc": 52.5, "val_loss": 13.813945055007935, "val_acc": 55.0, "val_auroc": 0.646, "time": 156.94}
{"epoch": 9, "training_loss": 54.35994338989258, "training_acc": 83.75, "val_loss": 13.821601867675781, "val_acc": 55.0, "val_auroc": 0.677, "time": 173.15}
{"epoch": 10, "training_loss": 54.32376194000244, "training_acc": 70.0, "val_loss": 13.73240351676941, "val_acc": 55.0, "val_auroc": 0.667, "time": 191.1}
{"epoch": 11, "training_loss": 54.40333557128906, "training_acc": 53.75, "val_loss": 13.718805313110352, "val_acc": 55.0, "val_auroc": 0.616, "time": 208.27}
{"epoch": 12, "training_loss": 54.453125, "training_acc": 51.25, "val_loss": 13.747191429138184, "val_acc": 55.0, "val_auroc": 0.596, "time": 224.58}
{"epoch": 13, "training_loss": 53.962961196899414, "training_acc": 65.0, "val_loss": 13.893803358078003, "val_acc": 55.0, "val_auroc": 0.545, "time": 240.8}
{"epoch": 14, "training_loss": 54.14856147766113, "training_acc": 73.75, "val_loss": 13.831392526626587, "val_acc": 55.0, "val_auroc": 0.586, "time": 259.36}
{"epoch": 15, "training_loss": 53.76895809173584, "training_acc": 78.75, "val_loss": 13.768393993377686, "val_acc": 55.0, "val_auroc": 0.545, "time": 276.6}
{"epoch": 16, "training_loss": 53.48864555358887, "training_acc": 56.25, "val_loss": 13.802729845046997, "val_acc": 55.0, "val_auroc": 0.535, "time": 294.03}
{"epoch": 17, "training_loss": 53.387657165527344, "training_acc": 53.75, "val_loss": 13.876184225082397, "val_acc": 55.0, "val_auroc": 0.586, "time": 310.24}
{"epoch": 18, "training_loss": 53.24028968811035, "training_acc": 80.0, "val_loss": 13.92466425895691, "val_acc": 55.0, "val_auroc": 0.586, "time": 327.0}
{"epoch": 19, "training_loss": 53.147847175598145, "training_acc": 66.25, "val_loss": 13.789697885513306, "val_acc": 55.0, "val_auroc": 0.525, "time": 343.81}
{"epoch": 20, "training_loss": 51.54491996765137, "training_acc": 81.25, "val_loss": 13.82051944732666, "val_acc": 55.0, "val_auroc": 0.566, "time": 360.1}
{"epoch": 21, "training_loss": 51.257436752319336, "training_acc": 83.75, "val_loss": 13.7508225440979, "val_acc": 55.0, "val_auroc": 0.545, "time": 376.6}
{"epoch": 22, "training_loss": 50.644643783569336, "training_acc": 80.0, "val_loss": 13.846532106399536, "val_acc": 55.0, "val_auroc": 0.545, "time": 394.5}
{"epoch": 23, "training_loss": 48.56546974182129, "training_acc": 91.25, "val_loss": 13.93272876739502, "val_acc": 55.0, "val_auroc": 0.586, "time": 411.87}
{"epoch": 24, "training_loss": 51.396403312683105, "training_acc": 61.25, "val_loss": 13.800163269042969, "val_acc": 55.0, "val_auroc": 0.576, "time": 428.35}
{"epoch": 25, "training_loss": 47.66554260253906, "training_acc": 80.0, "val_loss": 14.042494297027588, "val_acc": 55.0, "val_auroc": 0.495, "time": 445.14}
{"epoch": 26, "training_loss": 53.88297080993652, "training_acc": 52.5, "val_loss": 13.943623304367065, "val_acc": 55.0, "val_auroc": 0.525, "time": 462.37}
{"epoch": 27, "training_loss": 52.294721603393555, "training_acc": 60.0, "val_loss": 13.959587812423706, "val_acc": 55.0, "val_auroc": 0.596, "time": 479.16}
{"epoch": 28, "training_loss": 48.90743827819824, "training_acc": 80.0, "val_loss": 14.132305383682251, "val_acc": 55.0, "val_auroc": 0.566, "time": 495.64}
{"epoch": 29, "training_loss": 47.95644187927246, "training_acc": 81.25, "val_loss": 13.985213041305542, "val_acc": 55.0, "val_auroc": 0.576, "time": 514.14}
{"epoch": 30, "training_loss": 48.9320650100708, "training_acc": 65.0, "val_loss": 14.362603425979614, "val_acc": 60.0, "val_auroc": 0.556, "time": 531.87}
