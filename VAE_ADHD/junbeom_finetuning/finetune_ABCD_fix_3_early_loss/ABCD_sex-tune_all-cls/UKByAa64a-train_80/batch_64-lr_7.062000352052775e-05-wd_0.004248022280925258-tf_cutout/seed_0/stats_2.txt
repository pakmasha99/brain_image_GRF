"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.50197124481201, "training_acc": 52.5, "val_loss": 13.986438512802124, "val_acc": 50.0, "val_auroc": 0.47, "time": 14.56}
{"epoch": 1, "training_loss": 55.395724296569824, "training_acc": 52.5, "val_loss": 13.938902616500854, "val_acc": 50.0, "val_auroc": 0.53, "time": 28.61}
{"epoch": 2, "training_loss": 55.294114112854004, "training_acc": 52.5, "val_loss": 13.884247541427612, "val_acc": 50.0, "val_auroc": 0.52, "time": 42.01}
{"epoch": 3, "training_loss": 55.36084461212158, "training_acc": 52.5, "val_loss": 13.95383596420288, "val_acc": 50.0, "val_auroc": 0.28, "time": 54.73}
{"epoch": 4, "training_loss": 55.36466979980469, "training_acc": 52.5, "val_loss": 13.958220481872559, "val_acc": 50.0, "val_auroc": 0.21, "time": 67.24}
{"epoch": 5, "training_loss": 55.26764106750488, "training_acc": 52.5, "val_loss": 13.928712606430054, "val_acc": 50.0, "val_auroc": 0.27, "time": 80.16}
{"epoch": 6, "training_loss": 55.29973220825195, "training_acc": 52.5, "val_loss": 13.99535059928894, "val_acc": 50.0, "val_auroc": 0.29, "time": 92.73}
{"epoch": 7, "training_loss": 55.325571060180664, "training_acc": 52.5, "val_loss": 14.036697149276733, "val_acc": 50.0, "val_auroc": 0.21, "time": 105.27}
{"epoch": 8, "training_loss": 55.41317558288574, "training_acc": 52.5, "val_loss": 13.96959662437439, "val_acc": 50.0, "val_auroc": 0.3, "time": 117.34}
{"epoch": 9, "training_loss": 55.16139221191406, "training_acc": 52.5, "val_loss": 13.889613151550293, "val_acc": 50.0, "val_auroc": 0.34, "time": 130.04}
{"epoch": 10, "training_loss": 55.15778160095215, "training_acc": 57.5, "val_loss": 13.949521780014038, "val_acc": 50.0, "val_auroc": 0.28, "time": 142.34}
{"epoch": 11, "training_loss": 55.08407020568848, "training_acc": 56.25, "val_loss": 13.994762897491455, "val_acc": 50.0, "val_auroc": 0.31, "time": 154.3}
{"epoch": 12, "training_loss": 55.2298002243042, "training_acc": 52.5, "val_loss": 14.04038667678833, "val_acc": 50.0, "val_auroc": 0.29, "time": 166.4}
{"epoch": 13, "training_loss": 55.083269119262695, "training_acc": 52.5, "val_loss": 13.96178126335144, "val_acc": 50.0, "val_auroc": 0.32, "time": 178.75}
{"epoch": 14, "training_loss": 55.10324478149414, "training_acc": 52.5, "val_loss": 13.9275062084198, "val_acc": 50.0, "val_auroc": 0.34, "time": 190.98}
{"epoch": 15, "training_loss": 55.06910514831543, "training_acc": 60.0, "val_loss": 14.0359628200531, "val_acc": 50.0, "val_auroc": 0.28, "time": 203.2}
{"epoch": 16, "training_loss": 54.8831787109375, "training_acc": 52.5, "val_loss": 14.14179801940918, "val_acc": 50.0, "val_auroc": 0.31, "time": 215.89}
{"epoch": 17, "training_loss": 55.6008882522583, "training_acc": 52.5, "val_loss": 14.134072065353394, "val_acc": 50.0, "val_auroc": 0.45, "time": 228.77}
{"epoch": 18, "training_loss": 55.3821907043457, "training_acc": 52.5, "val_loss": 13.971245288848877, "val_acc": 50.0, "val_auroc": 0.47, "time": 241.35}
{"epoch": 19, "training_loss": 54.888362884521484, "training_acc": 52.5, "val_loss": 13.875712156295776, "val_acc": 50.0, "val_auroc": 0.48, "time": 254.55}
{"epoch": 20, "training_loss": 55.13641929626465, "training_acc": 50.0, "val_loss": 13.87017011642456, "val_acc": 50.0, "val_auroc": 0.49, "time": 267.52}
{"epoch": 21, "training_loss": 55.10100173950195, "training_acc": 63.75, "val_loss": 13.873125314712524, "val_acc": 50.0, "val_auroc": 0.52, "time": 279.58}
{"epoch": 22, "training_loss": 54.880943298339844, "training_acc": 55.0, "val_loss": 13.925306797027588, "val_acc": 50.0, "val_auroc": 0.48, "time": 291.8}
{"epoch": 23, "training_loss": 54.78010559082031, "training_acc": 52.5, "val_loss": 13.961660861968994, "val_acc": 50.0, "val_auroc": 0.52, "time": 304.25}
{"epoch": 24, "training_loss": 54.66578960418701, "training_acc": 52.5, "val_loss": 13.969602584838867, "val_acc": 50.0, "val_auroc": 0.52, "time": 316.59}
{"epoch": 25, "training_loss": 54.242231369018555, "training_acc": 52.5, "val_loss": 13.932644128799438, "val_acc": 50.0, "val_auroc": 0.49, "time": 328.91}
{"epoch": 26, "training_loss": 54.05715274810791, "training_acc": 53.75, "val_loss": 14.081157445907593, "val_acc": 50.0, "val_auroc": 0.48, "time": 343.68}
{"epoch": 27, "training_loss": 53.29478168487549, "training_acc": 52.5, "val_loss": 14.00539517402649, "val_acc": 50.0, "val_auroc": 0.52, "time": 356.25}
{"epoch": 28, "training_loss": 52.76189422607422, "training_acc": 53.75, "val_loss": 13.837484121322632, "val_acc": 50.0, "val_auroc": 0.47, "time": 368.99}
{"epoch": 29, "training_loss": 54.51736545562744, "training_acc": 58.75, "val_loss": 13.873721361160278, "val_acc": 50.0, "val_auroc": 0.45, "time": 381.24}
{"epoch": 30, "training_loss": 53.093865394592285, "training_acc": 71.25, "val_loss": 14.214048385620117, "val_acc": 50.0, "val_auroc": 0.52, "time": 394.28}
{"epoch": 31, "training_loss": 53.25259780883789, "training_acc": 52.5, "val_loss": 13.917979001998901, "val_acc": 50.0, "val_auroc": 0.53, "time": 406.86}
{"epoch": 32, "training_loss": 51.192338943481445, "training_acc": 77.5, "val_loss": 13.849705457687378, "val_acc": 50.0, "val_auroc": 0.51, "time": 420.08}
{"epoch": 33, "training_loss": 51.663204193115234, "training_acc": 72.5, "val_loss": 14.096180200576782, "val_acc": 50.0, "val_auroc": 0.58, "time": 432.56}
{"epoch": 34, "training_loss": 50.161970138549805, "training_acc": 66.25, "val_loss": 13.600854873657227, "val_acc": 50.0, "val_auroc": 0.64, "time": 445.3}
{"epoch": 35, "training_loss": 46.39638614654541, "training_acc": 86.25, "val_loss": 13.81882905960083, "val_acc": 50.0, "val_auroc": 0.57, "time": 457.58}
{"epoch": 36, "training_loss": 50.98289966583252, "training_acc": 67.5, "val_loss": 13.877511024475098, "val_acc": 50.0, "val_auroc": 0.62, "time": 470.34}
{"epoch": 37, "training_loss": 49.13026428222656, "training_acc": 81.25, "val_loss": 13.773303031921387, "val_acc": 50.0, "val_auroc": 0.58, "time": 483.42}
{"epoch": 38, "training_loss": 45.455183029174805, "training_acc": 82.5, "val_loss": 14.45230484008789, "val_acc": 50.0, "val_auroc": 0.53, "time": 496.29}
{"epoch": 39, "training_loss": 44.46381759643555, "training_acc": 75.0, "val_loss": 13.962959051132202, "val_acc": 60.0, "val_auroc": 0.62, "time": 508.64}
{"epoch": 40, "training_loss": 47.50793743133545, "training_acc": 72.5, "val_loss": 13.776495456695557, "val_acc": 45.0, "val_auroc": 0.56, "time": 521.32}
{"epoch": 41, "training_loss": 39.43680000305176, "training_acc": 93.75, "val_loss": 14.00813102722168, "val_acc": 60.0, "val_auroc": 0.62, "time": 533.77}
{"epoch": 42, "training_loss": 43.85312366485596, "training_acc": 83.75, "val_loss": 15.087896585464478, "val_acc": 50.0, "val_auroc": 0.53, "time": 546.5}
{"epoch": 43, "training_loss": 43.5128059387207, "training_acc": 73.75, "val_loss": 14.1292405128479, "val_acc": 50.0, "val_auroc": 0.58, "time": 558.74}
{"epoch": 44, "training_loss": 40.696563720703125, "training_acc": 85.0, "val_loss": 14.080027341842651, "val_acc": 55.0, "val_auroc": 0.54, "time": 571.29}
{"epoch": 45, "training_loss": 37.03047561645508, "training_acc": 95.0, "val_loss": 14.358992576599121, "val_acc": 50.0, "val_auroc": 0.52, "time": 583.6}
{"epoch": 46, "training_loss": 36.44929265975952, "training_acc": 93.75, "val_loss": 14.135497808456421, "val_acc": 50.0, "val_auroc": 0.53, "time": 595.47}
