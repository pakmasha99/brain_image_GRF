"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.49582862854004, "training_acc": 52.5, "val_loss": 13.939332962036133, "val_acc": 50.0, "val_auroc": 0.26, "time": 23.62}
{"epoch": 1, "training_loss": 55.35064888000488, "training_acc": 52.5, "val_loss": 13.902221918106079, "val_acc": 50.0, "val_auroc": 0.39, "time": 45.31}
{"epoch": 2, "training_loss": 55.130300521850586, "training_acc": 52.5, "val_loss": 13.879461288452148, "val_acc": 50.0, "val_auroc": 0.56, "time": 66.84}
{"epoch": 3, "training_loss": 55.163702964782715, "training_acc": 52.5, "val_loss": 13.885201215744019, "val_acc": 50.0, "val_auroc": 0.4, "time": 88.81}
{"epoch": 4, "training_loss": 55.16939163208008, "training_acc": 52.5, "val_loss": 13.901400566101074, "val_acc": 50.0, "val_auroc": 0.36, "time": 107.67}
{"epoch": 5, "training_loss": 55.0280876159668, "training_acc": 52.5, "val_loss": 13.895974159240723, "val_acc": 50.0, "val_auroc": 0.4, "time": 128.9}
{"epoch": 6, "training_loss": 54.98621463775635, "training_acc": 52.5, "val_loss": 13.874505758285522, "val_acc": 50.0, "val_auroc": 0.48, "time": 149.8}
{"epoch": 7, "training_loss": 55.01021480560303, "training_acc": 53.75, "val_loss": 13.847423791885376, "val_acc": 50.0, "val_auroc": 0.54, "time": 170.91}
{"epoch": 8, "training_loss": 54.751885414123535, "training_acc": 51.25, "val_loss": 13.884499073028564, "val_acc": 50.0, "val_auroc": 0.52, "time": 191.49}
{"epoch": 9, "training_loss": 54.71563911437988, "training_acc": 56.25, "val_loss": 13.863050937652588, "val_acc": 50.0, "val_auroc": 0.53, "time": 211.51}
{"epoch": 10, "training_loss": 54.38320541381836, "training_acc": 63.75, "val_loss": 13.8480544090271, "val_acc": 50.0, "val_auroc": 0.56, "time": 231.2}
{"epoch": 11, "training_loss": 54.1654748916626, "training_acc": 66.25, "val_loss": 13.900974988937378, "val_acc": 50.0, "val_auroc": 0.5, "time": 252.53}
{"epoch": 12, "training_loss": 53.95854091644287, "training_acc": 55.0, "val_loss": 13.894126415252686, "val_acc": 50.0, "val_auroc": 0.53, "time": 271.14}
{"epoch": 13, "training_loss": 53.94767189025879, "training_acc": 57.5, "val_loss": 13.90765905380249, "val_acc": 50.0, "val_auroc": 0.5, "time": 291.68}
{"epoch": 14, "training_loss": 53.6650390625, "training_acc": 57.5, "val_loss": 14.04860258102417, "val_acc": 50.0, "val_auroc": 0.39, "time": 313.28}
{"epoch": 15, "training_loss": 53.87369155883789, "training_acc": 52.5, "val_loss": 14.155362844467163, "val_acc": 50.0, "val_auroc": 0.32, "time": 334.61}
{"epoch": 16, "training_loss": 53.92375373840332, "training_acc": 52.5, "val_loss": 14.028578996658325, "val_acc": 50.0, "val_auroc": 0.45, "time": 353.74}
{"epoch": 17, "training_loss": 52.95703125, "training_acc": 55.0, "val_loss": 13.901541233062744, "val_acc": 50.0, "val_auroc": 0.47, "time": 377.4}
{"epoch": 18, "training_loss": 53.18931770324707, "training_acc": 61.25, "val_loss": 14.113572835922241, "val_acc": 50.0, "val_auroc": 0.42, "time": 394.52}
{"epoch": 19, "training_loss": 52.896225929260254, "training_acc": 52.5, "val_loss": 13.952966928482056, "val_acc": 50.0, "val_auroc": 0.47, "time": 414.63}
{"epoch": 20, "training_loss": 52.39409637451172, "training_acc": 66.25, "val_loss": 13.837114572525024, "val_acc": 50.0, "val_auroc": 0.5, "time": 435.79}
{"epoch": 21, "training_loss": 53.25677490234375, "training_acc": 78.75, "val_loss": 13.937082290649414, "val_acc": 50.0, "val_auroc": 0.45, "time": 457.16}
{"epoch": 22, "training_loss": 52.13694381713867, "training_acc": 70.0, "val_loss": 14.196984767913818, "val_acc": 50.0, "val_auroc": 0.4, "time": 477.32}
{"epoch": 23, "training_loss": 52.68685722351074, "training_acc": 52.5, "val_loss": 13.94610047340393, "val_acc": 50.0, "val_auroc": 0.49, "time": 497.35}
{"epoch": 24, "training_loss": 51.88130855560303, "training_acc": 73.75, "val_loss": 13.833776712417603, "val_acc": 50.0, "val_auroc": 0.53, "time": 516.15}
{"epoch": 25, "training_loss": 51.87001419067383, "training_acc": 82.5, "val_loss": 13.871678113937378, "val_acc": 50.0, "val_auroc": 0.49, "time": 537.58}
{"epoch": 26, "training_loss": 51.27271842956543, "training_acc": 82.5, "val_loss": 14.007314443588257, "val_acc": 50.0, "val_auroc": 0.45, "time": 556.71}
{"epoch": 27, "training_loss": 50.892751693725586, "training_acc": 68.75, "val_loss": 13.878742456436157, "val_acc": 50.0, "val_auroc": 0.5, "time": 577.01}
{"epoch": 28, "training_loss": 49.50760459899902, "training_acc": 85.0, "val_loss": 13.832350969314575, "val_acc": 50.0, "val_auroc": 0.51, "time": 596.72}
{"epoch": 29, "training_loss": 50.11005401611328, "training_acc": 87.5, "val_loss": 14.137901067733765, "val_acc": 50.0, "val_auroc": 0.44, "time": 616.45}
{"epoch": 30, "training_loss": 49.04276657104492, "training_acc": 70.0, "val_loss": 13.917524814605713, "val_acc": 50.0, "val_auroc": 0.46, "time": 636.9}
{"epoch": 31, "training_loss": 47.46128463745117, "training_acc": 86.25, "val_loss": 13.837199211120605, "val_acc": 50.0, "val_auroc": 0.5, "time": 658.33}
{"epoch": 32, "training_loss": 45.87442970275879, "training_acc": 93.75, "val_loss": 13.756393194198608, "val_acc": 50.0, "val_auroc": 0.51, "time": 677.51}
{"epoch": 33, "training_loss": 47.34198188781738, "training_acc": 86.25, "val_loss": 14.204206466674805, "val_acc": 50.0, "val_auroc": 0.41, "time": 700.14}
{"epoch": 34, "training_loss": 49.677260398864746, "training_acc": 67.5, "val_loss": 13.93278956413269, "val_acc": 50.0, "val_auroc": 0.48, "time": 718.44}
{"epoch": 35, "training_loss": 45.01772117614746, "training_acc": 88.75, "val_loss": 13.828277587890625, "val_acc": 50.0, "val_auroc": 0.51, "time": 737.81}
{"epoch": 36, "training_loss": 43.91872215270996, "training_acc": 93.75, "val_loss": 13.882290124893188, "val_acc": 50.0, "val_auroc": 0.51, "time": 756.54}
{"epoch": 37, "training_loss": 43.34785175323486, "training_acc": 90.0, "val_loss": 13.7631356716156, "val_acc": 55.0, "val_auroc": 0.52, "time": 776.66}
{"epoch": 38, "training_loss": 43.742520332336426, "training_acc": 90.0, "val_loss": 14.341988563537598, "val_acc": 50.0, "val_auroc": 0.48, "time": 795.78}
{"epoch": 39, "training_loss": 45.44588661193848, "training_acc": 77.5, "val_loss": 13.80555510520935, "val_acc": 60.0, "val_auroc": 0.55, "time": 815.11}
{"epoch": 40, "training_loss": 42.6514892578125, "training_acc": 87.5, "val_loss": 13.933662176132202, "val_acc": 55.0, "val_auroc": 0.55, "time": 833.81}
{"epoch": 41, "training_loss": 40.14126205444336, "training_acc": 92.5, "val_loss": 14.001766443252563, "val_acc": 55.0, "val_auroc": 0.52, "time": 853.79}
{"epoch": 42, "training_loss": 40.310882568359375, "training_acc": 90.0, "val_loss": 13.814430236816406, "val_acc": 45.0, "val_auroc": 0.55, "time": 874.02}
{"epoch": 43, "training_loss": 39.1241660118103, "training_acc": 95.0, "val_loss": 14.437915086746216, "val_acc": 50.0, "val_auroc": 0.49, "time": 896.18}
{"epoch": 44, "training_loss": 41.05745220184326, "training_acc": 83.75, "val_loss": 14.01331901550293, "val_acc": 60.0, "val_auroc": 0.63, "time": 915.72}
{"epoch": 45, "training_loss": 44.823065757751465, "training_acc": 80.0, "val_loss": 14.794412851333618, "val_acc": 50.0, "val_auroc": 0.45, "time": 935.85}
{"epoch": 46, "training_loss": 45.76557731628418, "training_acc": 72.5, "val_loss": 14.594327211380005, "val_acc": 50.0, "val_auroc": 0.49, "time": 957.32}
{"epoch": 47, "training_loss": 41.308770179748535, "training_acc": 83.75, "val_loss": 14.289884567260742, "val_acc": 45.0, "val_auroc": 0.57, "time": 979.01}
{"epoch": 48, "training_loss": 44.99696063995361, "training_acc": 72.5, "val_loss": 14.185482263565063, "val_acc": 50.0, "val_auroc": 0.5, "time": 998.49}
{"epoch": 49, "training_loss": 39.354928970336914, "training_acc": 90.0, "val_loss": 14.569333791732788, "val_acc": 50.0, "val_auroc": 0.5, "time": 1018.93}
{"epoch": 50, "training_loss": 41.54657745361328, "training_acc": 76.25, "val_loss": 13.945748805999756, "val_acc": 50.0, "val_auroc": 0.56, "time": 1038.51}
{"epoch": 51, "training_loss": 37.949262619018555, "training_acc": 95.0, "val_loss": 14.058090448379517, "val_acc": 55.0, "val_auroc": 0.55, "time": 1060.37}
