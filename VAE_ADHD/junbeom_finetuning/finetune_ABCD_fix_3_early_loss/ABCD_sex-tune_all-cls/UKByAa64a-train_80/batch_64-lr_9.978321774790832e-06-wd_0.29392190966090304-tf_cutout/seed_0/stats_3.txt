"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.388423919677734, "training_acc": 53.75, "val_loss": 13.89100432395935, "val_acc": 55.0, "val_auroc": 0.222, "time": 18.48}
{"epoch": 1, "training_loss": 55.514570236206055, "training_acc": 50.0, "val_loss": 13.871070146560669, "val_acc": 55.0, "val_auroc": 0.384, "time": 36.1}
{"epoch": 2, "training_loss": 55.460564613342285, "training_acc": 47.5, "val_loss": 13.811609745025635, "val_acc": 55.0, "val_auroc": 0.616, "time": 54.0}
{"epoch": 3, "training_loss": 55.35494899749756, "training_acc": 50.0, "val_loss": 13.833765983581543, "val_acc": 55.0, "val_auroc": 0.455, "time": 72.42}
{"epoch": 4, "training_loss": 55.37839412689209, "training_acc": 51.25, "val_loss": 13.831130266189575, "val_acc": 55.0, "val_auroc": 0.424, "time": 89.42}
{"epoch": 5, "training_loss": 55.43710517883301, "training_acc": 51.25, "val_loss": 13.85705828666687, "val_acc": 55.0, "val_auroc": 0.283, "time": 106.35}
{"epoch": 6, "training_loss": 55.3674955368042, "training_acc": 51.25, "val_loss": 13.828270435333252, "val_acc": 55.0, "val_auroc": 0.394, "time": 123.11}
{"epoch": 7, "training_loss": 55.398393630981445, "training_acc": 51.25, "val_loss": 13.810707330703735, "val_acc": 55.0, "val_auroc": 0.566, "time": 139.94}
{"epoch": 8, "training_loss": 55.42519760131836, "training_acc": 51.25, "val_loss": 13.809366226196289, "val_acc": 55.0, "val_auroc": 0.606, "time": 156.65}
{"epoch": 9, "training_loss": 55.3443489074707, "training_acc": 51.25, "val_loss": 13.817743062973022, "val_acc": 55.0, "val_auroc": 0.606, "time": 173.0}
{"epoch": 10, "training_loss": 55.34736251831055, "training_acc": 52.5, "val_loss": 13.8313889503479, "val_acc": 55.0, "val_auroc": 0.525, "time": 189.38}
{"epoch": 11, "training_loss": 55.294918060302734, "training_acc": 50.0, "val_loss": 13.826378583908081, "val_acc": 55.0, "val_auroc": 0.515, "time": 206.29}
{"epoch": 12, "training_loss": 55.257415771484375, "training_acc": 51.25, "val_loss": 13.819624185562134, "val_acc": 55.0, "val_auroc": 0.465, "time": 223.02}
{"epoch": 13, "training_loss": 55.27076053619385, "training_acc": 51.25, "val_loss": 13.821548223495483, "val_acc": 55.0, "val_auroc": 0.515, "time": 239.4}
{"epoch": 14, "training_loss": 55.30976867675781, "training_acc": 51.25, "val_loss": 13.82797122001648, "val_acc": 55.0, "val_auroc": 0.485, "time": 256.5}
{"epoch": 15, "training_loss": 55.145456314086914, "training_acc": 53.75, "val_loss": 13.832006454467773, "val_acc": 55.0, "val_auroc": 0.505, "time": 273.11}
{"epoch": 16, "training_loss": 54.97239112854004, "training_acc": 55.0, "val_loss": 13.827823400497437, "val_acc": 55.0, "val_auroc": 0.515, "time": 289.82}
{"epoch": 17, "training_loss": 55.0522346496582, "training_acc": 51.25, "val_loss": 13.823709487915039, "val_acc": 55.0, "val_auroc": 0.475, "time": 306.23}
{"epoch": 18, "training_loss": 54.92009258270264, "training_acc": 53.75, "val_loss": 13.828550577163696, "val_acc": 55.0, "val_auroc": 0.434, "time": 322.55}
{"epoch": 19, "training_loss": 54.80683708190918, "training_acc": 55.0, "val_loss": 13.843514919281006, "val_acc": 55.0, "val_auroc": 0.444, "time": 339.81}
{"epoch": 20, "training_loss": 54.91094779968262, "training_acc": 58.75, "val_loss": 13.864754438400269, "val_acc": 55.0, "val_auroc": 0.455, "time": 356.99}
{"epoch": 21, "training_loss": 54.641103744506836, "training_acc": 77.5, "val_loss": 13.8789963722229, "val_acc": 55.0, "val_auroc": 0.465, "time": 373.57}
{"epoch": 22, "training_loss": 54.921926498413086, "training_acc": 65.0, "val_loss": 13.87140154838562, "val_acc": 55.0, "val_auroc": 0.465, "time": 389.92}
{"epoch": 23, "training_loss": 54.57243061065674, "training_acc": 72.5, "val_loss": 13.850153684616089, "val_acc": 55.0, "val_auroc": 0.455, "time": 406.0}
{"epoch": 24, "training_loss": 54.413177490234375, "training_acc": 70.0, "val_loss": 13.822665214538574, "val_acc": 55.0, "val_auroc": 0.475, "time": 422.74}
{"epoch": 25, "training_loss": 54.56050682067871, "training_acc": 62.5, "val_loss": 13.796716928482056, "val_acc": 55.0, "val_auroc": 0.495, "time": 440.54}
{"epoch": 26, "training_loss": 54.75764274597168, "training_acc": 51.25, "val_loss": 13.785572052001953, "val_acc": 55.0, "val_auroc": 0.465, "time": 457.13}
{"epoch": 27, "training_loss": 54.448811531066895, "training_acc": 53.75, "val_loss": 13.805280923843384, "val_acc": 55.0, "val_auroc": 0.434, "time": 474.03}
{"epoch": 28, "training_loss": 54.15152359008789, "training_acc": 56.25, "val_loss": 13.849138021469116, "val_acc": 55.0, "val_auroc": 0.424, "time": 490.98}
{"epoch": 29, "training_loss": 53.935927391052246, "training_acc": 67.5, "val_loss": 13.888102769851685, "val_acc": 55.0, "val_auroc": 0.444, "time": 507.94}
{"epoch": 30, "training_loss": 54.18722915649414, "training_acc": 75.0, "val_loss": 13.887898921966553, "val_acc": 55.0, "val_auroc": 0.434, "time": 524.16}
{"epoch": 31, "training_loss": 54.100666999816895, "training_acc": 70.0, "val_loss": 13.858622312545776, "val_acc": 55.0, "val_auroc": 0.465, "time": 540.62}
{"epoch": 32, "training_loss": 53.770751953125, "training_acc": 77.5, "val_loss": 13.876243829727173, "val_acc": 55.0, "val_auroc": 0.485, "time": 557.29}
{"epoch": 33, "training_loss": 54.01877784729004, "training_acc": 71.25, "val_loss": 13.884109258651733, "val_acc": 55.0, "val_auroc": 0.485, "time": 574.16}
{"epoch": 34, "training_loss": 53.478339195251465, "training_acc": 75.0, "val_loss": 13.817389011383057, "val_acc": 55.0, "val_auroc": 0.495, "time": 590.51}
{"epoch": 35, "training_loss": 53.64880561828613, "training_acc": 67.5, "val_loss": 13.828785419464111, "val_acc": 55.0, "val_auroc": 0.485, "time": 606.59}
{"epoch": 36, "training_loss": 53.322832107543945, "training_acc": 73.75, "val_loss": 13.91227126121521, "val_acc": 55.0, "val_auroc": 0.475, "time": 623.15}
{"epoch": 37, "training_loss": 53.319732666015625, "training_acc": 73.75, "val_loss": 13.93431544303894, "val_acc": 55.0, "val_auroc": 0.485, "time": 640.06}
{"epoch": 38, "training_loss": 53.0704231262207, "training_acc": 78.75, "val_loss": 13.898873329162598, "val_acc": 55.0, "val_auroc": 0.505, "time": 656.34}
{"epoch": 39, "training_loss": 52.92671489715576, "training_acc": 80.0, "val_loss": 13.83457064628601, "val_acc": 55.0, "val_auroc": 0.515, "time": 672.2}
{"epoch": 40, "training_loss": 52.97583770751953, "training_acc": 75.0, "val_loss": 13.811979293823242, "val_acc": 55.0, "val_auroc": 0.485, "time": 688.91}
{"epoch": 41, "training_loss": 52.40312480926514, "training_acc": 77.5, "val_loss": 13.883174657821655, "val_acc": 55.0, "val_auroc": 0.465, "time": 705.33}
{"epoch": 42, "training_loss": 52.14946937561035, "training_acc": 78.75, "val_loss": 13.88986587524414, "val_acc": 55.0, "val_auroc": 0.495, "time": 721.15}
{"epoch": 43, "training_loss": 51.921908378601074, "training_acc": 80.0, "val_loss": 13.830711841583252, "val_acc": 55.0, "val_auroc": 0.505, "time": 737.17}
{"epoch": 44, "training_loss": 52.01843070983887, "training_acc": 77.5, "val_loss": 13.874622583389282, "val_acc": 55.0, "val_auroc": 0.485, "time": 753.49}
{"epoch": 45, "training_loss": 51.91014862060547, "training_acc": 81.25, "val_loss": 13.879221677780151, "val_acc": 55.0, "val_auroc": 0.485, "time": 770.01}
