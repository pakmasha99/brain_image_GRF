"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.49250411987305, "training_acc": 52.5, "val_loss": 14.048742055892944, "val_acc": 50.0, "val_auroc": 0.09, "time": 19.79}
{"epoch": 1, "training_loss": 55.42971420288086, "training_acc": 52.5, "val_loss": 13.985848426818848, "val_acc": 50.0, "val_auroc": 0.37, "time": 37.7}
{"epoch": 2, "training_loss": 55.18119716644287, "training_acc": 52.5, "val_loss": 14.011510610580444, "val_acc": 50.0, "val_auroc": 0.28, "time": 55.39}
{"epoch": 3, "training_loss": 55.093116760253906, "training_acc": 52.5, "val_loss": 13.985077142715454, "val_acc": 50.0, "val_auroc": 0.33, "time": 72.79}
{"epoch": 4, "training_loss": 55.22990131378174, "training_acc": 52.5, "val_loss": 13.937311172485352, "val_acc": 50.0, "val_auroc": 0.41, "time": 90.58}
{"epoch": 5, "training_loss": 55.02509593963623, "training_acc": 52.5, "val_loss": 13.982003927230835, "val_acc": 50.0, "val_auroc": 0.38, "time": 107.41}
{"epoch": 6, "training_loss": 54.92190170288086, "training_acc": 52.5, "val_loss": 13.958444595336914, "val_acc": 50.0, "val_auroc": 0.54, "time": 124.31}
{"epoch": 7, "training_loss": 55.07404708862305, "training_acc": 52.5, "val_loss": 13.937578201293945, "val_acc": 50.0, "val_auroc": 0.68, "time": 140.96}
{"epoch": 8, "training_loss": 54.92032241821289, "training_acc": 52.5, "val_loss": 13.964760303497314, "val_acc": 50.0, "val_auroc": 0.38, "time": 157.57}
{"epoch": 9, "training_loss": 54.89942932128906, "training_acc": 52.5, "val_loss": 13.92180323600769, "val_acc": 50.0, "val_auroc": 0.47, "time": 174.83}
{"epoch": 10, "training_loss": 54.833641052246094, "training_acc": 52.5, "val_loss": 13.914293050765991, "val_acc": 50.0, "val_auroc": 0.49, "time": 191.68}
{"epoch": 11, "training_loss": 54.80467224121094, "training_acc": 52.5, "val_loss": 13.906692266464233, "val_acc": 50.0, "val_auroc": 0.5, "time": 208.56}
{"epoch": 12, "training_loss": 54.58123588562012, "training_acc": 52.5, "val_loss": 13.876155614852905, "val_acc": 50.0, "val_auroc": 0.55, "time": 225.64}
{"epoch": 13, "training_loss": 54.4978141784668, "training_acc": 52.5, "val_loss": 13.873016834259033, "val_acc": 50.0, "val_auroc": 0.57, "time": 242.84}
{"epoch": 14, "training_loss": 54.40564727783203, "training_acc": 52.5, "val_loss": 13.836067914962769, "val_acc": 50.0, "val_auroc": 0.55, "time": 259.29}
{"epoch": 15, "training_loss": 54.284424781799316, "training_acc": 52.5, "val_loss": 13.839353322982788, "val_acc": 50.0, "val_auroc": 0.55, "time": 276.21}
{"epoch": 16, "training_loss": 53.882137298583984, "training_acc": 53.75, "val_loss": 13.869708776473999, "val_acc": 50.0, "val_auroc": 0.68, "time": 292.69}
{"epoch": 17, "training_loss": 54.29641532897949, "training_acc": 52.5, "val_loss": 13.90343427658081, "val_acc": 50.0, "val_auroc": 0.72, "time": 309.71}
{"epoch": 18, "training_loss": 53.90506458282471, "training_acc": 52.5, "val_loss": 13.859857320785522, "val_acc": 50.0, "val_auroc": 0.52, "time": 327.01}
{"epoch": 19, "training_loss": 53.46975612640381, "training_acc": 52.5, "val_loss": 13.86513352394104, "val_acc": 50.0, "val_auroc": 0.51, "time": 343.69}
{"epoch": 20, "training_loss": 53.589290618896484, "training_acc": 66.25, "val_loss": 13.885164260864258, "val_acc": 50.0, "val_auroc": 0.43, "time": 360.21}
{"epoch": 21, "training_loss": 53.24171829223633, "training_acc": 62.5, "val_loss": 13.830137252807617, "val_acc": 50.0, "val_auroc": 0.59, "time": 376.77}
{"epoch": 22, "training_loss": 53.25953769683838, "training_acc": 52.5, "val_loss": 13.790000677108765, "val_acc": 50.0, "val_auroc": 0.64, "time": 393.11}
{"epoch": 23, "training_loss": 52.80484867095947, "training_acc": 55.0, "val_loss": 13.820878267288208, "val_acc": 50.0, "val_auroc": 0.54, "time": 409.54}
{"epoch": 24, "training_loss": 52.2679500579834, "training_acc": 61.25, "val_loss": 13.845235109329224, "val_acc": 50.0, "val_auroc": 0.55, "time": 425.85}
{"epoch": 25, "training_loss": 51.86731719970703, "training_acc": 62.5, "val_loss": 13.974443674087524, "val_acc": 50.0, "val_auroc": 0.42, "time": 442.55}
{"epoch": 26, "training_loss": 52.06817626953125, "training_acc": 75.0, "val_loss": 13.977597951889038, "val_acc": 50.0, "val_auroc": 0.49, "time": 459.09}
{"epoch": 27, "training_loss": 52.221251487731934, "training_acc": 53.75, "val_loss": 13.94666314125061, "val_acc": 50.0, "val_auroc": 0.45, "time": 475.58}
{"epoch": 28, "training_loss": 50.63201141357422, "training_acc": 63.75, "val_loss": 13.74719500541687, "val_acc": 50.0, "val_auroc": 0.65, "time": 492.86}
{"epoch": 29, "training_loss": 55.042521476745605, "training_acc": 61.25, "val_loss": 13.825531005859375, "val_acc": 50.0, "val_auroc": 0.61, "time": 509.62}
{"epoch": 30, "training_loss": 55.37890815734863, "training_acc": 52.5, "val_loss": 13.840386867523193, "val_acc": 50.0, "val_auroc": 0.49, "time": 525.87}
{"epoch": 31, "training_loss": 55.128374099731445, "training_acc": 52.5, "val_loss": 13.863937854766846, "val_acc": 50.0, "val_auroc": 0.41, "time": 542.72}
{"epoch": 32, "training_loss": 54.56024646759033, "training_acc": 56.25, "val_loss": 13.897727727890015, "val_acc": 50.0, "val_auroc": 0.43, "time": 559.02}
{"epoch": 33, "training_loss": 54.18976020812988, "training_acc": 62.5, "val_loss": 13.902828693389893, "val_acc": 50.0, "val_auroc": 0.41, "time": 575.48}
{"epoch": 34, "training_loss": 53.83626937866211, "training_acc": 62.5, "val_loss": 13.882378339767456, "val_acc": 50.0, "val_auroc": 0.46, "time": 592.08}
{"epoch": 35, "training_loss": 53.37466526031494, "training_acc": 60.0, "val_loss": 13.824295997619629, "val_acc": 50.0, "val_auroc": 0.49, "time": 608.87}
{"epoch": 36, "training_loss": 53.13451099395752, "training_acc": 77.5, "val_loss": 13.787697553634644, "val_acc": 50.0, "val_auroc": 0.52, "time": 625.33}
{"epoch": 37, "training_loss": 52.507511138916016, "training_acc": 73.75, "val_loss": 13.805831670761108, "val_acc": 50.0, "val_auroc": 0.58, "time": 641.73}
{"epoch": 38, "training_loss": 52.53306484222412, "training_acc": 61.25, "val_loss": 13.7953782081604, "val_acc": 50.0, "val_auroc": 0.54, "time": 658.11}
{"epoch": 39, "training_loss": 51.80886459350586, "training_acc": 77.5, "val_loss": 13.782882690429688, "val_acc": 50.0, "val_auroc": 0.53, "time": 674.86}
{"epoch": 40, "training_loss": 50.73306083679199, "training_acc": 72.5, "val_loss": 13.845690488815308, "val_acc": 50.0, "val_auroc": 0.63, "time": 691.37}
{"epoch": 41, "training_loss": 51.67975616455078, "training_acc": 67.5, "val_loss": 13.710366487503052, "val_acc": 50.0, "val_auroc": 0.51, "time": 709.18}
{"epoch": 42, "training_loss": 49.479196548461914, "training_acc": 76.25, "val_loss": 13.690105676651001, "val_acc": 50.0, "val_auroc": 0.55, "time": 725.88}
{"epoch": 43, "training_loss": 48.23914337158203, "training_acc": 82.5, "val_loss": 13.802385330200195, "val_acc": 50.0, "val_auroc": 0.57, "time": 743.4}
{"epoch": 44, "training_loss": 48.72933387756348, "training_acc": 81.25, "val_loss": 13.81282091140747, "val_acc": 50.0, "val_auroc": 0.52, "time": 759.57}
{"epoch": 45, "training_loss": 47.45231819152832, "training_acc": 83.75, "val_loss": 13.876795768737793, "val_acc": 50.0, "val_auroc": 0.58, "time": 776.13}
{"epoch": 46, "training_loss": 46.762383460998535, "training_acc": 83.75, "val_loss": 13.668912649154663, "val_acc": 50.0, "val_auroc": 0.61, "time": 793.19}
{"epoch": 47, "training_loss": 47.37678241729736, "training_acc": 72.5, "val_loss": 14.228308200836182, "val_acc": 50.0, "val_auroc": 0.47, "time": 810.19}
{"epoch": 48, "training_loss": 55.39616775512695, "training_acc": 47.5, "val_loss": 13.745596408843994, "val_acc": 50.0, "val_auroc": 0.63, "time": 826.44}
{"epoch": 49, "training_loss": 48.863484382629395, "training_acc": 78.75, "val_loss": 14.271179437637329, "val_acc": 50.0, "val_auroc": 0.65, "time": 843.17}
{"epoch": 50, "training_loss": 50.372663497924805, "training_acc": 56.25, "val_loss": 13.708704710006714, "val_acc": 50.0, "val_auroc": 0.61, "time": 859.9}
{"epoch": 51, "training_loss": 47.30615234375, "training_acc": 92.5, "val_loss": 13.824084997177124, "val_acc": 50.0, "val_auroc": 0.62, "time": 876.41}
{"epoch": 52, "training_loss": 47.72334861755371, "training_acc": 83.75, "val_loss": 13.882629871368408, "val_acc": 50.0, "val_auroc": 0.62, "time": 893.21}
{"epoch": 53, "training_loss": 47.2439079284668, "training_acc": 66.25, "val_loss": 13.544769287109375, "val_acc": 50.0, "val_auroc": 0.62, "time": 910.66}
{"epoch": 54, "training_loss": 45.02343940734863, "training_acc": 87.5, "val_loss": 13.762296438217163, "val_acc": 55.0, "val_auroc": 0.63, "time": 927.29}
{"epoch": 55, "training_loss": 44.13759231567383, "training_acc": 87.5, "val_loss": 14.151885509490967, "val_acc": 50.0, "val_auroc": 0.66, "time": 944.31}
{"epoch": 56, "training_loss": 46.759910583496094, "training_acc": 63.75, "val_loss": 13.881874084472656, "val_acc": 50.0, "val_auroc": 0.57, "time": 961.17}
{"epoch": 57, "training_loss": 43.46118354797363, "training_acc": 97.5, "val_loss": 14.0554678440094, "val_acc": 65.0, "val_auroc": 0.58, "time": 978.03}
{"epoch": 58, "training_loss": 43.80279541015625, "training_acc": 88.75, "val_loss": 13.83832573890686, "val_acc": 50.0, "val_auroc": 0.65, "time": 994.85}
{"epoch": 59, "training_loss": 42.14289569854736, "training_acc": 82.5, "val_loss": 13.508615493774414, "val_acc": 55.0, "val_auroc": 0.63, "time": 1011.98}
{"epoch": 60, "training_loss": 39.13308763504028, "training_acc": 95.0, "val_loss": 13.579391241073608, "val_acc": 55.0, "val_auroc": 0.62, "time": 1028.7}
{"epoch": 61, "training_loss": 35.864487648010254, "training_acc": 97.5, "val_loss": 13.764197826385498, "val_acc": 55.0, "val_auroc": 0.63, "time": 1045.97}
{"epoch": 62, "training_loss": 35.72566032409668, "training_acc": 93.75, "val_loss": 13.663088083267212, "val_acc": 60.0, "val_auroc": 0.63, "time": 1062.78}
{"epoch": 63, "training_loss": 34.59861373901367, "training_acc": 96.25, "val_loss": 13.705580234527588, "val_acc": 65.0, "val_auroc": 0.64, "time": 1079.44}
{"epoch": 64, "training_loss": 33.80759334564209, "training_acc": 96.25, "val_loss": 14.114035367965698, "val_acc": 70.0, "val_auroc": 0.62, "time": 1095.86}
{"epoch": 65, "training_loss": 33.48867702484131, "training_acc": 98.75, "val_loss": 13.563231229782104, "val_acc": 60.0, "val_auroc": 0.63, "time": 1112.36}
{"epoch": 66, "training_loss": 32.22519397735596, "training_acc": 97.5, "val_loss": 14.73258376121521, "val_acc": 60.0, "val_auroc": 0.54, "time": 1131.29}
{"epoch": 67, "training_loss": 34.75768566131592, "training_acc": 95.0, "val_loss": 13.96005392074585, "val_acc": 60.0, "val_auroc": 0.59, "time": 1148.2}
{"epoch": 68, "training_loss": 30.16767692565918, "training_acc": 100.0, "val_loss": 13.79851222038269, "val_acc": 60.0, "val_auroc": 0.64, "time": 1164.41}
{"epoch": 69, "training_loss": 30.643138885498047, "training_acc": 98.75, "val_loss": 14.253147840499878, "val_acc": 60.0, "val_auroc": 0.59, "time": 1181.16}
{"epoch": 70, "training_loss": 28.771594047546387, "training_acc": 100.0, "val_loss": 13.643440008163452, "val_acc": 60.0, "val_auroc": 0.63, "time": 1198.39}
{"epoch": 71, "training_loss": 28.955485820770264, "training_acc": 98.75, "val_loss": 14.793376922607422, "val_acc": 60.0, "val_auroc": 0.6, "time": 1215.22}
{"epoch": 72, "training_loss": 28.761521339416504, "training_acc": 98.75, "val_loss": 13.714230060577393, "val_acc": 60.0, "val_auroc": 0.64, "time": 1231.44}
{"epoch": 73, "training_loss": 27.113561630249023, "training_acc": 100.0, "val_loss": 14.6390962600708, "val_acc": 60.0, "val_auroc": 0.57, "time": 1247.63}
{"epoch": 74, "training_loss": 28.656171798706055, "training_acc": 97.5, "val_loss": 13.821614980697632, "val_acc": 60.0, "val_auroc": 0.63, "time": 1264.53}
{"epoch": 75, "training_loss": 26.59068489074707, "training_acc": 100.0, "val_loss": 13.950388431549072, "val_acc": 60.0, "val_auroc": 0.6, "time": 1280.87}
{"epoch": 76, "training_loss": 24.785993099212646, "training_acc": 100.0, "val_loss": 13.861368894577026, "val_acc": 60.0, "val_auroc": 0.59, "time": 1297.47}
{"epoch": 77, "training_loss": 24.48691463470459, "training_acc": 100.0, "val_loss": 13.90499472618103, "val_acc": 60.0, "val_auroc": 0.59, "time": 1314.15}
{"epoch": 78, "training_loss": 23.737488746643066, "training_acc": 100.0, "val_loss": 14.025768041610718, "val_acc": 60.0, "val_auroc": 0.61, "time": 1330.39}
