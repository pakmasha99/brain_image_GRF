"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.17097854614258, "training_acc": 52.5, "val_loss": 14.003305435180664, "val_acc": 50.0, "val_auroc": 0.15, "time": 16.44}
{"epoch": 1, "training_loss": 55.985538482666016, "training_acc": 47.5, "val_loss": 13.887087106704712, "val_acc": 50.0, "val_auroc": 0.52, "time": 30.71}
{"epoch": 2, "training_loss": 55.41238594055176, "training_acc": 52.5, "val_loss": 13.966929912567139, "val_acc": 50.0, "val_auroc": 0.75, "time": 44.81}
{"epoch": 3, "training_loss": 55.68759727478027, "training_acc": 52.5, "val_loss": 14.022334814071655, "val_acc": 50.0, "val_auroc": 0.64, "time": 59.01}
{"epoch": 4, "training_loss": 55.59242248535156, "training_acc": 52.5, "val_loss": 13.914488554000854, "val_acc": 50.0, "val_auroc": 0.36, "time": 73.49}
{"epoch": 5, "training_loss": 55.42176818847656, "training_acc": 52.5, "val_loss": 13.88007640838623, "val_acc": 50.0, "val_auroc": 0.65, "time": 88.59}
{"epoch": 6, "training_loss": 55.481515884399414, "training_acc": 52.5, "val_loss": 13.980110883712769, "val_acc": 50.0, "val_auroc": 0.87, "time": 102.99}
{"epoch": 7, "training_loss": 55.4909610748291, "training_acc": 52.5, "val_loss": 14.130767583847046, "val_acc": 50.0, "val_auroc": 0.6, "time": 117.48}
{"epoch": 8, "training_loss": 55.90496635437012, "training_acc": 52.5, "val_loss": 13.93119215965271, "val_acc": 50.0, "val_auroc": 0.51, "time": 131.91}
{"epoch": 9, "training_loss": 55.34279251098633, "training_acc": 52.5, "val_loss": 13.87111783027649, "val_acc": 50.0, "val_auroc": 0.29, "time": 146.05}
{"epoch": 10, "training_loss": 55.65760517120361, "training_acc": 47.5, "val_loss": 13.875998258590698, "val_acc": 50.0, "val_auroc": 0.59, "time": 160.27}
{"epoch": 11, "training_loss": 55.57444477081299, "training_acc": 47.5, "val_loss": 13.877140283584595, "val_acc": 50.0, "val_auroc": 0.66, "time": 175.22}
{"epoch": 12, "training_loss": 55.399715423583984, "training_acc": 52.5, "val_loss": 13.961799144744873, "val_acc": 50.0, "val_auroc": 0.69, "time": 190.97}
{"epoch": 13, "training_loss": 55.46947479248047, "training_acc": 52.5, "val_loss": 13.974117040634155, "val_acc": 50.0, "val_auroc": 0.37, "time": 206.17}
{"epoch": 14, "training_loss": 55.45681190490723, "training_acc": 52.5, "val_loss": 13.911837339401245, "val_acc": 50.0, "val_auroc": 0.42, "time": 221.82}
{"epoch": 15, "training_loss": 55.55227279663086, "training_acc": 52.5, "val_loss": 13.89675259590149, "val_acc": 50.0, "val_auroc": 0.41, "time": 236.13}
{"epoch": 16, "training_loss": 55.33090782165527, "training_acc": 52.5, "val_loss": 13.985759019851685, "val_acc": 50.0, "val_auroc": 0.86, "time": 251.23}
{"epoch": 17, "training_loss": 55.56777572631836, "training_acc": 52.5, "val_loss": 14.092210531234741, "val_acc": 50.0, "val_auroc": 0.36, "time": 267.91}
{"epoch": 18, "training_loss": 55.76663017272949, "training_acc": 52.5, "val_loss": 13.995212316513062, "val_acc": 50.0, "val_auroc": 0.57, "time": 282.56}
{"epoch": 19, "training_loss": 55.39927101135254, "training_acc": 52.5, "val_loss": 13.87041449546814, "val_acc": 50.0, "val_auroc": 0.09, "time": 298.01}
{"epoch": 20, "training_loss": 55.46668815612793, "training_acc": 50.0, "val_loss": 13.880976438522339, "val_acc": 50.0, "val_auroc": 0.09, "time": 312.02}
{"epoch": 21, "training_loss": 55.71605587005615, "training_acc": 47.5, "val_loss": 13.877561092376709, "val_acc": 50.0, "val_auroc": 0.1, "time": 326.91}
{"epoch": 22, "training_loss": 55.61338996887207, "training_acc": 47.5, "val_loss": 13.865647315979004, "val_acc": 50.0, "val_auroc": 0.32, "time": 342.53}
{"epoch": 23, "training_loss": 55.2997989654541, "training_acc": 52.5, "val_loss": 13.948945999145508, "val_acc": 50.0, "val_auroc": 0.65, "time": 356.84}
{"epoch": 24, "training_loss": 55.35421943664551, "training_acc": 52.5, "val_loss": 14.13751482963562, "val_acc": 50.0, "val_auroc": 0.79, "time": 371.44}
{"epoch": 25, "training_loss": 55.90256881713867, "training_acc": 52.5, "val_loss": 14.251457452774048, "val_acc": 50.0, "val_auroc": 0.38, "time": 386.5}
{"epoch": 26, "training_loss": 56.26797866821289, "training_acc": 52.5, "val_loss": 14.219166040420532, "val_acc": 50.0, "val_auroc": 0.14, "time": 401.01}
{"epoch": 27, "training_loss": 56.109463691711426, "training_acc": 52.5, "val_loss": 14.134010076522827, "val_acc": 50.0, "val_auroc": 0.72, "time": 415.62}
{"epoch": 28, "training_loss": 55.75682830810547, "training_acc": 52.5, "val_loss": 13.928513526916504, "val_acc": 50.0, "val_auroc": 0.79, "time": 429.88}
{"epoch": 29, "training_loss": 55.47203826904297, "training_acc": 52.5, "val_loss": 13.871166706085205, "val_acc": 50.0, "val_auroc": 0.82, "time": 444.37}
{"epoch": 30, "training_loss": 55.69117832183838, "training_acc": 47.5, "val_loss": 13.908997774124146, "val_acc": 50.0, "val_auroc": 0.63, "time": 458.63}
{"epoch": 31, "training_loss": 55.92069435119629, "training_acc": 47.5, "val_loss": 13.891651630401611, "val_acc": 50.0, "val_auroc": 0.25, "time": 473.72}
{"epoch": 32, "training_loss": 55.8013334274292, "training_acc": 47.5, "val_loss": 13.873156309127808, "val_acc": 50.0, "val_auroc": 0.13, "time": 489.36}
{"epoch": 33, "training_loss": 55.60931587219238, "training_acc": 47.5, "val_loss": 13.863245248794556, "val_acc": 50.0, "val_auroc": 0.34, "time": 504.71}
{"epoch": 34, "training_loss": 55.40578079223633, "training_acc": 52.5, "val_loss": 13.888436555862427, "val_acc": 50.0, "val_auroc": 0.27, "time": 519.95}
{"epoch": 35, "training_loss": 55.55898666381836, "training_acc": 52.5, "val_loss": 13.941243886947632, "val_acc": 50.0, "val_auroc": 0.09, "time": 536.14}
{"epoch": 36, "training_loss": 55.4048547744751, "training_acc": 52.5, "val_loss": 13.914626836776733, "val_acc": 50.0, "val_auroc": 0.2, "time": 550.6}
{"epoch": 37, "training_loss": 55.342644691467285, "training_acc": 52.5, "val_loss": 13.875223398208618, "val_acc": 50.0, "val_auroc": 0.14, "time": 568.54}
{"epoch": 38, "training_loss": 55.46799087524414, "training_acc": 52.5, "val_loss": 13.865171670913696, "val_acc": 50.0, "val_auroc": 0.09, "time": 583.74}
{"epoch": 39, "training_loss": 55.41799354553223, "training_acc": 52.5, "val_loss": 13.867368698120117, "val_acc": 50.0, "val_auroc": 0.17, "time": 597.91}
{"epoch": 40, "training_loss": 55.454651832580566, "training_acc": 52.5, "val_loss": 13.866380453109741, "val_acc": 50.0, "val_auroc": 0.13, "time": 612.28}
{"epoch": 41, "training_loss": 55.37825107574463, "training_acc": 52.5, "val_loss": 13.864376544952393, "val_acc": 50.0, "val_auroc": 0.16, "time": 626.47}
{"epoch": 42, "training_loss": 55.57145881652832, "training_acc": 47.5, "val_loss": 13.864736557006836, "val_acc": 50.0, "val_auroc": 0.6, "time": 640.92}
{"epoch": 43, "training_loss": 55.511457443237305, "training_acc": 47.5, "val_loss": 13.868957757949829, "val_acc": 50.0, "val_auroc": 0.11, "time": 655.69}
{"epoch": 44, "training_loss": 55.39081382751465, "training_acc": 52.5, "val_loss": 13.89426589012146, "val_acc": 50.0, "val_auroc": 0.35, "time": 671.56}
{"epoch": 45, "training_loss": 55.364556312561035, "training_acc": 52.5, "val_loss": 13.91373872756958, "val_acc": 50.0, "val_auroc": 0.43, "time": 686.99}
{"epoch": 46, "training_loss": 55.37022686004639, "training_acc": 52.5, "val_loss": 13.920096158981323, "val_acc": 50.0, "val_auroc": 0.58, "time": 702.88}
{"epoch": 47, "training_loss": 55.381327629089355, "training_acc": 52.5, "val_loss": 13.916788101196289, "val_acc": 50.0, "val_auroc": 0.4, "time": 718.04}
{"epoch": 48, "training_loss": 55.45302200317383, "training_acc": 52.5, "val_loss": 13.921164274215698, "val_acc": 50.0, "val_auroc": 0.17, "time": 732.95}
{"epoch": 49, "training_loss": 55.399399757385254, "training_acc": 52.5, "val_loss": 13.954137563705444, "val_acc": 50.0, "val_auroc": 0.46, "time": 747.65}
{"epoch": 50, "training_loss": 55.43482780456543, "training_acc": 52.5, "val_loss": 13.937677145004272, "val_acc": 50.0, "val_auroc": 0.48, "time": 763.67}
{"epoch": 51, "training_loss": 55.38955497741699, "training_acc": 52.5, "val_loss": 13.896158933639526, "val_acc": 50.0, "val_auroc": 0.31, "time": 778.51}
{"epoch": 52, "training_loss": 55.42429161071777, "training_acc": 52.5, "val_loss": 13.878065347671509, "val_acc": 50.0, "val_auroc": 0.31, "time": 793.22}
