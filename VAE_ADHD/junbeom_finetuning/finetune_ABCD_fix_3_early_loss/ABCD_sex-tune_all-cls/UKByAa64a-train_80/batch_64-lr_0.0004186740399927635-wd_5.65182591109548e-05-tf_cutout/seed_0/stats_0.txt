"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 60.56223201751709, "training_acc": 42.5, "val_loss": 14.144995212554932, "val_acc": 50.0, "val_auroc": 0.31, "time": 19.57}
{"epoch": 1, "training_loss": 90.57321548461914, "training_acc": 45.0, "val_loss": 13.968724012374878, "val_acc": 50.0, "val_auroc": 0.57, "time": 37.18}
{"epoch": 2, "training_loss": 82.70601654052734, "training_acc": 47.5, "val_loss": 13.86073112487793, "val_acc": 50.0, "val_auroc": 0.62, "time": 51.06}
{"epoch": 3, "training_loss": 55.370588302612305, "training_acc": 52.5, "val_loss": 13.864648342132568, "val_acc": 50.0, "val_auroc": 0.53, "time": 68.61}
{"epoch": 4, "training_loss": 55.55439376831055, "training_acc": 51.25, "val_loss": 14.194673299789429, "val_acc": 50.0, "val_auroc": 0.47, "time": 86.06}
{"epoch": 5, "training_loss": 57.899521827697754, "training_acc": 45.0, "val_loss": 13.865551948547363, "val_acc": 50.0, "val_auroc": 0.5, "time": 101.66}
{"epoch": 6, "training_loss": 55.50350475311279, "training_acc": 47.5, "val_loss": 13.859742879867554, "val_acc": 50.0, "val_auroc": 0.5, "time": 118.79}
{"epoch": 7, "training_loss": 55.6677303314209, "training_acc": 52.5, "val_loss": 13.868683576583862, "val_acc": 50.0, "val_auroc": 0.49, "time": 136.1}
{"epoch": 8, "training_loss": 55.64507865905762, "training_acc": 47.5, "val_loss": 13.860015869140625, "val_acc": 50.0, "val_auroc": 0.48, "time": 153.69}
{"epoch": 9, "training_loss": 55.633750915527344, "training_acc": 47.5, "val_loss": 13.990789651870728, "val_acc": 50.0, "val_auroc": 0.52, "time": 170.94}
{"epoch": 10, "training_loss": 55.46183395385742, "training_acc": 52.5, "val_loss": 13.927191495895386, "val_acc": 50.0, "val_auroc": 0.5, "time": 188.22}
{"epoch": 11, "training_loss": 55.483208656311035, "training_acc": 52.5, "val_loss": 13.973883390426636, "val_acc": 50.0, "val_auroc": 0.49, "time": 205.24}
{"epoch": 12, "training_loss": 55.34877014160156, "training_acc": 52.5, "val_loss": 14.205883741378784, "val_acc": 50.0, "val_auroc": 0.48, "time": 222.55}
{"epoch": 13, "training_loss": 56.09658432006836, "training_acc": 52.5, "val_loss": 14.260828495025635, "val_acc": 50.0, "val_auroc": 0.49, "time": 239.8}
{"epoch": 14, "training_loss": 56.4019889831543, "training_acc": 52.5, "val_loss": 14.325119256973267, "val_acc": 50.0, "val_auroc": 0.47, "time": 256.99}
{"epoch": 15, "training_loss": 56.29890060424805, "training_acc": 52.5, "val_loss": 14.313431978225708, "val_acc": 50.0, "val_auroc": 0.49, "time": 274.14}
{"epoch": 16, "training_loss": 56.295273780822754, "training_acc": 52.5, "val_loss": 14.042776823043823, "val_acc": 50.0, "val_auroc": 0.49, "time": 290.94}
{"epoch": 17, "training_loss": 55.38125514984131, "training_acc": 52.5, "val_loss": 13.85771632194519, "val_acc": 50.0, "val_auroc": 0.49, "time": 308.73}
{"epoch": 18, "training_loss": 55.44271278381348, "training_acc": 57.5, "val_loss": 13.85831594467163, "val_acc": 50.0, "val_auroc": 0.49, "time": 326.7}
{"epoch": 19, "training_loss": 55.9136962890625, "training_acc": 46.25, "val_loss": 13.874510526657104, "val_acc": 50.0, "val_auroc": 0.48, "time": 343.77}
{"epoch": 20, "training_loss": 55.19413185119629, "training_acc": 55.0, "val_loss": 13.878148794174194, "val_acc": 50.0, "val_auroc": 0.48, "time": 360.84}
{"epoch": 21, "training_loss": 55.68980598449707, "training_acc": 47.5, "val_loss": 13.874791860580444, "val_acc": 50.0, "val_auroc": 0.47, "time": 378.05}
{"epoch": 22, "training_loss": 55.32605743408203, "training_acc": 51.25, "val_loss": 13.919161558151245, "val_acc": 50.0, "val_auroc": 0.47, "time": 395.05}
{"epoch": 23, "training_loss": 55.32126426696777, "training_acc": 52.5, "val_loss": 14.062719345092773, "val_acc": 50.0, "val_auroc": 0.46, "time": 411.96}
{"epoch": 24, "training_loss": 55.62293720245361, "training_acc": 52.5, "val_loss": 13.983248472213745, "val_acc": 50.0, "val_auroc": 0.4, "time": 428.24}
{"epoch": 25, "training_loss": 55.3699426651001, "training_acc": 52.5, "val_loss": 13.87488603591919, "val_acc": 50.0, "val_auroc": 0.54, "time": 442.38}
{"epoch": 26, "training_loss": 55.41123962402344, "training_acc": 53.75, "val_loss": 13.864713907241821, "val_acc": 50.0, "val_auroc": 0.53, "time": 459.41}
{"epoch": 27, "training_loss": 55.408180236816406, "training_acc": 66.25, "val_loss": 13.890155553817749, "val_acc": 50.0, "val_auroc": 0.43, "time": 476.48}
{"epoch": 28, "training_loss": 55.5965633392334, "training_acc": 52.5, "val_loss": 13.922322988510132, "val_acc": 50.0, "val_auroc": 0.43, "time": 491.66}
{"epoch": 29, "training_loss": 55.34246063232422, "training_acc": 52.5, "val_loss": 13.874620199203491, "val_acc": 50.0, "val_auroc": 0.48, "time": 508.62}
{"epoch": 30, "training_loss": 55.29239082336426, "training_acc": 52.5, "val_loss": 13.872212171554565, "val_acc": 50.0, "val_auroc": 0.45, "time": 525.8}
{"epoch": 31, "training_loss": 55.280869483947754, "training_acc": 52.5, "val_loss": 13.881988525390625, "val_acc": 50.0, "val_auroc": 0.46, "time": 543.04}
{"epoch": 32, "training_loss": 55.27941608428955, "training_acc": 52.5, "val_loss": 13.876196146011353, "val_acc": 50.0, "val_auroc": 0.45, "time": 559.9}
{"epoch": 33, "training_loss": 55.2914400100708, "training_acc": 52.5, "val_loss": 13.873766660690308, "val_acc": 50.0, "val_auroc": 0.45, "time": 576.78}
{"epoch": 34, "training_loss": 55.17851638793945, "training_acc": 52.5, "val_loss": 13.919413089752197, "val_acc": 50.0, "val_auroc": 0.45, "time": 594.36}
{"epoch": 35, "training_loss": 55.40706443786621, "training_acc": 52.5, "val_loss": 13.954085111618042, "val_acc": 50.0, "val_auroc": 0.45, "time": 611.67}
{"epoch": 36, "training_loss": 55.2822208404541, "training_acc": 52.5, "val_loss": 13.895481824874878, "val_acc": 50.0, "val_auroc": 0.45, "time": 628.83}
