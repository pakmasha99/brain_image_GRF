"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.481367111206055, "training_acc": 51.25, "val_loss": 13.84305715560913, "val_acc": 55.0, "val_auroc": 0.333, "time": 16.23}
{"epoch": 1, "training_loss": 55.38795852661133, "training_acc": 51.25, "val_loss": 13.811120986938477, "val_acc": 55.0, "val_auroc": 0.505, "time": 31.28}
{"epoch": 2, "training_loss": 55.3868932723999, "training_acc": 51.25, "val_loss": 13.794662952423096, "val_acc": 55.0, "val_auroc": 0.576, "time": 45.88}
{"epoch": 3, "training_loss": 55.413761138916016, "training_acc": 51.25, "val_loss": 13.812354803085327, "val_acc": 55.0, "val_auroc": 0.495, "time": 60.31}
{"epoch": 4, "training_loss": 55.50387477874756, "training_acc": 51.25, "val_loss": 13.78426194190979, "val_acc": 55.0, "val_auroc": 0.556, "time": 75.01}
{"epoch": 5, "training_loss": 55.38800525665283, "training_acc": 51.25, "val_loss": 13.762071132659912, "val_acc": 55.0, "val_auroc": 0.505, "time": 89.85}
{"epoch": 6, "training_loss": 55.50567626953125, "training_acc": 51.25, "val_loss": 13.77251148223877, "val_acc": 55.0, "val_auroc": 0.465, "time": 104.3}
{"epoch": 7, "training_loss": 55.39565086364746, "training_acc": 51.25, "val_loss": 13.832013607025146, "val_acc": 55.0, "val_auroc": 0.616, "time": 118.62}
{"epoch": 8, "training_loss": 55.369829177856445, "training_acc": 51.25, "val_loss": 13.915785551071167, "val_acc": 55.0, "val_auroc": 0.667, "time": 132.84}
{"epoch": 9, "training_loss": 55.457725524902344, "training_acc": 50.0, "val_loss": 13.981283903121948, "val_acc": 55.0, "val_auroc": 0.657, "time": 147.19}
{"epoch": 10, "training_loss": 55.52700996398926, "training_acc": 48.75, "val_loss": 13.872034549713135, "val_acc": 55.0, "val_auroc": 0.596, "time": 161.62}
{"epoch": 11, "training_loss": 55.20329284667969, "training_acc": 58.75, "val_loss": 13.768326044082642, "val_acc": 55.0, "val_auroc": 0.475, "time": 176.05}
{"epoch": 12, "training_loss": 55.60566425323486, "training_acc": 51.25, "val_loss": 13.760751485824585, "val_acc": 55.0, "val_auroc": 0.475, "time": 190.89}
{"epoch": 13, "training_loss": 55.62288475036621, "training_acc": 51.25, "val_loss": 13.774021863937378, "val_acc": 55.0, "val_auroc": 0.455, "time": 205.37}
{"epoch": 14, "training_loss": 55.43692684173584, "training_acc": 51.25, "val_loss": 13.817566633224487, "val_acc": 55.0, "val_auroc": 0.535, "time": 219.92}
{"epoch": 15, "training_loss": 55.58382034301758, "training_acc": 47.5, "val_loss": 13.835861682891846, "val_acc": 55.0, "val_auroc": 0.465, "time": 236.51}
{"epoch": 16, "training_loss": 55.340006828308105, "training_acc": 51.25, "val_loss": 13.782488107681274, "val_acc": 55.0, "val_auroc": 0.414, "time": 250.67}
{"epoch": 17, "training_loss": 55.53652381896973, "training_acc": 51.25, "val_loss": 13.768309354782104, "val_acc": 55.0, "val_auroc": 0.404, "time": 265.13}
{"epoch": 18, "training_loss": 55.53901290893555, "training_acc": 51.25, "val_loss": 13.780773878097534, "val_acc": 55.0, "val_auroc": 0.495, "time": 279.64}
{"epoch": 19, "training_loss": 55.33404731750488, "training_acc": 51.25, "val_loss": 13.849385976791382, "val_acc": 55.0, "val_auroc": 0.566, "time": 294.29}
{"epoch": 20, "training_loss": 55.45044422149658, "training_acc": 48.75, "val_loss": 13.920944929122925, "val_acc": 55.0, "val_auroc": 0.434, "time": 308.51}
{"epoch": 21, "training_loss": 55.445343017578125, "training_acc": 48.75, "val_loss": 13.874918222427368, "val_acc": 55.0, "val_auroc": 0.444, "time": 323.02}
{"epoch": 22, "training_loss": 55.356393814086914, "training_acc": 57.5, "val_loss": 13.822835683822632, "val_acc": 55.0, "val_auroc": 0.444, "time": 337.24}
{"epoch": 23, "training_loss": 55.31271839141846, "training_acc": 51.25, "val_loss": 13.80595088005066, "val_acc": 55.0, "val_auroc": 0.384, "time": 351.94}
{"epoch": 24, "training_loss": 55.32912635803223, "training_acc": 51.25, "val_loss": 13.795526027679443, "val_acc": 55.0, "val_auroc": 0.384, "time": 366.19}
{"epoch": 25, "training_loss": 55.331729888916016, "training_acc": 51.25, "val_loss": 13.782186508178711, "val_acc": 55.0, "val_auroc": 0.364, "time": 380.85}
{"epoch": 26, "training_loss": 55.470428466796875, "training_acc": 51.25, "val_loss": 13.79442572593689, "val_acc": 55.0, "val_auroc": 0.424, "time": 395.16}
{"epoch": 27, "training_loss": 55.760976791381836, "training_acc": 51.25, "val_loss": 13.788425922393799, "val_acc": 55.0, "val_auroc": 0.495, "time": 409.38}
{"epoch": 28, "training_loss": 55.60714626312256, "training_acc": 51.25, "val_loss": 13.785034418106079, "val_acc": 55.0, "val_auroc": 0.515, "time": 423.7}
{"epoch": 29, "training_loss": 55.37893104553223, "training_acc": 51.25, "val_loss": 13.874027729034424, "val_acc": 55.0, "val_auroc": 0.505, "time": 438.18}
{"epoch": 30, "training_loss": 55.41901969909668, "training_acc": 50.0, "val_loss": 13.914135694503784, "val_acc": 55.0, "val_auroc": 0.525, "time": 453.12}
{"epoch": 31, "training_loss": 55.50191116333008, "training_acc": 48.75, "val_loss": 13.942629098892212, "val_acc": 55.0, "val_auroc": 0.515, "time": 467.59}
