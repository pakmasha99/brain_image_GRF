"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5375862121582, "training_acc": 52.5, "val_loss": 13.818072080612183, "val_acc": 50.0, "val_auroc": 0.73, "time": 16.26}
{"epoch": 1, "training_loss": 55.3781623840332, "training_acc": 52.5, "val_loss": 13.876657485961914, "val_acc": 50.0, "val_auroc": 0.54, "time": 30.65}
{"epoch": 2, "training_loss": 55.36060428619385, "training_acc": 52.5, "val_loss": 13.953303098678589, "val_acc": 50.0, "val_auroc": 0.31, "time": 45.22}
{"epoch": 3, "training_loss": 55.28965663909912, "training_acc": 52.5, "val_loss": 13.94343614578247, "val_acc": 50.0, "val_auroc": 0.46, "time": 59.7}
{"epoch": 4, "training_loss": 55.337242126464844, "training_acc": 52.5, "val_loss": 13.911805152893066, "val_acc": 50.0, "val_auroc": 0.41, "time": 73.81}
{"epoch": 5, "training_loss": 55.29679870605469, "training_acc": 52.5, "val_loss": 13.874720335006714, "val_acc": 50.0, "val_auroc": 0.6, "time": 88.12}
{"epoch": 6, "training_loss": 55.286179542541504, "training_acc": 52.5, "val_loss": 13.934345245361328, "val_acc": 50.0, "val_auroc": 0.59, "time": 102.32}
{"epoch": 7, "training_loss": 55.26901435852051, "training_acc": 52.5, "val_loss": 14.029598236083984, "val_acc": 50.0, "val_auroc": 0.52, "time": 116.62}
{"epoch": 8, "training_loss": 55.56959342956543, "training_acc": 52.5, "val_loss": 13.952142000198364, "val_acc": 50.0, "val_auroc": 0.56, "time": 130.94}
{"epoch": 9, "training_loss": 55.245710372924805, "training_acc": 52.5, "val_loss": 13.853691816329956, "val_acc": 50.0, "val_auroc": 0.64, "time": 145.13}
{"epoch": 10, "training_loss": 55.245415687561035, "training_acc": 52.5, "val_loss": 13.85769248008728, "val_acc": 50.0, "val_auroc": 0.55, "time": 159.58}
{"epoch": 11, "training_loss": 55.12762641906738, "training_acc": 53.75, "val_loss": 13.902935981750488, "val_acc": 50.0, "val_auroc": 0.48, "time": 174.14}
{"epoch": 12, "training_loss": 55.29807186126709, "training_acc": 52.5, "val_loss": 13.962599039077759, "val_acc": 50.0, "val_auroc": 0.38, "time": 188.54}
{"epoch": 13, "training_loss": 55.139474868774414, "training_acc": 52.5, "val_loss": 13.922203779220581, "val_acc": 50.0, "val_auroc": 0.5, "time": 203.21}
{"epoch": 14, "training_loss": 55.14913368225098, "training_acc": 52.5, "val_loss": 13.869549036026001, "val_acc": 50.0, "val_auroc": 0.5, "time": 217.65}
{"epoch": 15, "training_loss": 55.2313232421875, "training_acc": 53.75, "val_loss": 13.888965845108032, "val_acc": 50.0, "val_auroc": 0.51, "time": 232.15}
{"epoch": 16, "training_loss": 55.03896427154541, "training_acc": 52.5, "val_loss": 13.996436595916748, "val_acc": 50.0, "val_auroc": 0.56, "time": 246.36}
{"epoch": 17, "training_loss": 55.30790615081787, "training_acc": 52.5, "val_loss": 14.063924551010132, "val_acc": 50.0, "val_auroc": 0.67, "time": 262.59}
{"epoch": 18, "training_loss": 55.20071029663086, "training_acc": 52.5, "val_loss": 13.921595811843872, "val_acc": 50.0, "val_auroc": 0.64, "time": 276.78}
{"epoch": 19, "training_loss": 54.78345966339111, "training_acc": 52.5, "val_loss": 13.837788105010986, "val_acc": 50.0, "val_auroc": 0.69, "time": 291.41}
