"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.560301780700684, "training_acc": 52.5, "val_loss": 13.921785354614258, "val_acc": 50.0, "val_auroc": 0.34, "time": 20.79}
{"epoch": 1, "training_loss": 55.30015563964844, "training_acc": 52.5, "val_loss": 13.83162260055542, "val_acc": 50.0, "val_auroc": 0.58, "time": 36.09}
{"epoch": 2, "training_loss": 55.21244239807129, "training_acc": 52.5, "val_loss": 13.85496973991394, "val_acc": 50.0, "val_auroc": 0.53, "time": 51.29}
{"epoch": 3, "training_loss": 55.279099464416504, "training_acc": 52.5, "val_loss": 13.893390893936157, "val_acc": 50.0, "val_auroc": 0.52, "time": 66.18}
{"epoch": 4, "training_loss": 55.12151622772217, "training_acc": 52.5, "val_loss": 13.865410089492798, "val_acc": 50.0, "val_auroc": 0.53, "time": 80.8}
{"epoch": 5, "training_loss": 54.99367809295654, "training_acc": 52.5, "val_loss": 13.868073225021362, "val_acc": 50.0, "val_auroc": 0.49, "time": 95.33}
{"epoch": 6, "training_loss": 54.97218322753906, "training_acc": 67.5, "val_loss": 13.835657835006714, "val_acc": 50.0, "val_auroc": 0.59, "time": 110.06}
{"epoch": 7, "training_loss": 55.007513999938965, "training_acc": 53.75, "val_loss": 13.837312459945679, "val_acc": 50.0, "val_auroc": 0.56, "time": 124.66}
{"epoch": 8, "training_loss": 54.62078285217285, "training_acc": 58.75, "val_loss": 13.892358541488647, "val_acc": 50.0, "val_auroc": 0.44, "time": 139.61}
{"epoch": 9, "training_loss": 54.77682685852051, "training_acc": 56.25, "val_loss": 13.848819732666016, "val_acc": 50.0, "val_auroc": 0.55, "time": 155.74}
{"epoch": 10, "training_loss": 54.172356605529785, "training_acc": 55.0, "val_loss": 13.782140016555786, "val_acc": 50.0, "val_auroc": 0.6, "time": 170.78}
{"epoch": 11, "training_loss": 53.809396743774414, "training_acc": 71.25, "val_loss": 14.053281545639038, "val_acc": 50.0, "val_auroc": 0.5, "time": 185.32}
{"epoch": 12, "training_loss": 54.86068916320801, "training_acc": 52.5, "val_loss": 14.09140944480896, "val_acc": 50.0, "val_auroc": 0.58, "time": 199.61}
{"epoch": 13, "training_loss": 55.43817138671875, "training_acc": 52.5, "val_loss": 14.0426504611969, "val_acc": 50.0, "val_auroc": 0.61, "time": 214.43}
{"epoch": 14, "training_loss": 55.201826095581055, "training_acc": 52.5, "val_loss": 14.0869140625, "val_acc": 50.0, "val_auroc": 0.53, "time": 228.69}
{"epoch": 15, "training_loss": 54.76760005950928, "training_acc": 52.5, "val_loss": 14.074662923812866, "val_acc": 50.0, "val_auroc": 0.52, "time": 243.17}
{"epoch": 16, "training_loss": 54.33419227600098, "training_acc": 52.5, "val_loss": 13.911608457565308, "val_acc": 50.0, "val_auroc": 0.52, "time": 257.35}
{"epoch": 17, "training_loss": 53.5279655456543, "training_acc": 52.5, "val_loss": 13.821413516998291, "val_acc": 50.0, "val_auroc": 0.54, "time": 271.89}
{"epoch": 18, "training_loss": 52.64399814605713, "training_acc": 66.25, "val_loss": 13.8480544090271, "val_acc": 50.0, "val_auroc": 0.57, "time": 286.46}
{"epoch": 19, "training_loss": 51.30546569824219, "training_acc": 66.25, "val_loss": 13.920713663101196, "val_acc": 50.0, "val_auroc": 0.33, "time": 301.2}
{"epoch": 20, "training_loss": 56.02563285827637, "training_acc": 37.5, "val_loss": 13.879151344299316, "val_acc": 50.0, "val_auroc": 0.2, "time": 315.64}
{"epoch": 21, "training_loss": 55.4857234954834, "training_acc": 47.5, "val_loss": 13.878182172775269, "val_acc": 50.0, "val_auroc": 0.35, "time": 330.19}
{"epoch": 22, "training_loss": 55.277462005615234, "training_acc": 52.5, "val_loss": 13.938082456588745, "val_acc": 50.0, "val_auroc": 0.5, "time": 344.52}
{"epoch": 23, "training_loss": 55.412851333618164, "training_acc": 52.5, "val_loss": 13.974390029907227, "val_acc": 50.0, "val_auroc": 0.51, "time": 359.29}
{"epoch": 24, "training_loss": 55.432106018066406, "training_acc": 52.5, "val_loss": 13.911718130111694, "val_acc": 50.0, "val_auroc": 0.5, "time": 373.56}
{"epoch": 25, "training_loss": 55.315040588378906, "training_acc": 52.5, "val_loss": 13.872733116149902, "val_acc": 50.0, "val_auroc": 0.43, "time": 388.34}
{"epoch": 26, "training_loss": 55.372610092163086, "training_acc": 52.5, "val_loss": 13.869496583938599, "val_acc": 50.0, "val_auroc": 0.47, "time": 402.71}
{"epoch": 27, "training_loss": 55.38211917877197, "training_acc": 52.5, "val_loss": 13.886995315551758, "val_acc": 50.0, "val_auroc": 0.45, "time": 417.18}
{"epoch": 28, "training_loss": 55.492581367492676, "training_acc": 52.5, "val_loss": 13.910895586013794, "val_acc": 50.0, "val_auroc": 0.44, "time": 432.03}
{"epoch": 29, "training_loss": 55.34114742279053, "training_acc": 52.5, "val_loss": 13.888438940048218, "val_acc": 50.0, "val_auroc": 0.5, "time": 446.28}
