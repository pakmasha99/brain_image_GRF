"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.50204277038574, "training_acc": 52.5, "val_loss": 13.915283679962158, "val_acc": 50.0, "val_auroc": 0.48, "time": 17.31}
{"epoch": 1, "training_loss": 55.46067237854004, "training_acc": 52.5, "val_loss": 13.919060230255127, "val_acc": 50.0, "val_auroc": 0.38, "time": 32.21}
{"epoch": 2, "training_loss": 55.33388805389404, "training_acc": 52.5, "val_loss": 13.884146213531494, "val_acc": 50.0, "val_auroc": 0.45, "time": 47.31}
{"epoch": 3, "training_loss": 55.22590637207031, "training_acc": 52.5, "val_loss": 13.845373392105103, "val_acc": 50.0, "val_auroc": 0.55, "time": 62.0}
{"epoch": 4, "training_loss": 55.27387046813965, "training_acc": 52.5, "val_loss": 13.87967586517334, "val_acc": 50.0, "val_auroc": 0.5, "time": 76.57}
{"epoch": 5, "training_loss": 55.224578857421875, "training_acc": 52.5, "val_loss": 13.8571035861969, "val_acc": 50.0, "val_auroc": 0.53, "time": 90.96}
{"epoch": 6, "training_loss": 55.301011085510254, "training_acc": 52.5, "val_loss": 13.870563507080078, "val_acc": 50.0, "val_auroc": 0.6, "time": 105.23}
{"epoch": 7, "training_loss": 55.19974613189697, "training_acc": 52.5, "val_loss": 13.885291814804077, "val_acc": 50.0, "val_auroc": 0.61, "time": 119.48}
{"epoch": 8, "training_loss": 54.97420406341553, "training_acc": 52.5, "val_loss": 13.876451253890991, "val_acc": 50.0, "val_auroc": 0.58, "time": 133.37}
{"epoch": 9, "training_loss": 55.002315521240234, "training_acc": 52.5, "val_loss": 13.834270238876343, "val_acc": 50.0, "val_auroc": 0.64, "time": 148.36}
{"epoch": 10, "training_loss": 54.96006965637207, "training_acc": 52.5, "val_loss": 13.827362060546875, "val_acc": 50.0, "val_auroc": 0.65, "time": 162.97}
{"epoch": 11, "training_loss": 54.862396240234375, "training_acc": 53.75, "val_loss": 13.808242082595825, "val_acc": 50.0, "val_auroc": 0.66, "time": 177.74}
{"epoch": 12, "training_loss": 54.76628303527832, "training_acc": 52.5, "val_loss": 13.801794052124023, "val_acc": 50.0, "val_auroc": 0.82, "time": 192.26}
{"epoch": 13, "training_loss": 54.654829025268555, "training_acc": 52.5, "val_loss": 13.783682584762573, "val_acc": 50.0, "val_auroc": 0.91, "time": 207.2}
{"epoch": 14, "training_loss": 54.7300910949707, "training_acc": 52.5, "val_loss": 13.833426237106323, "val_acc": 50.0, "val_auroc": 0.86, "time": 221.63}
{"epoch": 15, "training_loss": 54.60435104370117, "training_acc": 52.5, "val_loss": 13.889459371566772, "val_acc": 50.0, "val_auroc": 0.81, "time": 237.85}
{"epoch": 16, "training_loss": 54.85494613647461, "training_acc": 52.5, "val_loss": 13.869131803512573, "val_acc": 50.0, "val_auroc": 0.65, "time": 252.21}
{"epoch": 17, "training_loss": 54.3867826461792, "training_acc": 52.5, "val_loss": 13.779815435409546, "val_acc": 50.0, "val_auroc": 0.63, "time": 266.69}
{"epoch": 18, "training_loss": 54.11833572387695, "training_acc": 52.5, "val_loss": 13.70776891708374, "val_acc": 50.0, "val_auroc": 0.67, "time": 281.14}
{"epoch": 19, "training_loss": 53.90049743652344, "training_acc": 55.0, "val_loss": 13.655869960784912, "val_acc": 50.0, "val_auroc": 0.68, "time": 295.69}
{"epoch": 20, "training_loss": 53.89517593383789, "training_acc": 72.5, "val_loss": 13.596923351287842, "val_acc": 50.0, "val_auroc": 0.73, "time": 310.2}
{"epoch": 21, "training_loss": 53.38557052612305, "training_acc": 70.0, "val_loss": 13.698662519454956, "val_acc": 50.0, "val_auroc": 0.84, "time": 324.32}
{"epoch": 22, "training_loss": 53.82869911193848, "training_acc": 52.5, "val_loss": 13.64317774772644, "val_acc": 50.0, "val_auroc": 0.87, "time": 338.56}
{"epoch": 23, "training_loss": 53.49828338623047, "training_acc": 55.0, "val_loss": 13.519786596298218, "val_acc": 50.0, "val_auroc": 0.85, "time": 352.85}
{"epoch": 24, "training_loss": 52.428290367126465, "training_acc": 77.5, "val_loss": 13.644242286682129, "val_acc": 50.0, "val_auroc": 0.87, "time": 366.93}
{"epoch": 25, "training_loss": 52.72179698944092, "training_acc": 53.75, "val_loss": 13.515112400054932, "val_acc": 50.0, "val_auroc": 0.81, "time": 381.42}
{"epoch": 26, "training_loss": 52.795002937316895, "training_acc": 80.0, "val_loss": 13.651115894317627, "val_acc": 50.0, "val_auroc": 0.81, "time": 395.41}
{"epoch": 27, "training_loss": 52.025550842285156, "training_acc": 53.75, "val_loss": 13.316748142242432, "val_acc": 50.0, "val_auroc": 0.8, "time": 409.79}
{"epoch": 28, "training_loss": 50.22837734222412, "training_acc": 81.25, "val_loss": 13.789770603179932, "val_acc": 50.0, "val_auroc": 0.72, "time": 424.3}
{"epoch": 29, "training_loss": 52.797725677490234, "training_acc": 65.0, "val_loss": 13.792444467544556, "val_acc": 50.0, "val_auroc": 0.81, "time": 438.74}
{"epoch": 30, "training_loss": 52.439486503601074, "training_acc": 52.5, "val_loss": 13.405935764312744, "val_acc": 50.0, "val_auroc": 0.85, "time": 453.07}
{"epoch": 31, "training_loss": 50.76845455169678, "training_acc": 63.75, "val_loss": 13.263072967529297, "val_acc": 50.0, "val_auroc": 0.82, "time": 467.75}
{"epoch": 32, "training_loss": 49.826303482055664, "training_acc": 81.25, "val_loss": 13.206751346588135, "val_acc": 50.0, "val_auroc": 0.87, "time": 482.3}
{"epoch": 33, "training_loss": 49.28578281402588, "training_acc": 85.0, "val_loss": 13.576520681381226, "val_acc": 50.0, "val_auroc": 0.82, "time": 496.61}
{"epoch": 34, "training_loss": 51.15439224243164, "training_acc": 60.0, "val_loss": 12.970273494720459, "val_acc": 50.0, "val_auroc": 0.88, "time": 511.69}
{"epoch": 35, "training_loss": 48.6915979385376, "training_acc": 85.0, "val_loss": 13.788094520568848, "val_acc": 55.0, "val_auroc": 0.83, "time": 526.34}
{"epoch": 36, "training_loss": 51.38433265686035, "training_acc": 62.5, "val_loss": 12.805979251861572, "val_acc": 50.0, "val_auroc": 0.86, "time": 544.12}
{"epoch": 37, "training_loss": 46.48569869995117, "training_acc": 87.5, "val_loss": 12.588952779769897, "val_acc": 55.0, "val_auroc": 0.88, "time": 559.86}
{"epoch": 38, "training_loss": 44.13854789733887, "training_acc": 87.5, "val_loss": 12.083965539932251, "val_acc": 50.0, "val_auroc": 0.88, "time": 575.81}
{"epoch": 39, "training_loss": 42.79005241394043, "training_acc": 91.25, "val_loss": 13.078304529190063, "val_acc": 80.0, "val_auroc": 0.87, "time": 591.23}
{"epoch": 40, "training_loss": 44.4461727142334, "training_acc": 83.75, "val_loss": 12.06873893737793, "val_acc": 75.0, "val_auroc": 0.86, "time": 607.02}
{"epoch": 41, "training_loss": 39.39447784423828, "training_acc": 93.75, "val_loss": 13.071991205215454, "val_acc": 75.0, "val_auroc": 0.81, "time": 622.59}
{"epoch": 42, "training_loss": 41.6649227142334, "training_acc": 82.5, "val_loss": 11.734884977340698, "val_acc": 60.0, "val_auroc": 0.82, "time": 638.96}
{"epoch": 43, "training_loss": 38.81338119506836, "training_acc": 91.25, "val_loss": 11.72771692276001, "val_acc": 55.0, "val_auroc": 0.87, "time": 655.06}
{"epoch": 44, "training_loss": 38.45146369934082, "training_acc": 87.5, "val_loss": 12.473043203353882, "val_acc": 85.0, "val_auroc": 0.87, "time": 670.92}
{"epoch": 45, "training_loss": 37.783886432647705, "training_acc": 95.0, "val_loss": 12.429962158203125, "val_acc": 50.0, "val_auroc": 0.84, "time": 686.94}
{"epoch": 46, "training_loss": 38.897117614746094, "training_acc": 85.0, "val_loss": 13.968770503997803, "val_acc": 65.0, "val_auroc": 0.87, "time": 702.81}
{"epoch": 47, "training_loss": 38.7772102355957, "training_acc": 90.0, "val_loss": 12.42779016494751, "val_acc": 50.0, "val_auroc": 0.86, "time": 718.99}
{"epoch": 48, "training_loss": 38.63468647003174, "training_acc": 83.75, "val_loss": 11.556727886199951, "val_acc": 85.0, "val_auroc": 0.86, "time": 735.37}
{"epoch": 49, "training_loss": 30.91122007369995, "training_acc": 100.0, "val_loss": 11.576738357543945, "val_acc": 80.0, "val_auroc": 0.86, "time": 751.24}
{"epoch": 50, "training_loss": 29.904013633728027, "training_acc": 98.75, "val_loss": 11.12001895904541, "val_acc": 80.0, "val_auroc": 0.86, "time": 767.95}
{"epoch": 51, "training_loss": 28.727396965026855, "training_acc": 98.75, "val_loss": 10.731687545776367, "val_acc": 80.0, "val_auroc": 0.85, "time": 784.19}
{"epoch": 52, "training_loss": 28.65156078338623, "training_acc": 100.0, "val_loss": 10.953304767608643, "val_acc": 70.0, "val_auroc": 0.82, "time": 800.18}
{"epoch": 53, "training_loss": 28.135112762451172, "training_acc": 98.75, "val_loss": 11.677120923995972, "val_acc": 85.0, "val_auroc": 0.82, "time": 816.14}
{"epoch": 54, "training_loss": 26.224188327789307, "training_acc": 100.0, "val_loss": 10.972985029220581, "val_acc": 60.0, "val_auroc": 0.82, "time": 832.03}
{"epoch": 55, "training_loss": 26.82468891143799, "training_acc": 100.0, "val_loss": 11.443365812301636, "val_acc": 85.0, "val_auroc": 0.85, "time": 849.44}
{"epoch": 56, "training_loss": 25.23917579650879, "training_acc": 98.75, "val_loss": 11.88922643661499, "val_acc": 55.0, "val_auroc": 0.83, "time": 865.33}
{"epoch": 57, "training_loss": 29.61177921295166, "training_acc": 93.75, "val_loss": 13.516075611114502, "val_acc": 60.0, "val_auroc": 0.81, "time": 881.21}
{"epoch": 58, "training_loss": 26.154349327087402, "training_acc": 98.75, "val_loss": 10.662387609481812, "val_acc": 65.0, "val_auroc": 0.84, "time": 897.25}
{"epoch": 59, "training_loss": 26.205048084259033, "training_acc": 97.5, "val_loss": 12.388359308242798, "val_acc": 80.0, "val_auroc": 0.82, "time": 913.11}
