"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.67824077606201, "training_acc": 52.5, "val_loss": 13.964096307754517, "val_acc": 50.0, "val_auroc": 0.42, "time": 20.26}
{"epoch": 1, "training_loss": 55.41618251800537, "training_acc": 52.5, "val_loss": 13.91703486442566, "val_acc": 50.0, "val_auroc": 0.45, "time": 38.6}
{"epoch": 2, "training_loss": 55.4259557723999, "training_acc": 52.5, "val_loss": 13.926796913146973, "val_acc": 50.0, "val_auroc": 0.41, "time": 56.69}
{"epoch": 3, "training_loss": 55.49757480621338, "training_acc": 52.5, "val_loss": 13.981175422668457, "val_acc": 50.0, "val_auroc": 0.4, "time": 74.53}
{"epoch": 4, "training_loss": 55.45077705383301, "training_acc": 52.5, "val_loss": 13.917081356048584, "val_acc": 50.0, "val_auroc": 0.49, "time": 92.04}
{"epoch": 5, "training_loss": 55.39865207672119, "training_acc": 52.5, "val_loss": 13.891656398773193, "val_acc": 50.0, "val_auroc": 0.5, "time": 110.22}
{"epoch": 6, "training_loss": 55.451202392578125, "training_acc": 52.5, "val_loss": 13.971909284591675, "val_acc": 50.0, "val_auroc": 0.67, "time": 127.5}
{"epoch": 7, "training_loss": 55.463165283203125, "training_acc": 52.5, "val_loss": 14.05269980430603, "val_acc": 50.0, "val_auroc": 0.66, "time": 144.08}
{"epoch": 8, "training_loss": 55.70957946777344, "training_acc": 52.5, "val_loss": 13.928297758102417, "val_acc": 50.0, "val_auroc": 0.68, "time": 161.53}
{"epoch": 9, "training_loss": 55.3414945602417, "training_acc": 52.5, "val_loss": 13.861944675445557, "val_acc": 50.0, "val_auroc": 0.7, "time": 179.11}
{"epoch": 10, "training_loss": 55.47970771789551, "training_acc": 51.25, "val_loss": 13.86387825012207, "val_acc": 50.0, "val_auroc": 0.53, "time": 195.79}
{"epoch": 11, "training_loss": 55.40439319610596, "training_acc": 55.0, "val_loss": 13.893026113510132, "val_acc": 50.0, "val_auroc": 0.55, "time": 213.35}
{"epoch": 12, "training_loss": 55.387375831604004, "training_acc": 52.5, "val_loss": 13.952749967575073, "val_acc": 50.0, "val_auroc": 0.25, "time": 230.83}
{"epoch": 13, "training_loss": 55.427677154541016, "training_acc": 52.5, "val_loss": 13.923492431640625, "val_acc": 50.0, "val_auroc": 0.61, "time": 248.48}
{"epoch": 14, "training_loss": 55.36401176452637, "training_acc": 52.5, "val_loss": 13.879140615463257, "val_acc": 50.0, "val_auroc": 0.55, "time": 265.84}
{"epoch": 15, "training_loss": 55.50707244873047, "training_acc": 52.5, "val_loss": 13.882766962051392, "val_acc": 50.0, "val_auroc": 0.64, "time": 283.72}
{"epoch": 16, "training_loss": 55.27082443237305, "training_acc": 52.5, "val_loss": 13.9763343334198, "val_acc": 50.0, "val_auroc": 0.71, "time": 301.11}
{"epoch": 17, "training_loss": 55.53692436218262, "training_acc": 52.5, "val_loss": 14.065674543380737, "val_acc": 50.0, "val_auroc": 0.83, "time": 318.24}
{"epoch": 18, "training_loss": 55.69400215148926, "training_acc": 52.5, "val_loss": 13.99214506149292, "val_acc": 50.0, "val_auroc": 0.61, "time": 335.88}
{"epoch": 19, "training_loss": 55.41969013214111, "training_acc": 52.5, "val_loss": 13.885856866836548, "val_acc": 50.0, "val_auroc": 0.28, "time": 353.62}
{"epoch": 20, "training_loss": 55.40109825134277, "training_acc": 52.5, "val_loss": 13.866089582443237, "val_acc": 50.0, "val_auroc": 0.19, "time": 370.95}
{"epoch": 21, "training_loss": 55.474239349365234, "training_acc": 47.5, "val_loss": 13.865891695022583, "val_acc": 50.0, "val_auroc": 0.18, "time": 388.28}
{"epoch": 22, "training_loss": 55.4321928024292, "training_acc": 50.0, "val_loss": 13.87605905532837, "val_acc": 50.0, "val_auroc": 0.23, "time": 405.29}
{"epoch": 23, "training_loss": 55.30312156677246, "training_acc": 52.5, "val_loss": 13.927257061004639, "val_acc": 50.0, "val_auroc": 0.43, "time": 422.65}
{"epoch": 24, "training_loss": 55.33733367919922, "training_acc": 52.5, "val_loss": 14.020081758499146, "val_acc": 50.0, "val_auroc": 0.76, "time": 440.02}
{"epoch": 25, "training_loss": 55.58385753631592, "training_acc": 52.5, "val_loss": 14.076699018478394, "val_acc": 50.0, "val_auroc": 0.74, "time": 457.47}
{"epoch": 26, "training_loss": 55.77797508239746, "training_acc": 52.5, "val_loss": 14.08421516418457, "val_acc": 50.0, "val_auroc": 0.67, "time": 474.62}
{"epoch": 27, "training_loss": 55.73798084259033, "training_acc": 52.5, "val_loss": 14.082403182983398, "val_acc": 50.0, "val_auroc": 0.62, "time": 492.04}
{"epoch": 28, "training_loss": 55.73529815673828, "training_acc": 52.5, "val_loss": 13.964284658432007, "val_acc": 50.0, "val_auroc": 0.59, "time": 509.3}
