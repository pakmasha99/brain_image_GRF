"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.598703384399414, "training_acc": 52.5, "val_loss": 13.868554830551147, "val_acc": 50.0, "val_auroc": 0.46, "time": 20.23}
{"epoch": 1, "training_loss": 55.37992477416992, "training_acc": 52.5, "val_loss": 13.97859811782837, "val_acc": 50.0, "val_auroc": 0.48, "time": 38.81}
{"epoch": 2, "training_loss": 55.565497398376465, "training_acc": 52.5, "val_loss": 13.911789655685425, "val_acc": 50.0, "val_auroc": 0.58, "time": 56.84}
{"epoch": 3, "training_loss": 55.28218364715576, "training_acc": 52.5, "val_loss": 13.869785070419312, "val_acc": 50.0, "val_auroc": 0.57, "time": 75.04}
{"epoch": 4, "training_loss": 55.37264060974121, "training_acc": 52.5, "val_loss": 13.865824937820435, "val_acc": 50.0, "val_auroc": 0.32, "time": 92.85}
{"epoch": 5, "training_loss": 55.39079284667969, "training_acc": 52.5, "val_loss": 13.899474143981934, "val_acc": 50.0, "val_auroc": 0.47, "time": 110.25}
{"epoch": 6, "training_loss": 55.37876510620117, "training_acc": 52.5, "val_loss": 13.909605741500854, "val_acc": 50.0, "val_auroc": 0.5, "time": 127.98}
{"epoch": 7, "training_loss": 55.390790939331055, "training_acc": 52.5, "val_loss": 13.889020681381226, "val_acc": 50.0, "val_auroc": 0.66, "time": 145.35}
{"epoch": 8, "training_loss": 55.358641624450684, "training_acc": 52.5, "val_loss": 13.887516260147095, "val_acc": 50.0, "val_auroc": 0.6, "time": 162.55}
{"epoch": 9, "training_loss": 55.36419486999512, "training_acc": 52.5, "val_loss": 13.86467695236206, "val_acc": 50.0, "val_auroc": 0.52, "time": 180.41}
{"epoch": 10, "training_loss": 55.47295665740967, "training_acc": 50.0, "val_loss": 13.861972093582153, "val_acc": 50.0, "val_auroc": 0.58, "time": 198.5}
{"epoch": 11, "training_loss": 55.41137886047363, "training_acc": 50.0, "val_loss": 13.89541506767273, "val_acc": 50.0, "val_auroc": 0.62, "time": 215.86}
{"epoch": 12, "training_loss": 55.326528549194336, "training_acc": 52.5, "val_loss": 13.980401754379272, "val_acc": 50.0, "val_auroc": 0.71, "time": 233.54}
{"epoch": 13, "training_loss": 55.49992561340332, "training_acc": 52.5, "val_loss": 14.041807651519775, "val_acc": 50.0, "val_auroc": 0.71, "time": 251.08}
{"epoch": 14, "training_loss": 55.68588733673096, "training_acc": 52.5, "val_loss": 14.112386703491211, "val_acc": 50.0, "val_auroc": 0.62, "time": 268.36}
{"epoch": 15, "training_loss": 55.81241798400879, "training_acc": 52.5, "val_loss": 14.169257879257202, "val_acc": 50.0, "val_auroc": 0.65, "time": 285.62}
{"epoch": 16, "training_loss": 55.99432945251465, "training_acc": 52.5, "val_loss": 14.120352268218994, "val_acc": 50.0, "val_auroc": 0.6, "time": 301.23}
{"epoch": 17, "training_loss": 55.79116916656494, "training_acc": 52.5, "val_loss": 13.968371152877808, "val_acc": 50.0, "val_auroc": 0.64, "time": 318.19}
{"epoch": 18, "training_loss": 55.40303039550781, "training_acc": 52.5, "val_loss": 13.864017724990845, "val_acc": 50.0, "val_auroc": 0.61, "time": 335.38}
{"epoch": 19, "training_loss": 55.33171272277832, "training_acc": 57.5, "val_loss": 13.885682821273804, "val_acc": 50.0, "val_auroc": 0.74, "time": 351.72}
{"epoch": 20, "training_loss": 55.76487636566162, "training_acc": 47.5, "val_loss": 13.913557529449463, "val_acc": 50.0, "val_auroc": 0.73, "time": 369.06}
{"epoch": 21, "training_loss": 55.91726779937744, "training_acc": 47.5, "val_loss": 13.865145444869995, "val_acc": 50.0, "val_auroc": 0.64, "time": 386.18}
{"epoch": 22, "training_loss": 55.45923137664795, "training_acc": 50.0, "val_loss": 13.905891180038452, "val_acc": 50.0, "val_auroc": 0.59, "time": 403.65}
{"epoch": 23, "training_loss": 55.29399871826172, "training_acc": 52.5, "val_loss": 14.024510383605957, "val_acc": 50.0, "val_auroc": 0.59, "time": 420.87}
{"epoch": 24, "training_loss": 55.59085464477539, "training_acc": 52.5, "val_loss": 14.086068868637085, "val_acc": 50.0, "val_auroc": 0.6, "time": 437.8}
{"epoch": 25, "training_loss": 55.73754119873047, "training_acc": 52.5, "val_loss": 14.031847715377808, "val_acc": 50.0, "val_auroc": 0.66, "time": 455.0}
{"epoch": 26, "training_loss": 55.60930633544922, "training_acc": 52.5, "val_loss": 13.950647115707397, "val_acc": 50.0, "val_auroc": 0.7, "time": 471.81}
{"epoch": 27, "training_loss": 55.441450119018555, "training_acc": 52.5, "val_loss": 13.903664350509644, "val_acc": 50.0, "val_auroc": 0.63, "time": 489.33}
{"epoch": 28, "training_loss": 55.39974594116211, "training_acc": 52.5, "val_loss": 13.867292404174805, "val_acc": 50.0, "val_auroc": 0.62, "time": 506.63}
{"epoch": 29, "training_loss": 55.44821834564209, "training_acc": 50.0, "val_loss": 13.867820501327515, "val_acc": 50.0, "val_auroc": 0.64, "time": 523.9}
