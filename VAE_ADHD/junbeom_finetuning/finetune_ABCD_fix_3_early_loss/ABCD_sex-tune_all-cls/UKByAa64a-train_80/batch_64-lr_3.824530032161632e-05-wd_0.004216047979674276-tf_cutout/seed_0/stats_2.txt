"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.410573959350586, "training_acc": 52.5, "val_loss": 13.86964201927185, "val_acc": 50.0, "val_auroc": 0.55, "time": 19.71}
{"epoch": 1, "training_loss": 55.31139373779297, "training_acc": 52.5, "val_loss": 13.876138925552368, "val_acc": 50.0, "val_auroc": 0.51, "time": 37.59}
{"epoch": 2, "training_loss": 55.267757415771484, "training_acc": 52.5, "val_loss": 13.860524892807007, "val_acc": 50.0, "val_auroc": 0.49, "time": 56.01}
{"epoch": 3, "training_loss": 55.235748291015625, "training_acc": 52.5, "val_loss": 13.85113000869751, "val_acc": 50.0, "val_auroc": 0.52, "time": 80.26}
{"epoch": 4, "training_loss": 55.3260383605957, "training_acc": 52.5, "val_loss": 13.919275999069214, "val_acc": 50.0, "val_auroc": 0.45, "time": 98.53}
{"epoch": 5, "training_loss": 54.85005283355713, "training_acc": 52.5, "val_loss": 13.929044008255005, "val_acc": 50.0, "val_auroc": 0.42, "time": 118.39}
{"epoch": 6, "training_loss": 54.72217273712158, "training_acc": 52.5, "val_loss": 13.986812829971313, "val_acc": 50.0, "val_auroc": 0.39, "time": 136.92}
{"epoch": 7, "training_loss": 55.18655014038086, "training_acc": 52.5, "val_loss": 13.973487615585327, "val_acc": 50.0, "val_auroc": 0.42, "time": 157.55}
{"epoch": 8, "training_loss": 55.225534439086914, "training_acc": 52.5, "val_loss": 14.013503789901733, "val_acc": 50.0, "val_auroc": 0.23, "time": 173.92}
{"epoch": 9, "training_loss": 55.016672134399414, "training_acc": 52.5, "val_loss": 13.9412522315979, "val_acc": 50.0, "val_auroc": 0.4, "time": 190.95}
{"epoch": 10, "training_loss": 54.92496871948242, "training_acc": 52.5, "val_loss": 13.939540386199951, "val_acc": 50.0, "val_auroc": 0.37, "time": 208.86}
{"epoch": 11, "training_loss": 54.654239654541016, "training_acc": 52.5, "val_loss": 14.018588066101074, "val_acc": 50.0, "val_auroc": 0.29, "time": 227.86}
{"epoch": 12, "training_loss": 54.48404502868652, "training_acc": 52.5, "val_loss": 14.008654356002808, "val_acc": 50.0, "val_auroc": 0.29, "time": 246.16}
{"epoch": 13, "training_loss": 54.49783134460449, "training_acc": 52.5, "val_loss": 13.988600969314575, "val_acc": 50.0, "val_auroc": 0.38, "time": 264.25}
{"epoch": 14, "training_loss": 53.79299831390381, "training_acc": 53.75, "val_loss": 14.003374576568604, "val_acc": 50.0, "val_auroc": 0.38, "time": 281.22}
{"epoch": 15, "training_loss": 53.83887481689453, "training_acc": 60.0, "val_loss": 14.037554264068604, "val_acc": 50.0, "val_auroc": 0.4, "time": 299.23}
{"epoch": 16, "training_loss": 53.571510314941406, "training_acc": 52.5, "val_loss": 14.14253830909729, "val_acc": 50.0, "val_auroc": 0.39, "time": 315.9}
{"epoch": 17, "training_loss": 53.56216049194336, "training_acc": 52.5, "val_loss": 13.975800275802612, "val_acc": 50.0, "val_auroc": 0.32, "time": 333.01}
{"epoch": 18, "training_loss": 53.79755973815918, "training_acc": 67.5, "val_loss": 13.985992670059204, "val_acc": 50.0, "val_auroc": 0.4, "time": 350.18}
{"epoch": 19, "training_loss": 52.84527111053467, "training_acc": 66.25, "val_loss": 14.000747203826904, "val_acc": 50.0, "val_auroc": 0.47, "time": 367.34}
{"epoch": 20, "training_loss": 53.149831771850586, "training_acc": 55.0, "val_loss": 13.91815185546875, "val_acc": 50.0, "val_auroc": 0.44, "time": 384.97}
{"epoch": 21, "training_loss": 52.47842597961426, "training_acc": 80.0, "val_loss": 13.970708847045898, "val_acc": 50.0, "val_auroc": 0.47, "time": 402.38}
{"epoch": 22, "training_loss": 51.48150634765625, "training_acc": 68.75, "val_loss": 13.954733610153198, "val_acc": 50.0, "val_auroc": 0.5, "time": 419.25}
