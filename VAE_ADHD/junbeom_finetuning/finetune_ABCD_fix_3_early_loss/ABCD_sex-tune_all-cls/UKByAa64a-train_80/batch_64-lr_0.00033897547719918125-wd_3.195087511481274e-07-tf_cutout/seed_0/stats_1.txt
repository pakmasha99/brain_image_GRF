"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.02466011047363, "training_acc": 52.5, "val_loss": 15.001821517944336, "val_acc": 50.0, "val_auroc": 0.64, "time": 19.62}
{"epoch": 1, "training_loss": 64.9752426147461, "training_acc": 52.5, "val_loss": 13.936090469360352, "val_acc": 50.0, "val_auroc": 0.64, "time": 37.84}
{"epoch": 2, "training_loss": 55.85770797729492, "training_acc": 50.0, "val_loss": 16.37926697731018, "val_acc": 50.0, "val_auroc": 0.53, "time": 55.4}
{"epoch": 3, "training_loss": 64.94561004638672, "training_acc": 52.5, "val_loss": 13.97036075592041, "val_acc": 50.0, "val_auroc": 0.62, "time": 72.76}
{"epoch": 4, "training_loss": 56.205477714538574, "training_acc": 47.5, "val_loss": 13.875457048416138, "val_acc": 50.0, "val_auroc": 0.64, "time": 90.19}
{"epoch": 5, "training_loss": 55.29513645172119, "training_acc": 52.5, "val_loss": 14.082491397857666, "val_acc": 50.0, "val_auroc": 0.63, "time": 107.58}
{"epoch": 6, "training_loss": 55.59086894989014, "training_acc": 52.5, "val_loss": 13.940969705581665, "val_acc": 50.0, "val_auroc": 0.58, "time": 124.66}
{"epoch": 7, "training_loss": 55.748849868774414, "training_acc": 50.0, "val_loss": 14.58823561668396, "val_acc": 50.0, "val_auroc": 0.55, "time": 141.57}
{"epoch": 8, "training_loss": 56.68776607513428, "training_acc": 52.5, "val_loss": 14.226305484771729, "val_acc": 50.0, "val_auroc": 0.5, "time": 158.78}
{"epoch": 9, "training_loss": 57.622361183166504, "training_acc": 45.0, "val_loss": 13.874597549438477, "val_acc": 50.0, "val_auroc": 0.54, "time": 176.39}
{"epoch": 10, "training_loss": 55.282344818115234, "training_acc": 52.5, "val_loss": 13.914687633514404, "val_acc": 50.0, "val_auroc": 0.55, "time": 193.32}
{"epoch": 11, "training_loss": 55.36624336242676, "training_acc": 52.5, "val_loss": 13.918169736862183, "val_acc": 50.0, "val_auroc": 0.62, "time": 209.43}
{"epoch": 12, "training_loss": 55.37471389770508, "training_acc": 52.5, "val_loss": 13.89722466468811, "val_acc": 50.0, "val_auroc": 0.63, "time": 225.57}
{"epoch": 13, "training_loss": 55.4094352722168, "training_acc": 52.5, "val_loss": 13.954641819000244, "val_acc": 50.0, "val_auroc": 0.6, "time": 242.33}
{"epoch": 14, "training_loss": 55.506553649902344, "training_acc": 52.5, "val_loss": 14.209431409835815, "val_acc": 50.0, "val_auroc": 0.62, "time": 259.01}
{"epoch": 15, "training_loss": 56.107919692993164, "training_acc": 52.5, "val_loss": 14.342232942581177, "val_acc": 50.0, "val_auroc": 0.64, "time": 274.35}
{"epoch": 16, "training_loss": 56.56868362426758, "training_acc": 52.5, "val_loss": 14.086323976516724, "val_acc": 50.0, "val_auroc": 0.62, "time": 291.3}
{"epoch": 17, "training_loss": 55.604360580444336, "training_acc": 52.5, "val_loss": 13.847899436950684, "val_acc": 50.0, "val_auroc": 0.59, "time": 308.64}
{"epoch": 18, "training_loss": 55.306288719177246, "training_acc": 52.5, "val_loss": 13.924305438995361, "val_acc": 50.0, "val_auroc": 0.59, "time": 325.17}
{"epoch": 19, "training_loss": 56.073134422302246, "training_acc": 47.5, "val_loss": 13.91850233078003, "val_acc": 50.0, "val_auroc": 0.56, "time": 341.98}
{"epoch": 20, "training_loss": 55.94685363769531, "training_acc": 47.5, "val_loss": 13.874677419662476, "val_acc": 50.0, "val_auroc": 0.58, "time": 359.05}
{"epoch": 21, "training_loss": 55.557101249694824, "training_acc": 47.5, "val_loss": 13.866679668426514, "val_acc": 50.0, "val_auroc": 0.62, "time": 376.69}
{"epoch": 22, "training_loss": 55.256598472595215, "training_acc": 52.5, "val_loss": 14.044383764266968, "val_acc": 50.0, "val_auroc": 0.63, "time": 393.27}
{"epoch": 23, "training_loss": 55.615567207336426, "training_acc": 52.5, "val_loss": 14.161250591278076, "val_acc": 50.0, "val_auroc": 0.65, "time": 409.91}
{"epoch": 24, "training_loss": 55.9595947265625, "training_acc": 52.5, "val_loss": 14.091078042984009, "val_acc": 50.0, "val_auroc": 0.59, "time": 427.02}
{"epoch": 25, "training_loss": 55.763296127319336, "training_acc": 52.5, "val_loss": 13.928985595703125, "val_acc": 50.0, "val_auroc": 0.58, "time": 444.12}
{"epoch": 26, "training_loss": 55.39578914642334, "training_acc": 52.5, "val_loss": 13.863441944122314, "val_acc": 50.0, "val_auroc": 0.54, "time": 461.21}
{"epoch": 27, "training_loss": 55.341246604919434, "training_acc": 52.5, "val_loss": 13.85877013206482, "val_acc": 50.0, "val_auroc": 0.55, "time": 477.96}
{"epoch": 28, "training_loss": 55.539456367492676, "training_acc": 52.5, "val_loss": 13.855546712875366, "val_acc": 50.0, "val_auroc": 0.55, "time": 494.98}
{"epoch": 29, "training_loss": 55.401631355285645, "training_acc": 50.0, "val_loss": 13.861439228057861, "val_acc": 50.0, "val_auroc": 0.55, "time": 511.55}
{"epoch": 30, "training_loss": 55.49113368988037, "training_acc": 47.5, "val_loss": 13.85488748550415, "val_acc": 50.0, "val_auroc": 0.54, "time": 528.6}
{"epoch": 31, "training_loss": 55.292283058166504, "training_acc": 55.0, "val_loss": 13.91021728515625, "val_acc": 50.0, "val_auroc": 0.58, "time": 545.18}
{"epoch": 32, "training_loss": 55.48706340789795, "training_acc": 52.5, "val_loss": 13.935505151748657, "val_acc": 50.0, "val_auroc": 0.73, "time": 561.82}
{"epoch": 33, "training_loss": 55.40889263153076, "training_acc": 52.5, "val_loss": 13.890942335128784, "val_acc": 50.0, "val_auroc": 0.75, "time": 578.28}
{"epoch": 34, "training_loss": 55.345998764038086, "training_acc": 52.5, "val_loss": 13.874887228012085, "val_acc": 50.0, "val_auroc": 0.74, "time": 595.26}
{"epoch": 35, "training_loss": 55.394779205322266, "training_acc": 52.5, "val_loss": 13.857520818710327, "val_acc": 50.0, "val_auroc": 0.71, "time": 612.13}
{"epoch": 36, "training_loss": 55.265432357788086, "training_acc": 52.5, "val_loss": 13.865957260131836, "val_acc": 50.0, "val_auroc": 0.72, "time": 629.04}
