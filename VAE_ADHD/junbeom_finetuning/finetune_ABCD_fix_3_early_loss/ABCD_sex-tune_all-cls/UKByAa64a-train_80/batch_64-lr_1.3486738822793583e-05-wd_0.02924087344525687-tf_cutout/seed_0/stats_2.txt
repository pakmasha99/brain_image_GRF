"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.44906044006348, "training_acc": 52.5, "val_loss": 13.986549377441406, "val_acc": 50.0, "val_auroc": 0.64, "time": 19.52}
{"epoch": 1, "training_loss": 55.63029479980469, "training_acc": 52.5, "val_loss": 13.99914026260376, "val_acc": 50.0, "val_auroc": 0.57, "time": 37.43}
{"epoch": 2, "training_loss": 55.39773750305176, "training_acc": 52.5, "val_loss": 14.055378437042236, "val_acc": 50.0, "val_auroc": 0.28, "time": 56.34}
{"epoch": 3, "training_loss": 55.23095893859863, "training_acc": 52.5, "val_loss": 14.079060554504395, "val_acc": 50.0, "val_auroc": 0.21, "time": 73.96}
{"epoch": 4, "training_loss": 55.2009801864624, "training_acc": 52.5, "val_loss": 14.074453115463257, "val_acc": 50.0, "val_auroc": 0.27, "time": 90.78}
{"epoch": 5, "training_loss": 54.99297332763672, "training_acc": 52.5, "val_loss": 14.056706428527832, "val_acc": 50.0, "val_auroc": 0.29, "time": 108.03}
{"epoch": 6, "training_loss": 55.06879806518555, "training_acc": 52.5, "val_loss": 14.048522710800171, "val_acc": 50.0, "val_auroc": 0.3, "time": 125.33}
{"epoch": 7, "training_loss": 54.83919715881348, "training_acc": 52.5, "val_loss": 14.035757780075073, "val_acc": 50.0, "val_auroc": 0.28, "time": 143.47}
{"epoch": 8, "training_loss": 54.74838829040527, "training_acc": 52.5, "val_loss": 14.056816101074219, "val_acc": 50.0, "val_auroc": 0.31, "time": 161.75}
{"epoch": 9, "training_loss": 54.77028274536133, "training_acc": 52.5, "val_loss": 14.072434902191162, "val_acc": 50.0, "val_auroc": 0.25, "time": 178.67}
{"epoch": 10, "training_loss": 54.5156135559082, "training_acc": 52.5, "val_loss": 14.042285680770874, "val_acc": 50.0, "val_auroc": 0.27, "time": 197.33}
{"epoch": 11, "training_loss": 54.72112846374512, "training_acc": 52.5, "val_loss": 14.0865957736969, "val_acc": 50.0, "val_auroc": 0.27, "time": 219.01}
{"epoch": 12, "training_loss": 54.2849178314209, "training_acc": 52.5, "val_loss": 13.990529775619507, "val_acc": 50.0, "val_auroc": 0.42, "time": 236.03}
{"epoch": 13, "training_loss": 54.68004035949707, "training_acc": 52.5, "val_loss": 13.958557844161987, "val_acc": 50.0, "val_auroc": 0.51, "time": 253.37}
{"epoch": 14, "training_loss": 54.32491874694824, "training_acc": 52.5, "val_loss": 14.125092029571533, "val_acc": 50.0, "val_auroc": 0.23, "time": 270.29}
{"epoch": 15, "training_loss": 54.35544776916504, "training_acc": 52.5, "val_loss": 14.092464447021484, "val_acc": 50.0, "val_auroc": 0.26, "time": 289.46}
{"epoch": 16, "training_loss": 54.15346050262451, "training_acc": 52.5, "val_loss": 14.000357389450073, "val_acc": 50.0, "val_auroc": 0.39, "time": 306.36}
{"epoch": 17, "training_loss": 53.83514595031738, "training_acc": 52.5, "val_loss": 13.910750150680542, "val_acc": 50.0, "val_auroc": 0.56, "time": 323.67}
{"epoch": 18, "training_loss": 53.77169609069824, "training_acc": 52.5, "val_loss": 14.03659701347351, "val_acc": 50.0, "val_auroc": 0.3, "time": 340.54}
{"epoch": 19, "training_loss": 53.76757621765137, "training_acc": 52.5, "val_loss": 13.974065780639648, "val_acc": 50.0, "val_auroc": 0.38, "time": 357.45}
{"epoch": 20, "training_loss": 53.84025287628174, "training_acc": 52.5, "val_loss": 14.043183326721191, "val_acc": 50.0, "val_auroc": 0.32, "time": 374.48}
{"epoch": 21, "training_loss": 53.34688949584961, "training_acc": 57.5, "val_loss": 13.906177282333374, "val_acc": 50.0, "val_auroc": 0.51, "time": 392.02}
{"epoch": 22, "training_loss": 53.81062602996826, "training_acc": 52.5, "val_loss": 13.905826807022095, "val_acc": 50.0, "val_auroc": 0.56, "time": 409.59}
{"epoch": 23, "training_loss": 53.41687297821045, "training_acc": 52.5, "val_loss": 14.03027892112732, "val_acc": 50.0, "val_auroc": 0.34, "time": 427.92}
{"epoch": 24, "training_loss": 53.15641403198242, "training_acc": 53.75, "val_loss": 14.019463062286377, "val_acc": 50.0, "val_auroc": 0.34, "time": 445.14}
{"epoch": 25, "training_loss": 52.74500274658203, "training_acc": 56.25, "val_loss": 14.030746221542358, "val_acc": 50.0, "val_auroc": 0.31, "time": 462.79}
{"epoch": 26, "training_loss": 52.84981727600098, "training_acc": 60.0, "val_loss": 14.03039813041687, "val_acc": 50.0, "val_auroc": 0.34, "time": 479.88}
{"epoch": 27, "training_loss": 52.55142021179199, "training_acc": 58.75, "val_loss": 14.066050052642822, "val_acc": 50.0, "val_auroc": 0.34, "time": 498.34}
{"epoch": 28, "training_loss": 52.36400604248047, "training_acc": 63.75, "val_loss": 14.15697693824768, "val_acc": 50.0, "val_auroc": 0.32, "time": 515.54}
{"epoch": 29, "training_loss": 52.422563552856445, "training_acc": 70.0, "val_loss": 14.031494855880737, "val_acc": 50.0, "val_auroc": 0.35, "time": 532.98}
{"epoch": 30, "training_loss": 52.31202507019043, "training_acc": 61.25, "val_loss": 13.982199430465698, "val_acc": 50.0, "val_auroc": 0.4, "time": 550.41}
{"epoch": 31, "training_loss": 51.661874771118164, "training_acc": 60.0, "val_loss": 14.15150761604309, "val_acc": 50.0, "val_auroc": 0.34, "time": 567.68}
{"epoch": 32, "training_loss": 51.39126777648926, "training_acc": 75.0, "val_loss": 14.127236604690552, "val_acc": 50.0, "val_auroc": 0.32, "time": 584.36}
{"epoch": 33, "training_loss": 51.608285903930664, "training_acc": 66.25, "val_loss": 13.945624828338623, "val_acc": 50.0, "val_auroc": 0.44, "time": 603.62}
{"epoch": 34, "training_loss": 51.14463806152344, "training_acc": 66.25, "val_loss": 13.963050842285156, "val_acc": 50.0, "val_auroc": 0.39, "time": 620.58}
{"epoch": 35, "training_loss": 50.71900272369385, "training_acc": 70.0, "val_loss": 14.004896879196167, "val_acc": 50.0, "val_auroc": 0.37, "time": 638.11}
{"epoch": 36, "training_loss": 49.74419403076172, "training_acc": 77.5, "val_loss": 14.003914594650269, "val_acc": 50.0, "val_auroc": 0.38, "time": 654.88}
{"epoch": 37, "training_loss": 50.32421875, "training_acc": 73.75, "val_loss": 13.935987949371338, "val_acc": 50.0, "val_auroc": 0.41, "time": 672.17}
{"epoch": 38, "training_loss": 49.40005970001221, "training_acc": 78.75, "val_loss": 13.840440511703491, "val_acc": 50.0, "val_auroc": 0.49, "time": 689.3}
{"epoch": 39, "training_loss": 49.47709274291992, "training_acc": 75.0, "val_loss": 14.130109548568726, "val_acc": 50.0, "val_auroc": 0.38, "time": 708.07}
{"epoch": 40, "training_loss": 51.40543556213379, "training_acc": 73.75, "val_loss": 13.78907561302185, "val_acc": 50.0, "val_auroc": 0.5, "time": 725.45}
{"epoch": 41, "training_loss": 48.46954536437988, "training_acc": 78.75, "val_loss": 14.226573705673218, "val_acc": 50.0, "val_auroc": 0.35, "time": 742.81}
{"epoch": 42, "training_loss": 49.889671325683594, "training_acc": 80.0, "val_loss": 13.785244226455688, "val_acc": 50.0, "val_auroc": 0.52, "time": 759.88}
{"epoch": 43, "training_loss": 49.095224380493164, "training_acc": 73.75, "val_loss": 13.889573812484741, "val_acc": 50.0, "val_auroc": 0.44, "time": 777.98}
{"epoch": 44, "training_loss": 47.65938949584961, "training_acc": 81.25, "val_loss": 14.139856100082397, "val_acc": 50.0, "val_auroc": 0.41, "time": 794.8}
{"epoch": 45, "training_loss": 47.947752952575684, "training_acc": 88.75, "val_loss": 13.636505603790283, "val_acc": 50.0, "val_auroc": 0.65, "time": 813.4}
{"epoch": 46, "training_loss": 49.93898677825928, "training_acc": 68.75, "val_loss": 13.795156478881836, "val_acc": 50.0, "val_auroc": 0.52, "time": 830.94}
{"epoch": 47, "training_loss": 47.27512741088867, "training_acc": 86.25, "val_loss": 14.053131341934204, "val_acc": 50.0, "val_auroc": 0.44, "time": 848.72}
{"epoch": 48, "training_loss": 46.8923978805542, "training_acc": 86.25, "val_loss": 13.806041479110718, "val_acc": 50.0, "val_auroc": 0.63, "time": 865.22}
{"epoch": 49, "training_loss": 49.66337203979492, "training_acc": 62.5, "val_loss": 13.82373332977295, "val_acc": 50.0, "val_auroc": 0.53, "time": 883.2}
{"epoch": 50, "training_loss": 47.01049518585205, "training_acc": 81.25, "val_loss": 14.100536108016968, "val_acc": 50.0, "val_auroc": 0.42, "time": 900.04}
{"epoch": 51, "training_loss": 47.56180381774902, "training_acc": 87.5, "val_loss": 13.758337497711182, "val_acc": 50.0, "val_auroc": 0.55, "time": 917.19}
{"epoch": 52, "training_loss": 45.62165069580078, "training_acc": 81.25, "val_loss": 13.787273168563843, "val_acc": 50.0, "val_auroc": 0.56, "time": 933.94}
{"epoch": 53, "training_loss": 45.47861099243164, "training_acc": 82.5, "val_loss": 14.0274178981781, "val_acc": 50.0, "val_auroc": 0.44, "time": 951.03}
{"epoch": 54, "training_loss": 45.1472749710083, "training_acc": 88.75, "val_loss": 13.74651551246643, "val_acc": 50.0, "val_auroc": 0.53, "time": 968.25}
{"epoch": 55, "training_loss": 44.95090293884277, "training_acc": 81.25, "val_loss": 13.807930946350098, "val_acc": 50.0, "val_auroc": 0.53, "time": 985.04}
{"epoch": 56, "training_loss": 44.449710845947266, "training_acc": 85.0, "val_loss": 13.985832929611206, "val_acc": 50.0, "val_auroc": 0.47, "time": 1001.78}
{"epoch": 57, "training_loss": 43.76660919189453, "training_acc": 87.5, "val_loss": 13.864141702651978, "val_acc": 50.0, "val_auroc": 0.5, "time": 1019.84}
{"epoch": 58, "training_loss": 42.958282470703125, "training_acc": 90.0, "val_loss": 13.8510000705719, "val_acc": 50.0, "val_auroc": 0.49, "time": 1036.95}
{"epoch": 59, "training_loss": 42.24068021774292, "training_acc": 90.0, "val_loss": 13.782310485839844, "val_acc": 50.0, "val_auroc": 0.55, "time": 1053.96}
{"epoch": 60, "training_loss": 41.24214744567871, "training_acc": 88.75, "val_loss": 13.890045881271362, "val_acc": 50.0, "val_auroc": 0.51, "time": 1070.58}
{"epoch": 61, "training_loss": 41.71424674987793, "training_acc": 91.25, "val_loss": 13.848472833633423, "val_acc": 50.0, "val_auroc": 0.57, "time": 1087.86}
{"epoch": 62, "training_loss": 41.41000461578369, "training_acc": 87.5, "val_loss": 13.906522989273071, "val_acc": 50.0, "val_auroc": 0.51, "time": 1105.44}
{"epoch": 63, "training_loss": 40.780399322509766, "training_acc": 90.0, "val_loss": 13.893269300460815, "val_acc": 55.0, "val_auroc": 0.48, "time": 1122.46}
{"epoch": 64, "training_loss": 40.167762756347656, "training_acc": 87.5, "val_loss": 13.827024698257446, "val_acc": 55.0, "val_auroc": 0.59, "time": 1140.26}
