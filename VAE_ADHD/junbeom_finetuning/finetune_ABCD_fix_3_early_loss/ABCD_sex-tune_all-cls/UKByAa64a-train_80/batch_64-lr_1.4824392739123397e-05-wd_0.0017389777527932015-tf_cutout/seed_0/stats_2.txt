"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.644415855407715, "training_acc": 52.5, "val_loss": 14.002918004989624, "val_acc": 50.0, "val_auroc": 0.51, "time": 19.21}
{"epoch": 1, "training_loss": 55.596200942993164, "training_acc": 52.5, "val_loss": 13.993663787841797, "val_acc": 50.0, "val_auroc": 0.49, "time": 37.07}
{"epoch": 2, "training_loss": 55.403032302856445, "training_acc": 52.5, "val_loss": 14.006069898605347, "val_acc": 50.0, "val_auroc": 0.46, "time": 56.1}
{"epoch": 3, "training_loss": 55.3068265914917, "training_acc": 52.5, "val_loss": 14.022420644760132, "val_acc": 50.0, "val_auroc": 0.37, "time": 75.47}
{"epoch": 4, "training_loss": 55.23273849487305, "training_acc": 52.5, "val_loss": 14.011248350143433, "val_acc": 50.0, "val_auroc": 0.42, "time": 94.26}
{"epoch": 5, "training_loss": 54.99485397338867, "training_acc": 52.5, "val_loss": 14.03031587600708, "val_acc": 50.0, "val_auroc": 0.37, "time": 110.87}
{"epoch": 6, "training_loss": 54.9431266784668, "training_acc": 52.5, "val_loss": 14.041037559509277, "val_acc": 50.0, "val_auroc": 0.36, "time": 128.34}
{"epoch": 7, "training_loss": 54.75151252746582, "training_acc": 52.5, "val_loss": 14.080047607421875, "val_acc": 50.0, "val_auroc": 0.33, "time": 146.25}
{"epoch": 8, "training_loss": 54.82208442687988, "training_acc": 52.5, "val_loss": 14.085108041763306, "val_acc": 50.0, "val_auroc": 0.29, "time": 165.1}
{"epoch": 9, "training_loss": 54.842896461486816, "training_acc": 52.5, "val_loss": 14.07180666923523, "val_acc": 50.0, "val_auroc": 0.31, "time": 182.29}
{"epoch": 10, "training_loss": 54.49039077758789, "training_acc": 52.5, "val_loss": 14.022668600082397, "val_acc": 50.0, "val_auroc": 0.41, "time": 199.76}
{"epoch": 11, "training_loss": 54.30487823486328, "training_acc": 52.5, "val_loss": 14.071645736694336, "val_acc": 50.0, "val_auroc": 0.28, "time": 217.94}
{"epoch": 12, "training_loss": 53.99712944030762, "training_acc": 52.5, "val_loss": 14.010437726974487, "val_acc": 50.0, "val_auroc": 0.37, "time": 236.55}
{"epoch": 13, "training_loss": 54.14337921142578, "training_acc": 52.5, "val_loss": 14.034937620162964, "val_acc": 50.0, "val_auroc": 0.35, "time": 253.63}
{"epoch": 14, "training_loss": 53.69761562347412, "training_acc": 52.5, "val_loss": 14.01812195777893, "val_acc": 50.0, "val_auroc": 0.35, "time": 272.6}
{"epoch": 15, "training_loss": 53.60450553894043, "training_acc": 53.75, "val_loss": 13.984147310256958, "val_acc": 50.0, "val_auroc": 0.48, "time": 289.47}
{"epoch": 16, "training_loss": 53.54043006896973, "training_acc": 53.75, "val_loss": 13.972104787826538, "val_acc": 50.0, "val_auroc": 0.51, "time": 308.97}
{"epoch": 17, "training_loss": 53.179494857788086, "training_acc": 55.0, "val_loss": 14.154914617538452, "val_acc": 50.0, "val_auroc": 0.29, "time": 326.41}
{"epoch": 18, "training_loss": 52.83008003234863, "training_acc": 62.5, "val_loss": 14.186161756515503, "val_acc": 50.0, "val_auroc": 0.29, "time": 343.68}
{"epoch": 19, "training_loss": 52.91300582885742, "training_acc": 63.75, "val_loss": 13.94979476928711, "val_acc": 50.0, "val_auroc": 0.54, "time": 360.88}
{"epoch": 20, "training_loss": 52.50386619567871, "training_acc": 55.0, "val_loss": 14.28120493888855, "val_acc": 50.0, "val_auroc": 0.29, "time": 378.58}
{"epoch": 21, "training_loss": 52.4279670715332, "training_acc": 71.25, "val_loss": 13.82122278213501, "val_acc": 50.0, "val_auroc": 0.66, "time": 396.07}
{"epoch": 22, "training_loss": 53.38965606689453, "training_acc": 52.5, "val_loss": 14.062923192977905, "val_acc": 50.0, "val_auroc": 0.36, "time": 414.14}
{"epoch": 23, "training_loss": 52.33764171600342, "training_acc": 63.75, "val_loss": 14.341702461242676, "val_acc": 50.0, "val_auroc": 0.26, "time": 432.22}
{"epoch": 24, "training_loss": 52.280842781066895, "training_acc": 67.5, "val_loss": 13.798942565917969, "val_acc": 50.0, "val_auroc": 0.63, "time": 451.34}
{"epoch": 25, "training_loss": 52.57182693481445, "training_acc": 56.25, "val_loss": 14.32552695274353, "val_acc": 50.0, "val_auroc": 0.32, "time": 468.3}
{"epoch": 26, "training_loss": 52.37796592712402, "training_acc": 70.0, "val_loss": 14.263603687286377, "val_acc": 50.0, "val_auroc": 0.34, "time": 486.45}
{"epoch": 27, "training_loss": 52.620378494262695, "training_acc": 75.0, "val_loss": 14.1045081615448, "val_acc": 50.0, "val_auroc": 0.32, "time": 503.58}
{"epoch": 28, "training_loss": 51.66324996948242, "training_acc": 58.75, "val_loss": 13.897802829742432, "val_acc": 50.0, "val_auroc": 0.62, "time": 523.64}
{"epoch": 29, "training_loss": 52.84336471557617, "training_acc": 55.0, "val_loss": 14.199632406234741, "val_acc": 50.0, "val_auroc": 0.34, "time": 540.1}
{"epoch": 30, "training_loss": 51.29402160644531, "training_acc": 68.75, "val_loss": 14.454030990600586, "val_acc": 50.0, "val_auroc": 0.31, "time": 557.42}
{"epoch": 31, "training_loss": 51.380106925964355, "training_acc": 75.0, "val_loss": 14.180927276611328, "val_acc": 50.0, "val_auroc": 0.36, "time": 574.38}
{"epoch": 32, "training_loss": 50.53515148162842, "training_acc": 66.25, "val_loss": 14.038944244384766, "val_acc": 50.0, "val_auroc": 0.39, "time": 592.2}
{"epoch": 33, "training_loss": 50.64389991760254, "training_acc": 67.5, "val_loss": 14.374363422393799, "val_acc": 50.0, "val_auroc": 0.33, "time": 609.23}
{"epoch": 34, "training_loss": 50.72916030883789, "training_acc": 75.0, "val_loss": 14.112886190414429, "val_acc": 50.0, "val_auroc": 0.36, "time": 626.27}
{"epoch": 35, "training_loss": 50.05973148345947, "training_acc": 68.75, "val_loss": 13.976292610168457, "val_acc": 50.0, "val_auroc": 0.46, "time": 643.76}
{"epoch": 36, "training_loss": 49.451398849487305, "training_acc": 73.75, "val_loss": 14.316233396530151, "val_acc": 50.0, "val_auroc": 0.34, "time": 662.19}
{"epoch": 37, "training_loss": 49.61001491546631, "training_acc": 77.5, "val_loss": 14.168789386749268, "val_acc": 50.0, "val_auroc": 0.32, "time": 678.72}
{"epoch": 38, "training_loss": 48.904266357421875, "training_acc": 78.75, "val_loss": 13.96107792854309, "val_acc": 50.0, "val_auroc": 0.44, "time": 695.98}
{"epoch": 39, "training_loss": 48.851149559020996, "training_acc": 76.25, "val_loss": 14.433176517486572, "val_acc": 50.0, "val_auroc": 0.33, "time": 712.75}
{"epoch": 40, "training_loss": 49.3637638092041, "training_acc": 80.0, "val_loss": 14.167126417160034, "val_acc": 50.0, "val_auroc": 0.32, "time": 730.51}
{"epoch": 41, "training_loss": 47.6933708190918, "training_acc": 85.0, "val_loss": 14.265342950820923, "val_acc": 50.0, "val_auroc": 0.34, "time": 747.48}
{"epoch": 42, "training_loss": 48.1778450012207, "training_acc": 85.0, "val_loss": 14.411460161209106, "val_acc": 50.0, "val_auroc": 0.33, "time": 764.57}
{"epoch": 43, "training_loss": 47.67337131500244, "training_acc": 81.25, "val_loss": 13.954614400863647, "val_acc": 50.0, "val_auroc": 0.46, "time": 781.48}
