"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.78594207763672, "training_acc": 52.5, "val_loss": 14.093211889266968, "val_acc": 50.0, "val_auroc": 0.51, "time": 19.65}
{"epoch": 1, "training_loss": 55.733299255371094, "training_acc": 52.5, "val_loss": 14.053009748458862, "val_acc": 50.0, "val_auroc": 0.53, "time": 37.56}
{"epoch": 2, "training_loss": 55.45803260803223, "training_acc": 52.5, "val_loss": 14.057782888412476, "val_acc": 50.0, "val_auroc": 0.48, "time": 58.07}
{"epoch": 3, "training_loss": 55.3083438873291, "training_acc": 52.5, "val_loss": 14.019817113876343, "val_acc": 50.0, "val_auroc": 0.55, "time": 81.96}
{"epoch": 4, "training_loss": 55.35314750671387, "training_acc": 52.5, "val_loss": 14.019390344619751, "val_acc": 50.0, "val_auroc": 0.53, "time": 100.43}
{"epoch": 5, "training_loss": 55.0546817779541, "training_acc": 52.5, "val_loss": 14.052584171295166, "val_acc": 50.0, "val_auroc": 0.33, "time": 118.31}
{"epoch": 6, "training_loss": 55.21714687347412, "training_acc": 52.5, "val_loss": 14.035124778747559, "val_acc": 50.0, "val_auroc": 0.36, "time": 136.83}
{"epoch": 7, "training_loss": 54.79474449157715, "training_acc": 52.5, "val_loss": 14.039708375930786, "val_acc": 50.0, "val_auroc": 0.4, "time": 158.02}
{"epoch": 8, "training_loss": 54.73669147491455, "training_acc": 52.5, "val_loss": 14.01114821434021, "val_acc": 50.0, "val_auroc": 0.39, "time": 176.19}
{"epoch": 9, "training_loss": 54.75023651123047, "training_acc": 52.5, "val_loss": 13.996213674545288, "val_acc": 50.0, "val_auroc": 0.38, "time": 193.16}
{"epoch": 10, "training_loss": 54.75460624694824, "training_acc": 52.5, "val_loss": 13.98070216178894, "val_acc": 50.0, "val_auroc": 0.44, "time": 212.97}
{"epoch": 11, "training_loss": 54.28804969787598, "training_acc": 52.5, "val_loss": 13.991228342056274, "val_acc": 50.0, "val_auroc": 0.44, "time": 235.07}
{"epoch": 12, "training_loss": 54.21682167053223, "training_acc": 52.5, "val_loss": 14.034559726715088, "val_acc": 50.0, "val_auroc": 0.31, "time": 253.03}
{"epoch": 13, "training_loss": 54.29112911224365, "training_acc": 52.5, "val_loss": 14.027853012084961, "val_acc": 50.0, "val_auroc": 0.3, "time": 270.99}
{"epoch": 14, "training_loss": 54.00865936279297, "training_acc": 52.5, "val_loss": 13.966360092163086, "val_acc": 50.0, "val_auroc": 0.44, "time": 291.05}
{"epoch": 15, "training_loss": 54.08060646057129, "training_acc": 53.75, "val_loss": 13.968216180801392, "val_acc": 50.0, "val_auroc": 0.39, "time": 312.32}
{"epoch": 16, "training_loss": 53.84956741333008, "training_acc": 53.75, "val_loss": 13.891019821166992, "val_acc": 50.0, "val_auroc": 0.59, "time": 330.72}
{"epoch": 17, "training_loss": 53.728487968444824, "training_acc": 52.5, "val_loss": 14.08962607383728, "val_acc": 50.0, "val_auroc": 0.27, "time": 348.5}
{"epoch": 18, "training_loss": 53.403953552246094, "training_acc": 52.5, "val_loss": 14.041870832443237, "val_acc": 50.0, "val_auroc": 0.32, "time": 367.78}
{"epoch": 19, "training_loss": 53.25442886352539, "training_acc": 52.5, "val_loss": 13.902000188827515, "val_acc": 50.0, "val_auroc": 0.57, "time": 389.83}
{"epoch": 20, "training_loss": 53.274434089660645, "training_acc": 52.5, "val_loss": 14.08024549484253, "val_acc": 50.0, "val_auroc": 0.3, "time": 412.78}
{"epoch": 21, "training_loss": 53.12544631958008, "training_acc": 66.25, "val_loss": 13.907750844955444, "val_acc": 50.0, "val_auroc": 0.55, "time": 431.06}
{"epoch": 22, "training_loss": 53.20888423919678, "training_acc": 53.75, "val_loss": 14.131650924682617, "val_acc": 50.0, "val_auroc": 0.24, "time": 449.82}
{"epoch": 23, "training_loss": 52.95559120178223, "training_acc": 61.25, "val_loss": 14.05362844467163, "val_acc": 50.0, "val_auroc": 0.27, "time": 470.79}
{"epoch": 24, "training_loss": 52.84490966796875, "training_acc": 56.25, "val_loss": 13.823777437210083, "val_acc": 50.0, "val_auroc": 0.65, "time": 489.79}
{"epoch": 25, "training_loss": 53.05704879760742, "training_acc": 53.75, "val_loss": 14.056901931762695, "val_acc": 50.0, "val_auroc": 0.39, "time": 507.84}
{"epoch": 26, "training_loss": 53.14996147155762, "training_acc": 67.5, "val_loss": 13.990257978439331, "val_acc": 50.0, "val_auroc": 0.35, "time": 526.45}
{"epoch": 27, "training_loss": 53.29195785522461, "training_acc": 66.25, "val_loss": 14.064944982528687, "val_acc": 50.0, "val_auroc": 0.31, "time": 546.86}
{"epoch": 28, "training_loss": 52.293630599975586, "training_acc": 60.0, "val_loss": 13.87204885482788, "val_acc": 50.0, "val_auroc": 0.63, "time": 563.7}
{"epoch": 29, "training_loss": 53.14994430541992, "training_acc": 52.5, "val_loss": 13.943527936935425, "val_acc": 50.0, "val_auroc": 0.44, "time": 580.55}
{"epoch": 30, "training_loss": 52.245240211486816, "training_acc": 63.75, "val_loss": 14.157028198242188, "val_acc": 50.0, "val_auroc": 0.37, "time": 599.4}
{"epoch": 31, "training_loss": 52.05972385406494, "training_acc": 73.75, "val_loss": 14.106947183609009, "val_acc": 50.0, "val_auroc": 0.3, "time": 617.94}
{"epoch": 32, "training_loss": 51.3399772644043, "training_acc": 68.75, "val_loss": 14.025160074234009, "val_acc": 50.0, "val_auroc": 0.31, "time": 639.63}
{"epoch": 33, "training_loss": 51.475486755371094, "training_acc": 65.0, "val_loss": 14.046380519866943, "val_acc": 50.0, "val_auroc": 0.3, "time": 657.4}
{"epoch": 34, "training_loss": 51.24049663543701, "training_acc": 76.25, "val_loss": 13.996156454086304, "val_acc": 50.0, "val_auroc": 0.33, "time": 674.73}
{"epoch": 35, "training_loss": 50.73731231689453, "training_acc": 72.5, "val_loss": 14.012640714645386, "val_acc": 50.0, "val_auroc": 0.31, "time": 692.83}
{"epoch": 36, "training_loss": 49.51433753967285, "training_acc": 78.75, "val_loss": 14.07691478729248, "val_acc": 50.0, "val_auroc": 0.3, "time": 714.59}
{"epoch": 37, "training_loss": 50.015116691589355, "training_acc": 77.5, "val_loss": 13.843679428100586, "val_acc": 50.0, "val_auroc": 0.43, "time": 731.77}
{"epoch": 38, "training_loss": 49.207945823669434, "training_acc": 77.5, "val_loss": 13.91891360282898, "val_acc": 50.0, "val_auroc": 0.36, "time": 749.44}
{"epoch": 39, "training_loss": 48.941529273986816, "training_acc": 76.25, "val_loss": 14.272804260253906, "val_acc": 50.0, "val_auroc": 0.37, "time": 767.6}
{"epoch": 40, "training_loss": 50.35665512084961, "training_acc": 76.25, "val_loss": 13.977078199386597, "val_acc": 50.0, "val_auroc": 0.36, "time": 788.12}
{"epoch": 41, "training_loss": 47.7369384765625, "training_acc": 82.5, "val_loss": 14.334462881088257, "val_acc": 50.0, "val_auroc": 0.3, "time": 805.92}
{"epoch": 42, "training_loss": 48.996259689331055, "training_acc": 82.5, "val_loss": 13.864059448242188, "val_acc": 50.0, "val_auroc": 0.45, "time": 823.62}
{"epoch": 43, "training_loss": 49.08104705810547, "training_acc": 70.0, "val_loss": 13.943226337432861, "val_acc": 50.0, "val_auroc": 0.37, "time": 843.43}
