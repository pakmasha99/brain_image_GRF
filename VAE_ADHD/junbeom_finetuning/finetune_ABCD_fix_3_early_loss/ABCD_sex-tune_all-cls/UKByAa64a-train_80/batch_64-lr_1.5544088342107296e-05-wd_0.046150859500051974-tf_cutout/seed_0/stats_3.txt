"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.46992111206055, "training_acc": 51.25, "val_loss": 13.852554559707642, "val_acc": 55.0, "val_auroc": 0.364, "time": 19.6}
{"epoch": 1, "training_loss": 55.50497913360596, "training_acc": 51.25, "val_loss": 13.811545372009277, "val_acc": 55.0, "val_auroc": 0.626, "time": 37.38}
{"epoch": 2, "training_loss": 55.392666816711426, "training_acc": 51.25, "val_loss": 13.793104887008667, "val_acc": 55.0, "val_auroc": 0.586, "time": 55.53}
{"epoch": 3, "training_loss": 55.26375770568848, "training_acc": 51.25, "val_loss": 13.794864416122437, "val_acc": 55.0, "val_auroc": 0.566, "time": 74.43}
{"epoch": 4, "training_loss": 55.25605010986328, "training_acc": 51.25, "val_loss": 13.776544332504272, "val_acc": 55.0, "val_auroc": 0.636, "time": 93.48}
{"epoch": 5, "training_loss": 54.861602783203125, "training_acc": 51.25, "val_loss": 13.778750896453857, "val_acc": 55.0, "val_auroc": 0.596, "time": 112.26}
{"epoch": 6, "training_loss": 54.9427433013916, "training_acc": 51.25, "val_loss": 13.802490234375, "val_acc": 55.0, "val_auroc": 0.505, "time": 129.01}
{"epoch": 7, "training_loss": 55.014488220214844, "training_acc": 51.25, "val_loss": 13.764694929122925, "val_acc": 55.0, "val_auroc": 0.596, "time": 145.93}
{"epoch": 8, "training_loss": 54.85044479370117, "training_acc": 51.25, "val_loss": 13.779386281967163, "val_acc": 55.0, "val_auroc": 0.586, "time": 163.26}
{"epoch": 9, "training_loss": 54.665489196777344, "training_acc": 51.25, "val_loss": 13.776178359985352, "val_acc": 55.0, "val_auroc": 0.596, "time": 182.0}
{"epoch": 10, "training_loss": 54.41177845001221, "training_acc": 57.5, "val_loss": 13.803995847702026, "val_acc": 55.0, "val_auroc": 0.576, "time": 199.96}
{"epoch": 11, "training_loss": 54.338396072387695, "training_acc": 57.5, "val_loss": 13.768409490585327, "val_acc": 55.0, "val_auroc": 0.596, "time": 218.98}
{"epoch": 12, "training_loss": 54.277456283569336, "training_acc": 53.75, "val_loss": 13.747460842132568, "val_acc": 55.0, "val_auroc": 0.626, "time": 239.51}
{"epoch": 13, "training_loss": 54.273508071899414, "training_acc": 55.0, "val_loss": 13.728159666061401, "val_acc": 55.0, "val_auroc": 0.606, "time": 258.9}
{"epoch": 14, "training_loss": 53.996768951416016, "training_acc": 57.5, "val_loss": 13.768869638442993, "val_acc": 55.0, "val_auroc": 0.556, "time": 276.05}
{"epoch": 15, "training_loss": 53.80849266052246, "training_acc": 66.25, "val_loss": 13.802101612091064, "val_acc": 55.0, "val_auroc": 0.566, "time": 293.83}
{"epoch": 16, "training_loss": 53.553823471069336, "training_acc": 65.0, "val_loss": 13.803808689117432, "val_acc": 55.0, "val_auroc": 0.525, "time": 313.34}
{"epoch": 17, "training_loss": 53.55428600311279, "training_acc": 66.25, "val_loss": 13.789645433425903, "val_acc": 55.0, "val_auroc": 0.535, "time": 331.09}
{"epoch": 18, "training_loss": 53.351423263549805, "training_acc": 62.5, "val_loss": 13.778162002563477, "val_acc": 55.0, "val_auroc": 0.586, "time": 348.46}
{"epoch": 19, "training_loss": 53.04797649383545, "training_acc": 67.5, "val_loss": 13.82731318473816, "val_acc": 55.0, "val_auroc": 0.545, "time": 370.68}
{"epoch": 20, "training_loss": 53.233134269714355, "training_acc": 68.75, "val_loss": 13.849772214889526, "val_acc": 55.0, "val_auroc": 0.505, "time": 389.8}
{"epoch": 21, "training_loss": 52.927053451538086, "training_acc": 68.75, "val_loss": 13.867971897125244, "val_acc": 55.0, "val_auroc": 0.495, "time": 407.6}
{"epoch": 22, "training_loss": 52.9322509765625, "training_acc": 72.5, "val_loss": 13.88451337814331, "val_acc": 55.0, "val_auroc": 0.424, "time": 424.23}
{"epoch": 23, "training_loss": 52.42497539520264, "training_acc": 73.75, "val_loss": 13.834618330001831, "val_acc": 55.0, "val_auroc": 0.535, "time": 441.59}
{"epoch": 24, "training_loss": 52.235737800598145, "training_acc": 73.75, "val_loss": 13.820890188217163, "val_acc": 55.0, "val_auroc": 0.576, "time": 461.22}
{"epoch": 25, "training_loss": 52.25222682952881, "training_acc": 70.0, "val_loss": 13.788696527481079, "val_acc": 55.0, "val_auroc": 0.556, "time": 478.71}
{"epoch": 26, "training_loss": 52.340725898742676, "training_acc": 68.75, "val_loss": 13.80314826965332, "val_acc": 55.0, "val_auroc": 0.505, "time": 495.67}
{"epoch": 27, "training_loss": 52.22611427307129, "training_acc": 75.0, "val_loss": 13.754920959472656, "val_acc": 55.0, "val_auroc": 0.596, "time": 512.95}
{"epoch": 28, "training_loss": 52.51296520233154, "training_acc": 67.5, "val_loss": 13.781861066818237, "val_acc": 55.0, "val_auroc": 0.525, "time": 530.8}
{"epoch": 29, "training_loss": 51.94010925292969, "training_acc": 76.25, "val_loss": 13.812164068222046, "val_acc": 55.0, "val_auroc": 0.505, "time": 549.39}
{"epoch": 30, "training_loss": 51.44885444641113, "training_acc": 80.0, "val_loss": 13.836164474487305, "val_acc": 55.0, "val_auroc": 0.505, "time": 566.75}
{"epoch": 31, "training_loss": 51.784934997558594, "training_acc": 70.0, "val_loss": 13.912352323532104, "val_acc": 55.0, "val_auroc": 0.434, "time": 584.34}
{"epoch": 32, "training_loss": 51.1935338973999, "training_acc": 87.5, "val_loss": 13.921957015991211, "val_acc": 55.0, "val_auroc": 0.455, "time": 602.24}
