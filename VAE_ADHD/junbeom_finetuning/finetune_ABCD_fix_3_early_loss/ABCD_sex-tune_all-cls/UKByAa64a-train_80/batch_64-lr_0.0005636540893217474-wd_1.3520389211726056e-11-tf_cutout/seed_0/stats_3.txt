"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.46530723571777, "training_acc": 51.25, "val_loss": 35.372421741485596, "val_acc": 45.0, "val_auroc": 0.545, "time": 19.37}
{"epoch": 1, "training_loss": 117.25749588012695, "training_acc": 53.75, "val_loss": 13.788231611251831, "val_acc": 55.0, "val_auroc": 0.535, "time": 37.2}
{"epoch": 2, "training_loss": 58.0220832824707, "training_acc": 48.75, "val_loss": 89.53089714050293, "val_acc": 55.0, "val_auroc": 0.596, "time": 54.52}
{"epoch": 3, "training_loss": 344.9039831161499, "training_acc": 51.25, "val_loss": 15.032927989959717, "val_acc": 45.0, "val_auroc": 0.475, "time": 71.71}
{"epoch": 4, "training_loss": 58.21346473693848, "training_acc": 48.75, "val_loss": 13.953121900558472, "val_acc": 55.0, "val_auroc": 0.424, "time": 89.01}
{"epoch": 5, "training_loss": 55.319095611572266, "training_acc": 51.25, "val_loss": 13.829071521759033, "val_acc": 55.0, "val_auroc": 0.434, "time": 106.75}
{"epoch": 6, "training_loss": 56.1596794128418, "training_acc": 51.25, "val_loss": 13.924903869628906, "val_acc": 55.0, "val_auroc": 0.424, "time": 123.91}
{"epoch": 7, "training_loss": 55.517005920410156, "training_acc": 50.0, "val_loss": 13.972595930099487, "val_acc": 55.0, "val_auroc": 0.424, "time": 141.07}
{"epoch": 8, "training_loss": 56.25184440612793, "training_acc": 43.75, "val_loss": 13.803043365478516, "val_acc": 55.0, "val_auroc": 0.444, "time": 158.08}
{"epoch": 9, "training_loss": 55.35426712036133, "training_acc": 51.25, "val_loss": 14.094895124435425, "val_acc": 55.0, "val_auroc": 0.434, "time": 175.11}
{"epoch": 10, "training_loss": 55.83313751220703, "training_acc": 48.75, "val_loss": 13.849674463272095, "val_acc": 55.0, "val_auroc": 0.465, "time": 192.16}
{"epoch": 11, "training_loss": 55.06325054168701, "training_acc": 52.5, "val_loss": 13.785479068756104, "val_acc": 55.0, "val_auroc": 0.485, "time": 209.21}
{"epoch": 12, "training_loss": 56.221378326416016, "training_acc": 51.25, "val_loss": 13.790216445922852, "val_acc": 55.0, "val_auroc": 0.566, "time": 226.36}
{"epoch": 13, "training_loss": 56.053152084350586, "training_acc": 51.25, "val_loss": 13.78116488456726, "val_acc": 55.0, "val_auroc": 0.545, "time": 242.3}
{"epoch": 14, "training_loss": 55.344889640808105, "training_acc": 51.25, "val_loss": 13.969212770462036, "val_acc": 55.0, "val_auroc": 0.444, "time": 259.82}
{"epoch": 15, "training_loss": 55.96055603027344, "training_acc": 48.75, "val_loss": 13.996957540512085, "val_acc": 55.0, "val_auroc": 0.465, "time": 276.64}
{"epoch": 16, "training_loss": 55.4246129989624, "training_acc": 48.75, "val_loss": 13.802938461303711, "val_acc": 55.0, "val_auroc": 0.455, "time": 291.82}
{"epoch": 17, "training_loss": 55.542715072631836, "training_acc": 51.25, "val_loss": 13.7711501121521, "val_acc": 55.0, "val_auroc": 0.414, "time": 309.41}
{"epoch": 18, "training_loss": 55.63621520996094, "training_acc": 51.25, "val_loss": 13.77318263053894, "val_acc": 55.0, "val_auroc": 0.434, "time": 326.57}
{"epoch": 19, "training_loss": 55.4196662902832, "training_acc": 51.25, "val_loss": 13.840265274047852, "val_acc": 55.0, "val_auroc": 0.434, "time": 343.63}
{"epoch": 20, "training_loss": 55.478559494018555, "training_acc": 48.75, "val_loss": 13.980329036712646, "val_acc": 55.0, "val_auroc": 0.444, "time": 360.51}
{"epoch": 21, "training_loss": 55.61151599884033, "training_acc": 48.75, "val_loss": 13.952168226242065, "val_acc": 55.0, "val_auroc": 0.444, "time": 377.53}
{"epoch": 22, "training_loss": 55.5329532623291, "training_acc": 48.75, "val_loss": 13.861545324325562, "val_acc": 55.0, "val_auroc": 0.485, "time": 394.56}
{"epoch": 23, "training_loss": 55.39444065093994, "training_acc": 53.75, "val_loss": 13.810110092163086, "val_acc": 55.0, "val_auroc": 0.455, "time": 411.05}
{"epoch": 24, "training_loss": 55.363746643066406, "training_acc": 51.25, "val_loss": 13.77550482749939, "val_acc": 55.0, "val_auroc": 0.424, "time": 427.98}
{"epoch": 25, "training_loss": 55.43161106109619, "training_acc": 51.25, "val_loss": 13.770763874053955, "val_acc": 55.0, "val_auroc": 0.424, "time": 445.07}
{"epoch": 26, "training_loss": 55.68889904022217, "training_acc": 51.25, "val_loss": 13.80143404006958, "val_acc": 55.0, "val_auroc": 0.364, "time": 462.23}
{"epoch": 27, "training_loss": 56.09581661224365, "training_acc": 51.25, "val_loss": 13.809565305709839, "val_acc": 55.0, "val_auroc": 0.384, "time": 479.12}
{"epoch": 28, "training_loss": 56.12874412536621, "training_acc": 51.25, "val_loss": 13.769621849060059, "val_acc": 55.0, "val_auroc": 0.414, "time": 496.14}
{"epoch": 29, "training_loss": 55.72799301147461, "training_acc": 51.25, "val_loss": 13.802837133407593, "val_acc": 55.0, "val_auroc": 0.495, "time": 512.92}
{"epoch": 30, "training_loss": 55.39578151702881, "training_acc": 51.25, "val_loss": 13.879623413085938, "val_acc": 55.0, "val_auroc": 0.525, "time": 530.09}
{"epoch": 31, "training_loss": 55.407105445861816, "training_acc": 48.75, "val_loss": 13.969385623931885, "val_acc": 55.0, "val_auroc": 0.505, "time": 546.75}
{"epoch": 32, "training_loss": 55.55660438537598, "training_acc": 48.75, "val_loss": 14.081045389175415, "val_acc": 55.0, "val_auroc": 0.515, "time": 563.39}
{"epoch": 33, "training_loss": 55.834638595581055, "training_acc": 48.75, "val_loss": 14.045495986938477, "val_acc": 55.0, "val_auroc": 0.535, "time": 580.09}
{"epoch": 34, "training_loss": 55.66116523742676, "training_acc": 48.75, "val_loss": 13.904043436050415, "val_acc": 55.0, "val_auroc": 0.545, "time": 596.99}
{"epoch": 35, "training_loss": 55.56085205078125, "training_acc": 43.75, "val_loss": 13.84244680404663, "val_acc": 55.0, "val_auroc": 0.596, "time": 613.92}
{"epoch": 36, "training_loss": 55.39987564086914, "training_acc": 51.25, "val_loss": 13.830643892288208, "val_acc": 55.0, "val_auroc": 0.586, "time": 630.93}
{"epoch": 37, "training_loss": 55.38400840759277, "training_acc": 51.25, "val_loss": 13.81503701210022, "val_acc": 55.0, "val_auroc": 0.505, "time": 648.15}
{"epoch": 38, "training_loss": 55.379788398742676, "training_acc": 51.25, "val_loss": 13.800736665725708, "val_acc": 55.0, "val_auroc": 0.485, "time": 664.97}
{"epoch": 39, "training_loss": 55.38705062866211, "training_acc": 51.25, "val_loss": 13.789751529693604, "val_acc": 55.0, "val_auroc": 0.444, "time": 681.11}
{"epoch": 40, "training_loss": 55.435916900634766, "training_acc": 51.25, "val_loss": 13.790308237075806, "val_acc": 55.0, "val_auroc": 0.434, "time": 695.98}
{"epoch": 41, "training_loss": 55.37044334411621, "training_acc": 51.25, "val_loss": 13.819794654846191, "val_acc": 55.0, "val_auroc": 0.444, "time": 713.5}
{"epoch": 42, "training_loss": 55.39423942565918, "training_acc": 52.5, "val_loss": 13.864024877548218, "val_acc": 55.0, "val_auroc": 0.434, "time": 730.11}
{"epoch": 43, "training_loss": 55.381784439086914, "training_acc": 55.0, "val_loss": 13.880949020385742, "val_acc": 55.0, "val_auroc": 0.434, "time": 745.78}
{"epoch": 44, "training_loss": 55.41051769256592, "training_acc": 56.25, "val_loss": 13.894084692001343, "val_acc": 55.0, "val_auroc": 0.444, "time": 762.96}
{"epoch": 45, "training_loss": 55.40545082092285, "training_acc": 50.0, "val_loss": 13.930145502090454, "val_acc": 55.0, "val_auroc": 0.444, "time": 779.87}
{"epoch": 46, "training_loss": 55.4452018737793, "training_acc": 48.75, "val_loss": 13.959566354751587, "val_acc": 55.0, "val_auroc": 0.444, "time": 797.07}
{"epoch": 47, "training_loss": 55.4595832824707, "training_acc": 48.75, "val_loss": 13.917440176010132, "val_acc": 55.0, "val_auroc": 0.444, "time": 814.22}
