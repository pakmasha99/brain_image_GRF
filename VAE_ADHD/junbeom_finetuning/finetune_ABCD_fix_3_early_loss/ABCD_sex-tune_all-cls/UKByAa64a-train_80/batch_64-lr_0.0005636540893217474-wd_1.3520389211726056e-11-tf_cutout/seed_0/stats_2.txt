"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 61.99858474731445, "training_acc": 42.5, "val_loss": 20.310819149017334, "val_acc": 50.0, "val_auroc": 0.56, "time": 19.53}
{"epoch": 1, "training_loss": 147.53270721435547, "training_acc": 52.5, "val_loss": 13.917783498764038, "val_acc": 50.0, "val_auroc": 0.42, "time": 37.62}
{"epoch": 2, "training_loss": 58.07915496826172, "training_acc": 50.0, "val_loss": 14.630602598190308, "val_acc": 50.0, "val_auroc": 0.4, "time": 55.48}
{"epoch": 3, "training_loss": 57.62868690490723, "training_acc": 52.5, "val_loss": 14.984196424484253, "val_acc": 50.0, "val_auroc": 0.38, "time": 73.33}
{"epoch": 4, "training_loss": 58.054311752319336, "training_acc": 52.5, "val_loss": 13.901095390319824, "val_acc": 50.0, "val_auroc": 0.67, "time": 91.37}
{"epoch": 5, "training_loss": 55.85124588012695, "training_acc": 50.0, "val_loss": 14.48223352432251, "val_acc": 50.0, "val_auroc": 0.3, "time": 108.88}
{"epoch": 6, "training_loss": 58.759132385253906, "training_acc": 45.0, "val_loss": 13.971599340438843, "val_acc": 50.0, "val_auroc": 0.3, "time": 126.39}
{"epoch": 7, "training_loss": 55.41166305541992, "training_acc": 52.5, "val_loss": 14.11807894706726, "val_acc": 50.0, "val_auroc": 0.29, "time": 143.61}
{"epoch": 8, "training_loss": 55.74814987182617, "training_acc": 52.5, "val_loss": 13.891518115997314, "val_acc": 50.0, "val_auroc": 0.27, "time": 160.62}
{"epoch": 9, "training_loss": 55.572773933410645, "training_acc": 45.0, "val_loss": 13.93765926361084, "val_acc": 50.0, "val_auroc": 0.5, "time": 177.55}
{"epoch": 10, "training_loss": 55.93787479400635, "training_acc": 47.5, "val_loss": 13.932443857192993, "val_acc": 50.0, "val_auroc": 0.39, "time": 194.91}
{"epoch": 11, "training_loss": 55.269803047180176, "training_acc": 52.5, "val_loss": 14.560877084732056, "val_acc": 50.0, "val_auroc": 0.29, "time": 212.1}
{"epoch": 12, "training_loss": 56.77882385253906, "training_acc": 52.5, "val_loss": 13.90928030014038, "val_acc": 50.0, "val_auroc": 0.74, "time": 229.28}
{"epoch": 13, "training_loss": 55.31607246398926, "training_acc": 52.5, "val_loss": 13.836183547973633, "val_acc": 50.0, "val_auroc": 0.74, "time": 247.36}
{"epoch": 14, "training_loss": 55.54213523864746, "training_acc": 47.5, "val_loss": 13.836853504180908, "val_acc": 50.0, "val_auroc": 0.75, "time": 264.53}
{"epoch": 15, "training_loss": 55.47574996948242, "training_acc": 50.0, "val_loss": 13.908134698867798, "val_acc": 50.0, "val_auroc": 0.51, "time": 281.57}
{"epoch": 16, "training_loss": 55.25895309448242, "training_acc": 52.5, "val_loss": 14.109781980514526, "val_acc": 50.0, "val_auroc": 0.36, "time": 299.14}
{"epoch": 17, "training_loss": 55.900278091430664, "training_acc": 52.5, "val_loss": 14.192355871200562, "val_acc": 50.0, "val_auroc": 0.42, "time": 315.86}
{"epoch": 18, "training_loss": 55.91900825500488, "training_acc": 52.5, "val_loss": 13.935905694961548, "val_acc": 50.0, "val_auroc": 0.85, "time": 332.71}
{"epoch": 19, "training_loss": 55.25056171417236, "training_acc": 52.5, "val_loss": 13.868632316589355, "val_acc": 50.0, "val_auroc": 0.75, "time": 349.79}
{"epoch": 20, "training_loss": 55.72093391418457, "training_acc": 47.5, "val_loss": 13.906030654907227, "val_acc": 50.0, "val_auroc": 0.74, "time": 365.91}
{"epoch": 21, "training_loss": 55.866790771484375, "training_acc": 47.5, "val_loss": 13.854144811630249, "val_acc": 50.0, "val_auroc": 0.76, "time": 381.35}
{"epoch": 22, "training_loss": 55.44364547729492, "training_acc": 50.0, "val_loss": 13.884503841400146, "val_acc": 50.0, "val_auroc": 0.81, "time": 398.04}
{"epoch": 23, "training_loss": 55.27693176269531, "training_acc": 52.5, "val_loss": 13.998802900314331, "val_acc": 50.0, "val_auroc": 0.81, "time": 415.8}
{"epoch": 24, "training_loss": 55.50345420837402, "training_acc": 52.5, "val_loss": 14.125797748565674, "val_acc": 50.0, "val_auroc": 0.81, "time": 430.71}
{"epoch": 25, "training_loss": 55.86068916320801, "training_acc": 52.5, "val_loss": 14.126075506210327, "val_acc": 50.0, "val_auroc": 0.75, "time": 447.54}
{"epoch": 26, "training_loss": 55.98134422302246, "training_acc": 52.5, "val_loss": 14.045685529708862, "val_acc": 50.0, "val_auroc": 0.68, "time": 464.31}
{"epoch": 27, "training_loss": 55.629852294921875, "training_acc": 52.5, "val_loss": 14.00905966758728, "val_acc": 50.0, "val_auroc": 0.63, "time": 482.56}
{"epoch": 28, "training_loss": 55.52959442138672, "training_acc": 52.5, "val_loss": 13.903521299362183, "val_acc": 50.0, "val_auroc": 0.74, "time": 499.68}
{"epoch": 29, "training_loss": 55.41447925567627, "training_acc": 52.5, "val_loss": 13.861558437347412, "val_acc": 50.0, "val_auroc": 0.65, "time": 516.39}
{"epoch": 30, "training_loss": 55.50039291381836, "training_acc": 47.5, "val_loss": 13.86128306388855, "val_acc": 50.0, "val_auroc": 0.72, "time": 533.53}
{"epoch": 31, "training_loss": 55.531639099121094, "training_acc": 45.0, "val_loss": 13.855561017990112, "val_acc": 50.0, "val_auroc": 0.8, "time": 550.17}
{"epoch": 32, "training_loss": 55.446577072143555, "training_acc": 52.5, "val_loss": 13.853733539581299, "val_acc": 50.0, "val_auroc": 0.78, "time": 566.75}
