"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.8538761138916, "training_acc": 52.5, "val_loss": 13.952429294586182, "val_acc": 50.0, "val_auroc": 0.27, "time": 16.87}
{"epoch": 1, "training_loss": 55.620901107788086, "training_acc": 47.5, "val_loss": 13.924260139465332, "val_acc": 50.0, "val_auroc": 0.48, "time": 32.3}
{"epoch": 2, "training_loss": 55.45651817321777, "training_acc": 52.5, "val_loss": 13.908137083053589, "val_acc": 50.0, "val_auroc": 0.63, "time": 47.41}
{"epoch": 3, "training_loss": 55.5215539932251, "training_acc": 52.5, "val_loss": 14.032952785491943, "val_acc": 50.0, "val_auroc": 0.61, "time": 62.61}
{"epoch": 4, "training_loss": 55.58343505859375, "training_acc": 52.5, "val_loss": 13.900924921035767, "val_acc": 50.0, "val_auroc": 0.42, "time": 77.69}
{"epoch": 5, "training_loss": 55.41776657104492, "training_acc": 52.5, "val_loss": 13.888882398605347, "val_acc": 50.0, "val_auroc": 0.47, "time": 92.47}
{"epoch": 6, "training_loss": 55.44493007659912, "training_acc": 52.5, "val_loss": 14.012484550476074, "val_acc": 50.0, "val_auroc": 0.79, "time": 107.41}
{"epoch": 7, "training_loss": 55.5720100402832, "training_acc": 52.5, "val_loss": 14.098938703536987, "val_acc": 50.0, "val_auroc": 0.76, "time": 121.87}
{"epoch": 8, "training_loss": 55.78758430480957, "training_acc": 52.5, "val_loss": 13.917782306671143, "val_acc": 50.0, "val_auroc": 0.47, "time": 138.59}
{"epoch": 9, "training_loss": 55.3364372253418, "training_acc": 52.5, "val_loss": 13.86919617652893, "val_acc": 50.0, "val_auroc": 0.56, "time": 153.57}
{"epoch": 10, "training_loss": 55.626060485839844, "training_acc": 47.5, "val_loss": 13.86752724647522, "val_acc": 50.0, "val_auroc": 0.59, "time": 168.91}
{"epoch": 11, "training_loss": 55.478572845458984, "training_acc": 47.5, "val_loss": 13.894131183624268, "val_acc": 50.0, "val_auroc": 0.65, "time": 183.14}
{"epoch": 12, "training_loss": 55.405083656311035, "training_acc": 52.5, "val_loss": 13.988964557647705, "val_acc": 50.0, "val_auroc": 0.3, "time": 197.31}
{"epoch": 13, "training_loss": 55.50552749633789, "training_acc": 52.5, "val_loss": 13.948761224746704, "val_acc": 50.0, "val_auroc": 0.28, "time": 212.05}
{"epoch": 14, "training_loss": 55.39653205871582, "training_acc": 52.5, "val_loss": 13.882195949554443, "val_acc": 50.0, "val_auroc": 0.29, "time": 228.45}
{"epoch": 15, "training_loss": 55.54170608520508, "training_acc": 52.5, "val_loss": 13.881772756576538, "val_acc": 50.0, "val_auroc": 0.43, "time": 243.06}
{"epoch": 16, "training_loss": 55.27446174621582, "training_acc": 52.5, "val_loss": 13.99128794670105, "val_acc": 50.0, "val_auroc": 0.56, "time": 257.81}
{"epoch": 17, "training_loss": 55.59009552001953, "training_acc": 52.5, "val_loss": 14.119032621383667, "val_acc": 50.0, "val_auroc": 0.21, "time": 272.45}
{"epoch": 18, "training_loss": 55.826738357543945, "training_acc": 52.5, "val_loss": 14.003549814224243, "val_acc": 50.0, "val_auroc": 0.24, "time": 286.44}
{"epoch": 19, "training_loss": 55.4189395904541, "training_acc": 52.5, "val_loss": 13.875149488449097, "val_acc": 50.0, "val_auroc": 0.47, "time": 301.4}
{"epoch": 20, "training_loss": 55.43574333190918, "training_acc": 50.0, "val_loss": 13.868391513824463, "val_acc": 50.0, "val_auroc": 0.58, "time": 315.53}
{"epoch": 21, "training_loss": 55.568875312805176, "training_acc": 47.5, "val_loss": 13.86334776878357, "val_acc": 50.0, "val_auroc": 0.62, "time": 330.02}
{"epoch": 22, "training_loss": 55.45228958129883, "training_acc": 50.0, "val_loss": 13.87402892112732, "val_acc": 50.0, "val_auroc": 0.8, "time": 344.14}
{"epoch": 23, "training_loss": 55.309245109558105, "training_acc": 52.5, "val_loss": 13.939114809036255, "val_acc": 50.0, "val_auroc": 0.67, "time": 358.58}
{"epoch": 24, "training_loss": 55.36532783508301, "training_acc": 52.5, "val_loss": 14.058293104171753, "val_acc": 50.0, "val_auroc": 0.64, "time": 372.86}
{"epoch": 25, "training_loss": 55.68001747131348, "training_acc": 52.5, "val_loss": 14.130171537399292, "val_acc": 50.0, "val_auroc": 0.46, "time": 387.3}
{"epoch": 26, "training_loss": 55.92473888397217, "training_acc": 52.5, "val_loss": 14.122211933135986, "val_acc": 50.0, "val_auroc": 0.41, "time": 401.82}
{"epoch": 27, "training_loss": 55.84264659881592, "training_acc": 52.5, "val_loss": 14.089231491088867, "val_acc": 50.0, "val_auroc": 0.34, "time": 416.58}
{"epoch": 28, "training_loss": 55.70586585998535, "training_acc": 52.5, "val_loss": 13.939003944396973, "val_acc": 50.0, "val_auroc": 0.2, "time": 431.59}
{"epoch": 29, "training_loss": 55.45714092254639, "training_acc": 52.5, "val_loss": 13.862950801849365, "val_acc": 50.0, "val_auroc": 0.75, "time": 448.99}
{"epoch": 30, "training_loss": 55.477657318115234, "training_acc": 50.0, "val_loss": 13.868087530136108, "val_acc": 50.0, "val_auroc": 0.45, "time": 463.6}
{"epoch": 31, "training_loss": 55.57370662689209, "training_acc": 47.5, "val_loss": 13.867597579956055, "val_acc": 50.0, "val_auroc": 0.77, "time": 478.78}
{"epoch": 32, "training_loss": 55.56987190246582, "training_acc": 47.5, "val_loss": 13.868482112884521, "val_acc": 50.0, "val_auroc": 0.42, "time": 493.7}
{"epoch": 33, "training_loss": 55.56357765197754, "training_acc": 47.5, "val_loss": 13.865939378738403, "val_acc": 50.0, "val_auroc": 0.35, "time": 508.55}
{"epoch": 34, "training_loss": 55.50594520568848, "training_acc": 47.5, "val_loss": 13.869163990020752, "val_acc": 50.0, "val_auroc": 0.21, "time": 523.17}
{"epoch": 35, "training_loss": 55.55128288269043, "training_acc": 52.5, "val_loss": 13.89175295829773, "val_acc": 50.0, "val_auroc": 0.17, "time": 538.44}
{"epoch": 36, "training_loss": 55.349141120910645, "training_acc": 52.5, "val_loss": 13.883132934570312, "val_acc": 50.0, "val_auroc": 0.16, "time": 554.11}
{"epoch": 37, "training_loss": 55.353675842285156, "training_acc": 52.5, "val_loss": 13.871567249298096, "val_acc": 50.0, "val_auroc": 0.21, "time": 568.85}
{"epoch": 38, "training_loss": 55.429938316345215, "training_acc": 52.5, "val_loss": 13.868237733840942, "val_acc": 50.0, "val_auroc": 0.21, "time": 584.11}
{"epoch": 39, "training_loss": 55.39014720916748, "training_acc": 52.5, "val_loss": 13.880795240402222, "val_acc": 50.0, "val_auroc": 0.19, "time": 598.59}
{"epoch": 40, "training_loss": 55.42637634277344, "training_acc": 52.5, "val_loss": 13.878659009933472, "val_acc": 50.0, "val_auroc": 0.18, "time": 613.52}
{"epoch": 41, "training_loss": 55.332600593566895, "training_acc": 52.5, "val_loss": 13.863904476165771, "val_acc": 50.0, "val_auroc": 0.25, "time": 627.92}
{"epoch": 42, "training_loss": 55.51072692871094, "training_acc": 47.5, "val_loss": 13.864105939865112, "val_acc": 50.0, "val_auroc": 0.29, "time": 642.98}
{"epoch": 43, "training_loss": 55.479801177978516, "training_acc": 47.5, "val_loss": 13.866225481033325, "val_acc": 50.0, "val_auroc": 0.23, "time": 657.69}
{"epoch": 44, "training_loss": 55.40530872344971, "training_acc": 52.5, "val_loss": 13.877761363983154, "val_acc": 50.0, "val_auroc": 0.24, "time": 671.99}
{"epoch": 45, "training_loss": 55.36513328552246, "training_acc": 52.5, "val_loss": 13.89078140258789, "val_acc": 50.0, "val_auroc": 0.22, "time": 686.93}
{"epoch": 46, "training_loss": 55.349863052368164, "training_acc": 52.5, "val_loss": 13.903310298919678, "val_acc": 50.0, "val_auroc": 0.22, "time": 701.33}
{"epoch": 47, "training_loss": 55.36573028564453, "training_acc": 52.5, "val_loss": 13.913607597351074, "val_acc": 50.0, "val_auroc": 0.23, "time": 716.0}
{"epoch": 48, "training_loss": 55.41722869873047, "training_acc": 52.5, "val_loss": 13.929857015609741, "val_acc": 50.0, "val_auroc": 0.26, "time": 731.15}
