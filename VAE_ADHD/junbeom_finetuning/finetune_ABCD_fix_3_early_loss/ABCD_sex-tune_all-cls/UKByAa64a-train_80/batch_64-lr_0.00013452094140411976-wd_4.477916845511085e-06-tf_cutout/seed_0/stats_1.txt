"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.76500225067139, "training_acc": 43.75, "val_loss": 13.819987773895264, "val_acc": 50.0, "val_auroc": 0.49, "time": 16.25}
{"epoch": 1, "training_loss": 54.56135082244873, "training_acc": 56.25, "val_loss": 14.715871810913086, "val_acc": 50.0, "val_auroc": 0.48, "time": 30.38}
{"epoch": 2, "training_loss": 57.630048751831055, "training_acc": 50.0, "val_loss": 13.804359436035156, "val_acc": 50.0, "val_auroc": 0.75, "time": 45.63}
{"epoch": 3, "training_loss": 55.85366439819336, "training_acc": 47.5, "val_loss": 13.798564672470093, "val_acc": 50.0, "val_auroc": 0.75, "time": 61.29}
{"epoch": 4, "training_loss": 55.25456619262695, "training_acc": 52.5, "val_loss": 13.804572820663452, "val_acc": 50.0, "val_auroc": 0.7, "time": 78.6}
{"epoch": 5, "training_loss": 55.031341552734375, "training_acc": 56.25, "val_loss": 14.069757461547852, "val_acc": 50.0, "val_auroc": 0.69, "time": 93.57}
{"epoch": 6, "training_loss": 56.51832389831543, "training_acc": 52.5, "val_loss": 14.277428388595581, "val_acc": 50.0, "val_auroc": 0.7, "time": 108.12}
{"epoch": 7, "training_loss": 56.27379322052002, "training_acc": 52.5, "val_loss": 14.017025232315063, "val_acc": 50.0, "val_auroc": 0.68, "time": 123.03}
{"epoch": 8, "training_loss": 55.36594104766846, "training_acc": 52.5, "val_loss": 13.879218101501465, "val_acc": 50.0, "val_auroc": 0.74, "time": 138.0}
{"epoch": 9, "training_loss": 55.756431579589844, "training_acc": 47.5, "val_loss": 13.861507177352905, "val_acc": 50.0, "val_auroc": 0.74, "time": 153.05}
{"epoch": 10, "training_loss": 55.55806922912598, "training_acc": 47.5, "val_loss": 13.87865424156189, "val_acc": 50.0, "val_auroc": 0.78, "time": 168.23}
{"epoch": 11, "training_loss": 55.19573783874512, "training_acc": 52.5, "val_loss": 14.130079746246338, "val_acc": 50.0, "val_auroc": 0.86, "time": 182.79}
{"epoch": 12, "training_loss": 55.821353912353516, "training_acc": 52.5, "val_loss": 13.882861137390137, "val_acc": 50.0, "val_auroc": 0.86, "time": 199.21}
{"epoch": 13, "training_loss": 55.42118835449219, "training_acc": 52.5, "val_loss": 13.792389631271362, "val_acc": 50.0, "val_auroc": 0.74, "time": 214.4}
{"epoch": 14, "training_loss": 55.145111083984375, "training_acc": 52.5, "val_loss": 13.998091220855713, "val_acc": 50.0, "val_auroc": 0.72, "time": 230.0}
{"epoch": 15, "training_loss": 55.48019218444824, "training_acc": 52.5, "val_loss": 14.272894859313965, "val_acc": 50.0, "val_auroc": 0.77, "time": 244.87}
{"epoch": 16, "training_loss": 56.31792449951172, "training_acc": 52.5, "val_loss": 14.155508279800415, "val_acc": 50.0, "val_auroc": 0.76, "time": 260.3}
{"epoch": 17, "training_loss": 55.74612045288086, "training_acc": 52.5, "val_loss": 13.863857984542847, "val_acc": 50.0, "val_auroc": 0.68, "time": 275.56}
{"epoch": 18, "training_loss": 55.131890296936035, "training_acc": 52.5, "val_loss": 13.889092206954956, "val_acc": 50.0, "val_auroc": 0.7, "time": 290.63}
{"epoch": 19, "training_loss": 55.80068397521973, "training_acc": 47.5, "val_loss": 13.945856094360352, "val_acc": 50.0, "val_auroc": 0.74, "time": 305.4}
{"epoch": 20, "training_loss": 56.123167991638184, "training_acc": 47.5, "val_loss": 13.861268758773804, "val_acc": 50.0, "val_auroc": 0.75, "time": 321.0}
{"epoch": 21, "training_loss": 55.44903373718262, "training_acc": 47.5, "val_loss": 13.854767084121704, "val_acc": 50.0, "val_auroc": 0.74, "time": 336.08}
{"epoch": 22, "training_loss": 55.13682270050049, "training_acc": 52.5, "val_loss": 14.127017259597778, "val_acc": 50.0, "val_auroc": 0.73, "time": 351.09}
{"epoch": 23, "training_loss": 55.78241729736328, "training_acc": 52.5, "val_loss": 14.156774282455444, "val_acc": 50.0, "val_auroc": 0.7, "time": 365.71}
{"epoch": 24, "training_loss": 55.82330799102783, "training_acc": 52.5, "val_loss": 13.946466445922852, "val_acc": 50.0, "val_auroc": 0.63, "time": 383.83}
{"epoch": 25, "training_loss": 55.312875747680664, "training_acc": 52.5, "val_loss": 13.818744421005249, "val_acc": 50.0, "val_auroc": 0.69, "time": 399.07}
{"epoch": 26, "training_loss": 55.152732849121094, "training_acc": 57.5, "val_loss": 13.803036212921143, "val_acc": 50.0, "val_auroc": 0.71, "time": 413.88}
{"epoch": 27, "training_loss": 55.081478118896484, "training_acc": 53.75, "val_loss": 13.825069665908813, "val_acc": 50.0, "val_auroc": 0.71, "time": 428.68}
{"epoch": 28, "training_loss": 55.409969329833984, "training_acc": 52.5, "val_loss": 13.754421472549438, "val_acc": 50.0, "val_auroc": 0.74, "time": 443.15}
{"epoch": 29, "training_loss": 55.01710510253906, "training_acc": 50.0, "val_loss": 13.771393299102783, "val_acc": 50.0, "val_auroc": 0.73, "time": 457.48}
{"epoch": 30, "training_loss": 55.101736068725586, "training_acc": 50.0, "val_loss": 13.780457973480225, "val_acc": 50.0, "val_auroc": 0.71, "time": 471.63}
{"epoch": 31, "training_loss": 54.88324451446533, "training_acc": 52.5, "val_loss": 13.967126607894897, "val_acc": 50.0, "val_auroc": 0.73, "time": 486.37}
{"epoch": 32, "training_loss": 55.39867115020752, "training_acc": 52.5, "val_loss": 13.917560577392578, "val_acc": 50.0, "val_auroc": 0.7, "time": 500.38}
{"epoch": 33, "training_loss": 55.25099182128906, "training_acc": 52.5, "val_loss": 13.812670707702637, "val_acc": 50.0, "val_auroc": 0.66, "time": 514.35}
{"epoch": 34, "training_loss": 55.224931716918945, "training_acc": 55.0, "val_loss": 13.812932968139648, "val_acc": 50.0, "val_auroc": 0.65, "time": 528.73}
{"epoch": 35, "training_loss": 55.40473747253418, "training_acc": 48.75, "val_loss": 13.810847997665405, "val_acc": 50.0, "val_auroc": 0.64, "time": 543.06}
{"epoch": 36, "training_loss": 55.1361026763916, "training_acc": 47.5, "val_loss": 13.929318189620972, "val_acc": 50.0, "val_auroc": 0.61, "time": 557.88}
{"epoch": 37, "training_loss": 55.95223331451416, "training_acc": 47.5, "val_loss": 13.996254205703735, "val_acc": 50.0, "val_auroc": 0.6, "time": 572.9}
{"epoch": 38, "training_loss": 56.05314922332764, "training_acc": 47.5, "val_loss": 13.76876950263977, "val_acc": 50.0, "val_auroc": 0.67, "time": 588.3}
{"epoch": 39, "training_loss": 55.16773223876953, "training_acc": 51.25, "val_loss": 13.839415311813354, "val_acc": 50.0, "val_auroc": 0.75, "time": 603.77}
{"epoch": 40, "training_loss": 55.100314140319824, "training_acc": 52.5, "val_loss": 13.910530805587769, "val_acc": 50.0, "val_auroc": 0.82, "time": 618.64}
{"epoch": 41, "training_loss": 55.26703643798828, "training_acc": 52.5, "val_loss": 13.84989857673645, "val_acc": 50.0, "val_auroc": 0.85, "time": 633.75}
{"epoch": 42, "training_loss": 55.164536476135254, "training_acc": 52.5, "val_loss": 13.807052373886108, "val_acc": 50.0, "val_auroc": 0.84, "time": 649.93}
{"epoch": 43, "training_loss": 55.18595314025879, "training_acc": 58.75, "val_loss": 13.803564310073853, "val_acc": 50.0, "val_auroc": 0.83, "time": 666.15}
{"epoch": 44, "training_loss": 55.231032371520996, "training_acc": 60.0, "val_loss": 13.789236545562744, "val_acc": 50.0, "val_auroc": 0.84, "time": 681.46}
{"epoch": 45, "training_loss": 55.13327598571777, "training_acc": 58.75, "val_loss": 13.782573938369751, "val_acc": 50.0, "val_auroc": 0.83, "time": 698.24}
{"epoch": 46, "training_loss": 54.96732044219971, "training_acc": 52.5, "val_loss": 13.79780888557434, "val_acc": 50.0, "val_auroc": 0.83, "time": 712.88}
{"epoch": 47, "training_loss": 54.90046691894531, "training_acc": 52.5, "val_loss": 13.866140842437744, "val_acc": 50.0, "val_auroc": 0.83, "time": 727.31}
