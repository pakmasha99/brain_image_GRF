"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.20174980163574, "training_acc": 45.0, "val_loss": 13.838127851486206, "val_acc": 50.0, "val_auroc": 0.57, "time": 16.35}
{"epoch": 1, "training_loss": 55.291810035705566, "training_acc": 47.5, "val_loss": 112.8642749786377, "val_acc": 50.0, "val_auroc": 0.42, "time": 31.23}
{"epoch": 2, "training_loss": 344.4303741455078, "training_acc": 52.5, "val_loss": 13.958364725112915, "val_acc": 50.0, "val_auroc": 0.61, "time": 46.03}
{"epoch": 3, "training_loss": 56.18954563140869, "training_acc": 48.75, "val_loss": 13.83176565170288, "val_acc": 50.0, "val_auroc": 0.63, "time": 61.14}
{"epoch": 4, "training_loss": 55.435462951660156, "training_acc": 52.5, "val_loss": 13.952858448028564, "val_acc": 50.0, "val_auroc": 0.55, "time": 76.02}
{"epoch": 5, "training_loss": 55.700074195861816, "training_acc": 50.0, "val_loss": 14.176437854766846, "val_acc": 50.0, "val_auroc": 0.57, "time": 91.53}
{"epoch": 6, "training_loss": 58.77847480773926, "training_acc": 52.5, "val_loss": 14.306507110595703, "val_acc": 50.0, "val_auroc": 0.58, "time": 107.02}
{"epoch": 7, "training_loss": 56.585853576660156, "training_acc": 52.5, "val_loss": 14.038351774215698, "val_acc": 50.0, "val_auroc": 0.62, "time": 122.68}
{"epoch": 8, "training_loss": 55.5119686126709, "training_acc": 52.5, "val_loss": 14.062777757644653, "val_acc": 50.0, "val_auroc": 0.59, "time": 136.58}
{"epoch": 9, "training_loss": 56.73486614227295, "training_acc": 47.5, "val_loss": 13.820966482162476, "val_acc": 50.0, "val_auroc": 0.62, "time": 153.25}
{"epoch": 10, "training_loss": 55.352352142333984, "training_acc": 48.75, "val_loss": 13.934725522994995, "val_acc": 50.0, "val_auroc": 0.64, "time": 167.34}
{"epoch": 11, "training_loss": 55.439106941223145, "training_acc": 52.5, "val_loss": 14.000303745269775, "val_acc": 50.0, "val_auroc": 0.65, "time": 181.37}
{"epoch": 12, "training_loss": 55.58505821228027, "training_acc": 52.5, "val_loss": 13.774389028549194, "val_acc": 50.0, "val_auroc": 0.61, "time": 195.86}
{"epoch": 13, "training_loss": 55.29443645477295, "training_acc": 48.75, "val_loss": 13.823201656341553, "val_acc": 50.0, "val_auroc": 0.61, "time": 210.15}
{"epoch": 14, "training_loss": 55.05531024932861, "training_acc": 52.5, "val_loss": 14.43308711051941, "val_acc": 50.0, "val_auroc": 0.61, "time": 225.0}
{"epoch": 15, "training_loss": 56.947142601013184, "training_acc": 52.5, "val_loss": 14.443114995956421, "val_acc": 50.0, "val_auroc": 0.62, "time": 239.61}
{"epoch": 16, "training_loss": 56.980146408081055, "training_acc": 52.5, "val_loss": 13.93454909324646, "val_acc": 50.0, "val_auroc": 0.59, "time": 254.21}
{"epoch": 17, "training_loss": 55.1551628112793, "training_acc": 52.5, "val_loss": 13.831466436386108, "val_acc": 50.0, "val_auroc": 0.59, "time": 268.88}
{"epoch": 18, "training_loss": 55.506797790527344, "training_acc": 47.5, "val_loss": 13.947242498397827, "val_acc": 50.0, "val_auroc": 0.57, "time": 283.14}
{"epoch": 19, "training_loss": 56.211323738098145, "training_acc": 47.5, "val_loss": 13.824156522750854, "val_acc": 50.0, "val_auroc": 0.63, "time": 297.53}
{"epoch": 20, "training_loss": 55.44840908050537, "training_acc": 50.0, "val_loss": 13.79767656326294, "val_acc": 50.0, "val_auroc": 0.64, "time": 312.04}
{"epoch": 21, "training_loss": 55.106985092163086, "training_acc": 60.0, "val_loss": 13.857015371322632, "val_acc": 50.0, "val_auroc": 0.6, "time": 326.46}
{"epoch": 22, "training_loss": 55.1807222366333, "training_acc": 52.5, "val_loss": 14.035015106201172, "val_acc": 50.0, "val_auroc": 0.61, "time": 340.64}
{"epoch": 23, "training_loss": 55.560556411743164, "training_acc": 52.5, "val_loss": 14.074673652648926, "val_acc": 50.0, "val_auroc": 0.61, "time": 354.66}
{"epoch": 24, "training_loss": 55.69114112854004, "training_acc": 52.5, "val_loss": 13.96191954612732, "val_acc": 50.0, "val_auroc": 0.59, "time": 368.69}
{"epoch": 25, "training_loss": 55.39421463012695, "training_acc": 52.5, "val_loss": 13.823449611663818, "val_acc": 50.0, "val_auroc": 0.6, "time": 382.52}
{"epoch": 26, "training_loss": 55.08711051940918, "training_acc": 53.75, "val_loss": 13.793859481811523, "val_acc": 50.0, "val_auroc": 0.62, "time": 397.44}
{"epoch": 27, "training_loss": 55.17170333862305, "training_acc": 52.5, "val_loss": 13.79052996635437, "val_acc": 50.0, "val_auroc": 0.63, "time": 412.17}
{"epoch": 28, "training_loss": 55.338430404663086, "training_acc": 52.5, "val_loss": 13.777710199356079, "val_acc": 50.0, "val_auroc": 0.63, "time": 426.21}
{"epoch": 29, "training_loss": 55.05998420715332, "training_acc": 48.75, "val_loss": 13.810529708862305, "val_acc": 50.0, "val_auroc": 0.62, "time": 440.68}
{"epoch": 30, "training_loss": 55.139183044433594, "training_acc": 48.75, "val_loss": 13.792389631271362, "val_acc": 50.0, "val_auroc": 0.61, "time": 457.69}
{"epoch": 31, "training_loss": 54.883039474487305, "training_acc": 56.25, "val_loss": 13.996857404708862, "val_acc": 50.0, "val_auroc": 0.63, "time": 472.05}
