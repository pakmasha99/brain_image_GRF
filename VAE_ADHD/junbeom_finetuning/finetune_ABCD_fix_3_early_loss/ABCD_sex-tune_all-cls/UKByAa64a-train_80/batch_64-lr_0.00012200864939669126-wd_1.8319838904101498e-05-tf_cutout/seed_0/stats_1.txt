"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.53500175476074, "training_acc": 52.5, "val_loss": 13.878109455108643, "val_acc": 50.0, "val_auroc": 0.55, "time": 19.03}
{"epoch": 1, "training_loss": 55.34996032714844, "training_acc": 52.5, "val_loss": 13.887068033218384, "val_acc": 50.0, "val_auroc": 0.54, "time": 36.84}
{"epoch": 2, "training_loss": 55.3252534866333, "training_acc": 52.5, "val_loss": 13.877182006835938, "val_acc": 50.0, "val_auroc": 0.63, "time": 55.42}
{"epoch": 3, "training_loss": 55.36578369140625, "training_acc": 52.5, "val_loss": 13.877321481704712, "val_acc": 50.0, "val_auroc": 0.56, "time": 74.02}
{"epoch": 4, "training_loss": 55.328481674194336, "training_acc": 52.5, "val_loss": 13.881206512451172, "val_acc": 50.0, "val_auroc": 0.33, "time": 90.85}
{"epoch": 5, "training_loss": 55.4107141494751, "training_acc": 52.5, "val_loss": 13.897103071212769, "val_acc": 50.0, "val_auroc": 0.49, "time": 107.23}
{"epoch": 6, "training_loss": 55.35868263244629, "training_acc": 52.5, "val_loss": 13.887075185775757, "val_acc": 50.0, "val_auroc": 0.56, "time": 123.28}
{"epoch": 7, "training_loss": 55.36767864227295, "training_acc": 52.5, "val_loss": 13.885413408279419, "val_acc": 50.0, "val_auroc": 0.62, "time": 139.58}
{"epoch": 8, "training_loss": 55.34924602508545, "training_acc": 52.5, "val_loss": 13.893188238143921, "val_acc": 50.0, "val_auroc": 0.7, "time": 155.47}
{"epoch": 9, "training_loss": 55.341915130615234, "training_acc": 52.5, "val_loss": 13.856819868087769, "val_acc": 50.0, "val_auroc": 0.72, "time": 171.67}
{"epoch": 10, "training_loss": 55.4482364654541, "training_acc": 50.0, "val_loss": 13.859788179397583, "val_acc": 50.0, "val_auroc": 0.59, "time": 187.44}
{"epoch": 11, "training_loss": 55.36208915710449, "training_acc": 52.5, "val_loss": 13.895654678344727, "val_acc": 50.0, "val_auroc": 0.67, "time": 204.09}
{"epoch": 12, "training_loss": 55.32553482055664, "training_acc": 52.5, "val_loss": 13.964203596115112, "val_acc": 50.0, "val_auroc": 0.7, "time": 219.54}
{"epoch": 13, "training_loss": 55.47254467010498, "training_acc": 52.5, "val_loss": 14.001070261001587, "val_acc": 50.0, "val_auroc": 0.79, "time": 234.98}
{"epoch": 14, "training_loss": 55.60238552093506, "training_acc": 52.5, "val_loss": 14.078466892242432, "val_acc": 50.0, "val_auroc": 0.8, "time": 250.58}
{"epoch": 15, "training_loss": 55.738667488098145, "training_acc": 52.5, "val_loss": 14.146158695220947, "val_acc": 50.0, "val_auroc": 0.79, "time": 265.59}
{"epoch": 16, "training_loss": 55.93793296813965, "training_acc": 52.5, "val_loss": 14.111862182617188, "val_acc": 50.0, "val_auroc": 0.81, "time": 281.01}
{"epoch": 17, "training_loss": 55.78423309326172, "training_acc": 52.5, "val_loss": 13.969372510910034, "val_acc": 50.0, "val_auroc": 0.72, "time": 296.72}
{"epoch": 18, "training_loss": 55.40148735046387, "training_acc": 52.5, "val_loss": 13.86478066444397, "val_acc": 50.0, "val_auroc": 0.6, "time": 313.98}
{"epoch": 19, "training_loss": 55.31704330444336, "training_acc": 52.5, "val_loss": 13.875154256820679, "val_acc": 50.0, "val_auroc": 0.62, "time": 329.41}
{"epoch": 20, "training_loss": 55.676859855651855, "training_acc": 47.5, "val_loss": 13.902113437652588, "val_acc": 50.0, "val_auroc": 0.6, "time": 345.43}
{"epoch": 21, "training_loss": 55.828704833984375, "training_acc": 47.5, "val_loss": 13.85953426361084, "val_acc": 50.0, "val_auroc": 0.62, "time": 361.07}
{"epoch": 22, "training_loss": 55.408753395080566, "training_acc": 50.0, "val_loss": 13.914750814437866, "val_acc": 50.0, "val_auroc": 0.71, "time": 376.63}
{"epoch": 23, "training_loss": 55.32147979736328, "training_acc": 52.5, "val_loss": 14.023882150650024, "val_acc": 50.0, "val_auroc": 0.8, "time": 392.4}
{"epoch": 24, "training_loss": 55.596391677856445, "training_acc": 52.5, "val_loss": 14.068870544433594, "val_acc": 50.0, "val_auroc": 0.79, "time": 408.44}
{"epoch": 25, "training_loss": 55.695054054260254, "training_acc": 52.5, "val_loss": 14.002219438552856, "val_acc": 50.0, "val_auroc": 0.82, "time": 425.11}
{"epoch": 26, "training_loss": 55.54968070983887, "training_acc": 52.5, "val_loss": 13.929661512374878, "val_acc": 50.0, "val_auroc": 0.72, "time": 442.55}
{"epoch": 27, "training_loss": 55.40730381011963, "training_acc": 52.5, "val_loss": 13.898524045944214, "val_acc": 50.0, "val_auroc": 0.58, "time": 457.78}
{"epoch": 28, "training_loss": 55.438880920410156, "training_acc": 52.5, "val_loss": 13.870728015899658, "val_acc": 50.0, "val_auroc": 0.51, "time": 473.03}
