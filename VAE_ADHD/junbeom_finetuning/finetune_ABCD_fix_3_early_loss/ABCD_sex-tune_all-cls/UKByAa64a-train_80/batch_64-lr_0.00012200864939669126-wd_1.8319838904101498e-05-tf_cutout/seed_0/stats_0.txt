"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.6147346496582, "training_acc": 52.5, "val_loss": 13.901615142822266, "val_acc": 50.0, "val_auroc": 0.43, "time": 19.14}
{"epoch": 1, "training_loss": 55.382856369018555, "training_acc": 53.75, "val_loss": 13.89986276626587, "val_acc": 50.0, "val_auroc": 0.53, "time": 35.29}
{"epoch": 2, "training_loss": 55.36030578613281, "training_acc": 52.5, "val_loss": 13.862764835357666, "val_acc": 50.0, "val_auroc": 0.64, "time": 52.26}
{"epoch": 3, "training_loss": 55.38018989562988, "training_acc": 52.5, "val_loss": 13.864736557006836, "val_acc": 50.0, "val_auroc": 0.63, "time": 71.38}
{"epoch": 4, "training_loss": 55.37466812133789, "training_acc": 52.5, "val_loss": 13.879467248916626, "val_acc": 50.0, "val_auroc": 0.4, "time": 89.47}
{"epoch": 5, "training_loss": 55.39429759979248, "training_acc": 52.5, "val_loss": 13.865479230880737, "val_acc": 50.0, "val_auroc": 0.47, "time": 107.26}
{"epoch": 6, "training_loss": 55.41997146606445, "training_acc": 61.25, "val_loss": 13.8645339012146, "val_acc": 50.0, "val_auroc": 0.52, "time": 123.15}
{"epoch": 7, "training_loss": 55.55137252807617, "training_acc": 45.0, "val_loss": 13.870495557785034, "val_acc": 50.0, "val_auroc": 0.39, "time": 140.07}
{"epoch": 8, "training_loss": 55.42356300354004, "training_acc": 52.5, "val_loss": 13.868173360824585, "val_acc": 50.0, "val_auroc": 0.44, "time": 155.58}
{"epoch": 9, "training_loss": 55.40060615539551, "training_acc": 52.5, "val_loss": 13.871532678604126, "val_acc": 50.0, "val_auroc": 0.58, "time": 172.01}
{"epoch": 10, "training_loss": 55.33494853973389, "training_acc": 52.5, "val_loss": 13.903716802597046, "val_acc": 50.0, "val_auroc": 0.56, "time": 188.47}
{"epoch": 11, "training_loss": 55.31070423126221, "training_acc": 52.5, "val_loss": 13.989924192428589, "val_acc": 50.0, "val_auroc": 0.61, "time": 205.58}
{"epoch": 12, "training_loss": 55.47469711303711, "training_acc": 52.5, "val_loss": 14.089230298995972, "val_acc": 50.0, "val_auroc": 0.59, "time": 224.38}
{"epoch": 13, "training_loss": 55.79841232299805, "training_acc": 52.5, "val_loss": 14.14041519165039, "val_acc": 50.0, "val_auroc": 0.57, "time": 243.47}
{"epoch": 14, "training_loss": 55.95437049865723, "training_acc": 52.5, "val_loss": 14.223794937133789, "val_acc": 50.0, "val_auroc": 0.54, "time": 260.4}
{"epoch": 15, "training_loss": 56.09663200378418, "training_acc": 52.5, "val_loss": 14.274181127548218, "val_acc": 50.0, "val_auroc": 0.57, "time": 278.46}
{"epoch": 16, "training_loss": 56.273277282714844, "training_acc": 52.5, "val_loss": 14.15387749671936, "val_acc": 50.0, "val_auroc": 0.56, "time": 295.08}
{"epoch": 17, "training_loss": 55.83028602600098, "training_acc": 52.5, "val_loss": 13.973015546798706, "val_acc": 50.0, "val_auroc": 0.54, "time": 311.77}
{"epoch": 18, "training_loss": 55.46175193786621, "training_acc": 52.5, "val_loss": 13.877419233322144, "val_acc": 50.0, "val_auroc": 0.58, "time": 331.37}
{"epoch": 19, "training_loss": 55.3170051574707, "training_acc": 52.5, "val_loss": 13.863147497177124, "val_acc": 50.0, "val_auroc": 0.54, "time": 349.58}
{"epoch": 20, "training_loss": 55.43923377990723, "training_acc": 47.5, "val_loss": 13.901971578598022, "val_acc": 50.0, "val_auroc": 0.53, "time": 367.26}
{"epoch": 21, "training_loss": 55.921523094177246, "training_acc": 47.5, "val_loss": 13.88043761253357, "val_acc": 50.0, "val_auroc": 0.56, "time": 386.12}
