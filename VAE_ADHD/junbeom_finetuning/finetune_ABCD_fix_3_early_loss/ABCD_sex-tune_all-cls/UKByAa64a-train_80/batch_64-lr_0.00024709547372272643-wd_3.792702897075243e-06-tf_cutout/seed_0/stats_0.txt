"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 58.502450942993164, "training_acc": 42.5, "val_loss": 13.941642045974731, "val_acc": 50.0, "val_auroc": 0.47, "time": 16.74}
{"epoch": 1, "training_loss": 62.12821006774902, "training_acc": 45.0, "val_loss": 13.8973867893219, "val_acc": 50.0, "val_auroc": 0.54, "time": 32.5}
{"epoch": 2, "training_loss": 55.538445472717285, "training_acc": 52.5, "val_loss": 13.836244344711304, "val_acc": 50.0, "val_auroc": 0.57, "time": 47.81}
{"epoch": 3, "training_loss": 56.856059074401855, "training_acc": 52.5, "val_loss": 14.222939014434814, "val_acc": 50.0, "val_auroc": 0.55, "time": 62.23}
{"epoch": 4, "training_loss": 57.42964839935303, "training_acc": 47.5, "val_loss": 13.92093539237976, "val_acc": 50.0, "val_auroc": 0.43, "time": 77.06}
{"epoch": 5, "training_loss": 55.803157806396484, "training_acc": 52.5, "val_loss": 13.87358546257019, "val_acc": 50.0, "val_auroc": 0.51, "time": 91.93}
{"epoch": 6, "training_loss": 55.339399337768555, "training_acc": 52.5, "val_loss": 13.925385475158691, "val_acc": 50.0, "val_auroc": 0.63, "time": 106.78}
{"epoch": 7, "training_loss": 56.142760276794434, "training_acc": 46.25, "val_loss": 13.863906860351562, "val_acc": 50.0, "val_auroc": 0.48, "time": 121.76}
{"epoch": 8, "training_loss": 55.42685031890869, "training_acc": 47.5, "val_loss": 13.8754403591156, "val_acc": 50.0, "val_auroc": 0.46, "time": 137.33}
{"epoch": 9, "training_loss": 55.31288719177246, "training_acc": 52.5, "val_loss": 13.875888586044312, "val_acc": 50.0, "val_auroc": 0.49, "time": 153.05}
{"epoch": 10, "training_loss": 55.28571701049805, "training_acc": 52.5, "val_loss": 13.913156986236572, "val_acc": 50.0, "val_auroc": 0.48, "time": 167.97}
{"epoch": 11, "training_loss": 55.29963779449463, "training_acc": 52.5, "val_loss": 14.17467713356018, "val_acc": 50.0, "val_auroc": 0.54, "time": 182.46}
{"epoch": 12, "training_loss": 55.90550708770752, "training_acc": 52.5, "val_loss": 14.203845262527466, "val_acc": 50.0, "val_auroc": 0.51, "time": 197.51}
{"epoch": 13, "training_loss": 56.20485782623291, "training_acc": 52.5, "val_loss": 14.070491790771484, "val_acc": 50.0, "val_auroc": 0.55, "time": 214.37}
{"epoch": 14, "training_loss": 55.83829116821289, "training_acc": 52.5, "val_loss": 14.179989099502563, "val_acc": 50.0, "val_auroc": 0.47, "time": 229.48}
{"epoch": 15, "training_loss": 55.87118911743164, "training_acc": 52.5, "val_loss": 14.334763288497925, "val_acc": 50.0, "val_auroc": 0.55, "time": 244.64}
{"epoch": 16, "training_loss": 56.38559913635254, "training_acc": 52.5, "val_loss": 14.182722568511963, "val_acc": 50.0, "val_auroc": 0.51, "time": 259.37}
{"epoch": 17, "training_loss": 55.80101203918457, "training_acc": 52.5, "val_loss": 13.944567441940308, "val_acc": 50.0, "val_auroc": 0.5, "time": 273.77}
{"epoch": 18, "training_loss": 55.373069763183594, "training_acc": 52.5, "val_loss": 13.860511779785156, "val_acc": 50.0, "val_auroc": 0.53, "time": 288.23}
{"epoch": 19, "training_loss": 55.41270446777344, "training_acc": 61.25, "val_loss": 13.885078430175781, "val_acc": 50.0, "val_auroc": 0.51, "time": 304.43}
{"epoch": 20, "training_loss": 55.60193920135498, "training_acc": 47.5, "val_loss": 13.975470066070557, "val_acc": 50.0, "val_auroc": 0.49, "time": 319.11}
{"epoch": 21, "training_loss": 56.22707939147949, "training_acc": 47.5, "val_loss": 13.879233598709106, "val_acc": 50.0, "val_auroc": 0.48, "time": 335.2}
