"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.30364418029785, "training_acc": 48.75, "val_loss": 13.921804428100586, "val_acc": 50.0, "val_auroc": 0.35, "time": 16.67}
{"epoch": 1, "training_loss": 57.58054733276367, "training_acc": 51.25, "val_loss": 13.966912031173706, "val_acc": 50.0, "val_auroc": 0.54, "time": 31.11}
{"epoch": 2, "training_loss": 55.192142486572266, "training_acc": 52.5, "val_loss": 14.119757413864136, "val_acc": 50.0, "val_auroc": 0.32, "time": 46.47}
{"epoch": 3, "training_loss": 55.72597885131836, "training_acc": 52.5, "val_loss": 14.121848344802856, "val_acc": 50.0, "val_auroc": 0.38, "time": 60.88}
{"epoch": 4, "training_loss": 55.5466833114624, "training_acc": 52.5, "val_loss": 13.9403235912323, "val_acc": 50.0, "val_auroc": 0.31, "time": 75.5}
{"epoch": 5, "training_loss": 55.23287487030029, "training_acc": 50.0, "val_loss": 13.920711278915405, "val_acc": 50.0, "val_auroc": 0.28, "time": 91.16}
{"epoch": 6, "training_loss": 55.084739685058594, "training_acc": 56.25, "val_loss": 14.356797933578491, "val_acc": 50.0, "val_auroc": 0.31, "time": 106.89}
{"epoch": 7, "training_loss": 56.165300369262695, "training_acc": 52.5, "val_loss": 14.516342878341675, "val_acc": 50.0, "val_auroc": 0.32, "time": 121.75}
{"epoch": 8, "training_loss": 56.031588554382324, "training_acc": 52.5, "val_loss": 13.910880088806152, "val_acc": 50.0, "val_auroc": 0.3, "time": 137.32}
{"epoch": 9, "training_loss": 55.13627052307129, "training_acc": 52.5, "val_loss": 14.05038595199585, "val_acc": 50.0, "val_auroc": 0.33, "time": 152.46}
{"epoch": 10, "training_loss": 56.36318016052246, "training_acc": 47.5, "val_loss": 13.950841426849365, "val_acc": 50.0, "val_auroc": 0.32, "time": 167.18}
{"epoch": 11, "training_loss": 55.35158348083496, "training_acc": 51.25, "val_loss": 14.029781818389893, "val_acc": 50.0, "val_auroc": 0.32, "time": 184.46}
{"epoch": 12, "training_loss": 55.5617790222168, "training_acc": 52.5, "val_loss": 14.268743991851807, "val_acc": 50.0, "val_auroc": 0.29, "time": 199.55}
{"epoch": 13, "training_loss": 55.82101631164551, "training_acc": 52.5, "val_loss": 13.982962369918823, "val_acc": 50.0, "val_auroc": 0.38, "time": 214.77}
{"epoch": 14, "training_loss": 55.19737243652344, "training_acc": 52.5, "val_loss": 13.862365484237671, "val_acc": 50.0, "val_auroc": 0.5, "time": 230.12}
{"epoch": 15, "training_loss": 55.54276943206787, "training_acc": 62.5, "val_loss": 13.86415719985962, "val_acc": 50.0, "val_auroc": 0.5, "time": 244.94}
{"epoch": 16, "training_loss": 55.06797695159912, "training_acc": 68.75, "val_loss": 13.978601694107056, "val_acc": 50.0, "val_auroc": 0.38, "time": 259.49}
{"epoch": 17, "training_loss": 55.34086036682129, "training_acc": 52.5, "val_loss": 14.109578132629395, "val_acc": 50.0, "val_auroc": 0.36, "time": 274.0}
{"epoch": 18, "training_loss": 55.49370574951172, "training_acc": 52.5, "val_loss": 14.021776914596558, "val_acc": 50.0, "val_auroc": 0.32, "time": 288.81}
{"epoch": 19, "training_loss": 55.16543388366699, "training_acc": 52.5, "val_loss": 13.889857530593872, "val_acc": 50.0, "val_auroc": 0.34, "time": 304.01}
{"epoch": 20, "training_loss": 55.260684967041016, "training_acc": 50.0, "val_loss": 13.892555236816406, "val_acc": 50.0, "val_auroc": 0.39, "time": 318.79}
{"epoch": 21, "training_loss": 55.43624687194824, "training_acc": 47.5, "val_loss": 13.884057998657227, "val_acc": 50.0, "val_auroc": 0.38, "time": 333.27}
{"epoch": 22, "training_loss": 55.23118019104004, "training_acc": 50.0, "val_loss": 13.906019926071167, "val_acc": 50.0, "val_auroc": 0.42, "time": 347.25}
{"epoch": 23, "training_loss": 54.94975280761719, "training_acc": 52.5, "val_loss": 14.062749147415161, "val_acc": 50.0, "val_auroc": 0.4, "time": 361.71}
{"epoch": 24, "training_loss": 55.18473815917969, "training_acc": 52.5, "val_loss": 14.274294376373291, "val_acc": 50.0, "val_auroc": 0.43, "time": 376.21}
{"epoch": 25, "training_loss": 55.68721961975098, "training_acc": 52.5, "val_loss": 14.243358373641968, "val_acc": 50.0, "val_auroc": 0.42, "time": 390.98}
{"epoch": 26, "training_loss": 55.67409324645996, "training_acc": 52.5, "val_loss": 14.080090522766113, "val_acc": 50.0, "val_auroc": 0.36, "time": 407.29}
{"epoch": 27, "training_loss": 54.7554817199707, "training_acc": 52.5, "val_loss": 14.052774906158447, "val_acc": 50.0, "val_auroc": 0.34, "time": 423.08}
{"epoch": 28, "training_loss": 54.88235378265381, "training_acc": 52.5, "val_loss": 13.917626142501831, "val_acc": 50.0, "val_auroc": 0.3, "time": 437.45}
{"epoch": 29, "training_loss": 54.77643871307373, "training_acc": 50.0, "val_loss": 13.915399312973022, "val_acc": 50.0, "val_auroc": 0.34, "time": 452.25}
{"epoch": 30, "training_loss": 55.319725036621094, "training_acc": 47.5, "val_loss": 13.916006088256836, "val_acc": 50.0, "val_auroc": 0.31, "time": 466.5}
{"epoch": 31, "training_loss": 55.17560005187988, "training_acc": 52.5, "val_loss": 13.912410736083984, "val_acc": 50.0, "val_auroc": 0.33, "time": 481.83}
{"epoch": 32, "training_loss": 54.70472717285156, "training_acc": 63.75, "val_loss": 13.94594669342041, "val_acc": 50.0, "val_auroc": 0.35, "time": 498.42}
{"epoch": 33, "training_loss": 54.387603759765625, "training_acc": 53.75, "val_loss": 13.97403597831726, "val_acc": 50.0, "val_auroc": 0.36, "time": 512.84}
