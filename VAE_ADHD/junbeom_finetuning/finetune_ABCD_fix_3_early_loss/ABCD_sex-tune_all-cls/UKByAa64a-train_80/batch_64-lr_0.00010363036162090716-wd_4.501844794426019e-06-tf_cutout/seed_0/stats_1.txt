"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.335387229919434, "training_acc": 50.0, "val_loss": 13.872789144515991, "val_acc": 50.0, "val_auroc": 0.51, "time": 16.69}
{"epoch": 1, "training_loss": 55.3403377532959, "training_acc": 55.0, "val_loss": 18.31679940223694, "val_acc": 50.0, "val_auroc": 0.54, "time": 31.9}
{"epoch": 2, "training_loss": 66.92670345306396, "training_acc": 52.5, "val_loss": 13.87614369392395, "val_acc": 50.0, "val_auroc": 0.53, "time": 46.47}
{"epoch": 3, "training_loss": 55.22854042053223, "training_acc": 52.5, "val_loss": 13.843727111816406, "val_acc": 50.0, "val_auroc": 0.58, "time": 61.24}
{"epoch": 4, "training_loss": 55.46778964996338, "training_acc": 47.5, "val_loss": 13.827739953994751, "val_acc": 50.0, "val_auroc": 0.74, "time": 76.38}
{"epoch": 5, "training_loss": 55.23066711425781, "training_acc": 66.25, "val_loss": 13.895337581634521, "val_acc": 50.0, "val_auroc": 0.79, "time": 90.93}
{"epoch": 6, "training_loss": 55.2775764465332, "training_acc": 52.5, "val_loss": 13.816918134689331, "val_acc": 50.0, "val_auroc": 0.68, "time": 109.09}
{"epoch": 7, "training_loss": 55.22984504699707, "training_acc": 50.0, "val_loss": 13.785017728805542, "val_acc": 50.0, "val_auroc": 0.76, "time": 124.39}
{"epoch": 8, "training_loss": 55.09692096710205, "training_acc": 52.5, "val_loss": 13.85130524635315, "val_acc": 50.0, "val_auroc": 0.81, "time": 140.43}
{"epoch": 9, "training_loss": 54.8633451461792, "training_acc": 52.5, "val_loss": 13.837250471115112, "val_acc": 50.0, "val_auroc": 0.77, "time": 156.1}
{"epoch": 10, "training_loss": 55.8411922454834, "training_acc": 47.5, "val_loss": 13.73958945274353, "val_acc": 50.0, "val_auroc": 0.82, "time": 172.41}
{"epoch": 11, "training_loss": 54.81593132019043, "training_acc": 66.25, "val_loss": 14.076035022735596, "val_acc": 50.0, "val_auroc": 0.82, "time": 188.18}
{"epoch": 12, "training_loss": 55.564751625061035, "training_acc": 52.5, "val_loss": 13.993233442306519, "val_acc": 50.0, "val_auroc": 0.8, "time": 202.49}
{"epoch": 13, "training_loss": 55.48207950592041, "training_acc": 52.5, "val_loss": 13.810185194015503, "val_acc": 50.0, "val_auroc": 0.82, "time": 216.76}
{"epoch": 14, "training_loss": 55.15359878540039, "training_acc": 52.5, "val_loss": 13.89367938041687, "val_acc": 50.0, "val_auroc": 0.82, "time": 231.23}
{"epoch": 15, "training_loss": 55.03293037414551, "training_acc": 52.5, "val_loss": 14.181766510009766, "val_acc": 50.0, "val_auroc": 0.82, "time": 246.65}
{"epoch": 16, "training_loss": 55.88551902770996, "training_acc": 52.5, "val_loss": 14.076143503189087, "val_acc": 50.0, "val_auroc": 0.85, "time": 261.49}
{"epoch": 17, "training_loss": 55.34465026855469, "training_acc": 52.5, "val_loss": 13.743284940719604, "val_acc": 50.0, "val_auroc": 0.9, "time": 277.13}
{"epoch": 18, "training_loss": 54.61886787414551, "training_acc": 52.5, "val_loss": 13.846815824508667, "val_acc": 50.0, "val_auroc": 0.87, "time": 291.8}
{"epoch": 19, "training_loss": 55.542837142944336, "training_acc": 47.5, "val_loss": 13.839800357818604, "val_acc": 50.0, "val_auroc": 0.87, "time": 306.86}
{"epoch": 20, "training_loss": 55.60697555541992, "training_acc": 47.5, "val_loss": 13.694560527801514, "val_acc": 50.0, "val_auroc": 0.81, "time": 321.99}
{"epoch": 21, "training_loss": 54.4199275970459, "training_acc": 58.75, "val_loss": 13.88092041015625, "val_acc": 50.0, "val_auroc": 0.83, "time": 337.03}
{"epoch": 22, "training_loss": 54.87864971160889, "training_acc": 52.5, "val_loss": 14.159324169158936, "val_acc": 50.0, "val_auroc": 0.82, "time": 352.42}
{"epoch": 23, "training_loss": 55.55497169494629, "training_acc": 52.5, "val_loss": 13.901946544647217, "val_acc": 50.0, "val_auroc": 0.83, "time": 367.38}
{"epoch": 24, "training_loss": 54.66329002380371, "training_acc": 52.5, "val_loss": 13.63436222076416, "val_acc": 50.0, "val_auroc": 0.86, "time": 382.15}
{"epoch": 25, "training_loss": 54.32277488708496, "training_acc": 58.75, "val_loss": 13.572022914886475, "val_acc": 50.0, "val_auroc": 0.86, "time": 397.42}
{"epoch": 26, "training_loss": 54.08833885192871, "training_acc": 60.0, "val_loss": 13.641303777694702, "val_acc": 50.0, "val_auroc": 0.86, "time": 415.53}
{"epoch": 27, "training_loss": 53.51286029815674, "training_acc": 55.0, "val_loss": 13.40419054031372, "val_acc": 50.0, "val_auroc": 0.85, "time": 432.16}
{"epoch": 28, "training_loss": 53.73822784423828, "training_acc": 58.75, "val_loss": 14.348658323287964, "val_acc": 60.0, "val_auroc": 0.82, "time": 446.97}
{"epoch": 29, "training_loss": 57.798336029052734, "training_acc": 47.5, "val_loss": 13.529386520385742, "val_acc": 50.0, "val_auroc": 0.86, "time": 462.82}
{"epoch": 30, "training_loss": 53.42218208312988, "training_acc": 61.25, "val_loss": 14.371576309204102, "val_acc": 50.0, "val_auroc": 0.8, "time": 478.68}
{"epoch": 31, "training_loss": 56.078060150146484, "training_acc": 52.5, "val_loss": 14.26421046257019, "val_acc": 50.0, "val_auroc": 0.83, "time": 493.98}
{"epoch": 32, "training_loss": 55.16156578063965, "training_acc": 52.5, "val_loss": 13.69405746459961, "val_acc": 50.0, "val_auroc": 0.83, "time": 509.3}
{"epoch": 33, "training_loss": 55.17885684967041, "training_acc": 58.75, "val_loss": 13.971933126449585, "val_acc": 50.0, "val_auroc": 0.81, "time": 524.18}
{"epoch": 34, "training_loss": 56.10754871368408, "training_acc": 47.5, "val_loss": 13.744499683380127, "val_acc": 50.0, "val_auroc": 0.81, "time": 539.81}
{"epoch": 35, "training_loss": 55.6070442199707, "training_acc": 57.5, "val_loss": 13.801110982894897, "val_acc": 50.0, "val_auroc": 0.85, "time": 555.85}
{"epoch": 36, "training_loss": 54.66926670074463, "training_acc": 52.5, "val_loss": 13.729833364486694, "val_acc": 50.0, "val_auroc": 0.84, "time": 571.99}
{"epoch": 37, "training_loss": 54.51707744598389, "training_acc": 72.5, "val_loss": 13.80287766456604, "val_acc": 50.0, "val_auroc": 0.83, "time": 588.23}
{"epoch": 38, "training_loss": 55.38596534729004, "training_acc": 47.5, "val_loss": 13.786925077438354, "val_acc": 50.0, "val_auroc": 0.79, "time": 604.27}
{"epoch": 39, "training_loss": 55.051513671875, "training_acc": 47.5, "val_loss": 13.674070835113525, "val_acc": 50.0, "val_auroc": 0.82, "time": 620.47}
{"epoch": 40, "training_loss": 54.505730628967285, "training_acc": 63.75, "val_loss": 13.744663000106812, "val_acc": 50.0, "val_auroc": 0.79, "time": 636.5}
{"epoch": 41, "training_loss": 54.45042037963867, "training_acc": 52.5, "val_loss": 13.63252878189087, "val_acc": 50.0, "val_auroc": 0.79, "time": 652.96}
{"epoch": 42, "training_loss": 54.114280700683594, "training_acc": 61.25, "val_loss": 13.6124587059021, "val_acc": 50.0, "val_auroc": 0.79, "time": 667.93}
{"epoch": 43, "training_loss": 53.88717079162598, "training_acc": 62.5, "val_loss": 13.515335321426392, "val_acc": 50.0, "val_auroc": 0.79, "time": 683.05}
{"epoch": 44, "training_loss": 53.58485698699951, "training_acc": 68.75, "val_loss": 13.5189950466156, "val_acc": 50.0, "val_auroc": 0.8, "time": 698.15}
{"epoch": 45, "training_loss": 53.507497787475586, "training_acc": 58.75, "val_loss": 13.362482786178589, "val_acc": 50.0, "val_auroc": 0.8, "time": 713.72}
{"epoch": 46, "training_loss": 52.74110221862793, "training_acc": 72.5, "val_loss": 13.257673978805542, "val_acc": 50.0, "val_auroc": 0.79, "time": 730.88}
{"epoch": 47, "training_loss": 51.927513122558594, "training_acc": 63.75, "val_loss": 13.393906354904175, "val_acc": 50.0, "val_auroc": 0.79, "time": 747.21}
{"epoch": 48, "training_loss": 52.565731048583984, "training_acc": 56.25, "val_loss": 13.275072574615479, "val_acc": 50.0, "val_auroc": 0.82, "time": 762.61}
{"epoch": 49, "training_loss": 51.333683013916016, "training_acc": 56.25, "val_loss": 12.875663042068481, "val_acc": 50.0, "val_auroc": 0.81, "time": 778.06}
{"epoch": 50, "training_loss": 49.99911308288574, "training_acc": 73.75, "val_loss": 12.641299962997437, "val_acc": 50.0, "val_auroc": 0.8, "time": 795.44}
{"epoch": 51, "training_loss": 48.991530418395996, "training_acc": 68.75, "val_loss": 13.169392347335815, "val_acc": 75.0, "val_auroc": 0.82, "time": 811.73}
{"epoch": 52, "training_loss": 50.88617134094238, "training_acc": 61.25, "val_loss": 12.227500677108765, "val_acc": 65.0, "val_auroc": 0.83, "time": 827.06}
{"epoch": 53, "training_loss": 45.156375885009766, "training_acc": 76.25, "val_loss": 12.693880796432495, "val_acc": 50.0, "val_auroc": 0.76, "time": 843.03}
{"epoch": 54, "training_loss": 51.07325744628906, "training_acc": 63.75, "val_loss": 15.498659610748291, "val_acc": 50.0, "val_auroc": 0.83, "time": 858.67}
{"epoch": 55, "training_loss": 56.266547203063965, "training_acc": 52.5, "val_loss": 13.808783292770386, "val_acc": 50.0, "val_auroc": 0.94, "time": 874.07}
{"epoch": 56, "training_loss": 55.39722728729248, "training_acc": 47.5, "val_loss": 13.689970970153809, "val_acc": 50.0, "val_auroc": 0.9, "time": 889.05}
{"epoch": 57, "training_loss": 54.813008308410645, "training_acc": 50.0, "val_loss": 14.49656367301941, "val_acc": 50.0, "val_auroc": 0.74, "time": 904.6}
{"epoch": 58, "training_loss": 56.25670337677002, "training_acc": 52.5, "val_loss": 13.711854219436646, "val_acc": 50.0, "val_auroc": 0.97, "time": 920.23}
{"epoch": 59, "training_loss": 56.208492279052734, "training_acc": 47.5, "val_loss": 13.68539810180664, "val_acc": 50.0, "val_auroc": 0.87, "time": 935.88}
{"epoch": 60, "training_loss": 54.67244243621826, "training_acc": 50.0, "val_loss": 14.151594638824463, "val_acc": 50.0, "val_auroc": 0.83, "time": 951.21}
{"epoch": 61, "training_loss": 55.67463302612305, "training_acc": 52.5, "val_loss": 14.203236103057861, "val_acc": 50.0, "val_auroc": 0.79, "time": 968.23}
{"epoch": 62, "training_loss": 55.48849868774414, "training_acc": 52.5, "val_loss": 13.729106187820435, "val_acc": 50.0, "val_auroc": 0.76, "time": 985.43}
{"epoch": 63, "training_loss": 54.34722709655762, "training_acc": 60.0, "val_loss": 13.793227672576904, "val_acc": 50.0, "val_auroc": 0.75, "time": 1000.65}
{"epoch": 64, "training_loss": 55.388139724731445, "training_acc": 47.5, "val_loss": 13.776155710220337, "val_acc": 50.0, "val_auroc": 0.77, "time": 1017.45}
{"epoch": 65, "training_loss": 55.590681076049805, "training_acc": 47.5, "val_loss": 13.643244504928589, "val_acc": 50.0, "val_auroc": 0.77, "time": 1036.23}
{"epoch": 66, "training_loss": 54.46198081970215, "training_acc": 53.75, "val_loss": 13.577015399932861, "val_acc": 50.0, "val_auroc": 0.77, "time": 1052.0}
{"epoch": 67, "training_loss": 53.996439933776855, "training_acc": 63.75, "val_loss": 13.478485345840454, "val_acc": 50.0, "val_auroc": 0.77, "time": 1066.93}
{"epoch": 68, "training_loss": 53.46628189086914, "training_acc": 68.75, "val_loss": 13.393579721450806, "val_acc": 50.0, "val_auroc": 0.77, "time": 1082.49}
{"epoch": 69, "training_loss": 52.840168952941895, "training_acc": 67.5, "val_loss": 13.306509256362915, "val_acc": 50.0, "val_auroc": 0.77, "time": 1097.57}
{"epoch": 70, "training_loss": 52.035654067993164, "training_acc": 67.5, "val_loss": 13.105260133743286, "val_acc": 55.0, "val_auroc": 0.78, "time": 1113.92}
{"epoch": 71, "training_loss": 51.421332359313965, "training_acc": 70.0, "val_loss": 13.00488829612732, "val_acc": 50.0, "val_auroc": 0.77, "time": 1130.89}
