"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.343427658081055, "training_acc": 52.5, "val_loss": 13.883885145187378, "val_acc": 50.0, "val_auroc": 0.51, "time": 19.43}
{"epoch": 1, "training_loss": 55.48156547546387, "training_acc": 51.25, "val_loss": 13.910712003707886, "val_acc": 50.0, "val_auroc": 0.43, "time": 37.17}
{"epoch": 2, "training_loss": 55.27621269226074, "training_acc": 52.5, "val_loss": 13.910939693450928, "val_acc": 50.0, "val_auroc": 0.41, "time": 55.21}
{"epoch": 3, "training_loss": 55.36642074584961, "training_acc": 52.5, "val_loss": 13.938405513763428, "val_acc": 50.0, "val_auroc": 0.53, "time": 78.24}
{"epoch": 4, "training_loss": 55.3372220993042, "training_acc": 52.5, "val_loss": 13.928941488265991, "val_acc": 50.0, "val_auroc": 0.51, "time": 96.73}
{"epoch": 5, "training_loss": 55.34456157684326, "training_acc": 52.5, "val_loss": 13.897918462753296, "val_acc": 50.0, "val_auroc": 0.62, "time": 115.29}
{"epoch": 6, "training_loss": 55.293989181518555, "training_acc": 52.5, "val_loss": 13.975222110748291, "val_acc": 50.0, "val_auroc": 0.56, "time": 132.16}
{"epoch": 7, "training_loss": 55.22770023345947, "training_acc": 52.5, "val_loss": 14.049201011657715, "val_acc": 50.0, "val_auroc": 0.43, "time": 149.27}
{"epoch": 8, "training_loss": 55.43927574157715, "training_acc": 52.5, "val_loss": 13.93303632736206, "val_acc": 50.0, "val_auroc": 0.42, "time": 166.01}
{"epoch": 9, "training_loss": 55.195926666259766, "training_acc": 52.5, "val_loss": 13.868492841720581, "val_acc": 50.0, "val_auroc": 0.53, "time": 183.37}
{"epoch": 10, "training_loss": 55.36896324157715, "training_acc": 53.75, "val_loss": 13.862513303756714, "val_acc": 50.0, "val_auroc": 0.54, "time": 200.5}
{"epoch": 11, "training_loss": 55.22300720214844, "training_acc": 53.75, "val_loss": 13.932244777679443, "val_acc": 50.0, "val_auroc": 0.43, "time": 219.22}
{"epoch": 12, "training_loss": 55.27714538574219, "training_acc": 52.5, "val_loss": 13.980640172958374, "val_acc": 50.0, "val_auroc": 0.37, "time": 238.51}
{"epoch": 13, "training_loss": 55.30718231201172, "training_acc": 52.5, "val_loss": 13.9079749584198, "val_acc": 50.0, "val_auroc": 0.51, "time": 255.76}
{"epoch": 14, "training_loss": 55.21907329559326, "training_acc": 52.5, "val_loss": 13.87804627418518, "val_acc": 50.0, "val_auroc": 0.43, "time": 272.95}
{"epoch": 15, "training_loss": 55.24813652038574, "training_acc": 53.75, "val_loss": 13.896255493164062, "val_acc": 50.0, "val_auroc": 0.45, "time": 290.0}
{"epoch": 16, "training_loss": 55.004984855651855, "training_acc": 52.5, "val_loss": 14.015525579452515, "val_acc": 50.0, "val_auroc": 0.49, "time": 307.34}
{"epoch": 17, "training_loss": 55.569515228271484, "training_acc": 52.5, "val_loss": 14.084481000900269, "val_acc": 50.0, "val_auroc": 0.48, "time": 324.18}
{"epoch": 18, "training_loss": 55.48773765563965, "training_acc": 52.5, "val_loss": 13.959704637527466, "val_acc": 50.0, "val_auroc": 0.38, "time": 340.4}
{"epoch": 19, "training_loss": 55.20365905761719, "training_acc": 52.5, "val_loss": 13.872722387313843, "val_acc": 50.0, "val_auroc": 0.49, "time": 357.93}
{"epoch": 20, "training_loss": 55.27348518371582, "training_acc": 51.25, "val_loss": 13.866279125213623, "val_acc": 50.0, "val_auroc": 0.51, "time": 375.17}
{"epoch": 21, "training_loss": 55.363664627075195, "training_acc": 55.0, "val_loss": 13.855884075164795, "val_acc": 50.0, "val_auroc": 0.56, "time": 393.78}
{"epoch": 22, "training_loss": 55.30325984954834, "training_acc": 53.75, "val_loss": 13.88197660446167, "val_acc": 50.0, "val_auroc": 0.49, "time": 410.06}
{"epoch": 23, "training_loss": 55.05205535888672, "training_acc": 52.5, "val_loss": 13.95070195198059, "val_acc": 50.0, "val_auroc": 0.46, "time": 426.57}
{"epoch": 24, "training_loss": 55.167789459228516, "training_acc": 52.5, "val_loss": 14.04470682144165, "val_acc": 50.0, "val_auroc": 0.48, "time": 446.2}
{"epoch": 25, "training_loss": 55.4840087890625, "training_acc": 52.5, "val_loss": 14.05077338218689, "val_acc": 50.0, "val_auroc": 0.45, "time": 462.5}
{"epoch": 26, "training_loss": 55.611456871032715, "training_acc": 52.5, "val_loss": 14.008963108062744, "val_acc": 50.0, "val_auroc": 0.39, "time": 479.54}
{"epoch": 27, "training_loss": 55.10493278503418, "training_acc": 52.5, "val_loss": 14.032889604568481, "val_acc": 50.0, "val_auroc": 0.37, "time": 498.53}
{"epoch": 28, "training_loss": 55.37569236755371, "training_acc": 52.5, "val_loss": 13.93464207649231, "val_acc": 50.0, "val_auroc": 0.4, "time": 517.07}
{"epoch": 29, "training_loss": 55.07800102233887, "training_acc": 52.5, "val_loss": 13.8675856590271, "val_acc": 50.0, "val_auroc": 0.44, "time": 534.38}
{"epoch": 30, "training_loss": 55.3280553817749, "training_acc": 61.25, "val_loss": 13.888698816299438, "val_acc": 50.0, "val_auroc": 0.32, "time": 552.08}
{"epoch": 31, "training_loss": 55.2535343170166, "training_acc": 66.25, "val_loss": 13.906238079071045, "val_acc": 50.0, "val_auroc": 0.35, "time": 569.74}
{"epoch": 32, "training_loss": 54.93080711364746, "training_acc": 52.5, "val_loss": 13.903148174285889, "val_acc": 50.0, "val_auroc": 0.39, "time": 587.1}
{"epoch": 33, "training_loss": 54.8975830078125, "training_acc": 58.75, "val_loss": 13.909721374511719, "val_acc": 50.0, "val_auroc": 0.4, "time": 603.44}
{"epoch": 34, "training_loss": 54.90574359893799, "training_acc": 68.75, "val_loss": 13.936580419540405, "val_acc": 50.0, "val_auroc": 0.39, "time": 620.2}
{"epoch": 35, "training_loss": 54.94411849975586, "training_acc": 55.0, "val_loss": 13.973714113235474, "val_acc": 50.0, "val_auroc": 0.36, "time": 638.99}
{"epoch": 36, "training_loss": 54.45973873138428, "training_acc": 52.5, "val_loss": 13.940980434417725, "val_acc": 50.0, "val_auroc": 0.36, "time": 656.07}
{"epoch": 37, "training_loss": 54.136229515075684, "training_acc": 70.0, "val_loss": 13.985066413879395, "val_acc": 50.0, "val_auroc": 0.38, "time": 673.79}
{"epoch": 38, "training_loss": 54.323883056640625, "training_acc": 62.5, "val_loss": 13.97764801979065, "val_acc": 50.0, "val_auroc": 0.41, "time": 690.83}
{"epoch": 39, "training_loss": 54.154887199401855, "training_acc": 56.25, "val_loss": 14.068542718887329, "val_acc": 50.0, "val_auroc": 0.33, "time": 709.04}
{"epoch": 40, "training_loss": 53.89207649230957, "training_acc": 55.0, "val_loss": 13.938846588134766, "val_acc": 50.0, "val_auroc": 0.49, "time": 726.44}
