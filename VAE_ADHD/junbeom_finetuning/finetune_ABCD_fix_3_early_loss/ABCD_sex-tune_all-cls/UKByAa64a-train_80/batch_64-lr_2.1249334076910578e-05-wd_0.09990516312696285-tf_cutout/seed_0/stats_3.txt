"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.26923370361328, "training_acc": 51.25, "val_loss": 13.871382474899292, "val_acc": 55.0, "val_auroc": 0.374, "time": 19.7}
{"epoch": 1, "training_loss": 55.425957679748535, "training_acc": 51.25, "val_loss": 13.81608247756958, "val_acc": 55.0, "val_auroc": 0.525, "time": 37.6}
{"epoch": 2, "training_loss": 55.33869171142578, "training_acc": 51.25, "val_loss": 13.896087408065796, "val_acc": 55.0, "val_auroc": 0.343, "time": 56.23}
{"epoch": 3, "training_loss": 55.26521968841553, "training_acc": 58.75, "val_loss": 13.905494213104248, "val_acc": 55.0, "val_auroc": 0.263, "time": 78.04}
{"epoch": 4, "training_loss": 55.309043884277344, "training_acc": 58.75, "val_loss": 13.878345489501953, "val_acc": 55.0, "val_auroc": 0.303, "time": 96.03}
{"epoch": 5, "training_loss": 55.19561767578125, "training_acc": 51.25, "val_loss": 13.82895827293396, "val_acc": 55.0, "val_auroc": 0.444, "time": 114.73}
{"epoch": 6, "training_loss": 55.36925220489502, "training_acc": 51.25, "val_loss": 13.812955617904663, "val_acc": 55.0, "val_auroc": 0.505, "time": 135.51}
{"epoch": 7, "training_loss": 55.41166019439697, "training_acc": 51.25, "val_loss": 13.805205821990967, "val_acc": 55.0, "val_auroc": 0.535, "time": 156.12}
{"epoch": 8, "training_loss": 55.307692527770996, "training_acc": 51.25, "val_loss": 13.798388242721558, "val_acc": 55.0, "val_auroc": 0.677, "time": 173.45}
{"epoch": 9, "training_loss": 55.1993408203125, "training_acc": 51.25, "val_loss": 13.797863721847534, "val_acc": 55.0, "val_auroc": 0.677, "time": 192.29}
{"epoch": 10, "training_loss": 54.96459102630615, "training_acc": 55.0, "val_loss": 13.809417486190796, "val_acc": 55.0, "val_auroc": 0.545, "time": 210.44}
{"epoch": 11, "training_loss": 54.83826732635498, "training_acc": 52.5, "val_loss": 13.815102577209473, "val_acc": 55.0, "val_auroc": 0.485, "time": 229.45}
{"epoch": 12, "training_loss": 54.81870079040527, "training_acc": 52.5, "val_loss": 13.79534363746643, "val_acc": 55.0, "val_auroc": 0.495, "time": 247.75}
{"epoch": 13, "training_loss": 54.61606407165527, "training_acc": 58.75, "val_loss": 13.818385601043701, "val_acc": 55.0, "val_auroc": 0.505, "time": 266.58}
{"epoch": 14, "training_loss": 54.57997989654541, "training_acc": 56.25, "val_loss": 13.831239938735962, "val_acc": 55.0, "val_auroc": 0.495, "time": 285.79}
{"epoch": 15, "training_loss": 54.70893383026123, "training_acc": 65.0, "val_loss": 13.812063932418823, "val_acc": 55.0, "val_auroc": 0.515, "time": 306.47}
{"epoch": 16, "training_loss": 54.15886402130127, "training_acc": 66.25, "val_loss": 13.776940107345581, "val_acc": 55.0, "val_auroc": 0.515, "time": 324.88}
{"epoch": 17, "training_loss": 54.14626216888428, "training_acc": 61.25, "val_loss": 13.783005475997925, "val_acc": 55.0, "val_auroc": 0.505, "time": 342.61}
{"epoch": 18, "training_loss": 54.22884654998779, "training_acc": 60.0, "val_loss": 13.79221796989441, "val_acc": 55.0, "val_auroc": 0.495, "time": 360.24}
{"epoch": 19, "training_loss": 53.802120208740234, "training_acc": 62.5, "val_loss": 13.79991888999939, "val_acc": 55.0, "val_auroc": 0.455, "time": 379.08}
{"epoch": 20, "training_loss": 53.943037033081055, "training_acc": 65.0, "val_loss": 13.844480514526367, "val_acc": 55.0, "val_auroc": 0.434, "time": 396.17}
{"epoch": 21, "training_loss": 53.62185096740723, "training_acc": 76.25, "val_loss": 13.852777481079102, "val_acc": 55.0, "val_auroc": 0.475, "time": 413.77}
{"epoch": 22, "training_loss": 53.63880920410156, "training_acc": 70.0, "val_loss": 13.880242109298706, "val_acc": 55.0, "val_auroc": 0.465, "time": 430.46}
{"epoch": 23, "training_loss": 53.16544246673584, "training_acc": 77.5, "val_loss": 13.80946159362793, "val_acc": 55.0, "val_auroc": 0.566, "time": 448.18}
{"epoch": 24, "training_loss": 53.547353744506836, "training_acc": 62.5, "val_loss": 13.844772577285767, "val_acc": 55.0, "val_auroc": 0.475, "time": 469.9}
{"epoch": 25, "training_loss": 52.72884750366211, "training_acc": 66.25, "val_loss": 13.90123724937439, "val_acc": 55.0, "val_auroc": 0.444, "time": 490.38}
{"epoch": 26, "training_loss": 53.34213638305664, "training_acc": 75.0, "val_loss": 13.86583685874939, "val_acc": 55.0, "val_auroc": 0.444, "time": 507.94}
{"epoch": 27, "training_loss": 52.19716262817383, "training_acc": 67.5, "val_loss": 13.846184015274048, "val_acc": 55.0, "val_auroc": 0.455, "time": 525.55}
{"epoch": 28, "training_loss": 51.69339179992676, "training_acc": 67.5, "val_loss": 13.91571044921875, "val_acc": 55.0, "val_auroc": 0.455, "time": 543.47}
{"epoch": 29, "training_loss": 52.097421646118164, "training_acc": 85.0, "val_loss": 13.888345956802368, "val_acc": 55.0, "val_auroc": 0.465, "time": 560.68}
{"epoch": 30, "training_loss": 51.38189697265625, "training_acc": 71.25, "val_loss": 13.946822881698608, "val_acc": 55.0, "val_auroc": 0.455, "time": 577.45}
{"epoch": 31, "training_loss": 50.822896003723145, "training_acc": 75.0, "val_loss": 13.999936580657959, "val_acc": 55.0, "val_auroc": 0.465, "time": 595.96}
{"epoch": 32, "training_loss": 50.65561294555664, "training_acc": 80.0, "val_loss": 14.01715874671936, "val_acc": 55.0, "val_auroc": 0.455, "time": 616.63}
{"epoch": 33, "training_loss": 50.63738441467285, "training_acc": 86.25, "val_loss": 13.951940536499023, "val_acc": 55.0, "val_auroc": 0.455, "time": 634.11}
{"epoch": 34, "training_loss": 49.512413024902344, "training_acc": 73.75, "val_loss": 14.000457525253296, "val_acc": 55.0, "val_auroc": 0.465, "time": 655.29}
{"epoch": 35, "training_loss": 49.2767276763916, "training_acc": 83.75, "val_loss": 13.998880386352539, "val_acc": 55.0, "val_auroc": 0.465, "time": 672.54}
