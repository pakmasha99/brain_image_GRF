"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.43550682067871, "training_acc": 52.5, "val_loss": 13.933584690093994, "val_acc": 50.0, "val_auroc": 0.41, "time": 19.28}
{"epoch": 1, "training_loss": 55.3349723815918, "training_acc": 52.5, "val_loss": 13.95351767539978, "val_acc": 50.0, "val_auroc": 0.27, "time": 38.53}
{"epoch": 2, "training_loss": 55.173675537109375, "training_acc": 52.5, "val_loss": 13.952497243881226, "val_acc": 50.0, "val_auroc": 0.34, "time": 60.96}
{"epoch": 3, "training_loss": 55.13785266876221, "training_acc": 52.5, "val_loss": 13.96464228630066, "val_acc": 50.0, "val_auroc": 0.34, "time": 85.79}
{"epoch": 4, "training_loss": 55.134971618652344, "training_acc": 52.5, "val_loss": 13.98152232170105, "val_acc": 50.0, "val_auroc": 0.37, "time": 104.9}
{"epoch": 5, "training_loss": 54.94679832458496, "training_acc": 52.5, "val_loss": 13.92458438873291, "val_acc": 50.0, "val_auroc": 0.37, "time": 122.17}
{"epoch": 6, "training_loss": 54.88540554046631, "training_acc": 52.5, "val_loss": 13.939112424850464, "val_acc": 50.0, "val_auroc": 0.39, "time": 143.0}
{"epoch": 7, "training_loss": 54.82999134063721, "training_acc": 52.5, "val_loss": 14.0414297580719, "val_acc": 50.0, "val_auroc": 0.25, "time": 164.72}
{"epoch": 8, "training_loss": 54.92176628112793, "training_acc": 52.5, "val_loss": 14.062541723251343, "val_acc": 50.0, "val_auroc": 0.3, "time": 181.89}
{"epoch": 9, "training_loss": 54.62843322753906, "training_acc": 52.5, "val_loss": 13.871879577636719, "val_acc": 50.0, "val_auroc": 0.49, "time": 199.05}
{"epoch": 10, "training_loss": 54.813873291015625, "training_acc": 52.5, "val_loss": 13.933485746383667, "val_acc": 50.0, "val_auroc": 0.37, "time": 219.0}
{"epoch": 11, "training_loss": 54.510986328125, "training_acc": 52.5, "val_loss": 14.054111242294312, "val_acc": 50.0, "val_auroc": 0.32, "time": 239.07}
{"epoch": 12, "training_loss": 54.48483467102051, "training_acc": 52.5, "val_loss": 14.075363874435425, "val_acc": 50.0, "val_auroc": 0.34, "time": 258.08}
{"epoch": 13, "training_loss": 54.53270435333252, "training_acc": 52.5, "val_loss": 13.988193273544312, "val_acc": 50.0, "val_auroc": 0.41, "time": 277.8}
{"epoch": 14, "training_loss": 54.02750015258789, "training_acc": 53.75, "val_loss": 13.88819694519043, "val_acc": 50.0, "val_auroc": 0.48, "time": 297.59}
{"epoch": 15, "training_loss": 53.97642803192139, "training_acc": 68.75, "val_loss": 13.945648670196533, "val_acc": 50.0, "val_auroc": 0.46, "time": 319.06}
{"epoch": 16, "training_loss": 53.39356231689453, "training_acc": 52.5, "val_loss": 14.080883264541626, "val_acc": 50.0, "val_auroc": 0.54, "time": 337.54}
{"epoch": 17, "training_loss": 54.37466239929199, "training_acc": 52.5, "val_loss": 13.96743655204773, "val_acc": 50.0, "val_auroc": 0.48, "time": 355.82}
{"epoch": 18, "training_loss": 52.79447364807129, "training_acc": 57.5, "val_loss": 13.82231593132019, "val_acc": 50.0, "val_auroc": 0.53, "time": 376.09}
{"epoch": 19, "training_loss": 53.58568096160889, "training_acc": 77.5, "val_loss": 13.790308237075806, "val_acc": 50.0, "val_auroc": 0.55, "time": 395.87}
{"epoch": 20, "training_loss": 52.19862461090088, "training_acc": 68.75, "val_loss": 13.743077516555786, "val_acc": 50.0, "val_auroc": 0.6, "time": 414.13}
{"epoch": 21, "training_loss": 51.87541198730469, "training_acc": 66.25, "val_loss": 13.715704679489136, "val_acc": 50.0, "val_auroc": 0.56, "time": 433.72}
{"epoch": 22, "training_loss": 51.07679748535156, "training_acc": 78.75, "val_loss": 13.69137167930603, "val_acc": 50.0, "val_auroc": 0.58, "time": 455.22}
{"epoch": 23, "training_loss": 49.164878845214844, "training_acc": 83.75, "val_loss": 14.018429517745972, "val_acc": 50.0, "val_auroc": 0.59, "time": 475.05}
{"epoch": 24, "training_loss": 50.97303104400635, "training_acc": 60.0, "val_loss": 13.734267950057983, "val_acc": 50.0, "val_auroc": 0.62, "time": 492.35}
{"epoch": 25, "training_loss": 50.08022880554199, "training_acc": 76.25, "val_loss": 13.923629522323608, "val_acc": 50.0, "val_auroc": 0.62, "time": 509.59}
{"epoch": 26, "training_loss": 50.1983699798584, "training_acc": 61.25, "val_loss": 13.737242221832275, "val_acc": 50.0, "val_auroc": 0.59, "time": 528.48}
{"epoch": 27, "training_loss": 45.96981334686279, "training_acc": 85.0, "val_loss": 13.69465947151184, "val_acc": 50.0, "val_auroc": 0.6, "time": 550.51}
{"epoch": 28, "training_loss": 44.7708044052124, "training_acc": 86.25, "val_loss": 13.816972970962524, "val_acc": 50.0, "val_auroc": 0.6, "time": 570.07}
{"epoch": 29, "training_loss": 49.76425743103027, "training_acc": 73.75, "val_loss": 14.527966976165771, "val_acc": 50.0, "val_auroc": 0.6, "time": 588.96}
{"epoch": 30, "training_loss": 46.979445457458496, "training_acc": 70.0, "val_loss": 13.47081184387207, "val_acc": 55.0, "val_auroc": 0.64, "time": 611.02}
{"epoch": 31, "training_loss": 42.991817474365234, "training_acc": 90.0, "val_loss": 13.381004333496094, "val_acc": 50.0, "val_auroc": 0.64, "time": 630.71}
{"epoch": 32, "training_loss": 39.104615211486816, "training_acc": 97.5, "val_loss": 13.425272703170776, "val_acc": 65.0, "val_auroc": 0.65, "time": 647.97}
{"epoch": 33, "training_loss": 39.71562099456787, "training_acc": 88.75, "val_loss": 13.51283073425293, "val_acc": 55.0, "val_auroc": 0.64, "time": 666.58}
{"epoch": 34, "training_loss": 39.2020206451416, "training_acc": 91.25, "val_loss": 14.159667491912842, "val_acc": 50.0, "val_auroc": 0.64, "time": 686.93}
{"epoch": 35, "training_loss": 39.57156848907471, "training_acc": 82.5, "val_loss": 14.390991926193237, "val_acc": 55.0, "val_auroc": 0.65, "time": 705.12}
{"epoch": 36, "training_loss": 50.060829162597656, "training_acc": 65.0, "val_loss": 13.384746313095093, "val_acc": 55.0, "val_auroc": 0.65, "time": 724.67}
{"epoch": 37, "training_loss": 42.94781017303467, "training_acc": 95.0, "val_loss": 14.12699580192566, "val_acc": 50.0, "val_auroc": 0.66, "time": 743.14}
{"epoch": 38, "training_loss": 41.59426784515381, "training_acc": 81.25, "val_loss": 13.660932779312134, "val_acc": 60.0, "val_auroc": 0.6, "time": 763.85}
{"epoch": 39, "training_loss": 40.36377000808716, "training_acc": 90.0, "val_loss": 13.576010465621948, "val_acc": 55.0, "val_auroc": 0.62, "time": 782.99}
{"epoch": 40, "training_loss": 36.4246244430542, "training_acc": 96.25, "val_loss": 13.754316568374634, "val_acc": 60.0, "val_auroc": 0.55, "time": 800.45}
{"epoch": 41, "training_loss": 34.33925437927246, "training_acc": 97.5, "val_loss": 13.749134540557861, "val_acc": 60.0, "val_auroc": 0.63, "time": 817.69}
{"epoch": 42, "training_loss": 32.60822010040283, "training_acc": 97.5, "val_loss": 14.012278318405151, "val_acc": 55.0, "val_auroc": 0.64, "time": 837.3}
{"epoch": 43, "training_loss": 33.45894908905029, "training_acc": 96.25, "val_loss": 14.212582111358643, "val_acc": 55.0, "val_auroc": 0.64, "time": 854.6}
{"epoch": 44, "training_loss": 33.65846633911133, "training_acc": 91.25, "val_loss": 13.473995923995972, "val_acc": 60.0, "val_auroc": 0.63, "time": 873.69}
{"epoch": 45, "training_loss": 29.807151317596436, "training_acc": 100.0, "val_loss": 13.366073369979858, "val_acc": 60.0, "val_auroc": 0.66, "time": 895.0}
{"epoch": 46, "training_loss": 27.336543083190918, "training_acc": 100.0, "val_loss": 13.077057600021362, "val_acc": 65.0, "val_auroc": 0.68, "time": 916.54}
{"epoch": 47, "training_loss": 27.67130994796753, "training_acc": 100.0, "val_loss": 13.516905307769775, "val_acc": 55.0, "val_auroc": 0.66, "time": 934.07}
{"epoch": 48, "training_loss": 26.460330486297607, "training_acc": 100.0, "val_loss": 13.100429773330688, "val_acc": 65.0, "val_auroc": 0.67, "time": 951.6}
{"epoch": 49, "training_loss": 25.73081398010254, "training_acc": 100.0, "val_loss": 13.087629079818726, "val_acc": 55.0, "val_auroc": 0.67, "time": 968.36}
{"epoch": 50, "training_loss": 24.803964138031006, "training_acc": 100.0, "val_loss": 12.878880500793457, "val_acc": 65.0, "val_auroc": 0.71, "time": 989.4}
{"epoch": 51, "training_loss": 24.03174638748169, "training_acc": 100.0, "val_loss": 13.250151872634888, "val_acc": 55.0, "val_auroc": 0.66, "time": 1006.23}
{"epoch": 52, "training_loss": 23.433255672454834, "training_acc": 100.0, "val_loss": 13.375452756881714, "val_acc": 55.0, "val_auroc": 0.65, "time": 1022.91}
{"epoch": 53, "training_loss": 23.200891971588135, "training_acc": 100.0, "val_loss": 13.412632942199707, "val_acc": 60.0, "val_auroc": 0.65, "time": 1040.64}
{"epoch": 54, "training_loss": 22.506749629974365, "training_acc": 100.0, "val_loss": 13.548721075057983, "val_acc": 60.0, "val_auroc": 0.64, "time": 1058.89}
{"epoch": 55, "training_loss": 22.000651359558105, "training_acc": 100.0, "val_loss": 13.559411764144897, "val_acc": 60.0, "val_auroc": 0.65, "time": 1076.81}
{"epoch": 56, "training_loss": 21.372065544128418, "training_acc": 100.0, "val_loss": 13.559750318527222, "val_acc": 60.0, "val_auroc": 0.65, "time": 1094.26}
{"epoch": 57, "training_loss": 20.851198196411133, "training_acc": 100.0, "val_loss": 13.72394323348999, "val_acc": 55.0, "val_auroc": 0.64, "time": 1111.65}
{"epoch": 58, "training_loss": 20.923006057739258, "training_acc": 100.0, "val_loss": 14.187681674957275, "val_acc": 55.0, "val_auroc": 0.64, "time": 1134.55}
{"epoch": 59, "training_loss": 20.14709997177124, "training_acc": 100.0, "val_loss": 13.900278806686401, "val_acc": 60.0, "val_auroc": 0.63, "time": 1151.33}
{"epoch": 60, "training_loss": 19.562596321105957, "training_acc": 100.0, "val_loss": 13.985906839370728, "val_acc": 60.0, "val_auroc": 0.62, "time": 1169.09}
{"epoch": 61, "training_loss": 19.438615322113037, "training_acc": 100.0, "val_loss": 14.158061742782593, "val_acc": 60.0, "val_auroc": 0.61, "time": 1186.33}
{"epoch": 62, "training_loss": 18.970152378082275, "training_acc": 100.0, "val_loss": 14.74306344985962, "val_acc": 50.0, "val_auroc": 0.61, "time": 1205.62}
{"epoch": 63, "training_loss": 19.713223934173584, "training_acc": 100.0, "val_loss": 15.09656548500061, "val_acc": 55.0, "val_auroc": 0.6, "time": 1223.84}
{"epoch": 64, "training_loss": 19.34294843673706, "training_acc": 100.0, "val_loss": 15.092548131942749, "val_acc": 50.0, "val_auroc": 0.6, "time": 1241.93}
{"epoch": 65, "training_loss": 18.895917177200317, "training_acc": 100.0, "val_loss": 14.674926996231079, "val_acc": 60.0, "val_auroc": 0.59, "time": 1258.8}
{"epoch": 66, "training_loss": 18.292564392089844, "training_acc": 100.0, "val_loss": 15.490943193435669, "val_acc": 55.0, "val_auroc": 0.59, "time": 1279.17}
{"epoch": 67, "training_loss": 19.205607891082764, "training_acc": 98.75, "val_loss": 14.746664762496948, "val_acc": 55.0, "val_auroc": 0.58, "time": 1297.99}
{"epoch": 68, "training_loss": 18.273447513580322, "training_acc": 100.0, "val_loss": 14.493690729141235, "val_acc": 55.0, "val_auroc": 0.59, "time": 1315.48}
{"epoch": 69, "training_loss": 17.683709621429443, "training_acc": 100.0, "val_loss": 14.517041444778442, "val_acc": 55.0, "val_auroc": 0.59, "time": 1334.1}
