"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.2480354309082, "training_acc": 46.25, "val_loss": 13.889402151107788, "val_acc": 50.0, "val_auroc": 0.48, "time": 17.28}
{"epoch": 1, "training_loss": 55.012794494628906, "training_acc": 58.75, "val_loss": 14.033840894699097, "val_acc": 50.0, "val_auroc": 0.6, "time": 33.48}
{"epoch": 2, "training_loss": 56.693899154663086, "training_acc": 50.0, "val_loss": 14.32646632194519, "val_acc": 50.0, "val_auroc": 0.55, "time": 49.06}
{"epoch": 3, "training_loss": 56.47751235961914, "training_acc": 52.5, "val_loss": 14.517549276351929, "val_acc": 50.0, "val_auroc": 0.49, "time": 63.98}
{"epoch": 4, "training_loss": 56.08213138580322, "training_acc": 52.5, "val_loss": 13.87065052986145, "val_acc": 50.0, "val_auroc": 0.53, "time": 79.31}
{"epoch": 5, "training_loss": 55.673696517944336, "training_acc": 47.5, "val_loss": 13.87378215789795, "val_acc": 50.0, "val_auroc": 0.54, "time": 94.58}
{"epoch": 6, "training_loss": 55.42183494567871, "training_acc": 47.5, "val_loss": 13.971060514450073, "val_acc": 50.0, "val_auroc": 0.31, "time": 110.09}
{"epoch": 7, "training_loss": 55.25411415100098, "training_acc": 52.5, "val_loss": 14.036903381347656, "val_acc": 50.0, "val_auroc": 0.37, "time": 127.43}
{"epoch": 8, "training_loss": 55.269290924072266, "training_acc": 52.5, "val_loss": 13.97562861442566, "val_acc": 50.0, "val_auroc": 0.41, "time": 142.53}
{"epoch": 9, "training_loss": 55.07347297668457, "training_acc": 52.5, "val_loss": 13.873335123062134, "val_acc": 50.0, "val_auroc": 0.46, "time": 157.59}
{"epoch": 10, "training_loss": 55.29475975036621, "training_acc": 48.75, "val_loss": 13.85510802268982, "val_acc": 50.0, "val_auroc": 0.52, "time": 172.96}
{"epoch": 11, "training_loss": 55.22377967834473, "training_acc": 50.0, "val_loss": 13.849753141403198, "val_acc": 50.0, "val_auroc": 0.57, "time": 188.53}
{"epoch": 12, "training_loss": 54.83442497253418, "training_acc": 52.5, "val_loss": 14.051178693771362, "val_acc": 50.0, "val_auroc": 0.59, "time": 204.34}
{"epoch": 13, "training_loss": 55.22430610656738, "training_acc": 52.5, "val_loss": 14.03328537940979, "val_acc": 50.0, "val_auroc": 0.78, "time": 219.51}
{"epoch": 14, "training_loss": 55.37960338592529, "training_acc": 52.5, "val_loss": 13.925762176513672, "val_acc": 50.0, "val_auroc": 0.79, "time": 234.85}
{"epoch": 15, "training_loss": 54.94604301452637, "training_acc": 52.5, "val_loss": 13.867766857147217, "val_acc": 50.0, "val_auroc": 0.79, "time": 249.76}
{"epoch": 16, "training_loss": 54.816468238830566, "training_acc": 52.5, "val_loss": 13.796788454055786, "val_acc": 50.0, "val_auroc": 0.77, "time": 265.08}
{"epoch": 17, "training_loss": 54.25358009338379, "training_acc": 52.5, "val_loss": 13.64195466041565, "val_acc": 50.0, "val_auroc": 0.77, "time": 280.47}
{"epoch": 18, "training_loss": 53.808653831481934, "training_acc": 73.75, "val_loss": 13.684307336807251, "val_acc": 50.0, "val_auroc": 0.8, "time": 295.3}
{"epoch": 19, "training_loss": 54.425912857055664, "training_acc": 50.0, "val_loss": 13.54101300239563, "val_acc": 50.0, "val_auroc": 0.83, "time": 310.81}
{"epoch": 20, "training_loss": 53.52778434753418, "training_acc": 68.75, "val_loss": 13.42713475227356, "val_acc": 50.0, "val_auroc": 0.85, "time": 326.13}
{"epoch": 21, "training_loss": 52.591835021972656, "training_acc": 75.0, "val_loss": 13.737132549285889, "val_acc": 50.0, "val_auroc": 0.81, "time": 341.21}
{"epoch": 22, "training_loss": 53.32641410827637, "training_acc": 52.5, "val_loss": 13.252061605453491, "val_acc": 50.0, "val_auroc": 0.84, "time": 356.54}
{"epoch": 23, "training_loss": 52.09757137298584, "training_acc": 72.5, "val_loss": 13.5769784450531, "val_acc": 50.0, "val_auroc": 0.83, "time": 371.55}
{"epoch": 24, "training_loss": 51.61769485473633, "training_acc": 52.5, "val_loss": 13.131674528121948, "val_acc": 50.0, "val_auroc": 0.87, "time": 386.98}
{"epoch": 25, "training_loss": 50.59076118469238, "training_acc": 70.0, "val_loss": 12.920517921447754, "val_acc": 50.0, "val_auroc": 0.9, "time": 402.21}
{"epoch": 26, "training_loss": 49.81191444396973, "training_acc": 75.0, "val_loss": 12.670398950576782, "val_acc": 50.0, "val_auroc": 0.86, "time": 417.43}
{"epoch": 27, "training_loss": 47.06351184844971, "training_acc": 76.25, "val_loss": 15.802068710327148, "val_acc": 50.0, "val_auroc": 0.83, "time": 434.34}
{"epoch": 28, "training_loss": 54.65679740905762, "training_acc": 52.5, "val_loss": 16.325225830078125, "val_acc": 50.0, "val_auroc": 0.87, "time": 449.6}
{"epoch": 29, "training_loss": 65.89337921142578, "training_acc": 47.5, "val_loss": 15.88699221611023, "val_acc": 50.0, "val_auroc": 0.84, "time": 465.13}
{"epoch": 30, "training_loss": 62.57213878631592, "training_acc": 47.5, "val_loss": 14.144045114517212, "val_acc": 50.0, "val_auroc": 0.52, "time": 480.0}
{"epoch": 31, "training_loss": 56.76641654968262, "training_acc": 52.5, "val_loss": 15.21525502204895, "val_acc": 50.0, "val_auroc": 0.51, "time": 494.93}
{"epoch": 32, "training_loss": 58.29790782928467, "training_acc": 52.5, "val_loss": 13.929976224899292, "val_acc": 50.0, "val_auroc": 0.67, "time": 510.18}
{"epoch": 33, "training_loss": 55.25376319885254, "training_acc": 52.5, "val_loss": 13.819358348846436, "val_acc": 50.0, "val_auroc": 0.74, "time": 525.01}
{"epoch": 34, "training_loss": 55.183199882507324, "training_acc": 57.5, "val_loss": 13.81888747215271, "val_acc": 50.0, "val_auroc": 0.68, "time": 540.03}
{"epoch": 35, "training_loss": 55.24941539764404, "training_acc": 55.0, "val_loss": 13.8235604763031, "val_acc": 50.0, "val_auroc": 0.66, "time": 555.15}
{"epoch": 36, "training_loss": 55.02425765991211, "training_acc": 56.25, "val_loss": 13.847883939743042, "val_acc": 50.0, "val_auroc": 0.66, "time": 570.58}
{"epoch": 37, "training_loss": 55.351911544799805, "training_acc": 47.5, "val_loss": 13.948613405227661, "val_acc": 50.0, "val_auroc": 0.62, "time": 585.46}
{"epoch": 38, "training_loss": 56.075103759765625, "training_acc": 47.5, "val_loss": 13.956027030944824, "val_acc": 50.0, "val_auroc": 0.61, "time": 600.48}
{"epoch": 39, "training_loss": 56.08332920074463, "training_acc": 47.5, "val_loss": 13.827874660491943, "val_acc": 50.0, "val_auroc": 0.59, "time": 615.27}
{"epoch": 40, "training_loss": 55.250478744506836, "training_acc": 48.75, "val_loss": 13.829172849655151, "val_acc": 50.0, "val_auroc": 0.63, "time": 630.42}
{"epoch": 41, "training_loss": 55.23524475097656, "training_acc": 53.75, "val_loss": 13.865021467208862, "val_acc": 50.0, "val_auroc": 0.66, "time": 645.45}
{"epoch": 42, "training_loss": 55.11012840270996, "training_acc": 52.5, "val_loss": 13.82719874382019, "val_acc": 50.0, "val_auroc": 0.69, "time": 660.22}
{"epoch": 43, "training_loss": 54.97350025177002, "training_acc": 52.5, "val_loss": 13.801530599594116, "val_acc": 50.0, "val_auroc": 0.68, "time": 674.77}
{"epoch": 44, "training_loss": 54.91610908508301, "training_acc": 52.5, "val_loss": 13.78203272819519, "val_acc": 50.0, "val_auroc": 0.71, "time": 689.45}
{"epoch": 45, "training_loss": 54.90752029418945, "training_acc": 53.75, "val_loss": 13.761513233184814, "val_acc": 50.0, "val_auroc": 0.72, "time": 704.37}
