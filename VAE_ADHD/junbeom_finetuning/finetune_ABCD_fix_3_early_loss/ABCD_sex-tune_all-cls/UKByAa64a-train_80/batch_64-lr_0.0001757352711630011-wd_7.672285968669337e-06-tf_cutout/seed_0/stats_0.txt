"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.694777488708496, "training_acc": 52.5, "val_loss": 13.903398513793945, "val_acc": 50.0, "val_auroc": 0.4, "time": 18.73}
{"epoch": 1, "training_loss": 55.568532943725586, "training_acc": 52.5, "val_loss": 13.959959745407104, "val_acc": 50.0, "val_auroc": 0.35, "time": 34.12}
{"epoch": 2, "training_loss": 55.403236389160156, "training_acc": 52.5, "val_loss": 13.872716426849365, "val_acc": 50.0, "val_auroc": 0.41, "time": 49.88}
{"epoch": 3, "training_loss": 55.37672996520996, "training_acc": 52.5, "val_loss": 13.87056589126587, "val_acc": 50.0, "val_auroc": 0.41, "time": 65.03}
{"epoch": 4, "training_loss": 55.383121490478516, "training_acc": 52.5, "val_loss": 13.874433040618896, "val_acc": 50.0, "val_auroc": 0.31, "time": 80.22}
{"epoch": 5, "training_loss": 55.45043182373047, "training_acc": 52.5, "val_loss": 13.866027593612671, "val_acc": 50.0, "val_auroc": 0.4, "time": 96.27}
{"epoch": 6, "training_loss": 55.41982173919678, "training_acc": 52.5, "val_loss": 13.866915702819824, "val_acc": 50.0, "val_auroc": 0.44, "time": 111.59}
{"epoch": 7, "training_loss": 55.568843841552734, "training_acc": 45.0, "val_loss": 13.86611819267273, "val_acc": 50.0, "val_auroc": 0.4, "time": 128.15}
{"epoch": 8, "training_loss": 55.471041679382324, "training_acc": 47.5, "val_loss": 13.865513801574707, "val_acc": 50.0, "val_auroc": 0.36, "time": 144.38}
{"epoch": 9, "training_loss": 55.450608253479004, "training_acc": 50.0, "val_loss": 13.875370025634766, "val_acc": 50.0, "val_auroc": 0.38, "time": 160.05}
{"epoch": 10, "training_loss": 55.348154067993164, "training_acc": 52.5, "val_loss": 13.909974098205566, "val_acc": 50.0, "val_auroc": 0.46, "time": 175.26}
{"epoch": 11, "training_loss": 55.34779739379883, "training_acc": 52.5, "val_loss": 13.999899625778198, "val_acc": 50.0, "val_auroc": 0.54, "time": 192.28}
{"epoch": 12, "training_loss": 55.515703201293945, "training_acc": 52.5, "val_loss": 14.089497327804565, "val_acc": 50.0, "val_auroc": 0.72, "time": 206.79}
{"epoch": 13, "training_loss": 55.826602935791016, "training_acc": 52.5, "val_loss": 14.137352705001831, "val_acc": 50.0, "val_auroc": 0.65, "time": 222.12}
{"epoch": 14, "training_loss": 55.983479499816895, "training_acc": 52.5, "val_loss": 14.225939512252808, "val_acc": 50.0, "val_auroc": 0.56, "time": 237.81}
{"epoch": 15, "training_loss": 56.136112213134766, "training_acc": 52.5, "val_loss": 14.26793098449707, "val_acc": 50.0, "val_auroc": 0.5, "time": 252.96}
{"epoch": 16, "training_loss": 56.28672122955322, "training_acc": 52.5, "val_loss": 14.15290117263794, "val_acc": 50.0, "val_auroc": 0.42, "time": 268.32}
{"epoch": 17, "training_loss": 55.86232948303223, "training_acc": 52.5, "val_loss": 13.983421325683594, "val_acc": 50.0, "val_auroc": 0.38, "time": 283.81}
{"epoch": 18, "training_loss": 55.51074028015137, "training_acc": 52.5, "val_loss": 13.88381838798523, "val_acc": 50.0, "val_auroc": 0.32, "time": 299.4}
{"epoch": 19, "training_loss": 55.34311389923096, "training_acc": 52.5, "val_loss": 13.863586187362671, "val_acc": 50.0, "val_auroc": 0.56, "time": 315.5}
{"epoch": 20, "training_loss": 55.45522689819336, "training_acc": 47.5, "val_loss": 13.909494876861572, "val_acc": 50.0, "val_auroc": 0.69, "time": 331.52}
{"epoch": 21, "training_loss": 56.00393295288086, "training_acc": 47.5, "val_loss": 13.888810873031616, "val_acc": 50.0, "val_auroc": 0.69, "time": 347.0}
{"epoch": 22, "training_loss": 55.62276649475098, "training_acc": 47.5, "val_loss": 13.874715566635132, "val_acc": 50.0, "val_auroc": 0.35, "time": 362.46}
{"epoch": 23, "training_loss": 55.39901638031006, "training_acc": 52.5, "val_loss": 13.957312107086182, "val_acc": 50.0, "val_auroc": 0.44, "time": 377.83}
{"epoch": 24, "training_loss": 55.48634910583496, "training_acc": 52.5, "val_loss": 13.951847553253174, "val_acc": 50.0, "val_auroc": 0.5, "time": 393.77}
{"epoch": 25, "training_loss": 55.396406173706055, "training_acc": 52.5, "val_loss": 13.885061740875244, "val_acc": 50.0, "val_auroc": 0.48, "time": 409.04}
{"epoch": 26, "training_loss": 55.381314277648926, "training_acc": 52.5, "val_loss": 13.866024017333984, "val_acc": 50.0, "val_auroc": 0.67, "time": 424.64}
{"epoch": 27, "training_loss": 55.408082008361816, "training_acc": 52.5, "val_loss": 13.879477977752686, "val_acc": 50.0, "val_auroc": 0.65, "time": 439.9}
{"epoch": 28, "training_loss": 55.50728225708008, "training_acc": 52.5, "val_loss": 13.894041776657104, "val_acc": 50.0, "val_auroc": 0.55, "time": 455.81}
{"epoch": 29, "training_loss": 55.36841297149658, "training_acc": 52.5, "val_loss": 13.876844644546509, "val_acc": 50.0, "val_auroc": 0.57, "time": 471.55}
{"epoch": 30, "training_loss": 55.36185359954834, "training_acc": 52.5, "val_loss": 13.882070779800415, "val_acc": 50.0, "val_auroc": 0.52, "time": 489.0}
{"epoch": 31, "training_loss": 55.357343673706055, "training_acc": 52.5, "val_loss": 13.891382217407227, "val_acc": 50.0, "val_auroc": 0.53, "time": 504.81}
{"epoch": 32, "training_loss": 55.368743896484375, "training_acc": 52.5, "val_loss": 13.882616758346558, "val_acc": 50.0, "val_auroc": 0.51, "time": 519.52}
{"epoch": 33, "training_loss": 55.41370677947998, "training_acc": 52.5, "val_loss": 13.877016305923462, "val_acc": 50.0, "val_auroc": 0.48, "time": 534.79}
{"epoch": 34, "training_loss": 55.340383529663086, "training_acc": 52.5, "val_loss": 13.911312818527222, "val_acc": 50.0, "val_auroc": 0.42, "time": 550.01}
{"epoch": 35, "training_loss": 55.507381439208984, "training_acc": 52.5, "val_loss": 13.931699991226196, "val_acc": 50.0, "val_auroc": 0.41, "time": 564.74}
{"epoch": 36, "training_loss": 55.37370681762695, "training_acc": 52.5, "val_loss": 13.892261981964111, "val_acc": 50.0, "val_auroc": 0.49, "time": 579.95}
{"epoch": 37, "training_loss": 55.31653308868408, "training_acc": 52.5, "val_loss": 13.864976167678833, "val_acc": 50.0, "val_auroc": 0.48, "time": 594.91}
{"epoch": 38, "training_loss": 55.44853973388672, "training_acc": 50.0, "val_loss": 13.865317106246948, "val_acc": 50.0, "val_auroc": 0.7, "time": 609.37}
