"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.49754524230957, "training_acc": 51.25, "val_loss": 13.797363042831421, "val_acc": 55.0, "val_auroc": 0.374, "time": 19.59}
{"epoch": 1, "training_loss": 55.47825908660889, "training_acc": 51.25, "val_loss": 13.793268203735352, "val_acc": 55.0, "val_auroc": 0.374, "time": 37.13}
{"epoch": 2, "training_loss": 55.469780921936035, "training_acc": 51.25, "val_loss": 13.728004693984985, "val_acc": 55.0, "val_auroc": 0.636, "time": 54.44}
{"epoch": 3, "training_loss": 55.47757434844971, "training_acc": 51.25, "val_loss": 13.733521699905396, "val_acc": 55.0, "val_auroc": 0.747, "time": 73.63}
{"epoch": 4, "training_loss": 55.34605407714844, "training_acc": 51.25, "val_loss": 13.824520111083984, "val_acc": 55.0, "val_auroc": 0.475, "time": 91.32}
{"epoch": 5, "training_loss": 55.305795669555664, "training_acc": 51.25, "val_loss": 13.856635093688965, "val_acc": 55.0, "val_auroc": 0.414, "time": 109.19}
{"epoch": 6, "training_loss": 55.24133777618408, "training_acc": 55.0, "val_loss": 13.897708654403687, "val_acc": 55.0, "val_auroc": 0.364, "time": 127.83}
{"epoch": 7, "training_loss": 55.19722366333008, "training_acc": 50.0, "val_loss": 13.90181303024292, "val_acc": 55.0, "val_auroc": 0.333, "time": 145.42}
{"epoch": 8, "training_loss": 55.17635631561279, "training_acc": 55.0, "val_loss": 13.928155899047852, "val_acc": 55.0, "val_auroc": 0.374, "time": 162.37}
{"epoch": 9, "training_loss": 55.25275421142578, "training_acc": 52.5, "val_loss": 13.936654329299927, "val_acc": 55.0, "val_auroc": 0.384, "time": 179.27}
{"epoch": 10, "training_loss": 55.11289596557617, "training_acc": 58.75, "val_loss": 13.89011263847351, "val_acc": 55.0, "val_auroc": 0.434, "time": 195.92}
{"epoch": 11, "training_loss": 55.010661125183105, "training_acc": 57.5, "val_loss": 13.850284814834595, "val_acc": 55.0, "val_auroc": 0.455, "time": 217.69}
{"epoch": 12, "training_loss": 54.80622482299805, "training_acc": 52.5, "val_loss": 13.845826387405396, "val_acc": 55.0, "val_auroc": 0.424, "time": 236.01}
{"epoch": 13, "training_loss": 54.668270111083984, "training_acc": 52.5, "val_loss": 13.838443756103516, "val_acc": 55.0, "val_auroc": 0.485, "time": 253.59}
{"epoch": 14, "training_loss": 54.5397367477417, "training_acc": 51.25, "val_loss": 13.8290274143219, "val_acc": 55.0, "val_auroc": 0.556, "time": 270.96}
{"epoch": 15, "training_loss": 54.64880847930908, "training_acc": 67.5, "val_loss": 13.964099884033203, "val_acc": 55.0, "val_auroc": 0.414, "time": 288.75}
{"epoch": 16, "training_loss": 54.24411678314209, "training_acc": 70.0, "val_loss": 13.913896083831787, "val_acc": 55.0, "val_auroc": 0.343, "time": 307.62}
{"epoch": 17, "training_loss": 55.16181564331055, "training_acc": 51.25, "val_loss": 13.862820863723755, "val_acc": 55.0, "val_auroc": 0.404, "time": 324.33}
{"epoch": 18, "training_loss": 54.653273582458496, "training_acc": 51.25, "val_loss": 13.905489444732666, "val_acc": 55.0, "val_auroc": 0.424, "time": 340.91}
{"epoch": 19, "training_loss": 53.96491718292236, "training_acc": 62.5, "val_loss": 13.862427473068237, "val_acc": 55.0, "val_auroc": 0.545, "time": 359.25}
{"epoch": 20, "training_loss": 54.28963661193848, "training_acc": 76.25, "val_loss": 13.996952772140503, "val_acc": 55.0, "val_auroc": 0.455, "time": 377.16}
{"epoch": 21, "training_loss": 53.426963806152344, "training_acc": 68.75, "val_loss": 13.962455987930298, "val_acc": 55.0, "val_auroc": 0.404, "time": 394.34}
