"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.465606689453125, "training_acc": 51.25, "val_loss": 13.868948221206665, "val_acc": 50.0, "val_auroc": 0.56, "time": 19.76}
{"epoch": 1, "training_loss": 55.2959098815918, "training_acc": 52.5, "val_loss": 13.91179084777832, "val_acc": 50.0, "val_auroc": 0.36, "time": 37.34}
{"epoch": 2, "training_loss": 55.20161056518555, "training_acc": 52.5, "val_loss": 13.862485885620117, "val_acc": 50.0, "val_auroc": 0.61, "time": 55.89}
{"epoch": 3, "training_loss": 55.25913619995117, "training_acc": 52.5, "val_loss": 13.893235921859741, "val_acc": 50.0, "val_auroc": 0.6, "time": 79.22}
{"epoch": 4, "training_loss": 55.19295883178711, "training_acc": 52.5, "val_loss": 13.956928253173828, "val_acc": 50.0, "val_auroc": 0.37, "time": 98.75}
{"epoch": 5, "training_loss": 55.167354583740234, "training_acc": 52.5, "val_loss": 13.865102529525757, "val_acc": 50.0, "val_auroc": 0.58, "time": 115.7}
{"epoch": 6, "training_loss": 55.10184097290039, "training_acc": 52.5, "val_loss": 13.925697803497314, "val_acc": 50.0, "val_auroc": 0.46, "time": 133.05}
{"epoch": 7, "training_loss": 54.89631652832031, "training_acc": 52.5, "val_loss": 13.999543190002441, "val_acc": 50.0, "val_auroc": 0.34, "time": 152.65}
{"epoch": 8, "training_loss": 55.058780670166016, "training_acc": 52.5, "val_loss": 13.875255584716797, "val_acc": 50.0, "val_auroc": 0.59, "time": 170.34}
{"epoch": 9, "training_loss": 55.2162561416626, "training_acc": 52.5, "val_loss": 13.859738111495972, "val_acc": 50.0, "val_auroc": 0.51, "time": 188.04}
{"epoch": 10, "training_loss": 55.297061920166016, "training_acc": 52.5, "val_loss": 13.861289024353027, "val_acc": 50.0, "val_auroc": 0.53, "time": 205.07}
{"epoch": 11, "training_loss": 55.09846591949463, "training_acc": 52.5, "val_loss": 13.904231786727905, "val_acc": 50.0, "val_auroc": 0.47, "time": 224.39}
{"epoch": 12, "training_loss": 55.08316135406494, "training_acc": 52.5, "val_loss": 13.930405378341675, "val_acc": 50.0, "val_auroc": 0.43, "time": 243.04}
{"epoch": 13, "training_loss": 55.08260536193848, "training_acc": 52.5, "val_loss": 13.865026235580444, "val_acc": 50.0, "val_auroc": 0.6, "time": 260.26}
{"epoch": 14, "training_loss": 54.909016609191895, "training_acc": 52.5, "val_loss": 13.837529420852661, "val_acc": 50.0, "val_auroc": 0.63, "time": 277.38}
{"epoch": 15, "training_loss": 54.89645576477051, "training_acc": 52.5, "val_loss": 13.924583196640015, "val_acc": 50.0, "val_auroc": 0.52, "time": 295.87}
{"epoch": 16, "training_loss": 54.60626697540283, "training_acc": 52.5, "val_loss": 14.073694944381714, "val_acc": 50.0, "val_auroc": 0.49, "time": 313.18}
{"epoch": 17, "training_loss": 55.17624282836914, "training_acc": 52.5, "val_loss": 13.937697410583496, "val_acc": 50.0, "val_auroc": 0.48, "time": 330.83}
{"epoch": 18, "training_loss": 54.55943298339844, "training_acc": 52.5, "val_loss": 13.826764822006226, "val_acc": 50.0, "val_auroc": 0.66, "time": 347.96}
{"epoch": 19, "training_loss": 54.90345001220703, "training_acc": 60.0, "val_loss": 13.862842321395874, "val_acc": 50.0, "val_auroc": 0.6, "time": 365.29}
{"epoch": 20, "training_loss": 54.85531139373779, "training_acc": 63.75, "val_loss": 13.897463083267212, "val_acc": 50.0, "val_auroc": 0.43, "time": 383.54}
{"epoch": 21, "training_loss": 54.4684419631958, "training_acc": 62.5, "val_loss": 13.936727046966553, "val_acc": 50.0, "val_auroc": 0.43, "time": 400.74}
{"epoch": 22, "training_loss": 54.22216606140137, "training_acc": 52.5, "val_loss": 13.850857019424438, "val_acc": 50.0, "val_auroc": 0.47, "time": 418.75}
{"epoch": 23, "training_loss": 53.15549850463867, "training_acc": 80.0, "val_loss": 13.855139017105103, "val_acc": 50.0, "val_auroc": 0.46, "time": 436.87}
{"epoch": 24, "training_loss": 52.53922462463379, "training_acc": 63.75, "val_loss": 14.149640798568726, "val_acc": 50.0, "val_auroc": 0.47, "time": 453.62}
{"epoch": 25, "training_loss": 53.51484394073486, "training_acc": 56.25, "val_loss": 13.784419298171997, "val_acc": 50.0, "val_auroc": 0.52, "time": 471.74}
{"epoch": 26, "training_loss": 54.06489372253418, "training_acc": 63.75, "val_loss": 13.882783651351929, "val_acc": 50.0, "val_auroc": 0.48, "time": 488.62}
{"epoch": 27, "training_loss": 52.55668067932129, "training_acc": 57.5, "val_loss": 13.982347249984741, "val_acc": 50.0, "val_auroc": 0.49, "time": 505.08}
{"epoch": 28, "training_loss": 52.00311470031738, "training_acc": 55.0, "val_loss": 13.800266981124878, "val_acc": 50.0, "val_auroc": 0.54, "time": 522.82}
{"epoch": 29, "training_loss": 54.57373046875, "training_acc": 60.0, "val_loss": 13.834786415100098, "val_acc": 50.0, "val_auroc": 0.57, "time": 540.03}
{"epoch": 30, "training_loss": 55.13742733001709, "training_acc": 58.75, "val_loss": 13.865245580673218, "val_acc": 50.0, "val_auroc": 0.52, "time": 557.13}
{"epoch": 31, "training_loss": 54.78526973724365, "training_acc": 52.5, "val_loss": 13.91318678855896, "val_acc": 50.0, "val_auroc": 0.53, "time": 573.84}
{"epoch": 32, "training_loss": 54.36879920959473, "training_acc": 52.5, "val_loss": 13.835628032684326, "val_acc": 50.0, "val_auroc": 0.54, "time": 590.76}
{"epoch": 33, "training_loss": 54.10725212097168, "training_acc": 61.25, "val_loss": 13.827425241470337, "val_acc": 50.0, "val_auroc": 0.54, "time": 607.69}
{"epoch": 34, "training_loss": 54.45513916015625, "training_acc": 65.0, "val_loss": 13.886873722076416, "val_acc": 50.0, "val_auroc": 0.57, "time": 626.62}
{"epoch": 35, "training_loss": 54.04720115661621, "training_acc": 56.25, "val_loss": 13.901647329330444, "val_acc": 50.0, "val_auroc": 0.58, "time": 643.31}
{"epoch": 36, "training_loss": 52.12375259399414, "training_acc": 71.25, "val_loss": 13.796601295471191, "val_acc": 50.0, "val_auroc": 0.58, "time": 660.77}
{"epoch": 37, "training_loss": 52.626288414001465, "training_acc": 72.5, "val_loss": 13.798620700836182, "val_acc": 50.0, "val_auroc": 0.58, "time": 678.19}
{"epoch": 38, "training_loss": 51.50539302825928, "training_acc": 72.5, "val_loss": 13.722553253173828, "val_acc": 50.0, "val_auroc": 0.57, "time": 696.57}
{"epoch": 39, "training_loss": 49.466081619262695, "training_acc": 76.25, "val_loss": 13.874527215957642, "val_acc": 50.0, "val_auroc": 0.59, "time": 713.59}
{"epoch": 40, "training_loss": 49.90981674194336, "training_acc": 72.5, "val_loss": 13.958683013916016, "val_acc": 50.0, "val_auroc": 0.54, "time": 730.69}
{"epoch": 41, "training_loss": 46.868407249450684, "training_acc": 83.75, "val_loss": 13.803499937057495, "val_acc": 50.0, "val_auroc": 0.56, "time": 747.5}
{"epoch": 42, "training_loss": 42.436471939086914, "training_acc": 93.75, "val_loss": 13.90189528465271, "val_acc": 55.0, "val_auroc": 0.55, "time": 766.4}
{"epoch": 43, "training_loss": 42.0799503326416, "training_acc": 90.0, "val_loss": 14.28330659866333, "val_acc": 55.0, "val_auroc": 0.54, "time": 783.44}
{"epoch": 44, "training_loss": 45.79497051239014, "training_acc": 80.0, "val_loss": 13.808711767196655, "val_acc": 50.0, "val_auroc": 0.56, "time": 801.9}
{"epoch": 45, "training_loss": 37.41948127746582, "training_acc": 96.25, "val_loss": 13.675901889801025, "val_acc": 50.0, "val_auroc": 0.65, "time": 819.45}
{"epoch": 46, "training_loss": 38.72232151031494, "training_acc": 87.5, "val_loss": 13.64681601524353, "val_acc": 50.0, "val_auroc": 0.58, "time": 838.12}
{"epoch": 47, "training_loss": 34.06662940979004, "training_acc": 97.5, "val_loss": 14.112144708633423, "val_acc": 50.0, "val_auroc": 0.59, "time": 855.63}
{"epoch": 48, "training_loss": 35.89884042739868, "training_acc": 95.0, "val_loss": 13.820075988769531, "val_acc": 55.0, "val_auroc": 0.58, "time": 875.13}
{"epoch": 49, "training_loss": 30.13514804840088, "training_acc": 100.0, "val_loss": 14.061508178710938, "val_acc": 60.0, "val_auroc": 0.58, "time": 892.44}
{"epoch": 50, "training_loss": 28.348164081573486, "training_acc": 100.0, "val_loss": 14.70288872718811, "val_acc": 50.0, "val_auroc": 0.49, "time": 909.47}
{"epoch": 51, "training_loss": 29.35370683670044, "training_acc": 97.5, "val_loss": 14.60951566696167, "val_acc": 65.0, "val_auroc": 0.54, "time": 928.31}
{"epoch": 52, "training_loss": 26.068431854248047, "training_acc": 100.0, "val_loss": 14.496009349822998, "val_acc": 50.0, "val_auroc": 0.53, "time": 946.07}
{"epoch": 53, "training_loss": 26.04404067993164, "training_acc": 100.0, "val_loss": 14.731529951095581, "val_acc": 60.0, "val_auroc": 0.58, "time": 962.81}
{"epoch": 54, "training_loss": 26.437246322631836, "training_acc": 100.0, "val_loss": 15.820068120956421, "val_acc": 50.0, "val_auroc": 0.49, "time": 980.37}
{"epoch": 55, "training_loss": 27.681837558746338, "training_acc": 97.5, "val_loss": 14.907678365707397, "val_acc": 55.0, "val_auroc": 0.56, "time": 998.62}
{"epoch": 56, "training_loss": 23.88002109527588, "training_acc": 100.0, "val_loss": 16.031605005264282, "val_acc": 50.0, "val_auroc": 0.52, "time": 1016.0}
{"epoch": 57, "training_loss": 24.594039916992188, "training_acc": 100.0, "val_loss": 15.725064277648926, "val_acc": 50.0, "val_auroc": 0.56, "time": 1032.71}
{"epoch": 58, "training_loss": 25.335034370422363, "training_acc": 97.5, "val_loss": 15.636756420135498, "val_acc": 50.0, "val_auroc": 0.54, "time": 1051.62}
{"epoch": 59, "training_loss": 22.598273754119873, "training_acc": 100.0, "val_loss": 14.619277715682983, "val_acc": 60.0, "val_auroc": 0.54, "time": 1070.8}
{"epoch": 60, "training_loss": 20.73506736755371, "training_acc": 100.0, "val_loss": 15.101178884506226, "val_acc": 50.0, "val_auroc": 0.57, "time": 1088.85}
{"epoch": 61, "training_loss": 19.758147716522217, "training_acc": 100.0, "val_loss": 15.155924558639526, "val_acc": 50.0, "val_auroc": 0.52, "time": 1106.42}
{"epoch": 62, "training_loss": 19.069836139678955, "training_acc": 100.0, "val_loss": 15.09002685546875, "val_acc": 60.0, "val_auroc": 0.57, "time": 1123.91}
{"epoch": 63, "training_loss": 18.502658367156982, "training_acc": 100.0, "val_loss": 15.077238082885742, "val_acc": 60.0, "val_auroc": 0.58, "time": 1142.44}
{"epoch": 64, "training_loss": 18.261173486709595, "training_acc": 100.0, "val_loss": 15.38766860961914, "val_acc": 45.0, "val_auroc": 0.52, "time": 1159.61}
{"epoch": 65, "training_loss": 18.330900192260742, "training_acc": 100.0, "val_loss": 16.217777729034424, "val_acc": 55.0, "val_auroc": 0.53, "time": 1176.4}
