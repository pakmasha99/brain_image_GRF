"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.43975353240967, "training_acc": 58.75, "val_loss": 15.431617498397827, "val_acc": 50.0, "val_auroc": 0.46, "time": 17.03}
{"epoch": 1, "training_loss": 58.97177696228027, "training_acc": 52.5, "val_loss": 13.88614535331726, "val_acc": 50.0, "val_auroc": 0.44, "time": 32.16}
{"epoch": 2, "training_loss": 56.238386154174805, "training_acc": 50.0, "val_loss": 15.249019861221313, "val_acc": 50.0, "val_auroc": 0.64, "time": 46.81}
{"epoch": 3, "training_loss": 59.98180961608887, "training_acc": 52.5, "val_loss": 14.704958200454712, "val_acc": 50.0, "val_auroc": 0.55, "time": 63.58}
{"epoch": 4, "training_loss": 57.302584648132324, "training_acc": 52.5, "val_loss": 13.883293867111206, "val_acc": 50.0, "val_auroc": 0.57, "time": 78.93}
{"epoch": 5, "training_loss": 56.00473403930664, "training_acc": 47.5, "val_loss": 13.884878158569336, "val_acc": 50.0, "val_auroc": 0.35, "time": 93.62}
{"epoch": 6, "training_loss": 55.056968688964844, "training_acc": 52.5, "val_loss": 14.425328969955444, "val_acc": 50.0, "val_auroc": 0.41, "time": 108.29}
{"epoch": 7, "training_loss": 56.715410232543945, "training_acc": 52.5, "val_loss": 14.261410236358643, "val_acc": 50.0, "val_auroc": 0.34, "time": 123.69}
{"epoch": 8, "training_loss": 55.76028537750244, "training_acc": 52.5, "val_loss": 13.867329359054565, "val_acc": 50.0, "val_auroc": 0.26, "time": 138.8}
{"epoch": 9, "training_loss": 55.520931243896484, "training_acc": 47.5, "val_loss": 13.979809284210205, "val_acc": 50.0, "val_auroc": 0.3, "time": 153.85}
{"epoch": 10, "training_loss": 56.19266319274902, "training_acc": 47.5, "val_loss": 13.870582580566406, "val_acc": 50.0, "val_auroc": 0.27, "time": 170.11}
{"epoch": 11, "training_loss": 55.21233081817627, "training_acc": 52.5, "val_loss": 14.099792242050171, "val_acc": 50.0, "val_auroc": 0.62, "time": 185.18}
{"epoch": 12, "training_loss": 55.89802551269531, "training_acc": 52.5, "val_loss": 14.112604856491089, "val_acc": 50.0, "val_auroc": 0.72, "time": 200.41}
{"epoch": 13, "training_loss": 55.69013023376465, "training_acc": 52.5, "val_loss": 13.853260278701782, "val_acc": 50.0, "val_auroc": 0.75, "time": 215.69}
{"epoch": 14, "training_loss": 55.41179084777832, "training_acc": 52.5, "val_loss": 13.888462781906128, "val_acc": 50.0, "val_auroc": 0.74, "time": 230.58}
{"epoch": 15, "training_loss": 55.807016372680664, "training_acc": 47.5, "val_loss": 13.890703916549683, "val_acc": 50.0, "val_auroc": 0.24, "time": 245.72}
{"epoch": 16, "training_loss": 55.12103080749512, "training_acc": 52.5, "val_loss": 14.188047647476196, "val_acc": 50.0, "val_auroc": 0.17, "time": 260.8}
{"epoch": 17, "training_loss": 56.116634368896484, "training_acc": 52.5, "val_loss": 14.240541458129883, "val_acc": 50.0, "val_auroc": 0.16, "time": 275.79}
{"epoch": 18, "training_loss": 55.97466468811035, "training_acc": 52.5, "val_loss": 13.94710898399353, "val_acc": 50.0, "val_auroc": 0.54, "time": 290.81}
{"epoch": 19, "training_loss": 55.26887512207031, "training_acc": 52.5, "val_loss": 13.859636783599854, "val_acc": 50.0, "val_auroc": 0.64, "time": 306.2}
{"epoch": 20, "training_loss": 55.61178779602051, "training_acc": 47.5, "val_loss": 13.876858949661255, "val_acc": 50.0, "val_auroc": 0.64, "time": 320.95}
{"epoch": 21, "training_loss": 55.615474700927734, "training_acc": 47.5, "val_loss": 13.868881464004517, "val_acc": 50.0, "val_auroc": 0.83, "time": 335.57}
{"epoch": 22, "training_loss": 55.30332374572754, "training_acc": 52.5, "val_loss": 14.018627405166626, "val_acc": 50.0, "val_auroc": 0.59, "time": 350.77}
{"epoch": 23, "training_loss": 55.56661796569824, "training_acc": 52.5, "val_loss": 14.10029649734497, "val_acc": 50.0, "val_auroc": 0.82, "time": 367.14}
{"epoch": 24, "training_loss": 55.81517314910889, "training_acc": 52.5, "val_loss": 14.075669050216675, "val_acc": 50.0, "val_auroc": 0.81, "time": 382.02}
{"epoch": 25, "training_loss": 55.733102798461914, "training_acc": 52.5, "val_loss": 13.993871212005615, "val_acc": 50.0, "val_auroc": 0.83, "time": 397.42}
{"epoch": 26, "training_loss": 55.69107627868652, "training_acc": 52.5, "val_loss": 13.95479679107666, "val_acc": 50.0, "val_auroc": 0.79, "time": 412.98}
{"epoch": 27, "training_loss": 55.42689895629883, "training_acc": 52.5, "val_loss": 13.987811803817749, "val_acc": 50.0, "val_auroc": 0.52, "time": 428.04}
{"epoch": 28, "training_loss": 55.59992790222168, "training_acc": 52.5, "val_loss": 13.91109585762024, "val_acc": 50.0, "val_auroc": 0.62, "time": 442.66}
{"epoch": 29, "training_loss": 55.40927791595459, "training_acc": 52.5, "val_loss": 13.858436346054077, "val_acc": 50.0, "val_auroc": 0.72, "time": 457.21}
{"epoch": 30, "training_loss": 55.456003189086914, "training_acc": 50.0, "val_loss": 13.859671354293823, "val_acc": 50.0, "val_auroc": 0.64, "time": 471.86}
{"epoch": 31, "training_loss": 55.49683475494385, "training_acc": 45.0, "val_loss": 13.85853886604309, "val_acc": 50.0, "val_auroc": 0.74, "time": 486.18}
{"epoch": 32, "training_loss": 55.42268180847168, "training_acc": 52.5, "val_loss": 13.85775089263916, "val_acc": 50.0, "val_auroc": 0.72, "time": 500.42}
