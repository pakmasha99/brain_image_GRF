"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.488534927368164, "training_acc": 52.5, "val_loss": 13.932300806045532, "val_acc": 50.0, "val_auroc": 0.26, "time": 20.44}
{"epoch": 1, "training_loss": 55.30272960662842, "training_acc": 52.5, "val_loss": 13.897663354873657, "val_acc": 50.0, "val_auroc": 0.42, "time": 38.17}
{"epoch": 2, "training_loss": 55.10959529876709, "training_acc": 52.5, "val_loss": 13.89747142791748, "val_acc": 50.0, "val_auroc": 0.49, "time": 55.82}
{"epoch": 3, "training_loss": 55.00307655334473, "training_acc": 52.5, "val_loss": 13.94202470779419, "val_acc": 50.0, "val_auroc": 0.34, "time": 73.61}
{"epoch": 4, "training_loss": 54.85061073303223, "training_acc": 52.5, "val_loss": 13.93020749092102, "val_acc": 50.0, "val_auroc": 0.33, "time": 90.66}
{"epoch": 5, "training_loss": 54.78530502319336, "training_acc": 52.5, "val_loss": 13.919932842254639, "val_acc": 50.0, "val_auroc": 0.36, "time": 108.03}
{"epoch": 6, "training_loss": 54.8442964553833, "training_acc": 52.5, "val_loss": 13.906718492507935, "val_acc": 50.0, "val_auroc": 0.43, "time": 127.93}
{"epoch": 7, "training_loss": 54.60941791534424, "training_acc": 53.75, "val_loss": 13.873165845870972, "val_acc": 50.0, "val_auroc": 0.55, "time": 145.87}
{"epoch": 8, "training_loss": 54.59578323364258, "training_acc": 52.5, "val_loss": 13.87821912765503, "val_acc": 50.0, "val_auroc": 0.53, "time": 164.29}
{"epoch": 9, "training_loss": 54.52058410644531, "training_acc": 58.75, "val_loss": 13.886185884475708, "val_acc": 50.0, "val_auroc": 0.48, "time": 183.3}
{"epoch": 10, "training_loss": 54.13996505737305, "training_acc": 65.0, "val_loss": 13.874810934066772, "val_acc": 50.0, "val_auroc": 0.48, "time": 201.24}
{"epoch": 11, "training_loss": 53.940402030944824, "training_acc": 66.25, "val_loss": 13.911222219467163, "val_acc": 50.0, "val_auroc": 0.43, "time": 218.71}
{"epoch": 12, "training_loss": 53.849260330200195, "training_acc": 58.75, "val_loss": 13.872179985046387, "val_acc": 50.0, "val_auroc": 0.53, "time": 236.71}
{"epoch": 13, "training_loss": 53.58663082122803, "training_acc": 63.75, "val_loss": 13.879870176315308, "val_acc": 50.0, "val_auroc": 0.51, "time": 253.22}
{"epoch": 14, "training_loss": 53.28656768798828, "training_acc": 56.25, "val_loss": 14.02011752128601, "val_acc": 50.0, "val_auroc": 0.46, "time": 272.96}
{"epoch": 15, "training_loss": 53.44720458984375, "training_acc": 52.5, "val_loss": 13.95281195640564, "val_acc": 50.0, "val_auroc": 0.54, "time": 290.44}
{"epoch": 16, "training_loss": 53.265390396118164, "training_acc": 55.0, "val_loss": 13.94729495048523, "val_acc": 50.0, "val_auroc": 0.53, "time": 307.06}
{"epoch": 17, "training_loss": 52.57286548614502, "training_acc": 53.75, "val_loss": 13.986629247665405, "val_acc": 50.0, "val_auroc": 0.51, "time": 325.2}
{"epoch": 18, "training_loss": 52.52736854553223, "training_acc": 56.25, "val_loss": 13.846787214279175, "val_acc": 50.0, "val_auroc": 0.59, "time": 346.79}
{"epoch": 19, "training_loss": 52.48218250274658, "training_acc": 65.0, "val_loss": 13.905558586120605, "val_acc": 50.0, "val_auroc": 0.57, "time": 367.14}
{"epoch": 20, "training_loss": 51.59434509277344, "training_acc": 63.75, "val_loss": 13.828305006027222, "val_acc": 50.0, "val_auroc": 0.58, "time": 385.86}
{"epoch": 21, "training_loss": 52.49039173126221, "training_acc": 87.5, "val_loss": 14.078606367111206, "val_acc": 50.0, "val_auroc": 0.48, "time": 403.19}
{"epoch": 22, "training_loss": 51.70273494720459, "training_acc": 58.75, "val_loss": 13.93125057220459, "val_acc": 50.0, "val_auroc": 0.58, "time": 419.94}
{"epoch": 23, "training_loss": 50.18688774108887, "training_acc": 78.75, "val_loss": 13.766714334487915, "val_acc": 50.0, "val_auroc": 0.59, "time": 437.35}
{"epoch": 24, "training_loss": 50.56803512573242, "training_acc": 85.0, "val_loss": 13.819770812988281, "val_acc": 50.0, "val_auroc": 0.53, "time": 454.44}
{"epoch": 25, "training_loss": 49.344329833984375, "training_acc": 83.75, "val_loss": 13.744229078292847, "val_acc": 50.0, "val_auroc": 0.6, "time": 471.7}
{"epoch": 26, "training_loss": 50.635751724243164, "training_acc": 83.75, "val_loss": 14.035636186599731, "val_acc": 50.0, "val_auroc": 0.57, "time": 488.56}
{"epoch": 27, "training_loss": 49.477420806884766, "training_acc": 71.25, "val_loss": 13.678886890411377, "val_acc": 50.0, "val_auroc": 0.63, "time": 506.91}
{"epoch": 28, "training_loss": 49.198946952819824, "training_acc": 88.75, "val_loss": 13.733688592910767, "val_acc": 50.0, "val_auroc": 0.58, "time": 524.44}
{"epoch": 29, "training_loss": 47.071166038513184, "training_acc": 92.5, "val_loss": 13.846441507339478, "val_acc": 50.0, "val_auroc": 0.54, "time": 541.12}
{"epoch": 30, "training_loss": 46.92255401611328, "training_acc": 83.75, "val_loss": 13.699558973312378, "val_acc": 50.0, "val_auroc": 0.53, "time": 557.44}
{"epoch": 31, "training_loss": 45.15974998474121, "training_acc": 92.5, "val_loss": 13.719547986984253, "val_acc": 50.0, "val_auroc": 0.59, "time": 576.9}
{"epoch": 32, "training_loss": 48.49349308013916, "training_acc": 82.5, "val_loss": 13.66520881652832, "val_acc": 50.0, "val_auroc": 0.58, "time": 593.93}
{"epoch": 33, "training_loss": 45.80958080291748, "training_acc": 90.0, "val_loss": 13.744157552719116, "val_acc": 50.0, "val_auroc": 0.57, "time": 610.77}
{"epoch": 34, "training_loss": 44.09963417053223, "training_acc": 90.0, "val_loss": 13.887338638305664, "val_acc": 50.0, "val_auroc": 0.56, "time": 627.6}
{"epoch": 35, "training_loss": 43.04537010192871, "training_acc": 92.5, "val_loss": 13.794548511505127, "val_acc": 50.0, "val_auroc": 0.6, "time": 646.93}
{"epoch": 36, "training_loss": 46.26638603210449, "training_acc": 85.0, "val_loss": 14.158251285552979, "val_acc": 50.0, "val_auroc": 0.53, "time": 664.34}
{"epoch": 37, "training_loss": 43.23029708862305, "training_acc": 86.25, "val_loss": 13.806650638580322, "val_acc": 50.0, "val_auroc": 0.57, "time": 681.27}
{"epoch": 38, "training_loss": 42.591837882995605, "training_acc": 93.75, "val_loss": 14.471102952957153, "val_acc": 50.0, "val_auroc": 0.49, "time": 699.45}
{"epoch": 39, "training_loss": 44.22468185424805, "training_acc": 81.25, "val_loss": 13.909082412719727, "val_acc": 50.0, "val_auroc": 0.57, "time": 717.08}
{"epoch": 40, "training_loss": 43.786338806152344, "training_acc": 90.0, "val_loss": 14.030636548995972, "val_acc": 50.0, "val_auroc": 0.55, "time": 734.84}
{"epoch": 41, "training_loss": 39.574222564697266, "training_acc": 93.75, "val_loss": 13.816742897033691, "val_acc": 50.0, "val_auroc": 0.57, "time": 753.88}
{"epoch": 42, "training_loss": 38.94321250915527, "training_acc": 93.75, "val_loss": 13.675079345703125, "val_acc": 55.0, "val_auroc": 0.59, "time": 770.98}
{"epoch": 43, "training_loss": 38.75164842605591, "training_acc": 95.0, "val_loss": 14.432004690170288, "val_acc": 50.0, "val_auroc": 0.54, "time": 791.19}
{"epoch": 44, "training_loss": 39.30507755279541, "training_acc": 86.25, "val_loss": 14.0024733543396, "val_acc": 50.0, "val_auroc": 0.58, "time": 808.88}
{"epoch": 45, "training_loss": 40.97097396850586, "training_acc": 91.25, "val_loss": 14.344135522842407, "val_acc": 50.0, "val_auroc": 0.57, "time": 826.02}
{"epoch": 46, "training_loss": 39.29992341995239, "training_acc": 88.75, "val_loss": 13.850792646408081, "val_acc": 45.0, "val_auroc": 0.56, "time": 844.05}
{"epoch": 47, "training_loss": 36.1708927154541, "training_acc": 98.75, "val_loss": 13.740061521530151, "val_acc": 60.0, "val_auroc": 0.57, "time": 860.49}
{"epoch": 48, "training_loss": 34.6244330406189, "training_acc": 100.0, "val_loss": 14.674100875854492, "val_acc": 50.0, "val_auroc": 0.51, "time": 880.46}
{"epoch": 49, "training_loss": 37.57276678085327, "training_acc": 93.75, "val_loss": 13.677065372467041, "val_acc": 60.0, "val_auroc": 0.58, "time": 898.59}
{"epoch": 50, "training_loss": 35.724955558776855, "training_acc": 97.5, "val_loss": 14.40914511680603, "val_acc": 50.0, "val_auroc": 0.55, "time": 916.09}
{"epoch": 51, "training_loss": 35.100401878356934, "training_acc": 95.0, "val_loss": 13.953964710235596, "val_acc": 45.0, "val_auroc": 0.54, "time": 932.91}
