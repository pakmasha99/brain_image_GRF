"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.45914173126221, "training_acc": 52.5, "val_loss": 13.892868757247925, "val_acc": 50.0, "val_auroc": 0.53, "time": 16.77}
{"epoch": 1, "training_loss": 55.4621467590332, "training_acc": 52.5, "val_loss": 13.95706057548523, "val_acc": 50.0, "val_auroc": 0.43, "time": 31.28}
{"epoch": 2, "training_loss": 55.506561279296875, "training_acc": 52.5, "val_loss": 13.90170931816101, "val_acc": 50.0, "val_auroc": 0.59, "time": 47.88}
{"epoch": 3, "training_loss": 55.27407932281494, "training_acc": 52.5, "val_loss": 13.856348991394043, "val_acc": 50.0, "val_auroc": 0.68, "time": 62.41}
{"epoch": 4, "training_loss": 55.30881118774414, "training_acc": 52.5, "val_loss": 13.85228157043457, "val_acc": 50.0, "val_auroc": 0.62, "time": 76.93}
{"epoch": 5, "training_loss": 55.397093772888184, "training_acc": 52.5, "val_loss": 13.897942304611206, "val_acc": 50.0, "val_auroc": 0.64, "time": 91.69}
{"epoch": 6, "training_loss": 55.336798667907715, "training_acc": 52.5, "val_loss": 13.908332586288452, "val_acc": 50.0, "val_auroc": 0.65, "time": 106.06}
{"epoch": 7, "training_loss": 55.356515884399414, "training_acc": 52.5, "val_loss": 13.875054121017456, "val_acc": 50.0, "val_auroc": 0.65, "time": 120.21}
{"epoch": 8, "training_loss": 55.31031799316406, "training_acc": 52.5, "val_loss": 13.8674795627594, "val_acc": 50.0, "val_auroc": 0.65, "time": 134.88}
{"epoch": 9, "training_loss": 55.29351997375488, "training_acc": 52.5, "val_loss": 13.843903541564941, "val_acc": 50.0, "val_auroc": 0.65, "time": 149.91}
{"epoch": 10, "training_loss": 55.461341857910156, "training_acc": 50.0, "val_loss": 13.844636678695679, "val_acc": 50.0, "val_auroc": 0.68, "time": 165.87}
{"epoch": 11, "training_loss": 55.27775573730469, "training_acc": 65.0, "val_loss": 13.916969299316406, "val_acc": 50.0, "val_auroc": 0.71, "time": 181.08}
{"epoch": 12, "training_loss": 55.32772731781006, "training_acc": 52.5, "val_loss": 13.991845846176147, "val_acc": 50.0, "val_auroc": 0.7, "time": 195.43}
{"epoch": 13, "training_loss": 55.5345401763916, "training_acc": 52.5, "val_loss": 14.0054452419281, "val_acc": 50.0, "val_auroc": 0.78, "time": 209.94}
{"epoch": 14, "training_loss": 55.60118865966797, "training_acc": 52.5, "val_loss": 14.06360387802124, "val_acc": 50.0, "val_auroc": 0.72, "time": 224.31}
{"epoch": 15, "training_loss": 55.66814994812012, "training_acc": 52.5, "val_loss": 14.129528999328613, "val_acc": 50.0, "val_auroc": 0.78, "time": 238.67}
{"epoch": 16, "training_loss": 55.88023376464844, "training_acc": 52.5, "val_loss": 14.08349871635437, "val_acc": 50.0, "val_auroc": 0.82, "time": 253.03}
{"epoch": 17, "training_loss": 55.6682243347168, "training_acc": 52.5, "val_loss": 13.926539421081543, "val_acc": 50.0, "val_auroc": 0.76, "time": 267.34}
{"epoch": 18, "training_loss": 55.27479076385498, "training_acc": 52.5, "val_loss": 13.856977224349976, "val_acc": 50.0, "val_auroc": 0.7, "time": 282.08}
{"epoch": 19, "training_loss": 55.33260917663574, "training_acc": 57.5, "val_loss": 13.878493309020996, "val_acc": 50.0, "val_auroc": 0.67, "time": 296.67}
{"epoch": 20, "training_loss": 55.71237564086914, "training_acc": 47.5, "val_loss": 13.887442350387573, "val_acc": 50.0, "val_auroc": 0.62, "time": 310.89}
{"epoch": 21, "training_loss": 55.69893741607666, "training_acc": 47.5, "val_loss": 13.85362982749939, "val_acc": 50.0, "val_auroc": 0.7, "time": 325.41}
{"epoch": 22, "training_loss": 55.29917907714844, "training_acc": 52.5, "val_loss": 13.949421644210815, "val_acc": 50.0, "val_auroc": 0.5, "time": 341.88}
{"epoch": 23, "training_loss": 55.37413692474365, "training_acc": 52.5, "val_loss": 14.053252935409546, "val_acc": 50.0, "val_auroc": 0.43, "time": 357.24}
{"epoch": 24, "training_loss": 55.66493606567383, "training_acc": 52.5, "val_loss": 14.080016613006592, "val_acc": 50.0, "val_auroc": 0.48, "time": 371.58}
{"epoch": 25, "training_loss": 55.72629261016846, "training_acc": 52.5, "val_loss": 13.99488091468811, "val_acc": 50.0, "val_auroc": 0.52, "time": 386.15}
{"epoch": 26, "training_loss": 55.53009033203125, "training_acc": 52.5, "val_loss": 13.919018507003784, "val_acc": 50.0, "val_auroc": 0.51, "time": 401.06}
{"epoch": 27, "training_loss": 55.3920841217041, "training_acc": 52.5, "val_loss": 13.888006210327148, "val_acc": 50.0, "val_auroc": 0.73, "time": 415.86}
{"epoch": 28, "training_loss": 55.41410446166992, "training_acc": 52.5, "val_loss": 13.862260580062866, "val_acc": 50.0, "val_auroc": 0.73, "time": 430.28}
