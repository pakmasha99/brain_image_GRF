"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.69993305206299, "training_acc": 51.25, "val_loss": 13.835686445236206, "val_acc": 55.0, "val_auroc": 0.253, "time": 17.46}
{"epoch": 1, "training_loss": 55.56275463104248, "training_acc": 51.25, "val_loss": 13.779501914978027, "val_acc": 55.0, "val_auroc": 0.525, "time": 32.9}
{"epoch": 2, "training_loss": 55.46431922912598, "training_acc": 51.25, "val_loss": 13.786109685897827, "val_acc": 55.0, "val_auroc": 0.636, "time": 47.53}
{"epoch": 3, "training_loss": 55.43465328216553, "training_acc": 51.25, "val_loss": 13.813488483428955, "val_acc": 55.0, "val_auroc": 0.626, "time": 62.33}
{"epoch": 4, "training_loss": 55.54788398742676, "training_acc": 46.25, "val_loss": 13.785277605056763, "val_acc": 55.0, "val_auroc": 0.374, "time": 77.34}
{"epoch": 5, "training_loss": 55.425161361694336, "training_acc": 51.25, "val_loss": 13.767690658569336, "val_acc": 55.0, "val_auroc": 0.333, "time": 92.36}
{"epoch": 6, "training_loss": 55.60512447357178, "training_acc": 51.25, "val_loss": 13.78646731376648, "val_acc": 55.0, "val_auroc": 0.333, "time": 107.52}
{"epoch": 7, "training_loss": 55.42010307312012, "training_acc": 51.25, "val_loss": 13.854073286056519, "val_acc": 55.0, "val_auroc": 0.444, "time": 122.11}
{"epoch": 8, "training_loss": 55.47564125061035, "training_acc": 51.25, "val_loss": 13.951092958450317, "val_acc": 55.0, "val_auroc": 0.444, "time": 136.53}
{"epoch": 9, "training_loss": 55.55269145965576, "training_acc": 48.75, "val_loss": 13.999866247177124, "val_acc": 55.0, "val_auroc": 0.465, "time": 151.04}
{"epoch": 10, "training_loss": 55.59639549255371, "training_acc": 48.75, "val_loss": 13.820512294769287, "val_acc": 55.0, "val_auroc": 0.465, "time": 166.42}
{"epoch": 11, "training_loss": 55.27128791809082, "training_acc": 51.25, "val_loss": 13.768095970153809, "val_acc": 55.0, "val_auroc": 0.444, "time": 184.3}
{"epoch": 12, "training_loss": 55.85129928588867, "training_acc": 51.25, "val_loss": 13.763033151626587, "val_acc": 55.0, "val_auroc": 0.455, "time": 199.51}
{"epoch": 13, "training_loss": 55.64324951171875, "training_acc": 51.25, "val_loss": 13.802986145019531, "val_acc": 55.0, "val_auroc": 0.384, "time": 215.07}
{"epoch": 14, "training_loss": 55.38027381896973, "training_acc": 51.25, "val_loss": 13.898452520370483, "val_acc": 55.0, "val_auroc": 0.424, "time": 229.9}
{"epoch": 15, "training_loss": 55.7270622253418, "training_acc": 48.75, "val_loss": 13.877865076065063, "val_acc": 55.0, "val_auroc": 0.434, "time": 245.16}
{"epoch": 16, "training_loss": 55.32685947418213, "training_acc": 56.25, "val_loss": 13.769210577011108, "val_acc": 55.0, "val_auroc": 0.374, "time": 259.66}
{"epoch": 17, "training_loss": 55.66318988800049, "training_acc": 51.25, "val_loss": 13.765115737915039, "val_acc": 55.0, "val_auroc": 0.404, "time": 274.37}
{"epoch": 18, "training_loss": 55.6026725769043, "training_acc": 51.25, "val_loss": 13.784794807434082, "val_acc": 55.0, "val_auroc": 0.485, "time": 289.32}
{"epoch": 19, "training_loss": 55.373300552368164, "training_acc": 51.25, "val_loss": 13.876460790634155, "val_acc": 55.0, "val_auroc": 0.636, "time": 304.02}
{"epoch": 20, "training_loss": 55.53499794006348, "training_acc": 48.75, "val_loss": 13.928569555282593, "val_acc": 55.0, "val_auroc": 0.586, "time": 318.84}
{"epoch": 21, "training_loss": 55.534128189086914, "training_acc": 48.75, "val_loss": 13.855770826339722, "val_acc": 55.0, "val_auroc": 0.525, "time": 333.49}
{"epoch": 22, "training_loss": 55.45448303222656, "training_acc": 51.25, "val_loss": 13.80098581314087, "val_acc": 55.0, "val_auroc": 0.485, "time": 348.47}
{"epoch": 23, "training_loss": 55.43014717102051, "training_acc": 51.25, "val_loss": 13.783037662506104, "val_acc": 55.0, "val_auroc": 0.424, "time": 362.94}
{"epoch": 24, "training_loss": 55.46259784698486, "training_acc": 51.25, "val_loss": 13.76681923866272, "val_acc": 55.0, "val_auroc": 0.394, "time": 377.16}
{"epoch": 25, "training_loss": 55.556344985961914, "training_acc": 51.25, "val_loss": 13.766051530838013, "val_acc": 55.0, "val_auroc": 0.394, "time": 391.58}
{"epoch": 26, "training_loss": 55.730369567871094, "training_acc": 51.25, "val_loss": 13.785675764083862, "val_acc": 55.0, "val_auroc": 0.444, "time": 406.23}
{"epoch": 27, "training_loss": 56.02121639251709, "training_acc": 51.25, "val_loss": 13.782954216003418, "val_acc": 55.0, "val_auroc": 0.475, "time": 421.65}
{"epoch": 28, "training_loss": 55.95634174346924, "training_acc": 51.25, "val_loss": 13.76460313796997, "val_acc": 55.0, "val_auroc": 0.414, "time": 436.76}
{"epoch": 29, "training_loss": 55.629746437072754, "training_acc": 51.25, "val_loss": 13.842613697052002, "val_acc": 55.0, "val_auroc": 0.525, "time": 451.54}
{"epoch": 30, "training_loss": 55.43274116516113, "training_acc": 51.25, "val_loss": 13.921798467636108, "val_acc": 55.0, "val_auroc": 0.333, "time": 466.72}
{"epoch": 31, "training_loss": 55.529537200927734, "training_acc": 48.75, "val_loss": 13.981168270111084, "val_acc": 55.0, "val_auroc": 0.434, "time": 483.64}
