"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.55708122253418, "training_acc": 52.5, "val_loss": 13.88304591178894, "val_acc": 50.0, "val_auroc": 0.55, "time": 16.26}
{"epoch": 1, "training_loss": 55.41302013397217, "training_acc": 52.5, "val_loss": 13.86034369468689, "val_acc": 50.0, "val_auroc": 0.68, "time": 31.17}
{"epoch": 2, "training_loss": 55.37023448944092, "training_acc": 52.5, "val_loss": 13.94351840019226, "val_acc": 50.0, "val_auroc": 0.32, "time": 46.27}
{"epoch": 3, "training_loss": 55.39846611022949, "training_acc": 52.5, "val_loss": 13.964416980743408, "val_acc": 50.0, "val_auroc": 0.5, "time": 61.31}
{"epoch": 4, "training_loss": 55.46995735168457, "training_acc": 52.5, "val_loss": 13.907475471496582, "val_acc": 50.0, "val_auroc": 0.37, "time": 75.94}
{"epoch": 5, "training_loss": 55.36648178100586, "training_acc": 52.5, "val_loss": 13.904705047607422, "val_acc": 50.0, "val_auroc": 0.42, "time": 89.87}
{"epoch": 6, "training_loss": 55.47798538208008, "training_acc": 52.5, "val_loss": 13.987585306167603, "val_acc": 50.0, "val_auroc": 0.54, "time": 104.46}
{"epoch": 7, "training_loss": 55.480427742004395, "training_acc": 52.5, "val_loss": 14.0510094165802, "val_acc": 50.0, "val_auroc": 0.55, "time": 118.79}
{"epoch": 8, "training_loss": 55.64799976348877, "training_acc": 52.5, "val_loss": 13.91795039176941, "val_acc": 50.0, "val_auroc": 0.35, "time": 132.96}
{"epoch": 9, "training_loss": 55.32059288024902, "training_acc": 52.5, "val_loss": 13.875540494918823, "val_acc": 50.0, "val_auroc": 0.16, "time": 148.01}
{"epoch": 10, "training_loss": 55.48623561859131, "training_acc": 47.5, "val_loss": 13.87041687965393, "val_acc": 50.0, "val_auroc": 0.17, "time": 162.88}
{"epoch": 11, "training_loss": 55.35476112365723, "training_acc": 52.5, "val_loss": 13.913723230361938, "val_acc": 50.0, "val_auroc": 0.33, "time": 178.27}
{"epoch": 12, "training_loss": 55.39597225189209, "training_acc": 52.5, "val_loss": 13.96140456199646, "val_acc": 50.0, "val_auroc": 0.38, "time": 193.67}
{"epoch": 13, "training_loss": 55.43033981323242, "training_acc": 52.5, "val_loss": 13.916395902633667, "val_acc": 50.0, "val_auroc": 0.49, "time": 210.6}
{"epoch": 14, "training_loss": 55.34930419921875, "training_acc": 52.5, "val_loss": 13.876844644546509, "val_acc": 50.0, "val_auroc": 0.32, "time": 225.84}
{"epoch": 15, "training_loss": 55.508419036865234, "training_acc": 52.5, "val_loss": 13.88540506362915, "val_acc": 50.0, "val_auroc": 0.43, "time": 240.97}
{"epoch": 16, "training_loss": 55.27021026611328, "training_acc": 52.5, "val_loss": 13.982714414596558, "val_acc": 50.0, "val_auroc": 0.6, "time": 256.62}
{"epoch": 17, "training_loss": 55.550716400146484, "training_acc": 52.5, "val_loss": 14.066447019577026, "val_acc": 50.0, "val_auroc": 0.65, "time": 271.81}
{"epoch": 18, "training_loss": 55.68182373046875, "training_acc": 52.5, "val_loss": 13.984127044677734, "val_acc": 50.0, "val_auroc": 0.57, "time": 287.34}
{"epoch": 19, "training_loss": 55.4034538269043, "training_acc": 52.5, "val_loss": 13.883922100067139, "val_acc": 50.0, "val_auroc": 0.4, "time": 302.53}
{"epoch": 20, "training_loss": 55.39415645599365, "training_acc": 52.5, "val_loss": 13.862115144729614, "val_acc": 50.0, "val_auroc": 0.54, "time": 317.53}
