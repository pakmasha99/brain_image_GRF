"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.113786697387695, "training_acc": 47.5, "val_loss": 13.8625168800354, "val_acc": 50.0, "val_auroc": 0.49, "time": 19.03}
{"epoch": 1, "training_loss": 55.49611568450928, "training_acc": 51.25, "val_loss": 14.437602758407593, "val_acc": 50.0, "val_auroc": 0.64, "time": 34.36}
{"epoch": 2, "training_loss": 56.60532569885254, "training_acc": 52.5, "val_loss": 13.86926531791687, "val_acc": 50.0, "val_auroc": 0.65, "time": 49.25}
{"epoch": 3, "training_loss": 55.066582679748535, "training_acc": 51.25, "val_loss": 13.85465383529663, "val_acc": 50.0, "val_auroc": 0.57, "time": 64.76}
{"epoch": 4, "training_loss": 55.415425300598145, "training_acc": 48.75, "val_loss": 13.824652433395386, "val_acc": 50.0, "val_auroc": 0.61, "time": 79.88}
{"epoch": 5, "training_loss": 55.09161949157715, "training_acc": 57.5, "val_loss": 13.976970911026001, "val_acc": 50.0, "val_auroc": 0.75, "time": 94.63}
{"epoch": 6, "training_loss": 55.23844337463379, "training_acc": 52.5, "val_loss": 13.7407386302948, "val_acc": 50.0, "val_auroc": 0.77, "time": 109.17}
{"epoch": 7, "training_loss": 55.037954330444336, "training_acc": 57.5, "val_loss": 13.767508268356323, "val_acc": 50.0, "val_auroc": 0.7, "time": 123.89}
{"epoch": 8, "training_loss": 54.742098808288574, "training_acc": 55.0, "val_loss": 14.028124809265137, "val_acc": 50.0, "val_auroc": 0.58, "time": 138.63}
{"epoch": 9, "training_loss": 54.724345207214355, "training_acc": 52.5, "val_loss": 13.789640665054321, "val_acc": 50.0, "val_auroc": 0.74, "time": 154.47}
{"epoch": 10, "training_loss": 55.318359375, "training_acc": 47.5, "val_loss": 13.730891942977905, "val_acc": 50.0, "val_auroc": 0.8, "time": 169.96}
{"epoch": 11, "training_loss": 54.470054626464844, "training_acc": 67.5, "val_loss": 14.285666942596436, "val_acc": 50.0, "val_auroc": 0.78, "time": 186.07}
{"epoch": 12, "training_loss": 55.92435550689697, "training_acc": 52.5, "val_loss": 13.627742528915405, "val_acc": 50.0, "val_auroc": 0.8, "time": 201.37}
{"epoch": 13, "training_loss": 54.571693420410156, "training_acc": 60.0, "val_loss": 13.836901187896729, "val_acc": 50.0, "val_auroc": 0.8, "time": 216.99}
{"epoch": 14, "training_loss": 54.670724868774414, "training_acc": 52.5, "val_loss": 14.31602954864502, "val_acc": 50.0, "val_auroc": 0.72, "time": 232.81}
{"epoch": 15, "training_loss": 56.13625621795654, "training_acc": 52.5, "val_loss": 14.179033041000366, "val_acc": 50.0, "val_auroc": 0.63, "time": 248.77}
{"epoch": 16, "training_loss": 55.98891067504883, "training_acc": 52.5, "val_loss": 13.831744194030762, "val_acc": 50.0, "val_auroc": 0.69, "time": 264.38}
{"epoch": 17, "training_loss": 54.63294219970703, "training_acc": 52.5, "val_loss": 13.75766634941101, "val_acc": 50.0, "val_auroc": 0.76, "time": 280.22}
{"epoch": 18, "training_loss": 54.78972053527832, "training_acc": 48.75, "val_loss": 13.703478574752808, "val_acc": 50.0, "val_auroc": 0.83, "time": 295.63}
{"epoch": 19, "training_loss": 55.08742141723633, "training_acc": 52.5, "val_loss": 13.639322519302368, "val_acc": 50.0, "val_auroc": 0.84, "time": 311.44}
{"epoch": 20, "training_loss": 54.12513065338135, "training_acc": 65.0, "val_loss": 13.651782274246216, "val_acc": 50.0, "val_auroc": 0.82, "time": 328.59}
{"epoch": 21, "training_loss": 54.02703857421875, "training_acc": 52.5, "val_loss": 13.939558267593384, "val_acc": 50.0, "val_auroc": 0.78, "time": 344.38}
{"epoch": 22, "training_loss": 54.648966789245605, "training_acc": 52.5, "val_loss": 14.181653261184692, "val_acc": 50.0, "val_auroc": 0.79, "time": 360.64}
{"epoch": 23, "training_loss": 55.22415351867676, "training_acc": 52.5, "val_loss": 13.530495166778564, "val_acc": 50.0, "val_auroc": 0.85, "time": 376.77}
{"epoch": 24, "training_loss": 52.981685638427734, "training_acc": 70.0, "val_loss": 13.354395627975464, "val_acc": 50.0, "val_auroc": 0.81, "time": 392.18}
{"epoch": 25, "training_loss": 52.711798667907715, "training_acc": 70.0, "val_loss": 13.37781310081482, "val_acc": 50.0, "val_auroc": 0.82, "time": 406.71}
{"epoch": 26, "training_loss": 52.41856575012207, "training_acc": 62.5, "val_loss": 13.071898221969604, "val_acc": 50.0, "val_auroc": 0.82, "time": 422.73}
{"epoch": 27, "training_loss": 48.53186321258545, "training_acc": 72.5, "val_loss": 17.569035291671753, "val_acc": 50.0, "val_auroc": 0.82, "time": 438.96}
{"epoch": 28, "training_loss": 61.86872673034668, "training_acc": 52.5, "val_loss": 13.595802783966064, "val_acc": 75.0, "val_auroc": 0.82, "time": 454.17}
{"epoch": 29, "training_loss": 54.32992935180664, "training_acc": 47.5, "val_loss": 13.653898239135742, "val_acc": 50.0, "val_auroc": 0.76, "time": 469.94}
{"epoch": 30, "training_loss": 53.87941074371338, "training_acc": 53.75, "val_loss": 14.2367684841156, "val_acc": 50.0, "val_auroc": 0.75, "time": 485.99}
{"epoch": 31, "training_loss": 56.058115005493164, "training_acc": 52.5, "val_loss": 14.170897006988525, "val_acc": 50.0, "val_auroc": 0.77, "time": 502.23}
{"epoch": 32, "training_loss": 55.33628177642822, "training_acc": 52.5, "val_loss": 13.936176300048828, "val_acc": 50.0, "val_auroc": 0.66, "time": 518.39}
{"epoch": 33, "training_loss": 56.35603618621826, "training_acc": 47.5, "val_loss": 13.956130743026733, "val_acc": 50.0, "val_auroc": 0.64, "time": 534.94}
{"epoch": 34, "training_loss": 55.787912368774414, "training_acc": 50.0, "val_loss": 14.158328771591187, "val_acc": 50.0, "val_auroc": 0.5, "time": 550.6}
{"epoch": 35, "training_loss": 56.960649490356445, "training_acc": 52.5, "val_loss": 13.954483270645142, "val_acc": 50.0, "val_auroc": 0.54, "time": 566.04}
{"epoch": 36, "training_loss": 54.883368492126465, "training_acc": 52.5, "val_loss": 13.86973261833191, "val_acc": 50.0, "val_auroc": 0.7, "time": 580.73}
{"epoch": 37, "training_loss": 55.61393737792969, "training_acc": 47.5, "val_loss": 13.980895280838013, "val_acc": 50.0, "val_auroc": 0.68, "time": 596.26}
{"epoch": 38, "training_loss": 56.34317874908447, "training_acc": 47.5, "val_loss": 13.900959491729736, "val_acc": 50.0, "val_auroc": 0.69, "time": 610.95}
{"epoch": 39, "training_loss": 55.84428024291992, "training_acc": 47.5, "val_loss": 13.802778720855713, "val_acc": 50.0, "val_auroc": 0.75, "time": 629.03}
{"epoch": 40, "training_loss": 55.19265937805176, "training_acc": 55.0, "val_loss": 13.889268636703491, "val_acc": 50.0, "val_auroc": 0.74, "time": 644.51}
{"epoch": 41, "training_loss": 55.334394454956055, "training_acc": 52.5, "val_loss": 13.894094228744507, "val_acc": 50.0, "val_auroc": 0.8, "time": 659.78}
{"epoch": 42, "training_loss": 55.19983673095703, "training_acc": 52.5, "val_loss": 13.812183141708374, "val_acc": 50.0, "val_auroc": 0.78, "time": 675.72}
{"epoch": 43, "training_loss": 55.032968521118164, "training_acc": 52.5, "val_loss": 13.781293630599976, "val_acc": 50.0, "val_auroc": 0.77, "time": 690.92}
{"epoch": 44, "training_loss": 55.0584077835083, "training_acc": 60.0, "val_loss": 13.754609823226929, "val_acc": 50.0, "val_auroc": 0.76, "time": 706.06}
{"epoch": 45, "training_loss": 54.997901916503906, "training_acc": 63.75, "val_loss": 13.712236881256104, "val_acc": 50.0, "val_auroc": 0.75, "time": 720.65}
