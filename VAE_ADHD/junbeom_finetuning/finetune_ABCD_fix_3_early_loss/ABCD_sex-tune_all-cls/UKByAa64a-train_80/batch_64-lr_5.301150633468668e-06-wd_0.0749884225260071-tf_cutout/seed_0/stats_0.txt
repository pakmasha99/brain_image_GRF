"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.43754196166992, "training_acc": 52.5, "val_loss": 13.928531408309937, "val_acc": 50.0, "val_auroc": 0.31, "time": 19.12}
{"epoch": 1, "training_loss": 55.34406852722168, "training_acc": 52.5, "val_loss": 13.923286199569702, "val_acc": 50.0, "val_auroc": 0.37, "time": 36.58}
{"epoch": 2, "training_loss": 55.1829252243042, "training_acc": 52.5, "val_loss": 13.93366813659668, "val_acc": 50.0, "val_auroc": 0.32, "time": 59.7}
{"epoch": 3, "training_loss": 55.10381889343262, "training_acc": 52.5, "val_loss": 13.914673328399658, "val_acc": 50.0, "val_auroc": 0.35, "time": 81.66}
{"epoch": 4, "training_loss": 55.03444194793701, "training_acc": 52.5, "val_loss": 13.928467035293579, "val_acc": 50.0, "val_auroc": 0.34, "time": 99.3}
{"epoch": 5, "training_loss": 54.96109390258789, "training_acc": 52.5, "val_loss": 13.921654224395752, "val_acc": 50.0, "val_auroc": 0.4, "time": 119.46}
{"epoch": 6, "training_loss": 54.95369911193848, "training_acc": 52.5, "val_loss": 13.951339721679688, "val_acc": 50.0, "val_auroc": 0.3, "time": 139.48}
{"epoch": 7, "training_loss": 54.81719398498535, "training_acc": 52.5, "val_loss": 13.959617614746094, "val_acc": 50.0, "val_auroc": 0.27, "time": 160.37}
{"epoch": 8, "training_loss": 54.8736515045166, "training_acc": 52.5, "val_loss": 13.964606523513794, "val_acc": 50.0, "val_auroc": 0.3, "time": 177.23}
{"epoch": 9, "training_loss": 54.728394508361816, "training_acc": 52.5, "val_loss": 13.960915803909302, "val_acc": 50.0, "val_auroc": 0.32, "time": 194.61}
{"epoch": 10, "training_loss": 54.53152656555176, "training_acc": 53.75, "val_loss": 13.934375047683716, "val_acc": 50.0, "val_auroc": 0.36, "time": 214.24}
{"epoch": 11, "training_loss": 54.41422939300537, "training_acc": 56.25, "val_loss": 13.923895359039307, "val_acc": 50.0, "val_auroc": 0.44, "time": 234.21}
{"epoch": 12, "training_loss": 54.5575065612793, "training_acc": 53.75, "val_loss": 13.925739526748657, "val_acc": 50.0, "val_auroc": 0.4, "time": 251.62}
{"epoch": 13, "training_loss": 54.298709869384766, "training_acc": 53.75, "val_loss": 13.937386274337769, "val_acc": 50.0, "val_auroc": 0.42, "time": 270.61}
{"epoch": 14, "training_loss": 54.317901611328125, "training_acc": 52.5, "val_loss": 13.96090030670166, "val_acc": 50.0, "val_auroc": 0.41, "time": 290.54}
{"epoch": 15, "training_loss": 54.27646446228027, "training_acc": 53.75, "val_loss": 13.989886045455933, "val_acc": 50.0, "val_auroc": 0.39, "time": 312.37}
{"epoch": 16, "training_loss": 54.0551815032959, "training_acc": 53.75, "val_loss": 13.998932838439941, "val_acc": 50.0, "val_auroc": 0.39, "time": 331.39}
{"epoch": 17, "training_loss": 53.91341495513916, "training_acc": 52.5, "val_loss": 13.994191884994507, "val_acc": 50.0, "val_auroc": 0.38, "time": 349.63}
{"epoch": 18, "training_loss": 53.94463539123535, "training_acc": 53.75, "val_loss": 14.026817083358765, "val_acc": 50.0, "val_auroc": 0.38, "time": 368.42}
{"epoch": 19, "training_loss": 53.8549747467041, "training_acc": 53.75, "val_loss": 13.937371969223022, "val_acc": 50.0, "val_auroc": 0.48, "time": 388.24}
{"epoch": 20, "training_loss": 53.91171646118164, "training_acc": 53.75, "val_loss": 13.922419548034668, "val_acc": 50.0, "val_auroc": 0.49, "time": 405.62}
{"epoch": 21, "training_loss": 53.741153717041016, "training_acc": 56.25, "val_loss": 13.956794738769531, "val_acc": 50.0, "val_auroc": 0.45, "time": 424.67}
{"epoch": 22, "training_loss": 53.81255912780762, "training_acc": 55.0, "val_loss": 13.958796262741089, "val_acc": 50.0, "val_auroc": 0.45, "time": 444.54}
