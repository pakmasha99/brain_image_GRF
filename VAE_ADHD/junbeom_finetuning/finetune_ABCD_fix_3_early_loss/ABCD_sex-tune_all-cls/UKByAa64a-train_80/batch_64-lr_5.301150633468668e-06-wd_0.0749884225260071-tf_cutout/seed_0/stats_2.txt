"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.03507137298584, "training_acc": 52.5, "val_loss": 14.187978506088257, "val_acc": 50.0, "val_auroc": 0.62, "time": 19.63}
{"epoch": 1, "training_loss": 56.25173282623291, "training_acc": 52.5, "val_loss": 14.207273721694946, "val_acc": 50.0, "val_auroc": 0.41, "time": 37.49}
{"epoch": 2, "training_loss": 56.002235412597656, "training_acc": 52.5, "val_loss": 14.218965768814087, "val_acc": 50.0, "val_auroc": 0.36, "time": 59.26}
{"epoch": 3, "training_loss": 55.99386215209961, "training_acc": 52.5, "val_loss": 14.217417240142822, "val_acc": 50.0, "val_auroc": 0.31, "time": 82.0}
{"epoch": 4, "training_loss": 55.809502601623535, "training_acc": 52.5, "val_loss": 14.200994968414307, "val_acc": 50.0, "val_auroc": 0.34, "time": 100.99}
{"epoch": 5, "training_loss": 55.71995735168457, "training_acc": 52.5, "val_loss": 14.18361783027649, "val_acc": 50.0, "val_auroc": 0.25, "time": 118.96}
{"epoch": 6, "training_loss": 55.556467056274414, "training_acc": 52.5, "val_loss": 14.157370328903198, "val_acc": 50.0, "val_auroc": 0.33, "time": 137.95}
{"epoch": 7, "training_loss": 55.463584899902344, "training_acc": 52.5, "val_loss": 14.147108793258667, "val_acc": 50.0, "val_auroc": 0.34, "time": 159.46}
{"epoch": 8, "training_loss": 55.44735527038574, "training_acc": 52.5, "val_loss": 14.142495393753052, "val_acc": 50.0, "val_auroc": 0.31, "time": 176.36}
{"epoch": 9, "training_loss": 55.26723670959473, "training_acc": 52.5, "val_loss": 14.121507406234741, "val_acc": 50.0, "val_auroc": 0.33, "time": 194.86}
{"epoch": 10, "training_loss": 55.16782760620117, "training_acc": 52.5, "val_loss": 14.102152585983276, "val_acc": 50.0, "val_auroc": 0.34, "time": 213.13}
{"epoch": 11, "training_loss": 55.11289978027344, "training_acc": 52.5, "val_loss": 14.088314771652222, "val_acc": 50.0, "val_auroc": 0.35, "time": 236.09}
{"epoch": 12, "training_loss": 54.89682865142822, "training_acc": 52.5, "val_loss": 14.077930450439453, "val_acc": 50.0, "val_auroc": 0.35, "time": 255.36}
{"epoch": 13, "training_loss": 54.804704666137695, "training_acc": 52.5, "val_loss": 14.069353342056274, "val_acc": 50.0, "val_auroc": 0.36, "time": 275.25}
{"epoch": 14, "training_loss": 54.76528358459473, "training_acc": 52.5, "val_loss": 14.057258367538452, "val_acc": 50.0, "val_auroc": 0.39, "time": 293.26}
{"epoch": 15, "training_loss": 54.80516719818115, "training_acc": 52.5, "val_loss": 14.053536653518677, "val_acc": 50.0, "val_auroc": 0.37, "time": 315.03}
{"epoch": 16, "training_loss": 54.688148498535156, "training_acc": 52.5, "val_loss": 14.044636487960815, "val_acc": 50.0, "val_auroc": 0.44, "time": 332.18}
{"epoch": 17, "training_loss": 54.534624099731445, "training_acc": 52.5, "val_loss": 14.045243263244629, "val_acc": 50.0, "val_auroc": 0.44, "time": 349.62}
{"epoch": 18, "training_loss": 54.35088539123535, "training_acc": 52.5, "val_loss": 14.060167074203491, "val_acc": 50.0, "val_auroc": 0.36, "time": 367.74}
{"epoch": 19, "training_loss": 54.37453079223633, "training_acc": 52.5, "val_loss": 14.069420099258423, "val_acc": 50.0, "val_auroc": 0.33, "time": 387.87}
{"epoch": 20, "training_loss": 54.345693588256836, "training_acc": 52.5, "val_loss": 14.061390161514282, "val_acc": 50.0, "val_auroc": 0.31, "time": 405.73}
{"epoch": 21, "training_loss": 54.117916107177734, "training_acc": 52.5, "val_loss": 14.055384397506714, "val_acc": 50.0, "val_auroc": 0.37, "time": 423.94}
{"epoch": 22, "training_loss": 54.256784439086914, "training_acc": 52.5, "val_loss": 14.057976007461548, "val_acc": 50.0, "val_auroc": 0.37, "time": 441.88}
{"epoch": 23, "training_loss": 53.93148899078369, "training_acc": 52.5, "val_loss": 14.053516387939453, "val_acc": 50.0, "val_auroc": 0.38, "time": 462.06}
{"epoch": 24, "training_loss": 54.075130462646484, "training_acc": 52.5, "val_loss": 14.022032022476196, "val_acc": 50.0, "val_auroc": 0.52, "time": 481.22}
{"epoch": 25, "training_loss": 53.91926574707031, "training_acc": 52.5, "val_loss": 14.046061038970947, "val_acc": 50.0, "val_auroc": 0.39, "time": 498.72}
{"epoch": 26, "training_loss": 53.985493659973145, "training_acc": 52.5, "val_loss": 14.099539518356323, "val_acc": 50.0, "val_auroc": 0.27, "time": 519.28}
{"epoch": 27, "training_loss": 53.852444648742676, "training_acc": 52.5, "val_loss": 14.09096360206604, "val_acc": 50.0, "val_auroc": 0.31, "time": 541.13}
{"epoch": 28, "training_loss": 53.86639404296875, "training_acc": 52.5, "val_loss": 14.034713506698608, "val_acc": 50.0, "val_auroc": 0.44, "time": 559.96}
{"epoch": 29, "training_loss": 53.603732109069824, "training_acc": 52.5, "val_loss": 14.036394357681274, "val_acc": 50.0, "val_auroc": 0.45, "time": 579.93}
{"epoch": 30, "training_loss": 53.73093795776367, "training_acc": 52.5, "val_loss": 14.102579355239868, "val_acc": 50.0, "val_auroc": 0.24, "time": 597.44}
{"epoch": 31, "training_loss": 53.477067947387695, "training_acc": 52.5, "val_loss": 14.124983549118042, "val_acc": 50.0, "val_auroc": 0.23, "time": 616.03}
{"epoch": 32, "training_loss": 53.36595058441162, "training_acc": 52.5, "val_loss": 14.087857007980347, "val_acc": 50.0, "val_auroc": 0.32, "time": 633.51}
{"epoch": 33, "training_loss": 53.49480628967285, "training_acc": 52.5, "val_loss": 14.027831554412842, "val_acc": 50.0, "val_auroc": 0.51, "time": 651.83}
{"epoch": 34, "training_loss": 53.62501811981201, "training_acc": 52.5, "val_loss": 14.020376205444336, "val_acc": 50.0, "val_auroc": 0.5, "time": 671.09}
{"epoch": 35, "training_loss": 53.52786827087402, "training_acc": 52.5, "val_loss": 14.055969715118408, "val_acc": 50.0, "val_auroc": 0.37, "time": 690.6}
{"epoch": 36, "training_loss": 52.944549560546875, "training_acc": 52.5, "val_loss": 14.095953702926636, "val_acc": 50.0, "val_auroc": 0.27, "time": 709.79}
{"epoch": 37, "training_loss": 53.37754440307617, "training_acc": 55.0, "val_loss": 14.049025774002075, "val_acc": 50.0, "val_auroc": 0.4, "time": 727.92}
{"epoch": 38, "training_loss": 52.81845283508301, "training_acc": 55.0, "val_loss": 13.99411916732788, "val_acc": 50.0, "val_auroc": 0.54, "time": 745.34}
{"epoch": 39, "training_loss": 53.27971076965332, "training_acc": 52.5, "val_loss": 14.044445753097534, "val_acc": 50.0, "val_auroc": 0.4, "time": 765.27}
{"epoch": 40, "training_loss": 53.025254249572754, "training_acc": 60.0, "val_loss": 14.112790822982788, "val_acc": 50.0, "val_auroc": 0.27, "time": 783.9}
{"epoch": 41, "training_loss": 52.56758499145508, "training_acc": 60.0, "val_loss": 14.069139957427979, "val_acc": 50.0, "val_auroc": 0.36, "time": 801.16}
{"epoch": 42, "training_loss": 52.984965324401855, "training_acc": 58.75, "val_loss": 14.028831720352173, "val_acc": 50.0, "val_auroc": 0.42, "time": 818.3}
{"epoch": 43, "training_loss": 52.73715686798096, "training_acc": 60.0, "val_loss": 14.039697647094727, "val_acc": 50.0, "val_auroc": 0.38, "time": 836.47}
{"epoch": 44, "training_loss": 52.46798133850098, "training_acc": 60.0, "val_loss": 14.105194807052612, "val_acc": 50.0, "val_auroc": 0.29, "time": 857.05}
{"epoch": 45, "training_loss": 52.49919319152832, "training_acc": 61.25, "val_loss": 14.08182978630066, "val_acc": 50.0, "val_auroc": 0.32, "time": 874.45}
{"epoch": 46, "training_loss": 52.542131423950195, "training_acc": 58.75, "val_loss": 13.984273672103882, "val_acc": 50.0, "val_auroc": 0.51, "time": 892.45}
{"epoch": 47, "training_loss": 52.318485260009766, "training_acc": 58.75, "val_loss": 14.05591368675232, "val_acc": 50.0, "val_auroc": 0.37, "time": 911.02}
{"epoch": 48, "training_loss": 52.16763877868652, "training_acc": 61.25, "val_loss": 14.110045433044434, "val_acc": 50.0, "val_auroc": 0.32, "time": 930.36}
{"epoch": 49, "training_loss": 51.99158477783203, "training_acc": 62.5, "val_loss": 14.058980941772461, "val_acc": 50.0, "val_auroc": 0.37, "time": 947.58}
{"epoch": 50, "training_loss": 51.83069705963135, "training_acc": 61.25, "val_loss": 14.108068943023682, "val_acc": 50.0, "val_auroc": 0.33, "time": 968.08}
{"epoch": 51, "training_loss": 51.58783721923828, "training_acc": 66.25, "val_loss": 14.145240783691406, "val_acc": 50.0, "val_auroc": 0.29, "time": 986.02}
{"epoch": 52, "training_loss": 51.54819869995117, "training_acc": 68.75, "val_loss": 14.071096181869507, "val_acc": 50.0, "val_auroc": 0.38, "time": 1005.85}
{"epoch": 53, "training_loss": 51.57629871368408, "training_acc": 62.5, "val_loss": 14.102562665939331, "val_acc": 50.0, "val_auroc": 0.36, "time": 1024.1}
{"epoch": 54, "training_loss": 51.505496978759766, "training_acc": 65.0, "val_loss": 14.171351194381714, "val_acc": 50.0, "val_auroc": 0.29, "time": 1043.95}
{"epoch": 55, "training_loss": 51.17591667175293, "training_acc": 65.0, "val_loss": 14.097374677658081, "val_acc": 50.0, "val_auroc": 0.38, "time": 1062.12}
{"epoch": 56, "training_loss": 51.749765396118164, "training_acc": 58.75, "val_loss": 14.147244691848755, "val_acc": 50.0, "val_auroc": 0.33, "time": 1078.9}
{"epoch": 57, "training_loss": 51.23040771484375, "training_acc": 61.25, "val_loss": 14.292919635772705, "val_acc": 50.0, "val_auroc": 0.26, "time": 1096.34}
{"epoch": 58, "training_loss": 51.66122055053711, "training_acc": 71.25, "val_loss": 14.210563898086548, "val_acc": 50.0, "val_auroc": 0.31, "time": 1116.01}
{"epoch": 59, "training_loss": 51.246686935424805, "training_acc": 67.5, "val_loss": 14.062387943267822, "val_acc": 50.0, "val_auroc": 0.44, "time": 1133.86}
{"epoch": 60, "training_loss": 50.35528564453125, "training_acc": 66.25, "val_loss": 14.296435117721558, "val_acc": 50.0, "val_auroc": 0.25, "time": 1151.41}
{"epoch": 61, "training_loss": 50.73962211608887, "training_acc": 72.5, "val_loss": 14.188482761383057, "val_acc": 50.0, "val_auroc": 0.31, "time": 1170.97}
{"epoch": 62, "training_loss": 50.52705383300781, "training_acc": 67.5, "val_loss": 14.07874584197998, "val_acc": 50.0, "val_auroc": 0.38, "time": 1188.95}
{"epoch": 63, "training_loss": 50.4788236618042, "training_acc": 65.0, "val_loss": 14.307060241699219, "val_acc": 50.0, "val_auroc": 0.27, "time": 1206.64}
{"epoch": 64, "training_loss": 50.12103748321533, "training_acc": 77.5, "val_loss": 14.33523178100586, "val_acc": 50.0, "val_auroc": 0.27, "time": 1223.31}
{"epoch": 65, "training_loss": 49.81595230102539, "training_acc": 76.25, "val_loss": 14.15135145187378, "val_acc": 50.0, "val_auroc": 0.34, "time": 1240.9}
