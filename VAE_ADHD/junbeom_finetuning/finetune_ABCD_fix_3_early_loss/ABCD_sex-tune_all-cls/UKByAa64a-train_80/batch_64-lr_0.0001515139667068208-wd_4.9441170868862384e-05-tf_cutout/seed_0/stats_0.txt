"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.6530818939209, "training_acc": 52.5, "val_loss": 13.85332465171814, "val_acc": 50.0, "val_auroc": 0.67, "time": 18.82}
{"epoch": 1, "training_loss": 55.42960739135742, "training_acc": 52.5, "val_loss": 13.90606164932251, "val_acc": 50.0, "val_auroc": 0.49, "time": 36.39}
{"epoch": 2, "training_loss": 55.27327537536621, "training_acc": 52.5, "val_loss": 13.872801065444946, "val_acc": 50.0, "val_auroc": 0.45, "time": 52.88}
{"epoch": 3, "training_loss": 55.30735683441162, "training_acc": 52.5, "val_loss": 13.878902196884155, "val_acc": 50.0, "val_auroc": 0.53, "time": 69.24}
{"epoch": 4, "training_loss": 55.277995109558105, "training_acc": 52.5, "val_loss": 13.897207975387573, "val_acc": 50.0, "val_auroc": 0.29, "time": 84.76}
{"epoch": 5, "training_loss": 55.26281547546387, "training_acc": 52.5, "val_loss": 13.86950135231018, "val_acc": 50.0, "val_auroc": 0.46, "time": 101.29}
{"epoch": 6, "training_loss": 55.419931411743164, "training_acc": 47.5, "val_loss": 13.859341144561768, "val_acc": 50.0, "val_auroc": 0.61, "time": 120.05}
{"epoch": 7, "training_loss": 55.47075653076172, "training_acc": 48.75, "val_loss": 13.875277042388916, "val_acc": 50.0, "val_auroc": 0.42, "time": 136.71}
{"epoch": 8, "training_loss": 55.32449913024902, "training_acc": 53.75, "val_loss": 13.868826627731323, "val_acc": 50.0, "val_auroc": 0.45, "time": 154.04}
{"epoch": 9, "training_loss": 55.34695816040039, "training_acc": 52.5, "val_loss": 13.859285116195679, "val_acc": 50.0, "val_auroc": 0.61, "time": 170.73}
{"epoch": 10, "training_loss": 55.26008605957031, "training_acc": 52.5, "val_loss": 13.894706964492798, "val_acc": 50.0, "val_auroc": 0.65, "time": 186.67}
{"epoch": 11, "training_loss": 55.19407653808594, "training_acc": 52.5, "val_loss": 14.006026983261108, "val_acc": 50.0, "val_auroc": 0.65, "time": 202.48}
{"epoch": 12, "training_loss": 55.4296817779541, "training_acc": 52.5, "val_loss": 14.09949541091919, "val_acc": 50.0, "val_auroc": 0.58, "time": 218.74}
{"epoch": 13, "training_loss": 55.749295234680176, "training_acc": 52.5, "val_loss": 14.121376276016235, "val_acc": 50.0, "val_auroc": 0.62, "time": 235.55}
{"epoch": 14, "training_loss": 55.85761737823486, "training_acc": 52.5, "val_loss": 14.237165451049805, "val_acc": 50.0, "val_auroc": 0.59, "time": 251.52}
{"epoch": 15, "training_loss": 56.03821563720703, "training_acc": 52.5, "val_loss": 14.260183572769165, "val_acc": 50.0, "val_auroc": 0.55, "time": 267.5}
{"epoch": 16, "training_loss": 56.07200241088867, "training_acc": 52.5, "val_loss": 14.091695547103882, "val_acc": 50.0, "val_auroc": 0.6, "time": 282.68}
{"epoch": 17, "training_loss": 55.50758743286133, "training_acc": 52.5, "val_loss": 13.930134773254395, "val_acc": 50.0, "val_auroc": 0.55, "time": 298.79}
{"epoch": 18, "training_loss": 55.268707275390625, "training_acc": 52.5, "val_loss": 13.863385915756226, "val_acc": 50.0, "val_auroc": 0.6, "time": 314.36}
{"epoch": 19, "training_loss": 55.27298069000244, "training_acc": 52.5, "val_loss": 13.849680423736572, "val_acc": 50.0, "val_auroc": 0.6, "time": 330.08}
{"epoch": 20, "training_loss": 55.22761535644531, "training_acc": 56.25, "val_loss": 13.888747692108154, "val_acc": 50.0, "val_auroc": 0.57, "time": 345.73}
{"epoch": 21, "training_loss": 55.650081634521484, "training_acc": 47.5, "val_loss": 13.865755796432495, "val_acc": 50.0, "val_auroc": 0.53, "time": 361.53}
{"epoch": 22, "training_loss": 55.058433532714844, "training_acc": 57.5, "val_loss": 13.97938847541809, "val_acc": 50.0, "val_auroc": 0.38, "time": 377.74}
{"epoch": 23, "training_loss": 55.355010986328125, "training_acc": 52.5, "val_loss": 14.049186706542969, "val_acc": 50.0, "val_auroc": 0.26, "time": 393.34}
{"epoch": 24, "training_loss": 55.35222816467285, "training_acc": 52.5, "val_loss": 13.918017148971558, "val_acc": 50.0, "val_auroc": 0.36, "time": 409.63}
{"epoch": 25, "training_loss": 55.201364517211914, "training_acc": 52.5, "val_loss": 13.889936208724976, "val_acc": 50.0, "val_auroc": 0.29, "time": 425.69}
{"epoch": 26, "training_loss": 55.27523422241211, "training_acc": 56.25, "val_loss": 13.90363097190857, "val_acc": 50.0, "val_auroc": 0.35, "time": 444.22}
{"epoch": 27, "training_loss": 55.228111267089844, "training_acc": 52.5, "val_loss": 13.951430320739746, "val_acc": 50.0, "val_auroc": 0.38, "time": 460.93}
{"epoch": 28, "training_loss": 55.4815559387207, "training_acc": 52.5, "val_loss": 13.92886757850647, "val_acc": 50.0, "val_auroc": 0.5, "time": 477.89}
{"epoch": 29, "training_loss": 55.24557971954346, "training_acc": 52.5, "val_loss": 13.864506483078003, "val_acc": 50.0, "val_auroc": 0.58, "time": 494.13}
{"epoch": 30, "training_loss": 55.17771911621094, "training_acc": 52.5, "val_loss": 13.888663053512573, "val_acc": 50.0, "val_auroc": 0.51, "time": 511.96}
{"epoch": 31, "training_loss": 55.11009407043457, "training_acc": 52.5, "val_loss": 13.925396203994751, "val_acc": 50.0, "val_auroc": 0.39, "time": 527.99}
{"epoch": 32, "training_loss": 55.024718284606934, "training_acc": 52.5, "val_loss": 13.912897109985352, "val_acc": 50.0, "val_auroc": 0.41, "time": 544.12}
{"epoch": 33, "training_loss": 54.9658784866333, "training_acc": 57.5, "val_loss": 13.966912031173706, "val_acc": 50.0, "val_auroc": 0.39, "time": 560.16}
{"epoch": 34, "training_loss": 54.64632701873779, "training_acc": 55.0, "val_loss": 14.076483249664307, "val_acc": 50.0, "val_auroc": 0.5, "time": 576.57}
{"epoch": 35, "training_loss": 55.156494140625, "training_acc": 52.5, "val_loss": 13.952562808990479, "val_acc": 50.0, "val_auroc": 0.4, "time": 593.82}
{"epoch": 36, "training_loss": 54.626930236816406, "training_acc": 58.75, "val_loss": 13.90658974647522, "val_acc": 50.0, "val_auroc": 0.41, "time": 610.61}
{"epoch": 37, "training_loss": 55.44133949279785, "training_acc": 47.5, "val_loss": 13.902167081832886, "val_acc": 50.0, "val_auroc": 0.45, "time": 627.61}
{"epoch": 38, "training_loss": 55.50848579406738, "training_acc": 47.5, "val_loss": 13.882174491882324, "val_acc": 50.0, "val_auroc": 0.44, "time": 645.03}
