"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.53005027770996, "training_acc": 52.5, "val_loss": 13.92907977104187, "val_acc": 50.0, "val_auroc": 0.48, "time": 18.28}
{"epoch": 1, "training_loss": 55.41703796386719, "training_acc": 52.5, "val_loss": 13.896536827087402, "val_acc": 50.0, "val_auroc": 0.47, "time": 34.42}
{"epoch": 2, "training_loss": 55.398258209228516, "training_acc": 52.5, "val_loss": 13.889497518539429, "val_acc": 50.0, "val_auroc": 0.68, "time": 50.45}
{"epoch": 3, "training_loss": 55.34938430786133, "training_acc": 52.5, "val_loss": 13.889576196670532, "val_acc": 50.0, "val_auroc": 0.51, "time": 66.29}
{"epoch": 4, "training_loss": 55.32831382751465, "training_acc": 52.5, "val_loss": 13.86582612991333, "val_acc": 50.0, "val_auroc": 0.46, "time": 83.67}
{"epoch": 5, "training_loss": 55.43077278137207, "training_acc": 55.0, "val_loss": 13.896311521530151, "val_acc": 50.0, "val_auroc": 0.75, "time": 98.84}
{"epoch": 6, "training_loss": 55.40829277038574, "training_acc": 52.5, "val_loss": 13.890254497528076, "val_acc": 50.0, "val_auroc": 0.64, "time": 114.48}
{"epoch": 7, "training_loss": 55.3910026550293, "training_acc": 52.5, "val_loss": 13.88468623161316, "val_acc": 50.0, "val_auroc": 0.79, "time": 129.88}
{"epoch": 8, "training_loss": 55.36800956726074, "training_acc": 52.5, "val_loss": 13.890798091888428, "val_acc": 50.0, "val_auroc": 0.65, "time": 145.22}
{"epoch": 9, "training_loss": 55.364952087402344, "training_acc": 52.5, "val_loss": 13.859895467758179, "val_acc": 50.0, "val_auroc": 0.72, "time": 160.9}
{"epoch": 10, "training_loss": 55.45128059387207, "training_acc": 50.0, "val_loss": 13.860208988189697, "val_acc": 50.0, "val_auroc": 0.61, "time": 176.03}
{"epoch": 11, "training_loss": 55.397095680236816, "training_acc": 55.0, "val_loss": 13.900009393692017, "val_acc": 50.0, "val_auroc": 0.59, "time": 191.94}
{"epoch": 12, "training_loss": 55.33113479614258, "training_acc": 52.5, "val_loss": 13.980773687362671, "val_acc": 50.0, "val_auroc": 0.77, "time": 207.93}
{"epoch": 13, "training_loss": 55.50388526916504, "training_acc": 52.5, "val_loss": 14.022821187973022, "val_acc": 50.0, "val_auroc": 0.67, "time": 223.83}
{"epoch": 14, "training_loss": 55.64659881591797, "training_acc": 52.5, "val_loss": 14.086045026779175, "val_acc": 50.0, "val_auroc": 0.63, "time": 239.35}
{"epoch": 15, "training_loss": 55.738630294799805, "training_acc": 52.5, "val_loss": 14.152722358703613, "val_acc": 50.0, "val_auroc": 0.62, "time": 254.69}
{"epoch": 16, "training_loss": 55.94896125793457, "training_acc": 52.5, "val_loss": 14.12036657333374, "val_acc": 50.0, "val_auroc": 0.57, "time": 270.13}
{"epoch": 17, "training_loss": 55.80102825164795, "training_acc": 52.5, "val_loss": 13.969687223434448, "val_acc": 50.0, "val_auroc": 0.61, "time": 286.15}
{"epoch": 18, "training_loss": 55.39595031738281, "training_acc": 52.5, "val_loss": 13.864375352859497, "val_acc": 50.0, "val_auroc": 0.75, "time": 301.46}
{"epoch": 19, "training_loss": 55.34560203552246, "training_acc": 52.5, "val_loss": 13.881758451461792, "val_acc": 50.0, "val_auroc": 0.85, "time": 317.52}
{"epoch": 20, "training_loss": 55.72893238067627, "training_acc": 47.5, "val_loss": 13.911182880401611, "val_acc": 50.0, "val_auroc": 0.65, "time": 333.55}
{"epoch": 21, "training_loss": 55.889824867248535, "training_acc": 47.5, "val_loss": 13.864561319351196, "val_acc": 50.0, "val_auroc": 0.52, "time": 349.99}
{"epoch": 22, "training_loss": 55.419671058654785, "training_acc": 50.0, "val_loss": 13.916412591934204, "val_acc": 50.0, "val_auroc": 0.51, "time": 365.95}
{"epoch": 23, "training_loss": 55.31820201873779, "training_acc": 52.5, "val_loss": 14.024423360824585, "val_acc": 50.0, "val_auroc": 0.67, "time": 384.63}
{"epoch": 24, "training_loss": 55.59109306335449, "training_acc": 52.5, "val_loss": 14.079874753952026, "val_acc": 50.0, "val_auroc": 0.72, "time": 400.54}
{"epoch": 25, "training_loss": 55.72873401641846, "training_acc": 52.5, "val_loss": 14.016748666763306, "val_acc": 50.0, "val_auroc": 0.72, "time": 416.33}
{"epoch": 26, "training_loss": 55.58240509033203, "training_acc": 52.5, "val_loss": 13.93868088722229, "val_acc": 50.0, "val_auroc": 0.75, "time": 432.58}
{"epoch": 27, "training_loss": 55.41889667510986, "training_acc": 52.5, "val_loss": 13.899987936019897, "val_acc": 50.0, "val_auroc": 0.6, "time": 449.37}
{"epoch": 28, "training_loss": 55.423444747924805, "training_acc": 52.5, "val_loss": 13.86823296546936, "val_acc": 50.0, "val_auroc": 0.53, "time": 465.67}
