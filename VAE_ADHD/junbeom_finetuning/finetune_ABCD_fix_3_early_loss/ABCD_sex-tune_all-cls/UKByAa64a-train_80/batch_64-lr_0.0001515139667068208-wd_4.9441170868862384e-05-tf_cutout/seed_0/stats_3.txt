"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.61427307128906, "training_acc": 51.25, "val_loss": 13.77554178237915, "val_acc": 55.0, "val_auroc": 0.586, "time": 19.64}
{"epoch": 1, "training_loss": 55.51774787902832, "training_acc": 51.25, "val_loss": 13.790394067764282, "val_acc": 55.0, "val_auroc": 0.596, "time": 36.3}
{"epoch": 2, "training_loss": 55.39710807800293, "training_acc": 51.25, "val_loss": 13.822407722473145, "val_acc": 55.0, "val_auroc": 0.323, "time": 54.48}
{"epoch": 3, "training_loss": 55.41312026977539, "training_acc": 51.25, "val_loss": 13.818901777267456, "val_acc": 55.0, "val_auroc": 0.697, "time": 71.83}
{"epoch": 4, "training_loss": 55.46646499633789, "training_acc": 46.25, "val_loss": 13.77619981765747, "val_acc": 55.0, "val_auroc": 0.364, "time": 87.63}
{"epoch": 5, "training_loss": 55.48428916931152, "training_acc": 51.25, "val_loss": 13.78389596939087, "val_acc": 55.0, "val_auroc": 0.263, "time": 104.31}
{"epoch": 6, "training_loss": 55.487502098083496, "training_acc": 51.25, "val_loss": 13.813989162445068, "val_acc": 55.0, "val_auroc": 0.293, "time": 121.09}
{"epoch": 7, "training_loss": 55.39285850524902, "training_acc": 51.25, "val_loss": 13.8592529296875, "val_acc": 55.0, "val_auroc": 0.354, "time": 137.93}
{"epoch": 8, "training_loss": 55.52622127532959, "training_acc": 51.25, "val_loss": 13.934348821640015, "val_acc": 55.0, "val_auroc": 0.354, "time": 157.16}
{"epoch": 9, "training_loss": 55.54100036621094, "training_acc": 48.75, "val_loss": 13.989323377609253, "val_acc": 55.0, "val_auroc": 0.434, "time": 173.44}
{"epoch": 10, "training_loss": 55.59707069396973, "training_acc": 48.75, "val_loss": 13.81945013999939, "val_acc": 55.0, "val_auroc": 0.404, "time": 190.23}
{"epoch": 11, "training_loss": 55.299991607666016, "training_acc": 51.25, "val_loss": 13.769998550415039, "val_acc": 55.0, "val_auroc": 0.444, "time": 207.44}
{"epoch": 12, "training_loss": 55.92616653442383, "training_acc": 51.25, "val_loss": 13.769179582595825, "val_acc": 55.0, "val_auroc": 0.455, "time": 223.87}
{"epoch": 13, "training_loss": 55.7049560546875, "training_acc": 51.25, "val_loss": 13.790082931518555, "val_acc": 55.0, "val_auroc": 0.313, "time": 239.16}
{"epoch": 14, "training_loss": 55.40036964416504, "training_acc": 51.25, "val_loss": 13.869364261627197, "val_acc": 55.0, "val_auroc": 0.374, "time": 254.9}
{"epoch": 15, "training_loss": 55.684247970581055, "training_acc": 48.75, "val_loss": 13.861116170883179, "val_acc": 55.0, "val_auroc": 0.364, "time": 274.11}
{"epoch": 16, "training_loss": 55.33312129974365, "training_acc": 51.25, "val_loss": 13.771895170211792, "val_acc": 55.0, "val_auroc": 0.354, "time": 290.49}
{"epoch": 17, "training_loss": 55.65260696411133, "training_acc": 51.25, "val_loss": 13.766874074935913, "val_acc": 55.0, "val_auroc": 0.444, "time": 306.62}
{"epoch": 18, "training_loss": 55.635643005371094, "training_acc": 51.25, "val_loss": 13.778618574142456, "val_acc": 55.0, "val_auroc": 0.424, "time": 322.82}
{"epoch": 19, "training_loss": 55.394033432006836, "training_acc": 51.25, "val_loss": 13.861080408096313, "val_acc": 55.0, "val_auroc": 0.465, "time": 339.79}
{"epoch": 20, "training_loss": 55.51234436035156, "training_acc": 48.75, "val_loss": 13.932815790176392, "val_acc": 55.0, "val_auroc": 0.354, "time": 356.32}
{"epoch": 21, "training_loss": 55.55013847351074, "training_acc": 48.75, "val_loss": 13.88890266418457, "val_acc": 55.0, "val_auroc": 0.303, "time": 373.08}
{"epoch": 22, "training_loss": 55.47434616088867, "training_acc": 48.75, "val_loss": 13.830972909927368, "val_acc": 55.0, "val_auroc": 0.303, "time": 388.56}
{"epoch": 23, "training_loss": 55.41451549530029, "training_acc": 51.25, "val_loss": 13.796480894088745, "val_acc": 55.0, "val_auroc": 0.323, "time": 403.43}
{"epoch": 24, "training_loss": 55.42468070983887, "training_acc": 51.25, "val_loss": 13.769649267196655, "val_acc": 55.0, "val_auroc": 0.323, "time": 419.83}
{"epoch": 25, "training_loss": 55.519630432128906, "training_acc": 51.25, "val_loss": 13.766340017318726, "val_acc": 55.0, "val_auroc": 0.495, "time": 437.53}
{"epoch": 26, "training_loss": 55.734703063964844, "training_acc": 51.25, "val_loss": 13.785756826400757, "val_acc": 55.0, "val_auroc": 0.596, "time": 453.88}
{"epoch": 27, "training_loss": 56.03292179107666, "training_acc": 51.25, "val_loss": 13.787716627120972, "val_acc": 55.0, "val_auroc": 0.465, "time": 472.77}
{"epoch": 28, "training_loss": 56.01357650756836, "training_acc": 51.25, "val_loss": 13.763666152954102, "val_acc": 55.0, "val_auroc": 0.374, "time": 490.11}
{"epoch": 29, "training_loss": 55.67411994934082, "training_acc": 51.25, "val_loss": 13.817644119262695, "val_acc": 55.0, "val_auroc": 0.606, "time": 507.83}
{"epoch": 30, "training_loss": 55.42561340332031, "training_acc": 51.25, "val_loss": 13.897608518600464, "val_acc": 55.0, "val_auroc": 0.505, "time": 523.77}
{"epoch": 31, "training_loss": 55.47410774230957, "training_acc": 48.75, "val_loss": 13.977127075195312, "val_acc": 55.0, "val_auroc": 0.495, "time": 539.96}
{"epoch": 32, "training_loss": 55.61971855163574, "training_acc": 48.75, "val_loss": 14.056241512298584, "val_acc": 55.0, "val_auroc": 0.545, "time": 556.22}
{"epoch": 33, "training_loss": 55.819013595581055, "training_acc": 48.75, "val_loss": 14.030864238739014, "val_acc": 55.0, "val_auroc": 0.434, "time": 572.62}
{"epoch": 34, "training_loss": 55.694549560546875, "training_acc": 48.75, "val_loss": 13.905410766601562, "val_acc": 55.0, "val_auroc": 0.394, "time": 589.5}
{"epoch": 35, "training_loss": 55.624444007873535, "training_acc": 43.75, "val_loss": 13.835712671279907, "val_acc": 55.0, "val_auroc": 0.303, "time": 605.9}
{"epoch": 36, "training_loss": 55.4224328994751, "training_acc": 51.25, "val_loss": 13.816676139831543, "val_acc": 55.0, "val_auroc": 0.333, "time": 622.11}
{"epoch": 37, "training_loss": 55.41920471191406, "training_acc": 51.25, "val_loss": 13.792378902435303, "val_acc": 55.0, "val_auroc": 0.333, "time": 639.42}
{"epoch": 38, "training_loss": 55.43806838989258, "training_acc": 51.25, "val_loss": 13.775783777236938, "val_acc": 55.0, "val_auroc": 0.323, "time": 655.49}
{"epoch": 39, "training_loss": 55.49237823486328, "training_acc": 51.25, "val_loss": 13.768672943115234, "val_acc": 55.0, "val_auroc": 0.313, "time": 673.36}
{"epoch": 40, "training_loss": 55.56998348236084, "training_acc": 51.25, "val_loss": 13.772640228271484, "val_acc": 55.0, "val_auroc": 0.343, "time": 691.1}
{"epoch": 41, "training_loss": 55.47586917877197, "training_acc": 51.25, "val_loss": 13.809576034545898, "val_acc": 55.0, "val_auroc": 0.374, "time": 707.13}
{"epoch": 42, "training_loss": 55.46562957763672, "training_acc": 51.25, "val_loss": 13.863431215286255, "val_acc": 55.0, "val_auroc": 0.616, "time": 723.22}
{"epoch": 43, "training_loss": 55.450157165527344, "training_acc": 50.0, "val_loss": 13.883193731307983, "val_acc": 55.0, "val_auroc": 0.667, "time": 740.62}
{"epoch": 44, "training_loss": 55.48057746887207, "training_acc": 48.75, "val_loss": 13.896292448043823, "val_acc": 55.0, "val_auroc": 0.616, "time": 761.58}
{"epoch": 45, "training_loss": 55.4927978515625, "training_acc": 48.75, "val_loss": 13.918619155883789, "val_acc": 55.0, "val_auroc": 0.606, "time": 781.37}
{"epoch": 46, "training_loss": 55.529903411865234, "training_acc": 48.75, "val_loss": 13.926407098770142, "val_acc": 55.0, "val_auroc": 0.535, "time": 798.27}
{"epoch": 47, "training_loss": 55.53447437286377, "training_acc": 48.75, "val_loss": 13.900747299194336, "val_acc": 55.0, "val_auroc": 0.273, "time": 814.96}
