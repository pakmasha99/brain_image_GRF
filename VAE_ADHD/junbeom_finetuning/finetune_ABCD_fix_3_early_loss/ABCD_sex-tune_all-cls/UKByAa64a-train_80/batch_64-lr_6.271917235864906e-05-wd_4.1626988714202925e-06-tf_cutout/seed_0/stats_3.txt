"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.291441917419434, "training_acc": 51.25, "val_loss": 13.778320550918579, "val_acc": 55.0, "val_auroc": 0.566, "time": 17.27}
{"epoch": 1, "training_loss": 55.52058410644531, "training_acc": 51.25, "val_loss": 13.899372816085815, "val_acc": 55.0, "val_auroc": 0.232, "time": 32.52}
{"epoch": 2, "training_loss": 55.261573791503906, "training_acc": 51.25, "val_loss": 13.789287805557251, "val_acc": 55.0, "val_auroc": 0.566, "time": 47.68}
{"epoch": 3, "training_loss": 55.377949714660645, "training_acc": 51.25, "val_loss": 13.81168246269226, "val_acc": 55.0, "val_auroc": 0.525, "time": 62.74}
{"epoch": 4, "training_loss": 55.32639217376709, "training_acc": 51.25, "val_loss": 13.795050382614136, "val_acc": 55.0, "val_auroc": 0.404, "time": 77.8}
{"epoch": 5, "training_loss": 55.250450134277344, "training_acc": 51.25, "val_loss": 13.78102421760559, "val_acc": 55.0, "val_auroc": 0.576, "time": 93.01}
{"epoch": 6, "training_loss": 55.25822639465332, "training_acc": 51.25, "val_loss": 13.790420293807983, "val_acc": 55.0, "val_auroc": 0.485, "time": 108.26}
{"epoch": 7, "training_loss": 55.07784557342529, "training_acc": 51.25, "val_loss": 13.770599365234375, "val_acc": 55.0, "val_auroc": 0.657, "time": 123.78}
{"epoch": 8, "training_loss": 55.111549377441406, "training_acc": 52.5, "val_loss": 13.818331956863403, "val_acc": 55.0, "val_auroc": 0.626, "time": 138.96}
{"epoch": 9, "training_loss": 54.938743591308594, "training_acc": 76.25, "val_loss": 13.888787031173706, "val_acc": 55.0, "val_auroc": 0.545, "time": 154.32}
{"epoch": 10, "training_loss": 54.79788780212402, "training_acc": 60.0, "val_loss": 13.774117231369019, "val_acc": 55.0, "val_auroc": 0.576, "time": 169.62}
{"epoch": 11, "training_loss": 54.75805854797363, "training_acc": 52.5, "val_loss": 13.7367844581604, "val_acc": 55.0, "val_auroc": 0.525, "time": 185.27}
{"epoch": 12, "training_loss": 55.16695022583008, "training_acc": 51.25, "val_loss": 13.749788999557495, "val_acc": 55.0, "val_auroc": 0.434, "time": 200.64}
{"epoch": 13, "training_loss": 54.78546905517578, "training_acc": 51.25, "val_loss": 13.856196403503418, "val_acc": 55.0, "val_auroc": 0.434, "time": 215.82}
{"epoch": 14, "training_loss": 54.5742244720459, "training_acc": 72.5, "val_loss": 13.904062509536743, "val_acc": 55.0, "val_auroc": 0.404, "time": 231.4}
{"epoch": 15, "training_loss": 54.38256645202637, "training_acc": 66.25, "val_loss": 13.797688484191895, "val_acc": 55.0, "val_auroc": 0.444, "time": 246.42}
{"epoch": 16, "training_loss": 54.39176082611084, "training_acc": 51.25, "val_loss": 13.78169059753418, "val_acc": 55.0, "val_auroc": 0.566, "time": 261.58}
{"epoch": 17, "training_loss": 55.01129913330078, "training_acc": 51.25, "val_loss": 13.818889856338501, "val_acc": 55.0, "val_auroc": 0.444, "time": 276.85}
{"epoch": 18, "training_loss": 53.78281021118164, "training_acc": 57.5, "val_loss": 13.975279331207275, "val_acc": 55.0, "val_auroc": 0.434, "time": 291.86}
{"epoch": 19, "training_loss": 54.08432197570801, "training_acc": 61.25, "val_loss": 13.91194224357605, "val_acc": 55.0, "val_auroc": 0.444, "time": 309.34}
{"epoch": 20, "training_loss": 53.122982025146484, "training_acc": 71.25, "val_loss": 13.789547681808472, "val_acc": 55.0, "val_auroc": 0.475, "time": 325.39}
{"epoch": 21, "training_loss": 52.227248191833496, "training_acc": 71.25, "val_loss": 13.916631937026978, "val_acc": 55.0, "val_auroc": 0.465, "time": 340.81}
{"epoch": 22, "training_loss": 51.17740440368652, "training_acc": 83.75, "val_loss": 13.916834592819214, "val_acc": 55.0, "val_auroc": 0.485, "time": 356.85}
{"epoch": 23, "training_loss": 49.63796806335449, "training_acc": 80.0, "val_loss": 13.940900564193726, "val_acc": 55.0, "val_auroc": 0.515, "time": 371.83}
{"epoch": 24, "training_loss": 50.459129333496094, "training_acc": 68.75, "val_loss": 14.01160478591919, "val_acc": 55.0, "val_auroc": 0.525, "time": 386.79}
{"epoch": 25, "training_loss": 48.26807403564453, "training_acc": 78.75, "val_loss": 13.997334241867065, "val_acc": 55.0, "val_auroc": 0.626, "time": 401.94}
{"epoch": 26, "training_loss": 51.473989486694336, "training_acc": 56.25, "val_loss": 13.969067335128784, "val_acc": 55.0, "val_auroc": 0.535, "time": 417.03}
{"epoch": 27, "training_loss": 46.08989906311035, "training_acc": 88.75, "val_loss": 13.74574065208435, "val_acc": 55.0, "val_auroc": 0.576, "time": 432.28}
{"epoch": 28, "training_loss": 49.020148277282715, "training_acc": 67.5, "val_loss": 13.771101236343384, "val_acc": 55.0, "val_auroc": 0.566, "time": 447.3}
{"epoch": 29, "training_loss": 45.57841110229492, "training_acc": 91.25, "val_loss": 14.377516508102417, "val_acc": 50.0, "val_auroc": 0.525, "time": 462.4}
{"epoch": 30, "training_loss": 45.658796310424805, "training_acc": 76.25, "val_loss": 14.005106687545776, "val_acc": 55.0, "val_auroc": 0.596, "time": 477.47}
