"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.546560287475586, "training_acc": 48.75, "val_loss": 13.89957308769226, "val_acc": 55.0, "val_auroc": 0.525, "time": 18.98}
{"epoch": 1, "training_loss": 55.540510177612305, "training_acc": 51.25, "val_loss": 13.900734186172485, "val_acc": 55.0, "val_auroc": 0.495, "time": 36.47}
{"epoch": 2, "training_loss": 55.49188232421875, "training_acc": 48.75, "val_loss": 13.902084827423096, "val_acc": 55.0, "val_auroc": 0.424, "time": 53.54}
{"epoch": 3, "training_loss": 55.27390670776367, "training_acc": 52.5, "val_loss": 13.917725086212158, "val_acc": 55.0, "val_auroc": 0.384, "time": 70.6}
{"epoch": 4, "training_loss": 55.137784004211426, "training_acc": 63.75, "val_loss": 13.88255000114441, "val_acc": 55.0, "val_auroc": 0.455, "time": 87.54}
{"epoch": 5, "training_loss": 55.09260654449463, "training_acc": 70.0, "val_loss": 13.841084241867065, "val_acc": 55.0, "val_auroc": 0.525, "time": 104.64}
{"epoch": 6, "training_loss": 55.039374351501465, "training_acc": 71.25, "val_loss": 13.831377029418945, "val_acc": 55.0, "val_auroc": 0.566, "time": 122.95}
{"epoch": 7, "training_loss": 55.067251205444336, "training_acc": 70.0, "val_loss": 13.822983503341675, "val_acc": 55.0, "val_auroc": 0.586, "time": 140.48}
{"epoch": 8, "training_loss": 54.84046459197998, "training_acc": 81.25, "val_loss": 13.885762691497803, "val_acc": 55.0, "val_auroc": 0.414, "time": 157.8}
{"epoch": 9, "training_loss": 54.86483955383301, "training_acc": 83.75, "val_loss": 13.917238712310791, "val_acc": 55.0, "val_auroc": 0.394, "time": 177.88}
{"epoch": 10, "training_loss": 54.84618377685547, "training_acc": 81.25, "val_loss": 13.862227201461792, "val_acc": 55.0, "val_auroc": 0.465, "time": 194.61}
{"epoch": 11, "training_loss": 54.51733875274658, "training_acc": 87.5, "val_loss": 13.822546005249023, "val_acc": 55.0, "val_auroc": 0.515, "time": 211.74}
{"epoch": 12, "training_loss": 54.591026306152344, "training_acc": 78.75, "val_loss": 13.833147287368774, "val_acc": 55.0, "val_auroc": 0.475, "time": 230.01}
{"epoch": 13, "training_loss": 54.64018630981445, "training_acc": 78.75, "val_loss": 13.83574366569519, "val_acc": 55.0, "val_auroc": 0.515, "time": 247.14}
{"epoch": 14, "training_loss": 54.51670455932617, "training_acc": 77.5, "val_loss": 13.851841688156128, "val_acc": 55.0, "val_auroc": 0.485, "time": 264.94}
{"epoch": 15, "training_loss": 54.4014835357666, "training_acc": 72.5, "val_loss": 13.908671140670776, "val_acc": 55.0, "val_auroc": 0.374, "time": 282.84}
{"epoch": 16, "training_loss": 54.26198959350586, "training_acc": 78.75, "val_loss": 13.89218807220459, "val_acc": 55.0, "val_auroc": 0.374, "time": 299.66}
{"epoch": 17, "training_loss": 54.201005935668945, "training_acc": 78.75, "val_loss": 13.842412233352661, "val_acc": 55.0, "val_auroc": 0.465, "time": 317.35}
{"epoch": 18, "training_loss": 53.99487590789795, "training_acc": 75.0, "val_loss": 13.82609248161316, "val_acc": 55.0, "val_auroc": 0.465, "time": 335.24}
{"epoch": 19, "training_loss": 53.951605796813965, "training_acc": 73.75, "val_loss": 13.835853338241577, "val_acc": 55.0, "val_auroc": 0.444, "time": 352.58}
{"epoch": 20, "training_loss": 54.13025665283203, "training_acc": 70.0, "val_loss": 13.877195119857788, "val_acc": 55.0, "val_auroc": 0.434, "time": 369.52}
{"epoch": 21, "training_loss": 53.91702651977539, "training_acc": 75.0, "val_loss": 13.893131017684937, "val_acc": 55.0, "val_auroc": 0.404, "time": 387.72}
{"epoch": 22, "training_loss": 54.04929542541504, "training_acc": 72.5, "val_loss": 13.866910934448242, "val_acc": 55.0, "val_auroc": 0.414, "time": 405.08}
{"epoch": 23, "training_loss": 53.664241790771484, "training_acc": 72.5, "val_loss": 13.863435983657837, "val_acc": 55.0, "val_auroc": 0.394, "time": 423.6}
{"epoch": 24, "training_loss": 53.568885803222656, "training_acc": 77.5, "val_loss": 13.860663175582886, "val_acc": 55.0, "val_auroc": 0.424, "time": 440.77}
{"epoch": 25, "training_loss": 53.37532997131348, "training_acc": 75.0, "val_loss": 13.854366540908813, "val_acc": 55.0, "val_auroc": 0.444, "time": 460.28}
{"epoch": 26, "training_loss": 53.831787109375, "training_acc": 67.5, "val_loss": 13.836890459060669, "val_acc": 55.0, "val_auroc": 0.495, "time": 478.9}
{"epoch": 27, "training_loss": 53.41675567626953, "training_acc": 71.25, "val_loss": 13.834222555160522, "val_acc": 55.0, "val_auroc": 0.444, "time": 496.53}
{"epoch": 28, "training_loss": 53.43305683135986, "training_acc": 68.75, "val_loss": 13.846102952957153, "val_acc": 55.0, "val_auroc": 0.465, "time": 513.14}
{"epoch": 29, "training_loss": 53.11646842956543, "training_acc": 75.0, "val_loss": 13.862934112548828, "val_acc": 55.0, "val_auroc": 0.424, "time": 530.49}
{"epoch": 30, "training_loss": 53.0737886428833, "training_acc": 76.25, "val_loss": 13.86950135231018, "val_acc": 55.0, "val_auroc": 0.465, "time": 547.33}
