"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.29100513458252, "training_acc": 42.5, "val_loss": 13.857535123825073, "val_acc": 50.0, "val_auroc": 0.65, "time": 17.78}
{"epoch": 1, "training_loss": 57.05258560180664, "training_acc": 45.0, "val_loss": 21.6078782081604, "val_acc": 50.0, "val_auroc": 0.28, "time": 33.29}
{"epoch": 2, "training_loss": 74.29441452026367, "training_acc": 52.5, "val_loss": 13.87934684753418, "val_acc": 50.0, "val_auroc": 0.45, "time": 51.4}
{"epoch": 3, "training_loss": 55.493998527526855, "training_acc": 47.5, "val_loss": 13.898963928222656, "val_acc": 50.0, "val_auroc": 0.43, "time": 67.04}
{"epoch": 4, "training_loss": 55.550241470336914, "training_acc": 47.5, "val_loss": 13.887274265289307, "val_acc": 50.0, "val_auroc": 0.46, "time": 83.41}
{"epoch": 5, "training_loss": 55.29798889160156, "training_acc": 52.5, "val_loss": 14.762328863143921, "val_acc": 55.0, "val_auroc": 0.49, "time": 99.87}
{"epoch": 6, "training_loss": 58.884687423706055, "training_acc": 48.75, "val_loss": 14.21926498413086, "val_acc": 50.0, "val_auroc": 0.51, "time": 115.41}
{"epoch": 7, "training_loss": 56.12773323059082, "training_acc": 52.5, "val_loss": 13.9456307888031, "val_acc": 50.0, "val_auroc": 0.49, "time": 132.23}
{"epoch": 8, "training_loss": 55.18692111968994, "training_acc": 52.5, "val_loss": 13.979952335357666, "val_acc": 50.0, "val_auroc": 0.45, "time": 149.78}
{"epoch": 9, "training_loss": 55.974148750305176, "training_acc": 47.5, "val_loss": 13.873920440673828, "val_acc": 50.0, "val_auroc": 0.46, "time": 166.49}
{"epoch": 10, "training_loss": 55.20035362243652, "training_acc": 51.25, "val_loss": 13.999354839324951, "val_acc": 50.0, "val_auroc": 0.47, "time": 182.48}
{"epoch": 11, "training_loss": 55.33290672302246, "training_acc": 52.5, "val_loss": 14.14708137512207, "val_acc": 50.0, "val_auroc": 0.48, "time": 198.33}
{"epoch": 12, "training_loss": 55.71852779388428, "training_acc": 52.5, "val_loss": 14.124321937561035, "val_acc": 50.0, "val_auroc": 0.55, "time": 214.39}
{"epoch": 13, "training_loss": 55.777692794799805, "training_acc": 52.5, "val_loss": 14.065394401550293, "val_acc": 50.0, "val_auroc": 0.54, "time": 230.43}
{"epoch": 14, "training_loss": 55.56716537475586, "training_acc": 52.5, "val_loss": 14.226659536361694, "val_acc": 50.0, "val_auroc": 0.49, "time": 246.63}
{"epoch": 15, "training_loss": 55.72318077087402, "training_acc": 52.5, "val_loss": 14.39933180809021, "val_acc": 50.0, "val_auroc": 0.49, "time": 262.86}
{"epoch": 16, "training_loss": 56.262014389038086, "training_acc": 52.5, "val_loss": 14.130867719650269, "val_acc": 50.0, "val_auroc": 0.48, "time": 279.11}
{"epoch": 17, "training_loss": 55.122528076171875, "training_acc": 52.5, "val_loss": 13.869974613189697, "val_acc": 50.0, "val_auroc": 0.47, "time": 294.97}
{"epoch": 18, "training_loss": 55.17225456237793, "training_acc": 61.25, "val_loss": 13.876529932022095, "val_acc": 50.0, "val_auroc": 0.47, "time": 310.28}
{"epoch": 19, "training_loss": 55.68648624420166, "training_acc": 47.5, "val_loss": 13.873628377914429, "val_acc": 50.0, "val_auroc": 0.48, "time": 325.66}
