"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.02871608734131, "training_acc": 46.25, "val_loss": 13.907715082168579, "val_acc": 55.0, "val_auroc": 0.576, "time": 16.68}
{"epoch": 1, "training_loss": 55.49728965759277, "training_acc": 55.0, "val_loss": 16.847511529922485, "val_acc": 55.0, "val_auroc": 0.293, "time": 32.29}
{"epoch": 2, "training_loss": 68.28374195098877, "training_acc": 51.25, "val_loss": 13.911968469619751, "val_acc": 55.0, "val_auroc": 0.434, "time": 50.51}
{"epoch": 3, "training_loss": 55.389015197753906, "training_acc": 47.5, "val_loss": 14.032992124557495, "val_acc": 55.0, "val_auroc": 0.515, "time": 65.2}
{"epoch": 4, "training_loss": 55.2234525680542, "training_acc": 53.75, "val_loss": 14.026774168014526, "val_acc": 55.0, "val_auroc": 0.303, "time": 79.86}
{"epoch": 5, "training_loss": 57.2845516204834, "training_acc": 51.25, "val_loss": 13.785368204116821, "val_acc": 55.0, "val_auroc": 0.364, "time": 95.92}
{"epoch": 6, "training_loss": 55.48026371002197, "training_acc": 50.0, "val_loss": 14.046000242233276, "val_acc": 55.0, "val_auroc": 0.556, "time": 112.03}
{"epoch": 7, "training_loss": 55.60467338562012, "training_acc": 48.75, "val_loss": 13.939846754074097, "val_acc": 55.0, "val_auroc": 0.495, "time": 126.39}
{"epoch": 8, "training_loss": 55.6910514831543, "training_acc": 43.75, "val_loss": 13.946895599365234, "val_acc": 55.0, "val_auroc": 0.434, "time": 141.79}
{"epoch": 9, "training_loss": 55.32563018798828, "training_acc": 48.75, "val_loss": 14.09464716911316, "val_acc": 55.0, "val_auroc": 0.444, "time": 157.47}
{"epoch": 10, "training_loss": 55.33453178405762, "training_acc": 48.75, "val_loss": 13.786430358886719, "val_acc": 55.0, "val_auroc": 0.444, "time": 173.86}
{"epoch": 11, "training_loss": 55.25979995727539, "training_acc": 51.25, "val_loss": 13.852694034576416, "val_acc": 55.0, "val_auroc": 0.434, "time": 188.84}
{"epoch": 12, "training_loss": 56.55752754211426, "training_acc": 51.25, "val_loss": 13.775910139083862, "val_acc": 55.0, "val_auroc": 0.424, "time": 204.51}
{"epoch": 13, "training_loss": 55.71164321899414, "training_acc": 51.25, "val_loss": 14.02605414390564, "val_acc": 55.0, "val_auroc": 0.515, "time": 219.87}
{"epoch": 14, "training_loss": 55.57095813751221, "training_acc": 48.75, "val_loss": 14.231373071670532, "val_acc": 55.0, "val_auroc": 0.455, "time": 234.62}
{"epoch": 15, "training_loss": 56.096452713012695, "training_acc": 48.75, "val_loss": 13.89116644859314, "val_acc": 55.0, "val_auroc": 0.394, "time": 250.09}
{"epoch": 16, "training_loss": 55.009504318237305, "training_acc": 66.25, "val_loss": 13.80710244178772, "val_acc": 55.0, "val_auroc": 0.384, "time": 264.9}
{"epoch": 17, "training_loss": 56.04675769805908, "training_acc": 51.25, "val_loss": 13.830655813217163, "val_acc": 55.0, "val_auroc": 0.374, "time": 279.91}
{"epoch": 18, "training_loss": 55.98444175720215, "training_acc": 51.25, "val_loss": 13.798391819000244, "val_acc": 55.0, "val_auroc": 0.333, "time": 295.54}
{"epoch": 19, "training_loss": 55.209421157836914, "training_acc": 50.0, "val_loss": 14.092295169830322, "val_acc": 55.0, "val_auroc": 0.394, "time": 311.56}
{"epoch": 20, "training_loss": 56.060163497924805, "training_acc": 48.75, "val_loss": 14.235641956329346, "val_acc": 55.0, "val_auroc": 0.374, "time": 327.61}
{"epoch": 21, "training_loss": 56.10263442993164, "training_acc": 48.75, "val_loss": 13.96354079246521, "val_acc": 55.0, "val_auroc": 0.354, "time": 344.76}
{"epoch": 22, "training_loss": 55.53622817993164, "training_acc": 48.75, "val_loss": 13.805716037750244, "val_acc": 55.0, "val_auroc": 0.394, "time": 360.66}
{"epoch": 23, "training_loss": 55.353126525878906, "training_acc": 51.25, "val_loss": 13.78308653831482, "val_acc": 55.0, "val_auroc": 0.424, "time": 375.74}
{"epoch": 24, "training_loss": 55.51762104034424, "training_acc": 51.25, "val_loss": 13.788728713989258, "val_acc": 55.0, "val_auroc": 0.424, "time": 391.59}
{"epoch": 25, "training_loss": 55.67717456817627, "training_acc": 51.25, "val_loss": 13.814635276794434, "val_acc": 55.0, "val_auroc": 0.434, "time": 407.13}
{"epoch": 26, "training_loss": 55.845359802246094, "training_acc": 51.25, "val_loss": 13.857780694961548, "val_acc": 55.0, "val_auroc": 0.444, "time": 423.35}
{"epoch": 27, "training_loss": 56.12351894378662, "training_acc": 51.25, "val_loss": 13.815714120864868, "val_acc": 55.0, "val_auroc": 0.434, "time": 440.13}
{"epoch": 28, "training_loss": 55.48610973358154, "training_acc": 51.25, "val_loss": 13.909536600112915, "val_acc": 55.0, "val_auroc": 0.404, "time": 455.95}
{"epoch": 29, "training_loss": 55.59724140167236, "training_acc": 52.5, "val_loss": 14.140654802322388, "val_acc": 55.0, "val_auroc": 0.404, "time": 472.6}
{"epoch": 30, "training_loss": 55.77109718322754, "training_acc": 48.75, "val_loss": 13.84764552116394, "val_acc": 55.0, "val_auroc": 0.414, "time": 489.05}
{"epoch": 31, "training_loss": 55.75729465484619, "training_acc": 51.25, "val_loss": 14.143197536468506, "val_acc": 55.0, "val_auroc": 0.434, "time": 505.25}
