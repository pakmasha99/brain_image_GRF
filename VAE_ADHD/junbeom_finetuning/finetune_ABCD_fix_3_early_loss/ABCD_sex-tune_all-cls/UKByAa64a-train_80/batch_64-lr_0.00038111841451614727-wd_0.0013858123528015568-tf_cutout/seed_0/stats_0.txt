"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 60.078864097595215, "training_acc": 42.5, "val_loss": 13.972491025924683, "val_acc": 50.0, "val_auroc": 0.4, "time": 19.52}
{"epoch": 1, "training_loss": 73.55915069580078, "training_acc": 45.0, "val_loss": 13.881105184555054, "val_acc": 50.0, "val_auroc": 0.46, "time": 37.55}
{"epoch": 2, "training_loss": 65.76163101196289, "training_acc": 51.25, "val_loss": 13.975715637207031, "val_acc": 50.0, "val_auroc": 0.46, "time": 55.05}
{"epoch": 3, "training_loss": 56.245384216308594, "training_acc": 47.5, "val_loss": 14.061983823776245, "val_acc": 50.0, "val_auroc": 0.51, "time": 71.54}
{"epoch": 4, "training_loss": 59.36393451690674, "training_acc": 47.5, "val_loss": 14.793641567230225, "val_acc": 50.0, "val_auroc": 0.52, "time": 89.09}
{"epoch": 5, "training_loss": 60.31544876098633, "training_acc": 47.5, "val_loss": 13.89794111251831, "val_acc": 50.0, "val_auroc": 0.54, "time": 106.34}
{"epoch": 6, "training_loss": 55.917449951171875, "training_acc": 48.75, "val_loss": 13.874039649963379, "val_acc": 50.0, "val_auroc": 0.61, "time": 124.34}
{"epoch": 7, "training_loss": 55.50265598297119, "training_acc": 52.5, "val_loss": 13.868821859359741, "val_acc": 50.0, "val_auroc": 0.47, "time": 142.24}
{"epoch": 8, "training_loss": 55.295379638671875, "training_acc": 52.5, "val_loss": 13.896545171737671, "val_acc": 50.0, "val_auroc": 0.51, "time": 159.51}
{"epoch": 9, "training_loss": 55.80503463745117, "training_acc": 47.5, "val_loss": 13.867460489273071, "val_acc": 50.0, "val_auroc": 0.5, "time": 177.13}
{"epoch": 10, "training_loss": 55.262210845947266, "training_acc": 52.5, "val_loss": 14.004234075546265, "val_acc": 50.0, "val_auroc": 0.5, "time": 194.26}
{"epoch": 11, "training_loss": 55.51618957519531, "training_acc": 52.5, "val_loss": 14.10736083984375, "val_acc": 50.0, "val_auroc": 0.55, "time": 211.32}
{"epoch": 12, "training_loss": 55.785621643066406, "training_acc": 52.5, "val_loss": 14.107856750488281, "val_acc": 50.0, "val_auroc": 0.59, "time": 228.48}
{"epoch": 13, "training_loss": 55.93639945983887, "training_acc": 52.5, "val_loss": 14.098745584487915, "val_acc": 50.0, "val_auroc": 0.59, "time": 245.96}
{"epoch": 14, "training_loss": 55.880136489868164, "training_acc": 52.5, "val_loss": 14.261547327041626, "val_acc": 50.0, "val_auroc": 0.58, "time": 263.42}
{"epoch": 15, "training_loss": 56.170650482177734, "training_acc": 52.5, "val_loss": 14.37272310256958, "val_acc": 50.0, "val_auroc": 0.52, "time": 280.13}
{"epoch": 16, "training_loss": 56.54068660736084, "training_acc": 52.5, "val_loss": 14.116780757904053, "val_acc": 50.0, "val_auroc": 0.55, "time": 297.46}
{"epoch": 17, "training_loss": 55.65220832824707, "training_acc": 52.5, "val_loss": 13.884012699127197, "val_acc": 50.0, "val_auroc": 0.51, "time": 314.86}
{"epoch": 18, "training_loss": 55.385053634643555, "training_acc": 50.0, "val_loss": 13.86528491973877, "val_acc": 50.0, "val_auroc": 0.48, "time": 332.79}
{"epoch": 19, "training_loss": 55.74971961975098, "training_acc": 40.0, "val_loss": 13.867733478546143, "val_acc": 50.0, "val_auroc": 0.43, "time": 350.27}
{"epoch": 20, "training_loss": 55.46159648895264, "training_acc": 47.5, "val_loss": 13.911217451095581, "val_acc": 50.0, "val_auroc": 0.46, "time": 367.38}
{"epoch": 21, "training_loss": 55.91600704193115, "training_acc": 47.5, "val_loss": 13.876152038574219, "val_acc": 50.0, "val_auroc": 0.47, "time": 383.98}
{"epoch": 22, "training_loss": 55.40581130981445, "training_acc": 50.0, "val_loss": 13.89890193939209, "val_acc": 50.0, "val_auroc": 0.48, "time": 401.29}
{"epoch": 23, "training_loss": 55.3458194732666, "training_acc": 52.5, "val_loss": 14.017499685287476, "val_acc": 50.0, "val_auroc": 0.53, "time": 418.57}
{"epoch": 24, "training_loss": 55.57859230041504, "training_acc": 52.5, "val_loss": 13.983123302459717, "val_acc": 50.0, "val_auroc": 0.48, "time": 435.55}
{"epoch": 25, "training_loss": 55.40467834472656, "training_acc": 52.5, "val_loss": 13.881988525390625, "val_acc": 50.0, "val_auroc": 0.53, "time": 452.41}
{"epoch": 26, "training_loss": 55.377596855163574, "training_acc": 52.5, "val_loss": 13.862559795379639, "val_acc": 50.0, "val_auroc": 0.52, "time": 469.03}
{"epoch": 27, "training_loss": 55.43324089050293, "training_acc": 53.75, "val_loss": 13.872560262680054, "val_acc": 50.0, "val_auroc": 0.51, "time": 486.29}
{"epoch": 28, "training_loss": 55.52484130859375, "training_acc": 52.5, "val_loss": 13.904072046279907, "val_acc": 50.0, "val_auroc": 0.44, "time": 503.39}
{"epoch": 29, "training_loss": 55.3377799987793, "training_acc": 52.5, "val_loss": 13.885517120361328, "val_acc": 50.0, "val_auroc": 0.46, "time": 520.17}
{"epoch": 30, "training_loss": 55.324546813964844, "training_acc": 52.5, "val_loss": 13.887269496917725, "val_acc": 50.0, "val_auroc": 0.43, "time": 536.72}
{"epoch": 31, "training_loss": 55.316229820251465, "training_acc": 52.5, "val_loss": 13.894360065460205, "val_acc": 50.0, "val_auroc": 0.44, "time": 553.7}
{"epoch": 32, "training_loss": 55.31864929199219, "training_acc": 52.5, "val_loss": 13.882055282592773, "val_acc": 50.0, "val_auroc": 0.41, "time": 570.68}
{"epoch": 33, "training_loss": 55.376590728759766, "training_acc": 52.5, "val_loss": 13.873449563980103, "val_acc": 50.0, "val_auroc": 0.46, "time": 587.6}
{"epoch": 34, "training_loss": 55.28229999542236, "training_acc": 52.5, "val_loss": 13.902753591537476, "val_acc": 50.0, "val_auroc": 0.47, "time": 604.85}
{"epoch": 35, "training_loss": 55.443214416503906, "training_acc": 52.5, "val_loss": 13.931794166564941, "val_acc": 50.0, "val_auroc": 0.5, "time": 622.15}
{"epoch": 36, "training_loss": 55.30611610412598, "training_acc": 52.5, "val_loss": 13.889634609222412, "val_acc": 50.0, "val_auroc": 0.52, "time": 639.23}
{"epoch": 37, "training_loss": 55.215128898620605, "training_acc": 52.5, "val_loss": 13.862613439559937, "val_acc": 50.0, "val_auroc": 0.5, "time": 656.64}
{"epoch": 38, "training_loss": 55.367998123168945, "training_acc": 51.25, "val_loss": 13.869999647140503, "val_acc": 50.0, "val_auroc": 0.5, "time": 673.74}
{"epoch": 39, "training_loss": 55.51824760437012, "training_acc": 47.5, "val_loss": 13.866602182388306, "val_acc": 50.0, "val_auroc": 0.5, "time": 690.79}
{"epoch": 40, "training_loss": 55.43508529663086, "training_acc": 47.5, "val_loss": 13.864097595214844, "val_acc": 50.0, "val_auroc": 0.51, "time": 707.65}
{"epoch": 41, "training_loss": 55.44328498840332, "training_acc": 51.25, "val_loss": 13.879244327545166, "val_acc": 50.0, "val_auroc": 0.5, "time": 724.82}
{"epoch": 42, "training_loss": 55.2587308883667, "training_acc": 52.5, "val_loss": 13.880456686019897, "val_acc": 50.0, "val_auroc": 0.47, "time": 741.62}
{"epoch": 43, "training_loss": 55.240936279296875, "training_acc": 52.5, "val_loss": 13.901456594467163, "val_acc": 50.0, "val_auroc": 0.5, "time": 758.84}
{"epoch": 44, "training_loss": 55.36230278015137, "training_acc": 52.5, "val_loss": 13.919267654418945, "val_acc": 50.0, "val_auroc": 0.5, "time": 775.82}
{"epoch": 45, "training_loss": 55.25600624084473, "training_acc": 52.5, "val_loss": 13.891762495040894, "val_acc": 50.0, "val_auroc": 0.51, "time": 792.63}
