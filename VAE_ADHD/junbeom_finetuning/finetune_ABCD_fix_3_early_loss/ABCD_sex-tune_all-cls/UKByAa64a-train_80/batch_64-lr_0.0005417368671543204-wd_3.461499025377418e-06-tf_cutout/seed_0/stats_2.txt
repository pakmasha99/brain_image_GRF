"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.08260154724121, "training_acc": 52.5, "val_loss": 13.979462385177612, "val_acc": 50.0, "val_auroc": 0.18, "time": 18.01}
{"epoch": 1, "training_loss": 55.865739822387695, "training_acc": 47.5, "val_loss": 13.945406675338745, "val_acc": 50.0, "val_auroc": 0.38, "time": 33.1}
{"epoch": 2, "training_loss": 55.52642250061035, "training_acc": 50.0, "val_loss": 13.937547206878662, "val_acc": 50.0, "val_auroc": 0.28, "time": 47.97}
{"epoch": 3, "training_loss": 55.58552646636963, "training_acc": 52.5, "val_loss": 14.016703367233276, "val_acc": 50.0, "val_auroc": 0.38, "time": 63.32}
{"epoch": 4, "training_loss": 55.571078300476074, "training_acc": 52.5, "val_loss": 13.904675245285034, "val_acc": 50.0, "val_auroc": 0.43, "time": 78.83}
{"epoch": 5, "training_loss": 55.419654846191406, "training_acc": 52.5, "val_loss": 13.878988027572632, "val_acc": 50.0, "val_auroc": 0.7, "time": 95.55}
{"epoch": 6, "training_loss": 55.47020626068115, "training_acc": 52.5, "val_loss": 13.994448184967041, "val_acc": 50.0, "val_auroc": 0.73, "time": 111.34}
{"epoch": 7, "training_loss": 55.522948265075684, "training_acc": 52.5, "val_loss": 14.136812686920166, "val_acc": 50.0, "val_auroc": 0.27, "time": 127.11}
{"epoch": 8, "training_loss": 55.91246795654297, "training_acc": 52.5, "val_loss": 13.930734395980835, "val_acc": 50.0, "val_auroc": 0.3, "time": 144.0}
{"epoch": 9, "training_loss": 55.340529441833496, "training_acc": 52.5, "val_loss": 13.878639936447144, "val_acc": 50.0, "val_auroc": 0.28, "time": 161.34}
{"epoch": 10, "training_loss": 55.72415351867676, "training_acc": 47.5, "val_loss": 13.87879729270935, "val_acc": 50.0, "val_auroc": 0.22, "time": 177.26}
{"epoch": 11, "training_loss": 55.55817127227783, "training_acc": 47.5, "val_loss": 13.886736631393433, "val_acc": 50.0, "val_auroc": 0.24, "time": 192.72}
{"epoch": 12, "training_loss": 55.404290199279785, "training_acc": 52.5, "val_loss": 13.99266242980957, "val_acc": 50.0, "val_auroc": 0.33, "time": 208.72}
{"epoch": 13, "training_loss": 55.52284336090088, "training_acc": 52.5, "val_loss": 13.967224359512329, "val_acc": 50.0, "val_auroc": 0.59, "time": 224.82}
{"epoch": 14, "training_loss": 55.43147945404053, "training_acc": 52.5, "val_loss": 13.893152475357056, "val_acc": 50.0, "val_auroc": 0.67, "time": 241.34}
{"epoch": 15, "training_loss": 55.555593490600586, "training_acc": 52.5, "val_loss": 13.886446952819824, "val_acc": 50.0, "val_auroc": 0.37, "time": 257.36}
{"epoch": 16, "training_loss": 55.30741882324219, "training_acc": 52.5, "val_loss": 13.983063697814941, "val_acc": 50.0, "val_auroc": 0.83, "time": 273.61}
{"epoch": 17, "training_loss": 55.571210861206055, "training_acc": 52.5, "val_loss": 14.102232456207275, "val_acc": 50.0, "val_auroc": 0.4, "time": 292.96}
{"epoch": 18, "training_loss": 55.78176498413086, "training_acc": 52.5, "val_loss": 13.995417356491089, "val_acc": 50.0, "val_auroc": 0.41, "time": 309.97}
{"epoch": 19, "training_loss": 55.401994705200195, "training_acc": 52.5, "val_loss": 13.870630264282227, "val_acc": 50.0, "val_auroc": 0.51, "time": 327.41}
{"epoch": 20, "training_loss": 55.44987678527832, "training_acc": 50.0, "val_loss": 13.870415687561035, "val_acc": 50.0, "val_auroc": 0.85, "time": 343.72}
{"epoch": 21, "training_loss": 55.621392250061035, "training_acc": 47.5, "val_loss": 13.867007493972778, "val_acc": 50.0, "val_auroc": 0.87, "time": 359.45}
{"epoch": 22, "training_loss": 55.52747917175293, "training_acc": 47.5, "val_loss": 13.868874311447144, "val_acc": 50.0, "val_auroc": 0.71, "time": 375.93}
{"epoch": 23, "training_loss": 55.30671310424805, "training_acc": 52.5, "val_loss": 13.94283413887024, "val_acc": 50.0, "val_auroc": 0.78, "time": 391.88}
{"epoch": 24, "training_loss": 55.35293388366699, "training_acc": 52.5, "val_loss": 14.106487035751343, "val_acc": 50.0, "val_auroc": 0.33, "time": 407.95}
{"epoch": 25, "training_loss": 55.81208324432373, "training_acc": 52.5, "val_loss": 14.206953048706055, "val_acc": 50.0, "val_auroc": 0.64, "time": 423.57}
{"epoch": 26, "training_loss": 56.143009185791016, "training_acc": 52.5, "val_loss": 14.18326735496521, "val_acc": 50.0, "val_auroc": 0.68, "time": 439.18}
{"epoch": 27, "training_loss": 56.01031494140625, "training_acc": 52.5, "val_loss": 14.108572006225586, "val_acc": 50.0, "val_auroc": 0.55, "time": 455.15}
{"epoch": 28, "training_loss": 55.71073055267334, "training_acc": 52.5, "val_loss": 13.92279863357544, "val_acc": 50.0, "val_auroc": 0.18, "time": 470.34}
{"epoch": 29, "training_loss": 55.4640007019043, "training_acc": 52.5, "val_loss": 13.871564865112305, "val_acc": 50.0, "val_auroc": 0.17, "time": 485.69}
{"epoch": 30, "training_loss": 55.680564880371094, "training_acc": 47.5, "val_loss": 13.901838064193726, "val_acc": 50.0, "val_auroc": 0.55, "time": 500.86}
{"epoch": 31, "training_loss": 55.873077392578125, "training_acc": 47.5, "val_loss": 13.883110284805298, "val_acc": 50.0, "val_auroc": 0.83, "time": 515.85}
{"epoch": 32, "training_loss": 55.73969268798828, "training_acc": 47.5, "val_loss": 13.8683021068573, "val_acc": 50.0, "val_auroc": 0.78, "time": 531.35}
{"epoch": 33, "training_loss": 55.56515884399414, "training_acc": 47.5, "val_loss": 13.862441778182983, "val_acc": 50.0, "val_auroc": 0.81, "time": 547.14}
{"epoch": 34, "training_loss": 55.40413475036621, "training_acc": 52.5, "val_loss": 13.885281085968018, "val_acc": 50.0, "val_auroc": 0.82, "time": 562.61}
{"epoch": 35, "training_loss": 55.545677185058594, "training_acc": 52.5, "val_loss": 13.930662870407104, "val_acc": 50.0, "val_auroc": 0.12, "time": 578.22}
{"epoch": 36, "training_loss": 55.38677978515625, "training_acc": 52.5, "val_loss": 13.905775547027588, "val_acc": 50.0, "val_auroc": 0.16, "time": 595.56}
{"epoch": 37, "training_loss": 55.33942985534668, "training_acc": 52.5, "val_loss": 13.873859643936157, "val_acc": 50.0, "val_auroc": 0.16, "time": 612.96}
{"epoch": 38, "training_loss": 55.464051246643066, "training_acc": 52.5, "val_loss": 13.864482641220093, "val_acc": 50.0, "val_auroc": 0.18, "time": 630.09}
{"epoch": 39, "training_loss": 55.422492027282715, "training_acc": 52.5, "val_loss": 13.868714570999146, "val_acc": 50.0, "val_auroc": 0.17, "time": 646.72}
{"epoch": 40, "training_loss": 55.45425605773926, "training_acc": 52.5, "val_loss": 13.868383169174194, "val_acc": 50.0, "val_auroc": 0.17, "time": 662.96}
{"epoch": 41, "training_loss": 55.36656188964844, "training_acc": 52.5, "val_loss": 13.863775730133057, "val_acc": 50.0, "val_auroc": 0.18, "time": 679.19}
{"epoch": 42, "training_loss": 55.55195999145508, "training_acc": 47.5, "val_loss": 13.864504098892212, "val_acc": 50.0, "val_auroc": 0.18, "time": 695.8}
{"epoch": 43, "training_loss": 55.499051094055176, "training_acc": 47.5, "val_loss": 13.86921763420105, "val_acc": 50.0, "val_auroc": 0.19, "time": 712.73}
{"epoch": 44, "training_loss": 55.38789367675781, "training_acc": 52.5, "val_loss": 13.892344236373901, "val_acc": 50.0, "val_auroc": 0.36, "time": 729.62}
{"epoch": 45, "training_loss": 55.36269950866699, "training_acc": 52.5, "val_loss": 13.909387588500977, "val_acc": 50.0, "val_auroc": 0.28, "time": 747.61}
{"epoch": 46, "training_loss": 55.36549377441406, "training_acc": 52.5, "val_loss": 13.915354013442993, "val_acc": 50.0, "val_auroc": 0.29, "time": 764.71}
{"epoch": 47, "training_loss": 55.37518501281738, "training_acc": 52.5, "val_loss": 13.913894891738892, "val_acc": 50.0, "val_auroc": 0.27, "time": 781.17}
{"epoch": 48, "training_loss": 55.4427375793457, "training_acc": 52.5, "val_loss": 13.92155408859253, "val_acc": 50.0, "val_auroc": 0.26, "time": 798.34}
{"epoch": 49, "training_loss": 55.40077781677246, "training_acc": 52.5, "val_loss": 13.957698345184326, "val_acc": 50.0, "val_auroc": 0.35, "time": 816.26}
{"epoch": 50, "training_loss": 55.44140815734863, "training_acc": 52.5, "val_loss": 13.94163966178894, "val_acc": 50.0, "val_auroc": 0.32, "time": 833.12}
{"epoch": 51, "training_loss": 55.395710945129395, "training_acc": 52.5, "val_loss": 13.899492025375366, "val_acc": 50.0, "val_auroc": 0.25, "time": 850.25}
{"epoch": 52, "training_loss": 55.42685127258301, "training_acc": 52.5, "val_loss": 13.879954814910889, "val_acc": 50.0, "val_auroc": 0.25, "time": 867.38}
