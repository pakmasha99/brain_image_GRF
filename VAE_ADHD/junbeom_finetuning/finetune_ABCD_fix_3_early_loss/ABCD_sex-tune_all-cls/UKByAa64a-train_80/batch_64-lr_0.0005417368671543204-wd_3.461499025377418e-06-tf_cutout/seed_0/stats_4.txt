"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.19907855987549, "training_acc": 51.25, "val_loss": 13.767329454421997, "val_acc": 55.0, "val_auroc": 0.657, "time": 17.38}
{"epoch": 1, "training_loss": 56.23763179779053, "training_acc": 43.75, "val_loss": 13.771474361419678, "val_acc": 55.0, "val_auroc": 0.657, "time": 32.57}
{"epoch": 2, "training_loss": 56.0932092666626, "training_acc": 43.75, "val_loss": 13.771476745605469, "val_acc": 55.0, "val_auroc": 0.525, "time": 48.91}
{"epoch": 3, "training_loss": 55.95382881164551, "training_acc": 51.25, "val_loss": 13.814735412597656, "val_acc": 55.0, "val_auroc": 0.384, "time": 64.85}
{"epoch": 4, "training_loss": 55.52947807312012, "training_acc": 48.75, "val_loss": 13.843214511871338, "val_acc": 55.0, "val_auroc": 0.414, "time": 79.97}
{"epoch": 5, "training_loss": 55.444406509399414, "training_acc": 51.25, "val_loss": 13.805156946182251, "val_acc": 55.0, "val_auroc": 0.545, "time": 95.52}
{"epoch": 6, "training_loss": 55.45095157623291, "training_acc": 51.25, "val_loss": 13.789833784103394, "val_acc": 55.0, "val_auroc": 0.475, "time": 110.4}
{"epoch": 7, "training_loss": 55.4589900970459, "training_acc": 51.25, "val_loss": 13.790369033813477, "val_acc": 55.0, "val_auroc": 0.384, "time": 125.4}
{"epoch": 8, "training_loss": 55.48277473449707, "training_acc": 51.25, "val_loss": 13.900566101074219, "val_acc": 55.0, "val_auroc": 0.384, "time": 140.6}
{"epoch": 9, "training_loss": 55.75410461425781, "training_acc": 48.75, "val_loss": 13.957659006118774, "val_acc": 55.0, "val_auroc": 0.394, "time": 156.06}
{"epoch": 10, "training_loss": 55.58033561706543, "training_acc": 48.75, "val_loss": 13.81665587425232, "val_acc": 55.0, "val_auroc": 0.485, "time": 171.46}
{"epoch": 11, "training_loss": 55.39517593383789, "training_acc": 51.25, "val_loss": 13.765720129013062, "val_acc": 55.0, "val_auroc": 0.566, "time": 186.87}
{"epoch": 12, "training_loss": 55.67910861968994, "training_acc": 51.25, "val_loss": 13.76245379447937, "val_acc": 55.0, "val_auroc": 0.657, "time": 202.14}
{"epoch": 13, "training_loss": 55.6605281829834, "training_acc": 51.25, "val_loss": 13.78438949584961, "val_acc": 55.0, "val_auroc": 0.354, "time": 217.2}
{"epoch": 14, "training_loss": 55.44128894805908, "training_acc": 51.25, "val_loss": 13.869227170944214, "val_acc": 55.0, "val_auroc": 0.354, "time": 232.16}
{"epoch": 15, "training_loss": 55.66127014160156, "training_acc": 48.75, "val_loss": 13.956202268600464, "val_acc": 55.0, "val_auroc": 0.364, "time": 247.91}
{"epoch": 16, "training_loss": 55.596927642822266, "training_acc": 48.75, "val_loss": 13.810163736343384, "val_acc": 55.0, "val_auroc": 0.556, "time": 264.14}
{"epoch": 17, "training_loss": 55.48179244995117, "training_acc": 51.25, "val_loss": 13.766746520996094, "val_acc": 55.0, "val_auroc": 0.556, "time": 280.53}
{"epoch": 18, "training_loss": 55.86771011352539, "training_acc": 51.25, "val_loss": 13.767292499542236, "val_acc": 55.0, "val_auroc": 0.444, "time": 297.22}
{"epoch": 19, "training_loss": 55.7246675491333, "training_acc": 51.25, "val_loss": 13.781707286834717, "val_acc": 55.0, "val_auroc": 0.293, "time": 312.84}
{"epoch": 20, "training_loss": 55.44369316101074, "training_acc": 51.25, "val_loss": 13.902448415756226, "val_acc": 55.0, "val_auroc": 0.192, "time": 328.07}
{"epoch": 21, "training_loss": 55.51131248474121, "training_acc": 48.75, "val_loss": 14.00105595588684, "val_acc": 55.0, "val_auroc": 0.242, "time": 343.38}
{"epoch": 22, "training_loss": 55.675753593444824, "training_acc": 48.75, "val_loss": 13.97167444229126, "val_acc": 55.0, "val_auroc": 0.222, "time": 358.82}
{"epoch": 23, "training_loss": 55.589385986328125, "training_acc": 48.75, "val_loss": 13.873120546340942, "val_acc": 55.0, "val_auroc": 0.374, "time": 374.49}
{"epoch": 24, "training_loss": 55.52830982208252, "training_acc": 46.25, "val_loss": 13.810791969299316, "val_acc": 55.0, "val_auroc": 0.313, "time": 389.62}
{"epoch": 25, "training_loss": 55.435110092163086, "training_acc": 51.25, "val_loss": 13.782254457473755, "val_acc": 55.0, "val_auroc": 0.354, "time": 406.54}
{"epoch": 26, "training_loss": 55.450307846069336, "training_acc": 51.25, "val_loss": 13.763741254806519, "val_acc": 55.0, "val_auroc": 0.222, "time": 422.59}
{"epoch": 27, "training_loss": 55.62198829650879, "training_acc": 51.25, "val_loss": 13.76294732093811, "val_acc": 55.0, "val_auroc": 0.323, "time": 438.55}
{"epoch": 28, "training_loss": 55.61282539367676, "training_acc": 51.25, "val_loss": 13.780118227005005, "val_acc": 55.0, "val_auroc": 0.202, "time": 454.45}
{"epoch": 29, "training_loss": 55.6900691986084, "training_acc": 51.25, "val_loss": 13.816795349121094, "val_acc": 55.0, "val_auroc": 0.576, "time": 469.95}
{"epoch": 30, "training_loss": 55.42990493774414, "training_acc": 51.25, "val_loss": 13.804855346679688, "val_acc": 55.0, "val_auroc": 0.384, "time": 486.67}
{"epoch": 31, "training_loss": 55.445268630981445, "training_acc": 51.25, "val_loss": 13.820217847824097, "val_acc": 55.0, "val_auroc": 0.556, "time": 503.26}
