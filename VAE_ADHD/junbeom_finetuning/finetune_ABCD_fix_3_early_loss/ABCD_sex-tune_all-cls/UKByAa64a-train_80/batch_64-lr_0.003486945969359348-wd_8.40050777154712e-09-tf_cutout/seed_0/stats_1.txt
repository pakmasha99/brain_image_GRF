"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 114.04322052001953, "training_acc": 53.75, "val_loss": 5496465.0, "val_acc": 50.0, "val_auroc": 0.48, "time": 17.08}
{"epoch": 1, "training_loss": 17232388.125, "training_acc": 47.5, "val_loss": 1090.908203125, "val_acc": 50.0, "val_auroc": 0.47, "time": 33.4}
{"epoch": 2, "training_loss": 3598.295648574829, "training_acc": 47.5, "val_loss": 3324.2526245117188, "val_acc": 50.0, "val_auroc": 0.49, "time": 49.53}
{"epoch": 3, "training_loss": 9779.011344909668, "training_acc": 52.5, "val_loss": 365.0585174560547, "val_acc": 50.0, "val_auroc": 0.46, "time": 65.99}
{"epoch": 4, "training_loss": 3573.370361328125, "training_acc": 52.5, "val_loss": 752.6363372802734, "val_acc": 50.0, "val_auroc": 0.55, "time": 82.6}
{"epoch": 5, "training_loss": 2487.5022354125977, "training_acc": 50.0, "val_loss": 22.751305103302002, "val_acc": 50.0, "val_auroc": 0.39, "time": 98.6}
{"epoch": 6, "training_loss": 277.7873764038086, "training_acc": 52.5, "val_loss": 28.35163116455078, "val_acc": 50.0, "val_auroc": 0.51, "time": 114.44}
{"epoch": 7, "training_loss": 243.54959106445312, "training_acc": 50.0, "val_loss": 211.42080307006836, "val_acc": 50.0, "val_auroc": 0.49, "time": 129.7}
{"epoch": 8, "training_loss": 699.6718215942383, "training_acc": 52.5, "val_loss": 40.683302879333496, "val_acc": 50.0, "val_auroc": 0.67, "time": 147.84}
{"epoch": 9, "training_loss": 168.13123893737793, "training_acc": 45.0, "val_loss": 49.51296329498291, "val_acc": 50.0, "val_auroc": 0.64, "time": 165.13}
{"epoch": 10, "training_loss": 176.25768089294434, "training_acc": 47.5, "val_loss": 73.11872005462646, "val_acc": 50.0, "val_auroc": 0.47, "time": 180.96}
{"epoch": 11, "training_loss": 262.1562614440918, "training_acc": 52.5, "val_loss": 18.823156356811523, "val_acc": 50.0, "val_auroc": 0.75, "time": 198.37}
{"epoch": 12, "training_loss": 87.57423782348633, "training_acc": 47.5, "val_loss": 18.977832794189453, "val_acc": 50.0, "val_auroc": 0.82, "time": 214.8}
{"epoch": 13, "training_loss": 72.94687843322754, "training_acc": 52.5, "val_loss": 16.725071668624878, "val_acc": 50.0, "val_auroc": 0.78, "time": 231.12}
{"epoch": 14, "training_loss": 63.146507263183594, "training_acc": 55.0, "val_loss": 30.211780071258545, "val_acc": 50.0, "val_auroc": 0.82, "time": 248.9}
{"epoch": 15, "training_loss": 107.71341896057129, "training_acc": 52.5, "val_loss": 14.90337610244751, "val_acc": 50.0, "val_auroc": 0.79, "time": 265.53}
{"epoch": 16, "training_loss": 58.195733070373535, "training_acc": 52.5, "val_loss": 20.345706939697266, "val_acc": 50.0, "val_auroc": 0.78, "time": 282.77}
{"epoch": 17, "training_loss": 72.07891750335693, "training_acc": 55.0, "val_loss": 21.184635162353516, "val_acc": 50.0, "val_auroc": 0.77, "time": 301.12}
{"epoch": 18, "training_loss": 83.50608253479004, "training_acc": 47.5, "val_loss": 15.326743125915527, "val_acc": 50.0, "val_auroc": 0.76, "time": 316.61}
{"epoch": 19, "training_loss": 57.02595329284668, "training_acc": 57.5, "val_loss": 19.82219696044922, "val_acc": 50.0, "val_auroc": 0.77, "time": 330.91}
{"epoch": 20, "training_loss": 76.80607986450195, "training_acc": 47.5, "val_loss": 16.7033851146698, "val_acc": 50.0, "val_auroc": 0.8, "time": 345.89}
{"epoch": 21, "training_loss": 65.54249000549316, "training_acc": 52.5, "val_loss": 14.125667810440063, "val_acc": 50.0, "val_auroc": 0.79, "time": 361.67}
{"epoch": 22, "training_loss": 57.72564888000488, "training_acc": 50.0, "val_loss": 14.371769428253174, "val_acc": 65.0, "val_auroc": 0.77, "time": 377.21}
{"epoch": 23, "training_loss": 58.372483253479004, "training_acc": 47.5, "val_loss": 14.311636686325073, "val_acc": 50.0, "val_auroc": 0.76, "time": 392.33}
{"epoch": 24, "training_loss": 56.947431564331055, "training_acc": 52.5, "val_loss": 14.42561149597168, "val_acc": 50.0, "val_auroc": 0.78, "time": 408.18}
{"epoch": 25, "training_loss": 57.41998291015625, "training_acc": 48.75, "val_loss": 13.829339742660522, "val_acc": 50.0, "val_auroc": 0.79, "time": 425.64}
{"epoch": 26, "training_loss": 56.275028228759766, "training_acc": 47.5, "val_loss": 13.702675104141235, "val_acc": 50.0, "val_auroc": 0.77, "time": 441.96}
{"epoch": 27, "training_loss": 54.88690185546875, "training_acc": 52.5, "val_loss": 14.140084981918335, "val_acc": 50.0, "val_auroc": 0.75, "time": 458.84}
{"epoch": 28, "training_loss": 56.69119071960449, "training_acc": 52.5, "val_loss": 14.336719512939453, "val_acc": 70.0, "val_auroc": 0.77, "time": 474.8}
{"epoch": 29, "training_loss": 59.458356857299805, "training_acc": 47.5, "val_loss": 14.123640060424805, "val_acc": 50.0, "val_auroc": 0.78, "time": 493.29}
{"epoch": 30, "training_loss": 55.947248458862305, "training_acc": 52.5, "val_loss": 15.579878091812134, "val_acc": 50.0, "val_auroc": 0.75, "time": 508.79}
{"epoch": 31, "training_loss": 61.67756366729736, "training_acc": 52.5, "val_loss": 15.122530460357666, "val_acc": 50.0, "val_auroc": 0.77, "time": 526.62}
{"epoch": 32, "training_loss": 57.55263137817383, "training_acc": 52.5, "val_loss": 14.545559883117676, "val_acc": 50.0, "val_auroc": 0.79, "time": 544.45}
{"epoch": 33, "training_loss": 60.82129192352295, "training_acc": 47.5, "val_loss": 15.066380500793457, "val_acc": 50.0, "val_auroc": 0.8, "time": 562.76}
{"epoch": 34, "training_loss": 59.81550979614258, "training_acc": 47.5, "val_loss": 14.336098432540894, "val_acc": 50.0, "val_auroc": 0.76, "time": 580.59}
{"epoch": 35, "training_loss": 59.58192253112793, "training_acc": 52.5, "val_loss": 14.235045909881592, "val_acc": 50.0, "val_auroc": 0.76, "time": 596.66}
{"epoch": 36, "training_loss": 55.03678226470947, "training_acc": 56.25, "val_loss": 14.985319375991821, "val_acc": 50.0, "val_auroc": 0.75, "time": 616.37}
{"epoch": 37, "training_loss": 60.87689018249512, "training_acc": 47.5, "val_loss": 15.132583379745483, "val_acc": 50.0, "val_auroc": 0.76, "time": 633.48}
{"epoch": 38, "training_loss": 60.641629219055176, "training_acc": 47.5, "val_loss": 13.7444007396698, "val_acc": 50.0, "val_auroc": 0.79, "time": 650.97}
{"epoch": 39, "training_loss": 55.77984428405762, "training_acc": 52.5, "val_loss": 15.028706789016724, "val_acc": 50.0, "val_auroc": 0.76, "time": 667.54}
{"epoch": 40, "training_loss": 59.02122688293457, "training_acc": 52.5, "val_loss": 13.854559659957886, "val_acc": 50.0, "val_auroc": 0.76, "time": 684.29}
{"epoch": 41, "training_loss": 54.72328186035156, "training_acc": 56.25, "val_loss": 14.7150719165802, "val_acc": 50.0, "val_auroc": 0.77, "time": 701.31}
{"epoch": 42, "training_loss": 60.56107425689697, "training_acc": 47.5, "val_loss": 14.219063520431519, "val_acc": 60.0, "val_auroc": 0.78, "time": 718.13}
{"epoch": 43, "training_loss": 56.64241409301758, "training_acc": 50.0, "val_loss": 14.365980625152588, "val_acc": 50.0, "val_auroc": 0.76, "time": 735.91}
{"epoch": 44, "training_loss": 57.65486240386963, "training_acc": 52.5, "val_loss": 14.91619348526001, "val_acc": 50.0, "val_auroc": 0.76, "time": 754.65}
{"epoch": 45, "training_loss": 58.597171783447266, "training_acc": 52.5, "val_loss": 13.728388547897339, "val_acc": 50.0, "val_auroc": 0.78, "time": 771.13}
