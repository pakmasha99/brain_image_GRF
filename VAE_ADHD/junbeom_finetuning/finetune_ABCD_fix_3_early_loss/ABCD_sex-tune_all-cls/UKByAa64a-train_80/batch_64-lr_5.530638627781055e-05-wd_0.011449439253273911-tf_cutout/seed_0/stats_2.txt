"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.45000743865967, "training_acc": 52.5, "val_loss": 13.93227219581604, "val_acc": 50.0, "val_auroc": 0.56, "time": 19.52}
{"epoch": 1, "training_loss": 55.52556800842285, "training_acc": 52.5, "val_loss": 13.967169523239136, "val_acc": 50.0, "val_auroc": 0.27, "time": 37.29}
{"epoch": 2, "training_loss": 55.22497844696045, "training_acc": 52.5, "val_loss": 13.977996110916138, "val_acc": 50.0, "val_auroc": 0.32, "time": 57.97}
{"epoch": 3, "training_loss": 55.23691463470459, "training_acc": 52.5, "val_loss": 13.97872805595398, "val_acc": 50.0, "val_auroc": 0.34, "time": 79.22}
{"epoch": 4, "training_loss": 55.081974029541016, "training_acc": 52.5, "val_loss": 13.948249816894531, "val_acc": 50.0, "val_auroc": 0.41, "time": 96.99}
{"epoch": 5, "training_loss": 54.930503845214844, "training_acc": 52.5, "val_loss": 13.906358480453491, "val_acc": 50.0, "val_auroc": 0.4, "time": 115.3}
{"epoch": 6, "training_loss": 54.80868911743164, "training_acc": 52.5, "val_loss": 13.912314176559448, "val_acc": 50.0, "val_auroc": 0.48, "time": 133.97}
{"epoch": 7, "training_loss": 54.67643737792969, "training_acc": 52.5, "val_loss": 13.997539281845093, "val_acc": 50.0, "val_auroc": 0.44, "time": 153.86}
{"epoch": 8, "training_loss": 54.841054916381836, "training_acc": 52.5, "val_loss": 13.943201303482056, "val_acc": 50.0, "val_auroc": 0.45, "time": 171.38}
{"epoch": 9, "training_loss": 54.608985900878906, "training_acc": 52.5, "val_loss": 13.902608156204224, "val_acc": 50.0, "val_auroc": 0.49, "time": 189.48}
{"epoch": 10, "training_loss": 54.73740291595459, "training_acc": 55.0, "val_loss": 13.923059701919556, "val_acc": 50.0, "val_auroc": 0.42, "time": 208.36}
{"epoch": 11, "training_loss": 54.592204093933105, "training_acc": 71.25, "val_loss": 13.949335813522339, "val_acc": 50.0, "val_auroc": 0.38, "time": 228.06}
{"epoch": 12, "training_loss": 54.318817138671875, "training_acc": 52.5, "val_loss": 13.959376811981201, "val_acc": 50.0, "val_auroc": 0.45, "time": 246.78}
{"epoch": 13, "training_loss": 54.31239032745361, "training_acc": 52.5, "val_loss": 13.890465497970581, "val_acc": 50.0, "val_auroc": 0.52, "time": 267.05}
{"epoch": 14, "training_loss": 53.94794845581055, "training_acc": 52.5, "val_loss": 13.845778703689575, "val_acc": 50.0, "val_auroc": 0.56, "time": 285.97}
{"epoch": 15, "training_loss": 53.71532726287842, "training_acc": 62.5, "val_loss": 13.927961587905884, "val_acc": 50.0, "val_auroc": 0.46, "time": 304.98}
{"epoch": 16, "training_loss": 53.242238998413086, "training_acc": 52.5, "val_loss": 14.004615545272827, "val_acc": 50.0, "val_auroc": 0.6, "time": 322.93}
{"epoch": 17, "training_loss": 53.80196666717529, "training_acc": 52.5, "val_loss": 13.865132331848145, "val_acc": 50.0, "val_auroc": 0.57, "time": 341.74}
{"epoch": 18, "training_loss": 52.74778175354004, "training_acc": 53.75, "val_loss": 13.831074237823486, "val_acc": 50.0, "val_auroc": 0.58, "time": 360.43}
{"epoch": 19, "training_loss": 53.37252140045166, "training_acc": 85.0, "val_loss": 13.789852857589722, "val_acc": 50.0, "val_auroc": 0.57, "time": 379.77}
{"epoch": 20, "training_loss": 52.137064933776855, "training_acc": 78.75, "val_loss": 13.863354921340942, "val_acc": 50.0, "val_auroc": 0.55, "time": 398.83}
{"epoch": 21, "training_loss": 51.40543174743652, "training_acc": 62.5, "val_loss": 13.80198359489441, "val_acc": 50.0, "val_auroc": 0.55, "time": 417.5}
{"epoch": 22, "training_loss": 50.247772216796875, "training_acc": 85.0, "val_loss": 13.749213218688965, "val_acc": 50.0, "val_auroc": 0.53, "time": 435.33}
{"epoch": 23, "training_loss": 49.516536712646484, "training_acc": 88.75, "val_loss": 13.86394739151001, "val_acc": 50.0, "val_auroc": 0.68, "time": 453.87}
{"epoch": 24, "training_loss": 50.01888847351074, "training_acc": 62.5, "val_loss": 13.587961196899414, "val_acc": 50.0, "val_auroc": 0.6, "time": 473.27}
{"epoch": 25, "training_loss": 47.73396873474121, "training_acc": 90.0, "val_loss": 13.549255132675171, "val_acc": 50.0, "val_auroc": 0.61, "time": 492.86}
{"epoch": 26, "training_loss": 46.203857421875, "training_acc": 91.25, "val_loss": 14.574620723724365, "val_acc": 50.0, "val_auroc": 0.6, "time": 510.79}
{"epoch": 27, "training_loss": 50.67433738708496, "training_acc": 57.5, "val_loss": 13.803328275680542, "val_acc": 50.0, "val_auroc": 0.59, "time": 529.07}
{"epoch": 28, "training_loss": 48.062506675720215, "training_acc": 86.25, "val_loss": 13.652139902114868, "val_acc": 50.0, "val_auroc": 0.57, "time": 546.81}
{"epoch": 29, "training_loss": 42.64521026611328, "training_acc": 93.75, "val_loss": 13.45502257347107, "val_acc": 50.0, "val_auroc": 0.67, "time": 564.97}
{"epoch": 30, "training_loss": 41.802504539489746, "training_acc": 96.25, "val_loss": 13.623006343841553, "val_acc": 55.0, "val_auroc": 0.58, "time": 582.15}
{"epoch": 31, "training_loss": 40.22638416290283, "training_acc": 91.25, "val_loss": 14.078311920166016, "val_acc": 60.0, "val_auroc": 0.55, "time": 599.78}
{"epoch": 32, "training_loss": 43.6635684967041, "training_acc": 80.0, "val_loss": 13.506015539169312, "val_acc": 50.0, "val_auroc": 0.61, "time": 616.92}
{"epoch": 33, "training_loss": 37.44170570373535, "training_acc": 97.5, "val_loss": 13.330994844436646, "val_acc": 55.0, "val_auroc": 0.7, "time": 635.15}
{"epoch": 34, "training_loss": 36.8354434967041, "training_acc": 93.75, "val_loss": 13.532692193984985, "val_acc": 55.0, "val_auroc": 0.61, "time": 652.43}
{"epoch": 35, "training_loss": 34.56484794616699, "training_acc": 100.0, "val_loss": 14.648188352584839, "val_acc": 45.0, "val_auroc": 0.56, "time": 669.48}
{"epoch": 36, "training_loss": 41.719279766082764, "training_acc": 87.5, "val_loss": 14.167611598968506, "val_acc": 50.0, "val_auroc": 0.63, "time": 686.71}
{"epoch": 37, "training_loss": 35.80716514587402, "training_acc": 93.75, "val_loss": 13.207746744155884, "val_acc": 55.0, "val_auroc": 0.63, "time": 705.34}
{"epoch": 38, "training_loss": 32.185203552246094, "training_acc": 100.0, "val_loss": 13.143576383590698, "val_acc": 60.0, "val_auroc": 0.64, "time": 723.89}
{"epoch": 39, "training_loss": 30.00010395050049, "training_acc": 100.0, "val_loss": 13.504481315612793, "val_acc": 60.0, "val_auroc": 0.59, "time": 740.6}
{"epoch": 40, "training_loss": 29.921104431152344, "training_acc": 100.0, "val_loss": 13.647674322128296, "val_acc": 70.0, "val_auroc": 0.61, "time": 757.25}
{"epoch": 41, "training_loss": 30.266616344451904, "training_acc": 98.75, "val_loss": 13.470268249511719, "val_acc": 60.0, "val_auroc": 0.65, "time": 774.38}
{"epoch": 42, "training_loss": 26.832162857055664, "training_acc": 100.0, "val_loss": 13.374286890029907, "val_acc": 60.0, "val_auroc": 0.62, "time": 791.28}
{"epoch": 43, "training_loss": 27.07106590270996, "training_acc": 100.0, "val_loss": 13.203613758087158, "val_acc": 60.0, "val_auroc": 0.64, "time": 809.25}
{"epoch": 44, "training_loss": 25.456503868103027, "training_acc": 100.0, "val_loss": 13.273109197616577, "val_acc": 65.0, "val_auroc": 0.64, "time": 826.6}
{"epoch": 45, "training_loss": 24.61655044555664, "training_acc": 100.0, "val_loss": 14.257646799087524, "val_acc": 50.0, "val_auroc": 0.66, "time": 846.64}
{"epoch": 46, "training_loss": 25.88249111175537, "training_acc": 100.0, "val_loss": 14.276351928710938, "val_acc": 55.0, "val_auroc": 0.6, "time": 864.14}
{"epoch": 47, "training_loss": 25.93268632888794, "training_acc": 100.0, "val_loss": 14.18993353843689, "val_acc": 55.0, "val_auroc": 0.7, "time": 880.88}
{"epoch": 48, "training_loss": 24.14504384994507, "training_acc": 100.0, "val_loss": 14.100059270858765, "val_acc": 55.0, "val_auroc": 0.63, "time": 898.1}
{"epoch": 49, "training_loss": 23.9781551361084, "training_acc": 100.0, "val_loss": 15.13351559638977, "val_acc": 50.0, "val_auroc": 0.67, "time": 917.25}
{"epoch": 50, "training_loss": 24.89673137664795, "training_acc": 100.0, "val_loss": 15.681933164596558, "val_acc": 50.0, "val_auroc": 0.58, "time": 934.66}
{"epoch": 51, "training_loss": 27.083280086517334, "training_acc": 97.5, "val_loss": 16.004326343536377, "val_acc": 50.0, "val_auroc": 0.68, "time": 951.78}
{"epoch": 52, "training_loss": 28.07046604156494, "training_acc": 93.75, "val_loss": 15.301162004470825, "val_acc": 45.0, "val_auroc": 0.58, "time": 969.99}
{"epoch": 53, "training_loss": 26.691534996032715, "training_acc": 98.75, "val_loss": 14.17000412940979, "val_acc": 55.0, "val_auroc": 0.72, "time": 988.97}
{"epoch": 54, "training_loss": 23.72977876663208, "training_acc": 100.0, "val_loss": 13.733962774276733, "val_acc": 65.0, "val_auroc": 0.63, "time": 1006.25}
{"epoch": 55, "training_loss": 22.02451992034912, "training_acc": 100.0, "val_loss": 13.619444370269775, "val_acc": 60.0, "val_auroc": 0.64, "time": 1023.49}
{"epoch": 56, "training_loss": 19.84718418121338, "training_acc": 100.0, "val_loss": 13.473007678985596, "val_acc": 60.0, "val_auroc": 0.69, "time": 1040.43}
{"epoch": 57, "training_loss": 20.519591331481934, "training_acc": 100.0, "val_loss": 13.251117467880249, "val_acc": 65.0, "val_auroc": 0.67, "time": 1058.46}
