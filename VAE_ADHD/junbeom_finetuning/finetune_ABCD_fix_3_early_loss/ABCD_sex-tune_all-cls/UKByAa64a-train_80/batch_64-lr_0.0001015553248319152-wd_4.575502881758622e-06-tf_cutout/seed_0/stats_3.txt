"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.62937355041504, "training_acc": 42.5, "val_loss": 13.832763433456421, "val_acc": 55.0, "val_auroc": 0.566, "time": 18.6}
{"epoch": 1, "training_loss": 55.60164451599121, "training_acc": 50.0, "val_loss": 13.833504915237427, "val_acc": 55.0, "val_auroc": 0.556, "time": 36.18}
{"epoch": 2, "training_loss": 55.3531379699707, "training_acc": 51.25, "val_loss": 13.796541690826416, "val_acc": 55.0, "val_auroc": 0.576, "time": 55.0}
{"epoch": 3, "training_loss": 55.25979232788086, "training_acc": 51.25, "val_loss": 13.840688467025757, "val_acc": 55.0, "val_auroc": 0.444, "time": 70.29}
{"epoch": 4, "training_loss": 55.33591651916504, "training_acc": 53.75, "val_loss": 13.790807723999023, "val_acc": 55.0, "val_auroc": 0.465, "time": 86.5}
{"epoch": 5, "training_loss": 55.23388957977295, "training_acc": 51.25, "val_loss": 13.800619840621948, "val_acc": 55.0, "val_auroc": 0.313, "time": 102.02}
{"epoch": 6, "training_loss": 55.35775566101074, "training_acc": 51.25, "val_loss": 13.797686100006104, "val_acc": 55.0, "val_auroc": 0.404, "time": 117.45}
{"epoch": 7, "training_loss": 55.16915512084961, "training_acc": 51.25, "val_loss": 13.868101835250854, "val_acc": 55.0, "val_auroc": 0.364, "time": 132.88}
{"epoch": 8, "training_loss": 55.180800437927246, "training_acc": 56.25, "val_loss": 13.960145711898804, "val_acc": 55.0, "val_auroc": 0.343, "time": 148.08}
{"epoch": 9, "training_loss": 55.14470195770264, "training_acc": 48.75, "val_loss": 13.994265794754028, "val_acc": 55.0, "val_auroc": 0.495, "time": 164.31}
{"epoch": 10, "training_loss": 54.988304138183594, "training_acc": 48.75, "val_loss": 13.79973292350769, "val_acc": 55.0, "val_auroc": 0.566, "time": 179.98}
{"epoch": 11, "training_loss": 54.853477478027344, "training_acc": 51.25, "val_loss": 13.783831596374512, "val_acc": 55.0, "val_auroc": 0.475, "time": 195.86}
{"epoch": 12, "training_loss": 55.56930732727051, "training_acc": 51.25, "val_loss": 13.790262937545776, "val_acc": 55.0, "val_auroc": 0.444, "time": 212.21}
{"epoch": 13, "training_loss": 55.10125255584717, "training_acc": 51.25, "val_loss": 13.835657835006714, "val_acc": 55.0, "val_auroc": 0.434, "time": 228.68}
{"epoch": 14, "training_loss": 54.996676445007324, "training_acc": 53.75, "val_loss": 13.902932405471802, "val_acc": 55.0, "val_auroc": 0.444, "time": 248.37}
{"epoch": 15, "training_loss": 55.19729232788086, "training_acc": 60.0, "val_loss": 13.836227655410767, "val_acc": 55.0, "val_auroc": 0.444, "time": 264.25}
{"epoch": 16, "training_loss": 54.70169258117676, "training_acc": 51.25, "val_loss": 13.794424533843994, "val_acc": 55.0, "val_auroc": 0.505, "time": 279.48}
{"epoch": 17, "training_loss": 55.49728584289551, "training_acc": 51.25, "val_loss": 13.789318799972534, "val_acc": 55.0, "val_auroc": 0.495, "time": 295.19}
{"epoch": 18, "training_loss": 54.85275363922119, "training_acc": 51.25, "val_loss": 13.873457908630371, "val_acc": 55.0, "val_auroc": 0.414, "time": 310.7}
{"epoch": 19, "training_loss": 54.83557987213135, "training_acc": 72.5, "val_loss": 14.037208557128906, "val_acc": 55.0, "val_auroc": 0.475, "time": 325.78}
{"epoch": 20, "training_loss": 55.37040710449219, "training_acc": 48.75, "val_loss": 14.026353359222412, "val_acc": 55.0, "val_auroc": 0.505, "time": 341.33}
{"epoch": 21, "training_loss": 54.959415435791016, "training_acc": 48.75, "val_loss": 13.837603330612183, "val_acc": 55.0, "val_auroc": 0.495, "time": 357.38}
{"epoch": 22, "training_loss": 54.829840660095215, "training_acc": 58.75, "val_loss": 13.793147802352905, "val_acc": 55.0, "val_auroc": 0.465, "time": 372.95}
{"epoch": 23, "training_loss": 54.7195987701416, "training_acc": 51.25, "val_loss": 13.814301490783691, "val_acc": 55.0, "val_auroc": 0.475, "time": 388.09}
{"epoch": 24, "training_loss": 54.43379020690918, "training_acc": 53.75, "val_loss": 13.825472593307495, "val_acc": 55.0, "val_auroc": 0.485, "time": 404.41}
{"epoch": 25, "training_loss": 53.83806037902832, "training_acc": 53.75, "val_loss": 13.845077753067017, "val_acc": 55.0, "val_auroc": 0.495, "time": 421.65}
{"epoch": 26, "training_loss": 54.47254180908203, "training_acc": 51.25, "val_loss": 13.83836030960083, "val_acc": 55.0, "val_auroc": 0.525, "time": 438.93}
{"epoch": 27, "training_loss": 53.123329162597656, "training_acc": 57.5, "val_loss": 13.831653594970703, "val_acc": 55.0, "val_auroc": 0.515, "time": 456.38}
{"epoch": 28, "training_loss": 53.261457443237305, "training_acc": 58.75, "val_loss": 13.94601821899414, "val_acc": 55.0, "val_auroc": 0.495, "time": 472.48}
{"epoch": 29, "training_loss": 53.0692253112793, "training_acc": 68.75, "val_loss": 13.9584481716156, "val_acc": 55.0, "val_auroc": 0.525, "time": 488.18}
{"epoch": 30, "training_loss": 52.552743911743164, "training_acc": 67.5, "val_loss": 13.848124742507935, "val_acc": 55.0, "val_auroc": 0.505, "time": 503.73}
