"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.3797082901001, "training_acc": 52.5, "val_loss": 13.933433294296265, "val_acc": 50.0, "val_auroc": 0.74, "time": 19.34}
{"epoch": 1, "training_loss": 55.47358322143555, "training_acc": 52.5, "val_loss": 13.928982019424438, "val_acc": 50.0, "val_auroc": 0.72, "time": 37.38}
{"epoch": 2, "training_loss": 55.337175369262695, "training_acc": 52.5, "val_loss": 13.972591161727905, "val_acc": 50.0, "val_auroc": 0.4, "time": 55.45}
{"epoch": 3, "training_loss": 55.23277473449707, "training_acc": 52.5, "val_loss": 14.017881155014038, "val_acc": 50.0, "val_auroc": 0.32, "time": 78.58}
{"epoch": 4, "training_loss": 55.150442123413086, "training_acc": 52.5, "val_loss": 13.989061117172241, "val_acc": 50.0, "val_auroc": 0.32, "time": 97.22}
{"epoch": 5, "training_loss": 54.88878154754639, "training_acc": 52.5, "val_loss": 13.988077640533447, "val_acc": 50.0, "val_auroc": 0.37, "time": 117.29}
{"epoch": 6, "training_loss": 55.041781425476074, "training_acc": 52.5, "val_loss": 13.982316255569458, "val_acc": 50.0, "val_auroc": 0.36, "time": 135.01}
{"epoch": 7, "training_loss": 54.70178985595703, "training_acc": 52.5, "val_loss": 14.02025818824768, "val_acc": 50.0, "val_auroc": 0.29, "time": 155.94}
{"epoch": 8, "training_loss": 54.67573261260986, "training_acc": 52.5, "val_loss": 14.028469324111938, "val_acc": 50.0, "val_auroc": 0.3, "time": 173.75}
{"epoch": 9, "training_loss": 54.68559265136719, "training_acc": 52.5, "val_loss": 14.034472703933716, "val_acc": 50.0, "val_auroc": 0.29, "time": 191.03}
{"epoch": 10, "training_loss": 54.38225841522217, "training_acc": 52.5, "val_loss": 14.03477430343628, "val_acc": 50.0, "val_auroc": 0.3, "time": 208.06}
{"epoch": 11, "training_loss": 54.08710193634033, "training_acc": 52.5, "val_loss": 13.999806642532349, "val_acc": 50.0, "val_auroc": 0.36, "time": 227.08}
{"epoch": 12, "training_loss": 53.97231864929199, "training_acc": 52.5, "val_loss": 14.00452971458435, "val_acc": 50.0, "val_auroc": 0.36, "time": 246.18}
{"epoch": 13, "training_loss": 53.93333625793457, "training_acc": 52.5, "val_loss": 14.079419374465942, "val_acc": 50.0, "val_auroc": 0.3, "time": 266.05}
{"epoch": 14, "training_loss": 53.6720666885376, "training_acc": 53.75, "val_loss": 14.04020071029663, "val_acc": 50.0, "val_auroc": 0.32, "time": 284.11}
{"epoch": 15, "training_loss": 53.59321117401123, "training_acc": 55.0, "val_loss": 13.983349800109863, "val_acc": 50.0, "val_auroc": 0.37, "time": 302.31}
{"epoch": 16, "training_loss": 53.43296241760254, "training_acc": 53.75, "val_loss": 13.907294273376465, "val_acc": 50.0, "val_auroc": 0.49, "time": 319.67}
{"epoch": 17, "training_loss": 53.3349609375, "training_acc": 53.75, "val_loss": 14.229525327682495, "val_acc": 50.0, "val_auroc": 0.28, "time": 337.1}
{"epoch": 18, "training_loss": 53.38396167755127, "training_acc": 61.25, "val_loss": 13.927040100097656, "val_acc": 50.0, "val_auroc": 0.48, "time": 356.54}
{"epoch": 19, "training_loss": 52.927473068237305, "training_acc": 53.75, "val_loss": 14.03775691986084, "val_acc": 50.0, "val_auroc": 0.3, "time": 374.72}
{"epoch": 20, "training_loss": 52.33641242980957, "training_acc": 67.5, "val_loss": 14.14169192314148, "val_acc": 50.0, "val_auroc": 0.29, "time": 392.25}
{"epoch": 21, "training_loss": 52.124905586242676, "training_acc": 68.75, "val_loss": 13.812966346740723, "val_acc": 50.0, "val_auroc": 0.6, "time": 411.34}
{"epoch": 22, "training_loss": 53.01375675201416, "training_acc": 53.75, "val_loss": 14.287235736846924, "val_acc": 50.0, "val_auroc": 0.28, "time": 430.39}
{"epoch": 23, "training_loss": 53.19410991668701, "training_acc": 72.5, "val_loss": 14.004133939743042, "val_acc": 50.0, "val_auroc": 0.34, "time": 449.69}
{"epoch": 24, "training_loss": 52.21037673950195, "training_acc": 63.75, "val_loss": 13.75267744064331, "val_acc": 50.0, "val_auroc": 0.64, "time": 467.74}
{"epoch": 25, "training_loss": 53.33859443664551, "training_acc": 53.75, "val_loss": 14.129136800765991, "val_acc": 50.0, "val_auroc": 0.32, "time": 485.64}
{"epoch": 26, "training_loss": 52.41403007507324, "training_acc": 71.25, "val_loss": 14.17049765586853, "val_acc": 50.0, "val_auroc": 0.34, "time": 503.49}
{"epoch": 27, "training_loss": 53.22529315948486, "training_acc": 72.5, "val_loss": 13.984962701797485, "val_acc": 50.0, "val_auroc": 0.31, "time": 521.81}
{"epoch": 28, "training_loss": 51.92856979370117, "training_acc": 61.25, "val_loss": 13.88378381729126, "val_acc": 50.0, "val_auroc": 0.61, "time": 538.73}
{"epoch": 29, "training_loss": 53.27136421203613, "training_acc": 52.5, "val_loss": 13.913496732711792, "val_acc": 50.0, "val_auroc": 0.48, "time": 558.79}
{"epoch": 30, "training_loss": 52.07790565490723, "training_acc": 61.25, "val_loss": 14.2699134349823, "val_acc": 50.0, "val_auroc": 0.28, "time": 578.15}
{"epoch": 31, "training_loss": 51.795809745788574, "training_acc": 77.5, "val_loss": 14.271565675735474, "val_acc": 50.0, "val_auroc": 0.33, "time": 596.3}
{"epoch": 32, "training_loss": 51.01409149169922, "training_acc": 78.75, "val_loss": 14.006284475326538, "val_acc": 50.0, "val_auroc": 0.33, "time": 613.53}
{"epoch": 33, "training_loss": 51.20200824737549, "training_acc": 63.75, "val_loss": 13.967622518539429, "val_acc": 50.0, "val_auroc": 0.34, "time": 631.44}
{"epoch": 34, "training_loss": 50.905653953552246, "training_acc": 67.5, "val_loss": 14.061278104782104, "val_acc": 50.0, "val_auroc": 0.32, "time": 649.29}
{"epoch": 35, "training_loss": 50.31507587432861, "training_acc": 73.75, "val_loss": 14.117904901504517, "val_acc": 50.0, "val_auroc": 0.34, "time": 666.9}
{"epoch": 36, "training_loss": 49.36369705200195, "training_acc": 78.75, "val_loss": 13.881224393844604, "val_acc": 50.0, "val_auroc": 0.46, "time": 684.83}
{"epoch": 37, "training_loss": 50.071146965026855, "training_acc": 72.5, "val_loss": 13.901143074035645, "val_acc": 50.0, "val_auroc": 0.39, "time": 705.37}
{"epoch": 38, "training_loss": 49.09261989593506, "training_acc": 77.5, "val_loss": 14.040529727935791, "val_acc": 50.0, "val_auroc": 0.34, "time": 724.22}
{"epoch": 39, "training_loss": 48.774033546447754, "training_acc": 78.75, "val_loss": 14.037173986434937, "val_acc": 50.0, "val_auroc": 0.35, "time": 743.31}
{"epoch": 40, "training_loss": 48.82644462585449, "training_acc": 75.0, "val_loss": 14.049229621887207, "val_acc": 50.0, "val_auroc": 0.37, "time": 761.7}
{"epoch": 41, "training_loss": 47.71665000915527, "training_acc": 81.25, "val_loss": 14.202851057052612, "val_acc": 50.0, "val_auroc": 0.33, "time": 779.2}
{"epoch": 42, "training_loss": 48.14839458465576, "training_acc": 83.75, "val_loss": 13.867466449737549, "val_acc": 50.0, "val_auroc": 0.46, "time": 797.55}
{"epoch": 43, "training_loss": 48.57216739654541, "training_acc": 71.25, "val_loss": 14.21487808227539, "val_acc": 50.0, "val_auroc": 0.32, "time": 814.7}
