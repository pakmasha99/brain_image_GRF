"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 68.51382827758789, "training_acc": 53.75, "val_loss": 398.7821578979492, "val_acc": 50.0, "val_auroc": 0.86, "time": 16.67}
{"epoch": 1, "training_loss": 8729.475708007812, "training_acc": 52.5, "val_loss": 15.958274602890015, "val_acc": 50.0, "val_auroc": 0.5, "time": 31.91}
{"epoch": 2, "training_loss": 69.23492813110352, "training_acc": 50.0, "val_loss": 14.18025255203247, "val_acc": 50.0, "val_auroc": 0.61, "time": 46.69}
{"epoch": 3, "training_loss": 70.74895858764648, "training_acc": 47.5, "val_loss": 15.882680416107178, "val_acc": 50.0, "val_auroc": 0.54, "time": 61.23}
{"epoch": 4, "training_loss": 64.85858249664307, "training_acc": 47.5, "val_loss": 14.17277216911316, "val_acc": 50.0, "val_auroc": 0.49, "time": 76.59}
{"epoch": 5, "training_loss": 56.309157371520996, "training_acc": 52.5, "val_loss": 13.859689235687256, "val_acc": 50.0, "val_auroc": 0.58, "time": 92.4}
{"epoch": 6, "training_loss": 55.77972984313965, "training_acc": 47.5, "val_loss": 14.440668821334839, "val_acc": 50.0, "val_auroc": 0.56, "time": 108.07}
{"epoch": 7, "training_loss": 57.29635429382324, "training_acc": 50.0, "val_loss": 15.705033540725708, "val_acc": 50.0, "val_auroc": 0.49, "time": 123.64}
{"epoch": 8, "training_loss": 59.49291133880615, "training_acc": 52.5, "val_loss": 14.75196123123169, "val_acc": 50.0, "val_auroc": 0.55, "time": 139.75}
{"epoch": 9, "training_loss": 60.56981182098389, "training_acc": 45.0, "val_loss": 14.024966955184937, "val_acc": 50.0, "val_auroc": 0.59, "time": 155.21}
{"epoch": 10, "training_loss": 55.75887489318848, "training_acc": 50.0, "val_loss": 13.851919174194336, "val_acc": 50.0, "val_auroc": 0.67, "time": 170.23}
{"epoch": 11, "training_loss": 55.3305082321167, "training_acc": 52.5, "val_loss": 14.066178798675537, "val_acc": 50.0, "val_auroc": 0.77, "time": 185.53}
{"epoch": 12, "training_loss": 55.71616172790527, "training_acc": 52.5, "val_loss": 13.928927183151245, "val_acc": 50.0, "val_auroc": 0.64, "time": 200.85}
{"epoch": 13, "training_loss": 55.85821723937988, "training_acc": 47.5, "val_loss": 14.091147184371948, "val_acc": 50.0, "val_auroc": 0.77, "time": 215.85}
{"epoch": 14, "training_loss": 55.76589107513428, "training_acc": 52.5, "val_loss": 14.635064601898193, "val_acc": 50.0, "val_auroc": 0.61, "time": 230.92}
{"epoch": 15, "training_loss": 57.410438537597656, "training_acc": 52.5, "val_loss": 14.152151346206665, "val_acc": 50.0, "val_auroc": 0.76, "time": 248.11}
{"epoch": 16, "training_loss": 56.165578842163086, "training_acc": 52.5, "val_loss": 13.877108097076416, "val_acc": 50.0, "val_auroc": 0.78, "time": 263.18}
{"epoch": 17, "training_loss": 55.36405372619629, "training_acc": 52.5, "val_loss": 13.85571837425232, "val_acc": 50.0, "val_auroc": 0.64, "time": 277.89}
{"epoch": 18, "training_loss": 55.40157508850098, "training_acc": 52.5, "val_loss": 13.86661410331726, "val_acc": 50.0, "val_auroc": 0.64, "time": 293.53}
{"epoch": 19, "training_loss": 55.747944831848145, "training_acc": 42.5, "val_loss": 13.868783712387085, "val_acc": 50.0, "val_auroc": 0.64, "time": 308.21}
{"epoch": 20, "training_loss": 55.62392044067383, "training_acc": 47.5, "val_loss": 13.86972427368164, "val_acc": 50.0, "val_auroc": 0.66, "time": 322.6}
{"epoch": 21, "training_loss": 55.5650634765625, "training_acc": 47.5, "val_loss": 13.898547887802124, "val_acc": 50.0, "val_auroc": 0.77, "time": 337.7}
{"epoch": 22, "training_loss": 55.328861236572266, "training_acc": 52.5, "val_loss": 14.156893491744995, "val_acc": 50.0, "val_auroc": 0.55, "time": 353.08}
{"epoch": 23, "training_loss": 55.976335525512695, "training_acc": 52.5, "val_loss": 14.10274624824524, "val_acc": 50.0, "val_auroc": 0.57, "time": 369.24}
{"epoch": 24, "training_loss": 55.771291732788086, "training_acc": 52.5, "val_loss": 13.948372602462769, "val_acc": 50.0, "val_auroc": 0.54, "time": 385.17}
{"epoch": 25, "training_loss": 55.46652126312256, "training_acc": 52.5, "val_loss": 13.877118825912476, "val_acc": 50.0, "val_auroc": 0.6, "time": 400.41}
{"epoch": 26, "training_loss": 55.36597442626953, "training_acc": 52.5, "val_loss": 13.884948492050171, "val_acc": 50.0, "val_auroc": 0.66, "time": 415.19}
{"epoch": 27, "training_loss": 55.33255481719971, "training_acc": 52.5, "val_loss": 13.93635869026184, "val_acc": 50.0, "val_auroc": 0.63, "time": 429.94}
{"epoch": 28, "training_loss": 55.72521781921387, "training_acc": 52.5, "val_loss": 13.892160654067993, "val_acc": 50.0, "val_auroc": 0.77, "time": 446.23}
{"epoch": 29, "training_loss": 55.42680835723877, "training_acc": 53.75, "val_loss": 13.861469030380249, "val_acc": 50.0, "val_auroc": 0.62, "time": 463.43}
