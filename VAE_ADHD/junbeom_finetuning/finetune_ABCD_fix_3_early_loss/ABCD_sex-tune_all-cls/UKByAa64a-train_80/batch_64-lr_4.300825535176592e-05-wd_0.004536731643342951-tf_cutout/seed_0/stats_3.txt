"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.633256912231445, "training_acc": 51.25, "val_loss": 13.767547607421875, "val_acc": 55.0, "val_auroc": 0.515, "time": 19.36}
{"epoch": 1, "training_loss": 55.573241233825684, "training_acc": 51.25, "val_loss": 13.806785345077515, "val_acc": 55.0, "val_auroc": 0.424, "time": 37.44}
{"epoch": 2, "training_loss": 55.43360137939453, "training_acc": 51.25, "val_loss": 13.77779483795166, "val_acc": 55.0, "val_auroc": 0.465, "time": 55.31}
{"epoch": 3, "training_loss": 55.458839416503906, "training_acc": 51.25, "val_loss": 13.804092407226562, "val_acc": 55.0, "val_auroc": 0.394, "time": 73.17}
{"epoch": 4, "training_loss": 55.446144104003906, "training_acc": 51.25, "val_loss": 13.80186915397644, "val_acc": 55.0, "val_auroc": 0.404, "time": 90.88}
{"epoch": 5, "training_loss": 55.30380439758301, "training_acc": 51.25, "val_loss": 13.792750835418701, "val_acc": 55.0, "val_auroc": 0.424, "time": 109.78}
{"epoch": 6, "training_loss": 55.24868679046631, "training_acc": 51.25, "val_loss": 13.780897855758667, "val_acc": 55.0, "val_auroc": 0.576, "time": 127.18}
{"epoch": 7, "training_loss": 55.13890266418457, "training_acc": 51.25, "val_loss": 13.7936532497406, "val_acc": 55.0, "val_auroc": 0.606, "time": 145.9}
{"epoch": 8, "training_loss": 55.016265869140625, "training_acc": 51.25, "val_loss": 13.839752674102783, "val_acc": 55.0, "val_auroc": 0.606, "time": 162.35}
{"epoch": 9, "training_loss": 54.937684059143066, "training_acc": 75.0, "val_loss": 13.895890712738037, "val_acc": 55.0, "val_auroc": 0.636, "time": 179.34}
{"epoch": 10, "training_loss": 54.96121311187744, "training_acc": 52.5, "val_loss": 13.839845657348633, "val_acc": 55.0, "val_auroc": 0.636, "time": 196.24}
{"epoch": 11, "training_loss": 54.52665615081787, "training_acc": 78.75, "val_loss": 13.76049518585205, "val_acc": 55.0, "val_auroc": 0.616, "time": 214.2}
{"epoch": 12, "training_loss": 55.0245943069458, "training_acc": 51.25, "val_loss": 13.737901449203491, "val_acc": 55.0, "val_auroc": 0.697, "time": 230.84}
{"epoch": 13, "training_loss": 55.028221130371094, "training_acc": 51.25, "val_loss": 13.72918963432312, "val_acc": 55.0, "val_auroc": 0.667, "time": 250.59}
{"epoch": 14, "training_loss": 54.746585845947266, "training_acc": 51.25, "val_loss": 13.817421197891235, "val_acc": 55.0, "val_auroc": 0.596, "time": 267.8}
{"epoch": 15, "training_loss": 54.74785804748535, "training_acc": 65.0, "val_loss": 13.863978385925293, "val_acc": 55.0, "val_auroc": 0.535, "time": 285.61}
{"epoch": 16, "training_loss": 54.2648868560791, "training_acc": 80.0, "val_loss": 13.785293102264404, "val_acc": 55.0, "val_auroc": 0.566, "time": 302.29}
{"epoch": 17, "training_loss": 54.32890605926514, "training_acc": 51.25, "val_loss": 13.798612356185913, "val_acc": 55.0, "val_auroc": 0.535, "time": 319.17}
{"epoch": 18, "training_loss": 54.432509422302246, "training_acc": 51.25, "val_loss": 13.776921033859253, "val_acc": 55.0, "val_auroc": 0.556, "time": 336.71}
{"epoch": 19, "training_loss": 53.68674278259277, "training_acc": 58.75, "val_loss": 13.914690017700195, "val_acc": 55.0, "val_auroc": 0.576, "time": 353.86}
{"epoch": 20, "training_loss": 54.09959030151367, "training_acc": 68.75, "val_loss": 13.956959247589111, "val_acc": 55.0, "val_auroc": 0.556, "time": 370.54}
{"epoch": 21, "training_loss": 53.90444564819336, "training_acc": 63.75, "val_loss": 13.846467733383179, "val_acc": 55.0, "val_auroc": 0.515, "time": 388.26}
{"epoch": 22, "training_loss": 53.796932220458984, "training_acc": 66.25, "val_loss": 13.796026706695557, "val_acc": 55.0, "val_auroc": 0.576, "time": 405.73}
{"epoch": 23, "training_loss": 53.28007888793945, "training_acc": 62.5, "val_loss": 13.814618587493896, "val_acc": 55.0, "val_auroc": 0.606, "time": 422.95}
{"epoch": 24, "training_loss": 52.64070796966553, "training_acc": 76.25, "val_loss": 13.814815282821655, "val_acc": 55.0, "val_auroc": 0.586, "time": 439.47}
{"epoch": 25, "training_loss": 52.31867790222168, "training_acc": 65.0, "val_loss": 13.828953504562378, "val_acc": 55.0, "val_auroc": 0.596, "time": 456.2}
{"epoch": 26, "training_loss": 52.220826148986816, "training_acc": 62.5, "val_loss": 13.790652751922607, "val_acc": 55.0, "val_auroc": 0.606, "time": 473.7}
{"epoch": 27, "training_loss": 50.497453689575195, "training_acc": 75.0, "val_loss": 13.809248208999634, "val_acc": 55.0, "val_auroc": 0.596, "time": 491.36}
{"epoch": 28, "training_loss": 50.49819564819336, "training_acc": 68.75, "val_loss": 13.883284330368042, "val_acc": 55.0, "val_auroc": 0.566, "time": 508.26}
{"epoch": 29, "training_loss": 51.89801216125488, "training_acc": 77.5, "val_loss": 13.883966207504272, "val_acc": 55.0, "val_auroc": 0.586, "time": 526.55}
{"epoch": 30, "training_loss": 49.86649703979492, "training_acc": 86.25, "val_loss": 13.89270305633545, "val_acc": 55.0, "val_auroc": 0.616, "time": 544.69}
{"epoch": 31, "training_loss": 49.47274303436279, "training_acc": 72.5, "val_loss": 13.905452489852905, "val_acc": 55.0, "val_auroc": 0.616, "time": 561.22}
{"epoch": 32, "training_loss": 49.693631172180176, "training_acc": 76.25, "val_loss": 13.811261653900146, "val_acc": 55.0, "val_auroc": 0.606, "time": 578.12}
