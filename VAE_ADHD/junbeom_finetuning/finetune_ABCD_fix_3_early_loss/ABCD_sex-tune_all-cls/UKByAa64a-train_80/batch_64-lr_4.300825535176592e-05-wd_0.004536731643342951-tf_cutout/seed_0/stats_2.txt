"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.459699630737305, "training_acc": 52.5, "val_loss": 13.921644687652588, "val_acc": 50.0, "val_auroc": 0.51, "time": 19.76}
{"epoch": 1, "training_loss": 55.48398208618164, "training_acc": 52.5, "val_loss": 13.963934183120728, "val_acc": 50.0, "val_auroc": 0.37, "time": 37.51}
{"epoch": 2, "training_loss": 55.252784729003906, "training_acc": 52.5, "val_loss": 13.90184760093689, "val_acc": 50.0, "val_auroc": 0.44, "time": 59.94}
{"epoch": 3, "training_loss": 55.28090953826904, "training_acc": 52.5, "val_loss": 13.958702087402344, "val_acc": 50.0, "val_auroc": 0.34, "time": 81.86}
{"epoch": 4, "training_loss": 55.28447723388672, "training_acc": 52.5, "val_loss": 14.00952696800232, "val_acc": 50.0, "val_auroc": 0.23, "time": 100.28}
{"epoch": 5, "training_loss": 55.11782646179199, "training_acc": 52.5, "val_loss": 13.992383480072021, "val_acc": 50.0, "val_auroc": 0.26, "time": 118.58}
{"epoch": 6, "training_loss": 55.15130805969238, "training_acc": 52.5, "val_loss": 13.993656635284424, "val_acc": 50.0, "val_auroc": 0.37, "time": 139.22}
{"epoch": 7, "training_loss": 54.94285011291504, "training_acc": 52.5, "val_loss": 14.070123434066772, "val_acc": 50.0, "val_auroc": 0.34, "time": 159.91}
{"epoch": 8, "training_loss": 55.060302734375, "training_acc": 52.5, "val_loss": 14.098906517028809, "val_acc": 50.0, "val_auroc": 0.33, "time": 176.86}
{"epoch": 9, "training_loss": 54.98950958251953, "training_acc": 52.5, "val_loss": 13.933143615722656, "val_acc": 50.0, "val_auroc": 0.37, "time": 193.94}
{"epoch": 10, "training_loss": 54.89032745361328, "training_acc": 53.75, "val_loss": 13.876618146896362, "val_acc": 50.0, "val_auroc": 0.36, "time": 213.09}
{"epoch": 11, "training_loss": 54.911895751953125, "training_acc": 55.0, "val_loss": 14.005895853042603, "val_acc": 50.0, "val_auroc": 0.28, "time": 233.4}
{"epoch": 12, "training_loss": 54.845181465148926, "training_acc": 52.5, "val_loss": 14.011949300765991, "val_acc": 50.0, "val_auroc": 0.31, "time": 252.65}
{"epoch": 13, "training_loss": 54.85397911071777, "training_acc": 52.5, "val_loss": 13.941187858581543, "val_acc": 50.0, "val_auroc": 0.5, "time": 270.39}
{"epoch": 14, "training_loss": 54.67571544647217, "training_acc": 52.5, "val_loss": 14.044631719589233, "val_acc": 50.0, "val_auroc": 0.29, "time": 288.66}
{"epoch": 15, "training_loss": 54.53829002380371, "training_acc": 52.5, "val_loss": 14.025534391403198, "val_acc": 50.0, "val_auroc": 0.32, "time": 309.09}
{"epoch": 16, "training_loss": 54.51627731323242, "training_acc": 52.5, "val_loss": 14.070050716400146, "val_acc": 50.0, "val_auroc": 0.35, "time": 325.78}
{"epoch": 17, "training_loss": 54.5600700378418, "training_acc": 52.5, "val_loss": 14.071851968765259, "val_acc": 50.0, "val_auroc": 0.38, "time": 342.51}
{"epoch": 18, "training_loss": 54.16356658935547, "training_acc": 52.5, "val_loss": 14.051408767700195, "val_acc": 50.0, "val_auroc": 0.3, "time": 360.86}
{"epoch": 19, "training_loss": 54.13337421417236, "training_acc": 53.75, "val_loss": 14.003946781158447, "val_acc": 50.0, "val_auroc": 0.33, "time": 378.58}
{"epoch": 20, "training_loss": 53.78498077392578, "training_acc": 75.0, "val_loss": 13.928824663162231, "val_acc": 50.0, "val_auroc": 0.42, "time": 395.89}
{"epoch": 21, "training_loss": 53.78087520599365, "training_acc": 57.5, "val_loss": 13.911536931991577, "val_acc": 50.0, "val_auroc": 0.48, "time": 413.0}
{"epoch": 22, "training_loss": 53.76645278930664, "training_acc": 52.5, "val_loss": 13.968991041183472, "val_acc": 50.0, "val_auroc": 0.4, "time": 430.99}
{"epoch": 23, "training_loss": 52.92114067077637, "training_acc": 71.25, "val_loss": 14.007928371429443, "val_acc": 50.0, "val_auroc": 0.44, "time": 448.64}
{"epoch": 24, "training_loss": 52.6330680847168, "training_acc": 60.0, "val_loss": 14.090511798858643, "val_acc": 50.0, "val_auroc": 0.46, "time": 465.28}
{"epoch": 25, "training_loss": 52.93511962890625, "training_acc": 55.0, "val_loss": 14.02159333229065, "val_acc": 50.0, "val_auroc": 0.44, "time": 481.62}
{"epoch": 26, "training_loss": 52.91513538360596, "training_acc": 70.0, "val_loss": 14.134443998336792, "val_acc": 50.0, "val_auroc": 0.45, "time": 498.76}
{"epoch": 27, "training_loss": 52.25575828552246, "training_acc": 52.5, "val_loss": 14.05053973197937, "val_acc": 50.0, "val_auroc": 0.45, "time": 516.35}
{"epoch": 28, "training_loss": 51.59279251098633, "training_acc": 75.0, "val_loss": 13.892149925231934, "val_acc": 50.0, "val_auroc": 0.5, "time": 534.23}
{"epoch": 29, "training_loss": 52.41741752624512, "training_acc": 72.5, "val_loss": 14.064598083496094, "val_acc": 50.0, "val_auroc": 0.48, "time": 551.95}
