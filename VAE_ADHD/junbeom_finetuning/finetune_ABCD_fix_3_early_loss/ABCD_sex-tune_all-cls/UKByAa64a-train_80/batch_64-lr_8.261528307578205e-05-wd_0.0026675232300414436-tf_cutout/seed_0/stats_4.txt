"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.57768535614014, "training_acc": 51.25, "val_loss": 13.802639245986938, "val_acc": 55.0, "val_auroc": 0.515, "time": 16.88}
{"epoch": 1, "training_loss": 55.52179145812988, "training_acc": 51.25, "val_loss": 13.787978887557983, "val_acc": 55.0, "val_auroc": 0.475, "time": 32.49}
{"epoch": 2, "training_loss": 55.534847259521484, "training_acc": 51.25, "val_loss": 13.756427764892578, "val_acc": 55.0, "val_auroc": 0.596, "time": 49.55}
{"epoch": 3, "training_loss": 55.512285232543945, "training_acc": 51.25, "val_loss": 13.830698728561401, "val_acc": 55.0, "val_auroc": 0.586, "time": 64.59}
{"epoch": 4, "training_loss": 55.45098876953125, "training_acc": 48.75, "val_loss": 13.826066255569458, "val_acc": 55.0, "val_auroc": 0.515, "time": 79.87}
{"epoch": 5, "training_loss": 55.36266326904297, "training_acc": 51.25, "val_loss": 13.8107430934906, "val_acc": 55.0, "val_auroc": 0.657, "time": 94.28}
{"epoch": 6, "training_loss": 55.40949058532715, "training_acc": 51.25, "val_loss": 13.787882328033447, "val_acc": 55.0, "val_auroc": 0.596, "time": 109.31}
{"epoch": 7, "training_loss": 55.41305732727051, "training_acc": 51.25, "val_loss": 13.780263662338257, "val_acc": 55.0, "val_auroc": 0.596, "time": 124.74}
{"epoch": 8, "training_loss": 55.407257080078125, "training_acc": 51.25, "val_loss": 13.844335079193115, "val_acc": 55.0, "val_auroc": 0.455, "time": 138.79}
{"epoch": 9, "training_loss": 55.53124523162842, "training_acc": 46.25, "val_loss": 13.884197473526001, "val_acc": 55.0, "val_auroc": 0.414, "time": 153.41}
{"epoch": 10, "training_loss": 55.43789291381836, "training_acc": 50.0, "val_loss": 13.82377028465271, "val_acc": 55.0, "val_auroc": 0.434, "time": 168.84}
{"epoch": 11, "training_loss": 55.350412368774414, "training_acc": 51.25, "val_loss": 13.785192966461182, "val_acc": 55.0, "val_auroc": 0.444, "time": 183.33}
{"epoch": 12, "training_loss": 55.50998878479004, "training_acc": 51.25, "val_loss": 13.77581000328064, "val_acc": 55.0, "val_auroc": 0.455, "time": 197.71}
{"epoch": 13, "training_loss": 55.47598075866699, "training_acc": 51.25, "val_loss": 13.791879415512085, "val_acc": 55.0, "val_auroc": 0.465, "time": 212.75}
{"epoch": 14, "training_loss": 55.405174255371094, "training_acc": 51.25, "val_loss": 13.837342262268066, "val_acc": 55.0, "val_auroc": 0.475, "time": 227.38}
{"epoch": 15, "training_loss": 55.541006088256836, "training_acc": 46.25, "val_loss": 13.884526491165161, "val_acc": 55.0, "val_auroc": 0.545, "time": 241.53}
{"epoch": 16, "training_loss": 55.492835998535156, "training_acc": 48.75, "val_loss": 13.806194067001343, "val_acc": 55.0, "val_auroc": 0.576, "time": 256.6}
{"epoch": 17, "training_loss": 55.44559860229492, "training_acc": 51.25, "val_loss": 13.761417865753174, "val_acc": 55.0, "val_auroc": 0.535, "time": 271.25}
{"epoch": 18, "training_loss": 55.59587287902832, "training_acc": 51.25, "val_loss": 13.761982917785645, "val_acc": 55.0, "val_auroc": 0.556, "time": 285.58}
{"epoch": 19, "training_loss": 55.48694705963135, "training_acc": 51.25, "val_loss": 13.786534070968628, "val_acc": 55.0, "val_auroc": 0.515, "time": 300.92}
{"epoch": 20, "training_loss": 55.409812927246094, "training_acc": 51.25, "val_loss": 13.837158679962158, "val_acc": 55.0, "val_auroc": 0.545, "time": 315.44}
{"epoch": 21, "training_loss": 55.36616897583008, "training_acc": 51.25, "val_loss": 13.863941431045532, "val_acc": 55.0, "val_auroc": 0.535, "time": 329.81}
