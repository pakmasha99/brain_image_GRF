"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 58.307899475097656, "training_acc": 45.0, "val_loss": 13.95065188407898, "val_acc": 50.0, "val_auroc": 0.47, "time": 19.31}
{"epoch": 1, "training_loss": 55.18059539794922, "training_acc": 53.75, "val_loss": 228.48608016967773, "val_acc": 50.0, "val_auroc": 0.38, "time": 37.09}
{"epoch": 2, "training_loss": 683.9577684402466, "training_acc": 52.5, "val_loss": 14.964174032211304, "val_acc": 50.0, "val_auroc": 0.63, "time": 54.87}
{"epoch": 3, "training_loss": 60.18974781036377, "training_acc": 47.5, "val_loss": 13.877115249633789, "val_acc": 50.0, "val_auroc": 0.55, "time": 72.79}
{"epoch": 4, "training_loss": 55.68007850646973, "training_acc": 47.5, "val_loss": 14.691919088363647, "val_acc": 50.0, "val_auroc": 0.53, "time": 90.0}
{"epoch": 5, "training_loss": 58.044790267944336, "training_acc": 50.0, "val_loss": 14.42564845085144, "val_acc": 50.0, "val_auroc": 0.53, "time": 107.31}
{"epoch": 6, "training_loss": 56.57198524475098, "training_acc": 52.5, "val_loss": 14.087221622467041, "val_acc": 50.0, "val_auroc": 0.53, "time": 122.19}
{"epoch": 7, "training_loss": 55.96559715270996, "training_acc": 50.0, "val_loss": 14.644649028778076, "val_acc": 50.0, "val_auroc": 0.58, "time": 138.74}
{"epoch": 8, "training_loss": 57.17328453063965, "training_acc": 52.5, "val_loss": 13.862320184707642, "val_acc": 50.0, "val_auroc": 0.51, "time": 155.71}
{"epoch": 9, "training_loss": 55.51308345794678, "training_acc": 47.5, "val_loss": 14.195317029953003, "val_acc": 50.0, "val_auroc": 0.53, "time": 172.47}
{"epoch": 10, "training_loss": 56.638216972351074, "training_acc": 47.5, "val_loss": 13.971318006515503, "val_acc": 50.0, "val_auroc": 0.61, "time": 188.6}
{"epoch": 11, "training_loss": 55.53971290588379, "training_acc": 52.5, "val_loss": 14.158298969268799, "val_acc": 50.0, "val_auroc": 0.79, "time": 205.85}
{"epoch": 12, "training_loss": 56.00449275970459, "training_acc": 52.5, "val_loss": 13.837685585021973, "val_acc": 50.0, "val_auroc": 0.69, "time": 222.87}
{"epoch": 13, "training_loss": 55.51826477050781, "training_acc": 47.5, "val_loss": 13.8205087184906, "val_acc": 50.0, "val_auroc": 0.65, "time": 240.05}
{"epoch": 14, "training_loss": 55.12363052368164, "training_acc": 52.5, "val_loss": 14.089559316635132, "val_acc": 50.0, "val_auroc": 0.7, "time": 256.97}
{"epoch": 15, "training_loss": 55.841487884521484, "training_acc": 52.5, "val_loss": 14.39473032951355, "val_acc": 50.0, "val_auroc": 0.7, "time": 273.96}
{"epoch": 16, "training_loss": 56.73139953613281, "training_acc": 52.5, "val_loss": 14.23410415649414, "val_acc": 50.0, "val_auroc": 0.65, "time": 290.55}
{"epoch": 17, "training_loss": 56.081953048706055, "training_acc": 52.5, "val_loss": 13.925031423568726, "val_acc": 50.0, "val_auroc": 0.59, "time": 307.37}
{"epoch": 18, "training_loss": 55.29611396789551, "training_acc": 52.5, "val_loss": 13.860256671905518, "val_acc": 50.0, "val_auroc": 0.58, "time": 324.2}
{"epoch": 19, "training_loss": 55.52529335021973, "training_acc": 47.5, "val_loss": 13.963378667831421, "val_acc": 50.0, "val_auroc": 0.58, "time": 340.86}
{"epoch": 20, "training_loss": 56.264559745788574, "training_acc": 47.5, "val_loss": 13.95723819732666, "val_acc": 50.0, "val_auroc": 0.58, "time": 357.38}
{"epoch": 21, "training_loss": 56.06080341339111, "training_acc": 47.5, "val_loss": 13.846300840377808, "val_acc": 50.0, "val_auroc": 0.63, "time": 374.48}
{"epoch": 22, "training_loss": 55.34152030944824, "training_acc": 50.0, "val_loss": 13.94473671913147, "val_acc": 50.0, "val_auroc": 0.69, "time": 392.22}
{"epoch": 23, "training_loss": 55.35689353942871, "training_acc": 52.5, "val_loss": 14.114327430725098, "val_acc": 50.0, "val_auroc": 0.7, "time": 409.0}
{"epoch": 24, "training_loss": 55.81777763366699, "training_acc": 52.5, "val_loss": 14.166202545166016, "val_acc": 50.0, "val_auroc": 0.68, "time": 425.59}
{"epoch": 25, "training_loss": 55.95637130737305, "training_acc": 52.5, "val_loss": 14.036463499069214, "val_acc": 50.0, "val_auroc": 0.66, "time": 442.62}
{"epoch": 26, "training_loss": 55.639892578125, "training_acc": 52.5, "val_loss": 13.906841278076172, "val_acc": 50.0, "val_auroc": 0.61, "time": 459.47}
{"epoch": 27, "training_loss": 55.37781620025635, "training_acc": 52.5, "val_loss": 13.854299783706665, "val_acc": 50.0, "val_auroc": 0.64, "time": 476.17}
{"epoch": 28, "training_loss": 55.439504623413086, "training_acc": 52.5, "val_loss": 13.844438791275024, "val_acc": 50.0, "val_auroc": 0.63, "time": 493.13}
{"epoch": 29, "training_loss": 55.51314353942871, "training_acc": 53.75, "val_loss": 13.868883848190308, "val_acc": 50.0, "val_auroc": 0.61, "time": 509.88}
{"epoch": 30, "training_loss": 55.63079261779785, "training_acc": 47.5, "val_loss": 13.843706846237183, "val_acc": 50.0, "val_auroc": 0.62, "time": 526.6}
{"epoch": 31, "training_loss": 55.30384063720703, "training_acc": 50.0, "val_loss": 13.902144432067871, "val_acc": 50.0, "val_auroc": 0.6, "time": 543.34}
{"epoch": 32, "training_loss": 55.51159858703613, "training_acc": 52.5, "val_loss": 13.945655822753906, "val_acc": 50.0, "val_auroc": 0.62, "time": 559.86}
