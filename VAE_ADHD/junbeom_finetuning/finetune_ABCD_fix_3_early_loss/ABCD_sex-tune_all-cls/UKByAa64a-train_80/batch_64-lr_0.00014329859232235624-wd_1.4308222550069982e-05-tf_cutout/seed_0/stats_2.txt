"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5650634765625, "training_acc": 52.5, "val_loss": 13.859609365463257, "val_acc": 50.0, "val_auroc": 0.72, "time": 17.57}
{"epoch": 1, "training_loss": 55.37948417663574, "training_acc": 52.5, "val_loss": 13.976055383682251, "val_acc": 50.0, "val_auroc": 0.56, "time": 32.63}
{"epoch": 2, "training_loss": 55.65480995178223, "training_acc": 52.5, "val_loss": 13.940274715423584, "val_acc": 50.0, "val_auroc": 0.21, "time": 47.9}
{"epoch": 3, "training_loss": 55.47129249572754, "training_acc": 52.5, "val_loss": 13.980246782302856, "val_acc": 50.0, "val_auroc": 0.29, "time": 62.74}
{"epoch": 4, "training_loss": 55.46635055541992, "training_acc": 52.5, "val_loss": 13.94924521446228, "val_acc": 50.0, "val_auroc": 0.12, "time": 78.08}
{"epoch": 5, "training_loss": 55.40364646911621, "training_acc": 52.5, "val_loss": 13.893591165542603, "val_acc": 50.0, "val_auroc": 0.33, "time": 94.59}
{"epoch": 6, "training_loss": 55.434370040893555, "training_acc": 52.5, "val_loss": 13.952341079711914, "val_acc": 50.0, "val_auroc": 0.38, "time": 109.9}
{"epoch": 7, "training_loss": 55.39955711364746, "training_acc": 52.5, "val_loss": 14.046895503997803, "val_acc": 50.0, "val_auroc": 0.16, "time": 126.59}
{"epoch": 8, "training_loss": 55.682695388793945, "training_acc": 52.5, "val_loss": 13.930333852767944, "val_acc": 50.0, "val_auroc": 0.35, "time": 141.7}
{"epoch": 9, "training_loss": 55.34798717498779, "training_acc": 52.5, "val_loss": 13.859213590621948, "val_acc": 50.0, "val_auroc": 0.62, "time": 158.89}
{"epoch": 10, "training_loss": 55.424713134765625, "training_acc": 51.25, "val_loss": 13.864012956619263, "val_acc": 50.0, "val_auroc": 0.54, "time": 173.8}
{"epoch": 11, "training_loss": 55.35696029663086, "training_acc": 52.5, "val_loss": 13.891938924789429, "val_acc": 50.0, "val_auroc": 0.7, "time": 189.09}
{"epoch": 12, "training_loss": 55.4081974029541, "training_acc": 52.5, "val_loss": 13.933779001235962, "val_acc": 50.0, "val_auroc": 0.4, "time": 204.59}
{"epoch": 13, "training_loss": 55.406484603881836, "training_acc": 52.5, "val_loss": 13.9113450050354, "val_acc": 50.0, "val_auroc": 0.25, "time": 220.1}
{"epoch": 14, "training_loss": 55.34903335571289, "training_acc": 52.5, "val_loss": 13.883469104766846, "val_acc": 50.0, "val_auroc": 0.45, "time": 234.8}
{"epoch": 15, "training_loss": 55.48176383972168, "training_acc": 52.5, "val_loss": 13.892911672592163, "val_acc": 50.0, "val_auroc": 0.23, "time": 249.96}
{"epoch": 16, "training_loss": 55.28769016265869, "training_acc": 52.5, "val_loss": 13.988951444625854, "val_acc": 50.0, "val_auroc": 0.8, "time": 264.95}
{"epoch": 17, "training_loss": 55.57468032836914, "training_acc": 52.5, "val_loss": 14.064023494720459, "val_acc": 50.0, "val_auroc": 0.83, "time": 279.59}
{"epoch": 18, "training_loss": 55.689114570617676, "training_acc": 52.5, "val_loss": 13.970086574554443, "val_acc": 50.0, "val_auroc": 0.48, "time": 295.42}
{"epoch": 19, "training_loss": 55.37358856201172, "training_acc": 52.5, "val_loss": 13.875573873519897, "val_acc": 50.0, "val_auroc": 0.52, "time": 311.82}
{"epoch": 20, "training_loss": 55.41257572174072, "training_acc": 52.5, "val_loss": 13.866366147994995, "val_acc": 50.0, "val_auroc": 0.44, "time": 326.85}
{"epoch": 21, "training_loss": 55.48566150665283, "training_acc": 47.5, "val_loss": 13.862558603286743, "val_acc": 50.0, "val_auroc": 0.58, "time": 341.83}
{"epoch": 22, "training_loss": 55.41448783874512, "training_acc": 51.25, "val_loss": 13.878563642501831, "val_acc": 50.0, "val_auroc": 0.59, "time": 356.82}
{"epoch": 23, "training_loss": 55.29646682739258, "training_acc": 52.5, "val_loss": 13.93937349319458, "val_acc": 50.0, "val_auroc": 0.69, "time": 371.96}
{"epoch": 24, "training_loss": 55.370439529418945, "training_acc": 52.5, "val_loss": 14.033441543579102, "val_acc": 50.0, "val_auroc": 0.84, "time": 387.75}
{"epoch": 25, "training_loss": 55.62125301361084, "training_acc": 52.5, "val_loss": 14.086194038391113, "val_acc": 50.0, "val_auroc": 0.85, "time": 402.6}
{"epoch": 26, "training_loss": 55.810523986816406, "training_acc": 52.5, "val_loss": 14.086276292800903, "val_acc": 50.0, "val_auroc": 0.72, "time": 417.0}
{"epoch": 27, "training_loss": 55.743953704833984, "training_acc": 52.5, "val_loss": 14.075939655303955, "val_acc": 50.0, "val_auroc": 0.64, "time": 433.05}
{"epoch": 28, "training_loss": 55.70458793640137, "training_acc": 52.5, "val_loss": 13.96004319190979, "val_acc": 50.0, "val_auroc": 0.75, "time": 447.34}
