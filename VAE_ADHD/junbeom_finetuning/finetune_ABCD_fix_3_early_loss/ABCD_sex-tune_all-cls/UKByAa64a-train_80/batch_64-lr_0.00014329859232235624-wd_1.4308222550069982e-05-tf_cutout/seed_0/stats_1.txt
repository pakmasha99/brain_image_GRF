"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.458749771118164, "training_acc": 52.5, "val_loss": 13.866726160049438, "val_acc": 50.0, "val_auroc": 0.58, "time": 16.43}
{"epoch": 1, "training_loss": 55.31410789489746, "training_acc": 52.5, "val_loss": 13.900022506713867, "val_acc": 50.0, "val_auroc": 0.53, "time": 31.33}
{"epoch": 2, "training_loss": 55.43555164337158, "training_acc": 52.5, "val_loss": 13.901585340499878, "val_acc": 50.0, "val_auroc": 0.58, "time": 46.17}
{"epoch": 3, "training_loss": 55.320913314819336, "training_acc": 52.5, "val_loss": 13.876981735229492, "val_acc": 50.0, "val_auroc": 0.61, "time": 60.73}
{"epoch": 4, "training_loss": 55.349538803100586, "training_acc": 52.5, "val_loss": 13.862532377243042, "val_acc": 50.0, "val_auroc": 0.53, "time": 75.26}
{"epoch": 5, "training_loss": 55.40527153015137, "training_acc": 52.5, "val_loss": 13.884384632110596, "val_acc": 50.0, "val_auroc": 0.76, "time": 89.82}
{"epoch": 6, "training_loss": 55.38542461395264, "training_acc": 52.5, "val_loss": 13.91033411026001, "val_acc": 50.0, "val_auroc": 0.55, "time": 104.48}
{"epoch": 7, "training_loss": 55.387330055236816, "training_acc": 52.5, "val_loss": 13.89169692993164, "val_acc": 50.0, "val_auroc": 0.54, "time": 118.99}
{"epoch": 8, "training_loss": 55.344322204589844, "training_acc": 52.5, "val_loss": 13.885713815689087, "val_acc": 50.0, "val_auroc": 0.6, "time": 133.38}
{"epoch": 9, "training_loss": 55.3478889465332, "training_acc": 52.5, "val_loss": 13.857622146606445, "val_acc": 50.0, "val_auroc": 0.72, "time": 148.16}
{"epoch": 10, "training_loss": 55.46929931640625, "training_acc": 50.0, "val_loss": 13.85888934135437, "val_acc": 50.0, "val_auroc": 0.75, "time": 162.87}
{"epoch": 11, "training_loss": 55.409889221191406, "training_acc": 48.75, "val_loss": 13.894232511520386, "val_acc": 50.0, "val_auroc": 0.69, "time": 177.63}
{"epoch": 12, "training_loss": 55.32569885253906, "training_acc": 52.5, "val_loss": 13.9816153049469, "val_acc": 50.0, "val_auroc": 0.69, "time": 193.1}
{"epoch": 13, "training_loss": 55.49944305419922, "training_acc": 52.5, "val_loss": 14.039443731307983, "val_acc": 50.0, "val_auroc": 0.75, "time": 207.39}
{"epoch": 14, "training_loss": 55.69032859802246, "training_acc": 52.5, "val_loss": 14.11062240600586, "val_acc": 50.0, "val_auroc": 0.7, "time": 221.8}
{"epoch": 15, "training_loss": 55.813560485839844, "training_acc": 52.5, "val_loss": 14.165810346603394, "val_acc": 50.0, "val_auroc": 0.66, "time": 236.13}
{"epoch": 16, "training_loss": 55.99979209899902, "training_acc": 52.5, "val_loss": 14.117990732192993, "val_acc": 50.0, "val_auroc": 0.77, "time": 250.84}
{"epoch": 17, "training_loss": 55.79013252258301, "training_acc": 52.5, "val_loss": 13.961629867553711, "val_acc": 50.0, "val_auroc": 0.6, "time": 267.76}
{"epoch": 18, "training_loss": 55.38547706604004, "training_acc": 52.5, "val_loss": 13.867071866989136, "val_acc": 50.0, "val_auroc": 0.48, "time": 282.11}
{"epoch": 19, "training_loss": 55.319271087646484, "training_acc": 52.5, "val_loss": 13.88256549835205, "val_acc": 50.0, "val_auroc": 0.41, "time": 296.62}
{"epoch": 20, "training_loss": 55.70405960083008, "training_acc": 47.5, "val_loss": 13.90886664390564, "val_acc": 50.0, "val_auroc": 0.39, "time": 311.01}
{"epoch": 21, "training_loss": 55.83363914489746, "training_acc": 47.5, "val_loss": 13.867313861846924, "val_acc": 50.0, "val_auroc": 0.5, "time": 325.53}
{"epoch": 22, "training_loss": 55.3940486907959, "training_acc": 50.0, "val_loss": 13.922914266586304, "val_acc": 50.0, "val_auroc": 0.55, "time": 341.38}
{"epoch": 23, "training_loss": 55.32907485961914, "training_acc": 52.5, "val_loss": 14.033149480819702, "val_acc": 50.0, "val_auroc": 0.63, "time": 356.41}
{"epoch": 24, "training_loss": 55.61163806915283, "training_acc": 52.5, "val_loss": 14.07187819480896, "val_acc": 50.0, "val_auroc": 0.71, "time": 371.7}
{"epoch": 25, "training_loss": 55.70527267456055, "training_acc": 52.5, "val_loss": 14.00377869606018, "val_acc": 50.0, "val_auroc": 0.63, "time": 386.83}
{"epoch": 26, "training_loss": 55.55632209777832, "training_acc": 52.5, "val_loss": 13.934462070465088, "val_acc": 50.0, "val_auroc": 0.54, "time": 402.18}
{"epoch": 27, "training_loss": 55.42112064361572, "training_acc": 52.5, "val_loss": 13.897002935409546, "val_acc": 50.0, "val_auroc": 0.65, "time": 417.13}
{"epoch": 28, "training_loss": 55.423377990722656, "training_acc": 52.5, "val_loss": 13.86863112449646, "val_acc": 50.0, "val_auroc": 0.49, "time": 431.35}
