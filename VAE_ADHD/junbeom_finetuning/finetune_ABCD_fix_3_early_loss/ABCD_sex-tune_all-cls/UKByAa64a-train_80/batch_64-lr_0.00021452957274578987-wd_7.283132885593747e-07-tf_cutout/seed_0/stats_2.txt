"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.24691963195801, "training_acc": 48.75, "val_loss": 14.177724123001099, "val_acc": 60.0, "val_auroc": 0.75, "time": 17.02}
{"epoch": 1, "training_loss": 55.964773178100586, "training_acc": 52.5, "val_loss": 16.07704997062683, "val_acc": 50.0, "val_auroc": 0.6, "time": 32.08}
{"epoch": 2, "training_loss": 61.59921646118164, "training_acc": 50.0, "val_loss": 14.107240438461304, "val_acc": 50.0, "val_auroc": 0.32, "time": 47.77}
{"epoch": 3, "training_loss": 57.23641395568848, "training_acc": 47.5, "val_loss": 14.066016674041748, "val_acc": 50.0, "val_auroc": 0.33, "time": 62.95}
{"epoch": 4, "training_loss": 55.659607887268066, "training_acc": 52.5, "val_loss": 13.936384916305542, "val_acc": 50.0, "val_auroc": 0.21, "time": 78.21}
{"epoch": 5, "training_loss": 55.46281433105469, "training_acc": 50.0, "val_loss": 13.886760473251343, "val_acc": 50.0, "val_auroc": 0.33, "time": 94.42}
{"epoch": 6, "training_loss": 55.364593505859375, "training_acc": 52.5, "val_loss": 14.11342978477478, "val_acc": 50.0, "val_auroc": 0.37, "time": 109.99}
{"epoch": 7, "training_loss": 55.8254451751709, "training_acc": 52.5, "val_loss": 14.33138370513916, "val_acc": 50.0, "val_auroc": 0.29, "time": 124.94}
{"epoch": 8, "training_loss": 56.16943168640137, "training_acc": 52.5, "val_loss": 13.8986074924469, "val_acc": 50.0, "val_auroc": 0.58, "time": 140.4}
{"epoch": 9, "training_loss": 55.31650638580322, "training_acc": 52.5, "val_loss": 13.914905786514282, "val_acc": 50.0, "val_auroc": 0.64, "time": 156.21}
{"epoch": 10, "training_loss": 55.97986602783203, "training_acc": 47.5, "val_loss": 13.872603178024292, "val_acc": 50.0, "val_auroc": 0.41, "time": 173.92}
{"epoch": 11, "training_loss": 55.114521980285645, "training_acc": 52.5, "val_loss": 14.8518705368042, "val_acc": 50.0, "val_auroc": 0.25, "time": 191.55}
{"epoch": 12, "training_loss": 57.442227363586426, "training_acc": 52.5, "val_loss": 13.898446559906006, "val_acc": 50.0, "val_auroc": 0.76, "time": 206.66}
{"epoch": 13, "training_loss": 55.2778902053833, "training_acc": 52.5, "val_loss": 13.846602439880371, "val_acc": 50.0, "val_auroc": 0.79, "time": 222.33}
{"epoch": 14, "training_loss": 55.574764251708984, "training_acc": 47.5, "val_loss": 13.846982717514038, "val_acc": 50.0, "val_auroc": 0.74, "time": 237.33}
{"epoch": 15, "training_loss": 55.49427890777588, "training_acc": 47.5, "val_loss": 13.879739046096802, "val_acc": 50.0, "val_auroc": 0.73, "time": 252.6}
{"epoch": 16, "training_loss": 55.17329025268555, "training_acc": 52.5, "val_loss": 14.112809896469116, "val_acc": 50.0, "val_auroc": 0.64, "time": 267.5}
{"epoch": 17, "training_loss": 55.924943923950195, "training_acc": 52.5, "val_loss": 14.25145149230957, "val_acc": 50.0, "val_auroc": 0.6, "time": 285.42}
{"epoch": 18, "training_loss": 56.081101417541504, "training_acc": 52.5, "val_loss": 13.998473882675171, "val_acc": 50.0, "val_auroc": 0.62, "time": 303.21}
{"epoch": 19, "training_loss": 55.327096939086914, "training_acc": 52.5, "val_loss": 13.855425119400024, "val_acc": 50.0, "val_auroc": 0.81, "time": 320.46}
{"epoch": 20, "training_loss": 55.56575965881348, "training_acc": 57.5, "val_loss": 13.889573812484741, "val_acc": 50.0, "val_auroc": 0.72, "time": 335.88}
{"epoch": 21, "training_loss": 55.76461219787598, "training_acc": 47.5, "val_loss": 13.855785131454468, "val_acc": 50.0, "val_auroc": 0.73, "time": 351.42}
{"epoch": 22, "training_loss": 55.397878646850586, "training_acc": 50.0, "val_loss": 13.898983001708984, "val_acc": 50.0, "val_auroc": 0.75, "time": 366.92}
{"epoch": 23, "training_loss": 55.27754306793213, "training_acc": 52.5, "val_loss": 14.053624868392944, "val_acc": 50.0, "val_auroc": 0.74, "time": 383.91}
{"epoch": 24, "training_loss": 55.62464714050293, "training_acc": 52.5, "val_loss": 14.181556701660156, "val_acc": 50.0, "val_auroc": 0.79, "time": 399.66}
{"epoch": 25, "training_loss": 55.976261138916016, "training_acc": 52.5, "val_loss": 14.086591005325317, "val_acc": 50.0, "val_auroc": 0.85, "time": 413.93}
{"epoch": 26, "training_loss": 55.91933345794678, "training_acc": 52.5, "val_loss": 13.982373476028442, "val_acc": 50.0, "val_auroc": 0.79, "time": 429.16}
{"epoch": 27, "training_loss": 55.41830253601074, "training_acc": 52.5, "val_loss": 13.973321914672852, "val_acc": 50.0, "val_auroc": 0.72, "time": 444.31}
{"epoch": 28, "training_loss": 55.485836029052734, "training_acc": 52.5, "val_loss": 13.883286714553833, "val_acc": 50.0, "val_auroc": 0.65, "time": 460.23}
{"epoch": 29, "training_loss": 55.360618591308594, "training_acc": 51.25, "val_loss": 13.848644495010376, "val_acc": 50.0, "val_auroc": 0.77, "time": 475.55}
{"epoch": 30, "training_loss": 55.50050354003906, "training_acc": 47.5, "val_loss": 13.845890760421753, "val_acc": 50.0, "val_auroc": 0.78, "time": 493.72}
{"epoch": 31, "training_loss": 55.49966239929199, "training_acc": 45.0, "val_loss": 13.854866027832031, "val_acc": 50.0, "val_auroc": 0.82, "time": 510.77}
{"epoch": 32, "training_loss": 55.337114334106445, "training_acc": 52.5, "val_loss": 13.85342001914978, "val_acc": 50.0, "val_auroc": 0.85, "time": 525.45}
{"epoch": 33, "training_loss": 55.32008934020996, "training_acc": 52.5, "val_loss": 13.841679096221924, "val_acc": 50.0, "val_auroc": 0.83, "time": 541.05}
{"epoch": 34, "training_loss": 55.38648319244385, "training_acc": 50.0, "val_loss": 13.843387365341187, "val_acc": 50.0, "val_auroc": 0.83, "time": 555.56}
{"epoch": 35, "training_loss": 55.434818267822266, "training_acc": 52.5, "val_loss": 13.8638436794281, "val_acc": 50.0, "val_auroc": 0.85, "time": 571.27}
{"epoch": 36, "training_loss": 55.26234245300293, "training_acc": 52.5, "val_loss": 13.848485946655273, "val_acc": 50.0, "val_auroc": 0.84, "time": 585.96}
{"epoch": 37, "training_loss": 55.24863052368164, "training_acc": 52.5, "val_loss": 13.835214376449585, "val_acc": 50.0, "val_auroc": 0.8, "time": 602.16}
{"epoch": 38, "training_loss": 55.362244606018066, "training_acc": 51.25, "val_loss": 13.832730054855347, "val_acc": 50.0, "val_auroc": 0.82, "time": 618.32}
{"epoch": 39, "training_loss": 55.2888765335083, "training_acc": 66.25, "val_loss": 13.85414719581604, "val_acc": 50.0, "val_auroc": 0.81, "time": 634.16}
{"epoch": 40, "training_loss": 55.32112503051758, "training_acc": 52.5, "val_loss": 13.864542245864868, "val_acc": 50.0, "val_auroc": 0.78, "time": 651.71}
{"epoch": 41, "training_loss": 55.20786094665527, "training_acc": 52.5, "val_loss": 13.844118118286133, "val_acc": 50.0, "val_auroc": 0.8, "time": 667.52}
{"epoch": 42, "training_loss": 55.344722747802734, "training_acc": 47.5, "val_loss": 13.841040134429932, "val_acc": 50.0, "val_auroc": 0.74, "time": 682.93}
{"epoch": 43, "training_loss": 55.24147987365723, "training_acc": 70.0, "val_loss": 13.84841799736023, "val_acc": 50.0, "val_auroc": 0.69, "time": 698.76}
{"epoch": 44, "training_loss": 55.226070404052734, "training_acc": 52.5, "val_loss": 13.858855962753296, "val_acc": 50.0, "val_auroc": 0.62, "time": 714.28}
{"epoch": 45, "training_loss": 55.16236877441406, "training_acc": 52.5, "val_loss": 13.858871459960938, "val_acc": 50.0, "val_auroc": 0.66, "time": 730.32}
{"epoch": 46, "training_loss": 55.14889907836914, "training_acc": 52.5, "val_loss": 13.855370283126831, "val_acc": 50.0, "val_auroc": 0.68, "time": 746.57}
{"epoch": 47, "training_loss": 55.12104511260986, "training_acc": 52.5, "val_loss": 13.857181072235107, "val_acc": 50.0, "val_auroc": 0.66, "time": 762.72}
{"epoch": 48, "training_loss": 55.126296043395996, "training_acc": 52.5, "val_loss": 13.89405608177185, "val_acc": 50.0, "val_auroc": 0.68, "time": 778.61}
{"epoch": 49, "training_loss": 55.13601493835449, "training_acc": 52.5, "val_loss": 13.9810311794281, "val_acc": 50.0, "val_auroc": 0.73, "time": 795.84}
{"epoch": 50, "training_loss": 55.32185173034668, "training_acc": 52.5, "val_loss": 13.890380859375, "val_acc": 50.0, "val_auroc": 0.72, "time": 811.24}
{"epoch": 51, "training_loss": 54.99924182891846, "training_acc": 52.5, "val_loss": 13.798954486846924, "val_acc": 50.0, "val_auroc": 0.71, "time": 826.93}
{"epoch": 52, "training_loss": 55.286659240722656, "training_acc": 60.0, "val_loss": 13.803761005401611, "val_acc": 50.0, "val_auroc": 0.75, "time": 842.88}
{"epoch": 53, "training_loss": 55.064979553222656, "training_acc": 60.0, "val_loss": 13.875511884689331, "val_acc": 50.0, "val_auroc": 0.64, "time": 858.56}
{"epoch": 54, "training_loss": 54.89040946960449, "training_acc": 52.5, "val_loss": 13.934274911880493, "val_acc": 50.0, "val_auroc": 0.69, "time": 874.01}
{"epoch": 55, "training_loss": 55.09033393859863, "training_acc": 52.5, "val_loss": 14.020755290985107, "val_acc": 50.0, "val_auroc": 0.7, "time": 889.27}
{"epoch": 56, "training_loss": 55.339816093444824, "training_acc": 52.5, "val_loss": 14.01186227798462, "val_acc": 50.0, "val_auroc": 0.72, "time": 905.5}
{"epoch": 57, "training_loss": 55.12837314605713, "training_acc": 52.5, "val_loss": 13.824996948242188, "val_acc": 50.0, "val_auroc": 0.74, "time": 921.26}
{"epoch": 58, "training_loss": 54.84301567077637, "training_acc": 55.0, "val_loss": 13.881357908248901, "val_acc": 50.0, "val_auroc": 0.79, "time": 937.45}
{"epoch": 59, "training_loss": 55.76415157318115, "training_acc": 47.5, "val_loss": 13.89366626739502, "val_acc": 50.0, "val_auroc": 0.66, "time": 953.11}
{"epoch": 60, "training_loss": 55.54475402832031, "training_acc": 47.5, "val_loss": 13.859100341796875, "val_acc": 50.0, "val_auroc": 0.53, "time": 970.84}
{"epoch": 61, "training_loss": 55.01320171356201, "training_acc": 52.5, "val_loss": 13.955904245376587, "val_acc": 50.0, "val_auroc": 0.59, "time": 986.28}
{"epoch": 62, "training_loss": 55.30324172973633, "training_acc": 52.5, "val_loss": 14.02950644493103, "val_acc": 50.0, "val_auroc": 0.72, "time": 1002.57}
{"epoch": 63, "training_loss": 55.52001762390137, "training_acc": 52.5, "val_loss": 13.922929763793945, "val_acc": 50.0, "val_auroc": 0.7, "time": 1018.59}
{"epoch": 64, "training_loss": 55.31232261657715, "training_acc": 52.5, "val_loss": 13.827645778656006, "val_acc": 50.0, "val_auroc": 0.71, "time": 1033.54}
{"epoch": 65, "training_loss": 55.2777738571167, "training_acc": 53.75, "val_loss": 13.831130266189575, "val_acc": 50.0, "val_auroc": 0.68, "time": 1047.88}
{"epoch": 66, "training_loss": 55.22031593322754, "training_acc": 57.5, "val_loss": 13.831655979156494, "val_acc": 50.0, "val_auroc": 0.69, "time": 1062.47}
{"epoch": 67, "training_loss": 55.30747413635254, "training_acc": 46.25, "val_loss": 13.834418058395386, "val_acc": 50.0, "val_auroc": 0.66, "time": 1076.87}
{"epoch": 68, "training_loss": 55.37444591522217, "training_acc": 55.0, "val_loss": 13.879221677780151, "val_acc": 50.0, "val_auroc": 0.56, "time": 1091.1}
{"epoch": 69, "training_loss": 55.100162506103516, "training_acc": 52.5, "val_loss": 13.974655866622925, "val_acc": 50.0, "val_auroc": 0.55, "time": 1108.12}
{"epoch": 70, "training_loss": 55.26503944396973, "training_acc": 52.5, "val_loss": 13.9492928981781, "val_acc": 50.0, "val_auroc": 0.56, "time": 1123.29}
