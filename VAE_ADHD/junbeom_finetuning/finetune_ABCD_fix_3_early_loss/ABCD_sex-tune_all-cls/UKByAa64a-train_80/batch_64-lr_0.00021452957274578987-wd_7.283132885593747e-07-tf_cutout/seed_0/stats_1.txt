"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.07382392883301, "training_acc": 53.75, "val_loss": 13.904050588607788, "val_acc": 50.0, "val_auroc": 0.46, "time": 16.24}
{"epoch": 1, "training_loss": 57.41188716888428, "training_acc": 46.25, "val_loss": 17.442623376846313, "val_acc": 50.0, "val_auroc": 0.53, "time": 30.51}
{"epoch": 2, "training_loss": 65.009765625, "training_acc": 52.5, "val_loss": 13.894389867782593, "val_acc": 50.0, "val_auroc": 0.44, "time": 48.4}
{"epoch": 3, "training_loss": 56.46059226989746, "training_acc": 47.5, "val_loss": 15.37474274635315, "val_acc": 50.0, "val_auroc": 0.6, "time": 63.46}
{"epoch": 4, "training_loss": 61.78788089752197, "training_acc": 47.5, "val_loss": 14.031718969345093, "val_acc": 50.0, "val_auroc": 0.58, "time": 77.7}
{"epoch": 5, "training_loss": 55.71565341949463, "training_acc": 52.5, "val_loss": 13.99607539176941, "val_acc": 50.0, "val_auroc": 0.5, "time": 91.93}
{"epoch": 6, "training_loss": 55.4414119720459, "training_acc": 52.5, "val_loss": 13.93284559249878, "val_acc": 50.0, "val_auroc": 0.6, "time": 106.28}
{"epoch": 7, "training_loss": 55.771175384521484, "training_acc": 50.0, "val_loss": 14.686774015426636, "val_acc": 50.0, "val_auroc": 0.51, "time": 120.67}
{"epoch": 8, "training_loss": 57.009934425354004, "training_acc": 52.5, "val_loss": 13.859039545059204, "val_acc": 50.0, "val_auroc": 0.7, "time": 135.54}
{"epoch": 9, "training_loss": 55.43079471588135, "training_acc": 47.5, "val_loss": 13.935601711273193, "val_acc": 50.0, "val_auroc": 0.61, "time": 150.14}
{"epoch": 10, "training_loss": 56.033016204833984, "training_acc": 47.5, "val_loss": 13.850024938583374, "val_acc": 50.0, "val_auroc": 0.74, "time": 164.98}
{"epoch": 11, "training_loss": 55.255364418029785, "training_acc": 52.5, "val_loss": 14.074041843414307, "val_acc": 50.0, "val_auroc": 0.7, "time": 180.39}
{"epoch": 12, "training_loss": 55.71389961242676, "training_acc": 52.5, "val_loss": 14.070589542388916, "val_acc": 50.0, "val_auroc": 0.65, "time": 195.19}
{"epoch": 13, "training_loss": 55.81731986999512, "training_acc": 52.5, "val_loss": 13.936270475387573, "val_acc": 50.0, "val_auroc": 0.71, "time": 210.55}
{"epoch": 14, "training_loss": 55.54379844665527, "training_acc": 52.5, "val_loss": 13.987153768539429, "val_acc": 50.0, "val_auroc": 0.74, "time": 225.24}
{"epoch": 15, "training_loss": 55.43493461608887, "training_acc": 52.5, "val_loss": 14.1640305519104, "val_acc": 50.0, "val_auroc": 0.72, "time": 239.91}
{"epoch": 16, "training_loss": 55.97737693786621, "training_acc": 52.5, "val_loss": 14.165290594100952, "val_acc": 50.0, "val_auroc": 0.75, "time": 253.97}
{"epoch": 17, "training_loss": 55.89002227783203, "training_acc": 52.5, "val_loss": 13.920611143112183, "val_acc": 50.0, "val_auroc": 0.72, "time": 268.39}
{"epoch": 18, "training_loss": 55.25774097442627, "training_acc": 52.5, "val_loss": 13.855870962142944, "val_acc": 50.0, "val_auroc": 0.68, "time": 282.96}
{"epoch": 19, "training_loss": 55.50358200073242, "training_acc": 47.5, "val_loss": 13.974579572677612, "val_acc": 50.0, "val_auroc": 0.67, "time": 297.64}
{"epoch": 20, "training_loss": 56.31627082824707, "training_acc": 47.5, "val_loss": 13.927555084228516, "val_acc": 50.0, "val_auroc": 0.68, "time": 312.03}
{"epoch": 21, "training_loss": 55.86202335357666, "training_acc": 47.5, "val_loss": 13.852332830429077, "val_acc": 50.0, "val_auroc": 0.66, "time": 327.09}
{"epoch": 22, "training_loss": 55.2695951461792, "training_acc": 52.5, "val_loss": 14.001762866973877, "val_acc": 50.0, "val_auroc": 0.61, "time": 341.93}
{"epoch": 23, "training_loss": 55.45473003387451, "training_acc": 52.5, "val_loss": 14.175399541854858, "val_acc": 50.0, "val_auroc": 0.55, "time": 360.16}
{"epoch": 24, "training_loss": 55.95148277282715, "training_acc": 52.5, "val_loss": 14.161849021911621, "val_acc": 50.0, "val_auroc": 0.58, "time": 376.08}
{"epoch": 25, "training_loss": 55.90341377258301, "training_acc": 52.5, "val_loss": 13.978335857391357, "val_acc": 50.0, "val_auroc": 0.6, "time": 391.33}
{"epoch": 26, "training_loss": 55.50359916687012, "training_acc": 52.5, "val_loss": 13.88420581817627, "val_acc": 50.0, "val_auroc": 0.63, "time": 407.33}
{"epoch": 27, "training_loss": 55.35232925415039, "training_acc": 52.5, "val_loss": 13.86583685874939, "val_acc": 50.0, "val_auroc": 0.67, "time": 423.97}
{"epoch": 28, "training_loss": 55.503188133239746, "training_acc": 52.5, "val_loss": 13.856279850006104, "val_acc": 50.0, "val_auroc": 0.64, "time": 440.53}
{"epoch": 29, "training_loss": 55.42999267578125, "training_acc": 50.0, "val_loss": 13.864344358444214, "val_acc": 50.0, "val_auroc": 0.56, "time": 456.07}
