"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.847721099853516, "training_acc": 45.0, "val_loss": 14.341310262680054, "val_acc": 55.0, "val_auroc": 0.374, "time": 16.89}
{"epoch": 1, "training_loss": 53.577162742614746, "training_acc": 57.5, "val_loss": 21.927967071533203, "val_acc": 55.0, "val_auroc": 0.424, "time": 32.0}
{"epoch": 2, "training_loss": 90.75828647613525, "training_acc": 51.25, "val_loss": 13.848979473114014, "val_acc": 55.0, "val_auroc": 0.434, "time": 47.8}
{"epoch": 3, "training_loss": 55.41329097747803, "training_acc": 50.0, "val_loss": 20.149083137512207, "val_acc": 45.0, "val_auroc": 0.535, "time": 62.73}
{"epoch": 4, "training_loss": 72.29637336730957, "training_acc": 48.75, "val_loss": 13.882753849029541, "val_acc": 55.0, "val_auroc": 0.525, "time": 78.0}
{"epoch": 5, "training_loss": 55.42311382293701, "training_acc": 53.75, "val_loss": 13.76949667930603, "val_acc": 55.0, "val_auroc": 0.485, "time": 95.67}
{"epoch": 6, "training_loss": 55.67634677886963, "training_acc": 51.25, "val_loss": 13.785717487335205, "val_acc": 55.0, "val_auroc": 0.404, "time": 110.61}
{"epoch": 7, "training_loss": 55.4461669921875, "training_acc": 51.25, "val_loss": 13.886798620223999, "val_acc": 55.0, "val_auroc": 0.444, "time": 125.15}
{"epoch": 8, "training_loss": 55.62849998474121, "training_acc": 50.0, "val_loss": 14.277182817459106, "val_acc": 55.0, "val_auroc": 0.535, "time": 140.02}
{"epoch": 9, "training_loss": 56.669772148132324, "training_acc": 48.75, "val_loss": 14.042948484420776, "val_acc": 55.0, "val_auroc": 0.576, "time": 154.84}
{"epoch": 10, "training_loss": 55.66390132904053, "training_acc": 48.75, "val_loss": 13.775590658187866, "val_acc": 55.0, "val_auroc": 0.475, "time": 170.0}
{"epoch": 11, "training_loss": 55.81292724609375, "training_acc": 51.25, "val_loss": 13.8118577003479, "val_acc": 55.0, "val_auroc": 0.485, "time": 184.9}
{"epoch": 12, "training_loss": 56.19644737243652, "training_acc": 51.25, "val_loss": 13.760758638381958, "val_acc": 55.0, "val_auroc": 0.566, "time": 200.12}
{"epoch": 13, "training_loss": 55.57945537567139, "training_acc": 51.25, "val_loss": 13.890050649642944, "val_acc": 55.0, "val_auroc": 0.586, "time": 215.47}
{"epoch": 14, "training_loss": 55.44915771484375, "training_acc": 48.75, "val_loss": 14.000123739242554, "val_acc": 55.0, "val_auroc": 0.566, "time": 231.83}
{"epoch": 15, "training_loss": 55.777079582214355, "training_acc": 48.75, "val_loss": 13.96533489227295, "val_acc": 55.0, "val_auroc": 0.545, "time": 247.45}
{"epoch": 16, "training_loss": 55.28754138946533, "training_acc": 48.75, "val_loss": 13.76636028289795, "val_acc": 55.0, "val_auroc": 0.535, "time": 262.03}
{"epoch": 17, "training_loss": 55.49520397186279, "training_acc": 51.25, "val_loss": 13.782480955123901, "val_acc": 55.0, "val_auroc": 0.576, "time": 276.6}
{"epoch": 18, "training_loss": 56.061349868774414, "training_acc": 51.25, "val_loss": 13.769525289535522, "val_acc": 55.0, "val_auroc": 0.515, "time": 291.46}
{"epoch": 19, "training_loss": 55.71415424346924, "training_acc": 51.25, "val_loss": 13.795397281646729, "val_acc": 55.0, "val_auroc": 0.545, "time": 307.42}
{"epoch": 20, "training_loss": 55.38942337036133, "training_acc": 51.25, "val_loss": 13.959829807281494, "val_acc": 55.0, "val_auroc": 0.515, "time": 322.77}
{"epoch": 21, "training_loss": 55.574275970458984, "training_acc": 48.75, "val_loss": 14.038499593734741, "val_acc": 55.0, "val_auroc": 0.515, "time": 337.96}
{"epoch": 22, "training_loss": 55.69268608093262, "training_acc": 48.75, "val_loss": 13.953968286514282, "val_acc": 55.0, "val_auroc": 0.505, "time": 353.61}
{"epoch": 23, "training_loss": 55.47703742980957, "training_acc": 48.75, "val_loss": 13.828063011169434, "val_acc": 55.0, "val_auroc": 0.505, "time": 369.49}
{"epoch": 24, "training_loss": 55.46622276306152, "training_acc": 51.25, "val_loss": 13.77560019493103, "val_acc": 55.0, "val_auroc": 0.515, "time": 384.22}
{"epoch": 25, "training_loss": 55.44638633728027, "training_acc": 51.25, "val_loss": 13.76888632774353, "val_acc": 55.0, "val_auroc": 0.525, "time": 402.29}
{"epoch": 26, "training_loss": 55.4360237121582, "training_acc": 51.25, "val_loss": 13.76181960105896, "val_acc": 55.0, "val_auroc": 0.525, "time": 417.81}
{"epoch": 27, "training_loss": 55.47516059875488, "training_acc": 51.25, "val_loss": 13.764325380325317, "val_acc": 55.0, "val_auroc": 0.515, "time": 433.49}
{"epoch": 28, "training_loss": 55.40935516357422, "training_acc": 51.25, "val_loss": 13.802881240844727, "val_acc": 55.0, "val_auroc": 0.525, "time": 449.49}
{"epoch": 29, "training_loss": 55.53010940551758, "training_acc": 46.25, "val_loss": 13.853092193603516, "val_acc": 55.0, "val_auroc": 0.505, "time": 465.72}
{"epoch": 30, "training_loss": 55.314449310302734, "training_acc": 61.25, "val_loss": 13.82075548171997, "val_acc": 55.0, "val_auroc": 0.505, "time": 481.1}
{"epoch": 31, "training_loss": 55.30999946594238, "training_acc": 51.25, "val_loss": 13.811935186386108, "val_acc": 55.0, "val_auroc": 0.505, "time": 496.13}
