"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.51395797729492, "training_acc": 52.5, "val_loss": 13.928474187850952, "val_acc": 50.0, "val_auroc": 0.42, "time": 19.43}
{"epoch": 1, "training_loss": 55.45635223388672, "training_acc": 52.5, "val_loss": 13.936798572540283, "val_acc": 50.0, "val_auroc": 0.4, "time": 36.48}
{"epoch": 2, "training_loss": 55.15536689758301, "training_acc": 52.5, "val_loss": 13.925156593322754, "val_acc": 50.0, "val_auroc": 0.37, "time": 60.27}
{"epoch": 3, "training_loss": 55.22919464111328, "training_acc": 52.5, "val_loss": 13.839939832687378, "val_acc": 50.0, "val_auroc": 0.65, "time": 83.27}
{"epoch": 4, "training_loss": 55.36429214477539, "training_acc": 52.5, "val_loss": 13.878991603851318, "val_acc": 50.0, "val_auroc": 0.62, "time": 101.81}
{"epoch": 5, "training_loss": 55.36333465576172, "training_acc": 52.5, "val_loss": 13.86897087097168, "val_acc": 50.0, "val_auroc": 0.65, "time": 120.68}
{"epoch": 6, "training_loss": 55.41567420959473, "training_acc": 52.5, "val_loss": 13.853095769882202, "val_acc": 50.0, "val_auroc": 0.77, "time": 140.5}
{"epoch": 7, "training_loss": 55.32811164855957, "training_acc": 52.5, "val_loss": 13.872900009155273, "val_acc": 50.0, "val_auroc": 0.76, "time": 159.93}
{"epoch": 8, "training_loss": 55.39935874938965, "training_acc": 52.5, "val_loss": 13.89399528503418, "val_acc": 50.0, "val_auroc": 0.71, "time": 176.26}
{"epoch": 9, "training_loss": 55.19573211669922, "training_acc": 52.5, "val_loss": 13.828102350234985, "val_acc": 50.0, "val_auroc": 0.73, "time": 193.3}
{"epoch": 10, "training_loss": 55.2386531829834, "training_acc": 52.5, "val_loss": 13.774497509002686, "val_acc": 50.0, "val_auroc": 0.81, "time": 211.06}
{"epoch": 11, "training_loss": 55.22503089904785, "training_acc": 52.5, "val_loss": 13.759816884994507, "val_acc": 50.0, "val_auroc": 0.78, "time": 231.52}
{"epoch": 12, "training_loss": 55.099220275878906, "training_acc": 52.5, "val_loss": 13.78702163696289, "val_acc": 50.0, "val_auroc": 0.83, "time": 249.25}
{"epoch": 13, "training_loss": 55.14553928375244, "training_acc": 52.5, "val_loss": 13.77916932106018, "val_acc": 50.0, "val_auroc": 0.87, "time": 266.98}
{"epoch": 14, "training_loss": 55.09229850769043, "training_acc": 52.5, "val_loss": 13.754193782806396, "val_acc": 50.0, "val_auroc": 0.88, "time": 285.66}
{"epoch": 15, "training_loss": 55.123695373535156, "training_acc": 52.5, "val_loss": 13.752117156982422, "val_acc": 50.0, "val_auroc": 0.89, "time": 306.69}
{"epoch": 16, "training_loss": 54.87762451171875, "training_acc": 52.5, "val_loss": 13.832539319992065, "val_acc": 50.0, "val_auroc": 0.86, "time": 323.16}
{"epoch": 17, "training_loss": 54.88656234741211, "training_acc": 52.5, "val_loss": 13.821169137954712, "val_acc": 50.0, "val_auroc": 0.83, "time": 339.86}
{"epoch": 18, "training_loss": 54.80533409118652, "training_acc": 52.5, "val_loss": 13.725589513778687, "val_acc": 50.0, "val_auroc": 0.83, "time": 357.45}
{"epoch": 19, "training_loss": 54.89871883392334, "training_acc": 52.5, "val_loss": 13.77022385597229, "val_acc": 50.0, "val_auroc": 0.8, "time": 378.46}
{"epoch": 20, "training_loss": 54.97170639038086, "training_acc": 53.75, "val_loss": 13.694082498550415, "val_acc": 50.0, "val_auroc": 0.88, "time": 396.68}
{"epoch": 21, "training_loss": 54.50119590759277, "training_acc": 68.75, "val_loss": 13.635241985321045, "val_acc": 50.0, "val_auroc": 0.84, "time": 415.12}
{"epoch": 22, "training_loss": 54.47338008880615, "training_acc": 53.75, "val_loss": 13.788602352142334, "val_acc": 50.0, "val_auroc": 0.83, "time": 434.48}
{"epoch": 23, "training_loss": 54.76185131072998, "training_acc": 52.5, "val_loss": 13.635886907577515, "val_acc": 50.0, "val_auroc": 0.85, "time": 452.12}
{"epoch": 24, "training_loss": 53.87173080444336, "training_acc": 52.5, "val_loss": 13.64582896232605, "val_acc": 50.0, "val_auroc": 0.86, "time": 469.06}
{"epoch": 25, "training_loss": 53.263916969299316, "training_acc": 56.25, "val_loss": 13.52916955947876, "val_acc": 50.0, "val_auroc": 0.83, "time": 485.62}
{"epoch": 26, "training_loss": 53.78598690032959, "training_acc": 61.25, "val_loss": 13.533718585968018, "val_acc": 50.0, "val_auroc": 0.78, "time": 503.92}
{"epoch": 27, "training_loss": 52.108314514160156, "training_acc": 63.75, "val_loss": 13.556346893310547, "val_acc": 50.0, "val_auroc": 0.75, "time": 523.39}
{"epoch": 28, "training_loss": 51.57908344268799, "training_acc": 65.0, "val_loss": 13.53122591972351, "val_acc": 50.0, "val_auroc": 0.76, "time": 542.17}
{"epoch": 29, "training_loss": 52.75327491760254, "training_acc": 77.5, "val_loss": 13.625519275665283, "val_acc": 50.0, "val_auroc": 0.72, "time": 559.84}
{"epoch": 30, "training_loss": 50.49002742767334, "training_acc": 78.75, "val_loss": 14.11736011505127, "val_acc": 50.0, "val_auroc": 0.7, "time": 578.2}
{"epoch": 31, "training_loss": 51.4116153717041, "training_acc": 60.0, "val_loss": 13.598695993423462, "val_acc": 50.0, "val_auroc": 0.71, "time": 597.19}
{"epoch": 32, "training_loss": 53.17935848236084, "training_acc": 63.75, "val_loss": 13.41112494468689, "val_acc": 50.0, "val_auroc": 0.72, "time": 615.49}
{"epoch": 33, "training_loss": 50.278953552246094, "training_acc": 80.0, "val_loss": 14.51494574546814, "val_acc": 50.0, "val_auroc": 0.64, "time": 632.06}
{"epoch": 34, "training_loss": 52.129981994628906, "training_acc": 57.5, "val_loss": 13.712605237960815, "val_acc": 50.0, "val_auroc": 0.7, "time": 650.32}
{"epoch": 35, "training_loss": 47.805870056152344, "training_acc": 81.25, "val_loss": 13.701261281967163, "val_acc": 50.0, "val_auroc": 0.66, "time": 669.33}
{"epoch": 36, "training_loss": 52.25763130187988, "training_acc": 62.5, "val_loss": 13.27487587928772, "val_acc": 50.0, "val_auroc": 0.73, "time": 687.62}
{"epoch": 37, "training_loss": 48.264936447143555, "training_acc": 81.25, "val_loss": 13.856507539749146, "val_acc": 50.0, "val_auroc": 0.68, "time": 705.17}
{"epoch": 38, "training_loss": 46.61102867126465, "training_acc": 81.25, "val_loss": 13.670196533203125, "val_acc": 50.0, "val_auroc": 0.64, "time": 722.82}
{"epoch": 39, "training_loss": 44.842023849487305, "training_acc": 86.25, "val_loss": 13.340667486190796, "val_acc": 50.0, "val_auroc": 0.67, "time": 741.16}
{"epoch": 40, "training_loss": 43.33998966217041, "training_acc": 87.5, "val_loss": 13.588182926177979, "val_acc": 50.0, "val_auroc": 0.64, "time": 758.19}
{"epoch": 41, "training_loss": 42.702096939086914, "training_acc": 87.5, "val_loss": 13.806551694869995, "val_acc": 50.0, "val_auroc": 0.6, "time": 774.81}
{"epoch": 42, "training_loss": 39.560035705566406, "training_acc": 96.25, "val_loss": 14.013103246688843, "val_acc": 50.0, "val_auroc": 0.54, "time": 791.43}
{"epoch": 43, "training_loss": 39.07175827026367, "training_acc": 91.25, "val_loss": 13.98520827293396, "val_acc": 60.0, "val_auroc": 0.58, "time": 810.09}
{"epoch": 44, "training_loss": 40.81906175613403, "training_acc": 88.75, "val_loss": 13.916666507720947, "val_acc": 55.0, "val_auroc": 0.57, "time": 827.35}
{"epoch": 45, "training_loss": 37.77915954589844, "training_acc": 93.75, "val_loss": 13.796457052230835, "val_acc": 50.0, "val_auroc": 0.54, "time": 844.6}
{"epoch": 46, "training_loss": 36.70907783508301, "training_acc": 95.0, "val_loss": 13.893479108810425, "val_acc": 60.0, "val_auroc": 0.57, "time": 861.35}
{"epoch": 47, "training_loss": 35.30850887298584, "training_acc": 98.75, "val_loss": 14.505270719528198, "val_acc": 50.0, "val_auroc": 0.55, "time": 878.99}
{"epoch": 48, "training_loss": 35.374152183532715, "training_acc": 98.75, "val_loss": 13.933998346328735, "val_acc": 60.0, "val_auroc": 0.58, "time": 895.8}
{"epoch": 49, "training_loss": 32.70660352706909, "training_acc": 97.5, "val_loss": 14.238141775131226, "val_acc": 50.0, "val_auroc": 0.55, "time": 912.75}
{"epoch": 50, "training_loss": 32.27957630157471, "training_acc": 98.75, "val_loss": 14.275803565979004, "val_acc": 55.0, "val_auroc": 0.58, "time": 929.33}
{"epoch": 51, "training_loss": 35.604844093322754, "training_acc": 95.0, "val_loss": 14.853638410568237, "val_acc": 50.0, "val_auroc": 0.59, "time": 947.47}
{"epoch": 52, "training_loss": 31.692737579345703, "training_acc": 97.5, "val_loss": 13.778917789459229, "val_acc": 70.0, "val_auroc": 0.64, "time": 964.86}
{"epoch": 53, "training_loss": 32.107666969299316, "training_acc": 97.5, "val_loss": 14.035642147064209, "val_acc": 55.0, "val_auroc": 0.58, "time": 981.08}
{"epoch": 54, "training_loss": 28.46082830429077, "training_acc": 100.0, "val_loss": 14.841846227645874, "val_acc": 50.0, "val_auroc": 0.58, "time": 998.46}
{"epoch": 55, "training_loss": 29.72835922241211, "training_acc": 97.5, "val_loss": 14.320871829986572, "val_acc": 50.0, "val_auroc": 0.57, "time": 1015.45}
