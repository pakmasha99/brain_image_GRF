"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.60628128051758, "training_acc": 42.5, "val_loss": 14.418059587478638, "val_acc": 55.0, "val_auroc": 0.374, "time": 16.55}
{"epoch": 1, "training_loss": 54.60696983337402, "training_acc": 53.75, "val_loss": 38.419227600097656, "val_acc": 55.0, "val_auroc": 0.333, "time": 30.98}
{"epoch": 2, "training_loss": 136.32701301574707, "training_acc": 51.25, "val_loss": 13.8530433177948, "val_acc": 55.0, "val_auroc": 0.374, "time": 45.81}
{"epoch": 3, "training_loss": 55.065208435058594, "training_acc": 52.5, "val_loss": 14.184893369674683, "val_acc": 55.0, "val_auroc": 0.374, "time": 59.95}
{"epoch": 4, "training_loss": 55.48086452484131, "training_acc": 48.75, "val_loss": 13.799402713775635, "val_acc": 55.0, "val_auroc": 0.444, "time": 74.57}
{"epoch": 5, "training_loss": 55.32904815673828, "training_acc": 51.25, "val_loss": 13.85679841041565, "val_acc": 55.0, "val_auroc": 0.444, "time": 89.33}
{"epoch": 6, "training_loss": 55.68589210510254, "training_acc": 51.25, "val_loss": 14.099072217941284, "val_acc": 55.0, "val_auroc": 0.455, "time": 105.2}
{"epoch": 7, "training_loss": 55.450560569763184, "training_acc": 48.75, "val_loss": 13.957226276397705, "val_acc": 55.0, "val_auroc": 0.495, "time": 120.52}
{"epoch": 8, "training_loss": 55.73398780822754, "training_acc": 46.25, "val_loss": 13.819893598556519, "val_acc": 55.0, "val_auroc": 0.515, "time": 135.59}
{"epoch": 9, "training_loss": 54.7042121887207, "training_acc": 58.75, "val_loss": 14.184303283691406, "val_acc": 55.0, "val_auroc": 0.495, "time": 150.72}
{"epoch": 10, "training_loss": 55.19519329071045, "training_acc": 48.75, "val_loss": 13.777437210083008, "val_acc": 55.0, "val_auroc": 0.535, "time": 166.12}
{"epoch": 11, "training_loss": 54.70768928527832, "training_acc": 51.25, "val_loss": 14.045604467391968, "val_acc": 55.0, "val_auroc": 0.505, "time": 180.6}
{"epoch": 12, "training_loss": 57.30521011352539, "training_acc": 51.25, "val_loss": 13.905256986618042, "val_acc": 55.0, "val_auroc": 0.505, "time": 195.68}
{"epoch": 13, "training_loss": 56.046711921691895, "training_acc": 51.25, "val_loss": 13.879035711288452, "val_acc": 55.0, "val_auroc": 0.475, "time": 210.99}
{"epoch": 14, "training_loss": 54.87044906616211, "training_acc": 62.5, "val_loss": 14.353852272033691, "val_acc": 55.0, "val_auroc": 0.444, "time": 229.27}
{"epoch": 15, "training_loss": 56.41057205200195, "training_acc": 48.75, "val_loss": 14.081534147262573, "val_acc": 55.0, "val_auroc": 0.455, "time": 244.67}
{"epoch": 16, "training_loss": 54.75896644592285, "training_acc": 57.5, "val_loss": 13.800801038742065, "val_acc": 55.0, "val_auroc": 0.424, "time": 259.64}
{"epoch": 17, "training_loss": 55.719295501708984, "training_acc": 51.25, "val_loss": 13.866080045700073, "val_acc": 55.0, "val_auroc": 0.414, "time": 275.57}
{"epoch": 18, "training_loss": 56.153255462646484, "training_acc": 51.25, "val_loss": 13.774805068969727, "val_acc": 55.0, "val_auroc": 0.455, "time": 291.14}
{"epoch": 19, "training_loss": 55.078020095825195, "training_acc": 51.25, "val_loss": 14.064830541610718, "val_acc": 55.0, "val_auroc": 0.465, "time": 307.52}
{"epoch": 20, "training_loss": 55.87477779388428, "training_acc": 48.75, "val_loss": 14.333139657974243, "val_acc": 55.0, "val_auroc": 0.455, "time": 322.87}
{"epoch": 21, "training_loss": 56.09554862976074, "training_acc": 48.75, "val_loss": 13.945544958114624, "val_acc": 55.0, "val_auroc": 0.455, "time": 338.23}
{"epoch": 22, "training_loss": 55.23480796813965, "training_acc": 48.75, "val_loss": 13.808348178863525, "val_acc": 55.0, "val_auroc": 0.404, "time": 353.78}
{"epoch": 23, "training_loss": 55.23863983154297, "training_acc": 51.25, "val_loss": 13.82375955581665, "val_acc": 55.0, "val_auroc": 0.434, "time": 370.25}
{"epoch": 24, "training_loss": 55.51661777496338, "training_acc": 51.25, "val_loss": 13.837827444076538, "val_acc": 55.0, "val_auroc": 0.444, "time": 386.47}
{"epoch": 25, "training_loss": 55.531883239746094, "training_acc": 51.25, "val_loss": 13.851131200790405, "val_acc": 55.0, "val_auroc": 0.434, "time": 401.78}
{"epoch": 26, "training_loss": 55.43842124938965, "training_acc": 51.25, "val_loss": 13.869779109954834, "val_acc": 55.0, "val_auroc": 0.444, "time": 418.21}
{"epoch": 27, "training_loss": 55.29984664916992, "training_acc": 51.25, "val_loss": 13.867660760879517, "val_acc": 55.0, "val_auroc": 0.424, "time": 433.94}
{"epoch": 28, "training_loss": 55.07761001586914, "training_acc": 51.25, "val_loss": 13.95975947380066, "val_acc": 55.0, "val_auroc": 0.414, "time": 449.32}
{"epoch": 29, "training_loss": 55.11000728607178, "training_acc": 62.5, "val_loss": 14.286339282989502, "val_acc": 55.0, "val_auroc": 0.394, "time": 464.78}
{"epoch": 30, "training_loss": 55.66009712219238, "training_acc": 48.75, "val_loss": 14.086929559707642, "val_acc": 55.0, "val_auroc": 0.434, "time": 480.68}
{"epoch": 31, "training_loss": 55.47854995727539, "training_acc": 50.0, "val_loss": 13.928660154342651, "val_acc": 55.0, "val_auroc": 0.465, "time": 496.78}
{"epoch": 32, "training_loss": 54.82791614532471, "training_acc": 68.75, "val_loss": 13.906252384185791, "val_acc": 55.0, "val_auroc": 0.475, "time": 514.1}
{"epoch": 33, "training_loss": 54.69437885284424, "training_acc": 67.5, "val_loss": 13.89194130897522, "val_acc": 55.0, "val_auroc": 0.444, "time": 532.79}
{"epoch": 34, "training_loss": 54.571017265319824, "training_acc": 67.5, "val_loss": 13.857588768005371, "val_acc": 55.0, "val_auroc": 0.455, "time": 549.53}
{"epoch": 35, "training_loss": 54.642066955566406, "training_acc": 53.75, "val_loss": 13.882428407669067, "val_acc": 55.0, "val_auroc": 0.485, "time": 566.5}
{"epoch": 36, "training_loss": 54.45857238769531, "training_acc": 56.25, "val_loss": 14.015387296676636, "val_acc": 55.0, "val_auroc": 0.485, "time": 581.8}
{"epoch": 37, "training_loss": 54.22639465332031, "training_acc": 58.75, "val_loss": 13.89350414276123, "val_acc": 55.0, "val_auroc": 0.455, "time": 597.56}
