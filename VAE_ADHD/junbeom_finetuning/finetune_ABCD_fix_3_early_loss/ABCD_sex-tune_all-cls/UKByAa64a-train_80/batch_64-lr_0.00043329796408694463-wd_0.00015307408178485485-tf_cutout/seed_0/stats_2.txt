"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.02652835845947, "training_acc": 52.5, "val_loss": 13.923543691635132, "val_acc": 50.0, "val_auroc": 0.45, "time": 19.63}
{"epoch": 1, "training_loss": 55.56509780883789, "training_acc": 52.5, "val_loss": 13.943510055541992, "val_acc": 50.0, "val_auroc": 0.49, "time": 37.41}
{"epoch": 2, "training_loss": 55.49304485321045, "training_acc": 52.5, "val_loss": 13.96222472190857, "val_acc": 50.0, "val_auroc": 0.42, "time": 55.31}
{"epoch": 3, "training_loss": 55.66148376464844, "training_acc": 52.5, "val_loss": 14.008948802947998, "val_acc": 50.0, "val_auroc": 0.38, "time": 72.97}
{"epoch": 4, "training_loss": 55.53454113006592, "training_acc": 52.5, "val_loss": 13.892197608947754, "val_acc": 50.0, "val_auroc": 0.51, "time": 90.4}
{"epoch": 5, "training_loss": 55.42485237121582, "training_acc": 52.5, "val_loss": 13.875570297241211, "val_acc": 50.0, "val_auroc": 0.27, "time": 107.7}
{"epoch": 6, "training_loss": 55.453622817993164, "training_acc": 52.5, "val_loss": 14.024873971939087, "val_acc": 50.0, "val_auroc": 0.57, "time": 125.13}
{"epoch": 7, "training_loss": 55.59669494628906, "training_acc": 52.5, "val_loss": 14.1452956199646, "val_acc": 50.0, "val_auroc": 0.55, "time": 142.12}
{"epoch": 8, "training_loss": 55.85747814178467, "training_acc": 52.5, "val_loss": 13.898823261260986, "val_acc": 50.0, "val_auroc": 0.38, "time": 159.26}
{"epoch": 9, "training_loss": 55.32513236999512, "training_acc": 52.5, "val_loss": 13.87973427772522, "val_acc": 50.0, "val_auroc": 0.52, "time": 176.45}
{"epoch": 10, "training_loss": 55.719146728515625, "training_acc": 47.5, "val_loss": 13.867219686508179, "val_acc": 50.0, "val_auroc": 0.76, "time": 194.13}
{"epoch": 11, "training_loss": 55.453752517700195, "training_acc": 52.5, "val_loss": 13.91270637512207, "val_acc": 50.0, "val_auroc": 0.51, "time": 211.0}
{"epoch": 12, "training_loss": 55.431389808654785, "training_acc": 52.5, "val_loss": 14.016727209091187, "val_acc": 50.0, "val_auroc": 0.25, "time": 228.1}
{"epoch": 13, "training_loss": 55.55925941467285, "training_acc": 52.5, "val_loss": 13.951704502105713, "val_acc": 50.0, "val_auroc": 0.37, "time": 245.13}
{"epoch": 14, "training_loss": 55.39247512817383, "training_acc": 52.5, "val_loss": 13.874950408935547, "val_acc": 50.0, "val_auroc": 0.59, "time": 261.96}
{"epoch": 15, "training_loss": 55.585320472717285, "training_acc": 45.0, "val_loss": 13.874167203903198, "val_acc": 50.0, "val_auroc": 0.26, "time": 278.86}
{"epoch": 16, "training_loss": 55.26478290557861, "training_acc": 52.5, "val_loss": 13.991471529006958, "val_acc": 50.0, "val_auroc": 0.49, "time": 295.75}
{"epoch": 17, "training_loss": 55.59986877441406, "training_acc": 52.5, "val_loss": 14.133342504501343, "val_acc": 50.0, "val_auroc": 0.73, "time": 312.41}
{"epoch": 18, "training_loss": 55.86380958557129, "training_acc": 52.5, "val_loss": 13.999674320220947, "val_acc": 50.0, "val_auroc": 0.44, "time": 328.33}
{"epoch": 19, "training_loss": 55.39133644104004, "training_acc": 52.5, "val_loss": 13.866428136825562, "val_acc": 50.0, "val_auroc": 0.42, "time": 345.46}
{"epoch": 20, "training_loss": 55.480390548706055, "training_acc": 50.0, "val_loss": 13.876866102218628, "val_acc": 50.0, "val_auroc": 0.23, "time": 362.52}
{"epoch": 21, "training_loss": 55.643662452697754, "training_acc": 47.5, "val_loss": 13.86495590209961, "val_acc": 50.0, "val_auroc": 0.35, "time": 379.68}
{"epoch": 22, "training_loss": 55.4608736038208, "training_acc": 50.0, "val_loss": 13.883905410766602, "val_acc": 50.0, "val_auroc": 0.54, "time": 396.61}
{"epoch": 23, "training_loss": 55.295555114746094, "training_acc": 52.5, "val_loss": 13.969991207122803, "val_acc": 50.0, "val_auroc": 0.67, "time": 413.73}
{"epoch": 24, "training_loss": 55.429903984069824, "training_acc": 52.5, "val_loss": 14.097437858581543, "val_acc": 50.0, "val_auroc": 0.69, "time": 430.71}
{"epoch": 25, "training_loss": 55.782012939453125, "training_acc": 52.5, "val_loss": 14.125386476516724, "val_acc": 50.0, "val_auroc": 0.64, "time": 447.76}
{"epoch": 26, "training_loss": 55.947052001953125, "training_acc": 52.5, "val_loss": 14.091910123825073, "val_acc": 50.0, "val_auroc": 0.42, "time": 465.01}
{"epoch": 27, "training_loss": 55.75818634033203, "training_acc": 52.5, "val_loss": 14.054789543151855, "val_acc": 50.0, "val_auroc": 0.36, "time": 482.07}
{"epoch": 28, "training_loss": 55.64160633087158, "training_acc": 52.5, "val_loss": 13.914841413497925, "val_acc": 50.0, "val_auroc": 0.33, "time": 498.94}
{"epoch": 29, "training_loss": 55.433600425720215, "training_acc": 52.5, "val_loss": 13.863627910614014, "val_acc": 50.0, "val_auroc": 0.46, "time": 516.39}
{"epoch": 30, "training_loss": 55.51300239562988, "training_acc": 47.5, "val_loss": 13.866462707519531, "val_acc": 50.0, "val_auroc": 0.63, "time": 533.07}
{"epoch": 31, "training_loss": 55.57388496398926, "training_acc": 47.5, "val_loss": 13.863965272903442, "val_acc": 50.0, "val_auroc": 0.64, "time": 551.2}
{"epoch": 32, "training_loss": 55.52414894104004, "training_acc": 47.5, "val_loss": 13.86401653289795, "val_acc": 50.0, "val_auroc": 0.58, "time": 567.74}
{"epoch": 33, "training_loss": 55.500603675842285, "training_acc": 47.5, "val_loss": 13.862923383712769, "val_acc": 50.0, "val_auroc": 0.64, "time": 584.82}
{"epoch": 34, "training_loss": 55.46086502075195, "training_acc": 47.5, "val_loss": 13.87460708618164, "val_acc": 50.0, "val_auroc": 0.4, "time": 601.73}
{"epoch": 35, "training_loss": 55.56215286254883, "training_acc": 52.5, "val_loss": 13.902451992034912, "val_acc": 50.0, "val_auroc": 0.32, "time": 618.46}
{"epoch": 36, "training_loss": 55.35152626037598, "training_acc": 52.5, "val_loss": 13.88338327407837, "val_acc": 50.0, "val_auroc": 0.27, "time": 635.2}
{"epoch": 37, "training_loss": 55.34257125854492, "training_acc": 52.5, "val_loss": 13.865746259689331, "val_acc": 50.0, "val_auroc": 0.32, "time": 652.03}
{"epoch": 38, "training_loss": 55.492292404174805, "training_acc": 47.5, "val_loss": 13.863469362258911, "val_acc": 50.0, "val_auroc": 0.37, "time": 668.92}
{"epoch": 39, "training_loss": 55.432743072509766, "training_acc": 52.5, "val_loss": 13.876501321792603, "val_acc": 50.0, "val_auroc": 0.35, "time": 685.78}
{"epoch": 40, "training_loss": 55.46306037902832, "training_acc": 52.5, "val_loss": 13.876699209213257, "val_acc": 50.0, "val_auroc": 0.33, "time": 702.61}
{"epoch": 41, "training_loss": 55.33378887176514, "training_acc": 52.5, "val_loss": 13.863623142242432, "val_acc": 50.0, "val_auroc": 0.27, "time": 719.72}
{"epoch": 42, "training_loss": 55.551886558532715, "training_acc": 47.5, "val_loss": 13.864244222640991, "val_acc": 50.0, "val_auroc": 0.26, "time": 736.41}
{"epoch": 43, "training_loss": 55.487610816955566, "training_acc": 47.5, "val_loss": 13.86995553970337, "val_acc": 50.0, "val_auroc": 0.34, "time": 753.31}
{"epoch": 44, "training_loss": 55.384647369384766, "training_acc": 52.5, "val_loss": 13.889446258544922, "val_acc": 50.0, "val_auroc": 0.44, "time": 770.09}
{"epoch": 45, "training_loss": 55.361976623535156, "training_acc": 52.5, "val_loss": 13.898327350616455, "val_acc": 50.0, "val_auroc": 0.73, "time": 785.84}
{"epoch": 46, "training_loss": 55.36051940917969, "training_acc": 52.5, "val_loss": 13.90312671661377, "val_acc": 50.0, "val_auroc": 0.68, "time": 802.93}
{"epoch": 47, "training_loss": 55.36708641052246, "training_acc": 52.5, "val_loss": 13.905336856842041, "val_acc": 50.0, "val_auroc": 0.49, "time": 819.88}
{"epoch": 48, "training_loss": 55.44307518005371, "training_acc": 52.5, "val_loss": 13.922265768051147, "val_acc": 50.0, "val_auroc": 0.28, "time": 836.44}
{"epoch": 49, "training_loss": 55.40851020812988, "training_acc": 52.5, "val_loss": 13.961987495422363, "val_acc": 50.0, "val_auroc": 0.56, "time": 852.73}
{"epoch": 50, "training_loss": 55.44899272918701, "training_acc": 52.5, "val_loss": 13.936642408370972, "val_acc": 50.0, "val_auroc": 0.28, "time": 869.5}
{"epoch": 51, "training_loss": 55.38652992248535, "training_acc": 52.5, "val_loss": 13.890661001205444, "val_acc": 50.0, "val_auroc": 0.42, "time": 886.36}
{"epoch": 52, "training_loss": 55.427724838256836, "training_acc": 52.5, "val_loss": 13.879050016403198, "val_acc": 50.0, "val_auroc": 0.29, "time": 903.81}
