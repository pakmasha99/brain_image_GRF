"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.811187744140625, "training_acc": 52.5, "val_loss": 13.903425931930542, "val_acc": 50.0, "val_auroc": 0.54, "time": 16.58}
{"epoch": 1, "training_loss": 55.653706550598145, "training_acc": 47.5, "val_loss": 13.908756971359253, "val_acc": 50.0, "val_auroc": 0.63, "time": 32.18}
{"epoch": 2, "training_loss": 55.43815040588379, "training_acc": 52.5, "val_loss": 13.95184874534607, "val_acc": 50.0, "val_auroc": 0.39, "time": 48.57}
{"epoch": 3, "training_loss": 55.5662956237793, "training_acc": 52.5, "val_loss": 14.0223228931427, "val_acc": 50.0, "val_auroc": 0.59, "time": 64.97}
{"epoch": 4, "training_loss": 55.569664001464844, "training_acc": 52.5, "val_loss": 13.90731692314148, "val_acc": 50.0, "val_auroc": 0.39, "time": 82.12}
{"epoch": 5, "training_loss": 55.41498565673828, "training_acc": 52.5, "val_loss": 13.881235122680664, "val_acc": 50.0, "val_auroc": 0.81, "time": 98.22}
{"epoch": 6, "training_loss": 55.45277976989746, "training_acc": 52.5, "val_loss": 13.975698947906494, "val_acc": 50.0, "val_auroc": 0.85, "time": 114.31}
{"epoch": 7, "training_loss": 55.48850917816162, "training_acc": 52.5, "val_loss": 14.093608856201172, "val_acc": 50.0, "val_auroc": 0.55, "time": 130.5}
{"epoch": 8, "training_loss": 55.785929679870605, "training_acc": 52.5, "val_loss": 13.9297616481781, "val_acc": 50.0, "val_auroc": 0.44, "time": 147.87}
{"epoch": 9, "training_loss": 55.352407455444336, "training_acc": 52.5, "val_loss": 13.863269090652466, "val_acc": 50.0, "val_auroc": 0.5, "time": 163.47}
{"epoch": 10, "training_loss": 55.52517509460449, "training_acc": 47.5, "val_loss": 13.860703706741333, "val_acc": 50.0, "val_auroc": 0.71, "time": 180.08}
{"epoch": 11, "training_loss": 55.42280197143555, "training_acc": 52.5, "val_loss": 13.893107175827026, "val_acc": 50.0, "val_auroc": 0.75, "time": 195.8}
{"epoch": 12, "training_loss": 55.404459953308105, "training_acc": 52.5, "val_loss": 13.963345289230347, "val_acc": 50.0, "val_auroc": 0.79, "time": 210.67}
{"epoch": 13, "training_loss": 55.458534240722656, "training_acc": 52.5, "val_loss": 13.932241201400757, "val_acc": 50.0, "val_auroc": 0.51, "time": 226.07}
{"epoch": 14, "training_loss": 55.37341499328613, "training_acc": 52.5, "val_loss": 13.881734609603882, "val_acc": 50.0, "val_auroc": 0.36, "time": 241.77}
{"epoch": 15, "training_loss": 55.53680992126465, "training_acc": 52.5, "val_loss": 13.883163928985596, "val_acc": 50.0, "val_auroc": 0.37, "time": 257.83}
{"epoch": 16, "training_loss": 55.28378677368164, "training_acc": 52.5, "val_loss": 13.98021936416626, "val_acc": 50.0, "val_auroc": 0.5, "time": 273.19}
{"epoch": 17, "training_loss": 55.55617332458496, "training_acc": 52.5, "val_loss": 14.095491170883179, "val_acc": 50.0, "val_auroc": 0.76, "time": 287.67}
{"epoch": 18, "training_loss": 55.776061058044434, "training_acc": 52.5, "val_loss": 14.00810718536377, "val_acc": 50.0, "val_auroc": 0.48, "time": 302.23}
{"epoch": 19, "training_loss": 55.44495677947998, "training_acc": 52.5, "val_loss": 13.886017799377441, "val_acc": 50.0, "val_auroc": 0.13, "time": 317.66}
{"epoch": 20, "training_loss": 55.41030788421631, "training_acc": 52.5, "val_loss": 13.864904642105103, "val_acc": 50.0, "val_auroc": 0.26, "time": 332.58}
{"epoch": 21, "training_loss": 55.5092191696167, "training_acc": 47.5, "val_loss": 13.86414885520935, "val_acc": 50.0, "val_auroc": 0.81, "time": 347.64}
{"epoch": 22, "training_loss": 55.491506576538086, "training_acc": 47.5, "val_loss": 13.865045309066772, "val_acc": 50.0, "val_auroc": 0.79, "time": 362.67}
{"epoch": 23, "training_loss": 55.33623695373535, "training_acc": 52.5, "val_loss": 13.90941858291626, "val_acc": 50.0, "val_auroc": 0.84, "time": 378.86}
{"epoch": 24, "training_loss": 55.308902740478516, "training_acc": 52.5, "val_loss": 14.025716781616211, "val_acc": 50.0, "val_auroc": 0.89, "time": 393.29}
{"epoch": 25, "training_loss": 55.60240364074707, "training_acc": 52.5, "val_loss": 14.11812424659729, "val_acc": 50.0, "val_auroc": 0.9, "time": 407.91}
{"epoch": 26, "training_loss": 55.87100410461426, "training_acc": 52.5, "val_loss": 14.138121604919434, "val_acc": 50.0, "val_auroc": 0.78, "time": 422.36}
{"epoch": 27, "training_loss": 55.888427734375, "training_acc": 52.5, "val_loss": 14.123451709747314, "val_acc": 50.0, "val_auroc": 0.65, "time": 436.94}
{"epoch": 28, "training_loss": 55.812851905822754, "training_acc": 52.5, "val_loss": 13.980008363723755, "val_acc": 50.0, "val_auroc": 0.77, "time": 451.32}
{"epoch": 29, "training_loss": 55.51798343658447, "training_acc": 52.5, "val_loss": 13.870123624801636, "val_acc": 50.0, "val_auroc": 0.76, "time": 466.35}
