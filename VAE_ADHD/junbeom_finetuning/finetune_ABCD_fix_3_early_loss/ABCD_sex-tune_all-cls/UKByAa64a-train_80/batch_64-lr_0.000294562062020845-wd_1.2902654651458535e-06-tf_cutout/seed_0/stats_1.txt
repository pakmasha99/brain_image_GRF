"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.722267150878906, "training_acc": 52.5, "val_loss": 13.96044373512268, "val_acc": 50.0, "val_auroc": 0.35, "time": 17.25}
{"epoch": 1, "training_loss": 55.497236251831055, "training_acc": 52.5, "val_loss": 13.962196111679077, "val_acc": 50.0, "val_auroc": 0.49, "time": 32.23}
{"epoch": 2, "training_loss": 55.544803619384766, "training_acc": 52.5, "val_loss": 13.926349878311157, "val_acc": 50.0, "val_auroc": 0.45, "time": 47.69}
{"epoch": 3, "training_loss": 55.38799571990967, "training_acc": 52.5, "val_loss": 13.866024017333984, "val_acc": 50.0, "val_auroc": 0.41, "time": 63.03}
{"epoch": 4, "training_loss": 55.4276180267334, "training_acc": 52.5, "val_loss": 13.863908052444458, "val_acc": 50.0, "val_auroc": 0.43, "time": 78.89}
{"epoch": 5, "training_loss": 55.39169692993164, "training_acc": 52.5, "val_loss": 13.933374881744385, "val_acc": 50.0, "val_auroc": 0.59, "time": 94.02}
{"epoch": 6, "training_loss": 55.40594959259033, "training_acc": 52.5, "val_loss": 13.888381719589233, "val_acc": 50.0, "val_auroc": 0.49, "time": 109.34}
{"epoch": 7, "training_loss": 55.408620834350586, "training_acc": 52.5, "val_loss": 13.880882263183594, "val_acc": 50.0, "val_auroc": 0.69, "time": 127.29}
{"epoch": 8, "training_loss": 55.37177085876465, "training_acc": 52.5, "val_loss": 13.885364532470703, "val_acc": 50.0, "val_auroc": 0.4, "time": 143.59}
{"epoch": 9, "training_loss": 55.3846492767334, "training_acc": 52.5, "val_loss": 13.863061666488647, "val_acc": 50.0, "val_auroc": 0.52, "time": 158.38}
{"epoch": 10, "training_loss": 55.542144775390625, "training_acc": 47.5, "val_loss": 13.863080739974976, "val_acc": 50.0, "val_auroc": 0.48, "time": 173.26}
{"epoch": 11, "training_loss": 55.39487838745117, "training_acc": 50.0, "val_loss": 13.92704963684082, "val_acc": 50.0, "val_auroc": 0.54, "time": 187.64}
{"epoch": 12, "training_loss": 55.37582969665527, "training_acc": 52.5, "val_loss": 14.013649225234985, "val_acc": 50.0, "val_auroc": 0.54, "time": 203.58}
{"epoch": 13, "training_loss": 55.6088752746582, "training_acc": 52.5, "val_loss": 14.033950567245483, "val_acc": 50.0, "val_auroc": 0.55, "time": 218.64}
{"epoch": 14, "training_loss": 55.699750900268555, "training_acc": 52.5, "val_loss": 14.10648226737976, "val_acc": 50.0, "val_auroc": 0.5, "time": 232.82}
{"epoch": 15, "training_loss": 55.798479080200195, "training_acc": 52.5, "val_loss": 14.175974130630493, "val_acc": 50.0, "val_auroc": 0.49, "time": 247.29}
{"epoch": 16, "training_loss": 56.02726745605469, "training_acc": 52.5, "val_loss": 14.102712869644165, "val_acc": 50.0, "val_auroc": 0.54, "time": 261.87}
{"epoch": 17, "training_loss": 55.739402770996094, "training_acc": 52.5, "val_loss": 13.928478956222534, "val_acc": 50.0, "val_auroc": 0.48, "time": 276.63}
{"epoch": 18, "training_loss": 55.340402603149414, "training_acc": 52.5, "val_loss": 13.864884376525879, "val_acc": 50.0, "val_auroc": 0.49, "time": 291.68}
{"epoch": 19, "training_loss": 55.5164909362793, "training_acc": 47.5, "val_loss": 13.91175627708435, "val_acc": 50.0, "val_auroc": 0.51, "time": 307.28}
{"epoch": 20, "training_loss": 55.9571533203125, "training_acc": 47.5, "val_loss": 13.92215609550476, "val_acc": 50.0, "val_auroc": 0.54, "time": 322.77}
{"epoch": 21, "training_loss": 55.901474952697754, "training_acc": 47.5, "val_loss": 13.863013982772827, "val_acc": 50.0, "val_auroc": 0.68, "time": 338.12}
{"epoch": 22, "training_loss": 55.349266052246094, "training_acc": 52.5, "val_loss": 13.97408127784729, "val_acc": 50.0, "val_auroc": 0.52, "time": 353.16}
{"epoch": 23, "training_loss": 55.43825435638428, "training_acc": 52.5, "val_loss": 14.104299545288086, "val_acc": 50.0, "val_auroc": 0.5, "time": 369.08}
{"epoch": 24, "training_loss": 55.79568386077881, "training_acc": 52.5, "val_loss": 14.10922646522522, "val_acc": 50.0, "val_auroc": 0.47, "time": 385.89}
{"epoch": 25, "training_loss": 55.80051136016846, "training_acc": 52.5, "val_loss": 13.991899490356445, "val_acc": 50.0, "val_auroc": 0.58, "time": 400.76}
{"epoch": 26, "training_loss": 55.5265998840332, "training_acc": 52.5, "val_loss": 13.906111717224121, "val_acc": 50.0, "val_auroc": 0.59, "time": 415.56}
{"epoch": 27, "training_loss": 55.38460063934326, "training_acc": 52.5, "val_loss": 13.88238787651062, "val_acc": 50.0, "val_auroc": 0.6, "time": 433.83}
{"epoch": 28, "training_loss": 55.50063896179199, "training_acc": 52.5, "val_loss": 13.864338397979736, "val_acc": 50.0, "val_auroc": 0.66, "time": 449.05}
{"epoch": 29, "training_loss": 55.489070892333984, "training_acc": 50.0, "val_loss": 13.874142169952393, "val_acc": 50.0, "val_auroc": 0.57, "time": 465.74}
{"epoch": 30, "training_loss": 55.63633346557617, "training_acc": 47.5, "val_loss": 13.863184452056885, "val_acc": 50.0, "val_auroc": 0.49, "time": 481.89}
{"epoch": 31, "training_loss": 55.37576103210449, "training_acc": 52.5, "val_loss": 13.92652153968811, "val_acc": 50.0, "val_auroc": 0.5, "time": 497.05}
{"epoch": 32, "training_loss": 55.604084968566895, "training_acc": 52.5, "val_loss": 13.964240550994873, "val_acc": 50.0, "val_auroc": 0.47, "time": 512.4}
{"epoch": 33, "training_loss": 55.46745491027832, "training_acc": 52.5, "val_loss": 13.90658974647522, "val_acc": 50.0, "val_auroc": 0.51, "time": 527.04}
{"epoch": 34, "training_loss": 55.37680149078369, "training_acc": 52.5, "val_loss": 13.886919021606445, "val_acc": 50.0, "val_auroc": 0.45, "time": 542.1}
{"epoch": 35, "training_loss": 55.430429458618164, "training_acc": 52.5, "val_loss": 13.867356777191162, "val_acc": 50.0, "val_auroc": 0.51, "time": 557.48}
{"epoch": 36, "training_loss": 55.299394607543945, "training_acc": 52.5, "val_loss": 13.882101774215698, "val_acc": 50.0, "val_auroc": 0.56, "time": 573.44}
{"epoch": 37, "training_loss": 55.64636993408203, "training_acc": 47.5, "val_loss": 13.959604501724243, "val_acc": 50.0, "val_auroc": 0.55, "time": 590.42}
{"epoch": 38, "training_loss": 56.289100646972656, "training_acc": 47.5, "val_loss": 13.96370530128479, "val_acc": 50.0, "val_auroc": 0.54, "time": 607.72}
{"epoch": 39, "training_loss": 56.21871471405029, "training_acc": 47.5, "val_loss": 13.882789611816406, "val_acc": 50.0, "val_auroc": 0.51, "time": 625.83}
{"epoch": 40, "training_loss": 55.69263458251953, "training_acc": 47.5, "val_loss": 13.866733312606812, "val_acc": 50.0, "val_auroc": 0.48, "time": 642.38}
