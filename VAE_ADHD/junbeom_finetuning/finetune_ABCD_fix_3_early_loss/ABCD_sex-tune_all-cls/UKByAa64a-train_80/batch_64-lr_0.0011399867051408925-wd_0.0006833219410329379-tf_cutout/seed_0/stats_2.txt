"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 67.25588417053223, "training_acc": 53.75, "val_loss": 694.7892761230469, "val_acc": 50.0, "val_auroc": 0.75, "time": 18.37}
{"epoch": 1, "training_loss": 2839.8892822265625, "training_acc": 52.5, "val_loss": 14.746465682983398, "val_acc": 50.0, "val_auroc": 0.29, "time": 35.94}
{"epoch": 2, "training_loss": 124.10094451904297, "training_acc": 50.0, "val_loss": 29.235475063323975, "val_acc": 50.0, "val_auroc": 0.24, "time": 53.29}
{"epoch": 3, "training_loss": 103.1337890625, "training_acc": 52.5, "val_loss": 14.256305694580078, "val_acc": 50.0, "val_auroc": 0.14, "time": 70.82}
{"epoch": 4, "training_loss": 57.37175178527832, "training_acc": 47.5, "val_loss": 14.594879150390625, "val_acc": 50.0, "val_auroc": 0.23, "time": 87.81}
{"epoch": 5, "training_loss": 58.25302314758301, "training_acc": 50.0, "val_loss": 16.315529346466064, "val_acc": 50.0, "val_auroc": 0.24, "time": 104.56}
{"epoch": 6, "training_loss": 64.4004135131836, "training_acc": 45.0, "val_loss": 14.509505033493042, "val_acc": 50.0, "val_auroc": 0.25, "time": 121.92}
{"epoch": 7, "training_loss": 56.694406509399414, "training_acc": 52.5, "val_loss": 14.028936624526978, "val_acc": 50.0, "val_auroc": 0.26, "time": 139.37}
{"epoch": 8, "training_loss": 55.201894760131836, "training_acc": 52.5, "val_loss": 14.511923789978027, "val_acc": 50.0, "val_auroc": 0.72, "time": 156.17}
{"epoch": 9, "training_loss": 59.07055950164795, "training_acc": 47.5, "val_loss": 13.872889280319214, "val_acc": 50.0, "val_auroc": 0.51, "time": 173.28}
{"epoch": 10, "training_loss": 55.38165283203125, "training_acc": 50.0, "val_loss": 14.680490493774414, "val_acc": 50.0, "val_auroc": 0.26, "time": 190.59}
{"epoch": 11, "training_loss": 57.3692741394043, "training_acc": 52.5, "val_loss": 14.257711172103882, "val_acc": 50.0, "val_auroc": 0.26, "time": 207.64}
{"epoch": 12, "training_loss": 55.9026517868042, "training_acc": 52.5, "val_loss": 13.87454867362976, "val_acc": 50.0, "val_auroc": 0.28, "time": 224.47}
{"epoch": 13, "training_loss": 55.50826072692871, "training_acc": 47.5, "val_loss": 13.93875241279602, "val_acc": 50.0, "val_auroc": 0.73, "time": 241.32}
{"epoch": 14, "training_loss": 56.10510063171387, "training_acc": 47.5, "val_loss": 13.890585899353027, "val_acc": 50.0, "val_auroc": 0.3, "time": 258.12}
{"epoch": 15, "training_loss": 55.22780227661133, "training_acc": 52.5, "val_loss": 14.699214696884155, "val_acc": 50.0, "val_auroc": 0.28, "time": 274.98}
{"epoch": 16, "training_loss": 57.519484519958496, "training_acc": 52.5, "val_loss": 14.555965662002563, "val_acc": 50.0, "val_auroc": 0.31, "time": 291.66}
{"epoch": 17, "training_loss": 56.74421405792236, "training_acc": 52.5, "val_loss": 13.917347192764282, "val_acc": 50.0, "val_auroc": 0.34, "time": 308.53}
{"epoch": 18, "training_loss": 55.184139251708984, "training_acc": 55.0, "val_loss": 13.914371728897095, "val_acc": 50.0, "val_auroc": 0.68, "time": 325.16}
{"epoch": 19, "training_loss": 55.97664451599121, "training_acc": 47.5, "val_loss": 13.953951597213745, "val_acc": 50.0, "val_auroc": 0.72, "time": 341.93}
{"epoch": 20, "training_loss": 56.19333076477051, "training_acc": 47.5, "val_loss": 13.869688510894775, "val_acc": 50.0, "val_auroc": 0.73, "time": 359.19}
{"epoch": 21, "training_loss": 55.53025436401367, "training_acc": 50.0, "val_loss": 13.918393850326538, "val_acc": 50.0, "val_auroc": 0.35, "time": 376.05}
{"epoch": 22, "training_loss": 55.32342338562012, "training_acc": 52.5, "val_loss": 14.07190203666687, "val_acc": 50.0, "val_auroc": 0.33, "time": 392.81}
{"epoch": 23, "training_loss": 55.668731689453125, "training_acc": 52.5, "val_loss": 14.095155000686646, "val_acc": 50.0, "val_auroc": 0.36, "time": 409.28}
{"epoch": 24, "training_loss": 55.74620246887207, "training_acc": 52.5, "val_loss": 14.068634510040283, "val_acc": 50.0, "val_auroc": 0.38, "time": 424.89}
{"epoch": 25, "training_loss": 55.65378761291504, "training_acc": 52.5, "val_loss": 13.995558023452759, "val_acc": 50.0, "val_auroc": 0.37, "time": 441.82}
{"epoch": 26, "training_loss": 55.709227561950684, "training_acc": 52.5, "val_loss": 13.977276086807251, "val_acc": 50.0, "val_auroc": 0.37, "time": 458.56}
{"epoch": 27, "training_loss": 55.44063949584961, "training_acc": 52.5, "val_loss": 14.068498611450195, "val_acc": 50.0, "val_auroc": 0.37, "time": 474.88}
{"epoch": 28, "training_loss": 55.83444786071777, "training_acc": 52.5, "val_loss": 13.905222415924072, "val_acc": 50.0, "val_auroc": 0.45, "time": 491.77}
{"epoch": 29, "training_loss": 55.44991111755371, "training_acc": 50.0, "val_loss": 13.869513273239136, "val_acc": 50.0, "val_auroc": 0.8, "time": 509.12}
{"epoch": 30, "training_loss": 55.720004081726074, "training_acc": 47.5, "val_loss": 13.858699798583984, "val_acc": 50.0, "val_auroc": 0.79, "time": 526.64}
{"epoch": 31, "training_loss": 55.684146881103516, "training_acc": 45.0, "val_loss": 13.854351043701172, "val_acc": 50.0, "val_auroc": 0.79, "time": 544.36}
{"epoch": 32, "training_loss": 55.40760040283203, "training_acc": 52.5, "val_loss": 13.857618570327759, "val_acc": 50.0, "val_auroc": 0.85, "time": 561.05}
{"epoch": 33, "training_loss": 55.35061454772949, "training_acc": 52.5, "val_loss": 13.85064959526062, "val_acc": 50.0, "val_auroc": 0.8, "time": 578.5}
{"epoch": 34, "training_loss": 55.43315410614014, "training_acc": 52.5, "val_loss": 13.860095739364624, "val_acc": 50.0, "val_auroc": 0.87, "time": 595.5}
{"epoch": 35, "training_loss": 55.546284675598145, "training_acc": 52.5, "val_loss": 13.882372379302979, "val_acc": 50.0, "val_auroc": 0.97, "time": 612.32}
{"epoch": 36, "training_loss": 55.31344413757324, "training_acc": 52.5, "val_loss": 13.854120969772339, "val_acc": 50.0, "val_auroc": 0.88, "time": 628.87}
{"epoch": 37, "training_loss": 55.34398078918457, "training_acc": 52.5, "val_loss": 13.84450078010559, "val_acc": 50.0, "val_auroc": 0.82, "time": 646.07}
{"epoch": 38, "training_loss": 55.51675605773926, "training_acc": 51.25, "val_loss": 13.84453535079956, "val_acc": 50.0, "val_auroc": 0.81, "time": 662.77}
{"epoch": 39, "training_loss": 55.441040992736816, "training_acc": 47.5, "val_loss": 13.857349157333374, "val_acc": 50.0, "val_auroc": 0.83, "time": 679.53}
{"epoch": 40, "training_loss": 55.44377613067627, "training_acc": 52.5, "val_loss": 13.86926531791687, "val_acc": 50.0, "val_auroc": 0.85, "time": 696.25}
{"epoch": 41, "training_loss": 55.297372817993164, "training_acc": 52.5, "val_loss": 13.850314617156982, "val_acc": 50.0, "val_auroc": 0.79, "time": 713.1}
{"epoch": 42, "training_loss": 55.456295013427734, "training_acc": 46.25, "val_loss": 13.846567869186401, "val_acc": 50.0, "val_auroc": 0.8, "time": 729.79}
{"epoch": 43, "training_loss": 55.39653205871582, "training_acc": 55.0, "val_loss": 13.857120275497437, "val_acc": 50.0, "val_auroc": 0.83, "time": 746.56}
{"epoch": 44, "training_loss": 55.34272289276123, "training_acc": 52.5, "val_loss": 13.870939016342163, "val_acc": 50.0, "val_auroc": 0.72, "time": 763.12}
{"epoch": 45, "training_loss": 55.32641410827637, "training_acc": 52.5, "val_loss": 13.877862691879272, "val_acc": 50.0, "val_auroc": 0.72, "time": 779.72}
{"epoch": 46, "training_loss": 55.32359600067139, "training_acc": 52.5, "val_loss": 13.882699012756348, "val_acc": 50.0, "val_auroc": 0.76, "time": 797.06}
{"epoch": 47, "training_loss": 55.32585525512695, "training_acc": 52.5, "val_loss": 13.891534805297852, "val_acc": 50.0, "val_auroc": 0.72, "time": 814.75}
{"epoch": 48, "training_loss": 55.36476230621338, "training_acc": 52.5, "val_loss": 13.909245729446411, "val_acc": 50.0, "val_auroc": 0.7, "time": 831.3}
{"epoch": 49, "training_loss": 55.347578048706055, "training_acc": 52.5, "val_loss": 13.952817916870117, "val_acc": 50.0, "val_auroc": 0.66, "time": 847.86}
{"epoch": 50, "training_loss": 55.406742095947266, "training_acc": 52.5, "val_loss": 13.940919637680054, "val_acc": 50.0, "val_auroc": 0.71, "time": 863.16}
{"epoch": 51, "training_loss": 55.36552429199219, "training_acc": 52.5, "val_loss": 13.895211219787598, "val_acc": 50.0, "val_auroc": 0.73, "time": 878.58}
{"epoch": 52, "training_loss": 55.38942813873291, "training_acc": 52.5, "val_loss": 13.870354890823364, "val_acc": 50.0, "val_auroc": 0.75, "time": 895.19}
{"epoch": 53, "training_loss": 55.30940914154053, "training_acc": 52.5, "val_loss": 13.869082927703857, "val_acc": 50.0, "val_auroc": 0.74, "time": 911.85}
{"epoch": 54, "training_loss": 55.30710411071777, "training_acc": 52.5, "val_loss": 13.875200748443604, "val_acc": 50.0, "val_auroc": 0.72, "time": 927.79}
{"epoch": 55, "training_loss": 55.28029155731201, "training_acc": 52.5, "val_loss": 13.91891598701477, "val_acc": 50.0, "val_auroc": 0.68, "time": 944.41}
{"epoch": 56, "training_loss": 55.37434196472168, "training_acc": 52.5, "val_loss": 13.986451625823975, "val_acc": 50.0, "val_auroc": 0.62, "time": 961.04}
