"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.382354736328125, "training_acc": 52.5, "val_loss": 13.928302526473999, "val_acc": 50.0, "val_auroc": 0.5, "time": 19.08}
{"epoch": 1, "training_loss": 55.43244171142578, "training_acc": 52.5, "val_loss": 13.951026201248169, "val_acc": 50.0, "val_auroc": 0.39, "time": 36.13}
{"epoch": 2, "training_loss": 55.31121253967285, "training_acc": 52.5, "val_loss": 13.965975046157837, "val_acc": 50.0, "val_auroc": 0.4, "time": 54.26}
{"epoch": 3, "training_loss": 55.130263328552246, "training_acc": 52.5, "val_loss": 13.918254375457764, "val_acc": 50.0, "val_auroc": 0.41, "time": 79.58}
{"epoch": 4, "training_loss": 55.12490463256836, "training_acc": 52.5, "val_loss": 13.872240781784058, "val_acc": 50.0, "val_auroc": 0.52, "time": 98.04}
{"epoch": 5, "training_loss": 55.01533126831055, "training_acc": 52.5, "val_loss": 13.87593150138855, "val_acc": 50.0, "val_auroc": 0.48, "time": 116.52}
{"epoch": 6, "training_loss": 54.94674205780029, "training_acc": 52.5, "val_loss": 13.9164400100708, "val_acc": 50.0, "val_auroc": 0.46, "time": 135.99}
{"epoch": 7, "training_loss": 54.79321479797363, "training_acc": 52.5, "val_loss": 13.96524429321289, "val_acc": 50.0, "val_auroc": 0.44, "time": 157.25}
{"epoch": 8, "training_loss": 54.74509239196777, "training_acc": 52.5, "val_loss": 13.946069478988647, "val_acc": 50.0, "val_auroc": 0.4, "time": 174.09}
{"epoch": 9, "training_loss": 54.56511878967285, "training_acc": 52.5, "val_loss": 13.857930898666382, "val_acc": 50.0, "val_auroc": 0.54, "time": 191.16}
{"epoch": 10, "training_loss": 54.78899574279785, "training_acc": 52.5, "val_loss": 13.8498055934906, "val_acc": 50.0, "val_auroc": 0.6, "time": 209.98}
{"epoch": 11, "training_loss": 54.629987716674805, "training_acc": 52.5, "val_loss": 13.885281085968018, "val_acc": 50.0, "val_auroc": 0.43, "time": 230.18}
{"epoch": 12, "training_loss": 54.330594062805176, "training_acc": 52.5, "val_loss": 13.936446905136108, "val_acc": 50.0, "val_auroc": 0.4, "time": 247.36}
{"epoch": 13, "training_loss": 54.28994083404541, "training_acc": 52.5, "val_loss": 13.918877840042114, "val_acc": 50.0, "val_auroc": 0.4, "time": 265.5}
{"epoch": 14, "training_loss": 54.16640853881836, "training_acc": 52.5, "val_loss": 13.903255462646484, "val_acc": 50.0, "val_auroc": 0.42, "time": 282.7}
{"epoch": 15, "training_loss": 54.08388328552246, "training_acc": 52.5, "val_loss": 13.89011263847351, "val_acc": 50.0, "val_auroc": 0.42, "time": 302.08}
{"epoch": 16, "training_loss": 53.65922737121582, "training_acc": 53.75, "val_loss": 13.899950981140137, "val_acc": 50.0, "val_auroc": 0.49, "time": 318.41}
{"epoch": 17, "training_loss": 53.6821174621582, "training_acc": 52.5, "val_loss": 13.908175230026245, "val_acc": 50.0, "val_auroc": 0.53, "time": 334.98}
{"epoch": 18, "training_loss": 53.27586555480957, "training_acc": 52.5, "val_loss": 13.922975063323975, "val_acc": 50.0, "val_auroc": 0.44, "time": 352.41}
{"epoch": 19, "training_loss": 53.247039794921875, "training_acc": 58.75, "val_loss": 13.835210800170898, "val_acc": 50.0, "val_auroc": 0.49, "time": 372.08}
{"epoch": 20, "training_loss": 53.28225517272949, "training_acc": 81.25, "val_loss": 13.88273000717163, "val_acc": 50.0, "val_auroc": 0.42, "time": 389.5}
{"epoch": 21, "training_loss": 52.77277183532715, "training_acc": 62.5, "val_loss": 13.898358345031738, "val_acc": 50.0, "val_auroc": 0.5, "time": 406.96}
{"epoch": 22, "training_loss": 52.91464138031006, "training_acc": 55.0, "val_loss": 13.901292085647583, "val_acc": 50.0, "val_auroc": 0.39, "time": 423.91}
{"epoch": 23, "training_loss": 52.22246074676514, "training_acc": 71.25, "val_loss": 13.866018056869507, "val_acc": 50.0, "val_auroc": 0.46, "time": 441.49}
{"epoch": 24, "training_loss": 51.95471382141113, "training_acc": 80.0, "val_loss": 13.904260396957397, "val_acc": 50.0, "val_auroc": 0.5, "time": 457.29}
{"epoch": 25, "training_loss": 52.33553981781006, "training_acc": 53.75, "val_loss": 13.894742727279663, "val_acc": 50.0, "val_auroc": 0.51, "time": 473.26}
{"epoch": 26, "training_loss": 52.1360387802124, "training_acc": 61.25, "val_loss": 13.870012760162354, "val_acc": 50.0, "val_auroc": 0.49, "time": 489.88}
{"epoch": 27, "training_loss": 51.47857475280762, "training_acc": 80.0, "val_loss": 14.005547761917114, "val_acc": 50.0, "val_auroc": 0.43, "time": 508.04}
{"epoch": 28, "training_loss": 51.12419509887695, "training_acc": 58.75, "val_loss": 13.990691900253296, "val_acc": 50.0, "val_auroc": 0.41, "time": 525.34}
{"epoch": 29, "training_loss": 50.80371284484863, "training_acc": 78.75, "val_loss": 14.012113809585571, "val_acc": 50.0, "val_auroc": 0.39, "time": 542.69}
{"epoch": 30, "training_loss": 50.41795253753662, "training_acc": 76.25, "val_loss": 14.016174077987671, "val_acc": 50.0, "val_auroc": 0.47, "time": 560.85}
{"epoch": 31, "training_loss": 50.163503646850586, "training_acc": 62.5, "val_loss": 13.908623456954956, "val_acc": 50.0, "val_auroc": 0.49, "time": 578.62}
{"epoch": 32, "training_loss": 49.60028076171875, "training_acc": 86.25, "val_loss": 13.942465782165527, "val_acc": 50.0, "val_auroc": 0.49, "time": 594.71}
{"epoch": 33, "training_loss": 49.09599685668945, "training_acc": 86.25, "val_loss": 13.962059020996094, "val_acc": 50.0, "val_auroc": 0.5, "time": 610.71}
{"epoch": 34, "training_loss": 49.17603874206543, "training_acc": 73.75, "val_loss": 13.894060850143433, "val_acc": 50.0, "val_auroc": 0.5, "time": 628.45}
{"epoch": 35, "training_loss": 48.14333534240723, "training_acc": 85.0, "val_loss": 13.784666061401367, "val_acc": 50.0, "val_auroc": 0.56, "time": 645.72}
{"epoch": 36, "training_loss": 47.154916763305664, "training_acc": 92.5, "val_loss": 13.818291425704956, "val_acc": 50.0, "val_auroc": 0.59, "time": 662.7}
{"epoch": 37, "training_loss": 46.639652252197266, "training_acc": 80.0, "val_loss": 13.777793645858765, "val_acc": 50.0, "val_auroc": 0.56, "time": 679.23}
{"epoch": 38, "training_loss": 46.19021987915039, "training_acc": 88.75, "val_loss": 13.78628134727478, "val_acc": 50.0, "val_auroc": 0.58, "time": 696.01}
{"epoch": 39, "training_loss": 45.81840991973877, "training_acc": 78.75, "val_loss": 13.84753704071045, "val_acc": 50.0, "val_auroc": 0.56, "time": 714.61}
{"epoch": 40, "training_loss": 47.03350257873535, "training_acc": 86.25, "val_loss": 13.760209083557129, "val_acc": 50.0, "val_auroc": 0.59, "time": 731.65}
{"epoch": 41, "training_loss": 42.00536632537842, "training_acc": 97.5, "val_loss": 13.853881359100342, "val_acc": 45.0, "val_auroc": 0.55, "time": 747.98}
{"epoch": 42, "training_loss": 44.2085018157959, "training_acc": 88.75, "val_loss": 13.95951509475708, "val_acc": 50.0, "val_auroc": 0.62, "time": 765.08}
{"epoch": 43, "training_loss": 44.770381927490234, "training_acc": 78.75, "val_loss": 13.921704292297363, "val_acc": 55.0, "val_auroc": 0.57, "time": 784.8}
{"epoch": 44, "training_loss": 46.416791915893555, "training_acc": 80.0, "val_loss": 13.765925168991089, "val_acc": 55.0, "val_auroc": 0.56, "time": 801.61}
{"epoch": 45, "training_loss": 41.158310890197754, "training_acc": 92.5, "val_loss": 13.782416582107544, "val_acc": 55.0, "val_auroc": 0.58, "time": 818.13}
{"epoch": 46, "training_loss": 40.02432823181152, "training_acc": 96.25, "val_loss": 13.76325011253357, "val_acc": 50.0, "val_auroc": 0.58, "time": 835.43}
{"epoch": 47, "training_loss": 39.33039665222168, "training_acc": 100.0, "val_loss": 13.883609771728516, "val_acc": 55.0, "val_auroc": 0.55, "time": 853.32}
{"epoch": 48, "training_loss": 39.20906925201416, "training_acc": 97.5, "val_loss": 13.774231672286987, "val_acc": 55.0, "val_auroc": 0.56, "time": 869.7}
{"epoch": 49, "training_loss": 37.258399963378906, "training_acc": 98.75, "val_loss": 13.708221912384033, "val_acc": 55.0, "val_auroc": 0.56, "time": 886.85}
{"epoch": 50, "training_loss": 36.33426856994629, "training_acc": 100.0, "val_loss": 13.662712574005127, "val_acc": 55.0, "val_auroc": 0.58, "time": 904.88}
{"epoch": 51, "training_loss": 35.42025852203369, "training_acc": 100.0, "val_loss": 13.598817586898804, "val_acc": 55.0, "val_auroc": 0.58, "time": 922.43}
{"epoch": 52, "training_loss": 35.48484230041504, "training_acc": 100.0, "val_loss": 13.8767671585083, "val_acc": 55.0, "val_auroc": 0.62, "time": 939.17}
{"epoch": 53, "training_loss": 34.87690877914429, "training_acc": 98.75, "val_loss": 13.694425821304321, "val_acc": 55.0, "val_auroc": 0.55, "time": 956.05}
{"epoch": 54, "training_loss": 34.84221172332764, "training_acc": 98.75, "val_loss": 14.22007441520691, "val_acc": 55.0, "val_auroc": 0.64, "time": 972.89}
{"epoch": 55, "training_loss": 36.723177909851074, "training_acc": 92.5, "val_loss": 13.657993078231812, "val_acc": 55.0, "val_auroc": 0.58, "time": 990.01}
{"epoch": 56, "training_loss": 33.1743860244751, "training_acc": 100.0, "val_loss": 14.129092693328857, "val_acc": 55.0, "val_auroc": 0.61, "time": 1008.36}
{"epoch": 57, "training_loss": 32.6181640625, "training_acc": 97.5, "val_loss": 13.797944784164429, "val_acc": 60.0, "val_auroc": 0.62, "time": 1025.6}
{"epoch": 58, "training_loss": 34.728829860687256, "training_acc": 95.0, "val_loss": 14.562873840332031, "val_acc": 55.0, "val_auroc": 0.65, "time": 1043.12}
{"epoch": 59, "training_loss": 34.8348503112793, "training_acc": 92.5, "val_loss": 13.677539825439453, "val_acc": 55.0, "val_auroc": 0.61, "time": 1060.83}
{"epoch": 60, "training_loss": 31.742679119110107, "training_acc": 100.0, "val_loss": 14.271970987319946, "val_acc": 55.0, "val_auroc": 0.64, "time": 1078.49}
{"epoch": 61, "training_loss": 31.122305870056152, "training_acc": 97.5, "val_loss": 13.719925880432129, "val_acc": 55.0, "val_auroc": 0.59, "time": 1095.65}
{"epoch": 62, "training_loss": 29.95553493499756, "training_acc": 100.0, "val_loss": 13.992691040039062, "val_acc": 50.0, "val_auroc": 0.59, "time": 1116.11}
{"epoch": 63, "training_loss": 29.100635528564453, "training_acc": 100.0, "val_loss": 13.957136869430542, "val_acc": 55.0, "val_auroc": 0.58, "time": 1133.56}
{"epoch": 64, "training_loss": 28.14502239227295, "training_acc": 100.0, "val_loss": 13.788700103759766, "val_acc": 55.0, "val_auroc": 0.57, "time": 1152.48}
{"epoch": 65, "training_loss": 28.482409477233887, "training_acc": 98.75, "val_loss": 14.281449317932129, "val_acc": 50.0, "val_auroc": 0.61, "time": 1169.6}
{"epoch": 66, "training_loss": 28.799370288848877, "training_acc": 98.75, "val_loss": 13.963011503219604, "val_acc": 60.0, "val_auroc": 0.55, "time": 1188.48}
{"epoch": 67, "training_loss": 28.75480365753174, "training_acc": 100.0, "val_loss": 14.3639075756073, "val_acc": 50.0, "val_auroc": 0.58, "time": 1205.49}
{"epoch": 68, "training_loss": 27.44791030883789, "training_acc": 100.0, "val_loss": 13.993431329727173, "val_acc": 50.0, "val_auroc": 0.56, "time": 1224.26}
{"epoch": 69, "training_loss": 27.143805503845215, "training_acc": 100.0, "val_loss": 14.038002490997314, "val_acc": 50.0, "val_auroc": 0.57, "time": 1240.46}
{"epoch": 70, "training_loss": 26.257452964782715, "training_acc": 100.0, "val_loss": 14.424664974212646, "val_acc": 50.0, "val_auroc": 0.58, "time": 1258.22}
