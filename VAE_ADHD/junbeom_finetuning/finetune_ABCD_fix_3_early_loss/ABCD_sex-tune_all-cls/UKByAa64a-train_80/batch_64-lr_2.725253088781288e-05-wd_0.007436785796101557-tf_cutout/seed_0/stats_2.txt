"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.355956077575684, "training_acc": 52.5, "val_loss": 13.872573375701904, "val_acc": 50.0, "val_auroc": 0.52, "time": 19.01}
{"epoch": 1, "training_loss": 55.38776969909668, "training_acc": 52.5, "val_loss": 13.870967626571655, "val_acc": 50.0, "val_auroc": 0.52, "time": 36.9}
{"epoch": 2, "training_loss": 55.13753032684326, "training_acc": 52.5, "val_loss": 13.896175622940063, "val_acc": 50.0, "val_auroc": 0.39, "time": 54.23}
{"epoch": 3, "training_loss": 55.225830078125, "training_acc": 52.5, "val_loss": 13.897508382797241, "val_acc": 50.0, "val_auroc": 0.41, "time": 71.66}
{"epoch": 4, "training_loss": 55.163214683532715, "training_acc": 52.5, "val_loss": 13.90817403793335, "val_acc": 50.0, "val_auroc": 0.38, "time": 90.85}
{"epoch": 5, "training_loss": 55.114317893981934, "training_acc": 52.5, "val_loss": 13.897638320922852, "val_acc": 50.0, "val_auroc": 0.45, "time": 108.18}
{"epoch": 6, "training_loss": 55.32258415222168, "training_acc": 52.5, "val_loss": 13.866596221923828, "val_acc": 50.0, "val_auroc": 0.53, "time": 127.81}
{"epoch": 7, "training_loss": 55.12587547302246, "training_acc": 52.5, "val_loss": 13.871679306030273, "val_acc": 50.0, "val_auroc": 0.59, "time": 148.07}
{"epoch": 8, "training_loss": 55.060054779052734, "training_acc": 52.5, "val_loss": 13.841990232467651, "val_acc": 50.0, "val_auroc": 0.64, "time": 165.31}
{"epoch": 9, "training_loss": 54.82063674926758, "training_acc": 52.5, "val_loss": 13.815101385116577, "val_acc": 50.0, "val_auroc": 0.67, "time": 182.91}
{"epoch": 10, "training_loss": 54.752506256103516, "training_acc": 52.5, "val_loss": 13.794984817504883, "val_acc": 50.0, "val_auroc": 0.66, "time": 200.99}
{"epoch": 11, "training_loss": 54.6141471862793, "training_acc": 52.5, "val_loss": 13.791993856430054, "val_acc": 50.0, "val_auroc": 0.65, "time": 218.55}
{"epoch": 12, "training_loss": 54.53822135925293, "training_acc": 52.5, "val_loss": 13.837764263153076, "val_acc": 50.0, "val_auroc": 0.62, "time": 235.77}
{"epoch": 13, "training_loss": 54.46165370941162, "training_acc": 52.5, "val_loss": 13.833084106445312, "val_acc": 50.0, "val_auroc": 0.59, "time": 252.39}
{"epoch": 14, "training_loss": 54.33726978302002, "training_acc": 52.5, "val_loss": 13.822442293167114, "val_acc": 50.0, "val_auroc": 0.6, "time": 271.08}
{"epoch": 15, "training_loss": 54.256422996520996, "training_acc": 52.5, "val_loss": 13.839659690856934, "val_acc": 50.0, "val_auroc": 0.57, "time": 288.59}
{"epoch": 16, "training_loss": 53.93005180358887, "training_acc": 53.75, "val_loss": 13.86593222618103, "val_acc": 50.0, "val_auroc": 0.59, "time": 305.31}
{"epoch": 17, "training_loss": 54.27641677856445, "training_acc": 52.5, "val_loss": 13.848634958267212, "val_acc": 50.0, "val_auroc": 0.59, "time": 321.85}
{"epoch": 18, "training_loss": 53.813350677490234, "training_acc": 52.5, "val_loss": 13.79449725151062, "val_acc": 50.0, "val_auroc": 0.56, "time": 339.06}
{"epoch": 19, "training_loss": 53.84034538269043, "training_acc": 55.0, "val_loss": 13.787622451782227, "val_acc": 50.0, "val_auroc": 0.54, "time": 356.34}
{"epoch": 20, "training_loss": 53.72591209411621, "training_acc": 72.5, "val_loss": 13.75268816947937, "val_acc": 50.0, "val_auroc": 0.59, "time": 373.16}
{"epoch": 21, "training_loss": 53.19688606262207, "training_acc": 60.0, "val_loss": 13.782647848129272, "val_acc": 50.0, "val_auroc": 0.59, "time": 389.77}
{"epoch": 22, "training_loss": 53.49845027923584, "training_acc": 55.0, "val_loss": 13.738141059875488, "val_acc": 50.0, "val_auroc": 0.63, "time": 406.85}
{"epoch": 23, "training_loss": 52.74894332885742, "training_acc": 63.75, "val_loss": 13.700323104858398, "val_acc": 50.0, "val_auroc": 0.62, "time": 424.37}
{"epoch": 24, "training_loss": 52.552998542785645, "training_acc": 65.0, "val_loss": 13.791412115097046, "val_acc": 50.0, "val_auroc": 0.57, "time": 441.03}
{"epoch": 25, "training_loss": 52.162299156188965, "training_acc": 58.75, "val_loss": 13.8528573513031, "val_acc": 50.0, "val_auroc": 0.56, "time": 457.73}
{"epoch": 26, "training_loss": 52.620779037475586, "training_acc": 60.0, "val_loss": 13.898630142211914, "val_acc": 50.0, "val_auroc": 0.61, "time": 474.57}
{"epoch": 27, "training_loss": 53.17242431640625, "training_acc": 52.5, "val_loss": 13.838580846786499, "val_acc": 50.0, "val_auroc": 0.62, "time": 492.12}
{"epoch": 28, "training_loss": 52.89750957489014, "training_acc": 53.75, "val_loss": 13.790117502212524, "val_acc": 50.0, "val_auroc": 0.56, "time": 508.68}
{"epoch": 29, "training_loss": 53.98131561279297, "training_acc": 76.25, "val_loss": 13.789900541305542, "val_acc": 50.0, "val_auroc": 0.58, "time": 525.07}
{"epoch": 30, "training_loss": 54.130855560302734, "training_acc": 63.75, "val_loss": 13.747652769088745, "val_acc": 50.0, "val_auroc": 0.6, "time": 541.68}
{"epoch": 31, "training_loss": 51.883628845214844, "training_acc": 72.5, "val_loss": 13.939038515090942, "val_acc": 50.0, "val_auroc": 0.58, "time": 560.21}
{"epoch": 32, "training_loss": 52.29716873168945, "training_acc": 52.5, "val_loss": 13.721455335617065, "val_acc": 50.0, "val_auroc": 0.62, "time": 576.73}
{"epoch": 33, "training_loss": 51.06429576873779, "training_acc": 77.5, "val_loss": 13.71387004852295, "val_acc": 50.0, "val_auroc": 0.61, "time": 592.82}
{"epoch": 34, "training_loss": 51.018492698669434, "training_acc": 87.5, "val_loss": 13.758929967880249, "val_acc": 50.0, "val_auroc": 0.58, "time": 609.58}
{"epoch": 35, "training_loss": 50.89240837097168, "training_acc": 66.25, "val_loss": 13.727799654006958, "val_acc": 50.0, "val_auroc": 0.59, "time": 626.48}
{"epoch": 36, "training_loss": 50.27838706970215, "training_acc": 71.25, "val_loss": 13.639076948165894, "val_acc": 50.0, "val_auroc": 0.68, "time": 643.26}
{"epoch": 37, "training_loss": 50.050384521484375, "training_acc": 86.25, "val_loss": 13.660902976989746, "val_acc": 50.0, "val_auroc": 0.63, "time": 659.71}
{"epoch": 38, "training_loss": 49.07371520996094, "training_acc": 88.75, "val_loss": 13.579849004745483, "val_acc": 50.0, "val_auroc": 0.66, "time": 677.35}
{"epoch": 39, "training_loss": 48.19950580596924, "training_acc": 81.25, "val_loss": 13.498473167419434, "val_acc": 50.0, "val_auroc": 0.67, "time": 694.61}
{"epoch": 40, "training_loss": 48.05881690979004, "training_acc": 92.5, "val_loss": 13.670252561569214, "val_acc": 50.0, "val_auroc": 0.61, "time": 711.46}
{"epoch": 41, "training_loss": 46.64280033111572, "training_acc": 90.0, "val_loss": 13.409236669540405, "val_acc": 50.0, "val_auroc": 0.65, "time": 728.36}
{"epoch": 42, "training_loss": 45.78334045410156, "training_acc": 92.5, "val_loss": 13.408294916152954, "val_acc": 50.0, "val_auroc": 0.62, "time": 745.5}
{"epoch": 43, "training_loss": 44.63157081604004, "training_acc": 91.25, "val_loss": 13.783262968063354, "val_acc": 50.0, "val_auroc": 0.61, "time": 762.27}
{"epoch": 44, "training_loss": 44.49109745025635, "training_acc": 90.0, "val_loss": 13.473141193389893, "val_acc": 50.0, "val_auroc": 0.62, "time": 779.16}
{"epoch": 45, "training_loss": 43.359251976013184, "training_acc": 88.75, "val_loss": 13.329795598983765, "val_acc": 50.0, "val_auroc": 0.63, "time": 795.95}
{"epoch": 46, "training_loss": 41.25232410430908, "training_acc": 95.0, "val_loss": 13.283494710922241, "val_acc": 50.0, "val_auroc": 0.62, "time": 813.32}
{"epoch": 47, "training_loss": 40.480730056762695, "training_acc": 95.0, "val_loss": 13.418055772781372, "val_acc": 50.0, "val_auroc": 0.62, "time": 830.27}
{"epoch": 48, "training_loss": 39.84744739532471, "training_acc": 97.5, "val_loss": 13.4630286693573, "val_acc": 50.0, "val_auroc": 0.58, "time": 846.93}
{"epoch": 49, "training_loss": 39.127543449401855, "training_acc": 95.0, "val_loss": 13.439644575119019, "val_acc": 60.0, "val_auroc": 0.6, "time": 864.11}
{"epoch": 50, "training_loss": 37.9246883392334, "training_acc": 96.25, "val_loss": 13.642445802688599, "val_acc": 65.0, "val_auroc": 0.6, "time": 881.97}
{"epoch": 51, "training_loss": 36.758002281188965, "training_acc": 97.5, "val_loss": 13.781931400299072, "val_acc": 60.0, "val_auroc": 0.55, "time": 899.74}
{"epoch": 52, "training_loss": 35.60726737976074, "training_acc": 98.75, "val_loss": 13.59275221824646, "val_acc": 55.0, "val_auroc": 0.58, "time": 916.56}
{"epoch": 53, "training_loss": 36.2170295715332, "training_acc": 96.25, "val_loss": 13.809946775436401, "val_acc": 55.0, "val_auroc": 0.56, "time": 932.79}
{"epoch": 54, "training_loss": 36.31125354766846, "training_acc": 98.75, "val_loss": 13.62383246421814, "val_acc": 60.0, "val_auroc": 0.58, "time": 949.8}
{"epoch": 55, "training_loss": 33.5569429397583, "training_acc": 98.75, "val_loss": 13.75403881072998, "val_acc": 55.0, "val_auroc": 0.58, "time": 966.79}
{"epoch": 56, "training_loss": 33.78200387954712, "training_acc": 100.0, "val_loss": 14.71051812171936, "val_acc": 65.0, "val_auroc": 0.57, "time": 984.52}
{"epoch": 57, "training_loss": 36.58127403259277, "training_acc": 95.0, "val_loss": 13.945940732955933, "val_acc": 60.0, "val_auroc": 0.58, "time": 1001.27}
{"epoch": 58, "training_loss": 32.02214431762695, "training_acc": 97.5, "val_loss": 14.099206924438477, "val_acc": 70.0, "val_auroc": 0.58, "time": 1018.04}
{"epoch": 59, "training_loss": 30.14398193359375, "training_acc": 100.0, "val_loss": 13.97909164428711, "val_acc": 60.0, "val_auroc": 0.57, "time": 1035.79}
{"epoch": 60, "training_loss": 30.083388328552246, "training_acc": 100.0, "val_loss": 14.101876020431519, "val_acc": 65.0, "val_auroc": 0.57, "time": 1054.74}
{"epoch": 61, "training_loss": 28.958045959472656, "training_acc": 98.75, "val_loss": 14.126818180084229, "val_acc": 60.0, "val_auroc": 0.56, "time": 1071.32}
{"epoch": 62, "training_loss": 28.718536376953125, "training_acc": 100.0, "val_loss": 14.639256000518799, "val_acc": 60.0, "val_auroc": 0.54, "time": 1087.92}
{"epoch": 63, "training_loss": 28.571287155151367, "training_acc": 100.0, "val_loss": 14.297628402709961, "val_acc": 55.0, "val_auroc": 0.57, "time": 1104.7}
{"epoch": 64, "training_loss": 28.91718578338623, "training_acc": 98.75, "val_loss": 15.28186321258545, "val_acc": 50.0, "val_auroc": 0.56, "time": 1125.03}
{"epoch": 65, "training_loss": 28.692376136779785, "training_acc": 100.0, "val_loss": 14.106016159057617, "val_acc": 60.0, "val_auroc": 0.54, "time": 1141.67}
