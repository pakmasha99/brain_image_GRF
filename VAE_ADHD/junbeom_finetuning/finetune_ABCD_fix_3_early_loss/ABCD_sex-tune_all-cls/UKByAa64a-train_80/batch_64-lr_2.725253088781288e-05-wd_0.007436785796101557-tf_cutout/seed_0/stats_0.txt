"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.496596336364746, "training_acc": 52.5, "val_loss": 13.939074277877808, "val_acc": 50.0, "val_auroc": 0.25, "time": 18.78}
{"epoch": 1, "training_loss": 55.30026817321777, "training_acc": 52.5, "val_loss": 13.893253803253174, "val_acc": 50.0, "val_auroc": 0.43, "time": 36.57}
{"epoch": 2, "training_loss": 55.37355422973633, "training_acc": 52.5, "val_loss": 13.887237310409546, "val_acc": 50.0, "val_auroc": 0.49, "time": 54.66}
{"epoch": 3, "training_loss": 55.32425308227539, "training_acc": 52.5, "val_loss": 13.878337144851685, "val_acc": 50.0, "val_auroc": 0.48, "time": 72.13}
{"epoch": 4, "training_loss": 55.413291931152344, "training_acc": 52.5, "val_loss": 13.878967761993408, "val_acc": 50.0, "val_auroc": 0.51, "time": 89.61}
{"epoch": 5, "training_loss": 55.22407341003418, "training_acc": 52.5, "val_loss": 13.899301290512085, "val_acc": 50.0, "val_auroc": 0.39, "time": 107.97}
{"epoch": 6, "training_loss": 55.04054832458496, "training_acc": 52.5, "val_loss": 13.891980648040771, "val_acc": 50.0, "val_auroc": 0.42, "time": 127.18}
{"epoch": 7, "training_loss": 54.91238021850586, "training_acc": 53.75, "val_loss": 13.893016576766968, "val_acc": 50.0, "val_auroc": 0.42, "time": 143.94}
{"epoch": 8, "training_loss": 54.77031707763672, "training_acc": 57.5, "val_loss": 13.855549097061157, "val_acc": 50.0, "val_auroc": 0.53, "time": 161.07}
{"epoch": 9, "training_loss": 54.750643730163574, "training_acc": 70.0, "val_loss": 13.863214254379272, "val_acc": 50.0, "val_auroc": 0.52, "time": 178.96}
{"epoch": 10, "training_loss": 54.447832107543945, "training_acc": 76.25, "val_loss": 13.849397897720337, "val_acc": 50.0, "val_auroc": 0.57, "time": 197.36}
{"epoch": 11, "training_loss": 54.343305587768555, "training_acc": 63.75, "val_loss": 13.838871717453003, "val_acc": 50.0, "val_auroc": 0.56, "time": 213.86}
{"epoch": 12, "training_loss": 54.06302547454834, "training_acc": 65.0, "val_loss": 13.782399892807007, "val_acc": 50.0, "val_auroc": 0.58, "time": 231.69}
{"epoch": 13, "training_loss": 54.00655746459961, "training_acc": 67.5, "val_loss": 13.964627981185913, "val_acc": 50.0, "val_auroc": 0.45, "time": 249.15}
{"epoch": 14, "training_loss": 54.18637561798096, "training_acc": 52.5, "val_loss": 13.96984338760376, "val_acc": 50.0, "val_auroc": 0.49, "time": 266.29}
{"epoch": 15, "training_loss": 53.61737632751465, "training_acc": 52.5, "val_loss": 13.831151723861694, "val_acc": 50.0, "val_auroc": 0.58, "time": 283.68}
{"epoch": 16, "training_loss": 52.942453384399414, "training_acc": 56.25, "val_loss": 14.05497431755066, "val_acc": 50.0, "val_auroc": 0.51, "time": 300.43}
{"epoch": 17, "training_loss": 52.67843055725098, "training_acc": 52.5, "val_loss": 13.80927324295044, "val_acc": 50.0, "val_auroc": 0.55, "time": 318.4}
{"epoch": 18, "training_loss": 52.39762783050537, "training_acc": 76.25, "val_loss": 14.088340997695923, "val_acc": 50.0, "val_auroc": 0.48, "time": 334.82}
{"epoch": 19, "training_loss": 51.71908473968506, "training_acc": 60.0, "val_loss": 13.902077674865723, "val_acc": 50.0, "val_auroc": 0.46, "time": 351.42}
{"epoch": 20, "training_loss": 55.03441333770752, "training_acc": 55.0, "val_loss": 13.952959775924683, "val_acc": 50.0, "val_auroc": 0.34, "time": 368.84}
{"epoch": 21, "training_loss": 55.6270809173584, "training_acc": 52.5, "val_loss": 13.959007263183594, "val_acc": 50.0, "val_auroc": 0.26, "time": 385.62}
{"epoch": 22, "training_loss": 55.15142631530762, "training_acc": 50.0, "val_loss": 13.956729173660278, "val_acc": 50.0, "val_auroc": 0.25, "time": 403.35}
{"epoch": 23, "training_loss": 54.51979637145996, "training_acc": 78.75, "val_loss": 13.975967168807983, "val_acc": 50.0, "val_auroc": 0.28, "time": 422.52}
{"epoch": 24, "training_loss": 54.325782775878906, "training_acc": 53.75, "val_loss": 13.994572162628174, "val_acc": 50.0, "val_auroc": 0.36, "time": 439.7}
{"epoch": 25, "training_loss": 53.777581214904785, "training_acc": 53.75, "val_loss": 13.975063562393188, "val_acc": 50.0, "val_auroc": 0.38, "time": 457.88}
{"epoch": 26, "training_loss": 53.55144023895264, "training_acc": 65.0, "val_loss": 13.98455023765564, "val_acc": 50.0, "val_auroc": 0.41, "time": 475.06}
{"epoch": 27, "training_loss": 52.623046875, "training_acc": 75.0, "val_loss": 14.027608633041382, "val_acc": 50.0, "val_auroc": 0.4, "time": 491.33}
{"epoch": 28, "training_loss": 52.29548454284668, "training_acc": 65.0, "val_loss": 13.941071033477783, "val_acc": 50.0, "val_auroc": 0.41, "time": 508.06}
{"epoch": 29, "training_loss": 51.64271545410156, "training_acc": 83.75, "val_loss": 13.997081518173218, "val_acc": 50.0, "val_auroc": 0.42, "time": 525.07}
{"epoch": 30, "training_loss": 50.886253356933594, "training_acc": 75.0, "val_loss": 14.160248041152954, "val_acc": 50.0, "val_auroc": 0.39, "time": 542.23}
{"epoch": 31, "training_loss": 50.54797172546387, "training_acc": 70.0, "val_loss": 13.925013542175293, "val_acc": 50.0, "val_auroc": 0.52, "time": 559.58}
