"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.511199951171875, "training_acc": 48.75, "val_loss": 13.808265924453735, "val_acc": 55.0, "val_auroc": 0.414, "time": 19.78}
{"epoch": 1, "training_loss": 55.41505241394043, "training_acc": 52.5, "val_loss": 13.825727701187134, "val_acc": 55.0, "val_auroc": 0.465, "time": 37.02}
{"epoch": 2, "training_loss": 55.27607250213623, "training_acc": 53.75, "val_loss": 13.833162784576416, "val_acc": 55.0, "val_auroc": 0.465, "time": 54.35}
{"epoch": 3, "training_loss": 55.201364517211914, "training_acc": 52.5, "val_loss": 13.867599964141846, "val_acc": 55.0, "val_auroc": 0.384, "time": 72.02}
{"epoch": 4, "training_loss": 55.089454650878906, "training_acc": 51.25, "val_loss": 13.796967267990112, "val_acc": 55.0, "val_auroc": 0.525, "time": 89.42}
{"epoch": 5, "training_loss": 54.944576263427734, "training_acc": 52.5, "val_loss": 13.770853281021118, "val_acc": 55.0, "val_auroc": 0.566, "time": 107.07}
{"epoch": 6, "training_loss": 54.83889675140381, "training_acc": 51.25, "val_loss": 13.798106908798218, "val_acc": 55.0, "val_auroc": 0.596, "time": 124.83}
{"epoch": 7, "training_loss": 54.91276741027832, "training_acc": 55.0, "val_loss": 13.8404381275177, "val_acc": 55.0, "val_auroc": 0.535, "time": 142.71}
{"epoch": 8, "training_loss": 55.06744194030762, "training_acc": 53.75, "val_loss": 13.85109543800354, "val_acc": 55.0, "val_auroc": 0.495, "time": 159.37}
{"epoch": 9, "training_loss": 54.78932476043701, "training_acc": 72.5, "val_loss": 13.790782690048218, "val_acc": 55.0, "val_auroc": 0.626, "time": 177.27}
{"epoch": 10, "training_loss": 54.64027976989746, "training_acc": 67.5, "val_loss": 13.68067979812622, "val_acc": 55.0, "val_auroc": 0.747, "time": 194.39}
{"epoch": 11, "training_loss": 54.395179748535156, "training_acc": 63.75, "val_loss": 13.691091537475586, "val_acc": 55.0, "val_auroc": 0.657, "time": 211.98}
{"epoch": 12, "training_loss": 54.33938980102539, "training_acc": 52.5, "val_loss": 13.710068464279175, "val_acc": 55.0, "val_auroc": 0.576, "time": 228.36}
{"epoch": 13, "training_loss": 54.31134796142578, "training_acc": 52.5, "val_loss": 13.73836874961853, "val_acc": 55.0, "val_auroc": 0.556, "time": 244.89}
{"epoch": 14, "training_loss": 54.007890701293945, "training_acc": 56.25, "val_loss": 13.793185949325562, "val_acc": 55.0, "val_auroc": 0.525, "time": 262.3}
{"epoch": 15, "training_loss": 53.670654296875, "training_acc": 71.25, "val_loss": 13.813613653182983, "val_acc": 55.0, "val_auroc": 0.444, "time": 279.61}
{"epoch": 16, "training_loss": 53.5496244430542, "training_acc": 58.75, "val_loss": 13.820186853408813, "val_acc": 55.0, "val_auroc": 0.434, "time": 296.82}
{"epoch": 17, "training_loss": 53.25655460357666, "training_acc": 58.75, "val_loss": 13.888250589370728, "val_acc": 55.0, "val_auroc": 0.455, "time": 313.72}
{"epoch": 18, "training_loss": 53.62864112854004, "training_acc": 80.0, "val_loss": 13.908737897872925, "val_acc": 55.0, "val_auroc": 0.475, "time": 330.37}
{"epoch": 19, "training_loss": 53.7235050201416, "training_acc": 73.75, "val_loss": 13.783906698226929, "val_acc": 55.0, "val_auroc": 0.475, "time": 347.4}
{"epoch": 20, "training_loss": 52.28295612335205, "training_acc": 75.0, "val_loss": 13.780663013458252, "val_acc": 55.0, "val_auroc": 0.424, "time": 364.18}
{"epoch": 21, "training_loss": 52.399757385253906, "training_acc": 65.0, "val_loss": 13.902581930160522, "val_acc": 55.0, "val_auroc": 0.465, "time": 381.23}
{"epoch": 22, "training_loss": 52.180673599243164, "training_acc": 75.0, "val_loss": 13.853205442428589, "val_acc": 55.0, "val_auroc": 0.455, "time": 397.94}
{"epoch": 23, "training_loss": 50.718010902404785, "training_acc": 90.0, "val_loss": 13.796992301940918, "val_acc": 55.0, "val_auroc": 0.475, "time": 414.66}
{"epoch": 24, "training_loss": 51.81412601470947, "training_acc": 65.0, "val_loss": 13.749406337738037, "val_acc": 55.0, "val_auroc": 0.495, "time": 432.64}
{"epoch": 25, "training_loss": 50.19321346282959, "training_acc": 73.75, "val_loss": 13.824535608291626, "val_acc": 55.0, "val_auroc": 0.485, "time": 449.96}
{"epoch": 26, "training_loss": 50.62551021575928, "training_acc": 70.0, "val_loss": 13.742090463638306, "val_acc": 55.0, "val_auroc": 0.525, "time": 467.4}
{"epoch": 27, "training_loss": 48.86424160003662, "training_acc": 81.25, "val_loss": 13.768357038497925, "val_acc": 55.0, "val_auroc": 0.525, "time": 484.58}
{"epoch": 28, "training_loss": 49.20322132110596, "training_acc": 71.25, "val_loss": 14.216461181640625, "val_acc": 55.0, "val_auroc": 0.434, "time": 501.83}
{"epoch": 29, "training_loss": 52.26325798034668, "training_acc": 62.5, "val_loss": 14.014294147491455, "val_acc": 55.0, "val_auroc": 0.525, "time": 519.94}
