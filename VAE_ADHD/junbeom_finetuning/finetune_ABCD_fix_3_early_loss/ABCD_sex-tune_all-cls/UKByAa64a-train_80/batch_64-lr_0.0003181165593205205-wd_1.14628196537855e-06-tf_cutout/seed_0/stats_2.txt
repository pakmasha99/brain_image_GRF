"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.80965614318848, "training_acc": 52.5, "val_loss": 13.939594030380249, "val_acc": 50.0, "val_auroc": 0.36, "time": 18.01}
{"epoch": 1, "training_loss": 55.513214111328125, "training_acc": 52.5, "val_loss": 13.893870115280151, "val_acc": 50.0, "val_auroc": 0.3, "time": 33.83}
{"epoch": 2, "training_loss": 55.36745262145996, "training_acc": 52.5, "val_loss": 13.97046446800232, "val_acc": 50.0, "val_auroc": 0.32, "time": 49.42}
{"epoch": 3, "training_loss": 55.6542911529541, "training_acc": 52.5, "val_loss": 14.019238948822021, "val_acc": 50.0, "val_auroc": 0.72, "time": 65.23}
{"epoch": 4, "training_loss": 55.58445167541504, "training_acc": 52.5, "val_loss": 13.909910917282104, "val_acc": 50.0, "val_auroc": 0.23, "time": 80.75}
{"epoch": 5, "training_loss": 55.41800308227539, "training_acc": 52.5, "val_loss": 13.879684209823608, "val_acc": 50.0, "val_auroc": 0.45, "time": 96.58}
{"epoch": 6, "training_loss": 55.46892738342285, "training_acc": 52.5, "val_loss": 13.986988067626953, "val_acc": 50.0, "val_auroc": 0.65, "time": 112.11}
{"epoch": 7, "training_loss": 55.50539016723633, "training_acc": 52.5, "val_loss": 14.12578821182251, "val_acc": 50.0, "val_auroc": 0.75, "time": 128.13}
{"epoch": 8, "training_loss": 55.86950874328613, "training_acc": 52.5, "val_loss": 13.926105499267578, "val_acc": 50.0, "val_auroc": 0.17, "time": 143.58}
{"epoch": 9, "training_loss": 55.335641860961914, "training_acc": 52.5, "val_loss": 13.8729989528656, "val_acc": 50.0, "val_auroc": 0.14, "time": 159.76}
{"epoch": 10, "training_loss": 55.604071617126465, "training_acc": 47.5, "val_loss": 13.868427276611328, "val_acc": 50.0, "val_auroc": 0.18, "time": 175.8}
{"epoch": 11, "training_loss": 55.47319030761719, "training_acc": 47.5, "val_loss": 13.885868787765503, "val_acc": 50.0, "val_auroc": 0.32, "time": 192.29}
{"epoch": 12, "training_loss": 55.39305019378662, "training_acc": 52.5, "val_loss": 13.958991765975952, "val_acc": 50.0, "val_auroc": 0.65, "time": 208.74}
{"epoch": 13, "training_loss": 55.450645446777344, "training_acc": 52.5, "val_loss": 13.942155838012695, "val_acc": 50.0, "val_auroc": 0.63, "time": 224.71}
{"epoch": 14, "training_loss": 55.39459037780762, "training_acc": 52.5, "val_loss": 13.891241550445557, "val_acc": 50.0, "val_auroc": 0.32, "time": 240.5}
{"epoch": 15, "training_loss": 55.52472114562988, "training_acc": 52.5, "val_loss": 13.885825872421265, "val_acc": 50.0, "val_auroc": 0.38, "time": 256.11}
{"epoch": 16, "training_loss": 55.297882080078125, "training_acc": 52.5, "val_loss": 13.979074954986572, "val_acc": 50.0, "val_auroc": 0.79, "time": 271.95}
{"epoch": 17, "training_loss": 55.55146408081055, "training_acc": 52.5, "val_loss": 14.080402851104736, "val_acc": 50.0, "val_auroc": 0.8, "time": 289.99}
{"epoch": 18, "training_loss": 55.729440689086914, "training_acc": 52.5, "val_loss": 13.988847732543945, "val_acc": 50.0, "val_auroc": 0.77, "time": 305.81}
{"epoch": 19, "training_loss": 55.41013813018799, "training_acc": 52.5, "val_loss": 13.876234292984009, "val_acc": 50.0, "val_auroc": 0.76, "time": 321.69}
{"epoch": 20, "training_loss": 55.42295837402344, "training_acc": 50.0, "val_loss": 13.864946365356445, "val_acc": 50.0, "val_auroc": 0.74, "time": 337.61}
{"epoch": 21, "training_loss": 55.54186820983887, "training_acc": 47.5, "val_loss": 13.863574266433716, "val_acc": 50.0, "val_auroc": 0.72, "time": 353.88}
{"epoch": 22, "training_loss": 55.479583740234375, "training_acc": 50.0, "val_loss": 13.869767189025879, "val_acc": 50.0, "val_auroc": 0.7, "time": 369.39}
{"epoch": 23, "training_loss": 55.31410312652588, "training_acc": 52.5, "val_loss": 13.927849531173706, "val_acc": 50.0, "val_auroc": 0.21, "time": 384.88}
{"epoch": 24, "training_loss": 55.334635734558105, "training_acc": 52.5, "val_loss": 14.044020175933838, "val_acc": 50.0, "val_auroc": 0.49, "time": 400.58}
{"epoch": 25, "training_loss": 55.63928031921387, "training_acc": 52.5, "val_loss": 14.125480651855469, "val_acc": 50.0, "val_auroc": 0.13, "time": 416.51}
{"epoch": 26, "training_loss": 55.8878288269043, "training_acc": 52.5, "val_loss": 14.138873815536499, "val_acc": 50.0, "val_auroc": 0.41, "time": 432.5}
{"epoch": 27, "training_loss": 55.886253356933594, "training_acc": 52.5, "val_loss": 14.121350049972534, "val_acc": 50.0, "val_auroc": 0.56, "time": 448.45}
{"epoch": 28, "training_loss": 55.803690910339355, "training_acc": 52.5, "val_loss": 13.975064754486084, "val_acc": 50.0, "val_auroc": 0.36, "time": 464.15}
{"epoch": 29, "training_loss": 55.51177501678467, "training_acc": 52.5, "val_loss": 13.86806607246399, "val_acc": 50.0, "val_auroc": 0.2, "time": 480.33}
{"epoch": 30, "training_loss": 55.43915939331055, "training_acc": 50.0, "val_loss": 13.866512775421143, "val_acc": 50.0, "val_auroc": 0.26, "time": 496.73}
{"epoch": 31, "training_loss": 55.53899002075195, "training_acc": 47.5, "val_loss": 13.8723886013031, "val_acc": 50.0, "val_auroc": 0.37, "time": 513.37}
{"epoch": 32, "training_loss": 55.60864067077637, "training_acc": 47.5, "val_loss": 13.876069784164429, "val_acc": 50.0, "val_auroc": 0.64, "time": 529.95}
{"epoch": 33, "training_loss": 55.648048400878906, "training_acc": 47.5, "val_loss": 13.87072205543518, "val_acc": 50.0, "val_auroc": 0.72, "time": 546.19}
{"epoch": 34, "training_loss": 55.564645767211914, "training_acc": 47.5, "val_loss": 13.863687515258789, "val_acc": 50.0, "val_auroc": 0.64, "time": 562.05}
{"epoch": 35, "training_loss": 55.57192325592041, "training_acc": 52.5, "val_loss": 13.883684873580933, "val_acc": 50.0, "val_auroc": 0.83, "time": 577.76}
{"epoch": 36, "training_loss": 55.354562759399414, "training_acc": 52.5, "val_loss": 13.88681411743164, "val_acc": 50.0, "val_auroc": 0.78, "time": 595.43}
{"epoch": 37, "training_loss": 55.36361885070801, "training_acc": 52.5, "val_loss": 13.880785703659058, "val_acc": 50.0, "val_auroc": 0.71, "time": 611.48}
{"epoch": 38, "training_loss": 55.40060806274414, "training_acc": 52.5, "val_loss": 13.875843286514282, "val_acc": 50.0, "val_auroc": 0.75, "time": 627.52}
{"epoch": 39, "training_loss": 55.365745544433594, "training_acc": 52.5, "val_loss": 13.88715147972107, "val_acc": 50.0, "val_auroc": 0.69, "time": 643.6}
{"epoch": 40, "training_loss": 55.40096664428711, "training_acc": 52.5, "val_loss": 13.878705501556396, "val_acc": 50.0, "val_auroc": 0.42, "time": 659.71}
