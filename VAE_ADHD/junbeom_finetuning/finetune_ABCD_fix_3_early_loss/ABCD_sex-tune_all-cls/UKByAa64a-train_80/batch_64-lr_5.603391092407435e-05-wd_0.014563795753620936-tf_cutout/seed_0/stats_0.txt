"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.54081153869629, "training_acc": 52.5, "val_loss": 13.934692144393921, "val_acc": 50.0, "val_auroc": 0.27, "time": 22.92}
{"epoch": 1, "training_loss": 55.23822212219238, "training_acc": 52.5, "val_loss": 13.886550664901733, "val_acc": 50.0, "val_auroc": 0.39, "time": 47.63}
{"epoch": 2, "training_loss": 55.20289611816406, "training_acc": 52.5, "val_loss": 13.890553712844849, "val_acc": 50.0, "val_auroc": 0.47, "time": 72.25}
{"epoch": 3, "training_loss": 55.336466789245605, "training_acc": 52.5, "val_loss": 13.891348838806152, "val_acc": 50.0, "val_auroc": 0.43, "time": 95.83}
{"epoch": 4, "training_loss": 55.273738861083984, "training_acc": 52.5, "val_loss": 13.920496702194214, "val_acc": 50.0, "val_auroc": 0.34, "time": 116.07}
{"epoch": 5, "training_loss": 54.97350597381592, "training_acc": 52.5, "val_loss": 13.894293308258057, "val_acc": 50.0, "val_auroc": 0.36, "time": 136.1}
{"epoch": 6, "training_loss": 55.15622520446777, "training_acc": 52.5, "val_loss": 13.837034702301025, "val_acc": 50.0, "val_auroc": 0.57, "time": 156.44}
{"epoch": 7, "training_loss": 54.86788558959961, "training_acc": 61.25, "val_loss": 13.871108293533325, "val_acc": 50.0, "val_auroc": 0.46, "time": 177.38}
{"epoch": 8, "training_loss": 54.89594841003418, "training_acc": 75.0, "val_loss": 13.89910101890564, "val_acc": 50.0, "val_auroc": 0.35, "time": 194.21}
{"epoch": 9, "training_loss": 54.9099063873291, "training_acc": 68.75, "val_loss": 13.846352100372314, "val_acc": 50.0, "val_auroc": 0.54, "time": 211.8}
{"epoch": 10, "training_loss": 54.792280197143555, "training_acc": 56.25, "val_loss": 13.869417905807495, "val_acc": 50.0, "val_auroc": 0.48, "time": 230.26}
{"epoch": 11, "training_loss": 54.3625373840332, "training_acc": 55.0, "val_loss": 13.93144965171814, "val_acc": 50.0, "val_auroc": 0.42, "time": 250.94}
{"epoch": 12, "training_loss": 54.0628547668457, "training_acc": 53.75, "val_loss": 13.931277990341187, "val_acc": 50.0, "val_auroc": 0.42, "time": 269.54}
{"epoch": 13, "training_loss": 54.179518699645996, "training_acc": 56.25, "val_loss": 14.185543060302734, "val_acc": 50.0, "val_auroc": 0.24, "time": 287.28}
{"epoch": 14, "training_loss": 54.629249572753906, "training_acc": 52.5, "val_loss": 14.163440465927124, "val_acc": 50.0, "val_auroc": 0.36, "time": 305.62}
{"epoch": 15, "training_loss": 54.47977638244629, "training_acc": 52.5, "val_loss": 14.00783658027649, "val_acc": 50.0, "val_auroc": 0.44, "time": 324.47}
{"epoch": 16, "training_loss": 53.34053993225098, "training_acc": 53.75, "val_loss": 14.067397117614746, "val_acc": 50.0, "val_auroc": 0.4, "time": 342.22}
{"epoch": 17, "training_loss": 52.90900421142578, "training_acc": 52.5, "val_loss": 14.12621021270752, "val_acc": 50.0, "val_auroc": 0.44, "time": 358.82}
{"epoch": 18, "training_loss": 51.82320499420166, "training_acc": 55.0, "val_loss": 13.950632810592651, "val_acc": 50.0, "val_auroc": 0.49, "time": 376.72}
{"epoch": 19, "training_loss": 52.44058895111084, "training_acc": 65.0, "val_loss": 13.855167627334595, "val_acc": 50.0, "val_auroc": 0.44, "time": 394.27}
{"epoch": 20, "training_loss": 51.40602397918701, "training_acc": 85.0, "val_loss": 13.893563747406006, "val_acc": 50.0, "val_auroc": 0.46, "time": 412.45}
{"epoch": 21, "training_loss": 50.15968894958496, "training_acc": 76.25, "val_loss": 14.240516424179077, "val_acc": 50.0, "val_auroc": 0.46, "time": 430.95}
{"epoch": 22, "training_loss": 51.107845306396484, "training_acc": 60.0, "val_loss": 13.941923379898071, "val_acc": 50.0, "val_auroc": 0.43, "time": 449.27}
{"epoch": 23, "training_loss": 48.63297176361084, "training_acc": 80.0, "val_loss": 14.10234808921814, "val_acc": 50.0, "val_auroc": 0.49, "time": 466.06}
{"epoch": 24, "training_loss": 48.066895484924316, "training_acc": 75.0, "val_loss": 13.795444965362549, "val_acc": 50.0, "val_auroc": 0.58, "time": 485.73}
{"epoch": 25, "training_loss": 45.56511116027832, "training_acc": 87.5, "val_loss": 13.745877742767334, "val_acc": 50.0, "val_auroc": 0.57, "time": 504.34}
{"epoch": 26, "training_loss": 46.123252868652344, "training_acc": 83.75, "val_loss": 14.40258264541626, "val_acc": 50.0, "val_auroc": 0.46, "time": 523.67}
{"epoch": 27, "training_loss": 47.693437576293945, "training_acc": 72.5, "val_loss": 13.929656744003296, "val_acc": 55.0, "val_auroc": 0.57, "time": 542.0}
{"epoch": 28, "training_loss": 42.61241054534912, "training_acc": 85.0, "val_loss": 14.165624380111694, "val_acc": 40.0, "val_auroc": 0.43, "time": 561.78}
{"epoch": 29, "training_loss": 49.01039791107178, "training_acc": 67.5, "val_loss": 15.227683782577515, "val_acc": 50.0, "val_auroc": 0.39, "time": 580.88}
{"epoch": 30, "training_loss": 51.72065544128418, "training_acc": 53.75, "val_loss": 13.894808292388916, "val_acc": 50.0, "val_auroc": 0.55, "time": 600.77}
{"epoch": 31, "training_loss": 44.74363136291504, "training_acc": 85.0, "val_loss": 14.2630934715271, "val_acc": 45.0, "val_auroc": 0.5, "time": 617.83}
{"epoch": 32, "training_loss": 49.7891149520874, "training_acc": 61.25, "val_loss": 14.434295892715454, "val_acc": 50.0, "val_auroc": 0.52, "time": 637.88}
{"epoch": 33, "training_loss": 43.82009410858154, "training_acc": 75.0, "val_loss": 14.162304401397705, "val_acc": 60.0, "val_auroc": 0.57, "time": 656.52}
{"epoch": 34, "training_loss": 38.94626331329346, "training_acc": 92.5, "val_loss": 14.587219953536987, "val_acc": 50.0, "val_auroc": 0.5, "time": 676.43}
{"epoch": 35, "training_loss": 37.93768119812012, "training_acc": 90.0, "val_loss": 14.314810037612915, "val_acc": 40.0, "val_auroc": 0.51, "time": 694.91}
{"epoch": 36, "training_loss": 40.24584484100342, "training_acc": 85.0, "val_loss": 15.104883909225464, "val_acc": 50.0, "val_auroc": 0.45, "time": 715.05}
{"epoch": 37, "training_loss": 39.20688056945801, "training_acc": 85.0, "val_loss": 14.530068635940552, "val_acc": 55.0, "val_auroc": 0.51, "time": 733.21}
{"epoch": 38, "training_loss": 47.081214904785156, "training_acc": 68.75, "val_loss": 13.977845907211304, "val_acc": 50.0, "val_auroc": 0.57, "time": 752.21}
{"epoch": 39, "training_loss": 38.5449275970459, "training_acc": 92.5, "val_loss": 15.071598291397095, "val_acc": 50.0, "val_auroc": 0.52, "time": 769.23}
{"epoch": 40, "training_loss": 38.06386375427246, "training_acc": 86.25, "val_loss": 14.091233015060425, "val_acc": 45.0, "val_auroc": 0.6, "time": 787.91}
{"epoch": 41, "training_loss": 37.66691780090332, "training_acc": 90.0, "val_loss": 14.055498838424683, "val_acc": 45.0, "val_auroc": 0.6, "time": 806.49}
{"epoch": 42, "training_loss": 33.77728271484375, "training_acc": 96.25, "val_loss": 14.303027391433716, "val_acc": 50.0, "val_auroc": 0.57, "time": 826.09}
{"epoch": 43, "training_loss": 31.796835899353027, "training_acc": 96.25, "val_loss": 14.705404043197632, "val_acc": 50.0, "val_auroc": 0.59, "time": 843.73}
{"epoch": 44, "training_loss": 31.234583377838135, "training_acc": 95.0, "val_loss": 14.826254844665527, "val_acc": 60.0, "val_auroc": 0.59, "time": 861.22}
