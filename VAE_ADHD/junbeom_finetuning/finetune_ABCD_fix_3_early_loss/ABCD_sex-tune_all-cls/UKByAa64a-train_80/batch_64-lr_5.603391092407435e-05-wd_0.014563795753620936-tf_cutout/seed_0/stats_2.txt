"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.515010833740234, "training_acc": 52.5, "val_loss": 13.882182836532593, "val_acc": 50.0, "val_auroc": 0.51, "time": 18.36}
{"epoch": 1, "training_loss": 55.405086517333984, "training_acc": 52.5, "val_loss": 13.861764669418335, "val_acc": 50.0, "val_auroc": 0.65, "time": 37.68}
{"epoch": 2, "training_loss": 55.3375825881958, "training_acc": 52.5, "val_loss": 13.861119747161865, "val_acc": 50.0, "val_auroc": 0.57, "time": 59.16}
{"epoch": 3, "training_loss": 55.22540855407715, "training_acc": 52.5, "val_loss": 13.912019729614258, "val_acc": 50.0, "val_auroc": 0.47, "time": 81.26}
{"epoch": 4, "training_loss": 55.16014862060547, "training_acc": 52.5, "val_loss": 13.899133205413818, "val_acc": 50.0, "val_auroc": 0.54, "time": 99.88}
{"epoch": 5, "training_loss": 55.07938003540039, "training_acc": 52.5, "val_loss": 13.840463161468506, "val_acc": 50.0, "val_auroc": 0.58, "time": 119.09}
{"epoch": 6, "training_loss": 55.05561637878418, "training_acc": 52.5, "val_loss": 13.959044218063354, "val_acc": 50.0, "val_auroc": 0.29, "time": 136.68}
{"epoch": 7, "training_loss": 55.10255527496338, "training_acc": 52.5, "val_loss": 14.012938737869263, "val_acc": 50.0, "val_auroc": 0.28, "time": 155.69}
{"epoch": 8, "training_loss": 55.19258975982666, "training_acc": 52.5, "val_loss": 13.972138166427612, "val_acc": 50.0, "val_auroc": 0.37, "time": 173.81}
{"epoch": 9, "training_loss": 55.128079414367676, "training_acc": 52.5, "val_loss": 13.971647024154663, "val_acc": 50.0, "val_auroc": 0.26, "time": 192.12}
{"epoch": 10, "training_loss": 55.09672737121582, "training_acc": 52.5, "val_loss": 13.942121267318726, "val_acc": 50.0, "val_auroc": 0.36, "time": 208.93}
{"epoch": 11, "training_loss": 55.04813194274902, "training_acc": 52.5, "val_loss": 13.938552141189575, "val_acc": 50.0, "val_auroc": 0.35, "time": 228.23}
{"epoch": 12, "training_loss": 54.899885177612305, "training_acc": 52.5, "val_loss": 13.948867321014404, "val_acc": 50.0, "val_auroc": 0.3, "time": 247.38}
{"epoch": 13, "training_loss": 54.812137603759766, "training_acc": 52.5, "val_loss": 13.888615369796753, "val_acc": 50.0, "val_auroc": 0.5, "time": 265.07}
{"epoch": 14, "training_loss": 54.66889190673828, "training_acc": 52.5, "val_loss": 13.880012035369873, "val_acc": 50.0, "val_auroc": 0.46, "time": 282.01}
{"epoch": 15, "training_loss": 54.49517250061035, "training_acc": 53.75, "val_loss": 13.977581262588501, "val_acc": 50.0, "val_auroc": 0.57, "time": 301.84}
{"epoch": 16, "training_loss": 54.78064727783203, "training_acc": 52.5, "val_loss": 14.08339262008667, "val_acc": 50.0, "val_auroc": 0.62, "time": 318.33}
{"epoch": 17, "training_loss": 55.379117012023926, "training_acc": 52.5, "val_loss": 14.049758911132812, "val_acc": 50.0, "val_auroc": 0.68, "time": 335.15}
{"epoch": 18, "training_loss": 54.915395736694336, "training_acc": 52.5, "val_loss": 13.880473375320435, "val_acc": 50.0, "val_auroc": 0.49, "time": 351.1}
{"epoch": 19, "training_loss": 54.52675247192383, "training_acc": 52.5, "val_loss": 13.819400072097778, "val_acc": 50.0, "val_auroc": 0.67, "time": 371.35}
{"epoch": 20, "training_loss": 55.12190628051758, "training_acc": 52.5, "val_loss": 13.823695182800293, "val_acc": 50.0, "val_auroc": 0.63, "time": 387.86}
{"epoch": 21, "training_loss": 54.895917892456055, "training_acc": 57.5, "val_loss": 13.799875974655151, "val_acc": 50.0, "val_auroc": 0.68, "time": 404.76}
{"epoch": 22, "training_loss": 54.57662296295166, "training_acc": 60.0, "val_loss": 13.856382369995117, "val_acc": 50.0, "val_auroc": 0.55, "time": 421.78}
{"epoch": 23, "training_loss": 54.14212703704834, "training_acc": 55.0, "val_loss": 13.847578763961792, "val_acc": 50.0, "val_auroc": 0.63, "time": 439.22}
{"epoch": 24, "training_loss": 53.931278228759766, "training_acc": 52.5, "val_loss": 14.035261869430542, "val_acc": 50.0, "val_auroc": 0.56, "time": 456.82}
{"epoch": 25, "training_loss": 54.388014793395996, "training_acc": 52.5, "val_loss": 13.921082019805908, "val_acc": 50.0, "val_auroc": 0.56, "time": 473.55}
{"epoch": 26, "training_loss": 54.20304489135742, "training_acc": 55.0, "val_loss": 13.848642110824585, "val_acc": 50.0, "val_auroc": 0.51, "time": 491.68}
{"epoch": 27, "training_loss": 53.391653060913086, "training_acc": 55.0, "val_loss": 14.058042764663696, "val_acc": 50.0, "val_auroc": 0.46, "time": 511.12}
{"epoch": 28, "training_loss": 53.22330856323242, "training_acc": 52.5, "val_loss": 13.766788244247437, "val_acc": 50.0, "val_auroc": 0.7, "time": 528.6}
{"epoch": 29, "training_loss": 54.96337890625, "training_acc": 61.25, "val_loss": 13.846619129180908, "val_acc": 50.0, "val_auroc": 0.47, "time": 545.51}
{"epoch": 30, "training_loss": 55.30745983123779, "training_acc": 52.5, "val_loss": 13.904142379760742, "val_acc": 50.0, "val_auroc": 0.35, "time": 564.63}
{"epoch": 31, "training_loss": 55.10858917236328, "training_acc": 52.5, "val_loss": 13.904932737350464, "val_acc": 50.0, "val_auroc": 0.43, "time": 582.25}
{"epoch": 32, "training_loss": 54.83126926422119, "training_acc": 52.5, "val_loss": 13.842557668685913, "val_acc": 50.0, "val_auroc": 0.52, "time": 599.43}
{"epoch": 33, "training_loss": 54.85703659057617, "training_acc": 62.5, "val_loss": 13.808397054672241, "val_acc": 50.0, "val_auroc": 0.59, "time": 616.64}
{"epoch": 34, "training_loss": 54.82545280456543, "training_acc": 65.0, "val_loss": 13.856267929077148, "val_acc": 50.0, "val_auroc": 0.64, "time": 632.64}
{"epoch": 35, "training_loss": 54.96995735168457, "training_acc": 52.5, "val_loss": 13.876036405563354, "val_acc": 50.0, "val_auroc": 0.72, "time": 648.23}
{"epoch": 36, "training_loss": 54.45875358581543, "training_acc": 52.5, "val_loss": 13.7831711769104, "val_acc": 50.0, "val_auroc": 0.62, "time": 665.16}
{"epoch": 37, "training_loss": 54.471689224243164, "training_acc": 71.25, "val_loss": 13.755234479904175, "val_acc": 50.0, "val_auroc": 0.65, "time": 681.79}
{"epoch": 38, "training_loss": 54.29339027404785, "training_acc": 70.0, "val_loss": 13.74437928199768, "val_acc": 50.0, "val_auroc": 0.69, "time": 698.91}
{"epoch": 39, "training_loss": 53.91706657409668, "training_acc": 66.25, "val_loss": 13.843042850494385, "val_acc": 50.0, "val_auroc": 0.65, "time": 715.84}
{"epoch": 40, "training_loss": 53.59072685241699, "training_acc": 52.5, "val_loss": 13.74740481376648, "val_acc": 50.0, "val_auroc": 0.66, "time": 735.48}
{"epoch": 41, "training_loss": 53.799171447753906, "training_acc": 66.25, "val_loss": 13.737446069717407, "val_acc": 50.0, "val_auroc": 0.62, "time": 756.64}
{"epoch": 42, "training_loss": 53.15093231201172, "training_acc": 66.25, "val_loss": 13.921831846237183, "val_acc": 50.0, "val_auroc": 0.66, "time": 773.66}
{"epoch": 43, "training_loss": 54.049638748168945, "training_acc": 52.5, "val_loss": 13.900190591812134, "val_acc": 50.0, "val_auroc": 0.64, "time": 790.49}
{"epoch": 44, "training_loss": 53.97872829437256, "training_acc": 52.5, "val_loss": 13.729987144470215, "val_acc": 50.0, "val_auroc": 0.74, "time": 810.14}
{"epoch": 45, "training_loss": 53.53444862365723, "training_acc": 80.0, "val_loss": 13.654383420944214, "val_acc": 50.0, "val_auroc": 0.75, "time": 828.71}
{"epoch": 46, "training_loss": 52.33963584899902, "training_acc": 88.75, "val_loss": 13.752797842025757, "val_acc": 50.0, "val_auroc": 0.7, "time": 848.66}
{"epoch": 47, "training_loss": 51.96649742126465, "training_acc": 61.25, "val_loss": 13.563425540924072, "val_acc": 50.0, "val_auroc": 0.7, "time": 866.46}
{"epoch": 48, "training_loss": 51.10500907897949, "training_acc": 80.0, "val_loss": 13.900063037872314, "val_acc": 50.0, "val_auroc": 0.61, "time": 886.14}
{"epoch": 49, "training_loss": 51.41305732727051, "training_acc": 61.25, "val_loss": 13.653106689453125, "val_acc": 50.0, "val_auroc": 0.68, "time": 904.67}
{"epoch": 50, "training_loss": 49.31319046020508, "training_acc": 77.5, "val_loss": 13.433394432067871, "val_acc": 50.0, "val_auroc": 0.71, "time": 922.64}
{"epoch": 51, "training_loss": 48.915205001831055, "training_acc": 81.25, "val_loss": 13.312559127807617, "val_acc": 50.0, "val_auroc": 0.72, "time": 940.65}
{"epoch": 52, "training_loss": 46.38849353790283, "training_acc": 86.25, "val_loss": 13.587646484375, "val_acc": 50.0, "val_auroc": 0.67, "time": 957.9}
{"epoch": 53, "training_loss": 45.2234468460083, "training_acc": 81.25, "val_loss": 13.285297155380249, "val_acc": 50.0, "val_auroc": 0.7, "time": 977.04}
{"epoch": 54, "training_loss": 44.39687538146973, "training_acc": 88.75, "val_loss": 14.48789358139038, "val_acc": 50.0, "val_auroc": 0.7, "time": 996.8}
{"epoch": 55, "training_loss": 50.08396339416504, "training_acc": 58.75, "val_loss": 13.395874500274658, "val_acc": 50.0, "val_auroc": 0.67, "time": 1016.04}
{"epoch": 56, "training_loss": 41.90464210510254, "training_acc": 91.25, "val_loss": 13.46435546875, "val_acc": 55.0, "val_auroc": 0.62, "time": 1034.08}
{"epoch": 57, "training_loss": 42.93293857574463, "training_acc": 90.0, "val_loss": 13.222501277923584, "val_acc": 55.0, "val_auroc": 0.67, "time": 1051.39}
{"epoch": 58, "training_loss": 38.745662212371826, "training_acc": 98.75, "val_loss": 13.454827070236206, "val_acc": 50.0, "val_auroc": 0.7, "time": 1071.49}
{"epoch": 59, "training_loss": 37.81824970245361, "training_acc": 91.25, "val_loss": 12.788554430007935, "val_acc": 55.0, "val_auroc": 0.69, "time": 1090.54}
{"epoch": 60, "training_loss": 33.478867530822754, "training_acc": 96.25, "val_loss": 13.03568720817566, "val_acc": 55.0, "val_auroc": 0.67, "time": 1108.73}
{"epoch": 61, "training_loss": 31.866533279418945, "training_acc": 98.75, "val_loss": 12.859480381011963, "val_acc": 60.0, "val_auroc": 0.68, "time": 1125.83}
{"epoch": 62, "training_loss": 32.12610149383545, "training_acc": 96.25, "val_loss": 13.349266052246094, "val_acc": 55.0, "val_auroc": 0.65, "time": 1145.52}
{"epoch": 63, "training_loss": 28.516526222229004, "training_acc": 100.0, "val_loss": 14.153997898101807, "val_acc": 60.0, "val_auroc": 0.59, "time": 1165.37}
{"epoch": 64, "training_loss": 31.648178100585938, "training_acc": 93.75, "val_loss": 13.471671342849731, "val_acc": 60.0, "val_auroc": 0.64, "time": 1182.43}
{"epoch": 65, "training_loss": 26.398545265197754, "training_acc": 100.0, "val_loss": 13.517454862594604, "val_acc": 50.0, "val_auroc": 0.6, "time": 1200.7}
{"epoch": 66, "training_loss": 25.541070461273193, "training_acc": 98.75, "val_loss": 14.057973623275757, "val_acc": 65.0, "val_auroc": 0.58, "time": 1220.1}
{"epoch": 67, "training_loss": 24.628360748291016, "training_acc": 100.0, "val_loss": 13.85854721069336, "val_acc": 50.0, "val_auroc": 0.62, "time": 1237.73}
{"epoch": 68, "training_loss": 23.949831008911133, "training_acc": 100.0, "val_loss": 14.034628868103027, "val_acc": 60.0, "val_auroc": 0.6, "time": 1254.72}
{"epoch": 69, "training_loss": 23.196433544158936, "training_acc": 100.0, "val_loss": 14.052174091339111, "val_acc": 55.0, "val_auroc": 0.65, "time": 1272.68}
{"epoch": 70, "training_loss": 22.90666675567627, "training_acc": 100.0, "val_loss": 14.900513887405396, "val_acc": 60.0, "val_auroc": 0.56, "time": 1293.7}
{"epoch": 71, "training_loss": 25.8748836517334, "training_acc": 100.0, "val_loss": 14.424856901168823, "val_acc": 50.0, "val_auroc": 0.61, "time": 1312.9}
{"epoch": 72, "training_loss": 21.343550205230713, "training_acc": 100.0, "val_loss": 14.710229635238647, "val_acc": 60.0, "val_auroc": 0.54, "time": 1330.35}
{"epoch": 73, "training_loss": 22.907413482666016, "training_acc": 100.0, "val_loss": 14.772706031799316, "val_acc": 45.0, "val_auroc": 0.59, "time": 1347.39}
{"epoch": 74, "training_loss": 21.6463680267334, "training_acc": 100.0, "val_loss": 14.414312839508057, "val_acc": 65.0, "val_auroc": 0.6, "time": 1365.55}
{"epoch": 75, "training_loss": 21.614079475402832, "training_acc": 98.75, "val_loss": 14.591524600982666, "val_acc": 55.0, "val_auroc": 0.67, "time": 1385.98}
{"epoch": 76, "training_loss": 22.496850967407227, "training_acc": 100.0, "val_loss": 13.857117891311646, "val_acc": 70.0, "val_auroc": 0.64, "time": 1402.51}
{"epoch": 77, "training_loss": 19.9265456199646, "training_acc": 100.0, "val_loss": 14.895223379135132, "val_acc": 50.0, "val_auroc": 0.65, "time": 1419.84}
{"epoch": 78, "training_loss": 20.349743604660034, "training_acc": 98.75, "val_loss": 14.118328094482422, "val_acc": 60.0, "val_auroc": 0.63, "time": 1438.95}
