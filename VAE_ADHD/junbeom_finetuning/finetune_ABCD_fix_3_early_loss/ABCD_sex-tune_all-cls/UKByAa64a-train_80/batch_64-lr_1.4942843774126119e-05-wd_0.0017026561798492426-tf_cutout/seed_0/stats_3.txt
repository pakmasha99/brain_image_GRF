"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.5567512512207, "training_acc": 48.75, "val_loss": 13.908613920211792, "val_acc": 55.0, "val_auroc": 0.485, "time": 19.69}
{"epoch": 1, "training_loss": 55.53689765930176, "training_acc": 50.0, "val_loss": 13.94685983657837, "val_acc": 55.0, "val_auroc": 0.303, "time": 37.02}
{"epoch": 2, "training_loss": 55.33436298370361, "training_acc": 53.75, "val_loss": 13.912428617477417, "val_acc": 55.0, "val_auroc": 0.455, "time": 55.11}
{"epoch": 3, "training_loss": 55.16899490356445, "training_acc": 57.5, "val_loss": 13.893940448760986, "val_acc": 55.0, "val_auroc": 0.424, "time": 72.79}
{"epoch": 4, "training_loss": 55.13180160522461, "training_acc": 63.75, "val_loss": 13.854444026947021, "val_acc": 55.0, "val_auroc": 0.444, "time": 90.0}
{"epoch": 5, "training_loss": 54.95033645629883, "training_acc": 70.0, "val_loss": 13.843564987182617, "val_acc": 55.0, "val_auroc": 0.455, "time": 111.71}
{"epoch": 6, "training_loss": 54.765676498413086, "training_acc": 78.75, "val_loss": 13.844441175460815, "val_acc": 55.0, "val_auroc": 0.515, "time": 131.65}
{"epoch": 7, "training_loss": 54.74770641326904, "training_acc": 68.75, "val_loss": 13.864860534667969, "val_acc": 55.0, "val_auroc": 0.444, "time": 151.25}
{"epoch": 8, "training_loss": 54.81903266906738, "training_acc": 66.25, "val_loss": 13.844040632247925, "val_acc": 55.0, "val_auroc": 0.434, "time": 168.18}
{"epoch": 9, "training_loss": 54.619253158569336, "training_acc": 65.0, "val_loss": 13.83743405342102, "val_acc": 55.0, "val_auroc": 0.414, "time": 189.21}
{"epoch": 10, "training_loss": 54.49891662597656, "training_acc": 65.0, "val_loss": 13.81856918334961, "val_acc": 55.0, "val_auroc": 0.515, "time": 206.64}
{"epoch": 11, "training_loss": 54.18064022064209, "training_acc": 71.25, "val_loss": 13.811711072921753, "val_acc": 55.0, "val_auroc": 0.545, "time": 224.93}
{"epoch": 12, "training_loss": 54.156293869018555, "training_acc": 67.5, "val_loss": 13.782695531845093, "val_acc": 55.0, "val_auroc": 0.586, "time": 242.13}
{"epoch": 13, "training_loss": 54.120492935180664, "training_acc": 65.0, "val_loss": 13.799372911453247, "val_acc": 55.0, "val_auroc": 0.586, "time": 259.96}
{"epoch": 14, "training_loss": 53.9768180847168, "training_acc": 65.0, "val_loss": 13.814249038696289, "val_acc": 55.0, "val_auroc": 0.525, "time": 278.89}
{"epoch": 15, "training_loss": 53.8002815246582, "training_acc": 70.0, "val_loss": 13.821661472320557, "val_acc": 55.0, "val_auroc": 0.515, "time": 296.47}
{"epoch": 16, "training_loss": 53.5895357131958, "training_acc": 66.25, "val_loss": 13.82138729095459, "val_acc": 55.0, "val_auroc": 0.465, "time": 314.6}
{"epoch": 17, "training_loss": 53.51546096801758, "training_acc": 68.75, "val_loss": 13.813422918319702, "val_acc": 55.0, "val_auroc": 0.475, "time": 332.36}
{"epoch": 18, "training_loss": 53.33725833892822, "training_acc": 67.5, "val_loss": 13.84137511253357, "val_acc": 55.0, "val_auroc": 0.485, "time": 350.28}
{"epoch": 19, "training_loss": 53.17696666717529, "training_acc": 67.5, "val_loss": 13.855675458908081, "val_acc": 55.0, "val_auroc": 0.505, "time": 368.94}
{"epoch": 20, "training_loss": 53.20145797729492, "training_acc": 73.75, "val_loss": 13.863195180892944, "val_acc": 55.0, "val_auroc": 0.485, "time": 385.63}
{"epoch": 21, "training_loss": 52.84132194519043, "training_acc": 71.25, "val_loss": 13.83686900138855, "val_acc": 55.0, "val_auroc": 0.525, "time": 402.72}
{"epoch": 22, "training_loss": 53.00051307678223, "training_acc": 67.5, "val_loss": 13.853299617767334, "val_acc": 55.0, "val_auroc": 0.434, "time": 421.08}
{"epoch": 23, "training_loss": 53.016507148742676, "training_acc": 76.25, "val_loss": 13.829838037490845, "val_acc": 55.0, "val_auroc": 0.525, "time": 438.54}
{"epoch": 24, "training_loss": 53.21585464477539, "training_acc": 62.5, "val_loss": 13.85472297668457, "val_acc": 55.0, "val_auroc": 0.414, "time": 455.82}
{"epoch": 25, "training_loss": 53.370174407958984, "training_acc": 60.0, "val_loss": 13.860054016113281, "val_acc": 55.0, "val_auroc": 0.475, "time": 472.84}
{"epoch": 26, "training_loss": 52.919700622558594, "training_acc": 70.0, "val_loss": 13.89951229095459, "val_acc": 55.0, "val_auroc": 0.384, "time": 489.92}
{"epoch": 27, "training_loss": 52.11504936218262, "training_acc": 70.0, "val_loss": 13.857440948486328, "val_acc": 55.0, "val_auroc": 0.535, "time": 507.76}
{"epoch": 28, "training_loss": 52.677348136901855, "training_acc": 66.25, "val_loss": 13.882710933685303, "val_acc": 55.0, "val_auroc": 0.455, "time": 524.58}
{"epoch": 29, "training_loss": 51.72856330871582, "training_acc": 75.0, "val_loss": 13.895739316940308, "val_acc": 55.0, "val_auroc": 0.424, "time": 542.07}
{"epoch": 30, "training_loss": 51.89945316314697, "training_acc": 81.25, "val_loss": 13.860037326812744, "val_acc": 55.0, "val_auroc": 0.505, "time": 561.44}
{"epoch": 31, "training_loss": 51.85435485839844, "training_acc": 70.0, "val_loss": 13.903259038925171, "val_acc": 55.0, "val_auroc": 0.485, "time": 579.36}
