"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.48221969604492, "training_acc": 41.25, "val_loss": 13.893970251083374, "val_acc": 50.0, "val_auroc": 0.46, "time": 18.89}
{"epoch": 1, "training_loss": 54.813015937805176, "training_acc": 52.5, "val_loss": 17.550610303878784, "val_acc": 50.0, "val_auroc": 0.38, "time": 35.35}
{"epoch": 2, "training_loss": 65.82574272155762, "training_acc": 50.0, "val_loss": 13.861706256866455, "val_acc": 50.0, "val_auroc": 0.61, "time": 52.44}
{"epoch": 3, "training_loss": 55.274535179138184, "training_acc": 52.5, "val_loss": 14.274166822433472, "val_acc": 50.0, "val_auroc": 0.69, "time": 68.92}
{"epoch": 4, "training_loss": 56.1520881652832, "training_acc": 52.5, "val_loss": 14.102833271026611, "val_acc": 50.0, "val_auroc": 0.8, "time": 84.53}
{"epoch": 5, "training_loss": 56.739681243896484, "training_acc": 50.0, "val_loss": 14.013879299163818, "val_acc": 50.0, "val_auroc": 0.71, "time": 102.84}
{"epoch": 6, "training_loss": 55.7287540435791, "training_acc": 52.5, "val_loss": 14.128382205963135, "val_acc": 50.0, "val_auroc": 0.44, "time": 118.79}
{"epoch": 7, "training_loss": 55.79895877838135, "training_acc": 52.5, "val_loss": 14.130353927612305, "val_acc": 50.0, "val_auroc": 0.38, "time": 134.09}
{"epoch": 8, "training_loss": 55.663818359375, "training_acc": 52.5, "val_loss": 13.870090246200562, "val_acc": 50.0, "val_auroc": 0.47, "time": 148.92}
{"epoch": 9, "training_loss": 55.509963035583496, "training_acc": 48.75, "val_loss": 14.029706716537476, "val_acc": 50.0, "val_auroc": 0.48, "time": 165.27}
{"epoch": 10, "training_loss": 56.41656494140625, "training_acc": 47.5, "val_loss": 13.871095180511475, "val_acc": 50.0, "val_auroc": 0.36, "time": 180.66}
{"epoch": 11, "training_loss": 55.230658531188965, "training_acc": 52.5, "val_loss": 14.113960266113281, "val_acc": 50.0, "val_auroc": 0.28, "time": 195.95}
{"epoch": 12, "training_loss": 55.9094820022583, "training_acc": 52.5, "val_loss": 14.193928241729736, "val_acc": 50.0, "val_auroc": 0.36, "time": 211.56}
{"epoch": 13, "training_loss": 55.83026695251465, "training_acc": 52.5, "val_loss": 13.877679109573364, "val_acc": 50.0, "val_auroc": 0.59, "time": 227.03}
{"epoch": 14, "training_loss": 55.3376522064209, "training_acc": 52.5, "val_loss": 13.877507448196411, "val_acc": 50.0, "val_auroc": 0.79, "time": 242.36}
{"epoch": 15, "training_loss": 55.97075271606445, "training_acc": 47.5, "val_loss": 13.853371143341064, "val_acc": 50.0, "val_auroc": 0.78, "time": 258.24}
{"epoch": 16, "training_loss": 55.093605041503906, "training_acc": 52.5, "val_loss": 14.041179418563843, "val_acc": 50.0, "val_auroc": 0.72, "time": 273.41}
{"epoch": 17, "training_loss": 55.713857650756836, "training_acc": 52.5, "val_loss": 14.15083646774292, "val_acc": 50.0, "val_auroc": 0.76, "time": 288.81}
{"epoch": 18, "training_loss": 55.847848892211914, "training_acc": 52.5, "val_loss": 13.96190881729126, "val_acc": 50.0, "val_auroc": 0.73, "time": 304.07}
{"epoch": 19, "training_loss": 55.29452037811279, "training_acc": 52.5, "val_loss": 13.871128559112549, "val_acc": 50.0, "val_auroc": 0.27, "time": 319.73}
{"epoch": 20, "training_loss": 55.53972148895264, "training_acc": 61.25, "val_loss": 13.886867761611938, "val_acc": 50.0, "val_auroc": 0.37, "time": 334.82}
{"epoch": 21, "training_loss": 55.61336803436279, "training_acc": 47.5, "val_loss": 13.88053297996521, "val_acc": 50.0, "val_auroc": 0.43, "time": 350.31}
{"epoch": 22, "training_loss": 55.29533576965332, "training_acc": 52.5, "val_loss": 14.056509733200073, "val_acc": 50.0, "val_auroc": 0.6, "time": 365.89}
{"epoch": 23, "training_loss": 55.658348083496094, "training_acc": 52.5, "val_loss": 14.04147982597351, "val_acc": 50.0, "val_auroc": 0.69, "time": 381.48}
{"epoch": 24, "training_loss": 56.154212951660156, "training_acc": 47.5, "val_loss": 14.165791273117065, "val_acc": 50.0, "val_auroc": 0.69, "time": 400.19}
{"epoch": 25, "training_loss": 55.90095138549805, "training_acc": 52.5, "val_loss": 13.943597078323364, "val_acc": 50.0, "val_auroc": 0.73, "time": 415.8}
{"epoch": 26, "training_loss": 55.52694129943848, "training_acc": 52.5, "val_loss": 13.94917368888855, "val_acc": 50.0, "val_auroc": 0.68, "time": 431.43}
{"epoch": 27, "training_loss": 55.408952713012695, "training_acc": 52.5, "val_loss": 14.039123058319092, "val_acc": 50.0, "val_auroc": 0.57, "time": 446.87}
{"epoch": 28, "training_loss": 55.79616355895996, "training_acc": 52.5, "val_loss": 13.95484209060669, "val_acc": 50.0, "val_auroc": 0.49, "time": 462.37}
{"epoch": 29, "training_loss": 55.459293365478516, "training_acc": 52.5, "val_loss": 13.872593641281128, "val_acc": 50.0, "val_auroc": 0.18, "time": 478.69}
{"epoch": 30, "training_loss": 55.431711196899414, "training_acc": 50.0, "val_loss": 13.87241244316101, "val_acc": 50.0, "val_auroc": 0.18, "time": 494.05}
{"epoch": 31, "training_loss": 55.50675964355469, "training_acc": 45.0, "val_loss": 13.866289854049683, "val_acc": 50.0, "val_auroc": 0.38, "time": 509.02}
{"epoch": 32, "training_loss": 55.42900276184082, "training_acc": 58.75, "val_loss": 13.861218690872192, "val_acc": 50.0, "val_auroc": 0.59, "time": 524.04}
{"epoch": 33, "training_loss": 55.42160987854004, "training_acc": 55.0, "val_loss": 13.856288194656372, "val_acc": 50.0, "val_auroc": 0.63, "time": 540.03}
{"epoch": 34, "training_loss": 55.42158031463623, "training_acc": 58.75, "val_loss": 13.861194849014282, "val_acc": 50.0, "val_auroc": 0.73, "time": 555.41}
