"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.8148775100708, "training_acc": 42.5, "val_loss": 13.869870901107788, "val_acc": 50.0, "val_auroc": 0.66, "time": 19.89}
{"epoch": 1, "training_loss": 57.04322052001953, "training_acc": 46.25, "val_loss": 188.8619613647461, "val_acc": 50.0, "val_auroc": 0.51, "time": 35.81}
{"epoch": 2, "training_loss": 571.4364080429077, "training_acc": 52.5, "val_loss": 13.846969604492188, "val_acc": 50.0, "val_auroc": 0.62, "time": 52.11}
{"epoch": 3, "training_loss": 55.77105236053467, "training_acc": 47.5, "val_loss": 13.852585554122925, "val_acc": 50.0, "val_auroc": 0.69, "time": 68.87}
{"epoch": 4, "training_loss": 55.680665016174316, "training_acc": 47.5, "val_loss": 13.927488327026367, "val_acc": 50.0, "val_auroc": 0.47, "time": 85.63}
{"epoch": 5, "training_loss": 56.0538272857666, "training_acc": 46.25, "val_loss": 14.814287424087524, "val_acc": 35.0, "val_auroc": 0.46, "time": 102.14}
{"epoch": 6, "training_loss": 59.75554943084717, "training_acc": 47.5, "val_loss": 14.685834646224976, "val_acc": 50.0, "val_auroc": 0.45, "time": 118.99}
{"epoch": 7, "training_loss": 56.42117118835449, "training_acc": 52.5, "val_loss": 14.72386121749878, "val_acc": 30.0, "val_auroc": 0.44, "time": 136.25}
{"epoch": 8, "training_loss": 59.43494129180908, "training_acc": 47.5, "val_loss": 13.934708833694458, "val_acc": 50.0, "val_auroc": 0.45, "time": 152.72}
{"epoch": 9, "training_loss": 55.50122261047363, "training_acc": 52.5, "val_loss": 14.29904818534851, "val_acc": 50.0, "val_auroc": 0.44, "time": 169.71}
{"epoch": 10, "training_loss": 56.07586097717285, "training_acc": 52.5, "val_loss": 13.887794017791748, "val_acc": 50.0, "val_auroc": 0.49, "time": 186.93}
{"epoch": 11, "training_loss": 55.617881774902344, "training_acc": 53.75, "val_loss": 13.928500413894653, "val_acc": 50.0, "val_auroc": 0.49, "time": 202.45}
{"epoch": 12, "training_loss": 54.94709300994873, "training_acc": 52.5, "val_loss": 14.425808191299438, "val_acc": 50.0, "val_auroc": 0.48, "time": 220.98}
{"epoch": 13, "training_loss": 56.57674789428711, "training_acc": 52.5, "val_loss": 14.413384199142456, "val_acc": 50.0, "val_auroc": 0.46, "time": 240.69}
{"epoch": 14, "training_loss": 56.836429595947266, "training_acc": 52.5, "val_loss": 14.277485609054565, "val_acc": 50.0, "val_auroc": 0.48, "time": 258.92}
{"epoch": 15, "training_loss": 55.95707893371582, "training_acc": 52.5, "val_loss": 14.21819806098938, "val_acc": 50.0, "val_auroc": 0.46, "time": 275.42}
{"epoch": 16, "training_loss": 55.981207847595215, "training_acc": 52.5, "val_loss": 14.02835488319397, "val_acc": 50.0, "val_auroc": 0.44, "time": 292.76}
{"epoch": 17, "training_loss": 55.21296977996826, "training_acc": 52.5, "val_loss": 13.902311325073242, "val_acc": 50.0, "val_auroc": 0.45, "time": 309.18}
{"epoch": 18, "training_loss": 55.127267837524414, "training_acc": 48.75, "val_loss": 13.893941640853882, "val_acc": 50.0, "val_auroc": 0.44, "time": 326.44}
{"epoch": 19, "training_loss": 55.69972229003906, "training_acc": 52.5, "val_loss": 13.889867067337036, "val_acc": 50.0, "val_auroc": 0.43, "time": 342.73}
{"epoch": 20, "training_loss": 54.937557220458984, "training_acc": 62.5, "val_loss": 14.010521173477173, "val_acc": 50.0, "val_auroc": 0.44, "time": 359.54}
{"epoch": 21, "training_loss": 56.106285095214844, "training_acc": 47.5, "val_loss": 13.89083743095398, "val_acc": 50.0, "val_auroc": 0.45, "time": 376.37}
