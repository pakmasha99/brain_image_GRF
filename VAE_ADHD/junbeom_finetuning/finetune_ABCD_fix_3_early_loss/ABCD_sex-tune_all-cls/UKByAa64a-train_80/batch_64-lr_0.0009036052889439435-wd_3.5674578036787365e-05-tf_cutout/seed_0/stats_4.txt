"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 53.94585990905762, "training_acc": 56.25, "val_loss": 70.71437358856201, "val_acc": 45.0, "val_auroc": 0.566, "time": 19.56}
{"epoch": 1, "training_loss": 4433.865783691406, "training_acc": 56.25, "val_loss": 39.756507873535156, "val_acc": 55.0, "val_auroc": 0.394, "time": 37.63}
{"epoch": 2, "training_loss": 158.52625846862793, "training_acc": 51.25, "val_loss": 14.10709023475647, "val_acc": 55.0, "val_auroc": 0.556, "time": 55.62}
{"epoch": 3, "training_loss": 125.0516586303711, "training_acc": 43.75, "val_loss": 89.30181503295898, "val_acc": 45.0, "val_auroc": 0.465, "time": 72.89}
{"epoch": 4, "training_loss": 292.4839553833008, "training_acc": 48.75, "val_loss": 15.49815058708191, "val_acc": 45.0, "val_auroc": 0.485, "time": 89.82}
{"epoch": 5, "training_loss": 59.63770771026611, "training_acc": 48.75, "val_loss": 14.521466493606567, "val_acc": 55.0, "val_auroc": 0.495, "time": 106.94}
{"epoch": 6, "training_loss": 60.000160217285156, "training_acc": 51.25, "val_loss": 13.969447612762451, "val_acc": 55.0, "val_auroc": 0.495, "time": 124.1}
{"epoch": 7, "training_loss": 55.956787109375, "training_acc": 48.75, "val_loss": 13.86404275894165, "val_acc": 55.0, "val_auroc": 0.465, "time": 141.3}
{"epoch": 8, "training_loss": 57.968326568603516, "training_acc": 55.0, "val_loss": 14.076859951019287, "val_acc": 55.0, "val_auroc": 0.465, "time": 155.86}
{"epoch": 9, "training_loss": 57.65223217010498, "training_acc": 48.75, "val_loss": 14.35879111289978, "val_acc": 55.0, "val_auroc": 0.505, "time": 172.73}
{"epoch": 10, "training_loss": 56.35311031341553, "training_acc": 48.75, "val_loss": 13.767342567443848, "val_acc": 55.0, "val_auroc": 0.566, "time": 189.98}
{"epoch": 11, "training_loss": 55.79819202423096, "training_acc": 51.25, "val_loss": 13.89600157737732, "val_acc": 55.0, "val_auroc": 0.535, "time": 206.86}
{"epoch": 12, "training_loss": 56.89938545227051, "training_acc": 51.25, "val_loss": 13.769172430038452, "val_acc": 55.0, "val_auroc": 0.535, "time": 221.64}
{"epoch": 13, "training_loss": 55.931007385253906, "training_acc": 51.25, "val_loss": 13.930463790893555, "val_acc": 55.0, "val_auroc": 0.606, "time": 238.47}
{"epoch": 14, "training_loss": 55.49384784698486, "training_acc": 48.75, "val_loss": 14.194239377975464, "val_acc": 55.0, "val_auroc": 0.505, "time": 255.38}
{"epoch": 15, "training_loss": 56.31931114196777, "training_acc": 48.75, "val_loss": 14.06150221824646, "val_acc": 55.0, "val_auroc": 0.505, "time": 272.3}
{"epoch": 16, "training_loss": 55.311180114746094, "training_acc": 48.75, "val_loss": 13.764212131500244, "val_acc": 55.0, "val_auroc": 0.586, "time": 289.44}
{"epoch": 17, "training_loss": 56.030720710754395, "training_acc": 51.25, "val_loss": 13.961687088012695, "val_acc": 55.0, "val_auroc": 0.545, "time": 306.13}
{"epoch": 18, "training_loss": 57.261131286621094, "training_acc": 51.25, "val_loss": 13.802721500396729, "val_acc": 55.0, "val_auroc": 0.535, "time": 322.9}
{"epoch": 19, "training_loss": 55.97561264038086, "training_acc": 51.25, "val_loss": 13.810416460037231, "val_acc": 55.0, "val_auroc": 0.606, "time": 339.95}
{"epoch": 20, "training_loss": 55.43160152435303, "training_acc": 51.25, "val_loss": 14.04734492301941, "val_acc": 55.0, "val_auroc": 0.434, "time": 357.41}
{"epoch": 21, "training_loss": 55.78495407104492, "training_acc": 48.75, "val_loss": 14.077228307723999, "val_acc": 55.0, "val_auroc": 0.475, "time": 374.1}
{"epoch": 22, "training_loss": 55.81789779663086, "training_acc": 48.75, "val_loss": 13.935922384262085, "val_acc": 55.0, "val_auroc": 0.717, "time": 390.92}
{"epoch": 23, "training_loss": 55.4818115234375, "training_acc": 47.5, "val_loss": 13.798712491989136, "val_acc": 55.0, "val_auroc": 0.646, "time": 407.89}
{"epoch": 24, "training_loss": 55.540589332580566, "training_acc": 51.25, "val_loss": 13.771440982818604, "val_acc": 55.0, "val_auroc": 0.657, "time": 424.77}
{"epoch": 25, "training_loss": 55.58316993713379, "training_acc": 51.25, "val_loss": 13.788455724716187, "val_acc": 55.0, "val_auroc": 0.667, "time": 441.82}
{"epoch": 26, "training_loss": 55.4403657913208, "training_acc": 51.25, "val_loss": 13.774888515472412, "val_acc": 55.0, "val_auroc": 0.657, "time": 458.48}
{"epoch": 27, "training_loss": 55.47632598876953, "training_acc": 51.25, "val_loss": 13.773483037948608, "val_acc": 55.0, "val_auroc": 0.646, "time": 475.42}
{"epoch": 28, "training_loss": 55.46477508544922, "training_acc": 51.25, "val_loss": 13.812592029571533, "val_acc": 55.0, "val_auroc": 0.626, "time": 492.4}
{"epoch": 29, "training_loss": 55.64372539520264, "training_acc": 43.75, "val_loss": 13.850088119506836, "val_acc": 55.0, "val_auroc": 0.566, "time": 509.21}
{"epoch": 30, "training_loss": 55.42897891998291, "training_acc": 51.25, "val_loss": 13.803062438964844, "val_acc": 55.0, "val_auroc": 0.636, "time": 526.03}
{"epoch": 31, "training_loss": 55.4493522644043, "training_acc": 51.25, "val_loss": 13.79468560218811, "val_acc": 55.0, "val_auroc": 0.646, "time": 543.03}
{"epoch": 32, "training_loss": 55.432899475097656, "training_acc": 51.25, "val_loss": 13.806484937667847, "val_acc": 55.0, "val_auroc": 0.616, "time": 559.7}
{"epoch": 33, "training_loss": 55.40584468841553, "training_acc": 51.25, "val_loss": 13.810917139053345, "val_acc": 55.0, "val_auroc": 0.596, "time": 576.58}
{"epoch": 34, "training_loss": 55.413190841674805, "training_acc": 51.25, "val_loss": 13.813023567199707, "val_acc": 55.0, "val_auroc": 0.586, "time": 593.09}
{"epoch": 35, "training_loss": 55.40240955352783, "training_acc": 51.25, "val_loss": 13.8070809841156, "val_acc": 55.0, "val_auroc": 0.596, "time": 609.55}
