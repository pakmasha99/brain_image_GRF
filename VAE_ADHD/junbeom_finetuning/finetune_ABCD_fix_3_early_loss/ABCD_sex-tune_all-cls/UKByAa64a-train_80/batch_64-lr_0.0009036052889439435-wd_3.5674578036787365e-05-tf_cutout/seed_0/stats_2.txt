"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 67.35096740722656, "training_acc": 42.5, "val_loss": 30.96585512161255, "val_acc": 50.0, "val_auroc": 0.65, "time": 19.38}
{"epoch": 1, "training_loss": 451.02276611328125, "training_acc": 52.5, "val_loss": 14.133402109146118, "val_acc": 50.0, "val_auroc": 0.24, "time": 37.44}
{"epoch": 2, "training_loss": 57.46178150177002, "training_acc": 50.0, "val_loss": 16.426680088043213, "val_acc": 50.0, "val_auroc": 0.29, "time": 55.54}
{"epoch": 3, "training_loss": 69.83247566223145, "training_acc": 47.5, "val_loss": 14.228718280792236, "val_acc": 50.0, "val_auroc": 0.37, "time": 73.21}
{"epoch": 4, "training_loss": 56.32565879821777, "training_acc": 52.5, "val_loss": 13.947687149047852, "val_acc": 50.0, "val_auroc": 0.26, "time": 91.13}
{"epoch": 5, "training_loss": 55.71160888671875, "training_acc": 50.0, "val_loss": 13.89783263206482, "val_acc": 50.0, "val_auroc": 0.28, "time": 109.4}
{"epoch": 6, "training_loss": 55.188018798828125, "training_acc": 52.5, "val_loss": 15.844671726226807, "val_acc": 50.0, "val_auroc": 0.29, "time": 126.99}
{"epoch": 7, "training_loss": 60.58028507232666, "training_acc": 52.5, "val_loss": 14.004639387130737, "val_acc": 50.0, "val_auroc": 0.25, "time": 144.29}
{"epoch": 8, "training_loss": 55.19894599914551, "training_acc": 52.5, "val_loss": 13.902596235275269, "val_acc": 50.0, "val_auroc": 0.54, "time": 161.26}
{"epoch": 9, "training_loss": 55.92983818054199, "training_acc": 47.5, "val_loss": 13.942409753799438, "val_acc": 50.0, "val_auroc": 0.72, "time": 177.33}
{"epoch": 10, "training_loss": 56.00693607330322, "training_acc": 47.5, "val_loss": 13.888720273971558, "val_acc": 50.0, "val_auroc": 0.62, "time": 194.66}
{"epoch": 11, "training_loss": 55.22077560424805, "training_acc": 52.5, "val_loss": 14.202468395233154, "val_acc": 50.0, "val_auroc": 0.31, "time": 211.75}
{"epoch": 12, "training_loss": 56.12361717224121, "training_acc": 52.5, "val_loss": 14.090330600738525, "val_acc": 50.0, "val_auroc": 0.27, "time": 228.34}
{"epoch": 13, "training_loss": 55.5853910446167, "training_acc": 52.5, "val_loss": 13.85860800743103, "val_acc": 50.0, "val_auroc": 0.72, "time": 245.35}
{"epoch": 14, "training_loss": 55.50497055053711, "training_acc": 47.5, "val_loss": 13.885892629623413, "val_acc": 50.0, "val_auroc": 0.74, "time": 263.07}
{"epoch": 15, "training_loss": 55.824204444885254, "training_acc": 47.5, "val_loss": 13.867942094802856, "val_acc": 50.0, "val_auroc": 0.7, "time": 280.19}
{"epoch": 16, "training_loss": 55.15432548522949, "training_acc": 52.5, "val_loss": 14.037929773330688, "val_acc": 50.0, "val_auroc": 0.29, "time": 296.91}
{"epoch": 17, "training_loss": 55.67642784118652, "training_acc": 52.5, "val_loss": 14.135181903839111, "val_acc": 50.0, "val_auroc": 0.26, "time": 314.3}
{"epoch": 18, "training_loss": 55.77105712890625, "training_acc": 52.5, "val_loss": 13.957030773162842, "val_acc": 50.0, "val_auroc": 0.23, "time": 331.09}
{"epoch": 19, "training_loss": 55.27335166931152, "training_acc": 52.5, "val_loss": 13.878034353256226, "val_acc": 50.0, "val_auroc": 0.22, "time": 348.32}
{"epoch": 20, "training_loss": 55.67213535308838, "training_acc": 47.5, "val_loss": 13.88852596282959, "val_acc": 50.0, "val_auroc": 0.46, "time": 365.5}
{"epoch": 21, "training_loss": 55.697200775146484, "training_acc": 47.5, "val_loss": 13.861416578292847, "val_acc": 50.0, "val_auroc": 0.63, "time": 382.53}
{"epoch": 22, "training_loss": 55.387269020080566, "training_acc": 52.5, "val_loss": 13.899068832397461, "val_acc": 50.0, "val_auroc": 0.52, "time": 399.36}
{"epoch": 23, "training_loss": 55.30067825317383, "training_acc": 52.5, "val_loss": 13.975313901901245, "val_acc": 50.0, "val_auroc": 0.49, "time": 416.18}
{"epoch": 24, "training_loss": 55.44491100311279, "training_acc": 52.5, "val_loss": 14.073401689529419, "val_acc": 50.0, "val_auroc": 0.46, "time": 432.96}
{"epoch": 25, "training_loss": 55.70479202270508, "training_acc": 52.5, "val_loss": 14.097824096679688, "val_acc": 50.0, "val_auroc": 0.37, "time": 449.85}
{"epoch": 26, "training_loss": 55.85503673553467, "training_acc": 52.5, "val_loss": 14.063104391098022, "val_acc": 50.0, "val_auroc": 0.27, "time": 466.83}
{"epoch": 27, "training_loss": 55.65666103363037, "training_acc": 52.5, "val_loss": 14.0451979637146, "val_acc": 50.0, "val_auroc": 0.21, "time": 483.8}
{"epoch": 28, "training_loss": 55.612876892089844, "training_acc": 52.5, "val_loss": 13.944923877716064, "val_acc": 50.0, "val_auroc": 0.25, "time": 500.89}
{"epoch": 29, "training_loss": 55.44086265563965, "training_acc": 52.5, "val_loss": 13.869882822036743, "val_acc": 50.0, "val_auroc": 0.42, "time": 517.9}
{"epoch": 30, "training_loss": 55.40811538696289, "training_acc": 52.5, "val_loss": 13.860278129577637, "val_acc": 50.0, "val_auroc": 0.65, "time": 534.56}
{"epoch": 31, "training_loss": 55.44788837432861, "training_acc": 52.5, "val_loss": 13.859020471572876, "val_acc": 50.0, "val_auroc": 0.73, "time": 551.38}
{"epoch": 32, "training_loss": 55.4320592880249, "training_acc": 52.5, "val_loss": 13.858668804168701, "val_acc": 50.0, "val_auroc": 0.73, "time": 567.97}
{"epoch": 33, "training_loss": 55.45953559875488, "training_acc": 47.5, "val_loss": 13.85840892791748, "val_acc": 50.0, "val_auroc": 0.75, "time": 585.97}
{"epoch": 34, "training_loss": 55.47806167602539, "training_acc": 47.5, "val_loss": 13.859301805496216, "val_acc": 50.0, "val_auroc": 0.77, "time": 603.08}
{"epoch": 35, "training_loss": 55.5049934387207, "training_acc": 52.5, "val_loss": 13.871023654937744, "val_acc": 50.0, "val_auroc": 0.66, "time": 620.07}
{"epoch": 36, "training_loss": 55.35110664367676, "training_acc": 52.5, "val_loss": 13.872133493423462, "val_acc": 50.0, "val_auroc": 0.69, "time": 635.42}
{"epoch": 37, "training_loss": 55.356261253356934, "training_acc": 52.5, "val_loss": 13.868926763534546, "val_acc": 50.0, "val_auroc": 0.73, "time": 650.24}
{"epoch": 38, "training_loss": 55.37880802154541, "training_acc": 52.5, "val_loss": 13.866733312606812, "val_acc": 50.0, "val_auroc": 0.77, "time": 667.01}
{"epoch": 39, "training_loss": 55.35951232910156, "training_acc": 52.5, "val_loss": 13.873547315597534, "val_acc": 50.0, "val_auroc": 0.77, "time": 683.58}
{"epoch": 40, "training_loss": 55.376508712768555, "training_acc": 52.5, "val_loss": 13.873475790023804, "val_acc": 50.0, "val_auroc": 0.82, "time": 699.33}
{"epoch": 41, "training_loss": 55.326860427856445, "training_acc": 52.5, "val_loss": 13.86332392692566, "val_acc": 50.0, "val_auroc": 0.84, "time": 716.72}
{"epoch": 42, "training_loss": 55.397823333740234, "training_acc": 52.5, "val_loss": 13.859225511550903, "val_acc": 50.0, "val_auroc": 0.89, "time": 733.65}
{"epoch": 43, "training_loss": 55.381545066833496, "training_acc": 52.5, "val_loss": 13.861701488494873, "val_acc": 50.0, "val_auroc": 0.83, "time": 750.38}
{"epoch": 44, "training_loss": 55.36389350891113, "training_acc": 52.5, "val_loss": 13.864779472351074, "val_acc": 50.0, "val_auroc": 0.83, "time": 767.05}
{"epoch": 45, "training_loss": 55.34828567504883, "training_acc": 52.5, "val_loss": 13.867415189743042, "val_acc": 50.0, "val_auroc": 0.83, "time": 784.6}
{"epoch": 46, "training_loss": 55.34291648864746, "training_acc": 52.5, "val_loss": 13.871620893478394, "val_acc": 50.0, "val_auroc": 0.84, "time": 801.71}
{"epoch": 47, "training_loss": 55.336825370788574, "training_acc": 52.5, "val_loss": 13.87766718864441, "val_acc": 50.0, "val_auroc": 0.85, "time": 818.93}
{"epoch": 48, "training_loss": 55.33222198486328, "training_acc": 52.5, "val_loss": 13.8884437084198, "val_acc": 50.0, "val_auroc": 0.87, "time": 835.5}
{"epoch": 49, "training_loss": 55.33778762817383, "training_acc": 52.5, "val_loss": 13.913387060165405, "val_acc": 50.0, "val_auroc": 0.86, "time": 853.38}
{"epoch": 50, "training_loss": 55.36174201965332, "training_acc": 52.5, "val_loss": 13.922923803329468, "val_acc": 50.0, "val_auroc": 0.83, "time": 870.29}
{"epoch": 51, "training_loss": 55.363850593566895, "training_acc": 52.5, "val_loss": 13.914440870285034, "val_acc": 50.0, "val_auroc": 0.83, "time": 887.71}
{"epoch": 52, "training_loss": 55.379390716552734, "training_acc": 52.5, "val_loss": 13.90471339225769, "val_acc": 50.0, "val_auroc": 0.83, "time": 905.0}
