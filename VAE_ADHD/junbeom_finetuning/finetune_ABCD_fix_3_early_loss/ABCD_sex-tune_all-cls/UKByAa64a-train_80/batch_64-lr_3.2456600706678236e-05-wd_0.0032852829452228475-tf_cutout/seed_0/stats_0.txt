"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.508113861083984, "training_acc": 52.5, "val_loss": 13.929728269577026, "val_acc": 50.0, "val_auroc": 0.24, "time": 19.47}
{"epoch": 1, "training_loss": 55.28644371032715, "training_acc": 52.5, "val_loss": 13.830910921096802, "val_acc": 50.0, "val_auroc": 0.62, "time": 37.67}
{"epoch": 2, "training_loss": 55.31941604614258, "training_acc": 52.5, "val_loss": 13.836251497268677, "val_acc": 50.0, "val_auroc": 0.64, "time": 55.75}
{"epoch": 3, "training_loss": 55.20741081237793, "training_acc": 52.5, "val_loss": 13.867759704589844, "val_acc": 50.0, "val_auroc": 0.52, "time": 72.77}
{"epoch": 4, "training_loss": 55.08905506134033, "training_acc": 52.5, "val_loss": 13.861761093139648, "val_acc": 50.0, "val_auroc": 0.5, "time": 89.89}
{"epoch": 5, "training_loss": 55.12874412536621, "training_acc": 52.5, "val_loss": 13.849853277206421, "val_acc": 50.0, "val_auroc": 0.56, "time": 106.77}
{"epoch": 6, "training_loss": 55.05363845825195, "training_acc": 52.5, "val_loss": 13.828471899032593, "val_acc": 50.0, "val_auroc": 0.57, "time": 123.92}
{"epoch": 7, "training_loss": 54.749107360839844, "training_acc": 62.5, "val_loss": 13.84401559829712, "val_acc": 50.0, "val_auroc": 0.51, "time": 140.72}
{"epoch": 8, "training_loss": 54.63825511932373, "training_acc": 73.75, "val_loss": 13.840612173080444, "val_acc": 50.0, "val_auroc": 0.55, "time": 157.65}
{"epoch": 9, "training_loss": 54.552452087402344, "training_acc": 76.25, "val_loss": 13.81503939628601, "val_acc": 50.0, "val_auroc": 0.55, "time": 174.89}
{"epoch": 10, "training_loss": 54.346200942993164, "training_acc": 73.75, "val_loss": 13.797907829284668, "val_acc": 50.0, "val_auroc": 0.59, "time": 191.71}
{"epoch": 11, "training_loss": 53.86063575744629, "training_acc": 78.75, "val_loss": 13.808640241622925, "val_acc": 50.0, "val_auroc": 0.57, "time": 208.36}
{"epoch": 12, "training_loss": 53.9212589263916, "training_acc": 53.75, "val_loss": 13.773256540298462, "val_acc": 50.0, "val_auroc": 0.67, "time": 225.83}
{"epoch": 13, "training_loss": 53.58363723754883, "training_acc": 66.25, "val_loss": 13.789538145065308, "val_acc": 50.0, "val_auroc": 0.61, "time": 242.34}
{"epoch": 14, "training_loss": 53.308921813964844, "training_acc": 55.0, "val_loss": 14.038794040679932, "val_acc": 50.0, "val_auroc": 0.52, "time": 258.97}
{"epoch": 15, "training_loss": 54.20170497894287, "training_acc": 52.5, "val_loss": 14.141291379928589, "val_acc": 50.0, "val_auroc": 0.45, "time": 275.45}
{"epoch": 16, "training_loss": 53.79478073120117, "training_acc": 52.5, "val_loss": 13.895798921585083, "val_acc": 50.0, "val_auroc": 0.53, "time": 292.32}
{"epoch": 17, "training_loss": 52.87553119659424, "training_acc": 56.25, "val_loss": 13.930977582931519, "val_acc": 50.0, "val_auroc": 0.49, "time": 309.04}
{"epoch": 18, "training_loss": 51.70238399505615, "training_acc": 60.0, "val_loss": 13.815500736236572, "val_acc": 50.0, "val_auroc": 0.52, "time": 325.55}
{"epoch": 19, "training_loss": 51.40770435333252, "training_acc": 73.75, "val_loss": 13.954412937164307, "val_acc": 50.0, "val_auroc": 0.37, "time": 343.62}
{"epoch": 20, "training_loss": 53.14904594421387, "training_acc": 81.25, "val_loss": 13.894293308258057, "val_acc": 50.0, "val_auroc": 0.51, "time": 360.49}
{"epoch": 21, "training_loss": 50.48668670654297, "training_acc": 67.5, "val_loss": 13.732948303222656, "val_acc": 50.0, "val_auroc": 0.54, "time": 377.32}
{"epoch": 22, "training_loss": 49.45964241027832, "training_acc": 86.25, "val_loss": 13.824571371078491, "val_acc": 50.0, "val_auroc": 0.5, "time": 393.88}
{"epoch": 23, "training_loss": 48.108635902404785, "training_acc": 81.25, "val_loss": 13.773678541183472, "val_acc": 50.0, "val_auroc": 0.54, "time": 410.43}
{"epoch": 24, "training_loss": 48.566078186035156, "training_acc": 87.5, "val_loss": 13.800718784332275, "val_acc": 50.0, "val_auroc": 0.55, "time": 428.07}
{"epoch": 25, "training_loss": 48.28233623504639, "training_acc": 83.75, "val_loss": 13.702783584594727, "val_acc": 50.0, "val_auroc": 0.55, "time": 444.76}
{"epoch": 26, "training_loss": 46.357688903808594, "training_acc": 90.0, "val_loss": 13.779882192611694, "val_acc": 50.0, "val_auroc": 0.51, "time": 461.12}
{"epoch": 27, "training_loss": 45.13468265533447, "training_acc": 83.75, "val_loss": 13.644472360610962, "val_acc": 50.0, "val_auroc": 0.59, "time": 478.19}
{"epoch": 28, "training_loss": 43.57052040100098, "training_acc": 88.75, "val_loss": 13.945647478103638, "val_acc": 50.0, "val_auroc": 0.51, "time": 494.86}
{"epoch": 29, "training_loss": 46.03626346588135, "training_acc": 82.5, "val_loss": 14.020576477050781, "val_acc": 50.0, "val_auroc": 0.51, "time": 511.43}
{"epoch": 30, "training_loss": 45.32888698577881, "training_acc": 73.75, "val_loss": 13.698724508285522, "val_acc": 55.0, "val_auroc": 0.56, "time": 528.27}
{"epoch": 31, "training_loss": 40.85020446777344, "training_acc": 90.0, "val_loss": 13.672224283218384, "val_acc": 50.0, "val_auroc": 0.61, "time": 545.13}
{"epoch": 32, "training_loss": 41.23116731643677, "training_acc": 92.5, "val_loss": 13.836005926132202, "val_acc": 50.0, "val_auroc": 0.56, "time": 562.27}
{"epoch": 33, "training_loss": 40.84812259674072, "training_acc": 87.5, "val_loss": 13.786031007766724, "val_acc": 60.0, "val_auroc": 0.58, "time": 578.74}
{"epoch": 34, "training_loss": 38.5813307762146, "training_acc": 91.25, "val_loss": 13.845824003219604, "val_acc": 60.0, "val_auroc": 0.58, "time": 595.13}
{"epoch": 35, "training_loss": 36.513760566711426, "training_acc": 95.0, "val_loss": 13.83716344833374, "val_acc": 50.0, "val_auroc": 0.62, "time": 611.67}
{"epoch": 36, "training_loss": 39.55357074737549, "training_acc": 92.5, "val_loss": 14.083245992660522, "val_acc": 50.0, "val_auroc": 0.54, "time": 628.84}
{"epoch": 37, "training_loss": 37.18960237503052, "training_acc": 88.75, "val_loss": 13.908387422561646, "val_acc": 50.0, "val_auroc": 0.61, "time": 645.22}
{"epoch": 38, "training_loss": 34.48615550994873, "training_acc": 96.25, "val_loss": 14.162288904190063, "val_acc": 50.0, "val_auroc": 0.54, "time": 662.0}
{"epoch": 39, "training_loss": 35.992552757263184, "training_acc": 91.25, "val_loss": 14.109011888504028, "val_acc": 50.0, "val_auroc": 0.57, "time": 678.53}
{"epoch": 40, "training_loss": 33.457563400268555, "training_acc": 96.25, "val_loss": 14.458649158477783, "val_acc": 50.0, "val_auroc": 0.51, "time": 695.45}
{"epoch": 41, "training_loss": 34.98485088348389, "training_acc": 91.25, "val_loss": 14.572956562042236, "val_acc": 45.0, "val_auroc": 0.57, "time": 712.05}
{"epoch": 42, "training_loss": 37.662123680114746, "training_acc": 88.75, "val_loss": 14.259355068206787, "val_acc": 55.0, "val_auroc": 0.54, "time": 728.49}
{"epoch": 43, "training_loss": 32.065202713012695, "training_acc": 95.0, "val_loss": 14.174517393112183, "val_acc": 50.0, "val_auroc": 0.58, "time": 745.0}
{"epoch": 44, "training_loss": 30.493562698364258, "training_acc": 97.5, "val_loss": 14.2022705078125, "val_acc": 55.0, "val_auroc": 0.56, "time": 761.96}
{"epoch": 45, "training_loss": 29.465500354766846, "training_acc": 97.5, "val_loss": 14.18192744255066, "val_acc": 55.0, "val_auroc": 0.58, "time": 778.69}
{"epoch": 46, "training_loss": 27.93805170059204, "training_acc": 98.75, "val_loss": 14.293661117553711, "val_acc": 50.0, "val_auroc": 0.55, "time": 795.54}
