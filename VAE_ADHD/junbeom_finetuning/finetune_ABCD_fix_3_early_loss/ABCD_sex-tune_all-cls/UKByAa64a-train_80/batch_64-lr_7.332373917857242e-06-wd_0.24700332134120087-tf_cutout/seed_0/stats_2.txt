"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.99189853668213, "training_acc": 52.5, "val_loss": 14.166116714477539, "val_acc": 50.0, "val_auroc": 0.42, "time": 19.59}
{"epoch": 1, "training_loss": 55.78574752807617, "training_acc": 52.5, "val_loss": 14.143073558807373, "val_acc": 50.0, "val_auroc": 0.4, "time": 37.17}
{"epoch": 2, "training_loss": 55.591105461120605, "training_acc": 52.5, "val_loss": 14.114410877227783, "val_acc": 50.0, "val_auroc": 0.52, "time": 54.98}
{"epoch": 3, "training_loss": 55.744476318359375, "training_acc": 52.5, "val_loss": 14.087507724761963, "val_acc": 50.0, "val_auroc": 0.57, "time": 72.5}
{"epoch": 4, "training_loss": 55.533034324645996, "training_acc": 52.5, "val_loss": 14.097026586532593, "val_acc": 50.0, "val_auroc": 0.48, "time": 89.08}
{"epoch": 5, "training_loss": 55.428205490112305, "training_acc": 52.5, "val_loss": 14.09771203994751, "val_acc": 50.0, "val_auroc": 0.43, "time": 105.34}
{"epoch": 6, "training_loss": 55.29496955871582, "training_acc": 52.5, "val_loss": 14.093828201293945, "val_acc": 50.0, "val_auroc": 0.36, "time": 121.87}
{"epoch": 7, "training_loss": 55.16323757171631, "training_acc": 52.5, "val_loss": 14.086958169937134, "val_acc": 50.0, "val_auroc": 0.36, "time": 138.51}
{"epoch": 8, "training_loss": 55.05168342590332, "training_acc": 52.5, "val_loss": 14.07953143119812, "val_acc": 50.0, "val_auroc": 0.36, "time": 155.59}
{"epoch": 9, "training_loss": 54.920546531677246, "training_acc": 52.5, "val_loss": 14.052293300628662, "val_acc": 50.0, "val_auroc": 0.41, "time": 172.33}
{"epoch": 10, "training_loss": 54.67281532287598, "training_acc": 52.5, "val_loss": 13.996056318283081, "val_acc": 50.0, "val_auroc": 0.47, "time": 189.73}
{"epoch": 11, "training_loss": 54.70760154724121, "training_acc": 52.5, "val_loss": 13.999887704849243, "val_acc": 50.0, "val_auroc": 0.43, "time": 206.54}
{"epoch": 12, "training_loss": 54.58663558959961, "training_acc": 52.5, "val_loss": 14.03762698173523, "val_acc": 50.0, "val_auroc": 0.35, "time": 223.59}
{"epoch": 13, "training_loss": 54.52873706817627, "training_acc": 52.5, "val_loss": 14.038118124008179, "val_acc": 50.0, "val_auroc": 0.32, "time": 240.09}
{"epoch": 14, "training_loss": 54.33729362487793, "training_acc": 52.5, "val_loss": 14.032431840896606, "val_acc": 50.0, "val_auroc": 0.35, "time": 257.09}
{"epoch": 15, "training_loss": 54.44686698913574, "training_acc": 52.5, "val_loss": 14.033485651016235, "val_acc": 50.0, "val_auroc": 0.37, "time": 273.8}
{"epoch": 16, "training_loss": 54.18643379211426, "training_acc": 52.5, "val_loss": 13.981481790542603, "val_acc": 50.0, "val_auroc": 0.52, "time": 290.45}
{"epoch": 17, "training_loss": 54.00528812408447, "training_acc": 52.5, "val_loss": 13.977783918380737, "val_acc": 50.0, "val_auroc": 0.53, "time": 307.19}
{"epoch": 18, "training_loss": 53.89201545715332, "training_acc": 52.5, "val_loss": 14.076284170150757, "val_acc": 50.0, "val_auroc": 0.26, "time": 323.78}
{"epoch": 19, "training_loss": 53.97871398925781, "training_acc": 52.5, "val_loss": 14.040466547012329, "val_acc": 50.0, "val_auroc": 0.36, "time": 340.22}
{"epoch": 20, "training_loss": 53.7241096496582, "training_acc": 52.5, "val_loss": 13.911272287368774, "val_acc": 50.0, "val_auroc": 0.58, "time": 356.85}
{"epoch": 21, "training_loss": 53.92475605010986, "training_acc": 52.5, "val_loss": 13.97914171218872, "val_acc": 50.0, "val_auroc": 0.49, "time": 373.19}
{"epoch": 22, "training_loss": 53.713690757751465, "training_acc": 52.5, "val_loss": 14.107420444488525, "val_acc": 50.0, "val_auroc": 0.23, "time": 389.85}
{"epoch": 23, "training_loss": 53.641204833984375, "training_acc": 52.5, "val_loss": 14.006325006484985, "val_acc": 50.0, "val_auroc": 0.43, "time": 406.35}
{"epoch": 24, "training_loss": 53.53061389923096, "training_acc": 53.75, "val_loss": 13.875817060470581, "val_acc": 50.0, "val_auroc": 0.65, "time": 423.45}
{"epoch": 25, "training_loss": 53.858211517333984, "training_acc": 52.5, "val_loss": 13.97891879081726, "val_acc": 50.0, "val_auroc": 0.49, "time": 440.14}
{"epoch": 26, "training_loss": 53.504897117614746, "training_acc": 52.5, "val_loss": 14.164108037948608, "val_acc": 50.0, "val_auroc": 0.24, "time": 456.91}
{"epoch": 27, "training_loss": 53.65124702453613, "training_acc": 52.5, "val_loss": 14.10191297531128, "val_acc": 50.0, "val_auroc": 0.31, "time": 473.69}
{"epoch": 28, "training_loss": 53.075551986694336, "training_acc": 53.75, "val_loss": 13.929237127304077, "val_acc": 50.0, "val_auroc": 0.55, "time": 490.39}
{"epoch": 29, "training_loss": 53.33003520965576, "training_acc": 52.5, "val_loss": 13.992341756820679, "val_acc": 50.0, "val_auroc": 0.47, "time": 506.91}
{"epoch": 30, "training_loss": 53.296342849731445, "training_acc": 53.75, "val_loss": 14.146260023117065, "val_acc": 50.0, "val_auroc": 0.24, "time": 523.25}
{"epoch": 31, "training_loss": 52.96407699584961, "training_acc": 58.75, "val_loss": 14.09663438796997, "val_acc": 50.0, "val_auroc": 0.31, "time": 539.98}
{"epoch": 32, "training_loss": 52.5689697265625, "training_acc": 60.0, "val_loss": 13.940271139144897, "val_acc": 50.0, "val_auroc": 0.49, "time": 556.79}
{"epoch": 33, "training_loss": 52.785200119018555, "training_acc": 57.5, "val_loss": 13.989624977111816, "val_acc": 50.0, "val_auroc": 0.41, "time": 573.32}
{"epoch": 34, "training_loss": 52.67243576049805, "training_acc": 56.25, "val_loss": 13.997659683227539, "val_acc": 50.0, "val_auroc": 0.42, "time": 589.81}
{"epoch": 35, "training_loss": 52.53825092315674, "training_acc": 60.0, "val_loss": 13.991260528564453, "val_acc": 50.0, "val_auroc": 0.42, "time": 606.49}
{"epoch": 36, "training_loss": 51.9043083190918, "training_acc": 66.25, "val_loss": 13.9840829372406, "val_acc": 50.0, "val_auroc": 0.46, "time": 623.34}
{"epoch": 37, "training_loss": 52.35795211791992, "training_acc": 61.25, "val_loss": 13.98577332496643, "val_acc": 50.0, "val_auroc": 0.45, "time": 639.97}
{"epoch": 38, "training_loss": 51.67766761779785, "training_acc": 70.0, "val_loss": 13.913971185684204, "val_acc": 50.0, "val_auroc": 0.51, "time": 656.69}
{"epoch": 39, "training_loss": 51.847856521606445, "training_acc": 65.0, "val_loss": 14.013779163360596, "val_acc": 50.0, "val_auroc": 0.4, "time": 674.37}
{"epoch": 40, "training_loss": 51.71169090270996, "training_acc": 68.75, "val_loss": 14.054824113845825, "val_acc": 50.0, "val_auroc": 0.38, "time": 691.12}
{"epoch": 41, "training_loss": 51.12682914733887, "training_acc": 75.0, "val_loss": 13.974798917770386, "val_acc": 50.0, "val_auroc": 0.43, "time": 707.9}
{"epoch": 42, "training_loss": 51.640567779541016, "training_acc": 70.0, "val_loss": 13.980896472930908, "val_acc": 50.0, "val_auroc": 0.44, "time": 724.15}
{"epoch": 43, "training_loss": 51.41644477844238, "training_acc": 65.0, "val_loss": 13.9705491065979, "val_acc": 50.0, "val_auroc": 0.43, "time": 740.7}
