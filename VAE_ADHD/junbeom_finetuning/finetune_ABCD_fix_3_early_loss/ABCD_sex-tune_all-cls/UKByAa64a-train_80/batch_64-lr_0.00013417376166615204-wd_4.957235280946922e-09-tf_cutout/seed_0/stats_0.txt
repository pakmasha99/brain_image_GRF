"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.63142013549805, "training_acc": 52.5, "val_loss": 13.907636404037476, "val_acc": 50.0, "val_auroc": 0.42, "time": 19.49}
{"epoch": 1, "training_loss": 55.341708183288574, "training_acc": 52.5, "val_loss": 13.885506391525269, "val_acc": 50.0, "val_auroc": 0.39, "time": 37.34}
{"epoch": 2, "training_loss": 55.38533020019531, "training_acc": 52.5, "val_loss": 13.903710842132568, "val_acc": 50.0, "val_auroc": 0.37, "time": 54.99}
{"epoch": 3, "training_loss": 55.25637149810791, "training_acc": 52.5, "val_loss": 13.892207145690918, "val_acc": 50.0, "val_auroc": 0.4, "time": 72.63}
{"epoch": 4, "training_loss": 55.195491790771484, "training_acc": 52.5, "val_loss": 13.903480768203735, "val_acc": 50.0, "val_auroc": 0.39, "time": 90.48}
{"epoch": 5, "training_loss": 55.31254768371582, "training_acc": 52.5, "val_loss": 13.897099494934082, "val_acc": 50.0, "val_auroc": 0.4, "time": 107.87}
{"epoch": 6, "training_loss": 55.30481147766113, "training_acc": 53.75, "val_loss": 13.903502225875854, "val_acc": 50.0, "val_auroc": 0.41, "time": 125.55}
{"epoch": 7, "training_loss": 55.4187593460083, "training_acc": 48.75, "val_loss": 13.911970853805542, "val_acc": 50.0, "val_auroc": 0.4, "time": 142.53}
{"epoch": 8, "training_loss": 55.22930145263672, "training_acc": 56.25, "val_loss": 13.919662237167358, "val_acc": 50.0, "val_auroc": 0.43, "time": 159.46}
{"epoch": 9, "training_loss": 55.32619285583496, "training_acc": 50.0, "val_loss": 13.896951675415039, "val_acc": 50.0, "val_auroc": 0.44, "time": 176.67}
{"epoch": 10, "training_loss": 55.05368232727051, "training_acc": 52.5, "val_loss": 14.01863694190979, "val_acc": 50.0, "val_auroc": 0.49, "time": 193.61}
{"epoch": 11, "training_loss": 55.08145999908447, "training_acc": 52.5, "val_loss": 14.072109460830688, "val_acc": 50.0, "val_auroc": 0.48, "time": 211.12}
{"epoch": 12, "training_loss": 55.06843090057373, "training_acc": 52.5, "val_loss": 13.988512754440308, "val_acc": 50.0, "val_auroc": 0.5, "time": 228.23}
{"epoch": 13, "training_loss": 54.71485137939453, "training_acc": 52.5, "val_loss": 14.376153945922852, "val_acc": 50.0, "val_auroc": 0.48, "time": 245.65}
{"epoch": 14, "training_loss": 56.510108947753906, "training_acc": 52.5, "val_loss": 14.428590536117554, "val_acc": 50.0, "val_auroc": 0.43, "time": 262.64}
{"epoch": 15, "training_loss": 56.613962173461914, "training_acc": 52.5, "val_loss": 14.336202144622803, "val_acc": 50.0, "val_auroc": 0.34, "time": 280.02}
{"epoch": 16, "training_loss": 56.0195426940918, "training_acc": 52.5, "val_loss": 14.093685150146484, "val_acc": 50.0, "val_auroc": 0.45, "time": 296.82}
{"epoch": 17, "training_loss": 54.996548652648926, "training_acc": 52.5, "val_loss": 13.939741849899292, "val_acc": 50.0, "val_auroc": 0.44, "time": 314.04}
{"epoch": 18, "training_loss": 54.808794021606445, "training_acc": 52.5, "val_loss": 13.959671258926392, "val_acc": 50.0, "val_auroc": 0.43, "time": 331.29}
{"epoch": 19, "training_loss": 55.097296714782715, "training_acc": 57.5, "val_loss": 13.946837186813354, "val_acc": 50.0, "val_auroc": 0.42, "time": 348.05}
{"epoch": 20, "training_loss": 54.60849952697754, "training_acc": 68.75, "val_loss": 13.958507776260376, "val_acc": 50.0, "val_auroc": 0.38, "time": 364.74}
