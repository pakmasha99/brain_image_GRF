"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.655805587768555, "training_acc": 52.5, "val_loss": 13.953307867050171, "val_acc": 50.0, "val_auroc": 0.4, "time": 19.87}
{"epoch": 1, "training_loss": 55.41422653198242, "training_acc": 52.5, "val_loss": 13.981274366378784, "val_acc": 50.0, "val_auroc": 0.31, "time": 37.72}
{"epoch": 2, "training_loss": 55.27301788330078, "training_acc": 52.5, "val_loss": 13.946483135223389, "val_acc": 50.0, "val_auroc": 0.41, "time": 56.35}
{"epoch": 3, "training_loss": 55.41365909576416, "training_acc": 52.5, "val_loss": 13.992284536361694, "val_acc": 50.0, "val_auroc": 0.23, "time": 74.05}
{"epoch": 4, "training_loss": 55.36425971984863, "training_acc": 52.5, "val_loss": 13.913620710372925, "val_acc": 50.0, "val_auroc": 0.31, "time": 91.47}
{"epoch": 5, "training_loss": 55.34535789489746, "training_acc": 52.5, "val_loss": 13.89034628868103, "val_acc": 50.0, "val_auroc": 0.59, "time": 109.2}
{"epoch": 6, "training_loss": 55.40954780578613, "training_acc": 52.5, "val_loss": 13.977402448654175, "val_acc": 50.0, "val_auroc": 0.66, "time": 126.53}
{"epoch": 7, "training_loss": 55.463117599487305, "training_acc": 52.5, "val_loss": 14.040192365646362, "val_acc": 50.0, "val_auroc": 0.41, "time": 143.99}
{"epoch": 8, "training_loss": 55.643123626708984, "training_acc": 52.5, "val_loss": 13.920221328735352, "val_acc": 50.0, "val_auroc": 0.33, "time": 161.27}
{"epoch": 9, "training_loss": 55.31730556488037, "training_acc": 52.5, "val_loss": 13.867758512496948, "val_acc": 50.0, "val_auroc": 0.5, "time": 178.52}
{"epoch": 10, "training_loss": 55.458003997802734, "training_acc": 50.0, "val_loss": 13.872263431549072, "val_acc": 50.0, "val_auroc": 0.38, "time": 195.76}
{"epoch": 11, "training_loss": 55.3336296081543, "training_acc": 52.5, "val_loss": 13.915249109268188, "val_acc": 50.0, "val_auroc": 0.57, "time": 212.95}
{"epoch": 12, "training_loss": 55.38724899291992, "training_acc": 52.5, "val_loss": 13.954323530197144, "val_acc": 50.0, "val_auroc": 0.49, "time": 230.16}
{"epoch": 13, "training_loss": 55.38445854187012, "training_acc": 52.5, "val_loss": 13.899441957473755, "val_acc": 50.0, "val_auroc": 0.41, "time": 247.0}
{"epoch": 14, "training_loss": 55.32033729553223, "training_acc": 52.5, "val_loss": 13.870152235031128, "val_acc": 50.0, "val_auroc": 0.56, "time": 264.09}
{"epoch": 15, "training_loss": 55.50328731536865, "training_acc": 53.75, "val_loss": 13.894835710525513, "val_acc": 50.0, "val_auroc": 0.37, "time": 281.14}
{"epoch": 16, "training_loss": 55.221099853515625, "training_acc": 52.5, "val_loss": 14.047659635543823, "val_acc": 50.0, "val_auroc": 0.41, "time": 298.36}
{"epoch": 17, "training_loss": 55.70619010925293, "training_acc": 52.5, "val_loss": 14.08531665802002, "val_acc": 50.0, "val_auroc": 0.22, "time": 315.54}
{"epoch": 18, "training_loss": 55.61258888244629, "training_acc": 52.5, "val_loss": 13.916599750518799, "val_acc": 50.0, "val_auroc": 0.22, "time": 330.27}
{"epoch": 19, "training_loss": 55.28511905670166, "training_acc": 52.5, "val_loss": 13.85841965675354, "val_acc": 50.0, "val_auroc": 0.61, "time": 347.59}
{"epoch": 20, "training_loss": 55.49582862854004, "training_acc": 51.25, "val_loss": 13.855729103088379, "val_acc": 50.0, "val_auroc": 0.69, "time": 364.96}
{"epoch": 21, "training_loss": 55.441593170166016, "training_acc": 50.0, "val_loss": 13.871992826461792, "val_acc": 50.0, "val_auroc": 0.73, "time": 382.82}
{"epoch": 22, "training_loss": 55.32929229736328, "training_acc": 52.5, "val_loss": 13.925501108169556, "val_acc": 50.0, "val_auroc": 0.74, "time": 399.13}
{"epoch": 23, "training_loss": 55.39792060852051, "training_acc": 52.5, "val_loss": 13.987572193145752, "val_acc": 50.0, "val_auroc": 0.67, "time": 416.52}
{"epoch": 24, "training_loss": 55.49166774749756, "training_acc": 52.5, "val_loss": 14.055002927780151, "val_acc": 50.0, "val_auroc": 0.57, "time": 433.7}
{"epoch": 25, "training_loss": 55.65259647369385, "training_acc": 52.5, "val_loss": 14.045469760894775, "val_acc": 50.0, "val_auroc": 0.49, "time": 451.04}
{"epoch": 26, "training_loss": 55.75606727600098, "training_acc": 52.5, "val_loss": 14.014188051223755, "val_acc": 50.0, "val_auroc": 0.45, "time": 468.45}
{"epoch": 27, "training_loss": 55.51750469207764, "training_acc": 52.5, "val_loss": 14.029344320297241, "val_acc": 50.0, "val_auroc": 0.4, "time": 485.72}
{"epoch": 28, "training_loss": 55.63974952697754, "training_acc": 52.5, "val_loss": 13.92271637916565, "val_acc": 50.0, "val_auroc": 0.31, "time": 503.18}
{"epoch": 29, "training_loss": 55.42507457733154, "training_acc": 52.5, "val_loss": 13.858569860458374, "val_acc": 50.0, "val_auroc": 0.69, "time": 520.44}
{"epoch": 30, "training_loss": 55.44445037841797, "training_acc": 51.25, "val_loss": 13.858319520950317, "val_acc": 50.0, "val_auroc": 0.71, "time": 537.66}
{"epoch": 31, "training_loss": 55.48456001281738, "training_acc": 48.75, "val_loss": 13.860175609588623, "val_acc": 50.0, "val_auroc": 0.77, "time": 555.17}
{"epoch": 32, "training_loss": 55.42283821105957, "training_acc": 52.5, "val_loss": 13.862112760543823, "val_acc": 50.0, "val_auroc": 0.62, "time": 572.34}
{"epoch": 33, "training_loss": 55.42378234863281, "training_acc": 52.5, "val_loss": 13.859560489654541, "val_acc": 50.0, "val_auroc": 0.7, "time": 589.29}
{"epoch": 34, "training_loss": 55.46057891845703, "training_acc": 47.5, "val_loss": 13.866075277328491, "val_acc": 50.0, "val_auroc": 0.7, "time": 607.28}
{"epoch": 35, "training_loss": 55.5341739654541, "training_acc": 52.5, "val_loss": 13.891843557357788, "val_acc": 50.0, "val_auroc": 0.56, "time": 624.74}
{"epoch": 36, "training_loss": 55.33295440673828, "training_acc": 52.5, "val_loss": 13.879214525222778, "val_acc": 50.0, "val_auroc": 0.39, "time": 642.35}
{"epoch": 37, "training_loss": 55.337815284729004, "training_acc": 52.5, "val_loss": 13.867781162261963, "val_acc": 50.0, "val_auroc": 0.47, "time": 659.48}
{"epoch": 38, "training_loss": 55.468825340270996, "training_acc": 47.5, "val_loss": 13.864903450012207, "val_acc": 50.0, "val_auroc": 0.57, "time": 676.42}
{"epoch": 39, "training_loss": 55.41630268096924, "training_acc": 52.5, "val_loss": 13.878412246704102, "val_acc": 50.0, "val_auroc": 0.48, "time": 694.1}
