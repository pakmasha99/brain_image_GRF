"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 66.23196029663086, "training_acc": 47.5, "val_loss": 69.31931495666504, "val_acc": 50.0, "val_auroc": 0.53, "time": 19.66}
{"epoch": 1, "training_loss": 243.96992111206055, "training_acc": 52.5, "val_loss": 13.894655704498291, "val_acc": 50.0, "val_auroc": 0.25, "time": 38.03}
{"epoch": 2, "training_loss": 57.39102745056152, "training_acc": 50.0, "val_loss": 40.7304048538208, "val_acc": 50.0, "val_auroc": 0.68, "time": 55.99}
{"epoch": 3, "training_loss": 144.74363613128662, "training_acc": 47.5, "val_loss": 14.101762771606445, "val_acc": 50.0, "val_auroc": 0.25, "time": 73.78}
{"epoch": 4, "training_loss": 56.31400775909424, "training_acc": 52.5, "val_loss": 14.293441772460938, "val_acc": 50.0, "val_auroc": 0.24, "time": 91.23}
{"epoch": 5, "training_loss": 56.275367736816406, "training_acc": 52.5, "val_loss": 13.891297578811646, "val_acc": 50.0, "val_auroc": 0.24, "time": 109.22}
{"epoch": 6, "training_loss": 55.81611442565918, "training_acc": 42.5, "val_loss": 14.566892385482788, "val_acc": 50.0, "val_auroc": 0.26, "time": 126.61}
{"epoch": 7, "training_loss": 57.02812957763672, "training_acc": 52.5, "val_loss": 14.2083740234375, "val_acc": 50.0, "val_auroc": 0.25, "time": 144.17}
{"epoch": 8, "training_loss": 55.48592185974121, "training_acc": 52.5, "val_loss": 13.915457725524902, "val_acc": 50.0, "val_auroc": 0.27, "time": 161.36}
{"epoch": 9, "training_loss": 56.034080505371094, "training_acc": 47.5, "val_loss": 13.986221551895142, "val_acc": 50.0, "val_auroc": 0.69, "time": 178.77}
{"epoch": 10, "training_loss": 56.24320030212402, "training_acc": 47.5, "val_loss": 13.868582248687744, "val_acc": 50.0, "val_auroc": 0.66, "time": 196.52}
{"epoch": 11, "training_loss": 55.178462982177734, "training_acc": 52.5, "val_loss": 14.193321466445923, "val_acc": 50.0, "val_auroc": 0.25, "time": 213.37}
{"epoch": 12, "training_loss": 56.13010215759277, "training_acc": 52.5, "val_loss": 14.175643920898438, "val_acc": 50.0, "val_auroc": 0.25, "time": 229.28}
{"epoch": 13, "training_loss": 55.841508865356445, "training_acc": 52.5, "val_loss": 13.923852443695068, "val_acc": 50.0, "val_auroc": 0.26, "time": 246.52}
{"epoch": 14, "training_loss": 55.34368324279785, "training_acc": 52.5, "val_loss": 13.86720895767212, "val_acc": 50.0, "val_auroc": 0.19, "time": 264.35}
{"epoch": 15, "training_loss": 55.632253646850586, "training_acc": 45.0, "val_loss": 13.863608837127686, "val_acc": 50.0, "val_auroc": 0.48, "time": 281.51}
{"epoch": 16, "training_loss": 55.37955284118652, "training_acc": 55.0, "val_loss": 13.887141942977905, "val_acc": 50.0, "val_auroc": 0.66, "time": 299.14}
{"epoch": 17, "training_loss": 55.38080883026123, "training_acc": 52.5, "val_loss": 13.969074487686157, "val_acc": 50.0, "val_auroc": 0.44, "time": 316.6}
{"epoch": 18, "training_loss": 55.51830768585205, "training_acc": 52.5, "val_loss": 13.979954719543457, "val_acc": 50.0, "val_auroc": 0.36, "time": 334.19}
{"epoch": 19, "training_loss": 55.4433536529541, "training_acc": 52.5, "val_loss": 13.911666870117188, "val_acc": 50.0, "val_auroc": 0.4, "time": 351.49}
{"epoch": 20, "training_loss": 55.38780212402344, "training_acc": 52.5, "val_loss": 13.8705575466156, "val_acc": 50.0, "val_auroc": 0.54, "time": 368.82}
{"epoch": 21, "training_loss": 55.37936878204346, "training_acc": 52.5, "val_loss": 13.863625526428223, "val_acc": 50.0, "val_auroc": 0.81, "time": 385.7}
{"epoch": 22, "training_loss": 55.38425636291504, "training_acc": 52.5, "val_loss": 13.8694167137146, "val_acc": 50.0, "val_auroc": 0.84, "time": 403.21}
{"epoch": 23, "training_loss": 55.334163665771484, "training_acc": 52.5, "val_loss": 13.896640539169312, "val_acc": 50.0, "val_auroc": 0.88, "time": 420.75}
{"epoch": 24, "training_loss": 55.30643081665039, "training_acc": 52.5, "val_loss": 13.966350555419922, "val_acc": 50.0, "val_auroc": 0.5, "time": 438.49}
{"epoch": 25, "training_loss": 55.449026107788086, "training_acc": 52.5, "val_loss": 14.043035507202148, "val_acc": 50.0, "val_auroc": 0.34, "time": 455.64}
{"epoch": 26, "training_loss": 55.64353370666504, "training_acc": 52.5, "val_loss": 14.081817865371704, "val_acc": 50.0, "val_auroc": 0.34, "time": 473.0}
{"epoch": 27, "training_loss": 55.71595478057861, "training_acc": 52.5, "val_loss": 14.103330373764038, "val_acc": 50.0, "val_auroc": 0.35, "time": 490.09}
{"epoch": 28, "training_loss": 55.79610347747803, "training_acc": 52.5, "val_loss": 13.998878002166748, "val_acc": 50.0, "val_auroc": 0.36, "time": 507.28}
{"epoch": 29, "training_loss": 55.531532287597656, "training_acc": 52.5, "val_loss": 13.894861936569214, "val_acc": 50.0, "val_auroc": 0.63, "time": 524.74}
{"epoch": 30, "training_loss": 55.36889839172363, "training_acc": 52.5, "val_loss": 13.869044780731201, "val_acc": 50.0, "val_auroc": 0.79, "time": 542.06}
{"epoch": 31, "training_loss": 55.35271072387695, "training_acc": 52.5, "val_loss": 13.862236738204956, "val_acc": 50.0, "val_auroc": 0.82, "time": 559.36}
{"epoch": 32, "training_loss": 55.37349891662598, "training_acc": 52.5, "val_loss": 13.859413862228394, "val_acc": 50.0, "val_auroc": 0.77, "time": 576.77}
{"epoch": 33, "training_loss": 55.453001976013184, "training_acc": 45.0, "val_loss": 13.861078023910522, "val_acc": 50.0, "val_auroc": 0.79, "time": 594.14}
{"epoch": 34, "training_loss": 55.525559425354004, "training_acc": 47.5, "val_loss": 13.85938286781311, "val_acc": 50.0, "val_auroc": 0.77, "time": 611.71}
{"epoch": 35, "training_loss": 55.54228210449219, "training_acc": 42.5, "val_loss": 13.86325478553772, "val_acc": 50.0, "val_auroc": 0.78, "time": 628.61}
{"epoch": 36, "training_loss": 55.38097095489502, "training_acc": 52.5, "val_loss": 13.863877058029175, "val_acc": 50.0, "val_auroc": 0.82, "time": 646.13}
{"epoch": 37, "training_loss": 55.386444091796875, "training_acc": 52.5, "val_loss": 13.863171339035034, "val_acc": 50.0, "val_auroc": 0.82, "time": 663.31}
{"epoch": 38, "training_loss": 55.39608573913574, "training_acc": 52.5, "val_loss": 13.863446712493896, "val_acc": 50.0, "val_auroc": 0.82, "time": 680.15}
{"epoch": 39, "training_loss": 55.37541484832764, "training_acc": 52.5, "val_loss": 13.872593641281128, "val_acc": 50.0, "val_auroc": 0.76, "time": 696.18}
{"epoch": 40, "training_loss": 55.39206886291504, "training_acc": 52.5, "val_loss": 13.874744176864624, "val_acc": 50.0, "val_auroc": 0.79, "time": 713.62}
{"epoch": 41, "training_loss": 55.330241203308105, "training_acc": 52.5, "val_loss": 13.865855932235718, "val_acc": 50.0, "val_auroc": 0.79, "time": 731.13}
{"epoch": 42, "training_loss": 55.40379524230957, "training_acc": 52.5, "val_loss": 13.861874341964722, "val_acc": 50.0, "val_auroc": 0.81, "time": 747.62}
{"epoch": 43, "training_loss": 55.38458824157715, "training_acc": 52.5, "val_loss": 13.863956928253174, "val_acc": 50.0, "val_auroc": 0.81, "time": 764.58}
{"epoch": 44, "training_loss": 55.368900299072266, "training_acc": 52.5, "val_loss": 13.86656641960144, "val_acc": 50.0, "val_auroc": 0.8, "time": 783.1}
{"epoch": 45, "training_loss": 55.3552303314209, "training_acc": 52.5, "val_loss": 13.868718147277832, "val_acc": 50.0, "val_auroc": 0.84, "time": 800.29}
{"epoch": 46, "training_loss": 55.348093032836914, "training_acc": 52.5, "val_loss": 13.872041702270508, "val_acc": 50.0, "val_auroc": 0.85, "time": 817.76}
{"epoch": 47, "training_loss": 55.339375495910645, "training_acc": 52.5, "val_loss": 13.878411054611206, "val_acc": 50.0, "val_auroc": 0.84, "time": 834.99}
{"epoch": 48, "training_loss": 55.33866786956787, "training_acc": 52.5, "val_loss": 13.891643285751343, "val_acc": 50.0, "val_auroc": 0.8, "time": 852.3}
{"epoch": 49, "training_loss": 55.346747398376465, "training_acc": 52.5, "val_loss": 13.917114734649658, "val_acc": 50.0, "val_auroc": 0.77, "time": 869.82}
{"epoch": 50, "training_loss": 55.370643615722656, "training_acc": 52.5, "val_loss": 13.927993774414062, "val_acc": 50.0, "val_auroc": 0.77, "time": 887.15}
{"epoch": 51, "training_loss": 55.37915229797363, "training_acc": 52.5, "val_loss": 13.921811580657959, "val_acc": 50.0, "val_auroc": 0.73, "time": 904.22}
{"epoch": 52, "training_loss": 55.393484115600586, "training_acc": 52.5, "val_loss": 13.913525342941284, "val_acc": 50.0, "val_auroc": 0.73, "time": 921.46}
{"epoch": 53, "training_loss": 55.35681915283203, "training_acc": 52.5, "val_loss": 13.910659551620483, "val_acc": 50.0, "val_auroc": 0.78, "time": 938.78}
