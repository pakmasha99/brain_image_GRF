"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.476327896118164, "training_acc": 52.5, "val_loss": 13.8637113571167, "val_acc": 50.0, "val_auroc": 0.6, "time": 16.09}
{"epoch": 1, "training_loss": 55.419769287109375, "training_acc": 52.5, "val_loss": 13.911879062652588, "val_acc": 50.0, "val_auroc": 0.44, "time": 30.32}
{"epoch": 2, "training_loss": 55.3680477142334, "training_acc": 52.5, "val_loss": 13.933957815170288, "val_acc": 50.0, "val_auroc": 0.44, "time": 44.43}
{"epoch": 3, "training_loss": 55.337992668151855, "training_acc": 52.5, "val_loss": 13.92832636833191, "val_acc": 50.0, "val_auroc": 0.47, "time": 58.7}
{"epoch": 4, "training_loss": 55.21774482727051, "training_acc": 52.5, "val_loss": 13.943504095077515, "val_acc": 50.0, "val_auroc": 0.32, "time": 73.02}
{"epoch": 5, "training_loss": 55.101858139038086, "training_acc": 52.5, "val_loss": 13.894217014312744, "val_acc": 50.0, "val_auroc": 0.44, "time": 87.43}
{"epoch": 6, "training_loss": 55.052062034606934, "training_acc": 52.5, "val_loss": 13.906463384628296, "val_acc": 50.0, "val_auroc": 0.63, "time": 101.78}
{"epoch": 7, "training_loss": 54.9909782409668, "training_acc": 52.5, "val_loss": 13.957346677780151, "val_acc": 50.0, "val_auroc": 0.63, "time": 116.05}
{"epoch": 8, "training_loss": 55.10412406921387, "training_acc": 52.5, "val_loss": 13.945975303649902, "val_acc": 50.0, "val_auroc": 0.51, "time": 130.36}
{"epoch": 9, "training_loss": 54.883811950683594, "training_acc": 52.5, "val_loss": 13.895869255065918, "val_acc": 50.0, "val_auroc": 0.45, "time": 144.39}
{"epoch": 10, "training_loss": 54.838250160217285, "training_acc": 52.5, "val_loss": 13.860939741134644, "val_acc": 50.0, "val_auroc": 0.56, "time": 158.75}
{"epoch": 11, "training_loss": 54.75533580780029, "training_acc": 52.5, "val_loss": 13.858752250671387, "val_acc": 50.0, "val_auroc": 0.57, "time": 173.41}
{"epoch": 12, "training_loss": 54.62664318084717, "training_acc": 52.5, "val_loss": 13.860820531845093, "val_acc": 50.0, "val_auroc": 0.6, "time": 187.62}
{"epoch": 13, "training_loss": 54.38632297515869, "training_acc": 52.5, "val_loss": 13.843218088150024, "val_acc": 50.0, "val_auroc": 0.62, "time": 202.27}
{"epoch": 14, "training_loss": 54.25565147399902, "training_acc": 52.5, "val_loss": 13.832447528839111, "val_acc": 50.0, "val_auroc": 0.63, "time": 219.09}
{"epoch": 15, "training_loss": 54.36338996887207, "training_acc": 52.5, "val_loss": 13.849204778671265, "val_acc": 50.0, "val_auroc": 0.65, "time": 233.4}
{"epoch": 16, "training_loss": 53.929534912109375, "training_acc": 52.5, "val_loss": 13.89125108718872, "val_acc": 50.0, "val_auroc": 0.63, "time": 247.58}
{"epoch": 17, "training_loss": 53.90840816497803, "training_acc": 52.5, "val_loss": 13.845529556274414, "val_acc": 50.0, "val_auroc": 0.71, "time": 261.79}
{"epoch": 18, "training_loss": 53.66050338745117, "training_acc": 52.5, "val_loss": 13.802928924560547, "val_acc": 50.0, "val_auroc": 0.66, "time": 276.28}
{"epoch": 19, "training_loss": 53.56955337524414, "training_acc": 65.0, "val_loss": 13.784828186035156, "val_acc": 50.0, "val_auroc": 0.64, "time": 291.07}
{"epoch": 20, "training_loss": 53.31721115112305, "training_acc": 81.25, "val_loss": 13.810393810272217, "val_acc": 50.0, "val_auroc": 0.69, "time": 305.38}
{"epoch": 21, "training_loss": 53.13768196105957, "training_acc": 55.0, "val_loss": 13.827165365219116, "val_acc": 50.0, "val_auroc": 0.65, "time": 319.6}
{"epoch": 22, "training_loss": 52.58012771606445, "training_acc": 55.0, "val_loss": 13.815950155258179, "val_acc": 50.0, "val_auroc": 0.58, "time": 333.72}
{"epoch": 23, "training_loss": 52.04034614562988, "training_acc": 66.25, "val_loss": 13.8279128074646, "val_acc": 50.0, "val_auroc": 0.63, "time": 347.87}
{"epoch": 24, "training_loss": 51.91518020629883, "training_acc": 58.75, "val_loss": 13.80974531173706, "val_acc": 50.0, "val_auroc": 0.65, "time": 362.16}
{"epoch": 25, "training_loss": 50.65883541107178, "training_acc": 62.5, "val_loss": 13.729304075241089, "val_acc": 50.0, "val_auroc": 0.59, "time": 376.71}
{"epoch": 26, "training_loss": 49.708824157714844, "training_acc": 87.5, "val_loss": 14.092501401901245, "val_acc": 50.0, "val_auroc": 0.7, "time": 391.29}
{"epoch": 27, "training_loss": 52.80703544616699, "training_acc": 52.5, "val_loss": 13.87407660484314, "val_acc": 50.0, "val_auroc": 0.57, "time": 405.3}
{"epoch": 28, "training_loss": 48.716535568237305, "training_acc": 80.0, "val_loss": 13.89020562171936, "val_acc": 50.0, "val_auroc": 0.57, "time": 419.71}
{"epoch": 29, "training_loss": 50.48217487335205, "training_acc": 75.0, "val_loss": 13.895502090454102, "val_acc": 50.0, "val_auroc": 0.61, "time": 434.26}
{"epoch": 30, "training_loss": 48.00740718841553, "training_acc": 71.25, "val_loss": 13.731001615524292, "val_acc": 50.0, "val_auroc": 0.6, "time": 448.27}
{"epoch": 31, "training_loss": 46.483293533325195, "training_acc": 90.0, "val_loss": 13.679550886154175, "val_acc": 50.0, "val_auroc": 0.57, "time": 463.01}
{"epoch": 32, "training_loss": 46.29794979095459, "training_acc": 85.0, "val_loss": 13.69313359260559, "val_acc": 50.0, "val_auroc": 0.59, "time": 477.6}
{"epoch": 33, "training_loss": 44.505149841308594, "training_acc": 91.25, "val_loss": 14.06772494316101, "val_acc": 50.0, "val_auroc": 0.68, "time": 491.67}
{"epoch": 34, "training_loss": 47.919307708740234, "training_acc": 70.0, "val_loss": 13.582258224487305, "val_acc": 50.0, "val_auroc": 0.59, "time": 506.32}
{"epoch": 35, "training_loss": 42.73940849304199, "training_acc": 96.25, "val_loss": 13.443447351455688, "val_acc": 50.0, "val_auroc": 0.63, "time": 523.24}
{"epoch": 36, "training_loss": 40.7231388092041, "training_acc": 91.25, "val_loss": 13.785070180892944, "val_acc": 50.0, "val_auroc": 0.67, "time": 537.89}
{"epoch": 37, "training_loss": 39.4813814163208, "training_acc": 88.75, "val_loss": 13.399561643600464, "val_acc": 55.0, "val_auroc": 0.64, "time": 552.38}
{"epoch": 38, "training_loss": 36.97153377532959, "training_acc": 95.0, "val_loss": 13.122926950454712, "val_acc": 50.0, "val_auroc": 0.7, "time": 566.95}
{"epoch": 39, "training_loss": 36.0844144821167, "training_acc": 97.5, "val_loss": 13.773236274719238, "val_acc": 50.0, "val_auroc": 0.62, "time": 581.3}
{"epoch": 40, "training_loss": 35.764451026916504, "training_acc": 97.5, "val_loss": 14.84938383102417, "val_acc": 50.0, "val_auroc": 0.52, "time": 595.76}
{"epoch": 41, "training_loss": 43.25044250488281, "training_acc": 80.0, "val_loss": 14.270190000534058, "val_acc": 50.0, "val_auroc": 0.64, "time": 610.3}
{"epoch": 42, "training_loss": 35.457679748535156, "training_acc": 93.75, "val_loss": 13.932312726974487, "val_acc": 55.0, "val_auroc": 0.55, "time": 624.51}
{"epoch": 43, "training_loss": 31.057950973510742, "training_acc": 100.0, "val_loss": 13.817811012268066, "val_acc": 55.0, "val_auroc": 0.6, "time": 639.06}
{"epoch": 44, "training_loss": 29.633702278137207, "training_acc": 100.0, "val_loss": 14.199938774108887, "val_acc": 60.0, "val_auroc": 0.57, "time": 653.76}
{"epoch": 45, "training_loss": 31.358198165893555, "training_acc": 97.5, "val_loss": 15.49852728843689, "val_acc": 50.0, "val_auroc": 0.6, "time": 668.51}
{"epoch": 46, "training_loss": 37.923359870910645, "training_acc": 85.0, "val_loss": 14.599227905273438, "val_acc": 50.0, "val_auroc": 0.58, "time": 682.73}
{"epoch": 47, "training_loss": 33.410194396972656, "training_acc": 95.0, "val_loss": 15.23490309715271, "val_acc": 50.0, "val_auroc": 0.65, "time": 696.79}
{"epoch": 48, "training_loss": 35.338794231414795, "training_acc": 87.5, "val_loss": 13.757518529891968, "val_acc": 60.0, "val_auroc": 0.6, "time": 711.41}
{"epoch": 49, "training_loss": 28.018154621124268, "training_acc": 98.75, "val_loss": 13.707331418991089, "val_acc": 60.0, "val_auroc": 0.6, "time": 725.56}
{"epoch": 50, "training_loss": 25.87846088409424, "training_acc": 100.0, "val_loss": 13.914566040039062, "val_acc": 55.0, "val_auroc": 0.6, "time": 739.76}
{"epoch": 51, "training_loss": 24.66496181488037, "training_acc": 100.0, "val_loss": 13.688777685165405, "val_acc": 60.0, "val_auroc": 0.59, "time": 754.14}
{"epoch": 52, "training_loss": 24.949934005737305, "training_acc": 100.0, "val_loss": 14.423971176147461, "val_acc": 55.0, "val_auroc": 0.66, "time": 768.3}
{"epoch": 53, "training_loss": 24.842801094055176, "training_acc": 100.0, "val_loss": 13.898156881332397, "val_acc": 55.0, "val_auroc": 0.59, "time": 782.69}
{"epoch": 54, "training_loss": 23.31212329864502, "training_acc": 100.0, "val_loss": 13.743778467178345, "val_acc": 55.0, "val_auroc": 0.61, "time": 796.96}
{"epoch": 55, "training_loss": 22.289328575134277, "training_acc": 100.0, "val_loss": 14.025605916976929, "val_acc": 60.0, "val_auroc": 0.64, "time": 811.14}
{"epoch": 56, "training_loss": 21.82091474533081, "training_acc": 100.0, "val_loss": 13.874083757400513, "val_acc": 55.0, "val_auroc": 0.63, "time": 827.36}
{"epoch": 57, "training_loss": 21.32688045501709, "training_acc": 100.0, "val_loss": 13.810595273971558, "val_acc": 55.0, "val_auroc": 0.62, "time": 841.45}
