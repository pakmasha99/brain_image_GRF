"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.79568958282471, "training_acc": 45.0, "val_loss": 14.707978963851929, "val_acc": 45.0, "val_auroc": 0.556, "time": 16.9}
{"epoch": 1, "training_loss": 74.02608871459961, "training_acc": 53.75, "val_loss": 13.782685995101929, "val_acc": 55.0, "val_auroc": 0.424, "time": 31.69}
{"epoch": 2, "training_loss": 56.7233829498291, "training_acc": 48.75, "val_loss": 14.130009412765503, "val_acc": 55.0, "val_auroc": 0.444, "time": 50.58}
{"epoch": 3, "training_loss": 55.77468681335449, "training_acc": 48.75, "val_loss": 32.45687246322632, "val_acc": 45.0, "val_auroc": 0.414, "time": 68.34}
{"epoch": 4, "training_loss": 106.47002029418945, "training_acc": 53.75, "val_loss": 14.289696216583252, "val_acc": 55.0, "val_auroc": 0.434, "time": 85.36}
{"epoch": 5, "training_loss": 58.805155754089355, "training_acc": 51.25, "val_loss": 13.914330005645752, "val_acc": 55.0, "val_auroc": 0.495, "time": 102.0}
{"epoch": 6, "training_loss": 55.52054405212402, "training_acc": 48.75, "val_loss": 13.799501657485962, "val_acc": 55.0, "val_auroc": 0.596, "time": 118.77}
{"epoch": 7, "training_loss": 55.58185386657715, "training_acc": 51.25, "val_loss": 13.849304914474487, "val_acc": 55.0, "val_auroc": 0.626, "time": 134.67}
{"epoch": 8, "training_loss": 55.57013130187988, "training_acc": 51.25, "val_loss": 14.965788125991821, "val_acc": 45.0, "val_auroc": 0.444, "time": 151.6}
{"epoch": 9, "training_loss": 58.14101505279541, "training_acc": 48.75, "val_loss": 13.938978910446167, "val_acc": 55.0, "val_auroc": 0.485, "time": 169.51}
{"epoch": 10, "training_loss": 55.05961608886719, "training_acc": 53.75, "val_loss": 13.89136552810669, "val_acc": 55.0, "val_auroc": 0.566, "time": 186.64}
{"epoch": 11, "training_loss": 57.068175315856934, "training_acc": 51.25, "val_loss": 13.953888416290283, "val_acc": 55.0, "val_auroc": 0.576, "time": 203.5}
{"epoch": 12, "training_loss": 57.30067253112793, "training_acc": 51.25, "val_loss": 13.754851818084717, "val_acc": 55.0, "val_auroc": 0.616, "time": 219.41}
{"epoch": 13, "training_loss": 55.604684829711914, "training_acc": 51.25, "val_loss": 14.010595083236694, "val_acc": 55.0, "val_auroc": 0.394, "time": 234.67}
{"epoch": 14, "training_loss": 55.623313903808594, "training_acc": 48.75, "val_loss": 14.107816219329834, "val_acc": 55.0, "val_auroc": 0.394, "time": 250.58}
{"epoch": 15, "training_loss": 55.84648895263672, "training_acc": 48.75, "val_loss": 13.88450026512146, "val_acc": 55.0, "val_auroc": 0.434, "time": 265.86}
{"epoch": 16, "training_loss": 55.02849578857422, "training_acc": 58.75, "val_loss": 13.800630569458008, "val_acc": 55.0, "val_auroc": 0.455, "time": 283.27}
{"epoch": 17, "training_loss": 56.23196792602539, "training_acc": 51.25, "val_loss": 13.871277570724487, "val_acc": 55.0, "val_auroc": 0.495, "time": 301.19}
{"epoch": 18, "training_loss": 56.37364387512207, "training_acc": 51.25, "val_loss": 13.768539428710938, "val_acc": 55.0, "val_auroc": 0.505, "time": 316.63}
{"epoch": 19, "training_loss": 55.24717044830322, "training_acc": 51.25, "val_loss": 14.000694751739502, "val_acc": 55.0, "val_auroc": 0.465, "time": 333.25}
{"epoch": 20, "training_loss": 55.82161521911621, "training_acc": 48.75, "val_loss": 14.25648808479309, "val_acc": 55.0, "val_auroc": 0.455, "time": 351.21}
{"epoch": 21, "training_loss": 56.14479446411133, "training_acc": 48.75, "val_loss": 13.99423599243164, "val_acc": 55.0, "val_auroc": 0.444, "time": 367.51}
{"epoch": 22, "training_loss": 55.56266212463379, "training_acc": 51.25, "val_loss": 13.815199136734009, "val_acc": 55.0, "val_auroc": 0.465, "time": 383.26}
{"epoch": 23, "training_loss": 55.34541416168213, "training_acc": 51.25, "val_loss": 13.774610757827759, "val_acc": 55.0, "val_auroc": 0.465, "time": 400.28}
{"epoch": 24, "training_loss": 55.48916530609131, "training_acc": 51.25, "val_loss": 13.777483701705933, "val_acc": 55.0, "val_auroc": 0.465, "time": 416.78}
{"epoch": 25, "training_loss": 55.70586967468262, "training_acc": 51.25, "val_loss": 13.797576427459717, "val_acc": 55.0, "val_auroc": 0.475, "time": 432.35}
{"epoch": 26, "training_loss": 55.94775104522705, "training_acc": 51.25, "val_loss": 13.82002592086792, "val_acc": 55.0, "val_auroc": 0.455, "time": 447.18}
{"epoch": 27, "training_loss": 56.120155334472656, "training_acc": 51.25, "val_loss": 13.795675039291382, "val_acc": 55.0, "val_auroc": 0.444, "time": 463.51}
{"epoch": 28, "training_loss": 55.77029991149902, "training_acc": 51.25, "val_loss": 13.794177770614624, "val_acc": 55.0, "val_auroc": 0.455, "time": 479.73}
{"epoch": 29, "training_loss": 55.4532585144043, "training_acc": 48.75, "val_loss": 14.002951383590698, "val_acc": 55.0, "val_auroc": 0.444, "time": 494.87}
{"epoch": 30, "training_loss": 55.56101417541504, "training_acc": 48.75, "val_loss": 14.066189527511597, "val_acc": 55.0, "val_auroc": 0.444, "time": 510.8}
{"epoch": 31, "training_loss": 55.73538398742676, "training_acc": 48.75, "val_loss": 14.03163194656372, "val_acc": 55.0, "val_auroc": 0.444, "time": 526.55}
