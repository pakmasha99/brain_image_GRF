"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.611345291137695, "training_acc": 52.5, "val_loss": 14.07487154006958, "val_acc": 50.0, "val_auroc": 0.6, "time": 16.67}
{"epoch": 1, "training_loss": 57.546817779541016, "training_acc": 52.5, "val_loss": 13.873814344406128, "val_acc": 50.0, "val_auroc": 0.5, "time": 31.18}
{"epoch": 2, "training_loss": 55.65321636199951, "training_acc": 50.0, "val_loss": 13.87840747833252, "val_acc": 50.0, "val_auroc": 0.52, "time": 47.8}
{"epoch": 3, "training_loss": 55.225704193115234, "training_acc": 52.5, "val_loss": 15.258064270019531, "val_acc": 50.0, "val_auroc": 0.52, "time": 62.69}
{"epoch": 4, "training_loss": 61.19931602478027, "training_acc": 47.5, "val_loss": 14.132050275802612, "val_acc": 50.0, "val_auroc": 0.62, "time": 77.24}
{"epoch": 5, "training_loss": 56.06540870666504, "training_acc": 50.0, "val_loss": 13.86019229888916, "val_acc": 50.0, "val_auroc": 0.58, "time": 93.27}
{"epoch": 6, "training_loss": 55.56661033630371, "training_acc": 47.5, "val_loss": 13.84470820426941, "val_acc": 50.0, "val_auroc": 0.7, "time": 108.45}
{"epoch": 7, "training_loss": 55.33523941040039, "training_acc": 52.5, "val_loss": 13.945956230163574, "val_acc": 50.0, "val_auroc": 0.68, "time": 123.75}
{"epoch": 8, "training_loss": 55.44970512390137, "training_acc": 52.5, "val_loss": 13.820594549179077, "val_acc": 50.0, "val_auroc": 0.66, "time": 140.97}
{"epoch": 9, "training_loss": 55.31573486328125, "training_acc": 62.5, "val_loss": 14.132606983184814, "val_acc": 50.0, "val_auroc": 0.63, "time": 156.91}
{"epoch": 10, "training_loss": 56.54868507385254, "training_acc": 47.5, "val_loss": 13.989564180374146, "val_acc": 50.0, "val_auroc": 0.71, "time": 173.1}
{"epoch": 11, "training_loss": 55.53257942199707, "training_acc": 52.5, "val_loss": 14.111586809158325, "val_acc": 50.0, "val_auroc": 0.67, "time": 188.02}
{"epoch": 12, "training_loss": 55.81402015686035, "training_acc": 52.5, "val_loss": 13.89289140701294, "val_acc": 50.0, "val_auroc": 0.67, "time": 203.25}
{"epoch": 13, "training_loss": 55.547194480895996, "training_acc": 52.5, "val_loss": 13.898937702178955, "val_acc": 50.0, "val_auroc": 0.62, "time": 218.44}
{"epoch": 14, "training_loss": 55.264525413513184, "training_acc": 52.5, "val_loss": 14.219480752944946, "val_acc": 50.0, "val_auroc": 0.66, "time": 233.67}
{"epoch": 15, "training_loss": 56.08897399902344, "training_acc": 52.5, "val_loss": 14.426158666610718, "val_acc": 50.0, "val_auroc": 0.67, "time": 248.74}
{"epoch": 16, "training_loss": 56.78664779663086, "training_acc": 52.5, "val_loss": 14.120306968688965, "val_acc": 50.0, "val_auroc": 0.63, "time": 263.76}
{"epoch": 17, "training_loss": 55.68160343170166, "training_acc": 52.5, "val_loss": 13.870681524276733, "val_acc": 50.0, "val_auroc": 0.56, "time": 278.8}
{"epoch": 18, "training_loss": 55.30547904968262, "training_acc": 52.5, "val_loss": 13.917685747146606, "val_acc": 50.0, "val_auroc": 0.55, "time": 294.12}
{"epoch": 19, "training_loss": 55.991007804870605, "training_acc": 47.5, "val_loss": 13.931362628936768, "val_acc": 50.0, "val_auroc": 0.62, "time": 311.85}
{"epoch": 20, "training_loss": 56.05845260620117, "training_acc": 47.5, "val_loss": 13.87784481048584, "val_acc": 50.0, "val_auroc": 0.68, "time": 326.93}
{"epoch": 21, "training_loss": 55.530303955078125, "training_acc": 47.5, "val_loss": 13.956477642059326, "val_acc": 50.0, "val_auroc": 0.57, "time": 341.62}
{"epoch": 22, "training_loss": 55.41934108734131, "training_acc": 52.5, "val_loss": 14.25911545753479, "val_acc": 50.0, "val_auroc": 0.58, "time": 359.16}
{"epoch": 23, "training_loss": 56.24382400512695, "training_acc": 52.5, "val_loss": 14.0473473072052, "val_acc": 50.0, "val_auroc": 0.7, "time": 375.35}
{"epoch": 24, "training_loss": 55.63166046142578, "training_acc": 52.5, "val_loss": 13.935316801071167, "val_acc": 50.0, "val_auroc": 0.64, "time": 391.78}
{"epoch": 25, "training_loss": 55.42445945739746, "training_acc": 52.5, "val_loss": 13.875892162322998, "val_acc": 50.0, "val_auroc": 0.62, "time": 408.75}
{"epoch": 26, "training_loss": 55.32148361206055, "training_acc": 52.5, "val_loss": 13.86716604232788, "val_acc": 50.0, "val_auroc": 0.62, "time": 424.24}
{"epoch": 27, "training_loss": 55.299848556518555, "training_acc": 52.5, "val_loss": 13.881386518478394, "val_acc": 50.0, "val_auroc": 0.63, "time": 440.95}
