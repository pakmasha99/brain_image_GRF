"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 58.158308029174805, "training_acc": 40.0, "val_loss": 14.03788685798645, "val_acc": 50.0, "val_auroc": 0.62, "time": 17.32}
{"epoch": 1, "training_loss": 55.48675537109375, "training_acc": 52.5, "val_loss": 13.921215534210205, "val_acc": 50.0, "val_auroc": 0.68, "time": 31.96}
{"epoch": 2, "training_loss": 55.888771057128906, "training_acc": 50.0, "val_loss": 13.962602615356445, "val_acc": 50.0, "val_auroc": 0.65, "time": 46.53}
{"epoch": 3, "training_loss": 63.15913391113281, "training_acc": 47.5, "val_loss": 13.992074728012085, "val_acc": 50.0, "val_auroc": 0.54, "time": 61.2}
{"epoch": 4, "training_loss": 55.54759216308594, "training_acc": 52.5, "val_loss": 13.909536600112915, "val_acc": 50.0, "val_auroc": 0.28, "time": 76.01}
{"epoch": 5, "training_loss": 55.54866886138916, "training_acc": 50.0, "val_loss": 14.105443954467773, "val_acc": 50.0, "val_auroc": 0.3, "time": 90.73}
{"epoch": 6, "training_loss": 56.305315017700195, "training_acc": 52.5, "val_loss": 14.785689115524292, "val_acc": 50.0, "val_auroc": 0.31, "time": 105.27}
{"epoch": 7, "training_loss": 57.69360065460205, "training_acc": 52.5, "val_loss": 13.996528387069702, "val_acc": 50.0, "val_auroc": 0.38, "time": 119.57}
{"epoch": 8, "training_loss": 55.176809310913086, "training_acc": 52.5, "val_loss": 13.942995071411133, "val_acc": 50.0, "val_auroc": 0.75, "time": 133.87}
{"epoch": 9, "training_loss": 56.19868087768555, "training_acc": 47.5, "val_loss": 13.918483257293701, "val_acc": 50.0, "val_auroc": 0.52, "time": 148.14}
{"epoch": 10, "training_loss": 55.76037788391113, "training_acc": 50.0, "val_loss": 13.993589878082275, "val_acc": 50.0, "val_auroc": 0.5, "time": 162.5}
{"epoch": 11, "training_loss": 55.43863105773926, "training_acc": 52.5, "val_loss": 14.330859184265137, "val_acc": 50.0, "val_auroc": 0.41, "time": 177.18}
{"epoch": 12, "training_loss": 56.349342346191406, "training_acc": 52.5, "val_loss": 13.95821213722229, "val_acc": 50.0, "val_auroc": 0.75, "time": 191.91}
{"epoch": 13, "training_loss": 55.35157871246338, "training_acc": 52.5, "val_loss": 13.86515498161316, "val_acc": 50.0, "val_auroc": 0.69, "time": 207.27}
{"epoch": 14, "training_loss": 55.71249866485596, "training_acc": 47.5, "val_loss": 13.843967914581299, "val_acc": 50.0, "val_auroc": 0.75, "time": 222.37}
{"epoch": 15, "training_loss": 55.375176429748535, "training_acc": 52.5, "val_loss": 14.014298915863037, "val_acc": 50.0, "val_auroc": 0.75, "time": 237.43}
{"epoch": 16, "training_loss": 55.40956497192383, "training_acc": 52.5, "val_loss": 14.569143056869507, "val_acc": 50.0, "val_auroc": 0.78, "time": 251.57}
{"epoch": 17, "training_loss": 57.18273067474365, "training_acc": 52.5, "val_loss": 14.192460775375366, "val_acc": 50.0, "val_auroc": 0.71, "time": 267.49}
{"epoch": 18, "training_loss": 55.71174430847168, "training_acc": 52.5, "val_loss": 13.853458166122437, "val_acc": 50.0, "val_auroc": 0.77, "time": 286.29}
{"epoch": 19, "training_loss": 55.32686424255371, "training_acc": 55.0, "val_loss": 13.965171575546265, "val_acc": 50.0, "val_auroc": 0.73, "time": 300.9}
{"epoch": 20, "training_loss": 56.346466064453125, "training_acc": 47.5, "val_loss": 13.873070478439331, "val_acc": 50.0, "val_auroc": 0.74, "time": 315.96}
{"epoch": 21, "training_loss": 55.565879821777344, "training_acc": 50.0, "val_loss": 13.951908349990845, "val_acc": 50.0, "val_auroc": 0.29, "time": 331.96}
{"epoch": 22, "training_loss": 55.39107131958008, "training_acc": 52.5, "val_loss": 14.126042127609253, "val_acc": 50.0, "val_auroc": 0.2, "time": 346.88}
{"epoch": 23, "training_loss": 55.84436511993408, "training_acc": 52.5, "val_loss": 14.056861400604248, "val_acc": 50.0, "val_auroc": 0.27, "time": 361.61}
{"epoch": 24, "training_loss": 55.68434715270996, "training_acc": 52.5, "val_loss": 14.01751160621643, "val_acc": 50.0, "val_auroc": 0.35, "time": 376.84}
{"epoch": 25, "training_loss": 55.53763675689697, "training_acc": 52.5, "val_loss": 13.985598087310791, "val_acc": 50.0, "val_auroc": 0.33, "time": 392.26}
{"epoch": 26, "training_loss": 55.61720275878906, "training_acc": 52.5, "val_loss": 13.97613525390625, "val_acc": 50.0, "val_auroc": 0.35, "time": 407.18}
{"epoch": 27, "training_loss": 55.436458587646484, "training_acc": 52.5, "val_loss": 14.033169746398926, "val_acc": 50.0, "val_auroc": 0.32, "time": 424.18}
{"epoch": 28, "training_loss": 55.69633483886719, "training_acc": 52.5, "val_loss": 13.939981460571289, "val_acc": 50.0, "val_auroc": 0.22, "time": 438.97}
{"epoch": 29, "training_loss": 55.415971755981445, "training_acc": 52.5, "val_loss": 13.863251209259033, "val_acc": 50.0, "val_auroc": 0.52, "time": 455.26}
{"epoch": 30, "training_loss": 55.452134132385254, "training_acc": 50.0, "val_loss": 13.865801095962524, "val_acc": 50.0, "val_auroc": 0.51, "time": 472.15}
{"epoch": 31, "training_loss": 55.533263206481934, "training_acc": 47.5, "val_loss": 13.860751390457153, "val_acc": 50.0, "val_auroc": 0.61, "time": 488.79}
{"epoch": 32, "training_loss": 55.46541118621826, "training_acc": 48.75, "val_loss": 13.859261274337769, "val_acc": 50.0, "val_auroc": 0.6, "time": 505.73}
{"epoch": 33, "training_loss": 55.426273345947266, "training_acc": 47.5, "val_loss": 13.856558799743652, "val_acc": 50.0, "val_auroc": 0.66, "time": 523.29}
