"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.81319522857666, "training_acc": 53.75, "val_loss": 20.90665340423584, "val_acc": 50.0, "val_auroc": 0.46, "time": 20.67}
{"epoch": 1, "training_loss": 74.1042947769165, "training_acc": 52.5, "val_loss": 13.951812982559204, "val_acc": 50.0, "val_auroc": 0.25, "time": 37.05}
{"epoch": 2, "training_loss": 55.504897117614746, "training_acc": 50.0, "val_loss": 40.44164180755615, "val_acc": 50.0, "val_auroc": 0.27, "time": 52.35}
{"epoch": 3, "training_loss": 143.70734214782715, "training_acc": 47.5, "val_loss": 13.986061811447144, "val_acc": 50.0, "val_auroc": 0.76, "time": 67.65}
{"epoch": 4, "training_loss": 56.598259925842285, "training_acc": 47.5, "val_loss": 14.027012586593628, "val_acc": 50.0, "val_auroc": 0.7, "time": 83.52}
{"epoch": 5, "training_loss": 55.78511428833008, "training_acc": 51.25, "val_loss": 14.021503925323486, "val_acc": 50.0, "val_auroc": 0.71, "time": 99.91}
{"epoch": 6, "training_loss": 58.727670669555664, "training_acc": 45.0, "val_loss": 15.477166175842285, "val_acc": 50.0, "val_auroc": 0.36, "time": 115.49}
{"epoch": 7, "training_loss": 60.04709529876709, "training_acc": 52.5, "val_loss": 14.391323328018188, "val_acc": 50.0, "val_auroc": 0.27, "time": 130.86}
{"epoch": 8, "training_loss": 55.7197151184082, "training_acc": 52.5, "val_loss": 13.881723880767822, "val_acc": 50.0, "val_auroc": 0.64, "time": 147.19}
{"epoch": 9, "training_loss": 55.9367561340332, "training_acc": 47.5, "val_loss": 14.001567363739014, "val_acc": 50.0, "val_auroc": 0.65, "time": 163.63}
{"epoch": 10, "training_loss": 56.456552505493164, "training_acc": 47.5, "val_loss": 13.852388858795166, "val_acc": 50.0, "val_auroc": 0.64, "time": 179.53}
{"epoch": 11, "training_loss": 55.26959991455078, "training_acc": 52.5, "val_loss": 14.032338857650757, "val_acc": 50.0, "val_auroc": 0.66, "time": 195.56}
{"epoch": 12, "training_loss": 55.739906311035156, "training_acc": 52.5, "val_loss": 14.173182249069214, "val_acc": 50.0, "val_auroc": 0.63, "time": 211.27}
{"epoch": 13, "training_loss": 55.907501220703125, "training_acc": 52.5, "val_loss": 13.944315910339355, "val_acc": 50.0, "val_auroc": 0.73, "time": 229.21}
{"epoch": 14, "training_loss": 55.36344242095947, "training_acc": 52.5, "val_loss": 13.85513186454773, "val_acc": 50.0, "val_auroc": 0.79, "time": 244.42}
{"epoch": 15, "training_loss": 55.87240695953369, "training_acc": 47.5, "val_loss": 13.853468894958496, "val_acc": 50.0, "val_auroc": 0.73, "time": 259.78}
{"epoch": 16, "training_loss": 55.279052734375, "training_acc": 55.0, "val_loss": 13.925436735153198, "val_acc": 50.0, "val_auroc": 0.78, "time": 275.17}
{"epoch": 17, "training_loss": 55.455902099609375, "training_acc": 52.5, "val_loss": 14.077733755111694, "val_acc": 50.0, "val_auroc": 0.74, "time": 290.7}
{"epoch": 18, "training_loss": 55.754639625549316, "training_acc": 52.5, "val_loss": 14.026323556900024, "val_acc": 50.0, "val_auroc": 0.74, "time": 306.66}
{"epoch": 19, "training_loss": 55.49243927001953, "training_acc": 52.5, "val_loss": 13.892960548400879, "val_acc": 50.0, "val_auroc": 0.78, "time": 322.58}
{"epoch": 20, "training_loss": 55.3930082321167, "training_acc": 52.5, "val_loss": 13.854796886444092, "val_acc": 50.0, "val_auroc": 0.76, "time": 338.46}
{"epoch": 21, "training_loss": 55.4601936340332, "training_acc": 53.75, "val_loss": 13.853729963302612, "val_acc": 50.0, "val_auroc": 0.76, "time": 354.36}
{"epoch": 22, "training_loss": 55.45989513397217, "training_acc": 50.0, "val_loss": 13.856626749038696, "val_acc": 50.0, "val_auroc": 0.82, "time": 371.92}
{"epoch": 23, "training_loss": 55.33067035675049, "training_acc": 52.5, "val_loss": 13.896235227584839, "val_acc": 50.0, "val_auroc": 0.8, "time": 388.14}
{"epoch": 24, "training_loss": 55.2770471572876, "training_acc": 52.5, "val_loss": 13.997279405593872, "val_acc": 50.0, "val_auroc": 0.75, "time": 405.22}
{"epoch": 25, "training_loss": 55.51463985443115, "training_acc": 52.5, "val_loss": 14.104946851730347, "val_acc": 50.0, "val_auroc": 0.55, "time": 423.12}
{"epoch": 26, "training_loss": 55.79885196685791, "training_acc": 52.5, "val_loss": 14.144161939620972, "val_acc": 50.0, "val_auroc": 0.43, "time": 439.09}
{"epoch": 27, "training_loss": 55.86795997619629, "training_acc": 52.5, "val_loss": 14.132919311523438, "val_acc": 50.0, "val_auroc": 0.41, "time": 455.25}
{"epoch": 28, "training_loss": 55.79702186584473, "training_acc": 52.5, "val_loss": 13.964594602584839, "val_acc": 50.0, "val_auroc": 0.65, "time": 472.26}
{"epoch": 29, "training_loss": 55.47043228149414, "training_acc": 52.5, "val_loss": 13.85219693183899, "val_acc": 50.0, "val_auroc": 0.71, "time": 488.28}
{"epoch": 30, "training_loss": 55.43715476989746, "training_acc": 50.0, "val_loss": 13.850933313369751, "val_acc": 50.0, "val_auroc": 0.76, "time": 505.4}
{"epoch": 31, "training_loss": 55.530616760253906, "training_acc": 47.5, "val_loss": 13.847650289535522, "val_acc": 50.0, "val_auroc": 0.76, "time": 521.54}
{"epoch": 32, "training_loss": 55.51103973388672, "training_acc": 47.5, "val_loss": 13.844698667526245, "val_acc": 50.0, "val_auroc": 0.77, "time": 540.8}
{"epoch": 33, "training_loss": 55.47606086730957, "training_acc": 47.5, "val_loss": 13.841818571090698, "val_acc": 50.0, "val_auroc": 0.77, "time": 556.72}
{"epoch": 34, "training_loss": 55.43337345123291, "training_acc": 47.5, "val_loss": 13.85474681854248, "val_acc": 50.0, "val_auroc": 0.77, "time": 573.64}
{"epoch": 35, "training_loss": 55.51042938232422, "training_acc": 52.5, "val_loss": 13.89048457145691, "val_acc": 50.0, "val_auroc": 0.78, "time": 590.07}
{"epoch": 36, "training_loss": 55.33889865875244, "training_acc": 52.5, "val_loss": 13.882651329040527, "val_acc": 50.0, "val_auroc": 0.64, "time": 605.95}
{"epoch": 37, "training_loss": 55.32787895202637, "training_acc": 52.5, "val_loss": 13.867379426956177, "val_acc": 50.0, "val_auroc": 0.67, "time": 621.77}
{"epoch": 38, "training_loss": 55.40089225769043, "training_acc": 52.5, "val_loss": 13.860130310058594, "val_acc": 50.0, "val_auroc": 0.83, "time": 637.72}
{"epoch": 39, "training_loss": 55.37054443359375, "training_acc": 52.5, "val_loss": 13.865870237350464, "val_acc": 50.0, "val_auroc": 0.77, "time": 654.34}
{"epoch": 40, "training_loss": 55.3891487121582, "training_acc": 52.5, "val_loss": 13.866188526153564, "val_acc": 50.0, "val_auroc": 0.77, "time": 670.6}
{"epoch": 41, "training_loss": 55.338117599487305, "training_acc": 52.5, "val_loss": 13.858107328414917, "val_acc": 50.0, "val_auroc": 0.81, "time": 686.25}
{"epoch": 42, "training_loss": 55.42834663391113, "training_acc": 52.5, "val_loss": 13.85679841041565, "val_acc": 50.0, "val_auroc": 0.79, "time": 701.92}
{"epoch": 43, "training_loss": 55.39369773864746, "training_acc": 52.5, "val_loss": 13.859885931015015, "val_acc": 50.0, "val_auroc": 0.75, "time": 717.74}
{"epoch": 44, "training_loss": 55.371917724609375, "training_acc": 52.5, "val_loss": 13.865132331848145, "val_acc": 50.0, "val_auroc": 0.73, "time": 733.03}
{"epoch": 45, "training_loss": 55.32693290710449, "training_acc": 52.5, "val_loss": 13.870375156402588, "val_acc": 50.0, "val_auroc": 0.75, "time": 748.26}
{"epoch": 46, "training_loss": 55.30892848968506, "training_acc": 52.5, "val_loss": 13.876944780349731, "val_acc": 50.0, "val_auroc": 0.76, "time": 763.59}
{"epoch": 47, "training_loss": 55.31400108337402, "training_acc": 52.5, "val_loss": 13.885523080825806, "val_acc": 50.0, "val_auroc": 0.76, "time": 779.34}
{"epoch": 48, "training_loss": 55.32021903991699, "training_acc": 52.5, "val_loss": 13.90110969543457, "val_acc": 50.0, "val_auroc": 0.8, "time": 794.98}
{"epoch": 49, "training_loss": 55.317270278930664, "training_acc": 52.5, "val_loss": 13.93487811088562, "val_acc": 50.0, "val_auroc": 0.77, "time": 810.34}
{"epoch": 50, "training_loss": 55.38645935058594, "training_acc": 52.5, "val_loss": 13.936082124710083, "val_acc": 50.0, "val_auroc": 0.79, "time": 826.22}
{"epoch": 51, "training_loss": 55.37334060668945, "training_acc": 52.5, "val_loss": 13.907414674758911, "val_acc": 50.0, "val_auroc": 0.81, "time": 843.81}
{"epoch": 52, "training_loss": 55.37711524963379, "training_acc": 52.5, "val_loss": 13.886104822158813, "val_acc": 50.0, "val_auroc": 0.83, "time": 858.94}
