"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.3233699798584, "training_acc": 53.75, "val_loss": 14.165687561035156, "val_acc": 50.0, "val_auroc": 0.47, "time": 19.13}
{"epoch": 1, "training_loss": 93.60765838623047, "training_acc": 45.0, "val_loss": 15.102671384811401, "val_acc": 50.0, "val_auroc": 0.41, "time": 37.56}
{"epoch": 2, "training_loss": 58.6087064743042, "training_acc": 50.0, "val_loss": 24.48755979537964, "val_acc": 50.0, "val_auroc": 0.5, "time": 55.21}
{"epoch": 3, "training_loss": 81.96940517425537, "training_acc": 52.5, "val_loss": 14.557360410690308, "val_acc": 50.0, "val_auroc": 0.48, "time": 74.31}
{"epoch": 4, "training_loss": 58.48948097229004, "training_acc": 47.5, "val_loss": 14.463785886764526, "val_acc": 50.0, "val_auroc": 0.45, "time": 92.09}
{"epoch": 5, "training_loss": 56.67924690246582, "training_acc": 52.5, "val_loss": 13.884607553482056, "val_acc": 50.0, "val_auroc": 0.4, "time": 111.74}
{"epoch": 6, "training_loss": 55.468597412109375, "training_acc": 48.75, "val_loss": 13.915367126464844, "val_acc": 50.0, "val_auroc": 0.4, "time": 128.81}
{"epoch": 7, "training_loss": 55.49578285217285, "training_acc": 50.0, "val_loss": 15.861105918884277, "val_acc": 50.0, "val_auroc": 0.52, "time": 145.95}
{"epoch": 8, "training_loss": 59.6493034362793, "training_acc": 52.5, "val_loss": 14.088550806045532, "val_acc": 50.0, "val_auroc": 0.5, "time": 163.34}
{"epoch": 9, "training_loss": 56.889166831970215, "training_acc": 45.0, "val_loss": 13.866536617279053, "val_acc": 50.0, "val_auroc": 0.54, "time": 183.9}
{"epoch": 10, "training_loss": 55.3667688369751, "training_acc": 50.0, "val_loss": 13.86974811553955, "val_acc": 50.0, "val_auroc": 0.59, "time": 201.28}
{"epoch": 11, "training_loss": 55.292076110839844, "training_acc": 52.5, "val_loss": 13.987945318222046, "val_acc": 50.0, "val_auroc": 0.64, "time": 219.07}
{"epoch": 12, "training_loss": 55.51262092590332, "training_acc": 52.5, "val_loss": 13.927901983261108, "val_acc": 50.0, "val_auroc": 0.6, "time": 237.21}
{"epoch": 13, "training_loss": 55.56053924560547, "training_acc": 52.5, "val_loss": 13.899286985397339, "val_acc": 50.0, "val_auroc": 0.6, "time": 254.72}
{"epoch": 14, "training_loss": 55.44077205657959, "training_acc": 52.5, "val_loss": 14.239479303359985, "val_acc": 50.0, "val_auroc": 0.61, "time": 271.02}
{"epoch": 15, "training_loss": 56.281049728393555, "training_acc": 52.5, "val_loss": 14.390649795532227, "val_acc": 50.0, "val_auroc": 0.63, "time": 287.16}
{"epoch": 16, "training_loss": 56.771780014038086, "training_acc": 52.5, "val_loss": 13.956201076507568, "val_acc": 50.0, "val_auroc": 0.61, "time": 303.75}
{"epoch": 17, "training_loss": 55.29762649536133, "training_acc": 52.5, "val_loss": 13.84151816368103, "val_acc": 50.0, "val_auroc": 0.6, "time": 320.98}
{"epoch": 18, "training_loss": 55.6088981628418, "training_acc": 47.5, "val_loss": 13.92808198928833, "val_acc": 50.0, "val_auroc": 0.6, "time": 338.23}
{"epoch": 19, "training_loss": 56.1846866607666, "training_acc": 47.5, "val_loss": 13.840939998626709, "val_acc": 50.0, "val_auroc": 0.6, "time": 355.94}
{"epoch": 20, "training_loss": 55.48855018615723, "training_acc": 47.5, "val_loss": 13.830709457397461, "val_acc": 50.0, "val_auroc": 0.61, "time": 373.99}
{"epoch": 21, "training_loss": 55.32100200653076, "training_acc": 63.75, "val_loss": 13.865737915039062, "val_acc": 50.0, "val_auroc": 0.64, "time": 391.01}
{"epoch": 22, "training_loss": 55.261353492736816, "training_acc": 52.5, "val_loss": 14.021905660629272, "val_acc": 50.0, "val_auroc": 0.69, "time": 408.57}
{"epoch": 23, "training_loss": 55.59005928039551, "training_acc": 52.5, "val_loss": 14.1054105758667, "val_acc": 50.0, "val_auroc": 0.71, "time": 424.95}
{"epoch": 24, "training_loss": 55.79583549499512, "training_acc": 52.5, "val_loss": 14.045650959014893, "val_acc": 50.0, "val_auroc": 0.69, "time": 443.07}
{"epoch": 25, "training_loss": 55.63761901855469, "training_acc": 52.5, "val_loss": 13.908931016921997, "val_acc": 50.0, "val_auroc": 0.67, "time": 459.91}
{"epoch": 26, "training_loss": 55.32946491241455, "training_acc": 52.5, "val_loss": 13.852046728134155, "val_acc": 50.0, "val_auroc": 0.64, "time": 478.0}
{"epoch": 27, "training_loss": 55.274109840393066, "training_acc": 52.5, "val_loss": 13.844634294509888, "val_acc": 50.0, "val_auroc": 0.64, "time": 495.86}
{"epoch": 28, "training_loss": 55.46293258666992, "training_acc": 52.5, "val_loss": 13.833684921264648, "val_acc": 50.0, "val_auroc": 0.61, "time": 511.6}
{"epoch": 29, "training_loss": 55.340938568115234, "training_acc": 48.75, "val_loss": 13.849433660507202, "val_acc": 50.0, "val_auroc": 0.61, "time": 528.72}
{"epoch": 30, "training_loss": 55.47150993347168, "training_acc": 47.5, "val_loss": 13.825550079345703, "val_acc": 50.0, "val_auroc": 0.62, "time": 544.58}
{"epoch": 31, "training_loss": 55.17097187042236, "training_acc": 52.5, "val_loss": 13.91249418258667, "val_acc": 50.0, "val_auroc": 0.64, "time": 559.99}
{"epoch": 32, "training_loss": 55.50728225708008, "training_acc": 52.5, "val_loss": 13.949893712997437, "val_acc": 50.0, "val_auroc": 0.66, "time": 577.66}
{"epoch": 33, "training_loss": 55.372291564941406, "training_acc": 52.5, "val_loss": 13.875377178192139, "val_acc": 50.0, "val_auroc": 0.68, "time": 594.91}
{"epoch": 34, "training_loss": 55.2600212097168, "training_acc": 52.5, "val_loss": 13.84339690208435, "val_acc": 50.0, "val_auroc": 0.69, "time": 613.97}
{"epoch": 35, "training_loss": 55.26665115356445, "training_acc": 52.5, "val_loss": 13.827434778213501, "val_acc": 50.0, "val_auroc": 0.68, "time": 630.21}
{"epoch": 36, "training_loss": 55.156877517700195, "training_acc": 60.0, "val_loss": 13.888609409332275, "val_acc": 50.0, "val_auroc": 0.62, "time": 649.5}
{"epoch": 37, "training_loss": 55.72700881958008, "training_acc": 47.5, "val_loss": 14.017311334609985, "val_acc": 50.0, "val_auroc": 0.62, "time": 665.59}
{"epoch": 38, "training_loss": 56.49091148376465, "training_acc": 47.5, "val_loss": 13.950247764587402, "val_acc": 50.0, "val_auroc": 0.61, "time": 681.72}
{"epoch": 39, "training_loss": 56.06434440612793, "training_acc": 47.5, "val_loss": 13.82803201675415, "val_acc": 50.0, "val_auroc": 0.64, "time": 696.89}
{"epoch": 40, "training_loss": 55.379465103149414, "training_acc": 47.5, "val_loss": 13.8491690158844, "val_acc": 50.0, "val_auroc": 0.67, "time": 711.93}
{"epoch": 41, "training_loss": 55.38612747192383, "training_acc": 52.5, "val_loss": 13.88095498085022, "val_acc": 50.0, "val_auroc": 0.68, "time": 728.87}
{"epoch": 42, "training_loss": 55.271860122680664, "training_acc": 52.5, "val_loss": 13.869487047195435, "val_acc": 50.0, "val_auroc": 0.67, "time": 744.05}
{"epoch": 43, "training_loss": 55.27462196350098, "training_acc": 52.5, "val_loss": 13.867354393005371, "val_acc": 50.0, "val_auroc": 0.68, "time": 759.13}
{"epoch": 44, "training_loss": 55.26860046386719, "training_acc": 52.5, "val_loss": 13.866528272628784, "val_acc": 50.0, "val_auroc": 0.68, "time": 774.1}
{"epoch": 45, "training_loss": 55.26883316040039, "training_acc": 52.5, "val_loss": 13.857859373092651, "val_acc": 50.0, "val_auroc": 0.68, "time": 791.64}
{"epoch": 46, "training_loss": 55.28874588012695, "training_acc": 52.5, "val_loss": 13.85741114616394, "val_acc": 50.0, "val_auroc": 0.67, "time": 806.67}
{"epoch": 47, "training_loss": 55.18869972229004, "training_acc": 52.5, "val_loss": 13.886535167694092, "val_acc": 50.0, "val_auroc": 0.66, "time": 821.59}
{"epoch": 48, "training_loss": 55.234954833984375, "training_acc": 52.5, "val_loss": 13.954648971557617, "val_acc": 50.0, "val_auroc": 0.65, "time": 836.79}
{"epoch": 49, "training_loss": 55.43635845184326, "training_acc": 52.5, "val_loss": 14.017136096954346, "val_acc": 50.0, "val_auroc": 0.66, "time": 851.82}
