"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 59.53114891052246, "training_acc": 42.5, "val_loss": 14.011439085006714, "val_acc": 50.0, "val_auroc": 0.38, "time": 17.68}
{"epoch": 1, "training_loss": 72.34244346618652, "training_acc": 45.0, "val_loss": 13.904945850372314, "val_acc": 50.0, "val_auroc": 0.39, "time": 33.78}
{"epoch": 2, "training_loss": 57.465728759765625, "training_acc": 47.5, "val_loss": 13.89647364616394, "val_acc": 50.0, "val_auroc": 0.53, "time": 50.15}
{"epoch": 3, "training_loss": 56.31865882873535, "training_acc": 47.5, "val_loss": 15.243593454360962, "val_acc": 50.0, "val_auroc": 0.5, "time": 65.57}
{"epoch": 4, "training_loss": 61.4028377532959, "training_acc": 48.75, "val_loss": 14.166315793991089, "val_acc": 50.0, "val_auroc": 0.48, "time": 81.07}
{"epoch": 5, "training_loss": 55.972450256347656, "training_acc": 52.5, "val_loss": 13.898357152938843, "val_acc": 50.0, "val_auroc": 0.43, "time": 96.71}
{"epoch": 6, "training_loss": 55.76689624786377, "training_acc": 47.5, "val_loss": 13.871493339538574, "val_acc": 50.0, "val_auroc": 0.41, "time": 113.19}
{"epoch": 7, "training_loss": 55.782493591308594, "training_acc": 45.0, "val_loss": 13.88444185256958, "val_acc": 50.0, "val_auroc": 0.41, "time": 129.13}
{"epoch": 8, "training_loss": 55.32915782928467, "training_acc": 51.25, "val_loss": 13.867233991622925, "val_acc": 50.0, "val_auroc": 0.51, "time": 146.29}
{"epoch": 9, "training_loss": 55.45614814758301, "training_acc": 50.0, "val_loss": 13.870598077774048, "val_acc": 50.0, "val_auroc": 0.51, "time": 163.19}
{"epoch": 10, "training_loss": 55.289597511291504, "training_acc": 52.5, "val_loss": 13.988654613494873, "val_acc": 50.0, "val_auroc": 0.47, "time": 178.77}
{"epoch": 11, "training_loss": 55.48757362365723, "training_acc": 52.5, "val_loss": 14.12272334098816, "val_acc": 50.0, "val_auroc": 0.5, "time": 193.85}
{"epoch": 12, "training_loss": 55.810112953186035, "training_acc": 52.5, "val_loss": 14.112683534622192, "val_acc": 50.0, "val_auroc": 0.48, "time": 209.47}
{"epoch": 13, "training_loss": 55.946279525756836, "training_acc": 52.5, "val_loss": 14.093017578125, "val_acc": 50.0, "val_auroc": 0.5, "time": 225.21}
{"epoch": 14, "training_loss": 55.84576416015625, "training_acc": 52.5, "val_loss": 14.272153377532959, "val_acc": 50.0, "val_auroc": 0.48, "time": 242.95}
{"epoch": 15, "training_loss": 56.15161323547363, "training_acc": 52.5, "val_loss": 14.380133152008057, "val_acc": 50.0, "val_auroc": 0.44, "time": 259.32}
{"epoch": 16, "training_loss": 56.563947677612305, "training_acc": 52.5, "val_loss": 14.109145402908325, "val_acc": 50.0, "val_auroc": 0.47, "time": 274.91}
{"epoch": 17, "training_loss": 55.59870529174805, "training_acc": 52.5, "val_loss": 13.885294198989868, "val_acc": 50.0, "val_auroc": 0.49, "time": 290.14}
{"epoch": 18, "training_loss": 55.350419998168945, "training_acc": 48.75, "val_loss": 13.867442607879639, "val_acc": 50.0, "val_auroc": 0.46, "time": 306.03}
{"epoch": 19, "training_loss": 55.68263816833496, "training_acc": 40.0, "val_loss": 13.86875033378601, "val_acc": 50.0, "val_auroc": 0.48, "time": 321.56}
{"epoch": 20, "training_loss": 55.46270942687988, "training_acc": 47.5, "val_loss": 13.920762538909912, "val_acc": 50.0, "val_auroc": 0.51, "time": 336.42}
{"epoch": 21, "training_loss": 55.957265853881836, "training_acc": 47.5, "val_loss": 13.858517408370972, "val_acc": 50.0, "val_auroc": 0.52, "time": 352.18}
{"epoch": 22, "training_loss": 55.28370475769043, "training_acc": 52.5, "val_loss": 13.947032690048218, "val_acc": 50.0, "val_auroc": 0.47, "time": 367.56}
{"epoch": 23, "training_loss": 55.44456672668457, "training_acc": 52.5, "val_loss": 14.073063135147095, "val_acc": 50.0, "val_auroc": 0.57, "time": 384.68}
{"epoch": 24, "training_loss": 55.657894134521484, "training_acc": 52.5, "val_loss": 13.934541940689087, "val_acc": 50.0, "val_auroc": 0.56, "time": 400.74}
{"epoch": 25, "training_loss": 55.3464469909668, "training_acc": 52.5, "val_loss": 13.864916563034058, "val_acc": 50.0, "val_auroc": 0.52, "time": 416.13}
{"epoch": 26, "training_loss": 55.4711799621582, "training_acc": 50.0, "val_loss": 13.862663507461548, "val_acc": 50.0, "val_auroc": 0.51, "time": 432.78}
{"epoch": 27, "training_loss": 55.37756156921387, "training_acc": 51.25, "val_loss": 13.926533460617065, "val_acc": 50.0, "val_auroc": 0.54, "time": 450.61}
{"epoch": 28, "training_loss": 55.74195384979248, "training_acc": 52.5, "val_loss": 13.961405754089355, "val_acc": 50.0, "val_auroc": 0.56, "time": 466.21}
{"epoch": 29, "training_loss": 55.4307804107666, "training_acc": 52.5, "val_loss": 13.878206014633179, "val_acc": 50.0, "val_auroc": 0.54, "time": 482.0}
{"epoch": 30, "training_loss": 55.32182693481445, "training_acc": 52.5, "val_loss": 13.872789144515991, "val_acc": 50.0, "val_auroc": 0.53, "time": 497.17}
{"epoch": 31, "training_loss": 55.32626914978027, "training_acc": 52.5, "val_loss": 13.883612155914307, "val_acc": 50.0, "val_auroc": 0.51, "time": 513.39}
{"epoch": 32, "training_loss": 55.32954025268555, "training_acc": 52.5, "val_loss": 13.875735998153687, "val_acc": 50.0, "val_auroc": 0.52, "time": 528.65}
{"epoch": 33, "training_loss": 55.38812446594238, "training_acc": 52.5, "val_loss": 13.871166706085205, "val_acc": 50.0, "val_auroc": 0.53, "time": 546.65}
{"epoch": 34, "training_loss": 55.30237674713135, "training_acc": 52.5, "val_loss": 13.91443133354187, "val_acc": 50.0, "val_auroc": 0.51, "time": 562.28}
{"epoch": 35, "training_loss": 55.52198791503906, "training_acc": 52.5, "val_loss": 13.94683837890625, "val_acc": 50.0, "val_auroc": 0.52, "time": 578.08}
{"epoch": 36, "training_loss": 55.31929969787598, "training_acc": 52.5, "val_loss": 13.887972831726074, "val_acc": 50.0, "val_auroc": 0.55, "time": 594.03}
{"epoch": 37, "training_loss": 55.22696304321289, "training_acc": 52.5, "val_loss": 13.857494592666626, "val_acc": 50.0, "val_auroc": 0.59, "time": 610.22}
{"epoch": 38, "training_loss": 55.443960189819336, "training_acc": 63.75, "val_loss": 13.872036933898926, "val_acc": 50.0, "val_auroc": 0.58, "time": 626.09}
{"epoch": 39, "training_loss": 55.58579635620117, "training_acc": 47.5, "val_loss": 13.86109709739685, "val_acc": 50.0, "val_auroc": 0.61, "time": 642.13}
{"epoch": 40, "training_loss": 55.4580192565918, "training_acc": 47.5, "val_loss": 13.85661244392395, "val_acc": 50.0, "val_auroc": 0.61, "time": 657.76}
{"epoch": 41, "training_loss": 55.45603561401367, "training_acc": 52.5, "val_loss": 13.866958618164062, "val_acc": 50.0, "val_auroc": 0.54, "time": 672.91}
{"epoch": 42, "training_loss": 55.30268669128418, "training_acc": 52.5, "val_loss": 13.869510889053345, "val_acc": 50.0, "val_auroc": 0.53, "time": 689.01}
{"epoch": 43, "training_loss": 55.29949760437012, "training_acc": 52.5, "val_loss": 13.88739824295044, "val_acc": 50.0, "val_auroc": 0.56, "time": 705.75}
{"epoch": 44, "training_loss": 55.39303398132324, "training_acc": 52.5, "val_loss": 13.905947208404541, "val_acc": 50.0, "val_auroc": 0.57, "time": 721.36}
{"epoch": 45, "training_loss": 55.297035217285156, "training_acc": 52.5, "val_loss": 13.893297910690308, "val_acc": 50.0, "val_auroc": 0.58, "time": 739.48}
{"epoch": 46, "training_loss": 55.299283027648926, "training_acc": 52.5, "val_loss": 13.896344900131226, "val_acc": 50.0, "val_auroc": 0.57, "time": 754.91}
{"epoch": 47, "training_loss": 55.24921417236328, "training_acc": 52.5, "val_loss": 13.910123109817505, "val_acc": 50.0, "val_auroc": 0.55, "time": 770.36}
{"epoch": 48, "training_loss": 55.24363327026367, "training_acc": 52.5, "val_loss": 13.91203761100769, "val_acc": 50.0, "val_auroc": 0.55, "time": 786.47}
{"epoch": 49, "training_loss": 55.22068691253662, "training_acc": 52.5, "val_loss": 13.915811777114868, "val_acc": 50.0, "val_auroc": 0.53, "time": 801.86}
{"epoch": 50, "training_loss": 55.24127960205078, "training_acc": 52.5, "val_loss": 13.932236433029175, "val_acc": 50.0, "val_auroc": 0.54, "time": 817.29}
{"epoch": 51, "training_loss": 55.22538375854492, "training_acc": 52.5, "val_loss": 13.962862491607666, "val_acc": 50.0, "val_auroc": 0.56, "time": 833.92}
{"epoch": 52, "training_loss": 55.28988552093506, "training_acc": 52.5, "val_loss": 13.968533277511597, "val_acc": 50.0, "val_auroc": 0.56, "time": 851.65}
{"epoch": 53, "training_loss": 55.26976776123047, "training_acc": 52.5, "val_loss": 13.945096731185913, "val_acc": 50.0, "val_auroc": 0.54, "time": 868.2}
{"epoch": 54, "training_loss": 55.17478370666504, "training_acc": 52.5, "val_loss": 13.917053937911987, "val_acc": 50.0, "val_auroc": 0.54, "time": 885.66}
{"epoch": 55, "training_loss": 55.066718101501465, "training_acc": 52.5, "val_loss": 13.889391422271729, "val_acc": 50.0, "val_auroc": 0.51, "time": 901.24}
{"epoch": 56, "training_loss": 55.0599365234375, "training_acc": 52.5, "val_loss": 13.859487771987915, "val_acc": 50.0, "val_auroc": 0.5, "time": 916.55}
{"epoch": 57, "training_loss": 55.23964500427246, "training_acc": 60.0, "val_loss": 13.8926100730896, "val_acc": 50.0, "val_auroc": 0.49, "time": 932.55}
{"epoch": 58, "training_loss": 55.54097270965576, "training_acc": 47.5, "val_loss": 13.890557289123535, "val_acc": 50.0, "val_auroc": 0.49, "time": 948.37}
{"epoch": 59, "training_loss": 55.44259071350098, "training_acc": 47.5, "val_loss": 13.867231607437134, "val_acc": 50.0, "val_auroc": 0.5, "time": 965.07}
