"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.83874702453613, "training_acc": 52.5, "val_loss": 14.121812582015991, "val_acc": 50.0, "val_auroc": 0.41, "time": 19.41}
{"epoch": 1, "training_loss": 55.77615165710449, "training_acc": 52.5, "val_loss": 14.11920428276062, "val_acc": 50.0, "val_auroc": 0.23, "time": 37.35}
{"epoch": 2, "training_loss": 55.59149742126465, "training_acc": 52.5, "val_loss": 14.129012823104858, "val_acc": 50.0, "val_auroc": 0.25, "time": 54.55}
{"epoch": 3, "training_loss": 55.369614601135254, "training_acc": 52.5, "val_loss": 14.06183123588562, "val_acc": 50.0, "val_auroc": 0.33, "time": 72.59}
{"epoch": 4, "training_loss": 55.28082275390625, "training_acc": 52.5, "val_loss": 14.028077125549316, "val_acc": 50.0, "val_auroc": 0.42, "time": 90.01}
{"epoch": 5, "training_loss": 55.2924747467041, "training_acc": 52.5, "val_loss": 13.976508378982544, "val_acc": 50.0, "val_auroc": 0.57, "time": 107.57}
{"epoch": 6, "training_loss": 55.39374351501465, "training_acc": 52.5, "val_loss": 13.96094560623169, "val_acc": 50.0, "val_auroc": 0.54, "time": 124.64}
{"epoch": 7, "training_loss": 55.17802619934082, "training_acc": 52.5, "val_loss": 13.977431058883667, "val_acc": 50.0, "val_auroc": 0.53, "time": 141.83}
{"epoch": 8, "training_loss": 55.01447868347168, "training_acc": 52.5, "val_loss": 13.926583528518677, "val_acc": 50.0, "val_auroc": 0.61, "time": 158.95}
{"epoch": 9, "training_loss": 54.94011974334717, "training_acc": 52.5, "val_loss": 13.9273202419281, "val_acc": 50.0, "val_auroc": 0.57, "time": 175.84}
{"epoch": 10, "training_loss": 54.819862365722656, "training_acc": 52.5, "val_loss": 13.937405347824097, "val_acc": 50.0, "val_auroc": 0.48, "time": 192.71}
{"epoch": 11, "training_loss": 54.77908897399902, "training_acc": 52.5, "val_loss": 13.937383890151978, "val_acc": 50.0, "val_auroc": 0.51, "time": 209.53}
{"epoch": 12, "training_loss": 54.574005126953125, "training_acc": 52.5, "val_loss": 13.916834592819214, "val_acc": 50.0, "val_auroc": 0.55, "time": 227.14}
{"epoch": 13, "training_loss": 54.46016216278076, "training_acc": 52.5, "val_loss": 13.892070055007935, "val_acc": 50.0, "val_auroc": 0.6, "time": 246.48}
{"epoch": 14, "training_loss": 54.34807586669922, "training_acc": 52.5, "val_loss": 13.874297142028809, "val_acc": 50.0, "val_auroc": 0.63, "time": 263.52}
{"epoch": 15, "training_loss": 54.2063102722168, "training_acc": 52.5, "val_loss": 13.885191679000854, "val_acc": 50.0, "val_auroc": 0.61, "time": 280.57}
{"epoch": 16, "training_loss": 53.961082458496094, "training_acc": 52.5, "val_loss": 13.89874815940857, "val_acc": 50.0, "val_auroc": 0.62, "time": 297.03}
{"epoch": 17, "training_loss": 53.76402759552002, "training_acc": 52.5, "val_loss": 13.88852596282959, "val_acc": 50.0, "val_auroc": 0.61, "time": 313.68}
{"epoch": 18, "training_loss": 53.511566162109375, "training_acc": 52.5, "val_loss": 13.866691589355469, "val_acc": 50.0, "val_auroc": 0.62, "time": 330.37}
{"epoch": 19, "training_loss": 53.49174118041992, "training_acc": 52.5, "val_loss": 13.856366872787476, "val_acc": 50.0, "val_auroc": 0.63, "time": 347.09}
{"epoch": 20, "training_loss": 53.22083377838135, "training_acc": 52.5, "val_loss": 13.843063116073608, "val_acc": 50.0, "val_auroc": 0.61, "time": 364.08}
{"epoch": 21, "training_loss": 53.265066146850586, "training_acc": 53.75, "val_loss": 13.90105128288269, "val_acc": 50.0, "val_auroc": 0.5, "time": 380.58}
{"epoch": 22, "training_loss": 53.15650749206543, "training_acc": 56.25, "val_loss": 13.894861936569214, "val_acc": 50.0, "val_auroc": 0.51, "time": 398.42}
{"epoch": 23, "training_loss": 52.54853820800781, "training_acc": 57.5, "val_loss": 13.72318148612976, "val_acc": 50.0, "val_auroc": 0.71, "time": 414.92}
{"epoch": 24, "training_loss": 52.88214683532715, "training_acc": 53.75, "val_loss": 13.7265145778656, "val_acc": 50.0, "val_auroc": 0.69, "time": 431.46}
{"epoch": 25, "training_loss": 52.66887950897217, "training_acc": 52.5, "val_loss": 13.939083814620972, "val_acc": 50.0, "val_auroc": 0.46, "time": 448.5}
{"epoch": 26, "training_loss": 53.15858554840088, "training_acc": 55.0, "val_loss": 13.948640823364258, "val_acc": 50.0, "val_auroc": 0.46, "time": 465.4}
{"epoch": 27, "training_loss": 52.657676696777344, "training_acc": 56.25, "val_loss": 13.974355459213257, "val_acc": 50.0, "val_auroc": 0.52, "time": 482.31}
{"epoch": 28, "training_loss": 52.694541931152344, "training_acc": 52.5, "val_loss": 13.824403285980225, "val_acc": 50.0, "val_auroc": 0.65, "time": 498.81}
{"epoch": 29, "training_loss": 52.7898645401001, "training_acc": 56.25, "val_loss": 13.828954696655273, "val_acc": 50.0, "val_auroc": 0.59, "time": 515.45}
{"epoch": 30, "training_loss": 53.077880859375, "training_acc": 75.0, "val_loss": 13.997972011566162, "val_acc": 50.0, "val_auroc": 0.42, "time": 532.26}
{"epoch": 31, "training_loss": 51.66912269592285, "training_acc": 70.0, "val_loss": 14.012817144393921, "val_acc": 50.0, "val_auroc": 0.43, "time": 548.86}
{"epoch": 32, "training_loss": 51.596245765686035, "training_acc": 58.75, "val_loss": 13.829617500305176, "val_acc": 50.0, "val_auroc": 0.62, "time": 565.19}
{"epoch": 33, "training_loss": 51.96415424346924, "training_acc": 86.25, "val_loss": 13.81556749343872, "val_acc": 50.0, "val_auroc": 0.57, "time": 581.83}
{"epoch": 34, "training_loss": 52.593092918395996, "training_acc": 88.75, "val_loss": 13.861736059188843, "val_acc": 50.0, "val_auroc": 0.54, "time": 598.51}
{"epoch": 35, "training_loss": 51.63313579559326, "training_acc": 71.25, "val_loss": 13.966113328933716, "val_acc": 50.0, "val_auroc": 0.48, "time": 615.33}
{"epoch": 36, "training_loss": 50.40023994445801, "training_acc": 63.75, "val_loss": 13.871768712997437, "val_acc": 50.0, "val_auroc": 0.52, "time": 632.81}
{"epoch": 37, "training_loss": 50.5755558013916, "training_acc": 83.75, "val_loss": 13.793703317642212, "val_acc": 50.0, "val_auroc": 0.57, "time": 649.58}
{"epoch": 38, "training_loss": 50.4876708984375, "training_acc": 87.5, "val_loss": 13.736041784286499, "val_acc": 50.0, "val_auroc": 0.64, "time": 667.18}
{"epoch": 39, "training_loss": 49.64944839477539, "training_acc": 77.5, "val_loss": 13.956807851791382, "val_acc": 50.0, "val_auroc": 0.45, "time": 684.12}
{"epoch": 40, "training_loss": 49.5040168762207, "training_acc": 75.0, "val_loss": 13.899811506271362, "val_acc": 50.0, "val_auroc": 0.46, "time": 701.35}
{"epoch": 41, "training_loss": 49.778818130493164, "training_acc": 96.25, "val_loss": 13.814753293991089, "val_acc": 50.0, "val_auroc": 0.55, "time": 719.81}
{"epoch": 42, "training_loss": 48.78127861022949, "training_acc": 90.0, "val_loss": 13.791831731796265, "val_acc": 50.0, "val_auroc": 0.57, "time": 737.07}
