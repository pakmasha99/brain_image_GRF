"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.56766891479492, "training_acc": 50.0, "val_loss": 13.798459768295288, "val_acc": 55.0, "val_auroc": 0.515, "time": 19.95}
{"epoch": 1, "training_loss": 55.4243860244751, "training_acc": 52.5, "val_loss": 13.848109245300293, "val_acc": 55.0, "val_auroc": 0.455, "time": 37.91}
{"epoch": 2, "training_loss": 55.27042198181152, "training_acc": 53.75, "val_loss": 13.842672109603882, "val_acc": 55.0, "val_auroc": 0.414, "time": 55.8}
{"epoch": 3, "training_loss": 55.01909255981445, "training_acc": 56.25, "val_loss": 13.8128662109375, "val_acc": 55.0, "val_auroc": 0.525, "time": 73.43}
{"epoch": 4, "training_loss": 54.8143253326416, "training_acc": 56.25, "val_loss": 13.792308568954468, "val_acc": 55.0, "val_auroc": 0.616, "time": 90.53}
{"epoch": 5, "training_loss": 54.69902229309082, "training_acc": 53.75, "val_loss": 13.79191279411316, "val_acc": 55.0, "val_auroc": 0.535, "time": 107.61}
{"epoch": 6, "training_loss": 54.81914234161377, "training_acc": 52.5, "val_loss": 13.809448480606079, "val_acc": 55.0, "val_auroc": 0.485, "time": 124.66}
{"epoch": 7, "training_loss": 54.51226615905762, "training_acc": 53.75, "val_loss": 13.776506185531616, "val_acc": 55.0, "val_auroc": 0.535, "time": 142.0}
{"epoch": 8, "training_loss": 54.390249252319336, "training_acc": 58.75, "val_loss": 13.807995319366455, "val_acc": 55.0, "val_auroc": 0.505, "time": 158.66}
{"epoch": 9, "training_loss": 54.14922332763672, "training_acc": 66.25, "val_loss": 13.814367055892944, "val_acc": 55.0, "val_auroc": 0.525, "time": 175.33}
{"epoch": 10, "training_loss": 54.15902900695801, "training_acc": 70.0, "val_loss": 13.80942702293396, "val_acc": 55.0, "val_auroc": 0.515, "time": 191.9}
{"epoch": 11, "training_loss": 54.13619422912598, "training_acc": 68.75, "val_loss": 13.809926509857178, "val_acc": 55.0, "val_auroc": 0.475, "time": 208.18}
{"epoch": 12, "training_loss": 53.92397499084473, "training_acc": 70.0, "val_loss": 13.82646918296814, "val_acc": 55.0, "val_auroc": 0.495, "time": 225.15}
{"epoch": 13, "training_loss": 54.0453987121582, "training_acc": 62.5, "val_loss": 13.842555284500122, "val_acc": 55.0, "val_auroc": 0.475, "time": 241.9}
{"epoch": 14, "training_loss": 53.83724594116211, "training_acc": 63.75, "val_loss": 13.833242654800415, "val_acc": 55.0, "val_auroc": 0.475, "time": 259.17}
{"epoch": 15, "training_loss": 53.69272422790527, "training_acc": 65.0, "val_loss": 13.860876560211182, "val_acc": 55.0, "val_auroc": 0.455, "time": 276.48}
{"epoch": 16, "training_loss": 53.192742347717285, "training_acc": 71.25, "val_loss": 13.889598846435547, "val_acc": 55.0, "val_auroc": 0.394, "time": 293.64}
{"epoch": 17, "training_loss": 53.40530490875244, "training_acc": 70.0, "val_loss": 13.825018405914307, "val_acc": 55.0, "val_auroc": 0.556, "time": 311.53}
{"epoch": 18, "training_loss": 53.06269454956055, "training_acc": 67.5, "val_loss": 13.885170221328735, "val_acc": 55.0, "val_auroc": 0.384, "time": 328.16}
{"epoch": 19, "training_loss": 53.277791023254395, "training_acc": 71.25, "val_loss": 13.852999210357666, "val_acc": 55.0, "val_auroc": 0.505, "time": 344.95}
{"epoch": 20, "training_loss": 53.19502258300781, "training_acc": 73.75, "val_loss": 13.875961303710938, "val_acc": 55.0, "val_auroc": 0.434, "time": 361.83}
{"epoch": 21, "training_loss": 52.57369041442871, "training_acc": 67.5, "val_loss": 13.88114333152771, "val_acc": 55.0, "val_auroc": 0.414, "time": 379.64}
{"epoch": 22, "training_loss": 53.0859432220459, "training_acc": 67.5, "val_loss": 13.914235830307007, "val_acc": 55.0, "val_auroc": 0.424, "time": 396.49}
{"epoch": 23, "training_loss": 52.67237854003906, "training_acc": 65.0, "val_loss": 13.883540630340576, "val_acc": 55.0, "val_auroc": 0.495, "time": 413.12}
{"epoch": 24, "training_loss": 52.06497001647949, "training_acc": 67.5, "val_loss": 13.88620376586914, "val_acc": 55.0, "val_auroc": 0.495, "time": 429.38}
{"epoch": 25, "training_loss": 51.86396312713623, "training_acc": 70.0, "val_loss": 13.869179487228394, "val_acc": 55.0, "val_auroc": 0.505, "time": 446.25}
{"epoch": 26, "training_loss": 51.941521644592285, "training_acc": 68.75, "val_loss": 13.819319009780884, "val_acc": 55.0, "val_auroc": 0.545, "time": 463.06}
