"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.534034729003906, "training_acc": 51.25, "val_loss": 13.801591396331787, "val_acc": 55.0, "val_auroc": 0.384, "time": 19.73}
{"epoch": 1, "training_loss": 55.58675193786621, "training_acc": 51.25, "val_loss": 13.762962818145752, "val_acc": 55.0, "val_auroc": 0.465, "time": 37.71}
{"epoch": 2, "training_loss": 55.449167251586914, "training_acc": 51.25, "val_loss": 13.80262017250061, "val_acc": 55.0, "val_auroc": 0.455, "time": 57.24}
{"epoch": 3, "training_loss": 55.43725299835205, "training_acc": 51.25, "val_loss": 13.754805326461792, "val_acc": 55.0, "val_auroc": 0.576, "time": 81.29}
{"epoch": 4, "training_loss": 55.416680335998535, "training_acc": 51.25, "val_loss": 13.788388967514038, "val_acc": 55.0, "val_auroc": 0.414, "time": 102.37}
{"epoch": 5, "training_loss": 55.45448017120361, "training_acc": 51.25, "val_loss": 13.805557489395142, "val_acc": 55.0, "val_auroc": 0.515, "time": 120.55}
{"epoch": 6, "training_loss": 55.26191329956055, "training_acc": 51.25, "val_loss": 13.827911615371704, "val_acc": 55.0, "val_auroc": 0.535, "time": 140.62}
{"epoch": 7, "training_loss": 55.13885307312012, "training_acc": 52.5, "val_loss": 13.819221258163452, "val_acc": 55.0, "val_auroc": 0.545, "time": 161.91}
{"epoch": 8, "training_loss": 55.07776927947998, "training_acc": 53.75, "val_loss": 13.873733282089233, "val_acc": 55.0, "val_auroc": 0.556, "time": 180.54}
{"epoch": 9, "training_loss": 55.220699310302734, "training_acc": 61.25, "val_loss": 13.895092010498047, "val_acc": 55.0, "val_auroc": 0.556, "time": 198.23}
{"epoch": 10, "training_loss": 55.26489448547363, "training_acc": 55.0, "val_loss": 13.823410272598267, "val_acc": 55.0, "val_auroc": 0.525, "time": 215.1}
{"epoch": 11, "training_loss": 55.03275108337402, "training_acc": 51.25, "val_loss": 13.76773715019226, "val_acc": 55.0, "val_auroc": 0.535, "time": 234.74}
{"epoch": 12, "training_loss": 55.09058952331543, "training_acc": 51.25, "val_loss": 13.754836320877075, "val_acc": 55.0, "val_auroc": 0.545, "time": 251.87}
{"epoch": 13, "training_loss": 55.08837890625, "training_acc": 51.25, "val_loss": 13.784066438674927, "val_acc": 55.0, "val_auroc": 0.576, "time": 268.33}
{"epoch": 14, "training_loss": 54.87129783630371, "training_acc": 51.25, "val_loss": 13.843768835067749, "val_acc": 55.0, "val_auroc": 0.556, "time": 284.81}
{"epoch": 15, "training_loss": 54.821327209472656, "training_acc": 62.5, "val_loss": 13.84805679321289, "val_acc": 55.0, "val_auroc": 0.535, "time": 302.97}
{"epoch": 16, "training_loss": 54.440284729003906, "training_acc": 77.5, "val_loss": 13.732168674468994, "val_acc": 55.0, "val_auroc": 0.566, "time": 320.65}
{"epoch": 17, "training_loss": 54.93198108673096, "training_acc": 51.25, "val_loss": 13.749626874923706, "val_acc": 55.0, "val_auroc": 0.525, "time": 338.3}
{"epoch": 18, "training_loss": 55.17178726196289, "training_acc": 51.25, "val_loss": 13.740513324737549, "val_acc": 55.0, "val_auroc": 0.586, "time": 356.75}
{"epoch": 19, "training_loss": 54.68383598327637, "training_acc": 51.25, "val_loss": 13.84257197380066, "val_acc": 55.0, "val_auroc": 0.576, "time": 376.11}
{"epoch": 20, "training_loss": 54.59950828552246, "training_acc": 78.75, "val_loss": 13.90917181968689, "val_acc": 55.0, "val_auroc": 0.556, "time": 394.12}
{"epoch": 21, "training_loss": 54.31137943267822, "training_acc": 68.75, "val_loss": 13.79870891571045, "val_acc": 55.0, "val_auroc": 0.566, "time": 414.5}
{"epoch": 22, "training_loss": 54.084177017211914, "training_acc": 67.5, "val_loss": 13.785779476165771, "val_acc": 55.0, "val_auroc": 0.556, "time": 432.81}
{"epoch": 23, "training_loss": 53.33908748626709, "training_acc": 73.75, "val_loss": 13.783137798309326, "val_acc": 55.0, "val_auroc": 0.556, "time": 450.23}
{"epoch": 24, "training_loss": 52.96407699584961, "training_acc": 72.5, "val_loss": 13.900067806243896, "val_acc": 55.0, "val_auroc": 0.556, "time": 466.85}
{"epoch": 25, "training_loss": 53.006821632385254, "training_acc": 67.5, "val_loss": 13.661445379257202, "val_acc": 55.0, "val_auroc": 0.545, "time": 485.54}
{"epoch": 26, "training_loss": 51.302836418151855, "training_acc": 70.0, "val_loss": 13.647241592407227, "val_acc": 55.0, "val_auroc": 0.535, "time": 504.55}
{"epoch": 27, "training_loss": 51.151302337646484, "training_acc": 68.75, "val_loss": 13.877758979797363, "val_acc": 55.0, "val_auroc": 0.566, "time": 522.57}
{"epoch": 28, "training_loss": 50.23496627807617, "training_acc": 78.75, "val_loss": 13.913532495498657, "val_acc": 55.0, "val_auroc": 0.545, "time": 540.47}
{"epoch": 29, "training_loss": 48.502784729003906, "training_acc": 87.5, "val_loss": 13.654564619064331, "val_acc": 55.0, "val_auroc": 0.515, "time": 557.84}
{"epoch": 30, "training_loss": 53.40516471862793, "training_acc": 51.25, "val_loss": 13.624236583709717, "val_acc": 55.0, "val_auroc": 0.566, "time": 575.32}
{"epoch": 31, "training_loss": 51.877872467041016, "training_acc": 65.0, "val_loss": 13.92939567565918, "val_acc": 55.0, "val_auroc": 0.606, "time": 593.12}
{"epoch": 32, "training_loss": 49.23047637939453, "training_acc": 86.25, "val_loss": 13.548163175582886, "val_acc": 55.0, "val_auroc": 0.576, "time": 610.34}
{"epoch": 33, "training_loss": 47.999552726745605, "training_acc": 83.75, "val_loss": 13.52698564529419, "val_acc": 55.0, "val_auroc": 0.606, "time": 629.37}
{"epoch": 34, "training_loss": 45.097411155700684, "training_acc": 86.25, "val_loss": 13.242498636245728, "val_acc": 55.0, "val_auroc": 0.606, "time": 646.66}
{"epoch": 35, "training_loss": 43.25285625457764, "training_acc": 85.0, "val_loss": 13.998711109161377, "val_acc": 60.0, "val_auroc": 0.606, "time": 664.58}
{"epoch": 36, "training_loss": 42.00410747528076, "training_acc": 87.5, "val_loss": 13.733105659484863, "val_acc": 60.0, "val_auroc": 0.586, "time": 681.32}
{"epoch": 37, "training_loss": 40.75876808166504, "training_acc": 87.5, "val_loss": 13.390769958496094, "val_acc": 60.0, "val_auroc": 0.616, "time": 698.2}
{"epoch": 38, "training_loss": 41.43345928192139, "training_acc": 81.25, "val_loss": 13.933234214782715, "val_acc": 65.0, "val_auroc": 0.606, "time": 714.91}
{"epoch": 39, "training_loss": 37.90964603424072, "training_acc": 95.0, "val_loss": 13.059055805206299, "val_acc": 65.0, "val_auroc": 0.606, "time": 736.07}
{"epoch": 40, "training_loss": 39.275315284729004, "training_acc": 85.0, "val_loss": 14.304389953613281, "val_acc": 60.0, "val_auroc": 0.556, "time": 753.62}
{"epoch": 41, "training_loss": 35.584503173828125, "training_acc": 93.75, "val_loss": 13.15055251121521, "val_acc": 65.0, "val_auroc": 0.636, "time": 770.48}
{"epoch": 42, "training_loss": 33.392558574676514, "training_acc": 95.0, "val_loss": 13.98341417312622, "val_acc": 55.0, "val_auroc": 0.657, "time": 787.38}
{"epoch": 43, "training_loss": 29.158198356628418, "training_acc": 98.75, "val_loss": 13.178749084472656, "val_acc": 70.0, "val_auroc": 0.646, "time": 804.48}
{"epoch": 44, "training_loss": 30.30874729156494, "training_acc": 95.0, "val_loss": 14.734833240509033, "val_acc": 50.0, "val_auroc": 0.566, "time": 821.16}
{"epoch": 45, "training_loss": 27.77276849746704, "training_acc": 97.5, "val_loss": 14.104108810424805, "val_acc": 60.0, "val_auroc": 0.596, "time": 838.97}
{"epoch": 46, "training_loss": 25.648707389831543, "training_acc": 98.75, "val_loss": 14.37700629234314, "val_acc": 55.0, "val_auroc": 0.616, "time": 855.56}
{"epoch": 47, "training_loss": 24.9456844329834, "training_acc": 98.75, "val_loss": 15.218175649642944, "val_acc": 55.0, "val_auroc": 0.576, "time": 874.92}
{"epoch": 48, "training_loss": 24.767929553985596, "training_acc": 100.0, "val_loss": 13.131047487258911, "val_acc": 75.0, "val_auroc": 0.677, "time": 894.32}
{"epoch": 49, "training_loss": 25.245792388916016, "training_acc": 98.75, "val_loss": 15.300353765487671, "val_acc": 55.0, "val_auroc": 0.616, "time": 911.16}
{"epoch": 50, "training_loss": 22.6816349029541, "training_acc": 100.0, "val_loss": 13.996796607971191, "val_acc": 60.0, "val_auroc": 0.636, "time": 927.81}
{"epoch": 51, "training_loss": 21.368417739868164, "training_acc": 100.0, "val_loss": 16.1104416847229, "val_acc": 60.0, "val_auroc": 0.556, "time": 945.37}
{"epoch": 52, "training_loss": 22.23752737045288, "training_acc": 100.0, "val_loss": 13.272775411605835, "val_acc": 70.0, "val_auroc": 0.646, "time": 962.38}
{"epoch": 53, "training_loss": 22.996439933776855, "training_acc": 97.5, "val_loss": 17.69727349281311, "val_acc": 45.0, "val_auroc": 0.485, "time": 980.03}
{"epoch": 54, "training_loss": 29.6302490234375, "training_acc": 91.25, "val_loss": 13.299278020858765, "val_acc": 65.0, "val_auroc": 0.636, "time": 996.66}
{"epoch": 55, "training_loss": 21.58060932159424, "training_acc": 100.0, "val_loss": 13.17733645439148, "val_acc": 65.0, "val_auroc": 0.677, "time": 1014.52}
{"epoch": 56, "training_loss": 20.986228466033936, "training_acc": 100.0, "val_loss": 15.289667844772339, "val_acc": 60.0, "val_auroc": 0.606, "time": 1032.92}
{"epoch": 57, "training_loss": 19.414312839508057, "training_acc": 100.0, "val_loss": 13.61149787902832, "val_acc": 65.0, "val_auroc": 0.636, "time": 1050.71}
{"epoch": 58, "training_loss": 18.884570360183716, "training_acc": 100.0, "val_loss": 13.482762575149536, "val_acc": 65.0, "val_auroc": 0.646, "time": 1067.43}
