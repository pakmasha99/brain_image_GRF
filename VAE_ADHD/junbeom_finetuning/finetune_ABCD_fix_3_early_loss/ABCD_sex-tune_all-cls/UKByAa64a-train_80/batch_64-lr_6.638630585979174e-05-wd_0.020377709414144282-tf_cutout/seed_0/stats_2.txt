"main_optuna.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.45465660095215, "training_acc": 52.5, "val_loss": 13.933930397033691, "val_acc": 50.0, "val_auroc": 0.46, "time": 19.53}
{"epoch": 1, "training_loss": 55.41779708862305, "training_acc": 52.5, "val_loss": 13.988935947418213, "val_acc": 50.0, "val_auroc": 0.28, "time": 37.17}
{"epoch": 2, "training_loss": 55.33291816711426, "training_acc": 52.5, "val_loss": 13.958882093429565, "val_acc": 50.0, "val_auroc": 0.44, "time": 58.12}
{"epoch": 3, "training_loss": 55.28581237792969, "training_acc": 52.5, "val_loss": 13.993971347808838, "val_acc": 50.0, "val_auroc": 0.31, "time": 79.55}
{"epoch": 4, "training_loss": 55.27225399017334, "training_acc": 52.5, "val_loss": 13.970164060592651, "val_acc": 50.0, "val_auroc": 0.27, "time": 97.87}
{"epoch": 5, "training_loss": 55.11369037628174, "training_acc": 52.5, "val_loss": 13.858156204223633, "val_acc": 50.0, "val_auroc": 0.59, "time": 117.41}
{"epoch": 6, "training_loss": 55.22086048126221, "training_acc": 52.5, "val_loss": 13.974182605743408, "val_acc": 50.0, "val_auroc": 0.32, "time": 136.54}
{"epoch": 7, "training_loss": 55.0584716796875, "training_acc": 52.5, "val_loss": 14.056767225265503, "val_acc": 50.0, "val_auroc": 0.27, "time": 159.91}
{"epoch": 8, "training_loss": 55.36372184753418, "training_acc": 52.5, "val_loss": 14.01427149772644, "val_acc": 50.0, "val_auroc": 0.29, "time": 178.17}
{"epoch": 9, "training_loss": 55.10916996002197, "training_acc": 52.5, "val_loss": 13.907190561294556, "val_acc": 50.0, "val_auroc": 0.32, "time": 196.87}
{"epoch": 10, "training_loss": 55.07418441772461, "training_acc": 52.5, "val_loss": 13.847943544387817, "val_acc": 50.0, "val_auroc": 0.58, "time": 217.58}
{"epoch": 11, "training_loss": 55.110304832458496, "training_acc": 52.5, "val_loss": 13.865283727645874, "val_acc": 50.0, "val_auroc": 0.55, "time": 235.36}
{"epoch": 12, "training_loss": 54.95992469787598, "training_acc": 52.5, "val_loss": 13.90436053276062, "val_acc": 50.0, "val_auroc": 0.63, "time": 252.5}
{"epoch": 13, "training_loss": 54.94571304321289, "training_acc": 52.5, "val_loss": 13.906906843185425, "val_acc": 50.0, "val_auroc": 0.64, "time": 269.76}
{"epoch": 14, "training_loss": 54.57050132751465, "training_acc": 52.5, "val_loss": 13.986238241195679, "val_acc": 50.0, "val_auroc": 0.27, "time": 289.38}
{"epoch": 15, "training_loss": 54.71328353881836, "training_acc": 53.75, "val_loss": 13.99784803390503, "val_acc": 50.0, "val_auroc": 0.32, "time": 309.55}
{"epoch": 16, "training_loss": 54.27760410308838, "training_acc": 52.5, "val_loss": 13.991607427597046, "val_acc": 50.0, "val_auroc": 0.5, "time": 326.5}
{"epoch": 17, "training_loss": 55.045891761779785, "training_acc": 52.5, "val_loss": 14.012730121612549, "val_acc": 50.0, "val_auroc": 0.42, "time": 343.55}
{"epoch": 18, "training_loss": 54.844980239868164, "training_acc": 52.5, "val_loss": 13.94356369972229, "val_acc": 50.0, "val_auroc": 0.42, "time": 361.74}
{"epoch": 19, "training_loss": 54.79974842071533, "training_acc": 52.5, "val_loss": 13.885294198989868, "val_acc": 50.0, "val_auroc": 0.45, "time": 381.37}
{"epoch": 20, "training_loss": 54.827362060546875, "training_acc": 58.75, "val_loss": 13.905375003814697, "val_acc": 50.0, "val_auroc": 0.45, "time": 403.39}
{"epoch": 21, "training_loss": 54.719088554382324, "training_acc": 73.75, "val_loss": 13.933961391448975, "val_acc": 50.0, "val_auroc": 0.4, "time": 420.94}
{"epoch": 22, "training_loss": 54.37148094177246, "training_acc": 58.75, "val_loss": 13.99739146232605, "val_acc": 50.0, "val_auroc": 0.4, "time": 440.57}
{"epoch": 23, "training_loss": 53.944833755493164, "training_acc": 52.5, "val_loss": 14.027355909347534, "val_acc": 50.0, "val_auroc": 0.44, "time": 461.02}
{"epoch": 24, "training_loss": 53.526668548583984, "training_acc": 52.5, "val_loss": 14.104694128036499, "val_acc": 50.0, "val_auroc": 0.43, "time": 480.59}
{"epoch": 25, "training_loss": 53.515586853027344, "training_acc": 52.5, "val_loss": 14.012187719345093, "val_acc": 50.0, "val_auroc": 0.44, "time": 497.48}
{"epoch": 26, "training_loss": 53.2548713684082, "training_acc": 55.0, "val_loss": 14.129592180252075, "val_acc": 50.0, "val_auroc": 0.4, "time": 515.64}
{"epoch": 27, "training_loss": 51.8685245513916, "training_acc": 55.0, "val_loss": 14.197882413864136, "val_acc": 50.0, "val_auroc": 0.39, "time": 536.06}
{"epoch": 28, "training_loss": 50.84799766540527, "training_acc": 57.5, "val_loss": 13.755168914794922, "val_acc": 50.0, "val_auroc": 0.72, "time": 555.97}
{"epoch": 29, "training_loss": 54.85068893432617, "training_acc": 55.0, "val_loss": 13.810017108917236, "val_acc": 50.0, "val_auroc": 0.76, "time": 574.93}
{"epoch": 30, "training_loss": 54.984374046325684, "training_acc": 53.75, "val_loss": 13.905251026153564, "val_acc": 50.0, "val_auroc": 0.49, "time": 593.94}
{"epoch": 31, "training_loss": 54.684617042541504, "training_acc": 52.5, "val_loss": 13.920596837997437, "val_acc": 50.0, "val_auroc": 0.45, "time": 613.13}
{"epoch": 32, "training_loss": 54.12145137786865, "training_acc": 53.75, "val_loss": 13.914245367050171, "val_acc": 50.0, "val_auroc": 0.38, "time": 632.98}
{"epoch": 33, "training_loss": 53.92532730102539, "training_acc": 77.5, "val_loss": 13.870195150375366, "val_acc": 50.0, "val_auroc": 0.5, "time": 651.31}
{"epoch": 34, "training_loss": 53.33585548400879, "training_acc": 78.75, "val_loss": 13.958977460861206, "val_acc": 50.0, "val_auroc": 0.61, "time": 669.79}
{"epoch": 35, "training_loss": 53.33401107788086, "training_acc": 52.5, "val_loss": 13.895152807235718, "val_acc": 50.0, "val_auroc": 0.5, "time": 688.28}
{"epoch": 36, "training_loss": 53.64986610412598, "training_acc": 58.75, "val_loss": 13.928980827331543, "val_acc": 50.0, "val_auroc": 0.47, "time": 705.73}
{"epoch": 37, "training_loss": 53.98408126831055, "training_acc": 62.5, "val_loss": 13.954833745956421, "val_acc": 50.0, "val_auroc": 0.45, "time": 723.01}
{"epoch": 38, "training_loss": 52.806697845458984, "training_acc": 75.0, "val_loss": 14.007437229156494, "val_acc": 50.0, "val_auroc": 0.45, "time": 744.05}
{"epoch": 39, "training_loss": 51.53129959106445, "training_acc": 67.5, "val_loss": 14.010224342346191, "val_acc": 50.0, "val_auroc": 0.47, "time": 762.92}
{"epoch": 40, "training_loss": 50.52231216430664, "training_acc": 87.5, "val_loss": 13.9797842502594, "val_acc": 50.0, "val_auroc": 0.51, "time": 782.48}
{"epoch": 41, "training_loss": 48.67039680480957, "training_acc": 82.5, "val_loss": 14.080971479415894, "val_acc": 50.0, "val_auroc": 0.48, "time": 799.65}
{"epoch": 42, "training_loss": 46.56330394744873, "training_acc": 88.75, "val_loss": 14.247039556503296, "val_acc": 50.0, "val_auroc": 0.5, "time": 817.86}
{"epoch": 43, "training_loss": 44.458436012268066, "training_acc": 83.75, "val_loss": 13.830159902572632, "val_acc": 50.0, "val_auroc": 0.71, "time": 837.35}
{"epoch": 44, "training_loss": 48.32197713851929, "training_acc": 72.5, "val_loss": 14.528491497039795, "val_acc": 50.0, "val_auroc": 0.59, "time": 854.66}
{"epoch": 45, "training_loss": 44.50132656097412, "training_acc": 77.5, "val_loss": 13.929489850997925, "val_acc": 60.0, "val_auroc": 0.62, "time": 872.57}
{"epoch": 46, "training_loss": 40.63462543487549, "training_acc": 91.25, "val_loss": 14.184038639068604, "val_acc": 50.0, "val_auroc": 0.53, "time": 894.49}
{"epoch": 47, "training_loss": 39.75388240814209, "training_acc": 91.25, "val_loss": 14.603271484375, "val_acc": 50.0, "val_auroc": 0.47, "time": 916.49}
