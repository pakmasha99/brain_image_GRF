"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.41445541381836, "training_acc": 51.25, "val_loss": 13.80567193031311, "val_acc": 55.0, "val_auroc": 0.778, "time": 18.28}
{"epoch": 1, "training_loss": 56.436729431152344, "training_acc": 51.25, "val_loss": 13.795660734176636, "val_acc": 55.0, "val_auroc": 0.747, "time": 39.74}
{"epoch": 2, "training_loss": 56.301724433898926, "training_acc": 51.25, "val_loss": 13.78880500793457, "val_acc": 55.0, "val_auroc": 0.697, "time": 65.83}
{"epoch": 3, "training_loss": 56.23214149475098, "training_acc": 51.25, "val_loss": 13.782391548156738, "val_acc": 55.0, "val_auroc": 0.677, "time": 87.87}
{"epoch": 4, "training_loss": 56.082457542419434, "training_acc": 51.25, "val_loss": 13.771862983703613, "val_acc": 55.0, "val_auroc": 0.626, "time": 106.74}
{"epoch": 5, "training_loss": 55.8623571395874, "training_acc": 51.25, "val_loss": 13.762539625167847, "val_acc": 55.0, "val_auroc": 0.586, "time": 125.29}
{"epoch": 6, "training_loss": 55.79326248168945, "training_acc": 51.25, "val_loss": 13.755950927734375, "val_acc": 55.0, "val_auroc": 0.576, "time": 146.97}
{"epoch": 7, "training_loss": 55.62343406677246, "training_acc": 51.25, "val_loss": 13.754137754440308, "val_acc": 55.0, "val_auroc": 0.566, "time": 167.72}
{"epoch": 8, "training_loss": 55.51677417755127, "training_acc": 51.25, "val_loss": 13.750401735305786, "val_acc": 55.0, "val_auroc": 0.535, "time": 185.28}
{"epoch": 9, "training_loss": 55.36820983886719, "training_acc": 51.25, "val_loss": 13.745189905166626, "val_acc": 55.0, "val_auroc": 0.535, "time": 205.82}
{"epoch": 10, "training_loss": 55.32362174987793, "training_acc": 51.25, "val_loss": 13.739421367645264, "val_acc": 55.0, "val_auroc": 0.566, "time": 225.31}
{"epoch": 11, "training_loss": 55.22440433502197, "training_acc": 51.25, "val_loss": 13.73594045639038, "val_acc": 55.0, "val_auroc": 0.545, "time": 248.37}
{"epoch": 12, "training_loss": 55.089202880859375, "training_acc": 51.25, "val_loss": 13.732001781463623, "val_acc": 55.0, "val_auroc": 0.545, "time": 266.1}
{"epoch": 13, "training_loss": 54.96404838562012, "training_acc": 51.25, "val_loss": 13.729227781295776, "val_acc": 55.0, "val_auroc": 0.545, "time": 284.42}
{"epoch": 14, "training_loss": 54.84981727600098, "training_acc": 51.25, "val_loss": 13.730919361114502, "val_acc": 55.0, "val_auroc": 0.545, "time": 304.04}
{"epoch": 15, "training_loss": 54.94442939758301, "training_acc": 51.25, "val_loss": 13.735240697860718, "val_acc": 55.0, "val_auroc": 0.525, "time": 324.86}
{"epoch": 16, "training_loss": 54.7413272857666, "training_acc": 51.25, "val_loss": 13.735671043395996, "val_acc": 55.0, "val_auroc": 0.535, "time": 341.06}
{"epoch": 17, "training_loss": 54.72280502319336, "training_acc": 51.25, "val_loss": 13.73228907585144, "val_acc": 55.0, "val_auroc": 0.545, "time": 358.55}
{"epoch": 18, "training_loss": 54.669240951538086, "training_acc": 51.25, "val_loss": 13.732956647872925, "val_acc": 55.0, "val_auroc": 0.525, "time": 378.19}
{"epoch": 19, "training_loss": 54.537776947021484, "training_acc": 51.25, "val_loss": 13.735171556472778, "val_acc": 55.0, "val_auroc": 0.505, "time": 398.58}
{"epoch": 20, "training_loss": 54.43474006652832, "training_acc": 51.25, "val_loss": 13.740161657333374, "val_acc": 55.0, "val_auroc": 0.505, "time": 417.92}
{"epoch": 21, "training_loss": 54.40243625640869, "training_acc": 51.25, "val_loss": 13.74849557876587, "val_acc": 55.0, "val_auroc": 0.505, "time": 435.54}
{"epoch": 22, "training_loss": 54.28235912322998, "training_acc": 51.25, "val_loss": 13.753424882888794, "val_acc": 55.0, "val_auroc": 0.505, "time": 455.11}
{"epoch": 23, "training_loss": 54.165082931518555, "training_acc": 51.25, "val_loss": 13.74901294708252, "val_acc": 55.0, "val_auroc": 0.505, "time": 475.88}
{"epoch": 24, "training_loss": 54.304264068603516, "training_acc": 51.25, "val_loss": 13.742947578430176, "val_acc": 55.0, "val_auroc": 0.505, "time": 492.62}
{"epoch": 25, "training_loss": 54.21002769470215, "training_acc": 51.25, "val_loss": 13.737491369247437, "val_acc": 55.0, "val_auroc": 0.515, "time": 509.58}
{"epoch": 26, "training_loss": 53.997196197509766, "training_acc": 51.25, "val_loss": 13.732504844665527, "val_acc": 55.0, "val_auroc": 0.515, "time": 528.52}
{"epoch": 27, "training_loss": 54.0526237487793, "training_acc": 51.25, "val_loss": 13.730520009994507, "val_acc": 55.0, "val_auroc": 0.515, "time": 548.54}
{"epoch": 28, "training_loss": 54.043856620788574, "training_acc": 51.25, "val_loss": 13.737516403198242, "val_acc": 55.0, "val_auroc": 0.515, "time": 565.57}
{"epoch": 29, "training_loss": 53.96538734436035, "training_acc": 52.5, "val_loss": 13.751554489135742, "val_acc": 55.0, "val_auroc": 0.505, "time": 582.71}
{"epoch": 30, "training_loss": 53.87478065490723, "training_acc": 51.25, "val_loss": 13.760454654693604, "val_acc": 55.0, "val_auroc": 0.515, "time": 601.83}
{"epoch": 31, "training_loss": 53.75512409210205, "training_acc": 52.5, "val_loss": 13.764028549194336, "val_acc": 55.0, "val_auroc": 0.515, "time": 621.72}
{"epoch": 32, "training_loss": 53.74056434631348, "training_acc": 52.5, "val_loss": 13.766887187957764, "val_acc": 55.0, "val_auroc": 0.515, "time": 637.26}
