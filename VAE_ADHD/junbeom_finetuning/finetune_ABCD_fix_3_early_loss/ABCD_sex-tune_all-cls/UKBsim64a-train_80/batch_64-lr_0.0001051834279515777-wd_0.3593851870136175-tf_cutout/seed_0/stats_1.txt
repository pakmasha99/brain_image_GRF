"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.18940353393555, "training_acc": 53.75, "val_loss": 13.755214214324951, "val_acc": 50.0, "val_auroc": 0.64, "time": 18.89}
{"epoch": 1, "training_loss": 61.34327697753906, "training_acc": 46.25, "val_loss": 13.75432014465332, "val_acc": 50.0, "val_auroc": 0.67, "time": 42.67}
{"epoch": 2, "training_loss": 55.32419204711914, "training_acc": 51.25, "val_loss": 14.0432608127594, "val_acc": 50.0, "val_auroc": 0.7, "time": 64.98}
{"epoch": 3, "training_loss": 55.769715309143066, "training_acc": 52.5, "val_loss": 13.837603330612183, "val_acc": 50.0, "val_auroc": 0.62, "time": 88.01}
{"epoch": 4, "training_loss": 55.72306251525879, "training_acc": 47.5, "val_loss": 13.796125650405884, "val_acc": 50.0, "val_auroc": 0.65, "time": 107.52}
{"epoch": 5, "training_loss": 55.3255672454834, "training_acc": 50.0, "val_loss": 13.985103368759155, "val_acc": 50.0, "val_auroc": 0.7, "time": 125.95}
{"epoch": 6, "training_loss": 55.61698913574219, "training_acc": 52.5, "val_loss": 13.830946683883667, "val_acc": 50.0, "val_auroc": 0.77, "time": 145.57}
{"epoch": 7, "training_loss": 55.300381660461426, "training_acc": 55.0, "val_loss": 13.733910322189331, "val_acc": 50.0, "val_auroc": 0.77, "time": 166.34}
{"epoch": 8, "training_loss": 55.252159118652344, "training_acc": 52.5, "val_loss": 13.703666925430298, "val_acc": 50.0, "val_auroc": 0.76, "time": 183.24}
{"epoch": 9, "training_loss": 55.145344734191895, "training_acc": 56.25, "val_loss": 13.671096563339233, "val_acc": 50.0, "val_auroc": 0.77, "time": 203.03}
{"epoch": 10, "training_loss": 54.99818229675293, "training_acc": 53.75, "val_loss": 13.642903566360474, "val_acc": 50.0, "val_auroc": 0.78, "time": 222.28}
{"epoch": 11, "training_loss": 54.67641639709473, "training_acc": 61.25, "val_loss": 13.749688863754272, "val_acc": 50.0, "val_auroc": 0.79, "time": 242.94}
{"epoch": 12, "training_loss": 54.90632152557373, "training_acc": 52.5, "val_loss": 13.695720434188843, "val_acc": 50.0, "val_auroc": 0.78, "time": 261.24}
{"epoch": 13, "training_loss": 55.00924873352051, "training_acc": 53.75, "val_loss": 13.532400131225586, "val_acc": 50.0, "val_auroc": 0.78, "time": 280.07}
{"epoch": 14, "training_loss": 54.68870830535889, "training_acc": 51.25, "val_loss": 13.740475177764893, "val_acc": 50.0, "val_auroc": 0.78, "time": 297.39}
{"epoch": 15, "training_loss": 55.33730697631836, "training_acc": 52.5, "val_loss": 13.99939775466919, "val_acc": 50.0, "val_auroc": 0.77, "time": 319.73}
{"epoch": 16, "training_loss": 56.03295421600342, "training_acc": 52.5, "val_loss": 13.464840650558472, "val_acc": 50.0, "val_auroc": 0.77, "time": 338.55}
{"epoch": 17, "training_loss": 53.99898719787598, "training_acc": 53.75, "val_loss": 13.662642240524292, "val_acc": 50.0, "val_auroc": 0.78, "time": 357.43}
{"epoch": 18, "training_loss": 54.79944324493408, "training_acc": 46.25, "val_loss": 13.472808599472046, "val_acc": 50.0, "val_auroc": 0.78, "time": 380.33}
{"epoch": 19, "training_loss": 55.12253475189209, "training_acc": 58.75, "val_loss": 13.452492952346802, "val_acc": 50.0, "val_auroc": 0.77, "time": 400.51}
{"epoch": 20, "training_loss": 53.90016746520996, "training_acc": 58.75, "val_loss": 13.490285873413086, "val_acc": 50.0, "val_auroc": 0.81, "time": 420.94}
{"epoch": 21, "training_loss": 54.22905349731445, "training_acc": 61.25, "val_loss": 13.345867395401001, "val_acc": 50.0, "val_auroc": 0.81, "time": 441.06}
{"epoch": 22, "training_loss": 53.6017427444458, "training_acc": 62.5, "val_loss": 13.622677326202393, "val_acc": 50.0, "val_auroc": 0.8, "time": 458.63}
{"epoch": 23, "training_loss": 54.5070743560791, "training_acc": 53.75, "val_loss": 13.332662582397461, "val_acc": 50.0, "val_auroc": 0.82, "time": 479.97}
{"epoch": 24, "training_loss": 53.57565784454346, "training_acc": 55.0, "val_loss": 13.190637826919556, "val_acc": 50.0, "val_auroc": 0.83, "time": 498.53}
{"epoch": 25, "training_loss": 52.96671485900879, "training_acc": 65.0, "val_loss": 13.103463649749756, "val_acc": 50.0, "val_auroc": 0.82, "time": 518.9}
{"epoch": 26, "training_loss": 53.221314430236816, "training_acc": 60.0, "val_loss": 13.026126623153687, "val_acc": 50.0, "val_auroc": 0.81, "time": 538.43}
{"epoch": 27, "training_loss": 52.36914825439453, "training_acc": 63.75, "val_loss": 12.843700647354126, "val_acc": 50.0, "val_auroc": 0.81, "time": 558.62}
{"epoch": 28, "training_loss": 53.54134750366211, "training_acc": 57.5, "val_loss": 14.464654922485352, "val_acc": 50.0, "val_auroc": 0.83, "time": 577.91}
{"epoch": 29, "training_loss": 57.878716468811035, "training_acc": 47.5, "val_loss": 13.467262983322144, "val_acc": 45.0, "val_auroc": 0.8, "time": 597.03}
{"epoch": 30, "training_loss": 53.602938652038574, "training_acc": 57.5, "val_loss": 14.61025357246399, "val_acc": 50.0, "val_auroc": 0.74, "time": 615.0}
{"epoch": 31, "training_loss": 57.98207664489746, "training_acc": 52.5, "val_loss": 14.348286390304565, "val_acc": 50.0, "val_auroc": 0.74, "time": 636.07}
{"epoch": 32, "training_loss": 55.9716157913208, "training_acc": 52.5, "val_loss": 13.703646659851074, "val_acc": 50.0, "val_auroc": 0.77, "time": 653.77}
{"epoch": 33, "training_loss": 55.20075988769531, "training_acc": 57.5, "val_loss": 13.935296535491943, "val_acc": 50.0, "val_auroc": 0.77, "time": 674.82}
{"epoch": 34, "training_loss": 56.10742378234863, "training_acc": 47.5, "val_loss": 13.75510573387146, "val_acc": 50.0, "val_auroc": 0.74, "time": 694.38}
{"epoch": 35, "training_loss": 55.81040000915527, "training_acc": 40.0, "val_loss": 13.737213611602783, "val_acc": 50.0, "val_auroc": 0.76, "time": 715.87}
{"epoch": 36, "training_loss": 54.87018394470215, "training_acc": 52.5, "val_loss": 13.735636472702026, "val_acc": 50.0, "val_auroc": 0.72, "time": 733.66}
{"epoch": 37, "training_loss": 54.906158447265625, "training_acc": 60.0, "val_loss": 13.83657693862915, "val_acc": 50.0, "val_auroc": 0.71, "time": 752.84}
{"epoch": 38, "training_loss": 55.70659065246582, "training_acc": 47.5, "val_loss": 13.821557760238647, "val_acc": 50.0, "val_auroc": 0.75, "time": 771.6}
{"epoch": 39, "training_loss": 55.59756374359131, "training_acc": 48.75, "val_loss": 13.66571307182312, "val_acc": 50.0, "val_auroc": 0.74, "time": 791.96}
{"epoch": 40, "training_loss": 54.79708003997803, "training_acc": 58.75, "val_loss": 13.71988296508789, "val_acc": 50.0, "val_auroc": 0.74, "time": 809.04}
{"epoch": 41, "training_loss": 54.85687065124512, "training_acc": 52.5, "val_loss": 13.648134469985962, "val_acc": 50.0, "val_auroc": 0.76, "time": 827.01}
{"epoch": 42, "training_loss": 54.51690673828125, "training_acc": 55.0, "val_loss": 13.604967594146729, "val_acc": 50.0, "val_auroc": 0.77, "time": 846.45}
{"epoch": 43, "training_loss": 54.446638107299805, "training_acc": 70.0, "val_loss": 13.564571142196655, "val_acc": 50.0, "val_auroc": 0.76, "time": 865.86}
{"epoch": 44, "training_loss": 54.340797424316406, "training_acc": 67.5, "val_loss": 13.502951860427856, "val_acc": 50.0, "val_auroc": 0.78, "time": 883.38}
{"epoch": 45, "training_loss": 54.00894737243652, "training_acc": 60.0, "val_loss": 13.439733982086182, "val_acc": 50.0, "val_auroc": 0.78, "time": 902.58}
{"epoch": 46, "training_loss": 53.828935623168945, "training_acc": 61.25, "val_loss": 13.370475769042969, "val_acc": 50.0, "val_auroc": 0.79, "time": 921.84}
