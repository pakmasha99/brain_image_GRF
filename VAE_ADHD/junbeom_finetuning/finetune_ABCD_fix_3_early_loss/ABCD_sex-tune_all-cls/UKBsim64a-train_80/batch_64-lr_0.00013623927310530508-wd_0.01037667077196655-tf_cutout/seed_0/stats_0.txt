"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.8145694732666, "training_acc": 52.5, "val_loss": 13.903459310531616, "val_acc": 50.0, "val_auroc": 0.43, "time": 19.62}
{"epoch": 1, "training_loss": 55.63224124908447, "training_acc": 46.25, "val_loss": 13.886088132858276, "val_acc": 50.0, "val_auroc": 0.48, "time": 44.11}
{"epoch": 2, "training_loss": 55.28194046020508, "training_acc": 52.5, "val_loss": 13.895517587661743, "val_acc": 50.0, "val_auroc": 0.51, "time": 64.68}
{"epoch": 3, "training_loss": 55.12384223937988, "training_acc": 52.5, "val_loss": 13.877311944961548, "val_acc": 50.0, "val_auroc": 0.47, "time": 86.34}
{"epoch": 4, "training_loss": 55.078402519226074, "training_acc": 52.5, "val_loss": 13.878368139266968, "val_acc": 50.0, "val_auroc": 0.46, "time": 104.8}
{"epoch": 5, "training_loss": 55.17752647399902, "training_acc": 57.5, "val_loss": 13.873775005340576, "val_acc": 50.0, "val_auroc": 0.46, "time": 125.62}
{"epoch": 6, "training_loss": 55.08788871765137, "training_acc": 60.0, "val_loss": 13.869876861572266, "val_acc": 50.0, "val_auroc": 0.46, "time": 145.25}
{"epoch": 7, "training_loss": 55.09356689453125, "training_acc": 55.0, "val_loss": 13.900624513626099, "val_acc": 50.0, "val_auroc": 0.46, "time": 166.19}
{"epoch": 8, "training_loss": 54.61314582824707, "training_acc": 58.75, "val_loss": 13.890055418014526, "val_acc": 50.0, "val_auroc": 0.45, "time": 184.73}
{"epoch": 9, "training_loss": 54.58998489379883, "training_acc": 61.25, "val_loss": 13.927769660949707, "val_acc": 50.0, "val_auroc": 0.44, "time": 205.38}
{"epoch": 10, "training_loss": 54.06833362579346, "training_acc": 57.5, "val_loss": 14.047081470489502, "val_acc": 50.0, "val_auroc": 0.46, "time": 225.49}
{"epoch": 11, "training_loss": 54.19426918029785, "training_acc": 57.5, "val_loss": 14.041584730148315, "val_acc": 50.0, "val_auroc": 0.47, "time": 246.19}
{"epoch": 12, "training_loss": 54.452388763427734, "training_acc": 53.75, "val_loss": 13.86209487915039, "val_acc": 50.0, "val_auroc": 0.46, "time": 263.96}
{"epoch": 13, "training_loss": 53.17687702178955, "training_acc": 65.0, "val_loss": 14.597877264022827, "val_acc": 50.0, "val_auroc": 0.39, "time": 286.9}
{"epoch": 14, "training_loss": 56.992472648620605, "training_acc": 52.5, "val_loss": 14.489338397979736, "val_acc": 50.0, "val_auroc": 0.46, "time": 307.07}
{"epoch": 15, "training_loss": 56.4058723449707, "training_acc": 52.5, "val_loss": 14.214259386062622, "val_acc": 50.0, "val_auroc": 0.48, "time": 328.54}
{"epoch": 16, "training_loss": 55.53424549102783, "training_acc": 52.5, "val_loss": 13.994988203048706, "val_acc": 50.0, "val_auroc": 0.48, "time": 348.11}
{"epoch": 17, "training_loss": 54.72670364379883, "training_acc": 52.5, "val_loss": 13.905538320541382, "val_acc": 50.0, "val_auroc": 0.49, "time": 373.02}
{"epoch": 18, "training_loss": 54.45272636413574, "training_acc": 53.75, "val_loss": 13.926310539245605, "val_acc": 50.0, "val_auroc": 0.47, "time": 393.68}
{"epoch": 19, "training_loss": 54.61574935913086, "training_acc": 57.5, "val_loss": 13.875038623809814, "val_acc": 50.0, "val_auroc": 0.46, "time": 413.89}
{"epoch": 20, "training_loss": 53.96876525878906, "training_acc": 67.5, "val_loss": 13.936765193939209, "val_acc": 50.0, "val_auroc": 0.49, "time": 432.02}
{"epoch": 21, "training_loss": 54.71919059753418, "training_acc": 50.0, "val_loss": 13.977419137954712, "val_acc": 50.0, "val_auroc": 0.45, "time": 454.48}
{"epoch": 22, "training_loss": 54.2482967376709, "training_acc": 56.25, "val_loss": 14.189722537994385, "val_acc": 50.0, "val_auroc": 0.41, "time": 473.83}
{"epoch": 23, "training_loss": 55.3631649017334, "training_acc": 52.5, "val_loss": 14.140589237213135, "val_acc": 50.0, "val_auroc": 0.45, "time": 493.74}
{"epoch": 24, "training_loss": 54.873390197753906, "training_acc": 52.5, "val_loss": 13.902629613876343, "val_acc": 50.0, "val_auroc": 0.45, "time": 510.35}
{"epoch": 25, "training_loss": 54.596903800964355, "training_acc": 57.5, "val_loss": 13.914300203323364, "val_acc": 50.0, "val_auroc": 0.43, "time": 530.91}
{"epoch": 26, "training_loss": 55.16155433654785, "training_acc": 47.5, "val_loss": 13.905209302902222, "val_acc": 50.0, "val_auroc": 0.44, "time": 550.39}
{"epoch": 27, "training_loss": 54.44807434082031, "training_acc": 55.0, "val_loss": 13.92155647277832, "val_acc": 50.0, "val_auroc": 0.45, "time": 571.2}
{"epoch": 28, "training_loss": 54.21835994720459, "training_acc": 62.5, "val_loss": 13.938820362091064, "val_acc": 50.0, "val_auroc": 0.44, "time": 588.37}
{"epoch": 29, "training_loss": 53.34480667114258, "training_acc": 68.75, "val_loss": 13.961565494537354, "val_acc": 50.0, "val_auroc": 0.44, "time": 611.61}
{"epoch": 30, "training_loss": 53.000412940979004, "training_acc": 65.0, "val_loss": 14.079521894454956, "val_acc": 50.0, "val_auroc": 0.4, "time": 629.88}
{"epoch": 31, "training_loss": 52.38273620605469, "training_acc": 63.75, "val_loss": 14.144991636276245, "val_acc": 50.0, "val_auroc": 0.41, "time": 648.1}
