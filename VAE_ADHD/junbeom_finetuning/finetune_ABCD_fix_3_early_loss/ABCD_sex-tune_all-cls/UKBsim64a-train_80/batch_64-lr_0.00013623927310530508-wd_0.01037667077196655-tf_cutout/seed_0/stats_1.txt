"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.83747482299805, "training_acc": 52.5, "val_loss": 13.950166702270508, "val_acc": 50.0, "val_auroc": 0.51, "time": 20.47}
{"epoch": 1, "training_loss": 55.72979927062988, "training_acc": 52.5, "val_loss": 13.936080932617188, "val_acc": 50.0, "val_auroc": 0.41, "time": 42.7}
{"epoch": 2, "training_loss": 55.391140937805176, "training_acc": 52.5, "val_loss": 13.867398500442505, "val_acc": 50.0, "val_auroc": 0.79, "time": 68.41}
{"epoch": 3, "training_loss": 55.30165100097656, "training_acc": 52.5, "val_loss": 13.82750153541565, "val_acc": 50.0, "val_auroc": 0.88, "time": 94.27}
{"epoch": 4, "training_loss": 55.265533447265625, "training_acc": 52.5, "val_loss": 13.82199764251709, "val_acc": 50.0, "val_auroc": 0.86, "time": 112.61}
{"epoch": 5, "training_loss": 55.2994384765625, "training_acc": 52.5, "val_loss": 13.81475567817688, "val_acc": 50.0, "val_auroc": 0.82, "time": 135.72}
{"epoch": 6, "training_loss": 55.241177558898926, "training_acc": 52.5, "val_loss": 13.814166784286499, "val_acc": 50.0, "val_auroc": 0.82, "time": 158.95}
{"epoch": 7, "training_loss": 55.18231773376465, "training_acc": 52.5, "val_loss": 13.839542865753174, "val_acc": 50.0, "val_auroc": 0.83, "time": 180.42}
{"epoch": 8, "training_loss": 55.17430877685547, "training_acc": 52.5, "val_loss": 13.843740224838257, "val_acc": 50.0, "val_auroc": 0.79, "time": 199.0}
{"epoch": 9, "training_loss": 55.192200660705566, "training_acc": 52.5, "val_loss": 13.810755014419556, "val_acc": 50.0, "val_auroc": 0.79, "time": 219.42}
{"epoch": 10, "training_loss": 55.34381866455078, "training_acc": 56.25, "val_loss": 13.789949417114258, "val_acc": 50.0, "val_auroc": 0.86, "time": 239.99}
{"epoch": 11, "training_loss": 55.19870471954346, "training_acc": 57.5, "val_loss": 13.857786655426025, "val_acc": 50.0, "val_auroc": 0.77, "time": 260.5}
{"epoch": 12, "training_loss": 55.1635627746582, "training_acc": 52.5, "val_loss": 13.889214992523193, "val_acc": 50.0, "val_auroc": 0.78, "time": 279.54}
{"epoch": 13, "training_loss": 55.31582164764404, "training_acc": 52.5, "val_loss": 13.898447751998901, "val_acc": 50.0, "val_auroc": 0.79, "time": 301.46}
{"epoch": 14, "training_loss": 55.334136962890625, "training_acc": 52.5, "val_loss": 13.979750871658325, "val_acc": 50.0, "val_auroc": 0.8, "time": 321.93}
{"epoch": 15, "training_loss": 55.35362911224365, "training_acc": 52.5, "val_loss": 14.044784307479858, "val_acc": 50.0, "val_auroc": 0.82, "time": 340.97}
{"epoch": 16, "training_loss": 55.572394371032715, "training_acc": 52.5, "val_loss": 13.967151641845703, "val_acc": 50.0, "val_auroc": 0.78, "time": 358.75}
{"epoch": 17, "training_loss": 55.328874588012695, "training_acc": 52.5, "val_loss": 13.808128833770752, "val_acc": 50.0, "val_auroc": 0.8, "time": 378.67}
{"epoch": 18, "training_loss": 54.89455986022949, "training_acc": 52.5, "val_loss": 13.823765516281128, "val_acc": 50.0, "val_auroc": 0.82, "time": 399.95}
{"epoch": 19, "training_loss": 55.41316032409668, "training_acc": 46.25, "val_loss": 13.824518918991089, "val_acc": 50.0, "val_auroc": 0.81, "time": 418.12}
{"epoch": 20, "training_loss": 55.40490245819092, "training_acc": 47.5, "val_loss": 13.770887851715088, "val_acc": 50.0, "val_auroc": 0.83, "time": 435.31}
{"epoch": 21, "training_loss": 55.20808792114258, "training_acc": 51.25, "val_loss": 13.792047500610352, "val_acc": 50.0, "val_auroc": 0.82, "time": 454.47}
{"epoch": 22, "training_loss": 55.0368070602417, "training_acc": 52.5, "val_loss": 13.940056562423706, "val_acc": 50.0, "val_auroc": 0.82, "time": 477.01}
{"epoch": 23, "training_loss": 55.28734874725342, "training_acc": 52.5, "val_loss": 13.952068090438843, "val_acc": 50.0, "val_auroc": 0.82, "time": 495.05}
{"epoch": 24, "training_loss": 55.31882953643799, "training_acc": 52.5, "val_loss": 13.868340253829956, "val_acc": 50.0, "val_auroc": 0.83, "time": 512.15}
{"epoch": 25, "training_loss": 55.00450325012207, "training_acc": 52.5, "val_loss": 13.747023344039917, "val_acc": 50.0, "val_auroc": 0.8, "time": 530.12}
{"epoch": 26, "training_loss": 54.87650108337402, "training_acc": 52.5, "val_loss": 13.725528717041016, "val_acc": 50.0, "val_auroc": 0.81, "time": 553.39}
{"epoch": 27, "training_loss": 54.73900032043457, "training_acc": 52.5, "val_loss": 13.667367696762085, "val_acc": 50.0, "val_auroc": 0.79, "time": 571.81}
{"epoch": 28, "training_loss": 54.617658615112305, "training_acc": 52.5, "val_loss": 13.722656965255737, "val_acc": 50.0, "val_auroc": 0.8, "time": 589.79}
{"epoch": 29, "training_loss": 55.08867263793945, "training_acc": 66.25, "val_loss": 13.79025936126709, "val_acc": 50.0, "val_auroc": 0.87, "time": 609.84}
{"epoch": 30, "training_loss": 55.30508613586426, "training_acc": 47.5, "val_loss": 13.820090293884277, "val_acc": 50.0, "val_auroc": 0.8, "time": 631.59}
{"epoch": 31, "training_loss": 55.181339263916016, "training_acc": 52.5, "val_loss": 13.92069697380066, "val_acc": 50.0, "val_auroc": 0.77, "time": 650.68}
{"epoch": 32, "training_loss": 55.46642875671387, "training_acc": 52.5, "val_loss": 13.895043134689331, "val_acc": 50.0, "val_auroc": 0.76, "time": 668.63}
{"epoch": 33, "training_loss": 55.28393363952637, "training_acc": 52.5, "val_loss": 13.844763040542603, "val_acc": 50.0, "val_auroc": 0.68, "time": 687.4}
{"epoch": 34, "training_loss": 55.230037689208984, "training_acc": 52.5, "val_loss": 13.840337991714478, "val_acc": 50.0, "val_auroc": 0.68, "time": 709.73}
{"epoch": 35, "training_loss": 55.452545166015625, "training_acc": 52.5, "val_loss": 13.83370041847229, "val_acc": 50.0, "val_auroc": 0.69, "time": 732.04}
{"epoch": 36, "training_loss": 55.17804145812988, "training_acc": 53.75, "val_loss": 13.850568532943726, "val_acc": 50.0, "val_auroc": 0.77, "time": 750.33}
{"epoch": 37, "training_loss": 55.564537048339844, "training_acc": 47.5, "val_loss": 13.914839029312134, "val_acc": 50.0, "val_auroc": 0.82, "time": 771.48}
{"epoch": 38, "training_loss": 56.09419345855713, "training_acc": 47.5, "val_loss": 13.897486925125122, "val_acc": 50.0, "val_auroc": 0.81, "time": 791.39}
{"epoch": 39, "training_loss": 55.923410415649414, "training_acc": 47.5, "val_loss": 13.839184045791626, "val_acc": 50.0, "val_auroc": 0.79, "time": 811.17}
{"epoch": 40, "training_loss": 55.43825912475586, "training_acc": 47.5, "val_loss": 13.850526809692383, "val_acc": 50.0, "val_auroc": 0.73, "time": 829.28}
{"epoch": 41, "training_loss": 55.38505744934082, "training_acc": 52.5, "val_loss": 13.859248161315918, "val_acc": 50.0, "val_auroc": 0.74, "time": 849.78}
{"epoch": 42, "training_loss": 55.19194221496582, "training_acc": 52.5, "val_loss": 13.835991621017456, "val_acc": 50.0, "val_auroc": 0.77, "time": 869.21}
{"epoch": 43, "training_loss": 55.196725845336914, "training_acc": 52.5, "val_loss": 13.836520910263062, "val_acc": 50.0, "val_auroc": 0.76, "time": 888.45}
{"epoch": 44, "training_loss": 55.16569137573242, "training_acc": 52.5, "val_loss": 13.83924126625061, "val_acc": 50.0, "val_auroc": 0.71, "time": 907.1}
{"epoch": 45, "training_loss": 55.121530532836914, "training_acc": 52.5, "val_loss": 13.819860219955444, "val_acc": 50.0, "val_auroc": 0.73, "time": 927.9}
{"epoch": 46, "training_loss": 55.09925556182861, "training_acc": 52.5, "val_loss": 13.80297064781189, "val_acc": 50.0, "val_auroc": 0.77, "time": 947.18}
