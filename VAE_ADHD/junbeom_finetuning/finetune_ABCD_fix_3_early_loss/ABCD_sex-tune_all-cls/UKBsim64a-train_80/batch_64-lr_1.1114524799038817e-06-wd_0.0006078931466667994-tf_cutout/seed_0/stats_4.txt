"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 54.672953605651855, "training_acc": 52.5, "val_loss": 15.283801555633545, "val_acc": 55.0, "val_auroc": 0.505, "time": 19.18}
{"epoch": 1, "training_loss": 62.517226219177246, "training_acc": 51.25, "val_loss": 15.090949535369873, "val_acc": 55.0, "val_auroc": 0.485, "time": 44.07}
{"epoch": 2, "training_loss": 61.33115196228027, "training_acc": 51.25, "val_loss": 14.883662462234497, "val_acc": 55.0, "val_auroc": 0.485, "time": 69.11}
{"epoch": 3, "training_loss": 60.17128086090088, "training_acc": 51.25, "val_loss": 14.675559997558594, "val_acc": 55.0, "val_auroc": 0.485, "time": 91.29}
{"epoch": 4, "training_loss": 59.250532150268555, "training_acc": 51.25, "val_loss": 14.476431608200073, "val_acc": 55.0, "val_auroc": 0.495, "time": 111.95}
{"epoch": 5, "training_loss": 58.03287696838379, "training_acc": 51.25, "val_loss": 14.301917552947998, "val_acc": 55.0, "val_auroc": 0.495, "time": 132.73}
{"epoch": 6, "training_loss": 56.74691581726074, "training_acc": 52.5, "val_loss": 14.159198999404907, "val_acc": 55.0, "val_auroc": 0.485, "time": 154.43}
{"epoch": 7, "training_loss": 56.33224391937256, "training_acc": 52.5, "val_loss": 14.050682783126831, "val_acc": 55.0, "val_auroc": 0.485, "time": 176.2}
{"epoch": 8, "training_loss": 55.1608772277832, "training_acc": 52.5, "val_loss": 13.966761827468872, "val_acc": 55.0, "val_auroc": 0.485, "time": 194.38}
{"epoch": 9, "training_loss": 55.53805351257324, "training_acc": 51.25, "val_loss": 13.913823366165161, "val_acc": 55.0, "val_auroc": 0.485, "time": 216.33}
{"epoch": 10, "training_loss": 54.89161682128906, "training_acc": 52.5, "val_loss": 13.881863355636597, "val_acc": 55.0, "val_auroc": 0.475, "time": 238.18}
{"epoch": 11, "training_loss": 54.62792682647705, "training_acc": 53.75, "val_loss": 13.864411115646362, "val_acc": 55.0, "val_auroc": 0.485, "time": 260.28}
{"epoch": 12, "training_loss": 54.27599906921387, "training_acc": 52.5, "val_loss": 13.860057592391968, "val_acc": 55.0, "val_auroc": 0.495, "time": 277.88}
{"epoch": 13, "training_loss": 54.30814743041992, "training_acc": 53.75, "val_loss": 13.865823745727539, "val_acc": 55.0, "val_auroc": 0.495, "time": 298.09}
{"epoch": 14, "training_loss": 53.86099052429199, "training_acc": 61.25, "val_loss": 13.876323699951172, "val_acc": 55.0, "val_auroc": 0.495, "time": 319.29}
{"epoch": 15, "training_loss": 53.87954235076904, "training_acc": 60.0, "val_loss": 13.88921856880188, "val_acc": 55.0, "val_auroc": 0.495, "time": 338.72}
{"epoch": 16, "training_loss": 53.83312225341797, "training_acc": 61.25, "val_loss": 13.898704051971436, "val_acc": 55.0, "val_auroc": 0.495, "time": 356.18}
{"epoch": 17, "training_loss": 54.173187255859375, "training_acc": 61.25, "val_loss": 13.90265703201294, "val_acc": 55.0, "val_auroc": 0.505, "time": 379.06}
{"epoch": 18, "training_loss": 53.90887641906738, "training_acc": 63.75, "val_loss": 13.906621932983398, "val_acc": 55.0, "val_auroc": 0.505, "time": 398.9}
{"epoch": 19, "training_loss": 54.000633239746094, "training_acc": 63.75, "val_loss": 13.913295269012451, "val_acc": 55.0, "val_auroc": 0.505, "time": 420.58}
{"epoch": 20, "training_loss": 53.80746078491211, "training_acc": 63.75, "val_loss": 13.9206063747406, "val_acc": 55.0, "val_auroc": 0.505, "time": 438.16}
{"epoch": 21, "training_loss": 54.03117847442627, "training_acc": 61.25, "val_loss": 13.926771879196167, "val_acc": 55.0, "val_auroc": 0.505, "time": 458.19}
{"epoch": 22, "training_loss": 53.563270568847656, "training_acc": 62.5, "val_loss": 13.930686712265015, "val_acc": 55.0, "val_auroc": 0.505, "time": 477.21}
{"epoch": 23, "training_loss": 53.61780548095703, "training_acc": 66.25, "val_loss": 13.92982006072998, "val_acc": 55.0, "val_auroc": 0.505, "time": 495.9}
{"epoch": 24, "training_loss": 54.32758712768555, "training_acc": 61.25, "val_loss": 13.928264379501343, "val_acc": 55.0, "val_auroc": 0.505, "time": 512.11}
{"epoch": 25, "training_loss": 53.64128494262695, "training_acc": 61.25, "val_loss": 13.923641443252563, "val_acc": 55.0, "val_auroc": 0.505, "time": 533.36}
{"epoch": 26, "training_loss": 53.52182865142822, "training_acc": 60.0, "val_loss": 13.91405463218689, "val_acc": 55.0, "val_auroc": 0.495, "time": 551.87}
{"epoch": 27, "training_loss": 53.797325134277344, "training_acc": 67.5, "val_loss": 13.90214204788208, "val_acc": 55.0, "val_auroc": 0.495, "time": 571.78}
{"epoch": 28, "training_loss": 53.4996452331543, "training_acc": 66.25, "val_loss": 13.895001411437988, "val_acc": 55.0, "val_auroc": 0.495, "time": 589.84}
{"epoch": 29, "training_loss": 54.23572540283203, "training_acc": 57.5, "val_loss": 13.888826370239258, "val_acc": 55.0, "val_auroc": 0.495, "time": 609.62}
{"epoch": 30, "training_loss": 53.659162521362305, "training_acc": 62.5, "val_loss": 13.879722356796265, "val_acc": 55.0, "val_auroc": 0.495, "time": 627.19}
{"epoch": 31, "training_loss": 53.57948398590088, "training_acc": 63.75, "val_loss": 13.87600302696228, "val_acc": 55.0, "val_auroc": 0.505, "time": 647.11}
