"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.76072406768799, "training_acc": 52.5, "val_loss": 13.920671939849854, "val_acc": 50.0, "val_auroc": 0.27, "time": 19.21}
{"epoch": 1, "training_loss": 55.60689353942871, "training_acc": 48.75, "val_loss": 13.93473505973816, "val_acc": 50.0, "val_auroc": 0.39, "time": 36.45}
{"epoch": 2, "training_loss": 55.27973747253418, "training_acc": 52.5, "val_loss": 13.889409303665161, "val_acc": 50.0, "val_auroc": 0.55, "time": 56.0}
{"epoch": 3, "training_loss": 55.11447238922119, "training_acc": 52.5, "val_loss": 13.895862102508545, "val_acc": 50.0, "val_auroc": 0.49, "time": 79.29}
{"epoch": 4, "training_loss": 54.99662113189697, "training_acc": 52.5, "val_loss": 13.865913152694702, "val_acc": 50.0, "val_auroc": 0.5, "time": 97.39}
{"epoch": 5, "training_loss": 54.9500732421875, "training_acc": 65.0, "val_loss": 13.860946893692017, "val_acc": 50.0, "val_auroc": 0.5, "time": 115.81}
{"epoch": 6, "training_loss": 54.741329193115234, "training_acc": 68.75, "val_loss": 13.867061138153076, "val_acc": 50.0, "val_auroc": 0.49, "time": 134.73}
{"epoch": 7, "training_loss": 54.58963584899902, "training_acc": 56.25, "val_loss": 13.869322538375854, "val_acc": 50.0, "val_auroc": 0.5, "time": 155.37}
{"epoch": 8, "training_loss": 54.14498519897461, "training_acc": 68.75, "val_loss": 13.85180115699768, "val_acc": 50.0, "val_auroc": 0.53, "time": 173.75}
{"epoch": 9, "training_loss": 54.20362854003906, "training_acc": 65.0, "val_loss": 13.9590322971344, "val_acc": 50.0, "val_auroc": 0.49, "time": 191.05}
{"epoch": 10, "training_loss": 54.01875686645508, "training_acc": 57.5, "val_loss": 13.82121205329895, "val_acc": 50.0, "val_auroc": 0.54, "time": 209.08}
{"epoch": 11, "training_loss": 53.21737098693848, "training_acc": 67.5, "val_loss": 14.138678312301636, "val_acc": 50.0, "val_auroc": 0.42, "time": 228.84}
{"epoch": 12, "training_loss": 55.215213775634766, "training_acc": 52.5, "val_loss": 14.130700826644897, "val_acc": 50.0, "val_auroc": 0.47, "time": 247.67}
{"epoch": 13, "training_loss": 55.55915832519531, "training_acc": 52.5, "val_loss": 14.084184169769287, "val_acc": 50.0, "val_auroc": 0.52, "time": 265.35}
{"epoch": 14, "training_loss": 55.19150352478027, "training_acc": 52.5, "val_loss": 14.119741916656494, "val_acc": 50.0, "val_auroc": 0.53, "time": 283.47}
{"epoch": 15, "training_loss": 54.63246726989746, "training_acc": 52.5, "val_loss": 14.13596510887146, "val_acc": 50.0, "val_auroc": 0.51, "time": 302.3}
{"epoch": 16, "training_loss": 54.293349266052246, "training_acc": 52.5, "val_loss": 14.028916358947754, "val_acc": 50.0, "val_auroc": 0.49, "time": 319.12}
{"epoch": 17, "training_loss": 53.584190368652344, "training_acc": 56.25, "val_loss": 13.874435424804688, "val_acc": 50.0, "val_auroc": 0.52, "time": 336.07}
{"epoch": 18, "training_loss": 53.020461082458496, "training_acc": 70.0, "val_loss": 13.97883653640747, "val_acc": 50.0, "val_auroc": 0.5, "time": 354.19}
{"epoch": 19, "training_loss": 53.41280555725098, "training_acc": 63.75, "val_loss": 13.89101505279541, "val_acc": 50.0, "val_auroc": 0.46, "time": 374.49}
{"epoch": 20, "training_loss": 52.22104454040527, "training_acc": 72.5, "val_loss": 14.010926485061646, "val_acc": 50.0, "val_auroc": 0.44, "time": 393.27}
{"epoch": 21, "training_loss": 53.88263130187988, "training_acc": 53.75, "val_loss": 14.074211120605469, "val_acc": 50.0, "val_auroc": 0.48, "time": 410.56}
{"epoch": 22, "training_loss": 53.824113845825195, "training_acc": 56.25, "val_loss": 14.23906683921814, "val_acc": 50.0, "val_auroc": 0.46, "time": 428.69}
{"epoch": 23, "training_loss": 54.66095542907715, "training_acc": 52.5, "val_loss": 14.00632381439209, "val_acc": 50.0, "val_auroc": 0.5, "time": 447.19}
{"epoch": 24, "training_loss": 53.61940574645996, "training_acc": 53.75, "val_loss": 13.863109350204468, "val_acc": 50.0, "val_auroc": 0.49, "time": 466.11}
{"epoch": 25, "training_loss": 53.70855522155762, "training_acc": 63.75, "val_loss": 13.92798900604248, "val_acc": 50.0, "val_auroc": 0.48, "time": 482.63}
{"epoch": 26, "training_loss": 53.87253379821777, "training_acc": 53.75, "val_loss": 13.88230562210083, "val_acc": 50.0, "val_auroc": 0.5, "time": 500.78}
{"epoch": 27, "training_loss": 52.444252014160156, "training_acc": 65.0, "val_loss": 14.038336277008057, "val_acc": 50.0, "val_auroc": 0.46, "time": 519.27}
{"epoch": 28, "training_loss": 52.192203521728516, "training_acc": 62.5, "val_loss": 14.033313989639282, "val_acc": 50.0, "val_auroc": 0.5, "time": 540.05}
{"epoch": 29, "training_loss": 53.10439395904541, "training_acc": 56.25, "val_loss": 14.003152847290039, "val_acc": 50.0, "val_auroc": 0.44, "time": 558.48}
