"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.83703422546387, "training_acc": 52.5, "val_loss": 13.945902585983276, "val_acc": 50.0, "val_auroc": 0.55, "time": 19.01}
{"epoch": 1, "training_loss": 55.742584228515625, "training_acc": 52.5, "val_loss": 13.847228288650513, "val_acc": 50.0, "val_auroc": 0.86, "time": 37.81}
{"epoch": 2, "training_loss": 55.31270790100098, "training_acc": 52.5, "val_loss": 13.825552463531494, "val_acc": 50.0, "val_auroc": 0.81, "time": 65.2}
{"epoch": 3, "training_loss": 55.25560474395752, "training_acc": 52.5, "val_loss": 13.826497793197632, "val_acc": 50.0, "val_auroc": 0.81, "time": 86.34}
{"epoch": 4, "training_loss": 55.25423622131348, "training_acc": 52.5, "val_loss": 13.84592056274414, "val_acc": 50.0, "val_auroc": 0.67, "time": 104.84}
{"epoch": 5, "training_loss": 55.25303649902344, "training_acc": 52.5, "val_loss": 13.839914798736572, "val_acc": 50.0, "val_auroc": 0.69, "time": 128.63}
{"epoch": 6, "training_loss": 55.251380920410156, "training_acc": 52.5, "val_loss": 13.823870420455933, "val_acc": 50.0, "val_auroc": 0.79, "time": 153.84}
{"epoch": 7, "training_loss": 55.181901931762695, "training_acc": 52.5, "val_loss": 13.803815841674805, "val_acc": 50.0, "val_auroc": 0.82, "time": 173.43}
{"epoch": 8, "training_loss": 55.13173866271973, "training_acc": 52.5, "val_loss": 13.783165216445923, "val_acc": 50.0, "val_auroc": 0.84, "time": 190.46}
{"epoch": 9, "training_loss": 55.110413551330566, "training_acc": 52.5, "val_loss": 13.783587217330933, "val_acc": 50.0, "val_auroc": 0.84, "time": 209.93}
{"epoch": 10, "training_loss": 55.19647789001465, "training_acc": 68.75, "val_loss": 13.743894100189209, "val_acc": 50.0, "val_auroc": 0.83, "time": 231.48}
{"epoch": 11, "training_loss": 55.001882553100586, "training_acc": 62.5, "val_loss": 13.807554244995117, "val_acc": 50.0, "val_auroc": 0.79, "time": 254.77}
{"epoch": 12, "training_loss": 55.011199951171875, "training_acc": 52.5, "val_loss": 13.76967191696167, "val_acc": 50.0, "val_auroc": 0.8, "time": 272.29}
{"epoch": 13, "training_loss": 55.022154808044434, "training_acc": 52.5, "val_loss": 13.760977983474731, "val_acc": 50.0, "val_auroc": 0.77, "time": 291.97}
{"epoch": 14, "training_loss": 54.9375581741333, "training_acc": 52.5, "val_loss": 13.922501802444458, "val_acc": 50.0, "val_auroc": 0.78, "time": 312.2}
{"epoch": 15, "training_loss": 55.12420845031738, "training_acc": 52.5, "val_loss": 14.118461608886719, "val_acc": 50.0, "val_auroc": 0.73, "time": 331.44}
{"epoch": 16, "training_loss": 55.63585662841797, "training_acc": 52.5, "val_loss": 13.841747045516968, "val_acc": 50.0, "val_auroc": 0.73, "time": 347.77}
{"epoch": 17, "training_loss": 54.79922866821289, "training_acc": 52.5, "val_loss": 13.792407512664795, "val_acc": 50.0, "val_auroc": 0.81, "time": 366.07}
{"epoch": 18, "training_loss": 54.980350494384766, "training_acc": 55.0, "val_loss": 13.845672607421875, "val_acc": 50.0, "val_auroc": 0.59, "time": 387.56}
{"epoch": 19, "training_loss": 55.4836540222168, "training_acc": 48.75, "val_loss": 13.778878450393677, "val_acc": 50.0, "val_auroc": 0.72, "time": 407.45}
{"epoch": 20, "training_loss": 55.01835250854492, "training_acc": 51.25, "val_loss": 13.65339994430542, "val_acc": 50.0, "val_auroc": 0.77, "time": 426.33}
{"epoch": 21, "training_loss": 54.58930015563965, "training_acc": 66.25, "val_loss": 13.761833906173706, "val_acc": 50.0, "val_auroc": 0.74, "time": 446.26}
{"epoch": 22, "training_loss": 54.7041072845459, "training_acc": 52.5, "val_loss": 13.777273893356323, "val_acc": 50.0, "val_auroc": 0.71, "time": 467.17}
{"epoch": 23, "training_loss": 54.52848434448242, "training_acc": 52.5, "val_loss": 13.66368293762207, "val_acc": 50.0, "val_auroc": 0.75, "time": 486.48}
{"epoch": 24, "training_loss": 54.13368225097656, "training_acc": 52.5, "val_loss": 13.581703901290894, "val_acc": 50.0, "val_auroc": 0.76, "time": 503.81}
{"epoch": 25, "training_loss": 53.449591636657715, "training_acc": 52.5, "val_loss": 13.497394323348999, "val_acc": 50.0, "val_auroc": 0.74, "time": 523.09}
{"epoch": 26, "training_loss": 53.298598289489746, "training_acc": 61.25, "val_loss": 13.381187915802002, "val_acc": 50.0, "val_auroc": 0.7, "time": 545.08}
{"epoch": 27, "training_loss": 52.356523513793945, "training_acc": 58.75, "val_loss": 13.343126773834229, "val_acc": 50.0, "val_auroc": 0.74, "time": 564.86}
{"epoch": 28, "training_loss": 52.59052753448486, "training_acc": 65.0, "val_loss": 13.87020230293274, "val_acc": 50.0, "val_auroc": 0.59, "time": 583.97}
{"epoch": 29, "training_loss": 55.37643909454346, "training_acc": 52.5, "val_loss": 13.881524801254272, "val_acc": 50.0, "val_auroc": 0.77, "time": 605.75}
{"epoch": 30, "training_loss": 55.54991054534912, "training_acc": 47.5, "val_loss": 13.859829902648926, "val_acc": 50.0, "val_auroc": 0.76, "time": 629.08}
{"epoch": 31, "training_loss": 55.2525634765625, "training_acc": 52.5, "val_loss": 13.91931414604187, "val_acc": 50.0, "val_auroc": 0.78, "time": 649.01}
{"epoch": 32, "training_loss": 55.490572929382324, "training_acc": 52.5, "val_loss": 13.868048191070557, "val_acc": 50.0, "val_auroc": 0.81, "time": 668.91}
{"epoch": 33, "training_loss": 55.371490478515625, "training_acc": 52.5, "val_loss": 13.864675760269165, "val_acc": 50.0, "val_auroc": 0.74, "time": 688.05}
{"epoch": 34, "training_loss": 55.27935218811035, "training_acc": 52.5, "val_loss": 13.89799952507019, "val_acc": 50.0, "val_auroc": 0.68, "time": 709.22}
{"epoch": 35, "training_loss": 55.623148918151855, "training_acc": 52.5, "val_loss": 13.8650643825531, "val_acc": 50.0, "val_auroc": 0.71, "time": 729.79}
{"epoch": 36, "training_loss": 55.19110870361328, "training_acc": 52.5, "val_loss": 13.874324560165405, "val_acc": 50.0, "val_auroc": 0.7, "time": 749.7}
{"epoch": 37, "training_loss": 55.73093032836914, "training_acc": 47.5, "val_loss": 13.935517072677612, "val_acc": 50.0, "val_auroc": 0.67, "time": 768.73}
{"epoch": 38, "training_loss": 56.16114521026611, "training_acc": 47.5, "val_loss": 13.883209228515625, "val_acc": 50.0, "val_auroc": 0.75, "time": 789.18}
{"epoch": 39, "training_loss": 55.75843811035156, "training_acc": 47.5, "val_loss": 13.86116623878479, "val_acc": 50.0, "val_auroc": 0.7, "time": 809.84}
{"epoch": 40, "training_loss": 55.40273857116699, "training_acc": 52.5, "val_loss": 13.888634443283081, "val_acc": 50.0, "val_auroc": 0.81, "time": 828.36}
{"epoch": 41, "training_loss": 55.455183029174805, "training_acc": 52.5, "val_loss": 13.876560926437378, "val_acc": 50.0, "val_auroc": 0.64, "time": 846.43}
{"epoch": 42, "training_loss": 55.37295341491699, "training_acc": 52.5, "val_loss": 13.862924575805664, "val_acc": 50.0, "val_auroc": 0.64, "time": 867.84}
{"epoch": 43, "training_loss": 55.37935733795166, "training_acc": 52.5, "val_loss": 13.875648975372314, "val_acc": 50.0, "val_auroc": 0.62, "time": 887.13}
{"epoch": 44, "training_loss": 55.3614444732666, "training_acc": 52.5, "val_loss": 13.892987966537476, "val_acc": 50.0, "val_auroc": 0.65, "time": 905.96}
{"epoch": 45, "training_loss": 55.343631744384766, "training_acc": 52.5, "val_loss": 13.88851284980774, "val_acc": 50.0, "val_auroc": 0.66, "time": 924.83}
{"epoch": 46, "training_loss": 55.38406276702881, "training_acc": 52.5, "val_loss": 13.895326852798462, "val_acc": 50.0, "val_auroc": 0.7, "time": 945.9}
