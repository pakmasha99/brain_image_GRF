"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.64690399169922, "training_acc": 51.25, "val_loss": 13.788076639175415, "val_acc": 55.0, "val_auroc": 0.434, "time": 20.37}
{"epoch": 1, "training_loss": 55.621371269226074, "training_acc": 51.25, "val_loss": 13.816438913345337, "val_acc": 55.0, "val_auroc": 0.535, "time": 44.64}
{"epoch": 2, "training_loss": 55.308048248291016, "training_acc": 53.75, "val_loss": 13.79023551940918, "val_acc": 55.0, "val_auroc": 0.434, "time": 67.92}
{"epoch": 3, "training_loss": 55.20743465423584, "training_acc": 51.25, "val_loss": 13.871017694473267, "val_acc": 55.0, "val_auroc": 0.525, "time": 88.11}
{"epoch": 4, "training_loss": 55.4133415222168, "training_acc": 61.25, "val_loss": 13.819034099578857, "val_acc": 55.0, "val_auroc": 0.404, "time": 107.22}
{"epoch": 5, "training_loss": 55.281639099121094, "training_acc": 51.25, "val_loss": 13.794550895690918, "val_acc": 55.0, "val_auroc": 0.414, "time": 124.84}
{"epoch": 6, "training_loss": 55.2564697265625, "training_acc": 51.25, "val_loss": 13.823318481445312, "val_acc": 55.0, "val_auroc": 0.465, "time": 143.41}
{"epoch": 7, "training_loss": 55.18501853942871, "training_acc": 51.25, "val_loss": 13.858920335769653, "val_acc": 55.0, "val_auroc": 0.434, "time": 161.74}
{"epoch": 8, "training_loss": 55.258962631225586, "training_acc": 52.5, "val_loss": 13.931856155395508, "val_acc": 55.0, "val_auroc": 0.434, "time": 181.24}
{"epoch": 9, "training_loss": 55.15779209136963, "training_acc": 51.25, "val_loss": 14.001359939575195, "val_acc": 55.0, "val_auroc": 0.465, "time": 199.85}
{"epoch": 10, "training_loss": 55.181633949279785, "training_acc": 48.75, "val_loss": 13.798439502716064, "val_acc": 55.0, "val_auroc": 0.515, "time": 217.35}
{"epoch": 11, "training_loss": 55.13708305358887, "training_acc": 51.25, "val_loss": 13.773826360702515, "val_acc": 55.0, "val_auroc": 0.485, "time": 235.93}
{"epoch": 12, "training_loss": 56.01828098297119, "training_acc": 51.25, "val_loss": 13.758407831192017, "val_acc": 55.0, "val_auroc": 0.515, "time": 252.22}
{"epoch": 13, "training_loss": 55.625959396362305, "training_acc": 51.25, "val_loss": 13.781260251998901, "val_acc": 55.0, "val_auroc": 0.455, "time": 271.74}
{"epoch": 14, "training_loss": 55.303208351135254, "training_acc": 51.25, "val_loss": 13.854361772537231, "val_acc": 55.0, "val_auroc": 0.505, "time": 288.07}
{"epoch": 15, "training_loss": 55.62459850311279, "training_acc": 45.0, "val_loss": 13.856282234191895, "val_acc": 55.0, "val_auroc": 0.495, "time": 305.55}
{"epoch": 16, "training_loss": 55.00122261047363, "training_acc": 58.75, "val_loss": 13.77549409866333, "val_acc": 55.0, "val_auroc": 0.434, "time": 322.91}
{"epoch": 17, "training_loss": 55.65709114074707, "training_acc": 51.25, "val_loss": 13.774203062057495, "val_acc": 55.0, "val_auroc": 0.333, "time": 342.65}
{"epoch": 18, "training_loss": 55.520681381225586, "training_acc": 51.25, "val_loss": 13.810328245162964, "val_acc": 55.0, "val_auroc": 0.455, "time": 362.62}
{"epoch": 19, "training_loss": 55.28190994262695, "training_acc": 51.25, "val_loss": 13.946914672851562, "val_acc": 55.0, "val_auroc": 0.414, "time": 381.55}
{"epoch": 20, "training_loss": 55.55208683013916, "training_acc": 48.75, "val_loss": 13.996882438659668, "val_acc": 55.0, "val_auroc": 0.495, "time": 398.21}
{"epoch": 21, "training_loss": 55.492902755737305, "training_acc": 48.75, "val_loss": 13.851684331893921, "val_acc": 55.0, "val_auroc": 0.455, "time": 416.56}
{"epoch": 22, "training_loss": 55.34214973449707, "training_acc": 52.5, "val_loss": 13.799521923065186, "val_acc": 55.0, "val_auroc": 0.455, "time": 434.99}
{"epoch": 23, "training_loss": 55.3577995300293, "training_acc": 51.25, "val_loss": 13.795796632766724, "val_acc": 55.0, "val_auroc": 0.465, "time": 454.73}
{"epoch": 24, "training_loss": 55.36200141906738, "training_acc": 51.25, "val_loss": 13.783777952194214, "val_acc": 55.0, "val_auroc": 0.465, "time": 472.27}
{"epoch": 25, "training_loss": 55.39254665374756, "training_acc": 51.25, "val_loss": 13.777854442596436, "val_acc": 55.0, "val_auroc": 0.434, "time": 493.05}
{"epoch": 26, "training_loss": 55.618062019348145, "training_acc": 51.25, "val_loss": 13.798998594284058, "val_acc": 55.0, "val_auroc": 0.424, "time": 513.55}
{"epoch": 27, "training_loss": 55.87182903289795, "training_acc": 51.25, "val_loss": 13.786484003067017, "val_acc": 55.0, "val_auroc": 0.475, "time": 533.05}
{"epoch": 28, "training_loss": 55.62433624267578, "training_acc": 51.25, "val_loss": 13.802223205566406, "val_acc": 55.0, "val_auroc": 0.424, "time": 549.27}
{"epoch": 29, "training_loss": 55.39087200164795, "training_acc": 48.75, "val_loss": 13.94591212272644, "val_acc": 55.0, "val_auroc": 0.414, "time": 569.29}
{"epoch": 30, "training_loss": 55.535953521728516, "training_acc": 48.75, "val_loss": 13.959569931030273, "val_acc": 55.0, "val_auroc": 0.444, "time": 590.58}
{"epoch": 31, "training_loss": 55.576650619506836, "training_acc": 48.75, "val_loss": 13.9708411693573, "val_acc": 55.0, "val_auroc": 0.485, "time": 607.55}
