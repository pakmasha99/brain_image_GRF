"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 54.56259727478027, "training_acc": 56.25, "val_loss": 18.759552240371704, "val_acc": 55.0, "val_auroc": 0.586, "time": 19.31}
{"epoch": 1, "training_loss": 74.49491786956787, "training_acc": 51.25, "val_loss": 15.843521356582642, "val_acc": 55.0, "val_auroc": 0.556, "time": 37.21}
{"epoch": 2, "training_loss": 61.39866828918457, "training_acc": 51.25, "val_loss": 14.037424325942993, "val_acc": 55.0, "val_auroc": 0.515, "time": 61.4}
{"epoch": 3, "training_loss": 54.17554187774658, "training_acc": 56.25, "val_loss": 13.876172304153442, "val_acc": 55.0, "val_auroc": 0.495, "time": 86.59}
{"epoch": 4, "training_loss": 54.160627365112305, "training_acc": 55.0, "val_loss": 14.27215576171875, "val_acc": 55.0, "val_auroc": 0.485, "time": 103.81}
{"epoch": 5, "training_loss": 55.33485794067383, "training_acc": 51.25, "val_loss": 14.461859464645386, "val_acc": 50.0, "val_auroc": 0.475, "time": 125.33}
{"epoch": 6, "training_loss": 55.88361930847168, "training_acc": 48.75, "val_loss": 14.431613683700562, "val_acc": 55.0, "val_auroc": 0.475, "time": 147.26}
{"epoch": 7, "training_loss": 55.80296325683594, "training_acc": 48.75, "val_loss": 14.295681715011597, "val_acc": 55.0, "val_auroc": 0.505, "time": 169.83}
{"epoch": 8, "training_loss": 55.145626068115234, "training_acc": 50.0, "val_loss": 14.13278341293335, "val_acc": 55.0, "val_auroc": 0.556, "time": 187.15}
{"epoch": 9, "training_loss": 55.024009704589844, "training_acc": 51.25, "val_loss": 13.988511562347412, "val_acc": 55.0, "val_auroc": 0.545, "time": 204.76}
{"epoch": 10, "training_loss": 54.30344581604004, "training_acc": 51.25, "val_loss": 13.851596117019653, "val_acc": 55.0, "val_auroc": 0.545, "time": 225.4}
{"epoch": 11, "training_loss": 53.97095966339111, "training_acc": 63.75, "val_loss": 13.741692304611206, "val_acc": 55.0, "val_auroc": 0.576, "time": 249.83}
{"epoch": 12, "training_loss": 54.01910877227783, "training_acc": 62.5, "val_loss": 13.692992925643921, "val_acc": 55.0, "val_auroc": 0.586, "time": 266.46}
{"epoch": 13, "training_loss": 53.62471389770508, "training_acc": 56.25, "val_loss": 13.692926168441772, "val_acc": 55.0, "val_auroc": 0.596, "time": 284.3}
{"epoch": 14, "training_loss": 53.48637008666992, "training_acc": 55.0, "val_loss": 13.703621625900269, "val_acc": 55.0, "val_auroc": 0.596, "time": 304.25}
{"epoch": 15, "training_loss": 53.53123474121094, "training_acc": 55.0, "val_loss": 13.714680671691895, "val_acc": 55.0, "val_auroc": 0.566, "time": 326.57}
{"epoch": 16, "training_loss": 53.75631141662598, "training_acc": 55.0, "val_loss": 13.735325336456299, "val_acc": 55.0, "val_auroc": 0.566, "time": 343.94}
{"epoch": 17, "training_loss": 53.65967845916748, "training_acc": 56.25, "val_loss": 13.75268816947937, "val_acc": 55.0, "val_auroc": 0.566, "time": 362.53}
{"epoch": 18, "training_loss": 53.44646453857422, "training_acc": 55.0, "val_loss": 13.744219541549683, "val_acc": 55.0, "val_auroc": 0.556, "time": 383.44}
{"epoch": 19, "training_loss": 52.87696838378906, "training_acc": 61.25, "val_loss": 13.738678693771362, "val_acc": 55.0, "val_auroc": 0.545, "time": 405.01}
{"epoch": 20, "training_loss": 52.51643371582031, "training_acc": 66.25, "val_loss": 13.773528337478638, "val_acc": 55.0, "val_auroc": 0.545, "time": 421.55}
{"epoch": 21, "training_loss": 52.74246120452881, "training_acc": 68.75, "val_loss": 13.82149338722229, "val_acc": 55.0, "val_auroc": 0.535, "time": 439.98}
{"epoch": 22, "training_loss": 52.29512596130371, "training_acc": 72.5, "val_loss": 13.84783148765564, "val_acc": 55.0, "val_auroc": 0.535, "time": 460.38}
{"epoch": 23, "training_loss": 52.25724411010742, "training_acc": 71.25, "val_loss": 13.83745789527893, "val_acc": 55.0, "val_auroc": 0.545, "time": 482.24}
{"epoch": 24, "training_loss": 52.575660705566406, "training_acc": 67.5, "val_loss": 13.797773122787476, "val_acc": 55.0, "val_auroc": 0.545, "time": 498.64}
{"epoch": 25, "training_loss": 51.44803333282471, "training_acc": 67.5, "val_loss": 13.804761171340942, "val_acc": 55.0, "val_auroc": 0.545, "time": 516.77}
{"epoch": 26, "training_loss": 51.133599281311035, "training_acc": 61.25, "val_loss": 13.934468030929565, "val_acc": 55.0, "val_auroc": 0.535, "time": 535.43}
{"epoch": 27, "training_loss": 52.20380973815918, "training_acc": 57.5, "val_loss": 14.088739156723022, "val_acc": 55.0, "val_auroc": 0.556, "time": 556.12}
{"epoch": 28, "training_loss": 52.62622547149658, "training_acc": 60.0, "val_loss": 14.039987325668335, "val_acc": 55.0, "val_auroc": 0.556, "time": 573.09}
{"epoch": 29, "training_loss": 52.683393478393555, "training_acc": 58.75, "val_loss": 13.838279247283936, "val_acc": 55.0, "val_auroc": 0.556, "time": 590.53}
{"epoch": 30, "training_loss": 51.14915943145752, "training_acc": 66.25, "val_loss": 13.779458999633789, "val_acc": 55.0, "val_auroc": 0.556, "time": 612.4}
{"epoch": 31, "training_loss": 51.010799407958984, "training_acc": 67.5, "val_loss": 13.85527491569519, "val_acc": 55.0, "val_auroc": 0.566, "time": 634.64}
{"epoch": 32, "training_loss": 51.317325592041016, "training_acc": 67.5, "val_loss": 13.94368052482605, "val_acc": 50.0, "val_auroc": 0.556, "time": 654.62}
