"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.428619384765625, "training_acc": 43.75, "val_loss": 14.332302808761597, "val_acc": 50.0, "val_auroc": 0.79, "time": 18.13}
{"epoch": 1, "training_loss": 59.39855766296387, "training_acc": 47.5, "val_loss": 13.870736360549927, "val_acc": 50.0, "val_auroc": 0.77, "time": 36.39}
{"epoch": 2, "training_loss": 55.715736389160156, "training_acc": 50.0, "val_loss": 14.155077934265137, "val_acc": 50.0, "val_auroc": 0.5, "time": 60.17}
{"epoch": 3, "training_loss": 55.816734313964844, "training_acc": 52.5, "val_loss": 14.247798919677734, "val_acc": 50.0, "val_auroc": 0.32, "time": 85.26}
{"epoch": 4, "training_loss": 55.837772369384766, "training_acc": 52.5, "val_loss": 13.846243619918823, "val_acc": 50.0, "val_auroc": 0.56, "time": 101.8}
{"epoch": 5, "training_loss": 55.433518409729004, "training_acc": 58.75, "val_loss": 13.813313245773315, "val_acc": 50.0, "val_auroc": 0.74, "time": 120.7}
{"epoch": 6, "training_loss": 54.78768730163574, "training_acc": 68.75, "val_loss": 14.288614988327026, "val_acc": 50.0, "val_auroc": 0.68, "time": 142.03}
{"epoch": 7, "training_loss": 56.142269134521484, "training_acc": 52.5, "val_loss": 14.555294513702393, "val_acc": 50.0, "val_auroc": 0.42, "time": 163.8}
{"epoch": 8, "training_loss": 56.490936279296875, "training_acc": 52.5, "val_loss": 13.939942121505737, "val_acc": 50.0, "val_auroc": 0.43, "time": 181.43}
{"epoch": 9, "training_loss": 55.12489318847656, "training_acc": 53.75, "val_loss": 13.923463821411133, "val_acc": 50.0, "val_auroc": 0.6, "time": 199.56}
{"epoch": 10, "training_loss": 56.02329349517822, "training_acc": 47.5, "val_loss": 13.90764832496643, "val_acc": 50.0, "val_auroc": 0.68, "time": 219.78}
{"epoch": 11, "training_loss": 55.65216064453125, "training_acc": 47.5, "val_loss": 13.880304098129272, "val_acc": 50.0, "val_auroc": 0.57, "time": 239.76}
{"epoch": 12, "training_loss": 55.30360794067383, "training_acc": 52.5, "val_loss": 14.091377258300781, "val_acc": 50.0, "val_auroc": 0.64, "time": 257.48}
{"epoch": 13, "training_loss": 55.660417556762695, "training_acc": 52.5, "val_loss": 13.951061964035034, "val_acc": 50.0, "val_auroc": 0.76, "time": 277.18}
{"epoch": 14, "training_loss": 55.23895454406738, "training_acc": 52.5, "val_loss": 13.757247924804688, "val_acc": 50.0, "val_auroc": 0.8, "time": 298.08}
{"epoch": 15, "training_loss": 55.655619621276855, "training_acc": 50.0, "val_loss": 13.728678226470947, "val_acc": 50.0, "val_auroc": 0.81, "time": 319.59}
{"epoch": 16, "training_loss": 54.765628814697266, "training_acc": 70.0, "val_loss": 13.995696306228638, "val_acc": 50.0, "val_auroc": 0.8, "time": 338.02}
{"epoch": 17, "training_loss": 55.54745674133301, "training_acc": 52.5, "val_loss": 14.267885684967041, "val_acc": 50.0, "val_auroc": 0.83, "time": 357.46}
{"epoch": 18, "training_loss": 56.0700798034668, "training_acc": 52.5, "val_loss": 14.01241660118103, "val_acc": 50.0, "val_auroc": 0.83, "time": 378.15}
{"epoch": 19, "training_loss": 55.22439002990723, "training_acc": 52.5, "val_loss": 13.80658507347107, "val_acc": 50.0, "val_auroc": 0.81, "time": 399.53}
{"epoch": 20, "training_loss": 55.255218505859375, "training_acc": 52.5, "val_loss": 13.853092193603516, "val_acc": 50.0, "val_auroc": 0.76, "time": 416.08}
{"epoch": 21, "training_loss": 55.65681266784668, "training_acc": 47.5, "val_loss": 13.819032907485962, "val_acc": 50.0, "val_auroc": 0.81, "time": 435.53}
{"epoch": 22, "training_loss": 55.428162574768066, "training_acc": 47.5, "val_loss": 13.764232397079468, "val_acc": 50.0, "val_auroc": 0.85, "time": 455.59}
{"epoch": 23, "training_loss": 54.80267906188965, "training_acc": 61.25, "val_loss": 13.87366533279419, "val_acc": 50.0, "val_auroc": 0.87, "time": 477.4}
{"epoch": 24, "training_loss": 54.96420669555664, "training_acc": 52.5, "val_loss": 14.038596153259277, "val_acc": 50.0, "val_auroc": 0.87, "time": 495.41}
{"epoch": 25, "training_loss": 55.541035652160645, "training_acc": 52.5, "val_loss": 13.950496912002563, "val_acc": 50.0, "val_auroc": 0.89, "time": 514.29}
{"epoch": 26, "training_loss": 55.76220512390137, "training_acc": 52.5, "val_loss": 13.800333738327026, "val_acc": 50.0, "val_auroc": 0.87, "time": 534.81}
{"epoch": 27, "training_loss": 54.8272705078125, "training_acc": 52.5, "val_loss": 13.702784776687622, "val_acc": 50.0, "val_auroc": 0.86, "time": 556.11}
{"epoch": 28, "training_loss": 54.85754203796387, "training_acc": 52.5, "val_loss": 13.595353364944458, "val_acc": 50.0, "val_auroc": 0.86, "time": 574.44}
{"epoch": 29, "training_loss": 55.027220726013184, "training_acc": 53.75, "val_loss": 13.788865804672241, "val_acc": 50.0, "val_auroc": 0.85, "time": 593.02}
{"epoch": 30, "training_loss": 55.709672927856445, "training_acc": 47.5, "val_loss": 13.665049076080322, "val_acc": 50.0, "val_auroc": 0.83, "time": 613.83}
{"epoch": 31, "training_loss": 54.93217658996582, "training_acc": 62.5, "val_loss": 13.797756433486938, "val_acc": 50.0, "val_auroc": 0.88, "time": 635.12}
{"epoch": 32, "training_loss": 54.69461250305176, "training_acc": 52.5, "val_loss": 13.720053434371948, "val_acc": 50.0, "val_auroc": 0.88, "time": 652.74}
{"epoch": 33, "training_loss": 54.681467056274414, "training_acc": 53.75, "val_loss": 13.57107162475586, "val_acc": 50.0, "val_auroc": 0.87, "time": 671.44}
{"epoch": 34, "training_loss": 54.62133502960205, "training_acc": 61.25, "val_loss": 13.516613245010376, "val_acc": 50.0, "val_auroc": 0.86, "time": 692.25}
{"epoch": 35, "training_loss": 54.68270969390869, "training_acc": 60.0, "val_loss": 13.56012225151062, "val_acc": 50.0, "val_auroc": 0.87, "time": 711.54}
{"epoch": 36, "training_loss": 54.09484672546387, "training_acc": 60.0, "val_loss": 13.427267074584961, "val_acc": 50.0, "val_auroc": 0.89, "time": 728.6}
{"epoch": 37, "training_loss": 54.40522861480713, "training_acc": 61.25, "val_loss": 13.408570289611816, "val_acc": 50.0, "val_auroc": 0.87, "time": 747.81}
{"epoch": 38, "training_loss": 54.38914966583252, "training_acc": 51.25, "val_loss": 13.465726375579834, "val_acc": 50.0, "val_auroc": 0.89, "time": 768.85}
{"epoch": 39, "training_loss": 53.92635917663574, "training_acc": 57.5, "val_loss": 14.028304815292358, "val_acc": 50.0, "val_auroc": 0.86, "time": 789.8}
{"epoch": 40, "training_loss": 55.25019454956055, "training_acc": 52.5, "val_loss": 13.596279621124268, "val_acc": 50.0, "val_auroc": 0.87, "time": 807.73}
{"epoch": 41, "training_loss": 53.3098726272583, "training_acc": 60.0, "val_loss": 13.749042749404907, "val_acc": 65.0, "val_auroc": 0.85, "time": 825.69}
{"epoch": 42, "training_loss": 56.612640380859375, "training_acc": 47.5, "val_loss": 13.5414457321167, "val_acc": 50.0, "val_auroc": 0.87, "time": 845.83}
{"epoch": 43, "training_loss": 54.28201389312744, "training_acc": 50.0, "val_loss": 13.852732181549072, "val_acc": 50.0, "val_auroc": 0.75, "time": 866.5}
{"epoch": 44, "training_loss": 54.700233459472656, "training_acc": 52.5, "val_loss": 14.03687834739685, "val_acc": 50.0, "val_auroc": 0.52, "time": 883.23}
{"epoch": 45, "training_loss": 55.076637268066406, "training_acc": 52.5, "val_loss": 13.941826820373535, "val_acc": 50.0, "val_auroc": 0.56, "time": 902.69}
{"epoch": 46, "training_loss": 54.93213081359863, "training_acc": 52.5, "val_loss": 13.85212779045105, "val_acc": 50.0, "val_auroc": 0.63, "time": 923.4}
{"epoch": 47, "training_loss": 54.735435485839844, "training_acc": 52.5, "val_loss": 13.821463584899902, "val_acc": 50.0, "val_auroc": 0.66, "time": 943.3}
{"epoch": 48, "training_loss": 54.88331985473633, "training_acc": 61.25, "val_loss": 13.817003965377808, "val_acc": 50.0, "val_auroc": 0.68, "time": 960.54}
{"epoch": 49, "training_loss": 54.57397270202637, "training_acc": 52.5, "val_loss": 13.924423456192017, "val_acc": 50.0, "val_auroc": 0.71, "time": 978.16}
{"epoch": 50, "training_loss": 54.724748611450195, "training_acc": 52.5, "val_loss": 13.835798501968384, "val_acc": 50.0, "val_auroc": 0.73, "time": 1000.14}
{"epoch": 51, "training_loss": 54.25114727020264, "training_acc": 52.5, "val_loss": 13.710097074508667, "val_acc": 50.0, "val_auroc": 0.72, "time": 1020.78}
{"epoch": 52, "training_loss": 54.34163856506348, "training_acc": 67.5, "val_loss": 13.695473670959473, "val_acc": 50.0, "val_auroc": 0.71, "time": 1039.88}
{"epoch": 53, "training_loss": 53.87616443634033, "training_acc": 75.0, "val_loss": 13.706973791122437, "val_acc": 50.0, "val_auroc": 0.72, "time": 1063.42}
{"epoch": 54, "training_loss": 53.59184646606445, "training_acc": 56.25, "val_loss": 13.79172682762146, "val_acc": 50.0, "val_auroc": 0.76, "time": 1082.52}
{"epoch": 55, "training_loss": 53.59663391113281, "training_acc": 52.5, "val_loss": 13.936504125595093, "val_acc": 50.0, "val_auroc": 0.78, "time": 1104.54}
{"epoch": 56, "training_loss": 54.09044647216797, "training_acc": 52.5, "val_loss": 13.595496416091919, "val_acc": 50.0, "val_auroc": 0.73, "time": 1123.3}
