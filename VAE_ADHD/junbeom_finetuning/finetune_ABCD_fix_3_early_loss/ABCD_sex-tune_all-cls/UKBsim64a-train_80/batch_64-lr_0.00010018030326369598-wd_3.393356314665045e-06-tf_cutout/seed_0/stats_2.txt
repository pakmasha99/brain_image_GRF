"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.426984786987305, "training_acc": 52.5, "val_loss": 13.847143650054932, "val_acc": 50.0, "val_auroc": 0.79, "time": 18.82}
{"epoch": 1, "training_loss": 55.45226001739502, "training_acc": 52.5, "val_loss": 13.931020498275757, "val_acc": 50.0, "val_auroc": 0.55, "time": 41.72}
{"epoch": 2, "training_loss": 55.14808654785156, "training_acc": 52.5, "val_loss": 13.851258754730225, "val_acc": 50.0, "val_auroc": 0.68, "time": 65.81}
{"epoch": 3, "training_loss": 55.25257873535156, "training_acc": 52.5, "val_loss": 13.887667655944824, "val_acc": 50.0, "val_auroc": 0.52, "time": 87.51}
{"epoch": 4, "training_loss": 55.16755676269531, "training_acc": 52.5, "val_loss": 13.84688138961792, "val_acc": 50.0, "val_auroc": 0.77, "time": 105.47}
{"epoch": 5, "training_loss": 55.03924751281738, "training_acc": 52.5, "val_loss": 13.716057538986206, "val_acc": 50.0, "val_auroc": 0.86, "time": 125.58}
{"epoch": 6, "training_loss": 55.021910667419434, "training_acc": 52.5, "val_loss": 13.943361043930054, "val_acc": 50.0, "val_auroc": 0.8, "time": 146.72}
{"epoch": 7, "training_loss": 55.09294128417969, "training_acc": 52.5, "val_loss": 14.108037948608398, "val_acc": 50.0, "val_auroc": 0.3, "time": 165.16}
{"epoch": 8, "training_loss": 55.402753829956055, "training_acc": 52.5, "val_loss": 13.930304050445557, "val_acc": 50.0, "val_auroc": 0.44, "time": 180.51}
{"epoch": 9, "training_loss": 55.178518295288086, "training_acc": 52.5, "val_loss": 13.832814693450928, "val_acc": 50.0, "val_auroc": 0.76, "time": 197.14}
{"epoch": 10, "training_loss": 55.22607898712158, "training_acc": 52.5, "val_loss": 13.814951181411743, "val_acc": 50.0, "val_auroc": 0.72, "time": 218.41}
{"epoch": 11, "training_loss": 55.09567928314209, "training_acc": 58.75, "val_loss": 13.819562196731567, "val_acc": 50.0, "val_auroc": 0.77, "time": 236.76}
{"epoch": 12, "training_loss": 54.98275566101074, "training_acc": 52.5, "val_loss": 13.756908178329468, "val_acc": 50.0, "val_auroc": 0.88, "time": 252.78}
{"epoch": 13, "training_loss": 54.841938972473145, "training_acc": 52.5, "val_loss": 13.612384796142578, "val_acc": 50.0, "val_auroc": 0.87, "time": 269.74}
{"epoch": 14, "training_loss": 54.828253746032715, "training_acc": 58.75, "val_loss": 13.658037185668945, "val_acc": 50.0, "val_auroc": 0.91, "time": 289.12}
{"epoch": 15, "training_loss": 54.54278564453125, "training_acc": 52.5, "val_loss": 13.892576694488525, "val_acc": 50.0, "val_auroc": 0.88, "time": 306.73}
{"epoch": 16, "training_loss": 54.84792900085449, "training_acc": 52.5, "val_loss": 13.89870285987854, "val_acc": 50.0, "val_auroc": 0.88, "time": 325.35}
{"epoch": 17, "training_loss": 54.67993354797363, "training_acc": 55.0, "val_loss": 13.560327291488647, "val_acc": 50.0, "val_auroc": 0.93, "time": 341.18}
{"epoch": 18, "training_loss": 55.035417556762695, "training_acc": 55.0, "val_loss": 13.859838247299194, "val_acc": 50.0, "val_auroc": 0.58, "time": 362.03}
{"epoch": 19, "training_loss": 55.67754554748535, "training_acc": 48.75, "val_loss": 13.842198848724365, "val_acc": 50.0, "val_auroc": 0.64, "time": 381.18}
{"epoch": 20, "training_loss": 55.28407955169678, "training_acc": 57.5, "val_loss": 13.749125003814697, "val_acc": 50.0, "val_auroc": 0.81, "time": 397.99}
{"epoch": 21, "training_loss": 54.936604499816895, "training_acc": 55.0, "val_loss": 13.784435987472534, "val_acc": 50.0, "val_auroc": 0.85, "time": 415.32}
{"epoch": 22, "training_loss": 54.93340301513672, "training_acc": 52.5, "val_loss": 13.748488426208496, "val_acc": 50.0, "val_auroc": 0.85, "time": 434.58}
{"epoch": 23, "training_loss": 54.80918884277344, "training_acc": 52.5, "val_loss": 13.709278106689453, "val_acc": 50.0, "val_auroc": 0.85, "time": 452.76}
{"epoch": 24, "training_loss": 54.668601989746094, "training_acc": 52.5, "val_loss": 13.842030763626099, "val_acc": 50.0, "val_auroc": 0.85, "time": 469.86}
{"epoch": 25, "training_loss": 55.03786277770996, "training_acc": 52.5, "val_loss": 13.694332838058472, "val_acc": 50.0, "val_auroc": 0.81, "time": 486.72}
{"epoch": 26, "training_loss": 55.327155113220215, "training_acc": 53.75, "val_loss": 13.73031497001648, "val_acc": 50.0, "val_auroc": 0.78, "time": 506.53}
{"epoch": 27, "training_loss": 54.361026763916016, "training_acc": 52.5, "val_loss": 13.868582248687744, "val_acc": 50.0, "val_auroc": 0.72, "time": 523.72}
{"epoch": 28, "training_loss": 54.972328186035156, "training_acc": 52.5, "val_loss": 13.629204034805298, "val_acc": 50.0, "val_auroc": 0.82, "time": 540.49}
{"epoch": 29, "training_loss": 54.84370231628418, "training_acc": 63.75, "val_loss": 13.85000467300415, "val_acc": 50.0, "val_auroc": 0.58, "time": 557.52}
{"epoch": 30, "training_loss": 55.4835319519043, "training_acc": 47.5, "val_loss": 13.829017877578735, "val_acc": 50.0, "val_auroc": 0.8, "time": 576.86}
{"epoch": 31, "training_loss": 55.3037748336792, "training_acc": 52.5, "val_loss": 13.76907229423523, "val_acc": 50.0, "val_auroc": 0.85, "time": 595.45}
{"epoch": 32, "training_loss": 55.0214262008667, "training_acc": 52.5, "val_loss": 13.705263137817383, "val_acc": 50.0, "val_auroc": 0.83, "time": 612.12}
{"epoch": 33, "training_loss": 54.96797180175781, "training_acc": 57.5, "val_loss": 13.653414249420166, "val_acc": 50.0, "val_auroc": 0.79, "time": 628.47}
{"epoch": 34, "training_loss": 54.81767463684082, "training_acc": 66.25, "val_loss": 13.734434843063354, "val_acc": 50.0, "val_auroc": 0.79, "time": 647.21}
{"epoch": 35, "training_loss": 55.05819511413574, "training_acc": 52.5, "val_loss": 13.858978748321533, "val_acc": 50.0, "val_auroc": 0.69, "time": 665.8}
{"epoch": 36, "training_loss": 54.815935134887695, "training_acc": 52.5, "val_loss": 13.681964874267578, "val_acc": 50.0, "val_auroc": 0.75, "time": 683.48}
