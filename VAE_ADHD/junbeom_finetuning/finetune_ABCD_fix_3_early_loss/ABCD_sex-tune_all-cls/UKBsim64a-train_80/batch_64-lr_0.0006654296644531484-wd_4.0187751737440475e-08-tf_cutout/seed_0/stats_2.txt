"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.47906494140625, "training_acc": 52.5, "val_loss": 13.950518369674683, "val_acc": 50.0, "val_auroc": 0.47, "time": 18.73}
{"epoch": 1, "training_loss": 55.73704719543457, "training_acc": 47.5, "val_loss": 13.917107582092285, "val_acc": 50.0, "val_auroc": 0.77, "time": 41.57}
{"epoch": 2, "training_loss": 55.51966190338135, "training_acc": 50.0, "val_loss": 13.904551267623901, "val_acc": 50.0, "val_auroc": 0.77, "time": 62.46}
{"epoch": 3, "training_loss": 55.53469657897949, "training_acc": 52.5, "val_loss": 14.00530457496643, "val_acc": 50.0, "val_auroc": 0.68, "time": 85.64}
{"epoch": 4, "training_loss": 55.53598594665527, "training_acc": 52.5, "val_loss": 13.879549503326416, "val_acc": 50.0, "val_auroc": 0.66, "time": 110.29}
{"epoch": 5, "training_loss": 55.42878341674805, "training_acc": 51.25, "val_loss": 13.875250816345215, "val_acc": 50.0, "val_auroc": 0.52, "time": 133.69}
{"epoch": 6, "training_loss": 55.418264389038086, "training_acc": 52.5, "val_loss": 14.044440984725952, "val_acc": 50.0, "val_auroc": 0.82, "time": 154.03}
{"epoch": 7, "training_loss": 55.65526008605957, "training_acc": 52.5, "val_loss": 14.177004098892212, "val_acc": 50.0, "val_auroc": 0.5, "time": 174.54}
{"epoch": 8, "training_loss": 55.9262752532959, "training_acc": 52.5, "val_loss": 13.905030488967896, "val_acc": 50.0, "val_auroc": 0.23, "time": 192.44}
{"epoch": 9, "training_loss": 55.327226638793945, "training_acc": 52.5, "val_loss": 13.894342184066772, "val_acc": 50.0, "val_auroc": 0.51, "time": 214.03}
{"epoch": 10, "training_loss": 55.84995651245117, "training_acc": 47.5, "val_loss": 13.876198530197144, "val_acc": 50.0, "val_auroc": 0.75, "time": 234.61}
{"epoch": 11, "training_loss": 55.52057361602783, "training_acc": 47.5, "val_loss": 13.914073705673218, "val_acc": 50.0, "val_auroc": 0.77, "time": 255.01}
{"epoch": 12, "training_loss": 55.45124626159668, "training_acc": 52.5, "val_loss": 14.036970138549805, "val_acc": 50.0, "val_auroc": 0.22, "time": 275.28}
{"epoch": 13, "training_loss": 55.59946060180664, "training_acc": 52.5, "val_loss": 13.944180011749268, "val_acc": 50.0, "val_auroc": 0.59, "time": 296.7}
{"epoch": 14, "training_loss": 55.3798942565918, "training_acc": 52.5, "val_loss": 13.869863748550415, "val_acc": 50.0, "val_auroc": 0.43, "time": 316.36}
{"epoch": 15, "training_loss": 55.61198425292969, "training_acc": 45.0, "val_loss": 13.875610828399658, "val_acc": 50.0, "val_auroc": 0.18, "time": 337.08}
{"epoch": 16, "training_loss": 55.23086929321289, "training_acc": 52.5, "val_loss": 14.049561023712158, "val_acc": 50.0, "val_auroc": 0.44, "time": 354.77}
{"epoch": 17, "training_loss": 55.772589683532715, "training_acc": 52.5, "val_loss": 14.216889142990112, "val_acc": 50.0, "val_auroc": 0.47, "time": 374.04}
{"epoch": 18, "training_loss": 56.05391311645508, "training_acc": 52.5, "val_loss": 14.007749557495117, "val_acc": 50.0, "val_auroc": 0.31, "time": 391.86}
{"epoch": 19, "training_loss": 55.37705135345459, "training_acc": 52.5, "val_loss": 13.863272666931152, "val_acc": 50.0, "val_auroc": 0.32, "time": 412.2}
{"epoch": 20, "training_loss": 55.579864501953125, "training_acc": 50.0, "val_loss": 13.909727334976196, "val_acc": 50.0, "val_auroc": 0.33, "time": 431.97}
{"epoch": 21, "training_loss": 55.8994026184082, "training_acc": 47.5, "val_loss": 13.874541521072388, "val_acc": 50.0, "val_auroc": 0.4, "time": 452.97}
{"epoch": 22, "training_loss": 55.55544471740723, "training_acc": 48.75, "val_loss": 13.88368844985962, "val_acc": 50.0, "val_auroc": 0.26, "time": 473.19}
{"epoch": 23, "training_loss": 55.26032733917236, "training_acc": 52.5, "val_loss": 14.025369882583618, "val_acc": 50.0, "val_auroc": 0.46, "time": 494.11}
{"epoch": 24, "training_loss": 55.54617404937744, "training_acc": 52.5, "val_loss": 14.219777584075928, "val_acc": 50.0, "val_auroc": 0.45, "time": 511.22}
{"epoch": 25, "training_loss": 56.12741470336914, "training_acc": 52.5, "val_loss": 14.23383355140686, "val_acc": 50.0, "val_auroc": 0.49, "time": 531.36}
{"epoch": 26, "training_loss": 56.27566146850586, "training_acc": 52.5, "val_loss": 14.122532606124878, "val_acc": 50.0, "val_auroc": 0.52, "time": 549.72}
{"epoch": 27, "training_loss": 55.83658981323242, "training_acc": 52.5, "val_loss": 14.029898643493652, "val_acc": 50.0, "val_auroc": 0.07, "time": 567.67}
{"epoch": 28, "training_loss": 55.52811622619629, "training_acc": 52.5, "val_loss": 13.886398077011108, "val_acc": 50.0, "val_auroc": 0.19, "time": 589.72}
{"epoch": 29, "training_loss": 55.46049118041992, "training_acc": 50.0, "val_loss": 13.888155221939087, "val_acc": 50.0, "val_auroc": 0.22, "time": 610.4}
{"epoch": 30, "training_loss": 55.81332778930664, "training_acc": 47.5, "val_loss": 13.903183937072754, "val_acc": 50.0, "val_auroc": 0.3, "time": 628.48}
{"epoch": 31, "training_loss": 55.89631271362305, "training_acc": 47.5, "val_loss": 13.869479894638062, "val_acc": 50.0, "val_auroc": 0.65, "time": 647.78}
{"epoch": 32, "training_loss": 55.6254940032959, "training_acc": 47.5, "val_loss": 13.862806558609009, "val_acc": 50.0, "val_auroc": 0.83, "time": 666.64}
{"epoch": 33, "training_loss": 55.440917015075684, "training_acc": 52.5, "val_loss": 13.868389129638672, "val_acc": 50.0, "val_auroc": 0.53, "time": 686.44}
{"epoch": 34, "training_loss": 55.36537551879883, "training_acc": 52.5, "val_loss": 13.897377252578735, "val_acc": 50.0, "val_auroc": 0.6, "time": 704.14}
{"epoch": 35, "training_loss": 55.53700637817383, "training_acc": 52.5, "val_loss": 13.926805257797241, "val_acc": 50.0, "val_auroc": 0.81, "time": 721.81}
{"epoch": 36, "training_loss": 55.373244285583496, "training_acc": 52.5, "val_loss": 13.88616681098938, "val_acc": 50.0, "val_auroc": 0.75, "time": 740.56}
{"epoch": 37, "training_loss": 55.32145309448242, "training_acc": 52.5, "val_loss": 13.862980604171753, "val_acc": 50.0, "val_auroc": 0.8, "time": 760.24}
{"epoch": 38, "training_loss": 55.53934669494629, "training_acc": 47.5, "val_loss": 13.863674402236938, "val_acc": 50.0, "val_auroc": 0.58, "time": 780.94}
{"epoch": 39, "training_loss": 55.49245643615723, "training_acc": 47.5, "val_loss": 13.869341611862183, "val_acc": 50.0, "val_auroc": 0.43, "time": 801.4}
{"epoch": 40, "training_loss": 55.496578216552734, "training_acc": 52.5, "val_loss": 13.87515664100647, "val_acc": 50.0, "val_auroc": 0.63, "time": 820.2}
{"epoch": 41, "training_loss": 55.34530162811279, "training_acc": 52.5, "val_loss": 13.863245248794556, "val_acc": 50.0, "val_auroc": 0.25, "time": 838.78}
{"epoch": 42, "training_loss": 55.53079319000244, "training_acc": 47.5, "val_loss": 13.863213062286377, "val_acc": 50.0, "val_auroc": 0.37, "time": 856.49}
{"epoch": 43, "training_loss": 55.47236251831055, "training_acc": 47.5, "val_loss": 13.873180150985718, "val_acc": 50.0, "val_auroc": 0.66, "time": 875.47}
{"epoch": 44, "training_loss": 55.375518798828125, "training_acc": 52.5, "val_loss": 13.896640539169312, "val_acc": 50.0, "val_auroc": 0.68, "time": 895.94}
{"epoch": 45, "training_loss": 55.36277770996094, "training_acc": 52.5, "val_loss": 13.905467987060547, "val_acc": 50.0, "val_auroc": 0.71, "time": 915.7}
{"epoch": 46, "training_loss": 55.366676330566406, "training_acc": 52.5, "val_loss": 13.903757333755493, "val_acc": 50.0, "val_auroc": 0.59, "time": 936.89}
{"epoch": 47, "training_loss": 55.36350631713867, "training_acc": 52.5, "val_loss": 13.900957107543945, "val_acc": 50.0, "val_auroc": 0.49, "time": 958.94}
{"epoch": 48, "training_loss": 55.44884490966797, "training_acc": 52.5, "val_loss": 13.91545295715332, "val_acc": 50.0, "val_auroc": 0.42, "time": 975.45}
{"epoch": 49, "training_loss": 55.40345859527588, "training_acc": 52.5, "val_loss": 13.971227407455444, "val_acc": 50.0, "val_auroc": 0.44, "time": 994.11}
{"epoch": 50, "training_loss": 55.46962070465088, "training_acc": 52.5, "val_loss": 13.950788974761963, "val_acc": 50.0, "val_auroc": 0.52, "time": 1012.49}
{"epoch": 51, "training_loss": 55.407400131225586, "training_acc": 52.5, "val_loss": 13.89464259147644, "val_acc": 50.0, "val_auroc": 0.47, "time": 1032.83}
