"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.29689693450928, "training_acc": 51.25, "val_loss": 13.782063722610474, "val_acc": 55.0, "val_auroc": 0.455, "time": 22.94}
{"epoch": 1, "training_loss": 56.15492248535156, "training_acc": 43.75, "val_loss": 13.767319917678833, "val_acc": 55.0, "val_auroc": 0.414, "time": 46.07}
{"epoch": 2, "training_loss": 56.3002986907959, "training_acc": 43.75, "val_loss": 13.76315951347351, "val_acc": 55.0, "val_auroc": 0.626, "time": 68.0}
{"epoch": 3, "training_loss": 55.847097396850586, "training_acc": 51.25, "val_loss": 13.85296106338501, "val_acc": 55.0, "val_auroc": 0.545, "time": 93.06}
{"epoch": 4, "training_loss": 55.55001163482666, "training_acc": 48.75, "val_loss": 13.889107704162598, "val_acc": 55.0, "val_auroc": 0.505, "time": 113.08}
{"epoch": 5, "training_loss": 55.481719970703125, "training_acc": 48.75, "val_loss": 13.819319009780884, "val_acc": 55.0, "val_auroc": 0.434, "time": 136.5}
{"epoch": 6, "training_loss": 55.4356050491333, "training_acc": 51.25, "val_loss": 13.783892393112183, "val_acc": 55.0, "val_auroc": 0.444, "time": 159.35}
{"epoch": 7, "training_loss": 55.47157573699951, "training_acc": 51.25, "val_loss": 13.779664039611816, "val_acc": 55.0, "val_auroc": 0.424, "time": 180.71}
{"epoch": 8, "training_loss": 55.48384666442871, "training_acc": 51.25, "val_loss": 13.904174566268921, "val_acc": 55.0, "val_auroc": 0.505, "time": 200.25}
{"epoch": 9, "training_loss": 55.785783767700195, "training_acc": 48.75, "val_loss": 13.96640419960022, "val_acc": 55.0, "val_auroc": 0.545, "time": 219.03}
{"epoch": 10, "training_loss": 55.59827423095703, "training_acc": 47.5, "val_loss": 13.814172744750977, "val_acc": 55.0, "val_auroc": 0.475, "time": 238.03}
{"epoch": 11, "training_loss": 55.3970422744751, "training_acc": 51.25, "val_loss": 13.764253854751587, "val_acc": 55.0, "val_auroc": 0.424, "time": 258.81}
{"epoch": 12, "training_loss": 55.7165412902832, "training_acc": 51.25, "val_loss": 13.762897253036499, "val_acc": 55.0, "val_auroc": 0.485, "time": 279.75}
{"epoch": 13, "training_loss": 55.673644065856934, "training_acc": 51.25, "val_loss": 13.791944980621338, "val_acc": 55.0, "val_auroc": 0.414, "time": 300.24}
{"epoch": 14, "training_loss": 55.427955627441406, "training_acc": 51.25, "val_loss": 13.900905847549438, "val_acc": 55.0, "val_auroc": 0.424, "time": 320.13}
{"epoch": 15, "training_loss": 55.7262020111084, "training_acc": 48.75, "val_loss": 13.977799415588379, "val_acc": 55.0, "val_auroc": 0.444, "time": 340.06}
{"epoch": 16, "training_loss": 55.58172416687012, "training_acc": 48.75, "val_loss": 13.794710636138916, "val_acc": 55.0, "val_auroc": 0.495, "time": 358.86}
{"epoch": 17, "training_loss": 55.51453495025635, "training_acc": 51.25, "val_loss": 13.778222799301147, "val_acc": 55.0, "val_auroc": 0.495, "time": 378.99}
{"epoch": 18, "training_loss": 56.015363693237305, "training_acc": 51.25, "val_loss": 13.77021074295044, "val_acc": 55.0, "val_auroc": 0.535, "time": 398.97}
{"epoch": 19, "training_loss": 55.743133544921875, "training_acc": 51.25, "val_loss": 13.792312145233154, "val_acc": 55.0, "val_auroc": 0.485, "time": 419.62}
{"epoch": 20, "training_loss": 55.42735576629639, "training_acc": 48.75, "val_loss": 13.95160436630249, "val_acc": 55.0, "val_auroc": 0.495, "time": 438.74}
{"epoch": 21, "training_loss": 55.596558570861816, "training_acc": 48.75, "val_loss": 14.017192125320435, "val_acc": 55.0, "val_auroc": 0.556, "time": 458.44}
{"epoch": 22, "training_loss": 55.7062873840332, "training_acc": 48.75, "val_loss": 13.954352140426636, "val_acc": 55.0, "val_auroc": 0.515, "time": 475.47}
{"epoch": 23, "training_loss": 55.552083015441895, "training_acc": 48.75, "val_loss": 13.8430917263031, "val_acc": 55.0, "val_auroc": 0.576, "time": 495.83}
{"epoch": 24, "training_loss": 55.52204895019531, "training_acc": 51.25, "val_loss": 13.791006803512573, "val_acc": 55.0, "val_auroc": 0.414, "time": 514.67}
{"epoch": 25, "training_loss": 55.48177242279053, "training_acc": 51.25, "val_loss": 13.775047063827515, "val_acc": 55.0, "val_auroc": 0.535, "time": 532.1}
{"epoch": 26, "training_loss": 55.47930717468262, "training_acc": 51.25, "val_loss": 13.76311182975769, "val_acc": 55.0, "val_auroc": 0.424, "time": 551.81}
{"epoch": 27, "training_loss": 55.63246154785156, "training_acc": 51.25, "val_loss": 13.763700723648071, "val_acc": 55.0, "val_auroc": 0.434, "time": 569.9}
{"epoch": 28, "training_loss": 55.5577507019043, "training_acc": 51.25, "val_loss": 13.802467584609985, "val_acc": 55.0, "val_auroc": 0.434, "time": 590.61}
{"epoch": 29, "training_loss": 55.71976280212402, "training_acc": 43.75, "val_loss": 13.861767053604126, "val_acc": 55.0, "val_auroc": 0.505, "time": 609.95}
{"epoch": 30, "training_loss": 55.45242404937744, "training_acc": 51.25, "val_loss": 13.816540241241455, "val_acc": 55.0, "val_auroc": 0.545, "time": 626.19}
{"epoch": 31, "training_loss": 55.46658897399902, "training_acc": 51.25, "val_loss": 13.81099820137024, "val_acc": 55.0, "val_auroc": 0.505, "time": 643.6}
