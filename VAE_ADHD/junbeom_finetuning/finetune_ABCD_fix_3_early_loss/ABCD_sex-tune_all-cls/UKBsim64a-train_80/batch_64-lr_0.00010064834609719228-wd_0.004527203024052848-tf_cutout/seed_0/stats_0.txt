"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.7616491317749, "training_acc": 52.5, "val_loss": 13.919808864593506, "val_acc": 50.0, "val_auroc": 0.28, "time": 16.77}
{"epoch": 1, "training_loss": 55.60246467590332, "training_acc": 50.0, "val_loss": 13.917725086212158, "val_acc": 50.0, "val_auroc": 0.56, "time": 32.5}
{"epoch": 2, "training_loss": 55.28890037536621, "training_acc": 52.5, "val_loss": 13.894352912902832, "val_acc": 50.0, "val_auroc": 0.49, "time": 52.21}
{"epoch": 3, "training_loss": 55.016448974609375, "training_acc": 52.5, "val_loss": 13.870651721954346, "val_acc": 50.0, "val_auroc": 0.46, "time": 75.37}
{"epoch": 4, "training_loss": 55.029916763305664, "training_acc": 53.75, "val_loss": 13.877346515655518, "val_acc": 50.0, "val_auroc": 0.48, "time": 92.97}
{"epoch": 5, "training_loss": 54.939144134521484, "training_acc": 60.0, "val_loss": 13.871616125106812, "val_acc": 50.0, "val_auroc": 0.46, "time": 110.99}
{"epoch": 6, "training_loss": 54.855533599853516, "training_acc": 60.0, "val_loss": 13.852845430374146, "val_acc": 50.0, "val_auroc": 0.5, "time": 131.68}
{"epoch": 7, "training_loss": 54.71360397338867, "training_acc": 66.25, "val_loss": 13.84922742843628, "val_acc": 50.0, "val_auroc": 0.48, "time": 151.6}
{"epoch": 8, "training_loss": 54.14568901062012, "training_acc": 63.75, "val_loss": 13.863393068313599, "val_acc": 50.0, "val_auroc": 0.47, "time": 167.69}
{"epoch": 9, "training_loss": 54.18779373168945, "training_acc": 61.25, "val_loss": 13.922842741012573, "val_acc": 50.0, "val_auroc": 0.48, "time": 183.51}
{"epoch": 10, "training_loss": 53.65036582946777, "training_acc": 65.0, "val_loss": 13.919984102249146, "val_acc": 50.0, "val_auroc": 0.45, "time": 201.22}
{"epoch": 11, "training_loss": 53.280975341796875, "training_acc": 62.5, "val_loss": 14.157911539077759, "val_acc": 50.0, "val_auroc": 0.41, "time": 221.41}
{"epoch": 12, "training_loss": 53.9888916015625, "training_acc": 56.25, "val_loss": 13.840769529342651, "val_acc": 50.0, "val_auroc": 0.48, "time": 238.11}
{"epoch": 13, "training_loss": 53.46416473388672, "training_acc": 60.0, "val_loss": 14.060707092285156, "val_acc": 50.0, "val_auroc": 0.46, "time": 253.93}
{"epoch": 14, "training_loss": 52.7417573928833, "training_acc": 58.75, "val_loss": 14.524328708648682, "val_acc": 50.0, "val_auroc": 0.39, "time": 271.56}
{"epoch": 15, "training_loss": 54.614662170410156, "training_acc": 53.75, "val_loss": 13.916065692901611, "val_acc": 50.0, "val_auroc": 0.45, "time": 292.14}
{"epoch": 16, "training_loss": 53.003085136413574, "training_acc": 65.0, "val_loss": 13.969076871871948, "val_acc": 50.0, "val_auroc": 0.45, "time": 311.27}
{"epoch": 17, "training_loss": 52.335859298706055, "training_acc": 63.75, "val_loss": 14.19092059135437, "val_acc": 50.0, "val_auroc": 0.45, "time": 327.86}
{"epoch": 18, "training_loss": 51.99804973602295, "training_acc": 62.5, "val_loss": 13.910993337631226, "val_acc": 50.0, "val_auroc": 0.47, "time": 345.63}
{"epoch": 19, "training_loss": 52.98465156555176, "training_acc": 63.75, "val_loss": 13.952268362045288, "val_acc": 50.0, "val_auroc": 0.46, "time": 364.76}
{"epoch": 20, "training_loss": 51.47972869873047, "training_acc": 71.25, "val_loss": 14.03121829032898, "val_acc": 50.0, "val_auroc": 0.45, "time": 383.27}
{"epoch": 21, "training_loss": 50.62197494506836, "training_acc": 68.75, "val_loss": 14.250863790512085, "val_acc": 50.0, "val_auroc": 0.48, "time": 399.4}
{"epoch": 22, "training_loss": 51.41211700439453, "training_acc": 62.5, "val_loss": 14.10983681678772, "val_acc": 55.0, "val_auroc": 0.46, "time": 415.98}
{"epoch": 23, "training_loss": 49.15810966491699, "training_acc": 75.0, "val_loss": 14.187923669815063, "val_acc": 50.0, "val_auroc": 0.44, "time": 436.6}
{"epoch": 24, "training_loss": 49.49589729309082, "training_acc": 63.75, "val_loss": 14.417753219604492, "val_acc": 35.0, "val_auroc": 0.42, "time": 455.15}
{"epoch": 25, "training_loss": 54.202820777893066, "training_acc": 50.0, "val_loss": 13.941583633422852, "val_acc": 50.0, "val_auroc": 0.49, "time": 471.32}
{"epoch": 26, "training_loss": 50.082210540771484, "training_acc": 71.25, "val_loss": 14.634795188903809, "val_acc": 50.0, "val_auroc": 0.44, "time": 488.64}
{"epoch": 27, "training_loss": 52.185537338256836, "training_acc": 60.0, "val_loss": 14.033116102218628, "val_acc": 55.0, "val_auroc": 0.48, "time": 507.32}
{"epoch": 28, "training_loss": 48.325904846191406, "training_acc": 77.5, "val_loss": 14.350162744522095, "val_acc": 45.0, "val_auroc": 0.49, "time": 525.24}
{"epoch": 29, "training_loss": 50.07529067993164, "training_acc": 65.0, "val_loss": 14.615910053253174, "val_acc": 50.0, "val_auroc": 0.46, "time": 542.09}
{"epoch": 30, "training_loss": 50.81028175354004, "training_acc": 61.25, "val_loss": 14.19476866722107, "val_acc": 55.0, "val_auroc": 0.47, "time": 560.33}
{"epoch": 31, "training_loss": 47.28072929382324, "training_acc": 75.0, "val_loss": 14.571199417114258, "val_acc": 55.0, "val_auroc": 0.49, "time": 579.46}
