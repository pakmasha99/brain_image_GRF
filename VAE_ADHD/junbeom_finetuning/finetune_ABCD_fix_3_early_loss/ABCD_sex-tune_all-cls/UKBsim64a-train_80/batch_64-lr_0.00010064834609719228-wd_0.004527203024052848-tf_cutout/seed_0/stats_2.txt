"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.75539302825928, "training_acc": 42.5, "val_loss": 13.92881989479065, "val_acc": 50.0, "val_auroc": 0.29, "time": 18.96}
{"epoch": 1, "training_loss": 55.63458061218262, "training_acc": 46.25, "val_loss": 13.822816610336304, "val_acc": 50.0, "val_auroc": 0.57, "time": 37.16}
{"epoch": 2, "training_loss": 55.14228439331055, "training_acc": 58.75, "val_loss": 13.681974411010742, "val_acc": 50.0, "val_auroc": 0.84, "time": 61.54}
{"epoch": 3, "training_loss": 54.888254165649414, "training_acc": 56.25, "val_loss": 13.926483392715454, "val_acc": 50.0, "val_auroc": 0.78, "time": 84.54}
{"epoch": 4, "training_loss": 54.95389270782471, "training_acc": 52.5, "val_loss": 13.737465143203735, "val_acc": 50.0, "val_auroc": 0.87, "time": 103.78}
{"epoch": 5, "training_loss": 55.146400451660156, "training_acc": 57.5, "val_loss": 13.685334920883179, "val_acc": 50.0, "val_auroc": 0.82, "time": 123.04}
{"epoch": 6, "training_loss": 54.98158073425293, "training_acc": 56.25, "val_loss": 13.965297937393188, "val_acc": 50.0, "val_auroc": 0.8, "time": 143.36}
{"epoch": 7, "training_loss": 55.21076011657715, "training_acc": 52.5, "val_loss": 14.003679752349854, "val_acc": 50.0, "val_auroc": 0.53, "time": 162.59}
{"epoch": 8, "training_loss": 55.329336166381836, "training_acc": 52.5, "val_loss": 13.884693384170532, "val_acc": 50.0, "val_auroc": 0.75, "time": 179.78}
{"epoch": 9, "training_loss": 55.18872261047363, "training_acc": 52.5, "val_loss": 13.805474042892456, "val_acc": 50.0, "val_auroc": 0.77, "time": 197.76}
{"epoch": 10, "training_loss": 55.14152717590332, "training_acc": 52.5, "val_loss": 13.837963342666626, "val_acc": 50.0, "val_auroc": 0.6, "time": 218.19}
{"epoch": 11, "training_loss": 55.083635330200195, "training_acc": 52.5, "val_loss": 13.880032300949097, "val_acc": 50.0, "val_auroc": 0.68, "time": 237.84}
{"epoch": 12, "training_loss": 55.08125305175781, "training_acc": 52.5, "val_loss": 13.90712857246399, "val_acc": 50.0, "val_auroc": 0.74, "time": 258.94}
{"epoch": 13, "training_loss": 55.01600170135498, "training_acc": 52.5, "val_loss": 13.75221848487854, "val_acc": 50.0, "val_auroc": 0.83, "time": 276.15}
{"epoch": 14, "training_loss": 54.762447357177734, "training_acc": 53.75, "val_loss": 13.646291494369507, "val_acc": 50.0, "val_auroc": 0.88, "time": 296.83}
{"epoch": 15, "training_loss": 54.565656661987305, "training_acc": 61.25, "val_loss": 13.988351821899414, "val_acc": 50.0, "val_auroc": 0.82, "time": 316.04}
{"epoch": 16, "training_loss": 54.91674613952637, "training_acc": 52.5, "val_loss": 14.150546789169312, "val_acc": 50.0, "val_auroc": 0.43, "time": 335.13}
{"epoch": 17, "training_loss": 55.50206279754639, "training_acc": 52.5, "val_loss": 14.058411121368408, "val_acc": 50.0, "val_auroc": 0.63, "time": 352.44}
{"epoch": 18, "training_loss": 55.03981971740723, "training_acc": 52.5, "val_loss": 13.831367492675781, "val_acc": 50.0, "val_auroc": 0.66, "time": 372.6}
{"epoch": 19, "training_loss": 54.794403076171875, "training_acc": 56.25, "val_loss": 13.788677453994751, "val_acc": 50.0, "val_auroc": 0.78, "time": 390.96}
{"epoch": 20, "training_loss": 55.27192974090576, "training_acc": 47.5, "val_loss": 13.78031611442566, "val_acc": 50.0, "val_auroc": 0.86, "time": 411.47}
{"epoch": 21, "training_loss": 55.20707321166992, "training_acc": 51.25, "val_loss": 13.79352331161499, "val_acc": 50.0, "val_auroc": 0.87, "time": 427.63}
{"epoch": 22, "training_loss": 54.74968719482422, "training_acc": 55.0, "val_loss": 13.859553337097168, "val_acc": 50.0, "val_auroc": 0.9, "time": 447.55}
{"epoch": 23, "training_loss": 54.68344593048096, "training_acc": 52.5, "val_loss": 13.738583326339722, "val_acc": 50.0, "val_auroc": 0.89, "time": 465.86}
{"epoch": 24, "training_loss": 54.56359386444092, "training_acc": 55.0, "val_loss": 13.83865475654602, "val_acc": 50.0, "val_auroc": 0.89, "time": 485.15}
{"epoch": 25, "training_loss": 54.52338218688965, "training_acc": 52.5, "val_loss": 13.821030855178833, "val_acc": 50.0, "val_auroc": 0.84, "time": 503.26}
{"epoch": 26, "training_loss": 54.559051513671875, "training_acc": 53.75, "val_loss": 13.797321319580078, "val_acc": 50.0, "val_auroc": 0.79, "time": 522.63}
{"epoch": 27, "training_loss": 54.09157657623291, "training_acc": 53.75, "val_loss": 13.454121351242065, "val_acc": 50.0, "val_auroc": 0.83, "time": 541.42}
{"epoch": 28, "training_loss": 53.48738193511963, "training_acc": 62.5, "val_loss": 13.629240989685059, "val_acc": 50.0, "val_auroc": 0.83, "time": 563.91}
{"epoch": 29, "training_loss": 55.51828956604004, "training_acc": 47.5, "val_loss": 13.895313739776611, "val_acc": 50.0, "val_auroc": 0.39, "time": 581.03}
{"epoch": 30, "training_loss": 55.791582107543945, "training_acc": 47.5, "val_loss": 13.802099227905273, "val_acc": 50.0, "val_auroc": 0.73, "time": 600.58}
{"epoch": 31, "training_loss": 55.20759391784668, "training_acc": 67.5, "val_loss": 13.705261945724487, "val_acc": 50.0, "val_auroc": 0.86, "time": 619.36}
{"epoch": 32, "training_loss": 54.93057632446289, "training_acc": 52.5, "val_loss": 13.633358478546143, "val_acc": 50.0, "val_auroc": 0.84, "time": 639.69}
{"epoch": 33, "training_loss": 55.08987998962402, "training_acc": 58.75, "val_loss": 13.57448697090149, "val_acc": 50.0, "val_auroc": 0.87, "time": 657.38}
{"epoch": 34, "training_loss": 54.57660675048828, "training_acc": 57.5, "val_loss": 13.81837248802185, "val_acc": 50.0, "val_auroc": 0.9, "time": 678.22}
{"epoch": 35, "training_loss": 55.113765716552734, "training_acc": 52.5, "val_loss": 13.968313932418823, "val_acc": 50.0, "val_auroc": 0.72, "time": 696.63}
{"epoch": 36, "training_loss": 54.94533157348633, "training_acc": 52.5, "val_loss": 13.683358430862427, "val_acc": 50.0, "val_auroc": 0.81, "time": 718.9}
{"epoch": 37, "training_loss": 54.47029495239258, "training_acc": 66.25, "val_loss": 13.620781898498535, "val_acc": 50.0, "val_auroc": 0.79, "time": 736.48}
{"epoch": 38, "training_loss": 54.75892734527588, "training_acc": 48.75, "val_loss": 13.549916744232178, "val_acc": 50.0, "val_auroc": 0.82, "time": 755.98}
{"epoch": 39, "training_loss": 54.13081169128418, "training_acc": 73.75, "val_loss": 13.916391134262085, "val_acc": 50.0, "val_auroc": 0.65, "time": 774.36}
{"epoch": 40, "training_loss": 54.59866142272949, "training_acc": 52.5, "val_loss": 13.751089572906494, "val_acc": 50.0, "val_auroc": 0.7, "time": 795.03}
{"epoch": 41, "training_loss": 54.07545852661133, "training_acc": 61.25, "val_loss": 13.592417240142822, "val_acc": 50.0, "val_auroc": 0.76, "time": 812.09}
{"epoch": 42, "training_loss": 54.944098472595215, "training_acc": 50.0, "val_loss": 13.545241355895996, "val_acc": 50.0, "val_auroc": 0.75, "time": 834.22}
{"epoch": 43, "training_loss": 54.181034088134766, "training_acc": 53.75, "val_loss": 13.747862577438354, "val_acc": 50.0, "val_auroc": 0.73, "time": 853.03}
{"epoch": 44, "training_loss": 54.13825035095215, "training_acc": 55.0, "val_loss": 13.70128870010376, "val_acc": 50.0, "val_auroc": 0.7, "time": 873.15}
{"epoch": 45, "training_loss": 52.987135887145996, "training_acc": 60.0, "val_loss": 13.442200422286987, "val_acc": 50.0, "val_auroc": 0.74, "time": 890.62}
{"epoch": 46, "training_loss": 53.87131881713867, "training_acc": 57.5, "val_loss": 13.34588885307312, "val_acc": 50.0, "val_auroc": 0.81, "time": 909.35}
{"epoch": 47, "training_loss": 52.53307914733887, "training_acc": 70.0, "val_loss": 13.494194746017456, "val_acc": 50.0, "val_auroc": 0.81, "time": 929.15}
{"epoch": 48, "training_loss": 52.51982879638672, "training_acc": 65.0, "val_loss": 13.741708993911743, "val_acc": 50.0, "val_auroc": 0.7, "time": 947.58}
{"epoch": 49, "training_loss": 52.26707363128662, "training_acc": 60.0, "val_loss": 12.91352391242981, "val_acc": 50.0, "val_auroc": 0.74, "time": 965.86}
{"epoch": 50, "training_loss": 51.43730926513672, "training_acc": 65.0, "val_loss": 12.879351377487183, "val_acc": 50.0, "val_auroc": 0.8, "time": 984.29}
{"epoch": 51, "training_loss": 51.135223388671875, "training_acc": 70.0, "val_loss": 13.82303237915039, "val_acc": 50.0, "val_auroc": 0.69, "time": 1003.05}
{"epoch": 52, "training_loss": 51.65702247619629, "training_acc": 63.75, "val_loss": 13.141852617263794, "val_acc": 50.0, "val_auroc": 0.73, "time": 1022.45}
{"epoch": 53, "training_loss": 48.58634662628174, "training_acc": 75.0, "val_loss": 12.753973007202148, "val_acc": 55.0, "val_auroc": 0.73, "time": 1040.47}
{"epoch": 54, "training_loss": 50.12506103515625, "training_acc": 67.5, "val_loss": 14.612196683883667, "val_acc": 50.0, "val_auroc": 0.64, "time": 1058.06}
{"epoch": 55, "training_loss": 54.60222244262695, "training_acc": 55.0, "val_loss": 14.522802829742432, "val_acc": 50.0, "val_auroc": 0.53, "time": 1078.44}
{"epoch": 56, "training_loss": 55.81494903564453, "training_acc": 52.5, "val_loss": 14.061791896820068, "val_acc": 50.0, "val_auroc": 0.47, "time": 1096.5}
{"epoch": 57, "training_loss": 54.367302894592285, "training_acc": 52.5, "val_loss": 13.805903196334839, "val_acc": 50.0, "val_auroc": 0.6, "time": 1115.26}
{"epoch": 58, "training_loss": 54.07761001586914, "training_acc": 62.5, "val_loss": 13.741192817687988, "val_acc": 50.0, "val_auroc": 0.61, "time": 1133.92}
{"epoch": 59, "training_loss": 53.66447925567627, "training_acc": 66.25, "val_loss": 13.627973794937134, "val_acc": 50.0, "val_auroc": 0.66, "time": 1151.84}
{"epoch": 60, "training_loss": 52.833656311035156, "training_acc": 60.0, "val_loss": 13.532490730285645, "val_acc": 50.0, "val_auroc": 0.66, "time": 1172.62}
{"epoch": 61, "training_loss": 52.45399284362793, "training_acc": 63.75, "val_loss": 13.55085015296936, "val_acc": 50.0, "val_auroc": 0.65, "time": 1192.64}
{"epoch": 62, "training_loss": 50.86870288848877, "training_acc": 71.25, "val_loss": 13.945982456207275, "val_acc": 50.0, "val_auroc": 0.65, "time": 1210.69}
{"epoch": 63, "training_loss": 51.54410457611084, "training_acc": 62.5, "val_loss": 13.752529621124268, "val_acc": 50.0, "val_auroc": 0.57, "time": 1228.97}
{"epoch": 64, "training_loss": 50.95384407043457, "training_acc": 65.0, "val_loss": 14.525623321533203, "val_acc": 50.0, "val_auroc": 0.69, "time": 1246.29}
{"epoch": 65, "training_loss": 53.10444259643555, "training_acc": 58.75, "val_loss": 13.71656060218811, "val_acc": 50.0, "val_auroc": 0.56, "time": 1264.95}
{"epoch": 66, "training_loss": 50.08054542541504, "training_acc": 73.75, "val_loss": 13.913315534591675, "val_acc": 50.0, "val_auroc": 0.52, "time": 1283.12}
{"epoch": 67, "training_loss": 51.750972747802734, "training_acc": 65.0, "val_loss": 13.961907625198364, "val_acc": 50.0, "val_auroc": 0.54, "time": 1301.21}
{"epoch": 68, "training_loss": 49.018402099609375, "training_acc": 76.25, "val_loss": 14.307020902633667, "val_acc": 50.0, "val_auroc": 0.6, "time": 1321.4}
{"epoch": 69, "training_loss": 48.674232482910156, "training_acc": 73.75, "val_loss": 13.81129264831543, "val_acc": 55.0, "val_auroc": 0.58, "time": 1341.46}
{"epoch": 70, "training_loss": 47.28919219970703, "training_acc": 75.0, "val_loss": 13.913408517837524, "val_acc": 55.0, "val_auroc": 0.59, "time": 1359.97}
{"epoch": 71, "training_loss": 45.86730766296387, "training_acc": 81.25, "val_loss": 14.379738569259644, "val_acc": 50.0, "val_auroc": 0.61, "time": 1377.47}
{"epoch": 72, "training_loss": 44.304447174072266, "training_acc": 82.5, "val_loss": 14.285327196121216, "val_acc": 55.0, "val_auroc": 0.51, "time": 1395.13}
