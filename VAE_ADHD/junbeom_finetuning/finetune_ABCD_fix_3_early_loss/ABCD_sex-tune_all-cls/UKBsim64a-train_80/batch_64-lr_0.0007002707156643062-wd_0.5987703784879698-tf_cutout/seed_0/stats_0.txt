"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 71.54792022705078, "training_acc": 46.25, "val_loss": 16.66664958000183, "val_acc": 55.0, "val_auroc": 0.5, "time": 18.64}
{"epoch": 1, "training_loss": 75.18812370300293, "training_acc": 55.0, "val_loss": 13.962122201919556, "val_acc": 50.0, "val_auroc": 0.53, "time": 41.31}
{"epoch": 2, "training_loss": 58.1087646484375, "training_acc": 52.5, "val_loss": 14.063853025436401, "val_acc": 50.0, "val_auroc": 0.54, "time": 66.49}
{"epoch": 3, "training_loss": 55.85555839538574, "training_acc": 52.5, "val_loss": 14.039257764816284, "val_acc": 50.0, "val_auroc": 0.52, "time": 88.25}
{"epoch": 4, "training_loss": 56.52643394470215, "training_acc": 47.5, "val_loss": 13.973506689071655, "val_acc": 50.0, "val_auroc": 0.5, "time": 108.53}
{"epoch": 5, "training_loss": 55.61026191711426, "training_acc": 52.5, "val_loss": 18.449426889419556, "val_acc": 50.0, "val_auroc": 0.51, "time": 129.93}
{"epoch": 6, "training_loss": 72.35287380218506, "training_acc": 47.5, "val_loss": 13.92605185508728, "val_acc": 50.0, "val_auroc": 0.51, "time": 150.42}
{"epoch": 7, "training_loss": 55.54777526855469, "training_acc": 52.5, "val_loss": 13.862415552139282, "val_acc": 50.0, "val_auroc": 0.51, "time": 172.13}
{"epoch": 8, "training_loss": 55.41468048095703, "training_acc": 52.5, "val_loss": 13.877815008163452, "val_acc": 50.0, "val_auroc": 0.53, "time": 188.91}
{"epoch": 9, "training_loss": 55.64841842651367, "training_acc": 47.5, "val_loss": 13.927476406097412, "val_acc": 50.0, "val_auroc": 0.53, "time": 209.28}
{"epoch": 10, "training_loss": 55.367557525634766, "training_acc": 52.5, "val_loss": 14.009332656860352, "val_acc": 50.0, "val_auroc": 0.5, "time": 231.79}
{"epoch": 11, "training_loss": 55.763166427612305, "training_acc": 52.5, "val_loss": 14.123033285140991, "val_acc": 50.0, "val_auroc": 0.53, "time": 254.13}
{"epoch": 12, "training_loss": 55.89384841918945, "training_acc": 52.5, "val_loss": 14.198604822158813, "val_acc": 50.0, "val_auroc": 0.51, "time": 272.38}
{"epoch": 13, "training_loss": 56.3512659072876, "training_acc": 52.5, "val_loss": 14.158128499984741, "val_acc": 50.0, "val_auroc": 0.49, "time": 290.75}
{"epoch": 14, "training_loss": 56.161502838134766, "training_acc": 52.5, "val_loss": 14.45347547531128, "val_acc": 50.0, "val_auroc": 0.49, "time": 311.13}
{"epoch": 15, "training_loss": 56.7708797454834, "training_acc": 52.5, "val_loss": 14.472274780273438, "val_acc": 50.0, "val_auroc": 0.54, "time": 331.99}
{"epoch": 16, "training_loss": 56.885934829711914, "training_acc": 52.5, "val_loss": 14.035929441452026, "val_acc": 50.0, "val_auroc": 0.46, "time": 350.84}
{"epoch": 17, "training_loss": 55.477487564086914, "training_acc": 52.5, "val_loss": 13.86997103691101, "val_acc": 50.0, "val_auroc": 0.42, "time": 369.73}
{"epoch": 18, "training_loss": 55.45517921447754, "training_acc": 50.0, "val_loss": 13.873851299285889, "val_acc": 50.0, "val_auroc": 0.47, "time": 389.73}
{"epoch": 19, "training_loss": 55.82946014404297, "training_acc": 40.0, "val_loss": 13.876874446868896, "val_acc": 50.0, "val_auroc": 0.41, "time": 411.86}
{"epoch": 20, "training_loss": 55.58512496948242, "training_acc": 47.5, "val_loss": 13.924355506896973, "val_acc": 50.0, "val_auroc": 0.44, "time": 433.51}
{"epoch": 21, "training_loss": 56.02614784240723, "training_acc": 47.5, "val_loss": 13.875091075897217, "val_acc": 50.0, "val_auroc": 0.47, "time": 451.31}
{"epoch": 22, "training_loss": 55.37895107269287, "training_acc": 52.5, "val_loss": 13.968557119369507, "val_acc": 50.0, "val_auroc": 0.43, "time": 471.75}
{"epoch": 23, "training_loss": 55.560354232788086, "training_acc": 52.5, "val_loss": 14.202669858932495, "val_acc": 50.0, "val_auroc": 0.48, "time": 492.65}
{"epoch": 24, "training_loss": 56.04556751251221, "training_acc": 52.5, "val_loss": 14.04128909111023, "val_acc": 50.0, "val_auroc": 0.4, "time": 509.53}
{"epoch": 25, "training_loss": 55.51445484161377, "training_acc": 52.5, "val_loss": 13.870071172714233, "val_acc": 50.0, "val_auroc": 0.36, "time": 529.13}
{"epoch": 26, "training_loss": 55.48715114593506, "training_acc": 50.0, "val_loss": 13.878684043884277, "val_acc": 50.0, "val_auroc": 0.39, "time": 549.11}
