"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.90582084655762, "training_acc": 53.75, "val_loss": 103.58206748962402, "val_acc": 45.0, "val_auroc": 0.566, "time": 20.02}
{"epoch": 1, "training_loss": 311.4652462005615, "training_acc": 56.25, "val_loss": 22.882061004638672, "val_acc": 55.0, "val_auroc": 0.455, "time": 42.81}
{"epoch": 2, "training_loss": 161.18222045898438, "training_acc": 43.75, "val_loss": 17.335904836654663, "val_acc": 45.0, "val_auroc": 0.556, "time": 67.2}
{"epoch": 3, "training_loss": 66.15695381164551, "training_acc": 48.75, "val_loss": 13.77149224281311, "val_acc": 55.0, "val_auroc": 0.495, "time": 92.76}
{"epoch": 4, "training_loss": 55.45918655395508, "training_acc": 51.25, "val_loss": 13.993643522262573, "val_acc": 55.0, "val_auroc": 0.455, "time": 111.33}
{"epoch": 5, "training_loss": 56.848358154296875, "training_acc": 51.25, "val_loss": 14.37968134880066, "val_acc": 55.0, "val_auroc": 0.475, "time": 132.74}
{"epoch": 6, "training_loss": 56.492902755737305, "training_acc": 48.75, "val_loss": 14.084389209747314, "val_acc": 55.0, "val_auroc": 0.444, "time": 152.6}
{"epoch": 7, "training_loss": 57.33539009094238, "training_acc": 51.25, "val_loss": 14.005061388015747, "val_acc": 55.0, "val_auroc": 0.444, "time": 173.5}
{"epoch": 8, "training_loss": 55.50342845916748, "training_acc": 48.75, "val_loss": 14.749128818511963, "val_acc": 55.0, "val_auroc": 0.424, "time": 190.99}
{"epoch": 9, "training_loss": 57.57792663574219, "training_acc": 48.75, "val_loss": 13.902382850646973, "val_acc": 55.0, "val_auroc": 0.455, "time": 211.35}
{"epoch": 10, "training_loss": 55.62791442871094, "training_acc": 47.5, "val_loss": 13.92956256866455, "val_acc": 55.0, "val_auroc": 0.444, "time": 231.94}
{"epoch": 11, "training_loss": 56.915968894958496, "training_acc": 51.25, "val_loss": 13.806765079498291, "val_acc": 55.0, "val_auroc": 0.444, "time": 250.61}
{"epoch": 12, "training_loss": 55.92773914337158, "training_acc": 51.25, "val_loss": 13.801006078720093, "val_acc": 55.0, "val_auroc": 0.455, "time": 268.04}
{"epoch": 13, "training_loss": 55.52647399902344, "training_acc": 48.75, "val_loss": 13.964890241622925, "val_acc": 55.0, "val_auroc": 0.414, "time": 288.68}
{"epoch": 14, "training_loss": 55.643959045410156, "training_acc": 48.75, "val_loss": 14.00397539138794, "val_acc": 55.0, "val_auroc": 0.495, "time": 310.24}
{"epoch": 15, "training_loss": 55.78160572052002, "training_acc": 48.75, "val_loss": 13.934965133666992, "val_acc": 55.0, "val_auroc": 0.515, "time": 328.33}
{"epoch": 16, "training_loss": 55.31797122955322, "training_acc": 48.75, "val_loss": 13.762578964233398, "val_acc": 55.0, "val_auroc": 0.525, "time": 347.78}
{"epoch": 17, "training_loss": 55.82447052001953, "training_acc": 51.25, "val_loss": 13.887728452682495, "val_acc": 55.0, "val_auroc": 0.455, "time": 368.64}
{"epoch": 18, "training_loss": 56.787235260009766, "training_acc": 51.25, "val_loss": 13.791154623031616, "val_acc": 55.0, "val_auroc": 0.434, "time": 389.69}
{"epoch": 19, "training_loss": 55.83481216430664, "training_acc": 51.25, "val_loss": 13.819620609283447, "val_acc": 55.0, "val_auroc": 0.505, "time": 407.06}
{"epoch": 20, "training_loss": 55.42379188537598, "training_acc": 51.25, "val_loss": 14.064968824386597, "val_acc": 55.0, "val_auroc": 0.485, "time": 425.09}
{"epoch": 21, "training_loss": 55.83358192443848, "training_acc": 48.75, "val_loss": 14.145568609237671, "val_acc": 55.0, "val_auroc": 0.495, "time": 444.6}
{"epoch": 22, "training_loss": 55.98653697967529, "training_acc": 48.75, "val_loss": 14.011411666870117, "val_acc": 55.0, "val_auroc": 0.545, "time": 467.21}
{"epoch": 23, "training_loss": 55.62726879119873, "training_acc": 48.75, "val_loss": 13.839744329452515, "val_acc": 55.0, "val_auroc": 0.424, "time": 485.37}
{"epoch": 24, "training_loss": 55.55000305175781, "training_acc": 51.25, "val_loss": 13.7740159034729, "val_acc": 55.0, "val_auroc": 0.434, "time": 502.53}
{"epoch": 25, "training_loss": 55.523780822753906, "training_acc": 51.25, "val_loss": 13.767786026000977, "val_acc": 55.0, "val_auroc": 0.444, "time": 521.79}
{"epoch": 26, "training_loss": 55.549221992492676, "training_acc": 51.25, "val_loss": 13.765956163406372, "val_acc": 55.0, "val_auroc": 0.444, "time": 544.38}
{"epoch": 27, "training_loss": 55.64118957519531, "training_acc": 51.25, "val_loss": 13.76821517944336, "val_acc": 55.0, "val_auroc": 0.465, "time": 564.62}
{"epoch": 28, "training_loss": 55.495747566223145, "training_acc": 51.25, "val_loss": 13.81306767463684, "val_acc": 55.0, "val_auroc": 0.495, "time": 582.81}
{"epoch": 29, "training_loss": 55.64929962158203, "training_acc": 43.75, "val_loss": 13.869541883468628, "val_acc": 55.0, "val_auroc": 0.515, "time": 603.25}
{"epoch": 30, "training_loss": 55.446495056152344, "training_acc": 48.75, "val_loss": 13.83358359336853, "val_acc": 55.0, "val_auroc": 0.505, "time": 623.97}
{"epoch": 31, "training_loss": 55.450571060180664, "training_acc": 51.25, "val_loss": 13.82140040397644, "val_acc": 55.0, "val_auroc": 0.475, "time": 643.53}
{"epoch": 32, "training_loss": 55.42202377319336, "training_acc": 51.25, "val_loss": 13.823145627975464, "val_acc": 55.0, "val_auroc": 0.495, "time": 660.15}
{"epoch": 33, "training_loss": 55.41257858276367, "training_acc": 51.25, "val_loss": 13.812973499298096, "val_acc": 55.0, "val_auroc": 0.505, "time": 681.38}
{"epoch": 34, "training_loss": 55.41565704345703, "training_acc": 51.25, "val_loss": 13.803256750106812, "val_acc": 55.0, "val_auroc": 0.515, "time": 702.52}
{"epoch": 35, "training_loss": 55.4167594909668, "training_acc": 51.25, "val_loss": 13.79257082939148, "val_acc": 55.0, "val_auroc": 0.525, "time": 721.85}
