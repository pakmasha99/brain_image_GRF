"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.65534782409668, "training_acc": 52.5, "val_loss": 13.863528966903687, "val_acc": 50.0, "val_auroc": 0.62, "time": 20.12}
{"epoch": 1, "training_loss": 55.408172607421875, "training_acc": 46.25, "val_loss": 13.757942914962769, "val_acc": 50.0, "val_auroc": 0.82, "time": 45.14}
{"epoch": 2, "training_loss": 55.2093391418457, "training_acc": 52.5, "val_loss": 13.738731145858765, "val_acc": 50.0, "val_auroc": 0.81, "time": 70.02}
{"epoch": 3, "training_loss": 55.08312702178955, "training_acc": 52.5, "val_loss": 13.78965973854065, "val_acc": 50.0, "val_auroc": 0.83, "time": 90.03}
{"epoch": 4, "training_loss": 55.12319850921631, "training_acc": 52.5, "val_loss": 13.774608373641968, "val_acc": 50.0, "val_auroc": 0.88, "time": 107.79}
{"epoch": 5, "training_loss": 55.153926849365234, "training_acc": 51.25, "val_loss": 13.752151727676392, "val_acc": 50.0, "val_auroc": 0.84, "time": 130.2}
{"epoch": 6, "training_loss": 55.08432865142822, "training_acc": 52.5, "val_loss": 13.772484064102173, "val_acc": 50.0, "val_auroc": 0.89, "time": 151.97}
{"epoch": 7, "training_loss": 55.16043663024902, "training_acc": 52.5, "val_loss": 13.775986433029175, "val_acc": 50.0, "val_auroc": 0.85, "time": 173.08}
{"epoch": 8, "training_loss": 55.05620002746582, "training_acc": 52.5, "val_loss": 13.745216131210327, "val_acc": 50.0, "val_auroc": 0.85, "time": 194.54}
{"epoch": 9, "training_loss": 54.95303821563721, "training_acc": 52.5, "val_loss": 13.795384168624878, "val_acc": 50.0, "val_auroc": 0.8, "time": 214.05}
{"epoch": 10, "training_loss": 55.17927551269531, "training_acc": 66.25, "val_loss": 13.764746189117432, "val_acc": 50.0, "val_auroc": 0.86, "time": 235.25}
{"epoch": 11, "training_loss": 55.033912658691406, "training_acc": 53.75, "val_loss": 13.714593648910522, "val_acc": 50.0, "val_auroc": 0.82, "time": 255.33}
{"epoch": 12, "training_loss": 54.963680267333984, "training_acc": 52.5, "val_loss": 13.66284728050232, "val_acc": 50.0, "val_auroc": 0.79, "time": 273.76}
{"epoch": 13, "training_loss": 54.93265151977539, "training_acc": 52.5, "val_loss": 13.593100309371948, "val_acc": 50.0, "val_auroc": 0.82, "time": 294.96}
{"epoch": 14, "training_loss": 54.99231243133545, "training_acc": 52.5, "val_loss": 13.698568344116211, "val_acc": 50.0, "val_auroc": 0.83, "time": 315.79}
{"epoch": 15, "training_loss": 55.207942962646484, "training_acc": 52.5, "val_loss": 13.68389368057251, "val_acc": 50.0, "val_auroc": 0.81, "time": 333.31}
{"epoch": 16, "training_loss": 55.35636043548584, "training_acc": 52.5, "val_loss": 13.62547755241394, "val_acc": 50.0, "val_auroc": 0.79, "time": 352.41}
{"epoch": 17, "training_loss": 54.72598361968994, "training_acc": 52.5, "val_loss": 13.647124767303467, "val_acc": 50.0, "val_auroc": 0.8, "time": 373.34}
{"epoch": 18, "training_loss": 54.433133125305176, "training_acc": 55.0, "val_loss": 13.759897947311401, "val_acc": 50.0, "val_auroc": 0.77, "time": 394.02}
{"epoch": 19, "training_loss": 55.17842102050781, "training_acc": 55.0, "val_loss": 13.716679811477661, "val_acc": 50.0, "val_auroc": 0.77, "time": 414.04}
{"epoch": 20, "training_loss": 54.66960430145264, "training_acc": 62.5, "val_loss": 13.493298292160034, "val_acc": 50.0, "val_auroc": 0.84, "time": 432.16}
{"epoch": 21, "training_loss": 54.159976959228516, "training_acc": 71.25, "val_loss": 13.561543226242065, "val_acc": 50.0, "val_auroc": 0.84, "time": 453.13}
{"epoch": 22, "training_loss": 54.69655895233154, "training_acc": 52.5, "val_loss": 13.66243839263916, "val_acc": 50.0, "val_auroc": 0.84, "time": 473.87}
{"epoch": 23, "training_loss": 54.89691352844238, "training_acc": 53.75, "val_loss": 13.436352014541626, "val_acc": 50.0, "val_auroc": 0.84, "time": 494.85}
{"epoch": 24, "training_loss": 54.201090812683105, "training_acc": 53.75, "val_loss": 13.289881944656372, "val_acc": 50.0, "val_auroc": 0.82, "time": 512.62}
{"epoch": 25, "training_loss": 53.55304718017578, "training_acc": 58.75, "val_loss": 13.148170709609985, "val_acc": 50.0, "val_auroc": 0.83, "time": 532.71}
{"epoch": 26, "training_loss": 53.46015167236328, "training_acc": 58.75, "val_loss": 12.982429265975952, "val_acc": 50.0, "val_auroc": 0.85, "time": 553.5}
{"epoch": 27, "training_loss": 53.02099132537842, "training_acc": 65.0, "val_loss": 13.099044561386108, "val_acc": 50.0, "val_auroc": 0.83, "time": 570.52}
{"epoch": 28, "training_loss": 53.46866416931152, "training_acc": 56.25, "val_loss": 14.062376022338867, "val_acc": 50.0, "val_auroc": 0.36, "time": 588.58}
{"epoch": 29, "training_loss": 56.093461990356445, "training_acc": 47.5, "val_loss": 13.856033086776733, "val_acc": 50.0, "val_auroc": 0.48, "time": 608.83}
{"epoch": 30, "training_loss": 55.40262317657471, "training_acc": 52.5, "val_loss": 13.901232481002808, "val_acc": 50.0, "val_auroc": 0.8, "time": 626.74}
{"epoch": 31, "training_loss": 55.37955856323242, "training_acc": 52.5, "val_loss": 13.969666957855225, "val_acc": 50.0, "val_auroc": 0.67, "time": 643.9}
{"epoch": 32, "training_loss": 55.53484630584717, "training_acc": 52.5, "val_loss": 13.88584017753601, "val_acc": 50.0, "val_auroc": 0.65, "time": 661.64}
{"epoch": 33, "training_loss": 55.37045478820801, "training_acc": 52.5, "val_loss": 13.85248064994812, "val_acc": 50.0, "val_auroc": 0.62, "time": 680.56}
{"epoch": 34, "training_loss": 55.38841247558594, "training_acc": 52.5, "val_loss": 13.872455358505249, "val_acc": 50.0, "val_auroc": 0.61, "time": 699.23}
{"epoch": 35, "training_loss": 55.558095932006836, "training_acc": 52.5, "val_loss": 13.869631290435791, "val_acc": 50.0, "val_auroc": 0.61, "time": 716.4}
{"epoch": 36, "training_loss": 55.29059600830078, "training_acc": 52.5, "val_loss": 13.861931562423706, "val_acc": 50.0, "val_auroc": 0.63, "time": 734.63}
{"epoch": 37, "training_loss": 55.54048824310303, "training_acc": 47.5, "val_loss": 13.903084993362427, "val_acc": 50.0, "val_auroc": 0.61, "time": 754.54}
{"epoch": 38, "training_loss": 55.994462966918945, "training_acc": 47.5, "val_loss": 13.895058631896973, "val_acc": 50.0, "val_auroc": 0.74, "time": 772.21}
{"epoch": 39, "training_loss": 55.855207443237305, "training_acc": 47.5, "val_loss": 13.85865569114685, "val_acc": 50.0, "val_auroc": 0.67, "time": 791.43}
{"epoch": 40, "training_loss": 55.49936103820801, "training_acc": 47.5, "val_loss": 13.868454694747925, "val_acc": 50.0, "val_auroc": 0.73, "time": 811.36}
{"epoch": 41, "training_loss": 55.478020668029785, "training_acc": 52.5, "val_loss": 13.874262571334839, "val_acc": 50.0, "val_auroc": 0.67, "time": 831.72}
{"epoch": 42, "training_loss": 55.369046211242676, "training_acc": 52.5, "val_loss": 13.863266706466675, "val_acc": 50.0, "val_auroc": 0.7, "time": 849.86}
{"epoch": 43, "training_loss": 55.374473571777344, "training_acc": 52.5, "val_loss": 13.872931003570557, "val_acc": 50.0, "val_auroc": 0.67, "time": 867.67}
{"epoch": 44, "training_loss": 55.360008239746094, "training_acc": 52.5, "val_loss": 13.889081478118896, "val_acc": 50.0, "val_auroc": 0.67, "time": 888.73}
{"epoch": 45, "training_loss": 55.34975051879883, "training_acc": 52.5, "val_loss": 13.892067670822144, "val_acc": 50.0, "val_auroc": 0.57, "time": 907.77}
