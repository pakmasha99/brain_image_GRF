"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.76193809509277, "training_acc": 52.5, "val_loss": 13.917235136032104, "val_acc": 50.0, "val_auroc": 0.32, "time": 19.93}
{"epoch": 1, "training_loss": 55.5811243057251, "training_acc": 48.75, "val_loss": 13.893487453460693, "val_acc": 50.0, "val_auroc": 0.56, "time": 42.27}
{"epoch": 2, "training_loss": 55.19682693481445, "training_acc": 52.5, "val_loss": 13.90438437461853, "val_acc": 50.0, "val_auroc": 0.44, "time": 65.23}
{"epoch": 3, "training_loss": 55.0258264541626, "training_acc": 52.5, "val_loss": 13.89033555984497, "val_acc": 50.0, "val_auroc": 0.42, "time": 87.56}
{"epoch": 4, "training_loss": 54.91571617126465, "training_acc": 52.5, "val_loss": 13.908820152282715, "val_acc": 50.0, "val_auroc": 0.44, "time": 109.04}
{"epoch": 5, "training_loss": 54.91957473754883, "training_acc": 60.0, "val_loss": 13.892548084259033, "val_acc": 50.0, "val_auroc": 0.41, "time": 130.8}
{"epoch": 6, "training_loss": 54.7584810256958, "training_acc": 61.25, "val_loss": 13.895457983016968, "val_acc": 50.0, "val_auroc": 0.43, "time": 151.76}
{"epoch": 7, "training_loss": 54.552510261535645, "training_acc": 61.25, "val_loss": 13.916124105453491, "val_acc": 50.0, "val_auroc": 0.45, "time": 170.34}
{"epoch": 8, "training_loss": 54.09909439086914, "training_acc": 63.75, "val_loss": 13.93992304801941, "val_acc": 50.0, "val_auroc": 0.44, "time": 187.98}
{"epoch": 9, "training_loss": 54.26160430908203, "training_acc": 60.0, "val_loss": 13.971443176269531, "val_acc": 50.0, "val_auroc": 0.41, "time": 209.46}
{"epoch": 10, "training_loss": 53.859856605529785, "training_acc": 57.5, "val_loss": 13.875950574874878, "val_acc": 50.0, "val_auroc": 0.47, "time": 230.78}
{"epoch": 11, "training_loss": 52.983842849731445, "training_acc": 71.25, "val_loss": 14.19843077659607, "val_acc": 50.0, "val_auroc": 0.36, "time": 248.79}
{"epoch": 12, "training_loss": 54.86101245880127, "training_acc": 53.75, "val_loss": 14.145560264587402, "val_acc": 50.0, "val_auroc": 0.4, "time": 266.2}
{"epoch": 13, "training_loss": 54.72485542297363, "training_acc": 55.0, "val_loss": 13.875994682312012, "val_acc": 50.0, "val_auroc": 0.47, "time": 286.89}
{"epoch": 14, "training_loss": 53.59270668029785, "training_acc": 56.25, "val_loss": 14.268655776977539, "val_acc": 50.0, "val_auroc": 0.48, "time": 307.94}
{"epoch": 15, "training_loss": 54.76093578338623, "training_acc": 52.5, "val_loss": 14.42283034324646, "val_acc": 50.0, "val_auroc": 0.49, "time": 325.25}
{"epoch": 16, "training_loss": 56.305227279663086, "training_acc": 52.5, "val_loss": 14.23403263092041, "val_acc": 50.0, "val_auroc": 0.39, "time": 343.12}
{"epoch": 17, "training_loss": 55.674781799316406, "training_acc": 52.5, "val_loss": 14.006388187408447, "val_acc": 50.0, "val_auroc": 0.46, "time": 364.01}
{"epoch": 18, "training_loss": 55.025211334228516, "training_acc": 52.5, "val_loss": 13.897542953491211, "val_acc": 50.0, "val_auroc": 0.49, "time": 384.81}
{"epoch": 19, "training_loss": 54.90985107421875, "training_acc": 52.5, "val_loss": 13.872898817062378, "val_acc": 50.0, "val_auroc": 0.49, "time": 403.87}
{"epoch": 20, "training_loss": 54.87784957885742, "training_acc": 67.5, "val_loss": 13.893260955810547, "val_acc": 50.0, "val_auroc": 0.48, "time": 423.76}
{"epoch": 21, "training_loss": 55.15138626098633, "training_acc": 47.5, "val_loss": 13.8676917552948, "val_acc": 50.0, "val_auroc": 0.48, "time": 444.81}
{"epoch": 22, "training_loss": 54.64396286010742, "training_acc": 53.75, "val_loss": 13.922127485275269, "val_acc": 50.0, "val_auroc": 0.46, "time": 464.99}
{"epoch": 23, "training_loss": 54.62428283691406, "training_acc": 52.5, "val_loss": 14.007107019424438, "val_acc": 50.0, "val_auroc": 0.43, "time": 481.68}
{"epoch": 24, "training_loss": 54.7405481338501, "training_acc": 52.5, "val_loss": 13.921287059783936, "val_acc": 50.0, "val_auroc": 0.49, "time": 501.17}
{"epoch": 25, "training_loss": 54.203537940979004, "training_acc": 55.0, "val_loss": 13.86273980140686, "val_acc": 50.0, "val_auroc": 0.47, "time": 523.05}
{"epoch": 26, "training_loss": 54.52478504180908, "training_acc": 70.0, "val_loss": 13.866186141967773, "val_acc": 50.0, "val_auroc": 0.47, "time": 543.04}
{"epoch": 27, "training_loss": 53.99150085449219, "training_acc": 76.25, "val_loss": 13.94599199295044, "val_acc": 50.0, "val_auroc": 0.48, "time": 560.21}
{"epoch": 28, "training_loss": 54.10195541381836, "training_acc": 53.75, "val_loss": 14.003978967666626, "val_acc": 50.0, "val_auroc": 0.46, "time": 580.53}
{"epoch": 29, "training_loss": 53.6413459777832, "training_acc": 57.5, "val_loss": 13.890328407287598, "val_acc": 50.0, "val_auroc": 0.45, "time": 600.83}
{"epoch": 30, "training_loss": 53.31937026977539, "training_acc": 67.5, "val_loss": 13.95134449005127, "val_acc": 50.0, "val_auroc": 0.48, "time": 619.7}
{"epoch": 31, "training_loss": 52.68556213378906, "training_acc": 62.5, "val_loss": 13.997955322265625, "val_acc": 50.0, "val_auroc": 0.47, "time": 637.06}
{"epoch": 32, "training_loss": 52.046202659606934, "training_acc": 65.0, "val_loss": 13.95586371421814, "val_acc": 50.0, "val_auroc": 0.44, "time": 654.56}
{"epoch": 33, "training_loss": 52.92331886291504, "training_acc": 63.75, "val_loss": 14.055954217910767, "val_acc": 50.0, "val_auroc": 0.45, "time": 675.95}
{"epoch": 34, "training_loss": 51.47879219055176, "training_acc": 65.0, "val_loss": 14.16420578956604, "val_acc": 50.0, "val_auroc": 0.47, "time": 696.45}
{"epoch": 35, "training_loss": 50.82110595703125, "training_acc": 66.25, "val_loss": 14.075307846069336, "val_acc": 50.0, "val_auroc": 0.42, "time": 714.43}
{"epoch": 36, "training_loss": 54.047791481018066, "training_acc": 55.0, "val_loss": 13.983782529830933, "val_acc": 50.0, "val_auroc": 0.45, "time": 734.1}
{"epoch": 37, "training_loss": 52.48646831512451, "training_acc": 68.75, "val_loss": 14.279922246932983, "val_acc": 50.0, "val_auroc": 0.5, "time": 755.93}
{"epoch": 38, "training_loss": 52.37535572052002, "training_acc": 58.75, "val_loss": 13.97672176361084, "val_acc": 50.0, "val_auroc": 0.49, "time": 775.05}
{"epoch": 39, "training_loss": 51.2952995300293, "training_acc": 71.25, "val_loss": 14.004080295562744, "val_acc": 50.0, "val_auroc": 0.49, "time": 792.97}
{"epoch": 40, "training_loss": 49.611114501953125, "training_acc": 78.75, "val_loss": 14.188374280929565, "val_acc": 50.0, "val_auroc": 0.49, "time": 811.49}
{"epoch": 41, "training_loss": 48.93495750427246, "training_acc": 71.25, "val_loss": 14.250072240829468, "val_acc": 45.0, "val_auroc": 0.46, "time": 832.9}
{"epoch": 42, "training_loss": 50.73112487792969, "training_acc": 65.0, "val_loss": 14.390480518341064, "val_acc": 50.0, "val_auroc": 0.47, "time": 853.18}
{"epoch": 43, "training_loss": 49.86751079559326, "training_acc": 62.5, "val_loss": 14.27904486656189, "val_acc": 50.0, "val_auroc": 0.49, "time": 872.21}
{"epoch": 44, "training_loss": 47.16788959503174, "training_acc": 78.75, "val_loss": 14.580918550491333, "val_acc": 55.0, "val_auroc": 0.44, "time": 889.89}
