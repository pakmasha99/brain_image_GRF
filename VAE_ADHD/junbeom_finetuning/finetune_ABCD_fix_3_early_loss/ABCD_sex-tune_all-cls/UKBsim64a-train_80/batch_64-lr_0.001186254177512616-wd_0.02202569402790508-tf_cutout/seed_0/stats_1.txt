"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.72071647644043, "training_acc": 55.0, "val_loss": 148.55015754699707, "val_acc": 50.0, "val_auroc": 0.41, "time": 19.61}
{"epoch": 1, "training_loss": 733.0461730957031, "training_acc": 47.5, "val_loss": 19.308618307113647, "val_acc": 50.0, "val_auroc": 0.57, "time": 42.84}
{"epoch": 2, "training_loss": 74.06854343414307, "training_acc": 55.0, "val_loss": 16.20285987854004, "val_acc": 50.0, "val_auroc": 0.46, "time": 63.91}
{"epoch": 3, "training_loss": 72.1559829711914, "training_acc": 52.5, "val_loss": 24.58801031112671, "val_acc": 50.0, "val_auroc": 0.5, "time": 88.17}
{"epoch": 4, "training_loss": 87.0689525604248, "training_acc": 52.5, "val_loss": 15.204771757125854, "val_acc": 50.0, "val_auroc": 0.47, "time": 106.19}
{"epoch": 5, "training_loss": 58.823439598083496, "training_acc": 52.5, "val_loss": 13.878469467163086, "val_acc": 50.0, "val_auroc": 0.55, "time": 127.49}
{"epoch": 6, "training_loss": 55.76306343078613, "training_acc": 47.5, "val_loss": 13.981555700302124, "val_acc": 50.0, "val_auroc": 0.57, "time": 148.61}
{"epoch": 7, "training_loss": 56.19682312011719, "training_acc": 47.5, "val_loss": 13.874214887619019, "val_acc": 50.0, "val_auroc": 0.66, "time": 170.84}
{"epoch": 8, "training_loss": 55.515387535095215, "training_acc": 52.5, "val_loss": 14.156851768493652, "val_acc": 50.0, "val_auroc": 0.55, "time": 187.44}
{"epoch": 9, "training_loss": 55.88433074951172, "training_acc": 52.5, "val_loss": 13.88576626777649, "val_acc": 50.0, "val_auroc": 0.56, "time": 208.23}
{"epoch": 10, "training_loss": 55.51741600036621, "training_acc": 50.0, "val_loss": 13.893599510192871, "val_acc": 50.0, "val_auroc": 0.57, "time": 228.77}
{"epoch": 11, "training_loss": 55.78109169006348, "training_acc": 47.5, "val_loss": 13.861732482910156, "val_acc": 50.0, "val_auroc": 0.56, "time": 250.54}
{"epoch": 12, "training_loss": 55.39256191253662, "training_acc": 50.0, "val_loss": 13.951538801193237, "val_acc": 50.0, "val_auroc": 0.5, "time": 267.87}
{"epoch": 13, "training_loss": 55.37372589111328, "training_acc": 52.5, "val_loss": 14.137259721755981, "val_acc": 50.0, "val_auroc": 0.41, "time": 288.43}
{"epoch": 14, "training_loss": 55.89232635498047, "training_acc": 52.5, "val_loss": 14.274176359176636, "val_acc": 50.0, "val_auroc": 0.46, "time": 307.51}
{"epoch": 15, "training_loss": 56.28797149658203, "training_acc": 52.5, "val_loss": 14.276278018951416, "val_acc": 50.0, "val_auroc": 0.42, "time": 326.69}
{"epoch": 16, "training_loss": 56.319236755371094, "training_acc": 52.5, "val_loss": 14.119081497192383, "val_acc": 50.0, "val_auroc": 0.42, "time": 343.29}
{"epoch": 17, "training_loss": 55.74047565460205, "training_acc": 52.5, "val_loss": 13.93433928489685, "val_acc": 50.0, "val_auroc": 0.5, "time": 364.17}
{"epoch": 18, "training_loss": 55.35101890563965, "training_acc": 52.5, "val_loss": 13.863449096679688, "val_acc": 50.0, "val_auroc": 0.56, "time": 382.56}
{"epoch": 19, "training_loss": 55.42009449005127, "training_acc": 47.5, "val_loss": 13.921403884887695, "val_acc": 50.0, "val_auroc": 0.53, "time": 402.53}
{"epoch": 20, "training_loss": 56.01163864135742, "training_acc": 47.5, "val_loss": 13.964141607284546, "val_acc": 50.0, "val_auroc": 0.53, "time": 420.46}
{"epoch": 21, "training_loss": 56.20527648925781, "training_acc": 47.5, "val_loss": 13.886475563049316, "val_acc": 50.0, "val_auroc": 0.53, "time": 439.43}
{"epoch": 22, "training_loss": 55.633352279663086, "training_acc": 47.5, "val_loss": 13.882865905761719, "val_acc": 50.0, "val_auroc": 0.47, "time": 457.87}
{"epoch": 23, "training_loss": 55.24195194244385, "training_acc": 52.5, "val_loss": 14.028404951095581, "val_acc": 50.0, "val_auroc": 0.58, "time": 476.74}
{"epoch": 24, "training_loss": 55.60743427276611, "training_acc": 52.5, "val_loss": 14.183177947998047, "val_acc": 50.0, "val_auroc": 0.53, "time": 494.62}
{"epoch": 25, "training_loss": 56.01163387298584, "training_acc": 52.5, "val_loss": 14.143370389938354, "val_acc": 50.0, "val_auroc": 0.53, "time": 515.48}
{"epoch": 26, "training_loss": 55.88681697845459, "training_acc": 52.5, "val_loss": 14.012621641159058, "val_acc": 50.0, "val_auroc": 0.24, "time": 536.18}
{"epoch": 27, "training_loss": 55.565199851989746, "training_acc": 52.5, "val_loss": 13.917111158370972, "val_acc": 50.0, "val_auroc": 0.3, "time": 556.46}
{"epoch": 28, "training_loss": 55.319963455200195, "training_acc": 52.5, "val_loss": 13.867634534835815, "val_acc": 50.0, "val_auroc": 0.36, "time": 573.47}
{"epoch": 29, "training_loss": 55.47930717468262, "training_acc": 50.0, "val_loss": 13.882595300674438, "val_acc": 50.0, "val_auroc": 0.34, "time": 592.69}
{"epoch": 30, "training_loss": 55.736249923706055, "training_acc": 47.5, "val_loss": 13.871639966964722, "val_acc": 50.0, "val_auroc": 0.43, "time": 611.78}
