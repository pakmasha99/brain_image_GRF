"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.54190635681152, "training_acc": 51.25, "val_loss": 13.821525573730469, "val_acc": 55.0, "val_auroc": 0.323, "time": 19.27}
{"epoch": 1, "training_loss": 55.42060947418213, "training_acc": 51.25, "val_loss": 13.779462575912476, "val_acc": 55.0, "val_auroc": 0.505, "time": 39.67}
{"epoch": 2, "training_loss": 55.18447685241699, "training_acc": 51.25, "val_loss": 13.835906982421875, "val_acc": 55.0, "val_auroc": 0.465, "time": 64.46}
{"epoch": 3, "training_loss": 54.973426818847656, "training_acc": 53.75, "val_loss": 13.889514207839966, "val_acc": 55.0, "val_auroc": 0.616, "time": 83.42}
{"epoch": 4, "training_loss": 55.22614097595215, "training_acc": 56.25, "val_loss": 13.776741027832031, "val_acc": 55.0, "val_auroc": 0.556, "time": 101.5}
{"epoch": 5, "training_loss": 54.96415901184082, "training_acc": 51.25, "val_loss": 13.756592273712158, "val_acc": 55.0, "val_auroc": 0.545, "time": 122.37}
{"epoch": 6, "training_loss": 54.91974639892578, "training_acc": 51.25, "val_loss": 13.823641538619995, "val_acc": 55.0, "val_auroc": 0.646, "time": 141.31}
{"epoch": 7, "training_loss": 55.076226234436035, "training_acc": 52.5, "val_loss": 13.8097083568573, "val_acc": 55.0, "val_auroc": 0.566, "time": 159.21}
{"epoch": 8, "training_loss": 55.00628089904785, "training_acc": 57.5, "val_loss": 13.814607858657837, "val_acc": 55.0, "val_auroc": 0.566, "time": 177.65}
{"epoch": 9, "training_loss": 54.53804397583008, "training_acc": 63.75, "val_loss": 13.933441638946533, "val_acc": 55.0, "val_auroc": 0.566, "time": 196.28}
{"epoch": 10, "training_loss": 54.50984477996826, "training_acc": 58.75, "val_loss": 13.755888938903809, "val_acc": 55.0, "val_auroc": 0.586, "time": 215.89}
{"epoch": 11, "training_loss": 55.07345676422119, "training_acc": 51.25, "val_loss": 13.769960403442383, "val_acc": 55.0, "val_auroc": 0.596, "time": 233.95}
{"epoch": 12, "training_loss": 55.79972171783447, "training_acc": 51.25, "val_loss": 13.752789497375488, "val_acc": 55.0, "val_auroc": 0.606, "time": 252.61}
{"epoch": 13, "training_loss": 55.24683475494385, "training_acc": 51.25, "val_loss": 13.8184654712677, "val_acc": 55.0, "val_auroc": 0.505, "time": 274.81}
{"epoch": 14, "training_loss": 54.70487880706787, "training_acc": 61.25, "val_loss": 13.939589262008667, "val_acc": 55.0, "val_auroc": 0.505, "time": 292.92}
{"epoch": 15, "training_loss": 54.7879695892334, "training_acc": 53.75, "val_loss": 13.804339170455933, "val_acc": 55.0, "val_auroc": 0.495, "time": 313.0}
{"epoch": 16, "training_loss": 54.6110782623291, "training_acc": 53.75, "val_loss": 13.793425559997559, "val_acc": 55.0, "val_auroc": 0.556, "time": 329.78}
{"epoch": 17, "training_loss": 55.51215744018555, "training_acc": 51.25, "val_loss": 13.790037631988525, "val_acc": 55.0, "val_auroc": 0.535, "time": 351.29}
{"epoch": 18, "training_loss": 55.241044998168945, "training_acc": 51.25, "val_loss": 13.804923295974731, "val_acc": 55.0, "val_auroc": 0.566, "time": 370.66}
{"epoch": 19, "training_loss": 54.676947593688965, "training_acc": 61.25, "val_loss": 13.97689938545227, "val_acc": 55.0, "val_auroc": 0.556, "time": 388.02}
{"epoch": 20, "training_loss": 55.07199764251709, "training_acc": 48.75, "val_loss": 14.080415964126587, "val_acc": 55.0, "val_auroc": 0.545, "time": 407.27}
{"epoch": 21, "training_loss": 55.079543113708496, "training_acc": 48.75, "val_loss": 13.892295360565186, "val_acc": 55.0, "val_auroc": 0.566, "time": 427.45}
{"epoch": 22, "training_loss": 54.70102882385254, "training_acc": 65.0, "val_loss": 13.793518543243408, "val_acc": 55.0, "val_auroc": 0.545, "time": 447.04}
{"epoch": 23, "training_loss": 54.51054573059082, "training_acc": 58.75, "val_loss": 13.782624006271362, "val_acc": 55.0, "val_auroc": 0.525, "time": 467.09}
{"epoch": 24, "training_loss": 54.32387733459473, "training_acc": 60.0, "val_loss": 13.784784078598022, "val_acc": 55.0, "val_auroc": 0.525, "time": 483.93}
{"epoch": 25, "training_loss": 53.810434341430664, "training_acc": 63.75, "val_loss": 13.817180395126343, "val_acc": 55.0, "val_auroc": 0.556, "time": 504.32}
{"epoch": 26, "training_loss": 54.814321517944336, "training_acc": 51.25, "val_loss": 13.836618661880493, "val_acc": 55.0, "val_auroc": 0.566, "time": 523.92}
{"epoch": 27, "training_loss": 54.505868911743164, "training_acc": 51.25, "val_loss": 13.774336576461792, "val_acc": 55.0, "val_auroc": 0.545, "time": 543.1}
{"epoch": 28, "training_loss": 53.58489418029785, "training_acc": 63.75, "val_loss": 14.13533091545105, "val_acc": 55.0, "val_auroc": 0.505, "time": 563.61}
{"epoch": 29, "training_loss": 55.263038635253906, "training_acc": 50.0, "val_loss": 14.187806844711304, "val_acc": 55.0, "val_auroc": 0.475, "time": 583.23}
{"epoch": 30, "training_loss": 55.76426887512207, "training_acc": 48.75, "val_loss": 13.967461585998535, "val_acc": 55.0, "val_auroc": 0.535, "time": 601.76}
{"epoch": 31, "training_loss": 54.980347633361816, "training_acc": 55.0, "val_loss": 13.839035034179688, "val_acc": 55.0, "val_auroc": 0.566, "time": 621.42}
