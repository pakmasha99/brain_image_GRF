"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 100.40737915039062, "training_acc": 46.25, "val_loss": 572.4277496337891, "val_acc": 50.0, "val_auroc": 0.48, "time": 20.49}
{"epoch": 1, "training_loss": 1971.7143478393555, "training_acc": 45.0, "val_loss": 14.368870258331299, "val_acc": 50.0, "val_auroc": 0.46, "time": 42.52}
{"epoch": 2, "training_loss": 147.63450241088867, "training_acc": 52.5, "val_loss": 15.137499570846558, "val_acc": 50.0, "val_auroc": 0.48, "time": 65.24}
{"epoch": 3, "training_loss": 58.84076499938965, "training_acc": 52.5, "val_loss": 13.867634534835815, "val_acc": 50.0, "val_auroc": 0.52, "time": 87.5}
{"epoch": 4, "training_loss": 55.660776138305664, "training_acc": 47.5, "val_loss": 13.862041234970093, "val_acc": 50.0, "val_auroc": 0.59, "time": 106.04}
{"epoch": 5, "training_loss": 56.64064884185791, "training_acc": 50.0, "val_loss": 13.867225646972656, "val_acc": 50.0, "val_auroc": 0.53, "time": 126.98}
{"epoch": 6, "training_loss": 55.723952293395996, "training_acc": 47.5, "val_loss": 13.989626169204712, "val_acc": 50.0, "val_auroc": 0.55, "time": 148.31}
{"epoch": 7, "training_loss": 56.68119716644287, "training_acc": 45.0, "val_loss": 13.907665014266968, "val_acc": 50.0, "val_auroc": 0.56, "time": 169.12}
{"epoch": 8, "training_loss": 55.34848594665527, "training_acc": 52.5, "val_loss": 13.863433599472046, "val_acc": 50.0, "val_auroc": 0.58, "time": 186.88}
{"epoch": 9, "training_loss": 55.38675498962402, "training_acc": 52.5, "val_loss": 13.8621985912323, "val_acc": 50.0, "val_auroc": 0.59, "time": 209.28}
{"epoch": 10, "training_loss": 55.4360933303833, "training_acc": 50.0, "val_loss": 14.046049118041992, "val_acc": 50.0, "val_auroc": 0.56, "time": 228.74}
{"epoch": 11, "training_loss": 55.6966667175293, "training_acc": 52.5, "val_loss": 14.28747296333313, "val_acc": 50.0, "val_auroc": 0.59, "time": 249.15}
{"epoch": 12, "training_loss": 56.43313789367676, "training_acc": 52.5, "val_loss": 14.059555530548096, "val_acc": 50.0, "val_auroc": 0.56, "time": 266.82}
{"epoch": 13, "training_loss": 55.98413372039795, "training_acc": 52.5, "val_loss": 14.06990647315979, "val_acc": 50.0, "val_auroc": 0.48, "time": 285.86}
{"epoch": 14, "training_loss": 55.82754325866699, "training_acc": 52.5, "val_loss": 14.471338987350464, "val_acc": 50.0, "val_auroc": 0.53, "time": 303.08}
{"epoch": 15, "training_loss": 56.85428237915039, "training_acc": 52.5, "val_loss": 14.541962146759033, "val_acc": 50.0, "val_auroc": 0.56, "time": 322.28}
{"epoch": 16, "training_loss": 57.146297454833984, "training_acc": 52.5, "val_loss": 14.014910459518433, "val_acc": 50.0, "val_auroc": 0.54, "time": 339.53}
{"epoch": 17, "training_loss": 55.45785331726074, "training_acc": 52.5, "val_loss": 13.859599828720093, "val_acc": 50.0, "val_auroc": 0.58, "time": 361.74}
{"epoch": 18, "training_loss": 55.53783416748047, "training_acc": 51.25, "val_loss": 13.870199918746948, "val_acc": 50.0, "val_auroc": 0.59, "time": 379.22}
{"epoch": 19, "training_loss": 55.93908500671387, "training_acc": 40.0, "val_loss": 13.865034580230713, "val_acc": 50.0, "val_auroc": 0.56, "time": 400.12}
{"epoch": 20, "training_loss": 55.48517417907715, "training_acc": 47.5, "val_loss": 13.902771472930908, "val_acc": 50.0, "val_auroc": 0.58, "time": 417.53}
{"epoch": 21, "training_loss": 55.92574691772461, "training_acc": 47.5, "val_loss": 13.872088193893433, "val_acc": 50.0, "val_auroc": 0.51, "time": 438.31}
{"epoch": 22, "training_loss": 55.384756088256836, "training_acc": 52.5, "val_loss": 13.959416151046753, "val_acc": 50.0, "val_auroc": 0.52, "time": 455.21}
{"epoch": 23, "training_loss": 55.546199798583984, "training_acc": 52.5, "val_loss": 14.199060201644897, "val_acc": 50.0, "val_auroc": 0.53, "time": 475.48}
{"epoch": 24, "training_loss": 56.04059982299805, "training_acc": 52.5, "val_loss": 14.046796560287476, "val_acc": 50.0, "val_auroc": 0.52, "time": 492.53}
{"epoch": 25, "training_loss": 55.52958106994629, "training_acc": 52.5, "val_loss": 13.87127161026001, "val_acc": 50.0, "val_auroc": 0.57, "time": 513.9}
{"epoch": 26, "training_loss": 55.447771072387695, "training_acc": 50.0, "val_loss": 13.87381911277771, "val_acc": 50.0, "val_auroc": 0.52, "time": 530.79}
{"epoch": 27, "training_loss": 55.63576126098633, "training_acc": 47.5, "val_loss": 13.862899541854858, "val_acc": 50.0, "val_auroc": 0.56, "time": 550.52}
{"epoch": 28, "training_loss": 55.63529682159424, "training_acc": 41.25, "val_loss": 13.877214193344116, "val_acc": 50.0, "val_auroc": 0.51, "time": 567.11}
{"epoch": 29, "training_loss": 55.346699714660645, "training_acc": 52.5, "val_loss": 13.877540826797485, "val_acc": 50.0, "val_auroc": 0.56, "time": 586.04}
{"epoch": 30, "training_loss": 55.3299560546875, "training_acc": 52.5, "val_loss": 13.897113800048828, "val_acc": 50.0, "val_auroc": 0.56, "time": 603.86}
{"epoch": 31, "training_loss": 55.35047626495361, "training_acc": 52.5, "val_loss": 13.918144702911377, "val_acc": 50.0, "val_auroc": 0.55, "time": 622.37}
{"epoch": 32, "training_loss": 55.371028900146484, "training_acc": 52.5, "val_loss": 13.888018131256104, "val_acc": 50.0, "val_auroc": 0.58, "time": 639.55}
{"epoch": 33, "training_loss": 55.427391052246094, "training_acc": 52.5, "val_loss": 13.867732286453247, "val_acc": 50.0, "val_auroc": 0.57, "time": 658.26}
{"epoch": 34, "training_loss": 55.340187072753906, "training_acc": 52.5, "val_loss": 13.893308639526367, "val_acc": 50.0, "val_auroc": 0.58, "time": 677.18}
{"epoch": 35, "training_loss": 55.50343322753906, "training_acc": 52.5, "val_loss": 13.920927047729492, "val_acc": 50.0, "val_auroc": 0.56, "time": 697.72}
{"epoch": 36, "training_loss": 55.33974266052246, "training_acc": 52.5, "val_loss": 13.882529735565186, "val_acc": 50.0, "val_auroc": 0.55, "time": 715.18}
