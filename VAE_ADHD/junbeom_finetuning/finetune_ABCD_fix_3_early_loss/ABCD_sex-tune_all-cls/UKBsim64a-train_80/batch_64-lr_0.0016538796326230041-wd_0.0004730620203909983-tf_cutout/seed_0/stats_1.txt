"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 73.10383033752441, "training_acc": 53.75, "val_loss": 67.49307155609131, "val_acc": 50.0, "val_auroc": 0.58, "time": 18.83}
{"epoch": 1, "training_loss": 27258.541091918945, "training_acc": 52.5, "val_loss": 26.731574535369873, "val_acc": 50.0, "val_auroc": 0.23, "time": 38.16}
{"epoch": 2, "training_loss": 104.20428848266602, "training_acc": 50.0, "val_loss": 18.949378728866577, "val_acc": 50.0, "val_auroc": 0.48, "time": 61.77}
{"epoch": 3, "training_loss": 73.64613723754883, "training_acc": 47.5, "val_loss": 23.61091375350952, "val_acc": 50.0, "val_auroc": 0.57, "time": 86.12}
{"epoch": 4, "training_loss": 157.72544860839844, "training_acc": 52.5, "val_loss": 15.066410303115845, "val_acc": 50.0, "val_auroc": 0.49, "time": 104.97}
{"epoch": 5, "training_loss": 61.268598556518555, "training_acc": 50.0, "val_loss": 16.645723581314087, "val_acc": 50.0, "val_auroc": 0.58, "time": 124.17}
{"epoch": 6, "training_loss": 62.033329010009766, "training_acc": 52.5, "val_loss": 15.398353338241577, "val_acc": 50.0, "val_auroc": 0.4, "time": 146.17}
{"epoch": 7, "training_loss": 60.83374214172363, "training_acc": 50.0, "val_loss": 16.597477197647095, "val_acc": 50.0, "val_auroc": 0.57, "time": 167.15}
{"epoch": 8, "training_loss": 61.759233474731445, "training_acc": 53.75, "val_loss": 15.189094543457031, "val_acc": 50.0, "val_auroc": 0.38, "time": 183.85}
{"epoch": 9, "training_loss": 61.608948707580566, "training_acc": 45.0, "val_loss": 13.948482275009155, "val_acc": 50.0, "val_auroc": 0.53, "time": 203.3}
{"epoch": 10, "training_loss": 55.486162185668945, "training_acc": 52.5, "val_loss": 14.010782241821289, "val_acc": 50.0, "val_auroc": 0.56, "time": 223.28}
{"epoch": 11, "training_loss": 55.616597175598145, "training_acc": 52.5, "val_loss": 13.933172225952148, "val_acc": 50.0, "val_auroc": 0.7, "time": 243.22}
{"epoch": 12, "training_loss": 55.472904205322266, "training_acc": 52.5, "val_loss": 14.03591513633728, "val_acc": 50.0, "val_auroc": 0.67, "time": 260.36}
{"epoch": 13, "training_loss": 56.0877685546875, "training_acc": 47.5, "val_loss": 14.581602811813354, "val_acc": 50.0, "val_auroc": 0.6, "time": 281.92}
{"epoch": 14, "training_loss": 57.99278450012207, "training_acc": 52.5, "val_loss": 14.474560022354126, "val_acc": 50.0, "val_auroc": 0.61, "time": 302.37}
{"epoch": 15, "training_loss": 56.96057891845703, "training_acc": 52.5, "val_loss": 14.143131971359253, "val_acc": 50.0, "val_auroc": 0.59, "time": 322.07}
{"epoch": 16, "training_loss": 56.1653938293457, "training_acc": 52.5, "val_loss": 13.918546438217163, "val_acc": 50.0, "val_auroc": 0.83, "time": 339.34}
{"epoch": 17, "training_loss": 55.48406410217285, "training_acc": 52.5, "val_loss": 13.855116367340088, "val_acc": 50.0, "val_auroc": 0.66, "time": 359.98}
{"epoch": 18, "training_loss": 55.41522789001465, "training_acc": 52.5, "val_loss": 13.911947011947632, "val_acc": 50.0, "val_auroc": 0.54, "time": 379.9}
{"epoch": 19, "training_loss": 56.117539405822754, "training_acc": 47.5, "val_loss": 13.882114887237549, "val_acc": 50.0, "val_auroc": 0.56, "time": 399.77}
{"epoch": 20, "training_loss": 55.68288803100586, "training_acc": 47.5, "val_loss": 13.86636734008789, "val_acc": 50.0, "val_auroc": 0.56, "time": 417.1}
{"epoch": 21, "training_loss": 55.45104789733887, "training_acc": 50.0, "val_loss": 13.942655324935913, "val_acc": 50.0, "val_auroc": 0.68, "time": 436.69}
{"epoch": 22, "training_loss": 55.405426025390625, "training_acc": 52.5, "val_loss": 14.216246604919434, "val_acc": 50.0, "val_auroc": 0.64, "time": 456.28}
{"epoch": 23, "training_loss": 56.149940490722656, "training_acc": 52.5, "val_loss": 14.118027687072754, "val_acc": 50.0, "val_auroc": 0.58, "time": 476.61}
{"epoch": 24, "training_loss": 55.82969665527344, "training_acc": 52.5, "val_loss": 13.93035888671875, "val_acc": 50.0, "val_auroc": 0.86, "time": 493.69}
{"epoch": 25, "training_loss": 55.44492244720459, "training_acc": 52.5, "val_loss": 13.859919309616089, "val_acc": 50.0, "val_auroc": 0.79, "time": 512.1}
{"epoch": 26, "training_loss": 55.393877029418945, "training_acc": 52.5, "val_loss": 13.873597383499146, "val_acc": 50.0, "val_auroc": 0.84, "time": 532.62}
{"epoch": 27, "training_loss": 55.31290245056152, "training_acc": 52.5, "val_loss": 13.942307233810425, "val_acc": 50.0, "val_auroc": 0.66, "time": 553.99}
{"epoch": 28, "training_loss": 55.75817394256592, "training_acc": 52.5, "val_loss": 13.884384632110596, "val_acc": 50.0, "val_auroc": 0.77, "time": 571.48}
{"epoch": 29, "training_loss": 55.4554557800293, "training_acc": 50.0, "val_loss": 13.881367444992065, "val_acc": 50.0, "val_auroc": 0.62, "time": 591.83}
{"epoch": 30, "training_loss": 55.81285095214844, "training_acc": 47.5, "val_loss": 13.858064413070679, "val_acc": 50.0, "val_auroc": 0.7, "time": 614.35}
{"epoch": 31, "training_loss": 55.42512226104736, "training_acc": 50.0, "val_loss": 13.906539678573608, "val_acc": 50.0, "val_auroc": 0.73, "time": 634.83}
{"epoch": 32, "training_loss": 55.58717155456543, "training_acc": 52.5, "val_loss": 13.96161437034607, "val_acc": 50.0, "val_auroc": 0.63, "time": 651.31}
{"epoch": 33, "training_loss": 55.459238052368164, "training_acc": 52.5, "val_loss": 13.907643556594849, "val_acc": 50.0, "val_auroc": 0.61, "time": 671.01}
{"epoch": 34, "training_loss": 55.376502990722656, "training_acc": 52.5, "val_loss": 13.884806632995605, "val_acc": 50.0, "val_auroc": 0.72, "time": 690.21}
{"epoch": 35, "training_loss": 55.40681838989258, "training_acc": 52.5, "val_loss": 13.863791227340698, "val_acc": 50.0, "val_auroc": 0.53, "time": 709.71}
{"epoch": 36, "training_loss": 55.3075008392334, "training_acc": 57.5, "val_loss": 13.92045259475708, "val_acc": 50.0, "val_auroc": 0.42, "time": 727.39}
