"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.81618309020996, "training_acc": 52.5, "val_loss": 13.906940221786499, "val_acc": 50.0, "val_auroc": 0.4, "time": 20.34}
{"epoch": 1, "training_loss": 55.56752300262451, "training_acc": 52.5, "val_loss": 13.928648233413696, "val_acc": 50.0, "val_auroc": 0.38, "time": 41.47}
{"epoch": 2, "training_loss": 55.28190803527832, "training_acc": 52.5, "val_loss": 13.887388706207275, "val_acc": 50.0, "val_auroc": 0.48, "time": 63.9}
{"epoch": 3, "training_loss": 55.13247013092041, "training_acc": 52.5, "val_loss": 13.861806392669678, "val_acc": 50.0, "val_auroc": 0.57, "time": 86.38}
{"epoch": 4, "training_loss": 55.01892566680908, "training_acc": 52.5, "val_loss": 13.869374990463257, "val_acc": 50.0, "val_auroc": 0.49, "time": 104.36}
{"epoch": 5, "training_loss": 55.01326847076416, "training_acc": 57.5, "val_loss": 13.875559568405151, "val_acc": 50.0, "val_auroc": 0.48, "time": 123.89}
{"epoch": 6, "training_loss": 55.08334922790527, "training_acc": 53.75, "val_loss": 13.865435123443604, "val_acc": 50.0, "val_auroc": 0.51, "time": 145.85}
{"epoch": 7, "training_loss": 54.93677520751953, "training_acc": 57.5, "val_loss": 13.891630172729492, "val_acc": 50.0, "val_auroc": 0.47, "time": 167.89}
{"epoch": 8, "training_loss": 54.53001594543457, "training_acc": 63.75, "val_loss": 13.882969617843628, "val_acc": 50.0, "val_auroc": 0.49, "time": 185.38}
{"epoch": 9, "training_loss": 54.60424995422363, "training_acc": 58.75, "val_loss": 13.925596475601196, "val_acc": 50.0, "val_auroc": 0.47, "time": 205.87}
{"epoch": 10, "training_loss": 54.185832023620605, "training_acc": 57.5, "val_loss": 13.910343647003174, "val_acc": 50.0, "val_auroc": 0.5, "time": 228.38}
{"epoch": 11, "training_loss": 53.86951732635498, "training_acc": 63.75, "val_loss": 14.196703433990479, "val_acc": 50.0, "val_auroc": 0.39, "time": 248.15}
{"epoch": 12, "training_loss": 55.31456756591797, "training_acc": 52.5, "val_loss": 14.20488715171814, "val_acc": 50.0, "val_auroc": 0.43, "time": 268.26}
{"epoch": 13, "training_loss": 55.62863540649414, "training_acc": 52.5, "val_loss": 14.091708660125732, "val_acc": 50.0, "val_auroc": 0.49, "time": 288.58}
{"epoch": 14, "training_loss": 55.06391143798828, "training_acc": 52.5, "val_loss": 14.034422636032104, "val_acc": 50.0, "val_auroc": 0.5, "time": 309.25}
{"epoch": 15, "training_loss": 54.31915473937988, "training_acc": 52.5, "val_loss": 14.121860265731812, "val_acc": 50.0, "val_auroc": 0.5, "time": 329.58}
{"epoch": 16, "training_loss": 53.93922805786133, "training_acc": 55.0, "val_loss": 14.255080223083496, "val_acc": 50.0, "val_auroc": 0.51, "time": 347.43}
{"epoch": 17, "training_loss": 53.634695053100586, "training_acc": 53.75, "val_loss": 13.827379941940308, "val_acc": 50.0, "val_auroc": 0.52, "time": 367.65}
{"epoch": 18, "training_loss": 53.91058158874512, "training_acc": 66.25, "val_loss": 14.051198959350586, "val_acc": 50.0, "val_auroc": 0.49, "time": 385.16}
{"epoch": 19, "training_loss": 54.23755359649658, "training_acc": 60.0, "val_loss": 14.091018438339233, "val_acc": 50.0, "val_auroc": 0.48, "time": 402.48}
{"epoch": 20, "training_loss": 52.35750102996826, "training_acc": 65.0, "val_loss": 14.024053812026978, "val_acc": 50.0, "val_auroc": 0.49, "time": 419.1}
{"epoch": 21, "training_loss": 55.34542942047119, "training_acc": 48.75, "val_loss": 13.8990318775177, "val_acc": 50.0, "val_auroc": 0.46, "time": 438.38}
{"epoch": 22, "training_loss": 53.26500225067139, "training_acc": 70.0, "val_loss": 14.164454936981201, "val_acc": 50.0, "val_auroc": 0.43, "time": 459.59}
{"epoch": 23, "training_loss": 54.55490493774414, "training_acc": 52.5, "val_loss": 14.18230414390564, "val_acc": 50.0, "val_auroc": 0.48, "time": 477.89}
{"epoch": 24, "training_loss": 54.142706871032715, "training_acc": 52.5, "val_loss": 13.922358751296997, "val_acc": 50.0, "val_auroc": 0.5, "time": 494.97}
{"epoch": 25, "training_loss": 53.69405651092529, "training_acc": 72.5, "val_loss": 13.918617963790894, "val_acc": 50.0, "val_auroc": 0.5, "time": 513.79}
{"epoch": 26, "training_loss": 53.90243339538574, "training_acc": 68.75, "val_loss": 14.025533199310303, "val_acc": 50.0, "val_auroc": 0.51, "time": 531.88}
{"epoch": 27, "training_loss": 52.87792110443115, "training_acc": 60.0, "val_loss": 14.114611148834229, "val_acc": 50.0, "val_auroc": 0.49, "time": 549.55}
{"epoch": 28, "training_loss": 52.48946952819824, "training_acc": 62.5, "val_loss": 13.986634016036987, "val_acc": 50.0, "val_auroc": 0.46, "time": 566.56}
{"epoch": 29, "training_loss": 53.82844924926758, "training_acc": 53.75, "val_loss": 13.97558331489563, "val_acc": 50.0, "val_auroc": 0.47, "time": 587.13}
{"epoch": 30, "training_loss": 51.70633411407471, "training_acc": 73.75, "val_loss": 14.4633150100708, "val_acc": 50.0, "val_auroc": 0.44, "time": 606.55}
{"epoch": 31, "training_loss": 53.81496334075928, "training_acc": 55.0, "val_loss": 14.061002731323242, "val_acc": 50.0, "val_auroc": 0.44, "time": 625.74}
{"epoch": 32, "training_loss": 51.17449378967285, "training_acc": 73.75, "val_loss": 14.168189764022827, "val_acc": 50.0, "val_auroc": 0.45, "time": 645.76}
{"epoch": 33, "training_loss": 51.103678703308105, "training_acc": 67.5, "val_loss": 14.319403171539307, "val_acc": 50.0, "val_auroc": 0.49, "time": 666.16}
{"epoch": 34, "training_loss": 50.653289794921875, "training_acc": 66.25, "val_loss": 14.102233648300171, "val_acc": 50.0, "val_auroc": 0.49, "time": 685.53}
{"epoch": 35, "training_loss": 48.92406463623047, "training_acc": 78.75, "val_loss": 14.316681623458862, "val_acc": 45.0, "val_auroc": 0.47, "time": 702.94}
{"epoch": 36, "training_loss": 50.83873748779297, "training_acc": 66.25, "val_loss": 14.52396035194397, "val_acc": 55.0, "val_auroc": 0.45, "time": 720.56}
