"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 3628.789047241211, "training_acc": 46.25, "val_loss": 3.0103108223421644e+31, "val_acc": 50.0, "val_auroc": 0.32, "time": 18.36}
{"epoch": 1, "training_loss": 9.936817183892924e+31, "training_acc": 52.5, "val_loss": 1.9762048281900544e+29, "val_acc": 50.0, "val_auroc": 0.38, "time": 40.47}
{"epoch": 2, "training_loss": 5.934375027906543e+29, "training_acc": 52.5, "val_loss": 2.5488251362427026e+26, "val_acc": 50.0, "val_auroc": 0.43, "time": 63.28}
{"epoch": 3, "training_loss": 8.021716125196456e+26, "training_acc": 52.5, "val_loss": 1.3922687295391688e+25, "val_acc": 50.0, "val_auroc": 0.56, "time": 88.42}
{"epoch": 4, "training_loss": 4.832957250018844e+25, "training_acc": 47.5, "val_loss": 3.3611478659973786e+23, "val_acc": 50.0, "val_auroc": 0.56, "time": 108.08}
{"epoch": 5, "training_loss": 1.1806356253893703e+24, "training_acc": 47.5, "val_loss": 1.0271941091892658e+21, "val_acc": 50.0, "val_auroc": 0.5, "time": 127.06}
{"epoch": 6, "training_loss": 3.4926325505885995e+21, "training_acc": 47.5, "val_loss": 6.57993937549525e+19, "val_acc": 50.0, "val_auroc": 0.54, "time": 149.69}
{"epoch": 7, "training_loss": 2.2784372723232958e+20, "training_acc": 47.5, "val_loss": 5.812909133266944e+16, "val_acc": 50.0, "val_auroc": 0.47, "time": 168.84}
{"epoch": 8, "training_loss": 1.725255235183575e+17, "training_acc": 52.5, "val_loss": 756097786839040.0, "val_acc": 50.0, "val_auroc": 0.5, "time": 186.5}
{"epoch": 9, "training_loss": 2465865882664960.0, "training_acc": 47.5, "val_loss": 374610083840.0, "val_acc": 50.0, "val_auroc": 0.39, "time": 206.36}
{"epoch": 10, "training_loss": 62673464328192.0, "training_acc": 50.0, "val_loss": 1085044572160.0, "val_acc": 50.0, "val_auroc": 0.52, "time": 223.78}
{"epoch": 11, "training_loss": 5346963095552.0, "training_acc": 52.5, "val_loss": 788489994240.0, "val_acc": 50.0, "val_auroc": 0.41, "time": 242.63}
{"epoch": 12, "training_loss": 2727871447040.0, "training_acc": 52.5, "val_loss": 36545699840.0, "val_acc": 50.0, "val_auroc": 0.29, "time": 260.05}
{"epoch": 13, "training_loss": 183950852096.0, "training_acc": 45.0, "val_loss": 37236101120.0, "val_acc": 50.0, "val_auroc": 0.64, "time": 277.43}
{"epoch": 14, "training_loss": 111843028096.0, "training_acc": 57.5, "val_loss": 4244828160.0, "val_acc": 50.0, "val_auroc": 0.42, "time": 295.19}
{"epoch": 15, "training_loss": 14162896640.0, "training_acc": 52.5, "val_loss": 205706860.0, "val_acc": 50.0, "val_auroc": 0.67, "time": 313.81}
{"epoch": 16, "training_loss": 2801833088.0, "training_acc": 52.5, "val_loss": 72968730.0, "val_acc": 50.0, "val_auroc": 0.67, "time": 331.24}
{"epoch": 17, "training_loss": 336684400.0, "training_acc": 47.5, "val_loss": 25298605.0, "val_acc": 50.0, "val_auroc": 0.71, "time": 349.34}
{"epoch": 18, "training_loss": 88244179.5, "training_acc": 50.0, "val_loss": 2407047.34375, "val_acc": 50.0, "val_auroc": 0.22, "time": 367.99}
{"epoch": 19, "training_loss": 13425946.0, "training_acc": 60.0, "val_loss": 2991200.9375, "val_acc": 50.0, "val_auroc": 0.57, "time": 384.83}
{"epoch": 20, "training_loss": 16844172.0, "training_acc": 45.0, "val_loss": 879573.515625, "val_acc": 50.0, "val_auroc": 0.39, "time": 402.27}
{"epoch": 21, "training_loss": 2894804.0703125, "training_acc": 47.5, "val_loss": 43093.7109375, "val_acc": 50.0, "val_auroc": 0.49, "time": 419.85}
{"epoch": 22, "training_loss": 160687.33984375, "training_acc": 47.5, "val_loss": 38055.7275390625, "val_acc": 40.0, "val_auroc": 0.48, "time": 441.5}
{"epoch": 23, "training_loss": 181693.60876464844, "training_acc": 45.0, "val_loss": 38142.80029296875, "val_acc": 50.0, "val_auroc": 0.59, "time": 460.58}
{"epoch": 24, "training_loss": 137030.49340820312, "training_acc": 47.5, "val_loss": 13987.3974609375, "val_acc": 50.0, "val_auroc": 0.48, "time": 479.97}
{"epoch": 25, "training_loss": 46763.06005859375, "training_acc": 52.5, "val_loss": 5866.495361328125, "val_acc": 50.0, "val_auroc": 0.5, "time": 498.56}
{"epoch": 26, "training_loss": 20372.238067626953, "training_acc": 50.0, "val_loss": 262.82440185546875, "val_acc": 50.0, "val_auroc": 0.4, "time": 518.79}
{"epoch": 27, "training_loss": 1594.55224609375, "training_acc": 47.5, "val_loss": 326.14444732666016, "val_acc": 50.0, "val_auroc": 0.6, "time": 535.67}
{"epoch": 28, "training_loss": 927.8790817260742, "training_acc": 52.5, "val_loss": 145.8005428314209, "val_acc": 50.0, "val_auroc": 0.4, "time": 555.34}
{"epoch": 29, "training_loss": 551.357780456543, "training_acc": 47.5, "val_loss": 15.887001752853394, "val_acc": 50.0, "val_auroc": 0.31, "time": 573.14}
{"epoch": 30, "training_loss": 76.93583297729492, "training_acc": 50.0, "val_loss": 17.298802137374878, "val_acc": 50.0, "val_auroc": 0.27, "time": 592.0}
{"epoch": 31, "training_loss": 70.6601619720459, "training_acc": 47.5, "val_loss": 16.316746473312378, "val_acc": 50.0, "val_auroc": 0.47, "time": 610.13}
{"epoch": 32, "training_loss": 59.96228885650635, "training_acc": 52.5, "val_loss": 15.271775722503662, "val_acc": 50.0, "val_auroc": 0.46, "time": 629.17}
{"epoch": 33, "training_loss": 61.95597267150879, "training_acc": 47.5, "val_loss": 14.025259017944336, "val_acc": 50.0, "val_auroc": 0.58, "time": 647.8}
{"epoch": 34, "training_loss": 55.47750949859619, "training_acc": 52.5, "val_loss": 15.30213713645935, "val_acc": 50.0, "val_auroc": 0.35, "time": 670.02}
{"epoch": 35, "training_loss": 57.45967483520508, "training_acc": 52.5, "val_loss": 14.027489423751831, "val_acc": 50.0, "val_auroc": 0.43, "time": 687.54}
{"epoch": 36, "training_loss": 56.598527908325195, "training_acc": 47.5, "val_loss": 13.87104868888855, "val_acc": 50.0, "val_auroc": 0.37, "time": 707.72}
{"epoch": 37, "training_loss": 57.699116706848145, "training_acc": 52.5, "val_loss": 13.869184255599976, "val_acc": 50.0, "val_auroc": 0.52, "time": 725.34}
{"epoch": 38, "training_loss": 56.194003105163574, "training_acc": 47.5, "val_loss": 14.145408868789673, "val_acc": 50.0, "val_auroc": 0.56, "time": 745.33}
{"epoch": 39, "training_loss": 57.05052947998047, "training_acc": 47.5, "val_loss": 13.983052968978882, "val_acc": 50.0, "val_auroc": 0.53, "time": 763.77}
{"epoch": 40, "training_loss": 55.49052906036377, "training_acc": 52.5, "val_loss": 14.066956043243408, "val_acc": 50.0, "val_auroc": 0.6, "time": 781.62}
{"epoch": 41, "training_loss": 55.61767101287842, "training_acc": 52.5, "val_loss": 13.881925344467163, "val_acc": 50.0, "val_auroc": 0.55, "time": 798.43}
{"epoch": 42, "training_loss": 55.910850524902344, "training_acc": 47.5, "val_loss": 13.864938020706177, "val_acc": 50.0, "val_auroc": 0.56, "time": 820.42}
{"epoch": 43, "training_loss": 55.13161563873291, "training_acc": 52.5, "val_loss": 15.852283239364624, "val_acc": 50.0, "val_auroc": 0.56, "time": 838.36}
{"epoch": 44, "training_loss": 59.021965980529785, "training_acc": 52.5, "val_loss": 13.942642211914062, "val_acc": 50.0, "val_auroc": 0.63, "time": 858.42}
{"epoch": 45, "training_loss": 56.45686912536621, "training_acc": 47.5, "val_loss": 14.10219430923462, "val_acc": 50.0, "val_auroc": 0.55, "time": 874.96}
{"epoch": 46, "training_loss": 56.78033447265625, "training_acc": 47.5, "val_loss": 13.870033025741577, "val_acc": 50.0, "val_auroc": 0.59, "time": 892.99}
{"epoch": 47, "training_loss": 55.646995544433594, "training_acc": 47.5, "val_loss": 13.98999810218811, "val_acc": 50.0, "val_auroc": 0.32, "time": 910.52}
{"epoch": 48, "training_loss": 55.52414035797119, "training_acc": 52.5, "val_loss": 13.916682004928589, "val_acc": 50.0, "val_auroc": 0.53, "time": 927.57}
{"epoch": 49, "training_loss": 55.39069080352783, "training_acc": 52.5, "val_loss": 13.897520303726196, "val_acc": 50.0, "val_auroc": 0.46, "time": 944.57}
{"epoch": 50, "training_loss": 55.384968757629395, "training_acc": 52.5, "val_loss": 13.920049667358398, "val_acc": 50.0, "val_auroc": 0.53, "time": 963.39}
{"epoch": 51, "training_loss": 55.368746757507324, "training_acc": 52.5, "val_loss": 13.979743719100952, "val_acc": 50.0, "val_auroc": 0.54, "time": 981.65}
{"epoch": 52, "training_loss": 55.48738193511963, "training_acc": 52.5, "val_loss": 13.974031209945679, "val_acc": 50.0, "val_auroc": 0.66, "time": 1001.39}
{"epoch": 53, "training_loss": 55.48128318786621, "training_acc": 52.5, "val_loss": 13.93297553062439, "val_acc": 50.0, "val_auroc": 0.46, "time": 1017.77}
{"epoch": 54, "training_loss": 55.40733528137207, "training_acc": 52.5, "val_loss": 13.908815383911133, "val_acc": 50.0, "val_auroc": 0.495, "time": 1035.21}
{"epoch": 55, "training_loss": 55.361127853393555, "training_acc": 52.5, "val_loss": 13.892921209335327, "val_acc": 50.0, "val_auroc": 0.45, "time": 1053.95}
{"epoch": 56, "training_loss": 55.350104331970215, "training_acc": 52.5, "val_loss": 13.872345685958862, "val_acc": 50.0, "val_auroc": 0.5, "time": 1072.78}
{"epoch": 57, "training_loss": 55.361703872680664, "training_acc": 52.5, "val_loss": 13.863492012023926, "val_acc": 50.0, "val_auroc": 0.5, "time": 1089.7}
{"epoch": 58, "training_loss": 55.42466354370117, "training_acc": 52.5, "val_loss": 13.863195180892944, "val_acc": 50.0, "val_auroc": 0.5, "time": 1109.18}
{"epoch": 59, "training_loss": 55.51643753051758, "training_acc": 47.5, "val_loss": 13.86297345161438, "val_acc": 50.0, "val_auroc": 0.5, "time": 1127.44}
{"epoch": 60, "training_loss": 55.412590980529785, "training_acc": 52.5, "val_loss": 13.87555718421936, "val_acc": 50.0, "val_auroc": 0.5, "time": 1147.11}
{"epoch": 61, "training_loss": 55.337406158447266, "training_acc": 52.5, "val_loss": 13.942087888717651, "val_acc": 50.0, "val_auroc": 0.5, "time": 1163.48}
{"epoch": 62, "training_loss": 55.44866752624512, "training_acc": 52.5, "val_loss": 13.901493549346924, "val_acc": 50.0, "val_auroc": 0.5, "time": 1184.02}
{"epoch": 63, "training_loss": 55.309688568115234, "training_acc": 52.5, "val_loss": 13.878164291381836, "val_acc": 50.0, "val_auroc": 0.5, "time": 1202.14}
{"epoch": 64, "training_loss": 55.35569190979004, "training_acc": 52.5, "val_loss": 13.876476287841797, "val_acc": 50.0, "val_auroc": 0.5, "time": 1222.23}
{"epoch": 65, "training_loss": 55.3544921875, "training_acc": 52.5, "val_loss": 13.873296976089478, "val_acc": 50.0, "val_auroc": 0.5, "time": 1239.23}
{"epoch": 66, "training_loss": 55.357011795043945, "training_acc": 52.5, "val_loss": 13.869377374649048, "val_acc": 50.0, "val_auroc": 0.5, "time": 1258.92}
{"epoch": 67, "training_loss": 55.37017250061035, "training_acc": 52.5, "val_loss": 13.86690616607666, "val_acc": 50.0, "val_auroc": 0.5, "time": 1277.02}
{"epoch": 68, "training_loss": 55.39236640930176, "training_acc": 52.5, "val_loss": 13.865407705307007, "val_acc": 50.0, "val_auroc": 0.5, "time": 1295.43}
{"epoch": 69, "training_loss": 55.40129375457764, "training_acc": 52.5, "val_loss": 13.864811658859253, "val_acc": 50.0, "val_auroc": 0.5, "time": 1312.31}
{"epoch": 70, "training_loss": 55.40542411804199, "training_acc": 52.5, "val_loss": 13.865455389022827, "val_acc": 50.0, "val_auroc": 0.5, "time": 1331.97}
{"epoch": 71, "training_loss": 55.402984619140625, "training_acc": 52.5, "val_loss": 13.867610692977905, "val_acc": 50.0, "val_auroc": 0.5, "time": 1349.48}
{"epoch": 72, "training_loss": 55.38843536376953, "training_acc": 52.5, "val_loss": 13.86880874633789, "val_acc": 50.0, "val_auroc": 0.5, "time": 1366.9}
{"epoch": 73, "training_loss": 55.51051330566406, "training_acc": 52.5, "val_loss": 13.865735530853271, "val_acc": 50.0, "val_auroc": 0.5, "time": 1383.92}
{"epoch": 74, "training_loss": 55.40817832946777, "training_acc": 52.5, "val_loss": 13.866318464279175, "val_acc": 50.0, "val_auroc": 0.5, "time": 1402.13}
{"epoch": 75, "training_loss": 55.39158344268799, "training_acc": 52.5, "val_loss": 13.866586685180664, "val_acc": 50.0, "val_auroc": 0.5, "time": 1418.94}
{"epoch": 76, "training_loss": 55.389092445373535, "training_acc": 52.5, "val_loss": 13.867167234420776, "val_acc": 50.0, "val_auroc": 0.5, "time": 1437.22}
{"epoch": 77, "training_loss": 55.383605003356934, "training_acc": 52.5, "val_loss": 13.868459463119507, "val_acc": 50.0, "val_auroc": 0.5, "time": 1454.02}
{"epoch": 78, "training_loss": 55.37631416320801, "training_acc": 52.5, "val_loss": 13.870837688446045, "val_acc": 50.0, "val_auroc": 0.5, "time": 1473.77}
