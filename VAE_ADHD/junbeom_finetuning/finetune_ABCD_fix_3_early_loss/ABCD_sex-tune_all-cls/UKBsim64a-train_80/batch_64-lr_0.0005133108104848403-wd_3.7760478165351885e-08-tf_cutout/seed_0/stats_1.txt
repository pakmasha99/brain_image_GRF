"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.92492485046387, "training_acc": 55.0, "val_loss": 20.444352626800537, "val_acc": 50.0, "val_auroc": 0.52, "time": 19.72}
{"epoch": 1, "training_loss": 121.62422180175781, "training_acc": 52.5, "val_loss": 14.411423206329346, "val_acc": 50.0, "val_auroc": 0.26, "time": 38.98}
{"epoch": 2, "training_loss": 61.594627380371094, "training_acc": 50.0, "val_loss": 14.766348600387573, "val_acc": 50.0, "val_auroc": 0.5, "time": 56.6}
{"epoch": 3, "training_loss": 57.026665687561035, "training_acc": 52.5, "val_loss": 16.482137441635132, "val_acc": 50.0, "val_auroc": 0.5, "time": 76.18}
{"epoch": 4, "training_loss": 65.71489143371582, "training_acc": 47.5, "val_loss": 14.36194896697998, "val_acc": 50.0, "val_auroc": 0.53, "time": 95.25}
{"epoch": 5, "training_loss": 56.44113731384277, "training_acc": 53.75, "val_loss": 13.870679140090942, "val_acc": 50.0, "val_auroc": 0.37, "time": 114.19}
{"epoch": 6, "training_loss": 55.50924873352051, "training_acc": 47.5, "val_loss": 13.91222357749939, "val_acc": 50.0, "val_auroc": 0.39, "time": 133.28}
{"epoch": 7, "training_loss": 55.364681243896484, "training_acc": 52.5, "val_loss": 13.992176055908203, "val_acc": 50.0, "val_auroc": 0.47, "time": 152.02}
{"epoch": 8, "training_loss": 55.477723121643066, "training_acc": 52.5, "val_loss": 13.87492060661316, "val_acc": 50.0, "val_auroc": 0.53, "time": 170.2}
{"epoch": 9, "training_loss": 55.374290466308594, "training_acc": 51.25, "val_loss": 14.028300046920776, "val_acc": 50.0, "val_auroc": 0.54, "time": 186.91}
{"epoch": 10, "training_loss": 56.38844585418701, "training_acc": 47.5, "val_loss": 13.906575441360474, "val_acc": 50.0, "val_auroc": 0.73, "time": 203.17}
{"epoch": 11, "training_loss": 55.33131408691406, "training_acc": 52.5, "val_loss": 14.335206747055054, "val_acc": 50.0, "val_auroc": 0.66, "time": 220.69}
{"epoch": 12, "training_loss": 56.41958427429199, "training_acc": 52.5, "val_loss": 13.919857740402222, "val_acc": 50.0, "val_auroc": 0.75, "time": 238.53}
{"epoch": 13, "training_loss": 55.662171363830566, "training_acc": 47.5, "val_loss": 13.865100145339966, "val_acc": 50.0, "val_auroc": 0.65, "time": 256.57}
{"epoch": 14, "training_loss": 55.24272632598877, "training_acc": 52.5, "val_loss": 14.200762510299683, "val_acc": 50.0, "val_auroc": 0.81, "time": 273.61}
{"epoch": 15, "training_loss": 56.07896423339844, "training_acc": 52.5, "val_loss": 14.512145519256592, "val_acc": 50.0, "val_auroc": 0.89, "time": 291.75}
{"epoch": 16, "training_loss": 57.08878231048584, "training_acc": 52.5, "val_loss": 14.088674783706665, "val_acc": 50.0, "val_auroc": 0.59, "time": 308.24}
{"epoch": 17, "training_loss": 55.57614040374756, "training_acc": 52.5, "val_loss": 13.863581418991089, "val_acc": 50.0, "val_auroc": 0.53, "time": 326.05}
{"epoch": 18, "training_loss": 55.41436195373535, "training_acc": 52.5, "val_loss": 13.962153196334839, "val_acc": 50.0, "val_auroc": 0.51, "time": 343.86}
{"epoch": 19, "training_loss": 56.26236629486084, "training_acc": 47.5, "val_loss": 13.940881490707397, "val_acc": 50.0, "val_auroc": 0.57, "time": 362.66}
{"epoch": 20, "training_loss": 56.050188064575195, "training_acc": 47.5, "val_loss": 13.87110948562622, "val_acc": 50.0, "val_auroc": 0.6, "time": 380.32}
{"epoch": 21, "training_loss": 55.46173858642578, "training_acc": 53.75, "val_loss": 13.939557075500488, "val_acc": 50.0, "val_auroc": 0.73, "time": 398.22}
{"epoch": 22, "training_loss": 55.39445877075195, "training_acc": 52.5, "val_loss": 14.25042986869812, "val_acc": 50.0, "val_auroc": 0.75, "time": 416.08}
{"epoch": 23, "training_loss": 56.22524070739746, "training_acc": 52.5, "val_loss": 14.19448733329773, "val_acc": 50.0, "val_auroc": 0.82, "time": 435.28}
{"epoch": 24, "training_loss": 56.04345512390137, "training_acc": 52.5, "val_loss": 13.979319334030151, "val_acc": 50.0, "val_auroc": 0.65, "time": 453.69}
{"epoch": 25, "training_loss": 55.52784824371338, "training_acc": 52.5, "val_loss": 13.869235515594482, "val_acc": 50.0, "val_auroc": 0.59, "time": 471.19}
{"epoch": 26, "training_loss": 55.38382911682129, "training_acc": 52.5, "val_loss": 13.860116004943848, "val_acc": 50.0, "val_auroc": 0.56, "time": 489.05}
{"epoch": 27, "training_loss": 55.34829139709473, "training_acc": 52.5, "val_loss": 13.87715220451355, "val_acc": 50.0, "val_auroc": 0.56, "time": 506.88}
{"epoch": 28, "training_loss": 55.642805099487305, "training_acc": 52.5, "val_loss": 13.871653079986572, "val_acc": 50.0, "val_auroc": 0.57, "time": 524.17}
{"epoch": 29, "training_loss": 55.366254806518555, "training_acc": 55.0, "val_loss": 13.858460187911987, "val_acc": 50.0, "val_auroc": 0.56, "time": 541.98}
{"epoch": 30, "training_loss": 55.51564407348633, "training_acc": 47.5, "val_loss": 13.855388164520264, "val_acc": 50.0, "val_auroc": 0.56, "time": 560.67}
{"epoch": 31, "training_loss": 55.30425834655762, "training_acc": 51.25, "val_loss": 13.929060697555542, "val_acc": 50.0, "val_auroc": 0.58, "time": 578.45}
{"epoch": 32, "training_loss": 55.60603427886963, "training_acc": 52.5, "val_loss": 13.966124057769775, "val_acc": 50.0, "val_auroc": 0.63, "time": 595.27}
{"epoch": 33, "training_loss": 55.45818328857422, "training_acc": 52.5, "val_loss": 13.883496522903442, "val_acc": 50.0, "val_auroc": 0.66, "time": 612.74}
{"epoch": 34, "training_loss": 55.3330192565918, "training_acc": 52.5, "val_loss": 13.859885931015015, "val_acc": 50.0, "val_auroc": 0.62, "time": 634.74}
{"epoch": 35, "training_loss": 55.40014457702637, "training_acc": 52.5, "val_loss": 13.855432271957397, "val_acc": 50.0, "val_auroc": 0.6, "time": 652.99}
{"epoch": 36, "training_loss": 55.34419059753418, "training_acc": 52.5, "val_loss": 13.94068717956543, "val_acc": 50.0, "val_auroc": 0.59, "time": 670.09}
{"epoch": 37, "training_loss": 56.010061264038086, "training_acc": 47.5, "val_loss": 14.059442281723022, "val_acc": 50.0, "val_auroc": 0.55, "time": 692.38}
{"epoch": 38, "training_loss": 56.68893814086914, "training_acc": 47.5, "val_loss": 13.961786031723022, "val_acc": 50.0, "val_auroc": 0.58, "time": 711.03}
{"epoch": 39, "training_loss": 56.094844818115234, "training_acc": 47.5, "val_loss": 13.85007381439209, "val_acc": 50.0, "val_auroc": 0.61, "time": 728.95}
{"epoch": 40, "training_loss": 55.40806293487549, "training_acc": 52.5, "val_loss": 13.91195297241211, "val_acc": 50.0, "val_auroc": 0.65, "time": 746.82}
{"epoch": 41, "training_loss": 55.51597213745117, "training_acc": 52.5, "val_loss": 13.924834728240967, "val_acc": 50.0, "val_auroc": 0.64, "time": 764.79}
{"epoch": 42, "training_loss": 55.38372611999512, "training_acc": 52.5, "val_loss": 13.868286609649658, "val_acc": 50.0, "val_auroc": 0.65, "time": 783.04}
{"epoch": 43, "training_loss": 55.32253932952881, "training_acc": 52.5, "val_loss": 13.859633207321167, "val_acc": 50.0, "val_auroc": 0.66, "time": 801.15}
{"epoch": 44, "training_loss": 55.32156562805176, "training_acc": 52.5, "val_loss": 13.862714767456055, "val_acc": 50.0, "val_auroc": 0.68, "time": 818.5}
{"epoch": 45, "training_loss": 55.29705810546875, "training_acc": 52.5, "val_loss": 13.862742185592651, "val_acc": 50.0, "val_auroc": 0.65, "time": 836.31}
{"epoch": 46, "training_loss": 55.32695484161377, "training_acc": 52.5, "val_loss": 13.876608610153198, "val_acc": 50.0, "val_auroc": 0.64, "time": 854.51}
{"epoch": 47, "training_loss": 55.27664089202881, "training_acc": 52.5, "val_loss": 13.945320844650269, "val_acc": 50.0, "val_auroc": 0.64, "time": 873.06}
{"epoch": 48, "training_loss": 55.37782669067383, "training_acc": 52.5, "val_loss": 14.039435386657715, "val_acc": 50.0, "val_auroc": 0.65, "time": 890.76}
{"epoch": 49, "training_loss": 55.69567012786865, "training_acc": 52.5, "val_loss": 14.084137678146362, "val_acc": 50.0, "val_auroc": 0.63, "time": 907.87}
{"epoch": 50, "training_loss": 55.749441146850586, "training_acc": 52.5, "val_loss": 13.95214319229126, "val_acc": 50.0, "val_auroc": 0.66, "time": 925.62}
{"epoch": 51, "training_loss": 55.33072090148926, "training_acc": 52.5, "val_loss": 13.8584303855896, "val_acc": 50.0, "val_auroc": 0.67, "time": 945.08}
{"epoch": 52, "training_loss": 55.20375442504883, "training_acc": 52.5, "val_loss": 13.866398334503174, "val_acc": 50.0, "val_auroc": 0.69, "time": 962.7}
{"epoch": 53, "training_loss": 55.6742057800293, "training_acc": 47.5, "val_loss": 13.886919021606445, "val_acc": 50.0, "val_auroc": 0.69, "time": 980.55}
{"epoch": 54, "training_loss": 55.720181465148926, "training_acc": 47.5, "val_loss": 13.847228288650513, "val_acc": 50.0, "val_auroc": 0.73, "time": 999.33}
{"epoch": 55, "training_loss": 55.43310546875, "training_acc": 53.75, "val_loss": 13.89062762260437, "val_acc": 50.0, "val_auroc": 0.72, "time": 1019.35}
{"epoch": 56, "training_loss": 55.38399887084961, "training_acc": 52.5, "val_loss": 13.909057378768921, "val_acc": 50.0, "val_auroc": 0.76, "time": 1036.83}
{"epoch": 57, "training_loss": 55.340110778808594, "training_acc": 52.5, "val_loss": 13.876336812973022, "val_acc": 50.0, "val_auroc": 0.72, "time": 1054.46}
{"epoch": 58, "training_loss": 55.30479049682617, "training_acc": 52.5, "val_loss": 13.846924304962158, "val_acc": 50.0, "val_auroc": 0.68, "time": 1075.24}
{"epoch": 59, "training_loss": 55.446250915527344, "training_acc": 47.5, "val_loss": 13.844819068908691, "val_acc": 50.0, "val_auroc": 0.67, "time": 1093.89}
{"epoch": 60, "training_loss": 55.39931678771973, "training_acc": 48.75, "val_loss": 13.847501277923584, "val_acc": 50.0, "val_auroc": 0.75, "time": 1112.67}
{"epoch": 61, "training_loss": 55.250844955444336, "training_acc": 52.5, "val_loss": 13.89365553855896, "val_acc": 50.0, "val_auroc": 0.76, "time": 1131.01}
{"epoch": 62, "training_loss": 55.30963134765625, "training_acc": 52.5, "val_loss": 13.943066596984863, "val_acc": 50.0, "val_auroc": 0.75, "time": 1149.45}
{"epoch": 63, "training_loss": 55.41258430480957, "training_acc": 52.5, "val_loss": 13.905630111694336, "val_acc": 50.0, "val_auroc": 0.78, "time": 1167.47}
{"epoch": 64, "training_loss": 55.25887966156006, "training_acc": 52.5, "val_loss": 13.849881887435913, "val_acc": 50.0, "val_auroc": 0.75, "time": 1184.99}
{"epoch": 65, "training_loss": 55.188472747802734, "training_acc": 52.5, "val_loss": 13.858579397201538, "val_acc": 50.0, "val_auroc": 0.77, "time": 1201.45}
{"epoch": 66, "training_loss": 55.564964294433594, "training_acc": 47.5, "val_loss": 13.96153450012207, "val_acc": 50.0, "val_auroc": 0.73, "time": 1222.65}
{"epoch": 67, "training_loss": 56.23535633087158, "training_acc": 47.5, "val_loss": 13.982982635498047, "val_acc": 50.0, "val_auroc": 0.65, "time": 1241.33}
{"epoch": 68, "training_loss": 56.23422718048096, "training_acc": 47.5, "val_loss": 13.870750665664673, "val_acc": 50.0, "val_auroc": 0.66, "time": 1261.27}
{"epoch": 69, "training_loss": 55.594289779663086, "training_acc": 47.5, "val_loss": 13.89667272567749, "val_acc": 50.0, "val_auroc": 0.7, "time": 1279.61}
{"epoch": 70, "training_loss": 55.35005187988281, "training_acc": 52.5, "val_loss": 13.97111177444458, "val_acc": 50.0, "val_auroc": 0.67, "time": 1298.74}
{"epoch": 71, "training_loss": 55.45685863494873, "training_acc": 52.5, "val_loss": 13.938436508178711, "val_acc": 50.0, "val_auroc": 0.68, "time": 1319.92}
{"epoch": 72, "training_loss": 55.41415023803711, "training_acc": 52.5, "val_loss": 13.899887800216675, "val_acc": 50.0, "val_auroc": 0.71, "time": 1339.74}
{"epoch": 73, "training_loss": 55.435781478881836, "training_acc": 52.5, "val_loss": 13.92743468284607, "val_acc": 50.0, "val_auroc": 0.72, "time": 1356.53}
{"epoch": 74, "training_loss": 55.76620674133301, "training_acc": 52.5, "val_loss": 13.927696943283081, "val_acc": 50.0, "val_auroc": 0.74, "time": 1376.55}
{"epoch": 75, "training_loss": 55.49127388000488, "training_acc": 52.5, "val_loss": 13.852719068527222, "val_acc": 50.0, "val_auroc": 0.76, "time": 1396.28}
{"epoch": 76, "training_loss": 55.38570690155029, "training_acc": 52.5, "val_loss": 13.862804174423218, "val_acc": 50.0, "val_auroc": 0.8, "time": 1414.52}
{"epoch": 77, "training_loss": 55.19215488433838, "training_acc": 52.5, "val_loss": 13.975837230682373, "val_acc": 50.0, "val_auroc": 0.8, "time": 1434.77}
{"epoch": 78, "training_loss": 55.39766502380371, "training_acc": 52.5, "val_loss": 14.17595624923706, "val_acc": 50.0, "val_auroc": 0.79, "time": 1453.77}
