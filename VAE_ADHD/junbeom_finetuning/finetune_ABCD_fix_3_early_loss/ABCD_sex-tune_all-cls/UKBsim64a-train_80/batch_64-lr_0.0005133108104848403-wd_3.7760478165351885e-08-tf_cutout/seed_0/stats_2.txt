"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 61.32787322998047, "training_acc": 57.5, "val_loss": 21.623170375823975, "val_acc": 50.0, "val_auroc": 0.76, "time": 20.4}
{"epoch": 1, "training_loss": 96.51580715179443, "training_acc": 52.5, "val_loss": 21.66923761367798, "val_acc": 50.0, "val_auroc": 0.75, "time": 44.84}
{"epoch": 2, "training_loss": 107.64315032958984, "training_acc": 50.0, "val_loss": 14.764171838760376, "val_acc": 50.0, "val_auroc": 0.42, "time": 70.2}
{"epoch": 3, "training_loss": 58.821014404296875, "training_acc": 47.5, "val_loss": 13.85085940361023, "val_acc": 50.0, "val_auroc": 0.61, "time": 89.98}
{"epoch": 4, "training_loss": 55.550724029541016, "training_acc": 51.25, "val_loss": 13.881219625473022, "val_acc": 50.0, "val_auroc": 0.66, "time": 109.07}
{"epoch": 5, "training_loss": 55.580631256103516, "training_acc": 50.0, "val_loss": 14.148215055465698, "val_acc": 50.0, "val_auroc": 0.33, "time": 132.43}
{"epoch": 6, "training_loss": 56.7574462890625, "training_acc": 46.25, "val_loss": 15.478929281234741, "val_acc": 50.0, "val_auroc": 0.3, "time": 154.05}
{"epoch": 7, "training_loss": 59.59303092956543, "training_acc": 52.5, "val_loss": 14.007407426834106, "val_acc": 50.0, "val_auroc": 0.48, "time": 172.53}
{"epoch": 8, "training_loss": 55.03098964691162, "training_acc": 52.5, "val_loss": 14.063442945480347, "val_acc": 50.0, "val_auroc": 0.65, "time": 189.84}
{"epoch": 9, "training_loss": 57.05925941467285, "training_acc": 47.5, "val_loss": 14.02567744255066, "val_acc": 50.0, "val_auroc": 0.69, "time": 211.01}
{"epoch": 10, "training_loss": 56.4669885635376, "training_acc": 47.5, "val_loss": 13.901480436325073, "val_acc": 50.0, "val_auroc": 0.63, "time": 230.31}
{"epoch": 11, "training_loss": 55.19252586364746, "training_acc": 52.5, "val_loss": 14.278173446655273, "val_acc": 50.0, "val_auroc": 0.38, "time": 246.94}
{"epoch": 12, "training_loss": 56.343421936035156, "training_acc": 52.5, "val_loss": 14.193953275680542, "val_acc": 50.0, "val_auroc": 0.44, "time": 265.08}
{"epoch": 13, "training_loss": 55.8682746887207, "training_acc": 52.5, "val_loss": 13.88479471206665, "val_acc": 50.0, "val_auroc": 0.39, "time": 285.91}
{"epoch": 14, "training_loss": 55.32753276824951, "training_acc": 52.5, "val_loss": 13.90214204788208, "val_acc": 50.0, "val_auroc": 0.36, "time": 305.53}
{"epoch": 15, "training_loss": 56.06753063201904, "training_acc": 47.5, "val_loss": 13.86904001235962, "val_acc": 50.0, "val_auroc": 0.36, "time": 322.86}
{"epoch": 16, "training_loss": 55.197110176086426, "training_acc": 55.0, "val_loss": 14.077751636505127, "val_acc": 50.0, "val_auroc": 0.4, "time": 340.02}
{"epoch": 17, "training_loss": 55.91280746459961, "training_acc": 52.5, "val_loss": 14.398561716079712, "val_acc": 50.0, "val_auroc": 0.46, "time": 359.28}
{"epoch": 18, "training_loss": 56.558470726013184, "training_acc": 52.5, "val_loss": 14.058128595352173, "val_acc": 50.0, "val_auroc": 0.8, "time": 377.77}
{"epoch": 19, "training_loss": 55.433597564697266, "training_acc": 52.5, "val_loss": 13.84772539138794, "val_acc": 50.0, "val_auroc": 0.78, "time": 395.3}
{"epoch": 20, "training_loss": 55.66522407531738, "training_acc": 47.5, "val_loss": 13.924168348312378, "val_acc": 50.0, "val_auroc": 0.75, "time": 413.38}
{"epoch": 21, "training_loss": 56.02602005004883, "training_acc": 47.5, "val_loss": 13.853180408477783, "val_acc": 50.0, "val_auroc": 0.74, "time": 432.77}
{"epoch": 22, "training_loss": 55.41273784637451, "training_acc": 50.0, "val_loss": 13.917914628982544, "val_acc": 50.0, "val_auroc": 0.66, "time": 451.99}
{"epoch": 23, "training_loss": 55.302263259887695, "training_acc": 52.5, "val_loss": 14.07863974571228, "val_acc": 50.0, "val_auroc": 0.35, "time": 469.5}
{"epoch": 24, "training_loss": 55.67685604095459, "training_acc": 52.5, "val_loss": 14.218873977661133, "val_acc": 50.0, "val_auroc": 0.28, "time": 487.35}
{"epoch": 25, "training_loss": 56.08514213562012, "training_acc": 52.5, "val_loss": 14.168685674667358, "val_acc": 50.0, "val_auroc": 0.32, "time": 506.54}
{"epoch": 26, "training_loss": 56.097917556762695, "training_acc": 52.5, "val_loss": 14.047027826309204, "val_acc": 50.0, "val_auroc": 0.32, "time": 525.36}
{"epoch": 27, "training_loss": 55.62097930908203, "training_acc": 52.5, "val_loss": 13.988586664199829, "val_acc": 50.0, "val_auroc": 0.3, "time": 542.34}
{"epoch": 28, "training_loss": 55.4686336517334, "training_acc": 52.5, "val_loss": 13.886206150054932, "val_acc": 50.0, "val_auroc": 0.31, "time": 560.55}
{"epoch": 29, "training_loss": 55.448020935058594, "training_acc": 50.0, "val_loss": 13.8890540599823, "val_acc": 50.0, "val_auroc": 0.34, "time": 581.03}
{"epoch": 30, "training_loss": 55.754425048828125, "training_acc": 47.5, "val_loss": 13.89014482498169, "val_acc": 50.0, "val_auroc": 0.39, "time": 600.25}
{"epoch": 31, "training_loss": 55.77828407287598, "training_acc": 47.5, "val_loss": 13.866530656814575, "val_acc": 50.0, "val_auroc": 0.38, "time": 617.42}
{"epoch": 32, "training_loss": 55.52492141723633, "training_acc": 45.0, "val_loss": 13.866182565689087, "val_acc": 50.0, "val_auroc": 0.45, "time": 634.69}
{"epoch": 33, "training_loss": 55.38206672668457, "training_acc": 52.5, "val_loss": 13.86940598487854, "val_acc": 50.0, "val_auroc": 0.51, "time": 655.23}
{"epoch": 34, "training_loss": 55.35608673095703, "training_acc": 52.5, "val_loss": 13.888819217681885, "val_acc": 50.0, "val_auroc": 0.64, "time": 674.44}
{"epoch": 35, "training_loss": 55.49734401702881, "training_acc": 52.5, "val_loss": 13.912966251373291, "val_acc": 50.0, "val_auroc": 0.68, "time": 691.01}
{"epoch": 36, "training_loss": 55.34215450286865, "training_acc": 52.5, "val_loss": 13.876882791519165, "val_acc": 50.0, "val_auroc": 0.75, "time": 708.94}
{"epoch": 37, "training_loss": 55.30791664123535, "training_acc": 52.5, "val_loss": 13.856586217880249, "val_acc": 50.0, "val_auroc": 0.79, "time": 728.59}
{"epoch": 38, "training_loss": 55.48875713348389, "training_acc": 47.5, "val_loss": 13.855990171432495, "val_acc": 50.0, "val_auroc": 0.75, "time": 748.05}
