"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 63.07390213012695, "training_acc": 45.0, "val_loss": 222850340.0, "val_acc": 45.0, "val_auroc": 0.545, "time": 18.47}
{"epoch": 1, "training_loss": 595079361.75, "training_acc": 56.25, "val_loss": 130179.130859375, "val_acc": 55.0, "val_auroc": 0.434, "time": 41.87}
{"epoch": 2, "training_loss": 509220.580078125, "training_acc": 51.25, "val_loss": 3988.4280395507812, "val_acc": 55.0, "val_auroc": 0.455, "time": 66.2}
{"epoch": 3, "training_loss": 13070.473754882812, "training_acc": 56.25, "val_loss": 394.5088577270508, "val_acc": 55.0, "val_auroc": 0.455, "time": 88.23}
{"epoch": 4, "training_loss": 3153.1661376953125, "training_acc": 48.75, "val_loss": 779.2089080810547, "val_acc": 45.0, "val_auroc": 0.545, "time": 106.67}
{"epoch": 5, "training_loss": 2493.539764404297, "training_acc": 48.75, "val_loss": 15.776087045669556, "val_acc": 55.0, "val_auroc": 0.475, "time": 128.56}
{"epoch": 6, "training_loss": 272.55562591552734, "training_acc": 48.75, "val_loss": 112.51321792602539, "val_acc": 55.0, "val_auroc": 0.475, "time": 148.56}
{"epoch": 7, "training_loss": 423.5819511413574, "training_acc": 51.25, "val_loss": 158.43287467956543, "val_acc": 45.0, "val_auroc": 0.545, "time": 167.95}
{"epoch": 8, "training_loss": 637.3065643310547, "training_acc": 43.75, "val_loss": 119.21137809753418, "val_acc": 45.0, "val_auroc": 0.545, "time": 185.06}
{"epoch": 9, "training_loss": 423.45033264160156, "training_acc": 48.75, "val_loss": 36.036198139190674, "val_acc": 55.0, "val_auroc": 0.515, "time": 204.15}
{"epoch": 10, "training_loss": 156.5728759765625, "training_acc": 51.25, "val_loss": 76.92033290863037, "val_acc": 55.0, "val_auroc": 0.515, "time": 223.16}
{"epoch": 11, "training_loss": 289.2273244857788, "training_acc": 51.25, "val_loss": 72.00819492340088, "val_acc": 45.0, "val_auroc": 0.545, "time": 242.72}
{"epoch": 12, "training_loss": 229.08326148986816, "training_acc": 48.75, "val_loss": 32.37560749053955, "val_acc": 55.0, "val_auroc": 0.495, "time": 259.84}
{"epoch": 13, "training_loss": 129.199613571167, "training_acc": 48.75, "val_loss": 21.119351387023926, "val_acc": 55.0, "val_auroc": 0.626, "time": 280.55}
{"epoch": 14, "training_loss": 78.01736450195312, "training_acc": 56.25, "val_loss": 39.70736742019653, "val_acc": 45.0, "val_auroc": 0.586, "time": 299.96}
{"epoch": 15, "training_loss": 122.65874099731445, "training_acc": 53.75, "val_loss": 18.222368955612183, "val_acc": 55.0, "val_auroc": 0.667, "time": 320.66}
{"epoch": 16, "training_loss": 87.96004104614258, "training_acc": 41.25, "val_loss": 44.7860050201416, "val_acc": 55.0, "val_auroc": 0.566, "time": 343.15}
{"epoch": 17, "training_loss": 164.44917678833008, "training_acc": 51.25, "val_loss": 30.5481219291687, "val_acc": 45.0, "val_auroc": 0.576, "time": 362.44}
{"epoch": 18, "training_loss": 106.83046340942383, "training_acc": 48.75, "val_loss": 13.765314817428589, "val_acc": 55.0, "val_auroc": 0.606, "time": 381.78}
{"epoch": 19, "training_loss": 60.20658493041992, "training_acc": 51.25, "val_loss": 13.860254287719727, "val_acc": 55.0, "val_auroc": 0.576, "time": 402.5}
{"epoch": 20, "training_loss": 56.970062255859375, "training_acc": 51.25, "val_loss": 13.745050430297852, "val_acc": 55.0, "val_auroc": 0.616, "time": 420.14}
{"epoch": 21, "training_loss": 55.80220127105713, "training_acc": 51.25, "val_loss": 16.167503595352173, "val_acc": 45.0, "val_auroc": 0.576, "time": 439.7}
{"epoch": 22, "training_loss": 60.780426025390625, "training_acc": 48.75, "val_loss": 13.812212944030762, "val_acc": 55.0, "val_auroc": 0.636, "time": 458.84}
{"epoch": 23, "training_loss": 57.1058931350708, "training_acc": 48.75, "val_loss": 13.759009838104248, "val_acc": 55.0, "val_auroc": 0.566, "time": 479.48}
{"epoch": 24, "training_loss": 56.18643569946289, "training_acc": 51.25, "val_loss": 14.467682838439941, "val_acc": 55.0, "val_auroc": 0.535, "time": 496.92}
{"epoch": 25, "training_loss": 57.59626293182373, "training_acc": 48.75, "val_loss": 13.919333219528198, "val_acc": 55.0, "val_auroc": 0.556, "time": 516.05}
{"epoch": 26, "training_loss": 57.36312675476074, "training_acc": 51.25, "val_loss": 13.907490968704224, "val_acc": 55.0, "val_auroc": 0.576, "time": 535.16}
{"epoch": 27, "training_loss": 56.46719741821289, "training_acc": 51.25, "val_loss": 14.934208393096924, "val_acc": 55.0, "val_auroc": 0.576, "time": 555.42}
{"epoch": 28, "training_loss": 57.97115135192871, "training_acc": 48.75, "val_loss": 13.900995254516602, "val_acc": 55.0, "val_auroc": 0.596, "time": 575.94}
{"epoch": 29, "training_loss": 55.19416809082031, "training_acc": 53.75, "val_loss": 14.209432601928711, "val_acc": 55.0, "val_auroc": 0.626, "time": 595.44}
{"epoch": 30, "training_loss": 59.10113525390625, "training_acc": 51.25, "val_loss": 13.774089813232422, "val_acc": 55.0, "val_auroc": 0.616, "time": 615.05}
{"epoch": 31, "training_loss": 55.51160526275635, "training_acc": 53.75, "val_loss": 15.369096994400024, "val_acc": 45.0, "val_auroc": 0.556, "time": 636.0}
{"epoch": 32, "training_loss": 59.52348327636719, "training_acc": 48.75, "val_loss": 14.163955450057983, "val_acc": 55.0, "val_auroc": 0.545, "time": 653.37}
{"epoch": 33, "training_loss": 56.01446342468262, "training_acc": 48.75, "val_loss": 13.919992446899414, "val_acc": 55.0, "val_auroc": 0.636, "time": 673.0}
{"epoch": 34, "training_loss": 56.995914459228516, "training_acc": 51.25, "val_loss": 13.765932321548462, "val_acc": 55.0, "val_auroc": 0.505, "time": 691.77}
{"epoch": 35, "training_loss": 55.61656188964844, "training_acc": 51.25, "val_loss": 14.409880638122559, "val_acc": 55.0, "val_auroc": 0.465, "time": 712.32}
{"epoch": 36, "training_loss": 56.21438407897949, "training_acc": 48.75, "val_loss": 13.778032064437866, "val_acc": 55.0, "val_auroc": 0.525, "time": 729.31}
{"epoch": 37, "training_loss": 55.994751930236816, "training_acc": 51.25, "val_loss": 13.890224695205688, "val_acc": 55.0, "val_auroc": 0.545, "time": 747.77}
{"epoch": 38, "training_loss": 56.64542198181152, "training_acc": 51.25, "val_loss": 13.886889219284058, "val_acc": 55.0, "val_auroc": 0.545, "time": 766.76}
{"epoch": 39, "training_loss": 56.4517765045166, "training_acc": 51.25, "val_loss": 13.945382833480835, "val_acc": 55.0, "val_auroc": 0.535, "time": 784.76}
