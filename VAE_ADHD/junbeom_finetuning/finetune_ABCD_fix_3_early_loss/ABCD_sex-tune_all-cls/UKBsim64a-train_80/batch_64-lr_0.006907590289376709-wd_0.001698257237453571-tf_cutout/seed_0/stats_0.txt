"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 271.15577697753906, "training_acc": 46.25, "val_loss": 16698327695360.0, "val_acc": 50.0, "val_auroc": 0.49, "time": 20.0}
{"epoch": 1, "training_loss": 54457136444093.94, "training_acc": 45.0, "val_loss": 290068460.0, "val_acc": 50.0, "val_auroc": 0.48, "time": 41.25}
{"epoch": 2, "training_loss": 39802411776.0, "training_acc": 52.5, "val_loss": 35660217.5, "val_acc": 50.0, "val_auroc": 0.5, "time": 63.4}
{"epoch": 3, "training_loss": 119793208.5, "training_acc": 47.5, "val_loss": 12654196.25, "val_acc": 50.0, "val_auroc": 0.51, "time": 85.35}
{"epoch": 4, "training_loss": 39958136.5, "training_acc": 52.5, "val_loss": 6218356.875, "val_acc": 50.0, "val_auroc": 0.54, "time": 102.03}
{"epoch": 5, "training_loss": 22016146.0, "training_acc": 47.5, "val_loss": 1357691.25, "val_acc": 50.0, "val_auroc": 0.47, "time": 120.57}
{"epoch": 6, "training_loss": 4346434.75, "training_acc": 52.5, "val_loss": 64324.4140625, "val_acc": 50.0, "val_auroc": 0.52, "time": 142.45}
{"epoch": 7, "training_loss": 1130294.59375, "training_acc": 45.0, "val_loss": 656606.71875, "val_acc": 50.0, "val_auroc": 0.59, "time": 163.06}
{"epoch": 8, "training_loss": 3045323.625, "training_acc": 47.5, "val_loss": 150215.654296875, "val_acc": 50.0, "val_auroc": 0.49, "time": 180.94}
{"epoch": 9, "training_loss": 825129.21875, "training_acc": 47.5, "val_loss": 358043.0859375, "val_acc": 50.0, "val_auroc": 0.33, "time": 199.06}
{"epoch": 10, "training_loss": 1143205.2265625, "training_acc": 52.5, "val_loss": 83465.263671875, "val_acc": 50.0, "val_auroc": 0.44, "time": 222.87}
{"epoch": 11, "training_loss": 441370.703125, "training_acc": 52.5, "val_loss": 1799777.65625, "val_acc": 50.0, "val_auroc": 0.45, "time": 241.15}
{"epoch": 12, "training_loss": 6523859.4375, "training_acc": 47.5, "val_loss": 2555882.5, "val_acc": 50.0, "val_auroc": 0.56, "time": 258.14}
{"epoch": 13, "training_loss": 8349677.40625, "training_acc": 45.0, "val_loss": 23030.33935546875, "val_acc": 50.0, "val_auroc": 0.65, "time": 279.16}
{"epoch": 14, "training_loss": 93837.130859375, "training_acc": 42.5, "val_loss": 181597.40234375, "val_acc": 50.0, "val_auroc": 0.61, "time": 299.83}
{"epoch": 15, "training_loss": 614699.14453125, "training_acc": 47.5, "val_loss": 54179.3408203125, "val_acc": 50.0, "val_auroc": 0.57, "time": 319.65}
{"epoch": 16, "training_loss": 196475.740234375, "training_acc": 47.5, "val_loss": 10435.362548828125, "val_acc": 50.0, "val_auroc": 0.78, "time": 337.57}
{"epoch": 17, "training_loss": 37105.70654296875, "training_acc": 52.5, "val_loss": 37970.9765625, "val_acc": 50.0, "val_auroc": 0.7, "time": 357.95}
{"epoch": 18, "training_loss": 125752.76025390625, "training_acc": 50.0, "val_loss": 950.1912689208984, "val_acc": 50.0, "val_auroc": 0.84, "time": 378.26}
{"epoch": 19, "training_loss": 16292.62548828125, "training_acc": 60.0, "val_loss": 19526.282958984375, "val_acc": 50.0, "val_auroc": 0.65, "time": 397.53}
{"epoch": 20, "training_loss": 70524.69384765625, "training_acc": 45.0, "val_loss": 3424.4369506835938, "val_acc": 50.0, "val_auroc": 0.8, "time": 415.31}
{"epoch": 21, "training_loss": 17918.13818359375, "training_acc": 47.5, "val_loss": 1896.5718078613281, "val_acc": 50.0, "val_auroc": 0.58, "time": 434.33}
{"epoch": 22, "training_loss": 9182.26123046875, "training_acc": 52.5, "val_loss": 7050.9930419921875, "val_acc": 50.0, "val_auroc": 0.62, "time": 457.51}
{"epoch": 23, "training_loss": 24021.1376953125, "training_acc": 52.5, "val_loss": 3626.1447143554688, "val_acc": 50.0, "val_auroc": 0.51, "time": 479.62}
{"epoch": 24, "training_loss": 14067.654296875, "training_acc": 47.5, "val_loss": 320.3784942626953, "val_acc": 50.0, "val_auroc": 0.51, "time": 498.14}
{"epoch": 25, "training_loss": 1365.0362548828125, "training_acc": 51.25, "val_loss": 496.3531494140625, "val_acc": 50.0, "val_auroc": 0.52, "time": 515.55}
{"epoch": 26, "training_loss": 1787.895751953125, "training_acc": 50.0, "val_loss": 1229.8983001708984, "val_acc": 50.0, "val_auroc": 0.51, "time": 537.46}
{"epoch": 27, "training_loss": 4216.075439453125, "training_acc": 52.5, "val_loss": 282.6246643066406, "val_acc": 50.0, "val_auroc": 0.48, "time": 557.48}
{"epoch": 28, "training_loss": 996.231575012207, "training_acc": 48.75, "val_loss": 242.21014022827148, "val_acc": 50.0, "val_auroc": 0.5, "time": 575.99}
{"epoch": 29, "training_loss": 914.1683349609375, "training_acc": 47.5, "val_loss": 181.3088035583496, "val_acc": 50.0, "val_auroc": 0.48, "time": 595.67}
{"epoch": 30, "training_loss": 440.16056060791016, "training_acc": 55.0, "val_loss": 418.1538772583008, "val_acc": 50.0, "val_auroc": 0.56, "time": 615.67}
{"epoch": 31, "training_loss": 1245.1150131225586, "training_acc": 53.75, "val_loss": 571.3408279418945, "val_acc": 50.0, "val_auroc": 0.48, "time": 635.58}
{"epoch": 32, "training_loss": 2234.0982666015625, "training_acc": 47.5, "val_loss": 558.8556671142578, "val_acc": 50.0, "val_auroc": 0.48, "time": 656.15}
{"epoch": 33, "training_loss": 2031.07861328125, "training_acc": 52.5, "val_loss": 111.21432304382324, "val_acc": 45.0, "val_auroc": 0.49, "time": 676.39}
{"epoch": 34, "training_loss": 948.3646545410156, "training_acc": 50.0, "val_loss": 567.2995758056641, "val_acc": 50.0, "val_auroc": 0.53, "time": 697.31}
{"epoch": 35, "training_loss": 2168.441635131836, "training_acc": 42.5, "val_loss": 225.5594825744629, "val_acc": 50.0, "val_auroc": 0.5, "time": 715.93}
{"epoch": 36, "training_loss": 894.4910888671875, "training_acc": 52.5, "val_loss": 334.72949981689453, "val_acc": 50.0, "val_auroc": 0.48, "time": 735.84}
{"epoch": 37, "training_loss": 1459.4490966796875, "training_acc": 42.5, "val_loss": 236.86893463134766, "val_acc": 50.0, "val_auroc": 0.5, "time": 752.71}
{"epoch": 38, "training_loss": 849.9917907714844, "training_acc": 51.25, "val_loss": 270.01813888549805, "val_acc": 50.0, "val_auroc": 0.5, "time": 771.14}
{"epoch": 39, "training_loss": 1100.5661315917969, "training_acc": 47.5, "val_loss": 367.09400177001953, "val_acc": 50.0, "val_auroc": 0.52, "time": 791.64}
{"epoch": 40, "training_loss": 1126.2982635498047, "training_acc": 53.75, "val_loss": 262.3924255371094, "val_acc": 50.0, "val_auroc": 0.54, "time": 809.97}
{"epoch": 41, "training_loss": 913.4534606933594, "training_acc": 42.5, "val_loss": 90.34354209899902, "val_acc": 45.0, "val_auroc": 0.49, "time": 828.48}
{"epoch": 42, "training_loss": 435.9416046142578, "training_acc": 55.0, "val_loss": 97.36310958862305, "val_acc": 45.0, "val_auroc": 0.54, "time": 848.0}
{"epoch": 43, "training_loss": 358.4632377624512, "training_acc": 52.5, "val_loss": 103.50750923156738, "val_acc": 45.0, "val_auroc": 0.5, "time": 866.59}
{"epoch": 44, "training_loss": 321.95505142211914, "training_acc": 62.5, "val_loss": 210.9187126159668, "val_acc": 50.0, "val_auroc": 0.51, "time": 883.69}
{"epoch": 45, "training_loss": 714.9132843017578, "training_acc": 50.0, "val_loss": 123.67579460144043, "val_acc": 50.0, "val_auroc": 0.53, "time": 903.19}
{"epoch": 46, "training_loss": 641.95849609375, "training_acc": 46.25, "val_loss": 60.2278470993042, "val_acc": 50.0, "val_auroc": 0.52, "time": 924.06}
{"epoch": 47, "training_loss": 611.4950866699219, "training_acc": 46.25, "val_loss": 331.458740234375, "val_acc": 50.0, "val_auroc": 0.57, "time": 941.2}
{"epoch": 48, "training_loss": 1025.6105194091797, "training_acc": 50.0, "val_loss": 74.89068031311035, "val_acc": 50.0, "val_auroc": 0.54, "time": 960.48}
{"epoch": 49, "training_loss": 439.27490234375, "training_acc": 52.5, "val_loss": 169.0042495727539, "val_acc": 50.0, "val_auroc": 0.49, "time": 981.83}
{"epoch": 50, "training_loss": 883.7427368164062, "training_acc": 46.25, "val_loss": 198.111572265625, "val_acc": 50.0, "val_auroc": 0.47, "time": 1001.96}
{"epoch": 51, "training_loss": 800.1794281005859, "training_acc": 50.0, "val_loss": 329.9100875854492, "val_acc": 50.0, "val_auroc": 0.55, "time": 1020.81}
{"epoch": 52, "training_loss": 942.2273292541504, "training_acc": 55.0, "val_loss": 245.77396392822266, "val_acc": 50.0, "val_auroc": 0.51, "time": 1038.18}
{"epoch": 53, "training_loss": 903.7154083251953, "training_acc": 51.25, "val_loss": 246.92974090576172, "val_acc": 50.0, "val_auroc": 0.5, "time": 1057.15}
{"epoch": 54, "training_loss": 839.6603698730469, "training_acc": 52.5, "val_loss": 94.75794792175293, "val_acc": 55.0, "val_auroc": 0.52, "time": 1076.22}
{"epoch": 55, "training_loss": 501.2191162109375, "training_acc": 50.0, "val_loss": 202.0741844177246, "val_acc": 50.0, "val_auroc": 0.57, "time": 1093.6}
{"epoch": 56, "training_loss": 560.3491973876953, "training_acc": 58.75, "val_loss": 291.79819107055664, "val_acc": 50.0, "val_auroc": 0.48, "time": 1111.73}
{"epoch": 57, "training_loss": 986.0336380004883, "training_acc": 52.5, "val_loss": 230.40987014770508, "val_acc": 50.0, "val_auroc": 0.56, "time": 1132.13}
{"epoch": 58, "training_loss": 626.4425392150879, "training_acc": 56.25, "val_loss": 182.95564651489258, "val_acc": 50.0, "val_auroc": 0.56, "time": 1152.03}
{"epoch": 59, "training_loss": 576.2761001586914, "training_acc": 53.75, "val_loss": 265.4214286804199, "val_acc": 50.0, "val_auroc": 0.52, "time": 1171.28}
{"epoch": 60, "training_loss": 863.2134494781494, "training_acc": 51.25, "val_loss": 374.3943405151367, "val_acc": 50.0, "val_auroc": 0.62, "time": 1189.54}
{"epoch": 61, "training_loss": 1398.5356750488281, "training_acc": 47.5, "val_loss": 381.40796661376953, "val_acc": 50.0, "val_auroc": 0.58, "time": 1207.01}
{"epoch": 62, "training_loss": 1451.9168090820312, "training_acc": 52.5, "val_loss": 171.76183700561523, "val_acc": 50.0, "val_auroc": 0.52, "time": 1227.95}
{"epoch": 63, "training_loss": 727.812744140625, "training_acc": 55.0, "val_loss": 684.0388488769531, "val_acc": 50.0, "val_auroc": 0.53, "time": 1245.98}
{"epoch": 64, "training_loss": 2568.6218872070312, "training_acc": 47.5, "val_loss": 259.5435905456543, "val_acc": 50.0, "val_auroc": 0.51, "time": 1267.3}
{"epoch": 65, "training_loss": 1137.0014343261719, "training_acc": 51.25, "val_loss": 62.09263801574707, "val_acc": 55.0, "val_auroc": 0.48, "time": 1285.45}
