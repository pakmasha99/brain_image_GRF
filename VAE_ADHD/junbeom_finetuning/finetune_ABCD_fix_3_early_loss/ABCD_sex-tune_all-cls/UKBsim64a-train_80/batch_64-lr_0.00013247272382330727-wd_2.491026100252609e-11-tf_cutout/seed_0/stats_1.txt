"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 56.762338638305664, "training_acc": 55.0, "val_loss": 14.174786806106567, "val_acc": 50.0, "val_auroc": 0.79, "time": 19.8}
{"epoch": 1, "training_loss": 70.93300437927246, "training_acc": 47.5, "val_loss": 14.106504917144775, "val_acc": 50.0, "val_auroc": 0.79, "time": 45.09}
{"epoch": 2, "training_loss": 56.86703014373779, "training_acc": 47.5, "val_loss": 13.960907459259033, "val_acc": 50.0, "val_auroc": 0.36, "time": 71.9}
{"epoch": 3, "training_loss": 55.60344982147217, "training_acc": 52.5, "val_loss": 14.093483686447144, "val_acc": 50.0, "val_auroc": 0.58, "time": 96.84}
{"epoch": 4, "training_loss": 55.58656024932861, "training_acc": 52.5, "val_loss": 13.848850727081299, "val_acc": 50.0, "val_auroc": 0.59, "time": 115.76}
{"epoch": 5, "training_loss": 55.52170467376709, "training_acc": 52.5, "val_loss": 13.846317529678345, "val_acc": 50.0, "val_auroc": 0.62, "time": 135.98}
{"epoch": 6, "training_loss": 55.428707122802734, "training_acc": 51.25, "val_loss": 13.930727243423462, "val_acc": 50.0, "val_auroc": 0.82, "time": 157.4}
{"epoch": 7, "training_loss": 55.36828327178955, "training_acc": 52.5, "val_loss": 13.932526111602783, "val_acc": 50.0, "val_auroc": 0.79, "time": 178.17}
{"epoch": 8, "training_loss": 55.29569053649902, "training_acc": 52.5, "val_loss": 13.822234869003296, "val_acc": 50.0, "val_auroc": 0.78, "time": 196.85}
{"epoch": 9, "training_loss": 55.105024337768555, "training_acc": 52.5, "val_loss": 13.84282112121582, "val_acc": 50.0, "val_auroc": 0.78, "time": 216.58}
{"epoch": 10, "training_loss": 55.71618843078613, "training_acc": 47.5, "val_loss": 13.757452964782715, "val_acc": 50.0, "val_auroc": 0.77, "time": 238.87}
{"epoch": 11, "training_loss": 55.066725730895996, "training_acc": 65.0, "val_loss": 14.032067060470581, "val_acc": 50.0, "val_auroc": 0.81, "time": 257.95}
{"epoch": 12, "training_loss": 55.648531913757324, "training_acc": 52.5, "val_loss": 14.045898914337158, "val_acc": 50.0, "val_auroc": 0.79, "time": 275.13}
{"epoch": 13, "training_loss": 55.73970413208008, "training_acc": 52.5, "val_loss": 13.826316595077515, "val_acc": 50.0, "val_auroc": 0.75, "time": 297.16}
{"epoch": 14, "training_loss": 55.39462852478027, "training_acc": 52.5, "val_loss": 13.805150985717773, "val_acc": 50.0, "val_auroc": 0.75, "time": 319.01}
{"epoch": 15, "training_loss": 55.08844757080078, "training_acc": 52.5, "val_loss": 13.958771228790283, "val_acc": 50.0, "val_auroc": 0.75, "time": 337.53}
{"epoch": 16, "training_loss": 55.47803974151611, "training_acc": 52.5, "val_loss": 13.94130825996399, "val_acc": 50.0, "val_auroc": 0.74, "time": 354.42}
{"epoch": 17, "training_loss": 55.3868350982666, "training_acc": 52.5, "val_loss": 13.695230484008789, "val_acc": 50.0, "val_auroc": 0.72, "time": 374.55}
{"epoch": 18, "training_loss": 54.78502368927002, "training_acc": 55.0, "val_loss": 13.892713785171509, "val_acc": 50.0, "val_auroc": 0.74, "time": 395.79}
{"epoch": 19, "training_loss": 56.159542083740234, "training_acc": 47.5, "val_loss": 13.818542957305908, "val_acc": 50.0, "val_auroc": 0.74, "time": 415.37}
{"epoch": 20, "training_loss": 55.49370002746582, "training_acc": 47.5, "val_loss": 13.729344606399536, "val_acc": 50.0, "val_auroc": 0.75, "time": 432.9}
{"epoch": 21, "training_loss": 54.77055358886719, "training_acc": 72.5, "val_loss": 13.884156942367554, "val_acc": 50.0, "val_auroc": 0.77, "time": 450.91}
{"epoch": 22, "training_loss": 55.19510841369629, "training_acc": 52.5, "val_loss": 14.098272323608398, "val_acc": 50.0, "val_auroc": 0.8, "time": 471.77}
{"epoch": 23, "training_loss": 55.783371925354004, "training_acc": 52.5, "val_loss": 13.837236166000366, "val_acc": 50.0, "val_auroc": 0.79, "time": 490.25}
{"epoch": 24, "training_loss": 55.08173942565918, "training_acc": 52.5, "val_loss": 13.643049001693726, "val_acc": 50.0, "val_auroc": 0.79, "time": 507.8}
{"epoch": 25, "training_loss": 54.65656852722168, "training_acc": 52.5, "val_loss": 13.580660820007324, "val_acc": 50.0, "val_auroc": 0.79, "time": 528.03}
{"epoch": 26, "training_loss": 54.82358169555664, "training_acc": 57.5, "val_loss": 13.556884527206421, "val_acc": 50.0, "val_auroc": 0.8, "time": 549.81}
{"epoch": 27, "training_loss": 54.36117935180664, "training_acc": 53.75, "val_loss": 13.561943769454956, "val_acc": 50.0, "val_auroc": 0.8, "time": 568.44}
{"epoch": 28, "training_loss": 54.80850028991699, "training_acc": 52.5, "val_loss": 13.62688660621643, "val_acc": 50.0, "val_auroc": 0.79, "time": 586.18}
{"epoch": 29, "training_loss": 55.36947822570801, "training_acc": 50.0, "val_loss": 13.955672979354858, "val_acc": 50.0, "val_auroc": 0.81, "time": 606.36}
{"epoch": 30, "training_loss": 55.8747673034668, "training_acc": 47.5, "val_loss": 13.763478994369507, "val_acc": 50.0, "val_auroc": 0.8, "time": 626.26}
{"epoch": 31, "training_loss": 54.85818576812744, "training_acc": 52.5, "val_loss": 14.445104598999023, "val_acc": 50.0, "val_auroc": 0.76, "time": 644.67}
{"epoch": 32, "training_loss": 56.68608093261719, "training_acc": 52.5, "val_loss": 13.859847784042358, "val_acc": 50.0, "val_auroc": 0.77, "time": 663.03}
{"epoch": 33, "training_loss": 55.07928466796875, "training_acc": 52.5, "val_loss": 13.710147142410278, "val_acc": 50.0, "val_auroc": 0.77, "time": 681.93}
{"epoch": 34, "training_loss": 54.95494842529297, "training_acc": 61.25, "val_loss": 13.701013326644897, "val_acc": 50.0, "val_auroc": 0.74, "time": 703.22}
{"epoch": 35, "training_loss": 55.380066871643066, "training_acc": 56.25, "val_loss": 13.696975708007812, "val_acc": 50.0, "val_auroc": 0.73, "time": 722.32}
{"epoch": 36, "training_loss": 54.9407844543457, "training_acc": 60.0, "val_loss": 13.81152868270874, "val_acc": 50.0, "val_auroc": 0.72, "time": 740.56}
{"epoch": 37, "training_loss": 55.656588554382324, "training_acc": 47.5, "val_loss": 13.966917991638184, "val_acc": 50.0, "val_auroc": 0.72, "time": 758.88}
{"epoch": 38, "training_loss": 56.27835750579834, "training_acc": 47.5, "val_loss": 13.710987567901611, "val_acc": 50.0, "val_auroc": 0.72, "time": 780.92}
{"epoch": 39, "training_loss": 55.19307518005371, "training_acc": 46.25, "val_loss": 13.783378601074219, "val_acc": 50.0, "val_auroc": 0.73, "time": 800.12}
{"epoch": 40, "training_loss": 55.108001708984375, "training_acc": 52.5, "val_loss": 13.901033401489258, "val_acc": 50.0, "val_auroc": 0.74, "time": 817.32}
{"epoch": 41, "training_loss": 55.20849800109863, "training_acc": 52.5, "val_loss": 13.754167556762695, "val_acc": 50.0, "val_auroc": 0.74, "time": 838.9}
{"epoch": 42, "training_loss": 54.97896385192871, "training_acc": 53.75, "val_loss": 13.771713972091675, "val_acc": 50.0, "val_auroc": 0.75, "time": 860.11}
{"epoch": 43, "training_loss": 55.28177452087402, "training_acc": 47.5, "val_loss": 13.731257915496826, "val_acc": 50.0, "val_auroc": 0.75, "time": 879.27}
{"epoch": 44, "training_loss": 55.138710021972656, "training_acc": 51.25, "val_loss": 13.68887186050415, "val_acc": 50.0, "val_auroc": 0.76, "time": 896.94}
{"epoch": 45, "training_loss": 54.789259910583496, "training_acc": 50.0, "val_loss": 13.679178953170776, "val_acc": 50.0, "val_auroc": 0.76, "time": 917.74}
