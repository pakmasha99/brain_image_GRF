"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.62759017944336, "training_acc": 52.5, "val_loss": 13.905109167098999, "val_acc": 50.0, "val_auroc": 0.36, "time": 20.62}
{"epoch": 1, "training_loss": 55.458011627197266, "training_acc": 52.5, "val_loss": 13.900545835494995, "val_acc": 50.0, "val_auroc": 0.53, "time": 38.7}
{"epoch": 2, "training_loss": 55.131513595581055, "training_acc": 52.5, "val_loss": 13.9033842086792, "val_acc": 50.0, "val_auroc": 0.56, "time": 55.0}
{"epoch": 3, "training_loss": 54.93267631530762, "training_acc": 52.5, "val_loss": 13.867934942245483, "val_acc": 50.0, "val_auroc": 0.54, "time": 71.77}
{"epoch": 4, "training_loss": 54.544729232788086, "training_acc": 52.5, "val_loss": 13.845211267471313, "val_acc": 50.0, "val_auroc": 0.56, "time": 88.77}
{"epoch": 5, "training_loss": 54.545228004455566, "training_acc": 60.0, "val_loss": 13.848569393157959, "val_acc": 50.0, "val_auroc": 0.51, "time": 105.56}
{"epoch": 6, "training_loss": 54.075927734375, "training_acc": 66.25, "val_loss": 13.836679458618164, "val_acc": 50.0, "val_auroc": 0.51, "time": 122.39}
{"epoch": 7, "training_loss": 53.83500862121582, "training_acc": 66.25, "val_loss": 13.90836477279663, "val_acc": 50.0, "val_auroc": 0.52, "time": 138.92}
{"epoch": 8, "training_loss": 53.66786289215088, "training_acc": 58.75, "val_loss": 13.845865726470947, "val_acc": 50.0, "val_auroc": 0.53, "time": 155.02}
{"epoch": 9, "training_loss": 53.119096755981445, "training_acc": 75.0, "val_loss": 13.808062076568604, "val_acc": 50.0, "val_auroc": 0.53, "time": 172.46}
{"epoch": 10, "training_loss": 52.67470932006836, "training_acc": 71.25, "val_loss": 13.915878534317017, "val_acc": 50.0, "val_auroc": 0.51, "time": 188.57}
{"epoch": 11, "training_loss": 52.616536140441895, "training_acc": 65.0, "val_loss": 13.852542638778687, "val_acc": 50.0, "val_auroc": 0.54, "time": 204.89}
{"epoch": 12, "training_loss": 52.059696197509766, "training_acc": 67.5, "val_loss": 13.954495191574097, "val_acc": 50.0, "val_auroc": 0.52, "time": 221.46}
{"epoch": 13, "training_loss": 52.19591999053955, "training_acc": 62.5, "val_loss": 14.113754034042358, "val_acc": 50.0, "val_auroc": 0.52, "time": 238.01}
{"epoch": 14, "training_loss": 52.43751239776611, "training_acc": 62.5, "val_loss": 14.143060445785522, "val_acc": 50.0, "val_auroc": 0.52, "time": 253.54}
{"epoch": 15, "training_loss": 51.79336452484131, "training_acc": 63.75, "val_loss": 13.7432861328125, "val_acc": 50.0, "val_auroc": 0.55, "time": 269.52}
{"epoch": 16, "training_loss": 51.235612869262695, "training_acc": 68.75, "val_loss": 14.05801773071289, "val_acc": 50.0, "val_auroc": 0.55, "time": 286.52}
{"epoch": 17, "training_loss": 51.08700466156006, "training_acc": 63.75, "val_loss": 14.146140813827515, "val_acc": 50.0, "val_auroc": 0.54, "time": 303.47}
{"epoch": 18, "training_loss": 50.79423141479492, "training_acc": 62.5, "val_loss": 13.718036413192749, "val_acc": 50.0, "val_auroc": 0.58, "time": 319.87}
{"epoch": 19, "training_loss": 52.24734687805176, "training_acc": 71.25, "val_loss": 13.734182119369507, "val_acc": 50.0, "val_auroc": 0.59, "time": 336.53}
{"epoch": 20, "training_loss": 49.89081859588623, "training_acc": 75.0, "val_loss": 13.792756795883179, "val_acc": 50.0, "val_auroc": 0.59, "time": 353.26}
{"epoch": 21, "training_loss": 49.00825595855713, "training_acc": 75.0, "val_loss": 13.726698160171509, "val_acc": 50.0, "val_auroc": 0.58, "time": 369.76}
{"epoch": 22, "training_loss": 48.658926010131836, "training_acc": 75.0, "val_loss": 13.813620805740356, "val_acc": 50.0, "val_auroc": 0.58, "time": 386.82}
{"epoch": 23, "training_loss": 47.65861225128174, "training_acc": 76.25, "val_loss": 13.718234300613403, "val_acc": 50.0, "val_auroc": 0.57, "time": 403.17}
{"epoch": 24, "training_loss": 48.43922424316406, "training_acc": 76.25, "val_loss": 13.705246448516846, "val_acc": 55.0, "val_auroc": 0.57, "time": 419.74}
{"epoch": 25, "training_loss": 47.80617713928223, "training_acc": 80.0, "val_loss": 13.84265422821045, "val_acc": 55.0, "val_auroc": 0.55, "time": 436.21}
{"epoch": 26, "training_loss": 46.919602394104004, "training_acc": 77.5, "val_loss": 13.739956617355347, "val_acc": 55.0, "val_auroc": 0.56, "time": 452.78}
{"epoch": 27, "training_loss": 46.62465000152588, "training_acc": 78.75, "val_loss": 14.181588888168335, "val_acc": 50.0, "val_auroc": 0.49, "time": 468.81}
{"epoch": 28, "training_loss": 48.68837547302246, "training_acc": 65.0, "val_loss": 13.78166675567627, "val_acc": 55.0, "val_auroc": 0.55, "time": 485.43}
{"epoch": 29, "training_loss": 46.87033271789551, "training_acc": 80.0, "val_loss": 13.863211870193481, "val_acc": 55.0, "val_auroc": 0.54, "time": 502.11}
{"epoch": 30, "training_loss": 45.459829330444336, "training_acc": 85.0, "val_loss": 14.341373443603516, "val_acc": 50.0, "val_auroc": 0.5, "time": 517.81}
{"epoch": 31, "training_loss": 47.872188568115234, "training_acc": 68.75, "val_loss": 13.880760669708252, "val_acc": 55.0, "val_auroc": 0.55, "time": 534.07}
{"epoch": 32, "training_loss": 46.550941467285156, "training_acc": 78.75, "val_loss": 13.884763717651367, "val_acc": 60.0, "val_auroc": 0.54, "time": 550.69}
{"epoch": 33, "training_loss": 43.830780029296875, "training_acc": 81.25, "val_loss": 13.866411447525024, "val_acc": 55.0, "val_auroc": 0.53, "time": 567.56}
{"epoch": 34, "training_loss": 43.7291316986084, "training_acc": 81.25, "val_loss": 13.832014799118042, "val_acc": 60.0, "val_auroc": 0.55, "time": 583.08}
{"epoch": 35, "training_loss": 43.69752883911133, "training_acc": 82.5, "val_loss": 13.882668018341064, "val_acc": 60.0, "val_auroc": 0.55, "time": 599.6}
{"epoch": 36, "training_loss": 43.86338138580322, "training_acc": 83.75, "val_loss": 13.878068923950195, "val_acc": 60.0, "val_auroc": 0.55, "time": 615.54}
{"epoch": 37, "training_loss": 43.81442356109619, "training_acc": 78.75, "val_loss": 14.033643007278442, "val_acc": 60.0, "val_auroc": 0.59, "time": 632.1}
{"epoch": 38, "training_loss": 46.872347831726074, "training_acc": 71.25, "val_loss": 13.916383981704712, "val_acc": 60.0, "val_auroc": 0.55, "time": 648.66}
{"epoch": 39, "training_loss": 43.22341728210449, "training_acc": 81.25, "val_loss": 14.299792051315308, "val_acc": 50.0, "val_auroc": 0.49, "time": 664.44}
{"epoch": 40, "training_loss": 44.51424598693848, "training_acc": 73.75, "val_loss": 14.046629667282104, "val_acc": 50.0, "val_auroc": 0.56, "time": 680.84}
{"epoch": 41, "training_loss": 43.72534465789795, "training_acc": 78.75, "val_loss": 14.031696319580078, "val_acc": 55.0, "val_auroc": 0.55, "time": 697.65}
{"epoch": 42, "training_loss": 42.02840328216553, "training_acc": 83.75, "val_loss": 13.960716724395752, "val_acc": 55.0, "val_auroc": 0.57, "time": 713.9}
{"epoch": 43, "training_loss": 41.445356369018555, "training_acc": 85.0, "val_loss": 14.037156105041504, "val_acc": 55.0, "val_auroc": 0.53, "time": 729.51}
