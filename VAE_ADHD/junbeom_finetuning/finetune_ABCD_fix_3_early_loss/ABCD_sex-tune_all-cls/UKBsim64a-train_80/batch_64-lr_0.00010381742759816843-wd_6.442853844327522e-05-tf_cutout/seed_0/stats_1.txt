"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 57.41843795776367, "training_acc": 40.0, "val_loss": 13.944473266601562, "val_acc": 50.0, "val_auroc": 0.63, "time": 20.97}
{"epoch": 1, "training_loss": 58.954097747802734, "training_acc": 47.5, "val_loss": 13.895735740661621, "val_acc": 50.0, "val_auroc": 0.57, "time": 46.54}
{"epoch": 2, "training_loss": 55.32139015197754, "training_acc": 50.0, "val_loss": 14.165780544281006, "val_acc": 50.0, "val_auroc": 0.68, "time": 72.1}
{"epoch": 3, "training_loss": 55.94242286682129, "training_acc": 52.5, "val_loss": 13.75309944152832, "val_acc": 50.0, "val_auroc": 0.69, "time": 96.23}
{"epoch": 4, "training_loss": 55.101579666137695, "training_acc": 52.5, "val_loss": 13.81791353225708, "val_acc": 50.0, "val_auroc": 0.8, "time": 118.44}
{"epoch": 5, "training_loss": 55.72397994995117, "training_acc": 52.5, "val_loss": 13.97844672203064, "val_acc": 50.0, "val_auroc": 0.78, "time": 138.96}
{"epoch": 6, "training_loss": 55.78889179229736, "training_acc": 52.5, "val_loss": 13.839219808578491, "val_acc": 50.0, "val_auroc": 0.81, "time": 161.08}
{"epoch": 7, "training_loss": 55.23783874511719, "training_acc": 53.75, "val_loss": 13.727809190750122, "val_acc": 50.0, "val_auroc": 0.79, "time": 181.28}
{"epoch": 8, "training_loss": 55.126352310180664, "training_acc": 51.25, "val_loss": 13.695029020309448, "val_acc": 50.0, "val_auroc": 0.75, "time": 201.25}
{"epoch": 9, "training_loss": 55.133103370666504, "training_acc": 56.25, "val_loss": 13.659287691116333, "val_acc": 50.0, "val_auroc": 0.76, "time": 221.17}
{"epoch": 10, "training_loss": 54.870683670043945, "training_acc": 60.0, "val_loss": 13.612793684005737, "val_acc": 50.0, "val_auroc": 0.78, "time": 241.76}
{"epoch": 11, "training_loss": 54.58900737762451, "training_acc": 57.5, "val_loss": 13.616845607757568, "val_acc": 50.0, "val_auroc": 0.76, "time": 262.35}
{"epoch": 12, "training_loss": 54.77158164978027, "training_acc": 52.5, "val_loss": 13.487123250961304, "val_acc": 50.0, "val_auroc": 0.77, "time": 280.9}
{"epoch": 13, "training_loss": 54.658185958862305, "training_acc": 57.5, "val_loss": 13.417693376541138, "val_acc": 50.0, "val_auroc": 0.76, "time": 301.34}
{"epoch": 14, "training_loss": 54.37729740142822, "training_acc": 53.75, "val_loss": 13.92835021018982, "val_acc": 50.0, "val_auroc": 0.76, "time": 320.44}
{"epoch": 15, "training_loss": 56.71275520324707, "training_acc": 52.5, "val_loss": 13.545228242874146, "val_acc": 50.0, "val_auroc": 0.76, "time": 340.12}
{"epoch": 16, "training_loss": 55.51205825805664, "training_acc": 55.0, "val_loss": 13.301390409469604, "val_acc": 50.0, "val_auroc": 0.78, "time": 361.21}
{"epoch": 17, "training_loss": 53.81338691711426, "training_acc": 62.5, "val_loss": 13.285859823226929, "val_acc": 50.0, "val_auroc": 0.79, "time": 379.99}
{"epoch": 18, "training_loss": 53.56260395050049, "training_acc": 66.25, "val_loss": 13.261922597885132, "val_acc": 50.0, "val_auroc": 0.81, "time": 400.21}
{"epoch": 19, "training_loss": 54.47732162475586, "training_acc": 63.75, "val_loss": 13.123197555541992, "val_acc": 50.0, "val_auroc": 0.8, "time": 422.24}
{"epoch": 20, "training_loss": 53.11173439025879, "training_acc": 67.5, "val_loss": 13.246042728424072, "val_acc": 55.0, "val_auroc": 0.82, "time": 442.06}
{"epoch": 21, "training_loss": 52.850029945373535, "training_acc": 68.75, "val_loss": 13.496944904327393, "val_acc": 50.0, "val_auroc": 0.82, "time": 464.92}
{"epoch": 22, "training_loss": 54.913320541381836, "training_acc": 52.5, "val_loss": 13.650702238082886, "val_acc": 50.0, "val_auroc": 0.82, "time": 485.56}
{"epoch": 23, "training_loss": 55.02084159851074, "training_acc": 53.75, "val_loss": 13.131946325302124, "val_acc": 50.0, "val_auroc": 0.82, "time": 505.16}
{"epoch": 24, "training_loss": 53.328829765319824, "training_acc": 62.5, "val_loss": 13.002971410751343, "val_acc": 50.0, "val_auroc": 0.82, "time": 524.63}
{"epoch": 25, "training_loss": 52.689106941223145, "training_acc": 67.5, "val_loss": 12.847572565078735, "val_acc": 50.0, "val_auroc": 0.84, "time": 545.81}
{"epoch": 26, "training_loss": 53.03606986999512, "training_acc": 61.25, "val_loss": 12.723089456558228, "val_acc": 50.0, "val_auroc": 0.83, "time": 565.5}
{"epoch": 27, "training_loss": 51.48429203033447, "training_acc": 67.5, "val_loss": 12.391084432601929, "val_acc": 45.0, "val_auroc": 0.83, "time": 585.26}
{"epoch": 28, "training_loss": 52.72347354888916, "training_acc": 57.5, "val_loss": 16.177587509155273, "val_acc": 50.0, "val_auroc": 0.84, "time": 604.75}
{"epoch": 29, "training_loss": 63.696577072143555, "training_acc": 47.5, "val_loss": 13.689321279525757, "val_acc": 50.0, "val_auroc": 0.83, "time": 625.13}
{"epoch": 30, "training_loss": 54.150054931640625, "training_acc": 55.0, "val_loss": 16.492656469345093, "val_acc": 50.0, "val_auroc": 0.42, "time": 644.84}
{"epoch": 31, "training_loss": 62.093711853027344, "training_acc": 52.5, "val_loss": 14.208450317382812, "val_acc": 50.0, "val_auroc": 0.8, "time": 668.22}
{"epoch": 32, "training_loss": 55.351704597473145, "training_acc": 52.5, "val_loss": 13.637290000915527, "val_acc": 50.0, "val_auroc": 0.83, "time": 688.22}
{"epoch": 33, "training_loss": 55.178415298461914, "training_acc": 62.5, "val_loss": 13.74963641166687, "val_acc": 50.0, "val_auroc": 0.81, "time": 709.84}
{"epoch": 34, "training_loss": 55.417245864868164, "training_acc": 47.5, "val_loss": 13.626852035522461, "val_acc": 50.0, "val_auroc": 0.79, "time": 729.54}
{"epoch": 35, "training_loss": 55.568281173706055, "training_acc": 55.0, "val_loss": 13.703625202178955, "val_acc": 50.0, "val_auroc": 0.77, "time": 753.21}
{"epoch": 36, "training_loss": 54.76305294036865, "training_acc": 52.5, "val_loss": 13.689912557601929, "val_acc": 50.0, "val_auroc": 0.77, "time": 773.15}
{"epoch": 37, "training_loss": 54.97778511047363, "training_acc": 47.5, "val_loss": 13.914045095443726, "val_acc": 50.0, "val_auroc": 0.78, "time": 795.97}
{"epoch": 38, "training_loss": 56.31193923950195, "training_acc": 47.5, "val_loss": 13.840411901473999, "val_acc": 50.0, "val_auroc": 0.78, "time": 815.41}
{"epoch": 39, "training_loss": 55.889404296875, "training_acc": 47.5, "val_loss": 13.640990257263184, "val_acc": 50.0, "val_auroc": 0.78, "time": 835.07}
{"epoch": 40, "training_loss": 54.864946365356445, "training_acc": 53.75, "val_loss": 13.755543231964111, "val_acc": 50.0, "val_auroc": 0.77, "time": 855.12}
{"epoch": 41, "training_loss": 55.12864112854004, "training_acc": 52.5, "val_loss": 13.696926832199097, "val_acc": 50.0, "val_auroc": 0.77, "time": 876.0}
{"epoch": 42, "training_loss": 54.731197357177734, "training_acc": 51.25, "val_loss": 13.624168634414673, "val_acc": 50.0, "val_auroc": 0.8, "time": 894.56}
{"epoch": 43, "training_loss": 54.676191329956055, "training_acc": 66.25, "val_loss": 13.606805801391602, "val_acc": 50.0, "val_auroc": 0.81, "time": 914.6}
{"epoch": 44, "training_loss": 54.654520988464355, "training_acc": 68.75, "val_loss": 13.534371852874756, "val_acc": 50.0, "val_auroc": 0.83, "time": 934.88}
{"epoch": 45, "training_loss": 54.29981994628906, "training_acc": 61.25, "val_loss": 13.454997539520264, "val_acc": 50.0, "val_auroc": 0.81, "time": 957.26}
{"epoch": 46, "training_loss": 54.11367893218994, "training_acc": 58.75, "val_loss": 13.403005599975586, "val_acc": 50.0, "val_auroc": 0.8, "time": 975.44}
