"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 58.400221824645996, "training_acc": 42.5, "val_loss": 14.113640785217285, "val_acc": 50.0, "val_auroc": 0.41, "time": 23.23}
{"epoch": 1, "training_loss": 55.54277229309082, "training_acc": 52.5, "val_loss": 15.048397779464722, "val_acc": 50.0, "val_auroc": 0.51, "time": 48.26}
{"epoch": 2, "training_loss": 57.692073822021484, "training_acc": 52.5, "val_loss": 13.87586236000061, "val_acc": 50.0, "val_auroc": 0.7, "time": 71.05}
{"epoch": 3, "training_loss": 55.85721683502197, "training_acc": 47.5, "val_loss": 14.305353164672852, "val_acc": 50.0, "val_auroc": 0.35, "time": 95.96}
{"epoch": 4, "training_loss": 56.002418518066406, "training_acc": 52.5, "val_loss": 14.124113321304321, "val_acc": 50.0, "val_auroc": 0.2, "time": 114.4}
{"epoch": 5, "training_loss": 55.675458908081055, "training_acc": 53.75, "val_loss": 13.861554861068726, "val_acc": 50.0, "val_auroc": 0.67, "time": 138.86}
{"epoch": 6, "training_loss": 55.75378227233887, "training_acc": 47.5, "val_loss": 13.91384243965149, "val_acc": 50.0, "val_auroc": 0.73, "time": 158.78}
{"epoch": 7, "training_loss": 55.28306198120117, "training_acc": 52.5, "val_loss": 14.407644271850586, "val_acc": 50.0, "val_auroc": 0.66, "time": 180.42}
{"epoch": 8, "training_loss": 56.71595001220703, "training_acc": 52.5, "val_loss": 14.075547456741333, "val_acc": 50.0, "val_auroc": 0.47, "time": 197.14}
{"epoch": 9, "training_loss": 55.385677337646484, "training_acc": 52.5, "val_loss": 13.88154149055481, "val_acc": 50.0, "val_auroc": 0.46, "time": 220.06}
{"epoch": 10, "training_loss": 55.71358776092529, "training_acc": 47.5, "val_loss": 13.924945592880249, "val_acc": 50.0, "val_auroc": 0.47, "time": 239.11}
{"epoch": 11, "training_loss": 55.76258850097656, "training_acc": 47.5, "val_loss": 13.853886127471924, "val_acc": 50.0, "val_auroc": 0.69, "time": 261.17}
{"epoch": 12, "training_loss": 55.3210506439209, "training_acc": 52.5, "val_loss": 14.009121656417847, "val_acc": 50.0, "val_auroc": 0.8, "time": 278.58}
{"epoch": 13, "training_loss": 55.510987281799316, "training_acc": 52.5, "val_loss": 13.963680267333984, "val_acc": 50.0, "val_auroc": 0.88, "time": 299.6}
{"epoch": 14, "training_loss": 55.351014137268066, "training_acc": 52.5, "val_loss": 13.786685466766357, "val_acc": 50.0, "val_auroc": 0.93, "time": 319.06}
{"epoch": 15, "training_loss": 55.56200408935547, "training_acc": 45.0, "val_loss": 13.767499923706055, "val_acc": 50.0, "val_auroc": 0.85, "time": 339.03}
{"epoch": 16, "training_loss": 54.94490623474121, "training_acc": 58.75, "val_loss": 13.97157073020935, "val_acc": 50.0, "val_auroc": 0.8, "time": 358.06}
{"epoch": 17, "training_loss": 55.510273933410645, "training_acc": 52.5, "val_loss": 14.209386110305786, "val_acc": 50.0, "val_auroc": 0.75, "time": 379.4}
{"epoch": 18, "training_loss": 55.897216796875, "training_acc": 52.5, "val_loss": 13.972610235214233, "val_acc": 50.0, "val_auroc": 0.75, "time": 400.68}
{"epoch": 19, "training_loss": 55.118059158325195, "training_acc": 52.5, "val_loss": 13.822023868560791, "val_acc": 50.0, "val_auroc": 0.77, "time": 421.94}
{"epoch": 20, "training_loss": 55.35621452331543, "training_acc": 57.5, "val_loss": 13.868534564971924, "val_acc": 50.0, "val_auroc": 0.86, "time": 439.72}
{"epoch": 21, "training_loss": 55.71971416473389, "training_acc": 47.5, "val_loss": 13.803566694259644, "val_acc": 50.0, "val_auroc": 0.91, "time": 460.47}
{"epoch": 22, "training_loss": 55.25795078277588, "training_acc": 52.5, "val_loss": 13.83476972579956, "val_acc": 50.0, "val_auroc": 0.87, "time": 480.0}
{"epoch": 23, "training_loss": 54.951194763183594, "training_acc": 52.5, "val_loss": 13.992904424667358, "val_acc": 50.0, "val_auroc": 0.88, "time": 498.79}
{"epoch": 24, "training_loss": 55.34495735168457, "training_acc": 52.5, "val_loss": 14.127010107040405, "val_acc": 50.0, "val_auroc": 0.9, "time": 516.29}
{"epoch": 25, "training_loss": 55.77078437805176, "training_acc": 52.5, "val_loss": 13.98352861404419, "val_acc": 50.0, "val_auroc": 0.88, "time": 538.38}
{"epoch": 26, "training_loss": 55.74399185180664, "training_acc": 52.5, "val_loss": 13.862332105636597, "val_acc": 50.0, "val_auroc": 0.83, "time": 556.75}
{"epoch": 27, "training_loss": 54.8486328125, "training_acc": 52.5, "val_loss": 13.848791122436523, "val_acc": 50.0, "val_auroc": 0.8, "time": 578.94}
{"epoch": 28, "training_loss": 55.06413459777832, "training_acc": 52.5, "val_loss": 13.761323690414429, "val_acc": 50.0, "val_auroc": 0.81, "time": 598.59}
{"epoch": 29, "training_loss": 54.88652229309082, "training_acc": 57.5, "val_loss": 13.8427734375, "val_acc": 50.0, "val_auroc": 0.8, "time": 619.01}
{"epoch": 30, "training_loss": 55.52150535583496, "training_acc": 47.5, "val_loss": 13.785897493362427, "val_acc": 50.0, "val_auroc": 0.76, "time": 638.09}
{"epoch": 31, "training_loss": 55.16169357299805, "training_acc": 46.25, "val_loss": 13.826029300689697, "val_acc": 50.0, "val_auroc": 0.74, "time": 659.77}
{"epoch": 32, "training_loss": 54.67002868652344, "training_acc": 52.5, "val_loss": 13.816831111907959, "val_acc": 50.0, "val_auroc": 0.74, "time": 679.61}
{"epoch": 33, "training_loss": 54.630245208740234, "training_acc": 52.5, "val_loss": 13.731249570846558, "val_acc": 50.0, "val_auroc": 0.79, "time": 701.64}
{"epoch": 34, "training_loss": 54.650428771972656, "training_acc": 61.25, "val_loss": 13.672723770141602, "val_acc": 50.0, "val_auroc": 0.8, "time": 720.59}
{"epoch": 35, "training_loss": 54.63134765625, "training_acc": 61.25, "val_loss": 13.658478260040283, "val_acc": 50.0, "val_auroc": 0.82, "time": 743.71}
{"epoch": 36, "training_loss": 54.02425956726074, "training_acc": 58.75, "val_loss": 13.59505295753479, "val_acc": 50.0, "val_auroc": 0.81, "time": 763.44}
{"epoch": 37, "training_loss": 54.411373138427734, "training_acc": 62.5, "val_loss": 13.579236268997192, "val_acc": 50.0, "val_auroc": 0.81, "time": 787.44}
{"epoch": 38, "training_loss": 54.20116424560547, "training_acc": 53.75, "val_loss": 13.64534616470337, "val_acc": 50.0, "val_auroc": 0.84, "time": 805.43}
{"epoch": 39, "training_loss": 54.01340389251709, "training_acc": 53.75, "val_loss": 14.005537033081055, "val_acc": 50.0, "val_auroc": 0.82, "time": 824.74}
{"epoch": 40, "training_loss": 54.56321430206299, "training_acc": 52.5, "val_loss": 13.591564893722534, "val_acc": 50.0, "val_auroc": 0.77, "time": 846.77}
{"epoch": 41, "training_loss": 53.47859573364258, "training_acc": 75.0, "val_loss": 14.046138525009155, "val_acc": 60.0, "val_auroc": 0.78, "time": 867.33}
{"epoch": 42, "training_loss": 56.695664405822754, "training_acc": 47.5, "val_loss": 13.62342357635498, "val_acc": 50.0, "val_auroc": 0.79, "time": 885.69}
{"epoch": 43, "training_loss": 54.22130012512207, "training_acc": 52.5, "val_loss": 13.982008695602417, "val_acc": 50.0, "val_auroc": 0.63, "time": 906.92}
{"epoch": 44, "training_loss": 54.90329551696777, "training_acc": 52.5, "val_loss": 14.108506441116333, "val_acc": 50.0, "val_auroc": 0.52, "time": 926.16}
{"epoch": 45, "training_loss": 55.060142517089844, "training_acc": 52.5, "val_loss": 13.961714506149292, "val_acc": 50.0, "val_auroc": 0.46, "time": 946.77}
{"epoch": 46, "training_loss": 54.77412033081055, "training_acc": 52.5, "val_loss": 13.8931143283844, "val_acc": 50.0, "val_auroc": 0.43, "time": 964.69}
{"epoch": 47, "training_loss": 54.56527328491211, "training_acc": 57.5, "val_loss": 13.884085416793823, "val_acc": 50.0, "val_auroc": 0.43, "time": 984.82}
{"epoch": 48, "training_loss": 54.55993461608887, "training_acc": 63.75, "val_loss": 13.929907083511353, "val_acc": 50.0, "val_auroc": 0.49, "time": 1004.36}
{"epoch": 49, "training_loss": 54.32415199279785, "training_acc": 52.5, "val_loss": 14.105843305587769, "val_acc": 50.0, "val_auroc": 0.53, "time": 1025.48}
{"epoch": 50, "training_loss": 54.40800666809082, "training_acc": 52.5, "val_loss": 13.847590684890747, "val_acc": 50.0, "val_auroc": 0.53, "time": 1043.75}
{"epoch": 51, "training_loss": 53.57732677459717, "training_acc": 65.0, "val_loss": 13.857624530792236, "val_acc": 50.0, "val_auroc": 0.51, "time": 1064.49}
{"epoch": 52, "training_loss": 53.66205310821533, "training_acc": 65.0, "val_loss": 13.920916318893433, "val_acc": 50.0, "val_auroc": 0.57, "time": 1085.07}
{"epoch": 53, "training_loss": 53.954413414001465, "training_acc": 53.75, "val_loss": 14.024081230163574, "val_acc": 50.0, "val_auroc": 0.59, "time": 1107.56}
{"epoch": 54, "training_loss": 53.9482536315918, "training_acc": 58.75, "val_loss": 13.672702312469482, "val_acc": 50.0, "val_auroc": 0.63, "time": 1127.28}
{"epoch": 55, "training_loss": 52.47409152984619, "training_acc": 71.25, "val_loss": 13.975861072540283, "val_acc": 50.0, "val_auroc": 0.69, "time": 1149.17}
{"epoch": 56, "training_loss": 53.74504566192627, "training_acc": 52.5, "val_loss": 13.776521682739258, "val_acc": 50.0, "val_auroc": 0.69, "time": 1168.8}
