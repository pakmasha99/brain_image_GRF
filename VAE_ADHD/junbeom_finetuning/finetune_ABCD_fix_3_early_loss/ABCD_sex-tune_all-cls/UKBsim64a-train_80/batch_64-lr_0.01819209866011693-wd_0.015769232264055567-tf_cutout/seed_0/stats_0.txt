"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 766.4413909912109, "training_acc": 46.25, "val_loss": 4.264911210608944e+27, "val_acc": 50.0, "val_auroc": 0.55, "time": 20.6}
{"epoch": 1, "training_loss": 1.5698661625977844e+28, "training_acc": 52.5, "val_loss": 3.849838070727354e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 44.05}
{"epoch": 2, "training_loss": 1.4179544950326633e+28, "training_acc": 52.5, "val_loss": 3.4896107903257166e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 66.84}
{"epoch": 3, "training_loss": 1.289130757592802e+28, "training_acc": 52.5, "val_loss": 3.1641755449866215e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 89.74}
{"epoch": 4, "training_loss": 1.1616118837991336e+28, "training_acc": 52.5, "val_loss": 2.85942537164714e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 109.59}
{"epoch": 5, "training_loss": 1.0438838038900274e+28, "training_acc": 52.5, "val_loss": 2.5875740440259156e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 130.7}
{"epoch": 6, "training_loss": 9.490709040372794e+27, "training_acc": 52.5, "val_loss": 2.3418484711014047e+27, "val_acc": 50.0, "val_auroc": 0.55, "time": 152.24}
{"epoch": 7, "training_loss": 8.585408364070079e+27, "training_acc": 52.5, "val_loss": 2.1201180539330937e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 174.87}
{"epoch": 8, "training_loss": 7.777409097667841e+27, "training_acc": 52.5, "val_loss": 1.9198919286687095e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 192.76}
{"epoch": 9, "training_loss": 7.074692630817941e+27, "training_acc": 52.5, "val_loss": 1.7383114033791496e+27, "val_acc": 50.0, "val_auroc": 0.55, "time": 213.79}
{"epoch": 10, "training_loss": 6.401240964210289e+27, "training_acc": 52.5, "val_loss": 1.5747695801843887e+27, "val_acc": 50.0, "val_auroc": 0.55, "time": 235.43}
{"epoch": 11, "training_loss": 5.820278099548236e+27, "training_acc": 52.5, "val_loss": 1.4110662557452625e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 254.4}
{"epoch": 12, "training_loss": 5.18846066052797e+27, "training_acc": 52.5, "val_loss": 1.2778570594669448e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 273.39}
{"epoch": 13, "training_loss": 4.711880615668386e+27, "training_acc": 52.5, "val_loss": 1.1572161833283677e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 294.87}
{"epoch": 14, "training_loss": 4.29695634101147e+27, "training_acc": 52.5, "val_loss": 1.0481387409461157e+27, "val_acc": 50.0, "val_auroc": 0.54, "time": 314.97}
{"epoch": 15, "training_loss": 3.833431425867732e+27, "training_acc": 52.5, "val_loss": 9.493128921153871e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 335.66}
{"epoch": 16, "training_loss": 3.510655758302208e+27, "training_acc": 52.5, "val_loss": 8.595865454350583e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 353.98}
{"epoch": 17, "training_loss": 3.150471089879381e+27, "training_acc": 52.5, "val_loss": 7.786678734138833e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 375.82}
{"epoch": 18, "training_loss": 2.870967278053131e+27, "training_acc": 52.5, "val_loss": 7.054458747731626e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 395.49}
{"epoch": 19, "training_loss": 2.595840288299762e+27, "training_acc": 52.5, "val_loss": 6.386429741352114e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 416.54}
{"epoch": 20, "training_loss": 2.349861478472607e+27, "training_acc": 52.5, "val_loss": 5.786427715430424e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 434.41}
{"epoch": 21, "training_loss": 2.141430278337725e+27, "training_acc": 52.5, "val_loss": 5.2407933171485766e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 455.87}
{"epoch": 22, "training_loss": 1.929521627137276e+27, "training_acc": 52.5, "val_loss": 4.745404160374699e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 475.5}
{"epoch": 23, "training_loss": 1.7107372472312567e+27, "training_acc": 52.5, "val_loss": 4.29264681266097e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 494.7}
{"epoch": 24, "training_loss": 1.5818376715371594e+27, "training_acc": 52.5, "val_loss": 3.887744930760462e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 512.94}
{"epoch": 25, "training_loss": 1.4135882392547878e+27, "training_acc": 52.5, "val_loss": 3.5189200379978105e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 534.88}
{"epoch": 26, "training_loss": 1.2183798128458935e+27, "training_acc": 52.5, "val_loss": 3.082870598144543e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 555.17}
{"epoch": 27, "training_loss": 1.1089270530087178e+27, "training_acc": 52.5, "val_loss": 2.7883782441327096e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 573.77}
{"epoch": 28, "training_loss": 9.803620459118854e+26, "training_acc": 52.5, "val_loss": 2.5162813903478642e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 593.43}
{"epoch": 29, "training_loss": 9.272254801845462e+26, "training_acc": 52.5, "val_loss": 2.272397909286554e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 615.14}
{"epoch": 30, "training_loss": 8.568182609986608e+26, "training_acc": 52.5, "val_loss": 2.0548803595297967e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 633.52}
{"epoch": 31, "training_loss": 7.366749488879838e+26, "training_acc": 52.5, "val_loss": 1.7628104088912928e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 651.23}
{"epoch": 32, "training_loss": 6.474554910646845e+26, "training_acc": 52.5, "val_loss": 1.5796020737293784e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 668.86}
{"epoch": 33, "training_loss": 5.756057826090952e+26, "training_acc": 52.5, "val_loss": 1.409818587151407e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 690.22}
{"epoch": 34, "training_loss": 5.6404223817230555e+26, "training_acc": 55.0, "val_loss": 1.2724419946856773e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 708.7}
{"epoch": 35, "training_loss": 4.6177262203068834e+26, "training_acc": 51.25, "val_loss": 1.1200691216252253e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 728.39}
{"epoch": 36, "training_loss": 4.178422175279831e+26, "training_acc": 52.5, "val_loss": 1.0030531229308525e+26, "val_acc": 50.0, "val_auroc": 0.54, "time": 748.44}
{"epoch": 37, "training_loss": 3.641088535129992e+26, "training_acc": 52.5, "val_loss": 9.038753563400577e+25, "val_acc": 50.0, "val_auroc": 0.53, "time": 770.25}
{"epoch": 38, "training_loss": 3.127560694908436e+26, "training_acc": 52.5, "val_loss": 8.15504211242319e+25, "val_acc": 50.0, "val_auroc": 0.48, "time": 790.76}
{"epoch": 39, "training_loss": 2.836877455197243e+26, "training_acc": 52.5, "val_loss": 7.3497264414553075e+25, "val_acc": 50.0, "val_auroc": 0.48, "time": 809.85}
{"epoch": 40, "training_loss": 2.6248316247844896e+26, "training_acc": 52.5, "val_loss": 6.6546150783482796e+25, "val_acc": 50.0, "val_auroc": 0.49, "time": 828.6}
{"epoch": 41, "training_loss": 2.2946799159206284e+26, "training_acc": 52.5, "val_loss": 5.9238409708e+25, "val_acc": 50.0, "val_auroc": 0.49, "time": 849.16}
{"epoch": 42, "training_loss": 2.0840817398659197e+26, "training_acc": 52.5, "val_loss": 5.202771580016749e+25, "val_acc": 50.0, "val_auroc": 0.51, "time": 869.72}
{"epoch": 43, "training_loss": 1.8940796533290988e+26, "training_acc": 50.0, "val_loss": 4.5247649603520685e+25, "val_acc": 50.0, "val_auroc": 0.5, "time": 889.65}
{"epoch": 44, "training_loss": 1.4219724320102414e+26, "training_acc": 52.5, "val_loss": 3.626788123367805e+25, "val_acc": 50.0, "val_auroc": 0.48, "time": 909.37}
{"epoch": 45, "training_loss": 1.1850285353649553e+26, "training_acc": 53.75, "val_loss": 3.1721805095774078e+25, "val_acc": 50.0, "val_auroc": 0.49, "time": 930.11}
{"epoch": 46, "training_loss": 1.1315450255809208e+26, "training_acc": 51.25, "val_loss": 2.7619724793901724e+25, "val_acc": 50.0, "val_auroc": 0.47, "time": 951.05}
{"epoch": 47, "training_loss": 7.794212384418536e+25, "training_acc": 55.0, "val_loss": 2.094843241775893e+25, "val_acc": 50.0, "val_auroc": 0.44, "time": 973.44}
{"epoch": 48, "training_loss": 6.655914651468272e+25, "training_acc": 53.75, "val_loss": 1.7459565123453104e+25, "val_acc": 50.0, "val_auroc": 0.41, "time": 992.68}
{"epoch": 49, "training_loss": 5.1654605037003615e+25, "training_acc": 47.5, "val_loss": 1.460240081534394e+25, "val_acc": 50.0, "val_auroc": 0.39, "time": 1013.14}
{"epoch": 50, "training_loss": 4.036851807782664e+25, "training_acc": 55.0, "val_loss": 1.210033056604616e+25, "val_acc": 45.0, "val_auroc": 0.37, "time": 1031.24}
{"epoch": 51, "training_loss": 2.6745907715276873e+25, "training_acc": 50.0, "val_loss": 8.695109888627382e+24, "val_acc": 45.0, "val_auroc": 0.48, "time": 1052.38}
{"epoch": 52, "training_loss": 1.3952099331780525e+25, "training_acc": 55.0, "val_loss": 5.213641468077371e+24, "val_acc": 50.0, "val_auroc": 0.55, "time": 1070.57}
{"epoch": 53, "training_loss": 5.813104625693567e+24, "training_acc": 52.5, "val_loss": 5.209567241638474e+23, "val_acc": 50.0, "val_auroc": 0.3, "time": 1091.59}
{"epoch": 54, "training_loss": 2.3538261430691517e+24, "training_acc": 52.5, "val_loss": 4.6420290209167966e+20, "val_acc": 60.0, "val_auroc": 0.75, "time": 1110.57}
{"epoch": 55, "training_loss": 5.834777969498181e+23, "training_acc": 53.75, "val_loss": 8.355920694409272e+20, "val_acc": 50.0, "val_auroc": 0.22, "time": 1130.52}
{"epoch": 56, "training_loss": 1.1642260344517794e+21, "training_acc": 57.5, "val_loss": 2.870074168559272e+19, "val_acc": 50.0, "val_auroc": 0.33, "time": 1149.21}
{"epoch": 57, "training_loss": 8.707460774166465e+20, "training_acc": 47.5, "val_loss": 2.0994162981685166e+19, "val_acc": 50.0, "val_auroc": 0.62, "time": 1170.92}
{"epoch": 58, "training_loss": 5.526702057968621e+20, "training_acc": 52.5, "val_loss": 1.9847009515077632e+17, "val_acc": 50.0, "val_auroc": 0.61, "time": 1190.78}
{"epoch": 59, "training_loss": 2.563548056360321e+18, "training_acc": 46.25, "val_loss": 9.855186430748262e+17, "val_acc": 50.0, "val_auroc": 0.64, "time": 1211.31}
{"epoch": 60, "training_loss": 4.1000282824418263e+18, "training_acc": 47.5, "val_loss": 5.660885866722099e+17, "val_acc": 50.0, "val_auroc": 0.52, "time": 1228.93}
{"epoch": 61, "training_loss": 2.434329876451295e+18, "training_acc": 50.0, "val_loss": 1.1410607978001203e+18, "val_acc": 50.0, "val_auroc": 0.53, "time": 1248.49}
{"epoch": 62, "training_loss": 4.023573810123899e+18, "training_acc": 52.5, "val_loss": 1.3190673494704128e+18, "val_acc": 50.0, "val_auroc": 0.44, "time": 1268.74}
{"epoch": 63, "training_loss": 5.556232546104115e+18, "training_acc": 47.5, "val_loss": 3.428472461669171e+17, "val_acc": 50.0, "val_auroc": 0.47, "time": 1288.57}
{"epoch": 64, "training_loss": 1.3859409008021996e+18, "training_acc": 45.0, "val_loss": 4.045964151095296e+16, "val_acc": 50.0, "val_auroc": 0.79, "time": 1307.5}
{"epoch": 65, "training_loss": 1.2679744185171968e+17, "training_acc": 52.5, "val_loss": 1.1041227046649856e+17, "val_acc": 50.0, "val_auroc": 0.62, "time": 1327.47}
{"epoch": 66, "training_loss": 3.7039727523240346e+17, "training_acc": 48.75, "val_loss": 1.5055709355900928e+17, "val_acc": 50.0, "val_auroc": 0.61, "time": 1346.81}
{"epoch": 67, "training_loss": 5.5330790646061466e+17, "training_acc": 52.5, "val_loss": 2.3994908540928e+16, "val_acc": 50.0, "val_auroc": 0.73, "time": 1365.99}
{"epoch": 68, "training_loss": 1.181937504794706e+17, "training_acc": 50.0, "val_loss": 3.675136943194112e+16, "val_acc": 50.0, "val_auroc": 0.29, "time": 1383.97}
{"epoch": 69, "training_loss": 1.6575605940158464e+17, "training_acc": 47.5, "val_loss": 7855714630369280.0, "val_acc": 50.0, "val_auroc": 0.64, "time": 1404.36}
{"epoch": 70, "training_loss": 3.816570216251392e+16, "training_acc": 50.0, "val_loss": 1.476999390429184e+16, "val_acc": 50.0, "val_auroc": 0.66, "time": 1423.26}
{"epoch": 71, "training_loss": 6.680205945366118e+16, "training_acc": 52.5, "val_loss": 6998144550174720.0, "val_acc": 50.0, "val_auroc": 0.65, "time": 1442.96}
{"epoch": 72, "training_loss": 2.964446342492979e+16, "training_acc": 55.0, "val_loss": 8996637795942400.0, "val_acc": 50.0, "val_auroc": 0.34, "time": 1459.85}
{"epoch": 73, "training_loss": 3.222983402114253e+16, "training_acc": 47.5, "val_loss": 2343757278085120.0, "val_acc": 50.0, "val_auroc": 0.65, "time": 1478.25}
{"epoch": 74, "training_loss": 1.123081334554624e+16, "training_acc": 51.25, "val_loss": 2319110541148160.0, "val_acc": 50.0, "val_auroc": 0.61, "time": 1498.2}
{"epoch": 75, "training_loss": 7627228410019840.0, "training_acc": 47.5, "val_loss": 2410627737845760.0, "val_acc": 50.0, "val_auroc": 0.53, "time": 1515.64}
{"epoch": 76, "training_loss": 1.2313108596916224e+16, "training_acc": 48.75, "val_loss": 634302245109760.0, "val_acc": 55.0, "val_auroc": 0.69, "time": 1533.54}
{"epoch": 77, "training_loss": 3925559306354688.0, "training_acc": 53.75, "val_loss": 1559400619704320.0, "val_acc": 50.0, "val_auroc": 0.76, "time": 1553.47}
{"epoch": 78, "training_loss": 6112377338593280.0, "training_acc": 51.25, "val_loss": 689846909665280.0, "val_acc": 55.0, "val_auroc": 0.68, "time": 1573.83}
{"epoch": 79, "training_loss": 3261698022572032.0, "training_acc": 50.0, "val_loss": 463770568622080.0, "val_acc": 50.0, "val_auroc": 0.81, "time": 1591.96}
{"epoch": 80, "training_loss": 4516587608473600.0, "training_acc": 50.0, "val_loss": 274876837396480.0, "val_acc": 75.0, "val_auroc": 0.79, "time": 1609.53}
{"epoch": 81, "training_loss": 1687087849930752.0, "training_acc": 53.75, "val_loss": 121302763438080.0, "val_acc": 70.0, "val_auroc": 0.8, "time": 1628.87}
{"epoch": 82, "training_loss": 2312105449488384.0, "training_acc": 55.0, "val_loss": 527978190602240.0, "val_acc": 50.0, "val_auroc": 0.68, "time": 1646.0}
{"epoch": 83, "training_loss": 2012521816915968.0, "training_acc": 48.75, "val_loss": 699957279457280.0, "val_acc": 50.0, "val_auroc": 0.7, "time": 1664.49}
{"epoch": 84, "training_loss": 4393608736145408.0, "training_acc": 52.5, "val_loss": 540767546245120.0, "val_acc": 50.0, "val_auroc": 0.67, "time": 1682.99}
{"epoch": 85, "training_loss": 3867770521387008.0, "training_acc": 50.0, "val_loss": 795307734466560.0, "val_acc": 50.0, "val_auroc": 0.6, "time": 1702.06}
{"epoch": 86, "training_loss": 4283637172273152.0, "training_acc": 47.5, "val_loss": 208056814141440.0, "val_acc": 50.0, "val_auroc": 0.86, "time": 1719.65}
{"epoch": 87, "training_loss": 1639221513158656.0, "training_acc": 48.75, "val_loss": 782486669885440.0, "val_acc": 50.0, "val_auroc": 0.77, "time": 1739.74}
{"epoch": 88, "training_loss": 4270866623889408.0, "training_acc": 53.75, "val_loss": 531615491031040.0, "val_acc": 50.0, "val_auroc": 0.47, "time": 1756.95}
{"epoch": 89, "training_loss": 2707565637009408.0, "training_acc": 46.25, "val_loss": 458736858562560.0, "val_acc": 55.0, "val_auroc": 0.46, "time": 1776.99}
{"epoch": 90, "training_loss": 2147239908605952.0, "training_acc": 41.25, "val_loss": 262306550251520.0, "val_acc": 55.0, "val_auroc": 0.63, "time": 1795.54}
{"epoch": 91, "training_loss": 1093300031324160.0, "training_acc": 56.25, "val_loss": 600718830469120.0, "val_acc": 50.0, "val_auroc": 0.42, "time": 1813.85}
{"epoch": 92, "training_loss": 2627000103600128.0, "training_acc": 41.25, "val_loss": 526849671168000.0, "val_acc": 55.0, "val_auroc": 0.46, "time": 1831.02}
{"epoch": 93, "training_loss": 2560999878033408.0, "training_acc": 46.25, "val_loss": 252701384376320.0, "val_acc": 55.0, "val_auroc": 0.54, "time": 1848.95}
{"epoch": 94, "training_loss": 861486687715328.0, "training_acc": 53.75, "val_loss": 155871346688000.0, "val_acc": 60.0, "val_auroc": 0.57, "time": 1868.06}
{"epoch": 95, "training_loss": 890071305682944.0, "training_acc": 48.75, "val_loss": 355129370869760.0, "val_acc": 50.0, "val_auroc": 0.47, "time": 1888.33}
{"epoch": 96, "training_loss": 874439772209152.0, "training_acc": 43.75, "val_loss": 126276337664000.0, "val_acc": 45.0, "val_auroc": 0.49, "time": 1905.88}
{"epoch": 97, "training_loss": 632315822735360.0, "training_acc": 57.5, "val_loss": 232836615372800.0, "val_acc": 50.0, "val_auroc": 0.61, "time": 1924.31}
{"epoch": 98, "training_loss": 919608332648448.0, "training_acc": 52.5, "val_loss": 45472431472640.0, "val_acc": 65.0, "val_auroc": 0.71, "time": 1943.83}
{"epoch": 99, "training_loss": 464565137571840.0, "training_acc": 51.25, "val_loss": 41526965043200.0, "val_acc": 55.0, "val_auroc": 0.64, "time": 1962.08}
{"epoch": 100, "training_loss": 395061829304320.0, "training_acc": 52.5, "val_loss": 43999795609600.0, "val_acc": 45.0, "val_auroc": 0.59, "time": 1979.5}
{"epoch": 101, "training_loss": 357772923240448.0, "training_acc": 43.75, "val_loss": 49266499256320.0, "val_acc": 50.0, "val_auroc": 0.49, "time": 1998.58}
{"epoch": 102, "training_loss": 285871412609024.0, "training_acc": 56.25, "val_loss": 66635882823680.0, "val_acc": 55.0, "val_auroc": 0.5, "time": 2018.16}
{"epoch": 103, "training_loss": 334130202017792.0, "training_acc": 50.0, "val_loss": 124096106987520.0, "val_acc": 50.0, "val_auroc": 0.43, "time": 2037.8}
{"epoch": 104, "training_loss": 395174035324928.0, "training_acc": 51.25, "val_loss": 40256193167360.0, "val_acc": 60.0, "val_auroc": 0.56, "time": 2054.94}
{"epoch": 105, "training_loss": 195317395881984.0, "training_acc": 53.75, "val_loss": 20663087923200.0, "val_acc": 70.0, "val_auroc": 0.64, "time": 2073.16}
{"epoch": 106, "training_loss": 207813603229696.0, "training_acc": 48.75, "val_loss": 22199612211200.0, "val_acc": 50.0, "val_auroc": 0.6, "time": 2092.57}
{"epoch": 107, "training_loss": 176024939659264.0, "training_acc": 47.5, "val_loss": 33780455178240.0, "val_acc": 45.0, "val_auroc": 0.45, "time": 2110.13}
{"epoch": 108, "training_loss": 239354769309696.0, "training_acc": 47.5, "val_loss": 54328117166080.0, "val_acc": 50.0, "val_auroc": 0.49, "time": 2128.54}
{"epoch": 109, "training_loss": 189877282930688.0, "training_acc": 55.0, "val_loss": 26296742051840.0, "val_acc": 40.0, "val_auroc": 0.52, "time": 2147.12}
{"epoch": 110, "training_loss": 102388530675712.0, "training_acc": 53.75, "val_loss": 23207319961600.0, "val_acc": 45.0, "val_auroc": 0.54, "time": 2168.07}
{"epoch": 111, "training_loss": 159854119354368.0, "training_acc": 57.5, "val_loss": 48496089497600.0, "val_acc": 55.0, "val_auroc": 0.51, "time": 2188.5}
{"epoch": 112, "training_loss": 206291842629632.0, "training_acc": 46.25, "val_loss": 37901476823040.0, "val_acc": 50.0, "val_auroc": 0.4, "time": 2205.1}
{"epoch": 113, "training_loss": 210772030390272.0, "training_acc": 42.5, "val_loss": 25642566942720.0, "val_acc": 60.0, "val_auroc": 0.48, "time": 2223.76}
{"epoch": 114, "training_loss": 149966030897152.0, "training_acc": 52.5, "val_loss": 20756771635200.0, "val_acc": 50.0, "val_auroc": 0.44, "time": 2242.37}
{"epoch": 115, "training_loss": 164019163889664.0, "training_acc": 47.5, "val_loss": 25963882086400.0, "val_acc": 55.0, "val_auroc": 0.62, "time": 2259.43}
{"epoch": 116, "training_loss": 178760028520448.0, "training_acc": 50.0, "val_loss": 26780463267840.0, "val_acc": 55.0, "val_auroc": 0.48, "time": 2277.11}
{"epoch": 117, "training_loss": 130300449390592.0, "training_acc": 53.75, "val_loss": 35265170636800.0, "val_acc": 50.0, "val_auroc": 0.68, "time": 2295.41}
{"epoch": 118, "training_loss": 112118242213888.0, "training_acc": 56.25, "val_loss": 19585856962560.0, "val_acc": 45.0, "val_auroc": 0.45, "time": 2313.44}
{"epoch": 119, "training_loss": 94718255955968.0, "training_acc": 50.0, "val_loss": 20383915048960.0, "val_acc": 60.0, "val_auroc": 0.53, "time": 2332.38}
{"epoch": 120, "training_loss": 90851174776832.0, "training_acc": 56.25, "val_loss": 18771691438080.0, "val_acc": 60.0, "val_auroc": 0.63, "time": 2350.75}
{"epoch": 121, "training_loss": 88782342717440.0, "training_acc": 60.0, "val_loss": 26017301790720.0, "val_acc": 55.0, "val_auroc": 0.42, "time": 2368.61}
{"epoch": 122, "training_loss": 90559922307072.0, "training_acc": 56.25, "val_loss": 9997610516480.0, "val_acc": 45.0, "val_auroc": 0.64, "time": 2387.32}
{"epoch": 123, "training_loss": 77065135063040.0, "training_acc": 47.5, "val_loss": 19364933795840.0, "val_acc": 55.0, "val_auroc": 0.75, "time": 2403.92}
{"epoch": 124, "training_loss": 75591692845056.0, "training_acc": 52.5, "val_loss": 74605998899200.0, "val_acc": 50.0, "val_auroc": 0.42, "time": 2423.12}
{"epoch": 125, "training_loss": 183899493761024.0, "training_acc": 52.5, "val_loss": 12846247444480.0, "val_acc": 70.0, "val_auroc": 0.73, "time": 2441.39}
{"epoch": 126, "training_loss": 108302432206848.0, "training_acc": 51.25, "val_loss": 19862345482240.0, "val_acc": 55.0, "val_auroc": 0.68, "time": 2460.21}
{"epoch": 127, "training_loss": 122022168363008.0, "training_acc": 40.0, "val_loss": 19566797783040.0, "val_acc": 45.0, "val_auroc": 0.45, "time": 2480.24}
{"epoch": 128, "training_loss": 57659935948800.0, "training_acc": 61.25, "val_loss": 4403004513976320.0, "val_acc": 50.0, "val_auroc": 0.59, "time": 2499.01}
{"epoch": 129, "training_loss": 1.3668216412831744e+16, "training_acc": 52.5, "val_loss": 121246528307200.0, "val_acc": 50.0, "val_auroc": 0.37, "time": 2517.53}
{"epoch": 130, "training_loss": 387589659951104.0, "training_acc": 47.5, "val_loss": 41229806469120.0, "val_acc": 60.0, "val_auroc": 0.5, "time": 2535.61}
{"epoch": 131, "training_loss": 192836246962176.0, "training_acc": 48.75, "val_loss": 109088677560320.0, "val_acc": 50.0, "val_auroc": 0.5, "time": 2552.56}
{"epoch": 132, "training_loss": 420267918622720.0, "training_acc": 47.5, "val_loss": 57962193223680.0, "val_acc": 55.0, "val_auroc": 0.53, "time": 2572.03}
{"epoch": 133, "training_loss": 566577053302784.0, "training_acc": 43.75, "val_loss": 175451563622400.0, "val_acc": 50.0, "val_auroc": 0.48, "time": 2591.98}
{"epoch": 134, "training_loss": 633027713564672.0, "training_acc": 52.5, "val_loss": 1107607641128960.0, "val_acc": 50.0, "val_auroc": 0.61, "time": 2611.6}
{"epoch": 135, "training_loss": 3775775543132160.0, "training_acc": 52.5, "val_loss": 437965322977280.0, "val_acc": 50.0, "val_auroc": 0.7, "time": 2630.83}
{"epoch": 136, "training_loss": 1850471627096064.0, "training_acc": 52.5, "val_loss": 439077987942400.0, "val_acc": 50.0, "val_auroc": 0.61, "time": 2649.21}
{"epoch": 137, "training_loss": 1683620334927872.0, "training_acc": 52.5, "val_loss": 358111143526400.0, "val_acc": 50.0, "val_auroc": 0.6, "time": 2667.39}
{"epoch": 138, "training_loss": 1377944291246080.0, "training_acc": 52.5, "val_loss": 260780222054400.0, "val_acc": 50.0, "val_auroc": 0.62, "time": 2685.33}
{"epoch": 139, "training_loss": 971692327305216.0, "training_acc": 52.5, "val_loss": 145560206049280.0, "val_acc": 50.0, "val_auroc": 0.73, "time": 2702.31}
{"epoch": 140, "training_loss": 564425677340672.0, "training_acc": 52.5, "val_loss": 63300435968000.0, "val_acc": 50.0, "val_auroc": 0.77, "time": 2721.03}
{"epoch": 141, "training_loss": 227760907747328.0, "training_acc": 55.0, "val_loss": 44938108600320.0, "val_acc": 50.0, "val_auroc": 0.71, "time": 2739.77}
