"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 342.30138778686523, "training_acc": 55.0, "val_loss": 5.379652797253532e+25, "val_acc": 50.0, "val_auroc": 0.43, "time": 18.92}
{"epoch": 1, "training_loss": 2.123160106498289e+26, "training_acc": 47.5, "val_loss": 4.065387710297113e+25, "val_acc": 50.0, "val_auroc": 0.4, "time": 42.14}
{"epoch": 2, "training_loss": 1.6495822876834455e+26, "training_acc": 47.5, "val_loss": 3.5195168478146703e+25, "val_acc": 50.0, "val_auroc": 0.4, "time": 67.51}
{"epoch": 3, "training_loss": 1.4314748341096411e+26, "training_acc": 47.5, "val_loss": 3.0243217853760935e+25, "val_acc": 50.0, "val_auroc": 0.38, "time": 89.6}
{"epoch": 4, "training_loss": 1.2321147604210876e+26, "training_acc": 47.5, "val_loss": 2.600364013324917e+25, "val_acc": 50.0, "val_auroc": 0.37, "time": 107.67}
{"epoch": 5, "training_loss": 1.0548081612659654e+26, "training_acc": 47.5, "val_loss": 2.2171418403352616e+25, "val_acc": 50.0, "val_auroc": 0.37, "time": 127.29}
{"epoch": 6, "training_loss": 8.90742404422651e+25, "training_acc": 47.5, "val_loss": 1.8504815288744718e+25, "val_acc": 50.0, "val_auroc": 0.35, "time": 149.44}
{"epoch": 7, "training_loss": 7.179779009439381e+25, "training_acc": 47.5, "val_loss": 1.549371866594797e+25, "val_acc": 50.0, "val_auroc": 0.35, "time": 167.98}
{"epoch": 8, "training_loss": 6.0741224442510955e+25, "training_acc": 47.5, "val_loss": 1.2707154947325285e+25, "val_acc": 50.0, "val_auroc": 0.35, "time": 184.97}
{"epoch": 9, "training_loss": 4.678444612291917e+25, "training_acc": 47.5, "val_loss": 1.0196687106018326e+25, "val_acc": 50.0, "val_auroc": 0.34, "time": 205.17}
{"epoch": 10, "training_loss": 3.739519865751059e+25, "training_acc": 47.5, "val_loss": 7.848820828537653e+24, "val_acc": 50.0, "val_auroc": 0.27, "time": 226.33}
{"epoch": 11, "training_loss": 2.7522592886520854e+25, "training_acc": 47.5, "val_loss": 5.769146791170654e+24, "val_acc": 50.0, "val_auroc": 0.28, "time": 244.81}
{"epoch": 12, "training_loss": 1.8106168178944928e+25, "training_acc": 47.5, "val_loss": 3.7795166438893907e+24, "val_acc": 50.0, "val_auroc": 0.32, "time": 263.02}
{"epoch": 13, "training_loss": 9.815888085800978e+24, "training_acc": 47.5, "val_loss": 1.527290069103453e+24, "val_acc": 50.0, "val_auroc": 0.34, "time": 282.43}
{"epoch": 14, "training_loss": 3.775257013261034e+24, "training_acc": 47.5, "val_loss": 4.525470233060914e+20, "val_acc": 45.0, "val_auroc": 0.39, "time": 303.23}
{"epoch": 15, "training_loss": 5.23134969640306e+21, "training_acc": 56.25, "val_loss": 2.8779208332908954e+19, "val_acc": 50.0, "val_auroc": 0.4, "time": 322.71}
{"epoch": 16, "training_loss": 1.4712134082712568e+21, "training_acc": 52.5, "val_loss": 3.4039087791991685e+19, "val_acc": 50.0, "val_auroc": 0.62, "time": 342.66}
{"epoch": 17, "training_loss": 2.094782305258185e+21, "training_acc": 52.5, "val_loss": 3.2252521584588227e+19, "val_acc": 50.0, "val_auroc": 0.46, "time": 363.14}
{"epoch": 18, "training_loss": 2.3359423599263875e+21, "training_acc": 47.5, "val_loss": 8.243593926808699e+18, "val_acc": 50.0, "val_auroc": 0.43, "time": 384.08}
{"epoch": 19, "training_loss": 3.4750084127362803e+20, "training_acc": 47.5, "val_loss": 3.4703256294785024e+17, "val_acc": 50.0, "val_auroc": 0.64, "time": 401.73}
{"epoch": 20, "training_loss": 6.180859260688138e+18, "training_acc": 52.5, "val_loss": 9.465658495006147e+18, "val_acc": 50.0, "val_auroc": 0.61, "time": 419.57}
{"epoch": 21, "training_loss": 1.3918709779532664e+20, "training_acc": 47.5, "val_loss": 1.0105327559450296e+19, "val_acc": 50.0, "val_auroc": 0.36, "time": 438.05}
{"epoch": 22, "training_loss": 4.545146213542291e+19, "training_acc": 52.5, "val_loss": 2.1528703959826432e+18, "val_acc": 50.0, "val_auroc": 0.23, "time": 457.97}
{"epoch": 23, "training_loss": 8.110284807730102e+18, "training_acc": 52.5, "val_loss": 1.6007505247207424e+17, "val_acc": 50.0, "val_auroc": 0.53, "time": 477.13}
{"epoch": 24, "training_loss": 8.55903694086996e+17, "training_acc": 47.5, "val_loss": 1.3810901131984896e+17, "val_acc": 50.0, "val_auroc": 0.73, "time": 495.56}
{"epoch": 25, "training_loss": 6.436914902954148e+17, "training_acc": 50.0, "val_loss": 1.728355237888e+16, "val_acc": 50.0, "val_auroc": 0.32, "time": 514.75}
{"epoch": 26, "training_loss": 1.0590623988763853e+17, "training_acc": 51.25, "val_loss": 1.3067800493319782e+18, "val_acc": 50.0, "val_auroc": 0.51, "time": 534.23}
{"epoch": 27, "training_loss": 4.979767876790518e+18, "training_acc": 50.0, "val_loss": 3.8019398396542976e+17, "val_acc": 50.0, "val_auroc": 0.38, "time": 552.1}
{"epoch": 28, "training_loss": 1.2080278248001372e+18, "training_acc": 60.0, "val_loss": 3.0462792133771264e+17, "val_acc": 50.0, "val_auroc": 0.48, "time": 570.52}
{"epoch": 29, "training_loss": 1.341471599693398e+18, "training_acc": 47.5, "val_loss": 2426119651328000.0, "val_acc": 50.0, "val_auroc": 0.41, "time": 592.15}
{"epoch": 30, "training_loss": 2.2949424595258573e+17, "training_acc": 52.5, "val_loss": 1.7094131973095424e+17, "val_acc": 50.0, "val_auroc": 0.15, "time": 611.4}
{"epoch": 31, "training_loss": 5.388327413916631e+17, "training_acc": 52.5, "val_loss": 8.029630338433024e+16, "val_acc": 50.0, "val_auroc": 0.41, "time": 630.04}
{"epoch": 32, "training_loss": 3.208309023577211e+17, "training_acc": 47.5, "val_loss": 2.23893356806144e+16, "val_acc": 50.0, "val_auroc": 0.61, "time": 648.06}
{"epoch": 33, "training_loss": 7.976845834610278e+16, "training_acc": 50.0, "val_loss": 1.223146153705472e+16, "val_acc": 50.0, "val_auroc": 0.64, "time": 668.83}
{"epoch": 34, "training_loss": 5.145117524911718e+16, "training_acc": 52.5, "val_loss": 2913942372352000.0, "val_acc": 50.0, "val_auroc": 0.67, "time": 688.15}
{"epoch": 35, "training_loss": 1.0689697529462784e+16, "training_acc": 57.5, "val_loss": 5177241826754560.0, "val_acc": 50.0, "val_auroc": 0.36, "time": 707.18}
{"epoch": 36, "training_loss": 2.077286621983539e+16, "training_acc": 47.5, "val_loss": 3321883063746560.0, "val_acc": 50.0, "val_auroc": 0.65, "time": 724.86}
{"epoch": 37, "training_loss": 1.2806400086376448e+16, "training_acc": 47.5, "val_loss": 2629645065256960.0, "val_acc": 50.0, "val_auroc": 0.69, "time": 744.93}
{"epoch": 38, "training_loss": 1.1373122255060992e+16, "training_acc": 52.5, "val_loss": 2015232880803840.0, "val_acc": 50.0, "val_auroc": 0.46, "time": 764.48}
{"epoch": 39, "training_loss": 6269883520122880.0, "training_acc": 52.5, "val_loss": 1333386018816000.0, "val_acc": 50.0, "val_auroc": 0.29, "time": 783.3}
{"epoch": 40, "training_loss": 5544858076839936.0, "training_acc": 47.5, "val_loss": 1001445360926720.0, "val_acc": 50.0, "val_auroc": 0.55, "time": 801.89}
{"epoch": 41, "training_loss": 3752040748548096.0, "training_acc": 42.5, "val_loss": 13304534138880.0, "val_acc": 70.0, "val_auroc": 0.66, "time": 822.47}
{"epoch": 42, "training_loss": 303701633794048.0, "training_acc": 41.25, "val_loss": 32160950517760.0, "val_acc": 45.0, "val_auroc": 0.45, "time": 841.35}
{"epoch": 43, "training_loss": 514833736794112.0, "training_acc": 40.0, "val_loss": 70011893841920.0, "val_acc": 20.0, "val_auroc": 0.19, "time": 859.62}
{"epoch": 44, "training_loss": 353612173672448.0, "training_acc": 45.0, "val_loss": 176148625489920.0, "val_acc": 50.0, "val_auroc": 0.24, "time": 877.53}
{"epoch": 45, "training_loss": 524264813887488.0, "training_acc": 50.0, "val_loss": 145370623508480.0, "val_acc": 50.0, "val_auroc": 0.29, "time": 895.11}
{"epoch": 46, "training_loss": 658823522025472.0, "training_acc": 47.5, "val_loss": 65115898511360.0, "val_acc": 35.0, "val_auroc": 0.31, "time": 915.95}
{"epoch": 47, "training_loss": 288260622385152.0, "training_acc": 51.25, "val_loss": 58234088980480.0, "val_acc": 35.0, "val_auroc": 0.32, "time": 935.34}
{"epoch": 48, "training_loss": 397325209960448.0, "training_acc": 40.0, "val_loss": 89958058557440.0, "val_acc": 50.0, "val_auroc": 0.35, "time": 956.77}
{"epoch": 49, "training_loss": 340124332195840.0, "training_acc": 52.5, "val_loss": 110454888202240.0, "val_acc": 45.0, "val_auroc": 0.61, "time": 975.93}
{"epoch": 50, "training_loss": 1225646965522432.0, "training_acc": 50.0, "val_loss": 337932556697600.0, "val_acc": 50.0, "val_auroc": 0.66, "time": 993.66}
{"epoch": 51, "training_loss": 1272308060651520.0, "training_acc": 47.5, "val_loss": 218220954910720.0, "val_acc": 50.0, "val_auroc": 0.54, "time": 1010.88}
{"epoch": 52, "training_loss": 913894415532032.0, "training_acc": 52.5, "val_loss": 313933189611520.0, "val_acc": 50.0, "val_auroc": 0.37, "time": 1028.69}
{"epoch": 53, "training_loss": 1169801300934656.0, "training_acc": 52.5, "val_loss": 80387846963200.0, "val_acc": 50.0, "val_auroc": 0.22, "time": 1047.53}
{"epoch": 54, "training_loss": 318438639665152.0, "training_acc": 50.0, "val_loss": 141169556193280.0, "val_acc": 50.0, "val_auroc": 0.25, "time": 1068.95}
{"epoch": 55, "training_loss": 519333184798720.0, "training_acc": 48.75, "val_loss": 98624014909440.0, "val_acc": 50.0, "val_auroc": 0.21, "time": 1087.38}
{"epoch": 56, "training_loss": 377016641650688.0, "training_acc": 47.5, "val_loss": 59514122403840.0, "val_acc": 50.0, "val_auroc": 0.21, "time": 1106.44}
{"epoch": 57, "training_loss": 380000100417536.0, "training_acc": 52.5, "val_loss": 43471074754560.0, "val_acc": 50.0, "val_auroc": 0.17, "time": 1127.55}
{"epoch": 58, "training_loss": 395027301793792.0, "training_acc": 50.0, "val_loss": 113470487920640.0, "val_acc": 50.0, "val_auroc": 0.28, "time": 1147.74}
{"epoch": 59, "training_loss": 413958561333248.0, "training_acc": 50.0, "val_loss": 66804105871360.0, "val_acc": 50.0, "val_auroc": 0.28, "time": 1165.32}
{"epoch": 60, "training_loss": 225642180247552.0, "training_acc": 51.25, "val_loss": 81165874626560.0, "val_acc": 50.0, "val_auroc": 0.24, "time": 1183.88}
