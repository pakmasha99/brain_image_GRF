"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.66622543334961, "training_acc": 51.25, "val_loss": 13.757524490356445, "val_acc": 55.0, "val_auroc": 0.576, "time": 23.36}
{"epoch": 1, "training_loss": 55.53604698181152, "training_acc": 51.25, "val_loss": 13.771964311599731, "val_acc": 55.0, "val_auroc": 0.545, "time": 47.46}
{"epoch": 2, "training_loss": 55.11387348175049, "training_acc": 51.25, "val_loss": 13.794890642166138, "val_acc": 55.0, "val_auroc": 0.535, "time": 71.82}
{"epoch": 3, "training_loss": 54.9437952041626, "training_acc": 51.25, "val_loss": 13.804115056991577, "val_acc": 55.0, "val_auroc": 0.515, "time": 96.84}
{"epoch": 4, "training_loss": 54.714659690856934, "training_acc": 61.25, "val_loss": 13.765732049942017, "val_acc": 55.0, "val_auroc": 0.545, "time": 116.64}
{"epoch": 5, "training_loss": 54.61542320251465, "training_acc": 53.75, "val_loss": 13.785614967346191, "val_acc": 55.0, "val_auroc": 0.535, "time": 137.55}
{"epoch": 6, "training_loss": 54.41479301452637, "training_acc": 65.0, "val_loss": 13.828368186950684, "val_acc": 55.0, "val_auroc": 0.596, "time": 159.99}
{"epoch": 7, "training_loss": 54.38948154449463, "training_acc": 68.75, "val_loss": 13.769930601119995, "val_acc": 55.0, "val_auroc": 0.566, "time": 180.72}
{"epoch": 8, "training_loss": 53.9206428527832, "training_acc": 63.75, "val_loss": 13.987147808074951, "val_acc": 55.0, "val_auroc": 0.545, "time": 198.68}
{"epoch": 9, "training_loss": 54.629984855651855, "training_acc": 53.75, "val_loss": 13.738491535186768, "val_acc": 55.0, "val_auroc": 0.545, "time": 222.64}
{"epoch": 10, "training_loss": 53.377017974853516, "training_acc": 61.25, "val_loss": 13.754286766052246, "val_acc": 55.0, "val_auroc": 0.545, "time": 244.37}
{"epoch": 11, "training_loss": 54.33158588409424, "training_acc": 53.75, "val_loss": 13.734215497970581, "val_acc": 55.0, "val_auroc": 0.566, "time": 264.12}
{"epoch": 12, "training_loss": 53.341156005859375, "training_acc": 62.5, "val_loss": 13.740440607070923, "val_acc": 55.0, "val_auroc": 0.566, "time": 284.04}
{"epoch": 13, "training_loss": 52.761844635009766, "training_acc": 76.25, "val_loss": 13.776191473007202, "val_acc": 55.0, "val_auroc": 0.556, "time": 308.35}
{"epoch": 14, "training_loss": 52.38674449920654, "training_acc": 75.0, "val_loss": 13.746308088302612, "val_acc": 55.0, "val_auroc": 0.556, "time": 329.71}
{"epoch": 15, "training_loss": 52.13496780395508, "training_acc": 62.5, "val_loss": 13.77687692642212, "val_acc": 55.0, "val_auroc": 0.556, "time": 349.38}
{"epoch": 16, "training_loss": 51.62478828430176, "training_acc": 61.25, "val_loss": 14.08286452293396, "val_acc": 55.0, "val_auroc": 0.556, "time": 369.12}
{"epoch": 17, "training_loss": 53.55964660644531, "training_acc": 57.5, "val_loss": 14.028340578079224, "val_acc": 55.0, "val_auroc": 0.616, "time": 389.89}
{"epoch": 18, "training_loss": 53.2796745300293, "training_acc": 57.5, "val_loss": 14.05498743057251, "val_acc": 55.0, "val_auroc": 0.606, "time": 410.74}
{"epoch": 19, "training_loss": 53.44979476928711, "training_acc": 56.25, "val_loss": 13.792930841445923, "val_acc": 55.0, "val_auroc": 0.545, "time": 431.44}
{"epoch": 20, "training_loss": 50.35334777832031, "training_acc": 71.25, "val_loss": 13.822135925292969, "val_acc": 55.0, "val_auroc": 0.535, "time": 449.95}
{"epoch": 21, "training_loss": 49.76309013366699, "training_acc": 73.75, "val_loss": 13.787835836410522, "val_acc": 55.0, "val_auroc": 0.566, "time": 469.61}
{"epoch": 22, "training_loss": 48.831369400024414, "training_acc": 78.75, "val_loss": 13.809088468551636, "val_acc": 50.0, "val_auroc": 0.586, "time": 490.51}
{"epoch": 23, "training_loss": 47.43157958984375, "training_acc": 73.75, "val_loss": 14.16081190109253, "val_acc": 55.0, "val_auroc": 0.606, "time": 511.02}
{"epoch": 24, "training_loss": 49.83198165893555, "training_acc": 67.5, "val_loss": 14.088515043258667, "val_acc": 55.0, "val_auroc": 0.596, "time": 530.96}
{"epoch": 25, "training_loss": 48.46987724304199, "training_acc": 63.75, "val_loss": 14.38319444656372, "val_acc": 55.0, "val_auroc": 0.576, "time": 551.62}
{"epoch": 26, "training_loss": 47.74162483215332, "training_acc": 70.0, "val_loss": 13.73170256614685, "val_acc": 55.0, "val_auroc": 0.586, "time": 571.97}
{"epoch": 27, "training_loss": 47.15311622619629, "training_acc": 71.25, "val_loss": 14.546791315078735, "val_acc": 55.0, "val_auroc": 0.606, "time": 592.93}
{"epoch": 28, "training_loss": 50.81722354888916, "training_acc": 62.5, "val_loss": 13.617743253707886, "val_acc": 50.0, "val_auroc": 0.596, "time": 613.18}
{"epoch": 29, "training_loss": 48.67511558532715, "training_acc": 76.25, "val_loss": 14.751901626586914, "val_acc": 55.0, "val_auroc": 0.626, "time": 632.74}
{"epoch": 30, "training_loss": 53.65114212036133, "training_acc": 50.0, "val_loss": 13.755918741226196, "val_acc": 55.0, "val_auroc": 0.566, "time": 652.85}
{"epoch": 31, "training_loss": 50.901535987854004, "training_acc": 67.5, "val_loss": 13.871309757232666, "val_acc": 55.0, "val_auroc": 0.566, "time": 673.55}
{"epoch": 32, "training_loss": 51.10237216949463, "training_acc": 61.25, "val_loss": 13.677723407745361, "val_acc": 55.0, "val_auroc": 0.566, "time": 693.21}
{"epoch": 33, "training_loss": 48.13188552856445, "training_acc": 77.5, "val_loss": 13.544481992721558, "val_acc": 55.0, "val_auroc": 0.606, "time": 713.21}
{"epoch": 34, "training_loss": 47.371026039123535, "training_acc": 78.75, "val_loss": 13.740236759185791, "val_acc": 55.0, "val_auroc": 0.566, "time": 732.81}
{"epoch": 35, "training_loss": 45.66231918334961, "training_acc": 78.75, "val_loss": 14.830547571182251, "val_acc": 55.0, "val_auroc": 0.566, "time": 752.63}
{"epoch": 36, "training_loss": 52.08802127838135, "training_acc": 57.5, "val_loss": 14.502317905426025, "val_acc": 55.0, "val_auroc": 0.545, "time": 771.13}
{"epoch": 37, "training_loss": 51.03293228149414, "training_acc": 57.5, "val_loss": 13.920458555221558, "val_acc": 55.0, "val_auroc": 0.545, "time": 791.92}
{"epoch": 38, "training_loss": 50.4988956451416, "training_acc": 62.5, "val_loss": 13.923710584640503, "val_acc": 55.0, "val_auroc": 0.545, "time": 812.65}
{"epoch": 39, "training_loss": 49.22767639160156, "training_acc": 62.5, "val_loss": 13.747711181640625, "val_acc": 50.0, "val_auroc": 0.556, "time": 834.04}
{"epoch": 40, "training_loss": 46.28415393829346, "training_acc": 75.0, "val_loss": 13.696037530899048, "val_acc": 50.0, "val_auroc": 0.576, "time": 852.72}
{"epoch": 41, "training_loss": 43.214173316955566, "training_acc": 81.25, "val_loss": 13.635225296020508, "val_acc": 55.0, "val_auroc": 0.586, "time": 873.3}
{"epoch": 42, "training_loss": 42.9913010597229, "training_acc": 81.25, "val_loss": 14.02413010597229, "val_acc": 50.0, "val_auroc": 0.586, "time": 894.88}
{"epoch": 43, "training_loss": 42.48333930969238, "training_acc": 78.75, "val_loss": 14.258004426956177, "val_acc": 60.0, "val_auroc": 0.586, "time": 914.93}
{"epoch": 44, "training_loss": 41.449748516082764, "training_acc": 80.0, "val_loss": 14.545379877090454, "val_acc": 50.0, "val_auroc": 0.556, "time": 934.18}
{"epoch": 45, "training_loss": 43.0357608795166, "training_acc": 77.5, "val_loss": 15.488601922988892, "val_acc": 55.0, "val_auroc": 0.667, "time": 955.99}
{"epoch": 46, "training_loss": 50.16607856750488, "training_acc": 63.75, "val_loss": 14.082984924316406, "val_acc": 50.0, "val_auroc": 0.566, "time": 976.44}
{"epoch": 47, "training_loss": 42.329572677612305, "training_acc": 73.75, "val_loss": 13.976507186889648, "val_acc": 55.0, "val_auroc": 0.566, "time": 996.36}
{"epoch": 48, "training_loss": 44.69014263153076, "training_acc": 71.25, "val_loss": 13.909138441085815, "val_acc": 50.0, "val_auroc": 0.566, "time": 1015.49}
{"epoch": 49, "training_loss": 42.2804651260376, "training_acc": 78.75, "val_loss": 14.5687997341156, "val_acc": 55.0, "val_auroc": 0.576, "time": 1035.3}
{"epoch": 50, "training_loss": 42.772396087646484, "training_acc": 75.0, "val_loss": 14.541049003601074, "val_acc": 55.0, "val_auroc": 0.576, "time": 1055.8}
{"epoch": 51, "training_loss": 44.04165840148926, "training_acc": 77.5, "val_loss": 13.839665651321411, "val_acc": 50.0, "val_auroc": 0.596, "time": 1074.99}
{"epoch": 52, "training_loss": 39.08331489562988, "training_acc": 85.0, "val_loss": 15.011780261993408, "val_acc": 55.0, "val_auroc": 0.556, "time": 1093.1}
