"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 124.7339973449707, "training_acc": 38.75, "val_loss": 5524856320.0, "val_acc": 45.0, "val_auroc": 0.455, "time": 19.7}
{"epoch": 1, "training_loss": 15567883024.904785, "training_acc": 53.75, "val_loss": 4985.05859375, "val_acc": 55.0, "val_auroc": 0.535, "time": 44.25}
{"epoch": 2, "training_loss": 274910.16015625, "training_acc": 48.75, "val_loss": 134271.904296875, "val_acc": 55.0, "val_auroc": 0.525, "time": 63.12}
{"epoch": 3, "training_loss": 492483.5078125, "training_acc": 51.25, "val_loss": 11829.500732421875, "val_acc": 55.0, "val_auroc": 0.525, "time": 86.48}
{"epoch": 4, "training_loss": 45466.818359375, "training_acc": 51.25, "val_loss": 717.2495269775391, "val_acc": 45.0, "val_auroc": 0.525, "time": 105.17}
{"epoch": 5, "training_loss": 32858.5712890625, "training_acc": 51.25, "val_loss": 2419.203643798828, "val_acc": 55.0, "val_auroc": 0.586, "time": 127.12}
{"epoch": 6, "training_loss": 9790.937255859375, "training_acc": 51.25, "val_loss": 785.1481628417969, "val_acc": 55.0, "val_auroc": 0.657, "time": 146.13}
{"epoch": 7, "training_loss": 5136.3896484375, "training_acc": 51.25, "val_loss": 2044.5695495605469, "val_acc": 45.0, "val_auroc": 0.535, "time": 168.24}
{"epoch": 8, "training_loss": 6513.130882263184, "training_acc": 43.75, "val_loss": 447.7219772338867, "val_acc": 45.0, "val_auroc": 0.606, "time": 185.81}
{"epoch": 9, "training_loss": 1602.9080810546875, "training_acc": 48.75, "val_loss": 14.123083353042603, "val_acc": 60.0, "val_auroc": 0.586, "time": 206.3}
{"epoch": 10, "training_loss": 611.4839859008789, "training_acc": 50.0, "val_loss": 219.26536560058594, "val_acc": 55.0, "val_auroc": 0.596, "time": 224.83}
{"epoch": 11, "training_loss": 841.6916770935059, "training_acc": 47.5, "val_loss": 79.11288738250732, "val_acc": 55.0, "val_auroc": 0.576, "time": 246.77}
{"epoch": 12, "training_loss": 495.3786315917969, "training_acc": 53.75, "val_loss": 199.02963638305664, "val_acc": 45.0, "val_auroc": 0.606, "time": 263.46}
{"epoch": 13, "training_loss": 889.6115112304688, "training_acc": 48.75, "val_loss": 181.5950584411621, "val_acc": 55.0, "val_auroc": 0.596, "time": 283.36}
{"epoch": 14, "training_loss": 744.0936431884766, "training_acc": 53.75, "val_loss": 99.62686538696289, "val_acc": 45.0, "val_auroc": 0.556, "time": 302.21}
{"epoch": 15, "training_loss": 424.9706268310547, "training_acc": 56.25, "val_loss": 310.95062255859375, "val_acc": 55.0, "val_auroc": 0.495, "time": 325.5}
{"epoch": 16, "training_loss": 1237.7588806152344, "training_acc": 51.25, "val_loss": 43.883376121520996, "val_acc": 45.0, "val_auroc": 0.545, "time": 342.06}
{"epoch": 17, "training_loss": 187.7599983215332, "training_acc": 46.25, "val_loss": 127.24257469177246, "val_acc": 45.0, "val_auroc": 0.556, "time": 360.16}
{"epoch": 18, "training_loss": 443.81060791015625, "training_acc": 48.75, "val_loss": 70.68812847137451, "val_acc": 55.0, "val_auroc": 0.576, "time": 378.28}
{"epoch": 19, "training_loss": 277.0593566894531, "training_acc": 51.25, "val_loss": 103.8107967376709, "val_acc": 45.0, "val_auroc": 0.576, "time": 398.42}
{"epoch": 20, "training_loss": 357.9185333251953, "training_acc": 48.75, "val_loss": 120.42327880859375, "val_acc": 55.0, "val_auroc": 0.616, "time": 414.79}
{"epoch": 21, "training_loss": 501.5335388183594, "training_acc": 48.75, "val_loss": 122.07813262939453, "val_acc": 55.0, "val_auroc": 0.646, "time": 432.97}
{"epoch": 22, "training_loss": 446.4411277770996, "training_acc": 51.25, "val_loss": 177.76723861694336, "val_acc": 45.0, "val_auroc": 0.566, "time": 452.28}
{"epoch": 23, "training_loss": 604.3569107055664, "training_acc": 48.75, "val_loss": 42.76566982269287, "val_acc": 55.0, "val_auroc": 0.657, "time": 472.24}
{"epoch": 24, "training_loss": 187.33330535888672, "training_acc": 51.25, "val_loss": 13.490723371505737, "val_acc": 55.0, "val_auroc": 0.606, "time": 489.57}
{"epoch": 25, "training_loss": 90.54471588134766, "training_acc": 46.25, "val_loss": 13.892203569412231, "val_acc": 55.0, "val_auroc": 0.586, "time": 508.84}
{"epoch": 26, "training_loss": 60.58986282348633, "training_acc": 51.25, "val_loss": 13.756755590438843, "val_acc": 55.0, "val_auroc": 0.616, "time": 527.4}
{"epoch": 27, "training_loss": 74.33821105957031, "training_acc": 48.75, "val_loss": 13.97444486618042, "val_acc": 55.0, "val_auroc": 0.566, "time": 548.01}
{"epoch": 28, "training_loss": 68.46632194519043, "training_acc": 51.25, "val_loss": 13.937234878540039, "val_acc": 55.0, "val_auroc": 0.586, "time": 565.17}
{"epoch": 29, "training_loss": 62.980438232421875, "training_acc": 48.75, "val_loss": 15.880632400512695, "val_acc": 45.0, "val_auroc": 0.576, "time": 584.58}
{"epoch": 30, "training_loss": 64.18737316131592, "training_acc": 48.75, "val_loss": 17.16167449951172, "val_acc": 55.0, "val_auroc": 0.515, "time": 603.16}
{"epoch": 31, "training_loss": 67.37721538543701, "training_acc": 51.25, "val_loss": 18.134819269180298, "val_acc": 45.0, "val_auroc": 0.545, "time": 624.65}
{"epoch": 32, "training_loss": 69.49255180358887, "training_acc": 48.75, "val_loss": 14.41595196723938, "val_acc": 55.0, "val_auroc": 0.566, "time": 642.29}
{"epoch": 33, "training_loss": 58.160943031311035, "training_acc": 51.25, "val_loss": 15.523560047149658, "val_acc": 55.0, "val_auroc": 0.566, "time": 660.79}
{"epoch": 34, "training_loss": 65.35660171508789, "training_acc": 50.0, "val_loss": 14.838541746139526, "val_acc": 45.0, "val_auroc": 0.576, "time": 678.76}
{"epoch": 35, "training_loss": 58.84744453430176, "training_acc": 48.75, "val_loss": 14.226493835449219, "val_acc": 55.0, "val_auroc": 0.556, "time": 700.13}
{"epoch": 36, "training_loss": 56.05287456512451, "training_acc": 55.0, "val_loss": 13.873623609542847, "val_acc": 55.0, "val_auroc": 0.556, "time": 717.51}
{"epoch": 37, "training_loss": 57.70747661590576, "training_acc": 51.25, "val_loss": 13.74441385269165, "val_acc": 55.0, "val_auroc": 0.566, "time": 737.16}
{"epoch": 38, "training_loss": 57.464717864990234, "training_acc": 45.0, "val_loss": 13.868811130523682, "val_acc": 55.0, "val_auroc": 0.576, "time": 757.12}
{"epoch": 39, "training_loss": 56.23584175109863, "training_acc": 43.75, "val_loss": 13.6534583568573, "val_acc": 55.0, "val_auroc": 0.576, "time": 778.24}
{"epoch": 40, "training_loss": 56.29199981689453, "training_acc": 50.0, "val_loss": 13.681116104125977, "val_acc": 55.0, "val_auroc": 0.576, "time": 794.82}
{"epoch": 41, "training_loss": 55.14134216308594, "training_acc": 53.75, "val_loss": 14.728895425796509, "val_acc": 60.0, "val_auroc": 0.596, "time": 812.26}
{"epoch": 42, "training_loss": 57.854286193847656, "training_acc": 48.75, "val_loss": 13.66085410118103, "val_acc": 55.0, "val_auroc": 0.556, "time": 830.41}
{"epoch": 43, "training_loss": 56.71761703491211, "training_acc": 52.5, "val_loss": 13.909357786178589, "val_acc": 55.0, "val_auroc": 0.576, "time": 851.47}
