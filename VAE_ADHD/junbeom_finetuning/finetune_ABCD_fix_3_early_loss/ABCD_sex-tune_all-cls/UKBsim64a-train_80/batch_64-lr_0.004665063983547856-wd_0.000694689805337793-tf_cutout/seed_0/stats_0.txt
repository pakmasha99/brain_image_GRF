"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 194.5321044921875, "training_acc": 46.25, "val_loss": 871523840.0, "val_acc": 50.0, "val_auroc": 0.5, "time": 19.49}
{"epoch": 1, "training_loss": 2849645478.8793945, "training_acc": 45.0, "val_loss": 17978078.75, "val_acc": 50.0, "val_auroc": 0.52, "time": 38.69}
{"epoch": 2, "training_loss": 56025310.5, "training_acc": 52.5, "val_loss": 256218.7890625, "val_acc": 50.0, "val_auroc": 0.49, "time": 61.8}
{"epoch": 3, "training_loss": 899652.03125, "training_acc": 47.5, "val_loss": 9456.544189453125, "val_acc": 50.0, "val_auroc": 0.48, "time": 86.75}
{"epoch": 4, "training_loss": 33185.02795410156, "training_acc": 47.5, "val_loss": 114.62485313415527, "val_acc": 50.0, "val_auroc": 0.32, "time": 105.14}
{"epoch": 5, "training_loss": 2168.598846435547, "training_acc": 45.0, "val_loss": 1481.9635009765625, "val_acc": 50.0, "val_auroc": 0.49, "time": 128.53}
{"epoch": 6, "training_loss": 4417.374423980713, "training_acc": 52.5, "val_loss": 726.7873382568359, "val_acc": 50.0, "val_auroc": 0.42, "time": 149.45}
{"epoch": 7, "training_loss": 2362.373992919922, "training_acc": 52.5, "val_loss": 934.4620513916016, "val_acc": 50.0, "val_auroc": 0.48, "time": 171.72}
{"epoch": 8, "training_loss": 3581.12255859375, "training_acc": 47.5, "val_loss": 126.16480827331543, "val_acc": 50.0, "val_auroc": 0.5, "time": 189.07}
{"epoch": 9, "training_loss": 686.4531860351562, "training_acc": 47.5, "val_loss": 264.740047454834, "val_acc": 50.0, "val_auroc": 0.55, "time": 205.89}
{"epoch": 10, "training_loss": 816.849588394165, "training_acc": 52.5, "val_loss": 440.7967758178711, "val_acc": 50.0, "val_auroc": 0.53, "time": 225.31}
{"epoch": 11, "training_loss": 1509.3414001464844, "training_acc": 47.5, "val_loss": 448.93077850341797, "val_acc": 50.0, "val_auroc": 0.58, "time": 243.56}
{"epoch": 12, "training_loss": 1452.146427154541, "training_acc": 47.5, "val_loss": 228.94058227539062, "val_acc": 50.0, "val_auroc": 0.53, "time": 260.49}
{"epoch": 13, "training_loss": 826.3340148925781, "training_acc": 52.5, "val_loss": 110.39697647094727, "val_acc": 50.0, "val_auroc": 0.55, "time": 279.55}
{"epoch": 14, "training_loss": 440.47972106933594, "training_acc": 42.5, "val_loss": 19.3576180934906, "val_acc": 50.0, "val_auroc": 0.65, "time": 300.65}
{"epoch": 15, "training_loss": 97.79718780517578, "training_acc": 52.5, "val_loss": 51.88199043273926, "val_acc": 50.0, "val_auroc": 0.61, "time": 318.4}
{"epoch": 16, "training_loss": 177.3180637359619, "training_acc": 47.5, "val_loss": 23.402163982391357, "val_acc": 50.0, "val_auroc": 0.71, "time": 335.54}
{"epoch": 17, "training_loss": 91.41516590118408, "training_acc": 47.5, "val_loss": 18.882251977920532, "val_acc": 50.0, "val_auroc": 0.68, "time": 356.52}
{"epoch": 18, "training_loss": 70.83871555328369, "training_acc": 50.0, "val_loss": 14.78056788444519, "val_acc": 50.0, "val_auroc": 0.74, "time": 377.06}
{"epoch": 19, "training_loss": 68.6033821105957, "training_acc": 40.0, "val_loss": 17.616318464279175, "val_acc": 50.0, "val_auroc": 0.75, "time": 394.71}
{"epoch": 20, "training_loss": 72.58852005004883, "training_acc": 47.5, "val_loss": 15.075187683105469, "val_acc": 50.0, "val_auroc": 0.66, "time": 412.04}
{"epoch": 21, "training_loss": 59.62785625457764, "training_acc": 52.5, "val_loss": 14.155830144882202, "val_acc": 50.0, "val_auroc": 0.69, "time": 431.13}
{"epoch": 22, "training_loss": 57.68706130981445, "training_acc": 47.5, "val_loss": 14.237769842147827, "val_acc": 50.0, "val_auroc": 0.63, "time": 451.29}
{"epoch": 23, "training_loss": 56.98430061340332, "training_acc": 52.5, "val_loss": 13.814252614974976, "val_acc": 50.0, "val_auroc": 0.6, "time": 469.89}
{"epoch": 24, "training_loss": 56.3004035949707, "training_acc": 47.5, "val_loss": 14.069826602935791, "val_acc": 50.0, "val_auroc": 0.65, "time": 485.89}
{"epoch": 25, "training_loss": 57.46350288391113, "training_acc": 47.5, "val_loss": 14.278011322021484, "val_acc": 50.0, "val_auroc": 0.6, "time": 505.51}
{"epoch": 26, "training_loss": 56.00573921203613, "training_acc": 52.5, "val_loss": 13.9409339427948, "val_acc": 50.0, "val_auroc": 0.63, "time": 523.11}
{"epoch": 27, "training_loss": 55.36287498474121, "training_acc": 52.5, "val_loss": 15.50455927848816, "val_acc": 50.0, "val_auroc": 0.58, "time": 542.0}
{"epoch": 28, "training_loss": 58.40596580505371, "training_acc": 52.5, "val_loss": 16.093822717666626, "val_acc": 50.0, "val_auroc": 0.57, "time": 559.14}
{"epoch": 29, "training_loss": 66.37657451629639, "training_acc": 47.5, "val_loss": 14.060977697372437, "val_acc": 50.0, "val_auroc": 0.59, "time": 579.78}
{"epoch": 30, "training_loss": 56.72012805938721, "training_acc": 52.5, "val_loss": 16.491413116455078, "val_acc": 50.0, "val_auroc": 0.58, "time": 599.59}
{"epoch": 31, "training_loss": 61.14121723175049, "training_acc": 53.75, "val_loss": 15.143402814865112, "val_acc": 50.0, "val_auroc": 0.52, "time": 618.18}
{"epoch": 32, "training_loss": 61.58981800079346, "training_acc": 47.5, "val_loss": 13.845350742340088, "val_acc": 50.0, "val_auroc": 0.58, "time": 634.52}
{"epoch": 33, "training_loss": 54.71274375915527, "training_acc": 58.75, "val_loss": 15.819575786590576, "val_acc": 50.0, "val_auroc": 0.58, "time": 652.91}
{"epoch": 34, "training_loss": 60.74075126647949, "training_acc": 52.5, "val_loss": 13.904529809951782, "val_acc": 50.0, "val_auroc": 0.55, "time": 670.76}
{"epoch": 35, "training_loss": 56.03411293029785, "training_acc": 43.75, "val_loss": 14.048384428024292, "val_acc": 50.0, "val_auroc": 0.54, "time": 689.52}
{"epoch": 36, "training_loss": 56.36773490905762, "training_acc": 47.5, "val_loss": 13.885713815689087, "val_acc": 50.0, "val_auroc": 0.55, "time": 706.74}
{"epoch": 37, "training_loss": 56.03730583190918, "training_acc": 56.25, "val_loss": 13.856066465377808, "val_acc": 50.0, "val_auroc": 0.55, "time": 724.3}
{"epoch": 38, "training_loss": 55.24070072174072, "training_acc": 55.0, "val_loss": 13.877240419387817, "val_acc": 50.0, "val_auroc": 0.53, "time": 744.64}
{"epoch": 39, "training_loss": 55.620036125183105, "training_acc": 47.5, "val_loss": 14.2479407787323, "val_acc": 50.0, "val_auroc": 0.58, "time": 762.77}
{"epoch": 40, "training_loss": 55.495646476745605, "training_acc": 52.5, "val_loss": 13.915983438491821, "val_acc": 50.0, "val_auroc": 0.59, "time": 778.79}
{"epoch": 41, "training_loss": 54.61049556732178, "training_acc": 53.75, "val_loss": 14.156758785247803, "val_acc": 50.0, "val_auroc": 0.56, "time": 797.97}
{"epoch": 42, "training_loss": 57.404343605041504, "training_acc": 47.5, "val_loss": 13.85845422744751, "val_acc": 50.0, "val_auroc": 0.57, "time": 816.28}
