"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 183.89564514160156, "training_acc": 52.5, "val_loss": 8492799360.0, "val_acc": 50.0, "val_auroc": 0.48, "time": 18.51}
{"epoch": 1, "training_loss": 25627066977.666748, "training_acc": 47.5, "val_loss": 3468.7261962890625, "val_acc": 50.0, "val_auroc": 0.56, "time": 38.75}
{"epoch": 2, "training_loss": 17858922.172851562, "training_acc": 50.0, "val_loss": 199364.00390625, "val_acc": 50.0, "val_auroc": 0.47, "time": 61.92}
{"epoch": 3, "training_loss": 691300.33203125, "training_acc": 47.5, "val_loss": 8096.5850830078125, "val_acc": 50.0, "val_auroc": 0.51, "time": 84.12}
{"epoch": 4, "training_loss": 33099.8466796875, "training_acc": 47.5, "val_loss": 5110.140686035156, "val_acc": 50.0, "val_auroc": 0.43, "time": 102.38}
{"epoch": 5, "training_loss": 18481.793334960938, "training_acc": 50.0, "val_loss": 2094.59228515625, "val_acc": 50.0, "val_auroc": 0.46, "time": 124.46}
{"epoch": 6, "training_loss": 6514.735656738281, "training_acc": 52.5, "val_loss": 1705.8726501464844, "val_acc": 50.0, "val_auroc": 0.42, "time": 148.13}
{"epoch": 7, "training_loss": 5217.740203857422, "training_acc": 50.0, "val_loss": 1535.9426879882812, "val_acc": 50.0, "val_auroc": 0.4, "time": 172.87}
{"epoch": 8, "training_loss": 5036.972900390625, "training_acc": 52.5, "val_loss": 1331.2274169921875, "val_acc": 50.0, "val_auroc": 0.48, "time": 189.9}
{"epoch": 9, "training_loss": 4846.680572509766, "training_acc": 47.5, "val_loss": 2065.120086669922, "val_acc": 50.0, "val_auroc": 0.37, "time": 209.48}
{"epoch": 10, "training_loss": 6430.384979248047, "training_acc": 52.5, "val_loss": 2300.703125, "val_acc": 50.0, "val_auroc": 0.47, "time": 228.11}
{"epoch": 11, "training_loss": 8478.166015625, "training_acc": 47.5, "val_loss": 231.21112823486328, "val_acc": 50.0, "val_auroc": 0.55, "time": 248.43}
{"epoch": 12, "training_loss": 753.6123008728027, "training_acc": 52.5, "val_loss": 818.7413787841797, "val_acc": 50.0, "val_auroc": 0.44, "time": 265.41}
{"epoch": 13, "training_loss": 2761.4520874023438, "training_acc": 47.5, "val_loss": 561.8380355834961, "val_acc": 50.0, "val_auroc": 0.45, "time": 284.63}
{"epoch": 14, "training_loss": 2034.6138610839844, "training_acc": 52.5, "val_loss": 197.68417358398438, "val_acc": 50.0, "val_auroc": 0.32, "time": 302.79}
{"epoch": 15, "training_loss": 718.3781051635742, "training_acc": 47.5, "val_loss": 39.454734325408936, "val_acc": 50.0, "val_auroc": 0.1, "time": 324.4}
{"epoch": 16, "training_loss": 211.00484466552734, "training_acc": 52.5, "val_loss": 117.58015632629395, "val_acc": 50.0, "val_auroc": 0.24, "time": 341.12}
{"epoch": 17, "training_loss": 380.3069381713867, "training_acc": 55.0, "val_loss": 15.991513729095459, "val_acc": 50.0, "val_auroc": 0.36, "time": 363.4}
{"epoch": 18, "training_loss": 179.18695831298828, "training_acc": 47.5, "val_loss": 64.63424682617188, "val_acc": 50.0, "val_auroc": 0.29, "time": 382.27}
{"epoch": 19, "training_loss": 237.1724090576172, "training_acc": 57.5, "val_loss": 117.7452278137207, "val_acc": 50.0, "val_auroc": 0.37, "time": 402.8}
{"epoch": 20, "training_loss": 436.6946830749512, "training_acc": 47.5, "val_loss": 24.340012073516846, "val_acc": 50.0, "val_auroc": 0.33, "time": 419.73}
{"epoch": 21, "training_loss": 121.21423721313477, "training_acc": 52.5, "val_loss": 35.75029134750366, "val_acc": 50.0, "val_auroc": 0.27, "time": 438.34}
{"epoch": 22, "training_loss": 226.79242706298828, "training_acc": 50.0, "val_loss": 104.57448959350586, "val_acc": 50.0, "val_auroc": 0.39, "time": 460.16}
{"epoch": 23, "training_loss": 342.4826316833496, "training_acc": 52.5, "val_loss": 64.4630765914917, "val_acc": 50.0, "val_auroc": 0.26, "time": 480.59}
{"epoch": 24, "training_loss": 204.43025970458984, "training_acc": 52.5, "val_loss": 60.25472164154053, "val_acc": 50.0, "val_auroc": 0.43, "time": 497.19}
{"epoch": 25, "training_loss": 233.22438049316406, "training_acc": 47.5, "val_loss": 34.12847280502319, "val_acc": 50.0, "val_auroc": 0.27, "time": 514.89}
{"epoch": 26, "training_loss": 126.66803741455078, "training_acc": 52.5, "val_loss": 15.800632238388062, "val_acc": 50.0, "val_auroc": 0.19, "time": 533.78}
{"epoch": 27, "training_loss": 89.58421325683594, "training_acc": 50.0, "val_loss": 17.4614417552948, "val_acc": 50.0, "val_auroc": 0.14, "time": 554.85}
{"epoch": 28, "training_loss": 64.76057815551758, "training_acc": 52.5, "val_loss": 36.80379629135132, "val_acc": 50.0, "val_auroc": 0.36, "time": 571.35}
{"epoch": 29, "training_loss": 148.4272346496582, "training_acc": 47.5, "val_loss": 14.090856313705444, "val_acc": 50.0, "val_auroc": 0.29, "time": 589.18}
{"epoch": 30, "training_loss": 61.86848831176758, "training_acc": 53.75, "val_loss": 32.591493129730225, "val_acc": 50.0, "val_auroc": 0.21, "time": 610.73}
{"epoch": 31, "training_loss": 109.52880382537842, "training_acc": 52.5, "val_loss": 25.709717273712158, "val_acc": 50.0, "val_auroc": 0.34, "time": 631.5}
{"epoch": 32, "training_loss": 101.63593673706055, "training_acc": 47.5, "val_loss": 14.390738010406494, "val_acc": 50.0, "val_auroc": 0.27, "time": 647.69}
{"epoch": 33, "training_loss": 57.06790351867676, "training_acc": 52.5, "val_loss": 15.707550048828125, "val_acc": 50.0, "val_auroc": 0.21, "time": 665.04}
{"epoch": 34, "training_loss": 58.96585750579834, "training_acc": 52.5, "val_loss": 14.485082626342773, "val_acc": 45.0, "val_auroc": 0.24, "time": 685.03}
{"epoch": 35, "training_loss": 59.13251495361328, "training_acc": 40.0, "val_loss": 15.068793296813965, "val_acc": 45.0, "val_auroc": 0.26, "time": 705.24}
{"epoch": 36, "training_loss": 61.29820251464844, "training_acc": 47.5, "val_loss": 14.25845742225647, "val_acc": 50.0, "val_auroc": 0.26, "time": 720.63}
{"epoch": 37, "training_loss": 58.71177291870117, "training_acc": 42.5, "val_loss": 14.958399534225464, "val_acc": 45.0, "val_auroc": 0.22, "time": 739.86}
{"epoch": 38, "training_loss": 59.78500747680664, "training_acc": 47.5, "val_loss": 14.975417852401733, "val_acc": 50.0, "val_auroc": 0.23, "time": 760.5}
{"epoch": 39, "training_loss": 58.187679290771484, "training_acc": 52.5, "val_loss": 14.18636679649353, "val_acc": 50.0, "val_auroc": 0.25, "time": 780.46}
{"epoch": 40, "training_loss": 56.06847381591797, "training_acc": 52.5, "val_loss": 14.652971029281616, "val_acc": 35.0, "val_auroc": 0.24, "time": 796.46}
{"epoch": 41, "training_loss": 60.47793197631836, "training_acc": 42.5, "val_loss": 14.264930486679077, "val_acc": 50.0, "val_auroc": 0.29, "time": 815.51}
{"epoch": 42, "training_loss": 56.358229637145996, "training_acc": 48.75, "val_loss": 14.175938367843628, "val_acc": 50.0, "val_auroc": 0.21, "time": 837.1}
{"epoch": 43, "training_loss": 55.228702545166016, "training_acc": 55.0, "val_loss": 14.86453890800476, "val_acc": 50.0, "val_auroc": 0.31, "time": 858.71}
{"epoch": 44, "training_loss": 56.625701904296875, "training_acc": 52.5, "val_loss": 14.24736738204956, "val_acc": 50.0, "val_auroc": 0.23, "time": 875.09}
{"epoch": 45, "training_loss": 56.46529006958008, "training_acc": 50.0, "val_loss": 14.197369813919067, "val_acc": 50.0, "val_auroc": 0.22, "time": 893.87}
{"epoch": 46, "training_loss": 55.612443923950195, "training_acc": 50.0, "val_loss": 15.575988292694092, "val_acc": 50.0, "val_auroc": 0.32, "time": 914.24}
{"epoch": 47, "training_loss": 59.299482345581055, "training_acc": 52.5, "val_loss": 14.169425964355469, "val_acc": 50.0, "val_auroc": 0.27, "time": 933.95}
{"epoch": 48, "training_loss": 57.37550163269043, "training_acc": 45.0, "val_loss": 14.142754077911377, "val_acc": 50.0, "val_auroc": 0.31, "time": 949.73}
