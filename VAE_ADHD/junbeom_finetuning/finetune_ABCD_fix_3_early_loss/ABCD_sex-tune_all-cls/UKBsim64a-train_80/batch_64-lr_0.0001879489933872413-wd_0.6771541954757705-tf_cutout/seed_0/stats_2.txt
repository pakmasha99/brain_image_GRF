"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 59.13884162902832, "training_acc": 41.25, "val_loss": 14.22545313835144, "val_acc": 50.0, "val_auroc": 0.86, "time": 18.77}
{"epoch": 1, "training_loss": 72.56455993652344, "training_acc": 47.5, "val_loss": 14.571794271469116, "val_acc": 50.0, "val_auroc": 0.83, "time": 35.54}
{"epoch": 2, "training_loss": 58.48929977416992, "training_acc": 47.5, "val_loss": 14.026244878768921, "val_acc": 50.0, "val_auroc": 0.34, "time": 58.72}
{"epoch": 3, "training_loss": 55.4391393661499, "training_acc": 52.5, "val_loss": 14.614278078079224, "val_acc": 50.0, "val_auroc": 0.47, "time": 83.58}
{"epoch": 4, "training_loss": 57.00171661376953, "training_acc": 52.5, "val_loss": 13.898519277572632, "val_acc": 50.0, "val_auroc": 0.24, "time": 101.81}
{"epoch": 5, "training_loss": 55.725918769836426, "training_acc": 48.75, "val_loss": 13.907387256622314, "val_acc": 50.0, "val_auroc": 0.24, "time": 118.87}
{"epoch": 6, "training_loss": 55.17332935333252, "training_acc": 55.0, "val_loss": 14.462282657623291, "val_acc": 50.0, "val_auroc": 0.32, "time": 139.39}
{"epoch": 7, "training_loss": 56.82788848876953, "training_acc": 52.5, "val_loss": 14.615929126739502, "val_acc": 50.0, "val_auroc": 0.35, "time": 160.34}
{"epoch": 8, "training_loss": 56.65450191497803, "training_acc": 52.5, "val_loss": 13.874077796936035, "val_acc": 50.0, "val_auroc": 0.55, "time": 176.4}
{"epoch": 9, "training_loss": 55.32743263244629, "training_acc": 52.5, "val_loss": 13.96966814994812, "val_acc": 50.0, "val_auroc": 0.7, "time": 193.23}
{"epoch": 10, "training_loss": 56.35100173950195, "training_acc": 47.5, "val_loss": 13.863848447799683, "val_acc": 50.0, "val_auroc": 0.69, "time": 213.97}
{"epoch": 11, "training_loss": 55.27049160003662, "training_acc": 52.5, "val_loss": 14.120274782180786, "val_acc": 50.0, "val_auroc": 0.36, "time": 234.72}
{"epoch": 12, "training_loss": 55.95492649078369, "training_acc": 52.5, "val_loss": 14.270975589752197, "val_acc": 50.0, "val_auroc": 0.31, "time": 252.28}
{"epoch": 13, "training_loss": 55.984806060791016, "training_acc": 52.5, "val_loss": 13.91168475151062, "val_acc": 50.0, "val_auroc": 0.59, "time": 269.74}
{"epoch": 14, "training_loss": 55.272446632385254, "training_acc": 53.75, "val_loss": 13.84567379951477, "val_acc": 50.0, "val_auroc": 0.66, "time": 288.83}
{"epoch": 15, "training_loss": 55.80405807495117, "training_acc": 47.5, "val_loss": 13.842407464981079, "val_acc": 50.0, "val_auroc": 0.69, "time": 309.37}
{"epoch": 16, "training_loss": 55.086618423461914, "training_acc": 58.75, "val_loss": 14.083770513534546, "val_acc": 50.0, "val_auroc": 0.56, "time": 326.16}
{"epoch": 17, "training_loss": 55.861188888549805, "training_acc": 52.5, "val_loss": 14.30417537689209, "val_acc": 50.0, "val_auroc": 0.55, "time": 343.83}
{"epoch": 18, "training_loss": 56.22287082672119, "training_acc": 52.5, "val_loss": 14.00367259979248, "val_acc": 50.0, "val_auroc": 0.47, "time": 362.74}
{"epoch": 19, "training_loss": 55.29349613189697, "training_acc": 52.5, "val_loss": 13.874351978302002, "val_acc": 50.0, "val_auroc": 0.47, "time": 383.55}
{"epoch": 20, "training_loss": 55.69770812988281, "training_acc": 47.5, "val_loss": 13.933502435684204, "val_acc": 50.0, "val_auroc": 0.28, "time": 401.51}
{"epoch": 21, "training_loss": 55.91528511047363, "training_acc": 47.5, "val_loss": 13.87582540512085, "val_acc": 50.0, "val_auroc": 0.21, "time": 423.06}
{"epoch": 22, "training_loss": 55.328229904174805, "training_acc": 52.5, "val_loss": 14.03130054473877, "val_acc": 50.0, "val_auroc": 0.25, "time": 441.67}
{"epoch": 23, "training_loss": 55.508745193481445, "training_acc": 52.5, "val_loss": 14.215046167373657, "val_acc": 50.0, "val_auroc": 0.39, "time": 461.7}
{"epoch": 24, "training_loss": 56.04836654663086, "training_acc": 52.5, "val_loss": 14.169148206710815, "val_acc": 50.0, "val_auroc": 0.49, "time": 478.68}
{"epoch": 25, "training_loss": 55.919301986694336, "training_acc": 52.5, "val_loss": 13.985350131988525, "val_acc": 50.0, "val_auroc": 0.54, "time": 496.4}
{"epoch": 26, "training_loss": 55.73188304901123, "training_acc": 52.5, "val_loss": 13.915408849716187, "val_acc": 50.0, "val_auroc": 0.55, "time": 516.6}
{"epoch": 27, "training_loss": 55.28624248504639, "training_acc": 52.5, "val_loss": 13.961347341537476, "val_acc": 50.0, "val_auroc": 0.46, "time": 537.13}
{"epoch": 28, "training_loss": 55.58790397644043, "training_acc": 52.5, "val_loss": 13.9040207862854, "val_acc": 50.0, "val_auroc": 0.46, "time": 554.86}
{"epoch": 29, "training_loss": 55.352277755737305, "training_acc": 52.5, "val_loss": 13.865399360656738, "val_acc": 50.0, "val_auroc": 0.57, "time": 574.09}
{"epoch": 30, "training_loss": 55.53161430358887, "training_acc": 47.5, "val_loss": 13.868368864059448, "val_acc": 50.0, "val_auroc": 0.56, "time": 593.01}
{"epoch": 31, "training_loss": 55.55593490600586, "training_acc": 51.25, "val_loss": 13.859734535217285, "val_acc": 50.0, "val_auroc": 0.57, "time": 613.1}
{"epoch": 32, "training_loss": 55.34771919250488, "training_acc": 56.25, "val_loss": 13.857377767562866, "val_acc": 50.0, "val_auroc": 0.63, "time": 629.68}
{"epoch": 33, "training_loss": 55.302629470825195, "training_acc": 52.5, "val_loss": 13.853926658630371, "val_acc": 50.0, "val_auroc": 0.65, "time": 646.7}
{"epoch": 34, "training_loss": 55.313045501708984, "training_acc": 53.75, "val_loss": 13.860985040664673, "val_acc": 50.0, "val_auroc": 0.69, "time": 666.39}
