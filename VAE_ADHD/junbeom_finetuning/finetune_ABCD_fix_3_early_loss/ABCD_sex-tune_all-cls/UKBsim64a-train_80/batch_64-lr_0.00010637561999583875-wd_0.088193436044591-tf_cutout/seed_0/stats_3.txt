"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.58073806762695, "training_acc": 52.5, "val_loss": 13.819514513015747, "val_acc": 55.0, "val_auroc": 0.444, "time": 19.74}
{"epoch": 1, "training_loss": 55.48492240905762, "training_acc": 47.5, "val_loss": 13.841029405593872, "val_acc": 55.0, "val_auroc": 0.545, "time": 41.31}
{"epoch": 2, "training_loss": 55.21300411224365, "training_acc": 60.0, "val_loss": 13.805234432220459, "val_acc": 55.0, "val_auroc": 0.525, "time": 66.95}
{"epoch": 3, "training_loss": 55.00443077087402, "training_acc": 53.75, "val_loss": 13.876560926437378, "val_acc": 55.0, "val_auroc": 0.495, "time": 91.4}
{"epoch": 4, "training_loss": 55.23751449584961, "training_acc": 58.75, "val_loss": 13.817504644393921, "val_acc": 55.0, "val_auroc": 0.545, "time": 109.05}
{"epoch": 5, "training_loss": 55.02555847167969, "training_acc": 53.75, "val_loss": 13.789039850234985, "val_acc": 55.0, "val_auroc": 0.505, "time": 130.4}
{"epoch": 6, "training_loss": 54.846567153930664, "training_acc": 51.25, "val_loss": 13.777947425842285, "val_acc": 55.0, "val_auroc": 0.485, "time": 153.17}
{"epoch": 7, "training_loss": 54.73585891723633, "training_acc": 52.5, "val_loss": 13.843024969100952, "val_acc": 55.0, "val_auroc": 0.525, "time": 173.89}
{"epoch": 8, "training_loss": 54.90130805969238, "training_acc": 70.0, "val_loss": 13.889678716659546, "val_acc": 55.0, "val_auroc": 0.535, "time": 190.36}
{"epoch": 9, "training_loss": 54.51964282989502, "training_acc": 62.5, "val_loss": 13.84229063987732, "val_acc": 55.0, "val_auroc": 0.525, "time": 211.25}
{"epoch": 10, "training_loss": 54.282620429992676, "training_acc": 70.0, "val_loss": 13.773680925369263, "val_acc": 55.0, "val_auroc": 0.586, "time": 232.94}
{"epoch": 11, "training_loss": 55.04482173919678, "training_acc": 51.25, "val_loss": 13.782356977462769, "val_acc": 55.0, "val_auroc": 0.576, "time": 252.43}
{"epoch": 12, "training_loss": 54.937238693237305, "training_acc": 51.25, "val_loss": 13.93190860748291, "val_acc": 55.0, "val_auroc": 0.525, "time": 270.02}
{"epoch": 13, "training_loss": 54.964786529541016, "training_acc": 48.75, "val_loss": 14.019056558609009, "val_acc": 55.0, "val_auroc": 0.515, "time": 289.25}
{"epoch": 14, "training_loss": 55.182573318481445, "training_acc": 52.5, "val_loss": 13.866925239562988, "val_acc": 55.0, "val_auroc": 0.535, "time": 310.68}
{"epoch": 15, "training_loss": 54.453941345214844, "training_acc": 72.5, "val_loss": 13.790524005889893, "val_acc": 55.0, "val_auroc": 0.556, "time": 330.98}
{"epoch": 16, "training_loss": 54.67513084411621, "training_acc": 51.25, "val_loss": 13.842281103134155, "val_acc": 55.0, "val_auroc": 0.576, "time": 347.58}
{"epoch": 17, "training_loss": 55.19108009338379, "training_acc": 51.25, "val_loss": 13.803635835647583, "val_acc": 55.0, "val_auroc": 0.515, "time": 367.64}
{"epoch": 18, "training_loss": 53.92696571350098, "training_acc": 61.25, "val_loss": 14.011902809143066, "val_acc": 55.0, "val_auroc": 0.667, "time": 388.49}
{"epoch": 19, "training_loss": 55.48149299621582, "training_acc": 48.75, "val_loss": 14.062502384185791, "val_acc": 55.0, "val_auroc": 0.586, "time": 408.33}
{"epoch": 20, "training_loss": 55.36349678039551, "training_acc": 48.75, "val_loss": 13.93497347831726, "val_acc": 55.0, "val_auroc": 0.545, "time": 425.69}
{"epoch": 21, "training_loss": 54.84500789642334, "training_acc": 56.25, "val_loss": 13.794554471969604, "val_acc": 55.0, "val_auroc": 0.515, "time": 445.43}
{"epoch": 22, "training_loss": 54.86843490600586, "training_acc": 51.25, "val_loss": 13.78302812576294, "val_acc": 55.0, "val_auroc": 0.535, "time": 465.74}
{"epoch": 23, "training_loss": 54.55291557312012, "training_acc": 52.5, "val_loss": 13.787553310394287, "val_acc": 55.0, "val_auroc": 0.535, "time": 485.18}
{"epoch": 24, "training_loss": 54.3339204788208, "training_acc": 57.5, "val_loss": 13.78316879272461, "val_acc": 55.0, "val_auroc": 0.556, "time": 501.82}
{"epoch": 25, "training_loss": 54.131940841674805, "training_acc": 53.75, "val_loss": 13.856680393218994, "val_acc": 55.0, "val_auroc": 0.576, "time": 521.31}
{"epoch": 26, "training_loss": 54.71041488647461, "training_acc": 51.25, "val_loss": 13.78475546836853, "val_acc": 55.0, "val_auroc": 0.556, "time": 544.25}
{"epoch": 27, "training_loss": 53.608455657958984, "training_acc": 61.25, "val_loss": 13.740705251693726, "val_acc": 55.0, "val_auroc": 0.556, "time": 564.64}
{"epoch": 28, "training_loss": 53.83263874053955, "training_acc": 60.0, "val_loss": 13.907337188720703, "val_acc": 55.0, "val_auroc": 0.545, "time": 581.71}
{"epoch": 29, "training_loss": 54.015342712402344, "training_acc": 61.25, "val_loss": 14.080623388290405, "val_acc": 55.0, "val_auroc": 0.606, "time": 601.68}
{"epoch": 30, "training_loss": 54.662949562072754, "training_acc": 50.0, "val_loss": 13.786745071411133, "val_acc": 55.0, "val_auroc": 0.525, "time": 621.81}
{"epoch": 31, "training_loss": 53.64743423461914, "training_acc": 57.5, "val_loss": 13.803777694702148, "val_acc": 55.0, "val_auroc": 0.545, "time": 641.02}
{"epoch": 32, "training_loss": 52.987610816955566, "training_acc": 63.75, "val_loss": 14.000600576400757, "val_acc": 55.0, "val_auroc": 0.545, "time": 657.33}
{"epoch": 33, "training_loss": 53.22726249694824, "training_acc": 58.75, "val_loss": 13.803044557571411, "val_acc": 55.0, "val_auroc": 0.566, "time": 676.93}
{"epoch": 34, "training_loss": 52.29586315155029, "training_acc": 70.0, "val_loss": 13.90375018119812, "val_acc": 55.0, "val_auroc": 0.566, "time": 697.2}
{"epoch": 35, "training_loss": 51.86846733093262, "training_acc": 62.5, "val_loss": 14.69744324684143, "val_acc": 55.0, "val_auroc": 0.616, "time": 716.54}
{"epoch": 36, "training_loss": 56.42312526702881, "training_acc": 48.75, "val_loss": 14.183838367462158, "val_acc": 55.0, "val_auroc": 0.485, "time": 733.53}
{"epoch": 37, "training_loss": 55.55440044403076, "training_acc": 48.75, "val_loss": 13.81259799003601, "val_acc": 55.0, "val_auroc": 0.535, "time": 753.84}
{"epoch": 38, "training_loss": 55.17609405517578, "training_acc": 51.25, "val_loss": 13.77931833267212, "val_acc": 55.0, "val_auroc": 0.465, "time": 774.76}
{"epoch": 39, "training_loss": 55.457672119140625, "training_acc": 51.25, "val_loss": 13.783737421035767, "val_acc": 55.0, "val_auroc": 0.404, "time": 794.84}
{"epoch": 40, "training_loss": 55.53887367248535, "training_acc": 51.25, "val_loss": 13.785030841827393, "val_acc": 55.0, "val_auroc": 0.404, "time": 811.8}
{"epoch": 41, "training_loss": 55.26481628417969, "training_acc": 51.25, "val_loss": 13.85440707206726, "val_acc": 55.0, "val_auroc": 0.465, "time": 831.77}
{"epoch": 42, "training_loss": 55.259395599365234, "training_acc": 55.0, "val_loss": 13.90430212020874, "val_acc": 55.0, "val_auroc": 0.394, "time": 853.57}
{"epoch": 43, "training_loss": 55.29807472229004, "training_acc": 56.25, "val_loss": 13.855305910110474, "val_acc": 55.0, "val_auroc": 0.404, "time": 873.11}
{"epoch": 44, "training_loss": 55.217740058898926, "training_acc": 55.0, "val_loss": 13.846191167831421, "val_acc": 55.0, "val_auroc": 0.424, "time": 892.0}
{"epoch": 45, "training_loss": 55.10960006713867, "training_acc": 56.25, "val_loss": 13.90122652053833, "val_acc": 55.0, "val_auroc": 0.434, "time": 910.69}
{"epoch": 46, "training_loss": 55.07097244262695, "training_acc": 60.0, "val_loss": 13.958252668380737, "val_acc": 55.0, "val_auroc": 0.434, "time": 931.29}
