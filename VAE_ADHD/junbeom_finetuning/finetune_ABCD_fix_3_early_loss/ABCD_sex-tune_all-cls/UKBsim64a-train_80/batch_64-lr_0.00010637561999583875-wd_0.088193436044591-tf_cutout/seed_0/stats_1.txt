"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.621646881103516, "training_acc": 52.5, "val_loss": 13.868865966796875, "val_acc": 50.0, "val_auroc": 0.61, "time": 19.4}
{"epoch": 1, "training_loss": 55.41731929779053, "training_acc": 52.5, "val_loss": 13.841758966445923, "val_acc": 50.0, "val_auroc": 0.65, "time": 41.05}
{"epoch": 2, "training_loss": 55.3641300201416, "training_acc": 52.5, "val_loss": 13.831440210342407, "val_acc": 50.0, "val_auroc": 0.66, "time": 65.54}
{"epoch": 3, "training_loss": 55.28450965881348, "training_acc": 52.5, "val_loss": 13.847203254699707, "val_acc": 50.0, "val_auroc": 0.67, "time": 89.93}
{"epoch": 4, "training_loss": 55.20241069793701, "training_acc": 52.5, "val_loss": 13.863697052001953, "val_acc": 50.0, "val_auroc": 0.65, "time": 109.33}
{"epoch": 5, "training_loss": 55.22977256774902, "training_acc": 52.5, "val_loss": 13.813921213150024, "val_acc": 50.0, "val_auroc": 0.79, "time": 129.39}
{"epoch": 6, "training_loss": 55.183993339538574, "training_acc": 52.5, "val_loss": 13.765180110931396, "val_acc": 50.0, "val_auroc": 0.81, "time": 151.09}
{"epoch": 7, "training_loss": 55.12063789367676, "training_acc": 52.5, "val_loss": 13.771966695785522, "val_acc": 50.0, "val_auroc": 0.8, "time": 170.99}
{"epoch": 8, "training_loss": 54.963985443115234, "training_acc": 52.5, "val_loss": 13.76463770866394, "val_acc": 50.0, "val_auroc": 0.78, "time": 188.84}
{"epoch": 9, "training_loss": 54.9715576171875, "training_acc": 52.5, "val_loss": 13.784240484237671, "val_acc": 50.0, "val_auroc": 0.8, "time": 208.08}
{"epoch": 10, "training_loss": 55.18473434448242, "training_acc": 62.5, "val_loss": 13.77742886543274, "val_acc": 50.0, "val_auroc": 0.78, "time": 227.11}
{"epoch": 11, "training_loss": 55.0748233795166, "training_acc": 56.25, "val_loss": 13.736565113067627, "val_acc": 50.0, "val_auroc": 0.81, "time": 248.31}
{"epoch": 12, "training_loss": 54.89759635925293, "training_acc": 52.5, "val_loss": 13.776040077209473, "val_acc": 50.0, "val_auroc": 0.81, "time": 264.75}
{"epoch": 13, "training_loss": 55.06715965270996, "training_acc": 52.5, "val_loss": 13.671153783798218, "val_acc": 50.0, "val_auroc": 0.8, "time": 284.33}
{"epoch": 14, "training_loss": 55.05813217163086, "training_acc": 52.5, "val_loss": 13.686760663986206, "val_acc": 50.0, "val_auroc": 0.78, "time": 307.24}
{"epoch": 15, "training_loss": 54.87848663330078, "training_acc": 52.5, "val_loss": 13.690493106842041, "val_acc": 50.0, "val_auroc": 0.77, "time": 328.58}
{"epoch": 16, "training_loss": 55.1763801574707, "training_acc": 52.5, "val_loss": 13.619468212127686, "val_acc": 50.0, "val_auroc": 0.77, "time": 346.9}
{"epoch": 17, "training_loss": 54.86654281616211, "training_acc": 52.5, "val_loss": 13.57947587966919, "val_acc": 50.0, "val_auroc": 0.76, "time": 365.77}
{"epoch": 18, "training_loss": 54.2982063293457, "training_acc": 55.0, "val_loss": 13.790429830551147, "val_acc": 50.0, "val_auroc": 0.81, "time": 385.97}
{"epoch": 19, "training_loss": 55.135637283325195, "training_acc": 53.75, "val_loss": 13.678265810012817, "val_acc": 50.0, "val_auroc": 0.87, "time": 406.71}
{"epoch": 20, "training_loss": 54.6871337890625, "training_acc": 57.5, "val_loss": 13.438267707824707, "val_acc": 50.0, "val_auroc": 0.81, "time": 424.11}
{"epoch": 21, "training_loss": 54.10807514190674, "training_acc": 65.0, "val_loss": 13.576420545578003, "val_acc": 50.0, "val_auroc": 0.78, "time": 442.16}
{"epoch": 22, "training_loss": 54.746291160583496, "training_acc": 52.5, "val_loss": 13.364667892456055, "val_acc": 50.0, "val_auroc": 0.81, "time": 463.73}
{"epoch": 23, "training_loss": 54.25342559814453, "training_acc": 52.5, "val_loss": 13.404293060302734, "val_acc": 50.0, "val_auroc": 0.84, "time": 482.84}
{"epoch": 24, "training_loss": 53.78810501098633, "training_acc": 65.0, "val_loss": 13.507765531539917, "val_acc": 50.0, "val_auroc": 0.82, "time": 500.57}
{"epoch": 25, "training_loss": 54.03010368347168, "training_acc": 52.5, "val_loss": 13.25478196144104, "val_acc": 50.0, "val_auroc": 0.84, "time": 519.58}
{"epoch": 26, "training_loss": 53.36127853393555, "training_acc": 61.25, "val_loss": 13.100199699401855, "val_acc": 50.0, "val_auroc": 0.84, "time": 541.61}
{"epoch": 27, "training_loss": 52.89968299865723, "training_acc": 61.25, "val_loss": 12.929372787475586, "val_acc": 50.0, "val_auroc": 0.82, "time": 564.87}
{"epoch": 28, "training_loss": 53.17298698425293, "training_acc": 65.0, "val_loss": 14.00647521018982, "val_acc": 50.0, "val_auroc": 0.56, "time": 581.67}
{"epoch": 29, "training_loss": 55.9903450012207, "training_acc": 47.5, "val_loss": 13.890078067779541, "val_acc": 50.0, "val_auroc": 0.42, "time": 598.7}
{"epoch": 30, "training_loss": 55.51809597015381, "training_acc": 48.75, "val_loss": 13.858016729354858, "val_acc": 50.0, "val_auroc": 0.79, "time": 618.39}
{"epoch": 31, "training_loss": 55.28327560424805, "training_acc": 52.5, "val_loss": 13.92579436302185, "val_acc": 50.0, "val_auroc": 0.75, "time": 639.41}
{"epoch": 32, "training_loss": 55.491973876953125, "training_acc": 52.5, "val_loss": 13.878109455108643, "val_acc": 50.0, "val_auroc": 0.72, "time": 658.1}
{"epoch": 33, "training_loss": 55.35865306854248, "training_acc": 52.5, "val_loss": 13.84827971458435, "val_acc": 50.0, "val_auroc": 0.76, "time": 676.8}
{"epoch": 34, "training_loss": 55.32857131958008, "training_acc": 52.5, "val_loss": 13.870877027511597, "val_acc": 50.0, "val_auroc": 0.73, "time": 696.89}
{"epoch": 35, "training_loss": 55.55114555358887, "training_acc": 52.5, "val_loss": 13.86805534362793, "val_acc": 50.0, "val_auroc": 0.66, "time": 718.45}
{"epoch": 36, "training_loss": 55.20031929016113, "training_acc": 52.5, "val_loss": 13.848646879196167, "val_acc": 50.0, "val_auroc": 0.73, "time": 736.19}
{"epoch": 37, "training_loss": 55.490057945251465, "training_acc": 47.5, "val_loss": 13.899765014648438, "val_acc": 50.0, "val_auroc": 0.78, "time": 754.92}
{"epoch": 38, "training_loss": 55.957258224487305, "training_acc": 47.5, "val_loss": 13.886195421218872, "val_acc": 50.0, "val_auroc": 0.76, "time": 774.86}
{"epoch": 39, "training_loss": 55.7928581237793, "training_acc": 47.5, "val_loss": 13.854668140411377, "val_acc": 50.0, "val_auroc": 0.67, "time": 794.91}
{"epoch": 40, "training_loss": 55.43498992919922, "training_acc": 55.0, "val_loss": 13.873381614685059, "val_acc": 50.0, "val_auroc": 0.69, "time": 813.32}
{"epoch": 41, "training_loss": 55.44491767883301, "training_acc": 52.5, "val_loss": 13.873122930526733, "val_acc": 50.0, "val_auroc": 0.67, "time": 831.14}
{"epoch": 42, "training_loss": 55.34630489349365, "training_acc": 52.5, "val_loss": 13.857598304748535, "val_acc": 50.0, "val_auroc": 0.75, "time": 850.48}
{"epoch": 43, "training_loss": 55.35165214538574, "training_acc": 52.5, "val_loss": 13.868440389633179, "val_acc": 50.0, "val_auroc": 0.68, "time": 870.8}
{"epoch": 44, "training_loss": 55.33393573760986, "training_acc": 52.5, "val_loss": 13.88601303100586, "val_acc": 50.0, "val_auroc": 0.68, "time": 891.52}
{"epoch": 45, "training_loss": 55.32699203491211, "training_acc": 52.5, "val_loss": 13.88379454612732, "val_acc": 50.0, "val_auroc": 0.64, "time": 909.05}
{"epoch": 46, "training_loss": 55.36224174499512, "training_acc": 52.5, "val_loss": 13.888062238693237, "val_acc": 50.0, "val_auroc": 0.64, "time": 928.19}
