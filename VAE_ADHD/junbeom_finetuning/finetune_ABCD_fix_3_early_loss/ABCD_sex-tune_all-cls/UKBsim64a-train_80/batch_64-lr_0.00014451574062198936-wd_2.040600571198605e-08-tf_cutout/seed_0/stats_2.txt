"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.743764877319336, "training_acc": 52.5, "val_loss": 13.981653451919556, "val_acc": 50.0, "val_auroc": 0.25, "time": 17.57}
{"epoch": 1, "training_loss": 55.581459045410156, "training_acc": 52.5, "val_loss": 13.969337940216064, "val_acc": 50.0, "val_auroc": 0.26, "time": 34.85}
{"epoch": 2, "training_loss": 55.23935413360596, "training_acc": 52.5, "val_loss": 13.958594799041748, "val_acc": 50.0, "val_auroc": 0.38, "time": 58.81}
{"epoch": 3, "training_loss": 55.302934646606445, "training_acc": 52.5, "val_loss": 13.961372375488281, "val_acc": 50.0, "val_auroc": 0.33, "time": 81.5}
{"epoch": 4, "training_loss": 55.30149555206299, "training_acc": 52.5, "val_loss": 13.911479711532593, "val_acc": 50.0, "val_auroc": 0.6, "time": 99.3}
{"epoch": 5, "training_loss": 55.223876953125, "training_acc": 52.5, "val_loss": 13.885765075683594, "val_acc": 50.0, "val_auroc": 0.51, "time": 117.73}
{"epoch": 6, "training_loss": 55.278029441833496, "training_acc": 52.5, "val_loss": 13.945908546447754, "val_acc": 50.0, "val_auroc": 0.72, "time": 137.9}
{"epoch": 7, "training_loss": 55.210307121276855, "training_acc": 52.5, "val_loss": 14.041348695755005, "val_acc": 50.0, "val_auroc": 0.51, "time": 158.4}
{"epoch": 8, "training_loss": 55.446099281311035, "training_acc": 52.5, "val_loss": 13.902995586395264, "val_acc": 50.0, "val_auroc": 0.57, "time": 174.54}
{"epoch": 9, "training_loss": 55.139780044555664, "training_acc": 52.5, "val_loss": 13.891414403915405, "val_acc": 50.0, "val_auroc": 0.45, "time": 190.25}
{"epoch": 10, "training_loss": 55.34825134277344, "training_acc": 57.5, "val_loss": 13.895691633224487, "val_acc": 50.0, "val_auroc": 0.43, "time": 209.54}
{"epoch": 11, "training_loss": 55.218923568725586, "training_acc": 52.5, "val_loss": 13.946079015731812, "val_acc": 50.0, "val_auroc": 0.46, "time": 227.6}
{"epoch": 12, "training_loss": 55.32202339172363, "training_acc": 52.5, "val_loss": 13.941034078598022, "val_acc": 50.0, "val_auroc": 0.68, "time": 245.09}
{"epoch": 13, "training_loss": 55.25230026245117, "training_acc": 52.5, "val_loss": 13.836967945098877, "val_acc": 50.0, "val_auroc": 0.81, "time": 262.43}
{"epoch": 14, "training_loss": 55.159976959228516, "training_acc": 52.5, "val_loss": 13.789491653442383, "val_acc": 50.0, "val_auroc": 0.8, "time": 280.45}
{"epoch": 15, "training_loss": 55.21820831298828, "training_acc": 52.5, "val_loss": 13.910092115402222, "val_acc": 50.0, "val_auroc": 0.77, "time": 299.74}
{"epoch": 16, "training_loss": 55.12027359008789, "training_acc": 52.5, "val_loss": 14.061325788497925, "val_acc": 50.0, "val_auroc": 0.78, "time": 315.73}
{"epoch": 17, "training_loss": 55.70558261871338, "training_acc": 52.5, "val_loss": 14.068533182144165, "val_acc": 50.0, "val_auroc": 0.81, "time": 331.79}
{"epoch": 18, "training_loss": 55.60341835021973, "training_acc": 52.5, "val_loss": 13.920739889144897, "val_acc": 50.0, "val_auroc": 0.72, "time": 349.67}
{"epoch": 19, "training_loss": 55.23743534088135, "training_acc": 52.5, "val_loss": 13.856323957443237, "val_acc": 50.0, "val_auroc": 0.67, "time": 372.22}
{"epoch": 20, "training_loss": 55.38829517364502, "training_acc": 50.0, "val_loss": 13.870464563369751, "val_acc": 50.0, "val_auroc": 0.5, "time": 391.57}
{"epoch": 21, "training_loss": 55.414554595947266, "training_acc": 47.5, "val_loss": 13.86008620262146, "val_acc": 50.0, "val_auroc": 0.59, "time": 410.64}
{"epoch": 22, "training_loss": 55.269845962524414, "training_acc": 52.5, "val_loss": 13.892595767974854, "val_acc": 50.0, "val_auroc": 0.79, "time": 429.46}
{"epoch": 23, "training_loss": 55.227821350097656, "training_acc": 52.5, "val_loss": 13.95311713218689, "val_acc": 50.0, "val_auroc": 0.82, "time": 448.98}
{"epoch": 24, "training_loss": 55.364126205444336, "training_acc": 52.5, "val_loss": 14.018748998641968, "val_acc": 50.0, "val_auroc": 0.8, "time": 466.26}
{"epoch": 25, "training_loss": 55.46634387969971, "training_acc": 52.5, "val_loss": 13.991267681121826, "val_acc": 50.0, "val_auroc": 0.6, "time": 482.96}
{"epoch": 26, "training_loss": 55.60984802246094, "training_acc": 52.5, "val_loss": 13.966914415359497, "val_acc": 50.0, "val_auroc": 0.56, "time": 502.56}
{"epoch": 27, "training_loss": 55.244436264038086, "training_acc": 52.5, "val_loss": 14.001365900039673, "val_acc": 50.0, "val_auroc": 0.44, "time": 521.66}
{"epoch": 28, "training_loss": 55.440497398376465, "training_acc": 52.5, "val_loss": 13.897775411605835, "val_acc": 50.0, "val_auroc": 0.52, "time": 540.59}
{"epoch": 29, "training_loss": 55.23735427856445, "training_acc": 52.5, "val_loss": 13.860303163528442, "val_acc": 50.0, "val_auroc": 0.6, "time": 559.31}
{"epoch": 30, "training_loss": 55.40007972717285, "training_acc": 55.0, "val_loss": 13.862558603286743, "val_acc": 50.0, "val_auroc": 0.49, "time": 577.57}
{"epoch": 31, "training_loss": 55.39677429199219, "training_acc": 51.25, "val_loss": 13.848540782928467, "val_acc": 50.0, "val_auroc": 0.63, "time": 597.12}
{"epoch": 32, "training_loss": 55.25576972961426, "training_acc": 52.5, "val_loss": 13.832014799118042, "val_acc": 50.0, "val_auroc": 0.72, "time": 615.48}
{"epoch": 33, "training_loss": 55.22340774536133, "training_acc": 63.75, "val_loss": 13.827224969863892, "val_acc": 50.0, "val_auroc": 0.69, "time": 632.63}
