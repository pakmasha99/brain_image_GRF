"main_optuna_fix_3.py --pretrained_path /scratch/connectome/study_group/VAE_ADHD/junbeom_weights/UKBsim64a.pth --mode finetuning --train_num 80 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_ABCD_fix_3_early_loss --binary_class True --run_where lab --early_criteria loss"
{"epoch": 0, "training_loss": 55.82162857055664, "training_acc": 52.5, "val_loss": 13.902920484542847, "val_acc": 50.0, "val_auroc": 0.42, "time": 18.56}
{"epoch": 1, "training_loss": 55.63445281982422, "training_acc": 47.5, "val_loss": 13.90223741531372, "val_acc": 50.0, "val_auroc": 0.42, "time": 38.73}
{"epoch": 2, "training_loss": 55.13216495513916, "training_acc": 52.5, "val_loss": 13.862619400024414, "val_acc": 50.0, "val_auroc": 0.52, "time": 60.0}
{"epoch": 3, "training_loss": 54.88680648803711, "training_acc": 52.5, "val_loss": 13.881244659423828, "val_acc": 50.0, "val_auroc": 0.46, "time": 82.85}
{"epoch": 4, "training_loss": 55.130035400390625, "training_acc": 58.75, "val_loss": 13.86738657951355, "val_acc": 50.0, "val_auroc": 0.49, "time": 101.02}
{"epoch": 5, "training_loss": 55.23635959625244, "training_acc": 57.5, "val_loss": 13.885993957519531, "val_acc": 50.0, "val_auroc": 0.48, "time": 119.05}
{"epoch": 6, "training_loss": 55.000017166137695, "training_acc": 56.25, "val_loss": 13.86561632156372, "val_acc": 50.0, "val_auroc": 0.49, "time": 139.42}
{"epoch": 7, "training_loss": 54.95361518859863, "training_acc": 62.5, "val_loss": 13.858040571212769, "val_acc": 50.0, "val_auroc": 0.48, "time": 161.83}
{"epoch": 8, "training_loss": 54.81948471069336, "training_acc": 58.75, "val_loss": 13.877085447311401, "val_acc": 50.0, "val_auroc": 0.46, "time": 179.15}
{"epoch": 9, "training_loss": 54.377458572387695, "training_acc": 65.0, "val_loss": 13.876749277114868, "val_acc": 50.0, "val_auroc": 0.45, "time": 196.8}
{"epoch": 10, "training_loss": 53.929710388183594, "training_acc": 61.25, "val_loss": 14.091787338256836, "val_acc": 50.0, "val_auroc": 0.32, "time": 216.11}
{"epoch": 11, "training_loss": 54.583333015441895, "training_acc": 53.75, "val_loss": 13.83327603340149, "val_acc": 50.0, "val_auroc": 0.49, "time": 238.16}
{"epoch": 12, "training_loss": 53.956467628479004, "training_acc": 57.5, "val_loss": 13.776969909667969, "val_acc": 50.0, "val_auroc": 0.48, "time": 256.04}
{"epoch": 13, "training_loss": 53.157379150390625, "training_acc": 65.0, "val_loss": 14.690121412277222, "val_acc": 50.0, "val_auroc": 0.52, "time": 272.85}
{"epoch": 14, "training_loss": 57.65196228027344, "training_acc": 52.5, "val_loss": 14.517369270324707, "val_acc": 50.0, "val_auroc": 0.47, "time": 294.87}
{"epoch": 15, "training_loss": 56.73559856414795, "training_acc": 52.5, "val_loss": 14.342167377471924, "val_acc": 50.0, "val_auroc": 0.52, "time": 316.82}
{"epoch": 16, "training_loss": 56.09863090515137, "training_acc": 52.5, "val_loss": 14.088090658187866, "val_acc": 50.0, "val_auroc": 0.52, "time": 333.88}
{"epoch": 17, "training_loss": 55.169044494628906, "training_acc": 52.5, "val_loss": 13.931699991226196, "val_acc": 50.0, "val_auroc": 0.49, "time": 350.78}
{"epoch": 18, "training_loss": 54.72612762451172, "training_acc": 52.5, "val_loss": 13.903419971466064, "val_acc": 50.0, "val_auroc": 0.51, "time": 369.57}
{"epoch": 19, "training_loss": 54.96406936645508, "training_acc": 53.75, "val_loss": 13.885191679000854, "val_acc": 50.0, "val_auroc": 0.49, "time": 388.3}
{"epoch": 20, "training_loss": 54.50739097595215, "training_acc": 67.5, "val_loss": 13.92869234085083, "val_acc": 50.0, "val_auroc": 0.46, "time": 406.0}
{"epoch": 21, "training_loss": 55.065704345703125, "training_acc": 47.5, "val_loss": 13.891406059265137, "val_acc": 50.0, "val_auroc": 0.46, "time": 423.14}
{"epoch": 22, "training_loss": 54.402167320251465, "training_acc": 63.75, "val_loss": 14.033880233764648, "val_acc": 50.0, "val_auroc": 0.42, "time": 444.18}
{"epoch": 23, "training_loss": 55.002384185791016, "training_acc": 52.5, "val_loss": 14.033733606338501, "val_acc": 50.0, "val_auroc": 0.51, "time": 463.78}
{"epoch": 24, "training_loss": 54.76539993286133, "training_acc": 52.5, "val_loss": 13.866640329360962, "val_acc": 50.0, "val_auroc": 0.51, "time": 480.83}
{"epoch": 25, "training_loss": 54.52565383911133, "training_acc": 62.5, "val_loss": 13.857959508895874, "val_acc": 50.0, "val_auroc": 0.5, "time": 497.96}
{"epoch": 26, "training_loss": 54.882758140563965, "training_acc": 53.75, "val_loss": 13.856642246246338, "val_acc": 50.0, "val_auroc": 0.51, "time": 519.23}
{"epoch": 27, "training_loss": 54.174553871154785, "training_acc": 58.75, "val_loss": 13.980474472045898, "val_acc": 50.0, "val_auroc": 0.5, "time": 537.24}
{"epoch": 28, "training_loss": 54.52003288269043, "training_acc": 53.75, "val_loss": 13.840287923812866, "val_acc": 50.0, "val_auroc": 0.5, "time": 553.77}
{"epoch": 29, "training_loss": 54.086177825927734, "training_acc": 60.0, "val_loss": 13.846031427383423, "val_acc": 50.0, "val_auroc": 0.51, "time": 570.14}
{"epoch": 30, "training_loss": 54.007680892944336, "training_acc": 66.25, "val_loss": 14.05495285987854, "val_acc": 50.0, "val_auroc": 0.53, "time": 588.63}
{"epoch": 31, "training_loss": 54.31733512878418, "training_acc": 52.5, "val_loss": 14.012899398803711, "val_acc": 50.0, "val_auroc": 0.49, "time": 609.61}
