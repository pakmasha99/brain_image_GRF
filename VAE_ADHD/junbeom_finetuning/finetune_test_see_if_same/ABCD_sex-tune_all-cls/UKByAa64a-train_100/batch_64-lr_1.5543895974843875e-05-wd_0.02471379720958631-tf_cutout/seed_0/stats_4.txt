"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.3642349243164, "training_acc": 47.0, "val_loss": 17.35972911119461, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.20770120620728, "training_acc": 56.0, "val_loss": 17.326003313064575, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.33684229850769, "training_acc": 53.0, "val_loss": 17.405959963798523, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.00833082199097, "training_acc": 53.0, "val_loss": 17.415851354599, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.06053853034973, "training_acc": 53.0, "val_loss": 17.378245294094086, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.1407322883606, "training_acc": 53.0, "val_loss": 17.337024211883545, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.04768061637878, "training_acc": 54.0, "val_loss": 17.32606142759323, "val_acc": 52.0}
{"epoch": 7, "training_loss": 68.88246822357178, "training_acc": 55.0, "val_loss": 17.320339381694794, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.60089087486267, "training_acc": 52.0, "val_loss": 17.312365770339966, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.85039353370667, "training_acc": 52.0, "val_loss": 17.295967042446136, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.86423683166504, "training_acc": 54.0, "val_loss": 17.286595702171326, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.59890007972717, "training_acc": 54.0, "val_loss": 17.285652458667755, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.1391749382019, "training_acc": 54.0, "val_loss": 17.265823483467102, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.46425342559814, "training_acc": 54.0, "val_loss": 17.249973118305206, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.37465476989746, "training_acc": 52.0, "val_loss": 17.309914529323578, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.38895058631897, "training_acc": 53.0, "val_loss": 17.247986793518066, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.60403275489807, "training_acc": 66.0, "val_loss": 17.228715121746063, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.00728273391724, "training_acc": 58.0, "val_loss": 17.195914685726166, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.33503317832947, "training_acc": 52.0, "val_loss": 17.18316376209259, "val_acc": 52.0}
{"epoch": 19, "training_loss": 65.97321009635925, "training_acc": 63.0, "val_loss": 17.244304716587067, "val_acc": 52.0}
{"epoch": 20, "training_loss": 66.43560695648193, "training_acc": 61.0, "val_loss": 17.078837752342224, "val_acc": 52.0}
{"epoch": 21, "training_loss": 65.84176754951477, "training_acc": 52.0, "val_loss": 17.01868772506714, "val_acc": 52.0}
{"epoch": 22, "training_loss": 65.29854941368103, "training_acc": 58.0, "val_loss": 17.180432379245758, "val_acc": 52.0}
{"epoch": 23, "training_loss": 66.00489926338196, "training_acc": 66.0, "val_loss": 16.912078857421875, "val_acc": 52.0}
{"epoch": 24, "training_loss": 64.02840495109558, "training_acc": 64.0, "val_loss": 16.949737071990967, "val_acc": 52.0}
{"epoch": 25, "training_loss": 65.23392820358276, "training_acc": 61.0, "val_loss": 16.840113699436188, "val_acc": 52.0}
{"epoch": 26, "training_loss": 63.49930739402771, "training_acc": 69.0, "val_loss": 17.307186126708984, "val_acc": 52.0}
{"epoch": 27, "training_loss": 64.55422616004944, "training_acc": 66.0, "val_loss": 16.81259572505951, "val_acc": 52.0}
{"epoch": 28, "training_loss": 61.395699977874756, "training_acc": 67.0, "val_loss": 16.620540618896484, "val_acc": 52.0}
{"epoch": 29, "training_loss": 58.908817768096924, "training_acc": 71.0, "val_loss": 16.572894155979156, "val_acc": 56.0}
{"epoch": 30, "training_loss": 59.15907382965088, "training_acc": 74.0, "val_loss": 16.488273441791534, "val_acc": 56.0}
{"epoch": 31, "training_loss": 60.419506788253784, "training_acc": 66.0, "val_loss": 17.04825758934021, "val_acc": 52.0}
{"epoch": 32, "training_loss": 56.9941840171814, "training_acc": 70.0, "val_loss": 16.711387038230896, "val_acc": 56.0}
{"epoch": 33, "training_loss": 63.11854553222656, "training_acc": 71.0, "val_loss": 18.16512644290924, "val_acc": 60.0}
{"epoch": 34, "training_loss": 65.72520160675049, "training_acc": 59.0, "val_loss": 17.764070630073547, "val_acc": 60.0}
{"epoch": 35, "training_loss": 58.74794816970825, "training_acc": 68.0, "val_loss": 19.29027885198593, "val_acc": 52.0}
{"epoch": 36, "training_loss": 64.97928595542908, "training_acc": 54.0, "val_loss": 16.68209731578827, "val_acc": 52.0}
{"epoch": 37, "training_loss": 54.417577266693115, "training_acc": 73.0, "val_loss": 18.68186742067337, "val_acc": 48.0}
{"epoch": 38, "training_loss": 61.857749700546265, "training_acc": 62.0, "val_loss": 20.463193953037262, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.97381281852722, "training_acc": 59.0, "val_loss": 17.425647377967834, "val_acc": 56.0}
{"epoch": 40, "training_loss": 60.91139554977417, "training_acc": 65.0, "val_loss": 19.29488182067871, "val_acc": 48.0}
{"epoch": 41, "training_loss": 72.54068422317505, "training_acc": 48.0, "val_loss": 18.82876753807068, "val_acc": 48.0}
{"epoch": 42, "training_loss": 68.76310467720032, "training_acc": 52.0, "val_loss": 16.834968328475952, "val_acc": 52.0}
{"epoch": 43, "training_loss": 58.478965759277344, "training_acc": 72.0, "val_loss": 19.724376499652863, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.04824686050415, "training_acc": 53.0, "val_loss": 17.42493361234665, "val_acc": 52.0}
{"epoch": 45, "training_loss": 62.449244260787964, "training_acc": 62.0, "val_loss": 17.144770920276642, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.84782600402832, "training_acc": 78.0, "val_loss": 17.11394488811493, "val_acc": 52.0}
{"epoch": 47, "training_loss": 59.574424266815186, "training_acc": 80.0, "val_loss": 16.760295629501343, "val_acc": 52.0}
{"epoch": 48, "training_loss": 57.81978964805603, "training_acc": 64.0, "val_loss": 18.253570795059204, "val_acc": 52.0}
{"epoch": 49, "training_loss": 59.570196866989136, "training_acc": 62.0, "val_loss": 16.980227828025818, "val_acc": 64.0}
