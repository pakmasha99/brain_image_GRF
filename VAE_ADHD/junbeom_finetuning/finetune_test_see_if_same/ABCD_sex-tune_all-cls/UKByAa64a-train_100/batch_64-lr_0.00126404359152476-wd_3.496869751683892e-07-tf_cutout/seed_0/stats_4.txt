"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.20331835746765, "training_acc": 45.0, "val_loss": 17.45193749666214, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.43654537200928, "training_acc": 51.0, "val_loss": 17.418499290943146, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.74942827224731, "training_acc": 49.0, "val_loss": 17.325372993946075, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.1759603023529, "training_acc": 53.0, "val_loss": 17.360417544841766, "val_acc": 52.0}
{"epoch": 4, "training_loss": 70.29248356819153, "training_acc": 53.0, "val_loss": 17.30920821428299, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.32593154907227, "training_acc": 51.0, "val_loss": 17.450454831123352, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.79693722724915, "training_acc": 47.0, "val_loss": 17.309851944446564, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.56090903282166, "training_acc": 53.0, "val_loss": 17.360158264636993, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.3866503238678, "training_acc": 53.0, "val_loss": 17.31361895799637, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.17294430732727, "training_acc": 53.0, "val_loss": 17.34860986471176, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.41492533683777, "training_acc": 47.0, "val_loss": 17.317843437194824, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.1662187576294, "training_acc": 53.0, "val_loss": 17.33717918395996, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.19252514839172, "training_acc": 53.0, "val_loss": 17.450782656669617, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.60373330116272, "training_acc": 53.0, "val_loss": 17.481940984725952, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.45911502838135, "training_acc": 53.0, "val_loss": 17.31433868408203, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.97973561286926, "training_acc": 53.0, "val_loss": 17.398421466350555, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.76178026199341, "training_acc": 47.0, "val_loss": 17.402008175849915, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.51280570030212, "training_acc": 47.0, "val_loss": 17.31153279542923, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.59034085273743, "training_acc": 53.0, "val_loss": 17.477910220623016, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.56741738319397, "training_acc": 53.0, "val_loss": 17.38068014383316, "val_acc": 52.0}
{"epoch": 20, "training_loss": 70.0367968082428, "training_acc": 53.0, "val_loss": 17.30928122997284, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.34999322891235, "training_acc": 53.0, "val_loss": 17.314037680625916, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.13553524017334, "training_acc": 53.0, "val_loss": 17.308935523033142, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.49624013900757, "training_acc": 53.0, "val_loss": 17.308692634105682, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.15881133079529, "training_acc": 53.0, "val_loss": 17.36127883195877, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.26105451583862, "training_acc": 53.0, "val_loss": 17.376215755939484, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.29186511039734, "training_acc": 53.0, "val_loss": 17.328010499477386, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24654078483582, "training_acc": 53.0, "val_loss": 17.319968342781067, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.5049421787262, "training_acc": 45.0, "val_loss": 17.317387461662292, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.30484747886658, "training_acc": 53.0, "val_loss": 17.334015667438507, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.2561264038086, "training_acc": 53.0, "val_loss": 17.36540198326111, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.22713899612427, "training_acc": 53.0, "val_loss": 17.324058711528778, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.13905644416809, "training_acc": 53.0, "val_loss": 17.308856546878815, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2140200138092, "training_acc": 53.0, "val_loss": 17.31111854314804, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.17419195175171, "training_acc": 53.0, "val_loss": 17.311692237854004, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.11017918586731, "training_acc": 53.0, "val_loss": 17.343002557754517, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.36667990684509, "training_acc": 53.0, "val_loss": 17.363901436328888, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.26545333862305, "training_acc": 53.0, "val_loss": 17.31194257736206, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.1842429637909, "training_acc": 53.0, "val_loss": 17.309655249118805, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.17326378822327, "training_acc": 53.0, "val_loss": 17.308837175369263, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.3039186000824, "training_acc": 53.0, "val_loss": 17.31797754764557, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.56207227706909, "training_acc": 53.0, "val_loss": 17.39836037158966, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.33808445930481, "training_acc": 53.0, "val_loss": 17.331290245056152, "val_acc": 52.0}
