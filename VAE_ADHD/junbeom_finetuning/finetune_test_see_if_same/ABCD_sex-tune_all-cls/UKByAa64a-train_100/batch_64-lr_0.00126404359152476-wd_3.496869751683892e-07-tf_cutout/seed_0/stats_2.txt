"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.80826163291931, "training_acc": 45.0, "val_loss": 17.361214756965637, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.35628056526184, "training_acc": 47.0, "val_loss": 17.336390912532806, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.23603558540344, "training_acc": 53.0, "val_loss": 17.426586151123047, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.58921527862549, "training_acc": 53.0, "val_loss": 17.383617162704468, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.34687781333923, "training_acc": 53.0, "val_loss": 17.313377559185028, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.2036395072937, "training_acc": 53.0, "val_loss": 17.339716851711273, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.3995246887207, "training_acc": 45.0, "val_loss": 17.35363006591797, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.54645490646362, "training_acc": 45.0, "val_loss": 17.31172204017639, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.5381166934967, "training_acc": 43.0, "val_loss": 17.31758415699005, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.61332392692566, "training_acc": 53.0, "val_loss": 17.453204095363617, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.55157017707825, "training_acc": 53.0, "val_loss": 17.32790917158127, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.05041003227234, "training_acc": 53.0, "val_loss": 17.372651398181915, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.72143054008484, "training_acc": 47.0, "val_loss": 17.381970584392548, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.42173099517822, "training_acc": 51.0, "val_loss": 17.315305769443512, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.0650098323822, "training_acc": 53.0, "val_loss": 17.4485445022583, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.56247401237488, "training_acc": 53.0, "val_loss": 17.597945034503937, "val_acc": 52.0}
{"epoch": 16, "training_loss": 70.19369268417358, "training_acc": 53.0, "val_loss": 17.409266531467438, "val_acc": 52.0}
{"epoch": 17, "training_loss": 70.17248201370239, "training_acc": 53.0, "val_loss": 17.3379048705101, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.40117621421814, "training_acc": 47.0, "val_loss": 17.351089417934418, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.39340114593506, "training_acc": 49.0, "val_loss": 17.30916202068329, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.52928280830383, "training_acc": 53.0, "val_loss": 17.344501614570618, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.20089221000671, "training_acc": 53.0, "val_loss": 17.326733469963074, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.17182660102844, "training_acc": 53.0, "val_loss": 17.3148974776268, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.1494448184967, "training_acc": 53.0, "val_loss": 17.312215268611908, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.2453339099884, "training_acc": 53.0, "val_loss": 17.308878898620605, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.14929580688477, "training_acc": 53.0, "val_loss": 17.32327938079834, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.25139594078064, "training_acc": 53.0, "val_loss": 17.36798882484436, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.29081702232361, "training_acc": 53.0, "val_loss": 17.325741052627563, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14543986320496, "training_acc": 53.0, "val_loss": 17.32015311717987, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.28627490997314, "training_acc": 51.0, "val_loss": 17.329201102256775, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.3004641532898, "training_acc": 53.0, "val_loss": 17.30913519859314, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.16330075263977, "training_acc": 53.0, "val_loss": 17.38850325345993, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.5296220779419, "training_acc": 53.0, "val_loss": 17.40674525499344, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.815194606781, "training_acc": 53.0, "val_loss": 17.432235181331635, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.47348880767822, "training_acc": 53.0, "val_loss": 17.499060928821564, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.64796566963196, "training_acc": 53.0, "val_loss": 17.371371388435364, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.66990995407104, "training_acc": 53.0, "val_loss": 17.321069538593292, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.26615858078003, "training_acc": 53.0, "val_loss": 17.33027994632721, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.4260151386261, "training_acc": 47.0, "val_loss": 17.310558259487152, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.04815292358398, "training_acc": 53.0, "val_loss": 17.371365427970886, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.27778363227844, "training_acc": 53.0, "val_loss": 17.48623549938202, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.6929578781128, "training_acc": 53.0, "val_loss": 17.41507351398468, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.3572506904602, "training_acc": 53.0, "val_loss": 17.333027720451355, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.26753330230713, "training_acc": 53.0, "val_loss": 17.327995598316193, "val_acc": 52.0}
