"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 72.82628989219666, "training_acc": 46.0, "val_loss": 17.433032393455505, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.5432140827179, "training_acc": 51.0, "val_loss": 17.309464514255524, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.44387865066528, "training_acc": 53.0, "val_loss": 17.48122125864029, "val_acc": 52.0}
{"epoch": 3, "training_loss": 71.22850131988525, "training_acc": 47.0, "val_loss": 17.335160076618195, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27889204025269, "training_acc": 47.0, "val_loss": 17.44750887155533, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.49542164802551, "training_acc": 53.0, "val_loss": 17.708607017993927, "val_acc": 52.0}
{"epoch": 6, "training_loss": 70.34957528114319, "training_acc": 53.0, "val_loss": 17.477431893348694, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.5627224445343, "training_acc": 53.0, "val_loss": 17.317314445972443, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.22911071777344, "training_acc": 53.0, "val_loss": 17.31196492910385, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.28203892707825, "training_acc": 53.0, "val_loss": 17.311282455921173, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.09302377700806, "training_acc": 53.0, "val_loss": 17.369109392166138, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.51158857345581, "training_acc": 53.0, "val_loss": 17.385880649089813, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.32882928848267, "training_acc": 53.0, "val_loss": 17.309802770614624, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.21784210205078, "training_acc": 53.0, "val_loss": 17.31073409318924, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.46141767501831, "training_acc": 43.0, "val_loss": 17.312416434288025, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.83917927742004, "training_acc": 53.0, "val_loss": 17.378370463848114, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.38126802444458, "training_acc": 53.0, "val_loss": 17.320607602596283, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.1369400024414, "training_acc": 53.0, "val_loss": 17.3108771443367, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.50993800163269, "training_acc": 53.0, "val_loss": 17.308712005615234, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.12416505813599, "training_acc": 53.0, "val_loss": 17.34268367290497, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.46064114570618, "training_acc": 43.0, "val_loss": 17.34004318714142, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.41803359985352, "training_acc": 45.0, "val_loss": 17.319950461387634, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.43365931510925, "training_acc": 53.0, "val_loss": 17.308712005615234, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17794346809387, "training_acc": 53.0, "val_loss": 17.30887144804001, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.12857174873352, "training_acc": 53.0, "val_loss": 17.323531210422516, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1346914768219, "training_acc": 53.0, "val_loss": 17.350764572620392, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.32525205612183, "training_acc": 53.0, "val_loss": 17.34418421983719, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.1659505367279, "training_acc": 53.0, "val_loss": 17.308741807937622, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.17665123939514, "training_acc": 53.0, "val_loss": 17.31676459312439, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24718618392944, "training_acc": 53.0, "val_loss": 17.30983853340149, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.2059473991394, "training_acc": 53.0, "val_loss": 17.31092929840088, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.48006534576416, "training_acc": 53.0, "val_loss": 17.31736958026886, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.040940284729, "training_acc": 53.0, "val_loss": 17.41362363100052, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.56857991218567, "training_acc": 53.0, "val_loss": 17.47990995645523, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.71673274040222, "training_acc": 53.0, "val_loss": 17.335736751556396, "val_acc": 52.0}
{"epoch": 35, "training_loss": 68.92870593070984, "training_acc": 53.0, "val_loss": 17.396599054336548, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.3074643611908, "training_acc": 47.0, "val_loss": 17.503583431243896, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.91693496704102, "training_acc": 47.0, "val_loss": 17.314402759075165, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.2184853553772, "training_acc": 53.0, "val_loss": 17.45281219482422, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.50860238075256, "training_acc": 53.0, "val_loss": 17.575430870056152, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.96395134925842, "training_acc": 53.0, "val_loss": 17.439910769462585, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.19191455841064, "training_acc": 53.0, "val_loss": 17.30951964855194, "val_acc": 52.0}
