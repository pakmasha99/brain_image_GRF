"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.78383564949036, "training_acc": 53.0, "val_loss": 17.58030652999878, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.64507412910461, "training_acc": 53.0, "val_loss": 17.530570924282074, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.61414980888367, "training_acc": 53.0, "val_loss": 17.493297159671783, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.3945631980896, "training_acc": 53.0, "val_loss": 17.45414435863495, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.08998990058899, "training_acc": 53.0, "val_loss": 17.464347183704376, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.06759071350098, "training_acc": 53.0, "val_loss": 17.460979521274567, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.164133310318, "training_acc": 53.0, "val_loss": 17.411769926548004, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.01643967628479, "training_acc": 53.0, "val_loss": 17.395393550395966, "val_acc": 52.0}
{"epoch": 8, "training_loss": 68.5403516292572, "training_acc": 53.0, "val_loss": 17.439426481723785, "val_acc": 52.0}
{"epoch": 9, "training_loss": 68.70437121391296, "training_acc": 53.0, "val_loss": 17.46729612350464, "val_acc": 52.0}
{"epoch": 10, "training_loss": 68.59137010574341, "training_acc": 53.0, "val_loss": 17.354048788547516, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.79654026031494, "training_acc": 53.0, "val_loss": 17.28155165910721, "val_acc": 52.0}
{"epoch": 12, "training_loss": 68.66812109947205, "training_acc": 53.0, "val_loss": 17.354488372802734, "val_acc": 52.0}
{"epoch": 13, "training_loss": 68.31283473968506, "training_acc": 53.0, "val_loss": 17.51406043767929, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.10530757904053, "training_acc": 53.0, "val_loss": 17.524734139442444, "val_acc": 52.0}
{"epoch": 15, "training_loss": 68.53926968574524, "training_acc": 53.0, "val_loss": 17.351020872592926, "val_acc": 52.0}
{"epoch": 16, "training_loss": 67.80689239501953, "training_acc": 53.0, "val_loss": 17.365144193172455, "val_acc": 52.0}
{"epoch": 17, "training_loss": 67.79138684272766, "training_acc": 53.0, "val_loss": 17.57180243730545, "val_acc": 52.0}
{"epoch": 18, "training_loss": 67.59534406661987, "training_acc": 53.0, "val_loss": 17.569556832313538, "val_acc": 52.0}
{"epoch": 19, "training_loss": 67.53915762901306, "training_acc": 54.0, "val_loss": 17.366410791873932, "val_acc": 52.0}
{"epoch": 20, "training_loss": 67.70150375366211, "training_acc": 62.0, "val_loss": 17.416293919086456, "val_acc": 52.0}
{"epoch": 21, "training_loss": 67.43411827087402, "training_acc": 56.0, "val_loss": 17.66536980867386, "val_acc": 52.0}
{"epoch": 22, "training_loss": 67.01354217529297, "training_acc": 55.0, "val_loss": 17.6014706492424, "val_acc": 52.0}
{"epoch": 23, "training_loss": 67.53768515586853, "training_acc": 59.0, "val_loss": 17.49475449323654, "val_acc": 52.0}
{"epoch": 24, "training_loss": 66.3942563533783, "training_acc": 71.0, "val_loss": 17.572130262851715, "val_acc": 52.0}
{"epoch": 25, "training_loss": 66.40210676193237, "training_acc": 60.0, "val_loss": 17.647740244865417, "val_acc": 52.0}
{"epoch": 26, "training_loss": 65.49184465408325, "training_acc": 69.0, "val_loss": 17.930114269256592, "val_acc": 52.0}
{"epoch": 27, "training_loss": 65.65983486175537, "training_acc": 61.0, "val_loss": 17.839542031288147, "val_acc": 52.0}
{"epoch": 28, "training_loss": 63.952839851379395, "training_acc": 71.0, "val_loss": 17.896857857704163, "val_acc": 52.0}
{"epoch": 29, "training_loss": 64.76911664009094, "training_acc": 66.0, "val_loss": 17.54925101995468, "val_acc": 52.0}
{"epoch": 30, "training_loss": 64.49471759796143, "training_acc": 75.0, "val_loss": 18.085399270057678, "val_acc": 52.0}
