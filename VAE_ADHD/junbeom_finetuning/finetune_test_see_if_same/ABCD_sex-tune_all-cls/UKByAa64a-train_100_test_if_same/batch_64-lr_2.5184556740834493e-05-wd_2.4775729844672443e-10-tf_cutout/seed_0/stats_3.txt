"main_optuna_fix_see_if_same.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.16934108734131, "training_acc": 53.0, "val_loss": 17.37564653158188, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.16870617866516, "training_acc": 53.0, "val_loss": 17.344406247138977, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1230537891388, "training_acc": 53.0, "val_loss": 17.31570065021515, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.16816830635071, "training_acc": 53.0, "val_loss": 17.324885725975037, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.26667308807373, "training_acc": 53.0, "val_loss": 17.33260303735733, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10391926765442, "training_acc": 53.0, "val_loss": 17.318107187747955, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.04571270942688, "training_acc": 53.0, "val_loss": 17.30782240629196, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.11346912384033, "training_acc": 53.0, "val_loss": 17.303170263767242, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.19335198402405, "training_acc": 53.0, "val_loss": 17.306208610534668, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.3227162361145, "training_acc": 53.0, "val_loss": 17.313776910305023, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.07134580612183, "training_acc": 53.0, "val_loss": 17.3181414604187, "val_acc": 52.0}
{"epoch": 11, "training_loss": 68.99349069595337, "training_acc": 53.0, "val_loss": 17.321684956550598, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14374232292175, "training_acc": 53.0, "val_loss": 17.32531189918518, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.23722100257874, "training_acc": 53.0, "val_loss": 17.31516271829605, "val_acc": 52.0}
{"epoch": 14, "training_loss": 68.97020697593689, "training_acc": 53.0, "val_loss": 17.300628125667572, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.26528477668762, "training_acc": 53.0, "val_loss": 17.306941747665405, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.01995468139648, "training_acc": 53.0, "val_loss": 17.30443984270096, "val_acc": 52.0}
{"epoch": 17, "training_loss": 68.92492723464966, "training_acc": 53.0, "val_loss": 17.311063408851624, "val_acc": 52.0}
{"epoch": 18, "training_loss": 68.80364298820496, "training_acc": 53.0, "val_loss": 17.32722818851471, "val_acc": 52.0}
{"epoch": 19, "training_loss": 68.90499496459961, "training_acc": 53.0, "val_loss": 17.359870672225952, "val_acc": 52.0}
{"epoch": 20, "training_loss": 68.87393474578857, "training_acc": 53.0, "val_loss": 17.40092784166336, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.165278673172, "training_acc": 53.0, "val_loss": 17.3587828874588, "val_acc": 52.0}
{"epoch": 22, "training_loss": 68.75452470779419, "training_acc": 53.0, "val_loss": 17.319205403327942, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.03005409240723, "training_acc": 53.0, "val_loss": 17.29418933391571, "val_acc": 52.0}
{"epoch": 24, "training_loss": 68.84667921066284, "training_acc": 53.0, "val_loss": 17.337802052497864, "val_acc": 52.0}
{"epoch": 25, "training_loss": 68.84710788726807, "training_acc": 53.0, "val_loss": 17.347121238708496, "val_acc": 52.0}
{"epoch": 26, "training_loss": 68.48725533485413, "training_acc": 53.0, "val_loss": 17.30467975139618, "val_acc": 52.0}
{"epoch": 27, "training_loss": 68.16048121452332, "training_acc": 54.0, "val_loss": 17.317771911621094, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.02046036720276, "training_acc": 62.0, "val_loss": 17.367859184741974, "val_acc": 52.0}
{"epoch": 29, "training_loss": 67.56349062919617, "training_acc": 57.0, "val_loss": 17.373088002204895, "val_acc": 52.0}
{"epoch": 30, "training_loss": 67.06417965888977, "training_acc": 60.0, "val_loss": 17.300060391426086, "val_acc": 52.0}
{"epoch": 31, "training_loss": 66.77995491027832, "training_acc": 68.0, "val_loss": 17.305132746696472, "val_acc": 52.0}
{"epoch": 32, "training_loss": 66.68994069099426, "training_acc": 66.0, "val_loss": 17.413806915283203, "val_acc": 52.0}
{"epoch": 33, "training_loss": 65.97882628440857, "training_acc": 60.0, "val_loss": 17.43444800376892, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.25879669189453, "training_acc": 51.0, "val_loss": 17.314167320728302, "val_acc": 52.0}
{"epoch": 35, "training_loss": 67.68373727798462, "training_acc": 62.0, "val_loss": 17.427071928977966, "val_acc": 52.0}
{"epoch": 36, "training_loss": 67.77829480171204, "training_acc": 53.0, "val_loss": 17.44474172592163, "val_acc": 52.0}
{"epoch": 37, "training_loss": 66.65419483184814, "training_acc": 54.0, "val_loss": 17.238999903202057, "val_acc": 52.0}
{"epoch": 38, "training_loss": 65.84020805358887, "training_acc": 66.0, "val_loss": 17.200545966625214, "val_acc": 52.0}
{"epoch": 39, "training_loss": 65.70746231079102, "training_acc": 64.0, "val_loss": 17.25825071334839, "val_acc": 52.0}
{"epoch": 40, "training_loss": 62.97992515563965, "training_acc": 76.0, "val_loss": 17.309562861919403, "val_acc": 52.0}
{"epoch": 41, "training_loss": 63.22236180305481, "training_acc": 70.0, "val_loss": 17.145252227783203, "val_acc": 52.0}
{"epoch": 42, "training_loss": 61.38467192649841, "training_acc": 86.0, "val_loss": 17.809119820594788, "val_acc": 52.0}
{"epoch": 43, "training_loss": 67.41452121734619, "training_acc": 56.0, "val_loss": 17.365042865276337, "val_acc": 52.0}
{"epoch": 44, "training_loss": 65.60778093338013, "training_acc": 62.0, "val_loss": 17.13130474090576, "val_acc": 52.0}
{"epoch": 45, "training_loss": 63.65593647956848, "training_acc": 79.0, "val_loss": 17.325586080551147, "val_acc": 52.0}
{"epoch": 46, "training_loss": 61.66280817985535, "training_acc": 73.0, "val_loss": 17.366375029087067, "val_acc": 52.0}
{"epoch": 47, "training_loss": 62.91887021064758, "training_acc": 77.0, "val_loss": 17.204879224300385, "val_acc": 52.0}
{"epoch": 48, "training_loss": 61.806143045425415, "training_acc": 77.0, "val_loss": 17.550362646579742, "val_acc": 52.0}
{"epoch": 49, "training_loss": 58.51350712776184, "training_acc": 83.0, "val_loss": 17.70109087228775, "val_acc": 52.0}
{"epoch": 50, "training_loss": 58.27717661857605, "training_acc": 77.0, "val_loss": 17.02767163515091, "val_acc": 52.0}
{"epoch": 51, "training_loss": 55.66826605796814, "training_acc": 89.0, "val_loss": 17.993180453777313, "val_acc": 52.0}
{"epoch": 52, "training_loss": 53.9094181060791, "training_acc": 84.0, "val_loss": 17.017163336277008, "val_acc": 44.0}
{"epoch": 53, "training_loss": 52.80414319038391, "training_acc": 91.0, "val_loss": 17.934665083885193, "val_acc": 52.0}
{"epoch": 54, "training_loss": 51.564085960388184, "training_acc": 89.0, "val_loss": 17.8609237074852, "val_acc": 52.0}
{"epoch": 55, "training_loss": 50.63727927207947, "training_acc": 89.0, "val_loss": 16.84022545814514, "val_acc": 48.0}
{"epoch": 56, "training_loss": 48.54351806640625, "training_acc": 94.0, "val_loss": 17.386239767074585, "val_acc": 52.0}
{"epoch": 57, "training_loss": 47.00398051738739, "training_acc": 91.0, "val_loss": 18.687687814235687, "val_acc": 52.0}
{"epoch": 58, "training_loss": 47.362727999687195, "training_acc": 91.0, "val_loss": 17.074140906333923, "val_acc": 52.0}
{"epoch": 59, "training_loss": 43.99122178554535, "training_acc": 95.0, "val_loss": 16.625796258449554, "val_acc": 44.0}
{"epoch": 60, "training_loss": 44.85202193260193, "training_acc": 92.0, "val_loss": 16.633860766887665, "val_acc": 52.0}
{"epoch": 61, "training_loss": 44.32821834087372, "training_acc": 90.0, "val_loss": 16.79452508687973, "val_acc": 44.0}
{"epoch": 62, "training_loss": 39.40837550163269, "training_acc": 99.0, "val_loss": 19.013649225234985, "val_acc": 52.0}
{"epoch": 63, "training_loss": 41.260035157203674, "training_acc": 95.0, "val_loss": 16.42206162214279, "val_acc": 64.0}
{"epoch": 64, "training_loss": 44.79108262062073, "training_acc": 91.0, "val_loss": 16.62607192993164, "val_acc": 48.0}
{"epoch": 65, "training_loss": 38.294503927230835, "training_acc": 98.0, "val_loss": 16.385136544704437, "val_acc": 64.0}
{"epoch": 66, "training_loss": 39.39409327507019, "training_acc": 95.0, "val_loss": 18.265439569950104, "val_acc": 52.0}
{"epoch": 67, "training_loss": 38.797494411468506, "training_acc": 95.0, "val_loss": 17.38291084766388, "val_acc": 48.0}
{"epoch": 68, "training_loss": 37.09412360191345, "training_acc": 95.0, "val_loss": 16.799674928188324, "val_acc": 44.0}
{"epoch": 69, "training_loss": 35.04415535926819, "training_acc": 97.0, "val_loss": 17.574875056743622, "val_acc": 48.0}
{"epoch": 70, "training_loss": 34.24300682544708, "training_acc": 99.0, "val_loss": 17.711785435676575, "val_acc": 48.0}
{"epoch": 71, "training_loss": 32.9385461807251, "training_acc": 100.0, "val_loss": 17.42747128009796, "val_acc": 40.0}
{"epoch": 72, "training_loss": 32.544870376586914, "training_acc": 100.0, "val_loss": 16.62762463092804, "val_acc": 52.0}
{"epoch": 73, "training_loss": 32.37848651409149, "training_acc": 99.0, "val_loss": 18.235602974891663, "val_acc": 48.0}
{"epoch": 74, "training_loss": 31.77127778530121, "training_acc": 99.0, "val_loss": 17.101173102855682, "val_acc": 44.0}
{"epoch": 75, "training_loss": 30.909417510032654, "training_acc": 100.0, "val_loss": 18.821759521961212, "val_acc": 52.0}
{"epoch": 76, "training_loss": 30.981401443481445, "training_acc": 100.0, "val_loss": 17.72746592760086, "val_acc": 40.0}
{"epoch": 77, "training_loss": 30.223944187164307, "training_acc": 100.0, "val_loss": 18.26152205467224, "val_acc": 40.0}
{"epoch": 78, "training_loss": 28.534482717514038, "training_acc": 100.0, "val_loss": 17.82487779855728, "val_acc": 40.0}
{"epoch": 79, "training_loss": 29.56721866130829, "training_acc": 100.0, "val_loss": 19.02587115764618, "val_acc": 44.0}
{"epoch": 80, "training_loss": 29.430883169174194, "training_acc": 98.0, "val_loss": 17.59835034608841, "val_acc": 44.0}
{"epoch": 81, "training_loss": 27.887365698814392, "training_acc": 99.0, "val_loss": 19.986502826213837, "val_acc": 52.0}
{"epoch": 82, "training_loss": 29.12985134124756, "training_acc": 100.0, "val_loss": 18.119335174560547, "val_acc": 44.0}
{"epoch": 83, "training_loss": 27.589523911476135, "training_acc": 99.0, "val_loss": 19.4132462143898, "val_acc": 44.0}
{"epoch": 84, "training_loss": 27.32043147087097, "training_acc": 99.0, "val_loss": 20.27086764574051, "val_acc": 52.0}
