"main_optuna.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc --eval_mode True --learning_rate 1.050531802303288e-05 --weight_decay 1.6467213137570964e-09 --BN inst"
{"epoch": 0, "training_loss": 69.40033650398254, "training_acc": 52.0, "val_loss": 17.277243733406067, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.36663007736206, "training_acc": 52.0, "val_loss": 17.247220873832703, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.17172169685364, "training_acc": 52.0, "val_loss": 17.261216044425964, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.1255795955658, "training_acc": 52.0, "val_loss": 17.274068295955658, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.0709125995636, "training_acc": 52.0, "val_loss": 17.274130880832672, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.00949931144714, "training_acc": 52.0, "val_loss": 17.290090024471283, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.18548893928528, "training_acc": 52.0, "val_loss": 17.28859692811966, "val_acc": 56.0}
{"epoch": 7, "training_loss": 68.95600438117981, "training_acc": 52.0, "val_loss": 17.257587611675262, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.12343573570251, "training_acc": 52.0, "val_loss": 17.2393336892128, "val_acc": 56.0}
{"epoch": 9, "training_loss": 68.82670855522156, "training_acc": 52.0, "val_loss": 17.255759239196777, "val_acc": 56.0}
{"epoch": 10, "training_loss": 68.7857494354248, "training_acc": 52.0, "val_loss": 17.317335307598114, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.66149926185608, "training_acc": 52.0, "val_loss": 17.354632914066315, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.84190130233765, "training_acc": 52.0, "val_loss": 17.370979487895966, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.66646766662598, "training_acc": 53.0, "val_loss": 17.376303672790527, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.95849585533142, "training_acc": 54.0, "val_loss": 17.36283004283905, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.69924712181091, "training_acc": 58.0, "val_loss": 17.37721562385559, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.89243054389954, "training_acc": 58.0, "val_loss": 17.390842735767365, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.73766803741455, "training_acc": 56.0, "val_loss": 17.370960116386414, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.60001349449158, "training_acc": 55.0, "val_loss": 17.311978340148926, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.45192408561707, "training_acc": 56.0, "val_loss": 17.27384775876999, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.2391426563263, "training_acc": 55.0, "val_loss": 17.272257804870605, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.24221992492676, "training_acc": 55.0, "val_loss": 17.42507964372635, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.10589122772217, "training_acc": 65.0, "val_loss": 17.45554506778717, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.3258707523346, "training_acc": 61.0, "val_loss": 17.42199808359146, "val_acc": 56.0}
{"epoch": 24, "training_loss": 67.84309077262878, "training_acc": 63.0, "val_loss": 17.36001968383789, "val_acc": 56.0}
{"epoch": 25, "training_loss": 67.58364987373352, "training_acc": 60.0, "val_loss": 17.380475997924805, "val_acc": 56.0}
{"epoch": 26, "training_loss": 67.53868055343628, "training_acc": 64.0, "val_loss": 17.418372631072998, "val_acc": 56.0}
{"epoch": 27, "training_loss": 67.97194933891296, "training_acc": 61.0, "val_loss": 17.54780113697052, "val_acc": 56.0}
