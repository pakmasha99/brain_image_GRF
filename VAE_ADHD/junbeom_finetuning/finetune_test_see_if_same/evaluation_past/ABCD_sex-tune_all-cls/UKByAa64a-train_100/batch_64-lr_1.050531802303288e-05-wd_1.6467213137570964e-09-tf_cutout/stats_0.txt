"main_optuna.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_see_if_same --binary_class True --run_where sdcc --eval_mode True --learning_rate 1.050531802303288e-05 --weight_decay 1.6467213137570964e-09 --BN inst"
{"epoch": 0, "training_loss": 69.40033650398254, "training_acc": 52.0, "val_loss": 17.277242243289948, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.36346793174744, "training_acc": 52.0, "val_loss": 17.254914343357086, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.1939308643341, "training_acc": 52.0, "val_loss": 17.280280590057373, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.0945520401001, "training_acc": 52.0, "val_loss": 17.209455370903015, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.0621190071106, "training_acc": 52.0, "val_loss": 17.22649335861206, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.09309983253479, "training_acc": 52.0, "val_loss": 17.21472144126892, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.09673953056335, "training_acc": 52.0, "val_loss": 17.216971516609192, "val_acc": 56.0}
{"epoch": 7, "training_loss": 68.96646571159363, "training_acc": 52.0, "val_loss": 17.21612960100174, "val_acc": 56.0}
{"epoch": 8, "training_loss": 68.96820378303528, "training_acc": 52.0, "val_loss": 17.213214933872223, "val_acc": 56.0}
{"epoch": 9, "training_loss": 68.70231652259827, "training_acc": 52.0, "val_loss": 17.246213555336, "val_acc": 56.0}
{"epoch": 10, "training_loss": 68.7534921169281, "training_acc": 52.0, "val_loss": 17.269667983055115, "val_acc": 56.0}
{"epoch": 11, "training_loss": 68.60419082641602, "training_acc": 54.0, "val_loss": 17.286348342895508, "val_acc": 56.0}
{"epoch": 12, "training_loss": 68.65902376174927, "training_acc": 56.0, "val_loss": 17.293086647987366, "val_acc": 56.0}
{"epoch": 13, "training_loss": 68.45885920524597, "training_acc": 62.0, "val_loss": 17.309169471263885, "val_acc": 56.0}
{"epoch": 14, "training_loss": 68.66743469238281, "training_acc": 55.0, "val_loss": 17.324326932430267, "val_acc": 56.0}
{"epoch": 15, "training_loss": 68.46886920928955, "training_acc": 61.0, "val_loss": 17.303143441677094, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.63547158241272, "training_acc": 53.0, "val_loss": 17.257583141326904, "val_acc": 56.0}
{"epoch": 17, "training_loss": 68.4417290687561, "training_acc": 53.0, "val_loss": 17.2489196062088, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.37712812423706, "training_acc": 53.0, "val_loss": 17.247983813285828, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.37625527381897, "training_acc": 55.0, "val_loss": 17.28864461183548, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.01076483726501, "training_acc": 55.0, "val_loss": 17.310933768749237, "val_acc": 56.0}
{"epoch": 21, "training_loss": 67.96345901489258, "training_acc": 58.0, "val_loss": 17.3703595995903, "val_acc": 56.0}
{"epoch": 22, "training_loss": 67.68177032470703, "training_acc": 64.0, "val_loss": 17.37436205148697, "val_acc": 56.0}
