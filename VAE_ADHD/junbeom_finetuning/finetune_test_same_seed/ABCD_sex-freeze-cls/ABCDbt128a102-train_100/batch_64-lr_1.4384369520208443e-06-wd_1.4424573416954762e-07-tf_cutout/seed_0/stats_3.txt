"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.31840229034424, "training_acc": 53.0, "val_loss": 17.359979450702667, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.26019406318665, "training_acc": 53.0, "val_loss": 17.360039055347443, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.39508485794067, "training_acc": 53.0, "val_loss": 17.360103130340576, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.24552464485168, "training_acc": 53.0, "val_loss": 17.360137403011322, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25422263145447, "training_acc": 53.0, "val_loss": 17.360128462314606, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.33846712112427, "training_acc": 53.0, "val_loss": 17.360135912895203, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22053980827332, "training_acc": 53.0, "val_loss": 17.360129952430725, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.27565121650696, "training_acc": 53.0, "val_loss": 17.36009567975998, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.20930600166321, "training_acc": 53.0, "val_loss": 17.360076308250427, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.32811784744263, "training_acc": 53.0, "val_loss": 17.360039055347443, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.2657778263092, "training_acc": 53.0, "val_loss": 17.35999584197998, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.27415108680725, "training_acc": 53.0, "val_loss": 17.359940707683563, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.35634183883667, "training_acc": 53.0, "val_loss": 17.359893023967743, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.31077456474304, "training_acc": 53.0, "val_loss": 17.359870672225952, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.29460859298706, "training_acc": 53.0, "val_loss": 17.359843850135803, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.22462916374207, "training_acc": 53.0, "val_loss": 17.359821498394012, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.28150987625122, "training_acc": 53.0, "val_loss": 17.359821498394012, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.3132472038269, "training_acc": 53.0, "val_loss": 17.359797656536102, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.23775029182434, "training_acc": 53.0, "val_loss": 17.359770834445953, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.27612566947937, "training_acc": 53.0, "val_loss": 17.35975593328476, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.32950282096863, "training_acc": 53.0, "val_loss": 17.359735071659088, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.26700162887573, "training_acc": 53.0, "val_loss": 17.35972762107849, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28407788276672, "training_acc": 53.0, "val_loss": 17.35973358154297, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.22968244552612, "training_acc": 53.0, "val_loss": 17.3597052693367, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.22036695480347, "training_acc": 53.0, "val_loss": 17.35970675945282, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.28943252563477, "training_acc": 53.0, "val_loss": 17.359673976898193, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.29106116294861, "training_acc": 53.0, "val_loss": 17.359638214111328, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.24533152580261, "training_acc": 53.0, "val_loss": 17.359618842601776, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.2748954296112, "training_acc": 53.0, "val_loss": 17.359603941440582, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.24528074264526, "training_acc": 53.0, "val_loss": 17.359592020511627, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.19211292266846, "training_acc": 53.0, "val_loss": 17.35958307981491, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.24809694290161, "training_acc": 53.0, "val_loss": 17.359571158885956, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.28616333007812, "training_acc": 53.0, "val_loss": 17.35958606004715, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.29656338691711, "training_acc": 53.0, "val_loss": 17.359592020511627, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.28888201713562, "training_acc": 53.0, "val_loss": 17.359592020511627, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.30168771743774, "training_acc": 53.0, "val_loss": 17.35958755016327, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.33790898323059, "training_acc": 53.0, "val_loss": 17.35958755016327, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.32446122169495, "training_acc": 53.0, "val_loss": 17.359593510627747, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.21245884895325, "training_acc": 53.0, "val_loss": 17.359593510627747, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.295170545578, "training_acc": 53.0, "val_loss": 17.35960990190506, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.32721853256226, "training_acc": 53.0, "val_loss": 17.359618842601776, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.24300384521484, "training_acc": 53.0, "val_loss": 17.359624803066254, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.24580430984497, "training_acc": 53.0, "val_loss": 17.359651625156403, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.2649314403534, "training_acc": 53.0, "val_loss": 17.35968291759491, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.2833321094513, "training_acc": 53.0, "val_loss": 17.359739542007446, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.26713871955872, "training_acc": 53.0, "val_loss": 17.359763383865356, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.29110646247864, "training_acc": 53.0, "val_loss": 17.35977530479431, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.3112940788269, "training_acc": 53.0, "val_loss": 17.359770834445953, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.17402291297913, "training_acc": 53.0, "val_loss": 17.359794676303864, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.3118007183075, "training_acc": 53.0, "val_loss": 17.35980212688446, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.2785222530365, "training_acc": 53.0, "val_loss": 17.35978275537491, "val_acc": 52.0}
