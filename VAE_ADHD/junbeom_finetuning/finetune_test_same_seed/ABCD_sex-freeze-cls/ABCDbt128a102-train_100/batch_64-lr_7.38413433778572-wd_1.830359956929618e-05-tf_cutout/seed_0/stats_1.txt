"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5590.292320251465, "training_acc": 45.0, "val_loss": 4498.247146606445, "val_acc": 52.0}
{"epoch": 1, "training_loss": 13456.683715820312, "training_acc": 58.0, "val_loss": 3325.100326538086, "val_acc": 44.0}
{"epoch": 2, "training_loss": 12038.675598144531, "training_acc": 55.0, "val_loss": 5702.754592895508, "val_acc": 36.0}
{"epoch": 3, "training_loss": 9216.116973876953, "training_acc": 61.0, "val_loss": 6565.938568115234, "val_acc": 52.0}
{"epoch": 4, "training_loss": 11574.503814697266, "training_acc": 63.0, "val_loss": 4379.405975341797, "val_acc": 44.0}
{"epoch": 5, "training_loss": 7888.935272216797, "training_acc": 62.0, "val_loss": 3332.0552825927734, "val_acc": 56.0}
{"epoch": 6, "training_loss": 7460.6861572265625, "training_acc": 62.0, "val_loss": 3787.9806518554688, "val_acc": 52.0}
{"epoch": 7, "training_loss": 13264.29312133789, "training_acc": 59.0, "val_loss": 2844.1835403442383, "val_acc": 56.0}
{"epoch": 8, "training_loss": 6047.834854125977, "training_acc": 60.0, "val_loss": 4581.113052368164, "val_acc": 44.0}
{"epoch": 9, "training_loss": 10850.853332519531, "training_acc": 53.0, "val_loss": 3601.1062622070312, "val_acc": 36.0}
{"epoch": 10, "training_loss": 4905.328796386719, "training_acc": 71.0, "val_loss": 3255.7960510253906, "val_acc": 60.0}
{"epoch": 11, "training_loss": 3891.718048095703, "training_acc": 71.0, "val_loss": 2686.9232177734375, "val_acc": 44.0}
{"epoch": 12, "training_loss": 5328.70703125, "training_acc": 62.0, "val_loss": 2402.5524139404297, "val_acc": 48.0}
{"epoch": 13, "training_loss": 3113.2057189941406, "training_acc": 69.0, "val_loss": 2229.9713134765625, "val_acc": 60.0}
{"epoch": 14, "training_loss": 3710.3696060180664, "training_acc": 73.0, "val_loss": 2299.9027252197266, "val_acc": 48.0}
{"epoch": 15, "training_loss": 4234.7021484375, "training_acc": 69.0, "val_loss": 1363.90962600708, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1630.8460998535156, "training_acc": 80.0, "val_loss": 1963.7651443481445, "val_acc": 56.0}
{"epoch": 17, "training_loss": 2632.776117324829, "training_acc": 75.0, "val_loss": 2235.9025955200195, "val_acc": 44.0}
{"epoch": 18, "training_loss": 2876.708038330078, "training_acc": 67.0, "val_loss": 2118.547821044922, "val_acc": 36.0}
{"epoch": 19, "training_loss": 1913.9716567993164, "training_acc": 74.0, "val_loss": 2341.977882385254, "val_acc": 36.0}
{"epoch": 20, "training_loss": 2698.256103515625, "training_acc": 69.0, "val_loss": 1388.376808166504, "val_acc": 44.0}
{"epoch": 21, "training_loss": 2860.229721069336, "training_acc": 72.0, "val_loss": 1224.179458618164, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3160.0325469970703, "training_acc": 71.0, "val_loss": 1722.054672241211, "val_acc": 40.0}
{"epoch": 23, "training_loss": 2157.5447387695312, "training_acc": 72.0, "val_loss": 2798.096466064453, "val_acc": 52.0}
{"epoch": 24, "training_loss": 2652.0280151367188, "training_acc": 68.0, "val_loss": 2926.3601303100586, "val_acc": 36.0}
{"epoch": 25, "training_loss": 3003.479393005371, "training_acc": 68.0, "val_loss": 2469.6001052856445, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3413.1950073242188, "training_acc": 71.0, "val_loss": 2312.598991394043, "val_acc": 44.0}
{"epoch": 27, "training_loss": 2919.9313201904297, "training_acc": 70.0, "val_loss": 2646.0277557373047, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1353.1426525115967, "training_acc": 79.0, "val_loss": 2841.454315185547, "val_acc": 52.0}
{"epoch": 29, "training_loss": 3835.8282623291016, "training_acc": 72.0, "val_loss": 2636.8003845214844, "val_acc": 28.0}
{"epoch": 30, "training_loss": 2910.0130615234375, "training_acc": 72.0, "val_loss": 2003.4189224243164, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1958.9044723510742, "training_acc": 80.0, "val_loss": 1998.3938217163086, "val_acc": 56.0}
{"epoch": 32, "training_loss": 2424.159194946289, "training_acc": 73.0, "val_loss": 2435.441780090332, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2372.8462677001953, "training_acc": 76.0, "val_loss": 2595.3989028930664, "val_acc": 36.0}
{"epoch": 34, "training_loss": 2509.392303466797, "training_acc": 77.0, "val_loss": 2173.383331298828, "val_acc": 44.0}
{"epoch": 35, "training_loss": 1397.6741256713867, "training_acc": 80.0, "val_loss": 2482.2792053222656, "val_acc": 40.0}
{"epoch": 36, "training_loss": 3067.683006286621, "training_acc": 65.0, "val_loss": 2051.310920715332, "val_acc": 56.0}
{"epoch": 37, "training_loss": 3583.133499145508, "training_acc": 71.0, "val_loss": 2964.413833618164, "val_acc": 40.0}
{"epoch": 38, "training_loss": 2196.5684814453125, "training_acc": 68.0, "val_loss": 3285.942840576172, "val_acc": 56.0}
{"epoch": 39, "training_loss": 3495.6839447021484, "training_acc": 72.0, "val_loss": 3382.442092895508, "val_acc": 40.0}
{"epoch": 40, "training_loss": 2428.5760192871094, "training_acc": 77.0, "val_loss": 3532.2158813476562, "val_acc": 36.0}
