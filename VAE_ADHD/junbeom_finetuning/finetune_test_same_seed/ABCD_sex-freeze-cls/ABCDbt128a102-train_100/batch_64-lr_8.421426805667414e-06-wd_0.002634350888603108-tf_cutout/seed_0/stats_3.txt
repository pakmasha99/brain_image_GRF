"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.70966410636902, "training_acc": 47.0, "val_loss": 17.41003394126892, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.6118175983429, "training_acc": 47.0, "val_loss": 17.402686178684235, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.61562657356262, "training_acc": 47.0, "val_loss": 17.396581172943115, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.67810916900635, "training_acc": 47.0, "val_loss": 17.391330003738403, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.56336379051208, "training_acc": 47.0, "val_loss": 17.386634647846222, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.62619018554688, "training_acc": 47.0, "val_loss": 17.382711172103882, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.52703142166138, "training_acc": 47.0, "val_loss": 17.37893968820572, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.60102415084839, "training_acc": 47.0, "val_loss": 17.375965416431427, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.59178566932678, "training_acc": 47.0, "val_loss": 17.37319529056549, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.50934910774231, "training_acc": 47.0, "val_loss": 17.370131611824036, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.44098448753357, "training_acc": 47.0, "val_loss": 17.36716479063034, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.47570514678955, "training_acc": 47.0, "val_loss": 17.363865673542023, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.40102052688599, "training_acc": 47.0, "val_loss": 17.360763251781464, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.35430455207825, "training_acc": 47.0, "val_loss": 17.357924580574036, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.46283793449402, "training_acc": 47.0, "val_loss": 17.355063557624817, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.37004590034485, "training_acc": 47.0, "val_loss": 17.35253483057022, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.27461171150208, "training_acc": 49.0, "val_loss": 17.34989881515503, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.32480931282043, "training_acc": 53.0, "val_loss": 17.34718680381775, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.36282896995544, "training_acc": 51.0, "val_loss": 17.34459102153778, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.33159732818604, "training_acc": 51.0, "val_loss": 17.342372238636017, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.38004684448242, "training_acc": 54.0, "val_loss": 17.340141534805298, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.40640568733215, "training_acc": 44.0, "val_loss": 17.33790934085846, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.28274607658386, "training_acc": 51.0, "val_loss": 17.33594238758087, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.29449844360352, "training_acc": 52.0, "val_loss": 17.334263026714325, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.31411647796631, "training_acc": 52.0, "val_loss": 17.332753539085388, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.26758217811584, "training_acc": 52.0, "val_loss": 17.33129471540451, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.20370697975159, "training_acc": 53.0, "val_loss": 17.32991635799408, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.29153323173523, "training_acc": 50.0, "val_loss": 17.328551411628723, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.21283841133118, "training_acc": 55.0, "val_loss": 17.32715517282486, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.22335457801819, "training_acc": 50.0, "val_loss": 17.325954139232635, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.21566796302795, "training_acc": 53.0, "val_loss": 17.32512265443802, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.2064561843872, "training_acc": 54.0, "val_loss": 17.324262857437134, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.1299901008606, "training_acc": 55.0, "val_loss": 17.323388159275055, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.17435431480408, "training_acc": 52.0, "val_loss": 17.322686314582825, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.2726263999939, "training_acc": 53.0, "val_loss": 17.32209175825119, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.22157311439514, "training_acc": 52.0, "val_loss": 17.321647703647614, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.31659317016602, "training_acc": 53.0, "val_loss": 17.321184277534485, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.20916032791138, "training_acc": 53.0, "val_loss": 17.32068955898285, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.15996026992798, "training_acc": 53.0, "val_loss": 17.320285737514496, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.21050453186035, "training_acc": 53.0, "val_loss": 17.31989085674286, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.11391019821167, "training_acc": 53.0, "val_loss": 17.319533228874207, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.12455439567566, "training_acc": 53.0, "val_loss": 17.31921285390854, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.08166551589966, "training_acc": 53.0, "val_loss": 17.319007217884064, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.15546441078186, "training_acc": 53.0, "val_loss": 17.31885075569153, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.17522096633911, "training_acc": 53.0, "val_loss": 17.318643629550934, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.19712281227112, "training_acc": 53.0, "val_loss": 17.318449914455414, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.15856099128723, "training_acc": 53.0, "val_loss": 17.318302392959595, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.11808061599731, "training_acc": 53.0, "val_loss": 17.318180203437805, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.15010070800781, "training_acc": 53.0, "val_loss": 17.318095266819, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.09970164299011, "training_acc": 53.0, "val_loss": 17.318060994148254, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.24045944213867, "training_acc": 53.0, "val_loss": 17.31807291507721, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.20394849777222, "training_acc": 53.0, "val_loss": 17.31811612844467, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.12278866767883, "training_acc": 53.0, "val_loss": 17.318195104599, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.18707394599915, "training_acc": 53.0, "val_loss": 17.31829196214676, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.125328540802, "training_acc": 53.0, "val_loss": 17.318378388881683, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.09254837036133, "training_acc": 53.0, "val_loss": 17.31841117143631, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.10503482818604, "training_acc": 53.0, "val_loss": 17.318446934223175, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.16836929321289, "training_acc": 53.0, "val_loss": 17.31850355863571, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.05556893348694, "training_acc": 53.0, "val_loss": 17.3185795545578, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.13648176193237, "training_acc": 53.0, "val_loss": 17.318645119667053, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.08859300613403, "training_acc": 53.0, "val_loss": 17.31869876384735, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.09450840950012, "training_acc": 53.0, "val_loss": 17.318782210350037, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.19399619102478, "training_acc": 53.0, "val_loss": 17.31882095336914, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.05721378326416, "training_acc": 53.0, "val_loss": 17.31889694929123, "val_acc": 52.0}
{"epoch": 64, "training_loss": 68.99185299873352, "training_acc": 53.0, "val_loss": 17.31894016265869, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.13348388671875, "training_acc": 53.0, "val_loss": 17.319035530090332, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.0982391834259, "training_acc": 53.0, "val_loss": 17.319117486476898, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.14397501945496, "training_acc": 53.0, "val_loss": 17.319121956825256, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.1296124458313, "training_acc": 53.0, "val_loss": 17.31909215450287, "val_acc": 52.0}
