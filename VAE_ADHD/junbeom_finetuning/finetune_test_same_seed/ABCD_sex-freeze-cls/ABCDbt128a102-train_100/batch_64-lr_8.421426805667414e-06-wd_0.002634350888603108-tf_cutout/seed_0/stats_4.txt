"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.2221302986145, "training_acc": 53.0, "val_loss": 17.329828441143036, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.25221610069275, "training_acc": 53.0, "val_loss": 17.32938587665558, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.14232134819031, "training_acc": 53.0, "val_loss": 17.328983545303345, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.25616216659546, "training_acc": 53.0, "val_loss": 17.32873171567917, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.27034831047058, "training_acc": 53.0, "val_loss": 17.32860952615738, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22300815582275, "training_acc": 53.0, "val_loss": 17.328494787216187, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.1166000366211, "training_acc": 53.0, "val_loss": 17.328377068042755, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1162383556366, "training_acc": 53.0, "val_loss": 17.328250408172607, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.12906002998352, "training_acc": 53.0, "val_loss": 17.328181862831116, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.19001770019531, "training_acc": 53.0, "val_loss": 17.328128218650818, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.1316225528717, "training_acc": 53.0, "val_loss": 17.328105866909027, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.10421109199524, "training_acc": 53.0, "val_loss": 17.328116297721863, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.08342862129211, "training_acc": 53.0, "val_loss": 17.328152060508728, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.18384289741516, "training_acc": 53.0, "val_loss": 17.328229546546936, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.15091323852539, "training_acc": 53.0, "val_loss": 17.328345775604248, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.17313385009766, "training_acc": 53.0, "val_loss": 17.32846051454544, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1375892162323, "training_acc": 53.0, "val_loss": 17.32863038778305, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.18446278572083, "training_acc": 53.0, "val_loss": 17.328807711601257, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.14943337440491, "training_acc": 53.0, "val_loss": 17.329010367393494, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15507078170776, "training_acc": 53.0, "val_loss": 17.329204082489014, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.10800671577454, "training_acc": 53.0, "val_loss": 17.329448461532593, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.11941576004028, "training_acc": 53.0, "val_loss": 17.329619824886322, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18381524085999, "training_acc": 53.0, "val_loss": 17.32981652021408, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.15140843391418, "training_acc": 53.0, "val_loss": 17.32996702194214, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1877670288086, "training_acc": 53.0, "val_loss": 17.330075800418854, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.1232557296753, "training_acc": 53.0, "val_loss": 17.330177128314972, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.12564945220947, "training_acc": 53.0, "val_loss": 17.330239713191986, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.09597086906433, "training_acc": 53.0, "val_loss": 17.33030080795288, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.16030955314636, "training_acc": 53.0, "val_loss": 17.33039617538452, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.14347219467163, "training_acc": 53.0, "val_loss": 17.330525815486908, "val_acc": 52.0}
