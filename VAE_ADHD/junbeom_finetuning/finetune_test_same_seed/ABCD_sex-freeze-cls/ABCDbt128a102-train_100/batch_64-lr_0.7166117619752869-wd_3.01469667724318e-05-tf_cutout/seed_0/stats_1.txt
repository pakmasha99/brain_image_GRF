"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 583.8473129272461, "training_acc": 45.0, "val_loss": 517.6012992858887, "val_acc": 48.0}
{"epoch": 1, "training_loss": 1401.8441925048828, "training_acc": 57.0, "val_loss": 361.95101737976074, "val_acc": 44.0}
{"epoch": 2, "training_loss": 1006.3867626190186, "training_acc": 61.0, "val_loss": 580.4846286773682, "val_acc": 36.0}
{"epoch": 3, "training_loss": 918.1588706970215, "training_acc": 63.0, "val_loss": 633.0826282501221, "val_acc": 52.0}
{"epoch": 4, "training_loss": 1143.2070350646973, "training_acc": 65.0, "val_loss": 438.13891410827637, "val_acc": 44.0}
{"epoch": 5, "training_loss": 700.9325504302979, "training_acc": 62.0, "val_loss": 244.95859146118164, "val_acc": 48.0}
{"epoch": 6, "training_loss": 627.1112403869629, "training_acc": 62.0, "val_loss": 337.89618015289307, "val_acc": 52.0}
{"epoch": 7, "training_loss": 978.7150897979736, "training_acc": 57.0, "val_loss": 168.38395595550537, "val_acc": 52.0}
{"epoch": 8, "training_loss": 468.6191349029541, "training_acc": 63.0, "val_loss": 251.31852626800537, "val_acc": 36.0}
{"epoch": 9, "training_loss": 632.5236282348633, "training_acc": 62.0, "val_loss": 337.3775005340576, "val_acc": 60.0}
{"epoch": 10, "training_loss": 576.2643566131592, "training_acc": 67.0, "val_loss": 187.25496530532837, "val_acc": 48.0}
{"epoch": 11, "training_loss": 415.0788736343384, "training_acc": 63.0, "val_loss": 175.47881603240967, "val_acc": 52.0}
{"epoch": 12, "training_loss": 185.28021335601807, "training_acc": 72.0, "val_loss": 150.26535987854004, "val_acc": 44.0}
{"epoch": 13, "training_loss": 199.37257862091064, "training_acc": 68.0, "val_loss": 160.71133613586426, "val_acc": 52.0}
{"epoch": 14, "training_loss": 320.8335933685303, "training_acc": 73.0, "val_loss": 147.53167629241943, "val_acc": 40.0}
{"epoch": 15, "training_loss": 171.9821138381958, "training_acc": 77.0, "val_loss": 168.40871572494507, "val_acc": 56.0}
{"epoch": 16, "training_loss": 229.6480269432068, "training_acc": 69.0, "val_loss": 156.06106519699097, "val_acc": 44.0}
{"epoch": 17, "training_loss": 227.2165117263794, "training_acc": 64.0, "val_loss": 136.01009845733643, "val_acc": 48.0}
{"epoch": 18, "training_loss": 153.68715715408325, "training_acc": 75.0, "val_loss": 109.9521279335022, "val_acc": 48.0}
{"epoch": 19, "training_loss": 164.94206380844116, "training_acc": 71.0, "val_loss": 154.13299798965454, "val_acc": 40.0}
{"epoch": 20, "training_loss": 170.85545349121094, "training_acc": 76.0, "val_loss": 215.52040576934814, "val_acc": 48.0}
{"epoch": 21, "training_loss": 274.345890045166, "training_acc": 74.0, "val_loss": 236.07580661773682, "val_acc": 40.0}
{"epoch": 22, "training_loss": 231.5318946838379, "training_acc": 65.0, "val_loss": 226.18303298950195, "val_acc": 40.0}
{"epoch": 23, "training_loss": 227.18770122528076, "training_acc": 78.0, "val_loss": 166.1651849746704, "val_acc": 44.0}
{"epoch": 24, "training_loss": 187.7585802078247, "training_acc": 74.0, "val_loss": 107.37640857696533, "val_acc": 52.0}
{"epoch": 25, "training_loss": 157.9893455505371, "training_acc": 75.0, "val_loss": 150.51604509353638, "val_acc": 44.0}
{"epoch": 26, "training_loss": 209.93105030059814, "training_acc": 75.0, "val_loss": 171.32346630096436, "val_acc": 44.0}
{"epoch": 27, "training_loss": 241.90641260147095, "training_acc": 71.0, "val_loss": 219.40970420837402, "val_acc": 60.0}
{"epoch": 28, "training_loss": 337.60702419281006, "training_acc": 71.0, "val_loss": 190.49793481826782, "val_acc": 52.0}
{"epoch": 29, "training_loss": 208.34204483032227, "training_acc": 71.0, "val_loss": 173.47992658615112, "val_acc": 44.0}
{"epoch": 30, "training_loss": 184.04768753051758, "training_acc": 73.0, "val_loss": 169.17517185211182, "val_acc": 52.0}
{"epoch": 31, "training_loss": 156.49645948410034, "training_acc": 76.0, "val_loss": 133.22713375091553, "val_acc": 44.0}
{"epoch": 32, "training_loss": 270.9930467605591, "training_acc": 70.0, "val_loss": 114.71089124679565, "val_acc": 60.0}
{"epoch": 33, "training_loss": 183.90275144577026, "training_acc": 76.0, "val_loss": 271.65536880493164, "val_acc": 40.0}
{"epoch": 34, "training_loss": 283.3932304382324, "training_acc": 64.0, "val_loss": 234.2498540878296, "val_acc": 52.0}
{"epoch": 35, "training_loss": 270.2479066848755, "training_acc": 75.0, "val_loss": 270.3125476837158, "val_acc": 36.0}
{"epoch": 36, "training_loss": 231.29421997070312, "training_acc": 72.0, "val_loss": 242.12346076965332, "val_acc": 36.0}
{"epoch": 37, "training_loss": 188.916015625, "training_acc": 75.0, "val_loss": 211.45977973937988, "val_acc": 52.0}
{"epoch": 38, "training_loss": 218.23033237457275, "training_acc": 68.0, "val_loss": 239.79437351226807, "val_acc": 48.0}
{"epoch": 39, "training_loss": 179.12639331817627, "training_acc": 72.0, "val_loss": 287.5325918197632, "val_acc": 44.0}
{"epoch": 40, "training_loss": 384.5236072540283, "training_acc": 74.0, "val_loss": 218.3034896850586, "val_acc": 40.0}
{"epoch": 41, "training_loss": 158.50555276870728, "training_acc": 72.0, "val_loss": 183.2394242286682, "val_acc": 52.0}
{"epoch": 42, "training_loss": 307.4578742980957, "training_acc": 70.0, "val_loss": 164.59622383117676, "val_acc": 52.0}
{"epoch": 43, "training_loss": 248.6463747024536, "training_acc": 72.0, "val_loss": 167.99956560134888, "val_acc": 48.0}
