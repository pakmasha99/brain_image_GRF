"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.89648199081421, "training_acc": 56.0, "val_loss": 18.23214441537857, "val_acc": 48.0}
{"epoch": 1, "training_loss": 66.9926438331604, "training_acc": 64.0, "val_loss": 18.378236889839172, "val_acc": 52.0}
{"epoch": 2, "training_loss": 65.47245049476624, "training_acc": 62.0, "val_loss": 18.305860459804535, "val_acc": 52.0}
{"epoch": 3, "training_loss": 65.06360149383545, "training_acc": 62.0, "val_loss": 18.294253945350647, "val_acc": 52.0}
{"epoch": 4, "training_loss": 63.56808042526245, "training_acc": 65.0, "val_loss": 18.296019732952118, "val_acc": 56.0}
{"epoch": 5, "training_loss": 64.08194470405579, "training_acc": 64.0, "val_loss": 18.226242065429688, "val_acc": 52.0}
{"epoch": 6, "training_loss": 63.00812315940857, "training_acc": 62.0, "val_loss": 18.31706315279007, "val_acc": 48.0}
{"epoch": 7, "training_loss": 62.09958600997925, "training_acc": 65.0, "val_loss": 18.36397349834442, "val_acc": 48.0}
{"epoch": 8, "training_loss": 61.42166447639465, "training_acc": 62.0, "val_loss": 18.474192917346954, "val_acc": 48.0}
{"epoch": 9, "training_loss": 61.23055601119995, "training_acc": 69.0, "val_loss": 18.677735328674316, "val_acc": 56.0}
{"epoch": 10, "training_loss": 60.496352434158325, "training_acc": 66.0, "val_loss": 18.861982226371765, "val_acc": 56.0}
{"epoch": 11, "training_loss": 61.50805616378784, "training_acc": 66.0, "val_loss": 18.75196397304535, "val_acc": 52.0}
{"epoch": 12, "training_loss": 59.584014654159546, "training_acc": 68.0, "val_loss": 18.490447103977203, "val_acc": 48.0}
{"epoch": 13, "training_loss": 59.50082325935364, "training_acc": 64.0, "val_loss": 18.51523369550705, "val_acc": 48.0}
{"epoch": 14, "training_loss": 59.86232876777649, "training_acc": 70.0, "val_loss": 18.64742636680603, "val_acc": 52.0}
{"epoch": 15, "training_loss": 59.744776248931885, "training_acc": 64.0, "val_loss": 18.649476766586304, "val_acc": 52.0}
{"epoch": 16, "training_loss": 59.214454889297485, "training_acc": 67.0, "val_loss": 18.67964118719101, "val_acc": 52.0}
{"epoch": 17, "training_loss": 59.72998285293579, "training_acc": 63.0, "val_loss": 18.869878351688385, "val_acc": 48.0}
{"epoch": 18, "training_loss": 58.16941428184509, "training_acc": 67.0, "val_loss": 18.989726901054382, "val_acc": 52.0}
{"epoch": 19, "training_loss": 59.47195744514465, "training_acc": 66.0, "val_loss": 19.178833067417145, "val_acc": 56.0}
{"epoch": 20, "training_loss": 57.49246573448181, "training_acc": 66.0, "val_loss": 19.085845351219177, "val_acc": 56.0}
{"epoch": 21, "training_loss": 57.04030394554138, "training_acc": 68.0, "val_loss": 19.052493572235107, "val_acc": 52.0}
{"epoch": 22, "training_loss": 58.226091146469116, "training_acc": 67.0, "val_loss": 19.14142519235611, "val_acc": 52.0}
{"epoch": 23, "training_loss": 56.62178897857666, "training_acc": 70.0, "val_loss": 19.211597740650177, "val_acc": 52.0}
{"epoch": 24, "training_loss": 56.85091304779053, "training_acc": 71.0, "val_loss": 19.28362399339676, "val_acc": 52.0}
