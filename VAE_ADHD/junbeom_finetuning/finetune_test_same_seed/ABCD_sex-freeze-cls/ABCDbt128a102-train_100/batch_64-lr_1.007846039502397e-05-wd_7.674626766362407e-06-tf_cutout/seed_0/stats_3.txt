"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.42093968391418, "training_acc": 49.0, "val_loss": 17.325271666049957, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.36087155342102, "training_acc": 45.0, "val_loss": 17.322060465812683, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.31996655464172, "training_acc": 49.0, "val_loss": 17.31979548931122, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.41161584854126, "training_acc": 50.0, "val_loss": 17.317628860473633, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.25085496902466, "training_acc": 53.0, "val_loss": 17.31593608856201, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.22823667526245, "training_acc": 56.0, "val_loss": 17.314311861991882, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.32801055908203, "training_acc": 53.0, "val_loss": 17.313016951084137, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.22881507873535, "training_acc": 53.0, "val_loss": 17.312248051166534, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.27630686759949, "training_acc": 53.0, "val_loss": 17.31187254190445, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.20006680488586, "training_acc": 53.0, "val_loss": 17.31148511171341, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.29282879829407, "training_acc": 53.0, "val_loss": 17.31102019548416, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.25238728523254, "training_acc": 53.0, "val_loss": 17.310544848442078, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.2746319770813, "training_acc": 53.0, "val_loss": 17.310138046741486, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.19594955444336, "training_acc": 53.0, "val_loss": 17.309802770614624, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.16719031333923, "training_acc": 53.0, "val_loss": 17.30945110321045, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.18663787841797, "training_acc": 53.0, "val_loss": 17.309223115444183, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.18769574165344, "training_acc": 53.0, "val_loss": 17.308974266052246, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.19901657104492, "training_acc": 53.0, "val_loss": 17.308804392814636, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.2328188419342, "training_acc": 53.0, "val_loss": 17.308619618415833, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.15866875648499, "training_acc": 53.0, "val_loss": 17.308489978313446, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.16749215126038, "training_acc": 53.0, "val_loss": 17.30843335390091, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.15321660041809, "training_acc": 53.0, "val_loss": 17.308402061462402, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.20296120643616, "training_acc": 53.0, "val_loss": 17.308372259140015, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.17672371864319, "training_acc": 53.0, "val_loss": 17.308352887630463, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.17768383026123, "training_acc": 53.0, "val_loss": 17.30831116437912, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.16913938522339, "training_acc": 53.0, "val_loss": 17.308297753334045, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.17334365844727, "training_acc": 53.0, "val_loss": 17.308296263217926, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.21940422058105, "training_acc": 53.0, "val_loss": 17.30830669403076, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.11935520172119, "training_acc": 53.0, "val_loss": 17.30833351612091, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.25243878364563, "training_acc": 53.0, "val_loss": 17.30838716030121, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.23341417312622, "training_acc": 53.0, "val_loss": 17.308439314365387, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.10814118385315, "training_acc": 53.0, "val_loss": 17.308516800403595, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.16020894050598, "training_acc": 53.0, "val_loss": 17.308583855628967, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.21367192268372, "training_acc": 53.0, "val_loss": 17.30867028236389, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.14984488487244, "training_acc": 53.0, "val_loss": 17.308762669563293, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.18435454368591, "training_acc": 53.0, "val_loss": 17.308849096298218, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.19509887695312, "training_acc": 53.0, "val_loss": 17.308923602104187, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.16373062133789, "training_acc": 53.0, "val_loss": 17.3089861869812, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.2665867805481, "training_acc": 53.0, "val_loss": 17.309100925922394, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.19721269607544, "training_acc": 53.0, "val_loss": 17.309287190437317, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.10514402389526, "training_acc": 53.0, "val_loss": 17.309390008449554, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.15590023994446, "training_acc": 53.0, "val_loss": 17.30959266424179, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.15123343467712, "training_acc": 53.0, "val_loss": 17.309685051441193, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.2116711139679, "training_acc": 53.0, "val_loss": 17.309798300266266, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.15158939361572, "training_acc": 53.0, "val_loss": 17.309945821762085, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.15507006645203, "training_acc": 53.0, "val_loss": 17.310012876987457, "val_acc": 52.0}
