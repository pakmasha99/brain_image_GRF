"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.26776123046875, "training_acc": 53.0, "val_loss": 17.309004068374634, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.2267735004425, "training_acc": 53.0, "val_loss": 17.308619618415833, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.1509301662445, "training_acc": 53.0, "val_loss": 17.30816811323166, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.28092122077942, "training_acc": 53.0, "val_loss": 17.307372391223907, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14561820030212, "training_acc": 53.0, "val_loss": 17.307233810424805, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.26683020591736, "training_acc": 53.0, "val_loss": 17.307059466838837, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.24743747711182, "training_acc": 53.0, "val_loss": 17.306479811668396, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.21701335906982, "training_acc": 53.0, "val_loss": 17.30564832687378, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.13355994224548, "training_acc": 53.0, "val_loss": 17.305278778076172, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.29268956184387, "training_acc": 53.0, "val_loss": 17.30528175830841, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21837162971497, "training_acc": 53.0, "val_loss": 17.304807901382446, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.2504334449768, "training_acc": 53.0, "val_loss": 17.304083704948425, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.14985394477844, "training_acc": 53.0, "val_loss": 17.30380356311798, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.16274881362915, "training_acc": 53.0, "val_loss": 17.30375438928604, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.09558391571045, "training_acc": 53.0, "val_loss": 17.303626239299774, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.25400447845459, "training_acc": 53.0, "val_loss": 17.303231358528137, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.1948459148407, "training_acc": 53.0, "val_loss": 17.30283349752426, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.20965504646301, "training_acc": 53.0, "val_loss": 17.30223447084427, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17496943473816, "training_acc": 53.0, "val_loss": 17.301654815673828, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14995193481445, "training_acc": 53.0, "val_loss": 17.301173508167267, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.2265636920929, "training_acc": 53.0, "val_loss": 17.301146686077118, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.1749758720398, "training_acc": 53.0, "val_loss": 17.301145195961, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.18113446235657, "training_acc": 53.0, "val_loss": 17.301014065742493, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.21641564369202, "training_acc": 53.0, "val_loss": 17.300590872764587, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.18958806991577, "training_acc": 53.0, "val_loss": 17.300184071063995, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.25994086265564, "training_acc": 53.0, "val_loss": 17.299844324588776, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.18973445892334, "training_acc": 53.0, "val_loss": 17.29998290538788, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.21948981285095, "training_acc": 53.0, "val_loss": 17.299899458885193, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.14200139045715, "training_acc": 53.0, "val_loss": 17.29978173971176, "val_acc": 52.0}
{"epoch": 29, "training_loss": 69.26285219192505, "training_acc": 53.0, "val_loss": 17.29956418275833, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.18213605880737, "training_acc": 53.0, "val_loss": 17.29918271303177, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.1772472858429, "training_acc": 53.0, "val_loss": 17.298999428749084, "val_acc": 52.0}
{"epoch": 32, "training_loss": 69.23606443405151, "training_acc": 53.0, "val_loss": 17.29853004217148, "val_acc": 52.0}
{"epoch": 33, "training_loss": 69.2344753742218, "training_acc": 53.0, "val_loss": 17.29815900325775, "val_acc": 52.0}
{"epoch": 34, "training_loss": 69.1441080570221, "training_acc": 53.0, "val_loss": 17.29813665151596, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.22703337669373, "training_acc": 53.0, "val_loss": 17.298264801502228, "val_acc": 52.0}
{"epoch": 36, "training_loss": 69.1002779006958, "training_acc": 53.0, "val_loss": 17.298518121242523, "val_acc": 52.0}
{"epoch": 37, "training_loss": 69.13412070274353, "training_acc": 53.0, "val_loss": 17.29882061481476, "val_acc": 52.0}
{"epoch": 38, "training_loss": 69.17755579948425, "training_acc": 53.0, "val_loss": 17.29900687932968, "val_acc": 52.0}
{"epoch": 39, "training_loss": 69.25808262825012, "training_acc": 53.0, "val_loss": 17.299339175224304, "val_acc": 52.0}
{"epoch": 40, "training_loss": 69.16621375083923, "training_acc": 53.0, "val_loss": 17.299312353134155, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.14808440208435, "training_acc": 53.0, "val_loss": 17.299048602581024, "val_acc": 52.0}
{"epoch": 42, "training_loss": 69.23548579216003, "training_acc": 53.0, "val_loss": 17.298755049705505, "val_acc": 52.0}
{"epoch": 43, "training_loss": 69.11859059333801, "training_acc": 53.0, "val_loss": 17.298248410224915, "val_acc": 52.0}
{"epoch": 44, "training_loss": 69.16511583328247, "training_acc": 53.0, "val_loss": 17.29763001203537, "val_acc": 52.0}
{"epoch": 45, "training_loss": 69.17294430732727, "training_acc": 53.0, "val_loss": 17.297114431858063, "val_acc": 52.0}
{"epoch": 46, "training_loss": 69.29200100898743, "training_acc": 53.0, "val_loss": 17.296668887138367, "val_acc": 52.0}
{"epoch": 47, "training_loss": 69.14931130409241, "training_acc": 53.0, "val_loss": 17.296472191810608, "val_acc": 52.0}
{"epoch": 48, "training_loss": 69.13283491134644, "training_acc": 53.0, "val_loss": 17.296241223812103, "val_acc": 52.0}
{"epoch": 49, "training_loss": 69.24396061897278, "training_acc": 53.0, "val_loss": 17.29598194360733, "val_acc": 52.0}
{"epoch": 50, "training_loss": 69.15733814239502, "training_acc": 53.0, "val_loss": 17.29576140642166, "val_acc": 52.0}
{"epoch": 51, "training_loss": 69.12480521202087, "training_acc": 53.0, "val_loss": 17.295455932617188, "val_acc": 52.0}
{"epoch": 52, "training_loss": 69.23205518722534, "training_acc": 53.0, "val_loss": 17.295236885547638, "val_acc": 52.0}
{"epoch": 53, "training_loss": 69.14900803565979, "training_acc": 53.0, "val_loss": 17.295275628566742, "val_acc": 52.0}
{"epoch": 54, "training_loss": 69.21682262420654, "training_acc": 53.0, "val_loss": 17.295143008232117, "val_acc": 52.0}
{"epoch": 55, "training_loss": 69.1415069103241, "training_acc": 53.0, "val_loss": 17.295019328594208, "val_acc": 52.0}
{"epoch": 56, "training_loss": 69.1733751296997, "training_acc": 53.0, "val_loss": 17.294974625110626, "val_acc": 52.0}
{"epoch": 57, "training_loss": 69.14229154586792, "training_acc": 53.0, "val_loss": 17.294788360595703, "val_acc": 52.0}
{"epoch": 58, "training_loss": 69.16237282752991, "training_acc": 53.0, "val_loss": 17.294488847255707, "val_acc": 52.0}
{"epoch": 59, "training_loss": 69.13784670829773, "training_acc": 53.0, "val_loss": 17.294147610664368, "val_acc": 52.0}
{"epoch": 60, "training_loss": 69.19238233566284, "training_acc": 53.0, "val_loss": 17.293861508369446, "val_acc": 52.0}
{"epoch": 61, "training_loss": 69.12468028068542, "training_acc": 53.0, "val_loss": 17.29387938976288, "val_acc": 52.0}
{"epoch": 62, "training_loss": 69.20541048049927, "training_acc": 53.0, "val_loss": 17.293712496757507, "val_acc": 52.0}
{"epoch": 63, "training_loss": 69.12746095657349, "training_acc": 53.0, "val_loss": 17.293581366539, "val_acc": 52.0}
{"epoch": 64, "training_loss": 69.17738842964172, "training_acc": 53.0, "val_loss": 17.293469607830048, "val_acc": 52.0}
{"epoch": 65, "training_loss": 69.17834520339966, "training_acc": 53.0, "val_loss": 17.293421924114227, "val_acc": 52.0}
{"epoch": 66, "training_loss": 69.20848274230957, "training_acc": 53.0, "val_loss": 17.293472588062286, "val_acc": 52.0}
{"epoch": 67, "training_loss": 69.19510746002197, "training_acc": 53.0, "val_loss": 17.293551564216614, "val_acc": 52.0}
{"epoch": 68, "training_loss": 69.12606883049011, "training_acc": 53.0, "val_loss": 17.293746769428253, "val_acc": 52.0}
{"epoch": 69, "training_loss": 69.13930225372314, "training_acc": 53.0, "val_loss": 17.294007539749146, "val_acc": 52.0}
{"epoch": 70, "training_loss": 69.09222030639648, "training_acc": 53.0, "val_loss": 17.29416251182556, "val_acc": 52.0}
{"epoch": 71, "training_loss": 69.14858341217041, "training_acc": 53.0, "val_loss": 17.294439673423767, "val_acc": 52.0}
{"epoch": 72, "training_loss": 69.12532114982605, "training_acc": 53.0, "val_loss": 17.294614017009735, "val_acc": 52.0}
{"epoch": 73, "training_loss": 69.10329484939575, "training_acc": 53.0, "val_loss": 17.294733226299286, "val_acc": 52.0}
{"epoch": 74, "training_loss": 69.22673439979553, "training_acc": 53.0, "val_loss": 17.295026779174805, "val_acc": 52.0}
{"epoch": 75, "training_loss": 69.04519605636597, "training_acc": 53.0, "val_loss": 17.29530692100525, "val_acc": 52.0}
{"epoch": 76, "training_loss": 69.21966481208801, "training_acc": 53.0, "val_loss": 17.295639216899872, "val_acc": 52.0}
{"epoch": 77, "training_loss": 69.1119499206543, "training_acc": 53.0, "val_loss": 17.295832931995392, "val_acc": 52.0}
{"epoch": 78, "training_loss": 69.12778329849243, "training_acc": 53.0, "val_loss": 17.29609966278076, "val_acc": 52.0}
{"epoch": 79, "training_loss": 69.16449475288391, "training_acc": 53.0, "val_loss": 17.29624718427658, "val_acc": 52.0}
{"epoch": 80, "training_loss": 69.17857480049133, "training_acc": 53.0, "val_loss": 17.296282947063446, "val_acc": 52.0}
{"epoch": 81, "training_loss": 69.1794593334198, "training_acc": 53.0, "val_loss": 17.29636788368225, "val_acc": 52.0}
{"epoch": 82, "training_loss": 69.17398810386658, "training_acc": 53.0, "val_loss": 17.29624569416046, "val_acc": 52.0}
{"epoch": 83, "training_loss": 69.12472462654114, "training_acc": 53.0, "val_loss": 17.29593575000763, "val_acc": 52.0}
{"epoch": 84, "training_loss": 69.15261912345886, "training_acc": 53.0, "val_loss": 17.295847833156586, "val_acc": 52.0}
