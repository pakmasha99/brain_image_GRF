"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 102.43620824813843, "training_acc": 47.0, "val_loss": 20.08654773235321, "val_acc": 52.0}
{"epoch": 1, "training_loss": 73.36985349655151, "training_acc": 59.0, "val_loss": 30.918139219284058, "val_acc": 48.0}
{"epoch": 2, "training_loss": 119.47906494140625, "training_acc": 47.0, "val_loss": 18.776552379131317, "val_acc": 48.0}
{"epoch": 3, "training_loss": 70.64714741706848, "training_acc": 55.0, "val_loss": 23.65017980337143, "val_acc": 52.0}
{"epoch": 4, "training_loss": 96.54244375228882, "training_acc": 53.0, "val_loss": 22.765810787677765, "val_acc": 52.0}
{"epoch": 5, "training_loss": 83.45395255088806, "training_acc": 53.0, "val_loss": 17.717650532722473, "val_acc": 52.0}
{"epoch": 6, "training_loss": 71.92603063583374, "training_acc": 47.0, "val_loss": 21.989871561527252, "val_acc": 48.0}
{"epoch": 7, "training_loss": 87.10848426818848, "training_acc": 47.0, "val_loss": 18.306806683540344, "val_acc": 48.0}
{"epoch": 8, "training_loss": 69.97092485427856, "training_acc": 55.0, "val_loss": 19.03122216463089, "val_acc": 52.0}
{"epoch": 9, "training_loss": 76.77675294876099, "training_acc": 53.0, "val_loss": 20.747528970241547, "val_acc": 52.0}
{"epoch": 10, "training_loss": 79.0325710773468, "training_acc": 53.0, "val_loss": 17.462921142578125, "val_acc": 52.0}
{"epoch": 11, "training_loss": 71.10969066619873, "training_acc": 49.0, "val_loss": 19.696156680583954, "val_acc": 48.0}
{"epoch": 12, "training_loss": 79.21449327468872, "training_acc": 47.0, "val_loss": 18.52540224790573, "val_acc": 44.0}
{"epoch": 13, "training_loss": 71.43605375289917, "training_acc": 47.0, "val_loss": 17.76302605867386, "val_acc": 52.0}
{"epoch": 14, "training_loss": 72.23923873901367, "training_acc": 53.0, "val_loss": 19.671155512332916, "val_acc": 52.0}
{"epoch": 15, "training_loss": 76.17149257659912, "training_acc": 53.0, "val_loss": 17.586524784564972, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.499840259552, "training_acc": 51.0, "val_loss": 18.168102204799652, "val_acc": 52.0}
{"epoch": 17, "training_loss": 73.47088289260864, "training_acc": 47.0, "val_loss": 17.97902286052704, "val_acc": 52.0}
{"epoch": 18, "training_loss": 70.34085178375244, "training_acc": 47.0, "val_loss": 17.592452466487885, "val_acc": 52.0}
{"epoch": 19, "training_loss": 71.09931516647339, "training_acc": 53.0, "val_loss": 18.57686936855316, "val_acc": 52.0}
{"epoch": 20, "training_loss": 72.1217873096466, "training_acc": 53.0, "val_loss": 17.359153926372528, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.7365653514862, "training_acc": 49.0, "val_loss": 18.007510900497437, "val_acc": 52.0}
{"epoch": 22, "training_loss": 71.80131483078003, "training_acc": 47.0, "val_loss": 17.464911937713623, "val_acc": 52.0}
{"epoch": 23, "training_loss": 68.8870108127594, "training_acc": 58.0, "val_loss": 17.521296441555023, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.86096620559692, "training_acc": 53.0, "val_loss": 17.94324815273285, "val_acc": 52.0}
{"epoch": 25, "training_loss": 70.22642183303833, "training_acc": 53.0, "val_loss": 17.33609288930893, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.11732459068298, "training_acc": 49.0, "val_loss": 17.599105834960938, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.74881553649902, "training_acc": 47.0, "val_loss": 17.334087193012238, "val_acc": 52.0}
{"epoch": 28, "training_loss": 68.08090686798096, "training_acc": 53.0, "val_loss": 17.872096598148346, "val_acc": 52.0}
{"epoch": 29, "training_loss": 70.70835995674133, "training_acc": 53.0, "val_loss": 17.770719528198242, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.02788281440735, "training_acc": 53.0, "val_loss": 17.466555535793304, "val_acc": 52.0}
{"epoch": 31, "training_loss": 69.05858945846558, "training_acc": 47.0, "val_loss": 18.189334869384766, "val_acc": 48.0}
{"epoch": 32, "training_loss": 72.01617932319641, "training_acc": 47.0, "val_loss": 17.360833287239075, "val_acc": 52.0}
{"epoch": 33, "training_loss": 68.11097455024719, "training_acc": 66.0, "val_loss": 18.0497407913208, "val_acc": 52.0}
{"epoch": 34, "training_loss": 71.70355224609375, "training_acc": 53.0, "val_loss": 17.687641084194183, "val_acc": 52.0}
{"epoch": 35, "training_loss": 69.87205338478088, "training_acc": 57.0, "val_loss": 17.653976380825043, "val_acc": 52.0}
{"epoch": 36, "training_loss": 70.81261324882507, "training_acc": 47.0, "val_loss": 17.411303520202637, "val_acc": 52.0}
{"epoch": 37, "training_loss": 68.39531874656677, "training_acc": 51.0, "val_loss": 17.947791516780853, "val_acc": 52.0}
{"epoch": 38, "training_loss": 70.68778324127197, "training_acc": 53.0, "val_loss": 17.70080476999283, "val_acc": 52.0}
{"epoch": 39, "training_loss": 70.20033764839172, "training_acc": 56.0, "val_loss": 17.446136474609375, "val_acc": 52.0}
{"epoch": 40, "training_loss": 68.95677256584167, "training_acc": 47.0, "val_loss": 17.365995049476624, "val_acc": 52.0}
{"epoch": 41, "training_loss": 69.99372482299805, "training_acc": 54.0, "val_loss": 17.36072301864624, "val_acc": 52.0}
{"epoch": 42, "training_loss": 68.89863681793213, "training_acc": 53.0, "val_loss": 17.334090173244476, "val_acc": 52.0}
{"epoch": 43, "training_loss": 68.20505905151367, "training_acc": 61.0, "val_loss": 17.38409548997879, "val_acc": 52.0}
{"epoch": 44, "training_loss": 70.37955117225647, "training_acc": 53.0, "val_loss": 17.36217439174652, "val_acc": 52.0}
{"epoch": 45, "training_loss": 67.5039131641388, "training_acc": 60.0, "val_loss": 17.81311184167862, "val_acc": 52.0}
{"epoch": 46, "training_loss": 73.74862146377563, "training_acc": 47.0, "val_loss": 17.54647195339203, "val_acc": 52.0}
