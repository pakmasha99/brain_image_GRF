"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.40044069290161, "training_acc": 50.0, "val_loss": 27.59348452091217, "val_acc": 56.0}
{"epoch": 1, "training_loss": 100.27666234970093, "training_acc": 52.0, "val_loss": 25.94599723815918, "val_acc": 44.0}
{"epoch": 2, "training_loss": 97.80524063110352, "training_acc": 48.0, "val_loss": 20.354121923446655, "val_acc": 44.0}
{"epoch": 3, "training_loss": 77.0537576675415, "training_acc": 46.0, "val_loss": 19.475851953029633, "val_acc": 56.0}
{"epoch": 4, "training_loss": 82.66569828987122, "training_acc": 52.0, "val_loss": 18.016986548900604, "val_acc": 56.0}
{"epoch": 5, "training_loss": 70.74497365951538, "training_acc": 52.0, "val_loss": 19.33874487876892, "val_acc": 44.0}
{"epoch": 6, "training_loss": 77.02093505859375, "training_acc": 48.0, "val_loss": 20.347782969474792, "val_acc": 44.0}
{"epoch": 7, "training_loss": 74.48103976249695, "training_acc": 48.0, "val_loss": 17.204080522060394, "val_acc": 56.0}
{"epoch": 8, "training_loss": 74.69215202331543, "training_acc": 52.0, "val_loss": 18.499666452407837, "val_acc": 56.0}
{"epoch": 9, "training_loss": 74.81997990608215, "training_acc": 52.0, "val_loss": 17.303603887557983, "val_acc": 56.0}
{"epoch": 10, "training_loss": 70.04102993011475, "training_acc": 60.0, "val_loss": 19.58112120628357, "val_acc": 44.0}
{"epoch": 11, "training_loss": 74.31493282318115, "training_acc": 48.0, "val_loss": 17.569413781166077, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.99906253814697, "training_acc": 46.0, "val_loss": 17.446178197860718, "val_acc": 56.0}
{"epoch": 13, "training_loss": 71.31535959243774, "training_acc": 52.0, "val_loss": 17.181727290153503, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.41714930534363, "training_acc": 54.0, "val_loss": 17.610716819763184, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.92658710479736, "training_acc": 48.0, "val_loss": 17.570872604846954, "val_acc": 56.0}
{"epoch": 16, "training_loss": 68.92555689811707, "training_acc": 48.0, "val_loss": 17.15591996908188, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.141930103302, "training_acc": 52.0, "val_loss": 17.144477367401123, "val_acc": 56.0}
{"epoch": 18, "training_loss": 68.74457430839539, "training_acc": 53.0, "val_loss": 17.393827438354492, "val_acc": 56.0}
{"epoch": 19, "training_loss": 68.61752820014954, "training_acc": 53.0, "val_loss": 17.494243383407593, "val_acc": 56.0}
{"epoch": 20, "training_loss": 68.58708691596985, "training_acc": 54.0, "val_loss": 17.169184982776642, "val_acc": 56.0}
{"epoch": 21, "training_loss": 68.27620315551758, "training_acc": 52.0, "val_loss": 17.15959459543228, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.41627764701843, "training_acc": 52.0, "val_loss": 17.168983817100525, "val_acc": 56.0}
{"epoch": 23, "training_loss": 68.07039332389832, "training_acc": 55.0, "val_loss": 17.975828051567078, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.7504768371582, "training_acc": 48.0, "val_loss": 17.503857612609863, "val_acc": 56.0}
{"epoch": 25, "training_loss": 68.28457021713257, "training_acc": 55.0, "val_loss": 17.145991325378418, "val_acc": 56.0}
{"epoch": 26, "training_loss": 71.27237176895142, "training_acc": 52.0, "val_loss": 17.137213051319122, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.30383110046387, "training_acc": 52.0, "val_loss": 18.43484193086624, "val_acc": 56.0}
{"epoch": 28, "training_loss": 71.45709657669067, "training_acc": 48.0, "val_loss": 17.419174313545227, "val_acc": 56.0}
{"epoch": 29, "training_loss": 67.97872996330261, "training_acc": 56.0, "val_loss": 17.56736934185028, "val_acc": 56.0}
{"epoch": 30, "training_loss": 73.07112455368042, "training_acc": 52.0, "val_loss": 17.13588684797287, "val_acc": 56.0}
{"epoch": 31, "training_loss": 72.5572235584259, "training_acc": 42.0, "val_loss": 19.000238180160522, "val_acc": 60.0}
{"epoch": 32, "training_loss": 71.57359266281128, "training_acc": 48.0, "val_loss": 17.16042459011078, "val_acc": 56.0}
{"epoch": 33, "training_loss": 68.18260169029236, "training_acc": 53.0, "val_loss": 17.47116595506668, "val_acc": 56.0}
{"epoch": 34, "training_loss": 70.40186810493469, "training_acc": 52.0, "val_loss": 17.19910353422165, "val_acc": 56.0}
{"epoch": 35, "training_loss": 68.65179467201233, "training_acc": 52.0, "val_loss": 18.419750034809113, "val_acc": 56.0}
{"epoch": 36, "training_loss": 70.26184749603271, "training_acc": 48.0, "val_loss": 17.19096004962921, "val_acc": 56.0}
{"epoch": 37, "training_loss": 67.3450677394867, "training_acc": 53.0, "val_loss": 17.54191666841507, "val_acc": 56.0}
{"epoch": 38, "training_loss": 71.10398125648499, "training_acc": 52.0, "val_loss": 17.187926173210144, "val_acc": 56.0}
{"epoch": 39, "training_loss": 68.27921772003174, "training_acc": 52.0, "val_loss": 17.61028617620468, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.27196669578552, "training_acc": 48.0, "val_loss": 18.014629185199738, "val_acc": 56.0}
{"epoch": 41, "training_loss": 68.94404196739197, "training_acc": 53.0, "val_loss": 17.153726518154144, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.84000539779663, "training_acc": 52.0, "val_loss": 17.173925042152405, "val_acc": 56.0}
{"epoch": 43, "training_loss": 67.31441617012024, "training_acc": 53.0, "val_loss": 18.222324550151825, "val_acc": 56.0}
{"epoch": 44, "training_loss": 71.56228971481323, "training_acc": 48.0, "val_loss": 18.252435326576233, "val_acc": 56.0}
{"epoch": 45, "training_loss": 70.13134694099426, "training_acc": 46.0, "val_loss": 17.339828610420227, "val_acc": 56.0}
{"epoch": 46, "training_loss": 70.00493836402893, "training_acc": 52.0, "val_loss": 17.15828627347946, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.09988164901733, "training_acc": 46.0, "val_loss": 17.933261394500732, "val_acc": 56.0}
{"epoch": 48, "training_loss": 68.79771018028259, "training_acc": 48.0, "val_loss": 17.262814939022064, "val_acc": 56.0}
{"epoch": 49, "training_loss": 68.51115131378174, "training_acc": 62.0, "val_loss": 17.14494228363037, "val_acc": 56.0}
