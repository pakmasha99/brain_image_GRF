"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 26042.16986846924, "training_acc": 55.0, "val_loss": 11752.435302734375, "val_acc": 48.0}
{"epoch": 1, "training_loss": 37543.696228027344, "training_acc": 47.0, "val_loss": 15356.23779296875, "val_acc": 52.0}
{"epoch": 2, "training_loss": 63397.8212890625, "training_acc": 53.0, "val_loss": 10739.624786376953, "val_acc": 52.0}
{"epoch": 3, "training_loss": 34263.023376464844, "training_acc": 49.0, "val_loss": 7619.013977050781, "val_acc": 48.0}
{"epoch": 4, "training_loss": 22365.6902923584, "training_acc": 47.0, "val_loss": 10567.094421386719, "val_acc": 52.0}
{"epoch": 5, "training_loss": 47389.249755859375, "training_acc": 53.0, "val_loss": 11989.771270751953, "val_acc": 52.0}
{"epoch": 6, "training_loss": 34025.43817138672, "training_acc": 53.0, "val_loss": 9598.107147216797, "val_acc": 48.0}
{"epoch": 7, "training_loss": 48857.0146484375, "training_acc": 47.0, "val_loss": 13854.472351074219, "val_acc": 48.0}
{"epoch": 8, "training_loss": 45865.78106689453, "training_acc": 47.0, "val_loss": 5786.30256652832, "val_acc": 52.0}
{"epoch": 9, "training_loss": 29353.566650390625, "training_acc": 53.0, "val_loss": 11217.857360839844, "val_acc": 52.0}
{"epoch": 10, "training_loss": 36432.103515625, "training_acc": 53.0, "val_loss": 2288.1282806396484, "val_acc": 48.0}
{"epoch": 11, "training_loss": 12987.344909667969, "training_acc": 47.0, "val_loss": 2161.506462097168, "val_acc": 48.0}
{"epoch": 12, "training_loss": 11146.622497558594, "training_acc": 53.0, "val_loss": 7394.7265625, "val_acc": 52.0}
{"epoch": 13, "training_loss": 24777.306701660156, "training_acc": 53.0, "val_loss": 1375.1115798950195, "val_acc": 48.0}
{"epoch": 14, "training_loss": 7184.486328125, "training_acc": 47.0, "val_loss": 1774.5719909667969, "val_acc": 52.0}
{"epoch": 15, "training_loss": 4809.591178894043, "training_acc": 53.0, "val_loss": 4182.734680175781, "val_acc": 48.0}
{"epoch": 16, "training_loss": 16005.883117675781, "training_acc": 47.0, "val_loss": 1865.1483535766602, "val_acc": 52.0}
{"epoch": 17, "training_loss": 6918.3685302734375, "training_acc": 53.0, "val_loss": 1816.1577224731445, "val_acc": 48.0}
{"epoch": 18, "training_loss": 5597.300003051758, "training_acc": 47.0, "val_loss": 5080.126190185547, "val_acc": 52.0}
{"epoch": 19, "training_loss": 21345.679809570312, "training_acc": 53.0, "val_loss": 2689.112663269043, "val_acc": 52.0}
{"epoch": 20, "training_loss": 12072.666320800781, "training_acc": 55.0, "val_loss": 7676.789093017578, "val_acc": 48.0}
{"epoch": 21, "training_loss": 27213.76776123047, "training_acc": 47.0, "val_loss": 2319.1869735717773, "val_acc": 52.0}
{"epoch": 22, "training_loss": 9836.0078125, "training_acc": 53.0, "val_loss": 2049.3043899536133, "val_acc": 52.0}
{"epoch": 23, "training_loss": 9816.052673339844, "training_acc": 53.0, "val_loss": 4800.171661376953, "val_acc": 48.0}
{"epoch": 24, "training_loss": 14263.166389465332, "training_acc": 48.0, "val_loss": 4199.034881591797, "val_acc": 52.0}
{"epoch": 25, "training_loss": 14135.581481933594, "training_acc": 53.0, "val_loss": 997.2660064697266, "val_acc": 48.0}
{"epoch": 26, "training_loss": 3042.3076171875, "training_acc": 49.0, "val_loss": 4252.550506591797, "val_acc": 52.0}
{"epoch": 27, "training_loss": 16193.321105957031, "training_acc": 53.0, "val_loss": 288.26842308044434, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4697.888977050781, "training_acc": 61.0, "val_loss": 1766.3766860961914, "val_acc": 48.0}
{"epoch": 29, "training_loss": 10090.422668457031, "training_acc": 49.0, "val_loss": 5532.190322875977, "val_acc": 52.0}
{"epoch": 30, "training_loss": 16923.346000671387, "training_acc": 53.0, "val_loss": 5102.31819152832, "val_acc": 48.0}
{"epoch": 31, "training_loss": 22277.615844726562, "training_acc": 47.0, "val_loss": 1700.927734375, "val_acc": 48.0}
{"epoch": 32, "training_loss": 11031.182067871094, "training_acc": 55.0, "val_loss": 10146.460723876953, "val_acc": 52.0}
{"epoch": 33, "training_loss": 36814.392517089844, "training_acc": 53.0, "val_loss": 4302.029037475586, "val_acc": 52.0}
{"epoch": 34, "training_loss": 19496.529418945312, "training_acc": 43.0, "val_loss": 7160.147857666016, "val_acc": 48.0}
{"epoch": 35, "training_loss": 24962.069274902344, "training_acc": 47.0, "val_loss": 3313.3594512939453, "val_acc": 52.0}
{"epoch": 36, "training_loss": 14834.565979003906, "training_acc": 53.0, "val_loss": 3070.606803894043, "val_acc": 52.0}
{"epoch": 37, "training_loss": 12571.279724121094, "training_acc": 49.0, "val_loss": 4701.013565063477, "val_acc": 48.0}
{"epoch": 38, "training_loss": 12886.634254455566, "training_acc": 50.0, "val_loss": 6903.351593017578, "val_acc": 52.0}
{"epoch": 39, "training_loss": 29079.862548828125, "training_acc": 53.0, "val_loss": 7508.619689941406, "val_acc": 52.0}
{"epoch": 40, "training_loss": 19703.528564453125, "training_acc": 53.0, "val_loss": 8464.865112304688, "val_acc": 48.0}
{"epoch": 41, "training_loss": 41108.2763671875, "training_acc": 47.0, "val_loss": 11285.450744628906, "val_acc": 48.0}
{"epoch": 42, "training_loss": 36805.0146484375, "training_acc": 47.0, "val_loss": 5421.636199951172, "val_acc": 52.0}
{"epoch": 43, "training_loss": 26948.771240234375, "training_acc": 53.0, "val_loss": 10241.93344116211, "val_acc": 52.0}
{"epoch": 44, "training_loss": 32319.441162109375, "training_acc": 53.0, "val_loss": 1946.5152740478516, "val_acc": 48.0}
{"epoch": 45, "training_loss": 12155.458251953125, "training_acc": 47.0, "val_loss": 2386.232566833496, "val_acc": 48.0}
{"epoch": 46, "training_loss": 12501.425598144531, "training_acc": 47.0, "val_loss": 6352.767562866211, "val_acc": 52.0}
