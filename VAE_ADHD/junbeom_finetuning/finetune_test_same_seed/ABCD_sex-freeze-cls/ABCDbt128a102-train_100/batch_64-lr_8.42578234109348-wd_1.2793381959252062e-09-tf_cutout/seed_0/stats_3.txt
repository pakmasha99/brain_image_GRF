"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 55949.11353302002, "training_acc": 50.0, "val_loss": 10740.33203125, "val_acc": 52.0}
{"epoch": 1, "training_loss": 61432.572998046875, "training_acc": 55.0, "val_loss": 37296.97265625, "val_acc": 48.0}
{"epoch": 2, "training_loss": 140958.35400390625, "training_acc": 47.0, "val_loss": 12533.074188232422, "val_acc": 48.0}
{"epoch": 3, "training_loss": 50565.85986328125, "training_acc": 47.0, "val_loss": 21836.468505859375, "val_acc": 52.0}
{"epoch": 4, "training_loss": 88016.48852539062, "training_acc": 53.0, "val_loss": 18662.88299560547, "val_acc": 52.0}
{"epoch": 5, "training_loss": 60040.19226074219, "training_acc": 53.0, "val_loss": 7643.729400634766, "val_acc": 48.0}
{"epoch": 6, "training_loss": 40695.487060546875, "training_acc": 47.0, "val_loss": 13213.075256347656, "val_acc": 48.0}
{"epoch": 7, "training_loss": 42511.14208984375, "training_acc": 47.0, "val_loss": 6156.924819946289, "val_acc": 52.0}
{"epoch": 8, "training_loss": 31760.967041015625, "training_acc": 53.0, "val_loss": 11612.39013671875, "val_acc": 52.0}
{"epoch": 9, "training_loss": 37790.58215332031, "training_acc": 53.0, "val_loss": 2389.5978927612305, "val_acc": 48.0}
{"epoch": 10, "training_loss": 15435.016235351562, "training_acc": 47.0, "val_loss": 3705.2501678466797, "val_acc": 48.0}
{"epoch": 11, "training_loss": 13271.059509277344, "training_acc": 53.0, "val_loss": 5547.906112670898, "val_acc": 52.0}
{"epoch": 12, "training_loss": 18351.333435058594, "training_acc": 53.0, "val_loss": 3823.928451538086, "val_acc": 48.0}
{"epoch": 13, "training_loss": 17388.8046875, "training_acc": 47.0, "val_loss": 2022.7836608886719, "val_acc": 48.0}
{"epoch": 14, "training_loss": 12404.348449707031, "training_acc": 51.0, "val_loss": 8231.950378417969, "val_acc": 52.0}
{"epoch": 15, "training_loss": 29346.03515625, "training_acc": 53.0, "val_loss": 387.44895458221436, "val_acc": 52.0}
{"epoch": 16, "training_loss": 19508.81463623047, "training_acc": 43.0, "val_loss": 14128.570556640625, "val_acc": 48.0}
{"epoch": 17, "training_loss": 54672.56884765625, "training_acc": 47.0, "val_loss": 5462.819290161133, "val_acc": 48.0}
{"epoch": 18, "training_loss": 18518.89276123047, "training_acc": 53.0, "val_loss": 8992.928314208984, "val_acc": 52.0}
{"epoch": 19, "training_loss": 36071.756103515625, "training_acc": 53.0, "val_loss": 5138.444137573242, "val_acc": 52.0}
{"epoch": 20, "training_loss": 18241.78143310547, "training_acc": 49.0, "val_loss": 6259.139633178711, "val_acc": 48.0}
{"epoch": 21, "training_loss": 21586.461059570312, "training_acc": 47.0, "val_loss": 3177.361297607422, "val_acc": 52.0}
{"epoch": 22, "training_loss": 14667.429016113281, "training_acc": 53.0, "val_loss": 2485.2983474731445, "val_acc": 52.0}
{"epoch": 23, "training_loss": 13515.043823242188, "training_acc": 47.0, "val_loss": 5369.972610473633, "val_acc": 48.0}
{"epoch": 24, "training_loss": 15491.584030151367, "training_acc": 47.0, "val_loss": 6825.846862792969, "val_acc": 52.0}
{"epoch": 25, "training_loss": 30943.333740234375, "training_acc": 53.0, "val_loss": 8924.446868896484, "val_acc": 52.0}
{"epoch": 26, "training_loss": 28235.157196044922, "training_acc": 53.0, "val_loss": 5275.156021118164, "val_acc": 48.0}
{"epoch": 27, "training_loss": 26689.658813476562, "training_acc": 47.0, "val_loss": 6322.340774536133, "val_acc": 48.0}
{"epoch": 28, "training_loss": 21859.286499023438, "training_acc": 37.0, "val_loss": 2589.2751693725586, "val_acc": 52.0}
{"epoch": 29, "training_loss": 8239.918426513672, "training_acc": 45.0, "val_loss": 1322.904109954834, "val_acc": 52.0}
{"epoch": 30, "training_loss": 3368.8248252868652, "training_acc": 55.0, "val_loss": 1923.6324310302734, "val_acc": 52.0}
{"epoch": 31, "training_loss": 4584.471866607666, "training_acc": 57.0, "val_loss": 4953.775405883789, "val_acc": 48.0}
{"epoch": 32, "training_loss": 19714.533935546875, "training_acc": 47.0, "val_loss": 346.17908000946045, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2618.4003143310547, "training_acc": 56.0, "val_loss": 2263.19522857666, "val_acc": 48.0}
{"epoch": 34, "training_loss": 6714.58317565918, "training_acc": 47.0, "val_loss": 5020.7122802734375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 22145.973876953125, "training_acc": 53.0, "val_loss": 3263.48876953125, "val_acc": 52.0}
{"epoch": 36, "training_loss": 13105.714599609375, "training_acc": 53.0, "val_loss": 6219.517135620117, "val_acc": 48.0}
{"epoch": 37, "training_loss": 20662.438385009766, "training_acc": 47.0, "val_loss": 3964.011764526367, "val_acc": 52.0}
{"epoch": 38, "training_loss": 17875.73809814453, "training_acc": 53.0, "val_loss": 3810.498046875, "val_acc": 52.0}
{"epoch": 39, "training_loss": 11700.980895996094, "training_acc": 53.0, "val_loss": 3298.9356994628906, "val_acc": 48.0}
{"epoch": 40, "training_loss": 7507.806360244751, "training_acc": 59.0, "val_loss": 3328.860092163086, "val_acc": 52.0}
{"epoch": 41, "training_loss": 10798.901672363281, "training_acc": 53.0, "val_loss": 3138.4408950805664, "val_acc": 48.0}
{"epoch": 42, "training_loss": 12055.064056396484, "training_acc": 47.0, "val_loss": 1892.0944213867188, "val_acc": 52.0}
{"epoch": 43, "training_loss": 6726.844207763672, "training_acc": 53.0, "val_loss": 2314.382743835449, "val_acc": 48.0}
{"epoch": 44, "training_loss": 7389.2296142578125, "training_acc": 47.0, "val_loss": 4396.303939819336, "val_acc": 52.0}
{"epoch": 45, "training_loss": 18968.143676757812, "training_acc": 53.0, "val_loss": 2287.053680419922, "val_acc": 52.0}
{"epoch": 46, "training_loss": 12914.002014160156, "training_acc": 51.0, "val_loss": 7445.941925048828, "val_acc": 48.0}
{"epoch": 47, "training_loss": 25657.199249267578, "training_acc": 47.0, "val_loss": 3117.4163818359375, "val_acc": 52.0}
{"epoch": 48, "training_loss": 13954.49267578125, "training_acc": 53.0, "val_loss": 2682.792854309082, "val_acc": 52.0}
{"epoch": 49, "training_loss": 8432.222076416016, "training_acc": 61.0, "val_loss": 4528.12385559082, "val_acc": 48.0}
{"epoch": 50, "training_loss": 12979.832042694092, "training_acc": 46.0, "val_loss": 6002.350997924805, "val_acc": 52.0}
{"epoch": 51, "training_loss": 25026.648559570312, "training_acc": 53.0, "val_loss": 5296.897506713867, "val_acc": 52.0}
