"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.20217633247375, "training_acc": 54.0, "val_loss": 17.27961003780365, "val_acc": 52.0}
{"epoch": 1, "training_loss": 69.05990147590637, "training_acc": 53.0, "val_loss": 17.28542298078537, "val_acc": 52.0}
{"epoch": 2, "training_loss": 69.06206607818604, "training_acc": 53.0, "val_loss": 17.29653924703598, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.14691233634949, "training_acc": 53.0, "val_loss": 17.2951802611351, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.14324116706848, "training_acc": 53.0, "val_loss": 17.296336591243744, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.10338759422302, "training_acc": 53.0, "val_loss": 17.292018234729767, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.06878232955933, "training_acc": 53.0, "val_loss": 17.285500466823578, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.04884648323059, "training_acc": 53.0, "val_loss": 17.28137582540512, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.16948771476746, "training_acc": 53.0, "val_loss": 17.278751730918884, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.0791220664978, "training_acc": 53.0, "val_loss": 17.2779843211174, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.06288576126099, "training_acc": 53.0, "val_loss": 17.278562486171722, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.12063908576965, "training_acc": 53.0, "val_loss": 17.28055477142334, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.02056288719177, "training_acc": 53.0, "val_loss": 17.282508313655853, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.09535574913025, "training_acc": 53.0, "val_loss": 17.284591495990753, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.05002760887146, "training_acc": 53.0, "val_loss": 17.28426069021225, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.09486722946167, "training_acc": 53.0, "val_loss": 17.285999655723572, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.00604939460754, "training_acc": 53.0, "val_loss": 17.29186922311783, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.10335087776184, "training_acc": 53.0, "val_loss": 17.29869395494461, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.09287881851196, "training_acc": 53.0, "val_loss": 17.305690050125122, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.14451766014099, "training_acc": 53.0, "val_loss": 17.310768365859985, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.12228178977966, "training_acc": 53.0, "val_loss": 17.313258349895477, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.07918524742126, "training_acc": 53.0, "val_loss": 17.314498126506805, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.11994051933289, "training_acc": 53.0, "val_loss": 17.314982414245605, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.08776092529297, "training_acc": 53.0, "val_loss": 17.309102416038513, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.1120080947876, "training_acc": 53.0, "val_loss": 17.30310171842575, "val_acc": 52.0}
{"epoch": 25, "training_loss": 69.13541603088379, "training_acc": 53.0, "val_loss": 17.2976091504097, "val_acc": 52.0}
{"epoch": 26, "training_loss": 69.10426497459412, "training_acc": 53.0, "val_loss": 17.296519875526428, "val_acc": 52.0}
{"epoch": 27, "training_loss": 69.11617088317871, "training_acc": 53.0, "val_loss": 17.29092001914978, "val_acc": 52.0}
{"epoch": 28, "training_loss": 69.06555557250977, "training_acc": 53.0, "val_loss": 17.287805676460266, "val_acc": 52.0}
