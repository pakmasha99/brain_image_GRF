"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.669180393219, "training_acc": 47.0, "val_loss": 17.673377692699432, "val_acc": 52.0}
{"epoch": 1, "training_loss": 70.76545763015747, "training_acc": 47.0, "val_loss": 17.52312183380127, "val_acc": 52.0}
{"epoch": 2, "training_loss": 70.24182152748108, "training_acc": 47.0, "val_loss": 17.41495132446289, "val_acc": 52.0}
{"epoch": 3, "training_loss": 69.51929783821106, "training_acc": 47.0, "val_loss": 17.351034283638, "val_acc": 52.0}
{"epoch": 4, "training_loss": 69.53436708450317, "training_acc": 49.0, "val_loss": 17.314764857292175, "val_acc": 52.0}
{"epoch": 5, "training_loss": 69.12058639526367, "training_acc": 56.0, "val_loss": 17.302308976650238, "val_acc": 52.0}
{"epoch": 6, "training_loss": 69.22368502616882, "training_acc": 53.0, "val_loss": 17.302754521369934, "val_acc": 52.0}
{"epoch": 7, "training_loss": 69.1915934085846, "training_acc": 53.0, "val_loss": 17.30974018573761, "val_acc": 52.0}
{"epoch": 8, "training_loss": 69.10672879219055, "training_acc": 53.0, "val_loss": 17.317236959934235, "val_acc": 52.0}
{"epoch": 9, "training_loss": 69.11044001579285, "training_acc": 53.0, "val_loss": 17.327046394348145, "val_acc": 52.0}
{"epoch": 10, "training_loss": 69.21965789794922, "training_acc": 53.0, "val_loss": 17.33684539794922, "val_acc": 52.0}
{"epoch": 11, "training_loss": 69.17153644561768, "training_acc": 53.0, "val_loss": 17.33795702457428, "val_acc": 52.0}
{"epoch": 12, "training_loss": 69.12393093109131, "training_acc": 53.0, "val_loss": 17.34013259410858, "val_acc": 52.0}
{"epoch": 13, "training_loss": 69.06151628494263, "training_acc": 53.0, "val_loss": 17.339251935482025, "val_acc": 52.0}
{"epoch": 14, "training_loss": 69.11693120002747, "training_acc": 53.0, "val_loss": 17.337627708911896, "val_acc": 52.0}
{"epoch": 15, "training_loss": 69.19593262672424, "training_acc": 53.0, "val_loss": 17.337515950202942, "val_acc": 52.0}
{"epoch": 16, "training_loss": 69.14286160469055, "training_acc": 53.0, "val_loss": 17.33584702014923, "val_acc": 52.0}
{"epoch": 17, "training_loss": 69.09911894798279, "training_acc": 53.0, "val_loss": 17.334116995334625, "val_acc": 52.0}
{"epoch": 18, "training_loss": 69.17163801193237, "training_acc": 53.0, "val_loss": 17.329730093479156, "val_acc": 52.0}
{"epoch": 19, "training_loss": 69.17953419685364, "training_acc": 53.0, "val_loss": 17.324531078338623, "val_acc": 52.0}
{"epoch": 20, "training_loss": 69.0575053691864, "training_acc": 53.0, "val_loss": 17.319926619529724, "val_acc": 52.0}
{"epoch": 21, "training_loss": 69.09397673606873, "training_acc": 53.0, "val_loss": 17.316776514053345, "val_acc": 52.0}
{"epoch": 22, "training_loss": 69.12850618362427, "training_acc": 53.0, "val_loss": 17.314228415489197, "val_acc": 52.0}
{"epoch": 23, "training_loss": 69.16310620307922, "training_acc": 53.0, "val_loss": 17.311690747737885, "val_acc": 52.0}
{"epoch": 24, "training_loss": 69.01449370384216, "training_acc": 53.0, "val_loss": 17.30991005897522, "val_acc": 52.0}
