"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.28790593147278, "training_acc": 52.0, "val_loss": 17.193002998828888, "val_acc": 56.0}
{"epoch": 1, "training_loss": 69.2046446800232, "training_acc": 52.0, "val_loss": 17.174796760082245, "val_acc": 56.0}
{"epoch": 2, "training_loss": 69.19170761108398, "training_acc": 52.0, "val_loss": 17.176178097724915, "val_acc": 56.0}
{"epoch": 3, "training_loss": 69.22284293174744, "training_acc": 52.0, "val_loss": 17.187488079071045, "val_acc": 56.0}
{"epoch": 4, "training_loss": 69.32295227050781, "training_acc": 52.0, "val_loss": 17.204509675502777, "val_acc": 56.0}
{"epoch": 5, "training_loss": 69.24079823493958, "training_acc": 52.0, "val_loss": 17.212513089179993, "val_acc": 56.0}
{"epoch": 6, "training_loss": 69.22906994819641, "training_acc": 52.0, "val_loss": 17.225752770900726, "val_acc": 56.0}
{"epoch": 7, "training_loss": 69.24833798408508, "training_acc": 52.0, "val_loss": 17.232593894004822, "val_acc": 56.0}
{"epoch": 8, "training_loss": 69.2125608921051, "training_acc": 52.0, "val_loss": 17.22879409790039, "val_acc": 56.0}
{"epoch": 9, "training_loss": 69.20630836486816, "training_acc": 52.0, "val_loss": 17.232272028923035, "val_acc": 56.0}
{"epoch": 10, "training_loss": 69.24305653572083, "training_acc": 51.0, "val_loss": 17.233440279960632, "val_acc": 56.0}
{"epoch": 11, "training_loss": 69.21103692054749, "training_acc": 51.0, "val_loss": 17.230044305324554, "val_acc": 56.0}
{"epoch": 12, "training_loss": 69.20666217803955, "training_acc": 52.0, "val_loss": 17.225703597068787, "val_acc": 56.0}
{"epoch": 13, "training_loss": 69.30873370170593, "training_acc": 52.0, "val_loss": 17.223986983299255, "val_acc": 56.0}
{"epoch": 14, "training_loss": 69.20032143592834, "training_acc": 52.0, "val_loss": 17.217376828193665, "val_acc": 56.0}
{"epoch": 15, "training_loss": 69.26150941848755, "training_acc": 52.0, "val_loss": 17.20806509256363, "val_acc": 56.0}
{"epoch": 16, "training_loss": 69.16808295249939, "training_acc": 52.0, "val_loss": 17.195098102092743, "val_acc": 56.0}
{"epoch": 17, "training_loss": 69.25777435302734, "training_acc": 52.0, "val_loss": 17.18638986349106, "val_acc": 56.0}
{"epoch": 18, "training_loss": 69.23388767242432, "training_acc": 52.0, "val_loss": 17.17960387468338, "val_acc": 56.0}
{"epoch": 19, "training_loss": 69.16601920127869, "training_acc": 52.0, "val_loss": 17.1747088432312, "val_acc": 56.0}
{"epoch": 20, "training_loss": 69.16617512702942, "training_acc": 52.0, "val_loss": 17.17359870672226, "val_acc": 56.0}
{"epoch": 21, "training_loss": 69.19892191886902, "training_acc": 52.0, "val_loss": 17.172271013259888, "val_acc": 56.0}
{"epoch": 22, "training_loss": 69.20909523963928, "training_acc": 52.0, "val_loss": 17.168498039245605, "val_acc": 56.0}
{"epoch": 23, "training_loss": 69.206463098526, "training_acc": 52.0, "val_loss": 17.171338200569153, "val_acc": 56.0}
{"epoch": 24, "training_loss": 69.17789840698242, "training_acc": 52.0, "val_loss": 17.177850008010864, "val_acc": 56.0}
{"epoch": 25, "training_loss": 69.28139877319336, "training_acc": 52.0, "val_loss": 17.18774139881134, "val_acc": 56.0}
{"epoch": 26, "training_loss": 69.17383623123169, "training_acc": 52.0, "val_loss": 17.192260921001434, "val_acc": 56.0}
{"epoch": 27, "training_loss": 69.17461490631104, "training_acc": 52.0, "val_loss": 17.205803096294403, "val_acc": 56.0}
{"epoch": 28, "training_loss": 69.25874161720276, "training_acc": 52.0, "val_loss": 17.21833050251007, "val_acc": 56.0}
{"epoch": 29, "training_loss": 69.18487191200256, "training_acc": 52.0, "val_loss": 17.223209142684937, "val_acc": 56.0}
{"epoch": 30, "training_loss": 69.30651950836182, "training_acc": 52.0, "val_loss": 17.22184717655182, "val_acc": 56.0}
{"epoch": 31, "training_loss": 69.14168977737427, "training_acc": 52.0, "val_loss": 17.228026688098907, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.09785532951355, "training_acc": 52.0, "val_loss": 17.223380506038666, "val_acc": 56.0}
{"epoch": 33, "training_loss": 69.26794147491455, "training_acc": 52.0, "val_loss": 17.21903532743454, "val_acc": 56.0}
{"epoch": 34, "training_loss": 69.16422200202942, "training_acc": 52.0, "val_loss": 17.211824655532837, "val_acc": 56.0}
{"epoch": 35, "training_loss": 69.18517231941223, "training_acc": 52.0, "val_loss": 17.207741737365723, "val_acc": 56.0}
{"epoch": 36, "training_loss": 69.25644707679749, "training_acc": 52.0, "val_loss": 17.203357815742493, "val_acc": 56.0}
{"epoch": 37, "training_loss": 69.22386622428894, "training_acc": 52.0, "val_loss": 17.198120057582855, "val_acc": 56.0}
{"epoch": 38, "training_loss": 69.13520932197571, "training_acc": 52.0, "val_loss": 17.188380658626556, "val_acc": 56.0}
{"epoch": 39, "training_loss": 69.22956705093384, "training_acc": 52.0, "val_loss": 17.175762355327606, "val_acc": 56.0}
{"epoch": 40, "training_loss": 69.14475226402283, "training_acc": 52.0, "val_loss": 17.17023402452469, "val_acc": 56.0}
{"epoch": 41, "training_loss": 69.24325203895569, "training_acc": 52.0, "val_loss": 17.166730761528015, "val_acc": 56.0}
{"epoch": 42, "training_loss": 69.1277425289154, "training_acc": 52.0, "val_loss": 17.16470718383789, "val_acc": 56.0}
{"epoch": 43, "training_loss": 69.18132495880127, "training_acc": 52.0, "val_loss": 17.16688722372055, "val_acc": 56.0}
{"epoch": 44, "training_loss": 69.20093417167664, "training_acc": 52.0, "val_loss": 17.175334692001343, "val_acc": 56.0}
{"epoch": 45, "training_loss": 69.1918613910675, "training_acc": 52.0, "val_loss": 17.181935906410217, "val_acc": 56.0}
{"epoch": 46, "training_loss": 69.18347573280334, "training_acc": 52.0, "val_loss": 17.190377414226532, "val_acc": 56.0}
{"epoch": 47, "training_loss": 69.14664363861084, "training_acc": 52.0, "val_loss": 17.199015617370605, "val_acc": 56.0}
{"epoch": 48, "training_loss": 69.14464020729065, "training_acc": 52.0, "val_loss": 17.20259040594101, "val_acc": 56.0}
{"epoch": 49, "training_loss": 69.17039513587952, "training_acc": 52.0, "val_loss": 17.20571517944336, "val_acc": 56.0}
{"epoch": 50, "training_loss": 69.26585507392883, "training_acc": 52.0, "val_loss": 17.21140593290329, "val_acc": 56.0}
