"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 124.66213989257812, "training_acc": 52.0, "val_loss": 52.50612497329712, "val_acc": 60.0}
{"epoch": 1, "training_loss": 179.5198531150818, "training_acc": 60.0, "val_loss": 56.87026381492615, "val_acc": 56.0}
{"epoch": 2, "training_loss": 142.40838479995728, "training_acc": 63.0, "val_loss": 34.8382443189621, "val_acc": 52.0}
{"epoch": 3, "training_loss": 141.463805437088, "training_acc": 57.0, "val_loss": 56.828564405441284, "val_acc": 48.0}
{"epoch": 4, "training_loss": 127.55147743225098, "training_acc": 63.0, "val_loss": 48.881906270980835, "val_acc": 44.0}
{"epoch": 5, "training_loss": 90.96350073814392, "training_acc": 69.0, "val_loss": 44.53843832015991, "val_acc": 36.0}
{"epoch": 6, "training_loss": 77.31754541397095, "training_acc": 64.0, "val_loss": 53.59470248222351, "val_acc": 48.0}
{"epoch": 7, "training_loss": 73.27942991256714, "training_acc": 64.0, "val_loss": 46.38885259628296, "val_acc": 44.0}
{"epoch": 8, "training_loss": 79.82987594604492, "training_acc": 70.0, "val_loss": 48.01494777202606, "val_acc": 48.0}
{"epoch": 9, "training_loss": 69.86125564575195, "training_acc": 68.0, "val_loss": 40.885129570961, "val_acc": 40.0}
{"epoch": 10, "training_loss": 63.05069088935852, "training_acc": 69.0, "val_loss": 37.63166666030884, "val_acc": 48.0}
{"epoch": 11, "training_loss": 57.11924922466278, "training_acc": 69.0, "val_loss": 38.9586865901947, "val_acc": 52.0}
{"epoch": 12, "training_loss": 55.98400688171387, "training_acc": 75.0, "val_loss": 33.13313126564026, "val_acc": 48.0}
{"epoch": 13, "training_loss": 63.728644609451294, "training_acc": 66.0, "val_loss": 34.92212891578674, "val_acc": 56.0}
{"epoch": 14, "training_loss": 53.775063157081604, "training_acc": 72.0, "val_loss": 31.479722261428833, "val_acc": 56.0}
{"epoch": 15, "training_loss": 50.731927156448364, "training_acc": 75.0, "val_loss": 28.36005687713623, "val_acc": 60.0}
{"epoch": 16, "training_loss": 53.671956300735474, "training_acc": 72.0, "val_loss": 35.259345173835754, "val_acc": 44.0}
{"epoch": 17, "training_loss": 61.49199080467224, "training_acc": 72.0, "val_loss": 30.811327695846558, "val_acc": 52.0}
{"epoch": 18, "training_loss": 58.47202229499817, "training_acc": 69.0, "val_loss": 30.269935727119446, "val_acc": 52.0}
{"epoch": 19, "training_loss": 49.9744291305542, "training_acc": 74.0, "val_loss": 39.31765556335449, "val_acc": 60.0}
{"epoch": 20, "training_loss": 54.451472878456116, "training_acc": 74.0, "val_loss": 35.692036151885986, "val_acc": 44.0}
{"epoch": 21, "training_loss": 66.02741813659668, "training_acc": 63.0, "val_loss": 41.84284806251526, "val_acc": 48.0}
{"epoch": 22, "training_loss": 56.355281591415405, "training_acc": 74.0, "val_loss": 33.82031321525574, "val_acc": 48.0}
{"epoch": 23, "training_loss": 48.59371757507324, "training_acc": 75.0, "val_loss": 32.33991265296936, "val_acc": 48.0}
{"epoch": 24, "training_loss": 58.60976529121399, "training_acc": 67.0, "val_loss": 40.51190912723541, "val_acc": 48.0}
{"epoch": 25, "training_loss": 56.4850355386734, "training_acc": 75.0, "val_loss": 37.295523285865784, "val_acc": 48.0}
{"epoch": 26, "training_loss": 44.435768127441406, "training_acc": 79.0, "val_loss": 36.67769432067871, "val_acc": 48.0}
{"epoch": 27, "training_loss": 44.23945593833923, "training_acc": 77.0, "val_loss": 37.18286454677582, "val_acc": 56.0}
{"epoch": 28, "training_loss": 45.378143072128296, "training_acc": 76.0, "val_loss": 31.049367785453796, "val_acc": 48.0}
{"epoch": 29, "training_loss": 44.94928026199341, "training_acc": 78.0, "val_loss": 32.497572898864746, "val_acc": 60.0}
{"epoch": 30, "training_loss": 38.61795270442963, "training_acc": 79.0, "val_loss": 36.30385994911194, "val_acc": 60.0}
{"epoch": 31, "training_loss": 50.65918803215027, "training_acc": 76.0, "val_loss": 31.034469604492188, "val_acc": 52.0}
{"epoch": 32, "training_loss": 51.17634320259094, "training_acc": 75.0, "val_loss": 36.30283176898956, "val_acc": 52.0}
{"epoch": 33, "training_loss": 46.321096420288086, "training_acc": 77.0, "val_loss": 32.800304889678955, "val_acc": 56.0}
{"epoch": 34, "training_loss": 49.64820909500122, "training_acc": 74.0, "val_loss": 37.44068741798401, "val_acc": 68.0}
