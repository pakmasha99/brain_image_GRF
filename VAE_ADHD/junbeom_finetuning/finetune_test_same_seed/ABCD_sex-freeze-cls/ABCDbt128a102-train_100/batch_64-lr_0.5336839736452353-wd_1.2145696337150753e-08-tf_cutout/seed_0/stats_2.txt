"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/BT_weights/BT_weights_no_norm5//ABCDbt128a102.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ABCD_sex --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4131.963203430176, "training_acc": 53.0, "val_loss": 814.2355918884277, "val_acc": 52.0}
{"epoch": 1, "training_loss": 3943.3013916015625, "training_acc": 55.0, "val_loss": 2201.8808364868164, "val_acc": 48.0}
{"epoch": 2, "training_loss": 8352.36245727539, "training_acc": 47.0, "val_loss": 729.667329788208, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2640.9536895751953, "training_acc": 53.0, "val_loss": 1369.12841796875, "val_acc": 52.0}
{"epoch": 4, "training_loss": 5521.316619873047, "training_acc": 53.0, "val_loss": 1160.302448272705, "val_acc": 52.0}
{"epoch": 5, "training_loss": 3696.351703643799, "training_acc": 53.0, "val_loss": 548.48313331604, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2803.5406188964844, "training_acc": 47.0, "val_loss": 906.7314147949219, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3020.068130493164, "training_acc": 47.0, "val_loss": 331.5784215927124, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1715.0778274536133, "training_acc": 53.0, "val_loss": 635.7087135314941, "val_acc": 52.0}
{"epoch": 9, "training_loss": 2002.8389701843262, "training_acc": 53.0, "val_loss": 308.1003427505493, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1499.9719619750977, "training_acc": 47.0, "val_loss": 341.27190113067627, "val_acc": 48.0}
{"epoch": 11, "training_loss": 1137.9339981079102, "training_acc": 47.0, "val_loss": 257.1530342102051, "val_acc": 52.0}
{"epoch": 12, "training_loss": 733.1180143356323, "training_acc": 53.0, "val_loss": 408.3472728729248, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1742.2325744628906, "training_acc": 47.0, "val_loss": 195.1011300086975, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1005.5810203552246, "training_acc": 49.0, "val_loss": 557.254695892334, "val_acc": 52.0}
{"epoch": 15, "training_loss": 2031.4100646972656, "training_acc": 53.0, "val_loss": 107.49359130859375, "val_acc": 52.0}
{"epoch": 16, "training_loss": 962.513313293457, "training_acc": 53.0, "val_loss": 770.6608295440674, "val_acc": 48.0}
{"epoch": 17, "training_loss": 3003.8471755981445, "training_acc": 47.0, "val_loss": 250.76894760131836, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1323.9955139160156, "training_acc": 47.0, "val_loss": 757.9068660736084, "val_acc": 52.0}
{"epoch": 19, "training_loss": 2971.827766418457, "training_acc": 53.0, "val_loss": 530.7197570800781, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1392.9114441871643, "training_acc": 53.0, "val_loss": 672.7553367614746, "val_acc": 48.0}
{"epoch": 21, "training_loss": 3157.841049194336, "training_acc": 47.0, "val_loss": 940.8115386962891, "val_acc": 48.0}
{"epoch": 22, "training_loss": 3334.2668838500977, "training_acc": 47.0, "val_loss": 48.03436100482941, "val_acc": 52.0}
{"epoch": 23, "training_loss": 552.989917755127, "training_acc": 53.0, "val_loss": 310.65969467163086, "val_acc": 52.0}
{"epoch": 24, "training_loss": 763.0100221633911, "training_acc": 53.0, "val_loss": 511.58390045166016, "val_acc": 48.0}
{"epoch": 25, "training_loss": 2326.701332092285, "training_acc": 47.0, "val_loss": 578.2815933227539, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1729.4145622253418, "training_acc": 47.0, "val_loss": 507.6451301574707, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2300.347885131836, "training_acc": 53.0, "val_loss": 853.2114028930664, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2992.558204650879, "training_acc": 53.0, "val_loss": 179.19589281082153, "val_acc": 52.0}
{"epoch": 29, "training_loss": 951.6171798706055, "training_acc": 59.0, "val_loss": 886.7877960205078, "val_acc": 48.0}
{"epoch": 30, "training_loss": 3717.165969848633, "training_acc": 47.0, "val_loss": 610.9706878662109, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1495.8313279151917, "training_acc": 47.0, "val_loss": 721.3091850280762, "val_acc": 52.0}
{"epoch": 32, "training_loss": 3555.3134765625, "training_acc": 53.0, "val_loss": 1229.5634269714355, "val_acc": 52.0}
{"epoch": 33, "training_loss": 4482.566436767578, "training_acc": 53.0, "val_loss": 589.4323825836182, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1583.8432970046997, "training_acc": 51.0, "val_loss": 428.717041015625, "val_acc": 48.0}
{"epoch": 35, "training_loss": 1843.317153930664, "training_acc": 47.0, "val_loss": 90.77876210212708, "val_acc": 48.0}
{"epoch": 36, "training_loss": 909.7309265136719, "training_acc": 51.0, "val_loss": 823.5360145568848, "val_acc": 52.0}
{"epoch": 37, "training_loss": 3161.861801147461, "training_acc": 53.0, "val_loss": 580.0117015838623, "val_acc": 52.0}
{"epoch": 38, "training_loss": 1683.1515951156616, "training_acc": 53.0, "val_loss": 616.5616989135742, "val_acc": 48.0}
{"epoch": 39, "training_loss": 3131.989288330078, "training_acc": 47.0, "val_loss": 901.0149955749512, "val_acc": 48.0}
{"epoch": 40, "training_loss": 3154.1571655273438, "training_acc": 47.0, "val_loss": 123.93964529037476, "val_acc": 52.0}
{"epoch": 41, "training_loss": 862.040153503418, "training_acc": 53.0, "val_loss": 382.05766677856445, "val_acc": 52.0}
