"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 83.52542877197266, "training_acc": 42.0, "val_loss": 19.631682336330414, "val_acc": 72.0}
{"epoch": 1, "training_loss": 74.20362949371338, "training_acc": 60.0, "val_loss": 16.027696430683136, "val_acc": 28.0}
{"epoch": 2, "training_loss": 60.944668769836426, "training_acc": 72.0, "val_loss": 20.35197913646698, "val_acc": 72.0}
{"epoch": 3, "training_loss": 72.84547162055969, "training_acc": 72.0, "val_loss": 15.500202775001526, "val_acc": 24.0}
{"epoch": 4, "training_loss": 61.90955448150635, "training_acc": 72.0, "val_loss": 15.39359986782074, "val_acc": 52.0}
{"epoch": 5, "training_loss": 60.671878814697266, "training_acc": 72.0, "val_loss": 14.987178146839142, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.36669898033142, "training_acc": 72.0, "val_loss": 15.238635241985321, "val_acc": 72.0}
{"epoch": 7, "training_loss": 61.418708086013794, "training_acc": 72.0, "val_loss": 15.004870295524597, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.815130949020386, "training_acc": 72.0, "val_loss": 14.976367354393005, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.70402932167053, "training_acc": 72.0, "val_loss": 14.913846552371979, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.408530712127686, "training_acc": 72.0, "val_loss": 15.008257329463959, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.70881986618042, "training_acc": 72.0, "val_loss": 14.959873259067535, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.606804847717285, "training_acc": 72.0, "val_loss": 14.87867683172226, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.83917307853699, "training_acc": 72.0, "val_loss": 14.878623187541962, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.51470232009888, "training_acc": 72.0, "val_loss": 14.852643013000488, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.33523201942444, "training_acc": 72.0, "val_loss": 14.843994379043579, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.176593542099, "training_acc": 72.0, "val_loss": 14.824828505516052, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.53298568725586, "training_acc": 72.0, "val_loss": 14.839480817317963, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.43751263618469, "training_acc": 72.0, "val_loss": 14.800098538398743, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.218064069747925, "training_acc": 72.0, "val_loss": 14.785480499267578, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.00629258155823, "training_acc": 72.0, "val_loss": 14.81475979089737, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.570334911346436, "training_acc": 72.0, "val_loss": 14.791607856750488, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.047932863235474, "training_acc": 72.0, "val_loss": 14.767774939537048, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.217453479766846, "training_acc": 72.0, "val_loss": 14.796292781829834, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.16428875923157, "training_acc": 72.0, "val_loss": 14.730405807495117, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.999839305877686, "training_acc": 72.0, "val_loss": 14.754943549633026, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.94673156738281, "training_acc": 72.0, "val_loss": 14.734470844268799, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.86086964607239, "training_acc": 72.0, "val_loss": 14.65899795293808, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.77424359321594, "training_acc": 72.0, "val_loss": 14.610576629638672, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.56968808174133, "training_acc": 72.0, "val_loss": 14.547279477119446, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.716238260269165, "training_acc": 72.0, "val_loss": 14.590544998645782, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.2197048664093, "training_acc": 72.0, "val_loss": 14.572899043560028, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.26501131057739, "training_acc": 72.0, "val_loss": 14.733222126960754, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.45547556877136, "training_acc": 72.0, "val_loss": 14.659547805786133, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.15701079368591, "training_acc": 72.0, "val_loss": 14.741182327270508, "val_acc": 72.0}
{"epoch": 35, "training_loss": 58.927040338516235, "training_acc": 72.0, "val_loss": 14.780908823013306, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.017375469207764, "training_acc": 72.0, "val_loss": 14.754170179367065, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.186633825302124, "training_acc": 72.0, "val_loss": 14.708903431892395, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.706828594207764, "training_acc": 72.0, "val_loss": 14.71605896949768, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.989035844802856, "training_acc": 72.0, "val_loss": 14.697293937206268, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.98466181755066, "training_acc": 72.0, "val_loss": 14.605902135372162, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.713496923446655, "training_acc": 72.0, "val_loss": 14.483614265918732, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.179121255874634, "training_acc": 72.0, "val_loss": 14.415465295314789, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.17396378517151, "training_acc": 72.0, "val_loss": 14.247775077819824, "val_acc": 72.0}
{"epoch": 44, "training_loss": 57.645195960998535, "training_acc": 72.0, "val_loss": 13.91887217760086, "val_acc": 72.0}
{"epoch": 45, "training_loss": 57.39828872680664, "training_acc": 72.0, "val_loss": 13.515417277812958, "val_acc": 72.0}
{"epoch": 46, "training_loss": 57.6569242477417, "training_acc": 72.0, "val_loss": 15.115518867969513, "val_acc": 72.0}
{"epoch": 47, "training_loss": 60.240540742874146, "training_acc": 72.0, "val_loss": 14.181779325008392, "val_acc": 84.0}
{"epoch": 48, "training_loss": 60.226441383361816, "training_acc": 72.0, "val_loss": 14.969673752784729, "val_acc": 56.0}
{"epoch": 49, "training_loss": 59.53345561027527, "training_acc": 72.0, "val_loss": 14.669051766395569, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.57134032249451, "training_acc": 72.0, "val_loss": 14.980943500995636, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.52407455444336, "training_acc": 72.0, "val_loss": 14.60341066122055, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.5907986164093, "training_acc": 72.0, "val_loss": 14.510814845561981, "val_acc": 72.0}
{"epoch": 53, "training_loss": 58.65921139717102, "training_acc": 72.0, "val_loss": 14.62099403142929, "val_acc": 72.0}
{"epoch": 54, "training_loss": 58.70216679573059, "training_acc": 72.0, "val_loss": 14.683249592781067, "val_acc": 72.0}
{"epoch": 55, "training_loss": 58.95348787307739, "training_acc": 72.0, "val_loss": 14.336918294429779, "val_acc": 72.0}
{"epoch": 56, "training_loss": 58.199462890625, "training_acc": 72.0, "val_loss": 14.193856716156006, "val_acc": 72.0}
{"epoch": 57, "training_loss": 57.16449022293091, "training_acc": 72.0, "val_loss": 14.350025355815887, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.260008335113525, "training_acc": 72.0, "val_loss": 13.721922039985657, "val_acc": 72.0}
{"epoch": 59, "training_loss": 58.71608281135559, "training_acc": 72.0, "val_loss": 14.300397038459778, "val_acc": 68.0}
{"epoch": 60, "training_loss": 57.818440675735474, "training_acc": 72.0, "val_loss": 14.375358819961548, "val_acc": 72.0}
{"epoch": 61, "training_loss": 57.9331591129303, "training_acc": 72.0, "val_loss": 14.852510392665863, "val_acc": 72.0}
{"epoch": 62, "training_loss": 58.904892683029175, "training_acc": 72.0, "val_loss": 14.509381353855133, "val_acc": 72.0}
{"epoch": 63, "training_loss": 57.54668426513672, "training_acc": 72.0, "val_loss": 14.437803626060486, "val_acc": 72.0}
{"epoch": 64, "training_loss": 58.04896950721741, "training_acc": 72.0, "val_loss": 14.476196467876434, "val_acc": 72.0}
