"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 77.22340321540833, "training_acc": 57.0, "val_loss": 23.977501690387726, "val_acc": 72.0}
{"epoch": 1, "training_loss": 122.52860879898071, "training_acc": 56.0, "val_loss": 15.69562554359436, "val_acc": 28.0}
{"epoch": 2, "training_loss": 88.71400499343872, "training_acc": 72.0, "val_loss": 15.222109854221344, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.00057673454285, "training_acc": 72.0, "val_loss": 15.695315599441528, "val_acc": 28.0}
{"epoch": 4, "training_loss": 62.3114595413208, "training_acc": 72.0, "val_loss": 14.938731491565704, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.567891120910645, "training_acc": 72.0, "val_loss": 15.353506803512573, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.842830181121826, "training_acc": 72.0, "val_loss": 15.45662134885788, "val_acc": 28.0}
{"epoch": 7, "training_loss": 62.376601696014404, "training_acc": 72.0, "val_loss": 15.313228964805603, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61.1592755317688, "training_acc": 72.0, "val_loss": 15.130047500133514, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.34830975532532, "training_acc": 72.0, "val_loss": 14.89119678735733, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.45147252082825, "training_acc": 72.0, "val_loss": 14.993926882743835, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.75785994529724, "training_acc": 72.0, "val_loss": 14.886040985584259, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.7292754650116, "training_acc": 72.0, "val_loss": 14.869759976863861, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.73894143104553, "training_acc": 72.0, "val_loss": 14.853034913539886, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.23761320114136, "training_acc": 72.0, "val_loss": 14.993131160736084, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.88632607460022, "training_acc": 72.0, "val_loss": 14.86520767211914, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.09003305435181, "training_acc": 72.0, "val_loss": 14.885520935058594, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.555991411209106, "training_acc": 72.0, "val_loss": 14.986123144626617, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.86551380157471, "training_acc": 72.0, "val_loss": 14.893077313899994, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.56813335418701, "training_acc": 72.0, "val_loss": 14.819049835205078, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.15790796279907, "training_acc": 72.0, "val_loss": 14.823517203330994, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.548420906066895, "training_acc": 72.0, "val_loss": 14.809298515319824, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.88660967350006, "training_acc": 72.0, "val_loss": 14.846396446228027, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.24365949630737, "training_acc": 72.0, "val_loss": 14.812564849853516, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.16748011112213, "training_acc": 72.0, "val_loss": 14.794793725013733, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.90835118293762, "training_acc": 72.0, "val_loss": 14.920203387737274, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.64791536331177, "training_acc": 72.0, "val_loss": 14.93009477853775, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.95196843147278, "training_acc": 72.0, "val_loss": 14.775949716567993, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.95754957199097, "training_acc": 72.0, "val_loss": 14.790748059749603, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.03895330429077, "training_acc": 72.0, "val_loss": 14.799025654792786, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.295332193374634, "training_acc": 72.0, "val_loss": 14.772304892539978, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.85280776023865, "training_acc": 72.0, "val_loss": 14.772838354110718, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.117149114608765, "training_acc": 72.0, "val_loss": 14.854291081428528, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.08727025985718, "training_acc": 72.0, "val_loss": 14.71843272447586, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.60741114616394, "training_acc": 72.0, "val_loss": 14.810308814048767, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.5999755859375, "training_acc": 72.0, "val_loss": 14.913702011108398, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.341108560562134, "training_acc": 72.0, "val_loss": 14.69121128320694, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.68434453010559, "training_acc": 72.0, "val_loss": 14.808252453804016, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.029677629470825, "training_acc": 72.0, "val_loss": 14.747214317321777, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.070690393447876, "training_acc": 72.0, "val_loss": 14.660058915615082, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.58508372306824, "training_acc": 72.0, "val_loss": 14.630259573459625, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.41051173210144, "training_acc": 72.0, "val_loss": 14.530599117279053, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.16331601142883, "training_acc": 72.0, "val_loss": 14.431498944759369, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.005187034606934, "training_acc": 72.0, "val_loss": 14.288236200809479, "val_acc": 72.0}
{"epoch": 44, "training_loss": 57.541186809539795, "training_acc": 72.0, "val_loss": 14.75328654050827, "val_acc": 68.0}
{"epoch": 45, "training_loss": 59.16228723526001, "training_acc": 72.0, "val_loss": 14.071010053157806, "val_acc": 72.0}
{"epoch": 46, "training_loss": 61.98017692565918, "training_acc": 72.0, "val_loss": 14.668843150138855, "val_acc": 68.0}
{"epoch": 47, "training_loss": 60.384665727615356, "training_acc": 72.0, "val_loss": 15.282273292541504, "val_acc": 68.0}
{"epoch": 48, "training_loss": 60.74682807922363, "training_acc": 72.0, "val_loss": 14.867398142814636, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.2977569103241, "training_acc": 72.0, "val_loss": 15.020617842674255, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.924957513809204, "training_acc": 72.0, "val_loss": 14.843690395355225, "val_acc": 72.0}
{"epoch": 51, "training_loss": 60.40682125091553, "training_acc": 72.0, "val_loss": 15.04347026348114, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.817864656448364, "training_acc": 72.0, "val_loss": 14.856396615505219, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.29727506637573, "training_acc": 72.0, "val_loss": 14.89456295967102, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.39895749092102, "training_acc": 72.0, "val_loss": 14.919570088386536, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.48949146270752, "training_acc": 72.0, "val_loss": 14.837376773357391, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.39243984222412, "training_acc": 72.0, "val_loss": 14.81076180934906, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.15865445137024, "training_acc": 72.0, "val_loss": 14.796994626522064, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.13631224632263, "training_acc": 72.0, "val_loss": 14.818044006824493, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.052334785461426, "training_acc": 72.0, "val_loss": 14.779168367385864, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.09064221382141, "training_acc": 72.0, "val_loss": 14.887197315692902, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.310911417007446, "training_acc": 72.0, "val_loss": 14.746114611625671, "val_acc": 72.0}
{"epoch": 62, "training_loss": 58.750219106674194, "training_acc": 72.0, "val_loss": 14.77058231830597, "val_acc": 72.0}
{"epoch": 63, "training_loss": 58.79931998252869, "training_acc": 72.0, "val_loss": 14.711889624595642, "val_acc": 72.0}
{"epoch": 64, "training_loss": 58.56775784492493, "training_acc": 72.0, "val_loss": 14.757457375526428, "val_acc": 72.0}
