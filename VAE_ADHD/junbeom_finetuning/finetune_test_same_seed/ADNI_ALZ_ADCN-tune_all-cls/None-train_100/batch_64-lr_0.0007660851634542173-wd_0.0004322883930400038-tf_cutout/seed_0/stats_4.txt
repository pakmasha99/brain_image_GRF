"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 104.1463418006897, "training_acc": 38.0, "val_loss": 53.32283973693848, "val_acc": 72.0}
{"epoch": 1, "training_loss": 154.1803104877472, "training_acc": 58.0, "val_loss": 14.899128675460815, "val_acc": 72.0}
{"epoch": 2, "training_loss": 67.21178102493286, "training_acc": 72.0, "val_loss": 26.136648654937744, "val_acc": 28.0}
{"epoch": 3, "training_loss": 85.47969365119934, "training_acc": 54.0, "val_loss": 15.199746191501617, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.074748516082764, "training_acc": 72.0, "val_loss": 15.975205600261688, "val_acc": 72.0}
{"epoch": 5, "training_loss": 62.959142446517944, "training_acc": 72.0, "val_loss": 15.090097486972809, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.46791410446167, "training_acc": 72.0, "val_loss": 15.239894390106201, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.96416187286377, "training_acc": 72.0, "val_loss": 14.928174018859863, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.50851845741272, "training_acc": 72.0, "val_loss": 15.300929546356201, "val_acc": 72.0}
{"epoch": 9, "training_loss": 61.48998999595642, "training_acc": 72.0, "val_loss": 14.877118170261383, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.92362904548645, "training_acc": 72.0, "val_loss": 15.141960978507996, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.83032202720642, "training_acc": 72.0, "val_loss": 15.13839066028595, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.57247233390808, "training_acc": 72.0, "val_loss": 14.89378809928894, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.67655110359192, "training_acc": 72.0, "val_loss": 14.901462197303772, "val_acc": 72.0}
{"epoch": 14, "training_loss": 61.71231269836426, "training_acc": 72.0, "val_loss": 14.861421287059784, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.11167550086975, "training_acc": 72.0, "val_loss": 14.992240071296692, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.301262617111206, "training_acc": 72.0, "val_loss": 15.185780823230743, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.85389041900635, "training_acc": 72.0, "val_loss": 15.126022696495056, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.52414107322693, "training_acc": 72.0, "val_loss": 14.982306957244873, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.652634143829346, "training_acc": 72.0, "val_loss": 14.81628566980362, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.671764612197876, "training_acc": 72.0, "val_loss": 14.986942708492279, "val_acc": 72.0}
{"epoch": 21, "training_loss": 60.09645962715149, "training_acc": 72.0, "val_loss": 14.886674284934998, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.07842493057251, "training_acc": 72.0, "val_loss": 14.804039895534515, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.3412811756134, "training_acc": 72.0, "val_loss": 14.808154106140137, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.331082344055176, "training_acc": 72.0, "val_loss": 14.798130095005035, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.44293141365051, "training_acc": 72.0, "val_loss": 14.783547818660736, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.224754333496094, "training_acc": 72.0, "val_loss": 14.781054854393005, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.20954155921936, "training_acc": 72.0, "val_loss": 14.769884943962097, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.14177417755127, "training_acc": 72.0, "val_loss": 14.755959808826447, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.13870286941528, "training_acc": 72.0, "val_loss": 14.742657542228699, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.08054304122925, "training_acc": 72.0, "val_loss": 14.730875194072723, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.45512318611145, "training_acc": 72.0, "val_loss": 14.745709300041199, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.89296841621399, "training_acc": 72.0, "val_loss": 14.765705168247223, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.11999726295471, "training_acc": 72.0, "val_loss": 14.792144298553467, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.127681016922, "training_acc": 72.0, "val_loss": 14.68101590871811, "val_acc": 72.0}
{"epoch": 35, "training_loss": 58.98504376411438, "training_acc": 72.0, "val_loss": 14.660978317260742, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.39490246772766, "training_acc": 72.0, "val_loss": 14.6913081407547, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.45021891593933, "training_acc": 72.0, "val_loss": 14.665289223194122, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.86682200431824, "training_acc": 72.0, "val_loss": 14.621135592460632, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.02352571487427, "training_acc": 72.0, "val_loss": 14.876338839530945, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.46582508087158, "training_acc": 72.0, "val_loss": 14.981210231781006, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.111539125442505, "training_acc": 72.0, "val_loss": 14.609958231449127, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.33829402923584, "training_acc": 72.0, "val_loss": 15.038591623306274, "val_acc": 60.0}
{"epoch": 43, "training_loss": 59.820560932159424, "training_acc": 72.0, "val_loss": 14.723412692546844, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.655982971191406, "training_acc": 72.0, "val_loss": 14.748845994472504, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.15942358970642, "training_acc": 72.0, "val_loss": 14.877192676067352, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.451855421066284, "training_acc": 72.0, "val_loss": 14.783081412315369, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.07244420051575, "training_acc": 72.0, "val_loss": 14.738842844963074, "val_acc": 72.0}
{"epoch": 48, "training_loss": 58.896342515945435, "training_acc": 72.0, "val_loss": 14.727960526943207, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.81688690185547, "training_acc": 72.0, "val_loss": 14.715112745761871, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.81296944618225, "training_acc": 72.0, "val_loss": 14.693060517311096, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.59628653526306, "training_acc": 72.0, "val_loss": 14.66962844133377, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.36857891082764, "training_acc": 72.0, "val_loss": 14.675448834896088, "val_acc": 72.0}
{"epoch": 53, "training_loss": 61.83755445480347, "training_acc": 72.0, "val_loss": 14.6392822265625, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.34394574165344, "training_acc": 72.0, "val_loss": 15.173408389091492, "val_acc": 72.0}
{"epoch": 55, "training_loss": 60.836236000061035, "training_acc": 72.0, "val_loss": 15.115699172019958, "val_acc": 72.0}
{"epoch": 56, "training_loss": 60.27590203285217, "training_acc": 72.0, "val_loss": 14.884079992771149, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.350014448165894, "training_acc": 72.0, "val_loss": 14.807742834091187, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.26220631599426, "training_acc": 72.0, "val_loss": 14.982549846172333, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.90218734741211, "training_acc": 72.0, "val_loss": 14.752502739429474, "val_acc": 72.0}
{"epoch": 60, "training_loss": 58.89597272872925, "training_acc": 72.0, "val_loss": 14.888565242290497, "val_acc": 72.0}
