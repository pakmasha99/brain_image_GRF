"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 76.41000866889954, "training_acc": 73.0, "val_loss": 24.41016286611557, "val_acc": 72.0}
{"epoch": 1, "training_loss": 127.3829140663147, "training_acc": 54.0, "val_loss": 16.38360172510147, "val_acc": 28.0}
{"epoch": 2, "training_loss": 62.79775285720825, "training_acc": 72.0, "val_loss": 19.34928148984909, "val_acc": 72.0}
{"epoch": 3, "training_loss": 66.66415023803711, "training_acc": 72.0, "val_loss": 15.71047157049179, "val_acc": 28.0}
{"epoch": 4, "training_loss": 63.29367733001709, "training_acc": 72.0, "val_loss": 15.457959473133087, "val_acc": 28.0}
{"epoch": 5, "training_loss": 60.75221610069275, "training_acc": 72.0, "val_loss": 15.364834666252136, "val_acc": 72.0}
{"epoch": 6, "training_loss": 62.151379108428955, "training_acc": 72.0, "val_loss": 14.881907403469086, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.86133313179016, "training_acc": 72.0, "val_loss": 14.84445035457611, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.65759801864624, "training_acc": 72.0, "val_loss": 14.826995134353638, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.66621422767639, "training_acc": 72.0, "val_loss": 14.821206033229828, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.54348611831665, "training_acc": 72.0, "val_loss": 14.834330976009369, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.67629408836365, "training_acc": 72.0, "val_loss": 14.906328916549683, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.6640784740448, "training_acc": 72.0, "val_loss": 14.789403975009918, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.23048281669617, "training_acc": 72.0, "val_loss": 14.804822206497192, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.48460650444031, "training_acc": 72.0, "val_loss": 14.889097213745117, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.705209732055664, "training_acc": 72.0, "val_loss": 14.839839935302734, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.56256818771362, "training_acc": 72.0, "val_loss": 14.79334831237793, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.96444034576416, "training_acc": 72.0, "val_loss": 14.836463332176208, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.56297039985657, "training_acc": 72.0, "val_loss": 14.782664179801941, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.25341534614563, "training_acc": 72.0, "val_loss": 14.788517355918884, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.38574528694153, "training_acc": 72.0, "val_loss": 14.784152805805206, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.30666399002075, "training_acc": 72.0, "val_loss": 14.765000343322754, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.33842849731445, "training_acc": 72.0, "val_loss": 14.76195752620697, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.266435623168945, "training_acc": 72.0, "val_loss": 14.769905805587769, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.18907141685486, "training_acc": 72.0, "val_loss": 14.739872515201569, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.06422805786133, "training_acc": 72.0, "val_loss": 14.720484614372253, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.23563885688782, "training_acc": 72.0, "val_loss": 14.706288278102875, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.910648345947266, "training_acc": 72.0, "val_loss": 14.7047758102417, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.826472759246826, "training_acc": 72.0, "val_loss": 14.662517607212067, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.856295108795166, "training_acc": 72.0, "val_loss": 14.8185133934021, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.332770109176636, "training_acc": 72.0, "val_loss": 14.88829106092453, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.258689165115356, "training_acc": 72.0, "val_loss": 14.685916900634766, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.59184241294861, "training_acc": 72.0, "val_loss": 14.651484787464142, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.232869386672974, "training_acc": 72.0, "val_loss": 14.747899770736694, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.39352822303772, "training_acc": 72.0, "val_loss": 14.653781056404114, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.8254292011261, "training_acc": 72.0, "val_loss": 15.051205456256866, "val_acc": 56.0}
{"epoch": 36, "training_loss": 59.99147605895996, "training_acc": 72.0, "val_loss": 14.665688574314117, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.25009632110596, "training_acc": 72.0, "val_loss": 14.805503189563751, "val_acc": 72.0}
{"epoch": 38, "training_loss": 57.75261306762695, "training_acc": 72.0, "val_loss": 14.439313113689423, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.17131805419922, "training_acc": 72.0, "val_loss": 14.788267016410828, "val_acc": 72.0}
{"epoch": 40, "training_loss": 69.08085107803345, "training_acc": 72.0, "val_loss": 14.630548655986786, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.07997536659241, "training_acc": 72.0, "val_loss": 15.938356518745422, "val_acc": 28.0}
{"epoch": 42, "training_loss": 63.652698040008545, "training_acc": 72.0, "val_loss": 15.693122148513794, "val_acc": 28.0}
{"epoch": 43, "training_loss": 62.39775991439819, "training_acc": 72.0, "val_loss": 15.24364948272705, "val_acc": 72.0}
{"epoch": 44, "training_loss": 61.20217299461365, "training_acc": 72.0, "val_loss": 14.928732812404633, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.96282339096069, "training_acc": 72.0, "val_loss": 14.77908045053482, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.62827181816101, "training_acc": 72.0, "val_loss": 14.78513777256012, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.471516609191895, "training_acc": 72.0, "val_loss": 14.904829859733582, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.84629559516907, "training_acc": 72.0, "val_loss": 14.730802178382874, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.90819811820984, "training_acc": 72.0, "val_loss": 14.82757180929184, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.13115644454956, "training_acc": 72.0, "val_loss": 14.668479561805725, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.41934132575989, "training_acc": 72.0, "val_loss": 14.63603526353836, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.20301103591919, "training_acc": 72.0, "val_loss": 14.492785930633545, "val_acc": 72.0}
{"epoch": 53, "training_loss": 58.235196113586426, "training_acc": 72.0, "val_loss": 15.803489089012146, "val_acc": 72.0}
{"epoch": 54, "training_loss": 62.90148377418518, "training_acc": 72.0, "val_loss": 14.898981153964996, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.9440803527832, "training_acc": 72.0, "val_loss": 14.913874864578247, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.91258907318115, "training_acc": 72.0, "val_loss": 14.996257424354553, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.978251934051514, "training_acc": 72.0, "val_loss": 14.89596962928772, "val_acc": 72.0}
