"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.57526445388794, "training_acc": 72.0, "val_loss": 15.581269562244415, "val_acc": 28.0}
{"epoch": 1, "training_loss": 60.45723843574524, "training_acc": 72.0, "val_loss": 15.375420451164246, "val_acc": 72.0}
{"epoch": 2, "training_loss": 63.22904133796692, "training_acc": 72.0, "val_loss": 15.516968071460724, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.688013553619385, "training_acc": 72.0, "val_loss": 14.941507577896118, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.528645038604736, "training_acc": 72.0, "val_loss": 15.206928551197052, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.08275556564331, "training_acc": 72.0, "val_loss": 15.367719531059265, "val_acc": 60.0}
{"epoch": 6, "training_loss": 61.360219955444336, "training_acc": 72.0, "val_loss": 15.113809704780579, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.40148568153381, "training_acc": 72.0, "val_loss": 14.910504221916199, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.657959938049316, "training_acc": 72.0, "val_loss": 14.9104043841362, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.54651880264282, "training_acc": 72.0, "val_loss": 14.955747127532959, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.739843130111694, "training_acc": 72.0, "val_loss": 14.916028082370758, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.10891366004944, "training_acc": 72.0, "val_loss": 14.8492231965065, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.1799373626709, "training_acc": 72.0, "val_loss": 14.88272249698639, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.55491280555725, "training_acc": 72.0, "val_loss": 14.88715261220932, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.16674494743347, "training_acc": 72.0, "val_loss": 14.809507131576538, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.953439474105835, "training_acc": 72.0, "val_loss": 14.855366945266724, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.70962381362915, "training_acc": 72.0, "val_loss": 14.879348874092102, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.67374348640442, "training_acc": 72.0, "val_loss": 14.799775183200836, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.40769958496094, "training_acc": 72.0, "val_loss": 14.724506437778473, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.21947264671326, "training_acc": 72.0, "val_loss": 14.691981673240662, "val_acc": 72.0}
{"epoch": 20, "training_loss": 57.87279224395752, "training_acc": 72.0, "val_loss": 14.643615484237671, "val_acc": 72.0}
{"epoch": 21, "training_loss": 57.75670576095581, "training_acc": 72.0, "val_loss": 14.615786075592041, "val_acc": 72.0}
{"epoch": 22, "training_loss": 57.97107195854187, "training_acc": 72.0, "val_loss": 14.72531408071518, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.30875217914581, "training_acc": 72.0, "val_loss": 14.533671736717224, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.600618839263916, "training_acc": 72.0, "val_loss": 14.496058225631714, "val_acc": 72.0}
{"epoch": 25, "training_loss": 57.318660259246826, "training_acc": 72.0, "val_loss": 14.436520636081696, "val_acc": 72.0}
{"epoch": 26, "training_loss": 56.5508759021759, "training_acc": 72.0, "val_loss": 14.466480910778046, "val_acc": 72.0}
{"epoch": 27, "training_loss": 55.75961780548096, "training_acc": 72.0, "val_loss": 14.479249715805054, "val_acc": 72.0}
{"epoch": 28, "training_loss": 56.30742657184601, "training_acc": 72.0, "val_loss": 14.341413974761963, "val_acc": 72.0}
{"epoch": 29, "training_loss": 54.95137822628021, "training_acc": 72.0, "val_loss": 14.381180703639984, "val_acc": 72.0}
{"epoch": 30, "training_loss": 55.42364573478699, "training_acc": 72.0, "val_loss": 14.096145331859589, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.07211399078369, "training_acc": 72.0, "val_loss": 14.075683057308197, "val_acc": 72.0}
{"epoch": 32, "training_loss": 53.5315967798233, "training_acc": 72.0, "val_loss": 14.310254156589508, "val_acc": 72.0}
{"epoch": 33, "training_loss": 54.393696784973145, "training_acc": 72.0, "val_loss": 13.873648643493652, "val_acc": 72.0}
{"epoch": 34, "training_loss": 53.52049946784973, "training_acc": 72.0, "val_loss": 14.339835941791534, "val_acc": 72.0}
{"epoch": 35, "training_loss": 53.35726594924927, "training_acc": 72.0, "val_loss": 13.7315034866333, "val_acc": 76.0}
{"epoch": 36, "training_loss": 52.02333462238312, "training_acc": 74.0, "val_loss": 14.291790127754211, "val_acc": 76.0}
{"epoch": 37, "training_loss": 51.88575899600983, "training_acc": 73.0, "val_loss": 13.699738681316376, "val_acc": 72.0}
{"epoch": 38, "training_loss": 56.81225895881653, "training_acc": 76.0, "val_loss": 13.822704553604126, "val_acc": 68.0}
{"epoch": 39, "training_loss": 55.30509567260742, "training_acc": 70.0, "val_loss": 13.690966367721558, "val_acc": 76.0}
{"epoch": 40, "training_loss": 54.57796311378479, "training_acc": 74.0, "val_loss": 15.174560248851776, "val_acc": 72.0}
{"epoch": 41, "training_loss": 52.86434888839722, "training_acc": 72.0, "val_loss": 14.130847156047821, "val_acc": 68.0}
{"epoch": 42, "training_loss": 55.59344029426575, "training_acc": 72.0, "val_loss": 14.191384613513947, "val_acc": 68.0}
{"epoch": 43, "training_loss": 52.51320230960846, "training_acc": 75.0, "val_loss": 15.02121388912201, "val_acc": 72.0}
{"epoch": 44, "training_loss": 54.329200744628906, "training_acc": 72.0, "val_loss": 15.668994188308716, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.74015545845032, "training_acc": 72.0, "val_loss": 13.860522210597992, "val_acc": 68.0}
{"epoch": 46, "training_loss": 54.7595579624176, "training_acc": 74.0, "val_loss": 15.441961586475372, "val_acc": 40.0}
{"epoch": 47, "training_loss": 58.96591401100159, "training_acc": 73.0, "val_loss": 14.032384753227234, "val_acc": 72.0}
{"epoch": 48, "training_loss": 54.164613246917725, "training_acc": 72.0, "val_loss": 14.657840132713318, "val_acc": 72.0}
{"epoch": 49, "training_loss": 54.79650104045868, "training_acc": 72.0, "val_loss": 14.85418826341629, "val_acc": 72.0}
{"epoch": 50, "training_loss": 52.671775817871094, "training_acc": 72.0, "val_loss": 14.04317319393158, "val_acc": 72.0}
{"epoch": 51, "training_loss": 52.46502375602722, "training_acc": 72.0, "val_loss": 14.084996283054352, "val_acc": 72.0}
{"epoch": 52, "training_loss": 54.32728600502014, "training_acc": 74.0, "val_loss": 14.120261371135712, "val_acc": 64.0}
{"epoch": 53, "training_loss": 53.56098210811615, "training_acc": 75.0, "val_loss": 13.983604311943054, "val_acc": 76.0}
{"epoch": 54, "training_loss": 51.024019718170166, "training_acc": 72.0, "val_loss": 15.313489735126495, "val_acc": 72.0}
{"epoch": 55, "training_loss": 54.973450660705566, "training_acc": 72.0, "val_loss": 13.996617496013641, "val_acc": 76.0}
{"epoch": 56, "training_loss": 51.319809675216675, "training_acc": 73.0, "val_loss": 14.19760286808014, "val_acc": 68.0}
{"epoch": 57, "training_loss": 54.77582406997681, "training_acc": 75.0, "val_loss": 13.927581906318665, "val_acc": 72.0}
{"epoch": 58, "training_loss": 51.45752692222595, "training_acc": 79.0, "val_loss": 14.342711865901947, "val_acc": 72.0}
