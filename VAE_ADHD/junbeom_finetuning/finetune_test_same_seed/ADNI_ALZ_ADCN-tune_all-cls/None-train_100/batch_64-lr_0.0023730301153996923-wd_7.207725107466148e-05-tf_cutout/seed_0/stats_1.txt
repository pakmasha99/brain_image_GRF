"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.35347008705139, "training_acc": 71.0, "val_loss": 15.787643194198608, "val_acc": 72.0}
{"epoch": 1, "training_loss": 62.89866757392883, "training_acc": 72.0, "val_loss": 14.985689520835876, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.76719403266907, "training_acc": 72.0, "val_loss": 14.845980703830719, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.831634521484375, "training_acc": 72.0, "val_loss": 14.875510334968567, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.79654359817505, "training_acc": 72.0, "val_loss": 14.980241656303406, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.49315524101257, "training_acc": 72.0, "val_loss": 14.824894070625305, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.627084493637085, "training_acc": 72.0, "val_loss": 14.833283424377441, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.31984782218933, "training_acc": 72.0, "val_loss": 14.89112377166748, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.7142539024353, "training_acc": 72.0, "val_loss": 14.825953543186188, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.12955284118652, "training_acc": 72.0, "val_loss": 14.958414435386658, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.87077808380127, "training_acc": 72.0, "val_loss": 15.020474791526794, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.907015323638916, "training_acc": 72.0, "val_loss": 14.824624359607697, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.02492666244507, "training_acc": 72.0, "val_loss": 14.99255746603012, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.850268840789795, "training_acc": 72.0, "val_loss": 14.831313490867615, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.32511639595032, "training_acc": 72.0, "val_loss": 14.893950521945953, "val_acc": 72.0}
{"epoch": 15, "training_loss": 60.31534171104431, "training_acc": 72.0, "val_loss": 14.865697920322418, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.95275020599365, "training_acc": 72.0, "val_loss": 14.914412796497345, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.871936321258545, "training_acc": 72.0, "val_loss": 14.861667156219482, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.184792041778564, "training_acc": 72.0, "val_loss": 14.887423813343048, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.553428411483765, "training_acc": 72.0, "val_loss": 15.070357918739319, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.058330059051514, "training_acc": 72.0, "val_loss": 14.82444703578949, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.22511959075928, "training_acc": 72.0, "val_loss": 14.970757067203522, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.02667427062988, "training_acc": 72.0, "val_loss": 14.964289963245392, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.82621741294861, "training_acc": 72.0, "val_loss": 14.863090217113495, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.33132481575012, "training_acc": 72.0, "val_loss": 14.836345613002777, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.29066777229309, "training_acc": 72.0, "val_loss": 14.925335347652435, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.94033670425415, "training_acc": 72.0, "val_loss": 14.886170625686646, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.35290813446045, "training_acc": 72.0, "val_loss": 14.86036628484726, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.39573264122009, "training_acc": 72.0, "val_loss": 14.994412660598755, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.01613211631775, "training_acc": 72.0, "val_loss": 14.874720573425293, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.20203113555908, "training_acc": 72.0, "val_loss": 14.892308413982391, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.69670522212982, "training_acc": 72.0, "val_loss": 15.098391473293304, "val_acc": 72.0}
{"epoch": 32, "training_loss": 60.57475805282593, "training_acc": 72.0, "val_loss": 15.142822265625, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.62112259864807, "training_acc": 72.0, "val_loss": 14.827938377857208, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.347915172576904, "training_acc": 72.0, "val_loss": 14.90543931722641, "val_acc": 72.0}
{"epoch": 35, "training_loss": 60.08599019050598, "training_acc": 72.0, "val_loss": 14.874368906021118, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.27900958061218, "training_acc": 72.0, "val_loss": 14.890262484550476, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.69908261299133, "training_acc": 72.0, "val_loss": 15.014147758483887, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.77429020404816, "training_acc": 72.0, "val_loss": 14.854979515075684, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.40879797935486, "training_acc": 72.0, "val_loss": 14.831028878688812, "val_acc": 72.0}
