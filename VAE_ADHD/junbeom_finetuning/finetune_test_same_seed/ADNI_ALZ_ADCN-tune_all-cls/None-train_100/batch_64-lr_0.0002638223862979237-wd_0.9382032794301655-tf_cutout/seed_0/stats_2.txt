"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.98758625984192, "training_acc": 52.0, "val_loss": 16.829898953437805, "val_acc": 28.0}
{"epoch": 1, "training_loss": 66.07224583625793, "training_acc": 72.0, "val_loss": 15.135756134986877, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.08768939971924, "training_acc": 72.0, "val_loss": 14.836348593235016, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.13903450965881, "training_acc": 72.0, "val_loss": 14.846707880496979, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.16228103637695, "training_acc": 72.0, "val_loss": 14.838680624961853, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.244563579559326, "training_acc": 72.0, "val_loss": 14.831171929836273, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.19125747680664, "training_acc": 72.0, "val_loss": 14.839157462120056, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.2594211101532, "training_acc": 72.0, "val_loss": 14.840729534626007, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.41804814338684, "training_acc": 72.0, "val_loss": 14.840330183506012, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.3810920715332, "training_acc": 72.0, "val_loss": 14.85259085893631, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.161197662353516, "training_acc": 72.0, "val_loss": 14.845825731754303, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.080915451049805, "training_acc": 72.0, "val_loss": 14.866313338279724, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.1906054019928, "training_acc": 72.0, "val_loss": 14.853927493095398, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.24464678764343, "training_acc": 72.0, "val_loss": 14.839556813240051, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.10240912437439, "training_acc": 72.0, "val_loss": 14.848050475120544, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.14933943748474, "training_acc": 72.0, "val_loss": 14.867323637008667, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.11512875556946, "training_acc": 72.0, "val_loss": 14.84408974647522, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.13930606842041, "training_acc": 72.0, "val_loss": 14.845949411392212, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.97127938270569, "training_acc": 72.0, "val_loss": 14.856354892253876, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.95541834831238, "training_acc": 72.0, "val_loss": 14.847362041473389, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.5795111656189, "training_acc": 72.0, "val_loss": 14.851352572441101, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.192280769348145, "training_acc": 72.0, "val_loss": 14.844539761543274, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.92831230163574, "training_acc": 72.0, "val_loss": 14.839908480644226, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.94429421424866, "training_acc": 72.0, "val_loss": 14.894148707389832, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.73175263404846, "training_acc": 72.0, "val_loss": 14.840202033519745, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.72498965263367, "training_acc": 72.0, "val_loss": 14.812368154525757, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.16323208808899, "training_acc": 72.0, "val_loss": 14.799478650093079, "val_acc": 72.0}
{"epoch": 27, "training_loss": 57.861878633499146, "training_acc": 72.0, "val_loss": 14.77506160736084, "val_acc": 72.0}
{"epoch": 28, "training_loss": 57.7606155872345, "training_acc": 72.0, "val_loss": 14.893344044685364, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.35546565055847, "training_acc": 72.0, "val_loss": 14.908875524997711, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.18233060836792, "training_acc": 72.0, "val_loss": 14.88908976316452, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.543442487716675, "training_acc": 72.0, "val_loss": 14.843544363975525, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.386528730392456, "training_acc": 72.0, "val_loss": 14.840663969516754, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.223843812942505, "training_acc": 72.0, "val_loss": 14.86978530883789, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.1379599571228, "training_acc": 72.0, "val_loss": 14.847083389759064, "val_acc": 72.0}
{"epoch": 35, "training_loss": 58.87262511253357, "training_acc": 72.0, "val_loss": 14.851440489292145, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.76188325881958, "training_acc": 72.0, "val_loss": 14.860495924949646, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.99399518966675, "training_acc": 72.0, "val_loss": 14.852267503738403, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.50258731842041, "training_acc": 72.0, "val_loss": 14.857436716556549, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.98196792602539, "training_acc": 72.0, "val_loss": 14.846700429916382, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.700340032577515, "training_acc": 72.0, "val_loss": 14.851242303848267, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.848140716552734, "training_acc": 72.0, "val_loss": 14.84244018793106, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.3099365234375, "training_acc": 72.0, "val_loss": 14.840471744537354, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.46278357505798, "training_acc": 72.0, "val_loss": 14.84091579914093, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.176167726516724, "training_acc": 72.0, "val_loss": 14.851745963096619, "val_acc": 72.0}
{"epoch": 45, "training_loss": 57.77137112617493, "training_acc": 72.0, "val_loss": 14.815126359462738, "val_acc": 72.0}
{"epoch": 46, "training_loss": 57.715439319610596, "training_acc": 72.0, "val_loss": 14.831128716468811, "val_acc": 72.0}
