"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 62.160754442214966, "training_acc": 72.0, "val_loss": 15.149471163749695, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.78166604042053, "training_acc": 72.0, "val_loss": 14.983148872852325, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.7335090637207, "training_acc": 72.0, "val_loss": 14.866477251052856, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.84577941894531, "training_acc": 72.0, "val_loss": 14.837482571601868, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.607077836990356, "training_acc": 72.0, "val_loss": 14.834867417812347, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.2660756111145, "training_acc": 72.0, "val_loss": 14.884419739246368, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.000176429748535, "training_acc": 72.0, "val_loss": 14.857172966003418, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.37023329734802, "training_acc": 72.0, "val_loss": 14.86111730337143, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.71238303184509, "training_acc": 72.0, "val_loss": 14.849677681922913, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.25930380821228, "training_acc": 72.0, "val_loss": 14.85324501991272, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.15143132209778, "training_acc": 72.0, "val_loss": 14.904284477233887, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.41462063789368, "training_acc": 72.0, "val_loss": 14.83953595161438, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.290056228637695, "training_acc": 72.0, "val_loss": 14.955560863018036, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.824060678482056, "training_acc": 72.0, "val_loss": 14.970917999744415, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.81126356124878, "training_acc": 72.0, "val_loss": 14.850926399230957, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.284613847732544, "training_acc": 72.0, "val_loss": 14.85123336315155, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.78890347480774, "training_acc": 72.0, "val_loss": 14.905275404453278, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.534780979156494, "training_acc": 72.0, "val_loss": 14.824123680591583, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.31045913696289, "training_acc": 72.0, "val_loss": 14.866127073764801, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.465630769729614, "training_acc": 72.0, "val_loss": 14.86247330904007, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.554572343826294, "training_acc": 72.0, "val_loss": 14.83113020658493, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.43363285064697, "training_acc": 72.0, "val_loss": 14.825361967086792, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.34468722343445, "training_acc": 72.0, "val_loss": 14.828576147556305, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.344067335128784, "training_acc": 72.0, "val_loss": 14.824740588665009, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.37536978721619, "training_acc": 72.0, "val_loss": 14.857873320579529, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.39660596847534, "training_acc": 72.0, "val_loss": 14.942595362663269, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.76840305328369, "training_acc": 72.0, "val_loss": 14.884844422340393, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.55755138397217, "training_acc": 72.0, "val_loss": 14.82580155134201, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.27408266067505, "training_acc": 72.0, "val_loss": 14.861087501049042, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.51557278633118, "training_acc": 72.0, "val_loss": 14.861978590488434, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.48892307281494, "training_acc": 72.0, "val_loss": 14.82381522655487, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.30693244934082, "training_acc": 72.0, "val_loss": 14.836272597312927, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.352043867111206, "training_acc": 72.0, "val_loss": 14.832516014575958, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.32537007331848, "training_acc": 72.0, "val_loss": 14.825180172920227, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.29712390899658, "training_acc": 72.0, "val_loss": 14.825865626335144, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.559083461761475, "training_acc": 72.0, "val_loss": 14.827942848205566, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.411014795303345, "training_acc": 72.0, "val_loss": 14.838835597038269, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.35935616493225, "training_acc": 72.0, "val_loss": 14.834703505039215, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.32066106796265, "training_acc": 72.0, "val_loss": 14.824070036411285, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.883373975753784, "training_acc": 72.0, "val_loss": 14.842164516448975, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.298537731170654, "training_acc": 72.0, "val_loss": 14.830878376960754, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.478461027145386, "training_acc": 72.0, "val_loss": 14.874349534511566, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.463918685913086, "training_acc": 72.0, "val_loss": 14.829407632350922, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.68553566932678, "training_acc": 72.0, "val_loss": 14.834029972553253, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.37349224090576, "training_acc": 72.0, "val_loss": 14.823964238166809, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.44518280029297, "training_acc": 72.0, "val_loss": 14.824575185775757, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.270997762680054, "training_acc": 72.0, "val_loss": 14.858169853687286, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.51876711845398, "training_acc": 72.0, "val_loss": 14.857566356658936, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.38560771942139, "training_acc": 72.0, "val_loss": 14.82527107000351, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.540557861328125, "training_acc": 72.0, "val_loss": 14.85503762960434, "val_acc": 72.0}
