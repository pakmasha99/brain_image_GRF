"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 68.9915235042572, "training_acc": 40.0, "val_loss": 15.233519673347473, "val_acc": 72.0}
{"epoch": 1, "training_loss": 66.83616948127747, "training_acc": 72.0, "val_loss": 14.88180160522461, "val_acc": 72.0}
{"epoch": 2, "training_loss": 63.149378538131714, "training_acc": 72.0, "val_loss": 15.86252897977829, "val_acc": 28.0}
{"epoch": 3, "training_loss": 62.86399054527283, "training_acc": 72.0, "val_loss": 14.891281723976135, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.998469948768616, "training_acc": 72.0, "val_loss": 15.214654803276062, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.77994894981384, "training_acc": 72.0, "val_loss": 15.176394581794739, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.298797607421875, "training_acc": 72.0, "val_loss": 14.83602523803711, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.092727184295654, "training_acc": 72.0, "val_loss": 14.97049629688263, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.02385425567627, "training_acc": 72.0, "val_loss": 15.005350112915039, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.950443506240845, "training_acc": 72.0, "val_loss": 14.814268052577972, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.155062675476074, "training_acc": 72.0, "val_loss": 14.774428308010101, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.07484531402588, "training_acc": 72.0, "val_loss": 14.744648337364197, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.21464991569519, "training_acc": 72.0, "val_loss": 14.708898961544037, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.043888568878174, "training_acc": 72.0, "val_loss": 14.714813232421875, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.884663105010986, "training_acc": 72.0, "val_loss": 14.661885797977448, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.59815335273743, "training_acc": 72.0, "val_loss": 14.611037075519562, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.26385450363159, "training_acc": 72.0, "val_loss": 14.612749218940735, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.06802439689636, "training_acc": 72.0, "val_loss": 14.528749883174896, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.32072699069977, "training_acc": 72.0, "val_loss": 14.471916854381561, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.47915816307068, "training_acc": 72.0, "val_loss": 14.545629918575287, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.257094621658325, "training_acc": 72.0, "val_loss": 14.679107069969177, "val_acc": 80.0}
{"epoch": 21, "training_loss": 59.07321524620056, "training_acc": 72.0, "val_loss": 14.70162719488144, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.110918283462524, "training_acc": 72.0, "val_loss": 14.406721293926239, "val_acc": 72.0}
{"epoch": 23, "training_loss": 56.8227653503418, "training_acc": 72.0, "val_loss": 14.666135609149933, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.46672058105469, "training_acc": 72.0, "val_loss": 14.277507364749908, "val_acc": 72.0}
{"epoch": 25, "training_loss": 56.273972511291504, "training_acc": 72.0, "val_loss": 14.296180009841919, "val_acc": 80.0}
{"epoch": 26, "training_loss": 57.318971395492554, "training_acc": 72.0, "val_loss": 14.197191596031189, "val_acc": 72.0}
{"epoch": 27, "training_loss": 55.2376868724823, "training_acc": 72.0, "val_loss": 14.191460609436035, "val_acc": 72.0}
{"epoch": 28, "training_loss": 55.14929246902466, "training_acc": 72.0, "val_loss": 14.180245995521545, "val_acc": 48.0}
{"epoch": 29, "training_loss": 56.672295808792114, "training_acc": 72.0, "val_loss": 13.994583487510681, "val_acc": 68.0}
{"epoch": 30, "training_loss": 53.89040803909302, "training_acc": 72.0, "val_loss": 14.576645195484161, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.61238121986389, "training_acc": 73.0, "val_loss": 14.225953817367554, "val_acc": 80.0}
{"epoch": 32, "training_loss": 54.28130388259888, "training_acc": 72.0, "val_loss": 13.902977108955383, "val_acc": 60.0}
{"epoch": 33, "training_loss": 54.09819436073303, "training_acc": 71.0, "val_loss": 13.850164413452148, "val_acc": 60.0}
{"epoch": 34, "training_loss": 53.08674502372742, "training_acc": 74.0, "val_loss": 14.194706082344055, "val_acc": 80.0}
{"epoch": 35, "training_loss": 51.93182396888733, "training_acc": 75.0, "val_loss": 13.96370530128479, "val_acc": 80.0}
{"epoch": 36, "training_loss": 51.3802387714386, "training_acc": 74.0, "val_loss": 14.62191790342331, "val_acc": 52.0}
{"epoch": 37, "training_loss": 57.12171268463135, "training_acc": 69.0, "val_loss": 21.137918531894684, "val_acc": 72.0}
{"epoch": 38, "training_loss": 67.45469665527344, "training_acc": 72.0, "val_loss": 13.67453783750534, "val_acc": 80.0}
{"epoch": 39, "training_loss": 54.9347460269928, "training_acc": 73.0, "val_loss": 15.277396142482758, "val_acc": 44.0}
{"epoch": 40, "training_loss": 61.68288064002991, "training_acc": 72.0, "val_loss": 14.782817661762238, "val_acc": 52.0}
{"epoch": 41, "training_loss": 58.787938356399536, "training_acc": 72.0, "val_loss": 14.532425999641418, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.287938356399536, "training_acc": 72.0, "val_loss": 14.889761805534363, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.840951681137085, "training_acc": 72.0, "val_loss": 14.80557769536972, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.335047006607056, "training_acc": 72.0, "val_loss": 14.510531723499298, "val_acc": 72.0}
{"epoch": 45, "training_loss": 57.826393604278564, "training_acc": 72.0, "val_loss": 14.53874409198761, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.01214528083801, "training_acc": 72.0, "val_loss": 14.525453746318817, "val_acc": 72.0}
{"epoch": 47, "training_loss": 57.636590242385864, "training_acc": 72.0, "val_loss": 14.391602575778961, "val_acc": 72.0}
{"epoch": 48, "training_loss": 56.40956974029541, "training_acc": 72.0, "val_loss": 14.355824887752533, "val_acc": 72.0}
{"epoch": 49, "training_loss": 56.214221477508545, "training_acc": 72.0, "val_loss": 14.357726275920868, "val_acc": 72.0}
{"epoch": 50, "training_loss": 55.159579277038574, "training_acc": 72.0, "val_loss": 14.14581835269928, "val_acc": 72.0}
{"epoch": 51, "training_loss": 55.33019137382507, "training_acc": 72.0, "val_loss": 14.085523784160614, "val_acc": 76.0}
{"epoch": 52, "training_loss": 55.69682860374451, "training_acc": 72.0, "val_loss": 14.179208874702454, "val_acc": 80.0}
{"epoch": 53, "training_loss": 52.95050275325775, "training_acc": 72.0, "val_loss": 14.939960837364197, "val_acc": 72.0}
{"epoch": 54, "training_loss": 54.748454570770264, "training_acc": 72.0, "val_loss": 14.058409631252289, "val_acc": 68.0}
{"epoch": 55, "training_loss": 56.569838523864746, "training_acc": 73.0, "val_loss": 14.16875422000885, "val_acc": 48.0}
{"epoch": 56, "training_loss": 54.560269594192505, "training_acc": 70.0, "val_loss": 14.960485696792603, "val_acc": 72.0}
{"epoch": 57, "training_loss": 55.02038502693176, "training_acc": 72.0, "val_loss": 14.01434987783432, "val_acc": 80.0}
