"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.8446536064148, "training_acc": 42.0, "val_loss": 17.182321846485138, "val_acc": 28.0}
{"epoch": 1, "training_loss": 67.6007571220398, "training_acc": 72.0, "val_loss": 15.562646090984344, "val_acc": 28.0}
{"epoch": 2, "training_loss": 61.35408902168274, "training_acc": 72.0, "val_loss": 14.991725981235504, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.81129574775696, "training_acc": 72.0, "val_loss": 14.81463611125946, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.28965091705322, "training_acc": 72.0, "val_loss": 14.757564663887024, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.49775791168213, "training_acc": 72.0, "val_loss": 14.753589034080505, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.96430945396423, "training_acc": 72.0, "val_loss": 14.766094088554382, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.08106184005737, "training_acc": 72.0, "val_loss": 14.740963280200958, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.96029615402222, "training_acc": 72.0, "val_loss": 14.722713828086853, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.97952961921692, "training_acc": 72.0, "val_loss": 14.691108465194702, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.61536645889282, "training_acc": 72.0, "val_loss": 14.666126668453217, "val_acc": 72.0}
{"epoch": 11, "training_loss": 58.51754808425903, "training_acc": 72.0, "val_loss": 14.621710777282715, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.443751096725464, "training_acc": 72.0, "val_loss": 14.569485187530518, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.583099722862244, "training_acc": 72.0, "val_loss": 14.564676582813263, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.48543906211853, "training_acc": 72.0, "val_loss": 14.617866277694702, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.10073494911194, "training_acc": 72.0, "val_loss": 14.490944147109985, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.019667625427246, "training_acc": 72.0, "val_loss": 14.485689997673035, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.39454889297485, "training_acc": 72.0, "val_loss": 14.427736401557922, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.44332814216614, "training_acc": 72.0, "val_loss": 14.666680991649628, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.56108808517456, "training_acc": 72.0, "val_loss": 14.510653913021088, "val_acc": 72.0}
{"epoch": 20, "training_loss": 57.96359443664551, "training_acc": 72.0, "val_loss": 14.385008811950684, "val_acc": 72.0}
{"epoch": 21, "training_loss": 57.43273162841797, "training_acc": 72.0, "val_loss": 14.258424937725067, "val_acc": 72.0}
{"epoch": 22, "training_loss": 57.19030475616455, "training_acc": 72.0, "val_loss": 14.142635464668274, "val_acc": 72.0}
{"epoch": 23, "training_loss": 56.77432298660278, "training_acc": 72.0, "val_loss": 14.11222219467163, "val_acc": 72.0}
{"epoch": 24, "training_loss": 56.67483830451965, "training_acc": 72.0, "val_loss": 13.96675854921341, "val_acc": 72.0}
{"epoch": 25, "training_loss": 56.22432065010071, "training_acc": 72.0, "val_loss": 13.734915852546692, "val_acc": 72.0}
{"epoch": 26, "training_loss": 55.40295720100403, "training_acc": 72.0, "val_loss": 13.753220438957214, "val_acc": 72.0}
{"epoch": 27, "training_loss": 55.05763864517212, "training_acc": 72.0, "val_loss": 13.615822792053223, "val_acc": 80.0}
{"epoch": 28, "training_loss": 55.4821503162384, "training_acc": 72.0, "val_loss": 13.677020370960236, "val_acc": 72.0}
{"epoch": 29, "training_loss": 54.64366436004639, "training_acc": 72.0, "val_loss": 13.321521878242493, "val_acc": 84.0}
{"epoch": 30, "training_loss": 56.28002882003784, "training_acc": 72.0, "val_loss": 13.386034965515137, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.96166372299194, "training_acc": 72.0, "val_loss": 14.203746616840363, "val_acc": 72.0}
{"epoch": 32, "training_loss": 56.08902645111084, "training_acc": 72.0, "val_loss": 13.615193963050842, "val_acc": 84.0}
{"epoch": 33, "training_loss": 55.50271964073181, "training_acc": 72.0, "val_loss": 13.450142741203308, "val_acc": 76.0}
{"epoch": 34, "training_loss": 54.78625988960266, "training_acc": 72.0, "val_loss": 13.969391584396362, "val_acc": 72.0}
{"epoch": 35, "training_loss": 54.82678961753845, "training_acc": 72.0, "val_loss": 13.321170210838318, "val_acc": 80.0}
{"epoch": 36, "training_loss": 54.32855820655823, "training_acc": 72.0, "val_loss": 13.281774520874023, "val_acc": 80.0}
{"epoch": 37, "training_loss": 54.602999448776245, "training_acc": 72.0, "val_loss": 13.21088820695877, "val_acc": 80.0}
{"epoch": 38, "training_loss": 52.91331672668457, "training_acc": 72.0, "val_loss": 12.996207177639008, "val_acc": 84.0}
{"epoch": 39, "training_loss": 52.99017524719238, "training_acc": 72.0, "val_loss": 12.89360523223877, "val_acc": 84.0}
{"epoch": 40, "training_loss": 52.62640404701233, "training_acc": 72.0, "val_loss": 12.891650199890137, "val_acc": 84.0}
{"epoch": 41, "training_loss": 51.11764860153198, "training_acc": 72.0, "val_loss": 12.76388168334961, "val_acc": 88.0}
{"epoch": 42, "training_loss": 53.0808584690094, "training_acc": 72.0, "val_loss": 12.883591651916504, "val_acc": 84.0}
{"epoch": 43, "training_loss": 51.499298453330994, "training_acc": 72.0, "val_loss": 12.98682689666748, "val_acc": 80.0}
{"epoch": 44, "training_loss": 50.78113150596619, "training_acc": 72.0, "val_loss": 13.005171716213226, "val_acc": 68.0}
{"epoch": 45, "training_loss": 50.97289180755615, "training_acc": 72.0, "val_loss": 12.843240797519684, "val_acc": 84.0}
{"epoch": 46, "training_loss": 50.70894014835358, "training_acc": 72.0, "val_loss": 13.108675181865692, "val_acc": 80.0}
{"epoch": 47, "training_loss": 49.640952587127686, "training_acc": 72.0, "val_loss": 12.958274781703949, "val_acc": 72.0}
{"epoch": 48, "training_loss": 49.45500683784485, "training_acc": 77.0, "val_loss": 13.122008740901947, "val_acc": 84.0}
{"epoch": 49, "training_loss": 49.731985449790955, "training_acc": 72.0, "val_loss": 13.02482932806015, "val_acc": 84.0}
{"epoch": 50, "training_loss": 49.56027543544769, "training_acc": 75.0, "val_loss": 12.972769141197205, "val_acc": 84.0}
{"epoch": 51, "training_loss": 47.50407302379608, "training_acc": 74.0, "val_loss": 12.899169325828552, "val_acc": 84.0}
{"epoch": 52, "training_loss": 47.46171176433563, "training_acc": 77.0, "val_loss": 12.949128448963165, "val_acc": 84.0}
{"epoch": 53, "training_loss": 47.62975895404816, "training_acc": 75.0, "val_loss": 12.836721539497375, "val_acc": 84.0}
{"epoch": 54, "training_loss": 45.39704144001007, "training_acc": 78.0, "val_loss": 12.831452488899231, "val_acc": 80.0}
{"epoch": 55, "training_loss": 46.00126600265503, "training_acc": 75.0, "val_loss": 12.813283503055573, "val_acc": 80.0}
{"epoch": 56, "training_loss": 44.77989423274994, "training_acc": 80.0, "val_loss": 13.148748874664307, "val_acc": 72.0}
{"epoch": 57, "training_loss": 44.535107254981995, "training_acc": 81.0, "val_loss": 13.129161298274994, "val_acc": 84.0}
{"epoch": 58, "training_loss": 44.002771854400635, "training_acc": 77.0, "val_loss": 13.763761520385742, "val_acc": 60.0}
{"epoch": 59, "training_loss": 48.78975534439087, "training_acc": 79.0, "val_loss": 13.357114791870117, "val_acc": 80.0}
{"epoch": 60, "training_loss": 45.75834882259369, "training_acc": 74.0, "val_loss": 13.020436465740204, "val_acc": 72.0}
