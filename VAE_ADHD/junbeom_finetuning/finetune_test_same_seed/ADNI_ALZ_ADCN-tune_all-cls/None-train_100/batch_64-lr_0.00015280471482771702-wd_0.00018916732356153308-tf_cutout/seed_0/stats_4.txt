"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 75.50166511535645, "training_acc": 28.0, "val_loss": 18.50684881210327, "val_acc": 28.0}
{"epoch": 1, "training_loss": 72.47271156311035, "training_acc": 40.0, "val_loss": 16.093818843364716, "val_acc": 28.0}
{"epoch": 2, "training_loss": 63.49778985977173, "training_acc": 72.0, "val_loss": 15.077212452888489, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.17961812019348, "training_acc": 72.0, "val_loss": 14.81679081916809, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.364712953567505, "training_acc": 72.0, "val_loss": 14.77932333946228, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.283713817596436, "training_acc": 72.0, "val_loss": 14.822213351726532, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.19317293167114, "training_acc": 72.0, "val_loss": 14.819550514221191, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.43048667907715, "training_acc": 72.0, "val_loss": 14.858564734458923, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.45827102661133, "training_acc": 72.0, "val_loss": 14.817237854003906, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.384827852249146, "training_acc": 72.0, "val_loss": 14.803527295589447, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.154481172561646, "training_acc": 72.0, "val_loss": 14.799590408802032, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.16956353187561, "training_acc": 72.0, "val_loss": 14.79627788066864, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.14282274246216, "training_acc": 72.0, "val_loss": 14.800047874450684, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.10198259353638, "training_acc": 72.0, "val_loss": 14.787492156028748, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.13567066192627, "training_acc": 72.0, "val_loss": 14.772838354110718, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.04488706588745, "training_acc": 72.0, "val_loss": 14.762872457504272, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.11043095588684, "training_acc": 72.0, "val_loss": 14.749781787395477, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.980546712875366, "training_acc": 72.0, "val_loss": 14.7304967045784, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.77764177322388, "training_acc": 72.0, "val_loss": 14.70700055360794, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.701730489730835, "training_acc": 72.0, "val_loss": 14.686320722103119, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.835201263427734, "training_acc": 72.0, "val_loss": 14.68559354543686, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.695656061172485, "training_acc": 72.0, "val_loss": 14.680327475070953, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.618793964385986, "training_acc": 72.0, "val_loss": 14.606960117816925, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.46990156173706, "training_acc": 72.0, "val_loss": 14.58638608455658, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.26733207702637, "training_acc": 72.0, "val_loss": 14.567600190639496, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.305052042007446, "training_acc": 72.0, "val_loss": 14.462290704250336, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.0392370223999, "training_acc": 72.0, "val_loss": 14.40976858139038, "val_acc": 72.0}
{"epoch": 27, "training_loss": 57.601996660232544, "training_acc": 72.0, "val_loss": 14.359767735004425, "val_acc": 72.0}
{"epoch": 28, "training_loss": 57.35711693763733, "training_acc": 72.0, "val_loss": 14.315775036811829, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.44876170158386, "training_acc": 72.0, "val_loss": 14.270716905593872, "val_acc": 72.0}
{"epoch": 30, "training_loss": 57.704678535461426, "training_acc": 72.0, "val_loss": 14.221329987049103, "val_acc": 72.0}
{"epoch": 31, "training_loss": 56.5159170627594, "training_acc": 72.0, "val_loss": 14.556612074375153, "val_acc": 72.0}
{"epoch": 32, "training_loss": 57.33723258972168, "training_acc": 72.0, "val_loss": 14.084725081920624, "val_acc": 72.0}
{"epoch": 33, "training_loss": 56.71154046058655, "training_acc": 72.0, "val_loss": 14.095841348171234, "val_acc": 72.0}
{"epoch": 34, "training_loss": 56.75454068183899, "training_acc": 72.0, "val_loss": 14.294442534446716, "val_acc": 72.0}
{"epoch": 35, "training_loss": 56.15821361541748, "training_acc": 72.0, "val_loss": 14.025022089481354, "val_acc": 72.0}
{"epoch": 36, "training_loss": 55.55709099769592, "training_acc": 72.0, "val_loss": 13.740415871143341, "val_acc": 80.0}
{"epoch": 37, "training_loss": 55.24104642868042, "training_acc": 72.0, "val_loss": 14.109481871128082, "val_acc": 72.0}
{"epoch": 38, "training_loss": 54.217856645584106, "training_acc": 72.0, "val_loss": 14.594541490077972, "val_acc": 56.0}
{"epoch": 39, "training_loss": 60.078871965408325, "training_acc": 72.0, "val_loss": 14.548656344413757, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.505016803741455, "training_acc": 72.0, "val_loss": 14.483694732189178, "val_acc": 72.0}
{"epoch": 41, "training_loss": 57.702475786209106, "training_acc": 72.0, "val_loss": 14.46744054555893, "val_acc": 72.0}
{"epoch": 42, "training_loss": 57.37407994270325, "training_acc": 72.0, "val_loss": 14.286234974861145, "val_acc": 72.0}
{"epoch": 43, "training_loss": 56.11246061325073, "training_acc": 72.0, "val_loss": 13.98388296365738, "val_acc": 72.0}
{"epoch": 44, "training_loss": 55.845404863357544, "training_acc": 72.0, "val_loss": 13.887026906013489, "val_acc": 72.0}
{"epoch": 45, "training_loss": 55.10289406776428, "training_acc": 72.0, "val_loss": 13.764636218547821, "val_acc": 72.0}
{"epoch": 46, "training_loss": 54.47950744628906, "training_acc": 72.0, "val_loss": 13.707603514194489, "val_acc": 80.0}
{"epoch": 47, "training_loss": 54.55097985267639, "training_acc": 72.0, "val_loss": 13.55663388967514, "val_acc": 80.0}
{"epoch": 48, "training_loss": 53.597912549972534, "training_acc": 72.0, "val_loss": 13.519971072673798, "val_acc": 80.0}
{"epoch": 49, "training_loss": 52.65755796432495, "training_acc": 72.0, "val_loss": 13.743624091148376, "val_acc": 76.0}
{"epoch": 50, "training_loss": 52.02344560623169, "training_acc": 72.0, "val_loss": 13.365629315376282, "val_acc": 72.0}
{"epoch": 51, "training_loss": 52.92705059051514, "training_acc": 72.0, "val_loss": 13.987965881824493, "val_acc": 72.0}
{"epoch": 52, "training_loss": 53.157652139663696, "training_acc": 72.0, "val_loss": 13.535350561141968, "val_acc": 76.0}
{"epoch": 53, "training_loss": 49.94321310520172, "training_acc": 72.0, "val_loss": 12.968781590461731, "val_acc": 72.0}
{"epoch": 54, "training_loss": 51.47282958030701, "training_acc": 72.0, "val_loss": 12.932777404785156, "val_acc": 72.0}
{"epoch": 55, "training_loss": 49.86798310279846, "training_acc": 75.0, "val_loss": 13.881416618824005, "val_acc": 76.0}
{"epoch": 56, "training_loss": 51.407193422317505, "training_acc": 73.0, "val_loss": 12.540438771247864, "val_acc": 76.0}
{"epoch": 57, "training_loss": 48.505502820014954, "training_acc": 78.0, "val_loss": 12.83315122127533, "val_acc": 80.0}
{"epoch": 58, "training_loss": 47.86004626750946, "training_acc": 77.0, "val_loss": 13.464735448360443, "val_acc": 76.0}
{"epoch": 59, "training_loss": 51.24019980430603, "training_acc": 74.0, "val_loss": 12.614454329013824, "val_acc": 76.0}
{"epoch": 60, "training_loss": 51.14777445793152, "training_acc": 76.0, "val_loss": 12.933717668056488, "val_acc": 84.0}
{"epoch": 61, "training_loss": 53.099066495895386, "training_acc": 73.0, "val_loss": 13.732719421386719, "val_acc": 72.0}
{"epoch": 62, "training_loss": 51.847633600234985, "training_acc": 73.0, "val_loss": 12.794536352157593, "val_acc": 76.0}
{"epoch": 63, "training_loss": 50.17779731750488, "training_acc": 78.0, "val_loss": 12.561425566673279, "val_acc": 80.0}
{"epoch": 64, "training_loss": 46.47398054599762, "training_acc": 77.0, "val_loss": 12.665660679340363, "val_acc": 72.0}
{"epoch": 65, "training_loss": 47.71985960006714, "training_acc": 81.0, "val_loss": 12.75322288274765, "val_acc": 72.0}
{"epoch": 66, "training_loss": 46.040210604667664, "training_acc": 81.0, "val_loss": 12.47236579656601, "val_acc": 76.0}
{"epoch": 67, "training_loss": 47.411606788635254, "training_acc": 82.0, "val_loss": 13.186417520046234, "val_acc": 84.0}
{"epoch": 68, "training_loss": 45.50234794616699, "training_acc": 79.0, "val_loss": 12.061156332492828, "val_acc": 80.0}
{"epoch": 69, "training_loss": 47.159441113471985, "training_acc": 80.0, "val_loss": 13.552862405776978, "val_acc": 76.0}
{"epoch": 70, "training_loss": 49.47126913070679, "training_acc": 75.0, "val_loss": 12.736745178699493, "val_acc": 80.0}
{"epoch": 71, "training_loss": 45.91169321537018, "training_acc": 80.0, "val_loss": 12.212204933166504, "val_acc": 72.0}
{"epoch": 72, "training_loss": 47.571441411972046, "training_acc": 81.0, "val_loss": 12.61553019285202, "val_acc": 76.0}
{"epoch": 73, "training_loss": 48.497352719306946, "training_acc": 78.0, "val_loss": 12.595391273498535, "val_acc": 84.0}
{"epoch": 74, "training_loss": 42.83427691459656, "training_acc": 79.0, "val_loss": 12.282873690128326, "val_acc": 80.0}
{"epoch": 75, "training_loss": 46.628175497055054, "training_acc": 83.0, "val_loss": 13.150276243686676, "val_acc": 80.0}
{"epoch": 76, "training_loss": 45.91341769695282, "training_acc": 77.0, "val_loss": 12.515036761760712, "val_acc": 76.0}
{"epoch": 77, "training_loss": 41.01411175727844, "training_acc": 83.0, "val_loss": 12.677086889743805, "val_acc": 68.0}
{"epoch": 78, "training_loss": 53.802029848098755, "training_acc": 72.0, "val_loss": 13.006776571273804, "val_acc": 80.0}
{"epoch": 79, "training_loss": 46.35368347167969, "training_acc": 78.0, "val_loss": 13.861536979675293, "val_acc": 76.0}
{"epoch": 80, "training_loss": 44.710384249687195, "training_acc": 77.0, "val_loss": 11.923511326313019, "val_acc": 80.0}
{"epoch": 81, "training_loss": 44.694143891334534, "training_acc": 84.0, "val_loss": 12.51966506242752, "val_acc": 80.0}
{"epoch": 82, "training_loss": 44.76178812980652, "training_acc": 77.0, "val_loss": 11.894962191581726, "val_acc": 76.0}
{"epoch": 83, "training_loss": 41.62671887874603, "training_acc": 84.0, "val_loss": 12.118793278932571, "val_acc": 72.0}
{"epoch": 84, "training_loss": 41.22514593601227, "training_acc": 84.0, "val_loss": 12.609769403934479, "val_acc": 76.0}
{"epoch": 85, "training_loss": 38.734437704086304, "training_acc": 84.0, "val_loss": 12.31435015797615, "val_acc": 76.0}
{"epoch": 86, "training_loss": 41.15610682964325, "training_acc": 87.0, "val_loss": 13.16772848367691, "val_acc": 76.0}
{"epoch": 87, "training_loss": 43.289759397506714, "training_acc": 78.0, "val_loss": 11.937755346298218, "val_acc": 76.0}
{"epoch": 88, "training_loss": 42.31254994869232, "training_acc": 84.0, "val_loss": 12.697209417819977, "val_acc": 80.0}
{"epoch": 89, "training_loss": 41.370434045791626, "training_acc": 80.0, "val_loss": 12.65554279088974, "val_acc": 76.0}
{"epoch": 90, "training_loss": 45.6785204410553, "training_acc": 79.0, "val_loss": 12.238987535238266, "val_acc": 76.0}
{"epoch": 91, "training_loss": 39.965641260147095, "training_acc": 88.0, "val_loss": 13.643792271614075, "val_acc": 80.0}
{"epoch": 92, "training_loss": 38.784576535224915, "training_acc": 83.0, "val_loss": 11.911891400814056, "val_acc": 80.0}
{"epoch": 93, "training_loss": 40.78598630428314, "training_acc": 88.0, "val_loss": 12.081632018089294, "val_acc": 80.0}
{"epoch": 94, "training_loss": 35.74933850765228, "training_acc": 88.0, "val_loss": 12.930242717266083, "val_acc": 80.0}
{"epoch": 95, "training_loss": 37.663745641708374, "training_acc": 85.0, "val_loss": 12.685692310333252, "val_acc": 76.0}
{"epoch": 96, "training_loss": 36.21105599403381, "training_acc": 89.0, "val_loss": 12.814269959926605, "val_acc": 80.0}
{"epoch": 97, "training_loss": 38.306384563446045, "training_acc": 87.0, "val_loss": 12.654341757297516, "val_acc": 76.0}
{"epoch": 98, "training_loss": 32.826618790626526, "training_acc": 91.0, "val_loss": 11.985181272029877, "val_acc": 76.0}
{"epoch": 99, "training_loss": 34.69325244426727, "training_acc": 88.0, "val_loss": 14.543835818767548, "val_acc": 76.0}
{"epoch": 100, "training_loss": 39.9409863948822, "training_acc": 86.0, "val_loss": 12.242566049098969, "val_acc": 76.0}
{"epoch": 101, "training_loss": 33.23900651931763, "training_acc": 89.0, "val_loss": 12.525606155395508, "val_acc": 76.0}
