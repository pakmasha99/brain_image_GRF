"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 72.00735926628113, "training_acc": 42.0, "val_loss": 17.287616431713104, "val_acc": 28.0}
{"epoch": 1, "training_loss": 67.05249261856079, "training_acc": 66.0, "val_loss": 15.370136499404907, "val_acc": 40.0}
{"epoch": 2, "training_loss": 60.86109185218811, "training_acc": 72.0, "val_loss": 14.820803701877594, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.61954975128174, "training_acc": 72.0, "val_loss": 14.791087806224823, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.49695181846619, "training_acc": 72.0, "val_loss": 14.798684418201447, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.27210211753845, "training_acc": 72.0, "val_loss": 14.817611873149872, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.25741744041443, "training_acc": 72.0, "val_loss": 14.79017436504364, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.37783908843994, "training_acc": 72.0, "val_loss": 14.802694320678711, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.2188286781311, "training_acc": 72.0, "val_loss": 14.781740307807922, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.13452649116516, "training_acc": 72.0, "val_loss": 14.78625237941742, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.142250061035156, "training_acc": 72.0, "val_loss": 14.78402465581894, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.15900421142578, "training_acc": 72.0, "val_loss": 14.75885808467865, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.044963359832764, "training_acc": 72.0, "val_loss": 14.746414124965668, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.03675198554993, "training_acc": 72.0, "val_loss": 14.739233255386353, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.05094933509827, "training_acc": 72.0, "val_loss": 14.729708433151245, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.11803126335144, "training_acc": 72.0, "val_loss": 14.709693193435669, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.866703033447266, "training_acc": 72.0, "val_loss": 14.67074602842331, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.10136866569519, "training_acc": 72.0, "val_loss": 14.633014798164368, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.43053388595581, "training_acc": 72.0, "val_loss": 14.728374779224396, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.99555945396423, "training_acc": 72.0, "val_loss": 14.582216739654541, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.240556478500366, "training_acc": 72.0, "val_loss": 14.56049382686615, "val_acc": 72.0}
{"epoch": 21, "training_loss": 57.79689383506775, "training_acc": 72.0, "val_loss": 14.39751535654068, "val_acc": 72.0}
{"epoch": 22, "training_loss": 57.47642922401428, "training_acc": 72.0, "val_loss": 14.905646443367004, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.418662309646606, "training_acc": 72.0, "val_loss": 14.858999848365784, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.193310022354126, "training_acc": 72.0, "val_loss": 14.803294837474823, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.40393948554993, "training_acc": 72.0, "val_loss": 14.840108156204224, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.48121738433838, "training_acc": 72.0, "val_loss": 14.81299102306366, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.42078375816345, "training_acc": 72.0, "val_loss": 14.819976687431335, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.37195134162903, "training_acc": 72.0, "val_loss": 14.80836570262909, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.267810106277466, "training_acc": 72.0, "val_loss": 14.818349480628967, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.20364809036255, "training_acc": 72.0, "val_loss": 14.835183322429657, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.2465603351593, "training_acc": 72.0, "val_loss": 14.82623964548111, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.3483452796936, "training_acc": 72.0, "val_loss": 14.815881848335266, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.289522886276245, "training_acc": 72.0, "val_loss": 14.816032350063324, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.34671354293823, "training_acc": 72.0, "val_loss": 14.814727008342743, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.316383600234985, "training_acc": 72.0, "val_loss": 14.809948205947876, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.219457387924194, "training_acc": 72.0, "val_loss": 14.807645976543427, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.106098651885986, "training_acc": 72.0, "val_loss": 14.804568886756897, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.18630599975586, "training_acc": 72.0, "val_loss": 14.814719557762146, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.13398289680481, "training_acc": 72.0, "val_loss": 14.84687328338623, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.36890912055969, "training_acc": 72.0, "val_loss": 14.850503206253052, "val_acc": 72.0}
