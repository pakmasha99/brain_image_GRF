"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.71057105064392, "training_acc": 38.0, "val_loss": 16.571596264839172, "val_acc": 28.0}
{"epoch": 1, "training_loss": 65.01825165748596, "training_acc": 72.0, "val_loss": 15.121367573738098, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.546074628829956, "training_acc": 72.0, "val_loss": 14.888732135295868, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.40532612800598, "training_acc": 72.0, "val_loss": 14.81456458568573, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.4266471862793, "training_acc": 72.0, "val_loss": 14.826925098896027, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.3941171169281, "training_acc": 72.0, "val_loss": 14.829717576503754, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.426108837127686, "training_acc": 72.0, "val_loss": 14.843657612800598, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.216137409210205, "training_acc": 72.0, "val_loss": 14.833159744739532, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.16213321685791, "training_acc": 72.0, "val_loss": 14.841324090957642, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.223251819610596, "training_acc": 72.0, "val_loss": 14.84791785478592, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.287193059921265, "training_acc": 72.0, "val_loss": 14.8399218916893, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.12230920791626, "training_acc": 72.0, "val_loss": 14.845503866672516, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.100422620773315, "training_acc": 72.0, "val_loss": 14.860303699970245, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.10459089279175, "training_acc": 72.0, "val_loss": 14.840784668922424, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.19055128097534, "training_acc": 72.0, "val_loss": 14.840084314346313, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.989399671554565, "training_acc": 72.0, "val_loss": 14.838150143623352, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.91608023643494, "training_acc": 72.0, "val_loss": 14.83316421508789, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.75541806221008, "training_acc": 72.0, "val_loss": 14.834986627101898, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.05985355377197, "training_acc": 72.0, "val_loss": 14.822766184806824, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.96211838722229, "training_acc": 72.0, "val_loss": 14.813666045665741, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.798749685287476, "training_acc": 72.0, "val_loss": 14.833743870258331, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.51598048210144, "training_acc": 72.0, "val_loss": 14.761810004711151, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.404388189315796, "training_acc": 72.0, "val_loss": 14.726035296916962, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.99600911140442, "training_acc": 72.0, "val_loss": 14.708945155143738, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.30921483039856, "training_acc": 72.0, "val_loss": 14.761237800121307, "val_acc": 72.0}
{"epoch": 25, "training_loss": 57.66805696487427, "training_acc": 72.0, "val_loss": 14.768071472644806, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.40119981765747, "training_acc": 72.0, "val_loss": 14.600734412670135, "val_acc": 72.0}
{"epoch": 27, "training_loss": 57.47533869743347, "training_acc": 72.0, "val_loss": 14.699386060237885, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.44614863395691, "training_acc": 72.0, "val_loss": 14.6303191781044, "val_acc": 72.0}
{"epoch": 29, "training_loss": 57.53314936161041, "training_acc": 72.0, "val_loss": 14.548647403717041, "val_acc": 72.0}
{"epoch": 30, "training_loss": 56.81609272956848, "training_acc": 72.0, "val_loss": 14.44297581911087, "val_acc": 72.0}
{"epoch": 31, "training_loss": 56.259262561798096, "training_acc": 72.0, "val_loss": 14.43490982055664, "val_acc": 72.0}
{"epoch": 32, "training_loss": 55.462422609329224, "training_acc": 72.0, "val_loss": 14.678572118282318, "val_acc": 72.0}
{"epoch": 33, "training_loss": 55.55447840690613, "training_acc": 72.0, "val_loss": 14.35742974281311, "val_acc": 68.0}
{"epoch": 34, "training_loss": 55.81272625923157, "training_acc": 72.0, "val_loss": 14.330138266086578, "val_acc": 72.0}
{"epoch": 35, "training_loss": 55.00124216079712, "training_acc": 72.0, "val_loss": 14.365783333778381, "val_acc": 72.0}
{"epoch": 36, "training_loss": 55.73377728462219, "training_acc": 72.0, "val_loss": 14.540725946426392, "val_acc": 72.0}
{"epoch": 37, "training_loss": 54.314847230911255, "training_acc": 72.0, "val_loss": 14.326952397823334, "val_acc": 72.0}
{"epoch": 38, "training_loss": 55.19634294509888, "training_acc": 72.0, "val_loss": 14.213739335536957, "val_acc": 68.0}
{"epoch": 39, "training_loss": 52.21268153190613, "training_acc": 72.0, "val_loss": 14.085248112678528, "val_acc": 72.0}
{"epoch": 40, "training_loss": 52.59178066253662, "training_acc": 72.0, "val_loss": 14.107032120227814, "val_acc": 68.0}
{"epoch": 41, "training_loss": 51.07434701919556, "training_acc": 72.0, "val_loss": 13.975068926811218, "val_acc": 68.0}
{"epoch": 42, "training_loss": 51.139928698539734, "training_acc": 72.0, "val_loss": 14.257916808128357, "val_acc": 68.0}
{"epoch": 43, "training_loss": 53.1310920715332, "training_acc": 72.0, "val_loss": 14.006160199642181, "val_acc": 72.0}
{"epoch": 44, "training_loss": 51.26041769981384, "training_acc": 72.0, "val_loss": 14.785633981227875, "val_acc": 68.0}
{"epoch": 45, "training_loss": 50.38308501243591, "training_acc": 72.0, "val_loss": 14.106498658657074, "val_acc": 68.0}
{"epoch": 46, "training_loss": 50.90386211872101, "training_acc": 72.0, "val_loss": 14.733090996742249, "val_acc": 68.0}
{"epoch": 47, "training_loss": 51.34883904457092, "training_acc": 72.0, "val_loss": 13.85156661272049, "val_acc": 72.0}
{"epoch": 48, "training_loss": 48.51966166496277, "training_acc": 72.0, "val_loss": 13.683867454528809, "val_acc": 72.0}
{"epoch": 49, "training_loss": 49.91365361213684, "training_acc": 72.0, "val_loss": 13.515578210353851, "val_acc": 76.0}
{"epoch": 50, "training_loss": 47.81046664714813, "training_acc": 73.0, "val_loss": 13.830320537090302, "val_acc": 72.0}
{"epoch": 51, "training_loss": 49.56407594680786, "training_acc": 72.0, "val_loss": 13.888794183731079, "val_acc": 68.0}
{"epoch": 52, "training_loss": 45.87133038043976, "training_acc": 72.0, "val_loss": 13.897213339805603, "val_acc": 68.0}
{"epoch": 53, "training_loss": 47.96761107444763, "training_acc": 75.0, "val_loss": 13.290639221668243, "val_acc": 76.0}
{"epoch": 54, "training_loss": 45.27288043498993, "training_acc": 78.0, "val_loss": 13.000372052192688, "val_acc": 76.0}
{"epoch": 55, "training_loss": 45.35077977180481, "training_acc": 82.0, "val_loss": 13.137593865394592, "val_acc": 68.0}
{"epoch": 56, "training_loss": 44.26663565635681, "training_acc": 75.0, "val_loss": 13.18361610174179, "val_acc": 72.0}
{"epoch": 57, "training_loss": 43.96492385864258, "training_acc": 81.0, "val_loss": 13.656757771968842, "val_acc": 76.0}
{"epoch": 58, "training_loss": 45.6721248626709, "training_acc": 81.0, "val_loss": 12.877462804317474, "val_acc": 80.0}
{"epoch": 59, "training_loss": 41.00185179710388, "training_acc": 82.0, "val_loss": 13.197216391563416, "val_acc": 72.0}
{"epoch": 60, "training_loss": 42.44430387020111, "training_acc": 83.0, "val_loss": 14.209775626659393, "val_acc": 72.0}
{"epoch": 61, "training_loss": 43.32944333553314, "training_acc": 84.0, "val_loss": 15.40507823228836, "val_acc": 68.0}
{"epoch": 62, "training_loss": 44.618239998817444, "training_acc": 78.0, "val_loss": 14.070799946784973, "val_acc": 52.0}
{"epoch": 63, "training_loss": 48.24326181411743, "training_acc": 82.0, "val_loss": 15.010319650173187, "val_acc": 68.0}
{"epoch": 64, "training_loss": 43.77231764793396, "training_acc": 78.0, "val_loss": 12.886244058609009, "val_acc": 68.0}
{"epoch": 65, "training_loss": 40.467193365097046, "training_acc": 86.0, "val_loss": 12.858471274375916, "val_acc": 76.0}
{"epoch": 66, "training_loss": 42.74789500236511, "training_acc": 86.0, "val_loss": 12.603673338890076, "val_acc": 72.0}
{"epoch": 67, "training_loss": 38.3342319726944, "training_acc": 87.0, "val_loss": 12.628678977489471, "val_acc": 72.0}
{"epoch": 68, "training_loss": 38.63053023815155, "training_acc": 86.0, "val_loss": 15.126557648181915, "val_acc": 72.0}
{"epoch": 69, "training_loss": 44.14997124671936, "training_acc": 82.0, "val_loss": 13.588608801364899, "val_acc": 56.0}
{"epoch": 70, "training_loss": 42.46956264972687, "training_acc": 84.0, "val_loss": 15.841151773929596, "val_acc": 68.0}
{"epoch": 71, "training_loss": 45.26965248584747, "training_acc": 77.0, "val_loss": 12.799669802188873, "val_acc": 72.0}
{"epoch": 72, "training_loss": 39.06247961521149, "training_acc": 81.0, "val_loss": 13.229084014892578, "val_acc": 72.0}
{"epoch": 73, "training_loss": 43.08901393413544, "training_acc": 83.0, "val_loss": 12.70764172077179, "val_acc": 68.0}
{"epoch": 74, "training_loss": 36.149030327796936, "training_acc": 88.0, "val_loss": 12.839536368846893, "val_acc": 72.0}
{"epoch": 75, "training_loss": 35.79384982585907, "training_acc": 86.0, "val_loss": 13.849054276943207, "val_acc": 76.0}
{"epoch": 76, "training_loss": 34.51675796508789, "training_acc": 88.0, "val_loss": 12.98338919878006, "val_acc": 68.0}
{"epoch": 77, "training_loss": 29.711244583129883, "training_acc": 90.0, "val_loss": 13.468112051486969, "val_acc": 76.0}
{"epoch": 78, "training_loss": 28.99590528011322, "training_acc": 91.0, "val_loss": 14.628246426582336, "val_acc": 64.0}
{"epoch": 79, "training_loss": 40.110729336738586, "training_acc": 85.0, "val_loss": 15.570151805877686, "val_acc": 72.0}
{"epoch": 80, "training_loss": 39.337021350860596, "training_acc": 82.0, "val_loss": 12.698006629943848, "val_acc": 72.0}
{"epoch": 81, "training_loss": 35.25663459300995, "training_acc": 89.0, "val_loss": 13.249395787715912, "val_acc": 72.0}
{"epoch": 82, "training_loss": 38.03806126117706, "training_acc": 86.0, "val_loss": 12.268909811973572, "val_acc": 72.0}
{"epoch": 83, "training_loss": 32.24272358417511, "training_acc": 90.0, "val_loss": 12.420610338449478, "val_acc": 76.0}
{"epoch": 84, "training_loss": 28.857714295387268, "training_acc": 89.0, "val_loss": 12.659721076488495, "val_acc": 72.0}
{"epoch": 85, "training_loss": 27.48870074748993, "training_acc": 94.0, "val_loss": 13.079321384429932, "val_acc": 76.0}
{"epoch": 86, "training_loss": 28.46622908115387, "training_acc": 91.0, "val_loss": 13.464206457138062, "val_acc": 72.0}
{"epoch": 87, "training_loss": 25.62942510843277, "training_acc": 93.0, "val_loss": 14.132794737815857, "val_acc": 80.0}
{"epoch": 88, "training_loss": 27.22526514530182, "training_acc": 92.0, "val_loss": 14.931590855121613, "val_acc": 72.0}
{"epoch": 89, "training_loss": 22.49971354007721, "training_acc": 95.0, "val_loss": 14.937321841716766, "val_acc": 68.0}
{"epoch": 90, "training_loss": 20.73719322681427, "training_acc": 97.0, "val_loss": 14.585824310779572, "val_acc": 68.0}
{"epoch": 91, "training_loss": 21.538587629795074, "training_acc": 96.0, "val_loss": 13.827073574066162, "val_acc": 72.0}
{"epoch": 92, "training_loss": 19.94399732351303, "training_acc": 96.0, "val_loss": 13.982120156288147, "val_acc": 76.0}
{"epoch": 93, "training_loss": 18.475520730018616, "training_acc": 98.0, "val_loss": 14.900355041027069, "val_acc": 76.0}
{"epoch": 94, "training_loss": 17.370743930339813, "training_acc": 96.0, "val_loss": 14.91096317768097, "val_acc": 72.0}
{"epoch": 95, "training_loss": 19.18879061937332, "training_acc": 97.0, "val_loss": 15.608841180801392, "val_acc": 76.0}
{"epoch": 96, "training_loss": 25.371415495872498, "training_acc": 91.0, "val_loss": 14.28377479314804, "val_acc": 68.0}
{"epoch": 97, "training_loss": 27.141247034072876, "training_acc": 93.0, "val_loss": 14.101797342300415, "val_acc": 80.0}
{"epoch": 98, "training_loss": 18.295163929462433, "training_acc": 97.0, "val_loss": 14.236655831336975, "val_acc": 72.0}
{"epoch": 99, "training_loss": 16.909273207187653, "training_acc": 98.0, "val_loss": 15.115636587142944, "val_acc": 72.0}
{"epoch": 100, "training_loss": 16.90897810459137, "training_acc": 98.0, "val_loss": 17.328445613384247, "val_acc": 72.0}
{"epoch": 101, "training_loss": 17.510899782180786, "training_acc": 96.0, "val_loss": 14.492766559123993, "val_acc": 72.0}
