"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.60491633415222, "training_acc": 40.0, "val_loss": 17.452751100063324, "val_acc": 28.0}
{"epoch": 1, "training_loss": 67.97607064247131, "training_acc": 44.0, "val_loss": 15.557487308979034, "val_acc": 28.0}
{"epoch": 2, "training_loss": 62.13733792304993, "training_acc": 72.0, "val_loss": 15.143570303916931, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.41216850280762, "training_acc": 72.0, "val_loss": 14.90848958492279, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.374985218048096, "training_acc": 72.0, "val_loss": 14.82274979352951, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.095597982406616, "training_acc": 72.0, "val_loss": 14.818128943443298, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.88888931274414, "training_acc": 72.0, "val_loss": 14.83844518661499, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.07617807388306, "training_acc": 72.0, "val_loss": 14.81245905160904, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.83102083206177, "training_acc": 72.0, "val_loss": 14.797680079936981, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.85068941116333, "training_acc": 72.0, "val_loss": 14.794410765171051, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.597134828567505, "training_acc": 72.0, "val_loss": 14.801101386547089, "val_acc": 72.0}
{"epoch": 11, "training_loss": 58.52262473106384, "training_acc": 72.0, "val_loss": 14.780822396278381, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.231032609939575, "training_acc": 72.0, "val_loss": 14.767281711101532, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.70503497123718, "training_acc": 72.0, "val_loss": 14.735923707485199, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.40082383155823, "training_acc": 72.0, "val_loss": 14.836378395557404, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.82931315898895, "training_acc": 72.0, "val_loss": 14.723879098892212, "val_acc": 72.0}
{"epoch": 16, "training_loss": 57.90270256996155, "training_acc": 72.0, "val_loss": 14.67728316783905, "val_acc": 72.0}
{"epoch": 17, "training_loss": 57.884318828582764, "training_acc": 72.0, "val_loss": 14.65957760810852, "val_acc": 72.0}
{"epoch": 18, "training_loss": 56.87053632736206, "training_acc": 72.0, "val_loss": 14.71802443265915, "val_acc": 72.0}
{"epoch": 19, "training_loss": 56.87786149978638, "training_acc": 72.0, "val_loss": 14.526492357254028, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.56313347816467, "training_acc": 72.0, "val_loss": 14.577782154083252, "val_acc": 72.0}
{"epoch": 21, "training_loss": 55.72051453590393, "training_acc": 72.0, "val_loss": 14.465756714344025, "val_acc": 72.0}
{"epoch": 22, "training_loss": 54.67879891395569, "training_acc": 72.0, "val_loss": 14.342178404331207, "val_acc": 72.0}
{"epoch": 23, "training_loss": 54.62987303733826, "training_acc": 72.0, "val_loss": 15.086449682712555, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.8060839176178, "training_acc": 72.0, "val_loss": 14.318326115608215, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.994860887527466, "training_acc": 72.0, "val_loss": 14.64340090751648, "val_acc": 68.0}
{"epoch": 26, "training_loss": 55.75296759605408, "training_acc": 72.0, "val_loss": 14.756067097187042, "val_acc": 72.0}
{"epoch": 27, "training_loss": 56.15761661529541, "training_acc": 72.0, "val_loss": 14.533992111682892, "val_acc": 72.0}
{"epoch": 28, "training_loss": 54.835543632507324, "training_acc": 72.0, "val_loss": 14.316503703594208, "val_acc": 68.0}
{"epoch": 29, "training_loss": 54.351783871650696, "training_acc": 72.0, "val_loss": 14.451026916503906, "val_acc": 72.0}
{"epoch": 30, "training_loss": 55.153178453445435, "training_acc": 72.0, "val_loss": 14.300000667572021, "val_acc": 72.0}
{"epoch": 31, "training_loss": 53.68088150024414, "training_acc": 72.0, "val_loss": 14.383864402770996, "val_acc": 68.0}
{"epoch": 32, "training_loss": 54.562270164489746, "training_acc": 72.0, "val_loss": 14.164157211780548, "val_acc": 72.0}
{"epoch": 33, "training_loss": 51.745707988739014, "training_acc": 72.0, "val_loss": 14.010956883430481, "val_acc": 64.0}
{"epoch": 34, "training_loss": 51.70095884799957, "training_acc": 72.0, "val_loss": 14.001277089118958, "val_acc": 68.0}
{"epoch": 35, "training_loss": 50.164971470832825, "training_acc": 72.0, "val_loss": 15.110446512699127, "val_acc": 72.0}
{"epoch": 36, "training_loss": 53.43173635005951, "training_acc": 72.0, "val_loss": 14.051549136638641, "val_acc": 68.0}
{"epoch": 37, "training_loss": 49.515697717666626, "training_acc": 72.0, "val_loss": 14.360278844833374, "val_acc": 64.0}
{"epoch": 38, "training_loss": 52.436442613601685, "training_acc": 72.0, "val_loss": 14.548636972904205, "val_acc": 68.0}
{"epoch": 39, "training_loss": 54.071542263031006, "training_acc": 72.0, "val_loss": 14.868603646755219, "val_acc": 72.0}
{"epoch": 40, "training_loss": 51.02427315711975, "training_acc": 72.0, "val_loss": 14.39010500907898, "val_acc": 64.0}
{"epoch": 41, "training_loss": 52.87221074104309, "training_acc": 73.0, "val_loss": 14.261782169342041, "val_acc": 68.0}
{"epoch": 42, "training_loss": 53.23596525192261, "training_acc": 72.0, "val_loss": 14.855864644050598, "val_acc": 72.0}
{"epoch": 43, "training_loss": 53.13244962692261, "training_acc": 72.0, "val_loss": 14.172214269638062, "val_acc": 64.0}
{"epoch": 44, "training_loss": 53.53051781654358, "training_acc": 72.0, "val_loss": 13.985764980316162, "val_acc": 76.0}
{"epoch": 45, "training_loss": 50.8758659362793, "training_acc": 73.0, "val_loss": 14.573238790035248, "val_acc": 68.0}
{"epoch": 46, "training_loss": 51.42708992958069, "training_acc": 72.0, "val_loss": 14.220625162124634, "val_acc": 72.0}
{"epoch": 47, "training_loss": 48.828964829444885, "training_acc": 73.0, "val_loss": 13.788595795631409, "val_acc": 76.0}
{"epoch": 48, "training_loss": 50.41961407661438, "training_acc": 81.0, "val_loss": 13.718259334564209, "val_acc": 76.0}
{"epoch": 49, "training_loss": 48.16424918174744, "training_acc": 75.0, "val_loss": 14.36426192522049, "val_acc": 68.0}
{"epoch": 50, "training_loss": 48.247228384017944, "training_acc": 75.0, "val_loss": 13.723978400230408, "val_acc": 76.0}
{"epoch": 51, "training_loss": 46.98089408874512, "training_acc": 78.0, "val_loss": 13.704562187194824, "val_acc": 68.0}
{"epoch": 52, "training_loss": 46.350395917892456, "training_acc": 82.0, "val_loss": 14.016872644424438, "val_acc": 72.0}
{"epoch": 53, "training_loss": 46.548593044281006, "training_acc": 77.0, "val_loss": 13.519330322742462, "val_acc": 80.0}
{"epoch": 54, "training_loss": 48.635334491729736, "training_acc": 79.0, "val_loss": 13.588400185108185, "val_acc": 68.0}
{"epoch": 55, "training_loss": 45.47760057449341, "training_acc": 83.0, "val_loss": 14.735731482505798, "val_acc": 68.0}
{"epoch": 56, "training_loss": 48.738924741744995, "training_acc": 76.0, "val_loss": 13.390229642391205, "val_acc": 76.0}
{"epoch": 57, "training_loss": 47.68717408180237, "training_acc": 81.0, "val_loss": 13.275602459907532, "val_acc": 72.0}
{"epoch": 58, "training_loss": 47.13496232032776, "training_acc": 77.0, "val_loss": 13.622650504112244, "val_acc": 76.0}
{"epoch": 59, "training_loss": 44.51283061504364, "training_acc": 83.0, "val_loss": 13.067834079265594, "val_acc": 72.0}
{"epoch": 60, "training_loss": 46.956215381622314, "training_acc": 80.0, "val_loss": 13.133418560028076, "val_acc": 72.0}
{"epoch": 61, "training_loss": 42.79728937149048, "training_acc": 83.0, "val_loss": 13.230453431606293, "val_acc": 72.0}
{"epoch": 62, "training_loss": 42.85239064693451, "training_acc": 87.0, "val_loss": 14.25720602273941, "val_acc": 68.0}
{"epoch": 63, "training_loss": 44.78095829486847, "training_acc": 77.0, "val_loss": 13.102860748767853, "val_acc": 72.0}
{"epoch": 64, "training_loss": 45.20984327793121, "training_acc": 86.0, "val_loss": 13.15593272447586, "val_acc": 72.0}
{"epoch": 65, "training_loss": 42.3258615732193, "training_acc": 80.0, "val_loss": 14.484994113445282, "val_acc": 68.0}
{"epoch": 66, "training_loss": 43.09936010837555, "training_acc": 81.0, "val_loss": 12.996990978717804, "val_acc": 76.0}
{"epoch": 67, "training_loss": 40.80707907676697, "training_acc": 87.0, "val_loss": 13.308188319206238, "val_acc": 76.0}
{"epoch": 68, "training_loss": 38.952701807022095, "training_acc": 86.0, "val_loss": 13.824039697647095, "val_acc": 72.0}
{"epoch": 69, "training_loss": 38.30060434341431, "training_acc": 84.0, "val_loss": 12.888821959495544, "val_acc": 68.0}
{"epoch": 70, "training_loss": 40.16770160198212, "training_acc": 83.0, "val_loss": 13.335180282592773, "val_acc": 76.0}
{"epoch": 71, "training_loss": 37.1510009765625, "training_acc": 89.0, "val_loss": 13.079945743083954, "val_acc": 72.0}
{"epoch": 72, "training_loss": 36.52717971801758, "training_acc": 88.0, "val_loss": 13.641802966594696, "val_acc": 72.0}
{"epoch": 73, "training_loss": 36.38367438316345, "training_acc": 88.0, "val_loss": 13.279515504837036, "val_acc": 76.0}
{"epoch": 74, "training_loss": 34.93865370750427, "training_acc": 92.0, "val_loss": 13.989652693271637, "val_acc": 72.0}
{"epoch": 75, "training_loss": 33.144089221954346, "training_acc": 89.0, "val_loss": 13.248294591903687, "val_acc": 64.0}
{"epoch": 76, "training_loss": 35.51803421974182, "training_acc": 90.0, "val_loss": 16.7396679520607, "val_acc": 68.0}
{"epoch": 77, "training_loss": 42.64228975772858, "training_acc": 79.0, "val_loss": 13.187500834465027, "val_acc": 64.0}
{"epoch": 78, "training_loss": 40.03793966770172, "training_acc": 89.0, "val_loss": 14.56897258758545, "val_acc": 68.0}
{"epoch": 79, "training_loss": 43.2656192779541, "training_acc": 78.0, "val_loss": 12.727685272693634, "val_acc": 72.0}
{"epoch": 80, "training_loss": 38.48704779148102, "training_acc": 87.0, "val_loss": 13.123579323291779, "val_acc": 76.0}
{"epoch": 81, "training_loss": 36.00510489940643, "training_acc": 86.0, "val_loss": 12.970933318138123, "val_acc": 68.0}
{"epoch": 82, "training_loss": 36.555885553359985, "training_acc": 91.0, "val_loss": 14.632314443588257, "val_acc": 72.0}
{"epoch": 83, "training_loss": 38.04520356655121, "training_acc": 84.0, "val_loss": 12.44255155324936, "val_acc": 76.0}
{"epoch": 84, "training_loss": 35.66709923744202, "training_acc": 88.0, "val_loss": 12.513187527656555, "val_acc": 80.0}
{"epoch": 85, "training_loss": 39.20043933391571, "training_acc": 86.0, "val_loss": 13.185201585292816, "val_acc": 76.0}
{"epoch": 86, "training_loss": 36.75494050979614, "training_acc": 85.0, "val_loss": 12.534859776496887, "val_acc": 76.0}
{"epoch": 87, "training_loss": 31.806586503982544, "training_acc": 93.0, "val_loss": 13.161125779151917, "val_acc": 76.0}
{"epoch": 88, "training_loss": 32.806766748428345, "training_acc": 91.0, "val_loss": 13.41417133808136, "val_acc": 76.0}
{"epoch": 89, "training_loss": 29.98372709751129, "training_acc": 91.0, "val_loss": 13.25758546590805, "val_acc": 60.0}
{"epoch": 90, "training_loss": 32.47117817401886, "training_acc": 94.0, "val_loss": 14.445458352565765, "val_acc": 72.0}
{"epoch": 91, "training_loss": 30.907264947891235, "training_acc": 89.0, "val_loss": 13.404248654842377, "val_acc": 64.0}
{"epoch": 92, "training_loss": 37.57580542564392, "training_acc": 85.0, "val_loss": 13.760967552661896, "val_acc": 76.0}
{"epoch": 93, "training_loss": 30.44079625606537, "training_acc": 90.0, "val_loss": 13.439226150512695, "val_acc": 60.0}
{"epoch": 94, "training_loss": 27.942303895950317, "training_acc": 97.0, "val_loss": 15.340997278690338, "val_acc": 72.0}
{"epoch": 95, "training_loss": 27.539648115634918, "training_acc": 92.0, "val_loss": 13.764320313930511, "val_acc": 64.0}
{"epoch": 96, "training_loss": 24.353067278862, "training_acc": 99.0, "val_loss": 14.3996462225914, "val_acc": 68.0}
{"epoch": 97, "training_loss": 25.928102135658264, "training_acc": 94.0, "val_loss": 14.717820286750793, "val_acc": 72.0}
{"epoch": 98, "training_loss": 28.31551742553711, "training_acc": 92.0, "val_loss": 14.124269783496857, "val_acc": 68.0}
{"epoch": 99, "training_loss": 20.96028447151184, "training_acc": 97.0, "val_loss": 14.666242897510529, "val_acc": 72.0}
{"epoch": 100, "training_loss": 21.885668575763702, "training_acc": 96.0, "val_loss": 13.610747456550598, "val_acc": 64.0}
{"epoch": 101, "training_loss": 21.993966817855835, "training_acc": 98.0, "val_loss": 14.578638970851898, "val_acc": 72.0}
{"epoch": 102, "training_loss": 22.133773744106293, "training_acc": 96.0, "val_loss": 13.52531760931015, "val_acc": 72.0}
