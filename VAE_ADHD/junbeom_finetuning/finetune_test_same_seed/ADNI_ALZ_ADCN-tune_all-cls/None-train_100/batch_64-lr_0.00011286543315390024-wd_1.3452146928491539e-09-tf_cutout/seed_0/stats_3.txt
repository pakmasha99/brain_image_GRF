"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 73.22655487060547, "training_acc": 28.0, "val_loss": 18.01999658346176, "val_acc": 28.0}
{"epoch": 1, "training_loss": 70.37166237831116, "training_acc": 44.0, "val_loss": 16.04221910238266, "val_acc": 28.0}
{"epoch": 2, "training_loss": 63.46012473106384, "training_acc": 72.0, "val_loss": 15.257041156291962, "val_acc": 68.0}
{"epoch": 3, "training_loss": 60.725430727005005, "training_acc": 72.0, "val_loss": 14.97412621974945, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.62405014038086, "training_acc": 72.0, "val_loss": 14.84353095293045, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.09326505661011, "training_acc": 72.0, "val_loss": 14.798322319984436, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.02256488800049, "training_acc": 72.0, "val_loss": 14.783316850662231, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58.965709924697876, "training_acc": 72.0, "val_loss": 14.769747853279114, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.21277403831482, "training_acc": 72.0, "val_loss": 14.770442247390747, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.86145806312561, "training_acc": 72.0, "val_loss": 14.75963145494461, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.86291193962097, "training_acc": 72.0, "val_loss": 14.770728349685669, "val_acc": 72.0}
{"epoch": 11, "training_loss": 58.78106236457825, "training_acc": 72.0, "val_loss": 14.717476069927216, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.72194719314575, "training_acc": 72.0, "val_loss": 14.685770869255066, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.643046617507935, "training_acc": 72.0, "val_loss": 14.64126706123352, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.390442848205566, "training_acc": 72.0, "val_loss": 14.595058560371399, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.335349559783936, "training_acc": 72.0, "val_loss": 14.604909718036652, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.259974002838135, "training_acc": 72.0, "val_loss": 14.509628713130951, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.46922016143799, "training_acc": 72.0, "val_loss": 14.581216871738434, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.27598166465759, "training_acc": 72.0, "val_loss": 14.536881446838379, "val_acc": 72.0}
{"epoch": 19, "training_loss": 57.819072008132935, "training_acc": 72.0, "val_loss": 14.412659406661987, "val_acc": 72.0}
{"epoch": 20, "training_loss": 57.52805781364441, "training_acc": 72.0, "val_loss": 14.389514923095703, "val_acc": 72.0}
{"epoch": 21, "training_loss": 57.28839898109436, "training_acc": 72.0, "val_loss": 14.231033623218536, "val_acc": 72.0}
{"epoch": 22, "training_loss": 56.70162916183472, "training_acc": 72.0, "val_loss": 14.100363850593567, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.34588170051575, "training_acc": 72.0, "val_loss": 14.048756659030914, "val_acc": 72.0}
{"epoch": 24, "training_loss": 56.58969187736511, "training_acc": 72.0, "val_loss": 14.028652012348175, "val_acc": 72.0}
{"epoch": 25, "training_loss": 56.299519300460815, "training_acc": 72.0, "val_loss": 14.15669471025467, "val_acc": 68.0}
{"epoch": 26, "training_loss": 57.04942440986633, "training_acc": 72.0, "val_loss": 13.809193670749664, "val_acc": 76.0}
{"epoch": 27, "training_loss": 55.112536668777466, "training_acc": 72.0, "val_loss": 13.729602098464966, "val_acc": 72.0}
{"epoch": 28, "training_loss": 54.598498582839966, "training_acc": 72.0, "val_loss": 13.668888807296753, "val_acc": 68.0}
{"epoch": 29, "training_loss": 58.38780951499939, "training_acc": 72.0, "val_loss": 13.849203288555145, "val_acc": 76.0}
{"epoch": 30, "training_loss": 55.61191415786743, "training_acc": 72.0, "val_loss": 13.989323377609253, "val_acc": 72.0}
{"epoch": 31, "training_loss": 56.300159215927124, "training_acc": 72.0, "val_loss": 13.99172842502594, "val_acc": 72.0}
{"epoch": 32, "training_loss": 55.52755641937256, "training_acc": 72.0, "val_loss": 13.597968220710754, "val_acc": 68.0}
{"epoch": 33, "training_loss": 54.353161096572876, "training_acc": 72.0, "val_loss": 13.522979617118835, "val_acc": 76.0}
{"epoch": 34, "training_loss": 54.49501299858093, "training_acc": 72.0, "val_loss": 13.651013374328613, "val_acc": 76.0}
{"epoch": 35, "training_loss": 53.49533271789551, "training_acc": 72.0, "val_loss": 14.13642168045044, "val_acc": 72.0}
{"epoch": 36, "training_loss": 56.671489000320435, "training_acc": 72.0, "val_loss": 13.49845677614212, "val_acc": 68.0}
{"epoch": 37, "training_loss": 53.99581265449524, "training_acc": 72.0, "val_loss": 13.980647921562195, "val_acc": 72.0}
{"epoch": 38, "training_loss": 55.007386922836304, "training_acc": 72.0, "val_loss": 13.383987545967102, "val_acc": 68.0}
{"epoch": 39, "training_loss": 53.940818071365356, "training_acc": 72.0, "val_loss": 13.173989951610565, "val_acc": 76.0}
{"epoch": 40, "training_loss": 53.72823143005371, "training_acc": 72.0, "val_loss": 13.151596486568451, "val_acc": 76.0}
{"epoch": 41, "training_loss": 51.866718769073486, "training_acc": 72.0, "val_loss": 13.172322511672974, "val_acc": 72.0}
{"epoch": 42, "training_loss": 52.73275876045227, "training_acc": 72.0, "val_loss": 13.215942680835724, "val_acc": 68.0}
{"epoch": 43, "training_loss": 54.78193259239197, "training_acc": 72.0, "val_loss": 13.22578638792038, "val_acc": 72.0}
{"epoch": 44, "training_loss": 53.29201865196228, "training_acc": 72.0, "val_loss": 13.31106573343277, "val_acc": 72.0}
{"epoch": 45, "training_loss": 52.522740602493286, "training_acc": 72.0, "val_loss": 13.368657231330872, "val_acc": 72.0}
{"epoch": 46, "training_loss": 52.177592039108276, "training_acc": 72.0, "val_loss": 12.94107586145401, "val_acc": 72.0}
{"epoch": 47, "training_loss": 51.27891027927399, "training_acc": 77.0, "val_loss": 13.10577243566513, "val_acc": 68.0}
{"epoch": 48, "training_loss": 51.67451310157776, "training_acc": 73.0, "val_loss": 12.871615588665009, "val_acc": 76.0}
{"epoch": 49, "training_loss": 50.47010159492493, "training_acc": 77.0, "val_loss": 12.85090297460556, "val_acc": 72.0}
{"epoch": 50, "training_loss": 51.26409959793091, "training_acc": 78.0, "val_loss": 12.684652209281921, "val_acc": 76.0}
{"epoch": 51, "training_loss": 48.673234939575195, "training_acc": 82.0, "val_loss": 12.78478354215622, "val_acc": 72.0}
{"epoch": 52, "training_loss": 51.52172088623047, "training_acc": 76.0, "val_loss": 12.632288038730621, "val_acc": 76.0}
{"epoch": 53, "training_loss": 49.814799785614014, "training_acc": 76.0, "val_loss": 12.655198574066162, "val_acc": 72.0}
{"epoch": 54, "training_loss": 49.100321650505066, "training_acc": 81.0, "val_loss": 12.64083981513977, "val_acc": 72.0}
{"epoch": 55, "training_loss": 48.60783886909485, "training_acc": 74.0, "val_loss": 12.70790696144104, "val_acc": 76.0}
{"epoch": 56, "training_loss": 53.639686822891235, "training_acc": 74.0, "val_loss": 13.127708435058594, "val_acc": 72.0}
{"epoch": 57, "training_loss": 53.49154281616211, "training_acc": 72.0, "val_loss": 13.770759105682373, "val_acc": 72.0}
{"epoch": 58, "training_loss": 54.841357469558716, "training_acc": 72.0, "val_loss": 13.39174211025238, "val_acc": 76.0}
{"epoch": 59, "training_loss": 54.445464849472046, "training_acc": 72.0, "val_loss": 13.167962431907654, "val_acc": 76.0}
{"epoch": 60, "training_loss": 53.77147030830383, "training_acc": 72.0, "val_loss": 13.087831437587738, "val_acc": 72.0}
{"epoch": 61, "training_loss": 51.27493238449097, "training_acc": 72.0, "val_loss": 13.040180504322052, "val_acc": 72.0}
