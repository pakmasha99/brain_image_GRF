"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.58439683914185, "training_acc": 42.0, "val_loss": 15.24374634027481, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.655858755111694, "training_acc": 72.0, "val_loss": 15.146774053573608, "val_acc": 72.0}
{"epoch": 2, "training_loss": 61.285911321640015, "training_acc": 72.0, "val_loss": 15.044644474983215, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.97059631347656, "training_acc": 72.0, "val_loss": 14.826686680316925, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.27631688117981, "training_acc": 72.0, "val_loss": 14.912495017051697, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.61858296394348, "training_acc": 72.0, "val_loss": 14.826816320419312, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.418195486068726, "training_acc": 72.0, "val_loss": 15.030203759670258, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.282527804374695, "training_acc": 72.0, "val_loss": 14.916306734085083, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.5819878578186, "training_acc": 72.0, "val_loss": 14.826813340187073, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.990333557128906, "training_acc": 72.0, "val_loss": 14.861045777797699, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.40084195137024, "training_acc": 72.0, "val_loss": 14.823928475379944, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.30476117134094, "training_acc": 72.0, "val_loss": 14.845995604991913, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.39872097969055, "training_acc": 72.0, "val_loss": 14.838521182537079, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.830671548843384, "training_acc": 72.0, "val_loss": 14.828948676586151, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.586602210998535, "training_acc": 72.0, "val_loss": 14.858132600784302, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.391865968704224, "training_acc": 72.0, "val_loss": 14.82488363981247, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.20936560630798, "training_acc": 72.0, "val_loss": 14.910520613193512, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.16652226448059, "training_acc": 72.0, "val_loss": 14.902745187282562, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.13169574737549, "training_acc": 72.0, "val_loss": 14.850765466690063, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.49940466880798, "training_acc": 72.0, "val_loss": 14.867836236953735, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.47136211395264, "training_acc": 72.0, "val_loss": 14.871340990066528, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.611618518829346, "training_acc": 72.0, "val_loss": 14.827573299407959, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.34204316139221, "training_acc": 72.0, "val_loss": 14.896726608276367, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.71635556221008, "training_acc": 72.0, "val_loss": 14.886793494224548, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.46146249771118, "training_acc": 72.0, "val_loss": 14.828921854496002, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.48334455490112, "training_acc": 72.0, "val_loss": 14.889433979988098, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.567532539367676, "training_acc": 72.0, "val_loss": 14.83365148305893, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.3249933719635, "training_acc": 72.0, "val_loss": 14.826886355876923, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.40107011795044, "training_acc": 72.0, "val_loss": 14.832937717437744, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.316558599472046, "training_acc": 72.0, "val_loss": 14.826126396656036, "val_acc": 72.0}
