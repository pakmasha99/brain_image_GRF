"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.2969102859497, "training_acc": 46.0, "val_loss": 15.543977916240692, "val_acc": 72.0}
{"epoch": 1, "training_loss": 63.92084217071533, "training_acc": 72.0, "val_loss": 15.400025248527527, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.40746831893921, "training_acc": 72.0, "val_loss": 14.953452348709106, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.065343618392944, "training_acc": 72.0, "val_loss": 15.050873160362244, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.15241312980652, "training_acc": 72.0, "val_loss": 14.869898557662964, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.30718207359314, "training_acc": 72.0, "val_loss": 14.858929812908173, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.0860857963562, "training_acc": 72.0, "val_loss": 14.834509789943695, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.39041543006897, "training_acc": 72.0, "val_loss": 14.921967685222626, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.669551849365234, "training_acc": 72.0, "val_loss": 14.850486814975739, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.39970803260803, "training_acc": 72.0, "val_loss": 14.832444489002228, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.29987907409668, "training_acc": 72.0, "val_loss": 14.923146367073059, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.70992708206177, "training_acc": 72.0, "val_loss": 14.841164648532867, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.362140417099, "training_acc": 72.0, "val_loss": 14.875344932079315, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.51509189605713, "training_acc": 72.0, "val_loss": 14.846096932888031, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.345664501190186, "training_acc": 72.0, "val_loss": 14.835643768310547, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.360782623291016, "training_acc": 72.0, "val_loss": 14.846351742744446, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.43844676017761, "training_acc": 72.0, "val_loss": 14.82514888048172, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.558258056640625, "training_acc": 72.0, "val_loss": 14.892897009849548, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.576824426651, "training_acc": 72.0, "val_loss": 14.824031293392181, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.271838903427124, "training_acc": 72.0, "val_loss": 14.84488993883133, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.39705181121826, "training_acc": 72.0, "val_loss": 14.848725497722626, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.40722966194153, "training_acc": 72.0, "val_loss": 14.82769101858139, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.28345799446106, "training_acc": 72.0, "val_loss": 14.921917021274567, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.87820887565613, "training_acc": 72.0, "val_loss": 14.838311076164246, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.35559582710266, "training_acc": 72.0, "val_loss": 14.947311580181122, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.81400227546692, "training_acc": 72.0, "val_loss": 14.917224645614624, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.8140652179718, "training_acc": 72.0, "val_loss": 14.828267693519592, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.389060258865356, "training_acc": 72.0, "val_loss": 14.825674891471863, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.446282625198364, "training_acc": 72.0, "val_loss": 14.824216067790985, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.28235602378845, "training_acc": 72.0, "val_loss": 14.842173457145691, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.460545778274536, "training_acc": 72.0, "val_loss": 14.834672212600708, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.284584283828735, "training_acc": 72.0, "val_loss": 14.852546155452728, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.52492582798004, "training_acc": 72.0, "val_loss": 14.958198368549347, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.92801022529602, "training_acc": 72.0, "val_loss": 14.965516328811646, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.19754433631897, "training_acc": 72.0, "val_loss": 14.832352101802826, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.786041259765625, "training_acc": 72.0, "val_loss": 15.400981903076172, "val_acc": 28.0}
{"epoch": 36, "training_loss": 61.444251537323, "training_acc": 72.0, "val_loss": 14.929002523422241, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.30845665931702, "training_acc": 72.0, "val_loss": 15.030121803283691, "val_acc": 72.0}
