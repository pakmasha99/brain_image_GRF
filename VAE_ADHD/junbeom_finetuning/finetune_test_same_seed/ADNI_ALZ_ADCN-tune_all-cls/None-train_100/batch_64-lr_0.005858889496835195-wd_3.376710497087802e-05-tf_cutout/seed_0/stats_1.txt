"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 304.31232833862305, "training_acc": 72.0, "val_loss": 39450279936000.0, "val_acc": 72.0}
{"epoch": 1, "training_loss": 104823953294963.61, "training_acc": 72.0, "val_loss": 1137.370777130127, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3153.2884483337402, "training_acc": 46.0, "val_loss": 4811.25373840332, "val_acc": 28.0}
{"epoch": 3, "training_loss": 14053.440948486328, "training_acc": 28.0, "val_loss": 560.8387470245361, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2059.4513092041016, "training_acc": 72.0, "val_loss": 271.18310928344727, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1334.5433502197266, "training_acc": 54.0, "val_loss": 18.089821934700012, "val_acc": 72.0}
{"epoch": 6, "training_loss": 464.9834175109863, "training_acc": 52.0, "val_loss": 406.4990043640137, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1546.9328727722168, "training_acc": 72.0, "val_loss": 145.91100215911865, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2878.4841918945312, "training_acc": 54.0, "val_loss": 119.727623462677, "val_acc": 72.0}
{"epoch": 9, "training_loss": 409.3448963165283, "training_acc": 72.0, "val_loss": 647.5130558013916, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1982.6621475219727, "training_acc": 42.0, "val_loss": 221.5904712677002, "val_acc": 72.0}
{"epoch": 11, "training_loss": 726.7972049713135, "training_acc": 72.0, "val_loss": 15.146228671073914, "val_acc": 72.0}
{"epoch": 12, "training_loss": 497.0504035949707, "training_acc": 56.0, "val_loss": 38.48520815372467, "val_acc": 28.0}
{"epoch": 13, "training_loss": 358.09095191955566, "training_acc": 44.0, "val_loss": 135.53926944732666, "val_acc": 72.0}
{"epoch": 14, "training_loss": 457.5947036743164, "training_acc": 72.0, "val_loss": 17.178016901016235, "val_acc": 28.0}
{"epoch": 15, "training_loss": 60.55065584182739, "training_acc": 67.0, "val_loss": 29.324230551719666, "val_acc": 72.0}
{"epoch": 16, "training_loss": 563.5665702819824, "training_acc": 58.0, "val_loss": 14.950145781040192, "val_acc": 72.0}
{"epoch": 17, "training_loss": 77.1656641960144, "training_acc": 72.0, "val_loss": 47.29849100112915, "val_acc": 72.0}
{"epoch": 18, "training_loss": 152.96229457855225, "training_acc": 72.0, "val_loss": 56.45650029182434, "val_acc": 28.0}
{"epoch": 19, "training_loss": 158.78314685821533, "training_acc": 46.0, "val_loss": 20.951198041439056, "val_acc": 72.0}
{"epoch": 20, "training_loss": 78.53823733329773, "training_acc": 72.0, "val_loss": 14.640593528747559, "val_acc": 72.0}
{"epoch": 21, "training_loss": 76.52157497406006, "training_acc": 52.0, "val_loss": 16.63772016763687, "val_acc": 72.0}
{"epoch": 22, "training_loss": 70.69302868843079, "training_acc": 72.0, "val_loss": 15.483245253562927, "val_acc": 72.0}
{"epoch": 23, "training_loss": 68.93591666221619, "training_acc": 72.0, "val_loss": 22.531335055828094, "val_acc": 28.0}
{"epoch": 24, "training_loss": 83.66189122200012, "training_acc": 28.0, "val_loss": 18.02985370159149, "val_acc": 72.0}
{"epoch": 25, "training_loss": 68.85807466506958, "training_acc": 72.0, "val_loss": 14.73684310913086, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.28230023384094, "training_acc": 72.0, "val_loss": 15.14967530965805, "val_acc": 72.0}
{"epoch": 27, "training_loss": 60.3474383354187, "training_acc": 72.0, "val_loss": 15.019060671329498, "val_acc": 72.0}
{"epoch": 28, "training_loss": 61.3770010471344, "training_acc": 72.0, "val_loss": 14.690515398979187, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.386390209198, "training_acc": 72.0, "val_loss": 15.190871059894562, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.95864295959473, "training_acc": 72.0, "val_loss": 14.738699793815613, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.32190775871277, "training_acc": 72.0, "val_loss": 15.448613464832306, "val_acc": 28.0}
{"epoch": 32, "training_loss": 61.88624906539917, "training_acc": 72.0, "val_loss": 14.731091260910034, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.36817240715027, "training_acc": 72.0, "val_loss": 15.0093212723732, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.45161175727844, "training_acc": 72.0, "val_loss": 14.76466953754425, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.56591439247131, "training_acc": 72.0, "val_loss": 14.855511486530304, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.74465608596802, "training_acc": 72.0, "val_loss": 14.709201455116272, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.76175045967102, "training_acc": 72.0, "val_loss": 14.730758965015411, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.31503677368164, "training_acc": 72.0, "val_loss": 15.287469327449799, "val_acc": 40.0}
{"epoch": 39, "training_loss": 61.06135559082031, "training_acc": 72.0, "val_loss": 14.72877711057663, "val_acc": 72.0}
