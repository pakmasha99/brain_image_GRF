"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 329.39563369750977, "training_acc": 40.0, "val_loss": 99731929600.0, "val_acc": 72.0}
{"epoch": 1, "training_loss": 224368690538.2439, "training_acc": 72.0, "val_loss": 98.39601516723633, "val_acc": 72.0}
{"epoch": 2, "training_loss": 35325.591247558594, "training_acc": 60.0, "val_loss": 26683.70361328125, "val_acc": 28.0}
{"epoch": 3, "training_loss": 75113.48431396484, "training_acc": 28.0, "val_loss": 3582.1121215820312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 12126.351913452148, "training_acc": 72.0, "val_loss": 1988.6703491210938, "val_acc": 28.0}
{"epoch": 5, "training_loss": 6353.284034729004, "training_acc": 34.0, "val_loss": 19.44211721420288, "val_acc": 28.0}
{"epoch": 6, "training_loss": 408.54321670532227, "training_acc": 54.0, "val_loss": 34.96142029762268, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2225.7310333251953, "training_acc": 56.0, "val_loss": 247.9534149169922, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1028.1010284423828, "training_acc": 48.0, "val_loss": 430.8036804199219, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1429.2799034118652, "training_acc": 72.0, "val_loss": 160.88194847106934, "val_acc": 72.0}
{"epoch": 10, "training_loss": 364.9301152229309, "training_acc": 64.0, "val_loss": 73.13675284385681, "val_acc": 72.0}
{"epoch": 11, "training_loss": 266.2085018157959, "training_acc": 72.0, "val_loss": 291.9400930404663, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1075.5843544006348, "training_acc": 38.0, "val_loss": 37.83280849456787, "val_acc": 72.0}
{"epoch": 13, "training_loss": 285.2902317047119, "training_acc": 58.0, "val_loss": 104.47264909744263, "val_acc": 72.0}
{"epoch": 14, "training_loss": 628.2923049926758, "training_acc": 72.0, "val_loss": 104.67039346694946, "val_acc": 72.0}
{"epoch": 15, "training_loss": 307.5446548461914, "training_acc": 53.0, "val_loss": 20.211400091648102, "val_acc": 28.0}
{"epoch": 16, "training_loss": 154.5561113357544, "training_acc": 48.0, "val_loss": 38.68350386619568, "val_acc": 72.0}
{"epoch": 17, "training_loss": 429.48284912109375, "training_acc": 60.0, "val_loss": 35.9230101108551, "val_acc": 72.0}
{"epoch": 18, "training_loss": 156.26908922195435, "training_acc": 72.0, "val_loss": 18.706807494163513, "val_acc": 72.0}
{"epoch": 19, "training_loss": 256.02961349487305, "training_acc": 48.0, "val_loss": 22.096143662929535, "val_acc": 72.0}
{"epoch": 20, "training_loss": 124.00219011306763, "training_acc": 72.0, "val_loss": 35.36808788776398, "val_acc": 72.0}
{"epoch": 21, "training_loss": 105.67221260070801, "training_acc": 72.0, "val_loss": 56.99917674064636, "val_acc": 28.0}
{"epoch": 22, "training_loss": 175.15633416175842, "training_acc": 40.0, "val_loss": 21.1224764585495, "val_acc": 72.0}
{"epoch": 23, "training_loss": 82.0193076133728, "training_acc": 72.0, "val_loss": 15.669041872024536, "val_acc": 72.0}
{"epoch": 24, "training_loss": 63.66230893135071, "training_acc": 72.0, "val_loss": 16.903764009475708, "val_acc": 28.0}
{"epoch": 25, "training_loss": 64.87173700332642, "training_acc": 66.0, "val_loss": 16.320106387138367, "val_acc": 72.0}
{"epoch": 26, "training_loss": 65.35770916938782, "training_acc": 72.0, "val_loss": 14.774638414382935, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.11239171028137, "training_acc": 73.0, "val_loss": 15.387222170829773, "val_acc": 40.0}
{"epoch": 28, "training_loss": 58.8086678981781, "training_acc": 72.0, "val_loss": 16.88520908355713, "val_acc": 72.0}
{"epoch": 29, "training_loss": 69.73738932609558, "training_acc": 72.0, "val_loss": 15.329587459564209, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.488014698028564, "training_acc": 72.0, "val_loss": 18.15667301416397, "val_acc": 28.0}
{"epoch": 31, "training_loss": 70.75651097297668, "training_acc": 42.0, "val_loss": 14.849802851676941, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.683542251586914, "training_acc": 72.0, "val_loss": 16.869251430034637, "val_acc": 72.0}
{"epoch": 33, "training_loss": 65.66582179069519, "training_acc": 72.0, "val_loss": 14.810793101787567, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.743937492370605, "training_acc": 72.0, "val_loss": 16.21445268392563, "val_acc": 28.0}
{"epoch": 35, "training_loss": 64.68750739097595, "training_acc": 71.0, "val_loss": 14.827363193035126, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.408106327056885, "training_acc": 72.0, "val_loss": 15.255841612815857, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.49132585525513, "training_acc": 72.0, "val_loss": 14.865364134311676, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.734198331832886, "training_acc": 72.0, "val_loss": 15.039262175559998, "val_acc": 72.0}
{"epoch": 39, "training_loss": 60.42264986038208, "training_acc": 72.0, "val_loss": 14.837612211704254, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.783308267593384, "training_acc": 72.0, "val_loss": 14.84985202550888, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.40705966949463, "training_acc": 72.0, "val_loss": 14.88063633441925, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.22823452949524, "training_acc": 72.0, "val_loss": 14.865681529045105, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.88937306404114, "training_acc": 72.0, "val_loss": 15.045052766799927, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.56397080421448, "training_acc": 72.0, "val_loss": 14.885635673999786, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.54059672355652, "training_acc": 72.0, "val_loss": 14.864575862884521, "val_acc": 72.0}
