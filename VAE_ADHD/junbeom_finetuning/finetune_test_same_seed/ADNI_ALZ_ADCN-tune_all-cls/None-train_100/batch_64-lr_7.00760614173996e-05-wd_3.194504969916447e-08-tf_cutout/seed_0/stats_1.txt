"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 64.95842361450195, "training_acc": 71.0, "val_loss": 15.585348010063171, "val_acc": 28.0}
{"epoch": 1, "training_loss": 64.27710270881653, "training_acc": 72.0, "val_loss": 15.007355809211731, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.2496223449707, "training_acc": 72.0, "val_loss": 14.944124221801758, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.941977977752686, "training_acc": 72.0, "val_loss": 14.879085123538971, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.471764087677, "training_acc": 72.0, "val_loss": 14.878162741661072, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.60816168785095, "training_acc": 72.0, "val_loss": 14.91641253232956, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.82477784156799, "training_acc": 72.0, "val_loss": 14.786644279956818, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.04191613197327, "training_acc": 72.0, "val_loss": 14.743620157241821, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.86092162132263, "training_acc": 72.0, "val_loss": 14.69971388578415, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.43050837516785, "training_acc": 72.0, "val_loss": 14.709101617336273, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.666499376297, "training_acc": 72.0, "val_loss": 14.595174789428711, "val_acc": 72.0}
{"epoch": 11, "training_loss": 58.54004406929016, "training_acc": 72.0, "val_loss": 14.730596542358398, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.51579570770264, "training_acc": 72.0, "val_loss": 14.575880765914917, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.526925802230835, "training_acc": 72.0, "val_loss": 14.481040835380554, "val_acc": 72.0}
{"epoch": 14, "training_loss": 56.57406568527222, "training_acc": 72.0, "val_loss": 14.769023656845093, "val_acc": 64.0}
{"epoch": 15, "training_loss": 58.087226152420044, "training_acc": 72.0, "val_loss": 14.378105103969574, "val_acc": 72.0}
{"epoch": 16, "training_loss": 56.54420495033264, "training_acc": 72.0, "val_loss": 14.55611139535904, "val_acc": 72.0}
{"epoch": 17, "training_loss": 56.3020761013031, "training_acc": 72.0, "val_loss": 14.610540866851807, "val_acc": 56.0}
{"epoch": 18, "training_loss": 56.60230326652527, "training_acc": 72.0, "val_loss": 14.458689093589783, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.88701820373535, "training_acc": 72.0, "val_loss": 14.256623387336731, "val_acc": 64.0}
{"epoch": 20, "training_loss": 55.55777144432068, "training_acc": 72.0, "val_loss": 14.314004778862, "val_acc": 72.0}
{"epoch": 21, "training_loss": 55.63383412361145, "training_acc": 72.0, "val_loss": 14.234337210655212, "val_acc": 68.0}
{"epoch": 22, "training_loss": 54.921029567718506, "training_acc": 73.0, "val_loss": 14.285105466842651, "val_acc": 60.0}
{"epoch": 23, "training_loss": 51.96378946304321, "training_acc": 74.0, "val_loss": 17.47209131717682, "val_acc": 72.0}
{"epoch": 24, "training_loss": 70.74159860610962, "training_acc": 72.0, "val_loss": 15.045996010303497, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.21608519554138, "training_acc": 72.0, "val_loss": 16.07784479856491, "val_acc": 40.0}
{"epoch": 26, "training_loss": 63.70928883552551, "training_acc": 69.0, "val_loss": 15.601103007793427, "val_acc": 40.0}
{"epoch": 27, "training_loss": 61.15867757797241, "training_acc": 72.0, "val_loss": 14.855290949344635, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.648727893829346, "training_acc": 72.0, "val_loss": 14.733467996120453, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.916290283203125, "training_acc": 72.0, "val_loss": 14.801368117332458, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.85287094116211, "training_acc": 72.0, "val_loss": 14.817897975444794, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.96016299724579, "training_acc": 72.0, "val_loss": 14.784778654575348, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.53874373435974, "training_acc": 72.0, "val_loss": 14.750568568706512, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.37033128738403, "training_acc": 72.0, "val_loss": 14.693650603294373, "val_acc": 72.0}
{"epoch": 34, "training_loss": 57.94809007644653, "training_acc": 72.0, "val_loss": 14.627684652805328, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.716357469558716, "training_acc": 72.0, "val_loss": 14.601992070674896, "val_acc": 72.0}
{"epoch": 36, "training_loss": 57.50501894950867, "training_acc": 72.0, "val_loss": 14.55257534980774, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.247018814086914, "training_acc": 72.0, "val_loss": 14.594142138957977, "val_acc": 72.0}
{"epoch": 38, "training_loss": 57.04846119880676, "training_acc": 72.0, "val_loss": 14.722299575805664, "val_acc": 72.0}
{"epoch": 39, "training_loss": 56.60721564292908, "training_acc": 72.0, "val_loss": 14.480182528495789, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.71388220787048, "training_acc": 72.0, "val_loss": 14.404413104057312, "val_acc": 72.0}
