"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.73023271560669, "training_acc": 71.0, "val_loss": 18.06512027978897, "val_acc": 72.0}
{"epoch": 1, "training_loss": 114.5814847946167, "training_acc": 52.0, "val_loss": 16.100993752479553, "val_acc": 28.0}
{"epoch": 2, "training_loss": 64.64651823043823, "training_acc": 72.0, "val_loss": 14.962095022201538, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.47051167488098, "training_acc": 72.0, "val_loss": 14.976854622364044, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.934932470321655, "training_acc": 72.0, "val_loss": 15.116702020168304, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.015708923339844, "training_acc": 72.0, "val_loss": 14.910317957401276, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.67719554901123, "training_acc": 72.0, "val_loss": 15.194092690944672, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.72541904449463, "training_acc": 72.0, "val_loss": 14.933542907238007, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.60461735725403, "training_acc": 72.0, "val_loss": 14.973600208759308, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.042259216308594, "training_acc": 72.0, "val_loss": 14.988844096660614, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.69240665435791, "training_acc": 72.0, "val_loss": 14.909431338310242, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.53732681274414, "training_acc": 72.0, "val_loss": 14.935441315174103, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.576183795928955, "training_acc": 72.0, "val_loss": 14.84929472208023, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.24186718463898, "training_acc": 72.0, "val_loss": 14.889039099216461, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.80162811279297, "training_acc": 72.0, "val_loss": 14.925654232501984, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.88895535469055, "training_acc": 72.0, "val_loss": 14.89407867193222, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.54774069786072, "training_acc": 72.0, "val_loss": 15.1121586561203, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.40704011917114, "training_acc": 72.0, "val_loss": 15.000241994857788, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.79979467391968, "training_acc": 72.0, "val_loss": 14.824022352695465, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.27986216545105, "training_acc": 72.0, "val_loss": 14.87957090139389, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.695900201797485, "training_acc": 72.0, "val_loss": 14.82505202293396, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.27601218223572, "training_acc": 72.0, "val_loss": 14.851567149162292, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.281338691711426, "training_acc": 72.0, "val_loss": 14.84798938035965, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.188843727111816, "training_acc": 72.0, "val_loss": 14.78482037782669, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.130530834198, "training_acc": 72.0, "val_loss": 14.786562323570251, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.063992500305176, "training_acc": 72.0, "val_loss": 14.739339053630829, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.86247944831848, "training_acc": 72.0, "val_loss": 14.768481254577637, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.922906160354614, "training_acc": 72.0, "val_loss": 14.672203361988068, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.92266082763672, "training_acc": 72.0, "val_loss": 14.801749587059021, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.66382431983948, "training_acc": 72.0, "val_loss": 14.632019400596619, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.26124548912048, "training_acc": 72.0, "val_loss": 14.677868783473969, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.16978693008423, "training_acc": 72.0, "val_loss": 14.619877934455872, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.00648093223572, "training_acc": 72.0, "val_loss": 14.437034726142883, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.46262454986572, "training_acc": 72.0, "val_loss": 14.437659084796906, "val_acc": 72.0}
{"epoch": 34, "training_loss": 57.80879497528076, "training_acc": 72.0, "val_loss": 14.471770823001862, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.41733193397522, "training_acc": 72.0, "val_loss": 14.270010590553284, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.35234832763672, "training_acc": 72.0, "val_loss": 14.1618013381958, "val_acc": 72.0}
{"epoch": 37, "training_loss": 56.191497802734375, "training_acc": 72.0, "val_loss": 14.154990017414093, "val_acc": 68.0}
{"epoch": 38, "training_loss": 55.30162835121155, "training_acc": 72.0, "val_loss": 15.431857109069824, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.478737354278564, "training_acc": 72.0, "val_loss": 14.0001580119133, "val_acc": 76.0}
{"epoch": 40, "training_loss": 55.90982174873352, "training_acc": 72.0, "val_loss": 14.158450067043304, "val_acc": 76.0}
{"epoch": 41, "training_loss": 57.939332008361816, "training_acc": 72.0, "val_loss": 14.39887136220932, "val_acc": 64.0}
{"epoch": 42, "training_loss": 56.7925922870636, "training_acc": 73.0, "val_loss": 13.88566941022873, "val_acc": 76.0}
{"epoch": 43, "training_loss": 54.54949629306793, "training_acc": 72.0, "val_loss": 16.470646858215332, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.88601458072662, "training_acc": 72.0, "val_loss": 13.986639678478241, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.0339252948761, "training_acc": 74.0, "val_loss": 13.99172991514206, "val_acc": 76.0}
{"epoch": 46, "training_loss": 52.93446934223175, "training_acc": 72.0, "val_loss": 14.124546945095062, "val_acc": 76.0}
{"epoch": 47, "training_loss": 53.361868143081665, "training_acc": 72.0, "val_loss": 16.997617483139038, "val_acc": 36.0}
{"epoch": 48, "training_loss": 63.221009492874146, "training_acc": 61.0, "val_loss": 16.85628443956375, "val_acc": 72.0}
{"epoch": 49, "training_loss": 63.81428825855255, "training_acc": 72.0, "val_loss": 15.730667114257812, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.84293341636658, "training_acc": 72.0, "val_loss": 14.47732299566269, "val_acc": 72.0}
{"epoch": 51, "training_loss": 57.17237091064453, "training_acc": 72.0, "val_loss": 14.635677635669708, "val_acc": 76.0}
{"epoch": 52, "training_loss": 58.44420075416565, "training_acc": 72.0, "val_loss": 14.387364685535431, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.052247524261475, "training_acc": 72.0, "val_loss": 14.242865145206451, "val_acc": 72.0}
{"epoch": 54, "training_loss": 56.25273132324219, "training_acc": 72.0, "val_loss": 14.048680663108826, "val_acc": 72.0}
{"epoch": 55, "training_loss": 58.006218671798706, "training_acc": 72.0, "val_loss": 14.919514954090118, "val_acc": 52.0}
{"epoch": 56, "training_loss": 60.094722509384155, "training_acc": 72.0, "val_loss": 15.07481187582016, "val_acc": 52.0}
{"epoch": 57, "training_loss": 56.78197121620178, "training_acc": 72.0, "val_loss": 16.796424984931946, "val_acc": 72.0}
{"epoch": 58, "training_loss": 61.09398627281189, "training_acc": 72.0, "val_loss": 14.210951328277588, "val_acc": 72.0}
{"epoch": 59, "training_loss": 57.59016251564026, "training_acc": 72.0, "val_loss": 15.064619481563568, "val_acc": 56.0}
{"epoch": 60, "training_loss": 60.07974052429199, "training_acc": 72.0, "val_loss": 15.074853599071503, "val_acc": 68.0}
{"epoch": 61, "training_loss": 59.53062129020691, "training_acc": 72.0, "val_loss": 14.640997350215912, "val_acc": 72.0}
