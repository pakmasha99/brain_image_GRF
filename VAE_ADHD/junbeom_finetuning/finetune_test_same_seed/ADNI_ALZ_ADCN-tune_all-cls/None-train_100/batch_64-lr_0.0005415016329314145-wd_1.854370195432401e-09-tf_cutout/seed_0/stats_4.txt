"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 75.66950345039368, "training_acc": 54.0, "val_loss": 15.131095051765442, "val_acc": 72.0}
{"epoch": 1, "training_loss": 145.76867866516113, "training_acc": 54.0, "val_loss": 15.962226688861847, "val_acc": 28.0}
{"epoch": 2, "training_loss": 63.23573899269104, "training_acc": 72.0, "val_loss": 15.02889096736908, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.069254875183105, "training_acc": 72.0, "val_loss": 15.174812078475952, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.95188903808594, "training_acc": 72.0, "val_loss": 14.867456257343292, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.9091911315918, "training_acc": 72.0, "val_loss": 14.899343252182007, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.86282205581665, "training_acc": 72.0, "val_loss": 14.89146202802658, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.71921133995056, "training_acc": 72.0, "val_loss": 14.896062016487122, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.77315640449524, "training_acc": 72.0, "val_loss": 14.777740836143494, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.67638635635376, "training_acc": 72.0, "val_loss": 14.772821962833405, "val_acc": 72.0}
{"epoch": 10, "training_loss": 67.94473648071289, "training_acc": 72.0, "val_loss": 14.833305776119232, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.494300842285156, "training_acc": 72.0, "val_loss": 15.326760709285736, "val_acc": 68.0}
{"epoch": 12, "training_loss": 60.943819761276245, "training_acc": 72.0, "val_loss": 14.840589463710785, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.12454152107239, "training_acc": 72.0, "val_loss": 15.647928416728973, "val_acc": 72.0}
{"epoch": 14, "training_loss": 62.32382559776306, "training_acc": 72.0, "val_loss": 14.82742726802826, "val_acc": 72.0}
{"epoch": 15, "training_loss": 60.08894681930542, "training_acc": 72.0, "val_loss": 14.978745579719543, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.96091103553772, "training_acc": 72.0, "val_loss": 14.842256903648376, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.82681894302368, "training_acc": 72.0, "val_loss": 14.817492663860321, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.62250876426697, "training_acc": 72.0, "val_loss": 14.792223274707794, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.28196048736572, "training_acc": 72.0, "val_loss": 14.834752678871155, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.57514309883118, "training_acc": 72.0, "val_loss": 14.940392971038818, "val_acc": 72.0}
{"epoch": 21, "training_loss": 60.109172344207764, "training_acc": 72.0, "val_loss": 14.865551888942719, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.540847063064575, "training_acc": 72.0, "val_loss": 14.80417549610138, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.44914722442627, "training_acc": 72.0, "val_loss": 14.762291312217712, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.65553617477417, "training_acc": 72.0, "val_loss": 14.75633829832077, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.38760304450989, "training_acc": 72.0, "val_loss": 14.791199564933777, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.257957220077515, "training_acc": 72.0, "val_loss": 14.776736497879028, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.16170525550842, "training_acc": 72.0, "val_loss": 14.747820794582367, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.000093936920166, "training_acc": 72.0, "val_loss": 14.73468691110611, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.002888441085815, "training_acc": 72.0, "val_loss": 14.760260283946991, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.02635192871094, "training_acc": 72.0, "val_loss": 14.699456095695496, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.818325996398926, "training_acc": 72.0, "val_loss": 14.720192551612854, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.90158462524414, "training_acc": 72.0, "val_loss": 14.666074514389038, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.81472730636597, "training_acc": 72.0, "val_loss": 14.686383306980133, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.5611686706543, "training_acc": 72.0, "val_loss": 14.872050285339355, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.18384528160095, "training_acc": 72.0, "val_loss": 14.563480019569397, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.04193925857544, "training_acc": 72.0, "val_loss": 14.778950810432434, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.70554971694946, "training_acc": 72.0, "val_loss": 14.610917866230011, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.234910011291504, "training_acc": 72.0, "val_loss": 14.668835699558258, "val_acc": 72.0}
{"epoch": 39, "training_loss": 57.38508439064026, "training_acc": 72.0, "val_loss": 14.745928347110748, "val_acc": 68.0}
{"epoch": 40, "training_loss": 58.901564598083496, "training_acc": 72.0, "val_loss": 14.441272616386414, "val_acc": 72.0}
{"epoch": 41, "training_loss": 56.61847996711731, "training_acc": 72.0, "val_loss": 14.173418283462524, "val_acc": 72.0}
{"epoch": 42, "training_loss": 56.066433906555176, "training_acc": 72.0, "val_loss": 16.40000343322754, "val_acc": 72.0}
{"epoch": 43, "training_loss": 66.62602281570435, "training_acc": 72.0, "val_loss": 15.52680879831314, "val_acc": 36.0}
{"epoch": 44, "training_loss": 61.046889781951904, "training_acc": 72.0, "val_loss": 14.47998732328415, "val_acc": 72.0}
{"epoch": 45, "training_loss": 57.80378270149231, "training_acc": 72.0, "val_loss": 15.045802295207977, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.54512333869934, "training_acc": 72.0, "val_loss": 14.656077325344086, "val_acc": 72.0}
{"epoch": 47, "training_loss": 58.39599967002869, "training_acc": 72.0, "val_loss": 14.656232297420502, "val_acc": 72.0}
{"epoch": 48, "training_loss": 58.51904296875, "training_acc": 72.0, "val_loss": 14.696989953517914, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.748775005340576, "training_acc": 72.0, "val_loss": 14.674648642539978, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.54559373855591, "training_acc": 72.0, "val_loss": 14.577685296535492, "val_acc": 72.0}
{"epoch": 51, "training_loss": 57.95055818557739, "training_acc": 72.0, "val_loss": 14.618661999702454, "val_acc": 72.0}
{"epoch": 52, "training_loss": 57.71444368362427, "training_acc": 72.0, "val_loss": 14.681307971477509, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.99452877044678, "training_acc": 72.0, "val_loss": 14.372964203357697, "val_acc": 72.0}
{"epoch": 54, "training_loss": 57.15497875213623, "training_acc": 72.0, "val_loss": 14.331136643886566, "val_acc": 72.0}
{"epoch": 55, "training_loss": 56.10142159461975, "training_acc": 72.0, "val_loss": 14.720603823661804, "val_acc": 72.0}
{"epoch": 56, "training_loss": 57.515880703926086, "training_acc": 72.0, "val_loss": 14.278867840766907, "val_acc": 72.0}
{"epoch": 57, "training_loss": 56.07993173599243, "training_acc": 72.0, "val_loss": 14.121398329734802, "val_acc": 76.0}
{"epoch": 58, "training_loss": 55.538541078567505, "training_acc": 72.0, "val_loss": 14.12803828716278, "val_acc": 72.0}
{"epoch": 59, "training_loss": 54.11419475078583, "training_acc": 72.0, "val_loss": 17.520710825920105, "val_acc": 72.0}
{"epoch": 60, "training_loss": 57.889920234680176, "training_acc": 72.0, "val_loss": 15.397289395332336, "val_acc": 40.0}
{"epoch": 61, "training_loss": 63.984066009521484, "training_acc": 72.0, "val_loss": 16.137637197971344, "val_acc": 28.0}
{"epoch": 62, "training_loss": 64.20131278038025, "training_acc": 72.0, "val_loss": 15.443611145019531, "val_acc": 28.0}
{"epoch": 63, "training_loss": 62.420246601104736, "training_acc": 72.0, "val_loss": 14.829638600349426, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.250168561935425, "training_acc": 72.0, "val_loss": 14.88138884305954, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.69998097419739, "training_acc": 72.0, "val_loss": 14.823415875434875, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.16245198249817, "training_acc": 72.0, "val_loss": 14.689180254936218, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.12713146209717, "training_acc": 72.0, "val_loss": 14.71833884716034, "val_acc": 72.0}
{"epoch": 68, "training_loss": 58.86616492271423, "training_acc": 72.0, "val_loss": 14.625369012355804, "val_acc": 72.0}
{"epoch": 69, "training_loss": 58.37424063682556, "training_acc": 72.0, "val_loss": 14.650586247444153, "val_acc": 72.0}
{"epoch": 70, "training_loss": 58.43840670585632, "training_acc": 72.0, "val_loss": 14.618104696273804, "val_acc": 72.0}
{"epoch": 71, "training_loss": 58.99529051780701, "training_acc": 72.0, "val_loss": 14.488066732883453, "val_acc": 72.0}
{"epoch": 72, "training_loss": 57.62934970855713, "training_acc": 72.0, "val_loss": 14.519475400447845, "val_acc": 72.0}
{"epoch": 73, "training_loss": 57.54241871833801, "training_acc": 72.0, "val_loss": 14.332324266433716, "val_acc": 72.0}
{"epoch": 74, "training_loss": 56.95347261428833, "training_acc": 72.0, "val_loss": 14.245830476284027, "val_acc": 72.0}
{"epoch": 75, "training_loss": 56.93360710144043, "training_acc": 72.0, "val_loss": 14.316543936729431, "val_acc": 72.0}
{"epoch": 76, "training_loss": 55.47671627998352, "training_acc": 72.0, "val_loss": 13.965429365634918, "val_acc": 72.0}
{"epoch": 77, "training_loss": 55.04983162879944, "training_acc": 72.0, "val_loss": 14.441947638988495, "val_acc": 52.0}
{"epoch": 78, "training_loss": 59.34442901611328, "training_acc": 72.0, "val_loss": 14.7478848695755, "val_acc": 48.0}
{"epoch": 79, "training_loss": 60.86463785171509, "training_acc": 72.0, "val_loss": 14.051716029644012, "val_acc": 72.0}
{"epoch": 80, "training_loss": 57.065833568573, "training_acc": 72.0, "val_loss": 13.899509608745575, "val_acc": 72.0}
{"epoch": 81, "training_loss": 57.391724824905396, "training_acc": 72.0, "val_loss": 14.658941328525543, "val_acc": 72.0}
{"epoch": 82, "training_loss": 59.135971784591675, "training_acc": 72.0, "val_loss": 14.1668900847435, "val_acc": 72.0}
{"epoch": 83, "training_loss": 55.240960359573364, "training_acc": 72.0, "val_loss": 15.678653120994568, "val_acc": 72.0}
{"epoch": 84, "training_loss": 59.99575090408325, "training_acc": 72.0, "val_loss": 14.827696979045868, "val_acc": 72.0}
{"epoch": 85, "training_loss": 56.25834536552429, "training_acc": 72.0, "val_loss": 14.261965453624725, "val_acc": 72.0}
{"epoch": 86, "training_loss": 56.96755933761597, "training_acc": 72.0, "val_loss": 14.58946317434311, "val_acc": 68.0}
{"epoch": 87, "training_loss": 58.320565700531006, "training_acc": 72.0, "val_loss": 14.255794882774353, "val_acc": 76.0}
{"epoch": 88, "training_loss": 56.16927146911621, "training_acc": 72.0, "val_loss": 14.44864571094513, "val_acc": 72.0}
{"epoch": 89, "training_loss": 58.47004675865173, "training_acc": 72.0, "val_loss": 14.524278044700623, "val_acc": 72.0}
{"epoch": 90, "training_loss": 56.13503956794739, "training_acc": 72.0, "val_loss": 14.266185462474823, "val_acc": 72.0}
{"epoch": 91, "training_loss": 56.66297149658203, "training_acc": 72.0, "val_loss": 14.232559502124786, "val_acc": 68.0}
{"epoch": 92, "training_loss": 55.651164293289185, "training_acc": 72.0, "val_loss": 14.18239176273346, "val_acc": 72.0}
{"epoch": 93, "training_loss": 57.58386778831482, "training_acc": 72.0, "val_loss": 14.752987027168274, "val_acc": 72.0}
{"epoch": 94, "training_loss": 56.3204984664917, "training_acc": 72.0, "val_loss": 14.005999267101288, "val_acc": 72.0}
{"epoch": 95, "training_loss": 55.333577394485474, "training_acc": 72.0, "val_loss": 13.999107480049133, "val_acc": 64.0}
{"epoch": 96, "training_loss": 53.60127258300781, "training_acc": 72.0, "val_loss": 14.607520401477814, "val_acc": 72.0}
{"epoch": 97, "training_loss": 55.09574902057648, "training_acc": 72.0, "val_loss": 14.527453482151031, "val_acc": 72.0}
{"epoch": 98, "training_loss": 54.75342345237732, "training_acc": 72.0, "val_loss": 14.243291318416595, "val_acc": 52.0}
{"epoch": 99, "training_loss": 57.28806710243225, "training_acc": 73.0, "val_loss": 14.344930648803711, "val_acc": 52.0}
