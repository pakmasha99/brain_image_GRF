"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 79.0603551864624, "training_acc": 72.0, "val_loss": 15.668882429599762, "val_acc": 72.0}
{"epoch": 1, "training_loss": 115.30309772491455, "training_acc": 52.0, "val_loss": 15.866969525814056, "val_acc": 28.0}
{"epoch": 2, "training_loss": 59.60493457317352, "training_acc": 72.0, "val_loss": 24.715083837509155, "val_acc": 72.0}
{"epoch": 3, "training_loss": 86.73808646202087, "training_acc": 72.0, "val_loss": 15.485808253288269, "val_acc": 32.0}
{"epoch": 4, "training_loss": 62.42005968093872, "training_acc": 72.0, "val_loss": 15.293999016284943, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.02170133590698, "training_acc": 72.0, "val_loss": 15.062636137008667, "val_acc": 72.0}
{"epoch": 6, "training_loss": 61.39672017097473, "training_acc": 72.0, "val_loss": 14.874596893787384, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.03693675994873, "training_acc": 72.0, "val_loss": 15.251559019088745, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61.08191418647766, "training_acc": 72.0, "val_loss": 15.0679811835289, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.6117160320282, "training_acc": 72.0, "val_loss": 14.847899973392487, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.536943554878235, "training_acc": 72.0, "val_loss": 14.863546192646027, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.994781494140625, "training_acc": 72.0, "val_loss": 14.958152174949646, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.62668597698212, "training_acc": 72.0, "val_loss": 14.825598895549774, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.51103186607361, "training_acc": 72.0, "val_loss": 14.82267677783966, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.491581201553345, "training_acc": 72.0, "val_loss": 14.841262996196747, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.44256377220154, "training_acc": 72.0, "val_loss": 14.81671929359436, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.35293126106262, "training_acc": 72.0, "val_loss": 14.795061945915222, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.383261919021606, "training_acc": 72.0, "val_loss": 14.822295308113098, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.59027695655823, "training_acc": 72.0, "val_loss": 14.786514639854431, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.22499489784241, "training_acc": 72.0, "val_loss": 14.772048592567444, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.223047971725464, "training_acc": 72.0, "val_loss": 14.763624966144562, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.14501976966858, "training_acc": 72.0, "val_loss": 14.749012887477875, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.16708207130432, "training_acc": 72.0, "val_loss": 14.737898111343384, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.01019215583801, "training_acc": 72.0, "val_loss": 14.724564552307129, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.911056995391846, "training_acc": 72.0, "val_loss": 14.702725410461426, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.06135129928589, "training_acc": 72.0, "val_loss": 14.701512455940247, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.65860676765442, "training_acc": 72.0, "val_loss": 14.775954186916351, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.927435874938965, "training_acc": 72.0, "val_loss": 14.646226167678833, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.35503959655762, "training_acc": 72.0, "val_loss": 14.630338549613953, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.048510789871216, "training_acc": 72.0, "val_loss": 14.609046280384064, "val_acc": 72.0}
{"epoch": 30, "training_loss": 57.865694761276245, "training_acc": 72.0, "val_loss": 14.492128789424896, "val_acc": 72.0}
{"epoch": 31, "training_loss": 57.35986638069153, "training_acc": 72.0, "val_loss": 15.338025987148285, "val_acc": 40.0}
{"epoch": 32, "training_loss": 61.306835412979126, "training_acc": 72.0, "val_loss": 15.010710060596466, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.32340979576111, "training_acc": 72.0, "val_loss": 14.832434058189392, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.25955605506897, "training_acc": 72.0, "val_loss": 14.66069221496582, "val_acc": 72.0}
{"epoch": 35, "training_loss": 61.19866240024567, "training_acc": 72.0, "val_loss": 14.716954529285431, "val_acc": 72.0}
{"epoch": 36, "training_loss": 64.33521366119385, "training_acc": 72.0, "val_loss": 14.923156797885895, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.20845127105713, "training_acc": 72.0, "val_loss": 15.169711410999298, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.286757946014404, "training_acc": 72.0, "val_loss": 14.928767085075378, "val_acc": 72.0}
{"epoch": 39, "training_loss": 60.21661949157715, "training_acc": 72.0, "val_loss": 15.132756531238556, "val_acc": 72.0}
{"epoch": 40, "training_loss": 60.57356023788452, "training_acc": 72.0, "val_loss": 14.955680072307587, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.9876811504364, "training_acc": 72.0, "val_loss": 15.355154871940613, "val_acc": 28.0}
{"epoch": 42, "training_loss": 61.455801010131836, "training_acc": 72.0, "val_loss": 15.136541426181793, "val_acc": 72.0}
{"epoch": 43, "training_loss": 60.171101808547974, "training_acc": 72.0, "val_loss": 14.852669835090637, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.345078468322754, "training_acc": 72.0, "val_loss": 15.066629648208618, "val_acc": 72.0}
{"epoch": 45, "training_loss": 61.06119155883789, "training_acc": 72.0, "val_loss": 14.906422793865204, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.55849480628967, "training_acc": 72.0, "val_loss": 14.91895467042923, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.910823345184326, "training_acc": 72.0, "val_loss": 15.023404359817505, "val_acc": 72.0}
{"epoch": 48, "training_loss": 60.11459279060364, "training_acc": 72.0, "val_loss": 14.915050566196442, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.59272336959839, "training_acc": 72.0, "val_loss": 14.818648993968964, "val_acc": 72.0}
