"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 64.49008214473724, "training_acc": 52.0, "val_loss": 15.113411843776703, "val_acc": 72.0}
{"epoch": 1, "training_loss": 64.09621977806091, "training_acc": 72.0, "val_loss": 15.068751573562622, "val_acc": 72.0}
{"epoch": 2, "training_loss": 77.77125406265259, "training_acc": 72.0, "val_loss": 15.246802568435669, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.55203199386597, "training_acc": 72.0, "val_loss": 15.230661630630493, "val_acc": 72.0}
{"epoch": 4, "training_loss": 61.12050461769104, "training_acc": 72.0, "val_loss": 15.028513967990875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.69603633880615, "training_acc": 72.0, "val_loss": 15.05691260099411, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.372211933135986, "training_acc": 72.0, "val_loss": 15.09193480014801, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.647099018096924, "training_acc": 72.0, "val_loss": 14.864031970500946, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.58854675292969, "training_acc": 72.0, "val_loss": 14.879347383975983, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.64538621902466, "training_acc": 72.0, "val_loss": 14.842458069324493, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.52462887763977, "training_acc": 72.0, "val_loss": 14.808720350265503, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.57744073867798, "training_acc": 72.0, "val_loss": 14.789420366287231, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.240668058395386, "training_acc": 72.0, "val_loss": 14.819672703742981, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.8376727104187, "training_acc": 72.0, "val_loss": 14.757581055164337, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.096657514572144, "training_acc": 72.0, "val_loss": 14.748746156692505, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.11758852005005, "training_acc": 72.0, "val_loss": 14.694182574748993, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.189525842666626, "training_acc": 72.0, "val_loss": 14.661853015422821, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.11389970779419, "training_acc": 72.0, "val_loss": 14.72557783126831, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.98869323730469, "training_acc": 72.0, "val_loss": 14.61549997329712, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.30315375328064, "training_acc": 72.0, "val_loss": 14.608724415302277, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.38709735870361, "training_acc": 72.0, "val_loss": 14.5479217171669, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.02490019798279, "training_acc": 72.0, "val_loss": 14.46983814239502, "val_acc": 72.0}
{"epoch": 22, "training_loss": 57.653470277786255, "training_acc": 72.0, "val_loss": 14.399290084838867, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.371909379959106, "training_acc": 72.0, "val_loss": 14.35251384973526, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.06085801124573, "training_acc": 72.0, "val_loss": 14.725367724895477, "val_acc": 60.0}
{"epoch": 25, "training_loss": 58.1124153137207, "training_acc": 72.0, "val_loss": 16.506461799144745, "val_acc": 72.0}
{"epoch": 26, "training_loss": 64.56371998786926, "training_acc": 72.0, "val_loss": 14.89986926317215, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.82170009613037, "training_acc": 72.0, "val_loss": 14.859643578529358, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.48704409599304, "training_acc": 72.0, "val_loss": 15.045943856239319, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.07295608520508, "training_acc": 72.0, "val_loss": 14.811505377292633, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.03660726547241, "training_acc": 72.0, "val_loss": 14.715984463691711, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.94965934753418, "training_acc": 72.0, "val_loss": 14.757847785949707, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.72750687599182, "training_acc": 72.0, "val_loss": 14.621065557003021, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.45844292640686, "training_acc": 72.0, "val_loss": 14.65529352426529, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.438228130340576, "training_acc": 72.0, "val_loss": 14.540235698223114, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.71140456199646, "training_acc": 72.0, "val_loss": 14.690583944320679, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.08724522590637, "training_acc": 72.0, "val_loss": 14.551007747650146, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.474937200546265, "training_acc": 72.0, "val_loss": 14.327280223369598, "val_acc": 72.0}
{"epoch": 38, "training_loss": 56.58369445800781, "training_acc": 72.0, "val_loss": 14.560599625110626, "val_acc": 72.0}
{"epoch": 39, "training_loss": 56.77639198303223, "training_acc": 72.0, "val_loss": 14.312729239463806, "val_acc": 68.0}
{"epoch": 40, "training_loss": 57.37255144119263, "training_acc": 72.0, "val_loss": 14.194981753826141, "val_acc": 68.0}
{"epoch": 41, "training_loss": 57.833489418029785, "training_acc": 72.0, "val_loss": 13.90853077173233, "val_acc": 80.0}
{"epoch": 42, "training_loss": 55.35169982910156, "training_acc": 72.0, "val_loss": 14.052197337150574, "val_acc": 72.0}
{"epoch": 43, "training_loss": 54.792826414108276, "training_acc": 72.0, "val_loss": 13.889776170253754, "val_acc": 80.0}
{"epoch": 44, "training_loss": 56.53149676322937, "training_acc": 73.0, "val_loss": 14.278507232666016, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.507232666015625, "training_acc": 72.0, "val_loss": 13.869673013687134, "val_acc": 80.0}
{"epoch": 46, "training_loss": 55.77701687812805, "training_acc": 75.0, "val_loss": 13.779743015766144, "val_acc": 80.0}
{"epoch": 47, "training_loss": 55.14580678939819, "training_acc": 72.0, "val_loss": 13.526543974876404, "val_acc": 80.0}
{"epoch": 48, "training_loss": 56.1091947555542, "training_acc": 71.0, "val_loss": 13.490773737430573, "val_acc": 76.0}
{"epoch": 49, "training_loss": 54.38953757286072, "training_acc": 74.0, "val_loss": 14.406104385852814, "val_acc": 72.0}
{"epoch": 50, "training_loss": 52.05882906913757, "training_acc": 72.0, "val_loss": 14.046253263950348, "val_acc": 52.0}
{"epoch": 51, "training_loss": 57.24416732788086, "training_acc": 73.0, "val_loss": 13.467440009117126, "val_acc": 80.0}
{"epoch": 52, "training_loss": 55.360201835632324, "training_acc": 72.0, "val_loss": 14.6405428647995, "val_acc": 72.0}
{"epoch": 53, "training_loss": 53.62077784538269, "training_acc": 72.0, "val_loss": 13.906262814998627, "val_acc": 52.0}
{"epoch": 54, "training_loss": 57.010058641433716, "training_acc": 75.0, "val_loss": 13.85134607553482, "val_acc": 68.0}
{"epoch": 55, "training_loss": 57.650391578674316, "training_acc": 72.0, "val_loss": 13.833007216453552, "val_acc": 72.0}
{"epoch": 56, "training_loss": 54.092931032180786, "training_acc": 72.0, "val_loss": 13.900144398212433, "val_acc": 72.0}
{"epoch": 57, "training_loss": 53.026792764663696, "training_acc": 72.0, "val_loss": 13.50916475057602, "val_acc": 80.0}
{"epoch": 58, "training_loss": 51.92038536071777, "training_acc": 72.0, "val_loss": 13.338282704353333, "val_acc": 80.0}
{"epoch": 59, "training_loss": 50.08612787723541, "training_acc": 77.0, "val_loss": 14.01480883359909, "val_acc": 80.0}
{"epoch": 60, "training_loss": 48.81515860557556, "training_acc": 78.0, "val_loss": 13.457439839839935, "val_acc": 64.0}
{"epoch": 61, "training_loss": 52.3255512714386, "training_acc": 74.0, "val_loss": 16.04922264814377, "val_acc": 80.0}
{"epoch": 62, "training_loss": 53.74783682823181, "training_acc": 80.0, "val_loss": 13.14132809638977, "val_acc": 64.0}
{"epoch": 63, "training_loss": 51.091280460357666, "training_acc": 78.0, "val_loss": 15.784084796905518, "val_acc": 72.0}
{"epoch": 64, "training_loss": 54.41325235366821, "training_acc": 72.0, "val_loss": 12.63180822134018, "val_acc": 84.0}
{"epoch": 65, "training_loss": 51.742292165756226, "training_acc": 71.0, "val_loss": 12.629525363445282, "val_acc": 76.0}
{"epoch": 66, "training_loss": 52.14107847213745, "training_acc": 78.0, "val_loss": 13.887929916381836, "val_acc": 76.0}
{"epoch": 67, "training_loss": 50.31647062301636, "training_acc": 73.0, "val_loss": 12.823615968227386, "val_acc": 84.0}
{"epoch": 68, "training_loss": 51.03601956367493, "training_acc": 73.0, "val_loss": 12.643752992153168, "val_acc": 72.0}
{"epoch": 69, "training_loss": 48.6966392993927, "training_acc": 82.0, "val_loss": 13.792933523654938, "val_acc": 80.0}
{"epoch": 70, "training_loss": 51.22180652618408, "training_acc": 76.0, "val_loss": 13.0806103348732, "val_acc": 56.0}
{"epoch": 71, "training_loss": 56.87822437286377, "training_acc": 71.0, "val_loss": 13.582950830459595, "val_acc": 72.0}
{"epoch": 72, "training_loss": 56.360795974731445, "training_acc": 72.0, "val_loss": 14.773547649383545, "val_acc": 72.0}
{"epoch": 73, "training_loss": 58.437538504600525, "training_acc": 72.0, "val_loss": 14.06923532485962, "val_acc": 72.0}
{"epoch": 74, "training_loss": 55.72746920585632, "training_acc": 72.0, "val_loss": 13.951091468334198, "val_acc": 80.0}
{"epoch": 75, "training_loss": 54.394575238227844, "training_acc": 72.0, "val_loss": 14.760738611221313, "val_acc": 72.0}
{"epoch": 76, "training_loss": 55.552868008613586, "training_acc": 72.0, "val_loss": 14.897426962852478, "val_acc": 72.0}
{"epoch": 77, "training_loss": 53.89229369163513, "training_acc": 71.0, "val_loss": 14.488929510116577, "val_acc": 52.0}
{"epoch": 78, "training_loss": 56.080810546875, "training_acc": 69.0, "val_loss": 13.756775856018066, "val_acc": 76.0}
{"epoch": 79, "training_loss": 53.56733822822571, "training_acc": 74.0, "val_loss": 14.784203469753265, "val_acc": 72.0}
{"epoch": 80, "training_loss": 53.36828601360321, "training_acc": 73.0, "val_loss": 13.523171842098236, "val_acc": 80.0}
{"epoch": 81, "training_loss": 53.268447160720825, "training_acc": 73.0, "val_loss": 13.70062381029129, "val_acc": 64.0}
{"epoch": 82, "training_loss": 53.24153184890747, "training_acc": 77.0, "val_loss": 13.375486433506012, "val_acc": 80.0}
{"epoch": 83, "training_loss": 54.61428189277649, "training_acc": 75.0, "val_loss": 14.101500809192657, "val_acc": 80.0}
{"epoch": 84, "training_loss": 52.48964512348175, "training_acc": 72.0, "val_loss": 13.245964050292969, "val_acc": 68.0}
