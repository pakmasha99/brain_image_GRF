"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.81971716880798, "training_acc": 42.0, "val_loss": 15.271200239658356, "val_acc": 72.0}
{"epoch": 1, "training_loss": 73.04056882858276, "training_acc": 72.0, "val_loss": 15.098381042480469, "val_acc": 72.0}
{"epoch": 2, "training_loss": 63.231626749038696, "training_acc": 72.0, "val_loss": 15.718652307987213, "val_acc": 28.0}
{"epoch": 3, "training_loss": 62.03670930862427, "training_acc": 72.0, "val_loss": 15.004312992095947, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.45729947090149, "training_acc": 72.0, "val_loss": 15.203282237052917, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.49053168296814, "training_acc": 72.0, "val_loss": 14.992006123065948, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.67009735107422, "training_acc": 72.0, "val_loss": 14.952972531318665, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.6069221496582, "training_acc": 72.0, "val_loss": 14.937889575958252, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.657620429992676, "training_acc": 72.0, "val_loss": 15.014351904392242, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.97961783409119, "training_acc": 72.0, "val_loss": 14.888782799243927, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.24090242385864, "training_acc": 72.0, "val_loss": 14.841943979263306, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.235077142715454, "training_acc": 72.0, "val_loss": 14.788533747196198, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.959006547927856, "training_acc": 72.0, "val_loss": 14.745475351810455, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.10642981529236, "training_acc": 72.0, "val_loss": 14.76927399635315, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.572165966033936, "training_acc": 72.0, "val_loss": 14.886412024497986, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.98700666427612, "training_acc": 72.0, "val_loss": 14.674200117588043, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.55905222892761, "training_acc": 72.0, "val_loss": 14.822003245353699, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.95994687080383, "training_acc": 72.0, "val_loss": 14.677555859088898, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.560508728027344, "training_acc": 72.0, "val_loss": 14.775334298610687, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.93239951133728, "training_acc": 72.0, "val_loss": 14.788974821567535, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.82828140258789, "training_acc": 72.0, "val_loss": 14.720945060253143, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.74463152885437, "training_acc": 72.0, "val_loss": 14.606960117816925, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.55813264846802, "training_acc": 72.0, "val_loss": 14.637722074985504, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.719202518463135, "training_acc": 72.0, "val_loss": 14.533731341362, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.191105365753174, "training_acc": 72.0, "val_loss": 14.533792436122894, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.31654667854309, "training_acc": 72.0, "val_loss": 14.50003832578659, "val_acc": 72.0}
{"epoch": 26, "training_loss": 57.9929723739624, "training_acc": 72.0, "val_loss": 14.273212850093842, "val_acc": 72.0}
{"epoch": 27, "training_loss": 57.606581926345825, "training_acc": 72.0, "val_loss": 14.12799060344696, "val_acc": 72.0}
{"epoch": 28, "training_loss": 57.11100745201111, "training_acc": 72.0, "val_loss": 14.164143800735474, "val_acc": 72.0}
{"epoch": 29, "training_loss": 56.78767228126526, "training_acc": 72.0, "val_loss": 13.780702650547028, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.08984303474426, "training_acc": 72.0, "val_loss": 14.420680701732635, "val_acc": 72.0}
{"epoch": 31, "training_loss": 62.10638189315796, "training_acc": 72.0, "val_loss": 14.051109552383423, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.83734107017517, "training_acc": 72.0, "val_loss": 15.026108920574188, "val_acc": 56.0}
{"epoch": 33, "training_loss": 60.69291424751282, "training_acc": 72.0, "val_loss": 14.770402014255524, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.64153027534485, "training_acc": 72.0, "val_loss": 14.770898222923279, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.00640606880188, "training_acc": 72.0, "val_loss": 14.85491544008255, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.19586515426636, "training_acc": 72.0, "val_loss": 14.747600257396698, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.04257917404175, "training_acc": 72.0, "val_loss": 14.659711718559265, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.6146719455719, "training_acc": 72.0, "val_loss": 14.64339792728424, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.999194860458374, "training_acc": 72.0, "val_loss": 14.550085365772247, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.63995313644409, "training_acc": 72.0, "val_loss": 14.435800909996033, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.24573826789856, "training_acc": 72.0, "val_loss": 14.353951811790466, "val_acc": 72.0}
{"epoch": 42, "training_loss": 57.85932230949402, "training_acc": 72.0, "val_loss": 14.21656608581543, "val_acc": 72.0}
{"epoch": 43, "training_loss": 57.84922957420349, "training_acc": 72.0, "val_loss": 14.046834409236908, "val_acc": 72.0}
{"epoch": 44, "training_loss": 57.31059288978577, "training_acc": 72.0, "val_loss": 13.729524612426758, "val_acc": 72.0}
{"epoch": 45, "training_loss": 56.64086937904358, "training_acc": 72.0, "val_loss": 13.656587898731232, "val_acc": 76.0}
{"epoch": 46, "training_loss": 57.2633752822876, "training_acc": 72.0, "val_loss": 14.097459614276886, "val_acc": 72.0}
{"epoch": 47, "training_loss": 58.804107904434204, "training_acc": 72.0, "val_loss": 13.456325232982635, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.01471257209778, "training_acc": 72.0, "val_loss": 14.552070200443268, "val_acc": 64.0}
{"epoch": 49, "training_loss": 58.51177191734314, "training_acc": 72.0, "val_loss": 14.34592604637146, "val_acc": 72.0}
{"epoch": 50, "training_loss": 57.75735783576965, "training_acc": 72.0, "val_loss": 14.678271114826202, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.6835777759552, "training_acc": 72.0, "val_loss": 14.078478515148163, "val_acc": 72.0}
{"epoch": 52, "training_loss": 57.06839895248413, "training_acc": 72.0, "val_loss": 13.774977624416351, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.12610149383545, "training_acc": 72.0, "val_loss": 13.623426854610443, "val_acc": 72.0}
{"epoch": 54, "training_loss": 55.950291872024536, "training_acc": 72.0, "val_loss": 13.86042833328247, "val_acc": 72.0}
{"epoch": 55, "training_loss": 56.303669452667236, "training_acc": 72.0, "val_loss": 13.087347149848938, "val_acc": 76.0}
{"epoch": 56, "training_loss": 55.56110405921936, "training_acc": 72.0, "val_loss": 12.869022786617279, "val_acc": 76.0}
{"epoch": 57, "training_loss": 54.74166917800903, "training_acc": 72.0, "val_loss": 12.739135324954987, "val_acc": 72.0}
{"epoch": 58, "training_loss": 57.034703493118286, "training_acc": 72.0, "val_loss": 13.851472735404968, "val_acc": 60.0}
{"epoch": 59, "training_loss": 61.45562410354614, "training_acc": 75.0, "val_loss": 14.192362129688263, "val_acc": 72.0}
{"epoch": 60, "training_loss": 56.890098333358765, "training_acc": 72.0, "val_loss": 15.432901680469513, "val_acc": 72.0}
{"epoch": 61, "training_loss": 61.2692334651947, "training_acc": 72.0, "val_loss": 14.352908730506897, "val_acc": 72.0}
{"epoch": 62, "training_loss": 57.28451085090637, "training_acc": 72.0, "val_loss": 13.635513186454773, "val_acc": 72.0}
{"epoch": 63, "training_loss": 56.19690179824829, "training_acc": 72.0, "val_loss": 13.400255143642426, "val_acc": 84.0}
{"epoch": 64, "training_loss": 55.49830746650696, "training_acc": 72.0, "val_loss": 13.302716612815857, "val_acc": 72.0}
{"epoch": 65, "training_loss": 56.097609519958496, "training_acc": 72.0, "val_loss": 13.294738531112671, "val_acc": 72.0}
{"epoch": 66, "training_loss": 56.145708441734314, "training_acc": 72.0, "val_loss": 13.038206100463867, "val_acc": 84.0}
{"epoch": 67, "training_loss": 55.18381714820862, "training_acc": 73.0, "val_loss": 13.219314813613892, "val_acc": 72.0}
{"epoch": 68, "training_loss": 53.584659576416016, "training_acc": 72.0, "val_loss": 13.254322111606598, "val_acc": 72.0}
{"epoch": 69, "training_loss": 54.0736700296402, "training_acc": 74.0, "val_loss": 12.160354107618332, "val_acc": 76.0}
{"epoch": 70, "training_loss": 54.38961458206177, "training_acc": 73.0, "val_loss": 11.982578039169312, "val_acc": 84.0}
{"epoch": 71, "training_loss": 57.64698004722595, "training_acc": 74.0, "val_loss": 12.652891874313354, "val_acc": 80.0}
{"epoch": 72, "training_loss": 61.10563397407532, "training_acc": 71.0, "val_loss": 13.733556866645813, "val_acc": 60.0}
{"epoch": 73, "training_loss": 57.98034906387329, "training_acc": 74.0, "val_loss": 13.398626446723938, "val_acc": 72.0}
{"epoch": 74, "training_loss": 53.68097698688507, "training_acc": 72.0, "val_loss": 13.647565245628357, "val_acc": 72.0}
{"epoch": 75, "training_loss": 54.95974063873291, "training_acc": 72.0, "val_loss": 13.589899241924286, "val_acc": 72.0}
{"epoch": 76, "training_loss": 53.09287464618683, "training_acc": 72.0, "val_loss": 13.322782516479492, "val_acc": 80.0}
{"epoch": 77, "training_loss": 53.09029960632324, "training_acc": 72.0, "val_loss": 13.074731826782227, "val_acc": 84.0}
{"epoch": 78, "training_loss": 51.838475465774536, "training_acc": 74.0, "val_loss": 12.583155930042267, "val_acc": 88.0}
{"epoch": 79, "training_loss": 51.19039523601532, "training_acc": 76.0, "val_loss": 12.09716945886612, "val_acc": 88.0}
{"epoch": 80, "training_loss": 52.370906352996826, "training_acc": 76.0, "val_loss": 11.843767017126083, "val_acc": 88.0}
{"epoch": 81, "training_loss": 49.356276750564575, "training_acc": 77.0, "val_loss": 12.286749482154846, "val_acc": 68.0}
{"epoch": 82, "training_loss": 51.973076820373535, "training_acc": 74.0, "val_loss": 13.891859352588654, "val_acc": 80.0}
{"epoch": 83, "training_loss": 55.35244703292847, "training_acc": 76.0, "val_loss": 12.28770911693573, "val_acc": 76.0}
{"epoch": 84, "training_loss": 49.563384771347046, "training_acc": 74.0, "val_loss": 13.132260739803314, "val_acc": 64.0}
{"epoch": 85, "training_loss": 51.437509655952454, "training_acc": 75.0, "val_loss": 14.187119901180267, "val_acc": 72.0}
{"epoch": 86, "training_loss": 54.622065782547, "training_acc": 72.0, "val_loss": 12.04134076833725, "val_acc": 84.0}
{"epoch": 87, "training_loss": 51.95800447463989, "training_acc": 73.0, "val_loss": 12.54168450832367, "val_acc": 64.0}
{"epoch": 88, "training_loss": 51.40034532546997, "training_acc": 80.0, "val_loss": 13.305981457233429, "val_acc": 80.0}
{"epoch": 89, "training_loss": 51.078420639038086, "training_acc": 75.0, "val_loss": 13.521721959114075, "val_acc": 80.0}
{"epoch": 90, "training_loss": 49.51304078102112, "training_acc": 78.0, "val_loss": 12.592831254005432, "val_acc": 84.0}
{"epoch": 91, "training_loss": 48.13723802566528, "training_acc": 76.0, "val_loss": 12.811486423015594, "val_acc": 64.0}
{"epoch": 92, "training_loss": 47.6724956035614, "training_acc": 83.0, "val_loss": 13.384844362735748, "val_acc": 80.0}
{"epoch": 93, "training_loss": 43.35025370121002, "training_acc": 79.0, "val_loss": 13.045695424079895, "val_acc": 68.0}
{"epoch": 94, "training_loss": 49.04203426837921, "training_acc": 76.0, "val_loss": 12.277991324663162, "val_acc": 76.0}
{"epoch": 95, "training_loss": 51.830207109451294, "training_acc": 79.0, "val_loss": 12.671875953674316, "val_acc": 72.0}
{"epoch": 96, "training_loss": 43.59311521053314, "training_acc": 81.0, "val_loss": 12.90387362241745, "val_acc": 72.0}
{"epoch": 97, "training_loss": 44.611512184143066, "training_acc": 78.0, "val_loss": 16.29902571439743, "val_acc": 48.0}
{"epoch": 98, "training_loss": 62.000805616378784, "training_acc": 60.0, "val_loss": 13.16482126712799, "val_acc": 80.0}
{"epoch": 99, "training_loss": 52.83647084236145, "training_acc": 74.0, "val_loss": 17.63809323310852, "val_acc": 72.0}
