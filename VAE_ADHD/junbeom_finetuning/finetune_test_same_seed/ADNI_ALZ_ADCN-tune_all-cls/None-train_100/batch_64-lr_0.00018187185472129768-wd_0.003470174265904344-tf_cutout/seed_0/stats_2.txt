"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.20767974853516, "training_acc": 44.0, "val_loss": 14.962135255336761, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.63300538063049, "training_acc": 72.0, "val_loss": 15.542548894882202, "val_acc": 72.0}
{"epoch": 2, "training_loss": 61.226701498031616, "training_acc": 72.0, "val_loss": 15.000973641872406, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.49417591094971, "training_acc": 72.0, "val_loss": 14.997872710227966, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.49950098991394, "training_acc": 72.0, "val_loss": 14.897647500038147, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.72767734527588, "training_acc": 72.0, "val_loss": 14.872914552688599, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.03546071052551, "training_acc": 72.0, "val_loss": 15.041476488113403, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.70192313194275, "training_acc": 72.0, "val_loss": 14.835691452026367, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.17969250679016, "training_acc": 72.0, "val_loss": 14.99735414981842, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.34001564979553, "training_acc": 72.0, "val_loss": 14.841897785663605, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.17306447029114, "training_acc": 72.0, "val_loss": 14.88284319639206, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.22157859802246, "training_acc": 72.0, "val_loss": 14.77704644203186, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.90887093544006, "training_acc": 72.0, "val_loss": 14.853759109973907, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.05244469642639, "training_acc": 72.0, "val_loss": 14.740051329135895, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.23514676094055, "training_acc": 72.0, "val_loss": 14.661173522472382, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.10104489326477, "training_acc": 72.0, "val_loss": 14.621083438396454, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.62347769737244, "training_acc": 72.0, "val_loss": 14.518369734287262, "val_acc": 72.0}
{"epoch": 17, "training_loss": 57.809529304504395, "training_acc": 72.0, "val_loss": 14.676852524280548, "val_acc": 72.0}
{"epoch": 18, "training_loss": 56.71442639827728, "training_acc": 72.0, "val_loss": 15.70824533700943, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.57795190811157, "training_acc": 72.0, "val_loss": 14.670638740062714, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.95879793167114, "training_acc": 72.0, "val_loss": 14.815515279769897, "val_acc": 68.0}
{"epoch": 21, "training_loss": 58.686363220214844, "training_acc": 72.0, "val_loss": 14.670513570308685, "val_acc": 68.0}
{"epoch": 22, "training_loss": 57.85207939147949, "training_acc": 72.0, "val_loss": 14.509855210781097, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.175772190093994, "training_acc": 72.0, "val_loss": 14.615881443023682, "val_acc": 72.0}
{"epoch": 24, "training_loss": 55.854565143585205, "training_acc": 72.0, "val_loss": 14.212246239185333, "val_acc": 72.0}
{"epoch": 25, "training_loss": 54.32497763633728, "training_acc": 72.0, "val_loss": 14.17817771434784, "val_acc": 72.0}
{"epoch": 26, "training_loss": 55.06722569465637, "training_acc": 72.0, "val_loss": 19.42073553800583, "val_acc": 72.0}
{"epoch": 27, "training_loss": 60.548370122909546, "training_acc": 72.0, "val_loss": 16.347768902778625, "val_acc": 28.0}
{"epoch": 28, "training_loss": 66.12525486946106, "training_acc": 72.0, "val_loss": 15.217117965221405, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.154210805892944, "training_acc": 72.0, "val_loss": 17.44331121444702, "val_acc": 72.0}
{"epoch": 30, "training_loss": 67.16422700881958, "training_acc": 72.0, "val_loss": 14.936940371990204, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.20474720001221, "training_acc": 72.0, "val_loss": 15.437646210193634, "val_acc": 28.0}
{"epoch": 32, "training_loss": 61.55310797691345, "training_acc": 72.0, "val_loss": 15.251870453357697, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.66046953201294, "training_acc": 72.0, "val_loss": 14.924100041389465, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.720531940460205, "training_acc": 72.0, "val_loss": 14.993730187416077, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.9894814491272, "training_acc": 72.0, "val_loss": 14.882472157478333, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.32815217971802, "training_acc": 72.0, "val_loss": 15.021409094333649, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.04504323005676, "training_acc": 72.0, "val_loss": 14.921694993972778, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.61373710632324, "training_acc": 72.0, "val_loss": 14.852775633335114, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.000107288360596, "training_acc": 72.0, "val_loss": 14.885547757148743, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.10532069206238, "training_acc": 72.0, "val_loss": 14.856329560279846, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.07678151130676, "training_acc": 72.0, "val_loss": 14.789412915706635, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.583688497543335, "training_acc": 72.0, "val_loss": 14.744096994400024, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.252840995788574, "training_acc": 72.0, "val_loss": 14.70392495393753, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.00991487503052, "training_acc": 72.0, "val_loss": 14.660535752773285, "val_acc": 72.0}
