"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.00985670089722, "training_acc": 53.0, "val_loss": 21.559622883796692, "val_acc": 72.0}
{"epoch": 1, "training_loss": 92.8766667842865, "training_acc": 52.0, "val_loss": 16.06462597846985, "val_acc": 28.0}
{"epoch": 2, "training_loss": 62.65660524368286, "training_acc": 72.0, "val_loss": 15.860295295715332, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.3698570728302, "training_acc": 72.0, "val_loss": 15.493778884410858, "val_acc": 28.0}
{"epoch": 4, "training_loss": 61.47547626495361, "training_acc": 72.0, "val_loss": 14.963492751121521, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.39819073677063, "training_acc": 72.0, "val_loss": 14.933589100837708, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.244558811187744, "training_acc": 72.0, "val_loss": 15.236347913742065, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.832634687423706, "training_acc": 72.0, "val_loss": 15.047195553779602, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.73815584182739, "training_acc": 72.0, "val_loss": 14.89793062210083, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.63347625732422, "training_acc": 72.0, "val_loss": 14.888837933540344, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.76271891593933, "training_acc": 72.0, "val_loss": 14.897364377975464, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.36595368385315, "training_acc": 72.0, "val_loss": 14.879226684570312, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.54404592514038, "training_acc": 72.0, "val_loss": 14.87414538860321, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.38263654708862, "training_acc": 72.0, "val_loss": 14.8724764585495, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.2610867023468, "training_acc": 72.0, "val_loss": 14.849591255187988, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.12423372268677, "training_acc": 72.0, "val_loss": 14.847059547901154, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.52848696708679, "training_acc": 72.0, "val_loss": 14.838708937168121, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.05506634712219, "training_acc": 72.0, "val_loss": 14.874917268753052, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.479454040527344, "training_acc": 72.0, "val_loss": 14.817234873771667, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.496830701828, "training_acc": 72.0, "val_loss": 14.79748785495758, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.34167456626892, "training_acc": 72.0, "val_loss": 14.897681772708893, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.318265199661255, "training_acc": 72.0, "val_loss": 14.804042875766754, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.922534227371216, "training_acc": 72.0, "val_loss": 14.79012668132782, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.76362347602844, "training_acc": 72.0, "val_loss": 14.775802195072174, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.140015840530396, "training_acc": 72.0, "val_loss": 14.760945737361908, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.70184659957886, "training_acc": 72.0, "val_loss": 14.815923571586609, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.98180389404297, "training_acc": 72.0, "val_loss": 14.765173196792603, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.57106423377991, "training_acc": 72.0, "val_loss": 14.75239098072052, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.806477785110474, "training_acc": 72.0, "val_loss": 14.715467393398285, "val_acc": 72.0}
{"epoch": 29, "training_loss": 57.92389535903931, "training_acc": 72.0, "val_loss": 14.83001857995987, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.64043045043945, "training_acc": 72.0, "val_loss": 14.684683084487915, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.071820974349976, "training_acc": 72.0, "val_loss": 14.597710967063904, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.00965476036072, "training_acc": 72.0, "val_loss": 14.588144421577454, "val_acc": 72.0}
{"epoch": 33, "training_loss": 57.09354209899902, "training_acc": 72.0, "val_loss": 16.025148332118988, "val_acc": 72.0}
{"epoch": 34, "training_loss": 61.39635992050171, "training_acc": 72.0, "val_loss": 14.550700783729553, "val_acc": 72.0}
{"epoch": 35, "training_loss": 56.90816116333008, "training_acc": 72.0, "val_loss": 14.48219120502472, "val_acc": 72.0}
{"epoch": 36, "training_loss": 56.684738516807556, "training_acc": 72.0, "val_loss": 14.881764352321625, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.19304347038269, "training_acc": 72.0, "val_loss": 14.618682861328125, "val_acc": 72.0}
{"epoch": 38, "training_loss": 56.91072702407837, "training_acc": 72.0, "val_loss": 14.152847230434418, "val_acc": 76.0}
{"epoch": 39, "training_loss": 55.58788251876831, "training_acc": 72.0, "val_loss": 16.47174209356308, "val_acc": 32.0}
{"epoch": 40, "training_loss": 63.21000599861145, "training_acc": 71.0, "val_loss": 15.244744718074799, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.25876045227051, "training_acc": 72.0, "val_loss": 14.8375004529953, "val_acc": 72.0}
{"epoch": 42, "training_loss": 56.5201530456543, "training_acc": 72.0, "val_loss": 14.731043577194214, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.43750619888306, "training_acc": 72.0, "val_loss": 14.533518254756927, "val_acc": 72.0}
{"epoch": 44, "training_loss": 57.23350739479065, "training_acc": 72.0, "val_loss": 14.953528344631195, "val_acc": 72.0}
{"epoch": 45, "training_loss": 57.67631459236145, "training_acc": 72.0, "val_loss": 14.927573502063751, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.09223675727844, "training_acc": 72.0, "val_loss": 14.627841114997864, "val_acc": 72.0}
{"epoch": 47, "training_loss": 56.612576484680176, "training_acc": 72.0, "val_loss": 16.377785801887512, "val_acc": 72.0}
{"epoch": 48, "training_loss": 64.5956027507782, "training_acc": 72.0, "val_loss": 15.172222256660461, "val_acc": 64.0}
{"epoch": 49, "training_loss": 59.88217806816101, "training_acc": 72.0, "val_loss": 14.860253036022186, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.56538367271423, "training_acc": 72.0, "val_loss": 14.849631488323212, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.667762756347656, "training_acc": 72.0, "val_loss": 14.845967292785645, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.115506410598755, "training_acc": 72.0, "val_loss": 14.69346284866333, "val_acc": 72.0}
{"epoch": 53, "training_loss": 58.331624031066895, "training_acc": 72.0, "val_loss": 14.516109228134155, "val_acc": 72.0}
{"epoch": 54, "training_loss": 58.05849099159241, "training_acc": 72.0, "val_loss": 14.532126486301422, "val_acc": 72.0}
{"epoch": 55, "training_loss": 55.871437549591064, "training_acc": 72.0, "val_loss": 14.876426756381989, "val_acc": 64.0}
{"epoch": 56, "training_loss": 57.970091581344604, "training_acc": 72.0, "val_loss": 14.257201552391052, "val_acc": 76.0}
{"epoch": 57, "training_loss": 55.59325361251831, "training_acc": 72.0, "val_loss": 15.106196701526642, "val_acc": 72.0}
