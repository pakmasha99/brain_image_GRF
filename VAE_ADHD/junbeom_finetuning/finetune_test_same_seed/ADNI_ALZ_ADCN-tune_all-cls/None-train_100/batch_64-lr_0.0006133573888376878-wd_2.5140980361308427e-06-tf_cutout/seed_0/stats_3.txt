"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 78.73814153671265, "training_acc": 44.0, "val_loss": 32.72492289543152, "val_acc": 72.0}
{"epoch": 1, "training_loss": 113.81071543693542, "training_acc": 56.0, "val_loss": 15.453441441059113, "val_acc": 28.0}
{"epoch": 2, "training_loss": 60.835615158081055, "training_acc": 72.0, "val_loss": 14.968104660511017, "val_acc": 72.0}
{"epoch": 3, "training_loss": 62.544942140579224, "training_acc": 72.0, "val_loss": 14.956529438495636, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.42820072174072, "training_acc": 72.0, "val_loss": 14.945884048938751, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.51814293861389, "training_acc": 72.0, "val_loss": 15.075886249542236, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.005685567855835, "training_acc": 72.0, "val_loss": 15.130183100700378, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.210110902786255, "training_acc": 72.0, "val_loss": 14.91287648677826, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.53504014015198, "training_acc": 72.0, "val_loss": 14.97056931257248, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.91759133338928, "training_acc": 72.0, "val_loss": 14.879487454891205, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.53049969673157, "training_acc": 72.0, "val_loss": 14.915923774242401, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.542680501937866, "training_acc": 72.0, "val_loss": 14.998866617679596, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.90583109855652, "training_acc": 72.0, "val_loss": 14.920935034751892, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.534560441970825, "training_acc": 72.0, "val_loss": 14.851142466068268, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.66683316230774, "training_acc": 72.0, "val_loss": 14.873407781124115, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.67502999305725, "training_acc": 72.0, "val_loss": 14.834131300449371, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.909740567207336, "training_acc": 72.0, "val_loss": 14.821845293045044, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.18848204612732, "training_acc": 72.0, "val_loss": 14.89776223897934, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.483635663986206, "training_acc": 72.0, "val_loss": 14.8649662733078, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.34682106971741, "training_acc": 72.0, "val_loss": 14.797049760818481, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.27422332763672, "training_acc": 72.0, "val_loss": 14.783334732055664, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.01832628250122, "training_acc": 72.0, "val_loss": 14.772428572177887, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.13619661331177, "training_acc": 72.0, "val_loss": 14.799840748310089, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.937978744506836, "training_acc": 72.0, "val_loss": 14.762702584266663, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.05038046836853, "training_acc": 72.0, "val_loss": 14.887109398841858, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.278613328933716, "training_acc": 72.0, "val_loss": 14.72088247537613, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.68233060836792, "training_acc": 72.0, "val_loss": 14.779683947563171, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.86731719970703, "training_acc": 72.0, "val_loss": 14.67224806547165, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.532421588897705, "training_acc": 72.0, "val_loss": 14.819863438606262, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.18824052810669, "training_acc": 72.0, "val_loss": 14.685644209384918, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.01000142097473, "training_acc": 72.0, "val_loss": 15.09833037853241, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.95116877555847, "training_acc": 72.0, "val_loss": 14.665935933589935, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.29126858711243, "training_acc": 72.0, "val_loss": 14.925575256347656, "val_acc": 68.0}
{"epoch": 33, "training_loss": 59.46952033042908, "training_acc": 72.0, "val_loss": 14.665932953357697, "val_acc": 68.0}
{"epoch": 34, "training_loss": 58.31175255775452, "training_acc": 72.0, "val_loss": 14.554440975189209, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.86792254447937, "training_acc": 72.0, "val_loss": 14.376328885555267, "val_acc": 68.0}
{"epoch": 36, "training_loss": 57.136093854904175, "training_acc": 72.0, "val_loss": 14.651873707771301, "val_acc": 72.0}
{"epoch": 37, "training_loss": 65.32769322395325, "training_acc": 72.0, "val_loss": 14.504793286323547, "val_acc": 72.0}
{"epoch": 38, "training_loss": 61.53559494018555, "training_acc": 72.0, "val_loss": 15.369139611721039, "val_acc": 32.0}
{"epoch": 39, "training_loss": 60.843127489089966, "training_acc": 72.0, "val_loss": 14.960446953773499, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.5909321308136, "training_acc": 72.0, "val_loss": 14.75210189819336, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.018181562423706, "training_acc": 72.0, "val_loss": 14.849506318569183, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.284218549728394, "training_acc": 72.0, "val_loss": 14.707694947719574, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.84711980819702, "training_acc": 72.0, "val_loss": 14.692939817905426, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.92495393753052, "training_acc": 72.0, "val_loss": 14.683069288730621, "val_acc": 72.0}
{"epoch": 45, "training_loss": 58.43013620376587, "training_acc": 72.0, "val_loss": 14.671823382377625, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.45994853973389, "training_acc": 72.0, "val_loss": 14.472651481628418, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.45635724067688, "training_acc": 72.0, "val_loss": 15.152592957019806, "val_acc": 72.0}
{"epoch": 48, "training_loss": 60.400906801223755, "training_acc": 72.0, "val_loss": 14.878173172473907, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.214061975479126, "training_acc": 72.0, "val_loss": 14.823147654533386, "val_acc": 72.0}
{"epoch": 50, "training_loss": 60.18055748939514, "training_acc": 72.0, "val_loss": 14.792264997959137, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.81435012817383, "training_acc": 72.0, "val_loss": 14.74183052778244, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.077163219451904, "training_acc": 72.0, "val_loss": 14.764624834060669, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.14348578453064, "training_acc": 72.0, "val_loss": 14.628885686397552, "val_acc": 72.0}
{"epoch": 54, "training_loss": 58.52907705307007, "training_acc": 72.0, "val_loss": 14.562462270259857, "val_acc": 72.0}
