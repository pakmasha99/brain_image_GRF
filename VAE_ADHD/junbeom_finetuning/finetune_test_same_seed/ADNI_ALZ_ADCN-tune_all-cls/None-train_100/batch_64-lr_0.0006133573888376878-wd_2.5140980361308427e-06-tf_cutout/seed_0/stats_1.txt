"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 80.06156778335571, "training_acc": 72.0, "val_loss": 15.748760104179382, "val_acc": 72.0}
{"epoch": 1, "training_loss": 74.92802429199219, "training_acc": 60.0, "val_loss": 16.240030527114868, "val_acc": 28.0}
{"epoch": 2, "training_loss": 62.49802231788635, "training_acc": 72.0, "val_loss": 19.007112085819244, "val_acc": 72.0}
{"epoch": 3, "training_loss": 68.95876121520996, "training_acc": 72.0, "val_loss": 15.578791499137878, "val_acc": 28.0}
{"epoch": 4, "training_loss": 62.40667796134949, "training_acc": 72.0, "val_loss": 15.105029940605164, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.9981415271759, "training_acc": 72.0, "val_loss": 14.85031247138977, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.75321912765503, "training_acc": 72.0, "val_loss": 14.846065640449524, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.702675342559814, "training_acc": 72.0, "val_loss": 14.839132130146027, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.552528858184814, "training_acc": 72.0, "val_loss": 14.834529161453247, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.627482652664185, "training_acc": 72.0, "val_loss": 14.769305288791656, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.32828116416931, "training_acc": 72.0, "val_loss": 14.792010188102722, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.44501614570618, "training_acc": 72.0, "val_loss": 14.721976220607758, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.49929141998291, "training_acc": 72.0, "val_loss": 14.763614535331726, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.421963930130005, "training_acc": 72.0, "val_loss": 14.748035371303558, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.19135296344757, "training_acc": 72.0, "val_loss": 14.777539670467377, "val_acc": 72.0}
{"epoch": 15, "training_loss": 65.88033628463745, "training_acc": 72.0, "val_loss": 14.805091917514801, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.09407353401184, "training_acc": 72.0, "val_loss": 15.314558148384094, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.675286293029785, "training_acc": 72.0, "val_loss": 15.415766835212708, "val_acc": 28.0}
{"epoch": 18, "training_loss": 61.536277532577515, "training_acc": 72.0, "val_loss": 15.132425725460052, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.852778673172, "training_acc": 72.0, "val_loss": 14.851421117782593, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.712223052978516, "training_acc": 72.0, "val_loss": 14.804035425186157, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.41877746582031, "training_acc": 72.0, "val_loss": 14.80158120393753, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.47608494758606, "training_acc": 72.0, "val_loss": 14.802248775959015, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.31101679801941, "training_acc": 72.0, "val_loss": 14.816680550575256, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.551769971847534, "training_acc": 72.0, "val_loss": 14.765085279941559, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.00622916221619, "training_acc": 72.0, "val_loss": 14.851804077625275, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.426854372024536, "training_acc": 72.0, "val_loss": 14.827543497085571, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.19226789474487, "training_acc": 72.0, "val_loss": 14.748561382293701, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.92679524421692, "training_acc": 72.0, "val_loss": 14.787884056568146, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.1516592502594, "training_acc": 72.0, "val_loss": 14.773054420948029, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.061057567596436, "training_acc": 72.0, "val_loss": 14.715921878814697, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.803520917892456, "training_acc": 72.0, "val_loss": 14.695514738559723, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.547120094299316, "training_acc": 72.0, "val_loss": 14.652694761753082, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.48965263366699, "training_acc": 72.0, "val_loss": 14.655286073684692, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.37379837036133, "training_acc": 72.0, "val_loss": 15.108643472194672, "val_acc": 56.0}
{"epoch": 35, "training_loss": 60.04689049720764, "training_acc": 72.0, "val_loss": 14.712931215763092, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.706146240234375, "training_acc": 72.0, "val_loss": 14.695629477500916, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.75594961643219, "training_acc": 72.0, "val_loss": 14.694778621196747, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.50966238975525, "training_acc": 72.0, "val_loss": 14.68680053949356, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.84923183917999, "training_acc": 72.0, "val_loss": 14.580054581165314, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.007100343704224, "training_acc": 72.0, "val_loss": 14.506438374519348, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.37349486351013, "training_acc": 72.0, "val_loss": 14.527006447315216, "val_acc": 72.0}
{"epoch": 42, "training_loss": 56.85965323448181, "training_acc": 72.0, "val_loss": 15.433143079280853, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.44172525405884, "training_acc": 72.0, "val_loss": 14.697141945362091, "val_acc": 56.0}
{"epoch": 44, "training_loss": 58.72109270095825, "training_acc": 72.0, "val_loss": 14.815284311771393, "val_acc": 60.0}
{"epoch": 45, "training_loss": 57.90066123008728, "training_acc": 72.0, "val_loss": 14.773258566856384, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.11984133720398, "training_acc": 72.0, "val_loss": 14.541055262088776, "val_acc": 72.0}
{"epoch": 47, "training_loss": 56.4176025390625, "training_acc": 72.0, "val_loss": 14.524029195308685, "val_acc": 76.0}
{"epoch": 48, "training_loss": 57.70093560218811, "training_acc": 72.0, "val_loss": 14.378175139427185, "val_acc": 68.0}
{"epoch": 49, "training_loss": 56.145610094070435, "training_acc": 72.0, "val_loss": 14.690116047859192, "val_acc": 72.0}
{"epoch": 50, "training_loss": 56.96136832237244, "training_acc": 72.0, "val_loss": 14.230909943580627, "val_acc": 56.0}
{"epoch": 51, "training_loss": 55.252251863479614, "training_acc": 72.0, "val_loss": 14.14688527584076, "val_acc": 60.0}
{"epoch": 52, "training_loss": 55.40792965888977, "training_acc": 73.0, "val_loss": 14.951682090759277, "val_acc": 56.0}
{"epoch": 53, "training_loss": 60.88848829269409, "training_acc": 72.0, "val_loss": 14.113198220729828, "val_acc": 60.0}
{"epoch": 54, "training_loss": 52.94094467163086, "training_acc": 74.0, "val_loss": 14.071227610111237, "val_acc": 64.0}
{"epoch": 55, "training_loss": 55.63523864746094, "training_acc": 72.0, "val_loss": 14.083057641983032, "val_acc": 60.0}
{"epoch": 56, "training_loss": 54.52307987213135, "training_acc": 73.0, "val_loss": 14.281950891017914, "val_acc": 60.0}
{"epoch": 57, "training_loss": 54.50277876853943, "training_acc": 74.0, "val_loss": 14.478644728660583, "val_acc": 76.0}
{"epoch": 58, "training_loss": 52.618332266807556, "training_acc": 73.0, "val_loss": 14.174051582813263, "val_acc": 60.0}
{"epoch": 59, "training_loss": 53.15450930595398, "training_acc": 74.0, "val_loss": 16.371402144432068, "val_acc": 76.0}
{"epoch": 60, "training_loss": 59.786089181900024, "training_acc": 75.0, "val_loss": 14.329306781291962, "val_acc": 60.0}
{"epoch": 61, "training_loss": 52.547157287597656, "training_acc": 77.0, "val_loss": 15.872041881084442, "val_acc": 72.0}
{"epoch": 62, "training_loss": 61.14680004119873, "training_acc": 72.0, "val_loss": 14.17100578546524, "val_acc": 76.0}
{"epoch": 63, "training_loss": 54.929184913635254, "training_acc": 73.0, "val_loss": 15.02663791179657, "val_acc": 56.0}
{"epoch": 64, "training_loss": 58.78710865974426, "training_acc": 73.0, "val_loss": 14.740891754627228, "val_acc": 60.0}
{"epoch": 65, "training_loss": 58.02697968482971, "training_acc": 72.0, "val_loss": 14.302729070186615, "val_acc": 76.0}
{"epoch": 66, "training_loss": 56.27959370613098, "training_acc": 72.0, "val_loss": 14.319255948066711, "val_acc": 72.0}
{"epoch": 67, "training_loss": 56.59978675842285, "training_acc": 72.0, "val_loss": 14.205189049243927, "val_acc": 76.0}
{"epoch": 68, "training_loss": 55.1993248462677, "training_acc": 72.0, "val_loss": 14.110814034938812, "val_acc": 60.0}
{"epoch": 69, "training_loss": 54.19870340824127, "training_acc": 75.0, "val_loss": 14.06157910823822, "val_acc": 64.0}
{"epoch": 70, "training_loss": 53.789506912231445, "training_acc": 75.0, "val_loss": 14.362303912639618, "val_acc": 60.0}
{"epoch": 71, "training_loss": 52.62311673164368, "training_acc": 75.0, "val_loss": 19.24346536397934, "val_acc": 40.0}
{"epoch": 72, "training_loss": 65.78409266471863, "training_acc": 62.0, "val_loss": 16.32480025291443, "val_acc": 72.0}
{"epoch": 73, "training_loss": 62.96187901496887, "training_acc": 72.0, "val_loss": 14.648091793060303, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.32318329811096, "training_acc": 72.0, "val_loss": 14.539285004138947, "val_acc": 64.0}
{"epoch": 75, "training_loss": 58.401461124420166, "training_acc": 72.0, "val_loss": 14.794471859931946, "val_acc": 60.0}
{"epoch": 76, "training_loss": 58.35493040084839, "training_acc": 72.0, "val_loss": 14.58040326833725, "val_acc": 76.0}
{"epoch": 77, "training_loss": 57.76276135444641, "training_acc": 72.0, "val_loss": 14.457279443740845, "val_acc": 76.0}
{"epoch": 78, "training_loss": 57.09282350540161, "training_acc": 72.0, "val_loss": 14.363546669483185, "val_acc": 72.0}
{"epoch": 79, "training_loss": 56.43467116355896, "training_acc": 72.0, "val_loss": 14.265136420726776, "val_acc": 76.0}
{"epoch": 80, "training_loss": 55.60539197921753, "training_acc": 72.0, "val_loss": 14.187566936016083, "val_acc": 76.0}
{"epoch": 81, "training_loss": 55.39082336425781, "training_acc": 72.0, "val_loss": 14.17059451341629, "val_acc": 76.0}
{"epoch": 82, "training_loss": 54.20455026626587, "training_acc": 72.0, "val_loss": 14.045430719852448, "val_acc": 60.0}
{"epoch": 83, "training_loss": 54.972140312194824, "training_acc": 72.0, "val_loss": 13.931846618652344, "val_acc": 60.0}
{"epoch": 84, "training_loss": 53.40287709236145, "training_acc": 72.0, "val_loss": 15.239745378494263, "val_acc": 76.0}
{"epoch": 85, "training_loss": 55.00285482406616, "training_acc": 72.0, "val_loss": 14.758382737636566, "val_acc": 60.0}
{"epoch": 86, "training_loss": 60.90213465690613, "training_acc": 68.0, "val_loss": 15.32212346792221, "val_acc": 40.0}
{"epoch": 87, "training_loss": 58.19525861740112, "training_acc": 71.0, "val_loss": 14.435023069381714, "val_acc": 76.0}
{"epoch": 88, "training_loss": 63.28653287887573, "training_acc": 72.0, "val_loss": 15.583929419517517, "val_acc": 72.0}
{"epoch": 89, "training_loss": 58.81837844848633, "training_acc": 72.0, "val_loss": 14.173296093940735, "val_acc": 76.0}
{"epoch": 90, "training_loss": 56.15455675125122, "training_acc": 72.0, "val_loss": 14.713627099990845, "val_acc": 60.0}
{"epoch": 91, "training_loss": 58.95635962486267, "training_acc": 72.0, "val_loss": 14.939023554325104, "val_acc": 60.0}
{"epoch": 92, "training_loss": 59.63920617103577, "training_acc": 72.0, "val_loss": 14.767083525657654, "val_acc": 60.0}
{"epoch": 93, "training_loss": 58.146244049072266, "training_acc": 72.0, "val_loss": 14.544084668159485, "val_acc": 76.0}
{"epoch": 94, "training_loss": 57.60528635978699, "training_acc": 72.0, "val_loss": 14.40492868423462, "val_acc": 72.0}
{"epoch": 95, "training_loss": 57.03922998905182, "training_acc": 72.0, "val_loss": 14.381030201911926, "val_acc": 72.0}
{"epoch": 96, "training_loss": 57.33407998085022, "training_acc": 72.0, "val_loss": 14.370836317539215, "val_acc": 72.0}
{"epoch": 97, "training_loss": 56.87851405143738, "training_acc": 72.0, "val_loss": 14.228138327598572, "val_acc": 72.0}
{"epoch": 98, "training_loss": 55.95304012298584, "training_acc": 72.0, "val_loss": 14.156387746334076, "val_acc": 72.0}
{"epoch": 99, "training_loss": 55.523847341537476, "training_acc": 72.0, "val_loss": 14.086960256099701, "val_acc": 64.0}
{"epoch": 100, "training_loss": 54.839396715164185, "training_acc": 72.0, "val_loss": 14.072103798389435, "val_acc": 72.0}
{"epoch": 101, "training_loss": 53.168641090393066, "training_acc": 72.0, "val_loss": 14.227236807346344, "val_acc": 76.0}
{"epoch": 102, "training_loss": 53.78280508518219, "training_acc": 72.0, "val_loss": 14.085637032985687, "val_acc": 60.0}
