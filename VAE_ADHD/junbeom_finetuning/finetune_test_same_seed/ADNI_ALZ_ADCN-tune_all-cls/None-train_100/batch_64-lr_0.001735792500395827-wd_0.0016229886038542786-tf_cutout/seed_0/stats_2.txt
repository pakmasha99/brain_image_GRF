"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.72481083869934, "training_acc": 40.0, "val_loss": 14.860150218009949, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.92193150520325, "training_acc": 72.0, "val_loss": 15.32643735408783, "val_acc": 72.0}
{"epoch": 2, "training_loss": 61.02655386924744, "training_acc": 72.0, "val_loss": 14.917734265327454, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.43940734863281, "training_acc": 72.0, "val_loss": 14.867348968982697, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.62031579017639, "training_acc": 72.0, "val_loss": 14.86862599849701, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.565884590148926, "training_acc": 72.0, "val_loss": 14.82485830783844, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.19148826599121, "training_acc": 72.0, "val_loss": 15.004178881645203, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.074119567871094, "training_acc": 72.0, "val_loss": 14.895609021186829, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.46267342567444, "training_acc": 72.0, "val_loss": 14.828050136566162, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.76529049873352, "training_acc": 72.0, "val_loss": 14.824798703193665, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.80268406867981, "training_acc": 72.0, "val_loss": 14.84954059123993, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.687798261642456, "training_acc": 72.0, "val_loss": 14.824599027633667, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.3587851524353, "training_acc": 72.0, "val_loss": 14.82553482055664, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.31403660774231, "training_acc": 72.0, "val_loss": 14.837460219860077, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.349446535110474, "training_acc": 72.0, "val_loss": 14.84881043434143, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.46017909049988, "training_acc": 72.0, "val_loss": 14.836730062961578, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.47459697723389, "training_acc": 72.0, "val_loss": 14.827291667461395, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.292327642440796, "training_acc": 72.0, "val_loss": 14.847998321056366, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.75914907455444, "training_acc": 72.0, "val_loss": 14.919586479663849, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.609261989593506, "training_acc": 72.0, "val_loss": 14.829975366592407, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.323846101760864, "training_acc": 72.0, "val_loss": 14.849695563316345, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.79084038734436, "training_acc": 72.0, "val_loss": 14.856977760791779, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.30417728424072, "training_acc": 72.0, "val_loss": 14.836587011814117, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.39926099777222, "training_acc": 72.0, "val_loss": 14.906561374664307, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.711517095565796, "training_acc": 72.0, "val_loss": 14.856672286987305, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.29334545135498, "training_acc": 72.0, "val_loss": 14.850601553916931, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.37132382392883, "training_acc": 72.0, "val_loss": 14.935298264026642, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.74420094490051, "training_acc": 72.0, "val_loss": 14.918303489685059, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.586058139801025, "training_acc": 72.0, "val_loss": 14.825868606567383, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.23403477668762, "training_acc": 72.0, "val_loss": 14.866147935390472, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.50938105583191, "training_acc": 72.0, "val_loss": 14.896409213542938, "val_acc": 72.0}
