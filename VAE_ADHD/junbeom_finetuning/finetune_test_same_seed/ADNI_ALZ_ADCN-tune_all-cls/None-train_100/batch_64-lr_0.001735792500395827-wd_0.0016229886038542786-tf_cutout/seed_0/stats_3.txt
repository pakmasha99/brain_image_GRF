"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.55332207679749, "training_acc": 53.0, "val_loss": 15.015311539173126, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.05676865577698, "training_acc": 72.0, "val_loss": 16.118676960468292, "val_acc": 72.0}
{"epoch": 2, "training_loss": 63.016082525253296, "training_acc": 72.0, "val_loss": 14.86874669790268, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.261523962020874, "training_acc": 72.0, "val_loss": 14.953890442848206, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.13562631607056, "training_acc": 72.0, "val_loss": 14.908427000045776, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.62192916870117, "training_acc": 72.0, "val_loss": 14.860343933105469, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.39817690849304, "training_acc": 72.0, "val_loss": 14.826278388500214, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.43517470359802, "training_acc": 72.0, "val_loss": 14.87443894147873, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.58593487739563, "training_acc": 72.0, "val_loss": 14.92038369178772, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.67615222930908, "training_acc": 72.0, "val_loss": 14.875632524490356, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.69719696044922, "training_acc": 72.0, "val_loss": 14.823997020721436, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.30925011634827, "training_acc": 72.0, "val_loss": 14.824861288070679, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.451403856277466, "training_acc": 72.0, "val_loss": 14.837834239006042, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.376201152801514, "training_acc": 72.0, "val_loss": 14.894619584083557, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.73316955566406, "training_acc": 72.0, "val_loss": 14.88724946975708, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.38462448120117, "training_acc": 72.0, "val_loss": 14.836648106575012, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.42281889915466, "training_acc": 72.0, "val_loss": 14.929422736167908, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.77703380584717, "training_acc": 72.0, "val_loss": 14.843760430812836, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.18122100830078, "training_acc": 72.0, "val_loss": 14.897577464580536, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.56314468383789, "training_acc": 72.0, "val_loss": 15.11160284280777, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.51752972602844, "training_acc": 72.0, "val_loss": 14.926543831825256, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.590161085128784, "training_acc": 72.0, "val_loss": 14.82415497303009, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.24349856376648, "training_acc": 72.0, "val_loss": 14.893220365047455, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.00709080696106, "training_acc": 72.0, "val_loss": 14.882458746433258, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.45744252204895, "training_acc": 72.0, "val_loss": 14.85067754983902, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.40490460395813, "training_acc": 72.0, "val_loss": 14.925646781921387, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.77953267097473, "training_acc": 72.0, "val_loss": 14.845672249794006, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.23277235031128, "training_acc": 72.0, "val_loss": 14.88570123910904, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.76487398147583, "training_acc": 72.0, "val_loss": 14.952993392944336, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.715760469436646, "training_acc": 72.0, "val_loss": 14.829134941101074, "val_acc": 72.0}
