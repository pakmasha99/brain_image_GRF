"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 72.47343277931213, "training_acc": 35.0, "val_loss": 16.83206558227539, "val_acc": 28.0}
{"epoch": 1, "training_loss": 66.78919911384583, "training_acc": 72.0, "val_loss": 15.431222319602966, "val_acc": 28.0}
{"epoch": 2, "training_loss": 60.76622247695923, "training_acc": 72.0, "val_loss": 14.838802814483643, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.256877422332764, "training_acc": 72.0, "val_loss": 14.892531931400299, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.69543504714966, "training_acc": 72.0, "val_loss": 14.86714780330658, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.56280851364136, "training_acc": 72.0, "val_loss": 14.831739664077759, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.47065556049347, "training_acc": 72.0, "val_loss": 14.849649369716644, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.503133058547974, "training_acc": 72.0, "val_loss": 14.891840517520905, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.48775029182434, "training_acc": 72.0, "val_loss": 14.835260808467865, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.27315616607666, "training_acc": 72.0, "val_loss": 14.82764333486557, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.57081842422485, "training_acc": 72.0, "val_loss": 14.835768938064575, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.24588441848755, "training_acc": 72.0, "val_loss": 14.836385846138, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.28397035598755, "training_acc": 72.0, "val_loss": 14.847584068775177, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.35809254646301, "training_acc": 72.0, "val_loss": 14.838749170303345, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.26497769355774, "training_acc": 72.0, "val_loss": 14.837107062339783, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.601489782333374, "training_acc": 72.0, "val_loss": 14.8408442735672, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.53884840011597, "training_acc": 72.0, "val_loss": 14.837925136089325, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.374420166015625, "training_acc": 72.0, "val_loss": 14.833703637123108, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.205796241760254, "training_acc": 72.0, "val_loss": 14.832563698291779, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.37339234352112, "training_acc": 72.0, "val_loss": 14.844003319740295, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.29932379722595, "training_acc": 72.0, "val_loss": 14.830282330513, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.25494885444641, "training_acc": 72.0, "val_loss": 14.828464388847351, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.32731294631958, "training_acc": 72.0, "val_loss": 14.82928842306137, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.26830744743347, "training_acc": 72.0, "val_loss": 14.837318658828735, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.254364013671875, "training_acc": 72.0, "val_loss": 14.835821092128754, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.23267960548401, "training_acc": 72.0, "val_loss": 14.833472669124603, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.28263831138611, "training_acc": 72.0, "val_loss": 14.833706617355347, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.29882764816284, "training_acc": 72.0, "val_loss": 14.83309119939804, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.219653367996216, "training_acc": 72.0, "val_loss": 14.842189848423004, "val_acc": 72.0}
