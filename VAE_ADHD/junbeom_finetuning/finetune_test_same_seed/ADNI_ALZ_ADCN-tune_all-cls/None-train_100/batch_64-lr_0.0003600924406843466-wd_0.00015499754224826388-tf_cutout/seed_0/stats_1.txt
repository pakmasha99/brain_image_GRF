"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.75144290924072, "training_acc": 72.0, "val_loss": 15.041141211986542, "val_acc": 72.0}
{"epoch": 1, "training_loss": 75.71498441696167, "training_acc": 52.0, "val_loss": 15.999488532543182, "val_acc": 72.0}
{"epoch": 2, "training_loss": 64.90082097053528, "training_acc": 72.0, "val_loss": 15.31556099653244, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.953588008880615, "training_acc": 72.0, "val_loss": 14.884617924690247, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.71442103385925, "training_acc": 72.0, "val_loss": 14.979815483093262, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.02401161193848, "training_acc": 72.0, "val_loss": 14.93573933839798, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.81286931037903, "training_acc": 72.0, "val_loss": 14.972813427448273, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.78493142127991, "training_acc": 72.0, "val_loss": 14.913830161094666, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.65967321395874, "training_acc": 72.0, "val_loss": 14.771468937397003, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.17720031738281, "training_acc": 72.0, "val_loss": 14.94101732969284, "val_acc": 72.0}
{"epoch": 10, "training_loss": 61.109060287475586, "training_acc": 72.0, "val_loss": 14.928790926933289, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.916157960891724, "training_acc": 72.0, "val_loss": 14.942331612110138, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.54128801822662, "training_acc": 72.0, "val_loss": 14.709755778312683, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.27830719947815, "training_acc": 72.0, "val_loss": 14.692451059818268, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.8197557926178, "training_acc": 72.0, "val_loss": 14.667436480522156, "val_acc": 72.0}
{"epoch": 15, "training_loss": 58.521605491638184, "training_acc": 72.0, "val_loss": 14.645259082317352, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.55307459831238, "training_acc": 72.0, "val_loss": 14.642271399497986, "val_acc": 72.0}
{"epoch": 17, "training_loss": 57.738365650177, "training_acc": 72.0, "val_loss": 14.499625563621521, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.835057973861694, "training_acc": 72.0, "val_loss": 14.371401071548462, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.9948308467865, "training_acc": 72.0, "val_loss": 14.714212715625763, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.62799954414368, "training_acc": 72.0, "val_loss": 15.02210944890976, "val_acc": 72.0}
{"epoch": 21, "training_loss": 60.11953091621399, "training_acc": 72.0, "val_loss": 15.085634589195251, "val_acc": 72.0}
{"epoch": 22, "training_loss": 61.581406354904175, "training_acc": 72.0, "val_loss": 14.861351251602173, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.48205280303955, "training_acc": 72.0, "val_loss": 15.150405466556549, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.69844126701355, "training_acc": 72.0, "val_loss": 14.892861247062683, "val_acc": 72.0}
{"epoch": 25, "training_loss": 60.41149950027466, "training_acc": 72.0, "val_loss": 14.820510149002075, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.703266620635986, "training_acc": 72.0, "val_loss": 14.806531369686127, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.484522342681885, "training_acc": 72.0, "val_loss": 14.844782650470734, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.577354192733765, "training_acc": 72.0, "val_loss": 14.803846180438995, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.352532625198364, "training_acc": 72.0, "val_loss": 14.734499156475067, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.1767897605896, "training_acc": 72.0, "val_loss": 14.716611802577972, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.057037353515625, "training_acc": 72.0, "val_loss": 14.684222638607025, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.831180810928345, "training_acc": 72.0, "val_loss": 14.672966301441193, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.04786038398743, "training_acc": 72.0, "val_loss": 14.571619033813477, "val_acc": 72.0}
{"epoch": 34, "training_loss": 58.37709927558899, "training_acc": 72.0, "val_loss": 14.506062865257263, "val_acc": 72.0}
{"epoch": 35, "training_loss": 61.32010340690613, "training_acc": 72.0, "val_loss": 14.50674682855606, "val_acc": 72.0}
{"epoch": 36, "training_loss": 65.12347364425659, "training_acc": 72.0, "val_loss": 14.918699860572815, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.03604865074158, "training_acc": 72.0, "val_loss": 14.984188973903656, "val_acc": 72.0}
