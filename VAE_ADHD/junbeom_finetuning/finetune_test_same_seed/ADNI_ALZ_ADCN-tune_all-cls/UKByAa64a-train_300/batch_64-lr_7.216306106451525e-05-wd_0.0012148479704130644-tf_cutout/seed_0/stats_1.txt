"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 173.66586112976074, "training_acc": 72.33333333333333, "val_loss": 43.59977596998215, "val_acc": 57.333333333333336}
{"epoch": 1, "training_loss": 223.23719000816345, "training_acc": 71.0, "val_loss": 45.77907955646515, "val_acc": 54.666666666666664}
{"epoch": 2, "training_loss": 182.0656123161316, "training_acc": 72.33333333333333, "val_loss": 44.308064579963684, "val_acc": 72.0}
{"epoch": 3, "training_loss": 173.76971888542175, "training_acc": 72.33333333333333, "val_loss": 43.57749181985855, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 169.77366876602173, "training_acc": 72.33333333333333, "val_loss": 45.4362416267395, "val_acc": 56.0}
{"epoch": 5, "training_loss": 168.7409257888794, "training_acc": 73.33333333333333, "val_loss": 42.936032354831696, "val_acc": 68.0}
{"epoch": 6, "training_loss": 157.07771801948547, "training_acc": 73.66666666666667, "val_loss": 44.9630651473999, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 154.0741937160492, "training_acc": 73.66666666666667, "val_loss": 45.28816419839859, "val_acc": 58.666666666666664}
{"epoch": 8, "training_loss": 152.57139801979065, "training_acc": 74.33333333333333, "val_loss": 45.254845678806305, "val_acc": 64.0}
{"epoch": 9, "training_loss": 150.39271664619446, "training_acc": 75.66666666666667, "val_loss": 45.9103539288044, "val_acc": 65.33333333333333}
{"epoch": 10, "training_loss": 157.67600965499878, "training_acc": 74.0, "val_loss": 44.8496053814888, "val_acc": 64.0}
{"epoch": 11, "training_loss": 152.30444169044495, "training_acc": 76.0, "val_loss": 43.66000083088875, "val_acc": 58.666666666666664}
{"epoch": 12, "training_loss": 152.56706535816193, "training_acc": 75.66666666666667, "val_loss": 43.807329177856445, "val_acc": 65.33333333333333}
{"epoch": 13, "training_loss": 151.57997059822083, "training_acc": 75.66666666666667, "val_loss": 51.24723172187805, "val_acc": 72.0}
{"epoch": 14, "training_loss": 166.45469665527344, "training_acc": 73.33333333333333, "val_loss": 46.02286809682846, "val_acc": 60.0}
{"epoch": 15, "training_loss": 157.19089603424072, "training_acc": 77.33333333333333, "val_loss": 45.28837329149246, "val_acc": 72.0}
{"epoch": 16, "training_loss": 159.6068000793457, "training_acc": 72.0, "val_loss": 44.758405685424805, "val_acc": 60.0}
{"epoch": 17, "training_loss": 149.85752034187317, "training_acc": 76.0, "val_loss": 45.32904523611069, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 148.2041358947754, "training_acc": 77.0, "val_loss": 45.17722314596176, "val_acc": 66.66666666666667}
{"epoch": 19, "training_loss": 150.6304166316986, "training_acc": 72.0, "val_loss": 44.396052807569504, "val_acc": 61.333333333333336}
{"epoch": 20, "training_loss": 144.51275849342346, "training_acc": 76.0, "val_loss": 42.87460422515869, "val_acc": 61.333333333333336}
{"epoch": 21, "training_loss": 146.39033675193787, "training_acc": 77.66666666666667, "val_loss": 43.89158076047897, "val_acc": 66.66666666666667}
{"epoch": 22, "training_loss": 140.1705391407013, "training_acc": 78.0, "val_loss": 44.38751882314682, "val_acc": 57.333333333333336}
{"epoch": 23, "training_loss": 137.25545036792755, "training_acc": 79.33333333333333, "val_loss": 47.152435302734375, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 141.22272741794586, "training_acc": 79.66666666666667, "val_loss": 45.58583736419678, "val_acc": 74.66666666666667}
{"epoch": 25, "training_loss": 146.53333139419556, "training_acc": 76.0, "val_loss": 43.44407856464386, "val_acc": 66.66666666666667}
{"epoch": 26, "training_loss": 157.43524825572968, "training_acc": 74.66666666666667, "val_loss": 44.83510226011276, "val_acc": 60.0}
{"epoch": 27, "training_loss": 156.03704261779785, "training_acc": 75.66666666666667, "val_loss": 44.39119732379913, "val_acc": 72.0}
{"epoch": 28, "training_loss": 146.25216817855835, "training_acc": 77.33333333333333, "val_loss": 43.409039080142975, "val_acc": 61.333333333333336}
{"epoch": 29, "training_loss": 144.01182639598846, "training_acc": 78.33333333333333, "val_loss": 44.97966402769089, "val_acc": 60.0}
{"epoch": 30, "training_loss": 149.77433729171753, "training_acc": 75.33333333333333, "val_loss": 48.33652102947235, "val_acc": 72.0}
{"epoch": 31, "training_loss": 143.41950130462646, "training_acc": 75.0, "val_loss": 47.82812350988388, "val_acc": 56.0}
{"epoch": 32, "training_loss": 147.7646552324295, "training_acc": 76.0, "val_loss": 45.999189615249634, "val_acc": 74.66666666666667}
{"epoch": 33, "training_loss": 132.15327656269073, "training_acc": 82.33333333333333, "val_loss": 44.114371597766876, "val_acc": 60.0}
{"epoch": 34, "training_loss": 141.04490399360657, "training_acc": 79.0, "val_loss": 48.335896015167236, "val_acc": 56.0}
{"epoch": 35, "training_loss": 142.80080676078796, "training_acc": 78.66666666666667, "val_loss": 46.076670825481415, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 149.5627738237381, "training_acc": 73.66666666666667, "val_loss": 48.37924766540527, "val_acc": 72.0}
{"epoch": 37, "training_loss": 149.4807484149933, "training_acc": 75.0, "val_loss": 45.805369317531586, "val_acc": 56.0}
{"epoch": 38, "training_loss": 148.4742751121521, "training_acc": 80.0, "val_loss": 46.692243576049805, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 146.05201184749603, "training_acc": 78.33333333333333, "val_loss": 43.90130287408829, "val_acc": 69.33333333333333}
