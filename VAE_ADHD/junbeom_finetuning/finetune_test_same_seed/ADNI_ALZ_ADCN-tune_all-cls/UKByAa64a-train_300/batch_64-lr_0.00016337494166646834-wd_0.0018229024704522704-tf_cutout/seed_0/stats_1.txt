"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 166.45420622825623, "training_acc": 73.0, "val_loss": 70.29577267169952, "val_acc": 28.0}
{"epoch": 1, "training_loss": 220.57052993774414, "training_acc": 64.0, "val_loss": 44.00256532430649, "val_acc": 72.0}
{"epoch": 2, "training_loss": 176.87096858024597, "training_acc": 72.33333333333333, "val_loss": 45.277995735406876, "val_acc": 72.0}
{"epoch": 3, "training_loss": 180.53056359291077, "training_acc": 72.33333333333333, "val_loss": 44.96450561285019, "val_acc": 65.33333333333333}
{"epoch": 4, "training_loss": 173.76761746406555, "training_acc": 72.33333333333333, "val_loss": 44.49560087919235, "val_acc": 72.0}
{"epoch": 5, "training_loss": 167.22420477867126, "training_acc": 72.33333333333333, "val_loss": 43.4030818939209, "val_acc": 69.33333333333333}
{"epoch": 6, "training_loss": 161.10348224639893, "training_acc": 74.33333333333333, "val_loss": 48.879981219768524, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 178.46498847007751, "training_acc": 67.0, "val_loss": 47.66469019651413, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 172.42061233520508, "training_acc": 72.33333333333333, "val_loss": 43.7485089302063, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 168.69984006881714, "training_acc": 72.33333333333333, "val_loss": 43.66778028011322, "val_acc": 69.33333333333333}
{"epoch": 10, "training_loss": 161.59085988998413, "training_acc": 72.33333333333333, "val_loss": 42.58928793668747, "val_acc": 62.666666666666664}
{"epoch": 11, "training_loss": 159.93704652786255, "training_acc": 75.0, "val_loss": 42.922940731048584, "val_acc": 61.333333333333336}
{"epoch": 12, "training_loss": 160.63862252235413, "training_acc": 71.0, "val_loss": 43.321571826934814, "val_acc": 60.0}
{"epoch": 13, "training_loss": 159.64277172088623, "training_acc": 72.66666666666667, "val_loss": 42.62372148036957, "val_acc": 65.33333333333333}
{"epoch": 14, "training_loss": 161.0292136669159, "training_acc": 73.33333333333333, "val_loss": 42.93141680955887, "val_acc": 65.33333333333333}
{"epoch": 15, "training_loss": 155.28026628494263, "training_acc": 73.0, "val_loss": 43.240403056144714, "val_acc": 61.333333333333336}
{"epoch": 16, "training_loss": 151.61962604522705, "training_acc": 77.66666666666667, "val_loss": 53.73907107114792, "val_acc": 69.33333333333333}
{"epoch": 17, "training_loss": 158.30024671554565, "training_acc": 75.0, "val_loss": 45.39441365003586, "val_acc": 58.666666666666664}
{"epoch": 18, "training_loss": 160.35108482837677, "training_acc": 76.66666666666667, "val_loss": 45.387125104665756, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 159.52692413330078, "training_acc": 75.0, "val_loss": 44.75076115131378, "val_acc": 58.666666666666664}
{"epoch": 20, "training_loss": 162.94008088111877, "training_acc": 72.66666666666667, "val_loss": 45.381593465805054, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 157.6550350189209, "training_acc": 75.0, "val_loss": 43.71928381919861, "val_acc": 58.666666666666664}
{"epoch": 22, "training_loss": 158.12312030792236, "training_acc": 74.0, "val_loss": 44.05484676361084, "val_acc": 61.333333333333336}
{"epoch": 23, "training_loss": 162.5672196149826, "training_acc": 72.33333333333333, "val_loss": 46.65283954143524, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 161.7524642944336, "training_acc": 73.0, "val_loss": 43.428275644779205, "val_acc": 60.0}
{"epoch": 25, "training_loss": 171.03721499443054, "training_acc": 76.33333333333333, "val_loss": 43.599226891994476, "val_acc": 64.0}
{"epoch": 26, "training_loss": 166.64735889434814, "training_acc": 73.0, "val_loss": 45.293248653411865, "val_acc": 69.33333333333333}
{"epoch": 27, "training_loss": 161.76567459106445, "training_acc": 72.66666666666667, "val_loss": 42.70689803361893, "val_acc": 66.66666666666667}
{"epoch": 28, "training_loss": 154.99192333221436, "training_acc": 74.0, "val_loss": 50.52656376361847, "val_acc": 68.0}
{"epoch": 29, "training_loss": 166.07500863075256, "training_acc": 72.0, "val_loss": 43.11013174057007, "val_acc": 60.0}
