"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 184.3638665676117, "training_acc": 71.0, "val_loss": 44.215646147727966, "val_acc": 68.0}
{"epoch": 1, "training_loss": 495.5737807750702, "training_acc": 58.333333333333336, "val_loss": 43.680694937705994, "val_acc": 72.0}
{"epoch": 2, "training_loss": 182.0196716785431, "training_acc": 72.33333333333333, "val_loss": 54.275001525878906, "val_acc": 28.0}
{"epoch": 3, "training_loss": 196.5183880329132, "training_acc": 64.33333333333333, "val_loss": 44.75812250375748, "val_acc": 72.0}
{"epoch": 4, "training_loss": 178.42685675621033, "training_acc": 72.33333333333333, "val_loss": 43.8202338218689, "val_acc": 72.0}
{"epoch": 5, "training_loss": 176.06165051460266, "training_acc": 72.33333333333333, "val_loss": 44.422496914863586, "val_acc": 72.0}
{"epoch": 6, "training_loss": 177.86329245567322, "training_acc": 72.33333333333333, "val_loss": 43.61945140361786, "val_acc": 72.0}
{"epoch": 7, "training_loss": 172.5524560213089, "training_acc": 72.33333333333333, "val_loss": 43.97290617227554, "val_acc": 72.0}
{"epoch": 8, "training_loss": 178.85747289657593, "training_acc": 72.33333333333333, "val_loss": 42.08346927165985, "val_acc": 72.0}
{"epoch": 9, "training_loss": 174.50259160995483, "training_acc": 72.33333333333333, "val_loss": 42.66308772563934, "val_acc": 72.0}
{"epoch": 10, "training_loss": 175.83405256271362, "training_acc": 72.33333333333333, "val_loss": 42.542178213596344, "val_acc": 72.0}
{"epoch": 11, "training_loss": 173.26827001571655, "training_acc": 72.33333333333333, "val_loss": 41.76284930109978, "val_acc": 72.0}
{"epoch": 12, "training_loss": 172.74962258338928, "training_acc": 72.33333333333333, "val_loss": 39.70350447297096, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 168.112340092659, "training_acc": 72.33333333333333, "val_loss": 46.51434197276831, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.01490783691406, "training_acc": 73.0, "val_loss": 40.0478737950325, "val_acc": 78.66666666666667}
{"epoch": 15, "training_loss": 168.30144596099854, "training_acc": 72.0, "val_loss": 39.43610209226608, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 166.63765168190002, "training_acc": 71.0, "val_loss": 44.16213309764862, "val_acc": 72.0}
{"epoch": 17, "training_loss": 186.9313187599182, "training_acc": 70.66666666666667, "val_loss": 41.784679889678955, "val_acc": 64.0}
{"epoch": 18, "training_loss": 169.48098242282867, "training_acc": 73.66666666666667, "val_loss": 43.13653123378754, "val_acc": 72.0}
{"epoch": 19, "training_loss": 175.12610054016113, "training_acc": 72.33333333333333, "val_loss": 42.579380720853806, "val_acc": 72.0}
{"epoch": 20, "training_loss": 172.2913944721222, "training_acc": 72.33333333333333, "val_loss": 42.04644864797592, "val_acc": 76.0}
{"epoch": 21, "training_loss": 170.3991231918335, "training_acc": 72.33333333333333, "val_loss": 41.591592878103256, "val_acc": 72.0}
{"epoch": 22, "training_loss": 168.90764343738556, "training_acc": 72.33333333333333, "val_loss": 39.07239156961441, "val_acc": 80.0}
{"epoch": 23, "training_loss": 171.0676667690277, "training_acc": 72.33333333333333, "val_loss": 39.35919088125229, "val_acc": 78.66666666666667}
{"epoch": 24, "training_loss": 171.2157280445099, "training_acc": 72.0, "val_loss": 40.089692771434784, "val_acc": 72.0}
{"epoch": 25, "training_loss": 167.23502469062805, "training_acc": 72.33333333333333, "val_loss": 38.93343198299408, "val_acc": 74.66666666666667}
{"epoch": 26, "training_loss": 163.43917572498322, "training_acc": 72.33333333333333, "val_loss": 38.01181477308273, "val_acc": 74.66666666666667}
{"epoch": 27, "training_loss": 169.17621207237244, "training_acc": 70.0, "val_loss": 36.21323227882385, "val_acc": 80.0}
{"epoch": 28, "training_loss": 167.5287914276123, "training_acc": 72.0, "val_loss": 39.934116780757904, "val_acc": 62.666666666666664}
{"epoch": 29, "training_loss": 170.9154440164566, "training_acc": 72.66666666666667, "val_loss": 42.33057337999344, "val_acc": 72.0}
{"epoch": 30, "training_loss": 177.66741132736206, "training_acc": 72.33333333333333, "val_loss": 40.32718461751938, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 170.1723117828369, "training_acc": 72.33333333333333, "val_loss": 40.63678455352783, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 167.60959029197693, "training_acc": 72.33333333333333, "val_loss": 40.49058640003204, "val_acc": 72.0}
{"epoch": 33, "training_loss": 165.6091570854187, "training_acc": 72.33333333333333, "val_loss": 38.2219820022583, "val_acc": 78.66666666666667}
{"epoch": 34, "training_loss": 164.74562430381775, "training_acc": 72.0, "val_loss": 37.148371517658234, "val_acc": 80.0}
{"epoch": 35, "training_loss": 171.2609715461731, "training_acc": 68.0, "val_loss": 42.439263582229614, "val_acc": 72.0}
{"epoch": 36, "training_loss": 178.299658536911, "training_acc": 72.33333333333333, "val_loss": 39.73426607251167, "val_acc": 78.66666666666667}
{"epoch": 37, "training_loss": 168.86647057533264, "training_acc": 72.33333333333333, "val_loss": 39.528571009635925, "val_acc": 74.66666666666667}
{"epoch": 38, "training_loss": 164.90801358222961, "training_acc": 72.33333333333333, "val_loss": 40.55008411407471, "val_acc": 72.0}
{"epoch": 39, "training_loss": 163.11289191246033, "training_acc": 72.66666666666667, "val_loss": 38.012477070093155, "val_acc": 78.66666666666667}
{"epoch": 40, "training_loss": 163.600891828537, "training_acc": 72.66666666666667, "val_loss": 37.43087637424469, "val_acc": 76.0}
{"epoch": 41, "training_loss": 159.74018049240112, "training_acc": 72.0, "val_loss": 36.353362917900085, "val_acc": 78.66666666666667}
{"epoch": 42, "training_loss": 163.5113422870636, "training_acc": 74.0, "val_loss": 37.0869859457016, "val_acc": 74.66666666666667}
{"epoch": 43, "training_loss": 167.65535950660706, "training_acc": 74.33333333333333, "val_loss": 38.05758583545685, "val_acc": 76.0}
{"epoch": 44, "training_loss": 167.24335551261902, "training_acc": 75.0, "val_loss": 39.07446309924126, "val_acc": 74.66666666666667}
{"epoch": 45, "training_loss": 163.06757402420044, "training_acc": 72.33333333333333, "val_loss": 37.891159147024155, "val_acc": 76.0}
{"epoch": 46, "training_loss": 161.60287749767303, "training_acc": 71.66666666666667, "val_loss": 39.85087072849274, "val_acc": 74.66666666666667}
