"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 188.86401796340942, "training_acc": 64.0, "val_loss": 44.52852392196655, "val_acc": 72.0}
{"epoch": 1, "training_loss": 177.1269347667694, "training_acc": 72.33333333333333, "val_loss": 45.982711017131805, "val_acc": 72.0}
{"epoch": 2, "training_loss": 180.33318161964417, "training_acc": 72.33333333333333, "val_loss": 44.55133697390556, "val_acc": 72.0}
{"epoch": 3, "training_loss": 177.69546461105347, "training_acc": 72.33333333333333, "val_loss": 44.47483915090561, "val_acc": 72.0}
{"epoch": 4, "training_loss": 177.84033155441284, "training_acc": 72.33333333333333, "val_loss": 44.47120988368988, "val_acc": 72.0}
{"epoch": 5, "training_loss": 176.72998976707458, "training_acc": 72.33333333333333, "val_loss": 44.68014931678772, "val_acc": 72.0}
{"epoch": 6, "training_loss": 178.21474623680115, "training_acc": 72.33333333333333, "val_loss": 44.512999296188354, "val_acc": 72.0}
{"epoch": 7, "training_loss": 177.19629049301147, "training_acc": 72.33333333333333, "val_loss": 44.49623912572861, "val_acc": 72.0}
{"epoch": 8, "training_loss": 177.69824385643005, "training_acc": 72.33333333333333, "val_loss": 44.473733365535736, "val_acc": 72.0}
{"epoch": 9, "training_loss": 177.0008144378662, "training_acc": 72.33333333333333, "val_loss": 44.53504145145416, "val_acc": 72.0}
{"epoch": 10, "training_loss": 179.70938563346863, "training_acc": 72.33333333333333, "val_loss": 44.51756328344345, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.0334906578064, "training_acc": 72.33333333333333, "val_loss": 44.544207751750946, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.36091375350952, "training_acc": 72.33333333333333, "val_loss": 44.46915948390961, "val_acc": 72.0}
{"epoch": 13, "training_loss": 178.42284560203552, "training_acc": 72.33333333333333, "val_loss": 44.52738273143768, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.36088299751282, "training_acc": 72.33333333333333, "val_loss": 44.527049005031586, "val_acc": 72.0}
{"epoch": 15, "training_loss": 177.7139437198639, "training_acc": 72.33333333333333, "val_loss": 44.50939095020294, "val_acc": 72.0}
{"epoch": 16, "training_loss": 177.40634274482727, "training_acc": 72.33333333333333, "val_loss": 44.60291966795921, "val_acc": 72.0}
{"epoch": 17, "training_loss": 177.6191816329956, "training_acc": 72.33333333333333, "val_loss": 44.488996505737305, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.93722224235535, "training_acc": 72.33333333333333, "val_loss": 44.526761412620544, "val_acc": 72.0}
{"epoch": 19, "training_loss": 177.42732572555542, "training_acc": 72.33333333333333, "val_loss": 44.47102764248848, "val_acc": 72.0}
{"epoch": 20, "training_loss": 179.2588393688202, "training_acc": 72.33333333333333, "val_loss": 44.496171951293945, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.09922456741333, "training_acc": 72.33333333333333, "val_loss": 44.708374321460724, "val_acc": 72.0}
{"epoch": 22, "training_loss": 177.8857991695404, "training_acc": 72.33333333333333, "val_loss": 44.69625821709633, "val_acc": 72.0}
{"epoch": 23, "training_loss": 177.54536485671997, "training_acc": 72.33333333333333, "val_loss": 44.483978390693665, "val_acc": 72.0}
{"epoch": 24, "training_loss": 177.1599156856537, "training_acc": 72.33333333333333, "val_loss": 44.47032022476196, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.18473386764526, "training_acc": 72.33333333333333, "val_loss": 44.50439330935478, "val_acc": 72.0}
{"epoch": 26, "training_loss": 177.465313911438, "training_acc": 72.33333333333333, "val_loss": 44.473315715789795, "val_acc": 72.0}
{"epoch": 27, "training_loss": 177.4830231666565, "training_acc": 72.33333333333333, "val_loss": 44.50360727310181, "val_acc": 72.0}
{"epoch": 28, "training_loss": 176.88890862464905, "training_acc": 72.33333333333333, "val_loss": 44.493765115737915, "val_acc": 72.0}
{"epoch": 29, "training_loss": 177.48309111595154, "training_acc": 72.33333333333333, "val_loss": 44.56071117520332, "val_acc": 72.0}
{"epoch": 30, "training_loss": 177.05575156211853, "training_acc": 72.33333333333333, "val_loss": 44.475346088409424, "val_acc": 72.0}
{"epoch": 31, "training_loss": 177.09775114059448, "training_acc": 72.33333333333333, "val_loss": 44.470669746398926, "val_acc": 72.0}
