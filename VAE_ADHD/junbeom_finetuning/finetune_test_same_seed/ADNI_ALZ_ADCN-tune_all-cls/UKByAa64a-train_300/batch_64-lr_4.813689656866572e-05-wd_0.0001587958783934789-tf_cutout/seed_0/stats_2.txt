"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 180.35015964508057, "training_acc": 73.0, "val_loss": 45.91204386949539, "val_acc": 46.666666666666664}
{"epoch": 1, "training_loss": 170.70790934562683, "training_acc": 74.0, "val_loss": 43.942686438560486, "val_acc": 72.0}
{"epoch": 2, "training_loss": 156.91315054893494, "training_acc": 74.33333333333333, "val_loss": 50.44648575782776, "val_acc": 44.0}
{"epoch": 3, "training_loss": 167.79610681533813, "training_acc": 72.66666666666667, "val_loss": 43.03861528635025, "val_acc": 65.33333333333333}
{"epoch": 4, "training_loss": 159.38279819488525, "training_acc": 74.0, "val_loss": 43.49535018205643, "val_acc": 70.66666666666667}
{"epoch": 5, "training_loss": 151.947368144989, "training_acc": 73.66666666666667, "val_loss": 43.85231637954712, "val_acc": 68.0}
{"epoch": 6, "training_loss": 156.55746054649353, "training_acc": 72.66666666666667, "val_loss": 49.360179632902145, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 149.64046895503998, "training_acc": 75.33333333333333, "val_loss": 43.90312975645065, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 150.75052523612976, "training_acc": 76.0, "val_loss": 43.637588024139404, "val_acc": 66.66666666666667}
{"epoch": 9, "training_loss": 145.37101423740387, "training_acc": 78.0, "val_loss": 45.54453635215759, "val_acc": 69.33333333333333}
{"epoch": 10, "training_loss": 139.19321870803833, "training_acc": 80.0, "val_loss": 46.16813886165619, "val_acc": 70.66666666666667}
{"epoch": 11, "training_loss": 138.95290970802307, "training_acc": 79.66666666666667, "val_loss": 43.94062227010727, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 132.91298747062683, "training_acc": 80.0, "val_loss": 43.24384254217148, "val_acc": 72.0}
{"epoch": 13, "training_loss": 131.13342547416687, "training_acc": 80.0, "val_loss": 46.535999447107315, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 130.9537796974182, "training_acc": 80.33333333333333, "val_loss": 40.236389338970184, "val_acc": 69.33333333333333}
{"epoch": 15, "training_loss": 120.1415866613388, "training_acc": 83.33333333333333, "val_loss": 41.455899477005005, "val_acc": 76.0}
{"epoch": 16, "training_loss": 113.42416405677795, "training_acc": 84.33333333333333, "val_loss": 52.56105834245682, "val_acc": 52.0}
{"epoch": 17, "training_loss": 136.9472267627716, "training_acc": 81.66666666666667, "val_loss": 43.94334989786148, "val_acc": 76.0}
{"epoch": 18, "training_loss": 132.31209194660187, "training_acc": 78.33333333333333, "val_loss": 49.937817096710205, "val_acc": 49.333333333333336}
{"epoch": 19, "training_loss": 145.93925666809082, "training_acc": 76.66666666666667, "val_loss": 40.65795361995697, "val_acc": 72.0}
{"epoch": 20, "training_loss": 124.59426689147949, "training_acc": 83.33333333333333, "val_loss": 40.48414534330368, "val_acc": 72.0}
{"epoch": 21, "training_loss": 114.5610636472702, "training_acc": 82.0, "val_loss": 50.461371541023254, "val_acc": 62.666666666666664}
{"epoch": 22, "training_loss": 127.4741336107254, "training_acc": 81.33333333333333, "val_loss": 39.16951730847359, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 110.82110571861267, "training_acc": 84.66666666666667, "val_loss": 36.12025886774063, "val_acc": 80.0}
{"epoch": 24, "training_loss": 95.3059595823288, "training_acc": 87.66666666666667, "val_loss": 51.10753810405731, "val_acc": 78.66666666666667}
{"epoch": 25, "training_loss": 111.10489654541016, "training_acc": 83.33333333333333, "val_loss": 40.56951177120209, "val_acc": 80.0}
{"epoch": 26, "training_loss": 108.60997116565704, "training_acc": 82.66666666666667, "val_loss": 46.58045116066933, "val_acc": 78.66666666666667}
{"epoch": 27, "training_loss": 100.30389547348022, "training_acc": 82.66666666666667, "val_loss": 44.330169558525085, "val_acc": 78.66666666666667}
{"epoch": 28, "training_loss": 87.98382246494293, "training_acc": 87.0, "val_loss": 45.13345551490784, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 77.31388118863106, "training_acc": 90.0, "val_loss": 43.05846244096756, "val_acc": 84.0}
{"epoch": 30, "training_loss": 62.72475677728653, "training_acc": 92.0, "val_loss": 40.3625518232584, "val_acc": 86.66666666666667}
{"epoch": 31, "training_loss": 46.78182703256607, "training_acc": 93.33333333333333, "val_loss": 43.53163769841194, "val_acc": 85.33333333333333}
{"epoch": 32, "training_loss": 46.96767246723175, "training_acc": 93.33333333333333, "val_loss": 49.83776670694351, "val_acc": 74.66666666666667}
{"epoch": 33, "training_loss": 119.12064981460571, "training_acc": 86.66666666666667, "val_loss": 107.09290593862534, "val_acc": 72.0}
{"epoch": 34, "training_loss": 145.7511111497879, "training_acc": 81.33333333333333, "val_loss": 41.023058354854584, "val_acc": 69.33333333333333}
{"epoch": 35, "training_loss": 143.9016411304474, "training_acc": 74.66666666666667, "val_loss": 44.54826211929321, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 140.46106958389282, "training_acc": 76.33333333333333, "val_loss": 41.87387374043465, "val_acc": 70.66666666666667}
{"epoch": 37, "training_loss": 135.7707930803299, "training_acc": 81.66666666666667, "val_loss": 48.467483162879944, "val_acc": 70.66666666666667}
{"epoch": 38, "training_loss": 128.9771909713745, "training_acc": 80.0, "val_loss": 44.406258910894394, "val_acc": 66.66666666666667}
{"epoch": 39, "training_loss": 119.7043845653534, "training_acc": 81.66666666666667, "val_loss": 49.05120885372162, "val_acc": 70.66666666666667}
{"epoch": 40, "training_loss": 113.56347703933716, "training_acc": 85.0, "val_loss": 42.18254974484444, "val_acc": 77.33333333333333}
{"epoch": 41, "training_loss": 96.90895521640778, "training_acc": 86.66666666666667, "val_loss": 38.97058057785034, "val_acc": 76.0}
{"epoch": 42, "training_loss": 80.4236249923706, "training_acc": 88.33333333333333, "val_loss": 36.74355071783066, "val_acc": 80.0}
