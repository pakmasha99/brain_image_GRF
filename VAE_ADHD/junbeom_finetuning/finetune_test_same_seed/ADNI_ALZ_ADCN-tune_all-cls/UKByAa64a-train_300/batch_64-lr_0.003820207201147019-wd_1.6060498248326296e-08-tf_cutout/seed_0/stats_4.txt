"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 319.7160978317261, "training_acc": 51.333333333333336, "val_loss": 18029707968.0, "val_acc": 72.0}
{"epoch": 1, "training_loss": 12833309729.082031, "training_acc": 49.666666666666664, "val_loss": 1265560.666015625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1465883.1406707764, "training_acc": 65.0, "val_loss": 16375.324310302734, "val_acc": 28.0}
{"epoch": 3, "training_loss": 17470.577852249146, "training_acc": 56.333333333333336, "val_loss": 307.6301815509796, "val_acc": 28.0}
{"epoch": 4, "training_loss": 1652.2784099578857, "training_acc": 66.33333333333333, "val_loss": 89.24312210083008, "val_acc": 28.0}
{"epoch": 5, "training_loss": 600.7344779968262, "training_acc": 56.333333333333336, "val_loss": 269.1972827911377, "val_acc": 72.0}
{"epoch": 6, "training_loss": 731.8246965408325, "training_acc": 65.66666666666667, "val_loss": 71.57136344909668, "val_acc": 72.0}
{"epoch": 7, "training_loss": 236.02825140953064, "training_acc": 72.33333333333333, "val_loss": 131.02959656715393, "val_acc": 28.0}
{"epoch": 8, "training_loss": 284.1603260040283, "training_acc": 63.0, "val_loss": 51.87386691570282, "val_acc": 28.0}
{"epoch": 9, "training_loss": 218.94657492637634, "training_acc": 70.33333333333333, "val_loss": 49.09781974554062, "val_acc": 72.0}
{"epoch": 10, "training_loss": 193.45460295677185, "training_acc": 72.33333333333333, "val_loss": 45.505654990673065, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 182.70154118537903, "training_acc": 72.33333333333333, "val_loss": 44.39872074127197, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.8590121269226, "training_acc": 72.33333333333333, "val_loss": 44.54270684719086, "val_acc": 72.0}
{"epoch": 13, "training_loss": 178.09330439567566, "training_acc": 72.33333333333333, "val_loss": 44.863336741924286, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.0309443473816, "training_acc": 72.33333333333333, "val_loss": 45.07586795091629, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 178.56684494018555, "training_acc": 72.33333333333333, "val_loss": 44.75128835439682, "val_acc": 72.0}
{"epoch": 16, "training_loss": 183.8927366733551, "training_acc": 72.33333333333333, "val_loss": 44.47462385892868, "val_acc": 72.0}
{"epoch": 17, "training_loss": 180.40366578102112, "training_acc": 72.33333333333333, "val_loss": 44.18667984008789, "val_acc": 72.0}
{"epoch": 18, "training_loss": 182.20906257629395, "training_acc": 72.33333333333333, "val_loss": 44.166754961013794, "val_acc": 72.0}
{"epoch": 19, "training_loss": 181.2271957397461, "training_acc": 72.33333333333333, "val_loss": 44.6940131187439, "val_acc": 72.0}
{"epoch": 20, "training_loss": 179.68276190757751, "training_acc": 72.33333333333333, "val_loss": 44.41629821062088, "val_acc": 72.0}
{"epoch": 21, "training_loss": 175.97652006149292, "training_acc": 72.33333333333333, "val_loss": 44.666582107543945, "val_acc": 72.0}
{"epoch": 22, "training_loss": 180.42624306678772, "training_acc": 72.33333333333333, "val_loss": 44.05027687549591, "val_acc": 72.0}
{"epoch": 23, "training_loss": 176.91049003601074, "training_acc": 72.33333333333333, "val_loss": 44.41448414325714, "val_acc": 72.0}
{"epoch": 24, "training_loss": 178.08596849441528, "training_acc": 72.33333333333333, "val_loss": 44.240398943424225, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.17816162109375, "training_acc": 72.33333333333333, "val_loss": 43.934719145298004, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.40401911735535, "training_acc": 72.33333333333333, "val_loss": 43.919472217559814, "val_acc": 72.0}
{"epoch": 27, "training_loss": 175.961088180542, "training_acc": 72.33333333333333, "val_loss": 43.717159271240234, "val_acc": 72.0}
{"epoch": 28, "training_loss": 178.04239916801453, "training_acc": 72.33333333333333, "val_loss": 44.09312689304352, "val_acc": 72.0}
{"epoch": 29, "training_loss": 181.62331748008728, "training_acc": 72.33333333333333, "val_loss": 44.25923979282379, "val_acc": 72.0}
{"epoch": 30, "training_loss": 179.3639943599701, "training_acc": 72.33333333333333, "val_loss": 44.42398780584335, "val_acc": 72.0}
{"epoch": 31, "training_loss": 180.8601372241974, "training_acc": 72.33333333333333, "val_loss": 44.27842140197754, "val_acc": 72.0}
{"epoch": 32, "training_loss": 178.06080222129822, "training_acc": 72.33333333333333, "val_loss": 44.85754817724228, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.310209274292, "training_acc": 72.33333333333333, "val_loss": 44.06911480426788, "val_acc": 72.0}
{"epoch": 34, "training_loss": 180.16961288452148, "training_acc": 72.33333333333333, "val_loss": 44.28653073310852, "val_acc": 72.0}
{"epoch": 35, "training_loss": 180.7412621974945, "training_acc": 72.33333333333333, "val_loss": 44.07010167837143, "val_acc": 72.0}
{"epoch": 36, "training_loss": 176.66881775856018, "training_acc": 72.33333333333333, "val_loss": 44.085038900375366, "val_acc": 72.0}
{"epoch": 37, "training_loss": 176.91284704208374, "training_acc": 72.33333333333333, "val_loss": 44.155016124248505, "val_acc": 72.0}
{"epoch": 38, "training_loss": 177.08932280540466, "training_acc": 72.33333333333333, "val_loss": 44.096532225608826, "val_acc": 72.0}
{"epoch": 39, "training_loss": 176.26874923706055, "training_acc": 72.33333333333333, "val_loss": 44.03847926855087, "val_acc": 72.0}
{"epoch": 40, "training_loss": 176.6100950241089, "training_acc": 72.33333333333333, "val_loss": 44.04984784126282, "val_acc": 72.0}
{"epoch": 41, "training_loss": 176.12888526916504, "training_acc": 72.33333333333333, "val_loss": 43.95263347029686, "val_acc": 72.0}
{"epoch": 42, "training_loss": 176.5085666179657, "training_acc": 72.33333333333333, "val_loss": 43.94379350543022, "val_acc": 72.0}
{"epoch": 43, "training_loss": 177.66546034812927, "training_acc": 72.33333333333333, "val_loss": 43.87421524524689, "val_acc": 72.0}
{"epoch": 44, "training_loss": 179.64677953720093, "training_acc": 72.33333333333333, "val_loss": 44.249926030635834, "val_acc": 72.0}
{"epoch": 45, "training_loss": 176.47020292282104, "training_acc": 72.33333333333333, "val_loss": 44.58292603492737, "val_acc": 72.0}
{"epoch": 46, "training_loss": 177.35082077980042, "training_acc": 72.33333333333333, "val_loss": 43.9911003112793, "val_acc": 72.0}
