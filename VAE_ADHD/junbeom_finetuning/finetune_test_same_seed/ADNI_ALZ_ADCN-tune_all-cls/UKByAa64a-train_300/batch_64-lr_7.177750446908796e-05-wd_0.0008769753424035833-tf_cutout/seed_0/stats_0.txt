"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 181.17646384239197, "training_acc": 71.66666666666667, "val_loss": 41.429601311683655, "val_acc": 73.33333333333333}
{"epoch": 1, "training_loss": 176.2379298210144, "training_acc": 72.0, "val_loss": 39.94083794951439, "val_acc": 74.66666666666667}
{"epoch": 2, "training_loss": 176.7417140007019, "training_acc": 73.0, "val_loss": 44.995077192783356, "val_acc": 44.0}
{"epoch": 3, "training_loss": 168.57948994636536, "training_acc": 75.0, "val_loss": 42.52324914932251, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 169.67065572738647, "training_acc": 73.66666666666667, "val_loss": 40.757444739341736, "val_acc": 62.666666666666664}
{"epoch": 5, "training_loss": 170.07470631599426, "training_acc": 71.33333333333333, "val_loss": 37.69746744632721, "val_acc": 77.33333333333333}
{"epoch": 6, "training_loss": 175.4230499267578, "training_acc": 72.66666666666667, "val_loss": 38.374564439058304, "val_acc": 78.66666666666667}
{"epoch": 7, "training_loss": 169.54173922538757, "training_acc": 72.0, "val_loss": 37.420953154563904, "val_acc": 77.33333333333333}
{"epoch": 8, "training_loss": 164.26095700263977, "training_acc": 72.33333333333333, "val_loss": 35.07900121808052, "val_acc": 78.66666666666667}
{"epoch": 9, "training_loss": 167.86224126815796, "training_acc": 69.66666666666667, "val_loss": 36.293740034103394, "val_acc": 76.0}
{"epoch": 10, "training_loss": 160.89083218574524, "training_acc": 73.33333333333333, "val_loss": 36.01537948846817, "val_acc": 78.66666666666667}
{"epoch": 11, "training_loss": 161.16990661621094, "training_acc": 72.0, "val_loss": 36.31750485301018, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 166.47711324691772, "training_acc": 73.33333333333333, "val_loss": 35.14749425649643, "val_acc": 77.33333333333333}
{"epoch": 13, "training_loss": 157.42815589904785, "training_acc": 73.0, "val_loss": 36.16945892572403, "val_acc": 76.0}
{"epoch": 14, "training_loss": 157.0976917743683, "training_acc": 73.33333333333333, "val_loss": 33.86442548036575, "val_acc": 80.0}
{"epoch": 15, "training_loss": 154.73690676689148, "training_acc": 75.33333333333333, "val_loss": 36.338094890117645, "val_acc": 69.33333333333333}
{"epoch": 16, "training_loss": 153.204252243042, "training_acc": 74.66666666666667, "val_loss": 33.129897713661194, "val_acc": 80.0}
{"epoch": 17, "training_loss": 149.25109386444092, "training_acc": 74.66666666666667, "val_loss": 36.63144639134407, "val_acc": 65.33333333333333}
{"epoch": 18, "training_loss": 152.8620195388794, "training_acc": 72.66666666666667, "val_loss": 33.95911681652069, "val_acc": 77.33333333333333}
{"epoch": 19, "training_loss": 151.70900654792786, "training_acc": 74.0, "val_loss": 35.74961096048355, "val_acc": 66.66666666666667}
{"epoch": 20, "training_loss": 154.32716763019562, "training_acc": 74.0, "val_loss": 36.479095220565796, "val_acc": 77.33333333333333}
{"epoch": 21, "training_loss": 150.22360110282898, "training_acc": 77.33333333333333, "val_loss": 33.85147708654404, "val_acc": 78.66666666666667}
{"epoch": 22, "training_loss": 143.38668835163116, "training_acc": 77.0, "val_loss": 32.48509722948074, "val_acc": 81.33333333333333}
{"epoch": 23, "training_loss": 135.93484210968018, "training_acc": 80.0, "val_loss": 30.60339456796646, "val_acc": 84.0}
{"epoch": 24, "training_loss": 137.08911335468292, "training_acc": 80.66666666666667, "val_loss": 30.467848986387253, "val_acc": 82.66666666666667}
{"epoch": 25, "training_loss": 180.47892928123474, "training_acc": 70.66666666666667, "val_loss": 41.31421732902527, "val_acc": 84.0}
{"epoch": 26, "training_loss": 175.55273485183716, "training_acc": 72.66666666666667, "val_loss": 40.338258266448975, "val_acc": 80.0}
{"epoch": 27, "training_loss": 168.69015789031982, "training_acc": 72.0, "val_loss": 39.018783390522, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 160.577495098114, "training_acc": 72.66666666666667, "val_loss": 34.52366015315056, "val_acc": 80.0}
{"epoch": 29, "training_loss": 159.61964869499207, "training_acc": 75.33333333333333, "val_loss": 35.54885995388031, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 154.72723472118378, "training_acc": 76.0, "val_loss": 34.94879752397537, "val_acc": 81.33333333333333}
{"epoch": 31, "training_loss": 150.2947132587433, "training_acc": 76.0, "val_loss": 32.50106805562973, "val_acc": 85.33333333333333}
{"epoch": 32, "training_loss": 144.9443929195404, "training_acc": 78.0, "val_loss": 31.19049859046936, "val_acc": 82.66666666666667}
{"epoch": 33, "training_loss": 133.47560501098633, "training_acc": 80.0, "val_loss": 31.4957015812397, "val_acc": 81.33333333333333}
{"epoch": 34, "training_loss": 126.66481232643127, "training_acc": 82.33333333333333, "val_loss": 37.181320905685425, "val_acc": 77.33333333333333}
{"epoch": 35, "training_loss": 167.6020064353943, "training_acc": 73.0, "val_loss": 41.14451402425766, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 169.62395215034485, "training_acc": 72.0, "val_loss": 42.723196148872375, "val_acc": 68.0}
{"epoch": 37, "training_loss": 171.23566818237305, "training_acc": 72.0, "val_loss": 38.348276019096375, "val_acc": 73.33333333333333}
{"epoch": 38, "training_loss": 164.23242950439453, "training_acc": 72.33333333333333, "val_loss": 36.942385256290436, "val_acc": 78.66666666666667}
{"epoch": 39, "training_loss": 161.1730353832245, "training_acc": 73.66666666666667, "val_loss": 33.696409583091736, "val_acc": 78.66666666666667}
{"epoch": 40, "training_loss": 158.3143825531006, "training_acc": 74.33333333333333, "val_loss": 33.82223325967789, "val_acc": 78.66666666666667}
{"epoch": 41, "training_loss": 153.9484394788742, "training_acc": 74.0, "val_loss": 36.855248153209686, "val_acc": 77.33333333333333}
{"epoch": 42, "training_loss": 155.7003026008606, "training_acc": 73.66666666666667, "val_loss": 35.59125608205795, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 164.3833236694336, "training_acc": 71.66666666666667, "val_loss": 34.92634725570679, "val_acc": 80.0}
