"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 191.69194197654724, "training_acc": 71.66666666666667, "val_loss": 45.13774877786636, "val_acc": 61.333333333333336}
{"epoch": 1, "training_loss": 177.34645175933838, "training_acc": 72.0, "val_loss": 42.13691073656082, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 173.85354709625244, "training_acc": 72.0, "val_loss": 41.53717893362045, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 171.84355902671814, "training_acc": 72.0, "val_loss": 40.19694370031357, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 174.60597681999207, "training_acc": 72.0, "val_loss": 39.618517994880676, "val_acc": 74.66666666666667}
{"epoch": 5, "training_loss": 167.68025612831116, "training_acc": 72.0, "val_loss": 38.38185304403305, "val_acc": 78.66666666666667}
{"epoch": 6, "training_loss": 160.80554580688477, "training_acc": 72.66666666666667, "val_loss": 36.81335833668709, "val_acc": 77.33333333333333}
{"epoch": 7, "training_loss": 162.4183211326599, "training_acc": 73.66666666666667, "val_loss": 35.11512267589569, "val_acc": 77.33333333333333}
{"epoch": 8, "training_loss": 165.21974563598633, "training_acc": 74.66666666666667, "val_loss": 36.819733679294586, "val_acc": 76.0}
{"epoch": 9, "training_loss": 159.14395201206207, "training_acc": 74.33333333333333, "val_loss": 35.74877950549126, "val_acc": 77.33333333333333}
{"epoch": 10, "training_loss": 157.75444412231445, "training_acc": 73.0, "val_loss": 35.05482631921768, "val_acc": 77.33333333333333}
{"epoch": 11, "training_loss": 155.3179452419281, "training_acc": 76.66666666666667, "val_loss": 34.6939542889595, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 160.20283460617065, "training_acc": 75.66666666666667, "val_loss": 35.55314216017723, "val_acc": 77.33333333333333}
{"epoch": 13, "training_loss": 153.26373314857483, "training_acc": 75.0, "val_loss": 36.59849667549133, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 152.27147436141968, "training_acc": 74.0, "val_loss": 34.98362798988819, "val_acc": 76.0}
{"epoch": 15, "training_loss": 147.58252000808716, "training_acc": 77.0, "val_loss": 37.742400884628296, "val_acc": 61.333333333333336}
{"epoch": 16, "training_loss": 149.24184393882751, "training_acc": 77.33333333333333, "val_loss": 34.406382501125336, "val_acc": 76.0}
{"epoch": 17, "training_loss": 145.55515956878662, "training_acc": 77.66666666666667, "val_loss": 32.8882839679718, "val_acc": 81.33333333333333}
{"epoch": 18, "training_loss": 136.14967012405396, "training_acc": 80.0, "val_loss": 32.62390476465225, "val_acc": 81.33333333333333}
{"epoch": 19, "training_loss": 134.07846891880035, "training_acc": 80.66666666666667, "val_loss": 32.92453843355179, "val_acc": 82.66666666666667}
{"epoch": 20, "training_loss": 137.60686218738556, "training_acc": 78.66666666666667, "val_loss": 39.7829852104187, "val_acc": 78.66666666666667}
{"epoch": 21, "training_loss": 147.04519474506378, "training_acc": 78.0, "val_loss": 32.25430256128311, "val_acc": 82.66666666666667}
{"epoch": 22, "training_loss": 130.40153396129608, "training_acc": 81.33333333333333, "val_loss": 32.082611322402954, "val_acc": 81.33333333333333}
{"epoch": 23, "training_loss": 125.43882668018341, "training_acc": 84.33333333333333, "val_loss": 31.528164088726044, "val_acc": 80.0}
{"epoch": 24, "training_loss": 148.261057138443, "training_acc": 79.0, "val_loss": 38.42364966869354, "val_acc": 77.33333333333333}
{"epoch": 25, "training_loss": 112.5132532119751, "training_acc": 83.66666666666667, "val_loss": 30.89414072036743, "val_acc": 82.66666666666667}
{"epoch": 26, "training_loss": 131.8531254529953, "training_acc": 80.0, "val_loss": 35.453509002923965, "val_acc": 68.0}
{"epoch": 27, "training_loss": 118.99285793304443, "training_acc": 84.66666666666667, "val_loss": 31.979933515191078, "val_acc": 82.66666666666667}
{"epoch": 28, "training_loss": 111.91183161735535, "training_acc": 85.0, "val_loss": 33.71480667591095, "val_acc": 77.33333333333333}
{"epoch": 29, "training_loss": 102.65608274936676, "training_acc": 88.0, "val_loss": 34.49860996007919, "val_acc": 80.0}
{"epoch": 30, "training_loss": 118.155402302742, "training_acc": 82.66666666666667, "val_loss": 35.74711874127388, "val_acc": 77.33333333333333}
{"epoch": 31, "training_loss": 99.49724197387695, "training_acc": 87.0, "val_loss": 34.705175280570984, "val_acc": 78.66666666666667}
{"epoch": 32, "training_loss": 77.39436221122742, "training_acc": 92.0, "val_loss": 31.870092540979385, "val_acc": 78.66666666666667}
{"epoch": 33, "training_loss": 75.93607097864151, "training_acc": 90.66666666666667, "val_loss": 34.67035362124443, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 70.23193383216858, "training_acc": 91.33333333333333, "val_loss": 52.962393179535866, "val_acc": 78.66666666666667}
{"epoch": 35, "training_loss": 139.26611375808716, "training_acc": 82.0, "val_loss": 33.484771370887756, "val_acc": 84.0}
{"epoch": 36, "training_loss": 117.23847997188568, "training_acc": 83.33333333333333, "val_loss": 40.73631685972214, "val_acc": 78.66666666666667}
{"epoch": 37, "training_loss": 124.91770386695862, "training_acc": 80.33333333333333, "val_loss": 33.52593284845352, "val_acc": 70.66666666666667}
{"epoch": 38, "training_loss": 110.51509809494019, "training_acc": 85.0, "val_loss": 30.716808438301086, "val_acc": 81.33333333333333}
{"epoch": 39, "training_loss": 87.34411817789078, "training_acc": 90.66666666666667, "val_loss": 33.81608451157808, "val_acc": 82.66666666666667}
{"epoch": 40, "training_loss": 85.67053556442261, "training_acc": 87.0, "val_loss": 28.98970252275467, "val_acc": 82.66666666666667}
{"epoch": 41, "training_loss": 80.61085677146912, "training_acc": 90.33333333333333, "val_loss": 29.190675795078278, "val_acc": 84.0}
{"epoch": 42, "training_loss": 69.97560954093933, "training_acc": 91.33333333333333, "val_loss": 30.20315784215927, "val_acc": 76.0}
{"epoch": 43, "training_loss": 73.31317263841629, "training_acc": 91.0, "val_loss": 37.470485627651215, "val_acc": 69.33333333333333}
{"epoch": 44, "training_loss": 79.14319801330566, "training_acc": 89.66666666666667, "val_loss": 30.260333597660065, "val_acc": 80.0}
{"epoch": 45, "training_loss": 49.023258566856384, "training_acc": 94.66666666666667, "val_loss": 35.47940403223038, "val_acc": 82.66666666666667}
{"epoch": 46, "training_loss": 55.12373596429825, "training_acc": 95.33333333333333, "val_loss": 45.88016019761562, "val_acc": 81.33333333333333}
{"epoch": 47, "training_loss": 48.576680064201355, "training_acc": 95.33333333333333, "val_loss": 32.85055649280548, "val_acc": 82.66666666666667}
{"epoch": 48, "training_loss": 53.10506311058998, "training_acc": 93.66666666666667, "val_loss": 45.988864839076996, "val_acc": 72.0}
{"epoch": 49, "training_loss": 48.280532091856, "training_acc": 94.33333333333333, "val_loss": 43.95663070678711, "val_acc": 69.33333333333333}
{"epoch": 50, "training_loss": 83.22418570518494, "training_acc": 89.0, "val_loss": 35.86530262231827, "val_acc": 80.0}
{"epoch": 51, "training_loss": 80.65004003047943, "training_acc": 89.0, "val_loss": 62.131330490112305, "val_acc": 62.666666666666664}
{"epoch": 52, "training_loss": 117.64135092496872, "training_acc": 82.0, "val_loss": 29.62903007864952, "val_acc": 81.33333333333333}
{"epoch": 53, "training_loss": 68.50234699249268, "training_acc": 90.66666666666667, "val_loss": 38.825563319027424, "val_acc": 81.33333333333333}
{"epoch": 54, "training_loss": 62.03450524806976, "training_acc": 91.66666666666667, "val_loss": 33.68169964849949, "val_acc": 73.33333333333333}
{"epoch": 55, "training_loss": 54.323429346084595, "training_acc": 93.0, "val_loss": 33.26242706179619, "val_acc": 84.0}
{"epoch": 56, "training_loss": 37.92669415473938, "training_acc": 95.66666666666667, "val_loss": 34.663707971572876, "val_acc": 84.0}
{"epoch": 57, "training_loss": 27.084721624851227, "training_acc": 97.33333333333333, "val_loss": 36.622294425964355, "val_acc": 81.33333333333333}
{"epoch": 58, "training_loss": 24.27734485268593, "training_acc": 97.66666666666667, "val_loss": 50.79551291465759, "val_acc": 84.0}
{"epoch": 59, "training_loss": 41.15030360966921, "training_acc": 95.0, "val_loss": 103.94629484415054, "val_acc": 74.66666666666667}
