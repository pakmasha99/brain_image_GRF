"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 191.80726957321167, "training_acc": 72.33333333333333, "val_loss": 48.89466214179993, "val_acc": 28.0}
{"epoch": 1, "training_loss": 182.6961169242859, "training_acc": 72.0, "val_loss": 44.54709431529045, "val_acc": 72.0}
{"epoch": 2, "training_loss": 172.28689229488373, "training_acc": 72.33333333333333, "val_loss": 43.7222700715065, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 166.11418628692627, "training_acc": 72.33333333333333, "val_loss": 43.45801803469658, "val_acc": 66.66666666666667}
{"epoch": 4, "training_loss": 162.9230922460556, "training_acc": 72.33333333333333, "val_loss": 42.81963092088699, "val_acc": 69.33333333333333}
{"epoch": 5, "training_loss": 155.89686787128448, "training_acc": 72.66666666666667, "val_loss": 43.49109834432602, "val_acc": 66.66666666666667}
{"epoch": 6, "training_loss": 151.89082205295563, "training_acc": 75.0, "val_loss": 43.27057021856308, "val_acc": 64.0}
{"epoch": 7, "training_loss": 149.07309651374817, "training_acc": 75.33333333333333, "val_loss": 44.88028925657272, "val_acc": 65.33333333333333}
{"epoch": 8, "training_loss": 153.10483503341675, "training_acc": 74.66666666666667, "val_loss": 44.92574259638786, "val_acc": 61.333333333333336}
{"epoch": 9, "training_loss": 149.98043155670166, "training_acc": 76.33333333333333, "val_loss": 45.47656071186066, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 144.03989219665527, "training_acc": 74.66666666666667, "val_loss": 43.14068937301636, "val_acc": 60.0}
{"epoch": 11, "training_loss": 148.02562963962555, "training_acc": 76.33333333333333, "val_loss": 43.99251461029053, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 144.37380421161652, "training_acc": 76.33333333333333, "val_loss": 43.40985405445099, "val_acc": 65.33333333333333}
{"epoch": 13, "training_loss": 140.21804630756378, "training_acc": 77.66666666666667, "val_loss": 43.90975871682167, "val_acc": 65.33333333333333}
{"epoch": 14, "training_loss": 137.49600529670715, "training_acc": 80.0, "val_loss": 45.30069154500961, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 137.49243664741516, "training_acc": 79.0, "val_loss": 43.09735822677612, "val_acc": 61.333333333333336}
{"epoch": 16, "training_loss": 133.42863142490387, "training_acc": 78.66666666666667, "val_loss": 42.349566638469696, "val_acc": 61.333333333333336}
{"epoch": 17, "training_loss": 134.1672830581665, "training_acc": 81.0, "val_loss": 52.06307512521744, "val_acc": 72.0}
{"epoch": 18, "training_loss": 145.085715174675, "training_acc": 77.0, "val_loss": 42.15021324157715, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 128.65059685707092, "training_acc": 79.66666666666667, "val_loss": 41.823295533657074, "val_acc": 65.33333333333333}
{"epoch": 20, "training_loss": 127.40783524513245, "training_acc": 82.33333333333333, "val_loss": 43.48937523365021, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 121.61278069019318, "training_acc": 82.66666666666667, "val_loss": 45.013493955135345, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 118.53413677215576, "training_acc": 83.33333333333333, "val_loss": 41.39784163236618, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 125.7695665359497, "training_acc": 78.33333333333333, "val_loss": 42.12080982327461, "val_acc": 72.0}
{"epoch": 24, "training_loss": 116.78065705299377, "training_acc": 82.66666666666667, "val_loss": 40.03923526406288, "val_acc": 70.66666666666667}
{"epoch": 25, "training_loss": 113.19228065013885, "training_acc": 84.33333333333333, "val_loss": 40.574501395225525, "val_acc": 68.0}
{"epoch": 26, "training_loss": 111.64163267612457, "training_acc": 85.0, "val_loss": 41.2988298535347, "val_acc": 65.33333333333333}
{"epoch": 27, "training_loss": 103.9561003446579, "training_acc": 86.0, "val_loss": 42.49612641334534, "val_acc": 72.0}
{"epoch": 28, "training_loss": 98.96514427661896, "training_acc": 87.0, "val_loss": 42.220253109931946, "val_acc": 72.0}
{"epoch": 29, "training_loss": 87.40472370386124, "training_acc": 92.0, "val_loss": 49.017902821302414, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 120.48155587911606, "training_acc": 83.33333333333333, "val_loss": 68.8133956193924, "val_acc": 72.0}
{"epoch": 31, "training_loss": 122.97396874427795, "training_acc": 83.0, "val_loss": 44.104212164878845, "val_acc": 69.33333333333333}
{"epoch": 32, "training_loss": 102.19561100006104, "training_acc": 86.0, "val_loss": 42.51879581809044, "val_acc": 72.0}
{"epoch": 33, "training_loss": 94.53450071811676, "training_acc": 87.66666666666667, "val_loss": 43.114024847745895, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 83.76840883493423, "training_acc": 91.33333333333333, "val_loss": 43.7097030878067, "val_acc": 72.0}
{"epoch": 35, "training_loss": 80.56681191921234, "training_acc": 90.66666666666667, "val_loss": 40.515076875686646, "val_acc": 76.0}
{"epoch": 36, "training_loss": 77.45617866516113, "training_acc": 91.66666666666667, "val_loss": 43.476765155792236, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 88.0667524933815, "training_acc": 86.0, "val_loss": 64.98818451166153, "val_acc": 72.0}
{"epoch": 38, "training_loss": 90.62187910079956, "training_acc": 85.66666666666667, "val_loss": 47.84266948699951, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 72.60437148809433, "training_acc": 90.33333333333333, "val_loss": 44.42122200131416, "val_acc": 76.0}
{"epoch": 40, "training_loss": 75.46310675144196, "training_acc": 90.33333333333333, "val_loss": 47.50385844707489, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 82.66241008043289, "training_acc": 89.33333333333333, "val_loss": 54.09292924404144, "val_acc": 72.0}
{"epoch": 42, "training_loss": 80.93170392513275, "training_acc": 87.66666666666667, "val_loss": 44.72731441259384, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 61.30353409051895, "training_acc": 92.66666666666667, "val_loss": 44.34563630819321, "val_acc": 73.33333333333333}
