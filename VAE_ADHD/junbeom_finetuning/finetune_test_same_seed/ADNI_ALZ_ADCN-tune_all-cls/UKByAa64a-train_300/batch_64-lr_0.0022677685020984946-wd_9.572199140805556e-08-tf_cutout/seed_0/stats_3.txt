"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 277.47091603279114, "training_acc": 58.333333333333336, "val_loss": 239394972.5, "val_acc": 72.0}
{"epoch": 1, "training_loss": 177672065.2890463, "training_acc": 56.333333333333336, "val_loss": 1880.3477802276611, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3608.5542335510254, "training_acc": 50.666666666666664, "val_loss": 625.8279609680176, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1064.6248865127563, "training_acc": 59.0, "val_loss": 94.16547805070877, "val_acc": 72.0}
{"epoch": 4, "training_loss": 294.62902879714966, "training_acc": 62.0, "val_loss": 61.05191719532013, "val_acc": 72.0}
{"epoch": 5, "training_loss": 231.17197847366333, "training_acc": 59.666666666666664, "val_loss": 69.80153095722198, "val_acc": 72.0}
{"epoch": 6, "training_loss": 256.6133325099945, "training_acc": 71.66666666666667, "val_loss": 63.94960653781891, "val_acc": 72.0}
{"epoch": 7, "training_loss": 207.9364070892334, "training_acc": 60.333333333333336, "val_loss": 45.19326803088188, "val_acc": 72.0}
{"epoch": 8, "training_loss": 175.90128111839294, "training_acc": 72.33333333333333, "val_loss": 43.921458423137665, "val_acc": 72.0}
{"epoch": 9, "training_loss": 182.34505152702332, "training_acc": 71.66666666666667, "val_loss": 44.36206293106079, "val_acc": 72.0}
{"epoch": 10, "training_loss": 187.53602647781372, "training_acc": 72.33333333333333, "val_loss": 46.31920862197876, "val_acc": 29.333333333333332}
{"epoch": 11, "training_loss": 180.35806345939636, "training_acc": 72.33333333333333, "val_loss": 44.167110443115234, "val_acc": 72.0}
{"epoch": 12, "training_loss": 176.6257541179657, "training_acc": 72.33333333333333, "val_loss": 43.82977819442749, "val_acc": 72.0}
{"epoch": 13, "training_loss": 175.4323923587799, "training_acc": 72.33333333333333, "val_loss": 43.718887746334076, "val_acc": 72.0}
{"epoch": 14, "training_loss": 175.92522811889648, "training_acc": 72.33333333333333, "val_loss": 43.958095490932465, "val_acc": 72.0}
{"epoch": 15, "training_loss": 178.168461561203, "training_acc": 72.33333333333333, "val_loss": 43.81630939245224, "val_acc": 72.0}
{"epoch": 16, "training_loss": 185.96838760375977, "training_acc": 72.33333333333333, "val_loss": 47.70723330974579, "val_acc": 28.0}
{"epoch": 17, "training_loss": 180.70796585083008, "training_acc": 72.66666666666667, "val_loss": 44.00118166208267, "val_acc": 72.0}
{"epoch": 18, "training_loss": 186.5207313299179, "training_acc": 62.333333333333336, "val_loss": 44.656308472156525, "val_acc": 72.0}
{"epoch": 19, "training_loss": 177.8189661502838, "training_acc": 72.33333333333333, "val_loss": 44.20503795146942, "val_acc": 72.0}
{"epoch": 20, "training_loss": 178.27569913864136, "training_acc": 72.33333333333333, "val_loss": 44.36241775751114, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 182.30009412765503, "training_acc": 72.33333333333333, "val_loss": 43.82577860355377, "val_acc": 72.0}
{"epoch": 22, "training_loss": 187.72294235229492, "training_acc": 71.33333333333333, "val_loss": 47.099374890327454, "val_acc": 72.0}
{"epoch": 23, "training_loss": 181.39286303520203, "training_acc": 72.33333333333333, "val_loss": 43.96060562133789, "val_acc": 72.0}
{"epoch": 24, "training_loss": 177.3162841796875, "training_acc": 72.33333333333333, "val_loss": 44.087502121925354, "val_acc": 72.0}
{"epoch": 25, "training_loss": 175.3135120868683, "training_acc": 72.33333333333333, "val_loss": 44.45930391550064, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.41733241081238, "training_acc": 72.33333333333333, "val_loss": 43.84501767158508, "val_acc": 72.0}
{"epoch": 27, "training_loss": 175.19080924987793, "training_acc": 72.33333333333333, "val_loss": 43.76459836959839, "val_acc": 72.0}
{"epoch": 28, "training_loss": 175.46325659751892, "training_acc": 72.33333333333333, "val_loss": 43.668715476989746, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.47347164154053, "training_acc": 72.33333333333333, "val_loss": 43.88497942686081, "val_acc": 72.0}
{"epoch": 30, "training_loss": 175.43263339996338, "training_acc": 72.33333333333333, "val_loss": 43.82970541715622, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 174.77954387664795, "training_acc": 72.33333333333333, "val_loss": 43.45611393451691, "val_acc": 72.0}
{"epoch": 32, "training_loss": 173.70087957382202, "training_acc": 72.33333333333333, "val_loss": 43.38244837522507, "val_acc": 72.0}
{"epoch": 33, "training_loss": 173.87996244430542, "training_acc": 72.33333333333333, "val_loss": 43.17165696620941, "val_acc": 72.0}
{"epoch": 34, "training_loss": 171.99903440475464, "training_acc": 72.33333333333333, "val_loss": 42.91040924191475, "val_acc": 72.0}
{"epoch": 35, "training_loss": 172.0157334804535, "training_acc": 72.33333333333333, "val_loss": 42.65176957845688, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 170.56439924240112, "training_acc": 72.33333333333333, "val_loss": 42.454867362976074, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 171.6166684627533, "training_acc": 71.66666666666667, "val_loss": 41.88650643825531, "val_acc": 72.0}
{"epoch": 38, "training_loss": 171.472065448761, "training_acc": 72.33333333333333, "val_loss": 41.66312211751938, "val_acc": 72.0}
{"epoch": 39, "training_loss": 170.87149930000305, "training_acc": 71.66666666666667, "val_loss": 41.80433177947998, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 171.448979139328, "training_acc": 71.0, "val_loss": 41.18183332681656, "val_acc": 72.0}
{"epoch": 41, "training_loss": 167.33297419548035, "training_acc": 72.33333333333333, "val_loss": 41.07041609287262, "val_acc": 72.0}
{"epoch": 42, "training_loss": 165.0096833705902, "training_acc": 72.33333333333333, "val_loss": 40.77142548561096, "val_acc": 72.0}
{"epoch": 43, "training_loss": 168.01713013648987, "training_acc": 73.0, "val_loss": 40.93624231219292, "val_acc": 72.0}
{"epoch": 44, "training_loss": 167.8889319896698, "training_acc": 73.0, "val_loss": 41.794630110263824, "val_acc": 70.66666666666667}
{"epoch": 45, "training_loss": 173.99452209472656, "training_acc": 72.66666666666667, "val_loss": 44.20131880044937, "val_acc": 53.333333333333336}
{"epoch": 46, "training_loss": 179.30368971824646, "training_acc": 69.0, "val_loss": 44.793106228113174, "val_acc": 72.0}
{"epoch": 47, "training_loss": 177.268972158432, "training_acc": 72.33333333333333, "val_loss": 43.351894557476044, "val_acc": 72.0}
{"epoch": 48, "training_loss": 173.6370906829834, "training_acc": 72.33333333333333, "val_loss": 43.56434208154678, "val_acc": 72.0}
{"epoch": 49, "training_loss": 175.12447047233582, "training_acc": 72.33333333333333, "val_loss": 43.23898106813431, "val_acc": 72.0}
{"epoch": 50, "training_loss": 173.0151183605194, "training_acc": 72.0, "val_loss": 42.634549617767334, "val_acc": 73.33333333333333}
{"epoch": 51, "training_loss": 171.6067590713501, "training_acc": 72.33333333333333, "val_loss": 42.42447301745415, "val_acc": 72.0}
{"epoch": 52, "training_loss": 169.6454553604126, "training_acc": 72.0, "val_loss": 42.231645703315735, "val_acc": 73.33333333333333}
{"epoch": 53, "training_loss": 170.12707328796387, "training_acc": 72.33333333333333, "val_loss": 42.68309372663498, "val_acc": 74.66666666666667}
{"epoch": 54, "training_loss": 171.70306503772736, "training_acc": 72.66666666666667, "val_loss": 44.84285718202591, "val_acc": 72.0}
{"epoch": 55, "training_loss": 180.799902677536, "training_acc": 70.66666666666667, "val_loss": 44.37630742788315, "val_acc": 53.333333333333336}
{"epoch": 56, "training_loss": 175.3649525642395, "training_acc": 73.33333333333333, "val_loss": 43.3655960559845, "val_acc": 72.0}
{"epoch": 57, "training_loss": 173.96351957321167, "training_acc": 72.33333333333333, "val_loss": 43.474967420101166, "val_acc": 76.0}
{"epoch": 58, "training_loss": 171.55139255523682, "training_acc": 72.0, "val_loss": 42.67576315999031, "val_acc": 72.0}
{"epoch": 59, "training_loss": 172.0672869682312, "training_acc": 72.33333333333333, "val_loss": 42.15429711341858, "val_acc": 72.0}
{"epoch": 60, "training_loss": 171.2256302833557, "training_acc": 72.0, "val_loss": 41.83447366952896, "val_acc": 72.0}
{"epoch": 61, "training_loss": 168.31763982772827, "training_acc": 72.0, "val_loss": 41.40236419439316, "val_acc": 72.0}
