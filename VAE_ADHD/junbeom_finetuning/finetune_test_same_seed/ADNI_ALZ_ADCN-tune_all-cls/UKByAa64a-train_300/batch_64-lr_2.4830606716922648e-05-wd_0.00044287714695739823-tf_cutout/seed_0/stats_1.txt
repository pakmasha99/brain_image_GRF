"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 189.76859426498413, "training_acc": 72.66666666666667, "val_loss": 46.191861271858215, "val_acc": 50.666666666666664}
{"epoch": 1, "training_loss": 169.06139397621155, "training_acc": 72.33333333333333, "val_loss": 43.431207835674286, "val_acc": 64.0}
{"epoch": 2, "training_loss": 166.73310256004333, "training_acc": 72.33333333333333, "val_loss": 43.09456852078438, "val_acc": 69.33333333333333}
{"epoch": 3, "training_loss": 162.86441087722778, "training_acc": 72.0, "val_loss": 43.96087694168091, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 153.05584287643433, "training_acc": 73.66666666666667, "val_loss": 43.395702838897705, "val_acc": 61.333333333333336}
{"epoch": 5, "training_loss": 150.82630944252014, "training_acc": 75.33333333333333, "val_loss": 44.795430302619934, "val_acc": 69.33333333333333}
{"epoch": 6, "training_loss": 144.515531539917, "training_acc": 75.66666666666667, "val_loss": 44.272495836019516, "val_acc": 60.0}
{"epoch": 7, "training_loss": 147.88170719146729, "training_acc": 78.0, "val_loss": 44.687768161296844, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 147.67800116539001, "training_acc": 78.0, "val_loss": 43.562219977378845, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 143.85503041744232, "training_acc": 77.33333333333333, "val_loss": 45.23066544532776, "val_acc": 62.666666666666664}
{"epoch": 10, "training_loss": 140.3339146375656, "training_acc": 78.66666666666667, "val_loss": 46.23592573404312, "val_acc": 61.333333333333336}
{"epoch": 11, "training_loss": 132.0568529367447, "training_acc": 80.33333333333333, "val_loss": 45.547386825084686, "val_acc": 62.666666666666664}
{"epoch": 12, "training_loss": 132.6783046722412, "training_acc": 80.0, "val_loss": 46.821541011333466, "val_acc": 58.666666666666664}
{"epoch": 13, "training_loss": 130.8744511604309, "training_acc": 82.0, "val_loss": 43.383848398923874, "val_acc": 60.0}
{"epoch": 14, "training_loss": 139.45493292808533, "training_acc": 77.0, "val_loss": 42.343395590782166, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 125.58469843864441, "training_acc": 83.0, "val_loss": 45.353123009204865, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 124.77447128295898, "training_acc": 79.66666666666667, "val_loss": 42.35228940844536, "val_acc": 72.0}
{"epoch": 17, "training_loss": 114.61766254901886, "training_acc": 85.66666666666667, "val_loss": 41.55123645067215, "val_acc": 68.0}
{"epoch": 18, "training_loss": 109.0697546005249, "training_acc": 86.0, "val_loss": 44.98167359828949, "val_acc": 74.66666666666667}
{"epoch": 19, "training_loss": 100.95827031135559, "training_acc": 87.0, "val_loss": 46.66155481338501, "val_acc": 74.66666666666667}
{"epoch": 20, "training_loss": 90.08346939086914, "training_acc": 90.33333333333333, "val_loss": 47.13598483800888, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 94.8642715215683, "training_acc": 89.66666666666667, "val_loss": 56.16089305281639, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 116.52909421920776, "training_acc": 81.33333333333333, "val_loss": 42.54804039001465, "val_acc": 76.0}
{"epoch": 23, "training_loss": 104.8528391122818, "training_acc": 87.33333333333333, "val_loss": 50.89780277013779, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 99.05933618545532, "training_acc": 88.66666666666667, "val_loss": 45.06292846798897, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 92.85048121213913, "training_acc": 89.33333333333333, "val_loss": 48.724328339099884, "val_acc": 72.0}
{"epoch": 26, "training_loss": 79.4036215543747, "training_acc": 90.33333333333333, "val_loss": 45.53653281927109, "val_acc": 74.66666666666667}
{"epoch": 27, "training_loss": 72.86900961399078, "training_acc": 89.66666666666667, "val_loss": 48.897614032030106, "val_acc": 68.0}
{"epoch": 28, "training_loss": 60.85902911424637, "training_acc": 92.66666666666667, "val_loss": 57.25575864315033, "val_acc": 76.0}
{"epoch": 29, "training_loss": 59.34616041183472, "training_acc": 92.66666666666667, "val_loss": 59.0195534825325, "val_acc": 76.0}
{"epoch": 30, "training_loss": 47.535374999046326, "training_acc": 94.66666666666667, "val_loss": 59.899412989616394, "val_acc": 74.66666666666667}
{"epoch": 31, "training_loss": 91.33547687530518, "training_acc": 89.33333333333333, "val_loss": 83.51334553956985, "val_acc": 70.66666666666667}
{"epoch": 32, "training_loss": 94.80134963989258, "training_acc": 87.33333333333333, "val_loss": 61.42083811759949, "val_acc": 72.0}
{"epoch": 33, "training_loss": 103.94518744945526, "training_acc": 85.0, "val_loss": 42.426399648189545, "val_acc": 76.0}
{"epoch": 34, "training_loss": 75.96851468086243, "training_acc": 92.0, "val_loss": 48.22079238295555, "val_acc": 77.33333333333333}
{"epoch": 35, "training_loss": 59.30673158168793, "training_acc": 92.33333333333333, "val_loss": 54.37635713815689, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 45.0091427564621, "training_acc": 95.33333333333333, "val_loss": 55.406324326992035, "val_acc": 76.0}
