"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 187.89194083213806, "training_acc": 60.0, "val_loss": 47.983339965343475, "val_acc": 32.0}
{"epoch": 1, "training_loss": 216.3455159664154, "training_acc": 74.0, "val_loss": 45.50762605667114, "val_acc": 64.0}
{"epoch": 2, "training_loss": 173.70287561416626, "training_acc": 72.33333333333333, "val_loss": 85.18592703342438, "val_acc": 28.0}
{"epoch": 3, "training_loss": 234.6915512084961, "training_acc": 59.0, "val_loss": 44.319569647312164, "val_acc": 72.0}
{"epoch": 4, "training_loss": 180.96149492263794, "training_acc": 72.33333333333333, "val_loss": 44.34040588140488, "val_acc": 72.0}
{"epoch": 5, "training_loss": 178.1989929676056, "training_acc": 72.33333333333333, "val_loss": 44.083780229091644, "val_acc": 72.0}
{"epoch": 6, "training_loss": 171.5780086517334, "training_acc": 72.33333333333333, "val_loss": 43.64992040395737, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 167.01402473449707, "training_acc": 72.33333333333333, "val_loss": 43.072873532772064, "val_acc": 61.333333333333336}
{"epoch": 8, "training_loss": 163.5624122619629, "training_acc": 72.33333333333333, "val_loss": 50.643197417259216, "val_acc": 69.33333333333333}
{"epoch": 9, "training_loss": 172.528874874115, "training_acc": 71.33333333333333, "val_loss": 42.987137258052826, "val_acc": 62.666666666666664}
{"epoch": 10, "training_loss": 167.564532995224, "training_acc": 73.0, "val_loss": 43.18243330717087, "val_acc": 64.0}
{"epoch": 11, "training_loss": 166.15321898460388, "training_acc": 72.33333333333333, "val_loss": 43.32404559850693, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 161.9030487537384, "training_acc": 72.66666666666667, "val_loss": 43.21801194548607, "val_acc": 62.666666666666664}
{"epoch": 13, "training_loss": 156.1457531452179, "training_acc": 74.0, "val_loss": 45.9762316942215, "val_acc": 66.66666666666667}
{"epoch": 14, "training_loss": 153.38313555717468, "training_acc": 73.66666666666667, "val_loss": 45.311914801597595, "val_acc": 60.0}
{"epoch": 15, "training_loss": 149.41258001327515, "training_acc": 74.33333333333333, "val_loss": 45.83601796627045, "val_acc": 61.333333333333336}
{"epoch": 16, "training_loss": 153.99779295921326, "training_acc": 76.0, "val_loss": 48.258678793907166, "val_acc": 65.33333333333333}
{"epoch": 17, "training_loss": 155.27808451652527, "training_acc": 73.33333333333333, "val_loss": 44.52201563119888, "val_acc": 65.33333333333333}
{"epoch": 18, "training_loss": 153.91625213623047, "training_acc": 73.66666666666667, "val_loss": 45.647255539894104, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 153.8707733154297, "training_acc": 76.66666666666667, "val_loss": 45.26050513982773, "val_acc": 66.66666666666667}
{"epoch": 20, "training_loss": 153.34382009506226, "training_acc": 76.0, "val_loss": 49.40273243188858, "val_acc": 53.333333333333336}
{"epoch": 21, "training_loss": 164.67472052574158, "training_acc": 73.33333333333333, "val_loss": 44.77510446310043, "val_acc": 61.333333333333336}
{"epoch": 22, "training_loss": 160.5723056793213, "training_acc": 76.33333333333333, "val_loss": 46.76343894004822, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 167.5023455619812, "training_acc": 72.33333333333333, "val_loss": 43.07489448785782, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 167.20283889770508, "training_acc": 74.66666666666667, "val_loss": 43.69081270694733, "val_acc": 62.666666666666664}
{"epoch": 25, "training_loss": 158.44039225578308, "training_acc": 74.0, "val_loss": 45.31464874744415, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 154.83843612670898, "training_acc": 73.66666666666667, "val_loss": 44.680104821920395, "val_acc": 60.0}
{"epoch": 27, "training_loss": 150.292959690094, "training_acc": 75.66666666666667, "val_loss": 51.9211340546608, "val_acc": 69.33333333333333}
{"epoch": 28, "training_loss": 157.34367656707764, "training_acc": 72.0, "val_loss": 46.05432027578354, "val_acc": 66.66666666666667}
