"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 198.47945356369019, "training_acc": 62.333333333333336, "val_loss": 44.66242790222168, "val_acc": 77.33333333333333}
{"epoch": 1, "training_loss": 178.00594854354858, "training_acc": 72.33333333333333, "val_loss": 42.98554229736328, "val_acc": 72.0}
{"epoch": 2, "training_loss": 172.10129475593567, "training_acc": 72.33333333333333, "val_loss": 40.87070143222809, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 169.27090859413147, "training_acc": 72.33333333333333, "val_loss": 38.411442279815674, "val_acc": 80.0}
{"epoch": 4, "training_loss": 165.37283492088318, "training_acc": 72.33333333333333, "val_loss": 37.636980414390564, "val_acc": 74.66666666666667}
{"epoch": 5, "training_loss": 159.63538074493408, "training_acc": 72.33333333333333, "val_loss": 38.835613429546356, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 160.25946879386902, "training_acc": 74.33333333333333, "val_loss": 35.35252049565315, "val_acc": 80.0}
{"epoch": 7, "training_loss": 158.28907871246338, "training_acc": 73.0, "val_loss": 40.743343859910965, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 155.74261045455933, "training_acc": 76.33333333333333, "val_loss": 35.18113434314728, "val_acc": 80.0}
{"epoch": 9, "training_loss": 153.8815598487854, "training_acc": 75.33333333333333, "val_loss": 39.365755677223206, "val_acc": 74.66666666666667}
{"epoch": 10, "training_loss": 158.43206357955933, "training_acc": 72.0, "val_loss": 37.740942627191544, "val_acc": 76.0}
{"epoch": 11, "training_loss": 153.5980006456375, "training_acc": 77.0, "val_loss": 39.978065729141235, "val_acc": 76.0}
{"epoch": 12, "training_loss": 155.33081150054932, "training_acc": 75.66666666666667, "val_loss": 33.52148962020874, "val_acc": 82.66666666666667}
{"epoch": 13, "training_loss": 148.13934588432312, "training_acc": 75.0, "val_loss": 34.19880247116089, "val_acc": 80.0}
{"epoch": 14, "training_loss": 145.5952067375183, "training_acc": 78.33333333333333, "val_loss": 35.49387511610985, "val_acc": 77.33333333333333}
{"epoch": 15, "training_loss": 138.25689351558685, "training_acc": 79.66666666666667, "val_loss": 36.409859865903854, "val_acc": 77.33333333333333}
{"epoch": 16, "training_loss": 143.99963808059692, "training_acc": 75.66666666666667, "val_loss": 36.928883612155914, "val_acc": 76.0}
{"epoch": 17, "training_loss": 137.2133572101593, "training_acc": 78.0, "val_loss": 57.09489071369171, "val_acc": 72.0}
{"epoch": 18, "training_loss": 169.66613745689392, "training_acc": 76.0, "val_loss": 36.0850630402565, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 146.13231134414673, "training_acc": 78.0, "val_loss": 34.05871921777725, "val_acc": 78.66666666666667}
{"epoch": 20, "training_loss": 136.66007268428802, "training_acc": 79.0, "val_loss": 31.853127390146255, "val_acc": 84.0}
{"epoch": 21, "training_loss": 120.5313720703125, "training_acc": 83.66666666666667, "val_loss": 31.20908272266388, "val_acc": 82.66666666666667}
{"epoch": 22, "training_loss": 111.03405040502548, "training_acc": 83.66666666666667, "val_loss": 45.42912673577666, "val_acc": 76.0}
{"epoch": 23, "training_loss": 127.08411478996277, "training_acc": 80.66666666666667, "val_loss": 31.11964038014412, "val_acc": 78.66666666666667}
{"epoch": 24, "training_loss": 105.38916432857513, "training_acc": 87.0, "val_loss": 31.935177594423294, "val_acc": 82.66666666666667}
{"epoch": 25, "training_loss": 120.64511513710022, "training_acc": 81.0, "val_loss": 35.402890741825104, "val_acc": 78.66666666666667}
{"epoch": 26, "training_loss": 112.66043066978455, "training_acc": 85.33333333333333, "val_loss": 29.650989711284637, "val_acc": 82.66666666666667}
{"epoch": 27, "training_loss": 107.41461563110352, "training_acc": 84.0, "val_loss": 35.61504179239273, "val_acc": 72.0}
{"epoch": 28, "training_loss": 92.935631275177, "training_acc": 87.0, "val_loss": 39.12986671924591, "val_acc": 72.0}
{"epoch": 29, "training_loss": 100.60792458057404, "training_acc": 85.0, "val_loss": 35.88988119363785, "val_acc": 80.0}
{"epoch": 30, "training_loss": 81.34983855485916, "training_acc": 87.66666666666667, "val_loss": 39.31325227022171, "val_acc": 80.0}
{"epoch": 31, "training_loss": 83.58032417297363, "training_acc": 90.0, "val_loss": 45.63263380527496, "val_acc": 78.66666666666667}
{"epoch": 32, "training_loss": 67.9951496720314, "training_acc": 91.33333333333333, "val_loss": 33.852753818035126, "val_acc": 88.0}
{"epoch": 33, "training_loss": 53.77446752786636, "training_acc": 94.66666666666667, "val_loss": 46.647273540496826, "val_acc": 69.33333333333333}
{"epoch": 34, "training_loss": 97.32772171497345, "training_acc": 83.66666666666667, "val_loss": 39.15013809502125, "val_acc": 81.33333333333333}
{"epoch": 35, "training_loss": 76.9196429848671, "training_acc": 90.66666666666667, "val_loss": 34.096355617046356, "val_acc": 81.33333333333333}
{"epoch": 36, "training_loss": 67.51544046401978, "training_acc": 91.66666666666667, "val_loss": 32.44877815246582, "val_acc": 89.33333333333333}
{"epoch": 37, "training_loss": 41.19091419875622, "training_acc": 96.0, "val_loss": 35.238995445892215, "val_acc": 86.66666666666667}
{"epoch": 38, "training_loss": 79.10030472278595, "training_acc": 90.33333333333333, "val_loss": 42.91458038985729, "val_acc": 68.0}
{"epoch": 39, "training_loss": 82.99891746044159, "training_acc": 88.66666666666667, "val_loss": 29.01341688632965, "val_acc": 85.33333333333333}
{"epoch": 40, "training_loss": 67.48794639110565, "training_acc": 91.0, "val_loss": 47.30901938676834, "val_acc": 77.33333333333333}
{"epoch": 41, "training_loss": 61.75485920906067, "training_acc": 92.33333333333333, "val_loss": 37.321963369846344, "val_acc": 82.66666666666667}
{"epoch": 42, "training_loss": 65.5964070558548, "training_acc": 90.66666666666667, "val_loss": 33.08620196580887, "val_acc": 86.66666666666667}
{"epoch": 43, "training_loss": 57.226601362228394, "training_acc": 92.33333333333333, "val_loss": 47.36649227142334, "val_acc": 68.0}
{"epoch": 44, "training_loss": 60.66538920998573, "training_acc": 91.33333333333333, "val_loss": 30.626256108283997, "val_acc": 86.66666666666667}
{"epoch": 45, "training_loss": 33.016279220581055, "training_acc": 97.33333333333333, "val_loss": 37.501354306936264, "val_acc": 86.66666666666667}
{"epoch": 46, "training_loss": 22.594494376331568, "training_acc": 97.0, "val_loss": 47.15019242465496, "val_acc": 86.66666666666667}
{"epoch": 47, "training_loss": 16.392199523746967, "training_acc": 98.0, "val_loss": 46.60259401798248, "val_acc": 89.33333333333333}
{"epoch": 48, "training_loss": 14.20274218916893, "training_acc": 98.66666666666667, "val_loss": 63.59417510032654, "val_acc": 84.0}
{"epoch": 49, "training_loss": 100.56740951538086, "training_acc": 88.66666666666667, "val_loss": 47.35134369134903, "val_acc": 81.33333333333333}
{"epoch": 50, "training_loss": 105.75419175624847, "training_acc": 84.0, "val_loss": 32.09736451506615, "val_acc": 84.0}
{"epoch": 51, "training_loss": 102.42269366979599, "training_acc": 89.0, "val_loss": 41.28100222349167, "val_acc": 77.33333333333333}
{"epoch": 52, "training_loss": 111.34303021430969, "training_acc": 81.66666666666667, "val_loss": 35.25518414378166, "val_acc": 70.66666666666667}
{"epoch": 53, "training_loss": 75.07895696163177, "training_acc": 92.0, "val_loss": 33.99784402549267, "val_acc": 81.33333333333333}
{"epoch": 54, "training_loss": 53.399821400642395, "training_acc": 93.33333333333333, "val_loss": 41.93875974416733, "val_acc": 82.66666666666667}
{"epoch": 55, "training_loss": 36.004184037446976, "training_acc": 95.33333333333333, "val_loss": 35.87915325164795, "val_acc": 88.0}
{"epoch": 56, "training_loss": 20.923206508159637, "training_acc": 97.0, "val_loss": 42.226094134151936, "val_acc": 84.0}
{"epoch": 57, "training_loss": 16.793898284435272, "training_acc": 98.33333333333333, "val_loss": 46.39586120843887, "val_acc": 84.0}
{"epoch": 58, "training_loss": 9.775717496871948, "training_acc": 99.0, "val_loss": 62.149476289749146, "val_acc": 84.0}
