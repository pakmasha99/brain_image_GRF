"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 179.14477241039276, "training_acc": 63.0, "val_loss": 55.17868089675903, "val_acc": 28.0}
{"epoch": 1, "training_loss": 279.4848384857178, "training_acc": 60.666666666666664, "val_loss": 45.15314495563507, "val_acc": 72.0}
{"epoch": 2, "training_loss": 183.35174942016602, "training_acc": 72.33333333333333, "val_loss": 44.345806896686554, "val_acc": 72.0}
{"epoch": 3, "training_loss": 176.1910970211029, "training_acc": 73.66666666666667, "val_loss": 45.38687324523926, "val_acc": 56.0}
{"epoch": 4, "training_loss": 173.64812350273132, "training_acc": 72.33333333333333, "val_loss": 43.94012373685837, "val_acc": 69.33333333333333}
{"epoch": 5, "training_loss": 171.3777632713318, "training_acc": 72.33333333333333, "val_loss": 43.5667918920517, "val_acc": 72.0}
{"epoch": 6, "training_loss": 169.3239803314209, "training_acc": 72.0, "val_loss": 44.52578270435333, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 163.72686862945557, "training_acc": 72.66666666666667, "val_loss": 45.53720676898956, "val_acc": 52.0}
{"epoch": 8, "training_loss": 169.431866645813, "training_acc": 73.66666666666667, "val_loss": 44.224829494953156, "val_acc": 60.0}
{"epoch": 9, "training_loss": 166.91146862506866, "training_acc": 71.66666666666667, "val_loss": 50.491590082645416, "val_acc": 72.0}
{"epoch": 10, "training_loss": 182.85865759849548, "training_acc": 72.33333333333333, "val_loss": 44.828715205192566, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 182.35197496414185, "training_acc": 72.33333333333333, "val_loss": 44.46433734893799, "val_acc": 72.0}
{"epoch": 12, "training_loss": 175.38374662399292, "training_acc": 72.33333333333333, "val_loss": 44.365177273750305, "val_acc": 72.0}
{"epoch": 13, "training_loss": 172.92328262329102, "training_acc": 72.33333333333333, "val_loss": 43.76127517223358, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 166.49273419380188, "training_acc": 72.33333333333333, "val_loss": 46.4937749505043, "val_acc": 72.0}
{"epoch": 15, "training_loss": 178.99239301681519, "training_acc": 71.66666666666667, "val_loss": 43.45149314403534, "val_acc": 66.66666666666667}
{"epoch": 16, "training_loss": 173.06333112716675, "training_acc": 72.33333333333333, "val_loss": 43.609985798597336, "val_acc": 72.0}
{"epoch": 17, "training_loss": 171.19889187812805, "training_acc": 73.66666666666667, "val_loss": 43.54673773050308, "val_acc": 66.66666666666667}
{"epoch": 18, "training_loss": 166.02603483200073, "training_acc": 72.0, "val_loss": 43.48765605688095, "val_acc": 66.66666666666667}
{"epoch": 19, "training_loss": 157.92539596557617, "training_acc": 73.66666666666667, "val_loss": 44.69132924079895, "val_acc": 68.0}
{"epoch": 20, "training_loss": 159.54217970371246, "training_acc": 75.66666666666667, "val_loss": 48.619891703128815, "val_acc": 72.0}
{"epoch": 21, "training_loss": 169.035071849823, "training_acc": 72.66666666666667, "val_loss": 50.705635607242584, "val_acc": 44.0}
{"epoch": 22, "training_loss": 168.3083622455597, "training_acc": 71.0, "val_loss": 45.33806949853897, "val_acc": 72.0}
{"epoch": 23, "training_loss": 173.8983337879181, "training_acc": 72.33333333333333, "val_loss": 43.68721425533295, "val_acc": 72.0}
{"epoch": 24, "training_loss": 167.50194096565247, "training_acc": 72.33333333333333, "val_loss": 43.549730479717255, "val_acc": 64.0}
{"epoch": 25, "training_loss": 162.55785024166107, "training_acc": 72.33333333333333, "val_loss": 43.264300525188446, "val_acc": 66.66666666666667}
{"epoch": 26, "training_loss": 155.30476331710815, "training_acc": 73.33333333333333, "val_loss": 43.797575891017914, "val_acc": 65.33333333333333}
{"epoch": 27, "training_loss": 154.0644714832306, "training_acc": 75.0, "val_loss": 46.15079343318939, "val_acc": 61.333333333333336}
{"epoch": 28, "training_loss": 155.3439600467682, "training_acc": 74.0, "val_loss": 48.143486976623535, "val_acc": 65.33333333333333}
{"epoch": 29, "training_loss": 160.09586381912231, "training_acc": 75.0, "val_loss": 46.624518275260925, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 159.2660915851593, "training_acc": 73.66666666666667, "val_loss": 44.66603696346283, "val_acc": 50.666666666666664}
{"epoch": 31, "training_loss": 159.73098850250244, "training_acc": 72.66666666666667, "val_loss": 44.3471497297287, "val_acc": 68.0}
{"epoch": 32, "training_loss": 156.57485818862915, "training_acc": 73.66666666666667, "val_loss": 43.60584777593613, "val_acc": 62.666666666666664}
{"epoch": 33, "training_loss": 156.247976064682, "training_acc": 75.66666666666667, "val_loss": 44.46667551994324, "val_acc": 62.666666666666664}
{"epoch": 34, "training_loss": 159.50768494606018, "training_acc": 72.33333333333333, "val_loss": 48.12158888578415, "val_acc": 70.66666666666667}
{"epoch": 35, "training_loss": 154.69340133666992, "training_acc": 74.33333333333333, "val_loss": 44.65822595357895, "val_acc": 56.0}
{"epoch": 36, "training_loss": 151.50100243091583, "training_acc": 72.66666666666667, "val_loss": 46.40312337875366, "val_acc": 68.0}
{"epoch": 37, "training_loss": 156.94768524169922, "training_acc": 73.33333333333333, "val_loss": 44.697427213191986, "val_acc": 64.0}
{"epoch": 38, "training_loss": 152.90704083442688, "training_acc": 74.66666666666667, "val_loss": 44.36864638328552, "val_acc": 64.0}
{"epoch": 39, "training_loss": 152.6834373474121, "training_acc": 75.66666666666667, "val_loss": 46.290064334869385, "val_acc": 65.33333333333333}
{"epoch": 40, "training_loss": 151.8577651977539, "training_acc": 74.0, "val_loss": 44.960231959819794, "val_acc": 66.66666666666667}
{"epoch": 41, "training_loss": 151.22363352775574, "training_acc": 74.66666666666667, "val_loss": 43.970546662807465, "val_acc": 68.0}
{"epoch": 42, "training_loss": 149.75251424312592, "training_acc": 73.66666666666667, "val_loss": 44.450775146484375, "val_acc": 66.66666666666667}
{"epoch": 43, "training_loss": 150.64255452156067, "training_acc": 75.0, "val_loss": 46.100660622119904, "val_acc": 65.33333333333333}
{"epoch": 44, "training_loss": 151.4952278137207, "training_acc": 75.0, "val_loss": 45.0047065615654, "val_acc": 61.333333333333336}
