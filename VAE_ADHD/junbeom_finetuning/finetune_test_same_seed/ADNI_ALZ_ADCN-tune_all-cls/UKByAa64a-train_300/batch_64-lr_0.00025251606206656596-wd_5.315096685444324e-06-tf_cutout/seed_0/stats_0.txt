"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 181.6371340751648, "training_acc": 71.66666666666667, "val_loss": 49.55802595615387, "val_acc": 73.33333333333333}
{"epoch": 1, "training_loss": 214.49755024909973, "training_acc": 72.0, "val_loss": 44.65778225660324, "val_acc": 78.66666666666667}
{"epoch": 2, "training_loss": 196.33359384536743, "training_acc": 61.666666666666664, "val_loss": 43.42094612121582, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 179.42665195465088, "training_acc": 72.0, "val_loss": 43.183340549468994, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 181.4147732257843, "training_acc": 72.0, "val_loss": 43.620762288570404, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 179.85009837150574, "training_acc": 72.0, "val_loss": 43.349825859069824, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 176.7205138206482, "training_acc": 72.0, "val_loss": 42.59358564019203, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 175.91370153427124, "training_acc": 72.0, "val_loss": 41.797366976737976, "val_acc": 76.0}
{"epoch": 8, "training_loss": 175.50442266464233, "training_acc": 72.0, "val_loss": 41.879928052425385, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 175.22849082946777, "training_acc": 72.0, "val_loss": 38.77864366769791, "val_acc": 78.66666666666667}
{"epoch": 10, "training_loss": 169.1466236114502, "training_acc": 72.0, "val_loss": 37.066027879714966, "val_acc": 74.66666666666667}
{"epoch": 11, "training_loss": 165.43157052993774, "training_acc": 72.33333333333333, "val_loss": 49.09759533405304, "val_acc": 33.333333333333336}
{"epoch": 12, "training_loss": 185.18029165267944, "training_acc": 68.66666666666667, "val_loss": 41.237618178129196, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 173.7420175075531, "training_acc": 72.0, "val_loss": 43.86018663644791, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 176.76440978050232, "training_acc": 72.0, "val_loss": 41.74205109477043, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 177.271164894104, "training_acc": 72.0, "val_loss": 40.53064185380936, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 173.56125330924988, "training_acc": 72.0, "val_loss": 40.84007948637009, "val_acc": 77.33333333333333}
{"epoch": 17, "training_loss": 171.18568658828735, "training_acc": 72.0, "val_loss": 38.81309774518013, "val_acc": 77.33333333333333}
{"epoch": 18, "training_loss": 168.11420822143555, "training_acc": 72.0, "val_loss": 37.212155282497406, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 169.15081143379211, "training_acc": 72.0, "val_loss": 39.39871472120285, "val_acc": 64.0}
{"epoch": 20, "training_loss": 168.7971270084381, "training_acc": 69.33333333333333, "val_loss": 39.237730860710144, "val_acc": 78.66666666666667}
{"epoch": 21, "training_loss": 170.8010413646698, "training_acc": 72.0, "val_loss": 37.30732840299606, "val_acc": 78.66666666666667}
{"epoch": 22, "training_loss": 163.3541977405548, "training_acc": 72.0, "val_loss": 35.53719228506088, "val_acc": 78.66666666666667}
{"epoch": 23, "training_loss": 162.62436747550964, "training_acc": 71.66666666666667, "val_loss": 35.0112646818161, "val_acc": 76.0}
{"epoch": 24, "training_loss": 164.56574010849, "training_acc": 71.0, "val_loss": 34.43368619680405, "val_acc": 74.66666666666667}
{"epoch": 25, "training_loss": 166.19553136825562, "training_acc": 72.66666666666667, "val_loss": 45.278005838394165, "val_acc": 46.666666666666664}
{"epoch": 26, "training_loss": 174.76192104816437, "training_acc": 70.33333333333333, "val_loss": 38.66575425863266, "val_acc": 77.33333333333333}
{"epoch": 27, "training_loss": 170.426349401474, "training_acc": 72.0, "val_loss": 37.930665493011475, "val_acc": 78.66666666666667}
{"epoch": 28, "training_loss": 162.71210932731628, "training_acc": 72.0, "val_loss": 36.70542907714844, "val_acc": 78.66666666666667}
{"epoch": 29, "training_loss": 163.94831776618958, "training_acc": 71.33333333333333, "val_loss": 35.09646421670914, "val_acc": 78.66666666666667}
{"epoch": 30, "training_loss": 165.8276959657669, "training_acc": 71.0, "val_loss": 35.08662539720535, "val_acc": 78.66666666666667}
{"epoch": 31, "training_loss": 162.53031277656555, "training_acc": 73.33333333333333, "val_loss": 37.08571130037308, "val_acc": 72.0}
{"epoch": 32, "training_loss": 163.60186672210693, "training_acc": 72.66666666666667, "val_loss": 34.649185359478, "val_acc": 76.0}
{"epoch": 33, "training_loss": 159.41678524017334, "training_acc": 73.66666666666667, "val_loss": 34.121453911066055, "val_acc": 78.66666666666667}
{"epoch": 34, "training_loss": 159.64124584197998, "training_acc": 74.0, "val_loss": 33.68939024209976, "val_acc": 78.66666666666667}
{"epoch": 35, "training_loss": 159.27920806407928, "training_acc": 75.33333333333333, "val_loss": 35.45455580949783, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 156.42606937885284, "training_acc": 75.66666666666667, "val_loss": 33.272340536117554, "val_acc": 78.66666666666667}
{"epoch": 37, "training_loss": 153.128351688385, "training_acc": 75.66666666666667, "val_loss": 32.10292398929596, "val_acc": 82.66666666666667}
{"epoch": 38, "training_loss": 159.25570952892303, "training_acc": 74.0, "val_loss": 33.76585438847542, "val_acc": 76.0}
{"epoch": 39, "training_loss": 150.70011734962463, "training_acc": 76.33333333333333, "val_loss": 30.20098802447319, "val_acc": 82.66666666666667}
{"epoch": 40, "training_loss": 153.32257437705994, "training_acc": 76.33333333333333, "val_loss": 34.01972609758377, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 148.4218224287033, "training_acc": 79.33333333333333, "val_loss": 29.751201301813126, "val_acc": 86.66666666666667}
{"epoch": 42, "training_loss": 140.21467792987823, "training_acc": 77.66666666666667, "val_loss": 31.074376702308655, "val_acc": 80.0}
{"epoch": 43, "training_loss": 150.08811283111572, "training_acc": 76.0, "val_loss": 31.670392632484436, "val_acc": 76.0}
{"epoch": 44, "training_loss": 169.34896230697632, "training_acc": 71.66666666666667, "val_loss": 40.68427795171738, "val_acc": 80.0}
{"epoch": 45, "training_loss": 168.85210180282593, "training_acc": 72.0, "val_loss": 38.39672303199768, "val_acc": 78.66666666666667}
{"epoch": 46, "training_loss": 166.03634357452393, "training_acc": 74.33333333333333, "val_loss": 35.4468292593956, "val_acc": 78.66666666666667}
{"epoch": 47, "training_loss": 158.89215230941772, "training_acc": 73.66666666666667, "val_loss": 34.374762535095215, "val_acc": 78.66666666666667}
{"epoch": 48, "training_loss": 158.4949653148651, "training_acc": 75.33333333333333, "val_loss": 33.25615304708481, "val_acc": 80.0}
{"epoch": 49, "training_loss": 152.23343896865845, "training_acc": 78.66666666666667, "val_loss": 31.92264574766159, "val_acc": 84.0}
{"epoch": 50, "training_loss": 138.38414359092712, "training_acc": 79.0, "val_loss": 37.03082624077797, "val_acc": 70.66666666666667}
{"epoch": 51, "training_loss": 211.3323986530304, "training_acc": 68.66666666666667, "val_loss": 40.4336012005806, "val_acc": 78.66666666666667}
{"epoch": 52, "training_loss": 173.95711588859558, "training_acc": 72.33333333333333, "val_loss": 39.81819561123848, "val_acc": 78.66666666666667}
{"epoch": 53, "training_loss": 170.3754153251648, "training_acc": 73.0, "val_loss": 37.369228810071945, "val_acc": 78.66666666666667}
{"epoch": 54, "training_loss": 166.6200773715973, "training_acc": 73.66666666666667, "val_loss": 41.411350935697556, "val_acc": 57.333333333333336}
{"epoch": 55, "training_loss": 168.06340312957764, "training_acc": 71.66666666666667, "val_loss": 37.229698836803436, "val_acc": 78.66666666666667}
{"epoch": 56, "training_loss": 166.75068068504333, "training_acc": 72.33333333333333, "val_loss": 36.42083251476288, "val_acc": 74.66666666666667}
{"epoch": 57, "training_loss": 162.7371265888214, "training_acc": 73.0, "val_loss": 36.866366505622864, "val_acc": 70.66666666666667}
{"epoch": 58, "training_loss": 171.10318100452423, "training_acc": 73.0, "val_loss": 40.14960139989853, "val_acc": 73.33333333333333}
{"epoch": 59, "training_loss": 181.19002079963684, "training_acc": 72.0, "val_loss": 40.10870838165283, "val_acc": 77.33333333333333}
{"epoch": 60, "training_loss": 173.59311151504517, "training_acc": 72.0, "val_loss": 40.145950973033905, "val_acc": 78.66666666666667}
