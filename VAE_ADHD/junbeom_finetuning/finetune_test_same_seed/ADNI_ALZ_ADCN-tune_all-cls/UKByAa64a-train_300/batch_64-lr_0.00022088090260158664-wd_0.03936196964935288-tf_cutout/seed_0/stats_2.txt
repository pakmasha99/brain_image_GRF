"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 178.79813408851624, "training_acc": 65.33333333333333, "val_loss": 44.06354534626007, "val_acc": 72.0}
{"epoch": 1, "training_loss": 209.33178520202637, "training_acc": 62.333333333333336, "val_loss": 44.17788988351822, "val_acc": 72.0}
{"epoch": 2, "training_loss": 201.0798258781433, "training_acc": 72.33333333333333, "val_loss": 44.90885490179062, "val_acc": 72.0}
{"epoch": 3, "training_loss": 179.74500799179077, "training_acc": 72.33333333333333, "val_loss": 44.32965785264969, "val_acc": 72.0}
{"epoch": 4, "training_loss": 177.19232559204102, "training_acc": 72.33333333333333, "val_loss": 44.41724634170532, "val_acc": 72.0}
{"epoch": 5, "training_loss": 176.1672945022583, "training_acc": 72.33333333333333, "val_loss": 44.53789275884628, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 179.11798644065857, "training_acc": 72.33333333333333, "val_loss": 44.376244604587555, "val_acc": 72.0}
{"epoch": 7, "training_loss": 176.0552749633789, "training_acc": 72.33333333333333, "val_loss": 44.45100274682045, "val_acc": 72.0}
{"epoch": 8, "training_loss": 172.9151804447174, "training_acc": 72.33333333333333, "val_loss": 44.52944129705429, "val_acc": 72.0}
{"epoch": 9, "training_loss": 172.7355499267578, "training_acc": 72.33333333333333, "val_loss": 43.490787625312805, "val_acc": 68.0}
{"epoch": 10, "training_loss": 170.09682941436768, "training_acc": 72.33333333333333, "val_loss": 46.40570366382599, "val_acc": 40.0}
{"epoch": 11, "training_loss": 173.83221244812012, "training_acc": 72.33333333333333, "val_loss": 46.7911856174469, "val_acc": 72.0}
{"epoch": 12, "training_loss": 169.34603667259216, "training_acc": 72.33333333333333, "val_loss": 43.61741000413895, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 159.1584038734436, "training_acc": 72.33333333333333, "val_loss": 43.62928581237793, "val_acc": 65.33333333333333}
{"epoch": 14, "training_loss": 162.46930575370789, "training_acc": 74.33333333333333, "val_loss": 44.00823423266411, "val_acc": 66.66666666666667}
{"epoch": 15, "training_loss": 152.9373540878296, "training_acc": 73.66666666666667, "val_loss": 44.09972730278969, "val_acc": 70.66666666666667}
{"epoch": 16, "training_loss": 153.4196766614914, "training_acc": 74.33333333333333, "val_loss": 46.5818789601326, "val_acc": 66.66666666666667}
{"epoch": 17, "training_loss": 161.32466411590576, "training_acc": 74.0, "val_loss": 44.297526478767395, "val_acc": 61.333333333333336}
{"epoch": 18, "training_loss": 165.6822246313095, "training_acc": 73.66666666666667, "val_loss": 43.69504678249359, "val_acc": 72.0}
{"epoch": 19, "training_loss": 171.94796466827393, "training_acc": 72.33333333333333, "val_loss": 43.11920404434204, "val_acc": 72.0}
{"epoch": 20, "training_loss": 164.94756364822388, "training_acc": 72.33333333333333, "val_loss": 43.26760309934616, "val_acc": 69.33333333333333}
{"epoch": 21, "training_loss": 161.2484381198883, "training_acc": 72.33333333333333, "val_loss": 44.601356506347656, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 153.08415865898132, "training_acc": 72.0, "val_loss": 44.05796441435814, "val_acc": 57.333333333333336}
{"epoch": 23, "training_loss": 159.30686962604523, "training_acc": 73.66666666666667, "val_loss": 45.93896323442459, "val_acc": 50.666666666666664}
{"epoch": 24, "training_loss": 167.94347643852234, "training_acc": 70.0, "val_loss": 44.247929871082306, "val_acc": 68.0}
{"epoch": 25, "training_loss": 162.90918135643005, "training_acc": 71.0, "val_loss": 43.59621274471283, "val_acc": 61.333333333333336}
{"epoch": 26, "training_loss": 161.2855143547058, "training_acc": 72.66666666666667, "val_loss": 45.258388340473175, "val_acc": 69.33333333333333}
{"epoch": 27, "training_loss": 157.38832330703735, "training_acc": 72.0, "val_loss": 43.524074375629425, "val_acc": 61.333333333333336}
{"epoch": 28, "training_loss": 153.07628095149994, "training_acc": 74.33333333333333, "val_loss": 47.364527463912964, "val_acc": 69.33333333333333}
{"epoch": 29, "training_loss": 155.08969521522522, "training_acc": 74.33333333333333, "val_loss": 44.69299405813217, "val_acc": 66.66666666666667}
{"epoch": 30, "training_loss": 150.86136543750763, "training_acc": 73.66666666666667, "val_loss": 44.34750646352768, "val_acc": 62.666666666666664}
{"epoch": 31, "training_loss": 151.2405242919922, "training_acc": 75.0, "val_loss": 47.10513636469841, "val_acc": 65.33333333333333}
{"epoch": 32, "training_loss": 150.33058631420135, "training_acc": 74.33333333333333, "val_loss": 44.46108257770538, "val_acc": 69.33333333333333}
{"epoch": 33, "training_loss": 148.6828237771988, "training_acc": 74.0, "val_loss": 44.50999742746353, "val_acc": 68.0}
{"epoch": 34, "training_loss": 147.1045060157776, "training_acc": 75.66666666666667, "val_loss": 45.58988535404205, "val_acc": 68.0}
{"epoch": 35, "training_loss": 148.940434217453, "training_acc": 76.33333333333333, "val_loss": 44.10930114984512, "val_acc": 66.66666666666667}
{"epoch": 36, "training_loss": 146.37088918685913, "training_acc": 75.0, "val_loss": 44.018857419490814, "val_acc": 69.33333333333333}
{"epoch": 37, "training_loss": 145.78235352039337, "training_acc": 76.33333333333333, "val_loss": 43.29204761981964, "val_acc": 65.33333333333333}
{"epoch": 38, "training_loss": 145.84945487976074, "training_acc": 75.0, "val_loss": 46.075560212135315, "val_acc": 69.33333333333333}
