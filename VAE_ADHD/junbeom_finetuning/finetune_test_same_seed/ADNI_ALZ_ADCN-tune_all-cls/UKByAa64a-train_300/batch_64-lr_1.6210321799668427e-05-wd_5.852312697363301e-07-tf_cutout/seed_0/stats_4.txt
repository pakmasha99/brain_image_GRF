"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 214.435706615448, "training_acc": 43.333333333333336, "val_loss": 48.915536403656006, "val_acc": 28.0}
{"epoch": 1, "training_loss": 186.987398147583, "training_acc": 72.66666666666667, "val_loss": 44.68149608373642, "val_acc": 72.0}
{"epoch": 2, "training_loss": 176.66545248031616, "training_acc": 72.33333333333333, "val_loss": 43.66666892170906, "val_acc": 72.0}
{"epoch": 3, "training_loss": 174.54988551139832, "training_acc": 72.33333333333333, "val_loss": 43.04997134208679, "val_acc": 72.0}
{"epoch": 4, "training_loss": 173.75875067710876, "training_acc": 72.33333333333333, "val_loss": 42.20163005590439, "val_acc": 72.0}
{"epoch": 5, "training_loss": 170.85411930084229, "training_acc": 72.33333333333333, "val_loss": 41.77346393465996, "val_acc": 72.0}
{"epoch": 6, "training_loss": 170.16027879714966, "training_acc": 72.33333333333333, "val_loss": 40.104097843170166, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 165.55134987831116, "training_acc": 72.33333333333333, "val_loss": 39.063899248838425, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 162.4703938961029, "training_acc": 72.33333333333333, "val_loss": 38.08678621053696, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 158.91530656814575, "training_acc": 72.33333333333333, "val_loss": 35.79620760679245, "val_acc": 81.33333333333333}
{"epoch": 10, "training_loss": 157.4312400817871, "training_acc": 73.66666666666667, "val_loss": 35.1158190369606, "val_acc": 81.33333333333333}
{"epoch": 11, "training_loss": 155.0004177093506, "training_acc": 74.33333333333333, "val_loss": 35.79728847742081, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 153.47393453121185, "training_acc": 76.66666666666667, "val_loss": 46.04803955554962, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 163.8162522315979, "training_acc": 73.33333333333333, "val_loss": 34.50502026081085, "val_acc": 81.33333333333333}
{"epoch": 14, "training_loss": 151.2807240486145, "training_acc": 75.66666666666667, "val_loss": 34.78897142410278, "val_acc": 81.33333333333333}
{"epoch": 15, "training_loss": 147.2361798286438, "training_acc": 76.33333333333333, "val_loss": 34.10183000564575, "val_acc": 82.66666666666667}
{"epoch": 16, "training_loss": 146.1151397228241, "training_acc": 79.33333333333333, "val_loss": 35.57763496041298, "val_acc": 77.33333333333333}
{"epoch": 17, "training_loss": 146.74676883220673, "training_acc": 76.66666666666667, "val_loss": 44.860450968146324, "val_acc": 72.0}
{"epoch": 18, "training_loss": 156.23238229751587, "training_acc": 77.33333333333333, "val_loss": 34.54072007536888, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 138.70998799800873, "training_acc": 81.0, "val_loss": 36.56178483366966, "val_acc": 74.66666666666667}
{"epoch": 20, "training_loss": 138.89535450935364, "training_acc": 79.0, "val_loss": 41.235511779785156, "val_acc": 74.66666666666667}
{"epoch": 21, "training_loss": 134.3076367378235, "training_acc": 80.66666666666667, "val_loss": 33.09519290924072, "val_acc": 76.0}
{"epoch": 22, "training_loss": 145.70088839530945, "training_acc": 74.33333333333333, "val_loss": 33.73120981454849, "val_acc": 81.33333333333333}
{"epoch": 23, "training_loss": 126.17311775684357, "training_acc": 82.33333333333333, "val_loss": 39.09475362300873, "val_acc": 76.0}
{"epoch": 24, "training_loss": 128.0203046798706, "training_acc": 81.66666666666667, "val_loss": 42.28592795133591, "val_acc": 76.0}
{"epoch": 25, "training_loss": 134.86384308338165, "training_acc": 79.33333333333333, "val_loss": 32.07107090950012, "val_acc": 81.33333333333333}
{"epoch": 26, "training_loss": 114.75311326980591, "training_acc": 84.33333333333333, "val_loss": 32.19671767950058, "val_acc": 81.33333333333333}
{"epoch": 27, "training_loss": 104.01782858371735, "training_acc": 88.33333333333333, "val_loss": 33.70450794696808, "val_acc": 82.66666666666667}
{"epoch": 28, "training_loss": 92.35124135017395, "training_acc": 89.66666666666667, "val_loss": 38.19897496700287, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 132.98433220386505, "training_acc": 79.66666666666667, "val_loss": 38.22208259999752, "val_acc": 78.66666666666667}
{"epoch": 30, "training_loss": 91.28839683532715, "training_acc": 88.0, "val_loss": 39.001184195280075, "val_acc": 80.0}
{"epoch": 31, "training_loss": 103.30622458457947, "training_acc": 86.0, "val_loss": 39.389406621456146, "val_acc": 80.0}
{"epoch": 32, "training_loss": 85.370376765728, "training_acc": 88.33333333333333, "val_loss": 36.28347023576498, "val_acc": 81.33333333333333}
{"epoch": 33, "training_loss": 78.68138605356216, "training_acc": 90.66666666666667, "val_loss": 35.514492362737656, "val_acc": 81.33333333333333}
{"epoch": 34, "training_loss": 70.9772185087204, "training_acc": 91.33333333333333, "val_loss": 38.89327085018158, "val_acc": 74.66666666666667}
{"epoch": 35, "training_loss": 58.95380127429962, "training_acc": 92.0, "val_loss": 39.482260286808014, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 51.670285820961, "training_acc": 94.0, "val_loss": 40.236939042806625, "val_acc": 80.0}
{"epoch": 37, "training_loss": 60.4833288192749, "training_acc": 91.0, "val_loss": 40.14110463857651, "val_acc": 82.66666666666667}
{"epoch": 38, "training_loss": 83.52430981397629, "training_acc": 88.0, "val_loss": 62.05498683452606, "val_acc": 64.0}
{"epoch": 39, "training_loss": 123.13748854398727, "training_acc": 83.66666666666667, "val_loss": 39.40608170628548, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 105.06225061416626, "training_acc": 83.0, "val_loss": 37.30738067626953, "val_acc": 81.33333333333333}
{"epoch": 41, "training_loss": 72.79203152656555, "training_acc": 90.66666666666667, "val_loss": 43.56577110290527, "val_acc": 80.0}
{"epoch": 42, "training_loss": 62.54223185777664, "training_acc": 92.33333333333333, "val_loss": 34.47005903720856, "val_acc": 77.33333333333333}
{"epoch": 43, "training_loss": 67.5672225356102, "training_acc": 92.66666666666667, "val_loss": 42.25019934773445, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.57183504104614, "training_acc": 91.66666666666667, "val_loss": 37.782372891902924, "val_acc": 76.0}
