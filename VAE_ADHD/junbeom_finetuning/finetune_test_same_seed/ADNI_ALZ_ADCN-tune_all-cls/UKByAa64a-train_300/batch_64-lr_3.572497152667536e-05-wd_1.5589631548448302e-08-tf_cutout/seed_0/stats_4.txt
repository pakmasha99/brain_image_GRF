"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 189.62743377685547, "training_acc": 63.333333333333336, "val_loss": 45.521607875823975, "val_acc": 40.0}
{"epoch": 1, "training_loss": 178.59391498565674, "training_acc": 72.33333333333333, "val_loss": 41.85632008314133, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 177.93992257118225, "training_acc": 72.33333333333333, "val_loss": 43.433733344078064, "val_acc": 72.0}
{"epoch": 3, "training_loss": 178.65094447135925, "training_acc": 72.33333333333333, "val_loss": 41.05355930328369, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 169.3801748752594, "training_acc": 72.33333333333333, "val_loss": 40.93414455652237, "val_acc": 72.0}
{"epoch": 5, "training_loss": 169.61717319488525, "training_acc": 72.33333333333333, "val_loss": 38.814251482486725, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 163.89527654647827, "training_acc": 73.66666666666667, "val_loss": 40.69360789656639, "val_acc": 74.66666666666667}
{"epoch": 7, "training_loss": 163.54186010360718, "training_acc": 73.33333333333333, "val_loss": 35.92975437641144, "val_acc": 80.0}
{"epoch": 8, "training_loss": 156.1041877269745, "training_acc": 74.0, "val_loss": 45.42261826992035, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 168.17183303833008, "training_acc": 73.0, "val_loss": 36.64626756310463, "val_acc": 84.0}
{"epoch": 10, "training_loss": 160.2823567390442, "training_acc": 73.33333333333333, "val_loss": 37.46948683261871, "val_acc": 74.66666666666667}
{"epoch": 11, "training_loss": 155.6164300441742, "training_acc": 73.66666666666667, "val_loss": 34.013114124536514, "val_acc": 80.0}
{"epoch": 12, "training_loss": 157.924711227417, "training_acc": 75.33333333333333, "val_loss": 37.212889820337296, "val_acc": 74.66666666666667}
{"epoch": 13, "training_loss": 159.74263787269592, "training_acc": 73.33333333333333, "val_loss": 35.86884558200836, "val_acc": 77.33333333333333}
{"epoch": 14, "training_loss": 157.02999067306519, "training_acc": 74.0, "val_loss": 39.50524374842644, "val_acc": 72.0}
{"epoch": 15, "training_loss": 158.6280870437622, "training_acc": 75.66666666666667, "val_loss": 35.498117715120316, "val_acc": 81.33333333333333}
{"epoch": 16, "training_loss": 151.48398733139038, "training_acc": 77.66666666666667, "val_loss": 39.744981467723846, "val_acc": 74.66666666666667}
{"epoch": 17, "training_loss": 152.1809482574463, "training_acc": 75.33333333333333, "val_loss": 34.99646571278572, "val_acc": 78.66666666666667}
{"epoch": 18, "training_loss": 148.63815534114838, "training_acc": 76.33333333333333, "val_loss": 35.58841335773468, "val_acc": 77.33333333333333}
{"epoch": 19, "training_loss": 145.0847671031952, "training_acc": 77.33333333333333, "val_loss": 35.10823166370392, "val_acc": 77.33333333333333}
{"epoch": 20, "training_loss": 142.31595063209534, "training_acc": 78.66666666666667, "val_loss": 37.024221539497375, "val_acc": 74.66666666666667}
{"epoch": 21, "training_loss": 146.23045682907104, "training_acc": 77.33333333333333, "val_loss": 33.17230108380318, "val_acc": 81.33333333333333}
{"epoch": 22, "training_loss": 133.11725282669067, "training_acc": 80.0, "val_loss": 35.28033024072647, "val_acc": 77.33333333333333}
{"epoch": 23, "training_loss": 136.3195365667343, "training_acc": 79.66666666666667, "val_loss": 38.945788502693176, "val_acc": 74.66666666666667}
{"epoch": 24, "training_loss": 126.51315379142761, "training_acc": 81.33333333333333, "val_loss": 31.37361490726471, "val_acc": 81.33333333333333}
{"epoch": 25, "training_loss": 131.15482115745544, "training_acc": 80.66666666666667, "val_loss": 48.18090531229973, "val_acc": 76.0}
{"epoch": 26, "training_loss": 125.08811366558075, "training_acc": 84.0, "val_loss": 36.14277324080467, "val_acc": 76.0}
{"epoch": 27, "training_loss": 130.44234418869019, "training_acc": 80.33333333333333, "val_loss": 43.73959768563509, "val_acc": 76.0}
{"epoch": 28, "training_loss": 132.81770718097687, "training_acc": 82.66666666666667, "val_loss": 37.23477704077959, "val_acc": 77.33333333333333}
{"epoch": 29, "training_loss": 130.45524656772614, "training_acc": 78.33333333333333, "val_loss": 33.54057814180851, "val_acc": 77.33333333333333}
{"epoch": 30, "training_loss": 114.49063777923584, "training_acc": 83.33333333333333, "val_loss": 31.70389050245285, "val_acc": 82.66666666666667}
{"epoch": 31, "training_loss": 104.35809421539307, "training_acc": 85.33333333333333, "val_loss": 38.727048218250275, "val_acc": 77.33333333333333}
{"epoch": 32, "training_loss": 100.27379989624023, "training_acc": 83.66666666666667, "val_loss": 50.3350887298584, "val_acc": 76.0}
{"epoch": 33, "training_loss": 121.47012138366699, "training_acc": 79.66666666666667, "val_loss": 45.30615282058716, "val_acc": 76.0}
{"epoch": 34, "training_loss": 143.6694438457489, "training_acc": 78.33333333333333, "val_loss": 36.14030742645264, "val_acc": 68.0}
{"epoch": 35, "training_loss": 131.74075424671173, "training_acc": 82.0, "val_loss": 37.227240800857544, "val_acc": 77.33333333333333}
{"epoch": 36, "training_loss": 115.97017669677734, "training_acc": 81.0, "val_loss": 31.73150971531868, "val_acc": 84.0}
{"epoch": 37, "training_loss": 101.51254272460938, "training_acc": 86.0, "val_loss": 35.78406745195389, "val_acc": 74.66666666666667}
{"epoch": 38, "training_loss": 96.90973854064941, "training_acc": 88.0, "val_loss": 42.209161043167114, "val_acc": 70.66666666666667}
{"epoch": 39, "training_loss": 100.46402680873871, "training_acc": 86.0, "val_loss": 33.2562854886055, "val_acc": 76.0}
{"epoch": 40, "training_loss": 75.3165722489357, "training_acc": 90.66666666666667, "val_loss": 33.06363505125046, "val_acc": 84.0}
{"epoch": 41, "training_loss": 91.62734997272491, "training_acc": 88.33333333333333, "val_loss": 33.675559997558594, "val_acc": 84.0}
{"epoch": 42, "training_loss": 65.73072917759418, "training_acc": 91.33333333333333, "val_loss": 33.56182497739792, "val_acc": 86.66666666666667}
{"epoch": 43, "training_loss": 61.52961754798889, "training_acc": 92.33333333333333, "val_loss": 41.24917459487915, "val_acc": 80.0}
