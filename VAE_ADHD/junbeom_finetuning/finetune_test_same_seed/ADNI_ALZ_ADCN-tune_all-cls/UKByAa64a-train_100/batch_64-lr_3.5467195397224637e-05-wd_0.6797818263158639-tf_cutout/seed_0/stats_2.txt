"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.99903106689453, "training_acc": 28.0, "val_loss": 17.78305619955063, "val_acc": 28.0}
{"epoch": 1, "training_loss": 70.38370132446289, "training_acc": 33.0, "val_loss": 17.067550122737885, "val_acc": 28.0}
{"epoch": 2, "training_loss": 67.92948532104492, "training_acc": 73.0, "val_loss": 16.516384482383728, "val_acc": 28.0}
{"epoch": 3, "training_loss": 65.65523791313171, "training_acc": 70.0, "val_loss": 15.909364819526672, "val_acc": 28.0}
{"epoch": 4, "training_loss": 63.498414278030396, "training_acc": 72.0, "val_loss": 15.541127324104309, "val_acc": 32.0}
{"epoch": 5, "training_loss": 61.863373041152954, "training_acc": 72.0, "val_loss": 15.350914001464844, "val_acc": 64.0}
{"epoch": 6, "training_loss": 60.92516565322876, "training_acc": 72.0, "val_loss": 15.158796310424805, "val_acc": 64.0}
{"epoch": 7, "training_loss": 61.17289972305298, "training_acc": 72.0, "val_loss": 15.190848708152771, "val_acc": 68.0}
{"epoch": 8, "training_loss": 60.43103361129761, "training_acc": 72.0, "val_loss": 14.992555975914001, "val_acc": 64.0}
{"epoch": 9, "training_loss": 58.76746869087219, "training_acc": 72.0, "val_loss": 14.922741055488586, "val_acc": 68.0}
{"epoch": 10, "training_loss": 58.41782593727112, "training_acc": 72.0, "val_loss": 14.851202070713043, "val_acc": 68.0}
{"epoch": 11, "training_loss": 57.652209520339966, "training_acc": 72.0, "val_loss": 14.738735556602478, "val_acc": 68.0}
{"epoch": 12, "training_loss": 57.12998700141907, "training_acc": 72.0, "val_loss": 14.683276414871216, "val_acc": 68.0}
{"epoch": 13, "training_loss": 56.453601360321045, "training_acc": 72.0, "val_loss": 14.624299108982086, "val_acc": 68.0}
{"epoch": 14, "training_loss": 55.780983448028564, "training_acc": 72.0, "val_loss": 14.613021910190582, "val_acc": 64.0}
{"epoch": 15, "training_loss": 55.288623452186584, "training_acc": 72.0, "val_loss": 14.778539538383484, "val_acc": 68.0}
{"epoch": 16, "training_loss": 55.49563145637512, "training_acc": 72.0, "val_loss": 14.700831472873688, "val_acc": 68.0}
{"epoch": 17, "training_loss": 54.769397020339966, "training_acc": 72.0, "val_loss": 14.52053040266037, "val_acc": 68.0}
{"epoch": 18, "training_loss": 54.11560893058777, "training_acc": 72.0, "val_loss": 14.924110472202301, "val_acc": 64.0}
{"epoch": 19, "training_loss": 54.22375464439392, "training_acc": 72.0, "val_loss": 14.886757731437683, "val_acc": 68.0}
{"epoch": 20, "training_loss": 52.73302149772644, "training_acc": 72.0, "val_loss": 14.433622360229492, "val_acc": 68.0}
{"epoch": 21, "training_loss": 53.80150318145752, "training_acc": 72.0, "val_loss": 14.694836735725403, "val_acc": 64.0}
{"epoch": 22, "training_loss": 52.28409552574158, "training_acc": 72.0, "val_loss": 14.983977377414703, "val_acc": 68.0}
{"epoch": 23, "training_loss": 52.10979127883911, "training_acc": 72.0, "val_loss": 14.557716250419617, "val_acc": 64.0}
{"epoch": 24, "training_loss": 50.982069969177246, "training_acc": 72.0, "val_loss": 14.500947296619415, "val_acc": 68.0}
{"epoch": 25, "training_loss": 50.71724987030029, "training_acc": 72.0, "val_loss": 14.884886145591736, "val_acc": 68.0}
{"epoch": 26, "training_loss": 51.10959839820862, "training_acc": 75.0, "val_loss": 14.699028432369232, "val_acc": 64.0}
{"epoch": 27, "training_loss": 48.617300510406494, "training_acc": 73.0, "val_loss": 14.453475177288055, "val_acc": 64.0}
{"epoch": 28, "training_loss": 51.343048334121704, "training_acc": 77.0, "val_loss": 15.158367156982422, "val_acc": 68.0}
{"epoch": 29, "training_loss": 51.527162313461304, "training_acc": 76.0, "val_loss": 15.278224647045135, "val_acc": 64.0}
{"epoch": 30, "training_loss": 52.372454047203064, "training_acc": 74.0, "val_loss": 14.646826684474945, "val_acc": 68.0}
{"epoch": 31, "training_loss": 48.64470839500427, "training_acc": 82.0, "val_loss": 14.530529081821442, "val_acc": 64.0}
{"epoch": 32, "training_loss": 48.72958970069885, "training_acc": 85.0, "val_loss": 15.275229513645172, "val_acc": 68.0}
{"epoch": 33, "training_loss": 50.31012451648712, "training_acc": 75.0, "val_loss": 15.219256281852722, "val_acc": 68.0}
{"epoch": 34, "training_loss": 48.65204465389252, "training_acc": 81.0, "val_loss": 14.689457416534424, "val_acc": 68.0}
{"epoch": 35, "training_loss": 47.10505390167236, "training_acc": 84.0, "val_loss": 15.371653437614441, "val_acc": 68.0}
{"epoch": 36, "training_loss": 47.0319629907608, "training_acc": 78.0, "val_loss": 14.950446784496307, "val_acc": 64.0}
{"epoch": 37, "training_loss": 44.95363450050354, "training_acc": 85.0, "val_loss": 15.037013590335846, "val_acc": 68.0}
{"epoch": 38, "training_loss": 44.47220587730408, "training_acc": 83.0, "val_loss": 15.095658600330353, "val_acc": 68.0}
{"epoch": 39, "training_loss": 44.09172976016998, "training_acc": 87.0, "val_loss": 14.954955875873566, "val_acc": 68.0}
