"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.26679229736328, "training_acc": 69.0, "val_loss": 15.901993215084076, "val_acc": 28.0}
{"epoch": 1, "training_loss": 63.224687576293945, "training_acc": 72.0, "val_loss": 14.657750725746155, "val_acc": 72.0}
{"epoch": 2, "training_loss": 58.635249853134155, "training_acc": 72.0, "val_loss": 14.82190489768982, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.055392265319824, "training_acc": 72.0, "val_loss": 14.671894907951355, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.12832975387573, "training_acc": 72.0, "val_loss": 14.266090095043182, "val_acc": 72.0}
{"epoch": 5, "training_loss": 57.21303391456604, "training_acc": 72.0, "val_loss": 14.603342115879059, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.05168795585632, "training_acc": 72.0, "val_loss": 14.49001133441925, "val_acc": 72.0}
{"epoch": 7, "training_loss": 56.93704068660736, "training_acc": 72.0, "val_loss": 14.06048983335495, "val_acc": 68.0}
{"epoch": 8, "training_loss": 55.1421844959259, "training_acc": 72.0, "val_loss": 13.771291077136993, "val_acc": 64.0}
{"epoch": 9, "training_loss": 52.945526123046875, "training_acc": 72.0, "val_loss": 14.525504410266876, "val_acc": 72.0}
{"epoch": 10, "training_loss": 53.25025749206543, "training_acc": 72.0, "val_loss": 13.472627103328705, "val_acc": 64.0}
{"epoch": 11, "training_loss": 54.51060223579407, "training_acc": 72.0, "val_loss": 13.068178296089172, "val_acc": 72.0}
{"epoch": 12, "training_loss": 51.907973289489746, "training_acc": 72.0, "val_loss": 14.49163556098938, "val_acc": 72.0}
{"epoch": 13, "training_loss": 53.55853044986725, "training_acc": 72.0, "val_loss": 13.07518482208252, "val_acc": 64.0}
{"epoch": 14, "training_loss": 52.65517497062683, "training_acc": 72.0, "val_loss": 13.05750459432602, "val_acc": 80.0}
{"epoch": 15, "training_loss": 50.8257999420166, "training_acc": 72.0, "val_loss": 13.651421666145325, "val_acc": 72.0}
{"epoch": 16, "training_loss": 48.47600865364075, "training_acc": 76.0, "val_loss": 13.031576573848724, "val_acc": 64.0}
{"epoch": 17, "training_loss": 50.831114411354065, "training_acc": 79.0, "val_loss": 13.004258275032043, "val_acc": 76.0}
{"epoch": 18, "training_loss": 50.96076321601868, "training_acc": 76.0, "val_loss": 13.931635022163391, "val_acc": 68.0}
{"epoch": 19, "training_loss": 50.05817472934723, "training_acc": 72.0, "val_loss": 13.183392584323883, "val_acc": 68.0}
{"epoch": 20, "training_loss": 47.161243081092834, "training_acc": 80.0, "val_loss": 13.536079227924347, "val_acc": 72.0}
{"epoch": 21, "training_loss": 49.32278275489807, "training_acc": 74.0, "val_loss": 13.816647231578827, "val_acc": 68.0}
{"epoch": 22, "training_loss": 46.20106112957001, "training_acc": 81.0, "val_loss": 12.729912996292114, "val_acc": 68.0}
{"epoch": 23, "training_loss": 45.79815673828125, "training_acc": 81.0, "val_loss": 12.877459824085236, "val_acc": 72.0}
{"epoch": 24, "training_loss": 42.96463406085968, "training_acc": 78.0, "val_loss": 13.66984099149704, "val_acc": 72.0}
{"epoch": 25, "training_loss": 43.594688177108765, "training_acc": 78.0, "val_loss": 12.993746995925903, "val_acc": 64.0}
{"epoch": 26, "training_loss": 40.175296902656555, "training_acc": 83.0, "val_loss": 12.532652914524078, "val_acc": 76.0}
{"epoch": 27, "training_loss": 38.35267186164856, "training_acc": 85.0, "val_loss": 12.310812622308731, "val_acc": 76.0}
{"epoch": 28, "training_loss": 36.97139537334442, "training_acc": 85.0, "val_loss": 13.106425106525421, "val_acc": 72.0}
{"epoch": 29, "training_loss": 34.749136090278625, "training_acc": 87.0, "val_loss": 11.702606081962585, "val_acc": 80.0}
{"epoch": 30, "training_loss": 42.63133645057678, "training_acc": 81.0, "val_loss": 16.027773916721344, "val_acc": 72.0}
{"epoch": 31, "training_loss": 40.7579391002655, "training_acc": 81.0, "val_loss": 14.046384394168854, "val_acc": 68.0}
{"epoch": 32, "training_loss": 36.75986731052399, "training_acc": 80.0, "val_loss": 13.29122930765152, "val_acc": 76.0}
{"epoch": 33, "training_loss": 42.95430862903595, "training_acc": 76.0, "val_loss": 14.586012065410614, "val_acc": 72.0}
{"epoch": 34, "training_loss": 30.768381118774414, "training_acc": 88.0, "val_loss": 16.01329892873764, "val_acc": 68.0}
{"epoch": 35, "training_loss": 40.803520143032074, "training_acc": 80.0, "val_loss": 16.73993319272995, "val_acc": 72.0}
{"epoch": 36, "training_loss": 38.30446791648865, "training_acc": 82.0, "val_loss": 15.411670506000519, "val_acc": 72.0}
{"epoch": 37, "training_loss": 28.224223732948303, "training_acc": 90.0, "val_loss": 13.323406875133514, "val_acc": 68.0}
{"epoch": 38, "training_loss": 26.462270498275757, "training_acc": 93.0, "val_loss": 11.283203959465027, "val_acc": 72.0}
{"epoch": 39, "training_loss": 32.98527908325195, "training_acc": 89.0, "val_loss": 13.167940080165863, "val_acc": 72.0}
{"epoch": 40, "training_loss": 30.040729761123657, "training_acc": 88.0, "val_loss": 14.552849531173706, "val_acc": 72.0}
{"epoch": 41, "training_loss": 24.447268545627594, "training_acc": 90.0, "val_loss": 16.188064217567444, "val_acc": 76.0}
{"epoch": 42, "training_loss": 27.60387408733368, "training_acc": 88.0, "val_loss": 16.29291921854019, "val_acc": 76.0}
{"epoch": 43, "training_loss": 21.131796717643738, "training_acc": 91.0, "val_loss": 14.065629243850708, "val_acc": 72.0}
{"epoch": 44, "training_loss": 14.457939147949219, "training_acc": 95.0, "val_loss": 11.416736990213394, "val_acc": 80.0}
{"epoch": 45, "training_loss": 17.446687936782837, "training_acc": 92.0, "val_loss": 21.954257786273956, "val_acc": 76.0}
{"epoch": 46, "training_loss": 31.194673657417297, "training_acc": 84.0, "val_loss": 15.65479040145874, "val_acc": 76.0}
{"epoch": 47, "training_loss": 11.255376696586609, "training_acc": 95.0, "val_loss": 15.903928875923157, "val_acc": 76.0}
{"epoch": 48, "training_loss": 13.701105892658234, "training_acc": 95.0, "val_loss": 31.1771959066391, "val_acc": 72.0}
{"epoch": 49, "training_loss": 24.276835441589355, "training_acc": 91.0, "val_loss": 14.671114087104797, "val_acc": 76.0}
{"epoch": 50, "training_loss": 9.91614344716072, "training_acc": 97.0, "val_loss": 21.412871778011322, "val_acc": 80.0}
{"epoch": 51, "training_loss": 16.968974947929382, "training_acc": 95.0, "val_loss": 14.567054808139801, "val_acc": 76.0}
{"epoch": 52, "training_loss": 9.828825175762177, "training_acc": 97.0, "val_loss": 16.219645738601685, "val_acc": 68.0}
{"epoch": 53, "training_loss": 8.285266697406769, "training_acc": 97.0, "val_loss": 17.319664359092712, "val_acc": 72.0}
{"epoch": 54, "training_loss": 10.714917361736298, "training_acc": 95.0, "val_loss": 14.733625948429108, "val_acc": 80.0}
{"epoch": 55, "training_loss": 8.613581717014313, "training_acc": 97.0, "val_loss": 14.431123435497284, "val_acc": 80.0}
{"epoch": 56, "training_loss": 3.9882378727197647, "training_acc": 100.0, "val_loss": 12.775278091430664, "val_acc": 80.0}
{"epoch": 57, "training_loss": 3.0102242454886436, "training_acc": 100.0, "val_loss": 16.562125086784363, "val_acc": 80.0}
