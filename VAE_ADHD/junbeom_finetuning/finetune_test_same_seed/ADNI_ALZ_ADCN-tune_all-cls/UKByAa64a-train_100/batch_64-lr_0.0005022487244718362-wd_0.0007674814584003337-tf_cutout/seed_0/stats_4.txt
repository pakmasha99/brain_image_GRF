"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.73837637901306, "training_acc": 72.0, "val_loss": 15.175189077854156, "val_acc": 72.0}
{"epoch": 1, "training_loss": 59.59385657310486, "training_acc": 72.0, "val_loss": 15.020884573459625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.43458104133606, "training_acc": 72.0, "val_loss": 15.033243596553802, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.07082986831665, "training_acc": 72.0, "val_loss": 14.910002052783966, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.663650035858154, "training_acc": 72.0, "val_loss": 14.83324021100998, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.28284692764282, "training_acc": 72.0, "val_loss": 14.829787611961365, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.840197801589966, "training_acc": 72.0, "val_loss": 14.82403576374054, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.17815136909485, "training_acc": 72.0, "val_loss": 14.892955124378204, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.61240029335022, "training_acc": 72.0, "val_loss": 14.915801584720612, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.7798113822937, "training_acc": 72.0, "val_loss": 14.847196638584137, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.473406076431274, "training_acc": 72.0, "val_loss": 14.831283688545227, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.36388897895813, "training_acc": 72.0, "val_loss": 14.845938980579376, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.45644474029541, "training_acc": 72.0, "val_loss": 14.853207767009735, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.42664933204651, "training_acc": 72.0, "val_loss": 14.828535914421082, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.407456159591675, "training_acc": 72.0, "val_loss": 14.823804795742035, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.30423378944397, "training_acc": 72.0, "val_loss": 14.823727309703827, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.384581565856934, "training_acc": 72.0, "val_loss": 14.824680984020233, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.479941844940186, "training_acc": 72.0, "val_loss": 14.824411273002625, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.48004651069641, "training_acc": 72.0, "val_loss": 14.82464224100113, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.34542512893677, "training_acc": 72.0, "val_loss": 14.824604988098145, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.27420353889465, "training_acc": 72.0, "val_loss": 14.844357967376709, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.4339816570282, "training_acc": 72.0, "val_loss": 14.856739342212677, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.40573191642761, "training_acc": 72.0, "val_loss": 14.832675457000732, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.29209232330322, "training_acc": 72.0, "val_loss": 14.825160801410675, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.28115773200989, "training_acc": 72.0, "val_loss": 14.844568073749542, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.37402009963989, "training_acc": 72.0, "val_loss": 14.877577126026154, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.51269602775574, "training_acc": 72.0, "val_loss": 14.865049719810486, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.42233228683472, "training_acc": 72.0, "val_loss": 14.83009159564972, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.30702209472656, "training_acc": 72.0, "val_loss": 14.834007620811462, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.339418172836304, "training_acc": 72.0, "val_loss": 14.863044023513794, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.433088302612305, "training_acc": 72.0, "val_loss": 14.902490377426147, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.66942524909973, "training_acc": 72.0, "val_loss": 14.909334480762482, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.5818235874176, "training_acc": 72.0, "val_loss": 14.851702749729156, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.378357887268066, "training_acc": 72.0, "val_loss": 14.825402200222015, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.40261673927307, "training_acc": 72.0, "val_loss": 14.858818054199219, "val_acc": 72.0}
