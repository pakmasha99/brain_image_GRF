"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 68.99689602851868, "training_acc": 59.0, "val_loss": 17.51464456319809, "val_acc": 28.0}
{"epoch": 1, "training_loss": 68.82638573646545, "training_acc": 53.0, "val_loss": 16.35214239358902, "val_acc": 28.0}
{"epoch": 2, "training_loss": 64.5636830329895, "training_acc": 72.0, "val_loss": 15.395331382751465, "val_acc": 36.0}
{"epoch": 3, "training_loss": 60.70942997932434, "training_acc": 72.0, "val_loss": 14.719288051128387, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.794535398483276, "training_acc": 72.0, "val_loss": 14.778102934360504, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.31462514400482, "training_acc": 72.0, "val_loss": 14.887793362140656, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.04104232788086, "training_acc": 72.0, "val_loss": 14.669212698936462, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58.409322023391724, "training_acc": 72.0, "val_loss": 14.522963762283325, "val_acc": 72.0}
{"epoch": 8, "training_loss": 57.93227553367615, "training_acc": 72.0, "val_loss": 14.518150687217712, "val_acc": 72.0}
{"epoch": 9, "training_loss": 57.53018879890442, "training_acc": 72.0, "val_loss": 14.470461010932922, "val_acc": 72.0}
{"epoch": 10, "training_loss": 57.344977378845215, "training_acc": 72.0, "val_loss": 14.330953359603882, "val_acc": 72.0}
{"epoch": 11, "training_loss": 56.82685708999634, "training_acc": 72.0, "val_loss": 14.127945899963379, "val_acc": 72.0}
{"epoch": 12, "training_loss": 56.80059027671814, "training_acc": 72.0, "val_loss": 14.002104103565216, "val_acc": 72.0}
{"epoch": 13, "training_loss": 55.81243085861206, "training_acc": 72.0, "val_loss": 13.879483938217163, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.31247353553772, "training_acc": 72.0, "val_loss": 13.770604133605957, "val_acc": 72.0}
{"epoch": 15, "training_loss": 54.71004891395569, "training_acc": 72.0, "val_loss": 13.671383261680603, "val_acc": 72.0}
{"epoch": 16, "training_loss": 54.589091062545776, "training_acc": 72.0, "val_loss": 13.531425595283508, "val_acc": 76.0}
{"epoch": 17, "training_loss": 53.4781334400177, "training_acc": 72.0, "val_loss": 13.450989127159119, "val_acc": 76.0}
{"epoch": 18, "training_loss": 52.36640548706055, "training_acc": 72.0, "val_loss": 13.389867544174194, "val_acc": 76.0}
{"epoch": 19, "training_loss": 52.58438587188721, "training_acc": 72.0, "val_loss": 13.336475193500519, "val_acc": 76.0}
{"epoch": 20, "training_loss": 51.24303436279297, "training_acc": 72.0, "val_loss": 13.31167072057724, "val_acc": 76.0}
{"epoch": 21, "training_loss": 52.007920026779175, "training_acc": 72.0, "val_loss": 13.280601799488068, "val_acc": 72.0}
{"epoch": 22, "training_loss": 51.491546273231506, "training_acc": 72.0, "val_loss": 13.279536366462708, "val_acc": 68.0}
{"epoch": 23, "training_loss": 50.99980688095093, "training_acc": 72.0, "val_loss": 13.29147219657898, "val_acc": 76.0}
{"epoch": 24, "training_loss": 50.67116189002991, "training_acc": 72.0, "val_loss": 13.297690451145172, "val_acc": 64.0}
{"epoch": 25, "training_loss": 49.836965560913086, "training_acc": 72.0, "val_loss": 13.263948261737823, "val_acc": 68.0}
{"epoch": 26, "training_loss": 47.28490626811981, "training_acc": 72.0, "val_loss": 13.58623057603836, "val_acc": 76.0}
{"epoch": 27, "training_loss": 50.574912309646606, "training_acc": 72.0, "val_loss": 13.367463648319244, "val_acc": 76.0}
{"epoch": 28, "training_loss": 47.60362195968628, "training_acc": 73.0, "val_loss": 13.630856573581696, "val_acc": 68.0}
{"epoch": 29, "training_loss": 50.41124987602234, "training_acc": 79.0, "val_loss": 13.541831076145172, "val_acc": 64.0}
{"epoch": 30, "training_loss": 47.26538121700287, "training_acc": 80.0, "val_loss": 13.542574644088745, "val_acc": 72.0}
{"epoch": 31, "training_loss": 46.32891380786896, "training_acc": 74.0, "val_loss": 14.853684604167938, "val_acc": 76.0}
{"epoch": 32, "training_loss": 49.617950439453125, "training_acc": 72.0, "val_loss": 13.460168242454529, "val_acc": 72.0}
{"epoch": 33, "training_loss": 44.965869426727295, "training_acc": 78.0, "val_loss": 13.70941698551178, "val_acc": 64.0}
{"epoch": 34, "training_loss": 48.65464973449707, "training_acc": 82.0, "val_loss": 13.837920129299164, "val_acc": 64.0}
{"epoch": 35, "training_loss": 46.782570242881775, "training_acc": 82.0, "val_loss": 13.542978465557098, "val_acc": 72.0}
{"epoch": 36, "training_loss": 45.805333852767944, "training_acc": 78.0, "val_loss": 14.640943706035614, "val_acc": 76.0}
{"epoch": 37, "training_loss": 46.40016543865204, "training_acc": 73.0, "val_loss": 13.38796615600586, "val_acc": 72.0}
{"epoch": 38, "training_loss": 44.03921568393707, "training_acc": 83.0, "val_loss": 13.571636378765106, "val_acc": 64.0}
{"epoch": 39, "training_loss": 45.004209876060486, "training_acc": 85.0, "val_loss": 13.35284411907196, "val_acc": 76.0}
{"epoch": 40, "training_loss": 41.66794812679291, "training_acc": 80.0, "val_loss": 13.90581876039505, "val_acc": 72.0}
{"epoch": 41, "training_loss": 45.40815281867981, "training_acc": 77.0, "val_loss": 13.524387776851654, "val_acc": 72.0}
{"epoch": 42, "training_loss": 41.21468698978424, "training_acc": 83.0, "val_loss": 13.931111991405487, "val_acc": 64.0}
{"epoch": 43, "training_loss": 45.475019454956055, "training_acc": 84.0, "val_loss": 13.548687100410461, "val_acc": 68.0}
{"epoch": 44, "training_loss": 40.87827479839325, "training_acc": 84.0, "val_loss": 14.160698652267456, "val_acc": 72.0}
