"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.26053714752197, "training_acc": 40.0, "val_loss": 17.252609133720398, "val_acc": 28.0}
{"epoch": 1, "training_loss": 68.358393907547, "training_acc": 68.0, "val_loss": 16.28914624452591, "val_acc": 28.0}
{"epoch": 2, "training_loss": 64.3211989402771, "training_acc": 72.0, "val_loss": 15.6866654753685, "val_acc": 28.0}
{"epoch": 3, "training_loss": 62.59400200843811, "training_acc": 72.0, "val_loss": 15.11957198381424, "val_acc": 64.0}
{"epoch": 4, "training_loss": 60.331093311309814, "training_acc": 72.0, "val_loss": 14.792019128799438, "val_acc": 68.0}
{"epoch": 5, "training_loss": 59.30058765411377, "training_acc": 72.0, "val_loss": 14.717818796634674, "val_acc": 68.0}
{"epoch": 6, "training_loss": 58.834800720214844, "training_acc": 72.0, "val_loss": 14.503556489944458, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58.455371141433716, "training_acc": 72.0, "val_loss": 14.478863775730133, "val_acc": 68.0}
{"epoch": 8, "training_loss": 57.96662783622742, "training_acc": 72.0, "val_loss": 14.267909526824951, "val_acc": 72.0}
{"epoch": 9, "training_loss": 56.48678135871887, "training_acc": 72.0, "val_loss": 14.31213766336441, "val_acc": 72.0}
{"epoch": 10, "training_loss": 56.547064781188965, "training_acc": 72.0, "val_loss": 13.979004323482513, "val_acc": 68.0}
{"epoch": 11, "training_loss": 55.9941508769989, "training_acc": 72.0, "val_loss": 13.897565007209778, "val_acc": 76.0}
{"epoch": 12, "training_loss": 55.18523097038269, "training_acc": 72.0, "val_loss": 14.239741861820221, "val_acc": 72.0}
{"epoch": 13, "training_loss": 55.135818123817444, "training_acc": 72.0, "val_loss": 13.92461359500885, "val_acc": 72.0}
{"epoch": 14, "training_loss": 54.67937397956848, "training_acc": 72.0, "val_loss": 13.644200563430786, "val_acc": 76.0}
{"epoch": 15, "training_loss": 54.758777379989624, "training_acc": 72.0, "val_loss": 13.490395247936249, "val_acc": 72.0}
{"epoch": 16, "training_loss": 53.630343437194824, "training_acc": 72.0, "val_loss": 13.889312744140625, "val_acc": 72.0}
{"epoch": 17, "training_loss": 53.65955328941345, "training_acc": 72.0, "val_loss": 13.368494808673859, "val_acc": 76.0}
{"epoch": 18, "training_loss": 52.415257692337036, "training_acc": 72.0, "val_loss": 13.195204734802246, "val_acc": 76.0}
{"epoch": 19, "training_loss": 52.12274932861328, "training_acc": 72.0, "val_loss": 13.554750382900238, "val_acc": 72.0}
{"epoch": 20, "training_loss": 50.83633768558502, "training_acc": 72.0, "val_loss": 13.946829736232758, "val_acc": 68.0}
{"epoch": 21, "training_loss": 51.09585213661194, "training_acc": 72.0, "val_loss": 13.595615327358246, "val_acc": 64.0}
{"epoch": 22, "training_loss": 54.09251809120178, "training_acc": 72.0, "val_loss": 13.496589660644531, "val_acc": 72.0}
{"epoch": 23, "training_loss": 50.126840353012085, "training_acc": 73.0, "val_loss": 14.391009509563446, "val_acc": 72.0}
{"epoch": 24, "training_loss": 50.81182670593262, "training_acc": 74.0, "val_loss": 13.142679631710052, "val_acc": 68.0}
{"epoch": 25, "training_loss": 49.54953908920288, "training_acc": 80.0, "val_loss": 13.192105293273926, "val_acc": 76.0}
{"epoch": 26, "training_loss": 47.62913715839386, "training_acc": 74.0, "val_loss": 13.058097660541534, "val_acc": 76.0}
{"epoch": 27, "training_loss": 46.92801344394684, "training_acc": 81.0, "val_loss": 12.985606491565704, "val_acc": 68.0}
{"epoch": 28, "training_loss": 47.39778816699982, "training_acc": 84.0, "val_loss": 13.9558345079422, "val_acc": 68.0}
{"epoch": 29, "training_loss": 46.938244342803955, "training_acc": 75.0, "val_loss": 12.874068319797516, "val_acc": 68.0}
{"epoch": 30, "training_loss": 47.63336980342865, "training_acc": 85.0, "val_loss": 14.113231003284454, "val_acc": 72.0}
{"epoch": 31, "training_loss": 48.346078634262085, "training_acc": 76.0, "val_loss": 12.943147122859955, "val_acc": 76.0}
{"epoch": 32, "training_loss": 45.492414116859436, "training_acc": 85.0, "val_loss": 12.648636102676392, "val_acc": 72.0}
{"epoch": 33, "training_loss": 43.067602038383484, "training_acc": 87.0, "val_loss": 14.540617167949677, "val_acc": 72.0}
{"epoch": 34, "training_loss": 46.57350397109985, "training_acc": 78.0, "val_loss": 12.532393634319305, "val_acc": 72.0}
{"epoch": 35, "training_loss": 44.22121250629425, "training_acc": 86.0, "val_loss": 12.56188154220581, "val_acc": 76.0}
{"epoch": 36, "training_loss": 40.62851428985596, "training_acc": 87.0, "val_loss": 13.5209321975708, "val_acc": 76.0}
{"epoch": 37, "training_loss": 40.218125343322754, "training_acc": 84.0, "val_loss": 12.557084858417511, "val_acc": 68.0}
{"epoch": 38, "training_loss": 41.20353949069977, "training_acc": 90.0, "val_loss": 12.104325741529465, "val_acc": 76.0}
{"epoch": 39, "training_loss": 36.9375319480896, "training_acc": 90.0, "val_loss": 12.321984767913818, "val_acc": 76.0}
{"epoch": 40, "training_loss": 36.917271971702576, "training_acc": 87.0, "val_loss": 12.395521998405457, "val_acc": 68.0}
{"epoch": 41, "training_loss": 38.979225635528564, "training_acc": 91.0, "val_loss": 11.60508617758751, "val_acc": 76.0}
{"epoch": 42, "training_loss": 36.33563423156738, "training_acc": 92.0, "val_loss": 13.555540144443512, "val_acc": 76.0}
{"epoch": 43, "training_loss": 36.823505878448486, "training_acc": 85.0, "val_loss": 11.985421925783157, "val_acc": 72.0}
{"epoch": 44, "training_loss": 32.61569380760193, "training_acc": 96.0, "val_loss": 13.594818115234375, "val_acc": 76.0}
{"epoch": 45, "training_loss": 34.666683077812195, "training_acc": 93.0, "val_loss": 12.357856333255768, "val_acc": 72.0}
{"epoch": 46, "training_loss": 34.275368332862854, "training_acc": 96.0, "val_loss": 14.161193370819092, "val_acc": 76.0}
{"epoch": 47, "training_loss": 33.535616636276245, "training_acc": 92.0, "val_loss": 12.767572700977325, "val_acc": 60.0}
{"epoch": 48, "training_loss": 34.18980538845062, "training_acc": 96.0, "val_loss": 14.868001639842987, "val_acc": 72.0}
{"epoch": 49, "training_loss": 35.599634647369385, "training_acc": 88.0, "val_loss": 13.24097067117691, "val_acc": 56.0}
{"epoch": 50, "training_loss": 35.49904191493988, "training_acc": 92.0, "val_loss": 14.402279257774353, "val_acc": 76.0}
{"epoch": 51, "training_loss": 33.58565318584442, "training_acc": 89.0, "val_loss": 11.460117250680923, "val_acc": 72.0}
{"epoch": 52, "training_loss": 29.330109119415283, "training_acc": 98.0, "val_loss": 11.552480608224869, "val_acc": 84.0}
{"epoch": 53, "training_loss": 28.002166748046875, "training_acc": 98.0, "val_loss": 10.915522277355194, "val_acc": 84.0}
{"epoch": 54, "training_loss": 26.287640929222107, "training_acc": 100.0, "val_loss": 11.192132532596588, "val_acc": 80.0}
{"epoch": 55, "training_loss": 25.86722767353058, "training_acc": 97.0, "val_loss": 10.504718869924545, "val_acc": 80.0}
{"epoch": 56, "training_loss": 25.368612110614777, "training_acc": 100.0, "val_loss": 11.877313256263733, "val_acc": 84.0}
{"epoch": 57, "training_loss": 25.09821969270706, "training_acc": 97.0, "val_loss": 10.10616198182106, "val_acc": 84.0}
{"epoch": 58, "training_loss": 24.78727352619171, "training_acc": 100.0, "val_loss": 11.859168112277985, "val_acc": 84.0}
{"epoch": 59, "training_loss": 24.45719736814499, "training_acc": 99.0, "val_loss": 10.461093485355377, "val_acc": 84.0}
{"epoch": 60, "training_loss": 23.83372586965561, "training_acc": 100.0, "val_loss": 12.189668416976929, "val_acc": 84.0}
{"epoch": 61, "training_loss": 22.658551394939423, "training_acc": 99.0, "val_loss": 10.615570098161697, "val_acc": 84.0}
{"epoch": 62, "training_loss": 22.70000845193863, "training_acc": 99.0, "val_loss": 9.990590810775757, "val_acc": 84.0}
{"epoch": 63, "training_loss": 21.799072265625, "training_acc": 100.0, "val_loss": 11.947739124298096, "val_acc": 84.0}
{"epoch": 64, "training_loss": 22.31348431110382, "training_acc": 99.0, "val_loss": 9.871828556060791, "val_acc": 76.0}
{"epoch": 65, "training_loss": 23.010093450546265, "training_acc": 99.0, "val_loss": 11.753588169813156, "val_acc": 84.0}
{"epoch": 66, "training_loss": 21.86549025774002, "training_acc": 98.0, "val_loss": 10.055545717477798, "val_acc": 80.0}
{"epoch": 67, "training_loss": 22.29750084877014, "training_acc": 99.0, "val_loss": 13.305611908435822, "val_acc": 80.0}
{"epoch": 68, "training_loss": 24.77476304769516, "training_acc": 96.0, "val_loss": 13.237246870994568, "val_acc": 60.0}
{"epoch": 69, "training_loss": 36.144033551216125, "training_acc": 86.0, "val_loss": 13.710811734199524, "val_acc": 76.0}
{"epoch": 70, "training_loss": 28.169849038124084, "training_acc": 96.0, "val_loss": 11.281171441078186, "val_acc": 68.0}
{"epoch": 71, "training_loss": 22.988958477973938, "training_acc": 99.0, "val_loss": 12.436837702989578, "val_acc": 84.0}
{"epoch": 72, "training_loss": 21.004653751850128, "training_acc": 100.0, "val_loss": 10.748232901096344, "val_acc": 80.0}
{"epoch": 73, "training_loss": 20.577746331691742, "training_acc": 100.0, "val_loss": 10.74957326054573, "val_acc": 80.0}
{"epoch": 74, "training_loss": 20.027358949184418, "training_acc": 100.0, "val_loss": 11.243324726819992, "val_acc": 88.0}
{"epoch": 75, "training_loss": 20.13391411304474, "training_acc": 99.0, "val_loss": 10.71731150150299, "val_acc": 80.0}
{"epoch": 76, "training_loss": 19.773529887199402, "training_acc": 100.0, "val_loss": 10.85914596915245, "val_acc": 80.0}
{"epoch": 77, "training_loss": 19.0444455742836, "training_acc": 100.0, "val_loss": 12.278001755475998, "val_acc": 84.0}
{"epoch": 78, "training_loss": 19.39215362071991, "training_acc": 100.0, "val_loss": 10.936354100704193, "val_acc": 80.0}
{"epoch": 79, "training_loss": 18.643239080905914, "training_acc": 100.0, "val_loss": 10.67056655883789, "val_acc": 80.0}
{"epoch": 80, "training_loss": 18.45752078294754, "training_acc": 100.0, "val_loss": 12.041474878787994, "val_acc": 84.0}
{"epoch": 81, "training_loss": 18.136544704437256, "training_acc": 99.0, "val_loss": 10.904394835233688, "val_acc": 84.0}
{"epoch": 82, "training_loss": 17.483712434768677, "training_acc": 100.0, "val_loss": 10.147242993116379, "val_acc": 76.0}
{"epoch": 83, "training_loss": 18.27793312072754, "training_acc": 100.0, "val_loss": 11.251457780599594, "val_acc": 84.0}
