"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 68.6182291507721, "training_acc": 46.0, "val_loss": 16.0604327917099, "val_acc": 28.0}
{"epoch": 1, "training_loss": 63.6820273399353, "training_acc": 72.0, "val_loss": 15.011385083198547, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.58834791183472, "training_acc": 72.0, "val_loss": 14.837858080863953, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.153741121292114, "training_acc": 72.0, "val_loss": 14.779798686504364, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.93606495857239, "training_acc": 72.0, "val_loss": 14.827105402946472, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.92513036727905, "training_acc": 72.0, "val_loss": 14.75873589515686, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.19516324996948, "training_acc": 72.0, "val_loss": 14.829684793949127, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.300015687942505, "training_acc": 72.0, "val_loss": 14.834703505039215, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.292821645736694, "training_acc": 72.0, "val_loss": 14.734505116939545, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.52167463302612, "training_acc": 72.0, "val_loss": 14.772973954677582, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.785080671310425, "training_acc": 72.0, "val_loss": 14.669755101203918, "val_acc": 72.0}
{"epoch": 11, "training_loss": 57.535892724990845, "training_acc": 72.0, "val_loss": 14.95501697063446, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.867226243019104, "training_acc": 72.0, "val_loss": 14.738066494464874, "val_acc": 72.0}
{"epoch": 13, "training_loss": 56.803794741630554, "training_acc": 72.0, "val_loss": 14.652489125728607, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.054028034210205, "training_acc": 72.0, "val_loss": 14.474411308765411, "val_acc": 72.0}
{"epoch": 15, "training_loss": 57.286208391189575, "training_acc": 72.0, "val_loss": 14.762796461582184, "val_acc": 72.0}
{"epoch": 16, "training_loss": 56.761919021606445, "training_acc": 72.0, "val_loss": 14.630454778671265, "val_acc": 72.0}
{"epoch": 17, "training_loss": 56.919663429260254, "training_acc": 72.0, "val_loss": 15.152174234390259, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.253822565078735, "training_acc": 72.0, "val_loss": 15.013295412063599, "val_acc": 72.0}
{"epoch": 19, "training_loss": 56.83579659461975, "training_acc": 72.0, "val_loss": 14.49948400259018, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.807169675827026, "training_acc": 72.0, "val_loss": 14.581087231636047, "val_acc": 72.0}
{"epoch": 21, "training_loss": 54.527244329452515, "training_acc": 72.0, "val_loss": 14.830827713012695, "val_acc": 68.0}
{"epoch": 22, "training_loss": 52.304959297180176, "training_acc": 72.0, "val_loss": 15.081501007080078, "val_acc": 68.0}
{"epoch": 23, "training_loss": 51.23553454875946, "training_acc": 72.0, "val_loss": 15.695537626743317, "val_acc": 68.0}
{"epoch": 24, "training_loss": 50.48866415023804, "training_acc": 72.0, "val_loss": 15.63178300857544, "val_acc": 52.0}
{"epoch": 25, "training_loss": 53.190136432647705, "training_acc": 72.0, "val_loss": 15.622536838054657, "val_acc": 56.0}
{"epoch": 26, "training_loss": 52.910645484924316, "training_acc": 72.0, "val_loss": 16.164739429950714, "val_acc": 64.0}
{"epoch": 27, "training_loss": 54.01557207107544, "training_acc": 72.0, "val_loss": 15.292416512966156, "val_acc": 68.0}
{"epoch": 28, "training_loss": 49.180830240249634, "training_acc": 72.0, "val_loss": 15.332330763339996, "val_acc": 52.0}
{"epoch": 29, "training_loss": 50.121243715286255, "training_acc": 82.0, "val_loss": 16.880665719509125, "val_acc": 68.0}
{"epoch": 30, "training_loss": 53.978530168533325, "training_acc": 74.0, "val_loss": 15.216442942619324, "val_acc": 72.0}
{"epoch": 31, "training_loss": 50.86624813079834, "training_acc": 78.0, "val_loss": 15.876667201519012, "val_acc": 52.0}
{"epoch": 32, "training_loss": 51.36628460884094, "training_acc": 76.0, "val_loss": 15.580183267593384, "val_acc": 64.0}
{"epoch": 33, "training_loss": 49.229734897613525, "training_acc": 73.0, "val_loss": 16.144411265850067, "val_acc": 52.0}
