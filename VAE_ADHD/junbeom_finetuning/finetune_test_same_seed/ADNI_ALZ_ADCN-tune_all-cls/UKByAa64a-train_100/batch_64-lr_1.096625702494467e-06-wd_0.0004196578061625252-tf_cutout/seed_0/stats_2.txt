"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.41615772247314, "training_acc": 29.0, "val_loss": 18.133743107318878, "val_acc": 28.0}
{"epoch": 1, "training_loss": 72.27215838432312, "training_acc": 28.0, "val_loss": 17.96189844608307, "val_acc": 28.0}
{"epoch": 2, "training_loss": 71.61399388313293, "training_acc": 28.0, "val_loss": 17.7626833319664, "val_acc": 28.0}
{"epoch": 3, "training_loss": 70.61804986000061, "training_acc": 28.0, "val_loss": 17.560672760009766, "val_acc": 28.0}
{"epoch": 4, "training_loss": 69.93543720245361, "training_acc": 33.0, "val_loss": 17.366115748882294, "val_acc": 28.0}
{"epoch": 5, "training_loss": 69.1199676990509, "training_acc": 60.0, "val_loss": 17.181357741355896, "val_acc": 28.0}
{"epoch": 6, "training_loss": 68.49889349937439, "training_acc": 71.0, "val_loss": 17.008130252361298, "val_acc": 28.0}
{"epoch": 7, "training_loss": 67.6745069026947, "training_acc": 70.0, "val_loss": 16.84243232011795, "val_acc": 28.0}
{"epoch": 8, "training_loss": 67.14863348007202, "training_acc": 71.0, "val_loss": 16.683748364448547, "val_acc": 28.0}
{"epoch": 9, "training_loss": 66.59024357795715, "training_acc": 72.0, "val_loss": 16.526256501674652, "val_acc": 28.0}
{"epoch": 10, "training_loss": 65.89630174636841, "training_acc": 72.0, "val_loss": 16.36822074651718, "val_acc": 28.0}
{"epoch": 11, "training_loss": 65.33155488967896, "training_acc": 72.0, "val_loss": 16.216662526130676, "val_acc": 28.0}
{"epoch": 12, "training_loss": 64.7014684677124, "training_acc": 72.0, "val_loss": 16.07934534549713, "val_acc": 28.0}
{"epoch": 13, "training_loss": 64.21917390823364, "training_acc": 72.0, "val_loss": 15.950563549995422, "val_acc": 28.0}
{"epoch": 14, "training_loss": 63.49150371551514, "training_acc": 72.0, "val_loss": 15.832051634788513, "val_acc": 28.0}
{"epoch": 15, "training_loss": 62.95511817932129, "training_acc": 72.0, "val_loss": 15.72021096944809, "val_acc": 28.0}
{"epoch": 16, "training_loss": 62.590252161026, "training_acc": 72.0, "val_loss": 15.600302815437317, "val_acc": 28.0}
{"epoch": 17, "training_loss": 62.13969874382019, "training_acc": 72.0, "val_loss": 15.465421974658966, "val_acc": 36.0}
{"epoch": 18, "training_loss": 61.59594917297363, "training_acc": 72.0, "val_loss": 15.326710045337677, "val_acc": 48.0}
{"epoch": 19, "training_loss": 60.9693124294281, "training_acc": 72.0, "val_loss": 15.202498435974121, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.480037212371826, "training_acc": 72.0, "val_loss": 15.087419748306274, "val_acc": 68.0}
{"epoch": 21, "training_loss": 60.076873540878296, "training_acc": 72.0, "val_loss": 14.958377182483673, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.616313457489014, "training_acc": 72.0, "val_loss": 14.8370161652565, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.202778339385986, "training_acc": 72.0, "val_loss": 14.73609209060669, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.86514401435852, "training_acc": 72.0, "val_loss": 14.664405584335327, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.335541009902954, "training_acc": 72.0, "val_loss": 14.63281363248825, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.28094983100891, "training_acc": 72.0, "val_loss": 14.63850885629654, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.26862549781799, "training_acc": 72.0, "val_loss": 14.667484164237976, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.17074155807495, "training_acc": 72.0, "val_loss": 14.67704027891159, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.53003239631653, "training_acc": 72.0, "val_loss": 14.663070440292358, "val_acc": 72.0}
{"epoch": 30, "training_loss": 57.430063247680664, "training_acc": 72.0, "val_loss": 14.63349312543869, "val_acc": 72.0}
{"epoch": 31, "training_loss": 57.033037185668945, "training_acc": 72.0, "val_loss": 14.608944952487946, "val_acc": 72.0}
{"epoch": 32, "training_loss": 57.63912224769592, "training_acc": 72.0, "val_loss": 14.589762687683105, "val_acc": 72.0}
{"epoch": 33, "training_loss": 57.657516956329346, "training_acc": 72.0, "val_loss": 14.572301506996155, "val_acc": 72.0}
{"epoch": 34, "training_loss": 57.44411587715149, "training_acc": 72.0, "val_loss": 14.557084441184998, "val_acc": 72.0}
{"epoch": 35, "training_loss": 57.48169231414795, "training_acc": 72.0, "val_loss": 14.543873071670532, "val_acc": 72.0}
{"epoch": 36, "training_loss": 57.09695243835449, "training_acc": 72.0, "val_loss": 14.53121155500412, "val_acc": 72.0}
{"epoch": 37, "training_loss": 56.99164152145386, "training_acc": 72.0, "val_loss": 14.519734680652618, "val_acc": 72.0}
{"epoch": 38, "training_loss": 56.95677328109741, "training_acc": 72.0, "val_loss": 14.509132504463196, "val_acc": 72.0}
{"epoch": 39, "training_loss": 56.56291127204895, "training_acc": 72.0, "val_loss": 14.502297341823578, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.98143649101257, "training_acc": 72.0, "val_loss": 14.495334029197693, "val_acc": 72.0}
{"epoch": 41, "training_loss": 55.89837312698364, "training_acc": 72.0, "val_loss": 14.48887437582016, "val_acc": 72.0}
{"epoch": 42, "training_loss": 55.40735626220703, "training_acc": 72.0, "val_loss": 14.484542608261108, "val_acc": 72.0}
{"epoch": 43, "training_loss": 55.39087271690369, "training_acc": 72.0, "val_loss": 14.476945996284485, "val_acc": 72.0}
{"epoch": 44, "training_loss": 56.36257243156433, "training_acc": 72.0, "val_loss": 14.465038478374481, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.88474702835083, "training_acc": 72.0, "val_loss": 14.461788535118103, "val_acc": 72.0}
{"epoch": 46, "training_loss": 54.35027265548706, "training_acc": 72.0, "val_loss": 14.472006261348724, "val_acc": 76.0}
{"epoch": 47, "training_loss": 54.36799454689026, "training_acc": 72.0, "val_loss": 14.470914006233215, "val_acc": 76.0}
{"epoch": 48, "training_loss": 53.571781873703, "training_acc": 72.0, "val_loss": 14.457492530345917, "val_acc": 72.0}
{"epoch": 49, "training_loss": 54.42145538330078, "training_acc": 72.0, "val_loss": 14.432947337627411, "val_acc": 72.0}
{"epoch": 50, "training_loss": 53.59815335273743, "training_acc": 72.0, "val_loss": 14.447231590747833, "val_acc": 72.0}
{"epoch": 51, "training_loss": 52.640774965286255, "training_acc": 72.0, "val_loss": 14.491747319698334, "val_acc": 72.0}
{"epoch": 52, "training_loss": 54.13596272468567, "training_acc": 72.0, "val_loss": 14.525039494037628, "val_acc": 68.0}
{"epoch": 53, "training_loss": 54.012577533721924, "training_acc": 72.0, "val_loss": 14.536674320697784, "val_acc": 68.0}
{"epoch": 54, "training_loss": 53.374348282814026, "training_acc": 72.0, "val_loss": 14.54194188117981, "val_acc": 68.0}
{"epoch": 55, "training_loss": 52.87542510032654, "training_acc": 72.0, "val_loss": 14.602328836917877, "val_acc": 68.0}
{"epoch": 56, "training_loss": 51.86344373226166, "training_acc": 72.0, "val_loss": 14.59907740354538, "val_acc": 68.0}
{"epoch": 57, "training_loss": 52.81008839607239, "training_acc": 72.0, "val_loss": 14.595302939414978, "val_acc": 68.0}
{"epoch": 58, "training_loss": 50.731669425964355, "training_acc": 72.0, "val_loss": 14.593686163425446, "val_acc": 68.0}
{"epoch": 59, "training_loss": 52.1656699180603, "training_acc": 72.0, "val_loss": 14.574581384658813, "val_acc": 68.0}
{"epoch": 60, "training_loss": 50.6625839471817, "training_acc": 72.0, "val_loss": 14.570680260658264, "val_acc": 64.0}
{"epoch": 61, "training_loss": 51.96445631980896, "training_acc": 72.0, "val_loss": 14.595477283000946, "val_acc": 64.0}
{"epoch": 62, "training_loss": 51.409507751464844, "training_acc": 72.0, "val_loss": 14.622274041175842, "val_acc": 64.0}
{"epoch": 63, "training_loss": 50.94710552692413, "training_acc": 72.0, "val_loss": 14.624331891536713, "val_acc": 64.0}
{"epoch": 64, "training_loss": 49.945465326309204, "training_acc": 72.0, "val_loss": 14.64850902557373, "val_acc": 64.0}
{"epoch": 65, "training_loss": 49.832425117492676, "training_acc": 72.0, "val_loss": 14.70126062631607, "val_acc": 64.0}
{"epoch": 66, "training_loss": 50.79311156272888, "training_acc": 74.0, "val_loss": 14.748753607273102, "val_acc": 64.0}
{"epoch": 67, "training_loss": 49.960824847221375, "training_acc": 74.0, "val_loss": 14.756476879119873, "val_acc": 64.0}
{"epoch": 68, "training_loss": 51.477041482925415, "training_acc": 74.0, "val_loss": 14.809520542621613, "val_acc": 64.0}
