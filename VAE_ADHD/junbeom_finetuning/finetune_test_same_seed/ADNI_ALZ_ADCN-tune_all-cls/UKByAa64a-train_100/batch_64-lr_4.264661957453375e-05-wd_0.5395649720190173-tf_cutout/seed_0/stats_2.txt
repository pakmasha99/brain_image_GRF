"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.88055205345154, "training_acc": 37.0, "val_loss": 17.56446808576584, "val_acc": 28.0}
{"epoch": 1, "training_loss": 69.55191421508789, "training_acc": 42.0, "val_loss": 16.82255119085312, "val_acc": 28.0}
{"epoch": 2, "training_loss": 67.0029969215393, "training_acc": 73.0, "val_loss": 16.22557044029236, "val_acc": 28.0}
{"epoch": 3, "training_loss": 64.69504261016846, "training_acc": 72.0, "val_loss": 15.89614748954773, "val_acc": 28.0}
{"epoch": 4, "training_loss": 63.21254897117615, "training_acc": 72.0, "val_loss": 15.419390797615051, "val_acc": 52.0}
{"epoch": 5, "training_loss": 60.6610209941864, "training_acc": 72.0, "val_loss": 15.197338163852692, "val_acc": 60.0}
{"epoch": 6, "training_loss": 59.81876349449158, "training_acc": 72.0, "val_loss": 14.985039830207825, "val_acc": 68.0}
{"epoch": 7, "training_loss": 58.379374742507935, "training_acc": 72.0, "val_loss": 14.945891499519348, "val_acc": 64.0}
{"epoch": 8, "training_loss": 57.35836124420166, "training_acc": 72.0, "val_loss": 14.781089127063751, "val_acc": 64.0}
{"epoch": 9, "training_loss": 57.327433824539185, "training_acc": 72.0, "val_loss": 14.77261334657669, "val_acc": 68.0}
{"epoch": 10, "training_loss": 55.80209827423096, "training_acc": 72.0, "val_loss": 14.755856990814209, "val_acc": 68.0}
{"epoch": 11, "training_loss": 54.93014931678772, "training_acc": 72.0, "val_loss": 14.60358202457428, "val_acc": 64.0}
{"epoch": 12, "training_loss": 55.521138191223145, "training_acc": 72.0, "val_loss": 14.631743729114532, "val_acc": 64.0}
{"epoch": 13, "training_loss": 54.44919514656067, "training_acc": 72.0, "val_loss": 14.814017713069916, "val_acc": 68.0}
{"epoch": 14, "training_loss": 52.650755524635315, "training_acc": 72.0, "val_loss": 14.860206842422485, "val_acc": 68.0}
{"epoch": 15, "training_loss": 53.21542942523956, "training_acc": 72.0, "val_loss": 15.079182386398315, "val_acc": 68.0}
{"epoch": 16, "training_loss": 52.18907833099365, "training_acc": 72.0, "val_loss": 14.690396189689636, "val_acc": 64.0}
{"epoch": 17, "training_loss": 51.270076513290405, "training_acc": 72.0, "val_loss": 15.09501039981842, "val_acc": 68.0}
{"epoch": 18, "training_loss": 51.161327838897705, "training_acc": 73.0, "val_loss": 14.69651609659195, "val_acc": 68.0}
{"epoch": 19, "training_loss": 50.064048767089844, "training_acc": 75.0, "val_loss": 15.088234841823578, "val_acc": 68.0}
{"epoch": 20, "training_loss": 51.91537022590637, "training_acc": 76.0, "val_loss": 14.926333725452423, "val_acc": 64.0}
{"epoch": 21, "training_loss": 49.64643168449402, "training_acc": 76.0, "val_loss": 14.551052451133728, "val_acc": 56.0}
{"epoch": 22, "training_loss": 49.939138770103455, "training_acc": 83.0, "val_loss": 15.523959696292877, "val_acc": 64.0}
{"epoch": 23, "training_loss": 52.924336671829224, "training_acc": 72.0, "val_loss": 15.218426287174225, "val_acc": 68.0}
{"epoch": 24, "training_loss": 52.945674419403076, "training_acc": 74.0, "val_loss": 14.672870934009552, "val_acc": 52.0}
{"epoch": 25, "training_loss": 55.36909461021423, "training_acc": 73.0, "val_loss": 14.664393663406372, "val_acc": 68.0}
{"epoch": 26, "training_loss": 48.22220432758331, "training_acc": 72.0, "val_loss": 15.45838713645935, "val_acc": 64.0}
{"epoch": 27, "training_loss": 50.48448193073273, "training_acc": 73.0, "val_loss": 14.889641106128693, "val_acc": 68.0}
{"epoch": 28, "training_loss": 48.762296199798584, "training_acc": 77.0, "val_loss": 14.577725529670715, "val_acc": 56.0}
{"epoch": 29, "training_loss": 46.94252562522888, "training_acc": 84.0, "val_loss": 15.460194647312164, "val_acc": 64.0}
{"epoch": 30, "training_loss": 50.22315990924835, "training_acc": 73.0, "val_loss": 15.44664204120636, "val_acc": 68.0}
{"epoch": 31, "training_loss": 46.54283905029297, "training_acc": 79.0, "val_loss": 14.778457581996918, "val_acc": 52.0}
{"epoch": 32, "training_loss": 46.17997610569, "training_acc": 85.0, "val_loss": 15.37141352891922, "val_acc": 68.0}
{"epoch": 33, "training_loss": 45.55248820781708, "training_acc": 78.0, "val_loss": 15.176789462566376, "val_acc": 68.0}
{"epoch": 34, "training_loss": 44.34299635887146, "training_acc": 83.0, "val_loss": 14.680945873260498, "val_acc": 68.0}
{"epoch": 35, "training_loss": 43.41692936420441, "training_acc": 85.0, "val_loss": 15.729162096977234, "val_acc": 68.0}
{"epoch": 36, "training_loss": 42.96267247200012, "training_acc": 81.0, "val_loss": 15.013432502746582, "val_acc": 68.0}
{"epoch": 37, "training_loss": 43.16377854347229, "training_acc": 89.0, "val_loss": 15.341931581497192, "val_acc": 68.0}
{"epoch": 38, "training_loss": 40.100926995277405, "training_acc": 86.0, "val_loss": 15.337774157524109, "val_acc": 68.0}
{"epoch": 39, "training_loss": 40.024391651153564, "training_acc": 86.0, "val_loss": 14.552409946918488, "val_acc": 52.0}
{"epoch": 40, "training_loss": 41.51146852970123, "training_acc": 92.0, "val_loss": 16.09741747379303, "val_acc": 64.0}
