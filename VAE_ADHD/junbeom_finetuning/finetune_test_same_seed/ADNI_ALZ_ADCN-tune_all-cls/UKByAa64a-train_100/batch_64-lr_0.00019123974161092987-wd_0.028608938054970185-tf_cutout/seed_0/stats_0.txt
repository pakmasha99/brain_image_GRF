"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.74632120132446, "training_acc": 42.0, "val_loss": 16.544662415981293, "val_acc": 28.0}
{"epoch": 1, "training_loss": 65.81334733963013, "training_acc": 72.0, "val_loss": 15.536491572856903, "val_acc": 28.0}
{"epoch": 2, "training_loss": 61.25159311294556, "training_acc": 72.0, "val_loss": 14.876383543014526, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.48491954803467, "training_acc": 72.0, "val_loss": 14.772360026836395, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.16837239265442, "training_acc": 72.0, "val_loss": 14.717806875705719, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.77633833885193, "training_acc": 72.0, "val_loss": 14.737090468406677, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.98317742347717, "training_acc": 72.0, "val_loss": 14.700016379356384, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.071354150772095, "training_acc": 72.0, "val_loss": 14.54453319311142, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.62008619308472, "training_acc": 72.0, "val_loss": 14.395782351493835, "val_acc": 72.0}
{"epoch": 9, "training_loss": 58.209561586380005, "training_acc": 72.0, "val_loss": 14.486585557460785, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.053974866867065, "training_acc": 72.0, "val_loss": 14.182345569133759, "val_acc": 72.0}
{"epoch": 11, "training_loss": 57.58318567276001, "training_acc": 72.0, "val_loss": 14.082755148410797, "val_acc": 72.0}
{"epoch": 12, "training_loss": 56.85379409790039, "training_acc": 72.0, "val_loss": 15.06243348121643, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.65467286109924, "training_acc": 72.0, "val_loss": 14.523516595363617, "val_acc": 72.0}
{"epoch": 14, "training_loss": 57.40628480911255, "training_acc": 72.0, "val_loss": 14.24974799156189, "val_acc": 72.0}
{"epoch": 15, "training_loss": 56.53342890739441, "training_acc": 72.0, "val_loss": 13.993555307388306, "val_acc": 72.0}
{"epoch": 16, "training_loss": 56.22232365608215, "training_acc": 72.0, "val_loss": 13.36582750082016, "val_acc": 76.0}
{"epoch": 17, "training_loss": 55.705689668655396, "training_acc": 72.0, "val_loss": 13.446103036403656, "val_acc": 76.0}
{"epoch": 18, "training_loss": 56.68793749809265, "training_acc": 72.0, "val_loss": 13.756129145622253, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.63742804527283, "training_acc": 72.0, "val_loss": 13.1997749209404, "val_acc": 76.0}
{"epoch": 20, "training_loss": 52.754008769989014, "training_acc": 72.0, "val_loss": 13.720279932022095, "val_acc": 76.0}
{"epoch": 21, "training_loss": 55.05686688423157, "training_acc": 72.0, "val_loss": 13.606104254722595, "val_acc": 64.0}
{"epoch": 22, "training_loss": 56.88631248474121, "training_acc": 72.0, "val_loss": 13.31125944852829, "val_acc": 72.0}
{"epoch": 23, "training_loss": 51.797656774520874, "training_acc": 72.0, "val_loss": 13.608679175376892, "val_acc": 76.0}
{"epoch": 24, "training_loss": 52.29459023475647, "training_acc": 72.0, "val_loss": 13.135391473770142, "val_acc": 76.0}
{"epoch": 25, "training_loss": 51.52889275550842, "training_acc": 72.0, "val_loss": 13.493353128433228, "val_acc": 60.0}
{"epoch": 26, "training_loss": 49.502506613731384, "training_acc": 72.0, "val_loss": 13.112585246562958, "val_acc": 72.0}
{"epoch": 27, "training_loss": 48.00834262371063, "training_acc": 72.0, "val_loss": 12.79403418302536, "val_acc": 68.0}
{"epoch": 28, "training_loss": 46.02477324008942, "training_acc": 74.0, "val_loss": 13.689041137695312, "val_acc": 76.0}
{"epoch": 29, "training_loss": 46.70924937725067, "training_acc": 79.0, "val_loss": 14.000214636325836, "val_acc": 68.0}
{"epoch": 30, "training_loss": 43.408687472343445, "training_acc": 80.0, "val_loss": 12.817175686359406, "val_acc": 68.0}
{"epoch": 31, "training_loss": 44.232418060302734, "training_acc": 84.0, "val_loss": 13.961507380008698, "val_acc": 76.0}
{"epoch": 32, "training_loss": 41.88475954532623, "training_acc": 81.0, "val_loss": 16.199521720409393, "val_acc": 72.0}
{"epoch": 33, "training_loss": 50.502731680870056, "training_acc": 78.0, "val_loss": 13.45052421092987, "val_acc": 68.0}
{"epoch": 34, "training_loss": 38.557892203330994, "training_acc": 87.0, "val_loss": 12.433791905641556, "val_acc": 72.0}
{"epoch": 35, "training_loss": 40.009817123413086, "training_acc": 86.0, "val_loss": 11.837884038686752, "val_acc": 76.0}
{"epoch": 36, "training_loss": 41.69920206069946, "training_acc": 83.0, "val_loss": 13.103130459785461, "val_acc": 76.0}
{"epoch": 37, "training_loss": 32.43337273597717, "training_acc": 91.0, "val_loss": 14.43125456571579, "val_acc": 64.0}
{"epoch": 38, "training_loss": 33.438093423843384, "training_acc": 91.0, "val_loss": 12.690053880214691, "val_acc": 68.0}
{"epoch": 39, "training_loss": 43.608439445495605, "training_acc": 81.0, "val_loss": 12.758657336235046, "val_acc": 72.0}
{"epoch": 40, "training_loss": 34.03534209728241, "training_acc": 89.0, "val_loss": 12.619665265083313, "val_acc": 64.0}
{"epoch": 41, "training_loss": 38.730101227760315, "training_acc": 84.0, "val_loss": 12.200822681188583, "val_acc": 72.0}
{"epoch": 42, "training_loss": 34.007646441459656, "training_acc": 92.0, "val_loss": 14.05995786190033, "val_acc": 76.0}
{"epoch": 43, "training_loss": 44.29939246177673, "training_acc": 83.0, "val_loss": 12.260346859693527, "val_acc": 68.0}
{"epoch": 44, "training_loss": 40.90985178947449, "training_acc": 84.0, "val_loss": 14.933477342128754, "val_acc": 76.0}
{"epoch": 45, "training_loss": 44.97722363471985, "training_acc": 83.0, "val_loss": 11.855065822601318, "val_acc": 84.0}
{"epoch": 46, "training_loss": 40.403979539871216, "training_acc": 79.0, "val_loss": 12.007404118776321, "val_acc": 72.0}
{"epoch": 47, "training_loss": 40.123693108558655, "training_acc": 83.0, "val_loss": 11.48933544754982, "val_acc": 84.0}
{"epoch": 48, "training_loss": 41.48571753501892, "training_acc": 85.0, "val_loss": 11.165337264537811, "val_acc": 76.0}
{"epoch": 49, "training_loss": 29.768308639526367, "training_acc": 94.0, "val_loss": 13.054659962654114, "val_acc": 72.0}
{"epoch": 50, "training_loss": 36.07200276851654, "training_acc": 87.0, "val_loss": 12.265527248382568, "val_acc": 72.0}
{"epoch": 51, "training_loss": 31.66762763261795, "training_acc": 90.0, "val_loss": 13.044776022434235, "val_acc": 72.0}
{"epoch": 52, "training_loss": 28.604074478149414, "training_acc": 93.0, "val_loss": 12.858931720256805, "val_acc": 72.0}
{"epoch": 53, "training_loss": 37.46479070186615, "training_acc": 82.0, "val_loss": 12.127590924501419, "val_acc": 72.0}
{"epoch": 54, "training_loss": 27.100967049598694, "training_acc": 94.0, "val_loss": 12.82801628112793, "val_acc": 80.0}
{"epoch": 55, "training_loss": 30.278745770454407, "training_acc": 91.0, "val_loss": 15.50920307636261, "val_acc": 52.0}
{"epoch": 56, "training_loss": 49.81177866458893, "training_acc": 69.0, "val_loss": 13.247576355934143, "val_acc": 80.0}
{"epoch": 57, "training_loss": 33.749266266822815, "training_acc": 83.0, "val_loss": 11.315198987722397, "val_acc": 68.0}
{"epoch": 58, "training_loss": 29.63484787940979, "training_acc": 95.0, "val_loss": 11.670009046792984, "val_acc": 72.0}
{"epoch": 59, "training_loss": 26.177046060562134, "training_acc": 95.0, "val_loss": 13.674719631671906, "val_acc": 72.0}
{"epoch": 60, "training_loss": 31.531648874282837, "training_acc": 90.0, "val_loss": 12.233135104179382, "val_acc": 72.0}
{"epoch": 61, "training_loss": 23.884957194328308, "training_acc": 95.0, "val_loss": 13.233868777751923, "val_acc": 76.0}
{"epoch": 62, "training_loss": 37.24072706699371, "training_acc": 85.0, "val_loss": 12.708747386932373, "val_acc": 80.0}
{"epoch": 63, "training_loss": 28.669700622558594, "training_acc": 88.0, "val_loss": 11.824332922697067, "val_acc": 72.0}
{"epoch": 64, "training_loss": 30.41293776035309, "training_acc": 89.0, "val_loss": 13.925395905971527, "val_acc": 80.0}
{"epoch": 65, "training_loss": 43.81667876243591, "training_acc": 85.0, "val_loss": 13.56900930404663, "val_acc": 80.0}
{"epoch": 66, "training_loss": 31.364748001098633, "training_acc": 91.0, "val_loss": 11.229214072227478, "val_acc": 72.0}
{"epoch": 67, "training_loss": 30.46354031562805, "training_acc": 92.0, "val_loss": 12.519125640392303, "val_acc": 84.0}
