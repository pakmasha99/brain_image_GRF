"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 89.66219329833984, "training_acc": 49.0, "val_loss": 18561.196899414062, "val_acc": 72.0}
{"epoch": 1, "training_loss": 40552.28700351715, "training_acc": 72.0, "val_loss": 19.82526034116745, "val_acc": 28.0}
{"epoch": 2, "training_loss": 100.92038345336914, "training_acc": 52.0, "val_loss": 750.8900165557861, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1959.3892936706543, "training_acc": 28.0, "val_loss": 22.918696701526642, "val_acc": 72.0}
{"epoch": 4, "training_loss": 88.38230109214783, "training_acc": 72.0, "val_loss": 14.951419830322266, "val_acc": 72.0}
{"epoch": 5, "training_loss": 61.45068979263306, "training_acc": 72.0, "val_loss": 14.88199234008789, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.9105908870697, "training_acc": 72.0, "val_loss": 14.922067523002625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.02314376831055, "training_acc": 72.0, "val_loss": 14.936338365077972, "val_acc": 72.0}
{"epoch": 8, "training_loss": 73.79271125793457, "training_acc": 72.0, "val_loss": 15.127503871917725, "val_acc": 72.0}
{"epoch": 9, "training_loss": 63.3112370967865, "training_acc": 72.0, "val_loss": 16.583287715911865, "val_acc": 28.0}
{"epoch": 10, "training_loss": 63.974276304244995, "training_acc": 72.0, "val_loss": 14.914655685424805, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.16578269004822, "training_acc": 72.0, "val_loss": 15.417639911174774, "val_acc": 72.0}
{"epoch": 12, "training_loss": 61.41133236885071, "training_acc": 72.0, "val_loss": 14.896756410598755, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.51691770553589, "training_acc": 72.0, "val_loss": 15.011997520923615, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.13915967941284, "training_acc": 72.0, "val_loss": 14.88349735736847, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.71492052078247, "training_acc": 72.0, "val_loss": 14.911943674087524, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.38402962684631, "training_acc": 72.0, "val_loss": 14.941610395908356, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.77023363113403, "training_acc": 72.0, "val_loss": 14.885115623474121, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.56485557556152, "training_acc": 72.0, "val_loss": 15.032130479812622, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.21688103675842, "training_acc": 72.0, "val_loss": 15.051870048046112, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.23756980895996, "training_acc": 72.0, "val_loss": 14.898678660392761, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.86399507522583, "training_acc": 72.0, "val_loss": 14.871124923229218, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.61528396606445, "training_acc": 72.0, "val_loss": 14.869752526283264, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.49801182746887, "training_acc": 72.0, "val_loss": 14.848490059375763, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.492106676101685, "training_acc": 72.0, "val_loss": 14.853718876838684, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.40494203567505, "training_acc": 72.0, "val_loss": 14.875274896621704, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.459163665771484, "training_acc": 72.0, "val_loss": 14.849697053432465, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.30619835853577, "training_acc": 72.0, "val_loss": 14.836475253105164, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.07606625556946, "training_acc": 72.0, "val_loss": 15.034322440624237, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.37918567657471, "training_acc": 72.0, "val_loss": 14.896462857723236, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.321656465530396, "training_acc": 72.0, "val_loss": 14.93828296661377, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.91277241706848, "training_acc": 72.0, "val_loss": 15.035362541675568, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.927130937576294, "training_acc": 72.0, "val_loss": 14.86022025346756, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.40073752403259, "training_acc": 72.0, "val_loss": 14.85615074634552, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.56985926628113, "training_acc": 72.0, "val_loss": 14.862114191055298, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.75934863090515, "training_acc": 72.0, "val_loss": 14.822123944759369, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.17551112174988, "training_acc": 72.0, "val_loss": 14.814655482769012, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.5619854927063, "training_acc": 72.0, "val_loss": 14.805112779140472, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.554847955703735, "training_acc": 72.0, "val_loss": 14.850340783596039, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.247384548187256, "training_acc": 72.0, "val_loss": 14.811843633651733, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.981160402297974, "training_acc": 72.0, "val_loss": 14.794881641864777, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.95920252799988, "training_acc": 72.0, "val_loss": 14.783599972724915, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.025036334991455, "training_acc": 72.0, "val_loss": 14.783191680908203, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.7604603767395, "training_acc": 72.0, "val_loss": 14.856240153312683, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.04279685020447, "training_acc": 72.0, "val_loss": 14.832431077957153, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.102391719818115, "training_acc": 72.0, "val_loss": 14.755883812904358, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.65314865112305, "training_acc": 72.0, "val_loss": 14.739961922168732, "val_acc": 72.0}
{"epoch": 47, "training_loss": 58.48362135887146, "training_acc": 72.0, "val_loss": 14.786739647388458, "val_acc": 72.0}
{"epoch": 48, "training_loss": 58.45977306365967, "training_acc": 72.0, "val_loss": 14.74360078573227, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.15395140647888, "training_acc": 72.0, "val_loss": 14.67542052268982, "val_acc": 72.0}
{"epoch": 50, "training_loss": 57.844390630722046, "training_acc": 72.0, "val_loss": 14.687003195285797, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.32620859146118, "training_acc": 72.0, "val_loss": 15.224504470825195, "val_acc": 72.0}
{"epoch": 52, "training_loss": 60.74374079704285, "training_acc": 72.0, "val_loss": 14.665603637695312, "val_acc": 72.0}
{"epoch": 53, "training_loss": 58.70158100128174, "training_acc": 72.0, "val_loss": 14.938578009605408, "val_acc": 68.0}
{"epoch": 54, "training_loss": 58.96789574623108, "training_acc": 72.0, "val_loss": 14.797830581665039, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.624316692352295, "training_acc": 72.0, "val_loss": 14.82531726360321, "val_acc": 72.0}
{"epoch": 56, "training_loss": 58.97549510002136, "training_acc": 72.0, "val_loss": 14.859490096569061, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.67394685745239, "training_acc": 72.0, "val_loss": 14.824725687503815, "val_acc": 72.0}
{"epoch": 58, "training_loss": 58.72392463684082, "training_acc": 72.0, "val_loss": 14.981457591056824, "val_acc": 72.0}
{"epoch": 59, "training_loss": 62.58031439781189, "training_acc": 72.0, "val_loss": 14.746899902820587, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.07030487060547, "training_acc": 72.0, "val_loss": 15.311096608638763, "val_acc": 52.0}
{"epoch": 61, "training_loss": 61.00520467758179, "training_acc": 72.0, "val_loss": 15.252488851547241, "val_acc": 72.0}
{"epoch": 62, "training_loss": 60.60141324996948, "training_acc": 72.0, "val_loss": 14.923211932182312, "val_acc": 72.0}
{"epoch": 63, "training_loss": 59.02118420600891, "training_acc": 72.0, "val_loss": 14.785578846931458, "val_acc": 72.0}
{"epoch": 64, "training_loss": 60.4869921207428, "training_acc": 72.0, "val_loss": 14.876055717468262, "val_acc": 72.0}
{"epoch": 65, "training_loss": 58.47975993156433, "training_acc": 72.0, "val_loss": 14.825312793254852, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.672425508499146, "training_acc": 72.0, "val_loss": 14.984896779060364, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.2199068069458, "training_acc": 72.0, "val_loss": 14.729629456996918, "val_acc": 72.0}
{"epoch": 68, "training_loss": 58.159034967422485, "training_acc": 72.0, "val_loss": 15.03543108701706, "val_acc": 72.0}
{"epoch": 69, "training_loss": 60.005481243133545, "training_acc": 72.0, "val_loss": 14.976593852043152, "val_acc": 72.0}
{"epoch": 70, "training_loss": 58.736759662628174, "training_acc": 72.0, "val_loss": 14.761105179786682, "val_acc": 72.0}
{"epoch": 71, "training_loss": 58.823280811309814, "training_acc": 72.0, "val_loss": 14.984060823917389, "val_acc": 72.0}
