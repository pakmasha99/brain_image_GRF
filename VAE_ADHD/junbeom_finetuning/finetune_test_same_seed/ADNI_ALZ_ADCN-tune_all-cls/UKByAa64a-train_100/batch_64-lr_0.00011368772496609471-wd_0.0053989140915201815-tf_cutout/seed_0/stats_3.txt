"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 73.25758790969849, "training_acc": 28.0, "val_loss": 17.75953322649002, "val_acc": 28.0}
{"epoch": 1, "training_loss": 70.21542000770569, "training_acc": 49.0, "val_loss": 16.75736755132675, "val_acc": 28.0}
{"epoch": 2, "training_loss": 66.14396357536316, "training_acc": 72.0, "val_loss": 15.569420158863068, "val_acc": 28.0}
{"epoch": 3, "training_loss": 61.757861375808716, "training_acc": 72.0, "val_loss": 15.025344491004944, "val_acc": 68.0}
{"epoch": 4, "training_loss": 59.674453020095825, "training_acc": 72.0, "val_loss": 14.740486443042755, "val_acc": 68.0}
{"epoch": 5, "training_loss": 58.81108546257019, "training_acc": 72.0, "val_loss": 14.591532945632935, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.18492674827576, "training_acc": 72.0, "val_loss": 14.455263316631317, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.895747661590576, "training_acc": 72.0, "val_loss": 14.293789863586426, "val_acc": 72.0}
{"epoch": 8, "training_loss": 56.856892824172974, "training_acc": 72.0, "val_loss": 14.370870590209961, "val_acc": 72.0}
{"epoch": 9, "training_loss": 57.124267578125, "training_acc": 72.0, "val_loss": 13.970054686069489, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.578364610672, "training_acc": 72.0, "val_loss": 14.155931770801544, "val_acc": 72.0}
{"epoch": 11, "training_loss": 57.89319562911987, "training_acc": 72.0, "val_loss": 13.776497542858124, "val_acc": 68.0}
{"epoch": 12, "training_loss": 57.161885499954224, "training_acc": 72.0, "val_loss": 14.045782387256622, "val_acc": 72.0}
{"epoch": 13, "training_loss": 56.74872028827667, "training_acc": 72.0, "val_loss": 13.891389966011047, "val_acc": 68.0}
{"epoch": 14, "training_loss": 54.78989577293396, "training_acc": 72.0, "val_loss": 13.645368814468384, "val_acc": 72.0}
{"epoch": 15, "training_loss": 54.366241216659546, "training_acc": 72.0, "val_loss": 13.363374769687653, "val_acc": 68.0}
{"epoch": 16, "training_loss": 53.06126022338867, "training_acc": 72.0, "val_loss": 13.319285213947296, "val_acc": 72.0}
{"epoch": 17, "training_loss": 52.3758602142334, "training_acc": 72.0, "val_loss": 13.924527168273926, "val_acc": 72.0}
{"epoch": 18, "training_loss": 56.77645540237427, "training_acc": 72.0, "val_loss": 13.916291296482086, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.298911571502686, "training_acc": 72.0, "val_loss": 13.087686896324158, "val_acc": 72.0}
{"epoch": 20, "training_loss": 53.632238149642944, "training_acc": 72.0, "val_loss": 13.005858659744263, "val_acc": 72.0}
{"epoch": 21, "training_loss": 51.26452946662903, "training_acc": 72.0, "val_loss": 13.41446340084076, "val_acc": 68.0}
{"epoch": 22, "training_loss": 51.65958833694458, "training_acc": 72.0, "val_loss": 13.260678946971893, "val_acc": 68.0}
{"epoch": 23, "training_loss": 53.023937821388245, "training_acc": 76.0, "val_loss": 14.30191844701767, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.35310363769531, "training_acc": 72.0, "val_loss": 14.842155575752258, "val_acc": 72.0}
{"epoch": 25, "training_loss": 57.992746114730835, "training_acc": 72.0, "val_loss": 14.579112827777863, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.31151294708252, "training_acc": 72.0, "val_loss": 14.844141900539398, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.95263981819153, "training_acc": 72.0, "val_loss": 14.585903286933899, "val_acc": 68.0}
{"epoch": 28, "training_loss": 58.09739804267883, "training_acc": 72.0, "val_loss": 14.388087391853333, "val_acc": 72.0}
{"epoch": 29, "training_loss": 57.28528571128845, "training_acc": 72.0, "val_loss": 14.219196140766144, "val_acc": 72.0}
{"epoch": 30, "training_loss": 56.66394877433777, "training_acc": 72.0, "val_loss": 14.009499549865723, "val_acc": 68.0}
{"epoch": 31, "training_loss": 55.5495982170105, "training_acc": 72.0, "val_loss": 13.791698217391968, "val_acc": 72.0}
{"epoch": 32, "training_loss": 54.42134189605713, "training_acc": 72.0, "val_loss": 13.652235269546509, "val_acc": 72.0}
{"epoch": 33, "training_loss": 54.37007927894592, "training_acc": 72.0, "val_loss": 13.204221427440643, "val_acc": 68.0}
{"epoch": 34, "training_loss": 52.45877814292908, "training_acc": 72.0, "val_loss": 13.045071065425873, "val_acc": 72.0}
{"epoch": 35, "training_loss": 51.861321687698364, "training_acc": 72.0, "val_loss": 12.954835593700409, "val_acc": 72.0}
{"epoch": 36, "training_loss": 51.931015491485596, "training_acc": 72.0, "val_loss": 12.757788598537445, "val_acc": 72.0}
{"epoch": 37, "training_loss": 51.046515226364136, "training_acc": 72.0, "val_loss": 12.71701455116272, "val_acc": 72.0}
{"epoch": 38, "training_loss": 49.283547043800354, "training_acc": 79.0, "val_loss": 12.688705325126648, "val_acc": 72.0}
{"epoch": 39, "training_loss": 48.05098795890808, "training_acc": 77.0, "val_loss": 12.467825412750244, "val_acc": 76.0}
{"epoch": 40, "training_loss": 48.36154520511627, "training_acc": 81.0, "val_loss": 12.260294705629349, "val_acc": 76.0}
{"epoch": 41, "training_loss": 47.86651301383972, "training_acc": 78.0, "val_loss": 12.220878154039383, "val_acc": 76.0}
{"epoch": 42, "training_loss": 45.4532128572464, "training_acc": 83.0, "val_loss": 12.122083455324173, "val_acc": 76.0}
{"epoch": 43, "training_loss": 44.45743370056152, "training_acc": 83.0, "val_loss": 11.725055426359177, "val_acc": 80.0}
{"epoch": 44, "training_loss": 40.91564130783081, "training_acc": 84.0, "val_loss": 12.718789279460907, "val_acc": 76.0}
{"epoch": 45, "training_loss": 46.17200243473053, "training_acc": 79.0, "val_loss": 10.96380427479744, "val_acc": 80.0}
{"epoch": 46, "training_loss": 37.75251603126526, "training_acc": 85.0, "val_loss": 10.877050459384918, "val_acc": 80.0}
{"epoch": 47, "training_loss": 39.14128625392914, "training_acc": 90.0, "val_loss": 11.709186434745789, "val_acc": 72.0}
{"epoch": 48, "training_loss": 46.05809831619263, "training_acc": 84.0, "val_loss": 10.990998148918152, "val_acc": 80.0}
{"epoch": 49, "training_loss": 49.85877704620361, "training_acc": 73.0, "val_loss": 12.550924718379974, "val_acc": 80.0}
{"epoch": 50, "training_loss": 50.38554644584656, "training_acc": 87.0, "val_loss": 15.478155016899109, "val_acc": 72.0}
{"epoch": 51, "training_loss": 60.956756591796875, "training_acc": 72.0, "val_loss": 14.831215143203735, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.57672929763794, "training_acc": 72.0, "val_loss": 14.6705761551857, "val_acc": 72.0}
{"epoch": 53, "training_loss": 58.556124687194824, "training_acc": 72.0, "val_loss": 14.693588018417358, "val_acc": 72.0}
{"epoch": 54, "training_loss": 58.728447675704956, "training_acc": 72.0, "val_loss": 14.587095379829407, "val_acc": 72.0}
{"epoch": 55, "training_loss": 58.674548625946045, "training_acc": 72.0, "val_loss": 14.546579122543335, "val_acc": 72.0}
{"epoch": 56, "training_loss": 58.26293182373047, "training_acc": 72.0, "val_loss": 14.456911385059357, "val_acc": 72.0}
{"epoch": 57, "training_loss": 57.81762337684631, "training_acc": 72.0, "val_loss": 14.307014644145966, "val_acc": 72.0}
{"epoch": 58, "training_loss": 57.64202284812927, "training_acc": 72.0, "val_loss": 14.130955934524536, "val_acc": 72.0}
{"epoch": 59, "training_loss": 56.602656841278076, "training_acc": 72.0, "val_loss": 13.91129344701767, "val_acc": 72.0}
{"epoch": 60, "training_loss": 55.896384954452515, "training_acc": 72.0, "val_loss": 13.697294890880585, "val_acc": 80.0}
{"epoch": 61, "training_loss": 56.11590528488159, "training_acc": 72.0, "val_loss": 13.669812679290771, "val_acc": 68.0}
{"epoch": 62, "training_loss": 54.50579571723938, "training_acc": 72.0, "val_loss": 13.419593870639801, "val_acc": 72.0}
{"epoch": 63, "training_loss": 54.47520971298218, "training_acc": 72.0, "val_loss": 13.16104382276535, "val_acc": 76.0}
{"epoch": 64, "training_loss": 53.83222818374634, "training_acc": 72.0, "val_loss": 13.030204176902771, "val_acc": 76.0}
{"epoch": 65, "training_loss": 51.27075529098511, "training_acc": 72.0, "val_loss": 12.918877601623535, "val_acc": 72.0}
