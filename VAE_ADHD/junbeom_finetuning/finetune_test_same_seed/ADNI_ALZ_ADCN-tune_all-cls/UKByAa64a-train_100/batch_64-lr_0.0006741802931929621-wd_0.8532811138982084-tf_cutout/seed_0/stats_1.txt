"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 63.631507873535156, "training_acc": 51.0, "val_loss": 236.734938621521, "val_acc": 72.0}
{"epoch": 1, "training_loss": 578.6207849979401, "training_acc": 72.0, "val_loss": 244.50676441192627, "val_acc": 28.0}
{"epoch": 2, "training_loss": 615.8144245147705, "training_acc": 48.0, "val_loss": 21.436572074890137, "val_acc": 72.0}
{"epoch": 3, "training_loss": 73.04015254974365, "training_acc": 72.0, "val_loss": 24.633288383483887, "val_acc": 28.0}
{"epoch": 4, "training_loss": 87.7426598072052, "training_acc": 42.0, "val_loss": 18.168051540851593, "val_acc": 72.0}
{"epoch": 5, "training_loss": 66.80770993232727, "training_acc": 72.0, "val_loss": 15.309081971645355, "val_acc": 72.0}
{"epoch": 6, "training_loss": 61.640803813934326, "training_acc": 72.0, "val_loss": 15.24878740310669, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.485318183898926, "training_acc": 72.0, "val_loss": 15.486648678779602, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61.17794895172119, "training_acc": 72.0, "val_loss": 14.99866098165512, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.037495374679565, "training_acc": 72.0, "val_loss": 15.006273984909058, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.812891721725464, "training_acc": 72.0, "val_loss": 14.9030402302742, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.010801792144775, "training_acc": 72.0, "val_loss": 14.941772818565369, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.85473299026489, "training_acc": 72.0, "val_loss": 14.960673451423645, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.05440068244934, "training_acc": 72.0, "val_loss": 14.886602759361267, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.251044511795044, "training_acc": 72.0, "val_loss": 14.833080768585205, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.3968071937561, "training_acc": 72.0, "val_loss": 15.053865313529968, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.15518593788147, "training_acc": 72.0, "val_loss": 14.859426021575928, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.3036584854126, "training_acc": 72.0, "val_loss": 14.807546138763428, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.17770075798035, "training_acc": 72.0, "val_loss": 14.849917590618134, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.460447549819946, "training_acc": 72.0, "val_loss": 14.829996228218079, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.32162117958069, "training_acc": 72.0, "val_loss": 14.726093411445618, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.57311964035034, "training_acc": 72.0, "val_loss": 14.712846279144287, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.66336464881897, "training_acc": 72.0, "val_loss": 14.696164429187775, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.96237564086914, "training_acc": 72.0, "val_loss": 14.665946364402771, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.09100699424744, "training_acc": 72.0, "val_loss": 14.637139439582825, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.274524450302124, "training_acc": 72.0, "val_loss": 14.640597999095917, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.8508734703064, "training_acc": 72.0, "val_loss": 14.601148664951324, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.635486364364624, "training_acc": 72.0, "val_loss": 14.551061391830444, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.32536339759827, "training_acc": 72.0, "val_loss": 14.467158913612366, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.80353093147278, "training_acc": 72.0, "val_loss": 14.3538236618042, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.69863438606262, "training_acc": 72.0, "val_loss": 14.520004391670227, "val_acc": 68.0}
{"epoch": 31, "training_loss": 58.28971004486084, "training_acc": 72.0, "val_loss": 14.403051137924194, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.173656940460205, "training_acc": 72.0, "val_loss": 14.214447140693665, "val_acc": 72.0}
{"epoch": 33, "training_loss": 57.42786145210266, "training_acc": 72.0, "val_loss": 14.065797626972198, "val_acc": 68.0}
{"epoch": 34, "training_loss": 58.40726351737976, "training_acc": 72.0, "val_loss": 14.54513967037201, "val_acc": 64.0}
{"epoch": 35, "training_loss": 59.08750605583191, "training_acc": 72.0, "val_loss": 14.277875423431396, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.82669401168823, "training_acc": 72.0, "val_loss": 14.423379302024841, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.65126371383667, "training_acc": 72.0, "val_loss": 14.56441730260849, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.78668570518494, "training_acc": 72.0, "val_loss": 15.124006569385529, "val_acc": 52.0}
{"epoch": 39, "training_loss": 60.186336040496826, "training_acc": 72.0, "val_loss": 14.552086591720581, "val_acc": 68.0}
{"epoch": 40, "training_loss": 58.12108898162842, "training_acc": 72.0, "val_loss": 14.417222142219543, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.4022102355957, "training_acc": 72.0, "val_loss": 14.603860676288605, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.90989804267883, "training_acc": 72.0, "val_loss": 14.421285688877106, "val_acc": 72.0}
{"epoch": 43, "training_loss": 57.954978704452515, "training_acc": 72.0, "val_loss": 14.397704601287842, "val_acc": 72.0}
{"epoch": 44, "training_loss": 57.811333417892456, "training_acc": 72.0, "val_loss": 14.508043229579926, "val_acc": 76.0}
{"epoch": 45, "training_loss": 58.076308488845825, "training_acc": 72.0, "val_loss": 14.273828268051147, "val_acc": 68.0}
{"epoch": 46, "training_loss": 57.041085958480835, "training_acc": 72.0, "val_loss": 13.996675610542297, "val_acc": 72.0}
{"epoch": 47, "training_loss": 57.68229055404663, "training_acc": 72.0, "val_loss": 13.922441005706787, "val_acc": 72.0}
{"epoch": 48, "training_loss": 62.31534457206726, "training_acc": 72.0, "val_loss": 13.765324652194977, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.15047574043274, "training_acc": 72.0, "val_loss": 15.753193199634552, "val_acc": 36.0}
{"epoch": 50, "training_loss": 62.430243730545044, "training_acc": 72.0, "val_loss": 14.765197038650513, "val_acc": 60.0}
{"epoch": 51, "training_loss": 58.141342878341675, "training_acc": 72.0, "val_loss": 14.312291145324707, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.03187298774719, "training_acc": 72.0, "val_loss": 14.786618947982788, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.56026530265808, "training_acc": 72.0, "val_loss": 14.743296802043915, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.36551785469055, "training_acc": 72.0, "val_loss": 14.673690497875214, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.171284198760986, "training_acc": 72.0, "val_loss": 14.712034165859222, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.05779528617859, "training_acc": 72.0, "val_loss": 14.720004796981812, "val_acc": 72.0}
{"epoch": 57, "training_loss": 58.994568824768066, "training_acc": 72.0, "val_loss": 14.681224524974823, "val_acc": 72.0}
{"epoch": 58, "training_loss": 58.88529992103577, "training_acc": 72.0, "val_loss": 14.643679559230804, "val_acc": 72.0}
{"epoch": 59, "training_loss": 58.66906404495239, "training_acc": 72.0, "val_loss": 14.605174958705902, "val_acc": 72.0}
{"epoch": 60, "training_loss": 58.56347322463989, "training_acc": 72.0, "val_loss": 14.563044905662537, "val_acc": 72.0}
{"epoch": 61, "training_loss": 58.42675828933716, "training_acc": 72.0, "val_loss": 14.517782628536224, "val_acc": 72.0}
{"epoch": 62, "training_loss": 58.23620295524597, "training_acc": 72.0, "val_loss": 14.462967216968536, "val_acc": 72.0}
{"epoch": 63, "training_loss": 58.07745575904846, "training_acc": 72.0, "val_loss": 14.384263753890991, "val_acc": 72.0}
{"epoch": 64, "training_loss": 57.7204053401947, "training_acc": 72.0, "val_loss": 14.28954154253006, "val_acc": 72.0}
{"epoch": 65, "training_loss": 57.11384391784668, "training_acc": 72.0, "val_loss": 14.137472212314606, "val_acc": 72.0}
{"epoch": 66, "training_loss": 58.44222354888916, "training_acc": 72.0, "val_loss": 14.156311750411987, "val_acc": 72.0}
{"epoch": 67, "training_loss": 56.71981167793274, "training_acc": 72.0, "val_loss": 14.480260014533997, "val_acc": 68.0}
