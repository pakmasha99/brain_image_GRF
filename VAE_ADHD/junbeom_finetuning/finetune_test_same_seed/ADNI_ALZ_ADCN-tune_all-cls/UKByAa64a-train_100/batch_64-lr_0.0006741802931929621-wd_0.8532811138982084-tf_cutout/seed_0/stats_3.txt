"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.04832363128662, "training_acc": 67.0, "val_loss": 117.2528862953186, "val_acc": 72.0}
{"epoch": 1, "training_loss": 349.173789024353, "training_acc": 72.0, "val_loss": 29.05750870704651, "val_acc": 28.0}
{"epoch": 2, "training_loss": 100.20311856269836, "training_acc": 38.0, "val_loss": 14.981472492218018, "val_acc": 72.0}
{"epoch": 3, "training_loss": 64.21504926681519, "training_acc": 72.0, "val_loss": 28.47362458705902, "val_acc": 72.0}
{"epoch": 4, "training_loss": 94.32292938232422, "training_acc": 72.0, "val_loss": 15.640871226787567, "val_acc": 28.0}
{"epoch": 5, "training_loss": 62.69038391113281, "training_acc": 72.0, "val_loss": 15.435168147087097, "val_acc": 28.0}
{"epoch": 6, "training_loss": 61.723456621170044, "training_acc": 72.0, "val_loss": 14.910629391670227, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.51393961906433, "training_acc": 72.0, "val_loss": 14.906229078769684, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.62700581550598, "training_acc": 72.0, "val_loss": 14.800959825515747, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.39366555213928, "training_acc": 72.0, "val_loss": 14.873796701431274, "val_acc": 72.0}
{"epoch": 10, "training_loss": 61.07988095283508, "training_acc": 72.0, "val_loss": 14.922776818275452, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.696075439453125, "training_acc": 72.0, "val_loss": 15.12567549943924, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.39219284057617, "training_acc": 72.0, "val_loss": 14.917740225791931, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.5425910949707, "training_acc": 72.0, "val_loss": 14.824512600898743, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.224690437316895, "training_acc": 72.0, "val_loss": 14.868023991584778, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.487173557281494, "training_acc": 72.0, "val_loss": 14.879059791564941, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.817445516586304, "training_acc": 72.0, "val_loss": 14.8347407579422, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.32903981208801, "training_acc": 72.0, "val_loss": 14.82277512550354, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.27712607383728, "training_acc": 72.0, "val_loss": 14.786133170127869, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.073673486709595, "training_acc": 72.0, "val_loss": 14.787973463535309, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.172527551651, "training_acc": 72.0, "val_loss": 14.795640110969543, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.24178981781006, "training_acc": 72.0, "val_loss": 14.727677404880524, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.023425817489624, "training_acc": 72.0, "val_loss": 14.69750702381134, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.78255534172058, "training_acc": 72.0, "val_loss": 14.657628536224365, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.55367922782898, "training_acc": 72.0, "val_loss": 14.585980772972107, "val_acc": 72.0}
{"epoch": 25, "training_loss": 60.655768156051636, "training_acc": 72.0, "val_loss": 14.891442656517029, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.08135175704956, "training_acc": 72.0, "val_loss": 14.687690138816833, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.81034469604492, "training_acc": 72.0, "val_loss": 14.789053797721863, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.27240777015686, "training_acc": 72.0, "val_loss": 14.721065759658813, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.76685380935669, "training_acc": 72.0, "val_loss": 14.60655927658081, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.81548237800598, "training_acc": 72.0, "val_loss": 14.628897607326508, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.45228886604309, "training_acc": 72.0, "val_loss": 14.440542459487915, "val_acc": 72.0}
{"epoch": 32, "training_loss": 57.86890387535095, "training_acc": 72.0, "val_loss": 14.494289457798004, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.497668981552124, "training_acc": 72.0, "val_loss": 14.261157810688019, "val_acc": 72.0}
{"epoch": 34, "training_loss": 55.84033250808716, "training_acc": 72.0, "val_loss": 15.111207962036133, "val_acc": 72.0}
{"epoch": 35, "training_loss": 58.300701379776, "training_acc": 72.0, "val_loss": 15.208646655082703, "val_acc": 52.0}
{"epoch": 36, "training_loss": 60.42455267906189, "training_acc": 72.0, "val_loss": 14.7393599152565, "val_acc": 68.0}
{"epoch": 37, "training_loss": 59.36156439781189, "training_acc": 72.0, "val_loss": 13.962256908416748, "val_acc": 72.0}
{"epoch": 38, "training_loss": 57.19951033592224, "training_acc": 72.0, "val_loss": 14.689134061336517, "val_acc": 72.0}
{"epoch": 39, "training_loss": 57.014368295669556, "training_acc": 72.0, "val_loss": 14.42624032497406, "val_acc": 72.0}
{"epoch": 40, "training_loss": 57.908478021621704, "training_acc": 72.0, "val_loss": 13.84628415107727, "val_acc": 68.0}
{"epoch": 41, "training_loss": 56.549057483673096, "training_acc": 72.0, "val_loss": 14.544643461704254, "val_acc": 64.0}
{"epoch": 42, "training_loss": 56.484230279922485, "training_acc": 72.0, "val_loss": 13.86413723230362, "val_acc": 72.0}
{"epoch": 43, "training_loss": 56.015799045562744, "training_acc": 72.0, "val_loss": 13.609668612480164, "val_acc": 68.0}
{"epoch": 44, "training_loss": 55.435638427734375, "training_acc": 72.0, "val_loss": 14.030462503433228, "val_acc": 72.0}
{"epoch": 45, "training_loss": 53.73132371902466, "training_acc": 72.0, "val_loss": 14.944423735141754, "val_acc": 72.0}
{"epoch": 46, "training_loss": 57.94270849227905, "training_acc": 71.0, "val_loss": 13.89007568359375, "val_acc": 72.0}
{"epoch": 47, "training_loss": 53.99341940879822, "training_acc": 72.0, "val_loss": 13.716031610965729, "val_acc": 68.0}
{"epoch": 48, "training_loss": 53.88991320133209, "training_acc": 73.0, "val_loss": 13.612565398216248, "val_acc": 64.0}
{"epoch": 49, "training_loss": 54.34195828437805, "training_acc": 73.0, "val_loss": 14.111456274986267, "val_acc": 72.0}
{"epoch": 50, "training_loss": 57.74673318862915, "training_acc": 68.0, "val_loss": 13.618260622024536, "val_acc": 64.0}
{"epoch": 51, "training_loss": 56.185497999191284, "training_acc": 72.0, "val_loss": 14.087970554828644, "val_acc": 72.0}
{"epoch": 52, "training_loss": 55.85456323623657, "training_acc": 72.0, "val_loss": 14.597225189208984, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.34650802612305, "training_acc": 72.0, "val_loss": 14.568358659744263, "val_acc": 72.0}
{"epoch": 54, "training_loss": 56.66306281089783, "training_acc": 72.0, "val_loss": 13.920621573925018, "val_acc": 68.0}
{"epoch": 55, "training_loss": 54.315985321998596, "training_acc": 72.0, "val_loss": 14.480708539485931, "val_acc": 72.0}
{"epoch": 56, "training_loss": 58.748193979263306, "training_acc": 72.0, "val_loss": 14.151966571807861, "val_acc": 68.0}
{"epoch": 57, "training_loss": 56.68253755569458, "training_acc": 72.0, "val_loss": 14.069104194641113, "val_acc": 64.0}
{"epoch": 58, "training_loss": 55.40003275871277, "training_acc": 72.0, "val_loss": 14.263182878494263, "val_acc": 72.0}
{"epoch": 59, "training_loss": 54.94370687007904, "training_acc": 72.0, "val_loss": 13.476262986660004, "val_acc": 68.0}
{"epoch": 60, "training_loss": 53.51924693584442, "training_acc": 72.0, "val_loss": 14.356586337089539, "val_acc": 72.0}
{"epoch": 61, "training_loss": 55.49746251106262, "training_acc": 72.0, "val_loss": 13.862036168575287, "val_acc": 72.0}
{"epoch": 62, "training_loss": 54.25556206703186, "training_acc": 72.0, "val_loss": 15.114793181419373, "val_acc": 48.0}
{"epoch": 63, "training_loss": 57.23975110054016, "training_acc": 70.0, "val_loss": 13.466189801692963, "val_acc": 64.0}
{"epoch": 64, "training_loss": 53.134976387023926, "training_acc": 72.0, "val_loss": 14.439398050308228, "val_acc": 68.0}
{"epoch": 65, "training_loss": 55.82305431365967, "training_acc": 72.0, "val_loss": 13.496537506580353, "val_acc": 64.0}
{"epoch": 66, "training_loss": 52.820011615753174, "training_acc": 72.0, "val_loss": 13.993079960346222, "val_acc": 72.0}
{"epoch": 67, "training_loss": 53.68824076652527, "training_acc": 72.0, "val_loss": 13.595440983772278, "val_acc": 72.0}
{"epoch": 68, "training_loss": 52.85915148258209, "training_acc": 72.0, "val_loss": 13.617847859859467, "val_acc": 64.0}
{"epoch": 69, "training_loss": 53.03732705116272, "training_acc": 72.0, "val_loss": 13.7958824634552, "val_acc": 72.0}
{"epoch": 70, "training_loss": 52.10165619850159, "training_acc": 73.0, "val_loss": 14.09863531589508, "val_acc": 72.0}
{"epoch": 71, "training_loss": 52.523276567459106, "training_acc": 75.0, "val_loss": 14.037221670150757, "val_acc": 64.0}
{"epoch": 72, "training_loss": 53.15842866897583, "training_acc": 71.0, "val_loss": 14.073079824447632, "val_acc": 72.0}
{"epoch": 73, "training_loss": 53.380093812942505, "training_acc": 71.0, "val_loss": 14.08379077911377, "val_acc": 72.0}
{"epoch": 74, "training_loss": 52.03846526145935, "training_acc": 74.0, "val_loss": 14.820852875709534, "val_acc": 72.0}
{"epoch": 75, "training_loss": 53.45353555679321, "training_acc": 72.0, "val_loss": 14.279685914516449, "val_acc": 72.0}
{"epoch": 76, "training_loss": 53.03013324737549, "training_acc": 73.0, "val_loss": 14.167197048664093, "val_acc": 64.0}
{"epoch": 77, "training_loss": 50.552175760269165, "training_acc": 73.0, "val_loss": 16.420216858386993, "val_acc": 68.0}
{"epoch": 78, "training_loss": 57.36478352546692, "training_acc": 72.0, "val_loss": 15.043112635612488, "val_acc": 68.0}
{"epoch": 79, "training_loss": 55.6772723197937, "training_acc": 70.0, "val_loss": 14.007523655891418, "val_acc": 64.0}
{"epoch": 80, "training_loss": 52.52519965171814, "training_acc": 72.0, "val_loss": 14.272382855415344, "val_acc": 72.0}
{"epoch": 81, "training_loss": 54.53187608718872, "training_acc": 72.0, "val_loss": 13.923190534114838, "val_acc": 72.0}
{"epoch": 82, "training_loss": 53.30280613899231, "training_acc": 72.0, "val_loss": 14.02592808008194, "val_acc": 68.0}
