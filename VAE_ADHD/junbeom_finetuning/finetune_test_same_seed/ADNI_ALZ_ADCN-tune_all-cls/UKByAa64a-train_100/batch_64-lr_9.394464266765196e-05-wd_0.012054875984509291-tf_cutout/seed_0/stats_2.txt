"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.69293880462646, "training_acc": 44.0, "val_loss": 17.254315316677094, "val_acc": 28.0}
{"epoch": 1, "training_loss": 68.30174326896667, "training_acc": 65.0, "val_loss": 16.54568463563919, "val_acc": 28.0}
{"epoch": 2, "training_loss": 65.68918681144714, "training_acc": 72.0, "val_loss": 15.79638123512268, "val_acc": 28.0}
{"epoch": 3, "training_loss": 62.85279560089111, "training_acc": 72.0, "val_loss": 15.322884917259216, "val_acc": 56.0}
{"epoch": 4, "training_loss": 61.02669548988342, "training_acc": 72.0, "val_loss": 15.084274113178253, "val_acc": 68.0}
{"epoch": 5, "training_loss": 59.51732540130615, "training_acc": 72.0, "val_loss": 14.837752282619476, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.17420697212219, "training_acc": 72.0, "val_loss": 14.719860255718231, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.170159339904785, "training_acc": 72.0, "val_loss": 14.549550414085388, "val_acc": 72.0}
{"epoch": 8, "training_loss": 56.74339294433594, "training_acc": 72.0, "val_loss": 14.665238559246063, "val_acc": 72.0}
{"epoch": 9, "training_loss": 55.317612648010254, "training_acc": 72.0, "val_loss": 14.496442675590515, "val_acc": 72.0}
{"epoch": 10, "training_loss": 56.02644634246826, "training_acc": 72.0, "val_loss": 15.065331757068634, "val_acc": 72.0}
{"epoch": 11, "training_loss": 56.20073699951172, "training_acc": 72.0, "val_loss": 14.360645413398743, "val_acc": 64.0}
{"epoch": 12, "training_loss": 56.542407274246216, "training_acc": 72.0, "val_loss": 14.364194869995117, "val_acc": 68.0}
{"epoch": 13, "training_loss": 54.32789921760559, "training_acc": 72.0, "val_loss": 15.054570138454437, "val_acc": 72.0}
{"epoch": 14, "training_loss": 53.15618824958801, "training_acc": 72.0, "val_loss": 14.244601130485535, "val_acc": 60.0}
{"epoch": 15, "training_loss": 53.760515332221985, "training_acc": 72.0, "val_loss": 14.874373376369476, "val_acc": 68.0}
{"epoch": 16, "training_loss": 51.69335913658142, "training_acc": 72.0, "val_loss": 15.231278538703918, "val_acc": 68.0}
{"epoch": 17, "training_loss": 51.02900314331055, "training_acc": 72.0, "val_loss": 14.345812797546387, "val_acc": 56.0}
{"epoch": 18, "training_loss": 54.97822093963623, "training_acc": 72.0, "val_loss": 15.269246697425842, "val_acc": 68.0}
{"epoch": 19, "training_loss": 51.806010246276855, "training_acc": 72.0, "val_loss": 16.0501629114151, "val_acc": 68.0}
{"epoch": 20, "training_loss": 53.10811972618103, "training_acc": 72.0, "val_loss": 14.31347280740738, "val_acc": 56.0}
{"epoch": 21, "training_loss": 52.74443531036377, "training_acc": 72.0, "val_loss": 14.835987985134125, "val_acc": 64.0}
{"epoch": 22, "training_loss": 48.2072719335556, "training_acc": 72.0, "val_loss": 15.587493777275085, "val_acc": 68.0}
{"epoch": 23, "training_loss": 48.98392117023468, "training_acc": 73.0, "val_loss": 15.086936950683594, "val_acc": 68.0}
{"epoch": 24, "training_loss": 46.851067900657654, "training_acc": 77.0, "val_loss": 15.457475185394287, "val_acc": 68.0}
{"epoch": 25, "training_loss": 50.24408292770386, "training_acc": 75.0, "val_loss": 14.934298396110535, "val_acc": 68.0}
{"epoch": 26, "training_loss": 48.458247423172, "training_acc": 80.0, "val_loss": 15.262345969676971, "val_acc": 68.0}
{"epoch": 27, "training_loss": 45.939892053604126, "training_acc": 78.0, "val_loss": 15.997953712940216, "val_acc": 64.0}
{"epoch": 28, "training_loss": 49.450369358062744, "training_acc": 77.0, "val_loss": 15.170350670814514, "val_acc": 68.0}
{"epoch": 29, "training_loss": 46.888609170913696, "training_acc": 80.0, "val_loss": 15.706607699394226, "val_acc": 68.0}
{"epoch": 30, "training_loss": 43.534828782081604, "training_acc": 85.0, "val_loss": 15.030831098556519, "val_acc": 52.0}
{"epoch": 31, "training_loss": 48.359649896621704, "training_acc": 83.0, "val_loss": 16.644583642482758, "val_acc": 64.0}
{"epoch": 32, "training_loss": 45.42069208621979, "training_acc": 80.0, "val_loss": 15.964092314243317, "val_acc": 68.0}
{"epoch": 33, "training_loss": 42.23422014713287, "training_acc": 84.0, "val_loss": 15.487924218177795, "val_acc": 68.0}
