"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.3174660205841, "training_acc": 51.0, "val_loss": 763.3050441741943, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1877.5906822681427, "training_acc": 72.0, "val_loss": 313.79497051239014, "val_acc": 28.0}
{"epoch": 2, "training_loss": 770.2447938919067, "training_acc": 48.0, "val_loss": 21.67947292327881, "val_acc": 72.0}
{"epoch": 3, "training_loss": 75.21164464950562, "training_acc": 72.0, "val_loss": 18.82013827562332, "val_acc": 28.0}
{"epoch": 4, "training_loss": 70.76725125312805, "training_acc": 42.0, "val_loss": 18.454785645008087, "val_acc": 72.0}
{"epoch": 5, "training_loss": 67.22495818138123, "training_acc": 72.0, "val_loss": 16.30072146654129, "val_acc": 28.0}
{"epoch": 6, "training_loss": 64.98106050491333, "training_acc": 72.0, "val_loss": 15.027761459350586, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.82849645614624, "training_acc": 72.0, "val_loss": 15.653987228870392, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61.87197661399841, "training_acc": 72.0, "val_loss": 15.07548838853836, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.47474026679993, "training_acc": 72.0, "val_loss": 15.015795826911926, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.69187259674072, "training_acc": 72.0, "val_loss": 15.258444845676422, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.87286424636841, "training_acc": 72.0, "val_loss": 14.942336082458496, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.37912178039551, "training_acc": 72.0, "val_loss": 15.371513366699219, "val_acc": 48.0}
{"epoch": 13, "training_loss": 61.51311159133911, "training_acc": 72.0, "val_loss": 15.133155882358551, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.866533279418945, "training_acc": 72.0, "val_loss": 14.914703369140625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.57983136177063, "training_acc": 72.0, "val_loss": 15.282830595970154, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.80420637130737, "training_acc": 72.0, "val_loss": 14.957690238952637, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.52391076087952, "training_acc": 72.0, "val_loss": 14.90873247385025, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.51323676109314, "training_acc": 72.0, "val_loss": 14.967438578605652, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.84788203239441, "training_acc": 72.0, "val_loss": 14.925377070903778, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.5996470451355, "training_acc": 72.0, "val_loss": 14.8443803191185, "val_acc": 72.0}
{"epoch": 21, "training_loss": 60.05505299568176, "training_acc": 72.0, "val_loss": 14.87162709236145, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.125587940216064, "training_acc": 72.0, "val_loss": 14.844240248203278, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.354697465896606, "training_acc": 72.0, "val_loss": 14.834338426589966, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.5212482213974, "training_acc": 72.0, "val_loss": 14.823772013187408, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.634058713912964, "training_acc": 72.0, "val_loss": 14.837396144866943, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.335750102996826, "training_acc": 72.0, "val_loss": 14.816536009311676, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.263903856277466, "training_acc": 72.0, "val_loss": 14.80381041765213, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.3194305896759, "training_acc": 72.0, "val_loss": 14.795415103435516, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.218180418014526, "training_acc": 72.0, "val_loss": 14.78462815284729, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.33282017707825, "training_acc": 72.0, "val_loss": 14.772960543632507, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.18797969818115, "training_acc": 72.0, "val_loss": 14.771601557731628, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.164947271347046, "training_acc": 72.0, "val_loss": 14.744344353675842, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.06668996810913, "training_acc": 72.0, "val_loss": 14.720828831195831, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.141956090927124, "training_acc": 72.0, "val_loss": 14.696073532104492, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.059139251708984, "training_acc": 72.0, "val_loss": 14.719685912132263, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.01082944869995, "training_acc": 72.0, "val_loss": 14.649124443531036, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.19569492340088, "training_acc": 72.0, "val_loss": 14.705809950828552, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.820470094680786, "training_acc": 72.0, "val_loss": 14.797568321228027, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.11776375770569, "training_acc": 72.0, "val_loss": 14.588867127895355, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.57159161567688, "training_acc": 72.0, "val_loss": 14.49563205242157, "val_acc": 72.0}
{"epoch": 41, "training_loss": 58.24478483200073, "training_acc": 72.0, "val_loss": 14.46959674358368, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.31592679023743, "training_acc": 72.0, "val_loss": 14.678111672401428, "val_acc": 68.0}
{"epoch": 43, "training_loss": 59.56798005104065, "training_acc": 72.0, "val_loss": 14.957325160503387, "val_acc": 64.0}
{"epoch": 44, "training_loss": 59.579254388809204, "training_acc": 72.0, "val_loss": 14.463023841381073, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.02247738838196, "training_acc": 72.0, "val_loss": 14.60886150598526, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.72860264778137, "training_acc": 72.0, "val_loss": 14.629468321800232, "val_acc": 72.0}
{"epoch": 47, "training_loss": 60.11655044555664, "training_acc": 72.0, "val_loss": 14.688500761985779, "val_acc": 72.0}
{"epoch": 48, "training_loss": 60.935940980911255, "training_acc": 72.0, "val_loss": 14.571772515773773, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.61769413948059, "training_acc": 72.0, "val_loss": 14.627580344676971, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.727508544921875, "training_acc": 72.0, "val_loss": 14.594101905822754, "val_acc": 72.0}
{"epoch": 51, "training_loss": 58.394742250442505, "training_acc": 72.0, "val_loss": 14.499805867671967, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.29698824882507, "training_acc": 72.0, "val_loss": 14.433625340461731, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.721229791641235, "training_acc": 72.0, "val_loss": 14.655117690563202, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.19531774520874, "training_acc": 72.0, "val_loss": 14.533032476902008, "val_acc": 68.0}
{"epoch": 55, "training_loss": 57.39786171913147, "training_acc": 72.0, "val_loss": 14.672738313674927, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.64026093482971, "training_acc": 72.0, "val_loss": 14.7683784365654, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.089702129364014, "training_acc": 72.0, "val_loss": 14.378441870212555, "val_acc": 72.0}
{"epoch": 58, "training_loss": 57.90794491767883, "training_acc": 72.0, "val_loss": 14.994749426841736, "val_acc": 60.0}
{"epoch": 59, "training_loss": 59.55019021034241, "training_acc": 72.0, "val_loss": 14.331814646720886, "val_acc": 68.0}
{"epoch": 60, "training_loss": 57.676305532455444, "training_acc": 72.0, "val_loss": 14.40475583076477, "val_acc": 72.0}
{"epoch": 61, "training_loss": 58.31293344497681, "training_acc": 72.0, "val_loss": 14.131389558315277, "val_acc": 72.0}
{"epoch": 62, "training_loss": 56.92223405838013, "training_acc": 72.0, "val_loss": 14.074838161468506, "val_acc": 68.0}
{"epoch": 63, "training_loss": 56.05276417732239, "training_acc": 72.0, "val_loss": 13.854125142097473, "val_acc": 72.0}
{"epoch": 64, "training_loss": 57.95662045478821, "training_acc": 72.0, "val_loss": 13.403043150901794, "val_acc": 76.0}
{"epoch": 65, "training_loss": 54.9234504699707, "training_acc": 72.0, "val_loss": 14.18418437242508, "val_acc": 68.0}
{"epoch": 66, "training_loss": 55.19534730911255, "training_acc": 72.0, "val_loss": 17.57585257291794, "val_acc": 28.0}
{"epoch": 67, "training_loss": 70.76675534248352, "training_acc": 40.0, "val_loss": 16.066084802150726, "val_acc": 28.0}
{"epoch": 68, "training_loss": 69.90437650680542, "training_acc": 72.0, "val_loss": 16.292496025562286, "val_acc": 28.0}
{"epoch": 69, "training_loss": 65.50275230407715, "training_acc": 72.0, "val_loss": 15.640135109424591, "val_acc": 32.0}
{"epoch": 70, "training_loss": 60.951191663742065, "training_acc": 72.0, "val_loss": 15.464414656162262, "val_acc": 72.0}
{"epoch": 71, "training_loss": 61.69903922080994, "training_acc": 72.0, "val_loss": 15.45601636171341, "val_acc": 72.0}
{"epoch": 72, "training_loss": 62.92252779006958, "training_acc": 72.0, "val_loss": 15.151801705360413, "val_acc": 72.0}
{"epoch": 73, "training_loss": 60.62717795372009, "training_acc": 72.0, "val_loss": 15.081019699573517, "val_acc": 72.0}
{"epoch": 74, "training_loss": 60.2953155040741, "training_acc": 72.0, "val_loss": 15.018421411514282, "val_acc": 72.0}
{"epoch": 75, "training_loss": 59.83887839317322, "training_acc": 72.0, "val_loss": 15.134678781032562, "val_acc": 72.0}
{"epoch": 76, "training_loss": 60.56145524978638, "training_acc": 72.0, "val_loss": 15.110740065574646, "val_acc": 72.0}
{"epoch": 77, "training_loss": 59.95812439918518, "training_acc": 72.0, "val_loss": 14.973500370979309, "val_acc": 72.0}
{"epoch": 78, "training_loss": 59.976643323898315, "training_acc": 72.0, "val_loss": 15.03174901008606, "val_acc": 72.0}
{"epoch": 79, "training_loss": 60.23299479484558, "training_acc": 72.0, "val_loss": 14.977587759494781, "val_acc": 72.0}
{"epoch": 80, "training_loss": 60.054184913635254, "training_acc": 72.0, "val_loss": 14.911341667175293, "val_acc": 72.0}
{"epoch": 81, "training_loss": 59.62791705131531, "training_acc": 72.0, "val_loss": 14.916539192199707, "val_acc": 72.0}
{"epoch": 82, "training_loss": 59.699334383010864, "training_acc": 72.0, "val_loss": 14.888252317905426, "val_acc": 72.0}
{"epoch": 83, "training_loss": 59.50740170478821, "training_acc": 72.0, "val_loss": 14.853504300117493, "val_acc": 72.0}
