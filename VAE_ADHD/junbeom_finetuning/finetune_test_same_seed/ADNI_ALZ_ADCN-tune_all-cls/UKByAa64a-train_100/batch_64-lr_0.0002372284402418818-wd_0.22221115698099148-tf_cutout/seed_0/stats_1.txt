"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 63.56779599189758, "training_acc": 72.0, "val_loss": 15.44833779335022, "val_acc": 28.0}
{"epoch": 1, "training_loss": 61.75573444366455, "training_acc": 72.0, "val_loss": 15.062430500984192, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.64530539512634, "training_acc": 72.0, "val_loss": 14.858579635620117, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.57756948471069, "training_acc": 72.0, "val_loss": 14.869970083236694, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.65757346153259, "training_acc": 72.0, "val_loss": 14.893098175525665, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.5571346282959, "training_acc": 72.0, "val_loss": 14.885251224040985, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.54085183143616, "training_acc": 72.0, "val_loss": 14.833000302314758, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.300663232803345, "training_acc": 72.0, "val_loss": 14.817500114440918, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.27920866012573, "training_acc": 72.0, "val_loss": 14.816237986087799, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.28572154045105, "training_acc": 72.0, "val_loss": 14.811950922012329, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.208979845047, "training_acc": 72.0, "val_loss": 14.799605309963226, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.532236099243164, "training_acc": 72.0, "val_loss": 14.81081247329712, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.74731981754303, "training_acc": 72.0, "val_loss": 14.80272114276886, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.24470067024231, "training_acc": 72.0, "val_loss": 14.796297252178192, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.45145404338837, "training_acc": 72.0, "val_loss": 14.786164462566376, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.53648042678833, "training_acc": 72.0, "val_loss": 14.805983006954193, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.20951557159424, "training_acc": 72.0, "val_loss": 14.759555459022522, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.00412034988403, "training_acc": 72.0, "val_loss": 14.687764644622803, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.74086904525757, "training_acc": 72.0, "val_loss": 14.661267399787903, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.67520523071289, "training_acc": 72.0, "val_loss": 14.71695750951767, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.51538896560669, "training_acc": 72.0, "val_loss": 14.769889414310455, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.29471278190613, "training_acc": 72.0, "val_loss": 14.815783500671387, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.25167512893677, "training_acc": 72.0, "val_loss": 14.792653918266296, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.180763244628906, "training_acc": 72.0, "val_loss": 14.761781692504883, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.12618970870972, "training_acc": 72.0, "val_loss": 14.73093330860138, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.988099098205566, "training_acc": 72.0, "val_loss": 14.672385156154633, "val_acc": 72.0}
{"epoch": 26, "training_loss": 58.808940410614014, "training_acc": 72.0, "val_loss": 14.612485468387604, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.29576134681702, "training_acc": 72.0, "val_loss": 14.805099368095398, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.7027702331543, "training_acc": 72.0, "val_loss": 14.868977665901184, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.49872422218323, "training_acc": 72.0, "val_loss": 14.840099215507507, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.342434883117676, "training_acc": 72.0, "val_loss": 14.821791648864746, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.283862590789795, "training_acc": 72.0, "val_loss": 14.823772013187408, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.30874824523926, "training_acc": 72.0, "val_loss": 14.820101857185364, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.29355716705322, "training_acc": 72.0, "val_loss": 14.815360307693481, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.268285036087036, "training_acc": 72.0, "val_loss": 14.82323557138443, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.327874422073364, "training_acc": 72.0, "val_loss": 14.828863739967346, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.347846269607544, "training_acc": 72.0, "val_loss": 14.832822978496552, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.83206558227539, "training_acc": 72.0, "val_loss": 14.82292264699936, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.51340198516846, "training_acc": 72.0, "val_loss": 14.84910398721695, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.42930746078491, "training_acc": 72.0, "val_loss": 14.827722311019897, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.39942669868469, "training_acc": 72.0, "val_loss": 14.823344349861145, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.30920052528381, "training_acc": 72.0, "val_loss": 14.821839332580566, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.48268985748291, "training_acc": 72.0, "val_loss": 14.822438359260559, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.2634220123291, "training_acc": 72.0, "val_loss": 14.822214841842651, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.43573355674744, "training_acc": 72.0, "val_loss": 14.836953580379486, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.43014478683472, "training_acc": 72.0, "val_loss": 14.82628732919693, "val_acc": 72.0}
