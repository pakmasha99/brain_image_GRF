"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 70.69318127632141, "training_acc": 39.0, "val_loss": 16.536487638950348, "val_acc": 28.0}
{"epoch": 1, "training_loss": 65.83555960655212, "training_acc": 72.0, "val_loss": 15.558071434497833, "val_acc": 28.0}
{"epoch": 2, "training_loss": 61.3328378200531, "training_acc": 72.0, "val_loss": 14.842015504837036, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.376710176467896, "training_acc": 72.0, "val_loss": 14.788739383220673, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.457889795303345, "training_acc": 72.0, "val_loss": 14.787520468235016, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.178959131240845, "training_acc": 72.0, "val_loss": 14.797767996788025, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.29647183418274, "training_acc": 72.0, "val_loss": 14.792655408382416, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.34269392490387, "training_acc": 72.0, "val_loss": 14.85384851694107, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.14456343650818, "training_acc": 72.0, "val_loss": 14.920134842395782, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.559234619140625, "training_acc": 72.0, "val_loss": 14.81131762266159, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.30100750923157, "training_acc": 72.0, "val_loss": 14.795282483100891, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.18161487579346, "training_acc": 72.0, "val_loss": 14.78801965713501, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.12267780303955, "training_acc": 72.0, "val_loss": 14.781706035137177, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.10606384277344, "training_acc": 72.0, "val_loss": 14.76621925830841, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.116398334503174, "training_acc": 72.0, "val_loss": 14.750753343105316, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.09094738960266, "training_acc": 72.0, "val_loss": 14.712639153003693, "val_acc": 72.0}
{"epoch": 16, "training_loss": 58.80066394805908, "training_acc": 72.0, "val_loss": 14.7199347615242, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.87467885017395, "training_acc": 72.0, "val_loss": 14.565937221050262, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.37393665313721, "training_acc": 72.0, "val_loss": 14.800333976745605, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.97536516189575, "training_acc": 72.0, "val_loss": 14.49054628610611, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.070783615112305, "training_acc": 72.0, "val_loss": 14.750221371650696, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.75133800506592, "training_acc": 72.0, "val_loss": 14.53125923871994, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.27100467681885, "training_acc": 72.0, "val_loss": 14.202356338500977, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.62564182281494, "training_acc": 72.0, "val_loss": 14.221428334712982, "val_acc": 72.0}
{"epoch": 24, "training_loss": 57.976271867752075, "training_acc": 72.0, "val_loss": 14.91737812757492, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.52537250518799, "training_acc": 72.0, "val_loss": 14.827178418636322, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.196948289871216, "training_acc": 72.0, "val_loss": 14.86494094133377, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.6451358795166, "training_acc": 72.0, "val_loss": 14.865012466907501, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.565855264663696, "training_acc": 72.0, "val_loss": 14.825817942619324, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.27703905105591, "training_acc": 72.0, "val_loss": 14.826856553554535, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.407923221588135, "training_acc": 72.0, "val_loss": 14.82650637626648, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.28109097480774, "training_acc": 72.0, "val_loss": 14.842815697193146, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.35058307647705, "training_acc": 72.0, "val_loss": 14.832048118114471, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.30677103996277, "training_acc": 72.0, "val_loss": 14.82151448726654, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.28413534164429, "training_acc": 72.0, "val_loss": 14.82175886631012, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.35603308677673, "training_acc": 72.0, "val_loss": 14.826858043670654, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.44315767288208, "training_acc": 72.0, "val_loss": 14.836691319942474, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.2632737159729, "training_acc": 72.0, "val_loss": 14.815816283226013, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.1900794506073, "training_acc": 72.0, "val_loss": 14.834991097450256, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.26089406013489, "training_acc": 72.0, "val_loss": 14.87157791852951, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.426849365234375, "training_acc": 72.0, "val_loss": 14.863575994968414, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.54706335067749, "training_acc": 72.0, "val_loss": 14.826920628547668, "val_acc": 72.0}
