"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 180.17528676986694, "training_acc": 63.0, "val_loss": 45.89203202724457, "val_acc": 72.0}
{"epoch": 1, "training_loss": 179.34173369407654, "training_acc": 72.33333333333333, "val_loss": 44.47732377052307, "val_acc": 72.0}
{"epoch": 2, "training_loss": 177.77703380584717, "training_acc": 72.33333333333333, "val_loss": 44.708384454250336, "val_acc": 72.0}
{"epoch": 3, "training_loss": 177.5701940059662, "training_acc": 72.33333333333333, "val_loss": 44.58773136138916, "val_acc": 72.0}
{"epoch": 4, "training_loss": 178.12087225914001, "training_acc": 72.33333333333333, "val_loss": 44.66101384162903, "val_acc": 72.0}
{"epoch": 5, "training_loss": 177.69277548789978, "training_acc": 72.33333333333333, "val_loss": 44.47744035720825, "val_acc": 72.0}
{"epoch": 6, "training_loss": 180.45922875404358, "training_acc": 72.33333333333333, "val_loss": 44.4893159866333, "val_acc": 72.0}
{"epoch": 7, "training_loss": 180.40750217437744, "training_acc": 72.33333333333333, "val_loss": 44.47302454710007, "val_acc": 72.0}
{"epoch": 8, "training_loss": 182.70405173301697, "training_acc": 72.33333333333333, "val_loss": 44.89400541782379, "val_acc": 72.0}
{"epoch": 9, "training_loss": 180.53265404701233, "training_acc": 72.33333333333333, "val_loss": 44.7915421128273, "val_acc": 72.0}
{"epoch": 10, "training_loss": 177.62177538871765, "training_acc": 72.33333333333333, "val_loss": 44.807577073574066, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.52976417541504, "training_acc": 72.33333333333333, "val_loss": 44.49018633365631, "val_acc": 72.0}
{"epoch": 12, "training_loss": 179.7707269191742, "training_acc": 72.33333333333333, "val_loss": 44.48211967945099, "val_acc": 72.0}
{"epoch": 13, "training_loss": 180.15570449829102, "training_acc": 72.33333333333333, "val_loss": 44.714928567409515, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.70222330093384, "training_acc": 72.33333333333333, "val_loss": 45.07707926630974, "val_acc": 72.0}
{"epoch": 15, "training_loss": 178.51879119873047, "training_acc": 72.33333333333333, "val_loss": 44.479818284511566, "val_acc": 72.0}
{"epoch": 16, "training_loss": 181.46639442443848, "training_acc": 72.33333333333333, "val_loss": 44.49006575345993, "val_acc": 72.0}
{"epoch": 17, "training_loss": 176.5341296195984, "training_acc": 72.33333333333333, "val_loss": 44.89787310361862, "val_acc": 72.0}
{"epoch": 18, "training_loss": 178.36053681373596, "training_acc": 72.33333333333333, "val_loss": 44.50144189596176, "val_acc": 72.0}
{"epoch": 19, "training_loss": 176.55751729011536, "training_acc": 72.33333333333333, "val_loss": 44.66391217708588, "val_acc": 72.0}
{"epoch": 20, "training_loss": 178.3020212650299, "training_acc": 72.33333333333333, "val_loss": 44.474002957344055, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.9578149318695, "training_acc": 72.33333333333333, "val_loss": 44.4716522693634, "val_acc": 72.0}
{"epoch": 22, "training_loss": 176.97098684310913, "training_acc": 72.33333333333333, "val_loss": 44.48146265745163, "val_acc": 72.0}
{"epoch": 23, "training_loss": 177.3125936985016, "training_acc": 72.33333333333333, "val_loss": 44.487385869026184, "val_acc": 72.0}
{"epoch": 24, "training_loss": 178.00952100753784, "training_acc": 72.33333333333333, "val_loss": 44.49597007036209, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.3179965019226, "training_acc": 72.33333333333333, "val_loss": 44.47541919350624, "val_acc": 72.0}
{"epoch": 26, "training_loss": 177.5569305419922, "training_acc": 72.33333333333333, "val_loss": 44.47339004278183, "val_acc": 72.0}
{"epoch": 27, "training_loss": 177.30660200119019, "training_acc": 72.33333333333333, "val_loss": 44.47160458564758, "val_acc": 72.0}
{"epoch": 28, "training_loss": 177.51016974449158, "training_acc": 72.33333333333333, "val_loss": 44.47191160917282, "val_acc": 72.0}
{"epoch": 29, "training_loss": 177.8073012828827, "training_acc": 72.33333333333333, "val_loss": 44.53549802303314, "val_acc": 72.0}
{"epoch": 30, "training_loss": 177.16566443443298, "training_acc": 72.33333333333333, "val_loss": 44.59163770079613, "val_acc": 72.0}
{"epoch": 31, "training_loss": 178.31107711791992, "training_acc": 72.33333333333333, "val_loss": 44.56720185279846, "val_acc": 72.0}
{"epoch": 32, "training_loss": 177.9223756790161, "training_acc": 72.33333333333333, "val_loss": 44.479489386081696, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.03311252593994, "training_acc": 72.33333333333333, "val_loss": 44.51117938756943, "val_acc": 72.0}
{"epoch": 34, "training_loss": 177.37923979759216, "training_acc": 72.33333333333333, "val_loss": 44.47161704301834, "val_acc": 72.0}
{"epoch": 35, "training_loss": 177.51925325393677, "training_acc": 72.33333333333333, "val_loss": 44.58376896381378, "val_acc": 72.0}
{"epoch": 36, "training_loss": 177.63734126091003, "training_acc": 72.33333333333333, "val_loss": 44.68076425790787, "val_acc": 72.0}
{"epoch": 37, "training_loss": 177.5219612121582, "training_acc": 72.33333333333333, "val_loss": 44.47518336772919, "val_acc": 72.0}
{"epoch": 38, "training_loss": 179.94744420051575, "training_acc": 72.33333333333333, "val_loss": 44.61119508743286, "val_acc": 72.0}
{"epoch": 39, "training_loss": 179.0869219303131, "training_acc": 72.33333333333333, "val_loss": 45.10784912109375, "val_acc": 72.0}
{"epoch": 40, "training_loss": 177.33397364616394, "training_acc": 72.33333333333333, "val_loss": 44.64232221245766, "val_acc": 72.0}
{"epoch": 41, "training_loss": 178.3234827518463, "training_acc": 72.33333333333333, "val_loss": 44.52086025476456, "val_acc": 72.0}
{"epoch": 42, "training_loss": 177.52493500709534, "training_acc": 72.33333333333333, "val_loss": 44.94531470537186, "val_acc": 72.0}
{"epoch": 43, "training_loss": 177.71493649482727, "training_acc": 72.33333333333333, "val_loss": 44.53984922170639, "val_acc": 72.0}
{"epoch": 44, "training_loss": 178.88560891151428, "training_acc": 72.33333333333333, "val_loss": 44.471639811992645, "val_acc": 72.0}
{"epoch": 45, "training_loss": 179.46838855743408, "training_acc": 72.33333333333333, "val_loss": 44.48383563756943, "val_acc": 72.0}
{"epoch": 46, "training_loss": 176.19227051734924, "training_acc": 72.33333333333333, "val_loss": 44.89077574014664, "val_acc": 72.0}
