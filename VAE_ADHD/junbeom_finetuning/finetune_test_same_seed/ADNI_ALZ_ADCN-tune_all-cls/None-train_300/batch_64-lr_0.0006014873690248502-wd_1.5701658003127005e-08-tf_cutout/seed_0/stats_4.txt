"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 187.37458062171936, "training_acc": 64.33333333333333, "val_loss": 44.465630531311035, "val_acc": 72.0}
{"epoch": 1, "training_loss": 180.86719155311584, "training_acc": 72.33333333333333, "val_loss": 45.31005948781967, "val_acc": 72.0}
{"epoch": 2, "training_loss": 179.67138123512268, "training_acc": 72.33333333333333, "val_loss": 44.497679233551025, "val_acc": 72.0}
{"epoch": 3, "training_loss": 177.6238534450531, "training_acc": 72.33333333333333, "val_loss": 44.46698722243309, "val_acc": 72.0}
{"epoch": 4, "training_loss": 178.31734466552734, "training_acc": 72.33333333333333, "val_loss": 44.49079942703247, "val_acc": 72.0}
{"epoch": 5, "training_loss": 177.58124136924744, "training_acc": 72.33333333333333, "val_loss": 44.569811165332794, "val_acc": 72.0}
{"epoch": 6, "training_loss": 177.5024344921112, "training_acc": 72.33333333333333, "val_loss": 44.473410189151764, "val_acc": 72.0}
{"epoch": 7, "training_loss": 177.26909494400024, "training_acc": 72.33333333333333, "val_loss": 44.493131160736084, "val_acc": 72.0}
{"epoch": 8, "training_loss": 177.2408950328827, "training_acc": 72.33333333333333, "val_loss": 44.466458678245544, "val_acc": 72.0}
{"epoch": 9, "training_loss": 177.63829469680786, "training_acc": 72.33333333333333, "val_loss": 44.51254087686539, "val_acc": 72.0}
{"epoch": 10, "training_loss": 177.45394015312195, "training_acc": 72.33333333333333, "val_loss": 44.49392646551132, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.30212569236755, "training_acc": 72.33333333333333, "val_loss": 44.493098348379135, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.09647345542908, "training_acc": 72.33333333333333, "val_loss": 44.464994579553604, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.01466059684753, "training_acc": 72.33333333333333, "val_loss": 44.46396213769913, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.93063926696777, "training_acc": 72.33333333333333, "val_loss": 44.46417918801308, "val_acc": 72.0}
{"epoch": 15, "training_loss": 176.9256567955017, "training_acc": 72.33333333333333, "val_loss": 44.55955612659454, "val_acc": 72.0}
{"epoch": 16, "training_loss": 177.9421603679657, "training_acc": 72.33333333333333, "val_loss": 44.47719568014145, "val_acc": 72.0}
{"epoch": 17, "training_loss": 177.12644696235657, "training_acc": 72.33333333333333, "val_loss": 44.46019107103348, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.95323157310486, "training_acc": 72.33333333333333, "val_loss": 44.45766639709473, "val_acc": 72.0}
{"epoch": 19, "training_loss": 178.23069024085999, "training_acc": 72.33333333333333, "val_loss": 44.47653782367706, "val_acc": 72.0}
{"epoch": 20, "training_loss": 176.61837720870972, "training_acc": 72.33333333333333, "val_loss": 44.59963655471802, "val_acc": 72.0}
{"epoch": 21, "training_loss": 179.08889269828796, "training_acc": 72.33333333333333, "val_loss": 44.61745339632034, "val_acc": 72.0}
{"epoch": 22, "training_loss": 176.8168728351593, "training_acc": 72.33333333333333, "val_loss": 44.571818828582764, "val_acc": 72.0}
{"epoch": 23, "training_loss": 177.91487908363342, "training_acc": 72.33333333333333, "val_loss": 44.48178970813751, "val_acc": 72.0}
{"epoch": 24, "training_loss": 176.99055886268616, "training_acc": 72.33333333333333, "val_loss": 44.47321796417236, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.4161114692688, "training_acc": 72.33333333333333, "val_loss": 44.45628893375397, "val_acc": 72.0}
{"epoch": 26, "training_loss": 176.97449684143066, "training_acc": 72.33333333333333, "val_loss": 44.46650558710098, "val_acc": 72.0}
{"epoch": 27, "training_loss": 177.63379323482513, "training_acc": 72.33333333333333, "val_loss": 44.45477116107941, "val_acc": 72.0}
{"epoch": 28, "training_loss": 177.6737880706787, "training_acc": 72.33333333333333, "val_loss": 44.66443741321564, "val_acc": 72.0}
{"epoch": 29, "training_loss": 180.80167055130005, "training_acc": 72.33333333333333, "val_loss": 44.52111196517944, "val_acc": 72.0}
{"epoch": 30, "training_loss": 177.09835004806519, "training_acc": 72.33333333333333, "val_loss": 44.576605916023254, "val_acc": 72.0}
{"epoch": 31, "training_loss": 177.42209434509277, "training_acc": 72.33333333333333, "val_loss": 44.54225358366966, "val_acc": 72.0}
{"epoch": 32, "training_loss": 177.16222858428955, "training_acc": 72.33333333333333, "val_loss": 44.47528672218323, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.09082174301147, "training_acc": 72.33333333333333, "val_loss": 44.48949861526489, "val_acc": 72.0}
{"epoch": 34, "training_loss": 177.16176772117615, "training_acc": 72.33333333333333, "val_loss": 44.470678091049194, "val_acc": 72.0}
{"epoch": 35, "training_loss": 177.49050164222717, "training_acc": 72.33333333333333, "val_loss": 44.50315001606941, "val_acc": 72.0}
{"epoch": 36, "training_loss": 177.25830340385437, "training_acc": 72.33333333333333, "val_loss": 44.47448843717575, "val_acc": 72.0}
{"epoch": 37, "training_loss": 177.3101863861084, "training_acc": 72.33333333333333, "val_loss": 44.513938426971436, "val_acc": 72.0}
{"epoch": 38, "training_loss": 177.4980924129486, "training_acc": 72.33333333333333, "val_loss": 44.525249898433685, "val_acc": 72.0}
{"epoch": 39, "training_loss": 177.31990766525269, "training_acc": 72.33333333333333, "val_loss": 44.473035752773285, "val_acc": 72.0}
{"epoch": 40, "training_loss": 177.16764855384827, "training_acc": 72.33333333333333, "val_loss": 44.46705478429794, "val_acc": 72.0}
{"epoch": 41, "training_loss": 178.1136507987976, "training_acc": 72.33333333333333, "val_loss": 44.50386470556259, "val_acc": 72.0}
{"epoch": 42, "training_loss": 177.47727942466736, "training_acc": 72.33333333333333, "val_loss": 44.56435978412628, "val_acc": 72.0}
{"epoch": 43, "training_loss": 177.7392599582672, "training_acc": 72.33333333333333, "val_loss": 44.52612882852554, "val_acc": 72.0}
{"epoch": 44, "training_loss": 177.14830493927002, "training_acc": 72.33333333333333, "val_loss": 44.47913986444473, "val_acc": 72.0}
{"epoch": 45, "training_loss": 177.17329859733582, "training_acc": 72.33333333333333, "val_loss": 44.469276666641235, "val_acc": 72.0}
{"epoch": 46, "training_loss": 177.04013204574585, "training_acc": 72.33333333333333, "val_loss": 44.48488998413086, "val_acc": 72.0}
