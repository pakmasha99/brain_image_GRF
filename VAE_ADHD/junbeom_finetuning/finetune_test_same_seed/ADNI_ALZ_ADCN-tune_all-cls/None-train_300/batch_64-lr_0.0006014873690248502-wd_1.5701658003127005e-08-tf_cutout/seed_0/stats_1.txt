"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 177.93520414829254, "training_acc": 72.33333333333333, "val_loss": 44.945718824863434, "val_acc": 72.0}
{"epoch": 1, "training_loss": 179.5219600200653, "training_acc": 72.33333333333333, "val_loss": 44.73029375076294, "val_acc": 72.0}
{"epoch": 2, "training_loss": 177.80399131774902, "training_acc": 72.33333333333333, "val_loss": 44.47999256849289, "val_acc": 72.0}
{"epoch": 3, "training_loss": 178.4429154396057, "training_acc": 72.33333333333333, "val_loss": 44.524218291044235, "val_acc": 72.0}
{"epoch": 4, "training_loss": 177.51242113113403, "training_acc": 72.33333333333333, "val_loss": 44.62871301174164, "val_acc": 72.0}
{"epoch": 5, "training_loss": 178.27950048446655, "training_acc": 72.33333333333333, "val_loss": 44.48340916633606, "val_acc": 72.0}
{"epoch": 6, "training_loss": 177.34245896339417, "training_acc": 72.33333333333333, "val_loss": 44.61210086941719, "val_acc": 72.0}
{"epoch": 7, "training_loss": 177.01662588119507, "training_acc": 72.33333333333333, "val_loss": 44.51380008459091, "val_acc": 72.0}
{"epoch": 8, "training_loss": 177.46247625350952, "training_acc": 72.33333333333333, "val_loss": 44.47334510087967, "val_acc": 72.0}
{"epoch": 9, "training_loss": 177.40270805358887, "training_acc": 72.33333333333333, "val_loss": 44.56555449962616, "val_acc": 72.0}
{"epoch": 10, "training_loss": 178.13689398765564, "training_acc": 72.33333333333333, "val_loss": 44.47197049856186, "val_acc": 72.0}
{"epoch": 11, "training_loss": 177.0330789089203, "training_acc": 72.33333333333333, "val_loss": 44.46786665916443, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.63140678405762, "training_acc": 72.33333333333333, "val_loss": 44.46795654296875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.30112838745117, "training_acc": 72.33333333333333, "val_loss": 44.50501608848572, "val_acc": 72.0}
{"epoch": 14, "training_loss": 177.05132484436035, "training_acc": 72.33333333333333, "val_loss": 44.49379754066467, "val_acc": 72.0}
{"epoch": 15, "training_loss": 177.48462057113647, "training_acc": 72.33333333333333, "val_loss": 44.4777769446373, "val_acc": 72.0}
{"epoch": 16, "training_loss": 177.5795168876648, "training_acc": 72.33333333333333, "val_loss": 44.46834397315979, "val_acc": 72.0}
{"epoch": 17, "training_loss": 177.43358421325684, "training_acc": 72.33333333333333, "val_loss": 44.623553812503815, "val_acc": 72.0}
{"epoch": 18, "training_loss": 177.30745100975037, "training_acc": 72.33333333333333, "val_loss": 44.49338614940643, "val_acc": 72.0}
{"epoch": 19, "training_loss": 177.30449843406677, "training_acc": 72.33333333333333, "val_loss": 44.459151327610016, "val_acc": 72.0}
{"epoch": 20, "training_loss": 177.2214114665985, "training_acc": 72.33333333333333, "val_loss": 44.45568799972534, "val_acc": 72.0}
{"epoch": 21, "training_loss": 176.8705403804779, "training_acc": 72.33333333333333, "val_loss": 44.451909244060516, "val_acc": 72.0}
{"epoch": 22, "training_loss": 177.3625147342682, "training_acc": 72.33333333333333, "val_loss": 44.45375096797943, "val_acc": 72.0}
{"epoch": 23, "training_loss": 177.4627070426941, "training_acc": 72.33333333333333, "val_loss": 44.39879244565964, "val_acc": 72.0}
{"epoch": 24, "training_loss": 177.04015922546387, "training_acc": 72.33333333333333, "val_loss": 44.38388165831566, "val_acc": 72.0}
{"epoch": 25, "training_loss": 176.52725958824158, "training_acc": 72.33333333333333, "val_loss": 44.39819425344467, "val_acc": 72.0}
{"epoch": 26, "training_loss": 173.76843786239624, "training_acc": 72.33333333333333, "val_loss": 43.72503328323364, "val_acc": 72.0}
{"epoch": 27, "training_loss": 174.9074990749359, "training_acc": 72.33333333333333, "val_loss": 44.55228811502457, "val_acc": 72.0}
{"epoch": 28, "training_loss": 179.9891176223755, "training_acc": 72.33333333333333, "val_loss": 44.46671608090401, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.73928785324097, "training_acc": 72.33333333333333, "val_loss": 44.686146438121796, "val_acc": 72.0}
{"epoch": 30, "training_loss": 177.513028383255, "training_acc": 72.33333333333333, "val_loss": 44.442932426929474, "val_acc": 72.0}
{"epoch": 31, "training_loss": 178.0041036605835, "training_acc": 72.33333333333333, "val_loss": 44.47918230295181, "val_acc": 72.0}
{"epoch": 32, "training_loss": 176.76749563217163, "training_acc": 72.33333333333333, "val_loss": 44.582994878292084, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.342755317688, "training_acc": 72.33333333333333, "val_loss": 44.464777290821075, "val_acc": 72.0}
{"epoch": 34, "training_loss": 177.470468044281, "training_acc": 72.33333333333333, "val_loss": 44.46274581551552, "val_acc": 72.0}
{"epoch": 35, "training_loss": 177.70771479606628, "training_acc": 72.33333333333333, "val_loss": 44.61584293842316, "val_acc": 72.0}
{"epoch": 36, "training_loss": 176.79829955101013, "training_acc": 72.33333333333333, "val_loss": 44.58222711086273, "val_acc": 72.0}
{"epoch": 37, "training_loss": 177.550598859787, "training_acc": 72.33333333333333, "val_loss": 44.4705086350441, "val_acc": 72.0}
{"epoch": 38, "training_loss": 177.03370261192322, "training_acc": 72.33333333333333, "val_loss": 44.45479518175125, "val_acc": 72.0}
{"epoch": 39, "training_loss": 179.62447381019592, "training_acc": 72.33333333333333, "val_loss": 44.527348279953, "val_acc": 72.0}
{"epoch": 40, "training_loss": 177.70024132728577, "training_acc": 72.33333333333333, "val_loss": 44.536279410123825, "val_acc": 72.0}
{"epoch": 41, "training_loss": 177.32484602928162, "training_acc": 72.33333333333333, "val_loss": 44.523778796195984, "val_acc": 72.0}
{"epoch": 42, "training_loss": 176.85867285728455, "training_acc": 72.33333333333333, "val_loss": 44.411943674087524, "val_acc": 72.0}
{"epoch": 43, "training_loss": 177.34651613235474, "training_acc": 72.33333333333333, "val_loss": 44.53088238835335, "val_acc": 72.0}
{"epoch": 44, "training_loss": 177.62221789360046, "training_acc": 72.33333333333333, "val_loss": 44.46530967950821, "val_acc": 72.0}
{"epoch": 45, "training_loss": 177.85357022285461, "training_acc": 72.33333333333333, "val_loss": 44.4832524061203, "val_acc": 72.0}
