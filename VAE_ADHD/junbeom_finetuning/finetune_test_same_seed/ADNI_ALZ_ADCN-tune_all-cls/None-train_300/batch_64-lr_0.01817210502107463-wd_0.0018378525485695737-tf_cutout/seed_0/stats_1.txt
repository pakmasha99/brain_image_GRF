"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1744.2764377593994, "training_acc": 59.0, "val_loss": 1.2102571702563635e+17, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8.63540712885063e+16, "training_acc": 51.0, "val_loss": 181.86081886291504, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4432.050136566162, "training_acc": 65.0, "val_loss": 47.6558575630188, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2369.1155281066895, "training_acc": 55.666666666666664, "val_loss": 952.579999923706, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4504.843980789185, "training_acc": 61.666666666666664, "val_loss": 3631.724494934082, "val_acc": 28.0}
{"epoch": 5, "training_loss": 4940.378549575806, "training_acc": 59.0, "val_loss": 313.21966457366943, "val_acc": 72.0}
{"epoch": 6, "training_loss": 842.8056859970093, "training_acc": 65.66666666666667, "val_loss": 315.3152856826782, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2644.5332679748535, "training_acc": 51.0, "val_loss": 286.9303357601166, "val_acc": 28.0}
{"epoch": 8, "training_loss": 5098.518333435059, "training_acc": 49.0, "val_loss": 315.80282640457153, "val_acc": 72.0}
{"epoch": 9, "training_loss": 515.9411563873291, "training_acc": 61.666666666666664, "val_loss": 43.705406963825226, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2718.2705178260803, "training_acc": 62.0, "val_loss": 107.50607299804688, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1397.5624389648438, "training_acc": 57.0, "val_loss": 174.30233812332153, "val_acc": 72.0}
{"epoch": 12, "training_loss": 8650.387184143066, "training_acc": 66.0, "val_loss": 364.38313245773315, "val_acc": 28.0}
{"epoch": 13, "training_loss": 6178.302505493164, "training_acc": 51.0, "val_loss": 1228.5769138336182, "val_acc": 28.0}
{"epoch": 14, "training_loss": 2961.9891834259033, "training_acc": 53.666666666666664, "val_loss": 47.66930139064789, "val_acc": 72.0}
{"epoch": 15, "training_loss": 812.1804690361023, "training_acc": 61.666666666666664, "val_loss": 45.22653925418854, "val_acc": 72.0}
{"epoch": 16, "training_loss": 244.0183048248291, "training_acc": 68.33333333333333, "val_loss": 321.2221841812134, "val_acc": 72.0}
{"epoch": 17, "training_loss": 426.8324947357178, "training_acc": 72.33333333333333, "val_loss": 44.52663433551788, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3356.5913710594177, "training_acc": 61.666666666666664, "val_loss": 45.502115190029144, "val_acc": 74.66666666666667}
{"epoch": 19, "training_loss": 4624.207633972168, "training_acc": 57.0, "val_loss": 84.12780380249023, "val_acc": 72.0}
{"epoch": 20, "training_loss": 9710.703918457031, "training_acc": 62.666666666666664, "val_loss": 4293.45987701416, "val_acc": 72.0}
{"epoch": 21, "training_loss": 34673.224182128906, "training_acc": 48.333333333333336, "val_loss": 4579.826629638672, "val_acc": 72.0}
{"epoch": 22, "training_loss": 47120.52565193176, "training_acc": 67.0, "val_loss": 56.22912734746933, "val_acc": 72.0}
{"epoch": 23, "training_loss": 590.6165072917938, "training_acc": 72.33333333333333, "val_loss": 65.04352575540543, "val_acc": 72.0}
{"epoch": 24, "training_loss": 8444.506729125977, "training_acc": 67.66666666666667, "val_loss": 4573.115400314331, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4172.536647319794, "training_acc": 72.33333333333333, "val_loss": 903.7136096954346, "val_acc": 72.0}
{"epoch": 26, "training_loss": 869.1423678398132, "training_acc": 72.33333333333333, "val_loss": 44.75420495867729, "val_acc": 72.0}
{"epoch": 27, "training_loss": 180.73841905593872, "training_acc": 72.33333333333333, "val_loss": 44.47523272037506, "val_acc": 72.0}
{"epoch": 28, "training_loss": 178.21743202209473, "training_acc": 72.33333333333333, "val_loss": 46.082088112831116, "val_acc": 72.0}
