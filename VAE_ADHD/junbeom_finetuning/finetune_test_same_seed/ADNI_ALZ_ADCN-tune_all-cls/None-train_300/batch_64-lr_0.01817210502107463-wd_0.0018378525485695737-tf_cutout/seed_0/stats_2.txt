"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2412.342752456665, "training_acc": 54.666666666666664, "val_loss": 837282235940864.0, "val_acc": 72.0}
{"epoch": 1, "training_loss": 544272013130973.25, "training_acc": 39.666666666666664, "val_loss": 21765.216857910156, "val_acc": 72.0}
{"epoch": 2, "training_loss": 98504.62121582031, "training_acc": 43.0, "val_loss": 101728.19946289062, "val_acc": 72.0}
{"epoch": 3, "training_loss": 170663.4369840622, "training_acc": 64.66666666666667, "val_loss": 3190.888868331909, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9437.160228729248, "training_acc": 64.33333333333333, "val_loss": 524.153733253479, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3676.7739486694336, "training_acc": 54.0, "val_loss": 707.7432479858398, "val_acc": 72.0}
{"epoch": 6, "training_loss": 34775.38575744629, "training_acc": 65.0, "val_loss": 1189.0975675582886, "val_acc": 72.0}
{"epoch": 7, "training_loss": 27567.70371246338, "training_acc": 72.33333333333333, "val_loss": 2659.838134765625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 171276.30838012695, "training_acc": 57.0, "val_loss": 3090.983642578125, "val_acc": 28.0}
{"epoch": 9, "training_loss": 3122.1270895004272, "training_acc": 49.666666666666664, "val_loss": 47.38733500242233, "val_acc": 66.66666666666667}
{"epoch": 10, "training_loss": 142032.45765304565, "training_acc": 50.666666666666664, "val_loss": 55100.04248046875, "val_acc": 72.0}
{"epoch": 11, "training_loss": 43740.04924798012, "training_acc": 65.0, "val_loss": 265.2571015357971, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1315.3971445560455, "training_acc": 61.666666666666664, "val_loss": 16346.51773071289, "val_acc": 28.0}
{"epoch": 13, "training_loss": 13884.63026046753, "training_acc": 62.333333333333336, "val_loss": 49.79511749744415, "val_acc": 72.0}
{"epoch": 14, "training_loss": 9707.147899627686, "training_acc": 72.33333333333333, "val_loss": 58.865234375, "val_acc": 28.0}
{"epoch": 15, "training_loss": 136112.06573057175, "training_acc": 36.333333333333336, "val_loss": 142.61731576919556, "val_acc": 28.0}
{"epoch": 16, "training_loss": 577.7647109031677, "training_acc": 27.666666666666668, "val_loss": 93.95199596881866, "val_acc": 28.0}
{"epoch": 17, "training_loss": 248.90602827072144, "training_acc": 41.0, "val_loss": 44.08668851852417, "val_acc": 74.66666666666667}
{"epoch": 18, "training_loss": 210865.53311920166, "training_acc": 69.66666666666667, "val_loss": 1286258.8203125, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1172608.3960285187, "training_acc": 60.333333333333336, "val_loss": 54.00474011898041, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3539084.0063552856, "training_acc": 64.33333333333333, "val_loss": 16160369.125, "val_acc": 28.0}
{"epoch": 21, "training_loss": 13809754.07251215, "training_acc": 51.666666666666664, "val_loss": 73.90878963470459, "val_acc": 72.0}
{"epoch": 22, "training_loss": 61840911.414554596, "training_acc": 65.66666666666667, "val_loss": 52069331.5, "val_acc": 72.0}
{"epoch": 23, "training_loss": 48760418.62773609, "training_acc": 49.0, "val_loss": 188887.10327148438, "val_acc": 68.0}
{"epoch": 24, "training_loss": 483988.24347019196, "training_acc": 43.0, "val_loss": 59.217979431152344, "val_acc": 28.0}
{"epoch": 25, "training_loss": 194.04981112480164, "training_acc": 64.33333333333333, "val_loss": 63.71202206611633, "val_acc": 72.0}
{"epoch": 26, "training_loss": 222.76042556762695, "training_acc": 72.33333333333333, "val_loss": 48.47469073534012, "val_acc": 28.0}
{"epoch": 27, "training_loss": 190.3651843070984, "training_acc": 72.33333333333333, "val_loss": 48.023940682411194, "val_acc": 72.0}
{"epoch": 28, "training_loss": 182.09189820289612, "training_acc": 72.33333333333333, "val_loss": 46.05818575620651, "val_acc": 28.0}
{"epoch": 29, "training_loss": 185.6321349143982, "training_acc": 72.33333333333333, "val_loss": 46.109891176223755, "val_acc": 72.0}
{"epoch": 30, "training_loss": 180.92910480499268, "training_acc": 72.33333333333333, "val_loss": 45.13247749209404, "val_acc": 72.0}
{"epoch": 31, "training_loss": 177.15941786766052, "training_acc": 72.33333333333333, "val_loss": 45.490725219249725, "val_acc": 72.0}
{"epoch": 32, "training_loss": 181.24870419502258, "training_acc": 72.33333333333333, "val_loss": 44.682945251464844, "val_acc": 72.0}
{"epoch": 33, "training_loss": 178.01941752433777, "training_acc": 72.33333333333333, "val_loss": 44.536963522434235, "val_acc": 72.0}
{"epoch": 34, "training_loss": 177.05829787254333, "training_acc": 72.33333333333333, "val_loss": 44.477576196193695, "val_acc": 72.0}
{"epoch": 35, "training_loss": 177.3412425518036, "training_acc": 72.33333333333333, "val_loss": 44.47222089767456, "val_acc": 72.0}
{"epoch": 36, "training_loss": 177.53968477249146, "training_acc": 72.33333333333333, "val_loss": 44.56146854162216, "val_acc": 72.0}
