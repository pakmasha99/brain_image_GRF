"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 300 --layer_control tune_all --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 318.07108068466187, "training_acc": 60.333333333333336, "val_loss": 3072393.4609375, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2649800.0811462402, "training_acc": 51.0, "val_loss": 896.1238403320312, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1522.8262948989868, "training_acc": 64.33333333333333, "val_loss": 118.26125252246857, "val_acc": 28.0}
{"epoch": 3, "training_loss": 360.37610030174255, "training_acc": 53.0, "val_loss": 46.75840085744858, "val_acc": 29.333333333333332}
{"epoch": 4, "training_loss": 185.17874312400818, "training_acc": 72.33333333333333, "val_loss": 51.077166855335236, "val_acc": 28.0}
{"epoch": 5, "training_loss": 188.12583589553833, "training_acc": 72.33333333333333, "val_loss": 45.25234603881836, "val_acc": 72.0}
{"epoch": 6, "training_loss": 184.31513333320618, "training_acc": 72.33333333333333, "val_loss": 44.78748661279678, "val_acc": 72.0}
{"epoch": 7, "training_loss": 184.38672375679016, "training_acc": 72.33333333333333, "val_loss": 45.97197371721268, "val_acc": 68.0}
{"epoch": 8, "training_loss": 180.0716552734375, "training_acc": 72.33333333333333, "val_loss": 44.76125746965408, "val_acc": 72.0}
{"epoch": 9, "training_loss": 178.7170171737671, "training_acc": 72.33333333333333, "val_loss": 44.622560918331146, "val_acc": 72.0}
{"epoch": 10, "training_loss": 179.0277988910675, "training_acc": 72.33333333333333, "val_loss": 44.998190104961395, "val_acc": 72.0}
{"epoch": 11, "training_loss": 176.79152011871338, "training_acc": 72.33333333333333, "val_loss": 45.377646803855896, "val_acc": 72.0}
{"epoch": 12, "training_loss": 179.5905840396881, "training_acc": 72.33333333333333, "val_loss": 44.627532094717026, "val_acc": 72.0}
{"epoch": 13, "training_loss": 177.14591336250305, "training_acc": 72.33333333333333, "val_loss": 45.758687913417816, "val_acc": 72.0}
{"epoch": 14, "training_loss": 178.12884306907654, "training_acc": 72.33333333333333, "val_loss": 44.77142947912216, "val_acc": 72.0}
{"epoch": 15, "training_loss": 176.74321746826172, "training_acc": 72.33333333333333, "val_loss": 45.26471447944641, "val_acc": 72.0}
{"epoch": 16, "training_loss": 182.9992904663086, "training_acc": 72.33333333333333, "val_loss": 45.403563380241394, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 182.13539481163025, "training_acc": 72.33333333333333, "val_loss": 44.573735415935516, "val_acc": 72.0}
{"epoch": 18, "training_loss": 178.44385743141174, "training_acc": 72.33333333333333, "val_loss": 44.95436090230942, "val_acc": 72.0}
{"epoch": 19, "training_loss": 177.81697249412537, "training_acc": 72.33333333333333, "val_loss": 44.64759048819542, "val_acc": 72.0}
{"epoch": 20, "training_loss": 176.7084662914276, "training_acc": 72.33333333333333, "val_loss": 44.62036055326462, "val_acc": 72.0}
{"epoch": 21, "training_loss": 180.6607472896576, "training_acc": 72.33333333333333, "val_loss": 44.459018766880035, "val_acc": 72.0}
{"epoch": 22, "training_loss": 187.53610563278198, "training_acc": 72.33333333333333, "val_loss": 44.809820771217346, "val_acc": 72.0}
{"epoch": 23, "training_loss": 181.4828338623047, "training_acc": 72.33333333333333, "val_loss": 44.5303892493248, "val_acc": 72.0}
{"epoch": 24, "training_loss": 179.23474264144897, "training_acc": 72.33333333333333, "val_loss": 44.543136060237885, "val_acc": 72.0}
{"epoch": 25, "training_loss": 177.82539129257202, "training_acc": 72.33333333333333, "val_loss": 46.45983237028122, "val_acc": 72.0}
{"epoch": 26, "training_loss": 181.98502707481384, "training_acc": 72.33333333333333, "val_loss": 44.521854877471924, "val_acc": 72.0}
{"epoch": 27, "training_loss": 178.09280729293823, "training_acc": 72.33333333333333, "val_loss": 44.48941856622696, "val_acc": 72.0}
{"epoch": 28, "training_loss": 176.18149948120117, "training_acc": 72.33333333333333, "val_loss": 44.786945551633835, "val_acc": 72.0}
{"epoch": 29, "training_loss": 176.8861119747162, "training_acc": 72.33333333333333, "val_loss": 44.40790110826492, "val_acc": 72.0}
{"epoch": 30, "training_loss": 175.85995841026306, "training_acc": 72.33333333333333, "val_loss": 44.36902838945389, "val_acc": 72.0}
{"epoch": 31, "training_loss": 174.77423071861267, "training_acc": 72.33333333333333, "val_loss": 44.57827016711235, "val_acc": 72.0}
{"epoch": 32, "training_loss": 179.19848680496216, "training_acc": 72.33333333333333, "val_loss": 44.27279180288315, "val_acc": 72.0}
{"epoch": 33, "training_loss": 174.24894332885742, "training_acc": 72.33333333333333, "val_loss": 44.65957951545715, "val_acc": 72.0}
{"epoch": 34, "training_loss": 175.12205266952515, "training_acc": 72.33333333333333, "val_loss": 44.56616508960724, "val_acc": 72.0}
{"epoch": 35, "training_loss": 174.14941477775574, "training_acc": 72.33333333333333, "val_loss": 46.598470747470856, "val_acc": 72.0}
{"epoch": 36, "training_loss": 179.0253803730011, "training_acc": 72.33333333333333, "val_loss": 45.532697916030884, "val_acc": 68.0}
{"epoch": 37, "training_loss": 175.35649633407593, "training_acc": 72.33333333333333, "val_loss": 45.32275325059891, "val_acc": 72.0}
{"epoch": 38, "training_loss": 174.61611151695251, "training_acc": 72.33333333333333, "val_loss": 44.78305673599243, "val_acc": 69.33333333333333}
{"epoch": 39, "training_loss": 177.48607087135315, "training_acc": 72.33333333333333, "val_loss": 44.674321711063385, "val_acc": 72.0}
{"epoch": 40, "training_loss": 175.9761769771576, "training_acc": 72.33333333333333, "val_loss": 45.36258488893509, "val_acc": 72.0}
{"epoch": 41, "training_loss": 174.86967635154724, "training_acc": 72.33333333333333, "val_loss": 44.18728467822075, "val_acc": 72.0}
{"epoch": 42, "training_loss": 171.08092212677002, "training_acc": 72.33333333333333, "val_loss": 44.091157257556915, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 174.93648505210876, "training_acc": 72.33333333333333, "val_loss": 47.042721807956696, "val_acc": 44.0}
{"epoch": 44, "training_loss": 175.23112154006958, "training_acc": 74.33333333333333, "val_loss": 44.388689279556274, "val_acc": 72.0}
{"epoch": 45, "training_loss": 175.2393319606781, "training_acc": 72.33333333333333, "val_loss": 44.10790020227432, "val_acc": 72.0}
{"epoch": 46, "training_loss": 177.40686511993408, "training_acc": 72.33333333333333, "val_loss": 45.42185553908348, "val_acc": 72.0}
{"epoch": 47, "training_loss": 183.8322741985321, "training_acc": 72.33333333333333, "val_loss": 45.23608696460724, "val_acc": 66.66666666666667}
{"epoch": 48, "training_loss": 178.24308347702026, "training_acc": 72.33333333333333, "val_loss": 44.64482218027115, "val_acc": 72.0}
{"epoch": 49, "training_loss": 175.22281217575073, "training_acc": 72.33333333333333, "val_loss": 44.70333003997803, "val_acc": 72.0}
{"epoch": 50, "training_loss": 176.53558921813965, "training_acc": 72.33333333333333, "val_loss": 46.7656335234642, "val_acc": 72.0}
{"epoch": 51, "training_loss": 182.85166025161743, "training_acc": 72.33333333333333, "val_loss": 45.26578092575073, "val_acc": 68.0}
{"epoch": 52, "training_loss": 176.3669412136078, "training_acc": 72.33333333333333, "val_loss": 44.573703825473785, "val_acc": 72.0}
{"epoch": 53, "training_loss": 175.43978548049927, "training_acc": 72.33333333333333, "val_loss": 44.276727974414825, "val_acc": 72.0}
{"epoch": 54, "training_loss": 172.71018028259277, "training_acc": 72.33333333333333, "val_loss": 44.368286311626434, "val_acc": 72.0}
{"epoch": 55, "training_loss": 172.14305555820465, "training_acc": 72.0, "val_loss": 49.088751047849655, "val_acc": 72.0}
{"epoch": 56, "training_loss": 180.06547570228577, "training_acc": 72.33333333333333, "val_loss": 45.53135871887207, "val_acc": 68.0}
{"epoch": 57, "training_loss": 179.31662726402283, "training_acc": 72.33333333333333, "val_loss": 44.41972932219505, "val_acc": 72.0}
{"epoch": 58, "training_loss": 179.32491064071655, "training_acc": 72.33333333333333, "val_loss": 44.28800582885742, "val_acc": 72.0}
{"epoch": 59, "training_loss": 173.42706537246704, "training_acc": 72.33333333333333, "val_loss": 44.15044230222702, "val_acc": 72.0}
{"epoch": 60, "training_loss": 174.2383576631546, "training_acc": 72.0, "val_loss": 48.50974225997925, "val_acc": 72.0}
{"epoch": 61, "training_loss": 187.83400106430054, "training_acc": 73.0, "val_loss": 44.43409198522568, "val_acc": 69.33333333333333}
