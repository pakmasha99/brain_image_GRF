"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3044.198613166809, "training_acc": 62.0, "val_loss": 568.1209344863892, "val_acc": 30.666666666666668}
{"epoch": 1, "training_loss": 1360.3796138763428, "training_acc": 62.333333333333336, "val_loss": 341.25059700012207, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 862.6304807662964, "training_acc": 66.0, "val_loss": 225.08807754516602, "val_acc": 65.33333333333333}
{"epoch": 3, "training_loss": 566.2883715629578, "training_acc": 70.33333333333333, "val_loss": 138.93477183580399, "val_acc": 56.0}
{"epoch": 4, "training_loss": 397.768292427063, "training_acc": 64.33333333333333, "val_loss": 86.48809921741486, "val_acc": 65.33333333333333}
{"epoch": 5, "training_loss": 323.5036451816559, "training_acc": 69.66666666666667, "val_loss": 90.0297532081604, "val_acc": 68.0}
{"epoch": 6, "training_loss": 295.1278347969055, "training_acc": 73.33333333333333, "val_loss": 80.24809116125107, "val_acc": 72.0}
{"epoch": 7, "training_loss": 205.98320817947388, "training_acc": 74.33333333333333, "val_loss": 53.39304542541504, "val_acc": 72.0}
{"epoch": 8, "training_loss": 259.2473747730255, "training_acc": 68.66666666666667, "val_loss": 243.1901409626007, "val_acc": 28.0}
{"epoch": 9, "training_loss": 545.1055784225464, "training_acc": 59.333333333333336, "val_loss": 70.94676786661148, "val_acc": 69.33333333333333}
{"epoch": 10, "training_loss": 252.99540328979492, "training_acc": 74.33333333333333, "val_loss": 74.73842859268188, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 244.91907119750977, "training_acc": 71.33333333333333, "val_loss": 72.49086463451385, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 214.44520902633667, "training_acc": 75.0, "val_loss": 53.75861608982086, "val_acc": 58.666666666666664}
{"epoch": 13, "training_loss": 381.056293964386, "training_acc": 66.66666666666667, "val_loss": 231.4049732685089, "val_acc": 38.666666666666664}
{"epoch": 14, "training_loss": 571.7980470657349, "training_acc": 63.333333333333336, "val_loss": 100.20489931106567, "val_acc": 62.666666666666664}
{"epoch": 15, "training_loss": 505.41098833084106, "training_acc": 65.66666666666667, "val_loss": 161.23824858665466, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 380.82585859298706, "training_acc": 72.33333333333333, "val_loss": 121.93529742956161, "val_acc": 66.66666666666667}
{"epoch": 17, "training_loss": 268.65626311302185, "training_acc": 75.33333333333333, "val_loss": 110.86505484580994, "val_acc": 72.0}
{"epoch": 18, "training_loss": 346.48355865478516, "training_acc": 67.0, "val_loss": 52.994643330574036, "val_acc": 68.0}
{"epoch": 19, "training_loss": 258.94892168045044, "training_acc": 69.66666666666667, "val_loss": 103.24123418331146, "val_acc": 52.0}
{"epoch": 20, "training_loss": 254.87469911575317, "training_acc": 71.0, "val_loss": 171.80503284931183, "val_acc": 44.0}
{"epoch": 21, "training_loss": 402.6640856266022, "training_acc": 70.0, "val_loss": 111.22104835510254, "val_acc": 52.0}
{"epoch": 22, "training_loss": 266.4734539985657, "training_acc": 73.0, "val_loss": 100.58634757995605, "val_acc": 48.0}
{"epoch": 23, "training_loss": 254.9975335597992, "training_acc": 71.33333333333333, "val_loss": 50.230811297893524, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 134.8112187385559, "training_acc": 79.0, "val_loss": 65.89896136522293, "val_acc": 72.0}
{"epoch": 25, "training_loss": 186.01356077194214, "training_acc": 77.33333333333333, "val_loss": 106.30798530578613, "val_acc": 72.0}
{"epoch": 26, "training_loss": 413.753613948822, "training_acc": 66.33333333333333, "val_loss": 135.68313646316528, "val_acc": 72.0}
{"epoch": 27, "training_loss": 284.4065089225769, "training_acc": 72.0, "val_loss": 115.18992161750793, "val_acc": 76.0}
{"epoch": 28, "training_loss": 277.26053380966187, "training_acc": 72.33333333333333, "val_loss": 64.56752860546112, "val_acc": 72.0}
{"epoch": 29, "training_loss": 175.757417678833, "training_acc": 75.66666666666667, "val_loss": 89.37021297216415, "val_acc": 49.333333333333336}
{"epoch": 30, "training_loss": 194.31133484840393, "training_acc": 75.33333333333333, "val_loss": 52.976167753338814, "val_acc": 69.33333333333333}
{"epoch": 31, "training_loss": 143.73149299621582, "training_acc": 79.33333333333333, "val_loss": 63.529577761888504, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 140.5885190963745, "training_acc": 80.66666666666667, "val_loss": 45.39913374185562, "val_acc": 72.0}
{"epoch": 33, "training_loss": 202.218159198761, "training_acc": 76.66666666666667, "val_loss": 64.06050944328308, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 286.3375816345215, "training_acc": 69.66666666666667, "val_loss": 64.89833295345306, "val_acc": 68.0}
{"epoch": 35, "training_loss": 266.5728735923767, "training_acc": 75.33333333333333, "val_loss": 124.98087334632874, "val_acc": 72.0}
{"epoch": 36, "training_loss": 286.39570665359497, "training_acc": 72.66666666666667, "val_loss": 66.56086051464081, "val_acc": 76.0}
{"epoch": 37, "training_loss": 206.48689663410187, "training_acc": 74.33333333333333, "val_loss": 68.25371038913727, "val_acc": 57.333333333333336}
{"epoch": 38, "training_loss": 111.98585057258606, "training_acc": 84.66666666666667, "val_loss": 69.4473614692688, "val_acc": 60.0}
{"epoch": 39, "training_loss": 136.1184332370758, "training_acc": 82.66666666666667, "val_loss": 57.89189338684082, "val_acc": 76.0}
{"epoch": 40, "training_loss": 154.62346696853638, "training_acc": 78.0, "val_loss": 42.978466510772705, "val_acc": 74.66666666666667}
{"epoch": 41, "training_loss": 155.22001957893372, "training_acc": 78.66666666666667, "val_loss": 49.4005269408226, "val_acc": 80.0}
{"epoch": 42, "training_loss": 125.17035794258118, "training_acc": 83.0, "val_loss": 47.40483683347702, "val_acc": 69.33333333333333}
{"epoch": 43, "training_loss": 100.60987102985382, "training_acc": 87.0, "val_loss": 44.8162499666214, "val_acc": 65.33333333333333}
{"epoch": 44, "training_loss": 150.1012440919876, "training_acc": 75.0, "val_loss": 102.71408295631409, "val_acc": 72.0}
{"epoch": 45, "training_loss": 348.0417242050171, "training_acc": 70.33333333333333, "val_loss": 101.4691174030304, "val_acc": 76.0}
{"epoch": 46, "training_loss": 242.27642142772675, "training_acc": 74.33333333333333, "val_loss": 63.11751174926758, "val_acc": 78.66666666666667}
{"epoch": 47, "training_loss": 188.5157334804535, "training_acc": 76.33333333333333, "val_loss": 104.6585841178894, "val_acc": 37.333333333333336}
{"epoch": 48, "training_loss": 221.02009415626526, "training_acc": 73.33333333333333, "val_loss": 50.85255241394043, "val_acc": 70.66666666666667}
{"epoch": 49, "training_loss": 207.21984958648682, "training_acc": 72.33333333333333, "val_loss": 111.09026753902435, "val_acc": 73.33333333333333}
{"epoch": 50, "training_loss": 208.54113113880157, "training_acc": 77.0, "val_loss": 68.2762194275856, "val_acc": 73.33333333333333}
{"epoch": 51, "training_loss": 117.65745830535889, "training_acc": 82.0, "val_loss": 45.38114959001541, "val_acc": 80.0}
{"epoch": 52, "training_loss": 110.97188079357147, "training_acc": 84.0, "val_loss": 59.2575021982193, "val_acc": 77.33333333333333}
{"epoch": 53, "training_loss": 124.02138638496399, "training_acc": 84.0, "val_loss": 60.62041509151459, "val_acc": 62.666666666666664}
{"epoch": 54, "training_loss": 166.48474860191345, "training_acc": 79.0, "val_loss": 49.521698236465454, "val_acc": 80.0}
{"epoch": 55, "training_loss": 89.14995610713959, "training_acc": 88.66666666666667, "val_loss": 50.761700093746185, "val_acc": 76.0}
{"epoch": 56, "training_loss": 111.27870494127274, "training_acc": 82.33333333333333, "val_loss": 54.411243200302124, "val_acc": 61.333333333333336}
{"epoch": 57, "training_loss": 105.19133794307709, "training_acc": 85.33333333333333, "val_loss": 53.90160691738129, "val_acc": 62.666666666666664}
{"epoch": 58, "training_loss": 117.28619122505188, "training_acc": 83.33333333333333, "val_loss": 63.46474838256836, "val_acc": 77.33333333333333}
{"epoch": 59, "training_loss": 204.72952508926392, "training_acc": 76.66666666666667, "val_loss": 84.38485342264175, "val_acc": 74.66666666666667}
