"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14984082.446861267, "training_acc": 64.33333333333333, "val_loss": 6182649.5390625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 16493398.0625, "training_acc": 58.0, "val_loss": 4637856.8125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 10322370.6875, "training_acc": 67.66666666666667, "val_loss": 4551246.14453125, "val_acc": 33.333333333333336}
{"epoch": 3, "training_loss": 8523069.77734375, "training_acc": 64.0, "val_loss": 3532794.2109375, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 7968027.5546875, "training_acc": 72.66666666666667, "val_loss": 2372819.919921875, "val_acc": 50.666666666666664}
{"epoch": 5, "training_loss": 6419869.57421875, "training_acc": 60.666666666666664, "val_loss": 2017480.513671875, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 4406751.6953125, "training_acc": 71.0, "val_loss": 1430797.673828125, "val_acc": 54.666666666666664}
{"epoch": 7, "training_loss": 3267060.87109375, "training_acc": 68.0, "val_loss": 793447.01171875, "val_acc": 56.0}
{"epoch": 8, "training_loss": 2300347.30859375, "training_acc": 65.33333333333333, "val_loss": 527230.2978515625, "val_acc": 54.666666666666664}
{"epoch": 9, "training_loss": 1048677.583984375, "training_acc": 71.0, "val_loss": 348202.3537597656, "val_acc": 56.0}
{"epoch": 10, "training_loss": 986072.474609375, "training_acc": 68.33333333333333, "val_loss": 205657.87768554688, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1828398.76171875, "training_acc": 66.0, "val_loss": 1239266.7734375, "val_acc": 37.333333333333336}
{"epoch": 12, "training_loss": 2628821.921875, "training_acc": 61.0, "val_loss": 726872.298828125, "val_acc": 61.333333333333336}
{"epoch": 13, "training_loss": 1915718.1572265625, "training_acc": 72.66666666666667, "val_loss": 448949.78515625, "val_acc": 64.0}
{"epoch": 14, "training_loss": 1118097.8515625, "training_acc": 68.33333333333333, "val_loss": 238081.87622070312, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 1041823.1328125, "training_acc": 68.0, "val_loss": 237575.94177246094, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1332757.7890625, "training_acc": 68.66666666666667, "val_loss": 582827.994140625, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1004294.1889648438, "training_acc": 73.33333333333333, "val_loss": 313474.9816894531, "val_acc": 68.0}
{"epoch": 18, "training_loss": 800099.7065429688, "training_acc": 71.66666666666667, "val_loss": 322588.298828125, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 509770.1018066406, "training_acc": 75.0, "val_loss": 315419.3791503906, "val_acc": 58.666666666666664}
{"epoch": 20, "training_loss": 926408.9931640625, "training_acc": 69.33333333333333, "val_loss": 360438.2802734375, "val_acc": 72.0}
{"epoch": 21, "training_loss": 581766.8203125, "training_acc": 78.0, "val_loss": 413979.158203125, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1368882.6484375, "training_acc": 66.33333333333333, "val_loss": 475661.51953125, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 2214207.0952148438, "training_acc": 65.0, "val_loss": 710694.5927734375, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 1563137.826171875, "training_acc": 72.33333333333333, "val_loss": 650979.318359375, "val_acc": 69.33333333333333}
{"epoch": 25, "training_loss": 1116244.400390625, "training_acc": 70.66666666666667, "val_loss": 433033.8381347656, "val_acc": 69.33333333333333}
{"epoch": 26, "training_loss": 869840.2900390625, "training_acc": 73.33333333333333, "val_loss": 295685.12646484375, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 1194366.673828125, "training_acc": 70.0, "val_loss": 688345.2553710938, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1409207.77734375, "training_acc": 67.66666666666667, "val_loss": 411153.8962402344, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 1135443.94140625, "training_acc": 69.33333333333333, "val_loss": 623550.0388183594, "val_acc": 69.33333333333333}
