"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 17397589.871601105, "training_acc": 53.0, "val_loss": 349180.5205078125, "val_acc": 65.33333333333333}
{"epoch": 1, "training_loss": 5849083.765625, "training_acc": 70.33333333333333, "val_loss": 751731.5029296875, "val_acc": 58.666666666666664}
{"epoch": 2, "training_loss": 3675613.0859375, "training_acc": 62.333333333333336, "val_loss": 576402.724609375, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 2549909.03515625, "training_acc": 64.66666666666667, "val_loss": 901525.5458984375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2321403.236328125, "training_acc": 68.33333333333333, "val_loss": 271817.2580566406, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1181873.4921875, "training_acc": 63.333333333333336, "val_loss": 236285.72717285156, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1622961.1875, "training_acc": 62.333333333333336, "val_loss": 157898.8974609375, "val_acc": 77.33333333333333}
{"epoch": 7, "training_loss": 1333734.92578125, "training_acc": 67.66666666666667, "val_loss": 216965.0947265625, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 2524939.2578125, "training_acc": 60.333333333333336, "val_loss": 113964.12493896484, "val_acc": 76.0}
{"epoch": 9, "training_loss": 600992.7578125, "training_acc": 71.0, "val_loss": 143125.94018554688, "val_acc": 72.0}
{"epoch": 10, "training_loss": 763937.6640625, "training_acc": 71.0, "val_loss": 323137.67333984375, "val_acc": 49.333333333333336}
{"epoch": 11, "training_loss": 1227397.5556640625, "training_acc": 61.0, "val_loss": 222666.68823242188, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 651659.9536132812, "training_acc": 78.33333333333333, "val_loss": 301378.81787109375, "val_acc": 72.0}
{"epoch": 13, "training_loss": 549045.6169433594, "training_acc": 73.66666666666667, "val_loss": 189037.59826660156, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 1639455.9631347656, "training_acc": 66.0, "val_loss": 425512.037109375, "val_acc": 52.0}
{"epoch": 15, "training_loss": 1897523.26171875, "training_acc": 65.33333333333333, "val_loss": 507110.64990234375, "val_acc": 56.0}
{"epoch": 16, "training_loss": 2297819.9306640625, "training_acc": 69.66666666666667, "val_loss": 957568.841796875, "val_acc": 33.333333333333336}
{"epoch": 17, "training_loss": 1784981.94921875, "training_acc": 60.333333333333336, "val_loss": 214960.68774414062, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 1874708.044921875, "training_acc": 65.33333333333333, "val_loss": 788872.98046875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4251325.1640625, "training_acc": 65.33333333333333, "val_loss": 758048.6015625, "val_acc": 53.333333333333336}
{"epoch": 20, "training_loss": 3569123.5625, "training_acc": 66.66666666666667, "val_loss": 563822.2958984375, "val_acc": 64.0}
{"epoch": 21, "training_loss": 3863834.171875, "training_acc": 61.666666666666664, "val_loss": 1270928.1240234375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3178298.15625, "training_acc": 70.0, "val_loss": 274977.06787109375, "val_acc": 78.66666666666667}
{"epoch": 23, "training_loss": 2597161.53515625, "training_acc": 72.0, "val_loss": 510021.43017578125, "val_acc": 53.333333333333336}
{"epoch": 24, "training_loss": 1460863.22265625, "training_acc": 69.0, "val_loss": 355865.9375, "val_acc": 58.666666666666664}
{"epoch": 25, "training_loss": 796121.6215820312, "training_acc": 73.33333333333333, "val_loss": 180780.30786132812, "val_acc": 77.33333333333333}
{"epoch": 26, "training_loss": 418823.02001953125, "training_acc": 76.33333333333333, "val_loss": 108142.03915405273, "val_acc": 76.0}
{"epoch": 27, "training_loss": 729862.96875, "training_acc": 70.33333333333333, "val_loss": 358922.91015625, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2335440.798828125, "training_acc": 61.333333333333336, "val_loss": 1011930.822265625, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3718700.875, "training_acc": 66.66666666666667, "val_loss": 223127.3291015625, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 2262050.0322265625, "training_acc": 71.66666666666667, "val_loss": 695771.345703125, "val_acc": 57.333333333333336}
{"epoch": 31, "training_loss": 3192515.6171875, "training_acc": 65.33333333333333, "val_loss": 167529.83154296875, "val_acc": 84.0}
{"epoch": 32, "training_loss": 2283920.79296875, "training_acc": 64.66666666666667, "val_loss": 410100.322265625, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 1946337.4765625, "training_acc": 65.66666666666667, "val_loss": 666252.7734375, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1640948.046875, "training_acc": 69.66666666666667, "val_loss": 382199.095703125, "val_acc": 76.0}
{"epoch": 35, "training_loss": 905762.1499023438, "training_acc": 77.0, "val_loss": 135601.46899414062, "val_acc": 80.0}
{"epoch": 36, "training_loss": 343074.2980957031, "training_acc": 81.33333333333333, "val_loss": 153268.064453125, "val_acc": 76.0}
{"epoch": 37, "training_loss": 420740.8623046875, "training_acc": 80.66666666666667, "val_loss": 137066.79248046875, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1094985.357421875, "training_acc": 69.66666666666667, "val_loss": 131587.70947265625, "val_acc": 81.33333333333333}
{"epoch": 39, "training_loss": 460686.1730957031, "training_acc": 78.66666666666667, "val_loss": 255761.7822265625, "val_acc": 76.0}
{"epoch": 40, "training_loss": 353633.3859863281, "training_acc": 82.0, "val_loss": 103802.68035888672, "val_acc": 82.66666666666667}
{"epoch": 41, "training_loss": 719173.0244140625, "training_acc": 73.0, "val_loss": 298505.595703125, "val_acc": 73.33333333333333}
{"epoch": 42, "training_loss": 1003341.619140625, "training_acc": 72.33333333333333, "val_loss": 148956.36328125, "val_acc": 84.0}
{"epoch": 43, "training_loss": 1832255.47265625, "training_acc": 68.66666666666667, "val_loss": 456175.95654296875, "val_acc": 74.66666666666667}
{"epoch": 44, "training_loss": 1414895.9453125, "training_acc": 67.66666666666667, "val_loss": 107341.77099609375, "val_acc": 80.0}
{"epoch": 45, "training_loss": 531684.603515625, "training_acc": 77.0, "val_loss": 351228.1494140625, "val_acc": 49.333333333333336}
{"epoch": 46, "training_loss": 2092916.1015625, "training_acc": 64.66666666666667, "val_loss": 235315.109375, "val_acc": 70.66666666666667}
{"epoch": 47, "training_loss": 1418363.541015625, "training_acc": 73.66666666666667, "val_loss": 218239.40270996094, "val_acc": 76.0}
{"epoch": 48, "training_loss": 1070811.22265625, "training_acc": 74.33333333333333, "val_loss": 140791.19079589844, "val_acc": 73.33333333333333}
{"epoch": 49, "training_loss": 1139837.0625, "training_acc": 69.0, "val_loss": 324999.3447265625, "val_acc": 73.33333333333333}
{"epoch": 50, "training_loss": 1326357.599609375, "training_acc": 68.66666666666667, "val_loss": 206940.86860656738, "val_acc": 80.0}
{"epoch": 51, "training_loss": 951163.9140625, "training_acc": 74.66666666666667, "val_loss": 124635.54125976562, "val_acc": 81.33333333333333}
{"epoch": 52, "training_loss": 601543.490234375, "training_acc": 78.0, "val_loss": 323405.9201660156, "val_acc": 53.333333333333336}
{"epoch": 53, "training_loss": 696076.5478515625, "training_acc": 74.33333333333333, "val_loss": 163415.20434570312, "val_acc": 78.66666666666667}
{"epoch": 54, "training_loss": 701607.3876953125, "training_acc": 75.33333333333333, "val_loss": 274718.2634277344, "val_acc": 78.66666666666667}
{"epoch": 55, "training_loss": 641930.9921875, "training_acc": 79.66666666666667, "val_loss": 238690.1181640625, "val_acc": 78.66666666666667}
{"epoch": 56, "training_loss": 542270.7626953125, "training_acc": 80.33333333333333, "val_loss": 274643.9580078125, "val_acc": 53.333333333333336}
{"epoch": 57, "training_loss": 381568.70739746094, "training_acc": 82.0, "val_loss": 172703.35522460938, "val_acc": 72.0}
{"epoch": 58, "training_loss": 792099.8530273438, "training_acc": 72.66666666666667, "val_loss": 171488.30181884766, "val_acc": 80.0}
{"epoch": 59, "training_loss": 498655.57958984375, "training_acc": 81.66666666666667, "val_loss": 203928.17700195312, "val_acc": 78.66666666666667}
