"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1063.6179666519165, "training_acc": 62.0, "val_loss": 103.52399909496307, "val_acc": 36.0}
{"epoch": 1, "training_loss": 433.3139455318451, "training_acc": 65.33333333333333, "val_loss": 66.2391020655632, "val_acc": 74.66666666666667}
{"epoch": 2, "training_loss": 334.29942655563354, "training_acc": 62.333333333333336, "val_loss": 126.26587390899658, "val_acc": 72.0}
{"epoch": 3, "training_loss": 310.157372713089, "training_acc": 68.33333333333333, "val_loss": 40.20029363036156, "val_acc": 77.33333333333333}
{"epoch": 4, "training_loss": 194.64053463935852, "training_acc": 66.33333333333333, "val_loss": 42.490438997745514, "val_acc": 62.666666666666664}
{"epoch": 5, "training_loss": 212.2106740474701, "training_acc": 66.0, "val_loss": 50.14257335662842, "val_acc": 70.66666666666667}
{"epoch": 6, "training_loss": 187.04307782649994, "training_acc": 69.66666666666667, "val_loss": 70.15497660636902, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 226.09794878959656, "training_acc": 69.0, "val_loss": 52.57010763883591, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 196.16736268997192, "training_acc": 73.0, "val_loss": 56.80313318967819, "val_acc": 72.0}
{"epoch": 9, "training_loss": 225.495183467865, "training_acc": 64.33333333333333, "val_loss": 62.32740545272827, "val_acc": 72.0}
{"epoch": 10, "training_loss": 224.9730761051178, "training_acc": 70.33333333333333, "val_loss": 37.234355092048645, "val_acc": 81.33333333333333}
{"epoch": 11, "training_loss": 195.01345705986023, "training_acc": 70.0, "val_loss": 39.014003574848175, "val_acc": 76.0}
{"epoch": 12, "training_loss": 189.8379044532776, "training_acc": 70.66666666666667, "val_loss": 41.35804086923599, "val_acc": 72.0}
{"epoch": 13, "training_loss": 155.69107842445374, "training_acc": 76.0, "val_loss": 38.99871811270714, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 145.21988105773926, "training_acc": 73.0, "val_loss": 41.11565786600113, "val_acc": 64.0}
{"epoch": 15, "training_loss": 144.45408165454865, "training_acc": 76.33333333333333, "val_loss": 40.06868714094162, "val_acc": 72.0}
{"epoch": 16, "training_loss": 143.3495010137558, "training_acc": 76.66666666666667, "val_loss": 41.28094059228897, "val_acc": 78.66666666666667}
{"epoch": 17, "training_loss": 150.96800100803375, "training_acc": 78.33333333333333, "val_loss": 44.05664002895355, "val_acc": 72.0}
{"epoch": 18, "training_loss": 155.8681604862213, "training_acc": 75.0, "val_loss": 70.06866693496704, "val_acc": 72.0}
{"epoch": 19, "training_loss": 223.51657557487488, "training_acc": 61.666666666666664, "val_loss": 93.29582357406616, "val_acc": 72.0}
{"epoch": 20, "training_loss": 273.96399760246277, "training_acc": 67.33333333333333, "val_loss": 51.64744785428047, "val_acc": 74.66666666666667}
{"epoch": 21, "training_loss": 215.97934699058533, "training_acc": 74.33333333333333, "val_loss": 46.96124505996704, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 193.8373076915741, "training_acc": 76.66666666666667, "val_loss": 42.0994992852211, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 154.27731227874756, "training_acc": 77.33333333333333, "val_loss": 40.70782995223999, "val_acc": 65.33333333333333}
{"epoch": 24, "training_loss": 155.46576070785522, "training_acc": 74.0, "val_loss": 40.30543750524521, "val_acc": 66.66666666666667}
{"epoch": 25, "training_loss": 171.2644863128662, "training_acc": 71.33333333333333, "val_loss": 44.00477409362793, "val_acc": 76.0}
{"epoch": 26, "training_loss": 152.93971729278564, "training_acc": 76.66666666666667, "val_loss": 43.932421147823334, "val_acc": 74.66666666666667}
{"epoch": 27, "training_loss": 133.42628014087677, "training_acc": 79.66666666666667, "val_loss": 46.91122168302536, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 139.08628749847412, "training_acc": 77.0, "val_loss": 62.17028880119324, "val_acc": 72.0}
{"epoch": 29, "training_loss": 191.99967777729034, "training_acc": 73.33333333333333, "val_loss": 57.53729346394539, "val_acc": 72.0}
