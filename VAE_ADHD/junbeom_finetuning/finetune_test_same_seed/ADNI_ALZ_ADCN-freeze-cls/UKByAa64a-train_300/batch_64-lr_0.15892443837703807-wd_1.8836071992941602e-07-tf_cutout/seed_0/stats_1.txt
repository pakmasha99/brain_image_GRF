"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1158.064698457718, "training_acc": 70.33333333333333, "val_loss": 495.1081380844116, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1003.0386848449707, "training_acc": 53.666666666666664, "val_loss": 329.4966011047363, "val_acc": 72.0}
{"epoch": 2, "training_loss": 814.2736015319824, "training_acc": 71.33333333333333, "val_loss": 194.9427444934845, "val_acc": 48.0}
{"epoch": 3, "training_loss": 442.513126373291, "training_acc": 65.0, "val_loss": 142.1162600517273, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 322.51682806015015, "training_acc": 66.33333333333333, "val_loss": 83.13410234451294, "val_acc": 62.666666666666664}
{"epoch": 5, "training_loss": 200.73455595970154, "training_acc": 73.66666666666667, "val_loss": 82.90857684612274, "val_acc": 50.666666666666664}
{"epoch": 6, "training_loss": 218.63588523864746, "training_acc": 66.0, "val_loss": 73.61675643920898, "val_acc": 46.666666666666664}
{"epoch": 7, "training_loss": 193.35995507240295, "training_acc": 66.66666666666667, "val_loss": 52.9230882525444, "val_acc": 61.333333333333336}
{"epoch": 8, "training_loss": 157.2236224412918, "training_acc": 75.66666666666667, "val_loss": 48.762914955616, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 150.27579522132874, "training_acc": 74.33333333333333, "val_loss": 43.10065573453903, "val_acc": 64.0}
{"epoch": 10, "training_loss": 145.74642944335938, "training_acc": 77.33333333333333, "val_loss": 41.08548104763031, "val_acc": 66.66666666666667}
{"epoch": 11, "training_loss": 139.4002525806427, "training_acc": 80.0, "val_loss": 45.33250266313553, "val_acc": 65.33333333333333}
{"epoch": 12, "training_loss": 152.42884373664856, "training_acc": 76.33333333333333, "val_loss": 46.22726729512215, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 137.80734884738922, "training_acc": 80.0, "val_loss": 44.78888359665871, "val_acc": 74.66666666666667}
{"epoch": 14, "training_loss": 140.5825800895691, "training_acc": 78.0, "val_loss": 44.57778662443161, "val_acc": 68.0}
{"epoch": 15, "training_loss": 137.33116590976715, "training_acc": 80.33333333333333, "val_loss": 53.26297515630722, "val_acc": 62.666666666666664}
{"epoch": 16, "training_loss": 148.11397743225098, "training_acc": 77.0, "val_loss": 48.76219576597214, "val_acc": 66.66666666666667}
{"epoch": 17, "training_loss": 156.84741115570068, "training_acc": 73.66666666666667, "val_loss": 47.34950602054596, "val_acc": 64.0}
{"epoch": 18, "training_loss": 168.40265035629272, "training_acc": 70.33333333333333, "val_loss": 57.73338842391968, "val_acc": 72.0}
{"epoch": 19, "training_loss": 155.1057722568512, "training_acc": 77.33333333333333, "val_loss": 62.395298570394516, "val_acc": 72.0}
{"epoch": 20, "training_loss": 149.8920338153839, "training_acc": 77.33333333333333, "val_loss": 50.42985740303993, "val_acc": 76.0}
{"epoch": 21, "training_loss": 127.30283117294312, "training_acc": 80.33333333333333, "val_loss": 45.86093616485596, "val_acc": 68.0}
{"epoch": 22, "training_loss": 122.85283327102661, "training_acc": 82.33333333333333, "val_loss": 45.409166514873505, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 126.539391040802, "training_acc": 82.0, "val_loss": 46.595229506492615, "val_acc": 68.0}
{"epoch": 24, "training_loss": 143.36257791519165, "training_acc": 79.33333333333333, "val_loss": 67.14239835739136, "val_acc": 53.333333333333336}
{"epoch": 25, "training_loss": 159.23430275917053, "training_acc": 74.0, "val_loss": 62.38345944881439, "val_acc": 58.666666666666664}
{"epoch": 26, "training_loss": 137.67950856685638, "training_acc": 79.33333333333333, "val_loss": 57.933850318193436, "val_acc": 61.333333333333336}
{"epoch": 27, "training_loss": 135.99561715126038, "training_acc": 80.0, "val_loss": 48.28772592544556, "val_acc": 74.66666666666667}
{"epoch": 28, "training_loss": 142.37733435630798, "training_acc": 77.66666666666667, "val_loss": 46.436384320259094, "val_acc": 72.0}
{"epoch": 29, "training_loss": 117.90136480331421, "training_acc": 82.66666666666667, "val_loss": 54.4903444647789, "val_acc": 64.0}
