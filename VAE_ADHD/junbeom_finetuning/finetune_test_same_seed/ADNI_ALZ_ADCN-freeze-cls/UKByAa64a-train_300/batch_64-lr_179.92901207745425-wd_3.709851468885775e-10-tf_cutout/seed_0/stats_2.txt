"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3496287.5964279175, "training_acc": 56.333333333333336, "val_loss": 111065.50476074219, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1263469.685546875, "training_acc": 50.333333333333336, "val_loss": 941599.234375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3774196.47265625, "training_acc": 72.33333333333333, "val_loss": 342517.0173339844, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1101711.267578125, "training_acc": 53.0, "val_loss": 210128.931640625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 840139.7353515625, "training_acc": 55.0, "val_loss": 467202.82861328125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1542080.455078125, "training_acc": 72.33333333333333, "val_loss": 606339.6259765625, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1269417.0747070312, "training_acc": 52.333333333333336, "val_loss": 58441.50149536133, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1325684.94921875, "training_acc": 44.333333333333336, "val_loss": 641458.431640625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1796721.1296386719, "training_acc": 72.33333333333333, "val_loss": 802068.4794921875, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2506873.84375, "training_acc": 41.0, "val_loss": 705124.671875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2356472.5556640625, "training_acc": 72.33333333333333, "val_loss": 131204.79296875, "val_acc": 28.0}
{"epoch": 11, "training_loss": 755283.6572265625, "training_acc": 54.333333333333336, "val_loss": 195341.263671875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 546357.2517089844, "training_acc": 61.0, "val_loss": 65123.04333496094, "val_acc": 28.0}
{"epoch": 13, "training_loss": 514260.9569091797, "training_acc": 56.0, "val_loss": 64034.30859375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 388797.27685546875, "training_acc": 61.0, "val_loss": 31027.674407958984, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1095728.083984375, "training_acc": 49.666666666666664, "val_loss": 525849.541015625, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1395842.6266174316, "training_acc": 75.0, "val_loss": 623358.3916015625, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1442758.0625, "training_acc": 50.333333333333336, "val_loss": 175309.0439453125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 815019.6064453125, "training_acc": 56.0, "val_loss": 435434.6640625, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1724442.064453125, "training_acc": 72.33333333333333, "val_loss": 182924.03540039062, "val_acc": 28.0}
{"epoch": 20, "training_loss": 863059.43359375, "training_acc": 55.0, "val_loss": 250653.53125, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1052562.521484375, "training_acc": 53.0, "val_loss": 275951.22607421875, "val_acc": 72.0}
{"epoch": 22, "training_loss": 875607.03515625, "training_acc": 66.33333333333333, "val_loss": 121216.00402832031, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1176684.521484375, "training_acc": 63.666666666666664, "val_loss": 231068.55712890625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 846538.5146484375, "training_acc": 53.666666666666664, "val_loss": 564420.0649414062, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2426490.01171875, "training_acc": 72.33333333333333, "val_loss": 172052.61083984375, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1282421.076171875, "training_acc": 42.333333333333336, "val_loss": 719409.5693359375, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3388288.32421875, "training_acc": 72.33333333333333, "val_loss": 571258.630859375, "val_acc": 72.0}
{"epoch": 28, "training_loss": 985704.1782226562, "training_acc": 54.0, "val_loss": 336127.2529296875, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2089172.09375, "training_acc": 72.33333333333333, "val_loss": 405192.9287109375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1279108.4283447266, "training_acc": 54.333333333333336, "val_loss": 261728.0458984375, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1256491.5693359375, "training_acc": 72.33333333333333, "val_loss": 117718.80285644531, "val_acc": 28.0}
{"epoch": 32, "training_loss": 949574.296875, "training_acc": 52.0, "val_loss": 356599.81201171875, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1049479.177734375, "training_acc": 60.333333333333336, "val_loss": 77901.60772705078, "val_acc": 72.0}
