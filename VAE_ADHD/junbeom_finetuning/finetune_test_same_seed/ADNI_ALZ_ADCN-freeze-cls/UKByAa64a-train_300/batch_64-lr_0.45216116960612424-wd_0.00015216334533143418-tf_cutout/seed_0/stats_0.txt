"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9273.220748901367, "training_acc": 54.666666666666664, "val_loss": 1268.656005859375, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 6474.477348327637, "training_acc": 64.0, "val_loss": 1436.0747871398926, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 4357.240633010864, "training_acc": 54.0, "val_loss": 644.8349924087524, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 2920.640064239502, "training_acc": 51.333333333333336, "val_loss": 727.9355220794678, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 5755.579902648926, "training_acc": 72.0, "val_loss": 813.6624059677124, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 5692.275230407715, "training_acc": 48.0, "val_loss": 585.0293521881104, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 4952.655746459961, "training_acc": 72.0, "val_loss": 998.5997014045715, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 3302.777551174164, "training_acc": 54.666666666666664, "val_loss": 389.68173122406006, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 1449.4400992393494, "training_acc": 61.333333333333336, "val_loss": 58.40710246562958, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 1110.8184823989868, "training_acc": 63.333333333333336, "val_loss": 273.5374946594238, "val_acc": 26.666666666666668}
{"epoch": 10, "training_loss": 836.0406894683838, "training_acc": 54.666666666666664, "val_loss": 442.74092197418213, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 1735.494089126587, "training_acc": 60.666666666666664, "val_loss": 508.4806215763092, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 2851.387098312378, "training_acc": 72.0, "val_loss": 375.7128233909607, "val_acc": 26.666666666666668}
{"epoch": 13, "training_loss": 1610.3044414520264, "training_acc": 56.0, "val_loss": 80.62804192304611, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 2747.7531089782715, "training_acc": 54.666666666666664, "val_loss": 919.73681640625, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 2783.003257751465, "training_acc": 67.33333333333333, "val_loss": 1709.2117385864258, "val_acc": 26.666666666666668}
{"epoch": 16, "training_loss": 4980.697677612305, "training_acc": 52.666666666666664, "val_loss": 2078.759147644043, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 5953.052006721497, "training_acc": 72.0, "val_loss": 1896.2996711730957, "val_acc": 26.666666666666668}
{"epoch": 18, "training_loss": 5891.275619506836, "training_acc": 45.333333333333336, "val_loss": 1512.5910873413086, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 5781.530654907227, "training_acc": 72.0, "val_loss": 227.26180839538574, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 1645.3255224227905, "training_acc": 52.666666666666664, "val_loss": 73.39900434017181, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 2806.3487396240234, "training_acc": 50.666666666666664, "val_loss": 1294.8377990722656, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 3838.670211791992, "training_acc": 66.0, "val_loss": 415.72786378860474, "val_acc": 26.666666666666668}
{"epoch": 23, "training_loss": 2188.9171199798584, "training_acc": 64.66666666666667, "val_loss": 61.09706902503967, "val_acc": 78.66666666666667}
{"epoch": 24, "training_loss": 3081.8256645202637, "training_acc": 50.666666666666664, "val_loss": 746.0560913085938, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 2521.1137313842773, "training_acc": 66.66666666666667, "val_loss": 1925.152774810791, "val_acc": 26.666666666666668}
{"epoch": 26, "training_loss": 5854.512802124023, "training_acc": 50.0, "val_loss": 2191.7448539733887, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 6779.886613845825, "training_acc": 72.0, "val_loss": 1086.9200477600098, "val_acc": 26.666666666666668}
