"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9217.828395843506, "training_acc": 57.0, "val_loss": 1271.8175506591797, "val_acc": 28.0}
{"epoch": 1, "training_loss": 6423.905952453613, "training_acc": 63.0, "val_loss": 1505.8232421875, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4785.2261691093445, "training_acc": 53.666666666666664, "val_loss": 672.5472269058228, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1907.5761539936066, "training_acc": 63.0, "val_loss": 70.48753070831299, "val_acc": 28.0}
{"epoch": 4, "training_loss": 1535.6780242919922, "training_acc": 55.0, "val_loss": 149.8600207567215, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1242.3264074325562, "training_acc": 60.333333333333336, "val_loss": 797.3741931915283, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4511.123264312744, "training_acc": 72.33333333333333, "val_loss": 372.15164279937744, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3104.3659229278564, "training_acc": 51.0, "val_loss": 452.4131016731262, "val_acc": 72.0}
{"epoch": 8, "training_loss": 901.9821105003357, "training_acc": 63.0, "val_loss": 746.9197578430176, "val_acc": 28.0}
{"epoch": 9, "training_loss": 3227.6111450195312, "training_acc": 53.666666666666664, "val_loss": 1281.3389682769775, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3909.1970596313477, "training_acc": 57.666666666666664, "val_loss": 107.81605219841003, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1810.5425119400024, "training_acc": 64.33333333333333, "val_loss": 43.54294925928116, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 626.4896907806396, "training_acc": 61.0, "val_loss": 423.9247121810913, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1776.134967803955, "training_acc": 59.666666666666664, "val_loss": 608.6453278064728, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3689.0514068603516, "training_acc": 72.33333333333333, "val_loss": 144.70601511001587, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3113.0042114257812, "training_acc": 52.333333333333336, "val_loss": 509.6281895637512, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1680.4533252716064, "training_acc": 57.0, "val_loss": 972.1661720275879, "val_acc": 72.0}
{"epoch": 17, "training_loss": 3242.2586631774902, "training_acc": 63.666666666666664, "val_loss": 466.39459466934204, "val_acc": 28.0}
{"epoch": 18, "training_loss": 3834.1267280578613, "training_acc": 59.666666666666664, "val_loss": 747.2593393325806, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4958.44734954834, "training_acc": 42.333333333333336, "val_loss": 1039.403157234192, "val_acc": 72.0}
{"epoch": 20, "training_loss": 8069.091110229492, "training_acc": 72.33333333333333, "val_loss": 2256.6863555908203, "val_acc": 72.0}
{"epoch": 21, "training_loss": 6161.166229248047, "training_acc": 64.33333333333333, "val_loss": 3068.5077209472656, "val_acc": 28.0}
{"epoch": 22, "training_loss": 5543.348007202148, "training_acc": 57.0, "val_loss": 1281.5656108856201, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3357.2514152526855, "training_acc": 59.0, "val_loss": 147.52673816680908, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1106.835678100586, "training_acc": 67.0, "val_loss": 46.18515783548355, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1124.046516418457, "training_acc": 67.0, "val_loss": 51.62929683923721, "val_acc": 70.66666666666667}
{"epoch": 26, "training_loss": 716.2587361335754, "training_acc": 63.0, "val_loss": 135.11762404441833, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1124.9381694793701, "training_acc": 59.666666666666664, "val_loss": 378.08173751831055, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1215.793544769287, "training_acc": 55.666666666666664, "val_loss": 69.35632246732712, "val_acc": 62.666666666666664}
{"epoch": 29, "training_loss": 1273.5054330825806, "training_acc": 66.66666666666667, "val_loss": 115.02719366550446, "val_acc": 72.0}
{"epoch": 30, "training_loss": 995.5098171234131, "training_acc": 61.0, "val_loss": 228.76675081253052, "val_acc": 72.0}
