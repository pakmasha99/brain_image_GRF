"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10826.49744796753, "training_acc": 65.0, "val_loss": 1263.2378549575806, "val_acc": 28.0}
{"epoch": 1, "training_loss": 5419.373382568359, "training_acc": 65.0, "val_loss": 1236.0117225646973, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4880.160402059555, "training_acc": 52.333333333333336, "val_loss": 569.0481667518616, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1891.395908355713, "training_acc": 61.0, "val_loss": 300.2276029586792, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1432.0068397521973, "training_acc": 61.0, "val_loss": 574.4368369579315, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2231.1991004943848, "training_acc": 51.0, "val_loss": 1280.9760837554932, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4520.312705993652, "training_acc": 72.33333333333333, "val_loss": 751.0636711120605, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2520.1191749572754, "training_acc": 51.666666666666664, "val_loss": 278.02122950553894, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1873.2728271484375, "training_acc": 52.333333333333336, "val_loss": 1035.9517269134521, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2003.9398412704468, "training_acc": 63.0, "val_loss": 438.52262902259827, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2240.372459769249, "training_acc": 73.33333333333333, "val_loss": 1195.5872087478638, "val_acc": 28.0}
{"epoch": 11, "training_loss": 4319.310089111328, "training_acc": 50.333333333333336, "val_loss": 1386.183448791504, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3194.04594039917, "training_acc": 57.666666666666664, "val_loss": 402.4422812461853, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2102.7700424194336, "training_acc": 73.0, "val_loss": 1196.9338760375977, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3742.4472427368164, "training_acc": 52.333333333333336, "val_loss": 1191.346477508545, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3444.601650238037, "training_acc": 56.333333333333336, "val_loss": 261.26177406311035, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2348.626558303833, "training_acc": 72.33333333333333, "val_loss": 835.692063331604, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2948.2524185180664, "training_acc": 51.666666666666664, "val_loss": 605.07093334198, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2046.479808807373, "training_acc": 55.666666666666664, "val_loss": 925.1853408813477, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2997.1174545288086, "training_acc": 64.33333333333333, "val_loss": 41.5152046084404, "val_acc": 77.33333333333333}
{"epoch": 20, "training_loss": 936.6632289886475, "training_acc": 68.33333333333333, "val_loss": 410.13037943840027, "val_acc": 28.0}
{"epoch": 21, "training_loss": 3115.1603507995605, "training_acc": 62.333333333333336, "val_loss": 528.2836995124817, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1697.657871246338, "training_acc": 54.0, "val_loss": 800.6538248062134, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3029.3532333374023, "training_acc": 57.666666666666664, "val_loss": 187.33273458480835, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1706.4166376590729, "training_acc": 73.66666666666667, "val_loss": 824.6814403533936, "val_acc": 28.0}
{"epoch": 25, "training_loss": 2768.343563079834, "training_acc": 58.666666666666664, "val_loss": 1082.3119735717773, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3581.0354537963867, "training_acc": 57.0, "val_loss": 95.0980418920517, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 1265.2302722930908, "training_acc": 72.66666666666667, "val_loss": 1249.3223886489868, "val_acc": 28.0}
{"epoch": 28, "training_loss": 3239.2792167663574, "training_acc": 53.666666666666664, "val_loss": 642.4601497650146, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1809.6260299682617, "training_acc": 54.333333333333336, "val_loss": 998.2565908432007, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3486.88623046875, "training_acc": 62.333333333333336, "val_loss": 371.3496241569519, "val_acc": 28.0}
{"epoch": 31, "training_loss": 3956.1220626831055, "training_acc": 61.0, "val_loss": 856.0433382987976, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2803.4226150512695, "training_acc": 55.0, "val_loss": 482.41775608062744, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1216.5446224212646, "training_acc": 66.66666666666667, "val_loss": 325.7695188522339, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1056.7361888885498, "training_acc": 66.0, "val_loss": 317.23894929885864, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1569.7692070007324, "training_acc": 65.66666666666667, "val_loss": 71.53836986422539, "val_acc": 68.0}
{"epoch": 36, "training_loss": 1900.2410898208618, "training_acc": 67.0, "val_loss": 111.50808525085449, "val_acc": 50.666666666666664}
{"epoch": 37, "training_loss": 755.3060233592987, "training_acc": 54.333333333333336, "val_loss": 393.87620544433594, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1430.5816221237183, "training_acc": 60.333333333333336, "val_loss": 596.4645256996155, "val_acc": 72.0}
