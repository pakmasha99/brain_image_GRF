"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8992.832260131836, "training_acc": 57.666666666666664, "val_loss": 2753.5284423828125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 6656.430961608887, "training_acc": 63.666666666666664, "val_loss": 1239.1764373779297, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4869.81715631485, "training_acc": 53.666666666666664, "val_loss": 551.0228958129883, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1784.8441789150238, "training_acc": 56.0, "val_loss": 676.8265552520752, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2666.6235358715057, "training_acc": 72.33333333333333, "val_loss": 1659.8499908447266, "val_acc": 28.0}
{"epoch": 5, "training_loss": 4082.2887268066406, "training_acc": 53.0, "val_loss": 848.7186832427979, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2519.993812561035, "training_acc": 51.666666666666664, "val_loss": 1079.410327911377, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3680.5247654914856, "training_acc": 72.33333333333333, "val_loss": 1664.0647449493408, "val_acc": 28.0}
{"epoch": 8, "training_loss": 3704.1756591796875, "training_acc": 50.333333333333336, "val_loss": 297.9228296279907, "val_acc": 72.0}
{"epoch": 9, "training_loss": 919.1962146759033, "training_acc": 54.0, "val_loss": 405.38575744628906, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1219.2697966098785, "training_acc": 64.33333333333333, "val_loss": 143.9722353219986, "val_acc": 72.0}
{"epoch": 11, "training_loss": 872.9608917236328, "training_acc": 65.0, "val_loss": 369.47824907302856, "val_acc": 28.0}
{"epoch": 12, "training_loss": 761.6659240722656, "training_acc": 56.333333333333336, "val_loss": 437.8238983154297, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1761.273681640625, "training_acc": 59.666666666666664, "val_loss": 556.8144383430481, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3055.4085655212402, "training_acc": 72.33333333333333, "val_loss": 261.31226778030396, "val_acc": 28.0}
{"epoch": 15, "training_loss": 801.3132953643799, "training_acc": 51.0, "val_loss": 395.8662405014038, "val_acc": 72.0}
{"epoch": 16, "training_loss": 965.3722524642944, "training_acc": 63.0, "val_loss": 168.18288445472717, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1420.5406455993652, "training_acc": 52.333333333333336, "val_loss": 61.64634293317795, "val_acc": 69.33333333333333}
{"epoch": 18, "training_loss": 991.3725891113281, "training_acc": 68.66666666666667, "val_loss": 130.67218399047852, "val_acc": 41.333333333333336}
{"epoch": 19, "training_loss": 3479.229591369629, "training_acc": 63.333333333333336, "val_loss": 694.3868103027344, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2466.7024459838867, "training_acc": 52.333333333333336, "val_loss": 1255.0947666168213, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4778.204544067383, "training_acc": 72.33333333333333, "val_loss": 86.1406010389328, "val_acc": 56.0}
{"epoch": 22, "training_loss": 1693.5273780822754, "training_acc": 59.0, "val_loss": 634.1716413497925, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1417.2817211151123, "training_acc": 63.0, "val_loss": 470.92240476608276, "val_acc": 72.0}
{"epoch": 24, "training_loss": 909.4242544174194, "training_acc": 66.66666666666667, "val_loss": 420.8131446838379, "val_acc": 72.0}
{"epoch": 25, "training_loss": 920.9502358436584, "training_acc": 63.0, "val_loss": 243.38213515281677, "val_acc": 28.0}
{"epoch": 26, "training_loss": 855.7151412963867, "training_acc": 61.666666666666664, "val_loss": 182.0402376651764, "val_acc": 72.0}
{"epoch": 27, "training_loss": 950.2143685817719, "training_acc": 64.66666666666667, "val_loss": 252.7188274860382, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1109.5607089996338, "training_acc": 63.666666666666664, "val_loss": 495.9515686035156, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2560.9979400634766, "training_acc": 50.333333333333336, "val_loss": 1112.9749965667725, "val_acc": 72.0}
{"epoch": 30, "training_loss": 4023.8919105529785, "training_acc": 72.33333333333333, "val_loss": 625.7380166053772, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2612.3988151550293, "training_acc": 51.0, "val_loss": 598.4325857162476, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2697.274200439453, "training_acc": 52.0, "val_loss": 1095.6979713439941, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3493.6240520477295, "training_acc": 72.33333333333333, "val_loss": 1300.4259948730469, "val_acc": 28.0}
{"epoch": 34, "training_loss": 3503.1100845336914, "training_acc": 52.666666666666664, "val_loss": 1214.4126963615417, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2888.6975927352905, "training_acc": 56.333333333333336, "val_loss": 562.6773900985718, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2805.479772567749, "training_acc": 72.33333333333333, "val_loss": 941.2238616943359, "val_acc": 28.0}
