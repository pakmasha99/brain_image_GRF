"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 200.87422585487366, "training_acc": 72.33333333333333, "val_loss": 42.48660761117935, "val_acc": 73.33333333333333}
{"epoch": 1, "training_loss": 171.97116899490356, "training_acc": 72.0, "val_loss": 42.6288770288229, "val_acc": 72.0}
{"epoch": 2, "training_loss": 162.89652061462402, "training_acc": 75.0, "val_loss": 40.80571377277374, "val_acc": 72.0}
{"epoch": 3, "training_loss": 165.47210097312927, "training_acc": 74.33333333333333, "val_loss": 41.06012696027756, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 163.1098291873932, "training_acc": 73.33333333333333, "val_loss": 39.903153508901596, "val_acc": 72.0}
{"epoch": 5, "training_loss": 168.17011618614197, "training_acc": 72.33333333333333, "val_loss": 39.67601656913757, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 161.07393980026245, "training_acc": 74.33333333333333, "val_loss": 38.792482912540436, "val_acc": 76.0}
{"epoch": 7, "training_loss": 160.90767192840576, "training_acc": 74.66666666666667, "val_loss": 40.41822957992554, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 162.5002179145813, "training_acc": 72.33333333333333, "val_loss": 38.320166289806366, "val_acc": 76.0}
{"epoch": 9, "training_loss": 160.2041666507721, "training_acc": 75.0, "val_loss": 39.58251363039017, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 160.10354149341583, "training_acc": 73.66666666666667, "val_loss": 38.69990357756615, "val_acc": 76.0}
{"epoch": 11, "training_loss": 162.1204605102539, "training_acc": 73.33333333333333, "val_loss": 38.39777320623398, "val_acc": 76.0}
{"epoch": 12, "training_loss": 159.84354996681213, "training_acc": 73.33333333333333, "val_loss": 40.6434189081192, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 160.25909733772278, "training_acc": 72.66666666666667, "val_loss": 38.269291639328, "val_acc": 77.33333333333333}
{"epoch": 14, "training_loss": 161.57895803451538, "training_acc": 75.0, "val_loss": 41.14724189043045, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 157.84954023361206, "training_acc": 72.33333333333333, "val_loss": 38.34124135971069, "val_acc": 77.33333333333333}
{"epoch": 16, "training_loss": 160.25513076782227, "training_acc": 73.33333333333333, "val_loss": 40.7594358921051, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 160.69553637504578, "training_acc": 75.66666666666667, "val_loss": 38.420859426259995, "val_acc": 78.66666666666667}
{"epoch": 18, "training_loss": 159.90125346183777, "training_acc": 72.66666666666667, "val_loss": 38.713981717824936, "val_acc": 74.66666666666667}
{"epoch": 19, "training_loss": 156.91816329956055, "training_acc": 77.33333333333333, "val_loss": 39.3124635219574, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 154.4056762456894, "training_acc": 75.0, "val_loss": 39.27361112833023, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 158.5256873369217, "training_acc": 74.0, "val_loss": 38.73103731870651, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 157.29821705818176, "training_acc": 74.33333333333333, "val_loss": 38.16109275817871, "val_acc": 78.66666666666667}
{"epoch": 23, "training_loss": 157.37143850326538, "training_acc": 74.33333333333333, "val_loss": 38.418591022491455, "val_acc": 74.66666666666667}
{"epoch": 24, "training_loss": 159.78488421440125, "training_acc": 76.66666666666667, "val_loss": 40.96625044941902, "val_acc": 72.0}
{"epoch": 25, "training_loss": 158.50382781028748, "training_acc": 75.33333333333333, "val_loss": 38.01971831917763, "val_acc": 77.33333333333333}
{"epoch": 26, "training_loss": 155.08288955688477, "training_acc": 77.33333333333333, "val_loss": 43.93723350763321, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 159.36194396018982, "training_acc": 72.66666666666667, "val_loss": 38.28874534368515, "val_acc": 77.33333333333333}
{"epoch": 28, "training_loss": 157.53093242645264, "training_acc": 73.33333333333333, "val_loss": 40.945240527391434, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 156.2357532978058, "training_acc": 75.66666666666667, "val_loss": 38.40921604633331, "val_acc": 78.66666666666667}
{"epoch": 30, "training_loss": 157.8897557258606, "training_acc": 74.33333333333333, "val_loss": 39.227142333984375, "val_acc": 72.0}
{"epoch": 31, "training_loss": 162.51765632629395, "training_acc": 75.0, "val_loss": 40.781920433044434, "val_acc": 72.0}
{"epoch": 32, "training_loss": 163.40012753009796, "training_acc": 72.66666666666667, "val_loss": 38.277776420116425, "val_acc": 77.33333333333333}
{"epoch": 33, "training_loss": 156.92266178131104, "training_acc": 75.66666666666667, "val_loss": 41.325764536857605, "val_acc": 72.0}
{"epoch": 34, "training_loss": 156.59605956077576, "training_acc": 73.0, "val_loss": 39.29777252674103, "val_acc": 74.66666666666667}
{"epoch": 35, "training_loss": 159.8115336894989, "training_acc": 74.33333333333333, "val_loss": 43.20504307746887, "val_acc": 72.0}
{"epoch": 36, "training_loss": 160.40550112724304, "training_acc": 73.66666666666667, "val_loss": 38.595241010189056, "val_acc": 76.0}
{"epoch": 37, "training_loss": 161.66361570358276, "training_acc": 75.33333333333333, "val_loss": 42.696324586868286, "val_acc": 72.0}
{"epoch": 38, "training_loss": 156.76532983779907, "training_acc": 73.66666666666667, "val_loss": 38.10163277387619, "val_acc": 76.0}
{"epoch": 39, "training_loss": 153.34964752197266, "training_acc": 76.66666666666667, "val_loss": 40.85394901037216, "val_acc": 72.0}
{"epoch": 40, "training_loss": 154.0680797100067, "training_acc": 76.0, "val_loss": 38.06361120939255, "val_acc": 77.33333333333333}
{"epoch": 41, "training_loss": 153.76528882980347, "training_acc": 75.0, "val_loss": 40.622876703739166, "val_acc": 70.66666666666667}
{"epoch": 42, "training_loss": 153.83693838119507, "training_acc": 75.33333333333333, "val_loss": 38.21927002072334, "val_acc": 77.33333333333333}
{"epoch": 43, "training_loss": 159.10631000995636, "training_acc": 75.0, "val_loss": 44.836825013160706, "val_acc": 70.66666666666667}
{"epoch": 44, "training_loss": 163.6374545097351, "training_acc": 73.33333333333333, "val_loss": 40.00330808758736, "val_acc": 72.0}
