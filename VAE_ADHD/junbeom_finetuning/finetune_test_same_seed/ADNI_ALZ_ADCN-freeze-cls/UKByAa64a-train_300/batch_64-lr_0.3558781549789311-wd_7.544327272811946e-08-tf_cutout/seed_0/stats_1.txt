"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2397.6871490478516, "training_acc": 67.0, "val_loss": 1183.5803365707397, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2600.402172088623, "training_acc": 57.333333333333336, "val_loss": 911.7313318252563, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2380.4324350357056, "training_acc": 70.0, "val_loss": 462.9606957435608, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 1243.3269805908203, "training_acc": 59.666666666666664, "val_loss": 429.112820148468, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 1063.9742007255554, "training_acc": 76.33333333333333, "val_loss": 302.77165961265564, "val_acc": 52.0}
{"epoch": 5, "training_loss": 743.4555940628052, "training_acc": 64.66666666666667, "val_loss": 346.6504988670349, "val_acc": 69.33333333333333}
{"epoch": 6, "training_loss": 749.8399963378906, "training_acc": 68.66666666666667, "val_loss": 215.92137598991394, "val_acc": 52.0}
{"epoch": 7, "training_loss": 504.2598042488098, "training_acc": 67.33333333333333, "val_loss": 127.899609208107, "val_acc": 62.666666666666664}
{"epoch": 8, "training_loss": 317.9600577354431, "training_acc": 71.33333333333333, "val_loss": 130.06519508361816, "val_acc": 74.66666666666667}
{"epoch": 9, "training_loss": 294.4299840927124, "training_acc": 70.66666666666667, "val_loss": 100.22256898880005, "val_acc": 69.33333333333333}
{"epoch": 10, "training_loss": 249.28568840026855, "training_acc": 70.0, "val_loss": 50.90188863873482, "val_acc": 57.333333333333336}
{"epoch": 11, "training_loss": 203.02900981903076, "training_acc": 70.0, "val_loss": 53.01073870062828, "val_acc": 72.0}
{"epoch": 12, "training_loss": 185.12112092971802, "training_acc": 72.0, "val_loss": 64.75497877597809, "val_acc": 62.666666666666664}
{"epoch": 13, "training_loss": 158.39597463607788, "training_acc": 76.33333333333333, "val_loss": 79.98689246177673, "val_acc": 49.333333333333336}
{"epoch": 14, "training_loss": 199.39089512825012, "training_acc": 66.66666666666667, "val_loss": 47.93193104863167, "val_acc": 76.0}
{"epoch": 15, "training_loss": 129.96469593048096, "training_acc": 81.66666666666667, "val_loss": 51.67238736152649, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 125.83744549751282, "training_acc": 82.33333333333333, "val_loss": 62.27410453557968, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 137.99537754058838, "training_acc": 78.66666666666667, "val_loss": 52.08778738975525, "val_acc": 72.0}
{"epoch": 18, "training_loss": 146.32467460632324, "training_acc": 77.66666666666667, "val_loss": 83.0093549489975, "val_acc": 70.66666666666667}
{"epoch": 19, "training_loss": 201.59203028678894, "training_acc": 73.0, "val_loss": 103.45307683944702, "val_acc": 41.333333333333336}
{"epoch": 20, "training_loss": 257.35033774375916, "training_acc": 67.66666666666667, "val_loss": 84.8991873562336, "val_acc": 72.0}
{"epoch": 21, "training_loss": 216.08539080619812, "training_acc": 73.0, "val_loss": 74.02434027194977, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 152.07191157341003, "training_acc": 76.0, "val_loss": 80.52026081085205, "val_acc": 52.0}
{"epoch": 23, "training_loss": 225.0448923110962, "training_acc": 68.33333333333333, "val_loss": 77.2628344297409, "val_acc": 72.0}
{"epoch": 24, "training_loss": 176.47089087963104, "training_acc": 77.0, "val_loss": 62.8503475189209, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 109.54785680770874, "training_acc": 83.33333333333333, "val_loss": 46.78087994456291, "val_acc": 74.66666666666667}
{"epoch": 26, "training_loss": 122.53666031360626, "training_acc": 82.33333333333333, "val_loss": 61.50062268972397, "val_acc": 60.0}
{"epoch": 27, "training_loss": 176.76990675926208, "training_acc": 73.33333333333333, "val_loss": 91.09100580215454, "val_acc": 69.33333333333333}
{"epoch": 28, "training_loss": 191.16747093200684, "training_acc": 77.66666666666667, "val_loss": 64.99869155883789, "val_acc": 74.66666666666667}
{"epoch": 29, "training_loss": 138.8749442100525, "training_acc": 78.33333333333333, "val_loss": 59.4969779253006, "val_acc": 72.0}
{"epoch": 30, "training_loss": 155.0460307598114, "training_acc": 79.66666666666667, "val_loss": 148.69265460968018, "val_acc": 34.666666666666664}
{"epoch": 31, "training_loss": 229.47881388664246, "training_acc": 71.0, "val_loss": 69.23264223337173, "val_acc": 72.0}
{"epoch": 32, "training_loss": 167.78751254081726, "training_acc": 78.0, "val_loss": 78.72538435459137, "val_acc": 50.666666666666664}
{"epoch": 33, "training_loss": 128.16315734386444, "training_acc": 80.33333333333333, "val_loss": 54.82529538869858, "val_acc": 69.33333333333333}
{"epoch": 34, "training_loss": 138.4111189842224, "training_acc": 78.33333333333333, "val_loss": 101.2964793741703, "val_acc": 42.666666666666664}
{"epoch": 35, "training_loss": 190.44969391822815, "training_acc": 72.0, "val_loss": 67.10327768325806, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 141.86538994312286, "training_acc": 81.33333333333333, "val_loss": 59.630857944488525, "val_acc": 70.66666666666667}
{"epoch": 37, "training_loss": 129.6591727733612, "training_acc": 82.66666666666667, "val_loss": 64.17211174964905, "val_acc": 65.33333333333333}
{"epoch": 38, "training_loss": 131.00051951408386, "training_acc": 81.66666666666667, "val_loss": 55.972081661224365, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 108.04055845737457, "training_acc": 84.66666666666667, "val_loss": 63.35247886180878, "val_acc": 70.66666666666667}
{"epoch": 40, "training_loss": 134.48730146884918, "training_acc": 81.0, "val_loss": 107.55434846878052, "val_acc": 41.333333333333336}
{"epoch": 41, "training_loss": 261.6839642524719, "training_acc": 63.666666666666664, "val_loss": 122.1947653889656, "val_acc": 70.66666666666667}
{"epoch": 42, "training_loss": 268.42821073532104, "training_acc": 71.33333333333333, "val_loss": 127.29346972703934, "val_acc": 70.66666666666667}
{"epoch": 43, "training_loss": 242.1562361717224, "training_acc": 74.66666666666667, "val_loss": 65.20507955551147, "val_acc": 73.33333333333333}
{"epoch": 44, "training_loss": 210.59964191913605, "training_acc": 75.33333333333333, "val_loss": 133.28214752674103, "val_acc": 42.666666666666664}
