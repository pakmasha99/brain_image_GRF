"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5045.657363891602, "training_acc": 62.666666666666664, "val_loss": 1711.8086566925049, "val_acc": 28.0}
{"epoch": 1, "training_loss": 5004.090400695801, "training_acc": 55.666666666666664, "val_loss": 1499.7962231636047, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3375.3150310516357, "training_acc": 68.0, "val_loss": 700.3603172302246, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 2120.958360671997, "training_acc": 63.333333333333336, "val_loss": 750.640362739563, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1690.2880744934082, "training_acc": 72.0, "val_loss": 498.9258728027344, "val_acc": 53.333333333333336}
{"epoch": 5, "training_loss": 1076.5884504318237, "training_acc": 69.33333333333333, "val_loss": 279.68603324890137, "val_acc": 68.0}
{"epoch": 6, "training_loss": 867.6686277389526, "training_acc": 62.333333333333336, "val_loss": 305.15382289886475, "val_acc": 72.0}
{"epoch": 7, "training_loss": 657.5864582061768, "training_acc": 69.0, "val_loss": 96.25124090909958, "val_acc": 64.0}
{"epoch": 8, "training_loss": 237.93588304519653, "training_acc": 72.33333333333333, "val_loss": 66.87204456329346, "val_acc": 68.0}
{"epoch": 9, "training_loss": 424.67390990257263, "training_acc": 68.0, "val_loss": 162.10046339035034, "val_acc": 42.666666666666664}
{"epoch": 10, "training_loss": 596.1207418441772, "training_acc": 65.66666666666667, "val_loss": 95.83686590194702, "val_acc": 61.333333333333336}
{"epoch": 11, "training_loss": 653.0610790252686, "training_acc": 69.33333333333333, "val_loss": 102.24474629759789, "val_acc": 68.0}
{"epoch": 12, "training_loss": 771.7125091552734, "training_acc": 66.66666666666667, "val_loss": 163.88521552085876, "val_acc": 53.333333333333336}
{"epoch": 13, "training_loss": 727.2776129245758, "training_acc": 71.33333333333333, "val_loss": 365.7007575035095, "val_acc": 30.666666666666668}
{"epoch": 14, "training_loss": 920.6866617202759, "training_acc": 65.0, "val_loss": 167.66949820518494, "val_acc": 69.33333333333333}
{"epoch": 15, "training_loss": 458.8424129486084, "training_acc": 73.33333333333333, "val_loss": 152.44978058338165, "val_acc": 66.66666666666667}
{"epoch": 16, "training_loss": 364.02428150177, "training_acc": 74.66666666666667, "val_loss": 81.12897470593452, "val_acc": 72.0}
{"epoch": 17, "training_loss": 258.88215935230255, "training_acc": 73.66666666666667, "val_loss": 74.62067776918411, "val_acc": 54.666666666666664}
{"epoch": 18, "training_loss": 158.87329876422882, "training_acc": 78.0, "val_loss": 54.03912711143494, "val_acc": 72.0}
{"epoch": 19, "training_loss": 193.6575243473053, "training_acc": 74.66666666666667, "val_loss": 49.92735677957535, "val_acc": 68.0}
{"epoch": 20, "training_loss": 422.6627073287964, "training_acc": 70.0, "val_loss": 438.9256715774536, "val_acc": 30.666666666666668}
{"epoch": 21, "training_loss": 1348.531883239746, "training_acc": 62.0, "val_loss": 252.01243114471436, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1134.724380493164, "training_acc": 63.333333333333336, "val_loss": 461.0600552558899, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1228.2439517974854, "training_acc": 68.0, "val_loss": 196.20716857910156, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1333.1125192642212, "training_acc": 73.0, "val_loss": 244.8226716518402, "val_acc": 50.666666666666664}
{"epoch": 25, "training_loss": 814.6870031356812, "training_acc": 65.0, "val_loss": 149.21796771883965, "val_acc": 69.33333333333333}
{"epoch": 26, "training_loss": 514.2568693161011, "training_acc": 70.66666666666667, "val_loss": 159.55919289588928, "val_acc": 72.0}
{"epoch": 27, "training_loss": 490.3737859725952, "training_acc": 71.33333333333333, "val_loss": 151.32629120349884, "val_acc": 72.0}
{"epoch": 28, "training_loss": 420.6262273788452, "training_acc": 70.33333333333333, "val_loss": 123.07513403892517, "val_acc": 52.0}
{"epoch": 29, "training_loss": 372.3603398799896, "training_acc": 70.33333333333333, "val_loss": 229.18195462226868, "val_acc": 45.333333333333336}
{"epoch": 30, "training_loss": 458.3841562271118, "training_acc": 69.0, "val_loss": 156.7131049633026, "val_acc": 50.666666666666664}
{"epoch": 31, "training_loss": 295.1341574192047, "training_acc": 77.33333333333333, "val_loss": 58.879293382167816, "val_acc": 68.0}
{"epoch": 32, "training_loss": 170.8817114830017, "training_acc": 79.0, "val_loss": 59.9661368727684, "val_acc": 65.33333333333333}
{"epoch": 33, "training_loss": 120.81203877925873, "training_acc": 83.66666666666667, "val_loss": 59.27493607997894, "val_acc": 76.0}
{"epoch": 34, "training_loss": 153.32890903949738, "training_acc": 81.33333333333333, "val_loss": 104.40677189826965, "val_acc": 42.666666666666664}
{"epoch": 35, "training_loss": 225.18208122253418, "training_acc": 74.0, "val_loss": 68.78640472888947, "val_acc": 78.66666666666667}
{"epoch": 36, "training_loss": 187.64762210845947, "training_acc": 82.0, "val_loss": 79.44169020652771, "val_acc": 76.0}
{"epoch": 37, "training_loss": 174.70170843601227, "training_acc": 79.66666666666667, "val_loss": 98.64663398265839, "val_acc": 48.0}
{"epoch": 38, "training_loss": 187.81965696811676, "training_acc": 75.66666666666667, "val_loss": 75.12852108478546, "val_acc": 77.33333333333333}
