"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4622.9294509887695, "training_acc": 54.333333333333336, "val_loss": 263.83962965011597, "val_acc": 57.333333333333336}
{"epoch": 1, "training_loss": 2092.336483001709, "training_acc": 65.66666666666667, "val_loss": 243.95662927627563, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 1340.8760571479797, "training_acc": 62.666666666666664, "val_loss": 245.54410338401794, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 601.8190765380859, "training_acc": 68.0, "val_loss": 119.15813863277435, "val_acc": 57.333333333333336}
{"epoch": 4, "training_loss": 407.56345653533936, "training_acc": 61.666666666666664, "val_loss": 256.2328646183014, "val_acc": 72.0}
{"epoch": 5, "training_loss": 810.5839853286743, "training_acc": 61.666666666666664, "val_loss": 362.78263235092163, "val_acc": 72.0}
{"epoch": 6, "training_loss": 816.6942925453186, "training_acc": 66.0, "val_loss": 287.0158395767212, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 995.4103479385376, "training_acc": 64.33333333333333, "val_loss": 167.54435014724731, "val_acc": 72.0}
{"epoch": 8, "training_loss": 616.9259347915649, "training_acc": 67.66666666666667, "val_loss": 168.89465928077698, "val_acc": 72.0}
{"epoch": 9, "training_loss": 597.5326471328735, "training_acc": 64.66666666666667, "val_loss": 179.4704633951187, "val_acc": 72.0}
{"epoch": 10, "training_loss": 496.0599081516266, "training_acc": 70.33333333333333, "val_loss": 111.52637720108032, "val_acc": 72.0}
{"epoch": 11, "training_loss": 356.10623383522034, "training_acc": 72.33333333333333, "val_loss": 51.76000261306763, "val_acc": 76.0}
{"epoch": 12, "training_loss": 340.3759801387787, "training_acc": 68.0, "val_loss": 71.45683908462524, "val_acc": 61.333333333333336}
{"epoch": 13, "training_loss": 283.6032830476761, "training_acc": 68.66666666666667, "val_loss": 105.98028391599655, "val_acc": 72.0}
{"epoch": 14, "training_loss": 266.68822157382965, "training_acc": 73.66666666666667, "val_loss": 58.36880940198898, "val_acc": 68.0}
{"epoch": 15, "training_loss": 149.16035854816437, "training_acc": 76.33333333333333, "val_loss": 61.80705142021179, "val_acc": 77.33333333333333}
{"epoch": 16, "training_loss": 195.74569392204285, "training_acc": 74.66666666666667, "val_loss": 64.54124945402145, "val_acc": 78.66666666666667}
{"epoch": 17, "training_loss": 175.098735332489, "training_acc": 76.33333333333333, "val_loss": 52.250688433647156, "val_acc": 80.0}
{"epoch": 18, "training_loss": 295.1887149810791, "training_acc": 72.33333333333333, "val_loss": 252.8416886329651, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1187.2252740859985, "training_acc": 52.666666666666664, "val_loss": 828.5697631835938, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3452.822361946106, "training_acc": 72.33333333333333, "val_loss": 213.0116784926504, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 1700.2049598693848, "training_acc": 58.0, "val_loss": 512.7599210739136, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1247.2327365875244, "training_acc": 67.33333333333333, "val_loss": 195.06010687351227, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 798.6418633460999, "training_acc": 69.33333333333333, "val_loss": 111.21538197994232, "val_acc": 60.0}
{"epoch": 24, "training_loss": 535.5402145385742, "training_acc": 66.33333333333333, "val_loss": 75.60479259490967, "val_acc": 77.33333333333333}
{"epoch": 25, "training_loss": 283.3707106113434, "training_acc": 77.66666666666667, "val_loss": 88.94125890731812, "val_acc": 72.0}
{"epoch": 26, "training_loss": 238.59818410873413, "training_acc": 75.0, "val_loss": 127.39329385757446, "val_acc": 50.666666666666664}
{"epoch": 27, "training_loss": 224.3907458782196, "training_acc": 71.33333333333333, "val_loss": 82.64805853366852, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 164.62186336517334, "training_acc": 80.66666666666667, "val_loss": 58.92146027088165, "val_acc": 74.66666666666667}
{"epoch": 29, "training_loss": 128.20273506641388, "training_acc": 80.66666666666667, "val_loss": 66.96057724952698, "val_acc": 65.33333333333333}
{"epoch": 30, "training_loss": 141.41397047042847, "training_acc": 80.0, "val_loss": 128.90134570002556, "val_acc": 72.0}
