"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1857678.3274383545, "training_acc": 65.33333333333333, "val_loss": 858862.8642578125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1744308.375, "training_acc": 60.333333333333336, "val_loss": 587292.677734375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1233717.94140625, "training_acc": 71.33333333333333, "val_loss": 361376.7199707031, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 809463.4926757812, "training_acc": 69.0, "val_loss": 303181.8017578125, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 628158.0092773438, "training_acc": 70.33333333333333, "val_loss": 177135.8427734375, "val_acc": 57.333333333333336}
{"epoch": 5, "training_loss": 327506.7507324219, "training_acc": 71.33333333333333, "val_loss": 112518.6508178711, "val_acc": 52.0}
{"epoch": 6, "training_loss": 330867.4299316406, "training_acc": 56.666666666666664, "val_loss": 45052.72967529297, "val_acc": 69.33333333333333}
{"epoch": 7, "training_loss": 144787.66967773438, "training_acc": 69.66666666666667, "val_loss": 61819.620178222656, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 163583.98608398438, "training_acc": 68.66666666666667, "val_loss": 83584.87915039062, "val_acc": 38.666666666666664}
{"epoch": 9, "training_loss": 148295.0587158203, "training_acc": 63.666666666666664, "val_loss": 67792.53930664062, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 218678.29833984375, "training_acc": 64.33333333333333, "val_loss": 27085.35216140747, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 183149.2431640625, "training_acc": 68.33333333333333, "val_loss": 95763.63977050781, "val_acc": 49.333333333333336}
{"epoch": 12, "training_loss": 140561.02001953125, "training_acc": 70.66666666666667, "val_loss": 50129.500244140625, "val_acc": 65.33333333333333}
{"epoch": 13, "training_loss": 100257.23168945312, "training_acc": 73.66666666666667, "val_loss": 65824.80297851562, "val_acc": 69.33333333333333}
{"epoch": 14, "training_loss": 134758.13989257812, "training_acc": 70.66666666666667, "val_loss": 33197.232421875, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 141205.49047851562, "training_acc": 67.33333333333333, "val_loss": 50480.460021972656, "val_acc": 70.66666666666667}
{"epoch": 16, "training_loss": 138541.64794921875, "training_acc": 66.66666666666667, "val_loss": 49233.11486816406, "val_acc": 57.333333333333336}
{"epoch": 17, "training_loss": 117662.70031738281, "training_acc": 66.33333333333333, "val_loss": 53418.702224731445, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 69268.99670410156, "training_acc": 77.33333333333333, "val_loss": 24840.587478637695, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 88252.47583007812, "training_acc": 68.66666666666667, "val_loss": 68030.13977050781, "val_acc": 70.66666666666667}
{"epoch": 20, "training_loss": 335962.23828125, "training_acc": 62.0, "val_loss": 111594.35748291016, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 395262.2353515625, "training_acc": 69.66666666666667, "val_loss": 126620.33483886719, "val_acc": 56.0}
{"epoch": 22, "training_loss": 303244.8205566406, "training_acc": 73.33333333333333, "val_loss": 103111.27658081055, "val_acc": 61.333333333333336}
{"epoch": 23, "training_loss": 296244.7158203125, "training_acc": 67.33333333333333, "val_loss": 48455.236083984375, "val_acc": 74.66666666666667}
{"epoch": 24, "training_loss": 395051.01171875, "training_acc": 63.0, "val_loss": 260379.15380859375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 628015.7846679688, "training_acc": 61.0, "val_loss": 105809.19409179688, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 299948.2443847656, "training_acc": 77.66666666666667, "val_loss": 130540.05395507812, "val_acc": 61.333333333333336}
{"epoch": 27, "training_loss": 253138.01879882812, "training_acc": 71.33333333333333, "val_loss": 70463.68737792969, "val_acc": 76.0}
{"epoch": 28, "training_loss": 177909.60717773438, "training_acc": 69.33333333333333, "val_loss": 42834.06033325195, "val_acc": 74.66666666666667}
{"epoch": 29, "training_loss": 128548.85638427734, "training_acc": 74.66666666666667, "val_loss": 44584.518142700195, "val_acc": 65.33333333333333}
{"epoch": 30, "training_loss": 80075.45922851562, "training_acc": 76.66666666666667, "val_loss": 27147.48828125, "val_acc": 70.66666666666667}
{"epoch": 31, "training_loss": 167811.2109375, "training_acc": 67.0, "val_loss": 27297.988662719727, "val_acc": 66.66666666666667}
{"epoch": 32, "training_loss": 194734.35766601562, "training_acc": 69.0, "val_loss": 85992.42919921875, "val_acc": 56.0}
{"epoch": 33, "training_loss": 236761.84252929688, "training_acc": 66.33333333333333, "val_loss": 85147.49694824219, "val_acc": 53.333333333333336}
{"epoch": 34, "training_loss": 165567.13317871094, "training_acc": 69.33333333333333, "val_loss": 99915.00927734375, "val_acc": 52.0}
{"epoch": 35, "training_loss": 151248.2430419922, "training_acc": 68.0, "val_loss": 65278.9351272583, "val_acc": 65.33333333333333}
{"epoch": 36, "training_loss": 111467.10961914062, "training_acc": 76.33333333333333, "val_loss": 44196.353103637695, "val_acc": 74.66666666666667}
{"epoch": 37, "training_loss": 133733.3994140625, "training_acc": 71.33333333333333, "val_loss": 76843.703125, "val_acc": 69.33333333333333}
