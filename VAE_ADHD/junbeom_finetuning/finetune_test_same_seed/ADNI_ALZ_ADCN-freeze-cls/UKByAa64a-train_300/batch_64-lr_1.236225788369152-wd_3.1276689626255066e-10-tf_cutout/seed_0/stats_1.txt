"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 22496.28953552246, "training_acc": 69.0, "val_loss": 722.771427154541, "val_acc": 28.0}
{"epoch": 1, "training_loss": 17743.86734008789, "training_acc": 64.33333333333333, "val_loss": 4238.232292175293, "val_acc": 72.0}
{"epoch": 2, "training_loss": 14800.512859344482, "training_acc": 49.666666666666664, "val_loss": 1450.1392574310303, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5648.05721282959, "training_acc": 55.666666666666664, "val_loss": 2444.4537715911865, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15947.772644042969, "training_acc": 72.33333333333333, "val_loss": 2392.5257301330566, "val_acc": 72.0}
{"epoch": 5, "training_loss": 19384.916122436523, "training_acc": 43.0, "val_loss": 1345.9056568145752, "val_acc": 72.0}
{"epoch": 6, "training_loss": 16083.299194335938, "training_acc": 72.33333333333333, "val_loss": 4446.734916687012, "val_acc": 72.0}
{"epoch": 7, "training_loss": 14400.43441772461, "training_acc": 60.333333333333336, "val_loss": 3299.5374069213867, "val_acc": 28.0}
{"epoch": 8, "training_loss": 12600.345306396484, "training_acc": 63.666666666666664, "val_loss": 4398.948883056641, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9331.808563232422, "training_acc": 71.0, "val_loss": 7383.037628173828, "val_acc": 28.0}
{"epoch": 10, "training_loss": 14720.010772705078, "training_acc": 54.333333333333336, "val_loss": 3831.5173416137695, "val_acc": 72.0}
{"epoch": 11, "training_loss": 11575.52880859375, "training_acc": 63.666666666666664, "val_loss": 5316.692939758301, "val_acc": 28.0}
{"epoch": 12, "training_loss": 18014.492614746094, "training_acc": 50.333333333333336, "val_loss": 7173.145294189453, "val_acc": 72.0}
{"epoch": 13, "training_loss": 21667.32649230957, "training_acc": 72.33333333333333, "val_loss": 139.38942956924438, "val_acc": 60.0}
{"epoch": 14, "training_loss": 7236.295104980469, "training_acc": 55.0, "val_loss": 2152.582960128784, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5564.940260887146, "training_acc": 56.666666666666664, "val_loss": 1360.9043045043945, "val_acc": 72.0}
{"epoch": 16, "training_loss": 5369.367607116699, "training_acc": 66.33333333333333, "val_loss": 149.79583168029785, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2588.3950729370117, "training_acc": 63.666666666666664, "val_loss": 1494.6097145080566, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3945.637310028076, "training_acc": 60.0, "val_loss": 834.3053407669067, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4177.705718994141, "training_acc": 56.666666666666664, "val_loss": 919.2284717559814, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2977.719093322754, "training_acc": 63.0, "val_loss": 1792.843116760254, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3249.732674598694, "training_acc": 62.666666666666664, "val_loss": 933.5255193710327, "val_acc": 28.0}
{"epoch": 22, "training_loss": 4355.179353713989, "training_acc": 59.666666666666664, "val_loss": 3305.8560523986816, "val_acc": 28.0}
{"epoch": 23, "training_loss": 8559.914855957031, "training_acc": 55.0, "val_loss": 2075.0873737335205, "val_acc": 72.0}
{"epoch": 24, "training_loss": 5446.962326049805, "training_acc": 53.666666666666664, "val_loss": 2903.169143676758, "val_acc": 72.0}
{"epoch": 25, "training_loss": 8653.833696126938, "training_acc": 74.33333333333333, "val_loss": 3932.414737701416, "val_acc": 28.0}
{"epoch": 26, "training_loss": 11426.260635375977, "training_acc": 48.333333333333336, "val_loss": 2260.8085441589355, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4135.613925933838, "training_acc": 61.0, "val_loss": 1193.0700254440308, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2979.1021518707275, "training_acc": 61.0, "val_loss": 247.10826921463013, "val_acc": 58.666666666666664}
{"epoch": 29, "training_loss": 3744.028434753418, "training_acc": 65.33333333333333, "val_loss": 892.7057185173035, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2355.670913696289, "training_acc": 56.0, "val_loss": 622.6203603744507, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3177.1355595588684, "training_acc": 62.0, "val_loss": 1145.377498626709, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3628.9932174682617, "training_acc": 67.33333333333333, "val_loss": 702.0340924263, "val_acc": 72.0}
