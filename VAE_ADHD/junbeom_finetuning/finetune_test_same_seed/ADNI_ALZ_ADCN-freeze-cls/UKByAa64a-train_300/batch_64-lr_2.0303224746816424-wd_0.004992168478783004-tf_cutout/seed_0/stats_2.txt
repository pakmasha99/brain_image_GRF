"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 43567.26374053955, "training_acc": 55.0, "val_loss": 9834.304206848145, "val_acc": 28.0}
{"epoch": 1, "training_loss": 28148.772338867188, "training_acc": 64.33333333333333, "val_loss": 6161.536659240723, "val_acc": 72.0}
{"epoch": 2, "training_loss": 18203.367568969727, "training_acc": 55.0, "val_loss": 3512.016311645508, "val_acc": 72.0}
{"epoch": 3, "training_loss": 15371.1328125, "training_acc": 62.333333333333336, "val_loss": 4177.528167724609, "val_acc": 28.0}
{"epoch": 4, "training_loss": 12278.395065307617, "training_acc": 66.33333333333333, "val_loss": 1732.8867168426514, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9728.781707763672, "training_acc": 53.0, "val_loss": 6251.206520080566, "val_acc": 72.0}
{"epoch": 6, "training_loss": 17301.067260742188, "training_acc": 68.33333333333333, "val_loss": 2716.170108795166, "val_acc": 28.0}
{"epoch": 7, "training_loss": 11001.09521484375, "training_acc": 65.0, "val_loss": 522.6777257919312, "val_acc": 72.0}
{"epoch": 8, "training_loss": 13515.09487915039, "training_acc": 53.0, "val_loss": 4792.792589187622, "val_acc": 72.0}
{"epoch": 9, "training_loss": 14492.289924621582, "training_acc": 55.0, "val_loss": 2181.798397064209, "val_acc": 72.0}
{"epoch": 10, "training_loss": 14976.411590576172, "training_acc": 72.33333333333333, "val_loss": 1268.793888092041, "val_acc": 28.0}
{"epoch": 11, "training_loss": 3986.8143272399902, "training_acc": 61.333333333333336, "val_loss": 2430.2105140686035, "val_acc": 28.0}
{"epoch": 12, "training_loss": 7133.168411254883, "training_acc": 52.333333333333336, "val_loss": 1004.9026870727539, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4890.418981552124, "training_acc": 63.0, "val_loss": 318.5955364704132, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6439.810653686523, "training_acc": 59.666666666666664, "val_loss": 290.81950545310974, "val_acc": 42.666666666666664}
{"epoch": 15, "training_loss": 957.1902799606323, "training_acc": 66.33333333333333, "val_loss": 1362.0211248397827, "val_acc": 28.0}
{"epoch": 16, "training_loss": 5645.476606369019, "training_acc": 65.66666666666667, "val_loss": 4910.923004150391, "val_acc": 28.0}
{"epoch": 17, "training_loss": 17059.99105834961, "training_acc": 50.333333333333336, "val_loss": 5372.208869934082, "val_acc": 72.0}
{"epoch": 18, "training_loss": 16106.358367919922, "training_acc": 57.0, "val_loss": 701.3015127182007, "val_acc": 72.0}
{"epoch": 19, "training_loss": 7441.055694580078, "training_acc": 63.666666666666664, "val_loss": 457.5475926399231, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4111.854881286621, "training_acc": 63.0, "val_loss": 1423.2743835449219, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5365.260133743286, "training_acc": 57.666666666666664, "val_loss": 3691.352554321289, "val_acc": 28.0}
{"epoch": 22, "training_loss": 11341.14729309082, "training_acc": 56.666666666666664, "val_loss": 2385.4231758117676, "val_acc": 72.0}
{"epoch": 23, "training_loss": 6697.577850341797, "training_acc": 59.666666666666664, "val_loss": 2635.655870437622, "val_acc": 72.0}
{"epoch": 24, "training_loss": 9418.176483154297, "training_acc": 50.333333333333336, "val_loss": 5577.474388122559, "val_acc": 72.0}
{"epoch": 25, "training_loss": 20495.875732421875, "training_acc": 72.33333333333333, "val_loss": 995.9552965164185, "val_acc": 28.0}
{"epoch": 26, "training_loss": 10104.179412841797, "training_acc": 51.0, "val_loss": 3269.911087036133, "val_acc": 72.0}
{"epoch": 27, "training_loss": 12905.463134765625, "training_acc": 51.0, "val_loss": 3476.7877864837646, "val_acc": 72.0}
{"epoch": 28, "training_loss": 10323.941909790039, "training_acc": 69.0, "val_loss": 2388.2353706359863, "val_acc": 28.0}
{"epoch": 29, "training_loss": 12289.726379394531, "training_acc": 61.666666666666664, "val_loss": 1483.4397358894348, "val_acc": 72.0}
{"epoch": 30, "training_loss": 10778.801025390625, "training_acc": 52.333333333333336, "val_loss": 4292.770057678223, "val_acc": 72.0}
{"epoch": 31, "training_loss": 9658.618083953857, "training_acc": 57.666666666666664, "val_loss": 2895.9167137145996, "val_acc": 72.0}
{"epoch": 32, "training_loss": 16017.848922729492, "training_acc": 72.33333333333333, "val_loss": 430.7340965270996, "val_acc": 42.666666666666664}
{"epoch": 33, "training_loss": 8298.287124633789, "training_acc": 56.666666666666664, "val_loss": 2818.428985595703, "val_acc": 72.0}
