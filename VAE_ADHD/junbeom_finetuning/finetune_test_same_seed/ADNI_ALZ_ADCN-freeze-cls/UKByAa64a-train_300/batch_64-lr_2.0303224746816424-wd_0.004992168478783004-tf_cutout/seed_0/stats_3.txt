"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 39268.67192840576, "training_acc": 56.333333333333336, "val_loss": 641.4780440330505, "val_acc": 28.0}
{"epoch": 1, "training_loss": 30045.562774658203, "training_acc": 63.0, "val_loss": 7850.832542419434, "val_acc": 72.0}
{"epoch": 2, "training_loss": 13121.247528076172, "training_acc": 57.0, "val_loss": 5239.288391113281, "val_acc": 72.0}
{"epoch": 3, "training_loss": 16423.25523376465, "training_acc": 68.33333333333333, "val_loss": 1169.4612464904785, "val_acc": 28.0}
{"epoch": 4, "training_loss": 13203.189453125, "training_acc": 66.33333333333333, "val_loss": 1840.86181640625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 12940.518951416016, "training_acc": 51.0, "val_loss": 4474.24165725708, "val_acc": 72.0}
{"epoch": 6, "training_loss": 13081.653411865234, "training_acc": 67.66666666666667, "val_loss": 9882.840347290039, "val_acc": 28.0}
{"epoch": 7, "training_loss": 27302.084411621094, "training_acc": 53.666666666666664, "val_loss": 10989.218338012695, "val_acc": 72.0}
{"epoch": 8, "training_loss": 32743.28010559082, "training_acc": 72.33333333333333, "val_loss": 4631.335781097412, "val_acc": 28.0}
{"epoch": 9, "training_loss": 12100.770366668701, "training_acc": 48.333333333333336, "val_loss": 1007.3182792663574, "val_acc": 28.0}
{"epoch": 10, "training_loss": 6936.96696472168, "training_acc": 53.0, "val_loss": 350.84535217285156, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3378.943389892578, "training_acc": 65.0, "val_loss": 168.16717511415482, "val_acc": 72.0}
{"epoch": 12, "training_loss": 12435.591796875, "training_acc": 53.666666666666664, "val_loss": 5546.722839355469, "val_acc": 72.0}
{"epoch": 13, "training_loss": 15587.751708984375, "training_acc": 66.33333333333333, "val_loss": 3532.722385406494, "val_acc": 28.0}
{"epoch": 14, "training_loss": 9267.01053237915, "training_acc": 63.666666666666664, "val_loss": 845.3926458358765, "val_acc": 28.0}
{"epoch": 15, "training_loss": 3209.421127319336, "training_acc": 57.666666666666664, "val_loss": 1933.6829872131348, "val_acc": 72.0}
{"epoch": 16, "training_loss": 10521.81362915039, "training_acc": 56.333333333333336, "val_loss": 1943.0671119689941, "val_acc": 72.0}
{"epoch": 17, "training_loss": 11951.490356445312, "training_acc": 72.33333333333333, "val_loss": 1702.6433200836182, "val_acc": 28.0}
{"epoch": 18, "training_loss": 4891.237617492676, "training_acc": 63.0, "val_loss": 1647.5692768096924, "val_acc": 28.0}
{"epoch": 19, "training_loss": 5461.691871643066, "training_acc": 48.666666666666664, "val_loss": 1836.3661575317383, "val_acc": 72.0}
{"epoch": 20, "training_loss": 8639.756973266602, "training_acc": 65.0, "val_loss": 527.0550007820129, "val_acc": 28.0}
{"epoch": 21, "training_loss": 16076.223251342773, "training_acc": 65.0, "val_loss": 4549.969020843506, "val_acc": 72.0}
{"epoch": 22, "training_loss": 8663.549041748047, "training_acc": 54.666666666666664, "val_loss": 4022.5342559814453, "val_acc": 72.0}
{"epoch": 23, "training_loss": 12419.57861328125, "training_acc": 67.66666666666667, "val_loss": 4280.721702575684, "val_acc": 28.0}
{"epoch": 24, "training_loss": 10043.4896774292, "training_acc": 62.333333333333336, "val_loss": 192.97971630096436, "val_acc": 54.666666666666664}
{"epoch": 25, "training_loss": 3047.1230850219727, "training_acc": 59.0, "val_loss": 910.8401565551758, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4297.9790687561035, "training_acc": 65.0, "val_loss": 734.0096197128296, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4661.701854705811, "training_acc": 65.0, "val_loss": 743.7062091827393, "val_acc": 28.0}
{"epoch": 28, "training_loss": 5537.998046875, "training_acc": 55.0, "val_loss": 86.12497639656067, "val_acc": 78.66666666666667}
{"epoch": 29, "training_loss": 1715.9478759765625, "training_acc": 69.66666666666667, "val_loss": 2272.268810272217, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5365.861633300781, "training_acc": 63.0, "val_loss": 239.05056428909302, "val_acc": 48.0}
{"epoch": 31, "training_loss": 6238.111312866211, "training_acc": 56.666666666666664, "val_loss": 462.2382597923279, "val_acc": 28.0}
{"epoch": 32, "training_loss": 20267.82257080078, "training_acc": 63.0, "val_loss": 5824.658340454102, "val_acc": 72.0}
{"epoch": 33, "training_loss": 10646.956657409668, "training_acc": 52.333333333333336, "val_loss": 4114.6829833984375, "val_acc": 72.0}
{"epoch": 34, "training_loss": 14668.617706298828, "training_acc": 63.0, "val_loss": 3613.387969970703, "val_acc": 28.0}
{"epoch": 35, "training_loss": 16721.224243164062, "training_acc": 61.666666666666664, "val_loss": 2970.461748123169, "val_acc": 72.0}
{"epoch": 36, "training_loss": 18387.67063522339, "training_acc": 46.333333333333336, "val_loss": 5065.571708679199, "val_acc": 72.0}
{"epoch": 37, "training_loss": 40555.93927001953, "training_acc": 72.33333333333333, "val_loss": 10498.262191772461, "val_acc": 72.0}
{"epoch": 38, "training_loss": 23086.769638061523, "training_acc": 68.33333333333333, "val_loss": 10215.795677185059, "val_acc": 28.0}
{"epoch": 39, "training_loss": 31810.493530273438, "training_acc": 48.333333333333336, "val_loss": 10848.334609985352, "val_acc": 72.0}
{"epoch": 40, "training_loss": 30530.358234405518, "training_acc": 72.33333333333333, "val_loss": 7545.216156005859, "val_acc": 28.0}
{"epoch": 41, "training_loss": 25182.236602783203, "training_acc": 44.333333333333336, "val_loss": 8313.767414093018, "val_acc": 72.0}
{"epoch": 42, "training_loss": 30080.887664794922, "training_acc": 72.33333333333333, "val_loss": 509.8248748779297, "val_acc": 72.0}
{"epoch": 43, "training_loss": 26340.513389587402, "training_acc": 45.0, "val_loss": 5177.496580123901, "val_acc": 72.0}
{"epoch": 44, "training_loss": 25636.295204162598, "training_acc": 72.33333333333333, "val_loss": 1922.360975265503, "val_acc": 72.0}
{"epoch": 45, "training_loss": 10364.61262512207, "training_acc": 53.666666666666664, "val_loss": 3612.68408203125, "val_acc": 72.0}
{"epoch": 46, "training_loss": 12587.838623046875, "training_acc": 54.0, "val_loss": 2798.82373046875, "val_acc": 72.0}
{"epoch": 47, "training_loss": 21013.74740600586, "training_acc": 72.33333333333333, "val_loss": 2674.080005645752, "val_acc": 72.0}
