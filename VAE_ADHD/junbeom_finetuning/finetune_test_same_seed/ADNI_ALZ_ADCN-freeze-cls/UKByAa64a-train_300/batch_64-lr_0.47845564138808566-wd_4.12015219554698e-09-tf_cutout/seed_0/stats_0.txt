"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3297.161178588867, "training_acc": 64.33333333333333, "val_loss": 1168.9443368911743, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 2780.2944717407227, "training_acc": 61.666666666666664, "val_loss": 937.8884801864624, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 2430.1963329315186, "training_acc": 67.0, "val_loss": 489.7525215148926, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 1346.7932929992676, "training_acc": 64.66666666666667, "val_loss": 377.66450119018555, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 1312.1198816299438, "training_acc": 73.66666666666667, "val_loss": 335.4279565811157, "val_acc": 41.333333333333336}
{"epoch": 5, "training_loss": 992.3519191741943, "training_acc": 63.333333333333336, "val_loss": 86.88178277015686, "val_acc": 66.66666666666667}
{"epoch": 6, "training_loss": 681.9113121032715, "training_acc": 60.0, "val_loss": 272.5346122980118, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 664.5472972393036, "training_acc": 66.33333333333333, "val_loss": 162.0324535369873, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 642.7907943725586, "training_acc": 63.666666666666664, "val_loss": 70.51353693008423, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 605.6234350204468, "training_acc": 63.0, "val_loss": 56.72580052912235, "val_acc": 77.33333333333333}
{"epoch": 10, "training_loss": 396.6183547973633, "training_acc": 71.66666666666667, "val_loss": 56.50305414199829, "val_acc": 74.66666666666667}
{"epoch": 11, "training_loss": 270.0107169151306, "training_acc": 71.33333333333333, "val_loss": 49.99019458889961, "val_acc": 76.0}
{"epoch": 12, "training_loss": 197.86127042770386, "training_acc": 70.33333333333333, "val_loss": 52.37820291519165, "val_acc": 57.333333333333336}
{"epoch": 13, "training_loss": 261.5990619659424, "training_acc": 65.66666666666667, "val_loss": 88.05351400375366, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 266.4659175872803, "training_acc": 71.66666666666667, "val_loss": 54.71444030292332, "val_acc": 76.0}
{"epoch": 15, "training_loss": 258.5697865486145, "training_acc": 67.33333333333333, "val_loss": 53.2204675078392, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 292.3099181652069, "training_acc": 65.66666666666667, "val_loss": 151.24217057228088, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 418.7230806350708, "training_acc": 68.0, "val_loss": 60.280056565999985, "val_acc": 81.33333333333333}
{"epoch": 18, "training_loss": 233.55142617225647, "training_acc": 73.0, "val_loss": 37.75318717956543, "val_acc": 65.33333333333333}
{"epoch": 19, "training_loss": 182.58663368225098, "training_acc": 72.33333333333333, "val_loss": 71.12266765534878, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 165.9820522069931, "training_acc": 78.66666666666667, "val_loss": 69.29955637454987, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 328.6366572380066, "training_acc": 68.66666666666667, "val_loss": 31.342271506786346, "val_acc": 80.0}
{"epoch": 22, "training_loss": 298.95220482349396, "training_acc": 69.66666666666667, "val_loss": 122.63077187538147, "val_acc": 40.0}
{"epoch": 23, "training_loss": 343.21247959136963, "training_acc": 65.66666666666667, "val_loss": 30.91514080762863, "val_acc": 81.33333333333333}
{"epoch": 24, "training_loss": 194.11903715133667, "training_acc": 76.0, "val_loss": 53.81053930521011, "val_acc": 72.0}
{"epoch": 25, "training_loss": 130.37312579154968, "training_acc": 84.0, "val_loss": 27.626316010951996, "val_acc": 86.66666666666667}
{"epoch": 26, "training_loss": 143.37668812274933, "training_acc": 80.0, "val_loss": 76.05195379257202, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 431.77550506591797, "training_acc": 66.0, "val_loss": 80.72626823186874, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 471.8063278198242, "training_acc": 66.0, "val_loss": 62.52882495522499, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 330.9436249732971, "training_acc": 74.0, "val_loss": 43.59270578622818, "val_acc": 85.33333333333333}
{"epoch": 30, "training_loss": 357.2061367034912, "training_acc": 71.33333333333333, "val_loss": 191.8112645149231, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 553.9445934295654, "training_acc": 67.0, "val_loss": 70.8363938331604, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 303.6290521621704, "training_acc": 69.33333333333333, "val_loss": 47.697079598903656, "val_acc": 80.0}
{"epoch": 33, "training_loss": 252.29576563835144, "training_acc": 73.66666666666667, "val_loss": 75.88494849205017, "val_acc": 56.0}
{"epoch": 34, "training_loss": 232.16089344024658, "training_acc": 70.0, "val_loss": 104.20321583747864, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 529.8371241092682, "training_acc": 64.66666666666667, "val_loss": 135.07398331165314, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 578.140389919281, "training_acc": 62.0, "val_loss": 132.80010962486267, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 634.5648670196533, "training_acc": 73.33333333333333, "val_loss": 100.90680861473083, "val_acc": 64.0}
{"epoch": 38, "training_loss": 392.7361001968384, "training_acc": 73.0, "val_loss": 63.598374009132385, "val_acc": 64.0}
{"epoch": 39, "training_loss": 232.9184603691101, "training_acc": 73.66666666666667, "val_loss": 51.67252708226442, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 245.3348127603531, "training_acc": 71.66666666666667, "val_loss": 64.18750810623169, "val_acc": 76.0}
{"epoch": 41, "training_loss": 195.88434600830078, "training_acc": 77.66666666666667, "val_loss": 43.47925864905119, "val_acc": 84.0}
{"epoch": 42, "training_loss": 173.30763924121857, "training_acc": 79.0, "val_loss": 37.373358845710754, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 248.33136415481567, "training_acc": 67.66666666666667, "val_loss": 48.18018552660942, "val_acc": 81.33333333333333}
{"epoch": 44, "training_loss": 193.1346778869629, "training_acc": 76.66666666666667, "val_loss": 42.914152354002, "val_acc": 72.0}
