"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 856062.7299575806, "training_acc": 57.666666666666664, "val_loss": 293593.37939453125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 556062.0078125, "training_acc": 60.333333333333336, "val_loss": 73107.7080078125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 565249.0556640625, "training_acc": 45.0, "val_loss": 99999.96984863281, "val_acc": 72.0}
{"epoch": 3, "training_loss": 996945.994140625, "training_acc": 72.33333333333333, "val_loss": 271333.2900390625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 637366.2387695312, "training_acc": 67.0, "val_loss": 190272.31372070312, "val_acc": 28.0}
{"epoch": 5, "training_loss": 465393.46240234375, "training_acc": 51.666666666666664, "val_loss": 141705.9346923828, "val_acc": 72.0}
{"epoch": 6, "training_loss": 367228.3017578125, "training_acc": 67.66666666666667, "val_loss": 120320.9697265625, "val_acc": 28.0}
{"epoch": 7, "training_loss": 195151.62438964844, "training_acc": 63.0, "val_loss": 5449.6984786987305, "val_acc": 29.333333333333332}
{"epoch": 8, "training_loss": 77080.19049072266, "training_acc": 52.666666666666664, "val_loss": 28883.33868408203, "val_acc": 72.0}
{"epoch": 9, "training_loss": 103666.88720703125, "training_acc": 61.0, "val_loss": 15999.954071044922, "val_acc": 28.0}
{"epoch": 10, "training_loss": 148829.34985351562, "training_acc": 61.0, "val_loss": 86109.25659179688, "val_acc": 28.0}
{"epoch": 11, "training_loss": 310084.6640625, "training_acc": 52.333333333333336, "val_loss": 91487.69750976562, "val_acc": 72.0}
{"epoch": 12, "training_loss": 308400.154296875, "training_acc": 58.333333333333336, "val_loss": 1598.1640586853027, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 163349.8759765625, "training_acc": 72.66666666666667, "val_loss": 1960.8114862442017, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 77602.40060424805, "training_acc": 66.33333333333333, "val_loss": 36800.127502441406, "val_acc": 28.0}
{"epoch": 15, "training_loss": 105521.19604492188, "training_acc": 57.666666666666664, "val_loss": 2610.0363817662, "val_acc": 76.0}
{"epoch": 16, "training_loss": 59048.818115234375, "training_acc": 67.66666666666667, "val_loss": 27894.746215820312, "val_acc": 72.0}
{"epoch": 17, "training_loss": 75514.69848632812, "training_acc": 59.333333333333336, "val_loss": 13632.662879943848, "val_acc": 72.0}
{"epoch": 18, "training_loss": 89214.72863769531, "training_acc": 61.666666666666664, "val_loss": 18769.27734375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 118556.390625, "training_acc": 60.333333333333336, "val_loss": 99814.462890625, "val_acc": 72.0}
{"epoch": 20, "training_loss": 327540.6958618164, "training_acc": 72.33333333333333, "val_loss": 139449.27758789062, "val_acc": 28.0}
{"epoch": 21, "training_loss": 401945.42431640625, "training_acc": 47.333333333333336, "val_loss": 210923.01733398438, "val_acc": 72.0}
{"epoch": 22, "training_loss": 808732.0166015625, "training_acc": 72.33333333333333, "val_loss": 71676.86669921875, "val_acc": 72.0}
{"epoch": 23, "training_loss": 190830.0008544922, "training_acc": 52.333333333333336, "val_loss": 24081.845825195312, "val_acc": 72.0}
{"epoch": 24, "training_loss": 48407.66931152344, "training_acc": 61.0, "val_loss": 34897.65246582031, "val_acc": 72.0}
{"epoch": 25, "training_loss": 180755.03759765625, "training_acc": 63.0, "val_loss": 43093.046325683594, "val_acc": 28.0}
{"epoch": 26, "training_loss": 386673.15380859375, "training_acc": 62.333333333333336, "val_loss": 102363.30981445312, "val_acc": 72.0}
{"epoch": 27, "training_loss": 248632.1375732422, "training_acc": 51.0, "val_loss": 67009.390625, "val_acc": 72.0}
{"epoch": 28, "training_loss": 254298.38623046875, "training_acc": 63.0, "val_loss": 81905.09924316406, "val_acc": 28.0}
{"epoch": 29, "training_loss": 250336.22045898438, "training_acc": 63.0, "val_loss": 36558.132415771484, "val_acc": 72.0}
{"epoch": 30, "training_loss": 48489.1591796875, "training_acc": 65.33333333333333, "val_loss": 6221.99528503418, "val_acc": 72.0}
{"epoch": 31, "training_loss": 79835.1962890625, "training_acc": 66.33333333333333, "val_loss": 20597.072036743164, "val_acc": 72.0}
