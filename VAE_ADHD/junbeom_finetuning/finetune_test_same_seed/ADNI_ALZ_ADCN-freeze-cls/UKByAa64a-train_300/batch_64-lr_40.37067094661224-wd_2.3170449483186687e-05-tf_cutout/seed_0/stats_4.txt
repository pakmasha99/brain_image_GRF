"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 790282.5475349426, "training_acc": 69.0, "val_loss": 427394.072265625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1128827.27734375, "training_acc": 51.666666666666664, "val_loss": 439646.29345703125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1567143.4267578125, "training_acc": 72.33333333333333, "val_loss": 154495.00024414062, "val_acc": 72.0}
{"epoch": 3, "training_loss": 965041.2724609375, "training_acc": 47.666666666666664, "val_loss": 92838.36010742188, "val_acc": 28.0}
{"epoch": 4, "training_loss": 658040.2998046875, "training_acc": 63.666666666666664, "val_loss": 301167.1237792969, "val_acc": 72.0}
{"epoch": 5, "training_loss": 926192.1176757812, "training_acc": 72.33333333333333, "val_loss": 12103.352828979492, "val_acc": 72.0}
{"epoch": 6, "training_loss": 735072.1374511719, "training_acc": 39.0, "val_loss": 124222.05334472656, "val_acc": 72.0}
{"epoch": 7, "training_loss": 990329.640625, "training_acc": 72.33333333333333, "val_loss": 325898.1618652344, "val_acc": 72.0}
{"epoch": 8, "training_loss": 903849.7321777344, "training_acc": 72.33333333333333, "val_loss": 98127.15625, "val_acc": 28.0}
{"epoch": 9, "training_loss": 416130.22705078125, "training_acc": 46.333333333333336, "val_loss": 130643.07934570312, "val_acc": 72.0}
{"epoch": 10, "training_loss": 387427.1170654297, "training_acc": 72.33333333333333, "val_loss": 174313.72338867188, "val_acc": 28.0}
{"epoch": 11, "training_loss": 551575.3720703125, "training_acc": 41.666666666666664, "val_loss": 197781.390625, "val_acc": 72.0}
{"epoch": 12, "training_loss": 676055.7666015625, "training_acc": 72.33333333333333, "val_loss": 6870.122100830078, "val_acc": 72.0}
{"epoch": 13, "training_loss": 436817.9436035156, "training_acc": 46.333333333333336, "val_loss": 135327.1630859375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 600916.7221679688, "training_acc": 72.33333333333333, "val_loss": 73727.25610351562, "val_acc": 72.0}
{"epoch": 15, "training_loss": 368608.84436035156, "training_acc": 46.333333333333336, "val_loss": 106111.87866210938, "val_acc": 72.0}
{"epoch": 16, "training_loss": 741304.248046875, "training_acc": 72.33333333333333, "val_loss": 210165.00170898438, "val_acc": 72.0}
{"epoch": 17, "training_loss": 531026.2587890625, "training_acc": 68.33333333333333, "val_loss": 247338.00219726562, "val_acc": 28.0}
{"epoch": 18, "training_loss": 561060.8955078125, "training_acc": 49.666666666666664, "val_loss": 131236.98754882812, "val_acc": 72.0}
{"epoch": 19, "training_loss": 338525.03125, "training_acc": 68.33333333333333, "val_loss": 179358.64916992188, "val_acc": 28.0}
{"epoch": 20, "training_loss": 563468.13671875, "training_acc": 51.0, "val_loss": 211584.73583984375, "val_acc": 72.0}
{"epoch": 21, "training_loss": 616254.4570922852, "training_acc": 72.33333333333333, "val_loss": 131630.6378173828, "val_acc": 28.0}
{"epoch": 22, "training_loss": 495928.5966796875, "training_acc": 43.666666666666664, "val_loss": 175605.23559570312, "val_acc": 72.0}
{"epoch": 23, "training_loss": 580353.0336914062, "training_acc": 72.33333333333333, "val_loss": 3741.869644165039, "val_acc": 77.33333333333333}
{"epoch": 24, "training_loss": 293321.2080078125, "training_acc": 50.0, "val_loss": 48861.10168457031, "val_acc": 72.0}
{"epoch": 25, "training_loss": 129262.34069824219, "training_acc": 59.333333333333336, "val_loss": 84451.34899902344, "val_acc": 72.0}
{"epoch": 26, "training_loss": 284210.619140625, "training_acc": 65.0, "val_loss": 21149.988006591797, "val_acc": 28.0}
{"epoch": 27, "training_loss": 303782.61767578125, "training_acc": 62.333333333333336, "val_loss": 70679.96508789062, "val_acc": 72.0}
{"epoch": 28, "training_loss": 358340.6296386719, "training_acc": 45.333333333333336, "val_loss": 89271.1985168457, "val_acc": 72.0}
{"epoch": 29, "training_loss": 596202.7236328125, "training_acc": 72.33333333333333, "val_loss": 136513.91632080078, "val_acc": 72.0}
{"epoch": 30, "training_loss": 481048.9375, "training_acc": 57.333333333333336, "val_loss": 112440.23657226562, "val_acc": 28.0}
{"epoch": 31, "training_loss": 485020.03515625, "training_acc": 63.0, "val_loss": 145974.84814453125, "val_acc": 72.0}
{"epoch": 32, "training_loss": 348465.8740234375, "training_acc": 56.333333333333336, "val_loss": 14298.432495117188, "val_acc": 72.0}
{"epoch": 33, "training_loss": 118540.53564453125, "training_acc": 65.33333333333333, "val_loss": 7497.083343505859, "val_acc": 56.0}
{"epoch": 34, "training_loss": 340732.61376953125, "training_acc": 64.66666666666667, "val_loss": 81667.66998291016, "val_acc": 72.0}
{"epoch": 35, "training_loss": 204526.68493652344, "training_acc": 56.333333333333336, "val_loss": 44449.93176269531, "val_acc": 72.0}
{"epoch": 36, "training_loss": 119998.9899597168, "training_acc": 63.666666666666664, "val_loss": 6710.940208435059, "val_acc": 72.0}
{"epoch": 37, "training_loss": 95269.06262207031, "training_acc": 65.33333333333333, "val_loss": 5006.2710728645325, "val_acc": 73.33333333333333}
{"epoch": 38, "training_loss": 32965.584564208984, "training_acc": 61.0, "val_loss": 5014.101676940918, "val_acc": 77.33333333333333}
{"epoch": 39, "training_loss": 47796.76599121094, "training_acc": 60.333333333333336, "val_loss": 31116.47998046875, "val_acc": 72.0}
{"epoch": 40, "training_loss": 163101.201171875, "training_acc": 65.0, "val_loss": 30103.112579345703, "val_acc": 28.0}
{"epoch": 41, "training_loss": 426235.6982421875, "training_acc": 60.333333333333336, "val_loss": 102880.94152832031, "val_acc": 72.0}
{"epoch": 42, "training_loss": 230218.31872558594, "training_acc": 56.333333333333336, "val_loss": 51198.9592590332, "val_acc": 72.0}
