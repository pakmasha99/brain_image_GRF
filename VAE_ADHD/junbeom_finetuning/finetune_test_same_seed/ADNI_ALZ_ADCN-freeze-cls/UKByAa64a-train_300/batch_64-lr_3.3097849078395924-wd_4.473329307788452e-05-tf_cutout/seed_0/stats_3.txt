"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 21721.845726013184, "training_acc": 59.0, "val_loss": 3942.936351776123, "val_acc": 28.0}
{"epoch": 1, "training_loss": 9694.051139831543, "training_acc": 62.0, "val_loss": 627.9204759597778, "val_acc": 69.33333333333333}
{"epoch": 2, "training_loss": 5340.733741760254, "training_acc": 67.33333333333333, "val_loss": 1242.394790649414, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 4238.877685546875, "training_acc": 66.0, "val_loss": 665.3531351089478, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 2568.217876434326, "training_acc": 67.33333333333333, "val_loss": 503.64417457580566, "val_acc": 46.666666666666664}
{"epoch": 5, "training_loss": 846.4967708587646, "training_acc": 66.33333333333333, "val_loss": 1308.7341003417969, "val_acc": 72.0}
{"epoch": 6, "training_loss": 6867.495208740234, "training_acc": 66.33333333333333, "val_loss": 2536.6690406799316, "val_acc": 29.333333333333332}
{"epoch": 7, "training_loss": 7112.27717590332, "training_acc": 62.666666666666664, "val_loss": 554.2565488815308, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 5516.331619262695, "training_acc": 58.666666666666664, "val_loss": 1330.0220565795898, "val_acc": 74.66666666666667}
{"epoch": 9, "training_loss": 4516.838939666748, "training_acc": 65.66666666666667, "val_loss": 930.6621437072754, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 4000.7064514160156, "training_acc": 63.666666666666664, "val_loss": 983.0676870346069, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5321.744537353516, "training_acc": 68.0, "val_loss": 1043.6820096969604, "val_acc": 44.0}
{"epoch": 12, "training_loss": 6446.5533809661865, "training_acc": 63.666666666666664, "val_loss": 425.04051876068115, "val_acc": 74.66666666666667}
{"epoch": 13, "training_loss": 3225.779151916504, "training_acc": 65.0, "val_loss": 665.5673999786377, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2485.8692626953125, "training_acc": 66.0, "val_loss": 511.2190799713135, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 1905.251163482666, "training_acc": 71.33333333333333, "val_loss": 234.38004732131958, "val_acc": 76.0}
{"epoch": 16, "training_loss": 2712.1893920898438, "training_acc": 65.66666666666667, "val_loss": 345.9536032676697, "val_acc": 74.66666666666667}
{"epoch": 17, "training_loss": 4029.955726623535, "training_acc": 62.0, "val_loss": 783.457670211792, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2498.6736373901367, "training_acc": 66.0, "val_loss": 927.163200378418, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3012.687297821045, "training_acc": 66.66666666666667, "val_loss": 1183.3772974014282, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2684.336624145508, "training_acc": 68.66666666666667, "val_loss": 1328.4102973937988, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3100.135696411133, "training_acc": 71.33333333333333, "val_loss": 621.5550994873047, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3229.4097480773926, "training_acc": 66.66666666666667, "val_loss": 543.2641222476959, "val_acc": 78.66666666666667}
{"epoch": 23, "training_loss": 3079.921932220459, "training_acc": 75.0, "val_loss": 656.9396152496338, "val_acc": 64.0}
{"epoch": 24, "training_loss": 3020.3521308898926, "training_acc": 70.66666666666667, "val_loss": 1169.2317504882812, "val_acc": 36.0}
{"epoch": 25, "training_loss": 2962.6570949554443, "training_acc": 66.33333333333333, "val_loss": 1851.6926670074463, "val_acc": 30.666666666666668}
{"epoch": 26, "training_loss": 6510.106796264648, "training_acc": 60.333333333333336, "val_loss": 1702.2186975479126, "val_acc": 72.0}
{"epoch": 27, "training_loss": 5647.735931396484, "training_acc": 56.0, "val_loss": 1754.1538848876953, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5428.606269836426, "training_acc": 69.66666666666667, "val_loss": 586.8258423805237, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 2731.47739982605, "training_acc": 73.33333333333333, "val_loss": 663.4172744750977, "val_acc": 66.66666666666667}
{"epoch": 30, "training_loss": 2116.1965799331665, "training_acc": 72.66666666666667, "val_loss": 1916.1402282714844, "val_acc": 33.333333333333336}
{"epoch": 31, "training_loss": 3187.671401977539, "training_acc": 64.33333333333333, "val_loss": 2246.756929397583, "val_acc": 30.666666666666668}
{"epoch": 32, "training_loss": 4979.964317321777, "training_acc": 60.0, "val_loss": 319.386025428772, "val_acc": 81.33333333333333}
{"epoch": 33, "training_loss": 2050.9434814453125, "training_acc": 71.33333333333333, "val_loss": 323.199556350708, "val_acc": 80.0}
{"epoch": 34, "training_loss": 1087.6009693145752, "training_acc": 75.33333333333333, "val_loss": 248.33600521087646, "val_acc": 76.0}
