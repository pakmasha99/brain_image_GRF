"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19594.16298675537, "training_acc": 68.33333333333333, "val_loss": 6487.168983459473, "val_acc": 28.0}
{"epoch": 1, "training_loss": 16446.050567626953, "training_acc": 64.0, "val_loss": 4680.208419799805, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9638.61100769043, "training_acc": 66.33333333333333, "val_loss": 3284.039686203003, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 9009.998809814453, "training_acc": 69.66666666666667, "val_loss": 2903.3174591064453, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 7039.806266784668, "training_acc": 62.666666666666664, "val_loss": 1973.782871246338, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 5139.3394775390625, "training_acc": 70.0, "val_loss": 1529.994472503662, "val_acc": 54.666666666666664}
{"epoch": 6, "training_loss": 5049.568336486816, "training_acc": 65.66666666666667, "val_loss": 1910.8047828674316, "val_acc": 42.666666666666664}
{"epoch": 7, "training_loss": 3584.1323585510254, "training_acc": 66.0, "val_loss": 1077.0815525054932, "val_acc": 57.333333333333336}
{"epoch": 8, "training_loss": 2623.303050994873, "training_acc": 68.33333333333333, "val_loss": 1226.303020477295, "val_acc": 37.333333333333336}
{"epoch": 9, "training_loss": 2668.720844268799, "training_acc": 66.0, "val_loss": 1988.031940460205, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5674.876052856445, "training_acc": 57.0, "val_loss": 897.8505799770355, "val_acc": 62.666666666666664}
{"epoch": 11, "training_loss": 4009.954635620117, "training_acc": 64.66666666666667, "val_loss": 1720.9148635864258, "val_acc": 69.33333333333333}
{"epoch": 12, "training_loss": 3755.0250358581543, "training_acc": 66.66666666666667, "val_loss": 1267.1532917022705, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2811.473062515259, "training_acc": 69.66666666666667, "val_loss": 787.4127674102783, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 2111.464557647705, "training_acc": 70.66666666666667, "val_loss": 808.6642837524414, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 1248.725152015686, "training_acc": 76.33333333333333, "val_loss": 326.890572309494, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 1455.0292015075684, "training_acc": 65.33333333333333, "val_loss": 853.705904006958, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 3329.838539123535, "training_acc": 68.0, "val_loss": 923.3786599636078, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2653.4285831451416, "training_acc": 72.66666666666667, "val_loss": 706.1184997558594, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 1398.652925491333, "training_acc": 74.66666666666667, "val_loss": 680.6389236450195, "val_acc": 69.33333333333333}
{"epoch": 20, "training_loss": 2161.6690979003906, "training_acc": 64.33333333333333, "val_loss": 1106.6947495937347, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 2734.5409088134766, "training_acc": 69.66666666666667, "val_loss": 1290.5705633163452, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 2844.6931953430176, "training_acc": 73.33333333333333, "val_loss": 1406.2592220306396, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 2397.4659147262573, "training_acc": 72.0, "val_loss": 1051.269624710083, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 2196.0550689697266, "training_acc": 66.0, "val_loss": 1183.371826171875, "val_acc": 69.33333333333333}
{"epoch": 25, "training_loss": 2196.488063812256, "training_acc": 72.0, "val_loss": 1103.8476753234863, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2874.5981101989746, "training_acc": 70.33333333333333, "val_loss": 840.8358192443848, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2267.4108934402466, "training_acc": 69.33333333333333, "val_loss": 914.1213989257812, "val_acc": 70.66666666666667}
{"epoch": 28, "training_loss": 1753.5502529144287, "training_acc": 75.33333333333333, "val_loss": 746.1966018676758, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 1590.3983249664307, "training_acc": 70.66666666666667, "val_loss": 414.8869230747223, "val_acc": 64.0}
{"epoch": 30, "training_loss": 733.8137130737305, "training_acc": 80.0, "val_loss": 315.71567463874817, "val_acc": 66.66666666666667}
{"epoch": 31, "training_loss": 779.7171406745911, "training_acc": 74.33333333333333, "val_loss": 698.7927837371826, "val_acc": 69.33333333333333}
{"epoch": 32, "training_loss": 1592.140926361084, "training_acc": 72.0, "val_loss": 785.4593057632446, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1067.1749782562256, "training_acc": 77.0, "val_loss": 344.55331563949585, "val_acc": 78.66666666666667}
{"epoch": 34, "training_loss": 1503.4597663879395, "training_acc": 71.66666666666667, "val_loss": 363.3302311897278, "val_acc": 66.66666666666667}
{"epoch": 35, "training_loss": 510.58184814453125, "training_acc": 83.66666666666667, "val_loss": 610.5417122840881, "val_acc": 60.0}
{"epoch": 36, "training_loss": 753.2599935531616, "training_acc": 77.0, "val_loss": 285.0921440124512, "val_acc": 77.33333333333333}
{"epoch": 37, "training_loss": 286.5384306907654, "training_acc": 83.66666666666667, "val_loss": 274.5085424184799, "val_acc": 66.66666666666667}
{"epoch": 38, "training_loss": 374.41482973098755, "training_acc": 81.66666666666667, "val_loss": 263.6046071052551, "val_acc": 77.33333333333333}
{"epoch": 39, "training_loss": 804.6572418212891, "training_acc": 74.33333333333333, "val_loss": 818.6583766937256, "val_acc": 69.33333333333333}
{"epoch": 40, "training_loss": 2426.0555839538574, "training_acc": 68.33333333333333, "val_loss": 1314.7691006660461, "val_acc": 69.33333333333333}
{"epoch": 41, "training_loss": 2896.175807952881, "training_acc": 68.66666666666667, "val_loss": 1083.8321075439453, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1723.774606704712, "training_acc": 74.66666666666667, "val_loss": 593.7962837219238, "val_acc": 72.0}
{"epoch": 43, "training_loss": 515.6772353649139, "training_acc": 82.33333333333333, "val_loss": 330.50435626506805, "val_acc": 70.66666666666667}
{"epoch": 44, "training_loss": 672.0232191085815, "training_acc": 79.0, "val_loss": 588.7599210739136, "val_acc": 65.33333333333333}
{"epoch": 45, "training_loss": 1631.4934349060059, "training_acc": 71.0, "val_loss": 712.1539769172668, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1760.9024829864502, "training_acc": 72.66666666666667, "val_loss": 1183.0418243408203, "val_acc": 70.66666666666667}
{"epoch": 47, "training_loss": 3924.440954208374, "training_acc": 62.666666666666664, "val_loss": 1260.388442993164, "val_acc": 69.33333333333333}
{"epoch": 48, "training_loss": 2744.359760284424, "training_acc": 73.0, "val_loss": 998.3207178115845, "val_acc": 64.0}
{"epoch": 49, "training_loss": 2205.435661315918, "training_acc": 77.33333333333333, "val_loss": 1123.6755739450455, "val_acc": 64.0}
{"epoch": 50, "training_loss": 1630.011667251587, "training_acc": 76.0, "val_loss": 600.9387125968933, "val_acc": 72.0}
{"epoch": 51, "training_loss": 608.4249594211578, "training_acc": 80.0, "val_loss": 412.1149682998657, "val_acc": 73.33333333333333}
{"epoch": 52, "training_loss": 534.2205867767334, "training_acc": 81.0, "val_loss": 607.4271924495697, "val_acc": 58.666666666666664}
{"epoch": 53, "training_loss": 805.941478729248, "training_acc": 78.0, "val_loss": 746.858811378479, "val_acc": 70.66666666666667}
{"epoch": 54, "training_loss": 1569.1621189117432, "training_acc": 70.66666666666667, "val_loss": 947.1673450469971, "val_acc": 70.66666666666667}
{"epoch": 55, "training_loss": 1416.2360610961914, "training_acc": 75.0, "val_loss": 917.3667278289795, "val_acc": 57.333333333333336}
{"epoch": 56, "training_loss": 994.828164100647, "training_acc": 78.66666666666667, "val_loss": 461.80948543548584, "val_acc": 76.0}
{"epoch": 57, "training_loss": 1294.7002983093262, "training_acc": 72.33333333333333, "val_loss": 1371.595407485962, "val_acc": 69.33333333333333}
