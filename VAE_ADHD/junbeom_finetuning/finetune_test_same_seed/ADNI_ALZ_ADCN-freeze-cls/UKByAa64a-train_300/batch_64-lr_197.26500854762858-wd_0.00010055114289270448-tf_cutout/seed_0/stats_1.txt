"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4444710.21862793, "training_acc": 65.0, "val_loss": 910018.408203125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2444678.8203125, "training_acc": 64.33333333333333, "val_loss": 424171.64404296875, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2719621.03125, "training_acc": 44.333333333333336, "val_loss": 524070.81640625, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4008086.625, "training_acc": 72.33333333333333, "val_loss": 1076795.484375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2558020.53515625, "training_acc": 52.333333333333336, "val_loss": 95783.26171875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 658509.951171875, "training_acc": 65.66666666666667, "val_loss": 319015.2509765625, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1585047.451171875, "training_acc": 61.0, "val_loss": 324255.41833496094, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1486193.703125, "training_acc": 51.0, "val_loss": 195771.47802734375, "val_acc": 72.0}
{"epoch": 8, "training_loss": 628218.9311523438, "training_acc": 57.666666666666664, "val_loss": 329095.1514892578, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1852235.5546875, "training_acc": 72.33333333333333, "val_loss": 139202.42358398438, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1021483.55078125, "training_acc": 56.333333333333336, "val_loss": 331695.6181640625, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1406574.326171875, "training_acc": 55.666666666666664, "val_loss": 97466.35546875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 839558.5241699219, "training_acc": 72.33333333333333, "val_loss": 424196.16748046875, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1144952.4931640625, "training_acc": 57.0, "val_loss": 350139.6188964844, "val_acc": 72.0}
{"epoch": 14, "training_loss": 591977.0190429688, "training_acc": 61.666666666666664, "val_loss": 295406.91650390625, "val_acc": 28.0}
{"epoch": 15, "training_loss": 1653629.208984375, "training_acc": 53.0, "val_loss": 733263.720703125, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2023511.6452636719, "training_acc": 64.0, "val_loss": 686360.8017578125, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1410797.919921875, "training_acc": 61.0, "val_loss": 67379.7728881836, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1106385.7685546875, "training_acc": 57.666666666666664, "val_loss": 232682.88305664062, "val_acc": 72.0}
{"epoch": 19, "training_loss": 569739.1080322266, "training_acc": 65.33333333333333, "val_loss": 103649.486328125, "val_acc": 72.0}
{"epoch": 20, "training_loss": 467285.349609375, "training_acc": 62.333333333333336, "val_loss": 11151.00366973877, "val_acc": 66.66666666666667}
{"epoch": 21, "training_loss": 605243.1337890625, "training_acc": 58.666666666666664, "val_loss": 217512.25, "val_acc": 28.0}
{"epoch": 22, "training_loss": 519500.29345703125, "training_acc": 49.333333333333336, "val_loss": 202362.5478515625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 882902.251953125, "training_acc": 55.0, "val_loss": 262713.1721191406, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1563693.474609375, "training_acc": 72.33333333333333, "val_loss": 62928.73583984375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1649938.4453125, "training_acc": 43.0, "val_loss": 862276.9697265625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4112230.83984375, "training_acc": 72.33333333333333, "val_loss": 750640.4833984375, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1444673.9985351562, "training_acc": 52.666666666666664, "val_loss": 289713.8388671875, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1844391.482421875, "training_acc": 72.33333333333333, "val_loss": 98541.34057617188, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1349536.4326171875, "training_acc": 51.0, "val_loss": 205249.88305664062, "val_acc": 72.0}
{"epoch": 30, "training_loss": 472685.2744140625, "training_acc": 61.666666666666664, "val_loss": 95204.69934082031, "val_acc": 28.0}
{"epoch": 31, "training_loss": 504074.22265625, "training_acc": 56.333333333333336, "val_loss": 17615.110984802246, "val_acc": 74.66666666666667}
{"epoch": 32, "training_loss": 410950.7548828125, "training_acc": 62.333333333333336, "val_loss": 136500.1962890625, "val_acc": 72.0}
{"epoch": 33, "training_loss": 384965.5675048828, "training_acc": 64.33333333333333, "val_loss": 365034.24609375, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1082714.896484375, "training_acc": 57.0, "val_loss": 105948.80383300781, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1116622.07421875, "training_acc": 52.333333333333336, "val_loss": 583028.1552734375, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1652814.71484375, "training_acc": 65.0, "val_loss": 857336.0361328125, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2467659.3515625, "training_acc": 54.333333333333336, "val_loss": 1050634.4228515625, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3006172.146484375, "training_acc": 72.33333333333333, "val_loss": 284649.97314453125, "val_acc": 28.0}
{"epoch": 39, "training_loss": 1154827.6298828125, "training_acc": 52.0, "val_loss": 465551.0, "val_acc": 72.0}
