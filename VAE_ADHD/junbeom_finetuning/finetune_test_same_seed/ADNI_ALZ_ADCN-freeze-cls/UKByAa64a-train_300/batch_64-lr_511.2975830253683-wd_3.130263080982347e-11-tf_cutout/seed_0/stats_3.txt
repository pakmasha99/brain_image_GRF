"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3260206.874984741, "training_acc": 67.0, "val_loss": 1264344.19140625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 3146847.12890625, "training_acc": 61.333333333333336, "val_loss": 1105938.0986328125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2849684.67578125, "training_acc": 69.66666666666667, "val_loss": 440246.2109375, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 1831586.90625, "training_acc": 62.333333333333336, "val_loss": 485195.2978515625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1637976.5205078125, "training_acc": 61.0, "val_loss": 94831.85131835938, "val_acc": 70.66666666666667}
{"epoch": 5, "training_loss": 677990.2065429688, "training_acc": 72.0, "val_loss": 159403.04809570312, "val_acc": 52.0}
{"epoch": 6, "training_loss": 521116.8747558594, "training_acc": 66.0, "val_loss": 268524.8283691406, "val_acc": 34.666666666666664}
{"epoch": 7, "training_loss": 428984.109375, "training_acc": 67.66666666666667, "val_loss": 164833.57788085938, "val_acc": 38.666666666666664}
{"epoch": 8, "training_loss": 316803.0126953125, "training_acc": 63.333333333333336, "val_loss": 68262.2885131836, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 232334.25830078125, "training_acc": 69.33333333333333, "val_loss": 20987.655044555664, "val_acc": 72.0}
{"epoch": 10, "training_loss": 414219.26220703125, "training_acc": 65.0, "val_loss": 460974.68994140625, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1229008.734375, "training_acc": 56.333333333333336, "val_loss": 394833.17578125, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1113488.4736328125, "training_acc": 59.333333333333336, "val_loss": 142031.31896972656, "val_acc": 76.0}
{"epoch": 13, "training_loss": 1259561.01953125, "training_acc": 73.33333333333333, "val_loss": 93368.775390625, "val_acc": 76.0}
{"epoch": 14, "training_loss": 1055247.326171875, "training_acc": 63.0, "val_loss": 377368.36767578125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1014849.208984375, "training_acc": 69.33333333333333, "val_loss": 267761.7478027344, "val_acc": 44.0}
{"epoch": 16, "training_loss": 830317.654296875, "training_acc": 68.33333333333333, "val_loss": 62667.55944824219, "val_acc": 80.0}
{"epoch": 17, "training_loss": 605512.7778320312, "training_acc": 66.0, "val_loss": 230655.8154296875, "val_acc": 72.0}
{"epoch": 18, "training_loss": 614559.8564453125, "training_acc": 67.33333333333333, "val_loss": 58704.22180175781, "val_acc": 76.0}
{"epoch": 19, "training_loss": 614487.7176513672, "training_acc": 73.0, "val_loss": 238713.79711914062, "val_acc": 38.666666666666664}
{"epoch": 20, "training_loss": 451879.3995361328, "training_acc": 69.33333333333333, "val_loss": 189196.28619384766, "val_acc": 42.666666666666664}
{"epoch": 21, "training_loss": 512009.8603515625, "training_acc": 68.66666666666667, "val_loss": 37840.83203125, "val_acc": 81.33333333333333}
{"epoch": 22, "training_loss": 367012.60498046875, "training_acc": 68.66666666666667, "val_loss": 96662.19946289062, "val_acc": 56.0}
{"epoch": 23, "training_loss": 267755.62841796875, "training_acc": 68.0, "val_loss": 145985.13427734375, "val_acc": 42.666666666666664}
{"epoch": 24, "training_loss": 289025.25732421875, "training_acc": 68.66666666666667, "val_loss": 36320.02947998047, "val_acc": 77.33333333333333}
{"epoch": 25, "training_loss": 102716.6640625, "training_acc": 78.66666666666667, "val_loss": 35438.60330200195, "val_acc": 77.33333333333333}
{"epoch": 26, "training_loss": 132884.1756591797, "training_acc": 75.33333333333333, "val_loss": 42190.44842529297, "val_acc": 62.666666666666664}
{"epoch": 27, "training_loss": 97365.43957519531, "training_acc": 78.66666666666667, "val_loss": 30027.20610809326, "val_acc": 70.66666666666667}
{"epoch": 28, "training_loss": 176369.12408447266, "training_acc": 72.33333333333333, "val_loss": 87354.40521240234, "val_acc": 73.33333333333333}
