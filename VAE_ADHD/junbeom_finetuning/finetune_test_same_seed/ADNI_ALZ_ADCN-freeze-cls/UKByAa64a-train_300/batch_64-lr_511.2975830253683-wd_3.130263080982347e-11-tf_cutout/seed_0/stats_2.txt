"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3376403.529308319, "training_acc": 57.0, "val_loss": 429272.61376953125, "val_acc": 41.333333333333336}
{"epoch": 1, "training_loss": 2111046.59765625, "training_acc": 65.33333333333333, "val_loss": 416316.19580078125, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 1658285.7001953125, "training_acc": 57.333333333333336, "val_loss": 376984.36767578125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1260289.0708007812, "training_acc": 72.33333333333333, "val_loss": 266928.0576477051, "val_acc": 61.333333333333336}
{"epoch": 4, "training_loss": 915060.0048828125, "training_acc": 64.0, "val_loss": 361528.1135253906, "val_acc": 72.0}
{"epoch": 5, "training_loss": 896676.0703125, "training_acc": 61.666666666666664, "val_loss": 224632.97094726562, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 627578.328125, "training_acc": 68.33333333333333, "val_loss": 99642.01611328125, "val_acc": 64.0}
{"epoch": 7, "training_loss": 385051.26708984375, "training_acc": 71.0, "val_loss": 75932.87512207031, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 158784.8858642578, "training_acc": 74.0, "val_loss": 31887.352111816406, "val_acc": 61.333333333333336}
{"epoch": 9, "training_loss": 159926.33740234375, "training_acc": 69.0, "val_loss": 102334.74328613281, "val_acc": 72.0}
{"epoch": 10, "training_loss": 383806.99658203125, "training_acc": 67.0, "val_loss": 132751.43780517578, "val_acc": 72.0}
{"epoch": 11, "training_loss": 307296.578125, "training_acc": 68.33333333333333, "val_loss": 158843.29516601562, "val_acc": 72.0}
{"epoch": 12, "training_loss": 294164.66900634766, "training_acc": 70.66666666666667, "val_loss": 43966.338439941406, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 177308.76171875, "training_acc": 68.66666666666667, "val_loss": 143100.7427368164, "val_acc": 72.0}
{"epoch": 14, "training_loss": 500977.9793701172, "training_acc": 67.66666666666667, "val_loss": 59465.53210449219, "val_acc": 69.33333333333333}
{"epoch": 15, "training_loss": 197218.87841796875, "training_acc": 76.66666666666667, "val_loss": 54227.118225097656, "val_acc": 68.0}
{"epoch": 16, "training_loss": 284290.61767578125, "training_acc": 69.66666666666667, "val_loss": 329988.8024902344, "val_acc": 32.0}
{"epoch": 17, "training_loss": 714767.3564453125, "training_acc": 62.666666666666664, "val_loss": 194058.3077392578, "val_acc": 48.0}
{"epoch": 18, "training_loss": 533978.447265625, "training_acc": 65.0, "val_loss": 147587.4970703125, "val_acc": 56.0}
{"epoch": 19, "training_loss": 501803.55517578125, "training_acc": 69.33333333333333, "val_loss": 125530.97375488281, "val_acc": 68.0}
{"epoch": 20, "training_loss": 453263.1962890625, "training_acc": 65.66666666666667, "val_loss": 162637.8427734375, "val_acc": 72.0}
{"epoch": 21, "training_loss": 565261.7495117188, "training_acc": 66.0, "val_loss": 310603.60400390625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 731949.5654296875, "training_acc": 69.66666666666667, "val_loss": 129205.95288085938, "val_acc": 64.0}
{"epoch": 23, "training_loss": 503201.67431640625, "training_acc": 76.33333333333333, "val_loss": 294075.08056640625, "val_acc": 41.333333333333336}
{"epoch": 24, "training_loss": 708420.626953125, "training_acc": 64.66666666666667, "val_loss": 113822.42065429688, "val_acc": 69.33333333333333}
{"epoch": 25, "training_loss": 234364.23852539062, "training_acc": 74.33333333333333, "val_loss": 55317.59802246094, "val_acc": 72.0}
{"epoch": 26, "training_loss": 255265.9931640625, "training_acc": 73.0, "val_loss": 192913.62133789062, "val_acc": 33.333333333333336}
{"epoch": 27, "training_loss": 262979.70947265625, "training_acc": 69.0, "val_loss": 41798.17639160156, "val_acc": 73.33333333333333}
