"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4044144.7999458313, "training_acc": 57.666666666666664, "val_loss": 1262408.2578125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 3770477.671875, "training_acc": 43.0, "val_loss": 1200901.9453125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4472452.5703125, "training_acc": 72.33333333333333, "val_loss": 420388.2373046875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 938774.2158203125, "training_acc": 48.333333333333336, "val_loss": 157138.1768798828, "val_acc": 72.0}
{"epoch": 4, "training_loss": 697398.8564453125, "training_acc": 55.666666666666664, "val_loss": 394915.0166015625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1395199.16796875, "training_acc": 72.33333333333333, "val_loss": 426834.3759765625, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1124579.5732421875, "training_acc": 50.333333333333336, "val_loss": 113276.1499633789, "val_acc": 72.0}
{"epoch": 7, "training_loss": 524034.55078125, "training_acc": 59.0, "val_loss": 488455.22607421875, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1503530.7431640625, "training_acc": 63.0, "val_loss": 100591.7197265625, "val_acc": 28.0}
{"epoch": 9, "training_loss": 970945.67578125, "training_acc": 64.33333333333333, "val_loss": 200423.0821533203, "val_acc": 72.0}
{"epoch": 10, "training_loss": 791278.7182617188, "training_acc": 57.0, "val_loss": 341795.013671875, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1323130.4711914062, "training_acc": 72.33333333333333, "val_loss": 320597.53515625, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1027084.673828125, "training_acc": 53.0, "val_loss": 205871.46875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 684653.7719726562, "training_acc": 58.333333333333336, "val_loss": 271333.29638671875, "val_acc": 72.0}
{"epoch": 14, "training_loss": 955982.974609375, "training_acc": 65.66666666666667, "val_loss": 195349.015625, "val_acc": 28.0}
{"epoch": 15, "training_loss": 1022762.787109375, "training_acc": 63.0, "val_loss": 179636.81665039062, "val_acc": 72.0}
{"epoch": 16, "training_loss": 968885.4560546875, "training_acc": 52.0, "val_loss": 305952.6867675781, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1007691.0092773438, "training_acc": 72.66666666666667, "val_loss": 604739.3427734375, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1717560.484375, "training_acc": 47.333333333333336, "val_loss": 582745.369140625, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1639501.4584960938, "training_acc": 63.333333333333336, "val_loss": 21990.591804504395, "val_acc": 57.333333333333336}
{"epoch": 20, "training_loss": 460798.806640625, "training_acc": 67.33333333333333, "val_loss": 422416.16845703125, "val_acc": 28.0}
{"epoch": 21, "training_loss": 1000472.8330078125, "training_acc": 57.0, "val_loss": 243730.0, "val_acc": 72.0}
{"epoch": 22, "training_loss": 709118.0244140625, "training_acc": 53.666666666666664, "val_loss": 387370.67626953125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1416318.0441894531, "training_acc": 72.33333333333333, "val_loss": 356082.38232421875, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1178831.853515625, "training_acc": 49.0, "val_loss": 224908.3564453125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 440431.40625, "training_acc": 60.666666666666664, "val_loss": 127760.67407226562, "val_acc": 72.0}
{"epoch": 26, "training_loss": 503881.697265625, "training_acc": 60.333333333333336, "val_loss": 133359.05505371094, "val_acc": 72.0}
{"epoch": 27, "training_loss": 496188.3388671875, "training_acc": 58.666666666666664, "val_loss": 238537.93017578125, "val_acc": 72.0}
{"epoch": 28, "training_loss": 792660.232421875, "training_acc": 67.66666666666667, "val_loss": 455963.45556640625, "val_acc": 28.0}
{"epoch": 29, "training_loss": 895443.853515625, "training_acc": 67.33333333333333, "val_loss": 117820.11584472656, "val_acc": 72.0}
{"epoch": 30, "training_loss": 289088.8681640625, "training_acc": 66.66666666666667, "val_loss": 53055.87127685547, "val_acc": 41.333333333333336}
{"epoch": 31, "training_loss": 528600.85546875, "training_acc": 52.333333333333336, "val_loss": 23440.939819335938, "val_acc": 62.666666666666664}
{"epoch": 32, "training_loss": 745532.9409179688, "training_acc": 66.66666666666667, "val_loss": 89231.578125, "val_acc": 28.0}
{"epoch": 33, "training_loss": 273294.06689453125, "training_acc": 54.0, "val_loss": 106690.31414794922, "val_acc": 72.0}
{"epoch": 34, "training_loss": 649205.44140625, "training_acc": 50.666666666666664, "val_loss": 461602.47705078125, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1903477.93359375, "training_acc": 72.33333333333333, "val_loss": 24698.653259277344, "val_acc": 76.0}
{"epoch": 36, "training_loss": 1673216.5771484375, "training_acc": 46.666666666666664, "val_loss": 552528.1416015625, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2689471.546875, "training_acc": 72.33333333333333, "val_loss": 431490.9541015625, "val_acc": 72.0}
{"epoch": 38, "training_loss": 981825.5186767578, "training_acc": 54.666666666666664, "val_loss": 117511.30871582031, "val_acc": 72.0}
