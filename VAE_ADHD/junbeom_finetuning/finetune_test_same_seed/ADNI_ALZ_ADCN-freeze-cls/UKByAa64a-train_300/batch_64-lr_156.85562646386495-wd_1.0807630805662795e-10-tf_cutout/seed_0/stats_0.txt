"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3201372.617980957, "training_acc": 54.666666666666664, "val_loss": 438715.83642578125, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 2246554.796875, "training_acc": 64.0, "val_loss": 498767.8466796875, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 1509892.4125976562, "training_acc": 54.0, "val_loss": 224313.62622070312, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 1012158.259765625, "training_acc": 51.333333333333336, "val_loss": 253188.11010742188, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 2000045.271484375, "training_acc": 72.0, "val_loss": 283213.89404296875, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 2088212.525390625, "training_acc": 48.0, "val_loss": 165196.884765625, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 1513985.609375, "training_acc": 72.0, "val_loss": 279472.16955566406, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 1431039.546875, "training_acc": 46.666666666666664, "val_loss": 336482.90087890625, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 2873965.72265625, "training_acc": 72.0, "val_loss": 711432.2465820312, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 1614613.4775390625, "training_acc": 53.333333333333336, "val_loss": 56425.37239074707, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 343350.84228515625, "training_acc": 63.333333333333336, "val_loss": 99629.44592285156, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 374776.18212890625, "training_acc": 61.333333333333336, "val_loss": 54400.3388671875, "val_acc": 26.666666666666668}
{"epoch": 12, "training_loss": 313194.068359375, "training_acc": 61.333333333333336, "val_loss": 6867.896484375, "val_acc": 77.33333333333333}
{"epoch": 13, "training_loss": 308378.4697265625, "training_acc": 66.33333333333333, "val_loss": 62771.236328125, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 453738.03564453125, "training_acc": 57.333333333333336, "val_loss": 35484.4453125, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 239900.3204345703, "training_acc": 61.666666666666664, "val_loss": 53937.14453125, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 264031.5251464844, "training_acc": 66.0, "val_loss": 33816.486267089844, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 422289.3857421875, "training_acc": 61.666666666666664, "val_loss": 8932.773567199707, "val_acc": 80.0}
{"epoch": 18, "training_loss": 852844.470703125, "training_acc": 54.333333333333336, "val_loss": 495504.25, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 1547174.712890625, "training_acc": 72.0, "val_loss": 623851.4814453125, "val_acc": 26.666666666666668}
{"epoch": 20, "training_loss": 1899729.8369140625, "training_acc": 45.333333333333336, "val_loss": 581291.2543945312, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 2086134.1025390625, "training_acc": 72.0, "val_loss": 48567.26528930664, "val_acc": 26.666666666666668}
{"epoch": 22, "training_loss": 706531.8720703125, "training_acc": 51.666666666666664, "val_loss": 181119.43872070312, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 765839.4990234375, "training_acc": 53.666666666666664, "val_loss": 399031.451171875, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 1537676.6767578125, "training_acc": 72.0, "val_loss": 203282.455078125, "val_acc": 26.666666666666668}
{"epoch": 25, "training_loss": 1297984.00390625, "training_acc": 44.666666666666664, "val_loss": 304425.955078125, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 517776.7265625, "training_acc": 60.0, "val_loss": 285361.12109375, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 994281.7646484375, "training_acc": 65.33333333333333, "val_loss": 81900.2993774414, "val_acc": 26.666666666666668}
{"epoch": 28, "training_loss": 1164447.5234375, "training_acc": 61.333333333333336, "val_loss": 206352.67260742188, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 998808.5185546875, "training_acc": 55.666666666666664, "val_loss": 159769.01293945312, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 669543.7536621094, "training_acc": 58.666666666666664, "val_loss": 37909.8610534668, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 221869.8896484375, "training_acc": 63.333333333333336, "val_loss": 16511.845977783203, "val_acc": 80.0}
