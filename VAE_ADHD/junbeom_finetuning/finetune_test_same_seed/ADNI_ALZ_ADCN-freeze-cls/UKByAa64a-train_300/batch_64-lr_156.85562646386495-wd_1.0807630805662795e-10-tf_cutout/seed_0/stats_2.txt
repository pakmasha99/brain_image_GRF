"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3047942.986076355, "training_acc": 56.333333333333336, "val_loss": 96822.84448242188, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1101447.46484375, "training_acc": 50.333333333333336, "val_loss": 820852.361328125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3290208.99609375, "training_acc": 72.33333333333333, "val_loss": 298594.2890625, "val_acc": 72.0}
{"epoch": 3, "training_loss": 960431.41796875, "training_acc": 53.0, "val_loss": 183183.19995117188, "val_acc": 72.0}
{"epoch": 4, "training_loss": 732402.806640625, "training_acc": 55.0, "val_loss": 407291.00830078125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1344332.0009765625, "training_acc": 72.33333333333333, "val_loss": 528583.6005859375, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1106630.8208007812, "training_acc": 52.333333333333336, "val_loss": 50947.71487426758, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1155683.294921875, "training_acc": 44.333333333333336, "val_loss": 559200.8989257812, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1566319.3728027344, "training_acc": 72.33333333333333, "val_loss": 699212.357421875, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2185398.35546875, "training_acc": 41.0, "val_loss": 614703.0029296875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2054291.2734375, "training_acc": 72.33333333333333, "val_loss": 114377.04321289062, "val_acc": 28.0}
{"epoch": 11, "training_loss": 658426.9921875, "training_acc": 54.333333333333336, "val_loss": 170292.50830078125, "val_acc": 72.0}
{"epoch": 12, "training_loss": 476343.48046875, "training_acc": 61.0, "val_loss": 56434.52551269531, "val_acc": 28.0}
{"epoch": 13, "training_loss": 448230.9948730469, "training_acc": 56.333333333333336, "val_loss": 47068.6552734375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 353619.814453125, "training_acc": 63.0, "val_loss": 84164.98962402344, "val_acc": 72.0}
{"epoch": 15, "training_loss": 788004.16796875, "training_acc": 49.666666666666664, "val_loss": 573884.2373046875, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1725200.349609375, "training_acc": 72.33333333333333, "val_loss": 343253.72265625, "val_acc": 28.0}
{"epoch": 17, "training_loss": 874512.5576171875, "training_acc": 50.0, "val_loss": 16470.776748657227, "val_acc": 69.33333333333333}
{"epoch": 18, "training_loss": 396346.6943359375, "training_acc": 63.666666666666664, "val_loss": 34004.80096435547, "val_acc": 72.0}
{"epoch": 19, "training_loss": 769359.130859375, "training_acc": 55.666666666666664, "val_loss": 433366.0361328125, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1215210.4375, "training_acc": 66.33333333333333, "val_loss": 411350.279296875, "val_acc": 28.0}
{"epoch": 21, "training_loss": 658095.9873046875, "training_acc": 63.666666666666664, "val_loss": 164792.11840820312, "val_acc": 28.0}
{"epoch": 22, "training_loss": 424970.88330078125, "training_acc": 63.666666666666664, "val_loss": 167879.3984375, "val_acc": 28.0}
{"epoch": 23, "training_loss": 340608.66271972656, "training_acc": 61.333333333333336, "val_loss": 105264.75714111328, "val_acc": 28.0}
{"epoch": 24, "training_loss": 444946.1799316406, "training_acc": 65.66666666666667, "val_loss": 277336.5959472656, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1129289.966796875, "training_acc": 54.0, "val_loss": 435282.2919921875, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1484382.529296875, "training_acc": 52.333333333333336, "val_loss": 26635.40185546875, "val_acc": 68.0}
{"epoch": 27, "training_loss": 583971.1906738281, "training_acc": 72.33333333333333, "val_loss": 238415.81860351562, "val_acc": 28.0}
{"epoch": 28, "training_loss": 894226.359375, "training_acc": 55.0, "val_loss": 205659.7919921875, "val_acc": 72.0}
{"epoch": 29, "training_loss": 891139.8271484375, "training_acc": 53.333333333333336, "val_loss": 346281.99560546875, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1301044.8243408203, "training_acc": 72.33333333333333, "val_loss": 320284.33837890625, "val_acc": 28.0}
{"epoch": 31, "training_loss": 981907.578125, "training_acc": 55.0, "val_loss": 264922.4421386719, "val_acc": 72.0}
{"epoch": 32, "training_loss": 673832.7670898438, "training_acc": 56.333333333333336, "val_loss": 333637.658203125, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1162336.83203125, "training_acc": 72.33333333333333, "val_loss": 439493.10205078125, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1517794.23828125, "training_acc": 45.333333333333336, "val_loss": 795272.255859375, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2988490.33203125, "training_acc": 72.33333333333333, "val_loss": 253798.9775390625, "val_acc": 72.0}
{"epoch": 36, "training_loss": 668286.7578125, "training_acc": 55.0, "val_loss": 134578.8579711914, "val_acc": 72.0}
