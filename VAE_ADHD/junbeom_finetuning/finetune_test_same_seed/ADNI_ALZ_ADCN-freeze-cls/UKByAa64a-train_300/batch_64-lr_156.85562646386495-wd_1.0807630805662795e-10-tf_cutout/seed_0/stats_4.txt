"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3613596.0640945435, "training_acc": 65.66666666666667, "val_loss": 2088788.298828125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 4172198.6171875, "training_acc": 55.0, "val_loss": 1557814.0625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 5482417.91015625, "training_acc": 72.33333333333333, "val_loss": 538389.658203125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4427588.875, "training_acc": 43.0, "val_loss": 575859.2973632812, "val_acc": 28.0}
{"epoch": 4, "training_loss": 2840653.6640625, "training_acc": 62.333333333333336, "val_loss": 1220604.2216796875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3956878.451171875, "training_acc": 72.33333333333333, "val_loss": 201857.84375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2264895.7919921875, "training_acc": 39.0, "val_loss": 300962.1181640625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1328363.4560546875, "training_acc": 72.33333333333333, "val_loss": 152609.1485595703, "val_acc": 28.0}
{"epoch": 8, "training_loss": 796131.0986328125, "training_acc": 51.666666666666664, "val_loss": 208099.31762695312, "val_acc": 72.0}
{"epoch": 9, "training_loss": 987211.306640625, "training_acc": 50.333333333333336, "val_loss": 291517.359375, "val_acc": 72.0}
{"epoch": 10, "training_loss": 920830.857421875, "training_acc": 67.0, "val_loss": 75906.52758789062, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1349307.990234375, "training_acc": 61.0, "val_loss": 305036.1123046875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1459543.3681640625, "training_acc": 45.0, "val_loss": 334604.54833984375, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2453253.58984375, "training_acc": 72.33333333333333, "val_loss": 708129.9267578125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1696961.0703125, "training_acc": 65.33333333333333, "val_loss": 570885.0703125, "val_acc": 28.0}
{"epoch": 15, "training_loss": 1612179.634765625, "training_acc": 59.666666666666664, "val_loss": 820571.6936035156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2414922.2109375, "training_acc": 72.33333333333333, "val_loss": 277888.60986328125, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1121033.1533203125, "training_acc": 50.666666666666664, "val_loss": 408181.92822265625, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1004470.0659179688, "training_acc": 70.0, "val_loss": 485863.8603515625, "val_acc": 28.0}
{"epoch": 19, "training_loss": 789042.1635742188, "training_acc": 63.0, "val_loss": 71681.80944824219, "val_acc": 28.0}
{"epoch": 20, "training_loss": 279058.1862792969, "training_acc": 55.666666666666664, "val_loss": 122743.53234863281, "val_acc": 72.0}
{"epoch": 21, "training_loss": 500789.53125, "training_acc": 55.666666666666664, "val_loss": 63049.34356689453, "val_acc": 72.0}
{"epoch": 22, "training_loss": 293480.234375, "training_acc": 57.666666666666664, "val_loss": 63916.891357421875, "val_acc": 72.0}
{"epoch": 23, "training_loss": 328573.51623535156, "training_acc": 62.333333333333336, "val_loss": 25608.771606445312, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 383940.2041015625, "training_acc": 62.333333333333336, "val_loss": 66242.0072631836, "val_acc": 28.0}
{"epoch": 25, "training_loss": 286993.609375, "training_acc": 53.0, "val_loss": 108560.02905273438, "val_acc": 72.0}
{"epoch": 26, "training_loss": 338354.17431640625, "training_acc": 64.66666666666667, "val_loss": 126805.56359863281, "val_acc": 72.0}
{"epoch": 27, "training_loss": 350275.857421875, "training_acc": 65.0, "val_loss": 41508.2414855957, "val_acc": 72.0}
{"epoch": 28, "training_loss": 464947.92578125, "training_acc": 59.0, "val_loss": 76203.78845214844, "val_acc": 28.0}
{"epoch": 29, "training_loss": 344880.4140625, "training_acc": 55.666666666666664, "val_loss": 25074.996742248535, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 240080.45239257812, "training_acc": 64.66666666666667, "val_loss": 87798.78234863281, "val_acc": 72.0}
{"epoch": 31, "training_loss": 297253.37744140625, "training_acc": 63.0, "val_loss": 71341.08276367188, "val_acc": 72.0}
{"epoch": 32, "training_loss": 378824.28564453125, "training_acc": 60.666666666666664, "val_loss": 226391.83276367188, "val_acc": 28.0}
{"epoch": 33, "training_loss": 986195.958984375, "training_acc": 53.666666666666664, "val_loss": 381766.09619140625, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1169109.625, "training_acc": 57.0, "val_loss": 70118.35467529297, "val_acc": 72.0}
{"epoch": 35, "training_loss": 580121.6114501953, "training_acc": 73.33333333333333, "val_loss": 247354.734375, "val_acc": 28.0}
{"epoch": 36, "training_loss": 570602.9829101562, "training_acc": 60.333333333333336, "val_loss": 46703.583251953125, "val_acc": 45.333333333333336}
{"epoch": 37, "training_loss": 228406.72290039062, "training_acc": 57.666666666666664, "val_loss": 162634.60180664062, "val_acc": 72.0}
{"epoch": 38, "training_loss": 443730.9716796875, "training_acc": 63.666666666666664, "val_loss": 112353.541015625, "val_acc": 72.0}
{"epoch": 39, "training_loss": 335064.55126953125, "training_acc": 63.0, "val_loss": 94105.60717773438, "val_acc": 72.0}
{"epoch": 40, "training_loss": 373618.234375, "training_acc": 63.0, "val_loss": 171911.25952148438, "val_acc": 72.0}
{"epoch": 41, "training_loss": 466932.677734375, "training_acc": 60.333333333333336, "val_loss": 191181.46325683594, "val_acc": 72.0}
{"epoch": 42, "training_loss": 448551.7268066406, "training_acc": 63.0, "val_loss": 172676.771484375, "val_acc": 72.0}
{"epoch": 43, "training_loss": 400403.357421875, "training_acc": 66.66666666666667, "val_loss": 72562.92083740234, "val_acc": 72.0}
{"epoch": 44, "training_loss": 295798.4978027344, "training_acc": 62.333333333333336, "val_loss": 20969.42121887207, "val_acc": 77.33333333333333}
{"epoch": 45, "training_loss": 508204.421875, "training_acc": 59.666666666666664, "val_loss": 67599.13482666016, "val_acc": 72.0}
{"epoch": 46, "training_loss": 969865.5859375, "training_acc": 49.666666666666664, "val_loss": 418891.744140625, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1185286.126953125, "training_acc": 66.0, "val_loss": 427806.3828125, "val_acc": 28.0}
{"epoch": 48, "training_loss": 717845.935546875, "training_acc": 63.666666666666664, "val_loss": 23981.79302215576, "val_acc": 80.0}
{"epoch": 49, "training_loss": 334784.32861328125, "training_acc": 52.666666666666664, "val_loss": 106645.09375, "val_acc": 72.0}
{"epoch": 50, "training_loss": 579946.02734375, "training_acc": 67.66666666666667, "val_loss": 66335.75189208984, "val_acc": 44.0}
{"epoch": 51, "training_loss": 1035618.12890625, "training_acc": 64.33333333333333, "val_loss": 217265.37927246094, "val_acc": 72.0}
{"epoch": 52, "training_loss": 614964.4680175781, "training_acc": 58.666666666666664, "val_loss": 149328.4970703125, "val_acc": 72.0}
{"epoch": 53, "training_loss": 323545.6931152344, "training_acc": 66.0, "val_loss": 65784.83093261719, "val_acc": 72.0}
{"epoch": 54, "training_loss": 229972.0555419922, "training_acc": 64.0, "val_loss": 26727.207580566406, "val_acc": 77.33333333333333}
{"epoch": 55, "training_loss": 200545.2841796875, "training_acc": 64.66666666666667, "val_loss": 66827.35131835938, "val_acc": 72.0}
{"epoch": 56, "training_loss": 240928.640625, "training_acc": 64.66666666666667, "val_loss": 52260.30419921875, "val_acc": 72.0}
{"epoch": 57, "training_loss": 208932.830078125, "training_acc": 63.0, "val_loss": 52719.61413574219, "val_acc": 72.0}
{"epoch": 58, "training_loss": 142643.48876953125, "training_acc": 70.66666666666667, "val_loss": 24387.06594467163, "val_acc": 74.66666666666667}
{"epoch": 59, "training_loss": 111585.05004882812, "training_acc": 68.33333333333333, "val_loss": 73642.7035522461, "val_acc": 72.0}
{"epoch": 60, "training_loss": 303853.6208496094, "training_acc": 62.0, "val_loss": 25192.222480773926, "val_acc": 81.33333333333333}
{"epoch": 61, "training_loss": 277818.4777832031, "training_acc": 64.66666666666667, "val_loss": 156723.96948242188, "val_acc": 28.0}
{"epoch": 62, "training_loss": 353228.49462890625, "training_acc": 64.0, "val_loss": 72247.759765625, "val_acc": 40.0}
{"epoch": 63, "training_loss": 269095.98388671875, "training_acc": 62.0, "val_loss": 78878.5947265625, "val_acc": 72.0}
