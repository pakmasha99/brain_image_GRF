"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5840003.045211792, "training_acc": 58.333333333333336, "val_loss": 2595200.45703125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 6570040.8984375, "training_acc": 46.333333333333336, "val_loss": 1971790.576171875, "val_acc": 72.0}
{"epoch": 2, "training_loss": 7534733.6328125, "training_acc": 72.33333333333333, "val_loss": 724190.0087890625, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 3665777.1328125, "training_acc": 53.0, "val_loss": 256479.38806152344, "val_acc": 77.33333333333333}
{"epoch": 4, "training_loss": 3017155.6953125, "training_acc": 72.0, "val_loss": 668510.216796875, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 2544453.9609375, "training_acc": 65.66666666666667, "val_loss": 196051.84619140625, "val_acc": 69.33333333333333}
{"epoch": 6, "training_loss": 1618363.2421875, "training_acc": 73.33333333333333, "val_loss": 99302.10205078125, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 563014.4326171875, "training_acc": 65.0, "val_loss": 158071.8280029297, "val_acc": 48.0}
{"epoch": 8, "training_loss": 479373.0576171875, "training_acc": 64.0, "val_loss": 181094.66259765625, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1049621.0537109375, "training_acc": 59.666666666666664, "val_loss": 325654.234375, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1613097.451171875, "training_acc": 69.66666666666667, "val_loss": 256220.72645568848, "val_acc": 60.0}
{"epoch": 11, "training_loss": 1303104.576171875, "training_acc": 64.33333333333333, "val_loss": 88419.8740234375, "val_acc": 82.66666666666667}
{"epoch": 12, "training_loss": 997646.248046875, "training_acc": 63.666666666666664, "val_loss": 398573.43701171875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 961928.6787109375, "training_acc": 66.0, "val_loss": 220134.43408203125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 985385.71875, "training_acc": 70.0, "val_loss": 211245.4375, "val_acc": 46.666666666666664}
{"epoch": 15, "training_loss": 1463894.6572265625, "training_acc": 66.66666666666667, "val_loss": 205004.2626953125, "val_acc": 48.0}
{"epoch": 16, "training_loss": 945750.7880859375, "training_acc": 62.666666666666664, "val_loss": 274790.1726074219, "val_acc": 72.0}
{"epoch": 17, "training_loss": 862726.4619140625, "training_acc": 64.0, "val_loss": 266656.0670776367, "val_acc": 72.0}
{"epoch": 18, "training_loss": 740945.1342773438, "training_acc": 64.0, "val_loss": 104446.43713378906, "val_acc": 72.0}
{"epoch": 19, "training_loss": 349296.4426269531, "training_acc": 73.33333333333333, "val_loss": 68321.77838134766, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 392332.69140625, "training_acc": 65.66666666666667, "val_loss": 47413.69775390625, "val_acc": 77.33333333333333}
{"epoch": 21, "training_loss": 342124.16064453125, "training_acc": 71.66666666666667, "val_loss": 102809.66772460938, "val_acc": 76.0}
{"epoch": 22, "training_loss": 366816.03857421875, "training_acc": 72.33333333333333, "val_loss": 151157.873046875, "val_acc": 72.0}
{"epoch": 23, "training_loss": 319523.9296875, "training_acc": 74.0, "val_loss": 47869.8078918457, "val_acc": 64.0}
{"epoch": 24, "training_loss": 124017.10522460938, "training_acc": 80.33333333333333, "val_loss": 40292.485595703125, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 195177.50390625, "training_acc": 71.66666666666667, "val_loss": 91124.349609375, "val_acc": 46.666666666666664}
{"epoch": 26, "training_loss": 283394.68994140625, "training_acc": 68.66666666666667, "val_loss": 146564.8643798828, "val_acc": 72.0}
{"epoch": 27, "training_loss": 415174.556640625, "training_acc": 70.0, "val_loss": 57973.04901123047, "val_acc": 78.66666666666667}
{"epoch": 28, "training_loss": 300523.8757324219, "training_acc": 70.66666666666667, "val_loss": 37561.296875, "val_acc": 76.0}
{"epoch": 29, "training_loss": 145354.97412109375, "training_acc": 78.0, "val_loss": 29081.499145507812, "val_acc": 77.33333333333333}
{"epoch": 30, "training_loss": 148539.70141601562, "training_acc": 80.33333333333333, "val_loss": 83260.27026367188, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 376325.6416015625, "training_acc": 68.33333333333333, "val_loss": 43980.44674682617, "val_acc": 74.66666666666667}
{"epoch": 32, "training_loss": 306764.19775390625, "training_acc": 70.66666666666667, "val_loss": 79760.3275756836, "val_acc": 64.0}
{"epoch": 33, "training_loss": 606259.63671875, "training_acc": 66.33333333333333, "val_loss": 37301.138916015625, "val_acc": 72.0}
{"epoch": 34, "training_loss": 687937.1181640625, "training_acc": 68.33333333333333, "val_loss": 70793.5678100586, "val_acc": 65.33333333333333}
{"epoch": 35, "training_loss": 757553.384765625, "training_acc": 71.66666666666667, "val_loss": 192640.34985351562, "val_acc": 46.666666666666664}
{"epoch": 36, "training_loss": 605049.4243164062, "training_acc": 69.0, "val_loss": 104461.07373046875, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 286893.9609375, "training_acc": 77.0, "val_loss": 168809.45703125, "val_acc": 50.666666666666664}
{"epoch": 38, "training_loss": 302275.2907714844, "training_acc": 70.66666666666667, "val_loss": 36998.98828125, "val_acc": 76.0}
{"epoch": 39, "training_loss": 247616.734375, "training_acc": 76.0, "val_loss": 59849.677734375, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 227639.77197265625, "training_acc": 74.33333333333333, "val_loss": 104414.99792480469, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 413675.076171875, "training_acc": 66.0, "val_loss": 39804.4150390625, "val_acc": 72.0}
{"epoch": 42, "training_loss": 230077.71264648438, "training_acc": 77.0, "val_loss": 55073.69354248047, "val_acc": 72.0}
{"epoch": 43, "training_loss": 171713.72259521484, "training_acc": 79.33333333333333, "val_loss": 44661.481201171875, "val_acc": 78.66666666666667}
{"epoch": 44, "training_loss": 141380.310546875, "training_acc": 79.33333333333333, "val_loss": 35293.476623535156, "val_acc": 80.0}
{"epoch": 45, "training_loss": 302328.9443359375, "training_acc": 71.66666666666667, "val_loss": 61866.927825927734, "val_acc": 80.0}
{"epoch": 46, "training_loss": 225963.2872314453, "training_acc": 78.0, "val_loss": 52459.19161987305, "val_acc": 74.66666666666667}
{"epoch": 47, "training_loss": 310239.28466796875, "training_acc": 67.66666666666667, "val_loss": 147993.0479736328, "val_acc": 72.0}
{"epoch": 48, "training_loss": 480826.84716796875, "training_acc": 70.0, "val_loss": 96876.88061523438, "val_acc": 73.33333333333333}
