"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1406.9149932861328, "training_acc": 59.0, "val_loss": 263.14701747894287, "val_acc": 72.0}
{"epoch": 1, "training_loss": 980.1655321121216, "training_acc": 67.0, "val_loss": 100.072713971138, "val_acc": 66.66666666666667}
{"epoch": 2, "training_loss": 505.21351957321167, "training_acc": 69.33333333333333, "val_loss": 77.18804407119751, "val_acc": 77.33333333333333}
{"epoch": 3, "training_loss": 318.60073375701904, "training_acc": 70.33333333333333, "val_loss": 48.583110213279724, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 205.18099689483643, "training_acc": 67.33333333333333, "val_loss": 74.16361248493195, "val_acc": 44.0}
{"epoch": 5, "training_loss": 177.79106378555298, "training_acc": 73.0, "val_loss": 42.321699768304825, "val_acc": 76.0}
{"epoch": 6, "training_loss": 194.25741803646088, "training_acc": 69.66666666666667, "val_loss": 67.21275913715363, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 182.9492645263672, "training_acc": 72.33333333333333, "val_loss": 40.43819531798363, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 154.38384985923767, "training_acc": 73.66666666666667, "val_loss": 42.92177078127861, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 141.91139841079712, "training_acc": 75.66666666666667, "val_loss": 37.26358273625374, "val_acc": 81.33333333333333}
{"epoch": 10, "training_loss": 175.24915385246277, "training_acc": 72.66666666666667, "val_loss": 46.611411571502686, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 233.60424613952637, "training_acc": 61.0, "val_loss": 75.23828434944153, "val_acc": 72.0}
{"epoch": 12, "training_loss": 303.7095432281494, "training_acc": 66.33333333333333, "val_loss": 100.1863979101181, "val_acc": 72.0}
{"epoch": 13, "training_loss": 338.9218490123749, "training_acc": 67.0, "val_loss": 74.04874062538147, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 212.24981665611267, "training_acc": 74.0, "val_loss": 98.49308753013611, "val_acc": 72.0}
{"epoch": 15, "training_loss": 421.6714377403259, "training_acc": 62.666666666666664, "val_loss": 132.27970671653748, "val_acc": 72.0}
{"epoch": 16, "training_loss": 469.3306231498718, "training_acc": 68.66666666666667, "val_loss": 46.4154269695282, "val_acc": 80.0}
{"epoch": 17, "training_loss": 357.6535050868988, "training_acc": 73.66666666666667, "val_loss": 58.093509674072266, "val_acc": 65.33333333333333}
{"epoch": 18, "training_loss": 238.16184902191162, "training_acc": 67.33333333333333, "val_loss": 46.829899191856384, "val_acc": 77.33333333333333}
{"epoch": 19, "training_loss": 166.37724661827087, "training_acc": 73.0, "val_loss": 42.37581980228424, "val_acc": 77.33333333333333}
{"epoch": 20, "training_loss": 141.57845556735992, "training_acc": 78.66666666666667, "val_loss": 45.0250186920166, "val_acc": 65.33333333333333}
{"epoch": 21, "training_loss": 169.41019535064697, "training_acc": 72.66666666666667, "val_loss": 57.329280734062195, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 199.43512535095215, "training_acc": 70.66666666666667, "val_loss": 86.63403105735779, "val_acc": 72.0}
{"epoch": 23, "training_loss": 296.69962936639786, "training_acc": 69.0, "val_loss": 106.04051041603088, "val_acc": 72.0}
{"epoch": 24, "training_loss": 262.5470817089081, "training_acc": 70.66666666666667, "val_loss": 86.91112613677979, "val_acc": 72.0}
{"epoch": 25, "training_loss": 248.60231947898865, "training_acc": 71.0, "val_loss": 65.79509803652763, "val_acc": 74.66666666666667}
{"epoch": 26, "training_loss": 165.702761054039, "training_acc": 76.33333333333333, "val_loss": 49.963053703308105, "val_acc": 74.66666666666667}
{"epoch": 27, "training_loss": 126.60982298851013, "training_acc": 81.0, "val_loss": 39.20407563447952, "val_acc": 80.0}
{"epoch": 28, "training_loss": 123.12547492980957, "training_acc": 83.66666666666667, "val_loss": 40.391342759132385, "val_acc": 82.66666666666667}
