"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 671.3669452667236, "training_acc": 69.66666666666667, "val_loss": 247.2918086051941, "val_acc": 28.0}
{"epoch": 1, "training_loss": 674.6261854171753, "training_acc": 60.333333333333336, "val_loss": 167.30867195129395, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 515.2051458358765, "training_acc": 58.0, "val_loss": 131.84127461910248, "val_acc": 52.0}
{"epoch": 3, "training_loss": 491.07225799560547, "training_acc": 69.0, "val_loss": 163.9179515838623, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 345.7470417022705, "training_acc": 69.66666666666667, "val_loss": 153.7261700630188, "val_acc": 49.333333333333336}
{"epoch": 5, "training_loss": 348.4347686767578, "training_acc": 70.33333333333333, "val_loss": 115.25579154491425, "val_acc": 70.66666666666667}
{"epoch": 6, "training_loss": 286.75509881973267, "training_acc": 64.33333333333333, "val_loss": 66.35507422685623, "val_acc": 61.333333333333336}
{"epoch": 7, "training_loss": 223.0751554965973, "training_acc": 72.66666666666667, "val_loss": 65.63516235351562, "val_acc": 56.0}
{"epoch": 8, "training_loss": 211.65070867538452, "training_acc": 67.33333333333333, "val_loss": 71.0658347606659, "val_acc": 69.33333333333333}
{"epoch": 9, "training_loss": 218.07017946243286, "training_acc": 68.0, "val_loss": 60.76562878489494, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 200.0382363796234, "training_acc": 75.66666666666667, "val_loss": 83.4921464920044, "val_acc": 34.666666666666664}
{"epoch": 11, "training_loss": 194.29904913902283, "training_acc": 68.0, "val_loss": 56.67722952365875, "val_acc": 69.33333333333333}
{"epoch": 12, "training_loss": 179.8240909576416, "training_acc": 69.0, "val_loss": 51.99199151992798, "val_acc": 69.33333333333333}
{"epoch": 13, "training_loss": 151.48491382598877, "training_acc": 76.66666666666667, "val_loss": 46.66748571395874, "val_acc": 65.33333333333333}
{"epoch": 14, "training_loss": 149.99348163604736, "training_acc": 75.0, "val_loss": 49.118848741054535, "val_acc": 58.666666666666664}
{"epoch": 15, "training_loss": 137.9288865327835, "training_acc": 77.66666666666667, "val_loss": 46.444804310798645, "val_acc": 68.0}
{"epoch": 16, "training_loss": 137.39679336547852, "training_acc": 79.33333333333333, "val_loss": 46.28948950767517, "val_acc": 65.33333333333333}
{"epoch": 17, "training_loss": 143.73744237422943, "training_acc": 76.33333333333333, "val_loss": 48.06815314292908, "val_acc": 64.0}
{"epoch": 18, "training_loss": 136.99191188812256, "training_acc": 79.0, "val_loss": 50.477512419223785, "val_acc": 65.33333333333333}
{"epoch": 19, "training_loss": 145.09090089797974, "training_acc": 76.33333333333333, "val_loss": 45.93788734078407, "val_acc": 66.66666666666667}
{"epoch": 20, "training_loss": 135.58195066452026, "training_acc": 79.0, "val_loss": 45.852967232465744, "val_acc": 68.0}
{"epoch": 21, "training_loss": 134.17483854293823, "training_acc": 79.33333333333333, "val_loss": 46.56440931558609, "val_acc": 66.66666666666667}
{"epoch": 22, "training_loss": 139.87450766563416, "training_acc": 78.66666666666667, "val_loss": 45.57730370759964, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 146.52247869968414, "training_acc": 76.0, "val_loss": 50.844587087631226, "val_acc": 72.0}
{"epoch": 24, "training_loss": 141.25965762138367, "training_acc": 76.33333333333333, "val_loss": 46.867075085639954, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 143.78075003623962, "training_acc": 75.66666666666667, "val_loss": 48.02181816101074, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 140.77258944511414, "training_acc": 77.33333333333333, "val_loss": 49.571886360645294, "val_acc": 72.0}
{"epoch": 27, "training_loss": 143.65538477897644, "training_acc": 76.66666666666667, "val_loss": 46.091652035713196, "val_acc": 69.33333333333333}
{"epoch": 28, "training_loss": 140.54465579986572, "training_acc": 76.0, "val_loss": 47.31356245279312, "val_acc": 66.66666666666667}
{"epoch": 29, "training_loss": 128.9386261701584, "training_acc": 81.33333333333333, "val_loss": 46.03561735153198, "val_acc": 69.33333333333333}
{"epoch": 30, "training_loss": 127.5735512971878, "training_acc": 80.66666666666667, "val_loss": 45.669186532497406, "val_acc": 70.66666666666667}
{"epoch": 31, "training_loss": 133.4624888896942, "training_acc": 80.0, "val_loss": 51.38006514310837, "val_acc": 61.333333333333336}
{"epoch": 32, "training_loss": 166.72958481311798, "training_acc": 71.66666666666667, "val_loss": 49.75579336285591, "val_acc": 64.0}
{"epoch": 33, "training_loss": 173.87292456626892, "training_acc": 74.66666666666667, "val_loss": 60.03517961502075, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 173.39225602149963, "training_acc": 76.66666666666667, "val_loss": 88.21140658855438, "val_acc": 69.33333333333333}
{"epoch": 35, "training_loss": 198.45205903053284, "training_acc": 73.0, "val_loss": 55.55728489160538, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 154.63466238975525, "training_acc": 74.66666666666667, "val_loss": 62.23017102479935, "val_acc": 52.0}
{"epoch": 37, "training_loss": 210.727933883667, "training_acc": 68.0, "val_loss": 74.59184122085571, "val_acc": 48.0}
{"epoch": 38, "training_loss": 185.0367374420166, "training_acc": 72.33333333333333, "val_loss": 79.35022985935211, "val_acc": 50.666666666666664}
{"epoch": 39, "training_loss": 197.5041515827179, "training_acc": 71.0, "val_loss": 56.57223916053772, "val_acc": 72.0}
{"epoch": 40, "training_loss": 153.00349831581116, "training_acc": 77.0, "val_loss": 56.1291139125824, "val_acc": 72.0}
{"epoch": 41, "training_loss": 143.2367660999298, "training_acc": 75.66666666666667, "val_loss": 43.63777893781662, "val_acc": 74.66666666666667}
{"epoch": 42, "training_loss": 124.37772381305695, "training_acc": 80.66666666666667, "val_loss": 46.07694947719574, "val_acc": 70.66666666666667}
{"epoch": 43, "training_loss": 118.42975604534149, "training_acc": 83.66666666666667, "val_loss": 55.00862169265747, "val_acc": 72.0}
{"epoch": 44, "training_loss": 136.50401186943054, "training_acc": 79.33333333333333, "val_loss": 49.9620715379715, "val_acc": 72.0}
{"epoch": 45, "training_loss": 127.39329755306244, "training_acc": 80.33333333333333, "val_loss": 50.41183856129646, "val_acc": 68.0}
{"epoch": 46, "training_loss": 115.58989787101746, "training_acc": 85.0, "val_loss": 48.68574267625809, "val_acc": 73.33333333333333}
{"epoch": 47, "training_loss": 116.15011322498322, "training_acc": 81.33333333333333, "val_loss": 48.870643973350525, "val_acc": 68.0}
{"epoch": 48, "training_loss": 116.51347804069519, "training_acc": 83.0, "val_loss": 53.313155233860016, "val_acc": 65.33333333333333}
{"epoch": 49, "training_loss": 131.41685473918915, "training_acc": 81.33333333333333, "val_loss": 59.45334994792938, "val_acc": 62.666666666666664}
{"epoch": 50, "training_loss": 159.47917592525482, "training_acc": 76.0, "val_loss": 64.14577674865723, "val_acc": 56.0}
{"epoch": 51, "training_loss": 167.80840969085693, "training_acc": 74.66666666666667, "val_loss": 54.218335032463074, "val_acc": 72.0}
{"epoch": 52, "training_loss": 168.60760021209717, "training_acc": 75.0, "val_loss": 66.69644668698311, "val_acc": 70.66666666666667}
{"epoch": 53, "training_loss": 150.88435566425323, "training_acc": 75.0, "val_loss": 77.63626301288605, "val_acc": 70.66666666666667}
{"epoch": 54, "training_loss": 210.73524689674377, "training_acc": 69.66666666666667, "val_loss": 63.34924399852753, "val_acc": 73.33333333333333}
{"epoch": 55, "training_loss": 154.99261486530304, "training_acc": 78.33333333333333, "val_loss": 89.8460578918457, "val_acc": 48.0}
{"epoch": 56, "training_loss": 205.15281915664673, "training_acc": 71.33333333333333, "val_loss": 63.83722919225693, "val_acc": 62.666666666666664}
{"epoch": 57, "training_loss": 131.98017406463623, "training_acc": 79.0, "val_loss": 52.701212376356125, "val_acc": 73.33333333333333}
{"epoch": 58, "training_loss": 121.47276842594147, "training_acc": 83.0, "val_loss": 50.544963121414185, "val_acc": 76.0}
{"epoch": 59, "training_loss": 117.49882686138153, "training_acc": 83.66666666666667, "val_loss": 49.22738754749298, "val_acc": 72.0}
{"epoch": 60, "training_loss": 125.40283370018005, "training_acc": 78.66666666666667, "val_loss": 51.08406983315945, "val_acc": 72.0}
