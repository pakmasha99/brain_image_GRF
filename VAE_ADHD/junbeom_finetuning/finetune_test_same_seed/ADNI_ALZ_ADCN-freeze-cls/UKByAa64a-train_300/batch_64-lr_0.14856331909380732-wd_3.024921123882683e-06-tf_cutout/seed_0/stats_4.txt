"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 701.2597396373749, "training_acc": 58.333333333333336, "val_loss": 127.60141134262085, "val_acc": 72.0}
{"epoch": 1, "training_loss": 354.61971044540405, "training_acc": 69.33333333333333, "val_loss": 53.82089093327522, "val_acc": 74.66666666666667}
{"epoch": 2, "training_loss": 260.3253724575043, "training_acc": 69.33333333333333, "val_loss": 65.00489664077759, "val_acc": 32.0}
{"epoch": 3, "training_loss": 215.5612494945526, "training_acc": 63.333333333333336, "val_loss": 43.10038620233536, "val_acc": 54.666666666666664}
{"epoch": 4, "training_loss": 170.24079942703247, "training_acc": 71.0, "val_loss": 50.32020628452301, "val_acc": 70.66666666666667}
{"epoch": 5, "training_loss": 181.51770210266113, "training_acc": 71.33333333333333, "val_loss": 56.17390429973602, "val_acc": 70.66666666666667}
{"epoch": 6, "training_loss": 178.3239542245865, "training_acc": 72.33333333333333, "val_loss": 62.01172286272049, "val_acc": 72.0}
{"epoch": 7, "training_loss": 195.50762629508972, "training_acc": 68.0, "val_loss": 65.97475337982178, "val_acc": 72.0}
{"epoch": 8, "training_loss": 205.16101598739624, "training_acc": 70.0, "val_loss": 43.653960943222046, "val_acc": 72.0}
{"epoch": 9, "training_loss": 152.93008852005005, "training_acc": 76.33333333333333, "val_loss": 40.37087291479111, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 140.83639335632324, "training_acc": 79.66666666666667, "val_loss": 40.5766980946064, "val_acc": 76.0}
{"epoch": 11, "training_loss": 157.06003618240356, "training_acc": 74.66666666666667, "val_loss": 40.69408988952637, "val_acc": 77.33333333333333}
{"epoch": 12, "training_loss": 184.4851634502411, "training_acc": 71.0, "val_loss": 38.72499920427799, "val_acc": 80.0}
{"epoch": 13, "training_loss": 186.53464317321777, "training_acc": 68.0, "val_loss": 39.582749128341675, "val_acc": 76.0}
{"epoch": 14, "training_loss": 172.16718101501465, "training_acc": 70.66666666666667, "val_loss": 40.66865110397339, "val_acc": 76.0}
{"epoch": 15, "training_loss": 148.43597722053528, "training_acc": 74.66666666666667, "val_loss": 38.69630426168442, "val_acc": 80.0}
{"epoch": 16, "training_loss": 134.76851737499237, "training_acc": 81.33333333333333, "val_loss": 58.09492242336273, "val_acc": 72.0}
{"epoch": 17, "training_loss": 183.5027792453766, "training_acc": 68.33333333333333, "val_loss": 87.63717865943909, "val_acc": 72.0}
{"epoch": 18, "training_loss": 234.24618422985077, "training_acc": 68.0, "val_loss": 70.08406090736389, "val_acc": 70.66666666666667}
{"epoch": 19, "training_loss": 206.89729011058807, "training_acc": 71.33333333333333, "val_loss": 50.071572840213776, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 143.5727982521057, "training_acc": 79.33333333333333, "val_loss": 43.12342789769173, "val_acc": 76.0}
{"epoch": 21, "training_loss": 148.55605959892273, "training_acc": 75.33333333333333, "val_loss": 45.80955791473389, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 145.71500265598297, "training_acc": 76.66666666666667, "val_loss": 36.714399576187134, "val_acc": 80.0}
{"epoch": 23, "training_loss": 131.6200532913208, "training_acc": 78.66666666666667, "val_loss": 43.40476983785629, "val_acc": 74.66666666666667}
{"epoch": 24, "training_loss": 141.32472014427185, "training_acc": 77.0, "val_loss": 40.90582585334778, "val_acc": 74.66666666666667}
{"epoch": 25, "training_loss": 137.82761108875275, "training_acc": 77.66666666666667, "val_loss": 35.026797235012054, "val_acc": 78.66666666666667}
{"epoch": 26, "training_loss": 133.0855095386505, "training_acc": 78.0, "val_loss": 43.77658748626709, "val_acc": 76.0}
{"epoch": 27, "training_loss": 154.25042951107025, "training_acc": 76.0, "val_loss": 49.43936038017273, "val_acc": 76.0}
{"epoch": 28, "training_loss": 152.97778713703156, "training_acc": 73.66666666666667, "val_loss": 40.37929920852184, "val_acc": 76.0}
{"epoch": 29, "training_loss": 156.8562479019165, "training_acc": 74.66666666666667, "val_loss": 50.28808355331421, "val_acc": 76.0}
{"epoch": 30, "training_loss": 191.7119221687317, "training_acc": 72.0, "val_loss": 36.18611681461334, "val_acc": 82.66666666666667}
{"epoch": 31, "training_loss": 194.11822175979614, "training_acc": 71.33333333333333, "val_loss": 39.68519288301468, "val_acc": 70.66666666666667}
{"epoch": 32, "training_loss": 156.66314899921417, "training_acc": 74.0, "val_loss": 53.96116316318512, "val_acc": 52.0}
{"epoch": 33, "training_loss": 167.3036379814148, "training_acc": 71.66666666666667, "val_loss": 45.54206109046936, "val_acc": 58.666666666666664}
{"epoch": 34, "training_loss": 138.01150107383728, "training_acc": 78.0, "val_loss": 36.41897797584534, "val_acc": 81.33333333333333}
{"epoch": 35, "training_loss": 144.45248246192932, "training_acc": 76.0, "val_loss": 37.227432787418365, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 177.49039506912231, "training_acc": 72.33333333333333, "val_loss": 36.49782237410545, "val_acc": 81.33333333333333}
{"epoch": 37, "training_loss": 125.15659689903259, "training_acc": 80.0, "val_loss": 36.46408152580261, "val_acc": 76.0}
{"epoch": 38, "training_loss": 148.41067671775818, "training_acc": 74.66666666666667, "val_loss": 35.388578087091446, "val_acc": 74.66666666666667}
{"epoch": 39, "training_loss": 171.7786774635315, "training_acc": 73.33333333333333, "val_loss": 40.32952153682709, "val_acc": 78.66666666666667}
{"epoch": 40, "training_loss": 127.154625415802, "training_acc": 79.33333333333333, "val_loss": 51.500171184539795, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 133.7034329175949, "training_acc": 77.0, "val_loss": 43.81703186035156, "val_acc": 76.0}
{"epoch": 42, "training_loss": 128.78317761421204, "training_acc": 76.0, "val_loss": 43.83058479428291, "val_acc": 76.0}
{"epoch": 43, "training_loss": 124.64150595664978, "training_acc": 81.66666666666667, "val_loss": 37.20888730883598, "val_acc": 84.0}
{"epoch": 44, "training_loss": 121.71106624603271, "training_acc": 80.66666666666667, "val_loss": 35.67219936847687, "val_acc": 81.33333333333333}
