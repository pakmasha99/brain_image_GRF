"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1156.3336505889893, "training_acc": 67.66666666666667, "val_loss": 153.6380136013031, "val_acc": 37.333333333333336}
{"epoch": 1, "training_loss": 916.3688507080078, "training_acc": 67.0, "val_loss": 209.08034086227417, "val_acc": 69.33333333333333}
{"epoch": 2, "training_loss": 566.0771427154541, "training_acc": 64.0, "val_loss": 149.77903509140015, "val_acc": 65.33333333333333}
{"epoch": 3, "training_loss": 530.4259204864502, "training_acc": 72.33333333333333, "val_loss": 127.90861773490906, "val_acc": 64.0}
{"epoch": 4, "training_loss": 323.26106095314026, "training_acc": 68.0, "val_loss": 106.91616702079773, "val_acc": 72.0}
{"epoch": 5, "training_loss": 260.0048294067383, "training_acc": 65.33333333333333, "val_loss": 76.12558114528656, "val_acc": 69.33333333333333}
{"epoch": 6, "training_loss": 220.72311925888062, "training_acc": 67.66666666666667, "val_loss": 82.5772613286972, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 240.04275751113892, "training_acc": 69.66666666666667, "val_loss": 82.15688467025757, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 209.34397268295288, "training_acc": 69.0, "val_loss": 50.978543400764465, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 154.69187593460083, "training_acc": 75.0, "val_loss": 43.96991753578186, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 145.56521701812744, "training_acc": 79.66666666666667, "val_loss": 49.70055893063545, "val_acc": 65.33333333333333}
{"epoch": 11, "training_loss": 147.0473906993866, "training_acc": 80.0, "val_loss": 49.24845916032791, "val_acc": 64.0}
{"epoch": 12, "training_loss": 141.45920634269714, "training_acc": 77.66666666666667, "val_loss": 60.22229024767876, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 192.25302505493164, "training_acc": 70.0, "val_loss": 48.11402481794357, "val_acc": 72.0}
{"epoch": 14, "training_loss": 183.1189215183258, "training_acc": 74.0, "val_loss": 61.044063568115234, "val_acc": 57.333333333333336}
{"epoch": 15, "training_loss": 168.94300520420074, "training_acc": 73.0, "val_loss": 76.32245260477066, "val_acc": 46.666666666666664}
{"epoch": 16, "training_loss": 170.15151071548462, "training_acc": 70.66666666666667, "val_loss": 57.81049567461014, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 169.68808937072754, "training_acc": 76.33333333333333, "val_loss": 65.12457704544067, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 192.7602894306183, "training_acc": 71.33333333333333, "val_loss": 82.60816931724548, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 280.4580125808716, "training_acc": 65.33333333333333, "val_loss": 88.16343402862549, "val_acc": 70.66666666666667}
{"epoch": 20, "training_loss": 253.36108016967773, "training_acc": 76.33333333333333, "val_loss": 134.8867164850235, "val_acc": 42.666666666666664}
{"epoch": 21, "training_loss": 265.613676071167, "training_acc": 75.66666666666667, "val_loss": 82.75458639860153, "val_acc": 60.0}
{"epoch": 22, "training_loss": 200.56323051452637, "training_acc": 70.33333333333333, "val_loss": 81.91530287265778, "val_acc": 46.666666666666664}
{"epoch": 23, "training_loss": 233.57203078269958, "training_acc": 70.0, "val_loss": 81.19669044017792, "val_acc": 48.0}
{"epoch": 24, "training_loss": 223.8249683380127, "training_acc": 67.0, "val_loss": 88.24971896409988, "val_acc": 61.333333333333336}
{"epoch": 25, "training_loss": 208.12697792053223, "training_acc": 73.0, "val_loss": 68.70894813537598, "val_acc": 72.0}
{"epoch": 26, "training_loss": 137.96119785308838, "training_acc": 79.0, "val_loss": 53.73473018407822, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 119.07542991638184, "training_acc": 82.66666666666667, "val_loss": 49.8895138502121, "val_acc": 66.66666666666667}
{"epoch": 28, "training_loss": 124.74924921989441, "training_acc": 82.0, "val_loss": 53.104567885398865, "val_acc": 73.33333333333333}
