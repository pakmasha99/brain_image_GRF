"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1453.2651252746582, "training_acc": 55.0, "val_loss": 278.5854835510254, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1086.738203048706, "training_acc": 62.333333333333336, "val_loss": 237.35367023944855, "val_acc": 72.0}
{"epoch": 2, "training_loss": 804.1335535049438, "training_acc": 60.666666666666664, "val_loss": 70.65701103210449, "val_acc": 69.33333333333333}
{"epoch": 3, "training_loss": 736.762170791626, "training_acc": 70.0, "val_loss": 159.78647804260254, "val_acc": 72.0}
{"epoch": 4, "training_loss": 479.265597820282, "training_acc": 64.33333333333333, "val_loss": 47.124765783548355, "val_acc": 74.66666666666667}
{"epoch": 5, "training_loss": 292.0470509529114, "training_acc": 72.0, "val_loss": 135.0349690914154, "val_acc": 34.666666666666664}
{"epoch": 6, "training_loss": 366.08423614501953, "training_acc": 62.0, "val_loss": 45.925704300403595, "val_acc": 64.0}
{"epoch": 7, "training_loss": 230.8921356201172, "training_acc": 64.66666666666667, "val_loss": 37.48833949863911, "val_acc": 76.0}
{"epoch": 8, "training_loss": 204.4072709083557, "training_acc": 67.33333333333333, "val_loss": 46.8222838640213, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 191.80894362926483, "training_acc": 70.33333333333333, "val_loss": 56.07822334766388, "val_acc": 72.0}
{"epoch": 10, "training_loss": 196.31326127052307, "training_acc": 68.33333333333333, "val_loss": 55.79615169763565, "val_acc": 72.0}
{"epoch": 11, "training_loss": 200.1739251613617, "training_acc": 65.0, "val_loss": 60.4217643737793, "val_acc": 72.0}
{"epoch": 12, "training_loss": 192.08569025993347, "training_acc": 74.0, "val_loss": 38.43618994951248, "val_acc": 81.33333333333333}
{"epoch": 13, "training_loss": 168.76059532165527, "training_acc": 74.33333333333333, "val_loss": 36.00083041191101, "val_acc": 72.0}
{"epoch": 14, "training_loss": 157.87119388580322, "training_acc": 74.33333333333333, "val_loss": 56.13107627630234, "val_acc": 38.666666666666664}
{"epoch": 15, "training_loss": 164.4532492160797, "training_acc": 71.33333333333333, "val_loss": 35.362079828977585, "val_acc": 70.66666666666667}
{"epoch": 16, "training_loss": 147.4852374792099, "training_acc": 78.66666666666667, "val_loss": 35.31210368871689, "val_acc": 77.33333333333333}
{"epoch": 17, "training_loss": 139.46575784683228, "training_acc": 80.0, "val_loss": 38.34016752243042, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 189.85761523246765, "training_acc": 71.0, "val_loss": 54.876213282346725, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 192.43759536743164, "training_acc": 70.0, "val_loss": 66.2237052321434, "val_acc": 72.0}
{"epoch": 20, "training_loss": 215.10012459754944, "training_acc": 67.33333333333333, "val_loss": 56.48919463157654, "val_acc": 72.0}
{"epoch": 21, "training_loss": 182.9550085067749, "training_acc": 70.0, "val_loss": 44.227693140506744, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 173.90867066383362, "training_acc": 71.33333333333333, "val_loss": 33.274826765060425, "val_acc": 78.66666666666667}
{"epoch": 23, "training_loss": 185.8529281616211, "training_acc": 73.0, "val_loss": 45.69736438989639, "val_acc": 57.333333333333336}
{"epoch": 24, "training_loss": 170.82378017902374, "training_acc": 73.33333333333333, "val_loss": 34.61039352416992, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 162.99442315101624, "training_acc": 75.33333333333333, "val_loss": 33.87235498428345, "val_acc": 81.33333333333333}
{"epoch": 26, "training_loss": 192.9864696264267, "training_acc": 68.0, "val_loss": 88.05636554956436, "val_acc": 32.0}
{"epoch": 27, "training_loss": 248.51382493972778, "training_acc": 64.0, "val_loss": 35.3579415678978, "val_acc": 74.66666666666667}
{"epoch": 28, "training_loss": 143.00037217140198, "training_acc": 78.0, "val_loss": 36.17852547764778, "val_acc": 80.0}
{"epoch": 29, "training_loss": 136.28561973571777, "training_acc": 77.66666666666667, "val_loss": 59.440597504377365, "val_acc": 72.0}
{"epoch": 30, "training_loss": 173.30889081954956, "training_acc": 71.33333333333333, "val_loss": 35.45768854022026, "val_acc": 76.0}
{"epoch": 31, "training_loss": 129.56637012958527, "training_acc": 80.33333333333333, "val_loss": 32.36800628900528, "val_acc": 78.66666666666667}
{"epoch": 32, "training_loss": 144.10239958763123, "training_acc": 75.66666666666667, "val_loss": 34.513684794306755, "val_acc": 74.66666666666667}
{"epoch": 33, "training_loss": 148.72478461265564, "training_acc": 76.66666666666667, "val_loss": 39.072528690099716, "val_acc": 80.0}
{"epoch": 34, "training_loss": 180.45653212070465, "training_acc": 71.0, "val_loss": 41.02183961868286, "val_acc": 80.0}
{"epoch": 35, "training_loss": 129.78865504264832, "training_acc": 78.66666666666667, "val_loss": 39.83465212583542, "val_acc": 66.66666666666667}
{"epoch": 36, "training_loss": 135.02346897125244, "training_acc": 75.33333333333333, "val_loss": 34.7298321723938, "val_acc": 76.0}
{"epoch": 37, "training_loss": 113.77938079833984, "training_acc": 83.0, "val_loss": 41.72082334756851, "val_acc": 80.0}
{"epoch": 38, "training_loss": 160.32044422626495, "training_acc": 74.0, "val_loss": 55.67183071374893, "val_acc": 72.0}
{"epoch": 39, "training_loss": 148.94213247299194, "training_acc": 76.66666666666667, "val_loss": 35.16202932596207, "val_acc": 76.0}
{"epoch": 40, "training_loss": 118.7262806892395, "training_acc": 80.66666666666667, "val_loss": 34.48569777607918, "val_acc": 77.33333333333333}
{"epoch": 41, "training_loss": 118.62323808670044, "training_acc": 82.66666666666667, "val_loss": 32.056537091732025, "val_acc": 81.33333333333333}
{"epoch": 42, "training_loss": 137.0988380908966, "training_acc": 77.66666666666667, "val_loss": 40.450562477111816, "val_acc": 77.33333333333333}
{"epoch": 43, "training_loss": 126.34332346916199, "training_acc": 77.33333333333333, "val_loss": 42.002955943346024, "val_acc": 77.33333333333333}
{"epoch": 44, "training_loss": 153.36585414409637, "training_acc": 75.33333333333333, "val_loss": 34.91026359796524, "val_acc": 80.0}
{"epoch": 45, "training_loss": 149.3923316001892, "training_acc": 78.0, "val_loss": 34.27759379148483, "val_acc": 80.0}
{"epoch": 46, "training_loss": 151.1903017759323, "training_acc": 76.0, "val_loss": 43.013791143894196, "val_acc": 61.333333333333336}
{"epoch": 47, "training_loss": 130.82431972026825, "training_acc": 82.66666666666667, "val_loss": 37.51706236600876, "val_acc": 68.0}
{"epoch": 48, "training_loss": 113.34400379657745, "training_acc": 81.66666666666667, "val_loss": 33.5544376373291, "val_acc": 80.0}
{"epoch": 49, "training_loss": 128.80167937278748, "training_acc": 79.0, "val_loss": 32.69146713614464, "val_acc": 78.66666666666667}
{"epoch": 50, "training_loss": 134.18644547462463, "training_acc": 77.33333333333333, "val_loss": 34.079383462667465, "val_acc": 77.33333333333333}
{"epoch": 51, "training_loss": 131.4493486881256, "training_acc": 80.33333333333333, "val_loss": 51.249457001686096, "val_acc": 60.0}
{"epoch": 52, "training_loss": 147.49211955070496, "training_acc": 76.0, "val_loss": 33.24576708674431, "val_acc": 78.66666666666667}
{"epoch": 53, "training_loss": 120.61803162097931, "training_acc": 80.66666666666667, "val_loss": 48.64675533026457, "val_acc": 77.33333333333333}
{"epoch": 54, "training_loss": 135.71958756446838, "training_acc": 78.66666666666667, "val_loss": 33.68032795190811, "val_acc": 78.66666666666667}
{"epoch": 55, "training_loss": 122.2113219499588, "training_acc": 80.0, "val_loss": 33.533704072237015, "val_acc": 77.33333333333333}
{"epoch": 56, "training_loss": 153.62874686717987, "training_acc": 75.66666666666667, "val_loss": 59.4264460504055, "val_acc": 73.33333333333333}
{"epoch": 57, "training_loss": 155.51573657989502, "training_acc": 76.0, "val_loss": 47.56263357400894, "val_acc": 77.33333333333333}
{"epoch": 58, "training_loss": 135.50381529331207, "training_acc": 79.0, "val_loss": 38.27939733862877, "val_acc": 76.0}
{"epoch": 59, "training_loss": 107.34364974498749, "training_acc": 85.0, "val_loss": 33.85622385144234, "val_acc": 80.0}
{"epoch": 60, "training_loss": 120.92813754081726, "training_acc": 82.66666666666667, "val_loss": 55.37258172035217, "val_acc": 76.0}
