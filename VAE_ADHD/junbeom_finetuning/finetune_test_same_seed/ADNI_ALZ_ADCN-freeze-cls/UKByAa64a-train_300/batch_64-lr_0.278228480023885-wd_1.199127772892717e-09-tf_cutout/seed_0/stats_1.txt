"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1600.9188423156738, "training_acc": 67.66666666666667, "val_loss": 249.5677341222763, "val_acc": 30.666666666666668}
{"epoch": 1, "training_loss": 1360.2897701263428, "training_acc": 65.0, "val_loss": 356.5135164260864, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 943.7874393463135, "training_acc": 63.0, "val_loss": 247.23110437393188, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 878.7418212890625, "training_acc": 68.66666666666667, "val_loss": 277.78819942474365, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 636.6666970252991, "training_acc": 68.0, "val_loss": 162.79956930875778, "val_acc": 61.333333333333336}
{"epoch": 5, "training_loss": 410.4197700023651, "training_acc": 76.33333333333333, "val_loss": 172.17750525474548, "val_acc": 50.666666666666664}
{"epoch": 6, "training_loss": 368.7838935852051, "training_acc": 67.66666666666667, "val_loss": 92.37256622314453, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 373.81737756729126, "training_acc": 61.666666666666664, "val_loss": 108.81758224964142, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 259.37869000434875, "training_acc": 70.66666666666667, "val_loss": 57.05994611978531, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 164.74158191680908, "training_acc": 73.33333333333333, "val_loss": 42.50084960460663, "val_acc": 65.33333333333333}
{"epoch": 10, "training_loss": 137.27018785476685, "training_acc": 79.66666666666667, "val_loss": 43.88859558105469, "val_acc": 70.66666666666667}
{"epoch": 11, "training_loss": 128.7847272157669, "training_acc": 79.66666666666667, "val_loss": 48.059904396533966, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 135.80418801307678, "training_acc": 78.33333333333333, "val_loss": 49.89925116300583, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 169.5826518535614, "training_acc": 75.66666666666667, "val_loss": 95.40486335754395, "val_acc": 44.0}
{"epoch": 14, "training_loss": 191.1426501274109, "training_acc": 71.0, "val_loss": 83.40738368034363, "val_acc": 53.333333333333336}
{"epoch": 15, "training_loss": 203.28088569641113, "training_acc": 70.66666666666667, "val_loss": 49.91415351629257, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 150.74050784111023, "training_acc": 77.33333333333333, "val_loss": 60.488183438777924, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 146.24111950397491, "training_acc": 78.33333333333333, "val_loss": 46.00993540883064, "val_acc": 72.0}
{"epoch": 18, "training_loss": 127.10983681678772, "training_acc": 83.0, "val_loss": 64.58869180083275, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 155.43924963474274, "training_acc": 75.66666666666667, "val_loss": 89.65287494659424, "val_acc": 69.33333333333333}
{"epoch": 20, "training_loss": 203.80516457557678, "training_acc": 72.33333333333333, "val_loss": 107.29996502399445, "val_acc": 36.0}
{"epoch": 21, "training_loss": 190.06328415870667, "training_acc": 73.0, "val_loss": 54.88371230661869, "val_acc": 76.0}
{"epoch": 22, "training_loss": 154.20380902290344, "training_acc": 77.33333333333333, "val_loss": 61.91937988996506, "val_acc": 74.66666666666667}
{"epoch": 23, "training_loss": 177.21972858905792, "training_acc": 74.33333333333333, "val_loss": 116.2336333990097, "val_acc": 44.0}
{"epoch": 24, "training_loss": 225.52550506591797, "training_acc": 68.66666666666667, "val_loss": 81.06988459825516, "val_acc": 60.0}
{"epoch": 25, "training_loss": 173.21854186058044, "training_acc": 73.66666666666667, "val_loss": 77.02703332901001, "val_acc": 69.33333333333333}
{"epoch": 26, "training_loss": 208.51910042762756, "training_acc": 72.33333333333333, "val_loss": 81.30116009712219, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 156.50671005249023, "training_acc": 75.66666666666667, "val_loss": 63.4724178314209, "val_acc": 68.0}
{"epoch": 28, "training_loss": 115.25604903697968, "training_acc": 82.33333333333333, "val_loss": 51.45232114195824, "val_acc": 65.33333333333333}
