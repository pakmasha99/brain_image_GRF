"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 49813.106227874756, "training_acc": 61.0, "val_loss": 16477.856414794922, "val_acc": 28.0}
{"epoch": 1, "training_loss": 36927.712341308594, "training_acc": 64.0, "val_loss": 12867.9683303833, "val_acc": 72.0}
{"epoch": 2, "training_loss": 26783.108367919922, "training_acc": 69.33333333333333, "val_loss": 10331.114952087402, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 23550.782348632812, "training_acc": 66.33333333333333, "val_loss": 10267.458892822266, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 21360.200622558594, "training_acc": 68.66666666666667, "val_loss": 6098.208740234375, "val_acc": 53.333333333333336}
{"epoch": 5, "training_loss": 15942.147964477539, "training_acc": 72.0, "val_loss": 3731.1692428588867, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 6555.877830505371, "training_acc": 63.0, "val_loss": 1862.3084630966187, "val_acc": 66.66666666666667}
{"epoch": 7, "training_loss": 5429.314544677734, "training_acc": 72.33333333333333, "val_loss": 1271.2852969169617, "val_acc": 72.0}
{"epoch": 8, "training_loss": 14879.95947265625, "training_acc": 56.333333333333336, "val_loss": 7332.466064453125, "val_acc": 72.0}
{"epoch": 9, "training_loss": 17914.02325439453, "training_acc": 64.0, "val_loss": 2253.675178527832, "val_acc": 62.666666666666664}
{"epoch": 10, "training_loss": 14697.140701293945, "training_acc": 71.0, "val_loss": 3903.488296508789, "val_acc": 52.0}
{"epoch": 11, "training_loss": 14557.569198608398, "training_acc": 59.333333333333336, "val_loss": 5127.118183135986, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 9120.818939208984, "training_acc": 72.66666666666667, "val_loss": 2732.0184173583984, "val_acc": 58.666666666666664}
{"epoch": 13, "training_loss": 4860.98840713501, "training_acc": 77.33333333333333, "val_loss": 3677.7409858703613, "val_acc": 45.333333333333336}
{"epoch": 14, "training_loss": 8361.690971374512, "training_acc": 62.666666666666664, "val_loss": 3746.4051265716553, "val_acc": 42.666666666666664}
{"epoch": 15, "training_loss": 5449.811794281006, "training_acc": 69.33333333333333, "val_loss": 2860.4220123291016, "val_acc": 48.0}
{"epoch": 16, "training_loss": 4521.254322052002, "training_acc": 70.66666666666667, "val_loss": 1634.771722793579, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2664.5344829559326, "training_acc": 72.33333333333333, "val_loss": 723.3123688697815, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 3476.2479286193848, "training_acc": 69.0, "val_loss": 793.1329669952393, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 4201.278553009033, "training_acc": 67.33333333333333, "val_loss": 1396.1695652008057, "val_acc": 64.0}
{"epoch": 20, "training_loss": 2959.2718658447266, "training_acc": 69.33333333333333, "val_loss": 1708.8626403808594, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 6110.166263580322, "training_acc": 66.66666666666667, "val_loss": 1751.90935754776, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 3927.051658630371, "training_acc": 70.33333333333333, "val_loss": 1793.6684370040894, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 3158.1441078186035, "training_acc": 73.66666666666667, "val_loss": 1148.095230102539, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 1776.466100692749, "training_acc": 79.66666666666667, "val_loss": 558.9247727394104, "val_acc": 66.66666666666667}
{"epoch": 25, "training_loss": 4098.720812797546, "training_acc": 68.0, "val_loss": 713.9462606906891, "val_acc": 66.66666666666667}
{"epoch": 26, "training_loss": 1822.0449390411377, "training_acc": 74.66666666666667, "val_loss": 1079.4038429260254, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1661.0741024017334, "training_acc": 75.0, "val_loss": 820.9893126487732, "val_acc": 62.666666666666664}
{"epoch": 28, "training_loss": 4258.335556030273, "training_acc": 63.0, "val_loss": 1947.2326850891113, "val_acc": 69.33333333333333}
{"epoch": 29, "training_loss": 3681.334445953369, "training_acc": 73.66666666666667, "val_loss": 1589.1225776672363, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 2255.866279602051, "training_acc": 79.66666666666667, "val_loss": 1150.4049663543701, "val_acc": 61.333333333333336}
{"epoch": 31, "training_loss": 2597.437696456909, "training_acc": 72.0, "val_loss": 657.8153095245361, "val_acc": 69.33333333333333}
{"epoch": 32, "training_loss": 5009.952297210693, "training_acc": 67.66666666666667, "val_loss": 3755.079465866089, "val_acc": 33.333333333333336}
{"epoch": 33, "training_loss": 6310.78165435791, "training_acc": 69.0, "val_loss": 2326.022584915161, "val_acc": 58.666666666666664}
{"epoch": 34, "training_loss": 4885.949726104736, "training_acc": 70.66666666666667, "val_loss": 2024.1311779022217, "val_acc": 56.0}
{"epoch": 35, "training_loss": 3978.652473449707, "training_acc": 69.0, "val_loss": 1452.5566711425781, "val_acc": 69.33333333333333}
{"epoch": 36, "training_loss": 5107.749847412109, "training_acc": 67.66666666666667, "val_loss": 1954.642988204956, "val_acc": 69.33333333333333}
{"epoch": 37, "training_loss": 3357.5919227600098, "training_acc": 73.66666666666667, "val_loss": 1922.5789585113525, "val_acc": 70.66666666666667}
{"epoch": 38, "training_loss": 3459.0274238586426, "training_acc": 74.0, "val_loss": 1204.6315908432007, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3663.3900871276855, "training_acc": 71.33333333333333, "val_loss": 2925.161994934082, "val_acc": 36.0}
{"epoch": 40, "training_loss": 5009.9789028167725, "training_acc": 71.33333333333333, "val_loss": 2833.0053367614746, "val_acc": 44.0}
{"epoch": 41, "training_loss": 5421.719528198242, "training_acc": 70.33333333333333, "val_loss": 1217.8151588439941, "val_acc": 74.66666666666667}
{"epoch": 42, "training_loss": 1812.5026397705078, "training_acc": 78.66666666666667, "val_loss": 1245.1739253997803, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1273.2348175048828, "training_acc": 81.66666666666667, "val_loss": 965.6084041595459, "val_acc": 73.33333333333333}
