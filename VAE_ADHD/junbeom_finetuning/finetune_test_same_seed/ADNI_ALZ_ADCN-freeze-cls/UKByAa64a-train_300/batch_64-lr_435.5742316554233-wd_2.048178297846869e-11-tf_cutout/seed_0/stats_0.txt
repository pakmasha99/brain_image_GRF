"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2959762.5956344604, "training_acc": 64.33333333333333, "val_loss": 1068994.0322265625, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 2542323.0859375, "training_acc": 61.666666666666664, "val_loss": 865656.9716796875, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 2244923.5, "training_acc": 67.66666666666667, "val_loss": 471917.06689453125, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 1290368.4599609375, "training_acc": 64.66666666666667, "val_loss": 361564.76171875, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 1297721.53125, "training_acc": 74.66666666666667, "val_loss": 312881.6301269531, "val_acc": 42.666666666666664}
{"epoch": 5, "training_loss": 907236.091796875, "training_acc": 62.0, "val_loss": 95944.48901367188, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 567957.4614257812, "training_acc": 60.666666666666664, "val_loss": 214577.80029296875, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 523947.0809326172, "training_acc": 67.66666666666667, "val_loss": 128018.650390625, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 389687.9812011719, "training_acc": 66.66666666666667, "val_loss": 100901.02099609375, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 313183.37890625, "training_acc": 68.33333333333333, "val_loss": 118726.22384643555, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 508776.89111328125, "training_acc": 59.666666666666664, "val_loss": 141313.2257080078, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 330202.91357421875, "training_acc": 68.66666666666667, "val_loss": 27583.689331054688, "val_acc": 78.66666666666667}
{"epoch": 12, "training_loss": 317196.13330078125, "training_acc": 66.66666666666667, "val_loss": 123854.75903320312, "val_acc": 38.666666666666664}
{"epoch": 13, "training_loss": 269557.62841796875, "training_acc": 63.666666666666664, "val_loss": 30415.42409515381, "val_acc": 78.66666666666667}
{"epoch": 14, "training_loss": 166254.68920898438, "training_acc": 73.33333333333333, "val_loss": 43685.390625, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 105694.80078125, "training_acc": 71.33333333333333, "val_loss": 40795.861267089844, "val_acc": 72.0}
{"epoch": 16, "training_loss": 52552.550537109375, "training_acc": 76.33333333333333, "val_loss": 32466.982391357422, "val_acc": 74.66666666666667}
{"epoch": 17, "training_loss": 305644.98583984375, "training_acc": 66.0, "val_loss": 266294.75341796875, "val_acc": 26.666666666666668}
{"epoch": 18, "training_loss": 913545.740234375, "training_acc": 56.333333333333336, "val_loss": 155573.75244140625, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 459359.26806640625, "training_acc": 68.0, "val_loss": 55933.09426879883, "val_acc": 78.66666666666667}
{"epoch": 20, "training_loss": 164323.00024414062, "training_acc": 74.66666666666667, "val_loss": 60431.910583496094, "val_acc": 72.0}
{"epoch": 21, "training_loss": 207409.23669433594, "training_acc": 71.0, "val_loss": 125141.34545898438, "val_acc": 34.666666666666664}
{"epoch": 22, "training_loss": 375331.7109375, "training_acc": 60.333333333333336, "val_loss": 53418.71142578125, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 335681.12548828125, "training_acc": 71.66666666666667, "val_loss": 53092.114837646484, "val_acc": 74.66666666666667}
{"epoch": 24, "training_loss": 166445.1268310547, "training_acc": 74.33333333333333, "val_loss": 14125.754257202148, "val_acc": 81.33333333333333}
{"epoch": 25, "training_loss": 226295.62939453125, "training_acc": 67.66666666666667, "val_loss": 125686.70471191406, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 399179.08825683594, "training_acc": 65.66666666666667, "val_loss": 151625.71215820312, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 524684.8051757812, "training_acc": 70.33333333333333, "val_loss": 61699.86657714844, "val_acc": 74.66666666666667}
{"epoch": 28, "training_loss": 342930.2763671875, "training_acc": 72.66666666666667, "val_loss": 72158.98002624512, "val_acc": 69.33333333333333}
{"epoch": 29, "training_loss": 277085.92626953125, "training_acc": 67.66666666666667, "val_loss": 25826.077209472656, "val_acc": 74.66666666666667}
{"epoch": 30, "training_loss": 262144.966796875, "training_acc": 67.0, "val_loss": 44617.51461791992, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 251942.30981445312, "training_acc": 67.66666666666667, "val_loss": 79877.88525390625, "val_acc": 49.333333333333336}
{"epoch": 32, "training_loss": 216074.33349609375, "training_acc": 70.0, "val_loss": 18804.467588424683, "val_acc": 85.33333333333333}
{"epoch": 33, "training_loss": 121550.27954101562, "training_acc": 75.33333333333333, "val_loss": 131274.31469726562, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 410135.72412109375, "training_acc": 63.0, "val_loss": 249720.94268798828, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 773335.208984375, "training_acc": 57.666666666666664, "val_loss": 134604.87951660156, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 812756.2998046875, "training_acc": 71.0, "val_loss": 283510.22412109375, "val_acc": 42.666666666666664}
{"epoch": 37, "training_loss": 766731.9169921875, "training_acc": 62.333333333333336, "val_loss": 97758.98510742188, "val_acc": 80.0}
{"epoch": 38, "training_loss": 447334.7365722656, "training_acc": 72.66666666666667, "val_loss": 74580.56982421875, "val_acc": 81.33333333333333}
{"epoch": 39, "training_loss": 249517.96435546875, "training_acc": 73.0, "val_loss": 88129.92624282837, "val_acc": 70.66666666666667}
{"epoch": 40, "training_loss": 314300.68603515625, "training_acc": 66.33333333333333, "val_loss": 84829.61584472656, "val_acc": 72.0}
{"epoch": 41, "training_loss": 239506.07202148438, "training_acc": 70.33333333333333, "val_loss": 93036.96411132812, "val_acc": 73.33333333333333}
{"epoch": 42, "training_loss": 224427.36401367188, "training_acc": 76.0, "val_loss": 63423.85546875, "val_acc": 77.33333333333333}
{"epoch": 43, "training_loss": 202678.763671875, "training_acc": 71.0, "val_loss": 62830.83792114258, "val_acc": 73.33333333333333}
