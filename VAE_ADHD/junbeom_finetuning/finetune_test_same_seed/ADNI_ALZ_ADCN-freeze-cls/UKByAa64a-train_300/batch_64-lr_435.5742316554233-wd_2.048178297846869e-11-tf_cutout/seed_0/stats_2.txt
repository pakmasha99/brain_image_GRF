"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3088585.989135742, "training_acc": 57.333333333333336, "val_loss": 1041475.4326171875, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2307244.98828125, "training_acc": 65.66666666666667, "val_loss": 786958.1865234375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1762108.47265625, "training_acc": 65.66666666666667, "val_loss": 469067.22021484375, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 1354307.4375, "training_acc": 67.33333333333333, "val_loss": 496357.8583984375, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 1205388.046875, "training_acc": 70.66666666666667, "val_loss": 204769.3682861328, "val_acc": 62.666666666666664}
{"epoch": 5, "training_loss": 729986.8012695312, "training_acc": 67.66666666666667, "val_loss": 156656.36547851562, "val_acc": 49.333333333333336}
{"epoch": 6, "training_loss": 448925.46630859375, "training_acc": 68.66666666666667, "val_loss": 129493.20690917969, "val_acc": 70.66666666666667}
{"epoch": 7, "training_loss": 365047.96826171875, "training_acc": 65.33333333333333, "val_loss": 63126.67123413086, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 242885.1943359375, "training_acc": 72.33333333333333, "val_loss": 83025.17004394531, "val_acc": 52.0}
{"epoch": 9, "training_loss": 394945.4301147461, "training_acc": 65.0, "val_loss": 227827.603515625, "val_acc": 37.333333333333336}
{"epoch": 10, "training_loss": 432909.421875, "training_acc": 63.0, "val_loss": 158751.88842773438, "val_acc": 44.0}
{"epoch": 11, "training_loss": 227591.7752685547, "training_acc": 69.33333333333333, "val_loss": 58667.985595703125, "val_acc": 57.333333333333336}
{"epoch": 12, "training_loss": 292111.048828125, "training_acc": 65.33333333333333, "val_loss": 60454.95877075195, "val_acc": 72.0}
{"epoch": 13, "training_loss": 181993.658203125, "training_acc": 73.33333333333333, "val_loss": 82337.50415039062, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 187985.33813476562, "training_acc": 76.66666666666667, "val_loss": 118172.8681640625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 448349.90380859375, "training_acc": 63.333333333333336, "val_loss": 101225.87390136719, "val_acc": 72.0}
{"epoch": 16, "training_loss": 180135.91748046875, "training_acc": 75.33333333333333, "val_loss": 123576.99426269531, "val_acc": 41.333333333333336}
{"epoch": 17, "training_loss": 300303.50830078125, "training_acc": 64.0, "val_loss": 67066.18713378906, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 118448.07702636719, "training_acc": 77.33333333333333, "val_loss": 30769.23651123047, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 169335.14892578125, "training_acc": 68.33333333333333, "val_loss": 158324.19604492188, "val_acc": 72.0}
{"epoch": 20, "training_loss": 423233.99609375, "training_acc": 66.33333333333333, "val_loss": 166957.20751953125, "val_acc": 72.0}
{"epoch": 21, "training_loss": 381978.9870605469, "training_acc": 69.33333333333333, "val_loss": 196778.89306640625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 520944.75244140625, "training_acc": 69.0, "val_loss": 64013.319091796875, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 211801.5810546875, "training_acc": 78.33333333333333, "val_loss": 85817.20751953125, "val_acc": 62.666666666666664}
{"epoch": 24, "training_loss": 417163.74365234375, "training_acc": 66.0, "val_loss": 81028.43682861328, "val_acc": 50.666666666666664}
{"epoch": 25, "training_loss": 208824.24853515625, "training_acc": 70.66666666666667, "val_loss": 44203.70998954773, "val_acc": 70.66666666666667}
{"epoch": 26, "training_loss": 163224.802734375, "training_acc": 75.33333333333333, "val_loss": 84912.30969238281, "val_acc": 72.0}
{"epoch": 27, "training_loss": 137942.5284423828, "training_acc": 74.66666666666667, "val_loss": 71888.19323730469, "val_acc": 48.0}
{"epoch": 28, "training_loss": 171201.20056152344, "training_acc": 70.0, "val_loss": 38633.93865966797, "val_acc": 76.0}
{"epoch": 29, "training_loss": 125622.20751953125, "training_acc": 75.0, "val_loss": 84591.48083496094, "val_acc": 46.666666666666664}
{"epoch": 30, "training_loss": 161460.541015625, "training_acc": 75.66666666666667, "val_loss": 81820.06457519531, "val_acc": 50.666666666666664}
{"epoch": 31, "training_loss": 369597.9748535156, "training_acc": 68.33333333333333, "val_loss": 87465.72766113281, "val_acc": 56.0}
{"epoch": 32, "training_loss": 307145.640625, "training_acc": 74.33333333333333, "val_loss": 83380.87609863281, "val_acc": 57.333333333333336}
{"epoch": 33, "training_loss": 447790.400390625, "training_acc": 60.333333333333336, "val_loss": 33619.52685546875, "val_acc": 72.0}
{"epoch": 34, "training_loss": 287736.85595703125, "training_acc": 74.66666666666667, "val_loss": 60054.07141113281, "val_acc": 70.66666666666667}
{"epoch": 35, "training_loss": 318313.0576171875, "training_acc": 71.0, "val_loss": 54127.48547363281, "val_acc": 66.66666666666667}
{"epoch": 36, "training_loss": 241378.416015625, "training_acc": 74.66666666666667, "val_loss": 86453.46728515625, "val_acc": 53.333333333333336}
{"epoch": 37, "training_loss": 195546.99169921875, "training_acc": 74.66666666666667, "val_loss": 43492.04522705078, "val_acc": 77.33333333333333}
