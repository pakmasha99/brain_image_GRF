"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2981207.8111839294, "training_acc": 65.66666666666667, "val_loss": 1251800.69140625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2905042.7578125, "training_acc": 59.333333333333336, "val_loss": 856111.86328125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1566048.1904296875, "training_acc": 71.33333333333333, "val_loss": 566349.326171875, "val_acc": 46.666666666666664}
{"epoch": 3, "training_loss": 1241604.556640625, "training_acc": 63.666666666666664, "val_loss": 438172.1140136719, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 887529.126953125, "training_acc": 72.33333333333333, "val_loss": 282895.2916870117, "val_acc": 53.333333333333336}
{"epoch": 5, "training_loss": 668941.4497070312, "training_acc": 70.0, "val_loss": 86049.28149414062, "val_acc": 60.0}
{"epoch": 6, "training_loss": 478786.4580078125, "training_acc": 60.0, "val_loss": 52808.08059692383, "val_acc": 68.0}
{"epoch": 7, "training_loss": 266091.14990234375, "training_acc": 67.33333333333333, "val_loss": 127672.4428100586, "val_acc": 54.666666666666664}
{"epoch": 8, "training_loss": 385027.970703125, "training_acc": 66.66666666666667, "val_loss": 158645.4619140625, "val_acc": 46.666666666666664}
{"epoch": 9, "training_loss": 423923.228515625, "training_acc": 64.33333333333333, "val_loss": 90742.8720703125, "val_acc": 66.66666666666667}
{"epoch": 10, "training_loss": 171994.7455444336, "training_acc": 75.66666666666667, "val_loss": 26718.27166748047, "val_acc": 66.66666666666667}
{"epoch": 11, "training_loss": 159025.87182617188, "training_acc": 66.66666666666667, "val_loss": 24639.910766601562, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 93312.17993164062, "training_acc": 77.33333333333333, "val_loss": 69036.05572509766, "val_acc": 64.0}
{"epoch": 13, "training_loss": 123624.61169433594, "training_acc": 74.33333333333333, "val_loss": 50414.64781188965, "val_acc": 50.666666666666664}
{"epoch": 14, "training_loss": 178809.0606689453, "training_acc": 69.66666666666667, "val_loss": 124296.85412597656, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 429020.6662597656, "training_acc": 65.33333333333333, "val_loss": 173621.13427734375, "val_acc": 69.33333333333333}
{"epoch": 16, "training_loss": 580276.3481445312, "training_acc": 71.66666666666667, "val_loss": 182009.4981689453, "val_acc": 56.0}
{"epoch": 17, "training_loss": 448722.96875, "training_acc": 66.0, "val_loss": 279271.46533203125, "val_acc": 42.666666666666664}
{"epoch": 18, "training_loss": 678085.87109375, "training_acc": 65.33333333333333, "val_loss": 168904.32080078125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 418575.623046875, "training_acc": 66.66666666666667, "val_loss": 158458.41870117188, "val_acc": 74.66666666666667}
{"epoch": 20, "training_loss": 314070.0625, "training_acc": 69.66666666666667, "val_loss": 196115.10620117188, "val_acc": 69.33333333333333}
{"epoch": 21, "training_loss": 423282.7255859375, "training_acc": 65.33333333333333, "val_loss": 169882.4444580078, "val_acc": 69.33333333333333}
{"epoch": 22, "training_loss": 373683.28125, "training_acc": 69.66666666666667, "val_loss": 175038.57299804688, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 399687.623046875, "training_acc": 70.66666666666667, "val_loss": 174766.421875, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 300622.94201660156, "training_acc": 74.33333333333333, "val_loss": 93897.38049316406, "val_acc": 69.33333333333333}
{"epoch": 25, "training_loss": 204180.92126464844, "training_acc": 74.33333333333333, "val_loss": 64080.47021484375, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 81191.0132446289, "training_acc": 78.33333333333333, "val_loss": 34175.355224609375, "val_acc": 68.0}
{"epoch": 27, "training_loss": 69947.57043457031, "training_acc": 75.33333333333333, "val_loss": 49729.06005859375, "val_acc": 72.0}
{"epoch": 28, "training_loss": 95431.51171875, "training_acc": 82.33333333333333, "val_loss": 48852.5400390625, "val_acc": 72.0}
{"epoch": 29, "training_loss": 170493.45166015625, "training_acc": 73.66666666666667, "val_loss": 63168.18176269531, "val_acc": 54.666666666666664}
{"epoch": 30, "training_loss": 105840.03979492188, "training_acc": 73.33333333333333, "val_loss": 35987.21142578125, "val_acc": 73.33333333333333}
