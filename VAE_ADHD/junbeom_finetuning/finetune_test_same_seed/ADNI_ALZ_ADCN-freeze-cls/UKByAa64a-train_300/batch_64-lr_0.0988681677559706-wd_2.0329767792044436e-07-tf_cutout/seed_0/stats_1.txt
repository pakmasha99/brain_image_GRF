"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 575.410891532898, "training_acc": 63.666666666666664, "val_loss": 67.35634344816208, "val_acc": 61.333333333333336}
{"epoch": 1, "training_loss": 286.926185131073, "training_acc": 75.0, "val_loss": 88.05135488510132, "val_acc": 58.666666666666664}
{"epoch": 2, "training_loss": 284.31116914749146, "training_acc": 70.66666666666667, "val_loss": 94.57397723197937, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 221.6755108833313, "training_acc": 70.33333333333333, "val_loss": 64.90998214483261, "val_acc": 72.0}
{"epoch": 4, "training_loss": 206.1594054698944, "training_acc": 72.66666666666667, "val_loss": 80.86403214931488, "val_acc": 32.0}
{"epoch": 5, "training_loss": 230.0624668598175, "training_acc": 64.33333333333333, "val_loss": 66.89525252580643, "val_acc": 48.0}
{"epoch": 6, "training_loss": 212.98614311218262, "training_acc": 67.0, "val_loss": 62.032233238220215, "val_acc": 74.66666666666667}
{"epoch": 7, "training_loss": 192.396626830101, "training_acc": 67.33333333333333, "val_loss": 70.5660970211029, "val_acc": 72.0}
{"epoch": 8, "training_loss": 213.90417051315308, "training_acc": 70.33333333333333, "val_loss": 65.08463382720947, "val_acc": 62.666666666666664}
{"epoch": 9, "training_loss": 172.497487783432, "training_acc": 73.66666666666667, "val_loss": 55.304042398929596, "val_acc": 64.0}
{"epoch": 10, "training_loss": 169.64530968666077, "training_acc": 72.33333333333333, "val_loss": 59.338109225034714, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 165.99152207374573, "training_acc": 72.66666666666667, "val_loss": 51.96878057718277, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 151.12068283557892, "training_acc": 75.66666666666667, "val_loss": 53.29997652769089, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 152.94866001605988, "training_acc": 73.0, "val_loss": 46.78890162706375, "val_acc": 69.33333333333333}
{"epoch": 14, "training_loss": 140.80538868904114, "training_acc": 76.33333333333333, "val_loss": 47.784013003110886, "val_acc": 62.666666666666664}
{"epoch": 15, "training_loss": 143.84028482437134, "training_acc": 75.33333333333333, "val_loss": 47.38099908828735, "val_acc": 64.0}
{"epoch": 16, "training_loss": 138.01377308368683, "training_acc": 80.0, "val_loss": 48.419377863407135, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 132.779883146286, "training_acc": 78.66666666666667, "val_loss": 46.83817005157471, "val_acc": 66.66666666666667}
{"epoch": 18, "training_loss": 144.51657438278198, "training_acc": 74.33333333333333, "val_loss": 45.9096200466156, "val_acc": 66.66666666666667}
{"epoch": 19, "training_loss": 136.27947854995728, "training_acc": 79.33333333333333, "val_loss": 49.26570010185242, "val_acc": 64.0}
{"epoch": 20, "training_loss": 149.52548384666443, "training_acc": 75.0, "val_loss": 45.129537761211395, "val_acc": 68.0}
{"epoch": 21, "training_loss": 129.5976334810257, "training_acc": 82.0, "val_loss": 45.82519608736038, "val_acc": 69.33333333333333}
{"epoch": 22, "training_loss": 136.42791724205017, "training_acc": 80.66666666666667, "val_loss": 48.190620720386505, "val_acc": 64.0}
{"epoch": 23, "training_loss": 132.43334317207336, "training_acc": 77.33333333333333, "val_loss": 48.05693471431732, "val_acc": 64.0}
{"epoch": 24, "training_loss": 131.2712013721466, "training_acc": 81.66666666666667, "val_loss": 48.982673317193985, "val_acc": 72.0}
{"epoch": 25, "training_loss": 136.05592048168182, "training_acc": 76.66666666666667, "val_loss": 45.52785003185272, "val_acc": 70.66666666666667}
{"epoch": 26, "training_loss": 135.52809286117554, "training_acc": 80.33333333333333, "val_loss": 48.893681704998016, "val_acc": 72.0}
{"epoch": 27, "training_loss": 138.04397094249725, "training_acc": 80.33333333333333, "val_loss": 52.22574543952942, "val_acc": 72.0}
{"epoch": 28, "training_loss": 133.7750129699707, "training_acc": 79.0, "val_loss": 49.08468180894852, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 130.5978934764862, "training_acc": 79.66666666666667, "val_loss": 46.964321076869965, "val_acc": 72.0}
{"epoch": 30, "training_loss": 122.58567905426025, "training_acc": 82.0, "val_loss": 45.75418400764465, "val_acc": 72.0}
{"epoch": 31, "training_loss": 128.86105489730835, "training_acc": 80.33333333333333, "val_loss": 46.38804590702057, "val_acc": 72.0}
{"epoch": 32, "training_loss": 150.8309943675995, "training_acc": 75.0, "val_loss": 46.282061874866486, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 172.17577648162842, "training_acc": 73.33333333333333, "val_loss": 47.147788256406784, "val_acc": 72.0}
{"epoch": 34, "training_loss": 198.7360270023346, "training_acc": 68.0, "val_loss": 68.45396965742111, "val_acc": 72.0}
{"epoch": 35, "training_loss": 199.18114280700684, "training_acc": 70.66666666666667, "val_loss": 95.8746463060379, "val_acc": 69.33333333333333}
{"epoch": 36, "training_loss": 232.0949957370758, "training_acc": 71.0, "val_loss": 56.213820695877075, "val_acc": 72.0}
{"epoch": 37, "training_loss": 174.65128898620605, "training_acc": 75.33333333333333, "val_loss": 87.06790351867676, "val_acc": 45.333333333333336}
{"epoch": 38, "training_loss": 231.7098412513733, "training_acc": 68.66666666666667, "val_loss": 72.25275707244873, "val_acc": 56.0}
{"epoch": 39, "training_loss": 188.7576413154602, "training_acc": 73.66666666666667, "val_loss": 52.493412256240845, "val_acc": 72.0}
