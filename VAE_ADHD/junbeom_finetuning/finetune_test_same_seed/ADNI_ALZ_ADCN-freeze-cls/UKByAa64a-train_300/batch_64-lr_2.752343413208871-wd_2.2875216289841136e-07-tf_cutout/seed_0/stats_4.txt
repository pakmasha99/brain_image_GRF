"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18961.34307861328, "training_acc": 56.666666666666664, "val_loss": 5910.625518798828, "val_acc": 28.0}
{"epoch": 1, "training_loss": 18537.02764892578, "training_acc": 58.666666666666664, "val_loss": 6776.605966567993, "val_acc": 72.0}
{"epoch": 2, "training_loss": 16475.51971435547, "training_acc": 70.0, "val_loss": 2431.7050743103027, "val_acc": 62.666666666666664}
{"epoch": 3, "training_loss": 12448.224380493164, "training_acc": 57.666666666666664, "val_loss": 4096.922424316406, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11245.701477050781, "training_acc": 70.66666666666667, "val_loss": 1400.5441608428955, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 5298.786712646484, "training_acc": 64.33333333333333, "val_loss": 1539.0132188796997, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2799.9234466552734, "training_acc": 66.66666666666667, "val_loss": 1237.014253616333, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4552.870948791504, "training_acc": 58.666666666666664, "val_loss": 1213.089349746704, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7828.705093383789, "training_acc": 72.33333333333333, "val_loss": 567.5918827056885, "val_acc": 69.33333333333333}
{"epoch": 9, "training_loss": 4598.640480041504, "training_acc": 60.333333333333336, "val_loss": 2645.19815826416, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7198.015983581543, "training_acc": 66.33333333333333, "val_loss": 1073.1080074310303, "val_acc": 70.66666666666667}
{"epoch": 11, "training_loss": 6130.249244689941, "training_acc": 67.0, "val_loss": 823.3429956436157, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3372.6773948669434, "training_acc": 64.0, "val_loss": 933.1803131103516, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3457.0735397338867, "training_acc": 58.0, "val_loss": 1607.3125457763672, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4938.322780609131, "training_acc": 59.333333333333336, "val_loss": 806.40625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4139.690246582031, "training_acc": 69.66666666666667, "val_loss": 747.4397916793823, "val_acc": 69.33333333333333}
{"epoch": 16, "training_loss": 3416.0185470581055, "training_acc": 70.66666666666667, "val_loss": 821.423264503479, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1565.0784711837769, "training_acc": 70.66666666666667, "val_loss": 764.2886695861816, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1616.2771587371826, "training_acc": 68.0, "val_loss": 297.84001636505127, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 3571.0667877197266, "training_acc": 59.0, "val_loss": 2655.7077102661133, "val_acc": 72.0}
{"epoch": 20, "training_loss": 7356.105201721191, "training_acc": 64.0, "val_loss": 756.5287446975708, "val_acc": 61.333333333333336}
{"epoch": 21, "training_loss": 5007.409873962402, "training_acc": 68.33333333333333, "val_loss": 742.9286828041077, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 3755.1536140441895, "training_acc": 67.66666666666667, "val_loss": 1035.0828428268433, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1978.2816219329834, "training_acc": 71.0, "val_loss": 331.83385181427, "val_acc": 73.33333333333333}
{"epoch": 24, "training_loss": 1419.6932191848755, "training_acc": 70.66666666666667, "val_loss": 485.60255789756775, "val_acc": 69.33333333333333}
{"epoch": 25, "training_loss": 1199.984320640564, "training_acc": 74.0, "val_loss": 468.6340796947479, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 936.8140830993652, "training_acc": 77.66666666666667, "val_loss": 276.1173564195633, "val_acc": 81.33333333333333}
{"epoch": 27, "training_loss": 718.3579597473145, "training_acc": 76.0, "val_loss": 304.29641914367676, "val_acc": 65.33333333333333}
{"epoch": 28, "training_loss": 735.2018904685974, "training_acc": 73.33333333333333, "val_loss": 406.2601490020752, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1066.882083415985, "training_acc": 72.33333333333333, "val_loss": 238.81994978757575, "val_acc": 81.33333333333333}
{"epoch": 30, "training_loss": 743.6550195217133, "training_acc": 75.66666666666667, "val_loss": 389.0856523513794, "val_acc": 64.0}
{"epoch": 31, "training_loss": 2143.608144760132, "training_acc": 57.333333333333336, "val_loss": 374.47898864746094, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 765.5969865322113, "training_acc": 79.0, "val_loss": 250.207200050354, "val_acc": 80.0}
{"epoch": 33, "training_loss": 500.4662733078003, "training_acc": 81.66666666666667, "val_loss": 273.27460765838623, "val_acc": 65.33333333333333}
{"epoch": 34, "training_loss": 414.5439624786377, "training_acc": 80.0, "val_loss": 245.2802738547325, "val_acc": 66.66666666666667}
{"epoch": 35, "training_loss": 286.91416120529175, "training_acc": 82.33333333333333, "val_loss": 327.4438226222992, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 579.9367589950562, "training_acc": 78.33333333333333, "val_loss": 177.51147890090942, "val_acc": 81.33333333333333}
{"epoch": 37, "training_loss": 815.8350706100464, "training_acc": 75.66666666666667, "val_loss": 296.8163061141968, "val_acc": 60.0}
{"epoch": 38, "training_loss": 1661.9593315124512, "training_acc": 62.333333333333336, "val_loss": 384.04448688030243, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 1137.8138313293457, "training_acc": 75.33333333333333, "val_loss": 386.64069652557373, "val_acc": 76.0}
{"epoch": 40, "training_loss": 598.9887647628784, "training_acc": 81.66666666666667, "val_loss": 159.33030652999878, "val_acc": 82.66666666666667}
{"epoch": 41, "training_loss": 520.2170038223267, "training_acc": 78.66666666666667, "val_loss": 139.12910079956055, "val_acc": 81.33333333333333}
{"epoch": 42, "training_loss": 804.5400314331055, "training_acc": 73.0, "val_loss": 305.7353754043579, "val_acc": 76.0}
{"epoch": 43, "training_loss": 853.5118494033813, "training_acc": 76.0, "val_loss": 202.81743574142456, "val_acc": 81.33333333333333}
{"epoch": 44, "training_loss": 2332.113414287567, "training_acc": 62.666666666666664, "val_loss": 1162.7910385131836, "val_acc": 33.333333333333336}
{"epoch": 45, "training_loss": 2955.464178085327, "training_acc": 66.33333333333333, "val_loss": 779.1789259910583, "val_acc": 56.0}
{"epoch": 46, "training_loss": 3222.5969429016113, "training_acc": 67.33333333333333, "val_loss": 479.8967595100403, "val_acc": 74.66666666666667}
{"epoch": 47, "training_loss": 3349.383102416992, "training_acc": 65.0, "val_loss": 1409.3525199890137, "val_acc": 72.0}
{"epoch": 48, "training_loss": 3297.540397644043, "training_acc": 65.0, "val_loss": 1498.9556941986084, "val_acc": 72.0}
{"epoch": 49, "training_loss": 4502.248466491699, "training_acc": 65.66666666666667, "val_loss": 358.7381501197815, "val_acc": 81.33333333333333}
{"epoch": 50, "training_loss": 2549.001293182373, "training_acc": 75.66666666666667, "val_loss": 1012.081657409668, "val_acc": 49.333333333333336}
{"epoch": 51, "training_loss": 1822.991937637329, "training_acc": 73.33333333333333, "val_loss": 356.6124725341797, "val_acc": 64.0}
{"epoch": 52, "training_loss": 1181.1134624481201, "training_acc": 71.0, "val_loss": 198.3532691001892, "val_acc": 72.0}
{"epoch": 53, "training_loss": 970.7767820358276, "training_acc": 75.66666666666667, "val_loss": 454.2225151062012, "val_acc": 73.33333333333333}
{"epoch": 54, "training_loss": 755.8529233932495, "training_acc": 81.0, "val_loss": 267.8092693667859, "val_acc": 81.33333333333333}
{"epoch": 55, "training_loss": 544.7523002624512, "training_acc": 82.66666666666667, "val_loss": 268.6367670893669, "val_acc": 65.33333333333333}
{"epoch": 56, "training_loss": 699.9964647293091, "training_acc": 77.0, "val_loss": 235.63771396875381, "val_acc": 81.33333333333333}
{"epoch": 57, "training_loss": 478.59232664108276, "training_acc": 82.33333333333333, "val_loss": 343.0890072584152, "val_acc": 73.33333333333333}
{"epoch": 58, "training_loss": 960.5262470245361, "training_acc": 75.33333333333333, "val_loss": 260.0225410461426, "val_acc": 64.0}
{"epoch": 59, "training_loss": 1010.8780379295349, "training_acc": 74.0, "val_loss": 397.7573552131653, "val_acc": 58.666666666666664}
{"epoch": 60, "training_loss": 1356.5261974334717, "training_acc": 70.0, "val_loss": 298.7170572280884, "val_acc": 74.66666666666667}
