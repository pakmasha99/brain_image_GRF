"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 46761183.48670578, "training_acc": 63.666666666666664, "val_loss": 4239163.578125, "val_acc": 34.666666666666664}
{"epoch": 1, "training_loss": 27438051.5625, "training_acc": 58.666666666666664, "val_loss": 3985283.09765625, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 18642991.75, "training_acc": 57.333333333333336, "val_loss": 4175792.90625, "val_acc": 69.33333333333333}
{"epoch": 3, "training_loss": 19077150.765625, "training_acc": 72.33333333333333, "val_loss": 2264675.05078125, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 11195093.84375, "training_acc": 63.0, "val_loss": 3597406.6953125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7747291.5625, "training_acc": 67.66666666666667, "val_loss": 1058726.333984375, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 5842602.4609375, "training_acc": 63.0, "val_loss": 2228972.90234375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 12415943.09375, "training_acc": 65.0, "val_loss": 2142925.099609375, "val_acc": 45.333333333333336}
{"epoch": 8, "training_loss": 12908567.8125, "training_acc": 65.0, "val_loss": 1577271.05859375, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 8418713.1796875, "training_acc": 63.0, "val_loss": 2310951.2651367188, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 5765747.28515625, "training_acc": 71.33333333333333, "val_loss": 685164.0390625, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 2407441.94921875, "training_acc": 68.33333333333333, "val_loss": 836136.693359375, "val_acc": 56.0}
{"epoch": 12, "training_loss": 2562819.0009765625, "training_acc": 65.66666666666667, "val_loss": 830433.919921875, "val_acc": 78.66666666666667}
{"epoch": 13, "training_loss": 3127123.23828125, "training_acc": 70.66666666666667, "val_loss": 936978.66796875, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2552728.4765625, "training_acc": 66.66666666666667, "val_loss": 2036278.28125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5943244.517578125, "training_acc": 69.0, "val_loss": 442073.9501953125, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 3904716.546875, "training_acc": 66.66666666666667, "val_loss": 1286823.408203125, "val_acc": 56.0}
{"epoch": 17, "training_loss": 4422637.8203125, "training_acc": 73.0, "val_loss": 753007.4541015625, "val_acc": 78.66666666666667}
{"epoch": 18, "training_loss": 3446568.232421875, "training_acc": 67.33333333333333, "val_loss": 605612.9443359375, "val_acc": 57.333333333333336}
{"epoch": 19, "training_loss": 3438762.376953125, "training_acc": 64.66666666666667, "val_loss": 755919.46484375, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2459910.57421875, "training_acc": 69.66666666666667, "val_loss": 1338750.51953125, "val_acc": 56.0}
{"epoch": 21, "training_loss": 4176384.826171875, "training_acc": 66.0, "val_loss": 381657.3713378906, "val_acc": 80.0}
{"epoch": 22, "training_loss": 2902383.36328125, "training_acc": 67.66666666666667, "val_loss": 300718.7236328125, "val_acc": 80.0}
{"epoch": 23, "training_loss": 2008647.4609375, "training_acc": 69.33333333333333, "val_loss": 1467419.482421875, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2453744.19921875, "training_acc": 76.0, "val_loss": 469754.375, "val_acc": 78.66666666666667}
{"epoch": 25, "training_loss": 1415168.39453125, "training_acc": 77.66666666666667, "val_loss": 311215.7598876953, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 2609461.33984375, "training_acc": 66.66666666666667, "val_loss": 515531.0017089844, "val_acc": 77.33333333333333}
{"epoch": 27, "training_loss": 2315255.8125, "training_acc": 72.33333333333333, "val_loss": 1398979.044921875, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3491516.23828125, "training_acc": 69.66666666666667, "val_loss": 389048.556640625, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 3249489.65234375, "training_acc": 67.33333333333333, "val_loss": 1312639.625, "val_acc": 48.0}
{"epoch": 30, "training_loss": 4372696.265625, "training_acc": 65.0, "val_loss": 454729.34765625, "val_acc": 81.33333333333333}
{"epoch": 31, "training_loss": 2628176.796875, "training_acc": 73.66666666666667, "val_loss": 2268800.8818359375, "val_acc": 72.0}
{"epoch": 32, "training_loss": 5087491.21484375, "training_acc": 65.0, "val_loss": 464359.48828125, "val_acc": 70.66666666666667}
{"epoch": 33, "training_loss": 1681047.6533203125, "training_acc": 78.66666666666667, "val_loss": 421058.6375579834, "val_acc": 78.66666666666667}
{"epoch": 34, "training_loss": 4428204.671875, "training_acc": 68.0, "val_loss": 452094.9423828125, "val_acc": 69.33333333333333}
{"epoch": 35, "training_loss": 4593931.96875, "training_acc": 72.0, "val_loss": 752838.4155273438, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 2606730.130859375, "training_acc": 73.66666666666667, "val_loss": 705370.5515136719, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 2213450.20703125, "training_acc": 74.33333333333333, "val_loss": 389460.388671875, "val_acc": 82.66666666666667}
{"epoch": 38, "training_loss": 3688639.794921875, "training_acc": 65.33333333333333, "val_loss": 547913.0234375, "val_acc": 80.0}
{"epoch": 39, "training_loss": 1592958.533203125, "training_acc": 79.33333333333333, "val_loss": 934379.8359375, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 2405950.03125, "training_acc": 73.66666666666667, "val_loss": 315253.75, "val_acc": 84.0}
{"epoch": 41, "training_loss": 3988756.45703125, "training_acc": 69.0, "val_loss": 1033398.705078125, "val_acc": 58.666666666666664}
