"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1708.8040390014648, "training_acc": 61.666666666666664, "val_loss": 719.2629384994507, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1652.2059574127197, "training_acc": 60.0, "val_loss": 601.1511545181274, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1425.046558380127, "training_acc": 69.66666666666667, "val_loss": 431.15211176872253, "val_acc": 45.333333333333336}
{"epoch": 3, "training_loss": 1172.9615993499756, "training_acc": 58.666666666666664, "val_loss": 374.2168731689453, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 860.5750613212585, "training_acc": 74.66666666666667, "val_loss": 249.49884223937988, "val_acc": 57.333333333333336}
{"epoch": 5, "training_loss": 530.7875142097473, "training_acc": 68.0, "val_loss": 186.4530222415924, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 390.9446873664856, "training_acc": 72.0, "val_loss": 193.01452732086182, "val_acc": 48.0}
{"epoch": 7, "training_loss": 506.83271741867065, "training_acc": 62.0, "val_loss": 112.69776129722595, "val_acc": 52.0}
{"epoch": 8, "training_loss": 303.7580351829529, "training_acc": 65.0, "val_loss": 73.93972593545914, "val_acc": 64.0}
{"epoch": 9, "training_loss": 172.3354091644287, "training_acc": 74.66666666666667, "val_loss": 52.23046353459358, "val_acc": 66.66666666666667}
{"epoch": 10, "training_loss": 155.66904616355896, "training_acc": 75.33333333333333, "val_loss": 41.508953869342804, "val_acc": 64.0}
{"epoch": 11, "training_loss": 147.90811908245087, "training_acc": 78.66666666666667, "val_loss": 46.94072604179382, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 137.03684043884277, "training_acc": 77.66666666666667, "val_loss": 60.47711110115051, "val_acc": 65.33333333333333}
{"epoch": 13, "training_loss": 158.45551657676697, "training_acc": 80.0, "val_loss": 127.56751716136932, "val_acc": 29.333333333333332}
{"epoch": 14, "training_loss": 236.72376489639282, "training_acc": 66.0, "val_loss": 60.99745988845825, "val_acc": 64.0}
{"epoch": 15, "training_loss": 167.85188961029053, "training_acc": 76.0, "val_loss": 53.85364067554474, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 162.18924987316132, "training_acc": 75.66666666666667, "val_loss": 50.16355437040329, "val_acc": 76.0}
{"epoch": 17, "training_loss": 178.02746677398682, "training_acc": 71.33333333333333, "val_loss": 51.40795719623566, "val_acc": 69.33333333333333}
{"epoch": 18, "training_loss": 210.36960339546204, "training_acc": 68.66666666666667, "val_loss": 101.21219503879547, "val_acc": 44.0}
{"epoch": 19, "training_loss": 225.9127732515335, "training_acc": 70.0, "val_loss": 102.47265315055847, "val_acc": 41.333333333333336}
{"epoch": 20, "training_loss": 264.16660165786743, "training_acc": 64.0, "val_loss": 78.65225267410278, "val_acc": 58.666666666666664}
{"epoch": 21, "training_loss": 238.833069562912, "training_acc": 73.0, "val_loss": 116.50799763202667, "val_acc": 46.666666666666664}
{"epoch": 22, "training_loss": 273.66413259506226, "training_acc": 68.66666666666667, "val_loss": 113.00705552101135, "val_acc": 45.333333333333336}
{"epoch": 23, "training_loss": 193.983384847641, "training_acc": 74.66666666666667, "val_loss": 115.6724464893341, "val_acc": 44.0}
{"epoch": 24, "training_loss": 255.79703617095947, "training_acc": 67.66666666666667, "val_loss": 101.59347674250603, "val_acc": 56.0}
{"epoch": 25, "training_loss": 207.76824629306793, "training_acc": 75.0, "val_loss": 83.93127381801605, "val_acc": 54.666666666666664}
{"epoch": 26, "training_loss": 169.85348510742188, "training_acc": 71.66666666666667, "val_loss": 48.3705729842186, "val_acc": 72.0}
{"epoch": 27, "training_loss": 158.6091684103012, "training_acc": 73.0, "val_loss": 59.19061315059662, "val_acc": 72.0}
{"epoch": 28, "training_loss": 154.66472864151, "training_acc": 77.0, "val_loss": 87.92962098121643, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 170.88615834712982, "training_acc": 77.33333333333333, "val_loss": 55.26676160097122, "val_acc": 74.66666666666667}
