"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 22495.224979400635, "training_acc": 57.666666666666664, "val_loss": 964.0109920501709, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8595.572875976562, "training_acc": 61.666666666666664, "val_loss": 2214.291061401367, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4175.946090698242, "training_acc": 55.0, "val_loss": 743.4238634109497, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4673.555595397949, "training_acc": 55.666666666666664, "val_loss": 2369.883502960205, "val_acc": 72.0}
{"epoch": 4, "training_loss": 13580.987854003906, "training_acc": 72.33333333333333, "val_loss": 1402.0521478652954, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6418.4392166137695, "training_acc": 55.0, "val_loss": 2222.151502609253, "val_acc": 72.0}
{"epoch": 6, "training_loss": 7218.1521072387695, "training_acc": 61.0, "val_loss": 1041.4334878921509, "val_acc": 72.0}
{"epoch": 7, "training_loss": 7492.529113769531, "training_acc": 72.33333333333333, "val_loss": 2353.3819675445557, "val_acc": 28.0}
{"epoch": 8, "training_loss": 9153.106002807617, "training_acc": 51.0, "val_loss": 2410.329792022705, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5759.04451751709, "training_acc": 57.0, "val_loss": 2656.342861175537, "val_acc": 72.0}
{"epoch": 10, "training_loss": 8247.929828643799, "training_acc": 66.33333333333333, "val_loss": 196.15408730506897, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4719.521224975586, "training_acc": 61.0, "val_loss": 1026.33327293396, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1527.6961741447449, "training_acc": 68.0, "val_loss": 1677.7180271148682, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3546.818344116211, "training_acc": 57.666666666666664, "val_loss": 84.07499051094055, "val_acc": 49.333333333333336}
{"epoch": 14, "training_loss": 3583.6589736938477, "training_acc": 75.0, "val_loss": 535.4736642837524, "val_acc": 28.0}
{"epoch": 15, "training_loss": 2476.6588287353516, "training_acc": 52.333333333333336, "val_loss": 1454.0088539123535, "val_acc": 72.0}
{"epoch": 16, "training_loss": 6141.413024902344, "training_acc": 57.0, "val_loss": 1394.1287121772766, "val_acc": 72.0}
{"epoch": 17, "training_loss": 9519.650573730469, "training_acc": 72.33333333333333, "val_loss": 194.8516869544983, "val_acc": 72.0}
{"epoch": 18, "training_loss": 7924.037666320801, "training_acc": 55.666666666666664, "val_loss": 1234.5789394378662, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3753.1250286102295, "training_acc": 61.0, "val_loss": 151.7321286201477, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2585.4334392547607, "training_acc": 55.666666666666664, "val_loss": 1206.8207988739014, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5018.557556152344, "training_acc": 66.33333333333333, "val_loss": 405.065721988678, "val_acc": 28.0}
{"epoch": 22, "training_loss": 9430.20905303955, "training_acc": 63.666666666666664, "val_loss": 2142.6659507751465, "val_acc": 72.0}
{"epoch": 23, "training_loss": 9586.140553474426, "training_acc": 53.0, "val_loss": 1313.927719116211, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3770.2598628997803, "training_acc": 63.666666666666664, "val_loss": 333.4909234046936, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2217.048867225647, "training_acc": 61.0, "val_loss": 464.58961486816406, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2556.335252761841, "training_acc": 62.333333333333336, "val_loss": 400.80641412734985, "val_acc": 28.0}
{"epoch": 27, "training_loss": 5990.680326461792, "training_acc": 59.666666666666664, "val_loss": 1742.6347589492798, "val_acc": 28.0}
{"epoch": 28, "training_loss": 7144.137107849121, "training_acc": 56.333333333333336, "val_loss": 3161.8933143615723, "val_acc": 72.0}
{"epoch": 29, "training_loss": 10839.331665039062, "training_acc": 53.666666666666664, "val_loss": 627.5126361846924, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5040.1301612854, "training_acc": 72.33333333333333, "val_loss": 2988.949737548828, "val_acc": 28.0}
{"epoch": 31, "training_loss": 9171.436218261719, "training_acc": 51.666666666666664, "val_loss": 2069.3128242492676, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2769.599189758301, "training_acc": 64.33333333333333, "val_loss": 2598.3007888793945, "val_acc": 28.0}
