"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1567.1462097167969, "training_acc": 67.66666666666667, "val_loss": 242.13065242767334, "val_acc": 30.666666666666668}
{"epoch": 1, "training_loss": 1327.377857208252, "training_acc": 65.33333333333333, "val_loss": 345.69332122802734, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 918.8546676635742, "training_acc": 63.0, "val_loss": 239.0758490562439, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 855.4623346328735, "training_acc": 69.0, "val_loss": 267.3247649669647, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 616.0980682373047, "training_acc": 67.66666666666667, "val_loss": 157.69617187976837, "val_acc": 64.0}
{"epoch": 5, "training_loss": 392.22198247909546, "training_acc": 76.0, "val_loss": 176.04872584342957, "val_acc": 48.0}
{"epoch": 6, "training_loss": 360.97064113616943, "training_acc": 67.66666666666667, "val_loss": 82.08608078956604, "val_acc": 72.0}
{"epoch": 7, "training_loss": 384.30958223342896, "training_acc": 60.666666666666664, "val_loss": 119.0547126531601, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 281.2701497077942, "training_acc": 67.33333333333333, "val_loss": 75.04744899272919, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 179.78705406188965, "training_acc": 73.33333333333333, "val_loss": 50.06958711147308, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 174.26522541046143, "training_acc": 73.66666666666667, "val_loss": 54.73383346199989, "val_acc": 62.666666666666664}
{"epoch": 11, "training_loss": 166.06523489952087, "training_acc": 73.33333333333333, "val_loss": 45.00337779521942, "val_acc": 74.66666666666667}
{"epoch": 12, "training_loss": 143.86731445789337, "training_acc": 76.33333333333333, "val_loss": 68.4692334830761, "val_acc": 70.66666666666667}
{"epoch": 13, "training_loss": 225.18784523010254, "training_acc": 67.66666666666667, "val_loss": 55.78403031826019, "val_acc": 65.33333333333333}
{"epoch": 14, "training_loss": 222.9065284729004, "training_acc": 73.0, "val_loss": 72.92774558067322, "val_acc": 57.333333333333336}
{"epoch": 15, "training_loss": 202.98553574085236, "training_acc": 71.33333333333333, "val_loss": 109.94508528709412, "val_acc": 40.0}
{"epoch": 16, "training_loss": 211.15525126457214, "training_acc": 70.66666666666667, "val_loss": 64.00112920999527, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 185.16204857826233, "training_acc": 77.33333333333333, "val_loss": 73.32122737169266, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 204.5579799413681, "training_acc": 70.33333333333333, "val_loss": 95.14242997765541, "val_acc": 70.66666666666667}
{"epoch": 19, "training_loss": 287.84380173683167, "training_acc": 66.33333333333333, "val_loss": 124.04928970336914, "val_acc": 69.33333333333333}
{"epoch": 20, "training_loss": 332.3509159088135, "training_acc": 74.66666666666667, "val_loss": 129.25269961357117, "val_acc": 54.666666666666664}
{"epoch": 21, "training_loss": 290.03647208213806, "training_acc": 74.66666666666667, "val_loss": 117.788150370121, "val_acc": 57.333333333333336}
{"epoch": 22, "training_loss": 238.14629006385803, "training_acc": 72.0, "val_loss": 119.9880678653717, "val_acc": 46.666666666666664}
{"epoch": 23, "training_loss": 209.6521841287613, "training_acc": 76.66666666666667, "val_loss": 142.14446306228638, "val_acc": 38.666666666666664}
{"epoch": 24, "training_loss": 262.8741993904114, "training_acc": 68.33333333333333, "val_loss": 122.88131946325302, "val_acc": 45.333333333333336}
{"epoch": 25, "training_loss": 213.31515181064606, "training_acc": 74.33333333333333, "val_loss": 80.18795084953308, "val_acc": 60.0}
{"epoch": 26, "training_loss": 172.3685474395752, "training_acc": 76.66666666666667, "val_loss": 55.63971093297005, "val_acc": 65.33333333333333}
{"epoch": 27, "training_loss": 163.58366894721985, "training_acc": 78.33333333333333, "val_loss": 56.47050666809082, "val_acc": 72.0}
{"epoch": 28, "training_loss": 147.18394362926483, "training_acc": 77.33333333333333, "val_loss": 75.12712812423706, "val_acc": 72.0}
{"epoch": 29, "training_loss": 190.2515127658844, "training_acc": 71.66666666666667, "val_loss": 91.84380304813385, "val_acc": 69.33333333333333}
{"epoch": 30, "training_loss": 189.34671187400818, "training_acc": 75.0, "val_loss": 112.46934866905212, "val_acc": 70.66666666666667}
