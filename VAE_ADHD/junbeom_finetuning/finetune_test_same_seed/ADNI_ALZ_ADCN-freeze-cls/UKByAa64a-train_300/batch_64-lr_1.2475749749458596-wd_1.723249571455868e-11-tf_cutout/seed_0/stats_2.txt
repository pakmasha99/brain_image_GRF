"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 25286.522956848145, "training_acc": 59.666666666666664, "val_loss": 8403.041564941406, "val_acc": 28.0}
{"epoch": 1, "training_loss": 12596.546401977539, "training_acc": 70.33333333333333, "val_loss": 2079.5269775390625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 5326.095703125, "training_acc": 51.666666666666664, "val_loss": 3152.5024423599243, "val_acc": 72.0}
{"epoch": 3, "training_loss": 10753.675338745117, "training_acc": 65.0, "val_loss": 6266.494583129883, "val_acc": 28.0}
{"epoch": 4, "training_loss": 18365.742919921875, "training_acc": 53.666666666666664, "val_loss": 8526.339813232422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 28435.027923583984, "training_acc": 72.33333333333333, "val_loss": 1187.4356994628906, "val_acc": 72.0}
{"epoch": 6, "training_loss": 17958.250034332275, "training_acc": 42.333333333333336, "val_loss": 2856.0026206970215, "val_acc": 72.0}
{"epoch": 7, "training_loss": 12732.539581298828, "training_acc": 72.33333333333333, "val_loss": 94.90267300605774, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 12779.061485290527, "training_acc": 42.666666666666664, "val_loss": 5556.116714477539, "val_acc": 72.0}
{"epoch": 9, "training_loss": 26577.095779418945, "training_acc": 72.33333333333333, "val_loss": 4826.59619140625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 16917.471981048584, "training_acc": 55.666666666666664, "val_loss": 3415.166721343994, "val_acc": 28.0}
{"epoch": 11, "training_loss": 16510.147003173828, "training_acc": 60.333333333333336, "val_loss": 5518.925315856934, "val_acc": 72.0}
{"epoch": 12, "training_loss": 15292.32063293457, "training_acc": 65.66666666666667, "val_loss": 7067.261642456055, "val_acc": 28.0}
{"epoch": 13, "training_loss": 15882.202346801758, "training_acc": 53.666666666666664, "val_loss": 5126.175994873047, "val_acc": 72.0}
{"epoch": 14, "training_loss": 14335.098236083984, "training_acc": 72.33333333333333, "val_loss": 5981.652370452881, "val_acc": 28.0}
{"epoch": 15, "training_loss": 16754.082633972168, "training_acc": 47.666666666666664, "val_loss": 4511.577053070068, "val_acc": 72.0}
{"epoch": 16, "training_loss": 16207.042957305908, "training_acc": 72.33333333333333, "val_loss": 318.3306474685669, "val_acc": 40.0}
{"epoch": 17, "training_loss": 4474.843490600586, "training_acc": 57.333333333333336, "val_loss": 1309.463565826416, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2407.1703872680664, "training_acc": 54.333333333333336, "val_loss": 1091.5418510437012, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4700.634532928467, "training_acc": 69.66666666666667, "val_loss": 711.596230506897, "val_acc": 28.0}
{"epoch": 20, "training_loss": 7659.343566894531, "training_acc": 63.0, "val_loss": 1469.3975791931152, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3371.244209289551, "training_acc": 59.0, "val_loss": 848.998574256897, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1750.205722808838, "training_acc": 58.666666666666664, "val_loss": 1099.7577457427979, "val_acc": 72.0}
{"epoch": 23, "training_loss": 6017.938217163086, "training_acc": 62.333333333333336, "val_loss": 1062.0949850082397, "val_acc": 28.0}
{"epoch": 24, "training_loss": 10839.023895263672, "training_acc": 63.0, "val_loss": 3049.922306060791, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5904.626762390137, "training_acc": 54.0, "val_loss": 2265.8562622070312, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5382.098343849182, "training_acc": 62.333333333333336, "val_loss": 600.6442441940308, "val_acc": 72.0}
