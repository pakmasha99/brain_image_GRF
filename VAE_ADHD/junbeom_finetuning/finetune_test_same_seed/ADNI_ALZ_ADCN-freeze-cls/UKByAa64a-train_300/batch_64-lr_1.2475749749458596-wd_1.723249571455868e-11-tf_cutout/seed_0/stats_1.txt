"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 22702.40428161621, "training_acc": 69.0, "val_loss": 729.4341306686401, "val_acc": 28.0}
{"epoch": 1, "training_loss": 17906.7548828125, "training_acc": 64.33333333333333, "val_loss": 4277.133674621582, "val_acc": 72.0}
{"epoch": 2, "training_loss": 14936.397705078125, "training_acc": 49.666666666666664, "val_loss": 1463.4463243484497, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5699.90922164917, "training_acc": 55.666666666666664, "val_loss": 2466.891996383667, "val_acc": 72.0}
{"epoch": 4, "training_loss": 16094.183227539062, "training_acc": 72.33333333333333, "val_loss": 2414.4951171875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 19566.985946655273, "training_acc": 43.0, "val_loss": 1356.96852684021, "val_acc": 72.0}
{"epoch": 6, "training_loss": 16224.12954711914, "training_acc": 72.33333333333333, "val_loss": 4485.275932312012, "val_acc": 72.0}
{"epoch": 7, "training_loss": 14536.461517333984, "training_acc": 60.333333333333336, "val_loss": 3337.0764961242676, "val_acc": 28.0}
{"epoch": 8, "training_loss": 12712.894317626953, "training_acc": 63.666666666666664, "val_loss": 4436.149082183838, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9411.51806640625, "training_acc": 71.0, "val_loss": 7459.414489746094, "val_acc": 28.0}
{"epoch": 10, "training_loss": 14862.154083251953, "training_acc": 54.333333333333336, "val_loss": 3863.1988639831543, "val_acc": 72.0}
{"epoch": 11, "training_loss": 11675.2841796875, "training_acc": 63.666666666666664, "val_loss": 5374.587509155273, "val_acc": 28.0}
{"epoch": 12, "training_loss": 18187.34716796875, "training_acc": 50.333333333333336, "val_loss": 7235.386871337891, "val_acc": 72.0}
{"epoch": 13, "training_loss": 21851.956649780273, "training_acc": 72.33333333333333, "val_loss": 143.09597277641296, "val_acc": 56.0}
{"epoch": 14, "training_loss": 7265.175842285156, "training_acc": 55.0, "val_loss": 2255.75279045105, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5525.525532245636, "training_acc": 60.0, "val_loss": 691.5715055465698, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2286.08927154541, "training_acc": 65.33333333333333, "val_loss": 499.742290019989, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4889.135513305664, "training_acc": 58.666666666666664, "val_loss": 2694.711414337158, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6202.825305938721, "training_acc": 59.666666666666664, "val_loss": 1557.8952331542969, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8516.291160583496, "training_acc": 72.33333333333333, "val_loss": 539.0211229324341, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2251.1482009887695, "training_acc": 52.333333333333336, "val_loss": 441.87901878356934, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2424.2081451416016, "training_acc": 63.333333333333336, "val_loss": 602.8128137588501, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2439.051675796509, "training_acc": 61.666666666666664, "val_loss": 700.20454454422, "val_acc": 28.0}
{"epoch": 23, "training_loss": 3028.960563659668, "training_acc": 56.333333333333336, "val_loss": 415.2538924217224, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1949.13525390625, "training_acc": 65.0, "val_loss": 187.9791226387024, "val_acc": 66.66666666666667}
{"epoch": 25, "training_loss": 2724.5709743499756, "training_acc": 66.33333333333333, "val_loss": 879.7080726623535, "val_acc": 28.0}
{"epoch": 26, "training_loss": 3635.7355422973633, "training_acc": 53.666666666666664, "val_loss": 249.6287899017334, "val_acc": 56.0}
{"epoch": 27, "training_loss": 3527.551844596863, "training_acc": 69.33333333333333, "val_loss": 3279.546028137207, "val_acc": 28.0}
{"epoch": 28, "training_loss": 9572.590927124023, "training_acc": 53.666666666666664, "val_loss": 2599.446174621582, "val_acc": 72.0}
{"epoch": 29, "training_loss": 5702.787414550781, "training_acc": 52.666666666666664, "val_loss": 2156.600679397583, "val_acc": 72.0}
{"epoch": 30, "training_loss": 6399.672927856445, "training_acc": 68.33333333333333, "val_loss": 3660.095977783203, "val_acc": 28.0}
{"epoch": 31, "training_loss": 6934.781799316406, "training_acc": 63.0, "val_loss": 479.9620838165283, "val_acc": 72.0}
{"epoch": 32, "training_loss": 7299.872848510742, "training_acc": 50.333333333333336, "val_loss": 3267.746192932129, "val_acc": 72.0}
