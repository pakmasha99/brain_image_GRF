"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 24221.824005126953, "training_acc": 56.666666666666664, "val_loss": 2258.6155700683594, "val_acc": 28.0}
{"epoch": 1, "training_loss": 21366.697692871094, "training_acc": 62.333333333333336, "val_loss": 5434.508834838867, "val_acc": 72.0}
{"epoch": 2, "training_loss": 8163.177291870117, "training_acc": 56.333333333333336, "val_loss": 2113.2593097686768, "val_acc": 72.0}
{"epoch": 3, "training_loss": 11842.93603515625, "training_acc": 48.333333333333336, "val_loss": 1518.3588256835938, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11117.558349609375, "training_acc": 72.33333333333333, "val_loss": 1487.4227361679077, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6241.758850097656, "training_acc": 53.0, "val_loss": 3306.3009338378906, "val_acc": 72.0}
{"epoch": 6, "training_loss": 10804.610580444336, "training_acc": 63.666666666666664, "val_loss": 5745.031852722168, "val_acc": 28.0}
{"epoch": 7, "training_loss": 17221.643096923828, "training_acc": 52.333333333333336, "val_loss": 7296.13232421875, "val_acc": 72.0}
{"epoch": 8, "training_loss": 23235.038696289062, "training_acc": 72.33333333333333, "val_loss": 541.9580078125, "val_acc": 72.0}
{"epoch": 9, "training_loss": 15553.711668014526, "training_acc": 49.666666666666664, "val_loss": 2428.954891204834, "val_acc": 72.0}
{"epoch": 10, "training_loss": 10576.55827331543, "training_acc": 72.33333333333333, "val_loss": 939.2045631408691, "val_acc": 28.0}
{"epoch": 11, "training_loss": 6000.255142211914, "training_acc": 55.666666666666664, "val_loss": 2528.384567260742, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5665.989650726318, "training_acc": 55.666666666666664, "val_loss": 1051.583333015442, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3250.1842346191406, "training_acc": 61.0, "val_loss": 262.28862977027893, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5859.923004150391, "training_acc": 55.0, "val_loss": 2851.4478149414062, "val_acc": 72.0}
{"epoch": 15, "training_loss": 9450.567794799805, "training_acc": 55.666666666666664, "val_loss": 963.1036186218262, "val_acc": 72.0}
{"epoch": 16, "training_loss": 8076.734771728516, "training_acc": 72.33333333333333, "val_loss": 161.18884360790253, "val_acc": 54.666666666666664}
{"epoch": 17, "training_loss": 3428.155403137207, "training_acc": 60.333333333333336, "val_loss": 859.6884155273438, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3014.425828933716, "training_acc": 62.0, "val_loss": 79.1240083873272, "val_acc": 80.0}
{"epoch": 19, "training_loss": 3458.29439163208, "training_acc": 64.66666666666667, "val_loss": 1447.7203636169434, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2850.5186042785645, "training_acc": 66.33333333333333, "val_loss": 197.15554976463318, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3266.090175628662, "training_acc": 63.666666666666664, "val_loss": 1488.6129131317139, "val_acc": 28.0}
{"epoch": 22, "training_loss": 9437.586364746094, "training_acc": 53.0, "val_loss": 4109.737804412842, "val_acc": 72.0}
{"epoch": 23, "training_loss": 9684.338844299316, "training_acc": 57.0, "val_loss": 1096.145715713501, "val_acc": 72.0}
{"epoch": 24, "training_loss": 8078.484283447266, "training_acc": 72.33333333333333, "val_loss": 1225.5620975494385, "val_acc": 28.0}
{"epoch": 25, "training_loss": 7293.292587280273, "training_acc": 53.666666666666664, "val_loss": 2332.5336112976074, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4460.277145385742, "training_acc": 61.0, "val_loss": 902.695743560791, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2013.7689714431763, "training_acc": 66.33333333333333, "val_loss": 1092.8197660446167, "val_acc": 28.0}
{"epoch": 28, "training_loss": 4246.126857757568, "training_acc": 53.0, "val_loss": 476.21758699417114, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2582.370994567871, "training_acc": 65.33333333333333, "val_loss": 726.9668610095978, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2840.283866882324, "training_acc": 62.666666666666664, "val_loss": 568.6998381614685, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2673.516273498535, "training_acc": 60.0, "val_loss": 1941.4853591918945, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2993.9934883117676, "training_acc": 59.333333333333336, "val_loss": 125.40304136276245, "val_acc": 70.66666666666667}
{"epoch": 33, "training_loss": 797.9494667053223, "training_acc": 64.66666666666667, "val_loss": 505.99064016342163, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1893.8321800231934, "training_acc": 65.66666666666667, "val_loss": 1145.0201606750488, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4807.599792480469, "training_acc": 52.666666666666664, "val_loss": 3380.5903930664062, "val_acc": 72.0}
{"epoch": 36, "training_loss": 11649.338478088379, "training_acc": 72.33333333333333, "val_loss": 3613.1570472717285, "val_acc": 28.0}
{"epoch": 37, "training_loss": 8372.524417877197, "training_acc": 51.666666666666664, "val_loss": 883.8651494979858, "val_acc": 72.0}
