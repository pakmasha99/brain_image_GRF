"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 90346.64483642578, "training_acc": 65.0, "val_loss": 10976.245895385742, "val_acc": 34.666666666666664}
{"epoch": 1, "training_loss": 54209.32653808594, "training_acc": 61.666666666666664, "val_loss": 8032.8190994262695, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 34110.8532409668, "training_acc": 59.333333333333336, "val_loss": 11043.861465454102, "val_acc": 72.0}
{"epoch": 3, "training_loss": 33453.2663269043, "training_acc": 73.66666666666667, "val_loss": 5399.126804351807, "val_acc": 66.66666666666667}
{"epoch": 4, "training_loss": 35179.88610839844, "training_acc": 54.666666666666664, "val_loss": 11756.533203125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 29152.819610595703, "training_acc": 61.0, "val_loss": 2521.759292602539, "val_acc": 76.0}
{"epoch": 6, "training_loss": 15179.052734375, "training_acc": 72.66666666666667, "val_loss": 1769.368896484375, "val_acc": 76.0}
{"epoch": 7, "training_loss": 7842.285614013672, "training_acc": 69.33333333333333, "val_loss": 983.6856994628906, "val_acc": 61.333333333333336}
{"epoch": 8, "training_loss": 7539.9429931640625, "training_acc": 63.0, "val_loss": 2382.4418334960938, "val_acc": 44.0}
{"epoch": 9, "training_loss": 4717.820960998535, "training_acc": 65.66666666666667, "val_loss": 2607.488136291504, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 5787.907772064209, "training_acc": 66.66666666666667, "val_loss": 2260.2128353118896, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8443.81884765625, "training_acc": 68.66666666666667, "val_loss": 2579.7589797973633, "val_acc": 72.0}
{"epoch": 12, "training_loss": 10890.152465820312, "training_acc": 61.666666666666664, "val_loss": 4671.474517822266, "val_acc": 40.0}
{"epoch": 13, "training_loss": 17258.76773071289, "training_acc": 60.333333333333336, "val_loss": 1680.02396774292, "val_acc": 77.33333333333333}
{"epoch": 14, "training_loss": 13537.273712158203, "training_acc": 64.66666666666667, "val_loss": 3271.084861755371, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 9664.815795898438, "training_acc": 70.0, "val_loss": 2172.371898651123, "val_acc": 72.0}
{"epoch": 16, "training_loss": 8403.264236450195, "training_acc": 68.0, "val_loss": 986.8186416625977, "val_acc": 69.33333333333333}
{"epoch": 17, "training_loss": 13292.733642578125, "training_acc": 63.0, "val_loss": 2599.603274822235, "val_acc": 72.0}
{"epoch": 18, "training_loss": 11159.522750854492, "training_acc": 65.66666666666667, "val_loss": 3871.393822669983, "val_acc": 72.0}
{"epoch": 19, "training_loss": 12144.31364440918, "training_acc": 68.33333333333333, "val_loss": 3719.0526962280273, "val_acc": 72.0}
{"epoch": 20, "training_loss": 10560.30746459961, "training_acc": 65.66666666666667, "val_loss": 5474.452487945557, "val_acc": 72.0}
{"epoch": 21, "training_loss": 17974.610137939453, "training_acc": 56.0, "val_loss": 12029.598762512207, "val_acc": 72.0}
{"epoch": 22, "training_loss": 40616.545959472656, "training_acc": 71.0, "val_loss": 8656.793754577637, "val_acc": 26.666666666666668}
{"epoch": 23, "training_loss": 30560.050842285156, "training_acc": 60.666666666666664, "val_loss": 7751.557712554932, "val_acc": 72.0}
{"epoch": 24, "training_loss": 20075.705390930176, "training_acc": 65.0, "val_loss": 4688.739654541016, "val_acc": 70.66666666666667}
{"epoch": 25, "training_loss": 15363.599624633789, "training_acc": 69.33333333333333, "val_loss": 1819.9851341247559, "val_acc": 74.66666666666667}
{"epoch": 26, "training_loss": 8611.94543838501, "training_acc": 66.66666666666667, "val_loss": 3884.9834175109863, "val_acc": 72.0}
