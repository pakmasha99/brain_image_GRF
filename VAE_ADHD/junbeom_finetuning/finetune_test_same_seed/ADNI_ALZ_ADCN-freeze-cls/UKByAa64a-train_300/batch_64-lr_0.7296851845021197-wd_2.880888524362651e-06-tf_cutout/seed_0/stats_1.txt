"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3982.449810028076, "training_acc": 56.333333333333336, "val_loss": 446.5607466697693, "val_acc": 69.33333333333333}
{"epoch": 1, "training_loss": 2514.175986289978, "training_acc": 70.66666666666667, "val_loss": 646.0468139648438, "val_acc": 30.666666666666668}
{"epoch": 2, "training_loss": 1721.0046157836914, "training_acc": 62.666666666666664, "val_loss": 311.1750633716583, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 891.2249450683594, "training_acc": 64.66666666666667, "val_loss": 355.5540940761566, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 665.2919039726257, "training_acc": 64.0, "val_loss": 313.76781463623047, "val_acc": 69.33333333333333}
{"epoch": 5, "training_loss": 740.9898681640625, "training_acc": 67.0, "val_loss": 270.6134886741638, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 639.2007961273193, "training_acc": 70.0, "val_loss": 184.13980865478516, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 345.3723294734955, "training_acc": 73.66666666666667, "val_loss": 68.2593440413475, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 543.1503357887268, "training_acc": 65.0, "val_loss": 625.0129590034485, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1775.4945068359375, "training_acc": 58.0, "val_loss": 459.5930643081665, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 1274.7996559143066, "training_acc": 63.333333333333336, "val_loss": 426.41087341308594, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 1035.1898107528687, "training_acc": 75.66666666666667, "val_loss": 387.102126121521, "val_acc": 56.0}
{"epoch": 12, "training_loss": 937.910285949707, "training_acc": 70.66666666666667, "val_loss": 201.44304406642914, "val_acc": 60.0}
{"epoch": 13, "training_loss": 461.1578092575073, "training_acc": 70.33333333333333, "val_loss": 208.2662386894226, "val_acc": 49.333333333333336}
{"epoch": 14, "training_loss": 553.131867647171, "training_acc": 66.0, "val_loss": 300.0574071407318, "val_acc": 40.0}
{"epoch": 15, "training_loss": 468.4703598022461, "training_acc": 68.33333333333333, "val_loss": 247.58851742744446, "val_acc": 56.0}
{"epoch": 16, "training_loss": 731.8152523040771, "training_acc": 67.33333333333333, "val_loss": 282.492862701416, "val_acc": 45.333333333333336}
{"epoch": 17, "training_loss": 455.1088674068451, "training_acc": 71.33333333333333, "val_loss": 194.38833129405975, "val_acc": 50.666666666666664}
{"epoch": 18, "training_loss": 351.7048120498657, "training_acc": 67.0, "val_loss": 150.36931157112122, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 408.87157678604126, "training_acc": 70.33333333333333, "val_loss": 147.50666332244873, "val_acc": 72.0}
{"epoch": 20, "training_loss": 206.57788181304932, "training_acc": 80.0, "val_loss": 71.66157019138336, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 232.86424779891968, "training_acc": 75.0, "val_loss": 147.86198830604553, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 309.7870728969574, "training_acc": 70.0, "val_loss": 100.6841339468956, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 188.63841474056244, "training_acc": 79.0, "val_loss": 90.35916092991829, "val_acc": 77.33333333333333}
{"epoch": 24, "training_loss": 156.99228262901306, "training_acc": 81.66666666666667, "val_loss": 82.16857576370239, "val_acc": 70.66666666666667}
{"epoch": 25, "training_loss": 205.6842896938324, "training_acc": 73.0, "val_loss": 128.7853982448578, "val_acc": 72.0}
{"epoch": 26, "training_loss": 243.70491456985474, "training_acc": 79.33333333333333, "val_loss": 104.49336087703705, "val_acc": 70.66666666666667}
