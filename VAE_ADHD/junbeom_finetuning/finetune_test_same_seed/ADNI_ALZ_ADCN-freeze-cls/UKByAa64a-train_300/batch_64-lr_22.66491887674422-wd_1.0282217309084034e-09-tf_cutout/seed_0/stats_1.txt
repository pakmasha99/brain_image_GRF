"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 149876.65728759766, "training_acc": 61.666666666666664, "val_loss": 65481.38171386719, "val_acc": 28.0}
{"epoch": 1, "training_loss": 152047.62426757812, "training_acc": 59.666666666666664, "val_loss": 57268.03161621094, "val_acc": 72.0}
{"epoch": 2, "training_loss": 136674.9256591797, "training_acc": 71.0, "val_loss": 37419.25, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 113765.89233398438, "training_acc": 56.666666666666664, "val_loss": 30681.889434814453, "val_acc": 72.0}
{"epoch": 4, "training_loss": 72888.10534667969, "training_acc": 74.33333333333333, "val_loss": 20685.539596557617, "val_acc": 56.0}
{"epoch": 5, "training_loss": 44672.248596191406, "training_acc": 68.33333333333333, "val_loss": 15192.83544921875, "val_acc": 72.0}
{"epoch": 6, "training_loss": 30039.2373046875, "training_acc": 73.66666666666667, "val_loss": 16076.272117614746, "val_acc": 49.333333333333336}
{"epoch": 7, "training_loss": 40911.23013305664, "training_acc": 60.666666666666664, "val_loss": 13472.362762451172, "val_acc": 44.0}
{"epoch": 8, "training_loss": 32230.004150390625, "training_acc": 62.666666666666664, "val_loss": 5498.2534255981445, "val_acc": 61.333333333333336}
{"epoch": 9, "training_loss": 14426.197189331055, "training_acc": 71.33333333333333, "val_loss": 3821.9956436157227, "val_acc": 61.333333333333336}
{"epoch": 10, "training_loss": 14411.483428955078, "training_acc": 63.0, "val_loss": 3584.0038528442383, "val_acc": 72.0}
{"epoch": 11, "training_loss": 10665.037437438965, "training_acc": 70.66666666666667, "val_loss": 2685.6067237854004, "val_acc": 58.666666666666664}
{"epoch": 12, "training_loss": 5595.830268859863, "training_acc": 75.33333333333333, "val_loss": 2432.464457511902, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5510.138301849365, "training_acc": 75.33333333333333, "val_loss": 2387.182559967041, "val_acc": 61.333333333333336}
{"epoch": 14, "training_loss": 15390.842056274414, "training_acc": 63.0, "val_loss": 4821.238998413086, "val_acc": 72.0}
{"epoch": 15, "training_loss": 8050.618721008301, "training_acc": 72.33333333333333, "val_loss": 2541.3236694335938, "val_acc": 76.0}
{"epoch": 16, "training_loss": 6105.908676147461, "training_acc": 71.33333333333333, "val_loss": 3527.9881553649902, "val_acc": 69.33333333333333}
{"epoch": 17, "training_loss": 16894.282104492188, "training_acc": 64.0, "val_loss": 3904.3008785247803, "val_acc": 68.0}
{"epoch": 18, "training_loss": 14270.908889770508, "training_acc": 71.0, "val_loss": 6142.0499267578125, "val_acc": 61.333333333333336}
{"epoch": 19, "training_loss": 12824.491247177124, "training_acc": 73.66666666666667, "val_loss": 4298.523056030273, "val_acc": 57.333333333333336}
{"epoch": 20, "training_loss": 9894.11328125, "training_acc": 67.33333333333333, "val_loss": 3933.4491577148438, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 7714.268440246582, "training_acc": 74.66666666666667, "val_loss": 4106.6251583099365, "val_acc": 61.333333333333336}
{"epoch": 22, "training_loss": 8741.353378295898, "training_acc": 72.33333333333333, "val_loss": 3758.8605880737305, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 4322.438171386719, "training_acc": 80.33333333333333, "val_loss": 5837.4827880859375, "val_acc": 37.333333333333336}
{"epoch": 24, "training_loss": 28482.600158691406, "training_acc": 63.666666666666664, "val_loss": 6283.260818481445, "val_acc": 46.666666666666664}
{"epoch": 25, "training_loss": 19119.252075195312, "training_acc": 66.33333333333333, "val_loss": 7320.999080657959, "val_acc": 58.666666666666664}
{"epoch": 26, "training_loss": 15846.152954101562, "training_acc": 69.66666666666667, "val_loss": 5119.70182800293, "val_acc": 65.33333333333333}
{"epoch": 27, "training_loss": 9740.494689941406, "training_acc": 73.0, "val_loss": 4173.89111328125, "val_acc": 72.0}
{"epoch": 28, "training_loss": 7402.578704833984, "training_acc": 74.66666666666667, "val_loss": 3220.063018798828, "val_acc": 65.33333333333333}
{"epoch": 29, "training_loss": 9701.679443359375, "training_acc": 69.66666666666667, "val_loss": 3469.7068309783936, "val_acc": 72.0}
{"epoch": 30, "training_loss": 10618.067752838135, "training_acc": 73.0, "val_loss": 5675.542617797852, "val_acc": 70.66666666666667}
{"epoch": 31, "training_loss": 13604.775848388672, "training_acc": 69.66666666666667, "val_loss": 8315.955863952637, "val_acc": 70.66666666666667}
{"epoch": 32, "training_loss": 16800.281616210938, "training_acc": 70.33333333333333, "val_loss": 3873.4675188064575, "val_acc": 73.33333333333333}
