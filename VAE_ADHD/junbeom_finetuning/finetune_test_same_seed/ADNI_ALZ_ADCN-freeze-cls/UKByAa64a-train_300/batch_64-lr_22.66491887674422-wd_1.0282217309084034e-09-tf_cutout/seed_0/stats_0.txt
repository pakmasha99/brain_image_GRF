"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 154053.65154266357, "training_acc": 64.33333333333333, "val_loss": 55619.615173339844, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 132285.97314453125, "training_acc": 61.666666666666664, "val_loss": 45045.730041503906, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 116815.77172851562, "training_acc": 67.66666666666667, "val_loss": 24423.69497680664, "val_acc": 50.666666666666664}
{"epoch": 3, "training_loss": 66854.2709350586, "training_acc": 64.66666666666667, "val_loss": 18886.594787597656, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 67641.39935302734, "training_acc": 74.66666666666667, "val_loss": 16382.846282958984, "val_acc": 42.666666666666664}
{"epoch": 5, "training_loss": 47343.05285644531, "training_acc": 62.0, "val_loss": 5022.697135925293, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 29502.13589477539, "training_acc": 60.666666666666664, "val_loss": 11282.255195617676, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 27189.4428024292, "training_acc": 67.66666666666667, "val_loss": 6808.51692199707, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 20223.399688720703, "training_acc": 66.0, "val_loss": 5726.016265869141, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 18413.382957458496, "training_acc": 68.0, "val_loss": 5772.800771713257, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 23900.167572021484, "training_acc": 61.0, "val_loss": 5788.273807525635, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 15197.583709716797, "training_acc": 69.33333333333333, "val_loss": 1229.7386665344238, "val_acc": 78.66666666666667}
{"epoch": 12, "training_loss": 19026.062744140625, "training_acc": 64.66666666666667, "val_loss": 5303.956100463867, "val_acc": 41.333333333333336}
{"epoch": 13, "training_loss": 11926.757751464844, "training_acc": 65.33333333333333, "val_loss": 2033.3936324119568, "val_acc": 74.66666666666667}
{"epoch": 14, "training_loss": 9694.972946166992, "training_acc": 68.66666666666667, "val_loss": 3629.9052734375, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 5996.591144561768, "training_acc": 74.0, "val_loss": 1301.718409538269, "val_acc": 69.33333333333333}
{"epoch": 16, "training_loss": 10509.840026855469, "training_acc": 65.0, "val_loss": 7442.872596740723, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 19853.525665283203, "training_acc": 66.66666666666667, "val_loss": 3412.7064056396484, "val_acc": 77.33333333333333}
{"epoch": 18, "training_loss": 11083.5869140625, "training_acc": 72.66666666666667, "val_loss": 1103.2659301757812, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 14619.64128112793, "training_acc": 64.0, "val_loss": 855.3399968147278, "val_acc": 72.0}
{"epoch": 20, "training_loss": 5325.9287757873535, "training_acc": 75.33333333333333, "val_loss": 3970.5210304260254, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 16602.641387939453, "training_acc": 66.66666666666667, "val_loss": 1592.1871910095215, "val_acc": 81.33333333333333}
{"epoch": 22, "training_loss": 17578.443572998047, "training_acc": 66.33333333333333, "val_loss": 868.8264122009277, "val_acc": 84.0}
{"epoch": 23, "training_loss": 19148.145599365234, "training_acc": 64.33333333333333, "val_loss": 5498.721281051636, "val_acc": 40.0}
{"epoch": 24, "training_loss": 9510.87466430664, "training_acc": 69.66666666666667, "val_loss": 1791.5162410736084, "val_acc": 68.0}
{"epoch": 25, "training_loss": 18377.848266601562, "training_acc": 64.33333333333333, "val_loss": 1530.511329650879, "val_acc": 68.0}
{"epoch": 26, "training_loss": 33915.739849090576, "training_acc": 68.66666666666667, "val_loss": 12050.512664794922, "val_acc": 33.333333333333336}
{"epoch": 27, "training_loss": 26257.752517700195, "training_acc": 66.33333333333333, "val_loss": 2726.1588306427, "val_acc": 70.66666666666667}
{"epoch": 28, "training_loss": 12887.280044555664, "training_acc": 70.0, "val_loss": 3851.894130706787, "val_acc": 54.666666666666664}
{"epoch": 29, "training_loss": 23096.430084228516, "training_acc": 63.666666666666664, "val_loss": 1888.677619934082, "val_acc": 72.0}
{"epoch": 30, "training_loss": 8057.697616577148, "training_acc": 74.66666666666667, "val_loss": 968.4417247772217, "val_acc": 81.33333333333333}
{"epoch": 31, "training_loss": 13072.786560058594, "training_acc": 69.66666666666667, "val_loss": 6593.775695800781, "val_acc": 42.666666666666664}
{"epoch": 32, "training_loss": 13477.410583496094, "training_acc": 65.33333333333333, "val_loss": 1223.5215969085693, "val_acc": 82.66666666666667}
{"epoch": 33, "training_loss": 6386.022842407227, "training_acc": 76.0, "val_loss": 4269.683891296387, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 7654.7788009643555, "training_acc": 65.66666666666667, "val_loss": 2398.9307839870453, "val_acc": 78.66666666666667}
{"epoch": 35, "training_loss": 7549.877990722656, "training_acc": 73.66666666666667, "val_loss": 1228.1342930793762, "val_acc": 81.33333333333333}
{"epoch": 36, "training_loss": 6328.244453430176, "training_acc": 74.66666666666667, "val_loss": 2369.2485313415527, "val_acc": 76.0}
{"epoch": 37, "training_loss": 8825.806816101074, "training_acc": 70.0, "val_loss": 1704.1092557907104, "val_acc": 65.33333333333333}
{"epoch": 38, "training_loss": 29567.820678710938, "training_acc": 62.0, "val_loss": 1522.6364974975586, "val_acc": 82.66666666666667}
