"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 37471.53171157837, "training_acc": 59.0, "val_loss": 5021.422981262207, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15347.525875091553, "training_acc": 64.0, "val_loss": 3729.7510299682617, "val_acc": 72.0}
{"epoch": 2, "training_loss": 12303.078067779541, "training_acc": 58.333333333333336, "val_loss": 2882.7555618286133, "val_acc": 72.0}
{"epoch": 3, "training_loss": 13950.697937011719, "training_acc": 65.66666666666667, "val_loss": 2094.4672088623047, "val_acc": 45.333333333333336}
{"epoch": 4, "training_loss": 13523.341110229492, "training_acc": 65.66666666666667, "val_loss": 1302.7847747802734, "val_acc": 76.0}
{"epoch": 5, "training_loss": 10640.618621826172, "training_acc": 60.333333333333336, "val_loss": 4595.738510131836, "val_acc": 72.0}
{"epoch": 6, "training_loss": 10916.399765014648, "training_acc": 66.66666666666667, "val_loss": 1013.5184726715088, "val_acc": 77.33333333333333}
{"epoch": 7, "training_loss": 6234.805816650391, "training_acc": 68.33333333333333, "val_loss": 615.5864262580872, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 3820.6765899658203, "training_acc": 69.33333333333333, "val_loss": 903.3709707260132, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 2932.19384765625, "training_acc": 70.33333333333333, "val_loss": 2648.642738342285, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5468.2947998046875, "training_acc": 65.0, "val_loss": 1842.8938789367676, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4725.655876159668, "training_acc": 64.0, "val_loss": 1229.9173922538757, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 3620.636658668518, "training_acc": 66.66666666666667, "val_loss": 863.4221773147583, "val_acc": 53.333333333333336}
{"epoch": 13, "training_loss": 3003.6081314086914, "training_acc": 67.66666666666667, "val_loss": 927.4620361328125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2217.0787391662598, "training_acc": 72.0, "val_loss": 2171.8448448181152, "val_acc": 33.333333333333336}
{"epoch": 15, "training_loss": 6820.126876831055, "training_acc": 60.666666666666664, "val_loss": 780.0183601379395, "val_acc": 72.0}
{"epoch": 16, "training_loss": 6818.811737060547, "training_acc": 62.333333333333336, "val_loss": 920.0217704772949, "val_acc": 77.33333333333333}
{"epoch": 17, "training_loss": 5434.291042327881, "training_acc": 73.66666666666667, "val_loss": 1401.1849250793457, "val_acc": 61.333333333333336}
{"epoch": 18, "training_loss": 7325.352802276611, "training_acc": 65.0, "val_loss": 1961.8148880004883, "val_acc": 42.666666666666664}
{"epoch": 19, "training_loss": 4422.93701171875, "training_acc": 65.33333333333333, "val_loss": 383.3710741996765, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1295.7609243392944, "training_acc": 78.33333333333333, "val_loss": 619.017671585083, "val_acc": 77.33333333333333}
{"epoch": 21, "training_loss": 1841.2394161224365, "training_acc": 74.0, "val_loss": 524.7287920084782, "val_acc": 82.66666666666667}
{"epoch": 22, "training_loss": 2001.3126487731934, "training_acc": 73.66666666666667, "val_loss": 441.955527305603, "val_acc": 80.0}
{"epoch": 23, "training_loss": 2385.4016036987305, "training_acc": 70.33333333333333, "val_loss": 510.7662467956543, "val_acc": 81.33333333333333}
{"epoch": 24, "training_loss": 4139.665907859802, "training_acc": 67.0, "val_loss": 976.0427322387695, "val_acc": 65.33333333333333}
{"epoch": 25, "training_loss": 3134.8888664245605, "training_acc": 74.33333333333333, "val_loss": 730.4698858261108, "val_acc": 66.66666666666667}
{"epoch": 26, "training_loss": 5595.391418457031, "training_acc": 65.66666666666667, "val_loss": 1870.3443851470947, "val_acc": 41.333333333333336}
{"epoch": 27, "training_loss": 15136.281616210938, "training_acc": 67.66666666666667, "val_loss": 563.51145362854, "val_acc": 80.0}
{"epoch": 28, "training_loss": 13895.558807373047, "training_acc": 58.333333333333336, "val_loss": 7065.8612060546875, "val_acc": 72.0}
{"epoch": 29, "training_loss": 19413.916748046875, "training_acc": 64.0, "val_loss": 2156.2691440582275, "val_acc": 56.0}
{"epoch": 30, "training_loss": 14889.474212646484, "training_acc": 67.66666666666667, "val_loss": 1712.0905952453613, "val_acc": 74.66666666666667}
{"epoch": 31, "training_loss": 9240.561477661133, "training_acc": 63.666666666666664, "val_loss": 2482.0291032791138, "val_acc": 72.0}
{"epoch": 32, "training_loss": 5668.1684284210205, "training_acc": 69.33333333333333, "val_loss": 1411.0633239746094, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 4069.0032358169556, "training_acc": 72.0, "val_loss": 1323.3381967544556, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3556.2498817443848, "training_acc": 71.66666666666667, "val_loss": 1258.4452381134033, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 3343.4956665039062, "training_acc": 72.33333333333333, "val_loss": 1222.878583908081, "val_acc": 74.66666666666667}
{"epoch": 36, "training_loss": 3603.8429565429688, "training_acc": 75.0, "val_loss": 818.9405059814453, "val_acc": 77.33333333333333}
{"epoch": 37, "training_loss": 2355.0266580581665, "training_acc": 75.0, "val_loss": 1181.7279205322266, "val_acc": 61.333333333333336}
{"epoch": 38, "training_loss": 2245.5850715637207, "training_acc": 73.66666666666667, "val_loss": 559.0813615322113, "val_acc": 80.0}
