"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 48248.72673416138, "training_acc": 56.0, "val_loss": 13623.586250305176, "val_acc": 28.0}
{"epoch": 1, "training_loss": 35962.653381347656, "training_acc": 62.0, "val_loss": 9640.071792602539, "val_acc": 72.0}
{"epoch": 2, "training_loss": 29712.08673095703, "training_acc": 63.666666666666664, "val_loss": 3587.145853996277, "val_acc": 64.0}
{"epoch": 3, "training_loss": 28854.32470703125, "training_acc": 63.333333333333336, "val_loss": 5115.625658035278, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 15216.900360107422, "training_acc": 64.0, "val_loss": 1464.8816995620728, "val_acc": 74.66666666666667}
{"epoch": 5, "training_loss": 9567.531372070312, "training_acc": 69.0, "val_loss": 1275.4357299804688, "val_acc": 65.33333333333333}
{"epoch": 6, "training_loss": 6675.467910766602, "training_acc": 64.66666666666667, "val_loss": 998.7435722351074, "val_acc": 53.333333333333336}
{"epoch": 7, "training_loss": 3471.304313659668, "training_acc": 64.0, "val_loss": 387.16520166397095, "val_acc": 74.66666666666667}
{"epoch": 8, "training_loss": 3890.434036254883, "training_acc": 67.0, "val_loss": 910.1420345306396, "val_acc": 65.33333333333333}
{"epoch": 9, "training_loss": 4813.778399467468, "training_acc": 70.66666666666667, "val_loss": 2527.9041633605957, "val_acc": 33.333333333333336}
{"epoch": 10, "training_loss": 6883.394836425781, "training_acc": 59.0, "val_loss": 809.9084858894348, "val_acc": 56.0}
{"epoch": 11, "training_loss": 6342.3555908203125, "training_acc": 69.66666666666667, "val_loss": 2211.2787532806396, "val_acc": 42.666666666666664}
{"epoch": 12, "training_loss": 7051.718341827393, "training_acc": 64.0, "val_loss": 1466.0856647491455, "val_acc": 50.666666666666664}
{"epoch": 13, "training_loss": 4576.851745605469, "training_acc": 65.33333333333333, "val_loss": 1175.9308233261108, "val_acc": 49.333333333333336}
{"epoch": 14, "training_loss": 3014.716428756714, "training_acc": 68.0, "val_loss": 1047.3248348236084, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3566.0115356445312, "training_acc": 71.33333333333333, "val_loss": 521.0283432006836, "val_acc": 76.0}
{"epoch": 16, "training_loss": 1739.9359970092773, "training_acc": 74.0, "val_loss": 559.4081482887268, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 2168.7040452957153, "training_acc": 70.0, "val_loss": 255.93349599838257, "val_acc": 77.33333333333333}
{"epoch": 18, "training_loss": 1662.6034393310547, "training_acc": 76.66666666666667, "val_loss": 1540.158821105957, "val_acc": 72.0}
{"epoch": 19, "training_loss": 6291.323417663574, "training_acc": 64.0, "val_loss": 1329.7836198806763, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 3731.278263092041, "training_acc": 71.66666666666667, "val_loss": 1307.1788716316223, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3711.7351112365723, "training_acc": 70.0, "val_loss": 652.7793755531311, "val_acc": 54.666666666666664}
{"epoch": 22, "training_loss": 1619.931245803833, "training_acc": 74.0, "val_loss": 747.656063079834, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4953.840156555176, "training_acc": 65.0, "val_loss": 3599.018148422241, "val_acc": 72.0}
{"epoch": 24, "training_loss": 10413.640869140625, "training_acc": 60.666666666666664, "val_loss": 2704.364351272583, "val_acc": 72.0}
{"epoch": 25, "training_loss": 12677.6587600708, "training_acc": 71.66666666666667, "val_loss": 3450.0711708068848, "val_acc": 37.333333333333336}
{"epoch": 26, "training_loss": 10904.769081115723, "training_acc": 65.33333333333333, "val_loss": 633.8555908203125, "val_acc": 77.33333333333333}
{"epoch": 27, "training_loss": 5829.532318115234, "training_acc": 69.0, "val_loss": 818.5713529586792, "val_acc": 77.33333333333333}
{"epoch": 28, "training_loss": 8529.049224853516, "training_acc": 59.333333333333336, "val_loss": 1872.9977474212646, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 7664.870872497559, "training_acc": 71.33333333333333, "val_loss": 2632.1297721862793, "val_acc": 72.0}
{"epoch": 30, "training_loss": 7506.346378326416, "training_acc": 65.33333333333333, "val_loss": 2102.5116295814514, "val_acc": 72.0}
{"epoch": 31, "training_loss": 7344.094902038574, "training_acc": 72.0, "val_loss": 451.0311279296875, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 4380.965908050537, "training_acc": 68.33333333333333, "val_loss": 2036.6049556732178, "val_acc": 72.0}
{"epoch": 33, "training_loss": 7819.4488525390625, "training_acc": 63.333333333333336, "val_loss": 1571.4279508590698, "val_acc": 72.0}
{"epoch": 34, "training_loss": 8930.276123046875, "training_acc": 70.0, "val_loss": 1388.585039138794, "val_acc": 65.33333333333333}
{"epoch": 35, "training_loss": 10472.070816040039, "training_acc": 70.33333333333333, "val_loss": 998.850058555603, "val_acc": 72.0}
{"epoch": 36, "training_loss": 8929.45571899414, "training_acc": 64.66666666666667, "val_loss": 4264.240966796875, "val_acc": 72.0}
