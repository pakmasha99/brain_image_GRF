"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1585.3590278625488, "training_acc": 67.66666666666667, "val_loss": 246.12352085113525, "val_acc": 30.666666666666668}
{"epoch": 1, "training_loss": 1345.1369037628174, "training_acc": 65.33333333333333, "val_loss": 351.52486991882324, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 932.3937482833862, "training_acc": 63.0, "val_loss": 243.4632704257965, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 868.0587015151978, "training_acc": 69.0, "val_loss": 272.9925661087036, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 627.261429309845, "training_acc": 68.0, "val_loss": 160.43122589588165, "val_acc": 64.0}
{"epoch": 5, "training_loss": 402.08665013313293, "training_acc": 76.0, "val_loss": 174.15652441978455, "val_acc": 48.0}
{"epoch": 6, "training_loss": 365.24932622909546, "training_acc": 67.33333333333333, "val_loss": 87.46444910764694, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 379.3548107147217, "training_acc": 61.666666666666664, "val_loss": 113.87770104408264, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 269.19929599761963, "training_acc": 69.0, "val_loss": 65.35334968566895, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 169.24065673351288, "training_acc": 73.33333333333333, "val_loss": 43.0980229973793, "val_acc": 66.66666666666667}
{"epoch": 10, "training_loss": 155.12751460075378, "training_acc": 75.33333333333333, "val_loss": 48.52296382188797, "val_acc": 68.0}
{"epoch": 11, "training_loss": 140.59852874279022, "training_acc": 77.0, "val_loss": 53.38140249252319, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 156.7849963903427, "training_acc": 73.33333333333333, "val_loss": 57.63196101784706, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 187.58207654953003, "training_acc": 74.66666666666667, "val_loss": 72.86254125833511, "val_acc": 53.333333333333336}
{"epoch": 14, "training_loss": 188.71030449867249, "training_acc": 73.33333333333333, "val_loss": 116.40660095214844, "val_acc": 34.666666666666664}
{"epoch": 15, "training_loss": 223.43671250343323, "training_acc": 68.66666666666667, "val_loss": 59.81407731771469, "val_acc": 60.0}
{"epoch": 16, "training_loss": 180.3270149230957, "training_acc": 71.0, "val_loss": 84.7400815486908, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 175.38985109329224, "training_acc": 77.66666666666667, "val_loss": 79.95600998401642, "val_acc": 69.33333333333333}
{"epoch": 18, "training_loss": 173.83853459358215, "training_acc": 73.33333333333333, "val_loss": 71.36115422844887, "val_acc": 69.33333333333333}
{"epoch": 19, "training_loss": 143.0585185289383, "training_acc": 77.0, "val_loss": 71.256276845932, "val_acc": 70.66666666666667}
{"epoch": 20, "training_loss": 183.33619260787964, "training_acc": 74.0, "val_loss": 129.47048544883728, "val_acc": 29.333333333333332}
{"epoch": 21, "training_loss": 228.43464279174805, "training_acc": 69.33333333333333, "val_loss": 55.35596686601639, "val_acc": 72.0}
{"epoch": 22, "training_loss": 185.17590308189392, "training_acc": 74.0, "val_loss": 67.35292291641235, "val_acc": 74.66666666666667}
{"epoch": 23, "training_loss": 139.81415450572968, "training_acc": 81.33333333333333, "val_loss": 69.92146110534668, "val_acc": 61.333333333333336}
{"epoch": 24, "training_loss": 133.62513625621796, "training_acc": 78.66666666666667, "val_loss": 54.96363854408264, "val_acc": 72.0}
{"epoch": 25, "training_loss": 124.56963753700256, "training_acc": 80.66666666666667, "val_loss": 50.78045302629471, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 119.52977204322815, "training_acc": 83.66666666666667, "val_loss": 51.66862776875496, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 107.56330335140228, "training_acc": 84.66666666666667, "val_loss": 54.9727658033371, "val_acc": 69.33333333333333}
{"epoch": 28, "training_loss": 118.92914807796478, "training_acc": 83.66666666666667, "val_loss": 54.51751732826233, "val_acc": 72.0}
