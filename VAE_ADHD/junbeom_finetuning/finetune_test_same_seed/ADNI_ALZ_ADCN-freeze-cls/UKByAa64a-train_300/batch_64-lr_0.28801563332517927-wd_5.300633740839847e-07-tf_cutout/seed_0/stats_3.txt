"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1894.2168197631836, "training_acc": 56.333333333333336, "val_loss": 157.6707249879837, "val_acc": 45.333333333333336}
{"epoch": 1, "training_loss": 670.5865168571472, "training_acc": 65.0, "val_loss": 66.79651907086372, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 427.6126083135605, "training_acc": 69.33333333333333, "val_loss": 46.65109646320343, "val_acc": 80.0}
{"epoch": 3, "training_loss": 206.29622387886047, "training_acc": 68.66666666666667, "val_loss": 95.46116900444031, "val_acc": 30.666666666666668}
{"epoch": 4, "training_loss": 291.27275919914246, "training_acc": 59.0, "val_loss": 93.32602190971375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 301.01210260391235, "training_acc": 70.0, "val_loss": 94.91282260417938, "val_acc": 72.0}
{"epoch": 6, "training_loss": 301.3290505409241, "training_acc": 66.66666666666667, "val_loss": 92.21059608459473, "val_acc": 72.0}
{"epoch": 7, "training_loss": 262.83337807655334, "training_acc": 68.33333333333333, "val_loss": 39.87953960895538, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 207.73303151130676, "training_acc": 64.66666666666667, "val_loss": 37.21968460083008, "val_acc": 76.0}
{"epoch": 9, "training_loss": 154.85690712928772, "training_acc": 73.0, "val_loss": 66.49589967727661, "val_acc": 72.0}
{"epoch": 10, "training_loss": 176.8560276031494, "training_acc": 71.0, "val_loss": 36.045608565211296, "val_acc": 74.66666666666667}
{"epoch": 11, "training_loss": 227.05112779140472, "training_acc": 66.66666666666667, "val_loss": 56.82704955339432, "val_acc": 56.0}
{"epoch": 12, "training_loss": 179.7459466457367, "training_acc": 74.66666666666667, "val_loss": 36.957486391067505, "val_acc": 66.66666666666667}
{"epoch": 13, "training_loss": 156.85546708106995, "training_acc": 74.33333333333333, "val_loss": 39.699344515800476, "val_acc": 77.33333333333333}
{"epoch": 14, "training_loss": 147.08154487609863, "training_acc": 77.66666666666667, "val_loss": 79.34487062692642, "val_acc": 32.0}
{"epoch": 15, "training_loss": 192.91369247436523, "training_acc": 69.0, "val_loss": 38.76540410518646, "val_acc": 77.33333333333333}
{"epoch": 16, "training_loss": 154.89807963371277, "training_acc": 77.33333333333333, "val_loss": 36.54116702079773, "val_acc": 80.0}
{"epoch": 17, "training_loss": 156.9330539703369, "training_acc": 75.33333333333333, "val_loss": 55.68164473772049, "val_acc": 40.0}
{"epoch": 18, "training_loss": 167.35453343391418, "training_acc": 70.33333333333333, "val_loss": 52.124712228775024, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 172.3809151649475, "training_acc": 74.0, "val_loss": 54.49961072206497, "val_acc": 52.0}
{"epoch": 20, "training_loss": 156.71645629405975, "training_acc": 73.0, "val_loss": 37.28408193588257, "val_acc": 76.0}
{"epoch": 21, "training_loss": 196.52086734771729, "training_acc": 67.66666666666667, "val_loss": 51.866937816143036, "val_acc": 52.0}
{"epoch": 22, "training_loss": 141.86854445934296, "training_acc": 73.66666666666667, "val_loss": 39.76563611626625, "val_acc": 80.0}
{"epoch": 23, "training_loss": 148.60989022254944, "training_acc": 78.33333333333333, "val_loss": 64.1217690706253, "val_acc": 44.0}
{"epoch": 24, "training_loss": 198.05059349536896, "training_acc": 67.66666666666667, "val_loss": 43.05446472764015, "val_acc": 76.0}
{"epoch": 25, "training_loss": 130.07752966880798, "training_acc": 80.0, "val_loss": 50.56416016817093, "val_acc": 53.333333333333336}
{"epoch": 26, "training_loss": 152.04610753059387, "training_acc": 76.66666666666667, "val_loss": 40.318818151950836, "val_acc": 77.33333333333333}
{"epoch": 27, "training_loss": 183.19840145111084, "training_acc": 71.0, "val_loss": 69.32865869998932, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 205.51477813720703, "training_acc": 74.33333333333333, "val_loss": 40.64051961898804, "val_acc": 78.66666666666667}
{"epoch": 29, "training_loss": 152.78245401382446, "training_acc": 74.66666666666667, "val_loss": 87.60277724266052, "val_acc": 33.333333333333336}
