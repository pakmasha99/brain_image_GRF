"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 422.4147186279297, "training_acc": 57.333333333333336, "val_loss": 45.57989585399628, "val_acc": 62.666666666666664}
{"epoch": 1, "training_loss": 323.03367948532104, "training_acc": 66.66666666666667, "val_loss": 61.44209632277489, "val_acc": 72.0}
{"epoch": 2, "training_loss": 240.70601558685303, "training_acc": 61.666666666666664, "val_loss": 52.606834292411804, "val_acc": 72.0}
{"epoch": 3, "training_loss": 218.8168535232544, "training_acc": 74.33333333333333, "val_loss": 41.29391002655029, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 183.6386125087738, "training_acc": 68.33333333333333, "val_loss": 61.519803553819656, "val_acc": 72.0}
{"epoch": 5, "training_loss": 205.54009199142456, "training_acc": 73.0, "val_loss": 41.63903945684433, "val_acc": 61.333333333333336}
{"epoch": 6, "training_loss": 162.39750576019287, "training_acc": 74.33333333333333, "val_loss": 41.85676693916321, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 163.52267599105835, "training_acc": 71.33333333333333, "val_loss": 37.28627383708954, "val_acc": 77.33333333333333}
{"epoch": 8, "training_loss": 160.7052903175354, "training_acc": 74.66666666666667, "val_loss": 36.99908399581909, "val_acc": 80.0}
{"epoch": 9, "training_loss": 153.5625672340393, "training_acc": 75.66666666666667, "val_loss": 39.3858847618103, "val_acc": 73.33333333333333}
{"epoch": 10, "training_loss": 160.988671541214, "training_acc": 73.0, "val_loss": 37.83097457885742, "val_acc": 78.66666666666667}
{"epoch": 11, "training_loss": 168.78636503219604, "training_acc": 71.66666666666667, "val_loss": 39.98176294565201, "val_acc": 74.66666666666667}
{"epoch": 12, "training_loss": 167.36398708820343, "training_acc": 70.66666666666667, "val_loss": 37.933682680130005, "val_acc": 80.0}
{"epoch": 13, "training_loss": 149.16861748695374, "training_acc": 77.33333333333333, "val_loss": 43.07651537656784, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 163.9339292049408, "training_acc": 71.66666666666667, "val_loss": 40.42228692770004, "val_acc": 69.33333333333333}
{"epoch": 15, "training_loss": 148.02752923965454, "training_acc": 78.33333333333333, "val_loss": 37.628335773944855, "val_acc": 76.0}
{"epoch": 16, "training_loss": 144.90157961845398, "training_acc": 76.0, "val_loss": 42.829129219055176, "val_acc": 72.0}
{"epoch": 17, "training_loss": 152.52259302139282, "training_acc": 76.66666666666667, "val_loss": 37.69374945759773, "val_acc": 78.66666666666667}
{"epoch": 18, "training_loss": 148.74286222457886, "training_acc": 76.66666666666667, "val_loss": 37.6520180106163, "val_acc": 80.0}
{"epoch": 19, "training_loss": 142.31413328647614, "training_acc": 76.0, "val_loss": 41.83446216583252, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 148.2638214826584, "training_acc": 77.0, "val_loss": 37.38383328914642, "val_acc": 78.66666666666667}
{"epoch": 21, "training_loss": 141.18892002105713, "training_acc": 77.0, "val_loss": 36.829739570617676, "val_acc": 80.0}
{"epoch": 22, "training_loss": 140.74087381362915, "training_acc": 78.0, "val_loss": 41.53735840320587, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 152.09352231025696, "training_acc": 73.0, "val_loss": 46.46654134988785, "val_acc": 72.0}
{"epoch": 24, "training_loss": 142.8309645652771, "training_acc": 76.33333333333333, "val_loss": 39.0782762914896, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 148.21005630493164, "training_acc": 73.66666666666667, "val_loss": 44.02533674240112, "val_acc": 60.0}
{"epoch": 26, "training_loss": 184.53566002845764, "training_acc": 70.0, "val_loss": 39.34110087156296, "val_acc": 77.33333333333333}
{"epoch": 27, "training_loss": 157.8832539319992, "training_acc": 73.0, "val_loss": 51.409752160310745, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 154.86237144470215, "training_acc": 75.0, "val_loss": 37.194338858127594, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 138.12215530872345, "training_acc": 77.0, "val_loss": 36.135726511478424, "val_acc": 82.66666666666667}
{"epoch": 30, "training_loss": 140.2307779788971, "training_acc": 78.66666666666667, "val_loss": 38.840424716472626, "val_acc": 69.33333333333333}
{"epoch": 31, "training_loss": 164.16020476818085, "training_acc": 72.0, "val_loss": 46.29886883497238, "val_acc": 58.666666666666664}
{"epoch": 32, "training_loss": 151.17648148536682, "training_acc": 77.0, "val_loss": 45.98277390003204, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 145.79929721355438, "training_acc": 78.66666666666667, "val_loss": 42.64899492263794, "val_acc": 73.33333333333333}
{"epoch": 34, "training_loss": 136.6426134109497, "training_acc": 79.0, "val_loss": 36.924412816762924, "val_acc": 81.33333333333333}
{"epoch": 35, "training_loss": 132.8258582353592, "training_acc": 79.0, "val_loss": 36.510564506053925, "val_acc": 80.0}
{"epoch": 36, "training_loss": 131.27085947990417, "training_acc": 80.33333333333333, "val_loss": 36.479600101709366, "val_acc": 78.66666666666667}
{"epoch": 37, "training_loss": 130.73311614990234, "training_acc": 80.33333333333333, "val_loss": 36.471633702516556, "val_acc": 81.33333333333333}
{"epoch": 38, "training_loss": 133.32568550109863, "training_acc": 80.0, "val_loss": 37.99645656347275, "val_acc": 78.66666666666667}
{"epoch": 39, "training_loss": 129.17486691474915, "training_acc": 80.0, "val_loss": 36.110587537288666, "val_acc": 81.33333333333333}
{"epoch": 40, "training_loss": 125.71864342689514, "training_acc": 82.0, "val_loss": 40.34215331077576, "val_acc": 74.66666666666667}
{"epoch": 41, "training_loss": 135.75956559181213, "training_acc": 79.66666666666667, "val_loss": 36.45462912321091, "val_acc": 81.33333333333333}
{"epoch": 42, "training_loss": 125.92498779296875, "training_acc": 82.66666666666667, "val_loss": 43.32121467590332, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 138.33026838302612, "training_acc": 75.66666666666667, "val_loss": 37.2713024020195, "val_acc": 80.0}
{"epoch": 44, "training_loss": 131.76280426979065, "training_acc": 81.0, "val_loss": 36.99911227822304, "val_acc": 80.0}
{"epoch": 45, "training_loss": 127.89550685882568, "training_acc": 80.66666666666667, "val_loss": 38.738417744636536, "val_acc": 80.0}
{"epoch": 46, "training_loss": 129.35672390460968, "training_acc": 81.33333333333333, "val_loss": 39.318956315517426, "val_acc": 81.33333333333333}
{"epoch": 47, "training_loss": 135.62804281711578, "training_acc": 76.0, "val_loss": 43.433897256851196, "val_acc": 73.33333333333333}
{"epoch": 48, "training_loss": 131.32160019874573, "training_acc": 77.0, "val_loss": 37.29996621608734, "val_acc": 77.33333333333333}
{"epoch": 49, "training_loss": 129.03802609443665, "training_acc": 80.66666666666667, "val_loss": 40.47781276702881, "val_acc": 61.333333333333336}
{"epoch": 50, "training_loss": 126.72997069358826, "training_acc": 81.33333333333333, "val_loss": 38.63857817649841, "val_acc": 78.66666666666667}
{"epoch": 51, "training_loss": 132.26584887504578, "training_acc": 78.0, "val_loss": 48.60357400774956, "val_acc": 73.33333333333333}
{"epoch": 52, "training_loss": 144.67286217212677, "training_acc": 76.66666666666667, "val_loss": 46.462110579013824, "val_acc": 74.66666666666667}
{"epoch": 53, "training_loss": 153.29630088806152, "training_acc": 75.0, "val_loss": 39.813177317380905, "val_acc": 78.66666666666667}
{"epoch": 54, "training_loss": 138.68713521957397, "training_acc": 77.0, "val_loss": 44.50951021909714, "val_acc": 61.333333333333336}
{"epoch": 55, "training_loss": 159.32615852355957, "training_acc": 76.66666666666667, "val_loss": 37.613388538360596, "val_acc": 72.0}
{"epoch": 56, "training_loss": 133.5539722442627, "training_acc": 78.33333333333333, "val_loss": 36.47957754135132, "val_acc": 82.66666666666667}
{"epoch": 57, "training_loss": 124.42156851291656, "training_acc": 83.33333333333333, "val_loss": 40.00423729419708, "val_acc": 76.0}
{"epoch": 58, "training_loss": 145.09952569007874, "training_acc": 77.0, "val_loss": 40.18731930851936, "val_acc": 77.33333333333333}
