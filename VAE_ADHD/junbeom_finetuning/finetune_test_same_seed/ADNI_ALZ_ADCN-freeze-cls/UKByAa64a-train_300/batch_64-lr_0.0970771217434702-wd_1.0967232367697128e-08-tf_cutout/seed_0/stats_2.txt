"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 589.5417728424072, "training_acc": 63.0, "val_loss": 47.7072856426239, "val_acc": 68.0}
{"epoch": 1, "training_loss": 311.31932067871094, "training_acc": 70.66666666666667, "val_loss": 73.04041540622711, "val_acc": 48.0}
{"epoch": 2, "training_loss": 254.34521579742432, "training_acc": 71.0, "val_loss": 73.27689528465271, "val_acc": 72.0}
{"epoch": 3, "training_loss": 206.608744263649, "training_acc": 70.0, "val_loss": 68.24506950378418, "val_acc": 72.0}
{"epoch": 4, "training_loss": 208.1739103794098, "training_acc": 71.0, "val_loss": 58.30213022232056, "val_acc": 49.333333333333336}
{"epoch": 5, "training_loss": 175.0237216949463, "training_acc": 71.0, "val_loss": 51.76450675725937, "val_acc": 60.0}
{"epoch": 6, "training_loss": 160.94289243221283, "training_acc": 73.66666666666667, "val_loss": 52.84811007976532, "val_acc": 65.33333333333333}
{"epoch": 7, "training_loss": 154.1206018924713, "training_acc": 73.66666666666667, "val_loss": 46.472454369068146, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 150.76880836486816, "training_acc": 74.0, "val_loss": 44.035407185554504, "val_acc": 68.0}
{"epoch": 9, "training_loss": 156.92742109298706, "training_acc": 76.0, "val_loss": 45.83063071966171, "val_acc": 60.0}
{"epoch": 10, "training_loss": 151.91475820541382, "training_acc": 75.33333333333333, "val_loss": 46.4133580327034, "val_acc": 60.0}
{"epoch": 11, "training_loss": 140.82946264743805, "training_acc": 80.0, "val_loss": 43.33740872144699, "val_acc": 72.0}
{"epoch": 12, "training_loss": 142.04107916355133, "training_acc": 78.0, "val_loss": 44.71185219287872, "val_acc": 66.66666666666667}
{"epoch": 13, "training_loss": 147.35338377952576, "training_acc": 72.66666666666667, "val_loss": 50.14152657985687, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 143.7537614107132, "training_acc": 78.0, "val_loss": 50.90212345123291, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 165.86541223526, "training_acc": 73.66666666666667, "val_loss": 43.55358308553696, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 152.1593577861786, "training_acc": 76.33333333333333, "val_loss": 50.2006356716156, "val_acc": 52.0}
{"epoch": 17, "training_loss": 153.09603571891785, "training_acc": 75.33333333333333, "val_loss": 46.17308175563812, "val_acc": 56.0}
{"epoch": 18, "training_loss": 145.85637485980988, "training_acc": 77.66666666666667, "val_loss": 58.32539415359497, "val_acc": 45.333333333333336}
{"epoch": 19, "training_loss": 149.54899418354034, "training_acc": 74.66666666666667, "val_loss": 45.533258974552155, "val_acc": 65.33333333333333}
{"epoch": 20, "training_loss": 137.46164107322693, "training_acc": 78.66666666666667, "val_loss": 44.589457631111145, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 134.40132987499237, "training_acc": 79.33333333333333, "val_loss": 41.85729318857193, "val_acc": 77.33333333333333}
{"epoch": 22, "training_loss": 133.827299118042, "training_acc": 82.0, "val_loss": 42.19910168647766, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 137.276784658432, "training_acc": 78.33333333333333, "val_loss": 43.58611509203911, "val_acc": 68.0}
{"epoch": 24, "training_loss": 135.5644073486328, "training_acc": 78.66666666666667, "val_loss": 41.71157795190811, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 130.0972205400467, "training_acc": 82.0, "val_loss": 40.91049116849899, "val_acc": 68.0}
{"epoch": 26, "training_loss": 139.1434885263443, "training_acc": 77.33333333333333, "val_loss": 43.17275446653366, "val_acc": 64.0}
{"epoch": 27, "training_loss": 138.6018432378769, "training_acc": 79.66666666666667, "val_loss": 42.67226415872574, "val_acc": 65.33333333333333}
{"epoch": 28, "training_loss": 126.3791698217392, "training_acc": 81.33333333333333, "val_loss": 41.25835186243057, "val_acc": 65.33333333333333}
{"epoch": 29, "training_loss": 123.74018275737762, "training_acc": 82.0, "val_loss": 41.00841677188873, "val_acc": 76.0}
{"epoch": 30, "training_loss": 124.8461629152298, "training_acc": 79.33333333333333, "val_loss": 42.351736545562744, "val_acc": 77.33333333333333}
{"epoch": 31, "training_loss": 138.41561579704285, "training_acc": 75.66666666666667, "val_loss": 47.405454993247986, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 156.8806849718094, "training_acc": 75.33333333333333, "val_loss": 50.066422045230865, "val_acc": 74.66666666666667}
{"epoch": 33, "training_loss": 150.32300102710724, "training_acc": 76.0, "val_loss": 46.316563814878464, "val_acc": 74.66666666666667}
{"epoch": 34, "training_loss": 141.5867086648941, "training_acc": 77.0, "val_loss": 47.55071932077408, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 134.93859767913818, "training_acc": 78.0, "val_loss": 45.92621999979019, "val_acc": 76.0}
{"epoch": 36, "training_loss": 123.00349426269531, "training_acc": 79.33333333333333, "val_loss": 64.28426396846771, "val_acc": 72.0}
{"epoch": 37, "training_loss": 165.7020492553711, "training_acc": 74.33333333333333, "val_loss": 59.34836387634277, "val_acc": 74.66666666666667}
{"epoch": 38, "training_loss": 157.31456899642944, "training_acc": 73.66666666666667, "val_loss": 48.55839192867279, "val_acc": 72.0}
{"epoch": 39, "training_loss": 153.20196449756622, "training_acc": 77.66666666666667, "val_loss": 45.65268176794052, "val_acc": 68.0}
{"epoch": 40, "training_loss": 112.92871725559235, "training_acc": 83.0, "val_loss": 42.676652669906616, "val_acc": 66.66666666666667}
{"epoch": 41, "training_loss": 125.20641779899597, "training_acc": 80.66666666666667, "val_loss": 41.83842372894287, "val_acc": 69.33333333333333}
{"epoch": 42, "training_loss": 118.26331734657288, "training_acc": 82.33333333333333, "val_loss": 44.00035095214844, "val_acc": 65.33333333333333}
{"epoch": 43, "training_loss": 114.83174848556519, "training_acc": 84.66666666666667, "val_loss": 49.88266408443451, "val_acc": 74.66666666666667}
{"epoch": 44, "training_loss": 135.38039588928223, "training_acc": 77.0, "val_loss": 42.55513668060303, "val_acc": 74.66666666666667}
