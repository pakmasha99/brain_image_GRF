"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 17204.914680480957, "training_acc": 64.66666666666667, "val_loss": 3687.337516784668, "val_acc": 28.0}
{"epoch": 1, "training_loss": 9428.331367492676, "training_acc": 64.66666666666667, "val_loss": 1896.787857055664, "val_acc": 70.66666666666667}
{"epoch": 2, "training_loss": 5752.327415466309, "training_acc": 64.0, "val_loss": 1774.5911140441895, "val_acc": 70.66666666666667}
{"epoch": 3, "training_loss": 6672.385177612305, "training_acc": 72.33333333333333, "val_loss": 853.4751238822937, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 4255.7686767578125, "training_acc": 66.33333333333333, "val_loss": 880.89475440979, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3319.8429412841797, "training_acc": 59.333333333333336, "val_loss": 1360.306830406189, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4038.9922828674316, "training_acc": 58.0, "val_loss": 1641.9271717071533, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5440.864608764648, "training_acc": 65.33333333333333, "val_loss": 593.2563798427582, "val_acc": 69.33333333333333}
{"epoch": 8, "training_loss": 3520.838670730591, "training_acc": 69.0, "val_loss": 525.2578845024109, "val_acc": 77.33333333333333}
{"epoch": 9, "training_loss": 2831.8745727539062, "training_acc": 65.33333333333333, "val_loss": 678.5709886550903, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2549.311347961426, "training_acc": 64.33333333333333, "val_loss": 1084.686050415039, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3065.851921081543, "training_acc": 58.0, "val_loss": 1661.140058517456, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5203.866790771484, "training_acc": 67.66666666666667, "val_loss": 1004.835729598999, "val_acc": 53.333333333333336}
{"epoch": 13, "training_loss": 4859.307395935059, "training_acc": 65.0, "val_loss": 987.8080596923828, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 4910.153652191162, "training_acc": 61.333333333333336, "val_loss": 1530.6134948730469, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 4710.7836265563965, "training_acc": 71.0, "val_loss": 768.7906522750854, "val_acc": 70.66666666666667}
{"epoch": 16, "training_loss": 2769.7580375671387, "training_acc": 73.66666666666667, "val_loss": 618.705536365509, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 1935.1533012390137, "training_acc": 64.33333333333333, "val_loss": 264.07990646362305, "val_acc": 68.0}
{"epoch": 18, "training_loss": 3128.532985687256, "training_acc": 60.333333333333336, "val_loss": 1463.5747184753418, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3323.5486793518066, "training_acc": 66.33333333333333, "val_loss": 656.3669176101685, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2052.7255268096924, "training_acc": 73.33333333333333, "val_loss": 436.7322215256281, "val_acc": 77.33333333333333}
{"epoch": 21, "training_loss": 1310.7961626052856, "training_acc": 71.33333333333333, "val_loss": 236.52909994125366, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1083.8644104003906, "training_acc": 68.33333333333333, "val_loss": 631.253716468811, "val_acc": 45.333333333333336}
{"epoch": 23, "training_loss": 1010.0453472137451, "training_acc": 71.66666666666667, "val_loss": 247.49756050109863, "val_acc": 84.0}
{"epoch": 24, "training_loss": 897.8752965927124, "training_acc": 74.66666666666667, "val_loss": 227.93709802627563, "val_acc": 81.33333333333333}
{"epoch": 25, "training_loss": 627.6953897476196, "training_acc": 75.33333333333333, "val_loss": 186.36302983760834, "val_acc": 81.33333333333333}
{"epoch": 26, "training_loss": 472.3717999458313, "training_acc": 77.33333333333333, "val_loss": 219.9282249212265, "val_acc": 74.66666666666667}
{"epoch": 27, "training_loss": 851.8982763290405, "training_acc": 72.0, "val_loss": 632.2145948410034, "val_acc": 44.0}
{"epoch": 28, "training_loss": 1058.951509475708, "training_acc": 65.0, "val_loss": 288.4189553260803, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 939.7601280212402, "training_acc": 76.0, "val_loss": 615.0703210830688, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2492.9100155830383, "training_acc": 66.0, "val_loss": 832.6739959716797, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2920.945059776306, "training_acc": 66.0, "val_loss": 339.6976935863495, "val_acc": 74.66666666666667}
{"epoch": 32, "training_loss": 2048.1327590942383, "training_acc": 67.66666666666667, "val_loss": 707.1773920059204, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2170.6130981445312, "training_acc": 67.33333333333333, "val_loss": 856.4829721450806, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2901.4005393981934, "training_acc": 72.66666666666667, "val_loss": 247.24981689453125, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 2247.659887313843, "training_acc": 72.0, "val_loss": 1163.6451499462128, "val_acc": 36.0}
{"epoch": 36, "training_loss": 3322.825412750244, "training_acc": 63.666666666666664, "val_loss": 629.6521482467651, "val_acc": 57.333333333333336}
{"epoch": 37, "training_loss": 3408.1129417419434, "training_acc": 61.666666666666664, "val_loss": 621.7787952423096, "val_acc": 73.33333333333333}
{"epoch": 38, "training_loss": 1840.1836462020874, "training_acc": 70.66666666666667, "val_loss": 941.3389434814453, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1403.4463102817535, "training_acc": 76.0, "val_loss": 307.36124217510223, "val_acc": 74.66666666666667}
{"epoch": 40, "training_loss": 969.6033630371094, "training_acc": 74.33333333333333, "val_loss": 397.5842595100403, "val_acc": 57.333333333333336}
{"epoch": 41, "training_loss": 904.8977384567261, "training_acc": 73.66666666666667, "val_loss": 313.82030296325684, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1095.52170753479, "training_acc": 70.66666666666667, "val_loss": 308.3450336456299, "val_acc": 76.0}
{"epoch": 43, "training_loss": 1337.222993850708, "training_acc": 73.0, "val_loss": 638.6914758682251, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1545.335618019104, "training_acc": 74.33333333333333, "val_loss": 357.2329249382019, "val_acc": 76.0}
