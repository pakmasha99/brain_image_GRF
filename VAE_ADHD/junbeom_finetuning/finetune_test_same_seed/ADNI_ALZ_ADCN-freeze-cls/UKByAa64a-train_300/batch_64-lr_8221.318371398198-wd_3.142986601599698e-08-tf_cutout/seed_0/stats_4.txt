"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65167478.59259415, "training_acc": 65.0, "val_loss": 16319359.34375, "val_acc": 28.0}
{"epoch": 1, "training_loss": 46353596.4375, "training_acc": 62.333333333333336, "val_loss": 12662894.9375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 31549594.4375, "training_acc": 59.0, "val_loss": 2840817.70703125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 26678673.28125, "training_acc": 66.33333333333333, "val_loss": 7082079.28125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 14569365.46875, "training_acc": 72.0, "val_loss": 2870684.637939453, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 11793375.2890625, "training_acc": 68.33333333333333, "val_loss": 2660812.8203125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 7837146.875, "training_acc": 64.66666666666667, "val_loss": 855517.1064453125, "val_acc": 69.33333333333333}
{"epoch": 7, "training_loss": 4849515.3203125, "training_acc": 61.333333333333336, "val_loss": 1526755.46875, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8824759.87890625, "training_acc": 62.666666666666664, "val_loss": 2274694.63671875, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 6100046.455078125, "training_acc": 69.33333333333333, "val_loss": 1155176.0673828125, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2215297.703125, "training_acc": 72.33333333333333, "val_loss": 3331980.5078125, "val_acc": 33.333333333333336}
{"epoch": 11, "training_loss": 7343474.734375, "training_acc": 62.666666666666664, "val_loss": 565852.8168945312, "val_acc": 62.666666666666664}
{"epoch": 12, "training_loss": 3510727.1015625, "training_acc": 69.0, "val_loss": 1349388.71484375, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2367384.2890625, "training_acc": 75.33333333333333, "val_loss": 660717.6489257812, "val_acc": 74.66666666666667}
{"epoch": 14, "training_loss": 2477116.212890625, "training_acc": 71.33333333333333, "val_loss": 1186499.388671875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3468067.8125, "training_acc": 66.33333333333333, "val_loss": 2028634.158203125, "val_acc": 72.0}
{"epoch": 16, "training_loss": 7390880.6171875, "training_acc": 67.66666666666667, "val_loss": 2187050.6953125, "val_acc": 72.0}
{"epoch": 17, "training_loss": 6937990.6640625, "training_acc": 67.0, "val_loss": 1291400.759765625, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3909247.1171875, "training_acc": 70.66666666666667, "val_loss": 921948.794921875, "val_acc": 58.666666666666664}
{"epoch": 19, "training_loss": 2548637.4921875, "training_acc": 68.33333333333333, "val_loss": 1063768.197265625, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3983841.7265625, "training_acc": 69.66666666666667, "val_loss": 1650511.0, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2836829.1796875, "training_acc": 77.33333333333333, "val_loss": 571261.1762084961, "val_acc": 80.0}
{"epoch": 22, "training_loss": 1302981.67578125, "training_acc": 78.33333333333333, "val_loss": 1873276.060546875, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4006690.75, "training_acc": 71.66666666666667, "val_loss": 945696.2568359375, "val_acc": 57.333333333333336}
{"epoch": 24, "training_loss": 2304923.029296875, "training_acc": 76.33333333333333, "val_loss": 616235.0961914062, "val_acc": 81.33333333333333}
{"epoch": 25, "training_loss": 2694296.5078125, "training_acc": 73.0, "val_loss": 3018230.3671875, "val_acc": 72.0}
{"epoch": 26, "training_loss": 7509586.7109375, "training_acc": 64.66666666666667, "val_loss": 989637.880859375, "val_acc": 61.333333333333336}
{"epoch": 27, "training_loss": 3675029.8212890625, "training_acc": 76.0, "val_loss": 1738734.052734375, "val_acc": 56.0}
{"epoch": 28, "training_loss": 6263912.609375, "training_acc": 65.66666666666667, "val_loss": 1157197.294921875, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 4273756.68359375, "training_acc": 68.33333333333333, "val_loss": 1294242.9609375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3071849.7861328125, "training_acc": 71.66666666666667, "val_loss": 1051609.189453125, "val_acc": 60.0}
