"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 55866075.76750946, "training_acc": 64.33333333333333, "val_loss": 20201653.5625, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 47991559.9375, "training_acc": 61.666666666666664, "val_loss": 16322520.1875, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 42327614.71875, "training_acc": 67.33333333333333, "val_loss": 8667683.2890625, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 23728064.34375, "training_acc": 64.33333333333333, "val_loss": 6670201.765625, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 23662921.28125, "training_acc": 74.66666666666667, "val_loss": 5511659.25, "val_acc": 44.0}
{"epoch": 5, "training_loss": 17165743.03125, "training_acc": 62.0, "val_loss": 1654308.001953125, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 11314085.71875, "training_acc": 59.666666666666664, "val_loss": 4490068.03515625, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 12194877.859375, "training_acc": 63.333333333333336, "val_loss": 3001333.875, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 14245042.578125, "training_acc": 68.0, "val_loss": 3601609.2890625, "val_acc": 45.333333333333336}
{"epoch": 9, "training_loss": 14401018.38671875, "training_acc": 61.666666666666664, "val_loss": 2157218.650390625, "val_acc": 64.0}
{"epoch": 10, "training_loss": 8857382.640625, "training_acc": 64.0, "val_loss": 1134915.3525390625, "val_acc": 76.0}
{"epoch": 11, "training_loss": 7068701.8828125, "training_acc": 67.33333333333333, "val_loss": 788389.8818359375, "val_acc": 66.66666666666667}
{"epoch": 12, "training_loss": 7724352.921875, "training_acc": 65.0, "val_loss": 806599.443359375, "val_acc": 61.333333333333336}
{"epoch": 13, "training_loss": 4730264.8203125, "training_acc": 63.333333333333336, "val_loss": 779465.10546875, "val_acc": 66.66666666666667}
{"epoch": 14, "training_loss": 3581717.6796875, "training_acc": 69.0, "val_loss": 1230492.0, "val_acc": 73.33333333333333}
{"epoch": 15, "training_loss": 4953568.09375, "training_acc": 69.66666666666667, "val_loss": 1455731.859375, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 4829816.90234375, "training_acc": 69.66666666666667, "val_loss": 1903919.6328125, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 6927778.5625, "training_acc": 63.666666666666664, "val_loss": 337038.15625, "val_acc": 84.0}
{"epoch": 18, "training_loss": 4719561.0, "training_acc": 67.66666666666667, "val_loss": 1566331.6875, "val_acc": 56.0}
{"epoch": 19, "training_loss": 6203313.9921875, "training_acc": 64.66666666666667, "val_loss": 1211322.296875, "val_acc": 64.0}
{"epoch": 20, "training_loss": 6873753.453125, "training_acc": 65.66666666666667, "val_loss": 670305.919921875, "val_acc": 81.33333333333333}
{"epoch": 21, "training_loss": 3381563.9609375, "training_acc": 75.33333333333333, "val_loss": 406643.9460449219, "val_acc": 76.0}
{"epoch": 22, "training_loss": 2990984.57421875, "training_acc": 71.33333333333333, "val_loss": 965963.6259765625, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 2195905.9755859375, "training_acc": 75.0, "val_loss": 410795.73181152344, "val_acc": 65.33333333333333}
{"epoch": 24, "training_loss": 933229.5078125, "training_acc": 82.33333333333333, "val_loss": 201191.06274414062, "val_acc": 84.0}
{"epoch": 25, "training_loss": 2216672.109375, "training_acc": 75.66666666666667, "val_loss": 1005129.314453125, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 1533622.4951171875, "training_acc": 79.0, "val_loss": 236758.44165039062, "val_acc": 68.0}
{"epoch": 27, "training_loss": 3324838.419921875, "training_acc": 70.66666666666667, "val_loss": 191406.921875, "val_acc": 89.33333333333333}
{"epoch": 28, "training_loss": 3241588.5625, "training_acc": 66.0, "val_loss": 634334.9609375, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 4047796.603515625, "training_acc": 73.33333333333333, "val_loss": 1352219.97265625, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 6495416.3046875, "training_acc": 67.66666666666667, "val_loss": 1815846.412109375, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 4877012.96875, "training_acc": 68.66666666666667, "val_loss": 1163994.96484375, "val_acc": 61.333333333333336}
{"epoch": 32, "training_loss": 5440721.63671875, "training_acc": 63.666666666666664, "val_loss": 701158.5078125, "val_acc": 66.66666666666667}
{"epoch": 33, "training_loss": 3528981.515625, "training_acc": 70.0, "val_loss": 672061.2155761719, "val_acc": 74.66666666666667}
{"epoch": 34, "training_loss": 1677078.203125, "training_acc": 74.0, "val_loss": 1253699.7346191406, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 4553159.40625, "training_acc": 66.66666666666667, "val_loss": 390185.2919921875, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 2481990.73046875, "training_acc": 72.0, "val_loss": 1185002.76171875, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 5205161.9921875, "training_acc": 68.33333333333333, "val_loss": 1257890.30859375, "val_acc": 73.33333333333333}
{"epoch": 38, "training_loss": 3089969.0048828125, "training_acc": 73.66666666666667, "val_loss": 275074.97314453125, "val_acc": 84.0}
{"epoch": 39, "training_loss": 1940778.9453125, "training_acc": 74.66666666666667, "val_loss": 1554444.25, "val_acc": 73.33333333333333}
{"epoch": 40, "training_loss": 6324800.375, "training_acc": 67.0, "val_loss": 1761118.52734375, "val_acc": 73.33333333333333}
{"epoch": 41, "training_loss": 5378952.0234375, "training_acc": 68.33333333333333, "val_loss": 2318352.255859375, "val_acc": 73.33333333333333}
{"epoch": 42, "training_loss": 5498596.501953125, "training_acc": 72.0, "val_loss": 1563504.203125, "val_acc": 73.33333333333333}
{"epoch": 43, "training_loss": 3432805.34375, "training_acc": 70.66666666666667, "val_loss": 528617.6884765625, "val_acc": 68.0}
{"epoch": 44, "training_loss": 1231217.0693359375, "training_acc": 79.0, "val_loss": 291176.6571044922, "val_acc": 73.33333333333333}
{"epoch": 45, "training_loss": 1305444.1005859375, "training_acc": 77.66666666666667, "val_loss": 491391.466796875, "val_acc": 74.66666666666667}
{"epoch": 46, "training_loss": 1679031.921875, "training_acc": 78.0, "val_loss": 358053.73376464844, "val_acc": 80.0}
