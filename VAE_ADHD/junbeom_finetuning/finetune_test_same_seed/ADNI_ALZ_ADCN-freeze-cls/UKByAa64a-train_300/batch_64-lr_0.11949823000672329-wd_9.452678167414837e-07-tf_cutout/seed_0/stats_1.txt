"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 807.3513240814209, "training_acc": 65.33333333333333, "val_loss": 224.39943647384644, "val_acc": 28.0}
{"epoch": 1, "training_loss": 657.4110431671143, "training_acc": 64.0, "val_loss": 174.4858419895172, "val_acc": 72.0}
{"epoch": 2, "training_loss": 446.9790153503418, "training_acc": 63.666666666666664, "val_loss": 138.80971121788025, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 508.271541595459, "training_acc": 69.0, "val_loss": 161.8348410129547, "val_acc": 69.33333333333333}
{"epoch": 4, "training_loss": 340.4917206764221, "training_acc": 72.33333333333333, "val_loss": 118.54733490943909, "val_acc": 54.666666666666664}
{"epoch": 5, "training_loss": 253.8459403514862, "training_acc": 73.66666666666667, "val_loss": 91.04606354236603, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 203.47926712036133, "training_acc": 73.33333333333333, "val_loss": 60.12466722726822, "val_acc": 64.0}
{"epoch": 7, "training_loss": 163.9957093000412, "training_acc": 76.33333333333333, "val_loss": 61.829077303409576, "val_acc": 52.0}
{"epoch": 8, "training_loss": 191.6290364265442, "training_acc": 69.66666666666667, "val_loss": 62.5108882188797, "val_acc": 49.333333333333336}
{"epoch": 9, "training_loss": 215.96788001060486, "training_acc": 66.66666666666667, "val_loss": 51.18751257658005, "val_acc": 64.0}
{"epoch": 10, "training_loss": 205.02824592590332, "training_acc": 67.0, "val_loss": 76.0053848028183, "val_acc": 70.66666666666667}
{"epoch": 11, "training_loss": 218.01029062271118, "training_acc": 68.33333333333333, "val_loss": 60.230733156204224, "val_acc": 69.33333333333333}
{"epoch": 12, "training_loss": 191.73651504516602, "training_acc": 67.0, "val_loss": 47.0084844827652, "val_acc": 73.33333333333333}
{"epoch": 13, "training_loss": 184.80432772636414, "training_acc": 71.0, "val_loss": 47.95441097021103, "val_acc": 66.66666666666667}
{"epoch": 14, "training_loss": 151.31362962722778, "training_acc": 77.0, "val_loss": 73.47272145748138, "val_acc": 46.666666666666664}
{"epoch": 15, "training_loss": 184.5206573009491, "training_acc": 70.66666666666667, "val_loss": 55.97384935617447, "val_acc": 61.333333333333336}
{"epoch": 16, "training_loss": 145.97908508777618, "training_acc": 75.66666666666667, "val_loss": 50.81154879927635, "val_acc": 70.66666666666667}
{"epoch": 17, "training_loss": 138.52191638946533, "training_acc": 77.0, "val_loss": 45.1452180147171, "val_acc": 74.66666666666667}
{"epoch": 18, "training_loss": 145.76981055736542, "training_acc": 76.66666666666667, "val_loss": 45.09266412258148, "val_acc": 65.33333333333333}
{"epoch": 19, "training_loss": 156.38084506988525, "training_acc": 76.0, "val_loss": 50.68149049580097, "val_acc": 73.33333333333333}
{"epoch": 20, "training_loss": 136.83836197853088, "training_acc": 79.0, "val_loss": 51.70138704776764, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 141.89435493946075, "training_acc": 79.0, "val_loss": 48.08842760324478, "val_acc": 72.0}
{"epoch": 22, "training_loss": 155.94031691551208, "training_acc": 74.66666666666667, "val_loss": 49.06909191608429, "val_acc": 72.0}
{"epoch": 23, "training_loss": 148.6829969882965, "training_acc": 73.66666666666667, "val_loss": 61.00826597213745, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 157.2216761112213, "training_acc": 76.66666666666667, "val_loss": 56.50810444355011, "val_acc": 72.0}
{"epoch": 25, "training_loss": 144.350630402565, "training_acc": 78.0, "val_loss": 50.77973932027817, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 144.21194660663605, "training_acc": 78.0, "val_loss": 49.54917198419571, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 141.77402222156525, "training_acc": 75.66666666666667, "val_loss": 54.58778774738312, "val_acc": 72.0}
{"epoch": 28, "training_loss": 155.93703866004944, "training_acc": 73.0, "val_loss": 54.148865699768066, "val_acc": 66.66666666666667}
{"epoch": 29, "training_loss": 166.70318937301636, "training_acc": 75.66666666666667, "val_loss": 65.67718264460564, "val_acc": 57.333333333333336}
{"epoch": 30, "training_loss": 148.79031467437744, "training_acc": 75.66666666666667, "val_loss": 64.9222241640091, "val_acc": 56.0}
{"epoch": 31, "training_loss": 189.30021679401398, "training_acc": 72.66666666666667, "val_loss": 66.16742128133774, "val_acc": 54.666666666666664}
{"epoch": 32, "training_loss": 156.2011914253235, "training_acc": 73.0, "val_loss": 50.83265474438667, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 127.33824145793915, "training_acc": 81.33333333333333, "val_loss": 46.92695516347885, "val_acc": 76.0}
{"epoch": 34, "training_loss": 122.78040027618408, "training_acc": 79.66666666666667, "val_loss": 46.63725298643112, "val_acc": 72.0}
{"epoch": 35, "training_loss": 125.44243276119232, "training_acc": 82.0, "val_loss": 48.8867307305336, "val_acc": 72.0}
{"epoch": 36, "training_loss": 121.48326253890991, "training_acc": 81.33333333333333, "val_loss": 46.9505780339241, "val_acc": 66.66666666666667}
{"epoch": 37, "training_loss": 149.311927318573, "training_acc": 78.0, "val_loss": 60.60242873430252, "val_acc": 57.333333333333336}
