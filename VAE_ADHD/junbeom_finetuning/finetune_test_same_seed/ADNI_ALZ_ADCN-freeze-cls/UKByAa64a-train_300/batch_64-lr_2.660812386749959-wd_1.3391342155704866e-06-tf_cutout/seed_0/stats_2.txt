"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 15205.618057250977, "training_acc": 67.66666666666667, "val_loss": 6218.787643432617, "val_acc": 28.0}
{"epoch": 1, "training_loss": 16006.132553100586, "training_acc": 64.0, "val_loss": 4730.921989440918, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9556.472152709961, "training_acc": 70.0, "val_loss": 2760.4309730529785, "val_acc": 48.0}
{"epoch": 3, "training_loss": 7337.6171875, "training_acc": 70.0, "val_loss": 2892.655029296875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6641.046287536621, "training_acc": 66.33333333333333, "val_loss": 1170.7856845855713, "val_acc": 70.66666666666667}
{"epoch": 5, "training_loss": 5097.425338745117, "training_acc": 72.33333333333333, "val_loss": 1037.0897846221924, "val_acc": 52.0}
{"epoch": 6, "training_loss": 4666.295631408691, "training_acc": 60.0, "val_loss": 1109.2394695281982, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2308.2632942199707, "training_acc": 68.33333333333333, "val_loss": 735.8796679973602, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 2348.9011840820312, "training_acc": 68.33333333333333, "val_loss": 1000.5066051483154, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1900.2346448898315, "training_acc": 74.0, "val_loss": 690.4006199836731, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1713.7049369812012, "training_acc": 68.66666666666667, "val_loss": 345.60288095474243, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 1743.2434692382812, "training_acc": 60.0, "val_loss": 448.35909509658813, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 1564.8779315948486, "training_acc": 69.33333333333333, "val_loss": 461.5106554031372, "val_acc": 69.33333333333333}
{"epoch": 13, "training_loss": 1112.454734802246, "training_acc": 75.0, "val_loss": 556.2548689842224, "val_acc": 48.0}
{"epoch": 14, "training_loss": 1131.0799474716187, "training_acc": 65.0, "val_loss": 393.310772895813, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1171.2966995239258, "training_acc": 68.33333333333333, "val_loss": 190.8298361301422, "val_acc": 70.66666666666667}
{"epoch": 16, "training_loss": 600.0536155700684, "training_acc": 79.33333333333333, "val_loss": 440.5426502227783, "val_acc": 37.333333333333336}
{"epoch": 17, "training_loss": 1727.4030199050903, "training_acc": 61.333333333333336, "val_loss": 604.6719408035278, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1320.1443004608154, "training_acc": 73.0, "val_loss": 572.3870792388916, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1243.4170506000519, "training_acc": 75.33333333333333, "val_loss": 219.64269161224365, "val_acc": 66.66666666666667}
{"epoch": 20, "training_loss": 1413.3692932128906, "training_acc": 68.66666666666667, "val_loss": 215.45599746704102, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 1359.4511041641235, "training_acc": 70.0, "val_loss": 682.4942193031311, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1742.9977283477783, "training_acc": 72.0, "val_loss": 776.4141426086426, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 1657.5311431884766, "training_acc": 73.33333333333333, "val_loss": 767.6449995040894, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2485.758590698242, "training_acc": 63.333333333333336, "val_loss": 255.35262846946716, "val_acc": 66.66666666666667}
{"epoch": 25, "training_loss": 1533.7487564086914, "training_acc": 71.66666666666667, "val_loss": 708.0817012786865, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1809.6278076171875, "training_acc": 72.0, "val_loss": 738.0820636749268, "val_acc": 53.333333333333336}
{"epoch": 27, "training_loss": 2580.478298187256, "training_acc": 67.66666666666667, "val_loss": 670.2432403564453, "val_acc": 56.0}
{"epoch": 28, "training_loss": 2050.7483139038086, "training_acc": 71.66666666666667, "val_loss": 521.5233068466187, "val_acc": 73.33333333333333}
{"epoch": 29, "training_loss": 2308.895481109619, "training_acc": 65.33333333333333, "val_loss": 877.440019607544, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1561.2963399887085, "training_acc": 73.66666666666667, "val_loss": 741.1996574401855, "val_acc": 74.66666666666667}
{"epoch": 31, "training_loss": 1107.3216562271118, "training_acc": 81.0, "val_loss": 307.78377985954285, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1245.950517654419, "training_acc": 71.66666666666667, "val_loss": 392.5801753997803, "val_acc": 74.66666666666667}
{"epoch": 33, "training_loss": 1200.6001300811768, "training_acc": 74.66666666666667, "val_loss": 284.29167222976685, "val_acc": 74.66666666666667}
{"epoch": 34, "training_loss": 1120.704698085785, "training_acc": 75.66666666666667, "val_loss": 611.3879435062408, "val_acc": 49.333333333333336}
