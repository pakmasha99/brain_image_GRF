"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18122.127586364746, "training_acc": 58.0, "val_loss": 2942.898307800293, "val_acc": 29.333333333333332}
{"epoch": 1, "training_loss": 13760.98861694336, "training_acc": 61.0, "val_loss": 2718.1816368103027, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9242.819953918457, "training_acc": 58.666666666666664, "val_loss": 1614.0820293426514, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8654.600128173828, "training_acc": 73.66666666666667, "val_loss": 1186.1673259735107, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 5196.787109375, "training_acc": 62.0, "val_loss": 1568.466438293457, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5775.005477905273, "training_acc": 67.0, "val_loss": 886.1843938827515, "val_acc": 45.333333333333336}
{"epoch": 6, "training_loss": 4148.952041625977, "training_acc": 65.66666666666667, "val_loss": 400.6768217086792, "val_acc": 64.0}
{"epoch": 7, "training_loss": 2544.1402893066406, "training_acc": 62.666666666666664, "val_loss": 285.66697549819946, "val_acc": 78.66666666666667}
{"epoch": 8, "training_loss": 2565.3859519958496, "training_acc": 63.666666666666664, "val_loss": 245.84221744537354, "val_acc": 66.66666666666667}
{"epoch": 9, "training_loss": 2412.5783081054688, "training_acc": 61.666666666666664, "val_loss": 277.36739921569824, "val_acc": 74.66666666666667}
{"epoch": 10, "training_loss": 1377.7700090408325, "training_acc": 68.33333333333333, "val_loss": 668.1230335235596, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2087.5687217712402, "training_acc": 58.333333333333336, "val_loss": 523.0882127285004, "val_acc": 70.66666666666667}
{"epoch": 12, "training_loss": 2013.5649223327637, "training_acc": 67.66666666666667, "val_loss": 552.1188659667969, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2169.959825515747, "training_acc": 69.33333333333333, "val_loss": 291.3346071243286, "val_acc": 76.0}
{"epoch": 14, "training_loss": 984.6473507881165, "training_acc": 71.0, "val_loss": 272.33899688720703, "val_acc": 74.66666666666667}
{"epoch": 15, "training_loss": 812.8534984588623, "training_acc": 71.0, "val_loss": 227.71100306510925, "val_acc": 74.66666666666667}
{"epoch": 16, "training_loss": 674.3539175987244, "training_acc": 77.66666666666667, "val_loss": 170.04094409942627, "val_acc": 78.66666666666667}
{"epoch": 17, "training_loss": 801.4242715835571, "training_acc": 71.0, "val_loss": 553.563720703125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1871.3780608177185, "training_acc": 67.0, "val_loss": 1045.1464910507202, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3537.3034057617188, "training_acc": 69.33333333333333, "val_loss": 369.06056928634644, "val_acc": 77.33333333333333}
{"epoch": 20, "training_loss": 1859.7947444915771, "training_acc": 73.0, "val_loss": 302.4872028827667, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 1155.061902999878, "training_acc": 67.0, "val_loss": 856.4114990234375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3453.18985748291, "training_acc": 63.333333333333336, "val_loss": 490.5201802253723, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 1773.947304725647, "training_acc": 75.33333333333333, "val_loss": 310.85348892211914, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1734.0975036621094, "training_acc": 68.66666666666667, "val_loss": 237.30572080612183, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1450.5299091339111, "training_acc": 71.33333333333333, "val_loss": 235.07915019989014, "val_acc": 80.0}
{"epoch": 26, "training_loss": 736.7982831001282, "training_acc": 76.0, "val_loss": 162.7452073097229, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 736.809850692749, "training_acc": 70.66666666666667, "val_loss": 321.2688217163086, "val_acc": 72.0}
{"epoch": 28, "training_loss": 746.4809131622314, "training_acc": 74.66666666666667, "val_loss": 552.9962872266769, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1338.005760192871, "training_acc": 71.0, "val_loss": 336.89719462394714, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 1298.7539367675781, "training_acc": 68.33333333333333, "val_loss": 826.6502733230591, "val_acc": 38.666666666666664}
{"epoch": 31, "training_loss": 1660.6188402175903, "training_acc": 69.0, "val_loss": 175.29181098937988, "val_acc": 73.33333333333333}
{"epoch": 32, "training_loss": 776.1977987289429, "training_acc": 76.0, "val_loss": 221.3374718427658, "val_acc": 77.33333333333333}
{"epoch": 33, "training_loss": 958.5032911300659, "training_acc": 68.0, "val_loss": 472.1095552444458, "val_acc": 70.66666666666667}
{"epoch": 34, "training_loss": 1111.7581901550293, "training_acc": 74.0, "val_loss": 469.2052800655365, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 801.674026966095, "training_acc": 77.0, "val_loss": 320.09778118133545, "val_acc": 57.333333333333336}
{"epoch": 36, "training_loss": 565.7397203445435, "training_acc": 75.66666666666667, "val_loss": 327.9513168334961, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1101.0436942577362, "training_acc": 68.0, "val_loss": 190.59819960594177, "val_acc": 77.33333333333333}
{"epoch": 38, "training_loss": 763.1384510993958, "training_acc": 77.0, "val_loss": 334.12211751937866, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 730.0395679473877, "training_acc": 75.66666666666667, "val_loss": 148.37899374961853, "val_acc": 74.66666666666667}
{"epoch": 40, "training_loss": 322.21577167510986, "training_acc": 82.0, "val_loss": 207.30360198020935, "val_acc": 62.666666666666664}
{"epoch": 41, "training_loss": 701.5421371459961, "training_acc": 72.66666666666667, "val_loss": 222.29412841796875, "val_acc": 78.66666666666667}
{"epoch": 42, "training_loss": 653.4557209014893, "training_acc": 80.0, "val_loss": 234.66764545440674, "val_acc": 72.0}
{"epoch": 43, "training_loss": 589.2395753860474, "training_acc": 76.66666666666667, "val_loss": 220.244526386261, "val_acc": 78.66666666666667}
{"epoch": 44, "training_loss": 606.6786231994629, "training_acc": 80.0, "val_loss": 939.2161312103271, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1862.9488334655762, "training_acc": 69.33333333333333, "val_loss": 237.49177169799805, "val_acc": 76.0}
{"epoch": 46, "training_loss": 1831.2161827087402, "training_acc": 70.66666666666667, "val_loss": 667.7487525939941, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1756.925193786621, "training_acc": 70.0, "val_loss": 508.4335207939148, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1013.0470323562622, "training_acc": 74.66666666666667, "val_loss": 293.99706983566284, "val_acc": 61.333333333333336}
{"epoch": 49, "training_loss": 1215.2140350341797, "training_acc": 70.33333333333333, "val_loss": 268.7202641963959, "val_acc": 74.66666666666667}
{"epoch": 50, "training_loss": 1131.612693786621, "training_acc": 76.0, "val_loss": 380.9154853820801, "val_acc": 74.66666666666667}
{"epoch": 51, "training_loss": 735.5673166513443, "training_acc": 78.66666666666667, "val_loss": 148.7080307006836, "val_acc": 82.66666666666667}
{"epoch": 52, "training_loss": 634.3827056884766, "training_acc": 74.66666666666667, "val_loss": 769.0408358573914, "val_acc": 72.0}
{"epoch": 53, "training_loss": 2826.9239616394043, "training_acc": 70.33333333333333, "val_loss": 518.6939735412598, "val_acc": 70.66666666666667}
{"epoch": 54, "training_loss": 1878.5351600646973, "training_acc": 70.0, "val_loss": 571.4809942245483, "val_acc": 73.33333333333333}
{"epoch": 55, "training_loss": 1731.845302581787, "training_acc": 72.66666666666667, "val_loss": 649.4132251739502, "val_acc": 70.66666666666667}
{"epoch": 56, "training_loss": 2495.3639221191406, "training_acc": 66.66666666666667, "val_loss": 772.6005992889404, "val_acc": 72.0}
{"epoch": 57, "training_loss": 2701.9053769111633, "training_acc": 67.0, "val_loss": 432.92518854141235, "val_acc": 74.66666666666667}
{"epoch": 58, "training_loss": 2159.9316453933716, "training_acc": 65.66666666666667, "val_loss": 783.3030138015747, "val_acc": 70.66666666666667}
