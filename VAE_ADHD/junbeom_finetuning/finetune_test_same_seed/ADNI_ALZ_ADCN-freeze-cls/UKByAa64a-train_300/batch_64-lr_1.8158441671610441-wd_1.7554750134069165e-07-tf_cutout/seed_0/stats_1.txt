"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14402.420997619629, "training_acc": 67.66666666666667, "val_loss": 6553.371871948242, "val_acc": 28.0}
{"epoch": 1, "training_loss": 14662.260330200195, "training_acc": 44.666666666666664, "val_loss": 4142.5813636779785, "val_acc": 72.0}
{"epoch": 2, "training_loss": 13121.509094238281, "training_acc": 72.0, "val_loss": 1316.3031120300293, "val_acc": 66.66666666666667}
{"epoch": 3, "training_loss": 6507.616371154785, "training_acc": 60.666666666666664, "val_loss": 1513.815894126892, "val_acc": 64.0}
{"epoch": 4, "training_loss": 5905.721130371094, "training_acc": 74.0, "val_loss": 1843.6246604919434, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 4557.16463470459, "training_acc": 64.33333333333333, "val_loss": 1130.4958209991455, "val_acc": 61.333333333333336}
{"epoch": 6, "training_loss": 3174.5012397766113, "training_acc": 71.66666666666667, "val_loss": 863.7518801689148, "val_acc": 57.333333333333336}
{"epoch": 7, "training_loss": 2029.019790649414, "training_acc": 65.33333333333333, "val_loss": 448.5315742492676, "val_acc": 65.33333333333333}
{"epoch": 8, "training_loss": 916.8898992538452, "training_acc": 66.0, "val_loss": 175.78085660934448, "val_acc": 62.666666666666664}
{"epoch": 9, "training_loss": 659.1553630828857, "training_acc": 72.33333333333333, "val_loss": 205.3692671060562, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2085.572208404541, "training_acc": 64.0, "val_loss": 1165.8434581756592, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3390.073923110962, "training_acc": 59.333333333333336, "val_loss": 1057.8269805908203, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2518.485185623169, "training_acc": 68.33333333333333, "val_loss": 498.40729689598083, "val_acc": 62.666666666666664}
{"epoch": 13, "training_loss": 1816.2957496643066, "training_acc": 72.0, "val_loss": 378.3704659938812, "val_acc": 62.666666666666664}
{"epoch": 14, "training_loss": 839.080080986023, "training_acc": 71.0, "val_loss": 379.5030632019043, "val_acc": 74.66666666666667}
{"epoch": 15, "training_loss": 706.3122138977051, "training_acc": 71.66666666666667, "val_loss": 321.7714943885803, "val_acc": 72.0}
{"epoch": 16, "training_loss": 522.9205203056335, "training_acc": 76.33333333333333, "val_loss": 144.2054102793336, "val_acc": 72.0}
{"epoch": 17, "training_loss": 260.98053002357483, "training_acc": 78.33333333333333, "val_loss": 302.01465702056885, "val_acc": 44.0}
{"epoch": 18, "training_loss": 1756.0133934020996, "training_acc": 60.333333333333336, "val_loss": 445.4419250488281, "val_acc": 50.666666666666664}
{"epoch": 19, "training_loss": 1886.5042753219604, "training_acc": 69.0, "val_loss": 860.5161724090576, "val_acc": 46.666666666666664}
{"epoch": 20, "training_loss": 1924.1618957519531, "training_acc": 69.66666666666667, "val_loss": 548.216552734375, "val_acc": 61.333333333333336}
{"epoch": 21, "training_loss": 1441.4015879631042, "training_acc": 67.0, "val_loss": 393.9249596595764, "val_acc": 56.0}
{"epoch": 22, "training_loss": 1104.753457069397, "training_acc": 67.0, "val_loss": 226.62301301956177, "val_acc": 69.33333333333333}
{"epoch": 23, "training_loss": 915.8098602294922, "training_acc": 68.66666666666667, "val_loss": 566.5316362380981, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 1049.4594764709473, "training_acc": 74.33333333333333, "val_loss": 357.94168853759766, "val_acc": 64.0}
{"epoch": 25, "training_loss": 499.05679535865784, "training_acc": 80.0, "val_loss": 369.67814230918884, "val_acc": 48.0}
{"epoch": 26, "training_loss": 1098.77112865448, "training_acc": 64.33333333333333, "val_loss": 296.03586506843567, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 701.5941152572632, "training_acc": 76.0, "val_loss": 280.3290476799011, "val_acc": 66.66666666666667}
{"epoch": 28, "training_loss": 648.8095426559448, "training_acc": 77.33333333333333, "val_loss": 411.0094635486603, "val_acc": 57.333333333333336}
{"epoch": 29, "training_loss": 718.3474540710449, "training_acc": 72.33333333333333, "val_loss": 508.15377140045166, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 1890.5546035766602, "training_acc": 69.33333333333333, "val_loss": 414.7093605995178, "val_acc": 70.66666666666667}
{"epoch": 31, "training_loss": 1447.3898525238037, "training_acc": 74.66666666666667, "val_loss": 592.337085723877, "val_acc": 61.333333333333336}
{"epoch": 32, "training_loss": 1555.1796436309814, "training_acc": 71.66666666666667, "val_loss": 570.6429009437561, "val_acc": 60.0}
{"epoch": 33, "training_loss": 1128.9909467697144, "training_acc": 77.0, "val_loss": 625.7202763557434, "val_acc": 46.666666666666664}
{"epoch": 34, "training_loss": 2089.837875366211, "training_acc": 60.333333333333336, "val_loss": 277.7310495376587, "val_acc": 69.33333333333333}
{"epoch": 35, "training_loss": 636.2146530151367, "training_acc": 78.0, "val_loss": 326.00568294525146, "val_acc": 73.33333333333333}
