"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 58873357.474975586, "training_acc": 60.666666666666664, "val_loss": 22265233.734375, "val_acc": 28.0}
{"epoch": 1, "training_loss": 62042398.625, "training_acc": 57.333333333333336, "val_loss": 17597331.5625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 39946558.625, "training_acc": 65.0, "val_loss": 10923956.734375, "val_acc": 44.0}
{"epoch": 3, "training_loss": 24840406.0, "training_acc": 64.33333333333333, "val_loss": 10381416.46875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 22333765.109375, "training_acc": 73.66666666666667, "val_loss": 6002855.0625, "val_acc": 54.666666666666664}
{"epoch": 5, "training_loss": 15361412.0, "training_acc": 65.66666666666667, "val_loss": 3790394.91015625, "val_acc": 66.66666666666667}
{"epoch": 6, "training_loss": 10399487.515625, "training_acc": 66.0, "val_loss": 4252461.1484375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 10701917.390625, "training_acc": 64.66666666666667, "val_loss": 3280467.140625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 13924522.671875, "training_acc": 68.66666666666667, "val_loss": 3732754.078125, "val_acc": 49.333333333333336}
{"epoch": 9, "training_loss": 10095394.34375, "training_acc": 68.33333333333333, "val_loss": 2931365.8955078125, "val_acc": 60.0}
{"epoch": 10, "training_loss": 6826959.283203125, "training_acc": 71.66666666666667, "val_loss": 1269242.9938964844, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 2836657.4140625, "training_acc": 73.33333333333333, "val_loss": 951330.337890625, "val_acc": 52.0}
{"epoch": 12, "training_loss": 3326894.80078125, "training_acc": 67.66666666666667, "val_loss": 857699.46875, "val_acc": 58.666666666666664}
{"epoch": 13, "training_loss": 3242551.3125, "training_acc": 72.66666666666667, "val_loss": 1574953.7587890625, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 4784492.2734375, "training_acc": 70.0, "val_loss": 652029.1329498291, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 5426838.8828125, "training_acc": 69.0, "val_loss": 1725525.087890625, "val_acc": 48.0}
{"epoch": 16, "training_loss": 3717642.57421875, "training_acc": 73.33333333333333, "val_loss": 1032500.6015625, "val_acc": 64.0}
{"epoch": 17, "training_loss": 4189599.3125, "training_acc": 71.0, "val_loss": 516943.5908203125, "val_acc": 69.33333333333333}
{"epoch": 18, "training_loss": 3495772.046875, "training_acc": 69.0, "val_loss": 1357825.2841796875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4095117.078125, "training_acc": 70.66666666666667, "val_loss": 1034707.49609375, "val_acc": 74.66666666666667}
{"epoch": 20, "training_loss": 5430259.8125, "training_acc": 73.33333333333333, "val_loss": 1582826.8637695312, "val_acc": 72.0}
{"epoch": 21, "training_loss": 13266336.5625, "training_acc": 57.0, "val_loss": 7010105.5625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 14940115.625, "training_acc": 66.0, "val_loss": 2247884.80859375, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 10241956.77734375, "training_acc": 73.66666666666667, "val_loss": 3604737.88671875, "val_acc": 54.666666666666664}
{"epoch": 24, "training_loss": 8393866.703125, "training_acc": 72.66666666666667, "val_loss": 1423362.9296875, "val_acc": 66.66666666666667}
{"epoch": 25, "training_loss": 5488385.46875, "training_acc": 73.0, "val_loss": 901644.7509765625, "val_acc": 68.0}
{"epoch": 26, "training_loss": 7641686.9375, "training_acc": 68.33333333333333, "val_loss": 1306490.484375, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 6155726.1796875, "training_acc": 69.0, "val_loss": 1351269.9799804688, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 3692268.9921875, "training_acc": 76.33333333333333, "val_loss": 996372.0349121094, "val_acc": 77.33333333333333}
{"epoch": 29, "training_loss": 4659919.6826171875, "training_acc": 70.0, "val_loss": 3131779.3671875, "val_acc": 38.666666666666664}
{"epoch": 30, "training_loss": 4000617.84375, "training_acc": 73.0, "val_loss": 1178003.119140625, "val_acc": 62.666666666666664}
{"epoch": 31, "training_loss": 3893587.05078125, "training_acc": 71.0, "val_loss": 1954280.599609375, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6321635.3916015625, "training_acc": 72.66666666666667, "val_loss": 1899001.455078125, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 4494064.75390625, "training_acc": 75.0, "val_loss": 1041351.546875, "val_acc": 74.66666666666667}
{"epoch": 34, "training_loss": 2620437.7890625, "training_acc": 78.33333333333333, "val_loss": 720371.8774414062, "val_acc": 68.0}
{"epoch": 35, "training_loss": 3189396.419921875, "training_acc": 73.66666666666667, "val_loss": 1779545.70703125, "val_acc": 45.333333333333336}
{"epoch": 36, "training_loss": 6937074.171875, "training_acc": 62.666666666666664, "val_loss": 1416794.537109375, "val_acc": 66.66666666666667}
