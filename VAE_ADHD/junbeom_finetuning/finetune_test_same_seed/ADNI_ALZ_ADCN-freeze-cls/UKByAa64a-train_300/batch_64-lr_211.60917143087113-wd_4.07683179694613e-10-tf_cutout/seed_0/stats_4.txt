"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4160784.56716156, "training_acc": 68.33333333333333, "val_loss": 1603661.345703125, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2596559.005859375, "training_acc": 64.33333333333333, "val_loss": 254486.28649902344, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1745024.541015625, "training_acc": 51.666666666666664, "val_loss": 756705.2502441406, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2059859.90625, "training_acc": 68.33333333333333, "val_loss": 682804.484375, "val_acc": 28.0}
{"epoch": 4, "training_loss": 1279310.6455078125, "training_acc": 63.0, "val_loss": 160187.46459960938, "val_acc": 28.0}
{"epoch": 5, "training_loss": 534544.3071289062, "training_acc": 53.0, "val_loss": 78444.7587890625, "val_acc": 72.0}
{"epoch": 6, "training_loss": 678303.0859375, "training_acc": 63.0, "val_loss": 98963.17028808594, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1418738.4296875, "training_acc": 48.333333333333336, "val_loss": 706678.4838867188, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1916040.830078125, "training_acc": 66.33333333333333, "val_loss": 212026.82983398438, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1170449.357421875, "training_acc": 63.0, "val_loss": 49607.70654296875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1433780.9345703125, "training_acc": 52.333333333333336, "val_loss": 279064.8127441406, "val_acc": 72.0}
{"epoch": 11, "training_loss": 638423.3193359375, "training_acc": 57.333333333333336, "val_loss": 442560.13232421875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1531878.859375, "training_acc": 64.33333333333333, "val_loss": 174571.73083496094, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1503097.197265625, "training_acc": 62.333333333333336, "val_loss": 279365.5676269531, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1342148.4658203125, "training_acc": 56.333333333333336, "val_loss": 163844.1455078125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 833160.37109375, "training_acc": 57.0, "val_loss": 297172.482421875, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2221926.44921875, "training_acc": 72.33333333333333, "val_loss": 294130.21435546875, "val_acc": 72.0}
{"epoch": 17, "training_loss": 928823.37109375, "training_acc": 51.333333333333336, "val_loss": 451658.31640625, "val_acc": 72.0}
{"epoch": 18, "training_loss": 902218.63671875, "training_acc": 68.33333333333333, "val_loss": 28774.25144958496, "val_acc": 52.0}
{"epoch": 19, "training_loss": 1758979.6953125, "training_acc": 63.333333333333336, "val_loss": 468746.86083984375, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1238079.970703125, "training_acc": 51.0, "val_loss": 393478.25244140625, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1313800.408203125, "training_acc": 66.33333333333333, "val_loss": 189112.77758789062, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1461347.736328125, "training_acc": 61.0, "val_loss": 212516.75732421875, "val_acc": 72.0}
{"epoch": 23, "training_loss": 861888.884765625, "training_acc": 54.333333333333336, "val_loss": 551466.4228515625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1508926.859375, "training_acc": 67.66666666666667, "val_loss": 611078.2998046875, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1291959.296875, "training_acc": 64.33333333333333, "val_loss": 139110.77954101562, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1119102.83203125, "training_acc": 52.333333333333336, "val_loss": 495671.955078125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1446643.97265625, "training_acc": 67.0, "val_loss": 781697.6328125, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2104954.556640625, "training_acc": 58.666666666666664, "val_loss": 915114.0576171875, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2361492.6430664062, "training_acc": 72.33333333333333, "val_loss": 959877.8154296875, "val_acc": 28.0}
{"epoch": 30, "training_loss": 3062142.845703125, "training_acc": 41.666666666666664, "val_loss": 758824.6923828125, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2429203.890625, "training_acc": 72.33333333333333, "val_loss": 245171.75854492188, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1089667.5947265625, "training_acc": 51.666666666666664, "val_loss": 109192.93334960938, "val_acc": 72.0}
{"epoch": 33, "training_loss": 752286.1015625, "training_acc": 58.333333333333336, "val_loss": 322221.6298828125, "val_acc": 72.0}
{"epoch": 34, "training_loss": 789911.5048828125, "training_acc": 54.666666666666664, "val_loss": 482507.71875, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1765356.7338867188, "training_acc": 70.66666666666667, "val_loss": 561721.3325195312, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1887673.76171875, "training_acc": 51.0, "val_loss": 512432.13671875, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1678571.853515625, "training_acc": 58.0, "val_loss": 46193.06686401367, "val_acc": 69.33333333333333}
