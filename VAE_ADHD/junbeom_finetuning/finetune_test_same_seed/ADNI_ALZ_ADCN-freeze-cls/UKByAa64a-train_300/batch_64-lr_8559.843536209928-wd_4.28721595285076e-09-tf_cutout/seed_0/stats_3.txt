"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 57545735.26940918, "training_acc": 58.333333333333336, "val_loss": 14937407.5625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 44406815.875, "training_acc": 56.666666666666664, "val_loss": 10306042.4453125, "val_acc": 72.0}
{"epoch": 2, "training_loss": 28817252.140625, "training_acc": 55.333333333333336, "val_loss": 2896605.6953125, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 27086839.96875, "training_acc": 72.33333333333333, "val_loss": 1416681.8359375, "val_acc": 80.0}
{"epoch": 4, "training_loss": 16056334.75, "training_acc": 58.333333333333336, "val_loss": 5311718.890625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 20125064.65625, "training_acc": 66.33333333333333, "val_loss": 2715130.564453125, "val_acc": 52.0}
{"epoch": 6, "training_loss": 9267530.0625, "training_acc": 69.0, "val_loss": 3900224.125, "val_acc": 40.0}
{"epoch": 7, "training_loss": 11663320.265625, "training_acc": 63.333333333333336, "val_loss": 1216199.689453125, "val_acc": 56.0}
{"epoch": 8, "training_loss": 2697117.90625, "training_acc": 67.33333333333333, "val_loss": 2808506.3125, "val_acc": 34.666666666666664}
{"epoch": 9, "training_loss": 3946323.46875, "training_acc": 68.33333333333333, "val_loss": 1030724.423828125, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4571368.65625, "training_acc": 68.0, "val_loss": 532355.259765625, "val_acc": 74.66666666666667}
{"epoch": 11, "training_loss": 9019300.046875, "training_acc": 63.666666666666664, "val_loss": 3949115.8623046875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 11263543.375, "training_acc": 59.666666666666664, "val_loss": 3029142.2421875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 8943354.1015625, "training_acc": 69.33333333333333, "val_loss": 2045785.408203125, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 9025599.921875, "training_acc": 68.0, "val_loss": 1039325.7568359375, "val_acc": 74.66666666666667}
{"epoch": 15, "training_loss": 6933886.2734375, "training_acc": 62.666666666666664, "val_loss": 2528307.048828125, "val_acc": 72.0}
{"epoch": 16, "training_loss": 8724872.515625, "training_acc": 71.0, "val_loss": 1435027.5224609375, "val_acc": 53.333333333333336}
{"epoch": 17, "training_loss": 8201406.4296875, "training_acc": 68.66666666666667, "val_loss": 2052035.1328125, "val_acc": 64.0}
{"epoch": 18, "training_loss": 8512938.44921875, "training_acc": 70.33333333333333, "val_loss": 1177766.1181640625, "val_acc": 53.333333333333336}
{"epoch": 19, "training_loss": 6239491.078125, "training_acc": 67.66666666666667, "val_loss": 4893067.546875, "val_acc": 30.666666666666668}
{"epoch": 20, "training_loss": 7410218.02734375, "training_acc": 63.333333333333336, "val_loss": 882652.92578125, "val_acc": 58.666666666666664}
{"epoch": 21, "training_loss": 4031898.4140625, "training_acc": 73.33333333333333, "val_loss": 675411.228515625, "val_acc": 76.0}
{"epoch": 22, "training_loss": 6788615.828125, "training_acc": 68.66666666666667, "val_loss": 1051512.767578125, "val_acc": 65.33333333333333}
{"epoch": 23, "training_loss": 6552985.6796875, "training_acc": 70.33333333333333, "val_loss": 963837.9482421875, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 4268396.50390625, "training_acc": 71.66666666666667, "val_loss": 411595.697265625, "val_acc": 77.33333333333333}
{"epoch": 25, "training_loss": 2183450.6875, "training_acc": 76.66666666666667, "val_loss": 593327.6241455078, "val_acc": 58.666666666666664}
{"epoch": 26, "training_loss": 1586823.39453125, "training_acc": 75.33333333333333, "val_loss": 2059888.310546875, "val_acc": 41.333333333333336}
{"epoch": 27, "training_loss": 3883234.30078125, "training_acc": 69.33333333333333, "val_loss": 575266.015625, "val_acc": 77.33333333333333}
{"epoch": 28, "training_loss": 4728014.48046875, "training_acc": 70.33333333333333, "val_loss": 607600.25390625, "val_acc": 77.33333333333333}
{"epoch": 29, "training_loss": 1843412.05078125, "training_acc": 80.0, "val_loss": 489682.5849609375, "val_acc": 78.66666666666667}
{"epoch": 30, "training_loss": 5110772.939453125, "training_acc": 69.66666666666667, "val_loss": 1667238.8466796875, "val_acc": 42.666666666666664}
{"epoch": 31, "training_loss": 3140427.25, "training_acc": 68.0, "val_loss": 921935.9609375, "val_acc": 74.66666666666667}
{"epoch": 32, "training_loss": 1712445.54296875, "training_acc": 80.0, "val_loss": 474827.51904296875, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 1740897.796875, "training_acc": 75.66666666666667, "val_loss": 385683.40283203125, "val_acc": 78.66666666666667}
{"epoch": 34, "training_loss": 642010.8837890625, "training_acc": 87.66666666666667, "val_loss": 576268.8681640625, "val_acc": 62.666666666666664}
{"epoch": 35, "training_loss": 1671278.3173828125, "training_acc": 75.33333333333333, "val_loss": 1619330.064453125, "val_acc": 44.0}
{"epoch": 36, "training_loss": 4934236.58203125, "training_acc": 60.666666666666664, "val_loss": 1158066.0615234375, "val_acc": 74.66666666666667}
{"epoch": 37, "training_loss": 4826421.53125, "training_acc": 67.33333333333333, "val_loss": 1055434.4306640625, "val_acc": 68.0}
{"epoch": 38, "training_loss": 3544942.732421875, "training_acc": 74.33333333333333, "val_loss": 1031581.318359375, "val_acc": 52.0}
{"epoch": 39, "training_loss": 3671087.482421875, "training_acc": 69.66666666666667, "val_loss": 625912.740234375, "val_acc": 76.0}
{"epoch": 40, "training_loss": 4292074.603515625, "training_acc": 65.33333333333333, "val_loss": 1794251.751953125, "val_acc": 57.333333333333336}
{"epoch": 41, "training_loss": 6903963.375, "training_acc": 72.0, "val_loss": 1939334.99609375, "val_acc": 61.333333333333336}
{"epoch": 42, "training_loss": 7766697.75390625, "training_acc": 66.0, "val_loss": 774101.2724609375, "val_acc": 70.66666666666667}
{"epoch": 43, "training_loss": 7143214.609375, "training_acc": 66.33333333333333, "val_loss": 1302463.765625, "val_acc": 50.666666666666664}
{"epoch": 44, "training_loss": 9544354.83203125, "training_acc": 69.0, "val_loss": 5791026.609375, "val_acc": 32.0}
{"epoch": 45, "training_loss": 15782266.328125, "training_acc": 60.333333333333336, "val_loss": 1201668.376953125, "val_acc": 66.66666666666667}
{"epoch": 46, "training_loss": 6501869.359375, "training_acc": 70.0, "val_loss": 834744.67578125, "val_acc": 77.33333333333333}
{"epoch": 47, "training_loss": 2180509.54296875, "training_acc": 79.33333333333333, "val_loss": 522715.4619140625, "val_acc": 72.0}
{"epoch": 48, "training_loss": 3826375.263671875, "training_acc": 75.66666666666667, "val_loss": 4967414.03515625, "val_acc": 30.666666666666668}
{"epoch": 49, "training_loss": 10134156.345703125, "training_acc": 66.33333333333333, "val_loss": 3681776.0, "val_acc": 41.333333333333336}
{"epoch": 50, "training_loss": 12797559.734375, "training_acc": 60.333333333333336, "val_loss": 1124595.1313476562, "val_acc": 77.33333333333333}
{"epoch": 51, "training_loss": 7385951.7421875, "training_acc": 69.33333333333333, "val_loss": 1713166.603515625, "val_acc": 73.33333333333333}
{"epoch": 52, "training_loss": 5488247.0859375, "training_acc": 72.66666666666667, "val_loss": 861300.1171875, "val_acc": 76.0}
