"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 491430.6110305786, "training_acc": 65.0, "val_loss": 174777.58813476562, "val_acc": 28.0}
{"epoch": 1, "training_loss": 376732.49267578125, "training_acc": 54.666666666666664, "val_loss": 118573.75500488281, "val_acc": 72.0}
{"epoch": 2, "training_loss": 264194.05712890625, "training_acc": 71.66666666666667, "val_loss": 67970.66333007812, "val_acc": 53.333333333333336}
{"epoch": 3, "training_loss": 169642.26879882812, "training_acc": 60.666666666666664, "val_loss": 57893.65710449219, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 131367.7208251953, "training_acc": 65.33333333333333, "val_loss": 21758.56898498535, "val_acc": 61.333333333333336}
{"epoch": 5, "training_loss": 73705.05932617188, "training_acc": 67.0, "val_loss": 11643.48519897461, "val_acc": 60.0}
{"epoch": 6, "training_loss": 41096.8203125, "training_acc": 65.33333333333333, "val_loss": 8896.136749267578, "val_acc": 69.33333333333333}
{"epoch": 7, "training_loss": 14941.02082824707, "training_acc": 73.0, "val_loss": 5223.471481323242, "val_acc": 65.33333333333333}
{"epoch": 8, "training_loss": 31345.94692993164, "training_acc": 65.0, "val_loss": 13317.554718017578, "val_acc": 70.66666666666667}
{"epoch": 9, "training_loss": 33000.71871948242, "training_acc": 73.0, "val_loss": 18684.47425842285, "val_acc": 72.0}
{"epoch": 10, "training_loss": 74976.78576660156, "training_acc": 60.333333333333336, "val_loss": 43198.29623413086, "val_acc": 72.0}
{"epoch": 11, "training_loss": 114978.3232421875, "training_acc": 69.33333333333333, "val_loss": 19467.509307861328, "val_acc": 60.0}
{"epoch": 12, "training_loss": 95381.42010498047, "training_acc": 70.0, "val_loss": 23239.203422546387, "val_acc": 61.333333333333336}
{"epoch": 13, "training_loss": 49664.71319580078, "training_acc": 72.33333333333333, "val_loss": 15765.76135635376, "val_acc": 69.33333333333333}
{"epoch": 14, "training_loss": 33656.15026855469, "training_acc": 70.33333333333333, "val_loss": 19181.714820861816, "val_acc": 46.666666666666664}
{"epoch": 15, "training_loss": 38157.26281738281, "training_acc": 65.33333333333333, "val_loss": 11500.622383117676, "val_acc": 69.33333333333333}
{"epoch": 16, "training_loss": 23813.152435302734, "training_acc": 75.66666666666667, "val_loss": 17630.950256347656, "val_acc": 69.33333333333333}
{"epoch": 17, "training_loss": 33678.62600708008, "training_acc": 69.66666666666667, "val_loss": 11652.436340332031, "val_acc": 73.33333333333333}
{"epoch": 18, "training_loss": 24583.895080566406, "training_acc": 71.66666666666667, "val_loss": 29032.8475189209, "val_acc": 30.666666666666668}
{"epoch": 19, "training_loss": 40499.48498535156, "training_acc": 62.333333333333336, "val_loss": 15599.839477539062, "val_acc": 69.33333333333333}
{"epoch": 20, "training_loss": 49415.23342895508, "training_acc": 66.66666666666667, "val_loss": 17929.43256378174, "val_acc": 69.33333333333333}
{"epoch": 21, "training_loss": 39939.0578918457, "training_acc": 72.33333333333333, "val_loss": 18761.32440185547, "val_acc": 69.33333333333333}
{"epoch": 22, "training_loss": 34257.4962310791, "training_acc": 71.0, "val_loss": 8311.60903930664, "val_acc": 74.66666666666667}
{"epoch": 23, "training_loss": 8857.740257263184, "training_acc": 81.33333333333333, "val_loss": 5816.232292175293, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 14263.260223388672, "training_acc": 73.0, "val_loss": 10305.941833496094, "val_acc": 58.666666666666664}
{"epoch": 25, "training_loss": 15710.693389892578, "training_acc": 73.66666666666667, "val_loss": 9289.751953125, "val_acc": 72.0}
{"epoch": 26, "training_loss": 14238.440734863281, "training_acc": 77.33333333333333, "val_loss": 9772.657051086426, "val_acc": 56.0}
