"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 196.42781853675842, "training_acc": 72.0, "val_loss": 46.93782716989517, "val_acc": 28.0}
{"epoch": 1, "training_loss": 185.11416792869568, "training_acc": 72.33333333333333, "val_loss": 45.30685621500015, "val_acc": 72.0}
{"epoch": 2, "training_loss": 179.61224341392517, "training_acc": 72.33333333333333, "val_loss": 44.73537874221802, "val_acc": 72.0}
{"epoch": 3, "training_loss": 178.2583544254303, "training_acc": 72.33333333333333, "val_loss": 44.577407002449036, "val_acc": 72.0}
{"epoch": 4, "training_loss": 177.78714895248413, "training_acc": 72.33333333333333, "val_loss": 44.51225703954697, "val_acc": 72.0}
{"epoch": 5, "training_loss": 176.64008569717407, "training_acc": 72.33333333333333, "val_loss": 44.34469938278198, "val_acc": 72.0}
{"epoch": 6, "training_loss": 175.2888388633728, "training_acc": 72.33333333333333, "val_loss": 44.13301682472229, "val_acc": 72.0}
{"epoch": 7, "training_loss": 173.77929592132568, "training_acc": 72.33333333333333, "val_loss": 43.94913798570633, "val_acc": 72.0}
{"epoch": 8, "training_loss": 172.87974977493286, "training_acc": 72.33333333333333, "val_loss": 43.80514931678772, "val_acc": 72.0}
{"epoch": 9, "training_loss": 172.62155604362488, "training_acc": 72.33333333333333, "val_loss": 43.68991583585739, "val_acc": 72.0}
{"epoch": 10, "training_loss": 171.03401732444763, "training_acc": 72.33333333333333, "val_loss": 43.598029136657715, "val_acc": 72.0}
{"epoch": 11, "training_loss": 170.64282608032227, "training_acc": 72.33333333333333, "val_loss": 43.524767339229584, "val_acc": 72.0}
{"epoch": 12, "training_loss": 170.24410200119019, "training_acc": 72.33333333333333, "val_loss": 43.47215962409973, "val_acc": 72.0}
{"epoch": 13, "training_loss": 168.87845396995544, "training_acc": 72.33333333333333, "val_loss": 43.42229789495468, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 167.4753293991089, "training_acc": 72.33333333333333, "val_loss": 43.376671731472015, "val_acc": 72.0}
{"epoch": 15, "training_loss": 168.30164217948914, "training_acc": 72.33333333333333, "val_loss": 43.32119357585907, "val_acc": 72.0}
{"epoch": 16, "training_loss": 167.5066180229187, "training_acc": 72.33333333333333, "val_loss": 43.27569490671158, "val_acc": 72.0}
{"epoch": 17, "training_loss": 165.68788504600525, "training_acc": 72.0, "val_loss": 43.22086715698242, "val_acc": 72.0}
{"epoch": 18, "training_loss": 166.60586309432983, "training_acc": 72.33333333333333, "val_loss": 43.18634873628616, "val_acc": 72.0}
{"epoch": 19, "training_loss": 167.3719663619995, "training_acc": 72.33333333333333, "val_loss": 43.146919429302216, "val_acc": 70.66666666666667}
{"epoch": 20, "training_loss": 165.581134557724, "training_acc": 72.66666666666667, "val_loss": 43.14996147155762, "val_acc": 70.66666666666667}
{"epoch": 21, "training_loss": 163.31984424591064, "training_acc": 72.33333333333333, "val_loss": 43.17023855447769, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 163.67821097373962, "training_acc": 72.33333333333333, "val_loss": 43.15969541668892, "val_acc": 70.66666666666667}
{"epoch": 23, "training_loss": 163.2687544822693, "training_acc": 72.66666666666667, "val_loss": 43.140903890132904, "val_acc": 70.66666666666667}
{"epoch": 24, "training_loss": 165.0449538230896, "training_acc": 72.66666666666667, "val_loss": 43.106428146362305, "val_acc": 70.66666666666667}
{"epoch": 25, "training_loss": 164.85089707374573, "training_acc": 73.0, "val_loss": 43.11840635538101, "val_acc": 70.66666666666667}
{"epoch": 26, "training_loss": 164.4983470439911, "training_acc": 72.33333333333333, "val_loss": 43.106635093688965, "val_acc": 72.0}
{"epoch": 27, "training_loss": 161.97796607017517, "training_acc": 73.0, "val_loss": 43.17255300283432, "val_acc": 70.66666666666667}
{"epoch": 28, "training_loss": 165.51628184318542, "training_acc": 73.0, "val_loss": 43.15037727355957, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 164.07527112960815, "training_acc": 73.66666666666667, "val_loss": 43.173204362392426, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 165.42520380020142, "training_acc": 73.33333333333333, "val_loss": 43.15476897358894, "val_acc": 69.33333333333333}
{"epoch": 31, "training_loss": 162.87961506843567, "training_acc": 74.33333333333333, "val_loss": 43.17468959093094, "val_acc": 69.33333333333333}
{"epoch": 32, "training_loss": 159.3743863105774, "training_acc": 73.33333333333333, "val_loss": 43.19715237617493, "val_acc": 68.0}
{"epoch": 33, "training_loss": 161.11558651924133, "training_acc": 73.66666666666667, "val_loss": 43.17877548933029, "val_acc": 66.66666666666667}
{"epoch": 34, "training_loss": 159.84304785728455, "training_acc": 73.0, "val_loss": 43.199838280677795, "val_acc": 66.66666666666667}
{"epoch": 35, "training_loss": 162.42123794555664, "training_acc": 73.0, "val_loss": 43.20632341504097, "val_acc": 66.66666666666667}
{"epoch": 36, "training_loss": 163.26725959777832, "training_acc": 73.33333333333333, "val_loss": 43.198804914951324, "val_acc": 66.66666666666667}
{"epoch": 37, "training_loss": 162.60641384124756, "training_acc": 74.0, "val_loss": 43.256274938583374, "val_acc": 66.66666666666667}
{"epoch": 38, "training_loss": 161.80987811088562, "training_acc": 74.33333333333333, "val_loss": 43.29593285918236, "val_acc": 66.66666666666667}
{"epoch": 39, "training_loss": 158.76231479644775, "training_acc": 73.0, "val_loss": 43.25989180803299, "val_acc": 66.66666666666667}
{"epoch": 40, "training_loss": 159.8375551700592, "training_acc": 74.66666666666667, "val_loss": 43.290263175964355, "val_acc": 66.66666666666667}
{"epoch": 41, "training_loss": 162.17353677749634, "training_acc": 73.66666666666667, "val_loss": 43.27537018060684, "val_acc": 65.33333333333333}
{"epoch": 42, "training_loss": 161.87875652313232, "training_acc": 73.66666666666667, "val_loss": 43.262109875679016, "val_acc": 68.0}
{"epoch": 43, "training_loss": 162.0207405090332, "training_acc": 73.66666666666667, "val_loss": 43.2844018638134, "val_acc": 66.66666666666667}
