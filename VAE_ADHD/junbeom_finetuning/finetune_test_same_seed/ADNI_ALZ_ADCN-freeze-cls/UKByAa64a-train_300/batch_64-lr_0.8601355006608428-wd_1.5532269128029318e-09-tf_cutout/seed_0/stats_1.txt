"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 11540.640785217285, "training_acc": 62.333333333333336, "val_loss": 2313.056234359741, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4224.560432434082, "training_acc": 66.33333333333333, "val_loss": 772.7486600875854, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3286.910484313965, "training_acc": 59.0, "val_loss": 494.7187428474426, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2611.438449859619, "training_acc": 61.666666666666664, "val_loss": 943.9170837402344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5544.0849533081055, "training_acc": 52.333333333333336, "val_loss": 2040.8886241912842, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6443.452465057373, "training_acc": 72.33333333333333, "val_loss": 3441.8391551971436, "val_acc": 28.0}
{"epoch": 6, "training_loss": 10028.86408996582, "training_acc": 45.0, "val_loss": 4526.309478759766, "val_acc": 72.0}
{"epoch": 7, "training_loss": 16748.852905273438, "training_acc": 72.33333333333333, "val_loss": 1480.4700107574463, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3958.634231567383, "training_acc": 51.666666666666664, "val_loss": 789.1209945678711, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5445.126899719238, "training_acc": 49.666666666666664, "val_loss": 1582.4750213623047, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5043.795608520508, "training_acc": 66.33333333333333, "val_loss": 79.08663010597229, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 2456.1925506591797, "training_acc": 59.333333333333336, "val_loss": 1398.868016242981, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5229.641845703125, "training_acc": 59.666666666666664, "val_loss": 230.6719126701355, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3118.049545288086, "training_acc": 72.33333333333333, "val_loss": 2670.0131912231445, "val_acc": 28.0}
{"epoch": 14, "training_loss": 6129.876125335693, "training_acc": 53.666666666666664, "val_loss": 739.5394287109375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1459.0129261016846, "training_acc": 58.333333333333336, "val_loss": 492.105660200119, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1699.7509098052979, "training_acc": 64.33333333333333, "val_loss": 208.87078857421875, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1583.4376244544983, "training_acc": 62.666666666666664, "val_loss": 966.5374174118042, "val_acc": 28.0}
{"epoch": 18, "training_loss": 2247.625270843506, "training_acc": 57.666666666666664, "val_loss": 309.2066662311554, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1473.6759147644043, "training_acc": 64.0, "val_loss": 1061.3658351898193, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4240.047012329102, "training_acc": 54.333333333333336, "val_loss": 1138.1967277526855, "val_acc": 72.0}
{"epoch": 21, "training_loss": 7135.541610717773, "training_acc": 72.33333333333333, "val_loss": 587.3642129898071, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4261.5170974731445, "training_acc": 55.0, "val_loss": 1279.7556819915771, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4911.032577514648, "training_acc": 57.0, "val_loss": 743.9074022769928, "val_acc": 72.0}
{"epoch": 24, "training_loss": 6200.811653137207, "training_acc": 72.33333333333333, "val_loss": 130.71495807170868, "val_acc": 58.666666666666664}
{"epoch": 25, "training_loss": 4065.495895385742, "training_acc": 55.0, "val_loss": 2006.031337738037, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5349.300399780273, "training_acc": 54.333333333333336, "val_loss": 1054.2328505516052, "val_acc": 72.0}
{"epoch": 27, "training_loss": 5866.022300720215, "training_acc": 72.33333333333333, "val_loss": 479.01460695266724, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2179.5693225860596, "training_acc": 59.666666666666664, "val_loss": 147.70079064369202, "val_acc": 66.66666666666667}
{"epoch": 29, "training_loss": 2252.526762008667, "training_acc": 62.333333333333336, "val_loss": 488.7633366584778, "val_acc": 28.0}
