"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 20553.77703475952, "training_acc": 65.0, "val_loss": 2405.217517852783, "val_acc": 28.0}
{"epoch": 1, "training_loss": 10308.808685302734, "training_acc": 65.0, "val_loss": 2351.1694679260254, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9277.653492450714, "training_acc": 52.333333333333336, "val_loss": 947.9218616485596, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3763.418571472168, "training_acc": 54.333333333333336, "val_loss": 1383.8729329109192, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6408.246726989746, "training_acc": 72.33333333333333, "val_loss": 1655.7952766418457, "val_acc": 28.0}
{"epoch": 5, "training_loss": 6305.685943603516, "training_acc": 53.0, "val_loss": 1843.3072528839111, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2545.94344997406, "training_acc": 61.0, "val_loss": 755.175784111023, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3361.4241256713867, "training_acc": 66.66666666666667, "val_loss": 803.2805252075195, "val_acc": 28.0}
{"epoch": 8, "training_loss": 7656.812049865723, "training_acc": 63.666666666666664, "val_loss": 2182.368721008301, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3742.548309326172, "training_acc": 50.333333333333336, "val_loss": 578.1837005615234, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3601.0985260009766, "training_acc": 66.33333333333333, "val_loss": 1765.585584640503, "val_acc": 28.0}
{"epoch": 11, "training_loss": 6339.231651306152, "training_acc": 63.0, "val_loss": 962.4605150222778, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1595.019130706787, "training_acc": 57.333333333333336, "val_loss": 762.4846420288086, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3848.9378547668457, "training_acc": 66.0, "val_loss": 1231.5682334899902, "val_acc": 28.0}
{"epoch": 14, "training_loss": 7606.361106872559, "training_acc": 60.333333333333336, "val_loss": 1675.6461944580078, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5198.145399093628, "training_acc": 54.333333333333336, "val_loss": 1198.7993850708008, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4027.035053253174, "training_acc": 69.0, "val_loss": 1021.3025741577148, "val_acc": 28.0}
{"epoch": 17, "training_loss": 5040.450572967529, "training_acc": 64.33333333333333, "val_loss": 488.7371914386749, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4538.420166015625, "training_acc": 53.666666666666664, "val_loss": 2129.3255157470703, "val_acc": 72.0}
{"epoch": 19, "training_loss": 6090.49015045166, "training_acc": 65.33333333333333, "val_loss": 2204.382511138916, "val_acc": 28.0}
{"epoch": 20, "training_loss": 8138.438781738281, "training_acc": 59.666666666666664, "val_loss": 1350.4550323486328, "val_acc": 72.0}
{"epoch": 21, "training_loss": 8011.878059387207, "training_acc": 47.333333333333336, "val_loss": 1920.7080078125, "val_acc": 72.0}
{"epoch": 22, "training_loss": 15465.463806152344, "training_acc": 72.33333333333333, "val_loss": 4498.007400512695, "val_acc": 72.0}
{"epoch": 23, "training_loss": 10826.389709472656, "training_acc": 66.33333333333333, "val_loss": 5161.243675231934, "val_acc": 28.0}
{"epoch": 24, "training_loss": 10602.451805114746, "training_acc": 52.333333333333336, "val_loss": 2449.6349029541016, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5611.827512741089, "training_acc": 54.333333333333336, "val_loss": 1209.1846370697021, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6724.264953613281, "training_acc": 72.33333333333333, "val_loss": 178.46394431591034, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 7723.120574951172, "training_acc": 47.333333333333336, "val_loss": 2515.5456771850586, "val_acc": 72.0}
{"epoch": 28, "training_loss": 8620.986526489258, "training_acc": 72.33333333333333, "val_loss": 1379.003719329834, "val_acc": 28.0}
{"epoch": 29, "training_loss": 5372.9339599609375, "training_acc": 51.666666666666664, "val_loss": 1095.0294513702393, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5356.300675868988, "training_acc": 55.0, "val_loss": 1039.3425827026367, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4009.4176712036133, "training_acc": 66.33333333333333, "val_loss": 188.0646526813507, "val_acc": 46.666666666666664}
{"epoch": 32, "training_loss": 5679.060096740723, "training_acc": 62.0, "val_loss": 769.2184410095215, "val_acc": 72.0}
{"epoch": 33, "training_loss": 4633.036926269531, "training_acc": 50.333333333333336, "val_loss": 2102.40665435791, "val_acc": 72.0}
{"epoch": 34, "training_loss": 4399.480197906494, "training_acc": 63.666666666666664, "val_loss": 612.363528251648, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3336.486396789551, "training_acc": 65.66666666666667, "val_loss": 597.4360971450806, "val_acc": 28.0}
{"epoch": 36, "training_loss": 5757.500827789307, "training_acc": 63.0, "val_loss": 1342.244873046875, "val_acc": 72.0}
{"epoch": 37, "training_loss": 4300.4234483242035, "training_acc": 61.0, "val_loss": 1053.3285875320435, "val_acc": 72.0}
{"epoch": 38, "training_loss": 4008.9836616516113, "training_acc": 67.66666666666667, "val_loss": 250.72514533996582, "val_acc": 44.0}
{"epoch": 39, "training_loss": 4943.571220397949, "training_acc": 64.66666666666667, "val_loss": 776.3981022834778, "val_acc": 72.0}
{"epoch": 40, "training_loss": 4425.121242523193, "training_acc": 52.333333333333336, "val_loss": 1671.8154335021973, "val_acc": 72.0}
{"epoch": 41, "training_loss": 4059.049916267395, "training_acc": 59.0, "val_loss": 949.8914585113525, "val_acc": 72.0}
{"epoch": 42, "training_loss": 3503.452377796173, "training_acc": 73.0, "val_loss": 1546.9621410369873, "val_acc": 28.0}
{"epoch": 43, "training_loss": 7160.594757080078, "training_acc": 53.333333333333336, "val_loss": 2753.5792503356934, "val_acc": 72.0}
{"epoch": 44, "training_loss": 6527.6248207092285, "training_acc": 55.666666666666664, "val_loss": 721.3259887695312, "val_acc": 72.0}
{"epoch": 45, "training_loss": 3982.405776977539, "training_acc": 72.33333333333333, "val_loss": 1952.8825550079346, "val_acc": 28.0}
