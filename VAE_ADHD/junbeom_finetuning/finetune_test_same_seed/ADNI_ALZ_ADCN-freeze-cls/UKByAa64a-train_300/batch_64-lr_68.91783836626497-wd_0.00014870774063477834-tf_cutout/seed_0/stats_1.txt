"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 473209.60625457764, "training_acc": 65.66666666666667, "val_loss": 181439.05346679688, "val_acc": 28.0}
{"epoch": 1, "training_loss": 372769.62890625, "training_acc": 58.666666666666664, "val_loss": 113799.10827636719, "val_acc": 72.0}
{"epoch": 2, "training_loss": 270239.16259765625, "training_acc": 63.666666666666664, "val_loss": 73364.3515625, "val_acc": 52.0}
{"epoch": 3, "training_loss": 230597.36279296875, "training_acc": 70.33333333333333, "val_loss": 82852.62060546875, "val_acc": 70.66666666666667}
{"epoch": 4, "training_loss": 190594.96728515625, "training_acc": 64.0, "val_loss": 48877.035217285156, "val_acc": 57.333333333333336}
{"epoch": 5, "training_loss": 153597.66625976562, "training_acc": 73.66666666666667, "val_loss": 45456.2822265625, "val_acc": 73.33333333333333}
{"epoch": 6, "training_loss": 111519.53942871094, "training_acc": 59.666666666666664, "val_loss": 50423.434020996094, "val_acc": 69.33333333333333}
{"epoch": 7, "training_loss": 137118.1563720703, "training_acc": 70.33333333333333, "val_loss": 49857.719665527344, "val_acc": 37.333333333333336}
{"epoch": 8, "training_loss": 108495.46166992188, "training_acc": 67.0, "val_loss": 18341.566680908203, "val_acc": 61.333333333333336}
{"epoch": 9, "training_loss": 68041.80078125, "training_acc": 67.66666666666667, "val_loss": 16897.2353515625, "val_acc": 74.66666666666667}
{"epoch": 10, "training_loss": 31946.26043701172, "training_acc": 71.33333333333333, "val_loss": 6256.033226013184, "val_acc": 68.0}
{"epoch": 11, "training_loss": 50735.87548828125, "training_acc": 66.66666666666667, "val_loss": 44562.953063964844, "val_acc": 28.0}
{"epoch": 12, "training_loss": 96015.53723144531, "training_acc": 63.0, "val_loss": 13815.054428100586, "val_acc": 60.0}
{"epoch": 13, "training_loss": 59087.81866455078, "training_acc": 66.66666666666667, "val_loss": 13441.320922851562, "val_acc": 62.666666666666664}
{"epoch": 14, "training_loss": 52927.67706298828, "training_acc": 70.66666666666667, "val_loss": 18728.319137573242, "val_acc": 70.66666666666667}
{"epoch": 15, "training_loss": 59960.32080078125, "training_acc": 63.333333333333336, "val_loss": 15094.48550415039, "val_acc": 72.0}
{"epoch": 16, "training_loss": 42250.44958496094, "training_acc": 67.33333333333333, "val_loss": 26941.063285827637, "val_acc": 29.333333333333332}
{"epoch": 17, "training_loss": 49481.011657714844, "training_acc": 57.0, "val_loss": 23934.15020751953, "val_acc": 70.66666666666667}
{"epoch": 18, "training_loss": 100893.61010742188, "training_acc": 66.33333333333333, "val_loss": 15501.431518554688, "val_acc": 61.333333333333336}
{"epoch": 19, "training_loss": 66612.02899169922, "training_acc": 75.0, "val_loss": 31822.437057495117, "val_acc": 50.666666666666664}
{"epoch": 20, "training_loss": 60411.537109375, "training_acc": 66.66666666666667, "val_loss": 14100.582459449768, "val_acc": 72.0}
{"epoch": 21, "training_loss": 49150.505615234375, "training_acc": 69.0, "val_loss": 9806.399291992188, "val_acc": 74.66666666666667}
{"epoch": 22, "training_loss": 63076.68811035156, "training_acc": 64.66666666666667, "val_loss": 12038.727783203125, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 52289.82629394531, "training_acc": 67.0, "val_loss": 12488.81803894043, "val_acc": 66.66666666666667}
{"epoch": 24, "training_loss": 40602.292541503906, "training_acc": 74.33333333333333, "val_loss": 8335.032104492188, "val_acc": 72.0}
{"epoch": 25, "training_loss": 50548.91735839844, "training_acc": 57.666666666666664, "val_loss": 7903.100028991699, "val_acc": 73.33333333333333}
{"epoch": 26, "training_loss": 28613.3212890625, "training_acc": 73.0, "val_loss": 18371.56470489502, "val_acc": 70.66666666666667}
{"epoch": 27, "training_loss": 53560.93606567383, "training_acc": 68.66666666666667, "val_loss": 22812.05386352539, "val_acc": 70.66666666666667}
{"epoch": 28, "training_loss": 48330.380859375, "training_acc": 70.66666666666667, "val_loss": 11370.270160675049, "val_acc": 69.33333333333333}
{"epoch": 29, "training_loss": 32784.156829833984, "training_acc": 69.33333333333333, "val_loss": 10653.869491577148, "val_acc": 73.33333333333333}
