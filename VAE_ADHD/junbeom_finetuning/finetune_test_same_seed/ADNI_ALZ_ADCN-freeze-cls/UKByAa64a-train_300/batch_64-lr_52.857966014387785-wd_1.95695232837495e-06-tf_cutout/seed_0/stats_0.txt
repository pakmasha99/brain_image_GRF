"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 359220.75872039795, "training_acc": 64.33333333333333, "val_loss": 129783.79711914062, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 308530.87451171875, "training_acc": 61.666666666666664, "val_loss": 105009.62512207031, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 272314.1486816406, "training_acc": 67.33333333333333, "val_loss": 56432.36755371094, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 154332.28540039062, "training_acc": 64.0, "val_loss": 42823.630432128906, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 153366.9617919922, "training_acc": 74.33333333333333, "val_loss": 39119.9621887207, "val_acc": 42.666666666666664}
{"epoch": 5, "training_loss": 111126.31494140625, "training_acc": 61.666666666666664, "val_loss": 10773.702133178711, "val_acc": 74.66666666666667}
{"epoch": 6, "training_loss": 69363.54858398438, "training_acc": 60.666666666666664, "val_loss": 28561.900077819824, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 68093.51330566406, "training_acc": 65.66666666666667, "val_loss": 17371.106475830078, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 71740.5966796875, "training_acc": 58.333333333333336, "val_loss": 17873.302322387695, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 105328.9365234375, "training_acc": 66.0, "val_loss": 18168.584762573242, "val_acc": 56.0}
{"epoch": 10, "training_loss": 54644.841552734375, "training_acc": 69.0, "val_loss": 8456.349151611328, "val_acc": 69.33333333333333}
{"epoch": 11, "training_loss": 36798.4817199707, "training_acc": 70.0, "val_loss": 21504.094268798828, "val_acc": 37.333333333333336}
{"epoch": 12, "training_loss": 68875.90539550781, "training_acc": 64.0, "val_loss": 6131.337526321411, "val_acc": 72.0}
{"epoch": 13, "training_loss": 73217.34301757812, "training_acc": 60.0, "val_loss": 22693.526245117188, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 71332.67892456055, "training_acc": 62.333333333333336, "val_loss": 14020.0107421875, "val_acc": 74.66666666666667}
{"epoch": 15, "training_loss": 56953.06378173828, "training_acc": 73.66666666666667, "val_loss": 14787.930572509766, "val_acc": 60.0}
{"epoch": 16, "training_loss": 51586.36602783203, "training_acc": 67.66666666666667, "val_loss": 5357.491561889648, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 21587.29849243164, "training_acc": 71.33333333333333, "val_loss": 9315.191276550293, "val_acc": 72.0}
{"epoch": 18, "training_loss": 24857.900268554688, "training_acc": 72.33333333333333, "val_loss": 14056.720977783203, "val_acc": 73.33333333333333}
{"epoch": 19, "training_loss": 29554.836029052734, "training_acc": 70.33333333333333, "val_loss": 2657.7157287597656, "val_acc": 80.0}
{"epoch": 20, "training_loss": 26984.274780273438, "training_acc": 62.0, "val_loss": 11291.819641113281, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 46006.798248291016, "training_acc": 65.33333333333333, "val_loss": 11484.651229858398, "val_acc": 73.33333333333333}
{"epoch": 22, "training_loss": 30852.738006591797, "training_acc": 69.33333333333333, "val_loss": 4260.575981140137, "val_acc": 80.0}
{"epoch": 23, "training_loss": 16564.10546875, "training_acc": 77.66666666666667, "val_loss": 11313.091094970703, "val_acc": 46.666666666666664}
{"epoch": 24, "training_loss": 18275.229568481445, "training_acc": 69.0, "val_loss": 4071.331554412842, "val_acc": 72.0}
{"epoch": 25, "training_loss": 6889.308624267578, "training_acc": 84.33333333333333, "val_loss": 1844.0636291503906, "val_acc": 80.0}
{"epoch": 26, "training_loss": 35688.47314453125, "training_acc": 62.666666666666664, "val_loss": 17409.082244873047, "val_acc": 73.33333333333333}
{"epoch": 27, "training_loss": 51394.56816101074, "training_acc": 68.33333333333333, "val_loss": 5291.13134765625, "val_acc": 81.33333333333333}
{"epoch": 28, "training_loss": 19846.735763549805, "training_acc": 76.66666666666667, "val_loss": 3155.71190738678, "val_acc": 81.33333333333333}
{"epoch": 29, "training_loss": 11943.307510375977, "training_acc": 73.66666666666667, "val_loss": 9757.232299804688, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 52295.00402832031, "training_acc": 60.333333333333336, "val_loss": 24655.220779418945, "val_acc": 73.33333333333333}
{"epoch": 31, "training_loss": 50475.25360107422, "training_acc": 71.0, "val_loss": 8247.265579223633, "val_acc": 74.66666666666667}
{"epoch": 32, "training_loss": 28800.862106323242, "training_acc": 74.0, "val_loss": 11109.782424926758, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 28946.19497680664, "training_acc": 66.33333333333333, "val_loss": 2070.1152057647705, "val_acc": 76.0}
{"epoch": 34, "training_loss": 9404.7314453125, "training_acc": 74.0, "val_loss": 13835.592681884766, "val_acc": 73.33333333333333}
{"epoch": 35, "training_loss": 60188.12427520752, "training_acc": 64.66666666666667, "val_loss": 9753.880882263184, "val_acc": 73.33333333333333}
{"epoch": 36, "training_loss": 34996.28601074219, "training_acc": 68.33333333333333, "val_loss": 13486.54263305664, "val_acc": 73.33333333333333}
{"epoch": 37, "training_loss": 42554.500312805176, "training_acc": 70.33333333333333, "val_loss": 11664.91244506836, "val_acc": 73.33333333333333}
{"epoch": 38, "training_loss": 19366.894834518433, "training_acc": 75.66666666666667, "val_loss": 4709.76237487793, "val_acc": 73.33333333333333}
{"epoch": 39, "training_loss": 16089.733993530273, "training_acc": 75.0, "val_loss": 1561.425968170166, "val_acc": 85.33333333333333}
{"epoch": 40, "training_loss": 6211.122978210449, "training_acc": 82.33333333333333, "val_loss": 4777.832801818848, "val_acc": 76.0}
{"epoch": 41, "training_loss": 10572.749671936035, "training_acc": 73.0, "val_loss": 1782.8314208984375, "val_acc": 85.33333333333333}
{"epoch": 42, "training_loss": 6210.902778625488, "training_acc": 83.0, "val_loss": 1576.144874572754, "val_acc": 77.33333333333333}
{"epoch": 43, "training_loss": 5423.794006347656, "training_acc": 82.33333333333333, "val_loss": 4613.309005737305, "val_acc": 56.0}
{"epoch": 44, "training_loss": 31971.979248046875, "training_acc": 61.666666666666664, "val_loss": 11551.577224731445, "val_acc": 73.33333333333333}
{"epoch": 45, "training_loss": 45695.28137207031, "training_acc": 66.66666666666667, "val_loss": 19906.593170166016, "val_acc": 73.33333333333333}
{"epoch": 46, "training_loss": 41272.596923828125, "training_acc": 70.33333333333333, "val_loss": 12168.957294464111, "val_acc": 73.33333333333333}
{"epoch": 47, "training_loss": 43259.83380126953, "training_acc": 67.0, "val_loss": 11200.74797821045, "val_acc": 73.33333333333333}
{"epoch": 48, "training_loss": 21730.295043945312, "training_acc": 75.66666666666667, "val_loss": 2757.439031600952, "val_acc": 74.66666666666667}
{"epoch": 49, "training_loss": 25846.028358459473, "training_acc": 70.33333333333333, "val_loss": 9551.532501220703, "val_acc": 57.333333333333336}
{"epoch": 50, "training_loss": 25816.370483398438, "training_acc": 71.0, "val_loss": 2883.7843856811523, "val_acc": 81.33333333333333}
{"epoch": 51, "training_loss": 18422.558166503906, "training_acc": 76.33333333333333, "val_loss": 8340.37319946289, "val_acc": 73.33333333333333}
{"epoch": 52, "training_loss": 30876.095260620117, "training_acc": 71.0, "val_loss": 13055.834663391113, "val_acc": 73.33333333333333}
{"epoch": 53, "training_loss": 49443.28446960449, "training_acc": 67.66666666666667, "val_loss": 14241.254089355469, "val_acc": 73.33333333333333}
{"epoch": 54, "training_loss": 43294.12809753418, "training_acc": 69.0, "val_loss": 4974.629001617432, "val_acc": 81.33333333333333}
{"epoch": 55, "training_loss": 28218.463256835938, "training_acc": 70.33333333333333, "val_loss": 12015.244537353516, "val_acc": 73.33333333333333}
{"epoch": 56, "training_loss": 23797.106231689453, "training_acc": 77.0, "val_loss": 2938.890449523926, "val_acc": 74.66666666666667}
{"epoch": 57, "training_loss": 12699.861785888672, "training_acc": 77.33333333333333, "val_loss": 2110.1378326416016, "val_acc": 86.66666666666667}
{"epoch": 58, "training_loss": 13116.324401855469, "training_acc": 77.33333333333333, "val_loss": 3504.337188720703, "val_acc": 82.66666666666667}
