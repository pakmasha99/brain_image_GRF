"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 331731.8563308716, "training_acc": 57.666666666666664, "val_loss": 19350.08546447754, "val_acc": 53.333333333333336}
{"epoch": 1, "training_loss": 80575.1010131836, "training_acc": 69.66666666666667, "val_loss": 21122.960830688477, "val_acc": 62.666666666666664}
{"epoch": 2, "training_loss": 61152.195877075195, "training_acc": 67.66666666666667, "val_loss": 25862.291778564453, "val_acc": 33.333333333333336}
{"epoch": 3, "training_loss": 87536.1337890625, "training_acc": 56.666666666666664, "val_loss": 10654.1318359375, "val_acc": 49.333333333333336}
{"epoch": 4, "training_loss": 85944.64044189453, "training_acc": 66.66666666666667, "val_loss": 22499.843658447266, "val_acc": 52.0}
{"epoch": 5, "training_loss": 54107.57061767578, "training_acc": 68.0, "val_loss": 16423.547424316406, "val_acc": 58.666666666666664}
{"epoch": 6, "training_loss": 54206.42724609375, "training_acc": 64.33333333333333, "val_loss": 11036.712490081787, "val_acc": 61.333333333333336}
{"epoch": 7, "training_loss": 38235.67156982422, "training_acc": 67.33333333333333, "val_loss": 6433.216117858887, "val_acc": 66.66666666666667}
{"epoch": 8, "training_loss": 43255.81066894531, "training_acc": 68.33333333333333, "val_loss": 16428.592361450195, "val_acc": 44.0}
{"epoch": 9, "training_loss": 31110.09701538086, "training_acc": 64.66666666666667, "val_loss": 6492.967681884766, "val_acc": 70.66666666666667}
{"epoch": 10, "training_loss": 30060.202896118164, "training_acc": 69.0, "val_loss": 13052.237030029297, "val_acc": 72.0}
{"epoch": 11, "training_loss": 48074.02209472656, "training_acc": 66.33333333333333, "val_loss": 16587.80824279785, "val_acc": 72.0}
{"epoch": 12, "training_loss": 51262.810607910156, "training_acc": 67.33333333333333, "val_loss": 11391.078155517578, "val_acc": 72.0}
{"epoch": 13, "training_loss": 25058.366744995117, "training_acc": 74.33333333333333, "val_loss": 5878.610198974609, "val_acc": 72.0}
{"epoch": 14, "training_loss": 15404.749908447266, "training_acc": 73.66666666666667, "val_loss": 4660.60027885437, "val_acc": 76.0}
{"epoch": 15, "training_loss": 36221.05160522461, "training_acc": 64.33333333333333, "val_loss": 10627.351020812988, "val_acc": 48.0}
{"epoch": 16, "training_loss": 22409.441986083984, "training_acc": 70.0, "val_loss": 6335.539306640625, "val_acc": 74.66666666666667}
{"epoch": 17, "training_loss": 19630.057495117188, "training_acc": 70.66666666666667, "val_loss": 8538.28215789795, "val_acc": 50.666666666666664}
{"epoch": 18, "training_loss": 13628.224914550781, "training_acc": 72.66666666666667, "val_loss": 5327.501876831055, "val_acc": 50.666666666666664}
{"epoch": 19, "training_loss": 7513.591941833496, "training_acc": 79.0, "val_loss": 1819.152847290039, "val_acc": 70.66666666666667}
{"epoch": 20, "training_loss": 40505.26495361328, "training_acc": 72.0, "val_loss": 25127.2578125, "val_acc": 32.0}
{"epoch": 21, "training_loss": 33559.82595825195, "training_acc": 69.0, "val_loss": 12791.1904296875, "val_acc": 52.0}
{"epoch": 22, "training_loss": 28012.042541503906, "training_acc": 73.33333333333333, "val_loss": 4556.032814025879, "val_acc": 61.333333333333336}
{"epoch": 23, "training_loss": 30245.01609802246, "training_acc": 65.66666666666667, "val_loss": 10375.4638671875, "val_acc": 72.0}
{"epoch": 24, "training_loss": 37601.90188598633, "training_acc": 64.33333333333333, "val_loss": 7954.013618469238, "val_acc": 60.0}
{"epoch": 25, "training_loss": 15448.194885253906, "training_acc": 76.66666666666667, "val_loss": 5866.651641845703, "val_acc": 70.66666666666667}
{"epoch": 26, "training_loss": 11386.349609375, "training_acc": 81.0, "val_loss": 8390.749969482422, "val_acc": 41.333333333333336}
{"epoch": 27, "training_loss": 30702.990600585938, "training_acc": 64.0, "val_loss": 19969.455017089844, "val_acc": 72.0}
{"epoch": 28, "training_loss": 40073.344818115234, "training_acc": 70.33333333333333, "val_loss": 12716.367858886719, "val_acc": 72.0}
{"epoch": 29, "training_loss": 25293.833618164062, "training_acc": 76.33333333333333, "val_loss": 8614.675867080688, "val_acc": 72.0}
{"epoch": 30, "training_loss": 12227.634414672852, "training_acc": 77.0, "val_loss": 11241.654739379883, "val_acc": 72.0}
{"epoch": 31, "training_loss": 42764.33770751953, "training_acc": 62.666666666666664, "val_loss": 3796.67325592041, "val_acc": 72.0}
{"epoch": 32, "training_loss": 14504.127136230469, "training_acc": 79.66666666666667, "val_loss": 7467.791320800781, "val_acc": 73.33333333333333}
{"epoch": 33, "training_loss": 15692.213897705078, "training_acc": 77.33333333333333, "val_loss": 8896.164001464844, "val_acc": 48.0}
{"epoch": 34, "training_loss": 44323.801025390625, "training_acc": 64.0, "val_loss": 11345.9535446167, "val_acc": 38.666666666666664}
{"epoch": 35, "training_loss": 111599.06164550781, "training_acc": 67.0, "val_loss": 17301.506591796875, "val_acc": 52.0}
{"epoch": 36, "training_loss": 62375.92102050781, "training_acc": 67.33333333333333, "val_loss": 13731.647317886353, "val_acc": 69.33333333333333}
{"epoch": 37, "training_loss": 35086.05569458008, "training_acc": 77.0, "val_loss": 7366.195838928223, "val_acc": 72.0}
{"epoch": 38, "training_loss": 26139.11309814453, "training_acc": 70.33333333333333, "val_loss": 16175.475784301758, "val_acc": 37.333333333333336}
