"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 337088.8642425537, "training_acc": 67.0, "val_loss": 130763.13513183594, "val_acc": 28.0}
{"epoch": 1, "training_loss": 325337.109375, "training_acc": 61.333333333333336, "val_loss": 114293.84576416016, "val_acc": 72.0}
{"epoch": 2, "training_loss": 294490.98779296875, "training_acc": 69.66666666666667, "val_loss": 45614.8828125, "val_acc": 54.666666666666664}
{"epoch": 3, "training_loss": 189401.57592773438, "training_acc": 62.333333333333336, "val_loss": 50095.010681152344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 169344.2041015625, "training_acc": 61.0, "val_loss": 9802.101593017578, "val_acc": 70.66666666666667}
{"epoch": 5, "training_loss": 69858.2197265625, "training_acc": 72.0, "val_loss": 16645.710479736328, "val_acc": 52.0}
{"epoch": 6, "training_loss": 53954.34867095947, "training_acc": 66.0, "val_loss": 27755.46630859375, "val_acc": 34.666666666666664}
{"epoch": 7, "training_loss": 44499.343406677246, "training_acc": 68.0, "val_loss": 18872.720748901367, "val_acc": 33.333333333333336}
{"epoch": 8, "training_loss": 35422.47341918945, "training_acc": 62.333333333333336, "val_loss": 6631.8709716796875, "val_acc": 76.0}
{"epoch": 9, "training_loss": 28197.336853027344, "training_acc": 68.33333333333333, "val_loss": 5074.534957885742, "val_acc": 72.0}
{"epoch": 10, "training_loss": 35865.62333679199, "training_acc": 62.333333333333336, "val_loss": 1961.908314704895, "val_acc": 73.33333333333333}
{"epoch": 11, "training_loss": 19726.547973632812, "training_acc": 73.66666666666667, "val_loss": 2046.5475234985352, "val_acc": 76.0}
{"epoch": 12, "training_loss": 44646.63278198242, "training_acc": 64.33333333333333, "val_loss": 14068.848678588867, "val_acc": 38.666666666666664}
{"epoch": 13, "training_loss": 42895.18435668945, "training_acc": 67.66666666666667, "val_loss": 8663.357376098633, "val_acc": 56.0}
{"epoch": 14, "training_loss": 30610.56475830078, "training_acc": 66.66666666666667, "val_loss": 3002.098564147949, "val_acc": 74.66666666666667}
{"epoch": 15, "training_loss": 31117.720581054688, "training_acc": 65.66666666666667, "val_loss": 4270.856742858887, "val_acc": 72.0}
{"epoch": 16, "training_loss": 55454.606384277344, "training_acc": 64.66666666666667, "val_loss": 7084.735374450684, "val_acc": 73.33333333333333}
{"epoch": 17, "training_loss": 48995.713317871094, "training_acc": 65.66666666666667, "val_loss": 26978.035278320312, "val_acc": 72.0}
{"epoch": 18, "training_loss": 67916.1474609375, "training_acc": 69.0, "val_loss": 8339.5048828125, "val_acc": 78.66666666666667}
{"epoch": 19, "training_loss": 75602.12995910645, "training_acc": 74.0, "val_loss": 30184.489868164062, "val_acc": 33.333333333333336}
{"epoch": 20, "training_loss": 85689.87756347656, "training_acc": 62.666666666666664, "val_loss": 12291.680419921875, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 52232.984924316406, "training_acc": 65.33333333333333, "val_loss": 15649.065155029297, "val_acc": 72.0}
{"epoch": 22, "training_loss": 38594.44158935547, "training_acc": 68.33333333333333, "val_loss": 6452.636823654175, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 20085.45590209961, "training_acc": 75.0, "val_loss": 6350.350646972656, "val_acc": 62.666666666666664}
{"epoch": 24, "training_loss": 15035.186065673828, "training_acc": 71.66666666666667, "val_loss": 3225.858567237854, "val_acc": 77.33333333333333}
{"epoch": 25, "training_loss": 16144.687149047852, "training_acc": 73.66666666666667, "val_loss": 14685.135383605957, "val_acc": 34.666666666666664}
{"epoch": 26, "training_loss": 27880.695678710938, "training_acc": 64.0, "val_loss": 5383.020282745361, "val_acc": 76.0}
{"epoch": 27, "training_loss": 17695.956176757812, "training_acc": 74.0, "val_loss": 2504.0815620422363, "val_acc": 78.66666666666667}
{"epoch": 28, "training_loss": 27487.63232421875, "training_acc": 70.66666666666667, "val_loss": 12236.02523803711, "val_acc": 38.666666666666664}
{"epoch": 29, "training_loss": 29565.087783813477, "training_acc": 62.333333333333336, "val_loss": 5891.480339050293, "val_acc": 76.0}
