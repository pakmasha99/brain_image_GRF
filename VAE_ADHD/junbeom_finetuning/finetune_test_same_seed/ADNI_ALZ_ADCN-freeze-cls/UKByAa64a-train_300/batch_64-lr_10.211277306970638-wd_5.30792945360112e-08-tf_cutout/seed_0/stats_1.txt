"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 41421.10858154297, "training_acc": 64.0, "val_loss": 8741.130729675293, "val_acc": 72.0}
{"epoch": 1, "training_loss": 34027.34097290039, "training_acc": 68.66666666666667, "val_loss": 9778.210571289062, "val_acc": 44.0}
{"epoch": 2, "training_loss": 20544.660751342773, "training_acc": 69.33333333333333, "val_loss": 7987.2522621154785, "val_acc": 73.33333333333333}
{"epoch": 3, "training_loss": 17683.11851501465, "training_acc": 69.33333333333333, "val_loss": 5038.3049392700195, "val_acc": 73.33333333333333}
{"epoch": 4, "training_loss": 13578.879028320312, "training_acc": 64.66666666666667, "val_loss": 2398.559669494629, "val_acc": 57.333333333333336}
{"epoch": 5, "training_loss": 11173.826713562012, "training_acc": 68.0, "val_loss": 3683.4558296203613, "val_acc": 45.333333333333336}
{"epoch": 6, "training_loss": 15182.323913574219, "training_acc": 67.0, "val_loss": 5842.046440124512, "val_acc": 48.0}
{"epoch": 7, "training_loss": 17415.231872558594, "training_acc": 63.666666666666664, "val_loss": 6989.0974197387695, "val_acc": 70.66666666666667}
{"epoch": 8, "training_loss": 16151.650146484375, "training_acc": 66.0, "val_loss": 4148.696838378906, "val_acc": 68.0}
{"epoch": 9, "training_loss": 18670.70068359375, "training_acc": 74.33333333333333, "val_loss": 4560.317028045654, "val_acc": 50.666666666666664}
{"epoch": 10, "training_loss": 16170.385116577148, "training_acc": 58.0, "val_loss": 3227.079765319824, "val_acc": 72.0}
{"epoch": 11, "training_loss": 7200.358009338379, "training_acc": 70.33333333333333, "val_loss": 3058.1917457580566, "val_acc": 73.33333333333333}
{"epoch": 12, "training_loss": 4392.3864822387695, "training_acc": 74.66666666666667, "val_loss": 1742.5408878326416, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5931.718023300171, "training_acc": 64.0, "val_loss": 1001.0765056610107, "val_acc": 70.66666666666667}
{"epoch": 14, "training_loss": 2205.6585235595703, "training_acc": 76.33333333333333, "val_loss": 2143.323497772217, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4572.499652862549, "training_acc": 70.66666666666667, "val_loss": 852.7736775875092, "val_acc": 62.666666666666664}
{"epoch": 16, "training_loss": 3602.391300201416, "training_acc": 71.66666666666667, "val_loss": 766.8886489868164, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1411.3074569702148, "training_acc": 82.33333333333333, "val_loss": 2444.670234680176, "val_acc": 45.333333333333336}
{"epoch": 18, "training_loss": 8116.718353271484, "training_acc": 63.0, "val_loss": 1233.5396423339844, "val_acc": 74.66666666666667}
{"epoch": 19, "training_loss": 4357.1597328186035, "training_acc": 75.66666666666667, "val_loss": 1913.6214618682861, "val_acc": 74.66666666666667}
{"epoch": 20, "training_loss": 4306.9052810668945, "training_acc": 74.33333333333333, "val_loss": 1348.883888721466, "val_acc": 74.66666666666667}
{"epoch": 21, "training_loss": 5786.958557128906, "training_acc": 63.666666666666664, "val_loss": 1615.9165954589844, "val_acc": 70.66666666666667}
{"epoch": 22, "training_loss": 3890.594962120056, "training_acc": 77.0, "val_loss": 1621.2170429229736, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 1902.1036052703857, "training_acc": 79.33333333333333, "val_loss": 1476.3511505126953, "val_acc": 69.33333333333333}
{"epoch": 24, "training_loss": 5144.639980316162, "training_acc": 67.0, "val_loss": 6046.252067565918, "val_acc": 29.333333333333332}
{"epoch": 25, "training_loss": 10186.390518188477, "training_acc": 66.0, "val_loss": 3758.935317993164, "val_acc": 58.666666666666664}
{"epoch": 26, "training_loss": 8326.136611938477, "training_acc": 68.33333333333333, "val_loss": 2618.5100173950195, "val_acc": 66.66666666666667}
{"epoch": 27, "training_loss": 12017.763092041016, "training_acc": 65.33333333333333, "val_loss": 3083.2581329345703, "val_acc": 73.33333333333333}
{"epoch": 28, "training_loss": 7542.898223876953, "training_acc": 70.0, "val_loss": 4732.755886077881, "val_acc": 69.33333333333333}
{"epoch": 29, "training_loss": 9463.870391845703, "training_acc": 68.0, "val_loss": 4318.5172996521, "val_acc": 70.66666666666667}
{"epoch": 30, "training_loss": 7779.38667678833, "training_acc": 70.66666666666667, "val_loss": 4315.161460876465, "val_acc": 72.0}
{"epoch": 31, "training_loss": 9263.856342315674, "training_acc": 72.0, "val_loss": 3596.985939025879, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4811.621658325195, "training_acc": 75.66666666666667, "val_loss": 2911.02685546875, "val_acc": 69.33333333333333}
{"epoch": 33, "training_loss": 7018.291919231415, "training_acc": 70.0, "val_loss": 3560.8130073547363, "val_acc": 70.66666666666667}
{"epoch": 34, "training_loss": 9658.375, "training_acc": 67.0, "val_loss": 3664.0957860946655, "val_acc": 70.66666666666667}
{"epoch": 35, "training_loss": 7862.604866027832, "training_acc": 73.33333333333333, "val_loss": 2497.0642437934875, "val_acc": 73.33333333333333}
