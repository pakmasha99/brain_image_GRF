"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9157.792533874512, "training_acc": 56.666666666666664, "val_loss": 1514.8824272155762, "val_acc": 73.33333333333333}
{"epoch": 1, "training_loss": 10226.88623046875, "training_acc": 73.0, "val_loss": 820.5395293235779, "val_acc": 74.66666666666667}
{"epoch": 2, "training_loss": 6894.405963897705, "training_acc": 52.666666666666664, "val_loss": 1228.4846210479736, "val_acc": 74.66666666666667}
{"epoch": 3, "training_loss": 7302.819801330566, "training_acc": 72.33333333333333, "val_loss": 590.7441720962524, "val_acc": 76.0}
{"epoch": 4, "training_loss": 3735.292875289917, "training_acc": 63.0, "val_loss": 425.64731150865555, "val_acc": 73.33333333333333}
{"epoch": 5, "training_loss": 2006.1426830291748, "training_acc": 67.33333333333333, "val_loss": 385.80238103866577, "val_acc": 65.33333333333333}
{"epoch": 6, "training_loss": 1488.104437828064, "training_acc": 62.333333333333336, "val_loss": 137.9169270992279, "val_acc": 64.0}
{"epoch": 7, "training_loss": 936.8458805084229, "training_acc": 68.66666666666667, "val_loss": 157.21453714370728, "val_acc": 78.66666666666667}
{"epoch": 8, "training_loss": 1145.4213886260986, "training_acc": 69.0, "val_loss": 591.2688779830933, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1815.2244110107422, "training_acc": 65.0, "val_loss": 417.1688537597656, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1931.203945159912, "training_acc": 62.333333333333336, "val_loss": 539.8607790470123, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2862.998275756836, "training_acc": 56.666666666666664, "val_loss": 1501.3841667175293, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4829.291084289551, "training_acc": 66.0, "val_loss": 829.391923904419, "val_acc": 42.666666666666664}
{"epoch": 13, "training_loss": 3151.5252742767334, "training_acc": 67.33333333333333, "val_loss": 236.558189868927, "val_acc": 77.33333333333333}
{"epoch": 14, "training_loss": 1674.3698539733887, "training_acc": 70.66666666666667, "val_loss": 192.50002372264862, "val_acc": 78.66666666666667}
{"epoch": 15, "training_loss": 719.7061910629272, "training_acc": 75.33333333333333, "val_loss": 266.046434879303, "val_acc": 48.0}
{"epoch": 16, "training_loss": 666.1715536117554, "training_acc": 67.33333333333333, "val_loss": 107.68352401256561, "val_acc": 72.0}
{"epoch": 17, "training_loss": 480.382381439209, "training_acc": 76.33333333333333, "val_loss": 134.5064516067505, "val_acc": 81.33333333333333}
{"epoch": 18, "training_loss": 637.5762376785278, "training_acc": 71.0, "val_loss": 111.78343999385834, "val_acc": 61.333333333333336}
{"epoch": 19, "training_loss": 994.0456466674805, "training_acc": 68.66666666666667, "val_loss": 376.14402961730957, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1195.558886051178, "training_acc": 67.0, "val_loss": 332.4604768753052, "val_acc": 73.33333333333333}
{"epoch": 21, "training_loss": 620.6919240951538, "training_acc": 75.0, "val_loss": 100.48481959104538, "val_acc": 68.0}
{"epoch": 22, "training_loss": 1168.0431361198425, "training_acc": 66.66666666666667, "val_loss": 542.8473863601685, "val_acc": 33.333333333333336}
{"epoch": 23, "training_loss": 954.8616132736206, "training_acc": 68.66666666666667, "val_loss": 308.65486907958984, "val_acc": 54.666666666666664}
{"epoch": 24, "training_loss": 1228.5072765350342, "training_acc": 66.33333333333333, "val_loss": 123.56167316436768, "val_acc": 74.66666666666667}
{"epoch": 25, "training_loss": 826.2689597606659, "training_acc": 74.0, "val_loss": 177.3933870792389, "val_acc": 58.666666666666664}
{"epoch": 26, "training_loss": 808.106680393219, "training_acc": 70.33333333333333, "val_loss": 107.02795493602753, "val_acc": 69.33333333333333}
{"epoch": 27, "training_loss": 268.0852859020233, "training_acc": 81.0, "val_loss": 87.03003437817097, "val_acc": 77.33333333333333}
{"epoch": 28, "training_loss": 220.6528663635254, "training_acc": 80.0, "val_loss": 96.37997245788574, "val_acc": 70.66666666666667}
{"epoch": 29, "training_loss": 274.2949676513672, "training_acc": 79.66666666666667, "val_loss": 104.29600405693054, "val_acc": 73.33333333333333}
{"epoch": 30, "training_loss": 675.1550388336182, "training_acc": 72.0, "val_loss": 607.2291021347046, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2175.7107696533203, "training_acc": 60.0, "val_loss": 1356.9088115692139, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3599.4943771362305, "training_acc": 61.0, "val_loss": 381.53873443603516, "val_acc": 77.33333333333333}
{"epoch": 33, "training_loss": 1690.6209449768066, "training_acc": 75.66666666666667, "val_loss": 287.9233073592186, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1075.3626699447632, "training_acc": 73.33333333333333, "val_loss": 154.84192764759064, "val_acc": 74.66666666666667}
{"epoch": 35, "training_loss": 929.8406343460083, "training_acc": 69.0, "val_loss": 316.3854427933693, "val_acc": 72.0}
{"epoch": 36, "training_loss": 671.9998626708984, "training_acc": 75.0, "val_loss": 212.98387575149536, "val_acc": 66.66666666666667}
{"epoch": 37, "training_loss": 694.7852382659912, "training_acc": 75.0, "val_loss": 114.43465518951416, "val_acc": 80.0}
{"epoch": 38, "training_loss": 812.8069381713867, "training_acc": 70.66666666666667, "val_loss": 519.1946310997009, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1508.8151931762695, "training_acc": 65.0, "val_loss": 1074.8419675827026, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3108.194347381592, "training_acc": 61.333333333333336, "val_loss": 553.6084742546082, "val_acc": 72.0}
{"epoch": 41, "training_loss": 2854.553024291992, "training_acc": 71.33333333333333, "val_loss": 812.1007070541382, "val_acc": 48.0}
{"epoch": 42, "training_loss": 2867.2344970703125, "training_acc": 62.666666666666664, "val_loss": 255.0134015083313, "val_acc": 76.0}
{"epoch": 43, "training_loss": 2091.8002967834473, "training_acc": 68.66666666666667, "val_loss": 408.5590362548828, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1250.642723083496, "training_acc": 76.33333333333333, "val_loss": 505.72771549224854, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1274.5933628082275, "training_acc": 72.0, "val_loss": 609.0679061412811, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1574.1596202850342, "training_acc": 67.66666666666667, "val_loss": 397.044472694397, "val_acc": 72.0}
