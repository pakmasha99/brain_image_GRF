"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 300 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3523.794532775879, "training_acc": 64.33333333333333, "val_loss": 1250.8007354736328, "val_acc": 26.666666666666668}
{"epoch": 1, "training_loss": 2973.512092590332, "training_acc": 61.666666666666664, "val_loss": 1003.227744102478, "val_acc": 73.33333333333333}
{"epoch": 2, "training_loss": 2599.357021331787, "training_acc": 67.0, "val_loss": 523.9822688102722, "val_acc": 49.333333333333336}
{"epoch": 3, "training_loss": 1439.1278629302979, "training_acc": 64.66666666666667, "val_loss": 403.5247082710266, "val_acc": 74.66666666666667}
{"epoch": 4, "training_loss": 1401.032693862915, "training_acc": 73.66666666666667, "val_loss": 357.749306678772, "val_acc": 41.333333333333336}
{"epoch": 5, "training_loss": 1057.660457611084, "training_acc": 63.333333333333336, "val_loss": 91.19143044948578, "val_acc": 66.66666666666667}
{"epoch": 6, "training_loss": 728.0048599243164, "training_acc": 60.0, "val_loss": 291.29010474681854, "val_acc": 73.33333333333333}
{"epoch": 7, "training_loss": 703.3079423904419, "training_acc": 65.66666666666667, "val_loss": 173.1768548488617, "val_acc": 73.33333333333333}
{"epoch": 8, "training_loss": 688.5610036849976, "training_acc": 62.333333333333336, "val_loss": 83.31308031082153, "val_acc": 73.33333333333333}
{"epoch": 9, "training_loss": 672.5801811218262, "training_acc": 63.333333333333336, "val_loss": 57.07182116806507, "val_acc": 77.33333333333333}
{"epoch": 10, "training_loss": 438.72266578674316, "training_acc": 72.33333333333333, "val_loss": 47.3041558265686, "val_acc": 78.66666666666667}
{"epoch": 11, "training_loss": 267.0485882759094, "training_acc": 73.0, "val_loss": 46.50887459516525, "val_acc": 72.0}
{"epoch": 12, "training_loss": 170.27449250221252, "training_acc": 74.0, "val_loss": 44.09088534116745, "val_acc": 69.33333333333333}
{"epoch": 13, "training_loss": 224.11191153526306, "training_acc": 68.33333333333333, "val_loss": 77.72162938117981, "val_acc": 73.33333333333333}
{"epoch": 14, "training_loss": 246.6389195919037, "training_acc": 71.0, "val_loss": 52.72021144628525, "val_acc": 60.0}
{"epoch": 15, "training_loss": 186.09638595581055, "training_acc": 72.33333333333333, "val_loss": 83.62495565414429, "val_acc": 73.33333333333333}
{"epoch": 16, "training_loss": 271.8550465106964, "training_acc": 66.66666666666667, "val_loss": 28.712034225463867, "val_acc": 81.33333333333333}
{"epoch": 17, "training_loss": 293.48262572288513, "training_acc": 69.33333333333333, "val_loss": 176.7212302684784, "val_acc": 30.666666666666668}
{"epoch": 18, "training_loss": 522.0644636154175, "training_acc": 61.666666666666664, "val_loss": 94.61853969097137, "val_acc": 61.333333333333336}
{"epoch": 19, "training_loss": 512.6441366672516, "training_acc": 71.33333333333333, "val_loss": 194.73065280914307, "val_acc": 44.0}
{"epoch": 20, "training_loss": 705.1531202793121, "training_acc": 65.0, "val_loss": 50.95482361316681, "val_acc": 78.66666666666667}
{"epoch": 21, "training_loss": 535.9633779525757, "training_acc": 67.33333333333333, "val_loss": 45.587469696998596, "val_acc": 81.33333333333333}
{"epoch": 22, "training_loss": 633.4652404785156, "training_acc": 63.0, "val_loss": 147.84168696403503, "val_acc": 73.33333333333333}
{"epoch": 23, "training_loss": 467.1059923171997, "training_acc": 64.0, "val_loss": 39.64182108640671, "val_acc": 82.66666666666667}
{"epoch": 24, "training_loss": 487.50768089294434, "training_acc": 67.0, "val_loss": 98.81775307655334, "val_acc": 73.33333333333333}
{"epoch": 25, "training_loss": 210.5532729625702, "training_acc": 77.33333333333333, "val_loss": 31.6221866607666, "val_acc": 80.0}
{"epoch": 26, "training_loss": 154.89949870109558, "training_acc": 80.0, "val_loss": 80.87315547466278, "val_acc": 72.0}
{"epoch": 27, "training_loss": 406.38971281051636, "training_acc": 66.66666666666667, "val_loss": 40.25417944416404, "val_acc": 84.0}
{"epoch": 28, "training_loss": 409.06201934814453, "training_acc": 70.0, "val_loss": 57.48103591799736, "val_acc": 82.66666666666667}
{"epoch": 29, "training_loss": 325.03544425964355, "training_acc": 74.33333333333333, "val_loss": 34.239330887794495, "val_acc": 81.33333333333333}
{"epoch": 30, "training_loss": 255.01889991760254, "training_acc": 77.33333333333333, "val_loss": 94.46863651275635, "val_acc": 72.0}
{"epoch": 31, "training_loss": 497.08992195129395, "training_acc": 64.66666666666667, "val_loss": 51.478792905807495, "val_acc": 64.0}
{"epoch": 32, "training_loss": 427.30805349349976, "training_acc": 65.66666666666667, "val_loss": 86.9703928232193, "val_acc": 68.0}
{"epoch": 33, "training_loss": 386.2900516986847, "training_acc": 71.66666666666667, "val_loss": 65.86711120605469, "val_acc": 68.0}
{"epoch": 34, "training_loss": 336.94702911376953, "training_acc": 70.0, "val_loss": 63.70189905166626, "val_acc": 58.666666666666664}
{"epoch": 35, "training_loss": 195.50042748451233, "training_acc": 73.66666666666667, "val_loss": 44.53245371580124, "val_acc": 78.66666666666667}
