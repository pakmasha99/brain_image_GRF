"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 297.3343086242676, "training_acc": 72.0, "val_loss": 101.44919157028198, "val_acc": 72.0}
{"epoch": 1, "training_loss": 247.86805081367493, "training_acc": 73.0, "val_loss": 181.45986795425415, "val_acc": 28.0}
{"epoch": 2, "training_loss": 628.0656986236572, "training_acc": 28.0, "val_loss": 31.430205702781677, "val_acc": 72.0}
{"epoch": 3, "training_loss": 184.5102310180664, "training_acc": 72.0, "val_loss": 83.16180109977722, "val_acc": 72.0}
{"epoch": 4, "training_loss": 322.5356283187866, "training_acc": 72.0, "val_loss": 44.88830864429474, "val_acc": 72.0}
{"epoch": 5, "training_loss": 168.92415142059326, "training_acc": 70.0, "val_loss": 34.28286612033844, "val_acc": 36.0}
{"epoch": 6, "training_loss": 181.17920541763306, "training_acc": 44.0, "val_loss": 12.523557245731354, "val_acc": 76.0}
{"epoch": 7, "training_loss": 84.17213034629822, "training_acc": 79.0, "val_loss": 36.60590946674347, "val_acc": 72.0}
{"epoch": 8, "training_loss": 135.34822034835815, "training_acc": 72.0, "val_loss": 12.281632423400879, "val_acc": 72.0}
{"epoch": 9, "training_loss": 80.79895257949829, "training_acc": 61.0, "val_loss": 15.207366645336151, "val_acc": 56.0}
{"epoch": 10, "training_loss": 79.82688975334167, "training_acc": 60.0, "val_loss": 23.187941312789917, "val_acc": 72.0}
{"epoch": 11, "training_loss": 82.51830244064331, "training_acc": 72.0, "val_loss": 12.903900444507599, "val_acc": 68.0}
{"epoch": 12, "training_loss": 63.81013512611389, "training_acc": 59.0, "val_loss": 13.488936424255371, "val_acc": 68.0}
{"epoch": 13, "training_loss": 52.18263781070709, "training_acc": 72.0, "val_loss": 17.33730137348175, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.005165815353394, "training_acc": 72.0, "val_loss": 16.91594272851944, "val_acc": 32.0}
{"epoch": 15, "training_loss": 67.81778311729431, "training_acc": 58.0, "val_loss": 14.384336769580841, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.13050675392151, "training_acc": 72.0, "val_loss": 12.357999384403229, "val_acc": 80.0}
{"epoch": 17, "training_loss": 63.00074315071106, "training_acc": 64.0, "val_loss": 13.935945928096771, "val_acc": 72.0}
{"epoch": 18, "training_loss": 66.24025082588196, "training_acc": 72.0, "val_loss": 12.84666359424591, "val_acc": 72.0}
{"epoch": 19, "training_loss": 69.45790433883667, "training_acc": 59.0, "val_loss": 12.709087133407593, "val_acc": 76.0}
{"epoch": 20, "training_loss": 53.30988907814026, "training_acc": 72.0, "val_loss": 14.77193534374237, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50.26711344718933, "training_acc": 77.0, "val_loss": 15.668542683124542, "val_acc": 56.0}
{"epoch": 22, "training_loss": 68.76933670043945, "training_acc": 62.0, "val_loss": 16.18737429380417, "val_acc": 72.0}
{"epoch": 23, "training_loss": 62.29342007637024, "training_acc": 72.0, "val_loss": 11.840669065713882, "val_acc": 80.0}
{"epoch": 24, "training_loss": 57.56407713890076, "training_acc": 69.0, "val_loss": 12.82692551612854, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.21333360671997, "training_acc": 73.0, "val_loss": 13.096988201141357, "val_acc": 76.0}
{"epoch": 26, "training_loss": 54.1695077419281, "training_acc": 74.0, "val_loss": 13.386744260787964, "val_acc": 72.0}
{"epoch": 27, "training_loss": 52.8851592540741, "training_acc": 74.0, "val_loss": 13.420146703720093, "val_acc": 72.0}
{"epoch": 28, "training_loss": 54.95790719985962, "training_acc": 73.0, "val_loss": 13.393312692642212, "val_acc": 72.0}
{"epoch": 29, "training_loss": 52.56455183029175, "training_acc": 74.0, "val_loss": 12.954963743686676, "val_acc": 76.0}
{"epoch": 30, "training_loss": 55.73532700538635, "training_acc": 74.0, "val_loss": 14.281326532363892, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.87571740150452, "training_acc": 72.0, "val_loss": 12.965263426303864, "val_acc": 68.0}
{"epoch": 32, "training_loss": 60.35356426239014, "training_acc": 73.0, "val_loss": 14.557085931301117, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.42460262775421, "training_acc": 72.0, "val_loss": 12.650185823440552, "val_acc": 72.0}
{"epoch": 34, "training_loss": 51.07002639770508, "training_acc": 76.0, "val_loss": 12.388832122087479, "val_acc": 76.0}
{"epoch": 35, "training_loss": 51.987911224365234, "training_acc": 75.0, "val_loss": 13.08266669511795, "val_acc": 72.0}
{"epoch": 36, "training_loss": 53.58332324028015, "training_acc": 70.0, "val_loss": 12.383796274662018, "val_acc": 80.0}
{"epoch": 37, "training_loss": 57.74447989463806, "training_acc": 74.0, "val_loss": 12.62025386095047, "val_acc": 68.0}
{"epoch": 38, "training_loss": 53.27298712730408, "training_acc": 77.0, "val_loss": 12.324666976928711, "val_acc": 80.0}
{"epoch": 39, "training_loss": 55.29903602600098, "training_acc": 72.0, "val_loss": 12.735843658447266, "val_acc": 68.0}
{"epoch": 40, "training_loss": 54.008177757263184, "training_acc": 76.0, "val_loss": 12.039311975240707, "val_acc": 80.0}
{"epoch": 41, "training_loss": 49.36381721496582, "training_acc": 78.0, "val_loss": 12.002435326576233, "val_acc": 80.0}
{"epoch": 42, "training_loss": 53.403005599975586, "training_acc": 73.0, "val_loss": 15.251186490058899, "val_acc": 72.0}
