"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 422.2951240539551, "training_acc": 32.0, "val_loss": 106.90797567367554, "val_acc": 72.0}
{"epoch": 1, "training_loss": 321.8483304977417, "training_acc": 72.0, "val_loss": 119.53781843185425, "val_acc": 28.0}
{"epoch": 2, "training_loss": 513.2494506835938, "training_acc": 28.0, "val_loss": 20.597250759601593, "val_acc": 72.0}
{"epoch": 3, "training_loss": 131.26867961883545, "training_acc": 67.0, "val_loss": 70.39429545402527, "val_acc": 72.0}
{"epoch": 4, "training_loss": 240.76693677902222, "training_acc": 72.0, "val_loss": 38.14418017864227, "val_acc": 72.0}
{"epoch": 5, "training_loss": 92.50543165206909, "training_acc": 68.0, "val_loss": 34.94303822517395, "val_acc": 48.0}
{"epoch": 6, "training_loss": 168.67527079582214, "training_acc": 49.0, "val_loss": 24.781925976276398, "val_acc": 72.0}
{"epoch": 7, "training_loss": 97.41578578948975, "training_acc": 69.0, "val_loss": 33.846861124038696, "val_acc": 72.0}
{"epoch": 8, "training_loss": 93.06152296066284, "training_acc": 74.0, "val_loss": 19.243356585502625, "val_acc": 56.0}
{"epoch": 9, "training_loss": 87.80705523490906, "training_acc": 54.0, "val_loss": 17.816640436649323, "val_acc": 72.0}
{"epoch": 10, "training_loss": 66.66375088691711, "training_acc": 74.0, "val_loss": 19.392620027065277, "val_acc": 72.0}
{"epoch": 11, "training_loss": 57.245490074157715, "training_acc": 73.0, "val_loss": 22.201628983020782, "val_acc": 36.0}
{"epoch": 12, "training_loss": 81.0268075466156, "training_acc": 45.0, "val_loss": 18.449632823467255, "val_acc": 72.0}
{"epoch": 13, "training_loss": 70.93748831748962, "training_acc": 72.0, "val_loss": 14.483393728733063, "val_acc": 72.0}
{"epoch": 14, "training_loss": 69.18689012527466, "training_acc": 60.0, "val_loss": 13.589784502983093, "val_acc": 72.0}
{"epoch": 15, "training_loss": 52.797141790390015, "training_acc": 75.0, "val_loss": 16.36163741350174, "val_acc": 72.0}
{"epoch": 16, "training_loss": 55.22674894332886, "training_acc": 72.0, "val_loss": 14.558511972427368, "val_acc": 56.0}
{"epoch": 17, "training_loss": 54.66464281082153, "training_acc": 74.0, "val_loss": 15.16856700181961, "val_acc": 72.0}
{"epoch": 18, "training_loss": 54.12330400943756, "training_acc": 75.0, "val_loss": 14.586356282234192, "val_acc": 76.0}
{"epoch": 19, "training_loss": 54.083309173583984, "training_acc": 74.0, "val_loss": 14.124611020088196, "val_acc": 76.0}
{"epoch": 20, "training_loss": 51.48673677444458, "training_acc": 78.0, "val_loss": 13.792459666728973, "val_acc": 76.0}
{"epoch": 21, "training_loss": 52.16690707206726, "training_acc": 74.0, "val_loss": 14.529651403427124, "val_acc": 60.0}
{"epoch": 22, "training_loss": 57.1532678604126, "training_acc": 72.0, "val_loss": 15.720759332180023, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.983365535736084, "training_acc": 72.0, "val_loss": 13.980233669281006, "val_acc": 56.0}
{"epoch": 24, "training_loss": 57.70014524459839, "training_acc": 70.0, "val_loss": 15.541847050189972, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.893637895584106, "training_acc": 72.0, "val_loss": 13.71990293264389, "val_acc": 72.0}
{"epoch": 26, "training_loss": 50.18749690055847, "training_acc": 78.0, "val_loss": 13.939911127090454, "val_acc": 64.0}
{"epoch": 27, "training_loss": 54.386723041534424, "training_acc": 71.0, "val_loss": 14.776559174060822, "val_acc": 72.0}
{"epoch": 28, "training_loss": 51.48418843746185, "training_acc": 75.0, "val_loss": 13.99558037519455, "val_acc": 60.0}
{"epoch": 29, "training_loss": 57.47518610954285, "training_acc": 67.0, "val_loss": 14.403040707111359, "val_acc": 76.0}
{"epoch": 30, "training_loss": 55.979318380355835, "training_acc": 72.0, "val_loss": 15.518529713153839, "val_acc": 72.0}
{"epoch": 31, "training_loss": 50.79226529598236, "training_acc": 76.0, "val_loss": 15.27160108089447, "val_acc": 72.0}
{"epoch": 32, "training_loss": 55.464622259140015, "training_acc": 76.0, "val_loss": 14.544224739074707, "val_acc": 72.0}
{"epoch": 33, "training_loss": 52.42853116989136, "training_acc": 74.0, "val_loss": 13.678863644599915, "val_acc": 72.0}
