"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 134.12742519378662, "training_acc": 72.0, "val_loss": 35.576942563056946, "val_acc": 72.0}
{"epoch": 1, "training_loss": 98.96017646789551, "training_acc": 72.0, "val_loss": 35.638052225112915, "val_acc": 28.0}
{"epoch": 2, "training_loss": 135.5010120868683, "training_acc": 29.0, "val_loss": 14.582991600036621, "val_acc": 56.0}
{"epoch": 3, "training_loss": 67.65725612640381, "training_acc": 70.0, "val_loss": 24.540874361991882, "val_acc": 72.0}
{"epoch": 4, "training_loss": 95.49580502510071, "training_acc": 72.0, "val_loss": 20.928050577640533, "val_acc": 72.0}
{"epoch": 5, "training_loss": 74.62084209918976, "training_acc": 72.0, "val_loss": 14.134746789932251, "val_acc": 56.0}
{"epoch": 6, "training_loss": 65.21282720565796, "training_acc": 66.0, "val_loss": 18.04734915494919, "val_acc": 60.0}
{"epoch": 7, "training_loss": 74.33703970909119, "training_acc": 61.0, "val_loss": 13.66966962814331, "val_acc": 76.0}
{"epoch": 8, "training_loss": 59.39047884941101, "training_acc": 78.0, "val_loss": 16.79392158985138, "val_acc": 72.0}
{"epoch": 9, "training_loss": 67.94748377799988, "training_acc": 72.0, "val_loss": 13.849765062332153, "val_acc": 76.0}
{"epoch": 10, "training_loss": 54.88373875617981, "training_acc": 74.0, "val_loss": 14.212329685688019, "val_acc": 56.0}
{"epoch": 11, "training_loss": 60.63244557380676, "training_acc": 63.0, "val_loss": 13.276414573192596, "val_acc": 56.0}
{"epoch": 12, "training_loss": 52.93297505378723, "training_acc": 73.0, "val_loss": 13.48140686750412, "val_acc": 80.0}
{"epoch": 13, "training_loss": 54.01194715499878, "training_acc": 72.0, "val_loss": 14.624138176441193, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.38932645320892, "training_acc": 72.0, "val_loss": 12.93088048696518, "val_acc": 68.0}
{"epoch": 15, "training_loss": 51.83716678619385, "training_acc": 77.0, "val_loss": 13.292190432548523, "val_acc": 64.0}
{"epoch": 16, "training_loss": 53.779534578323364, "training_acc": 77.0, "val_loss": 12.996488809585571, "val_acc": 68.0}
{"epoch": 17, "training_loss": 53.06969594955444, "training_acc": 72.0, "val_loss": 13.890555500984192, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.5732262134552, "training_acc": 72.0, "val_loss": 12.983250617980957, "val_acc": 72.0}
{"epoch": 19, "training_loss": 50.44180202484131, "training_acc": 77.0, "val_loss": 13.832588493824005, "val_acc": 56.0}
{"epoch": 20, "training_loss": 52.78319001197815, "training_acc": 78.0, "val_loss": 12.874262034893036, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50.25882709026337, "training_acc": 75.0, "val_loss": 14.123161137104034, "val_acc": 76.0}
{"epoch": 22, "training_loss": 55.99725031852722, "training_acc": 72.0, "val_loss": 12.540312111377716, "val_acc": 68.0}
{"epoch": 23, "training_loss": 49.47286343574524, "training_acc": 75.0, "val_loss": 13.335169851779938, "val_acc": 68.0}
{"epoch": 24, "training_loss": 53.88853192329407, "training_acc": 74.0, "val_loss": 12.481105327606201, "val_acc": 68.0}
{"epoch": 25, "training_loss": 50.137638449668884, "training_acc": 76.0, "val_loss": 13.166780769824982, "val_acc": 80.0}
{"epoch": 26, "training_loss": 49.242517948150635, "training_acc": 74.0, "val_loss": 12.497051060199738, "val_acc": 72.0}
{"epoch": 27, "training_loss": 51.159786105155945, "training_acc": 78.0, "val_loss": 12.52737045288086, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.248640298843384, "training_acc": 76.0, "val_loss": 12.9513218998909, "val_acc": 76.0}
{"epoch": 29, "training_loss": 48.14957082271576, "training_acc": 75.0, "val_loss": 12.51988559961319, "val_acc": 68.0}
{"epoch": 30, "training_loss": 47.782877922058105, "training_acc": 78.0, "val_loss": 12.50695139169693, "val_acc": 68.0}
{"epoch": 31, "training_loss": 47.06190288066864, "training_acc": 80.0, "val_loss": 12.489884346723557, "val_acc": 72.0}
{"epoch": 32, "training_loss": 47.58004975318909, "training_acc": 77.0, "val_loss": 12.866590917110443, "val_acc": 72.0}
{"epoch": 33, "training_loss": 46.14722275733948, "training_acc": 77.0, "val_loss": 12.597455084323883, "val_acc": 68.0}
{"epoch": 34, "training_loss": 47.076297760009766, "training_acc": 77.0, "val_loss": 12.582159042358398, "val_acc": 68.0}
{"epoch": 35, "training_loss": 45.94417226314545, "training_acc": 80.0, "val_loss": 12.98789232969284, "val_acc": 72.0}
{"epoch": 36, "training_loss": 48.86205458641052, "training_acc": 78.0, "val_loss": 12.968279421329498, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.68765664100647, "training_acc": 76.0, "val_loss": 12.77809739112854, "val_acc": 68.0}
{"epoch": 38, "training_loss": 44.96308350563049, "training_acc": 79.0, "val_loss": 13.137519359588623, "val_acc": 72.0}
{"epoch": 39, "training_loss": 47.77691042423248, "training_acc": 76.0, "val_loss": 13.128824532032013, "val_acc": 72.0}
{"epoch": 40, "training_loss": 46.13143026828766, "training_acc": 79.0, "val_loss": 13.15048635005951, "val_acc": 68.0}
{"epoch": 41, "training_loss": 46.277246713638306, "training_acc": 80.0, "val_loss": 13.164709508419037, "val_acc": 68.0}
{"epoch": 42, "training_loss": 46.72775483131409, "training_acc": 78.0, "val_loss": 13.148291409015656, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.77020835876465, "training_acc": 80.0, "val_loss": 13.070060312747955, "val_acc": 68.0}
