"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1743.6491813659668, "training_acc": 72.0, "val_loss": 752.4550437927246, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2050.225109100342, "training_acc": 72.0, "val_loss": 1178.494930267334, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4931.460983276367, "training_acc": 28.0, "val_loss": 214.19012546539307, "val_acc": 36.0}
{"epoch": 3, "training_loss": 1305.8648414611816, "training_acc": 51.0, "val_loss": 672.9618549346924, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3027.398635864258, "training_acc": 72.0, "val_loss": 898.2436180114746, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3585.388557434082, "training_acc": 72.0, "val_loss": 665.0123119354248, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2338.195873260498, "training_acc": 72.0, "val_loss": 146.80099487304688, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1220.0327987670898, "training_acc": 65.0, "val_loss": 267.2285795211792, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1950.6137008666992, "training_acc": 45.0, "val_loss": 89.4987165927887, "val_acc": 84.0}
{"epoch": 9, "training_loss": 910.7188816070557, "training_acc": 71.0, "val_loss": 232.82842636108398, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1038.2761611938477, "training_acc": 73.0, "val_loss": 277.91223526000977, "val_acc": 72.0}
{"epoch": 11, "training_loss": 894.4611854553223, "training_acc": 71.0, "val_loss": 55.94545006752014, "val_acc": 80.0}
{"epoch": 12, "training_loss": 562.9326820373535, "training_acc": 63.0, "val_loss": 99.32240843772888, "val_acc": 56.0}
{"epoch": 13, "training_loss": 432.722900390625, "training_acc": 63.0, "val_loss": 174.73894357681274, "val_acc": 72.0}
{"epoch": 14, "training_loss": 645.1089782714844, "training_acc": 72.0, "val_loss": 131.5150260925293, "val_acc": 72.0}
{"epoch": 15, "training_loss": 334.61395168304443, "training_acc": 67.0, "val_loss": 99.92793798446655, "val_acc": 52.0}
{"epoch": 16, "training_loss": 393.7973985671997, "training_acc": 59.0, "val_loss": 106.45276308059692, "val_acc": 72.0}
{"epoch": 17, "training_loss": 282.1850049495697, "training_acc": 68.0, "val_loss": 40.75902700424194, "val_acc": 56.0}
{"epoch": 18, "training_loss": 176.99912071228027, "training_acc": 59.0, "val_loss": 34.30398106575012, "val_acc": 76.0}
{"epoch": 19, "training_loss": 179.8826723098755, "training_acc": 67.0, "val_loss": 16.01816564798355, "val_acc": 84.0}
{"epoch": 20, "training_loss": 107.65641117095947, "training_acc": 81.0, "val_loss": 44.74902153015137, "val_acc": 72.0}
{"epoch": 21, "training_loss": 129.4551477432251, "training_acc": 81.0, "val_loss": 106.77099227905273, "val_acc": 44.0}
{"epoch": 22, "training_loss": 317.04473543167114, "training_acc": 54.0, "val_loss": 83.65470170974731, "val_acc": 72.0}
{"epoch": 23, "training_loss": 271.8705081939697, "training_acc": 72.0, "val_loss": 48.02227020263672, "val_acc": 52.0}
{"epoch": 24, "training_loss": 134.3459599018097, "training_acc": 64.0, "val_loss": 46.17902934551239, "val_acc": 72.0}
{"epoch": 25, "training_loss": 102.23970353603363, "training_acc": 78.0, "val_loss": 66.70833230018616, "val_acc": 48.0}
{"epoch": 26, "training_loss": 183.85929346084595, "training_acc": 60.0, "val_loss": 49.74868297576904, "val_acc": 72.0}
{"epoch": 27, "training_loss": 158.53153276443481, "training_acc": 65.0, "val_loss": 17.226438224315643, "val_acc": 72.0}
{"epoch": 28, "training_loss": 78.4763731956482, "training_acc": 82.0, "val_loss": 22.97288328409195, "val_acc": 76.0}
{"epoch": 29, "training_loss": 120.49502658843994, "training_acc": 73.0, "val_loss": 20.70966064929962, "val_acc": 84.0}
{"epoch": 30, "training_loss": 58.680744379758835, "training_acc": 81.0, "val_loss": 19.270770251750946, "val_acc": 84.0}
{"epoch": 31, "training_loss": 41.404526352882385, "training_acc": 82.0, "val_loss": 33.39228630065918, "val_acc": 56.0}
{"epoch": 32, "training_loss": 112.2440767288208, "training_acc": 70.0, "val_loss": 57.84190893173218, "val_acc": 72.0}
{"epoch": 33, "training_loss": 182.44205570220947, "training_acc": 62.0, "val_loss": 30.4177463054657, "val_acc": 64.0}
{"epoch": 34, "training_loss": 81.14341640472412, "training_acc": 77.0, "val_loss": 30.59067130088806, "val_acc": 56.0}
{"epoch": 35, "training_loss": 73.96274638175964, "training_acc": 73.0, "val_loss": 38.32909166812897, "val_acc": 72.0}
{"epoch": 36, "training_loss": 75.89142382144928, "training_acc": 82.0, "val_loss": 23.73874932527542, "val_acc": 64.0}
{"epoch": 37, "training_loss": 86.18930959701538, "training_acc": 74.0, "val_loss": 13.80549818277359, "val_acc": 88.0}
{"epoch": 38, "training_loss": 48.551555156707764, "training_acc": 87.0, "val_loss": 14.694814383983612, "val_acc": 76.0}
{"epoch": 39, "training_loss": 79.73825550079346, "training_acc": 81.0, "val_loss": 13.794669508934021, "val_acc": 80.0}
{"epoch": 40, "training_loss": 54.614837646484375, "training_acc": 83.0, "val_loss": 15.626218914985657, "val_acc": 84.0}
{"epoch": 41, "training_loss": 47.925177812576294, "training_acc": 83.0, "val_loss": 22.831344604492188, "val_acc": 64.0}
{"epoch": 42, "training_loss": 60.89929986000061, "training_acc": 80.0, "val_loss": 23.431554436683655, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.51920700073242, "training_acc": 87.0, "val_loss": 17.523010075092316, "val_acc": 76.0}
{"epoch": 44, "training_loss": 40.27269983291626, "training_acc": 85.0, "val_loss": 27.00342833995819, "val_acc": 56.0}
{"epoch": 45, "training_loss": 43.34755861759186, "training_acc": 83.0, "val_loss": 43.69121491909027, "val_acc": 72.0}
{"epoch": 46, "training_loss": 76.04260432720184, "training_acc": 75.0, "val_loss": 18.559302389621735, "val_acc": 76.0}
{"epoch": 47, "training_loss": 48.58274793624878, "training_acc": 89.0, "val_loss": 19.398675858974457, "val_acc": 72.0}
{"epoch": 48, "training_loss": 22.65123361349106, "training_acc": 93.0, "val_loss": 29.756280779838562, "val_acc": 64.0}
{"epoch": 49, "training_loss": 32.92734372615814, "training_acc": 87.0, "val_loss": 31.294560432434082, "val_acc": 68.0}
{"epoch": 50, "training_loss": 40.537705063819885, "training_acc": 82.0, "val_loss": 18.39509904384613, "val_acc": 72.0}
{"epoch": 51, "training_loss": 25.885209918022156, "training_acc": 90.0, "val_loss": 15.020610392093658, "val_acc": 76.0}
{"epoch": 52, "training_loss": 32.03935053944588, "training_acc": 85.0, "val_loss": 16.54009073972702, "val_acc": 80.0}
{"epoch": 53, "training_loss": 44.9602267742157, "training_acc": 81.0, "val_loss": 46.25146687030792, "val_acc": 72.0}
{"epoch": 54, "training_loss": 91.28388798236847, "training_acc": 81.0, "val_loss": 58.581894636154175, "val_acc": 48.0}
{"epoch": 55, "training_loss": 225.48994255065918, "training_acc": 59.0, "val_loss": 140.5193328857422, "val_acc": 72.0}
{"epoch": 56, "training_loss": 392.41103982925415, "training_acc": 73.0, "val_loss": 158.97839069366455, "val_acc": 28.0}
{"epoch": 57, "training_loss": 414.9608414173126, "training_acc": 53.0, "val_loss": 92.98025369644165, "val_acc": 72.0}
{"epoch": 58, "training_loss": 272.64445781707764, "training_acc": 72.0, "val_loss": 71.93357944488525, "val_acc": 52.0}
