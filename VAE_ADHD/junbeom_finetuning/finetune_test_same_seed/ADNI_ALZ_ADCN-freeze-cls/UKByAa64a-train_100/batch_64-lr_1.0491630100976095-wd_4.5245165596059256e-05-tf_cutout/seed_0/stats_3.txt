"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 999.2782287597656, "training_acc": 72.0, "val_loss": 698.7608432769775, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1869.551547050476, "training_acc": 65.0, "val_loss": 824.9374389648438, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2083.2314281463623, "training_acc": 47.0, "val_loss": 405.38220405578613, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1752.5353546142578, "training_acc": 72.0, "val_loss": 562.7835750579834, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1884.916374206543, "training_acc": 72.0, "val_loss": 151.39257907867432, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1140.4380187988281, "training_acc": 52.0, "val_loss": 465.88048934936523, "val_acc": 44.0}
{"epoch": 6, "training_loss": 1192.9121990203857, "training_acc": 52.0, "val_loss": 222.18971252441406, "val_acc": 72.0}
{"epoch": 7, "training_loss": 889.1521339416504, "training_acc": 73.0, "val_loss": 404.9827575683594, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1423.667667388916, "training_acc": 72.0, "val_loss": 223.28619956970215, "val_acc": 72.0}
{"epoch": 9, "training_loss": 516.5806827545166, "training_acc": 76.0, "val_loss": 343.40593814849854, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1124.1451606750488, "training_acc": 52.0, "val_loss": 216.94273948669434, "val_acc": 68.0}
{"epoch": 11, "training_loss": 563.9902000427246, "training_acc": 72.0, "val_loss": 237.11395263671875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 831.0923142433167, "training_acc": 74.0, "val_loss": 162.51287460327148, "val_acc": 68.0}
{"epoch": 13, "training_loss": 389.8019428253174, "training_acc": 74.0, "val_loss": 185.08085012435913, "val_acc": 68.0}
{"epoch": 14, "training_loss": 394.3524446487427, "training_acc": 69.0, "val_loss": 86.4831805229187, "val_acc": 72.0}
{"epoch": 15, "training_loss": 216.100661277771, "training_acc": 77.0, "val_loss": 51.26505494117737, "val_acc": 72.0}
{"epoch": 16, "training_loss": 151.39978885650635, "training_acc": 70.0, "val_loss": 26.006239652633667, "val_acc": 76.0}
{"epoch": 17, "training_loss": 129.27547359466553, "training_acc": 74.0, "val_loss": 129.4006586074829, "val_acc": 36.0}
{"epoch": 18, "training_loss": 234.90386056900024, "training_acc": 56.0, "val_loss": 83.44675898551941, "val_acc": 72.0}
{"epoch": 19, "training_loss": 351.0812816619873, "training_acc": 72.0, "val_loss": 102.68306732177734, "val_acc": 36.0}
{"epoch": 20, "training_loss": 204.17630863189697, "training_acc": 55.0, "val_loss": 81.37392997741699, "val_acc": 72.0}
{"epoch": 21, "training_loss": 369.7858819961548, "training_acc": 72.0, "val_loss": 42.43687391281128, "val_acc": 80.0}
{"epoch": 22, "training_loss": 160.4278678894043, "training_acc": 77.0, "val_loss": 64.4512951374054, "val_acc": 68.0}
{"epoch": 23, "training_loss": 196.5493803024292, "training_acc": 72.0, "val_loss": 71.40756845474243, "val_acc": 80.0}
{"epoch": 24, "training_loss": 193.7233691215515, "training_acc": 80.0, "val_loss": 79.93835210800171, "val_acc": 56.0}
{"epoch": 25, "training_loss": 173.8434534072876, "training_acc": 69.0, "val_loss": 56.6244900226593, "val_acc": 80.0}
{"epoch": 26, "training_loss": 215.13409185409546, "training_acc": 77.0, "val_loss": 43.64171624183655, "val_acc": 64.0}
{"epoch": 27, "training_loss": 86.18476641178131, "training_acc": 72.0, "val_loss": 10.879741609096527, "val_acc": 88.0}
{"epoch": 28, "training_loss": 84.45403099060059, "training_acc": 78.0, "val_loss": 14.688202738761902, "val_acc": 68.0}
{"epoch": 29, "training_loss": 83.9175283908844, "training_acc": 73.0, "val_loss": 76.69546604156494, "val_acc": 40.0}
{"epoch": 30, "training_loss": 206.24203205108643, "training_acc": 58.0, "val_loss": 17.863379418849945, "val_acc": 84.0}
{"epoch": 31, "training_loss": 163.13106155395508, "training_acc": 64.0, "val_loss": 41.43141210079193, "val_acc": 84.0}
{"epoch": 32, "training_loss": 177.56261539459229, "training_acc": 76.0, "val_loss": 55.72637915611267, "val_acc": 72.0}
{"epoch": 33, "training_loss": 177.69011402130127, "training_acc": 72.0, "val_loss": 64.14706110954285, "val_acc": 72.0}
{"epoch": 34, "training_loss": 128.49192094802856, "training_acc": 80.0, "val_loss": 55.586713552474976, "val_acc": 76.0}
{"epoch": 35, "training_loss": 130.4833301305771, "training_acc": 86.0, "val_loss": 63.39294910430908, "val_acc": 60.0}
{"epoch": 36, "training_loss": 138.51900911331177, "training_acc": 71.0, "val_loss": 20.28915137052536, "val_acc": 72.0}
{"epoch": 37, "training_loss": 47.50835728645325, "training_acc": 84.0, "val_loss": 38.22806775569916, "val_acc": 44.0}
{"epoch": 38, "training_loss": 100.27938747406006, "training_acc": 74.0, "val_loss": 19.649839401245117, "val_acc": 68.0}
{"epoch": 39, "training_loss": 244.6964340209961, "training_acc": 57.0, "val_loss": 38.64317238330841, "val_acc": 72.0}
{"epoch": 40, "training_loss": 164.13778686523438, "training_acc": 72.0, "val_loss": 23.97369146347046, "val_acc": 64.0}
{"epoch": 41, "training_loss": 71.91920590400696, "training_acc": 74.0, "val_loss": 23.88067990541458, "val_acc": 84.0}
{"epoch": 42, "training_loss": 93.03736746311188, "training_acc": 79.0, "val_loss": 48.884835839271545, "val_acc": 60.0}
{"epoch": 43, "training_loss": 91.77335834503174, "training_acc": 75.0, "val_loss": 35.30077934265137, "val_acc": 80.0}
{"epoch": 44, "training_loss": 102.26459097862244, "training_acc": 76.0, "val_loss": 118.38548183441162, "val_acc": 36.0}
{"epoch": 45, "training_loss": 207.85794806480408, "training_acc": 64.0, "val_loss": 26.82228684425354, "val_acc": 84.0}
{"epoch": 46, "training_loss": 71.24916964769363, "training_acc": 83.0, "val_loss": 69.79014277458191, "val_acc": 44.0}
