"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1895.8182640075684, "training_acc": 38.0, "val_loss": 815.9793853759766, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2572.6979598999023, "training_acc": 72.0, "val_loss": 721.6742992401123, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2886.1998443603516, "training_acc": 28.0, "val_loss": 128.10510396957397, "val_acc": 68.0}
{"epoch": 3, "training_loss": 871.3162612915039, "training_acc": 70.0, "val_loss": 506.8800926208496, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1700.1052017211914, "training_acc": 72.0, "val_loss": 333.3285331726074, "val_acc": 72.0}
{"epoch": 5, "training_loss": 876.0770015716553, "training_acc": 74.0, "val_loss": 194.04985904693604, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1015.9051208496094, "training_acc": 56.0, "val_loss": 172.8322982788086, "val_acc": 76.0}
{"epoch": 7, "training_loss": 710.3386211395264, "training_acc": 67.0, "val_loss": 297.64132499694824, "val_acc": 72.0}
{"epoch": 8, "training_loss": 984.9291877746582, "training_acc": 72.0, "val_loss": 227.82645225524902, "val_acc": 76.0}
{"epoch": 9, "training_loss": 573.4730892181396, "training_acc": 73.0, "val_loss": 128.8283109664917, "val_acc": 68.0}
{"epoch": 10, "training_loss": 472.85939598083496, "training_acc": 71.0, "val_loss": 112.57543563842773, "val_acc": 68.0}
{"epoch": 11, "training_loss": 422.2978630065918, "training_acc": 70.0, "val_loss": 123.18238019943237, "val_acc": 72.0}
{"epoch": 12, "training_loss": 329.09599590301514, "training_acc": 66.0, "val_loss": 92.1312689781189, "val_acc": 52.0}
{"epoch": 13, "training_loss": 365.4766387939453, "training_acc": 59.0, "val_loss": 113.83775472640991, "val_acc": 72.0}
{"epoch": 14, "training_loss": 294.1669535636902, "training_acc": 72.0, "val_loss": 109.31694507598877, "val_acc": 52.0}
{"epoch": 15, "training_loss": 325.5692253112793, "training_acc": 52.0, "val_loss": 53.398895263671875, "val_acc": 68.0}
{"epoch": 16, "training_loss": 130.69996738433838, "training_acc": 73.0, "val_loss": 40.37348031997681, "val_acc": 68.0}
{"epoch": 17, "training_loss": 105.61302995681763, "training_acc": 80.0, "val_loss": 46.934568881988525, "val_acc": 72.0}
{"epoch": 18, "training_loss": 89.67046451568604, "training_acc": 84.0, "val_loss": 38.29593062400818, "val_acc": 72.0}
{"epoch": 19, "training_loss": 108.28189969062805, "training_acc": 77.0, "val_loss": 36.29528284072876, "val_acc": 72.0}
{"epoch": 20, "training_loss": 68.50462889671326, "training_acc": 85.0, "val_loss": 25.067773461341858, "val_acc": 60.0}
{"epoch": 21, "training_loss": 101.54226541519165, "training_acc": 73.0, "val_loss": 35.324421525001526, "val_acc": 64.0}
{"epoch": 22, "training_loss": 171.38279151916504, "training_acc": 60.0, "val_loss": 109.04266834259033, "val_acc": 72.0}
{"epoch": 23, "training_loss": 451.4401264190674, "training_acc": 72.0, "val_loss": 62.86692023277283, "val_acc": 72.0}
{"epoch": 24, "training_loss": 518.3318328857422, "training_acc": 52.0, "val_loss": 47.62643575668335, "val_acc": 64.0}
{"epoch": 25, "training_loss": 270.3364305496216, "training_acc": 68.0, "val_loss": 311.0685348510742, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1140.1090202331543, "training_acc": 72.0, "val_loss": 265.069580078125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 626.5268135070801, "training_acc": 73.0, "val_loss": 167.25878715515137, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1025.9193305969238, "training_acc": 45.0, "val_loss": 92.27970838546753, "val_acc": 80.0}
{"epoch": 29, "training_loss": 341.1694507598877, "training_acc": 74.0, "val_loss": 296.00791931152344, "val_acc": 72.0}
{"epoch": 30, "training_loss": 937.4213943481445, "training_acc": 72.0, "val_loss": 196.00378274917603, "val_acc": 72.0}
{"epoch": 31, "training_loss": 430.4193811416626, "training_acc": 77.0, "val_loss": 190.6087875366211, "val_acc": 52.0}
{"epoch": 32, "training_loss": 1038.4515266418457, "training_acc": 51.0, "val_loss": 90.59467911720276, "val_acc": 76.0}
{"epoch": 33, "training_loss": 312.88986587524414, "training_acc": 77.0, "val_loss": 246.8930959701538, "val_acc": 72.0}
{"epoch": 34, "training_loss": 670.5355958938599, "training_acc": 72.0, "val_loss": 79.22677397727966, "val_acc": 68.0}
{"epoch": 35, "training_loss": 154.59541034698486, "training_acc": 75.0, "val_loss": 90.50241112709045, "val_acc": 56.0}
{"epoch": 36, "training_loss": 286.6536793708801, "training_acc": 56.0, "val_loss": 122.55221605300903, "val_acc": 72.0}
{"epoch": 37, "training_loss": 242.68390607833862, "training_acc": 77.0, "val_loss": 61.319077014923096, "val_acc": 48.0}
{"epoch": 38, "training_loss": 139.4653835296631, "training_acc": 70.0, "val_loss": 83.04251432418823, "val_acc": 68.0}
{"epoch": 39, "training_loss": 158.56513118743896, "training_acc": 77.0, "val_loss": 49.637120962142944, "val_acc": 52.0}
