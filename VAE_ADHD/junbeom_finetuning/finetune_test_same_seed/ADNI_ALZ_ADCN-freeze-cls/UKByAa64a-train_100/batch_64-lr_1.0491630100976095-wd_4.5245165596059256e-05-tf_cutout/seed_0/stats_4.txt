"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1058.8589630126953, "training_acc": 70.0, "val_loss": 798.4883785247803, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2409.103691101074, "training_acc": 72.0, "val_loss": 1104.3862342834473, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4660.9006271362305, "training_acc": 28.0, "val_loss": 95.06780505180359, "val_acc": 64.0}
{"epoch": 3, "training_loss": 1083.7708435058594, "training_acc": 61.0, "val_loss": 651.9838809967041, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2503.766632080078, "training_acc": 72.0, "val_loss": 631.4314365386963, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2092.928092956543, "training_acc": 72.0, "val_loss": 220.48075199127197, "val_acc": 68.0}
{"epoch": 6, "training_loss": 997.2084541320801, "training_acc": 58.0, "val_loss": 307.9002618789673, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1621.7150535583496, "training_acc": 52.0, "val_loss": 162.3238205909729, "val_acc": 72.0}
{"epoch": 8, "training_loss": 525.5511665344238, "training_acc": 75.0, "val_loss": 333.68539810180664, "val_acc": 72.0}
{"epoch": 9, "training_loss": 906.5208683013916, "training_acc": 72.0, "val_loss": 193.4510350227356, "val_acc": 72.0}
{"epoch": 10, "training_loss": 579.3114223480225, "training_acc": 70.0, "val_loss": 130.57833909988403, "val_acc": 64.0}
{"epoch": 11, "training_loss": 609.3801069259644, "training_acc": 60.0, "val_loss": 128.5727620124817, "val_acc": 72.0}
{"epoch": 12, "training_loss": 399.57169342041016, "training_acc": 76.0, "val_loss": 84.06863212585449, "val_acc": 72.0}
{"epoch": 13, "training_loss": 262.77499198913574, "training_acc": 69.0, "val_loss": 69.39521431922913, "val_acc": 52.0}
{"epoch": 14, "training_loss": 235.07250881195068, "training_acc": 68.0, "val_loss": 94.9029266834259, "val_acc": 72.0}
{"epoch": 15, "training_loss": 337.8928165435791, "training_acc": 72.0, "val_loss": 203.97915840148926, "val_acc": 28.0}
{"epoch": 16, "training_loss": 478.5185036659241, "training_acc": 46.0, "val_loss": 88.69507908821106, "val_acc": 72.0}
{"epoch": 17, "training_loss": 462.1900882720947, "training_acc": 72.0, "val_loss": 16.27788245677948, "val_acc": 76.0}
{"epoch": 18, "training_loss": 362.54805755615234, "training_acc": 63.0, "val_loss": 24.969695508480072, "val_acc": 64.0}
{"epoch": 19, "training_loss": 308.4290466308594, "training_acc": 71.0, "val_loss": 146.4953064918518, "val_acc": 72.0}
{"epoch": 20, "training_loss": 454.09763193130493, "training_acc": 73.0, "val_loss": 69.22329068183899, "val_acc": 52.0}
{"epoch": 21, "training_loss": 350.4480228424072, "training_acc": 57.0, "val_loss": 61.61566376686096, "val_acc": 76.0}
{"epoch": 22, "training_loss": 262.86155128479004, "training_acc": 79.0, "val_loss": 79.3300449848175, "val_acc": 76.0}
{"epoch": 23, "training_loss": 219.75638055801392, "training_acc": 77.0, "val_loss": 83.42245221138, "val_acc": 52.0}
{"epoch": 24, "training_loss": 351.0661611557007, "training_acc": 62.0, "val_loss": 75.96218585968018, "val_acc": 72.0}
{"epoch": 25, "training_loss": 242.18674087524414, "training_acc": 77.0, "val_loss": 20.85578441619873, "val_acc": 64.0}
{"epoch": 26, "training_loss": 172.2978744506836, "training_acc": 66.0, "val_loss": 64.67657089233398, "val_acc": 72.0}
{"epoch": 27, "training_loss": 264.27416610717773, "training_acc": 75.0, "val_loss": 50.33697485923767, "val_acc": 72.0}
{"epoch": 28, "training_loss": 220.1058521270752, "training_acc": 66.0, "val_loss": 15.304705500602722, "val_acc": 80.0}
{"epoch": 29, "training_loss": 149.88676929473877, "training_acc": 79.0, "val_loss": 58.812910318374634, "val_acc": 76.0}
{"epoch": 30, "training_loss": 122.21075856685638, "training_acc": 83.0, "val_loss": 73.13947677612305, "val_acc": 44.0}
{"epoch": 31, "training_loss": 238.58797121047974, "training_acc": 60.0, "val_loss": 97.78639078140259, "val_acc": 72.0}
{"epoch": 32, "training_loss": 265.3652172088623, "training_acc": 75.0, "val_loss": 42.80502498149872, "val_acc": 56.0}
{"epoch": 33, "training_loss": 200.95438981056213, "training_acc": 69.0, "val_loss": 42.23646819591522, "val_acc": 76.0}
{"epoch": 34, "training_loss": 97.88849401473999, "training_acc": 82.0, "val_loss": 42.36672222614288, "val_acc": 80.0}
{"epoch": 35, "training_loss": 121.07120418548584, "training_acc": 72.0, "val_loss": 24.85683411359787, "val_acc": 80.0}
{"epoch": 36, "training_loss": 96.10492181777954, "training_acc": 79.0, "val_loss": 25.069937109947205, "val_acc": 84.0}
{"epoch": 37, "training_loss": 197.30088233947754, "training_acc": 64.0, "val_loss": 62.676966190338135, "val_acc": 72.0}
{"epoch": 38, "training_loss": 216.2124252319336, "training_acc": 72.0, "val_loss": 28.99164855480194, "val_acc": 84.0}
{"epoch": 39, "training_loss": 159.88581371307373, "training_acc": 73.0, "val_loss": 24.483446776866913, "val_acc": 80.0}
{"epoch": 40, "training_loss": 157.18725490570068, "training_acc": 76.0, "val_loss": 68.82259845733643, "val_acc": 72.0}
{"epoch": 41, "training_loss": 146.31582117080688, "training_acc": 74.0, "val_loss": 53.04621458053589, "val_acc": 52.0}
{"epoch": 42, "training_loss": 204.00351285934448, "training_acc": 67.0, "val_loss": 110.18961668014526, "val_acc": 72.0}
{"epoch": 43, "training_loss": 198.0136170387268, "training_acc": 74.0, "val_loss": 57.66453146934509, "val_acc": 68.0}
{"epoch": 44, "training_loss": 237.92139530181885, "training_acc": 65.0, "val_loss": 87.90380954742432, "val_acc": 76.0}
{"epoch": 45, "training_loss": 184.49289989471436, "training_acc": 78.0, "val_loss": 49.44855272769928, "val_acc": 80.0}
{"epoch": 46, "training_loss": 108.46468877792358, "training_acc": 75.0, "val_loss": 30.526137351989746, "val_acc": 80.0}
{"epoch": 47, "training_loss": 110.60914516448975, "training_acc": 79.0, "val_loss": 62.81236410140991, "val_acc": 72.0}
