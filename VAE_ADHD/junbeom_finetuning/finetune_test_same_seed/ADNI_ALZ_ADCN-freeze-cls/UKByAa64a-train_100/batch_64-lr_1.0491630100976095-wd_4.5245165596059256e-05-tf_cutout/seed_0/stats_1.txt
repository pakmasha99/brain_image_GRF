"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1366.5696334838867, "training_acc": 72.0, "val_loss": 709.7589015960693, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1755.4695825576782, "training_acc": 75.0, "val_loss": 1025.3509521484375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2994.744255065918, "training_acc": 33.0, "val_loss": 329.3642520904541, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1748.1734771728516, "training_acc": 72.0, "val_loss": 795.1653957366943, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2984.173988342285, "training_acc": 72.0, "val_loss": 613.61985206604, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2181.3336219787598, "training_acc": 72.0, "val_loss": 115.67181348800659, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1036.473388671875, "training_acc": 60.0, "val_loss": 315.38615226745605, "val_acc": 52.0}
{"epoch": 7, "training_loss": 927.3200073242188, "training_acc": 60.0, "val_loss": 173.547101020813, "val_acc": 80.0}
{"epoch": 8, "training_loss": 847.232177734375, "training_acc": 73.0, "val_loss": 270.30980587005615, "val_acc": 72.0}
{"epoch": 9, "training_loss": 908.6745414733887, "training_acc": 72.0, "val_loss": 79.6172022819519, "val_acc": 68.0}
{"epoch": 10, "training_loss": 442.0071048736572, "training_acc": 66.0, "val_loss": 204.49988842010498, "val_acc": 52.0}
{"epoch": 11, "training_loss": 643.5397119522095, "training_acc": 53.0, "val_loss": 175.11147260665894, "val_acc": 72.0}
{"epoch": 12, "training_loss": 747.8926963806152, "training_acc": 72.0, "val_loss": 195.8562731742859, "val_acc": 72.0}
{"epoch": 13, "training_loss": 591.6752138137817, "training_acc": 74.0, "val_loss": 136.79553270339966, "val_acc": 36.0}
{"epoch": 14, "training_loss": 514.15305519104, "training_acc": 43.0, "val_loss": 76.35692954063416, "val_acc": 72.0}
{"epoch": 15, "training_loss": 355.51988220214844, "training_acc": 73.0, "val_loss": 124.31100606918335, "val_acc": 72.0}
{"epoch": 16, "training_loss": 340.41531586647034, "training_acc": 77.0, "val_loss": 117.9255485534668, "val_acc": 40.0}
{"epoch": 17, "training_loss": 350.74570393562317, "training_acc": 53.0, "val_loss": 77.21258401870728, "val_acc": 72.0}
{"epoch": 18, "training_loss": 182.27164149284363, "training_acc": 73.0, "val_loss": 69.21425461769104, "val_acc": 44.0}
{"epoch": 19, "training_loss": 130.99083733558655, "training_acc": 72.0, "val_loss": 91.91568493843079, "val_acc": 72.0}
{"epoch": 20, "training_loss": 212.93780994415283, "training_acc": 72.0, "val_loss": 59.82581377029419, "val_acc": 48.0}
{"epoch": 21, "training_loss": 107.76741003990173, "training_acc": 71.0, "val_loss": 63.59577775001526, "val_acc": 72.0}
{"epoch": 22, "training_loss": 121.12469625473022, "training_acc": 68.0, "val_loss": 60.59187650680542, "val_acc": 72.0}
{"epoch": 23, "training_loss": 91.89517617225647, "training_acc": 79.0, "val_loss": 71.37097120285034, "val_acc": 48.0}
{"epoch": 24, "training_loss": 169.64154720306396, "training_acc": 62.0, "val_loss": 44.30441856384277, "val_acc": 60.0}
{"epoch": 25, "training_loss": 89.42977571487427, "training_acc": 75.0, "val_loss": 83.25977921485901, "val_acc": 72.0}
{"epoch": 26, "training_loss": 150.58547019958496, "training_acc": 72.0, "val_loss": 82.03449845314026, "val_acc": 40.0}
{"epoch": 27, "training_loss": 195.88582372665405, "training_acc": 54.0, "val_loss": 38.22568356990814, "val_acc": 68.0}
{"epoch": 28, "training_loss": 115.9390287399292, "training_acc": 68.0, "val_loss": 99.69489574432373, "val_acc": 72.0}
{"epoch": 29, "training_loss": 277.51007080078125, "training_acc": 72.0, "val_loss": 42.2348827123642, "val_acc": 68.0}
{"epoch": 30, "training_loss": 260.44985580444336, "training_acc": 61.0, "val_loss": 39.22916352748871, "val_acc": 72.0}
{"epoch": 31, "training_loss": 209.9487247467041, "training_acc": 73.0, "val_loss": 82.17111825942993, "val_acc": 76.0}
{"epoch": 32, "training_loss": 183.4039077758789, "training_acc": 76.0, "val_loss": 106.81930780410767, "val_acc": 52.0}
{"epoch": 33, "training_loss": 297.37976694107056, "training_acc": 61.0, "val_loss": 135.49163341522217, "val_acc": 72.0}
{"epoch": 34, "training_loss": 414.08282470703125, "training_acc": 72.0, "val_loss": 69.96373534202576, "val_acc": 80.0}
{"epoch": 35, "training_loss": 183.50193691253662, "training_acc": 76.0, "val_loss": 90.69779515266418, "val_acc": 52.0}
{"epoch": 36, "training_loss": 233.0475103855133, "training_acc": 69.0, "val_loss": 112.212073802948, "val_acc": 72.0}
{"epoch": 37, "training_loss": 344.5355443954468, "training_acc": 72.0, "val_loss": 42.24136173725128, "val_acc": 68.0}
{"epoch": 38, "training_loss": 258.53529167175293, "training_acc": 69.0, "val_loss": 39.65662717819214, "val_acc": 68.0}
{"epoch": 39, "training_loss": 188.74237728118896, "training_acc": 80.0, "val_loss": 134.96007919311523, "val_acc": 72.0}
{"epoch": 40, "training_loss": 297.2268075942993, "training_acc": 74.0, "val_loss": 129.44766283035278, "val_acc": 40.0}
{"epoch": 41, "training_loss": 377.71634101867676, "training_acc": 44.0, "val_loss": 148.17568063735962, "val_acc": 72.0}
{"epoch": 42, "training_loss": 607.8676528930664, "training_acc": 72.0, "val_loss": 253.42986583709717, "val_acc": 72.0}
{"epoch": 43, "training_loss": 697.5723857879639, "training_acc": 72.0, "val_loss": 51.29478573799133, "val_acc": 72.0}
{"epoch": 44, "training_loss": 391.3475036621094, "training_acc": 61.0, "val_loss": 105.43943643569946, "val_acc": 56.0}
{"epoch": 45, "training_loss": 389.00425815582275, "training_acc": 61.0, "val_loss": 207.835054397583, "val_acc": 72.0}
{"epoch": 46, "training_loss": 712.0101985931396, "training_acc": 72.0, "val_loss": 116.32423400878906, "val_acc": 76.0}
