"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 73128.7488937378, "training_acc": 42.0, "val_loss": 33139.35546875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 93854.87524414062, "training_acc": 72.0, "val_loss": 25530.55877685547, "val_acc": 28.0}
{"epoch": 2, "training_loss": 91124.27124023438, "training_acc": 32.0, "val_loss": 3992.3606872558594, "val_acc": 72.0}
{"epoch": 3, "training_loss": 23683.209716796875, "training_acc": 72.0, "val_loss": 8938.650512695312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 27859.150970458984, "training_acc": 73.0, "val_loss": 6988.9892578125, "val_acc": 56.0}
{"epoch": 5, "training_loss": 32325.392700195312, "training_acc": 50.0, "val_loss": 3372.9248046875, "val_acc": 64.0}
{"epoch": 6, "training_loss": 22716.823852539062, "training_acc": 68.0, "val_loss": 8434.187316894531, "val_acc": 72.0}
{"epoch": 7, "training_loss": 28043.845581054688, "training_acc": 72.0, "val_loss": 2407.551956176758, "val_acc": 64.0}
{"epoch": 8, "training_loss": 15972.957885742188, "training_acc": 66.0, "val_loss": 4663.538360595703, "val_acc": 60.0}
{"epoch": 9, "training_loss": 13875.039459228516, "training_acc": 62.0, "val_loss": 4946.156311035156, "val_acc": 72.0}
{"epoch": 10, "training_loss": 16385.375213623047, "training_acc": 72.0, "val_loss": 1242.0307159423828, "val_acc": 72.0}
{"epoch": 11, "training_loss": 9902.526550292969, "training_acc": 54.0, "val_loss": 4158.856964111328, "val_acc": 72.0}
{"epoch": 12, "training_loss": 18738.441345214844, "training_acc": 72.0, "val_loss": 5509.333038330078, "val_acc": 72.0}
{"epoch": 13, "training_loss": 14795.775665283203, "training_acc": 71.0, "val_loss": 9130.33218383789, "val_acc": 36.0}
{"epoch": 14, "training_loss": 26285.377044677734, "training_acc": 36.0, "val_loss": 6269.255065917969, "val_acc": 72.0}
{"epoch": 15, "training_loss": 24890.50909423828, "training_acc": 72.0, "val_loss": 9509.828186035156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 30169.47247314453, "training_acc": 72.0, "val_loss": 1309.5287322998047, "val_acc": 72.0}
{"epoch": 17, "training_loss": 12974.890014648438, "training_acc": 58.0, "val_loss": 1510.4557991027832, "val_acc": 64.0}
{"epoch": 18, "training_loss": 6533.592193603516, "training_acc": 76.0, "val_loss": 6766.847991943359, "val_acc": 72.0}
{"epoch": 19, "training_loss": 22465.2783203125, "training_acc": 72.0, "val_loss": 2298.74267578125, "val_acc": 80.0}
{"epoch": 20, "training_loss": 13587.344360351562, "training_acc": 60.0, "val_loss": 1280.8452606201172, "val_acc": 68.0}
{"epoch": 21, "training_loss": 4461.049987792969, "training_acc": 79.0, "val_loss": 5257.839202880859, "val_acc": 72.0}
{"epoch": 22, "training_loss": 14604.619537353516, "training_acc": 73.0, "val_loss": 1647.8437423706055, "val_acc": 52.0}
{"epoch": 23, "training_loss": 6124.723083496094, "training_acc": 64.0, "val_loss": 1694.4561004638672, "val_acc": 76.0}
{"epoch": 24, "training_loss": 3603.9332733154297, "training_acc": 79.0, "val_loss": 1473.8134384155273, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3978.7674255371094, "training_acc": 69.0, "val_loss": 1469.1582679748535, "val_acc": 64.0}
{"epoch": 26, "training_loss": 1914.1739044189453, "training_acc": 86.0, "val_loss": 1407.8278541564941, "val_acc": 52.0}
{"epoch": 27, "training_loss": 1497.6455307006836, "training_acc": 80.0, "val_loss": 2209.490203857422, "val_acc": 68.0}
{"epoch": 28, "training_loss": 2629.746253967285, "training_acc": 77.0, "val_loss": 1567.5070762634277, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1434.1315307617188, "training_acc": 84.0, "val_loss": 1605.2055358886719, "val_acc": 52.0}
