"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 68329.13989639282, "training_acc": 40.0, "val_loss": 33244.10095214844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 111620.96801757812, "training_acc": 72.0, "val_loss": 15602.418518066406, "val_acc": 28.0}
{"epoch": 2, "training_loss": 55438.00622558594, "training_acc": 32.0, "val_loss": 9365.574645996094, "val_acc": 72.0}
{"epoch": 3, "training_loss": 48170.9765625, "training_acc": 72.0, "val_loss": 15667.431640625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 47019.42370605469, "training_acc": 72.0, "val_loss": 4377.984237670898, "val_acc": 76.0}
{"epoch": 5, "training_loss": 31169.31884765625, "training_acc": 64.0, "val_loss": 8047.188568115234, "val_acc": 48.0}
{"epoch": 6, "training_loss": 42325.76544189453, "training_acc": 55.0, "val_loss": 7742.561340332031, "val_acc": 76.0}
{"epoch": 7, "training_loss": 26925.92218017578, "training_acc": 71.0, "val_loss": 8222.290802001953, "val_acc": 72.0}
{"epoch": 8, "training_loss": 22871.96990966797, "training_acc": 73.0, "val_loss": 4040.411376953125, "val_acc": 76.0}
{"epoch": 9, "training_loss": 15385.07958984375, "training_acc": 67.0, "val_loss": 3018.147659301758, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7480.113677978516, "training_acc": 75.0, "val_loss": 2958.7934494018555, "val_acc": 68.0}
{"epoch": 11, "training_loss": 7967.167449951172, "training_acc": 61.0, "val_loss": 2948.2250213623047, "val_acc": 52.0}
{"epoch": 12, "training_loss": 8215.391723632812, "training_acc": 67.0, "val_loss": 2465.9591674804688, "val_acc": 52.0}
{"epoch": 13, "training_loss": 5878.347946166992, "training_acc": 60.0, "val_loss": 2193.9315795898438, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3947.578399658203, "training_acc": 79.0, "val_loss": 2633.70304107666, "val_acc": 56.0}
{"epoch": 15, "training_loss": 10757.40705871582, "training_acc": 58.0, "val_loss": 4838.288879394531, "val_acc": 72.0}
{"epoch": 16, "training_loss": 15318.042602539062, "training_acc": 72.0, "val_loss": 2057.803726196289, "val_acc": 76.0}
{"epoch": 17, "training_loss": 7261.193817138672, "training_acc": 72.0, "val_loss": 1991.9769287109375, "val_acc": 60.0}
{"epoch": 18, "training_loss": 9582.141082763672, "training_acc": 64.0, "val_loss": 4175.840759277344, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8174.296112060547, "training_acc": 79.0, "val_loss": 3434.8587036132812, "val_acc": 52.0}
{"epoch": 20, "training_loss": 14522.452575683594, "training_acc": 51.0, "val_loss": 5147.283172607422, "val_acc": 72.0}
{"epoch": 21, "training_loss": 19177.19708251953, "training_acc": 72.0, "val_loss": 3422.5032806396484, "val_acc": 72.0}
{"epoch": 22, "training_loss": 15623.333312988281, "training_acc": 55.0, "val_loss": 1459.3952178955078, "val_acc": 64.0}
{"epoch": 23, "training_loss": 14250.142517089844, "training_acc": 55.0, "val_loss": 8458.915710449219, "val_acc": 72.0}
{"epoch": 24, "training_loss": 27634.90167236328, "training_acc": 72.0, "val_loss": 2424.9467849731445, "val_acc": 76.0}
{"epoch": 25, "training_loss": 12354.22998046875, "training_acc": 61.0, "val_loss": 2423.8866806030273, "val_acc": 64.0}
{"epoch": 26, "training_loss": 8037.010192871094, "training_acc": 72.0, "val_loss": 7545.479583740234, "val_acc": 72.0}
{"epoch": 27, "training_loss": 20754.24591064453, "training_acc": 72.0, "val_loss": 3633.584213256836, "val_acc": 68.0}
{"epoch": 28, "training_loss": 11736.309692382812, "training_acc": 70.0, "val_loss": 3544.6678161621094, "val_acc": 68.0}
{"epoch": 29, "training_loss": 12162.00309753418, "training_acc": 67.0, "val_loss": 5567.179489135742, "val_acc": 72.0}
{"epoch": 30, "training_loss": 14470.190551757812, "training_acc": 76.0, "val_loss": 3549.645233154297, "val_acc": 64.0}
{"epoch": 31, "training_loss": 5824.390686035156, "training_acc": 80.0, "val_loss": 3432.1487426757812, "val_acc": 56.0}
{"epoch": 32, "training_loss": 11456.11979675293, "training_acc": 65.0, "val_loss": 5279.612350463867, "val_acc": 72.0}
{"epoch": 33, "training_loss": 12211.751480102539, "training_acc": 73.0, "val_loss": 2201.1159896850586, "val_acc": 44.0}
{"epoch": 34, "training_loss": 5511.250457763672, "training_acc": 71.0, "val_loss": 1854.3878555297852, "val_acc": 60.0}
{"epoch": 35, "training_loss": 3392.908660888672, "training_acc": 81.0, "val_loss": 1728.33251953125, "val_acc": 48.0}
{"epoch": 36, "training_loss": 2313.2590827941895, "training_acc": 77.0, "val_loss": 1093.8650131225586, "val_acc": 56.0}
{"epoch": 37, "training_loss": 2284.370231628418, "training_acc": 73.0, "val_loss": 694.4897174835205, "val_acc": 68.0}
{"epoch": 38, "training_loss": 1510.102487564087, "training_acc": 85.0, "val_loss": 470.8320617675781, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1455.6579818725586, "training_acc": 83.0, "val_loss": 796.6733455657959, "val_acc": 76.0}
{"epoch": 40, "training_loss": 2171.5475006103516, "training_acc": 76.0, "val_loss": 1600.1995086669922, "val_acc": 72.0}
{"epoch": 41, "training_loss": 5054.072265625, "training_acc": 78.0, "val_loss": 2478.5512924194336, "val_acc": 44.0}
{"epoch": 42, "training_loss": 8463.616592407227, "training_acc": 54.0, "val_loss": 1998.731803894043, "val_acc": 72.0}
{"epoch": 43, "training_loss": 6763.520660400391, "training_acc": 61.0, "val_loss": 2488.7706756591797, "val_acc": 72.0}
{"epoch": 44, "training_loss": 9040.317138671875, "training_acc": 76.0, "val_loss": 1096.6131210327148, "val_acc": 80.0}
{"epoch": 45, "training_loss": 6564.924865722656, "training_acc": 71.0, "val_loss": 1368.886661529541, "val_acc": 76.0}
{"epoch": 46, "training_loss": 7095.492736816406, "training_acc": 78.0, "val_loss": 4668.197250366211, "val_acc": 72.0}
{"epoch": 47, "training_loss": 10114.830062866211, "training_acc": 75.0, "val_loss": 1474.9361038208008, "val_acc": 64.0}
{"epoch": 48, "training_loss": 5358.269546508789, "training_acc": 68.0, "val_loss": 2731.0741424560547, "val_acc": 72.0}
{"epoch": 49, "training_loss": 4934.430160522461, "training_acc": 80.0, "val_loss": 3263.3617401123047, "val_acc": 52.0}
{"epoch": 50, "training_loss": 7237.296291351318, "training_acc": 62.0, "val_loss": 3421.6182708740234, "val_acc": 72.0}
{"epoch": 51, "training_loss": 7461.345001220703, "training_acc": 73.0, "val_loss": 4721.285629272461, "val_acc": 40.0}
{"epoch": 52, "training_loss": 11424.875208377838, "training_acc": 56.0, "val_loss": 3015.402603149414, "val_acc": 72.0}
{"epoch": 53, "training_loss": 4945.948181152344, "training_acc": 79.0, "val_loss": 1610.1287841796875, "val_acc": 64.0}
{"epoch": 54, "training_loss": 4225.571716308594, "training_acc": 72.0, "val_loss": 2022.206687927246, "val_acc": 68.0}
{"epoch": 55, "training_loss": 4172.915832519531, "training_acc": 84.0, "val_loss": 2962.7756118774414, "val_acc": 72.0}
{"epoch": 56, "training_loss": 3765.771541595459, "training_acc": 83.0, "val_loss": 2219.675636291504, "val_acc": 72.0}
{"epoch": 57, "training_loss": 4728.369007110596, "training_acc": 73.0, "val_loss": 4871.494674682617, "val_acc": 72.0}
