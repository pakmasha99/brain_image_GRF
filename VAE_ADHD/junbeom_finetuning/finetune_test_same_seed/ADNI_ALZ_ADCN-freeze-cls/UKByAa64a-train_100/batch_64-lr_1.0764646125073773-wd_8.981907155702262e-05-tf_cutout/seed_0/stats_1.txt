"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1575.3222312927246, "training_acc": 56.0, "val_loss": 877.0991325378418, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2509.9389572143555, "training_acc": 72.0, "val_loss": 1053.050422668457, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3942.435791015625, "training_acc": 30.0, "val_loss": 100.28578042984009, "val_acc": 64.0}
{"epoch": 3, "training_loss": 1000.68359375, "training_acc": 67.0, "val_loss": 640.8674240112305, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2483.8656311035156, "training_acc": 72.0, "val_loss": 598.8107681274414, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2084.165214538574, "training_acc": 72.0, "val_loss": 164.73712921142578, "val_acc": 80.0}
{"epoch": 6, "training_loss": 960.8298835754395, "training_acc": 57.0, "val_loss": 441.22610092163086, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1492.8316230773926, "training_acc": 48.0, "val_loss": 106.09327554702759, "val_acc": 72.0}
{"epoch": 8, "training_loss": 695.7154121398926, "training_acc": 72.0, "val_loss": 364.96522426605225, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1441.5869941711426, "training_acc": 72.0, "val_loss": 262.8493070602417, "val_acc": 72.0}
{"epoch": 10, "training_loss": 834.7157135009766, "training_acc": 75.0, "val_loss": 212.59496212005615, "val_acc": 56.0}
{"epoch": 11, "training_loss": 982.4933433532715, "training_acc": 45.0, "val_loss": 115.67867994308472, "val_acc": 60.0}
{"epoch": 12, "training_loss": 385.43095207214355, "training_acc": 68.0, "val_loss": 221.82409763336182, "val_acc": 72.0}
{"epoch": 13, "training_loss": 867.0252151489258, "training_acc": 72.0, "val_loss": 149.82136487960815, "val_acc": 72.0}
{"epoch": 14, "training_loss": 445.5377736091614, "training_acc": 71.0, "val_loss": 177.9590129852295, "val_acc": 40.0}
{"epoch": 15, "training_loss": 497.3514156341553, "training_acc": 49.0, "val_loss": 111.54241561889648, "val_acc": 72.0}
{"epoch": 16, "training_loss": 455.59911346435547, "training_acc": 72.0, "val_loss": 99.84089732170105, "val_acc": 72.0}
{"epoch": 17, "training_loss": 353.2480306625366, "training_acc": 59.0, "val_loss": 43.43932569026947, "val_acc": 64.0}
{"epoch": 18, "training_loss": 205.7637424468994, "training_acc": 73.0, "val_loss": 79.34326529502869, "val_acc": 72.0}
{"epoch": 19, "training_loss": 170.54481840133667, "training_acc": 78.0, "val_loss": 78.66712808609009, "val_acc": 52.0}
{"epoch": 20, "training_loss": 193.71675825119019, "training_acc": 63.0, "val_loss": 80.84174394607544, "val_acc": 72.0}
{"epoch": 21, "training_loss": 155.87930727005005, "training_acc": 79.0, "val_loss": 77.04622745513916, "val_acc": 48.0}
{"epoch": 22, "training_loss": 179.8467059135437, "training_acc": 69.0, "val_loss": 57.93902277946472, "val_acc": 72.0}
{"epoch": 23, "training_loss": 98.9061074256897, "training_acc": 82.0, "val_loss": 68.11361312866211, "val_acc": 44.0}
{"epoch": 24, "training_loss": 106.703458070755, "training_acc": 63.0, "val_loss": 69.87140774726868, "val_acc": 72.0}
{"epoch": 25, "training_loss": 78.42884612083435, "training_acc": 80.0, "val_loss": 78.22471261024475, "val_acc": 36.0}
{"epoch": 26, "training_loss": 151.98170709609985, "training_acc": 63.0, "val_loss": 66.89956784248352, "val_acc": 72.0}
{"epoch": 27, "training_loss": 174.35127544403076, "training_acc": 68.0, "val_loss": 44.37575340270996, "val_acc": 64.0}
{"epoch": 28, "training_loss": 84.27254724502563, "training_acc": 81.0, "val_loss": 40.429750084877014, "val_acc": 64.0}
{"epoch": 29, "training_loss": 138.7270450592041, "training_acc": 71.0, "val_loss": 110.32661199569702, "val_acc": 72.0}
{"epoch": 30, "training_loss": 430.47146224975586, "training_acc": 72.0, "val_loss": 68.12983751296997, "val_acc": 76.0}
{"epoch": 31, "training_loss": 383.165584564209, "training_acc": 60.0, "val_loss": 74.02631044387817, "val_acc": 52.0}
{"epoch": 32, "training_loss": 233.2216968536377, "training_acc": 70.0, "val_loss": 216.64941310882568, "val_acc": 72.0}
{"epoch": 33, "training_loss": 667.2765045166016, "training_acc": 72.0, "val_loss": 77.98261046409607, "val_acc": 76.0}
{"epoch": 34, "training_loss": 151.28266716003418, "training_acc": 83.0, "val_loss": 206.2091588973999, "val_acc": 40.0}
{"epoch": 35, "training_loss": 655.1250162124634, "training_acc": 51.0, "val_loss": 137.39821910858154, "val_acc": 72.0}
{"epoch": 36, "training_loss": 449.5142002105713, "training_acc": 72.0, "val_loss": 95.96338272094727, "val_acc": 76.0}
{"epoch": 37, "training_loss": 274.60536766052246, "training_acc": 71.0, "val_loss": 141.63943529129028, "val_acc": 44.0}
{"epoch": 38, "training_loss": 359.43180990219116, "training_acc": 59.0, "val_loss": 128.13327312469482, "val_acc": 72.0}
{"epoch": 39, "training_loss": 408.56771087646484, "training_acc": 72.0, "val_loss": 79.92399334907532, "val_acc": 76.0}
{"epoch": 40, "training_loss": 148.104567527771, "training_acc": 79.0, "val_loss": 116.80506467819214, "val_acc": 36.0}
{"epoch": 41, "training_loss": 260.6169250011444, "training_acc": 60.0, "val_loss": 113.07179927825928, "val_acc": 76.0}
{"epoch": 42, "training_loss": 260.40800762176514, "training_acc": 75.0, "val_loss": 52.68338918685913, "val_acc": 60.0}
{"epoch": 43, "training_loss": 187.65690517425537, "training_acc": 70.0, "val_loss": 48.71086776256561, "val_acc": 68.0}
{"epoch": 44, "training_loss": 150.77306938171387, "training_acc": 81.0, "val_loss": 90.71971774101257, "val_acc": 76.0}
{"epoch": 45, "training_loss": 159.87285137176514, "training_acc": 79.0, "val_loss": 69.93844509124756, "val_acc": 52.0}
{"epoch": 46, "training_loss": 120.01862466335297, "training_acc": 74.0, "val_loss": 69.94417905807495, "val_acc": 76.0}
{"epoch": 47, "training_loss": 93.1450697183609, "training_acc": 81.0, "val_loss": 58.909058570861816, "val_acc": 40.0}
