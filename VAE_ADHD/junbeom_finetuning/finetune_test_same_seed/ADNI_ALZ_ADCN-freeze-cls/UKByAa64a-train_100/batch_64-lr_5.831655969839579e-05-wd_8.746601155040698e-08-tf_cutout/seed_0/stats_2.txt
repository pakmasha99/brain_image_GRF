"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.19724082946777, "training_acc": 72.0, "val_loss": 16.162845492362976, "val_acc": 28.0}
{"epoch": 1, "training_loss": 64.42366003990173, "training_acc": 72.0, "val_loss": 15.992780029773712, "val_acc": 28.0}
{"epoch": 2, "training_loss": 63.7359893321991, "training_acc": 72.0, "val_loss": 15.834933519363403, "val_acc": 28.0}
{"epoch": 3, "training_loss": 63.039647340774536, "training_acc": 72.0, "val_loss": 15.68727046251297, "val_acc": 28.0}
{"epoch": 4, "training_loss": 62.59370160102844, "training_acc": 72.0, "val_loss": 15.551604330539703, "val_acc": 28.0}
{"epoch": 5, "training_loss": 61.93819522857666, "training_acc": 72.0, "val_loss": 15.431630611419678, "val_acc": 28.0}
{"epoch": 6, "training_loss": 61.56047749519348, "training_acc": 72.0, "val_loss": 15.324056148529053, "val_acc": 72.0}
{"epoch": 7, "training_loss": 61.10892915725708, "training_acc": 72.0, "val_loss": 15.23275375366211, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.73571181297302, "training_acc": 72.0, "val_loss": 15.157875418663025, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.46141481399536, "training_acc": 72.0, "val_loss": 15.096637606620789, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.153393268585205, "training_acc": 72.0, "val_loss": 15.046259760856628, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.007683753967285, "training_acc": 72.0, "val_loss": 15.003602206707, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.75293207168579, "training_acc": 72.0, "val_loss": 14.970119297504425, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.65547299385071, "training_acc": 72.0, "val_loss": 14.94230180978775, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.52934288978577, "training_acc": 72.0, "val_loss": 14.921770989894867, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.44172811508179, "training_acc": 72.0, "val_loss": 14.905138313770294, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.45358347892761, "training_acc": 72.0, "val_loss": 14.893132448196411, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.279998540878296, "training_acc": 72.0, "val_loss": 14.884738624095917, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.32046818733215, "training_acc": 72.0, "val_loss": 14.878961443901062, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.3280189037323, "training_acc": 72.0, "val_loss": 14.875969290733337, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.23306226730347, "training_acc": 72.0, "val_loss": 14.874574542045593, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.296647787094116, "training_acc": 72.0, "val_loss": 14.87433910369873, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.27172017097473, "training_acc": 72.0, "val_loss": 14.875079691410065, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.368927001953125, "training_acc": 72.0, "val_loss": 14.876338839530945, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.38368558883667, "training_acc": 72.0, "val_loss": 14.877447485923767, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.410951137542725, "training_acc": 72.0, "val_loss": 14.878398180007935, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.24248147010803, "training_acc": 72.0, "val_loss": 14.878912270069122, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.49168539047241, "training_acc": 72.0, "val_loss": 14.87913727760315, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.309701442718506, "training_acc": 72.0, "val_loss": 14.879262447357178, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.30540585517883, "training_acc": 72.0, "val_loss": 14.879302680492401, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.30811047554016, "training_acc": 72.0, "val_loss": 14.879041910171509, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.41804099082947, "training_acc": 72.0, "val_loss": 14.879107475280762, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.3307044506073, "training_acc": 72.0, "val_loss": 14.879049360752106, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.287503719329834, "training_acc": 72.0, "val_loss": 14.879356324672699, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.248051404953, "training_acc": 72.0, "val_loss": 14.878900349140167, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.30372953414917, "training_acc": 72.0, "val_loss": 14.878655970096588, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.32111430168152, "training_acc": 72.0, "val_loss": 14.878374338150024, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.295939683914185, "training_acc": 72.0, "val_loss": 14.878249168395996, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.339375495910645, "training_acc": 72.0, "val_loss": 14.878293871879578, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.33041954040527, "training_acc": 72.0, "val_loss": 14.87782597541809, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.46750354766846, "training_acc": 72.0, "val_loss": 14.877618849277496, "val_acc": 72.0}
