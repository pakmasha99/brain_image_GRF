"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14030.842250823975, "training_acc": 42.0, "val_loss": 6902.35595703125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 23752.341857910156, "training_acc": 72.0, "val_loss": 4051.857376098633, "val_acc": 28.0}
{"epoch": 2, "training_loss": 17166.243408203125, "training_acc": 34.0, "val_loss": 1542.6020622253418, "val_acc": 76.0}
{"epoch": 3, "training_loss": 9066.998474121094, "training_acc": 71.0, "val_loss": 4231.383514404297, "val_acc": 72.0}
{"epoch": 4, "training_loss": 14368.64013671875, "training_acc": 72.0, "val_loss": 2374.5946884155273, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6847.315460205078, "training_acc": 76.0, "val_loss": 2231.1702728271484, "val_acc": 44.0}
{"epoch": 6, "training_loss": 13006.908630371094, "training_acc": 45.0, "val_loss": 1185.424518585205, "val_acc": 80.0}
{"epoch": 7, "training_loss": 6039.471405029297, "training_acc": 63.0, "val_loss": 3321.030807495117, "val_acc": 72.0}
{"epoch": 8, "training_loss": 11994.461059570312, "training_acc": 72.0, "val_loss": 3065.398406982422, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9071.368347167969, "training_acc": 72.0, "val_loss": 969.364070892334, "val_acc": 68.0}
{"epoch": 10, "training_loss": 5346.020599365234, "training_acc": 60.0, "val_loss": 1245.09859085083, "val_acc": 52.0}
{"epoch": 11, "training_loss": 4321.6521644592285, "training_acc": 62.0, "val_loss": 1801.3683319091797, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5662.874252319336, "training_acc": 72.0, "val_loss": 1888.096046447754, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4510.750244140625, "training_acc": 72.0, "val_loss": 1317.4336433410645, "val_acc": 52.0}
{"epoch": 14, "training_loss": 5713.187973022461, "training_acc": 46.0, "val_loss": 664.3066883087158, "val_acc": 64.0}
{"epoch": 15, "training_loss": 2911.1919708251953, "training_acc": 72.0, "val_loss": 1782.1401596069336, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4661.337310791016, "training_acc": 72.0, "val_loss": 651.4616012573242, "val_acc": 64.0}
{"epoch": 17, "training_loss": 2579.1490478515625, "training_acc": 64.0, "val_loss": 666.1246299743652, "val_acc": 60.0}
{"epoch": 18, "training_loss": 2092.2786407470703, "training_acc": 70.0, "val_loss": 1035.643196105957, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2019.498348236084, "training_acc": 76.0, "val_loss": 570.4967498779297, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1501.893684387207, "training_acc": 72.0, "val_loss": 530.6551933288574, "val_acc": 68.0}
{"epoch": 21, "training_loss": 1358.1080169677734, "training_acc": 67.0, "val_loss": 462.08744049072266, "val_acc": 64.0}
{"epoch": 22, "training_loss": 1885.3731384277344, "training_acc": 67.0, "val_loss": 357.1503162384033, "val_acc": 64.0}
{"epoch": 23, "training_loss": 1097.1025466918945, "training_acc": 80.0, "val_loss": 787.1755599975586, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2041.2845344543457, "training_acc": 63.0, "val_loss": 206.43343925476074, "val_acc": 60.0}
{"epoch": 25, "training_loss": 830.1904754638672, "training_acc": 74.0, "val_loss": 315.8372402191162, "val_acc": 76.0}
{"epoch": 26, "training_loss": 1221.653694152832, "training_acc": 71.0, "val_loss": 617.8299427032471, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1744.149070739746, "training_acc": 75.0, "val_loss": 338.1034851074219, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1297.9157485961914, "training_acc": 72.0, "val_loss": 189.89944458007812, "val_acc": 76.0}
{"epoch": 29, "training_loss": 1233.0642623901367, "training_acc": 77.0, "val_loss": 489.589262008667, "val_acc": 72.0}
{"epoch": 30, "training_loss": 929.1596298217773, "training_acc": 75.0, "val_loss": 104.06169891357422, "val_acc": 64.0}
{"epoch": 31, "training_loss": 857.2815628051758, "training_acc": 71.0, "val_loss": 322.93341159820557, "val_acc": 72.0}
{"epoch": 32, "training_loss": 869.1536254882812, "training_acc": 75.0, "val_loss": 195.95125913619995, "val_acc": 64.0}
{"epoch": 33, "training_loss": 712.1983528137207, "training_acc": 82.0, "val_loss": 576.9598960876465, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1687.8469161987305, "training_acc": 63.0, "val_loss": 267.8758382797241, "val_acc": 76.0}
{"epoch": 35, "training_loss": 424.0711555480957, "training_acc": 83.0, "val_loss": 326.61025524139404, "val_acc": 76.0}
{"epoch": 36, "training_loss": 521.5824871063232, "training_acc": 80.0, "val_loss": 253.75981330871582, "val_acc": 64.0}
{"epoch": 37, "training_loss": 489.9257926940918, "training_acc": 79.0, "val_loss": 557.6926231384277, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1005.3704957962036, "training_acc": 76.0, "val_loss": 303.72047424316406, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1080.3146514892578, "training_acc": 67.0, "val_loss": 578.3368587493896, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1076.352798461914, "training_acc": 66.0, "val_loss": 265.5375003814697, "val_acc": 76.0}
{"epoch": 41, "training_loss": 383.17994594573975, "training_acc": 85.0, "val_loss": 247.33474254608154, "val_acc": 76.0}
{"epoch": 42, "training_loss": 305.1748561859131, "training_acc": 87.0, "val_loss": 271.06053829193115, "val_acc": 64.0}
{"epoch": 43, "training_loss": 1377.2086563110352, "training_acc": 64.0, "val_loss": 896.0302352905273, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1460.7256774902344, "training_acc": 78.0, "val_loss": 698.6405372619629, "val_acc": 44.0}
{"epoch": 45, "training_loss": 2493.1556434631348, "training_acc": 53.0, "val_loss": 629.4039249420166, "val_acc": 76.0}
{"epoch": 46, "training_loss": 1326.914077758789, "training_acc": 79.0, "val_loss": 295.93400955200195, "val_acc": 68.0}
{"epoch": 47, "training_loss": 1333.2186965942383, "training_acc": 69.0, "val_loss": 562.5834941864014, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1014.3779945373535, "training_acc": 77.0, "val_loss": 136.81375980377197, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1105.323829650879, "training_acc": 71.0, "val_loss": 560.2245807647705, "val_acc": 72.0}
