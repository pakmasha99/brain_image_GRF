"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9518.070079803467, "training_acc": 41.0, "val_loss": 5109.976577758789, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15278.404205322266, "training_acc": 72.0, "val_loss": 5226.028060913086, "val_acc": 28.0}
{"epoch": 2, "training_loss": 20848.02960205078, "training_acc": 28.0, "val_loss": 677.0689964294434, "val_acc": 80.0}
{"epoch": 3, "training_loss": 8086.9564208984375, "training_acc": 64.0, "val_loss": 3982.495880126953, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15218.8017578125, "training_acc": 72.0, "val_loss": 3839.4237518310547, "val_acc": 72.0}
{"epoch": 5, "training_loss": 12252.704833984375, "training_acc": 72.0, "val_loss": 1386.7746353149414, "val_acc": 72.0}
{"epoch": 6, "training_loss": 6132.719146728516, "training_acc": 67.0, "val_loss": 2252.669906616211, "val_acc": 44.0}
{"epoch": 7, "training_loss": 10610.105438232422, "training_acc": 46.0, "val_loss": 1111.8306159973145, "val_acc": 76.0}
{"epoch": 8, "training_loss": 5497.607666015625, "training_acc": 69.0, "val_loss": 2577.6351928710938, "val_acc": 72.0}
{"epoch": 9, "training_loss": 8655.426574707031, "training_acc": 72.0, "val_loss": 2349.155616760254, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5724.468688964844, "training_acc": 73.0, "val_loss": 943.6362266540527, "val_acc": 76.0}
{"epoch": 11, "training_loss": 5849.346649169922, "training_acc": 62.0, "val_loss": 1489.0827178955078, "val_acc": 44.0}
{"epoch": 12, "training_loss": 6061.006324768066, "training_acc": 56.0, "val_loss": 1074.338150024414, "val_acc": 76.0}
{"epoch": 13, "training_loss": 3434.409881591797, "training_acc": 78.0, "val_loss": 1723.7115859985352, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4948.160415649414, "training_acc": 72.0, "val_loss": 514.3000602722168, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1925.0507354736328, "training_acc": 68.0, "val_loss": 583.4421157836914, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1827.5184288024902, "training_acc": 64.0, "val_loss": 1049.9402046203613, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2969.6160163879395, "training_acc": 72.0, "val_loss": 397.8466033935547, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1049.6312866210938, "training_acc": 64.0, "val_loss": 546.4418411254883, "val_acc": 64.0}
{"epoch": 19, "training_loss": 1001.9273910522461, "training_acc": 72.0, "val_loss": 412.807035446167, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1056.338809967041, "training_acc": 64.0, "val_loss": 578.2963752746582, "val_acc": 68.0}
{"epoch": 21, "training_loss": 1090.5755634307861, "training_acc": 74.0, "val_loss": 341.1094665527344, "val_acc": 68.0}
{"epoch": 22, "training_loss": 765.6178169250488, "training_acc": 76.0, "val_loss": 339.46664333343506, "val_acc": 64.0}
{"epoch": 23, "training_loss": 543.8854522705078, "training_acc": 82.0, "val_loss": 221.38404846191406, "val_acc": 56.0}
{"epoch": 24, "training_loss": 552.1180877685547, "training_acc": 75.0, "val_loss": 164.89129066467285, "val_acc": 48.0}
{"epoch": 25, "training_loss": 338.02227878570557, "training_acc": 77.0, "val_loss": 167.05453395843506, "val_acc": 52.0}
{"epoch": 26, "training_loss": 370.5959358215332, "training_acc": 76.0, "val_loss": 235.13212203979492, "val_acc": 72.0}
{"epoch": 27, "training_loss": 782.524845123291, "training_acc": 68.0, "val_loss": 478.55005264282227, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1884.9399490356445, "training_acc": 72.0, "val_loss": 106.58228397369385, "val_acc": 76.0}
{"epoch": 29, "training_loss": 1037.355369567871, "training_acc": 68.0, "val_loss": 173.32738637924194, "val_acc": 80.0}
{"epoch": 30, "training_loss": 1056.4801406860352, "training_acc": 73.0, "val_loss": 873.7428665161133, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2072.936237335205, "training_acc": 74.0, "val_loss": 694.7924613952637, "val_acc": 44.0}
{"epoch": 32, "training_loss": 2669.546941757202, "training_acc": 50.0, "val_loss": 680.7259559631348, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2269.2205810546875, "training_acc": 74.0, "val_loss": 498.49815368652344, "val_acc": 76.0}
{"epoch": 34, "training_loss": 1991.7581787109375, "training_acc": 63.0, "val_loss": 331.6352844238281, "val_acc": 76.0}
{"epoch": 35, "training_loss": 1446.4185638427734, "training_acc": 72.0, "val_loss": 859.0756416320801, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1739.5817527770996, "training_acc": 77.0, "val_loss": 535.1982116699219, "val_acc": 60.0}
{"epoch": 37, "training_loss": 1734.7901458740234, "training_acc": 57.0, "val_loss": 519.8216915130615, "val_acc": 76.0}
{"epoch": 38, "training_loss": 1043.0199546813965, "training_acc": 77.0, "val_loss": 270.4190731048584, "val_acc": 60.0}
{"epoch": 39, "training_loss": 726.0167350769043, "training_acc": 69.0, "val_loss": 408.48474502563477, "val_acc": 68.0}
{"epoch": 40, "training_loss": 955.9416809082031, "training_acc": 78.0, "val_loss": 230.10196685791016, "val_acc": 68.0}
{"epoch": 41, "training_loss": 417.5884380340576, "training_acc": 80.0, "val_loss": 301.1425495147705, "val_acc": 68.0}
{"epoch": 42, "training_loss": 507.5839681625366, "training_acc": 81.0, "val_loss": 142.2823190689087, "val_acc": 56.0}
{"epoch": 43, "training_loss": 156.24546909332275, "training_acc": 82.0, "val_loss": 228.385329246521, "val_acc": 72.0}
{"epoch": 44, "training_loss": 254.34230518341064, "training_acc": 87.0, "val_loss": 91.8803870677948, "val_acc": 68.0}
{"epoch": 45, "training_loss": 105.51623845100403, "training_acc": 87.0, "val_loss": 92.36519932746887, "val_acc": 76.0}
{"epoch": 46, "training_loss": 164.28238105773926, "training_acc": 88.0, "val_loss": 71.70436978340149, "val_acc": 72.0}
{"epoch": 47, "training_loss": 330.0369701385498, "training_acc": 81.0, "val_loss": 109.04442071914673, "val_acc": 68.0}
{"epoch": 48, "training_loss": 276.66854095458984, "training_acc": 77.0, "val_loss": 468.4460639953613, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1274.7289924621582, "training_acc": 72.0, "val_loss": 523.2823848724365, "val_acc": 40.0}
{"epoch": 50, "training_loss": 1461.9710731506348, "training_acc": 58.0, "val_loss": 619.4973468780518, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1483.3984146118164, "training_acc": 74.0, "val_loss": 200.8364200592041, "val_acc": 76.0}
{"epoch": 52, "training_loss": 849.5425643920898, "training_acc": 72.0, "val_loss": 301.1179447174072, "val_acc": 72.0}
{"epoch": 53, "training_loss": 930.2977676391602, "training_acc": 79.0, "val_loss": 207.01193809509277, "val_acc": 76.0}
{"epoch": 54, "training_loss": 520.1725177764893, "training_acc": 78.0, "val_loss": 212.64488697052002, "val_acc": 76.0}
{"epoch": 55, "training_loss": 335.5326261520386, "training_acc": 85.0, "val_loss": 140.41668176651, "val_acc": 68.0}
{"epoch": 56, "training_loss": 101.2793924510479, "training_acc": 85.0, "val_loss": 237.5856876373291, "val_acc": 68.0}
{"epoch": 57, "training_loss": 232.29520893096924, "training_acc": 86.0, "val_loss": 138.9959692955017, "val_acc": 64.0}
{"epoch": 58, "training_loss": 110.06149435043335, "training_acc": 86.0, "val_loss": 143.83589029312134, "val_acc": 72.0}
{"epoch": 59, "training_loss": 101.722243309021, "training_acc": 93.0, "val_loss": 126.58721208572388, "val_acc": 64.0}
{"epoch": 60, "training_loss": 145.37185144424438, "training_acc": 88.0, "val_loss": 173.31074476242065, "val_acc": 68.0}
{"epoch": 61, "training_loss": 262.22739028930664, "training_acc": 79.0, "val_loss": 386.0997200012207, "val_acc": 72.0}
{"epoch": 62, "training_loss": 552.404926776886, "training_acc": 79.0, "val_loss": 276.1026620864868, "val_acc": 64.0}
{"epoch": 63, "training_loss": 864.0660419464111, "training_acc": 65.0, "val_loss": 435.4266166687012, "val_acc": 72.0}
{"epoch": 64, "training_loss": 570.2560524940491, "training_acc": 82.0, "val_loss": 349.37238693237305, "val_acc": 56.0}
{"epoch": 65, "training_loss": 1726.7180938720703, "training_acc": 51.0, "val_loss": 781.532621383667, "val_acc": 72.0}
