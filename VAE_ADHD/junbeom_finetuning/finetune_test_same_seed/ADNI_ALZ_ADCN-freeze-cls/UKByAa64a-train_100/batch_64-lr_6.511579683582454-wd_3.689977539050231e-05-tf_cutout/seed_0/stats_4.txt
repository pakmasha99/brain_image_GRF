"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7570.350067138672, "training_acc": 46.0, "val_loss": 5126.153564453125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15594.957489013672, "training_acc": 72.0, "val_loss": 5394.33479309082, "val_acc": 28.0}
{"epoch": 2, "training_loss": 22795.15313720703, "training_acc": 29.0, "val_loss": 735.1784706115723, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5142.177337646484, "training_acc": 74.0, "val_loss": 3832.396697998047, "val_acc": 72.0}
{"epoch": 4, "training_loss": 14225.833618164062, "training_acc": 72.0, "val_loss": 3444.239044189453, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9646.78012084961, "training_acc": 72.0, "val_loss": 1076.718521118164, "val_acc": 68.0}
{"epoch": 6, "training_loss": 6297.9227294921875, "training_acc": 62.0, "val_loss": 2314.9805068969727, "val_acc": 48.0}
{"epoch": 7, "training_loss": 11223.365142822266, "training_acc": 43.0, "val_loss": 1298.5444068908691, "val_acc": 76.0}
{"epoch": 8, "training_loss": 3250.9461975097656, "training_acc": 77.0, "val_loss": 2494.704055786133, "val_acc": 72.0}
{"epoch": 9, "training_loss": 7422.009338378906, "training_acc": 72.0, "val_loss": 1539.4819259643555, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3730.758590698242, "training_acc": 72.0, "val_loss": 1141.3079261779785, "val_acc": 56.0}
{"epoch": 11, "training_loss": 6023.979827880859, "training_acc": 50.0, "val_loss": 766.022253036499, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2448.627899169922, "training_acc": 72.0, "val_loss": 1582.6982498168945, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4559.752212524414, "training_acc": 72.0, "val_loss": 482.367467880249, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1629.010597229004, "training_acc": 73.0, "val_loss": 990.2352333068848, "val_acc": 36.0}
{"epoch": 15, "training_loss": 3283.4168968200684, "training_acc": 56.0, "val_loss": 809.935188293457, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3101.584930419922, "training_acc": 72.0, "val_loss": 168.3511257171631, "val_acc": 76.0}
{"epoch": 17, "training_loss": 2299.0092163085938, "training_acc": 62.0, "val_loss": 309.233021736145, "val_acc": 52.0}
{"epoch": 18, "training_loss": 1710.146354675293, "training_acc": 64.0, "val_loss": 1079.4695854187012, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4232.745582580566, "training_acc": 72.0, "val_loss": 233.80060195922852, "val_acc": 76.0}
{"epoch": 20, "training_loss": 1803.218505859375, "training_acc": 65.0, "val_loss": 512.0808601379395, "val_acc": 56.0}
{"epoch": 21, "training_loss": 1619.814052581787, "training_acc": 70.0, "val_loss": 830.1405906677246, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2791.676525115967, "training_acc": 72.0, "val_loss": 285.71910858154297, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1435.7235260009766, "training_acc": 70.0, "val_loss": 271.16973400115967, "val_acc": 76.0}
{"epoch": 24, "training_loss": 1216.8427391052246, "training_acc": 74.0, "val_loss": 522.6230144500732, "val_acc": 76.0}
{"epoch": 25, "training_loss": 1336.8327713012695, "training_acc": 75.0, "val_loss": 207.405424118042, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1069.163516998291, "training_acc": 65.0, "val_loss": 270.97771167755127, "val_acc": 76.0}
{"epoch": 27, "training_loss": 1048.2309265136719, "training_acc": 76.0, "val_loss": 234.43613052368164, "val_acc": 52.0}
{"epoch": 28, "training_loss": 939.696460723877, "training_acc": 62.0, "val_loss": 663.6210918426514, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3004.2535400390625, "training_acc": 72.0, "val_loss": 652.2573471069336, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1882.6396827697754, "training_acc": 68.0, "val_loss": 366.31715297698975, "val_acc": 48.0}
{"epoch": 31, "training_loss": 1620.7868156433105, "training_acc": 61.0, "val_loss": 652.3928165435791, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1560.011474609375, "training_acc": 76.0, "val_loss": 348.4731674194336, "val_acc": 64.0}
{"epoch": 33, "training_loss": 1598.3498649597168, "training_acc": 66.0, "val_loss": 472.3287582397461, "val_acc": 76.0}
{"epoch": 34, "training_loss": 1432.0508270263672, "training_acc": 78.0, "val_loss": 450.09546279907227, "val_acc": 76.0}
{"epoch": 35, "training_loss": 1198.3798942565918, "training_acc": 75.0, "val_loss": 194.6423888206482, "val_acc": 72.0}
