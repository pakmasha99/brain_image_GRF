"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 91.57735252380371, "training_acc": 72.0, "val_loss": 14.48633223772049, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.51663780212402, "training_acc": 70.0, "val_loss": 13.715000450611115, "val_acc": 76.0}
{"epoch": 2, "training_loss": 62.66285991668701, "training_acc": 72.0, "val_loss": 14.904867112636566, "val_acc": 72.0}
{"epoch": 3, "training_loss": 56.675008058547974, "training_acc": 74.0, "val_loss": 19.412021338939667, "val_acc": 44.0}
{"epoch": 4, "training_loss": 85.19515776634216, "training_acc": 45.0, "val_loss": 13.253331184387207, "val_acc": 76.0}
{"epoch": 5, "training_loss": 61.610140562057495, "training_acc": 72.0, "val_loss": 22.811761498451233, "val_acc": 72.0}
{"epoch": 6, "training_loss": 82.38012456893921, "training_acc": 72.0, "val_loss": 13.910889625549316, "val_acc": 76.0}
{"epoch": 7, "training_loss": 57.720983028411865, "training_acc": 69.0, "val_loss": 17.29835867881775, "val_acc": 52.0}
{"epoch": 8, "training_loss": 63.21145296096802, "training_acc": 63.0, "val_loss": 13.548853993415833, "val_acc": 76.0}
{"epoch": 9, "training_loss": 56.084604024887085, "training_acc": 73.0, "val_loss": 14.928284287452698, "val_acc": 72.0}
{"epoch": 10, "training_loss": 56.636687874794006, "training_acc": 72.0, "val_loss": 14.142823219299316, "val_acc": 76.0}
{"epoch": 11, "training_loss": 54.29626226425171, "training_acc": 72.0, "val_loss": 13.251890242099762, "val_acc": 56.0}
{"epoch": 12, "training_loss": 55.32461500167847, "training_acc": 75.0, "val_loss": 13.442081212997437, "val_acc": 56.0}
{"epoch": 13, "training_loss": 51.62347590923309, "training_acc": 74.0, "val_loss": 14.55460786819458, "val_acc": 72.0}
{"epoch": 14, "training_loss": 56.360480427742004, "training_acc": 72.0, "val_loss": 13.880489766597748, "val_acc": 76.0}
{"epoch": 15, "training_loss": 54.216667890548706, "training_acc": 72.0, "val_loss": 13.17657083272934, "val_acc": 72.0}
{"epoch": 16, "training_loss": 53.12157416343689, "training_acc": 81.0, "val_loss": 13.07717114686966, "val_acc": 68.0}
{"epoch": 17, "training_loss": 51.96125519275665, "training_acc": 74.0, "val_loss": 13.666152954101562, "val_acc": 76.0}
{"epoch": 18, "training_loss": 53.662497997283936, "training_acc": 73.0, "val_loss": 12.972092628479004, "val_acc": 60.0}
{"epoch": 19, "training_loss": 50.831069111824036, "training_acc": 76.0, "val_loss": 12.854620814323425, "val_acc": 64.0}
{"epoch": 20, "training_loss": 48.01345241069794, "training_acc": 77.0, "val_loss": 14.283894002437592, "val_acc": 76.0}
{"epoch": 21, "training_loss": 56.55891275405884, "training_acc": 72.0, "val_loss": 12.593863904476166, "val_acc": 68.0}
{"epoch": 22, "training_loss": 52.87083959579468, "training_acc": 76.0, "val_loss": 12.559978663921356, "val_acc": 72.0}
{"epoch": 23, "training_loss": 50.91527462005615, "training_acc": 76.0, "val_loss": 13.384634256362915, "val_acc": 76.0}
{"epoch": 24, "training_loss": 51.93163514137268, "training_acc": 72.0, "val_loss": 13.008716702461243, "val_acc": 68.0}
{"epoch": 25, "training_loss": 51.49864721298218, "training_acc": 77.0, "val_loss": 13.651250302791595, "val_acc": 56.0}
{"epoch": 26, "training_loss": 51.114731550216675, "training_acc": 79.0, "val_loss": 13.639087975025177, "val_acc": 76.0}
{"epoch": 27, "training_loss": 52.41132092475891, "training_acc": 72.0, "val_loss": 14.14065957069397, "val_acc": 72.0}
{"epoch": 28, "training_loss": 54.86028480529785, "training_acc": 72.0, "val_loss": 14.527229964733124, "val_acc": 72.0}
{"epoch": 29, "training_loss": 51.86038339138031, "training_acc": 72.0, "val_loss": 13.28490525484085, "val_acc": 60.0}
{"epoch": 30, "training_loss": 49.94176506996155, "training_acc": 79.0, "val_loss": 13.057361543178558, "val_acc": 80.0}
{"epoch": 31, "training_loss": 49.58202934265137, "training_acc": 75.0, "val_loss": 12.382153421640396, "val_acc": 68.0}
{"epoch": 32, "training_loss": 50.19411492347717, "training_acc": 75.0, "val_loss": 12.44766190648079, "val_acc": 68.0}
{"epoch": 33, "training_loss": 47.67499613761902, "training_acc": 75.0, "val_loss": 12.522514164447784, "val_acc": 68.0}
{"epoch": 34, "training_loss": 50.72777497768402, "training_acc": 74.0, "val_loss": 12.96694278717041, "val_acc": 72.0}
{"epoch": 35, "training_loss": 54.73168861865997, "training_acc": 73.0, "val_loss": 14.708879590034485, "val_acc": 76.0}
{"epoch": 36, "training_loss": 54.952812910079956, "training_acc": 72.0, "val_loss": 12.88011223077774, "val_acc": 64.0}
{"epoch": 37, "training_loss": 46.27476906776428, "training_acc": 78.0, "val_loss": 13.39024156332016, "val_acc": 72.0}
{"epoch": 38, "training_loss": 47.12920951843262, "training_acc": 79.0, "val_loss": 13.040673732757568, "val_acc": 64.0}
{"epoch": 39, "training_loss": 47.34225535392761, "training_acc": 78.0, "val_loss": 13.082315027713776, "val_acc": 72.0}
{"epoch": 40, "training_loss": 46.40095281600952, "training_acc": 77.0, "val_loss": 12.965470552444458, "val_acc": 72.0}
{"epoch": 41, "training_loss": 47.11029267311096, "training_acc": 77.0, "val_loss": 12.667690217494965, "val_acc": 68.0}
{"epoch": 42, "training_loss": 49.43724966049194, "training_acc": 74.0, "val_loss": 12.765885889530182, "val_acc": 68.0}
{"epoch": 43, "training_loss": 48.84473407268524, "training_acc": 76.0, "val_loss": 14.088624715805054, "val_acc": 76.0}
{"epoch": 44, "training_loss": 49.692315101623535, "training_acc": 72.0, "val_loss": 13.4004145860672, "val_acc": 76.0}
{"epoch": 45, "training_loss": 46.06256914138794, "training_acc": 75.0, "val_loss": 13.052265346050262, "val_acc": 68.0}
{"epoch": 46, "training_loss": 50.37678098678589, "training_acc": 78.0, "val_loss": 13.080067932605743, "val_acc": 60.0}
{"epoch": 47, "training_loss": 46.39634609222412, "training_acc": 80.0, "val_loss": 13.709861040115356, "val_acc": 76.0}
{"epoch": 48, "training_loss": 47.02865397930145, "training_acc": 77.0, "val_loss": 13.277758657932281, "val_acc": 60.0}
{"epoch": 49, "training_loss": 47.41188383102417, "training_acc": 80.0, "val_loss": 13.152271509170532, "val_acc": 68.0}
{"epoch": 50, "training_loss": 46.15046191215515, "training_acc": 80.0, "val_loss": 13.547295331954956, "val_acc": 76.0}
