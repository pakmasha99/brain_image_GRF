"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1471.214527130127, "training_acc": 44.0, "val_loss": 659.0053081512451, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2455.9309101104736, "training_acc": 72.0, "val_loss": 491.7484760284424, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1832.511043548584, "training_acc": 28.0, "val_loss": 190.5721664428711, "val_acc": 72.0}
{"epoch": 3, "training_loss": 790.8551902770996, "training_acc": 72.0, "val_loss": 362.1708393096924, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1153.0957431793213, "training_acc": 72.0, "val_loss": 153.45120429992676, "val_acc": 76.0}
{"epoch": 5, "training_loss": 619.921760559082, "training_acc": 66.0, "val_loss": 161.88033819198608, "val_acc": 60.0}
{"epoch": 6, "training_loss": 772.0846557617188, "training_acc": 59.0, "val_loss": 204.41834926605225, "val_acc": 72.0}
{"epoch": 7, "training_loss": 531.054780960083, "training_acc": 75.0, "val_loss": 219.45528984069824, "val_acc": 72.0}
{"epoch": 8, "training_loss": 519.4101276397705, "training_acc": 74.0, "val_loss": 124.90882873535156, "val_acc": 64.0}
{"epoch": 9, "training_loss": 540.2274627685547, "training_acc": 60.0, "val_loss": 98.5015869140625, "val_acc": 64.0}
{"epoch": 10, "training_loss": 279.24405670166016, "training_acc": 78.0, "val_loss": 137.21970319747925, "val_acc": 72.0}
{"epoch": 11, "training_loss": 290.46391105651855, "training_acc": 75.0, "val_loss": 66.54813289642334, "val_acc": 56.0}
{"epoch": 12, "training_loss": 273.8334836959839, "training_acc": 55.0, "val_loss": 72.79506325721741, "val_acc": 72.0}
{"epoch": 13, "training_loss": 264.7319030761719, "training_acc": 72.0, "val_loss": 16.81372970342636, "val_acc": 84.0}
{"epoch": 14, "training_loss": 225.20620346069336, "training_acc": 63.0, "val_loss": 13.303440809249878, "val_acc": 64.0}
{"epoch": 15, "training_loss": 165.249831199646, "training_acc": 74.0, "val_loss": 71.3793694972992, "val_acc": 72.0}
{"epoch": 16, "training_loss": 216.49343633651733, "training_acc": 73.0, "val_loss": 126.21569633483887, "val_acc": 28.0}
{"epoch": 17, "training_loss": 312.71011424064636, "training_acc": 52.0, "val_loss": 71.94135189056396, "val_acc": 72.0}
{"epoch": 18, "training_loss": 237.22108364105225, "training_acc": 72.0, "val_loss": 56.71868920326233, "val_acc": 44.0}
{"epoch": 19, "training_loss": 230.28782844543457, "training_acc": 56.0, "val_loss": 71.36770486831665, "val_acc": 72.0}
{"epoch": 20, "training_loss": 252.1663179397583, "training_acc": 72.0, "val_loss": 47.98694550991058, "val_acc": 76.0}
{"epoch": 21, "training_loss": 263.6053276062012, "training_acc": 66.0, "val_loss": 42.69527196884155, "val_acc": 64.0}
{"epoch": 22, "training_loss": 209.82708930969238, "training_acc": 68.0, "val_loss": 101.60377025604248, "val_acc": 72.0}
{"epoch": 23, "training_loss": 242.0730357170105, "training_acc": 74.0, "val_loss": 43.59241724014282, "val_acc": 68.0}
{"epoch": 24, "training_loss": 191.7800099849701, "training_acc": 63.0, "val_loss": 46.815621852874756, "val_acc": 76.0}
{"epoch": 25, "training_loss": 105.04902935028076, "training_acc": 77.0, "val_loss": 18.846525251865387, "val_acc": 68.0}
{"epoch": 26, "training_loss": 73.24272108078003, "training_acc": 73.0, "val_loss": 45.38663327693939, "val_acc": 72.0}
{"epoch": 27, "training_loss": 132.44559454917908, "training_acc": 72.0, "val_loss": 126.7182469367981, "val_acc": 28.0}
{"epoch": 28, "training_loss": 321.951642870903, "training_acc": 51.0, "val_loss": 48.39196801185608, "val_acc": 72.0}
{"epoch": 29, "training_loss": 126.02020764350891, "training_acc": 74.0, "val_loss": 123.0414867401123, "val_acc": 28.0}
{"epoch": 30, "training_loss": 280.9872794151306, "training_acc": 55.0, "val_loss": 69.58999633789062, "val_acc": 72.0}
{"epoch": 31, "training_loss": 198.3831925392151, "training_acc": 73.0, "val_loss": 22.09746092557907, "val_acc": 72.0}
{"epoch": 32, "training_loss": 102.51056814193726, "training_acc": 71.0, "val_loss": 43.160927295684814, "val_acc": 80.0}
{"epoch": 33, "training_loss": 109.95566511154175, "training_acc": 79.0, "val_loss": 39.697661995887756, "val_acc": 76.0}
