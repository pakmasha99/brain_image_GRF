"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1061.4836807250977, "training_acc": 72.0, "val_loss": 654.2757511138916, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1766.155849456787, "training_acc": 72.0, "val_loss": 1002.3965835571289, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3671.34033203125, "training_acc": 28.0, "val_loss": 178.34511995315552, "val_acc": 64.0}
{"epoch": 3, "training_loss": 532.2229995727539, "training_acc": 67.0, "val_loss": 590.1204586029053, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2437.220863342285, "training_acc": 72.0, "val_loss": 735.0023746490479, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2742.3745727539062, "training_acc": 72.0, "val_loss": 488.07268142700195, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1437.5427551269531, "training_acc": 72.0, "val_loss": 241.36788845062256, "val_acc": 64.0}
{"epoch": 7, "training_loss": 913.9121551513672, "training_acc": 57.0, "val_loss": 542.0964241027832, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1812.8477096557617, "training_acc": 38.0, "val_loss": 238.6002540588379, "val_acc": 68.0}
{"epoch": 9, "training_loss": 511.88879203796387, "training_acc": 75.0, "val_loss": 357.12313652038574, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1399.6193923950195, "training_acc": 72.0, "val_loss": 356.784987449646, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1091.2470664978027, "training_acc": 72.0, "val_loss": 216.3395881652832, "val_acc": 72.0}
{"epoch": 12, "training_loss": 605.9409294128418, "training_acc": 65.0, "val_loss": 318.14727783203125, "val_acc": 48.0}
{"epoch": 13, "training_loss": 1004.1136741638184, "training_acc": 46.0, "val_loss": 174.16528463363647, "val_acc": 68.0}
{"epoch": 14, "training_loss": 412.4016170501709, "training_acc": 76.0, "val_loss": 195.52658796310425, "val_acc": 72.0}
{"epoch": 15, "training_loss": 694.2133884429932, "training_acc": 72.0, "val_loss": 106.00848197937012, "val_acc": 76.0}
{"epoch": 16, "training_loss": 266.96610927581787, "training_acc": 76.0, "val_loss": 172.38874435424805, "val_acc": 36.0}
{"epoch": 17, "training_loss": 485.4637269973755, "training_acc": 48.0, "val_loss": 74.93990659713745, "val_acc": 76.0}
{"epoch": 18, "training_loss": 417.99784660339355, "training_acc": 73.0, "val_loss": 79.28646802902222, "val_acc": 72.0}
{"epoch": 19, "training_loss": 248.940673828125, "training_acc": 68.0, "val_loss": 94.58109736442566, "val_acc": 36.0}
{"epoch": 20, "training_loss": 207.48613166809082, "training_acc": 59.0, "val_loss": 51.48929953575134, "val_acc": 72.0}
{"epoch": 21, "training_loss": 182.07123136520386, "training_acc": 77.0, "val_loss": 91.14577770233154, "val_acc": 36.0}
{"epoch": 22, "training_loss": 197.54276758432388, "training_acc": 62.0, "val_loss": 40.63592553138733, "val_acc": 80.0}
{"epoch": 23, "training_loss": 153.98919701576233, "training_acc": 77.0, "val_loss": 47.10346162319183, "val_acc": 56.0}
{"epoch": 24, "training_loss": 118.37522184848785, "training_acc": 66.0, "val_loss": 34.33554470539093, "val_acc": 84.0}
{"epoch": 25, "training_loss": 116.10528874397278, "training_acc": 78.0, "val_loss": 26.29273235797882, "val_acc": 56.0}
{"epoch": 26, "training_loss": 77.29624652862549, "training_acc": 77.0, "val_loss": 13.365839421749115, "val_acc": 88.0}
{"epoch": 27, "training_loss": 61.22388458251953, "training_acc": 81.0, "val_loss": 14.965438842773438, "val_acc": 72.0}
{"epoch": 28, "training_loss": 73.35818147659302, "training_acc": 73.0, "val_loss": 29.829376935958862, "val_acc": 72.0}
{"epoch": 29, "training_loss": 103.37821173667908, "training_acc": 75.0, "val_loss": 29.336410760879517, "val_acc": 56.0}
{"epoch": 30, "training_loss": 98.48477840423584, "training_acc": 73.0, "val_loss": 12.953317165374756, "val_acc": 88.0}
{"epoch": 31, "training_loss": 88.66397714614868, "training_acc": 72.0, "val_loss": 25.593504309654236, "val_acc": 84.0}
{"epoch": 32, "training_loss": 92.76199948787689, "training_acc": 78.0, "val_loss": 22.733677923679352, "val_acc": 60.0}
{"epoch": 33, "training_loss": 55.15709328651428, "training_acc": 79.0, "val_loss": 18.264193832874298, "val_acc": 80.0}
{"epoch": 34, "training_loss": 81.87048721313477, "training_acc": 81.0, "val_loss": 81.98761343955994, "val_acc": 40.0}
{"epoch": 35, "training_loss": 202.36957955360413, "training_acc": 57.0, "val_loss": 24.449126422405243, "val_acc": 84.0}
{"epoch": 36, "training_loss": 140.7655520439148, "training_acc": 70.0, "val_loss": 17.09527224302292, "val_acc": 84.0}
{"epoch": 37, "training_loss": 64.70286345481873, "training_acc": 81.0, "val_loss": 16.759449243545532, "val_acc": 60.0}
{"epoch": 38, "training_loss": 33.01649570465088, "training_acc": 84.0, "val_loss": 17.52578765153885, "val_acc": 60.0}
{"epoch": 39, "training_loss": 85.17912912368774, "training_acc": 68.0, "val_loss": 107.28216171264648, "val_acc": 36.0}
{"epoch": 40, "training_loss": 258.82184076309204, "training_acc": 46.0, "val_loss": 22.46568650007248, "val_acc": 80.0}
{"epoch": 41, "training_loss": 90.08968949317932, "training_acc": 76.0, "val_loss": 24.844272434711456, "val_acc": 64.0}
{"epoch": 42, "training_loss": 78.60709714889526, "training_acc": 77.0, "val_loss": 17.395129799842834, "val_acc": 80.0}
{"epoch": 43, "training_loss": 87.34057903289795, "training_acc": 73.0, "val_loss": 21.448487043380737, "val_acc": 84.0}
{"epoch": 44, "training_loss": 87.11018991470337, "training_acc": 78.0, "val_loss": 21.05622887611389, "val_acc": 68.0}
{"epoch": 45, "training_loss": 63.250264406204224, "training_acc": 71.0, "val_loss": 34.64001715183258, "val_acc": 72.0}
{"epoch": 46, "training_loss": 148.51840806007385, "training_acc": 74.0, "val_loss": 43.29676628112793, "val_acc": 40.0}
{"epoch": 47, "training_loss": 68.17163264751434, "training_acc": 71.0, "val_loss": 21.59031182527542, "val_acc": 80.0}
{"epoch": 48, "training_loss": 71.8297426700592, "training_acc": 77.0, "val_loss": 52.278321981430054, "val_acc": 44.0}
{"epoch": 49, "training_loss": 135.51852083206177, "training_acc": 63.0, "val_loss": 26.412728428840637, "val_acc": 80.0}
