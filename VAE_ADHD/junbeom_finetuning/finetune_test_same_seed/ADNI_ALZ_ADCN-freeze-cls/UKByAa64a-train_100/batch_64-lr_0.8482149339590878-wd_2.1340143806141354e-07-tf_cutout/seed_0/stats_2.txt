"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1330.2468338012695, "training_acc": 44.0, "val_loss": 708.7972640991211, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2294.4918365478516, "training_acc": 72.0, "val_loss": 428.88827323913574, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1594.991226196289, "training_acc": 33.0, "val_loss": 159.58235263824463, "val_acc": 72.0}
{"epoch": 3, "training_loss": 678.1038208007812, "training_acc": 71.0, "val_loss": 332.86328315734863, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1021.1120147705078, "training_acc": 72.0, "val_loss": 134.74148511886597, "val_acc": 68.0}
{"epoch": 5, "training_loss": 617.3038902282715, "training_acc": 70.0, "val_loss": 193.13174486160278, "val_acc": 48.0}
{"epoch": 6, "training_loss": 901.1269226074219, "training_acc": 56.0, "val_loss": 176.5117049217224, "val_acc": 76.0}
{"epoch": 7, "training_loss": 618.8599834442139, "training_acc": 75.0, "val_loss": 272.9132652282715, "val_acc": 72.0}
{"epoch": 8, "training_loss": 756.7870712280273, "training_acc": 72.0, "val_loss": 98.12638759613037, "val_acc": 80.0}
{"epoch": 9, "training_loss": 505.1748390197754, "training_acc": 62.0, "val_loss": 139.71023559570312, "val_acc": 48.0}
{"epoch": 10, "training_loss": 557.757908821106, "training_acc": 54.0, "val_loss": 167.2835350036621, "val_acc": 72.0}
{"epoch": 11, "training_loss": 548.0779838562012, "training_acc": 72.0, "val_loss": 136.86375617980957, "val_acc": 72.0}
{"epoch": 12, "training_loss": 315.435311794281, "training_acc": 73.0, "val_loss": 174.99865293502808, "val_acc": 40.0}
{"epoch": 13, "training_loss": 478.45072174072266, "training_acc": 49.0, "val_loss": 123.91762733459473, "val_acc": 72.0}
{"epoch": 14, "training_loss": 467.06110763549805, "training_acc": 72.0, "val_loss": 93.29540133476257, "val_acc": 72.0}
{"epoch": 15, "training_loss": 339.6371822357178, "training_acc": 60.0, "val_loss": 60.37192940711975, "val_acc": 60.0}
{"epoch": 16, "training_loss": 314.2572889328003, "training_acc": 58.0, "val_loss": 120.20212411880493, "val_acc": 72.0}
{"epoch": 17, "training_loss": 272.10997915267944, "training_acc": 72.0, "val_loss": 62.52714395523071, "val_acc": 68.0}
{"epoch": 18, "training_loss": 184.88998413085938, "training_acc": 69.0, "val_loss": 63.71861696243286, "val_acc": 72.0}
{"epoch": 19, "training_loss": 146.98179483413696, "training_acc": 81.0, "val_loss": 77.03484892845154, "val_acc": 72.0}
{"epoch": 20, "training_loss": 132.7278289794922, "training_acc": 80.0, "val_loss": 51.59909725189209, "val_acc": 64.0}
{"epoch": 21, "training_loss": 187.08586812019348, "training_acc": 63.0, "val_loss": 40.38843810558319, "val_acc": 68.0}
{"epoch": 22, "training_loss": 78.09742283821106, "training_acc": 79.0, "val_loss": 29.208770394325256, "val_acc": 68.0}
{"epoch": 23, "training_loss": 79.33444666862488, "training_acc": 71.0, "val_loss": 50.12763738632202, "val_acc": 72.0}
{"epoch": 24, "training_loss": 138.74417924880981, "training_acc": 72.0, "val_loss": 17.791961133480072, "val_acc": 56.0}
{"epoch": 25, "training_loss": 37.45906740427017, "training_acc": 82.0, "val_loss": 32.58363604545593, "val_acc": 72.0}
{"epoch": 26, "training_loss": 92.15997457504272, "training_acc": 71.0, "val_loss": 34.94175672531128, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.07801842689514, "training_acc": 81.0, "val_loss": 23.740389943122864, "val_acc": 72.0}
{"epoch": 28, "training_loss": 70.16729438304901, "training_acc": 80.0, "val_loss": 67.44562983512878, "val_acc": 72.0}
{"epoch": 29, "training_loss": 170.22072911262512, "training_acc": 75.0, "val_loss": 26.310160756111145, "val_acc": 60.0}
{"epoch": 30, "training_loss": 128.98500967025757, "training_acc": 63.0, "val_loss": 29.090145230293274, "val_acc": 76.0}
{"epoch": 31, "training_loss": 72.37376594543457, "training_acc": 77.0, "val_loss": 20.031124353408813, "val_acc": 72.0}
{"epoch": 32, "training_loss": 48.63743782043457, "training_acc": 85.0, "val_loss": 27.035459876060486, "val_acc": 64.0}
{"epoch": 33, "training_loss": 109.26903176307678, "training_acc": 64.0, "val_loss": 33.04773569107056, "val_acc": 76.0}
{"epoch": 34, "training_loss": 96.62274837493896, "training_acc": 70.0, "val_loss": 32.22775459289551, "val_acc": 76.0}
{"epoch": 35, "training_loss": 92.05364465713501, "training_acc": 78.0, "val_loss": 35.64685881137848, "val_acc": 60.0}
{"epoch": 36, "training_loss": 80.79096585512161, "training_acc": 71.0, "val_loss": 44.54360008239746, "val_acc": 72.0}
{"epoch": 37, "training_loss": 77.68791782855988, "training_acc": 80.0, "val_loss": 43.151724338531494, "val_acc": 60.0}
{"epoch": 38, "training_loss": 135.82601881027222, "training_acc": 67.0, "val_loss": 55.000239610672, "val_acc": 72.0}
{"epoch": 39, "training_loss": 167.17983102798462, "training_acc": 67.0, "val_loss": 24.77530986070633, "val_acc": 68.0}
{"epoch": 40, "training_loss": 53.457653284072876, "training_acc": 84.0, "val_loss": 31.483355164527893, "val_acc": 72.0}
{"epoch": 41, "training_loss": 127.99538707733154, "training_acc": 65.0, "val_loss": 59.69803333282471, "val_acc": 72.0}
{"epoch": 42, "training_loss": 182.93856811523438, "training_acc": 74.0, "val_loss": 24.85242187976837, "val_acc": 68.0}
{"epoch": 43, "training_loss": 162.82693672180176, "training_acc": 71.0, "val_loss": 47.96031713485718, "val_acc": 76.0}
