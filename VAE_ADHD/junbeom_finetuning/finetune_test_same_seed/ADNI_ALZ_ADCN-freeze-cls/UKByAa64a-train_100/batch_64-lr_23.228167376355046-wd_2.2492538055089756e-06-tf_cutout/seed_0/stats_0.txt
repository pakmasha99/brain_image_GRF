"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 37668.96027755737, "training_acc": 72.0, "val_loss": 16639.44854736328, "val_acc": 72.0}
{"epoch": 1, "training_loss": 45318.95422363281, "training_acc": 72.0, "val_loss": 26129.678344726562, "val_acc": 28.0}
{"epoch": 2, "training_loss": 109346.9365234375, "training_acc": 28.0, "val_loss": 4767.6849365234375, "val_acc": 36.0}
{"epoch": 3, "training_loss": 28932.851928710938, "training_acc": 51.0, "val_loss": 14863.998413085938, "val_acc": 72.0}
{"epoch": 4, "training_loss": 66875.27685546875, "training_acc": 72.0, "val_loss": 19835.476684570312, "val_acc": 72.0}
{"epoch": 5, "training_loss": 79174.52966308594, "training_acc": 72.0, "val_loss": 14655.809020996094, "val_acc": 72.0}
{"epoch": 6, "training_loss": 51492.83801269531, "training_acc": 72.0, "val_loss": 3167.4482345581055, "val_acc": 72.0}
{"epoch": 7, "training_loss": 26704.111083984375, "training_acc": 64.0, "val_loss": 5520.715713500977, "val_acc": 52.0}
{"epoch": 8, "training_loss": 41624.01873779297, "training_acc": 48.0, "val_loss": 1905.8671951293945, "val_acc": 80.0}
{"epoch": 9, "training_loss": 19560.690521240234, "training_acc": 71.0, "val_loss": 5190.958023071289, "val_acc": 72.0}
{"epoch": 10, "training_loss": 22876.2421875, "training_acc": 73.0, "val_loss": 6009.003829956055, "val_acc": 72.0}
{"epoch": 11, "training_loss": 19093.846252441406, "training_acc": 71.0, "val_loss": 1200.5695343017578, "val_acc": 80.0}
{"epoch": 12, "training_loss": 12556.236694335938, "training_acc": 60.0, "val_loss": 1661.4164352416992, "val_acc": 68.0}
{"epoch": 13, "training_loss": 7704.612045288086, "training_acc": 68.0, "val_loss": 4195.349502563477, "val_acc": 72.0}
{"epoch": 14, "training_loss": 15339.921081542969, "training_acc": 72.0, "val_loss": 2929.62703704834, "val_acc": 72.0}
{"epoch": 15, "training_loss": 7854.548309326172, "training_acc": 66.0, "val_loss": 2083.8294982910156, "val_acc": 56.0}
{"epoch": 16, "training_loss": 8830.286041259766, "training_acc": 59.0, "val_loss": 2650.4833221435547, "val_acc": 72.0}
{"epoch": 17, "training_loss": 6793.258712768555, "training_acc": 71.0, "val_loss": 1356.8320274353027, "val_acc": 52.0}
{"epoch": 18, "training_loss": 5423.752990722656, "training_acc": 53.0, "val_loss": 1131.6590309143066, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4400.84016418457, "training_acc": 74.0, "val_loss": 886.7270469665527, "val_acc": 60.0}
{"epoch": 20, "training_loss": 3516.581916809082, "training_acc": 73.0, "val_loss": 1112.8297805786133, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4629.503082275391, "training_acc": 78.0, "val_loss": 777.7305126190186, "val_acc": 60.0}
{"epoch": 22, "training_loss": 4071.659942626953, "training_acc": 63.0, "val_loss": 782.5469970703125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2607.003631591797, "training_acc": 77.0, "val_loss": 703.6969661712646, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1591.6707439422607, "training_acc": 71.0, "val_loss": 716.0091876983643, "val_acc": 68.0}
{"epoch": 25, "training_loss": 1603.6629524230957, "training_acc": 75.0, "val_loss": 583.9905261993408, "val_acc": 52.0}
{"epoch": 26, "training_loss": 1407.751781463623, "training_acc": 81.0, "val_loss": 886.1598014831543, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2893.387420654297, "training_acc": 65.0, "val_loss": 466.2485122680664, "val_acc": 76.0}
{"epoch": 28, "training_loss": 2926.195831298828, "training_acc": 70.0, "val_loss": 796.9610214233398, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3790.265579223633, "training_acc": 78.0, "val_loss": 278.9574146270752, "val_acc": 88.0}
{"epoch": 30, "training_loss": 4422.539001464844, "training_acc": 63.0, "val_loss": 1000.4147529602051, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4778.004089355469, "training_acc": 74.0, "val_loss": 320.6789493560791, "val_acc": 88.0}
{"epoch": 32, "training_loss": 3509.6895751953125, "training_acc": 67.0, "val_loss": 320.1218605041504, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2393.660415649414, "training_acc": 78.0, "val_loss": 1831.230354309082, "val_acc": 72.0}
{"epoch": 34, "training_loss": 4028.6408462524414, "training_acc": 78.0, "val_loss": 2148.940086364746, "val_acc": 56.0}
{"epoch": 35, "training_loss": 7563.344879150391, "training_acc": 50.0, "val_loss": 2229.4382095336914, "val_acc": 72.0}
{"epoch": 36, "training_loss": 5824.79801940918, "training_acc": 76.0, "val_loss": 839.2680168151855, "val_acc": 64.0}
{"epoch": 37, "training_loss": 3911.2462768554688, "training_acc": 71.0, "val_loss": 841.658878326416, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3367.2225036621094, "training_acc": 79.0, "val_loss": 528.3914566040039, "val_acc": 76.0}
{"epoch": 39, "training_loss": 2661.3434295654297, "training_acc": 72.0, "val_loss": 737.1076583862305, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2933.049041748047, "training_acc": 79.0, "val_loss": 402.05068588256836, "val_acc": 68.0}
{"epoch": 41, "training_loss": 3278.728271484375, "training_acc": 74.0, "val_loss": 1074.2380142211914, "val_acc": 72.0}
{"epoch": 42, "training_loss": 2919.5991287231445, "training_acc": 75.0, "val_loss": 399.2431640625, "val_acc": 68.0}
{"epoch": 43, "training_loss": 1826.6983184814453, "training_acc": 76.0, "val_loss": 1100.5651473999023, "val_acc": 72.0}
{"epoch": 44, "training_loss": 3546.083221435547, "training_acc": 79.0, "val_loss": 416.47443771362305, "val_acc": 76.0}
{"epoch": 45, "training_loss": 2958.0194702148438, "training_acc": 71.0, "val_loss": 1566.4692878723145, "val_acc": 72.0}
{"epoch": 46, "training_loss": 3510.6171646118164, "training_acc": 73.0, "val_loss": 511.9691848754883, "val_acc": 68.0}
{"epoch": 47, "training_loss": 2803.2034759521484, "training_acc": 72.0, "val_loss": 522.1223831176758, "val_acc": 68.0}
{"epoch": 48, "training_loss": 1647.3513259887695, "training_acc": 87.0, "val_loss": 1476.0615348815918, "val_acc": 72.0}
