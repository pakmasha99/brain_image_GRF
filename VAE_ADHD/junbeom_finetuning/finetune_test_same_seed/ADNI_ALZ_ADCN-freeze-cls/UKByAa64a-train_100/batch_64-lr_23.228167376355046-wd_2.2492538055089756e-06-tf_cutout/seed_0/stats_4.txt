"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 41564.740741729736, "training_acc": 41.0, "val_loss": 18286.245727539062, "val_acc": 72.0}
{"epoch": 1, "training_loss": 57104.54162597656, "training_acc": 72.0, "val_loss": 10243.800354003906, "val_acc": 32.0}
{"epoch": 2, "training_loss": 48820.478515625, "training_acc": 32.0, "val_loss": 3378.670883178711, "val_acc": 68.0}
{"epoch": 3, "training_loss": 16949.78271484375, "training_acc": 70.0, "val_loss": 9671.08383178711, "val_acc": 72.0}
{"epoch": 4, "training_loss": 28524.921875, "training_acc": 72.0, "val_loss": 4588.665771484375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 16648.769592285156, "training_acc": 65.0, "val_loss": 4192.684173583984, "val_acc": 64.0}
{"epoch": 6, "training_loss": 18121.38116455078, "training_acc": 57.0, "val_loss": 5137.051773071289, "val_acc": 68.0}
{"epoch": 7, "training_loss": 15675.130493164062, "training_acc": 73.0, "val_loss": 7452.0416259765625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 19296.472564697266, "training_acc": 72.0, "val_loss": 2752.449607849121, "val_acc": 64.0}
{"epoch": 9, "training_loss": 10537.901275634766, "training_acc": 60.0, "val_loss": 2076.177978515625, "val_acc": 64.0}
{"epoch": 10, "training_loss": 8139.033111572266, "training_acc": 65.0, "val_loss": 2355.901336669922, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5762.966354370117, "training_acc": 71.0, "val_loss": 2069.651412963867, "val_acc": 36.0}
{"epoch": 12, "training_loss": 8393.509765625, "training_acc": 54.0, "val_loss": 2844.399642944336, "val_acc": 72.0}
{"epoch": 13, "training_loss": 10008.653350830078, "training_acc": 72.0, "val_loss": 1733.285903930664, "val_acc": 40.0}
{"epoch": 14, "training_loss": 4515.28226852417, "training_acc": 56.0, "val_loss": 1609.0150833129883, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5735.4506912231445, "training_acc": 72.0, "val_loss": 1168.38960647583, "val_acc": 52.0}
{"epoch": 16, "training_loss": 4170.14192199707, "training_acc": 62.0, "val_loss": 1434.270191192627, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4165.501396179199, "training_acc": 72.0, "val_loss": 506.65578842163086, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2435.8328018188477, "training_acc": 76.0, "val_loss": 528.8245677947998, "val_acc": 76.0}
{"epoch": 19, "training_loss": 2263.773910522461, "training_acc": 77.0, "val_loss": 335.7173681259155, "val_acc": 68.0}
{"epoch": 20, "training_loss": 1794.830696105957, "training_acc": 71.0, "val_loss": 128.33502292633057, "val_acc": 80.0}
{"epoch": 21, "training_loss": 933.8311157226562, "training_acc": 71.0, "val_loss": 96.02975249290466, "val_acc": 80.0}
{"epoch": 22, "training_loss": 1047.6340103149414, "training_acc": 77.0, "val_loss": 1538.93461227417, "val_acc": 28.0}
{"epoch": 23, "training_loss": 4922.0344314575195, "training_acc": 58.0, "val_loss": 1545.4923629760742, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3150.6351890563965, "training_acc": 76.0, "val_loss": 1388.2508277893066, "val_acc": 36.0}
{"epoch": 25, "training_loss": 6601.786331176758, "training_acc": 58.0, "val_loss": 1969.4696426391602, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4117.591117858887, "training_acc": 73.0, "val_loss": 1092.5111770629883, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2922.07381439209, "training_acc": 70.0, "val_loss": 2443.157196044922, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5457.506729125977, "training_acc": 76.0, "val_loss": 1027.5830268859863, "val_acc": 68.0}
{"epoch": 29, "training_loss": 4801.972808837891, "training_acc": 61.0, "val_loss": 1842.7202224731445, "val_acc": 76.0}
{"epoch": 30, "training_loss": 4178.193893432617, "training_acc": 79.0, "val_loss": 1586.3107681274414, "val_acc": 76.0}
{"epoch": 31, "training_loss": 3751.1566009521484, "training_acc": 76.0, "val_loss": 615.7917976379395, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3732.780044555664, "training_acc": 73.0, "val_loss": 1449.3353843688965, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2696.936050415039, "training_acc": 78.0, "val_loss": 289.9214506149292, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1987.4057006835938, "training_acc": 78.0, "val_loss": 307.3275089263916, "val_acc": 68.0}
{"epoch": 35, "training_loss": 803.3776626586914, "training_acc": 81.0, "val_loss": 1072.8875160217285, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2356.7163515090942, "training_acc": 80.0, "val_loss": 401.61328315734863, "val_acc": 76.0}
{"epoch": 37, "training_loss": 1111.4813423156738, "training_acc": 78.0, "val_loss": 1015.3223037719727, "val_acc": 76.0}
{"epoch": 38, "training_loss": 1085.3939781188965, "training_acc": 84.0, "val_loss": 510.08057594299316, "val_acc": 76.0}
{"epoch": 39, "training_loss": 2172.5403747558594, "training_acc": 76.0, "val_loss": 1421.629238128662, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3555.226333618164, "training_acc": 68.0, "val_loss": 1149.6482849121094, "val_acc": 72.0}
