"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 23413.128448486328, "training_acc": 72.0, "val_loss": 15584.375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 40904.19470214844, "training_acc": 69.0, "val_loss": 14578.263854980469, "val_acc": 28.0}
{"epoch": 2, "training_loss": 40534.61489868164, "training_acc": 41.0, "val_loss": 4380.987167358398, "val_acc": 72.0}
{"epoch": 3, "training_loss": 13720.77163696289, "training_acc": 73.0, "val_loss": 3793.1106567382812, "val_acc": 68.0}
{"epoch": 4, "training_loss": 12361.609130859375, "training_acc": 53.0, "val_loss": 2881.5868377685547, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9720.993957519531, "training_acc": 72.0, "val_loss": 2810.9161376953125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 9430.679443359375, "training_acc": 66.0, "val_loss": 3296.8074798583984, "val_acc": 60.0}
{"epoch": 7, "training_loss": 7212.396087646484, "training_acc": 66.0, "val_loss": 2286.0782623291016, "val_acc": 72.0}
{"epoch": 8, "training_loss": 6827.423828125, "training_acc": 73.0, "val_loss": 4155.1116943359375, "val_acc": 36.0}
{"epoch": 9, "training_loss": 9376.980484008789, "training_acc": 51.0, "val_loss": 2534.7314834594727, "val_acc": 72.0}
{"epoch": 10, "training_loss": 10189.596099853516, "training_acc": 72.0, "val_loss": 734.3282222747803, "val_acc": 76.0}
{"epoch": 11, "training_loss": 8530.659057617188, "training_acc": 55.0, "val_loss": 1071.5377807617188, "val_acc": 60.0}
{"epoch": 12, "training_loss": 5753.482635498047, "training_acc": 70.0, "val_loss": 5371.479797363281, "val_acc": 72.0}
{"epoch": 13, "training_loss": 20555.929718017578, "training_acc": 72.0, "val_loss": 2488.1649017333984, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7384.863906860352, "training_acc": 66.0, "val_loss": 3076.6836166381836, "val_acc": 48.0}
{"epoch": 15, "training_loss": 8221.233963012695, "training_acc": 61.0, "val_loss": 1771.3266372680664, "val_acc": 80.0}
{"epoch": 16, "training_loss": 5006.374847412109, "training_acc": 77.0, "val_loss": 1797.0731735229492, "val_acc": 64.0}
{"epoch": 17, "training_loss": 4807.662872314453, "training_acc": 65.0, "val_loss": 1180.1508903503418, "val_acc": 80.0}
{"epoch": 18, "training_loss": 4739.638900756836, "training_acc": 75.0, "val_loss": 853.1940460205078, "val_acc": 80.0}
{"epoch": 19, "training_loss": 7981.246826171875, "training_acc": 53.0, "val_loss": 727.0116806030273, "val_acc": 80.0}
{"epoch": 20, "training_loss": 4076.5508728027344, "training_acc": 73.0, "val_loss": 328.2780170440674, "val_acc": 88.0}
{"epoch": 21, "training_loss": 5219.570220947266, "training_acc": 63.0, "val_loss": 676.6953468322754, "val_acc": 60.0}
{"epoch": 22, "training_loss": 3519.4461975097656, "training_acc": 77.0, "val_loss": 2383.461570739746, "val_acc": 72.0}
{"epoch": 23, "training_loss": 7156.033477783203, "training_acc": 72.0, "val_loss": 4145.348358154297, "val_acc": 40.0}
{"epoch": 24, "training_loss": 12781.076293945312, "training_acc": 48.0, "val_loss": 1671.1738586425781, "val_acc": 76.0}
{"epoch": 25, "training_loss": 8072.6290283203125, "training_acc": 74.0, "val_loss": 2504.2343139648438, "val_acc": 80.0}
{"epoch": 26, "training_loss": 8777.064056396484, "training_acc": 69.0, "val_loss": 2714.4105911254883, "val_acc": 64.0}
{"epoch": 27, "training_loss": 5420.322311401367, "training_acc": 69.0, "val_loss": 1766.5287017822266, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3930.1621856689453, "training_acc": 81.0, "val_loss": 1302.7118682861328, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1945.586654663086, "training_acc": 81.0, "val_loss": 996.9510078430176, "val_acc": 64.0}
{"epoch": 30, "training_loss": 1701.1389999389648, "training_acc": 79.0, "val_loss": 319.27330493927, "val_acc": 88.0}
{"epoch": 31, "training_loss": 1587.735610961914, "training_acc": 79.0, "val_loss": 463.0527973175049, "val_acc": 60.0}
{"epoch": 32, "training_loss": 1715.4838638305664, "training_acc": 73.0, "val_loss": 405.31811714172363, "val_acc": 68.0}
{"epoch": 33, "training_loss": 2458.688018798828, "training_acc": 70.0, "val_loss": 1000.5218505859375, "val_acc": 52.0}
{"epoch": 34, "training_loss": 2649.214630126953, "training_acc": 70.0, "val_loss": 712.9263877868652, "val_acc": 84.0}
{"epoch": 35, "training_loss": 2580.4920959472656, "training_acc": 76.0, "val_loss": 778.0483245849609, "val_acc": 64.0}
{"epoch": 36, "training_loss": 1469.234474182129, "training_acc": 78.0, "val_loss": 845.2126502990723, "val_acc": 84.0}
{"epoch": 37, "training_loss": 2165.445941925049, "training_acc": 75.0, "val_loss": 1281.5339088439941, "val_acc": 48.0}
{"epoch": 38, "training_loss": 4254.458206176758, "training_acc": 65.0, "val_loss": 762.3921871185303, "val_acc": 80.0}
{"epoch": 39, "training_loss": 5141.348297119141, "training_acc": 59.0, "val_loss": 546.3804721832275, "val_acc": 84.0}
{"epoch": 40, "training_loss": 2195.754379272461, "training_acc": 81.0, "val_loss": 383.78584384918213, "val_acc": 76.0}
{"epoch": 41, "training_loss": 2273.161361694336, "training_acc": 72.0, "val_loss": 606.1417102813721, "val_acc": 80.0}
{"epoch": 42, "training_loss": 3402.9540405273438, "training_acc": 77.0, "val_loss": 453.60584259033203, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1760.2794494628906, "training_acc": 77.0, "val_loss": 473.0432987213135, "val_acc": 72.0}
{"epoch": 44, "training_loss": 878.3107471466064, "training_acc": 86.0, "val_loss": 538.6865139007568, "val_acc": 80.0}
{"epoch": 45, "training_loss": 1571.40500831604, "training_acc": 81.0, "val_loss": 654.3379783630371, "val_acc": 68.0}
{"epoch": 46, "training_loss": 869.8043251037598, "training_acc": 84.0, "val_loss": 928.7870407104492, "val_acc": 72.0}
{"epoch": 47, "training_loss": 2051.975254058838, "training_acc": 76.0, "val_loss": 1648.1882095336914, "val_acc": 44.0}
{"epoch": 48, "training_loss": 4205.770950317383, "training_acc": 63.0, "val_loss": 1184.7654342651367, "val_acc": 72.0}
{"epoch": 49, "training_loss": 4147.44873046875, "training_acc": 72.0, "val_loss": 1561.947250366211, "val_acc": 52.0}
