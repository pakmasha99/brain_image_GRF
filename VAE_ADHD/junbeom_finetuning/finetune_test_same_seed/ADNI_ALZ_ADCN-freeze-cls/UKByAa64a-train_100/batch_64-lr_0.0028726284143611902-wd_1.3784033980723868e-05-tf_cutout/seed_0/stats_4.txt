"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.98232960700989, "training_acc": 64.0, "val_loss": 14.974433183670044, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.339176654815674, "training_acc": 72.0, "val_loss": 15.010111033916473, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.54781675338745, "training_acc": 72.0, "val_loss": 15.01343846321106, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.03238606452942, "training_acc": 72.0, "val_loss": 14.828681945800781, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.95460855960846, "training_acc": 72.0, "val_loss": 14.601127803325653, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.01654505729675, "training_acc": 72.0, "val_loss": 14.483942091464996, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.86100196838379, "training_acc": 72.0, "val_loss": 14.426788687705994, "val_acc": 68.0}
{"epoch": 7, "training_loss": 56.66250014305115, "training_acc": 72.0, "val_loss": 14.38993364572525, "val_acc": 68.0}
{"epoch": 8, "training_loss": 56.04101204872131, "training_acc": 72.0, "val_loss": 14.409899711608887, "val_acc": 68.0}
{"epoch": 9, "training_loss": 55.45864915847778, "training_acc": 72.0, "val_loss": 14.515970647335052, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.929080963134766, "training_acc": 72.0, "val_loss": 14.569030702114105, "val_acc": 72.0}
{"epoch": 11, "training_loss": 54.95592927932739, "training_acc": 72.0, "val_loss": 14.572112262248993, "val_acc": 68.0}
{"epoch": 12, "training_loss": 54.98405063152313, "training_acc": 72.0, "val_loss": 14.47017788887024, "val_acc": 72.0}
{"epoch": 13, "training_loss": 54.44085478782654, "training_acc": 74.0, "val_loss": 14.404483139514923, "val_acc": 76.0}
{"epoch": 14, "training_loss": 53.200071573257446, "training_acc": 74.0, "val_loss": 14.391559362411499, "val_acc": 76.0}
{"epoch": 15, "training_loss": 56.114009618759155, "training_acc": 76.0, "val_loss": 14.423984289169312, "val_acc": 76.0}
{"epoch": 16, "training_loss": 54.81567311286926, "training_acc": 75.0, "val_loss": 14.493566751480103, "val_acc": 76.0}
{"epoch": 17, "training_loss": 54.753448724746704, "training_acc": 75.0, "val_loss": 14.566226303577423, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.7674343585968, "training_acc": 75.0, "val_loss": 14.664669334888458, "val_acc": 72.0}
{"epoch": 19, "training_loss": 54.19197988510132, "training_acc": 76.0, "val_loss": 14.713844656944275, "val_acc": 72.0}
{"epoch": 20, "training_loss": 54.30244970321655, "training_acc": 76.0, "val_loss": 14.639948308467865, "val_acc": 72.0}
{"epoch": 21, "training_loss": 53.08843684196472, "training_acc": 75.0, "val_loss": 14.530222117900848, "val_acc": 76.0}
{"epoch": 22, "training_loss": 52.62051594257355, "training_acc": 74.0, "val_loss": 14.460913836956024, "val_acc": 72.0}
{"epoch": 23, "training_loss": 54.96641445159912, "training_acc": 73.0, "val_loss": 14.522500336170197, "val_acc": 76.0}
{"epoch": 24, "training_loss": 55.21956729888916, "training_acc": 75.0, "val_loss": 14.63102102279663, "val_acc": 76.0}
{"epoch": 25, "training_loss": 53.74171161651611, "training_acc": 75.0, "val_loss": 14.717970788478851, "val_acc": 72.0}
{"epoch": 26, "training_loss": 53.33611452579498, "training_acc": 77.0, "val_loss": 14.619377255439758, "val_acc": 76.0}
