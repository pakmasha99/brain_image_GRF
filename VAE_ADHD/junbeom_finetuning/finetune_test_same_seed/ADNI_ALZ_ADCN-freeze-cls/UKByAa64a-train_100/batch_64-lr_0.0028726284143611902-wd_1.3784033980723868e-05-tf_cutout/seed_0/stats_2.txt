"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.01742196083069, "training_acc": 52.0, "val_loss": 15.067294239997864, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.931074380874634, "training_acc": 72.0, "val_loss": 15.161997079849243, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.810861110687256, "training_acc": 72.0, "val_loss": 15.201947093009949, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.612526655197144, "training_acc": 72.0, "val_loss": 14.909768104553223, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.84157466888428, "training_acc": 72.0, "val_loss": 14.552539587020874, "val_acc": 72.0}
{"epoch": 5, "training_loss": 57.80762505531311, "training_acc": 72.0, "val_loss": 14.354947209358215, "val_acc": 76.0}
{"epoch": 6, "training_loss": 57.02344608306885, "training_acc": 72.0, "val_loss": 14.314350485801697, "val_acc": 68.0}
{"epoch": 7, "training_loss": 57.223172426223755, "training_acc": 73.0, "val_loss": 14.213857054710388, "val_acc": 68.0}
{"epoch": 8, "training_loss": 56.38093972206116, "training_acc": 71.0, "val_loss": 14.117772877216339, "val_acc": 68.0}
{"epoch": 9, "training_loss": 56.07573699951172, "training_acc": 72.0, "val_loss": 14.095434546470642, "val_acc": 68.0}
{"epoch": 10, "training_loss": 56.237072706222534, "training_acc": 71.0, "val_loss": 14.130976796150208, "val_acc": 76.0}
{"epoch": 11, "training_loss": 55.38684391975403, "training_acc": 72.0, "val_loss": 14.132961630821228, "val_acc": 76.0}
{"epoch": 12, "training_loss": 55.227577447891235, "training_acc": 72.0, "val_loss": 14.153702557086945, "val_acc": 76.0}
{"epoch": 13, "training_loss": 53.622334480285645, "training_acc": 72.0, "val_loss": 14.115487039089203, "val_acc": 68.0}
{"epoch": 14, "training_loss": 54.773946046829224, "training_acc": 71.0, "val_loss": 14.065471291542053, "val_acc": 68.0}
{"epoch": 15, "training_loss": 53.53256440162659, "training_acc": 73.0, "val_loss": 14.060534536838531, "val_acc": 68.0}
{"epoch": 16, "training_loss": 54.562652587890625, "training_acc": 74.0, "val_loss": 14.07577246427536, "val_acc": 68.0}
{"epoch": 17, "training_loss": 54.06792759895325, "training_acc": 73.0, "val_loss": 14.092011749744415, "val_acc": 68.0}
{"epoch": 18, "training_loss": 54.55321526527405, "training_acc": 73.0, "val_loss": 14.08817321062088, "val_acc": 68.0}
{"epoch": 19, "training_loss": 53.973336935043335, "training_acc": 73.0, "val_loss": 14.030081033706665, "val_acc": 68.0}
{"epoch": 20, "training_loss": 53.64207577705383, "training_acc": 73.0, "val_loss": 14.006629586219788, "val_acc": 68.0}
{"epoch": 21, "training_loss": 54.45063400268555, "training_acc": 72.0, "val_loss": 13.995210826396942, "val_acc": 72.0}
{"epoch": 22, "training_loss": 54.22124171257019, "training_acc": 74.0, "val_loss": 14.06550258398056, "val_acc": 68.0}
{"epoch": 23, "training_loss": 54.13365912437439, "training_acc": 72.0, "val_loss": 14.1453817486763, "val_acc": 68.0}
{"epoch": 24, "training_loss": 53.23891091346741, "training_acc": 75.0, "val_loss": 14.222267270088196, "val_acc": 68.0}
{"epoch": 25, "training_loss": 55.50676083564758, "training_acc": 76.0, "val_loss": 14.2658531665802, "val_acc": 68.0}
{"epoch": 26, "training_loss": 53.93799185752869, "training_acc": 76.0, "val_loss": 14.246124029159546, "val_acc": 68.0}
{"epoch": 27, "training_loss": 52.994699478149414, "training_acc": 75.0, "val_loss": 14.106914401054382, "val_acc": 68.0}
{"epoch": 28, "training_loss": 52.80088567733765, "training_acc": 75.0, "val_loss": 14.087295532226562, "val_acc": 68.0}
{"epoch": 29, "training_loss": 51.83382487297058, "training_acc": 74.0, "val_loss": 14.039728045463562, "val_acc": 68.0}
{"epoch": 30, "training_loss": 53.803993463516235, "training_acc": 75.0, "val_loss": 14.059573411941528, "val_acc": 68.0}
{"epoch": 31, "training_loss": 53.65835881233215, "training_acc": 75.0, "val_loss": 14.054140448570251, "val_acc": 68.0}
{"epoch": 32, "training_loss": 53.36663246154785, "training_acc": 76.0, "val_loss": 14.03389573097229, "val_acc": 68.0}
{"epoch": 33, "training_loss": 52.98381757736206, "training_acc": 74.0, "val_loss": 14.031055569648743, "val_acc": 68.0}
{"epoch": 34, "training_loss": 51.73668336868286, "training_acc": 76.0, "val_loss": 14.058329164981842, "val_acc": 68.0}
{"epoch": 35, "training_loss": 52.05870878696442, "training_acc": 75.0, "val_loss": 14.115715026855469, "val_acc": 68.0}
{"epoch": 36, "training_loss": 52.829071283340454, "training_acc": 76.0, "val_loss": 14.232854545116425, "val_acc": 68.0}
{"epoch": 37, "training_loss": 50.90569281578064, "training_acc": 76.0, "val_loss": 14.33352679014206, "val_acc": 68.0}
{"epoch": 38, "training_loss": 52.05433714389801, "training_acc": 75.0, "val_loss": 14.30538147687912, "val_acc": 68.0}
{"epoch": 39, "training_loss": 52.3485848903656, "training_acc": 76.0, "val_loss": 14.237730205059052, "val_acc": 68.0}
{"epoch": 40, "training_loss": 51.953728675842285, "training_acc": 76.0, "val_loss": 14.11808431148529, "val_acc": 68.0}
