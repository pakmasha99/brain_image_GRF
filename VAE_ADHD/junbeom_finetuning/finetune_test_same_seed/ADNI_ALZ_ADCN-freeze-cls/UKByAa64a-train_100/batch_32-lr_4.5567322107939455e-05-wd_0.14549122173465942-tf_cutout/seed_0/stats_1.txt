"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.72069311141968, "training_acc": 72.0, "val_loss": 16.907303035259247, "val_acc": 28.0}
{"epoch": 1, "training_loss": 67.33757758140564, "training_acc": 72.0, "val_loss": 16.81056320667267, "val_acc": 28.0}
{"epoch": 2, "training_loss": 66.99400424957275, "training_acc": 72.0, "val_loss": 16.72648787498474, "val_acc": 28.0}
{"epoch": 3, "training_loss": 66.68665409088135, "training_acc": 72.0, "val_loss": 16.66271537542343, "val_acc": 28.0}
{"epoch": 4, "training_loss": 66.4976224899292, "training_acc": 72.0, "val_loss": 16.59180223941803, "val_acc": 28.0}
{"epoch": 5, "training_loss": 66.29095840454102, "training_acc": 72.0, "val_loss": 16.515138745307922, "val_acc": 28.0}
{"epoch": 6, "training_loss": 65.9232964515686, "training_acc": 72.0, "val_loss": 16.44049733877182, "val_acc": 28.0}
{"epoch": 7, "training_loss": 65.50221943855286, "training_acc": 72.0, "val_loss": 16.36783331632614, "val_acc": 28.0}
{"epoch": 8, "training_loss": 65.1678819656372, "training_acc": 72.0, "val_loss": 16.295558214187622, "val_acc": 28.0}
{"epoch": 9, "training_loss": 64.96003293991089, "training_acc": 72.0, "val_loss": 16.225245594978333, "val_acc": 28.0}
{"epoch": 10, "training_loss": 64.7792706489563, "training_acc": 72.0, "val_loss": 16.162440180778503, "val_acc": 28.0}
{"epoch": 11, "training_loss": 64.37548923492432, "training_acc": 72.0, "val_loss": 16.103671491146088, "val_acc": 28.0}
{"epoch": 12, "training_loss": 64.20329523086548, "training_acc": 72.0, "val_loss": 16.04965031147003, "val_acc": 28.0}
{"epoch": 13, "training_loss": 63.847394943237305, "training_acc": 72.0, "val_loss": 15.997539460659027, "val_acc": 32.0}
{"epoch": 14, "training_loss": 63.56263995170593, "training_acc": 72.0, "val_loss": 15.944699943065643, "val_acc": 28.0}
{"epoch": 15, "training_loss": 63.595773696899414, "training_acc": 72.0, "val_loss": 15.893733501434326, "val_acc": 24.0}
{"epoch": 16, "training_loss": 63.1295747756958, "training_acc": 72.0, "val_loss": 15.842589735984802, "val_acc": 24.0}
{"epoch": 17, "training_loss": 63.15835738182068, "training_acc": 72.0, "val_loss": 15.797440707683563, "val_acc": 24.0}
{"epoch": 18, "training_loss": 62.90214705467224, "training_acc": 72.0, "val_loss": 15.760606527328491, "val_acc": 28.0}
{"epoch": 19, "training_loss": 62.30998182296753, "training_acc": 72.0, "val_loss": 15.727539360523224, "val_acc": 24.0}
{"epoch": 20, "training_loss": 62.66333532333374, "training_acc": 72.0, "val_loss": 15.696896612644196, "val_acc": 24.0}
{"epoch": 21, "training_loss": 62.187361001968384, "training_acc": 72.0, "val_loss": 15.67300260066986, "val_acc": 24.0}
{"epoch": 22, "training_loss": 62.22366285324097, "training_acc": 72.0, "val_loss": 15.656992793083191, "val_acc": 24.0}
{"epoch": 23, "training_loss": 62.16166663169861, "training_acc": 72.0, "val_loss": 15.641030669212341, "val_acc": 24.0}
{"epoch": 24, "training_loss": 62.19563388824463, "training_acc": 72.0, "val_loss": 15.624813735485077, "val_acc": 24.0}
{"epoch": 25, "training_loss": 62.07889723777771, "training_acc": 72.0, "val_loss": 15.606848895549774, "val_acc": 36.0}
{"epoch": 26, "training_loss": 61.9404501914978, "training_acc": 72.0, "val_loss": 15.585878491401672, "val_acc": 44.0}
{"epoch": 27, "training_loss": 62.044026136398315, "training_acc": 72.0, "val_loss": 15.564444661140442, "val_acc": 56.0}
{"epoch": 28, "training_loss": 61.93649697303772, "training_acc": 72.0, "val_loss": 15.539725124835968, "val_acc": 52.0}
{"epoch": 29, "training_loss": 61.60104990005493, "training_acc": 72.0, "val_loss": 15.516786277294159, "val_acc": 56.0}
{"epoch": 30, "training_loss": 61.77079129219055, "training_acc": 72.0, "val_loss": 15.498313307762146, "val_acc": 52.0}
{"epoch": 31, "training_loss": 61.596373558044434, "training_acc": 72.0, "val_loss": 15.481042861938477, "val_acc": 52.0}
{"epoch": 32, "training_loss": 61.639607429504395, "training_acc": 72.0, "val_loss": 15.466304123401642, "val_acc": 60.0}
{"epoch": 33, "training_loss": 61.33364272117615, "training_acc": 72.0, "val_loss": 15.4561847448349, "val_acc": 68.0}
{"epoch": 34, "training_loss": 61.232013463974, "training_acc": 72.0, "val_loss": 15.44618010520935, "val_acc": 72.0}
{"epoch": 35, "training_loss": 61.4745831489563, "training_acc": 72.0, "val_loss": 15.43685644865036, "val_acc": 72.0}
