"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10351.48811340332, "training_acc": 42.0, "val_loss": 264.5183324813843, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10496.8505859375, "training_acc": 60.0, "val_loss": 1164.0862464904785, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3745.9940795898438, "training_acc": 72.0, "val_loss": 1709.2353820800781, "val_acc": 28.0}
{"epoch": 3, "training_loss": 6439.881317138672, "training_acc": 44.0, "val_loss": 888.4231567382812, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2191.4326276779175, "training_acc": 58.0, "val_loss": 1013.1714820861816, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3411.3540115356445, "training_acc": 72.0, "val_loss": 690.7110214233398, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3433.4944458007812, "training_acc": 44.0, "val_loss": 756.9900512695312, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2442.852087020874, "training_acc": 50.0, "val_loss": 1280.772304534912, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4576.19596862793, "training_acc": 72.0, "val_loss": 251.34096145629883, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2722.567581176758, "training_acc": 50.0, "val_loss": 790.2846336364746, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2732.7890625, "training_acc": 72.0, "val_loss": 144.40096616744995, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1776.2357635498047, "training_acc": 44.0, "val_loss": 662.2098922729492, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1895.5774192810059, "training_acc": 72.0, "val_loss": 1107.5243949890137, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3046.2912673950195, "training_acc": 52.0, "val_loss": 417.3830509185791, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1054.3158540725708, "training_acc": 60.0, "val_loss": 897.2185134887695, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3095.4802169799805, "training_acc": 72.0, "val_loss": 20.65383344888687, "val_acc": 28.0}
{"epoch": 16, "training_loss": 892.9517440795898, "training_acc": 40.0, "val_loss": 22.79854267835617, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2196.2708740234375, "training_acc": 50.0, "val_loss": 659.5457553863525, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2279.9471130371094, "training_acc": 72.0, "val_loss": 388.2361650466919, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1682.5788497924805, "training_acc": 50.0, "val_loss": 572.8293895721436, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1610.0503840446472, "training_acc": 72.0, "val_loss": 1111.7088317871094, "val_acc": 28.0}
{"epoch": 21, "training_loss": 4255.795883178711, "training_acc": 38.0, "val_loss": 272.383713722229, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1593.7404022216797, "training_acc": 56.0, "val_loss": 752.7474403381348, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2600.6571044921875, "training_acc": 72.0, "val_loss": 65.30975103378296, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1465.922592163086, "training_acc": 44.0, "val_loss": 603.7337303161621, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1630.5100803375244, "training_acc": 72.0, "val_loss": 1146.3757514953613, "val_acc": 28.0}
{"epoch": 26, "training_loss": 3540.571075439453, "training_acc": 46.0, "val_loss": 294.7880268096924, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1451.202049255371, "training_acc": 56.0, "val_loss": 800.4472732543945, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2787.9542236328125, "training_acc": 72.0, "val_loss": 19.502395391464233, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1456.2247428894043, "training_acc": 56.0, "val_loss": 643.7358856201172, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2222.8999519348145, "training_acc": 72.0, "val_loss": 197.09728956222534, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2547.9785919189453, "training_acc": 36.0, "val_loss": 551.5766620635986, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1696.7427244186401, "training_acc": 52.0, "val_loss": 973.5320091247559, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3492.4925689697266, "training_acc": 72.0, "val_loss": 193.1538701057434, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1354.6238174438477, "training_acc": 60.0, "val_loss": 641.5449619293213, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2142.09761428833, "training_acc": 72.0, "val_loss": 359.91203784942627, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1933.2458267211914, "training_acc": 46.0, "val_loss": 549.92356300354, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1377.7807712554932, "training_acc": 72.0, "val_loss": 1322.0947265625, "val_acc": 28.0}
{"epoch": 38, "training_loss": 4202.612899780273, "training_acc": 42.0, "val_loss": 177.0812749862671, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1016.5481719970703, "training_acc": 64.0, "val_loss": 625.42724609375, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2048.943832397461, "training_acc": 72.0, "val_loss": 512.8915786743164, "val_acc": 28.0}
{"epoch": 41, "training_loss": 2564.427444458008, "training_acc": 42.0, "val_loss": 454.3403148651123, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1518.4922561645508, "training_acc": 54.0, "val_loss": 921.6064453125, "val_acc": 72.0}
{"epoch": 43, "training_loss": 3288.8604431152344, "training_acc": 72.0, "val_loss": 146.55396938323975, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1688.8266143798828, "training_acc": 56.0, "val_loss": 630.7488918304443, "val_acc": 72.0}
{"epoch": 45, "training_loss": 2117.34423828125, "training_acc": 72.0, "val_loss": 373.76201152801514, "val_acc": 28.0}
{"epoch": 46, "training_loss": 1788.9533996582031, "training_acc": 48.0, "val_loss": 552.2162914276123, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1439.2214679718018, "training_acc": 72.0, "val_loss": 1210.5539321899414, "val_acc": 28.0}
