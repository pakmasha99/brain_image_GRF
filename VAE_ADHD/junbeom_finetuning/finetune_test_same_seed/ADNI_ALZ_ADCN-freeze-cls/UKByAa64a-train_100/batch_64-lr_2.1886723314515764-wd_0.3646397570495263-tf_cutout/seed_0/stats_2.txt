"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8468.625820159912, "training_acc": 46.0, "val_loss": 443.0438041687012, "val_acc": 72.0}
{"epoch": 1, "training_loss": 12836.462280273438, "training_acc": 56.0, "val_loss": 1269.9809074401855, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4193.7327880859375, "training_acc": 72.0, "val_loss": 1370.3753471374512, "val_acc": 28.0}
{"epoch": 3, "training_loss": 5954.958038330078, "training_acc": 42.0, "val_loss": 870.9212303161621, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2724.5553131103516, "training_acc": 54.0, "val_loss": 1403.463077545166, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4943.61946105957, "training_acc": 72.0, "val_loss": 187.43529319763184, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3183.356689453125, "training_acc": 50.0, "val_loss": 797.8670597076416, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2734.437110900879, "training_acc": 72.0, "val_loss": 344.3487882614136, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1908.1994171142578, "training_acc": 48.0, "val_loss": 676.8579959869385, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1880.8396949768066, "training_acc": 72.0, "val_loss": 1235.385513305664, "val_acc": 28.0}
{"epoch": 10, "training_loss": 3686.544876098633, "training_acc": 48.0, "val_loss": 370.1146125793457, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1689.7637634277344, "training_acc": 54.0, "val_loss": 907.9647064208984, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3244.1772994995117, "training_acc": 72.0, "val_loss": 111.69735193252563, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2347.9850006103516, "training_acc": 50.0, "val_loss": 669.2174911499023, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2297.9105377197266, "training_acc": 72.0, "val_loss": 239.07134532928467, "val_acc": 28.0}
{"epoch": 15, "training_loss": 2228.9949798583984, "training_acc": 40.0, "val_loss": 551.7844676971436, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1517.5368418693542, "training_acc": 73.0, "val_loss": 180.39764165878296, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1590.421241760254, "training_acc": 52.0, "val_loss": 808.6294174194336, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2846.202491760254, "training_acc": 72.0, "val_loss": 47.738462686538696, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1972.9060897827148, "training_acc": 54.0, "val_loss": 560.2859973907471, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1865.662010192871, "training_acc": 72.0, "val_loss": 538.1884574890137, "val_acc": 28.0}
{"epoch": 21, "training_loss": 2442.1416244506836, "training_acc": 44.0, "val_loss": 460.7126235961914, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1315.5465059280396, "training_acc": 56.0, "val_loss": 904.2560577392578, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3181.4438552856445, "training_acc": 72.0, "val_loss": 99.31349158287048, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1474.3137969970703, "training_acc": 60.0, "val_loss": 544.2243576049805, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1766.5960845947266, "training_acc": 72.0, "val_loss": 628.6689758300781, "val_acc": 28.0}
{"epoch": 26, "training_loss": 2790.013832092285, "training_acc": 42.0, "val_loss": 413.2168769836426, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2037.565284729004, "training_acc": 48.0, "val_loss": 918.0442810058594, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3331.099624633789, "training_acc": 72.0, "val_loss": 75.08787512779236, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1893.0877380371094, "training_acc": 56.0, "val_loss": 509.088134765625, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1657.4224700927734, "training_acc": 72.0, "val_loss": 557.1059226989746, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2156.36808013916, "training_acc": 48.0, "val_loss": 490.0669574737549, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1215.245111465454, "training_acc": 72.0, "val_loss": 1295.8284378051758, "val_acc": 28.0}
{"epoch": 33, "training_loss": 4696.606353759766, "training_acc": 36.0, "val_loss": 142.69869327545166, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1490.7671432495117, "training_acc": 58.0, "val_loss": 604.6520233154297, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2025.190933227539, "training_acc": 72.0, "val_loss": 484.0280055999756, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2458.6946411132812, "training_acc": 42.0, "val_loss": 440.6649589538574, "val_acc": 72.0}
{"epoch": 37, "training_loss": 952.9693613052368, "training_acc": 72.0, "val_loss": 1504.0982246398926, "val_acc": 28.0}
