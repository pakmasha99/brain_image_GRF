"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 222.99781227111816, "training_acc": 61.0, "val_loss": 169.04942989349365, "val_acc": 72.0}
{"epoch": 1, "training_loss": 512.9499940872192, "training_acc": 72.0, "val_loss": 181.15160465240479, "val_acc": 28.0}
{"epoch": 2, "training_loss": 768.8325347900391, "training_acc": 28.0, "val_loss": 27.01757848262787, "val_acc": 72.0}
{"epoch": 3, "training_loss": 172.90014457702637, "training_acc": 73.0, "val_loss": 122.90165424346924, "val_acc": 72.0}
{"epoch": 4, "training_loss": 457.1267795562744, "training_acc": 72.0, "val_loss": 109.27680730819702, "val_acc": 72.0}
{"epoch": 5, "training_loss": 326.9419274330139, "training_acc": 73.0, "val_loss": 37.45071589946747, "val_acc": 64.0}
{"epoch": 6, "training_loss": 233.45731925964355, "training_acc": 61.0, "val_loss": 53.97920608520508, "val_acc": 52.0}
{"epoch": 7, "training_loss": 243.2067551612854, "training_acc": 55.0, "val_loss": 52.48550772666931, "val_acc": 72.0}
{"epoch": 8, "training_loss": 165.78322649002075, "training_acc": 71.0, "val_loss": 86.11962795257568, "val_acc": 72.0}
{"epoch": 9, "training_loss": 249.85572862625122, "training_acc": 72.0, "val_loss": 46.88467979431152, "val_acc": 72.0}
{"epoch": 10, "training_loss": 110.81175136566162, "training_acc": 75.0, "val_loss": 35.85152626037598, "val_acc": 60.0}
{"epoch": 11, "training_loss": 158.62144088745117, "training_acc": 63.0, "val_loss": 26.030898094177246, "val_acc": 64.0}
{"epoch": 12, "training_loss": 80.38052535057068, "training_acc": 74.0, "val_loss": 38.08368146419525, "val_acc": 72.0}
{"epoch": 13, "training_loss": 113.14262008666992, "training_acc": 72.0, "val_loss": 15.695405006408691, "val_acc": 68.0}
{"epoch": 14, "training_loss": 55.4526252746582, "training_acc": 69.0, "val_loss": 13.118229806423187, "val_acc": 68.0}
{"epoch": 15, "training_loss": 67.07028245925903, "training_acc": 70.0, "val_loss": 14.142875373363495, "val_acc": 72.0}
{"epoch": 16, "training_loss": 70.6629707813263, "training_acc": 65.0, "val_loss": 14.319616556167603, "val_acc": 48.0}
{"epoch": 17, "training_loss": 56.9679913520813, "training_acc": 69.0, "val_loss": 13.906601071357727, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.07878494262695, "training_acc": 68.0, "val_loss": 14.875881373882294, "val_acc": 48.0}
{"epoch": 19, "training_loss": 56.60337233543396, "training_acc": 66.0, "val_loss": 15.514956414699554, "val_acc": 76.0}
{"epoch": 20, "training_loss": 56.17607581615448, "training_acc": 74.0, "val_loss": 12.9927396774292, "val_acc": 76.0}
{"epoch": 21, "training_loss": 48.18660509586334, "training_acc": 77.0, "val_loss": 14.413288235664368, "val_acc": 76.0}
{"epoch": 22, "training_loss": 46.008148312568665, "training_acc": 80.0, "val_loss": 12.618084251880646, "val_acc": 76.0}
{"epoch": 23, "training_loss": 41.14910089969635, "training_acc": 82.0, "val_loss": 12.004417926073074, "val_acc": 84.0}
{"epoch": 24, "training_loss": 49.45082175731659, "training_acc": 79.0, "val_loss": 13.175265491008759, "val_acc": 80.0}
{"epoch": 25, "training_loss": 44.83278048038483, "training_acc": 76.0, "val_loss": 12.867888808250427, "val_acc": 52.0}
{"epoch": 26, "training_loss": 45.26190948486328, "training_acc": 76.0, "val_loss": 12.07950934767723, "val_acc": 76.0}
{"epoch": 27, "training_loss": 53.809653520584106, "training_acc": 75.0, "val_loss": 21.44562155008316, "val_acc": 40.0}
{"epoch": 28, "training_loss": 70.27918064594269, "training_acc": 54.0, "val_loss": 21.357853710651398, "val_acc": 72.0}
{"epoch": 29, "training_loss": 77.119069814682, "training_acc": 72.0, "val_loss": 12.245595455169678, "val_acc": 76.0}
{"epoch": 30, "training_loss": 63.547921657562256, "training_acc": 72.0, "val_loss": 12.804244458675385, "val_acc": 76.0}
{"epoch": 31, "training_loss": 46.82712197303772, "training_acc": 81.0, "val_loss": 18.81781369447708, "val_acc": 76.0}
{"epoch": 32, "training_loss": 61.692307233810425, "training_acc": 68.0, "val_loss": 12.081341445446014, "val_acc": 80.0}
{"epoch": 33, "training_loss": 45.247172474861145, "training_acc": 81.0, "val_loss": 14.996106922626495, "val_acc": 76.0}
{"epoch": 34, "training_loss": 40.7303820848465, "training_acc": 81.0, "val_loss": 16.40121638774872, "val_acc": 44.0}
{"epoch": 35, "training_loss": 64.82754802703857, "training_acc": 62.0, "val_loss": 14.413227140903473, "val_acc": 72.0}
{"epoch": 36, "training_loss": 37.12871479988098, "training_acc": 78.0, "val_loss": 20.34153640270233, "val_acc": 36.0}
{"epoch": 37, "training_loss": 61.819321155548096, "training_acc": 65.0, "val_loss": 18.83602887392044, "val_acc": 72.0}
{"epoch": 38, "training_loss": 64.09218883514404, "training_acc": 73.0, "val_loss": 15.283988416194916, "val_acc": 52.0}
{"epoch": 39, "training_loss": 68.02945804595947, "training_acc": 61.0, "val_loss": 19.73864883184433, "val_acc": 76.0}
{"epoch": 40, "training_loss": 75.65715789794922, "training_acc": 75.0, "val_loss": 19.168205559253693, "val_acc": 76.0}
{"epoch": 41, "training_loss": 40.63907861709595, "training_acc": 81.0, "val_loss": 25.388118624687195, "val_acc": 36.0}
{"epoch": 42, "training_loss": 86.02845752239227, "training_acc": 64.0, "val_loss": 31.537845730781555, "val_acc": 72.0}
