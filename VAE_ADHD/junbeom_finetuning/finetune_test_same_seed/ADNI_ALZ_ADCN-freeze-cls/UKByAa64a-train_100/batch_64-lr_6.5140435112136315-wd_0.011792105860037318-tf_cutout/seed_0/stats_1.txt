"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10243.550827026367, "training_acc": 72.0, "val_loss": 4610.315704345703, "val_acc": 72.0}
{"epoch": 1, "training_loss": 11775.370094299316, "training_acc": 72.0, "val_loss": 9148.416137695312, "val_acc": 28.0}
{"epoch": 2, "training_loss": 33165.589111328125, "training_acc": 28.0, "val_loss": 917.3584938049316, "val_acc": 60.0}
{"epoch": 3, "training_loss": 4572.527160644531, "training_acc": 64.0, "val_loss": 4238.273239135742, "val_acc": 72.0}
{"epoch": 4, "training_loss": 16348.958679199219, "training_acc": 72.0, "val_loss": 4365.879821777344, "val_acc": 72.0}
{"epoch": 5, "training_loss": 15431.153564453125, "training_acc": 72.0, "val_loss": 1638.0744934082031, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4044.8422241210938, "training_acc": 76.0, "val_loss": 2407.3339462280273, "val_acc": 44.0}
{"epoch": 7, "training_loss": 9424.250183105469, "training_acc": 40.0, "val_loss": 603.8283348083496, "val_acc": 68.0}
{"epoch": 8, "training_loss": 3875.451416015625, "training_acc": 70.0, "val_loss": 1871.9707489013672, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6953.488433837891, "training_acc": 72.0, "val_loss": 862.1455192565918, "val_acc": 76.0}
{"epoch": 10, "training_loss": 3242.225456237793, "training_acc": 66.0, "val_loss": 1215.2153015136719, "val_acc": 56.0}
{"epoch": 11, "training_loss": 3876.4021492004395, "training_acc": 56.0, "val_loss": 727.5144100189209, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3267.834571838379, "training_acc": 72.0, "val_loss": 672.7292537689209, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1950.8084297180176, "training_acc": 73.0, "val_loss": 923.2570648193359, "val_acc": 36.0}
{"epoch": 14, "training_loss": 2804.7328338623047, "training_acc": 44.0, "val_loss": 429.4982433319092, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1345.80318069458, "training_acc": 73.0, "val_loss": 567.0228004455566, "val_acc": 36.0}
{"epoch": 16, "training_loss": 1621.4093589782715, "training_acc": 50.0, "val_loss": 411.62285804748535, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1224.1238994598389, "training_acc": 70.0, "val_loss": 307.2469711303711, "val_acc": 52.0}
{"epoch": 18, "training_loss": 937.4349021911621, "training_acc": 68.0, "val_loss": 630.7707786560059, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1837.3460235595703, "training_acc": 72.0, "val_loss": 916.7342185974121, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2283.609070777893, "training_acc": 48.0, "val_loss": 664.4924163818359, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2264.498466491699, "training_acc": 72.0, "val_loss": 122.994863986969, "val_acc": 60.0}
{"epoch": 22, "training_loss": 623.9376850128174, "training_acc": 62.0, "val_loss": 407.159423828125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1202.3416748046875, "training_acc": 72.0, "val_loss": 504.830265045166, "val_acc": 36.0}
{"epoch": 24, "training_loss": 1883.1103477478027, "training_acc": 48.0, "val_loss": 435.75282096862793, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1870.0811767578125, "training_acc": 53.0, "val_loss": 338.6117696762085, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1288.6536254882812, "training_acc": 73.0, "val_loss": 192.80306100845337, "val_acc": 56.0}
{"epoch": 27, "training_loss": 868.7253875732422, "training_acc": 67.0, "val_loss": 299.6721029281616, "val_acc": 76.0}
{"epoch": 28, "training_loss": 1122.9031620025635, "training_acc": 70.0, "val_loss": 211.9980812072754, "val_acc": 52.0}
{"epoch": 29, "training_loss": 566.890061378479, "training_acc": 68.0, "val_loss": 62.59395480155945, "val_acc": 72.0}
{"epoch": 30, "training_loss": 959.9715423583984, "training_acc": 57.0, "val_loss": 726.828145980835, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2838.1616821289062, "training_acc": 72.0, "val_loss": 662.550163269043, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1517.063268661499, "training_acc": 66.0, "val_loss": 135.97205877304077, "val_acc": 76.0}
{"epoch": 33, "training_loss": 356.514591217041, "training_acc": 70.0, "val_loss": 263.3942127227783, "val_acc": 72.0}
{"epoch": 34, "training_loss": 554.3497262001038, "training_acc": 75.0, "val_loss": 108.81823301315308, "val_acc": 56.0}
{"epoch": 35, "training_loss": 535.0630073547363, "training_acc": 68.0, "val_loss": 236.90791130065918, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1820.0260772705078, "training_acc": 56.0, "val_loss": 414.93983268737793, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1558.9540634155273, "training_acc": 72.0, "val_loss": 121.47104740142822, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2822.363265991211, "training_acc": 54.0, "val_loss": 297.65849113464355, "val_acc": 40.0}
{"epoch": 39, "training_loss": 2209.2171478271484, "training_acc": 55.0, "val_loss": 2092.646026611328, "val_acc": 72.0}
{"epoch": 40, "training_loss": 8087.9197998046875, "training_acc": 72.0, "val_loss": 1642.7955627441406, "val_acc": 72.0}
{"epoch": 41, "training_loss": 4866.155403137207, "training_acc": 72.0, "val_loss": 1182.2184562683105, "val_acc": 48.0}
{"epoch": 42, "training_loss": 4857.970779418945, "training_acc": 43.0, "val_loss": 350.1133918762207, "val_acc": 64.0}
{"epoch": 43, "training_loss": 1834.0358123779297, "training_acc": 76.0, "val_loss": 1151.6732215881348, "val_acc": 72.0}
{"epoch": 44, "training_loss": 4136.764060974121, "training_acc": 72.0, "val_loss": 391.304612159729, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1959.0861892700195, "training_acc": 68.0, "val_loss": 732.3604106903076, "val_acc": 60.0}
{"epoch": 46, "training_loss": 2597.956657409668, "training_acc": 59.0, "val_loss": 638.814640045166, "val_acc": 72.0}
{"epoch": 47, "training_loss": 2320.3731231689453, "training_acc": 72.0, "val_loss": 273.89471530914307, "val_acc": 52.0}
{"epoch": 48, "training_loss": 1324.4513092041016, "training_acc": 53.0, "val_loss": 968.9019203186035, "val_acc": 72.0}
