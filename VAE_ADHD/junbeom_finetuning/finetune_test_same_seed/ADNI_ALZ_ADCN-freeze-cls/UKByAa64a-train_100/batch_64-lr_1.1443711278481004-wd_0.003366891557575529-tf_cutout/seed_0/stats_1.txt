"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1845.8495635986328, "training_acc": 72.0, "val_loss": 814.0596389770508, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2375.296899318695, "training_acc": 72.0, "val_loss": 1337.3879432678223, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4725.135879516602, "training_acc": 29.0, "val_loss": 88.64840269088745, "val_acc": 76.0}
{"epoch": 3, "training_loss": 949.6415786743164, "training_acc": 72.0, "val_loss": 761.31591796875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2843.5143432617188, "training_acc": 72.0, "val_loss": 711.2510681152344, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2426.108108520508, "training_acc": 72.0, "val_loss": 239.79239463806152, "val_acc": 72.0}
{"epoch": 6, "training_loss": 988.9065284729004, "training_acc": 59.0, "val_loss": 497.9461669921875, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1952.0826034545898, "training_acc": 41.0, "val_loss": 115.07384777069092, "val_acc": 56.0}
{"epoch": 8, "training_loss": 609.0525932312012, "training_acc": 76.0, "val_loss": 452.22434997558594, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1641.3072891235352, "training_acc": 72.0, "val_loss": 421.04954719543457, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1352.1171646118164, "training_acc": 72.0, "val_loss": 113.43430280685425, "val_acc": 60.0}
{"epoch": 11, "training_loss": 669.2834739685059, "training_acc": 61.0, "val_loss": 320.2251434326172, "val_acc": 56.0}
{"epoch": 12, "training_loss": 1121.3986587524414, "training_acc": 49.0, "val_loss": 136.29260063171387, "val_acc": 76.0}
{"epoch": 13, "training_loss": 673.8696174621582, "training_acc": 73.0, "val_loss": 296.01714611053467, "val_acc": 72.0}
{"epoch": 14, "training_loss": 980.5120620727539, "training_acc": 72.0, "val_loss": 88.70255947113037, "val_acc": 76.0}
{"epoch": 15, "training_loss": 486.86167335510254, "training_acc": 71.0, "val_loss": 197.08809852600098, "val_acc": 56.0}
{"epoch": 16, "training_loss": 696.4818754196167, "training_acc": 52.0, "val_loss": 154.56613302230835, "val_acc": 72.0}
{"epoch": 17, "training_loss": 613.706901550293, "training_acc": 72.0, "val_loss": 189.21446800231934, "val_acc": 72.0}
{"epoch": 18, "training_loss": 495.91185235977173, "training_acc": 76.0, "val_loss": 184.8763346672058, "val_acc": 40.0}
{"epoch": 19, "training_loss": 506.66886711120605, "training_acc": 49.0, "val_loss": 101.65208578109741, "val_acc": 72.0}
{"epoch": 20, "training_loss": 359.70882987976074, "training_acc": 72.0, "val_loss": 64.99234437942505, "val_acc": 72.0}
{"epoch": 21, "training_loss": 346.7772216796875, "training_acc": 58.0, "val_loss": 50.593024492263794, "val_acc": 56.0}
{"epoch": 22, "training_loss": 203.12201404571533, "training_acc": 71.0, "val_loss": 188.83209228515625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 595.0687417984009, "training_acc": 72.0, "val_loss": 38.68646025657654, "val_acc": 72.0}
{"epoch": 24, "training_loss": 265.8148937225342, "training_acc": 66.0, "val_loss": 54.533541202545166, "val_acc": 60.0}
{"epoch": 25, "training_loss": 229.60795783996582, "training_acc": 69.0, "val_loss": 101.45041942596436, "val_acc": 72.0}
{"epoch": 26, "training_loss": 249.37900161743164, "training_acc": 77.0, "val_loss": 77.35002636909485, "val_acc": 60.0}
{"epoch": 27, "training_loss": 289.8935852050781, "training_acc": 63.0, "val_loss": 89.97282385826111, "val_acc": 72.0}
{"epoch": 28, "training_loss": 308.34602546691895, "training_acc": 72.0, "val_loss": 49.30548071861267, "val_acc": 76.0}
{"epoch": 29, "training_loss": 137.41708278656006, "training_acc": 77.0, "val_loss": 62.81762719154358, "val_acc": 52.0}
{"epoch": 30, "training_loss": 171.9452953338623, "training_acc": 70.0, "val_loss": 181.70782327651978, "val_acc": 72.0}
{"epoch": 31, "training_loss": 519.6843204498291, "training_acc": 72.0, "val_loss": 43.88574957847595, "val_acc": 52.0}
{"epoch": 32, "training_loss": 187.0328483581543, "training_acc": 64.0, "val_loss": 62.04264760017395, "val_acc": 76.0}
{"epoch": 33, "training_loss": 186.55033493041992, "training_acc": 74.0, "val_loss": 39.05195891857147, "val_acc": 68.0}
{"epoch": 34, "training_loss": 178.15324783325195, "training_acc": 68.0, "val_loss": 45.62618136405945, "val_acc": 72.0}
{"epoch": 35, "training_loss": 113.86636209487915, "training_acc": 80.0, "val_loss": 61.11119985580444, "val_acc": 80.0}
{"epoch": 36, "training_loss": 162.54603624343872, "training_acc": 75.0, "val_loss": 76.55732035636902, "val_acc": 56.0}
{"epoch": 37, "training_loss": 186.79565286636353, "training_acc": 72.0, "val_loss": 103.33303213119507, "val_acc": 76.0}
{"epoch": 38, "training_loss": 231.8086178302765, "training_acc": 76.0, "val_loss": 65.28489589691162, "val_acc": 60.0}
{"epoch": 39, "training_loss": 123.59570288658142, "training_acc": 75.0, "val_loss": 69.0522313117981, "val_acc": 76.0}
{"epoch": 40, "training_loss": 109.78903937339783, "training_acc": 80.0, "val_loss": 95.06823420524597, "val_acc": 40.0}
{"epoch": 41, "training_loss": 189.95298099517822, "training_acc": 66.0, "val_loss": 75.89644193649292, "val_acc": 72.0}
{"epoch": 42, "training_loss": 101.34759521484375, "training_acc": 81.0, "val_loss": 84.70616936683655, "val_acc": 44.0}
