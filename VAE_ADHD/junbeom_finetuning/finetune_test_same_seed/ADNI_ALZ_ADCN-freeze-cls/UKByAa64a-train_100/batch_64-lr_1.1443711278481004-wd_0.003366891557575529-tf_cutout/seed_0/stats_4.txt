"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1613.8965911865234, "training_acc": 50.0, "val_loss": 906.3887596130371, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2863.8914909362793, "training_acc": 72.0, "val_loss": 766.4924144744873, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3325.3704528808594, "training_acc": 28.0, "val_loss": 187.61743307113647, "val_acc": 76.0}
{"epoch": 3, "training_loss": 1114.5393371582031, "training_acc": 69.0, "val_loss": 661.7392539978027, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2233.255958557129, "training_acc": 72.0, "val_loss": 534.764289855957, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1404.8155937194824, "training_acc": 70.0, "val_loss": 234.3181610107422, "val_acc": 64.0}
{"epoch": 6, "training_loss": 1182.850040435791, "training_acc": 65.0, "val_loss": 259.0327024459839, "val_acc": 64.0}
{"epoch": 7, "training_loss": 1318.0207443237305, "training_acc": 57.0, "val_loss": 291.2302494049072, "val_acc": 72.0}
{"epoch": 8, "training_loss": 948.2292022705078, "training_acc": 70.0, "val_loss": 443.44639778137207, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1201.585943222046, "training_acc": 74.0, "val_loss": 192.51840114593506, "val_acc": 76.0}
{"epoch": 10, "training_loss": 516.5646686553955, "training_acc": 69.0, "val_loss": 154.53640222549438, "val_acc": 56.0}
{"epoch": 11, "training_loss": 619.3449592590332, "training_acc": 57.0, "val_loss": 166.32262468338013, "val_acc": 72.0}
{"epoch": 12, "training_loss": 522.904634475708, "training_acc": 72.0, "val_loss": 85.04500389099121, "val_acc": 72.0}
{"epoch": 13, "training_loss": 434.82290267944336, "training_acc": 62.0, "val_loss": 105.75578212738037, "val_acc": 36.0}
{"epoch": 14, "training_loss": 446.4513282775879, "training_acc": 59.0, "val_loss": 209.40778255462646, "val_acc": 72.0}
{"epoch": 15, "training_loss": 853.9715728759766, "training_acc": 72.0, "val_loss": 59.73988175392151, "val_acc": 72.0}
{"epoch": 16, "training_loss": 551.645923614502, "training_acc": 58.0, "val_loss": 186.2459421157837, "val_acc": 36.0}
{"epoch": 17, "training_loss": 665.5250301361084, "training_acc": 47.0, "val_loss": 208.17620754241943, "val_acc": 72.0}
{"epoch": 18, "training_loss": 751.2141094207764, "training_acc": 72.0, "val_loss": 109.06811952590942, "val_acc": 72.0}
{"epoch": 19, "training_loss": 327.5107307434082, "training_acc": 67.0, "val_loss": 121.38806581497192, "val_acc": 64.0}
{"epoch": 20, "training_loss": 521.9508304595947, "training_acc": 62.0, "val_loss": 137.08784580230713, "val_acc": 72.0}
{"epoch": 21, "training_loss": 415.1660623550415, "training_acc": 75.0, "val_loss": 130.82985877990723, "val_acc": 72.0}
{"epoch": 22, "training_loss": 345.86650562286377, "training_acc": 77.0, "val_loss": 75.56936740875244, "val_acc": 64.0}
{"epoch": 23, "training_loss": 278.5248341560364, "training_acc": 70.0, "val_loss": 92.73554682731628, "val_acc": 76.0}
{"epoch": 24, "training_loss": 294.94548320770264, "training_acc": 75.0, "val_loss": 43.29182207584381, "val_acc": 80.0}
{"epoch": 25, "training_loss": 116.32193803787231, "training_acc": 76.0, "val_loss": 40.75208306312561, "val_acc": 60.0}
{"epoch": 26, "training_loss": 269.96378898620605, "training_acc": 60.0, "val_loss": 45.715659856796265, "val_acc": 72.0}
{"epoch": 27, "training_loss": 279.6701965332031, "training_acc": 62.0, "val_loss": 12.515266239643097, "val_acc": 68.0}
{"epoch": 28, "training_loss": 154.87857627868652, "training_acc": 74.0, "val_loss": 85.10231375694275, "val_acc": 72.0}
{"epoch": 29, "training_loss": 290.2731490135193, "training_acc": 70.0, "val_loss": 36.77850663661957, "val_acc": 48.0}
{"epoch": 30, "training_loss": 172.24653482437134, "training_acc": 67.0, "val_loss": 112.54462003707886, "val_acc": 72.0}
{"epoch": 31, "training_loss": 263.7735378742218, "training_acc": 74.0, "val_loss": 44.8953241109848, "val_acc": 56.0}
{"epoch": 32, "training_loss": 216.04607009887695, "training_acc": 68.0, "val_loss": 87.76922225952148, "val_acc": 76.0}
{"epoch": 33, "training_loss": 222.76023292541504, "training_acc": 78.0, "val_loss": 66.04974865913391, "val_acc": 76.0}
{"epoch": 34, "training_loss": 146.188738822937, "training_acc": 75.0, "val_loss": 27.924850583076477, "val_acc": 80.0}
{"epoch": 35, "training_loss": 97.2691650390625, "training_acc": 81.0, "val_loss": 24.110394716262817, "val_acc": 76.0}
{"epoch": 36, "training_loss": 51.86034798622131, "training_acc": 81.0, "val_loss": 50.531911849975586, "val_acc": 72.0}
{"epoch": 37, "training_loss": 126.5556640625, "training_acc": 75.0, "val_loss": 60.210198163986206, "val_acc": 44.0}
{"epoch": 38, "training_loss": 154.5450484752655, "training_acc": 67.0, "val_loss": 30.053192377090454, "val_acc": 72.0}
{"epoch": 39, "training_loss": 126.72860145568848, "training_acc": 70.0, "val_loss": 79.57624793052673, "val_acc": 72.0}
{"epoch": 40, "training_loss": 205.285382270813, "training_acc": 76.0, "val_loss": 37.48651444911957, "val_acc": 76.0}
{"epoch": 41, "training_loss": 118.54546451568604, "training_acc": 76.0, "val_loss": 41.28498435020447, "val_acc": 76.0}
{"epoch": 42, "training_loss": 158.1388692855835, "training_acc": 79.0, "val_loss": 127.33412981033325, "val_acc": 72.0}
{"epoch": 43, "training_loss": 247.25516724586487, "training_acc": 80.0, "val_loss": 63.69618773460388, "val_acc": 40.0}
{"epoch": 44, "training_loss": 237.36449456214905, "training_acc": 56.0, "val_loss": 118.45699548721313, "val_acc": 72.0}
{"epoch": 45, "training_loss": 273.4028015136719, "training_acc": 75.0, "val_loss": 35.8880877494812, "val_acc": 68.0}
{"epoch": 46, "training_loss": 146.44652032852173, "training_acc": 66.0, "val_loss": 61.79259419441223, "val_acc": 76.0}
