"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1749.2080841064453, "training_acc": 47.0, "val_loss": 933.1554412841797, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3149.0570755004883, "training_acc": 72.0, "val_loss": 773.3330726623535, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2957.1722869873047, "training_acc": 28.0, "val_loss": 206.8307399749756, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1050.3407745361328, "training_acc": 72.0, "val_loss": 545.428991317749, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1920.819679260254, "training_acc": 72.0, "val_loss": 323.11112880706787, "val_acc": 72.0}
{"epoch": 5, "training_loss": 808.6579904556274, "training_acc": 73.0, "val_loss": 312.6288414001465, "val_acc": 44.0}
{"epoch": 6, "training_loss": 1687.8230209350586, "training_acc": 46.0, "val_loss": 180.60052394866943, "val_acc": 72.0}
{"epoch": 7, "training_loss": 865.574405670166, "training_acc": 65.0, "val_loss": 412.7415180206299, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1433.0789985656738, "training_acc": 72.0, "val_loss": 440.14129638671875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1170.797046661377, "training_acc": 74.0, "val_loss": 176.75427198410034, "val_acc": 68.0}
{"epoch": 10, "training_loss": 505.1805820465088, "training_acc": 68.0, "val_loss": 201.60844326019287, "val_acc": 56.0}
{"epoch": 11, "training_loss": 958.7813091278076, "training_acc": 58.0, "val_loss": 175.77760219573975, "val_acc": 72.0}
{"epoch": 12, "training_loss": 487.47054862976074, "training_acc": 73.0, "val_loss": 203.40194702148438, "val_acc": 72.0}
{"epoch": 13, "training_loss": 422.62999725341797, "training_acc": 78.0, "val_loss": 134.91361141204834, "val_acc": 52.0}
{"epoch": 14, "training_loss": 440.7519245147705, "training_acc": 54.0, "val_loss": 152.16985940933228, "val_acc": 68.0}
{"epoch": 15, "training_loss": 494.8770694732666, "training_acc": 72.0, "val_loss": 146.5006709098816, "val_acc": 68.0}
{"epoch": 16, "training_loss": 493.29346656799316, "training_acc": 52.0, "val_loss": 98.54774475097656, "val_acc": 48.0}
{"epoch": 17, "training_loss": 301.9286193847656, "training_acc": 62.0, "val_loss": 99.50311183929443, "val_acc": 64.0}
{"epoch": 18, "training_loss": 212.8972568511963, "training_acc": 67.0, "val_loss": 71.73871397972107, "val_acc": 52.0}
{"epoch": 19, "training_loss": 231.77935886383057, "training_acc": 69.0, "val_loss": 98.88821244239807, "val_acc": 72.0}
{"epoch": 20, "training_loss": 255.67359733581543, "training_acc": 69.0, "val_loss": 57.266801595687866, "val_acc": 68.0}
{"epoch": 21, "training_loss": 166.2151336669922, "training_acc": 72.0, "val_loss": 71.88298106193542, "val_acc": 72.0}
{"epoch": 22, "training_loss": 108.88088846206665, "training_acc": 80.0, "val_loss": 33.64855945110321, "val_acc": 76.0}
{"epoch": 23, "training_loss": 84.1582579612732, "training_acc": 76.0, "val_loss": 37.28637099266052, "val_acc": 72.0}
{"epoch": 24, "training_loss": 66.39876866340637, "training_acc": 86.0, "val_loss": 18.52649301290512, "val_acc": 68.0}
{"epoch": 25, "training_loss": 73.62819385528564, "training_acc": 79.0, "val_loss": 47.35459089279175, "val_acc": 52.0}
{"epoch": 26, "training_loss": 343.809850692749, "training_acc": 48.0, "val_loss": 80.85628151893616, "val_acc": 72.0}
{"epoch": 27, "training_loss": 301.26727294921875, "training_acc": 61.0, "val_loss": 26.1163592338562, "val_acc": 72.0}
{"epoch": 28, "training_loss": 70.3575701713562, "training_acc": 85.0, "val_loss": 26.421278715133667, "val_acc": 76.0}
{"epoch": 29, "training_loss": 74.51106929779053, "training_acc": 77.0, "val_loss": 46.02389335632324, "val_acc": 76.0}
{"epoch": 30, "training_loss": 81.29978048801422, "training_acc": 81.0, "val_loss": 27.320975065231323, "val_acc": 76.0}
{"epoch": 31, "training_loss": 51.22974872589111, "training_acc": 84.0, "val_loss": 29.89746332168579, "val_acc": 72.0}
{"epoch": 32, "training_loss": 46.829534471035004, "training_acc": 88.0, "val_loss": 19.99645233154297, "val_acc": 56.0}
{"epoch": 33, "training_loss": 137.57579231262207, "training_acc": 71.0, "val_loss": 34.2721164226532, "val_acc": 64.0}
{"epoch": 34, "training_loss": 142.2056770324707, "training_acc": 68.0, "val_loss": 81.3912034034729, "val_acc": 72.0}
{"epoch": 35, "training_loss": 250.89353895187378, "training_acc": 72.0, "val_loss": 30.088117718696594, "val_acc": 56.0}
{"epoch": 36, "training_loss": 72.22714233398438, "training_acc": 75.0, "val_loss": 66.50089621543884, "val_acc": 72.0}
{"epoch": 37, "training_loss": 145.02022552490234, "training_acc": 77.0, "val_loss": 39.864540100097656, "val_acc": 76.0}
{"epoch": 38, "training_loss": 84.52694916725159, "training_acc": 79.0, "val_loss": 38.366952538490295, "val_acc": 68.0}
{"epoch": 39, "training_loss": 110.2575478553772, "training_acc": 79.0, "val_loss": 36.433014273643494, "val_acc": 64.0}
{"epoch": 40, "training_loss": 119.01072216033936, "training_acc": 68.0, "val_loss": 102.82255411148071, "val_acc": 72.0}
{"epoch": 41, "training_loss": 358.5931701660156, "training_acc": 72.0, "val_loss": 36.93298697471619, "val_acc": 56.0}
{"epoch": 42, "training_loss": 215.90821838378906, "training_acc": 66.0, "val_loss": 41.97348952293396, "val_acc": 72.0}
{"epoch": 43, "training_loss": 114.11234617233276, "training_acc": 76.0, "val_loss": 19.98967081308365, "val_acc": 72.0}
