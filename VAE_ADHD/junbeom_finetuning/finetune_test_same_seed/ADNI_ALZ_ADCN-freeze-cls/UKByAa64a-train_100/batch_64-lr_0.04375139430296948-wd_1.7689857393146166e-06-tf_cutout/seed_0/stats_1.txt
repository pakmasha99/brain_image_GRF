"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 131.60462951660156, "training_acc": 72.0, "val_loss": 34.65077877044678, "val_acc": 72.0}
{"epoch": 1, "training_loss": 96.87744164466858, "training_acc": 72.0, "val_loss": 34.414851665496826, "val_acc": 28.0}
{"epoch": 2, "training_loss": 131.21620631217957, "training_acc": 29.0, "val_loss": 14.613451063632965, "val_acc": 56.0}
{"epoch": 3, "training_loss": 67.10992121696472, "training_acc": 70.0, "val_loss": 23.86818826198578, "val_acc": 72.0}
{"epoch": 4, "training_loss": 92.9508330821991, "training_acc": 72.0, "val_loss": 20.419184863567352, "val_acc": 72.0}
{"epoch": 5, "training_loss": 73.1366560459137, "training_acc": 72.0, "val_loss": 14.083610475063324, "val_acc": 56.0}
{"epoch": 6, "training_loss": 64.57972192764282, "training_acc": 65.0, "val_loss": 17.69457459449768, "val_acc": 60.0}
{"epoch": 7, "training_loss": 73.03062391281128, "training_acc": 63.0, "val_loss": 13.626837730407715, "val_acc": 76.0}
{"epoch": 8, "training_loss": 59.0731680393219, "training_acc": 78.0, "val_loss": 16.543172299861908, "val_acc": 72.0}
{"epoch": 9, "training_loss": 67.06641340255737, "training_acc": 72.0, "val_loss": 13.801997900009155, "val_acc": 76.0}
{"epoch": 10, "training_loss": 54.78341579437256, "training_acc": 74.0, "val_loss": 14.087960124015808, "val_acc": 56.0}
{"epoch": 11, "training_loss": 60.01927375793457, "training_acc": 66.0, "val_loss": 13.270387053489685, "val_acc": 56.0}
{"epoch": 12, "training_loss": 53.03429436683655, "training_acc": 73.0, "val_loss": 13.407649099826813, "val_acc": 76.0}
{"epoch": 13, "training_loss": 53.7779221534729, "training_acc": 72.0, "val_loss": 14.580188691616058, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.31558549404144, "training_acc": 72.0, "val_loss": 12.945394217967987, "val_acc": 68.0}
{"epoch": 15, "training_loss": 51.821473360061646, "training_acc": 76.0, "val_loss": 13.270455598831177, "val_acc": 64.0}
{"epoch": 16, "training_loss": 53.888492822647095, "training_acc": 77.0, "val_loss": 12.984731793403625, "val_acc": 68.0}
{"epoch": 17, "training_loss": 53.09835433959961, "training_acc": 74.0, "val_loss": 13.867941498756409, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.744070291519165, "training_acc": 72.0, "val_loss": 12.990939617156982, "val_acc": 68.0}
{"epoch": 19, "training_loss": 50.36430072784424, "training_acc": 77.0, "val_loss": 13.824784755706787, "val_acc": 56.0}
{"epoch": 20, "training_loss": 52.966474533081055, "training_acc": 78.0, "val_loss": 12.82714307308197, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50.11739766597748, "training_acc": 75.0, "val_loss": 14.131598174571991, "val_acc": 76.0}
{"epoch": 22, "training_loss": 56.2141273021698, "training_acc": 72.0, "val_loss": 12.59213238954544, "val_acc": 68.0}
{"epoch": 23, "training_loss": 49.43491458892822, "training_acc": 77.0, "val_loss": 13.348595798015594, "val_acc": 68.0}
{"epoch": 24, "training_loss": 54.04258751869202, "training_acc": 73.0, "val_loss": 12.45468184351921, "val_acc": 68.0}
{"epoch": 25, "training_loss": 50.0856055021286, "training_acc": 76.0, "val_loss": 13.193541765213013, "val_acc": 80.0}
{"epoch": 26, "training_loss": 49.37725830078125, "training_acc": 74.0, "val_loss": 12.513816356658936, "val_acc": 68.0}
{"epoch": 27, "training_loss": 51.29882597923279, "training_acc": 78.0, "val_loss": 12.534451484680176, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.31360054016113, "training_acc": 77.0, "val_loss": 12.855149805545807, "val_acc": 76.0}
{"epoch": 29, "training_loss": 47.95593702793121, "training_acc": 75.0, "val_loss": 12.54686713218689, "val_acc": 72.0}
{"epoch": 30, "training_loss": 47.91409349441528, "training_acc": 79.0, "val_loss": 12.484700232744217, "val_acc": 68.0}
{"epoch": 31, "training_loss": 47.14578115940094, "training_acc": 80.0, "val_loss": 12.485940754413605, "val_acc": 72.0}
{"epoch": 32, "training_loss": 47.64053440093994, "training_acc": 78.0, "val_loss": 12.825661897659302, "val_acc": 72.0}
{"epoch": 33, "training_loss": 46.17098903656006, "training_acc": 77.0, "val_loss": 12.620384991168976, "val_acc": 68.0}
{"epoch": 34, "training_loss": 47.14410138130188, "training_acc": 77.0, "val_loss": 12.574447691440582, "val_acc": 68.0}
{"epoch": 35, "training_loss": 46.04590022563934, "training_acc": 80.0, "val_loss": 12.91532814502716, "val_acc": 72.0}
{"epoch": 36, "training_loss": 48.820719480514526, "training_acc": 78.0, "val_loss": 12.975645065307617, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.65827238559723, "training_acc": 76.0, "val_loss": 12.780435383319855, "val_acc": 72.0}
{"epoch": 38, "training_loss": 45.08177995681763, "training_acc": 78.0, "val_loss": 13.095822930335999, "val_acc": 72.0}
{"epoch": 39, "training_loss": 47.75398635864258, "training_acc": 77.0, "val_loss": 13.099461793899536, "val_acc": 68.0}
{"epoch": 40, "training_loss": 46.13547766208649, "training_acc": 78.0, "val_loss": 13.118670880794525, "val_acc": 68.0}
{"epoch": 41, "training_loss": 46.26260995864868, "training_acc": 78.0, "val_loss": 13.153018057346344, "val_acc": 72.0}
{"epoch": 42, "training_loss": 46.749236822128296, "training_acc": 79.0, "val_loss": 13.134559988975525, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.88696110248566, "training_acc": 80.0, "val_loss": 13.066913187503815, "val_acc": 68.0}
