"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1811.9100875854492, "training_acc": 72.0, "val_loss": 957.1495056152344, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2432.5306091308594, "training_acc": 72.0, "val_loss": 2280.635643005371, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8666.66830444336, "training_acc": 28.0, "val_loss": 611.6984844207764, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1969.761287689209, "training_acc": 50.0, "val_loss": 1053.4137725830078, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4638.112106323242, "training_acc": 72.0, "val_loss": 1548.3108520507812, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6186.888641357422, "training_acc": 72.0, "val_loss": 1443.4868812561035, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5515.123153686523, "training_acc": 72.0, "val_loss": 914.1798973083496, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3093.8773040771484, "training_acc": 72.0, "val_loss": 47.38268256187439, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1858.518455505371, "training_acc": 58.0, "val_loss": 1688.7706756591797, "val_acc": 28.0}
{"epoch": 9, "training_loss": 6291.278381347656, "training_acc": 28.0, "val_loss": 433.54172706604004, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1656.970027923584, "training_acc": 44.0, "val_loss": 793.7939167022705, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3563.080612182617, "training_acc": 72.0, "val_loss": 1223.7796783447266, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4939.138244628906, "training_acc": 72.0, "val_loss": 1215.5710220336914, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4688.875579833984, "training_acc": 72.0, "val_loss": 854.2131423950195, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3067.166976928711, "training_acc": 72.0, "val_loss": 209.09709930419922, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1198.7121047973633, "training_acc": 58.0, "val_loss": 809.6652984619141, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2779.496955871582, "training_acc": 28.0, "val_loss": 152.48937606811523, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1061.4049530029297, "training_acc": 72.0, "val_loss": 469.00172233581543, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1857.2338638305664, "training_acc": 72.0, "val_loss": 353.8593292236328, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1126.7630729675293, "training_acc": 72.0, "val_loss": 253.53689193725586, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1025.3324966430664, "training_acc": 28.0, "val_loss": 117.48313903808594, "val_acc": 72.0}
{"epoch": 21, "training_loss": 587.7266483306885, "training_acc": 72.0, "val_loss": 237.40320205688477, "val_acc": 72.0}
{"epoch": 22, "training_loss": 820.7362995147705, "training_acc": 72.0, "val_loss": 13.885436952114105, "val_acc": 76.0}
{"epoch": 23, "training_loss": 541.2134704589844, "training_acc": 58.0, "val_loss": 45.92365026473999, "val_acc": 28.0}
{"epoch": 24, "training_loss": 544.9462738037109, "training_acc": 44.0, "val_loss": 474.16415214538574, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2016.9428634643555, "training_acc": 72.0, "val_loss": 545.5225944519043, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2012.3125, "training_acc": 72.0, "val_loss": 256.95228576660156, "val_acc": 72.0}
{"epoch": 27, "training_loss": 664.6907629966736, "training_acc": 71.0, "val_loss": 457.26494789123535, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1592.1158905029297, "training_acc": 28.0, "val_loss": 170.36868333816528, "val_acc": 72.0}
{"epoch": 29, "training_loss": 854.9826126098633, "training_acc": 72.0, "val_loss": 382.2352409362793, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1455.7111282348633, "training_acc": 72.0, "val_loss": 223.76024723052979, "val_acc": 72.0}
{"epoch": 31, "training_loss": 610.9821225404739, "training_acc": 73.0, "val_loss": 532.5316429138184, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2011.9083137512207, "training_acc": 28.0, "val_loss": 62.809741497039795, "val_acc": 72.0}
{"epoch": 33, "training_loss": 425.72195053100586, "training_acc": 72.0, "val_loss": 205.0100326538086, "val_acc": 72.0}
{"epoch": 34, "training_loss": 691.8861808776855, "training_acc": 72.0, "val_loss": 55.37979006767273, "val_acc": 28.0}
{"epoch": 35, "training_loss": 221.80009365081787, "training_acc": 44.0, "val_loss": 32.333630323410034, "val_acc": 72.0}
{"epoch": 36, "training_loss": 200.35212516784668, "training_acc": 62.0, "val_loss": 78.39595675468445, "val_acc": 72.0}
{"epoch": 37, "training_loss": 313.96171474456787, "training_acc": 72.0, "val_loss": 39.329493045806885, "val_acc": 72.0}
{"epoch": 38, "training_loss": 358.3901653289795, "training_acc": 62.0, "val_loss": 15.003350377082825, "val_acc": 60.0}
{"epoch": 39, "training_loss": 234.9814910888672, "training_acc": 74.0, "val_loss": 151.49859189987183, "val_acc": 72.0}
{"epoch": 40, "training_loss": 476.93578815460205, "training_acc": 72.0, "val_loss": 181.94838762283325, "val_acc": 28.0}
{"epoch": 41, "training_loss": 491.52298307418823, "training_acc": 46.0, "val_loss": 71.7437744140625, "val_acc": 72.0}
