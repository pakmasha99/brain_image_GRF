"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2201.616813659668, "training_acc": 42.0, "val_loss": 1146.8218803405762, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3521.4170837402344, "training_acc": 72.0, "val_loss": 908.4061622619629, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3110.5963439941406, "training_acc": 28.0, "val_loss": 317.2727584838867, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1750.7907638549805, "training_acc": 72.0, "val_loss": 651.0805606842041, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2451.0690841674805, "training_acc": 72.0, "val_loss": 312.65294551849365, "val_acc": 72.0}
{"epoch": 5, "training_loss": 997.12939453125, "training_acc": 56.0, "val_loss": 58.94274115562439, "val_acc": 28.0}
{"epoch": 6, "training_loss": 495.8334541320801, "training_acc": 46.0, "val_loss": 430.6861400604248, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1816.7681274414062, "training_acc": 72.0, "val_loss": 386.88323497772217, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1266.6684284210205, "training_acc": 72.0, "val_loss": 228.35986614227295, "val_acc": 28.0}
{"epoch": 9, "training_loss": 814.9491214752197, "training_acc": 28.0, "val_loss": 199.43315982818604, "val_acc": 72.0}
{"epoch": 10, "training_loss": 943.8781242370605, "training_acc": 72.0, "val_loss": 368.0610656738281, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1385.3813667297363, "training_acc": 72.0, "val_loss": 154.0462613105774, "val_acc": 72.0}
{"epoch": 12, "training_loss": 615.0070343017578, "training_acc": 58.0, "val_loss": 79.24774885177612, "val_acc": 28.0}
{"epoch": 13, "training_loss": 529.0050430297852, "training_acc": 44.0, "val_loss": 372.47259616851807, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1544.715072631836, "training_acc": 72.0, "val_loss": 357.6263427734375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1225.067398071289, "training_acc": 72.0, "val_loss": 18.45708042383194, "val_acc": 32.0}
{"epoch": 16, "training_loss": 380.7036552429199, "training_acc": 39.0, "val_loss": 61.43127083778381, "val_acc": 72.0}
{"epoch": 17, "training_loss": 346.4885311126709, "training_acc": 72.0, "val_loss": 66.83878302574158, "val_acc": 72.0}
{"epoch": 18, "training_loss": 468.1165657043457, "training_acc": 54.0, "val_loss": 30.70143163204193, "val_acc": 72.0}
{"epoch": 19, "training_loss": 147.7081880569458, "training_acc": 72.0, "val_loss": 73.40933084487915, "val_acc": 28.0}
{"epoch": 20, "training_loss": 326.8833751678467, "training_acc": 46.0, "val_loss": 161.13874912261963, "val_acc": 72.0}
{"epoch": 21, "training_loss": 581.0627765655518, "training_acc": 72.0, "val_loss": 23.44704121351242, "val_acc": 28.0}
{"epoch": 22, "training_loss": 87.7088828086853, "training_acc": 48.0, "val_loss": 80.68690896034241, "val_acc": 28.0}
{"epoch": 23, "training_loss": 441.6198215484619, "training_acc": 42.0, "val_loss": 212.18090057373047, "val_acc": 72.0}
{"epoch": 24, "training_loss": 800.7155094146729, "training_acc": 72.0, "val_loss": 66.95051193237305, "val_acc": 72.0}
{"epoch": 25, "training_loss": 591.93603515625, "training_acc": 56.0, "val_loss": 125.3801703453064, "val_acc": 28.0}
{"epoch": 26, "training_loss": 561.3629550933838, "training_acc": 48.0, "val_loss": 391.0714626312256, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1627.1213874816895, "training_acc": 72.0, "val_loss": 434.83119010925293, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1593.3743324279785, "training_acc": 72.0, "val_loss": 144.88680362701416, "val_acc": 72.0}
{"epoch": 29, "training_loss": 643.0829238891602, "training_acc": 60.0, "val_loss": 240.98172187805176, "val_acc": 28.0}
{"epoch": 30, "training_loss": 827.0655345916748, "training_acc": 42.0, "val_loss": 234.36214923858643, "val_acc": 72.0}
{"epoch": 31, "training_loss": 939.0541877746582, "training_acc": 72.0, "val_loss": 163.2792592048645, "val_acc": 72.0}
{"epoch": 32, "training_loss": 483.41246247291565, "training_acc": 70.0, "val_loss": 208.34810733795166, "val_acc": 28.0}
{"epoch": 33, "training_loss": 526.8598453998566, "training_acc": 52.0, "val_loss": 108.61495733261108, "val_acc": 72.0}
{"epoch": 34, "training_loss": 391.4583387374878, "training_acc": 72.0, "val_loss": 71.88449501991272, "val_acc": 28.0}
