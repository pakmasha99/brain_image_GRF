"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2204.04296875, "training_acc": 42.0, "val_loss": 1152.8237342834473, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3543.754051208496, "training_acc": 72.0, "val_loss": 875.3990173339844, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3124.075927734375, "training_acc": 28.0, "val_loss": 291.62018299102783, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1591.6341934204102, "training_acc": 72.0, "val_loss": 700.5610942840576, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2725.6363677978516, "training_acc": 72.0, "val_loss": 461.0382080078125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1551.5516901016235, "training_acc": 72.0, "val_loss": 649.4931697845459, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2585.2883682250977, "training_acc": 28.0, "val_loss": 34.24963653087616, "val_acc": 72.0}
{"epoch": 7, "training_loss": 263.5800895690918, "training_acc": 72.0, "val_loss": 205.62095642089844, "val_acc": 72.0}
{"epoch": 8, "training_loss": 717.2111549377441, "training_acc": 72.0, "val_loss": 79.10934090614319, "val_acc": 28.0}
{"epoch": 9, "training_loss": 250.78154802322388, "training_acc": 50.0, "val_loss": 68.65702867507935, "val_acc": 72.0}
{"epoch": 10, "training_loss": 253.53947734832764, "training_acc": 56.0, "val_loss": 132.18038082122803, "val_acc": 72.0}
{"epoch": 11, "training_loss": 585.0508823394775, "training_acc": 72.0, "val_loss": 116.11727476119995, "val_acc": 72.0}
{"epoch": 12, "training_loss": 457.29216957092285, "training_acc": 54.0, "val_loss": 73.5145092010498, "val_acc": 72.0}
{"epoch": 13, "training_loss": 279.4114627838135, "training_acc": 72.0, "val_loss": 18.101800978183746, "val_acc": 28.0}
{"epoch": 14, "training_loss": 156.2373275756836, "training_acc": 47.0, "val_loss": 14.35564011335373, "val_acc": 72.0}
{"epoch": 15, "training_loss": 251.2178249359131, "training_acc": 60.0, "val_loss": 86.40210628509521, "val_acc": 72.0}
{"epoch": 16, "training_loss": 435.2767391204834, "training_acc": 72.0, "val_loss": 79.7573983669281, "val_acc": 72.0}
{"epoch": 17, "training_loss": 579.0769348144531, "training_acc": 50.0, "val_loss": 30.123955011367798, "val_acc": 72.0}
{"epoch": 18, "training_loss": 176.68001174926758, "training_acc": 72.0, "val_loss": 53.031158447265625, "val_acc": 28.0}
{"epoch": 19, "training_loss": 225.58598518371582, "training_acc": 50.0, "val_loss": 144.8822021484375, "val_acc": 72.0}
{"epoch": 20, "training_loss": 505.0361108779907, "training_acc": 72.0, "val_loss": 83.52635502815247, "val_acc": 28.0}
{"epoch": 21, "training_loss": 402.50365829467773, "training_acc": 38.0, "val_loss": 88.52991461753845, "val_acc": 72.0}
{"epoch": 22, "training_loss": 245.990660905838, "training_acc": 72.0, "val_loss": 35.39263308048248, "val_acc": 28.0}
{"epoch": 23, "training_loss": 301.4470901489258, "training_acc": 46.0, "val_loss": 233.32488536834717, "val_acc": 72.0}
{"epoch": 24, "training_loss": 892.9862289428711, "training_acc": 72.0, "val_loss": 101.82451009750366, "val_acc": 72.0}
{"epoch": 25, "training_loss": 536.2008857727051, "training_acc": 58.0, "val_loss": 50.63905119895935, "val_acc": 28.0}
{"epoch": 26, "training_loss": 439.7354736328125, "training_acc": 46.0, "val_loss": 390.5823230743408, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1625.6456680297852, "training_acc": 72.0, "val_loss": 396.85113430023193, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1400.7730712890625, "training_acc": 72.0, "val_loss": 55.294960737228394, "val_acc": 72.0}
{"epoch": 29, "training_loss": 939.6291732788086, "training_acc": 56.0, "val_loss": 583.5103511810303, "val_acc": 28.0}
{"epoch": 30, "training_loss": 1515.4388446807861, "training_acc": 28.0, "val_loss": 390.13259410858154, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2172.194122314453, "training_acc": 72.0, "val_loss": 863.7660980224609, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3492.9705657958984, "training_acc": 72.0, "val_loss": 879.7687530517578, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3362.5834732055664, "training_acc": 72.0, "val_loss": 567.2648906707764, "val_acc": 72.0}
