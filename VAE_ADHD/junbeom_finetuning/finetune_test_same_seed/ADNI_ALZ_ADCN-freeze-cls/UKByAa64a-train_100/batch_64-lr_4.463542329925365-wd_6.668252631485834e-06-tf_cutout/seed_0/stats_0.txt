"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7274.222789764404, "training_acc": 72.0, "val_loss": 3198.2975006103516, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8711.809783935547, "training_acc": 72.0, "val_loss": 5019.190216064453, "val_acc": 28.0}
{"epoch": 2, "training_loss": 21004.19610595703, "training_acc": 28.0, "val_loss": 914.5586013793945, "val_acc": 36.0}
{"epoch": 3, "training_loss": 5557.949432373047, "training_acc": 51.0, "val_loss": 2858.5201263427734, "val_acc": 72.0}
{"epoch": 4, "training_loss": 12860.943176269531, "training_acc": 72.0, "val_loss": 3815.433120727539, "val_acc": 72.0}
{"epoch": 5, "training_loss": 15229.95068359375, "training_acc": 72.0, "val_loss": 2821.690559387207, "val_acc": 72.0}
{"epoch": 6, "training_loss": 9917.493637084961, "training_acc": 72.0, "val_loss": 615.5354499816895, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5149.710540771484, "training_acc": 64.0, "val_loss": 1081.1633110046387, "val_acc": 52.0}
{"epoch": 8, "training_loss": 8081.554443359375, "training_acc": 47.0, "val_loss": 369.70813274383545, "val_acc": 80.0}
{"epoch": 9, "training_loss": 3795.8398818969727, "training_acc": 71.0, "val_loss": 981.3456535339355, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4349.748641967773, "training_acc": 73.0, "val_loss": 1138.1123542785645, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3622.124542236328, "training_acc": 71.0, "val_loss": 235.19535064697266, "val_acc": 80.0}
{"epoch": 12, "training_loss": 2464.8176879882812, "training_acc": 60.0, "val_loss": 332.06117153167725, "val_acc": 68.0}
{"epoch": 13, "training_loss": 1543.9565086364746, "training_acc": 68.0, "val_loss": 784.8399639129639, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2860.031768798828, "training_acc": 72.0, "val_loss": 541.077995300293, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1514.6496200561523, "training_acc": 66.0, "val_loss": 429.6408176422119, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1769.224609375, "training_acc": 59.0, "val_loss": 517.0120239257812, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1323.1871166229248, "training_acc": 72.0, "val_loss": 304.13665771484375, "val_acc": 48.0}
{"epoch": 18, "training_loss": 1108.7019958496094, "training_acc": 52.0, "val_loss": 238.7176513671875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 799.6700115203857, "training_acc": 76.0, "val_loss": 205.16357421875, "val_acc": 60.0}
{"epoch": 20, "training_loss": 677.5166854858398, "training_acc": 72.0, "val_loss": 212.9887580871582, "val_acc": 72.0}
{"epoch": 21, "training_loss": 838.0127983093262, "training_acc": 77.0, "val_loss": 198.78780841827393, "val_acc": 56.0}
{"epoch": 22, "training_loss": 804.7175235748291, "training_acc": 63.0, "val_loss": 173.22115898132324, "val_acc": 72.0}
{"epoch": 23, "training_loss": 561.0789604187012, "training_acc": 77.0, "val_loss": 149.69441890716553, "val_acc": 56.0}
{"epoch": 24, "training_loss": 340.98203325271606, "training_acc": 70.0, "val_loss": 143.2967185974121, "val_acc": 72.0}
{"epoch": 25, "training_loss": 321.0543622970581, "training_acc": 76.0, "val_loss": 93.93381476402283, "val_acc": 64.0}
{"epoch": 26, "training_loss": 240.76975917816162, "training_acc": 78.0, "val_loss": 108.25355052947998, "val_acc": 68.0}
{"epoch": 27, "training_loss": 264.3578176498413, "training_acc": 74.0, "val_loss": 44.09884810447693, "val_acc": 84.0}
{"epoch": 28, "training_loss": 309.27023124694824, "training_acc": 74.0, "val_loss": 221.8390941619873, "val_acc": 72.0}
{"epoch": 29, "training_loss": 692.4921817779541, "training_acc": 75.0, "val_loss": 230.7209014892578, "val_acc": 52.0}
{"epoch": 30, "training_loss": 575.5550527572632, "training_acc": 65.0, "val_loss": 404.52561378479004, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1632.3019638061523, "training_acc": 72.0, "val_loss": 125.54419040679932, "val_acc": 76.0}
{"epoch": 32, "training_loss": 1485.7118377685547, "training_acc": 59.0, "val_loss": 164.33709859848022, "val_acc": 64.0}
{"epoch": 33, "training_loss": 905.558032989502, "training_acc": 70.0, "val_loss": 920.4371452331543, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3274.2975158691406, "training_acc": 72.0, "val_loss": 377.74367332458496, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1344.2656326293945, "training_acc": 67.0, "val_loss": 521.1570262908936, "val_acc": 56.0}
{"epoch": 36, "training_loss": 1671.838659286499, "training_acc": 57.0, "val_loss": 595.2658653259277, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2096.829719543457, "training_acc": 72.0, "val_loss": 144.89386081695557, "val_acc": 84.0}
{"epoch": 38, "training_loss": 887.9594383239746, "training_acc": 74.0, "val_loss": 459.5921516418457, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1604.3502655029297, "training_acc": 64.0, "val_loss": 562.3260498046875, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2203.2381591796875, "training_acc": 73.0, "val_loss": 370.77221870422363, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1007.8429565429688, "training_acc": 76.0, "val_loss": 441.6511535644531, "val_acc": 56.0}
{"epoch": 42, "training_loss": 1228.277961730957, "training_acc": 63.0, "val_loss": 482.53912925720215, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1642.4795722961426, "training_acc": 73.0, "val_loss": 437.40673065185547, "val_acc": 72.0}
{"epoch": 44, "training_loss": 971.2640342712402, "training_acc": 66.0, "val_loss": 291.59374237060547, "val_acc": 56.0}
{"epoch": 45, "training_loss": 785.3006553649902, "training_acc": 65.0, "val_loss": 229.85186576843262, "val_acc": 72.0}
{"epoch": 46, "training_loss": 565.5186939239502, "training_acc": 74.0, "val_loss": 137.80386447906494, "val_acc": 64.0}
