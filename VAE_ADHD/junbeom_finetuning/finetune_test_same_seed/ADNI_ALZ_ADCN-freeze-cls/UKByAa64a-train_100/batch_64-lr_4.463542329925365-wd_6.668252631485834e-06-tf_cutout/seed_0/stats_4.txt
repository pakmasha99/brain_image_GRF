"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7921.036502838135, "training_acc": 72.0, "val_loss": 3010.035514831543, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8848.61559677124, "training_acc": 71.0, "val_loss": 4945.254898071289, "val_acc": 28.0}
{"epoch": 2, "training_loss": 21293.376037597656, "training_acc": 28.0, "val_loss": 779.6420574188232, "val_acc": 52.0}
{"epoch": 3, "training_loss": 4512.599075317383, "training_acc": 58.0, "val_loss": 3306.515121459961, "val_acc": 72.0}
{"epoch": 4, "training_loss": 13118.967254638672, "training_acc": 72.0, "val_loss": 4385.374069213867, "val_acc": 72.0}
{"epoch": 5, "training_loss": 16264.690490722656, "training_acc": 72.0, "val_loss": 3670.089340209961, "val_acc": 72.0}
{"epoch": 6, "training_loss": 12015.171905517578, "training_acc": 72.0, "val_loss": 1675.4831314086914, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4680.077430725098, "training_acc": 71.0, "val_loss": 1233.3284378051758, "val_acc": 60.0}
{"epoch": 8, "training_loss": 7732.516540527344, "training_acc": 54.0, "val_loss": 1064.090347290039, "val_acc": 64.0}
{"epoch": 9, "training_loss": 4939.743865966797, "training_acc": 57.0, "val_loss": 1467.0058250427246, "val_acc": 68.0}
{"epoch": 10, "training_loss": 4156.884796142578, "training_acc": 74.0, "val_loss": 1748.5654830932617, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4213.261878967285, "training_acc": 74.0, "val_loss": 839.3227577209473, "val_acc": 76.0}
{"epoch": 12, "training_loss": 2457.9757080078125, "training_acc": 69.0, "val_loss": 774.4984149932861, "val_acc": 56.0}
{"epoch": 13, "training_loss": 3237.8165130615234, "training_acc": 57.0, "val_loss": 640.662956237793, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1960.733627319336, "training_acc": 75.0, "val_loss": 1045.5410957336426, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2946.2308654785156, "training_acc": 72.0, "val_loss": 273.3873128890991, "val_acc": 64.0}
{"epoch": 16, "training_loss": 1813.4659729003906, "training_acc": 52.0, "val_loss": 179.22621965408325, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1232.1823272705078, "training_acc": 74.0, "val_loss": 421.2340831756592, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1169.477102279663, "training_acc": 73.0, "val_loss": 310.0970506668091, "val_acc": 48.0}
{"epoch": 19, "training_loss": 932.2681846618652, "training_acc": 60.0, "val_loss": 127.32375860214233, "val_acc": 76.0}
{"epoch": 20, "training_loss": 1549.0612258911133, "training_acc": 51.0, "val_loss": 70.27199864387512, "val_acc": 76.0}
{"epoch": 21, "training_loss": 477.8765640258789, "training_acc": 79.0, "val_loss": 172.61719703674316, "val_acc": 76.0}
{"epoch": 22, "training_loss": 600.2842617034912, "training_acc": 74.0, "val_loss": 129.63485717773438, "val_acc": 56.0}
{"epoch": 23, "training_loss": 859.454647064209, "training_acc": 65.0, "val_loss": 227.1233320236206, "val_acc": 76.0}
{"epoch": 24, "training_loss": 813.4879741668701, "training_acc": 66.0, "val_loss": 74.9999463558197, "val_acc": 72.0}
{"epoch": 25, "training_loss": 270.69615268707275, "training_acc": 83.0, "val_loss": 158.9974045753479, "val_acc": 76.0}
{"epoch": 26, "training_loss": 336.6090712547302, "training_acc": 83.0, "val_loss": 253.34620475769043, "val_acc": 48.0}
{"epoch": 27, "training_loss": 1156.067497253418, "training_acc": 55.0, "val_loss": 418.6823844909668, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1289.5152969360352, "training_acc": 74.0, "val_loss": 671.6379165649414, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1648.263786315918, "training_acc": 47.0, "val_loss": 463.6685848236084, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1750.536262512207, "training_acc": 72.0, "val_loss": 221.99394702911377, "val_acc": 76.0}
{"epoch": 31, "training_loss": 681.619026184082, "training_acc": 77.0, "val_loss": 159.5114231109619, "val_acc": 56.0}
{"epoch": 32, "training_loss": 962.6904335021973, "training_acc": 64.0, "val_loss": 333.8237524032593, "val_acc": 72.0}
{"epoch": 33, "training_loss": 702.3170204162598, "training_acc": 80.0, "val_loss": 334.88337993621826, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1408.123498916626, "training_acc": 56.0, "val_loss": 251.85773372650146, "val_acc": 76.0}
{"epoch": 35, "training_loss": 714.7123651504517, "training_acc": 74.0, "val_loss": 107.05112218856812, "val_acc": 64.0}
{"epoch": 36, "training_loss": 508.3556823730469, "training_acc": 76.0, "val_loss": 205.45964241027832, "val_acc": 76.0}
{"epoch": 37, "training_loss": 804.3440742492676, "training_acc": 76.0, "val_loss": 36.86809539794922, "val_acc": 84.0}
{"epoch": 38, "training_loss": 610.468433380127, "training_acc": 74.0, "val_loss": 136.91983222961426, "val_acc": 76.0}
{"epoch": 39, "training_loss": 497.27512550354004, "training_acc": 75.0, "val_loss": 33.9888721704483, "val_acc": 72.0}
{"epoch": 40, "training_loss": 346.86247634887695, "training_acc": 72.0, "val_loss": 212.16909885406494, "val_acc": 72.0}
{"epoch": 41, "training_loss": 777.549783706665, "training_acc": 73.0, "val_loss": 134.64455604553223, "val_acc": 48.0}
{"epoch": 42, "training_loss": 319.2344436645508, "training_acc": 71.0, "val_loss": 208.7212085723877, "val_acc": 76.0}
{"epoch": 43, "training_loss": 479.6780004501343, "training_acc": 80.0, "val_loss": 118.31467151641846, "val_acc": 68.0}
{"epoch": 44, "training_loss": 545.4093112945557, "training_acc": 74.0, "val_loss": 146.67489528656006, "val_acc": 80.0}
{"epoch": 45, "training_loss": 188.32416915893555, "training_acc": 86.0, "val_loss": 175.04808902740479, "val_acc": 48.0}
{"epoch": 46, "training_loss": 662.0077095031738, "training_acc": 62.0, "val_loss": 109.31609869003296, "val_acc": 84.0}
{"epoch": 47, "training_loss": 245.9006061553955, "training_acc": 81.0, "val_loss": 81.56847953796387, "val_acc": 84.0}
{"epoch": 48, "training_loss": 199.73173713684082, "training_acc": 90.0, "val_loss": 62.5980019569397, "val_acc": 80.0}
{"epoch": 49, "training_loss": 273.3672580718994, "training_acc": 77.0, "val_loss": 389.68987464904785, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1476.3655090332031, "training_acc": 72.0, "val_loss": 189.01928663253784, "val_acc": 76.0}
{"epoch": 51, "training_loss": 1265.752098083496, "training_acc": 58.0, "val_loss": 98.73097538948059, "val_acc": 80.0}
{"epoch": 52, "training_loss": 347.7334156036377, "training_acc": 81.0, "val_loss": 506.0405731201172, "val_acc": 72.0}
{"epoch": 53, "training_loss": 975.5027389526367, "training_acc": 75.0, "val_loss": 378.16643714904785, "val_acc": 36.0}
{"epoch": 54, "training_loss": 1620.324234008789, "training_acc": 59.0, "val_loss": 289.4270896911621, "val_acc": 76.0}
{"epoch": 55, "training_loss": 689.955883026123, "training_acc": 80.0, "val_loss": 489.6059513092041, "val_acc": 72.0}
{"epoch": 56, "training_loss": 1057.9254741668701, "training_acc": 77.0, "val_loss": 269.75250244140625, "val_acc": 52.0}
{"epoch": 57, "training_loss": 1040.6158237457275, "training_acc": 65.0, "val_loss": 365.7435417175293, "val_acc": 72.0}
{"epoch": 58, "training_loss": 766.6862449645996, "training_acc": 76.0, "val_loss": 153.36530208587646, "val_acc": 60.0}
