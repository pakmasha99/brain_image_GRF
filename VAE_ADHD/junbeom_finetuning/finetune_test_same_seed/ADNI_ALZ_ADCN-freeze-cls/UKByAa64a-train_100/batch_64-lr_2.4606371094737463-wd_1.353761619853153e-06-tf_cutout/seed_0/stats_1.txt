"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4533.808441162109, "training_acc": 49.0, "val_loss": 2029.8656463623047, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6038.753715515137, "training_acc": 72.0, "val_loss": 1918.3786392211914, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6936.752899169922, "training_acc": 28.0, "val_loss": 191.59159660339355, "val_acc": 80.0}
{"epoch": 3, "training_loss": 1968.9463348388672, "training_acc": 72.0, "val_loss": 1166.4552688598633, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4273.001647949219, "training_acc": 72.0, "val_loss": 739.0201091766357, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2161.439712524414, "training_acc": 75.0, "val_loss": 687.1213912963867, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3164.7902603149414, "training_acc": 48.0, "val_loss": 630.4291248321533, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1933.2869186401367, "training_acc": 62.0, "val_loss": 468.84593963623047, "val_acc": 76.0}
{"epoch": 8, "training_loss": 2016.3564529418945, "training_acc": 73.0, "val_loss": 554.0370941162109, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1638.1504459381104, "training_acc": 71.0, "val_loss": 271.89531326293945, "val_acc": 52.0}
{"epoch": 10, "training_loss": 1135.8943519592285, "training_acc": 62.0, "val_loss": 318.9859628677368, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1213.0357246398926, "training_acc": 63.0, "val_loss": 376.90374851226807, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1378.427963256836, "training_acc": 72.0, "val_loss": 217.87800788879395, "val_acc": 72.0}
{"epoch": 13, "training_loss": 930.7983474731445, "training_acc": 62.0, "val_loss": 299.16365146636963, "val_acc": 52.0}
{"epoch": 14, "training_loss": 900.606990814209, "training_acc": 57.0, "val_loss": 420.49994468688965, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1281.4326095581055, "training_acc": 72.0, "val_loss": 98.18785786628723, "val_acc": 68.0}
{"epoch": 16, "training_loss": 768.3314819335938, "training_acc": 59.0, "val_loss": 126.91842317581177, "val_acc": 48.0}
{"epoch": 17, "training_loss": 555.7283782958984, "training_acc": 68.0, "val_loss": 600.5924701690674, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1977.746681213379, "training_acc": 72.0, "val_loss": 294.76170539855957, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1003.6930503845215, "training_acc": 57.0, "val_loss": 353.7280797958374, "val_acc": 48.0}
{"epoch": 20, "training_loss": 1077.035638809204, "training_acc": 57.0, "val_loss": 352.21362113952637, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1033.7301406860352, "training_acc": 72.0, "val_loss": 157.5667381286621, "val_acc": 72.0}
{"epoch": 22, "training_loss": 763.4860343933105, "training_acc": 73.0, "val_loss": 243.15381050109863, "val_acc": 60.0}
{"epoch": 23, "training_loss": 856.9307222366333, "training_acc": 61.0, "val_loss": 269.5139169692993, "val_acc": 76.0}
{"epoch": 24, "training_loss": 786.6072235107422, "training_acc": 76.0, "val_loss": 150.72884559631348, "val_acc": 72.0}
{"epoch": 25, "training_loss": 750.8202133178711, "training_acc": 68.0, "val_loss": 150.40866136550903, "val_acc": 64.0}
{"epoch": 26, "training_loss": 285.0936098098755, "training_acc": 77.0, "val_loss": 219.55838203430176, "val_acc": 72.0}
{"epoch": 27, "training_loss": 485.41983127593994, "training_acc": 74.0, "val_loss": 348.37048053741455, "val_acc": 40.0}
{"epoch": 28, "training_loss": 693.3700723648071, "training_acc": 54.0, "val_loss": 336.1703634262085, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1077.6503639221191, "training_acc": 72.0, "val_loss": 205.8539867401123, "val_acc": 72.0}
{"epoch": 30, "training_loss": 741.9336128234863, "training_acc": 60.0, "val_loss": 185.41412353515625, "val_acc": 44.0}
{"epoch": 31, "training_loss": 610.9734535217285, "training_acc": 64.0, "val_loss": 391.3257360458374, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1083.4687995910645, "training_acc": 73.0, "val_loss": 156.64933919906616, "val_acc": 64.0}
{"epoch": 33, "training_loss": 470.2883605957031, "training_acc": 68.0, "val_loss": 135.639750957489, "val_acc": 64.0}
{"epoch": 34, "training_loss": 374.24612045288086, "training_acc": 74.0, "val_loss": 289.28024768829346, "val_acc": 76.0}
