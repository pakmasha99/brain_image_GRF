"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2268.8719749450684, "training_acc": 70.0, "val_loss": 1978.640365600586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5355.4801025390625, "training_acc": 72.0, "val_loss": 3120.6525802612305, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11189.402709960938, "training_acc": 28.0, "val_loss": 557.959508895874, "val_acc": 64.0}
{"epoch": 3, "training_loss": 2398.520751953125, "training_acc": 62.0, "val_loss": 1766.415786743164, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7150.661773681641, "training_acc": 72.0, "val_loss": 2167.22354888916, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8014.356521606445, "training_acc": 72.0, "val_loss": 1521.4930534362793, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4915.205154418945, "training_acc": 72.0, "val_loss": 795.7742691040039, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2145.9952545166016, "training_acc": 60.0, "val_loss": 1429.9741744995117, "val_acc": 44.0}
{"epoch": 8, "training_loss": 4669.039581298828, "training_acc": 44.0, "val_loss": 860.4471206665039, "val_acc": 68.0}
{"epoch": 9, "training_loss": 2122.4549560546875, "training_acc": 71.0, "val_loss": 891.4963722229004, "val_acc": 76.0}
{"epoch": 10, "training_loss": 3333.1590576171875, "training_acc": 74.0, "val_loss": 823.4587669372559, "val_acc": 76.0}
{"epoch": 11, "training_loss": 2416.5779151916504, "training_acc": 74.0, "val_loss": 723.1278419494629, "val_acc": 68.0}
{"epoch": 12, "training_loss": 1704.725830078125, "training_acc": 65.0, "val_loss": 817.4167633056641, "val_acc": 64.0}
{"epoch": 13, "training_loss": 1689.542121887207, "training_acc": 62.0, "val_loss": 499.7445583343506, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1426.8094482421875, "training_acc": 72.0, "val_loss": 488.61188888549805, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1581.8549346923828, "training_acc": 74.0, "val_loss": 297.60801792144775, "val_acc": 68.0}
{"epoch": 16, "training_loss": 826.5645141601562, "training_acc": 68.0, "val_loss": 323.85919094085693, "val_acc": 56.0}
{"epoch": 17, "training_loss": 509.39649200439453, "training_acc": 70.0, "val_loss": 318.8366413116455, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1295.5917320251465, "training_acc": 72.0, "val_loss": 93.10508370399475, "val_acc": 68.0}
{"epoch": 19, "training_loss": 1058.1894226074219, "training_acc": 58.0, "val_loss": 444.80481147766113, "val_acc": 36.0}
{"epoch": 20, "training_loss": 1249.1146621704102, "training_acc": 54.0, "val_loss": 499.36957359313965, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2052.5623779296875, "training_acc": 72.0, "val_loss": 282.2242259979248, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1024.0598640441895, "training_acc": 63.0, "val_loss": 447.96390533447266, "val_acc": 44.0}
{"epoch": 23, "training_loss": 1269.218173980713, "training_acc": 52.0, "val_loss": 231.0199499130249, "val_acc": 80.0}
{"epoch": 24, "training_loss": 892.3674850463867, "training_acc": 76.0, "val_loss": 238.9354705810547, "val_acc": 80.0}
{"epoch": 25, "training_loss": 763.653076171875, "training_acc": 73.0, "val_loss": 281.32524490356445, "val_acc": 56.0}
{"epoch": 26, "training_loss": 701.4839515686035, "training_acc": 64.0, "val_loss": 175.05123615264893, "val_acc": 80.0}
{"epoch": 27, "training_loss": 625.5909271240234, "training_acc": 76.0, "val_loss": 115.6944751739502, "val_acc": 72.0}
{"epoch": 28, "training_loss": 672.1007080078125, "training_acc": 72.0, "val_loss": 128.98956537246704, "val_acc": 60.0}
{"epoch": 29, "training_loss": 479.1721878051758, "training_acc": 70.0, "val_loss": 244.8503017425537, "val_acc": 72.0}
{"epoch": 30, "training_loss": 826.7233896255493, "training_acc": 73.0, "val_loss": 367.5023078918457, "val_acc": 36.0}
{"epoch": 31, "training_loss": 862.2501163482666, "training_acc": 51.0, "val_loss": 227.74231433868408, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1208.4522323608398, "training_acc": 72.0, "val_loss": 263.78631591796875, "val_acc": 72.0}
{"epoch": 33, "training_loss": 765.0406074523926, "training_acc": 72.0, "val_loss": 562.8416061401367, "val_acc": 32.0}
{"epoch": 34, "training_loss": 1411.1201267242432, "training_acc": 47.0, "val_loss": 197.6611852645874, "val_acc": 80.0}
{"epoch": 35, "training_loss": 1071.3192596435547, "training_acc": 73.0, "val_loss": 323.32191467285156, "val_acc": 72.0}
{"epoch": 36, "training_loss": 981.1831150054932, "training_acc": 74.0, "val_loss": 317.27330684661865, "val_acc": 56.0}
{"epoch": 37, "training_loss": 1035.1562881469727, "training_acc": 55.0, "val_loss": 195.80276012420654, "val_acc": 72.0}
