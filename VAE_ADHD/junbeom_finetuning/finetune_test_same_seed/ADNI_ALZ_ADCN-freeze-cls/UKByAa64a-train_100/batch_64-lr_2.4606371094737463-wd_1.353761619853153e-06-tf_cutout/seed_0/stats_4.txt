"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4353.623260498047, "training_acc": 72.0, "val_loss": 1730.1841735839844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5211.699703216553, "training_acc": 72.0, "val_loss": 2411.493682861328, "val_acc": 28.0}
{"epoch": 2, "training_loss": 10666.146789550781, "training_acc": 28.0, "val_loss": 362.89820671081543, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2913.0894317626953, "training_acc": 60.0, "val_loss": 1554.0242195129395, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6020.419479370117, "training_acc": 72.0, "val_loss": 1785.195541381836, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6086.312301635742, "training_acc": 72.0, "val_loss": 1091.7433738708496, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2779.5908584594727, "training_acc": 74.0, "val_loss": 560.158634185791, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3929.088180541992, "training_acc": 52.0, "val_loss": 615.8881187438965, "val_acc": 56.0}
{"epoch": 8, "training_loss": 3333.555778503418, "training_acc": 52.0, "val_loss": 724.5754241943359, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2308.7539138793945, "training_acc": 75.0, "val_loss": 1113.1396293640137, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3561.0626831054688, "training_acc": 72.0, "val_loss": 667.0688152313232, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1396.7244415283203, "training_acc": 76.0, "val_loss": 476.4982223510742, "val_acc": 52.0}
{"epoch": 12, "training_loss": 2622.0175704956055, "training_acc": 46.0, "val_loss": 278.97486686706543, "val_acc": 68.0}
{"epoch": 13, "training_loss": 1251.9485969543457, "training_acc": 61.0, "val_loss": 618.583345413208, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2156.0474014282227, "training_acc": 72.0, "val_loss": 456.06842041015625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1225.1161289215088, "training_acc": 73.0, "val_loss": 420.0859546661377, "val_acc": 32.0}
{"epoch": 16, "training_loss": 1778.6351776123047, "training_acc": 46.0, "val_loss": 127.33173370361328, "val_acc": 76.0}
{"epoch": 17, "training_loss": 1080.2185592651367, "training_acc": 72.0, "val_loss": 537.6605033874512, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2081.764846801758, "training_acc": 72.0, "val_loss": 117.99812316894531, "val_acc": 76.0}
{"epoch": 19, "training_loss": 951.5569000244141, "training_acc": 62.0, "val_loss": 355.15923500061035, "val_acc": 40.0}
{"epoch": 20, "training_loss": 1265.379981994629, "training_acc": 43.0, "val_loss": 320.95348834991455, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1030.0880680084229, "training_acc": 73.0, "val_loss": 132.7358365058899, "val_acc": 76.0}
{"epoch": 22, "training_loss": 832.790699005127, "training_acc": 67.0, "val_loss": 144.71094608306885, "val_acc": 68.0}
{"epoch": 23, "training_loss": 650.1344909667969, "training_acc": 74.0, "val_loss": 333.3359956741333, "val_acc": 72.0}
{"epoch": 24, "training_loss": 943.8166046142578, "training_acc": 77.0, "val_loss": 186.4723563194275, "val_acc": 76.0}
{"epoch": 25, "training_loss": 523.2524089813232, "training_acc": 73.0, "val_loss": 149.8093843460083, "val_acc": 64.0}
{"epoch": 26, "training_loss": 626.685848236084, "training_acc": 67.0, "val_loss": 133.69338512420654, "val_acc": 76.0}
{"epoch": 27, "training_loss": 445.8494396209717, "training_acc": 79.0, "val_loss": 64.88159894943237, "val_acc": 76.0}
{"epoch": 28, "training_loss": 324.3352108001709, "training_acc": 70.0, "val_loss": 16.748744249343872, "val_acc": 84.0}
{"epoch": 29, "training_loss": 288.7000102996826, "training_acc": 76.0, "val_loss": 28.056600689888, "val_acc": 80.0}
{"epoch": 30, "training_loss": 373.8703269958496, "training_acc": 69.0, "val_loss": 51.79835557937622, "val_acc": 52.0}
{"epoch": 31, "training_loss": 389.3249206542969, "training_acc": 70.0, "val_loss": 137.95944452285767, "val_acc": 72.0}
{"epoch": 32, "training_loss": 302.5173568725586, "training_acc": 78.0, "val_loss": 112.28194236755371, "val_acc": 52.0}
{"epoch": 33, "training_loss": 466.694974899292, "training_acc": 67.0, "val_loss": 158.28427076339722, "val_acc": 76.0}
{"epoch": 34, "training_loss": 322.1483750343323, "training_acc": 80.0, "val_loss": 64.36342597007751, "val_acc": 64.0}
{"epoch": 35, "training_loss": 201.72035360336304, "training_acc": 79.0, "val_loss": 64.94783759117126, "val_acc": 84.0}
{"epoch": 36, "training_loss": 101.72239971160889, "training_acc": 83.0, "val_loss": 81.6496729850769, "val_acc": 76.0}
{"epoch": 37, "training_loss": 247.71502923965454, "training_acc": 68.0, "val_loss": 98.4079658985138, "val_acc": 72.0}
{"epoch": 38, "training_loss": 243.79098415374756, "training_acc": 76.0, "val_loss": 194.70837116241455, "val_acc": 28.0}
{"epoch": 39, "training_loss": 512.3821392059326, "training_acc": 56.0, "val_loss": 87.45976686477661, "val_acc": 76.0}
{"epoch": 40, "training_loss": 172.1239914894104, "training_acc": 79.0, "val_loss": 63.08056712150574, "val_acc": 68.0}
{"epoch": 41, "training_loss": 246.07048320770264, "training_acc": 74.0, "val_loss": 116.85382127761841, "val_acc": 80.0}
{"epoch": 42, "training_loss": 208.64365100860596, "training_acc": 79.0, "val_loss": 74.04579520225525, "val_acc": 76.0}
{"epoch": 43, "training_loss": 213.85075759887695, "training_acc": 76.0, "val_loss": 76.47626399993896, "val_acc": 80.0}
{"epoch": 44, "training_loss": 135.05072832107544, "training_acc": 80.0, "val_loss": 82.5221300125122, "val_acc": 80.0}
{"epoch": 45, "training_loss": 130.74759984016418, "training_acc": 83.0, "val_loss": 48.18538427352905, "val_acc": 68.0}
{"epoch": 46, "training_loss": 77.02859663963318, "training_acc": 83.0, "val_loss": 50.11864900588989, "val_acc": 76.0}
{"epoch": 47, "training_loss": 116.18431806564331, "training_acc": 76.0, "val_loss": 54.708802700042725, "val_acc": 76.0}
