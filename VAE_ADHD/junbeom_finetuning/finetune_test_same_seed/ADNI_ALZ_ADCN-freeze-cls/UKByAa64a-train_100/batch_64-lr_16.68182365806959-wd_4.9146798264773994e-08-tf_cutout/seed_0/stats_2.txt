"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 78559.6562576294, "training_acc": 42.0, "val_loss": 41924.18518066406, "val_acc": 72.0}
{"epoch": 1, "training_loss": 139276.392578125, "training_acc": 72.0, "val_loss": 33738.592529296875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 114769.94604492188, "training_acc": 28.0, "val_loss": 12624.453735351562, "val_acc": 72.0}
{"epoch": 3, "training_loss": 71987.63037109375, "training_acc": 72.0, "val_loss": 29323.721313476562, "val_acc": 72.0}
{"epoch": 4, "training_loss": 114551.2177734375, "training_acc": 72.0, "val_loss": 20827.471923828125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 67482.05017089844, "training_acc": 72.0, "val_loss": 11631.640625, "val_acc": 28.0}
{"epoch": 6, "training_loss": 51477.499267578125, "training_acc": 28.0, "val_loss": 4700.259017944336, "val_acc": 72.0}
{"epoch": 7, "training_loss": 25156.340698242188, "training_acc": 72.0, "val_loss": 11003.214263916016, "val_acc": 72.0}
{"epoch": 8, "training_loss": 39621.8125, "training_acc": 72.0, "val_loss": 1792.9460525512695, "val_acc": 72.0}
{"epoch": 9, "training_loss": 29073.64404296875, "training_acc": 60.0, "val_loss": 16534.359741210938, "val_acc": 28.0}
{"epoch": 10, "training_loss": 48339.79754638672, "training_acc": 42.0, "val_loss": 8315.444946289062, "val_acc": 72.0}
{"epoch": 11, "training_loss": 35925.48046875, "training_acc": 72.0, "val_loss": 6991.313171386719, "val_acc": 72.0}
{"epoch": 12, "training_loss": 18075.602127075195, "training_acc": 72.0, "val_loss": 20828.5888671875, "val_acc": 28.0}
{"epoch": 13, "training_loss": 81611.95629882812, "training_acc": 28.0, "val_loss": 1315.0924682617188, "val_acc": 72.0}
{"epoch": 14, "training_loss": 10708.905822753906, "training_acc": 72.0, "val_loss": 7158.314514160156, "val_acc": 72.0}
{"epoch": 15, "training_loss": 24882.825317382812, "training_acc": 72.0, "val_loss": 444.2817211151123, "val_acc": 36.0}
{"epoch": 16, "training_loss": 8364.71728515625, "training_acc": 40.0, "val_loss": 1796.9039916992188, "val_acc": 72.0}
{"epoch": 17, "training_loss": 13175.22265625, "training_acc": 58.0, "val_loss": 1269.1585540771484, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6101.986907958984, "training_acc": 72.0, "val_loss": 2606.9103240966797, "val_acc": 28.0}
{"epoch": 19, "training_loss": 16635.372009277344, "training_acc": 36.0, "val_loss": 5469.254684448242, "val_acc": 72.0}
{"epoch": 20, "training_loss": 17660.015625, "training_acc": 72.0, "val_loss": 5065.214157104492, "val_acc": 28.0}
{"epoch": 21, "training_loss": 12839.4970703125, "training_acc": 52.0, "val_loss": 1354.305362701416, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2616.3463172912598, "training_acc": 70.0, "val_loss": 1234.123134613037, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4101.790481567383, "training_acc": 58.0, "val_loss": 5703.372573852539, "val_acc": 72.0}
{"epoch": 24, "training_loss": 26112.677368164062, "training_acc": 72.0, "val_loss": 7267.555236816406, "val_acc": 72.0}
{"epoch": 25, "training_loss": 22215.067962646484, "training_acc": 72.0, "val_loss": 9553.94515991211, "val_acc": 28.0}
{"epoch": 26, "training_loss": 31504.45831298828, "training_acc": 28.0, "val_loss": 7793.537902832031, "val_acc": 72.0}
{"epoch": 27, "training_loss": 43907.818359375, "training_acc": 72.0, "val_loss": 15324.252319335938, "val_acc": 72.0}
{"epoch": 28, "training_loss": 57192.22119140625, "training_acc": 72.0, "val_loss": 8014.814758300781, "val_acc": 72.0}
{"epoch": 29, "training_loss": 21361.81708908081, "training_acc": 68.0, "val_loss": 13336.241149902344, "val_acc": 28.0}
{"epoch": 30, "training_loss": 42772.87091064453, "training_acc": 28.0, "val_loss": 8691.742706298828, "val_acc": 72.0}
{"epoch": 31, "training_loss": 42164.786865234375, "training_acc": 72.0, "val_loss": 18318.57452392578, "val_acc": 72.0}
{"epoch": 32, "training_loss": 71736.69311523438, "training_acc": 72.0, "val_loss": 14437.635803222656, "val_acc": 72.0}
{"epoch": 33, "training_loss": 47970.04943847656, "training_acc": 72.0, "val_loss": 2456.070327758789, "val_acc": 28.0}
{"epoch": 34, "training_loss": 9970.661193847656, "training_acc": 28.0, "val_loss": 7259.883117675781, "val_acc": 72.0}
