"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 57162.54833984375, "training_acc": 72.0, "val_loss": 41159.51843261719, "val_acc": 72.0}
{"epoch": 1, "training_loss": 125535.0869140625, "training_acc": 72.0, "val_loss": 54534.466552734375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 194321.142578125, "training_acc": 28.0, "val_loss": 6018.967819213867, "val_acc": 72.0}
{"epoch": 3, "training_loss": 46167.7919921875, "training_acc": 72.0, "val_loss": 20399.456787109375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 76533.00830078125, "training_acc": 72.0, "val_loss": 8534.165954589844, "val_acc": 72.0}
{"epoch": 5, "training_loss": 43472.474609375, "training_acc": 52.0, "val_loss": 6879.380035400391, "val_acc": 28.0}
{"epoch": 6, "training_loss": 25169.54034423828, "training_acc": 50.0, "val_loss": 16340.435791015625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 68366.16333007812, "training_acc": 72.0, "val_loss": 17355.792236328125, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61053.04345703125, "training_acc": 72.0, "val_loss": 3454.5913696289062, "val_acc": 72.0}
{"epoch": 9, "training_loss": 45548.760009765625, "training_acc": 52.0, "val_loss": 23764.285278320312, "val_acc": 28.0}
{"epoch": 10, "training_loss": 62881.13179016113, "training_acc": 28.0, "val_loss": 15273.765563964844, "val_acc": 72.0}
{"epoch": 11, "training_loss": 76852.638671875, "training_acc": 72.0, "val_loss": 33051.3427734375, "val_acc": 72.0}
{"epoch": 12, "training_loss": 138896.921875, "training_acc": 72.0, "val_loss": 34952.044677734375, "val_acc": 72.0}
{"epoch": 13, "training_loss": 133770.10571289062, "training_acc": 72.0, "val_loss": 22456.204223632812, "val_acc": 72.0}
{"epoch": 14, "training_loss": 77810.6708984375, "training_acc": 72.0, "val_loss": 189.37225341796875, "val_acc": 64.0}
{"epoch": 15, "training_loss": 31611.92510986328, "training_acc": 44.0, "val_loss": 11628.687286376953, "val_acc": 28.0}
{"epoch": 16, "training_loss": 43893.42578125, "training_acc": 38.0, "val_loss": 12673.281860351562, "val_acc": 72.0}
{"epoch": 17, "training_loss": 53874.262451171875, "training_acc": 72.0, "val_loss": 13793.470764160156, "val_acc": 72.0}
{"epoch": 18, "training_loss": 48593.81457519531, "training_acc": 72.0, "val_loss": 2372.6314544677734, "val_acc": 72.0}
{"epoch": 19, "training_loss": 25552.052001953125, "training_acc": 64.0, "val_loss": 19863.043212890625, "val_acc": 28.0}
{"epoch": 20, "training_loss": 53161.406158447266, "training_acc": 28.0, "val_loss": 13663.825988769531, "val_acc": 72.0}
{"epoch": 21, "training_loss": 66625.54345703125, "training_acc": 72.0, "val_loss": 29041.558837890625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 117952.27661132812, "training_acc": 72.0, "val_loss": 29837.338256835938, "val_acc": 72.0}
{"epoch": 23, "training_loss": 112781.67138671875, "training_acc": 72.0, "val_loss": 18904.661560058594, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60363.841552734375, "training_acc": 72.0, "val_loss": 6997.257995605469, "val_acc": 28.0}
{"epoch": 25, "training_loss": 35588.14685058594, "training_acc": 28.0, "val_loss": 337.14213371276855, "val_acc": 76.0}
{"epoch": 26, "training_loss": 4117.716705322266, "training_acc": 76.0, "val_loss": 1918.9796447753906, "val_acc": 72.0}
{"epoch": 27, "training_loss": 13695.49609375, "training_acc": 52.0, "val_loss": 2660.4984283447266, "val_acc": 72.0}
{"epoch": 28, "training_loss": 10510.749267578125, "training_acc": 72.0, "val_loss": 1923.153305053711, "val_acc": 72.0}
{"epoch": 29, "training_loss": 12408.954528808594, "training_acc": 56.0, "val_loss": 2265.3743743896484, "val_acc": 72.0}
{"epoch": 30, "training_loss": 9309.434051513672, "training_acc": 72.0, "val_loss": 700.994873046875, "val_acc": 72.0}
{"epoch": 31, "training_loss": 16769.291625976562, "training_acc": 56.0, "val_loss": 1259.9845886230469, "val_acc": 28.0}
{"epoch": 32, "training_loss": 12997.177490234375, "training_acc": 50.0, "val_loss": 17429.283142089844, "val_acc": 72.0}
{"epoch": 33, "training_loss": 73845.83325195312, "training_acc": 72.0, "val_loss": 21156.51092529297, "val_acc": 72.0}
