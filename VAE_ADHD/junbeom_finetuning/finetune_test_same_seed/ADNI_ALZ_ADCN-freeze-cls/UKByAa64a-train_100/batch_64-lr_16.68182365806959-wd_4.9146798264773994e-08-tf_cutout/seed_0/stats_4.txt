"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 85653.58879852295, "training_acc": 47.0, "val_loss": 40438.8671875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 127800.37915039062, "training_acc": 72.0, "val_loss": 37562.17041015625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 131662.00732421875, "training_acc": 28.0, "val_loss": 9761.702728271484, "val_acc": 72.0}
{"epoch": 3, "training_loss": 53771.090087890625, "training_acc": 72.0, "val_loss": 23328.543090820312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 89493.61010742188, "training_acc": 72.0, "val_loss": 13161.947631835938, "val_acc": 72.0}
{"epoch": 5, "training_loss": 32217.032806396484, "training_acc": 72.0, "val_loss": 35055.072021484375, "val_acc": 28.0}
{"epoch": 6, "training_loss": 146645.5751953125, "training_acc": 28.0, "val_loss": 15306.385803222656, "val_acc": 28.0}
{"epoch": 7, "training_loss": 55185.86877441406, "training_acc": 44.0, "val_loss": 22983.241271972656, "val_acc": 72.0}
{"epoch": 8, "training_loss": 100364.6376953125, "training_acc": 72.0, "val_loss": 32433.94775390625, "val_acc": 72.0}
{"epoch": 9, "training_loss": 128876.91943359375, "training_acc": 72.0, "val_loss": 26697.927856445312, "val_acc": 72.0}
{"epoch": 10, "training_loss": 93676.90991210938, "training_acc": 72.0, "val_loss": 6990.334320068359, "val_acc": 72.0}
{"epoch": 11, "training_loss": 45948.92724609375, "training_acc": 54.0, "val_loss": 25431.768798828125, "val_acc": 28.0}
{"epoch": 12, "training_loss": 79462.64514160156, "training_acc": 28.0, "val_loss": 9484.790802001953, "val_acc": 72.0}
{"epoch": 13, "training_loss": 55280.3955078125, "training_acc": 72.0, "val_loss": 23398.24981689453, "val_acc": 72.0}
{"epoch": 14, "training_loss": 94053.35327148438, "training_acc": 72.0, "val_loss": 21568.234252929688, "val_acc": 72.0}
{"epoch": 15, "training_loss": 76758.27856445312, "training_acc": 72.0, "val_loss": 7983.012390136719, "val_acc": 72.0}
{"epoch": 16, "training_loss": 29399.68359375, "training_acc": 58.0, "val_loss": 11639.501953125, "val_acc": 28.0}
{"epoch": 17, "training_loss": 31571.426223754883, "training_acc": 46.0, "val_loss": 4746.687698364258, "val_acc": 72.0}
{"epoch": 18, "training_loss": 17847.196533203125, "training_acc": 72.0, "val_loss": 626.2338638305664, "val_acc": 72.0}
{"epoch": 19, "training_loss": 19359.595825195312, "training_acc": 60.0, "val_loss": 8451.216888427734, "val_acc": 28.0}
{"epoch": 20, "training_loss": 27719.152221679688, "training_acc": 48.0, "val_loss": 12147.647857666016, "val_acc": 72.0}
{"epoch": 21, "training_loss": 52048.797119140625, "training_acc": 72.0, "val_loss": 13518.104553222656, "val_acc": 72.0}
{"epoch": 22, "training_loss": 46279.788818359375, "training_acc": 72.0, "val_loss": 2311.6010665893555, "val_acc": 72.0}
{"epoch": 23, "training_loss": 39089.303955078125, "training_acc": 52.0, "val_loss": 22592.047119140625, "val_acc": 28.0}
{"epoch": 24, "training_loss": 63325.28857421875, "training_acc": 28.0, "val_loss": 12720.921325683594, "val_acc": 72.0}
{"epoch": 25, "training_loss": 64570.28076171875, "training_acc": 72.0, "val_loss": 28839.947509765625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 116246.63793945312, "training_acc": 72.0, "val_loss": 30185.140991210938, "val_acc": 72.0}
{"epoch": 27, "training_loss": 116108.69262695312, "training_acc": 72.0, "val_loss": 20450.636291503906, "val_acc": 72.0}
{"epoch": 28, "training_loss": 70096.79748535156, "training_acc": 72.0, "val_loss": 1269.9685096740723, "val_acc": 72.0}
{"epoch": 29, "training_loss": 54842.0400390625, "training_acc": 48.0, "val_loss": 37448.10485839844, "val_acc": 28.0}
{"epoch": 30, "training_loss": 130033.55395507812, "training_acc": 28.0, "val_loss": 3613.7298583984375, "val_acc": 72.0}
{"epoch": 31, "training_loss": 28979.50830078125, "training_acc": 72.0, "val_loss": 16849.046325683594, "val_acc": 72.0}
{"epoch": 32, "training_loss": 67810.88134765625, "training_acc": 72.0, "val_loss": 15379.887390136719, "val_acc": 72.0}
{"epoch": 33, "training_loss": 52308.400390625, "training_acc": 72.0, "val_loss": 2376.194190979004, "val_acc": 72.0}
{"epoch": 34, "training_loss": 27033.677001953125, "training_acc": 64.0, "val_loss": 23402.792358398438, "val_acc": 28.0}
{"epoch": 35, "training_loss": 71056.3359375, "training_acc": 28.0, "val_loss": 10101.9287109375, "val_acc": 72.0}
{"epoch": 36, "training_loss": 52794.242919921875, "training_acc": 72.0, "val_loss": 24689.54315185547, "val_acc": 72.0}
{"epoch": 37, "training_loss": 99699.21899414062, "training_acc": 72.0, "val_loss": 24831.076049804688, "val_acc": 72.0}
