"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71352.70530319214, "training_acc": 47.0, "val_loss": 42026.37939453125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 125902.4306640625, "training_acc": 72.0, "val_loss": 34981.4453125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 123441.10229492188, "training_acc": 28.0, "val_loss": 9996.82388305664, "val_acc": 72.0}
{"epoch": 3, "training_loss": 52770.536376953125, "training_acc": 72.0, "val_loss": 23518.017578125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 91207.39892578125, "training_acc": 72.0, "val_loss": 13961.843872070312, "val_acc": 72.0}
{"epoch": 5, "training_loss": 38440.340911865234, "training_acc": 72.0, "val_loss": 35413.330078125, "val_acc": 28.0}
{"epoch": 6, "training_loss": 144835.64697265625, "training_acc": 28.0, "val_loss": 14077.107238769531, "val_acc": 28.0}
{"epoch": 7, "training_loss": 47288.70544433594, "training_acc": 48.0, "val_loss": 23526.46026611328, "val_acc": 72.0}
{"epoch": 8, "training_loss": 102996.73828125, "training_acc": 72.0, "val_loss": 33497.186279296875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 132587.97021484375, "training_acc": 72.0, "val_loss": 27845.88623046875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 99866.18017578125, "training_acc": 72.0, "val_loss": 8862.528228759766, "val_acc": 72.0}
{"epoch": 11, "training_loss": 39894.439208984375, "training_acc": 56.0, "val_loss": 18314.881896972656, "val_acc": 28.0}
{"epoch": 12, "training_loss": 49169.452087402344, "training_acc": 28.0, "val_loss": 13248.136901855469, "val_acc": 72.0}
{"epoch": 13, "training_loss": 66318.60961914062, "training_acc": 72.0, "val_loss": 27867.269897460938, "val_acc": 72.0}
{"epoch": 14, "training_loss": 114453.49072265625, "training_acc": 72.0, "val_loss": 27310.745239257812, "val_acc": 72.0}
{"epoch": 15, "training_loss": 101962.08178710938, "training_acc": 72.0, "val_loss": 13538.121032714844, "val_acc": 72.0}
{"epoch": 16, "training_loss": 37546.7392578125, "training_acc": 72.0, "val_loss": 25896.124267578125, "val_acc": 28.0}
{"epoch": 17, "training_loss": 116344.0732421875, "training_acc": 28.0, "val_loss": 19772.03826904297, "val_acc": 28.0}
{"epoch": 18, "training_loss": 57785.15264892578, "training_acc": 44.0, "val_loss": 13784.521484375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 63635.045654296875, "training_acc": 72.0, "val_loss": 19546.39434814453, "val_acc": 72.0}
{"epoch": 20, "training_loss": 74387.78588867188, "training_acc": 72.0, "val_loss": 11518.270111083984, "val_acc": 72.0}
{"epoch": 21, "training_loss": 36079.72592163086, "training_acc": 72.0, "val_loss": 19206.326293945312, "val_acc": 28.0}
{"epoch": 22, "training_loss": 80999.50048828125, "training_acc": 28.0, "val_loss": 3559.04541015625, "val_acc": 28.0}
{"epoch": 23, "training_loss": 22768.462768554688, "training_acc": 48.0, "val_loss": 22417.71240234375, "val_acc": 72.0}
{"epoch": 24, "training_loss": 96101.01049804688, "training_acc": 72.0, "val_loss": 30751.202392578125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 121663.09521484375, "training_acc": 72.0, "val_loss": 26078.546142578125, "val_acc": 72.0}
{"epoch": 26, "training_loss": 93536.78564453125, "training_acc": 72.0, "val_loss": 10401.876831054688, "val_acc": 72.0}
{"epoch": 27, "training_loss": 28766.002380371094, "training_acc": 58.0, "val_loss": 8567.90771484375, "val_acc": 28.0}
{"epoch": 28, "training_loss": 24317.807373046875, "training_acc": 46.0, "val_loss": 4483.534622192383, "val_acc": 72.0}
{"epoch": 29, "training_loss": 16236.794921875, "training_acc": 72.0, "val_loss": 1000.4886627197266, "val_acc": 32.0}
{"epoch": 30, "training_loss": 5294.042572021484, "training_acc": 52.0, "val_loss": 4892.615127563477, "val_acc": 72.0}
{"epoch": 31, "training_loss": 16980.02066040039, "training_acc": 72.0, "val_loss": 3091.00341796875, "val_acc": 28.0}
{"epoch": 32, "training_loss": 16715.60821533203, "training_acc": 32.0, "val_loss": 2880.714225769043, "val_acc": 72.0}
{"epoch": 33, "training_loss": 9013.647903442383, "training_acc": 57.0, "val_loss": 3563.76953125, "val_acc": 72.0}
{"epoch": 34, "training_loss": 15070.3427734375, "training_acc": 72.0, "val_loss": 1872.3718643188477, "val_acc": 72.0}
{"epoch": 35, "training_loss": 17184.039306640625, "training_acc": 54.0, "val_loss": 348.36483001708984, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1859.1551971435547, "training_acc": 83.0, "val_loss": 3120.332908630371, "val_acc": 72.0}
{"epoch": 37, "training_loss": 8703.281356811523, "training_acc": 72.0, "val_loss": 11102.925872802734, "val_acc": 28.0}
{"epoch": 38, "training_loss": 33144.61346435547, "training_acc": 28.0, "val_loss": 9333.158874511719, "val_acc": 72.0}
{"epoch": 39, "training_loss": 45619.326904296875, "training_acc": 72.0, "val_loss": 18908.351135253906, "val_acc": 72.0}
{"epoch": 40, "training_loss": 74963.0546875, "training_acc": 72.0, "val_loss": 14985.15625, "val_acc": 72.0}
{"epoch": 41, "training_loss": 50603.60900878906, "training_acc": 72.0, "val_loss": 736.5992069244385, "val_acc": 52.0}
{"epoch": 42, "training_loss": 10646.696166992188, "training_acc": 39.0, "val_loss": 2530.3049087524414, "val_acc": 72.0}
{"epoch": 43, "training_loss": 10670.241333007812, "training_acc": 72.0, "val_loss": 2607.0175170898438, "val_acc": 72.0}
{"epoch": 44, "training_loss": 10637.791015625, "training_acc": 56.0, "val_loss": 3056.3833236694336, "val_acc": 72.0}
{"epoch": 45, "training_loss": 12124.32339477539, "training_acc": 72.0, "val_loss": 1504.375171661377, "val_acc": 72.0}
{"epoch": 46, "training_loss": 10582.124572753906, "training_acc": 62.0, "val_loss": 734.3612670898438, "val_acc": 76.0}
{"epoch": 47, "training_loss": 2572.8208541870117, "training_acc": 74.0, "val_loss": 3859.024429321289, "val_acc": 28.0}
{"epoch": 48, "training_loss": 15892.908142089844, "training_acc": 44.0, "val_loss": 6172.7294921875, "val_acc": 72.0}
{"epoch": 49, "training_loss": 22656.53271484375, "training_acc": 72.0, "val_loss": 695.9845542907715, "val_acc": 76.0}
{"epoch": 50, "training_loss": 21445.45849609375, "training_acc": 60.0, "val_loss": 10177.783203125, "val_acc": 28.0}
{"epoch": 51, "training_loss": 35235.660888671875, "training_acc": 42.0, "val_loss": 10543.313598632812, "val_acc": 72.0}
{"epoch": 52, "training_loss": 44095.746337890625, "training_acc": 72.0, "val_loss": 10378.782653808594, "val_acc": 72.0}
{"epoch": 53, "training_loss": 35298.96887207031, "training_acc": 72.0, "val_loss": 3672.8805541992188, "val_acc": 28.0}
{"epoch": 54, "training_loss": 10520.136245727539, "training_acc": 42.0, "val_loss": 3798.019790649414, "val_acc": 72.0}
