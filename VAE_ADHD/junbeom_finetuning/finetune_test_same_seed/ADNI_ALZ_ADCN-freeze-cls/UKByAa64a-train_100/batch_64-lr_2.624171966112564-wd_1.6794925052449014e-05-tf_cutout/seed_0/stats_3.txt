"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4692.673645019531, "training_acc": 40.0, "val_loss": 2122.583770751953, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6475.274917602539, "training_acc": 72.0, "val_loss": 1806.5326690673828, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6447.982666015625, "training_acc": 30.0, "val_loss": 335.2468252182007, "val_acc": 68.0}
{"epoch": 3, "training_loss": 2073.4417266845703, "training_acc": 72.0, "val_loss": 1105.0055503845215, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3876.399124145508, "training_acc": 72.0, "val_loss": 568.5317039489746, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1634.6741256713867, "training_acc": 67.0, "val_loss": 918.629264831543, "val_acc": 48.0}
{"epoch": 6, "training_loss": 2915.03369140625, "training_acc": 52.0, "val_loss": 569.2429542541504, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1152.1943855285645, "training_acc": 72.0, "val_loss": 672.6630687713623, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2226.6103591918945, "training_acc": 72.0, "val_loss": 438.50550651550293, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1067.1010856628418, "training_acc": 74.0, "val_loss": 626.8477439880371, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1882.6418952941895, "training_acc": 55.0, "val_loss": 269.91472244262695, "val_acc": 72.0}
{"epoch": 11, "training_loss": 862.7230529785156, "training_acc": 68.0, "val_loss": 225.95057487487793, "val_acc": 76.0}
{"epoch": 12, "training_loss": 686.9025554656982, "training_acc": 70.0, "val_loss": 223.8612413406372, "val_acc": 56.0}
{"epoch": 13, "training_loss": 595.1982173919678, "training_acc": 62.0, "val_loss": 154.55143451690674, "val_acc": 72.0}
{"epoch": 14, "training_loss": 467.01925897598267, "training_acc": 75.0, "val_loss": 204.90992069244385, "val_acc": 36.0}
{"epoch": 15, "training_loss": 660.1122894287109, "training_acc": 59.0, "val_loss": 209.34545993804932, "val_acc": 72.0}
{"epoch": 16, "training_loss": 772.6004762649536, "training_acc": 63.0, "val_loss": 147.35018014907837, "val_acc": 36.0}
{"epoch": 17, "training_loss": 480.96064376831055, "training_acc": 61.0, "val_loss": 122.85702228546143, "val_acc": 72.0}
{"epoch": 18, "training_loss": 648.9060440063477, "training_acc": 64.0, "val_loss": 109.84311103820801, "val_acc": 56.0}
{"epoch": 19, "training_loss": 488.9526557922363, "training_acc": 68.0, "val_loss": 265.48380851745605, "val_acc": 72.0}
{"epoch": 20, "training_loss": 780.628978729248, "training_acc": 74.0, "val_loss": 387.42382526397705, "val_acc": 52.0}
{"epoch": 21, "training_loss": 1183.6808547973633, "training_acc": 53.0, "val_loss": 180.963134765625, "val_acc": 72.0}
{"epoch": 22, "training_loss": 646.7106704711914, "training_acc": 75.0, "val_loss": 242.19374656677246, "val_acc": 80.0}
{"epoch": 23, "training_loss": 728.3501834869385, "training_acc": 73.0, "val_loss": 328.4372806549072, "val_acc": 52.0}
{"epoch": 24, "training_loss": 757.9906997680664, "training_acc": 60.0, "val_loss": 199.74197149276733, "val_acc": 80.0}
{"epoch": 25, "training_loss": 820.4122934341431, "training_acc": 74.0, "val_loss": 95.49297094345093, "val_acc": 76.0}
{"epoch": 26, "training_loss": 610.6302719116211, "training_acc": 63.0, "val_loss": 57.91556239128113, "val_acc": 80.0}
{"epoch": 27, "training_loss": 618.8558120727539, "training_acc": 74.0, "val_loss": 143.15283298492432, "val_acc": 72.0}
{"epoch": 28, "training_loss": 456.3256139755249, "training_acc": 73.0, "val_loss": 289.5354747772217, "val_acc": 36.0}
{"epoch": 29, "training_loss": 486.6271638870239, "training_acc": 62.0, "val_loss": 118.3698296546936, "val_acc": 76.0}
{"epoch": 30, "training_loss": 377.7848801612854, "training_acc": 77.0, "val_loss": 263.85176181793213, "val_acc": 36.0}
{"epoch": 31, "training_loss": 559.0884590148926, "training_acc": 56.0, "val_loss": 141.3870334625244, "val_acc": 80.0}
{"epoch": 32, "training_loss": 481.7573833465576, "training_acc": 78.0, "val_loss": 342.9391145706177, "val_acc": 40.0}
{"epoch": 33, "training_loss": 821.1204452514648, "training_acc": 55.0, "val_loss": 171.79429531097412, "val_acc": 80.0}
{"epoch": 34, "training_loss": 865.229419708252, "training_acc": 74.0, "val_loss": 196.10824584960938, "val_acc": 80.0}
{"epoch": 35, "training_loss": 681.2379398345947, "training_acc": 72.0, "val_loss": 274.2828845977783, "val_acc": 52.0}
{"epoch": 36, "training_loss": 490.6767339706421, "training_acc": 71.0, "val_loss": 152.88374423980713, "val_acc": 76.0}
{"epoch": 37, "training_loss": 584.2703304290771, "training_acc": 77.0, "val_loss": 88.07401061058044, "val_acc": 80.0}
{"epoch": 38, "training_loss": 532.1442604064941, "training_acc": 69.0, "val_loss": 63.23903799057007, "val_acc": 76.0}
{"epoch": 39, "training_loss": 306.90662384033203, "training_acc": 76.0, "val_loss": 109.38987731933594, "val_acc": 76.0}
{"epoch": 40, "training_loss": 437.06129360198975, "training_acc": 72.0, "val_loss": 209.32939052581787, "val_acc": 44.0}
{"epoch": 41, "training_loss": 352.08358573913574, "training_acc": 64.0, "val_loss": 96.67057394981384, "val_acc": 76.0}
{"epoch": 42, "training_loss": 339.6219291687012, "training_acc": 74.0, "val_loss": 121.5437650680542, "val_acc": 48.0}
{"epoch": 43, "training_loss": 149.22110891342163, "training_acc": 80.0, "val_loss": 67.05220937728882, "val_acc": 80.0}
{"epoch": 44, "training_loss": 123.03794717788696, "training_acc": 85.0, "val_loss": 171.25310897827148, "val_acc": 48.0}
{"epoch": 45, "training_loss": 359.7495880126953, "training_acc": 64.0, "val_loss": 84.0699315071106, "val_acc": 80.0}
