"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6804.088115692139, "training_acc": 42.0, "val_loss": 3609.036636352539, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10923.108367919922, "training_acc": 72.0, "val_loss": 2309.9578857421875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8401.117462158203, "training_acc": 31.0, "val_loss": 631.8986892700195, "val_acc": 76.0}
{"epoch": 3, "training_loss": 3278.592727661133, "training_acc": 73.0, "val_loss": 1464.5378112792969, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4867.908279418945, "training_acc": 73.0, "val_loss": 860.9837532043457, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2738.4306640625, "training_acc": 65.0, "val_loss": 1430.9723854064941, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3652.9371185302734, "training_acc": 50.0, "val_loss": 899.3808746337891, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2541.5666885375977, "training_acc": 74.0, "val_loss": 1041.838264465332, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3217.129898071289, "training_acc": 71.0, "val_loss": 753.3766746520996, "val_acc": 68.0}
{"epoch": 9, "training_loss": 1649.7095184326172, "training_acc": 68.0, "val_loss": 865.7282829284668, "val_acc": 64.0}
{"epoch": 10, "training_loss": 2233.790351867676, "training_acc": 58.0, "val_loss": 576.6979694366455, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2430.8550720214844, "training_acc": 72.0, "val_loss": 406.9514751434326, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1418.275478363037, "training_acc": 64.0, "val_loss": 558.6526393890381, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1848.0976791381836, "training_acc": 48.0, "val_loss": 488.12689781188965, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1639.3892660140991, "training_acc": 73.0, "val_loss": 426.2951850891113, "val_acc": 48.0}
{"epoch": 15, "training_loss": 1325.5289993286133, "training_acc": 54.0, "val_loss": 323.484206199646, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1757.8002624511719, "training_acc": 72.0, "val_loss": 250.53622722625732, "val_acc": 76.0}
{"epoch": 17, "training_loss": 952.7875175476074, "training_acc": 72.0, "val_loss": 508.9076519012451, "val_acc": 36.0}
{"epoch": 18, "training_loss": 1074.8294973373413, "training_acc": 60.0, "val_loss": 435.9208106994629, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1542.732334136963, "training_acc": 72.0, "val_loss": 191.09293222427368, "val_acc": 56.0}
{"epoch": 20, "training_loss": 513.665246963501, "training_acc": 71.0, "val_loss": 137.4480128288269, "val_acc": 76.0}
{"epoch": 21, "training_loss": 735.1107559204102, "training_acc": 70.0, "val_loss": 164.96343612670898, "val_acc": 60.0}
{"epoch": 22, "training_loss": 542.8269100189209, "training_acc": 63.0, "val_loss": 235.0513458251953, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1130.6786842346191, "training_acc": 72.0, "val_loss": 104.50323820114136, "val_acc": 72.0}
{"epoch": 24, "training_loss": 948.3189239501953, "training_acc": 68.0, "val_loss": 132.1725606918335, "val_acc": 80.0}
{"epoch": 25, "training_loss": 594.9596900939941, "training_acc": 77.0, "val_loss": 256.1687469482422, "val_acc": 80.0}
{"epoch": 26, "training_loss": 874.9898843765259, "training_acc": 76.0, "val_loss": 351.4934539794922, "val_acc": 48.0}
{"epoch": 27, "training_loss": 665.0022420883179, "training_acc": 68.0, "val_loss": 366.4846658706665, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1644.7334785461426, "training_acc": 72.0, "val_loss": 142.71314144134521, "val_acc": 80.0}
{"epoch": 29, "training_loss": 1162.942512512207, "training_acc": 68.0, "val_loss": 208.71541500091553, "val_acc": 56.0}
{"epoch": 30, "training_loss": 796.5966835021973, "training_acc": 67.0, "val_loss": 361.97853088378906, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1159.1014652252197, "training_acc": 73.0, "val_loss": 693.3627605438232, "val_acc": 32.0}
{"epoch": 32, "training_loss": 1436.9860258102417, "training_acc": 53.0, "val_loss": 288.04359436035156, "val_acc": 80.0}
{"epoch": 33, "training_loss": 1546.6697540283203, "training_acc": 73.0, "val_loss": 248.9259958267212, "val_acc": 76.0}
{"epoch": 34, "training_loss": 838.7633380889893, "training_acc": 79.0, "val_loss": 497.9030132293701, "val_acc": 52.0}
{"epoch": 35, "training_loss": 1139.6994018554688, "training_acc": 61.0, "val_loss": 232.81137943267822, "val_acc": 80.0}
{"epoch": 36, "training_loss": 737.0656757354736, "training_acc": 79.0, "val_loss": 175.1995086669922, "val_acc": 68.0}
{"epoch": 37, "training_loss": 504.54270362854004, "training_acc": 74.0, "val_loss": 134.39414501190186, "val_acc": 80.0}
{"epoch": 38, "training_loss": 490.534649848938, "training_acc": 79.0, "val_loss": 114.34621810913086, "val_acc": 56.0}
{"epoch": 39, "training_loss": 251.9265308380127, "training_acc": 73.0, "val_loss": 255.962872505188, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1077.988338470459, "training_acc": 72.0, "val_loss": 71.80169224739075, "val_acc": 60.0}
{"epoch": 41, "training_loss": 330.86268615722656, "training_acc": 68.0, "val_loss": 156.72718286514282, "val_acc": 72.0}
{"epoch": 42, "training_loss": 735.7345886230469, "training_acc": 74.0, "val_loss": 107.82942771911621, "val_acc": 68.0}
{"epoch": 43, "training_loss": 642.8758201599121, "training_acc": 73.0, "val_loss": 121.82766199111938, "val_acc": 80.0}
{"epoch": 44, "training_loss": 551.6224918365479, "training_acc": 79.0, "val_loss": 143.29010248184204, "val_acc": 80.0}
{"epoch": 45, "training_loss": 710.8222923278809, "training_acc": 68.0, "val_loss": 143.68276596069336, "val_acc": 68.0}
{"epoch": 46, "training_loss": 612.7343940734863, "training_acc": 76.0, "val_loss": 210.36124229431152, "val_acc": 72.0}
{"epoch": 47, "training_loss": 571.1322650909424, "training_acc": 78.0, "val_loss": 301.7791748046875, "val_acc": 44.0}
{"epoch": 48, "training_loss": 767.634895324707, "training_acc": 59.0, "val_loss": 87.01553344726562, "val_acc": 80.0}
{"epoch": 49, "training_loss": 642.4906234741211, "training_acc": 66.0, "val_loss": 75.13374090194702, "val_acc": 80.0}
{"epoch": 50, "training_loss": 335.2091484069824, "training_acc": 81.0, "val_loss": 100.23391246795654, "val_acc": 76.0}
{"epoch": 51, "training_loss": 336.9721088409424, "training_acc": 77.0, "val_loss": 98.07317852973938, "val_acc": 80.0}
{"epoch": 52, "training_loss": 300.3791751861572, "training_acc": 83.0, "val_loss": 73.92561435699463, "val_acc": 80.0}
{"epoch": 53, "training_loss": 350.5463104248047, "training_acc": 74.0, "val_loss": 61.28439903259277, "val_acc": 80.0}
{"epoch": 54, "training_loss": 306.6446542739868, "training_acc": 80.0, "val_loss": 137.99046277999878, "val_acc": 56.0}
{"epoch": 55, "training_loss": 239.11958026885986, "training_acc": 77.0, "val_loss": 204.57065105438232, "val_acc": 72.0}
{"epoch": 56, "training_loss": 840.4629573822021, "training_acc": 73.0, "val_loss": 293.28105449676514, "val_acc": 40.0}
{"epoch": 57, "training_loss": 629.315258026123, "training_acc": 64.0, "val_loss": 395.9627628326416, "val_acc": 72.0}
{"epoch": 58, "training_loss": 1990.900405883789, "training_acc": 72.0, "val_loss": 323.90997409820557, "val_acc": 72.0}
{"epoch": 59, "training_loss": 1234.1912174224854, "training_acc": 68.0, "val_loss": 474.45225715637207, "val_acc": 48.0}
{"epoch": 60, "training_loss": 1331.545742034912, "training_acc": 60.0, "val_loss": 339.1115427017212, "val_acc": 80.0}
{"epoch": 61, "training_loss": 1058.1896362304688, "training_acc": 76.0, "val_loss": 349.13244247436523, "val_acc": 64.0}
{"epoch": 62, "training_loss": 780.2405490875244, "training_acc": 70.0, "val_loss": 189.4281268119812, "val_acc": 76.0}
{"epoch": 63, "training_loss": 446.4385986328125, "training_acc": 79.0, "val_loss": 114.51815366744995, "val_acc": 80.0}
{"epoch": 64, "training_loss": 163.82766914367676, "training_acc": 80.0, "val_loss": 114.36799764633179, "val_acc": 64.0}
{"epoch": 65, "training_loss": 203.86612606048584, "training_acc": 81.0, "val_loss": 49.147599935531616, "val_acc": 68.0}
{"epoch": 66, "training_loss": 681.5214881896973, "training_acc": 62.0, "val_loss": 94.1578209400177, "val_acc": 72.0}
{"epoch": 67, "training_loss": 408.24582862854004, "training_acc": 76.0, "val_loss": 237.09754943847656, "val_acc": 40.0}
{"epoch": 68, "training_loss": 439.9273042678833, "training_acc": 71.0, "val_loss": 134.39931869506836, "val_acc": 72.0}
{"epoch": 69, "training_loss": 509.9268798828125, "training_acc": 77.0, "val_loss": 185.3557825088501, "val_acc": 60.0}
{"epoch": 70, "training_loss": 411.8263511657715, "training_acc": 75.0, "val_loss": 125.53743124008179, "val_acc": 84.0}
{"epoch": 71, "training_loss": 368.14737939834595, "training_acc": 81.0, "val_loss": 159.66652631759644, "val_acc": 68.0}
{"epoch": 72, "training_loss": 309.51347064971924, "training_acc": 74.0, "val_loss": 107.84533023834229, "val_acc": 80.0}
{"epoch": 73, "training_loss": 216.40932273864746, "training_acc": 85.0, "val_loss": 383.1469535827637, "val_acc": 44.0}
{"epoch": 74, "training_loss": 789.4844875335693, "training_acc": 63.0, "val_loss": 171.79429531097412, "val_acc": 72.0}
{"epoch": 75, "training_loss": 522.9082865715027, "training_acc": 81.0, "val_loss": 324.3887186050415, "val_acc": 48.0}
{"epoch": 76, "training_loss": 471.53433895111084, "training_acc": 71.0, "val_loss": 128.5772204399109, "val_acc": 76.0}
{"epoch": 77, "training_loss": 386.4073066711426, "training_acc": 79.0, "val_loss": 237.04149723052979, "val_acc": 52.0}
{"epoch": 78, "training_loss": 653.5467853546143, "training_acc": 68.0, "val_loss": 70.92254757881165, "val_acc": 84.0}
{"epoch": 79, "training_loss": 233.86263418197632, "training_acc": 86.0, "val_loss": 227.95944213867188, "val_acc": 60.0}
{"epoch": 80, "training_loss": 525.4279441833496, "training_acc": 71.0, "val_loss": 275.0561237335205, "val_acc": 72.0}
{"epoch": 81, "training_loss": 759.2242736816406, "training_acc": 78.0, "val_loss": 483.14781188964844, "val_acc": 40.0}
{"epoch": 82, "training_loss": 972.0526058673859, "training_acc": 65.0, "val_loss": 212.79723644256592, "val_acc": 72.0}
{"epoch": 83, "training_loss": 853.0039596557617, "training_acc": 74.0, "val_loss": 117.77710914611816, "val_acc": 68.0}
{"epoch": 84, "training_loss": 373.6123752593994, "training_acc": 74.0, "val_loss": 109.45719480514526, "val_acc": 84.0}
