"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2540.3047523498535, "training_acc": 34.0, "val_loss": 800.8978843688965, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2421.628593444824, "training_acc": 72.0, "val_loss": 536.6077899932861, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2207.769630432129, "training_acc": 30.0, "val_loss": 101.91506147384644, "val_acc": 80.0}
{"epoch": 3, "training_loss": 570.3316631317139, "training_acc": 71.0, "val_loss": 546.067476272583, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2117.9254608154297, "training_acc": 72.0, "val_loss": 522.5903987884521, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1588.0694618225098, "training_acc": 72.0, "val_loss": 169.56335306167603, "val_acc": 76.0}
{"epoch": 6, "training_loss": 982.4578628540039, "training_acc": 58.0, "val_loss": 248.38414192199707, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1047.062692642212, "training_acc": 59.0, "val_loss": 226.59895420074463, "val_acc": 72.0}
{"epoch": 8, "training_loss": 842.2618217468262, "training_acc": 74.0, "val_loss": 328.1276226043701, "val_acc": 72.0}
{"epoch": 9, "training_loss": 731.8520431518555, "training_acc": 73.0, "val_loss": 156.66970014572144, "val_acc": 76.0}
{"epoch": 10, "training_loss": 651.0417156219482, "training_acc": 64.0, "val_loss": 134.1194748878479, "val_acc": 68.0}
{"epoch": 11, "training_loss": 535.6884231567383, "training_acc": 62.0, "val_loss": 182.21054077148438, "val_acc": 72.0}
{"epoch": 12, "training_loss": 497.5995235443115, "training_acc": 73.0, "val_loss": 96.68918251991272, "val_acc": 72.0}
{"epoch": 13, "training_loss": 211.59993648529053, "training_acc": 75.0, "val_loss": 117.96258687973022, "val_acc": 44.0}
{"epoch": 14, "training_loss": 339.1369700431824, "training_acc": 58.0, "val_loss": 134.55967903137207, "val_acc": 72.0}
{"epoch": 15, "training_loss": 363.2777237892151, "training_acc": 72.0, "val_loss": 102.11573839187622, "val_acc": 48.0}
{"epoch": 16, "training_loss": 348.59608364105225, "training_acc": 52.0, "val_loss": 78.81958484649658, "val_acc": 72.0}
{"epoch": 17, "training_loss": 170.57038235664368, "training_acc": 69.0, "val_loss": 53.34416627883911, "val_acc": 64.0}
{"epoch": 18, "training_loss": 76.00615572929382, "training_acc": 83.0, "val_loss": 44.194331765174866, "val_acc": 68.0}
{"epoch": 19, "training_loss": 88.45185971260071, "training_acc": 79.0, "val_loss": 39.076781272888184, "val_acc": 68.0}
{"epoch": 20, "training_loss": 61.59902787208557, "training_acc": 85.0, "val_loss": 43.27135682106018, "val_acc": 76.0}
{"epoch": 21, "training_loss": 67.73371815681458, "training_acc": 85.0, "val_loss": 21.404320001602173, "val_acc": 68.0}
{"epoch": 22, "training_loss": 92.27484369277954, "training_acc": 71.0, "val_loss": 36.2772673368454, "val_acc": 72.0}
{"epoch": 23, "training_loss": 166.40799617767334, "training_acc": 67.0, "val_loss": 88.65678310394287, "val_acc": 72.0}
{"epoch": 24, "training_loss": 305.9930830001831, "training_acc": 72.0, "val_loss": 23.98492395877838, "val_acc": 76.0}
{"epoch": 25, "training_loss": 168.3623685836792, "training_acc": 72.0, "val_loss": 36.03654503822327, "val_acc": 76.0}
{"epoch": 26, "training_loss": 116.69484615325928, "training_acc": 81.0, "val_loss": 40.45800566673279, "val_acc": 76.0}
{"epoch": 27, "training_loss": 185.17400550842285, "training_acc": 67.0, "val_loss": 50.94408392906189, "val_acc": 72.0}
{"epoch": 28, "training_loss": 208.61195182800293, "training_acc": 77.0, "val_loss": 86.85833811759949, "val_acc": 76.0}
{"epoch": 29, "training_loss": 161.4707534313202, "training_acc": 80.0, "val_loss": 52.044105529785156, "val_acc": 64.0}
{"epoch": 30, "training_loss": 230.98746538162231, "training_acc": 67.0, "val_loss": 112.65050172805786, "val_acc": 72.0}
{"epoch": 31, "training_loss": 233.31620526313782, "training_acc": 75.0, "val_loss": 44.7081595659256, "val_acc": 64.0}
{"epoch": 32, "training_loss": 151.65124464035034, "training_acc": 64.0, "val_loss": 105.19980192184448, "val_acc": 72.0}
{"epoch": 33, "training_loss": 269.66985034942627, "training_acc": 72.0, "val_loss": 46.11015319824219, "val_acc": 52.0}
{"epoch": 34, "training_loss": 103.58447408676147, "training_acc": 65.0, "val_loss": 38.121649622917175, "val_acc": 72.0}
{"epoch": 35, "training_loss": 44.87324559688568, "training_acc": 82.0, "val_loss": 27.19014286994934, "val_acc": 60.0}
{"epoch": 36, "training_loss": 51.32586193084717, "training_acc": 79.0, "val_loss": 22.41038978099823, "val_acc": 64.0}
{"epoch": 37, "training_loss": 32.72705686092377, "training_acc": 87.0, "val_loss": 17.72419363260269, "val_acc": 72.0}
{"epoch": 38, "training_loss": 28.20613443851471, "training_acc": 90.0, "val_loss": 18.47354620695114, "val_acc": 76.0}
{"epoch": 39, "training_loss": 24.74846464395523, "training_acc": 89.0, "val_loss": 16.60325527191162, "val_acc": 68.0}
{"epoch": 40, "training_loss": 113.34977960586548, "training_acc": 71.0, "val_loss": 57.81662464141846, "val_acc": 72.0}
{"epoch": 41, "training_loss": 271.3321132659912, "training_acc": 55.0, "val_loss": 85.72184443473816, "val_acc": 72.0}
{"epoch": 42, "training_loss": 291.36448669433594, "training_acc": 72.0, "val_loss": 34.695541858673096, "val_acc": 76.0}
{"epoch": 43, "training_loss": 266.7902774810791, "training_acc": 66.0, "val_loss": 25.857242941856384, "val_acc": 80.0}
{"epoch": 44, "training_loss": 154.24875736236572, "training_acc": 80.0, "val_loss": 138.89025449752808, "val_acc": 72.0}
{"epoch": 45, "training_loss": 290.2946038246155, "training_acc": 76.0, "val_loss": 94.58169341087341, "val_acc": 52.0}
{"epoch": 46, "training_loss": 392.4199357032776, "training_acc": 58.0, "val_loss": 90.70398211479187, "val_acc": 76.0}
{"epoch": 47, "training_loss": 198.32140636444092, "training_acc": 80.0, "val_loss": 64.32841420173645, "val_acc": 72.0}
{"epoch": 48, "training_loss": 190.32857418060303, "training_acc": 73.0, "val_loss": 42.12746024131775, "val_acc": 80.0}
{"epoch": 49, "training_loss": 129.25716638565063, "training_acc": 79.0, "val_loss": 72.56338596343994, "val_acc": 72.0}
{"epoch": 50, "training_loss": 105.75698018074036, "training_acc": 84.0, "val_loss": 39.86411988735199, "val_acc": 64.0}
{"epoch": 51, "training_loss": 136.80741214752197, "training_acc": 63.0, "val_loss": 75.26883482933044, "val_acc": 72.0}
{"epoch": 52, "training_loss": 213.5206174850464, "training_acc": 60.0, "val_loss": 63.1844699382782, "val_acc": 72.0}
{"epoch": 53, "training_loss": 116.11905121803284, "training_acc": 78.0, "val_loss": 24.15490597486496, "val_acc": 68.0}
{"epoch": 54, "training_loss": 49.972660183906555, "training_acc": 78.0, "val_loss": 57.53554701805115, "val_acc": 72.0}
{"epoch": 55, "training_loss": 117.77486324310303, "training_acc": 80.0, "val_loss": 38.39014768600464, "val_acc": 68.0}
{"epoch": 56, "training_loss": 86.8867437839508, "training_acc": 76.0, "val_loss": 60.99063158035278, "val_acc": 76.0}
{"epoch": 57, "training_loss": 80.38848134875298, "training_acc": 85.0, "val_loss": 45.575299859046936, "val_acc": 72.0}
{"epoch": 58, "training_loss": 72.50294041633606, "training_acc": 82.0, "val_loss": 32.37859308719635, "val_acc": 68.0}
