"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1854.384033203125, "training_acc": 43.0, "val_loss": 817.6164627075195, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2552.6219635009766, "training_acc": 72.0, "val_loss": 630.4498195648193, "val_acc": 32.0}
{"epoch": 2, "training_loss": 2842.2621688842773, "training_acc": 29.0, "val_loss": 159.47338342666626, "val_acc": 76.0}
{"epoch": 3, "training_loss": 804.0168228149414, "training_acc": 73.0, "val_loss": 633.4595203399658, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2209.4815559387207, "training_acc": 72.0, "val_loss": 559.532356262207, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1515.3580112457275, "training_acc": 72.0, "val_loss": 223.3121633529663, "val_acc": 68.0}
{"epoch": 6, "training_loss": 1073.160530090332, "training_acc": 62.0, "val_loss": 313.2039785385132, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1816.7209014892578, "training_acc": 47.0, "val_loss": 284.0202569961548, "val_acc": 72.0}
{"epoch": 8, "training_loss": 953.861255645752, "training_acc": 73.0, "val_loss": 543.8446998596191, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1697.1948890686035, "training_acc": 72.0, "val_loss": 448.08359146118164, "val_acc": 72.0}
{"epoch": 10, "training_loss": 947.7144870758057, "training_acc": 72.0, "val_loss": 181.33126497268677, "val_acc": 64.0}
{"epoch": 11, "training_loss": 947.2419624328613, "training_acc": 58.0, "val_loss": 176.3315200805664, "val_acc": 60.0}
{"epoch": 12, "training_loss": 731.9643993377686, "training_acc": 65.0, "val_loss": 200.8765459060669, "val_acc": 72.0}
{"epoch": 13, "training_loss": 603.9348697662354, "training_acc": 74.0, "val_loss": 168.30466985702515, "val_acc": 72.0}
{"epoch": 14, "training_loss": 426.3423128128052, "training_acc": 71.0, "val_loss": 131.49302005767822, "val_acc": 48.0}
{"epoch": 15, "training_loss": 457.9926586151123, "training_acc": 58.0, "val_loss": 155.26586771011353, "val_acc": 72.0}
{"epoch": 16, "training_loss": 619.4711275100708, "training_acc": 72.0, "val_loss": 191.6530966758728, "val_acc": 72.0}
{"epoch": 17, "training_loss": 645.4943084716797, "training_acc": 72.0, "val_loss": 136.31787300109863, "val_acc": 28.0}
{"epoch": 18, "training_loss": 436.6926670074463, "training_acc": 37.0, "val_loss": 120.56456804275513, "val_acc": 72.0}
{"epoch": 19, "training_loss": 612.9203815460205, "training_acc": 72.0, "val_loss": 172.37054109573364, "val_acc": 72.0}
{"epoch": 20, "training_loss": 475.7919387817383, "training_acc": 75.0, "val_loss": 109.54216718673706, "val_acc": 48.0}
{"epoch": 21, "training_loss": 618.4666767120361, "training_acc": 51.0, "val_loss": 71.46198153495789, "val_acc": 76.0}
{"epoch": 22, "training_loss": 320.13024711608887, "training_acc": 74.0, "val_loss": 183.12890529632568, "val_acc": 72.0}
{"epoch": 23, "training_loss": 512.9899587631226, "training_acc": 73.0, "val_loss": 61.60714030265808, "val_acc": 76.0}
{"epoch": 24, "training_loss": 302.00748920440674, "training_acc": 70.0, "val_loss": 52.35940217971802, "val_acc": 68.0}
{"epoch": 25, "training_loss": 235.93016147613525, "training_acc": 74.0, "val_loss": 88.56498599052429, "val_acc": 72.0}
{"epoch": 26, "training_loss": 247.75733947753906, "training_acc": 78.0, "val_loss": 32.550910115242004, "val_acc": 60.0}
{"epoch": 27, "training_loss": 192.31843948364258, "training_acc": 58.0, "val_loss": 55.01627326011658, "val_acc": 72.0}
{"epoch": 28, "training_loss": 245.1164674758911, "training_acc": 74.0, "val_loss": 11.949928104877472, "val_acc": 84.0}
{"epoch": 29, "training_loss": 154.65669441223145, "training_acc": 69.0, "val_loss": 18.25687140226364, "val_acc": 72.0}
{"epoch": 30, "training_loss": 116.53481149673462, "training_acc": 76.0, "val_loss": 26.036500930786133, "val_acc": 60.0}
{"epoch": 31, "training_loss": 101.69523596763611, "training_acc": 67.0, "val_loss": 19.104570150375366, "val_acc": 80.0}
{"epoch": 32, "training_loss": 86.57647943496704, "training_acc": 73.0, "val_loss": 47.10683226585388, "val_acc": 76.0}
{"epoch": 33, "training_loss": 125.88816690444946, "training_acc": 77.0, "val_loss": 42.674094438552856, "val_acc": 48.0}
{"epoch": 34, "training_loss": 144.60423839092255, "training_acc": 65.0, "val_loss": 59.62103009223938, "val_acc": 72.0}
{"epoch": 35, "training_loss": 111.14641118049622, "training_acc": 78.0, "val_loss": 69.64266896247864, "val_acc": 40.0}
{"epoch": 36, "training_loss": 195.69256854057312, "training_acc": 64.0, "val_loss": 80.62448501586914, "val_acc": 72.0}
{"epoch": 37, "training_loss": 191.28357696533203, "training_acc": 74.0, "val_loss": 80.27679324150085, "val_acc": 36.0}
{"epoch": 38, "training_loss": 254.03279161453247, "training_acc": 57.0, "val_loss": 102.00577974319458, "val_acc": 72.0}
{"epoch": 39, "training_loss": 265.01854181289673, "training_acc": 72.0, "val_loss": 32.71898925304413, "val_acc": 80.0}
{"epoch": 40, "training_loss": 160.9941053390503, "training_acc": 71.0, "val_loss": 44.75676715373993, "val_acc": 76.0}
{"epoch": 41, "training_loss": 82.20850396156311, "training_acc": 83.0, "val_loss": 68.86364817619324, "val_acc": 76.0}
{"epoch": 42, "training_loss": 116.80049061775208, "training_acc": 81.0, "val_loss": 55.08723258972168, "val_acc": 48.0}
{"epoch": 43, "training_loss": 206.87907457351685, "training_acc": 61.0, "val_loss": 80.08761405944824, "val_acc": 72.0}
{"epoch": 44, "training_loss": 191.89092540740967, "training_acc": 76.0, "val_loss": 65.03979563713074, "val_acc": 40.0}
{"epoch": 45, "training_loss": 211.68438160419464, "training_acc": 57.0, "val_loss": 55.394017696380615, "val_acc": 72.0}
{"epoch": 46, "training_loss": 121.25848954916, "training_acc": 79.0, "val_loss": 49.92756247520447, "val_acc": 48.0}
{"epoch": 47, "training_loss": 140.5252764225006, "training_acc": 71.0, "val_loss": 47.94714152812958, "val_acc": 72.0}
