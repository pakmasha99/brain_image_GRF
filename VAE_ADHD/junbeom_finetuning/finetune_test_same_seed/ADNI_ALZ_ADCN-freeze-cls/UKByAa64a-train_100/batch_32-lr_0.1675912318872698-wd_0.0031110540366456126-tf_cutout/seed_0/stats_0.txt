"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1400.9685974121094, "training_acc": 54.0, "val_loss": 180.2896499633789, "val_acc": 28.0}
{"epoch": 1, "training_loss": 640.6209487915039, "training_acc": 40.0, "val_loss": 125.24467706680298, "val_acc": 72.0}
{"epoch": 2, "training_loss": 660.1392478942871, "training_acc": 50.0, "val_loss": 55.526202917099, "val_acc": 28.0}
{"epoch": 3, "training_loss": 664.9900245666504, "training_acc": 54.0, "val_loss": 338.3065700531006, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1261.4187469482422, "training_acc": 72.0, "val_loss": 114.98123407363892, "val_acc": 72.0}
{"epoch": 5, "training_loss": 591.0574588775635, "training_acc": 38.0, "val_loss": 89.47620987892151, "val_acc": 72.0}
{"epoch": 6, "training_loss": 687.2416687011719, "training_acc": 72.0, "val_loss": 250.67412853240967, "val_acc": 72.0}
{"epoch": 7, "training_loss": 838.5795415128232, "training_acc": 72.0, "val_loss": 44.84708309173584, "val_acc": 28.0}
{"epoch": 8, "training_loss": 232.46804809570312, "training_acc": 42.0, "val_loss": 43.00061762332916, "val_acc": 72.0}
{"epoch": 9, "training_loss": 217.92879456281662, "training_acc": 44.0, "val_loss": 118.7166690826416, "val_acc": 72.0}
{"epoch": 10, "training_loss": 573.0353889465332, "training_acc": 72.0, "val_loss": 59.61557626724243, "val_acc": 72.0}
{"epoch": 11, "training_loss": 278.88293051719666, "training_acc": 48.0, "val_loss": 52.22069025039673, "val_acc": 72.0}
{"epoch": 12, "training_loss": 160.74679374694824, "training_acc": 70.0, "val_loss": 15.69949984550476, "val_acc": 72.0}
{"epoch": 13, "training_loss": 95.51763439178467, "training_acc": 70.0, "val_loss": 28.262516856193542, "val_acc": 72.0}
{"epoch": 14, "training_loss": 139.73577117919922, "training_acc": 70.0, "val_loss": 13.550321757793427, "val_acc": 68.0}
{"epoch": 15, "training_loss": 159.15872383117676, "training_acc": 75.0, "val_loss": 88.4033203125, "val_acc": 28.0}
{"epoch": 16, "training_loss": 299.70761322975113, "training_acc": 40.0, "val_loss": 135.95201969146729, "val_acc": 72.0}
{"epoch": 17, "training_loss": 490.60393344424665, "training_acc": 72.0, "val_loss": 36.76465451717377, "val_acc": 28.0}
{"epoch": 18, "training_loss": 119.03956258296967, "training_acc": 56.0, "val_loss": 27.401944994926453, "val_acc": 28.0}
{"epoch": 19, "training_loss": 69.95777249336243, "training_acc": 62.0, "val_loss": 69.60621476173401, "val_acc": 28.0}
{"epoch": 20, "training_loss": 146.0700068473816, "training_acc": 60.0, "val_loss": 12.260978668928146, "val_acc": 80.0}
{"epoch": 21, "training_loss": 110.25563430786133, "training_acc": 55.0, "val_loss": 44.32055950164795, "val_acc": 28.0}
{"epoch": 22, "training_loss": 117.71401871740818, "training_acc": 61.0, "val_loss": 17.813163995742798, "val_acc": 72.0}
{"epoch": 23, "training_loss": 142.75636863708496, "training_acc": 52.0, "val_loss": 34.10953879356384, "val_acc": 72.0}
{"epoch": 24, "training_loss": 100.58685231208801, "training_acc": 54.0, "val_loss": 18.975818157196045, "val_acc": 72.0}
{"epoch": 25, "training_loss": 133.67482089996338, "training_acc": 52.0, "val_loss": 19.356730580329895, "val_acc": 72.0}
{"epoch": 26, "training_loss": 99.50986123085022, "training_acc": 62.0, "val_loss": 16.644027829170227, "val_acc": 72.0}
{"epoch": 27, "training_loss": 127.70705560594797, "training_acc": 56.0, "val_loss": 40.48157334327698, "val_acc": 72.0}
{"epoch": 28, "training_loss": 129.59722757339478, "training_acc": 59.0, "val_loss": 43.621355295181274, "val_acc": 72.0}
{"epoch": 29, "training_loss": 163.6396086215973, "training_acc": 59.0, "val_loss": 41.04452133178711, "val_acc": 72.0}
{"epoch": 30, "training_loss": 143.9971296787262, "training_acc": 59.0, "val_loss": 24.183766543865204, "val_acc": 72.0}
{"epoch": 31, "training_loss": 70.84936857223511, "training_acc": 67.0, "val_loss": 112.06393241882324, "val_acc": 28.0}
{"epoch": 32, "training_loss": 322.39818000793457, "training_acc": 48.0, "val_loss": 176.8119215965271, "val_acc": 72.0}
{"epoch": 33, "training_loss": 639.0117239801621, "training_acc": 72.0, "val_loss": 12.562882900238037, "val_acc": 72.0}
{"epoch": 34, "training_loss": 149.62536096572876, "training_acc": 56.0, "val_loss": 22.131334245204926, "val_acc": 72.0}
{"epoch": 35, "training_loss": 89.90864805877209, "training_acc": 60.0, "val_loss": 26.790663599967957, "val_acc": 72.0}
{"epoch": 36, "training_loss": 81.86892533302307, "training_acc": 67.0, "val_loss": 24.14453476667404, "val_acc": 72.0}
{"epoch": 37, "training_loss": 109.20274829864502, "training_acc": 53.0, "val_loss": 34.8782479763031, "val_acc": 28.0}
{"epoch": 38, "training_loss": 186.5546054840088, "training_acc": 54.0, "val_loss": 52.21003293991089, "val_acc": 28.0}
{"epoch": 39, "training_loss": 165.92059767246246, "training_acc": 53.0, "val_loss": 25.28914213180542, "val_acc": 28.0}
