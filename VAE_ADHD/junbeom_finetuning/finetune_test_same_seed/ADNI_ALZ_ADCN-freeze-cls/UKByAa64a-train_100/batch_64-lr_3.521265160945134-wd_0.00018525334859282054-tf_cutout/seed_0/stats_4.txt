"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5328.707607269287, "training_acc": 72.0, "val_loss": 2555.519485473633, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7685.714775085449, "training_acc": 72.0, "val_loss": 3458.1958770751953, "val_acc": 28.0}
{"epoch": 2, "training_loss": 14816.632141113281, "training_acc": 28.0, "val_loss": 492.41185188293457, "val_acc": 60.0}
{"epoch": 3, "training_loss": 3487.702590942383, "training_acc": 55.0, "val_loss": 2321.590805053711, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9081.468994140625, "training_acc": 72.0, "val_loss": 2674.3574142456055, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8572.25650024414, "training_acc": 72.0, "val_loss": 1566.0491943359375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4174.974716186523, "training_acc": 72.0, "val_loss": 891.251277923584, "val_acc": 60.0}
{"epoch": 7, "training_loss": 5398.260437011719, "training_acc": 56.0, "val_loss": 955.5935859680176, "val_acc": 60.0}
{"epoch": 8, "training_loss": 5539.505584716797, "training_acc": 57.0, "val_loss": 1031.3188552856445, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2752.2205085754395, "training_acc": 76.0, "val_loss": 1697.0129013061523, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4927.272033691406, "training_acc": 72.0, "val_loss": 1424.100112915039, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3346.9358291625977, "training_acc": 75.0, "val_loss": 584.9246501922607, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2018.4108963012695, "training_acc": 73.0, "val_loss": 607.8107833862305, "val_acc": 56.0}
{"epoch": 13, "training_loss": 3154.4531326293945, "training_acc": 52.0, "val_loss": 526.8522262573242, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1522.2966690063477, "training_acc": 76.0, "val_loss": 518.6521530151367, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1005.3266830444336, "training_acc": 73.0, "val_loss": 383.61430168151855, "val_acc": 36.0}
{"epoch": 16, "training_loss": 1302.1374759674072, "training_acc": 54.0, "val_loss": 287.81402111053467, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1215.0721282958984, "training_acc": 72.0, "val_loss": 133.44279527664185, "val_acc": 44.0}
{"epoch": 18, "training_loss": 432.03300952911377, "training_acc": 55.0, "val_loss": 180.8551549911499, "val_acc": 72.0}
{"epoch": 19, "training_loss": 750.1022567749023, "training_acc": 72.0, "val_loss": 509.61742401123047, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1201.0959615707397, "training_acc": 53.0, "val_loss": 408.3503723144531, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1444.3514728546143, "training_acc": 72.0, "val_loss": 228.07438373565674, "val_acc": 76.0}
{"epoch": 22, "training_loss": 543.4692192077637, "training_acc": 77.0, "val_loss": 238.81988525390625, "val_acc": 64.0}
{"epoch": 23, "training_loss": 960.3926544189453, "training_acc": 64.0, "val_loss": 382.3441743850708, "val_acc": 72.0}
{"epoch": 24, "training_loss": 980.7708225250244, "training_acc": 78.0, "val_loss": 175.372052192688, "val_acc": 72.0}
{"epoch": 25, "training_loss": 784.2388038635254, "training_acc": 69.0, "val_loss": 152.24459171295166, "val_acc": 76.0}
{"epoch": 26, "training_loss": 562.9151878356934, "training_acc": 74.0, "val_loss": 100.35068988800049, "val_acc": 80.0}
{"epoch": 27, "training_loss": 727.7136344909668, "training_acc": 65.0, "val_loss": 62.62368559837341, "val_acc": 76.0}
{"epoch": 28, "training_loss": 279.21827030181885, "training_acc": 77.0, "val_loss": 34.44091081619263, "val_acc": 64.0}
{"epoch": 29, "training_loss": 209.6641321182251, "training_acc": 71.0, "val_loss": 23.28493893146515, "val_acc": 80.0}
{"epoch": 30, "training_loss": 176.11870956420898, "training_acc": 77.0, "val_loss": 43.60898435115814, "val_acc": 56.0}
{"epoch": 31, "training_loss": 384.96466064453125, "training_acc": 67.0, "val_loss": 32.22204148769379, "val_acc": 88.0}
{"epoch": 32, "training_loss": 308.36494064331055, "training_acc": 72.0, "val_loss": 329.94091510772705, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1370.5128288269043, "training_acc": 72.0, "val_loss": 240.98546504974365, "val_acc": 72.0}
{"epoch": 34, "training_loss": 943.5106086730957, "training_acc": 65.0, "val_loss": 99.3911862373352, "val_acc": 64.0}
{"epoch": 35, "training_loss": 594.0565795898438, "training_acc": 72.0, "val_loss": 351.547908782959, "val_acc": 72.0}
{"epoch": 36, "training_loss": 656.8058223724365, "training_acc": 76.0, "val_loss": 221.9684600830078, "val_acc": 48.0}
{"epoch": 37, "training_loss": 689.3920564651489, "training_acc": 64.0, "val_loss": 347.95641899108887, "val_acc": 72.0}
{"epoch": 38, "training_loss": 963.7793350219727, "training_acc": 76.0, "val_loss": 193.3340311050415, "val_acc": 76.0}
{"epoch": 39, "training_loss": 672.5841255187988, "training_acc": 71.0, "val_loss": 169.38692331314087, "val_acc": 76.0}
{"epoch": 40, "training_loss": 514.1417274475098, "training_acc": 80.0, "val_loss": 235.66555976867676, "val_acc": 76.0}
{"epoch": 41, "training_loss": 636.8420181274414, "training_acc": 73.0, "val_loss": 92.64451861381531, "val_acc": 76.0}
{"epoch": 42, "training_loss": 563.7986297607422, "training_acc": 75.0, "val_loss": 286.1501932144165, "val_acc": 72.0}
{"epoch": 43, "training_loss": 482.4079670906067, "training_acc": 76.0, "val_loss": 90.46182036399841, "val_acc": 64.0}
{"epoch": 44, "training_loss": 380.88757133483887, "training_acc": 68.0, "val_loss": 291.87560081481934, "val_acc": 72.0}
{"epoch": 45, "training_loss": 706.7565846443176, "training_acc": 75.0, "val_loss": 277.99434661865234, "val_acc": 32.0}
{"epoch": 46, "training_loss": 755.5471820831299, "training_acc": 58.0, "val_loss": 358.5095167160034, "val_acc": 72.0}
{"epoch": 47, "training_loss": 818.273853302002, "training_acc": 74.0, "val_loss": 175.31678676605225, "val_acc": 56.0}
{"epoch": 48, "training_loss": 757.7965469360352, "training_acc": 62.0, "val_loss": 259.11865234375, "val_acc": 76.0}
