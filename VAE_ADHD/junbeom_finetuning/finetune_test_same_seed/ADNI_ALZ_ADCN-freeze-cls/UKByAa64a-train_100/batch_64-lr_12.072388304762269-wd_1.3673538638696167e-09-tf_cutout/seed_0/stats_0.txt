"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19220.480785369873, "training_acc": 72.0, "val_loss": 8741.267395019531, "val_acc": 72.0}
{"epoch": 1, "training_loss": 23586.197723388672, "training_acc": 72.0, "val_loss": 13494.111633300781, "val_acc": 28.0}
{"epoch": 2, "training_loss": 56112.78662109375, "training_acc": 28.0, "val_loss": 2131.2097549438477, "val_acc": 36.0}
{"epoch": 3, "training_loss": 13833.979919433594, "training_acc": 52.0, "val_loss": 8209.477996826172, "val_acc": 72.0}
{"epoch": 4, "training_loss": 37084.85144042969, "training_acc": 72.0, "val_loss": 11001.646423339844, "val_acc": 72.0}
{"epoch": 5, "training_loss": 44048.87725830078, "training_acc": 72.0, "val_loss": 8520.050811767578, "val_acc": 72.0}
{"epoch": 6, "training_loss": 30504.37127685547, "training_acc": 72.0, "val_loss": 2757.5496673583984, "val_acc": 72.0}
{"epoch": 7, "training_loss": 13664.838989257812, "training_acc": 65.0, "val_loss": 3113.661766052246, "val_acc": 44.0}
{"epoch": 8, "training_loss": 20107.042114257812, "training_acc": 47.0, "val_loss": 1232.5984001159668, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9910.398559570312, "training_acc": 66.0, "val_loss": 2672.3581314086914, "val_acc": 72.0}
{"epoch": 10, "training_loss": 11481.728454589844, "training_acc": 72.0, "val_loss": 3527.2056579589844, "val_acc": 72.0}
{"epoch": 11, "training_loss": 11809.536651611328, "training_acc": 73.0, "val_loss": 790.5401229858398, "val_acc": 80.0}
{"epoch": 12, "training_loss": 6627.265350341797, "training_acc": 62.0, "val_loss": 1523.2741355895996, "val_acc": 60.0}
{"epoch": 13, "training_loss": 8006.815673828125, "training_acc": 60.0, "val_loss": 1437.8737449645996, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6344.361602783203, "training_acc": 73.0, "val_loss": 2247.720146179199, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5660.595779418945, "training_acc": 75.0, "val_loss": 1642.9746627807617, "val_acc": 44.0}
{"epoch": 16, "training_loss": 5896.374481201172, "training_acc": 43.0, "val_loss": 1219.119930267334, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4044.484100341797, "training_acc": 72.0, "val_loss": 1464.3346786499023, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2734.7332191467285, "training_acc": 73.0, "val_loss": 1913.2179260253906, "val_acc": 44.0}
{"epoch": 19, "training_loss": 5176.303771972656, "training_acc": 48.0, "val_loss": 1627.6691436767578, "val_acc": 72.0}
{"epoch": 20, "training_loss": 6202.955841064453, "training_acc": 72.0, "val_loss": 1847.121238708496, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4418.084007263184, "training_acc": 76.0, "val_loss": 1510.1080894470215, "val_acc": 52.0}
{"epoch": 22, "training_loss": 6327.866729736328, "training_acc": 46.0, "val_loss": 488.70320320129395, "val_acc": 80.0}
{"epoch": 23, "training_loss": 3657.9524536132812, "training_acc": 78.0, "val_loss": 1836.1583709716797, "val_acc": 72.0}
{"epoch": 24, "training_loss": 6123.637344360352, "training_acc": 75.0, "val_loss": 365.28053283691406, "val_acc": 80.0}
{"epoch": 25, "training_loss": 5193.917633056641, "training_acc": 66.0, "val_loss": 618.0000305175781, "val_acc": 68.0}
{"epoch": 26, "training_loss": 2448.7574462890625, "training_acc": 71.0, "val_loss": 1251.4178276062012, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3586.227638244629, "training_acc": 73.0, "val_loss": 841.0279273986816, "val_acc": 52.0}
{"epoch": 28, "training_loss": 2440.032012939453, "training_acc": 54.0, "val_loss": 1044.5314407348633, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3979.47802734375, "training_acc": 72.0, "val_loss": 530.1548957824707, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3721.6652221679688, "training_acc": 56.0, "val_loss": 401.62267684936523, "val_acc": 64.0}
{"epoch": 31, "training_loss": 3059.598175048828, "training_acc": 65.0, "val_loss": 1293.3110237121582, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2981.4742431640625, "training_acc": 76.0, "val_loss": 1296.7581748962402, "val_acc": 48.0}
{"epoch": 33, "training_loss": 3632.2625465393066, "training_acc": 56.0, "val_loss": 983.0325126647949, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3430.831573486328, "training_acc": 74.0, "val_loss": 571.8338489532471, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1871.7862930297852, "training_acc": 74.0, "val_loss": 1039.4402503967285, "val_acc": 52.0}
{"epoch": 36, "training_loss": 2511.7225456237793, "training_acc": 66.0, "val_loss": 1317.73042678833, "val_acc": 72.0}
{"epoch": 37, "training_loss": 4243.266159057617, "training_acc": 74.0, "val_loss": 266.4048910140991, "val_acc": 76.0}
{"epoch": 38, "training_loss": 2058.452346801758, "training_acc": 69.0, "val_loss": 676.2585163116455, "val_acc": 64.0}
{"epoch": 39, "training_loss": 2279.4753341674805, "training_acc": 72.0, "val_loss": 1129.47359085083, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2561.3888092041016, "training_acc": 79.0, "val_loss": 343.52078437805176, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1915.1160583496094, "training_acc": 74.0, "val_loss": 287.62049674987793, "val_acc": 84.0}
{"epoch": 42, "training_loss": 879.0525283813477, "training_acc": 85.0, "val_loss": 660.6723308563232, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1692.3302116394043, "training_acc": 70.0, "val_loss": 482.7946186065674, "val_acc": 72.0}
{"epoch": 44, "training_loss": 892.9556045532227, "training_acc": 79.0, "val_loss": 457.5213432312012, "val_acc": 64.0}
{"epoch": 45, "training_loss": 935.4817199707031, "training_acc": 74.0, "val_loss": 248.43122959136963, "val_acc": 72.0}
{"epoch": 46, "training_loss": 508.9693603515625, "training_acc": 77.0, "val_loss": 395.0774669647217, "val_acc": 72.0}
{"epoch": 47, "training_loss": 681.0568261146545, "training_acc": 84.0, "val_loss": 348.28431606292725, "val_acc": 64.0}
{"epoch": 48, "training_loss": 792.993782043457, "training_acc": 76.0, "val_loss": 679.9798965454102, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1878.387710571289, "training_acc": 76.0, "val_loss": 263.4812355041504, "val_acc": 68.0}
{"epoch": 50, "training_loss": 870.7851638793945, "training_acc": 76.0, "val_loss": 339.45372104644775, "val_acc": 68.0}
{"epoch": 51, "training_loss": 767.0919617414474, "training_acc": 83.0, "val_loss": 471.7532157897949, "val_acc": 56.0}
{"epoch": 52, "training_loss": 1175.1037368774414, "training_acc": 72.0, "val_loss": 549.1093635559082, "val_acc": 72.0}
{"epoch": 53, "training_loss": 1343.1800498962402, "training_acc": 71.0, "val_loss": 157.3103904724121, "val_acc": 84.0}
{"epoch": 54, "training_loss": 333.3364715576172, "training_acc": 88.0, "val_loss": 200.1943826675415, "val_acc": 76.0}
{"epoch": 55, "training_loss": 475.3072175979614, "training_acc": 83.0, "val_loss": 271.869421005249, "val_acc": 72.0}
{"epoch": 56, "training_loss": 380.7037229537964, "training_acc": 90.0, "val_loss": 318.0471181869507, "val_acc": 68.0}
{"epoch": 57, "training_loss": 519.3352088928223, "training_acc": 84.0, "val_loss": 331.19359016418457, "val_acc": 68.0}
{"epoch": 58, "training_loss": 570.9596652984619, "training_acc": 84.0, "val_loss": 232.71262645721436, "val_acc": 72.0}
{"epoch": 59, "training_loss": 254.89492225646973, "training_acc": 85.0, "val_loss": 256.15763664245605, "val_acc": 68.0}
{"epoch": 60, "training_loss": 585.7939338684082, "training_acc": 80.0, "val_loss": 240.51594734191895, "val_acc": 72.0}
{"epoch": 61, "training_loss": 438.0479612350464, "training_acc": 85.0, "val_loss": 175.78771114349365, "val_acc": 84.0}
{"epoch": 62, "training_loss": 685.8720817565918, "training_acc": 83.0, "val_loss": 192.80927181243896, "val_acc": 76.0}
{"epoch": 63, "training_loss": 570.8559532165527, "training_acc": 85.0, "val_loss": 147.47495651245117, "val_acc": 80.0}
{"epoch": 64, "training_loss": 1042.1426162719727, "training_acc": 73.0, "val_loss": 1240.1997566223145, "val_acc": 72.0}
{"epoch": 65, "training_loss": 4972.3048095703125, "training_acc": 72.0, "val_loss": 742.5888538360596, "val_acc": 72.0}
{"epoch": 66, "training_loss": 5752.816558837891, "training_acc": 52.0, "val_loss": 446.65255546569824, "val_acc": 56.0}
{"epoch": 67, "training_loss": 2970.234573364258, "training_acc": 65.0, "val_loss": 3627.5115966796875, "val_acc": 72.0}
{"epoch": 68, "training_loss": 13077.871520996094, "training_acc": 72.0, "val_loss": 2606.2973022460938, "val_acc": 72.0}
{"epoch": 69, "training_loss": 6711.160987854004, "training_acc": 75.0, "val_loss": 2120.486259460449, "val_acc": 40.0}
{"epoch": 70, "training_loss": 10467.50033569336, "training_acc": 34.0, "val_loss": 1548.6430168151855, "val_acc": 72.0}
{"epoch": 71, "training_loss": 8336.156982421875, "training_acc": 75.0, "val_loss": 4143.000030517578, "val_acc": 72.0}
{"epoch": 72, "training_loss": 14329.229568481445, "training_acc": 72.0, "val_loss": 1722.9669570922852, "val_acc": 72.0}
{"epoch": 73, "training_loss": 3000.6598892211914, "training_acc": 82.0, "val_loss": 2581.45694732666, "val_acc": 48.0}
{"epoch": 74, "training_loss": 12897.510345458984, "training_acc": 40.0, "val_loss": 857.8803062438965, "val_acc": 76.0}
{"epoch": 75, "training_loss": 5476.073059082031, "training_acc": 77.0, "val_loss": 3432.193374633789, "val_acc": 72.0}
{"epoch": 76, "training_loss": 10541.392059326172, "training_acc": 72.0, "val_loss": 1026.1872291564941, "val_acc": 72.0}
{"epoch": 77, "training_loss": 3653.011947631836, "training_acc": 78.0, "val_loss": 2129.065704345703, "val_acc": 56.0}
{"epoch": 78, "training_loss": 8381.414558410645, "training_acc": 55.0, "val_loss": 1060.46724319458, "val_acc": 72.0}
{"epoch": 79, "training_loss": 3320.455711364746, "training_acc": 77.0, "val_loss": 1469.4337844848633, "val_acc": 72.0}
{"epoch": 80, "training_loss": 2272.560827255249, "training_acc": 80.0, "val_loss": 1439.3593788146973, "val_acc": 52.0}
{"epoch": 81, "training_loss": 4154.401044845581, "training_acc": 60.0, "val_loss": 1313.970947265625, "val_acc": 72.0}
{"epoch": 82, "training_loss": 2937.836639404297, "training_acc": 77.0, "val_loss": 940.3204917907715, "val_acc": 72.0}
