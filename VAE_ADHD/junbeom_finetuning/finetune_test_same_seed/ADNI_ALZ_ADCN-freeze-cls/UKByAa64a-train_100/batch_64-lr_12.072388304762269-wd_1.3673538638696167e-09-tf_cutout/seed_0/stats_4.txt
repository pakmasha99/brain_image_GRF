"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 16771.153999328613, "training_acc": 68.0, "val_loss": 9100.939178466797, "val_acc": 72.0}
{"epoch": 1, "training_loss": 27116.151611328125, "training_acc": 72.0, "val_loss": 10188.357543945312, "val_acc": 28.0}
{"epoch": 2, "training_loss": 44732.0390625, "training_acc": 29.0, "val_loss": 1476.3676643371582, "val_acc": 64.0}
{"epoch": 3, "training_loss": 9816.402770996094, "training_acc": 61.0, "val_loss": 8510.205078125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 33099.02209472656, "training_acc": 72.0, "val_loss": 9726.824188232422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 33021.32653808594, "training_acc": 72.0, "val_loss": 5944.006729125977, "val_acc": 72.0}
{"epoch": 6, "training_loss": 14269.395080566406, "training_acc": 73.0, "val_loss": 2943.3645248413086, "val_acc": 60.0}
{"epoch": 7, "training_loss": 22014.662719726562, "training_acc": 46.0, "val_loss": 3306.9690704345703, "val_acc": 52.0}
{"epoch": 8, "training_loss": 18909.197265625, "training_acc": 48.0, "val_loss": 3840.716552734375, "val_acc": 72.0}
{"epoch": 9, "training_loss": 11265.704803466797, "training_acc": 73.0, "val_loss": 6154.072952270508, "val_acc": 72.0}
{"epoch": 10, "training_loss": 19109.636352539062, "training_acc": 72.0, "val_loss": 4194.068145751953, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8266.658111572266, "training_acc": 72.0, "val_loss": 1940.657615661621, "val_acc": 64.0}
{"epoch": 12, "training_loss": 11428.380187988281, "training_acc": 61.0, "val_loss": 2134.5605850219727, "val_acc": 52.0}
{"epoch": 13, "training_loss": 10624.669647216797, "training_acc": 56.0, "val_loss": 2831.953811645508, "val_acc": 72.0}
{"epoch": 14, "training_loss": 10024.022003173828, "training_acc": 72.0, "val_loss": 3235.5953216552734, "val_acc": 72.0}
{"epoch": 15, "training_loss": 9006.993103027344, "training_acc": 72.0, "val_loss": 897.096061706543, "val_acc": 60.0}
{"epoch": 16, "training_loss": 6382.206878662109, "training_acc": 51.0, "val_loss": 622.6954936981201, "val_acc": 60.0}
{"epoch": 17, "training_loss": 2782.4251556396484, "training_acc": 74.0, "val_loss": 1632.9397201538086, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6240.684310913086, "training_acc": 72.0, "val_loss": 504.4486999511719, "val_acc": 60.0}
{"epoch": 19, "training_loss": 2135.167869567871, "training_acc": 59.0, "val_loss": 272.81811237335205, "val_acc": 68.0}
{"epoch": 20, "training_loss": 1927.4240264892578, "training_acc": 72.0, "val_loss": 379.8051357269287, "val_acc": 60.0}
{"epoch": 21, "training_loss": 1121.7207336425781, "training_acc": 68.0, "val_loss": 481.54101371765137, "val_acc": 76.0}
{"epoch": 22, "training_loss": 1637.3037185668945, "training_acc": 75.0, "val_loss": 594.4664001464844, "val_acc": 52.0}
{"epoch": 23, "training_loss": 2041.4314346313477, "training_acc": 62.0, "val_loss": 727.9944896697998, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2054.593551635742, "training_acc": 75.0, "val_loss": 792.5238609313965, "val_acc": 44.0}
{"epoch": 25, "training_loss": 2604.432441711426, "training_acc": 53.0, "val_loss": 530.110502243042, "val_acc": 76.0}
{"epoch": 26, "training_loss": 1548.0414123535156, "training_acc": 70.0, "val_loss": 506.2800407409668, "val_acc": 76.0}
{"epoch": 27, "training_loss": 1378.6795043945312, "training_acc": 78.0, "val_loss": 515.275764465332, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1628.174877166748, "training_acc": 63.0, "val_loss": 802.0195960998535, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2054.1000213623047, "training_acc": 75.0, "val_loss": 620.4108715057373, "val_acc": 48.0}
{"epoch": 30, "training_loss": 1940.7635803222656, "training_acc": 65.0, "val_loss": 640.3224945068359, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1342.6119346618652, "training_acc": 78.0, "val_loss": 921.1047172546387, "val_acc": 32.0}
{"epoch": 32, "training_loss": 2467.644338607788, "training_acc": 58.0, "val_loss": 686.9343280792236, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1680.7149195671082, "training_acc": 78.0, "val_loss": 583.192777633667, "val_acc": 44.0}
{"epoch": 34, "training_loss": 2123.0905685424805, "training_acc": 58.0, "val_loss": 855.4216384887695, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2094.2311096191406, "training_acc": 77.0, "val_loss": 283.26568603515625, "val_acc": 68.0}
{"epoch": 36, "training_loss": 1235.939998626709, "training_acc": 71.0, "val_loss": 389.5282745361328, "val_acc": 76.0}
{"epoch": 37, "training_loss": 567.291784286499, "training_acc": 81.0, "val_loss": 419.208288192749, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2620.857452392578, "training_acc": 62.0, "val_loss": 547.9302883148193, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1677.667709350586, "training_acc": 67.0, "val_loss": 140.8103585243225, "val_acc": 76.0}
{"epoch": 40, "training_loss": 715.8610000610352, "training_acc": 85.0, "val_loss": 267.9579734802246, "val_acc": 76.0}
{"epoch": 41, "training_loss": 2309.219253540039, "training_acc": 63.0, "val_loss": 441.9303894042969, "val_acc": 76.0}
{"epoch": 42, "training_loss": 1470.0463981628418, "training_acc": 77.0, "val_loss": 258.02953243255615, "val_acc": 80.0}
{"epoch": 43, "training_loss": 2115.1796875, "training_acc": 67.0, "val_loss": 657.5916767120361, "val_acc": 76.0}
{"epoch": 44, "training_loss": 2002.2434158325195, "training_acc": 78.0, "val_loss": 797.6446151733398, "val_acc": 76.0}
{"epoch": 45, "training_loss": 1706.340232849121, "training_acc": 72.0, "val_loss": 610.8034610748291, "val_acc": 48.0}
{"epoch": 46, "training_loss": 2137.369815826416, "training_acc": 67.0, "val_loss": 1223.7603187561035, "val_acc": 72.0}
{"epoch": 47, "training_loss": 2698.122688293457, "training_acc": 75.0, "val_loss": 562.6176834106445, "val_acc": 52.0}
{"epoch": 48, "training_loss": 2063.398292541504, "training_acc": 62.0, "val_loss": 787.6982688903809, "val_acc": 76.0}
{"epoch": 49, "training_loss": 2191.518394470215, "training_acc": 79.0, "val_loss": 594.1622257232666, "val_acc": 76.0}
{"epoch": 50, "training_loss": 2277.1234741210938, "training_acc": 67.0, "val_loss": 419.9842929840088, "val_acc": 76.0}
{"epoch": 51, "training_loss": 1301.2488327026367, "training_acc": 77.0, "val_loss": 189.53113555908203, "val_acc": 76.0}
{"epoch": 52, "training_loss": 511.10561752319336, "training_acc": 82.0, "val_loss": 437.3586177825928, "val_acc": 72.0}
{"epoch": 53, "training_loss": 856.1338882446289, "training_acc": 84.0, "val_loss": 222.94111251831055, "val_acc": 80.0}
{"epoch": 54, "training_loss": 796.9731369018555, "training_acc": 74.0, "val_loss": 700.0146389007568, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1653.4996871948242, "training_acc": 77.0, "val_loss": 334.82818603515625, "val_acc": 84.0}
{"epoch": 56, "training_loss": 1718.2530364990234, "training_acc": 77.0, "val_loss": 322.0668315887451, "val_acc": 80.0}
{"epoch": 57, "training_loss": 1277.6725006103516, "training_acc": 80.0, "val_loss": 903.3711433410645, "val_acc": 76.0}
{"epoch": 58, "training_loss": 1519.1294574737549, "training_acc": 79.0, "val_loss": 349.9913454055786, "val_acc": 68.0}
