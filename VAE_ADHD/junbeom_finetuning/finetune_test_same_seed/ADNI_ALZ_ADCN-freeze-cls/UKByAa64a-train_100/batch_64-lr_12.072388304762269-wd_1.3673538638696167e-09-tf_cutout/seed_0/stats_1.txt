"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 17217.272930145264, "training_acc": 56.0, "val_loss": 9839.134216308594, "val_acc": 72.0}
{"epoch": 1, "training_loss": 28161.34390258789, "training_acc": 72.0, "val_loss": 11803.679656982422, "val_acc": 28.0}
{"epoch": 2, "training_loss": 44185.76330566406, "training_acc": 30.0, "val_loss": 1103.3604621887207, "val_acc": 64.0}
{"epoch": 3, "training_loss": 11325.611145019531, "training_acc": 67.0, "val_loss": 7338.396453857422, "val_acc": 72.0}
{"epoch": 4, "training_loss": 28464.084594726562, "training_acc": 72.0, "val_loss": 6988.5650634765625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 24464.662475585938, "training_acc": 72.0, "val_loss": 2125.0940322875977, "val_acc": 76.0}
{"epoch": 6, "training_loss": 11120.513702392578, "training_acc": 60.0, "val_loss": 5075.735092163086, "val_acc": 48.0}
{"epoch": 7, "training_loss": 17547.96923828125, "training_acc": 44.0, "val_loss": 1183.7239265441895, "val_acc": 68.0}
{"epoch": 8, "training_loss": 8065.57568359375, "training_acc": 73.0, "val_loss": 4187.791061401367, "val_acc": 72.0}
{"epoch": 9, "training_loss": 16912.99005126953, "training_acc": 72.0, "val_loss": 3351.786422729492, "val_acc": 72.0}
{"epoch": 10, "training_loss": 11091.184112548828, "training_acc": 72.0, "val_loss": 1987.3449325561523, "val_acc": 60.0}
{"epoch": 11, "training_loss": 10593.939270019531, "training_acc": 48.0, "val_loss": 2372.1803665161133, "val_acc": 56.0}
{"epoch": 12, "training_loss": 6387.561698913574, "training_acc": 62.0, "val_loss": 2252.805519104004, "val_acc": 72.0}
{"epoch": 13, "training_loss": 9926.753845214844, "training_acc": 72.0, "val_loss": 2445.353889465332, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7377.996208190918, "training_acc": 72.0, "val_loss": 1788.7531280517578, "val_acc": 44.0}
{"epoch": 15, "training_loss": 8005.20361328125, "training_acc": 42.0, "val_loss": 537.8291606903076, "val_acc": 68.0}
{"epoch": 16, "training_loss": 5062.665374755859, "training_acc": 74.0, "val_loss": 3032.586097717285, "val_acc": 72.0}
{"epoch": 17, "training_loss": 10505.332275390625, "training_acc": 72.0, "val_loss": 1352.7658462524414, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3916.5413360595703, "training_acc": 71.0, "val_loss": 3639.2688751220703, "val_acc": 36.0}
{"epoch": 19, "training_loss": 11398.468231201172, "training_acc": 38.0, "val_loss": 843.2262420654297, "val_acc": 76.0}
{"epoch": 20, "training_loss": 4897.486053466797, "training_acc": 74.0, "val_loss": 2141.341209411621, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5861.142578125, "training_acc": 73.0, "val_loss": 859.853458404541, "val_acc": 64.0}
{"epoch": 22, "training_loss": 4449.6759033203125, "training_acc": 64.0, "val_loss": 1255.6286811828613, "val_acc": 52.0}
{"epoch": 23, "training_loss": 3830.686637878418, "training_acc": 65.0, "val_loss": 1632.6032638549805, "val_acc": 72.0}
{"epoch": 24, "training_loss": 5353.830871582031, "training_acc": 72.0, "val_loss": 770.1282978057861, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2727.524215698242, "training_acc": 72.0, "val_loss": 1119.8932647705078, "val_acc": 48.0}
{"epoch": 26, "training_loss": 2698.866641998291, "training_acc": 72.0, "val_loss": 1042.9365158081055, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2844.473388671875, "training_acc": 74.0, "val_loss": 560.7170104980469, "val_acc": 56.0}
{"epoch": 28, "training_loss": 1504.9845962524414, "training_acc": 67.0, "val_loss": 700.1893043518066, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1148.2366943359375, "training_acc": 83.0, "val_loss": 700.4948139190674, "val_acc": 72.0}
{"epoch": 30, "training_loss": 722.3803615570068, "training_acc": 84.0, "val_loss": 985.0124359130859, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1212.6282663345337, "training_acc": 74.0, "val_loss": 659.7140789031982, "val_acc": 76.0}
{"epoch": 32, "training_loss": 1137.1382369995117, "training_acc": 76.0, "val_loss": 538.4714126586914, "val_acc": 60.0}
{"epoch": 33, "training_loss": 225.3112497329712, "training_acc": 88.0, "val_loss": 576.6135215759277, "val_acc": 72.0}
{"epoch": 34, "training_loss": 401.7716808319092, "training_acc": 87.0, "val_loss": 743.42942237854, "val_acc": 48.0}
