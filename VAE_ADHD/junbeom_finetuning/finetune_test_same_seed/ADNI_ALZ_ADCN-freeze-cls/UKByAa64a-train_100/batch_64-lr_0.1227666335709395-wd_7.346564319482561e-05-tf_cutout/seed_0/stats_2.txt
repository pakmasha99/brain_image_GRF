"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 265.2519950866699, "training_acc": 59.0, "val_loss": 91.22250080108643, "val_acc": 72.0}
{"epoch": 1, "training_loss": 261.80006074905396, "training_acc": 72.0, "val_loss": 104.73867654800415, "val_acc": 28.0}
{"epoch": 2, "training_loss": 439.00729751586914, "training_acc": 28.0, "val_loss": 17.829519510269165, "val_acc": 60.0}
{"epoch": 3, "training_loss": 104.59135675430298, "training_acc": 68.0, "val_loss": 75.22216439247131, "val_acc": 72.0}
{"epoch": 4, "training_loss": 294.99800395965576, "training_acc": 72.0, "val_loss": 79.91555333137512, "val_acc": 72.0}
{"epoch": 5, "training_loss": 258.92999839782715, "training_acc": 72.0, "val_loss": 36.31952702999115, "val_acc": 76.0}
{"epoch": 6, "training_loss": 123.76177072525024, "training_acc": 69.0, "val_loss": 45.31974792480469, "val_acc": 44.0}
{"epoch": 7, "training_loss": 238.71321487426758, "training_acc": 46.0, "val_loss": 29.820427298545837, "val_acc": 52.0}
{"epoch": 8, "training_loss": 155.55935907363892, "training_acc": 65.0, "val_loss": 40.24837017059326, "val_acc": 72.0}
{"epoch": 9, "training_loss": 127.61280584335327, "training_acc": 73.0, "val_loss": 45.688629150390625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 130.88996505737305, "training_acc": 74.0, "val_loss": 23.364730179309845, "val_acc": 76.0}
{"epoch": 11, "training_loss": 82.69030857086182, "training_acc": 72.0, "val_loss": 25.221720337867737, "val_acc": 56.0}
{"epoch": 12, "training_loss": 106.59526467323303, "training_acc": 61.0, "val_loss": 19.352558255195618, "val_acc": 76.0}
{"epoch": 13, "training_loss": 67.45485258102417, "training_acc": 76.0, "val_loss": 28.690752387046814, "val_acc": 72.0}
{"epoch": 14, "training_loss": 85.20774841308594, "training_acc": 72.0, "val_loss": 15.062645077705383, "val_acc": 72.0}
{"epoch": 15, "training_loss": 56.92646908760071, "training_acc": 67.0, "val_loss": 18.18530261516571, "val_acc": 52.0}
{"epoch": 16, "training_loss": 71.62104487419128, "training_acc": 55.0, "val_loss": 18.59615594148636, "val_acc": 72.0}
{"epoch": 17, "training_loss": 57.55939078330994, "training_acc": 72.0, "val_loss": 14.943759143352509, "val_acc": 60.0}
{"epoch": 18, "training_loss": 54.005414724349976, "training_acc": 72.0, "val_loss": 14.79523479938507, "val_acc": 52.0}
{"epoch": 19, "training_loss": 48.374515771865845, "training_acc": 77.0, "val_loss": 16.950106620788574, "val_acc": 72.0}
{"epoch": 20, "training_loss": 49.28492510318756, "training_acc": 72.0, "val_loss": 13.809917867183685, "val_acc": 76.0}
{"epoch": 21, "training_loss": 48.85447871685028, "training_acc": 76.0, "val_loss": 13.884754478931427, "val_acc": 76.0}
{"epoch": 22, "training_loss": 43.873262882232666, "training_acc": 85.0, "val_loss": 15.728966891765594, "val_acc": 72.0}
{"epoch": 23, "training_loss": 46.26443648338318, "training_acc": 82.0, "val_loss": 14.226555824279785, "val_acc": 76.0}
{"epoch": 24, "training_loss": 48.16212999820709, "training_acc": 79.0, "val_loss": 13.901732861995697, "val_acc": 76.0}
{"epoch": 25, "training_loss": 47.38882505893707, "training_acc": 77.0, "val_loss": 16.071030497550964, "val_acc": 68.0}
{"epoch": 26, "training_loss": 43.882139682769775, "training_acc": 80.0, "val_loss": 13.496071100234985, "val_acc": 76.0}
{"epoch": 27, "training_loss": 47.032936453819275, "training_acc": 80.0, "val_loss": 14.041070640087128, "val_acc": 72.0}
{"epoch": 28, "training_loss": 41.32942235469818, "training_acc": 83.0, "val_loss": 14.788126945495605, "val_acc": 72.0}
{"epoch": 29, "training_loss": 43.80365872383118, "training_acc": 79.0, "val_loss": 13.280275464057922, "val_acc": 68.0}
{"epoch": 30, "training_loss": 41.49906313419342, "training_acc": 87.0, "val_loss": 13.337400555610657, "val_acc": 68.0}
{"epoch": 31, "training_loss": 42.05872702598572, "training_acc": 83.0, "val_loss": 15.262427926063538, "val_acc": 72.0}
{"epoch": 32, "training_loss": 44.37443780899048, "training_acc": 77.0, "val_loss": 13.29611986875534, "val_acc": 60.0}
{"epoch": 33, "training_loss": 43.44664263725281, "training_acc": 80.0, "val_loss": 13.332085311412811, "val_acc": 68.0}
{"epoch": 34, "training_loss": 41.00320625305176, "training_acc": 87.0, "val_loss": 14.17301595211029, "val_acc": 72.0}
{"epoch": 35, "training_loss": 40.34260594844818, "training_acc": 81.0, "val_loss": 13.658249378204346, "val_acc": 68.0}
{"epoch": 36, "training_loss": 38.54631793498993, "training_acc": 89.0, "val_loss": 14.174720644950867, "val_acc": 68.0}
{"epoch": 37, "training_loss": 37.99504625797272, "training_acc": 84.0, "val_loss": 14.407600462436676, "val_acc": 68.0}
{"epoch": 38, "training_loss": 40.07811892032623, "training_acc": 84.0, "val_loss": 13.726608455181122, "val_acc": 68.0}
{"epoch": 39, "training_loss": 41.97421455383301, "training_acc": 81.0, "val_loss": 14.768478274345398, "val_acc": 68.0}
{"epoch": 40, "training_loss": 39.437644958496094, "training_acc": 81.0, "val_loss": 14.194174110889435, "val_acc": 68.0}
{"epoch": 41, "training_loss": 41.122387290000916, "training_acc": 84.0, "val_loss": 13.539674878120422, "val_acc": 68.0}
{"epoch": 42, "training_loss": 38.036956667900085, "training_acc": 85.0, "val_loss": 14.018397033214569, "val_acc": 68.0}
{"epoch": 43, "training_loss": 38.79350709915161, "training_acc": 83.0, "val_loss": 13.819029927253723, "val_acc": 68.0}
{"epoch": 44, "training_loss": 37.62080526351929, "training_acc": 84.0, "val_loss": 14.318917691707611, "val_acc": 68.0}
{"epoch": 45, "training_loss": 37.63673400878906, "training_acc": 82.0, "val_loss": 15.807953476905823, "val_acc": 68.0}
{"epoch": 46, "training_loss": 43.05327248573303, "training_acc": 79.0, "val_loss": 13.870033621788025, "val_acc": 68.0}
{"epoch": 47, "training_loss": 43.28029477596283, "training_acc": 84.0, "val_loss": 14.039349555969238, "val_acc": 68.0}
{"epoch": 48, "training_loss": 38.92792320251465, "training_acc": 86.0, "val_loss": 15.556122362613678, "val_acc": 72.0}
