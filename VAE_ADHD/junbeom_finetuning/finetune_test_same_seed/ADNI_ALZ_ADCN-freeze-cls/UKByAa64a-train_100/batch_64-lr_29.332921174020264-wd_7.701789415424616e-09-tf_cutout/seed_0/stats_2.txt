"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 138077.2011795044, "training_acc": 42.0, "val_loss": 73728.076171875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 244988.25073242188, "training_acc": 72.0, "val_loss": 59339.75830078125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 201890.66259765625, "training_acc": 28.0, "val_loss": 22231.796264648438, "val_acc": 72.0}
{"epoch": 3, "training_loss": 126648.2744140625, "training_acc": 72.0, "val_loss": 51635.015869140625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 201790.04833984375, "training_acc": 72.0, "val_loss": 36739.58435058594, "val_acc": 72.0}
{"epoch": 5, "training_loss": 119144.74536132812, "training_acc": 72.0, "val_loss": 20078.253173828125, "val_acc": 28.0}
{"epoch": 6, "training_loss": 88980.85400390625, "training_acc": 28.0, "val_loss": 8440.36636352539, "val_acc": 72.0}
{"epoch": 7, "training_loss": 44884.375244140625, "training_acc": 72.0, "val_loss": 19533.401489257812, "val_acc": 72.0}
{"epoch": 8, "training_loss": 70420.10083007812, "training_acc": 72.0, "val_loss": 3352.1873474121094, "val_acc": 72.0}
{"epoch": 9, "training_loss": 50905.009765625, "training_acc": 60.0, "val_loss": 28603.500366210938, "val_acc": 28.0}
{"epoch": 10, "training_loss": 84125.29486083984, "training_acc": 42.0, "val_loss": 14796.434020996094, "val_acc": 72.0}
{"epoch": 11, "training_loss": 63814.699951171875, "training_acc": 72.0, "val_loss": 12437.090301513672, "val_acc": 72.0}
{"epoch": 12, "training_loss": 32260.413330078125, "training_acc": 72.0, "val_loss": 36395.892333984375, "val_acc": 28.0}
{"epoch": 13, "training_loss": 142694.423828125, "training_acc": 28.0, "val_loss": 2382.4506759643555, "val_acc": 72.0}
{"epoch": 14, "training_loss": 18894.0234375, "training_acc": 72.0, "val_loss": 12629.33578491211, "val_acc": 72.0}
{"epoch": 15, "training_loss": 43995.07116699219, "training_acc": 72.0, "val_loss": 716.6523456573486, "val_acc": 40.0}
{"epoch": 16, "training_loss": 15282.448120117188, "training_acc": 38.0, "val_loss": 3851.251983642578, "val_acc": 72.0}
{"epoch": 17, "training_loss": 21529.332885742188, "training_acc": 58.0, "val_loss": 3443.568801879883, "val_acc": 72.0}
{"epoch": 18, "training_loss": 15852.707885742188, "training_acc": 72.0, "val_loss": 604.079008102417, "val_acc": 44.0}
{"epoch": 19, "training_loss": 13879.65869140625, "training_acc": 49.0, "val_loss": 4069.068145751953, "val_acc": 72.0}
{"epoch": 20, "training_loss": 19954.904418945312, "training_acc": 58.0, "val_loss": 4372.055435180664, "val_acc": 72.0}
{"epoch": 21, "training_loss": 16311.322662353516, "training_acc": 72.0, "val_loss": 886.6806030273438, "val_acc": 72.0}
{"epoch": 22, "training_loss": 18194.609741210938, "training_acc": 68.0, "val_loss": 609.4900608062744, "val_acc": 52.0}
{"epoch": 23, "training_loss": 23487.662841796875, "training_acc": 57.0, "val_loss": 20501.487731933594, "val_acc": 72.0}
{"epoch": 24, "training_loss": 81640.89868164062, "training_acc": 72.0, "val_loss": 15769.212341308594, "val_acc": 72.0}
{"epoch": 25, "training_loss": 46215.493713378906, "training_acc": 72.0, "val_loss": 25383.311462402344, "val_acc": 28.0}
{"epoch": 26, "training_loss": 99154.93603515625, "training_acc": 28.0, "val_loss": 5712.141418457031, "val_acc": 72.0}
{"epoch": 27, "training_loss": 41229.161376953125, "training_acc": 72.0, "val_loss": 15145.878601074219, "val_acc": 72.0}
{"epoch": 28, "training_loss": 51360.40197753906, "training_acc": 72.0, "val_loss": 1680.4853439331055, "val_acc": 28.0}
{"epoch": 29, "training_loss": 9104.650421142578, "training_acc": 46.0, "val_loss": 3139.899253845215, "val_acc": 72.0}
{"epoch": 30, "training_loss": 17305.085571289062, "training_acc": 56.0, "val_loss": 5658.551788330078, "val_acc": 72.0}
{"epoch": 31, "training_loss": 23317.306518554688, "training_acc": 72.0, "val_loss": 4504.917907714844, "val_acc": 72.0}
{"epoch": 32, "training_loss": 21866.066040039062, "training_acc": 58.0, "val_loss": 2782.326889038086, "val_acc": 72.0}
{"epoch": 33, "training_loss": 9105.890716552734, "training_acc": 72.0, "val_loss": 5005.818176269531, "val_acc": 28.0}
{"epoch": 34, "training_loss": 24344.339477539062, "training_acc": 44.0, "val_loss": 10588.735961914062, "val_acc": 72.0}
{"epoch": 35, "training_loss": 36345.004821777344, "training_acc": 72.0, "val_loss": 688.950252532959, "val_acc": 72.0}
{"epoch": 36, "training_loss": 3128.9354705810547, "training_acc": 63.0, "val_loss": 2335.2611541748047, "val_acc": 72.0}
{"epoch": 37, "training_loss": 11268.158874511719, "training_acc": 52.0, "val_loss": 10086.189270019531, "val_acc": 72.0}
