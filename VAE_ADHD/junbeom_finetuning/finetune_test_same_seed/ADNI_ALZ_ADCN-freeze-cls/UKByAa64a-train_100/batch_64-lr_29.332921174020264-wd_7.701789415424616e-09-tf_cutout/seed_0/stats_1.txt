"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 100334.005859375, "training_acc": 72.0, "val_loss": 72431.15234375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 220896.49243164062, "training_acc": 72.0, "val_loss": 95641.12548828125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 340602.8876953125, "training_acc": 28.0, "val_loss": 10739.635467529297, "val_acc": 72.0}
{"epoch": 3, "training_loss": 81904.7705078125, "training_acc": 72.0, "val_loss": 36059.05456542969, "val_acc": 72.0}
{"epoch": 4, "training_loss": 135360.34326171875, "training_acc": 72.0, "val_loss": 15209.133911132812, "val_acc": 72.0}
{"epoch": 5, "training_loss": 76204.25854492188, "training_acc": 52.0, "val_loss": 11500.69808959961, "val_acc": 28.0}
{"epoch": 6, "training_loss": 43112.08801269531, "training_acc": 50.0, "val_loss": 29007.748413085938, "val_acc": 72.0}
{"epoch": 7, "training_loss": 121445.91796875, "training_acc": 72.0, "val_loss": 30806.573486328125, "val_acc": 72.0}
{"epoch": 8, "training_loss": 108453.18798828125, "training_acc": 72.0, "val_loss": 6373.346710205078, "val_acc": 72.0}
{"epoch": 9, "training_loss": 79890.376953125, "training_acc": 52.0, "val_loss": 40994.82727050781, "val_acc": 28.0}
{"epoch": 10, "training_loss": 107539.25207519531, "training_acc": 28.0, "val_loss": 27205.349731445312, "val_acc": 72.0}
{"epoch": 11, "training_loss": 136414.9931640625, "training_acc": 72.0, "val_loss": 58488.922119140625, "val_acc": 72.0}
{"epoch": 12, "training_loss": 245989.1162109375, "training_acc": 72.0, "val_loss": 61843.37158203125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 236793.720703125, "training_acc": 72.0, "val_loss": 39880.93566894531, "val_acc": 72.0}
{"epoch": 14, "training_loss": 138284.5986328125, "training_acc": 72.0, "val_loss": 217.79744625091553, "val_acc": 76.0}
{"epoch": 15, "training_loss": 91280.27862548828, "training_acc": 56.0, "val_loss": 63119.879150390625, "val_acc": 28.0}
{"epoch": 16, "training_loss": 209250.75244140625, "training_acc": 28.0, "val_loss": 12514.165496826172, "val_acc": 72.0}
{"epoch": 17, "training_loss": 73188.08837890625, "training_acc": 72.0, "val_loss": 38065.60974121094, "val_acc": 72.0}
{"epoch": 18, "training_loss": 156735.83447265625, "training_acc": 72.0, "val_loss": 37665.89050292969, "val_acc": 72.0}
{"epoch": 19, "training_loss": 135257.30419921875, "training_acc": 72.0, "val_loss": 15357.962036132812, "val_acc": 72.0}
{"epoch": 20, "training_loss": 48331.0302734375, "training_acc": 58.0, "val_loss": 14812.356567382812, "val_acc": 28.0}
{"epoch": 21, "training_loss": 43547.049255371094, "training_acc": 46.0, "val_loss": 10957.942199707031, "val_acc": 72.0}
{"epoch": 22, "training_loss": 42224.60546875, "training_acc": 72.0, "val_loss": 4070.906448364258, "val_acc": 72.0}
{"epoch": 23, "training_loss": 28497.380859375, "training_acc": 60.0, "val_loss": 3640.7196044921875, "val_acc": 28.0}
{"epoch": 24, "training_loss": 35199.063720703125, "training_acc": 42.0, "val_loss": 26788.104248046875, "val_acc": 72.0}
{"epoch": 25, "training_loss": 114462.36962890625, "training_acc": 72.0, "val_loss": 28668.951416015625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 103680.44995117188, "training_acc": 72.0, "val_loss": 7860.539245605469, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59341.34814453125, "training_acc": 52.0, "val_loss": 24454.661560058594, "val_acc": 28.0}
{"epoch": 28, "training_loss": 55889.146575927734, "training_acc": 56.0, "val_loss": 10931.841278076172, "val_acc": 72.0}
{"epoch": 29, "training_loss": 46898.39306640625, "training_acc": 72.0, "val_loss": 9865.337371826172, "val_acc": 72.0}
{"epoch": 30, "training_loss": 28422.74654006958, "training_acc": 75.0, "val_loss": 26510.397338867188, "val_acc": 28.0}
{"epoch": 31, "training_loss": 90360.66357421875, "training_acc": 28.0, "val_loss": 11476.222229003906, "val_acc": 72.0}
{"epoch": 32, "training_loss": 55606.593017578125, "training_acc": 72.0, "val_loss": 26243.569946289062, "val_acc": 72.0}
{"epoch": 33, "training_loss": 103043.0087890625, "training_acc": 72.0, "val_loss": 18547.018432617188, "val_acc": 72.0}
