"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 100473.72499847412, "training_acc": 48.0, "val_loss": 77494.53735351562, "val_acc": 72.0}
{"epoch": 1, "training_loss": 252052.42822265625, "training_acc": 72.0, "val_loss": 66495.25756835938, "val_acc": 28.0}
{"epoch": 2, "training_loss": 221276.4072265625, "training_acc": 28.0, "val_loss": 23470.497131347656, "val_acc": 72.0}
{"epoch": 3, "training_loss": 127494.37353515625, "training_acc": 72.0, "val_loss": 52242.138671875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 203777.24365234375, "training_acc": 72.0, "val_loss": 36259.42077636719, "val_acc": 72.0}
{"epoch": 5, "training_loss": 116037.81298828125, "training_acc": 72.0, "val_loss": 26597.198486328125, "val_acc": 28.0}
{"epoch": 6, "training_loss": 105190.31762695312, "training_acc": 28.0, "val_loss": 6883.808135986328, "val_acc": 72.0}
{"epoch": 7, "training_loss": 36680.06677246094, "training_acc": 72.0, "val_loss": 14627.854919433594, "val_acc": 72.0}
{"epoch": 8, "training_loss": 48304.49353027344, "training_acc": 72.0, "val_loss": 13111.714172363281, "val_acc": 28.0}
{"epoch": 9, "training_loss": 33428.96016407013, "training_acc": 49.0, "val_loss": 2910.267448425293, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5792.173976898193, "training_acc": 76.0, "val_loss": 5910.734176635742, "val_acc": 28.0}
{"epoch": 11, "training_loss": 34681.2314453125, "training_acc": 42.0, "val_loss": 18145.440673828125, "val_acc": 72.0}
{"epoch": 12, "training_loss": 70385.93725585938, "training_acc": 72.0, "val_loss": 10059.888458251953, "val_acc": 72.0}
{"epoch": 13, "training_loss": 34643.35241699219, "training_acc": 56.0, "val_loss": 2418.975830078125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7729.602813720703, "training_acc": 72.0, "val_loss": 17046.91619873047, "val_acc": 28.0}
{"epoch": 15, "training_loss": 43659.653648376465, "training_acc": 46.0, "val_loss": 2252.8139114379883, "val_acc": 72.0}
{"epoch": 16, "training_loss": 8814.825164794922, "training_acc": 62.0, "val_loss": 8874.192810058594, "val_acc": 72.0}
{"epoch": 17, "training_loss": 40425.787109375, "training_acc": 72.0, "val_loss": 9314.835357666016, "val_acc": 72.0}
{"epoch": 18, "training_loss": 25082.877437591553, "training_acc": 70.0, "val_loss": 13438.604736328125, "val_acc": 28.0}
{"epoch": 19, "training_loss": 41355.932861328125, "training_acc": 44.0, "val_loss": 8316.740417480469, "val_acc": 72.0}
{"epoch": 20, "training_loss": 28594.470947265625, "training_acc": 72.0, "val_loss": 7068.880462646484, "val_acc": 28.0}
{"epoch": 21, "training_loss": 21542.247802734375, "training_acc": 48.0, "val_loss": 4407.167053222656, "val_acc": 72.0}
{"epoch": 22, "training_loss": 10457.665428161621, "training_acc": 64.0, "val_loss": 1655.6808471679688, "val_acc": 72.0}
{"epoch": 23, "training_loss": 5260.840637207031, "training_acc": 66.0, "val_loss": 9090.49072265625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 38181.494384765625, "training_acc": 72.0, "val_loss": 8933.943176269531, "val_acc": 72.0}
{"epoch": 25, "training_loss": 23833.3999710083, "training_acc": 71.0, "val_loss": 15338.613891601562, "val_acc": 28.0}
{"epoch": 26, "training_loss": 44053.667907714844, "training_acc": 44.0, "val_loss": 6039.103317260742, "val_acc": 72.0}
{"epoch": 27, "training_loss": 18709.00902557373, "training_acc": 72.0, "val_loss": 17058.224487304688, "val_acc": 28.0}
{"epoch": 28, "training_loss": 42004.022064208984, "training_acc": 51.0, "val_loss": 7838.648986816406, "val_acc": 72.0}
{"epoch": 29, "training_loss": 30996.360961914062, "training_acc": 72.0, "val_loss": 3400.104522705078, "val_acc": 72.0}
{"epoch": 30, "training_loss": 45218.080078125, "training_acc": 48.0, "val_loss": 2575.7396697998047, "val_acc": 28.0}
{"epoch": 31, "training_loss": 35374.355224609375, "training_acc": 44.0, "val_loss": 33390.863037109375, "val_acc": 72.0}
{"epoch": 32, "training_loss": 144323.67236328125, "training_acc": 72.0, "val_loss": 39503.64685058594, "val_acc": 72.0}
{"epoch": 33, "training_loss": 147371.5283203125, "training_acc": 72.0, "val_loss": 20885.438537597656, "val_acc": 72.0}
{"epoch": 34, "training_loss": 54521.47052001953, "training_acc": 72.0, "val_loss": 42521.27380371094, "val_acc": 28.0}
{"epoch": 35, "training_loss": 179739.8173828125, "training_acc": 28.0, "val_loss": 23159.109497070312, "val_acc": 28.0}
{"epoch": 36, "training_loss": 73057.44079589844, "training_acc": 48.0, "val_loss": 30331.463623046875, "val_acc": 72.0}
{"epoch": 37, "training_loss": 132963.734375, "training_acc": 72.0, "val_loss": 41737.005615234375, "val_acc": 72.0}
{"epoch": 38, "training_loss": 160294.87890625, "training_acc": 72.0, "val_loss": 28704.348754882812, "val_acc": 72.0}
{"epoch": 39, "training_loss": 96582.73352050781, "training_acc": 72.0, "val_loss": 8833.049011230469, "val_acc": 28.0}
{"epoch": 40, "training_loss": 49839.30322265625, "training_acc": 28.0, "val_loss": 8865.245819091797, "val_acc": 72.0}
{"epoch": 41, "training_loss": 47724.072509765625, "training_acc": 72.0, "val_loss": 19103.579711914062, "val_acc": 72.0}
