"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 15771.927589416504, "training_acc": 60.0, "val_loss": 2972.5149154663086, "val_acc": 28.0}
{"epoch": 1, "training_loss": 6148.339813232422, "training_acc": 58.0, "val_loss": 3967.790985107422, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11156.956970214844, "training_acc": 40.0, "val_loss": 1764.3877029418945, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5918.384761810303, "training_acc": 52.0, "val_loss": 1788.473129272461, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10526.58447265625, "training_acc": 72.0, "val_loss": 3477.4192810058594, "val_acc": 72.0}
{"epoch": 5, "training_loss": 10109.182273864746, "training_acc": 72.0, "val_loss": 2873.1340408325195, "val_acc": 28.0}
{"epoch": 6, "training_loss": 11850.432540893555, "training_acc": 30.0, "val_loss": 2058.183479309082, "val_acc": 72.0}
{"epoch": 7, "training_loss": 9293.191528320312, "training_acc": 72.0, "val_loss": 2155.3823471069336, "val_acc": 72.0}
{"epoch": 8, "training_loss": 5658.835632324219, "training_acc": 70.0, "val_loss": 2480.4201126098633, "val_acc": 28.0}
{"epoch": 9, "training_loss": 4467.2266845703125, "training_acc": 52.0, "val_loss": 4175.657653808594, "val_acc": 72.0}
{"epoch": 10, "training_loss": 18328.526611328125, "training_acc": 72.0, "val_loss": 3775.383758544922, "val_acc": 72.0}
{"epoch": 11, "training_loss": 10180.768615722656, "training_acc": 68.0, "val_loss": 3061.1244201660156, "val_acc": 28.0}
{"epoch": 12, "training_loss": 5832.48974609375, "training_acc": 52.0, "val_loss": 3689.5103454589844, "val_acc": 72.0}
{"epoch": 13, "training_loss": 17091.372314453125, "training_acc": 72.0, "val_loss": 3015.0245666503906, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7364.594665527344, "training_acc": 60.0, "val_loss": 1191.142749786377, "val_acc": 28.0}
{"epoch": 15, "training_loss": 5524.533630371094, "training_acc": 60.0, "val_loss": 2264.522361755371, "val_acc": 72.0}
{"epoch": 16, "training_loss": 5599.363586425781, "training_acc": 72.0, "val_loss": 2400.707244873047, "val_acc": 28.0}
{"epoch": 17, "training_loss": 7289.551116943359, "training_acc": 36.0, "val_loss": 3247.2442626953125, "val_acc": 72.0}
{"epoch": 18, "training_loss": 12995.3681640625, "training_acc": 72.0, "val_loss": 1639.1450881958008, "val_acc": 72.0}
{"epoch": 19, "training_loss": 5696.130187988281, "training_acc": 56.0, "val_loss": 86.42699718475342, "val_acc": 68.0}
{"epoch": 20, "training_loss": 1871.175765991211, "training_acc": 75.0, "val_loss": 364.02037143707275, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1455.8394012451172, "training_acc": 62.0, "val_loss": 315.00656604766846, "val_acc": 72.0}
{"epoch": 22, "training_loss": 603.484522819519, "training_acc": 75.0, "val_loss": 145.06666660308838, "val_acc": 32.0}
{"epoch": 23, "training_loss": 2574.7064361572266, "training_acc": 55.0, "val_loss": 88.37655186653137, "val_acc": 76.0}
{"epoch": 24, "training_loss": 1629.9861488342285, "training_acc": 64.0, "val_loss": 76.594078540802, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1669.5654754638672, "training_acc": 57.0, "val_loss": 523.8436698913574, "val_acc": 28.0}
{"epoch": 26, "training_loss": 936.6664671897888, "training_acc": 55.0, "val_loss": 1678.9358139038086, "val_acc": 28.0}
{"epoch": 27, "training_loss": 5156.1463623046875, "training_acc": 42.0, "val_loss": 2686.1040115356445, "val_acc": 72.0}
{"epoch": 28, "training_loss": 11285.130249023438, "training_acc": 72.0, "val_loss": 1425.6101608276367, "val_acc": 72.0}
{"epoch": 29, "training_loss": 5878.564483642578, "training_acc": 62.0, "val_loss": 1860.5010986328125, "val_acc": 28.0}
{"epoch": 30, "training_loss": 6088.6575927734375, "training_acc": 62.0, "val_loss": 2789.742088317871, "val_acc": 72.0}
{"epoch": 31, "training_loss": 8083.837831735727, "training_acc": 74.0, "val_loss": 2663.5759353637695, "val_acc": 28.0}
{"epoch": 32, "training_loss": 6503.451469421387, "training_acc": 46.0, "val_loss": 1212.4018669128418, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3485.5347938537598, "training_acc": 72.0, "val_loss": 782.1533203125, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2949.5689697265625, "training_acc": 60.0, "val_loss": 945.8181381225586, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4135.700820922852, "training_acc": 52.0, "val_loss": 901.4686584472656, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4246.542175292969, "training_acc": 72.0, "val_loss": 341.30680561065674, "val_acc": 72.0}
{"epoch": 37, "training_loss": 4359.848899841309, "training_acc": 44.0, "val_loss": 1442.752742767334, "val_acc": 72.0}
{"epoch": 38, "training_loss": 5974.9133377075195, "training_acc": 72.0, "val_loss": 99.45856928825378, "val_acc": 68.0}
{"epoch": 39, "training_loss": 3694.6764373779297, "training_acc": 42.0, "val_loss": 2274.6036529541016, "val_acc": 72.0}
{"epoch": 40, "training_loss": 9184.97476196289, "training_acc": 72.0, "val_loss": 1197.2529411315918, "val_acc": 72.0}
{"epoch": 41, "training_loss": 3706.55864131443, "training_acc": 48.0, "val_loss": 902.9311180114746, "val_acc": 72.0}
{"epoch": 42, "training_loss": 3826.2848768234253, "training_acc": 71.0, "val_loss": 200.31192302703857, "val_acc": 56.0}
{"epoch": 43, "training_loss": 1175.9324035644531, "training_acc": 60.0, "val_loss": 358.090877532959, "val_acc": 72.0}
