"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19803.568977355957, "training_acc": 72.0, "val_loss": 2352.583694458008, "val_acc": 28.0}
{"epoch": 1, "training_loss": 7856.736831665039, "training_acc": 46.0, "val_loss": 1825.503158569336, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4236.230850219727, "training_acc": 58.0, "val_loss": 526.3766765594482, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2645.2559204101562, "training_acc": 54.0, "val_loss": 536.4326477050781, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1384.6462326049805, "training_acc": 64.0, "val_loss": 1050.6966590881348, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2992.6398315429688, "training_acc": 70.0, "val_loss": 1260.6510162353516, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6356.875732421875, "training_acc": 54.0, "val_loss": 2469.126319885254, "val_acc": 72.0}
{"epoch": 7, "training_loss": 8128.0380859375, "training_acc": 72.0, "val_loss": 1896.4263916015625, "val_acc": 28.0}
{"epoch": 8, "training_loss": 5479.318054199219, "training_acc": 44.0, "val_loss": 1698.1504440307617, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4415.173156738281, "training_acc": 72.0, "val_loss": 3138.9936447143555, "val_acc": 28.0}
{"epoch": 10, "training_loss": 7327.3248291015625, "training_acc": 46.0, "val_loss": 3116.9437408447266, "val_acc": 72.0}
{"epoch": 11, "training_loss": 11801.407424926758, "training_acc": 72.0, "val_loss": 559.2592716217041, "val_acc": 72.0}
{"epoch": 12, "training_loss": 7211.618236541748, "training_acc": 42.0, "val_loss": 1764.1935348510742, "val_acc": 72.0}
{"epoch": 13, "training_loss": 10660.358520507812, "training_acc": 72.0, "val_loss": 3783.089828491211, "val_acc": 72.0}
{"epoch": 14, "training_loss": 12375.06982421875, "training_acc": 72.0, "val_loss": 882.7954292297363, "val_acc": 28.0}
{"epoch": 15, "training_loss": 2940.1177978515625, "training_acc": 50.0, "val_loss": 1367.5776481628418, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4069.1492919921875, "training_acc": 68.0, "val_loss": 597.3219871520996, "val_acc": 28.0}
{"epoch": 17, "training_loss": 6267.151702880859, "training_acc": 54.0, "val_loss": 2851.333427429199, "val_acc": 72.0}
{"epoch": 18, "training_loss": 9069.783203125, "training_acc": 72.0, "val_loss": 1437.768268585205, "val_acc": 28.0}
{"epoch": 19, "training_loss": 4704.871841430664, "training_acc": 40.0, "val_loss": 1784.4411849975586, "val_acc": 72.0}
{"epoch": 20, "training_loss": 5483.9002685546875, "training_acc": 68.0, "val_loss": 330.18903732299805, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1829.7221069335938, "training_acc": 68.0, "val_loss": 173.49202632904053, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1476.6103057861328, "training_acc": 68.0, "val_loss": 725.9598731994629, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3609.446044921875, "training_acc": 72.0, "val_loss": 69.39581036567688, "val_acc": 68.0}
{"epoch": 24, "training_loss": 235.4487558156252, "training_acc": 77.0, "val_loss": 447.4127769470215, "val_acc": 28.0}
{"epoch": 25, "training_loss": 2552.688217163086, "training_acc": 60.0, "val_loss": 486.24887466430664, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1195.0511002540588, "training_acc": 58.0, "val_loss": 241.78602695465088, "val_acc": 72.0}
{"epoch": 27, "training_loss": 435.23026299476624, "training_acc": 70.0, "val_loss": 52.76898741722107, "val_acc": 68.0}
{"epoch": 28, "training_loss": 507.93172454833984, "training_acc": 69.0, "val_loss": 829.6801567077637, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2788.0469512939453, "training_acc": 70.0, "val_loss": 379.21764850616455, "val_acc": 28.0}
{"epoch": 30, "training_loss": 5857.8651123046875, "training_acc": 56.0, "val_loss": 2271.462631225586, "val_acc": 72.0}
{"epoch": 31, "training_loss": 6297.326599121094, "training_acc": 68.0, "val_loss": 2663.103485107422, "val_acc": 28.0}
{"epoch": 32, "training_loss": 5285.064224243164, "training_acc": 56.0, "val_loss": 938.1194114685059, "val_acc": 72.0}
{"epoch": 33, "training_loss": 4512.470016479492, "training_acc": 54.0, "val_loss": 746.1434364318848, "val_acc": 72.0}
{"epoch": 34, "training_loss": 5344.5889892578125, "training_acc": 72.0, "val_loss": 1318.8766479492188, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2566.3063804507256, "training_acc": 64.0, "val_loss": 81.9811999797821, "val_acc": 76.0}
{"epoch": 36, "training_loss": 372.6731414794922, "training_acc": 73.0, "val_loss": 2163.777732849121, "val_acc": 28.0}
{"epoch": 37, "training_loss": 5895.795928955078, "training_acc": 42.0, "val_loss": 949.0482330322266, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2232.7808227539062, "training_acc": 73.0, "val_loss": 184.48442220687866, "val_acc": 48.0}
{"epoch": 39, "training_loss": 4881.478790283203, "training_acc": 67.0, "val_loss": 2174.399948120117, "val_acc": 72.0}
{"epoch": 40, "training_loss": 4799.623718261719, "training_acc": 74.0, "val_loss": 5026.85432434082, "val_acc": 28.0}
{"epoch": 41, "training_loss": 12137.243255615234, "training_acc": 32.0, "val_loss": 4137.14599609375, "val_acc": 72.0}
{"epoch": 42, "training_loss": 21004.35577392578, "training_acc": 72.0, "val_loss": 6664.903259277344, "val_acc": 72.0}
{"epoch": 43, "training_loss": 23817.18505859375, "training_acc": 72.0, "val_loss": 2584.2147827148438, "val_acc": 72.0}
{"epoch": 44, "training_loss": 8547.63720703125, "training_acc": 58.0, "val_loss": 3389.0159606933594, "val_acc": 28.0}
{"epoch": 45, "training_loss": 6679.947509765625, "training_acc": 56.0, "val_loss": 1072.5647926330566, "val_acc": 72.0}
{"epoch": 46, "training_loss": 4636.710258483887, "training_acc": 60.0, "val_loss": 165.8872365951538, "val_acc": 56.0}
