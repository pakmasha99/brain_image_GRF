"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4742.3295974731445, "training_acc": 68.0, "val_loss": 2254.387855529785, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6568.935241699219, "training_acc": 72.0, "val_loss": 2494.0473556518555, "val_acc": 28.0}
{"epoch": 2, "training_loss": 10658.285217285156, "training_acc": 28.0, "val_loss": 354.66508865356445, "val_acc": 64.0}
{"epoch": 3, "training_loss": 2588.1305541992188, "training_acc": 63.0, "val_loss": 2115.532684326172, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8780.146575927734, "training_acc": 72.0, "val_loss": 2482.671356201172, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8748.698684692383, "training_acc": 72.0, "val_loss": 1505.1239967346191, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3919.3903884887695, "training_acc": 70.0, "val_loss": 720.9918022155762, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4531.986831665039, "training_acc": 50.0, "val_loss": 869.755744934082, "val_acc": 48.0}
{"epoch": 8, "training_loss": 3889.8858642578125, "training_acc": 52.0, "val_loss": 981.3009262084961, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3029.1934356689453, "training_acc": 75.0, "val_loss": 1547.1476554870605, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4322.640380859375, "training_acc": 72.0, "val_loss": 1025.2861976623535, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1646.1057357788086, "training_acc": 81.0, "val_loss": 640.0432586669922, "val_acc": 60.0}
{"epoch": 12, "training_loss": 3430.5859451293945, "training_acc": 56.0, "val_loss": 619.6272850036621, "val_acc": 64.0}
{"epoch": 13, "training_loss": 2345.698272705078, "training_acc": 61.0, "val_loss": 829.3570518493652, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2155.2788848876953, "training_acc": 73.0, "val_loss": 988.4113311767578, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2632.7065505981445, "training_acc": 72.0, "val_loss": 377.32696533203125, "val_acc": 64.0}
{"epoch": 16, "training_loss": 1905.8759155273438, "training_acc": 58.0, "val_loss": 393.5441732406616, "val_acc": 64.0}
{"epoch": 17, "training_loss": 956.1560115814209, "training_acc": 66.0, "val_loss": 601.5018939971924, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2330.3756713867188, "training_acc": 72.0, "val_loss": 689.8273944854736, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2046.4749908447266, "training_acc": 72.0, "val_loss": 309.9080801010132, "val_acc": 36.0}
{"epoch": 20, "training_loss": 1510.6079864501953, "training_acc": 45.0, "val_loss": 132.79824256896973, "val_acc": 80.0}
{"epoch": 21, "training_loss": 651.6908912658691, "training_acc": 73.0, "val_loss": 326.826810836792, "val_acc": 72.0}
{"epoch": 22, "training_loss": 786.2817363739014, "training_acc": 76.0, "val_loss": 375.4920959472656, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1307.178918838501, "training_acc": 50.0, "val_loss": 174.9502420425415, "val_acc": 76.0}
{"epoch": 24, "training_loss": 688.1436805725098, "training_acc": 75.0, "val_loss": 191.39187335968018, "val_acc": 76.0}
{"epoch": 25, "training_loss": 616.2643432617188, "training_acc": 75.0, "val_loss": 105.12697696685791, "val_acc": 68.0}
{"epoch": 26, "training_loss": 499.63090229034424, "training_acc": 68.0, "val_loss": 169.06346082687378, "val_acc": 72.0}
{"epoch": 27, "training_loss": 524.6080021858215, "training_acc": 77.0, "val_loss": 36.174994707107544, "val_acc": 80.0}
{"epoch": 28, "training_loss": 216.58192348480225, "training_acc": 77.0, "val_loss": 68.72662901878357, "val_acc": 76.0}
{"epoch": 29, "training_loss": 303.3529853820801, "training_acc": 78.0, "val_loss": 307.62765407562256, "val_acc": 40.0}
{"epoch": 30, "training_loss": 742.9835076332092, "training_acc": 60.0, "val_loss": 161.7321014404297, "val_acc": 72.0}
{"epoch": 31, "training_loss": 517.8106393814087, "training_acc": 76.0, "val_loss": 173.37234020233154, "val_acc": 48.0}
{"epoch": 32, "training_loss": 407.30184173583984, "training_acc": 65.0, "val_loss": 227.64794826507568, "val_acc": 72.0}
{"epoch": 33, "training_loss": 560.0710411071777, "training_acc": 76.0, "val_loss": 121.70600891113281, "val_acc": 68.0}
{"epoch": 34, "training_loss": 541.5628051757812, "training_acc": 69.0, "val_loss": 208.25529098510742, "val_acc": 76.0}
{"epoch": 35, "training_loss": 451.71226978302, "training_acc": 78.0, "val_loss": 97.25428819656372, "val_acc": 76.0}
{"epoch": 36, "training_loss": 333.63847160339355, "training_acc": 74.0, "val_loss": 109.64208841323853, "val_acc": 80.0}
{"epoch": 37, "training_loss": 279.8922290802002, "training_acc": 79.0, "val_loss": 132.9964518547058, "val_acc": 48.0}
{"epoch": 38, "training_loss": 508.21857166290283, "training_acc": 58.0, "val_loss": 67.40087866783142, "val_acc": 72.0}
{"epoch": 39, "training_loss": 707.2280693054199, "training_acc": 58.0, "val_loss": 145.88710069656372, "val_acc": 72.0}
{"epoch": 40, "training_loss": 659.8885536193848, "training_acc": 72.0, "val_loss": 47.56106734275818, "val_acc": 80.0}
{"epoch": 41, "training_loss": 328.4444351196289, "training_acc": 74.0, "val_loss": 120.31089067459106, "val_acc": 80.0}
{"epoch": 42, "training_loss": 229.3923625946045, "training_acc": 79.0, "val_loss": 89.3248200416565, "val_acc": 76.0}
{"epoch": 43, "training_loss": 272.43370819091797, "training_acc": 81.0, "val_loss": 100.54378509521484, "val_acc": 80.0}
{"epoch": 44, "training_loss": 192.098370552063, "training_acc": 83.0, "val_loss": 55.61355948448181, "val_acc": 84.0}
{"epoch": 45, "training_loss": 84.63551688194275, "training_acc": 82.0, "val_loss": 51.34918689727783, "val_acc": 84.0}
{"epoch": 46, "training_loss": 99.06508350372314, "training_acc": 79.0, "val_loss": 82.6820969581604, "val_acc": 72.0}
