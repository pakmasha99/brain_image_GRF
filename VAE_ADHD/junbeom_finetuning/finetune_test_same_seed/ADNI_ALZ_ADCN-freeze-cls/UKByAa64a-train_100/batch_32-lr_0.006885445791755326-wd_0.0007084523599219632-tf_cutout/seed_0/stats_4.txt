"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.7747642993927, "training_acc": 55.0, "val_loss": 15.05863219499588, "val_acc": 72.0}
{"epoch": 1, "training_loss": 58.13046884536743, "training_acc": 72.0, "val_loss": 15.426705777645111, "val_acc": 48.0}
{"epoch": 2, "training_loss": 62.78859782218933, "training_acc": 71.0, "val_loss": 14.313560724258423, "val_acc": 72.0}
{"epoch": 3, "training_loss": 56.12805724143982, "training_acc": 73.0, "val_loss": 15.250308811664581, "val_acc": 72.0}
{"epoch": 4, "training_loss": 57.17618536949158, "training_acc": 72.0, "val_loss": 14.477589726448059, "val_acc": 68.0}
{"epoch": 5, "training_loss": 54.48970985412598, "training_acc": 71.0, "val_loss": 14.405819773674011, "val_acc": 64.0}
{"epoch": 6, "training_loss": 56.92468500137329, "training_acc": 72.0, "val_loss": 14.612177014350891, "val_acc": 72.0}
{"epoch": 7, "training_loss": 63.171814918518066, "training_acc": 72.0, "val_loss": 16.97811633348465, "val_acc": 72.0}
{"epoch": 8, "training_loss": 60.53576970100403, "training_acc": 72.0, "val_loss": 14.417959749698639, "val_acc": 72.0}
{"epoch": 9, "training_loss": 53.108261942863464, "training_acc": 75.0, "val_loss": 14.048787951469421, "val_acc": 72.0}
{"epoch": 10, "training_loss": 53.59620523452759, "training_acc": 77.0, "val_loss": 14.100533723831177, "val_acc": 76.0}
{"epoch": 11, "training_loss": 52.307857394218445, "training_acc": 75.0, "val_loss": 14.342084527015686, "val_acc": 72.0}
{"epoch": 12, "training_loss": 53.30997180938721, "training_acc": 72.0, "val_loss": 14.56526666879654, "val_acc": 68.0}
{"epoch": 13, "training_loss": 53.405627608299255, "training_acc": 74.0, "val_loss": 14.241793751716614, "val_acc": 72.0}
{"epoch": 14, "training_loss": 53.32743000984192, "training_acc": 75.0, "val_loss": 14.413844048976898, "val_acc": 76.0}
{"epoch": 15, "training_loss": 53.74811232089996, "training_acc": 76.0, "val_loss": 14.590787887573242, "val_acc": 76.0}
{"epoch": 16, "training_loss": 51.51730763912201, "training_acc": 78.0, "val_loss": 15.184728801250458, "val_acc": 72.0}
{"epoch": 17, "training_loss": 53.61990785598755, "training_acc": 75.0, "val_loss": 15.29494971036911, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.14985942840576, "training_acc": 75.0, "val_loss": 14.279010891914368, "val_acc": 68.0}
{"epoch": 19, "training_loss": 54.91822791099548, "training_acc": 75.0, "val_loss": 14.25429880619049, "val_acc": 64.0}
{"epoch": 20, "training_loss": 56.458123207092285, "training_acc": 71.0, "val_loss": 14.082570374011993, "val_acc": 68.0}
{"epoch": 21, "training_loss": 53.675328731536865, "training_acc": 73.0, "val_loss": 13.932950794696808, "val_acc": 72.0}
{"epoch": 22, "training_loss": 52.49729681015015, "training_acc": 78.0, "val_loss": 13.898560404777527, "val_acc": 64.0}
{"epoch": 23, "training_loss": 55.856138706207275, "training_acc": 69.0, "val_loss": 14.099416136741638, "val_acc": 68.0}
{"epoch": 24, "training_loss": 53.2441623210907, "training_acc": 74.0, "val_loss": 14.758491516113281, "val_acc": 72.0}
{"epoch": 25, "training_loss": 56.41578197479248, "training_acc": 72.0, "val_loss": 14.70455676317215, "val_acc": 72.0}
{"epoch": 26, "training_loss": 52.93930745124817, "training_acc": 72.0, "val_loss": 14.01498168706894, "val_acc": 68.0}
{"epoch": 27, "training_loss": 58.392091274261475, "training_acc": 69.0, "val_loss": 14.659754931926727, "val_acc": 60.0}
{"epoch": 28, "training_loss": 52.86000061035156, "training_acc": 77.0, "val_loss": 14.828239381313324, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.403366565704346, "training_acc": 72.0, "val_loss": 17.42614358663559, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.15073835849762, "training_acc": 72.0, "val_loss": 15.020808577537537, "val_acc": 76.0}
{"epoch": 31, "training_loss": 52.09466600418091, "training_acc": 76.0, "val_loss": 14.012713730335236, "val_acc": 68.0}
{"epoch": 32, "training_loss": 50.37100005149841, "training_acc": 74.0, "val_loss": 14.062526822090149, "val_acc": 68.0}
{"epoch": 33, "training_loss": 53.1211519241333, "training_acc": 73.0, "val_loss": 14.769621193408966, "val_acc": 76.0}
{"epoch": 34, "training_loss": 50.884329319000244, "training_acc": 76.0, "val_loss": 14.230628311634064, "val_acc": 72.0}
{"epoch": 35, "training_loss": 50.73788285255432, "training_acc": 78.0, "val_loss": 14.119662344455719, "val_acc": 68.0}
{"epoch": 36, "training_loss": 53.52300536632538, "training_acc": 71.0, "val_loss": 14.128787815570831, "val_acc": 72.0}
{"epoch": 37, "training_loss": 50.23712921142578, "training_acc": 79.0, "val_loss": 14.21922892332077, "val_acc": 72.0}
{"epoch": 38, "training_loss": 51.191256523132324, "training_acc": 74.0, "val_loss": 14.0983447432518, "val_acc": 72.0}
{"epoch": 39, "training_loss": 51.277785301208496, "training_acc": 75.0, "val_loss": 14.142893254756927, "val_acc": 72.0}
{"epoch": 40, "training_loss": 51.12349891662598, "training_acc": 76.0, "val_loss": 14.207792282104492, "val_acc": 72.0}
{"epoch": 41, "training_loss": 52.30464816093445, "training_acc": 75.0, "val_loss": 14.676401019096375, "val_acc": 76.0}
