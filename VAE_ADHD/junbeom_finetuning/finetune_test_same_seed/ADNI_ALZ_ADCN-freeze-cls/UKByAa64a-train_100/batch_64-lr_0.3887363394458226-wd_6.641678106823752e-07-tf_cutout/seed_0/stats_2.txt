"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 558.0405387878418, "training_acc": 47.0, "val_loss": 320.93355655670166, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1132.660849571228, "training_acc": 72.0, "val_loss": 253.0846118927002, "val_acc": 28.0}
{"epoch": 2, "training_loss": 922.1548500061035, "training_acc": 31.0, "val_loss": 78.84917855262756, "val_acc": 72.0}
{"epoch": 3, "training_loss": 374.16629219055176, "training_acc": 72.0, "val_loss": 172.70296812057495, "val_acc": 72.0}
{"epoch": 4, "training_loss": 539.504861831665, "training_acc": 72.0, "val_loss": 73.8902747631073, "val_acc": 68.0}
{"epoch": 5, "training_loss": 303.98504638671875, "training_acc": 65.0, "val_loss": 108.65093469619751, "val_acc": 44.0}
{"epoch": 6, "training_loss": 552.3274450302124, "training_acc": 53.0, "val_loss": 64.41694498062134, "val_acc": 72.0}
{"epoch": 7, "training_loss": 281.2024269104004, "training_acc": 69.0, "val_loss": 138.64407539367676, "val_acc": 72.0}
{"epoch": 8, "training_loss": 446.2255573272705, "training_acc": 72.0, "val_loss": 85.19611954689026, "val_acc": 76.0}
{"epoch": 9, "training_loss": 197.0597677230835, "training_acc": 72.0, "val_loss": 80.90524673461914, "val_acc": 48.0}
{"epoch": 10, "training_loss": 412.9342746734619, "training_acc": 48.0, "val_loss": 42.11031496524811, "val_acc": 72.0}
{"epoch": 11, "training_loss": 228.6126880645752, "training_acc": 68.0, "val_loss": 124.54915046691895, "val_acc": 72.0}
{"epoch": 12, "training_loss": 419.5982856750488, "training_acc": 72.0, "val_loss": 65.83980321884155, "val_acc": 72.0}
{"epoch": 13, "training_loss": 167.58951425552368, "training_acc": 69.0, "val_loss": 92.51757860183716, "val_acc": 36.0}
{"epoch": 14, "training_loss": 279.552490234375, "training_acc": 50.0, "val_loss": 67.40644574165344, "val_acc": 72.0}
{"epoch": 15, "training_loss": 246.48275756835938, "training_acc": 72.0, "val_loss": 79.82773184776306, "val_acc": 72.0}
{"epoch": 16, "training_loss": 193.0985758304596, "training_acc": 72.0, "val_loss": 63.9611542224884, "val_acc": 40.0}
{"epoch": 17, "training_loss": 264.94121170043945, "training_acc": 43.0, "val_loss": 30.787581205368042, "val_acc": 68.0}
{"epoch": 18, "training_loss": 95.13673400878906, "training_acc": 81.0, "val_loss": 60.91175675392151, "val_acc": 72.0}
{"epoch": 19, "training_loss": 128.33603024482727, "training_acc": 74.0, "val_loss": 35.2607399225235, "val_acc": 60.0}
{"epoch": 20, "training_loss": 150.8563995361328, "training_acc": 61.0, "val_loss": 30.109527707099915, "val_acc": 68.0}
{"epoch": 21, "training_loss": 94.63514184951782, "training_acc": 71.0, "val_loss": 45.34766972064972, "val_acc": 72.0}
{"epoch": 22, "training_loss": 83.64441323280334, "training_acc": 78.0, "val_loss": 35.90450882911682, "val_acc": 56.0}
{"epoch": 23, "training_loss": 119.27438855171204, "training_acc": 61.0, "val_loss": 39.3690824508667, "val_acc": 72.0}
{"epoch": 24, "training_loss": 94.70188117027283, "training_acc": 73.0, "val_loss": 25.01952350139618, "val_acc": 64.0}
{"epoch": 25, "training_loss": 58.36055088043213, "training_acc": 78.0, "val_loss": 19.933408498764038, "val_acc": 64.0}
{"epoch": 26, "training_loss": 50.48200273513794, "training_acc": 82.0, "val_loss": 22.974616289138794, "val_acc": 68.0}
{"epoch": 27, "training_loss": 47.17380404472351, "training_acc": 76.0, "val_loss": 17.48918890953064, "val_acc": 52.0}
{"epoch": 28, "training_loss": 43.33461630344391, "training_acc": 78.0, "val_loss": 23.91495108604431, "val_acc": 72.0}
{"epoch": 29, "training_loss": 49.979576110839844, "training_acc": 78.0, "val_loss": 19.97520923614502, "val_acc": 60.0}
{"epoch": 30, "training_loss": 68.29758739471436, "training_acc": 65.0, "val_loss": 30.27861714363098, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.22324335575104, "training_acc": 80.0, "val_loss": 20.559516549110413, "val_acc": 56.0}
{"epoch": 32, "training_loss": 69.89826941490173, "training_acc": 67.0, "val_loss": 32.02424943447113, "val_acc": 72.0}
{"epoch": 33, "training_loss": 66.57383060455322, "training_acc": 75.0, "val_loss": 28.162601590156555, "val_acc": 44.0}
{"epoch": 34, "training_loss": 98.08338022232056, "training_acc": 57.0, "val_loss": 42.333197593688965, "val_acc": 72.0}
{"epoch": 35, "training_loss": 116.6281213760376, "training_acc": 72.0, "val_loss": 22.53604829311371, "val_acc": 72.0}
{"epoch": 36, "training_loss": 88.17756605148315, "training_acc": 72.0, "val_loss": 16.112777590751648, "val_acc": 76.0}
{"epoch": 37, "training_loss": 69.09798097610474, "training_acc": 77.0, "val_loss": 30.575677752494812, "val_acc": 76.0}
{"epoch": 38, "training_loss": 51.75313448905945, "training_acc": 85.0, "val_loss": 25.556892156600952, "val_acc": 56.0}
{"epoch": 39, "training_loss": 99.21347677707672, "training_acc": 63.0, "val_loss": 29.776209592819214, "val_acc": 72.0}
{"epoch": 40, "training_loss": 65.46153396368027, "training_acc": 80.0, "val_loss": 12.970547378063202, "val_acc": 64.0}
{"epoch": 41, "training_loss": 44.48560643196106, "training_acc": 81.0, "val_loss": 20.231230556964874, "val_acc": 72.0}
{"epoch": 42, "training_loss": 46.769948959350586, "training_acc": 80.0, "val_loss": 15.823282301425934, "val_acc": 52.0}
{"epoch": 43, "training_loss": 47.87965226173401, "training_acc": 70.0, "val_loss": 33.849287033081055, "val_acc": 72.0}
{"epoch": 44, "training_loss": 102.4776873588562, "training_acc": 72.0, "val_loss": 15.150032937526703, "val_acc": 72.0}
{"epoch": 45, "training_loss": 115.59476566314697, "training_acc": 58.0, "val_loss": 45.36036252975464, "val_acc": 72.0}
{"epoch": 46, "training_loss": 155.29624128341675, "training_acc": 72.0, "val_loss": 69.54475045204163, "val_acc": 72.0}
{"epoch": 47, "training_loss": 139.14444303512573, "training_acc": 75.0, "val_loss": 36.212095618247986, "val_acc": 56.0}
{"epoch": 48, "training_loss": 196.71343231201172, "training_acc": 63.0, "val_loss": 29.507553577423096, "val_acc": 68.0}
{"epoch": 49, "training_loss": 96.67012214660645, "training_acc": 78.0, "val_loss": 61.590343713760376, "val_acc": 72.0}
{"epoch": 50, "training_loss": 131.49967241287231, "training_acc": 77.0, "val_loss": 29.946964979171753, "val_acc": 64.0}
{"epoch": 51, "training_loss": 107.54367542266846, "training_acc": 65.0, "val_loss": 28.314027190208435, "val_acc": 64.0}
{"epoch": 52, "training_loss": 81.01823425292969, "training_acc": 79.0, "val_loss": 28.269296884536743, "val_acc": 64.0}
{"epoch": 53, "training_loss": 76.04265832901001, "training_acc": 70.0, "val_loss": 22.068840265274048, "val_acc": 56.0}
{"epoch": 54, "training_loss": 61.5533492565155, "training_acc": 79.0, "val_loss": 46.27010226249695, "val_acc": 72.0}
{"epoch": 55, "training_loss": 81.78704416751862, "training_acc": 77.0, "val_loss": 50.926047563552856, "val_acc": 44.0}
{"epoch": 56, "training_loss": 134.9106981754303, "training_acc": 53.0, "val_loss": 59.422773122787476, "val_acc": 72.0}
{"epoch": 57, "training_loss": 181.18780374526978, "training_acc": 72.0, "val_loss": 53.868114948272705, "val_acc": 72.0}
{"epoch": 58, "training_loss": 136.47590732574463, "training_acc": 68.0, "val_loss": 37.024518847465515, "val_acc": 56.0}
{"epoch": 59, "training_loss": 123.92144894599915, "training_acc": 65.0, "val_loss": 51.984238624572754, "val_acc": 72.0}
