"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 330.6725215911865, "training_acc": 54.0, "val_loss": 369.3573474884033, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1176.9959831237793, "training_acc": 72.0, "val_loss": 267.09980964660645, "val_acc": 28.0}
{"epoch": 2, "training_loss": 844.0168857574463, "training_acc": 33.0, "val_loss": 85.61124801635742, "val_acc": 72.0}
{"epoch": 3, "training_loss": 392.290189743042, "training_acc": 72.0, "val_loss": 160.97925901412964, "val_acc": 72.0}
{"epoch": 4, "training_loss": 566.4840641021729, "training_acc": 72.0, "val_loss": 83.79324078559875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 252.2383575439453, "training_acc": 64.0, "val_loss": 127.24930047988892, "val_acc": 64.0}
{"epoch": 6, "training_loss": 364.4778060913086, "training_acc": 60.0, "val_loss": 83.60653519630432, "val_acc": 72.0}
{"epoch": 7, "training_loss": 261.6602020263672, "training_acc": 73.0, "val_loss": 74.87661838531494, "val_acc": 72.0}
{"epoch": 8, "training_loss": 172.46712827682495, "training_acc": 74.0, "val_loss": 74.881511926651, "val_acc": 64.0}
{"epoch": 9, "training_loss": 158.95800590515137, "training_acc": 65.0, "val_loss": 39.817014336586, "val_acc": 72.0}
{"epoch": 10, "training_loss": 102.71396112442017, "training_acc": 76.0, "val_loss": 20.27234435081482, "val_acc": 76.0}
{"epoch": 11, "training_loss": 63.88348317146301, "training_acc": 70.0, "val_loss": 14.720278978347778, "val_acc": 72.0}
{"epoch": 12, "training_loss": 71.5361738204956, "training_acc": 67.0, "val_loss": 25.06859004497528, "val_acc": 48.0}
{"epoch": 13, "training_loss": 89.58249855041504, "training_acc": 52.0, "val_loss": 20.40467858314514, "val_acc": 40.0}
{"epoch": 14, "training_loss": 65.37056851387024, "training_acc": 68.0, "val_loss": 13.25937807559967, "val_acc": 68.0}
{"epoch": 15, "training_loss": 56.50194334983826, "training_acc": 72.0, "val_loss": 17.877987027168274, "val_acc": 76.0}
{"epoch": 16, "training_loss": 63.983339071273804, "training_acc": 79.0, "val_loss": 20.227038860321045, "val_acc": 68.0}
{"epoch": 17, "training_loss": 60.95333409309387, "training_acc": 76.0, "val_loss": 19.907937943935394, "val_acc": 72.0}
{"epoch": 18, "training_loss": 54.96081566810608, "training_acc": 81.0, "val_loss": 19.259807467460632, "val_acc": 60.0}
{"epoch": 19, "training_loss": 53.3486430644989, "training_acc": 72.0, "val_loss": 14.328248798847198, "val_acc": 60.0}
{"epoch": 20, "training_loss": 38.54828488826752, "training_acc": 84.0, "val_loss": 12.67545372247696, "val_acc": 60.0}
{"epoch": 21, "training_loss": 44.85121393203735, "training_acc": 79.0, "val_loss": 11.704453080892563, "val_acc": 72.0}
{"epoch": 22, "training_loss": 41.90858578681946, "training_acc": 78.0, "val_loss": 11.365441977977753, "val_acc": 64.0}
{"epoch": 23, "training_loss": 39.36635780334473, "training_acc": 81.0, "val_loss": 13.097085058689117, "val_acc": 64.0}
{"epoch": 24, "training_loss": 38.19532358646393, "training_acc": 84.0, "val_loss": 12.468535453081131, "val_acc": 72.0}
{"epoch": 25, "training_loss": 43.91601014137268, "training_acc": 78.0, "val_loss": 13.843260705471039, "val_acc": 80.0}
{"epoch": 26, "training_loss": 55.99349880218506, "training_acc": 73.0, "val_loss": 13.280357420444489, "val_acc": 84.0}
{"epoch": 27, "training_loss": 45.64778459072113, "training_acc": 80.0, "val_loss": 22.66296297311783, "val_acc": 36.0}
{"epoch": 28, "training_loss": 94.01922369003296, "training_acc": 62.0, "val_loss": 11.86576932668686, "val_acc": 76.0}
{"epoch": 29, "training_loss": 173.87616729736328, "training_acc": 49.0, "val_loss": 26.41178071498871, "val_acc": 72.0}
{"epoch": 30, "training_loss": 142.46772813796997, "training_acc": 72.0, "val_loss": 28.886738419532776, "val_acc": 72.0}
{"epoch": 31, "training_loss": 127.48990058898926, "training_acc": 61.0, "val_loss": 27.049285173416138, "val_acc": 60.0}
{"epoch": 32, "training_loss": 106.09744167327881, "training_acc": 70.0, "val_loss": 31.282657384872437, "val_acc": 80.0}
{"epoch": 33, "training_loss": 109.82570004463196, "training_acc": 70.0, "val_loss": 42.67338216304779, "val_acc": 60.0}
{"epoch": 34, "training_loss": 91.51175737380981, "training_acc": 69.0, "val_loss": 28.73038947582245, "val_acc": 80.0}
{"epoch": 35, "training_loss": 92.68987894058228, "training_acc": 77.0, "val_loss": 54.72842454910278, "val_acc": 44.0}
{"epoch": 36, "training_loss": 131.97989201545715, "training_acc": 52.0, "val_loss": 30.28824031352997, "val_acc": 76.0}
{"epoch": 37, "training_loss": 128.7992115020752, "training_acc": 73.0, "val_loss": 12.096644937992096, "val_acc": 80.0}
{"epoch": 38, "training_loss": 87.46423482894897, "training_acc": 65.0, "val_loss": 15.115438401699066, "val_acc": 84.0}
{"epoch": 39, "training_loss": 95.2207670211792, "training_acc": 77.0, "val_loss": 15.899722278118134, "val_acc": 76.0}
{"epoch": 40, "training_loss": 36.37550354003906, "training_acc": 85.0, "val_loss": 35.75041890144348, "val_acc": 48.0}
{"epoch": 41, "training_loss": 105.63327026367188, "training_acc": 65.0, "val_loss": 30.22453486919403, "val_acc": 76.0}
