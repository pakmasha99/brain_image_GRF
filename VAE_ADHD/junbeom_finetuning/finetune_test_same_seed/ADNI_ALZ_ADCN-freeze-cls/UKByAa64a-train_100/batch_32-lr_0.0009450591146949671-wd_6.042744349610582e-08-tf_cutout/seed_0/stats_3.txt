"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.83856344223022, "training_acc": 39.0, "val_loss": 16.160541772842407, "val_acc": 28.0}
{"epoch": 1, "training_loss": 64.79012632369995, "training_acc": 72.0, "val_loss": 15.311764180660248, "val_acc": 44.0}
{"epoch": 2, "training_loss": 61.53246998786926, "training_acc": 72.0, "val_loss": 14.763344824314117, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.878849506378174, "training_acc": 72.0, "val_loss": 14.605240523815155, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.67560863494873, "training_acc": 72.0, "val_loss": 14.618280529975891, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.99943709373474, "training_acc": 72.0, "val_loss": 14.573264122009277, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.864383697509766, "training_acc": 72.0, "val_loss": 14.508216083049774, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58.372185707092285, "training_acc": 72.0, "val_loss": 14.415320754051208, "val_acc": 72.0}
{"epoch": 8, "training_loss": 57.71240568161011, "training_acc": 72.0, "val_loss": 14.316155016422272, "val_acc": 72.0}
{"epoch": 9, "training_loss": 57.24906873703003, "training_acc": 72.0, "val_loss": 14.320795238018036, "val_acc": 72.0}
{"epoch": 10, "training_loss": 58.470749378204346, "training_acc": 72.0, "val_loss": 14.473484456539154, "val_acc": 68.0}
{"epoch": 11, "training_loss": 58.15800881385803, "training_acc": 72.0, "val_loss": 14.456342160701752, "val_acc": 68.0}
{"epoch": 12, "training_loss": 58.366512060165405, "training_acc": 72.0, "val_loss": 14.299958944320679, "val_acc": 68.0}
{"epoch": 13, "training_loss": 57.058969259262085, "training_acc": 72.0, "val_loss": 14.157964289188385, "val_acc": 80.0}
{"epoch": 14, "training_loss": 57.10519051551819, "training_acc": 72.0, "val_loss": 14.205138385295868, "val_acc": 72.0}
{"epoch": 15, "training_loss": 57.137309551239014, "training_acc": 72.0, "val_loss": 14.246906340122223, "val_acc": 72.0}
{"epoch": 16, "training_loss": 56.40762233734131, "training_acc": 72.0, "val_loss": 14.213617146015167, "val_acc": 72.0}
{"epoch": 17, "training_loss": 56.990727186203, "training_acc": 72.0, "val_loss": 14.132775366306305, "val_acc": 76.0}
{"epoch": 18, "training_loss": 57.53696608543396, "training_acc": 72.0, "val_loss": 14.097146689891815, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.92985248565674, "training_acc": 72.0, "val_loss": 14.101620018482208, "val_acc": 68.0}
{"epoch": 20, "training_loss": 55.564589977264404, "training_acc": 73.0, "val_loss": 14.087611436843872, "val_acc": 68.0}
{"epoch": 21, "training_loss": 56.35838317871094, "training_acc": 72.0, "val_loss": 14.077799022197723, "val_acc": 68.0}
{"epoch": 22, "training_loss": 54.57400465011597, "training_acc": 72.0, "val_loss": 14.078415930271149, "val_acc": 68.0}
{"epoch": 23, "training_loss": 55.76622009277344, "training_acc": 72.0, "val_loss": 14.10263180732727, "val_acc": 72.0}
{"epoch": 24, "training_loss": 54.5295786857605, "training_acc": 73.0, "val_loss": 14.113330841064453, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.88111853599548, "training_acc": 71.0, "val_loss": 14.142230153083801, "val_acc": 68.0}
{"epoch": 26, "training_loss": 55.93301546573639, "training_acc": 74.0, "val_loss": 14.106544852256775, "val_acc": 72.0}
{"epoch": 27, "training_loss": 54.05478000640869, "training_acc": 74.0, "val_loss": 14.098691940307617, "val_acc": 72.0}
{"epoch": 28, "training_loss": 56.17061114311218, "training_acc": 72.0, "val_loss": 14.102943241596222, "val_acc": 68.0}
{"epoch": 29, "training_loss": 55.46229803562164, "training_acc": 72.0, "val_loss": 14.108775556087494, "val_acc": 72.0}
{"epoch": 30, "training_loss": 56.105944871902466, "training_acc": 74.0, "val_loss": 14.12133127450943, "val_acc": 68.0}
{"epoch": 31, "training_loss": 54.929986000061035, "training_acc": 73.0, "val_loss": 14.145076274871826, "val_acc": 68.0}
{"epoch": 32, "training_loss": 55.52745711803436, "training_acc": 72.0, "val_loss": 14.16877955198288, "val_acc": 72.0}
{"epoch": 33, "training_loss": 54.6849160194397, "training_acc": 72.0, "val_loss": 14.216931164264679, "val_acc": 72.0}
{"epoch": 34, "training_loss": 54.926175117492676, "training_acc": 72.0, "val_loss": 14.2242431640625, "val_acc": 72.0}
{"epoch": 35, "training_loss": 54.73723125457764, "training_acc": 72.0, "val_loss": 14.18667733669281, "val_acc": 72.0}
{"epoch": 36, "training_loss": 54.82987833023071, "training_acc": 72.0, "val_loss": 14.162717759609222, "val_acc": 68.0}
{"epoch": 37, "training_loss": 54.94952857494354, "training_acc": 74.0, "val_loss": 14.156721532344818, "val_acc": 68.0}
{"epoch": 38, "training_loss": 55.07804727554321, "training_acc": 73.0, "val_loss": 14.165818691253662, "val_acc": 68.0}
{"epoch": 39, "training_loss": 54.66970908641815, "training_acc": 73.0, "val_loss": 14.168146252632141, "val_acc": 68.0}
{"epoch": 40, "training_loss": 54.74540877342224, "training_acc": 72.0, "val_loss": 14.186510443687439, "val_acc": 68.0}
