"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2586.914749145508, "training_acc": 72.0, "val_loss": 1154.9389839172363, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3372.6816415786743, "training_acc": 73.0, "val_loss": 1893.801498413086, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6735.821044921875, "training_acc": 29.0, "val_loss": 116.51856899261475, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1357.204734802246, "training_acc": 73.0, "val_loss": 1107.4110984802246, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4158.017860412598, "training_acc": 72.0, "val_loss": 1086.9359970092773, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3765.643165588379, "training_acc": 72.0, "val_loss": 461.9509696960449, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1529.3894577026367, "training_acc": 62.0, "val_loss": 652.3684024810791, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2842.2610778808594, "training_acc": 40.0, "val_loss": 232.25173950195312, "val_acc": 56.0}
{"epoch": 8, "training_loss": 904.198070526123, "training_acc": 65.0, "val_loss": 619.3001747131348, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2278.29549407959, "training_acc": 72.0, "val_loss": 643.7004089355469, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2114.5152893066406, "training_acc": 72.0, "val_loss": 189.3285632133484, "val_acc": 76.0}
{"epoch": 11, "training_loss": 901.699031829834, "training_acc": 67.0, "val_loss": 505.10687828063965, "val_acc": 56.0}
{"epoch": 12, "training_loss": 1912.1970748901367, "training_acc": 48.0, "val_loss": 151.51413679122925, "val_acc": 60.0}
{"epoch": 13, "training_loss": 898.309700012207, "training_acc": 68.0, "val_loss": 465.52348136901855, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1647.8745613098145, "training_acc": 72.0, "val_loss": 270.54665088653564, "val_acc": 72.0}
{"epoch": 15, "training_loss": 912.8551216125488, "training_acc": 74.0, "val_loss": 285.8489990234375, "val_acc": 60.0}
{"epoch": 16, "training_loss": 1259.8869972229004, "training_acc": 50.0, "val_loss": 92.5064206123352, "val_acc": 72.0}
{"epoch": 17, "training_loss": 534.8760776519775, "training_acc": 73.0, "val_loss": 321.89781665802, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1018.6463317871094, "training_acc": 72.0, "val_loss": 55.8985710144043, "val_acc": 72.0}
{"epoch": 19, "training_loss": 357.22959327697754, "training_acc": 69.0, "val_loss": 139.17319774627686, "val_acc": 44.0}
{"epoch": 20, "training_loss": 440.87195205688477, "training_acc": 65.0, "val_loss": 245.51239013671875, "val_acc": 72.0}
{"epoch": 21, "training_loss": 734.4088726043701, "training_acc": 72.0, "val_loss": 65.73455929756165, "val_acc": 56.0}
{"epoch": 22, "training_loss": 266.39289474487305, "training_acc": 60.0, "val_loss": 65.7760739326477, "val_acc": 76.0}
{"epoch": 23, "training_loss": 226.5091028213501, "training_acc": 75.0, "val_loss": 49.09387230873108, "val_acc": 76.0}
{"epoch": 24, "training_loss": 169.82762813568115, "training_acc": 71.0, "val_loss": 52.89317965507507, "val_acc": 68.0}
{"epoch": 25, "training_loss": 153.27435779571533, "training_acc": 78.0, "val_loss": 57.73918628692627, "val_acc": 52.0}
{"epoch": 26, "training_loss": 165.7264199256897, "training_acc": 69.0, "val_loss": 118.85137557983398, "val_acc": 72.0}
{"epoch": 27, "training_loss": 263.846314907074, "training_acc": 74.0, "val_loss": 147.54046201705933, "val_acc": 40.0}
{"epoch": 28, "training_loss": 272.2564241886139, "training_acc": 61.0, "val_loss": 125.69330930709839, "val_acc": 72.0}
{"epoch": 29, "training_loss": 212.97999954223633, "training_acc": 75.0, "val_loss": 135.5228066444397, "val_acc": 44.0}
{"epoch": 30, "training_loss": 280.7104229927063, "training_acc": 63.0, "val_loss": 156.0953974723816, "val_acc": 72.0}
{"epoch": 31, "training_loss": 340.02600479125977, "training_acc": 72.0, "val_loss": 118.37917566299438, "val_acc": 48.0}
{"epoch": 32, "training_loss": 214.88885128498077, "training_acc": 66.0, "val_loss": 126.14312171936035, "val_acc": 72.0}
{"epoch": 33, "training_loss": 195.31278228759766, "training_acc": 76.0, "val_loss": 136.83489561080933, "val_acc": 48.0}
{"epoch": 34, "training_loss": 277.3085961341858, "training_acc": 61.0, "val_loss": 100.72410106658936, "val_acc": 76.0}
{"epoch": 35, "training_loss": 118.33602917194366, "training_acc": 82.0, "val_loss": 55.30927777290344, "val_acc": 64.0}
{"epoch": 36, "training_loss": 67.63509440422058, "training_acc": 89.0, "val_loss": 66.50031208992004, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.68903172016144, "training_acc": 86.0, "val_loss": 65.90368747711182, "val_acc": 64.0}
{"epoch": 38, "training_loss": 72.95474410057068, "training_acc": 84.0, "val_loss": 76.76650285720825, "val_acc": 72.0}
{"epoch": 39, "training_loss": 105.42531824111938, "training_acc": 78.0, "val_loss": 91.46691560745239, "val_acc": 76.0}
{"epoch": 40, "training_loss": 115.44262647628784, "training_acc": 79.0, "val_loss": 116.36183261871338, "val_acc": 48.0}
{"epoch": 41, "training_loss": 264.06689834594727, "training_acc": 63.0, "val_loss": 102.01075077056885, "val_acc": 76.0}
{"epoch": 42, "training_loss": 115.21722507476807, "training_acc": 81.0, "val_loss": 113.67173194885254, "val_acc": 56.0}
