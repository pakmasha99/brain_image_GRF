"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2450.2923736572266, "training_acc": 47.0, "val_loss": 1323.288345336914, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4475.366451263428, "training_acc": 72.0, "val_loss": 1058.0976486206055, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4047.0473022460938, "training_acc": 28.0, "val_loss": 299.94189739227295, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1501.558219909668, "training_acc": 72.0, "val_loss": 765.5998229980469, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2679.7507705688477, "training_acc": 72.0, "val_loss": 444.8554992675781, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1109.8717670440674, "training_acc": 71.0, "val_loss": 417.4254894256592, "val_acc": 44.0}
{"epoch": 6, "training_loss": 2248.520393371582, "training_acc": 49.0, "val_loss": 248.21267127990723, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1173.3811721801758, "training_acc": 65.0, "val_loss": 587.1830463409424, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2046.0554580688477, "training_acc": 72.0, "val_loss": 615.8014297485352, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1631.1904335021973, "training_acc": 74.0, "val_loss": 232.5026512145996, "val_acc": 72.0}
{"epoch": 10, "training_loss": 701.4496173858643, "training_acc": 67.0, "val_loss": 275.68793296813965, "val_acc": 56.0}
{"epoch": 11, "training_loss": 1272.049798965454, "training_acc": 58.0, "val_loss": 258.7789058685303, "val_acc": 72.0}
{"epoch": 12, "training_loss": 742.7099494934082, "training_acc": 72.0, "val_loss": 274.33695793151855, "val_acc": 72.0}
{"epoch": 13, "training_loss": 559.5189538002014, "training_acc": 76.0, "val_loss": 210.57813167572021, "val_acc": 48.0}
{"epoch": 14, "training_loss": 656.1055488586426, "training_acc": 56.0, "val_loss": 216.32561683654785, "val_acc": 68.0}
{"epoch": 15, "training_loss": 670.6643714904785, "training_acc": 72.0, "val_loss": 200.96979141235352, "val_acc": 64.0}
{"epoch": 16, "training_loss": 668.3585090637207, "training_acc": 52.0, "val_loss": 148.20703268051147, "val_acc": 48.0}
{"epoch": 17, "training_loss": 467.9351978302002, "training_acc": 63.0, "val_loss": 187.57790327072144, "val_acc": 68.0}
{"epoch": 18, "training_loss": 343.36038398742676, "training_acc": 74.0, "val_loss": 162.60244846343994, "val_acc": 48.0}
{"epoch": 19, "training_loss": 436.5933656692505, "training_acc": 60.0, "val_loss": 145.52154541015625, "val_acc": 64.0}
{"epoch": 20, "training_loss": 282.2548875808716, "training_acc": 73.0, "val_loss": 113.74293565750122, "val_acc": 64.0}
{"epoch": 21, "training_loss": 133.27009773254395, "training_acc": 80.0, "val_loss": 74.77906346321106, "val_acc": 76.0}
{"epoch": 22, "training_loss": 146.40375089645386, "training_acc": 77.0, "val_loss": 88.10803294181824, "val_acc": 72.0}
{"epoch": 23, "training_loss": 135.24295091629028, "training_acc": 81.0, "val_loss": 29.963743686676025, "val_acc": 60.0}
{"epoch": 24, "training_loss": 116.15144968032837, "training_acc": 74.0, "val_loss": 39.869242906570435, "val_acc": 52.0}
{"epoch": 25, "training_loss": 216.3271026611328, "training_acc": 60.0, "val_loss": 28.21546196937561, "val_acc": 72.0}
{"epoch": 26, "training_loss": 91.400643825531, "training_acc": 75.0, "val_loss": 84.35896039009094, "val_acc": 72.0}
{"epoch": 27, "training_loss": 168.49779212474823, "training_acc": 78.0, "val_loss": 49.17706847190857, "val_acc": 52.0}
{"epoch": 28, "training_loss": 190.93315839767456, "training_acc": 75.0, "val_loss": 92.75726079940796, "val_acc": 72.0}
{"epoch": 29, "training_loss": 170.47901153564453, "training_acc": 81.0, "val_loss": 37.24472224712372, "val_acc": 68.0}
{"epoch": 30, "training_loss": 175.00217628479004, "training_acc": 66.0, "val_loss": 108.35812091827393, "val_acc": 72.0}
{"epoch": 31, "training_loss": 267.175386428833, "training_acc": 68.0, "val_loss": 37.56207823753357, "val_acc": 72.0}
{"epoch": 32, "training_loss": 170.85543298721313, "training_acc": 73.0, "val_loss": 107.55892992019653, "val_acc": 72.0}
{"epoch": 33, "training_loss": 175.50785207748413, "training_acc": 77.0, "val_loss": 50.55550932884216, "val_acc": 64.0}
{"epoch": 34, "training_loss": 252.57104873657227, "training_acc": 63.0, "val_loss": 100.0421404838562, "val_acc": 72.0}
{"epoch": 35, "training_loss": 449.0516109466553, "training_acc": 56.0, "val_loss": 79.70207929611206, "val_acc": 68.0}
{"epoch": 36, "training_loss": 207.5746946334839, "training_acc": 78.0, "val_loss": 73.86718392372131, "val_acc": 64.0}
{"epoch": 37, "training_loss": 120.90523386001587, "training_acc": 73.0, "val_loss": 73.36639165878296, "val_acc": 68.0}
{"epoch": 38, "training_loss": 164.81610202789307, "training_acc": 78.0, "val_loss": 92.00127720832825, "val_acc": 64.0}
{"epoch": 39, "training_loss": 132.03085613250732, "training_acc": 83.0, "val_loss": 85.81745624542236, "val_acc": 60.0}
{"epoch": 40, "training_loss": 234.33146858215332, "training_acc": 74.0, "val_loss": 178.5746455192566, "val_acc": 72.0}
{"epoch": 41, "training_loss": 315.9177131652832, "training_acc": 75.0, "val_loss": 259.07092094421387, "val_acc": 36.0}
{"epoch": 42, "training_loss": 679.9210667610168, "training_acc": 50.0, "val_loss": 152.73553133010864, "val_acc": 68.0}
{"epoch": 43, "training_loss": 284.18443393707275, "training_acc": 76.0, "val_loss": 127.51580476760864, "val_acc": 52.0}
{"epoch": 44, "training_loss": 237.30458092689514, "training_acc": 66.0, "val_loss": 125.78459978103638, "val_acc": 68.0}
