"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2590.4395294189453, "training_acc": 59.0, "val_loss": 1245.7901000976562, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3562.9937019348145, "training_acc": 72.0, "val_loss": 1647.365379333496, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6170.502899169922, "training_acc": 28.0, "val_loss": 290.536093711853, "val_acc": 64.0}
{"epoch": 3, "training_loss": 1086.9293060302734, "training_acc": 65.0, "val_loss": 1016.8615341186523, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4085.548049926758, "training_acc": 72.0, "val_loss": 1146.2716102600098, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4012.3463287353516, "training_acc": 72.0, "val_loss": 592.889404296875, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2083.7283115386963, "training_acc": 69.0, "val_loss": 645.0845718383789, "val_acc": 48.0}
{"epoch": 7, "training_loss": 2709.3877716064453, "training_acc": 44.0, "val_loss": 574.7663497924805, "val_acc": 64.0}
{"epoch": 8, "training_loss": 1209.257776260376, "training_acc": 66.0, "val_loss": 500.4206657409668, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1814.537971496582, "training_acc": 74.0, "val_loss": 630.6098937988281, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2162.1713638305664, "training_acc": 72.0, "val_loss": 413.8038158416748, "val_acc": 68.0}
{"epoch": 11, "training_loss": 1311.5121726989746, "training_acc": 66.0, "val_loss": 597.0465660095215, "val_acc": 56.0}
{"epoch": 12, "training_loss": 1788.4921112060547, "training_acc": 47.0, "val_loss": 380.01952171325684, "val_acc": 68.0}
{"epoch": 13, "training_loss": 747.6208953857422, "training_acc": 70.0, "val_loss": 404.3538570404053, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1640.7672500610352, "training_acc": 72.0, "val_loss": 362.28833198547363, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1099.5991592407227, "training_acc": 73.0, "val_loss": 305.4799795150757, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1088.6774520874023, "training_acc": 52.0, "val_loss": 222.31013774871826, "val_acc": 56.0}
{"epoch": 17, "training_loss": 680.765251159668, "training_acc": 62.0, "val_loss": 264.90259170532227, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1040.6170539855957, "training_acc": 72.0, "val_loss": 83.07095170021057, "val_acc": 76.0}
{"epoch": 19, "training_loss": 649.2840919494629, "training_acc": 64.0, "val_loss": 301.9235134124756, "val_acc": 32.0}
{"epoch": 20, "training_loss": 909.1806716918945, "training_acc": 50.0, "val_loss": 229.26559448242188, "val_acc": 72.0}
{"epoch": 21, "training_loss": 959.8837509155273, "training_acc": 72.0, "val_loss": 108.58989953994751, "val_acc": 80.0}
{"epoch": 22, "training_loss": 513.3526706695557, "training_acc": 65.0, "val_loss": 314.1366481781006, "val_acc": 40.0}
{"epoch": 23, "training_loss": 733.0659341812134, "training_acc": 58.0, "val_loss": 154.2721390724182, "val_acc": 76.0}
{"epoch": 24, "training_loss": 556.3202228546143, "training_acc": 74.0, "val_loss": 127.65990495681763, "val_acc": 76.0}
{"epoch": 25, "training_loss": 375.48202896118164, "training_acc": 73.0, "val_loss": 182.38418102264404, "val_acc": 52.0}
{"epoch": 26, "training_loss": 291.6602191925049, "training_acc": 71.0, "val_loss": 97.78416752815247, "val_acc": 80.0}
{"epoch": 27, "training_loss": 310.81836557388306, "training_acc": 75.0, "val_loss": 72.37470746040344, "val_acc": 56.0}
{"epoch": 28, "training_loss": 184.00353860855103, "training_acc": 73.0, "val_loss": 45.13273537158966, "val_acc": 52.0}
{"epoch": 29, "training_loss": 116.16153240203857, "training_acc": 79.0, "val_loss": 26.909920573234558, "val_acc": 68.0}
{"epoch": 30, "training_loss": 191.21640396118164, "training_acc": 67.0, "val_loss": 31.9756418466568, "val_acc": 60.0}
{"epoch": 31, "training_loss": 255.1395378112793, "training_acc": 73.0, "val_loss": 100.45645236968994, "val_acc": 40.0}
{"epoch": 32, "training_loss": 259.88448429107666, "training_acc": 66.0, "val_loss": 41.7218953371048, "val_acc": 84.0}
{"epoch": 33, "training_loss": 168.28376984596252, "training_acc": 76.0, "val_loss": 97.11950421333313, "val_acc": 52.0}
{"epoch": 34, "training_loss": 184.7779359817505, "training_acc": 70.0, "val_loss": 51.81850790977478, "val_acc": 76.0}
{"epoch": 35, "training_loss": 193.64414310455322, "training_acc": 76.0, "val_loss": 43.697360157966614, "val_acc": 80.0}
{"epoch": 36, "training_loss": 138.34238958358765, "training_acc": 81.0, "val_loss": 67.22912192344666, "val_acc": 60.0}
{"epoch": 37, "training_loss": 130.05949115753174, "training_acc": 71.0, "val_loss": 19.253148138523102, "val_acc": 64.0}
{"epoch": 38, "training_loss": 58.567280769348145, "training_acc": 87.0, "val_loss": 13.432170450687408, "val_acc": 76.0}
{"epoch": 39, "training_loss": 68.91586875915527, "training_acc": 82.0, "val_loss": 15.660057961940765, "val_acc": 80.0}
{"epoch": 40, "training_loss": 62.604918003082275, "training_acc": 83.0, "val_loss": 16.92371368408203, "val_acc": 64.0}
{"epoch": 41, "training_loss": 65.01605176925659, "training_acc": 84.0, "val_loss": 32.00935423374176, "val_acc": 64.0}
{"epoch": 42, "training_loss": 54.97855532169342, "training_acc": 83.0, "val_loss": 27.78213322162628, "val_acc": 80.0}
{"epoch": 43, "training_loss": 111.23407745361328, "training_acc": 80.0, "val_loss": 21.82062864303589, "val_acc": 68.0}
{"epoch": 44, "training_loss": 96.790274143219, "training_acc": 83.0, "val_loss": 14.589926600456238, "val_acc": 80.0}
{"epoch": 45, "training_loss": 48.66009259223938, "training_acc": 85.0, "val_loss": 17.239485681056976, "val_acc": 72.0}
{"epoch": 46, "training_loss": 81.57205629348755, "training_acc": 80.0, "val_loss": 23.749898374080658, "val_acc": 72.0}
{"epoch": 47, "training_loss": 55.489758133888245, "training_acc": 81.0, "val_loss": 9.672319144010544, "val_acc": 84.0}
{"epoch": 48, "training_loss": 59.10363960266113, "training_acc": 81.0, "val_loss": 10.14118567109108, "val_acc": 88.0}
{"epoch": 49, "training_loss": 67.86803483963013, "training_acc": 80.0, "val_loss": 57.68130421638489, "val_acc": 72.0}
{"epoch": 50, "training_loss": 176.7507176399231, "training_acc": 80.0, "val_loss": 85.03243923187256, "val_acc": 52.0}
{"epoch": 51, "training_loss": 257.01657485961914, "training_acc": 64.0, "val_loss": 64.18675184249878, "val_acc": 80.0}
{"epoch": 52, "training_loss": 185.48225450515747, "training_acc": 84.0, "val_loss": 52.191466093063354, "val_acc": 64.0}
{"epoch": 53, "training_loss": 155.23338174819946, "training_acc": 81.0, "val_loss": 79.2963445186615, "val_acc": 76.0}
{"epoch": 54, "training_loss": 170.9493763446808, "training_acc": 78.0, "val_loss": 118.53264570236206, "val_acc": 32.0}
{"epoch": 55, "training_loss": 350.55125522613525, "training_acc": 60.0, "val_loss": 148.2069492340088, "val_acc": 72.0}
{"epoch": 56, "training_loss": 400.25448989868164, "training_acc": 75.0, "val_loss": 407.58347511291504, "val_acc": 28.0}
{"epoch": 57, "training_loss": 862.2231199741364, "training_acc": 47.0, "val_loss": 157.8622817993164, "val_acc": 72.0}
{"epoch": 58, "training_loss": 689.4617691040039, "training_acc": 72.0, "val_loss": 64.38958644866943, "val_acc": 80.0}
{"epoch": 59, "training_loss": 385.88254165649414, "training_acc": 67.0, "val_loss": 96.5564489364624, "val_acc": 64.0}
{"epoch": 60, "training_loss": 261.85985946655273, "training_acc": 77.0, "val_loss": 188.09131383895874, "val_acc": 72.0}
{"epoch": 61, "training_loss": 594.3680634498596, "training_acc": 75.0, "val_loss": 131.87652826309204, "val_acc": 64.0}
{"epoch": 62, "training_loss": 305.4244976043701, "training_acc": 71.0, "val_loss": 87.17114329338074, "val_acc": 76.0}
{"epoch": 63, "training_loss": 229.74341201782227, "training_acc": 78.0, "val_loss": 72.2430408000946, "val_acc": 80.0}
{"epoch": 64, "training_loss": 207.9965386390686, "training_acc": 76.0, "val_loss": 86.41080260276794, "val_acc": 52.0}
{"epoch": 65, "training_loss": 294.5135555267334, "training_acc": 66.0, "val_loss": 77.54753232002258, "val_acc": 76.0}
{"epoch": 66, "training_loss": 277.162962436676, "training_acc": 74.0, "val_loss": 78.44208478927612, "val_acc": 48.0}
