"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7291.381889343262, "training_acc": 64.0, "val_loss": 3505.7456970214844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10265.404571533203, "training_acc": 72.0, "val_loss": 3388.937759399414, "val_acc": 28.0}
{"epoch": 2, "training_loss": 15052.643676757812, "training_acc": 28.0, "val_loss": 467.52076148986816, "val_acc": 68.0}
{"epoch": 3, "training_loss": 3014.4620819091797, "training_acc": 65.0, "val_loss": 2747.9963302612305, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9874.814361572266, "training_acc": 72.0, "val_loss": 2780.0304412841797, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8881.938781738281, "training_acc": 72.0, "val_loss": 1182.4772834777832, "val_acc": 68.0}
{"epoch": 6, "training_loss": 4122.465057373047, "training_acc": 70.0, "val_loss": 1287.3771667480469, "val_acc": 52.0}
{"epoch": 7, "training_loss": 6866.632629394531, "training_acc": 51.0, "val_loss": 874.9881744384766, "val_acc": 68.0}
{"epoch": 8, "training_loss": 2967.6261291503906, "training_acc": 67.0, "val_loss": 1979.4231414794922, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6334.523712158203, "training_acc": 72.0, "val_loss": 1969.778823852539, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4706.701889038086, "training_acc": 72.0, "val_loss": 749.9329566955566, "val_acc": 68.0}
{"epoch": 11, "training_loss": 2957.8306732177734, "training_acc": 66.0, "val_loss": 860.5276107788086, "val_acc": 56.0}
{"epoch": 12, "training_loss": 3485.532386779785, "training_acc": 60.0, "val_loss": 920.500373840332, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2548.252601623535, "training_acc": 78.0, "val_loss": 1231.2997817993164, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3221.2884826660156, "training_acc": 73.0, "val_loss": 435.64453125, "val_acc": 64.0}
{"epoch": 15, "training_loss": 2320.2168197631836, "training_acc": 57.0, "val_loss": 332.871150970459, "val_acc": 64.0}
{"epoch": 16, "training_loss": 1787.2403259277344, "training_acc": 61.0, "val_loss": 996.7903137207031, "val_acc": 72.0}
{"epoch": 17, "training_loss": 3202.8870239257812, "training_acc": 72.0, "val_loss": 226.2073278427124, "val_acc": 76.0}
{"epoch": 18, "training_loss": 1495.6912231445312, "training_acc": 58.0, "val_loss": 125.52167177200317, "val_acc": 68.0}
{"epoch": 19, "training_loss": 903.8321647644043, "training_acc": 69.0, "val_loss": 310.9790563583374, "val_acc": 72.0}
{"epoch": 20, "training_loss": 982.7537651062012, "training_acc": 70.0, "val_loss": 95.18451690673828, "val_acc": 68.0}
{"epoch": 21, "training_loss": 558.4724445343018, "training_acc": 71.0, "val_loss": 211.22722625732422, "val_acc": 76.0}
{"epoch": 22, "training_loss": 1008.483699798584, "training_acc": 61.0, "val_loss": 103.81163358688354, "val_acc": 76.0}
{"epoch": 23, "training_loss": 398.3975467681885, "training_acc": 80.0, "val_loss": 115.34980535507202, "val_acc": 44.0}
{"epoch": 24, "training_loss": 482.5292453765869, "training_acc": 64.0, "val_loss": 23.748554289340973, "val_acc": 76.0}
{"epoch": 25, "training_loss": 171.97887921333313, "training_acc": 78.0, "val_loss": 119.00429725646973, "val_acc": 76.0}
{"epoch": 26, "training_loss": 396.63391065597534, "training_acc": 78.0, "val_loss": 40.402743220329285, "val_acc": 68.0}
{"epoch": 27, "training_loss": 263.968523979187, "training_acc": 77.0, "val_loss": 140.63055515289307, "val_acc": 76.0}
{"epoch": 28, "training_loss": 338.9744186401367, "training_acc": 76.0, "val_loss": 80.32119274139404, "val_acc": 76.0}
{"epoch": 29, "training_loss": 401.44918632507324, "training_acc": 77.0, "val_loss": 76.23251080513, "val_acc": 80.0}
{"epoch": 30, "training_loss": 271.7986946105957, "training_acc": 76.0, "val_loss": 125.56650638580322, "val_acc": 80.0}
{"epoch": 31, "training_loss": 277.0505828857422, "training_acc": 82.0, "val_loss": 265.1132106781006, "val_acc": 44.0}
{"epoch": 32, "training_loss": 1013.5100440979004, "training_acc": 56.0, "val_loss": 252.65254974365234, "val_acc": 72.0}
{"epoch": 33, "training_loss": 385.16567063331604, "training_acc": 83.0, "val_loss": 136.03808879852295, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1112.7452545166016, "training_acc": 55.0, "val_loss": 411.8947505950928, "val_acc": 72.0}
{"epoch": 35, "training_loss": 805.4314374923706, "training_acc": 73.0, "val_loss": 570.4954147338867, "val_acc": 36.0}
{"epoch": 36, "training_loss": 2216.177070617676, "training_acc": 48.0, "val_loss": 439.6327495574951, "val_acc": 72.0}
{"epoch": 37, "training_loss": 946.5089282989502, "training_acc": 76.0, "val_loss": 154.82476949691772, "val_acc": 76.0}
{"epoch": 38, "training_loss": 703.9503059387207, "training_acc": 73.0, "val_loss": 256.3916206359863, "val_acc": 76.0}
{"epoch": 39, "training_loss": 724.2838935852051, "training_acc": 79.0, "val_loss": 195.32302618026733, "val_acc": 80.0}
{"epoch": 40, "training_loss": 843.8058700561523, "training_acc": 67.0, "val_loss": 169.50947046279907, "val_acc": 80.0}
{"epoch": 41, "training_loss": 363.78553581237793, "training_acc": 82.0, "val_loss": 201.53300762176514, "val_acc": 76.0}
{"epoch": 42, "training_loss": 571.3866920471191, "training_acc": 69.0, "val_loss": 186.63837909698486, "val_acc": 76.0}
{"epoch": 43, "training_loss": 266.78764724731445, "training_acc": 79.0, "val_loss": 125.4977822303772, "val_acc": 64.0}
