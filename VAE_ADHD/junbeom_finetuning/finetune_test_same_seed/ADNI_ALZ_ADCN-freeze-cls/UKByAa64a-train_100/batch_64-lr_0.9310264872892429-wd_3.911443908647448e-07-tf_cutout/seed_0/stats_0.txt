"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1552.2927513122559, "training_acc": 72.0, "val_loss": 667.8761959075928, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1819.987075805664, "training_acc": 72.0, "val_loss": 1045.3893661499023, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4374.545257568359, "training_acc": 28.0, "val_loss": 189.91211652755737, "val_acc": 36.0}
{"epoch": 3, "training_loss": 1158.5654373168945, "training_acc": 51.0, "val_loss": 597.1154689788818, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2686.0548095703125, "training_acc": 72.0, "val_loss": 796.8676567077637, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3180.6423110961914, "training_acc": 72.0, "val_loss": 589.7461891174316, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2073.1968383789062, "training_acc": 72.0, "val_loss": 129.72909212112427, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1082.9554176330566, "training_acc": 65.0, "val_loss": 237.67409324645996, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1732.593204498291, "training_acc": 45.0, "val_loss": 79.59002256393433, "val_acc": 84.0}
{"epoch": 9, "training_loss": 808.5959205627441, "training_acc": 71.0, "val_loss": 206.7403793334961, "val_acc": 72.0}
{"epoch": 10, "training_loss": 921.8260955810547, "training_acc": 73.0, "val_loss": 246.94769382476807, "val_acc": 72.0}
{"epoch": 11, "training_loss": 795.086145401001, "training_acc": 71.0, "val_loss": 49.885618686676025, "val_acc": 80.0}
{"epoch": 12, "training_loss": 503.23291015625, "training_acc": 63.0, "val_loss": 88.88470530509949, "val_acc": 56.0}
{"epoch": 13, "training_loss": 387.1986231803894, "training_acc": 63.0, "val_loss": 156.287682056427, "val_acc": 72.0}
{"epoch": 14, "training_loss": 578.7083377838135, "training_acc": 72.0, "val_loss": 119.6313738822937, "val_acc": 72.0}
{"epoch": 15, "training_loss": 295.7419710159302, "training_acc": 67.0, "val_loss": 92.54265427589417, "val_acc": 52.0}
{"epoch": 16, "training_loss": 350.65103340148926, "training_acc": 57.0, "val_loss": 89.4847571849823, "val_acc": 72.0}
{"epoch": 17, "training_loss": 239.19480228424072, "training_acc": 68.0, "val_loss": 34.10012125968933, "val_acc": 56.0}
{"epoch": 18, "training_loss": 151.68969106674194, "training_acc": 61.0, "val_loss": 29.707953333854675, "val_acc": 76.0}
{"epoch": 19, "training_loss": 160.9944658279419, "training_acc": 67.0, "val_loss": 14.669616520404816, "val_acc": 84.0}
{"epoch": 20, "training_loss": 95.8465633392334, "training_acc": 80.0, "val_loss": 38.592031598091125, "val_acc": 72.0}
{"epoch": 21, "training_loss": 111.90471363067627, "training_acc": 80.0, "val_loss": 90.40839076042175, "val_acc": 44.0}
{"epoch": 22, "training_loss": 268.54941487312317, "training_acc": 54.0, "val_loss": 63.82778286933899, "val_acc": 72.0}
{"epoch": 23, "training_loss": 181.71269130706787, "training_acc": 72.0, "val_loss": 99.73651766777039, "val_acc": 40.0}
{"epoch": 24, "training_loss": 269.7022008895874, "training_acc": 53.0, "val_loss": 58.88636112213135, "val_acc": 72.0}
{"epoch": 25, "training_loss": 152.93202924728394, "training_acc": 76.0, "val_loss": 63.34875822067261, "val_acc": 48.0}
{"epoch": 26, "training_loss": 151.8478000164032, "training_acc": 60.0, "val_loss": 39.341673254966736, "val_acc": 72.0}
{"epoch": 27, "training_loss": 106.32048010826111, "training_acc": 80.0, "val_loss": 51.20864510536194, "val_acc": 52.0}
{"epoch": 28, "training_loss": 139.96991539001465, "training_acc": 65.0, "val_loss": 45.43558657169342, "val_acc": 72.0}
{"epoch": 29, "training_loss": 119.95811438560486, "training_acc": 81.0, "val_loss": 35.56223213672638, "val_acc": 56.0}
{"epoch": 30, "training_loss": 66.03783160448074, "training_acc": 82.0, "val_loss": 53.879332542419434, "val_acc": 72.0}
{"epoch": 31, "training_loss": 112.11808824539185, "training_acc": 76.0, "val_loss": 68.0893063545227, "val_acc": 44.0}
{"epoch": 32, "training_loss": 170.24887430667877, "training_acc": 62.0, "val_loss": 44.268202781677246, "val_acc": 72.0}
{"epoch": 33, "training_loss": 96.5538010597229, "training_acc": 76.0, "val_loss": 20.56131362915039, "val_acc": 68.0}
{"epoch": 34, "training_loss": 99.11908388137817, "training_acc": 69.0, "val_loss": 23.854850232601166, "val_acc": 72.0}
{"epoch": 35, "training_loss": 109.28359031677246, "training_acc": 76.0, "val_loss": 20.3513503074646, "val_acc": 72.0}
{"epoch": 36, "training_loss": 56.12471055984497, "training_acc": 86.0, "val_loss": 15.448740124702454, "val_acc": 84.0}
{"epoch": 37, "training_loss": 43.90884184837341, "training_acc": 89.0, "val_loss": 18.53543221950531, "val_acc": 76.0}
{"epoch": 38, "training_loss": 59.00103235244751, "training_acc": 83.0, "val_loss": 20.339497923851013, "val_acc": 60.0}
