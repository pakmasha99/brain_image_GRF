"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 447.4933090209961, "training_acc": 70.0, "val_loss": 264.6380662918091, "val_acc": 72.0}
{"epoch": 1, "training_loss": 796.871340751648, "training_acc": 72.0, "val_loss": 389.11070823669434, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1356.318229675293, "training_acc": 28.0, "val_loss": 29.59337830543518, "val_acc": 56.0}
{"epoch": 3, "training_loss": 203.25232124328613, "training_acc": 72.0, "val_loss": 167.7164912223816, "val_acc": 72.0}
{"epoch": 4, "training_loss": 639.9936866760254, "training_acc": 72.0, "val_loss": 127.713143825531, "val_acc": 72.0}
{"epoch": 5, "training_loss": 388.1094789505005, "training_acc": 74.0, "val_loss": 76.95305347442627, "val_acc": 56.0}
{"epoch": 6, "training_loss": 372.65442848205566, "training_acc": 55.0, "val_loss": 124.25092458724976, "val_acc": 60.0}
{"epoch": 7, "training_loss": 440.8929433822632, "training_acc": 50.0, "val_loss": 67.09994077682495, "val_acc": 76.0}
{"epoch": 8, "training_loss": 336.2542610168457, "training_acc": 72.0, "val_loss": 132.30068683624268, "val_acc": 72.0}
{"epoch": 9, "training_loss": 501.30008697509766, "training_acc": 72.0, "val_loss": 75.5135715007782, "val_acc": 80.0}
{"epoch": 10, "training_loss": 230.28661251068115, "training_acc": 73.0, "val_loss": 91.82013273239136, "val_acc": 60.0}
{"epoch": 11, "training_loss": 417.51164054870605, "training_acc": 50.0, "val_loss": 60.77132821083069, "val_acc": 56.0}
{"epoch": 12, "training_loss": 177.69666481018066, "training_acc": 64.0, "val_loss": 63.97978067398071, "val_acc": 72.0}
{"epoch": 13, "training_loss": 278.5662593841553, "training_acc": 72.0, "val_loss": 61.107248067855835, "val_acc": 72.0}
{"epoch": 14, "training_loss": 223.98422634601593, "training_acc": 72.0, "val_loss": 43.72166991233826, "val_acc": 52.0}
{"epoch": 15, "training_loss": 167.5110001564026, "training_acc": 57.0, "val_loss": 15.545834600925446, "val_acc": 72.0}
{"epoch": 16, "training_loss": 87.8063817024231, "training_acc": 79.0, "val_loss": 43.91480088233948, "val_acc": 72.0}
{"epoch": 17, "training_loss": 132.44912362098694, "training_acc": 74.0, "val_loss": 30.41706681251526, "val_acc": 48.0}
{"epoch": 18, "training_loss": 114.71796417236328, "training_acc": 52.0, "val_loss": 28.100058436393738, "val_acc": 72.0}
{"epoch": 19, "training_loss": 104.43809843063354, "training_acc": 72.0, "val_loss": 26.713722944259644, "val_acc": 72.0}
{"epoch": 20, "training_loss": 83.14782547950745, "training_acc": 68.0, "val_loss": 25.763770937919617, "val_acc": 44.0}
{"epoch": 21, "training_loss": 69.99350535869598, "training_acc": 69.0, "val_loss": 41.96331799030304, "val_acc": 72.0}
{"epoch": 22, "training_loss": 116.62002635002136, "training_acc": 73.0, "val_loss": 18.404076993465424, "val_acc": 60.0}
{"epoch": 23, "training_loss": 82.5560245513916, "training_acc": 64.0, "val_loss": 18.0061012506485, "val_acc": 68.0}
{"epoch": 24, "training_loss": 55.63030433654785, "training_acc": 80.0, "val_loss": 42.45961904525757, "val_acc": 72.0}
{"epoch": 25, "training_loss": 100.5667759180069, "training_acc": 74.0, "val_loss": 24.617062509059906, "val_acc": 56.0}
{"epoch": 26, "training_loss": 67.36193907260895, "training_acc": 68.0, "val_loss": 21.26975655555725, "val_acc": 76.0}
{"epoch": 27, "training_loss": 47.24282658100128, "training_acc": 80.0, "val_loss": 18.24943572282791, "val_acc": 64.0}
{"epoch": 28, "training_loss": 37.112709045410156, "training_acc": 83.0, "val_loss": 18.84150505065918, "val_acc": 64.0}
{"epoch": 29, "training_loss": 37.62668001651764, "training_acc": 82.0, "val_loss": 19.838950037956238, "val_acc": 56.0}
{"epoch": 30, "training_loss": 37.181522727012634, "training_acc": 83.0, "val_loss": 23.586413264274597, "val_acc": 72.0}
{"epoch": 31, "training_loss": 50.086851477622986, "training_acc": 79.0, "val_loss": 18.322986364364624, "val_acc": 64.0}
{"epoch": 32, "training_loss": 34.401888370513916, "training_acc": 82.0, "val_loss": 17.66134947538376, "val_acc": 68.0}
{"epoch": 33, "training_loss": 36.146769523620605, "training_acc": 83.0, "val_loss": 18.399465084075928, "val_acc": 76.0}
{"epoch": 34, "training_loss": 35.687437415122986, "training_acc": 84.0, "val_loss": 17.55461096763611, "val_acc": 64.0}
