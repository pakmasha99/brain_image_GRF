"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 467.6549491882324, "training_acc": 49.0, "val_loss": 296.543550491333, "val_acc": 72.0}
{"epoch": 1, "training_loss": 923.4495124816895, "training_acc": 72.0, "val_loss": 72.25053310394287, "val_acc": 36.0}
{"epoch": 2, "training_loss": 326.0794258117676, "training_acc": 36.0, "val_loss": 63.2843017578125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 290.33855628967285, "training_acc": 72.0, "val_loss": 85.5622410774231, "val_acc": 72.0}
{"epoch": 4, "training_loss": 215.12101936340332, "training_acc": 74.0, "val_loss": 62.49040961265564, "val_acc": 44.0}
{"epoch": 5, "training_loss": 355.40945529937744, "training_acc": 42.0, "val_loss": 36.4471435546875, "val_acc": 72.0}
{"epoch": 6, "training_loss": 144.25630807876587, "training_acc": 73.0, "val_loss": 101.7451524734497, "val_acc": 72.0}
{"epoch": 7, "training_loss": 341.96484565734863, "training_acc": 72.0, "val_loss": 52.308475971221924, "val_acc": 76.0}
{"epoch": 8, "training_loss": 134.85537004470825, "training_acc": 69.0, "val_loss": 60.90609431266785, "val_acc": 40.0}
{"epoch": 9, "training_loss": 238.29538345336914, "training_acc": 54.0, "val_loss": 48.53570759296417, "val_acc": 72.0}
{"epoch": 10, "training_loss": 144.18022346496582, "training_acc": 73.0, "val_loss": 46.72320485115051, "val_acc": 72.0}
{"epoch": 11, "training_loss": 106.43752121925354, "training_acc": 76.0, "val_loss": 34.399643540382385, "val_acc": 48.0}
{"epoch": 12, "training_loss": 126.69911313056946, "training_acc": 58.0, "val_loss": 32.60480761528015, "val_acc": 64.0}
{"epoch": 13, "training_loss": 71.60338473320007, "training_acc": 75.0, "val_loss": 23.27568382024765, "val_acc": 56.0}
{"epoch": 14, "training_loss": 63.47025990486145, "training_acc": 65.0, "val_loss": 31.694087386131287, "val_acc": 72.0}
{"epoch": 15, "training_loss": 86.6920006275177, "training_acc": 72.0, "val_loss": 14.85414057970047, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.226011991500854, "training_acc": 71.0, "val_loss": 17.051570117473602, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.52623414993286, "training_acc": 79.0, "val_loss": 14.674502611160278, "val_acc": 76.0}
{"epoch": 18, "training_loss": 59.42083144187927, "training_acc": 73.0, "val_loss": 12.88510113954544, "val_acc": 84.0}
{"epoch": 19, "training_loss": 64.16779065132141, "training_acc": 70.0, "val_loss": 21.738722920417786, "val_acc": 72.0}
{"epoch": 20, "training_loss": 74.29514217376709, "training_acc": 67.0, "val_loss": 11.710822582244873, "val_acc": 72.0}
{"epoch": 21, "training_loss": 69.69779324531555, "training_acc": 65.0, "val_loss": 23.011741042137146, "val_acc": 72.0}
{"epoch": 22, "training_loss": 79.1260986328125, "training_acc": 64.0, "val_loss": 12.142404168844223, "val_acc": 76.0}
{"epoch": 23, "training_loss": 43.482848167419434, "training_acc": 79.0, "val_loss": 20.704756677150726, "val_acc": 72.0}
{"epoch": 24, "training_loss": 64.01488065719604, "training_acc": 71.0, "val_loss": 14.617429673671722, "val_acc": 72.0}
{"epoch": 25, "training_loss": 45.97948503494263, "training_acc": 81.0, "val_loss": 16.719146072864532, "val_acc": 72.0}
{"epoch": 26, "training_loss": 49.80060577392578, "training_acc": 75.0, "val_loss": 17.768236994743347, "val_acc": 68.0}
{"epoch": 27, "training_loss": 42.59430146217346, "training_acc": 79.0, "val_loss": 14.49022889137268, "val_acc": 68.0}
{"epoch": 28, "training_loss": 31.424316883087158, "training_acc": 88.0, "val_loss": 14.679516851902008, "val_acc": 64.0}
{"epoch": 29, "training_loss": 44.32483410835266, "training_acc": 83.0, "val_loss": 14.666284620761871, "val_acc": 68.0}
{"epoch": 30, "training_loss": 39.33283603191376, "training_acc": 83.0, "val_loss": 17.75783747434616, "val_acc": 72.0}
{"epoch": 31, "training_loss": 38.29355275630951, "training_acc": 84.0, "val_loss": 15.660512447357178, "val_acc": 68.0}
{"epoch": 32, "training_loss": 41.95836114883423, "training_acc": 82.0, "val_loss": 16.05636030435562, "val_acc": 72.0}
{"epoch": 33, "training_loss": 36.953368067741394, "training_acc": 83.0, "val_loss": 13.649231195449829, "val_acc": 68.0}
{"epoch": 34, "training_loss": 34.4001499414444, "training_acc": 86.0, "val_loss": 14.1166552901268, "val_acc": 72.0}
{"epoch": 35, "training_loss": 33.75541913509369, "training_acc": 88.0, "val_loss": 13.562333583831787, "val_acc": 64.0}
{"epoch": 36, "training_loss": 32.0799001455307, "training_acc": 88.0, "val_loss": 14.13431465625763, "val_acc": 76.0}
{"epoch": 37, "training_loss": 34.65361714363098, "training_acc": 87.0, "val_loss": 13.215552270412445, "val_acc": 64.0}
{"epoch": 38, "training_loss": 33.66686987876892, "training_acc": 87.0, "val_loss": 17.764176428318024, "val_acc": 72.0}
{"epoch": 39, "training_loss": 36.53373110294342, "training_acc": 87.0, "val_loss": 14.401237666606903, "val_acc": 68.0}
