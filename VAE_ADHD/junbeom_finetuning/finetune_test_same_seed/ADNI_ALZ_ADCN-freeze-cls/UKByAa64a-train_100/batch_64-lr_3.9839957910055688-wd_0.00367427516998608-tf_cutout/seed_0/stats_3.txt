"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7463.902484893799, "training_acc": 38.0, "val_loss": 3248.273468017578, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10326.215866088867, "training_acc": 72.0, "val_loss": 2348.5809326171875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8265.912963867188, "training_acc": 31.0, "val_loss": 622.1555709838867, "val_acc": 68.0}
{"epoch": 3, "training_loss": 2975.058624267578, "training_acc": 73.0, "val_loss": 1486.3174438476562, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4963.387741088867, "training_acc": 72.0, "val_loss": 812.9792213439941, "val_acc": 68.0}
{"epoch": 5, "training_loss": 3134.2796173095703, "training_acc": 63.0, "val_loss": 1248.0294227600098, "val_acc": 68.0}
{"epoch": 6, "training_loss": 3431.859001159668, "training_acc": 54.0, "val_loss": 815.8061027526855, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2105.7464141845703, "training_acc": 75.0, "val_loss": 792.245626449585, "val_acc": 76.0}
{"epoch": 8, "training_loss": 2277.1095123291016, "training_acc": 73.0, "val_loss": 681.6664695739746, "val_acc": 64.0}
{"epoch": 9, "training_loss": 2286.2859420776367, "training_acc": 54.0, "val_loss": 478.8037300109863, "val_acc": 68.0}
{"epoch": 10, "training_loss": 842.3391952514648, "training_acc": 74.0, "val_loss": 324.825119972229, "val_acc": 76.0}
{"epoch": 11, "training_loss": 840.4467430114746, "training_acc": 77.0, "val_loss": 718.9159870147705, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1763.9268870353699, "training_acc": 45.0, "val_loss": 276.21920108795166, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1007.4146785736084, "training_acc": 70.0, "val_loss": 581.307315826416, "val_acc": 32.0}
{"epoch": 14, "training_loss": 1801.8262901306152, "training_acc": 42.0, "val_loss": 172.42366075515747, "val_acc": 72.0}
{"epoch": 15, "training_loss": 682.2887058258057, "training_acc": 66.0, "val_loss": 122.81348705291748, "val_acc": 72.0}
{"epoch": 16, "training_loss": 350.7906002998352, "training_acc": 78.0, "val_loss": 187.4897599220276, "val_acc": 60.0}
{"epoch": 17, "training_loss": 535.3728189468384, "training_acc": 63.0, "val_loss": 111.81002855300903, "val_acc": 72.0}
{"epoch": 18, "training_loss": 253.97511672973633, "training_acc": 75.0, "val_loss": 94.02976632118225, "val_acc": 72.0}
{"epoch": 19, "training_loss": 189.61304593086243, "training_acc": 83.0, "val_loss": 144.75674629211426, "val_acc": 56.0}
{"epoch": 20, "training_loss": 545.7624931335449, "training_acc": 67.0, "val_loss": 93.6184823513031, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1094.829086303711, "training_acc": 57.0, "val_loss": 105.71266412734985, "val_acc": 72.0}
{"epoch": 22, "training_loss": 537.146821975708, "training_acc": 72.0, "val_loss": 175.7956862449646, "val_acc": 52.0}
{"epoch": 23, "training_loss": 413.5304641723633, "training_acc": 60.0, "val_loss": 153.0869722366333, "val_acc": 80.0}
{"epoch": 24, "training_loss": 462.7046813964844, "training_acc": 75.0, "val_loss": 113.05356025695801, "val_acc": 60.0}
{"epoch": 25, "training_loss": 220.5154891014099, "training_acc": 76.0, "val_loss": 92.95443296432495, "val_acc": 80.0}
{"epoch": 26, "training_loss": 335.8246192932129, "training_acc": 70.0, "val_loss": 102.9335618019104, "val_acc": 72.0}
{"epoch": 27, "training_loss": 376.85863995552063, "training_acc": 75.0, "val_loss": 23.488542437553406, "val_acc": 72.0}
{"epoch": 28, "training_loss": 60.38882565498352, "training_acc": 85.0, "val_loss": 28.775370121002197, "val_acc": 76.0}
{"epoch": 29, "training_loss": 67.65790700912476, "training_acc": 85.0, "val_loss": 164.50557708740234, "val_acc": 72.0}
{"epoch": 30, "training_loss": 493.4609228372574, "training_acc": 74.0, "val_loss": 120.71312665939331, "val_acc": 36.0}
{"epoch": 31, "training_loss": 980.0330505371094, "training_acc": 58.0, "val_loss": 398.1093168258667, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1012.2298984527588, "training_acc": 74.0, "val_loss": 1270.6735610961914, "val_acc": 28.0}
{"epoch": 33, "training_loss": 3449.312744140625, "training_acc": 30.0, "val_loss": 831.369686126709, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3884.1474609375, "training_acc": 72.0, "val_loss": 1710.4246139526367, "val_acc": 72.0}
{"epoch": 35, "training_loss": 6438.508850097656, "training_acc": 72.0, "val_loss": 1116.4862632751465, "val_acc": 72.0}
{"epoch": 36, "training_loss": 3328.924072265625, "training_acc": 74.0, "val_loss": 739.9339199066162, "val_acc": 48.0}
{"epoch": 37, "training_loss": 2547.0068130493164, "training_acc": 47.0, "val_loss": 515.510368347168, "val_acc": 68.0}
{"epoch": 38, "training_loss": 1200.93257522583, "training_acc": 75.0, "val_loss": 715.557336807251, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2320.462127685547, "training_acc": 72.0, "val_loss": 424.1150379180908, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1439.5545196533203, "training_acc": 68.0, "val_loss": 660.4665279388428, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1625.0948944091797, "training_acc": 65.0, "val_loss": 438.53116035461426, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1527.9258995056152, "training_acc": 73.0, "val_loss": 198.4189748764038, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1037.2549667358398, "training_acc": 64.0, "val_loss": 151.77282094955444, "val_acc": 68.0}
{"epoch": 44, "training_loss": 549.8183822631836, "training_acc": 76.0, "val_loss": 203.35376262664795, "val_acc": 72.0}
{"epoch": 45, "training_loss": 761.3689136505127, "training_acc": 67.0, "val_loss": 113.01723718643188, "val_acc": 68.0}
{"epoch": 46, "training_loss": 678.2458610534668, "training_acc": 65.0, "val_loss": 101.9091010093689, "val_acc": 80.0}
