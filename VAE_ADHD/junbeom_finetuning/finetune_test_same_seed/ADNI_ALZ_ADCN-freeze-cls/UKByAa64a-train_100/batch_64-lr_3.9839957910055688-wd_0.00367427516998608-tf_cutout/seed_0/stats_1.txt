"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5199.0483322143555, "training_acc": 47.0, "val_loss": 3390.924835205078, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9993.418426513672, "training_acc": 72.0, "val_loss": 3383.9561462402344, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11982.907135009766, "training_acc": 29.0, "val_loss": 448.80027770996094, "val_acc": 76.0}
{"epoch": 3, "training_loss": 2441.047966003418, "training_acc": 73.0, "val_loss": 2047.3114013671875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8153.902801513672, "training_acc": 72.0, "val_loss": 1690.2442932128906, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5641.677955627441, "training_acc": 73.0, "val_loss": 600.6320476531982, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3681.150390625, "training_acc": 57.0, "val_loss": 1110.9411239624023, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3807.959587097168, "training_acc": 61.0, "val_loss": 692.0512676239014, "val_acc": 76.0}
{"epoch": 8, "training_loss": 3007.2664184570312, "training_acc": 75.0, "val_loss": 872.1041679382324, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2799.299674987793, "training_acc": 72.0, "val_loss": 296.1771249771118, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1539.5457611083984, "training_acc": 62.0, "val_loss": 163.58484029769897, "val_acc": 68.0}
{"epoch": 11, "training_loss": 1007.7015266418457, "training_acc": 72.0, "val_loss": 325.00908374786377, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1169.05708694458, "training_acc": 58.0, "val_loss": 163.74191045761108, "val_acc": 72.0}
{"epoch": 13, "training_loss": 391.40460205078125, "training_acc": 67.0, "val_loss": 153.73187065124512, "val_acc": 64.0}
{"epoch": 14, "training_loss": 477.92944526672363, "training_acc": 60.0, "val_loss": 422.2862720489502, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1267.5898361206055, "training_acc": 72.0, "val_loss": 113.62347602844238, "val_acc": 64.0}
{"epoch": 16, "training_loss": 1133.0322341918945, "training_acc": 56.0, "val_loss": 132.75238275527954, "val_acc": 64.0}
{"epoch": 17, "training_loss": 791.787239074707, "training_acc": 78.0, "val_loss": 381.8908929824829, "val_acc": 72.0}
{"epoch": 18, "training_loss": 851.2932395935059, "training_acc": 71.0, "val_loss": 388.2251501083374, "val_acc": 56.0}
{"epoch": 19, "training_loss": 1349.0779781341553, "training_acc": 61.0, "val_loss": 426.44190788269043, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1276.2573547363281, "training_acc": 72.0, "val_loss": 192.51333475112915, "val_acc": 76.0}
{"epoch": 21, "training_loss": 783.6172065734863, "training_acc": 72.0, "val_loss": 177.15377807617188, "val_acc": 64.0}
{"epoch": 22, "training_loss": 594.0087051391602, "training_acc": 72.0, "val_loss": 310.8117341995239, "val_acc": 72.0}
{"epoch": 23, "training_loss": 760.6066093444824, "training_acc": 65.0, "val_loss": 105.5354118347168, "val_acc": 64.0}
{"epoch": 24, "training_loss": 173.22979164123535, "training_acc": 76.0, "val_loss": 260.45501232147217, "val_acc": 72.0}
{"epoch": 25, "training_loss": 514.5835113525391, "training_acc": 74.0, "val_loss": 889.7071838378906, "val_acc": 32.0}
{"epoch": 26, "training_loss": 2193.6054162979126, "training_acc": 45.0, "val_loss": 667.6031112670898, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2448.634666442871, "training_acc": 72.0, "val_loss": 718.1749820709229, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1993.6563148498535, "training_acc": 73.0, "val_loss": 807.5845718383789, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2308.6377563476562, "training_acc": 38.0, "val_loss": 502.85282135009766, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2173.4600677490234, "training_acc": 72.0, "val_loss": 791.747522354126, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2367.8137435913086, "training_acc": 72.0, "val_loss": 360.45665740966797, "val_acc": 56.0}
{"epoch": 32, "training_loss": 1903.6137466430664, "training_acc": 60.0, "val_loss": 383.7107181549072, "val_acc": 56.0}
{"epoch": 33, "training_loss": 1347.4494552612305, "training_acc": 69.0, "val_loss": 471.9714164733887, "val_acc": 80.0}
{"epoch": 34, "training_loss": 1592.244255065918, "training_acc": 75.0, "val_loss": 225.10004043579102, "val_acc": 72.0}
{"epoch": 35, "training_loss": 793.0228958129883, "training_acc": 78.0, "val_loss": 400.1880168914795, "val_acc": 56.0}
{"epoch": 36, "training_loss": 1028.977533340454, "training_acc": 62.0, "val_loss": 520.9836483001709, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2027.6396789550781, "training_acc": 72.0, "val_loss": 431.0157299041748, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1689.646900177002, "training_acc": 50.0, "val_loss": 109.64761972427368, "val_acc": 68.0}
{"epoch": 39, "training_loss": 379.17151260375977, "training_acc": 76.0, "val_loss": 317.83692836761475, "val_acc": 40.0}
{"epoch": 40, "training_loss": 690.2057447433472, "training_acc": 56.0, "val_loss": 158.38243961334229, "val_acc": 76.0}
{"epoch": 41, "training_loss": 347.8736381530762, "training_acc": 75.0, "val_loss": 163.79693746566772, "val_acc": 76.0}
{"epoch": 42, "training_loss": 332.0752167701721, "training_acc": 77.0, "val_loss": 149.31981563568115, "val_acc": 60.0}
