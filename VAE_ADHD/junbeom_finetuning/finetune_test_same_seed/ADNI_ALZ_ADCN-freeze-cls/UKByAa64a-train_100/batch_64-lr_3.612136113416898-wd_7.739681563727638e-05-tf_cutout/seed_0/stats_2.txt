"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4451.939025878906, "training_acc": 53.0, "val_loss": 2993.4959411621094, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8333.80990600586, "training_acc": 72.0, "val_loss": 2166.5740966796875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9051.38003540039, "training_acc": 29.0, "val_loss": 427.1597385406494, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2397.2534790039062, "training_acc": 75.0, "val_loss": 1925.4596710205078, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7090.371673583984, "training_acc": 72.0, "val_loss": 1542.2063827514648, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4228.51904296875, "training_acc": 70.0, "val_loss": 673.71826171875, "val_acc": 64.0}
{"epoch": 6, "training_loss": 4549.592102050781, "training_acc": 54.0, "val_loss": 883.5454940795898, "val_acc": 48.0}
{"epoch": 7, "training_loss": 3843.1723098754883, "training_acc": 61.0, "val_loss": 839.4452095031738, "val_acc": 76.0}
{"epoch": 8, "training_loss": 2717.3162384033203, "training_acc": 74.0, "val_loss": 1194.825267791748, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3528.4340286254883, "training_acc": 73.0, "val_loss": 470.5827236175537, "val_acc": 80.0}
{"epoch": 10, "training_loss": 1701.1867904663086, "training_acc": 70.0, "val_loss": 527.2132396697998, "val_acc": 56.0}
{"epoch": 11, "training_loss": 2144.3845176696777, "training_acc": 64.0, "val_loss": 513.9923572540283, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1471.7151260375977, "training_acc": 74.0, "val_loss": 399.9896764755249, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1341.4158096313477, "training_acc": 59.0, "val_loss": 163.54204416275024, "val_acc": 68.0}
{"epoch": 14, "training_loss": 988.7497711181641, "training_acc": 67.0, "val_loss": 603.41796875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1774.880666732788, "training_acc": 72.0, "val_loss": 361.66114807128906, "val_acc": 56.0}
{"epoch": 16, "training_loss": 1035.5709533691406, "training_acc": 52.0, "val_loss": 515.0467872619629, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1895.1768646240234, "training_acc": 72.0, "val_loss": 467.1010494232178, "val_acc": 72.0}
{"epoch": 18, "training_loss": 974.7849178314209, "training_acc": 74.0, "val_loss": 341.1216974258423, "val_acc": 48.0}
{"epoch": 19, "training_loss": 1152.7454271316528, "training_acc": 56.0, "val_loss": 459.82728004455566, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1256.3328590393066, "training_acc": 72.0, "val_loss": 207.80868530273438, "val_acc": 72.0}
{"epoch": 21, "training_loss": 814.6880722045898, "training_acc": 76.0, "val_loss": 187.507164478302, "val_acc": 64.0}
{"epoch": 22, "training_loss": 973.0978469848633, "training_acc": 66.0, "val_loss": 502.65517234802246, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1144.8519325256348, "training_acc": 74.0, "val_loss": 147.9498267173767, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1082.012565612793, "training_acc": 58.0, "val_loss": 262.24026679992676, "val_acc": 72.0}
{"epoch": 25, "training_loss": 835.7961502075195, "training_acc": 74.0, "val_loss": 239.7026538848877, "val_acc": 72.0}
{"epoch": 26, "training_loss": 688.2135810852051, "training_acc": 68.0, "val_loss": 186.3086462020874, "val_acc": 56.0}
{"epoch": 27, "training_loss": 877.1232414245605, "training_acc": 60.0, "val_loss": 472.73807525634766, "val_acc": 72.0}
{"epoch": 28, "training_loss": 915.7568607330322, "training_acc": 77.0, "val_loss": 197.76519536972046, "val_acc": 60.0}
{"epoch": 29, "training_loss": 853.702392578125, "training_acc": 62.0, "val_loss": 250.01707077026367, "val_acc": 68.0}
{"epoch": 30, "training_loss": 485.3380489349365, "training_acc": 80.0, "val_loss": 395.4573631286621, "val_acc": 72.0}
{"epoch": 31, "training_loss": 655.929515838623, "training_acc": 81.0, "val_loss": 221.90380096435547, "val_acc": 56.0}
{"epoch": 32, "training_loss": 800.2922439575195, "training_acc": 63.0, "val_loss": 311.39001846313477, "val_acc": 72.0}
{"epoch": 33, "training_loss": 960.5626182556152, "training_acc": 75.0, "val_loss": 255.2353858947754, "val_acc": 72.0}
{"epoch": 34, "training_loss": 877.5803298950195, "training_acc": 64.0, "val_loss": 123.35549592971802, "val_acc": 68.0}
{"epoch": 35, "training_loss": 355.1990566253662, "training_acc": 80.0, "val_loss": 108.59521627426147, "val_acc": 72.0}
{"epoch": 36, "training_loss": 317.74715423583984, "training_acc": 82.0, "val_loss": 146.78977727890015, "val_acc": 72.0}
{"epoch": 37, "training_loss": 321.45276069641113, "training_acc": 79.0, "val_loss": 57.16925263404846, "val_acc": 68.0}
{"epoch": 38, "training_loss": 281.42453479766846, "training_acc": 74.0, "val_loss": 50.85430145263672, "val_acc": 76.0}
{"epoch": 39, "training_loss": 122.54220724105835, "training_acc": 83.0, "val_loss": 121.67348861694336, "val_acc": 72.0}
{"epoch": 40, "training_loss": 137.39044046401978, "training_acc": 83.0, "val_loss": 251.39822959899902, "val_acc": 44.0}
{"epoch": 41, "training_loss": 910.9226884841919, "training_acc": 54.0, "val_loss": 218.6128854751587, "val_acc": 72.0}
{"epoch": 42, "training_loss": 399.23786449432373, "training_acc": 75.0, "val_loss": 75.60560703277588, "val_acc": 68.0}
{"epoch": 43, "training_loss": 501.161169052124, "training_acc": 64.0, "val_loss": 195.25201320648193, "val_acc": 72.0}
{"epoch": 44, "training_loss": 588.2728366851807, "training_acc": 72.0, "val_loss": 113.4982705116272, "val_acc": 72.0}
{"epoch": 45, "training_loss": 376.6858882904053, "training_acc": 75.0, "val_loss": 426.4493942260742, "val_acc": 72.0}
{"epoch": 46, "training_loss": 872.847993850708, "training_acc": 78.0, "val_loss": 144.19111013412476, "val_acc": 72.0}
{"epoch": 47, "training_loss": 551.0629825592041, "training_acc": 68.0, "val_loss": 310.72819232940674, "val_acc": 72.0}
{"epoch": 48, "training_loss": 775.6076698303223, "training_acc": 76.0, "val_loss": 138.82685899734497, "val_acc": 68.0}
{"epoch": 49, "training_loss": 797.9871673583984, "training_acc": 68.0, "val_loss": 163.30360174179077, "val_acc": 68.0}
{"epoch": 50, "training_loss": 538.5586814880371, "training_acc": 82.0, "val_loss": 363.0666971206665, "val_acc": 72.0}
{"epoch": 51, "training_loss": 541.4952051639557, "training_acc": 76.0, "val_loss": 380.2133798599243, "val_acc": 44.0}
{"epoch": 52, "training_loss": 1253.8959827423096, "training_acc": 57.0, "val_loss": 332.1638345718384, "val_acc": 72.0}
{"epoch": 53, "training_loss": 594.0338401794434, "training_acc": 79.0, "val_loss": 178.50735187530518, "val_acc": 72.0}
{"epoch": 54, "training_loss": 380.5526170730591, "training_acc": 73.0, "val_loss": 181.05837106704712, "val_acc": 68.0}
{"epoch": 55, "training_loss": 242.4161777496338, "training_acc": 83.0, "val_loss": 139.70202207565308, "val_acc": 72.0}
{"epoch": 56, "training_loss": 157.38505935668945, "training_acc": 83.0, "val_loss": 160.72317361831665, "val_acc": 68.0}
{"epoch": 57, "training_loss": 227.4986696243286, "training_acc": 84.0, "val_loss": 106.51612281799316, "val_acc": 64.0}
