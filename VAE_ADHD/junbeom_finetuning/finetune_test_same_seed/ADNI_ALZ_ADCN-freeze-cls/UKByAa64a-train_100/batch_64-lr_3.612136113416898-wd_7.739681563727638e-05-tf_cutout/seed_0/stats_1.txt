"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5793.985664367676, "training_acc": 72.0, "val_loss": 2453.7988662719727, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6694.838300704956, "training_acc": 72.0, "val_loss": 3764.9791717529297, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11987.773406982422, "training_acc": 28.0, "val_loss": 924.5282173156738, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5091.773773193359, "training_acc": 72.0, "val_loss": 2325.203514099121, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8605.390167236328, "training_acc": 72.0, "val_loss": 1592.5650596618652, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4858.7484130859375, "training_acc": 72.0, "val_loss": 908.9476585388184, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5294.1627197265625, "training_acc": 44.0, "val_loss": 1030.4936408996582, "val_acc": 60.0}
{"epoch": 7, "training_loss": 3129.689416885376, "training_acc": 59.0, "val_loss": 817.8962707519531, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3801.404525756836, "training_acc": 73.0, "val_loss": 1125.5695343017578, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4213.504577636719, "training_acc": 72.0, "val_loss": 431.4089298248291, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2149.8997802734375, "training_acc": 70.0, "val_loss": 892.690372467041, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2681.082229614258, "training_acc": 59.0, "val_loss": 316.38524532318115, "val_acc": 76.0}
{"epoch": 12, "training_loss": 1563.2523040771484, "training_acc": 74.0, "val_loss": 566.4334774017334, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1784.1305656433105, "training_acc": 73.0, "val_loss": 213.10625076293945, "val_acc": 60.0}
{"epoch": 14, "training_loss": 1284.391830444336, "training_acc": 68.0, "val_loss": 240.01479148864746, "val_acc": 56.0}
{"epoch": 15, "training_loss": 881.706916809082, "training_acc": 66.0, "val_loss": 420.5535411834717, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1014.5909776687622, "training_acc": 73.0, "val_loss": 778.6922454833984, "val_acc": 40.0}
{"epoch": 17, "training_loss": 1777.7824459075928, "training_acc": 43.0, "val_loss": 706.1741828918457, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2736.8718032836914, "training_acc": 72.0, "val_loss": 1033.0004692077637, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3117.0879669189453, "training_acc": 72.0, "val_loss": 100.94261169433594, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1430.9075622558594, "training_acc": 54.0, "val_loss": 252.30810642242432, "val_acc": 44.0}
{"epoch": 21, "training_loss": 1235.0997619628906, "training_acc": 61.0, "val_loss": 889.9374008178711, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3099.7012481689453, "training_acc": 72.0, "val_loss": 453.43017578125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1278.795581817627, "training_acc": 70.0, "val_loss": 492.280912399292, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1578.9630851745605, "training_acc": 62.0, "val_loss": 286.5605592727661, "val_acc": 76.0}
{"epoch": 25, "training_loss": 1079.4062690734863, "training_acc": 75.0, "val_loss": 349.9011754989624, "val_acc": 76.0}
{"epoch": 26, "training_loss": 1150.4437294006348, "training_acc": 74.0, "val_loss": 325.958514213562, "val_acc": 56.0}
{"epoch": 27, "training_loss": 900.7240619659424, "training_acc": 65.0, "val_loss": 251.4411211013794, "val_acc": 76.0}
{"epoch": 28, "training_loss": 734.8150119781494, "training_acc": 78.0, "val_loss": 159.77109670639038, "val_acc": 76.0}
{"epoch": 29, "training_loss": 332.1438674926758, "training_acc": 76.0, "val_loss": 152.52305269241333, "val_acc": 52.0}
{"epoch": 30, "training_loss": 335.6654224395752, "training_acc": 75.0, "val_loss": 285.42723655700684, "val_acc": 72.0}
{"epoch": 31, "training_loss": 659.3455905914307, "training_acc": 63.0, "val_loss": 152.56577730178833, "val_acc": 76.0}
{"epoch": 32, "training_loss": 153.7934970855713, "training_acc": 84.0, "val_loss": 114.67339992523193, "val_acc": 68.0}
{"epoch": 33, "training_loss": 156.8926568031311, "training_acc": 80.0, "val_loss": 161.5447759628296, "val_acc": 76.0}
{"epoch": 34, "training_loss": 230.66047048568726, "training_acc": 82.0, "val_loss": 125.29435157775879, "val_acc": 52.0}
{"epoch": 35, "training_loss": 117.16851162910461, "training_acc": 86.0, "val_loss": 121.07462882995605, "val_acc": 60.0}
{"epoch": 36, "training_loss": 152.65696144104004, "training_acc": 78.0, "val_loss": 198.69393110275269, "val_acc": 48.0}
{"epoch": 37, "training_loss": 237.56274366378784, "training_acc": 76.0, "val_loss": 134.26225185394287, "val_acc": 76.0}
{"epoch": 38, "training_loss": 176.87089824676514, "training_acc": 86.0, "val_loss": 109.69382524490356, "val_acc": 68.0}
