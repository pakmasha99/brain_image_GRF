"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4660.165630340576, "training_acc": 46.0, "val_loss": 1939.9545669555664, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6825.64009475708, "training_acc": 72.0, "val_loss": 1777.5354385375977, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5853.109573364258, "training_acc": 29.0, "val_loss": 406.510066986084, "val_acc": 76.0}
{"epoch": 3, "training_loss": 2078.178741455078, "training_acc": 72.0, "val_loss": 1090.8230781555176, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3958.789810180664, "training_acc": 72.0, "val_loss": 597.8738307952881, "val_acc": 76.0}
{"epoch": 5, "training_loss": 1480.243179321289, "training_acc": 75.0, "val_loss": 895.8429336547852, "val_acc": 48.0}
{"epoch": 6, "training_loss": 3129.8637619018555, "training_acc": 44.0, "val_loss": 602.5826454162598, "val_acc": 68.0}
{"epoch": 7, "training_loss": 1478.027931213379, "training_acc": 74.0, "val_loss": 838.111400604248, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3249.640884399414, "training_acc": 72.0, "val_loss": 675.1061916351318, "val_acc": 68.0}
{"epoch": 9, "training_loss": 1764.7653579711914, "training_acc": 74.0, "val_loss": 696.4094161987305, "val_acc": 68.0}
{"epoch": 10, "training_loss": 2161.9838638305664, "training_acc": 49.0, "val_loss": 609.0285301208496, "val_acc": 68.0}
{"epoch": 11, "training_loss": 1667.7468872070312, "training_acc": 61.0, "val_loss": 461.5364074707031, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1500.425895690918, "training_acc": 73.0, "val_loss": 363.4883403778076, "val_acc": 72.0}
{"epoch": 13, "training_loss": 924.8440589904785, "training_acc": 69.0, "val_loss": 427.06995010375977, "val_acc": 60.0}
{"epoch": 14, "training_loss": 990.325870513916, "training_acc": 59.0, "val_loss": 200.9061574935913, "val_acc": 76.0}
{"epoch": 15, "training_loss": 778.4203948974609, "training_acc": 72.0, "val_loss": 101.43154859542847, "val_acc": 68.0}
{"epoch": 16, "training_loss": 458.6986713409424, "training_acc": 63.0, "val_loss": 73.42754006385803, "val_acc": 68.0}
{"epoch": 17, "training_loss": 317.3971347808838, "training_acc": 73.0, "val_loss": 80.90934753417969, "val_acc": 76.0}
{"epoch": 18, "training_loss": 581.4384384155273, "training_acc": 63.0, "val_loss": 58.66392254829407, "val_acc": 80.0}
{"epoch": 19, "training_loss": 284.98931884765625, "training_acc": 74.0, "val_loss": 177.98434495925903, "val_acc": 48.0}
{"epoch": 20, "training_loss": 470.24516201019287, "training_acc": 59.0, "val_loss": 164.97827768325806, "val_acc": 72.0}
{"epoch": 21, "training_loss": 559.9743175506592, "training_acc": 72.0, "val_loss": 132.899272441864, "val_acc": 60.0}
{"epoch": 22, "training_loss": 483.93160820007324, "training_acc": 64.0, "val_loss": 135.7628345489502, "val_acc": 84.0}
{"epoch": 23, "training_loss": 444.84978008270264, "training_acc": 79.0, "val_loss": 106.7929744720459, "val_acc": 76.0}
{"epoch": 24, "training_loss": 321.96506118774414, "training_acc": 70.0, "val_loss": 91.69095158576965, "val_acc": 76.0}
{"epoch": 25, "training_loss": 316.5856742858887, "training_acc": 78.0, "val_loss": 87.49671578407288, "val_acc": 60.0}
{"epoch": 26, "training_loss": 237.89573287963867, "training_acc": 72.0, "val_loss": 27.64512300491333, "val_acc": 80.0}
{"epoch": 27, "training_loss": 185.78890132904053, "training_acc": 72.0, "val_loss": 142.7345871925354, "val_acc": 72.0}
{"epoch": 28, "training_loss": 649.9494667053223, "training_acc": 72.0, "val_loss": 177.05312967300415, "val_acc": 40.0}
{"epoch": 29, "training_loss": 341.2056350708008, "training_acc": 65.0, "val_loss": 22.243648767471313, "val_acc": 64.0}
{"epoch": 30, "training_loss": 244.47086906433105, "training_acc": 67.0, "val_loss": 68.37426424026489, "val_acc": 72.0}
{"epoch": 31, "training_loss": 254.35408425331116, "training_acc": 77.0, "val_loss": 83.81379246711731, "val_acc": 64.0}
{"epoch": 32, "training_loss": 226.10443353652954, "training_acc": 77.0, "val_loss": 95.14284133911133, "val_acc": 80.0}
{"epoch": 33, "training_loss": 286.900203704834, "training_acc": 78.0, "val_loss": 172.70373106002808, "val_acc": 48.0}
{"epoch": 34, "training_loss": 455.4637908935547, "training_acc": 66.0, "val_loss": 74.78938698768616, "val_acc": 80.0}
{"epoch": 35, "training_loss": 210.01147150993347, "training_acc": 80.0, "val_loss": 159.99250411987305, "val_acc": 40.0}
{"epoch": 36, "training_loss": 360.6005115509033, "training_acc": 61.0, "val_loss": 56.54158592224121, "val_acc": 72.0}
{"epoch": 37, "training_loss": 577.0534591674805, "training_acc": 55.0, "val_loss": 55.0734281539917, "val_acc": 80.0}
{"epoch": 38, "training_loss": 342.92436122894287, "training_acc": 74.0, "val_loss": 51.892322301864624, "val_acc": 64.0}
{"epoch": 39, "training_loss": 241.06314659118652, "training_acc": 73.0, "val_loss": 62.751686573028564, "val_acc": 76.0}
{"epoch": 40, "training_loss": 308.07729721069336, "training_acc": 77.0, "val_loss": 93.1122899055481, "val_acc": 64.0}
{"epoch": 41, "training_loss": 322.2678642272949, "training_acc": 72.0, "val_loss": 125.39846897125244, "val_acc": 76.0}
{"epoch": 42, "training_loss": 577.406795501709, "training_acc": 73.0, "val_loss": 65.29980301856995, "val_acc": 76.0}
{"epoch": 43, "training_loss": 448.6659736633301, "training_acc": 73.0, "val_loss": 59.86354947090149, "val_acc": 80.0}
{"epoch": 44, "training_loss": 384.6229248046875, "training_acc": 76.0, "val_loss": 66.69126749038696, "val_acc": 84.0}
{"epoch": 45, "training_loss": 330.5273914337158, "training_acc": 74.0, "val_loss": 53.961020708084106, "val_acc": 64.0}
{"epoch": 46, "training_loss": 200.8529987335205, "training_acc": 81.0, "val_loss": 29.167228937149048, "val_acc": 76.0}
{"epoch": 47, "training_loss": 291.61029052734375, "training_acc": 71.0, "val_loss": 89.32190537452698, "val_acc": 72.0}
{"epoch": 48, "training_loss": 382.56973457336426, "training_acc": 74.0, "val_loss": 32.24656581878662, "val_acc": 76.0}
