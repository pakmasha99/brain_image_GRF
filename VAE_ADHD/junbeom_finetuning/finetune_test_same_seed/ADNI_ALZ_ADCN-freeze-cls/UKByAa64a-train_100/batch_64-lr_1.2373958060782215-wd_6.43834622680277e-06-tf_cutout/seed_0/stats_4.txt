"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1286.8567428588867, "training_acc": 72.0, "val_loss": 846.3547706604004, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2062.5238456726074, "training_acc": 72.0, "val_loss": 1601.540756225586, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6550.299102783203, "training_acc": 28.0, "val_loss": 141.9334888458252, "val_acc": 60.0}
{"epoch": 3, "training_loss": 1239.6962814331055, "training_acc": 64.0, "val_loss": 967.9677963256836, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3904.875762939453, "training_acc": 72.0, "val_loss": 1143.0956840515137, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4106.315475463867, "training_acc": 72.0, "val_loss": 793.3112144470215, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2096.925922393799, "training_acc": 73.0, "val_loss": 247.50895500183105, "val_acc": 60.0}
{"epoch": 7, "training_loss": 1649.1436767578125, "training_acc": 55.0, "val_loss": 491.83926582336426, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2381.992515563965, "training_acc": 44.0, "val_loss": 289.5770311355591, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1163.47802734375, "training_acc": 71.0, "val_loss": 651.7695903778076, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2067.423065185547, "training_acc": 72.0, "val_loss": 580.5633544921875, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1327.142318725586, "training_acc": 77.0, "val_loss": 261.270809173584, "val_acc": 72.0}
{"epoch": 12, "training_loss": 864.0695114135742, "training_acc": 72.0, "val_loss": 275.14946460723877, "val_acc": 56.0}
{"epoch": 13, "training_loss": 1459.7400550842285, "training_acc": 55.0, "val_loss": 204.45878505706787, "val_acc": 72.0}
{"epoch": 14, "training_loss": 758.2830810546875, "training_acc": 75.0, "val_loss": 430.8868885040283, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1357.3735427856445, "training_acc": 72.0, "val_loss": 308.81543159484863, "val_acc": 72.0}
{"epoch": 16, "training_loss": 811.3100337982178, "training_acc": 68.0, "val_loss": 159.52765941619873, "val_acc": 56.0}
{"epoch": 17, "training_loss": 808.4427127838135, "training_acc": 52.0, "val_loss": 75.27273893356323, "val_acc": 72.0}
{"epoch": 18, "training_loss": 371.6501808166504, "training_acc": 74.0, "val_loss": 137.77939081192017, "val_acc": 72.0}
{"epoch": 19, "training_loss": 380.67125701904297, "training_acc": 69.0, "val_loss": 163.74268531799316, "val_acc": 44.0}
{"epoch": 20, "training_loss": 505.18409729003906, "training_acc": 52.0, "val_loss": 146.8503713607788, "val_acc": 72.0}
{"epoch": 21, "training_loss": 610.2055358886719, "training_acc": 72.0, "val_loss": 141.25765562057495, "val_acc": 72.0}
{"epoch": 22, "training_loss": 504.4772434234619, "training_acc": 66.0, "val_loss": 139.0873670578003, "val_acc": 40.0}
{"epoch": 23, "training_loss": 423.20888471603394, "training_acc": 63.0, "val_loss": 90.71778059005737, "val_acc": 72.0}
{"epoch": 24, "training_loss": 274.5510606765747, "training_acc": 77.0, "val_loss": 21.711982786655426, "val_acc": 68.0}
{"epoch": 25, "training_loss": 249.21830558776855, "training_acc": 63.0, "val_loss": 58.68405103683472, "val_acc": 76.0}
{"epoch": 26, "training_loss": 260.4544973373413, "training_acc": 77.0, "val_loss": 77.47386693954468, "val_acc": 72.0}
{"epoch": 27, "training_loss": 170.67026376724243, "training_acc": 79.0, "val_loss": 101.33007764816284, "val_acc": 48.0}
{"epoch": 28, "training_loss": 353.0955810546875, "training_acc": 59.0, "val_loss": 120.28472423553467, "val_acc": 72.0}
{"epoch": 29, "training_loss": 358.0505037307739, "training_acc": 72.0, "val_loss": 28.01365852355957, "val_acc": 64.0}
{"epoch": 30, "training_loss": 199.08076572418213, "training_acc": 66.0, "val_loss": 43.62868368625641, "val_acc": 76.0}
{"epoch": 31, "training_loss": 127.6761269569397, "training_acc": 80.0, "val_loss": 31.56742751598358, "val_acc": 76.0}
{"epoch": 32, "training_loss": 125.027756690979, "training_acc": 73.0, "val_loss": 23.505879938602448, "val_acc": 80.0}
{"epoch": 33, "training_loss": 97.14938473701477, "training_acc": 79.0, "val_loss": 13.472145795822144, "val_acc": 76.0}
{"epoch": 34, "training_loss": 74.67458963394165, "training_acc": 77.0, "val_loss": 32.72643983364105, "val_acc": 76.0}
{"epoch": 35, "training_loss": 75.61176228523254, "training_acc": 75.0, "val_loss": 50.20779371261597, "val_acc": 72.0}
{"epoch": 36, "training_loss": 113.3094642162323, "training_acc": 78.0, "val_loss": 81.2134861946106, "val_acc": 40.0}
{"epoch": 37, "training_loss": 268.22617197036743, "training_acc": 58.0, "val_loss": 55.47019839286804, "val_acc": 76.0}
{"epoch": 38, "training_loss": 127.86567711830139, "training_acc": 76.0, "val_loss": 29.873603582382202, "val_acc": 60.0}
{"epoch": 39, "training_loss": 138.84834051132202, "training_acc": 68.0, "val_loss": 81.99043273925781, "val_acc": 72.0}
{"epoch": 40, "training_loss": 128.5639214515686, "training_acc": 80.0, "val_loss": 61.92119121551514, "val_acc": 48.0}
{"epoch": 41, "training_loss": 238.6137809753418, "training_acc": 61.0, "val_loss": 84.25058722496033, "val_acc": 76.0}
{"epoch": 42, "training_loss": 129.16863191127777, "training_acc": 84.0, "val_loss": 56.90615773200989, "val_acc": 52.0}
{"epoch": 43, "training_loss": 247.95502400398254, "training_acc": 65.0, "val_loss": 76.12751722335815, "val_acc": 72.0}
{"epoch": 44, "training_loss": 150.1212005019188, "training_acc": 79.0, "val_loss": 26.878371834754944, "val_acc": 60.0}
{"epoch": 45, "training_loss": 66.63094758987427, "training_acc": 81.0, "val_loss": 51.141124963760376, "val_acc": 72.0}
{"epoch": 46, "training_loss": 71.89775812625885, "training_acc": 83.0, "val_loss": 54.03861999511719, "val_acc": 48.0}
{"epoch": 47, "training_loss": 236.11943531036377, "training_acc": 60.0, "val_loss": 96.79015278816223, "val_acc": 72.0}
{"epoch": 48, "training_loss": 222.08816742897034, "training_acc": 72.0, "val_loss": 62.07978129386902, "val_acc": 44.0}
{"epoch": 49, "training_loss": 175.30162739753723, "training_acc": 68.0, "val_loss": 121.6970682144165, "val_acc": 72.0}
{"epoch": 50, "training_loss": 280.3525159358978, "training_acc": 77.0, "val_loss": 42.58972704410553, "val_acc": 72.0}
{"epoch": 51, "training_loss": 169.91542720794678, "training_acc": 73.0, "val_loss": 99.94245171546936, "val_acc": 72.0}
{"epoch": 52, "training_loss": 225.35276222229004, "training_acc": 78.0, "val_loss": 50.80491900444031, "val_acc": 76.0}
