"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3877.766891479492, "training_acc": 42.0, "val_loss": 2046.8072891235352, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7135.976638793945, "training_acc": 72.0, "val_loss": 449.79190826416016, "val_acc": 36.0}
{"epoch": 2, "training_loss": 2299.2300720214844, "training_acc": 42.0, "val_loss": 544.2605972290039, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2102.9648513793945, "training_acc": 72.0, "val_loss": 790.6717300415039, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2160.908866882324, "training_acc": 72.0, "val_loss": 285.2130889892578, "val_acc": 64.0}
{"epoch": 5, "training_loss": 1594.9926261901855, "training_acc": 60.0, "val_loss": 252.97932624816895, "val_acc": 64.0}
{"epoch": 6, "training_loss": 1153.3177452087402, "training_acc": 70.0, "val_loss": 461.61909103393555, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1292.5736637115479, "training_acc": 74.0, "val_loss": 130.1186442375183, "val_acc": 64.0}
{"epoch": 8, "training_loss": 900.3462409973145, "training_acc": 61.0, "val_loss": 88.91931176185608, "val_acc": 76.0}
{"epoch": 9, "training_loss": 531.809700012207, "training_acc": 74.0, "val_loss": 60.176604986190796, "val_acc": 68.0}
{"epoch": 10, "training_loss": 960.200569152832, "training_acc": 59.0, "val_loss": 181.84269666671753, "val_acc": 44.0}
{"epoch": 11, "training_loss": 592.4497661590576, "training_acc": 66.0, "val_loss": 619.3431854248047, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2887.918716430664, "training_acc": 72.0, "val_loss": 479.26154136657715, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1574.708688735962, "training_acc": 72.0, "val_loss": 860.1118087768555, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3115.997627258301, "training_acc": 29.0, "val_loss": 114.8226261138916, "val_acc": 76.0}
{"epoch": 15, "training_loss": 702.1238021850586, "training_acc": 73.0, "val_loss": 617.5125598907471, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2078.0843086242676, "training_acc": 72.0, "val_loss": 353.1700372695923, "val_acc": 72.0}
{"epoch": 17, "training_loss": 860.7802925109863, "training_acc": 75.0, "val_loss": 349.690580368042, "val_acc": 56.0}
{"epoch": 18, "training_loss": 1749.1585807800293, "training_acc": 54.0, "val_loss": 255.9683322906494, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1040.7099533081055, "training_acc": 72.0, "val_loss": 652.037239074707, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2200.1687393188477, "training_acc": 72.0, "val_loss": 405.8915615081787, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1090.387825012207, "training_acc": 73.0, "val_loss": 387.99760341644287, "val_acc": 44.0}
{"epoch": 22, "training_loss": 1473.3225402832031, "training_acc": 53.0, "val_loss": 180.3002119064331, "val_acc": 76.0}
{"epoch": 23, "training_loss": 853.8536529541016, "training_acc": 74.0, "val_loss": 292.9368734359741, "val_acc": 72.0}
{"epoch": 24, "training_loss": 684.1836128234863, "training_acc": 75.0, "val_loss": 350.88326930999756, "val_acc": 36.0}
{"epoch": 25, "training_loss": 1295.4409265518188, "training_acc": 49.0, "val_loss": 143.10983419418335, "val_acc": 76.0}
{"epoch": 26, "training_loss": 439.4147653579712, "training_acc": 76.0, "val_loss": 59.84293222427368, "val_acc": 76.0}
{"epoch": 27, "training_loss": 419.45801544189453, "training_acc": 69.0, "val_loss": 24.433106184005737, "val_acc": 80.0}
{"epoch": 28, "training_loss": 359.5628128051758, "training_acc": 74.0, "val_loss": 110.22377014160156, "val_acc": 72.0}
{"epoch": 29, "training_loss": 526.9061164855957, "training_acc": 61.0, "val_loss": 40.582141280174255, "val_acc": 60.0}
{"epoch": 30, "training_loss": 319.43184089660645, "training_acc": 80.0, "val_loss": 192.64609813690186, "val_acc": 72.0}
{"epoch": 31, "training_loss": 565.5829782485962, "training_acc": 74.0, "val_loss": 187.7815842628479, "val_acc": 48.0}
{"epoch": 32, "training_loss": 457.6229729652405, "training_acc": 65.0, "val_loss": 121.0107684135437, "val_acc": 72.0}
{"epoch": 33, "training_loss": 412.22535133361816, "training_acc": 74.0, "val_loss": 131.00639581680298, "val_acc": 48.0}
{"epoch": 34, "training_loss": 386.246639251709, "training_acc": 63.0, "val_loss": 142.92428493499756, "val_acc": 72.0}
{"epoch": 35, "training_loss": 462.13534927368164, "training_acc": 75.0, "val_loss": 37.925684452056885, "val_acc": 84.0}
{"epoch": 36, "training_loss": 334.8872013092041, "training_acc": 73.0, "val_loss": 58.866697549819946, "val_acc": 76.0}
{"epoch": 37, "training_loss": 307.1410617828369, "training_acc": 76.0, "val_loss": 86.16551160812378, "val_acc": 80.0}
{"epoch": 38, "training_loss": 241.7450008392334, "training_acc": 76.0, "val_loss": 49.881353974342346, "val_acc": 60.0}
{"epoch": 39, "training_loss": 268.27302837371826, "training_acc": 77.0, "val_loss": 187.02460527420044, "val_acc": 72.0}
{"epoch": 40, "training_loss": 454.584010720253, "training_acc": 75.0, "val_loss": 168.82156133651733, "val_acc": 44.0}
{"epoch": 41, "training_loss": 466.76559352874756, "training_acc": 60.0, "val_loss": 111.5612268447876, "val_acc": 72.0}
{"epoch": 42, "training_loss": 209.39784932136536, "training_acc": 80.0, "val_loss": 52.98002362251282, "val_acc": 60.0}
{"epoch": 43, "training_loss": 128.0029957294464, "training_acc": 80.0, "val_loss": 80.2036702632904, "val_acc": 80.0}
{"epoch": 44, "training_loss": 121.33707809448242, "training_acc": 86.0, "val_loss": 65.51040410995483, "val_acc": 60.0}
{"epoch": 45, "training_loss": 321.231707572937, "training_acc": 66.0, "val_loss": 106.63751363754272, "val_acc": 72.0}
{"epoch": 46, "training_loss": 348.714204788208, "training_acc": 66.0, "val_loss": 45.550647377967834, "val_acc": 88.0}
