"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 615.4429588317871, "training_acc": 57.0, "val_loss": 320.2521085739136, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1057.7259449958801, "training_acc": 72.0, "val_loss": 376.01449489593506, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1298.1494255065918, "training_acc": 28.0, "val_loss": 46.91981375217438, "val_acc": 72.0}
{"epoch": 3, "training_loss": 267.3291072845459, "training_acc": 77.0, "val_loss": 215.50838947296143, "val_acc": 72.0}
{"epoch": 4, "training_loss": 824.812406539917, "training_acc": 72.0, "val_loss": 174.32403564453125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 620.9195346832275, "training_acc": 72.0, "val_loss": 60.32044291496277, "val_acc": 64.0}
{"epoch": 6, "training_loss": 343.14874267578125, "training_acc": 64.0, "val_loss": 157.17896223068237, "val_acc": 52.0}
{"epoch": 7, "training_loss": 589.3994274139404, "training_acc": 50.0, "val_loss": 66.9944167137146, "val_acc": 72.0}
{"epoch": 8, "training_loss": 321.6150302886963, "training_acc": 76.0, "val_loss": 133.71680974960327, "val_acc": 72.0}
{"epoch": 9, "training_loss": 494.19492530822754, "training_acc": 72.0, "val_loss": 59.47695970535278, "val_acc": 76.0}
{"epoch": 10, "training_loss": 200.78564929962158, "training_acc": 73.0, "val_loss": 98.37133288383484, "val_acc": 60.0}
{"epoch": 11, "training_loss": 382.7371349334717, "training_acc": 49.0, "val_loss": 33.97799730300903, "val_acc": 64.0}
{"epoch": 12, "training_loss": 163.23071575164795, "training_acc": 72.0, "val_loss": 98.98202419281006, "val_acc": 72.0}
{"epoch": 13, "training_loss": 332.72056579589844, "training_acc": 72.0, "val_loss": 32.364317774772644, "val_acc": 76.0}
{"epoch": 14, "training_loss": 177.43034648895264, "training_acc": 63.0, "val_loss": 46.670180559158325, "val_acc": 56.0}
{"epoch": 15, "training_loss": 115.99862861633301, "training_acc": 61.0, "val_loss": 64.4244909286499, "val_acc": 72.0}
{"epoch": 16, "training_loss": 207.890362739563, "training_acc": 72.0, "val_loss": 23.02316278219223, "val_acc": 64.0}
{"epoch": 17, "training_loss": 167.25026607513428, "training_acc": 55.0, "val_loss": 32.08021521568298, "val_acc": 44.0}
{"epoch": 18, "training_loss": 108.98498392105103, "training_acc": 64.0, "val_loss": 97.35051989555359, "val_acc": 72.0}
{"epoch": 19, "training_loss": 313.6342496871948, "training_acc": 72.0, "val_loss": 47.816917300224304, "val_acc": 72.0}
{"epoch": 20, "training_loss": 157.46530199050903, "training_acc": 61.0, "val_loss": 49.17535185813904, "val_acc": 40.0}
{"epoch": 21, "training_loss": 130.02499866485596, "training_acc": 59.0, "val_loss": 55.03968596458435, "val_acc": 72.0}
{"epoch": 22, "training_loss": 158.15125560760498, "training_acc": 72.0, "val_loss": 23.825979232788086, "val_acc": 64.0}
{"epoch": 23, "training_loss": 107.15323495864868, "training_acc": 69.0, "val_loss": 30.694571137428284, "val_acc": 64.0}
{"epoch": 24, "training_loss": 75.439129114151, "training_acc": 71.0, "val_loss": 40.84685742855072, "val_acc": 76.0}
{"epoch": 25, "training_loss": 120.37745523452759, "training_acc": 77.0, "val_loss": 24.52288568019867, "val_acc": 64.0}
{"epoch": 26, "training_loss": 62.40002202987671, "training_acc": 78.0, "val_loss": 37.11067736148834, "val_acc": 52.0}
{"epoch": 27, "training_loss": 80.50744295120239, "training_acc": 69.0, "val_loss": 44.6552574634552, "val_acc": 72.0}
{"epoch": 28, "training_loss": 114.21418237686157, "training_acc": 72.0, "val_loss": 28.763729333877563, "val_acc": 36.0}
{"epoch": 29, "training_loss": 77.11647891998291, "training_acc": 64.0, "val_loss": 38.03308308124542, "val_acc": 72.0}
{"epoch": 30, "training_loss": 101.27144765853882, "training_acc": 72.0, "val_loss": 26.567289233207703, "val_acc": 52.0}
{"epoch": 31, "training_loss": 81.39785671234131, "training_acc": 68.0, "val_loss": 25.250136852264404, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.2757785320282, "training_acc": 81.0, "val_loss": 33.22819769382477, "val_acc": 76.0}
{"epoch": 33, "training_loss": 69.09612548351288, "training_acc": 74.0, "val_loss": 42.779648303985596, "val_acc": 56.0}
{"epoch": 34, "training_loss": 114.23218393325806, "training_acc": 71.0, "val_loss": 44.653815031051636, "val_acc": 76.0}
{"epoch": 35, "training_loss": 104.55251133441925, "training_acc": 75.0, "val_loss": 26.392272114753723, "val_acc": 64.0}
