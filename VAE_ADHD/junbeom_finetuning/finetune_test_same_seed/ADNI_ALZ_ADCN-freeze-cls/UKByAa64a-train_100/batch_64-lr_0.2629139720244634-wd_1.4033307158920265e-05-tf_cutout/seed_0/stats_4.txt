"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 337.2449035644531, "training_acc": 48.0, "val_loss": 240.41566848754883, "val_acc": 72.0}
{"epoch": 1, "training_loss": 823.4789218902588, "training_acc": 72.0, "val_loss": 53.12355160713196, "val_acc": 40.0}
{"epoch": 2, "training_loss": 258.80821228027344, "training_acc": 36.0, "val_loss": 70.41608095169067, "val_acc": 72.0}
{"epoch": 3, "training_loss": 286.0586853027344, "training_acc": 72.0, "val_loss": 104.75165843963623, "val_acc": 72.0}
{"epoch": 4, "training_loss": 319.12847995758057, "training_acc": 72.0, "val_loss": 31.066006422042847, "val_acc": 60.0}
{"epoch": 5, "training_loss": 149.8410506248474, "training_acc": 61.0, "val_loss": 34.55297350883484, "val_acc": 60.0}
{"epoch": 6, "training_loss": 135.62083339691162, "training_acc": 61.0, "val_loss": 53.46689820289612, "val_acc": 72.0}
{"epoch": 7, "training_loss": 153.26638793945312, "training_acc": 73.0, "val_loss": 36.83269917964935, "val_acc": 72.0}
{"epoch": 8, "training_loss": 115.43960809707642, "training_acc": 70.0, "val_loss": 20.163637399673462, "val_acc": 60.0}
{"epoch": 9, "training_loss": 86.63552141189575, "training_acc": 65.0, "val_loss": 26.668405532836914, "val_acc": 72.0}
{"epoch": 10, "training_loss": 92.20489287376404, "training_acc": 72.0, "val_loss": 31.416112184524536, "val_acc": 32.0}
{"epoch": 11, "training_loss": 92.69213604927063, "training_acc": 50.0, "val_loss": 17.444075644016266, "val_acc": 64.0}
{"epoch": 12, "training_loss": 69.78616380691528, "training_acc": 72.0, "val_loss": 31.430476903915405, "val_acc": 28.0}
{"epoch": 13, "training_loss": 98.7122573852539, "training_acc": 49.0, "val_loss": 21.572476625442505, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.5602343082428, "training_acc": 75.0, "val_loss": 21.612945199012756, "val_acc": 60.0}
{"epoch": 15, "training_loss": 92.71241760253906, "training_acc": 59.0, "val_loss": 28.45967710018158, "val_acc": 72.0}
{"epoch": 16, "training_loss": 122.36515808105469, "training_acc": 73.0, "val_loss": 33.383700251579285, "val_acc": 72.0}
{"epoch": 17, "training_loss": 88.93039274215698, "training_acc": 74.0, "val_loss": 24.244549870491028, "val_acc": 64.0}
{"epoch": 18, "training_loss": 86.17911410331726, "training_acc": 69.0, "val_loss": 27.176985144615173, "val_acc": 72.0}
{"epoch": 19, "training_loss": 83.30213737487793, "training_acc": 73.0, "val_loss": 16.02361649274826, "val_acc": 72.0}
{"epoch": 20, "training_loss": 74.43989562988281, "training_acc": 65.0, "val_loss": 13.4055495262146, "val_acc": 72.0}
{"epoch": 21, "training_loss": 62.13458728790283, "training_acc": 74.0, "val_loss": 16.16615653038025, "val_acc": 76.0}
{"epoch": 22, "training_loss": 67.00108313560486, "training_acc": 67.0, "val_loss": 11.131763458251953, "val_acc": 80.0}
{"epoch": 23, "training_loss": 43.47259831428528, "training_acc": 83.0, "val_loss": 12.868066132068634, "val_acc": 76.0}
{"epoch": 24, "training_loss": 47.36716616153717, "training_acc": 72.0, "val_loss": 12.305203080177307, "val_acc": 56.0}
{"epoch": 25, "training_loss": 56.42302393913269, "training_acc": 70.0, "val_loss": 15.43075293302536, "val_acc": 76.0}
{"epoch": 26, "training_loss": 55.65597057342529, "training_acc": 72.0, "val_loss": 12.540946900844574, "val_acc": 68.0}
{"epoch": 27, "training_loss": 52.55414795875549, "training_acc": 78.0, "val_loss": 16.291543841362, "val_acc": 76.0}
{"epoch": 28, "training_loss": 52.86493635177612, "training_acc": 75.0, "val_loss": 11.948978900909424, "val_acc": 80.0}
{"epoch": 29, "training_loss": 39.9565407037735, "training_acc": 85.0, "val_loss": 16.936053335666656, "val_acc": 76.0}
{"epoch": 30, "training_loss": 46.40416979789734, "training_acc": 79.0, "val_loss": 11.795525997877121, "val_acc": 80.0}
{"epoch": 31, "training_loss": 36.797003626823425, "training_acc": 86.0, "val_loss": 12.539635598659515, "val_acc": 84.0}
{"epoch": 32, "training_loss": 34.594345688819885, "training_acc": 84.0, "val_loss": 12.011036276817322, "val_acc": 72.0}
{"epoch": 33, "training_loss": 39.7262179851532, "training_acc": 83.0, "val_loss": 13.916243612766266, "val_acc": 76.0}
{"epoch": 34, "training_loss": 34.90994668006897, "training_acc": 85.0, "val_loss": 12.64190673828125, "val_acc": 72.0}
{"epoch": 35, "training_loss": 37.65333354473114, "training_acc": 84.0, "val_loss": 14.699651300907135, "val_acc": 80.0}
{"epoch": 36, "training_loss": 36.36217737197876, "training_acc": 83.0, "val_loss": 12.955905497074127, "val_acc": 64.0}
{"epoch": 37, "training_loss": 39.04398274421692, "training_acc": 84.0, "val_loss": 15.861350297927856, "val_acc": 76.0}
{"epoch": 38, "training_loss": 47.85050868988037, "training_acc": 75.0, "val_loss": 15.573523938655853, "val_acc": 76.0}
{"epoch": 39, "training_loss": 36.759634613990784, "training_acc": 80.0, "val_loss": 12.066320329904556, "val_acc": 72.0}
{"epoch": 40, "training_loss": 35.77000629901886, "training_acc": 87.0, "val_loss": 16.664814949035645, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.965176701545715, "training_acc": 78.0, "val_loss": 12.37165778875351, "val_acc": 76.0}
