"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1158.765224456787, "training_acc": 72.0, "val_loss": 508.9139461517334, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1373.782464981079, "training_acc": 72.0, "val_loss": 782.732105255127, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3254.5765686035156, "training_acc": 28.0, "val_loss": 123.21627140045166, "val_acc": 36.0}
{"epoch": 3, "training_loss": 805.5630187988281, "training_acc": 52.0, "val_loss": 480.6731700897217, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2172.2548828125, "training_acc": 72.0, "val_loss": 645.6930160522461, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2587.651622772217, "training_acc": 72.0, "val_loss": 504.152774810791, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1811.955825805664, "training_acc": 72.0, "val_loss": 171.79676294326782, "val_acc": 72.0}
{"epoch": 7, "training_loss": 821.4333553314209, "training_acc": 65.0, "val_loss": 197.44127988815308, "val_acc": 44.0}
{"epoch": 8, "training_loss": 1267.1847496032715, "training_acc": 46.0, "val_loss": 94.30213570594788, "val_acc": 68.0}
{"epoch": 9, "training_loss": 663.6200466156006, "training_acc": 65.0, "val_loss": 141.18669033050537, "val_acc": 72.0}
{"epoch": 10, "training_loss": 651.3852233886719, "training_acc": 73.0, "val_loss": 216.4231538772583, "val_acc": 72.0}
{"epoch": 11, "training_loss": 749.0064678192139, "training_acc": 72.0, "val_loss": 60.20224094390869, "val_acc": 72.0}
{"epoch": 12, "training_loss": 402.610803604126, "training_acc": 65.0, "val_loss": 101.12324953079224, "val_acc": 56.0}
{"epoch": 13, "training_loss": 624.616792678833, "training_acc": 53.0, "val_loss": 48.21077883243561, "val_acc": 72.0}
{"epoch": 14, "training_loss": 330.40893745422363, "training_acc": 73.0, "val_loss": 154.703950881958, "val_acc": 72.0}
{"epoch": 15, "training_loss": 474.3574161529541, "training_acc": 72.0, "val_loss": 31.971240043640137, "val_acc": 76.0}
{"epoch": 16, "training_loss": 254.7394962310791, "training_acc": 63.0, "val_loss": 70.6031322479248, "val_acc": 56.0}
{"epoch": 17, "training_loss": 228.44945812225342, "training_acc": 62.0, "val_loss": 149.13983345031738, "val_acc": 72.0}
{"epoch": 18, "training_loss": 527.39794921875, "training_acc": 72.0, "val_loss": 92.15930700302124, "val_acc": 72.0}
{"epoch": 19, "training_loss": 340.23698234558105, "training_acc": 57.0, "val_loss": 81.39718174934387, "val_acc": 44.0}
{"epoch": 20, "training_loss": 192.52704167366028, "training_acc": 62.0, "val_loss": 94.55808997154236, "val_acc": 72.0}
{"epoch": 21, "training_loss": 312.0738639831543, "training_acc": 72.0, "val_loss": 29.98744249343872, "val_acc": 72.0}
{"epoch": 22, "training_loss": 204.5578212738037, "training_acc": 69.0, "val_loss": 51.09055042266846, "val_acc": 60.0}
{"epoch": 23, "training_loss": 238.91150522232056, "training_acc": 65.0, "val_loss": 68.0143654346466, "val_acc": 72.0}
{"epoch": 24, "training_loss": 239.19594383239746, "training_acc": 75.0, "val_loss": 20.973174273967743, "val_acc": 84.0}
{"epoch": 25, "training_loss": 189.2142972946167, "training_acc": 65.0, "val_loss": 20.777559280395508, "val_acc": 68.0}
{"epoch": 26, "training_loss": 84.24777889251709, "training_acc": 76.0, "val_loss": 48.600128293037415, "val_acc": 72.0}
{"epoch": 27, "training_loss": 97.92885446548462, "training_acc": 70.0, "val_loss": 36.261335015296936, "val_acc": 60.0}
{"epoch": 28, "training_loss": 111.72169780731201, "training_acc": 68.0, "val_loss": 47.46275246143341, "val_acc": 72.0}
{"epoch": 29, "training_loss": 121.69263219833374, "training_acc": 64.0, "val_loss": 23.99221509695053, "val_acc": 60.0}
{"epoch": 30, "training_loss": 43.358521580696106, "training_acc": 78.0, "val_loss": 39.035239815711975, "val_acc": 72.0}
{"epoch": 31, "training_loss": 87.03591084480286, "training_acc": 80.0, "val_loss": 49.86303746700287, "val_acc": 52.0}
{"epoch": 32, "training_loss": 155.7381626367569, "training_acc": 60.0, "val_loss": 41.11543297767639, "val_acc": 72.0}
{"epoch": 33, "training_loss": 119.75751948356628, "training_acc": 78.0, "val_loss": 20.470857620239258, "val_acc": 64.0}
{"epoch": 34, "training_loss": 76.55675053596497, "training_acc": 75.0, "val_loss": 13.546161353588104, "val_acc": 84.0}
{"epoch": 35, "training_loss": 31.15846747159958, "training_acc": 85.0, "val_loss": 15.768563747406006, "val_acc": 76.0}
{"epoch": 36, "training_loss": 30.648318648338318, "training_acc": 85.0, "val_loss": 25.205057859420776, "val_acc": 64.0}
{"epoch": 37, "training_loss": 66.70831775665283, "training_acc": 81.0, "val_loss": 54.485464096069336, "val_acc": 44.0}
{"epoch": 38, "training_loss": 128.36417722702026, "training_acc": 57.0, "val_loss": 31.76506757736206, "val_acc": 72.0}
{"epoch": 39, "training_loss": 41.56379461288452, "training_acc": 81.0, "val_loss": 32.243895530700684, "val_acc": 48.0}
{"epoch": 40, "training_loss": 110.16971445083618, "training_acc": 61.0, "val_loss": 38.12395632266998, "val_acc": 72.0}
{"epoch": 41, "training_loss": 81.71500897407532, "training_acc": 73.0, "val_loss": 13.380515575408936, "val_acc": 72.0}
{"epoch": 42, "training_loss": 34.57618498802185, "training_acc": 88.0, "val_loss": 30.414363741874695, "val_acc": 72.0}
{"epoch": 43, "training_loss": 91.04128789901733, "training_acc": 76.0, "val_loss": 16.86980575323105, "val_acc": 76.0}
{"epoch": 44, "training_loss": 46.33551621437073, "training_acc": 83.0, "val_loss": 25.63784122467041, "val_acc": 56.0}
{"epoch": 45, "training_loss": 47.4606756567955, "training_acc": 79.0, "val_loss": 20.222488045692444, "val_acc": 68.0}
{"epoch": 46, "training_loss": 48.61037850379944, "training_acc": 79.0, "val_loss": 23.909851908683777, "val_acc": 68.0}
{"epoch": 47, "training_loss": 38.25499528646469, "training_acc": 87.0, "val_loss": 18.024341762065887, "val_acc": 72.0}
{"epoch": 48, "training_loss": 34.59638774394989, "training_acc": 82.0, "val_loss": 29.663148522377014, "val_acc": 72.0}
{"epoch": 49, "training_loss": 52.17963457107544, "training_acc": 83.0, "val_loss": 22.205471992492676, "val_acc": 60.0}
{"epoch": 50, "training_loss": 52.09849089384079, "training_acc": 79.0, "val_loss": 33.709415793418884, "val_acc": 72.0}
{"epoch": 51, "training_loss": 76.15646380186081, "training_acc": 78.0, "val_loss": 27.146422863006592, "val_acc": 52.0}
{"epoch": 52, "training_loss": 88.42266798019409, "training_acc": 67.0, "val_loss": 44.48164999485016, "val_acc": 72.0}
{"epoch": 53, "training_loss": 136.18665647506714, "training_acc": 71.0, "val_loss": 14.860960841178894, "val_acc": 68.0}
{"epoch": 54, "training_loss": 56.19544553756714, "training_acc": 83.0, "val_loss": 22.210322320461273, "val_acc": 76.0}
{"epoch": 55, "training_loss": 74.12665033340454, "training_acc": 78.0, "val_loss": 15.134970843791962, "val_acc": 76.0}
{"epoch": 56, "training_loss": 39.6346595287323, "training_acc": 84.0, "val_loss": 19.289828836917877, "val_acc": 64.0}
{"epoch": 57, "training_loss": 47.61442279815674, "training_acc": 80.0, "val_loss": 36.03229820728302, "val_acc": 72.0}
{"epoch": 58, "training_loss": 88.1468186378479, "training_acc": 74.0, "val_loss": 78.53028774261475, "val_acc": 44.0}
{"epoch": 59, "training_loss": 163.33701354265213, "training_acc": 59.0, "val_loss": 68.84936094284058, "val_acc": 72.0}
{"epoch": 60, "training_loss": 184.68755722045898, "training_acc": 72.0, "val_loss": 14.310012757778168, "val_acc": 76.0}
