"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1231.5359916687012, "training_acc": 72.0, "val_loss": 494.6723937988281, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1244.3006148338318, "training_acc": 72.0, "val_loss": 1054.4821739196777, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4088.2967071533203, "training_acc": 28.0, "val_loss": 373.1248617172241, "val_acc": 28.0}
{"epoch": 3, "training_loss": 912.9492788314819, "training_acc": 57.0, "val_loss": 442.9108142852783, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1902.014259338379, "training_acc": 72.0, "val_loss": 683.4303855895996, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2612.3062057495117, "training_acc": 72.0, "val_loss": 591.5614604949951, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2150.625720977783, "training_acc": 72.0, "val_loss": 244.92876529693604, "val_acc": 72.0}
{"epoch": 7, "training_loss": 713.6804676055908, "training_acc": 74.0, "val_loss": 274.0410327911377, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1226.587272644043, "training_acc": 53.0, "val_loss": 345.51992416381836, "val_acc": 48.0}
{"epoch": 9, "training_loss": 1193.5555973052979, "training_acc": 48.0, "val_loss": 123.74160289764404, "val_acc": 72.0}
{"epoch": 10, "training_loss": 480.5744571685791, "training_acc": 79.0, "val_loss": 257.8526496887207, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1014.813549041748, "training_acc": 72.0, "val_loss": 187.26078271865845, "val_acc": 76.0}
{"epoch": 12, "training_loss": 759.0195693969727, "training_acc": 70.0, "val_loss": 101.92991495132446, "val_acc": 68.0}
{"epoch": 13, "training_loss": 445.0311031341553, "training_acc": 66.0, "val_loss": 166.93254709243774, "val_acc": 60.0}
{"epoch": 14, "training_loss": 557.8554706573486, "training_acc": 62.0, "val_loss": 72.84001111984253, "val_acc": 76.0}
{"epoch": 15, "training_loss": 427.29865074157715, "training_acc": 70.0, "val_loss": 139.40114974975586, "val_acc": 72.0}
{"epoch": 16, "training_loss": 461.96523571014404, "training_acc": 74.0, "val_loss": 35.021406412124634, "val_acc": 64.0}
{"epoch": 17, "training_loss": 322.29883575439453, "training_acc": 60.0, "val_loss": 30.378252267837524, "val_acc": 60.0}
{"epoch": 18, "training_loss": 147.6162633895874, "training_acc": 73.0, "val_loss": 129.7935128211975, "val_acc": 72.0}
{"epoch": 19, "training_loss": 411.15802478790283, "training_acc": 72.0, "val_loss": 40.45670926570892, "val_acc": 48.0}
{"epoch": 20, "training_loss": 221.1421604156494, "training_acc": 61.0, "val_loss": 39.793989062309265, "val_acc": 56.0}
{"epoch": 21, "training_loss": 158.94008350372314, "training_acc": 65.0, "val_loss": 62.86851763725281, "val_acc": 72.0}
{"epoch": 22, "training_loss": 146.60384321212769, "training_acc": 71.0, "val_loss": 37.94189393520355, "val_acc": 56.0}
{"epoch": 23, "training_loss": 77.45926213264465, "training_acc": 73.0, "val_loss": 46.72688841819763, "val_acc": 76.0}
{"epoch": 24, "training_loss": 104.30875778198242, "training_acc": 76.0, "val_loss": 39.212557673454285, "val_acc": 64.0}
{"epoch": 25, "training_loss": 78.60583424568176, "training_acc": 77.0, "val_loss": 34.09888744354248, "val_acc": 60.0}
{"epoch": 26, "training_loss": 59.38173055648804, "training_acc": 77.0, "val_loss": 34.22980010509491, "val_acc": 72.0}
{"epoch": 27, "training_loss": 41.882683515548706, "training_acc": 84.0, "val_loss": 42.52266585826874, "val_acc": 68.0}
{"epoch": 28, "training_loss": 54.82527017593384, "training_acc": 78.0, "val_loss": 49.22268092632294, "val_acc": 72.0}
{"epoch": 29, "training_loss": 64.33536911010742, "training_acc": 75.0, "val_loss": 85.48772931098938, "val_acc": 36.0}
{"epoch": 30, "training_loss": 213.1676959991455, "training_acc": 53.0, "val_loss": 85.43127179145813, "val_acc": 72.0}
{"epoch": 31, "training_loss": 145.44629299640656, "training_acc": 72.0, "val_loss": 80.46121001243591, "val_acc": 36.0}
{"epoch": 32, "training_loss": 182.42221426963806, "training_acc": 56.0, "val_loss": 75.15058517456055, "val_acc": 72.0}
{"epoch": 33, "training_loss": 134.6581151485443, "training_acc": 75.0, "val_loss": 61.90098524093628, "val_acc": 44.0}
{"epoch": 34, "training_loss": 131.90848422050476, "training_acc": 67.0, "val_loss": 59.45306420326233, "val_acc": 76.0}
{"epoch": 35, "training_loss": 158.65732145309448, "training_acc": 75.0, "val_loss": 30.88633418083191, "val_acc": 68.0}
{"epoch": 36, "training_loss": 146.0666093826294, "training_acc": 73.0, "val_loss": 30.828246474266052, "val_acc": 68.0}
