"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 11792.499687194824, "training_acc": 72.0, "val_loss": 4637.462615966797, "val_acc": 72.0}
{"epoch": 1, "training_loss": 13068.882232666016, "training_acc": 72.0, "val_loss": 6005.062484741211, "val_acc": 28.0}
{"epoch": 2, "training_loss": 26705.317749023438, "training_acc": 28.0, "val_loss": 949.1804122924805, "val_acc": 56.0}
{"epoch": 3, "training_loss": 6564.202484130859, "training_acc": 56.0, "val_loss": 4256.006622314453, "val_acc": 72.0}
{"epoch": 4, "training_loss": 16229.824584960938, "training_acc": 72.0, "val_loss": 5106.198501586914, "val_acc": 72.0}
{"epoch": 5, "training_loss": 17186.53741455078, "training_acc": 72.0, "val_loss": 3465.336227416992, "val_acc": 72.0}
{"epoch": 6, "training_loss": 10132.696258544922, "training_acc": 70.0, "val_loss": 1380.9039115905762, "val_acc": 72.0}
{"epoch": 7, "training_loss": 8688.287017822266, "training_acc": 61.0, "val_loss": 1454.3402671813965, "val_acc": 60.0}
{"epoch": 8, "training_loss": 6102.433090209961, "training_acc": 66.0, "val_loss": 1571.0101127624512, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4992.676055908203, "training_acc": 72.0, "val_loss": 2243.5449600219727, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5234.009750366211, "training_acc": 74.0, "val_loss": 1050.8413314819336, "val_acc": 76.0}
{"epoch": 11, "training_loss": 2661.303192138672, "training_acc": 73.0, "val_loss": 940.3976440429688, "val_acc": 56.0}
{"epoch": 12, "training_loss": 3450.4841079711914, "training_acc": 63.0, "val_loss": 706.0412406921387, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1911.3650665283203, "training_acc": 77.0, "val_loss": 458.07671546936035, "val_acc": 76.0}
{"epoch": 14, "training_loss": 2522.5786895751953, "training_acc": 59.0, "val_loss": 111.06597185134888, "val_acc": 68.0}
{"epoch": 15, "training_loss": 1340.6814727783203, "training_acc": 70.0, "val_loss": 442.94328689575195, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1775.632396697998, "training_acc": 62.0, "val_loss": 111.47291660308838, "val_acc": 56.0}
{"epoch": 17, "training_loss": 788.0360260009766, "training_acc": 71.0, "val_loss": 131.44532442092896, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2576.482192993164, "training_acc": 48.0, "val_loss": 112.43929862976074, "val_acc": 80.0}
{"epoch": 19, "training_loss": 1808.6571655273438, "training_acc": 72.0, "val_loss": 834.7585678100586, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2283.422607421875, "training_acc": 70.0, "val_loss": 533.6470127105713, "val_acc": 64.0}
{"epoch": 21, "training_loss": 2885.348991394043, "training_acc": 58.0, "val_loss": 586.5712642669678, "val_acc": 76.0}
{"epoch": 22, "training_loss": 1608.3493728637695, "training_acc": 74.0, "val_loss": 642.4964427947998, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1323.9870376586914, "training_acc": 76.0, "val_loss": 410.8506202697754, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1261.675521850586, "training_acc": 76.0, "val_loss": 306.53343200683594, "val_acc": 76.0}
{"epoch": 25, "training_loss": 517.846830368042, "training_acc": 80.0, "val_loss": 121.23483419418335, "val_acc": 80.0}
{"epoch": 26, "training_loss": 364.93808364868164, "training_acc": 80.0, "val_loss": 53.74006628990173, "val_acc": 64.0}
{"epoch": 27, "training_loss": 403.0754089355469, "training_acc": 75.0, "val_loss": 375.2256393432617, "val_acc": 48.0}
{"epoch": 28, "training_loss": 1444.429946899414, "training_acc": 62.0, "val_loss": 131.57100677490234, "val_acc": 68.0}
{"epoch": 29, "training_loss": 2199.271255493164, "training_acc": 53.0, "val_loss": 272.6365327835083, "val_acc": 72.0}
{"epoch": 30, "training_loss": 898.0780563354492, "training_acc": 71.0, "val_loss": 183.9654803276062, "val_acc": 80.0}
{"epoch": 31, "training_loss": 670.4773597717285, "training_acc": 70.0, "val_loss": 456.12077713012695, "val_acc": 76.0}
{"epoch": 32, "training_loss": 995.9362144470215, "training_acc": 80.0, "val_loss": 295.90890407562256, "val_acc": 76.0}
{"epoch": 33, "training_loss": 637.7919654846191, "training_acc": 79.0, "val_loss": 431.05015754699707, "val_acc": 76.0}
{"epoch": 34, "training_loss": 740.0623779296875, "training_acc": 79.0, "val_loss": 170.0455904006958, "val_acc": 76.0}
{"epoch": 35, "training_loss": 402.0400629043579, "training_acc": 74.0, "val_loss": 127.69230604171753, "val_acc": 80.0}
{"epoch": 36, "training_loss": 127.75267362594604, "training_acc": 86.0, "val_loss": 124.27133321762085, "val_acc": 68.0}
{"epoch": 37, "training_loss": 495.6848850250244, "training_acc": 73.0, "val_loss": 115.65971374511719, "val_acc": 72.0}
{"epoch": 38, "training_loss": 363.67608642578125, "training_acc": 69.0, "val_loss": 602.2307395935059, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2227.4356079101562, "training_acc": 72.0, "val_loss": 123.66305589675903, "val_acc": 80.0}
{"epoch": 40, "training_loss": 991.1409072875977, "training_acc": 69.0, "val_loss": 431.7115306854248, "val_acc": 76.0}
{"epoch": 41, "training_loss": 865.4295330047607, "training_acc": 79.0, "val_loss": 604.0246486663818, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1177.2715492248535, "training_acc": 80.0, "val_loss": 351.85441970825195, "val_acc": 68.0}
{"epoch": 43, "training_loss": 1164.4627742767334, "training_acc": 68.0, "val_loss": 683.8076114654541, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1457.2307052612305, "training_acc": 77.0, "val_loss": 264.9671792984009, "val_acc": 80.0}
{"epoch": 45, "training_loss": 626.3772773742676, "training_acc": 75.0, "val_loss": 206.00051879882812, "val_acc": 80.0}
