"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10556.79044342041, "training_acc": 42.0, "val_loss": 5933.495330810547, "val_acc": 72.0}
{"epoch": 1, "training_loss": 20084.333129882812, "training_acc": 72.0, "val_loss": 729.4683456420898, "val_acc": 48.0}
{"epoch": 2, "training_loss": 3997.2885665893555, "training_acc": 45.0, "val_loss": 1279.6462059020996, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4768.942184448242, "training_acc": 72.0, "val_loss": 1167.8302764892578, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3778.968765258789, "training_acc": 67.0, "val_loss": 1142.069435119629, "val_acc": 48.0}
{"epoch": 5, "training_loss": 4846.310974121094, "training_acc": 52.0, "val_loss": 1520.0450897216797, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5603.806716918945, "training_acc": 72.0, "val_loss": 1739.9269104003906, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4497.392593383789, "training_acc": 72.0, "val_loss": 1249.4722366333008, "val_acc": 36.0}
{"epoch": 8, "training_loss": 5451.795425415039, "training_acc": 35.0, "val_loss": 713.0809307098389, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2810.1867065429688, "training_acc": 74.0, "val_loss": 1524.7875213623047, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4123.714820861816, "training_acc": 73.0, "val_loss": 576.6481876373291, "val_acc": 76.0}
{"epoch": 11, "training_loss": 2528.4259643554688, "training_acc": 66.0, "val_loss": 595.1045989990234, "val_acc": 68.0}
{"epoch": 12, "training_loss": 1798.713939666748, "training_acc": 68.0, "val_loss": 1058.5798263549805, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2904.58341217041, "training_acc": 72.0, "val_loss": 461.59539222717285, "val_acc": 64.0}
{"epoch": 14, "training_loss": 2034.0164947509766, "training_acc": 64.0, "val_loss": 388.9298677444458, "val_acc": 68.0}
{"epoch": 15, "training_loss": 2081.5926208496094, "training_acc": 66.0, "val_loss": 791.4487838745117, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1555.6614036560059, "training_acc": 77.0, "val_loss": 820.7707405090332, "val_acc": 40.0}
{"epoch": 17, "training_loss": 2662.2493324279785, "training_acc": 51.0, "val_loss": 718.8928604125977, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1928.1132164001465, "training_acc": 74.0, "val_loss": 495.76783180236816, "val_acc": 68.0}
{"epoch": 19, "training_loss": 1268.4910888671875, "training_acc": 75.0, "val_loss": 386.99238300323486, "val_acc": 64.0}
{"epoch": 20, "training_loss": 1520.8284225463867, "training_acc": 64.0, "val_loss": 615.0607109069824, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1200.173101425171, "training_acc": 77.0, "val_loss": 354.5121431350708, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1134.416160583496, "training_acc": 62.0, "val_loss": 454.68664169311523, "val_acc": 72.0}
{"epoch": 23, "training_loss": 831.7526407241821, "training_acc": 75.0, "val_loss": 674.1968154907227, "val_acc": 44.0}
{"epoch": 24, "training_loss": 2029.8437843322754, "training_acc": 53.0, "val_loss": 256.2685251235962, "val_acc": 72.0}
{"epoch": 25, "training_loss": 797.1848182678223, "training_acc": 70.0, "val_loss": 307.4237585067749, "val_acc": 72.0}
{"epoch": 26, "training_loss": 646.2649040222168, "training_acc": 79.0, "val_loss": 125.11553764343262, "val_acc": 68.0}
{"epoch": 27, "training_loss": 498.70434284210205, "training_acc": 74.0, "val_loss": 243.33868026733398, "val_acc": 76.0}
{"epoch": 28, "training_loss": 669.1566867828369, "training_acc": 75.0, "val_loss": 64.43634629249573, "val_acc": 76.0}
{"epoch": 29, "training_loss": 612.2946510314941, "training_acc": 74.0, "val_loss": 554.3299674987793, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1149.554015159607, "training_acc": 78.0, "val_loss": 937.3034477233887, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2466.5003910064697, "training_acc": 47.0, "val_loss": 352.65355110168457, "val_acc": 72.0}
{"epoch": 32, "training_loss": 651.3789811134338, "training_acc": 79.0, "val_loss": 361.5344762802124, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1228.4102516174316, "training_acc": 62.0, "val_loss": 555.8629035949707, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1141.0816040039062, "training_acc": 75.0, "val_loss": 597.1775531768799, "val_acc": 48.0}
{"epoch": 35, "training_loss": 2296.104072570801, "training_acc": 53.0, "val_loss": 447.87917137145996, "val_acc": 72.0}
{"epoch": 36, "training_loss": 950.8705406188965, "training_acc": 80.0, "val_loss": 202.50673294067383, "val_acc": 76.0}
{"epoch": 37, "training_loss": 657.2457675933838, "training_acc": 72.0, "val_loss": 265.62302112579346, "val_acc": 76.0}
{"epoch": 38, "training_loss": 516.5004234313965, "training_acc": 85.0, "val_loss": 202.333402633667, "val_acc": 72.0}
{"epoch": 39, "training_loss": 488.1567039489746, "training_acc": 81.0, "val_loss": 166.33312702178955, "val_acc": 64.0}
{"epoch": 40, "training_loss": 279.29137802124023, "training_acc": 85.0, "val_loss": 175.11016130447388, "val_acc": 56.0}
{"epoch": 41, "training_loss": 302.3227710723877, "training_acc": 78.0, "val_loss": 274.2981433868408, "val_acc": 68.0}
{"epoch": 42, "training_loss": 440.3757355213165, "training_acc": 84.0, "val_loss": 137.50402927398682, "val_acc": 60.0}
{"epoch": 43, "training_loss": 220.1367645263672, "training_acc": 84.0, "val_loss": 243.74666213989258, "val_acc": 72.0}
{"epoch": 44, "training_loss": 287.812105178833, "training_acc": 89.0, "val_loss": 75.99465847015381, "val_acc": 72.0}
{"epoch": 45, "training_loss": 187.49157428741455, "training_acc": 83.0, "val_loss": 99.6137797832489, "val_acc": 76.0}
{"epoch": 46, "training_loss": 278.96023654937744, "training_acc": 88.0, "val_loss": 71.46625518798828, "val_acc": 64.0}
{"epoch": 47, "training_loss": 391.9473886489868, "training_acc": 75.0, "val_loss": 86.35364174842834, "val_acc": 80.0}
