"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10100.689182281494, "training_acc": 52.0, "val_loss": 4845.199966430664, "val_acc": 72.0}
{"epoch": 1, "training_loss": 14546.083770751953, "training_acc": 72.0, "val_loss": 4595.075225830078, "val_acc": 28.0}
{"epoch": 2, "training_loss": 18823.02734375, "training_acc": 29.0, "val_loss": 601.3930320739746, "val_acc": 68.0}
{"epoch": 3, "training_loss": 3790.6814575195312, "training_acc": 71.0, "val_loss": 3436.9251251220703, "val_acc": 72.0}
{"epoch": 4, "training_loss": 12997.548889160156, "training_acc": 72.0, "val_loss": 3083.563804626465, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9932.561019897461, "training_acc": 72.0, "val_loss": 838.2491111755371, "val_acc": 80.0}
{"epoch": 6, "training_loss": 4239.501495361328, "training_acc": 64.0, "val_loss": 1655.1382064819336, "val_acc": 40.0}
{"epoch": 7, "training_loss": 7084.290306091309, "training_acc": 55.0, "val_loss": 981.6115379333496, "val_acc": 68.0}
{"epoch": 8, "training_loss": 3895.3797912597656, "training_acc": 74.0, "val_loss": 2194.0773010253906, "val_acc": 72.0}
{"epoch": 9, "training_loss": 7186.718948364258, "training_acc": 72.0, "val_loss": 1061.6872787475586, "val_acc": 76.0}
{"epoch": 10, "training_loss": 3155.2941970825195, "training_acc": 73.0, "val_loss": 1218.2709693908691, "val_acc": 40.0}
{"epoch": 11, "training_loss": 5014.2705154418945, "training_acc": 44.0, "val_loss": 1060.790729522705, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3893.2847442626953, "training_acc": 72.0, "val_loss": 1615.042495727539, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4596.769721984863, "training_acc": 72.0, "val_loss": 562.9159927368164, "val_acc": 60.0}
{"epoch": 14, "training_loss": 2067.255683898926, "training_acc": 61.0, "val_loss": 521.1989402770996, "val_acc": 64.0}
{"epoch": 15, "training_loss": 1703.6395874023438, "training_acc": 69.0, "val_loss": 969.1021919250488, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2184.9796752929688, "training_acc": 72.0, "val_loss": 792.0007228851318, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2553.3123626708984, "training_acc": 47.0, "val_loss": 655.6733131408691, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2089.2088775634766, "training_acc": 74.0, "val_loss": 732.305383682251, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1276.0884094238281, "training_acc": 76.0, "val_loss": 529.8569202423096, "val_acc": 52.0}
{"epoch": 20, "training_loss": 1626.9169311523438, "training_acc": 61.0, "val_loss": 626.8908500671387, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1795.603126525879, "training_acc": 74.0, "val_loss": 318.340802192688, "val_acc": 68.0}
{"epoch": 22, "training_loss": 972.8671607971191, "training_acc": 67.0, "val_loss": 187.66708374023438, "val_acc": 76.0}
{"epoch": 23, "training_loss": 1099.5916213989258, "training_acc": 70.0, "val_loss": 263.34173679351807, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1093.0117874145508, "training_acc": 68.0, "val_loss": 218.96841526031494, "val_acc": 72.0}
{"epoch": 25, "training_loss": 504.75751304626465, "training_acc": 81.0, "val_loss": 125.11446475982666, "val_acc": 76.0}
{"epoch": 26, "training_loss": 407.2435836791992, "training_acc": 80.0, "val_loss": 181.3312292098999, "val_acc": 76.0}
{"epoch": 27, "training_loss": 352.04707431793213, "training_acc": 82.0, "val_loss": 73.67352843284607, "val_acc": 80.0}
{"epoch": 28, "training_loss": 198.17807340621948, "training_acc": 80.0, "val_loss": 252.94678211212158, "val_acc": 72.0}
{"epoch": 29, "training_loss": 589.7829442024231, "training_acc": 79.0, "val_loss": 75.44718980789185, "val_acc": 72.0}
{"epoch": 30, "training_loss": 589.373893737793, "training_acc": 75.0, "val_loss": 73.52306842803955, "val_acc": 68.0}
{"epoch": 31, "training_loss": 595.6057014465332, "training_acc": 72.0, "val_loss": 619.0729141235352, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2095.7742080688477, "training_acc": 72.0, "val_loss": 494.7122573852539, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1516.3793334960938, "training_acc": 64.0, "val_loss": 178.71580123901367, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1176.7045516967773, "training_acc": 67.0, "val_loss": 831.6960334777832, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1809.813865661621, "training_acc": 74.0, "val_loss": 368.57640743255615, "val_acc": 60.0}
{"epoch": 36, "training_loss": 1780.4342002868652, "training_acc": 58.0, "val_loss": 412.3746395111084, "val_acc": 68.0}
{"epoch": 37, "training_loss": 924.3954086303711, "training_acc": 78.0, "val_loss": 564.8200035095215, "val_acc": 76.0}
{"epoch": 38, "training_loss": 940.9470405578613, "training_acc": 80.0, "val_loss": 353.91836166381836, "val_acc": 60.0}
{"epoch": 39, "training_loss": 1345.1256847381592, "training_acc": 67.0, "val_loss": 411.8955135345459, "val_acc": 72.0}
{"epoch": 40, "training_loss": 721.7486438751221, "training_acc": 80.0, "val_loss": 247.11122512817383, "val_acc": 60.0}
{"epoch": 41, "training_loss": 709.019962310791, "training_acc": 73.0, "val_loss": 481.7538261413574, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1038.4453010559082, "training_acc": 74.0, "val_loss": 229.24623489379883, "val_acc": 52.0}
{"epoch": 43, "training_loss": 442.8110122680664, "training_acc": 70.0, "val_loss": 551.3421058654785, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1560.5678253173828, "training_acc": 74.0, "val_loss": 233.79499912261963, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1728.3465270996094, "training_acc": 66.0, "val_loss": 338.15932273864746, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1290.422103881836, "training_acc": 81.0, "val_loss": 733.2054138183594, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1315.8680744171143, "training_acc": 77.0, "val_loss": 680.5986404418945, "val_acc": 44.0}
{"epoch": 48, "training_loss": 2284.957794189453, "training_acc": 54.0, "val_loss": 771.3575839996338, "val_acc": 72.0}
{"epoch": 49, "training_loss": 2486.435287475586, "training_acc": 72.0, "val_loss": 481.5067768096924, "val_acc": 76.0}
