"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10099.641063690186, "training_acc": 72.0, "val_loss": 4447.976303100586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 12115.916748046875, "training_acc": 72.0, "val_loss": 6980.525207519531, "val_acc": 28.0}
{"epoch": 2, "training_loss": 29212.486328125, "training_acc": 28.0, "val_loss": 1272.2393989562988, "val_acc": 36.0}
{"epoch": 3, "training_loss": 7729.816741943359, "training_acc": 51.0, "val_loss": 3974.474334716797, "val_acc": 72.0}
{"epoch": 4, "training_loss": 17881.809936523438, "training_acc": 72.0, "val_loss": 5304.615020751953, "val_acc": 72.0}
{"epoch": 5, "training_loss": 21174.238403320312, "training_acc": 72.0, "val_loss": 3921.842575073242, "val_acc": 72.0}
{"epoch": 6, "training_loss": 13782.660034179688, "training_acc": 72.0, "val_loss": 852.8072357177734, "val_acc": 72.0}
{"epoch": 7, "training_loss": 7151.031951904297, "training_acc": 64.0, "val_loss": 1489.4763946533203, "val_acc": 52.0}
{"epoch": 8, "training_loss": 11184.201461791992, "training_acc": 47.0, "val_loss": 511.91039085388184, "val_acc": 80.0}
{"epoch": 9, "training_loss": 5256.996063232422, "training_acc": 71.0, "val_loss": 1374.6334075927734, "val_acc": 72.0}
{"epoch": 10, "training_loss": 6077.8160400390625, "training_acc": 73.0, "val_loss": 1591.0012245178223, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5060.682189941406, "training_acc": 71.0, "val_loss": 324.979829788208, "val_acc": 80.0}
{"epoch": 12, "training_loss": 3413.4502563476562, "training_acc": 60.0, "val_loss": 456.49070739746094, "val_acc": 68.0}
{"epoch": 13, "training_loss": 2120.804920196533, "training_acc": 68.0, "val_loss": 1099.7703552246094, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4010.448776245117, "training_acc": 72.0, "val_loss": 761.346435546875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2106.4763259887695, "training_acc": 66.0, "val_loss": 594.2862510681152, "val_acc": 52.0}
{"epoch": 16, "training_loss": 2439.0976791381836, "training_acc": 59.0, "val_loss": 698.0898380279541, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1794.6390056610107, "training_acc": 68.0, "val_loss": 259.89396572113037, "val_acc": 56.0}
{"epoch": 18, "training_loss": 985.7070198059082, "training_acc": 60.0, "val_loss": 151.2022614479065, "val_acc": 80.0}
{"epoch": 19, "training_loss": 1014.142505645752, "training_acc": 67.0, "val_loss": 108.77574682235718, "val_acc": 84.0}
{"epoch": 20, "training_loss": 714.7168846130371, "training_acc": 81.0, "val_loss": 225.48680305480957, "val_acc": 72.0}
{"epoch": 21, "training_loss": 746.0148162841797, "training_acc": 79.0, "val_loss": 567.6623821258545, "val_acc": 52.0}
{"epoch": 22, "training_loss": 1809.3738822937012, "training_acc": 53.0, "val_loss": 535.1085186004639, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1836.7125282287598, "training_acc": 72.0, "val_loss": 140.5562400817871, "val_acc": 72.0}
{"epoch": 24, "training_loss": 613.4061012268066, "training_acc": 67.0, "val_loss": 267.45805740356445, "val_acc": 72.0}
{"epoch": 25, "training_loss": 729.9646911621094, "training_acc": 74.0, "val_loss": 562.7823829650879, "val_acc": 44.0}
{"epoch": 26, "training_loss": 1401.55855178833, "training_acc": 54.0, "val_loss": 222.26495742797852, "val_acc": 72.0}
{"epoch": 27, "training_loss": 759.0017166137695, "training_acc": 67.0, "val_loss": 75.82770586013794, "val_acc": 76.0}
{"epoch": 28, "training_loss": 392.7605228424072, "training_acc": 82.0, "val_loss": 73.05986881256104, "val_acc": 80.0}
{"epoch": 29, "training_loss": 711.3185539245605, "training_acc": 71.0, "val_loss": 300.52490234375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 872.7280807495117, "training_acc": 77.0, "val_loss": 129.3529987335205, "val_acc": 76.0}
{"epoch": 31, "training_loss": 378.6536693572998, "training_acc": 76.0, "val_loss": 105.66147565841675, "val_acc": 72.0}
{"epoch": 32, "training_loss": 488.86431884765625, "training_acc": 79.0, "val_loss": 301.4812469482422, "val_acc": 72.0}
{"epoch": 33, "training_loss": 772.8891487121582, "training_acc": 69.0, "val_loss": 266.5189266204834, "val_acc": 72.0}
{"epoch": 34, "training_loss": 424.71986961364746, "training_acc": 76.0, "val_loss": 447.15771675109863, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1061.3425760269165, "training_acc": 62.0, "val_loss": 387.98065185546875, "val_acc": 72.0}
{"epoch": 36, "training_loss": 668.6350870132446, "training_acc": 78.0, "val_loss": 325.02598762512207, "val_acc": 48.0}
{"epoch": 37, "training_loss": 985.6604042053223, "training_acc": 61.0, "val_loss": 213.7259006500244, "val_acc": 76.0}
{"epoch": 38, "training_loss": 515.9033508300781, "training_acc": 81.0, "val_loss": 399.34825897216797, "val_acc": 48.0}
{"epoch": 39, "training_loss": 1385.4835205078125, "training_acc": 61.0, "val_loss": 392.2083616256714, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1154.9454498291016, "training_acc": 78.0, "val_loss": 349.46324825286865, "val_acc": 56.0}
{"epoch": 41, "training_loss": 1143.040901184082, "training_acc": 67.0, "val_loss": 376.6916751861572, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1395.893211364746, "training_acc": 73.0, "val_loss": 73.48222136497498, "val_acc": 84.0}
{"epoch": 43, "training_loss": 1125.7693710327148, "training_acc": 70.0, "val_loss": 139.7516131401062, "val_acc": 76.0}
{"epoch": 44, "training_loss": 783.5367584228516, "training_acc": 82.0, "val_loss": 234.22131538391113, "val_acc": 72.0}
{"epoch": 45, "training_loss": 722.2831649780273, "training_acc": 70.0, "val_loss": 310.05828380584717, "val_acc": 72.0}
{"epoch": 46, "training_loss": 481.223126411438, "training_acc": 79.0, "val_loss": 160.4422092437744, "val_acc": 56.0}
{"epoch": 47, "training_loss": 352.42723178863525, "training_acc": 81.0, "val_loss": 153.97565364837646, "val_acc": 68.0}
