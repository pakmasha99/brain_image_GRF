"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10454.965232849121, "training_acc": 43.0, "val_loss": 4766.373443603516, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15486.516891479492, "training_acc": 72.0, "val_loss": 4090.098190307617, "val_acc": 28.0}
{"epoch": 2, "training_loss": 17585.540618896484, "training_acc": 30.0, "val_loss": 876.8048286437988, "val_acc": 76.0}
{"epoch": 3, "training_loss": 3990.5697631835938, "training_acc": 72.0, "val_loss": 3311.725616455078, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11342.350982666016, "training_acc": 72.0, "val_loss": 2611.9930267333984, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5949.236892700195, "training_acc": 72.0, "val_loss": 1229.3658256530762, "val_acc": 64.0}
{"epoch": 6, "training_loss": 8033.609680175781, "training_acc": 52.0, "val_loss": 1233.3261489868164, "val_acc": 60.0}
{"epoch": 7, "training_loss": 6289.591529846191, "training_acc": 64.0, "val_loss": 2038.6465072631836, "val_acc": 72.0}
{"epoch": 8, "training_loss": 6689.359069824219, "training_acc": 73.0, "val_loss": 2062.554359436035, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5334.571838378906, "training_acc": 71.0, "val_loss": 880.5907249450684, "val_acc": 64.0}
{"epoch": 10, "training_loss": 4886.7825927734375, "training_acc": 56.0, "val_loss": 681.2546730041504, "val_acc": 68.0}
{"epoch": 11, "training_loss": 2306.248390197754, "training_acc": 72.0, "val_loss": 995.7184791564941, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2212.8730545043945, "training_acc": 74.0, "val_loss": 554.5506477355957, "val_acc": 52.0}
{"epoch": 13, "training_loss": 2226.7088775634766, "training_acc": 51.0, "val_loss": 523.6960411071777, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2527.014358520508, "training_acc": 72.0, "val_loss": 269.25342082977295, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1967.649398803711, "training_acc": 65.0, "val_loss": 589.105749130249, "val_acc": 36.0}
{"epoch": 16, "training_loss": 2600.2863159179688, "training_acc": 54.0, "val_loss": 1256.0062408447266, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5287.163421630859, "training_acc": 72.0, "val_loss": 571.3799953460693, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2568.548728942871, "training_acc": 59.0, "val_loss": 705.0646781921387, "val_acc": 36.0}
{"epoch": 19, "training_loss": 2535.173454284668, "training_acc": 60.0, "val_loss": 768.6471939086914, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2074.9662857055664, "training_acc": 76.0, "val_loss": 564.0754222869873, "val_acc": 76.0}
{"epoch": 21, "training_loss": 1543.7734832763672, "training_acc": 74.0, "val_loss": 427.8043746948242, "val_acc": 64.0}
{"epoch": 22, "training_loss": 1261.6430053710938, "training_acc": 74.0, "val_loss": 526.2781143188477, "val_acc": 76.0}
{"epoch": 23, "training_loss": 1408.178882598877, "training_acc": 76.0, "val_loss": 278.5038471221924, "val_acc": 64.0}
{"epoch": 24, "training_loss": 946.1855430603027, "training_acc": 71.0, "val_loss": 154.21797037124634, "val_acc": 76.0}
{"epoch": 25, "training_loss": 499.1968364715576, "training_acc": 77.0, "val_loss": 62.78461217880249, "val_acc": 72.0}
{"epoch": 26, "training_loss": 415.07938385009766, "training_acc": 75.0, "val_loss": 342.21012592315674, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1825.1917610168457, "training_acc": 72.0, "val_loss": 358.4501266479492, "val_acc": 48.0}
{"epoch": 28, "training_loss": 893.4805641174316, "training_acc": 59.0, "val_loss": 524.2874622344971, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2194.8794326782227, "training_acc": 72.0, "val_loss": 92.64568090438843, "val_acc": 80.0}
{"epoch": 30, "training_loss": 586.4519309997559, "training_acc": 71.0, "val_loss": 257.778000831604, "val_acc": 80.0}
{"epoch": 31, "training_loss": 509.98730659484863, "training_acc": 80.0, "val_loss": 306.9871187210083, "val_acc": 76.0}
{"epoch": 32, "training_loss": 616.4868669509888, "training_acc": 77.0, "val_loss": 253.53527069091797, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1069.1958656311035, "training_acc": 66.0, "val_loss": 307.89480209350586, "val_acc": 80.0}
{"epoch": 34, "training_loss": 443.37107276916504, "training_acc": 81.0, "val_loss": 162.58476972579956, "val_acc": 80.0}
{"epoch": 35, "training_loss": 308.23259258270264, "training_acc": 78.0, "val_loss": 113.9994740486145, "val_acc": 80.0}
{"epoch": 36, "training_loss": 585.0693244934082, "training_acc": 77.0, "val_loss": 462.3051166534424, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2135.076789855957, "training_acc": 73.0, "val_loss": 147.95055389404297, "val_acc": 68.0}
{"epoch": 38, "training_loss": 2067.527389526367, "training_acc": 60.0, "val_loss": 127.72804498672485, "val_acc": 76.0}
{"epoch": 39, "training_loss": 618.1175727844238, "training_acc": 80.0, "val_loss": 325.73068141937256, "val_acc": 76.0}
{"epoch": 40, "training_loss": 629.5794639587402, "training_acc": 75.0, "val_loss": 199.23386573791504, "val_acc": 80.0}
{"epoch": 41, "training_loss": 920.1809730529785, "training_acc": 76.0, "val_loss": 501.22241973876953, "val_acc": 76.0}
{"epoch": 42, "training_loss": 831.2025775909424, "training_acc": 82.0, "val_loss": 277.2000312805176, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1331.7832145690918, "training_acc": 67.0, "val_loss": 480.0763130187988, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1242.1531143188477, "training_acc": 75.0, "val_loss": 77.96207070350647, "val_acc": 84.0}
