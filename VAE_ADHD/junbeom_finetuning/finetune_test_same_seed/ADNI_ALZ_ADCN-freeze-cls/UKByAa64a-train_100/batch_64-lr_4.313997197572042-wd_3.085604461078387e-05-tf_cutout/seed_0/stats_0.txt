"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7031.991832733154, "training_acc": 72.0, "val_loss": 3090.727424621582, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8417.646286010742, "training_acc": 72.0, "val_loss": 4853.06282043457, "val_acc": 28.0}
{"epoch": 2, "training_loss": 20307.906127929688, "training_acc": 28.0, "val_loss": 884.821605682373, "val_acc": 36.0}
{"epoch": 3, "training_loss": 5373.366455078125, "training_acc": 51.0, "val_loss": 2762.667465209961, "val_acc": 72.0}
{"epoch": 4, "training_loss": 12429.578796386719, "training_acc": 72.0, "val_loss": 3687.217330932617, "val_acc": 72.0}
{"epoch": 5, "training_loss": 14717.885803222656, "training_acc": 72.0, "val_loss": 2726.3885498046875, "val_acc": 72.0}
{"epoch": 6, "training_loss": 9581.978088378906, "training_acc": 72.0, "val_loss": 594.0014362335205, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4975.699859619141, "training_acc": 64.0, "val_loss": 1045.505714416504, "val_acc": 52.0}
{"epoch": 8, "training_loss": 7808.281326293945, "training_acc": 47.0, "val_loss": 356.75244331359863, "val_acc": 80.0}
{"epoch": 9, "training_loss": 3662.8623428344727, "training_acc": 71.0, "val_loss": 951.0183334350586, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4211.609085083008, "training_acc": 73.0, "val_loss": 1102.0661354064941, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3507.673225402832, "training_acc": 71.0, "val_loss": 226.69522762298584, "val_acc": 80.0}
{"epoch": 12, "training_loss": 2375.318832397461, "training_acc": 60.0, "val_loss": 320.27392387390137, "val_acc": 68.0}
{"epoch": 13, "training_loss": 1487.9768390655518, "training_acc": 68.0, "val_loss": 759.1245174407959, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2767.2825927734375, "training_acc": 72.0, "val_loss": 523.207950592041, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1464.5528259277344, "training_acc": 66.0, "val_loss": 413.73209953308105, "val_acc": 52.0}
{"epoch": 16, "training_loss": 1707.6283569335938, "training_acc": 59.0, "val_loss": 500.6380558013916, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1281.9302949905396, "training_acc": 72.0, "val_loss": 302.0782947540283, "val_acc": 44.0}
{"epoch": 18, "training_loss": 1091.035385131836, "training_acc": 53.0, "val_loss": 235.70261001586914, "val_acc": 72.0}
{"epoch": 19, "training_loss": 771.1282176971436, "training_acc": 76.0, "val_loss": 184.43249464035034, "val_acc": 60.0}
{"epoch": 20, "training_loss": 623.7606983184814, "training_acc": 72.0, "val_loss": 189.94994163513184, "val_acc": 72.0}
{"epoch": 21, "training_loss": 750.6784439086914, "training_acc": 78.0, "val_loss": 219.4669485092163, "val_acc": 56.0}
{"epoch": 22, "training_loss": 801.6076469421387, "training_acc": 64.0, "val_loss": 180.19204139709473, "val_acc": 72.0}
{"epoch": 23, "training_loss": 524.8526916503906, "training_acc": 75.0, "val_loss": 258.7714195251465, "val_acc": 48.0}
{"epoch": 24, "training_loss": 639.3863496780396, "training_acc": 65.0, "val_loss": 84.74594950675964, "val_acc": 60.0}
{"epoch": 25, "training_loss": 413.2490577697754, "training_acc": 67.0, "val_loss": 279.50713634490967, "val_acc": 72.0}
{"epoch": 26, "training_loss": 994.4449043273926, "training_acc": 72.0, "val_loss": 91.92526936531067, "val_acc": 72.0}
{"epoch": 27, "training_loss": 360.37249755859375, "training_acc": 66.0, "val_loss": 237.8653049468994, "val_acc": 72.0}
{"epoch": 28, "training_loss": 769.7500877380371, "training_acc": 73.0, "val_loss": 103.26472520828247, "val_acc": 64.0}
{"epoch": 29, "training_loss": 516.9535675048828, "training_acc": 67.0, "val_loss": 173.52110147476196, "val_acc": 72.0}
{"epoch": 30, "training_loss": 633.3990941047668, "training_acc": 78.0, "val_loss": 50.6480872631073, "val_acc": 84.0}
{"epoch": 31, "training_loss": 311.2205810546875, "training_acc": 79.0, "val_loss": 59.14148688316345, "val_acc": 72.0}
{"epoch": 32, "training_loss": 244.09903049468994, "training_acc": 81.0, "val_loss": 64.42809104919434, "val_acc": 72.0}
{"epoch": 33, "training_loss": 119.57825040817261, "training_acc": 82.0, "val_loss": 147.71533012390137, "val_acc": 60.0}
{"epoch": 34, "training_loss": 188.7124524116516, "training_acc": 77.0, "val_loss": 162.8903865814209, "val_acc": 64.0}
{"epoch": 35, "training_loss": 489.7658386230469, "training_acc": 67.0, "val_loss": 72.70987629890442, "val_acc": 64.0}
{"epoch": 36, "training_loss": 418.3875312805176, "training_acc": 71.0, "val_loss": 334.938645362854, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1330.7742767333984, "training_acc": 72.0, "val_loss": 103.67763042449951, "val_acc": 76.0}
{"epoch": 38, "training_loss": 779.1359443664551, "training_acc": 71.0, "val_loss": 153.8511872291565, "val_acc": 68.0}
{"epoch": 39, "training_loss": 1040.1137504577637, "training_acc": 68.0, "val_loss": 410.6173515319824, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1543.7546844482422, "training_acc": 76.0, "val_loss": 89.40785527229309, "val_acc": 76.0}
{"epoch": 41, "training_loss": 1229.7879333496094, "training_acc": 68.0, "val_loss": 84.24503803253174, "val_acc": 80.0}
{"epoch": 42, "training_loss": 569.8583965301514, "training_acc": 82.0, "val_loss": 306.15978240966797, "val_acc": 72.0}
{"epoch": 43, "training_loss": 949.6781530380249, "training_acc": 79.0, "val_loss": 309.86125469207764, "val_acc": 52.0}
{"epoch": 44, "training_loss": 806.1493539810181, "training_acc": 61.0, "val_loss": 181.65267705917358, "val_acc": 72.0}
{"epoch": 45, "training_loss": 288.7871265411377, "training_acc": 80.0, "val_loss": 264.5848035812378, "val_acc": 44.0}
{"epoch": 46, "training_loss": 510.7017545700073, "training_acc": 71.0, "val_loss": 359.20891761779785, "val_acc": 72.0}
{"epoch": 47, "training_loss": 688.652361869812, "training_acc": 76.0, "val_loss": 760.8101844787598, "val_acc": 32.0}
{"epoch": 48, "training_loss": 1534.7648088932037, "training_acc": 57.0, "val_loss": 402.2833824157715, "val_acc": 72.0}
{"epoch": 49, "training_loss": 858.744457244873, "training_acc": 73.0, "val_loss": 202.53143310546875, "val_acc": 64.0}
