"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6146.256530761719, "training_acc": 72.0, "val_loss": 2620.8330154418945, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6443.18214225769, "training_acc": 70.0, "val_loss": 961.0414505004883, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4342.480377197266, "training_acc": 46.0, "val_loss": 1606.8527221679688, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5654.71418762207, "training_acc": 72.0, "val_loss": 543.9167499542236, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3307.074737548828, "training_acc": 55.0, "val_loss": 745.594596862793, "val_acc": 44.0}
{"epoch": 5, "training_loss": 3737.860969543457, "training_acc": 56.0, "val_loss": 1249.2294311523438, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4157.049774169922, "training_acc": 72.0, "val_loss": 1042.298412322998, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2454.3649673461914, "training_acc": 72.0, "val_loss": 586.6063117980957, "val_acc": 68.0}
{"epoch": 8, "training_loss": 2594.327320098877, "training_acc": 65.0, "val_loss": 475.83255767822266, "val_acc": 76.0}
{"epoch": 9, "training_loss": 1338.9432563781738, "training_acc": 75.0, "val_loss": 851.1188507080078, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2211.347267150879, "training_acc": 72.0, "val_loss": 361.9616985321045, "val_acc": 76.0}
{"epoch": 11, "training_loss": 1494.611427307129, "training_acc": 60.0, "val_loss": 300.24187564849854, "val_acc": 64.0}
{"epoch": 12, "training_loss": 1104.9291381835938, "training_acc": 70.0, "val_loss": 505.90782165527344, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1272.7354698181152, "training_acc": 69.0, "val_loss": 328.893518447876, "val_acc": 52.0}
{"epoch": 14, "training_loss": 872.0832138061523, "training_acc": 63.0, "val_loss": 275.00174045562744, "val_acc": 64.0}
{"epoch": 15, "training_loss": 602.5267944335938, "training_acc": 71.0, "val_loss": 204.65006828308105, "val_acc": 68.0}
{"epoch": 16, "training_loss": 553.7472038269043, "training_acc": 76.0, "val_loss": 153.69025468826294, "val_acc": 76.0}
{"epoch": 17, "training_loss": 717.9925689697266, "training_acc": 65.0, "val_loss": 451.4902591705322, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1524.0847930908203, "training_acc": 72.0, "val_loss": 271.2812662124634, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1145.5556869506836, "training_acc": 60.0, "val_loss": 110.0487232208252, "val_acc": 80.0}
{"epoch": 20, "training_loss": 863.1307373046875, "training_acc": 70.0, "val_loss": 535.7216835021973, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1216.145959854126, "training_acc": 76.0, "val_loss": 469.9552059173584, "val_acc": 36.0}
{"epoch": 22, "training_loss": 1670.9722919464111, "training_acc": 51.0, "val_loss": 485.6527805328369, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1470.0263748168945, "training_acc": 72.0, "val_loss": 412.01930046081543, "val_acc": 72.0}
{"epoch": 24, "training_loss": 707.2232303619385, "training_acc": 77.0, "val_loss": 206.3312292098999, "val_acc": 64.0}
{"epoch": 25, "training_loss": 680.9183673858643, "training_acc": 68.0, "val_loss": 382.3063373565674, "val_acc": 72.0}
{"epoch": 26, "training_loss": 694.9303073883057, "training_acc": 77.0, "val_loss": 172.95583486557007, "val_acc": 60.0}
{"epoch": 27, "training_loss": 533.2485857009888, "training_acc": 66.0, "val_loss": 217.49112606048584, "val_acc": 72.0}
{"epoch": 28, "training_loss": 276.1380224227905, "training_acc": 79.0, "val_loss": 475.1547336578369, "val_acc": 36.0}
{"epoch": 29, "training_loss": 1232.3606071472168, "training_acc": 58.0, "val_loss": 325.3793478012085, "val_acc": 72.0}
{"epoch": 30, "training_loss": 754.6452922821045, "training_acc": 74.0, "val_loss": 628.3838748931885, "val_acc": 32.0}
{"epoch": 31, "training_loss": 1419.1279501914978, "training_acc": 55.0, "val_loss": 454.7179698944092, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1377.194076538086, "training_acc": 72.0, "val_loss": 108.33414793014526, "val_acc": 72.0}
{"epoch": 33, "training_loss": 943.1617660522461, "training_acc": 68.0, "val_loss": 130.091655254364, "val_acc": 72.0}
{"epoch": 34, "training_loss": 350.39074516296387, "training_acc": 82.0, "val_loss": 349.7933864593506, "val_acc": 72.0}
{"epoch": 35, "training_loss": 986.50390625, "training_acc": 60.0, "val_loss": 130.43056726455688, "val_acc": 72.0}
{"epoch": 36, "training_loss": 363.0443992614746, "training_acc": 83.0, "val_loss": 112.63421773910522, "val_acc": 68.0}
{"epoch": 37, "training_loss": 244.2294921875, "training_acc": 78.0, "val_loss": 109.80286598205566, "val_acc": 72.0}
{"epoch": 38, "training_loss": 307.1919116973877, "training_acc": 79.0, "val_loss": 69.26046013832092, "val_acc": 64.0}
{"epoch": 39, "training_loss": 391.0398635864258, "training_acc": 69.0, "val_loss": 414.2338752746582, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1362.503849029541, "training_acc": 72.0, "val_loss": 270.202898979187, "val_acc": 72.0}
{"epoch": 41, "training_loss": 976.5030555725098, "training_acc": 65.0, "val_loss": 96.0957407951355, "val_acc": 64.0}
{"epoch": 42, "training_loss": 562.0151748657227, "training_acc": 72.0, "val_loss": 716.3352012634277, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2144.2515029907227, "training_acc": 72.0, "val_loss": 112.15094327926636, "val_acc": 68.0}
{"epoch": 44, "training_loss": 1846.7353057861328, "training_acc": 58.0, "val_loss": 177.0552635192871, "val_acc": 72.0}
{"epoch": 45, "training_loss": 420.10945892333984, "training_acc": 81.0, "val_loss": 682.1342468261719, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1547.3521041870117, "training_acc": 74.0, "val_loss": 241.9081687927246, "val_acc": 76.0}
{"epoch": 47, "training_loss": 979.3294677734375, "training_acc": 65.0, "val_loss": 242.0365333557129, "val_acc": 68.0}
{"epoch": 48, "training_loss": 711.6324615478516, "training_acc": 77.0, "val_loss": 490.3273582458496, "val_acc": 72.0}
{"epoch": 49, "training_loss": 833.4375038146973, "training_acc": 77.0, "val_loss": 277.12864875793457, "val_acc": 60.0}
{"epoch": 50, "training_loss": 846.9446601867676, "training_acc": 65.0, "val_loss": 237.8685474395752, "val_acc": 72.0}
{"epoch": 51, "training_loss": 412.65905570983887, "training_acc": 81.0, "val_loss": 142.09630489349365, "val_acc": 64.0}
{"epoch": 52, "training_loss": 462.9740562438965, "training_acc": 79.0, "val_loss": 182.31693506240845, "val_acc": 60.0}
{"epoch": 53, "training_loss": 325.362699508667, "training_acc": 85.0, "val_loss": 175.09602308273315, "val_acc": 64.0}
{"epoch": 54, "training_loss": 416.468074798584, "training_acc": 76.0, "val_loss": 100.02447366714478, "val_acc": 60.0}
{"epoch": 55, "training_loss": 102.33896428346634, "training_acc": 88.0, "val_loss": 150.86523294448853, "val_acc": 76.0}
{"epoch": 56, "training_loss": 164.75749111175537, "training_acc": 87.0, "val_loss": 101.64914131164551, "val_acc": 68.0}
{"epoch": 57, "training_loss": 119.82946443557739, "training_acc": 91.0, "val_loss": 122.44954109191895, "val_acc": 76.0}
