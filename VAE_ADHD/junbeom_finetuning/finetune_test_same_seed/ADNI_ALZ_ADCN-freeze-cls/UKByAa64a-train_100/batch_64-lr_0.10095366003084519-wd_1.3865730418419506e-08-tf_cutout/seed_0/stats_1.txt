"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 164.48354816436768, "training_acc": 73.0, "val_loss": 87.12949752807617, "val_acc": 72.0}
{"epoch": 1, "training_loss": 246.18361616134644, "training_acc": 72.0, "val_loss": 90.56292772293091, "val_acc": 28.0}
{"epoch": 2, "training_loss": 330.8608150482178, "training_acc": 29.0, "val_loss": 14.242717623710632, "val_acc": 68.0}
{"epoch": 3, "training_loss": 93.03723907470703, "training_acc": 78.0, "val_loss": 53.93240451812744, "val_acc": 72.0}
{"epoch": 4, "training_loss": 207.76112270355225, "training_acc": 72.0, "val_loss": 39.763373136520386, "val_acc": 72.0}
{"epoch": 5, "training_loss": 126.37616109848022, "training_acc": 73.0, "val_loss": 24.97103065252304, "val_acc": 60.0}
{"epoch": 6, "training_loss": 136.20688915252686, "training_acc": 52.0, "val_loss": 34.297630190849304, "val_acc": 48.0}
{"epoch": 7, "training_loss": 119.4385187625885, "training_acc": 55.0, "val_loss": 25.173789262771606, "val_acc": 72.0}
{"epoch": 8, "training_loss": 104.2939293384552, "training_acc": 72.0, "val_loss": 36.585089564323425, "val_acc": 72.0}
{"epoch": 9, "training_loss": 129.99540090560913, "training_acc": 72.0, "val_loss": 16.660206019878387, "val_acc": 76.0}
{"epoch": 10, "training_loss": 68.03685069084167, "training_acc": 75.0, "val_loss": 32.32944309711456, "val_acc": 48.0}
{"epoch": 11, "training_loss": 119.49443244934082, "training_acc": 44.0, "val_loss": 13.7791246175766, "val_acc": 60.0}
{"epoch": 12, "training_loss": 67.56406021118164, "training_acc": 75.0, "val_loss": 30.242303013801575, "val_acc": 72.0}
{"epoch": 13, "training_loss": 111.87325096130371, "training_acc": 72.0, "val_loss": 22.24428951740265, "val_acc": 72.0}
{"epoch": 14, "training_loss": 76.56328737735748, "training_acc": 73.0, "val_loss": 20.541787147521973, "val_acc": 52.0}
{"epoch": 15, "training_loss": 88.36613917350769, "training_acc": 51.0, "val_loss": 13.02337646484375, "val_acc": 64.0}
{"epoch": 16, "training_loss": 53.695706367492676, "training_acc": 76.0, "val_loss": 22.967104613780975, "val_acc": 72.0}
{"epoch": 17, "training_loss": 80.34386873245239, "training_acc": 72.0, "val_loss": 14.513975381851196, "val_acc": 76.0}
{"epoch": 18, "training_loss": 47.69791042804718, "training_acc": 80.0, "val_loss": 20.24262547492981, "val_acc": 40.0}
{"epoch": 19, "training_loss": 72.48594975471497, "training_acc": 56.0, "val_loss": 14.253188669681549, "val_acc": 76.0}
{"epoch": 20, "training_loss": 61.13738751411438, "training_acc": 75.0, "val_loss": 22.348181903362274, "val_acc": 72.0}
{"epoch": 21, "training_loss": 69.18431878089905, "training_acc": 72.0, "val_loss": 13.947303593158722, "val_acc": 60.0}
{"epoch": 22, "training_loss": 61.637349367141724, "training_acc": 70.0, "val_loss": 16.880470514297485, "val_acc": 52.0}
{"epoch": 23, "training_loss": 64.62504601478577, "training_acc": 61.0, "val_loss": 19.586192071437836, "val_acc": 72.0}
{"epoch": 24, "training_loss": 67.72473406791687, "training_acc": 72.0, "val_loss": 15.547411143779755, "val_acc": 76.0}
{"epoch": 25, "training_loss": 50.600590229034424, "training_acc": 75.0, "val_loss": 17.990639805793762, "val_acc": 44.0}
{"epoch": 26, "training_loss": 63.26186490058899, "training_acc": 64.0, "val_loss": 14.353929460048676, "val_acc": 76.0}
{"epoch": 27, "training_loss": 52.54965019226074, "training_acc": 78.0, "val_loss": 17.70627051591873, "val_acc": 72.0}
{"epoch": 28, "training_loss": 53.64588510990143, "training_acc": 76.0, "val_loss": 15.121212601661682, "val_acc": 52.0}
{"epoch": 29, "training_loss": 52.0518604516983, "training_acc": 78.0, "val_loss": 13.8785719871521, "val_acc": 60.0}
{"epoch": 30, "training_loss": 45.054378509521484, "training_acc": 80.0, "val_loss": 16.445109248161316, "val_acc": 76.0}
{"epoch": 31, "training_loss": 53.73936629295349, "training_acc": 72.0, "val_loss": 13.868264853954315, "val_acc": 64.0}
{"epoch": 32, "training_loss": 45.265013217926025, "training_acc": 79.0, "val_loss": 14.29404467344284, "val_acc": 60.0}
{"epoch": 33, "training_loss": 46.69296216964722, "training_acc": 79.0, "val_loss": 14.044399559497833, "val_acc": 64.0}
{"epoch": 34, "training_loss": 43.375335693359375, "training_acc": 82.0, "val_loss": 16.14276021718979, "val_acc": 76.0}
