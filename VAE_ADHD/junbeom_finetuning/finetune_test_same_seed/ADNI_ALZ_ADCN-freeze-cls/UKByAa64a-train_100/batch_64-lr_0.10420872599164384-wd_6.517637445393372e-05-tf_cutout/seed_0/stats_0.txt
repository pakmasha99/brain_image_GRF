"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 213.02268600463867, "training_acc": 72.0, "val_loss": 75.577312707901, "val_acc": 72.0}
{"epoch": 1, "training_loss": 208.63577890396118, "training_acc": 72.0, "val_loss": 111.30307912826538, "val_acc": 28.0}
{"epoch": 2, "training_loss": 454.6452693939209, "training_acc": 28.0, "val_loss": 17.046256363391876, "val_acc": 44.0}
{"epoch": 3, "training_loss": 120.79582166671753, "training_acc": 56.0, "val_loss": 66.73029065132141, "val_acc": 72.0}
{"epoch": 4, "training_loss": 292.92236328125, "training_acc": 72.0, "val_loss": 80.10796308517456, "val_acc": 72.0}
{"epoch": 5, "training_loss": 315.34351205825806, "training_acc": 72.0, "val_loss": 47.515952587127686, "val_acc": 72.0}
{"epoch": 6, "training_loss": 155.41698169708252, "training_acc": 75.0, "val_loss": 12.916786968708038, "val_acc": 76.0}
{"epoch": 7, "training_loss": 167.07287979125977, "training_acc": 59.0, "val_loss": 29.736152291297913, "val_acc": 44.0}
{"epoch": 8, "training_loss": 185.3007276058197, "training_acc": 52.0, "val_loss": 14.354036748409271, "val_acc": 76.0}
{"epoch": 9, "training_loss": 92.45569634437561, "training_acc": 73.0, "val_loss": 34.996482729911804, "val_acc": 72.0}
{"epoch": 10, "training_loss": 138.65196228027344, "training_acc": 72.0, "val_loss": 24.948732554912567, "val_acc": 72.0}
{"epoch": 11, "training_loss": 86.27079749107361, "training_acc": 70.0, "val_loss": 14.472366869449615, "val_acc": 64.0}
{"epoch": 12, "training_loss": 89.234299659729, "training_acc": 60.0, "val_loss": 14.29957002401352, "val_acc": 60.0}
{"epoch": 13, "training_loss": 60.64543306827545, "training_acc": 75.0, "val_loss": 23.730435967445374, "val_acc": 72.0}
{"epoch": 14, "training_loss": 94.79901790618896, "training_acc": 72.0, "val_loss": 22.715704143047333, "val_acc": 72.0}
{"epoch": 15, "training_loss": 67.5884039402008, "training_acc": 72.0, "val_loss": 20.24826407432556, "val_acc": 44.0}
{"epoch": 16, "training_loss": 81.6645176410675, "training_acc": 46.0, "val_loss": 14.451390504837036, "val_acc": 60.0}
{"epoch": 17, "training_loss": 51.34981977939606, "training_acc": 76.0, "val_loss": 21.29427343606949, "val_acc": 72.0}
{"epoch": 18, "training_loss": 76.36342716217041, "training_acc": 72.0, "val_loss": 13.896894454956055, "val_acc": 72.0}
{"epoch": 19, "training_loss": 61.186649799346924, "training_acc": 63.0, "val_loss": 16.62152111530304, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.85565149784088, "training_acc": 67.0, "val_loss": 15.621066093444824, "val_acc": 72.0}
{"epoch": 21, "training_loss": 69.07802391052246, "training_acc": 72.0, "val_loss": 15.836219489574432, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.325835943222046, "training_acc": 72.0, "val_loss": 14.562559127807617, "val_acc": 56.0}
{"epoch": 23, "training_loss": 61.910343170166016, "training_acc": 68.0, "val_loss": 11.509803682565689, "val_acc": 84.0}
{"epoch": 24, "training_loss": 50.067158460617065, "training_acc": 75.0, "val_loss": 15.667349100112915, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.09074521064758, "training_acc": 76.0, "val_loss": 11.730238050222397, "val_acc": 80.0}
{"epoch": 26, "training_loss": 46.70540475845337, "training_acc": 76.0, "val_loss": 12.833821773529053, "val_acc": 64.0}
{"epoch": 27, "training_loss": 50.242727160453796, "training_acc": 73.0, "val_loss": 13.417677581310272, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.26834833621979, "training_acc": 77.0, "val_loss": 12.85652369260788, "val_acc": 80.0}
{"epoch": 29, "training_loss": 47.091557025909424, "training_acc": 79.0, "val_loss": 12.91140466928482, "val_acc": 64.0}
{"epoch": 30, "training_loss": 44.27251446247101, "training_acc": 78.0, "val_loss": 13.419824838638306, "val_acc": 72.0}
{"epoch": 31, "training_loss": 48.82557010650635, "training_acc": 74.0, "val_loss": 12.964783608913422, "val_acc": 72.0}
{"epoch": 32, "training_loss": 45.58006727695465, "training_acc": 78.0, "val_loss": 13.855643570423126, "val_acc": 64.0}
{"epoch": 33, "training_loss": 48.788381695747375, "training_acc": 81.0, "val_loss": 14.386607706546783, "val_acc": 72.0}
{"epoch": 34, "training_loss": 52.80745482444763, "training_acc": 74.0, "val_loss": 13.375841081142426, "val_acc": 72.0}
{"epoch": 35, "training_loss": 46.163182735443115, "training_acc": 79.0, "val_loss": 14.171452820301056, "val_acc": 56.0}
{"epoch": 36, "training_loss": 50.07403743267059, "training_acc": 76.0, "val_loss": 12.93342411518097, "val_acc": 76.0}
{"epoch": 37, "training_loss": 51.16539716720581, "training_acc": 76.0, "val_loss": 13.10306191444397, "val_acc": 76.0}
{"epoch": 38, "training_loss": 43.585949063301086, "training_acc": 78.0, "val_loss": 14.633356034755707, "val_acc": 56.0}
{"epoch": 39, "training_loss": 55.745208859443665, "training_acc": 77.0, "val_loss": 12.94746845960617, "val_acc": 76.0}
{"epoch": 40, "training_loss": 53.2377233505249, "training_acc": 78.0, "val_loss": 12.805138528347015, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.469526410102844, "training_acc": 79.0, "val_loss": 13.614343106746674, "val_acc": 56.0}
{"epoch": 42, "training_loss": 49.64893341064453, "training_acc": 74.0, "val_loss": 13.263143599033356, "val_acc": 76.0}
