"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 329.4643745422363, "training_acc": 72.0, "val_loss": 127.07400321960449, "val_acc": 72.0}
{"epoch": 1, "training_loss": 347.301700592041, "training_acc": 72.0, "val_loss": 195.28292417526245, "val_acc": 28.0}
{"epoch": 2, "training_loss": 813.6902008056641, "training_acc": 28.0, "val_loss": 34.72675979137421, "val_acc": 36.0}
{"epoch": 3, "training_loss": 216.65782070159912, "training_acc": 53.0, "val_loss": 111.72921657562256, "val_acc": 72.0}
{"epoch": 4, "training_loss": 499.4459171295166, "training_acc": 72.0, "val_loss": 145.06717920303345, "val_acc": 72.0}
{"epoch": 5, "training_loss": 576.8104982376099, "training_acc": 72.0, "val_loss": 101.29430294036865, "val_acc": 72.0}
{"epoch": 6, "training_loss": 347.3448414802551, "training_acc": 72.0, "val_loss": 16.203273832798004, "val_acc": 76.0}
{"epoch": 7, "training_loss": 222.98487663269043, "training_acc": 60.0, "val_loss": 54.17412519454956, "val_acc": 44.0}
{"epoch": 8, "training_loss": 344.89635133743286, "training_acc": 45.0, "val_loss": 14.900040626525879, "val_acc": 80.0}
{"epoch": 9, "training_loss": 147.72069644927979, "training_acc": 71.0, "val_loss": 47.78778851032257, "val_acc": 72.0}
{"epoch": 10, "training_loss": 200.91491222381592, "training_acc": 73.0, "val_loss": 46.38018012046814, "val_acc": 72.0}
{"epoch": 11, "training_loss": 152.9978289604187, "training_acc": 71.0, "val_loss": 13.69028091430664, "val_acc": 80.0}
{"epoch": 12, "training_loss": 112.94188117980957, "training_acc": 63.0, "val_loss": 22.064468264579773, "val_acc": 52.0}
{"epoch": 13, "training_loss": 98.09249114990234, "training_acc": 64.0, "val_loss": 31.436052918434143, "val_acc": 72.0}
{"epoch": 14, "training_loss": 125.99590921401978, "training_acc": 72.0, "val_loss": 32.74339139461517, "val_acc": 72.0}
{"epoch": 15, "training_loss": 83.88735246658325, "training_acc": 74.0, "val_loss": 32.47454762458801, "val_acc": 44.0}
{"epoch": 16, "training_loss": 119.86319756507874, "training_acc": 47.0, "val_loss": 18.934617936611176, "val_acc": 68.0}
{"epoch": 17, "training_loss": 66.66299057006836, "training_acc": 73.0, "val_loss": 27.590641379356384, "val_acc": 72.0}
{"epoch": 18, "training_loss": 76.75416302680969, "training_acc": 72.0, "val_loss": 18.48136931657791, "val_acc": 44.0}
{"epoch": 19, "training_loss": 83.60953140258789, "training_acc": 49.0, "val_loss": 13.047237694263458, "val_acc": 80.0}
{"epoch": 20, "training_loss": 55.08417773246765, "training_acc": 74.0, "val_loss": 23.931889235973358, "val_acc": 72.0}
{"epoch": 21, "training_loss": 77.20140147209167, "training_acc": 74.0, "val_loss": 14.114022254943848, "val_acc": 60.0}
{"epoch": 22, "training_loss": 83.35319995880127, "training_acc": 61.0, "val_loss": 11.883281171321869, "val_acc": 68.0}
{"epoch": 23, "training_loss": 63.54769945144653, "training_acc": 74.0, "val_loss": 25.821194052696228, "val_acc": 72.0}
{"epoch": 24, "training_loss": 90.30452537536621, "training_acc": 74.0, "val_loss": 11.05877310037613, "val_acc": 84.0}
{"epoch": 25, "training_loss": 66.2925329208374, "training_acc": 72.0, "val_loss": 13.799816370010376, "val_acc": 60.0}
{"epoch": 26, "training_loss": 54.05279183387756, "training_acc": 75.0, "val_loss": 21.868060529232025, "val_acc": 72.0}
{"epoch": 27, "training_loss": 72.75421833992004, "training_acc": 72.0, "val_loss": 13.259753584861755, "val_acc": 64.0}
{"epoch": 28, "training_loss": 58.902936697006226, "training_acc": 71.0, "val_loss": 12.997770309448242, "val_acc": 76.0}
{"epoch": 29, "training_loss": 49.8926956653595, "training_acc": 77.0, "val_loss": 18.19039136171341, "val_acc": 72.0}
{"epoch": 30, "training_loss": 55.2607501745224, "training_acc": 77.0, "val_loss": 15.48200249671936, "val_acc": 52.0}
{"epoch": 31, "training_loss": 51.42775332927704, "training_acc": 73.0, "val_loss": 14.168626070022583, "val_acc": 72.0}
{"epoch": 32, "training_loss": 42.05584394931793, "training_acc": 80.0, "val_loss": 12.612821161746979, "val_acc": 64.0}
{"epoch": 33, "training_loss": 43.28084146976471, "training_acc": 79.0, "val_loss": 13.194113969802856, "val_acc": 76.0}
{"epoch": 34, "training_loss": 45.56590700149536, "training_acc": 79.0, "val_loss": 12.434274703264236, "val_acc": 84.0}
{"epoch": 35, "training_loss": 42.43602812290192, "training_acc": 81.0, "val_loss": 12.9193976521492, "val_acc": 64.0}
{"epoch": 36, "training_loss": 39.920782685279846, "training_acc": 83.0, "val_loss": 14.734646677970886, "val_acc": 72.0}
{"epoch": 37, "training_loss": 46.418113708496094, "training_acc": 78.0, "val_loss": 12.059659510850906, "val_acc": 64.0}
{"epoch": 38, "training_loss": 44.224055767059326, "training_acc": 79.0, "val_loss": 11.60777062177658, "val_acc": 64.0}
{"epoch": 39, "training_loss": 45.86626076698303, "training_acc": 76.0, "val_loss": 13.219165802001953, "val_acc": 76.0}
{"epoch": 40, "training_loss": 42.8290855884552, "training_acc": 80.0, "val_loss": 16.039511561393738, "val_acc": 52.0}
{"epoch": 41, "training_loss": 53.69540798664093, "training_acc": 69.0, "val_loss": 14.450983703136444, "val_acc": 72.0}
{"epoch": 42, "training_loss": 51.84391188621521, "training_acc": 77.0, "val_loss": 11.490198224782944, "val_acc": 84.0}
{"epoch": 43, "training_loss": 43.71470820903778, "training_acc": 79.0, "val_loss": 11.58335879445076, "val_acc": 68.0}
