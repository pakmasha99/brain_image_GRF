"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 686.5395088195801, "training_acc": 40.0, "val_loss": 328.04253101348877, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1110.6956100463867, "training_acc": 72.0, "val_loss": 47.433385252952576, "val_acc": 44.0}
{"epoch": 2, "training_loss": 300.4231357574463, "training_acc": 41.0, "val_loss": 61.591798067092896, "val_acc": 72.0}
{"epoch": 3, "training_loss": 237.27117729187012, "training_acc": 72.0, "val_loss": 80.54521083831787, "val_acc": 72.0}
{"epoch": 4, "training_loss": 237.8966817855835, "training_acc": 67.0, "val_loss": 36.774516105651855, "val_acc": 60.0}
{"epoch": 5, "training_loss": 151.68211221694946, "training_acc": 65.0, "val_loss": 43.715900182724, "val_acc": 76.0}
{"epoch": 6, "training_loss": 139.64604949951172, "training_acc": 73.0, "val_loss": 24.423541128635406, "val_acc": 64.0}
{"epoch": 7, "training_loss": 119.8117151260376, "training_acc": 58.0, "val_loss": 33.18353593349457, "val_acc": 72.0}
{"epoch": 8, "training_loss": 102.55399918556213, "training_acc": 72.0, "val_loss": 19.142886996269226, "val_acc": 68.0}
{"epoch": 9, "training_loss": 115.61550903320312, "training_acc": 57.0, "val_loss": 22.593924403190613, "val_acc": 72.0}
{"epoch": 10, "training_loss": 94.85082769393921, "training_acc": 72.0, "val_loss": 18.281809985637665, "val_acc": 64.0}
{"epoch": 11, "training_loss": 108.15362071990967, "training_acc": 59.0, "val_loss": 21.70160263776779, "val_acc": 68.0}
{"epoch": 12, "training_loss": 87.45911645889282, "training_acc": 75.0, "val_loss": 27.423429489135742, "val_acc": 68.0}
{"epoch": 13, "training_loss": 127.54480648040771, "training_acc": 58.0, "val_loss": 23.851363360881805, "val_acc": 72.0}
{"epoch": 14, "training_loss": 65.69812369346619, "training_acc": 77.0, "val_loss": 46.668991446495056, "val_acc": 72.0}
{"epoch": 15, "training_loss": 106.96883487701416, "training_acc": 74.0, "val_loss": 27.542787790298462, "val_acc": 60.0}
{"epoch": 16, "training_loss": 99.8161416053772, "training_acc": 65.0, "val_loss": 25.23501217365265, "val_acc": 68.0}
{"epoch": 17, "training_loss": 84.77014446258545, "training_acc": 73.0, "val_loss": 28.912168741226196, "val_acc": 72.0}
{"epoch": 18, "training_loss": 74.77589106559753, "training_acc": 74.0, "val_loss": 21.668027341365814, "val_acc": 56.0}
{"epoch": 19, "training_loss": 66.0154721736908, "training_acc": 71.0, "val_loss": 26.316988468170166, "val_acc": 64.0}
{"epoch": 20, "training_loss": 52.057671546936035, "training_acc": 79.0, "val_loss": 24.58147257566452, "val_acc": 48.0}
{"epoch": 21, "training_loss": 62.65396308898926, "training_acc": 65.0, "val_loss": 22.45781719684601, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.81094694137573, "training_acc": 72.0, "val_loss": 16.183000802993774, "val_acc": 68.0}
{"epoch": 23, "training_loss": 45.708979845047, "training_acc": 83.0, "val_loss": 15.850947797298431, "val_acc": 68.0}
{"epoch": 24, "training_loss": 52.23589062690735, "training_acc": 73.0, "val_loss": 20.40714919567108, "val_acc": 76.0}
{"epoch": 25, "training_loss": 52.69503903388977, "training_acc": 80.0, "val_loss": 15.833050012588501, "val_acc": 72.0}
{"epoch": 26, "training_loss": 63.5493004322052, "training_acc": 69.0, "val_loss": 21.388918161392212, "val_acc": 76.0}
{"epoch": 27, "training_loss": 61.68107867240906, "training_acc": 78.0, "val_loss": 13.95772248506546, "val_acc": 72.0}
{"epoch": 28, "training_loss": 75.23418474197388, "training_acc": 70.0, "val_loss": 22.69532084465027, "val_acc": 72.0}
{"epoch": 29, "training_loss": 78.22927045822144, "training_acc": 77.0, "val_loss": 15.12775868177414, "val_acc": 76.0}
{"epoch": 30, "training_loss": 69.16273498535156, "training_acc": 69.0, "val_loss": 13.556812703609467, "val_acc": 80.0}
{"epoch": 31, "training_loss": 67.52229166030884, "training_acc": 82.0, "val_loss": 19.698886573314667, "val_acc": 76.0}
{"epoch": 32, "training_loss": 62.31517791748047, "training_acc": 67.0, "val_loss": 14.582431316375732, "val_acc": 68.0}
{"epoch": 33, "training_loss": 57.27705383300781, "training_acc": 79.0, "val_loss": 21.36997878551483, "val_acc": 72.0}
{"epoch": 34, "training_loss": 35.51194250583649, "training_acc": 85.0, "val_loss": 17.96332150697708, "val_acc": 72.0}
{"epoch": 35, "training_loss": 41.116833090782166, "training_acc": 81.0, "val_loss": 34.4808965921402, "val_acc": 72.0}
{"epoch": 36, "training_loss": 74.5587100982666, "training_acc": 76.0, "val_loss": 21.43891155719757, "val_acc": 60.0}
{"epoch": 37, "training_loss": 56.20394206047058, "training_acc": 73.0, "val_loss": 29.310697317123413, "val_acc": 72.0}
{"epoch": 38, "training_loss": 62.203994274139404, "training_acc": 75.0, "val_loss": 21.106334030628204, "val_acc": 56.0}
{"epoch": 39, "training_loss": 60.786802768707275, "training_acc": 69.0, "val_loss": 29.597121477127075, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.168102502822876, "training_acc": 77.0, "val_loss": 14.913776516914368, "val_acc": 68.0}
{"epoch": 41, "training_loss": 34.90043568611145, "training_acc": 83.0, "val_loss": 18.508996069431305, "val_acc": 76.0}
{"epoch": 42, "training_loss": 34.075944781303406, "training_acc": 85.0, "val_loss": 14.599820971488953, "val_acc": 64.0}
{"epoch": 43, "training_loss": 40.90968298912048, "training_acc": 81.0, "val_loss": 25.9185791015625, "val_acc": 72.0}
{"epoch": 44, "training_loss": 55.97190594673157, "training_acc": 78.0, "val_loss": 14.719727635383606, "val_acc": 68.0}
{"epoch": 45, "training_loss": 50.06393504142761, "training_acc": 75.0, "val_loss": 16.467347741127014, "val_acc": 80.0}
{"epoch": 46, "training_loss": 28.76136815547943, "training_acc": 87.0, "val_loss": 12.783858180046082, "val_acc": 68.0}
{"epoch": 47, "training_loss": 32.950613260269165, "training_acc": 82.0, "val_loss": 17.77116358280182, "val_acc": 72.0}
{"epoch": 48, "training_loss": 38.705034255981445, "training_acc": 85.0, "val_loss": 15.304809808731079, "val_acc": 80.0}
{"epoch": 49, "training_loss": 33.406919956207275, "training_acc": 86.0, "val_loss": 14.027439057826996, "val_acc": 60.0}
{"epoch": 50, "training_loss": 35.24403268098831, "training_acc": 81.0, "val_loss": 18.29385757446289, "val_acc": 72.0}
{"epoch": 51, "training_loss": 37.15164017677307, "training_acc": 86.0, "val_loss": 13.4611114859581, "val_acc": 68.0}
{"epoch": 52, "training_loss": 31.30278766155243, "training_acc": 89.0, "val_loss": 13.294413685798645, "val_acc": 72.0}
{"epoch": 53, "training_loss": 35.01191437244415, "training_acc": 83.0, "val_loss": 13.947074115276337, "val_acc": 68.0}
{"epoch": 54, "training_loss": 24.59680199623108, "training_acc": 88.0, "val_loss": 14.009743928909302, "val_acc": 68.0}
{"epoch": 55, "training_loss": 31.785889267921448, "training_acc": 89.0, "val_loss": 13.942576944828033, "val_acc": 64.0}
{"epoch": 56, "training_loss": 28.68211019039154, "training_acc": 87.0, "val_loss": 15.534433722496033, "val_acc": 76.0}
{"epoch": 57, "training_loss": 26.63950264453888, "training_acc": 87.0, "val_loss": 15.165355801582336, "val_acc": 64.0}
{"epoch": 58, "training_loss": 32.85319536924362, "training_acc": 81.0, "val_loss": 23.932570219039917, "val_acc": 72.0}
{"epoch": 59, "training_loss": 36.81434500217438, "training_acc": 84.0, "val_loss": 15.006089210510254, "val_acc": 72.0}
{"epoch": 60, "training_loss": 34.893012285232544, "training_acc": 85.0, "val_loss": 24.709662795066833, "val_acc": 72.0}
{"epoch": 61, "training_loss": 42.29558193683624, "training_acc": 81.0, "val_loss": 15.534690022468567, "val_acc": 68.0}
{"epoch": 62, "training_loss": 33.85084807872772, "training_acc": 84.0, "val_loss": 22.704631090164185, "val_acc": 72.0}
{"epoch": 63, "training_loss": 40.25283992290497, "training_acc": 81.0, "val_loss": 16.039550304412842, "val_acc": 64.0}
{"epoch": 64, "training_loss": 42.00430619716644, "training_acc": 83.0, "val_loss": 25.973036885261536, "val_acc": 72.0}
{"epoch": 65, "training_loss": 31.89225137233734, "training_acc": 85.0, "val_loss": 16.80511087179184, "val_acc": 64.0}
