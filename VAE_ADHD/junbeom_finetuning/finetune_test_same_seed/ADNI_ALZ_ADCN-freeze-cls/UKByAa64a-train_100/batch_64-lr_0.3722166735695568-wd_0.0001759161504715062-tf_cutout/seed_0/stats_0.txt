"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 647.138858795166, "training_acc": 72.0, "val_loss": 267.5429105758667, "val_acc": 72.0}
{"epoch": 1, "training_loss": 729.5271978378296, "training_acc": 72.0, "val_loss": 416.9675350189209, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1744.5431518554688, "training_acc": 28.0, "val_loss": 76.11639499664307, "val_acc": 36.0}
{"epoch": 3, "training_loss": 463.643123626709, "training_acc": 51.0, "val_loss": 237.3460054397583, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1066.4918785095215, "training_acc": 72.0, "val_loss": 315.1550769805908, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1256.867166519165, "training_acc": 72.0, "val_loss": 230.32546043395996, "val_acc": 72.0}
{"epoch": 6, "training_loss": 805.2946605682373, "training_acc": 72.0, "val_loss": 45.35759389400482, "val_acc": 72.0}
{"epoch": 7, "training_loss": 436.5185203552246, "training_acc": 63.0, "val_loss": 98.83391857147217, "val_acc": 44.0}
{"epoch": 8, "training_loss": 696.8148488998413, "training_acc": 45.0, "val_loss": 31.4737468957901, "val_acc": 80.0}
{"epoch": 9, "training_loss": 316.4709367752075, "training_acc": 72.0, "val_loss": 86.10003590583801, "val_acc": 72.0}
{"epoch": 10, "training_loss": 374.60500144958496, "training_acc": 73.0, "val_loss": 95.44469714164734, "val_acc": 72.0}
{"epoch": 11, "training_loss": 306.1851062774658, "training_acc": 71.0, "val_loss": 21.87049835920334, "val_acc": 80.0}
{"epoch": 12, "training_loss": 213.84540176391602, "training_acc": 61.0, "val_loss": 36.44789755344391, "val_acc": 56.0}
{"epoch": 13, "training_loss": 158.02093172073364, "training_acc": 64.0, "val_loss": 68.14136505126953, "val_acc": 72.0}
{"epoch": 14, "training_loss": 255.9903383255005, "training_acc": 72.0, "val_loss": 55.69929480552673, "val_acc": 72.0}
{"epoch": 15, "training_loss": 127.86195540428162, "training_acc": 68.0, "val_loss": 54.69093322753906, "val_acc": 40.0}
{"epoch": 16, "training_loss": 171.39552092552185, "training_acc": 50.0, "val_loss": 36.096930503845215, "val_acc": 72.0}
{"epoch": 17, "training_loss": 97.86094117164612, "training_acc": 72.0, "val_loss": 17.877574265003204, "val_acc": 56.0}
{"epoch": 18, "training_loss": 57.27379059791565, "training_acc": 66.0, "val_loss": 14.857250452041626, "val_acc": 80.0}
{"epoch": 19, "training_loss": 48.83056676387787, "training_acc": 76.0, "val_loss": 11.27852350473404, "val_acc": 88.0}
{"epoch": 20, "training_loss": 46.77373671531677, "training_acc": 77.0, "val_loss": 11.302100867033005, "val_acc": 88.0}
{"epoch": 21, "training_loss": 52.262876749038696, "training_acc": 77.0, "val_loss": 19.31788921356201, "val_acc": 52.0}
{"epoch": 22, "training_loss": 63.22520637512207, "training_acc": 67.0, "val_loss": 17.798908054828644, "val_acc": 72.0}
{"epoch": 23, "training_loss": 55.68130850791931, "training_acc": 74.0, "val_loss": 22.11148589849472, "val_acc": 48.0}
{"epoch": 24, "training_loss": 74.299311876297, "training_acc": 62.0, "val_loss": 14.656585454940796, "val_acc": 72.0}
{"epoch": 25, "training_loss": 52.314507484436035, "training_acc": 70.0, "val_loss": 11.972858011722565, "val_acc": 76.0}
{"epoch": 26, "training_loss": 40.781206488609314, "training_acc": 77.0, "val_loss": 12.78831660747528, "val_acc": 64.0}
{"epoch": 27, "training_loss": 45.08128774166107, "training_acc": 82.0, "val_loss": 12.05955445766449, "val_acc": 80.0}
{"epoch": 28, "training_loss": 39.77798509597778, "training_acc": 83.0, "val_loss": 11.74832135438919, "val_acc": 80.0}
{"epoch": 29, "training_loss": 39.685903549194336, "training_acc": 82.0, "val_loss": 13.843193650245667, "val_acc": 72.0}
{"epoch": 30, "training_loss": 39.917274594306946, "training_acc": 78.0, "val_loss": 15.750336647033691, "val_acc": 72.0}
{"epoch": 31, "training_loss": 39.820526123046875, "training_acc": 81.0, "val_loss": 20.94263732433319, "val_acc": 48.0}
{"epoch": 32, "training_loss": 54.569427847862244, "training_acc": 69.0, "val_loss": 18.050864338874817, "val_acc": 72.0}
{"epoch": 33, "training_loss": 47.30778121948242, "training_acc": 81.0, "val_loss": 12.327288091182709, "val_acc": 68.0}
{"epoch": 34, "training_loss": 46.23331308364868, "training_acc": 80.0, "val_loss": 12.510862946510315, "val_acc": 76.0}
{"epoch": 35, "training_loss": 41.08043146133423, "training_acc": 79.0, "val_loss": 14.872726798057556, "val_acc": 76.0}
{"epoch": 36, "training_loss": 37.55017900466919, "training_acc": 82.0, "val_loss": 11.95291131734848, "val_acc": 68.0}
{"epoch": 37, "training_loss": 33.92926573753357, "training_acc": 89.0, "val_loss": 11.224131286144257, "val_acc": 80.0}
{"epoch": 38, "training_loss": 34.389588594436646, "training_acc": 86.0, "val_loss": 11.132466793060303, "val_acc": 76.0}
{"epoch": 39, "training_loss": 38.92217135429382, "training_acc": 81.0, "val_loss": 11.009819060564041, "val_acc": 76.0}
{"epoch": 40, "training_loss": 37.585880756378174, "training_acc": 88.0, "val_loss": 11.066332459449768, "val_acc": 76.0}
{"epoch": 41, "training_loss": 35.2133104801178, "training_acc": 85.0, "val_loss": 11.387550085783005, "val_acc": 84.0}
{"epoch": 42, "training_loss": 42.61486577987671, "training_acc": 76.0, "val_loss": 17.08177477121353, "val_acc": 72.0}
{"epoch": 43, "training_loss": 42.4846048951149, "training_acc": 80.0, "val_loss": 16.44512116909027, "val_acc": 52.0}
{"epoch": 44, "training_loss": 48.256025195121765, "training_acc": 74.0, "val_loss": 13.80111426115036, "val_acc": 72.0}
{"epoch": 45, "training_loss": 36.07613801956177, "training_acc": 83.0, "val_loss": 16.838088631629944, "val_acc": 68.0}
{"epoch": 46, "training_loss": 34.25748312473297, "training_acc": 84.0, "val_loss": 13.114629685878754, "val_acc": 76.0}
{"epoch": 47, "training_loss": 31.76223647594452, "training_acc": 90.0, "val_loss": 13.52650672197342, "val_acc": 64.0}
{"epoch": 48, "training_loss": 27.958649396896362, "training_acc": 90.0, "val_loss": 15.688271820545197, "val_acc": 72.0}
{"epoch": 49, "training_loss": 32.942238211631775, "training_acc": 83.0, "val_loss": 17.808841168880463, "val_acc": 68.0}
{"epoch": 50, "training_loss": 38.338597536087036, "training_acc": 84.0, "val_loss": 13.606229424476624, "val_acc": 72.0}
{"epoch": 51, "training_loss": 29.317332446575165, "training_acc": 88.0, "val_loss": 13.4153351187706, "val_acc": 80.0}
{"epoch": 52, "training_loss": 34.142234086990356, "training_acc": 86.0, "val_loss": 12.679001688957214, "val_acc": 80.0}
{"epoch": 53, "training_loss": 32.97564458847046, "training_acc": 80.0, "val_loss": 14.172939956188202, "val_acc": 72.0}
{"epoch": 54, "training_loss": 32.149261116981506, "training_acc": 84.0, "val_loss": 12.336031347513199, "val_acc": 76.0}
{"epoch": 55, "training_loss": 30.751078605651855, "training_acc": 88.0, "val_loss": 12.225768715143204, "val_acc": 76.0}
{"epoch": 56, "training_loss": 34.382055044174194, "training_acc": 86.0, "val_loss": 16.002903878688812, "val_acc": 72.0}
{"epoch": 57, "training_loss": 34.31236261129379, "training_acc": 80.0, "val_loss": 12.731865048408508, "val_acc": 60.0}
{"epoch": 58, "training_loss": 50.368842124938965, "training_acc": 76.0, "val_loss": 12.335114181041718, "val_acc": 60.0}
