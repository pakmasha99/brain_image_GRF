"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6090.410900115967, "training_acc": 42.0, "val_loss": 3403.3470153808594, "val_acc": 72.0}
{"epoch": 1, "training_loss": 11940.417236328125, "training_acc": 72.0, "val_loss": 1341.5871620178223, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4995.323272705078, "training_acc": 40.0, "val_loss": 829.2235374450684, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3418.413131713867, "training_acc": 72.0, "val_loss": 841.9620513916016, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2208.835464477539, "training_acc": 66.0, "val_loss": 635.9290599822998, "val_acc": 44.0}
{"epoch": 5, "training_loss": 2834.1900482177734, "training_acc": 56.0, "val_loss": 682.6608657836914, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2059.655403137207, "training_acc": 74.0, "val_loss": 473.8130569458008, "val_acc": 68.0}
{"epoch": 7, "training_loss": 1250.8831672668457, "training_acc": 68.0, "val_loss": 512.7388954162598, "val_acc": 44.0}
{"epoch": 8, "training_loss": 2405.110179901123, "training_acc": 51.0, "val_loss": 647.1352577209473, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1738.6530647277832, "training_acc": 72.0, "val_loss": 282.7928304672241, "val_acc": 48.0}
{"epoch": 10, "training_loss": 857.904239654541, "training_acc": 59.0, "val_loss": 306.7391872406006, "val_acc": 64.0}
{"epoch": 11, "training_loss": 581.4879455566406, "training_acc": 76.0, "val_loss": 229.91342544555664, "val_acc": 48.0}
{"epoch": 12, "training_loss": 730.7097663879395, "training_acc": 51.0, "val_loss": 151.85848474502563, "val_acc": 64.0}
{"epoch": 13, "training_loss": 360.26645278930664, "training_acc": 76.0, "val_loss": 161.3868236541748, "val_acc": 76.0}
{"epoch": 14, "training_loss": 288.6264338493347, "training_acc": 79.0, "val_loss": 89.79648947715759, "val_acc": 72.0}
{"epoch": 15, "training_loss": 456.08387756347656, "training_acc": 61.0, "val_loss": 609.7752571105957, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3035.175491333008, "training_acc": 72.0, "val_loss": 776.0912895202637, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2210.3199405670166, "training_acc": 72.0, "val_loss": 1222.8151321411133, "val_acc": 28.0}
{"epoch": 18, "training_loss": 4628.897842407227, "training_acc": 28.0, "val_loss": 448.51441383361816, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1947.8694534301758, "training_acc": 72.0, "val_loss": 1000.6289482116699, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3252.5175018310547, "training_acc": 72.0, "val_loss": 291.6794776916504, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1256.9473342895508, "training_acc": 74.0, "val_loss": 567.388391494751, "val_acc": 52.0}
{"epoch": 22, "training_loss": 2236.2648334503174, "training_acc": 53.0, "val_loss": 666.994571685791, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2286.2508239746094, "training_acc": 74.0, "val_loss": 652.1668434143066, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1449.1241025924683, "training_acc": 76.0, "val_loss": 302.581524848938, "val_acc": 68.0}
{"epoch": 25, "training_loss": 1344.46675491333, "training_acc": 64.0, "val_loss": 263.67883682250977, "val_acc": 68.0}
{"epoch": 26, "training_loss": 883.156909942627, "training_acc": 74.0, "val_loss": 354.1253328323364, "val_acc": 72.0}
{"epoch": 27, "training_loss": 813.956974029541, "training_acc": 63.0, "val_loss": 111.89554929733276, "val_acc": 44.0}
{"epoch": 28, "training_loss": 817.1367874145508, "training_acc": 63.0, "val_loss": 375.72319507598877, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1054.2520217895508, "training_acc": 63.0, "val_loss": 162.84700632095337, "val_acc": 72.0}
{"epoch": 30, "training_loss": 359.7689895629883, "training_acc": 65.0, "val_loss": 206.17492198944092, "val_acc": 72.0}
{"epoch": 31, "training_loss": 352.75824785232544, "training_acc": 80.0, "val_loss": 97.55699038505554, "val_acc": 64.0}
{"epoch": 32, "training_loss": 300.87198066711426, "training_acc": 71.0, "val_loss": 126.44835710525513, "val_acc": 72.0}
{"epoch": 33, "training_loss": 193.4983730316162, "training_acc": 80.0, "val_loss": 75.0862181186676, "val_acc": 72.0}
{"epoch": 34, "training_loss": 181.1028847694397, "training_acc": 77.0, "val_loss": 133.77315998077393, "val_acc": 72.0}
{"epoch": 35, "training_loss": 525.6524238586426, "training_acc": 61.0, "val_loss": 322.14176654815674, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1155.2514419555664, "training_acc": 72.0, "val_loss": 112.11633682250977, "val_acc": 72.0}
{"epoch": 37, "training_loss": 729.1562271118164, "training_acc": 70.0, "val_loss": 68.57155561447144, "val_acc": 76.0}
{"epoch": 38, "training_loss": 602.8140258789062, "training_acc": 72.0, "val_loss": 514.0273094177246, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1350.3961458206177, "training_acc": 73.0, "val_loss": 401.617956161499, "val_acc": 44.0}
{"epoch": 40, "training_loss": 1483.8722686767578, "training_acc": 48.0, "val_loss": 413.0821704864502, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1042.7231521606445, "training_acc": 72.0, "val_loss": 161.9162917137146, "val_acc": 72.0}
{"epoch": 42, "training_loss": 804.8810195922852, "training_acc": 64.0, "val_loss": 197.17626571655273, "val_acc": 68.0}
{"epoch": 43, "training_loss": 475.2755126953125, "training_acc": 76.0, "val_loss": 209.03925895690918, "val_acc": 72.0}
{"epoch": 44, "training_loss": 431.5862503051758, "training_acc": 74.0, "val_loss": 157.24979639053345, "val_acc": 72.0}
{"epoch": 45, "training_loss": 277.40400791168213, "training_acc": 77.0, "val_loss": 126.04247331619263, "val_acc": 56.0}
{"epoch": 46, "training_loss": 580.2460193634033, "training_acc": 56.0, "val_loss": 96.62091732025146, "val_acc": 72.0}
{"epoch": 47, "training_loss": 476.57146072387695, "training_acc": 64.0, "val_loss": 429.6012878417969, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1596.7564392089844, "training_acc": 72.0, "val_loss": 378.89912128448486, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1172.5799674987793, "training_acc": 61.0, "val_loss": 132.8294038772583, "val_acc": 76.0}
{"epoch": 50, "training_loss": 509.8681831359863, "training_acc": 67.0, "val_loss": 333.6871862411499, "val_acc": 72.0}
{"epoch": 51, "training_loss": 712.1838130950928, "training_acc": 76.0, "val_loss": 226.61662101745605, "val_acc": 56.0}
{"epoch": 52, "training_loss": 714.9388880729675, "training_acc": 63.0, "val_loss": 269.07875537872314, "val_acc": 72.0}
{"epoch": 53, "training_loss": 476.4285206794739, "training_acc": 79.0, "val_loss": 115.10542631149292, "val_acc": 76.0}
{"epoch": 54, "training_loss": 180.96800088882446, "training_acc": 81.0, "val_loss": 87.88946270942688, "val_acc": 64.0}
{"epoch": 55, "training_loss": 157.17688083648682, "training_acc": 78.0, "val_loss": 326.28374099731445, "val_acc": 72.0}
{"epoch": 56, "training_loss": 1011.3379669189453, "training_acc": 72.0, "val_loss": 248.82831573486328, "val_acc": 32.0}
