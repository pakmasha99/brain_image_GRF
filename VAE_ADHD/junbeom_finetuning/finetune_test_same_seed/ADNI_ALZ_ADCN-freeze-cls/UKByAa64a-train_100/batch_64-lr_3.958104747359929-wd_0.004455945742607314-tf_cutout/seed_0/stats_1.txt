"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6276.094345092773, "training_acc": 72.0, "val_loss": 2753.905487060547, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8011.2578048706055, "training_acc": 72.0, "val_loss": 4752.412796020508, "val_acc": 28.0}
{"epoch": 2, "training_loss": 16621.645446777344, "training_acc": 28.0, "val_loss": 332.83989429473877, "val_acc": 76.0}
{"epoch": 3, "training_loss": 3108.7704010009766, "training_acc": 69.0, "val_loss": 2347.835922241211, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8653.292037963867, "training_acc": 72.0, "val_loss": 1894.5934295654297, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6168.813186645508, "training_acc": 72.0, "val_loss": 347.41692543029785, "val_acc": 56.0}
{"epoch": 6, "training_loss": 2878.268096923828, "training_acc": 62.0, "val_loss": 1064.9603843688965, "val_acc": 56.0}
{"epoch": 7, "training_loss": 3141.872245788574, "training_acc": 56.0, "val_loss": 818.4836387634277, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3453.229766845703, "training_acc": 72.0, "val_loss": 1235.4262351989746, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3799.039695739746, "training_acc": 72.0, "val_loss": 280.07543087005615, "val_acc": 68.0}
{"epoch": 10, "training_loss": 1584.1244430541992, "training_acc": 64.0, "val_loss": 589.6942615509033, "val_acc": 60.0}
{"epoch": 11, "training_loss": 2151.700107574463, "training_acc": 54.0, "val_loss": 725.9592056274414, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2723.354476928711, "training_acc": 72.0, "val_loss": 554.4291973114014, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1391.7100162506104, "training_acc": 73.0, "val_loss": 571.3529109954834, "val_acc": 44.0}
{"epoch": 14, "training_loss": 1409.4218759536743, "training_acc": 53.0, "val_loss": 470.8735466003418, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1580.4660568237305, "training_acc": 72.0, "val_loss": 95.50355076789856, "val_acc": 68.0}
{"epoch": 16, "training_loss": 910.8815155029297, "training_acc": 66.0, "val_loss": 141.90012216567993, "val_acc": 72.0}
{"epoch": 17, "training_loss": 389.66887855529785, "training_acc": 74.0, "val_loss": 148.2629418373108, "val_acc": 56.0}
{"epoch": 18, "training_loss": 276.21183919906616, "training_acc": 68.0, "val_loss": 186.7434859275818, "val_acc": 72.0}
{"epoch": 19, "training_loss": 362.690710067749, "training_acc": 74.0, "val_loss": 133.973228931427, "val_acc": 56.0}
{"epoch": 20, "training_loss": 455.42700386047363, "training_acc": 66.0, "val_loss": 216.19832515716553, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1050.6098861694336, "training_acc": 53.0, "val_loss": 249.0851879119873, "val_acc": 72.0}
{"epoch": 22, "training_loss": 731.6332397460938, "training_acc": 72.0, "val_loss": 99.04751181602478, "val_acc": 68.0}
{"epoch": 23, "training_loss": 492.96786308288574, "training_acc": 68.0, "val_loss": 173.4263777732849, "val_acc": 76.0}
{"epoch": 24, "training_loss": 585.6864643096924, "training_acc": 76.0, "val_loss": 94.04894709587097, "val_acc": 68.0}
{"epoch": 25, "training_loss": 472.8333320617676, "training_acc": 71.0, "val_loss": 224.11584854125977, "val_acc": 72.0}
{"epoch": 26, "training_loss": 775.0849723815918, "training_acc": 73.0, "val_loss": 123.2290506362915, "val_acc": 48.0}
{"epoch": 27, "training_loss": 275.70872020721436, "training_acc": 68.0, "val_loss": 204.26335334777832, "val_acc": 72.0}
{"epoch": 28, "training_loss": 408.58306646347046, "training_acc": 76.0, "val_loss": 173.3501434326172, "val_acc": 40.0}
{"epoch": 29, "training_loss": 919.0065765380859, "training_acc": 54.0, "val_loss": 456.04166984558105, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1183.476104259491, "training_acc": 71.0, "val_loss": 418.8094139099121, "val_acc": 36.0}
{"epoch": 31, "training_loss": 1401.7911186218262, "training_acc": 46.0, "val_loss": 463.19122314453125, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1272.032220363617, "training_acc": 74.0, "val_loss": 333.8700532913208, "val_acc": 44.0}
{"epoch": 33, "training_loss": 1066.9417457580566, "training_acc": 54.0, "val_loss": 226.6249418258667, "val_acc": 76.0}
{"epoch": 34, "training_loss": 550.3601264953613, "training_acc": 79.0, "val_loss": 231.84473514556885, "val_acc": 60.0}
{"epoch": 35, "training_loss": 588.7137727737427, "training_acc": 63.0, "val_loss": 195.81652879714966, "val_acc": 76.0}
{"epoch": 36, "training_loss": 493.0093183517456, "training_acc": 76.0, "val_loss": 231.2272310256958, "val_acc": 40.0}
{"epoch": 37, "training_loss": 952.3061485290527, "training_acc": 53.0, "val_loss": 448.4060764312744, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1186.6601400375366, "training_acc": 74.0, "val_loss": 642.8748607635498, "val_acc": 28.0}
{"epoch": 39, "training_loss": 1651.9474129676819, "training_acc": 45.0, "val_loss": 271.63472175598145, "val_acc": 72.0}
{"epoch": 40, "training_loss": 665.1490345001221, "training_acc": 75.0, "val_loss": 351.36871337890625, "val_acc": 40.0}
{"epoch": 41, "training_loss": 997.8797950744629, "training_acc": 53.0, "val_loss": 284.79857444763184, "val_acc": 76.0}
{"epoch": 42, "training_loss": 760.8334846496582, "training_acc": 73.0, "val_loss": 274.91888999938965, "val_acc": 52.0}
{"epoch": 43, "training_loss": 884.5392532348633, "training_acc": 54.0, "val_loss": 397.85239696502686, "val_acc": 72.0}
