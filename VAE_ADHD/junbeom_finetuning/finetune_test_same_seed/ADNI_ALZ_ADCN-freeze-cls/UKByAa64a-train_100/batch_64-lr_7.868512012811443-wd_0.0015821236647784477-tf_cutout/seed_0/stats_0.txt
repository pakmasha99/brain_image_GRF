"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12542.852123260498, "training_acc": 72.0, "val_loss": 5599.567413330078, "val_acc": 72.0}
{"epoch": 1, "training_loss": 14850.579116821289, "training_acc": 72.0, "val_loss": 9246.804809570312, "val_acc": 28.0}
{"epoch": 2, "training_loss": 38231.05505371094, "training_acc": 28.0, "val_loss": 1588.283920288086, "val_acc": 36.0}
{"epoch": 3, "training_loss": 9440.2373046875, "training_acc": 50.0, "val_loss": 5351.665496826172, "val_acc": 72.0}
{"epoch": 4, "training_loss": 24164.412231445312, "training_acc": 72.0, "val_loss": 7126.886749267578, "val_acc": 72.0}
{"epoch": 5, "training_loss": 28503.85772705078, "training_acc": 72.0, "val_loss": 5446.751022338867, "val_acc": 72.0}
{"epoch": 6, "training_loss": 19450.78057861328, "training_acc": 72.0, "val_loss": 1676.778793334961, "val_acc": 72.0}
{"epoch": 7, "training_loss": 8647.228637695312, "training_acc": 65.0, "val_loss": 2238.2898330688477, "val_acc": 44.0}
{"epoch": 8, "training_loss": 13270.354309082031, "training_acc": 44.0, "val_loss": 652.5302410125732, "val_acc": 84.0}
{"epoch": 9, "training_loss": 5747.271942138672, "training_acc": 66.0, "val_loss": 1879.8515319824219, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7639.487487792969, "training_acc": 72.0, "val_loss": 1943.757438659668, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6183.439682006836, "training_acc": 72.0, "val_loss": 504.28099632263184, "val_acc": 80.0}
{"epoch": 12, "training_loss": 5172.632293701172, "training_acc": 56.0, "val_loss": 654.6420097351074, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3432.831123352051, "training_acc": 63.0, "val_loss": 1572.4101066589355, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6068.3447265625, "training_acc": 72.0, "val_loss": 1389.8324966430664, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3272.425666809082, "training_acc": 73.0, "val_loss": 1657.3389053344727, "val_acc": 36.0}
{"epoch": 16, "training_loss": 6704.101760864258, "training_acc": 34.0, "val_loss": 920.0981140136719, "val_acc": 72.0}
{"epoch": 17, "training_loss": 3687.903518676758, "training_acc": 72.0, "val_loss": 1710.1181030273438, "val_acc": 72.0}
{"epoch": 18, "training_loss": 5306.269027709961, "training_acc": 72.0, "val_loss": 274.5361328125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3313.2510681152344, "training_acc": 54.0, "val_loss": 426.71685218811035, "val_acc": 56.0}
{"epoch": 20, "training_loss": 1505.4350357055664, "training_acc": 72.0, "val_loss": 1266.8818473815918, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4053.111541748047, "training_acc": 72.0, "val_loss": 232.12153911590576, "val_acc": 84.0}
{"epoch": 22, "training_loss": 2868.351531982422, "training_acc": 63.0, "val_loss": 465.920352935791, "val_acc": 64.0}
{"epoch": 23, "training_loss": 2798.919334411621, "training_acc": 66.0, "val_loss": 1205.5066108703613, "val_acc": 72.0}
{"epoch": 24, "training_loss": 4346.183898925781, "training_acc": 72.0, "val_loss": 359.8650932312012, "val_acc": 76.0}
{"epoch": 25, "training_loss": 3013.0215606689453, "training_acc": 63.0, "val_loss": 628.443717956543, "val_acc": 56.0}
{"epoch": 26, "training_loss": 2059.352481842041, "training_acc": 67.0, "val_loss": 913.9501571655273, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2821.752113342285, "training_acc": 72.0, "val_loss": 152.87232398986816, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2067.5325927734375, "training_acc": 61.0, "val_loss": 230.65202236175537, "val_acc": 68.0}
{"epoch": 29, "training_loss": 1298.1087188720703, "training_acc": 78.0, "val_loss": 682.9587459564209, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2043.6211013793945, "training_acc": 62.0, "val_loss": 185.8759880065918, "val_acc": 52.0}
{"epoch": 31, "training_loss": 1006.161750793457, "training_acc": 67.0, "val_loss": 135.18757820129395, "val_acc": 68.0}
{"epoch": 32, "training_loss": 422.0744400024414, "training_acc": 75.0, "val_loss": 100.42519569396973, "val_acc": 84.0}
{"epoch": 33, "training_loss": 443.3927526473999, "training_acc": 82.0, "val_loss": 84.36464667320251, "val_acc": 84.0}
{"epoch": 34, "training_loss": 363.555850982666, "training_acc": 78.0, "val_loss": 106.94741010665894, "val_acc": 68.0}
{"epoch": 35, "training_loss": 260.88466358184814, "training_acc": 79.0, "val_loss": 114.42753076553345, "val_acc": 56.0}
{"epoch": 36, "training_loss": 874.4177780151367, "training_acc": 66.0, "val_loss": 784.7846508026123, "val_acc": 72.0}
{"epoch": 37, "training_loss": 3923.3365783691406, "training_acc": 72.0, "val_loss": 740.7235145568848, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2162.1617889404297, "training_acc": 61.0, "val_loss": 71.19276523590088, "val_acc": 80.0}
{"epoch": 39, "training_loss": 671.2549438476562, "training_acc": 73.0, "val_loss": 187.09858655929565, "val_acc": 76.0}
{"epoch": 40, "training_loss": 697.7191581726074, "training_acc": 76.0, "val_loss": 272.1008777618408, "val_acc": 56.0}
{"epoch": 41, "training_loss": 1366.8886032104492, "training_acc": 67.0, "val_loss": 348.11604022979736, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1317.3636474609375, "training_acc": 69.0, "val_loss": 142.98627376556396, "val_acc": 76.0}
{"epoch": 43, "training_loss": 529.5242252349854, "training_acc": 73.0, "val_loss": 377.3221969604492, "val_acc": 72.0}
{"epoch": 44, "training_loss": 789.9549312591553, "training_acc": 69.0, "val_loss": 767.8390979766846, "val_acc": 36.0}
{"epoch": 45, "training_loss": 2380.2920989990234, "training_acc": 46.0, "val_loss": 693.4485912322998, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1820.0183501243591, "training_acc": 75.0, "val_loss": 850.4948616027832, "val_acc": 32.0}
{"epoch": 47, "training_loss": 2845.071506500244, "training_acc": 46.0, "val_loss": 663.4317398071289, "val_acc": 72.0}
{"epoch": 48, "training_loss": 2010.5292701721191, "training_acc": 73.0, "val_loss": 338.3193254470825, "val_acc": 56.0}
{"epoch": 49, "training_loss": 1420.6165962219238, "training_acc": 60.0, "val_loss": 650.7832527160645, "val_acc": 72.0}
{"epoch": 50, "training_loss": 2528.821174621582, "training_acc": 72.0, "val_loss": 270.324182510376, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1986.2996978759766, "training_acc": 61.0, "val_loss": 145.78553438186646, "val_acc": 64.0}
{"epoch": 52, "training_loss": 1088.080223083496, "training_acc": 73.0, "val_loss": 838.6161804199219, "val_acc": 72.0}
{"epoch": 53, "training_loss": 2365.460590362549, "training_acc": 68.0, "val_loss": 638.7477397918701, "val_acc": 48.0}
{"epoch": 54, "training_loss": 2029.0565719604492, "training_acc": 55.0, "val_loss": 590.9725189208984, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1477.9610233306885, "training_acc": 72.0, "val_loss": 681.7008972167969, "val_acc": 48.0}
{"epoch": 56, "training_loss": 2189.5208435058594, "training_acc": 59.0, "val_loss": 628.5528659820557, "val_acc": 72.0}
{"epoch": 57, "training_loss": 1572.8828716278076, "training_acc": 75.0, "val_loss": 443.2065010070801, "val_acc": 52.0}
