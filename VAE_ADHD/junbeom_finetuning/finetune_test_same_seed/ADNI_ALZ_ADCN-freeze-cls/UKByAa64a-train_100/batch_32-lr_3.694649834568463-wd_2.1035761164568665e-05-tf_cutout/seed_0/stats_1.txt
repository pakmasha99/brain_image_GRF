"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9266.609365463257, "training_acc": 71.0, "val_loss": 3621.15478515625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 9254.127227783203, "training_acc": 38.0, "val_loss": 956.7861557006836, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2386.8641357421875, "training_acc": 67.0, "val_loss": 988.7599945068359, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2735.58984375, "training_acc": 59.0, "val_loss": 1833.4375381469727, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6683.256378173828, "training_acc": 72.0, "val_loss": 255.93860149383545, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3036.2001037597656, "training_acc": 54.0, "val_loss": 337.3103141784668, "val_acc": 76.0}
{"epoch": 6, "training_loss": 2349.3995057344437, "training_acc": 74.0, "val_loss": 276.49779319763184, "val_acc": 76.0}
{"epoch": 7, "training_loss": 1687.5241394042969, "training_acc": 62.0, "val_loss": 202.75561809539795, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1181.7461795806885, "training_acc": 69.0, "val_loss": 174.94748830795288, "val_acc": 72.0}
{"epoch": 9, "training_loss": 385.12004184722855, "training_acc": 68.0, "val_loss": 322.56484031677246, "val_acc": 72.0}
{"epoch": 10, "training_loss": 707.37852409482, "training_acc": 69.0, "val_loss": 227.00767517089844, "val_acc": 72.0}
{"epoch": 11, "training_loss": 598.7407250404358, "training_acc": 69.0, "val_loss": 217.30961799621582, "val_acc": 76.0}
{"epoch": 12, "training_loss": 786.5675724392058, "training_acc": 71.0, "val_loss": 531.6634178161621, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1400.6075021997094, "training_acc": 70.0, "val_loss": 840.6172752380371, "val_acc": 36.0}
{"epoch": 14, "training_loss": 1954.6255855560303, "training_acc": 58.0, "val_loss": 163.81655931472778, "val_acc": 64.0}
{"epoch": 15, "training_loss": 893.4474906921387, "training_acc": 59.0, "val_loss": 545.1863765716553, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1074.1639289855957, "training_acc": 75.0, "val_loss": 259.0566396713257, "val_acc": 60.0}
{"epoch": 17, "training_loss": 1504.2179641723633, "training_acc": 74.0, "val_loss": 533.8364124298096, "val_acc": 36.0}
{"epoch": 18, "training_loss": 1455.8744201660156, "training_acc": 56.0, "val_loss": 1028.920555114746, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2940.6404304504395, "training_acc": 72.0, "val_loss": 258.74290466308594, "val_acc": 64.0}
{"epoch": 20, "training_loss": 684.4532165527344, "training_acc": 72.0, "val_loss": 195.3860640525818, "val_acc": 80.0}
{"epoch": 21, "training_loss": 344.2046842575073, "training_acc": 76.0, "val_loss": 580.0838947296143, "val_acc": 40.0}
{"epoch": 22, "training_loss": 1354.331069946289, "training_acc": 62.0, "val_loss": 182.61144161224365, "val_acc": 72.0}
{"epoch": 23, "training_loss": 967.1500511169434, "training_acc": 65.0, "val_loss": 476.41239166259766, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1076.4329986572266, "training_acc": 73.0, "val_loss": 254.67610359191895, "val_acc": 80.0}
{"epoch": 25, "training_loss": 914.9138765335083, "training_acc": 79.0, "val_loss": 253.60794067382812, "val_acc": 60.0}
{"epoch": 26, "training_loss": 426.1664276123047, "training_acc": 81.0, "val_loss": 359.77423191070557, "val_acc": 76.0}
{"epoch": 27, "training_loss": 850.5249824523926, "training_acc": 67.0, "val_loss": 503.8118362426758, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1179.573224067688, "training_acc": 63.0, "val_loss": 388.6981010437012, "val_acc": 76.0}
{"epoch": 29, "training_loss": 957.4289169311523, "training_acc": 70.0, "val_loss": 234.39176082611084, "val_acc": 80.0}
{"epoch": 30, "training_loss": 836.4206123352051, "training_acc": 80.0, "val_loss": 492.53554344177246, "val_acc": 40.0}
{"epoch": 31, "training_loss": 1371.2052459716797, "training_acc": 63.0, "val_loss": 515.0659084320068, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1403.8565216064453, "training_acc": 62.0, "val_loss": 270.79131603240967, "val_acc": 72.0}
{"epoch": 33, "training_loss": 970.1851692199707, "training_acc": 64.0, "val_loss": 411.90314292907715, "val_acc": 76.0}
