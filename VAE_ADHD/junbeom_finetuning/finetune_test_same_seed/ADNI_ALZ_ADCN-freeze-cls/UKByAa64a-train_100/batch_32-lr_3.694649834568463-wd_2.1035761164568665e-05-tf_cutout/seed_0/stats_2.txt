"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10732.751739501953, "training_acc": 71.0, "val_loss": 1099.5034217834473, "val_acc": 32.0}
{"epoch": 1, "training_loss": 4519.810073852539, "training_acc": 46.0, "val_loss": 1547.4398612976074, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3639.1683349609375, "training_acc": 73.0, "val_loss": 1830.4197311401367, "val_acc": 40.0}
{"epoch": 3, "training_loss": 5911.541206359863, "training_acc": 51.0, "val_loss": 1541.4678573608398, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4920.913638114929, "training_acc": 71.0, "val_loss": 733.0667018890381, "val_acc": 68.0}
{"epoch": 5, "training_loss": 1980.553695678711, "training_acc": 75.0, "val_loss": 587.8682136535645, "val_acc": 68.0}
{"epoch": 6, "training_loss": 1658.1272583007812, "training_acc": 74.0, "val_loss": 375.38487911224365, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1422.8694763183594, "training_acc": 62.0, "val_loss": 245.99356651306152, "val_acc": 60.0}
{"epoch": 8, "training_loss": 578.6678404808044, "training_acc": 69.0, "val_loss": 531.0884475708008, "val_acc": 40.0}
{"epoch": 9, "training_loss": 1118.4868354797363, "training_acc": 57.0, "val_loss": 228.21362018585205, "val_acc": 48.0}
{"epoch": 10, "training_loss": 791.9168891906738, "training_acc": 70.0, "val_loss": 383.660626411438, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1261.72092628479, "training_acc": 59.0, "val_loss": 618.1817054748535, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2607.9558296203613, "training_acc": 72.0, "val_loss": 325.33421516418457, "val_acc": 44.0}
{"epoch": 13, "training_loss": 888.7271766662598, "training_acc": 53.0, "val_loss": 672.628116607666, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3836.790313720703, "training_acc": 72.0, "val_loss": 313.6794090270996, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3633.8328704833984, "training_acc": 55.0, "val_loss": 431.8489074707031, "val_acc": 68.0}
{"epoch": 16, "training_loss": 2091.0233306884766, "training_acc": 73.0, "val_loss": 437.69965171813965, "val_acc": 80.0}
{"epoch": 17, "training_loss": 2052.66605758667, "training_acc": 65.0, "val_loss": 471.6453552246094, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1654.6833419799805, "training_acc": 76.0, "val_loss": 266.1198616027832, "val_acc": 84.0}
{"epoch": 19, "training_loss": 2030.1819763183594, "training_acc": 54.0, "val_loss": 785.0420951843262, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3172.2585525512695, "training_acc": 72.0, "val_loss": 266.72987937927246, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2167.8284587860107, "training_acc": 47.0, "val_loss": 831.0035705566406, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2367.9710693359375, "training_acc": 74.0, "val_loss": 456.31275177001953, "val_acc": 56.0}
{"epoch": 23, "training_loss": 2169.7210693359375, "training_acc": 65.0, "val_loss": 847.3018646240234, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2370.5173950195312, "training_acc": 76.0, "val_loss": 351.7185688018799, "val_acc": 80.0}
{"epoch": 25, "training_loss": 1160.024917602539, "training_acc": 72.0, "val_loss": 349.58462715148926, "val_acc": 68.0}
{"epoch": 26, "training_loss": 884.4670333862305, "training_acc": 76.0, "val_loss": 844.1967964172363, "val_acc": 40.0}
{"epoch": 27, "training_loss": 1976.143898010254, "training_acc": 57.0, "val_loss": 837.0585441589355, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1545.4559125322849, "training_acc": 79.0, "val_loss": 1287.0593070983887, "val_acc": 32.0}
