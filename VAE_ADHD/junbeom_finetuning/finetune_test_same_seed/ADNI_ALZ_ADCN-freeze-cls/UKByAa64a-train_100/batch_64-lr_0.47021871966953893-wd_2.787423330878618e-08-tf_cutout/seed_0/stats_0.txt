"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 805.8816871643066, "training_acc": 72.0, "val_loss": 337.77220249176025, "val_acc": 72.0}
{"epoch": 1, "training_loss": 920.8752384185791, "training_acc": 72.0, "val_loss": 527.0946025848389, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2205.525405883789, "training_acc": 28.0, "val_loss": 95.88915705680847, "val_acc": 36.0}
{"epoch": 3, "training_loss": 585.1967258453369, "training_acc": 51.0, "val_loss": 300.5791664123535, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1351.2195358276367, "training_acc": 72.0, "val_loss": 399.9549388885498, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1595.588623046875, "training_acc": 72.0, "val_loss": 293.86160373687744, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1029.7818698883057, "training_acc": 72.0, "val_loss": 60.49528121948242, "val_acc": 72.0}
{"epoch": 7, "training_loss": 548.9144744873047, "training_acc": 64.0, "val_loss": 122.81960248947144, "val_acc": 44.0}
{"epoch": 8, "training_loss": 878.0339813232422, "training_acc": 44.0, "val_loss": 40.02810716629028, "val_acc": 84.0}
{"epoch": 9, "training_loss": 403.14835262298584, "training_acc": 72.0, "val_loss": 106.81750774383545, "val_acc": 72.0}
{"epoch": 10, "training_loss": 469.3687496185303, "training_acc": 73.0, "val_loss": 122.43191003799438, "val_acc": 72.0}
{"epoch": 11, "training_loss": 392.8907175064087, "training_acc": 71.0, "val_loss": 26.525717973709106, "val_acc": 80.0}
{"epoch": 12, "training_loss": 265.8162670135498, "training_acc": 61.0, "val_loss": 45.81630527973175, "val_acc": 56.0}
{"epoch": 13, "training_loss": 198.60925722122192, "training_acc": 64.0, "val_loss": 84.62663292884827, "val_acc": 72.0}
{"epoch": 14, "training_loss": 317.6320400238037, "training_acc": 72.0, "val_loss": 69.20362710952759, "val_acc": 72.0}
{"epoch": 15, "training_loss": 156.59058475494385, "training_acc": 68.0, "val_loss": 63.5546088218689, "val_acc": 44.0}
{"epoch": 16, "training_loss": 200.67604064941406, "training_acc": 51.0, "val_loss": 40.804240107536316, "val_acc": 72.0}
{"epoch": 17, "training_loss": 103.99391198158264, "training_acc": 72.0, "val_loss": 19.731399416923523, "val_acc": 56.0}
{"epoch": 18, "training_loss": 65.25379347801208, "training_acc": 65.0, "val_loss": 14.245730638504028, "val_acc": 84.0}
{"epoch": 19, "training_loss": 60.38769841194153, "training_acc": 77.0, "val_loss": 12.105586379766464, "val_acc": 88.0}
{"epoch": 20, "training_loss": 48.142691016197205, "training_acc": 79.0, "val_loss": 10.974149405956268, "val_acc": 92.0}
{"epoch": 21, "training_loss": 44.998745918273926, "training_acc": 78.0, "val_loss": 21.339240670204163, "val_acc": 56.0}
{"epoch": 22, "training_loss": 74.14399838447571, "training_acc": 65.0, "val_loss": 14.470373094081879, "val_acc": 64.0}
{"epoch": 23, "training_loss": 62.94949388504028, "training_acc": 69.0, "val_loss": 12.16898187994957, "val_acc": 76.0}
{"epoch": 24, "training_loss": 54.65820074081421, "training_acc": 77.0, "val_loss": 15.153825283050537, "val_acc": 56.0}
{"epoch": 25, "training_loss": 43.88719391822815, "training_acc": 78.0, "val_loss": 22.466881573200226, "val_acc": 72.0}
{"epoch": 26, "training_loss": 69.01538562774658, "training_acc": 76.0, "val_loss": 28.14338505268097, "val_acc": 56.0}
{"epoch": 27, "training_loss": 93.695885181427, "training_acc": 60.0, "val_loss": 20.821581780910492, "val_acc": 72.0}
{"epoch": 28, "training_loss": 64.8702404499054, "training_acc": 73.0, "val_loss": 12.84835934638977, "val_acc": 64.0}
{"epoch": 29, "training_loss": 42.94001793861389, "training_acc": 79.0, "val_loss": 14.340957999229431, "val_acc": 68.0}
{"epoch": 30, "training_loss": 47.43446707725525, "training_acc": 74.0, "val_loss": 24.39730167388916, "val_acc": 72.0}
{"epoch": 31, "training_loss": 61.6181697845459, "training_acc": 73.0, "val_loss": 38.20639252662659, "val_acc": 48.0}
{"epoch": 32, "training_loss": 95.88099098205566, "training_acc": 62.0, "val_loss": 27.304813265800476, "val_acc": 72.0}
{"epoch": 33, "training_loss": 63.959450364112854, "training_acc": 77.0, "val_loss": 15.368059277534485, "val_acc": 64.0}
{"epoch": 34, "training_loss": 63.94870352745056, "training_acc": 75.0, "val_loss": 17.874404788017273, "val_acc": 76.0}
{"epoch": 35, "training_loss": 53.245173931121826, "training_acc": 76.0, "val_loss": 12.57430762052536, "val_acc": 76.0}
{"epoch": 36, "training_loss": 33.49092650413513, "training_acc": 85.0, "val_loss": 13.682429492473602, "val_acc": 80.0}
{"epoch": 37, "training_loss": 30.257959604263306, "training_acc": 85.0, "val_loss": 12.778876721858978, "val_acc": 76.0}
{"epoch": 38, "training_loss": 40.28930711746216, "training_acc": 83.0, "val_loss": 12.360163778066635, "val_acc": 76.0}
{"epoch": 39, "training_loss": 33.22026777267456, "training_acc": 87.0, "val_loss": 12.562499940395355, "val_acc": 68.0}
