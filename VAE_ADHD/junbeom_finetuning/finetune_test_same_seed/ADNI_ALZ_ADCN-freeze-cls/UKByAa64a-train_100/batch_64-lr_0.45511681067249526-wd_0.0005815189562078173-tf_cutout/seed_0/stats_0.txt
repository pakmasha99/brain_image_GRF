"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 767.121166229248, "training_acc": 72.0, "val_loss": 330.3070545196533, "val_acc": 72.0}
{"epoch": 1, "training_loss": 891.6038551330566, "training_acc": 72.0, "val_loss": 507.5685501098633, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2110.137420654297, "training_acc": 28.0, "val_loss": 80.39120435714722, "val_acc": 36.0}
{"epoch": 3, "training_loss": 524.0609855651855, "training_acc": 52.0, "val_loss": 311.3776683807373, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1406.7851333618164, "training_acc": 72.0, "val_loss": 417.6012992858887, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1673.594295501709, "training_acc": 72.0, "val_loss": 324.96180534362793, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1166.83256149292, "training_acc": 72.0, "val_loss": 108.64142179489136, "val_acc": 72.0}
{"epoch": 7, "training_loss": 530.9334392547607, "training_acc": 65.0, "val_loss": 129.72145080566406, "val_acc": 44.0}
{"epoch": 8, "training_loss": 825.2124786376953, "training_acc": 46.0, "val_loss": 60.73669195175171, "val_acc": 68.0}
{"epoch": 9, "training_loss": 428.1998920440674, "training_acc": 65.0, "val_loss": 92.88702011108398, "val_acc": 72.0}
{"epoch": 10, "training_loss": 426.79644203186035, "training_acc": 73.0, "val_loss": 141.42054319381714, "val_acc": 72.0}
{"epoch": 11, "training_loss": 491.89277267456055, "training_acc": 72.0, "val_loss": 40.32871425151825, "val_acc": 72.0}
{"epoch": 12, "training_loss": 259.64347648620605, "training_acc": 65.0, "val_loss": 64.92341756820679, "val_acc": 56.0}
{"epoch": 13, "training_loss": 399.82855129241943, "training_acc": 53.0, "val_loss": 31.82183802127838, "val_acc": 72.0}
{"epoch": 14, "training_loss": 213.76455783843994, "training_acc": 72.0, "val_loss": 99.06575083732605, "val_acc": 72.0}
{"epoch": 15, "training_loss": 303.8258867263794, "training_acc": 72.0, "val_loss": 22.55399525165558, "val_acc": 76.0}
{"epoch": 16, "training_loss": 165.09215927124023, "training_acc": 62.0, "val_loss": 42.83241033554077, "val_acc": 56.0}
{"epoch": 17, "training_loss": 141.10815048217773, "training_acc": 62.0, "val_loss": 94.40701603889465, "val_acc": 72.0}
{"epoch": 18, "training_loss": 330.4241065979004, "training_acc": 72.0, "val_loss": 52.45347023010254, "val_acc": 72.0}
{"epoch": 19, "training_loss": 230.28016567230225, "training_acc": 56.0, "val_loss": 61.06206178665161, "val_acc": 44.0}
{"epoch": 20, "training_loss": 149.76278567314148, "training_acc": 64.0, "val_loss": 67.25965738296509, "val_acc": 72.0}
{"epoch": 21, "training_loss": 233.56413173675537, "training_acc": 72.0, "val_loss": 26.904085278511047, "val_acc": 72.0}
{"epoch": 22, "training_loss": 134.6753010749817, "training_acc": 68.0, "val_loss": 38.13573718070984, "val_acc": 60.0}
{"epoch": 23, "training_loss": 167.7848801612854, "training_acc": 66.0, "val_loss": 37.50547766685486, "val_acc": 72.0}
{"epoch": 24, "training_loss": 146.34539079666138, "training_acc": 77.0, "val_loss": 18.797294795513153, "val_acc": 80.0}
{"epoch": 25, "training_loss": 121.99806213378906, "training_acc": 63.0, "val_loss": 17.83738136291504, "val_acc": 64.0}
{"epoch": 26, "training_loss": 58.808242321014404, "training_acc": 77.0, "val_loss": 28.77209782600403, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.59667444229126, "training_acc": 74.0, "val_loss": 28.67700457572937, "val_acc": 56.0}
{"epoch": 28, "training_loss": 81.84309315681458, "training_acc": 65.0, "val_loss": 34.95815992355347, "val_acc": 72.0}
{"epoch": 29, "training_loss": 87.04362225532532, "training_acc": 71.0, "val_loss": 31.860238313674927, "val_acc": 48.0}
{"epoch": 30, "training_loss": 67.48806512355804, "training_acc": 66.0, "val_loss": 35.68662703037262, "val_acc": 72.0}
{"epoch": 31, "training_loss": 99.95592737197876, "training_acc": 75.0, "val_loss": 26.51689052581787, "val_acc": 52.0}
{"epoch": 32, "training_loss": 94.46553671360016, "training_acc": 65.0, "val_loss": 12.132538855075836, "val_acc": 84.0}
{"epoch": 33, "training_loss": 62.91654455661774, "training_acc": 82.0, "val_loss": 16.038881242275238, "val_acc": 80.0}
{"epoch": 34, "training_loss": 53.67649292945862, "training_acc": 82.0, "val_loss": 21.324138343334198, "val_acc": 56.0}
{"epoch": 35, "training_loss": 61.37776970863342, "training_acc": 71.0, "val_loss": 26.351436972618103, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.91025793552399, "training_acc": 80.0, "val_loss": 26.637735962867737, "val_acc": 48.0}
{"epoch": 37, "training_loss": 85.50334167480469, "training_acc": 63.0, "val_loss": 17.300839722156525, "val_acc": 64.0}
{"epoch": 38, "training_loss": 44.59868264198303, "training_acc": 80.0, "val_loss": 14.876130223274231, "val_acc": 68.0}
{"epoch": 39, "training_loss": 40.64983129501343, "training_acc": 84.0, "val_loss": 14.499768614768982, "val_acc": 72.0}
{"epoch": 40, "training_loss": 36.06321609020233, "training_acc": 85.0, "val_loss": 13.522304594516754, "val_acc": 76.0}
{"epoch": 41, "training_loss": 32.17354464530945, "training_acc": 87.0, "val_loss": 12.173210084438324, "val_acc": 80.0}
{"epoch": 42, "training_loss": 43.35018491744995, "training_acc": 76.0, "val_loss": 25.29459297657013, "val_acc": 72.0}
{"epoch": 43, "training_loss": 62.48827254772186, "training_acc": 76.0, "val_loss": 15.11656939983368, "val_acc": 60.0}
{"epoch": 44, "training_loss": 39.74200201034546, "training_acc": 76.0, "val_loss": 16.489873826503754, "val_acc": 72.0}
{"epoch": 45, "training_loss": 33.806240916252136, "training_acc": 84.0, "val_loss": 18.307898938655853, "val_acc": 52.0}
{"epoch": 46, "training_loss": 42.606308460235596, "training_acc": 81.0, "val_loss": 21.513600647449493, "val_acc": 72.0}
{"epoch": 47, "training_loss": 44.63072222471237, "training_acc": 82.0, "val_loss": 18.619464337825775, "val_acc": 52.0}
{"epoch": 48, "training_loss": 40.69425845146179, "training_acc": 83.0, "val_loss": 25.44204592704773, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.793421149253845, "training_acc": 78.0, "val_loss": 20.253905653953552, "val_acc": 52.0}
{"epoch": 50, "training_loss": 52.79819971323013, "training_acc": 74.0, "val_loss": 27.169010043144226, "val_acc": 72.0}
{"epoch": 51, "training_loss": 63.998433351516724, "training_acc": 80.0, "val_loss": 25.80220401287079, "val_acc": 52.0}
