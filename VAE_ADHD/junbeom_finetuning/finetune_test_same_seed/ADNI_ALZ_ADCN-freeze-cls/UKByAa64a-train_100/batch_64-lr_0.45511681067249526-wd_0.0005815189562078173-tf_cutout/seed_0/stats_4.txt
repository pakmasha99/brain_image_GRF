"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 674.4593353271484, "training_acc": 68.0, "val_loss": 343.1159019470215, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1020.8157043457031, "training_acc": 72.0, "val_loss": 384.3247652053833, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1688.910171508789, "training_acc": 29.0, "val_loss": 57.47278332710266, "val_acc": 60.0}
{"epoch": 3, "training_loss": 376.2074203491211, "training_acc": 61.0, "val_loss": 320.61564922332764, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1244.9221382141113, "training_acc": 72.0, "val_loss": 366.131067276001, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1240.2120895385742, "training_acc": 72.0, "val_loss": 223.20256233215332, "val_acc": 72.0}
{"epoch": 6, "training_loss": 535.0476288795471, "training_acc": 73.0, "val_loss": 112.3593807220459, "val_acc": 60.0}
{"epoch": 7, "training_loss": 826.8366775512695, "training_acc": 46.0, "val_loss": 120.73571681976318, "val_acc": 56.0}
{"epoch": 8, "training_loss": 679.9851989746094, "training_acc": 49.0, "val_loss": 149.8595952987671, "val_acc": 72.0}
{"epoch": 9, "training_loss": 438.17406463623047, "training_acc": 74.0, "val_loss": 230.85336685180664, "val_acc": 72.0}
{"epoch": 10, "training_loss": 710.4889822006226, "training_acc": 72.0, "val_loss": 151.771879196167, "val_acc": 72.0}
{"epoch": 11, "training_loss": 292.8022584915161, "training_acc": 72.0, "val_loss": 75.81109404563904, "val_acc": 68.0}
{"epoch": 12, "training_loss": 451.0918426513672, "training_acc": 61.0, "val_loss": 82.26980566978455, "val_acc": 52.0}
{"epoch": 13, "training_loss": 404.5738859176636, "training_acc": 56.0, "val_loss": 108.87278318405151, "val_acc": 72.0}
{"epoch": 14, "training_loss": 387.32218170166016, "training_acc": 72.0, "val_loss": 125.82833766937256, "val_acc": 72.0}
{"epoch": 15, "training_loss": 354.6889066696167, "training_acc": 72.0, "val_loss": 33.04695785045624, "val_acc": 60.0}
{"epoch": 16, "training_loss": 223.64917755126953, "training_acc": 51.0, "val_loss": 26.739665865898132, "val_acc": 64.0}
{"epoch": 17, "training_loss": 119.32755708694458, "training_acc": 73.0, "val_loss": 70.42677998542786, "val_acc": 72.0}
{"epoch": 18, "training_loss": 273.548264503479, "training_acc": 72.0, "val_loss": 12.911203503608704, "val_acc": 72.0}
{"epoch": 19, "training_loss": 119.5457649230957, "training_acc": 65.0, "val_loss": 28.796538710594177, "val_acc": 48.0}
{"epoch": 20, "training_loss": 156.9578456878662, "training_acc": 58.0, "val_loss": 74.29862022399902, "val_acc": 72.0}
{"epoch": 21, "training_loss": 285.5537405014038, "training_acc": 72.0, "val_loss": 14.814910292625427, "val_acc": 72.0}
{"epoch": 22, "training_loss": 120.62927150726318, "training_acc": 66.0, "val_loss": 24.41667765378952, "val_acc": 60.0}
{"epoch": 23, "training_loss": 115.11961221694946, "training_acc": 68.0, "val_loss": 56.90795183181763, "val_acc": 72.0}
{"epoch": 24, "training_loss": 159.85966563224792, "training_acc": 77.0, "val_loss": 22.559422254562378, "val_acc": 72.0}
{"epoch": 25, "training_loss": 89.72152948379517, "training_acc": 68.0, "val_loss": 23.901359736919403, "val_acc": 56.0}
{"epoch": 26, "training_loss": 76.98779106140137, "training_acc": 71.0, "val_loss": 35.23669242858887, "val_acc": 76.0}
{"epoch": 27, "training_loss": 94.6606879234314, "training_acc": 79.0, "val_loss": 21.69058918952942, "val_acc": 56.0}
{"epoch": 28, "training_loss": 104.58175897598267, "training_acc": 58.0, "val_loss": 34.53840613365173, "val_acc": 72.0}
{"epoch": 29, "training_loss": 162.2470235824585, "training_acc": 72.0, "val_loss": 23.477938771247864, "val_acc": 72.0}
{"epoch": 30, "training_loss": 171.8626766204834, "training_acc": 56.0, "val_loss": 14.802771806716919, "val_acc": 48.0}
{"epoch": 31, "training_loss": 105.36530303955078, "training_acc": 70.0, "val_loss": 56.571221351623535, "val_acc": 72.0}
{"epoch": 32, "training_loss": 149.44164180755615, "training_acc": 73.0, "val_loss": 30.10728359222412, "val_acc": 48.0}
{"epoch": 33, "training_loss": 119.82316207885742, "training_acc": 62.0, "val_loss": 33.01932215690613, "val_acc": 76.0}
{"epoch": 34, "training_loss": 104.57949733734131, "training_acc": 79.0, "val_loss": 33.20711553096771, "val_acc": 76.0}
{"epoch": 35, "training_loss": 104.86164140701294, "training_acc": 73.0, "val_loss": 21.686431765556335, "val_acc": 68.0}
{"epoch": 36, "training_loss": 96.87162733078003, "training_acc": 69.0, "val_loss": 38.45514953136444, "val_acc": 76.0}
{"epoch": 37, "training_loss": 83.19563221931458, "training_acc": 76.0, "val_loss": 34.64782536029816, "val_acc": 44.0}
