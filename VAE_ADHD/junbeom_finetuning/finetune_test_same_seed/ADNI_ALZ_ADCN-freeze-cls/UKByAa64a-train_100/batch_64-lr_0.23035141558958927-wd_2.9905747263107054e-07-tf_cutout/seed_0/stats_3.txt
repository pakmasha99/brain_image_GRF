"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 930.7417678833008, "training_acc": 46.0, "val_loss": 617.2394275665283, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2076.544677734375, "training_acc": 72.0, "val_loss": 385.8098268508911, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1183.3862686157227, "training_acc": 28.0, "val_loss": 239.28587436676025, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1297.2493743896484, "training_acc": 72.0, "val_loss": 476.36828422546387, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1873.2582778930664, "training_acc": 72.0, "val_loss": 346.3019847869873, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1172.0812530517578, "training_acc": 72.0, "val_loss": 19.870127737522125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1094.469093322754, "training_acc": 44.0, "val_loss": 590.8080101013184, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1888.7576293945312, "training_acc": 28.0, "val_loss": 136.354398727417, "val_acc": 72.0}
{"epoch": 8, "training_loss": 774.2091255187988, "training_acc": 72.0, "val_loss": 393.7262535095215, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1617.0718994140625, "training_acc": 72.0, "val_loss": 415.9197807312012, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1561.5304260253906, "training_acc": 72.0, "val_loss": 254.25527095794678, "val_acc": 72.0}
{"epoch": 11, "training_loss": 762.4684238433838, "training_acc": 72.0, "val_loss": 210.38239002227783, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1025.26513671875, "training_acc": 28.0, "val_loss": 124.5160698890686, "val_acc": 28.0}
{"epoch": 13, "training_loss": 597.1665134429932, "training_acc": 38.0, "val_loss": 249.798583984375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1105.4759674072266, "training_acc": 72.0, "val_loss": 318.4028148651123, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1216.6610374450684, "training_acc": 72.0, "val_loss": 198.68067502975464, "val_acc": 72.0}
{"epoch": 16, "training_loss": 603.7741317749023, "training_acc": 72.0, "val_loss": 159.3494415283203, "val_acc": 28.0}
{"epoch": 17, "training_loss": 749.7759666442871, "training_acc": 28.0, "val_loss": 13.652174174785614, "val_acc": 68.0}
{"epoch": 18, "training_loss": 160.34853267669678, "training_acc": 75.0, "val_loss": 145.55950164794922, "val_acc": 72.0}
{"epoch": 19, "training_loss": 579.166337966919, "training_acc": 72.0, "val_loss": 100.69961547851562, "val_acc": 72.0}
{"epoch": 20, "training_loss": 283.49667501449585, "training_acc": 72.0, "val_loss": 225.2840280532837, "val_acc": 28.0}
{"epoch": 21, "training_loss": 842.3290405273438, "training_acc": 28.0, "val_loss": 51.99887156486511, "val_acc": 72.0}
{"epoch": 22, "training_loss": 279.96913051605225, "training_acc": 72.0, "val_loss": 142.93519258499146, "val_acc": 72.0}
{"epoch": 23, "training_loss": 540.5399169921875, "training_acc": 72.0, "val_loss": 59.64173078536987, "val_acc": 72.0}
{"epoch": 24, "training_loss": 302.59850883483887, "training_acc": 56.0, "val_loss": 50.30719041824341, "val_acc": 28.0}
{"epoch": 25, "training_loss": 268.3264045715332, "training_acc": 44.0, "val_loss": 161.27382516860962, "val_acc": 72.0}
{"epoch": 26, "training_loss": 660.3138275146484, "training_acc": 72.0, "val_loss": 147.03153371810913, "val_acc": 72.0}
{"epoch": 27, "training_loss": 481.0434627532959, "training_acc": 72.0, "val_loss": 59.16397571563721, "val_acc": 28.0}
{"epoch": 28, "training_loss": 208.8369779586792, "training_acc": 28.0, "val_loss": 87.07314729690552, "val_acc": 72.0}
{"epoch": 29, "training_loss": 398.24895095825195, "training_acc": 72.0, "val_loss": 140.63481092453003, "val_acc": 72.0}
{"epoch": 30, "training_loss": 503.36462211608887, "training_acc": 72.0, "val_loss": 27.26099193096161, "val_acc": 72.0}
{"epoch": 31, "training_loss": 360.56214904785156, "training_acc": 58.0, "val_loss": 197.49702215194702, "val_acc": 28.0}
{"epoch": 32, "training_loss": 502.7959396839142, "training_acc": 50.0, "val_loss": 98.11486601829529, "val_acc": 72.0}
{"epoch": 33, "training_loss": 408.0435028076172, "training_acc": 72.0, "val_loss": 92.79086589813232, "val_acc": 72.0}
{"epoch": 34, "training_loss": 291.27070212364197, "training_acc": 72.0, "val_loss": 161.64913177490234, "val_acc": 28.0}
{"epoch": 35, "training_loss": 542.1773118972778, "training_acc": 28.0, "val_loss": 97.2517192363739, "val_acc": 72.0}
{"epoch": 36, "training_loss": 473.8543453216553, "training_acc": 72.0, "val_loss": 204.9055814743042, "val_acc": 72.0}
