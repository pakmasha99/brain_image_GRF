"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.46912431716919, "training_acc": 72.0, "val_loss": 14.985606074333191, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.09716057777405, "training_acc": 72.0, "val_loss": 15.054614841938019, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.5287983417511, "training_acc": 72.0, "val_loss": 14.823928475379944, "val_acc": 72.0}
{"epoch": 3, "training_loss": 58.62708234786987, "training_acc": 72.0, "val_loss": 14.618977904319763, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.14214873313904, "training_acc": 72.0, "val_loss": 14.618772268295288, "val_acc": 72.0}
{"epoch": 5, "training_loss": 56.85373616218567, "training_acc": 72.0, "val_loss": 14.468741416931152, "val_acc": 72.0}
{"epoch": 6, "training_loss": 56.41690468788147, "training_acc": 72.0, "val_loss": 14.55976814031601, "val_acc": 72.0}
{"epoch": 7, "training_loss": 56.91371047496796, "training_acc": 72.0, "val_loss": 14.74851667881012, "val_acc": 72.0}
{"epoch": 8, "training_loss": 55.92151880264282, "training_acc": 72.0, "val_loss": 14.812465012073517, "val_acc": 72.0}
{"epoch": 9, "training_loss": 56.04562604427338, "training_acc": 72.0, "val_loss": 14.735817909240723, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.458824157714844, "training_acc": 72.0, "val_loss": 14.674261212348938, "val_acc": 72.0}
{"epoch": 11, "training_loss": 55.84506130218506, "training_acc": 72.0, "val_loss": 14.457575976848602, "val_acc": 72.0}
{"epoch": 12, "training_loss": 54.62700593471527, "training_acc": 73.0, "val_loss": 14.384904503822327, "val_acc": 76.0}
{"epoch": 13, "training_loss": 55.06291627883911, "training_acc": 75.0, "val_loss": 14.37007337808609, "val_acc": 72.0}
{"epoch": 14, "training_loss": 54.51000452041626, "training_acc": 76.0, "val_loss": 14.352382719516754, "val_acc": 72.0}
{"epoch": 15, "training_loss": 55.38089036941528, "training_acc": 73.0, "val_loss": 14.348021149635315, "val_acc": 72.0}
{"epoch": 16, "training_loss": 54.3606573343277, "training_acc": 74.0, "val_loss": 14.478379487991333, "val_acc": 72.0}
{"epoch": 17, "training_loss": 55.09633111953735, "training_acc": 75.0, "val_loss": 14.621502161026001, "val_acc": 72.0}
{"epoch": 18, "training_loss": 54.34966444969177, "training_acc": 74.0, "val_loss": 14.690259099006653, "val_acc": 72.0}
{"epoch": 19, "training_loss": 53.53159165382385, "training_acc": 73.0, "val_loss": 14.756546914577484, "val_acc": 72.0}
{"epoch": 20, "training_loss": 53.6524875164032, "training_acc": 74.0, "val_loss": 14.476834237575531, "val_acc": 76.0}
{"epoch": 21, "training_loss": 54.91137385368347, "training_acc": 74.0, "val_loss": 14.398831129074097, "val_acc": 72.0}
{"epoch": 22, "training_loss": 55.846203327178955, "training_acc": 70.0, "val_loss": 14.395327866077423, "val_acc": 72.0}
{"epoch": 23, "training_loss": 55.58522963523865, "training_acc": 73.0, "val_loss": 14.52832818031311, "val_acc": 76.0}
{"epoch": 24, "training_loss": 52.07583045959473, "training_acc": 75.0, "val_loss": 14.469718933105469, "val_acc": 76.0}
{"epoch": 25, "training_loss": 55.1914381980896, "training_acc": 73.0, "val_loss": 14.529064297676086, "val_acc": 76.0}
{"epoch": 26, "training_loss": 53.16429853439331, "training_acc": 78.0, "val_loss": 14.670708775520325, "val_acc": 72.0}
{"epoch": 27, "training_loss": 52.399484038352966, "training_acc": 75.0, "val_loss": 14.775188267230988, "val_acc": 72.0}
{"epoch": 28, "training_loss": 54.285733342170715, "training_acc": 75.0, "val_loss": 14.711885154247284, "val_acc": 72.0}
{"epoch": 29, "training_loss": 52.06249213218689, "training_acc": 76.0, "val_loss": 14.592501521110535, "val_acc": 76.0}
{"epoch": 30, "training_loss": 52.4272301197052, "training_acc": 76.0, "val_loss": 14.514417946338654, "val_acc": 72.0}
{"epoch": 31, "training_loss": 53.88592338562012, "training_acc": 75.0, "val_loss": 14.564606547355652, "val_acc": 76.0}
{"epoch": 32, "training_loss": 52.51193296909332, "training_acc": 75.0, "val_loss": 14.870402216911316, "val_acc": 72.0}
{"epoch": 33, "training_loss": 54.94346225261688, "training_acc": 74.0, "val_loss": 15.338204801082611, "val_acc": 68.0}
{"epoch": 34, "training_loss": 55.81844520568848, "training_acc": 73.0, "val_loss": 15.214213728904724, "val_acc": 68.0}
