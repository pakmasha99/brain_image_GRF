"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.68380236625671, "training_acc": 62.0, "val_loss": 15.113858878612518, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.188473761081696, "training_acc": 72.0, "val_loss": 15.563584864139557, "val_acc": 72.0}
{"epoch": 2, "training_loss": 63.29808306694031, "training_acc": 72.0, "val_loss": 15.911060571670532, "val_acc": 72.0}
{"epoch": 3, "training_loss": 63.34152317047119, "training_acc": 72.0, "val_loss": 15.438328683376312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 61.71621358394623, "training_acc": 72.0, "val_loss": 14.808085560798645, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.65358281135559, "training_acc": 72.0, "val_loss": 14.599752426147461, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.51217532157898, "training_acc": 72.0, "val_loss": 14.468090236186981, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.12627649307251, "training_acc": 72.0, "val_loss": 14.388029277324677, "val_acc": 68.0}
{"epoch": 8, "training_loss": 56.79115009307861, "training_acc": 72.0, "val_loss": 14.28915411233902, "val_acc": 68.0}
{"epoch": 9, "training_loss": 56.45494270324707, "training_acc": 72.0, "val_loss": 14.214706420898438, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.87774407863617, "training_acc": 72.0, "val_loss": 14.202617108821869, "val_acc": 76.0}
{"epoch": 11, "training_loss": 54.97069549560547, "training_acc": 72.0, "val_loss": 14.181652665138245, "val_acc": 76.0}
{"epoch": 12, "training_loss": 55.22825813293457, "training_acc": 72.0, "val_loss": 14.054195582866669, "val_acc": 68.0}
{"epoch": 13, "training_loss": 56.103551149368286, "training_acc": 72.0, "val_loss": 14.068672060966492, "val_acc": 80.0}
{"epoch": 14, "training_loss": 56.229485511779785, "training_acc": 72.0, "val_loss": 14.026205241680145, "val_acc": 80.0}
{"epoch": 15, "training_loss": 56.34994721412659, "training_acc": 72.0, "val_loss": 13.990752398967743, "val_acc": 80.0}
{"epoch": 16, "training_loss": 55.90023946762085, "training_acc": 71.0, "val_loss": 13.995599746704102, "val_acc": 68.0}
{"epoch": 17, "training_loss": 53.4294468164444, "training_acc": 74.0, "val_loss": 14.288657903671265, "val_acc": 76.0}
{"epoch": 18, "training_loss": 54.16043782234192, "training_acc": 72.0, "val_loss": 14.776679873466492, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.55818557739258, "training_acc": 72.0, "val_loss": 14.960132539272308, "val_acc": 72.0}
{"epoch": 20, "training_loss": 54.66818189620972, "training_acc": 72.0, "val_loss": 14.321967959403992, "val_acc": 72.0}
{"epoch": 21, "training_loss": 53.731892585754395, "training_acc": 72.0, "val_loss": 13.946497440338135, "val_acc": 76.0}
{"epoch": 22, "training_loss": 56.43830370903015, "training_acc": 72.0, "val_loss": 14.00158703327179, "val_acc": 80.0}
{"epoch": 23, "training_loss": 55.56299090385437, "training_acc": 76.0, "val_loss": 13.969878852367401, "val_acc": 80.0}
{"epoch": 24, "training_loss": 55.52471435070038, "training_acc": 72.0, "val_loss": 14.101384580135345, "val_acc": 68.0}
{"epoch": 25, "training_loss": 53.07578921318054, "training_acc": 74.0, "val_loss": 14.503754675388336, "val_acc": 68.0}
{"epoch": 26, "training_loss": 54.738983154296875, "training_acc": 74.0, "val_loss": 14.602242410182953, "val_acc": 76.0}
{"epoch": 27, "training_loss": 54.032803535461426, "training_acc": 75.0, "val_loss": 14.439703524112701, "val_acc": 68.0}
{"epoch": 28, "training_loss": 55.886717796325684, "training_acc": 73.0, "val_loss": 14.312826097011566, "val_acc": 68.0}
{"epoch": 29, "training_loss": 55.18536067008972, "training_acc": 73.0, "val_loss": 14.394557476043701, "val_acc": 68.0}
{"epoch": 30, "training_loss": 54.62156677246094, "training_acc": 76.0, "val_loss": 14.413610100746155, "val_acc": 68.0}
{"epoch": 31, "training_loss": 54.30384695529938, "training_acc": 73.0, "val_loss": 14.611592888832092, "val_acc": 76.0}
{"epoch": 32, "training_loss": 54.93898153305054, "training_acc": 72.0, "val_loss": 14.667913317680359, "val_acc": 76.0}
{"epoch": 33, "training_loss": 54.68661642074585, "training_acc": 73.0, "val_loss": 14.138588309288025, "val_acc": 68.0}
{"epoch": 34, "training_loss": 52.782915353775024, "training_acc": 74.0, "val_loss": 13.978058099746704, "val_acc": 80.0}
{"epoch": 35, "training_loss": 54.66258382797241, "training_acc": 75.0, "val_loss": 14.066614210605621, "val_acc": 72.0}
{"epoch": 36, "training_loss": 54.6072678565979, "training_acc": 74.0, "val_loss": 13.948796689510345, "val_acc": 80.0}
{"epoch": 37, "training_loss": 52.185999751091, "training_acc": 73.0, "val_loss": 13.986268639564514, "val_acc": 68.0}
{"epoch": 38, "training_loss": 52.50802981853485, "training_acc": 76.0, "val_loss": 14.37622755765915, "val_acc": 76.0}
{"epoch": 39, "training_loss": 53.33429777622223, "training_acc": 72.0, "val_loss": 14.97458666563034, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.670140504837036, "training_acc": 72.0, "val_loss": 15.270543098449707, "val_acc": 72.0}
