"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 64.89363527297974, "training_acc": 72.0, "val_loss": 15.168735384941101, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.16086006164551, "training_acc": 72.0, "val_loss": 14.799608290195465, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.21678352355957, "training_acc": 72.0, "val_loss": 14.62886929512024, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.09625029563904, "training_acc": 72.0, "val_loss": 14.397360384464264, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.45633792877197, "training_acc": 72.0, "val_loss": 14.171712100505829, "val_acc": 72.0}
{"epoch": 5, "training_loss": 57.68373084068298, "training_acc": 72.0, "val_loss": 13.972809910774231, "val_acc": 72.0}
{"epoch": 6, "training_loss": 56.98797011375427, "training_acc": 72.0, "val_loss": 13.846319913864136, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.43819618225098, "training_acc": 72.0, "val_loss": 13.751266896724701, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.25850772857666, "training_acc": 72.0, "val_loss": 13.680936396121979, "val_acc": 72.0}
{"epoch": 9, "training_loss": 57.310795545578, "training_acc": 72.0, "val_loss": 13.417243957519531, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.403029441833496, "training_acc": 72.0, "val_loss": 13.3292555809021, "val_acc": 72.0}
{"epoch": 11, "training_loss": 55.46720838546753, "training_acc": 72.0, "val_loss": 13.22825402021408, "val_acc": 76.0}
{"epoch": 12, "training_loss": 56.43321204185486, "training_acc": 72.0, "val_loss": 13.162961602210999, "val_acc": 76.0}
{"epoch": 13, "training_loss": 57.67380475997925, "training_acc": 73.0, "val_loss": 13.131953775882721, "val_acc": 76.0}
{"epoch": 14, "training_loss": 56.299744844436646, "training_acc": 72.0, "val_loss": 13.217097520828247, "val_acc": 72.0}
{"epoch": 15, "training_loss": 56.665950298309326, "training_acc": 72.0, "val_loss": 13.225005567073822, "val_acc": 72.0}
{"epoch": 16, "training_loss": 55.46174514293671, "training_acc": 72.0, "val_loss": 13.107520341873169, "val_acc": 72.0}
{"epoch": 17, "training_loss": 55.41412794589996, "training_acc": 72.0, "val_loss": 13.140133023262024, "val_acc": 72.0}
{"epoch": 18, "training_loss": 56.28352236747742, "training_acc": 72.0, "val_loss": 13.281327486038208, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.53272199630737, "training_acc": 72.0, "val_loss": 13.151359558105469, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.19714283943176, "training_acc": 72.0, "val_loss": 12.919212877750397, "val_acc": 80.0}
{"epoch": 21, "training_loss": 55.08337163925171, "training_acc": 75.0, "val_loss": 12.846176326274872, "val_acc": 76.0}
{"epoch": 22, "training_loss": 55.22725868225098, "training_acc": 75.0, "val_loss": 12.814801931381226, "val_acc": 76.0}
{"epoch": 23, "training_loss": 55.94031858444214, "training_acc": 74.0, "val_loss": 12.778951227664948, "val_acc": 76.0}
{"epoch": 24, "training_loss": 55.49568068981171, "training_acc": 74.0, "val_loss": 12.82854974269867, "val_acc": 76.0}
{"epoch": 25, "training_loss": 55.52211236953735, "training_acc": 74.0, "val_loss": 12.929315865039825, "val_acc": 72.0}
{"epoch": 26, "training_loss": 56.75277757644653, "training_acc": 72.0, "val_loss": 12.979063391685486, "val_acc": 72.0}
{"epoch": 27, "training_loss": 55.62614619731903, "training_acc": 72.0, "val_loss": 13.040705025196075, "val_acc": 72.0}
{"epoch": 28, "training_loss": 56.407076358795166, "training_acc": 72.0, "val_loss": 13.226129114627838, "val_acc": 72.0}
{"epoch": 29, "training_loss": 54.87693738937378, "training_acc": 72.0, "val_loss": 13.253407180309296, "val_acc": 72.0}
{"epoch": 30, "training_loss": 55.704484939575195, "training_acc": 72.0, "val_loss": 13.018794357776642, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.324037075042725, "training_acc": 72.0, "val_loss": 12.834793329238892, "val_acc": 76.0}
{"epoch": 32, "training_loss": 55.73465871810913, "training_acc": 71.0, "val_loss": 12.863004207611084, "val_acc": 80.0}
{"epoch": 33, "training_loss": 55.972659945487976, "training_acc": 72.0, "val_loss": 12.874920666217804, "val_acc": 76.0}
{"epoch": 34, "training_loss": 56.62403202056885, "training_acc": 75.0, "val_loss": 13.016842305660248, "val_acc": 72.0}
{"epoch": 35, "training_loss": 56.129820704460144, "training_acc": 72.0, "val_loss": 13.484081625938416, "val_acc": 72.0}
{"epoch": 36, "training_loss": 56.51256275177002, "training_acc": 72.0, "val_loss": 13.784988224506378, "val_acc": 72.0}
{"epoch": 37, "training_loss": 56.454646706581116, "training_acc": 72.0, "val_loss": 13.633762300014496, "val_acc": 72.0}
{"epoch": 38, "training_loss": 55.86541032791138, "training_acc": 72.0, "val_loss": 13.228461146354675, "val_acc": 72.0}
{"epoch": 39, "training_loss": 54.89570391178131, "training_acc": 72.0, "val_loss": 13.007806241512299, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.11660552024841, "training_acc": 75.0, "val_loss": 12.918239831924438, "val_acc": 80.0}
{"epoch": 41, "training_loss": 54.201406478881836, "training_acc": 76.0, "val_loss": 12.89377212524414, "val_acc": 80.0}
{"epoch": 42, "training_loss": 53.761428356170654, "training_acc": 77.0, "val_loss": 12.894870340824127, "val_acc": 76.0}
