"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.16248154640198, "training_acc": 71.0, "val_loss": 16.8263241648674, "val_acc": 28.0}
{"epoch": 1, "training_loss": 66.73593950271606, "training_acc": 72.0, "val_loss": 16.739384829998016, "val_acc": 28.0}
{"epoch": 2, "training_loss": 66.37245655059814, "training_acc": 72.0, "val_loss": 16.67342782020569, "val_acc": 28.0}
{"epoch": 3, "training_loss": 66.11874008178711, "training_acc": 72.0, "val_loss": 16.590003669261932, "val_acc": 28.0}
{"epoch": 4, "training_loss": 65.77623128890991, "training_acc": 72.0, "val_loss": 16.503097116947174, "val_acc": 28.0}
{"epoch": 5, "training_loss": 65.50377035140991, "training_acc": 72.0, "val_loss": 16.422666609287262, "val_acc": 28.0}
{"epoch": 6, "training_loss": 65.24846935272217, "training_acc": 72.0, "val_loss": 16.334401071071625, "val_acc": 28.0}
{"epoch": 7, "training_loss": 64.61962080001831, "training_acc": 72.0, "val_loss": 16.24951958656311, "val_acc": 28.0}
{"epoch": 8, "training_loss": 64.27703666687012, "training_acc": 72.0, "val_loss": 16.16961658000946, "val_acc": 28.0}
{"epoch": 9, "training_loss": 64.05398511886597, "training_acc": 72.0, "val_loss": 16.109077632427216, "val_acc": 28.0}
{"epoch": 10, "training_loss": 64.09754061698914, "training_acc": 72.0, "val_loss": 16.044555604457855, "val_acc": 28.0}
{"epoch": 11, "training_loss": 63.742597579956055, "training_acc": 72.0, "val_loss": 15.988145768642426, "val_acc": 28.0}
{"epoch": 12, "training_loss": 63.43200922012329, "training_acc": 72.0, "val_loss": 15.933439135551453, "val_acc": 28.0}
{"epoch": 13, "training_loss": 63.03083372116089, "training_acc": 72.0, "val_loss": 15.878942608833313, "val_acc": 28.0}
{"epoch": 14, "training_loss": 62.947704792022705, "training_acc": 72.0, "val_loss": 15.824471414089203, "val_acc": 28.0}
{"epoch": 15, "training_loss": 62.55962419509888, "training_acc": 72.0, "val_loss": 15.774902701377869, "val_acc": 28.0}
{"epoch": 16, "training_loss": 62.749942779541016, "training_acc": 72.0, "val_loss": 15.731051564216614, "val_acc": 28.0}
{"epoch": 17, "training_loss": 62.403011202812195, "training_acc": 72.0, "val_loss": 15.684504806995392, "val_acc": 16.0}
{"epoch": 18, "training_loss": 62.297118186950684, "training_acc": 72.0, "val_loss": 15.63560664653778, "val_acc": 24.0}
{"epoch": 19, "training_loss": 61.86860656738281, "training_acc": 72.0, "val_loss": 15.595173835754395, "val_acc": 24.0}
{"epoch": 20, "training_loss": 61.701268911361694, "training_acc": 72.0, "val_loss": 15.560765564441681, "val_acc": 36.0}
{"epoch": 21, "training_loss": 61.692676067352295, "training_acc": 72.0, "val_loss": 15.527962148189545, "val_acc": 48.0}
{"epoch": 22, "training_loss": 61.6482470035553, "training_acc": 72.0, "val_loss": 15.49946516752243, "val_acc": 56.0}
{"epoch": 23, "training_loss": 61.369213581085205, "training_acc": 72.0, "val_loss": 15.468059480190277, "val_acc": 56.0}
{"epoch": 24, "training_loss": 61.27358102798462, "training_acc": 72.0, "val_loss": 15.437847375869751, "val_acc": 68.0}
{"epoch": 25, "training_loss": 61.365572452545166, "training_acc": 72.0, "val_loss": 15.410082042217255, "val_acc": 68.0}
{"epoch": 26, "training_loss": 60.99601697921753, "training_acc": 72.0, "val_loss": 15.384329855442047, "val_acc": 68.0}
{"epoch": 27, "training_loss": 60.96504783630371, "training_acc": 72.0, "val_loss": 15.35976380109787, "val_acc": 68.0}
{"epoch": 28, "training_loss": 60.90173673629761, "training_acc": 72.0, "val_loss": 15.33539891242981, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.83039355278015, "training_acc": 72.0, "val_loss": 15.312890708446503, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.535494327545166, "training_acc": 72.0, "val_loss": 15.292307734489441, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.72551369667053, "training_acc": 72.0, "val_loss": 15.274082124233246, "val_acc": 72.0}
{"epoch": 32, "training_loss": 60.730003356933594, "training_acc": 72.0, "val_loss": 15.264184772968292, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.6850368976593, "training_acc": 72.0, "val_loss": 15.251697599887848, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.382999420166016, "training_acc": 72.0, "val_loss": 15.23628830909729, "val_acc": 72.0}
{"epoch": 35, "training_loss": 60.26510238647461, "training_acc": 72.0, "val_loss": 15.222422778606415, "val_acc": 72.0}
{"epoch": 36, "training_loss": 60.43695259094238, "training_acc": 72.0, "val_loss": 15.208153426647186, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.396045446395874, "training_acc": 72.0, "val_loss": 15.194518864154816, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.24763774871826, "training_acc": 72.0, "val_loss": 15.18128216266632, "val_acc": 72.0}
{"epoch": 39, "training_loss": 60.395254611968994, "training_acc": 72.0, "val_loss": 15.16864150762558, "val_acc": 72.0}
{"epoch": 40, "training_loss": 60.211588859558105, "training_acc": 72.0, "val_loss": 15.156309306621552, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.0868124961853, "training_acc": 72.0, "val_loss": 15.145570039749146, "val_acc": 72.0}
{"epoch": 42, "training_loss": 60.18444514274597, "training_acc": 72.0, "val_loss": 15.135756134986877, "val_acc": 72.0}
{"epoch": 43, "training_loss": 60.301413774490356, "training_acc": 72.0, "val_loss": 15.126392245292664, "val_acc": 72.0}
{"epoch": 44, "training_loss": 60.41834568977356, "training_acc": 72.0, "val_loss": 15.117025375366211, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.931581020355225, "training_acc": 72.0, "val_loss": 15.10825902223587, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.947460412979126, "training_acc": 72.0, "val_loss": 15.10191261768341, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.886900901794434, "training_acc": 72.0, "val_loss": 15.09607881307602, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.74813771247864, "training_acc": 72.0, "val_loss": 15.089845657348633, "val_acc": 72.0}
{"epoch": 49, "training_loss": 60.01963710784912, "training_acc": 72.0, "val_loss": 15.083123743534088, "val_acc": 72.0}
{"epoch": 50, "training_loss": 60.24020528793335, "training_acc": 72.0, "val_loss": 15.074607729911804, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.862509965896606, "training_acc": 72.0, "val_loss": 15.065458416938782, "val_acc": 72.0}
{"epoch": 52, "training_loss": 60.05332088470459, "training_acc": 72.0, "val_loss": 15.056520700454712, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.6941077709198, "training_acc": 72.0, "val_loss": 15.047943592071533, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.91375541687012, "training_acc": 72.0, "val_loss": 15.040311217308044, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.90024995803833, "training_acc": 72.0, "val_loss": 15.032866597175598, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.704920530319214, "training_acc": 72.0, "val_loss": 15.02593457698822, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.850725173950195, "training_acc": 72.0, "val_loss": 15.019842982292175, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.6231586933136, "training_acc": 72.0, "val_loss": 15.013909339904785, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.62694811820984, "training_acc": 72.0, "val_loss": 15.00527411699295, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.75874328613281, "training_acc": 72.0, "val_loss": 14.99670147895813, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.602169036865234, "training_acc": 72.0, "val_loss": 14.991249144077301, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.709163427352905, "training_acc": 72.0, "val_loss": 14.986202120780945, "val_acc": 72.0}
{"epoch": 63, "training_loss": 59.60450983047485, "training_acc": 72.0, "val_loss": 14.981183409690857, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.74071180820465, "training_acc": 72.0, "val_loss": 14.975908398628235, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.620380878448486, "training_acc": 72.0, "val_loss": 14.969445765018463, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.567347288131714, "training_acc": 72.0, "val_loss": 14.962148666381836, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.52084827423096, "training_acc": 72.0, "val_loss": 14.956402778625488, "val_acc": 72.0}
{"epoch": 68, "training_loss": 59.53358173370361, "training_acc": 72.0, "val_loss": 14.950799942016602, "val_acc": 72.0}
