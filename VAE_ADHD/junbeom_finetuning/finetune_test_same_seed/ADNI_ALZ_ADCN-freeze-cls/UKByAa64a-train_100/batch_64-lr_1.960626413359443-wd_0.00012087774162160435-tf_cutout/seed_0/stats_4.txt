"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3516.8873901367188, "training_acc": 72.0, "val_loss": 1341.0463333129883, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3802.1924324035645, "training_acc": 72.0, "val_loss": 2123.4277725219727, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9180.750762939453, "training_acc": 28.0, "val_loss": 384.64510440826416, "val_acc": 48.0}
{"epoch": 3, "training_loss": 2329.3215408325195, "training_acc": 56.0, "val_loss": 1285.19287109375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4967.307418823242, "training_acc": 72.0, "val_loss": 1640.884780883789, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5583.264434814453, "training_acc": 72.0, "val_loss": 1220.5402374267578, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3210.7473678588867, "training_acc": 73.0, "val_loss": 452.8927803039551, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2155.635284423828, "training_acc": 54.0, "val_loss": 580.9722900390625, "val_acc": 56.0}
{"epoch": 8, "training_loss": 3331.0254974365234, "training_acc": 51.0, "val_loss": 473.2532024383545, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1381.5464401245117, "training_acc": 72.0, "val_loss": 841.9690132141113, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2245.2016792297363, "training_acc": 72.0, "val_loss": 754.7314167022705, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2068.394805908203, "training_acc": 72.0, "val_loss": 371.19646072387695, "val_acc": 68.0}
{"epoch": 12, "training_loss": 1127.5176963806152, "training_acc": 71.0, "val_loss": 308.70800018310547, "val_acc": 64.0}
{"epoch": 13, "training_loss": 1178.590835571289, "training_acc": 65.0, "val_loss": 304.8624277114868, "val_acc": 72.0}
{"epoch": 14, "training_loss": 715.9691791534424, "training_acc": 76.0, "val_loss": 252.2653579711914, "val_acc": 72.0}
{"epoch": 15, "training_loss": 551.414155960083, "training_acc": 71.0, "val_loss": 86.39101982116699, "val_acc": 64.0}
{"epoch": 16, "training_loss": 410.45938301086426, "training_acc": 66.0, "val_loss": 62.49709725379944, "val_acc": 72.0}
{"epoch": 17, "training_loss": 594.5656547546387, "training_acc": 58.0, "val_loss": 24.216382205486298, "val_acc": 72.0}
{"epoch": 18, "training_loss": 250.57476806640625, "training_acc": 74.0, "val_loss": 69.44213509559631, "val_acc": 56.0}
{"epoch": 19, "training_loss": 229.42142963409424, "training_acc": 57.0, "val_loss": 20.33102512359619, "val_acc": 84.0}
{"epoch": 20, "training_loss": 144.6399097442627, "training_acc": 75.0, "val_loss": 36.790016293525696, "val_acc": 80.0}
{"epoch": 21, "training_loss": 247.3425521850586, "training_acc": 74.0, "val_loss": 69.53139305114746, "val_acc": 76.0}
{"epoch": 22, "training_loss": 286.10958671569824, "training_acc": 74.0, "val_loss": 75.93643069267273, "val_acc": 76.0}
{"epoch": 23, "training_loss": 295.8164348602295, "training_acc": 76.0, "val_loss": 64.46405053138733, "val_acc": 76.0}
{"epoch": 24, "training_loss": 248.27008247375488, "training_acc": 71.0, "val_loss": 31.931668519973755, "val_acc": 88.0}
{"epoch": 25, "training_loss": 128.51503467559814, "training_acc": 80.0, "val_loss": 141.331148147583, "val_acc": 40.0}
{"epoch": 26, "training_loss": 586.9801425933838, "training_acc": 50.0, "val_loss": 111.00116968154907, "val_acc": 72.0}
{"epoch": 27, "training_loss": 399.7244005203247, "training_acc": 68.0, "val_loss": 37.578174471855164, "val_acc": 80.0}
{"epoch": 28, "training_loss": 192.31432151794434, "training_acc": 83.0, "val_loss": 56.785279512405396, "val_acc": 56.0}
{"epoch": 29, "training_loss": 176.5554497241974, "training_acc": 72.0, "val_loss": 96.162348985672, "val_acc": 72.0}
{"epoch": 30, "training_loss": 193.4396333694458, "training_acc": 78.0, "val_loss": 188.32350969314575, "val_acc": 36.0}
{"epoch": 31, "training_loss": 510.4199547767639, "training_acc": 56.0, "val_loss": 161.73638105392456, "val_acc": 72.0}
{"epoch": 32, "training_loss": 429.72118949890137, "training_acc": 73.0, "val_loss": 275.2934217453003, "val_acc": 28.0}
{"epoch": 33, "training_loss": 799.1354207992554, "training_acc": 49.0, "val_loss": 210.78722476959229, "val_acc": 72.0}
{"epoch": 34, "training_loss": 627.6314687728882, "training_acc": 72.0, "val_loss": 88.57453465461731, "val_acc": 72.0}
{"epoch": 35, "training_loss": 430.74474716186523, "training_acc": 67.0, "val_loss": 55.41677474975586, "val_acc": 80.0}
{"epoch": 36, "training_loss": 232.14705276489258, "training_acc": 78.0, "val_loss": 226.338791847229, "val_acc": 72.0}
{"epoch": 37, "training_loss": 523.4467325210571, "training_acc": 76.0, "val_loss": 79.59402203559875, "val_acc": 52.0}
{"epoch": 38, "training_loss": 380.45896434783936, "training_acc": 66.0, "val_loss": 109.32934284210205, "val_acc": 76.0}
