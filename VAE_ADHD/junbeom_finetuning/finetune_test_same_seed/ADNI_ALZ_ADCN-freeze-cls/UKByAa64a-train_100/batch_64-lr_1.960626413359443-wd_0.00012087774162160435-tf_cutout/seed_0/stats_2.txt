"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4302.027732849121, "training_acc": 72.0, "val_loss": 1361.2322807312012, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4261.94649887085, "training_acc": 72.0, "val_loss": 1942.1791076660156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8011.5228271484375, "training_acc": 28.0, "val_loss": 281.60433769226074, "val_acc": 48.0}
{"epoch": 3, "training_loss": 1762.6312255859375, "training_acc": 60.0, "val_loss": 1303.2204627990723, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5087.131423950195, "training_acc": 72.0, "val_loss": 1639.1094207763672, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5972.665512084961, "training_acc": 72.0, "val_loss": 1210.0373268127441, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3577.908203125, "training_acc": 72.0, "val_loss": 351.1523723602295, "val_acc": 80.0}
{"epoch": 7, "training_loss": 2090.72745513916, "training_acc": 57.0, "val_loss": 746.512508392334, "val_acc": 44.0}
{"epoch": 8, "training_loss": 3791.8097915649414, "training_acc": 50.0, "val_loss": 362.274169921875, "val_acc": 80.0}
{"epoch": 9, "training_loss": 1355.0576934814453, "training_acc": 71.0, "val_loss": 751.1970043182373, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2259.4969024658203, "training_acc": 71.0, "val_loss": 741.1056995391846, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1983.929542541504, "training_acc": 74.0, "val_loss": 321.54836654663086, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1134.8788375854492, "training_acc": 71.0, "val_loss": 338.5546684265137, "val_acc": 56.0}
{"epoch": 13, "training_loss": 1477.709945678711, "training_acc": 62.0, "val_loss": 283.0137252807617, "val_acc": 68.0}
{"epoch": 14, "training_loss": 838.502082824707, "training_acc": 75.0, "val_loss": 376.6785144805908, "val_acc": 72.0}
{"epoch": 15, "training_loss": 841.2668504714966, "training_acc": 76.0, "val_loss": 153.02014350891113, "val_acc": 60.0}
{"epoch": 16, "training_loss": 697.1784782409668, "training_acc": 56.0, "val_loss": 188.73766660690308, "val_acc": 72.0}
{"epoch": 17, "training_loss": 614.6449775695801, "training_acc": 73.0, "val_loss": 220.12791633605957, "val_acc": 72.0}
{"epoch": 18, "training_loss": 751.6125774383545, "training_acc": 55.0, "val_loss": 89.852374792099, "val_acc": 68.0}
{"epoch": 19, "training_loss": 551.2565307617188, "training_acc": 62.0, "val_loss": 199.35580492019653, "val_acc": 72.0}
{"epoch": 20, "training_loss": 429.87278270721436, "training_acc": 72.0, "val_loss": 170.66879272460938, "val_acc": 56.0}
{"epoch": 21, "training_loss": 654.2165422439575, "training_acc": 59.0, "val_loss": 199.74161386489868, "val_acc": 72.0}
{"epoch": 22, "training_loss": 477.0806465148926, "training_acc": 74.0, "val_loss": 99.26581978797913, "val_acc": 80.0}
{"epoch": 23, "training_loss": 315.95902824401855, "training_acc": 75.0, "val_loss": 98.90556335449219, "val_acc": 72.0}
{"epoch": 24, "training_loss": 298.01771354675293, "training_acc": 79.0, "val_loss": 83.60722661018372, "val_acc": 72.0}
{"epoch": 25, "training_loss": 186.80548763275146, "training_acc": 76.0, "val_loss": 57.96496272087097, "val_acc": 68.0}
{"epoch": 26, "training_loss": 182.39281940460205, "training_acc": 81.0, "val_loss": 105.85446357727051, "val_acc": 52.0}
{"epoch": 27, "training_loss": 335.3184537887573, "training_acc": 57.0, "val_loss": 58.779627084732056, "val_acc": 76.0}
{"epoch": 28, "training_loss": 120.84474468231201, "training_acc": 80.0, "val_loss": 47.02007174491882, "val_acc": 72.0}
{"epoch": 29, "training_loss": 128.6446533203125, "training_acc": 84.0, "val_loss": 32.521772384643555, "val_acc": 80.0}
{"epoch": 30, "training_loss": 119.80615544319153, "training_acc": 80.0, "val_loss": 64.13549780845642, "val_acc": 76.0}
{"epoch": 31, "training_loss": 107.36918354034424, "training_acc": 81.0, "val_loss": 29.468154907226562, "val_acc": 68.0}
{"epoch": 32, "training_loss": 197.06792831420898, "training_acc": 67.0, "val_loss": 113.95549774169922, "val_acc": 72.0}
{"epoch": 33, "training_loss": 549.1749076843262, "training_acc": 55.0, "val_loss": 56.75452947616577, "val_acc": 72.0}
{"epoch": 34, "training_loss": 159.28050708770752, "training_acc": 81.0, "val_loss": 100.42086839675903, "val_acc": 72.0}
{"epoch": 35, "training_loss": 243.86686325073242, "training_acc": 74.0, "val_loss": 73.57543706893921, "val_acc": 76.0}
{"epoch": 36, "training_loss": 219.20686054229736, "training_acc": 79.0, "val_loss": 112.14932203292847, "val_acc": 76.0}
{"epoch": 37, "training_loss": 221.49243354797363, "training_acc": 76.0, "val_loss": 51.78655385971069, "val_acc": 68.0}
{"epoch": 38, "training_loss": 143.55705070495605, "training_acc": 82.0, "val_loss": 39.616966247558594, "val_acc": 60.0}
{"epoch": 39, "training_loss": 73.39879316091537, "training_acc": 84.0, "val_loss": 70.89707255363464, "val_acc": 64.0}
{"epoch": 40, "training_loss": 129.68694162368774, "training_acc": 79.0, "val_loss": 55.65979480743408, "val_acc": 56.0}
{"epoch": 41, "training_loss": 114.72724866867065, "training_acc": 77.0, "val_loss": 40.49190282821655, "val_acc": 60.0}
{"epoch": 42, "training_loss": 103.90393805503845, "training_acc": 77.0, "val_loss": 40.96337854862213, "val_acc": 76.0}
{"epoch": 43, "training_loss": 47.32899808883667, "training_acc": 91.0, "val_loss": 43.25443208217621, "val_acc": 72.0}
{"epoch": 44, "training_loss": 177.84845685958862, "training_acc": 75.0, "val_loss": 64.3406331539154, "val_acc": 76.0}
{"epoch": 45, "training_loss": 140.0337996482849, "training_acc": 77.0, "val_loss": 50.07694363594055, "val_acc": 76.0}
{"epoch": 46, "training_loss": 51.393381118774414, "training_acc": 89.0, "val_loss": 27.605825662612915, "val_acc": 64.0}
{"epoch": 47, "training_loss": 69.3606538772583, "training_acc": 79.0, "val_loss": 26.976564526557922, "val_acc": 68.0}
{"epoch": 48, "training_loss": 63.04298257827759, "training_acc": 82.0, "val_loss": 77.37500667572021, "val_acc": 72.0}
{"epoch": 49, "training_loss": 97.32850915193558, "training_acc": 86.0, "val_loss": 78.26980948448181, "val_acc": 60.0}
{"epoch": 50, "training_loss": 257.02552127838135, "training_acc": 65.0, "val_loss": 146.90285921096802, "val_acc": 72.0}
{"epoch": 51, "training_loss": 228.38692569732666, "training_acc": 79.0, "val_loss": 127.38136053085327, "val_acc": 52.0}
{"epoch": 52, "training_loss": 454.9491720199585, "training_acc": 63.0, "val_loss": 217.11866855621338, "val_acc": 72.0}
{"epoch": 53, "training_loss": 425.14817810058594, "training_acc": 79.0, "val_loss": 85.99413633346558, "val_acc": 68.0}
{"epoch": 54, "training_loss": 313.03443002700806, "training_acc": 69.0, "val_loss": 100.64151287078857, "val_acc": 76.0}
{"epoch": 55, "training_loss": 135.15460729599, "training_acc": 85.0, "val_loss": 53.83259654045105, "val_acc": 72.0}
{"epoch": 56, "training_loss": 90.02458357810974, "training_acc": 84.0, "val_loss": 104.436194896698, "val_acc": 72.0}
{"epoch": 57, "training_loss": 136.81289052963257, "training_acc": 78.0, "val_loss": 65.55135846138, "val_acc": 64.0}
{"epoch": 58, "training_loss": 82.65868806838989, "training_acc": 80.0, "val_loss": 47.47833609580994, "val_acc": 60.0}
{"epoch": 59, "training_loss": 74.96031045913696, "training_acc": 82.0, "val_loss": 149.89773035049438, "val_acc": 72.0}
{"epoch": 60, "training_loss": 294.92487812042236, "training_acc": 76.0, "val_loss": 64.47328925132751, "val_acc": 72.0}
{"epoch": 61, "training_loss": 172.0025773048401, "training_acc": 74.0, "val_loss": 75.7961094379425, "val_acc": 72.0}
{"epoch": 62, "training_loss": 117.09951639175415, "training_acc": 89.0, "val_loss": 50.19519329071045, "val_acc": 72.0}
{"epoch": 63, "training_loss": 85.3688850402832, "training_acc": 80.0, "val_loss": 127.8799295425415, "val_acc": 72.0}
{"epoch": 64, "training_loss": 188.54554438591003, "training_acc": 77.0, "val_loss": 93.65507364273071, "val_acc": 52.0}
{"epoch": 65, "training_loss": 259.4616117477417, "training_acc": 59.0, "val_loss": 43.755897879600525, "val_acc": 76.0}
{"epoch": 66, "training_loss": 113.61074542999268, "training_acc": 78.0, "val_loss": 109.54458713531494, "val_acc": 72.0}
