"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3837.7423515319824, "training_acc": 38.0, "val_loss": 1562.353515625, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4628.620391845703, "training_acc": 72.0, "val_loss": 1241.957950592041, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4654.889938354492, "training_acc": 30.0, "val_loss": 284.1041564941406, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1570.7765350341797, "training_acc": 72.0, "val_loss": 885.6342315673828, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3216.3844299316406, "training_acc": 72.0, "val_loss": 549.0398406982422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1631.059211730957, "training_acc": 75.0, "val_loss": 642.3549652099609, "val_acc": 64.0}
{"epoch": 6, "training_loss": 2314.892234802246, "training_acc": 47.0, "val_loss": 519.8894023895264, "val_acc": 64.0}
{"epoch": 7, "training_loss": 1254.876377105713, "training_acc": 65.0, "val_loss": 455.13415336608887, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1510.261131286621, "training_acc": 73.0, "val_loss": 375.74310302734375, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1084.8139610290527, "training_acc": 70.0, "val_loss": 433.5836887359619, "val_acc": 64.0}
{"epoch": 10, "training_loss": 1166.9204139709473, "training_acc": 59.0, "val_loss": 235.6722116470337, "val_acc": 72.0}
{"epoch": 11, "training_loss": 720.7758178710938, "training_acc": 74.0, "val_loss": 249.5875358581543, "val_acc": 72.0}
{"epoch": 12, "training_loss": 669.9504241943359, "training_acc": 74.0, "val_loss": 320.16777992248535, "val_acc": 36.0}
{"epoch": 13, "training_loss": 926.1212301254272, "training_acc": 50.0, "val_loss": 239.55004215240479, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1116.635627746582, "training_acc": 72.0, "val_loss": 273.2462167739868, "val_acc": 72.0}
{"epoch": 15, "training_loss": 739.9751868247986, "training_acc": 74.0, "val_loss": 581.3112735748291, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1619.5366439819336, "training_acc": 33.0, "val_loss": 292.8666591644287, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1697.7708435058594, "training_acc": 72.0, "val_loss": 645.1965808868408, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2361.016326904297, "training_acc": 72.0, "val_loss": 250.8608102798462, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1017.3073177337646, "training_acc": 61.0, "val_loss": 489.10789489746094, "val_acc": 36.0}
{"epoch": 20, "training_loss": 1266.3285846710205, "training_acc": 48.0, "val_loss": 227.35741138458252, "val_acc": 80.0}
{"epoch": 21, "training_loss": 1039.3947792053223, "training_acc": 74.0, "val_loss": 439.67227935791016, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1487.7800407409668, "training_acc": 73.0, "val_loss": 200.7025957107544, "val_acc": 68.0}
{"epoch": 23, "training_loss": 719.8992805480957, "training_acc": 72.0, "val_loss": 394.3415403366089, "val_acc": 52.0}
{"epoch": 24, "training_loss": 1047.694911956787, "training_acc": 59.0, "val_loss": 219.6863889694214, "val_acc": 76.0}
{"epoch": 25, "training_loss": 962.6954116821289, "training_acc": 75.0, "val_loss": 262.5844955444336, "val_acc": 72.0}
{"epoch": 26, "training_loss": 823.1836566925049, "training_acc": 72.0, "val_loss": 311.86277866363525, "val_acc": 44.0}
{"epoch": 27, "training_loss": 963.7298545837402, "training_acc": 52.0, "val_loss": 95.43333053588867, "val_acc": 72.0}
{"epoch": 28, "training_loss": 356.9518871307373, "training_acc": 79.0, "val_loss": 143.8771367073059, "val_acc": 76.0}
{"epoch": 29, "training_loss": 537.9561333656311, "training_acc": 72.0, "val_loss": 227.60281562805176, "val_acc": 36.0}
{"epoch": 30, "training_loss": 426.91552782058716, "training_acc": 66.0, "val_loss": 119.62792873382568, "val_acc": 72.0}
{"epoch": 31, "training_loss": 501.295862197876, "training_acc": 72.0, "val_loss": 130.8845043182373, "val_acc": 52.0}
{"epoch": 32, "training_loss": 209.96042585372925, "training_acc": 61.0, "val_loss": 40.96941649913788, "val_acc": 84.0}
{"epoch": 33, "training_loss": 164.85570001602173, "training_acc": 78.0, "val_loss": 62.085896730422974, "val_acc": 60.0}
{"epoch": 34, "training_loss": 223.042818069458, "training_acc": 73.0, "val_loss": 80.24609088897705, "val_acc": 60.0}
{"epoch": 35, "training_loss": 63.845701694488525, "training_acc": 83.0, "val_loss": 23.305943608283997, "val_acc": 76.0}
{"epoch": 36, "training_loss": 134.01783227920532, "training_acc": 80.0, "val_loss": 206.54165744781494, "val_acc": 40.0}
{"epoch": 37, "training_loss": 404.72852325439453, "training_acc": 61.0, "val_loss": 46.45387530326843, "val_acc": 84.0}
{"epoch": 38, "training_loss": 169.14006090164185, "training_acc": 74.0, "val_loss": 92.14400053024292, "val_acc": 60.0}
{"epoch": 39, "training_loss": 221.6705722808838, "training_acc": 73.0, "val_loss": 21.894332766532898, "val_acc": 80.0}
{"epoch": 40, "training_loss": 227.70345306396484, "training_acc": 66.0, "val_loss": 51.460546255111694, "val_acc": 76.0}
{"epoch": 41, "training_loss": 237.61525869369507, "training_acc": 74.0, "val_loss": 64.56966996192932, "val_acc": 60.0}
{"epoch": 42, "training_loss": 158.25433778762817, "training_acc": 74.0, "val_loss": 46.56983017921448, "val_acc": 76.0}
{"epoch": 43, "training_loss": 126.59777450561523, "training_acc": 83.0, "val_loss": 80.33059239387512, "val_acc": 64.0}
{"epoch": 44, "training_loss": 175.90155673027039, "training_acc": 72.0, "val_loss": 35.3838711977005, "val_acc": 76.0}
{"epoch": 45, "training_loss": 70.63312566280365, "training_acc": 85.0, "val_loss": 38.952475786209106, "val_acc": 72.0}
{"epoch": 46, "training_loss": 103.03478479385376, "training_acc": 81.0, "val_loss": 16.145572066307068, "val_acc": 76.0}
{"epoch": 47, "training_loss": 78.62508201599121, "training_acc": 78.0, "val_loss": 22.700031101703644, "val_acc": 84.0}
{"epoch": 48, "training_loss": 98.76361441612244, "training_acc": 84.0, "val_loss": 154.73870038986206, "val_acc": 36.0}
{"epoch": 49, "training_loss": 294.92794609069824, "training_acc": 61.0, "val_loss": 91.50593280792236, "val_acc": 72.0}
{"epoch": 50, "training_loss": 265.3088915348053, "training_acc": 77.0, "val_loss": 57.95263648033142, "val_acc": 60.0}
{"epoch": 51, "training_loss": 87.30010747909546, "training_acc": 83.0, "val_loss": 35.10465919971466, "val_acc": 80.0}
{"epoch": 52, "training_loss": 136.26145458221436, "training_acc": 81.0, "val_loss": 46.88161015510559, "val_acc": 64.0}
{"epoch": 53, "training_loss": 167.67890453338623, "training_acc": 79.0, "val_loss": 21.92535549402237, "val_acc": 72.0}
{"epoch": 54, "training_loss": 77.15150928497314, "training_acc": 80.0, "val_loss": 56.345534324645996, "val_acc": 72.0}
{"epoch": 55, "training_loss": 213.69098806381226, "training_acc": 75.0, "val_loss": 182.13998079299927, "val_acc": 36.0}
{"epoch": 56, "training_loss": 381.8407573699951, "training_acc": 60.0, "val_loss": 99.95015263557434, "val_acc": 72.0}
{"epoch": 57, "training_loss": 278.9154064655304, "training_acc": 80.0, "val_loss": 242.43121147155762, "val_acc": 32.0}
{"epoch": 58, "training_loss": 440.1570761203766, "training_acc": 65.0, "val_loss": 127.88369655609131, "val_acc": 72.0}
{"epoch": 59, "training_loss": 393.0163278579712, "training_acc": 74.0, "val_loss": 138.71246576309204, "val_acc": 56.0}
{"epoch": 60, "training_loss": 396.51603412628174, "training_acc": 65.0, "val_loss": 62.60455250740051, "val_acc": 76.0}
{"epoch": 61, "training_loss": 147.83464813232422, "training_acc": 83.0, "val_loss": 39.86090123653412, "val_acc": 80.0}
{"epoch": 62, "training_loss": 96.290518283844, "training_acc": 85.0, "val_loss": 31.787636876106262, "val_acc": 80.0}
{"epoch": 63, "training_loss": 109.53983759880066, "training_acc": 80.0, "val_loss": 107.28344917297363, "val_acc": 44.0}
{"epoch": 64, "training_loss": 349.4464473724365, "training_acc": 63.0, "val_loss": 19.872911274433136, "val_acc": 76.0}
{"epoch": 65, "training_loss": 69.94209027290344, "training_acc": 83.0, "val_loss": 24.541300535202026, "val_acc": 84.0}
