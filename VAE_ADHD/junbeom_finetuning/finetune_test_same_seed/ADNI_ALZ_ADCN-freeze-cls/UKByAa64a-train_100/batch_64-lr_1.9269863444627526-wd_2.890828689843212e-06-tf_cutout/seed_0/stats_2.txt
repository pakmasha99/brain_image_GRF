"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9112.537239074707, "training_acc": 42.0, "val_loss": 4843.210983276367, "val_acc": 72.0}
{"epoch": 1, "training_loss": 16092.969787597656, "training_acc": 72.0, "val_loss": 3899.100112915039, "val_acc": 28.0}
{"epoch": 2, "training_loss": 13266.453643798828, "training_acc": 28.0, "val_loss": 1460.209846496582, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8318.716125488281, "training_acc": 72.0, "val_loss": 3391.7903900146484, "val_acc": 72.0}
{"epoch": 4, "training_loss": 13254.959564208984, "training_acc": 72.0, "val_loss": 2413.2205963134766, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7825.508377075195, "training_acc": 72.0, "val_loss": 1320.0334548950195, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5849.466766357422, "training_acc": 28.0, "val_loss": 554.1297435760498, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2947.124008178711, "training_acc": 72.0, "val_loss": 1282.8624725341797, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4624.487030029297, "training_acc": 72.0, "val_loss": 219.84779834747314, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3344.603302001953, "training_acc": 60.0, "val_loss": 1880.1177978515625, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5528.809188842773, "training_acc": 42.0, "val_loss": 971.6671943664551, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4190.54231262207, "training_acc": 72.0, "val_loss": 816.6619300842285, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2117.6640758514404, "training_acc": 72.0, "val_loss": 2392.063331604004, "val_acc": 28.0}
{"epoch": 13, "training_loss": 9378.378326416016, "training_acc": 28.0, "val_loss": 156.14416599273682, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1239.5727920532227, "training_acc": 72.0, "val_loss": 829.2964935302734, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2888.6394119262695, "training_acc": 72.0, "val_loss": 53.09138894081116, "val_acc": 36.0}
{"epoch": 16, "training_loss": 888.0843124389648, "training_acc": 38.0, "val_loss": 139.03838396072388, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1729.2076568603516, "training_acc": 58.0, "val_loss": 30.356210470199585, "val_acc": 72.0}
{"epoch": 18, "training_loss": 788.3286972045898, "training_acc": 74.0, "val_loss": 309.9503517150879, "val_acc": 72.0}
{"epoch": 19, "training_loss": 807.4031314849854, "training_acc": 64.0, "val_loss": 368.31936836242676, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1483.450080871582, "training_acc": 72.0, "val_loss": 72.87826538085938, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2919.2313537597656, "training_acc": 50.0, "val_loss": 684.5614910125732, "val_acc": 28.0}
{"epoch": 22, "training_loss": 4282.123947143555, "training_acc": 34.0, "val_loss": 1767.3942565917969, "val_acc": 72.0}
{"epoch": 23, "training_loss": 7423.572814941406, "training_acc": 72.0, "val_loss": 1922.9372024536133, "val_acc": 72.0}
{"epoch": 24, "training_loss": 6855.37109375, "training_acc": 72.0, "val_loss": 641.2800312042236, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3277.9146118164062, "training_acc": 56.0, "val_loss": 1273.711109161377, "val_acc": 28.0}
{"epoch": 26, "training_loss": 3934.4288291931152, "training_acc": 42.0, "val_loss": 781.0856342315674, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3252.2798614501953, "training_acc": 72.0, "val_loss": 462.1513843536377, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2308.518585205078, "training_acc": 54.0, "val_loss": 73.57075810432434, "val_acc": 44.0}
{"epoch": 29, "training_loss": 1254.9672546386719, "training_acc": 58.0, "val_loss": 1325.4666328430176, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5267.40087890625, "training_acc": 72.0, "val_loss": 1117.3686027526855, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3503.8396644592285, "training_acc": 72.0, "val_loss": 1043.030834197998, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3834.993095397949, "training_acc": 28.0, "val_loss": 705.8286190032959, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3361.6964263916016, "training_acc": 72.0, "val_loss": 1388.683032989502, "val_acc": 72.0}
{"epoch": 34, "training_loss": 5089.522644042969, "training_acc": 72.0, "val_loss": 609.5992088317871, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2939.2826538085938, "training_acc": 50.0, "val_loss": 224.73723888397217, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2253.7616119384766, "training_acc": 42.0, "val_loss": 1602.7290344238281, "val_acc": 72.0}
