"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12430.673664093018, "training_acc": 33.0, "val_loss": 4548.050689697266, "val_acc": 72.0}
{"epoch": 1, "training_loss": 14756.208038330078, "training_acc": 72.0, "val_loss": 3674.3003845214844, "val_acc": 28.0}
{"epoch": 2, "training_loss": 12699.834014892578, "training_acc": 28.0, "val_loss": 1238.9177322387695, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6491.377777099609, "training_acc": 72.0, "val_loss": 2608.5025787353516, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9902.329711914062, "training_acc": 72.0, "val_loss": 1330.1393508911133, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4326.315299987793, "training_acc": 52.0, "val_loss": 109.86758470535278, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1005.5859451293945, "training_acc": 54.0, "val_loss": 754.1192054748535, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3678.5615844726562, "training_acc": 72.0, "val_loss": 1079.9054145812988, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3554.623374938965, "training_acc": 72.0, "val_loss": 899.5675086975098, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2563.784204483032, "training_acc": 28.0, "val_loss": 1171.8419075012207, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5732.462738037109, "training_acc": 72.0, "val_loss": 2179.193115234375, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8488.314544677734, "training_acc": 72.0, "val_loss": 1503.5771369934082, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4589.8730545043945, "training_acc": 72.0, "val_loss": 1363.774585723877, "val_acc": 28.0}
{"epoch": 13, "training_loss": 5849.403991699219, "training_acc": 28.0, "val_loss": 256.974196434021, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1752.0765075683594, "training_acc": 72.0, "val_loss": 736.0655307769775, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2439.8572540283203, "training_acc": 72.0, "val_loss": 808.3134651184082, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2107.3732109069824, "training_acc": 44.0, "val_loss": 255.9220790863037, "val_acc": 72.0}
{"epoch": 17, "training_loss": 835.8909931182861, "training_acc": 72.0, "val_loss": 955.6681632995605, "val_acc": 28.0}
{"epoch": 18, "training_loss": 2663.369969367981, "training_acc": 42.0, "val_loss": 122.34638929367065, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1286.2580261230469, "training_acc": 52.0, "val_loss": 406.49304389953613, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1962.7690658569336, "training_acc": 72.0, "val_loss": 500.7883548736572, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1504.4210119247437, "training_acc": 62.0, "val_loss": 150.74340105056763, "val_acc": 72.0}
{"epoch": 22, "training_loss": 686.4148597717285, "training_acc": 52.0, "val_loss": 694.69895362854, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3184.17578125, "training_acc": 72.0, "val_loss": 991.5878295898438, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3352.797866821289, "training_acc": 72.0, "val_loss": 212.47830390930176, "val_acc": 28.0}
{"epoch": 25, "training_loss": 818.6496524810791, "training_acc": 42.0, "val_loss": 30.27530312538147, "val_acc": 76.0}
{"epoch": 26, "training_loss": 1170.9907760620117, "training_acc": 58.0, "val_loss": 360.1205348968506, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1659.5772705078125, "training_acc": 72.0, "val_loss": 462.2190475463867, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1625.1569347381592, "training_acc": 51.0, "val_loss": 401.43160820007324, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1702.6533889770508, "training_acc": 72.0, "val_loss": 178.34326028823853, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1176.4646530151367, "training_acc": 68.0, "val_loss": 94.12025213241577, "val_acc": 36.0}
{"epoch": 31, "training_loss": 1573.2591247558594, "training_acc": 51.0, "val_loss": 1484.6811294555664, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6064.4462890625, "training_acc": 72.0, "val_loss": 1372.3786354064941, "val_acc": 72.0}
{"epoch": 33, "training_loss": 4732.2785568237305, "training_acc": 72.0, "val_loss": 115.96916913986206, "val_acc": 32.0}
{"epoch": 34, "training_loss": 584.912769317627, "training_acc": 31.0, "val_loss": 1000.1030921936035, "val_acc": 72.0}
{"epoch": 35, "training_loss": 5035.5421142578125, "training_acc": 72.0, "val_loss": 1860.804557800293, "val_acc": 72.0}
{"epoch": 36, "training_loss": 7165.476593017578, "training_acc": 72.0, "val_loss": 1150.0961303710938, "val_acc": 72.0}
{"epoch": 37, "training_loss": 3471.1320152282715, "training_acc": 72.0, "val_loss": 2007.8483581542969, "val_acc": 28.0}
{"epoch": 38, "training_loss": 8192.154815673828, "training_acc": 28.0, "val_loss": 39.176806807518005, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1220.2264556884766, "training_acc": 77.0, "val_loss": 1186.0482215881348, "val_acc": 72.0}
{"epoch": 40, "training_loss": 4752.178405761719, "training_acc": 72.0, "val_loss": 770.9729671478271, "val_acc": 72.0}
{"epoch": 41, "training_loss": 2576.470203399658, "training_acc": 53.0, "val_loss": 42.08484888076782, "val_acc": 80.0}
{"epoch": 42, "training_loss": 310.06604766845703, "training_acc": 60.0, "val_loss": 676.3837814331055, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2922.072425842285, "training_acc": 72.0, "val_loss": 966.0497665405273, "val_acc": 72.0}
{"epoch": 44, "training_loss": 3324.2534942626953, "training_acc": 72.0, "val_loss": 66.41445755958557, "val_acc": 60.0}
