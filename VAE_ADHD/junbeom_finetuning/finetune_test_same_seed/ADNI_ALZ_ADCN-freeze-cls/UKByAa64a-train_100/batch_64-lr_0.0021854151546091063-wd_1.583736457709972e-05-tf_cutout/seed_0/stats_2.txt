"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.5540976524353, "training_acc": 59.0, "val_loss": 15.231803059577942, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.73236846923828, "training_acc": 72.0, "val_loss": 14.924348890781403, "val_acc": 72.0}
{"epoch": 2, "training_loss": 61.18725657463074, "training_acc": 72.0, "val_loss": 15.012943744659424, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.62407660484314, "training_acc": 72.0, "val_loss": 14.869287610054016, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.920947909355164, "training_acc": 72.0, "val_loss": 14.65279906988144, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.691243410110474, "training_acc": 72.0, "val_loss": 14.50287252664566, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.98520302772522, "training_acc": 72.0, "val_loss": 14.39271867275238, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.8569130897522, "training_acc": 72.0, "val_loss": 14.320248365402222, "val_acc": 76.0}
{"epoch": 8, "training_loss": 56.80759000778198, "training_acc": 72.0, "val_loss": 14.257518947124481, "val_acc": 76.0}
{"epoch": 9, "training_loss": 56.94077742099762, "training_acc": 72.0, "val_loss": 14.205309748649597, "val_acc": 76.0}
{"epoch": 10, "training_loss": 56.48554801940918, "training_acc": 72.0, "val_loss": 14.176329970359802, "val_acc": 76.0}
{"epoch": 11, "training_loss": 55.433411836624146, "training_acc": 72.0, "val_loss": 14.19445425271988, "val_acc": 76.0}
{"epoch": 12, "training_loss": 55.781052112579346, "training_acc": 72.0, "val_loss": 14.211483299732208, "val_acc": 76.0}
{"epoch": 13, "training_loss": 55.66570067405701, "training_acc": 72.0, "val_loss": 14.19723927974701, "val_acc": 76.0}
{"epoch": 14, "training_loss": 55.2437264919281, "training_acc": 72.0, "val_loss": 14.135976135730743, "val_acc": 76.0}
{"epoch": 15, "training_loss": 54.757254123687744, "training_acc": 72.0, "val_loss": 14.069731533527374, "val_acc": 72.0}
{"epoch": 16, "training_loss": 55.11938214302063, "training_acc": 72.0, "val_loss": 14.026297628879547, "val_acc": 68.0}
{"epoch": 17, "training_loss": 55.05850434303284, "training_acc": 74.0, "val_loss": 14.001426100730896, "val_acc": 68.0}
{"epoch": 18, "training_loss": 54.56881880760193, "training_acc": 75.0, "val_loss": 13.99153470993042, "val_acc": 68.0}
{"epoch": 19, "training_loss": 54.70157051086426, "training_acc": 74.0, "val_loss": 14.013266563415527, "val_acc": 68.0}
{"epoch": 20, "training_loss": 54.257794976234436, "training_acc": 73.0, "val_loss": 14.04501497745514, "val_acc": 68.0}
{"epoch": 21, "training_loss": 54.52857804298401, "training_acc": 75.0, "val_loss": 14.107860624790192, "val_acc": 68.0}
{"epoch": 22, "training_loss": 55.26166355609894, "training_acc": 74.0, "val_loss": 14.183062314987183, "val_acc": 72.0}
{"epoch": 23, "training_loss": 56.07207489013672, "training_acc": 74.0, "val_loss": 14.260996878147125, "val_acc": 76.0}
{"epoch": 24, "training_loss": 53.6713593006134, "training_acc": 72.0, "val_loss": 14.267396926879883, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.12076282501221, "training_acc": 72.0, "val_loss": 14.210346341133118, "val_acc": 72.0}
{"epoch": 26, "training_loss": 53.894036054611206, "training_acc": 75.0, "val_loss": 14.13765400648117, "val_acc": 68.0}
{"epoch": 27, "training_loss": 53.643712282180786, "training_acc": 74.0, "val_loss": 14.069178700447083, "val_acc": 68.0}
{"epoch": 28, "training_loss": 52.872814893722534, "training_acc": 73.0, "val_loss": 14.00887817144394, "val_acc": 68.0}
{"epoch": 29, "training_loss": 53.902183294296265, "training_acc": 73.0, "val_loss": 13.994035124778748, "val_acc": 72.0}
{"epoch": 30, "training_loss": 52.77802896499634, "training_acc": 74.0, "val_loss": 13.986833393573761, "val_acc": 72.0}
{"epoch": 31, "training_loss": 53.92196345329285, "training_acc": 71.0, "val_loss": 13.978183269500732, "val_acc": 72.0}
{"epoch": 32, "training_loss": 54.59615445137024, "training_acc": 73.0, "val_loss": 14.014716446399689, "val_acc": 68.0}
{"epoch": 33, "training_loss": 52.589436054229736, "training_acc": 77.0, "val_loss": 14.093057811260223, "val_acc": 68.0}
{"epoch": 34, "training_loss": 54.48397946357727, "training_acc": 75.0, "val_loss": 14.205197989940643, "val_acc": 68.0}
{"epoch": 35, "training_loss": 52.75431454181671, "training_acc": 75.0, "val_loss": 14.266099035739899, "val_acc": 68.0}
{"epoch": 36, "training_loss": 53.77352583408356, "training_acc": 74.0, "val_loss": 14.29465115070343, "val_acc": 68.0}
{"epoch": 37, "training_loss": 53.95728147029877, "training_acc": 73.0, "val_loss": 14.274729788303375, "val_acc": 68.0}
{"epoch": 38, "training_loss": 52.55887842178345, "training_acc": 75.0, "val_loss": 14.187975227832794, "val_acc": 68.0}
{"epoch": 39, "training_loss": 55.36693239212036, "training_acc": 75.0, "val_loss": 14.09580111503601, "val_acc": 68.0}
{"epoch": 40, "training_loss": 53.60720753669739, "training_acc": 76.0, "val_loss": 14.055629074573517, "val_acc": 68.0}
{"epoch": 41, "training_loss": 53.144580364227295, "training_acc": 75.0, "val_loss": 14.04154896736145, "val_acc": 68.0}
{"epoch": 42, "training_loss": 53.311623096466064, "training_acc": 76.0, "val_loss": 14.024585485458374, "val_acc": 68.0}
{"epoch": 43, "training_loss": 53.063151597976685, "training_acc": 75.0, "val_loss": 14.01461809873581, "val_acc": 72.0}
{"epoch": 44, "training_loss": 53.62825894355774, "training_acc": 76.0, "val_loss": 14.009417593479156, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.47752380371094, "training_acc": 74.0, "val_loss": 14.051181077957153, "val_acc": 68.0}
{"epoch": 46, "training_loss": 52.83469605445862, "training_acc": 74.0, "val_loss": 14.104320108890533, "val_acc": 68.0}
{"epoch": 47, "training_loss": 50.8994961977005, "training_acc": 76.0, "val_loss": 14.150243997573853, "val_acc": 68.0}
{"epoch": 48, "training_loss": 53.54841184616089, "training_acc": 76.0, "val_loss": 14.225129783153534, "val_acc": 68.0}
{"epoch": 49, "training_loss": 52.435139894485474, "training_acc": 76.0, "val_loss": 14.269210398197174, "val_acc": 68.0}
{"epoch": 50, "training_loss": 53.53530478477478, "training_acc": 76.0, "val_loss": 14.253614842891693, "val_acc": 68.0}
