"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.33272695541382, "training_acc": 73.0, "val_loss": 15.236160159111023, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.46610689163208, "training_acc": 72.0, "val_loss": 15.287330746650696, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.85592222213745, "training_acc": 72.0, "val_loss": 15.642808377742767, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.23305583000183, "training_acc": 72.0, "val_loss": 15.457071363925934, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.63513898849487, "training_acc": 72.0, "val_loss": 15.019427239894867, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.077940940856934, "training_acc": 72.0, "val_loss": 14.611072838306427, "val_acc": 72.0}
{"epoch": 6, "training_loss": 58.51487171649933, "training_acc": 72.0, "val_loss": 14.395275712013245, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.41293430328369, "training_acc": 72.0, "val_loss": 14.313115179538727, "val_acc": 80.0}
{"epoch": 8, "training_loss": 57.4795446395874, "training_acc": 72.0, "val_loss": 14.232654869556427, "val_acc": 76.0}
{"epoch": 9, "training_loss": 57.459065198898315, "training_acc": 72.0, "val_loss": 14.099298417568207, "val_acc": 76.0}
{"epoch": 10, "training_loss": 56.86728262901306, "training_acc": 72.0, "val_loss": 13.985578715801239, "val_acc": 76.0}
{"epoch": 11, "training_loss": 56.52392864227295, "training_acc": 72.0, "val_loss": 13.898955285549164, "val_acc": 80.0}
{"epoch": 12, "training_loss": 57.0102002620697, "training_acc": 72.0, "val_loss": 13.848160207271576, "val_acc": 80.0}
{"epoch": 13, "training_loss": 55.32702088356018, "training_acc": 72.0, "val_loss": 13.817347586154938, "val_acc": 80.0}
{"epoch": 14, "training_loss": 56.53585112094879, "training_acc": 72.0, "val_loss": 13.770692050457, "val_acc": 80.0}
{"epoch": 15, "training_loss": 57.31754183769226, "training_acc": 72.0, "val_loss": 13.723458349704742, "val_acc": 80.0}
{"epoch": 16, "training_loss": 56.222667932510376, "training_acc": 72.0, "val_loss": 13.652129471302032, "val_acc": 80.0}
{"epoch": 17, "training_loss": 55.58110165596008, "training_acc": 72.0, "val_loss": 13.59061747789383, "val_acc": 76.0}
{"epoch": 18, "training_loss": 55.4426052570343, "training_acc": 72.0, "val_loss": 13.54200392961502, "val_acc": 76.0}
{"epoch": 19, "training_loss": 54.54585242271423, "training_acc": 72.0, "val_loss": 13.491806387901306, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.26876783370972, "training_acc": 71.0, "val_loss": 13.464652001857758, "val_acc": 72.0}
{"epoch": 21, "training_loss": 53.9334831237793, "training_acc": 73.0, "val_loss": 13.4418785572052, "val_acc": 72.0}
{"epoch": 22, "training_loss": 55.43859028816223, "training_acc": 74.0, "val_loss": 13.422177731990814, "val_acc": 72.0}
{"epoch": 23, "training_loss": 57.97270441055298, "training_acc": 73.0, "val_loss": 13.40615451335907, "val_acc": 72.0}
{"epoch": 24, "training_loss": 56.63060450553894, "training_acc": 72.0, "val_loss": 13.398756086826324, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.75046968460083, "training_acc": 73.0, "val_loss": 13.400322198867798, "val_acc": 76.0}
{"epoch": 26, "training_loss": 53.60538935661316, "training_acc": 73.0, "val_loss": 13.414900004863739, "val_acc": 76.0}
{"epoch": 27, "training_loss": 53.067649602890015, "training_acc": 72.0, "val_loss": 13.411648571491241, "val_acc": 76.0}
{"epoch": 28, "training_loss": 55.663328409194946, "training_acc": 73.0, "val_loss": 13.388419151306152, "val_acc": 76.0}
{"epoch": 29, "training_loss": 52.937259912490845, "training_acc": 73.0, "val_loss": 13.358953595161438, "val_acc": 76.0}
{"epoch": 30, "training_loss": 53.8202908039093, "training_acc": 75.0, "val_loss": 13.328088819980621, "val_acc": 76.0}
{"epoch": 31, "training_loss": 54.39867568016052, "training_acc": 75.0, "val_loss": 13.308286666870117, "val_acc": 76.0}
{"epoch": 32, "training_loss": 55.96787214279175, "training_acc": 75.0, "val_loss": 13.313500583171844, "val_acc": 76.0}
{"epoch": 33, "training_loss": 53.032567262649536, "training_acc": 74.0, "val_loss": 13.294106721878052, "val_acc": 76.0}
{"epoch": 34, "training_loss": 55.15794134140015, "training_acc": 74.0, "val_loss": 13.287821412086487, "val_acc": 76.0}
{"epoch": 35, "training_loss": 52.51479172706604, "training_acc": 74.0, "val_loss": 13.287019729614258, "val_acc": 76.0}
{"epoch": 36, "training_loss": 54.8821382522583, "training_acc": 75.0, "val_loss": 13.290251791477203, "val_acc": 76.0}
{"epoch": 37, "training_loss": 54.716086626052856, "training_acc": 74.0, "val_loss": 13.271139562129974, "val_acc": 76.0}
{"epoch": 38, "training_loss": 53.86072611808777, "training_acc": 74.0, "val_loss": 13.248126208782196, "val_acc": 76.0}
{"epoch": 39, "training_loss": 54.844223618507385, "training_acc": 74.0, "val_loss": 13.242879509925842, "val_acc": 76.0}
{"epoch": 40, "training_loss": 53.70535206794739, "training_acc": 76.0, "val_loss": 13.240332901477814, "val_acc": 76.0}
{"epoch": 41, "training_loss": 54.65159893035889, "training_acc": 74.0, "val_loss": 13.25918436050415, "val_acc": 76.0}
{"epoch": 42, "training_loss": 53.47697830200195, "training_acc": 73.0, "val_loss": 13.280978798866272, "val_acc": 76.0}
{"epoch": 43, "training_loss": 54.3573694229126, "training_acc": 73.0, "val_loss": 13.287150859832764, "val_acc": 76.0}
{"epoch": 44, "training_loss": 53.19678616523743, "training_acc": 75.0, "val_loss": 13.283714652061462, "val_acc": 76.0}
{"epoch": 45, "training_loss": 53.2999541759491, "training_acc": 74.0, "val_loss": 13.254614174365997, "val_acc": 76.0}
{"epoch": 46, "training_loss": 53.13257670402527, "training_acc": 74.0, "val_loss": 13.229264318943024, "val_acc": 76.0}
{"epoch": 47, "training_loss": 51.99138307571411, "training_acc": 76.0, "val_loss": 13.206535577774048, "val_acc": 76.0}
{"epoch": 48, "training_loss": 52.937575340270996, "training_acc": 77.0, "val_loss": 13.193736970424652, "val_acc": 76.0}
{"epoch": 49, "training_loss": 53.85611891746521, "training_acc": 75.0, "val_loss": 13.192415237426758, "val_acc": 76.0}
{"epoch": 50, "training_loss": 52.84768486022949, "training_acc": 75.0, "val_loss": 13.187789916992188, "val_acc": 76.0}
{"epoch": 51, "training_loss": 52.3268666267395, "training_acc": 75.0, "val_loss": 13.150039315223694, "val_acc": 72.0}
{"epoch": 52, "training_loss": 53.221293449401855, "training_acc": 78.0, "val_loss": 13.13292682170868, "val_acc": 68.0}
{"epoch": 53, "training_loss": 53.58924341201782, "training_acc": 75.0, "val_loss": 13.130401074886322, "val_acc": 68.0}
{"epoch": 54, "training_loss": 53.02414572238922, "training_acc": 77.0, "val_loss": 13.120728731155396, "val_acc": 68.0}
{"epoch": 55, "training_loss": 53.18337619304657, "training_acc": 74.0, "val_loss": 13.124561309814453, "val_acc": 76.0}
{"epoch": 56, "training_loss": 52.74987804889679, "training_acc": 74.0, "val_loss": 13.180224597454071, "val_acc": 76.0}
{"epoch": 57, "training_loss": 51.64361000061035, "training_acc": 73.0, "val_loss": 13.272659480571747, "val_acc": 76.0}
{"epoch": 58, "training_loss": 51.6153564453125, "training_acc": 74.0, "val_loss": 13.238058984279633, "val_acc": 76.0}
{"epoch": 59, "training_loss": 53.379477739334106, "training_acc": 73.0, "val_loss": 13.173739612102509, "val_acc": 76.0}
{"epoch": 60, "training_loss": 53.69400143623352, "training_acc": 75.0, "val_loss": 13.133378326892853, "val_acc": 76.0}
{"epoch": 61, "training_loss": 51.49206733703613, "training_acc": 74.0, "val_loss": 13.08889240026474, "val_acc": 76.0}
{"epoch": 62, "training_loss": 52.33767628669739, "training_acc": 75.0, "val_loss": 13.053254783153534, "val_acc": 72.0}
{"epoch": 63, "training_loss": 53.094409823417664, "training_acc": 78.0, "val_loss": 13.043899834156036, "val_acc": 68.0}
{"epoch": 64, "training_loss": 51.893648624420166, "training_acc": 75.0, "val_loss": 13.03890347480774, "val_acc": 68.0}
{"epoch": 65, "training_loss": 53.07648777961731, "training_acc": 74.0, "val_loss": 13.0377858877182, "val_acc": 68.0}
{"epoch": 66, "training_loss": 54.11682176589966, "training_acc": 73.0, "val_loss": 13.050487637519836, "val_acc": 72.0}
{"epoch": 67, "training_loss": 53.383790493011475, "training_acc": 75.0, "val_loss": 13.062901794910431, "val_acc": 72.0}
{"epoch": 68, "training_loss": 52.5937283039093, "training_acc": 75.0, "val_loss": 13.076470792293549, "val_acc": 76.0}
{"epoch": 69, "training_loss": 52.21569848060608, "training_acc": 76.0, "val_loss": 13.075879216194153, "val_acc": 76.0}
{"epoch": 70, "training_loss": 51.21300458908081, "training_acc": 75.0, "val_loss": 13.064616918563843, "val_acc": 72.0}
{"epoch": 71, "training_loss": 51.09969520568848, "training_acc": 77.0, "val_loss": 13.05026262998581, "val_acc": 68.0}
{"epoch": 72, "training_loss": 51.99976134300232, "training_acc": 77.0, "val_loss": 13.043862581253052, "val_acc": 68.0}
{"epoch": 73, "training_loss": 52.69464039802551, "training_acc": 75.0, "val_loss": 13.042889535427094, "val_acc": 68.0}
{"epoch": 74, "training_loss": 51.575841188430786, "training_acc": 80.0, "val_loss": 13.046076893806458, "val_acc": 68.0}
{"epoch": 75, "training_loss": 52.98066449165344, "training_acc": 77.0, "val_loss": 13.048213720321655, "val_acc": 68.0}
{"epoch": 76, "training_loss": 53.214648962020874, "training_acc": 75.0, "val_loss": 13.055668771266937, "val_acc": 68.0}
{"epoch": 77, "training_loss": 52.57013750076294, "training_acc": 76.0, "val_loss": 13.093793392181396, "val_acc": 72.0}
{"epoch": 78, "training_loss": 51.396958231925964, "training_acc": 78.0, "val_loss": 13.140368461608887, "val_acc": 76.0}
{"epoch": 79, "training_loss": 53.82723355293274, "training_acc": 75.0, "val_loss": 13.227960467338562, "val_acc": 76.0}
{"epoch": 80, "training_loss": 52.80198812484741, "training_acc": 75.0, "val_loss": 13.233628869056702, "val_acc": 76.0}
{"epoch": 81, "training_loss": 53.45144248008728, "training_acc": 73.0, "val_loss": 13.17618191242218, "val_acc": 76.0}
{"epoch": 82, "training_loss": 50.61650204658508, "training_acc": 75.0, "val_loss": 13.08462917804718, "val_acc": 68.0}
{"epoch": 83, "training_loss": 53.09120011329651, "training_acc": 75.0, "val_loss": 13.056625425815582, "val_acc": 68.0}
{"epoch": 84, "training_loss": 50.694133043289185, "training_acc": 79.0, "val_loss": 13.049449026584625, "val_acc": 68.0}
