"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 152053.4111328125, "training_acc": 72.0, "val_loss": 109783.63037109375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 334811.494140625, "training_acc": 72.0, "val_loss": 144964.111328125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 516254.9384765625, "training_acc": 28.0, "val_loss": 16277.813720703125, "val_acc": 72.0}
{"epoch": 3, "training_loss": 124141.8076171875, "training_acc": 72.0, "val_loss": 54654.412841796875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 205164.29833984375, "training_acc": 72.0, "val_loss": 23052.151489257812, "val_acc": 72.0}
{"epoch": 5, "training_loss": 115503.189453125, "training_acc": 52.0, "val_loss": 17432.583618164062, "val_acc": 28.0}
{"epoch": 6, "training_loss": 65346.710205078125, "training_acc": 50.0, "val_loss": 43966.693115234375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 184073.98486328125, "training_acc": 72.0, "val_loss": 46693.12438964844, "val_acc": 72.0}
{"epoch": 8, "training_loss": 164380.6728515625, "training_acc": 72.0, "val_loss": 9659.65805053711, "val_acc": 72.0}
{"epoch": 9, "training_loss": 121090.30859375, "training_acc": 52.0, "val_loss": 62137.0361328125, "val_acc": 28.0}
{"epoch": 10, "training_loss": 163001.77603149414, "training_acc": 28.0, "val_loss": 41234.7412109375, "val_acc": 72.0}
{"epoch": 11, "training_loss": 206762.318359375, "training_acc": 72.0, "val_loss": 88651.17797851562, "val_acc": 72.0}
{"epoch": 12, "training_loss": 372843.552734375, "training_acc": 72.0, "val_loss": 93735.43701171875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 358905.7470703125, "training_acc": 72.0, "val_loss": 60446.88720703125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 209595.2412109375, "training_acc": 72.0, "val_loss": 329.62048053741455, "val_acc": 76.0}
{"epoch": 15, "training_loss": 138531.32470703125, "training_acc": 56.0, "val_loss": 95878.44848632812, "val_acc": 28.0}
{"epoch": 16, "training_loss": 318100.32666015625, "training_acc": 28.0, "val_loss": 18823.92578125, "val_acc": 72.0}
{"epoch": 17, "training_loss": 110317.25048828125, "training_acc": 72.0, "val_loss": 57501.318359375, "val_acc": 72.0}
{"epoch": 18, "training_loss": 236751.4345703125, "training_acc": 72.0, "val_loss": 56854.4677734375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 204031.607421875, "training_acc": 72.0, "val_loss": 23009.580993652344, "val_acc": 72.0}
{"epoch": 20, "training_loss": 73610.76159667969, "training_acc": 58.0, "val_loss": 23209.35821533203, "val_acc": 28.0}
{"epoch": 21, "training_loss": 67504.93273925781, "training_acc": 46.0, "val_loss": 16292.19970703125, "val_acc": 72.0}
{"epoch": 22, "training_loss": 62722.46081542969, "training_acc": 72.0, "val_loss": 5836.188507080078, "val_acc": 72.0}
{"epoch": 23, "training_loss": 43599.31494140625, "training_acc": 60.0, "val_loss": 6413.628387451172, "val_acc": 28.0}
{"epoch": 24, "training_loss": 55129.267578125, "training_acc": 42.0, "val_loss": 40242.498779296875, "val_acc": 72.0}
{"epoch": 25, "training_loss": 172039.892578125, "training_acc": 72.0, "val_loss": 43083.97521972656, "val_acc": 72.0}
{"epoch": 26, "training_loss": 155664.47705078125, "training_acc": 72.0, "val_loss": 11537.637329101562, "val_acc": 72.0}
{"epoch": 27, "training_loss": 90383.064453125, "training_acc": 52.0, "val_loss": 38048.919677734375, "val_acc": 28.0}
{"epoch": 28, "training_loss": 86673.97149658203, "training_acc": 56.0, "val_loss": 16181.8115234375, "val_acc": 72.0}
{"epoch": 29, "training_loss": 69530.65283203125, "training_acc": 72.0, "val_loss": 14561.328125, "val_acc": 72.0}
{"epoch": 30, "training_loss": 41800.29066848755, "training_acc": 71.0, "val_loss": 28090.347290039062, "val_acc": 28.0}
{"epoch": 31, "training_loss": 73217.93472290039, "training_acc": 36.0, "val_loss": 17784.64813232422, "val_acc": 72.0}
{"epoch": 32, "training_loss": 77641.09814453125, "training_acc": 72.0, "val_loss": 24455.70068359375, "val_acc": 72.0}
{"epoch": 33, "training_loss": 85916.32836914062, "training_acc": 72.0, "val_loss": 905.5715560913086, "val_acc": 68.0}
