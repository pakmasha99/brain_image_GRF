"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 209260.5127029419, "training_acc": 42.0, "val_loss": 111749.6826171875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 371328.86767578125, "training_acc": 72.0, "val_loss": 89941.2109375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 306005.279296875, "training_acc": 28.0, "val_loss": 33696.746826171875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 191960.8681640625, "training_acc": 72.0, "val_loss": 78263.14086914062, "val_acc": 72.0}
{"epoch": 4, "training_loss": 305853.0009765625, "training_acc": 72.0, "val_loss": 55686.065673828125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 180587.3037109375, "training_acc": 72.0, "val_loss": 30432.894897460938, "val_acc": 28.0}
{"epoch": 6, "training_loss": 134869.45703125, "training_acc": 28.0, "val_loss": 12792.935180664062, "val_acc": 72.0}
{"epoch": 7, "training_loss": 68030.7734375, "training_acc": 72.0, "val_loss": 29606.625366210938, "val_acc": 72.0}
{"epoch": 8, "training_loss": 106735.25610351562, "training_acc": 72.0, "val_loss": 5080.739974975586, "val_acc": 72.0}
{"epoch": 9, "training_loss": 77156.888671875, "training_acc": 60.0, "val_loss": 43354.67529296875, "val_acc": 28.0}
{"epoch": 10, "training_loss": 127509.30139160156, "training_acc": 42.0, "val_loss": 22426.792907714844, "val_acc": 72.0}
{"epoch": 11, "training_loss": 96723.3896484375, "training_acc": 72.0, "val_loss": 18850.71258544922, "val_acc": 72.0}
{"epoch": 12, "training_loss": 48896.44271850586, "training_acc": 72.0, "val_loss": 55165.673828125, "val_acc": 28.0}
{"epoch": 13, "training_loss": 216283.587890625, "training_acc": 28.0, "val_loss": 3610.9092712402344, "val_acc": 72.0}
{"epoch": 14, "training_loss": 28637.08837890625, "training_acc": 72.0, "val_loss": 19142.09747314453, "val_acc": 72.0}
{"epoch": 15, "training_loss": 66682.63244628906, "training_acc": 72.0, "val_loss": 1086.3542556762695, "val_acc": 40.0}
{"epoch": 16, "training_loss": 23096.978271484375, "training_acc": 38.0, "val_loss": 5776.554489135742, "val_acc": 72.0}
{"epoch": 17, "training_loss": 32800.270751953125, "training_acc": 58.0, "val_loss": 5108.993911743164, "val_acc": 72.0}
{"epoch": 18, "training_loss": 23548.0634765625, "training_acc": 72.0, "val_loss": 1115.1911735534668, "val_acc": 44.0}
{"epoch": 19, "training_loss": 25780.402587890625, "training_acc": 45.0, "val_loss": 10078.550720214844, "val_acc": 72.0}
{"epoch": 20, "training_loss": 24480.872787475586, "training_acc": 75.0, "val_loss": 34013.17138671875, "val_acc": 28.0}
{"epoch": 21, "training_loss": 109607.28637695312, "training_acc": 28.0, "val_loss": 22833.734130859375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 133683.990234375, "training_acc": 72.0, "val_loss": 50222.67150878906, "val_acc": 72.0}
{"epoch": 23, "training_loss": 195594.6416015625, "training_acc": 72.0, "val_loss": 37448.28186035156, "val_acc": 72.0}
{"epoch": 24, "training_loss": 119471.08715820312, "training_acc": 72.0, "val_loss": 13088.938903808594, "val_acc": 28.0}
{"epoch": 25, "training_loss": 58437.862548828125, "training_acc": 28.0, "val_loss": 13379.353332519531, "val_acc": 72.0}
{"epoch": 26, "training_loss": 67425.19750976562, "training_acc": 72.0, "val_loss": 24147.618103027344, "val_acc": 72.0}
{"epoch": 27, "training_loss": 81843.83056640625, "training_acc": 72.0, "val_loss": 1146.8889236450195, "val_acc": 68.0}
{"epoch": 28, "training_loss": 68474.88842773438, "training_acc": 61.0, "val_loss": 30265.29541015625, "val_acc": 28.0}
{"epoch": 29, "training_loss": 92500.10681152344, "training_acc": 46.0, "val_loss": 28554.742431640625, "val_acc": 72.0}
{"epoch": 30, "training_loss": 119220.5771484375, "training_acc": 72.0, "val_loss": 31435.382080078125, "val_acc": 72.0}
{"epoch": 31, "training_loss": 107825.93823242188, "training_acc": 72.0, "val_loss": 2102.8852462768555, "val_acc": 72.0}
{"epoch": 32, "training_loss": 78618.75708007812, "training_acc": 59.0, "val_loss": 54944.287109375, "val_acc": 28.0}
{"epoch": 33, "training_loss": 144932.5786743164, "training_acc": 28.0, "val_loss": 37902.33459472656, "val_acc": 72.0}
{"epoch": 34, "training_loss": 187696.158203125, "training_acc": 72.0, "val_loss": 82496.49658203125, "val_acc": 72.0}
