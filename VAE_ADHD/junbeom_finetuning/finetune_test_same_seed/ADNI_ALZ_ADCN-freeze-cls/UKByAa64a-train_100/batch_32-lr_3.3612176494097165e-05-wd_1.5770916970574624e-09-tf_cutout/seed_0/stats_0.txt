"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.20790433883667, "training_acc": 71.0, "val_loss": 16.87164306640625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 66.94808673858643, "training_acc": 72.0, "val_loss": 16.817454993724823, "val_acc": 28.0}
{"epoch": 2, "training_loss": 66.71311950683594, "training_acc": 72.0, "val_loss": 16.775459051132202, "val_acc": 28.0}
{"epoch": 3, "training_loss": 66.55548143386841, "training_acc": 72.0, "val_loss": 16.72193557024002, "val_acc": 28.0}
{"epoch": 4, "training_loss": 66.32652235031128, "training_acc": 72.0, "val_loss": 16.66530966758728, "val_acc": 28.0}
{"epoch": 5, "training_loss": 66.19517636299133, "training_acc": 72.0, "val_loss": 16.611774265766144, "val_acc": 28.0}
{"epoch": 6, "training_loss": 66.02405595779419, "training_acc": 72.0, "val_loss": 16.55232161283493, "val_acc": 28.0}
{"epoch": 7, "training_loss": 65.53437304496765, "training_acc": 72.0, "val_loss": 16.493895649909973, "val_acc": 28.0}
{"epoch": 8, "training_loss": 65.2861635684967, "training_acc": 72.0, "val_loss": 16.437552869319916, "val_acc": 28.0}
{"epoch": 9, "training_loss": 65.14863801002502, "training_acc": 72.0, "val_loss": 16.392886638641357, "val_acc": 28.0}
{"epoch": 10, "training_loss": 65.23679876327515, "training_acc": 72.0, "val_loss": 16.34467989206314, "val_acc": 28.0}
{"epoch": 11, "training_loss": 64.93302392959595, "training_acc": 72.0, "val_loss": 16.30113571882248, "val_acc": 28.0}
{"epoch": 12, "training_loss": 64.69458436965942, "training_acc": 72.0, "val_loss": 16.25799834728241, "val_acc": 28.0}
{"epoch": 13, "training_loss": 64.34310388565063, "training_acc": 72.0, "val_loss": 16.214120388031006, "val_acc": 28.0}
{"epoch": 14, "training_loss": 64.27687168121338, "training_acc": 72.0, "val_loss": 16.16932451725006, "val_acc": 28.0}
{"epoch": 15, "training_loss": 63.95949673652649, "training_acc": 72.0, "val_loss": 16.12734943628311, "val_acc": 28.0}
{"epoch": 16, "training_loss": 64.13820433616638, "training_acc": 72.0, "val_loss": 16.08911156654358, "val_acc": 28.0}
{"epoch": 17, "training_loss": 63.836509227752686, "training_acc": 72.0, "val_loss": 16.048099100589752, "val_acc": 28.0}
{"epoch": 18, "training_loss": 63.74049139022827, "training_acc": 72.0, "val_loss": 16.0046324133873, "val_acc": 28.0}
{"epoch": 19, "training_loss": 63.353694438934326, "training_acc": 72.0, "val_loss": 15.96703827381134, "val_acc": 28.0}
{"epoch": 20, "training_loss": 63.15740776062012, "training_acc": 72.0, "val_loss": 15.933683514595032, "val_acc": 28.0}
{"epoch": 21, "training_loss": 63.162022829055786, "training_acc": 72.0, "val_loss": 15.900959074497223, "val_acc": 28.0}
{"epoch": 22, "training_loss": 63.090677976608276, "training_acc": 72.0, "val_loss": 15.871435403823853, "val_acc": 28.0}
{"epoch": 23, "training_loss": 62.817148208618164, "training_acc": 72.0, "val_loss": 15.839390456676483, "val_acc": 28.0}
{"epoch": 24, "training_loss": 62.71825289726257, "training_acc": 72.0, "val_loss": 15.80781638622284, "val_acc": 28.0}
{"epoch": 25, "training_loss": 62.74275207519531, "training_acc": 72.0, "val_loss": 15.777929127216339, "val_acc": 28.0}
{"epoch": 26, "training_loss": 62.38791751861572, "training_acc": 72.0, "val_loss": 15.749184787273407, "val_acc": 28.0}
{"epoch": 27, "training_loss": 62.35878014564514, "training_acc": 72.0, "val_loss": 15.720905363559723, "val_acc": 24.0}
{"epoch": 28, "training_loss": 62.2661771774292, "training_acc": 72.0, "val_loss": 15.692062675952911, "val_acc": 16.0}
{"epoch": 29, "training_loss": 62.22356176376343, "training_acc": 72.0, "val_loss": 15.66450148820877, "val_acc": 28.0}
{"epoch": 30, "training_loss": 61.88787007331848, "training_acc": 72.0, "val_loss": 15.63921719789505, "val_acc": 28.0}
{"epoch": 31, "training_loss": 62.03497076034546, "training_acc": 72.0, "val_loss": 15.616154670715332, "val_acc": 20.0}
{"epoch": 32, "training_loss": 61.99553060531616, "training_acc": 72.0, "val_loss": 15.601097047328949, "val_acc": 24.0}
{"epoch": 33, "training_loss": 61.92529571056366, "training_acc": 72.0, "val_loss": 15.583115816116333, "val_acc": 32.0}
{"epoch": 34, "training_loss": 61.60615563392639, "training_acc": 72.0, "val_loss": 15.56159108877182, "val_acc": 40.0}
{"epoch": 35, "training_loss": 61.475979924201965, "training_acc": 72.0, "val_loss": 15.540947020053864, "val_acc": 52.0}
{"epoch": 36, "training_loss": 61.59191179275513, "training_acc": 72.0, "val_loss": 15.519773960113525, "val_acc": 56.0}
{"epoch": 37, "training_loss": 61.53159856796265, "training_acc": 72.0, "val_loss": 15.499462187290192, "val_acc": 56.0}
{"epoch": 38, "training_loss": 61.353471755981445, "training_acc": 72.0, "val_loss": 15.480481088161469, "val_acc": 64.0}
{"epoch": 39, "training_loss": 61.44048595428467, "training_acc": 72.0, "val_loss": 15.462285280227661, "val_acc": 68.0}
{"epoch": 40, "training_loss": 61.24305582046509, "training_acc": 72.0, "val_loss": 15.44535607099533, "val_acc": 68.0}
{"epoch": 41, "training_loss": 61.20459699630737, "training_acc": 72.0, "val_loss": 15.429510176181793, "val_acc": 68.0}
{"epoch": 42, "training_loss": 61.2253098487854, "training_acc": 72.0, "val_loss": 15.41430950164795, "val_acc": 68.0}
{"epoch": 43, "training_loss": 61.28626823425293, "training_acc": 72.0, "val_loss": 15.39861112833023, "val_acc": 68.0}
{"epoch": 44, "training_loss": 61.39713191986084, "training_acc": 72.0, "val_loss": 15.383617579936981, "val_acc": 68.0}
{"epoch": 45, "training_loss": 60.92766618728638, "training_acc": 72.0, "val_loss": 15.369579195976257, "val_acc": 68.0}
{"epoch": 46, "training_loss": 60.81279468536377, "training_acc": 72.0, "val_loss": 15.357705950737, "val_acc": 68.0}
{"epoch": 47, "training_loss": 60.819161891937256, "training_acc": 72.0, "val_loss": 15.346063673496246, "val_acc": 72.0}
{"epoch": 48, "training_loss": 60.62345743179321, "training_acc": 72.0, "val_loss": 15.335218608379364, "val_acc": 72.0}
{"epoch": 49, "training_loss": 60.879549503326416, "training_acc": 72.0, "val_loss": 15.323655307292938, "val_acc": 72.0}
