"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 20950.750633239746, "training_acc": 36.0, "val_loss": 7326.706695556641, "val_acc": 72.0}
{"epoch": 1, "training_loss": 21583.924865722656, "training_acc": 72.0, "val_loss": 5975.75569152832, "val_acc": 28.0}
{"epoch": 2, "training_loss": 27522.86346435547, "training_acc": 28.0, "val_loss": 1176.9657135009766, "val_acc": 68.0}
{"epoch": 3, "training_loss": 7293.641937255859, "training_acc": 67.0, "val_loss": 5932.172393798828, "val_acc": 72.0}
{"epoch": 4, "training_loss": 21735.243041992188, "training_acc": 72.0, "val_loss": 6062.79296875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 17922.767639160156, "training_acc": 72.0, "val_loss": 2561.338996887207, "val_acc": 72.0}
{"epoch": 6, "training_loss": 9442.586242675781, "training_acc": 59.0, "val_loss": 2446.9860076904297, "val_acc": 60.0}
{"epoch": 7, "training_loss": 12718.231903076172, "training_acc": 50.0, "val_loss": 2000.1209259033203, "val_acc": 72.0}
{"epoch": 8, "training_loss": 6956.833038330078, "training_acc": 75.0, "val_loss": 3533.551025390625, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9199.745361328125, "training_acc": 73.0, "val_loss": 2022.6486206054688, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5131.585418701172, "training_acc": 73.0, "val_loss": 1364.0546798706055, "val_acc": 64.0}
{"epoch": 11, "training_loss": 6610.106201171875, "training_acc": 56.0, "val_loss": 1405.4388999938965, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3593.614730834961, "training_acc": 76.0, "val_loss": 1132.8003883361816, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3044.029006958008, "training_acc": 62.0, "val_loss": 1014.2055511474609, "val_acc": 36.0}
{"epoch": 14, "training_loss": 2858.7025108337402, "training_acc": 59.0, "val_loss": 769.3159580230713, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2412.131920814514, "training_acc": 73.0, "val_loss": 764.0323162078857, "val_acc": 36.0}
{"epoch": 16, "training_loss": 2529.725814819336, "training_acc": 54.0, "val_loss": 839.1683578491211, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2332.4733848571777, "training_acc": 74.0, "val_loss": 1769.661521911621, "val_acc": 32.0}
{"epoch": 18, "training_loss": 5512.634254455566, "training_acc": 41.0, "val_loss": 942.5046920776367, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3593.6460571289062, "training_acc": 72.0, "val_loss": 728.6466121673584, "val_acc": 76.0}
{"epoch": 20, "training_loss": 1786.4363174438477, "training_acc": 76.0, "val_loss": 718.5523509979248, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2439.347328186035, "training_acc": 69.0, "val_loss": 641.2513732910156, "val_acc": 76.0}
{"epoch": 22, "training_loss": 1854.833381652832, "training_acc": 77.0, "val_loss": 488.8780117034912, "val_acc": 76.0}
{"epoch": 23, "training_loss": 1155.9711360931396, "training_acc": 77.0, "val_loss": 366.5269136428833, "val_acc": 64.0}
{"epoch": 24, "training_loss": 1355.9447536468506, "training_acc": 68.0, "val_loss": 181.0832977294922, "val_acc": 76.0}
{"epoch": 25, "training_loss": 2214.798080444336, "training_acc": 55.0, "val_loss": 703.1692504882812, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3954.7044372558594, "training_acc": 72.0, "val_loss": 611.4948749542236, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2916.564208984375, "training_acc": 61.0, "val_loss": 308.36191177368164, "val_acc": 52.0}
{"epoch": 28, "training_loss": 1261.9592208862305, "training_acc": 67.0, "val_loss": 90.11691212654114, "val_acc": 76.0}
{"epoch": 29, "training_loss": 972.9507141113281, "training_acc": 68.0, "val_loss": 658.7671279907227, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2064.2946014404297, "training_acc": 76.0, "val_loss": 531.3526630401611, "val_acc": 76.0}
{"epoch": 31, "training_loss": 971.2365188598633, "training_acc": 77.0, "val_loss": 491.8111801147461, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1417.943042755127, "training_acc": 78.0, "val_loss": 727.0068645477295, "val_acc": 76.0}
{"epoch": 33, "training_loss": 1087.137035369873, "training_acc": 80.0, "val_loss": 417.39087104797363, "val_acc": 80.0}
{"epoch": 34, "training_loss": 877.859489440918, "training_acc": 76.0, "val_loss": 407.4800968170166, "val_acc": 80.0}
{"epoch": 35, "training_loss": 475.2170343399048, "training_acc": 79.0, "val_loss": 255.2199363708496, "val_acc": 72.0}
{"epoch": 36, "training_loss": 181.77551460266113, "training_acc": 87.0, "val_loss": 265.5142068862915, "val_acc": 64.0}
{"epoch": 37, "training_loss": 832.8428688049316, "training_acc": 70.0, "val_loss": 280.3368091583252, "val_acc": 64.0}
{"epoch": 38, "training_loss": 1796.3264465332031, "training_acc": 59.0, "val_loss": 731.6555500030518, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2194.850166320801, "training_acc": 72.0, "val_loss": 348.83079528808594, "val_acc": 80.0}
{"epoch": 40, "training_loss": 1817.5965881347656, "training_acc": 69.0, "val_loss": 437.9344940185547, "val_acc": 76.0}
{"epoch": 41, "training_loss": 1251.770408630371, "training_acc": 77.0, "val_loss": 891.7591094970703, "val_acc": 76.0}
{"epoch": 42, "training_loss": 1581.9101066589355, "training_acc": 81.0, "val_loss": 568.6270236968994, "val_acc": 68.0}
{"epoch": 43, "training_loss": 1956.6245155334473, "training_acc": 70.0, "val_loss": 1217.8245544433594, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2180.399070739746, "training_acc": 75.0, "val_loss": 434.6789360046387, "val_acc": 64.0}
{"epoch": 45, "training_loss": 1643.838466644287, "training_acc": 68.0, "val_loss": 586.1683368682861, "val_acc": 76.0}
{"epoch": 46, "training_loss": 771.6706275939941, "training_acc": 78.0, "val_loss": 518.3154106140137, "val_acc": 40.0}
{"epoch": 47, "training_loss": 1489.4629392623901, "training_acc": 64.0, "val_loss": 473.1588840484619, "val_acc": 76.0}
