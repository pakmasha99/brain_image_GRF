"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19997.957515716553, "training_acc": 72.0, "val_loss": 6861.061096191406, "val_acc": 72.0}
{"epoch": 1, "training_loss": 18187.13037109375, "training_acc": 72.0, "val_loss": 10457.369995117188, "val_acc": 28.0}
{"epoch": 2, "training_loss": 44095.40417480469, "training_acc": 28.0, "val_loss": 2059.5443725585938, "val_acc": 44.0}
{"epoch": 3, "training_loss": 9717.792999267578, "training_acc": 56.0, "val_loss": 5332.376861572266, "val_acc": 72.0}
{"epoch": 4, "training_loss": 20203.749145507812, "training_acc": 72.0, "val_loss": 6078.748321533203, "val_acc": 72.0}
{"epoch": 5, "training_loss": 19938.094970703125, "training_acc": 72.0, "val_loss": 3176.3744354248047, "val_acc": 72.0}
{"epoch": 6, "training_loss": 8290.792083740234, "training_acc": 69.0, "val_loss": 2644.228935241699, "val_acc": 48.0}
{"epoch": 7, "training_loss": 15479.214599609375, "training_acc": 48.0, "val_loss": 2122.657585144043, "val_acc": 60.0}
{"epoch": 8, "training_loss": 8747.910690307617, "training_acc": 63.0, "val_loss": 2957.3076248168945, "val_acc": 72.0}
{"epoch": 9, "training_loss": 10477.978149414062, "training_acc": 73.0, "val_loss": 4103.947067260742, "val_acc": 72.0}
{"epoch": 10, "training_loss": 11737.563903808594, "training_acc": 72.0, "val_loss": 1918.7362670898438, "val_acc": 68.0}
{"epoch": 11, "training_loss": 4969.707015991211, "training_acc": 69.0, "val_loss": 1829.2631149291992, "val_acc": 52.0}
{"epoch": 12, "training_loss": 8533.870422363281, "training_acc": 53.0, "val_loss": 1264.8493766784668, "val_acc": 64.0}
{"epoch": 13, "training_loss": 4540.108703613281, "training_acc": 71.0, "val_loss": 2812.066650390625, "val_acc": 72.0}
{"epoch": 14, "training_loss": 8489.000457763672, "training_acc": 72.0, "val_loss": 1180.0122261047363, "val_acc": 68.0}
{"epoch": 15, "training_loss": 2911.574935913086, "training_acc": 67.0, "val_loss": 1483.5460662841797, "val_acc": 52.0}
{"epoch": 16, "training_loss": 4361.853874206543, "training_acc": 56.0, "val_loss": 1626.9645690917969, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4595.517135620117, "training_acc": 72.0, "val_loss": 737.8350734710693, "val_acc": 64.0}
{"epoch": 18, "training_loss": 2377.2540283203125, "training_acc": 69.0, "val_loss": 717.5188541412354, "val_acc": 56.0}
{"epoch": 19, "training_loss": 3589.8210220336914, "training_acc": 54.0, "val_loss": 1601.120376586914, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3830.745018005371, "training_acc": 74.0, "val_loss": 607.375955581665, "val_acc": 76.0}
{"epoch": 21, "training_loss": 2561.1752853393555, "training_acc": 63.0, "val_loss": 610.3542327880859, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1105.4431076049805, "training_acc": 84.0, "val_loss": 702.2679328918457, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1259.8248443603516, "training_acc": 82.0, "val_loss": 365.21971225738525, "val_acc": 60.0}
{"epoch": 24, "training_loss": 1410.1255187988281, "training_acc": 70.0, "val_loss": 722.0056056976318, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1948.4038887023926, "training_acc": 67.0, "val_loss": 260.7658624649048, "val_acc": 76.0}
{"epoch": 26, "training_loss": 568.582555770874, "training_acc": 82.0, "val_loss": 414.76755142211914, "val_acc": 52.0}
{"epoch": 27, "training_loss": 2291.756866455078, "training_acc": 54.0, "val_loss": 625.5789756774902, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1646.632553100586, "training_acc": 67.0, "val_loss": 177.94944047927856, "val_acc": 76.0}
{"epoch": 29, "training_loss": 1196.1887283325195, "training_acc": 76.0, "val_loss": 857.7302932739258, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1599.9599514007568, "training_acc": 75.0, "val_loss": 191.62025451660156, "val_acc": 72.0}
{"epoch": 31, "training_loss": 737.8714237213135, "training_acc": 70.0, "val_loss": 471.5869426727295, "val_acc": 76.0}
{"epoch": 32, "training_loss": 830.9543809890747, "training_acc": 79.0, "val_loss": 458.9090347290039, "val_acc": 48.0}
{"epoch": 33, "training_loss": 2132.8538856506348, "training_acc": 59.0, "val_loss": 1000.9807586669922, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2274.980422973633, "training_acc": 75.0, "val_loss": 1087.3082160949707, "val_acc": 36.0}
{"epoch": 35, "training_loss": 3244.192997932434, "training_acc": 54.0, "val_loss": 841.8402671813965, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2016.786449432373, "training_acc": 76.0, "val_loss": 214.55533504486084, "val_acc": 76.0}
{"epoch": 37, "training_loss": 1560.9061431884766, "training_acc": 68.0, "val_loss": 669.8132038116455, "val_acc": 76.0}
{"epoch": 38, "training_loss": 2385.8241271972656, "training_acc": 78.0, "val_loss": 856.8660736083984, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2414.567771911621, "training_acc": 67.0, "val_loss": 311.6050720214844, "val_acc": 68.0}
{"epoch": 40, "training_loss": 1387.7302627563477, "training_acc": 67.0, "val_loss": 544.2080020904541, "val_acc": 76.0}
{"epoch": 41, "training_loss": 666.30224609375, "training_acc": 82.0, "val_loss": 485.3057861328125, "val_acc": 60.0}
{"epoch": 42, "training_loss": 1695.0581436157227, "training_acc": 63.0, "val_loss": 873.2301712036133, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1759.9543151855469, "training_acc": 73.0, "val_loss": 319.31750774383545, "val_acc": 56.0}
{"epoch": 44, "training_loss": 714.4340934753418, "training_acc": 78.0, "val_loss": 446.8761444091797, "val_acc": 76.0}
{"epoch": 45, "training_loss": 493.206844329834, "training_acc": 82.0, "val_loss": 242.78621673583984, "val_acc": 64.0}
{"epoch": 46, "training_loss": 420.02173137664795, "training_acc": 83.0, "val_loss": 331.8211793899536, "val_acc": 76.0}
{"epoch": 47, "training_loss": 262.69508361816406, "training_acc": 92.0, "val_loss": 183.41045379638672, "val_acc": 60.0}
