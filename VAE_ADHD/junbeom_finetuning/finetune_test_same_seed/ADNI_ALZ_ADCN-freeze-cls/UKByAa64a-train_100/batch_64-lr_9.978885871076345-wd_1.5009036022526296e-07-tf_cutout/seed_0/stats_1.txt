"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18524.612907409668, "training_acc": 42.0, "val_loss": 8393.765258789062, "val_acc": 72.0}
{"epoch": 1, "training_loss": 23801.664123535156, "training_acc": 72.0, "val_loss": 6383.390426635742, "val_acc": 28.0}
{"epoch": 2, "training_loss": 22782.363677978516, "training_acc": 32.0, "val_loss": 1032.1964263916016, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6075.896087646484, "training_acc": 72.0, "val_loss": 2287.648582458496, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7140.3621826171875, "training_acc": 73.0, "val_loss": 1738.9162063598633, "val_acc": 56.0}
{"epoch": 5, "training_loss": 8061.982971191406, "training_acc": 52.0, "val_loss": 910.9423637390137, "val_acc": 60.0}
{"epoch": 6, "training_loss": 5697.958709716797, "training_acc": 67.0, "val_loss": 1923.379135131836, "val_acc": 72.0}
{"epoch": 7, "training_loss": 6223.811721801758, "training_acc": 72.0, "val_loss": 718.4264183044434, "val_acc": 64.0}
{"epoch": 8, "training_loss": 4261.3914794921875, "training_acc": 64.0, "val_loss": 855.5535316467285, "val_acc": 56.0}
{"epoch": 9, "training_loss": 2950.677909851074, "training_acc": 65.0, "val_loss": 1112.0363235473633, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3293.4986457824707, "training_acc": 72.0, "val_loss": 964.959716796875, "val_acc": 40.0}
{"epoch": 11, "training_loss": 2521.6438884735107, "training_acc": 57.0, "val_loss": 1101.6636848449707, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3959.758743286133, "training_acc": 72.0, "val_loss": 246.41766548156738, "val_acc": 68.0}
{"epoch": 13, "training_loss": 2506.829788208008, "training_acc": 59.0, "val_loss": 423.30055236816406, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1656.0080490112305, "training_acc": 74.0, "val_loss": 235.25598049163818, "val_acc": 68.0}
{"epoch": 15, "training_loss": 1362.474967956543, "training_acc": 66.0, "val_loss": 560.2486610412598, "val_acc": 76.0}
{"epoch": 16, "training_loss": 2068.206398010254, "training_acc": 77.0, "val_loss": 485.809850692749, "val_acc": 76.0}
{"epoch": 17, "training_loss": 1591.728385925293, "training_acc": 73.0, "val_loss": 321.74251079559326, "val_acc": 72.0}
{"epoch": 18, "training_loss": 905.8514442443848, "training_acc": 78.0, "val_loss": 623.3970642089844, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1582.9933280944824, "training_acc": 69.0, "val_loss": 316.35289192199707, "val_acc": 72.0}
{"epoch": 20, "training_loss": 512.9509201049805, "training_acc": 83.0, "val_loss": 680.5761337280273, "val_acc": 40.0}
{"epoch": 21, "training_loss": 1459.463996887207, "training_acc": 62.0, "val_loss": 1350.9055137634277, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3208.6842727661133, "training_acc": 72.0, "val_loss": 1312.736415863037, "val_acc": 32.0}
{"epoch": 23, "training_loss": 3251.5991859436035, "training_acc": 51.0, "val_loss": 754.3551921844482, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1271.8040180206299, "training_acc": 72.0, "val_loss": 472.3522663116455, "val_acc": 56.0}
{"epoch": 25, "training_loss": 1592.073715209961, "training_acc": 64.0, "val_loss": 504.7731876373291, "val_acc": 76.0}
{"epoch": 26, "training_loss": 1050.51806640625, "training_acc": 75.0, "val_loss": 397.6902484893799, "val_acc": 56.0}
{"epoch": 27, "training_loss": 1159.576545715332, "training_acc": 69.0, "val_loss": 530.3192615509033, "val_acc": 76.0}
{"epoch": 28, "training_loss": 1278.0248947143555, "training_acc": 73.0, "val_loss": 328.0444145202637, "val_acc": 60.0}
{"epoch": 29, "training_loss": 877.5567321777344, "training_acc": 77.0, "val_loss": 539.7668361663818, "val_acc": 76.0}
{"epoch": 30, "training_loss": 1174.8213195800781, "training_acc": 72.0, "val_loss": 287.60766983032227, "val_acc": 76.0}
{"epoch": 31, "training_loss": 318.64933490753174, "training_acc": 85.0, "val_loss": 272.95982837677, "val_acc": 60.0}
{"epoch": 32, "training_loss": 322.99809646606445, "training_acc": 80.0, "val_loss": 339.9108409881592, "val_acc": 72.0}
{"epoch": 33, "training_loss": 428.7485809326172, "training_acc": 81.0, "val_loss": 241.76867008209229, "val_acc": 64.0}
