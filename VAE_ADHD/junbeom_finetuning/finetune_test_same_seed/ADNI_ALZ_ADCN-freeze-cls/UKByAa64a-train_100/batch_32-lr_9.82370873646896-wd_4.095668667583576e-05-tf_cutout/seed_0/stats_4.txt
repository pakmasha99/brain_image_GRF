"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 30559.7550239563, "training_acc": 56.0, "val_loss": 1774.1722106933594, "val_acc": 72.0}
{"epoch": 1, "training_loss": 30524.916625976562, "training_acc": 42.0, "val_loss": 2886.1663818359375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 20100.923950195312, "training_acc": 72.0, "val_loss": 8820.909881591797, "val_acc": 72.0}
{"epoch": 3, "training_loss": 21712.711181640625, "training_acc": 72.0, "val_loss": 3159.8398208618164, "val_acc": 60.0}
{"epoch": 4, "training_loss": 34299.22595214844, "training_acc": 43.0, "val_loss": 3882.7354431152344, "val_acc": 60.0}
{"epoch": 5, "training_loss": 15949.366271972656, "training_acc": 57.0, "val_loss": 7174.23095703125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 22993.095703125, "training_acc": 72.0, "val_loss": 5961.099624633789, "val_acc": 72.0}
{"epoch": 7, "training_loss": 12314.23648071289, "training_acc": 71.0, "val_loss": 2914.064407348633, "val_acc": 60.0}
{"epoch": 8, "training_loss": 17841.511962890625, "training_acc": 55.0, "val_loss": 2304.4906616210938, "val_acc": 68.0}
{"epoch": 9, "training_loss": 7401.937316894531, "training_acc": 73.0, "val_loss": 2576.6035079956055, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7645.205139160156, "training_acc": 55.0, "val_loss": 1293.1459426879883, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8657.102783203125, "training_acc": 77.0, "val_loss": 4269.922256469727, "val_acc": 72.0}
{"epoch": 12, "training_loss": 11388.28628540039, "training_acc": 72.0, "val_loss": 1982.9702377319336, "val_acc": 36.0}
{"epoch": 13, "training_loss": 5820.016845703125, "training_acc": 53.0, "val_loss": 2449.337387084961, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6455.5003662109375, "training_acc": 69.0, "val_loss": 629.566764831543, "val_acc": 76.0}
{"epoch": 15, "training_loss": 3726.751251220703, "training_acc": 73.0, "val_loss": 532.4535369873047, "val_acc": 68.0}
{"epoch": 16, "training_loss": 2814.244873046875, "training_acc": 63.0, "val_loss": 1805.795669555664, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5402.206481933594, "training_acc": 73.0, "val_loss": 714.314079284668, "val_acc": 44.0}
{"epoch": 18, "training_loss": 2123.8835756778717, "training_acc": 68.0, "val_loss": 300.3436803817749, "val_acc": 80.0}
{"epoch": 19, "training_loss": 1169.5265197753906, "training_acc": 76.0, "val_loss": 1111.3273620605469, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3038.206687927246, "training_acc": 77.0, "val_loss": 3029.5372009277344, "val_acc": 28.0}
{"epoch": 21, "training_loss": 7400.548248291016, "training_acc": 49.0, "val_loss": 2771.1925506591797, "val_acc": 72.0}
{"epoch": 22, "training_loss": 7064.941650390625, "training_acc": 75.0, "val_loss": 2198.146438598633, "val_acc": 36.0}
{"epoch": 23, "training_loss": 8120.6287841796875, "training_acc": 47.0, "val_loss": 2282.777786254883, "val_acc": 72.0}
{"epoch": 24, "training_loss": 4140.443139791187, "training_acc": 78.0, "val_loss": 1643.7568664550781, "val_acc": 52.0}
{"epoch": 25, "training_loss": 6099.9844970703125, "training_acc": 61.0, "val_loss": 2657.949638366699, "val_acc": 72.0}
{"epoch": 26, "training_loss": 8612.077955245972, "training_acc": 72.0, "val_loss": 687.1651649475098, "val_acc": 68.0}
{"epoch": 27, "training_loss": 5444.2464599609375, "training_acc": 59.0, "val_loss": 1811.6079330444336, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5378.406494140625, "training_acc": 75.0, "val_loss": 647.4969387054443, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4482.2762451171875, "training_acc": 63.0, "val_loss": 2693.328094482422, "val_acc": 72.0}
{"epoch": 30, "training_loss": 11235.570434570312, "training_acc": 72.0, "val_loss": 940.336799621582, "val_acc": 76.0}
{"epoch": 31, "training_loss": 4526.243759155273, "training_acc": 60.0, "val_loss": 1386.6376876831055, "val_acc": 72.0}
{"epoch": 32, "training_loss": 7185.838470458984, "training_acc": 71.0, "val_loss": 553.3449649810791, "val_acc": 60.0}
{"epoch": 33, "training_loss": 9789.4091796875, "training_acc": 47.0, "val_loss": 1625.0593185424805, "val_acc": 72.0}
{"epoch": 34, "training_loss": 6012.4483642578125, "training_acc": 78.0, "val_loss": 2858.2048416137695, "val_acc": 72.0}
{"epoch": 35, "training_loss": 5577.6756591796875, "training_acc": 77.0, "val_loss": 1446.2028503417969, "val_acc": 68.0}
{"epoch": 36, "training_loss": 6062.347198486328, "training_acc": 66.0, "val_loss": 1537.9267692565918, "val_acc": 76.0}
{"epoch": 37, "training_loss": 3357.300018310547, "training_acc": 76.0, "val_loss": 539.0758514404297, "val_acc": 76.0}
