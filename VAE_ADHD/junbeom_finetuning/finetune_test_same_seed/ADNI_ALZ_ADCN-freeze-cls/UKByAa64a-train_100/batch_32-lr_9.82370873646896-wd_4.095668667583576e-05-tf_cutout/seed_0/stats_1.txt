"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 23970.211698532104, "training_acc": 63.0, "val_loss": 6596.981048583984, "val_acc": 28.0}
{"epoch": 1, "training_loss": 14927.34896850586, "training_acc": 49.0, "val_loss": 3482.333755493164, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9216.492950439453, "training_acc": 67.0, "val_loss": 3083.4007263183594, "val_acc": 60.0}
{"epoch": 3, "training_loss": 11065.618530273438, "training_acc": 62.0, "val_loss": 1665.4523849487305, "val_acc": 80.0}
{"epoch": 4, "training_loss": 4137.538791656494, "training_acc": 74.0, "val_loss": 3409.043502807617, "val_acc": 48.0}
{"epoch": 5, "training_loss": 9320.738037109375, "training_acc": 57.0, "val_loss": 4371.020889282227, "val_acc": 72.0}
{"epoch": 6, "training_loss": 15893.513000488281, "training_acc": 72.0, "val_loss": 531.8773746490479, "val_acc": 56.0}
{"epoch": 7, "training_loss": 10101.628158569336, "training_acc": 44.0, "val_loss": 2076.942825317383, "val_acc": 72.0}
{"epoch": 8, "training_loss": 9007.714599609375, "training_acc": 72.0, "val_loss": 1055.5922508239746, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6850.257194519043, "training_acc": 49.0, "val_loss": 646.831750869751, "val_acc": 68.0}
{"epoch": 10, "training_loss": 2298.0873059031055, "training_acc": 81.0, "val_loss": 477.7679920196533, "val_acc": 64.0}
{"epoch": 11, "training_loss": 1548.6600970029815, "training_acc": 76.0, "val_loss": 607.5529098510742, "val_acc": 72.0}
{"epoch": 12, "training_loss": 979.6054759025319, "training_acc": 69.0, "val_loss": 1349.9234199523926, "val_acc": 32.0}
{"epoch": 13, "training_loss": 3280.7646713256836, "training_acc": 63.0, "val_loss": 803.1229972839355, "val_acc": 36.0}
{"epoch": 14, "training_loss": 797.947395324707, "training_acc": 74.0, "val_loss": 1348.8245964050293, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3960.8837280273438, "training_acc": 73.0, "val_loss": 2971.2535858154297, "val_acc": 28.0}
{"epoch": 16, "training_loss": 7334.562194824219, "training_acc": 50.0, "val_loss": 1701.7412185668945, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5357.889633178711, "training_acc": 70.0, "val_loss": 558.0964088439941, "val_acc": 68.0}
{"epoch": 18, "training_loss": 4187.203857421875, "training_acc": 72.0, "val_loss": 508.95419120788574, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1055.370101928711, "training_acc": 76.0, "val_loss": 378.7364959716797, "val_acc": 68.0}
{"epoch": 20, "training_loss": 407.9998016357422, "training_acc": 84.0, "val_loss": 1294.421100616455, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3238.023697257042, "training_acc": 60.0, "val_loss": 1263.5246276855469, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3272.6200408935547, "training_acc": 70.0, "val_loss": 822.1580505371094, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3735.4700622558594, "training_acc": 72.0, "val_loss": 432.3579788208008, "val_acc": 56.0}
{"epoch": 24, "training_loss": 1287.3102722167969, "training_acc": 76.0, "val_loss": 1688.2341384887695, "val_acc": 40.0}
{"epoch": 25, "training_loss": 3362.788734436035, "training_acc": 62.0, "val_loss": 350.1640558242798, "val_acc": 68.0}
{"epoch": 26, "training_loss": 2089.920150756836, "training_acc": 68.0, "val_loss": 325.9852886199951, "val_acc": 68.0}
{"epoch": 27, "training_loss": 999.6769180297852, "training_acc": 75.0, "val_loss": 362.9850387573242, "val_acc": 68.0}
{"epoch": 28, "training_loss": 3060.567413330078, "training_acc": 61.0, "val_loss": 3163.4164810180664, "val_acc": 72.0}
{"epoch": 29, "training_loss": 11761.1220703125, "training_acc": 72.0, "val_loss": 556.5203666687012, "val_acc": 72.0}
{"epoch": 30, "training_loss": 6843.0767822265625, "training_acc": 54.0, "val_loss": 1540.483570098877, "val_acc": 72.0}
{"epoch": 31, "training_loss": 6009.6268310546875, "training_acc": 73.0, "val_loss": 765.0671005249023, "val_acc": 64.0}
{"epoch": 32, "training_loss": 3159.8865661621094, "training_acc": 70.0, "val_loss": 717.4835205078125, "val_acc": 76.0}
{"epoch": 33, "training_loss": 1092.216022491455, "training_acc": 79.0, "val_loss": 995.313835144043, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3973.202964782715, "training_acc": 72.0, "val_loss": 2734.901809692383, "val_acc": 32.0}
{"epoch": 35, "training_loss": 4139.4495849609375, "training_acc": 62.0, "val_loss": 2955.517578125, "val_acc": 72.0}
{"epoch": 36, "training_loss": 7952.030323028564, "training_acc": 72.0, "val_loss": 4112.045669555664, "val_acc": 32.0}
{"epoch": 37, "training_loss": 15104.81640625, "training_acc": 37.0, "val_loss": 4903.285598754883, "val_acc": 72.0}
{"epoch": 38, "training_loss": 21362.1005859375, "training_acc": 72.0, "val_loss": 5366.5008544921875, "val_acc": 72.0}
{"epoch": 39, "training_loss": 10888.57942199707, "training_acc": 73.0, "val_loss": 4043.862533569336, "val_acc": 56.0}
{"epoch": 40, "training_loss": 12155.6240234375, "training_acc": 59.0, "val_loss": 3157.9545974731445, "val_acc": 76.0}
{"epoch": 41, "training_loss": 11861.839599609375, "training_acc": 75.0, "val_loss": 2085.568046569824, "val_acc": 76.0}
{"epoch": 42, "training_loss": 5758.029113769531, "training_acc": 73.0, "val_loss": 1767.0783996582031, "val_acc": 56.0}
{"epoch": 43, "training_loss": 5134.066864013672, "training_acc": 74.0, "val_loss": 1444.8506355285645, "val_acc": 76.0}
{"epoch": 44, "training_loss": 2339.431427001953, "training_acc": 79.0, "val_loss": 2174.501419067383, "val_acc": 72.0}
{"epoch": 45, "training_loss": 9509.427734375, "training_acc": 72.0, "val_loss": 3195.5461502075195, "val_acc": 72.0}
