"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 22919.808448791504, "training_acc": 58.0, "val_loss": 6159.101486206055, "val_acc": 28.0}
{"epoch": 1, "training_loss": 18806.1943359375, "training_acc": 43.0, "val_loss": 4496.995162963867, "val_acc": 72.0}
{"epoch": 2, "training_loss": 12225.117553710938, "training_acc": 71.0, "val_loss": 1838.4273529052734, "val_acc": 76.0}
{"epoch": 3, "training_loss": 7526.693664550781, "training_acc": 70.0, "val_loss": 2529.228973388672, "val_acc": 68.0}
{"epoch": 4, "training_loss": 9174.803100585938, "training_acc": 71.0, "val_loss": 2097.2246170043945, "val_acc": 48.0}
{"epoch": 5, "training_loss": 13174.326171875, "training_acc": 41.0, "val_loss": 3085.4597091674805, "val_acc": 72.0}
{"epoch": 6, "training_loss": 14464.976196289062, "training_acc": 72.0, "val_loss": 2598.0979919433594, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5635.414611816406, "training_acc": 69.0, "val_loss": 1545.494270324707, "val_acc": 52.0}
{"epoch": 8, "training_loss": 5690.029769897461, "training_acc": 67.0, "val_loss": 1710.678482055664, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4569.584426879883, "training_acc": 68.0, "val_loss": 846.0476875305176, "val_acc": 80.0}
{"epoch": 10, "training_loss": 4817.080505371094, "training_acc": 75.0, "val_loss": 690.0331497192383, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3182.8805541992188, "training_acc": 55.0, "val_loss": 1257.3527336120605, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2210.4194107055664, "training_acc": 69.0, "val_loss": 670.522403717041, "val_acc": 64.0}
{"epoch": 13, "training_loss": 1799.3507919311523, "training_acc": 76.0, "val_loss": 811.3825798034668, "val_acc": 68.0}
{"epoch": 14, "training_loss": 1478.9004392623901, "training_acc": 77.0, "val_loss": 801.789379119873, "val_acc": 48.0}
{"epoch": 15, "training_loss": 3082.6197509765625, "training_acc": 68.0, "val_loss": 1425.6152153015137, "val_acc": 52.0}
{"epoch": 16, "training_loss": 3548.061737060547, "training_acc": 66.0, "val_loss": 813.3770942687988, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4427.39533996582, "training_acc": 58.0, "val_loss": 1567.8210258483887, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4209.319091796875, "training_acc": 74.0, "val_loss": 515.7719612121582, "val_acc": 64.0}
{"epoch": 19, "training_loss": 2669.1901092529297, "training_acc": 68.0, "val_loss": 958.8027954101562, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1495.4626770019531, "training_acc": 73.0, "val_loss": 321.4482307434082, "val_acc": 72.0}
{"epoch": 21, "training_loss": 769.8305969238281, "training_acc": 81.0, "val_loss": 450.3600597381592, "val_acc": 72.0}
{"epoch": 22, "training_loss": 648.235595703125, "training_acc": 82.0, "val_loss": 531.9705486297607, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1185.0826797485352, "training_acc": 72.0, "val_loss": 217.91317462921143, "val_acc": 76.0}
{"epoch": 24, "training_loss": 543.5480260848999, "training_acc": 82.0, "val_loss": 340.5618906021118, "val_acc": 76.0}
{"epoch": 25, "training_loss": 548.9646835327148, "training_acc": 88.0, "val_loss": 247.2301959991455, "val_acc": 76.0}
{"epoch": 26, "training_loss": 451.1416702270508, "training_acc": 82.0, "val_loss": 243.43314170837402, "val_acc": 68.0}
{"epoch": 27, "training_loss": 867.4502563476562, "training_acc": 75.0, "val_loss": 211.96606159210205, "val_acc": 76.0}
{"epoch": 28, "training_loss": 830.6946144104004, "training_acc": 73.0, "val_loss": 715.2823448181152, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1438.8561630249023, "training_acc": 69.0, "val_loss": 368.28484535217285, "val_acc": 72.0}
{"epoch": 30, "training_loss": 899.1776161193848, "training_acc": 81.0, "val_loss": 446.7111110687256, "val_acc": 72.0}
{"epoch": 31, "training_loss": 941.559211730957, "training_acc": 79.0, "val_loss": 621.0767269134521, "val_acc": 56.0}
{"epoch": 32, "training_loss": 1846.3977196216583, "training_acc": 66.0, "val_loss": 937.5522613525391, "val_acc": 52.0}
{"epoch": 33, "training_loss": 2080.4788513183594, "training_acc": 65.0, "val_loss": 394.27387714385986, "val_acc": 72.0}
{"epoch": 34, "training_loss": 748.8117904663086, "training_acc": 77.0, "val_loss": 1257.0219039916992, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2457.0459899902344, "training_acc": 77.0, "val_loss": 717.732572555542, "val_acc": 72.0}
{"epoch": 36, "training_loss": 969.3329010009766, "training_acc": 79.0, "val_loss": 524.1075992584229, "val_acc": 72.0}
{"epoch": 37, "training_loss": 689.8895044326782, "training_acc": 87.0, "val_loss": 1406.900405883789, "val_acc": 36.0}
{"epoch": 38, "training_loss": 2957.3994750976562, "training_acc": 62.0, "val_loss": 677.482795715332, "val_acc": 52.0}
{"epoch": 39, "training_loss": 1731.8286832570684, "training_acc": 71.0, "val_loss": 721.8368530273438, "val_acc": 48.0}
{"epoch": 40, "training_loss": 1764.3047523498535, "training_acc": 68.0, "val_loss": 1342.0316696166992, "val_acc": 40.0}
{"epoch": 41, "training_loss": 5008.51513671875, "training_acc": 52.0, "val_loss": 2220.41015625, "val_acc": 72.0}
{"epoch": 42, "training_loss": 3917.728988647461, "training_acc": 77.0, "val_loss": 1513.702392578125, "val_acc": 44.0}
{"epoch": 43, "training_loss": 4124.396041870117, "training_acc": 65.0, "val_loss": 621.2553024291992, "val_acc": 72.0}
{"epoch": 44, "training_loss": 4755.07829284668, "training_acc": 56.0, "val_loss": 2229.5534133911133, "val_acc": 72.0}
{"epoch": 45, "training_loss": 6579.982210159302, "training_acc": 73.0, "val_loss": 2238.140296936035, "val_acc": 36.0}
{"epoch": 46, "training_loss": 6957.326095581055, "training_acc": 50.0, "val_loss": 2602.6493072509766, "val_acc": 72.0}
