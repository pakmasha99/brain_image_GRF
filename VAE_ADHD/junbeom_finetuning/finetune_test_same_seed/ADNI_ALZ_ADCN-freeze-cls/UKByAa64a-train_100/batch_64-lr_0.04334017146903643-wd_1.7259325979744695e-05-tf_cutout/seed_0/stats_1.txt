"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 130.79196739196777, "training_acc": 72.0, "val_loss": 34.35344994068146, "val_acc": 72.0}
{"epoch": 1, "training_loss": 96.21167373657227, "training_acc": 72.0, "val_loss": 34.02376174926758, "val_acc": 28.0}
{"epoch": 2, "training_loss": 129.84886956214905, "training_acc": 29.0, "val_loss": 14.624489843845367, "val_acc": 56.0}
{"epoch": 3, "training_loss": 66.93895673751831, "training_acc": 69.0, "val_loss": 23.653249442577362, "val_acc": 72.0}
{"epoch": 4, "training_loss": 92.14052295684814, "training_acc": 72.0, "val_loss": 20.260994136333466, "val_acc": 72.0}
{"epoch": 5, "training_loss": 72.67732620239258, "training_acc": 72.0, "val_loss": 14.065691828727722, "val_acc": 56.0}
{"epoch": 6, "training_loss": 64.37226271629333, "training_acc": 65.0, "val_loss": 17.584413290023804, "val_acc": 60.0}
{"epoch": 7, "training_loss": 72.62250566482544, "training_acc": 63.0, "val_loss": 13.612686097621918, "val_acc": 76.0}
{"epoch": 8, "training_loss": 58.970683336257935, "training_acc": 78.0, "val_loss": 16.463500261306763, "val_acc": 72.0}
{"epoch": 9, "training_loss": 66.78849411010742, "training_acc": 72.0, "val_loss": 13.788148760795593, "val_acc": 76.0}
{"epoch": 10, "training_loss": 54.75445032119751, "training_acc": 74.0, "val_loss": 14.048556983470917, "val_acc": 56.0}
{"epoch": 11, "training_loss": 59.82416605949402, "training_acc": 67.0, "val_loss": 13.268814980983734, "val_acc": 56.0}
{"epoch": 12, "training_loss": 53.06904673576355, "training_acc": 73.0, "val_loss": 13.38469386100769, "val_acc": 76.0}
{"epoch": 13, "training_loss": 53.70504319667816, "training_acc": 72.0, "val_loss": 14.566169679164886, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.292065024375916, "training_acc": 72.0, "val_loss": 12.951314449310303, "val_acc": 68.0}
{"epoch": 15, "training_loss": 51.820573806762695, "training_acc": 76.0, "val_loss": 13.263067603111267, "val_acc": 64.0}
{"epoch": 16, "training_loss": 53.92177963256836, "training_acc": 76.0, "val_loss": 12.982341647148132, "val_acc": 72.0}
{"epoch": 17, "training_loss": 53.110827922821045, "training_acc": 74.0, "val_loss": 13.859564065933228, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.796022176742554, "training_acc": 72.0, "val_loss": 12.995311617851257, "val_acc": 68.0}
{"epoch": 19, "training_loss": 50.3442599773407, "training_acc": 75.0, "val_loss": 13.819791376590729, "val_acc": 56.0}
{"epoch": 20, "training_loss": 53.01852774620056, "training_acc": 78.0, "val_loss": 12.81428188085556, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50.07769203186035, "training_acc": 75.0, "val_loss": 14.131085574626923, "val_acc": 76.0}
{"epoch": 22, "training_loss": 56.275585889816284, "training_acc": 72.0, "val_loss": 12.611623108386993, "val_acc": 72.0}
{"epoch": 23, "training_loss": 49.43076467514038, "training_acc": 77.0, "val_loss": 13.349112868309021, "val_acc": 68.0}
{"epoch": 24, "training_loss": 54.08115077018738, "training_acc": 74.0, "val_loss": 12.44933307170868, "val_acc": 68.0}
{"epoch": 25, "training_loss": 50.07603847980499, "training_acc": 75.0, "val_loss": 13.198867440223694, "val_acc": 80.0}
{"epoch": 26, "training_loss": 49.41350030899048, "training_acc": 74.0, "val_loss": 12.522777915000916, "val_acc": 68.0}
{"epoch": 27, "training_loss": 51.343942165374756, "training_acc": 78.0, "val_loss": 12.536345422267914, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.33844804763794, "training_acc": 78.0, "val_loss": 12.825170159339905, "val_acc": 72.0}
{"epoch": 29, "training_loss": 47.89564764499664, "training_acc": 75.0, "val_loss": 12.555292248725891, "val_acc": 72.0}
{"epoch": 30, "training_loss": 47.959880113601685, "training_acc": 79.0, "val_loss": 12.478317320346832, "val_acc": 68.0}
{"epoch": 31, "training_loss": 47.169410943984985, "training_acc": 80.0, "val_loss": 12.486428767442703, "val_acc": 72.0}
{"epoch": 32, "training_loss": 47.666818141937256, "training_acc": 78.0, "val_loss": 12.810461223125458, "val_acc": 72.0}
{"epoch": 33, "training_loss": 46.17280387878418, "training_acc": 77.0, "val_loss": 12.628746032714844, "val_acc": 68.0}
{"epoch": 34, "training_loss": 47.16365087032318, "training_acc": 77.0, "val_loss": 12.571993470191956, "val_acc": 68.0}
{"epoch": 35, "training_loss": 46.07842934131622, "training_acc": 80.0, "val_loss": 12.893705070018768, "val_acc": 72.0}
{"epoch": 36, "training_loss": 48.81166958808899, "training_acc": 78.0, "val_loss": 12.974575161933899, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.64141845703125, "training_acc": 77.0, "val_loss": 12.78230994939804, "val_acc": 72.0}
{"epoch": 38, "training_loss": 45.11895775794983, "training_acc": 78.0, "val_loss": 13.085557520389557, "val_acc": 72.0}
{"epoch": 39, "training_loss": 47.753989815711975, "training_acc": 77.0, "val_loss": 13.088932633399963, "val_acc": 68.0}
{"epoch": 40, "training_loss": 46.1387699842453, "training_acc": 78.0, "val_loss": 13.109764456748962, "val_acc": 68.0}
{"epoch": 41, "training_loss": 46.26617884635925, "training_acc": 78.0, "val_loss": 13.150247931480408, "val_acc": 72.0}
{"epoch": 42, "training_loss": 46.759087562561035, "training_acc": 79.0, "val_loss": 13.129924237728119, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.92579627037048, "training_acc": 80.0, "val_loss": 13.065856695175171, "val_acc": 72.0}
