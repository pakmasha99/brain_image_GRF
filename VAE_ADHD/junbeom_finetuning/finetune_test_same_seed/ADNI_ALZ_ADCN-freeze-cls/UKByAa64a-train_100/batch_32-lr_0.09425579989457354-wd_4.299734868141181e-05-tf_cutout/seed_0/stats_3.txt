"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 264.88801431655884, "training_acc": 56.0, "val_loss": 38.11485469341278, "val_acc": 28.0}
{"epoch": 1, "training_loss": 137.49264764785767, "training_acc": 38.0, "val_loss": 35.6478750705719, "val_acc": 72.0}
{"epoch": 2, "training_loss": 95.6002345085144, "training_acc": 74.0, "val_loss": 35.93914806842804, "val_acc": 32.0}
{"epoch": 3, "training_loss": 89.32033696770668, "training_acc": 63.0, "val_loss": 40.97231924533844, "val_acc": 72.0}
{"epoch": 4, "training_loss": 142.28542733192444, "training_acc": 72.0, "val_loss": 20.889031887054443, "val_acc": 48.0}
{"epoch": 5, "training_loss": 87.79854249954224, "training_acc": 51.0, "val_loss": 25.589677691459656, "val_acc": 72.0}
{"epoch": 6, "training_loss": 110.2898051738739, "training_acc": 72.0, "val_loss": 18.775737285614014, "val_acc": 64.0}
{"epoch": 7, "training_loss": 82.54070675373077, "training_acc": 59.0, "val_loss": 18.500663340091705, "val_acc": 72.0}
{"epoch": 8, "training_loss": 70.07754325866699, "training_acc": 76.0, "val_loss": 20.41330635547638, "val_acc": 64.0}
{"epoch": 9, "training_loss": 76.10765886306763, "training_acc": 67.0, "val_loss": 20.957233011722565, "val_acc": 76.0}
{"epoch": 10, "training_loss": 108.93935060501099, "training_acc": 72.0, "val_loss": 15.729686617851257, "val_acc": 72.0}
{"epoch": 11, "training_loss": 73.78104734420776, "training_acc": 63.0, "val_loss": 16.394086182117462, "val_acc": 72.0}
{"epoch": 12, "training_loss": 85.72568905353546, "training_acc": 71.0, "val_loss": 15.059654414653778, "val_acc": 80.0}
{"epoch": 13, "training_loss": 72.016184091568, "training_acc": 58.0, "val_loss": 14.898422360420227, "val_acc": 72.0}
{"epoch": 14, "training_loss": 61.66166973114014, "training_acc": 75.0, "val_loss": 19.497139751911163, "val_acc": 56.0}
{"epoch": 15, "training_loss": 77.855712890625, "training_acc": 52.0, "val_loss": 13.780124485492706, "val_acc": 80.0}
{"epoch": 16, "training_loss": 51.29305577278137, "training_acc": 73.0, "val_loss": 15.146271884441376, "val_acc": 48.0}
{"epoch": 17, "training_loss": 46.47225522994995, "training_acc": 78.0, "val_loss": 13.401244580745697, "val_acc": 60.0}
{"epoch": 18, "training_loss": 48.705106258392334, "training_acc": 74.0, "val_loss": 12.155459821224213, "val_acc": 84.0}
{"epoch": 19, "training_loss": 47.502710580825806, "training_acc": 77.0, "val_loss": 14.364741742610931, "val_acc": 56.0}
{"epoch": 20, "training_loss": 43.713425666093826, "training_acc": 81.0, "val_loss": 13.80031406879425, "val_acc": 80.0}
{"epoch": 21, "training_loss": 46.87058210372925, "training_acc": 80.0, "val_loss": 25.83463490009308, "val_acc": 44.0}
{"epoch": 22, "training_loss": 63.94196629524231, "training_acc": 63.0, "val_loss": 17.06794947385788, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.23434257507324, "training_acc": 72.0, "val_loss": 11.906737834215164, "val_acc": 76.0}
{"epoch": 24, "training_loss": 46.231770277023315, "training_acc": 76.0, "val_loss": 12.50101625919342, "val_acc": 60.0}
{"epoch": 25, "training_loss": 43.06147801876068, "training_acc": 83.0, "val_loss": 12.337301671504974, "val_acc": 84.0}
{"epoch": 26, "training_loss": 54.276850938797, "training_acc": 76.0, "val_loss": 27.07059681415558, "val_acc": 40.0}
{"epoch": 27, "training_loss": 63.63970589637756, "training_acc": 63.0, "val_loss": 17.998690903186798, "val_acc": 80.0}
{"epoch": 28, "training_loss": 55.711350440979004, "training_acc": 77.0, "val_loss": 21.18477374315262, "val_acc": 60.0}
{"epoch": 29, "training_loss": 44.12089490890503, "training_acc": 79.0, "val_loss": 17.32395589351654, "val_acc": 80.0}
{"epoch": 30, "training_loss": 66.30697798728943, "training_acc": 77.0, "val_loss": 19.63445097208023, "val_acc": 40.0}
{"epoch": 31, "training_loss": 49.91342258453369, "training_acc": 67.0, "val_loss": 11.698566377162933, "val_acc": 64.0}
{"epoch": 32, "training_loss": 44.62128305435181, "training_acc": 75.0, "val_loss": 12.04361617565155, "val_acc": 68.0}
{"epoch": 33, "training_loss": 43.208401679992676, "training_acc": 79.0, "val_loss": 19.17305290699005, "val_acc": 48.0}
{"epoch": 34, "training_loss": 65.15285682678223, "training_acc": 67.0, "val_loss": 18.860141932964325, "val_acc": 72.0}
{"epoch": 35, "training_loss": 66.77797484397888, "training_acc": 77.0, "val_loss": 32.44660794734955, "val_acc": 32.0}
{"epoch": 36, "training_loss": 53.648691818118095, "training_acc": 71.0, "val_loss": 30.707406997680664, "val_acc": 72.0}
{"epoch": 37, "training_loss": 121.8188584446907, "training_acc": 72.0, "val_loss": 18.541879951953888, "val_acc": 56.0}
{"epoch": 38, "training_loss": 60.59420967102051, "training_acc": 71.0, "val_loss": 13.892404735088348, "val_acc": 68.0}
{"epoch": 39, "training_loss": 42.81659686565399, "training_acc": 78.0, "val_loss": 13.804078102111816, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.24049997329712, "training_acc": 73.0, "val_loss": 43.7387079000473, "val_acc": 28.0}
{"epoch": 41, "training_loss": 112.43354517221451, "training_acc": 54.0, "val_loss": 39.232102036476135, "val_acc": 72.0}
{"epoch": 42, "training_loss": 189.30088329315186, "training_acc": 72.0, "val_loss": 17.03389286994934, "val_acc": 80.0}
{"epoch": 43, "training_loss": 144.30119800567627, "training_acc": 44.0, "val_loss": 19.925250113010406, "val_acc": 80.0}
{"epoch": 44, "training_loss": 145.02912139892578, "training_acc": 73.0, "val_loss": 40.44688642024994, "val_acc": 72.0}
{"epoch": 45, "training_loss": 122.71304321289062, "training_acc": 66.0, "val_loss": 64.61690664291382, "val_acc": 36.0}
{"epoch": 46, "training_loss": 140.81037831306458, "training_acc": 55.0, "val_loss": 40.18540382385254, "val_acc": 72.0}
{"epoch": 47, "training_loss": 125.27145621180534, "training_acc": 73.0, "val_loss": 31.376823782920837, "val_acc": 64.0}
{"epoch": 48, "training_loss": 81.52626258134842, "training_acc": 68.0, "val_loss": 26.372316479682922, "val_acc": 64.0}
{"epoch": 49, "training_loss": 46.3612722158432, "training_acc": 81.0, "val_loss": 18.734996020793915, "val_acc": 76.0}
{"epoch": 50, "training_loss": 47.88311743736267, "training_acc": 82.0, "val_loss": 16.541990637779236, "val_acc": 52.0}
