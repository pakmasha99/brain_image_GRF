"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12699.503555297852, "training_acc": 72.0, "val_loss": 5921.953582763672, "val_acc": 72.0}
{"epoch": 1, "training_loss": 13439.437435150146, "training_acc": 72.0, "val_loss": 2909.199905395508, "val_acc": 32.0}
{"epoch": 2, "training_loss": 9745.837005615234, "training_acc": 44.0, "val_loss": 3149.026298522949, "val_acc": 72.0}
{"epoch": 3, "training_loss": 11181.29702758789, "training_acc": 72.0, "val_loss": 1613.6220932006836, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6913.451599121094, "training_acc": 59.0, "val_loss": 2306.831169128418, "val_acc": 60.0}
{"epoch": 5, "training_loss": 5685.689208984375, "training_acc": 66.0, "val_loss": 2016.0043716430664, "val_acc": 68.0}
{"epoch": 6, "training_loss": 6625.420135498047, "training_acc": 71.0, "val_loss": 1458.883285522461, "val_acc": 68.0}
{"epoch": 7, "training_loss": 4956.906433105469, "training_acc": 57.0, "val_loss": 2026.9123077392578, "val_acc": 56.0}
{"epoch": 8, "training_loss": 4002.597297668457, "training_acc": 66.0, "val_loss": 1544.9613571166992, "val_acc": 68.0}
{"epoch": 9, "training_loss": 5864.449188232422, "training_acc": 72.0, "val_loss": 982.4606895446777, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3272.2339782714844, "training_acc": 66.0, "val_loss": 1005.081844329834, "val_acc": 64.0}
{"epoch": 11, "training_loss": 2827.0728302001953, "training_acc": 62.0, "val_loss": 735.3166103363037, "val_acc": 80.0}
{"epoch": 12, "training_loss": 3428.0338134765625, "training_acc": 65.0, "val_loss": 549.3127346038818, "val_acc": 64.0}
{"epoch": 13, "training_loss": 1486.9076232910156, "training_acc": 68.0, "val_loss": 170.78129053115845, "val_acc": 80.0}
{"epoch": 14, "training_loss": 2095.3162994384766, "training_acc": 58.0, "val_loss": 606.9279193878174, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3297.4378814697266, "training_acc": 72.0, "val_loss": 549.2382526397705, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2838.9603424072266, "training_acc": 59.0, "val_loss": 107.35529661178589, "val_acc": 56.0}
{"epoch": 17, "training_loss": 673.6383094787598, "training_acc": 79.0, "val_loss": 150.68440437316895, "val_acc": 84.0}
{"epoch": 18, "training_loss": 852.9920883178711, "training_acc": 76.0, "val_loss": 217.89891719818115, "val_acc": 80.0}
{"epoch": 19, "training_loss": 973.9923324584961, "training_acc": 79.0, "val_loss": 355.3485870361328, "val_acc": 56.0}
{"epoch": 20, "training_loss": 867.2999839782715, "training_acc": 69.0, "val_loss": 294.7878360748291, "val_acc": 80.0}
{"epoch": 21, "training_loss": 660.0071334838867, "training_acc": 79.0, "val_loss": 784.2006683349609, "val_acc": 44.0}
{"epoch": 22, "training_loss": 2350.5187911987305, "training_acc": 54.0, "val_loss": 318.2661294937134, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1309.62984085083, "training_acc": 68.0, "val_loss": 121.73612117767334, "val_acc": 64.0}
{"epoch": 24, "training_loss": 483.7814712524414, "training_acc": 81.0, "val_loss": 495.4786777496338, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1157.0145835876465, "training_acc": 66.0, "val_loss": 77.07439064979553, "val_acc": 84.0}
{"epoch": 26, "training_loss": 382.8165760040283, "training_acc": 80.0, "val_loss": 238.25111389160156, "val_acc": 72.0}
{"epoch": 27, "training_loss": 709.4813232421875, "training_acc": 72.0, "val_loss": 61.83596849441528, "val_acc": 76.0}
{"epoch": 28, "training_loss": 190.17919993400574, "training_acc": 83.0, "val_loss": 43.3998703956604, "val_acc": 84.0}
{"epoch": 29, "training_loss": 176.41921424865723, "training_acc": 84.0, "val_loss": 328.50592136383057, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1126.0977001190186, "training_acc": 70.0, "val_loss": 55.392348766326904, "val_acc": 84.0}
{"epoch": 31, "training_loss": 187.06377267837524, "training_acc": 82.0, "val_loss": 83.262699842453, "val_acc": 80.0}
{"epoch": 32, "training_loss": 561.3579254150391, "training_acc": 73.0, "val_loss": 209.82000827789307, "val_acc": 76.0}
{"epoch": 33, "training_loss": 560.7864246368408, "training_acc": 78.0, "val_loss": 880.4998397827148, "val_acc": 32.0}
{"epoch": 34, "training_loss": 2134.4121017456055, "training_acc": 55.0, "val_loss": 641.4083480834961, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1615.8519411087036, "training_acc": 75.0, "val_loss": 1278.4062385559082, "val_acc": 32.0}
{"epoch": 36, "training_loss": 2542.638391494751, "training_acc": 53.0, "val_loss": 723.7532138824463, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2114.4641704559326, "training_acc": 75.0, "val_loss": 1196.305751800537, "val_acc": 52.0}
{"epoch": 38, "training_loss": 2825.5401668548584, "training_acc": 60.0, "val_loss": 682.1919441223145, "val_acc": 76.0}
{"epoch": 39, "training_loss": 1988.6290740966797, "training_acc": 77.0, "val_loss": 689.6478652954102, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1922.2378997802734, "training_acc": 69.0, "val_loss": 525.8990287780762, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1354.3673248291016, "training_acc": 75.0, "val_loss": 350.0868797302246, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1488.4008407592773, "training_acc": 74.0, "val_loss": 429.61535453796387, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1686.27783203125, "training_acc": 74.0, "val_loss": 289.9970054626465, "val_acc": 56.0}
{"epoch": 44, "training_loss": 663.4769802093506, "training_acc": 64.0, "val_loss": 79.09396290779114, "val_acc": 88.0}
{"epoch": 45, "training_loss": 609.0077476501465, "training_acc": 75.0, "val_loss": 415.18688201904297, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1423.9460334777832, "training_acc": 73.0, "val_loss": 869.693660736084, "val_acc": 48.0}
{"epoch": 47, "training_loss": 1697.605863571167, "training_acc": 62.0, "val_loss": 404.7877311706543, "val_acc": 80.0}
