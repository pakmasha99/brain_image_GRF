"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14059.150619506836, "training_acc": 47.0, "val_loss": 7678.568267822266, "val_acc": 72.0}
{"epoch": 1, "training_loss": 25919.993774414062, "training_acc": 72.0, "val_loss": 6333.896255493164, "val_acc": 28.0}
{"epoch": 2, "training_loss": 24210.14959716797, "training_acc": 28.0, "val_loss": 1718.113899230957, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8653.076843261719, "training_acc": 72.0, "val_loss": 4450.814437866211, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15602.743347167969, "training_acc": 72.0, "val_loss": 2605.142593383789, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6496.3172607421875, "training_acc": 70.0, "val_loss": 2403.9241790771484, "val_acc": 48.0}
{"epoch": 6, "training_loss": 13023.007141113281, "training_acc": 49.0, "val_loss": 1435.241413116455, "val_acc": 72.0}
{"epoch": 7, "training_loss": 6798.609954833984, "training_acc": 65.0, "val_loss": 3452.6199340820312, "val_acc": 72.0}
{"epoch": 8, "training_loss": 12121.023376464844, "training_acc": 72.0, "val_loss": 3657.435989379883, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9844.892272949219, "training_acc": 73.0, "val_loss": 1341.461181640625, "val_acc": 68.0}
{"epoch": 10, "training_loss": 4043.8911743164062, "training_acc": 67.0, "val_loss": 1658.1567764282227, "val_acc": 52.0}
{"epoch": 11, "training_loss": 7765.971862792969, "training_acc": 58.0, "val_loss": 1420.3752517700195, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3885.4617919921875, "training_acc": 73.0, "val_loss": 1500.1240730285645, "val_acc": 68.0}
{"epoch": 13, "training_loss": 3051.4432067871094, "training_acc": 77.0, "val_loss": 1136.8606567382812, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3365.670196533203, "training_acc": 57.0, "val_loss": 1293.2531356811523, "val_acc": 68.0}
{"epoch": 15, "training_loss": 4036.112762451172, "training_acc": 72.0, "val_loss": 1112.7314567565918, "val_acc": 64.0}
{"epoch": 16, "training_loss": 4082.5267944335938, "training_acc": 50.0, "val_loss": 847.279167175293, "val_acc": 48.0}
{"epoch": 17, "training_loss": 2854.4900512695312, "training_acc": 61.0, "val_loss": 1188.4909629821777, "val_acc": 68.0}
{"epoch": 18, "training_loss": 2266.0429611206055, "training_acc": 74.0, "val_loss": 1063.4345054626465, "val_acc": 48.0}
{"epoch": 19, "training_loss": 2895.7404708862305, "training_acc": 55.0, "val_loss": 897.1161842346191, "val_acc": 64.0}
{"epoch": 20, "training_loss": 1780.422248840332, "training_acc": 72.0, "val_loss": 663.9442443847656, "val_acc": 64.0}
{"epoch": 21, "training_loss": 762.722484588623, "training_acc": 78.0, "val_loss": 462.62450218200684, "val_acc": 68.0}
{"epoch": 22, "training_loss": 796.5119323730469, "training_acc": 80.0, "val_loss": 327.2762060165405, "val_acc": 68.0}
{"epoch": 23, "training_loss": 470.3001117706299, "training_acc": 83.0, "val_loss": 280.40385246276855, "val_acc": 76.0}
{"epoch": 24, "training_loss": 429.0126323699951, "training_acc": 84.0, "val_loss": 223.26691150665283, "val_acc": 52.0}
{"epoch": 25, "training_loss": 1982.8465270996094, "training_acc": 60.0, "val_loss": 888.1851196289062, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1828.0982685089111, "training_acc": 74.0, "val_loss": 2240.7121658325195, "val_acc": 28.0}
{"epoch": 27, "training_loss": 6366.0494384765625, "training_acc": 37.0, "val_loss": 1805.167579650879, "val_acc": 72.0}
{"epoch": 28, "training_loss": 7728.077575683594, "training_acc": 72.0, "val_loss": 3081.78653717041, "val_acc": 72.0}
{"epoch": 29, "training_loss": 10545.744415283203, "training_acc": 72.0, "val_loss": 1116.002368927002, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5111.049713134766, "training_acc": 60.0, "val_loss": 1927.3109436035156, "val_acc": 44.0}
{"epoch": 31, "training_loss": 6491.695495605469, "training_acc": 51.0, "val_loss": 1682.3408126831055, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6696.6131591796875, "training_acc": 73.0, "val_loss": 2528.007698059082, "val_acc": 72.0}
{"epoch": 33, "training_loss": 6980.473388671875, "training_acc": 73.0, "val_loss": 869.2244529724121, "val_acc": 80.0}
{"epoch": 34, "training_loss": 3765.2655639648438, "training_acc": 71.0, "val_loss": 935.8414649963379, "val_acc": 56.0}
{"epoch": 35, "training_loss": 3822.71573638916, "training_acc": 66.0, "val_loss": 1431.9982528686523, "val_acc": 72.0}
{"epoch": 36, "training_loss": 3822.859130859375, "training_acc": 76.0, "val_loss": 989.1718864440918, "val_acc": 76.0}
{"epoch": 37, "training_loss": 1672.643482208252, "training_acc": 75.0, "val_loss": 1305.461025238037, "val_acc": 44.0}
{"epoch": 38, "training_loss": 4450.635833740234, "training_acc": 52.0, "val_loss": 1102.5075912475586, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2830.891372680664, "training_acc": 72.0, "val_loss": 383.2737922668457, "val_acc": 68.0}
{"epoch": 40, "training_loss": 1973.5341033935547, "training_acc": 69.0, "val_loss": 448.7361431121826, "val_acc": 52.0}
{"epoch": 41, "training_loss": 1954.4666290283203, "training_acc": 80.0, "val_loss": 844.324779510498, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1588.4852409362793, "training_acc": 73.0, "val_loss": 687.4971389770508, "val_acc": 60.0}
{"epoch": 43, "training_loss": 2078.2946853637695, "training_acc": 58.0, "val_loss": 1138.5449409484863, "val_acc": 72.0}
