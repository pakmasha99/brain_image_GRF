"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12903.912780761719, "training_acc": 72.0, "val_loss": 6790.990447998047, "val_acc": 72.0}
{"epoch": 1, "training_loss": 19416.225616455078, "training_acc": 68.0, "val_loss": 11052.79541015625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 37752.88671875, "training_acc": 28.0, "val_loss": 876.7094612121582, "val_acc": 76.0}
{"epoch": 3, "training_loss": 6564.837432861328, "training_acc": 72.0, "val_loss": 5032.868576049805, "val_acc": 72.0}
{"epoch": 4, "training_loss": 18251.427612304688, "training_acc": 72.0, "val_loss": 3893.783950805664, "val_acc": 72.0}
{"epoch": 5, "training_loss": 12414.928039550781, "training_acc": 73.0, "val_loss": 1716.9811248779297, "val_acc": 56.0}
{"epoch": 6, "training_loss": 8969.54165649414, "training_acc": 51.0, "val_loss": 2754.7576904296875, "val_acc": 60.0}
{"epoch": 7, "training_loss": 9819.684020996094, "training_acc": 51.0, "val_loss": 1837.3600006103516, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8030.024841308594, "training_acc": 72.0, "val_loss": 2624.9887466430664, "val_acc": 72.0}
{"epoch": 9, "training_loss": 8572.14338684082, "training_acc": 73.0, "val_loss": 770.4530239105225, "val_acc": 60.0}
{"epoch": 10, "training_loss": 5957.972686767578, "training_acc": 59.0, "val_loss": 1174.7687339782715, "val_acc": 56.0}
{"epoch": 11, "training_loss": 3976.848129272461, "training_acc": 70.0, "val_loss": 1477.3382186889648, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5397.142333984375, "training_acc": 72.0, "val_loss": 673.834753036499, "val_acc": 76.0}
{"epoch": 13, "training_loss": 3750.3297424316406, "training_acc": 62.0, "val_loss": 999.2282867431641, "val_acc": 52.0}
{"epoch": 14, "training_loss": 3784.781478881836, "training_acc": 52.0, "val_loss": 1048.077392578125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2631.6741485595703, "training_acc": 72.0, "val_loss": 1721.2223052978516, "val_acc": 40.0}
{"epoch": 16, "training_loss": 5204.577728271484, "training_acc": 41.0, "val_loss": 1402.6920318603516, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5679.697158813477, "training_acc": 72.0, "val_loss": 2146.1368560791016, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6849.458587646484, "training_acc": 72.0, "val_loss": 320.79761028289795, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3272.339141845703, "training_acc": 58.0, "val_loss": 399.47667121887207, "val_acc": 68.0}
{"epoch": 20, "training_loss": 2690.776870727539, "training_acc": 71.0, "val_loss": 1457.0959091186523, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4507.985488891602, "training_acc": 72.0, "val_loss": 435.0313186645508, "val_acc": 68.0}
{"epoch": 22, "training_loss": 3523.011444091797, "training_acc": 66.0, "val_loss": 760.894775390625, "val_acc": 60.0}
{"epoch": 23, "training_loss": 2740.331527709961, "training_acc": 69.0, "val_loss": 1478.441333770752, "val_acc": 72.0}
{"epoch": 24, "training_loss": 4566.899169921875, "training_acc": 72.0, "val_loss": 560.1451873779297, "val_acc": 76.0}
{"epoch": 25, "training_loss": 3245.8182678222656, "training_acc": 60.0, "val_loss": 507.93724060058594, "val_acc": 64.0}
{"epoch": 26, "training_loss": 2566.4952545166016, "training_acc": 68.0, "val_loss": 1588.3872032165527, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4267.581169128418, "training_acc": 72.0, "val_loss": 418.04113388061523, "val_acc": 60.0}
{"epoch": 28, "training_loss": 1671.0613174438477, "training_acc": 65.0, "val_loss": 354.9686908721924, "val_acc": 60.0}
{"epoch": 29, "training_loss": 1037.7854385375977, "training_acc": 79.0, "val_loss": 549.2314338684082, "val_acc": 76.0}
{"epoch": 30, "training_loss": 1201.1627807617188, "training_acc": 72.0, "val_loss": 332.210898399353, "val_acc": 64.0}
{"epoch": 31, "training_loss": 536.8277645111084, "training_acc": 81.0, "val_loss": 582.4331760406494, "val_acc": 72.0}
{"epoch": 32, "training_loss": 840.4665412902832, "training_acc": 78.0, "val_loss": 367.3149108886719, "val_acc": 64.0}
{"epoch": 33, "training_loss": 420.19043254852295, "training_acc": 84.0, "val_loss": 387.94054985046387, "val_acc": 72.0}
{"epoch": 34, "training_loss": 911.6561431884766, "training_acc": 71.0, "val_loss": 680.8619976043701, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1044.6842651367188, "training_acc": 76.0, "val_loss": 422.45402336120605, "val_acc": 48.0}
{"epoch": 36, "training_loss": 550.1955757141113, "training_acc": 75.0, "val_loss": 626.5045642852783, "val_acc": 72.0}
{"epoch": 37, "training_loss": 990.7433662414551, "training_acc": 79.0, "val_loss": 502.14738845825195, "val_acc": 48.0}
