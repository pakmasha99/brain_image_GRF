"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 338.97681427001953, "training_acc": 70.0, "val_loss": 193.60520839691162, "val_acc": 72.0}
{"epoch": 1, "training_loss": 583.0194430351257, "training_acc": 72.0, "val_loss": 282.25841522216797, "val_acc": 28.0}
{"epoch": 2, "training_loss": 980.948070526123, "training_acc": 28.0, "val_loss": 22.88111299276352, "val_acc": 56.0}
{"epoch": 3, "training_loss": 154.36805725097656, "training_acc": 74.0, "val_loss": 122.34526872634888, "val_acc": 72.0}
{"epoch": 4, "training_loss": 464.50625801086426, "training_acc": 72.0, "val_loss": 90.92312455177307, "val_acc": 72.0}
{"epoch": 5, "training_loss": 274.84423542022705, "training_acc": 74.0, "val_loss": 58.94984006881714, "val_acc": 56.0}
{"epoch": 6, "training_loss": 280.4655294418335, "training_acc": 55.0, "val_loss": 88.96687626838684, "val_acc": 60.0}
{"epoch": 7, "training_loss": 316.11978912353516, "training_acc": 53.0, "val_loss": 50.1667320728302, "val_acc": 76.0}
{"epoch": 8, "training_loss": 250.171217918396, "training_acc": 73.0, "val_loss": 95.98464965820312, "val_acc": 72.0}
{"epoch": 9, "training_loss": 360.92582511901855, "training_acc": 72.0, "val_loss": 52.89842486381531, "val_acc": 80.0}
{"epoch": 10, "training_loss": 162.39841413497925, "training_acc": 75.0, "val_loss": 68.54769587516785, "val_acc": 60.0}
{"epoch": 11, "training_loss": 308.7984323501587, "training_acc": 49.0, "val_loss": 41.00058674812317, "val_acc": 56.0}
{"epoch": 12, "training_loss": 127.69839334487915, "training_acc": 68.0, "val_loss": 47.667694091796875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 203.0638279914856, "training_acc": 72.0, "val_loss": 41.12595021724701, "val_acc": 72.0}
{"epoch": 14, "training_loss": 153.81173741817474, "training_acc": 71.0, "val_loss": 35.81186532974243, "val_acc": 52.0}
{"epoch": 15, "training_loss": 124.5587887763977, "training_acc": 57.0, "val_loss": 14.372044801712036, "val_acc": 72.0}
{"epoch": 16, "training_loss": 73.25405049324036, "training_acc": 74.0, "val_loss": 30.23838996887207, "val_acc": 72.0}
{"epoch": 17, "training_loss": 88.7940731048584, "training_acc": 75.0, "val_loss": 27.99936532974243, "val_acc": 44.0}
{"epoch": 18, "training_loss": 94.95008397102356, "training_acc": 51.0, "val_loss": 24.75457638502121, "val_acc": 72.0}
{"epoch": 19, "training_loss": 89.1492018699646, "training_acc": 72.0, "val_loss": 22.377337515354156, "val_acc": 72.0}
{"epoch": 20, "training_loss": 68.3584713935852, "training_acc": 69.0, "val_loss": 23.19178134202957, "val_acc": 44.0}
{"epoch": 21, "training_loss": 62.848411321640015, "training_acc": 68.0, "val_loss": 32.93326497077942, "val_acc": 72.0}
{"epoch": 22, "training_loss": 97.25933885574341, "training_acc": 72.0, "val_loss": 15.424169600009918, "val_acc": 68.0}
{"epoch": 23, "training_loss": 67.44972896575928, "training_acc": 69.0, "val_loss": 17.02095717191696, "val_acc": 64.0}
{"epoch": 24, "training_loss": 51.68441939353943, "training_acc": 78.0, "val_loss": 35.45812964439392, "val_acc": 72.0}
{"epoch": 25, "training_loss": 93.20287775993347, "training_acc": 73.0, "val_loss": 16.752879321575165, "val_acc": 60.0}
{"epoch": 26, "training_loss": 56.98641896247864, "training_acc": 73.0, "val_loss": 16.7986661195755, "val_acc": 60.0}
{"epoch": 27, "training_loss": 44.15551793575287, "training_acc": 81.0, "val_loss": 25.701677799224854, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.51871919631958, "training_acc": 76.0, "val_loss": 23.952090740203857, "val_acc": 48.0}
{"epoch": 29, "training_loss": 63.05218589305878, "training_acc": 65.0, "val_loss": 20.718176662921906, "val_acc": 76.0}
{"epoch": 30, "training_loss": 51.019246101379395, "training_acc": 76.0, "val_loss": 16.60369485616684, "val_acc": 64.0}
{"epoch": 31, "training_loss": 55.605231046676636, "training_acc": 74.0, "val_loss": 18.910598754882812, "val_acc": 76.0}
{"epoch": 32, "training_loss": 52.00903868675232, "training_acc": 75.0, "val_loss": 16.84998869895935, "val_acc": 72.0}
{"epoch": 33, "training_loss": 53.142443895339966, "training_acc": 70.0, "val_loss": 15.889105200767517, "val_acc": 68.0}
{"epoch": 34, "training_loss": 40.487428426742554, "training_acc": 79.0, "val_loss": 19.569207727909088, "val_acc": 76.0}
