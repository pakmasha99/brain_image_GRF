"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 353.9011688232422, "training_acc": 49.0, "val_loss": 216.50750637054443, "val_acc": 72.0}
{"epoch": 1, "training_loss": 673.7785987854004, "training_acc": 72.0, "val_loss": 54.93631362915039, "val_acc": 28.0}
{"epoch": 2, "training_loss": 252.07492637634277, "training_acc": 35.0, "val_loss": 43.47756505012512, "val_acc": 72.0}
{"epoch": 3, "training_loss": 202.21388339996338, "training_acc": 72.0, "val_loss": 60.9557569026947, "val_acc": 72.0}
{"epoch": 4, "training_loss": 154.83608388900757, "training_acc": 74.0, "val_loss": 45.91851830482483, "val_acc": 40.0}
{"epoch": 5, "training_loss": 256.7775115966797, "training_acc": 43.0, "val_loss": 28.12749743461609, "val_acc": 72.0}
{"epoch": 6, "training_loss": 109.41462182998657, "training_acc": 74.0, "val_loss": 73.27009439468384, "val_acc": 72.0}
{"epoch": 7, "training_loss": 243.3629035949707, "training_acc": 72.0, "val_loss": 35.69369912147522, "val_acc": 72.0}
{"epoch": 8, "training_loss": 101.76218795776367, "training_acc": 69.0, "val_loss": 43.13490092754364, "val_acc": 40.0}
{"epoch": 9, "training_loss": 166.7960126399994, "training_acc": 57.0, "val_loss": 38.34843337535858, "val_acc": 72.0}
{"epoch": 10, "training_loss": 116.3182692527771, "training_acc": 72.0, "val_loss": 33.4187775850296, "val_acc": 72.0}
{"epoch": 11, "training_loss": 80.54751563072205, "training_acc": 75.0, "val_loss": 27.95339822769165, "val_acc": 48.0}
{"epoch": 12, "training_loss": 103.91492009162903, "training_acc": 52.0, "val_loss": 26.606035232543945, "val_acc": 72.0}
{"epoch": 13, "training_loss": 64.3365707397461, "training_acc": 77.0, "val_loss": 18.744604289531708, "val_acc": 64.0}
{"epoch": 14, "training_loss": 60.6915647983551, "training_acc": 71.0, "val_loss": 22.664591670036316, "val_acc": 72.0}
{"epoch": 15, "training_loss": 66.6490409374237, "training_acc": 72.0, "val_loss": 15.771852433681488, "val_acc": 72.0}
{"epoch": 16, "training_loss": 54.69857096672058, "training_acc": 74.0, "val_loss": 13.726025819778442, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.19255828857422, "training_acc": 69.0, "val_loss": 22.50482141971588, "val_acc": 72.0}
{"epoch": 18, "training_loss": 62.420535922050476, "training_acc": 73.0, "val_loss": 16.10320657491684, "val_acc": 56.0}
{"epoch": 19, "training_loss": 67.23389780521393, "training_acc": 67.0, "val_loss": 18.856599926948547, "val_acc": 72.0}
{"epoch": 20, "training_loss": 49.97802549600601, "training_acc": 79.0, "val_loss": 12.419167906045914, "val_acc": 76.0}
{"epoch": 21, "training_loss": 48.206098198890686, "training_acc": 72.0, "val_loss": 13.644927740097046, "val_acc": 76.0}
{"epoch": 22, "training_loss": 43.111871123313904, "training_acc": 82.0, "val_loss": 13.257475197315216, "val_acc": 76.0}
{"epoch": 23, "training_loss": 38.35036087036133, "training_acc": 85.0, "val_loss": 13.275374472141266, "val_acc": 72.0}
{"epoch": 24, "training_loss": 40.139065742492676, "training_acc": 81.0, "val_loss": 16.025497019290924, "val_acc": 72.0}
{"epoch": 25, "training_loss": 45.06463801860809, "training_acc": 76.0, "val_loss": 13.178953528404236, "val_acc": 68.0}
{"epoch": 26, "training_loss": 39.75448286533356, "training_acc": 83.0, "val_loss": 19.228467345237732, "val_acc": 72.0}
{"epoch": 27, "training_loss": 48.71576535701752, "training_acc": 78.0, "val_loss": 13.767969608306885, "val_acc": 72.0}
{"epoch": 28, "training_loss": 37.183245062828064, "training_acc": 81.0, "val_loss": 14.948506653308868, "val_acc": 72.0}
{"epoch": 29, "training_loss": 36.78062450885773, "training_acc": 83.0, "val_loss": 14.535602927207947, "val_acc": 68.0}
{"epoch": 30, "training_loss": 42.38767087459564, "training_acc": 79.0, "val_loss": 17.551620304584503, "val_acc": 72.0}
{"epoch": 31, "training_loss": 40.74562668800354, "training_acc": 80.0, "val_loss": 14.280334115028381, "val_acc": 68.0}
{"epoch": 32, "training_loss": 38.771828174591064, "training_acc": 83.0, "val_loss": 15.18249362707138, "val_acc": 72.0}
{"epoch": 33, "training_loss": 36.62011671066284, "training_acc": 82.0, "val_loss": 13.552843034267426, "val_acc": 68.0}
{"epoch": 34, "training_loss": 35.71551430225372, "training_acc": 85.0, "val_loss": 13.877421617507935, "val_acc": 68.0}
{"epoch": 35, "training_loss": 35.73876965045929, "training_acc": 88.0, "val_loss": 13.95835280418396, "val_acc": 68.0}
{"epoch": 36, "training_loss": 33.82106697559357, "training_acc": 89.0, "val_loss": 13.524708151817322, "val_acc": 68.0}
{"epoch": 37, "training_loss": 34.911253333091736, "training_acc": 87.0, "val_loss": 13.416394591331482, "val_acc": 68.0}
{"epoch": 38, "training_loss": 32.43772876262665, "training_acc": 85.0, "val_loss": 15.715287625789642, "val_acc": 68.0}
{"epoch": 39, "training_loss": 34.58738815784454, "training_acc": 87.0, "val_loss": 14.181920886039734, "val_acc": 68.0}
