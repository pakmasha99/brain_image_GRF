"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 953.1260986328125, "training_acc": 60.0, "val_loss": 409.0630531311035, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1219.2727661132812, "training_acc": 72.0, "val_loss": 343.5412406921387, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1499.065502166748, "training_acc": 28.0, "val_loss": 65.05582332611084, "val_acc": 68.0}
{"epoch": 3, "training_loss": 373.5413589477539, "training_acc": 67.0, "val_loss": 262.4924659729004, "val_acc": 72.0}
{"epoch": 4, "training_loss": 886.7219581604004, "training_acc": 72.0, "val_loss": 198.90868663787842, "val_acc": 72.0}
{"epoch": 5, "training_loss": 486.19968700408936, "training_acc": 71.0, "val_loss": 106.84940814971924, "val_acc": 60.0}
{"epoch": 6, "training_loss": 572.9134502410889, "training_acc": 58.0, "val_loss": 103.0760407447815, "val_acc": 64.0}
{"epoch": 7, "training_loss": 441.6688289642334, "training_acc": 64.0, "val_loss": 149.95079040527344, "val_acc": 72.0}
{"epoch": 8, "training_loss": 397.2664031982422, "training_acc": 76.0, "val_loss": 114.04250860214233, "val_acc": 72.0}
{"epoch": 9, "training_loss": 313.3213768005371, "training_acc": 67.0, "val_loss": 67.84175038337708, "val_acc": 68.0}
{"epoch": 10, "training_loss": 199.87344408035278, "training_acc": 73.0, "val_loss": 50.96115469932556, "val_acc": 72.0}
{"epoch": 11, "training_loss": 124.4874439239502, "training_acc": 77.0, "val_loss": 27.22638249397278, "val_acc": 64.0}
{"epoch": 12, "training_loss": 83.60128736495972, "training_acc": 64.0, "val_loss": 16.24114364385605, "val_acc": 68.0}
{"epoch": 13, "training_loss": 100.69902181625366, "training_acc": 62.0, "val_loss": 18.939654529094696, "val_acc": 68.0}
{"epoch": 14, "training_loss": 136.95032262802124, "training_acc": 72.0, "val_loss": 25.412237644195557, "val_acc": 36.0}
{"epoch": 15, "training_loss": 135.66453647613525, "training_acc": 59.0, "val_loss": 46.668463945388794, "val_acc": 36.0}
{"epoch": 16, "training_loss": 154.33133697509766, "training_acc": 48.0, "val_loss": 27.259352803230286, "val_acc": 76.0}
{"epoch": 17, "training_loss": 65.21637654304504, "training_acc": 79.0, "val_loss": 36.6122841835022, "val_acc": 68.0}
{"epoch": 18, "training_loss": 162.81430006027222, "training_acc": 67.0, "val_loss": 56.127625703811646, "val_acc": 76.0}
{"epoch": 19, "training_loss": 160.5054669380188, "training_acc": 72.0, "val_loss": 40.8995658159256, "val_acc": 72.0}
{"epoch": 20, "training_loss": 98.59908485412598, "training_acc": 75.0, "val_loss": 51.19403004646301, "val_acc": 76.0}
{"epoch": 21, "training_loss": 88.97846126556396, "training_acc": 78.0, "val_loss": 28.749176859855652, "val_acc": 64.0}
{"epoch": 22, "training_loss": 105.72882270812988, "training_acc": 67.0, "val_loss": 39.47910666465759, "val_acc": 72.0}
{"epoch": 23, "training_loss": 107.4478497505188, "training_acc": 73.0, "val_loss": 31.741973757743835, "val_acc": 40.0}
{"epoch": 24, "training_loss": 92.90365839004517, "training_acc": 61.0, "val_loss": 14.408954977989197, "val_acc": 72.0}
{"epoch": 25, "training_loss": 85.71318054199219, "training_acc": 62.0, "val_loss": 27.789637446403503, "val_acc": 72.0}
{"epoch": 26, "training_loss": 106.95661640167236, "training_acc": 72.0, "val_loss": 31.90714120864868, "val_acc": 36.0}
{"epoch": 27, "training_loss": 99.39085280895233, "training_acc": 62.0, "val_loss": 48.86915981769562, "val_acc": 72.0}
{"epoch": 28, "training_loss": 135.56040048599243, "training_acc": 73.0, "val_loss": 19.97549831867218, "val_acc": 68.0}
{"epoch": 29, "training_loss": 87.45894241333008, "training_acc": 67.0, "val_loss": 40.490591526031494, "val_acc": 76.0}
{"epoch": 30, "training_loss": 122.29004192352295, "training_acc": 78.0, "val_loss": 23.728740215301514, "val_acc": 76.0}
{"epoch": 31, "training_loss": 83.49664831161499, "training_acc": 72.0, "val_loss": 22.55672663450241, "val_acc": 76.0}
{"epoch": 32, "training_loss": 68.8063292503357, "training_acc": 77.0, "val_loss": 36.93731129169464, "val_acc": 72.0}
{"epoch": 33, "training_loss": 103.36688804626465, "training_acc": 62.0, "val_loss": 17.158105969429016, "val_acc": 84.0}
{"epoch": 34, "training_loss": 44.78853440284729, "training_acc": 79.0, "val_loss": 15.985457599163055, "val_acc": 44.0}
{"epoch": 35, "training_loss": 45.565401911735535, "training_acc": 72.0, "val_loss": 23.061835765838623, "val_acc": 76.0}
{"epoch": 36, "training_loss": 64.49456429481506, "training_acc": 70.0, "val_loss": 18.27632337808609, "val_acc": 76.0}
{"epoch": 37, "training_loss": 40.89353585243225, "training_acc": 83.0, "val_loss": 24.398532509803772, "val_acc": 48.0}
{"epoch": 38, "training_loss": 103.15683674812317, "training_acc": 60.0, "val_loss": 23.639672994613647, "val_acc": 76.0}
{"epoch": 39, "training_loss": 75.44909429550171, "training_acc": 67.0, "val_loss": 25.307223200798035, "val_acc": 76.0}
{"epoch": 40, "training_loss": 51.70268499851227, "training_acc": 81.0, "val_loss": 15.693125128746033, "val_acc": 80.0}
{"epoch": 41, "training_loss": 28.470136523246765, "training_acc": 90.0, "val_loss": 13.657855987548828, "val_acc": 84.0}
{"epoch": 42, "training_loss": 58.60239505767822, "training_acc": 80.0, "val_loss": 17.239147424697876, "val_acc": 84.0}
{"epoch": 43, "training_loss": 57.40564250946045, "training_acc": 71.0, "val_loss": 34.35353338718414, "val_acc": 72.0}
{"epoch": 44, "training_loss": 94.64797139167786, "training_acc": 74.0, "val_loss": 15.329152345657349, "val_acc": 64.0}
{"epoch": 45, "training_loss": 53.95635437965393, "training_acc": 75.0, "val_loss": 35.460785031318665, "val_acc": 76.0}
{"epoch": 46, "training_loss": 76.12232565879822, "training_acc": 79.0, "val_loss": 16.979393362998962, "val_acc": 68.0}
{"epoch": 47, "training_loss": 53.47117102146149, "training_acc": 76.0, "val_loss": 36.04908585548401, "val_acc": 76.0}
{"epoch": 48, "training_loss": 66.5829873085022, "training_acc": 79.0, "val_loss": 20.439881086349487, "val_acc": 56.0}
{"epoch": 49, "training_loss": 66.1278589963913, "training_acc": 73.0, "val_loss": 29.74923849105835, "val_acc": 76.0}
{"epoch": 50, "training_loss": 39.40212607383728, "training_acc": 84.0, "val_loss": 26.43941640853882, "val_acc": 36.0}
{"epoch": 51, "training_loss": 99.03139567375183, "training_acc": 66.0, "val_loss": 36.537277698516846, "val_acc": 72.0}
{"epoch": 52, "training_loss": 65.96321475505829, "training_acc": 78.0, "val_loss": 15.373551845550537, "val_acc": 72.0}
{"epoch": 53, "training_loss": 66.81058835983276, "training_acc": 72.0, "val_loss": 46.41388654708862, "val_acc": 72.0}
{"epoch": 54, "training_loss": 66.80774188041687, "training_acc": 78.0, "val_loss": 86.02591753005981, "val_acc": 28.0}
{"epoch": 55, "training_loss": 245.5914386510849, "training_acc": 52.0, "val_loss": 60.692012310028076, "val_acc": 72.0}
{"epoch": 56, "training_loss": 164.4632544517517, "training_acc": 73.0, "val_loss": 21.306607127189636, "val_acc": 76.0}
{"epoch": 57, "training_loss": 82.49680042266846, "training_acc": 75.0, "val_loss": 28.18361222743988, "val_acc": 80.0}
{"epoch": 58, "training_loss": 57.10279583930969, "training_acc": 83.0, "val_loss": 28.267741203308105, "val_acc": 80.0}
{"epoch": 59, "training_loss": 72.84895372390747, "training_acc": 74.0, "val_loss": 24.381618201732635, "val_acc": 80.0}
{"epoch": 60, "training_loss": 46.68929314613342, "training_acc": 81.0, "val_loss": 13.30830603837967, "val_acc": 80.0}
{"epoch": 61, "training_loss": 26.637510776519775, "training_acc": 86.0, "val_loss": 15.205979347229004, "val_acc": 88.0}
{"epoch": 62, "training_loss": 31.25017476081848, "training_acc": 88.0, "val_loss": 18.586227297782898, "val_acc": 48.0}
{"epoch": 63, "training_loss": 47.23301565647125, "training_acc": 75.0, "val_loss": 12.931005656719208, "val_acc": 76.0}
{"epoch": 64, "training_loss": 24.292514622211456, "training_acc": 92.0, "val_loss": 17.085736989974976, "val_acc": 88.0}
{"epoch": 65, "training_loss": 26.80220115184784, "training_acc": 92.0, "val_loss": 21.314890682697296, "val_acc": 56.0}
{"epoch": 66, "training_loss": 61.05282986164093, "training_acc": 72.0, "val_loss": 32.31661021709442, "val_acc": 76.0}
{"epoch": 67, "training_loss": 35.08345425128937, "training_acc": 85.0, "val_loss": 21.531860530376434, "val_acc": 60.0}
{"epoch": 68, "training_loss": 69.71547877788544, "training_acc": 69.0, "val_loss": 26.96404457092285, "val_acc": 76.0}
{"epoch": 69, "training_loss": 50.26135778427124, "training_acc": 77.0, "val_loss": 17.371000349521637, "val_acc": 84.0}
{"epoch": 70, "training_loss": 28.538917064666748, "training_acc": 88.0, "val_loss": 15.803678333759308, "val_acc": 76.0}
{"epoch": 71, "training_loss": 32.83737599849701, "training_acc": 85.0, "val_loss": 27.68479585647583, "val_acc": 76.0}
{"epoch": 72, "training_loss": 37.932365238666534, "training_acc": 81.0, "val_loss": 15.402133762836456, "val_acc": 80.0}
{"epoch": 73, "training_loss": 25.81836497783661, "training_acc": 86.0, "val_loss": 18.133248388767242, "val_acc": 84.0}
{"epoch": 74, "training_loss": 28.852121710777283, "training_acc": 88.0, "val_loss": 17.89991855621338, "val_acc": 84.0}
{"epoch": 75, "training_loss": 19.63730949163437, "training_acc": 92.0, "val_loss": 15.374740958213806, "val_acc": 80.0}
{"epoch": 76, "training_loss": 15.458480894565582, "training_acc": 96.0, "val_loss": 15.979388356208801, "val_acc": 80.0}
{"epoch": 77, "training_loss": 15.219032049179077, "training_acc": 95.0, "val_loss": 17.645995318889618, "val_acc": 88.0}
{"epoch": 78, "training_loss": 16.454976201057434, "training_acc": 92.0, "val_loss": 15.463076531887054, "val_acc": 80.0}
{"epoch": 79, "training_loss": 19.31385499238968, "training_acc": 92.0, "val_loss": 14.14579451084137, "val_acc": 76.0}
{"epoch": 80, "training_loss": 16.023266673088074, "training_acc": 95.0, "val_loss": 14.169420301914215, "val_acc": 80.0}
{"epoch": 81, "training_loss": 23.100239396095276, "training_acc": 93.0, "val_loss": 17.31940656900406, "val_acc": 88.0}
{"epoch": 82, "training_loss": 22.162229537963867, "training_acc": 89.0, "val_loss": 20.09817510843277, "val_acc": 84.0}
