"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 560611.9064292908, "training_acc": 72.0, "val_loss": 26553.912353515625, "val_acc": 72.0}
{"epoch": 1, "training_loss": 129868.7705078125, "training_acc": 62.0, "val_loss": 131061.85302734375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 421807.5909423828, "training_acc": 72.0, "val_loss": 208439.7216796875, "val_acc": 28.0}
{"epoch": 3, "training_loss": 586384.859375, "training_acc": 32.0, "val_loss": 175218.798828125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 980052.125, "training_acc": 72.0, "val_loss": 261387.939453125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 811936.28125, "training_acc": 72.0, "val_loss": 6745.826721191406, "val_acc": 28.0}
{"epoch": 6, "training_loss": 92036.21826171875, "training_acc": 48.0, "val_loss": 32662.380981445312, "val_acc": 72.0}
{"epoch": 7, "training_loss": 139207.10546875, "training_acc": 58.0, "val_loss": 60757.7392578125, "val_acc": 72.0}
{"epoch": 8, "training_loss": 443603.703125, "training_acc": 72.0, "val_loss": 111976.8310546875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 300795.5595703125, "training_acc": 52.0, "val_loss": 17303.863525390625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 140375.5302734375, "training_acc": 72.0, "val_loss": 946.1295127868652, "val_acc": 64.0}
{"epoch": 11, "training_loss": 171588.95944213867, "training_acc": 45.0, "val_loss": 53825.653076171875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 153609.943359375, "training_acc": 72.0, "val_loss": 33549.96337890625, "val_acc": 28.0}
{"epoch": 13, "training_loss": 100474.283203125, "training_acc": 62.0, "val_loss": 31119.070434570312, "val_acc": 72.0}
{"epoch": 14, "training_loss": 116344.39697265625, "training_acc": 54.0, "val_loss": 60457.763671875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 330429.07421875, "training_acc": 72.0, "val_loss": 101850.1708984375, "val_acc": 72.0}
{"epoch": 16, "training_loss": 257420.900390625, "training_acc": 72.0, "val_loss": 173562.2314453125, "val_acc": 28.0}
{"epoch": 17, "training_loss": 394573.775390625, "training_acc": 44.0, "val_loss": 85249.02954101562, "val_acc": 72.0}
{"epoch": 18, "training_loss": 374022.5625, "training_acc": 72.0, "val_loss": 52852.862548828125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 238232.94140625, "training_acc": 52.0, "val_loss": 15694.100952148438, "val_acc": 72.0}
{"epoch": 20, "training_loss": 160146.97509765625, "training_acc": 72.0, "val_loss": 40422.320556640625, "val_acc": 72.0}
{"epoch": 21, "training_loss": 212089.32958984375, "training_acc": 56.0, "val_loss": 4025.8216857910156, "val_acc": 72.0}
{"epoch": 22, "training_loss": 94055.36547851562, "training_acc": 74.0, "val_loss": 17610.870361328125, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61339.73260498047, "training_acc": 59.0, "val_loss": 4080.2146911621094, "val_acc": 60.0}
{"epoch": 24, "training_loss": 18003.671630859375, "training_acc": 72.0, "val_loss": 55577.471923828125, "val_acc": 28.0}
{"epoch": 25, "training_loss": 111888.69580078125, "training_acc": 54.0, "val_loss": 40502.86560058594, "val_acc": 28.0}
{"epoch": 26, "training_loss": 106538.86010742188, "training_acc": 50.0, "val_loss": 22097.314453125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 75285.18264770508, "training_acc": 69.0, "val_loss": 27564.31884765625, "val_acc": 72.0}
{"epoch": 28, "training_loss": 131369.79443359375, "training_acc": 72.0, "val_loss": 56365.313720703125, "val_acc": 28.0}
{"epoch": 29, "training_loss": 184425.419921875, "training_acc": 44.0, "val_loss": 67347.34497070312, "val_acc": 72.0}
