"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 747996.5963287354, "training_acc": 54.0, "val_loss": 96869.68383789062, "val_acc": 28.0}
{"epoch": 1, "training_loss": 345621.96875, "training_acc": 40.0, "val_loss": 68374.20043945312, "val_acc": 72.0}
{"epoch": 2, "training_loss": 360637.451171875, "training_acc": 50.0, "val_loss": 33823.22082519531, "val_acc": 28.0}
{"epoch": 3, "training_loss": 367416.302734375, "training_acc": 54.0, "val_loss": 187691.30859375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 708128.10546875, "training_acc": 72.0, "val_loss": 72630.37109375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 240297.22778320312, "training_acc": 38.0, "val_loss": 64891.6259765625, "val_acc": 72.0}
{"epoch": 6, "training_loss": 442532.4140625, "training_acc": 72.0, "val_loss": 156551.11083984375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 541332.3515625, "training_acc": 72.0, "val_loss": 14703.485107421875, "val_acc": 72.0}
{"epoch": 8, "training_loss": 322636.5642089844, "training_acc": 40.0, "val_loss": 36206.93359375, "val_acc": 72.0}
{"epoch": 9, "training_loss": 211840.359375, "training_acc": 72.0, "val_loss": 46769.73571777344, "val_acc": 72.0}
{"epoch": 10, "training_loss": 129490.50012207031, "training_acc": 56.0, "val_loss": 32005.264282226562, "val_acc": 72.0}
{"epoch": 11, "training_loss": 184485.64306640625, "training_acc": 72.0, "val_loss": 3714.3348693847656, "val_acc": 72.0}
{"epoch": 12, "training_loss": 349263.12463378906, "training_acc": 32.0, "val_loss": 76060.33935546875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 483910.98046875, "training_acc": 72.0, "val_loss": 179598.05908203125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 639436.52734375, "training_acc": 72.0, "val_loss": 47172.96447753906, "val_acc": 72.0}
{"epoch": 15, "training_loss": 194176.05113601685, "training_acc": 45.0, "val_loss": 36024.20349121094, "val_acc": 72.0}
{"epoch": 16, "training_loss": 209331.2578125, "training_acc": 72.0, "val_loss": 26699.508666992188, "val_acc": 72.0}
{"epoch": 17, "training_loss": 62597.65203857422, "training_acc": 66.0, "val_loss": 12481.511688232422, "val_acc": 72.0}
{"epoch": 18, "training_loss": 61913.0205078125, "training_acc": 66.0, "val_loss": 19153.805541992188, "val_acc": 72.0}
{"epoch": 19, "training_loss": 84683.697265625, "training_acc": 50.0, "val_loss": 16990.682983398438, "val_acc": 72.0}
{"epoch": 20, "training_loss": 53335.1337890625, "training_acc": 59.0, "val_loss": 10406.937408447266, "val_acc": 72.0}
{"epoch": 21, "training_loss": 68050.71069335938, "training_acc": 56.0, "val_loss": 33402.89001464844, "val_acc": 28.0}
{"epoch": 22, "training_loss": 61737.48498535156, "training_acc": 62.0, "val_loss": 12933.653259277344, "val_acc": 28.0}
{"epoch": 23, "training_loss": 76579.52001953125, "training_acc": 66.0, "val_loss": 12714.852905273438, "val_acc": 72.0}
{"epoch": 24, "training_loss": 110842.234375, "training_acc": 42.0, "val_loss": 81413.0126953125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 344861.2978515625, "training_acc": 72.0, "val_loss": 37653.25012207031, "val_acc": 72.0}
{"epoch": 26, "training_loss": 82755.55859375, "training_acc": 46.0, "val_loss": 60457.33642578125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 233631.703125, "training_acc": 72.0, "val_loss": 3910.19287109375, "val_acc": 56.0}
{"epoch": 28, "training_loss": 80473.1005859375, "training_acc": 50.0, "val_loss": 72500.6103515625, "val_acc": 72.0}
{"epoch": 29, "training_loss": 222845.3671875, "training_acc": 73.0, "val_loss": 88526.15356445312, "val_acc": 28.0}
{"epoch": 30, "training_loss": 213150.31689453125, "training_acc": 50.0, "val_loss": 65885.78491210938, "val_acc": 72.0}
