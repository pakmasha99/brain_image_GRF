"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 771121.3800754547, "training_acc": 56.0, "val_loss": 38854.42199707031, "val_acc": 72.0}
{"epoch": 1, "training_loss": 537055.6796875, "training_acc": 50.0, "val_loss": 136491.9677734375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 722104.9453125, "training_acc": 72.0, "val_loss": 115666.650390625, "val_acc": 72.0}
{"epoch": 3, "training_loss": 421372.341796875, "training_acc": 60.0, "val_loss": 164708.09326171875, "val_acc": 28.0}
{"epoch": 4, "training_loss": 258501.126953125, "training_acc": 62.0, "val_loss": 86679.94995117188, "val_acc": 72.0}
{"epoch": 5, "training_loss": 293482.6101074219, "training_acc": 68.0, "val_loss": 27450.494384765625, "val_acc": 72.0}
{"epoch": 6, "training_loss": 118340.79364013672, "training_acc": 70.0, "val_loss": 20988.33770751953, "val_acc": 72.0}
{"epoch": 7, "training_loss": 78162.20703125, "training_acc": 70.0, "val_loss": 19011.656188964844, "val_acc": 28.0}
{"epoch": 8, "training_loss": 265625.1962890625, "training_acc": 52.0, "val_loss": 109500.1953125, "val_acc": 72.0}
{"epoch": 9, "training_loss": 340368.7546386719, "training_acc": 68.0, "val_loss": 12120.177459716797, "val_acc": 72.0}
{"epoch": 10, "training_loss": 61163.67578125, "training_acc": 56.0, "val_loss": 26246.868896484375, "val_acc": 72.0}
{"epoch": 11, "training_loss": 88901.55688476562, "training_acc": 58.0, "val_loss": 13013.113403320312, "val_acc": 72.0}
{"epoch": 12, "training_loss": 43228.9580078125, "training_acc": 61.0, "val_loss": 26980.279541015625, "val_acc": 72.0}
{"epoch": 13, "training_loss": 97681.30261230469, "training_acc": 58.0, "val_loss": 54312.615966796875, "val_acc": 72.0}
{"epoch": 14, "training_loss": 363111.0703125, "training_acc": 72.0, "val_loss": 88739.84985351562, "val_acc": 72.0}
{"epoch": 15, "training_loss": 202984.2138671875, "training_acc": 70.0, "val_loss": 145409.1552734375, "val_acc": 28.0}
{"epoch": 16, "training_loss": 350790.171875, "training_acc": 44.0, "val_loss": 121254.736328125, "val_acc": 72.0}
{"epoch": 17, "training_loss": 431971.515625, "training_acc": 72.0, "val_loss": 15009.107971191406, "val_acc": 72.0}
{"epoch": 18, "training_loss": 289763.5341796875, "training_acc": 46.0, "val_loss": 71289.208984375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 570643.234375, "training_acc": 72.0, "val_loss": 192568.98193359375, "val_acc": 72.0}
{"epoch": 20, "training_loss": 611720.31640625, "training_acc": 72.0, "val_loss": 3243.593978881836, "val_acc": 52.0}
{"epoch": 21, "training_loss": 227420.2138671875, "training_acc": 35.0, "val_loss": 38081.91223144531, "val_acc": 72.0}
{"epoch": 22, "training_loss": 123153.09301757812, "training_acc": 70.0, "val_loss": 5249.480819702148, "val_acc": 76.0}
{"epoch": 23, "training_loss": 39515.51965332031, "training_acc": 63.0, "val_loss": 27836.090087890625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 90841.814453125, "training_acc": 54.0, "val_loss": 30052.334594726562, "val_acc": 72.0}
{"epoch": 25, "training_loss": 98944.8359375, "training_acc": 72.0, "val_loss": 6260.406112670898, "val_acc": 40.0}
{"epoch": 26, "training_loss": 113283.56982421875, "training_acc": 63.0, "val_loss": 34983.551025390625, "val_acc": 72.0}
{"epoch": 27, "training_loss": 153683.71533203125, "training_acc": 58.0, "val_loss": 5092.302703857422, "val_acc": 72.0}
{"epoch": 28, "training_loss": 73867.02978515625, "training_acc": 74.0, "val_loss": 7503.6041259765625, "val_acc": 72.0}
{"epoch": 29, "training_loss": 71086.96875, "training_acc": 60.0, "val_loss": 54395.64208984375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 231838.08984375, "training_acc": 72.0, "val_loss": 3846.518325805664, "val_acc": 76.0}
{"epoch": 31, "training_loss": 53683.57958984375, "training_acc": 57.0, "val_loss": 11224.423217773438, "val_acc": 72.0}
{"epoch": 32, "training_loss": 109943.765625, "training_acc": 46.0, "val_loss": 78391.71752929688, "val_acc": 72.0}
{"epoch": 33, "training_loss": 315088.44140625, "training_acc": 72.0, "val_loss": 16721.78497314453, "val_acc": 72.0}
{"epoch": 34, "training_loss": 329056.244140625, "training_acc": 44.0, "val_loss": 56339.825439453125, "val_acc": 72.0}
{"epoch": 35, "training_loss": 415386.9765625, "training_acc": 72.0, "val_loss": 154892.19970703125, "val_acc": 72.0}
{"epoch": 36, "training_loss": 532012.6669921875, "training_acc": 72.0, "val_loss": 18905.078125, "val_acc": 72.0}
{"epoch": 37, "training_loss": 351004.0283203125, "training_acc": 44.0, "val_loss": 56242.962646484375, "val_acc": 72.0}
{"epoch": 38, "training_loss": 384154.935546875, "training_acc": 72.0, "val_loss": 164131.50634765625, "val_acc": 72.0}
{"epoch": 39, "training_loss": 540556.5439453125, "training_acc": 72.0, "val_loss": 12740.813446044922, "val_acc": 72.0}
