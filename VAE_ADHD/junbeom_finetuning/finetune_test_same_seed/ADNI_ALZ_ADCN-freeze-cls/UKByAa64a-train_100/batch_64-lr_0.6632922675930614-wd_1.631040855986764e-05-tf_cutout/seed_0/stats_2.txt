"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1041.158203125, "training_acc": 64.0, "val_loss": 499.20105934143066, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1617.049892425537, "training_acc": 72.0, "val_loss": 620.0728416442871, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2569.147392272949, "training_acc": 30.0, "val_loss": 79.2877197265625, "val_acc": 68.0}
{"epoch": 3, "training_loss": 620.7741355895996, "training_acc": 68.0, "val_loss": 419.77500915527344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1625.2058944702148, "training_acc": 72.0, "val_loss": 442.49138832092285, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1457.7197799682617, "training_acc": 72.0, "val_loss": 195.95568180084229, "val_acc": 76.0}
{"epoch": 6, "training_loss": 526.8125915527344, "training_acc": 73.0, "val_loss": 192.78711080551147, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1088.776704788208, "training_acc": 53.0, "val_loss": 121.42423391342163, "val_acc": 68.0}
{"epoch": 8, "training_loss": 475.0941171646118, "training_acc": 71.0, "val_loss": 210.07592678070068, "val_acc": 72.0}
{"epoch": 9, "training_loss": 731.8293647766113, "training_acc": 73.0, "val_loss": 223.96271228790283, "val_acc": 72.0}
{"epoch": 10, "training_loss": 518.9178524017334, "training_acc": 72.0, "val_loss": 92.07298159599304, "val_acc": 72.0}
{"epoch": 11, "training_loss": 658.1011390686035, "training_acc": 61.0, "val_loss": 122.194504737854, "val_acc": 48.0}
{"epoch": 12, "training_loss": 434.7609233856201, "training_acc": 58.0, "val_loss": 135.4251265525818, "val_acc": 72.0}
{"epoch": 13, "training_loss": 439.6146945953369, "training_acc": 72.0, "val_loss": 141.49093627929688, "val_acc": 72.0}
{"epoch": 14, "training_loss": 321.77487802505493, "training_acc": 74.0, "val_loss": 97.91322946548462, "val_acc": 36.0}
{"epoch": 15, "training_loss": 435.01981925964355, "training_acc": 43.0, "val_loss": 63.95663022994995, "val_acc": 72.0}
{"epoch": 16, "training_loss": 223.15383434295654, "training_acc": 73.0, "val_loss": 122.86086082458496, "val_acc": 72.0}
{"epoch": 17, "training_loss": 324.7629098892212, "training_acc": 72.0, "val_loss": 60.898154973983765, "val_acc": 48.0}
{"epoch": 18, "training_loss": 296.68445777893066, "training_acc": 52.0, "val_loss": 45.42328119277954, "val_acc": 72.0}
{"epoch": 19, "training_loss": 123.4866738319397, "training_acc": 79.0, "val_loss": 102.41538286209106, "val_acc": 72.0}
{"epoch": 20, "training_loss": 230.78863716125488, "training_acc": 76.0, "val_loss": 44.42168474197388, "val_acc": 76.0}
{"epoch": 21, "training_loss": 166.50020933151245, "training_acc": 70.0, "val_loss": 40.89365601539612, "val_acc": 76.0}
{"epoch": 22, "training_loss": 116.98299264907837, "training_acc": 76.0, "val_loss": 61.944204568862915, "val_acc": 72.0}
{"epoch": 23, "training_loss": 109.92099237442017, "training_acc": 79.0, "val_loss": 41.193655133247375, "val_acc": 48.0}
{"epoch": 24, "training_loss": 122.4665298461914, "training_acc": 63.0, "val_loss": 65.79470634460449, "val_acc": 72.0}
{"epoch": 25, "training_loss": 217.49123096466064, "training_acc": 72.0, "val_loss": 28.784701228141785, "val_acc": 72.0}
{"epoch": 26, "training_loss": 159.99996948242188, "training_acc": 63.0, "val_loss": 19.779184460639954, "val_acc": 60.0}
{"epoch": 27, "training_loss": 91.60122156143188, "training_acc": 81.0, "val_loss": 96.94387316703796, "val_acc": 72.0}
{"epoch": 28, "training_loss": 253.21500253677368, "training_acc": 72.0, "val_loss": 36.47308349609375, "val_acc": 56.0}
{"epoch": 29, "training_loss": 165.24920749664307, "training_acc": 55.0, "val_loss": 41.455018520355225, "val_acc": 72.0}
{"epoch": 30, "training_loss": 121.07856035232544, "training_acc": 79.0, "val_loss": 50.7396399974823, "val_acc": 76.0}
{"epoch": 31, "training_loss": 104.25504541397095, "training_acc": 79.0, "val_loss": 39.46196138858795, "val_acc": 60.0}
{"epoch": 32, "training_loss": 155.7311978340149, "training_acc": 66.0, "val_loss": 47.75291979312897, "val_acc": 76.0}
{"epoch": 33, "training_loss": 96.63150906562805, "training_acc": 80.0, "val_loss": 23.25778901576996, "val_acc": 64.0}
{"epoch": 34, "training_loss": 66.55969619750977, "training_acc": 72.0, "val_loss": 48.17532300949097, "val_acc": 72.0}
{"epoch": 35, "training_loss": 115.634681224823, "training_acc": 74.0, "val_loss": 33.59117805957794, "val_acc": 56.0}
{"epoch": 36, "training_loss": 75.80138432979584, "training_acc": 68.0, "val_loss": 48.13803732395172, "val_acc": 72.0}
{"epoch": 37, "training_loss": 103.62518382072449, "training_acc": 75.0, "val_loss": 29.07516658306122, "val_acc": 60.0}
{"epoch": 38, "training_loss": 67.43444520235062, "training_acc": 71.0, "val_loss": 25.992372632026672, "val_acc": 68.0}
{"epoch": 39, "training_loss": 37.35386919975281, "training_acc": 83.0, "val_loss": 22.24152833223343, "val_acc": 68.0}
{"epoch": 40, "training_loss": 56.98538935184479, "training_acc": 78.0, "val_loss": 34.04582142829895, "val_acc": 72.0}
{"epoch": 41, "training_loss": 52.73524725437164, "training_acc": 85.0, "val_loss": 24.571919441223145, "val_acc": 64.0}
{"epoch": 42, "training_loss": 61.637991309165955, "training_acc": 75.0, "val_loss": 34.298887848854065, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.5718777179718, "training_acc": 82.0, "val_loss": 50.996577739715576, "val_acc": 44.0}
{"epoch": 44, "training_loss": 181.52670288085938, "training_acc": 49.0, "val_loss": 46.8930721282959, "val_acc": 72.0}
{"epoch": 45, "training_loss": 92.17269229888916, "training_acc": 73.0, "val_loss": 37.19842731952667, "val_acc": 48.0}
