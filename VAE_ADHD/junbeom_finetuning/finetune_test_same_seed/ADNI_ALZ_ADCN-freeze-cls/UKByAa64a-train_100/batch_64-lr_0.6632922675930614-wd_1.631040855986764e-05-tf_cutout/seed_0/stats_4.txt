"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1206.1410903930664, "training_acc": 72.0, "val_loss": 468.45688819885254, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1321.4277439117432, "training_acc": 72.0, "val_loss": 617.5183773040771, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2714.9896392822266, "training_acc": 29.0, "val_loss": 103.93580198287964, "val_acc": 48.0}
{"epoch": 3, "training_loss": 571.586238861084, "training_acc": 62.0, "val_loss": 403.7843704223633, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1435.3884811401367, "training_acc": 72.0, "val_loss": 467.51089096069336, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1528.771583557129, "training_acc": 72.0, "val_loss": 291.75660610198975, "val_acc": 72.0}
{"epoch": 6, "training_loss": 584.1296329498291, "training_acc": 75.0, "val_loss": 168.50450038909912, "val_acc": 64.0}
{"epoch": 7, "training_loss": 1057.8635902404785, "training_acc": 54.0, "val_loss": 241.97709560394287, "val_acc": 52.0}
{"epoch": 8, "training_loss": 1113.0024490356445, "training_acc": 54.0, "val_loss": 167.87710189819336, "val_acc": 72.0}
{"epoch": 9, "training_loss": 571.7691974639893, "training_acc": 76.0, "val_loss": 361.09488010406494, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1113.3099098205566, "training_acc": 72.0, "val_loss": 362.89656162261963, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1028.1780738830566, "training_acc": 72.0, "val_loss": 158.53644609451294, "val_acc": 76.0}
{"epoch": 12, "training_loss": 534.9741687774658, "training_acc": 65.0, "val_loss": 134.7541332244873, "val_acc": 64.0}
{"epoch": 13, "training_loss": 665.3470230102539, "training_acc": 58.0, "val_loss": 124.82850551605225, "val_acc": 76.0}
{"epoch": 14, "training_loss": 446.4577579498291, "training_acc": 68.0, "val_loss": 216.46645069122314, "val_acc": 72.0}
{"epoch": 15, "training_loss": 612.3608074188232, "training_acc": 72.0, "val_loss": 87.19521760940552, "val_acc": 76.0}
{"epoch": 16, "training_loss": 247.0339069366455, "training_acc": 70.0, "val_loss": 79.20371890068054, "val_acc": 56.0}
{"epoch": 17, "training_loss": 315.5338454246521, "training_acc": 57.0, "val_loss": 81.5876305103302, "val_acc": 72.0}
{"epoch": 18, "training_loss": 355.7836284637451, "training_acc": 72.0, "val_loss": 41.31946861743927, "val_acc": 72.0}
{"epoch": 19, "training_loss": 338.20627784729004, "training_acc": 54.0, "val_loss": 91.81134700775146, "val_acc": 28.0}
{"epoch": 20, "training_loss": 283.6910037994385, "training_acc": 54.0, "val_loss": 145.47356367111206, "val_acc": 72.0}
{"epoch": 21, "training_loss": 630.4851779937744, "training_acc": 72.0, "val_loss": 122.6146936416626, "val_acc": 72.0}
{"epoch": 22, "training_loss": 373.42403841018677, "training_acc": 72.0, "val_loss": 151.85786485671997, "val_acc": 32.0}
{"epoch": 23, "training_loss": 619.489086151123, "training_acc": 32.0, "val_loss": 43.10961067676544, "val_acc": 76.0}
{"epoch": 24, "training_loss": 239.82658004760742, "training_acc": 73.0, "val_loss": 171.44023180007935, "val_acc": 72.0}
{"epoch": 25, "training_loss": 550.765905380249, "training_acc": 72.0, "val_loss": 87.81750798225403, "val_acc": 72.0}
{"epoch": 26, "training_loss": 244.60315132141113, "training_acc": 75.0, "val_loss": 81.33634924888611, "val_acc": 64.0}
{"epoch": 27, "training_loss": 346.8343424797058, "training_acc": 58.0, "val_loss": 75.47275424003601, "val_acc": 76.0}
{"epoch": 28, "training_loss": 205.31734466552734, "training_acc": 75.0, "val_loss": 97.26377725601196, "val_acc": 76.0}
{"epoch": 29, "training_loss": 202.66528511047363, "training_acc": 76.0, "val_loss": 50.440746545791626, "val_acc": 68.0}
{"epoch": 30, "training_loss": 210.46816730499268, "training_acc": 66.0, "val_loss": 41.13493263721466, "val_acc": 68.0}
{"epoch": 31, "training_loss": 179.2347068786621, "training_acc": 68.0, "val_loss": 54.2266845703125, "val_acc": 76.0}
{"epoch": 32, "training_loss": 125.66029119491577, "training_acc": 79.0, "val_loss": 40.937820076942444, "val_acc": 52.0}
{"epoch": 33, "training_loss": 152.01043844223022, "training_acc": 60.0, "val_loss": 52.30867862701416, "val_acc": 72.0}
{"epoch": 34, "training_loss": 251.80099201202393, "training_acc": 72.0, "val_loss": 28.418946266174316, "val_acc": 72.0}
{"epoch": 35, "training_loss": 255.78115844726562, "training_acc": 57.0, "val_loss": 32.836729288101196, "val_acc": 52.0}
{"epoch": 36, "training_loss": 154.48486232757568, "training_acc": 63.0, "val_loss": 104.35134172439575, "val_acc": 72.0}
{"epoch": 37, "training_loss": 354.3363676071167, "training_acc": 72.0, "val_loss": 24.60138648748398, "val_acc": 80.0}
{"epoch": 38, "training_loss": 120.57783603668213, "training_acc": 74.0, "val_loss": 53.83341312408447, "val_acc": 52.0}
{"epoch": 39, "training_loss": 249.65628290176392, "training_acc": 62.0, "val_loss": 99.65479969978333, "val_acc": 72.0}
{"epoch": 40, "training_loss": 292.280481338501, "training_acc": 74.0, "val_loss": 55.576103925704956, "val_acc": 76.0}
{"epoch": 41, "training_loss": 203.46973514556885, "training_acc": 70.0, "val_loss": 48.41793477535248, "val_acc": 64.0}
{"epoch": 42, "training_loss": 221.6583490371704, "training_acc": 68.0, "val_loss": 84.3795120716095, "val_acc": 72.0}
{"epoch": 43, "training_loss": 238.43943881988525, "training_acc": 77.0, "val_loss": 56.42408728599548, "val_acc": 76.0}
{"epoch": 44, "training_loss": 123.87137460708618, "training_acc": 75.0, "val_loss": 60.00555157661438, "val_acc": 44.0}
{"epoch": 45, "training_loss": 214.91420602798462, "training_acc": 67.0, "val_loss": 57.13808536529541, "val_acc": 72.0}
{"epoch": 46, "training_loss": 169.320330619812, "training_acc": 76.0, "val_loss": 18.26220601797104, "val_acc": 84.0}
{"epoch": 47, "training_loss": 107.65451717376709, "training_acc": 74.0, "val_loss": 10.92347502708435, "val_acc": 68.0}
{"epoch": 48, "training_loss": 64.05597877502441, "training_acc": 82.0, "val_loss": 29.15867269039154, "val_acc": 72.0}
{"epoch": 49, "training_loss": 99.04392671585083, "training_acc": 69.0, "val_loss": 10.345973819494247, "val_acc": 76.0}
{"epoch": 50, "training_loss": 57.458579301834106, "training_acc": 81.0, "val_loss": 20.98132222890854, "val_acc": 84.0}
{"epoch": 51, "training_loss": 92.93590068817139, "training_acc": 74.0, "val_loss": 19.995136559009552, "val_acc": 84.0}
{"epoch": 52, "training_loss": 46.00297474861145, "training_acc": 85.0, "val_loss": 17.685633897781372, "val_acc": 84.0}
{"epoch": 53, "training_loss": 37.372010231018066, "training_acc": 85.0, "val_loss": 13.860583305358887, "val_acc": 68.0}
{"epoch": 54, "training_loss": 57.1899254322052, "training_acc": 77.0, "val_loss": 39.30734097957611, "val_acc": 76.0}
{"epoch": 55, "training_loss": 63.36317265033722, "training_acc": 81.0, "val_loss": 19.34056282043457, "val_acc": 56.0}
{"epoch": 56, "training_loss": 92.09218311309814, "training_acc": 66.0, "val_loss": 21.994605660438538, "val_acc": 84.0}
{"epoch": 57, "training_loss": 21.638912439346313, "training_acc": 91.0, "val_loss": 17.29026436805725, "val_acc": 68.0}
{"epoch": 58, "training_loss": 38.99153697490692, "training_acc": 84.0, "val_loss": 24.773433804512024, "val_acc": 84.0}
{"epoch": 59, "training_loss": 53.177364349365234, "training_acc": 80.0, "val_loss": 16.74749106168747, "val_acc": 68.0}
{"epoch": 60, "training_loss": 33.62573277950287, "training_acc": 87.0, "val_loss": 33.705246448516846, "val_acc": 76.0}
{"epoch": 61, "training_loss": 76.68084847927094, "training_acc": 79.0, "val_loss": 28.675413131713867, "val_acc": 48.0}
{"epoch": 62, "training_loss": 94.62371075153351, "training_acc": 70.0, "val_loss": 45.519229769706726, "val_acc": 72.0}
{"epoch": 63, "training_loss": 83.69721674919128, "training_acc": 80.0, "val_loss": 34.201157093048096, "val_acc": 48.0}
{"epoch": 64, "training_loss": 104.80840212106705, "training_acc": 66.0, "val_loss": 47.55352437496185, "val_acc": 72.0}
{"epoch": 65, "training_loss": 86.9991238117218, "training_acc": 78.0, "val_loss": 42.84072816371918, "val_acc": 40.0}
{"epoch": 66, "training_loss": 116.31095480918884, "training_acc": 63.0, "val_loss": 55.34999966621399, "val_acc": 72.0}
{"epoch": 67, "training_loss": 121.27330017089844, "training_acc": 74.0, "val_loss": 16.321930289268494, "val_acc": 88.0}
{"epoch": 68, "training_loss": 56.15734028816223, "training_acc": 80.0, "val_loss": 23.97198975086212, "val_acc": 80.0}
