"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1479.0200729370117, "training_acc": 71.0, "val_loss": 696.2597370147705, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2129.4955081939697, "training_acc": 72.0, "val_loss": 909.5851898193359, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4082.4052734375, "training_acc": 28.0, "val_loss": 112.11529970169067, "val_acc": 60.0}
{"epoch": 3, "training_loss": 840.7939262390137, "training_acc": 63.0, "val_loss": 706.2729358673096, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2877.12296295166, "training_acc": 72.0, "val_loss": 912.0254516601562, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3416.9130783081055, "training_acc": 72.0, "val_loss": 735.0412368774414, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2330.755516052246, "training_acc": 72.0, "val_loss": 297.6446866989136, "val_acc": 72.0}
{"epoch": 7, "training_loss": 725.4233474731445, "training_acc": 70.0, "val_loss": 363.016414642334, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2130.338279724121, "training_acc": 41.0, "val_loss": 217.11370944976807, "val_acc": 60.0}
{"epoch": 9, "training_loss": 1128.0467014312744, "training_acc": 58.0, "val_loss": 366.98381900787354, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1325.9763412475586, "training_acc": 74.0, "val_loss": 478.8205623626709, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1448.5371704101562, "training_acc": 72.0, "val_loss": 254.08082008361816, "val_acc": 72.0}
{"epoch": 12, "training_loss": 620.6955261230469, "training_acc": 75.0, "val_loss": 185.3742003440857, "val_acc": 56.0}
{"epoch": 13, "training_loss": 1027.288101196289, "training_acc": 50.0, "val_loss": 126.60601139068604, "val_acc": 64.0}
{"epoch": 14, "training_loss": 545.1873531341553, "training_acc": 66.0, "val_loss": 305.26647567749023, "val_acc": 72.0}
{"epoch": 15, "training_loss": 970.965654373169, "training_acc": 72.0, "val_loss": 289.8174047470093, "val_acc": 72.0}
{"epoch": 16, "training_loss": 892.2435417175293, "training_acc": 72.0, "val_loss": 71.63680791854858, "val_acc": 72.0}
{"epoch": 17, "training_loss": 420.273136138916, "training_acc": 63.0, "val_loss": 142.05021858215332, "val_acc": 40.0}
{"epoch": 18, "training_loss": 609.858494758606, "training_acc": 53.0, "val_loss": 170.9238886833191, "val_acc": 72.0}
{"epoch": 19, "training_loss": 675.6014080047607, "training_acc": 72.0, "val_loss": 153.34173440933228, "val_acc": 72.0}
{"epoch": 20, "training_loss": 414.0929260253906, "training_acc": 71.0, "val_loss": 171.55964374542236, "val_acc": 32.0}
{"epoch": 21, "training_loss": 654.8524036407471, "training_acc": 43.0, "val_loss": 47.11429476737976, "val_acc": 72.0}
{"epoch": 22, "training_loss": 299.20923614501953, "training_acc": 69.0, "val_loss": 142.45190620422363, "val_acc": 72.0}
{"epoch": 23, "training_loss": 389.98182582855225, "training_acc": 75.0, "val_loss": 58.55754017829895, "val_acc": 60.0}
{"epoch": 24, "training_loss": 335.61365699768066, "training_acc": 61.0, "val_loss": 51.66701674461365, "val_acc": 68.0}
{"epoch": 25, "training_loss": 194.62809038162231, "training_acc": 79.0, "val_loss": 128.8338541984558, "val_acc": 72.0}
{"epoch": 26, "training_loss": 425.48000717163086, "training_acc": 75.0, "val_loss": 55.300235748291016, "val_acc": 76.0}
{"epoch": 27, "training_loss": 218.32408332824707, "training_acc": 72.0, "val_loss": 83.6909294128418, "val_acc": 52.0}
{"epoch": 28, "training_loss": 273.13449907302856, "training_acc": 62.0, "val_loss": 97.38972187042236, "val_acc": 72.0}
{"epoch": 29, "training_loss": 324.8427906036377, "training_acc": 73.0, "val_loss": 14.916449785232544, "val_acc": 68.0}
{"epoch": 30, "training_loss": 177.97382068634033, "training_acc": 71.0, "val_loss": 16.301356256008148, "val_acc": 76.0}
{"epoch": 31, "training_loss": 121.75069999694824, "training_acc": 75.0, "val_loss": 43.31261217594147, "val_acc": 76.0}
{"epoch": 32, "training_loss": 155.0165786743164, "training_acc": 71.0, "val_loss": 18.876025080680847, "val_acc": 76.0}
{"epoch": 33, "training_loss": 73.71397066116333, "training_acc": 79.0, "val_loss": 50.31886100769043, "val_acc": 76.0}
{"epoch": 34, "training_loss": 124.35752844810486, "training_acc": 76.0, "val_loss": 24.03096705675125, "val_acc": 64.0}
{"epoch": 35, "training_loss": 86.2263457775116, "training_acc": 76.0, "val_loss": 45.11426389217377, "val_acc": 76.0}
{"epoch": 36, "training_loss": 123.00358486175537, "training_acc": 81.0, "val_loss": 78.09345722198486, "val_acc": 40.0}
{"epoch": 37, "training_loss": 203.705304145813, "training_acc": 57.0, "val_loss": 109.81712341308594, "val_acc": 72.0}
{"epoch": 38, "training_loss": 465.13560485839844, "training_acc": 72.0, "val_loss": 90.54165482521057, "val_acc": 72.0}
{"epoch": 39, "training_loss": 272.91346883773804, "training_acc": 67.0, "val_loss": 102.37046480178833, "val_acc": 36.0}
{"epoch": 40, "training_loss": 322.54149103164673, "training_acc": 53.0, "val_loss": 112.62211799621582, "val_acc": 72.0}
{"epoch": 41, "training_loss": 296.51857471466064, "training_acc": 76.0, "val_loss": 46.711188554763794, "val_acc": 76.0}
{"epoch": 42, "training_loss": 172.49357509613037, "training_acc": 70.0, "val_loss": 60.65551042556763, "val_acc": 76.0}
{"epoch": 43, "training_loss": 191.076566696167, "training_acc": 78.0, "val_loss": 126.36895179748535, "val_acc": 72.0}
{"epoch": 44, "training_loss": 253.05676174163818, "training_acc": 78.0, "val_loss": 39.49782848358154, "val_acc": 72.0}
{"epoch": 45, "training_loss": 183.2392225265503, "training_acc": 67.0, "val_loss": 49.33022856712341, "val_acc": 76.0}
{"epoch": 46, "training_loss": 116.3561372756958, "training_acc": 83.0, "val_loss": 67.68543720245361, "val_acc": 76.0}
{"epoch": 47, "training_loss": 149.2652940750122, "training_acc": 78.0, "val_loss": 30.306372046470642, "val_acc": 60.0}
{"epoch": 48, "training_loss": 230.3637409210205, "training_acc": 59.0, "val_loss": 82.14366436004639, "val_acc": 72.0}
