"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1313.500503540039, "training_acc": 72.0, "val_loss": 598.7391948699951, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1357.1195862293243, "training_acc": 76.0, "val_loss": 624.0286350250244, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1568.788477897644, "training_acc": 43.0, "val_loss": 251.10292434692383, "val_acc": 72.0}
{"epoch": 3, "training_loss": 974.3088989257812, "training_acc": 72.0, "val_loss": 165.9706950187683, "val_acc": 72.0}
{"epoch": 4, "training_loss": 645.5512351989746, "training_acc": 65.0, "val_loss": 211.88101768493652, "val_acc": 68.0}
{"epoch": 5, "training_loss": 488.06116485595703, "training_acc": 67.0, "val_loss": 160.07544994354248, "val_acc": 76.0}
{"epoch": 6, "training_loss": 448.97264862060547, "training_acc": 74.0, "val_loss": 136.8614673614502, "val_acc": 64.0}
{"epoch": 7, "training_loss": 351.4821186065674, "training_acc": 62.0, "val_loss": 88.21703791618347, "val_acc": 72.0}
{"epoch": 8, "training_loss": 191.87455940246582, "training_acc": 77.0, "val_loss": 75.75942873954773, "val_acc": 76.0}
{"epoch": 9, "training_loss": 312.96960735321045, "training_acc": 63.0, "val_loss": 33.75195264816284, "val_acc": 68.0}
{"epoch": 10, "training_loss": 92.84139490127563, "training_acc": 76.0, "val_loss": 25.87442398071289, "val_acc": 64.0}
{"epoch": 11, "training_loss": 78.50598859786987, "training_acc": 68.0, "val_loss": 94.29681301116943, "val_acc": 32.0}
{"epoch": 12, "training_loss": 172.49875330924988, "training_acc": 62.0, "val_loss": 101.36265754699707, "val_acc": 72.0}
{"epoch": 13, "training_loss": 337.5146064758301, "training_acc": 72.0, "val_loss": 128.2548189163208, "val_acc": 28.0}
{"epoch": 14, "training_loss": 322.12460470199585, "training_acc": 51.0, "val_loss": 141.91910028457642, "val_acc": 72.0}
{"epoch": 15, "training_loss": 654.6268272399902, "training_acc": 72.0, "val_loss": 181.64292573928833, "val_acc": 72.0}
{"epoch": 16, "training_loss": 529.2036790847778, "training_acc": 72.0, "val_loss": 214.66960906982422, "val_acc": 36.0}
{"epoch": 17, "training_loss": 757.4653644561768, "training_acc": 38.0, "val_loss": 65.1039719581604, "val_acc": 76.0}
{"epoch": 18, "training_loss": 441.42102432250977, "training_acc": 73.0, "val_loss": 138.36857080459595, "val_acc": 72.0}
{"epoch": 19, "training_loss": 361.38522815704346, "training_acc": 77.0, "val_loss": 156.66821002960205, "val_acc": 52.0}
{"epoch": 20, "training_loss": 488.2615566253662, "training_acc": 55.0, "val_loss": 94.15764212608337, "val_acc": 72.0}
{"epoch": 21, "training_loss": 309.678955078125, "training_acc": 77.0, "val_loss": 109.54936742782593, "val_acc": 76.0}
{"epoch": 22, "training_loss": 278.80585193634033, "training_acc": 74.0, "val_loss": 153.10018062591553, "val_acc": 56.0}
{"epoch": 23, "training_loss": 447.49622917175293, "training_acc": 55.0, "val_loss": 72.59754538536072, "val_acc": 72.0}
{"epoch": 24, "training_loss": 224.49350452423096, "training_acc": 77.0, "val_loss": 68.7273621559143, "val_acc": 80.0}
{"epoch": 25, "training_loss": 205.20501708984375, "training_acc": 71.0, "val_loss": 109.25889015197754, "val_acc": 36.0}
{"epoch": 26, "training_loss": 214.71129047870636, "training_acc": 64.0, "val_loss": 48.76509606838226, "val_acc": 72.0}
{"epoch": 27, "training_loss": 151.22667932510376, "training_acc": 72.0, "val_loss": 98.37339520454407, "val_acc": 40.0}
{"epoch": 28, "training_loss": 205.71527910232544, "training_acc": 62.0, "val_loss": 89.91329073905945, "val_acc": 72.0}
{"epoch": 29, "training_loss": 382.4807548522949, "training_acc": 72.0, "val_loss": 38.86735141277313, "val_acc": 76.0}
