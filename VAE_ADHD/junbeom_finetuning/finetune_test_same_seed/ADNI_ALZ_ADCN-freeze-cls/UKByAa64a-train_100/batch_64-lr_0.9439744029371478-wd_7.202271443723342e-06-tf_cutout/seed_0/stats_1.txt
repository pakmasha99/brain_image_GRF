"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1766.6247100830078, "training_acc": 49.0, "val_loss": 778.6929130554199, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2316.4735679626465, "training_acc": 72.0, "val_loss": 735.9899044036865, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2661.4815063476562, "training_acc": 28.0, "val_loss": 73.9519715309143, "val_acc": 76.0}
{"epoch": 3, "training_loss": 753.0001220703125, "training_acc": 72.0, "val_loss": 442.8733825683594, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1620.0286979675293, "training_acc": 72.0, "val_loss": 275.63064098358154, "val_acc": 72.0}
{"epoch": 5, "training_loss": 809.2636594772339, "training_acc": 76.0, "val_loss": 262.75901794433594, "val_acc": 60.0}
{"epoch": 6, "training_loss": 1199.947925567627, "training_acc": 49.0, "val_loss": 231.63788318634033, "val_acc": 56.0}
{"epoch": 7, "training_loss": 712.6945304870605, "training_acc": 62.0, "val_loss": 183.66347551345825, "val_acc": 76.0}
{"epoch": 8, "training_loss": 782.81520652771, "training_acc": 73.0, "val_loss": 203.4508228302002, "val_acc": 72.0}
{"epoch": 9, "training_loss": 608.9332132339478, "training_acc": 68.0, "val_loss": 99.2318868637085, "val_acc": 52.0}
{"epoch": 10, "training_loss": 409.67785453796387, "training_acc": 64.0, "val_loss": 105.63369989395142, "val_acc": 56.0}
{"epoch": 11, "training_loss": 418.3384647369385, "training_acc": 64.0, "val_loss": 131.5798044204712, "val_acc": 72.0}
{"epoch": 12, "training_loss": 455.9801330566406, "training_acc": 72.0, "val_loss": 46.0254967212677, "val_acc": 68.0}
{"epoch": 13, "training_loss": 274.73012924194336, "training_acc": 66.0, "val_loss": 49.162557721138, "val_acc": 56.0}
{"epoch": 14, "training_loss": 203.746262550354, "training_acc": 69.0, "val_loss": 187.09962368011475, "val_acc": 72.0}
{"epoch": 15, "training_loss": 548.189430475235, "training_acc": 72.0, "val_loss": 90.7030701637268, "val_acc": 32.0}
{"epoch": 16, "training_loss": 223.48234748840332, "training_acc": 50.0, "val_loss": 102.511727809906, "val_acc": 72.0}
{"epoch": 17, "training_loss": 261.6796684265137, "training_acc": 72.0, "val_loss": 40.60881733894348, "val_acc": 68.0}
{"epoch": 18, "training_loss": 162.22735786437988, "training_acc": 67.0, "val_loss": 49.73987340927124, "val_acc": 72.0}
{"epoch": 19, "training_loss": 134.52658891677856, "training_acc": 76.0, "val_loss": 38.68382275104523, "val_acc": 64.0}
{"epoch": 20, "training_loss": 106.63979482650757, "training_acc": 76.0, "val_loss": 48.36436212062836, "val_acc": 64.0}
{"epoch": 21, "training_loss": 125.37514138221741, "training_acc": 78.0, "val_loss": 52.163708209991455, "val_acc": 76.0}
{"epoch": 22, "training_loss": 168.6200475692749, "training_acc": 74.0, "val_loss": 34.63191092014313, "val_acc": 64.0}
{"epoch": 23, "training_loss": 109.9261679649353, "training_acc": 70.0, "val_loss": 30.795982480049133, "val_acc": 68.0}
{"epoch": 24, "training_loss": 78.06072473526001, "training_acc": 71.0, "val_loss": 68.93305778503418, "val_acc": 72.0}
{"epoch": 25, "training_loss": 159.47293043136597, "training_acc": 73.0, "val_loss": 43.111830949783325, "val_acc": 36.0}
{"epoch": 26, "training_loss": 71.94971096515656, "training_acc": 75.0, "val_loss": 37.291884422302246, "val_acc": 76.0}
{"epoch": 27, "training_loss": 85.50154161453247, "training_acc": 71.0, "val_loss": 26.823440194129944, "val_acc": 76.0}
{"epoch": 28, "training_loss": 47.58080542087555, "training_acc": 83.0, "val_loss": 25.526878237724304, "val_acc": 72.0}
{"epoch": 29, "training_loss": 52.90329074859619, "training_acc": 79.0, "val_loss": 27.722516655921936, "val_acc": 72.0}
{"epoch": 30, "training_loss": 54.55846309661865, "training_acc": 84.0, "val_loss": 40.37702977657318, "val_acc": 56.0}
{"epoch": 31, "training_loss": 98.40016222000122, "training_acc": 69.0, "val_loss": 26.782244443893433, "val_acc": 68.0}
{"epoch": 32, "training_loss": 79.449303150177, "training_acc": 75.0, "val_loss": 94.85642910003662, "val_acc": 72.0}
{"epoch": 33, "training_loss": 251.53176593780518, "training_acc": 72.0, "val_loss": 36.06356680393219, "val_acc": 52.0}
{"epoch": 34, "training_loss": 74.4454197883606, "training_acc": 71.0, "val_loss": 63.350266218185425, "val_acc": 72.0}
{"epoch": 35, "training_loss": 118.805659532547, "training_acc": 77.0, "val_loss": 58.44653248786926, "val_acc": 56.0}
{"epoch": 36, "training_loss": 102.00530588626862, "training_acc": 72.0, "val_loss": 76.50817036628723, "val_acc": 72.0}
{"epoch": 37, "training_loss": 145.448308467865, "training_acc": 77.0, "val_loss": 94.5039451122284, "val_acc": 40.0}
{"epoch": 38, "training_loss": 229.6078586578369, "training_acc": 60.0, "val_loss": 75.34894347190857, "val_acc": 76.0}
{"epoch": 39, "training_loss": 161.88842391967773, "training_acc": 76.0, "val_loss": 41.90398454666138, "val_acc": 60.0}
{"epoch": 40, "training_loss": 101.86957287788391, "training_acc": 77.0, "val_loss": 41.00663661956787, "val_acc": 80.0}
{"epoch": 41, "training_loss": 80.23524248600006, "training_acc": 84.0, "val_loss": 32.98889398574829, "val_acc": 60.0}
{"epoch": 42, "training_loss": 54.358173847198486, "training_acc": 82.0, "val_loss": 34.05243754386902, "val_acc": 68.0}
{"epoch": 43, "training_loss": 39.15305733680725, "training_acc": 84.0, "val_loss": 41.92320108413696, "val_acc": 64.0}
{"epoch": 44, "training_loss": 86.17285966873169, "training_acc": 70.0, "val_loss": 45.762547850608826, "val_acc": 44.0}
{"epoch": 45, "training_loss": 109.41984701156616, "training_acc": 66.0, "val_loss": 35.91214418411255, "val_acc": 72.0}
{"epoch": 46, "training_loss": 109.4929027557373, "training_acc": 76.0, "val_loss": 44.430869817733765, "val_acc": 80.0}
{"epoch": 47, "training_loss": 146.72325229644775, "training_acc": 78.0, "val_loss": 43.88776421546936, "val_acc": 64.0}
