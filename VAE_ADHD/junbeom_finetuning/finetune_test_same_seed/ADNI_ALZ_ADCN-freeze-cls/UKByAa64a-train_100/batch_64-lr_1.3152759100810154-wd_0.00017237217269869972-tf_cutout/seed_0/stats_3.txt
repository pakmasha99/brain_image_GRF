"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2012.849105834961, "training_acc": 72.0, "val_loss": 950.5056381225586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2380.42036819458, "training_acc": 72.0, "val_loss": 1735.0519180297852, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6750.186065673828, "training_acc": 28.0, "val_loss": 520.9063529968262, "val_acc": 36.0}
{"epoch": 3, "training_loss": 1876.5792541503906, "training_acc": 49.0, "val_loss": 830.0694465637207, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3307.696464538574, "training_acc": 72.0, "val_loss": 1130.06591796875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4326.923965454102, "training_acc": 72.0, "val_loss": 944.9020385742188, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3234.281784057617, "training_acc": 72.0, "val_loss": 442.403507232666, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1219.730110168457, "training_acc": 69.0, "val_loss": 702.8436183929443, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2460.252243041992, "training_acc": 48.0, "val_loss": 615.7082557678223, "val_acc": 68.0}
{"epoch": 9, "training_loss": 1436.965015411377, "training_acc": 59.0, "val_loss": 443.33653450012207, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1210.9861335754395, "training_acc": 72.0, "val_loss": 526.6010761260986, "val_acc": 68.0}
{"epoch": 11, "training_loss": 1772.173683166504, "training_acc": 73.0, "val_loss": 413.55905532836914, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1045.1306686401367, "training_acc": 74.0, "val_loss": 416.79844856262207, "val_acc": 64.0}
{"epoch": 13, "training_loss": 1279.5256729125977, "training_acc": 58.0, "val_loss": 435.5127811431885, "val_acc": 56.0}
{"epoch": 14, "training_loss": 924.5784597396851, "training_acc": 67.0, "val_loss": 223.3901023864746, "val_acc": 72.0}
{"epoch": 15, "training_loss": 685.888256072998, "training_acc": 73.0, "val_loss": 238.92483711242676, "val_acc": 72.0}
{"epoch": 16, "training_loss": 802.3796138763428, "training_acc": 73.0, "val_loss": 141.50265455245972, "val_acc": 64.0}
{"epoch": 17, "training_loss": 457.1145420074463, "training_acc": 58.0, "val_loss": 55.68809509277344, "val_acc": 60.0}
{"epoch": 18, "training_loss": 266.19812202453613, "training_acc": 70.0, "val_loss": 82.12448954582214, "val_acc": 72.0}
{"epoch": 19, "training_loss": 329.45463132858276, "training_acc": 72.0, "val_loss": 169.68481540679932, "val_acc": 36.0}
{"epoch": 20, "training_loss": 325.10610461235046, "training_acc": 59.0, "val_loss": 80.18802404403687, "val_acc": 72.0}
{"epoch": 21, "training_loss": 312.7067713737488, "training_acc": 75.0, "val_loss": 137.2782588005066, "val_acc": 44.0}
{"epoch": 22, "training_loss": 321.47107791900635, "training_acc": 60.0, "val_loss": 88.81310820579529, "val_acc": 80.0}
{"epoch": 23, "training_loss": 428.84542655944824, "training_acc": 73.0, "val_loss": 75.43632388114929, "val_acc": 76.0}
{"epoch": 24, "training_loss": 357.2666702270508, "training_acc": 68.0, "val_loss": 145.29800415039062, "val_acc": 56.0}
{"epoch": 25, "training_loss": 352.47887992858887, "training_acc": 71.0, "val_loss": 94.66809630393982, "val_acc": 76.0}
{"epoch": 26, "training_loss": 334.62723565101624, "training_acc": 76.0, "val_loss": 67.63746738433838, "val_acc": 72.0}
{"epoch": 27, "training_loss": 181.8286361694336, "training_acc": 73.0, "val_loss": 40.16534388065338, "val_acc": 72.0}
{"epoch": 28, "training_loss": 67.11521005630493, "training_acc": 84.0, "val_loss": 56.99425935745239, "val_acc": 52.0}
{"epoch": 29, "training_loss": 158.95380878448486, "training_acc": 64.0, "val_loss": 22.881507873535156, "val_acc": 60.0}
{"epoch": 30, "training_loss": 291.83436584472656, "training_acc": 58.0, "val_loss": 27.42133140563965, "val_acc": 64.0}
{"epoch": 31, "training_loss": 199.11890029907227, "training_acc": 72.0, "val_loss": 38.62124681472778, "val_acc": 60.0}
{"epoch": 32, "training_loss": 58.737255692481995, "training_acc": 75.0, "val_loss": 23.66478741168976, "val_acc": 88.0}
{"epoch": 33, "training_loss": 92.48618292808533, "training_acc": 78.0, "val_loss": 39.41261172294617, "val_acc": 68.0}
{"epoch": 34, "training_loss": 99.86977291107178, "training_acc": 79.0, "val_loss": 30.801767110824585, "val_acc": 80.0}
{"epoch": 35, "training_loss": 107.67815113067627, "training_acc": 72.0, "val_loss": 26.104319095611572, "val_acc": 68.0}
{"epoch": 36, "training_loss": 86.58189249038696, "training_acc": 83.0, "val_loss": 56.69243931770325, "val_acc": 56.0}
{"epoch": 37, "training_loss": 87.35388171672821, "training_acc": 75.0, "val_loss": 9.972988069057465, "val_acc": 84.0}
{"epoch": 38, "training_loss": 52.1964145898819, "training_acc": 87.0, "val_loss": 23.609566688537598, "val_acc": 64.0}
{"epoch": 39, "training_loss": 51.70137310028076, "training_acc": 78.0, "val_loss": 44.31062936782837, "val_acc": 56.0}
{"epoch": 40, "training_loss": 67.75952410697937, "training_acc": 84.0, "val_loss": 13.920976221561432, "val_acc": 84.0}
{"epoch": 41, "training_loss": 101.24210405349731, "training_acc": 73.0, "val_loss": 28.050675988197327, "val_acc": 84.0}
{"epoch": 42, "training_loss": 117.03009009361267, "training_acc": 78.0, "val_loss": 99.44881796836853, "val_acc": 36.0}
{"epoch": 43, "training_loss": 378.9779348373413, "training_acc": 50.0, "val_loss": 71.16783857345581, "val_acc": 72.0}
{"epoch": 44, "training_loss": 269.09393787384033, "training_acc": 67.0, "val_loss": 46.722009778022766, "val_acc": 64.0}
{"epoch": 45, "training_loss": 136.3596315383911, "training_acc": 78.0, "val_loss": 38.0872368812561, "val_acc": 80.0}
{"epoch": 46, "training_loss": 176.19073390960693, "training_acc": 71.0, "val_loss": 30.541139841079712, "val_acc": 80.0}
{"epoch": 47, "training_loss": 119.86282157897949, "training_acc": 76.0, "val_loss": 89.95509743690491, "val_acc": 32.0}
{"epoch": 48, "training_loss": 183.1460497379303, "training_acc": 61.0, "val_loss": 10.831019282341003, "val_acc": 80.0}
{"epoch": 49, "training_loss": 96.18642377853394, "training_acc": 77.0, "val_loss": 19.60541307926178, "val_acc": 72.0}
{"epoch": 50, "training_loss": 89.02169060707092, "training_acc": 76.0, "val_loss": 95.57254314422607, "val_acc": 36.0}
{"epoch": 51, "training_loss": 143.09403896331787, "training_acc": 65.0, "val_loss": 51.23649835586548, "val_acc": 72.0}
{"epoch": 52, "training_loss": 234.0383973121643, "training_acc": 63.0, "val_loss": 19.170796871185303, "val_acc": 84.0}
{"epoch": 53, "training_loss": 92.6023621559143, "training_acc": 79.0, "val_loss": 112.51379251480103, "val_acc": 36.0}
{"epoch": 54, "training_loss": 288.59075021743774, "training_acc": 60.0, "val_loss": 47.3132461309433, "val_acc": 84.0}
{"epoch": 55, "training_loss": 141.41190946102142, "training_acc": 81.0, "val_loss": 74.9628484249115, "val_acc": 52.0}
{"epoch": 56, "training_loss": 193.405695438385, "training_acc": 66.0, "val_loss": 35.324302315711975, "val_acc": 84.0}
