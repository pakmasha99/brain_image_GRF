"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2842.930503845215, "training_acc": 36.0, "val_loss": 1029.7770500183105, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3441.1596031188965, "training_acc": 72.0, "val_loss": 587.1143817901611, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2442.435089111328, "training_acc": 35.0, "val_loss": 196.47064208984375, "val_acc": 68.0}
{"epoch": 3, "training_loss": 818.4256973266602, "training_acc": 76.0, "val_loss": 555.0494194030762, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1894.8011741638184, "training_acc": 72.0, "val_loss": 296.5289354324341, "val_acc": 76.0}
{"epoch": 5, "training_loss": 969.1423654556274, "training_acc": 71.0, "val_loss": 296.24767303466797, "val_acc": 52.0}
{"epoch": 6, "training_loss": 1399.6163520812988, "training_acc": 53.0, "val_loss": 208.69581699371338, "val_acc": 72.0}
{"epoch": 7, "training_loss": 849.320198059082, "training_acc": 71.0, "val_loss": 438.79804611206055, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1288.6670608520508, "training_acc": 72.0, "val_loss": 225.7267713546753, "val_acc": 68.0}
{"epoch": 9, "training_loss": 535.1661643981934, "training_acc": 71.0, "val_loss": 241.59066677093506, "val_acc": 48.0}
{"epoch": 10, "training_loss": 1015.4685039520264, "training_acc": 59.0, "val_loss": 141.5725827217102, "val_acc": 64.0}
{"epoch": 11, "training_loss": 434.8571968078613, "training_acc": 76.0, "val_loss": 220.73266506195068, "val_acc": 72.0}
{"epoch": 12, "training_loss": 486.66260385513306, "training_acc": 73.0, "val_loss": 189.78358507156372, "val_acc": 36.0}
{"epoch": 13, "training_loss": 592.7734017372131, "training_acc": 53.0, "val_loss": 189.39025402069092, "val_acc": 72.0}
{"epoch": 14, "training_loss": 613.4641437530518, "training_acc": 72.0, "val_loss": 114.38887119293213, "val_acc": 60.0}
{"epoch": 15, "training_loss": 525.1124382019043, "training_acc": 57.0, "val_loss": 105.46790361404419, "val_acc": 52.0}
{"epoch": 16, "training_loss": 497.01505851745605, "training_acc": 56.0, "val_loss": 350.6207227706909, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1226.2348022460938, "training_acc": 72.0, "val_loss": 205.7727813720703, "val_acc": 72.0}
{"epoch": 18, "training_loss": 535.24338722229, "training_acc": 70.0, "val_loss": 157.4391484260559, "val_acc": 52.0}
{"epoch": 19, "training_loss": 579.9142351150513, "training_acc": 59.0, "val_loss": 223.93312454223633, "val_acc": 72.0}
{"epoch": 20, "training_loss": 628.8782444000244, "training_acc": 72.0, "val_loss": 212.8357172012329, "val_acc": 72.0}
{"epoch": 21, "training_loss": 404.73530769348145, "training_acc": 80.0, "val_loss": 128.62244844436646, "val_acc": 64.0}
{"epoch": 22, "training_loss": 521.4121799468994, "training_acc": 60.0, "val_loss": 112.76282072067261, "val_acc": 72.0}
{"epoch": 23, "training_loss": 366.0894012451172, "training_acc": 78.0, "val_loss": 224.15051460266113, "val_acc": 72.0}
{"epoch": 24, "training_loss": 492.9940700531006, "training_acc": 75.0, "val_loss": 82.1045994758606, "val_acc": 68.0}
{"epoch": 25, "training_loss": 266.1172914505005, "training_acc": 66.0, "val_loss": 97.89854884147644, "val_acc": 72.0}
{"epoch": 26, "training_loss": 216.27145290374756, "training_acc": 75.0, "val_loss": 69.16850805282593, "val_acc": 56.0}
{"epoch": 27, "training_loss": 176.93442392349243, "training_acc": 68.0, "val_loss": 112.19804286956787, "val_acc": 72.0}
{"epoch": 28, "training_loss": 283.497878074646, "training_acc": 72.0, "val_loss": 102.78798341751099, "val_acc": 52.0}
{"epoch": 29, "training_loss": 244.41640973091125, "training_acc": 58.0, "val_loss": 100.86178779602051, "val_acc": 72.0}
{"epoch": 30, "training_loss": 163.7452368736267, "training_acc": 76.0, "val_loss": 127.44704484939575, "val_acc": 44.0}
{"epoch": 31, "training_loss": 395.9221119880676, "training_acc": 59.0, "val_loss": 132.262921333313, "val_acc": 72.0}
{"epoch": 32, "training_loss": 296.8081464767456, "training_acc": 76.0, "val_loss": 75.07176995277405, "val_acc": 72.0}
{"epoch": 33, "training_loss": 192.29804134368896, "training_acc": 73.0, "val_loss": 60.93290448188782, "val_acc": 72.0}
{"epoch": 34, "training_loss": 128.56150126457214, "training_acc": 81.0, "val_loss": 153.41928005218506, "val_acc": 72.0}
{"epoch": 35, "training_loss": 325.30218029022217, "training_acc": 73.0, "val_loss": 60.17866134643555, "val_acc": 68.0}
{"epoch": 36, "training_loss": 224.91896724700928, "training_acc": 64.0, "val_loss": 125.32573938369751, "val_acc": 72.0}
{"epoch": 37, "training_loss": 354.27477645874023, "training_acc": 74.0, "val_loss": 75.36840438842773, "val_acc": 72.0}
{"epoch": 38, "training_loss": 207.09153270721436, "training_acc": 68.0, "val_loss": 44.568437337875366, "val_acc": 52.0}
{"epoch": 39, "training_loss": 149.157865524292, "training_acc": 75.0, "val_loss": 181.74917697906494, "val_acc": 72.0}
{"epoch": 40, "training_loss": 408.64390754699707, "training_acc": 74.0, "val_loss": 154.40139770507812, "val_acc": 44.0}
{"epoch": 41, "training_loss": 420.05915823578835, "training_acc": 59.0, "val_loss": 113.97522687911987, "val_acc": 72.0}
{"epoch": 42, "training_loss": 214.37556648254395, "training_acc": 77.0, "val_loss": 55.49944043159485, "val_acc": 68.0}
{"epoch": 43, "training_loss": 116.56572079658508, "training_acc": 75.0, "val_loss": 53.2298743724823, "val_acc": 68.0}
{"epoch": 44, "training_loss": 87.25010538101196, "training_acc": 83.0, "val_loss": 115.4992938041687, "val_acc": 72.0}
{"epoch": 45, "training_loss": 164.4439115524292, "training_acc": 81.0, "val_loss": 99.50606226921082, "val_acc": 56.0}
{"epoch": 46, "training_loss": 294.05011081695557, "training_acc": 53.0, "val_loss": 82.75433778762817, "val_acc": 72.0}
{"epoch": 47, "training_loss": 143.6596188545227, "training_acc": 78.0, "val_loss": 70.89451551437378, "val_acc": 60.0}
{"epoch": 48, "training_loss": 225.49752187728882, "training_acc": 65.0, "val_loss": 162.24749088287354, "val_acc": 72.0}
{"epoch": 49, "training_loss": 316.1794147491455, "training_acc": 74.0, "val_loss": 114.2743706703186, "val_acc": 44.0}
{"epoch": 50, "training_loss": 317.4245929121971, "training_acc": 61.0, "val_loss": 114.89366292953491, "val_acc": 72.0}
{"epoch": 51, "training_loss": 246.08801460266113, "training_acc": 77.0, "val_loss": 57.83457159996033, "val_acc": 68.0}
{"epoch": 52, "training_loss": 353.5853672027588, "training_acc": 70.0, "val_loss": 99.03472065925598, "val_acc": 76.0}
{"epoch": 53, "training_loss": 301.43372344970703, "training_acc": 78.0, "val_loss": 141.21787548065186, "val_acc": 72.0}
{"epoch": 54, "training_loss": 205.91447687149048, "training_acc": 75.0, "val_loss": 100.83503723144531, "val_acc": 52.0}
{"epoch": 55, "training_loss": 246.54282760620117, "training_acc": 65.0, "val_loss": 125.39604902267456, "val_acc": 72.0}
{"epoch": 56, "training_loss": 191.34529304504395, "training_acc": 77.0, "val_loss": 68.51348876953125, "val_acc": 68.0}
{"epoch": 57, "training_loss": 183.02399969100952, "training_acc": 66.0, "val_loss": 100.70652961730957, "val_acc": 72.0}
