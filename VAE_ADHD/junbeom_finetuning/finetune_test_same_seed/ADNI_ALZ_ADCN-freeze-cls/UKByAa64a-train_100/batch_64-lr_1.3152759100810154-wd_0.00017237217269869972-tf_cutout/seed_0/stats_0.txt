"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2174.6957054138184, "training_acc": 72.0, "val_loss": 942.8386688232422, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2568.1177711486816, "training_acc": 72.0, "val_loss": 1478.9716720581055, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6188.32763671875, "training_acc": 28.0, "val_loss": 269.20225620269775, "val_acc": 36.0}
{"epoch": 3, "training_loss": 1638.247169494629, "training_acc": 51.0, "val_loss": 843.6562538146973, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3795.53466796875, "training_acc": 72.0, "val_loss": 1126.2263298034668, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4495.498466491699, "training_acc": 72.0, "val_loss": 833.9385986328125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2932.5326232910156, "training_acc": 72.0, "val_loss": 184.48777198791504, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1528.1725997924805, "training_acc": 65.0, "val_loss": 333.55908393859863, "val_acc": 48.0}
{"epoch": 8, "training_loss": 2438.7156562805176, "training_acc": 45.0, "val_loss": 111.45095825195312, "val_acc": 84.0}
{"epoch": 9, "training_loss": 1137.526372909546, "training_acc": 71.0, "val_loss": 291.97185039520264, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1300.4439010620117, "training_acc": 73.0, "val_loss": 346.58827781677246, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1113.9215965270996, "training_acc": 71.0, "val_loss": 69.51658725738525, "val_acc": 80.0}
{"epoch": 12, "training_loss": 697.962890625, "training_acc": 63.0, "val_loss": 121.37082815170288, "val_acc": 56.0}
{"epoch": 13, "training_loss": 529.4927616119385, "training_acc": 63.0, "val_loss": 217.93649196624756, "val_acc": 72.0}
{"epoch": 14, "training_loss": 801.1388053894043, "training_acc": 72.0, "val_loss": 159.30328369140625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 425.69912910461426, "training_acc": 67.0, "val_loss": 118.11562776565552, "val_acc": 52.0}
{"epoch": 16, "training_loss": 493.45336723327637, "training_acc": 61.0, "val_loss": 144.60967779159546, "val_acc": 72.0}
{"epoch": 17, "training_loss": 377.3385899066925, "training_acc": 68.0, "val_loss": 58.98856520652771, "val_acc": 52.0}
{"epoch": 18, "training_loss": 238.42409229278564, "training_acc": 59.0, "val_loss": 45.589494705200195, "val_acc": 72.0}
{"epoch": 19, "training_loss": 218.23574924468994, "training_acc": 69.0, "val_loss": 19.510336220264435, "val_acc": 84.0}
{"epoch": 20, "training_loss": 132.23414611816406, "training_acc": 81.0, "val_loss": 57.15121626853943, "val_acc": 72.0}
{"epoch": 21, "training_loss": 164.78905630111694, "training_acc": 80.0, "val_loss": 143.43209266662598, "val_acc": 40.0}
{"epoch": 22, "training_loss": 423.98583912849426, "training_acc": 51.0, "val_loss": 122.01482057571411, "val_acc": 72.0}
{"epoch": 23, "training_loss": 441.7352352142334, "training_acc": 72.0, "val_loss": 18.889226019382477, "val_acc": 76.0}
{"epoch": 24, "training_loss": 323.44102668762207, "training_acc": 64.0, "val_loss": 20.045337080955505, "val_acc": 76.0}
{"epoch": 25, "training_loss": 174.25300788879395, "training_acc": 82.0, "val_loss": 101.7279863357544, "val_acc": 72.0}
{"epoch": 26, "training_loss": 274.70856738090515, "training_acc": 73.0, "val_loss": 107.7718734741211, "val_acc": 56.0}
{"epoch": 27, "training_loss": 362.88965702056885, "training_acc": 54.0, "val_loss": 108.39295387268066, "val_acc": 72.0}
{"epoch": 28, "training_loss": 318.56043338775635, "training_acc": 74.0, "val_loss": 77.91576981544495, "val_acc": 56.0}
{"epoch": 29, "training_loss": 315.65267276763916, "training_acc": 62.0, "val_loss": 76.40380859375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 288.3559594154358, "training_acc": 77.0, "val_loss": 81.95981979370117, "val_acc": 72.0}
{"epoch": 31, "training_loss": 159.26291942596436, "training_acc": 81.0, "val_loss": 96.20577096939087, "val_acc": 52.0}
{"epoch": 32, "training_loss": 267.14057540893555, "training_acc": 66.0, "val_loss": 78.49264144897461, "val_acc": 72.0}
{"epoch": 33, "training_loss": 167.82416915893555, "training_acc": 79.0, "val_loss": 35.58330833911896, "val_acc": 72.0}
{"epoch": 34, "training_loss": 120.56266164779663, "training_acc": 71.0, "val_loss": 42.19712316989899, "val_acc": 56.0}
{"epoch": 35, "training_loss": 103.28579950332642, "training_acc": 75.0, "val_loss": 87.13392615318298, "val_acc": 72.0}
{"epoch": 36, "training_loss": 157.45258712768555, "training_acc": 75.0, "val_loss": 54.34105396270752, "val_acc": 56.0}
{"epoch": 37, "training_loss": 138.27268648147583, "training_acc": 69.0, "val_loss": 23.815442621707916, "val_acc": 80.0}
{"epoch": 38, "training_loss": 63.585787773132324, "training_acc": 85.0, "val_loss": 34.32990312576294, "val_acc": 64.0}
{"epoch": 39, "training_loss": 124.47065281867981, "training_acc": 81.0, "val_loss": 32.02677071094513, "val_acc": 76.0}
{"epoch": 40, "training_loss": 112.14488935470581, "training_acc": 80.0, "val_loss": 68.78175139427185, "val_acc": 52.0}
{"epoch": 41, "training_loss": 175.9710066318512, "training_acc": 67.0, "val_loss": 42.43176579475403, "val_acc": 76.0}
{"epoch": 42, "training_loss": 171.72657680511475, "training_acc": 67.0, "val_loss": 28.858965635299683, "val_acc": 72.0}
