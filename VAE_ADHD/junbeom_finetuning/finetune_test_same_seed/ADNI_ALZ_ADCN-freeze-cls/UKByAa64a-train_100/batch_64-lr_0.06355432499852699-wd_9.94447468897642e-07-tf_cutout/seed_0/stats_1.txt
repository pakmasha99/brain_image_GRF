"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 157.61617851257324, "training_acc": 40.0, "val_loss": 51.01920962333679, "val_acc": 72.0}
{"epoch": 1, "training_loss": 156.06752347946167, "training_acc": 72.0, "val_loss": 45.55266797542572, "val_acc": 28.0}
{"epoch": 2, "training_loss": 169.2803292274475, "training_acc": 30.0, "val_loss": 13.687950372695923, "val_acc": 72.0}
{"epoch": 3, "training_loss": 73.01259684562683, "training_acc": 73.0, "val_loss": 36.23189926147461, "val_acc": 72.0}
{"epoch": 4, "training_loss": 142.9822096824646, "training_acc": 72.0, "val_loss": 28.55503559112549, "val_acc": 72.0}
{"epoch": 5, "training_loss": 99.74726724624634, "training_acc": 71.0, "val_loss": 17.520077526569366, "val_acc": 56.0}
{"epoch": 6, "training_loss": 93.1347713470459, "training_acc": 56.0, "val_loss": 22.14081585407257, "val_acc": 56.0}
{"epoch": 7, "training_loss": 82.03290724754333, "training_acc": 60.0, "val_loss": 15.5251145362854, "val_acc": 80.0}
{"epoch": 8, "training_loss": 70.4883017539978, "training_acc": 74.0, "val_loss": 19.074508547782898, "val_acc": 72.0}
{"epoch": 9, "training_loss": 72.80423927307129, "training_acc": 73.0, "val_loss": 13.221749663352966, "val_acc": 64.0}
{"epoch": 10, "training_loss": 62.455666065216064, "training_acc": 67.0, "val_loss": 15.534159541130066, "val_acc": 60.0}
{"epoch": 11, "training_loss": 61.878072023391724, "training_acc": 70.0, "val_loss": 14.11644071340561, "val_acc": 80.0}
{"epoch": 12, "training_loss": 62.15730047225952, "training_acc": 72.0, "val_loss": 16.382847726345062, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.144426584243774, "training_acc": 72.0, "val_loss": 13.233810663223267, "val_acc": 64.0}
{"epoch": 14, "training_loss": 55.13754224777222, "training_acc": 74.0, "val_loss": 13.864980638027191, "val_acc": 60.0}
{"epoch": 15, "training_loss": 56.14985966682434, "training_acc": 70.0, "val_loss": 14.34289813041687, "val_acc": 72.0}
{"epoch": 16, "training_loss": 52.83027267456055, "training_acc": 72.0, "val_loss": 13.417722284793854, "val_acc": 76.0}
{"epoch": 17, "training_loss": 52.0120644569397, "training_acc": 74.0, "val_loss": 13.396216928958893, "val_acc": 64.0}
{"epoch": 18, "training_loss": 51.41941273212433, "training_acc": 79.0, "val_loss": 13.446672260761261, "val_acc": 76.0}
{"epoch": 19, "training_loss": 51.03016209602356, "training_acc": 73.0, "val_loss": 13.789549469947815, "val_acc": 72.0}
{"epoch": 20, "training_loss": 49.04436731338501, "training_acc": 73.0, "val_loss": 13.22399377822876, "val_acc": 64.0}
{"epoch": 21, "training_loss": 50.35296559333801, "training_acc": 78.0, "val_loss": 12.82883882522583, "val_acc": 64.0}
{"epoch": 22, "training_loss": 51.0691602230072, "training_acc": 78.0, "val_loss": 13.52815181016922, "val_acc": 76.0}
{"epoch": 23, "training_loss": 50.14465951919556, "training_acc": 75.0, "val_loss": 13.211482763290405, "val_acc": 76.0}
{"epoch": 24, "training_loss": 51.26126432418823, "training_acc": 76.0, "val_loss": 12.730400264263153, "val_acc": 68.0}
{"epoch": 25, "training_loss": 46.84470725059509, "training_acc": 79.0, "val_loss": 12.971802055835724, "val_acc": 72.0}
{"epoch": 26, "training_loss": 47.26600241661072, "training_acc": 79.0, "val_loss": 13.007646799087524, "val_acc": 72.0}
{"epoch": 27, "training_loss": 46.01502537727356, "training_acc": 78.0, "val_loss": 12.75138407945633, "val_acc": 68.0}
{"epoch": 28, "training_loss": 47.75264084339142, "training_acc": 79.0, "val_loss": 12.806355953216553, "val_acc": 64.0}
{"epoch": 29, "training_loss": 49.109705209732056, "training_acc": 76.0, "val_loss": 13.099272549152374, "val_acc": 68.0}
{"epoch": 30, "training_loss": 46.32863092422485, "training_acc": 78.0, "val_loss": 12.98253983259201, "val_acc": 68.0}
{"epoch": 31, "training_loss": 48.53672385215759, "training_acc": 76.0, "val_loss": 12.97457069158554, "val_acc": 68.0}
{"epoch": 32, "training_loss": 45.70711708068848, "training_acc": 78.0, "val_loss": 13.526482880115509, "val_acc": 76.0}
{"epoch": 33, "training_loss": 46.984335064888, "training_acc": 75.0, "val_loss": 12.848229706287384, "val_acc": 72.0}
{"epoch": 34, "training_loss": 46.75630760192871, "training_acc": 80.0, "val_loss": 12.92441040277481, "val_acc": 68.0}
{"epoch": 35, "training_loss": 44.42016077041626, "training_acc": 79.0, "val_loss": 13.618484139442444, "val_acc": 76.0}
{"epoch": 36, "training_loss": 48.555171728134155, "training_acc": 78.0, "val_loss": 12.828707695007324, "val_acc": 68.0}
{"epoch": 37, "training_loss": 47.0532648563385, "training_acc": 78.0, "val_loss": 12.831185758113861, "val_acc": 64.0}
{"epoch": 38, "training_loss": 46.67030453681946, "training_acc": 81.0, "val_loss": 13.424472510814667, "val_acc": 80.0}
{"epoch": 39, "training_loss": 45.68646061420441, "training_acc": 75.0, "val_loss": 12.764576077461243, "val_acc": 68.0}
{"epoch": 40, "training_loss": 45.474143862724304, "training_acc": 83.0, "val_loss": 12.844973802566528, "val_acc": 64.0}
{"epoch": 41, "training_loss": 45.14199507236481, "training_acc": 79.0, "val_loss": 13.484050333499908, "val_acc": 80.0}
{"epoch": 42, "training_loss": 46.298980355262756, "training_acc": 77.0, "val_loss": 12.89854496717453, "val_acc": 72.0}
{"epoch": 43, "training_loss": 44.147966146469116, "training_acc": 81.0, "val_loss": 13.067881762981415, "val_acc": 64.0}
