"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 482.05966567993164, "training_acc": 44.0, "val_loss": 237.49301433563232, "val_acc": 72.0}
{"epoch": 1, "training_loss": 756.7321872711182, "training_acc": 72.0, "val_loss": 132.4963092803955, "val_acc": 28.0}
{"epoch": 2, "training_loss": 529.2624788284302, "training_acc": 30.0, "val_loss": 50.27374029159546, "val_acc": 72.0}
{"epoch": 3, "training_loss": 211.08124160766602, "training_acc": 72.0, "val_loss": 90.10372757911682, "val_acc": 72.0}
{"epoch": 4, "training_loss": 268.18693828582764, "training_acc": 73.0, "val_loss": 35.192087292671204, "val_acc": 76.0}
{"epoch": 5, "training_loss": 194.75527095794678, "training_acc": 61.0, "val_loss": 36.830294132232666, "val_acc": 60.0}
{"epoch": 6, "training_loss": 163.613667011261, "training_acc": 68.0, "val_loss": 61.25239133834839, "val_acc": 72.0}
{"epoch": 7, "training_loss": 185.22535800933838, "training_acc": 72.0, "val_loss": 29.968208074569702, "val_acc": 68.0}
{"epoch": 8, "training_loss": 115.98058938980103, "training_acc": 65.0, "val_loss": 25.620347261428833, "val_acc": 64.0}
{"epoch": 9, "training_loss": 85.78380703926086, "training_acc": 68.0, "val_loss": 42.42890775203705, "val_acc": 72.0}
{"epoch": 10, "training_loss": 117.01571130752563, "training_acc": 72.0, "val_loss": 29.25899624824524, "val_acc": 48.0}
{"epoch": 11, "training_loss": 100.94394063949585, "training_acc": 47.0, "val_loss": 32.198381423950195, "val_acc": 72.0}
{"epoch": 12, "training_loss": 127.88133144378662, "training_acc": 72.0, "val_loss": 27.342799305915833, "val_acc": 72.0}
{"epoch": 13, "training_loss": 101.78776121139526, "training_acc": 62.0, "val_loss": 22.90426939725876, "val_acc": 56.0}
{"epoch": 14, "training_loss": 95.63245725631714, "training_acc": 64.0, "val_loss": 43.089666962623596, "val_acc": 72.0}
{"epoch": 15, "training_loss": 109.24253964424133, "training_acc": 73.0, "val_loss": 23.65364581346512, "val_acc": 64.0}
{"epoch": 16, "training_loss": 99.0462064743042, "training_acc": 63.0, "val_loss": 24.994949996471405, "val_acc": 72.0}
{"epoch": 17, "training_loss": 72.22679233551025, "training_acc": 81.0, "val_loss": 40.33023118972778, "val_acc": 72.0}
{"epoch": 18, "training_loss": 85.82545042037964, "training_acc": 79.0, "val_loss": 27.994781732559204, "val_acc": 60.0}
{"epoch": 19, "training_loss": 130.80294132232666, "training_acc": 56.0, "val_loss": 30.86271584033966, "val_acc": 68.0}
{"epoch": 20, "training_loss": 89.28015470504761, "training_acc": 75.0, "val_loss": 47.22916781902313, "val_acc": 72.0}
{"epoch": 21, "training_loss": 119.06590962409973, "training_acc": 71.0, "val_loss": 22.87304848432541, "val_acc": 60.0}
{"epoch": 22, "training_loss": 85.88831675052643, "training_acc": 62.0, "val_loss": 21.494866907596588, "val_acc": 68.0}
{"epoch": 23, "training_loss": 60.54310202598572, "training_acc": 75.0, "val_loss": 18.017925322055817, "val_acc": 68.0}
{"epoch": 24, "training_loss": 59.93618059158325, "training_acc": 66.0, "val_loss": 19.00862008333206, "val_acc": 64.0}
{"epoch": 25, "training_loss": 46.76971900463104, "training_acc": 73.0, "val_loss": 17.158475518226624, "val_acc": 64.0}
{"epoch": 26, "training_loss": 42.81549668312073, "training_acc": 82.0, "val_loss": 15.231379866600037, "val_acc": 68.0}
{"epoch": 27, "training_loss": 43.676716327667236, "training_acc": 81.0, "val_loss": 14.180952310562134, "val_acc": 60.0}
{"epoch": 28, "training_loss": 51.33481240272522, "training_acc": 77.0, "val_loss": 22.219687700271606, "val_acc": 72.0}
{"epoch": 29, "training_loss": 62.7951443195343, "training_acc": 75.0, "val_loss": 14.36232328414917, "val_acc": 68.0}
{"epoch": 30, "training_loss": 79.31103086471558, "training_acc": 64.0, "val_loss": 27.196303009986877, "val_acc": 72.0}
{"epoch": 31, "training_loss": 77.57557284832001, "training_acc": 74.0, "val_loss": 36.20117902755737, "val_acc": 72.0}
{"epoch": 32, "training_loss": 75.80083012580872, "training_acc": 79.0, "val_loss": 25.094377994537354, "val_acc": 52.0}
{"epoch": 33, "training_loss": 102.6352653503418, "training_acc": 62.0, "val_loss": 27.69659459590912, "val_acc": 76.0}
{"epoch": 34, "training_loss": 82.70542049407959, "training_acc": 76.0, "val_loss": 21.438980102539062, "val_acc": 68.0}
{"epoch": 35, "training_loss": 66.38539600372314, "training_acc": 74.0, "val_loss": 15.058951079845428, "val_acc": 72.0}
{"epoch": 36, "training_loss": 50.08582878112793, "training_acc": 82.0, "val_loss": 22.711287438869476, "val_acc": 72.0}
{"epoch": 37, "training_loss": 47.22213304042816, "training_acc": 79.0, "val_loss": 21.485625207424164, "val_acc": 60.0}
{"epoch": 38, "training_loss": 60.320913910865784, "training_acc": 65.0, "val_loss": 22.45810627937317, "val_acc": 72.0}
{"epoch": 39, "training_loss": 52.49532496929169, "training_acc": 77.0, "val_loss": 16.03952795267105, "val_acc": 60.0}
{"epoch": 40, "training_loss": 46.04419565200806, "training_acc": 76.0, "val_loss": 19.994667172431946, "val_acc": 72.0}
{"epoch": 41, "training_loss": 45.4432168006897, "training_acc": 79.0, "val_loss": 13.764466345310211, "val_acc": 68.0}
{"epoch": 42, "training_loss": 33.453534960746765, "training_acc": 84.0, "val_loss": 18.935871124267578, "val_acc": 76.0}
{"epoch": 43, "training_loss": 39.90056002140045, "training_acc": 81.0, "val_loss": 13.247084617614746, "val_acc": 68.0}
{"epoch": 44, "training_loss": 33.541720032691956, "training_acc": 89.0, "val_loss": 14.044678211212158, "val_acc": 76.0}
{"epoch": 45, "training_loss": 32.62660217285156, "training_acc": 88.0, "val_loss": 13.301481306552887, "val_acc": 80.0}
{"epoch": 46, "training_loss": 27.992462158203125, "training_acc": 88.0, "val_loss": 13.292847573757172, "val_acc": 72.0}
{"epoch": 47, "training_loss": 35.65881061553955, "training_acc": 82.0, "val_loss": 14.085984230041504, "val_acc": 76.0}
{"epoch": 48, "training_loss": 38.75493574142456, "training_acc": 84.0, "val_loss": 12.422015517950058, "val_acc": 68.0}
{"epoch": 49, "training_loss": 34.662628531455994, "training_acc": 84.0, "val_loss": 17.046187818050385, "val_acc": 76.0}
{"epoch": 50, "training_loss": 34.62531530857086, "training_acc": 83.0, "val_loss": 13.022758066654205, "val_acc": 68.0}
{"epoch": 51, "training_loss": 38.016109108924866, "training_acc": 85.0, "val_loss": 13.107776641845703, "val_acc": 68.0}
{"epoch": 52, "training_loss": 31.410026788711548, "training_acc": 88.0, "val_loss": 21.924935281276703, "val_acc": 72.0}
{"epoch": 53, "training_loss": 44.57787251472473, "training_acc": 80.0, "val_loss": 13.992998003959656, "val_acc": 68.0}
{"epoch": 54, "training_loss": 39.597287774086, "training_acc": 83.0, "val_loss": 18.74270737171173, "val_acc": 72.0}
{"epoch": 55, "training_loss": 36.1202757358551, "training_acc": 82.0, "val_loss": 15.732626616954803, "val_acc": 68.0}
{"epoch": 56, "training_loss": 40.85436815023422, "training_acc": 78.0, "val_loss": 22.01368808746338, "val_acc": 72.0}
{"epoch": 57, "training_loss": 40.624516010284424, "training_acc": 78.0, "val_loss": 13.959217071533203, "val_acc": 64.0}
{"epoch": 58, "training_loss": 31.455200016498566, "training_acc": 89.0, "val_loss": 17.295490205287933, "val_acc": 64.0}
{"epoch": 59, "training_loss": 27.954569935798645, "training_acc": 86.0, "val_loss": 15.329673886299133, "val_acc": 72.0}
{"epoch": 60, "training_loss": 35.79531276226044, "training_acc": 84.0, "val_loss": 26.483052968978882, "val_acc": 72.0}
{"epoch": 61, "training_loss": 51.43643844127655, "training_acc": 77.0, "val_loss": 16.527919471263885, "val_acc": 72.0}
{"epoch": 62, "training_loss": 50.42972016334534, "training_acc": 74.0, "val_loss": 18.83048713207245, "val_acc": 76.0}
{"epoch": 63, "training_loss": 33.04051065444946, "training_acc": 85.0, "val_loss": 14.090687036514282, "val_acc": 68.0}
{"epoch": 64, "training_loss": 31.837321162223816, "training_acc": 84.0, "val_loss": 17.476023733615875, "val_acc": 72.0}
{"epoch": 65, "training_loss": 30.441003680229187, "training_acc": 90.0, "val_loss": 12.832105159759521, "val_acc": 64.0}
{"epoch": 66, "training_loss": 24.442388355731964, "training_acc": 94.0, "val_loss": 12.87631243467331, "val_acc": 68.0}
{"epoch": 67, "training_loss": 23.83948117494583, "training_acc": 93.0, "val_loss": 14.05845433473587, "val_acc": 76.0}
