"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1904.3028869628906, "training_acc": 72.0, "val_loss": 1065.4254913330078, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2558.449493408203, "training_acc": 74.0, "val_loss": 2055.7241439819336, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8190.8570556640625, "training_acc": 28.0, "val_loss": 203.89370918273926, "val_acc": 76.0}
{"epoch": 3, "training_loss": 1298.5154418945312, "training_acc": 72.0, "val_loss": 1183.9808464050293, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4581.256011962891, "training_acc": 72.0, "val_loss": 1243.8395500183105, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4336.4317626953125, "training_acc": 72.0, "val_loss": 662.0904445648193, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1624.443302154541, "training_acc": 71.0, "val_loss": 358.5001230239868, "val_acc": 52.0}
{"epoch": 7, "training_loss": 2358.8735733032227, "training_acc": 50.0, "val_loss": 266.6490316390991, "val_acc": 60.0}
{"epoch": 8, "training_loss": 1118.4456462860107, "training_acc": 64.0, "val_loss": 532.9485893249512, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1748.0652770996094, "training_acc": 72.0, "val_loss": 536.9303703308105, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1480.0812683105469, "training_acc": 72.0, "val_loss": 154.95617389678955, "val_acc": 68.0}
{"epoch": 11, "training_loss": 976.9759063720703, "training_acc": 54.0, "val_loss": 146.523118019104, "val_acc": 64.0}
{"epoch": 12, "training_loss": 479.9012475013733, "training_acc": 68.0, "val_loss": 240.28122425079346, "val_acc": 72.0}
{"epoch": 13, "training_loss": 712.5451507568359, "training_acc": 72.0, "val_loss": 60.095471143722534, "val_acc": 68.0}
{"epoch": 14, "training_loss": 359.8641128540039, "training_acc": 62.0, "val_loss": 53.557586669921875, "val_acc": 80.0}
{"epoch": 15, "training_loss": 295.6087017059326, "training_acc": 75.0, "val_loss": 39.73954617977142, "val_acc": 80.0}
{"epoch": 16, "training_loss": 176.00914478302002, "training_acc": 79.0, "val_loss": 46.59726619720459, "val_acc": 56.0}
{"epoch": 17, "training_loss": 384.92626190185547, "training_acc": 67.0, "val_loss": 155.51716089248657, "val_acc": 72.0}
{"epoch": 18, "training_loss": 501.86119174957275, "training_acc": 73.0, "val_loss": 302.88023948669434, "val_acc": 28.0}
{"epoch": 19, "training_loss": 864.8253936767578, "training_acc": 49.0, "val_loss": 171.55026197433472, "val_acc": 72.0}
{"epoch": 20, "training_loss": 582.1205234527588, "training_acc": 72.0, "val_loss": 63.80321979522705, "val_acc": 76.0}
{"epoch": 21, "training_loss": 276.5379810333252, "training_acc": 73.0, "val_loss": 62.22100853919983, "val_acc": 72.0}
{"epoch": 22, "training_loss": 203.5669116973877, "training_acc": 76.0, "val_loss": 105.93680143356323, "val_acc": 76.0}
{"epoch": 23, "training_loss": 241.3119020462036, "training_acc": 77.0, "val_loss": 58.49103331565857, "val_acc": 60.0}
{"epoch": 24, "training_loss": 283.3952794075012, "training_acc": 70.0, "val_loss": 51.872265338897705, "val_acc": 76.0}
{"epoch": 25, "training_loss": 132.83816123008728, "training_acc": 80.0, "val_loss": 14.773951470851898, "val_acc": 84.0}
{"epoch": 26, "training_loss": 76.00090503692627, "training_acc": 77.0, "val_loss": 59.400659799575806, "val_acc": 60.0}
{"epoch": 27, "training_loss": 229.77206230163574, "training_acc": 67.0, "val_loss": 20.531967282295227, "val_acc": 76.0}
{"epoch": 28, "training_loss": 380.4806480407715, "training_acc": 62.0, "val_loss": 41.83560609817505, "val_acc": 76.0}
{"epoch": 29, "training_loss": 111.32351112365723, "training_acc": 79.0, "val_loss": 69.56013441085815, "val_acc": 80.0}
{"epoch": 30, "training_loss": 130.64409017562866, "training_acc": 78.0, "val_loss": 68.13961863517761, "val_acc": 68.0}
{"epoch": 31, "training_loss": 186.57687091827393, "training_acc": 75.0, "val_loss": 187.11533546447754, "val_acc": 72.0}
{"epoch": 32, "training_loss": 416.81111240386963, "training_acc": 73.0, "val_loss": 68.89982223510742, "val_acc": 68.0}
{"epoch": 33, "training_loss": 246.57093334197998, "training_acc": 68.0, "val_loss": 131.27026557922363, "val_acc": 72.0}
{"epoch": 34, "training_loss": 330.9316291809082, "training_acc": 76.0, "val_loss": 49.96491074562073, "val_acc": 76.0}
{"epoch": 35, "training_loss": 172.62390232086182, "training_acc": 75.0, "val_loss": 78.31493020057678, "val_acc": 76.0}
{"epoch": 36, "training_loss": 143.31269073486328, "training_acc": 81.0, "val_loss": 36.245134472846985, "val_acc": 80.0}
{"epoch": 37, "training_loss": 66.33781385421753, "training_acc": 82.0, "val_loss": 43.90176236629486, "val_acc": 76.0}
{"epoch": 38, "training_loss": 43.01469928026199, "training_acc": 88.0, "val_loss": 31.781548261642456, "val_acc": 64.0}
{"epoch": 39, "training_loss": 115.59022521972656, "training_acc": 76.0, "val_loss": 31.879320740699768, "val_acc": 76.0}
{"epoch": 40, "training_loss": 117.14436292648315, "training_acc": 76.0, "val_loss": 52.650123834609985, "val_acc": 72.0}
{"epoch": 41, "training_loss": 69.26581192016602, "training_acc": 82.0, "val_loss": 32.57499933242798, "val_acc": 76.0}
{"epoch": 42, "training_loss": 80.00148975849152, "training_acc": 79.0, "val_loss": 78.17216515541077, "val_acc": 76.0}
{"epoch": 43, "training_loss": 150.14652299880981, "training_acc": 78.0, "val_loss": 35.03518104553223, "val_acc": 84.0}
{"epoch": 44, "training_loss": 50.23810315132141, "training_acc": 87.0, "val_loss": 42.31017529964447, "val_acc": 64.0}
