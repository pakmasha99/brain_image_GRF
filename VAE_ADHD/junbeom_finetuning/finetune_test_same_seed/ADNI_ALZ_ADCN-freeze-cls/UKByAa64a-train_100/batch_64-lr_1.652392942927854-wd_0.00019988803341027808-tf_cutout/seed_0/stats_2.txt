"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2448.9452629089355, "training_acc": 41.0, "val_loss": 1296.3346481323242, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3875.671241760254, "training_acc": 72.0, "val_loss": 1327.8191566467285, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5296.390182495117, "training_acc": 28.0, "val_loss": 172.06345796585083, "val_acc": 76.0}
{"epoch": 3, "training_loss": 2040.5261535644531, "training_acc": 64.0, "val_loss": 998.7851142883301, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3807.069137573242, "training_acc": 72.0, "val_loss": 952.7299880981445, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3015.3136978149414, "training_acc": 72.0, "val_loss": 334.48784351348877, "val_acc": 68.0}
{"epoch": 6, "training_loss": 1549.0838623046875, "training_acc": 64.0, "val_loss": 560.7873439788818, "val_acc": 44.0}
{"epoch": 7, "training_loss": 2571.940948486328, "training_acc": 47.0, "val_loss": 281.60643577575684, "val_acc": 80.0}
{"epoch": 8, "training_loss": 1383.9718856811523, "training_acc": 68.0, "val_loss": 632.1991443634033, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2022.4617385864258, "training_acc": 72.0, "val_loss": 482.4446201324463, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1104.1371269226074, "training_acc": 73.0, "val_loss": 246.52128219604492, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1402.4913635253906, "training_acc": 59.0, "val_loss": 244.6098804473877, "val_acc": 60.0}
{"epoch": 12, "training_loss": 907.8200550079346, "training_acc": 67.0, "val_loss": 314.64507579803467, "val_acc": 72.0}
{"epoch": 13, "training_loss": 889.113525390625, "training_acc": 72.0, "val_loss": 220.16847133636475, "val_acc": 72.0}
{"epoch": 14, "training_loss": 549.3404865264893, "training_acc": 63.0, "val_loss": 201.43671035766602, "val_acc": 44.0}
{"epoch": 15, "training_loss": 729.9501495361328, "training_acc": 58.0, "val_loss": 267.97468662261963, "val_acc": 72.0}
{"epoch": 16, "training_loss": 877.864107131958, "training_acc": 72.0, "val_loss": 181.33656978607178, "val_acc": 72.0}
{"epoch": 17, "training_loss": 696.3408432006836, "training_acc": 56.0, "val_loss": 173.92749786376953, "val_acc": 52.0}
{"epoch": 18, "training_loss": 514.3385934829712, "training_acc": 56.0, "val_loss": 209.26003456115723, "val_acc": 72.0}
{"epoch": 19, "training_loss": 419.78497219085693, "training_acc": 75.0, "val_loss": 115.62669277191162, "val_acc": 64.0}
{"epoch": 20, "training_loss": 389.2591915130615, "training_acc": 65.0, "val_loss": 145.6830382347107, "val_acc": 68.0}
{"epoch": 21, "training_loss": 286.51196002960205, "training_acc": 80.0, "val_loss": 151.91161632537842, "val_acc": 68.0}
{"epoch": 22, "training_loss": 272.4654264450073, "training_acc": 78.0, "val_loss": 111.74312829971313, "val_acc": 68.0}
{"epoch": 23, "training_loss": 371.62279987335205, "training_acc": 74.0, "val_loss": 149.8490571975708, "val_acc": 72.0}
{"epoch": 24, "training_loss": 233.5824728012085, "training_acc": 77.0, "val_loss": 107.39420652389526, "val_acc": 56.0}
{"epoch": 25, "training_loss": 322.7268662452698, "training_acc": 60.0, "val_loss": 133.77352952957153, "val_acc": 72.0}
{"epoch": 26, "training_loss": 282.73057222366333, "training_acc": 70.0, "val_loss": 70.33015489578247, "val_acc": 64.0}
{"epoch": 27, "training_loss": 213.85254764556885, "training_acc": 66.0, "val_loss": 44.25351917743683, "val_acc": 72.0}
{"epoch": 28, "training_loss": 112.6755542755127, "training_acc": 78.0, "val_loss": 48.72680306434631, "val_acc": 76.0}
{"epoch": 29, "training_loss": 101.7725281715393, "training_acc": 80.0, "val_loss": 28.559154272079468, "val_acc": 64.0}
{"epoch": 30, "training_loss": 200.55254364013672, "training_acc": 62.0, "val_loss": 110.95064878463745, "val_acc": 72.0}
{"epoch": 31, "training_loss": 207.78686380386353, "training_acc": 73.0, "val_loss": 23.1327086687088, "val_acc": 68.0}
{"epoch": 32, "training_loss": 182.85148239135742, "training_acc": 70.0, "val_loss": 110.82499027252197, "val_acc": 72.0}
{"epoch": 33, "training_loss": 159.52644062042236, "training_acc": 76.0, "val_loss": 77.94440388679504, "val_acc": 48.0}
{"epoch": 34, "training_loss": 256.76746129989624, "training_acc": 70.0, "val_loss": 113.65805864334106, "val_acc": 72.0}
{"epoch": 35, "training_loss": 192.34149932861328, "training_acc": 79.0, "val_loss": 90.51756858825684, "val_acc": 44.0}
{"epoch": 36, "training_loss": 278.2693428993225, "training_acc": 60.0, "val_loss": 110.52188873291016, "val_acc": 72.0}
{"epoch": 37, "training_loss": 183.33018565177917, "training_acc": 80.0, "val_loss": 160.02448797225952, "val_acc": 36.0}
{"epoch": 38, "training_loss": 554.4628639221191, "training_acc": 47.0, "val_loss": 171.6799259185791, "val_acc": 72.0}
{"epoch": 39, "training_loss": 333.72766160964966, "training_acc": 76.0, "val_loss": 174.05409812927246, "val_acc": 36.0}
{"epoch": 40, "training_loss": 474.11222791671753, "training_acc": 58.0, "val_loss": 189.34016227722168, "val_acc": 72.0}
{"epoch": 41, "training_loss": 523.6143379211426, "training_acc": 74.0, "val_loss": 101.92161798477173, "val_acc": 72.0}
{"epoch": 42, "training_loss": 422.49238777160645, "training_acc": 74.0, "val_loss": 79.30516004562378, "val_acc": 68.0}
{"epoch": 43, "training_loss": 269.78259468078613, "training_acc": 75.0, "val_loss": 201.8939733505249, "val_acc": 72.0}
{"epoch": 44, "training_loss": 366.4743423461914, "training_acc": 77.0, "val_loss": 90.11032581329346, "val_acc": 68.0}
{"epoch": 45, "training_loss": 278.2905921936035, "training_acc": 65.0, "val_loss": 72.71427512168884, "val_acc": 68.0}
{"epoch": 46, "training_loss": 78.46905636787415, "training_acc": 87.0, "val_loss": 61.73244118690491, "val_acc": 56.0}
{"epoch": 47, "training_loss": 118.93825578689575, "training_acc": 76.0, "val_loss": 57.37881064414978, "val_acc": 68.0}
{"epoch": 48, "training_loss": 93.47377634048462, "training_acc": 77.0, "val_loss": 94.48464512825012, "val_acc": 72.0}
{"epoch": 49, "training_loss": 163.6160659790039, "training_acc": 79.0, "val_loss": 125.84023475646973, "val_acc": 44.0}
{"epoch": 50, "training_loss": 349.7222902774811, "training_acc": 60.0, "val_loss": 156.37667179107666, "val_acc": 72.0}
