"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3241.2748222351074, "training_acc": 38.0, "val_loss": 1317.3380851745605, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3882.826416015625, "training_acc": 72.0, "val_loss": 1040.4916763305664, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4045.1290130615234, "training_acc": 32.0, "val_loss": 244.59896087646484, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1314.5809631347656, "training_acc": 72.0, "val_loss": 781.2410831451416, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2762.7864151000977, "training_acc": 72.0, "val_loss": 529.7860622406006, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1547.7524662017822, "training_acc": 73.0, "val_loss": 472.4050045013428, "val_acc": 64.0}
{"epoch": 6, "training_loss": 1889.6950149536133, "training_acc": 52.0, "val_loss": 406.77995681762695, "val_acc": 64.0}
{"epoch": 7, "training_loss": 835.5552005767822, "training_acc": 69.0, "val_loss": 404.83360290527344, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1310.4791793823242, "training_acc": 72.0, "val_loss": 292.0806407928467, "val_acc": 72.0}
{"epoch": 9, "training_loss": 961.9661903381348, "training_acc": 70.0, "val_loss": 362.64052391052246, "val_acc": 68.0}
{"epoch": 10, "training_loss": 968.0919189453125, "training_acc": 57.0, "val_loss": 184.8819136619568, "val_acc": 72.0}
{"epoch": 11, "training_loss": 567.2584590911865, "training_acc": 73.0, "val_loss": 185.95305681228638, "val_acc": 76.0}
{"epoch": 12, "training_loss": 502.98263931274414, "training_acc": 70.0, "val_loss": 206.20896816253662, "val_acc": 56.0}
{"epoch": 13, "training_loss": 565.7683458328247, "training_acc": 60.0, "val_loss": 154.8911213874817, "val_acc": 72.0}
{"epoch": 14, "training_loss": 635.5249176025391, "training_acc": 72.0, "val_loss": 48.362043499946594, "val_acc": 72.0}
{"epoch": 15, "training_loss": 711.4289054870605, "training_acc": 59.0, "val_loss": 173.7167477607727, "val_acc": 36.0}
{"epoch": 16, "training_loss": 543.8784103393555, "training_acc": 60.0, "val_loss": 403.3811569213867, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1702.44921875, "training_acc": 72.0, "val_loss": 287.2626543045044, "val_acc": 72.0}
{"epoch": 18, "training_loss": 746.5386927127838, "training_acc": 77.0, "val_loss": 673.4148025512695, "val_acc": 28.0}
{"epoch": 19, "training_loss": 2342.6206130981445, "training_acc": 28.0, "val_loss": 72.75492548942566, "val_acc": 80.0}
{"epoch": 20, "training_loss": 477.60399627685547, "training_acc": 77.0, "val_loss": 406.19096755981445, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1475.8801918029785, "training_acc": 72.0, "val_loss": 190.92997312545776, "val_acc": 80.0}
{"epoch": 22, "training_loss": 660.1893491744995, "training_acc": 70.0, "val_loss": 342.8107738494873, "val_acc": 48.0}
{"epoch": 23, "training_loss": 1002.3250408172607, "training_acc": 59.0, "val_loss": 159.7198486328125, "val_acc": 72.0}
{"epoch": 24, "training_loss": 386.2116165161133, "training_acc": 76.0, "val_loss": 197.5987195968628, "val_acc": 76.0}
{"epoch": 25, "training_loss": 603.0135917663574, "training_acc": 74.0, "val_loss": 197.012197971344, "val_acc": 52.0}
{"epoch": 26, "training_loss": 649.3019561767578, "training_acc": 57.0, "val_loss": 124.94856119155884, "val_acc": 72.0}
{"epoch": 27, "training_loss": 502.0620365142822, "training_acc": 70.0, "val_loss": 163.7877106666565, "val_acc": 72.0}
{"epoch": 28, "training_loss": 461.40045976638794, "training_acc": 76.0, "val_loss": 185.9342336654663, "val_acc": 44.0}
{"epoch": 29, "training_loss": 433.0931806564331, "training_acc": 55.0, "val_loss": 122.08894491195679, "val_acc": 72.0}
{"epoch": 30, "training_loss": 633.4067077636719, "training_acc": 72.0, "val_loss": 65.03694653511047, "val_acc": 80.0}
{"epoch": 31, "training_loss": 431.656436920166, "training_acc": 62.0, "val_loss": 196.6386079788208, "val_acc": 44.0}
{"epoch": 32, "training_loss": 657.4587783813477, "training_acc": 51.0, "val_loss": 151.7895221710205, "val_acc": 72.0}
{"epoch": 33, "training_loss": 531.8159284591675, "training_acc": 74.0, "val_loss": 126.33637189865112, "val_acc": 56.0}
