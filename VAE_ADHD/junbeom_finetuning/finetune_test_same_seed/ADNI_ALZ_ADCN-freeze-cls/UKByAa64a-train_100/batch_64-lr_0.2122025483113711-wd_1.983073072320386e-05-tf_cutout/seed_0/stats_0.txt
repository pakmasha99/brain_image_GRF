"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 387.9498519897461, "training_acc": 72.0, "val_loss": 152.93874740600586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 417.56358432769775, "training_acc": 72.0, "val_loss": 236.41798496246338, "val_acc": 28.0}
{"epoch": 2, "training_loss": 987.4690589904785, "training_acc": 28.0, "val_loss": 43.04971694946289, "val_acc": 36.0}
{"epoch": 3, "training_loss": 263.525429725647, "training_acc": 52.0, "val_loss": 134.5237135887146, "val_acc": 72.0}
{"epoch": 4, "training_loss": 602.829402923584, "training_acc": 72.0, "val_loss": 176.48550271987915, "val_acc": 72.0}
{"epoch": 5, "training_loss": 702.6792039871216, "training_acc": 72.0, "val_loss": 125.65680742263794, "val_acc": 72.0}
{"epoch": 6, "training_loss": 434.46214866638184, "training_acc": 72.0, "val_loss": 21.255867183208466, "val_acc": 76.0}
{"epoch": 7, "training_loss": 259.57565116882324, "training_acc": 60.0, "val_loss": 62.117767333984375, "val_acc": 44.0}
{"epoch": 8, "training_loss": 409.4941453933716, "training_acc": 45.0, "val_loss": 17.848847806453705, "val_acc": 80.0}
{"epoch": 9, "training_loss": 178.60356760025024, "training_acc": 71.0, "val_loss": 54.07552123069763, "val_acc": 72.0}
{"epoch": 10, "training_loss": 229.8076524734497, "training_acc": 73.0, "val_loss": 54.83404994010925, "val_acc": 72.0}
{"epoch": 11, "training_loss": 179.1566710472107, "training_acc": 71.0, "val_loss": 14.952370524406433, "val_acc": 80.0}
{"epoch": 12, "training_loss": 129.4555778503418, "training_acc": 63.0, "val_loss": 24.327246844768524, "val_acc": 52.0}
{"epoch": 13, "training_loss": 106.8409481048584, "training_acc": 63.0, "val_loss": 38.12223970890045, "val_acc": 72.0}
{"epoch": 14, "training_loss": 148.4579153060913, "training_acc": 72.0, "val_loss": 35.94789505004883, "val_acc": 72.0}
{"epoch": 15, "training_loss": 87.33985948562622, "training_acc": 71.0, "val_loss": 39.62259888648987, "val_acc": 44.0}
{"epoch": 16, "training_loss": 134.75582838058472, "training_acc": 49.0, "val_loss": 25.02824068069458, "val_acc": 72.0}
{"epoch": 17, "training_loss": 85.52487897872925, "training_acc": 72.0, "val_loss": 27.000492811203003, "val_acc": 72.0}
{"epoch": 18, "training_loss": 66.80472147464752, "training_acc": 76.0, "val_loss": 25.32610297203064, "val_acc": 44.0}
{"epoch": 19, "training_loss": 85.32824802398682, "training_acc": 54.0, "val_loss": 20.844972133636475, "val_acc": 72.0}
{"epoch": 20, "training_loss": 83.47860836982727, "training_acc": 72.0, "val_loss": 22.617480158805847, "val_acc": 72.0}
{"epoch": 21, "training_loss": 66.32559561729431, "training_acc": 76.0, "val_loss": 25.468233227729797, "val_acc": 56.0}
{"epoch": 22, "training_loss": 116.71550798416138, "training_acc": 55.0, "val_loss": 12.536275386810303, "val_acc": 84.0}
{"epoch": 23, "training_loss": 69.68625736236572, "training_acc": 74.0, "val_loss": 31.231501698493958, "val_acc": 72.0}
{"epoch": 24, "training_loss": 101.81951093673706, "training_acc": 75.0, "val_loss": 13.50782960653305, "val_acc": 60.0}
{"epoch": 25, "training_loss": 84.58126878738403, "training_acc": 68.0, "val_loss": 10.979785770177841, "val_acc": 76.0}
{"epoch": 26, "training_loss": 54.061586141586304, "training_acc": 75.0, "val_loss": 26.022860407829285, "val_acc": 72.0}
{"epoch": 27, "training_loss": 79.78249895572662, "training_acc": 72.0, "val_loss": 20.81262469291687, "val_acc": 48.0}
{"epoch": 28, "training_loss": 78.7614004611969, "training_acc": 54.0, "val_loss": 18.593338131904602, "val_acc": 72.0}
{"epoch": 29, "training_loss": 73.59396409988403, "training_acc": 72.0, "val_loss": 19.65257227420807, "val_acc": 72.0}
{"epoch": 30, "training_loss": 67.14900922775269, "training_acc": 68.0, "val_loss": 17.90621280670166, "val_acc": 48.0}
{"epoch": 31, "training_loss": 65.60998463630676, "training_acc": 63.0, "val_loss": 19.39738094806671, "val_acc": 72.0}
{"epoch": 32, "training_loss": 53.3560870885849, "training_acc": 76.0, "val_loss": 16.498751938343048, "val_acc": 52.0}
{"epoch": 33, "training_loss": 58.13922357559204, "training_acc": 74.0, "val_loss": 16.009879112243652, "val_acc": 72.0}
{"epoch": 34, "training_loss": 57.08402180671692, "training_acc": 76.0, "val_loss": 15.06325751543045, "val_acc": 76.0}
{"epoch": 35, "training_loss": 48.1049302816391, "training_acc": 80.0, "val_loss": 17.355969548225403, "val_acc": 52.0}
{"epoch": 36, "training_loss": 50.44791579246521, "training_acc": 73.0, "val_loss": 19.983859360218048, "val_acc": 72.0}
{"epoch": 37, "training_loss": 62.43015933036804, "training_acc": 75.0, "val_loss": 11.925841867923737, "val_acc": 72.0}
{"epoch": 38, "training_loss": 48.68854880332947, "training_acc": 76.0, "val_loss": 12.621413171291351, "val_acc": 64.0}
{"epoch": 39, "training_loss": 53.20577263832092, "training_acc": 77.0, "val_loss": 17.73095279932022, "val_acc": 72.0}
{"epoch": 40, "training_loss": 51.93985867500305, "training_acc": 77.0, "val_loss": 18.779712915420532, "val_acc": 52.0}
{"epoch": 41, "training_loss": 65.10557246208191, "training_acc": 65.0, "val_loss": 15.225066244602203, "val_acc": 76.0}
{"epoch": 42, "training_loss": 56.54836702346802, "training_acc": 75.0, "val_loss": 13.503794372081757, "val_acc": 76.0}
{"epoch": 43, "training_loss": 49.63637149333954, "training_acc": 76.0, "val_loss": 12.839893996715546, "val_acc": 64.0}
{"epoch": 44, "training_loss": 46.371456146240234, "training_acc": 77.0, "val_loss": 16.097132861614227, "val_acc": 72.0}
