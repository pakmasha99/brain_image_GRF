"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 391.0457229614258, "training_acc": 60.0, "val_loss": 166.03344678878784, "val_acc": 72.0}
{"epoch": 1, "training_loss": 536.9698648452759, "training_acc": 72.0, "val_loss": 139.9599313735962, "val_acc": 28.0}
{"epoch": 2, "training_loss": 610.0356636047363, "training_acc": 29.0, "val_loss": 31.853601336479187, "val_acc": 72.0}
{"epoch": 3, "training_loss": 108.0457010269165, "training_acc": 80.0, "val_loss": 114.1892671585083, "val_acc": 72.0}
{"epoch": 4, "training_loss": 369.02873134613037, "training_acc": 72.0, "val_loss": 96.55579924583435, "val_acc": 72.0}
{"epoch": 5, "training_loss": 230.96325016021729, "training_acc": 69.0, "val_loss": 46.23117744922638, "val_acc": 64.0}
{"epoch": 6, "training_loss": 204.09545993804932, "training_acc": 57.0, "val_loss": 50.91972351074219, "val_acc": 60.0}
{"epoch": 7, "training_loss": 225.23929452896118, "training_acc": 64.0, "val_loss": 66.60682559013367, "val_acc": 72.0}
{"epoch": 8, "training_loss": 189.8597764968872, "training_acc": 72.0, "val_loss": 84.38719511032104, "val_acc": 72.0}
{"epoch": 9, "training_loss": 210.5124969482422, "training_acc": 73.0, "val_loss": 46.98895812034607, "val_acc": 72.0}
{"epoch": 10, "training_loss": 120.0976300239563, "training_acc": 72.0, "val_loss": 36.87823712825775, "val_acc": 60.0}
{"epoch": 11, "training_loss": 121.51544523239136, "training_acc": 64.0, "val_loss": 33.76661241054535, "val_acc": 76.0}
{"epoch": 12, "training_loss": 98.08828973770142, "training_acc": 75.0, "val_loss": 38.13184201717377, "val_acc": 72.0}
{"epoch": 13, "training_loss": 96.53807806968689, "training_acc": 71.0, "val_loss": 27.038076519966125, "val_acc": 36.0}
{"epoch": 14, "training_loss": 105.5042507648468, "training_acc": 54.0, "val_loss": 22.58172184228897, "val_acc": 72.0}
{"epoch": 15, "training_loss": 100.40878224372864, "training_acc": 72.0, "val_loss": 14.285492897033691, "val_acc": 72.0}
{"epoch": 16, "training_loss": 129.46343421936035, "training_acc": 45.0, "val_loss": 13.730807602405548, "val_acc": 64.0}
{"epoch": 17, "training_loss": 86.94224405288696, "training_acc": 72.0, "val_loss": 21.617402136325836, "val_acc": 72.0}
{"epoch": 18, "training_loss": 81.21519303321838, "training_acc": 73.0, "val_loss": 32.726967334747314, "val_acc": 32.0}
{"epoch": 19, "training_loss": 97.26440298557281, "training_acc": 52.0, "val_loss": 16.981425881385803, "val_acc": 76.0}
{"epoch": 20, "training_loss": 58.57067537307739, "training_acc": 73.0, "val_loss": 15.201091766357422, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.498592376708984, "training_acc": 78.0, "val_loss": 16.71990305185318, "val_acc": 68.0}
{"epoch": 22, "training_loss": 54.942102670669556, "training_acc": 76.0, "val_loss": 20.066669583320618, "val_acc": 76.0}
{"epoch": 23, "training_loss": 57.1796441078186, "training_acc": 76.0, "val_loss": 15.60816764831543, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.81726109981537, "training_acc": 74.0, "val_loss": 13.731174170970917, "val_acc": 76.0}
{"epoch": 25, "training_loss": 46.56886887550354, "training_acc": 80.0, "val_loss": 14.837536215782166, "val_acc": 80.0}
{"epoch": 26, "training_loss": 51.59824991226196, "training_acc": 74.0, "val_loss": 11.2339586019516, "val_acc": 68.0}
{"epoch": 27, "training_loss": 44.18387818336487, "training_acc": 79.0, "val_loss": 12.384428083896637, "val_acc": 56.0}
{"epoch": 28, "training_loss": 46.25987255573273, "training_acc": 78.0, "val_loss": 11.357072740793228, "val_acc": 88.0}
{"epoch": 29, "training_loss": 48.5794221162796, "training_acc": 71.0, "val_loss": 11.142796277999878, "val_acc": 84.0}
{"epoch": 30, "training_loss": 40.85686779022217, "training_acc": 80.0, "val_loss": 11.76801398396492, "val_acc": 84.0}
{"epoch": 31, "training_loss": 38.081743597984314, "training_acc": 81.0, "val_loss": 12.470642477273941, "val_acc": 80.0}
{"epoch": 32, "training_loss": 36.159839272499084, "training_acc": 81.0, "val_loss": 14.470560848712921, "val_acc": 76.0}
{"epoch": 33, "training_loss": 36.90604650974274, "training_acc": 80.0, "val_loss": 14.312584698200226, "val_acc": 80.0}
{"epoch": 34, "training_loss": 42.24398386478424, "training_acc": 81.0, "val_loss": 17.64865517616272, "val_acc": 80.0}
{"epoch": 35, "training_loss": 41.834155678749084, "training_acc": 79.0, "val_loss": 14.289999008178711, "val_acc": 80.0}
{"epoch": 36, "training_loss": 37.44325411319733, "training_acc": 81.0, "val_loss": 13.997061550617218, "val_acc": 80.0}
{"epoch": 37, "training_loss": 46.30701231956482, "training_acc": 78.0, "val_loss": 13.528166711330414, "val_acc": 60.0}
{"epoch": 38, "training_loss": 50.57261562347412, "training_acc": 75.0, "val_loss": 20.373380184173584, "val_acc": 72.0}
{"epoch": 39, "training_loss": 70.76757383346558, "training_acc": 73.0, "val_loss": 12.697753310203552, "val_acc": 76.0}
{"epoch": 40, "training_loss": 51.16779708862305, "training_acc": 75.0, "val_loss": 12.463746964931488, "val_acc": 80.0}
{"epoch": 41, "training_loss": 42.92478394508362, "training_acc": 81.0, "val_loss": 16.24080240726471, "val_acc": 76.0}
{"epoch": 42, "training_loss": 42.11521911621094, "training_acc": 79.0, "val_loss": 14.740094542503357, "val_acc": 60.0}
{"epoch": 43, "training_loss": 48.4442640542984, "training_acc": 72.0, "val_loss": 18.673910200595856, "val_acc": 76.0}
{"epoch": 44, "training_loss": 45.29780948162079, "training_acc": 79.0, "val_loss": 14.916424453258514, "val_acc": 60.0}
{"epoch": 45, "training_loss": 51.41790008544922, "training_acc": 73.0, "val_loss": 19.303356111049652, "val_acc": 72.0}
{"epoch": 46, "training_loss": 52.468990087509155, "training_acc": 75.0, "val_loss": 12.051618099212646, "val_acc": 76.0}
{"epoch": 47, "training_loss": 37.780858635902405, "training_acc": 81.0, "val_loss": 16.900528967380524, "val_acc": 76.0}
{"epoch": 48, "training_loss": 44.64699423313141, "training_acc": 77.0, "val_loss": 12.009166181087494, "val_acc": 68.0}
