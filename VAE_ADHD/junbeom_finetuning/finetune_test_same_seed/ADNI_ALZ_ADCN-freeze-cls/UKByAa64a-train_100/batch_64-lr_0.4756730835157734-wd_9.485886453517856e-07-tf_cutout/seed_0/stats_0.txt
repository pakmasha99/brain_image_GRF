"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 814.716480255127, "training_acc": 72.0, "val_loss": 341.6792869567871, "val_acc": 72.0}
{"epoch": 1, "training_loss": 931.5164127349854, "training_acc": 72.0, "val_loss": 533.2305908203125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2231.204002380371, "training_acc": 28.0, "val_loss": 96.99578881263733, "val_acc": 36.0}
{"epoch": 3, "training_loss": 591.9728775024414, "training_acc": 51.0, "val_loss": 304.09719944000244, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1367.058967590332, "training_acc": 72.0, "val_loss": 404.66980934143066, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1614.4201965332031, "training_acc": 72.0, "val_loss": 297.3891019821167, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1042.2395286560059, "training_acc": 72.0, "val_loss": 61.33624315261841, "val_acc": 72.0}
{"epoch": 7, "training_loss": 555.1965827941895, "training_acc": 64.0, "val_loss": 124.16688203811646, "val_acc": 44.0}
{"epoch": 8, "training_loss": 888.1456089019775, "training_acc": 44.0, "val_loss": 40.5023992061615, "val_acc": 84.0}
{"epoch": 9, "training_loss": 407.97357082366943, "training_acc": 72.0, "val_loss": 107.98115730285645, "val_acc": 72.0}
{"epoch": 10, "training_loss": 474.6851291656494, "training_acc": 73.0, "val_loss": 123.93656969070435, "val_acc": 72.0}
{"epoch": 11, "training_loss": 397.74481105804443, "training_acc": 71.0, "val_loss": 26.790699362754822, "val_acc": 80.0}
{"epoch": 12, "training_loss": 268.68881130218506, "training_acc": 61.0, "val_loss": 46.33984565734863, "val_acc": 56.0}
{"epoch": 13, "training_loss": 200.88880896568298, "training_acc": 64.0, "val_loss": 85.51911115646362, "val_acc": 72.0}
{"epoch": 14, "training_loss": 320.95704078674316, "training_acc": 72.0, "val_loss": 69.91533637046814, "val_acc": 72.0}
{"epoch": 15, "training_loss": 158.17351174354553, "training_acc": 68.0, "val_loss": 63.97346258163452, "val_acc": 44.0}
{"epoch": 16, "training_loss": 202.20934391021729, "training_acc": 51.0, "val_loss": 41.045454144477844, "val_acc": 72.0}
{"epoch": 17, "training_loss": 104.46359276771545, "training_acc": 73.0, "val_loss": 19.68974471092224, "val_acc": 56.0}
{"epoch": 18, "training_loss": 65.4836015701294, "training_acc": 65.0, "val_loss": 14.1374871134758, "val_acc": 84.0}
{"epoch": 19, "training_loss": 61.24883532524109, "training_acc": 79.0, "val_loss": 12.27712407708168, "val_acc": 88.0}
{"epoch": 20, "training_loss": 48.83876276016235, "training_acc": 79.0, "val_loss": 10.90414822101593, "val_acc": 88.0}
{"epoch": 21, "training_loss": 44.97653293609619, "training_acc": 78.0, "val_loss": 20.858410000801086, "val_acc": 56.0}
{"epoch": 22, "training_loss": 73.32328343391418, "training_acc": 65.0, "val_loss": 14.24538940191269, "val_acc": 64.0}
{"epoch": 23, "training_loss": 62.564685583114624, "training_acc": 69.0, "val_loss": 12.438983470201492, "val_acc": 76.0}
{"epoch": 24, "training_loss": 54.883344888687134, "training_acc": 77.0, "val_loss": 16.354618966579437, "val_acc": 56.0}
{"epoch": 25, "training_loss": 45.18066215515137, "training_acc": 76.0, "val_loss": 21.830275654792786, "val_acc": 72.0}
{"epoch": 26, "training_loss": 66.11911451816559, "training_acc": 78.0, "val_loss": 27.31684446334839, "val_acc": 56.0}
{"epoch": 27, "training_loss": 93.80285835266113, "training_acc": 63.0, "val_loss": 21.284323930740356, "val_acc": 72.0}
{"epoch": 28, "training_loss": 67.53401708602905, "training_acc": 72.0, "val_loss": 12.291320413351059, "val_acc": 72.0}
{"epoch": 29, "training_loss": 42.48096513748169, "training_acc": 81.0, "val_loss": 13.81283849477768, "val_acc": 76.0}
{"epoch": 30, "training_loss": 45.16733932495117, "training_acc": 76.0, "val_loss": 26.567450165748596, "val_acc": 72.0}
{"epoch": 31, "training_loss": 68.19818043708801, "training_acc": 73.0, "val_loss": 41.049301624298096, "val_acc": 44.0}
{"epoch": 32, "training_loss": 102.84313404560089, "training_acc": 62.0, "val_loss": 28.63367199897766, "val_acc": 72.0}
{"epoch": 33, "training_loss": 66.54757535457611, "training_acc": 77.0, "val_loss": 15.876948833465576, "val_acc": 64.0}
{"epoch": 34, "training_loss": 64.59465837478638, "training_acc": 77.0, "val_loss": 17.970095574855804, "val_acc": 76.0}
{"epoch": 35, "training_loss": 50.535430788993835, "training_acc": 78.0, "val_loss": 12.927834689617157, "val_acc": 68.0}
{"epoch": 36, "training_loss": 32.72761845588684, "training_acc": 85.0, "val_loss": 14.457960426807404, "val_acc": 72.0}
{"epoch": 37, "training_loss": 29.752055287361145, "training_acc": 86.0, "val_loss": 14.555691182613373, "val_acc": 64.0}
{"epoch": 38, "training_loss": 44.39828181266785, "training_acc": 83.0, "val_loss": 12.887372076511383, "val_acc": 72.0}
{"epoch": 39, "training_loss": 30.278995394706726, "training_acc": 89.0, "val_loss": 12.818998098373413, "val_acc": 68.0}
