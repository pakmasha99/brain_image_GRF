"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 622.3930435180664, "training_acc": 70.0, "val_loss": 379.11949157714844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1141.7371835708618, "training_acc": 72.0, "val_loss": 559.2596530914307, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1951.1871948242188, "training_acc": 28.0, "val_loss": 40.19306004047394, "val_acc": 56.0}
{"epoch": 3, "training_loss": 283.99914360046387, "training_acc": 72.0, "val_loss": 238.444185256958, "val_acc": 72.0}
{"epoch": 4, "training_loss": 910.5017242431641, "training_acc": 72.0, "val_loss": 180.97667694091797, "val_acc": 72.0}
{"epoch": 5, "training_loss": 548.5601234436035, "training_acc": 74.0, "val_loss": 112.13245391845703, "val_acc": 56.0}
{"epoch": 6, "training_loss": 540.2182750701904, "training_acc": 55.0, "val_loss": 177.03133821487427, "val_acc": 60.0}
{"epoch": 7, "training_loss": 623.7320680618286, "training_acc": 50.0, "val_loss": 97.28530049324036, "val_acc": 76.0}
{"epoch": 8, "training_loss": 487.67087745666504, "training_acc": 73.0, "val_loss": 190.512216091156, "val_acc": 72.0}
{"epoch": 9, "training_loss": 720.8104438781738, "training_acc": 72.0, "val_loss": 107.46879577636719, "val_acc": 80.0}
{"epoch": 10, "training_loss": 326.58270740509033, "training_acc": 73.0, "val_loss": 132.80324935913086, "val_acc": 60.0}
{"epoch": 11, "training_loss": 597.6869812011719, "training_acc": 50.0, "val_loss": 86.44861578941345, "val_acc": 56.0}
{"epoch": 12, "training_loss": 247.70144081115723, "training_acc": 64.0, "val_loss": 90.0356113910675, "val_acc": 76.0}
{"epoch": 13, "training_loss": 393.28384494781494, "training_acc": 72.0, "val_loss": 85.15186309814453, "val_acc": 72.0}
{"epoch": 14, "training_loss": 312.18816447257996, "training_acc": 72.0, "val_loss": 63.96614909172058, "val_acc": 52.0}
{"epoch": 15, "training_loss": 240.35925388336182, "training_acc": 56.0, "val_loss": 20.68786919116974, "val_acc": 68.0}
{"epoch": 16, "training_loss": 123.80424547195435, "training_acc": 78.0, "val_loss": 63.94578218460083, "val_acc": 72.0}
{"epoch": 17, "training_loss": 190.8644347190857, "training_acc": 74.0, "val_loss": 44.92169916629791, "val_acc": 48.0}
{"epoch": 18, "training_loss": 160.87054204940796, "training_acc": 51.0, "val_loss": 44.051095843315125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 164.76844692230225, "training_acc": 72.0, "val_loss": 41.46404266357422, "val_acc": 72.0}
{"epoch": 20, "training_loss": 119.65409088134766, "training_acc": 68.0, "val_loss": 36.79463565349579, "val_acc": 44.0}
{"epoch": 21, "training_loss": 99.01264369487762, "training_acc": 67.0, "val_loss": 56.54054880142212, "val_acc": 72.0}
{"epoch": 22, "training_loss": 155.04355645179749, "training_acc": 74.0, "val_loss": 23.112620413303375, "val_acc": 60.0}
{"epoch": 23, "training_loss": 109.61720037460327, "training_acc": 64.0, "val_loss": 23.25069010257721, "val_acc": 72.0}
{"epoch": 24, "training_loss": 73.37334179878235, "training_acc": 79.0, "val_loss": 59.579265117645264, "val_acc": 72.0}
{"epoch": 25, "training_loss": 136.27312588691711, "training_acc": 73.0, "val_loss": 35.12087166309357, "val_acc": 52.0}
{"epoch": 26, "training_loss": 90.24834406375885, "training_acc": 66.0, "val_loss": 30.980587005615234, "val_acc": 76.0}
{"epoch": 27, "training_loss": 62.09351563453674, "training_acc": 79.0, "val_loss": 23.000232875347137, "val_acc": 48.0}
{"epoch": 28, "training_loss": 39.30069696903229, "training_acc": 81.0, "val_loss": 24.817271530628204, "val_acc": 68.0}
{"epoch": 29, "training_loss": 35.17261624336243, "training_acc": 80.0, "val_loss": 29.20224368572235, "val_acc": 40.0}
{"epoch": 30, "training_loss": 44.39881134033203, "training_acc": 81.0, "val_loss": 26.782989501953125, "val_acc": 72.0}
{"epoch": 31, "training_loss": 61.21055603027344, "training_acc": 76.0, "val_loss": 26.898014545440674, "val_acc": 76.0}
{"epoch": 32, "training_loss": 42.84464395046234, "training_acc": 80.0, "val_loss": 23.996150493621826, "val_acc": 48.0}
{"epoch": 33, "training_loss": 44.417280316352844, "training_acc": 79.0, "val_loss": 26.257333159446716, "val_acc": 76.0}
{"epoch": 34, "training_loss": 45.39746713638306, "training_acc": 78.0, "val_loss": 21.938705444335938, "val_acc": 56.0}
