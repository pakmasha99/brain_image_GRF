"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10293.642595291138, "training_acc": 72.0, "val_loss": 5321.538925170898, "val_acc": 28.0}
{"epoch": 1, "training_loss": 17219.15478515625, "training_acc": 32.0, "val_loss": 2564.4582748413086, "val_acc": 72.0}
{"epoch": 2, "training_loss": 14114.33251953125, "training_acc": 72.0, "val_loss": 3930.791473388672, "val_acc": 72.0}
{"epoch": 3, "training_loss": 11423.115966796875, "training_acc": 72.0, "val_loss": 2237.1816635131836, "val_acc": 28.0}
{"epoch": 4, "training_loss": 13604.315185546875, "training_acc": 28.0, "val_loss": 316.4149045944214, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3232.2530517578125, "training_acc": 72.0, "val_loss": 1496.3664054870605, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4933.64599609375, "training_acc": 72.0, "val_loss": 1181.9781303405762, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3282.588165283203, "training_acc": 50.0, "val_loss": 651.9141674041748, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2269.2851905822754, "training_acc": 52.0, "val_loss": 597.4097728729248, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3566.842529296875, "training_acc": 72.0, "val_loss": 452.2387504577637, "val_acc": 72.0}
{"epoch": 10, "training_loss": 602.9634189605713, "training_acc": 63.0, "val_loss": 778.0076503753662, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4435.2669677734375, "training_acc": 72.0, "val_loss": 1196.6853141784668, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3146.957550048828, "training_acc": 70.0, "val_loss": 1323.7936973571777, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2195.396739959717, "training_acc": 62.0, "val_loss": 280.9237003326416, "val_acc": 72.0}
{"epoch": 14, "training_loss": 877.7226010503291, "training_acc": 60.0, "val_loss": 39.85280394554138, "val_acc": 76.0}
{"epoch": 15, "training_loss": 980.008731842041, "training_acc": 60.0, "val_loss": 302.63545513153076, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1514.6053009033203, "training_acc": 50.0, "val_loss": 184.4407558441162, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1351.0008354187012, "training_acc": 52.0, "val_loss": 990.8228874206543, "val_acc": 28.0}
{"epoch": 18, "training_loss": 3107.7295837402344, "training_acc": 40.0, "val_loss": 1022.7557182312012, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3128.4173889160156, "training_acc": 72.0, "val_loss": 2215.4970169067383, "val_acc": 28.0}
{"epoch": 20, "training_loss": 8451.675350189209, "training_acc": 30.0, "val_loss": 1102.7030944824219, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5204.388092041016, "training_acc": 72.0, "val_loss": 802.3311614990234, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3720.1851119995117, "training_acc": 59.0, "val_loss": 1419.9480056762695, "val_acc": 28.0}
{"epoch": 23, "training_loss": 3624.710418701172, "training_acc": 58.0, "val_loss": 926.422119140625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2722.0988159179688, "training_acc": 58.0, "val_loss": 42.56939888000488, "val_acc": 76.0}
{"epoch": 25, "training_loss": 715.0772457122803, "training_acc": 73.0, "val_loss": 631.740140914917, "val_acc": 28.0}
{"epoch": 26, "training_loss": 2173.185287475586, "training_acc": 44.0, "val_loss": 1634.5500946044922, "val_acc": 72.0}
{"epoch": 27, "training_loss": 6065.59342956543, "training_acc": 72.0, "val_loss": 265.9945011138916, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4580.238851547241, "training_acc": 42.0, "val_loss": 800.2180099487305, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4433.42643737793, "training_acc": 72.0, "val_loss": 1397.5485801696777, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3234.0615005493164, "training_acc": 72.0, "val_loss": 1698.3877182006836, "val_acc": 28.0}
{"epoch": 31, "training_loss": 4009.510284423828, "training_acc": 46.0, "val_loss": 1699.6650695800781, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6312.432357788086, "training_acc": 72.0, "val_loss": 461.6579532623291, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2409.704765319824, "training_acc": 48.0, "val_loss": 493.85838508605957, "val_acc": 72.0}
