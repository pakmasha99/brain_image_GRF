"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10216.26639175415, "training_acc": 58.0, "val_loss": 971.949577331543, "val_acc": 28.0}
{"epoch": 1, "training_loss": 3785.4144592285156, "training_acc": 56.0, "val_loss": 1428.7808418273926, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4657.912246704102, "training_acc": 38.0, "val_loss": 1780.252456665039, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5873.301856994629, "training_acc": 72.0, "val_loss": 1396.553897857666, "val_acc": 28.0}
{"epoch": 4, "training_loss": 3730.532371520996, "training_acc": 46.0, "val_loss": 501.1514186859131, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2060.966572523117, "training_acc": 55.0, "val_loss": 47.43102490901947, "val_acc": 72.0}
{"epoch": 6, "training_loss": 881.6274566650391, "training_acc": 66.0, "val_loss": 124.2046594619751, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3323.8893432617188, "training_acc": 46.0, "val_loss": 223.20797443389893, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1201.5202293395996, "training_acc": 64.0, "val_loss": 297.96268939971924, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1589.6513395309448, "training_acc": 69.0, "val_loss": 270.5491781234741, "val_acc": 72.0}
{"epoch": 10, "training_loss": 868.9799652099609, "training_acc": 70.0, "val_loss": 271.27184867858887, "val_acc": 28.0}
{"epoch": 11, "training_loss": 3496.1676025390625, "training_acc": 54.0, "val_loss": 1319.4860458374023, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3604.6150817871094, "training_acc": 68.0, "val_loss": 1553.773021697998, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3136.118453979492, "training_acc": 58.0, "val_loss": 571.1995601654053, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2012.7073516845703, "training_acc": 56.0, "val_loss": 554.954719543457, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3789.25341796875, "training_acc": 72.0, "val_loss": 758.7732791900635, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3384.191162109375, "training_acc": 52.0, "val_loss": 58.6198091506958, "val_acc": 72.0}
{"epoch": 17, "training_loss": 870.3683471679688, "training_acc": 72.0, "val_loss": 905.4983139038086, "val_acc": 28.0}
{"epoch": 18, "training_loss": 2820.5494995117188, "training_acc": 42.0, "val_loss": 1122.1844673156738, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4375.238845825195, "training_acc": 72.0, "val_loss": 38.860443234443665, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1564.7385787963867, "training_acc": 44.0, "val_loss": 1054.8869132995605, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3885.4052124023438, "training_acc": 72.0, "val_loss": 475.4373073577881, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1901.3051834106445, "training_acc": 44.0, "val_loss": 1009.9285125732422, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2990.0656337738037, "training_acc": 72.0, "val_loss": 2299.665069580078, "val_acc": 28.0}
{"epoch": 24, "training_loss": 9290.416961669922, "training_acc": 28.0, "val_loss": 785.6057167053223, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3682.1058349609375, "training_acc": 72.0, "val_loss": 50.68811774253845, "val_acc": 76.0}
{"epoch": 26, "training_loss": 5150.821071624756, "training_acc": 45.0, "val_loss": 715.4220581054688, "val_acc": 72.0}
{"epoch": 27, "training_loss": 5889.809814453125, "training_acc": 72.0, "val_loss": 1617.000389099121, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4318.830680847168, "training_acc": 70.0, "val_loss": 474.21398162841797, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1938.4010620117188, "training_acc": 58.0, "val_loss": 511.2721920013428, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2333.176582336426, "training_acc": 52.0, "val_loss": 292.16740131378174, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1284.4858379364014, "training_acc": 71.0, "val_loss": 83.5772693157196, "val_acc": 52.0}
{"epoch": 32, "training_loss": 354.75819396972656, "training_acc": 74.0, "val_loss": 409.36036109924316, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1835.3975448608398, "training_acc": 72.0, "val_loss": 876.2048721313477, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2405.5577392578125, "training_acc": 46.0, "val_loss": 1439.9415016174316, "val_acc": 72.0}
{"epoch": 35, "training_loss": 6060.125915527344, "training_acc": 72.0, "val_loss": 361.9091033935547, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4196.166206359863, "training_acc": 46.0, "val_loss": 752.4697303771973, "val_acc": 72.0}
{"epoch": 37, "training_loss": 5240.216064453125, "training_acc": 72.0, "val_loss": 1585.0006103515625, "val_acc": 72.0}
{"epoch": 38, "training_loss": 4138.696594238281, "training_acc": 70.0, "val_loss": 1877.3693084716797, "val_acc": 28.0}
