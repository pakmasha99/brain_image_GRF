"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8563.592575073242, "training_acc": 62.0, "val_loss": 3715.863037109375, "val_acc": 28.0}
{"epoch": 1, "training_loss": 10212.677574157715, "training_acc": 36.0, "val_loss": 929.5805931091309, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3126.6521003246307, "training_acc": 54.0, "val_loss": 427.3923873901367, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1165.4827117919922, "training_acc": 72.0, "val_loss": 1388.5026931762695, "val_acc": 28.0}
{"epoch": 4, "training_loss": 3549.628349304199, "training_acc": 54.0, "val_loss": 549.2379665374756, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2605.357177734375, "training_acc": 60.0, "val_loss": 433.2605838775635, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4205.437347412109, "training_acc": 72.0, "val_loss": 970.8566665649414, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3357.461883544922, "training_acc": 60.0, "val_loss": 578.602409362793, "val_acc": 28.0}
{"epoch": 8, "training_loss": 3019.3546752929688, "training_acc": 62.0, "val_loss": 1876.0490417480469, "val_acc": 72.0}
{"epoch": 9, "training_loss": 7061.572998046875, "training_acc": 72.0, "val_loss": 479.0419101715088, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1560.418601989746, "training_acc": 46.0, "val_loss": 1004.7201156616211, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4021.7895126342773, "training_acc": 72.0, "val_loss": 217.21343994140625, "val_acc": 28.0}
{"epoch": 12, "training_loss": 701.8004188537598, "training_acc": 38.0, "val_loss": 678.2798290252686, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2231.6756286621094, "training_acc": 68.0, "val_loss": 43.640878796577454, "val_acc": 76.0}
{"epoch": 14, "training_loss": 614.586109161377, "training_acc": 71.0, "val_loss": 174.39587116241455, "val_acc": 72.0}
{"epoch": 15, "training_loss": 538.383394241333, "training_acc": 71.0, "val_loss": 203.15535068511963, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1013.9134759902954, "training_acc": 72.0, "val_loss": 73.94816279411316, "val_acc": 72.0}
{"epoch": 17, "training_loss": 369.9926199913025, "training_acc": 73.0, "val_loss": 534.2791557312012, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1592.168098449707, "training_acc": 54.0, "val_loss": 617.0766353607178, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1387.2030067443848, "training_acc": 48.0, "val_loss": 335.64863204956055, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1659.6841220855713, "training_acc": 72.0, "val_loss": 1727.5859832763672, "val_acc": 28.0}
{"epoch": 21, "training_loss": 5421.326919555664, "training_acc": 30.0, "val_loss": 1890.1313781738281, "val_acc": 72.0}
{"epoch": 22, "training_loss": 9523.073852539062, "training_acc": 72.0, "val_loss": 2522.5494384765625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 7990.4158935546875, "training_acc": 72.0, "val_loss": 150.74026584625244, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2029.0169372558594, "training_acc": 28.0, "val_loss": 1261.3283157348633, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5049.496887207031, "training_acc": 72.0, "val_loss": 143.19615364074707, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5352.055740356445, "training_acc": 46.0, "val_loss": 596.691083908081, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4631.940811157227, "training_acc": 72.0, "val_loss": 1621.851921081543, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4749.780517578125, "training_acc": 68.0, "val_loss": 182.51982927322388, "val_acc": 28.0}
{"epoch": 29, "training_loss": 3680.6566772460938, "training_acc": 54.0, "val_loss": 1198.1724739074707, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2552.4734802246094, "training_acc": 62.0, "val_loss": 361.75005435943604, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2226.3544921875, "training_acc": 72.0, "val_loss": 576.1636257171631, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2054.3818969726562, "training_acc": 44.0, "val_loss": 1016.5193557739258, "val_acc": 72.0}
