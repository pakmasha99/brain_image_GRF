"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 495.89197540283203, "training_acc": 49.0, "val_loss": 316.4068937301636, "val_acc": 72.0}
{"epoch": 1, "training_loss": 985.4006385803223, "training_acc": 72.0, "val_loss": 76.62850022315979, "val_acc": 36.0}
{"epoch": 2, "training_loss": 345.0127420425415, "training_acc": 35.0, "val_loss": 68.1397795677185, "val_acc": 72.0}
{"epoch": 3, "training_loss": 312.3330726623535, "training_acc": 72.0, "val_loss": 91.93612337112427, "val_acc": 72.0}
{"epoch": 4, "training_loss": 231.20874118804932, "training_acc": 74.0, "val_loss": 66.37826561927795, "val_acc": 44.0}
{"epoch": 5, "training_loss": 379.74560356140137, "training_acc": 42.0, "val_loss": 38.41025531291962, "val_acc": 72.0}
{"epoch": 6, "training_loss": 152.8405385017395, "training_acc": 72.0, "val_loss": 108.90779495239258, "val_acc": 72.0}
{"epoch": 7, "training_loss": 367.3679847717285, "training_acc": 72.0, "val_loss": 57.00482726097107, "val_acc": 76.0}
{"epoch": 8, "training_loss": 143.79655694961548, "training_acc": 70.0, "val_loss": 65.97505807876587, "val_acc": 40.0}
{"epoch": 9, "training_loss": 258.80027055740356, "training_acc": 54.0, "val_loss": 50.89616775512695, "val_acc": 68.0}
{"epoch": 10, "training_loss": 151.1535940170288, "training_acc": 72.0, "val_loss": 51.09838843345642, "val_acc": 72.0}
{"epoch": 11, "training_loss": 114.66065168380737, "training_acc": 76.0, "val_loss": 35.96372902393341, "val_acc": 48.0}
{"epoch": 12, "training_loss": 130.70456647872925, "training_acc": 57.0, "val_loss": 33.74037146568298, "val_acc": 64.0}
{"epoch": 13, "training_loss": 72.50606083869934, "training_acc": 75.0, "val_loss": 24.25723522901535, "val_acc": 56.0}
{"epoch": 14, "training_loss": 63.97469782829285, "training_acc": 68.0, "val_loss": 33.24252665042877, "val_acc": 72.0}
{"epoch": 15, "training_loss": 89.19426441192627, "training_acc": 72.0, "val_loss": 15.348869562149048, "val_acc": 64.0}
{"epoch": 16, "training_loss": 61.13906145095825, "training_acc": 67.0, "val_loss": 19.77069228887558, "val_acc": 72.0}
{"epoch": 17, "training_loss": 63.09305262565613, "training_acc": 75.0, "val_loss": 13.003328442573547, "val_acc": 84.0}
{"epoch": 18, "training_loss": 57.60528492927551, "training_acc": 69.0, "val_loss": 15.254780650138855, "val_acc": 76.0}
{"epoch": 19, "training_loss": 58.19158864021301, "training_acc": 80.0, "val_loss": 12.925919890403748, "val_acc": 80.0}
{"epoch": 20, "training_loss": 54.447524309158325, "training_acc": 77.0, "val_loss": 16.038091480731964, "val_acc": 72.0}
{"epoch": 21, "training_loss": 56.85690188407898, "training_acc": 74.0, "val_loss": 12.010853737592697, "val_acc": 72.0}
{"epoch": 22, "training_loss": 52.002710580825806, "training_acc": 73.0, "val_loss": 23.095057904720306, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.8535441160202, "training_acc": 79.0, "val_loss": 14.451058208942413, "val_acc": 68.0}
{"epoch": 24, "training_loss": 46.6908917427063, "training_acc": 75.0, "val_loss": 28.63982915878296, "val_acc": 72.0}
{"epoch": 25, "training_loss": 72.07587695121765, "training_acc": 74.0, "val_loss": 18.331235647201538, "val_acc": 56.0}
{"epoch": 26, "training_loss": 60.76925349235535, "training_acc": 70.0, "val_loss": 32.566794753074646, "val_acc": 72.0}
{"epoch": 27, "training_loss": 77.53865039348602, "training_acc": 72.0, "val_loss": 19.55522894859314, "val_acc": 60.0}
{"epoch": 28, "training_loss": 59.96257185935974, "training_acc": 67.0, "val_loss": 22.764261066913605, "val_acc": 72.0}
{"epoch": 29, "training_loss": 40.95146346092224, "training_acc": 82.0, "val_loss": 23.038898408412933, "val_acc": 52.0}
{"epoch": 30, "training_loss": 69.84556889533997, "training_acc": 71.0, "val_loss": 27.51377820968628, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.179922580718994, "training_acc": 78.0, "val_loss": 16.50291234254837, "val_acc": 68.0}
{"epoch": 32, "training_loss": 40.81934940814972, "training_acc": 83.0, "val_loss": 22.11872786283493, "val_acc": 72.0}
{"epoch": 33, "training_loss": 42.84405988454819, "training_acc": 81.0, "val_loss": 16.758140921592712, "val_acc": 60.0}
{"epoch": 34, "training_loss": 49.09524619579315, "training_acc": 73.0, "val_loss": 16.869407892227173, "val_acc": 72.0}
{"epoch": 35, "training_loss": 42.37658154964447, "training_acc": 83.0, "val_loss": 17.168113589286804, "val_acc": 72.0}
{"epoch": 36, "training_loss": 35.34131050109863, "training_acc": 83.0, "val_loss": 14.02987688779831, "val_acc": 60.0}
{"epoch": 37, "training_loss": 35.27270579338074, "training_acc": 84.0, "val_loss": 15.482425689697266, "val_acc": 72.0}
{"epoch": 38, "training_loss": 29.98056036233902, "training_acc": 85.0, "val_loss": 15.88853895664215, "val_acc": 72.0}
{"epoch": 39, "training_loss": 32.7927782535553, "training_acc": 89.0, "val_loss": 16.325972974300385, "val_acc": 72.0}
{"epoch": 40, "training_loss": 33.21484363079071, "training_acc": 84.0, "val_loss": 18.23911964893341, "val_acc": 72.0}
