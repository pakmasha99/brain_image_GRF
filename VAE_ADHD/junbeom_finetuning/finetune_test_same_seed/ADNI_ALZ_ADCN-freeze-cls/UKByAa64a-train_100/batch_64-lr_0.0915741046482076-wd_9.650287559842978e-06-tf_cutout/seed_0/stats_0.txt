"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 192.55740547180176, "training_acc": 72.0, "val_loss": 66.52926206588745, "val_acc": 72.0}
{"epoch": 1, "training_loss": 184.71644687652588, "training_acc": 72.0, "val_loss": 95.98260521888733, "val_acc": 28.0}
{"epoch": 2, "training_loss": 388.87188625335693, "training_acc": 28.0, "val_loss": 14.710120856761932, "val_acc": 52.0}
{"epoch": 3, "training_loss": 105.5427565574646, "training_acc": 57.0, "val_loss": 58.58098864555359, "val_acc": 72.0}
{"epoch": 4, "training_loss": 255.14875602722168, "training_acc": 72.0, "val_loss": 67.8688645362854, "val_acc": 72.0}
{"epoch": 5, "training_loss": 265.92104387283325, "training_acc": 72.0, "val_loss": 36.78309917449951, "val_acc": 72.0}
{"epoch": 6, "training_loss": 121.04891693592072, "training_acc": 73.0, "val_loss": 15.311744809150696, "val_acc": 64.0}
{"epoch": 7, "training_loss": 159.9381618499756, "training_acc": 52.0, "val_loss": 22.94258326292038, "val_acc": 44.0}
{"epoch": 8, "training_loss": 150.82153964042664, "training_acc": 54.0, "val_loss": 16.906188428401947, "val_acc": 72.0}
{"epoch": 9, "training_loss": 89.23618769645691, "training_acc": 71.0, "val_loss": 31.887400150299072, "val_acc": 72.0}
{"epoch": 10, "training_loss": 123.59387016296387, "training_acc": 72.0, "val_loss": 19.917938113212585, "val_acc": 72.0}
{"epoch": 11, "training_loss": 73.5272364616394, "training_acc": 75.0, "val_loss": 15.617212653160095, "val_acc": 56.0}
{"epoch": 12, "training_loss": 85.31637668609619, "training_acc": 59.0, "val_loss": 12.974351644515991, "val_acc": 68.0}
{"epoch": 13, "training_loss": 53.80084812641144, "training_acc": 77.0, "val_loss": 22.56949245929718, "val_acc": 72.0}
{"epoch": 14, "training_loss": 88.54270887374878, "training_acc": 72.0, "val_loss": 20.009776949882507, "val_acc": 72.0}
{"epoch": 15, "training_loss": 61.90888285636902, "training_acc": 73.0, "val_loss": 19.43361610174179, "val_acc": 48.0}
{"epoch": 16, "training_loss": 77.11515045166016, "training_acc": 49.0, "val_loss": 14.2129585146904, "val_acc": 60.0}
{"epoch": 17, "training_loss": 50.88431990146637, "training_acc": 78.0, "val_loss": 19.442756474018097, "val_acc": 72.0}
{"epoch": 18, "training_loss": 71.38846921920776, "training_acc": 72.0, "val_loss": 13.895677030086517, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.746342182159424, "training_acc": 67.0, "val_loss": 15.882368385791779, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.57362103462219, "training_acc": 69.0, "val_loss": 14.084644615650177, "val_acc": 72.0}
{"epoch": 21, "training_loss": 63.802929401397705, "training_acc": 72.0, "val_loss": 15.790984034538269, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.24669933319092, "training_acc": 72.0, "val_loss": 13.243673741817474, "val_acc": 60.0}
{"epoch": 23, "training_loss": 56.96222901344299, "training_acc": 73.0, "val_loss": 11.664676666259766, "val_acc": 76.0}
{"epoch": 24, "training_loss": 49.782357811927795, "training_acc": 74.0, "val_loss": 14.941953122615814, "val_acc": 72.0}
{"epoch": 25, "training_loss": 54.548073291778564, "training_acc": 76.0, "val_loss": 12.07413300871849, "val_acc": 80.0}
{"epoch": 26, "training_loss": 46.763967394828796, "training_acc": 80.0, "val_loss": 13.117919862270355, "val_acc": 64.0}
{"epoch": 27, "training_loss": 51.99623668193817, "training_acc": 77.0, "val_loss": 12.641195952892303, "val_acc": 80.0}
{"epoch": 28, "training_loss": 47.619638562202454, "training_acc": 78.0, "val_loss": 13.521398603916168, "val_acc": 72.0}
{"epoch": 29, "training_loss": 48.65802216529846, "training_acc": 75.0, "val_loss": 12.65401542186737, "val_acc": 68.0}
{"epoch": 30, "training_loss": 47.06432497501373, "training_acc": 77.0, "val_loss": 12.67848014831543, "val_acc": 76.0}
{"epoch": 31, "training_loss": 48.79538011550903, "training_acc": 75.0, "val_loss": 13.651512563228607, "val_acc": 72.0}
{"epoch": 32, "training_loss": 46.49296593666077, "training_acc": 77.0, "val_loss": 13.465447723865509, "val_acc": 64.0}
{"epoch": 33, "training_loss": 49.880786657333374, "training_acc": 80.0, "val_loss": 12.854759395122528, "val_acc": 76.0}
{"epoch": 34, "training_loss": 49.776692152023315, "training_acc": 75.0, "val_loss": 14.375294744968414, "val_acc": 72.0}
{"epoch": 35, "training_loss": 47.670976996421814, "training_acc": 76.0, "val_loss": 13.218100368976593, "val_acc": 64.0}
{"epoch": 36, "training_loss": 48.821388483047485, "training_acc": 78.0, "val_loss": 12.036137282848358, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.08127188682556, "training_acc": 77.0, "val_loss": 13.604967296123505, "val_acc": 72.0}
{"epoch": 38, "training_loss": 44.920514702796936, "training_acc": 75.0, "val_loss": 12.782329320907593, "val_acc": 64.0}
{"epoch": 39, "training_loss": 50.24085092544556, "training_acc": 77.0, "val_loss": 11.696960031986237, "val_acc": 80.0}
{"epoch": 40, "training_loss": 49.055108308792114, "training_acc": 76.0, "val_loss": 12.824548780918121, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.29918646812439, "training_acc": 78.0, "val_loss": 12.406081706285477, "val_acc": 64.0}
{"epoch": 42, "training_loss": 48.246540784835815, "training_acc": 76.0, "val_loss": 12.184348702430725, "val_acc": 84.0}
