"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2942.061637878418, "training_acc": 72.0, "val_loss": 1404.853343963623, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4461.3451499938965, "training_acc": 72.0, "val_loss": 2098.5456466674805, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7748.644958496094, "training_acc": 28.0, "val_loss": 94.57093477249146, "val_acc": 72.0}
{"epoch": 3, "training_loss": 905.6576766967773, "training_acc": 72.0, "val_loss": 676.2233734130859, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2653.8699951171875, "training_acc": 72.0, "val_loss": 391.6740655899048, "val_acc": 72.0}
{"epoch": 5, "training_loss": 988.9226989746094, "training_acc": 58.0, "val_loss": 137.37035989761353, "val_acc": 28.0}
{"epoch": 6, "training_loss": 563.9014225006104, "training_acc": 52.0, "val_loss": 488.6952877044678, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1959.0357704162598, "training_acc": 72.0, "val_loss": 379.44111824035645, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1137.1877841949463, "training_acc": 72.0, "val_loss": 687.8046035766602, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2518.722267150879, "training_acc": 28.0, "val_loss": 167.68800020217896, "val_acc": 72.0}
{"epoch": 10, "training_loss": 895.688159942627, "training_acc": 72.0, "val_loss": 391.30797386169434, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1416.7457962036133, "training_acc": 72.0, "val_loss": 71.62384390830994, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1302.9363479614258, "training_acc": 54.0, "val_loss": 650.4060745239258, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1848.116449356079, "training_acc": 42.0, "val_loss": 283.0251693725586, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1217.8121871948242, "training_acc": 72.0, "val_loss": 239.43195343017578, "val_acc": 72.0}
{"epoch": 15, "training_loss": 615.1479239463806, "training_acc": 72.0, "val_loss": 732.191276550293, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2850.0732803344727, "training_acc": 28.0, "val_loss": 82.67952799797058, "val_acc": 72.0}
{"epoch": 17, "training_loss": 721.0112380981445, "training_acc": 72.0, "val_loss": 339.656925201416, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1236.0186405181885, "training_acc": 72.0, "val_loss": 55.63859939575195, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1155.2515029907227, "training_acc": 50.0, "val_loss": 435.20121574401855, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1324.216739654541, "training_acc": 46.0, "val_loss": 398.32763671875, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1709.5968856811523, "training_acc": 72.0, "val_loss": 433.6601257324219, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1458.964210510254, "training_acc": 72.0, "val_loss": 14.498117566108704, "val_acc": 60.0}
{"epoch": 23, "training_loss": 752.0309829711914, "training_acc": 59.0, "val_loss": 226.34994983673096, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1218.585678100586, "training_acc": 38.0, "val_loss": 541.0684585571289, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2285.322624206543, "training_acc": 72.0, "val_loss": 586.4824295043945, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2090.724380493164, "training_acc": 72.0, "val_loss": 163.76830339431763, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1246.5950012207031, "training_acc": 52.0, "val_loss": 514.9006843566895, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1471.9984788894653, "training_acc": 44.0, "val_loss": 235.08217334747314, "val_acc": 72.0}
{"epoch": 29, "training_loss": 906.8723049163818, "training_acc": 72.0, "val_loss": 153.1200885772705, "val_acc": 72.0}
{"epoch": 30, "training_loss": 638.3219108581543, "training_acc": 50.0, "val_loss": 95.88176608085632, "val_acc": 72.0}
{"epoch": 31, "training_loss": 390.862096786499, "training_acc": 72.0, "val_loss": 19.472837448120117, "val_acc": 76.0}
{"epoch": 32, "training_loss": 390.2535705566406, "training_acc": 62.0, "val_loss": 58.294838666915894, "val_acc": 72.0}
{"epoch": 33, "training_loss": 257.1656141281128, "training_acc": 72.0, "val_loss": 16.185878217220306, "val_acc": 76.0}
{"epoch": 34, "training_loss": 181.83320999145508, "training_acc": 55.0, "val_loss": 217.38674640655518, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1034.3419609069824, "training_acc": 72.0, "val_loss": 329.1102886199951, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1101.9721126556396, "training_acc": 72.0, "val_loss": 70.24056315422058, "val_acc": 28.0}
{"epoch": 37, "training_loss": 239.01023864746094, "training_acc": 46.0, "val_loss": 17.8126260638237, "val_acc": 76.0}
{"epoch": 38, "training_loss": 93.34214639663696, "training_acc": 65.0, "val_loss": 156.24514818191528, "val_acc": 72.0}
{"epoch": 39, "training_loss": 646.9656372070312, "training_acc": 72.0, "val_loss": 117.0249342918396, "val_acc": 72.0}
{"epoch": 40, "training_loss": 648.8659553527832, "training_acc": 52.0, "val_loss": 54.62979078292847, "val_acc": 72.0}
{"epoch": 41, "training_loss": 170.09510564804077, "training_acc": 73.0, "val_loss": 55.09410500526428, "val_acc": 28.0}
