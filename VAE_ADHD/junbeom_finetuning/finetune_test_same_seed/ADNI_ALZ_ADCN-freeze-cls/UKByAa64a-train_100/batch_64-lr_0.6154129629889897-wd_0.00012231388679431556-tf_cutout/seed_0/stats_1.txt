"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2153.4624214172363, "training_acc": 72.0, "val_loss": 1391.8145179748535, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3751.5533561706543, "training_acc": 72.0, "val_loss": 2647.0741271972656, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9968.3857421875, "training_acc": 28.0, "val_loss": 345.3505277633667, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1869.388168334961, "training_acc": 48.0, "val_loss": 1643.2703018188477, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6798.689987182617, "training_acc": 72.0, "val_loss": 2322.503089904785, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9387.625885009766, "training_acc": 72.0, "val_loss": 2291.463279724121, "val_acc": 72.0}
{"epoch": 6, "training_loss": 8839.390853881836, "training_acc": 72.0, "val_loss": 1632.308006286621, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5807.146728515625, "training_acc": 72.0, "val_loss": 519.2841053009033, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2407.8619232177734, "training_acc": 50.0, "val_loss": 984.4192504882812, "val_acc": 28.0}
{"epoch": 9, "training_loss": 3202.862449645996, "training_acc": 28.0, "val_loss": 307.81219005584717, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1691.9699249267578, "training_acc": 72.0, "val_loss": 799.0416049957275, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3182.3190383911133, "training_acc": 72.0, "val_loss": 707.4779510498047, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2541.2746505737305, "training_acc": 72.0, "val_loss": 199.55300092697144, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1437.77685546875, "training_acc": 52.0, "val_loss": 612.285852432251, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1409.2437040805817, "training_acc": 54.0, "val_loss": 222.15101718902588, "val_acc": 72.0}
{"epoch": 15, "training_loss": 956.9308471679688, "training_acc": 72.0, "val_loss": 218.83351802825928, "val_acc": 72.0}
{"epoch": 16, "training_loss": 615.9181680679321, "training_acc": 72.0, "val_loss": 612.4698162078857, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2249.409423828125, "training_acc": 28.0, "val_loss": 175.6335973739624, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1092.3390731811523, "training_acc": 72.0, "val_loss": 471.008825302124, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1792.6152420043945, "training_acc": 72.0, "val_loss": 235.67171096801758, "val_acc": 72.0}
{"epoch": 20, "training_loss": 702.0666637420654, "training_acc": 58.0, "val_loss": 13.034608960151672, "val_acc": 72.0}
{"epoch": 21, "training_loss": 85.16759634017944, "training_acc": 78.0, "val_loss": 52.57152318954468, "val_acc": 28.0}
{"epoch": 22, "training_loss": 384.42644691467285, "training_acc": 44.0, "val_loss": 252.1340847015381, "val_acc": 72.0}
{"epoch": 23, "training_loss": 921.772928237915, "training_acc": 72.0, "val_loss": 22.242465615272522, "val_acc": 72.0}
{"epoch": 24, "training_loss": 926.8563537597656, "training_acc": 54.0, "val_loss": 342.66295433044434, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1154.0232849121094, "training_acc": 46.0, "val_loss": 472.45397567749023, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2098.0450439453125, "training_acc": 72.0, "val_loss": 536.3629817962646, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1914.7806587219238, "training_acc": 72.0, "val_loss": 98.75304102897644, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1342.1860733032227, "training_acc": 52.0, "val_loss": 682.450532913208, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1646.5949903726578, "training_acc": 50.0, "val_loss": 265.3186559677124, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1197.470760345459, "training_acc": 72.0, "val_loss": 366.4205312728882, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1284.6232261657715, "training_acc": 72.0, "val_loss": 13.95682543516159, "val_acc": 72.0}
{"epoch": 32, "training_loss": 701.437915802002, "training_acc": 62.0, "val_loss": 179.46898937225342, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1051.0052642822266, "training_acc": 40.0, "val_loss": 577.9789447784424, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2440.072479248047, "training_acc": 72.0, "val_loss": 642.3708915710449, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2353.229507446289, "training_acc": 72.0, "val_loss": 238.3291721343994, "val_acc": 72.0}
{"epoch": 36, "training_loss": 753.9123477935791, "training_acc": 62.0, "val_loss": 262.95294761657715, "val_acc": 28.0}
{"epoch": 37, "training_loss": 735.0988779067993, "training_acc": 52.0, "val_loss": 306.97717666625977, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1266.8355598449707, "training_acc": 72.0, "val_loss": 239.01920318603516, "val_acc": 72.0}
{"epoch": 39, "training_loss": 770.90935754776, "training_acc": 69.0, "val_loss": 354.2070150375366, "val_acc": 28.0}
