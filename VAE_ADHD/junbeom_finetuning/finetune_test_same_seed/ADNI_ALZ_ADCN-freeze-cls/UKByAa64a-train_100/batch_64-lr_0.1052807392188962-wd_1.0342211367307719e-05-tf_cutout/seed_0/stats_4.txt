"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 249.60587692260742, "training_acc": 51.0, "val_loss": 78.5193920135498, "val_acc": 72.0}
{"epoch": 1, "training_loss": 241.86089420318604, "training_acc": 72.0, "val_loss": 66.72235131263733, "val_acc": 28.0}
{"epoch": 2, "training_loss": 294.27168464660645, "training_acc": 28.0, "val_loss": 16.23002588748932, "val_acc": 64.0}
{"epoch": 3, "training_loss": 80.45069885253906, "training_acc": 72.0, "val_loss": 56.04875683784485, "val_acc": 72.0}
{"epoch": 4, "training_loss": 203.37922954559326, "training_acc": 72.0, "val_loss": 50.032979249954224, "val_acc": 72.0}
{"epoch": 5, "training_loss": 138.5459907054901, "training_acc": 74.0, "val_loss": 22.113071382045746, "val_acc": 64.0}
{"epoch": 6, "training_loss": 116.19343042373657, "training_acc": 61.0, "val_loss": 27.176278829574585, "val_acc": 56.0}
{"epoch": 7, "training_loss": 141.9273853302002, "training_acc": 54.0, "val_loss": 26.400378346443176, "val_acc": 76.0}
{"epoch": 8, "training_loss": 84.87019681930542, "training_acc": 76.0, "val_loss": 36.241209506988525, "val_acc": 72.0}
{"epoch": 9, "training_loss": 103.92485857009888, "training_acc": 72.0, "val_loss": 23.474590480327606, "val_acc": 72.0}
{"epoch": 10, "training_loss": 69.76125240325928, "training_acc": 72.0, "val_loss": 17.78985559940338, "val_acc": 60.0}
{"epoch": 11, "training_loss": 77.08499670028687, "training_acc": 61.0, "val_loss": 15.132968127727509, "val_acc": 72.0}
{"epoch": 12, "training_loss": 57.049309492111206, "training_acc": 71.0, "val_loss": 17.384979128837585, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.77000415325165, "training_acc": 72.0, "val_loss": 15.348871052265167, "val_acc": 48.0}
{"epoch": 14, "training_loss": 59.95795130729675, "training_acc": 64.0, "val_loss": 13.065205514431, "val_acc": 76.0}
{"epoch": 15, "training_loss": 55.05126404762268, "training_acc": 72.0, "val_loss": 13.929632306098938, "val_acc": 72.0}
{"epoch": 16, "training_loss": 56.664450883865356, "training_acc": 72.0, "val_loss": 14.29472416639328, "val_acc": 48.0}
{"epoch": 17, "training_loss": 52.6937221288681, "training_acc": 82.0, "val_loss": 12.63115108013153, "val_acc": 72.0}
{"epoch": 18, "training_loss": 47.072712659835815, "training_acc": 77.0, "val_loss": 14.932654798030853, "val_acc": 76.0}
{"epoch": 19, "training_loss": 51.06056606769562, "training_acc": 73.0, "val_loss": 13.57952505350113, "val_acc": 68.0}
{"epoch": 20, "training_loss": 49.23519682884216, "training_acc": 79.0, "val_loss": 13.99414986371994, "val_acc": 68.0}
{"epoch": 21, "training_loss": 50.44572603702545, "training_acc": 76.0, "val_loss": 15.971404314041138, "val_acc": 76.0}
{"epoch": 22, "training_loss": 51.69017052650452, "training_acc": 75.0, "val_loss": 13.985766470432281, "val_acc": 72.0}
{"epoch": 23, "training_loss": 44.99107766151428, "training_acc": 79.0, "val_loss": 14.031738042831421, "val_acc": 64.0}
{"epoch": 24, "training_loss": 50.87555432319641, "training_acc": 73.0, "val_loss": 13.228797912597656, "val_acc": 76.0}
{"epoch": 25, "training_loss": 46.56602132320404, "training_acc": 78.0, "val_loss": 12.907440960407257, "val_acc": 76.0}
{"epoch": 26, "training_loss": 44.82099425792694, "training_acc": 79.0, "val_loss": 12.467391788959503, "val_acc": 72.0}
{"epoch": 27, "training_loss": 44.14497780799866, "training_acc": 81.0, "val_loss": 12.63892948627472, "val_acc": 80.0}
{"epoch": 28, "training_loss": 45.59076738357544, "training_acc": 76.0, "val_loss": 12.312260270118713, "val_acc": 80.0}
{"epoch": 29, "training_loss": 45.65576231479645, "training_acc": 78.0, "val_loss": 12.164207547903061, "val_acc": 80.0}
{"epoch": 30, "training_loss": 43.77531540393829, "training_acc": 79.0, "val_loss": 12.47907429933548, "val_acc": 76.0}
{"epoch": 31, "training_loss": 43.88770282268524, "training_acc": 81.0, "val_loss": 12.440992146730423, "val_acc": 76.0}
{"epoch": 32, "training_loss": 42.11845529079437, "training_acc": 80.0, "val_loss": 13.671241700649261, "val_acc": 76.0}
{"epoch": 33, "training_loss": 44.8792188167572, "training_acc": 78.0, "val_loss": 12.753337621688843, "val_acc": 76.0}
{"epoch": 34, "training_loss": 44.71430945396423, "training_acc": 82.0, "val_loss": 13.198338449001312, "val_acc": 76.0}
{"epoch": 35, "training_loss": 44.27963078022003, "training_acc": 76.0, "val_loss": 13.782958686351776, "val_acc": 76.0}
{"epoch": 36, "training_loss": 43.69622838497162, "training_acc": 80.0, "val_loss": 13.300889730453491, "val_acc": 68.0}
{"epoch": 37, "training_loss": 46.71610879898071, "training_acc": 79.0, "val_loss": 14.970332384109497, "val_acc": 76.0}
{"epoch": 38, "training_loss": 57.97554039955139, "training_acc": 75.0, "val_loss": 12.90077120065689, "val_acc": 76.0}
{"epoch": 39, "training_loss": 48.97203087806702, "training_acc": 71.0, "val_loss": 12.745121121406555, "val_acc": 72.0}
{"epoch": 40, "training_loss": 44.670422077178955, "training_acc": 79.0, "val_loss": 18.167375028133392, "val_acc": 72.0}
{"epoch": 41, "training_loss": 54.38470125198364, "training_acc": 73.0, "val_loss": 13.412390649318695, "val_acc": 52.0}
{"epoch": 42, "training_loss": 51.261101961135864, "training_acc": 72.0, "val_loss": 12.732970714569092, "val_acc": 80.0}
{"epoch": 43, "training_loss": 49.34917163848877, "training_acc": 78.0, "val_loss": 14.24657255411148, "val_acc": 76.0}
{"epoch": 44, "training_loss": 47.214481234550476, "training_acc": 76.0, "val_loss": 13.010573387145996, "val_acc": 68.0}
{"epoch": 45, "training_loss": 44.63378465175629, "training_acc": 78.0, "val_loss": 14.95160460472107, "val_acc": 76.0}
{"epoch": 46, "training_loss": 42.56040006875992, "training_acc": 80.0, "val_loss": 11.916671693325043, "val_acc": 80.0}
{"epoch": 47, "training_loss": 38.897552609443665, "training_acc": 83.0, "val_loss": 11.77731454372406, "val_acc": 80.0}
{"epoch": 48, "training_loss": 39.63415718078613, "training_acc": 84.0, "val_loss": 13.044622540473938, "val_acc": 80.0}
{"epoch": 49, "training_loss": 40.53704047203064, "training_acc": 82.0, "val_loss": 11.723291128873825, "val_acc": 80.0}
{"epoch": 50, "training_loss": 41.44374370574951, "training_acc": 82.0, "val_loss": 12.012551724910736, "val_acc": 80.0}
{"epoch": 51, "training_loss": 39.27377128601074, "training_acc": 79.0, "val_loss": 12.357623875141144, "val_acc": 80.0}
{"epoch": 52, "training_loss": 40.48400568962097, "training_acc": 82.0, "val_loss": 12.123949080705643, "val_acc": 72.0}
{"epoch": 53, "training_loss": 45.290130376815796, "training_acc": 77.0, "val_loss": 12.227458506822586, "val_acc": 84.0}
{"epoch": 54, "training_loss": 43.71188139915466, "training_acc": 80.0, "val_loss": 12.732656300067902, "val_acc": 80.0}
{"epoch": 55, "training_loss": 38.024364590644836, "training_acc": 79.0, "val_loss": 13.404886424541473, "val_acc": 80.0}
{"epoch": 56, "training_loss": 40.49750900268555, "training_acc": 82.0, "val_loss": 12.316515296697617, "val_acc": 80.0}
{"epoch": 57, "training_loss": 39.912214279174805, "training_acc": 82.0, "val_loss": 13.237148523330688, "val_acc": 80.0}
{"epoch": 58, "training_loss": 39.973254323005676, "training_acc": 78.0, "val_loss": 12.6931831240654, "val_acc": 80.0}
{"epoch": 59, "training_loss": 35.503191351890564, "training_acc": 86.0, "val_loss": 15.406841039657593, "val_acc": 80.0}
{"epoch": 60, "training_loss": 40.50166344642639, "training_acc": 79.0, "val_loss": 12.633897364139557, "val_acc": 76.0}
{"epoch": 61, "training_loss": 43.50626242160797, "training_acc": 77.0, "val_loss": 12.444520741701126, "val_acc": 80.0}
{"epoch": 62, "training_loss": 36.70454275608063, "training_acc": 86.0, "val_loss": 13.74625712633133, "val_acc": 80.0}
{"epoch": 63, "training_loss": 39.4599643945694, "training_acc": 82.0, "val_loss": 11.938653886318207, "val_acc": 80.0}
{"epoch": 64, "training_loss": 43.21143293380737, "training_acc": 82.0, "val_loss": 11.872482299804688, "val_acc": 88.0}
{"epoch": 65, "training_loss": 35.03719747066498, "training_acc": 89.0, "val_loss": 11.637838184833527, "val_acc": 80.0}
{"epoch": 66, "training_loss": 37.93569195270538, "training_acc": 85.0, "val_loss": 11.912200599908829, "val_acc": 88.0}
{"epoch": 67, "training_loss": 38.93671429157257, "training_acc": 86.0, "val_loss": 12.568898499011993, "val_acc": 84.0}
{"epoch": 68, "training_loss": 42.22136616706848, "training_acc": 77.0, "val_loss": 12.341035902500153, "val_acc": 88.0}
{"epoch": 69, "training_loss": 43.65642201900482, "training_acc": 79.0, "val_loss": 12.258370965719223, "val_acc": 80.0}
{"epoch": 70, "training_loss": 38.227035999298096, "training_acc": 85.0, "val_loss": 15.76245129108429, "val_acc": 76.0}
{"epoch": 71, "training_loss": 35.39824676513672, "training_acc": 81.0, "val_loss": 12.623710930347443, "val_acc": 76.0}
{"epoch": 72, "training_loss": 36.8173793554306, "training_acc": 83.0, "val_loss": 16.940903663635254, "val_acc": 76.0}
{"epoch": 73, "training_loss": 50.970486879348755, "training_acc": 77.0, "val_loss": 12.715338170528412, "val_acc": 80.0}
{"epoch": 74, "training_loss": 39.59440803527832, "training_acc": 78.0, "val_loss": 12.379499524831772, "val_acc": 76.0}
{"epoch": 75, "training_loss": 41.11784529685974, "training_acc": 80.0, "val_loss": 17.491789162158966, "val_acc": 72.0}
{"epoch": 76, "training_loss": 39.37607443332672, "training_acc": 78.0, "val_loss": 13.226434588432312, "val_acc": 60.0}
{"epoch": 77, "training_loss": 46.80152869224548, "training_acc": 78.0, "val_loss": 14.221575856208801, "val_acc": 80.0}
{"epoch": 78, "training_loss": 45.64211869239807, "training_acc": 77.0, "val_loss": 14.99439924955368, "val_acc": 76.0}
{"epoch": 79, "training_loss": 41.38352155685425, "training_acc": 77.0, "val_loss": 12.750464677810669, "val_acc": 60.0}
{"epoch": 80, "training_loss": 45.21162700653076, "training_acc": 71.0, "val_loss": 15.800192952156067, "val_acc": 76.0}
{"epoch": 81, "training_loss": 34.74072051048279, "training_acc": 82.0, "val_loss": 11.965715140104294, "val_acc": 80.0}
{"epoch": 82, "training_loss": 35.24127542972565, "training_acc": 85.0, "val_loss": 12.068532407283783, "val_acc": 80.0}
{"epoch": 83, "training_loss": 37.48038828372955, "training_acc": 86.0, "val_loss": 13.427524268627167, "val_acc": 80.0}
{"epoch": 84, "training_loss": 33.35644721984863, "training_acc": 85.0, "val_loss": 11.996405571699142, "val_acc": 80.0}
