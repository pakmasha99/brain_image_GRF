"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 214.759126663208, "training_acc": 72.0, "val_loss": 76.34578347206116, "val_acc": 72.0}
{"epoch": 1, "training_loss": 210.67890310287476, "training_acc": 72.0, "val_loss": 112.59030103683472, "val_acc": 28.0}
{"epoch": 2, "training_loss": 460.1843547821045, "training_acc": 28.0, "val_loss": 17.272526025772095, "val_acc": 44.0}
{"epoch": 3, "training_loss": 122.153076171875, "training_acc": 56.0, "val_loss": 67.41503477096558, "val_acc": 72.0}
{"epoch": 4, "training_loss": 296.0953674316406, "training_acc": 72.0, "val_loss": 81.13523721694946, "val_acc": 72.0}
{"epoch": 5, "training_loss": 319.49231719970703, "training_acc": 72.0, "val_loss": 48.41640889644623, "val_acc": 72.0}
{"epoch": 6, "training_loss": 158.4544062614441, "training_acc": 75.0, "val_loss": 12.761253118515015, "val_acc": 80.0}
{"epoch": 7, "training_loss": 167.6132984161377, "training_acc": 59.0, "val_loss": 30.286282300949097, "val_acc": 44.0}
{"epoch": 8, "training_loss": 188.20600986480713, "training_acc": 50.0, "val_loss": 14.180406928062439, "val_acc": 72.0}
{"epoch": 9, "training_loss": 92.9048204421997, "training_acc": 73.0, "val_loss": 35.23527383804321, "val_acc": 72.0}
{"epoch": 10, "training_loss": 139.83270025253296, "training_acc": 72.0, "val_loss": 25.370249152183533, "val_acc": 72.0}
{"epoch": 11, "training_loss": 87.4448983669281, "training_acc": 70.0, "val_loss": 14.373297989368439, "val_acc": 64.0}
{"epoch": 12, "training_loss": 89.51145267486572, "training_acc": 60.0, "val_loss": 14.443130791187286, "val_acc": 60.0}
{"epoch": 13, "training_loss": 61.36280024051666, "training_acc": 75.0, "val_loss": 23.804496228694916, "val_acc": 72.0}
{"epoch": 14, "training_loss": 95.23314237594604, "training_acc": 72.0, "val_loss": 22.94037789106369, "val_acc": 72.0}
{"epoch": 15, "training_loss": 68.07390904426575, "training_acc": 72.0, "val_loss": 20.30513286590576, "val_acc": 44.0}
{"epoch": 16, "training_loss": 82.00262713432312, "training_acc": 46.0, "val_loss": 14.470089972019196, "val_acc": 60.0}
{"epoch": 17, "training_loss": 51.39185619354248, "training_acc": 76.0, "val_loss": 21.447761356830597, "val_acc": 72.0}
{"epoch": 18, "training_loss": 76.73899793624878, "training_acc": 72.0, "val_loss": 13.889329135417938, "val_acc": 72.0}
{"epoch": 19, "training_loss": 61.40553689002991, "training_acc": 63.0, "val_loss": 16.663949191570282, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.81787300109863, "training_acc": 67.0, "val_loss": 15.775813162326813, "val_acc": 72.0}
{"epoch": 21, "training_loss": 69.55225992202759, "training_acc": 72.0, "val_loss": 15.811516344547272, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.29743027687073, "training_acc": 72.0, "val_loss": 14.689706265926361, "val_acc": 56.0}
{"epoch": 23, "training_loss": 62.3306565284729, "training_acc": 69.0, "val_loss": 11.518966406583786, "val_acc": 84.0}
{"epoch": 24, "training_loss": 50.16361212730408, "training_acc": 75.0, "val_loss": 15.705466270446777, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55.06670331954956, "training_acc": 76.0, "val_loss": 11.72064021229744, "val_acc": 80.0}
{"epoch": 26, "training_loss": 46.72674024105072, "training_acc": 76.0, "val_loss": 12.781397998332977, "val_acc": 64.0}
{"epoch": 27, "training_loss": 50.03263175487518, "training_acc": 73.0, "val_loss": 13.476112484931946, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.275768756866455, "training_acc": 77.0, "val_loss": 12.81227171421051, "val_acc": 76.0}
{"epoch": 29, "training_loss": 47.021148920059204, "training_acc": 80.0, "val_loss": 12.911322712898254, "val_acc": 64.0}
{"epoch": 30, "training_loss": 43.98740601539612, "training_acc": 80.0, "val_loss": 13.49182277917862, "val_acc": 72.0}
{"epoch": 31, "training_loss": 48.73124051094055, "training_acc": 74.0, "val_loss": 12.899664044380188, "val_acc": 80.0}
{"epoch": 32, "training_loss": 45.53204536437988, "training_acc": 78.0, "val_loss": 13.79561722278595, "val_acc": 64.0}
{"epoch": 33, "training_loss": 48.43738532066345, "training_acc": 80.0, "val_loss": 14.524713158607483, "val_acc": 72.0}
{"epoch": 34, "training_loss": 52.95400094985962, "training_acc": 74.0, "val_loss": 13.217291235923767, "val_acc": 76.0}
{"epoch": 35, "training_loss": 46.01255404949188, "training_acc": 79.0, "val_loss": 14.174412190914154, "val_acc": 56.0}
{"epoch": 36, "training_loss": 49.85598886013031, "training_acc": 76.0, "val_loss": 13.067732751369476, "val_acc": 76.0}
{"epoch": 37, "training_loss": 51.40795063972473, "training_acc": 76.0, "val_loss": 12.98673152923584, "val_acc": 76.0}
{"epoch": 38, "training_loss": 43.44194042682648, "training_acc": 79.0, "val_loss": 14.751149713993073, "val_acc": 56.0}
{"epoch": 39, "training_loss": 55.9342759847641, "training_acc": 77.0, "val_loss": 13.132265210151672, "val_acc": 76.0}
{"epoch": 40, "training_loss": 53.64734864234924, "training_acc": 77.0, "val_loss": 12.703299522399902, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.43278908729553, "training_acc": 80.0, "val_loss": 13.670846819877625, "val_acc": 56.0}
{"epoch": 42, "training_loss": 49.45318555831909, "training_acc": 74.0, "val_loss": 13.444031774997711, "val_acc": 72.0}
