"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6422.393379211426, "training_acc": 46.0, "val_loss": 4304.874038696289, "val_acc": 72.0}
{"epoch": 1, "training_loss": 14035.839263916016, "training_acc": 72.0, "val_loss": 3522.4185943603516, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11694.966003417969, "training_acc": 28.0, "val_loss": 1345.2521324157715, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6818.358001708984, "training_acc": 72.0, "val_loss": 2913.449478149414, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11580.381713867188, "training_acc": 72.0, "val_loss": 2112.504768371582, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6633.036361694336, "training_acc": 72.0, "val_loss": 1513.809871673584, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6576.787261962891, "training_acc": 28.0, "val_loss": 227.711820602417, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1543.6080703735352, "training_acc": 72.0, "val_loss": 704.5662879943848, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2227.3049926757812, "training_acc": 72.0, "val_loss": 951.4936447143555, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2841.4611854553223, "training_acc": 28.0, "val_loss": 1010.1981163024902, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5381.327606201172, "training_acc": 72.0, "val_loss": 1964.3217086791992, "val_acc": 72.0}
{"epoch": 11, "training_loss": 7626.3341064453125, "training_acc": 72.0, "val_loss": 1346.8414306640625, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4318.303436279297, "training_acc": 72.0, "val_loss": 1257.1284294128418, "val_acc": 28.0}
{"epoch": 13, "training_loss": 5237.980514526367, "training_acc": 28.0, "val_loss": 243.09635162353516, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1664.8653030395508, "training_acc": 72.0, "val_loss": 666.7223930358887, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2216.647678375244, "training_acc": 72.0, "val_loss": 710.0967884063721, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1918.51460313797, "training_acc": 43.0, "val_loss": 47.2364068031311, "val_acc": 72.0}
{"epoch": 17, "training_loss": 504.1091957092285, "training_acc": 66.0, "val_loss": 329.44490909576416, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1361.6812629699707, "training_acc": 72.0, "val_loss": 225.77736377716064, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1652.0158767700195, "training_acc": 54.0, "val_loss": 114.6957278251648, "val_acc": 72.0}
{"epoch": 20, "training_loss": 460.78371238708496, "training_acc": 72.0, "val_loss": 271.61271572113037, "val_acc": 28.0}
{"epoch": 21, "training_loss": 960.7052764892578, "training_acc": 52.0, "val_loss": 624.590539932251, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2310.4448890686035, "training_acc": 72.0, "val_loss": 127.94468402862549, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2330.2064361572266, "training_acc": 54.0, "val_loss": 647.9775428771973, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2152.443618774414, "training_acc": 52.0, "val_loss": 1384.524154663086, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5909.682281494141, "training_acc": 72.0, "val_loss": 1650.0970840454102, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5984.306945800781, "training_acc": 72.0, "val_loss": 653.2126903533936, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2658.539894104004, "training_acc": 56.0, "val_loss": 687.5709533691406, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2796.3924560546875, "training_acc": 40.0, "val_loss": 915.7162666320801, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3775.259231567383, "training_acc": 72.0, "val_loss": 654.5035362243652, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1880.9940285682678, "training_acc": 64.0, "val_loss": 574.4814395904541, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2011.31196975708, "training_acc": 44.0, "val_loss": 589.8205280303955, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2134.1588287353516, "training_acc": 72.0, "val_loss": 66.5837287902832, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2445.3185119628906, "training_acc": 55.0, "val_loss": 749.3985652923584, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2035.290901184082, "training_acc": 56.0, "val_loss": 1368.8435554504395, "val_acc": 72.0}
{"epoch": 35, "training_loss": 5965.669403076172, "training_acc": 72.0, "val_loss": 1719.6544647216797, "val_acc": 72.0}
