"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 226132.24293327332, "training_acc": 69.0, "val_loss": 34828.68347167969, "val_acc": 32.0}
{"epoch": 1, "training_loss": 102180.931640625, "training_acc": 55.0, "val_loss": 42801.27258300781, "val_acc": 72.0}
{"epoch": 2, "training_loss": 108069.49291992188, "training_acc": 71.0, "val_loss": 26676.651000976562, "val_acc": 36.0}
{"epoch": 3, "training_loss": 62236.662109375, "training_acc": 65.0, "val_loss": 10524.508666992188, "val_acc": 72.0}
{"epoch": 4, "training_loss": 30062.7158203125, "training_acc": 61.0, "val_loss": 15372.599792480469, "val_acc": 72.0}
{"epoch": 5, "training_loss": 45184.70703125, "training_acc": 72.0, "val_loss": 9773.916625976562, "val_acc": 36.0}
{"epoch": 6, "training_loss": 38747.69836425781, "training_acc": 61.0, "val_loss": 2166.4413452148438, "val_acc": 72.0}
{"epoch": 7, "training_loss": 26908.583068847656, "training_acc": 60.0, "val_loss": 8021.009063720703, "val_acc": 72.0}
{"epoch": 8, "training_loss": 24858.60009765625, "training_acc": 67.0, "val_loss": 7936.085510253906, "val_acc": 72.0}
{"epoch": 9, "training_loss": 19624.81982421875, "training_acc": 74.0, "val_loss": 3696.091842651367, "val_acc": 76.0}
{"epoch": 10, "training_loss": 12998.478515625, "training_acc": 77.0, "val_loss": 5081.897735595703, "val_acc": 72.0}
{"epoch": 11, "training_loss": 15009.58642578125, "training_acc": 68.0, "val_loss": 7509.336090087891, "val_acc": 72.0}
{"epoch": 12, "training_loss": 16005.53286743164, "training_acc": 69.0, "val_loss": 9397.187042236328, "val_acc": 72.0}
{"epoch": 13, "training_loss": 21088.440032958984, "training_acc": 66.0, "val_loss": 13521.218872070312, "val_acc": 72.0}
{"epoch": 14, "training_loss": 45382.86212158203, "training_acc": 71.0, "val_loss": 1564.6979331970215, "val_acc": 76.0}
{"epoch": 15, "training_loss": 29180.296936035156, "training_acc": 54.0, "val_loss": 9040.10009765625, "val_acc": 72.0}
{"epoch": 16, "training_loss": 37657.346435546875, "training_acc": 70.0, "val_loss": 2219.8421478271484, "val_acc": 72.0}
{"epoch": 17, "training_loss": 26620.24432373047, "training_acc": 72.0, "val_loss": 7699.040222167969, "val_acc": 44.0}
{"epoch": 18, "training_loss": 28187.474365234375, "training_acc": 60.0, "val_loss": 4545.7275390625, "val_acc": 72.0}
{"epoch": 19, "training_loss": 33588.375732421875, "training_acc": 48.0, "val_loss": 14895.053100585938, "val_acc": 72.0}
{"epoch": 20, "training_loss": 55530.46301269531, "training_acc": 52.0, "val_loss": 12647.222137451172, "val_acc": 72.0}
{"epoch": 21, "training_loss": 51804.51171875, "training_acc": 72.0, "val_loss": 7075.895690917969, "val_acc": 56.0}
{"epoch": 22, "training_loss": 27356.422241210938, "training_acc": 65.0, "val_loss": 4806.641387939453, "val_acc": 76.0}
{"epoch": 23, "training_loss": 17999.3564453125, "training_acc": 68.0, "val_loss": 10836.306762695312, "val_acc": 72.0}
{"epoch": 24, "training_loss": 25532.84814453125, "training_acc": 59.0, "val_loss": 8318.95751953125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 22422.13555908203, "training_acc": 61.0, "val_loss": 2911.083984375, "val_acc": 68.0}
{"epoch": 26, "training_loss": 19153.651306152344, "training_acc": 60.0, "val_loss": 4196.100616455078, "val_acc": 72.0}
{"epoch": 27, "training_loss": 5768.531997680664, "training_acc": 77.0, "val_loss": 5123.733139038086, "val_acc": 40.0}
{"epoch": 28, "training_loss": 20553.1982421875, "training_acc": 65.0, "val_loss": 983.3127021789551, "val_acc": 64.0}
{"epoch": 29, "training_loss": 18311.590454101562, "training_acc": 66.0, "val_loss": 3554.269027709961, "val_acc": 76.0}
{"epoch": 30, "training_loss": 65418.037109375, "training_acc": 36.0, "val_loss": 33708.905029296875, "val_acc": 72.0}
{"epoch": 31, "training_loss": 145975.9814453125, "training_acc": 72.0, "val_loss": 12923.367309570312, "val_acc": 76.0}
{"epoch": 32, "training_loss": 87846.47595214844, "training_acc": 52.0, "val_loss": 9167.052459716797, "val_acc": 76.0}
{"epoch": 33, "training_loss": 76306.99389648438, "training_acc": 73.0, "val_loss": 15611.628723144531, "val_acc": 72.0}
{"epoch": 34, "training_loss": 65470.19482421875, "training_acc": 57.0, "val_loss": 7794.709777832031, "val_acc": 76.0}
{"epoch": 35, "training_loss": 69391.77807617188, "training_acc": 73.0, "val_loss": 5616.961669921875, "val_acc": 80.0}
{"epoch": 36, "training_loss": 49893.64196777344, "training_acc": 45.0, "val_loss": 16902.462768554688, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57570.08728027344, "training_acc": 69.0, "val_loss": 2239.09912109375, "val_acc": 76.0}
{"epoch": 38, "training_loss": 9981.841552734375, "training_acc": 75.0, "val_loss": 15662.53662109375, "val_acc": 72.0}
{"epoch": 39, "training_loss": 82753.8671875, "training_acc": 72.0, "val_loss": 2752.4688720703125, "val_acc": 48.0}
{"epoch": 40, "training_loss": 59794.10107421875, "training_acc": 34.0, "val_loss": 24584.963989257812, "val_acc": 72.0}
{"epoch": 41, "training_loss": 73747.61669921875, "training_acc": 71.0, "val_loss": 7045.857238769531, "val_acc": 56.0}
{"epoch": 42, "training_loss": 19032.580444335938, "training_acc": 72.0, "val_loss": 3566.556930541992, "val_acc": 76.0}
{"epoch": 43, "training_loss": 15537.960693359375, "training_acc": 65.0, "val_loss": 1571.4200973510742, "val_acc": 76.0}
{"epoch": 44, "training_loss": 23641.270629882812, "training_acc": 56.0, "val_loss": 5593.9178466796875, "val_acc": 72.0}
{"epoch": 45, "training_loss": 16744.762329101562, "training_acc": 64.0, "val_loss": 2943.242073059082, "val_acc": 76.0}
{"epoch": 46, "training_loss": 15067.811401367188, "training_acc": 61.0, "val_loss": 5594.989013671875, "val_acc": 72.0}
{"epoch": 47, "training_loss": 20889.31591796875, "training_acc": 59.0, "val_loss": 13642.3828125, "val_acc": 72.0}
