"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 314074.4645957947, "training_acc": 73.0, "val_loss": 18011.349487304688, "val_acc": 72.0}
{"epoch": 1, "training_loss": 249306.87133789062, "training_acc": 46.0, "val_loss": 31134.201049804688, "val_acc": 72.0}
{"epoch": 2, "training_loss": 174097.1689453125, "training_acc": 72.0, "val_loss": 42802.874755859375, "val_acc": 72.0}
{"epoch": 3, "training_loss": 78590.56103515625, "training_acc": 72.0, "val_loss": 26966.915893554688, "val_acc": 44.0}
{"epoch": 4, "training_loss": 75355.59765625, "training_acc": 64.0, "val_loss": 33119.61975097656, "val_acc": 72.0}
{"epoch": 5, "training_loss": 99126.11328125, "training_acc": 72.0, "val_loss": 12496.089935302734, "val_acc": 60.0}
{"epoch": 6, "training_loss": 65076.087890625, "training_acc": 59.0, "val_loss": 14086.067199707031, "val_acc": 72.0}
{"epoch": 7, "training_loss": 28767.344757080078, "training_acc": 72.0, "val_loss": 12227.980041503906, "val_acc": 36.0}
{"epoch": 8, "training_loss": 39698.8017578125, "training_acc": 58.0, "val_loss": 3798.763656616211, "val_acc": 72.0}
{"epoch": 9, "training_loss": 16141.796997070312, "training_acc": 65.0, "val_loss": 17088.890075683594, "val_acc": 28.0}
{"epoch": 10, "training_loss": 44631.14208984375, "training_acc": 52.0, "val_loss": 21295.32012939453, "val_acc": 72.0}
{"epoch": 11, "training_loss": 45938.8603515625, "training_acc": 71.0, "val_loss": 4878.889465332031, "val_acc": 72.0}
{"epoch": 12, "training_loss": 32472.7373046875, "training_acc": 72.0, "val_loss": 7642.841339111328, "val_acc": 68.0}
{"epoch": 13, "training_loss": 29476.514038085938, "training_acc": 66.0, "val_loss": 11458.33969116211, "val_acc": 72.0}
{"epoch": 14, "training_loss": 30928.767700195312, "training_acc": 72.0, "val_loss": 6401.657867431641, "val_acc": 72.0}
{"epoch": 15, "training_loss": 16152.48095703125, "training_acc": 73.0, "val_loss": 5739.178466796875, "val_acc": 72.0}
{"epoch": 16, "training_loss": 23764.280151367188, "training_acc": 69.0, "val_loss": 2685.9201431274414, "val_acc": 64.0}
{"epoch": 17, "training_loss": 14238.070442199707, "training_acc": 72.0, "val_loss": 8931.43081665039, "val_acc": 56.0}
{"epoch": 18, "training_loss": 29030.9306640625, "training_acc": 67.0, "val_loss": 23772.05810546875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 61702.80822753906, "training_acc": 71.0, "val_loss": 9492.754364013672, "val_acc": 52.0}
{"epoch": 20, "training_loss": 32643.181640625, "training_acc": 69.0, "val_loss": 17045.846557617188, "val_acc": 72.0}
{"epoch": 21, "training_loss": 51659.04931640625, "training_acc": 57.0, "val_loss": 6648.130035400391, "val_acc": 68.0}
{"epoch": 22, "training_loss": 14976.642456054688, "training_acc": 75.0, "val_loss": 8259.317016601562, "val_acc": 32.0}
{"epoch": 23, "training_loss": 48652.4873046875, "training_acc": 59.0, "val_loss": 7212.95166015625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 47698.78918457031, "training_acc": 46.0, "val_loss": 23869.964599609375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 87676.14376831055, "training_acc": 72.0, "val_loss": 17976.722717285156, "val_acc": 36.0}
{"epoch": 26, "training_loss": 58946.14453125, "training_acc": 48.0, "val_loss": 32369.570922851562, "val_acc": 72.0}
{"epoch": 27, "training_loss": 116045.4033203125, "training_acc": 72.0, "val_loss": 8006.35986328125, "val_acc": 72.0}
{"epoch": 28, "training_loss": 89663.7822265625, "training_acc": 42.0, "val_loss": 27146.37451171875, "val_acc": 72.0}
{"epoch": 29, "training_loss": 142149.5009765625, "training_acc": 72.0, "val_loss": 32545.596313476562, "val_acc": 72.0}
{"epoch": 30, "training_loss": 69724.48974609375, "training_acc": 66.0, "val_loss": 4671.926116943359, "val_acc": 56.0}
{"epoch": 31, "training_loss": 48202.615234375, "training_acc": 66.0, "val_loss": 4853.748321533203, "val_acc": 64.0}
{"epoch": 32, "training_loss": 53757.99609375, "training_acc": 52.0, "val_loss": 21121.32110595703, "val_acc": 72.0}
{"epoch": 33, "training_loss": 91374.28759765625, "training_acc": 72.0, "val_loss": 4430.463790893555, "val_acc": 68.0}
{"epoch": 34, "training_loss": 40593.33935546875, "training_acc": 47.0, "val_loss": 17382.955932617188, "val_acc": 72.0}
{"epoch": 35, "training_loss": 47155.3916015625, "training_acc": 62.0, "val_loss": 10026.985168457031, "val_acc": 72.0}
