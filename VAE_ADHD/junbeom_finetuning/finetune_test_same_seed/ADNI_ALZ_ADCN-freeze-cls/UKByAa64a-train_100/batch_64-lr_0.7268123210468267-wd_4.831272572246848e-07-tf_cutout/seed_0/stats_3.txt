"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 579.4519309997559, "training_acc": 54.0, "val_loss": 691.1865234375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2202.7808952331543, "training_acc": 72.0, "val_loss": 497.9177951812744, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1571.3687705993652, "training_acc": 33.0, "val_loss": 161.1202359199524, "val_acc": 72.0}
{"epoch": 3, "training_loss": 741.3355979919434, "training_acc": 72.0, "val_loss": 304.54320907592773, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1073.678071975708, "training_acc": 72.0, "val_loss": 155.6536316871643, "val_acc": 72.0}
{"epoch": 5, "training_loss": 470.843225479126, "training_acc": 65.0, "val_loss": 240.97707271575928, "val_acc": 64.0}
{"epoch": 6, "training_loss": 698.7450532913208, "training_acc": 59.0, "val_loss": 155.5699110031128, "val_acc": 72.0}
{"epoch": 7, "training_loss": 484.8834037780762, "training_acc": 73.0, "val_loss": 141.4099097251892, "val_acc": 72.0}
{"epoch": 8, "training_loss": 328.40495014190674, "training_acc": 74.0, "val_loss": 142.76103973388672, "val_acc": 64.0}
{"epoch": 9, "training_loss": 311.02014350891113, "training_acc": 61.0, "val_loss": 74.5523989200592, "val_acc": 72.0}
{"epoch": 10, "training_loss": 188.70163440704346, "training_acc": 75.0, "val_loss": 40.69031774997711, "val_acc": 76.0}
{"epoch": 11, "training_loss": 120.6986231803894, "training_acc": 67.0, "val_loss": 17.201709747314453, "val_acc": 76.0}
{"epoch": 12, "training_loss": 87.80991458892822, "training_acc": 66.0, "val_loss": 54.518359899520874, "val_acc": 44.0}
{"epoch": 13, "training_loss": 197.51371717453003, "training_acc": 54.0, "val_loss": 18.981730937957764, "val_acc": 56.0}
{"epoch": 14, "training_loss": 97.23488759994507, "training_acc": 63.0, "val_loss": 42.4547553062439, "val_acc": 72.0}
{"epoch": 15, "training_loss": 155.6556932926178, "training_acc": 73.0, "val_loss": 48.86530935764313, "val_acc": 56.0}
{"epoch": 16, "training_loss": 164.39497756958008, "training_acc": 58.0, "val_loss": 64.35482501983643, "val_acc": 72.0}
{"epoch": 17, "training_loss": 268.30477714538574, "training_acc": 72.0, "val_loss": 45.208293199539185, "val_acc": 76.0}
{"epoch": 18, "training_loss": 132.88110733032227, "training_acc": 75.0, "val_loss": 91.87401533126831, "val_acc": 48.0}
{"epoch": 19, "training_loss": 269.4580702781677, "training_acc": 55.0, "val_loss": 78.82472276687622, "val_acc": 72.0}
{"epoch": 20, "training_loss": 254.9038667678833, "training_acc": 73.0, "val_loss": 70.44262290000916, "val_acc": 60.0}
{"epoch": 21, "training_loss": 250.4773302078247, "training_acc": 57.0, "val_loss": 43.46199631690979, "val_acc": 80.0}
{"epoch": 22, "training_loss": 185.1918363571167, "training_acc": 74.0, "val_loss": 32.969725131988525, "val_acc": 76.0}
{"epoch": 23, "training_loss": 168.01765155792236, "training_acc": 63.0, "val_loss": 27.498260140419006, "val_acc": 72.0}
{"epoch": 24, "training_loss": 98.54004240036011, "training_acc": 80.0, "val_loss": 43.65705847740173, "val_acc": 72.0}
{"epoch": 25, "training_loss": 148.78233647346497, "training_acc": 72.0, "val_loss": 47.837987542152405, "val_acc": 52.0}
{"epoch": 26, "training_loss": 107.25585699081421, "training_acc": 68.0, "val_loss": 37.84966170787811, "val_acc": 72.0}
{"epoch": 27, "training_loss": 127.280690908432, "training_acc": 74.0, "val_loss": 54.06121611595154, "val_acc": 40.0}
{"epoch": 28, "training_loss": 170.1726746559143, "training_acc": 58.0, "val_loss": 26.7616868019104, "val_acc": 76.0}
{"epoch": 29, "training_loss": 175.23614692687988, "training_acc": 58.0, "val_loss": 17.388610541820526, "val_acc": 80.0}
{"epoch": 30, "training_loss": 64.39370775222778, "training_acc": 83.0, "val_loss": 22.953452169895172, "val_acc": 76.0}
