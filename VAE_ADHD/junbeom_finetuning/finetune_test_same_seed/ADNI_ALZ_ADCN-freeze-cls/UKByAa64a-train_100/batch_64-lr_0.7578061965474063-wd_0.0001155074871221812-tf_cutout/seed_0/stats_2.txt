"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1113.362392425537, "training_acc": 44.0, "val_loss": 665.7744407653809, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2179.4887733459473, "training_acc": 72.0, "val_loss": 268.81606578826904, "val_acc": 28.0}
{"epoch": 2, "training_loss": 962.6263771057129, "training_acc": 33.0, "val_loss": 187.1018886566162, "val_acc": 72.0}
{"epoch": 3, "training_loss": 740.8785705566406, "training_acc": 72.0, "val_loss": 280.7983875274658, "val_acc": 72.0}
{"epoch": 4, "training_loss": 857.264835357666, "training_acc": 72.0, "val_loss": 82.05806016921997, "val_acc": 80.0}
{"epoch": 5, "training_loss": 425.41289138793945, "training_acc": 62.0, "val_loss": 152.46617794036865, "val_acc": 44.0}
{"epoch": 6, "training_loss": 781.6378326416016, "training_acc": 56.0, "val_loss": 147.02340364456177, "val_acc": 72.0}
{"epoch": 7, "training_loss": 487.8727493286133, "training_acc": 71.0, "val_loss": 159.61616039276123, "val_acc": 72.0}
{"epoch": 8, "training_loss": 456.6714324951172, "training_acc": 68.0, "val_loss": 74.44610595703125, "val_acc": 56.0}
{"epoch": 9, "training_loss": 296.1315999031067, "training_acc": 58.0, "val_loss": 66.62484407424927, "val_acc": 64.0}
{"epoch": 10, "training_loss": 149.82443237304688, "training_acc": 73.0, "val_loss": 90.20559787750244, "val_acc": 52.0}
{"epoch": 11, "training_loss": 234.40118408203125, "training_acc": 50.0, "val_loss": 65.27166366577148, "val_acc": 60.0}
{"epoch": 12, "training_loss": 159.71090388298035, "training_acc": 69.0, "val_loss": 37.34355568885803, "val_acc": 56.0}
{"epoch": 13, "training_loss": 92.25444030761719, "training_acc": 73.0, "val_loss": 29.19439971446991, "val_acc": 72.0}
{"epoch": 14, "training_loss": 87.78325462341309, "training_acc": 74.0, "val_loss": 35.24768650531769, "val_acc": 76.0}
{"epoch": 15, "training_loss": 87.90263795852661, "training_acc": 76.0, "val_loss": 25.687748193740845, "val_acc": 68.0}
{"epoch": 16, "training_loss": 115.37760162353516, "training_acc": 63.0, "val_loss": 84.91715788841248, "val_acc": 72.0}
{"epoch": 17, "training_loss": 306.7830982208252, "training_acc": 72.0, "val_loss": 29.0797621011734, "val_acc": 72.0}
{"epoch": 18, "training_loss": 246.7249813079834, "training_acc": 60.0, "val_loss": 22.68102914094925, "val_acc": 68.0}
{"epoch": 19, "training_loss": 251.10052108764648, "training_acc": 62.0, "val_loss": 154.33741807937622, "val_acc": 72.0}
{"epoch": 20, "training_loss": 490.34071922302246, "training_acc": 72.0, "val_loss": 37.60180175304413, "val_acc": 80.0}
{"epoch": 21, "training_loss": 251.26738166809082, "training_acc": 65.0, "val_loss": 62.62890100479126, "val_acc": 52.0}
{"epoch": 22, "training_loss": 260.8815908432007, "training_acc": 66.0, "val_loss": 136.90613508224487, "val_acc": 72.0}
{"epoch": 23, "training_loss": 434.0089454650879, "training_acc": 72.0, "val_loss": 66.89181923866272, "val_acc": 68.0}
{"epoch": 24, "training_loss": 262.02796363830566, "training_acc": 71.0, "val_loss": 65.97824096679688, "val_acc": 64.0}
{"epoch": 25, "training_loss": 246.15624523162842, "training_acc": 59.0, "val_loss": 133.39098691940308, "val_acc": 72.0}
{"epoch": 26, "training_loss": 373.804669380188, "training_acc": 72.0, "val_loss": 65.90762138366699, "val_acc": 68.0}
{"epoch": 27, "training_loss": 120.04671716690063, "training_acc": 72.0, "val_loss": 106.11449480056763, "val_acc": 52.0}
{"epoch": 28, "training_loss": 315.9863271713257, "training_acc": 59.0, "val_loss": 113.20819854736328, "val_acc": 72.0}
{"epoch": 29, "training_loss": 300.57258319854736, "training_acc": 72.0, "val_loss": 49.46356415748596, "val_acc": 68.0}
{"epoch": 30, "training_loss": 210.41181755065918, "training_acc": 65.0, "val_loss": 51.077818870544434, "val_acc": 68.0}
{"epoch": 31, "training_loss": 176.66896057128906, "training_acc": 77.0, "val_loss": 110.08270978927612, "val_acc": 72.0}
{"epoch": 32, "training_loss": 235.29846143722534, "training_acc": 75.0, "val_loss": 61.55778169631958, "val_acc": 60.0}
{"epoch": 33, "training_loss": 216.74449968338013, "training_acc": 63.0, "val_loss": 77.38824486732483, "val_acc": 68.0}
{"epoch": 34, "training_loss": 182.13681983947754, "training_acc": 76.0, "val_loss": 69.77459788322449, "val_acc": 68.0}
{"epoch": 35, "training_loss": 102.32188367843628, "training_acc": 81.0, "val_loss": 78.59137058258057, "val_acc": 56.0}
{"epoch": 36, "training_loss": 289.4463129043579, "training_acc": 50.0, "val_loss": 72.10702896118164, "val_acc": 72.0}
{"epoch": 37, "training_loss": 123.52028584480286, "training_acc": 77.0, "val_loss": 40.65040349960327, "val_acc": 64.0}
