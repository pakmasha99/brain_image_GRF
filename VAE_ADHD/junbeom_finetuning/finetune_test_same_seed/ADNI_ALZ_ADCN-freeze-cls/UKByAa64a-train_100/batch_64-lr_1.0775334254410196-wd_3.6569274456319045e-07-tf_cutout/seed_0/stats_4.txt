"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2209.775131225586, "training_acc": 36.0, "val_loss": 827.3810386657715, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2568.920753479004, "training_acc": 72.0, "val_loss": 456.42547607421875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2055.7909545898438, "training_acc": 28.0, "val_loss": 160.29587984085083, "val_acc": 72.0}
{"epoch": 3, "training_loss": 633.194938659668, "training_acc": 73.0, "val_loss": 363.9341115951538, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1033.3680057525635, "training_acc": 72.0, "val_loss": 158.0610752105713, "val_acc": 68.0}
{"epoch": 5, "training_loss": 714.5981407165527, "training_acc": 63.0, "val_loss": 196.46576642990112, "val_acc": 60.0}
{"epoch": 6, "training_loss": 908.7269325256348, "training_acc": 58.0, "val_loss": 272.2986936569214, "val_acc": 72.0}
{"epoch": 7, "training_loss": 684.8548965454102, "training_acc": 75.0, "val_loss": 283.8050365447998, "val_acc": 72.0}
{"epoch": 8, "training_loss": 573.7720823287964, "training_acc": 78.0, "val_loss": 154.131817817688, "val_acc": 64.0}
{"epoch": 9, "training_loss": 765.2528076171875, "training_acc": 56.0, "val_loss": 126.86116695404053, "val_acc": 64.0}
{"epoch": 10, "training_loss": 404.040979385376, "training_acc": 68.0, "val_loss": 173.34142923355103, "val_acc": 72.0}
{"epoch": 11, "training_loss": 390.0858736038208, "training_acc": 74.0, "val_loss": 67.06095933914185, "val_acc": 64.0}
{"epoch": 12, "training_loss": 244.14174032211304, "training_acc": 65.0, "val_loss": 65.26294350624084, "val_acc": 72.0}
{"epoch": 13, "training_loss": 235.78939628601074, "training_acc": 72.0, "val_loss": 165.05526304244995, "val_acc": 28.0}
{"epoch": 14, "training_loss": 447.0588631629944, "training_acc": 45.0, "val_loss": 31.65472447872162, "val_acc": 72.0}
{"epoch": 15, "training_loss": 181.10401010513306, "training_acc": 68.0, "val_loss": 16.698607802391052, "val_acc": 76.0}
{"epoch": 16, "training_loss": 102.26522088050842, "training_acc": 70.0, "val_loss": 10.72106808423996, "val_acc": 80.0}
{"epoch": 17, "training_loss": 59.27474880218506, "training_acc": 78.0, "val_loss": 34.51290726661682, "val_acc": 52.0}
{"epoch": 18, "training_loss": 110.18509316444397, "training_acc": 74.0, "val_loss": 38.23406100273132, "val_acc": 76.0}
{"epoch": 19, "training_loss": 95.50415539741516, "training_acc": 80.0, "val_loss": 17.639686167240143, "val_acc": 76.0}
{"epoch": 20, "training_loss": 57.133578300476074, "training_acc": 80.0, "val_loss": 31.598812341690063, "val_acc": 76.0}
{"epoch": 21, "training_loss": 82.48914647102356, "training_acc": 73.0, "val_loss": 25.386440753936768, "val_acc": 52.0}
{"epoch": 22, "training_loss": 187.4844617843628, "training_acc": 65.0, "val_loss": 73.3754575252533, "val_acc": 72.0}
{"epoch": 23, "training_loss": 296.20048332214355, "training_acc": 59.0, "val_loss": 34.35172140598297, "val_acc": 76.0}
{"epoch": 24, "training_loss": 103.41859459877014, "training_acc": 81.0, "val_loss": 24.393990635871887, "val_acc": 80.0}
{"epoch": 25, "training_loss": 68.36109530925751, "training_acc": 72.0, "val_loss": 55.98704218864441, "val_acc": 76.0}
{"epoch": 26, "training_loss": 107.08983707427979, "training_acc": 79.0, "val_loss": 32.27994441986084, "val_acc": 56.0}
{"epoch": 27, "training_loss": 179.30453443527222, "training_acc": 69.0, "val_loss": 32.69784152507782, "val_acc": 76.0}
{"epoch": 28, "training_loss": 78.06278324127197, "training_acc": 77.0, "val_loss": 37.34350800514221, "val_acc": 72.0}
{"epoch": 29, "training_loss": 79.07404601573944, "training_acc": 79.0, "val_loss": 89.41410779953003, "val_acc": 28.0}
{"epoch": 30, "training_loss": 297.1527862548828, "training_acc": 53.0, "val_loss": 100.63787698745728, "val_acc": 72.0}
{"epoch": 31, "training_loss": 274.6040137410164, "training_acc": 77.0, "val_loss": 118.1350827217102, "val_acc": 36.0}
{"epoch": 32, "training_loss": 363.11688256263733, "training_acc": 52.0, "val_loss": 132.73829221725464, "val_acc": 72.0}
{"epoch": 33, "training_loss": 354.34765243530273, "training_acc": 74.0, "val_loss": 40.078359842300415, "val_acc": 80.0}
{"epoch": 34, "training_loss": 252.2492561340332, "training_acc": 68.0, "val_loss": 59.88388657569885, "val_acc": 76.0}
{"epoch": 35, "training_loss": 160.9099645614624, "training_acc": 81.0, "val_loss": 92.41282939910889, "val_acc": 72.0}
