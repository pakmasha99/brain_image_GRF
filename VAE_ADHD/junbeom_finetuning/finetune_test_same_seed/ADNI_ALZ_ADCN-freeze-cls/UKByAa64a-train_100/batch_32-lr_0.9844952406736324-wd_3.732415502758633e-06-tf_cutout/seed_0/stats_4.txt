"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2452.123249053955, "training_acc": 58.0, "val_loss": 639.9150371551514, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2060.927635192871, "training_acc": 36.0, "val_loss": 442.93837547302246, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1071.2460193634033, "training_acc": 72.0, "val_loss": 296.8109130859375, "val_acc": 52.0}
{"epoch": 3, "training_loss": 1439.8123774528503, "training_acc": 49.0, "val_loss": 496.8994140625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2155.5436401367188, "training_acc": 72.0, "val_loss": 597.1700191497803, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1515.6049423217773, "training_acc": 70.0, "val_loss": 257.38606452941895, "val_acc": 52.0}
{"epoch": 6, "training_loss": 763.6788558959961, "training_acc": 63.0, "val_loss": 316.22118949890137, "val_acc": 72.0}
{"epoch": 7, "training_loss": 681.5788192749023, "training_acc": 69.0, "val_loss": 120.61457633972168, "val_acc": 48.0}
{"epoch": 8, "training_loss": 254.12940883542615, "training_acc": 72.0, "val_loss": 136.91909313201904, "val_acc": 72.0}
{"epoch": 9, "training_loss": 342.86565828323364, "training_acc": 65.0, "val_loss": 70.2113151550293, "val_acc": 76.0}
{"epoch": 10, "training_loss": 149.04734897613525, "training_acc": 77.0, "val_loss": 52.64661908149719, "val_acc": 60.0}
{"epoch": 11, "training_loss": 251.52203750610352, "training_acc": 69.0, "val_loss": 150.1952052116394, "val_acc": 36.0}
{"epoch": 12, "training_loss": 489.10633087158203, "training_acc": 55.0, "val_loss": 122.15871810913086, "val_acc": 72.0}
{"epoch": 13, "training_loss": 279.3609904050827, "training_acc": 74.0, "val_loss": 44.32377815246582, "val_acc": 64.0}
{"epoch": 14, "training_loss": 215.59491730993614, "training_acc": 74.0, "val_loss": 25.458040833473206, "val_acc": 68.0}
{"epoch": 15, "training_loss": 109.58086702227592, "training_acc": 75.0, "val_loss": 43.45910847187042, "val_acc": 72.0}
{"epoch": 16, "training_loss": 123.92333314567804, "training_acc": 76.0, "val_loss": 17.62182265520096, "val_acc": 72.0}
{"epoch": 17, "training_loss": 97.42196732200682, "training_acc": 78.0, "val_loss": 39.598193764686584, "val_acc": 80.0}
{"epoch": 18, "training_loss": 108.28989887237549, "training_acc": 72.0, "val_loss": 103.26861143112183, "val_acc": 72.0}
{"epoch": 19, "training_loss": 265.57349228726525, "training_acc": 70.0, "val_loss": 82.32482671737671, "val_acc": 76.0}
{"epoch": 20, "training_loss": 185.1934051513672, "training_acc": 81.0, "val_loss": 35.84040403366089, "val_acc": 76.0}
{"epoch": 21, "training_loss": 249.88174510002136, "training_acc": 71.0, "val_loss": 51.724475622177124, "val_acc": 44.0}
{"epoch": 22, "training_loss": 141.1287317276001, "training_acc": 69.0, "val_loss": 47.444432973861694, "val_acc": 48.0}
{"epoch": 23, "training_loss": 205.55448186372814, "training_acc": 75.0, "val_loss": 26.12345814704895, "val_acc": 68.0}
{"epoch": 24, "training_loss": 71.97205924987793, "training_acc": 79.0, "val_loss": 64.8386001586914, "val_acc": 76.0}
{"epoch": 25, "training_loss": 130.8031177520752, "training_acc": 81.0, "val_loss": 94.71645951271057, "val_acc": 72.0}
{"epoch": 26, "training_loss": 217.34851205348969, "training_acc": 79.0, "val_loss": 199.6274471282959, "val_acc": 28.0}
{"epoch": 27, "training_loss": 280.3195037841797, "training_acc": 69.0, "val_loss": 42.338308691978455, "val_acc": 72.0}
{"epoch": 28, "training_loss": 291.35314559936523, "training_acc": 63.0, "val_loss": 204.7518014907837, "val_acc": 72.0}
{"epoch": 29, "training_loss": 392.29051780700684, "training_acc": 75.0, "val_loss": 353.93950939178467, "val_acc": 36.0}
{"epoch": 30, "training_loss": 933.2139892578125, "training_acc": 55.0, "val_loss": 407.49340057373047, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1224.6051177978516, "training_acc": 72.0, "val_loss": 113.17315101623535, "val_acc": 64.0}
{"epoch": 32, "training_loss": 1168.6713609695435, "training_acc": 44.0, "val_loss": 430.8444023132324, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2120.85799407959, "training_acc": 72.0, "val_loss": 592.7822113037109, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1289.9216108322144, "training_acc": 73.0, "val_loss": 361.5139961242676, "val_acc": 36.0}
{"epoch": 35, "training_loss": 1041.5313458442597, "training_acc": 56.0, "val_loss": 430.0354480743408, "val_acc": 72.0}
