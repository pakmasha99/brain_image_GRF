"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3045.0847396850586, "training_acc": 50.0, "val_loss": 211.93373203277588, "val_acc": 44.0}
{"epoch": 1, "training_loss": 747.0525360107422, "training_acc": 50.0, "val_loss": 277.02581882476807, "val_acc": 72.0}
{"epoch": 2, "training_loss": 706.2720260620117, "training_acc": 70.0, "val_loss": 158.39300155639648, "val_acc": 68.0}
{"epoch": 3, "training_loss": 609.4530353546143, "training_acc": 68.0, "val_loss": 98.39553833007812, "val_acc": 72.0}
{"epoch": 4, "training_loss": 250.91858100891113, "training_acc": 61.0, "val_loss": 148.07209968566895, "val_acc": 72.0}
{"epoch": 5, "training_loss": 510.3097620010376, "training_acc": 60.0, "val_loss": 67.42597222328186, "val_acc": 44.0}
{"epoch": 6, "training_loss": 320.2785406112671, "training_acc": 65.0, "val_loss": 373.55871200561523, "val_acc": 28.0}
{"epoch": 7, "training_loss": 900.5245208740234, "training_acc": 48.0, "val_loss": 213.2889986038208, "val_acc": 72.0}
{"epoch": 8, "training_loss": 594.1661643981934, "training_acc": 69.0, "val_loss": 280.0330400466919, "val_acc": 44.0}
{"epoch": 9, "training_loss": 679.4820022583008, "training_acc": 58.0, "val_loss": 226.5866756439209, "val_acc": 72.0}
{"epoch": 10, "training_loss": 912.3001708984375, "training_acc": 51.0, "val_loss": 99.53562617301941, "val_acc": 72.0}
{"epoch": 11, "training_loss": 861.1934814453125, "training_acc": 72.0, "val_loss": 176.76894664764404, "val_acc": 72.0}
{"epoch": 12, "training_loss": 491.38743019104004, "training_acc": 62.0, "val_loss": 75.3180742263794, "val_acc": 64.0}
{"epoch": 13, "training_loss": 354.6630719900131, "training_acc": 71.0, "val_loss": 91.56215190887451, "val_acc": 76.0}
{"epoch": 14, "training_loss": 238.18809519708157, "training_acc": 74.0, "val_loss": 135.28116941452026, "val_acc": 64.0}
{"epoch": 15, "training_loss": 327.47354686260064, "training_acc": 75.0, "val_loss": 160.5252981185913, "val_acc": 80.0}
{"epoch": 16, "training_loss": 385.3973949938081, "training_acc": 74.0, "val_loss": 206.8964719772339, "val_acc": 52.0}
{"epoch": 17, "training_loss": 460.7375112771986, "training_acc": 67.0, "val_loss": 298.85590076446533, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1165.6897735595703, "training_acc": 72.0, "val_loss": 90.11191129684448, "val_acc": 68.0}
{"epoch": 19, "training_loss": 764.9672946929932, "training_acc": 48.0, "val_loss": 251.25463008880615, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1743.982105255127, "training_acc": 72.0, "val_loss": 357.23702907562256, "val_acc": 72.0}
{"epoch": 21, "training_loss": 919.8177795410156, "training_acc": 66.0, "val_loss": 216.33856296539307, "val_acc": 56.0}
{"epoch": 22, "training_loss": 555.7369384765625, "training_acc": 68.0, "val_loss": 192.38659143447876, "val_acc": 72.0}
{"epoch": 23, "training_loss": 559.155725479126, "training_acc": 78.0, "val_loss": 138.3274793624878, "val_acc": 64.0}
{"epoch": 24, "training_loss": 273.2988681793213, "training_acc": 72.0, "val_loss": 86.75802946090698, "val_acc": 80.0}
{"epoch": 25, "training_loss": 265.8578910827637, "training_acc": 72.0, "val_loss": 37.36463785171509, "val_acc": 84.0}
{"epoch": 26, "training_loss": 294.94626903533936, "training_acc": 73.0, "val_loss": 126.43847465515137, "val_acc": 40.0}
{"epoch": 27, "training_loss": 255.26178073883057, "training_acc": 68.0, "val_loss": 49.839189648628235, "val_acc": 76.0}
{"epoch": 28, "training_loss": 251.73590564727783, "training_acc": 66.0, "val_loss": 36.442333459854126, "val_acc": 88.0}
{"epoch": 29, "training_loss": 101.51751989126205, "training_acc": 84.0, "val_loss": 60.43968200683594, "val_acc": 60.0}
{"epoch": 30, "training_loss": 77.61701613664627, "training_acc": 79.0, "val_loss": 31.411212682724, "val_acc": 88.0}
{"epoch": 31, "training_loss": 126.87665939331055, "training_acc": 73.0, "val_loss": 78.21729779243469, "val_acc": 72.0}
{"epoch": 32, "training_loss": 267.8461537361145, "training_acc": 74.0, "val_loss": 71.72888517379761, "val_acc": 60.0}
{"epoch": 33, "training_loss": 128.60458540916443, "training_acc": 81.0, "val_loss": 53.811973333358765, "val_acc": 56.0}
{"epoch": 34, "training_loss": 191.04337882995605, "training_acc": 72.0, "val_loss": 73.45387935638428, "val_acc": 60.0}
{"epoch": 35, "training_loss": 132.61027187108812, "training_acc": 77.0, "val_loss": 140.50179719924927, "val_acc": 72.0}
{"epoch": 36, "training_loss": 344.81999588012695, "training_acc": 74.0, "val_loss": 239.85223770141602, "val_acc": 32.0}
{"epoch": 37, "training_loss": 208.29005432128906, "training_acc": 80.0, "val_loss": 185.10067462921143, "val_acc": 72.0}
{"epoch": 38, "training_loss": 441.9380746483803, "training_acc": 79.0, "val_loss": 348.7966775894165, "val_acc": 44.0}
{"epoch": 39, "training_loss": 639.6333236694336, "training_acc": 57.0, "val_loss": 200.19829273223877, "val_acc": 72.0}
{"epoch": 40, "training_loss": 597.7704238891602, "training_acc": 68.0, "val_loss": 126.52162313461304, "val_acc": 72.0}
{"epoch": 41, "training_loss": 585.2580223083496, "training_acc": 72.0, "val_loss": 133.04232358932495, "val_acc": 64.0}
{"epoch": 42, "training_loss": 425.18973124011063, "training_acc": 65.0, "val_loss": 195.84673643112183, "val_acc": 72.0}
{"epoch": 43, "training_loss": 765.0072788000107, "training_acc": 72.0, "val_loss": 174.52093362808228, "val_acc": 36.0}
{"epoch": 44, "training_loss": 284.4002281036228, "training_acc": 66.0, "val_loss": 55.01958727836609, "val_acc": 72.0}
{"epoch": 45, "training_loss": 170.6148281097412, "training_acc": 76.0, "val_loss": 49.79403614997864, "val_acc": 76.0}
{"epoch": 46, "training_loss": 411.12745475769043, "training_acc": 74.0, "val_loss": 172.6133108139038, "val_acc": 32.0}
{"epoch": 47, "training_loss": 274.01089179514884, "training_acc": 65.0, "val_loss": 86.82199716567993, "val_acc": 76.0}
{"epoch": 48, "training_loss": 185.59747245907784, "training_acc": 74.0, "val_loss": 89.47107791900635, "val_acc": 48.0}
{"epoch": 49, "training_loss": 211.2646141052246, "training_acc": 79.0, "val_loss": 75.85632801055908, "val_acc": 56.0}
