"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2574.075595855713, "training_acc": 72.0, "val_loss": 746.5836048126221, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2669.857955932617, "training_acc": 33.0, "val_loss": 244.2760467529297, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1007.2819862365723, "training_acc": 74.0, "val_loss": 53.24714779853821, "val_acc": 80.0}
{"epoch": 3, "training_loss": 733.6489772796631, "training_acc": 69.0, "val_loss": 107.1151852607727, "val_acc": 72.0}
{"epoch": 4, "training_loss": 414.23972272872925, "training_acc": 71.0, "val_loss": 39.41977322101593, "val_acc": 72.0}
{"epoch": 5, "training_loss": 178.2445214097388, "training_acc": 74.0, "val_loss": 37.304285168647766, "val_acc": 56.0}
{"epoch": 6, "training_loss": 279.22796058654785, "training_acc": 56.0, "val_loss": 69.51994895935059, "val_acc": 72.0}
{"epoch": 7, "training_loss": 172.64072548691183, "training_acc": 70.0, "val_loss": 122.57267236709595, "val_acc": 72.0}
{"epoch": 8, "training_loss": 356.6090774536133, "training_acc": 74.0, "val_loss": 220.80647945404053, "val_acc": 32.0}
{"epoch": 9, "training_loss": 454.5717258453369, "training_acc": 64.0, "val_loss": 243.28694343566895, "val_acc": 72.0}
{"epoch": 10, "training_loss": 739.236439704895, "training_acc": 73.0, "val_loss": 236.6783618927002, "val_acc": 32.0}
{"epoch": 11, "training_loss": 470.0721836090088, "training_acc": 60.0, "val_loss": 117.90637969970703, "val_acc": 72.0}
{"epoch": 12, "training_loss": 451.8912544250488, "training_acc": 56.0, "val_loss": 163.23988437652588, "val_acc": 72.0}
{"epoch": 13, "training_loss": 696.2968783378601, "training_acc": 72.0, "val_loss": 120.52558660507202, "val_acc": 48.0}
{"epoch": 14, "training_loss": 386.00273513793945, "training_acc": 54.0, "val_loss": 40.88398516178131, "val_acc": 72.0}
{"epoch": 15, "training_loss": 210.30304336547852, "training_acc": 64.0, "val_loss": 74.38486814498901, "val_acc": 72.0}
{"epoch": 16, "training_loss": 161.02520275115967, "training_acc": 68.0, "val_loss": 158.57160091400146, "val_acc": 72.0}
{"epoch": 17, "training_loss": 569.1079166661948, "training_acc": 72.0, "val_loss": 87.09924817085266, "val_acc": 56.0}
{"epoch": 18, "training_loss": 334.7289932332933, "training_acc": 62.0, "val_loss": 174.85250234603882, "val_acc": 72.0}
{"epoch": 19, "training_loss": 450.6212637126446, "training_acc": 76.0, "val_loss": 240.62767028808594, "val_acc": 28.0}
{"epoch": 20, "training_loss": 484.4101734161377, "training_acc": 59.0, "val_loss": 271.11315727233887, "val_acc": 72.0}
{"epoch": 21, "training_loss": 692.8925313949585, "training_acc": 72.0, "val_loss": 200.0232219696045, "val_acc": 40.0}
{"epoch": 22, "training_loss": 453.4772720336914, "training_acc": 63.0, "val_loss": 209.29467678070068, "val_acc": 72.0}
{"epoch": 23, "training_loss": 460.5902442932129, "training_acc": 72.0, "val_loss": 77.761709690094, "val_acc": 68.0}
{"epoch": 24, "training_loss": 300.03684349544346, "training_acc": 74.0, "val_loss": 125.60954093933105, "val_acc": 72.0}
