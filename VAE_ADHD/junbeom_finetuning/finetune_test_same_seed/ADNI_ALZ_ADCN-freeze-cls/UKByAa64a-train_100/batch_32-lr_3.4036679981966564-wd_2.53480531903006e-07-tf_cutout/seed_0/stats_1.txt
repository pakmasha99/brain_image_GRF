"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 21622.26277923584, "training_acc": 72.0, "val_loss": 12475.422668457031, "val_acc": 28.0}
{"epoch": 1, "training_loss": 29296.70509338379, "training_acc": 44.0, "val_loss": 3316.4295196533203, "val_acc": 72.0}
{"epoch": 2, "training_loss": 11713.000610351562, "training_acc": 68.0, "val_loss": 387.66283988952637, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2230.8468017578125, "training_acc": 70.0, "val_loss": 668.5287952423096, "val_acc": 28.0}
{"epoch": 4, "training_loss": 7045.513366699219, "training_acc": 64.0, "val_loss": 4353.908920288086, "val_acc": 72.0}
{"epoch": 5, "training_loss": 13965.330169677734, "training_acc": 72.0, "val_loss": 4587.237548828125, "val_acc": 28.0}
{"epoch": 6, "training_loss": 13469.220275878906, "training_acc": 28.0, "val_loss": 4121.002960205078, "val_acc": 72.0}
{"epoch": 7, "training_loss": 17392.96533203125, "training_acc": 72.0, "val_loss": 3040.789222717285, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7293.868438720703, "training_acc": 70.0, "val_loss": 5696.098327636719, "val_acc": 28.0}
{"epoch": 9, "training_loss": 11843.651123046875, "training_acc": 48.0, "val_loss": 5085.951614379883, "val_acc": 72.0}
{"epoch": 10, "training_loss": 22315.013671875, "training_acc": 72.0, "val_loss": 4007.2166442871094, "val_acc": 72.0}
{"epoch": 11, "training_loss": 10275.704223632812, "training_acc": 54.0, "val_loss": 210.9771966934204, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1679.2698974609375, "training_acc": 70.0, "val_loss": 557.2381019592285, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1573.6157760620117, "training_acc": 68.0, "val_loss": 479.8362731933594, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1387.0367050170898, "training_acc": 67.0, "val_loss": 59.160882234573364, "val_acc": 76.0}
{"epoch": 15, "training_loss": 3112.9794006347656, "training_acc": 54.0, "val_loss": 1251.8258094787598, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3972.119155883789, "training_acc": 58.0, "val_loss": 2303.125, "val_acc": 72.0}
{"epoch": 17, "training_loss": 14371.03955078125, "training_acc": 72.0, "val_loss": 4943.006896972656, "val_acc": 72.0}
{"epoch": 18, "training_loss": 16122.598815917969, "training_acc": 72.0, "val_loss": 2352.56290435791, "val_acc": 28.0}
{"epoch": 19, "training_loss": 11469.861755371094, "training_acc": 28.0, "val_loss": 3016.94278717041, "val_acc": 72.0}
{"epoch": 20, "training_loss": 11929.467651367188, "training_acc": 72.0, "val_loss": 455.02309799194336, "val_acc": 72.0}
{"epoch": 21, "training_loss": 12338.171081542969, "training_acc": 46.0, "val_loss": 1888.8675689697266, "val_acc": 72.0}
{"epoch": 22, "training_loss": 15015.032043457031, "training_acc": 72.0, "val_loss": 5084.788131713867, "val_acc": 72.0}
{"epoch": 23, "training_loss": 15663.085586547852, "training_acc": 72.0, "val_loss": 4017.0143127441406, "val_acc": 28.0}
{"epoch": 24, "training_loss": 14254.8173828125, "training_acc": 32.0, "val_loss": 4024.291229248047, "val_acc": 72.0}
{"epoch": 25, "training_loss": 19949.469177246094, "training_acc": 72.0, "val_loss": 5524.321746826172, "val_acc": 72.0}
{"epoch": 26, "training_loss": 16902.6201171875, "training_acc": 72.0, "val_loss": 3414.025115966797, "val_acc": 28.0}
{"epoch": 27, "training_loss": 8824.540786743164, "training_acc": 43.0, "val_loss": 2033.4489822387695, "val_acc": 72.0}
{"epoch": 28, "training_loss": 6777.00156211853, "training_acc": 71.0, "val_loss": 1365.239429473877, "val_acc": 28.0}
{"epoch": 29, "training_loss": 4362.997871398926, "training_acc": 54.0, "val_loss": 201.23534202575684, "val_acc": 48.0}
{"epoch": 30, "training_loss": 857.8995990753174, "training_acc": 65.0, "val_loss": 173.55576753616333, "val_acc": 76.0}
{"epoch": 31, "training_loss": 1761.1579132080078, "training_acc": 63.0, "val_loss": 1266.118049621582, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4844.193431854248, "training_acc": 70.0, "val_loss": 122.05450534820557, "val_acc": 68.0}
{"epoch": 33, "training_loss": 1424.4310684204102, "training_acc": 71.0, "val_loss": 1083.151626586914, "val_acc": 72.0}
