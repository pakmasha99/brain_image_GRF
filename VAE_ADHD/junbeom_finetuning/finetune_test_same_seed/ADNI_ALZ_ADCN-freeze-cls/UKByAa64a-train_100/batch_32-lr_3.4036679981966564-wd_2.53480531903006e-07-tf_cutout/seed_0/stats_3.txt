"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 31755.159408569336, "training_acc": 52.0, "val_loss": 633.1409931182861, "val_acc": 72.0}
{"epoch": 1, "training_loss": 46580.76876831055, "training_acc": 38.0, "val_loss": 250.44856071472168, "val_acc": 72.0}
{"epoch": 2, "training_loss": 7357.439361572266, "training_acc": 72.0, "val_loss": 1892.0841217041016, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4826.232219696045, "training_acc": 52.0, "val_loss": 1629.3447494506836, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7682.572204589844, "training_acc": 72.0, "val_loss": 713.9744758605957, "val_acc": 28.0}
{"epoch": 5, "training_loss": 2220.4178161621094, "training_acc": 52.0, "val_loss": 749.5755672454834, "val_acc": 72.0}
{"epoch": 6, "training_loss": 6103.224060058594, "training_acc": 72.0, "val_loss": 1153.5688400268555, "val_acc": 28.0}
{"epoch": 7, "training_loss": 4732.090545654297, "training_acc": 42.0, "val_loss": 2686.1289978027344, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7895.951805114746, "training_acc": 72.0, "val_loss": 1160.6825828552246, "val_acc": 28.0}
{"epoch": 9, "training_loss": 5778.436370849609, "training_acc": 52.0, "val_loss": 1030.694580078125, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2332.8693590164185, "training_acc": 63.0, "val_loss": 401.9144535064697, "val_acc": 28.0}
{"epoch": 11, "training_loss": 3334.2881774902344, "training_acc": 62.0, "val_loss": 77.3616373538971, "val_acc": 76.0}
{"epoch": 12, "training_loss": 8541.08568572998, "training_acc": 46.0, "val_loss": 982.411003112793, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3080.0922241210938, "training_acc": 56.0, "val_loss": 290.5428171157837, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2191.0916328430176, "training_acc": 60.0, "val_loss": 555.9942722320557, "val_acc": 28.0}
{"epoch": 15, "training_loss": 3192.9007873535156, "training_acc": 60.0, "val_loss": 418.7781810760498, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1116.6942443847656, "training_acc": 63.0, "val_loss": 2321.2467193603516, "val_acc": 72.0}
{"epoch": 17, "training_loss": 8333.967041015625, "training_acc": 72.0, "val_loss": 1897.943115234375, "val_acc": 28.0}
{"epoch": 18, "training_loss": 6077.158874511719, "training_acc": 44.0, "val_loss": 3239.4100189208984, "val_acc": 72.0}
{"epoch": 19, "training_loss": 9784.649017333984, "training_acc": 70.0, "val_loss": 63.459813594818115, "val_acc": 76.0}
{"epoch": 20, "training_loss": 1463.5838623046875, "training_acc": 59.0, "val_loss": 371.2050199508667, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4936.752624511719, "training_acc": 40.0, "val_loss": 3423.8937377929688, "val_acc": 72.0}
{"epoch": 22, "training_loss": 17454.557983398438, "training_acc": 72.0, "val_loss": 3714.3951416015625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 10281.21826171875, "training_acc": 49.0, "val_loss": 1602.4160385131836, "val_acc": 72.0}
{"epoch": 24, "training_loss": 9548.863220214844, "training_acc": 72.0, "val_loss": 1810.4093551635742, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5416.264343261719, "training_acc": 41.0, "val_loss": 2048.478889465332, "val_acc": 72.0}
{"epoch": 26, "training_loss": 10668.085693359375, "training_acc": 72.0, "val_loss": 801.9986152648926, "val_acc": 72.0}
{"epoch": 27, "training_loss": 7497.496337890625, "training_acc": 44.0, "val_loss": 1757.172966003418, "val_acc": 72.0}
{"epoch": 28, "training_loss": 9402.673583984375, "training_acc": 72.0, "val_loss": 1027.0795822143555, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2279.347053527832, "training_acc": 58.0, "val_loss": 154.89881038665771, "val_acc": 76.0}
{"epoch": 30, "training_loss": 1383.1837921142578, "training_acc": 64.0, "val_loss": 98.93442392349243, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1996.480842590332, "training_acc": 63.0, "val_loss": 920.0419425964355, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3147.897937774658, "training_acc": 58.0, "val_loss": 135.59293746948242, "val_acc": 80.0}
{"epoch": 33, "training_loss": 1607.241226196289, "training_acc": 65.0, "val_loss": 739.4152641296387, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1417.661015510559, "training_acc": 68.0, "val_loss": 1373.0207443237305, "val_acc": 28.0}
{"epoch": 35, "training_loss": 4789.874824523926, "training_acc": 52.0, "val_loss": 289.2293691635132, "val_acc": 40.0}
{"epoch": 36, "training_loss": 2148.2427825927734, "training_acc": 42.0, "val_loss": 1711.2627029418945, "val_acc": 72.0}
{"epoch": 37, "training_loss": 5935.901153564453, "training_acc": 68.0, "val_loss": 812.7641677856445, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3298.5303659439087, "training_acc": 71.0, "val_loss": 118.58832836151123, "val_acc": 72.0}
