"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7721.19464302063, "training_acc": 72.0, "val_loss": 3986.2380981445312, "val_acc": 28.0}
{"epoch": 1, "training_loss": 12898.390625, "training_acc": 32.0, "val_loss": 1922.508430480957, "val_acc": 72.0}
{"epoch": 2, "training_loss": 10580.899230957031, "training_acc": 72.0, "val_loss": 2947.193717956543, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8566.874420166016, "training_acc": 72.0, "val_loss": 1672.220230102539, "val_acc": 28.0}
{"epoch": 4, "training_loss": 10178.617111206055, "training_acc": 28.0, "val_loss": 238.64707946777344, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2428.509521484375, "training_acc": 72.0, "val_loss": 1123.1491088867188, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3704.5574951171875, "training_acc": 72.0, "val_loss": 881.0182571411133, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2450.581985473633, "training_acc": 50.0, "val_loss": 490.45071601867676, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1698.7960588932037, "training_acc": 52.0, "val_loss": 406.4913272857666, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2330.9376525878906, "training_acc": 72.0, "val_loss": 156.65138959884644, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1051.957290649414, "training_acc": 48.0, "val_loss": 1064.4757270812988, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4943.0794677734375, "training_acc": 72.0, "val_loss": 1070.6395149230957, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2793.2073974609375, "training_acc": 70.0, "val_loss": 1146.203327178955, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2772.865249633789, "training_acc": 44.0, "val_loss": 1851.7864227294922, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7676.3544921875, "training_acc": 72.0, "val_loss": 1410.9878540039062, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3895.8880310058594, "training_acc": 70.0, "val_loss": 1251.81884765625, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2883.779083251953, "training_acc": 48.0, "val_loss": 1422.3215103149414, "val_acc": 72.0}
{"epoch": 17, "training_loss": 5430.847351074219, "training_acc": 72.0, "val_loss": 247.0611810684204, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4168.5067138671875, "training_acc": 46.0, "val_loss": 348.92797470092773, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3811.6825256347656, "training_acc": 72.0, "val_loss": 997.5141525268555, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1899.098232269287, "training_acc": 66.0, "val_loss": 70.62329053878784, "val_acc": 72.0}
{"epoch": 21, "training_loss": 238.0197353363037, "training_acc": 75.0, "val_loss": 164.3422245979309, "val_acc": 72.0}
{"epoch": 22, "training_loss": 561.9602890014648, "training_acc": 72.0, "val_loss": 453.6582946777344, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1928.3449096679688, "training_acc": 58.0, "val_loss": 353.7928581237793, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1625.0272827148438, "training_acc": 44.0, "val_loss": 425.2767086029053, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1034.914493560791, "training_acc": 62.0, "val_loss": 352.61549949645996, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1607.661117553711, "training_acc": 72.0, "val_loss": 86.76684498786926, "val_acc": 28.0}
{"epoch": 27, "training_loss": 431.8767890930176, "training_acc": 55.0, "val_loss": 170.9509253501892, "val_acc": 72.0}
{"epoch": 28, "training_loss": 664.5242691040039, "training_acc": 72.0, "val_loss": 75.34539699554443, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1333.6100692749023, "training_acc": 69.0, "val_loss": 702.6382923126221, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1372.7176208496094, "training_acc": 73.0, "val_loss": 1433.0307006835938, "val_acc": 28.0}
{"epoch": 31, "training_loss": 3295.9154357910156, "training_acc": 46.0, "val_loss": 1598.8531112670898, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6252.609802246094, "training_acc": 72.0, "val_loss": 865.0030136108398, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2975.7381896972656, "training_acc": 54.0, "val_loss": 380.9643507003784, "val_acc": 28.0}
{"epoch": 34, "training_loss": 4214.2802734375, "training_acc": 52.0, "val_loss": 1532.5037956237793, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4151.7163009643555, "training_acc": 70.0, "val_loss": 374.1166353225708, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1321.2981567382812, "training_acc": 58.0, "val_loss": 295.424485206604, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1364.535150527954, "training_acc": 57.0, "val_loss": 340.74838161468506, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2310.063674926758, "training_acc": 72.0, "val_loss": 79.9891710281372, "val_acc": 40.0}
{"epoch": 39, "training_loss": 926.5305213928223, "training_acc": 49.0, "val_loss": 590.8926963806152, "val_acc": 72.0}
