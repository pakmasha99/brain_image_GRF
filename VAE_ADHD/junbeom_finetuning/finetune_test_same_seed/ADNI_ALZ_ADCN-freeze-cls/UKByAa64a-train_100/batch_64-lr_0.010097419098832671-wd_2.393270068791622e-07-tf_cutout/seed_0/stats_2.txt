"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 72.5317931175232, "training_acc": 40.0, "val_loss": 16.148750483989716, "val_acc": 72.0}
{"epoch": 1, "training_loss": 64.33998608589172, "training_acc": 72.0, "val_loss": 15.241411328315735, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.31888008117676, "training_acc": 72.0, "val_loss": 14.490173757076263, "val_acc": 76.0}
{"epoch": 3, "training_loss": 57.56431698799133, "training_acc": 72.0, "val_loss": 14.694584906101227, "val_acc": 60.0}
{"epoch": 4, "training_loss": 59.79130935668945, "training_acc": 73.0, "val_loss": 14.078366756439209, "val_acc": 68.0}
{"epoch": 5, "training_loss": 54.02128458023071, "training_acc": 73.0, "val_loss": 14.269417524337769, "val_acc": 72.0}
{"epoch": 6, "training_loss": 54.894230365753174, "training_acc": 71.0, "val_loss": 14.474615454673767, "val_acc": 76.0}
{"epoch": 7, "training_loss": 54.76076817512512, "training_acc": 73.0, "val_loss": 14.304140210151672, "val_acc": 68.0}
{"epoch": 8, "training_loss": 54.85562515258789, "training_acc": 72.0, "val_loss": 14.121371507644653, "val_acc": 72.0}
{"epoch": 9, "training_loss": 53.85895109176636, "training_acc": 72.0, "val_loss": 14.127956330776215, "val_acc": 72.0}
{"epoch": 10, "training_loss": 56.36406421661377, "training_acc": 70.0, "val_loss": 14.257334172725677, "val_acc": 68.0}
{"epoch": 11, "training_loss": 52.7001895904541, "training_acc": 73.0, "val_loss": 14.435259997844696, "val_acc": 68.0}
{"epoch": 12, "training_loss": 51.69983768463135, "training_acc": 71.0, "val_loss": 14.358557760715485, "val_acc": 68.0}
{"epoch": 13, "training_loss": 54.02825403213501, "training_acc": 73.0, "val_loss": 14.317870140075684, "val_acc": 68.0}
{"epoch": 14, "training_loss": 51.3206650018692, "training_acc": 74.0, "val_loss": 14.101697504520416, "val_acc": 72.0}
{"epoch": 15, "training_loss": 52.927310943603516, "training_acc": 72.0, "val_loss": 14.127431809902191, "val_acc": 68.0}
{"epoch": 16, "training_loss": 52.89651584625244, "training_acc": 74.0, "val_loss": 14.201639592647552, "val_acc": 68.0}
{"epoch": 17, "training_loss": 53.516040682792664, "training_acc": 74.0, "val_loss": 14.333301782608032, "val_acc": 68.0}
{"epoch": 18, "training_loss": 51.83583080768585, "training_acc": 72.0, "val_loss": 14.100801944732666, "val_acc": 68.0}
{"epoch": 19, "training_loss": 50.79055404663086, "training_acc": 76.0, "val_loss": 14.024361968040466, "val_acc": 72.0}
{"epoch": 20, "training_loss": 51.1839485168457, "training_acc": 75.0, "val_loss": 14.086560904979706, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50.72770380973816, "training_acc": 75.0, "val_loss": 14.068745076656342, "val_acc": 72.0}
{"epoch": 22, "training_loss": 51.98153471946716, "training_acc": 76.0, "val_loss": 14.023302495479584, "val_acc": 72.0}
{"epoch": 23, "training_loss": 52.1019252538681, "training_acc": 74.0, "val_loss": 14.136354625225067, "val_acc": 72.0}
{"epoch": 24, "training_loss": 50.31325590610504, "training_acc": 76.0, "val_loss": 14.336934685707092, "val_acc": 68.0}
{"epoch": 25, "training_loss": 51.23562264442444, "training_acc": 76.0, "val_loss": 14.425501227378845, "val_acc": 68.0}
{"epoch": 26, "training_loss": 51.249070167541504, "training_acc": 75.0, "val_loss": 14.2393097281456, "val_acc": 72.0}
{"epoch": 27, "training_loss": 50.40289807319641, "training_acc": 78.0, "val_loss": 14.08359557390213, "val_acc": 72.0}
{"epoch": 28, "training_loss": 50.83129334449768, "training_acc": 81.0, "val_loss": 14.136408269405365, "val_acc": 72.0}
{"epoch": 29, "training_loss": 49.2406507730484, "training_acc": 77.0, "val_loss": 14.414899051189423, "val_acc": 68.0}
{"epoch": 30, "training_loss": 51.84619164466858, "training_acc": 74.0, "val_loss": 14.529767632484436, "val_acc": 68.0}
{"epoch": 31, "training_loss": 49.38311815261841, "training_acc": 75.0, "val_loss": 14.247561991214752, "val_acc": 68.0}
{"epoch": 32, "training_loss": 49.215532183647156, "training_acc": 78.0, "val_loss": 14.181837439537048, "val_acc": 72.0}
{"epoch": 33, "training_loss": 48.69583535194397, "training_acc": 79.0, "val_loss": 14.368294179439545, "val_acc": 68.0}
{"epoch": 34, "training_loss": 50.52603077888489, "training_acc": 75.0, "val_loss": 14.88579660654068, "val_acc": 68.0}
{"epoch": 35, "training_loss": 49.61493921279907, "training_acc": 75.0, "val_loss": 14.362750947475433, "val_acc": 68.0}
{"epoch": 36, "training_loss": 47.59237730503082, "training_acc": 76.0, "val_loss": 14.236678183078766, "val_acc": 72.0}
{"epoch": 37, "training_loss": 50.00357449054718, "training_acc": 82.0, "val_loss": 14.29813802242279, "val_acc": 68.0}
{"epoch": 38, "training_loss": 47.93630862236023, "training_acc": 76.0, "val_loss": 14.745987951755524, "val_acc": 68.0}
{"epoch": 39, "training_loss": 49.66840863227844, "training_acc": 77.0, "val_loss": 14.681658148765564, "val_acc": 64.0}
{"epoch": 40, "training_loss": 49.45994305610657, "training_acc": 79.0, "val_loss": 14.24337774515152, "val_acc": 68.0}
{"epoch": 41, "training_loss": 48.75858235359192, "training_acc": 76.0, "val_loss": 14.193004369735718, "val_acc": 72.0}
