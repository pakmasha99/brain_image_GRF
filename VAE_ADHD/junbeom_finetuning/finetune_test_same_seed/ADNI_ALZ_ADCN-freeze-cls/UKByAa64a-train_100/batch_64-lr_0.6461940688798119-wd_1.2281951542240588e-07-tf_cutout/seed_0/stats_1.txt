"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2256.713363647461, "training_acc": 72.0, "val_loss": 1594.683837890625, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4864.4090576171875, "training_acc": 72.0, "val_loss": 2111.423110961914, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7523.367904663086, "training_acc": 28.0, "val_loss": 233.46502780914307, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1789.9330291748047, "training_acc": 72.0, "val_loss": 790.5143737792969, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2966.356559753418, "training_acc": 72.0, "val_loss": 330.89659214019775, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1683.5443267822266, "training_acc": 52.0, "val_loss": 265.4336452484131, "val_acc": 28.0}
{"epoch": 6, "training_loss": 973.1124420166016, "training_acc": 50.0, "val_loss": 633.2835674285889, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2649.888473510742, "training_acc": 72.0, "val_loss": 672.6154804229736, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2366.5926818847656, "training_acc": 72.0, "val_loss": 134.13333892822266, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1764.1746673583984, "training_acc": 52.0, "val_loss": 919.492244720459, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2433.211199760437, "training_acc": 28.0, "val_loss": 579.709529876709, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2912.8989868164062, "training_acc": 72.0, "val_loss": 1245.3618049621582, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5219.675598144531, "training_acc": 72.0, "val_loss": 1297.8663444519043, "val_acc": 72.0}
{"epoch": 13, "training_loss": 4946.504455566406, "training_acc": 72.0, "val_loss": 794.1727161407471, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2701.119915008545, "training_acc": 72.0, "val_loss": 240.7268762588501, "val_acc": 28.0}
{"epoch": 15, "training_loss": 1423.6035461425781, "training_acc": 28.0, "val_loss": 52.51769423484802, "val_acc": 72.0}
{"epoch": 16, "training_loss": 451.774845123291, "training_acc": 72.0, "val_loss": 143.45613718032837, "val_acc": 72.0}
{"epoch": 17, "training_loss": 435.14076137542725, "training_acc": 56.0, "val_loss": 111.43062114715576, "val_acc": 72.0}
{"epoch": 18, "training_loss": 444.07879066467285, "training_acc": 72.0, "val_loss": 43.96222233772278, "val_acc": 28.0}
{"epoch": 19, "training_loss": 432.07508087158203, "training_acc": 36.0, "val_loss": 146.78304195404053, "val_acc": 72.0}
{"epoch": 20, "training_loss": 383.99068880081177, "training_acc": 72.0, "val_loss": 501.823091506958, "val_acc": 28.0}
{"epoch": 21, "training_loss": 1577.92183303833, "training_acc": 28.0, "val_loss": 326.6364097595215, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1579.6482009887695, "training_acc": 72.0, "val_loss": 695.7783699035645, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2785.2022857666016, "training_acc": 72.0, "val_loss": 557.6080799102783, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1838.5667915344238, "training_acc": 72.0, "val_loss": 97.05582857131958, "val_acc": 28.0}
{"epoch": 25, "training_loss": 361.64825344085693, "training_acc": 28.0, "val_loss": 245.12615203857422, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1139.0749549865723, "training_acc": 72.0, "val_loss": 382.9679489135742, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1376.8622016906738, "training_acc": 72.0, "val_loss": 39.72359299659729, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1522.2944030761719, "training_acc": 44.0, "val_loss": 607.4940204620361, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1711.1481323242188, "training_acc": 44.0, "val_loss": 332.03747272491455, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1384.4173049926758, "training_acc": 72.0, "val_loss": 347.95281887054443, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1154.7468872070312, "training_acc": 72.0, "val_loss": 170.56478261947632, "val_acc": 28.0}
{"epoch": 32, "training_loss": 468.22059202194214, "training_acc": 32.0, "val_loss": 274.4894027709961, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1272.7083930969238, "training_acc": 72.0, "val_loss": 440.9642696380615, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1607.109230041504, "training_acc": 72.0, "val_loss": 126.2027382850647, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1326.4735565185547, "training_acc": 46.0, "val_loss": 384.51621532440186, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1265.1165523529053, "training_acc": 44.0, "val_loss": 400.72789192199707, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1657.0745735168457, "training_acc": 72.0, "val_loss": 404.5102596282959, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1467.133295059204, "training_acc": 72.0, "val_loss": 52.54920721054077, "val_acc": 28.0}
{"epoch": 39, "training_loss": 146.82223534584045, "training_acc": 47.0, "val_loss": 64.19819593429565, "val_acc": 72.0}
{"epoch": 40, "training_loss": 176.64346420764923, "training_acc": 75.0, "val_loss": 51.45379304885864, "val_acc": 36.0}
{"epoch": 41, "training_loss": 313.33936500549316, "training_acc": 53.0, "val_loss": 257.4840307235718, "val_acc": 72.0}
{"epoch": 42, "training_loss": 961.4484062194824, "training_acc": 72.0, "val_loss": 49.70370829105377, "val_acc": 72.0}
{"epoch": 43, "training_loss": 861.7531661987305, "training_acc": 58.0, "val_loss": 389.33446407318115, "val_acc": 28.0}
{"epoch": 44, "training_loss": 1321.1777229309082, "training_acc": 42.0, "val_loss": 406.7187786102295, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1686.8280334472656, "training_acc": 72.0, "val_loss": 396.94013595581055, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1313.0430221557617, "training_acc": 72.0, "val_loss": 135.27201414108276, "val_acc": 28.0}
