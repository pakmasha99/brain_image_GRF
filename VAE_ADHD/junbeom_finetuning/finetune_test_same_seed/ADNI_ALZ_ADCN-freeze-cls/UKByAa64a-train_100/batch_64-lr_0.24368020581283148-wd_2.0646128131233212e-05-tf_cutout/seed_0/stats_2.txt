"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 355.18529891967773, "training_acc": 49.0, "val_loss": 217.4128770828247, "val_acc": 72.0}
{"epoch": 1, "training_loss": 676.6084079742432, "training_acc": 72.0, "val_loss": 55.11956214904785, "val_acc": 28.0}
{"epoch": 2, "training_loss": 252.86043739318848, "training_acc": 35.0, "val_loss": 43.7019020318985, "val_acc": 72.0}
{"epoch": 3, "training_loss": 203.18656253814697, "training_acc": 72.0, "val_loss": 61.21227741241455, "val_acc": 72.0}
{"epoch": 4, "training_loss": 155.43607759475708, "training_acc": 74.0, "val_loss": 46.12036645412445, "val_acc": 40.0}
{"epoch": 5, "training_loss": 257.8948554992676, "training_acc": 43.0, "val_loss": 28.230509161949158, "val_acc": 72.0}
{"epoch": 6, "training_loss": 109.82517099380493, "training_acc": 74.0, "val_loss": 73.59088659286499, "val_acc": 72.0}
{"epoch": 7, "training_loss": 244.43472003936768, "training_acc": 72.0, "val_loss": 35.853320360183716, "val_acc": 72.0}
{"epoch": 8, "training_loss": 102.11192893981934, "training_acc": 69.0, "val_loss": 43.30608248710632, "val_acc": 40.0}
{"epoch": 9, "training_loss": 167.48482537269592, "training_acc": 57.0, "val_loss": 38.47699165344238, "val_acc": 72.0}
{"epoch": 10, "training_loss": 116.65088939666748, "training_acc": 72.0, "val_loss": 33.530956506729126, "val_acc": 72.0}
{"epoch": 11, "training_loss": 80.78436660766602, "training_acc": 75.0, "val_loss": 28.023448586463928, "val_acc": 48.0}
{"epoch": 12, "training_loss": 104.2040708065033, "training_acc": 52.0, "val_loss": 26.691734790802002, "val_acc": 72.0}
{"epoch": 13, "training_loss": 64.45864343643188, "training_acc": 77.0, "val_loss": 18.800850212574005, "val_acc": 64.0}
{"epoch": 14, "training_loss": 60.75837802886963, "training_acc": 70.0, "val_loss": 22.792983055114746, "val_acc": 72.0}
{"epoch": 15, "training_loss": 66.98359179496765, "training_acc": 72.0, "val_loss": 15.755386650562286, "val_acc": 72.0}
{"epoch": 16, "training_loss": 54.80510425567627, "training_acc": 74.0, "val_loss": 13.712146878242493, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.24537968635559, "training_acc": 70.0, "val_loss": 22.556352615356445, "val_acc": 72.0}
{"epoch": 18, "training_loss": 62.57361841201782, "training_acc": 73.0, "val_loss": 16.1411315202713, "val_acc": 56.0}
{"epoch": 19, "training_loss": 67.51569211483002, "training_acc": 67.0, "val_loss": 18.95376145839691, "val_acc": 72.0}
{"epoch": 20, "training_loss": 50.17431718111038, "training_acc": 79.0, "val_loss": 12.430807203054428, "val_acc": 72.0}
{"epoch": 21, "training_loss": 48.420106172561646, "training_acc": 72.0, "val_loss": 13.711751997470856, "val_acc": 76.0}
{"epoch": 22, "training_loss": 43.215951800346375, "training_acc": 81.0, "val_loss": 13.21457326412201, "val_acc": 76.0}
{"epoch": 23, "training_loss": 38.23507118225098, "training_acc": 85.0, "val_loss": 13.30718994140625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 40.20897650718689, "training_acc": 81.0, "val_loss": 15.992146730422974, "val_acc": 72.0}
{"epoch": 25, "training_loss": 44.98034608364105, "training_acc": 76.0, "val_loss": 13.175316154956818, "val_acc": 68.0}
{"epoch": 26, "training_loss": 39.68630611896515, "training_acc": 83.0, "val_loss": 19.212962687015533, "val_acc": 72.0}
{"epoch": 27, "training_loss": 48.63507091999054, "training_acc": 78.0, "val_loss": 13.764403760433197, "val_acc": 72.0}
{"epoch": 28, "training_loss": 37.172319173812866, "training_acc": 81.0, "val_loss": 14.95078057050705, "val_acc": 72.0}
{"epoch": 29, "training_loss": 36.66229045391083, "training_acc": 83.0, "val_loss": 14.558488130569458, "val_acc": 64.0}
{"epoch": 30, "training_loss": 42.4663987159729, "training_acc": 79.0, "val_loss": 17.60944277048111, "val_acc": 72.0}
{"epoch": 31, "training_loss": 40.794432401657104, "training_acc": 80.0, "val_loss": 14.254559576511383, "val_acc": 68.0}
{"epoch": 32, "training_loss": 38.65551245212555, "training_acc": 83.0, "val_loss": 15.23200124502182, "val_acc": 68.0}
{"epoch": 33, "training_loss": 36.61404860019684, "training_acc": 82.0, "val_loss": 13.538442552089691, "val_acc": 68.0}
{"epoch": 34, "training_loss": 35.7250257730484, "training_acc": 88.0, "val_loss": 13.903650641441345, "val_acc": 68.0}
{"epoch": 35, "training_loss": 35.70328426361084, "training_acc": 88.0, "val_loss": 13.952980935573578, "val_acc": 68.0}
{"epoch": 36, "training_loss": 33.74262046813965, "training_acc": 89.0, "val_loss": 13.53222280740738, "val_acc": 68.0}
{"epoch": 37, "training_loss": 34.848907351493835, "training_acc": 87.0, "val_loss": 13.423457741737366, "val_acc": 68.0}
{"epoch": 38, "training_loss": 32.418169021606445, "training_acc": 85.0, "val_loss": 15.736521780490875, "val_acc": 68.0}
{"epoch": 39, "training_loss": 34.61241400241852, "training_acc": 87.0, "val_loss": 14.20343965291977, "val_acc": 68.0}
