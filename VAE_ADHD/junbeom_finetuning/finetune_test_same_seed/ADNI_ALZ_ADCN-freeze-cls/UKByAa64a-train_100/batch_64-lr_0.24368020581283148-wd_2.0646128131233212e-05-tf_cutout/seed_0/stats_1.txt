"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 340.2018928527832, "training_acc": 70.0, "val_loss": 194.4090485572815, "val_acc": 72.0}
{"epoch": 1, "training_loss": 585.4404969215393, "training_acc": 72.0, "val_loss": 283.46996307373047, "val_acc": 28.0}
{"epoch": 2, "training_loss": 985.2228908538818, "training_acc": 28.0, "val_loss": 22.957584261894226, "val_acc": 56.0}
{"epoch": 3, "training_loss": 154.9070749282837, "training_acc": 74.0, "val_loss": 122.86943197250366, "val_acc": 72.0}
{"epoch": 4, "training_loss": 466.55066871643066, "training_acc": 72.0, "val_loss": 91.37129187583923, "val_acc": 72.0}
{"epoch": 5, "training_loss": 276.23846912384033, "training_acc": 74.0, "val_loss": 59.1259241104126, "val_acc": 56.0}
{"epoch": 6, "training_loss": 281.4371166229248, "training_acc": 55.0, "val_loss": 89.404958486557, "val_acc": 60.0}
{"epoch": 7, "training_loss": 317.69006156921387, "training_acc": 53.0, "val_loss": 50.3417432308197, "val_acc": 76.0}
{"epoch": 8, "training_loss": 251.09039783477783, "training_acc": 73.0, "val_loss": 96.41644358634949, "val_acc": 72.0}
{"epoch": 9, "training_loss": 362.64148902893066, "training_acc": 72.0, "val_loss": 53.208935260772705, "val_acc": 80.0}
{"epoch": 10, "training_loss": 163.31655740737915, "training_acc": 74.0, "val_loss": 68.7820315361023, "val_acc": 60.0}
{"epoch": 11, "training_loss": 310.02757453918457, "training_acc": 49.0, "val_loss": 41.31269454956055, "val_acc": 56.0}
{"epoch": 12, "training_loss": 128.4203224182129, "training_acc": 68.0, "val_loss": 47.85244166851044, "val_acc": 72.0}
{"epoch": 13, "training_loss": 204.0073642730713, "training_acc": 72.0, "val_loss": 41.47331118583679, "val_acc": 72.0}
{"epoch": 14, "training_loss": 154.93992865085602, "training_acc": 71.0, "val_loss": 35.82981526851654, "val_acc": 52.0}
{"epoch": 15, "training_loss": 125.09431838989258, "training_acc": 57.0, "val_loss": 14.328683912754059, "val_acc": 72.0}
{"epoch": 16, "training_loss": 73.23481464385986, "training_acc": 74.0, "val_loss": 30.486109852790833, "val_acc": 72.0}
{"epoch": 17, "training_loss": 89.6128978729248, "training_acc": 75.0, "val_loss": 27.92001962661743, "val_acc": 44.0}
{"epoch": 18, "training_loss": 95.17607808113098, "training_acc": 51.0, "val_loss": 24.651016294956207, "val_acc": 72.0}
{"epoch": 19, "training_loss": 88.93422651290894, "training_acc": 72.0, "val_loss": 22.466571629047394, "val_acc": 72.0}
{"epoch": 20, "training_loss": 68.4501850605011, "training_acc": 69.0, "val_loss": 23.270325362682343, "val_acc": 44.0}
{"epoch": 21, "training_loss": 63.054821372032166, "training_acc": 68.0, "val_loss": 32.94930160045624, "val_acc": 72.0}
{"epoch": 22, "training_loss": 97.25538182258606, "training_acc": 72.0, "val_loss": 15.444523096084595, "val_acc": 68.0}
{"epoch": 23, "training_loss": 67.50133848190308, "training_acc": 69.0, "val_loss": 17.009936273097992, "val_acc": 64.0}
{"epoch": 24, "training_loss": 51.62192952632904, "training_acc": 78.0, "val_loss": 35.52544713020325, "val_acc": 72.0}
{"epoch": 25, "training_loss": 93.17623901367188, "training_acc": 73.0, "val_loss": 16.835889220237732, "val_acc": 60.0}
{"epoch": 26, "training_loss": 57.03519082069397, "training_acc": 73.0, "val_loss": 16.73983335494995, "val_acc": 60.0}
{"epoch": 27, "training_loss": 43.92272233963013, "training_acc": 81.0, "val_loss": 25.52798092365265, "val_acc": 72.0}
{"epoch": 28, "training_loss": 57.73180365562439, "training_acc": 76.0, "val_loss": 24.091635644435883, "val_acc": 48.0}
{"epoch": 29, "training_loss": 63.04317820072174, "training_acc": 64.0, "val_loss": 20.87370455265045, "val_acc": 76.0}
{"epoch": 30, "training_loss": 50.76134657859802, "training_acc": 76.0, "val_loss": 16.778676211833954, "val_acc": 56.0}
{"epoch": 31, "training_loss": 55.27930021286011, "training_acc": 76.0, "val_loss": 19.374632835388184, "val_acc": 76.0}
{"epoch": 32, "training_loss": 52.95910668373108, "training_acc": 75.0, "val_loss": 16.681350767612457, "val_acc": 72.0}
{"epoch": 33, "training_loss": 53.19010281562805, "training_acc": 69.0, "val_loss": 15.908938646316528, "val_acc": 68.0}
{"epoch": 34, "training_loss": 40.774877309799194, "training_acc": 78.0, "val_loss": 19.463202357292175, "val_acc": 76.0}
