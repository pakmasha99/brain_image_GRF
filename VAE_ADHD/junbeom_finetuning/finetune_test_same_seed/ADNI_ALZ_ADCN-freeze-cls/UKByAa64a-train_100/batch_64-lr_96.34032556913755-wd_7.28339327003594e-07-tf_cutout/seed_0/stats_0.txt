"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 153075.20002365112, "training_acc": 72.0, "val_loss": 69744.01245117188, "val_acc": 72.0}
{"epoch": 1, "training_loss": 188164.46118164062, "training_acc": 72.0, "val_loss": 107730.1513671875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 447963.21484375, "training_acc": 28.0, "val_loss": 17034.59014892578, "val_acc": 36.0}
{"epoch": 3, "training_loss": 110342.53173828125, "training_acc": 52.0, "val_loss": 65358.10546875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 295180.1142578125, "training_acc": 72.0, "val_loss": 87482.81860351562, "val_acc": 72.0}
{"epoch": 5, "training_loss": 350172.72802734375, "training_acc": 72.0, "val_loss": 67521.98486328125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 241409.91357421875, "training_acc": 72.0, "val_loss": 21389.488220214844, "val_acc": 72.0}
{"epoch": 7, "training_loss": 108779.42041015625, "training_acc": 65.0, "val_loss": 26308.3984375, "val_acc": 44.0}
{"epoch": 8, "training_loss": 165334.6025390625, "training_acc": 46.0, "val_loss": 9892.389678955078, "val_acc": 68.0}
{"epoch": 9, "training_loss": 79424.42358398438, "training_acc": 67.0, "val_loss": 22759.44061279297, "val_acc": 72.0}
{"epoch": 10, "training_loss": 96193.74072265625, "training_acc": 74.0, "val_loss": 28913.720703125, "val_acc": 72.0}
{"epoch": 11, "training_loss": 96796.74560546875, "training_acc": 73.0, "val_loss": 6629.8858642578125, "val_acc": 76.0}
{"epoch": 12, "training_loss": 54037.714599609375, "training_acc": 63.0, "val_loss": 13117.637634277344, "val_acc": 56.0}
{"epoch": 13, "training_loss": 71802.16577148438, "training_acc": 58.0, "val_loss": 9603.46450805664, "val_acc": 72.0}
{"epoch": 14, "training_loss": 48159.1142578125, "training_acc": 73.0, "val_loss": 19640.90576171875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 53581.931884765625, "training_acc": 72.0, "val_loss": 9948.097229003906, "val_acc": 56.0}
{"epoch": 16, "training_loss": 39566.25988769531, "training_acc": 44.0, "val_loss": 6787.859344482422, "val_acc": 68.0}
{"epoch": 17, "training_loss": 21644.26055908203, "training_acc": 73.0, "val_loss": 9669.22836303711, "val_acc": 72.0}
{"epoch": 18, "training_loss": 17953.889099121094, "training_acc": 74.0, "val_loss": 8070.308685302734, "val_acc": 52.0}
{"epoch": 19, "training_loss": 17479.010192871094, "training_acc": 64.0, "val_loss": 7200.775146484375, "val_acc": 72.0}
{"epoch": 20, "training_loss": 16256.775421142578, "training_acc": 73.0, "val_loss": 3455.3497314453125, "val_acc": 64.0}
{"epoch": 21, "training_loss": 13487.743896484375, "training_acc": 70.0, "val_loss": 1682.3999404907227, "val_acc": 80.0}
{"epoch": 22, "training_loss": 9810.080444335938, "training_acc": 72.0, "val_loss": 2694.803237915039, "val_acc": 72.0}
{"epoch": 23, "training_loss": 10193.201477050781, "training_acc": 80.0, "val_loss": 2846.2697982788086, "val_acc": 64.0}
{"epoch": 24, "training_loss": 8442.598007202148, "training_acc": 69.0, "val_loss": 1013.6359214782715, "val_acc": 76.0}
{"epoch": 25, "training_loss": 3740.802177429199, "training_acc": 80.0, "val_loss": 3537.667465209961, "val_acc": 48.0}
{"epoch": 26, "training_loss": 14411.281555175781, "training_acc": 61.0, "val_loss": 5523.057174682617, "val_acc": 72.0}
{"epoch": 27, "training_loss": 18397.05938720703, "training_acc": 65.0, "val_loss": 1240.6988143920898, "val_acc": 80.0}
{"epoch": 28, "training_loss": 6531.568267822266, "training_acc": 84.0, "val_loss": 1557.1121215820312, "val_acc": 68.0}
{"epoch": 29, "training_loss": 5940.241516113281, "training_acc": 74.0, "val_loss": 2794.283103942871, "val_acc": 72.0}
{"epoch": 30, "training_loss": 6889.706127166748, "training_acc": 78.0, "val_loss": 1177.5612831115723, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3859.5359497070312, "training_acc": 82.0, "val_loss": 4392.851638793945, "val_acc": 48.0}
{"epoch": 32, "training_loss": 18029.54217529297, "training_acc": 59.0, "val_loss": 10251.89208984375, "val_acc": 72.0}
{"epoch": 33, "training_loss": 23973.464126586914, "training_acc": 75.0, "val_loss": 15767.070007324219, "val_acc": 32.0}
{"epoch": 34, "training_loss": 43693.745597839355, "training_acc": 48.0, "val_loss": 6902.35595703125, "val_acc": 72.0}
{"epoch": 35, "training_loss": 14405.239532470703, "training_acc": 77.0, "val_loss": 5970.142364501953, "val_acc": 56.0}
{"epoch": 36, "training_loss": 15311.995147705078, "training_acc": 64.0, "val_loss": 5082.172775268555, "val_acc": 72.0}
{"epoch": 37, "training_loss": 16949.3427734375, "training_acc": 80.0, "val_loss": 2718.012237548828, "val_acc": 64.0}
{"epoch": 38, "training_loss": 10967.864334106445, "training_acc": 71.0, "val_loss": 1864.141845703125, "val_acc": 76.0}
{"epoch": 39, "training_loss": 5716.129180908203, "training_acc": 80.0, "val_loss": 3896.5476989746094, "val_acc": 48.0}
{"epoch": 40, "training_loss": 16887.010375976562, "training_acc": 56.0, "val_loss": 6106.343078613281, "val_acc": 72.0}
{"epoch": 41, "training_loss": 14102.814208984375, "training_acc": 69.0, "val_loss": 1734.5050811767578, "val_acc": 72.0}
{"epoch": 42, "training_loss": 2252.087257385254, "training_acc": 86.0, "val_loss": 1202.2741317749023, "val_acc": 80.0}
{"epoch": 43, "training_loss": 2335.7207107543945, "training_acc": 85.0, "val_loss": 4374.017333984375, "val_acc": 72.0}
