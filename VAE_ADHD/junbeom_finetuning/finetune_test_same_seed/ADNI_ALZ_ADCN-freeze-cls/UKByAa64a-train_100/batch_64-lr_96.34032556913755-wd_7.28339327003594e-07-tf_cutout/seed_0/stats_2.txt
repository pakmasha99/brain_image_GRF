"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 102842.42430496216, "training_acc": 51.0, "val_loss": 79354.0283203125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 253084.90600585938, "training_acc": 72.0, "val_loss": 84564.99633789062, "val_acc": 28.0}
{"epoch": 2, "training_loss": 340086.3251953125, "training_acc": 28.0, "val_loss": 12210.283660888672, "val_acc": 72.0}
{"epoch": 3, "training_loss": 92818.439453125, "training_acc": 74.0, "val_loss": 53578.326416015625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 198876.7587890625, "training_acc": 72.0, "val_loss": 39969.18029785156, "val_acc": 72.0}
{"epoch": 5, "training_loss": 98416.2509765625, "training_acc": 71.0, "val_loss": 17118.417358398438, "val_acc": 56.0}
{"epoch": 6, "training_loss": 127996.1044921875, "training_acc": 54.0, "val_loss": 29115.365600585938, "val_acc": 44.0}
{"epoch": 7, "training_loss": 127141.20336914062, "training_acc": 49.0, "val_loss": 25704.141235351562, "val_acc": 72.0}
{"epoch": 8, "training_loss": 97442.3076171875, "training_acc": 72.0, "val_loss": 38093.93310546875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 117007.74145507812, "training_acc": 72.0, "val_loss": 16894.439697265625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 49528.41442871094, "training_acc": 70.0, "val_loss": 18296.72088623047, "val_acc": 48.0}
{"epoch": 11, "training_loss": 85156.12719726562, "training_acc": 53.0, "val_loss": 11307.571411132812, "val_acc": 68.0}
{"epoch": 12, "training_loss": 31027.363647460938, "training_acc": 81.0, "val_loss": 26073.468017578125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 81912.73852539062, "training_acc": 72.0, "val_loss": 11415.087890625, "val_acc": 68.0}
{"epoch": 14, "training_loss": 45427.93017578125, "training_acc": 63.0, "val_loss": 16419.004821777344, "val_acc": 44.0}
{"epoch": 15, "training_loss": 48690.26477050781, "training_acc": 55.0, "val_loss": 17070.741271972656, "val_acc": 72.0}
{"epoch": 16, "training_loss": 50033.5283203125, "training_acc": 72.0, "val_loss": 13401.446533203125, "val_acc": 72.0}
{"epoch": 17, "training_loss": 28092.509765625, "training_acc": 70.0, "val_loss": 8850.071716308594, "val_acc": 52.0}
{"epoch": 18, "training_loss": 32139.38623046875, "training_acc": 64.0, "val_loss": 9414.681243896484, "val_acc": 72.0}
{"epoch": 19, "training_loss": 17641.345581054688, "training_acc": 75.0, "val_loss": 5133.347702026367, "val_acc": 64.0}
{"epoch": 20, "training_loss": 15938.591979980469, "training_acc": 70.0, "val_loss": 5039.262008666992, "val_acc": 60.0}
{"epoch": 21, "training_loss": 9616.211639404297, "training_acc": 82.0, "val_loss": 3597.7760314941406, "val_acc": 60.0}
{"epoch": 22, "training_loss": 6056.7432861328125, "training_acc": 80.0, "val_loss": 3173.7045288085938, "val_acc": 48.0}
{"epoch": 23, "training_loss": 7874.866149902344, "training_acc": 74.0, "val_loss": 2626.976776123047, "val_acc": 56.0}
{"epoch": 24, "training_loss": 9825.058197021484, "training_acc": 68.0, "val_loss": 1275.5772590637207, "val_acc": 68.0}
{"epoch": 25, "training_loss": 5524.292724609375, "training_acc": 74.0, "val_loss": 2826.863670349121, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6291.7625732421875, "training_acc": 79.0, "val_loss": 2032.2622299194336, "val_acc": 76.0}
{"epoch": 27, "training_loss": 6697.363220214844, "training_acc": 76.0, "val_loss": 3384.3643188476562, "val_acc": 76.0}
{"epoch": 28, "training_loss": 7137.649078369141, "training_acc": 79.0, "val_loss": 1860.8861923217773, "val_acc": 76.0}
{"epoch": 29, "training_loss": 3648.8560180664062, "training_acc": 88.0, "val_loss": 792.3933982849121, "val_acc": 80.0}
{"epoch": 30, "training_loss": 8955.171173095703, "training_acc": 70.0, "val_loss": 1056.7044258117676, "val_acc": 80.0}
{"epoch": 31, "training_loss": 14877.086059570312, "training_acc": 60.0, "val_loss": 10450.199127197266, "val_acc": 72.0}
{"epoch": 32, "training_loss": 46021.79443359375, "training_acc": 72.0, "val_loss": 10513.243103027344, "val_acc": 72.0}
{"epoch": 33, "training_loss": 22345.889678955078, "training_acc": 71.0, "val_loss": 3080.8937072753906, "val_acc": 60.0}
{"epoch": 34, "training_loss": 13140.384460449219, "training_acc": 67.0, "val_loss": 9352.437591552734, "val_acc": 72.0}
{"epoch": 35, "training_loss": 18935.28044128418, "training_acc": 80.0, "val_loss": 4847.770309448242, "val_acc": 64.0}
{"epoch": 36, "training_loss": 17254.1455078125, "training_acc": 65.0, "val_loss": 8036.608123779297, "val_acc": 72.0}
{"epoch": 37, "training_loss": 19465.035095214844, "training_acc": 76.0, "val_loss": 4846.979904174805, "val_acc": 60.0}
{"epoch": 38, "training_loss": 11477.5283203125, "training_acc": 76.0, "val_loss": 5182.593536376953, "val_acc": 64.0}
{"epoch": 39, "training_loss": 7842.2545166015625, "training_acc": 79.0, "val_loss": 5156.962203979492, "val_acc": 60.0}
{"epoch": 40, "training_loss": 7673.3638916015625, "training_acc": 75.0, "val_loss": 3993.2056427001953, "val_acc": 60.0}
{"epoch": 41, "training_loss": 4741.973541259766, "training_acc": 87.0, "val_loss": 4958.6395263671875, "val_acc": 64.0}
{"epoch": 42, "training_loss": 9240.575805664062, "training_acc": 80.0, "val_loss": 3196.829605102539, "val_acc": 68.0}
{"epoch": 43, "training_loss": 6138.347625732422, "training_acc": 83.0, "val_loss": 3148.050880432129, "val_acc": 68.0}
{"epoch": 44, "training_loss": 4202.331008911133, "training_acc": 81.0, "val_loss": 3019.9974060058594, "val_acc": 72.0}
{"epoch": 45, "training_loss": 3271.227020263672, "training_acc": 87.0, "val_loss": 1535.9899520874023, "val_acc": 68.0}
{"epoch": 46, "training_loss": 2803.92236328125, "training_acc": 80.0, "val_loss": 10704.843139648438, "val_acc": 72.0}
{"epoch": 47, "training_loss": 29167.36309814453, "training_acc": 72.0, "val_loss": 2041.835594177246, "val_acc": 76.0}
{"epoch": 48, "training_loss": 12135.76123046875, "training_acc": 76.0, "val_loss": 2432.5212478637695, "val_acc": 72.0}
