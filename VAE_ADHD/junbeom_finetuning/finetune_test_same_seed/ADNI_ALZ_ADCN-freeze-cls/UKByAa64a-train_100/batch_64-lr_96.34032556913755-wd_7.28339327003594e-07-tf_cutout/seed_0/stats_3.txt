"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 135401.4280090332, "training_acc": 44.0, "val_loss": 76319.48852539062, "val_acc": 72.0}
{"epoch": 1, "training_loss": 244030.09448242188, "training_acc": 72.0, "val_loss": 90717.6025390625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 318943.751953125, "training_acc": 28.0, "val_loss": 14431.996154785156, "val_acc": 68.0}
{"epoch": 3, "training_loss": 74542.13232421875, "training_acc": 69.0, "val_loss": 51695.81298828125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 199143.375, "training_acc": 72.0, "val_loss": 41284.20715332031, "val_acc": 72.0}
{"epoch": 5, "training_loss": 116942.46044921875, "training_acc": 71.0, "val_loss": 27290.972900390625, "val_acc": 64.0}
{"epoch": 6, "training_loss": 107593.6162109375, "training_acc": 52.0, "val_loss": 34569.3359375, "val_acc": 60.0}
{"epoch": 7, "training_loss": 99954.24536132812, "training_acc": 56.0, "val_loss": 24882.208251953125, "val_acc": 76.0}
{"epoch": 8, "training_loss": 107862.2119140625, "training_acc": 73.0, "val_loss": 34424.83825683594, "val_acc": 72.0}
{"epoch": 9, "training_loss": 116532.18017578125, "training_acc": 72.0, "val_loss": 19692.962646484375, "val_acc": 72.0}
{"epoch": 10, "training_loss": 53664.53186035156, "training_acc": 70.0, "val_loss": 33240.73486328125, "val_acc": 48.0}
{"epoch": 11, "training_loss": 102146.8447265625, "training_acc": 50.0, "val_loss": 15656.712341308594, "val_acc": 72.0}
{"epoch": 12, "training_loss": 42260.705078125, "training_acc": 77.0, "val_loss": 21362.991333007812, "val_acc": 72.0}
{"epoch": 13, "training_loss": 72251.10705566406, "training_acc": 72.0, "val_loss": 11255.944061279297, "val_acc": 68.0}
{"epoch": 14, "training_loss": 34322.11877441406, "training_acc": 74.0, "val_loss": 18532.937622070312, "val_acc": 52.0}
{"epoch": 15, "training_loss": 45492.7467956543, "training_acc": 58.0, "val_loss": 9959.571838378906, "val_acc": 72.0}
{"epoch": 16, "training_loss": 39064.21813964844, "training_acc": 73.0, "val_loss": 4043.631362915039, "val_acc": 76.0}
{"epoch": 17, "training_loss": 26003.238891601562, "training_acc": 61.0, "val_loss": 3320.8080291748047, "val_acc": 60.0}
{"epoch": 18, "training_loss": 12125.8720703125, "training_acc": 78.0, "val_loss": 6468.375396728516, "val_acc": 72.0}
{"epoch": 19, "training_loss": 19684.778701782227, "training_acc": 72.0, "val_loss": 11767.767333984375, "val_acc": 40.0}
{"epoch": 20, "training_loss": 23890.720947265625, "training_acc": 59.0, "val_loss": 6279.468536376953, "val_acc": 72.0}
{"epoch": 21, "training_loss": 20912.499572753906, "training_acc": 70.0, "val_loss": 7410.4736328125, "val_acc": 48.0}
{"epoch": 22, "training_loss": 23359.54931640625, "training_acc": 56.0, "val_loss": 3126.082420349121, "val_acc": 84.0}
{"epoch": 23, "training_loss": 13973.174133300781, "training_acc": 71.0, "val_loss": 5485.116958618164, "val_acc": 56.0}
{"epoch": 24, "training_loss": 20091.164794921875, "training_acc": 61.0, "val_loss": 5456.8603515625, "val_acc": 72.0}
{"epoch": 25, "training_loss": 19447.921020507812, "training_acc": 71.0, "val_loss": 4242.820739746094, "val_acc": 56.0}
{"epoch": 26, "training_loss": 11703.049102783203, "training_acc": 74.0, "val_loss": 5225.718688964844, "val_acc": 72.0}
{"epoch": 27, "training_loss": 16700.207489013672, "training_acc": 73.0, "val_loss": 4637.156295776367, "val_acc": 56.0}
{"epoch": 28, "training_loss": 10269.96792602539, "training_acc": 70.0, "val_loss": 2073.076629638672, "val_acc": 84.0}
{"epoch": 29, "training_loss": 6353.724609375, "training_acc": 86.0, "val_loss": 4339.085388183594, "val_acc": 60.0}
{"epoch": 30, "training_loss": 7478.978988647461, "training_acc": 73.0, "val_loss": 2576.2880325317383, "val_acc": 80.0}
{"epoch": 31, "training_loss": 10837.32080078125, "training_acc": 75.0, "val_loss": 3238.383102416992, "val_acc": 60.0}
{"epoch": 32, "training_loss": 8251.741271972656, "training_acc": 75.0, "val_loss": 1349.237060546875, "val_acc": 84.0}
{"epoch": 33, "training_loss": 4039.5321655273438, "training_acc": 82.0, "val_loss": 2678.2690048217773, "val_acc": 68.0}
{"epoch": 34, "training_loss": 7264.250640869141, "training_acc": 74.0, "val_loss": 1968.2191848754883, "val_acc": 60.0}
{"epoch": 35, "training_loss": 4659.315368652344, "training_acc": 81.0, "val_loss": 2686.48624420166, "val_acc": 76.0}
{"epoch": 36, "training_loss": 9811.578063964844, "training_acc": 77.0, "val_loss": 10513.095092773438, "val_acc": 32.0}
{"epoch": 37, "training_loss": 24722.837524414062, "training_acc": 56.0, "val_loss": 5438.055419921875, "val_acc": 72.0}
{"epoch": 38, "training_loss": 17213.082641601562, "training_acc": 77.0, "val_loss": 13308.045959472656, "val_acc": 32.0}
{"epoch": 39, "training_loss": 32108.52276611328, "training_acc": 47.0, "val_loss": 4678.855895996094, "val_acc": 80.0}
{"epoch": 40, "training_loss": 11517.22590637207, "training_acc": 78.0, "val_loss": 6235.602951049805, "val_acc": 56.0}
{"epoch": 41, "training_loss": 12564.818634033203, "training_acc": 68.0, "val_loss": 3602.1495819091797, "val_acc": 76.0}
{"epoch": 42, "training_loss": 8147.311096191406, "training_acc": 84.0, "val_loss": 3621.597671508789, "val_acc": 72.0}
{"epoch": 43, "training_loss": 6950.002517700195, "training_acc": 79.0, "val_loss": 2058.9406967163086, "val_acc": 84.0}
{"epoch": 44, "training_loss": 6782.16325378418, "training_acc": 80.0, "val_loss": 3199.0455627441406, "val_acc": 56.0}
{"epoch": 45, "training_loss": 9346.151672363281, "training_acc": 72.0, "val_loss": 330.8069705963135, "val_acc": 84.0}
{"epoch": 46, "training_loss": 11910.790283203125, "training_acc": 69.0, "val_loss": 4055.084228515625, "val_acc": 72.0}
{"epoch": 47, "training_loss": 19545.01934814453, "training_acc": 72.0, "val_loss": 1888.8113021850586, "val_acc": 64.0}
{"epoch": 48, "training_loss": 17240.740600585938, "training_acc": 68.0, "val_loss": 6688.661193847656, "val_acc": 72.0}
{"epoch": 49, "training_loss": 32752.876342773438, "training_acc": 73.0, "val_loss": 7467.938232421875, "val_acc": 72.0}
{"epoch": 50, "training_loss": 15592.311706542969, "training_acc": 73.0, "val_loss": 14011.891174316406, "val_acc": 48.0}
{"epoch": 51, "training_loss": 40261.433532714844, "training_acc": 62.0, "val_loss": 7027.01416015625, "val_acc": 80.0}
{"epoch": 52, "training_loss": 25665.18182373047, "training_acc": 79.0, "val_loss": 4629.124069213867, "val_acc": 76.0}
{"epoch": 53, "training_loss": 12111.158294677734, "training_acc": 75.0, "val_loss": 9211.927795410156, "val_acc": 48.0}
{"epoch": 54, "training_loss": 26002.640380859375, "training_acc": 59.0, "val_loss": 7362.675476074219, "val_acc": 72.0}
{"epoch": 55, "training_loss": 26256.21784210205, "training_acc": 77.0, "val_loss": 14318.844604492188, "val_acc": 36.0}
{"epoch": 56, "training_loss": 22870.32341003418, "training_acc": 62.0, "val_loss": 4349.599075317383, "val_acc": 76.0}
{"epoch": 57, "training_loss": 21567.536987304688, "training_acc": 75.0, "val_loss": 3992.2550201416016, "val_acc": 56.0}
{"epoch": 58, "training_loss": 12722.531555175781, "training_acc": 69.0, "val_loss": 1191.793155670166, "val_acc": 76.0}
{"epoch": 59, "training_loss": 8673.208801269531, "training_acc": 82.0, "val_loss": 2514.3320083618164, "val_acc": 60.0}
{"epoch": 60, "training_loss": 6174.686676025391, "training_acc": 78.0, "val_loss": 2265.0365829467773, "val_acc": 80.0}
{"epoch": 61, "training_loss": 10418.781188964844, "training_acc": 77.0, "val_loss": 5262.015533447266, "val_acc": 48.0}
{"epoch": 62, "training_loss": 12740.832916259766, "training_acc": 61.0, "val_loss": 986.2544059753418, "val_acc": 76.0}
{"epoch": 63, "training_loss": 3090.802688598633, "training_acc": 91.0, "val_loss": 2877.314567565918, "val_acc": 56.0}
{"epoch": 64, "training_loss": 6847.61474609375, "training_acc": 73.0, "val_loss": 377.80957221984863, "val_acc": 76.0}
