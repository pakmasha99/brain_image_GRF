"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 18844.239233016968, "training_acc": 54.0, "val_loss": 709.130334854126, "val_acc": 72.0}
{"epoch": 1, "training_loss": 21584.74267578125, "training_acc": 46.0, "val_loss": 671.4467525482178, "val_acc": 72.0}
{"epoch": 2, "training_loss": 9313.246154785156, "training_acc": 73.0, "val_loss": 4865.009689331055, "val_acc": 72.0}
{"epoch": 3, "training_loss": 15783.25341796875, "training_acc": 72.0, "val_loss": 1423.379135131836, "val_acc": 68.0}
{"epoch": 4, "training_loss": 9816.98486328125, "training_acc": 50.0, "val_loss": 1971.6552734375, "val_acc": 64.0}
{"epoch": 5, "training_loss": 8298.948669433594, "training_acc": 69.0, "val_loss": 3860.874557495117, "val_acc": 72.0}
{"epoch": 6, "training_loss": 12522.67684173584, "training_acc": 72.0, "val_loss": 2246.8408584594727, "val_acc": 68.0}
{"epoch": 7, "training_loss": 7571.585998535156, "training_acc": 59.0, "val_loss": 2873.7382888793945, "val_acc": 64.0}
{"epoch": 8, "training_loss": 4992.1634521484375, "training_acc": 73.0, "val_loss": 2522.469902038574, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6616.77880859375, "training_acc": 74.0, "val_loss": 2531.3608169555664, "val_acc": 64.0}
{"epoch": 10, "training_loss": 5719.337097167969, "training_acc": 65.0, "val_loss": 1873.4189987182617, "val_acc": 68.0}
{"epoch": 11, "training_loss": 5434.704664230347, "training_acc": 74.0, "val_loss": 1541.8745040893555, "val_acc": 76.0}
{"epoch": 12, "training_loss": 4379.027526855469, "training_acc": 71.0, "val_loss": 1302.4650573730469, "val_acc": 68.0}
{"epoch": 13, "training_loss": 2948.6214599609375, "training_acc": 72.0, "val_loss": 987.6621246337891, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2317.682144165039, "training_acc": 69.0, "val_loss": 179.89803552627563, "val_acc": 80.0}
{"epoch": 15, "training_loss": 1499.1337537765503, "training_acc": 71.0, "val_loss": 1801.0461807250977, "val_acc": 28.0}
{"epoch": 16, "training_loss": 4171.4473876953125, "training_acc": 49.0, "val_loss": 1189.8262977600098, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2754.5546875, "training_acc": 69.0, "val_loss": 331.22973442077637, "val_acc": 64.0}
{"epoch": 18, "training_loss": 2262.2794799804688, "training_acc": 73.0, "val_loss": 340.3715133666992, "val_acc": 60.0}
{"epoch": 19, "training_loss": 1129.218147277832, "training_acc": 69.0, "val_loss": 739.928150177002, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1981.32470703125, "training_acc": 71.0, "val_loss": 151.377534866333, "val_acc": 60.0}
{"epoch": 21, "training_loss": 2159.5209015568616, "training_acc": 68.0, "val_loss": 515.7252311706543, "val_acc": 44.0}
{"epoch": 22, "training_loss": 611.2462768554688, "training_acc": 77.0, "val_loss": 735.6465816497803, "val_acc": 40.0}
{"epoch": 23, "training_loss": 1633.3054275512695, "training_acc": 63.0, "val_loss": 627.7653694152832, "val_acc": 76.0}
{"epoch": 24, "training_loss": 2301.617950439453, "training_acc": 67.0, "val_loss": 754.7449588775635, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4614.840789794922, "training_acc": 72.0, "val_loss": 465.7066822052002, "val_acc": 80.0}
{"epoch": 26, "training_loss": 2693.635814666748, "training_acc": 59.0, "val_loss": 727.1543502807617, "val_acc": 80.0}
{"epoch": 27, "training_loss": 5085.743682861328, "training_acc": 72.0, "val_loss": 645.4437255859375, "val_acc": 60.0}
{"epoch": 28, "training_loss": 4275.431396484375, "training_acc": 58.0, "val_loss": 504.5164108276367, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1197.5685272216797, "training_acc": 79.0, "val_loss": 972.4817276000977, "val_acc": 44.0}
{"epoch": 30, "training_loss": 1891.659324645996, "training_acc": 65.0, "val_loss": 676.2350082397461, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2786.4659423828125, "training_acc": 60.0, "val_loss": 375.7002592086792, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2981.1607666015625, "training_acc": 72.0, "val_loss": 583.6473941802979, "val_acc": 40.0}
{"epoch": 33, "training_loss": 2734.4293670654297, "training_acc": 54.0, "val_loss": 428.91430854797363, "val_acc": 80.0}
{"epoch": 34, "training_loss": 995.4806823730469, "training_acc": 77.0, "val_loss": 1447.3196983337402, "val_acc": 36.0}
{"epoch": 35, "training_loss": 1955.2331848144531, "training_acc": 66.0, "val_loss": 791.7939186096191, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2227.0565185546875, "training_acc": 68.0, "val_loss": 559.4537734985352, "val_acc": 48.0}
{"epoch": 37, "training_loss": 834.8827819824219, "training_acc": 81.0, "val_loss": 271.2284803390503, "val_acc": 84.0}
{"epoch": 38, "training_loss": 827.2074584960938, "training_acc": 81.0, "val_loss": 231.53657913208008, "val_acc": 80.0}
{"epoch": 39, "training_loss": 1148.686882019043, "training_acc": 81.0, "val_loss": 642.557954788208, "val_acc": 52.0}
