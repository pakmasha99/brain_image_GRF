"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 124.07079792022705, "training_acc": 72.0, "val_loss": 31.918352842330933, "val_acc": 72.0}
{"epoch": 1, "training_loss": 90.81765222549438, "training_acc": 72.0, "val_loss": 30.84818124771118, "val_acc": 28.0}
{"epoch": 2, "training_loss": 118.79175138473511, "training_acc": 29.0, "val_loss": 14.74035531282425, "val_acc": 60.0}
{"epoch": 3, "training_loss": 65.63459825515747, "training_acc": 68.0, "val_loss": 21.91130369901657, "val_acc": 72.0}
{"epoch": 4, "training_loss": 85.6301736831665, "training_acc": 72.0, "val_loss": 19.062595069408417, "val_acc": 72.0}
{"epoch": 5, "training_loss": 69.22726094722748, "training_acc": 72.0, "val_loss": 13.89351338148117, "val_acc": 56.0}
{"epoch": 6, "training_loss": 62.60782074928284, "training_acc": 67.0, "val_loss": 16.73988103866577, "val_acc": 60.0}
{"epoch": 7, "training_loss": 69.48720622062683, "training_acc": 65.0, "val_loss": 13.491012156009674, "val_acc": 76.0}
{"epoch": 8, "training_loss": 58.12971496582031, "training_acc": 78.0, "val_loss": 15.828104317188263, "val_acc": 72.0}
{"epoch": 9, "training_loss": 64.61026000976562, "training_acc": 72.0, "val_loss": 13.702496886253357, "val_acc": 76.0}
{"epoch": 10, "training_loss": 54.57962918281555, "training_acc": 76.0, "val_loss": 13.73739093542099, "val_acc": 56.0}
{"epoch": 11, "training_loss": 58.260719776153564, "training_acc": 68.0, "val_loss": 13.262812793254852, "val_acc": 56.0}
{"epoch": 12, "training_loss": 53.40011525154114, "training_acc": 73.0, "val_loss": 13.210748136043549, "val_acc": 76.0}
{"epoch": 13, "training_loss": 53.15145230293274, "training_acc": 73.0, "val_loss": 14.453405141830444, "val_acc": 72.0}
{"epoch": 14, "training_loss": 55.10257017612457, "training_acc": 72.0, "val_loss": 13.024966418743134, "val_acc": 76.0}
{"epoch": 15, "training_loss": 51.89441156387329, "training_acc": 76.0, "val_loss": 13.196004927158356, "val_acc": 64.0}
{"epoch": 16, "training_loss": 54.16171383857727, "training_acc": 76.0, "val_loss": 12.98920065164566, "val_acc": 68.0}
{"epoch": 17, "training_loss": 53.27953624725342, "training_acc": 74.0, "val_loss": 13.770994544029236, "val_acc": 72.0}
{"epoch": 18, "training_loss": 53.16490840911865, "training_acc": 72.0, "val_loss": 13.064903020858765, "val_acc": 72.0}
{"epoch": 19, "training_loss": 50.2744083404541, "training_acc": 75.0, "val_loss": 13.734647631645203, "val_acc": 60.0}
{"epoch": 20, "training_loss": 53.30735433101654, "training_acc": 77.0, "val_loss": 12.754477560520172, "val_acc": 68.0}
{"epoch": 21, "training_loss": 49.87633514404297, "training_acc": 76.0, "val_loss": 14.067822694778442, "val_acc": 76.0}
{"epoch": 22, "training_loss": 56.61345338821411, "training_acc": 72.0, "val_loss": 12.818387150764465, "val_acc": 76.0}
{"epoch": 23, "training_loss": 49.55309581756592, "training_acc": 78.0, "val_loss": 13.283960521221161, "val_acc": 68.0}
{"epoch": 24, "training_loss": 54.171279191970825, "training_acc": 75.0, "val_loss": 12.468671798706055, "val_acc": 72.0}
{"epoch": 25, "training_loss": 50.16028594970703, "training_acc": 73.0, "val_loss": 13.179133832454681, "val_acc": 80.0}
{"epoch": 26, "training_loss": 49.5530948638916, "training_acc": 73.0, "val_loss": 12.66152411699295, "val_acc": 72.0}
{"epoch": 27, "training_loss": 51.74435210227966, "training_acc": 76.0, "val_loss": 12.534071505069733, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.56414031982422, "training_acc": 77.0, "val_loss": 12.61495053768158, "val_acc": 72.0}
{"epoch": 29, "training_loss": 47.499367356300354, "training_acc": 77.0, "val_loss": 12.602043151855469, "val_acc": 72.0}
{"epoch": 30, "training_loss": 48.34256863594055, "training_acc": 79.0, "val_loss": 12.458814680576324, "val_acc": 72.0}
{"epoch": 31, "training_loss": 47.344860911369324, "training_acc": 78.0, "val_loss": 12.503708899021149, "val_acc": 68.0}
{"epoch": 32, "training_loss": 47.96172285079956, "training_acc": 78.0, "val_loss": 12.66990602016449, "val_acc": 72.0}
{"epoch": 33, "training_loss": 46.12045109272003, "training_acc": 81.0, "val_loss": 12.69703209400177, "val_acc": 72.0}
{"epoch": 34, "training_loss": 47.270318388938904, "training_acc": 78.0, "val_loss": 12.560462951660156, "val_acc": 72.0}
{"epoch": 35, "training_loss": 46.33980655670166, "training_acc": 80.0, "val_loss": 12.757979333400726, "val_acc": 68.0}
{"epoch": 36, "training_loss": 48.84091019630432, "training_acc": 80.0, "val_loss": 12.907755374908447, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.39377212524414, "training_acc": 76.0, "val_loss": 12.812623381614685, "val_acc": 68.0}
{"epoch": 38, "training_loss": 45.41200792789459, "training_acc": 78.0, "val_loss": 13.053035736083984, "val_acc": 72.0}
{"epoch": 39, "training_loss": 47.887155175209045, "training_acc": 78.0, "val_loss": 13.0017951130867, "val_acc": 68.0}
{"epoch": 40, "training_loss": 46.23492443561554, "training_acc": 77.0, "val_loss": 13.056713342666626, "val_acc": 68.0}
{"epoch": 41, "training_loss": 46.43726325035095, "training_acc": 77.0, "val_loss": 13.138294219970703, "val_acc": 68.0}
{"epoch": 42, "training_loss": 46.88685154914856, "training_acc": 78.0, "val_loss": 13.095474243164062, "val_acc": 72.0}
{"epoch": 43, "training_loss": 45.258217334747314, "training_acc": 80.0, "val_loss": 13.052394986152649, "val_acc": 68.0}
{"epoch": 44, "training_loss": 45.26905298233032, "training_acc": 79.0, "val_loss": 13.059084117412567, "val_acc": 72.0}
{"epoch": 45, "training_loss": 44.1383558511734, "training_acc": 79.0, "val_loss": 13.269096612930298, "val_acc": 72.0}
{"epoch": 46, "training_loss": 44.36393368244171, "training_acc": 82.0, "val_loss": 13.02628368139267, "val_acc": 68.0}
{"epoch": 47, "training_loss": 45.316839814186096, "training_acc": 78.0, "val_loss": 13.113398849964142, "val_acc": 68.0}
{"epoch": 48, "training_loss": 44.036847829818726, "training_acc": 81.0, "val_loss": 13.3088618516922, "val_acc": 72.0}
{"epoch": 49, "training_loss": 45.176060914993286, "training_acc": 79.0, "val_loss": 13.01441490650177, "val_acc": 68.0}
