"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 350.87924575805664, "training_acc": 40.0, "val_loss": 143.6081051826477, "val_acc": 72.0}
{"epoch": 1, "training_loss": 469.1503572463989, "training_acc": 72.0, "val_loss": 45.08159160614014, "val_acc": 40.0}
{"epoch": 2, "training_loss": 241.37483024597168, "training_acc": 32.0, "val_loss": 31.7941814661026, "val_acc": 72.0}
{"epoch": 3, "training_loss": 121.33502388000488, "training_acc": 74.0, "val_loss": 66.03695750236511, "val_acc": 72.0}
{"epoch": 4, "training_loss": 183.2592363357544, "training_acc": 72.0, "val_loss": 28.20289134979248, "val_acc": 68.0}
{"epoch": 5, "training_loss": 122.85730075836182, "training_acc": 62.0, "val_loss": 29.71707582473755, "val_acc": 64.0}
{"epoch": 6, "training_loss": 118.75425052642822, "training_acc": 64.0, "val_loss": 44.24818456172943, "val_acc": 72.0}
{"epoch": 7, "training_loss": 147.1662187576294, "training_acc": 75.0, "val_loss": 51.906418800354004, "val_acc": 72.0}
{"epoch": 8, "training_loss": 125.95735120773315, "training_acc": 73.0, "val_loss": 24.614043533802032, "val_acc": 60.0}
{"epoch": 9, "training_loss": 152.8039789199829, "training_acc": 55.0, "val_loss": 20.774324238300323, "val_acc": 68.0}
{"epoch": 10, "training_loss": 80.65679132938385, "training_acc": 67.0, "val_loss": 46.94623947143555, "val_acc": 72.0}
{"epoch": 11, "training_loss": 168.8660969734192, "training_acc": 72.0, "val_loss": 33.33772122859955, "val_acc": 72.0}
{"epoch": 12, "training_loss": 76.71105742454529, "training_acc": 76.0, "val_loss": 42.14574992656708, "val_acc": 28.0}
{"epoch": 13, "training_loss": 168.4828782081604, "training_acc": 32.0, "val_loss": 19.48133558034897, "val_acc": 72.0}
{"epoch": 14, "training_loss": 91.96725988388062, "training_acc": 73.0, "val_loss": 42.05161929130554, "val_acc": 72.0}
{"epoch": 15, "training_loss": 138.29656958580017, "training_acc": 72.0, "val_loss": 14.981856942176819, "val_acc": 72.0}
{"epoch": 16, "training_loss": 69.24879384040833, "training_acc": 71.0, "val_loss": 21.717770397663116, "val_acc": 56.0}
{"epoch": 17, "training_loss": 73.38063299655914, "training_acc": 64.0, "val_loss": 29.591849446296692, "val_acc": 72.0}
{"epoch": 18, "training_loss": 98.32909369468689, "training_acc": 72.0, "val_loss": 25.36773383617401, "val_acc": 72.0}
{"epoch": 19, "training_loss": 69.09171605110168, "training_acc": 73.0, "val_loss": 20.593295991420746, "val_acc": 60.0}
{"epoch": 20, "training_loss": 83.39652156829834, "training_acc": 64.0, "val_loss": 16.44933670759201, "val_acc": 76.0}
{"epoch": 21, "training_loss": 62.077144622802734, "training_acc": 74.0, "val_loss": 21.910934150218964, "val_acc": 72.0}
{"epoch": 22, "training_loss": 63.62175786495209, "training_acc": 73.0, "val_loss": 17.3659086227417, "val_acc": 44.0}
{"epoch": 23, "training_loss": 64.85148167610168, "training_acc": 67.0, "val_loss": 13.173997402191162, "val_acc": 76.0}
{"epoch": 24, "training_loss": 70.286940574646, "training_acc": 74.0, "val_loss": 12.603068351745605, "val_acc": 76.0}
{"epoch": 25, "training_loss": 57.863903522491455, "training_acc": 69.0, "val_loss": 14.551100134849548, "val_acc": 48.0}
{"epoch": 26, "training_loss": 50.28269624710083, "training_acc": 74.0, "val_loss": 20.053844153881073, "val_acc": 72.0}
{"epoch": 27, "training_loss": 65.44146347045898, "training_acc": 74.0, "val_loss": 12.481635808944702, "val_acc": 80.0}
{"epoch": 28, "training_loss": 49.13165354728699, "training_acc": 78.0, "val_loss": 12.745499610900879, "val_acc": 72.0}
{"epoch": 29, "training_loss": 41.11319017410278, "training_acc": 81.0, "val_loss": 16.878941655158997, "val_acc": 76.0}
{"epoch": 30, "training_loss": 48.70898079872131, "training_acc": 79.0, "val_loss": 12.936751544475555, "val_acc": 76.0}
{"epoch": 31, "training_loss": 47.00671100616455, "training_acc": 77.0, "val_loss": 12.79393583536148, "val_acc": 76.0}
{"epoch": 32, "training_loss": 48.702903747558594, "training_acc": 77.0, "val_loss": 12.897582352161407, "val_acc": 76.0}
{"epoch": 33, "training_loss": 38.327356457710266, "training_acc": 78.0, "val_loss": 13.697470724582672, "val_acc": 60.0}
{"epoch": 34, "training_loss": 46.52477514743805, "training_acc": 79.0, "val_loss": 15.198670327663422, "val_acc": 76.0}
{"epoch": 35, "training_loss": 53.44404315948486, "training_acc": 75.0, "val_loss": 12.744034826755524, "val_acc": 60.0}
{"epoch": 36, "training_loss": 55.03865146636963, "training_acc": 72.0, "val_loss": 13.43175619840622, "val_acc": 80.0}
{"epoch": 37, "training_loss": 57.1610848903656, "training_acc": 77.0, "val_loss": 14.97037559747696, "val_acc": 80.0}
{"epoch": 38, "training_loss": 37.31764042377472, "training_acc": 83.0, "val_loss": 17.63547509908676, "val_acc": 44.0}
{"epoch": 39, "training_loss": 56.007569789886475, "training_acc": 70.0, "val_loss": 21.609899401664734, "val_acc": 72.0}
{"epoch": 40, "training_loss": 69.09618401527405, "training_acc": 74.0, "val_loss": 13.997769355773926, "val_acc": 76.0}
{"epoch": 41, "training_loss": 56.3589653968811, "training_acc": 74.0, "val_loss": 12.959946691989899, "val_acc": 72.0}
{"epoch": 42, "training_loss": 40.08126926422119, "training_acc": 84.0, "val_loss": 21.745780110359192, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.78818595409393, "training_acc": 76.0, "val_loss": 12.524895370006561, "val_acc": 72.0}
{"epoch": 44, "training_loss": 44.924519062042236, "training_acc": 78.0, "val_loss": 11.436092108488083, "val_acc": 88.0}
{"epoch": 45, "training_loss": 41.25832796096802, "training_acc": 79.0, "val_loss": 13.57802152633667, "val_acc": 80.0}
{"epoch": 46, "training_loss": 37.43827450275421, "training_acc": 79.0, "val_loss": 13.168272376060486, "val_acc": 56.0}
{"epoch": 47, "training_loss": 42.10907804965973, "training_acc": 80.0, "val_loss": 16.300863027572632, "val_acc": 72.0}
{"epoch": 48, "training_loss": 52.36855125427246, "training_acc": 74.0, "val_loss": 10.963468253612518, "val_acc": 88.0}
{"epoch": 49, "training_loss": 44.61751866340637, "training_acc": 77.0, "val_loss": 11.172149330377579, "val_acc": 88.0}
{"epoch": 50, "training_loss": 40.91533946990967, "training_acc": 83.0, "val_loss": 13.774816691875458, "val_acc": 80.0}
{"epoch": 51, "training_loss": 38.89499843120575, "training_acc": 82.0, "val_loss": 13.22842687368393, "val_acc": 68.0}
{"epoch": 52, "training_loss": 42.1142156124115, "training_acc": 79.0, "val_loss": 19.9873685836792, "val_acc": 76.0}
{"epoch": 53, "training_loss": 47.13460969924927, "training_acc": 80.0, "val_loss": 14.044143259525299, "val_acc": 80.0}
{"epoch": 54, "training_loss": 38.32050943374634, "training_acc": 83.0, "val_loss": 14.771482348442078, "val_acc": 76.0}
{"epoch": 55, "training_loss": 35.41414511203766, "training_acc": 83.0, "val_loss": 13.493198156356812, "val_acc": 84.0}
{"epoch": 56, "training_loss": 34.507259488105774, "training_acc": 87.0, "val_loss": 12.4239481985569, "val_acc": 80.0}
{"epoch": 57, "training_loss": 33.660444378852844, "training_acc": 89.0, "val_loss": 15.459118783473969, "val_acc": 76.0}
{"epoch": 58, "training_loss": 38.22324573993683, "training_acc": 83.0, "val_loss": 12.631498277187347, "val_acc": 72.0}
{"epoch": 59, "training_loss": 37.15235352516174, "training_acc": 88.0, "val_loss": 18.168750405311584, "val_acc": 72.0}
{"epoch": 60, "training_loss": 45.2634756565094, "training_acc": 75.0, "val_loss": 12.26852610707283, "val_acc": 76.0}
{"epoch": 61, "training_loss": 35.57270348072052, "training_acc": 88.0, "val_loss": 12.927255034446716, "val_acc": 80.0}
{"epoch": 62, "training_loss": 43.08114147186279, "training_acc": 82.0, "val_loss": 13.323448598384857, "val_acc": 80.0}
{"epoch": 63, "training_loss": 29.12894105911255, "training_acc": 91.0, "val_loss": 13.346211612224579, "val_acc": 76.0}
{"epoch": 64, "training_loss": 41.0857230424881, "training_acc": 81.0, "val_loss": 20.906776189804077, "val_acc": 76.0}
{"epoch": 65, "training_loss": 42.035030007362366, "training_acc": 81.0, "val_loss": 13.263995945453644, "val_acc": 76.0}
{"epoch": 66, "training_loss": 40.62945032119751, "training_acc": 81.0, "val_loss": 16.491027176380157, "val_acc": 76.0}
{"epoch": 67, "training_loss": 41.662474393844604, "training_acc": 80.0, "val_loss": 13.33988904953003, "val_acc": 84.0}
