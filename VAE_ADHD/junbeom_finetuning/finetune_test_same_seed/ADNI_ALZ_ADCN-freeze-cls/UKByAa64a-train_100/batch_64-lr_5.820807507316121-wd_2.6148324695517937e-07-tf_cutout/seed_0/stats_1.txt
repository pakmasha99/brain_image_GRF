"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10664.511047363281, "training_acc": 49.0, "val_loss": 4801.845550537109, "val_acc": 72.0}
{"epoch": 1, "training_loss": 14285.491439819336, "training_acc": 72.0, "val_loss": 4537.947463989258, "val_acc": 28.0}
{"epoch": 2, "training_loss": 16408.57208251953, "training_acc": 28.0, "val_loss": 452.736759185791, "val_acc": 80.0}
{"epoch": 3, "training_loss": 4658.938934326172, "training_acc": 72.0, "val_loss": 2762.554931640625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10121.885955810547, "training_acc": 72.0, "val_loss": 1753.6779403686523, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5128.346145629883, "training_acc": 75.0, "val_loss": 1630.38330078125, "val_acc": 60.0}
{"epoch": 6, "training_loss": 7507.806823730469, "training_acc": 48.0, "val_loss": 1501.8855094909668, "val_acc": 60.0}
{"epoch": 7, "training_loss": 4604.128517150879, "training_acc": 61.0, "val_loss": 1093.4255599975586, "val_acc": 76.0}
{"epoch": 8, "training_loss": 4695.9033203125, "training_acc": 73.0, "val_loss": 1283.8711738586426, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3802.251907348633, "training_acc": 70.0, "val_loss": 618.15185546875, "val_acc": 56.0}
{"epoch": 10, "training_loss": 2592.31876373291, "training_acc": 62.0, "val_loss": 714.3333435058594, "val_acc": 56.0}
{"epoch": 11, "training_loss": 2785.6250381469727, "training_acc": 64.0, "val_loss": 781.7047119140625, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2768.8975219726562, "training_acc": 72.0, "val_loss": 308.1865072250366, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1696.0925064086914, "training_acc": 65.0, "val_loss": 327.38051414489746, "val_acc": 56.0}
{"epoch": 14, "training_loss": 1282.7886123657227, "training_acc": 68.0, "val_loss": 1045.4442977905273, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3017.8811988830566, "training_acc": 72.0, "val_loss": 641.9273376464844, "val_acc": 32.0}
{"epoch": 16, "training_loss": 1264.787281036377, "training_acc": 53.0, "val_loss": 666.5482044219971, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1638.7355842590332, "training_acc": 72.0, "val_loss": 333.9122533798218, "val_acc": 36.0}
{"epoch": 18, "training_loss": 471.62619972229004, "training_acc": 68.0, "val_loss": 193.1612253189087, "val_acc": 60.0}
{"epoch": 19, "training_loss": 415.16997146606445, "training_acc": 80.0, "val_loss": 197.27208614349365, "val_acc": 60.0}
{"epoch": 20, "training_loss": 393.19153118133545, "training_acc": 79.0, "val_loss": 206.04641437530518, "val_acc": 60.0}
{"epoch": 21, "training_loss": 381.6045742034912, "training_acc": 80.0, "val_loss": 184.67657566070557, "val_acc": 68.0}
{"epoch": 22, "training_loss": 717.2436943054199, "training_acc": 71.0, "val_loss": 529.1104793548584, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1479.1588287353516, "training_acc": 72.0, "val_loss": 205.34653663635254, "val_acc": 48.0}
{"epoch": 24, "training_loss": 918.5632247924805, "training_acc": 65.0, "val_loss": 697.3531723022461, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2122.99259185791, "training_acc": 72.0, "val_loss": 603.6080360412598, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1681.0675773620605, "training_acc": 61.0, "val_loss": 131.4793348312378, "val_acc": 72.0}
{"epoch": 27, "training_loss": 326.6042356491089, "training_acc": 81.0, "val_loss": 148.1162667274475, "val_acc": 68.0}
{"epoch": 28, "training_loss": 295.02955293655396, "training_acc": 81.0, "val_loss": 201.55205726623535, "val_acc": 80.0}
{"epoch": 29, "training_loss": 410.0552749633789, "training_acc": 83.0, "val_loss": 258.0951690673828, "val_acc": 56.0}
{"epoch": 30, "training_loss": 910.5034427642822, "training_acc": 66.0, "val_loss": 222.39646911621094, "val_acc": 76.0}
{"epoch": 31, "training_loss": 614.1303596496582, "training_acc": 73.0, "val_loss": 242.09141731262207, "val_acc": 76.0}
{"epoch": 32, "training_loss": 476.63046646118164, "training_acc": 77.0, "val_loss": 453.43780517578125, "val_acc": 40.0}
{"epoch": 33, "training_loss": 1169.6931343078613, "training_acc": 54.0, "val_loss": 520.9176063537598, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1118.1271004676819, "training_acc": 77.0, "val_loss": 584.7681522369385, "val_acc": 40.0}
{"epoch": 35, "training_loss": 1839.3241386413574, "training_acc": 52.0, "val_loss": 651.0696887969971, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1656.6320209503174, "training_acc": 77.0, "val_loss": 251.78885459899902, "val_acc": 64.0}
{"epoch": 37, "training_loss": 557.6746044158936, "training_acc": 72.0, "val_loss": 187.3822569847107, "val_acc": 68.0}
{"epoch": 38, "training_loss": 283.07547760009766, "training_acc": 83.0, "val_loss": 172.66106605529785, "val_acc": 68.0}
{"epoch": 39, "training_loss": 246.29656267166138, "training_acc": 79.0, "val_loss": 301.9001007080078, "val_acc": 76.0}
{"epoch": 40, "training_loss": 569.0170593261719, "training_acc": 72.0, "val_loss": 191.18895530700684, "val_acc": 76.0}
{"epoch": 41, "training_loss": 227.22576332092285, "training_acc": 78.0, "val_loss": 186.84371709823608, "val_acc": 68.0}
{"epoch": 42, "training_loss": 136.7304811477661, "training_acc": 84.0, "val_loss": 162.068772315979, "val_acc": 68.0}
{"epoch": 43, "training_loss": 109.74092984199524, "training_acc": 87.0, "val_loss": 170.18941640853882, "val_acc": 60.0}
{"epoch": 44, "training_loss": 268.379732131958, "training_acc": 81.0, "val_loss": 212.5514030456543, "val_acc": 60.0}
{"epoch": 45, "training_loss": 239.16907453536987, "training_acc": 82.0, "val_loss": 196.22706174850464, "val_acc": 72.0}
