"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6092.10294342041, "training_acc": 44.0, "val_loss": 3677.4181365966797, "val_acc": 72.0}
{"epoch": 1, "training_loss": 11261.456817626953, "training_acc": 72.0, "val_loss": 2933.683204650879, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9862.115661621094, "training_acc": 29.0, "val_loss": 700.0689506530762, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2975.8605346679688, "training_acc": 74.0, "val_loss": 1778.9667129516602, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6271.827407836914, "training_acc": 72.0, "val_loss": 1082.082462310791, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2975.320602416992, "training_acc": 68.0, "val_loss": 1541.4756774902344, "val_acc": 64.0}
{"epoch": 6, "training_loss": 4469.184585571289, "training_acc": 55.0, "val_loss": 1138.1567001342773, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2541.6853408813477, "training_acc": 77.0, "val_loss": 1196.8684196472168, "val_acc": 68.0}
{"epoch": 8, "training_loss": 4287.889251708984, "training_acc": 73.0, "val_loss": 891.7227745056152, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2345.573532104492, "training_acc": 72.0, "val_loss": 970.8596229553223, "val_acc": 64.0}
{"epoch": 10, "training_loss": 2659.75244140625, "training_acc": 60.0, "val_loss": 439.4895076751709, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2016.2252197265625, "training_acc": 74.0, "val_loss": 752.0799160003662, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2339.4599609375, "training_acc": 72.0, "val_loss": 992.1313285827637, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2754.99019241333, "training_acc": 41.0, "val_loss": 486.41133308410645, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2482.668197631836, "training_acc": 72.0, "val_loss": 669.9650764465332, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1908.540283203125, "training_acc": 72.0, "val_loss": 1274.870777130127, "val_acc": 28.0}
{"epoch": 16, "training_loss": 4000.322479248047, "training_acc": 32.0, "val_loss": 305.79588413238525, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1546.9315643310547, "training_acc": 72.0, "val_loss": 788.7974739074707, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2778.08927154541, "training_acc": 72.0, "val_loss": 403.80029678344727, "val_acc": 68.0}
{"epoch": 19, "training_loss": 1506.5869674682617, "training_acc": 63.0, "val_loss": 757.1613788604736, "val_acc": 56.0}
{"epoch": 20, "training_loss": 1499.5786094665527, "training_acc": 63.0, "val_loss": 699.1878509521484, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2776.0256729125977, "training_acc": 72.0, "val_loss": 663.3569717407227, "val_acc": 76.0}
{"epoch": 22, "training_loss": 2194.9934005737305, "training_acc": 76.0, "val_loss": 667.41623878479, "val_acc": 64.0}
{"epoch": 23, "training_loss": 1501.1797142028809, "training_acc": 64.0, "val_loss": 524.2191791534424, "val_acc": 68.0}
{"epoch": 24, "training_loss": 1362.2897491455078, "training_acc": 70.0, "val_loss": 414.98284339904785, "val_acc": 80.0}
{"epoch": 25, "training_loss": 1320.7183952331543, "training_acc": 76.0, "val_loss": 338.71634006500244, "val_acc": 60.0}
{"epoch": 26, "training_loss": 1017.6234931945801, "training_acc": 59.0, "val_loss": 184.30426120758057, "val_acc": 80.0}
{"epoch": 27, "training_loss": 1031.1420783996582, "training_acc": 74.0, "val_loss": 81.52792453765869, "val_acc": 84.0}
{"epoch": 28, "training_loss": 1054.6284713745117, "training_acc": 65.0, "val_loss": 313.5120153427124, "val_acc": 52.0}
{"epoch": 29, "training_loss": 1397.9603729248047, "training_acc": 62.0, "val_loss": 507.8131675720215, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1739.6695442199707, "training_acc": 73.0, "val_loss": 461.06786727905273, "val_acc": 44.0}
{"epoch": 31, "training_loss": 1411.9287872314453, "training_acc": 53.0, "val_loss": 260.5037450790405, "val_acc": 80.0}
{"epoch": 32, "training_loss": 1291.5096817016602, "training_acc": 74.0, "val_loss": 335.72070598602295, "val_acc": 80.0}
{"epoch": 33, "training_loss": 1063.825189590454, "training_acc": 77.0, "val_loss": 489.9137020111084, "val_acc": 52.0}
{"epoch": 34, "training_loss": 1316.0247211456299, "training_acc": 62.0, "val_loss": 244.1676139831543, "val_acc": 80.0}
{"epoch": 35, "training_loss": 870.6442356109619, "training_acc": 78.0, "val_loss": 172.3857045173645, "val_acc": 72.0}
{"epoch": 36, "training_loss": 371.07897567749023, "training_acc": 78.0, "val_loss": 138.36599588394165, "val_acc": 64.0}
{"epoch": 37, "training_loss": 249.41111183166504, "training_acc": 77.0, "val_loss": 47.67034947872162, "val_acc": 76.0}
{"epoch": 38, "training_loss": 351.58818435668945, "training_acc": 76.0, "val_loss": 70.70684432983398, "val_acc": 76.0}
{"epoch": 39, "training_loss": 533.7166786193848, "training_acc": 72.0, "val_loss": 236.1807107925415, "val_acc": 40.0}
{"epoch": 40, "training_loss": 458.3782329559326, "training_acc": 72.0, "val_loss": 69.42717432975769, "val_acc": 76.0}
{"epoch": 41, "training_loss": 587.4327487945557, "training_acc": 73.0, "val_loss": 83.24977159500122, "val_acc": 64.0}
{"epoch": 42, "training_loss": 256.3826026916504, "training_acc": 79.0, "val_loss": 76.48163437843323, "val_acc": 76.0}
{"epoch": 43, "training_loss": 344.4885711669922, "training_acc": 80.0, "val_loss": 81.02014660835266, "val_acc": 84.0}
{"epoch": 44, "training_loss": 282.4902558326721, "training_acc": 83.0, "val_loss": 110.93608140945435, "val_acc": 64.0}
{"epoch": 45, "training_loss": 347.0814437866211, "training_acc": 73.0, "val_loss": 202.40941047668457, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1007.06396484375, "training_acc": 73.0, "val_loss": 31.309446692466736, "val_acc": 80.0}
{"epoch": 47, "training_loss": 554.5097389221191, "training_acc": 68.0, "val_loss": 86.62049770355225, "val_acc": 84.0}
{"epoch": 48, "training_loss": 521.8024978637695, "training_acc": 76.0, "val_loss": 35.63336133956909, "val_acc": 76.0}
{"epoch": 49, "training_loss": 198.10853958129883, "training_acc": 79.0, "val_loss": 43.48504841327667, "val_acc": 76.0}
{"epoch": 50, "training_loss": 210.09485054016113, "training_acc": 84.0, "val_loss": 55.775851011276245, "val_acc": 72.0}
{"epoch": 51, "training_loss": 193.00036430358887, "training_acc": 84.0, "val_loss": 67.38540530204773, "val_acc": 84.0}
{"epoch": 52, "training_loss": 298.1483488082886, "training_acc": 79.0, "val_loss": 397.04787731170654, "val_acc": 32.0}
{"epoch": 53, "training_loss": 671.3836660385132, "training_acc": 62.0, "val_loss": 69.90916132926941, "val_acc": 84.0}
{"epoch": 54, "training_loss": 245.51991748809814, "training_acc": 86.0, "val_loss": 464.27106857299805, "val_acc": 32.0}
{"epoch": 55, "training_loss": 1187.2920417785645, "training_acc": 54.0, "val_loss": 269.89848613739014, "val_acc": 72.0}
{"epoch": 56, "training_loss": 784.1127595901489, "training_acc": 77.0, "val_loss": 736.6376876831055, "val_acc": 32.0}
{"epoch": 57, "training_loss": 1414.1388425827026, "training_acc": 54.0, "val_loss": 306.2689781188965, "val_acc": 72.0}
{"epoch": 58, "training_loss": 1422.0015296936035, "training_acc": 73.0, "val_loss": 184.52990055084229, "val_acc": 80.0}
{"epoch": 59, "training_loss": 741.3170585632324, "training_acc": 79.0, "val_loss": 253.00536155700684, "val_acc": 68.0}
{"epoch": 60, "training_loss": 941.82177734375, "training_acc": 71.0, "val_loss": 196.22896909713745, "val_acc": 80.0}
{"epoch": 61, "training_loss": 587.3443870544434, "training_acc": 77.0, "val_loss": 149.2572546005249, "val_acc": 68.0}
{"epoch": 62, "training_loss": 275.95910835266113, "training_acc": 82.0, "val_loss": 67.54605770111084, "val_acc": 84.0}
{"epoch": 63, "training_loss": 306.31637382507324, "training_acc": 78.0, "val_loss": 21.891967952251434, "val_acc": 88.0}
{"epoch": 64, "training_loss": 142.0165309906006, "training_acc": 87.0, "val_loss": 159.91424322128296, "val_acc": 60.0}
{"epoch": 65, "training_loss": 194.95346212387085, "training_acc": 80.0, "val_loss": 17.94787496328354, "val_acc": 92.0}
{"epoch": 66, "training_loss": 148.46788120269775, "training_acc": 87.0, "val_loss": 424.89013671875, "val_acc": 32.0}
{"epoch": 67, "training_loss": 576.893000125885, "training_acc": 68.0, "val_loss": 89.3339991569519, "val_acc": 84.0}
{"epoch": 68, "training_loss": 352.38763093948364, "training_acc": 78.0, "val_loss": 147.62085676193237, "val_acc": 60.0}
{"epoch": 69, "training_loss": 349.0409517288208, "training_acc": 77.0, "val_loss": 124.21321868896484, "val_acc": 84.0}
{"epoch": 70, "training_loss": 319.53242444992065, "training_acc": 82.0, "val_loss": 155.98281621932983, "val_acc": 56.0}
{"epoch": 71, "training_loss": 263.6799650192261, "training_acc": 77.0, "val_loss": 66.41843318939209, "val_acc": 80.0}
{"epoch": 72, "training_loss": 102.3424642086029, "training_acc": 87.0, "val_loss": 93.25986504554749, "val_acc": 60.0}
{"epoch": 73, "training_loss": 121.65517854690552, "training_acc": 85.0, "val_loss": 24.479940533638, "val_acc": 80.0}
{"epoch": 74, "training_loss": 171.2646074295044, "training_acc": 84.0, "val_loss": 35.591837763786316, "val_acc": 80.0}
{"epoch": 75, "training_loss": 94.92798662185669, "training_acc": 91.0, "val_loss": 165.6250238418579, "val_acc": 44.0}
{"epoch": 76, "training_loss": 255.6574079990387, "training_acc": 78.0, "val_loss": 22.671206295490265, "val_acc": 84.0}
{"epoch": 77, "training_loss": 169.43616008758545, "training_acc": 81.0, "val_loss": 92.6090657711029, "val_acc": 84.0}
{"epoch": 78, "training_loss": 331.65096974372864, "training_acc": 78.0, "val_loss": 148.17453622817993, "val_acc": 56.0}
{"epoch": 79, "training_loss": 325.2066373825073, "training_acc": 76.0, "val_loss": 81.07532858848572, "val_acc": 80.0}
{"epoch": 80, "training_loss": 153.60751104354858, "training_acc": 86.0, "val_loss": 100.54347515106201, "val_acc": 76.0}
{"epoch": 81, "training_loss": 271.82494831085205, "training_acc": 77.0, "val_loss": 67.0633852481842, "val_acc": 80.0}
{"epoch": 82, "training_loss": 137.51867961883545, "training_acc": 85.0, "val_loss": 46.41844928264618, "val_acc": 84.0}
{"epoch": 83, "training_loss": 218.70430183410645, "training_acc": 87.0, "val_loss": 51.846498250961304, "val_acc": 80.0}
{"epoch": 84, "training_loss": 76.45013678073883, "training_acc": 89.0, "val_loss": 26.689264178276062, "val_acc": 80.0}
