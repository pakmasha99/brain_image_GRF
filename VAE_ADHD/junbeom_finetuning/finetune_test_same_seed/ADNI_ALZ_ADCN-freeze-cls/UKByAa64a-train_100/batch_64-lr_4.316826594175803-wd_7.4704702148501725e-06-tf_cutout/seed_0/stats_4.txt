"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5978.464611053467, "training_acc": 46.0, "val_loss": 3637.9451751708984, "val_acc": 72.0}
{"epoch": 1, "training_loss": 12664.529556274414, "training_acc": 72.0, "val_loss": 1826.3486862182617, "val_acc": 36.0}
{"epoch": 2, "training_loss": 8171.164520263672, "training_acc": 33.0, "val_loss": 1056.0151100158691, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3731.4488220214844, "training_acc": 72.0, "val_loss": 1825.179672241211, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5041.760223388672, "training_acc": 72.0, "val_loss": 835.1186752319336, "val_acc": 76.0}
{"epoch": 5, "training_loss": 2655.322525024414, "training_acc": 70.0, "val_loss": 816.05224609375, "val_acc": 60.0}
{"epoch": 6, "training_loss": 3570.3850021362305, "training_acc": 53.0, "val_loss": 843.4592247009277, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3032.341751098633, "training_acc": 69.0, "val_loss": 1124.0126609802246, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2586.7038230895996, "training_acc": 75.0, "val_loss": 476.81074142456055, "val_acc": 64.0}
{"epoch": 9, "training_loss": 1922.99361038208, "training_acc": 64.0, "val_loss": 325.6718635559082, "val_acc": 60.0}
{"epoch": 10, "training_loss": 1190.7521228790283, "training_acc": 68.0, "val_loss": 315.3534412384033, "val_acc": 72.0}
{"epoch": 11, "training_loss": 626.9617538452148, "training_acc": 76.0, "val_loss": 306.8690061569214, "val_acc": 40.0}
{"epoch": 12, "training_loss": 1881.7852630615234, "training_acc": 48.0, "val_loss": 579.9970626831055, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2448.5030517578125, "training_acc": 72.0, "val_loss": 1123.451042175293, "val_acc": 28.0}
{"epoch": 14, "training_loss": 2521.1894569396973, "training_acc": 34.0, "val_loss": 537.5621318817139, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2929.425491333008, "training_acc": 72.0, "val_loss": 584.8031044006348, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1770.0250911712646, "training_acc": 74.0, "val_loss": 693.8878536224365, "val_acc": 36.0}
{"epoch": 17, "training_loss": 2254.834711074829, "training_acc": 44.0, "val_loss": 530.2204608917236, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1762.612205505371, "training_acc": 75.0, "val_loss": 528.034782409668, "val_acc": 72.0}
{"epoch": 19, "training_loss": 940.2237854003906, "training_acc": 79.0, "val_loss": 532.3173522949219, "val_acc": 56.0}
{"epoch": 20, "training_loss": 2900.707633972168, "training_acc": 56.0, "val_loss": 384.73217487335205, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1079.1589622497559, "training_acc": 78.0, "val_loss": 750.6683349609375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1832.154541015625, "training_acc": 75.0, "val_loss": 292.37804412841797, "val_acc": 76.0}
{"epoch": 23, "training_loss": 1271.7405242919922, "training_acc": 66.0, "val_loss": 158.66674184799194, "val_acc": 68.0}
{"epoch": 24, "training_loss": 1031.137435913086, "training_acc": 70.0, "val_loss": 469.6004390716553, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1189.8049745559692, "training_acc": 75.0, "val_loss": 598.6025333404541, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1441.0104351043701, "training_acc": 49.0, "val_loss": 570.8526611328125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2617.550094604492, "training_acc": 72.0, "val_loss": 545.1660633087158, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1341.3036851882935, "training_acc": 71.0, "val_loss": 205.4337501525879, "val_acc": 52.0}
{"epoch": 29, "training_loss": 808.2647399902344, "training_acc": 64.0, "val_loss": 239.92674350738525, "val_acc": 76.0}
{"epoch": 30, "training_loss": 553.0738158226013, "training_acc": 76.0, "val_loss": 111.3965630531311, "val_acc": 76.0}
{"epoch": 31, "training_loss": 325.5839538574219, "training_acc": 75.0, "val_loss": 412.72854804992676, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1184.2417755126953, "training_acc": 75.0, "val_loss": 145.93859910964966, "val_acc": 76.0}
{"epoch": 33, "training_loss": 1068.3400497436523, "training_acc": 62.0, "val_loss": 105.49715757369995, "val_acc": 80.0}
{"epoch": 34, "training_loss": 337.1563129425049, "training_acc": 78.0, "val_loss": 157.90820121765137, "val_acc": 76.0}
{"epoch": 35, "training_loss": 561.477710723877, "training_acc": 74.0, "val_loss": 63.373398780822754, "val_acc": 84.0}
{"epoch": 36, "training_loss": 592.2291526794434, "training_acc": 74.0, "val_loss": 55.92740774154663, "val_acc": 76.0}
{"epoch": 37, "training_loss": 209.73529243469238, "training_acc": 73.0, "val_loss": 76.65223479270935, "val_acc": 88.0}
{"epoch": 38, "training_loss": 166.94444131851196, "training_acc": 86.0, "val_loss": 55.49602508544922, "val_acc": 68.0}
{"epoch": 39, "training_loss": 239.82084560394287, "training_acc": 72.0, "val_loss": 92.87394285202026, "val_acc": 80.0}
{"epoch": 40, "training_loss": 732.9994735717773, "training_acc": 62.0, "val_loss": 228.76367568969727, "val_acc": 72.0}
{"epoch": 41, "training_loss": 670.2909564971924, "training_acc": 73.0, "val_loss": 70.4424798488617, "val_acc": 84.0}
{"epoch": 42, "training_loss": 777.3558197021484, "training_acc": 66.0, "val_loss": 302.0806312561035, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1018.568733215332, "training_acc": 72.0, "val_loss": 232.1610927581787, "val_acc": 76.0}
{"epoch": 44, "training_loss": 624.405101776123, "training_acc": 71.0, "val_loss": 187.57768869400024, "val_acc": 68.0}
{"epoch": 45, "training_loss": 961.6804237365723, "training_acc": 68.0, "val_loss": 563.6561870574951, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1219.8231773376465, "training_acc": 79.0, "val_loss": 221.54741287231445, "val_acc": 76.0}
{"epoch": 47, "training_loss": 1079.6401443481445, "training_acc": 69.0, "val_loss": 196.03018760681152, "val_acc": 76.0}
{"epoch": 48, "training_loss": 774.4207038879395, "training_acc": 76.0, "val_loss": 428.1095027923584, "val_acc": 72.0}
{"epoch": 49, "training_loss": 739.438967704773, "training_acc": 80.0, "val_loss": 322.9623079299927, "val_acc": 40.0}
{"epoch": 50, "training_loss": 953.8592529296875, "training_acc": 60.0, "val_loss": 402.1174907684326, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1499.0571670532227, "training_acc": 72.0, "val_loss": 73.6662745475769, "val_acc": 88.0}
{"epoch": 52, "training_loss": 1285.1505661010742, "training_acc": 70.0, "val_loss": 69.48480010032654, "val_acc": 64.0}
{"epoch": 53, "training_loss": 544.536735534668, "training_acc": 80.0, "val_loss": 602.1507263183594, "val_acc": 72.0}
{"epoch": 54, "training_loss": 1835.191276550293, "training_acc": 72.0, "val_loss": 252.02250480651855, "val_acc": 44.0}
{"epoch": 55, "training_loss": 932.0747871398926, "training_acc": 53.0, "val_loss": 342.7419900894165, "val_acc": 72.0}
{"epoch": 56, "training_loss": 1144.7300567626953, "training_acc": 74.0, "val_loss": 278.432559967041, "val_acc": 76.0}
{"epoch": 57, "training_loss": 774.3386726379395, "training_acc": 70.0, "val_loss": 127.47682332992554, "val_acc": 80.0}
