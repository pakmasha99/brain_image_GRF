"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.9994785785675, "training_acc": 64.0, "val_loss": 14.984054863452911, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.33578133583069, "training_acc": 72.0, "val_loss": 14.999231696128845, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.49728012084961, "training_acc": 72.0, "val_loss": 15.012551844120026, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.053003787994385, "training_acc": 72.0, "val_loss": 14.839260280132294, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.01081454753876, "training_acc": 72.0, "val_loss": 14.612221717834473, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.06034064292908, "training_acc": 72.0, "val_loss": 14.489878714084625, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.872551679611206, "training_acc": 72.0, "val_loss": 14.430594444274902, "val_acc": 68.0}
{"epoch": 7, "training_loss": 56.70065426826477, "training_acc": 72.0, "val_loss": 14.39201533794403, "val_acc": 68.0}
{"epoch": 8, "training_loss": 56.09428119659424, "training_acc": 72.0, "val_loss": 14.404861629009247, "val_acc": 68.0}
{"epoch": 9, "training_loss": 55.490315198898315, "training_acc": 72.0, "val_loss": 14.501805603504181, "val_acc": 72.0}
{"epoch": 10, "training_loss": 55.938276529312134, "training_acc": 72.0, "val_loss": 14.55567479133606, "val_acc": 72.0}
{"epoch": 11, "training_loss": 54.98358988761902, "training_acc": 72.0, "val_loss": 14.56570029258728, "val_acc": 72.0}
{"epoch": 12, "training_loss": 55.002399921417236, "training_acc": 72.0, "val_loss": 14.471688866615295, "val_acc": 72.0}
{"epoch": 13, "training_loss": 54.469456911087036, "training_acc": 73.0, "val_loss": 14.408129453659058, "val_acc": 72.0}
{"epoch": 14, "training_loss": 53.236225605010986, "training_acc": 74.0, "val_loss": 14.393727481365204, "val_acc": 76.0}
{"epoch": 15, "training_loss": 56.107935428619385, "training_acc": 76.0, "val_loss": 14.423079788684845, "val_acc": 76.0}
{"epoch": 16, "training_loss": 54.82699131965637, "training_acc": 76.0, "val_loss": 14.487424492835999, "val_acc": 76.0}
{"epoch": 17, "training_loss": 54.77660298347473, "training_acc": 75.0, "val_loss": 14.554888010025024, "val_acc": 72.0}
{"epoch": 18, "training_loss": 52.79547953605652, "training_acc": 75.0, "val_loss": 14.650250971317291, "val_acc": 72.0}
{"epoch": 19, "training_loss": 54.194807052612305, "training_acc": 76.0, "val_loss": 14.701984822750092, "val_acc": 72.0}
{"epoch": 20, "training_loss": 54.313443422317505, "training_acc": 76.0, "val_loss": 14.635466039180756, "val_acc": 72.0}
{"epoch": 21, "training_loss": 53.11436581611633, "training_acc": 75.0, "val_loss": 14.531318843364716, "val_acc": 76.0}
{"epoch": 22, "training_loss": 52.637383580207825, "training_acc": 74.0, "val_loss": 14.463324844837189, "val_acc": 72.0}
{"epoch": 23, "training_loss": 54.97062277793884, "training_acc": 73.0, "val_loss": 14.524136483669281, "val_acc": 76.0}
{"epoch": 24, "training_loss": 55.233808755874634, "training_acc": 75.0, "val_loss": 14.629122614860535, "val_acc": 76.0}
{"epoch": 25, "training_loss": 53.75178647041321, "training_acc": 75.0, "val_loss": 14.712503552436829, "val_acc": 72.0}
{"epoch": 26, "training_loss": 53.35536789894104, "training_acc": 77.0, "val_loss": 14.615774154663086, "val_acc": 76.0}
