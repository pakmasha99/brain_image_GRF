"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 67.04018425941467, "training_acc": 52.0, "val_loss": 15.076422691345215, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.93190836906433, "training_acc": 72.0, "val_loss": 15.150833129882812, "val_acc": 72.0}
{"epoch": 2, "training_loss": 60.76313257217407, "training_acc": 72.0, "val_loss": 15.204805135726929, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.643279790878296, "training_acc": 72.0, "val_loss": 14.92796242237091, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.934837102890015, "training_acc": 72.0, "val_loss": 14.571240544319153, "val_acc": 72.0}
{"epoch": 5, "training_loss": 57.87449884414673, "training_acc": 72.0, "val_loss": 14.362777769565582, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.04462027549744, "training_acc": 72.0, "val_loss": 14.318868517875671, "val_acc": 68.0}
{"epoch": 7, "training_loss": 57.23047733306885, "training_acc": 73.0, "val_loss": 14.224790036678314, "val_acc": 72.0}
{"epoch": 8, "training_loss": 56.42707061767578, "training_acc": 71.0, "val_loss": 14.125227928161621, "val_acc": 68.0}
{"epoch": 9, "training_loss": 56.13640213012695, "training_acc": 72.0, "val_loss": 14.093884825706482, "val_acc": 68.0}
{"epoch": 10, "training_loss": 56.276684522628784, "training_acc": 71.0, "val_loss": 14.124947786331177, "val_acc": 76.0}
{"epoch": 11, "training_loss": 55.405346155166626, "training_acc": 72.0, "val_loss": 14.132338762283325, "val_acc": 76.0}
{"epoch": 12, "training_loss": 55.25581240653992, "training_acc": 72.0, "val_loss": 14.15959745645523, "val_acc": 76.0}
{"epoch": 13, "training_loss": 53.67181706428528, "training_acc": 72.0, "val_loss": 14.124885201454163, "val_acc": 68.0}
{"epoch": 14, "training_loss": 54.80024290084839, "training_acc": 71.0, "val_loss": 14.073184132575989, "val_acc": 68.0}
{"epoch": 15, "training_loss": 53.563227891922, "training_acc": 73.0, "val_loss": 14.064060151576996, "val_acc": 68.0}
{"epoch": 16, "training_loss": 54.583797454833984, "training_acc": 74.0, "val_loss": 14.073455333709717, "val_acc": 68.0}
{"epoch": 17, "training_loss": 54.08786129951477, "training_acc": 73.0, "val_loss": 14.084798097610474, "val_acc": 68.0}
{"epoch": 18, "training_loss": 54.56495189666748, "training_acc": 73.0, "val_loss": 14.080210030078888, "val_acc": 68.0}
{"epoch": 19, "training_loss": 54.000545024871826, "training_acc": 73.0, "val_loss": 14.02646154165268, "val_acc": 68.0}
{"epoch": 20, "training_loss": 53.67409634590149, "training_acc": 73.0, "val_loss": 14.005862176418304, "val_acc": 68.0}
{"epoch": 21, "training_loss": 54.46452045440674, "training_acc": 72.0, "val_loss": 13.995935022830963, "val_acc": 68.0}
{"epoch": 22, "training_loss": 54.24263310432434, "training_acc": 74.0, "val_loss": 14.06686156988144, "val_acc": 68.0}
{"epoch": 23, "training_loss": 54.16329264640808, "training_acc": 72.0, "val_loss": 14.145837724208832, "val_acc": 68.0}
{"epoch": 24, "training_loss": 53.272777795791626, "training_acc": 75.0, "val_loss": 14.221033453941345, "val_acc": 68.0}
{"epoch": 25, "training_loss": 55.536635637283325, "training_acc": 75.0, "val_loss": 14.263738691806793, "val_acc": 68.0}
{"epoch": 26, "training_loss": 53.96542692184448, "training_acc": 76.0, "val_loss": 14.244899153709412, "val_acc": 68.0}
{"epoch": 27, "training_loss": 53.025137066841125, "training_acc": 75.0, "val_loss": 14.108023047447205, "val_acc": 68.0}
{"epoch": 28, "training_loss": 52.83379817008972, "training_acc": 75.0, "val_loss": 14.088572561740875, "val_acc": 68.0}
{"epoch": 29, "training_loss": 51.86609768867493, "training_acc": 74.0, "val_loss": 14.040632545948029, "val_acc": 68.0}
{"epoch": 30, "training_loss": 53.83068919181824, "training_acc": 75.0, "val_loss": 14.059455692768097, "val_acc": 68.0}
{"epoch": 31, "training_loss": 53.693395376205444, "training_acc": 75.0, "val_loss": 14.053402841091156, "val_acc": 68.0}
{"epoch": 32, "training_loss": 53.40335512161255, "training_acc": 76.0, "val_loss": 14.033082127571106, "val_acc": 68.0}
{"epoch": 33, "training_loss": 53.025869607925415, "training_acc": 74.0, "val_loss": 14.030194282531738, "val_acc": 68.0}
{"epoch": 34, "training_loss": 51.78103566169739, "training_acc": 76.0, "val_loss": 14.05724436044693, "val_acc": 68.0}
{"epoch": 35, "training_loss": 52.10118126869202, "training_acc": 75.0, "val_loss": 14.114196598529816, "val_acc": 68.0}
{"epoch": 36, "training_loss": 52.86690878868103, "training_acc": 76.0, "val_loss": 14.230526983737946, "val_acc": 68.0}
{"epoch": 37, "training_loss": 50.942177295684814, "training_acc": 76.0, "val_loss": 14.331534504890442, "val_acc": 68.0}
{"epoch": 38, "training_loss": 52.08843231201172, "training_acc": 75.0, "val_loss": 14.305952191352844, "val_acc": 68.0}
{"epoch": 39, "training_loss": 52.39216732978821, "training_acc": 76.0, "val_loss": 14.240249991416931, "val_acc": 68.0}
{"epoch": 40, "training_loss": 52.001327991485596, "training_acc": 76.0, "val_loss": 14.121092855930328, "val_acc": 68.0}
