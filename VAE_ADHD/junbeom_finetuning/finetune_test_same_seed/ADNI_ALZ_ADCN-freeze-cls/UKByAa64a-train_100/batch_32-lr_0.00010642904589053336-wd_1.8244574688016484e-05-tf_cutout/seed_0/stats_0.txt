"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69.58884763717651, "training_acc": 45.0, "val_loss": 16.749435663223267, "val_acc": 28.0}
{"epoch": 1, "training_loss": 66.35212111473083, "training_acc": 72.0, "val_loss": 16.170066595077515, "val_acc": 28.0}
{"epoch": 2, "training_loss": 64.09942364692688, "training_acc": 72.0, "val_loss": 15.828773379325867, "val_acc": 28.0}
{"epoch": 3, "training_loss": 62.89328932762146, "training_acc": 72.0, "val_loss": 15.487335622310638, "val_acc": 28.0}
{"epoch": 4, "training_loss": 61.61775994300842, "training_acc": 72.0, "val_loss": 15.230438113212585, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.401307702064514, "training_acc": 72.0, "val_loss": 15.078341960906982, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.07734751701355, "training_acc": 72.0, "val_loss": 14.961698651313782, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.565208435058594, "training_acc": 72.0, "val_loss": 14.906498789787292, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.44625663757324, "training_acc": 72.0, "val_loss": 14.892038702964783, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.398401498794556, "training_acc": 72.0, "val_loss": 14.892731606960297, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.49508213996887, "training_acc": 72.0, "val_loss": 14.897239208221436, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.39811873435974, "training_acc": 72.0, "val_loss": 14.897815883159637, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.422523975372314, "training_acc": 72.0, "val_loss": 14.89664763212204, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.4831600189209, "training_acc": 72.0, "val_loss": 14.895853400230408, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.44454574584961, "training_acc": 72.0, "val_loss": 14.896804094314575, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.49334979057312, "training_acc": 72.0, "val_loss": 14.89522010087967, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.45862650871277, "training_acc": 72.0, "val_loss": 14.891985058784485, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.434486865997314, "training_acc": 72.0, "val_loss": 14.892849326133728, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.48425507545471, "training_acc": 72.0, "val_loss": 14.899787306785583, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.32671880722046, "training_acc": 72.0, "val_loss": 14.900793135166168, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.437448024749756, "training_acc": 72.0, "val_loss": 14.895673096179962, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.35580015182495, "training_acc": 72.0, "val_loss": 14.892387390136719, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.368067264556885, "training_acc": 72.0, "val_loss": 14.888475835323334, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.41711664199829, "training_acc": 72.0, "val_loss": 14.888130128383636, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.32667779922485, "training_acc": 72.0, "val_loss": 14.888258278369904, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.34834861755371, "training_acc": 72.0, "val_loss": 14.888456463813782, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.35008478164673, "training_acc": 72.0, "val_loss": 14.888808131217957, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.4521005153656, "training_acc": 72.0, "val_loss": 14.890258014202118, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.3511438369751, "training_acc": 72.0, "val_loss": 14.895522594451904, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.407389640808105, "training_acc": 72.0, "val_loss": 14.901082217693329, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.3622567653656, "training_acc": 72.0, "val_loss": 14.902111887931824, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.446794509887695, "training_acc": 72.0, "val_loss": 14.899249374866486, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.53916597366333, "training_acc": 72.0, "val_loss": 14.885307848453522, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.49776899814606, "training_acc": 72.0, "val_loss": 14.884074032306671, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.455589294433594, "training_acc": 72.0, "val_loss": 14.883796870708466, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.270357847213745, "training_acc": 72.0, "val_loss": 14.884623885154724, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.41597366333008, "training_acc": 72.0, "val_loss": 14.889359474182129, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.45504856109619, "training_acc": 72.0, "val_loss": 14.896130561828613, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.41738796234131, "training_acc": 72.0, "val_loss": 14.899900555610657, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.46113967895508, "training_acc": 72.0, "val_loss": 14.902108907699585, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.38749670982361, "training_acc": 72.0, "val_loss": 14.900240302085876, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.32529640197754, "training_acc": 72.0, "val_loss": 14.896750450134277, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.372493743896484, "training_acc": 72.0, "val_loss": 14.893728494644165, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.389339447021484, "training_acc": 72.0, "val_loss": 14.897498488426208, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.50664758682251, "training_acc": 72.0, "val_loss": 14.900298416614532, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.359071493148804, "training_acc": 72.0, "val_loss": 14.900144934654236, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.52422618865967, "training_acc": 72.0, "val_loss": 14.895689487457275, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.349257946014404, "training_acc": 72.0, "val_loss": 14.893339574337006, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.44870066642761, "training_acc": 72.0, "val_loss": 14.887841045856476, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.41324579715729, "training_acc": 72.0, "val_loss": 14.886769652366638, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.35690975189209, "training_acc": 72.0, "val_loss": 14.891323447227478, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.37362337112427, "training_acc": 72.0, "val_loss": 14.894866943359375, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.44537591934204, "training_acc": 72.0, "val_loss": 14.896763861179352, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.422329783439636, "training_acc": 72.0, "val_loss": 14.895330369472504, "val_acc": 72.0}
