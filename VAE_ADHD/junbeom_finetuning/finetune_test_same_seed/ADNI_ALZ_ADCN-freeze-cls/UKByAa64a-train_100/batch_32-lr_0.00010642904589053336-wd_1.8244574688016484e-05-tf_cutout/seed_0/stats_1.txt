"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 64.9984815120697, "training_acc": 72.0, "val_loss": 15.805922448635101, "val_acc": 28.0}
{"epoch": 1, "training_loss": 62.647085189819336, "training_acc": 72.0, "val_loss": 15.356114506721497, "val_acc": 52.0}
{"epoch": 2, "training_loss": 61.04907143115997, "training_acc": 72.0, "val_loss": 15.065953135490417, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.02135419845581, "training_acc": 72.0, "val_loss": 14.903491735458374, "val_acc": 72.0}
{"epoch": 4, "training_loss": 59.371336221694946, "training_acc": 72.0, "val_loss": 14.844359457492828, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.42532539367676, "training_acc": 72.0, "val_loss": 14.836341142654419, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.45777750015259, "training_acc": 72.0, "val_loss": 14.848288893699646, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.33930194377899, "training_acc": 72.0, "val_loss": 14.85014259815216, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.46165943145752, "training_acc": 72.0, "val_loss": 14.862394332885742, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.33676218986511, "training_acc": 72.0, "val_loss": 14.867091178894043, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.47963285446167, "training_acc": 72.0, "val_loss": 14.87409621477127, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.48113441467285, "training_acc": 72.0, "val_loss": 14.864780008792877, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.3926944732666, "training_acc": 72.0, "val_loss": 14.855875074863434, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.50855731964111, "training_acc": 72.0, "val_loss": 14.8466557264328, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.31705641746521, "training_acc": 72.0, "val_loss": 14.843200147151947, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.406702280044556, "training_acc": 72.0, "val_loss": 14.838798344135284, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.366257309913635, "training_acc": 72.0, "val_loss": 14.838309586048126, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.36441743373871, "training_acc": 72.0, "val_loss": 14.84428346157074, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.42005395889282, "training_acc": 72.0, "val_loss": 14.854392409324646, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.428364753723145, "training_acc": 72.0, "val_loss": 14.845971763134003, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.4489541053772, "training_acc": 72.0, "val_loss": 14.833340048789978, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.3374388217926, "training_acc": 72.0, "val_loss": 14.83137160539627, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.232993841171265, "training_acc": 72.0, "val_loss": 14.834338426589966, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.28850698471069, "training_acc": 72.0, "val_loss": 14.83735740184784, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.239386320114136, "training_acc": 72.0, "val_loss": 14.834918081760406, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.20068717002869, "training_acc": 72.0, "val_loss": 14.829742908477783, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.23758006095886, "training_acc": 72.0, "val_loss": 14.830398559570312, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.33486747741699, "training_acc": 72.0, "val_loss": 14.841791987419128, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.45245838165283, "training_acc": 72.0, "val_loss": 14.857181906700134, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.47556948661804, "training_acc": 72.0, "val_loss": 14.882193505764008, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.57131886482239, "training_acc": 72.0, "val_loss": 14.895474910736084, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.55247139930725, "training_acc": 72.0, "val_loss": 14.921841025352478, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.735904812812805, "training_acc": 72.0, "val_loss": 14.954592287540436, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.802502036094666, "training_acc": 72.0, "val_loss": 14.98032659292221, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.94140815734863, "training_acc": 72.0, "val_loss": 14.997424185276031, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.99331307411194, "training_acc": 72.0, "val_loss": 14.949692785739899, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.7337064743042, "training_acc": 72.0, "val_loss": 14.920422434806824, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.618340492248535, "training_acc": 72.0, "val_loss": 14.901761710643768, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.59302866458893, "training_acc": 72.0, "val_loss": 14.885683357715607, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.48111414909363, "training_acc": 72.0, "val_loss": 14.881181716918945, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.462985038757324, "training_acc": 72.0, "val_loss": 14.867517352104187, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.327332854270935, "training_acc": 72.0, "val_loss": 14.845862984657288, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.39460277557373, "training_acc": 72.0, "val_loss": 14.841939508914948, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.34372615814209, "training_acc": 72.0, "val_loss": 14.835876226425171, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.39840626716614, "training_acc": 72.0, "val_loss": 14.834031462669373, "val_acc": 72.0}
