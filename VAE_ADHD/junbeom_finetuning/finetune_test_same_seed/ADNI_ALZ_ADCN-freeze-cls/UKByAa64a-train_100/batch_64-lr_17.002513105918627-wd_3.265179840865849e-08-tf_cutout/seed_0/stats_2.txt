"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 32442.584255218506, "training_acc": 38.0, "val_loss": 13172.2412109375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 39660.58221435547, "training_acc": 72.0, "val_loss": 9906.455993652344, "val_acc": 28.0}
{"epoch": 2, "training_loss": 42678.12170410156, "training_acc": 28.0, "val_loss": 1909.4781875610352, "val_acc": 68.0}
{"epoch": 3, "training_loss": 9868.519409179688, "training_acc": 72.0, "val_loss": 8503.673553466797, "val_acc": 72.0}
{"epoch": 4, "training_loss": 32148.481811523438, "training_acc": 72.0, "val_loss": 7292.083740234375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 18794.704223632812, "training_acc": 74.0, "val_loss": 2916.6961669921875, "val_acc": 60.0}
{"epoch": 6, "training_loss": 18969.35186767578, "training_acc": 51.0, "val_loss": 4320.475006103516, "val_acc": 48.0}
{"epoch": 7, "training_loss": 20800.43716430664, "training_acc": 58.0, "val_loss": 4037.540054321289, "val_acc": 76.0}
{"epoch": 8, "training_loss": 14632.349609375, "training_acc": 72.0, "val_loss": 6407.551574707031, "val_acc": 72.0}
{"epoch": 9, "training_loss": 18414.643188476562, "training_acc": 72.0, "val_loss": 2839.842987060547, "val_acc": 68.0}
{"epoch": 10, "training_loss": 9262.631103515625, "training_acc": 67.0, "val_loss": 2956.1750411987305, "val_acc": 52.0}
{"epoch": 11, "training_loss": 12541.732940673828, "training_acc": 55.0, "val_loss": 2317.082405090332, "val_acc": 68.0}
{"epoch": 12, "training_loss": 7185.512634277344, "training_acc": 75.0, "val_loss": 3464.3142700195312, "val_acc": 72.0}
{"epoch": 13, "training_loss": 7977.677947998047, "training_acc": 72.0, "val_loss": 3238.3689880371094, "val_acc": 44.0}
{"epoch": 14, "training_loss": 11415.378143310547, "training_acc": 40.0, "val_loss": 1974.612808227539, "val_acc": 68.0}
{"epoch": 15, "training_loss": 8056.016662597656, "training_acc": 73.0, "val_loss": 2699.2006301879883, "val_acc": 72.0}
{"epoch": 16, "training_loss": 6332.787410736084, "training_acc": 72.0, "val_loss": 2153.843307495117, "val_acc": 48.0}
{"epoch": 17, "training_loss": 5434.819534301758, "training_acc": 55.0, "val_loss": 2603.091049194336, "val_acc": 72.0}
{"epoch": 18, "training_loss": 8946.394165039062, "training_acc": 72.0, "val_loss": 2871.608352661133, "val_acc": 72.0}
{"epoch": 19, "training_loss": 6411.2886962890625, "training_acc": 73.0, "val_loss": 1560.6868743896484, "val_acc": 60.0}
{"epoch": 20, "training_loss": 6643.118103027344, "training_acc": 57.0, "val_loss": 1312.0092391967773, "val_acc": 68.0}
{"epoch": 21, "training_loss": 4091.9520416259766, "training_acc": 76.0, "val_loss": 2159.5510482788086, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4099.69832611084, "training_acc": 73.0, "val_loss": 1145.744514465332, "val_acc": 60.0}
{"epoch": 23, "training_loss": 4445.603759765625, "training_acc": 66.0, "val_loss": 759.2835903167725, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1549.0447158813477, "training_acc": 79.0, "val_loss": 577.324390411377, "val_acc": 48.0}
{"epoch": 25, "training_loss": 1012.2748260498047, "training_acc": 75.0, "val_loss": 1234.385585784912, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2483.6817626953125, "training_acc": 74.0, "val_loss": 2202.3910522460938, "val_acc": 36.0}
{"epoch": 27, "training_loss": 5452.092323303223, "training_acc": 54.0, "val_loss": 1581.5770149230957, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4195.986122131348, "training_acc": 72.0, "val_loss": 489.8089408874512, "val_acc": 64.0}
{"epoch": 29, "training_loss": 2406.450019836426, "training_acc": 64.0, "val_loss": 1800.3259658813477, "val_acc": 72.0}
{"epoch": 30, "training_loss": 6225.445068359375, "training_acc": 72.0, "val_loss": 838.6327743530273, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2480.010025024414, "training_acc": 77.0, "val_loss": 1287.1134757995605, "val_acc": 52.0}
{"epoch": 32, "training_loss": 6129.633834838867, "training_acc": 53.0, "val_loss": 2383.3126068115234, "val_acc": 72.0}
{"epoch": 33, "training_loss": 5761.63374710083, "training_acc": 74.0, "val_loss": 911.6264343261719, "val_acc": 80.0}
{"epoch": 34, "training_loss": 2988.450164794922, "training_acc": 70.0, "val_loss": 1068.5935020446777, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3510.133026123047, "training_acc": 79.0, "val_loss": 1989.472770690918, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4121.943450927734, "training_acc": 75.0, "val_loss": 797.1970081329346, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2636.455997467041, "training_acc": 70.0, "val_loss": 1298.6713409423828, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2425.9304189682007, "training_acc": 75.0, "val_loss": 719.1610336303711, "val_acc": 56.0}
{"epoch": 39, "training_loss": 1071.8253841400146, "training_acc": 77.0, "val_loss": 992.4107551574707, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1066.7833003997803, "training_acc": 79.0, "val_loss": 906.0634613037109, "val_acc": 56.0}
{"epoch": 41, "training_loss": 3063.9180603027344, "training_acc": 57.0, "val_loss": 1037.9843711853027, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1443.1768989562988, "training_acc": 79.0, "val_loss": 520.2195167541504, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1832.0411567687988, "training_acc": 77.0, "val_loss": 998.692512512207, "val_acc": 76.0}
{"epoch": 44, "training_loss": 1641.225399017334, "training_acc": 85.0, "val_loss": 545.1752185821533, "val_acc": 76.0}
{"epoch": 45, "training_loss": 1505.4925384521484, "training_acc": 81.0, "val_loss": 534.053373336792, "val_acc": 76.0}
{"epoch": 46, "training_loss": 838.6033954620361, "training_acc": 88.0, "val_loss": 195.26013135910034, "val_acc": 80.0}
{"epoch": 47, "training_loss": 352.97633361816406, "training_acc": 84.0, "val_loss": 644.1262245178223, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1431.6335639953613, "training_acc": 75.0, "val_loss": 370.77813148498535, "val_acc": 60.0}
{"epoch": 49, "training_loss": 779.4221343994141, "training_acc": 78.0, "val_loss": 226.52480602264404, "val_acc": 68.0}
{"epoch": 50, "training_loss": 513.7581343650818, "training_acc": 85.0, "val_loss": 451.56731605529785, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1072.0518236160278, "training_acc": 85.0, "val_loss": 269.57855224609375, "val_acc": 80.0}
{"epoch": 52, "training_loss": 538.599609375, "training_acc": 90.0, "val_loss": 283.2048177719116, "val_acc": 76.0}
{"epoch": 53, "training_loss": 1277.1666793823242, "training_acc": 75.0, "val_loss": 1608.5060119628906, "val_acc": 72.0}
{"epoch": 54, "training_loss": 4825.125076293945, "training_acc": 72.0, "val_loss": 320.39012908935547, "val_acc": 68.0}
{"epoch": 55, "training_loss": 2867.840057373047, "training_acc": 73.0, "val_loss": 861.0694885253906, "val_acc": 72.0}
{"epoch": 56, "training_loss": 3333.8094177246094, "training_acc": 78.0, "val_loss": 903.7163734436035, "val_acc": 76.0}
{"epoch": 57, "training_loss": 2305.768508911133, "training_acc": 72.0, "val_loss": 802.8781890869141, "val_acc": 68.0}
{"epoch": 58, "training_loss": 1629.2460479736328, "training_acc": 81.0, "val_loss": 1085.0533485412598, "val_acc": 68.0}
{"epoch": 59, "training_loss": 976.9057197570801, "training_acc": 85.0, "val_loss": 1192.921257019043, "val_acc": 64.0}
{"epoch": 60, "training_loss": 2935.710437774658, "training_acc": 64.0, "val_loss": 2335.228157043457, "val_acc": 72.0}
{"epoch": 61, "training_loss": 4247.871353149414, "training_acc": 75.0, "val_loss": 1177.7901649475098, "val_acc": 64.0}
{"epoch": 62, "training_loss": 3108.4742393493652, "training_acc": 65.0, "val_loss": 1443.4901237487793, "val_acc": 64.0}
{"epoch": 63, "training_loss": 2623.610153198242, "training_acc": 80.0, "val_loss": 969.4362640380859, "val_acc": 68.0}
{"epoch": 64, "training_loss": 2959.3319549560547, "training_acc": 70.0, "val_loss": 1309.2601776123047, "val_acc": 68.0}
{"epoch": 65, "training_loss": 2323.301284790039, "training_acc": 77.0, "val_loss": 1042.6143646240234, "val_acc": 68.0}
