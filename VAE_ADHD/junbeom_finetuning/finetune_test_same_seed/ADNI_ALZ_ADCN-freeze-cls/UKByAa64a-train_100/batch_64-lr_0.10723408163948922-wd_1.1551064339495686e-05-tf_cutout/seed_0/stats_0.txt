"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 217.92310333251953, "training_acc": 72.0, "val_loss": 77.74491906166077, "val_acc": 72.0}
{"epoch": 1, "training_loss": 214.39976406097412, "training_acc": 72.0, "val_loss": 114.93574380874634, "val_acc": 28.0}
{"epoch": 2, "training_loss": 470.2721881866455, "training_acc": 28.0, "val_loss": 17.69297569990158, "val_acc": 44.0}
{"epoch": 3, "training_loss": 124.64399099349976, "training_acc": 56.0, "val_loss": 68.66085529327393, "val_acc": 72.0}
{"epoch": 4, "training_loss": 301.8651313781738, "training_acc": 72.0, "val_loss": 83.00003409385681, "val_acc": 72.0}
{"epoch": 5, "training_loss": 327.0219888687134, "training_acc": 72.0, "val_loss": 50.04620552062988, "val_acc": 72.0}
{"epoch": 6, "training_loss": 163.99478912353516, "training_acc": 74.0, "val_loss": 12.50436007976532, "val_acc": 80.0}
{"epoch": 7, "training_loss": 168.60966682434082, "training_acc": 61.0, "val_loss": 31.27059042453766, "val_acc": 44.0}
{"epoch": 8, "training_loss": 193.4548077583313, "training_acc": 50.0, "val_loss": 13.888336718082428, "val_acc": 72.0}
{"epoch": 9, "training_loss": 93.7877242565155, "training_acc": 74.0, "val_loss": 35.663631558418274, "val_acc": 72.0}
{"epoch": 10, "training_loss": 141.9498085975647, "training_acc": 72.0, "val_loss": 26.128065586090088, "val_acc": 72.0}
{"epoch": 11, "training_loss": 89.58808612823486, "training_acc": 70.0, "val_loss": 14.201238751411438, "val_acc": 64.0}
{"epoch": 12, "training_loss": 90.0134506225586, "training_acc": 60.0, "val_loss": 14.709275960922241, "val_acc": 60.0}
{"epoch": 13, "training_loss": 62.690383434295654, "training_acc": 75.0, "val_loss": 23.93674999475479, "val_acc": 72.0}
{"epoch": 14, "training_loss": 96.00494575500488, "training_acc": 72.0, "val_loss": 23.342230916023254, "val_acc": 72.0}
{"epoch": 15, "training_loss": 68.94232940673828, "training_acc": 72.0, "val_loss": 20.412836968898773, "val_acc": 44.0}
{"epoch": 16, "training_loss": 82.62042355537415, "training_acc": 46.0, "val_loss": 14.501355588436127, "val_acc": 60.0}
{"epoch": 17, "training_loss": 51.46802377700806, "training_acc": 76.0, "val_loss": 21.72359675168991, "val_acc": 72.0}
{"epoch": 18, "training_loss": 77.39149475097656, "training_acc": 72.0, "val_loss": 13.867741823196411, "val_acc": 72.0}
{"epoch": 19, "training_loss": 61.810627698898315, "training_acc": 63.0, "val_loss": 16.72774851322174, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.712839126586914, "training_acc": 68.0, "val_loss": 16.07004553079605, "val_acc": 72.0}
{"epoch": 21, "training_loss": 70.43258857727051, "training_acc": 72.0, "val_loss": 15.750254690647125, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.23373746871948, "training_acc": 71.0, "val_loss": 14.926624298095703, "val_acc": 56.0}
{"epoch": 23, "training_loss": 63.095053911209106, "training_acc": 68.0, "val_loss": 11.549238115549088, "val_acc": 84.0}
{"epoch": 24, "training_loss": 50.38057589530945, "training_acc": 75.0, "val_loss": 15.762223303318024, "val_acc": 72.0}
{"epoch": 25, "training_loss": 54.994388461112976, "training_acc": 76.0, "val_loss": 11.713366210460663, "val_acc": 72.0}
{"epoch": 26, "training_loss": 46.776612997055054, "training_acc": 74.0, "val_loss": 12.67787516117096, "val_acc": 64.0}
{"epoch": 27, "training_loss": 49.635701417922974, "training_acc": 74.0, "val_loss": 13.573713600635529, "val_acc": 72.0}
{"epoch": 28, "training_loss": 48.258880615234375, "training_acc": 77.0, "val_loss": 12.745152413845062, "val_acc": 84.0}
{"epoch": 29, "training_loss": 46.924203753471375, "training_acc": 79.0, "val_loss": 12.904109060764313, "val_acc": 64.0}
{"epoch": 30, "training_loss": 43.481764912605286, "training_acc": 80.0, "val_loss": 13.613958656787872, "val_acc": 72.0}
{"epoch": 31, "training_loss": 48.49395298957825, "training_acc": 74.0, "val_loss": 12.793990969657898, "val_acc": 84.0}
{"epoch": 32, "training_loss": 45.47046089172363, "training_acc": 79.0, "val_loss": 13.64690214395523, "val_acc": 64.0}
{"epoch": 33, "training_loss": 47.7233909368515, "training_acc": 80.0, "val_loss": 14.753715693950653, "val_acc": 72.0}
{"epoch": 34, "training_loss": 53.10747289657593, "training_acc": 74.0, "val_loss": 12.91716992855072, "val_acc": 76.0}
{"epoch": 35, "training_loss": 45.76992070674896, "training_acc": 80.0, "val_loss": 14.117959141731262, "val_acc": 56.0}
{"epoch": 36, "training_loss": 49.277477383613586, "training_acc": 75.0, "val_loss": 13.316124677658081, "val_acc": 76.0}
{"epoch": 37, "training_loss": 51.74886417388916, "training_acc": 76.0, "val_loss": 12.748382985591888, "val_acc": 76.0}
{"epoch": 38, "training_loss": 43.20096027851105, "training_acc": 80.0, "val_loss": 14.892013370990753, "val_acc": 52.0}
{"epoch": 39, "training_loss": 56.01558077335358, "training_acc": 77.0, "val_loss": 13.47842812538147, "val_acc": 72.0}
{"epoch": 40, "training_loss": 54.278098344802856, "training_acc": 75.0, "val_loss": 12.459932267665863, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.36516499519348, "training_acc": 81.0, "val_loss": 13.695038855075836, "val_acc": 56.0}
{"epoch": 42, "training_loss": 48.81800866127014, "training_acc": 75.0, "val_loss": 13.807827234268188, "val_acc": 72.0}
