"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.17460107803345, "training_acc": 72.0, "val_loss": 15.287432074546814, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.580615520477295, "training_acc": 72.0, "val_loss": 14.914582669734955, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.48105430603027, "training_acc": 72.0, "val_loss": 14.7494375705719, "val_acc": 72.0}
{"epoch": 3, "training_loss": 59.24822783470154, "training_acc": 72.0, "val_loss": 14.544723927974701, "val_acc": 72.0}
{"epoch": 4, "training_loss": 58.69689702987671, "training_acc": 72.0, "val_loss": 14.366206526756287, "val_acc": 72.0}
{"epoch": 5, "training_loss": 58.144182205200195, "training_acc": 72.0, "val_loss": 14.1946479678154, "val_acc": 72.0}
{"epoch": 6, "training_loss": 57.520087480545044, "training_acc": 72.0, "val_loss": 14.057406783103943, "val_acc": 72.0}
{"epoch": 7, "training_loss": 57.72440159320831, "training_acc": 72.0, "val_loss": 13.945259153842926, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.27479887008667, "training_acc": 72.0, "val_loss": 13.877475261688232, "val_acc": 72.0}
{"epoch": 9, "training_loss": 57.53798508644104, "training_acc": 72.0, "val_loss": 13.680122792720795, "val_acc": 72.0}
{"epoch": 10, "training_loss": 56.00563097000122, "training_acc": 72.0, "val_loss": 13.595739006996155, "val_acc": 72.0}
{"epoch": 11, "training_loss": 55.96938419342041, "training_acc": 72.0, "val_loss": 13.488870859146118, "val_acc": 72.0}
{"epoch": 12, "training_loss": 56.63764667510986, "training_acc": 72.0, "val_loss": 13.412481546401978, "val_acc": 80.0}
{"epoch": 13, "training_loss": 57.69918417930603, "training_acc": 71.0, "val_loss": 13.366290926933289, "val_acc": 80.0}
{"epoch": 14, "training_loss": 56.527730226516724, "training_acc": 72.0, "val_loss": 13.38968276977539, "val_acc": 72.0}
{"epoch": 15, "training_loss": 56.82863521575928, "training_acc": 72.0, "val_loss": 13.379275798797607, "val_acc": 72.0}
{"epoch": 16, "training_loss": 55.80904769897461, "training_acc": 72.0, "val_loss": 13.290612399578094, "val_acc": 72.0}
{"epoch": 17, "training_loss": 55.74132490158081, "training_acc": 72.0, "val_loss": 13.307267427444458, "val_acc": 72.0}
{"epoch": 18, "training_loss": 56.47270965576172, "training_acc": 72.0, "val_loss": 13.411442935466766, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55.76038193702698, "training_acc": 72.0, "val_loss": 13.318155705928802, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.42328119277954, "training_acc": 72.0, "val_loss": 13.120251893997192, "val_acc": 72.0}
{"epoch": 21, "training_loss": 55.33415699005127, "training_acc": 72.0, "val_loss": 13.030800223350525, "val_acc": 76.0}
{"epoch": 22, "training_loss": 55.4052654504776, "training_acc": 75.0, "val_loss": 12.974146008491516, "val_acc": 76.0}
{"epoch": 23, "training_loss": 56.09080219268799, "training_acc": 73.0, "val_loss": 12.933339178562164, "val_acc": 76.0}
{"epoch": 24, "training_loss": 55.786800265312195, "training_acc": 73.0, "val_loss": 12.937143445014954, "val_acc": 76.0}
{"epoch": 25, "training_loss": 55.75752902030945, "training_acc": 73.0, "val_loss": 12.986721098423004, "val_acc": 72.0}
{"epoch": 26, "training_loss": 56.878821849823, "training_acc": 72.0, "val_loss": 13.041266798973083, "val_acc": 72.0}
{"epoch": 27, "training_loss": 55.72861194610596, "training_acc": 72.0, "val_loss": 13.124093413352966, "val_acc": 72.0}
{"epoch": 28, "training_loss": 56.58159017562866, "training_acc": 72.0, "val_loss": 13.307468593120575, "val_acc": 72.0}
{"epoch": 29, "training_loss": 55.21697545051575, "training_acc": 72.0, "val_loss": 13.362845778465271, "val_acc": 72.0}
{"epoch": 30, "training_loss": 56.0639853477478, "training_acc": 72.0, "val_loss": 13.171464204788208, "val_acc": 72.0}
{"epoch": 31, "training_loss": 55.802478313446045, "training_acc": 72.0, "val_loss": 12.976151704788208, "val_acc": 72.0}
{"epoch": 32, "training_loss": 55.76598763465881, "training_acc": 72.0, "val_loss": 12.897045910358429, "val_acc": 76.0}
{"epoch": 33, "training_loss": 55.92558264732361, "training_acc": 72.0, "val_loss": 12.92911171913147, "val_acc": 76.0}
{"epoch": 34, "training_loss": 56.92635202407837, "training_acc": 74.0, "val_loss": 12.998920679092407, "val_acc": 76.0}
{"epoch": 35, "training_loss": 56.34606575965881, "training_acc": 72.0, "val_loss": 13.30239623785019, "val_acc": 72.0}
{"epoch": 36, "training_loss": 56.187620639801025, "training_acc": 72.0, "val_loss": 13.59674483537674, "val_acc": 72.0}
{"epoch": 37, "training_loss": 56.30645954608917, "training_acc": 72.0, "val_loss": 13.619130849838257, "val_acc": 72.0}
{"epoch": 38, "training_loss": 56.31567049026489, "training_acc": 72.0, "val_loss": 13.362614810466766, "val_acc": 72.0}
{"epoch": 39, "training_loss": 55.615776777267456, "training_acc": 72.0, "val_loss": 13.133199512958527, "val_acc": 72.0}
{"epoch": 40, "training_loss": 55.50866091251373, "training_acc": 72.0, "val_loss": 12.986087799072266, "val_acc": 72.0}
{"epoch": 41, "training_loss": 54.40193486213684, "training_acc": 72.0, "val_loss": 12.945528328418732, "val_acc": 80.0}
{"epoch": 42, "training_loss": 54.17693829536438, "training_acc": 77.0, "val_loss": 12.942585349082947, "val_acc": 76.0}
{"epoch": 43, "training_loss": 54.746206760406494, "training_acc": 75.0, "val_loss": 13.070207834243774, "val_acc": 72.0}
{"epoch": 44, "training_loss": 53.299941062927246, "training_acc": 72.0, "val_loss": 13.269956409931183, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54.4580078125, "training_acc": 72.0, "val_loss": 13.35635781288147, "val_acc": 72.0}
{"epoch": 46, "training_loss": 56.29946970939636, "training_acc": 72.0, "val_loss": 13.330499827861786, "val_acc": 72.0}
{"epoch": 47, "training_loss": 55.922091126441956, "training_acc": 72.0, "val_loss": 13.273091614246368, "val_acc": 72.0}
{"epoch": 48, "training_loss": 54.702569007873535, "training_acc": 72.0, "val_loss": 13.113996386528015, "val_acc": 72.0}
{"epoch": 49, "training_loss": 54.1709086894989, "training_acc": 72.0, "val_loss": 13.069558143615723, "val_acc": 80.0}
{"epoch": 50, "training_loss": 54.35432684421539, "training_acc": 72.0, "val_loss": 13.055923581123352, "val_acc": 76.0}
{"epoch": 51, "training_loss": 55.140097856521606, "training_acc": 72.0, "val_loss": 13.048137724399567, "val_acc": 72.0}
