"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2043.804671406746, "training_acc": 72.0, "val_loss": 477.6580810546875, "val_acc": 28.0}
{"epoch": 1, "training_loss": 1053.3544616699219, "training_acc": 57.0, "val_loss": 183.3291530609131, "val_acc": 72.0}
{"epoch": 2, "training_loss": 642.5576477050781, "training_acc": 63.0, "val_loss": 193.1973695755005, "val_acc": 64.0}
{"epoch": 3, "training_loss": 341.83178901672363, "training_acc": 74.0, "val_loss": 84.01734828948975, "val_acc": 72.0}
{"epoch": 4, "training_loss": 402.66319274902344, "training_acc": 62.0, "val_loss": 96.15485668182373, "val_acc": 72.0}
{"epoch": 5, "training_loss": 273.8893747329712, "training_acc": 54.0, "val_loss": 159.1779112815857, "val_acc": 72.0}
{"epoch": 6, "training_loss": 466.2894477844238, "training_acc": 63.0, "val_loss": 142.111337184906, "val_acc": 72.0}
{"epoch": 7, "training_loss": 930.3970413208008, "training_acc": 72.0, "val_loss": 80.41395545005798, "val_acc": 40.0}
{"epoch": 8, "training_loss": 535.5457057952881, "training_acc": 52.0, "val_loss": 245.10939121246338, "val_acc": 72.0}
{"epoch": 9, "training_loss": 884.1863021850586, "training_acc": 72.0, "val_loss": 248.114013671875, "val_acc": 36.0}
{"epoch": 10, "training_loss": 844.6278877258301, "training_acc": 44.0, "val_loss": 335.81416606903076, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1676.7758979797363, "training_acc": 72.0, "val_loss": 404.9700736999512, "val_acc": 72.0}
{"epoch": 12, "training_loss": 913.5881290435791, "training_acc": 74.0, "val_loss": 684.9013328552246, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1422.101058959961, "training_acc": 41.0, "val_loss": 257.2166681289673, "val_acc": 72.0}
{"epoch": 14, "training_loss": 730.365288734436, "training_acc": 74.0, "val_loss": 312.63134479522705, "val_acc": 48.0}
{"epoch": 15, "training_loss": 744.5462589263916, "training_acc": 57.0, "val_loss": 176.9634246826172, "val_acc": 76.0}
{"epoch": 16, "training_loss": 461.5897903442383, "training_acc": 77.0, "val_loss": 288.5232448577881, "val_acc": 48.0}
{"epoch": 17, "training_loss": 1164.9375000298023, "training_acc": 49.0, "val_loss": 178.42942476272583, "val_acc": 80.0}
{"epoch": 18, "training_loss": 1031.3556213378906, "training_acc": 73.0, "val_loss": 222.09365367889404, "val_acc": 72.0}
{"epoch": 19, "training_loss": 477.1454749107361, "training_acc": 78.0, "val_loss": 491.84837341308594, "val_acc": 28.0}
{"epoch": 20, "training_loss": 899.6779661178548, "training_acc": 57.0, "val_loss": 344.4397449493408, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1580.6200561523438, "training_acc": 72.0, "val_loss": 145.27419805526733, "val_acc": 80.0}
{"epoch": 22, "training_loss": 1260.6909942626953, "training_acc": 48.0, "val_loss": 250.39148330688477, "val_acc": 64.0}
{"epoch": 23, "training_loss": 969.8808364868164, "training_acc": 70.0, "val_loss": 547.9028701782227, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1835.9100004583597, "training_acc": 72.0, "val_loss": 254.84025478363037, "val_acc": 72.0}
{"epoch": 25, "training_loss": 639.7849082946777, "training_acc": 69.0, "val_loss": 250.03106594085693, "val_acc": 64.0}
{"epoch": 26, "training_loss": 451.44789123535156, "training_acc": 77.0, "val_loss": 189.70718383789062, "val_acc": 80.0}
