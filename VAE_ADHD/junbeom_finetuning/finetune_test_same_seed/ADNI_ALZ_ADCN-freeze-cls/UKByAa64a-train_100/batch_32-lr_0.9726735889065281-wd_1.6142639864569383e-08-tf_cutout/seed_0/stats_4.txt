"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2441.3218220472336, "training_acc": 72.0, "val_loss": 785.1589202880859, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2042.2195434570312, "training_acc": 46.0, "val_loss": 491.2661552429199, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1079.0854187011719, "training_acc": 73.0, "val_loss": 494.7077751159668, "val_acc": 36.0}
{"epoch": 3, "training_loss": 2105.3456115722656, "training_acc": 42.0, "val_loss": 429.42981719970703, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2067.5565490722656, "training_acc": 72.0, "val_loss": 533.293628692627, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1149.0615501403809, "training_acc": 74.0, "val_loss": 436.7757320404053, "val_acc": 32.0}
{"epoch": 6, "training_loss": 1799.0650253295898, "training_acc": 44.0, "val_loss": 227.04832553863525, "val_acc": 72.0}
{"epoch": 7, "training_loss": 467.64278411865234, "training_acc": 70.0, "val_loss": 354.665207862854, "val_acc": 32.0}
{"epoch": 8, "training_loss": 1388.1142196655273, "training_acc": 43.0, "val_loss": 260.2610111236572, "val_acc": 72.0}
{"epoch": 9, "training_loss": 891.3804640769958, "training_acc": 72.0, "val_loss": 91.88315868377686, "val_acc": 64.0}
{"epoch": 10, "training_loss": 474.09482288360596, "training_acc": 59.0, "val_loss": 130.39274215698242, "val_acc": 72.0}
{"epoch": 11, "training_loss": 297.71048748493195, "training_acc": 76.0, "val_loss": 76.3224184513092, "val_acc": 64.0}
{"epoch": 12, "training_loss": 297.21999740600586, "training_acc": 67.0, "val_loss": 40.81902205944061, "val_acc": 64.0}
{"epoch": 13, "training_loss": 199.09020900726318, "training_acc": 67.0, "val_loss": 58.44892859458923, "val_acc": 72.0}
{"epoch": 14, "training_loss": 150.84549045562744, "training_acc": 71.0, "val_loss": 93.41017007827759, "val_acc": 36.0}
{"epoch": 15, "training_loss": 176.25198578834534, "training_acc": 63.0, "val_loss": 25.62829852104187, "val_acc": 84.0}
{"epoch": 16, "training_loss": 80.78360891342163, "training_acc": 84.0, "val_loss": 60.44172644615173, "val_acc": 56.0}
{"epoch": 17, "training_loss": 211.73115956783295, "training_acc": 66.0, "val_loss": 162.0150923728943, "val_acc": 72.0}
{"epoch": 18, "training_loss": 425.2110011577606, "training_acc": 74.0, "val_loss": 434.8299026489258, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1280.6893730163574, "training_acc": 46.0, "val_loss": 377.6953458786011, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1525.7834777832031, "training_acc": 72.0, "val_loss": 162.697172164917, "val_acc": 72.0}
{"epoch": 21, "training_loss": 519.2224140167236, "training_acc": 61.0, "val_loss": 116.86491966247559, "val_acc": 72.0}
{"epoch": 22, "training_loss": 575.190616607666, "training_acc": 74.0, "val_loss": 168.3634638786316, "val_acc": 36.0}
{"epoch": 23, "training_loss": 1069.4849641919136, "training_acc": 45.0, "val_loss": 279.69462871551514, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1431.631492614746, "training_acc": 72.0, "val_loss": 199.11010265350342, "val_acc": 72.0}
{"epoch": 25, "training_loss": 913.1707458496094, "training_acc": 63.0, "val_loss": 127.46726274490356, "val_acc": 72.0}
{"epoch": 26, "training_loss": 874.0748825073242, "training_acc": 74.0, "val_loss": 538.8600826263428, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1421.5344505310059, "training_acc": 72.0, "val_loss": 142.23153591156006, "val_acc": 64.0}
{"epoch": 28, "training_loss": 692.4571895599365, "training_acc": 58.0, "val_loss": 133.5214614868164, "val_acc": 76.0}
{"epoch": 29, "training_loss": 249.0787457227707, "training_acc": 78.0, "val_loss": 62.09092140197754, "val_acc": 76.0}
{"epoch": 30, "training_loss": 98.25052380561829, "training_acc": 77.0, "val_loss": 29.928019642829895, "val_acc": 80.0}
{"epoch": 31, "training_loss": 116.46086597442627, "training_acc": 76.0, "val_loss": 68.96757483482361, "val_acc": 72.0}
{"epoch": 32, "training_loss": 240.59824514389038, "training_acc": 66.0, "val_loss": 40.1468425989151, "val_acc": 80.0}
{"epoch": 33, "training_loss": 98.81267929077148, "training_acc": 82.0, "val_loss": 172.81757593154907, "val_acc": 72.0}
{"epoch": 34, "training_loss": 593.1988301277161, "training_acc": 72.0, "val_loss": 163.01833391189575, "val_acc": 40.0}
