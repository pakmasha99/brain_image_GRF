"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2543.458393096924, "training_acc": 72.0, "val_loss": 737.5786781311035, "val_acc": 28.0}
{"epoch": 1, "training_loss": 2637.6828842163086, "training_acc": 33.0, "val_loss": 241.35091304779053, "val_acc": 72.0}
{"epoch": 2, "training_loss": 995.1886940002441, "training_acc": 74.0, "val_loss": 52.59971022605896, "val_acc": 80.0}
{"epoch": 3, "training_loss": 725.0082855224609, "training_acc": 69.0, "val_loss": 105.53754568099976, "val_acc": 72.0}
{"epoch": 4, "training_loss": 408.9657530784607, "training_acc": 71.0, "val_loss": 38.646045327186584, "val_acc": 72.0}
{"epoch": 5, "training_loss": 175.37624837935437, "training_acc": 74.0, "val_loss": 35.82260012626648, "val_acc": 56.0}
{"epoch": 6, "training_loss": 272.55060386657715, "training_acc": 57.0, "val_loss": 65.36306738853455, "val_acc": 68.0}
{"epoch": 7, "training_loss": 164.37946158228442, "training_acc": 70.0, "val_loss": 116.11895561218262, "val_acc": 72.0}
{"epoch": 8, "training_loss": 329.88914680480957, "training_acc": 73.0, "val_loss": 191.87623262405396, "val_acc": 36.0}
{"epoch": 9, "training_loss": 403.37390899658203, "training_acc": 69.0, "val_loss": 205.1234245300293, "val_acc": 72.0}
{"epoch": 10, "training_loss": 552.8938903808594, "training_acc": 73.0, "val_loss": 271.8034029006958, "val_acc": 28.0}
{"epoch": 11, "training_loss": 568.3706321716309, "training_acc": 57.0, "val_loss": 144.95941400527954, "val_acc": 72.0}
{"epoch": 12, "training_loss": 500.16601181030273, "training_acc": 58.0, "val_loss": 134.22030210494995, "val_acc": 72.0}
{"epoch": 13, "training_loss": 662.8360824584961, "training_acc": 72.0, "val_loss": 50.92356204986572, "val_acc": 60.0}
{"epoch": 14, "training_loss": 217.74391269683838, "training_acc": 66.0, "val_loss": 22.96973317861557, "val_acc": 68.0}
{"epoch": 15, "training_loss": 116.24595069885254, "training_acc": 70.0, "val_loss": 142.4155831336975, "val_acc": 40.0}
{"epoch": 16, "training_loss": 343.46106362342016, "training_acc": 59.0, "val_loss": 113.62909078598022, "val_acc": 72.0}
{"epoch": 17, "training_loss": 381.97874116897583, "training_acc": 57.0, "val_loss": 89.88606333732605, "val_acc": 72.0}
{"epoch": 18, "training_loss": 655.4769010543823, "training_acc": 74.0, "val_loss": 26.644527912139893, "val_acc": 80.0}
{"epoch": 19, "training_loss": 580.5193824768066, "training_acc": 53.0, "val_loss": 101.89342498779297, "val_acc": 72.0}
{"epoch": 20, "training_loss": 353.06669187545776, "training_acc": 72.0, "val_loss": 31.474193930625916, "val_acc": 80.0}
{"epoch": 21, "training_loss": 303.7771453857422, "training_acc": 76.0, "val_loss": 216.07720851898193, "val_acc": 36.0}
{"epoch": 22, "training_loss": 492.2517318725586, "training_acc": 54.0, "val_loss": 261.4187002182007, "val_acc": 72.0}
{"epoch": 23, "training_loss": 732.1071890294552, "training_acc": 73.0, "val_loss": 176.73048973083496, "val_acc": 44.0}
{"epoch": 24, "training_loss": 413.9291982650757, "training_acc": 61.0, "val_loss": 163.10410499572754, "val_acc": 72.0}
{"epoch": 25, "training_loss": 379.1506018638611, "training_acc": 70.0, "val_loss": 118.53749752044678, "val_acc": 56.0}
{"epoch": 26, "training_loss": 376.9692897796631, "training_acc": 68.0, "val_loss": 136.37659549713135, "val_acc": 72.0}
{"epoch": 27, "training_loss": 284.1920876502991, "training_acc": 67.0, "val_loss": 113.6293888092041, "val_acc": 72.0}
{"epoch": 28, "training_loss": 277.20414543151855, "training_acc": 74.0, "val_loss": 213.39693069458008, "val_acc": 48.0}
{"epoch": 29, "training_loss": 514.8374812602997, "training_acc": 57.0, "val_loss": 144.2071557044983, "val_acc": 72.0}
{"epoch": 30, "training_loss": 379.20123863220215, "training_acc": 69.0, "val_loss": 37.316641211509705, "val_acc": 80.0}
{"epoch": 31, "training_loss": 525.0122947692871, "training_acc": 74.0, "val_loss": 30.357447266578674, "val_acc": 80.0}
{"epoch": 32, "training_loss": 764.7207694649696, "training_acc": 54.0, "val_loss": 181.9984793663025, "val_acc": 72.0}
{"epoch": 33, "training_loss": 627.8605653047562, "training_acc": 73.0, "val_loss": 44.07980144023895, "val_acc": 68.0}
