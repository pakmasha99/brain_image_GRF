"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 234.96154594421387, "training_acc": 70.0, "val_loss": 19.554559886455536, "val_acc": 72.0}
{"epoch": 1, "training_loss": 176.86914443969727, "training_acc": 70.0, "val_loss": 21.41999751329422, "val_acc": 72.0}
{"epoch": 2, "training_loss": 319.43879890441895, "training_acc": 39.0, "val_loss": 45.21616995334625, "val_acc": 72.0}
{"epoch": 3, "training_loss": 227.4404468536377, "training_acc": 72.0, "val_loss": 86.11367344856262, "val_acc": 72.0}
{"epoch": 4, "training_loss": 195.47716856002808, "training_acc": 73.0, "val_loss": 42.96741783618927, "val_acc": 48.0}
{"epoch": 5, "training_loss": 198.21416133642197, "training_acc": 57.0, "val_loss": 43.19972097873688, "val_acc": 72.0}
{"epoch": 6, "training_loss": 188.6855936050415, "training_acc": 72.0, "val_loss": 47.723302245140076, "val_acc": 72.0}
{"epoch": 7, "training_loss": 131.16629314422607, "training_acc": 66.0, "val_loss": 27.7321994304657, "val_acc": 60.0}
{"epoch": 8, "training_loss": 96.03135108947754, "training_acc": 69.0, "val_loss": 31.447532773017883, "val_acc": 64.0}
{"epoch": 9, "training_loss": 60.391507267951965, "training_acc": 78.0, "val_loss": 25.917527079582214, "val_acc": 56.0}
{"epoch": 10, "training_loss": 105.82663390785456, "training_acc": 66.0, "val_loss": 38.79245221614838, "val_acc": 72.0}
{"epoch": 11, "training_loss": 78.55721020698547, "training_acc": 76.0, "val_loss": 28.653621673583984, "val_acc": 40.0}
{"epoch": 12, "training_loss": 90.99161911010742, "training_acc": 63.0, "val_loss": 25.782346725463867, "val_acc": 76.0}
{"epoch": 13, "training_loss": 78.45652675628662, "training_acc": 66.0, "val_loss": 28.84586751461029, "val_acc": 72.0}
{"epoch": 14, "training_loss": 145.31263232883066, "training_acc": 72.0, "val_loss": 38.372787833213806, "val_acc": 72.0}
{"epoch": 15, "training_loss": 88.50344562530518, "training_acc": 73.0, "val_loss": 17.052574455738068, "val_acc": 40.0}
{"epoch": 16, "training_loss": 80.37265968322754, "training_acc": 66.0, "val_loss": 20.235322415828705, "val_acc": 72.0}
{"epoch": 17, "training_loss": 54.55693769454956, "training_acc": 71.0, "val_loss": 13.794636726379395, "val_acc": 76.0}
{"epoch": 18, "training_loss": 49.509866416454315, "training_acc": 81.0, "val_loss": 28.048160672187805, "val_acc": 72.0}
{"epoch": 19, "training_loss": 71.86867225170135, "training_acc": 74.0, "val_loss": 17.206336557865143, "val_acc": 60.0}
{"epoch": 20, "training_loss": 61.71819305419922, "training_acc": 73.0, "val_loss": 24.900297820568085, "val_acc": 72.0}
{"epoch": 21, "training_loss": 47.249380350112915, "training_acc": 75.0, "val_loss": 22.605273127555847, "val_acc": 48.0}
{"epoch": 22, "training_loss": 66.66478395462036, "training_acc": 70.0, "val_loss": 21.203628182411194, "val_acc": 72.0}
{"epoch": 23, "training_loss": 49.116535663604736, "training_acc": 72.0, "val_loss": 13.136723637580872, "val_acc": 72.0}
{"epoch": 24, "training_loss": 56.278454065322876, "training_acc": 72.0, "val_loss": 12.533111870288849, "val_acc": 72.0}
{"epoch": 25, "training_loss": 44.911357402801514, "training_acc": 83.0, "val_loss": 14.07478153705597, "val_acc": 64.0}
{"epoch": 26, "training_loss": 45.1017746925354, "training_acc": 80.0, "val_loss": 14.183823764324188, "val_acc": 76.0}
{"epoch": 27, "training_loss": 42.55603790283203, "training_acc": 80.0, "val_loss": 19.791793823242188, "val_acc": 72.0}
{"epoch": 28, "training_loss": 74.37331366539001, "training_acc": 75.0, "val_loss": 19.470012187957764, "val_acc": 52.0}
{"epoch": 29, "training_loss": 81.20194959640503, "training_acc": 61.0, "val_loss": 24.088001251220703, "val_acc": 72.0}
{"epoch": 30, "training_loss": 47.90968179702759, "training_acc": 82.0, "val_loss": 15.424202382564545, "val_acc": 64.0}
{"epoch": 31, "training_loss": 73.59253662824631, "training_acc": 71.0, "val_loss": 16.035039722919464, "val_acc": 72.0}
{"epoch": 32, "training_loss": 52.95695185661316, "training_acc": 76.0, "val_loss": 25.46369433403015, "val_acc": 72.0}
{"epoch": 33, "training_loss": 88.49437183141708, "training_acc": 73.0, "val_loss": 13.094462454319, "val_acc": 76.0}
{"epoch": 34, "training_loss": 47.9477835893631, "training_acc": 76.0, "val_loss": 13.235016167163849, "val_acc": 76.0}
{"epoch": 35, "training_loss": 37.758555710315704, "training_acc": 84.0, "val_loss": 15.426161885261536, "val_acc": 72.0}
{"epoch": 36, "training_loss": 35.95078730583191, "training_acc": 83.0, "val_loss": 15.451402962207794, "val_acc": 64.0}
{"epoch": 37, "training_loss": 39.40007442235947, "training_acc": 85.0, "val_loss": 20.86310088634491, "val_acc": 72.0}
{"epoch": 38, "training_loss": 42.700464367866516, "training_acc": 83.0, "val_loss": 13.988207280635834, "val_acc": 64.0}
{"epoch": 39, "training_loss": 64.42519572377205, "training_acc": 80.0, "val_loss": 14.77588415145874, "val_acc": 60.0}
{"epoch": 40, "training_loss": 38.796738624572754, "training_acc": 83.0, "val_loss": 15.082667768001556, "val_acc": 68.0}
{"epoch": 41, "training_loss": 38.165027141571045, "training_acc": 84.0, "val_loss": 22.083207964897156, "val_acc": 72.0}
{"epoch": 42, "training_loss": 45.679602921009064, "training_acc": 84.0, "val_loss": 21.97709232568741, "val_acc": 44.0}
{"epoch": 43, "training_loss": 63.728790521621704, "training_acc": 68.0, "val_loss": 18.956518173217773, "val_acc": 72.0}
