"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 191.74033164978027, "training_acc": 72.0, "val_loss": 66.16759896278381, "val_acc": 72.0}
{"epoch": 1, "training_loss": 183.76443815231323, "training_acc": 72.0, "val_loss": 95.36771178245544, "val_acc": 28.0}
{"epoch": 2, "training_loss": 386.2365083694458, "training_acc": 28.0, "val_loss": 14.630945026874542, "val_acc": 52.0}
{"epoch": 3, "training_loss": 104.96712923049927, "training_acc": 57.0, "val_loss": 58.25321674346924, "val_acc": 72.0}
{"epoch": 4, "training_loss": 253.6286678314209, "training_acc": 72.0, "val_loss": 67.37558841705322, "val_acc": 72.0}
{"epoch": 5, "training_loss": 263.92918157577515, "training_acc": 72.0, "val_loss": 36.351484060287476, "val_acc": 72.0}
{"epoch": 6, "training_loss": 119.75620317459106, "training_acc": 73.0, "val_loss": 15.421201288700104, "val_acc": 64.0}
{"epoch": 7, "training_loss": 159.5854196548462, "training_acc": 52.0, "val_loss": 22.663596272468567, "val_acc": 52.0}
{"epoch": 8, "training_loss": 149.4396641254425, "training_acc": 54.0, "val_loss": 17.02483296394348, "val_acc": 72.0}
{"epoch": 9, "training_loss": 89.18937301635742, "training_acc": 71.0, "val_loss": 31.747275590896606, "val_acc": 72.0}
{"epoch": 10, "training_loss": 122.9298620223999, "training_acc": 72.0, "val_loss": 19.712768495082855, "val_acc": 72.0}
{"epoch": 11, "training_loss": 73.0664484500885, "training_acc": 74.0, "val_loss": 15.659242868423462, "val_acc": 56.0}
{"epoch": 12, "training_loss": 85.12295651435852, "training_acc": 59.0, "val_loss": 12.936225533485413, "val_acc": 68.0}
{"epoch": 13, "training_loss": 53.589874029159546, "training_acc": 77.0, "val_loss": 22.511611878871918, "val_acc": 72.0}
{"epoch": 14, "training_loss": 88.2407078742981, "training_acc": 72.0, "val_loss": 19.894123077392578, "val_acc": 72.0}
{"epoch": 15, "training_loss": 61.672173261642456, "training_acc": 73.0, "val_loss": 19.397282600402832, "val_acc": 48.0}
{"epoch": 16, "training_loss": 76.91086220741272, "training_acc": 49.0, "val_loss": 14.200280606746674, "val_acc": 60.0}
{"epoch": 17, "training_loss": 50.864230036735535, "training_acc": 78.0, "val_loss": 19.36516910791397, "val_acc": 72.0}
{"epoch": 18, "training_loss": 71.15348362922668, "training_acc": 72.0, "val_loss": 13.887111842632294, "val_acc": 72.0}
{"epoch": 19, "training_loss": 58.650349378585815, "training_acc": 68.0, "val_loss": 15.842470526695251, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.517813205718994, "training_acc": 69.0, "val_loss": 14.039455354213715, "val_acc": 72.0}
{"epoch": 21, "training_loss": 63.61683630943298, "training_acc": 72.0, "val_loss": 15.772520005702972, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.21240544319153, "training_acc": 72.0, "val_loss": 13.204021751880646, "val_acc": 60.0}
{"epoch": 23, "training_loss": 56.78694987297058, "training_acc": 73.0, "val_loss": 11.675559729337692, "val_acc": 76.0}
{"epoch": 24, "training_loss": 49.792184948921204, "training_acc": 74.0, "val_loss": 14.906342327594757, "val_acc": 72.0}
{"epoch": 25, "training_loss": 54.49590849876404, "training_acc": 76.0, "val_loss": 12.091725319623947, "val_acc": 80.0}
{"epoch": 26, "training_loss": 46.78009057044983, "training_acc": 79.0, "val_loss": 13.112840056419373, "val_acc": 64.0}
{"epoch": 27, "training_loss": 52.02095568180084, "training_acc": 77.0, "val_loss": 12.615293264389038, "val_acc": 80.0}
{"epoch": 28, "training_loss": 47.591625809669495, "training_acc": 78.0, "val_loss": 13.541772961616516, "val_acc": 72.0}
{"epoch": 29, "training_loss": 48.728859186172485, "training_acc": 75.0, "val_loss": 12.638610601425171, "val_acc": 68.0}
{"epoch": 30, "training_loss": 47.13061964511871, "training_acc": 77.0, "val_loss": 12.663888931274414, "val_acc": 72.0}
{"epoch": 31, "training_loss": 48.78036856651306, "training_acc": 75.0, "val_loss": 13.661284744739532, "val_acc": 72.0}
{"epoch": 32, "training_loss": 46.521050572395325, "training_acc": 77.0, "val_loss": 13.424845039844513, "val_acc": 64.0}
{"epoch": 33, "training_loss": 49.82045018672943, "training_acc": 80.0, "val_loss": 12.817749381065369, "val_acc": 76.0}
{"epoch": 34, "training_loss": 49.67238926887512, "training_acc": 75.0, "val_loss": 14.373628795146942, "val_acc": 72.0}
{"epoch": 35, "training_loss": 47.689720153808594, "training_acc": 76.0, "val_loss": 13.176265358924866, "val_acc": 64.0}
{"epoch": 36, "training_loss": 48.70422375202179, "training_acc": 78.0, "val_loss": 12.030422687530518, "val_acc": 72.0}
{"epoch": 37, "training_loss": 48.00500178337097, "training_acc": 77.0, "val_loss": 13.59592080116272, "val_acc": 72.0}
{"epoch": 38, "training_loss": 44.941824197769165, "training_acc": 75.0, "val_loss": 12.729868292808533, "val_acc": 64.0}
{"epoch": 39, "training_loss": 50.029130816459656, "training_acc": 77.0, "val_loss": 11.68343871831894, "val_acc": 80.0}
{"epoch": 40, "training_loss": 48.96387839317322, "training_acc": 76.0, "val_loss": 12.80098706483841, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.279889822006226, "training_acc": 78.0, "val_loss": 12.36993595957756, "val_acc": 64.0}
{"epoch": 42, "training_loss": 48.15826678276062, "training_acc": 77.0, "val_loss": 12.170843034982681, "val_acc": 84.0}
