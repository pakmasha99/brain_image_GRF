"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 669.3972206115723, "training_acc": 72.0, "val_loss": 191.29706621170044, "val_acc": 28.0}
{"epoch": 1, "training_loss": 685.6421337127686, "training_acc": 33.0, "val_loss": 65.24397134780884, "val_acc": 72.0}
{"epoch": 2, "training_loss": 265.0868339538574, "training_acc": 74.0, "val_loss": 15.299832820892334, "val_acc": 80.0}
{"epoch": 3, "training_loss": 181.70871925354004, "training_acc": 70.0, "val_loss": 22.323445975780487, "val_acc": 80.0}
{"epoch": 4, "training_loss": 105.49433374404907, "training_acc": 71.0, "val_loss": 12.527522444725037, "val_acc": 72.0}
{"epoch": 5, "training_loss": 54.72232177853584, "training_acc": 77.0, "val_loss": 23.34948629140854, "val_acc": 72.0}
{"epoch": 6, "training_loss": 105.68168592453003, "training_acc": 59.0, "val_loss": 18.91638934612274, "val_acc": 68.0}
{"epoch": 7, "training_loss": 76.7667384147644, "training_acc": 64.0, "val_loss": 18.09864640235901, "val_acc": 72.0}
{"epoch": 8, "training_loss": 97.64623928070068, "training_acc": 73.0, "val_loss": 28.40868830680847, "val_acc": 52.0}
{"epoch": 9, "training_loss": 99.12794642522931, "training_acc": 63.0, "val_loss": 49.184057116508484, "val_acc": 72.0}
{"epoch": 10, "training_loss": 147.4405345916748, "training_acc": 73.0, "val_loss": 61.53467297554016, "val_acc": 28.0}
{"epoch": 11, "training_loss": 129.6884732246399, "training_acc": 61.0, "val_loss": 28.256481885910034, "val_acc": 72.0}
{"epoch": 12, "training_loss": 121.87135982513428, "training_acc": 56.0, "val_loss": 44.65644061565399, "val_acc": 72.0}
{"epoch": 13, "training_loss": 164.00734567642212, "training_acc": 71.0, "val_loss": 13.375495374202728, "val_acc": 76.0}
{"epoch": 14, "training_loss": 68.62494421005249, "training_acc": 68.0, "val_loss": 22.80728816986084, "val_acc": 44.0}
{"epoch": 15, "training_loss": 85.80356025695801, "training_acc": 64.0, "val_loss": 30.238237977027893, "val_acc": 48.0}
{"epoch": 16, "training_loss": 93.37352083623409, "training_acc": 57.0, "val_loss": 42.688074707984924, "val_acc": 72.0}
{"epoch": 17, "training_loss": 123.8190279006958, "training_acc": 73.0, "val_loss": 11.702515184879303, "val_acc": 80.0}
{"epoch": 18, "training_loss": 78.92419892549515, "training_acc": 77.0, "val_loss": 11.86668574810028, "val_acc": 76.0}
{"epoch": 19, "training_loss": 57.59831368923187, "training_acc": 70.0, "val_loss": 13.54067176580429, "val_acc": 76.0}
{"epoch": 20, "training_loss": 52.159703731536865, "training_acc": 70.0, "val_loss": 25.832796096801758, "val_acc": 72.0}
{"epoch": 21, "training_loss": 61.3785195350647, "training_acc": 77.0, "val_loss": 13.642841577529907, "val_acc": 72.0}
{"epoch": 22, "training_loss": 48.713966369628906, "training_acc": 80.0, "val_loss": 11.692260205745697, "val_acc": 76.0}
{"epoch": 23, "training_loss": 50.27140295505524, "training_acc": 79.0, "val_loss": 13.054317235946655, "val_acc": 76.0}
{"epoch": 24, "training_loss": 53.24049115180969, "training_acc": 75.0, "val_loss": 20.191466808319092, "val_acc": 72.0}
{"epoch": 25, "training_loss": 61.35106062889099, "training_acc": 72.0, "val_loss": 26.32755935192108, "val_acc": 72.0}
{"epoch": 26, "training_loss": 68.4779725074768, "training_acc": 71.0, "val_loss": 22.027932107448578, "val_acc": 72.0}
{"epoch": 27, "training_loss": 57.39390301704407, "training_acc": 74.0, "val_loss": 16.618476808071136, "val_acc": 72.0}
{"epoch": 28, "training_loss": 42.74667000770569, "training_acc": 77.0, "val_loss": 10.297361016273499, "val_acc": 80.0}
{"epoch": 29, "training_loss": 40.64460200071335, "training_acc": 80.0, "val_loss": 10.483667254447937, "val_acc": 84.0}
{"epoch": 30, "training_loss": 38.82296657562256, "training_acc": 84.0, "val_loss": 21.693404018878937, "val_acc": 72.0}
{"epoch": 31, "training_loss": 40.989022850990295, "training_acc": 78.0, "val_loss": 50.683605670928955, "val_acc": 32.0}
{"epoch": 32, "training_loss": 119.25984716415405, "training_acc": 66.0, "val_loss": 54.23104763031006, "val_acc": 72.0}
{"epoch": 33, "training_loss": 168.82186794281006, "training_acc": 54.0, "val_loss": 55.121684074401855, "val_acc": 72.0}
{"epoch": 34, "training_loss": 379.43243980407715, "training_acc": 72.0, "val_loss": 81.38526678085327, "val_acc": 72.0}
{"epoch": 35, "training_loss": 208.05939483642578, "training_acc": 58.0, "val_loss": 13.282451033592224, "val_acc": 76.0}
{"epoch": 36, "training_loss": 179.00177383422852, "training_acc": 76.0, "val_loss": 82.6555609703064, "val_acc": 72.0}
{"epoch": 37, "training_loss": 147.45806503295898, "training_acc": 73.0, "val_loss": 20.57940363883972, "val_acc": 68.0}
{"epoch": 38, "training_loss": 182.36943435668945, "training_acc": 66.0, "val_loss": 38.394057750701904, "val_acc": 72.0}
{"epoch": 39, "training_loss": 110.31547594070435, "training_acc": 75.0, "val_loss": 13.996440172195435, "val_acc": 76.0}
{"epoch": 40, "training_loss": 127.21746063232422, "training_acc": 72.0, "val_loss": 13.095782697200775, "val_acc": 72.0}
{"epoch": 41, "training_loss": 68.49915194511414, "training_acc": 65.0, "val_loss": 41.38665795326233, "val_acc": 72.0}
{"epoch": 42, "training_loss": 91.71615219116211, "training_acc": 71.0, "val_loss": 34.24797058105469, "val_acc": 72.0}
{"epoch": 43, "training_loss": 126.55949974060059, "training_acc": 72.0, "val_loss": 46.937495470047, "val_acc": 40.0}
{"epoch": 44, "training_loss": 99.19022989273071, "training_acc": 66.0, "val_loss": 17.722678184509277, "val_acc": 76.0}
{"epoch": 45, "training_loss": 47.13911318778992, "training_acc": 81.0, "val_loss": 30.01975417137146, "val_acc": 72.0}
{"epoch": 46, "training_loss": 88.99921131134033, "training_acc": 77.0, "val_loss": 10.278397053480148, "val_acc": 84.0}
{"epoch": 47, "training_loss": 64.83038830757141, "training_acc": 78.0, "val_loss": 20.493602752685547, "val_acc": 52.0}
{"epoch": 48, "training_loss": 43.09539079666138, "training_acc": 81.0, "val_loss": 12.520153820514679, "val_acc": 76.0}
{"epoch": 49, "training_loss": 43.22879460453987, "training_acc": 75.0, "val_loss": 47.21742272377014, "val_acc": 72.0}
{"epoch": 50, "training_loss": 119.63656711578369, "training_acc": 72.0, "val_loss": 15.295164287090302, "val_acc": 56.0}
{"epoch": 51, "training_loss": 65.74102472513914, "training_acc": 75.0, "val_loss": 13.025788962841034, "val_acc": 80.0}
{"epoch": 52, "training_loss": 42.10457193851471, "training_acc": 83.0, "val_loss": 10.679075121879578, "val_acc": 88.0}
{"epoch": 53, "training_loss": 38.38413417339325, "training_acc": 83.0, "val_loss": 18.795199692249298, "val_acc": 72.0}
{"epoch": 54, "training_loss": 57.09469509124756, "training_acc": 76.0, "val_loss": 14.915461838245392, "val_acc": 76.0}
{"epoch": 55, "training_loss": 56.47135949134827, "training_acc": 78.0, "val_loss": 12.63391375541687, "val_acc": 60.0}
{"epoch": 56, "training_loss": 40.972083437256515, "training_acc": 83.0, "val_loss": 37.47594356536865, "val_acc": 72.0}
{"epoch": 57, "training_loss": 87.81253337860107, "training_acc": 74.0, "val_loss": 38.922712206840515, "val_acc": 44.0}
{"epoch": 58, "training_loss": 118.67872667312622, "training_acc": 63.0, "val_loss": 26.838418841362, "val_acc": 52.0}
{"epoch": 59, "training_loss": 121.15871691703796, "training_acc": 62.0, "val_loss": 52.83181667327881, "val_acc": 72.0}
{"epoch": 60, "training_loss": 117.5702133178711, "training_acc": 72.0, "val_loss": 25.999653339385986, "val_acc": 56.0}
{"epoch": 61, "training_loss": 65.50115184672177, "training_acc": 76.0, "val_loss": 41.28390550613403, "val_acc": 72.0}
{"epoch": 62, "training_loss": 90.31112992763519, "training_acc": 79.0, "val_loss": 38.49574625492096, "val_acc": 48.0}
{"epoch": 63, "training_loss": 134.86243343353271, "training_acc": 68.0, "val_loss": 24.381224811077118, "val_acc": 72.0}
{"epoch": 64, "training_loss": 64.9823169708252, "training_acc": 71.0, "val_loss": 39.68016803264618, "val_acc": 72.0}
{"epoch": 65, "training_loss": 118.02251672744751, "training_acc": 73.0, "val_loss": 66.30842685699463, "val_acc": 44.0}
