"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 700.0186367034912, "training_acc": 72.0, "val_loss": 113.29258680343628, "val_acc": 28.0}
{"epoch": 1, "training_loss": 318.6586084365845, "training_acc": 48.0, "val_loss": 140.70606231689453, "val_acc": 72.0}
{"epoch": 2, "training_loss": 450.68052673339844, "training_acc": 72.0, "val_loss": 74.53140020370483, "val_acc": 32.0}
{"epoch": 3, "training_loss": 263.8799591064453, "training_acc": 41.0, "val_loss": 86.05970740318298, "val_acc": 72.0}
{"epoch": 4, "training_loss": 303.0718119889498, "training_acc": 72.0, "val_loss": 20.224422216415405, "val_acc": 56.0}
{"epoch": 5, "training_loss": 93.04432797431946, "training_acc": 61.0, "val_loss": 59.089893102645874, "val_acc": 72.0}
{"epoch": 6, "training_loss": 191.3117799758911, "training_acc": 72.0, "val_loss": 60.70637106895447, "val_acc": 28.0}
{"epoch": 7, "training_loss": 189.3517894744873, "training_acc": 50.0, "val_loss": 47.820499539375305, "val_acc": 72.0}
{"epoch": 8, "training_loss": 127.0908260345459, "training_acc": 71.0, "val_loss": 17.82912015914917, "val_acc": 52.0}
{"epoch": 9, "training_loss": 86.70413875579834, "training_acc": 71.0, "val_loss": 14.326520264148712, "val_acc": 68.0}
{"epoch": 10, "training_loss": 63.39996951818466, "training_acc": 73.0, "val_loss": 15.50755649805069, "val_acc": 76.0}
{"epoch": 11, "training_loss": 58.93729901313782, "training_acc": 71.0, "val_loss": 42.199766635894775, "val_acc": 72.0}
{"epoch": 12, "training_loss": 156.75584840774536, "training_acc": 70.0, "val_loss": 21.846652030944824, "val_acc": 40.0}
{"epoch": 13, "training_loss": 50.15235662460327, "training_acc": 75.0, "val_loss": 15.273533761501312, "val_acc": 72.0}
{"epoch": 14, "training_loss": 46.225632414221764, "training_acc": 78.0, "val_loss": 28.20540964603424, "val_acc": 76.0}
{"epoch": 15, "training_loss": 77.5446400642395, "training_acc": 73.0, "val_loss": 48.239171504974365, "val_acc": 36.0}
{"epoch": 16, "training_loss": 118.37323833350092, "training_acc": 63.0, "val_loss": 43.10697019100189, "val_acc": 72.0}
{"epoch": 17, "training_loss": 80.4398684501648, "training_acc": 73.0, "val_loss": 18.60535740852356, "val_acc": 76.0}
{"epoch": 18, "training_loss": 103.18437534570694, "training_acc": 78.0, "val_loss": 16.73029512166977, "val_acc": 56.0}
{"epoch": 19, "training_loss": 49.58260715007782, "training_acc": 75.0, "val_loss": 32.32678174972534, "val_acc": 76.0}
{"epoch": 20, "training_loss": 85.37442541122437, "training_acc": 69.0, "val_loss": 15.783534944057465, "val_acc": 64.0}
{"epoch": 21, "training_loss": 50.08990189433098, "training_acc": 80.0, "val_loss": 15.937787294387817, "val_acc": 76.0}
{"epoch": 22, "training_loss": 45.01487946510315, "training_acc": 77.0, "val_loss": 27.760764956474304, "val_acc": 44.0}
{"epoch": 23, "training_loss": 66.66487956047058, "training_acc": 66.0, "val_loss": 14.320001006126404, "val_acc": 68.0}
{"epoch": 24, "training_loss": 44.221484899520874, "training_acc": 80.0, "val_loss": 29.587724804878235, "val_acc": 76.0}
{"epoch": 25, "training_loss": 66.25052809715271, "training_acc": 73.0, "val_loss": 16.109225153923035, "val_acc": 60.0}
{"epoch": 26, "training_loss": 78.67259740829468, "training_acc": 75.0, "val_loss": 14.40727561712265, "val_acc": 60.0}
{"epoch": 27, "training_loss": 44.574384927749634, "training_acc": 79.0, "val_loss": 23.931728303432465, "val_acc": 76.0}
{"epoch": 28, "training_loss": 58.91477394104004, "training_acc": 74.0, "val_loss": 15.279389917850494, "val_acc": 60.0}
{"epoch": 29, "training_loss": 55.92904090881348, "training_acc": 76.0, "val_loss": 30.794185400009155, "val_acc": 72.0}
{"epoch": 30, "training_loss": 85.28250551223755, "training_acc": 73.0, "val_loss": 38.717448711395264, "val_acc": 32.0}
{"epoch": 31, "training_loss": 76.11481809616089, "training_acc": 70.0, "val_loss": 19.45667266845703, "val_acc": 72.0}
{"epoch": 32, "training_loss": 71.47690488398075, "training_acc": 67.0, "val_loss": 47.725507616996765, "val_acc": 72.0}
{"epoch": 33, "training_loss": 126.4582370519638, "training_acc": 75.0, "val_loss": 59.33471322059631, "val_acc": 44.0}
{"epoch": 34, "training_loss": 135.03695106506348, "training_acc": 60.0, "val_loss": 26.94437801837921, "val_acc": 64.0}
{"epoch": 35, "training_loss": 159.81404411792755, "training_acc": 63.0, "val_loss": 44.018614292144775, "val_acc": 76.0}
{"epoch": 36, "training_loss": 148.55312776565552, "training_acc": 70.0, "val_loss": 18.66704672574997, "val_acc": 64.0}
{"epoch": 37, "training_loss": 55.49505007266998, "training_acc": 79.0, "val_loss": 18.527908623218536, "val_acc": 60.0}
{"epoch": 38, "training_loss": 54.52916717529297, "training_acc": 76.0, "val_loss": 48.31765294075012, "val_acc": 44.0}
{"epoch": 39, "training_loss": 106.6418762342073, "training_acc": 58.0, "val_loss": 58.74694585800171, "val_acc": 72.0}
{"epoch": 40, "training_loss": 117.01454067230225, "training_acc": 76.0, "val_loss": 39.69774544239044, "val_acc": 40.0}
{"epoch": 41, "training_loss": 109.91955137252808, "training_acc": 66.0, "val_loss": 24.956659972667694, "val_acc": 76.0}
{"epoch": 42, "training_loss": 84.23261046409607, "training_acc": 66.0, "val_loss": 28.57927680015564, "val_acc": 76.0}
