"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 163.75857543945312, "training_acc": 46.0, "val_loss": 80.30471801757812, "val_acc": 72.0}
{"epoch": 1, "training_loss": 270.4721918106079, "training_acc": 72.0, "val_loss": 47.328147292137146, "val_acc": 28.0}
{"epoch": 2, "training_loss": 217.5009765625, "training_acc": 28.0, "val_loss": 18.790118396282196, "val_acc": 72.0}
{"epoch": 3, "training_loss": 71.11921048164368, "training_acc": 75.0, "val_loss": 47.54154980182648, "val_acc": 72.0}
{"epoch": 4, "training_loss": 160.78415536880493, "training_acc": 72.0, "val_loss": 32.30862319469452, "val_acc": 72.0}
{"epoch": 5, "training_loss": 78.72590398788452, "training_acc": 72.0, "val_loss": 26.255837082862854, "val_acc": 48.0}
{"epoch": 6, "training_loss": 150.34907722473145, "training_acc": 51.0, "val_loss": 21.495719254016876, "val_acc": 60.0}
{"epoch": 7, "training_loss": 90.12851619720459, "training_acc": 68.0, "val_loss": 34.75219011306763, "val_acc": 72.0}
{"epoch": 8, "training_loss": 109.29395008087158, "training_acc": 74.0, "val_loss": 38.07171583175659, "val_acc": 72.0}
{"epoch": 9, "training_loss": 101.2316632270813, "training_acc": 74.0, "val_loss": 19.07176524400711, "val_acc": 68.0}
{"epoch": 10, "training_loss": 89.48662042617798, "training_acc": 67.0, "val_loss": 20.34257799386978, "val_acc": 56.0}
{"epoch": 11, "training_loss": 84.7649405002594, "training_acc": 58.0, "val_loss": 24.42590594291687, "val_acc": 72.0}
{"epoch": 12, "training_loss": 87.24254894256592, "training_acc": 72.0, "val_loss": 29.65640425682068, "val_acc": 72.0}
{"epoch": 13, "training_loss": 87.62704467773438, "training_acc": 72.0, "val_loss": 14.528405666351318, "val_acc": 64.0}
{"epoch": 14, "training_loss": 72.8306245803833, "training_acc": 62.0, "val_loss": 17.175234854221344, "val_acc": 36.0}
{"epoch": 15, "training_loss": 63.743107080459595, "training_acc": 62.0, "val_loss": 20.996254682540894, "val_acc": 72.0}
{"epoch": 16, "training_loss": 78.17530369758606, "training_acc": 72.0, "val_loss": 16.477878391742706, "val_acc": 72.0}
{"epoch": 17, "training_loss": 48.34149241447449, "training_acc": 75.0, "val_loss": 20.8536297082901, "val_acc": 28.0}
{"epoch": 18, "training_loss": 80.86915993690491, "training_acc": 43.0, "val_loss": 13.141465187072754, "val_acc": 72.0}
{"epoch": 19, "training_loss": 50.10977005958557, "training_acc": 77.0, "val_loss": 23.284873366355896, "val_acc": 72.0}
{"epoch": 20, "training_loss": 80.03585433959961, "training_acc": 72.0, "val_loss": 15.321631729602814, "val_acc": 72.0}
{"epoch": 21, "training_loss": 51.350114822387695, "training_acc": 75.0, "val_loss": 16.7778417468071, "val_acc": 60.0}
{"epoch": 22, "training_loss": 65.25302815437317, "training_acc": 63.0, "val_loss": 15.363563597202301, "val_acc": 76.0}
{"epoch": 23, "training_loss": 57.95464634895325, "training_acc": 74.0, "val_loss": 22.298339009284973, "val_acc": 72.0}
{"epoch": 24, "training_loss": 65.60844659805298, "training_acc": 73.0, "val_loss": 13.799861073493958, "val_acc": 64.0}
{"epoch": 25, "training_loss": 58.29619312286377, "training_acc": 71.0, "val_loss": 14.558839797973633, "val_acc": 64.0}
{"epoch": 26, "training_loss": 59.50545024871826, "training_acc": 67.0, "val_loss": 16.029536724090576, "val_acc": 76.0}
{"epoch": 27, "training_loss": 51.663360834121704, "training_acc": 78.0, "val_loss": 13.063433766365051, "val_acc": 76.0}
{"epoch": 28, "training_loss": 41.483394265174866, "training_acc": 79.0, "val_loss": 13.980449736118317, "val_acc": 60.0}
{"epoch": 29, "training_loss": 53.02566838264465, "training_acc": 74.0, "val_loss": 13.031601905822754, "val_acc": 76.0}
{"epoch": 30, "training_loss": 52.177504539489746, "training_acc": 76.0, "val_loss": 14.557120203971863, "val_acc": 76.0}
{"epoch": 31, "training_loss": 46.44680559635162, "training_acc": 77.0, "val_loss": 14.427204430103302, "val_acc": 52.0}
{"epoch": 32, "training_loss": 57.427868127822876, "training_acc": 65.0, "val_loss": 12.30653002858162, "val_acc": 76.0}
{"epoch": 33, "training_loss": 47.55963110923767, "training_acc": 74.0, "val_loss": 16.00409895181656, "val_acc": 72.0}
{"epoch": 34, "training_loss": 51.045870304107666, "training_acc": 73.0, "val_loss": 12.39297240972519, "val_acc": 76.0}
{"epoch": 35, "training_loss": 44.688271045684814, "training_acc": 80.0, "val_loss": 12.335597723722458, "val_acc": 76.0}
{"epoch": 36, "training_loss": 45.89431548118591, "training_acc": 78.0, "val_loss": 15.245437622070312, "val_acc": 76.0}
{"epoch": 37, "training_loss": 48.23309683799744, "training_acc": 77.0, "val_loss": 12.28741779923439, "val_acc": 76.0}
{"epoch": 38, "training_loss": 44.706852197647095, "training_acc": 82.0, "val_loss": 12.306565046310425, "val_acc": 80.0}
{"epoch": 39, "training_loss": 44.375712871551514, "training_acc": 83.0, "val_loss": 13.60636055469513, "val_acc": 80.0}
{"epoch": 40, "training_loss": 42.86656033992767, "training_acc": 80.0, "val_loss": 12.218138575553894, "val_acc": 76.0}
{"epoch": 41, "training_loss": 43.789363622665405, "training_acc": 77.0, "val_loss": 12.457992136478424, "val_acc": 76.0}
{"epoch": 42, "training_loss": 41.39356482028961, "training_acc": 78.0, "val_loss": 12.28272020816803, "val_acc": 80.0}
{"epoch": 43, "training_loss": 41.48808455467224, "training_acc": 81.0, "val_loss": 12.004274129867554, "val_acc": 80.0}
{"epoch": 44, "training_loss": 41.72775602340698, "training_acc": 85.0, "val_loss": 12.057844549417496, "val_acc": 80.0}
{"epoch": 45, "training_loss": 40.18012583255768, "training_acc": 80.0, "val_loss": 12.349545955657959, "val_acc": 80.0}
{"epoch": 46, "training_loss": 41.783642411231995, "training_acc": 80.0, "val_loss": 11.931382864713669, "val_acc": 84.0}
{"epoch": 47, "training_loss": 40.15077018737793, "training_acc": 83.0, "val_loss": 12.16280683875084, "val_acc": 80.0}
{"epoch": 48, "training_loss": 39.900230288505554, "training_acc": 78.0, "val_loss": 12.24222257733345, "val_acc": 80.0}
{"epoch": 49, "training_loss": 40.70555222034454, "training_acc": 82.0, "val_loss": 12.414642423391342, "val_acc": 80.0}
{"epoch": 50, "training_loss": 37.23149657249451, "training_acc": 82.0, "val_loss": 13.887691497802734, "val_acc": 80.0}
{"epoch": 51, "training_loss": 42.77197253704071, "training_acc": 79.0, "val_loss": 13.242016732692719, "val_acc": 80.0}
{"epoch": 52, "training_loss": 42.2124400138855, "training_acc": 81.0, "val_loss": 12.317733466625214, "val_acc": 80.0}
{"epoch": 53, "training_loss": 39.60228419303894, "training_acc": 83.0, "val_loss": 13.264063000679016, "val_acc": 80.0}
{"epoch": 54, "training_loss": 39.916778564453125, "training_acc": 79.0, "val_loss": 12.190612405538559, "val_acc": 80.0}
{"epoch": 55, "training_loss": 39.35235571861267, "training_acc": 83.0, "val_loss": 12.034736573696136, "val_acc": 80.0}
{"epoch": 56, "training_loss": 40.094587087631226, "training_acc": 82.0, "val_loss": 12.032489478588104, "val_acc": 88.0}
{"epoch": 57, "training_loss": 38.73388731479645, "training_acc": 85.0, "val_loss": 12.311943620443344, "val_acc": 84.0}
{"epoch": 58, "training_loss": 37.203062534332275, "training_acc": 86.0, "val_loss": 12.074293196201324, "val_acc": 84.0}
{"epoch": 59, "training_loss": 38.76069664955139, "training_acc": 85.0, "val_loss": 12.074102461338043, "val_acc": 84.0}
{"epoch": 60, "training_loss": 36.508118748664856, "training_acc": 85.0, "val_loss": 12.901420891284943, "val_acc": 80.0}
{"epoch": 61, "training_loss": 36.396469712257385, "training_acc": 84.0, "val_loss": 12.2237429022789, "val_acc": 84.0}
{"epoch": 62, "training_loss": 37.87815821170807, "training_acc": 82.0, "val_loss": 12.120463699102402, "val_acc": 80.0}
{"epoch": 63, "training_loss": 38.79087173938751, "training_acc": 83.0, "val_loss": 12.528380751609802, "val_acc": 84.0}
{"epoch": 64, "training_loss": 36.71091830730438, "training_acc": 82.0, "val_loss": 12.373212724924088, "val_acc": 80.0}
{"epoch": 65, "training_loss": 37.13691604137421, "training_acc": 83.0, "val_loss": 12.029772251844406, "val_acc": 84.0}
