"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 199.2669448852539, "training_acc": 72.0, "val_loss": 69.49560642242432, "val_acc": 72.0}
{"epoch": 1, "training_loss": 192.53252530097961, "training_acc": 72.0, "val_loss": 101.02992057800293, "val_acc": 28.0}
{"epoch": 2, "training_loss": 410.50940895080566, "training_acc": 28.0, "val_loss": 15.402694046497345, "val_acc": 44.0}
{"epoch": 3, "training_loss": 110.37333297729492, "training_acc": 58.0, "val_loss": 61.267173290252686, "val_acc": 72.0}
{"epoch": 4, "training_loss": 267.60160636901855, "training_acc": 72.0, "val_loss": 71.90535068511963, "val_acc": 72.0}
{"epoch": 5, "training_loss": 282.21912240982056, "training_acc": 72.0, "val_loss": 40.31831622123718, "val_acc": 72.0}
{"epoch": 6, "training_loss": 131.93088114261627, "training_acc": 75.0, "val_loss": 14.439156651496887, "val_acc": 68.0}
{"epoch": 7, "training_loss": 162.56912517547607, "training_acc": 53.0, "val_loss": 25.21766722202301, "val_acc": 44.0}
{"epoch": 8, "training_loss": 162.14797949790955, "training_acc": 54.0, "val_loss": 15.9785196185112, "val_acc": 72.0}
{"epoch": 9, "training_loss": 89.86356472969055, "training_acc": 71.0, "val_loss": 32.98146724700928, "val_acc": 72.0}
{"epoch": 10, "training_loss": 128.82037734985352, "training_acc": 72.0, "val_loss": 21.583406627178192, "val_acc": 72.0}
{"epoch": 11, "training_loss": 77.45629811286926, "training_acc": 74.0, "val_loss": 15.259015560150146, "val_acc": 56.0}
{"epoch": 12, "training_loss": 86.77480173110962, "training_acc": 59.0, "val_loss": 13.33075612783432, "val_acc": 68.0}
{"epoch": 13, "training_loss": 55.709681272506714, "training_acc": 74.0, "val_loss": 23.011910915374756, "val_acc": 72.0}
{"epoch": 14, "training_loss": 90.85637187957764, "training_acc": 72.0, "val_loss": 20.923659205436707, "val_acc": 72.0}
{"epoch": 15, "training_loss": 63.79657506942749, "training_acc": 73.0, "val_loss": 19.72608119249344, "val_acc": 48.0}
{"epoch": 16, "training_loss": 78.72735667228699, "training_acc": 47.0, "val_loss": 14.301975071430206, "val_acc": 60.0}
{"epoch": 17, "training_loss": 51.03932237625122, "training_acc": 78.0, "val_loss": 20.064179599285126, "val_acc": 72.0}
{"epoch": 18, "training_loss": 73.17673134803772, "training_acc": 72.0, "val_loss": 13.928911089897156, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.52935028076172, "training_acc": 65.0, "val_loss": 16.176879405975342, "val_acc": 52.0}
{"epoch": 20, "training_loss": 58.86573886871338, "training_acc": 69.0, "val_loss": 14.51358050107956, "val_acc": 72.0}
{"epoch": 21, "training_loss": 65.43046808242798, "training_acc": 72.0, "val_loss": 15.88607132434845, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.407440423965454, "training_acc": 72.0, "val_loss": 13.618920743465424, "val_acc": 56.0}
{"epoch": 23, "training_loss": 58.51547932624817, "training_acc": 72.0, "val_loss": 11.577294021844864, "val_acc": 72.0}
{"epoch": 24, "training_loss": 49.73610532283783, "training_acc": 74.0, "val_loss": 15.224646031856537, "val_acc": 72.0}
{"epoch": 25, "training_loss": 54.898216247558594, "training_acc": 76.0, "val_loss": 11.92883551120758, "val_acc": 80.0}
{"epoch": 26, "training_loss": 46.670726895332336, "training_acc": 79.0, "val_loss": 13.109877705574036, "val_acc": 64.0}
{"epoch": 27, "training_loss": 51.63701105117798, "training_acc": 77.0, "val_loss": 12.883920967578888, "val_acc": 76.0}
{"epoch": 28, "training_loss": 47.8827748298645, "training_acc": 77.0, "val_loss": 13.315637409687042, "val_acc": 72.0}
{"epoch": 29, "training_loss": 48.05279195308685, "training_acc": 76.0, "val_loss": 12.780210375785828, "val_acc": 64.0}
{"epoch": 30, "training_loss": 46.36875534057617, "training_acc": 77.0, "val_loss": 12.853813171386719, "val_acc": 84.0}
{"epoch": 31, "training_loss": 48.92845392227173, "training_acc": 76.0, "val_loss": 13.501949608325958, "val_acc": 72.0}
{"epoch": 32, "training_loss": 46.19896352291107, "training_acc": 76.0, "val_loss": 13.771411776542664, "val_acc": 64.0}
{"epoch": 33, "training_loss": 50.155691742897034, "training_acc": 80.0, "val_loss": 13.251784443855286, "val_acc": 76.0}
{"epoch": 34, "training_loss": 50.78028130531311, "training_acc": 74.0, "val_loss": 14.271973073482513, "val_acc": 72.0}
{"epoch": 35, "training_loss": 47.368698716163635, "training_acc": 77.0, "val_loss": 13.599060475826263, "val_acc": 64.0}
{"epoch": 36, "training_loss": 49.742191433906555, "training_acc": 79.0, "val_loss": 12.158357352018356, "val_acc": 88.0}
{"epoch": 37, "training_loss": 48.892099380493164, "training_acc": 76.0, "val_loss": 13.61110806465149, "val_acc": 72.0}
{"epoch": 38, "training_loss": 44.6427059173584, "training_acc": 75.0, "val_loss": 13.316832482814789, "val_acc": 60.0}
{"epoch": 39, "training_loss": 52.1890184879303, "training_acc": 75.0, "val_loss": 11.89553588628769, "val_acc": 88.0}
{"epoch": 40, "training_loss": 50.03702640533447, "training_acc": 76.0, "val_loss": 12.983696162700653, "val_acc": 76.0}
{"epoch": 41, "training_loss": 44.45510458946228, "training_acc": 78.0, "val_loss": 12.7694770693779, "val_acc": 64.0}
{"epoch": 42, "training_loss": 49.017210960388184, "training_acc": 77.0, "val_loss": 12.35593780875206, "val_acc": 80.0}
