"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3819.85994720459, "training_acc": 43.0, "val_loss": 2201.1938095092773, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7542.569351196289, "training_acc": 72.0, "val_loss": 1908.6977005004883, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6459.292221069336, "training_acc": 29.0, "val_loss": 482.3620319366455, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2357.3822174072266, "training_acc": 72.0, "val_loss": 1209.7736358642578, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4404.253967285156, "training_acc": 72.0, "val_loss": 660.7552528381348, "val_acc": 68.0}
{"epoch": 5, "training_loss": 2028.518569946289, "training_acc": 63.0, "val_loss": 905.5852890014648, "val_acc": 68.0}
{"epoch": 6, "training_loss": 3128.7383193969727, "training_acc": 43.0, "val_loss": 640.8506870269775, "val_acc": 68.0}
{"epoch": 7, "training_loss": 2145.499496459961, "training_acc": 71.0, "val_loss": 741.442060470581, "val_acc": 68.0}
{"epoch": 8, "training_loss": 2360.8965225219727, "training_acc": 74.0, "val_loss": 570.8955764770508, "val_acc": 68.0}
{"epoch": 9, "training_loss": 1609.1101531982422, "training_acc": 68.0, "val_loss": 693.0654048919678, "val_acc": 68.0}
{"epoch": 10, "training_loss": 1872.4871864318848, "training_acc": 54.0, "val_loss": 401.04360580444336, "val_acc": 68.0}
{"epoch": 11, "training_loss": 1280.7249374389648, "training_acc": 76.0, "val_loss": 395.45812606811523, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1085.6359100341797, "training_acc": 73.0, "val_loss": 475.68039894104004, "val_acc": 40.0}
{"epoch": 13, "training_loss": 1623.7879829406738, "training_acc": 44.0, "val_loss": 155.3213119506836, "val_acc": 76.0}
{"epoch": 14, "training_loss": 862.9249877929688, "training_acc": 74.0, "val_loss": 275.04026889801025, "val_acc": 72.0}
{"epoch": 15, "training_loss": 791.3354072570801, "training_acc": 69.0, "val_loss": 429.18314933776855, "val_acc": 32.0}
{"epoch": 16, "training_loss": 1050.510724067688, "training_acc": 51.0, "val_loss": 204.90684509277344, "val_acc": 72.0}
{"epoch": 17, "training_loss": 872.8786029815674, "training_acc": 72.0, "val_loss": 85.57777404785156, "val_acc": 72.0}
{"epoch": 18, "training_loss": 914.9126739501953, "training_acc": 59.0, "val_loss": 127.42025852203369, "val_acc": 64.0}
{"epoch": 19, "training_loss": 633.168384552002, "training_acc": 67.0, "val_loss": 425.55484771728516, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1541.2459106445312, "training_acc": 72.0, "val_loss": 133.32372903823853, "val_acc": 76.0}
{"epoch": 21, "training_loss": 640.0388832092285, "training_acc": 66.0, "val_loss": 357.74989128112793, "val_acc": 48.0}
{"epoch": 22, "training_loss": 1114.8960647583008, "training_acc": 58.0, "val_loss": 289.0861749649048, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1044.2305755615234, "training_acc": 73.0, "val_loss": 147.83931970596313, "val_acc": 76.0}
{"epoch": 24, "training_loss": 559.1020908355713, "training_acc": 68.0, "val_loss": 196.10832929611206, "val_acc": 60.0}
{"epoch": 25, "training_loss": 590.6351442337036, "training_acc": 66.0, "val_loss": 195.93294858932495, "val_acc": 72.0}
{"epoch": 26, "training_loss": 562.3369312286377, "training_acc": 73.0, "val_loss": 281.2835693359375, "val_acc": 44.0}
{"epoch": 27, "training_loss": 823.0210704803467, "training_acc": 50.0, "val_loss": 242.66831874847412, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1177.7163734436035, "training_acc": 72.0, "val_loss": 324.9161958694458, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1058.2354736328125, "training_acc": 73.0, "val_loss": 560.7622146606445, "val_acc": 32.0}
{"epoch": 30, "training_loss": 1699.586280822754, "training_acc": 36.0, "val_loss": 296.77298069000244, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1595.3578872680664, "training_acc": 72.0, "val_loss": 699.7578144073486, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2549.5445442199707, "training_acc": 72.0, "val_loss": 234.74068641662598, "val_acc": 76.0}
{"epoch": 33, "training_loss": 824.962459564209, "training_acc": 69.0, "val_loss": 548.521900177002, "val_acc": 48.0}
{"epoch": 34, "training_loss": 1471.8693752288818, "training_acc": 52.0, "val_loss": 253.3489227294922, "val_acc": 76.0}
{"epoch": 35, "training_loss": 987.3951530456543, "training_acc": 76.0, "val_loss": 296.7679977416992, "val_acc": 80.0}
{"epoch": 36, "training_loss": 957.2724933624268, "training_acc": 75.0, "val_loss": 228.80322933197021, "val_acc": 60.0}
