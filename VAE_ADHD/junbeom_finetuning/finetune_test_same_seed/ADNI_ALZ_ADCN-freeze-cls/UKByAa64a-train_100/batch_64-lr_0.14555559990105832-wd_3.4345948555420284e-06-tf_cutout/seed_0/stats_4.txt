"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 215.1797161102295, "training_acc": 48.0, "val_loss": 119.4955587387085, "val_acc": 72.0}
{"epoch": 1, "training_loss": 350.191349029541, "training_acc": 72.0, "val_loss": 81.67663216590881, "val_acc": 28.0}
{"epoch": 2, "training_loss": 392.85360527038574, "training_acc": 29.0, "val_loss": 25.19926428794861, "val_acc": 76.0}
{"epoch": 3, "training_loss": 151.5986680984497, "training_acc": 69.0, "val_loss": 79.54725623130798, "val_acc": 72.0}
{"epoch": 4, "training_loss": 267.93406915664673, "training_acc": 72.0, "val_loss": 53.968942165374756, "val_acc": 72.0}
{"epoch": 5, "training_loss": 146.37675094604492, "training_acc": 68.0, "val_loss": 32.44103193283081, "val_acc": 60.0}
{"epoch": 6, "training_loss": 187.43400764465332, "training_acc": 56.0, "val_loss": 29.05144989490509, "val_acc": 60.0}
{"epoch": 7, "training_loss": 121.26078987121582, "training_acc": 69.0, "val_loss": 43.824100494384766, "val_acc": 72.0}
{"epoch": 8, "training_loss": 122.14231061935425, "training_acc": 75.0, "val_loss": 46.4648574590683, "val_acc": 72.0}
{"epoch": 9, "training_loss": 116.47468304634094, "training_acc": 75.0, "val_loss": 20.370888710021973, "val_acc": 64.0}
{"epoch": 10, "training_loss": 84.56534385681152, "training_acc": 63.0, "val_loss": 20.019838213920593, "val_acc": 56.0}
{"epoch": 11, "training_loss": 85.56626987457275, "training_acc": 55.0, "val_loss": 26.337233185768127, "val_acc": 72.0}
{"epoch": 12, "training_loss": 83.05171251296997, "training_acc": 72.0, "val_loss": 13.746581971645355, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.631454944610596, "training_acc": 70.0, "val_loss": 16.269540786743164, "val_acc": 40.0}
{"epoch": 14, "training_loss": 62.676759004592896, "training_acc": 65.0, "val_loss": 19.493068754673004, "val_acc": 72.0}
{"epoch": 15, "training_loss": 75.48038148880005, "training_acc": 72.0, "val_loss": 14.539167284965515, "val_acc": 52.0}
{"epoch": 16, "training_loss": 58.24272894859314, "training_acc": 66.0, "val_loss": 12.441125512123108, "val_acc": 76.0}
{"epoch": 17, "training_loss": 47.078569531440735, "training_acc": 79.0, "val_loss": 16.49158000946045, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.30194091796875, "training_acc": 74.0, "val_loss": 12.812909483909607, "val_acc": 64.0}
{"epoch": 19, "training_loss": 47.29740571975708, "training_acc": 80.0, "val_loss": 13.015705347061157, "val_acc": 76.0}
{"epoch": 20, "training_loss": 47.10353350639343, "training_acc": 77.0, "val_loss": 13.320648670196533, "val_acc": 76.0}
{"epoch": 21, "training_loss": 49.33264195919037, "training_acc": 75.0, "val_loss": 12.34283521771431, "val_acc": 80.0}
{"epoch": 22, "training_loss": 46.151854515075684, "training_acc": 74.0, "val_loss": 11.84815987944603, "val_acc": 76.0}
{"epoch": 23, "training_loss": 42.96861708164215, "training_acc": 81.0, "val_loss": 12.543147802352905, "val_acc": 64.0}
{"epoch": 24, "training_loss": 45.78247094154358, "training_acc": 80.0, "val_loss": 13.853378593921661, "val_acc": 76.0}
{"epoch": 25, "training_loss": 49.9934823513031, "training_acc": 76.0, "val_loss": 11.381660401821136, "val_acc": 84.0}
{"epoch": 26, "training_loss": 41.94078350067139, "training_acc": 81.0, "val_loss": 11.649683862924576, "val_acc": 72.0}
{"epoch": 27, "training_loss": 45.80465006828308, "training_acc": 79.0, "val_loss": 11.792659759521484, "val_acc": 80.0}
{"epoch": 28, "training_loss": 41.6589058637619, "training_acc": 79.0, "val_loss": 11.623945832252502, "val_acc": 84.0}
{"epoch": 29, "training_loss": 41.56367111206055, "training_acc": 80.0, "val_loss": 12.649621069431305, "val_acc": 80.0}
{"epoch": 30, "training_loss": 41.088624596595764, "training_acc": 81.0, "val_loss": 11.980225890874863, "val_acc": 72.0}
{"epoch": 31, "training_loss": 44.08930039405823, "training_acc": 79.0, "val_loss": 12.584872543811798, "val_acc": 80.0}
{"epoch": 32, "training_loss": 39.1264922618866, "training_acc": 81.0, "val_loss": 12.370964139699936, "val_acc": 80.0}
{"epoch": 33, "training_loss": 38.76364290714264, "training_acc": 86.0, "val_loss": 12.458442151546478, "val_acc": 80.0}
{"epoch": 34, "training_loss": 40.49414920806885, "training_acc": 83.0, "val_loss": 12.137699127197266, "val_acc": 80.0}
{"epoch": 35, "training_loss": 41.3384530544281, "training_acc": 81.0, "val_loss": 12.282563000917435, "val_acc": 80.0}
{"epoch": 36, "training_loss": 40.73032760620117, "training_acc": 82.0, "val_loss": 12.786275148391724, "val_acc": 80.0}
{"epoch": 37, "training_loss": 41.34633696079254, "training_acc": 78.0, "val_loss": 12.102752178907394, "val_acc": 84.0}
{"epoch": 38, "training_loss": 41.07688581943512, "training_acc": 83.0, "val_loss": 12.219984084367752, "val_acc": 84.0}
{"epoch": 39, "training_loss": 52.300347566604614, "training_acc": 76.0, "val_loss": 12.341824918985367, "val_acc": 68.0}
{"epoch": 40, "training_loss": 49.66327786445618, "training_acc": 72.0, "val_loss": 14.35089260339737, "val_acc": 76.0}
{"epoch": 41, "training_loss": 43.698172211647034, "training_acc": 78.0, "val_loss": 15.900999307632446, "val_acc": 76.0}
{"epoch": 42, "training_loss": 48.7765908241272, "training_acc": 74.0, "val_loss": 12.684015929698944, "val_acc": 72.0}
{"epoch": 43, "training_loss": 43.209319710731506, "training_acc": 79.0, "val_loss": 18.021000921726227, "val_acc": 72.0}
{"epoch": 44, "training_loss": 54.1564838886261, "training_acc": 72.0, "val_loss": 11.888150870800018, "val_acc": 84.0}
