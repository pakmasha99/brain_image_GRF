"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 867.3884124755859, "training_acc": 72.0, "val_loss": 344.77381706237793, "val_acc": 72.0}
{"epoch": 1, "training_loss": 999.4150266647339, "training_acc": 72.0, "val_loss": 420.1216697692871, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1969.5561294555664, "training_acc": 28.0, "val_loss": 60.27367115020752, "val_acc": 64.0}
{"epoch": 3, "training_loss": 391.67399978637695, "training_acc": 63.0, "val_loss": 343.6976194381714, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1351.4305610656738, "training_acc": 72.0, "val_loss": 421.1517333984375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1503.2882099151611, "training_acc": 72.0, "val_loss": 305.04846572875977, "val_acc": 72.0}
{"epoch": 6, "training_loss": 888.1921262741089, "training_acc": 71.0, "val_loss": 99.21360611915588, "val_acc": 68.0}
{"epoch": 7, "training_loss": 509.08663177490234, "training_acc": 63.0, "val_loss": 166.1619782447815, "val_acc": 52.0}
{"epoch": 8, "training_loss": 885.5337753295898, "training_acc": 43.0, "val_loss": 103.04375886917114, "val_acc": 72.0}
{"epoch": 9, "training_loss": 385.1642208099365, "training_acc": 72.0, "val_loss": 240.73293209075928, "val_acc": 72.0}
{"epoch": 10, "training_loss": 750.0241966247559, "training_acc": 72.0, "val_loss": 240.40846824645996, "val_acc": 72.0}
{"epoch": 11, "training_loss": 653.9913120269775, "training_acc": 72.0, "val_loss": 101.91506147384644, "val_acc": 76.0}
{"epoch": 12, "training_loss": 251.8824586868286, "training_acc": 67.0, "val_loss": 113.92314434051514, "val_acc": 56.0}
{"epoch": 13, "training_loss": 646.6865291595459, "training_acc": 45.0, "val_loss": 61.535412073135376, "val_acc": 68.0}
{"epoch": 14, "training_loss": 261.2149248123169, "training_acc": 66.0, "val_loss": 147.0715045928955, "val_acc": 72.0}
{"epoch": 15, "training_loss": 462.07801246643066, "training_acc": 72.0, "val_loss": 91.84563755989075, "val_acc": 72.0}
{"epoch": 16, "training_loss": 273.4628553390503, "training_acc": 68.0, "val_loss": 53.37585210800171, "val_acc": 52.0}
{"epoch": 17, "training_loss": 232.71643543243408, "training_acc": 55.0, "val_loss": 37.502074241638184, "val_acc": 72.0}
{"epoch": 18, "training_loss": 186.1515827178955, "training_acc": 74.0, "val_loss": 40.00091552734375, "val_acc": 72.0}
{"epoch": 19, "training_loss": 136.0881485939026, "training_acc": 63.0, "val_loss": 34.558022022247314, "val_acc": 40.0}
{"epoch": 20, "training_loss": 96.481769323349, "training_acc": 68.0, "val_loss": 37.02892363071442, "val_acc": 72.0}
{"epoch": 21, "training_loss": 119.87882995605469, "training_acc": 75.0, "val_loss": 28.028061985969543, "val_acc": 48.0}
{"epoch": 22, "training_loss": 100.16387128829956, "training_acc": 62.0, "val_loss": 25.19357204437256, "val_acc": 72.0}
{"epoch": 23, "training_loss": 104.72262048721313, "training_acc": 78.0, "val_loss": 23.649702966213226, "val_acc": 76.0}
{"epoch": 24, "training_loss": 86.07744550704956, "training_acc": 71.0, "val_loss": 17.867738008499146, "val_acc": 64.0}
{"epoch": 25, "training_loss": 84.76683115959167, "training_acc": 71.0, "val_loss": 32.38394558429718, "val_acc": 76.0}
{"epoch": 26, "training_loss": 85.54308271408081, "training_acc": 76.0, "val_loss": 29.95895743370056, "val_acc": 48.0}
{"epoch": 27, "training_loss": 111.69727683067322, "training_acc": 59.0, "val_loss": 20.01446932554245, "val_acc": 76.0}
{"epoch": 28, "training_loss": 56.253254652023315, "training_acc": 78.0, "val_loss": 11.608868092298508, "val_acc": 84.0}
{"epoch": 29, "training_loss": 40.96562314033508, "training_acc": 82.0, "val_loss": 11.574967950582504, "val_acc": 72.0}
{"epoch": 30, "training_loss": 38.330655574798584, "training_acc": 84.0, "val_loss": 12.729597091674805, "val_acc": 76.0}
{"epoch": 31, "training_loss": 34.29173541069031, "training_acc": 82.0, "val_loss": 12.640735507011414, "val_acc": 76.0}
{"epoch": 32, "training_loss": 38.07741022109985, "training_acc": 81.0, "val_loss": 13.853847980499268, "val_acc": 68.0}
{"epoch": 33, "training_loss": 36.75621736049652, "training_acc": 81.0, "val_loss": 21.614843606948853, "val_acc": 76.0}
{"epoch": 34, "training_loss": 43.77394711971283, "training_acc": 81.0, "val_loss": 24.591514468193054, "val_acc": 44.0}
{"epoch": 35, "training_loss": 84.25834012031555, "training_acc": 66.0, "val_loss": 26.244089007377625, "val_acc": 76.0}
{"epoch": 36, "training_loss": 46.37256836891174, "training_acc": 77.0, "val_loss": 14.50355052947998, "val_acc": 68.0}
{"epoch": 37, "training_loss": 35.54984223842621, "training_acc": 85.0, "val_loss": 22.242847084999084, "val_acc": 76.0}
{"epoch": 38, "training_loss": 48.45098125934601, "training_acc": 80.0, "val_loss": 12.29243353009224, "val_acc": 76.0}
{"epoch": 39, "training_loss": 40.06288397312164, "training_acc": 82.0, "val_loss": 11.773768067359924, "val_acc": 80.0}
{"epoch": 40, "training_loss": 35.014410734176636, "training_acc": 85.0, "val_loss": 20.202429592609406, "val_acc": 76.0}
{"epoch": 41, "training_loss": 46.35646450519562, "training_acc": 81.0, "val_loss": 15.939483046531677, "val_acc": 60.0}
{"epoch": 42, "training_loss": 55.94262099266052, "training_acc": 75.0, "val_loss": 26.02003812789917, "val_acc": 72.0}
{"epoch": 43, "training_loss": 48.588619112968445, "training_acc": 79.0, "val_loss": 21.229688823223114, "val_acc": 52.0}
{"epoch": 44, "training_loss": 100.29677557945251, "training_acc": 64.0, "val_loss": 38.899803161621094, "val_acc": 72.0}
{"epoch": 45, "training_loss": 72.4969071149826, "training_acc": 76.0, "val_loss": 53.5733163356781, "val_acc": 36.0}
{"epoch": 46, "training_loss": 166.46787321567535, "training_acc": 53.0, "val_loss": 40.691083669662476, "val_acc": 72.0}
{"epoch": 47, "training_loss": 86.48606264591217, "training_acc": 75.0, "val_loss": 18.650518357753754, "val_acc": 68.0}
{"epoch": 48, "training_loss": 54.41579866409302, "training_acc": 78.0, "val_loss": 37.739428877830505, "val_acc": 72.0}
