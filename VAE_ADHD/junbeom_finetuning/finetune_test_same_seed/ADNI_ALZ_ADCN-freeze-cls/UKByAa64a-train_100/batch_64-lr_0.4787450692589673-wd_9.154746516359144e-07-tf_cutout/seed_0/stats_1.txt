"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 626.129768371582, "training_acc": 70.0, "val_loss": 381.56542778015137, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1149.1060342788696, "training_acc": 72.0, "val_loss": 562.8847122192383, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1963.8459701538086, "training_acc": 28.0, "val_loss": 40.41845202445984, "val_acc": 56.0}
{"epoch": 3, "training_loss": 285.7378673553467, "training_acc": 72.0, "val_loss": 239.94324207305908, "val_acc": 72.0}
{"epoch": 4, "training_loss": 916.2179908752441, "training_acc": 72.0, "val_loss": 182.0841670036316, "val_acc": 72.0}
{"epoch": 5, "training_loss": 551.873664855957, "training_acc": 74.0, "val_loss": 112.92328834533691, "val_acc": 56.0}
{"epoch": 6, "training_loss": 543.9377498626709, "training_acc": 55.0, "val_loss": 178.15673351287842, "val_acc": 60.0}
{"epoch": 7, "training_loss": 627.6148738861084, "training_acc": 50.0, "val_loss": 97.94658422470093, "val_acc": 76.0}
{"epoch": 8, "training_loss": 490.9904499053955, "training_acc": 73.0, "val_loss": 191.77080392837524, "val_acc": 72.0}
{"epoch": 9, "training_loss": 725.544116973877, "training_acc": 72.0, "val_loss": 108.157217502594, "val_acc": 80.0}
{"epoch": 10, "training_loss": 328.66297721862793, "training_acc": 73.0, "val_loss": 133.68325233459473, "val_acc": 60.0}
{"epoch": 11, "training_loss": 601.5722637176514, "training_acc": 50.0, "val_loss": 87.02864646911621, "val_acc": 56.0}
{"epoch": 12, "training_loss": 249.27200603485107, "training_acc": 64.0, "val_loss": 90.59715270996094, "val_acc": 76.0}
{"epoch": 13, "training_loss": 395.7817974090576, "training_acc": 72.0, "val_loss": 85.71970462799072, "val_acc": 72.0}
{"epoch": 14, "training_loss": 314.24839758872986, "training_acc": 72.0, "val_loss": 64.34246897697449, "val_acc": 52.0}
{"epoch": 15, "training_loss": 241.901291847229, "training_acc": 56.0, "val_loss": 20.78401893377304, "val_acc": 68.0}
{"epoch": 16, "training_loss": 124.51356887817383, "training_acc": 78.0, "val_loss": 64.39249515533447, "val_acc": 72.0}
{"epoch": 17, "training_loss": 192.2376046180725, "training_acc": 74.0, "val_loss": 45.11843025684357, "val_acc": 48.0}
{"epoch": 18, "training_loss": 161.64915227890015, "training_acc": 51.0, "val_loss": 44.32581663131714, "val_acc": 72.0}
{"epoch": 19, "training_loss": 165.8038845062256, "training_acc": 72.0, "val_loss": 41.7175829410553, "val_acc": 72.0}
{"epoch": 20, "training_loss": 120.35296297073364, "training_acc": 68.0, "val_loss": 36.950647830963135, "val_acc": 44.0}
{"epoch": 21, "training_loss": 99.4593073129654, "training_acc": 67.0, "val_loss": 56.852173805236816, "val_acc": 72.0}
{"epoch": 22, "training_loss": 155.80186200141907, "training_acc": 74.0, "val_loss": 23.239292204380035, "val_acc": 60.0}
{"epoch": 23, "training_loss": 110.21056127548218, "training_acc": 64.0, "val_loss": 23.384642601013184, "val_acc": 72.0}
{"epoch": 24, "training_loss": 73.7804594039917, "training_acc": 79.0, "val_loss": 59.90247130393982, "val_acc": 72.0}
{"epoch": 25, "training_loss": 136.88863253593445, "training_acc": 73.0, "val_loss": 35.37707328796387, "val_acc": 52.0}
{"epoch": 26, "training_loss": 90.80301988124847, "training_acc": 66.0, "val_loss": 31.288695335388184, "val_acc": 76.0}
{"epoch": 27, "training_loss": 62.61751973628998, "training_acc": 79.0, "val_loss": 23.192059993743896, "val_acc": 48.0}
{"epoch": 28, "training_loss": 39.57275903224945, "training_acc": 81.0, "val_loss": 24.932093918323517, "val_acc": 68.0}
{"epoch": 29, "training_loss": 35.12589359283447, "training_acc": 80.0, "val_loss": 29.239818453788757, "val_acc": 40.0}
{"epoch": 30, "training_loss": 44.353843450546265, "training_acc": 81.0, "val_loss": 26.66538655757904, "val_acc": 72.0}
{"epoch": 31, "training_loss": 61.15814232826233, "training_acc": 76.0, "val_loss": 27.43319571018219, "val_acc": 76.0}
{"epoch": 32, "training_loss": 43.85002946853638, "training_acc": 80.0, "val_loss": 24.410252273082733, "val_acc": 48.0}
{"epoch": 33, "training_loss": 45.3737016916275, "training_acc": 79.0, "val_loss": 26.605966687202454, "val_acc": 76.0}
{"epoch": 34, "training_loss": 46.1101496219635, "training_acc": 78.0, "val_loss": 22.111478447914124, "val_acc": 56.0}
