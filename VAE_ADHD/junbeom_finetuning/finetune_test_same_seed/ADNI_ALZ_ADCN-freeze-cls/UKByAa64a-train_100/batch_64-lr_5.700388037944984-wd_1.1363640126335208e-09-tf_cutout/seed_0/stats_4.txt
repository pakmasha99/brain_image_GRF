"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7758.156581878662, "training_acc": 72.0, "val_loss": 4180.826950073242, "val_acc": 72.0}
{"epoch": 1, "training_loss": 11656.525665283203, "training_acc": 72.0, "val_loss": 5686.927032470703, "val_acc": 28.0}
{"epoch": 2, "training_loss": 25138.338012695312, "training_acc": 28.0, "val_loss": 808.2005500793457, "val_acc": 60.0}
{"epoch": 3, "training_loss": 7014.422180175781, "training_acc": 52.0, "val_loss": 3991.9326782226562, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15315.844848632812, "training_acc": 72.0, "val_loss": 4689.430999755859, "val_acc": 72.0}
{"epoch": 5, "training_loss": 15939.171508789062, "training_acc": 72.0, "val_loss": 3204.404067993164, "val_acc": 72.0}
{"epoch": 6, "training_loss": 7847.279983520508, "training_acc": 72.0, "val_loss": 1306.6024780273438, "val_acc": 64.0}
{"epoch": 7, "training_loss": 8108.108856201172, "training_acc": 56.0, "val_loss": 2089.31884765625, "val_acc": 52.0}
{"epoch": 8, "training_loss": 11474.317581176758, "training_acc": 50.0, "val_loss": 1341.033935546875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4963.907699584961, "training_acc": 72.0, "val_loss": 2701.0072708129883, "val_acc": 72.0}
{"epoch": 10, "training_loss": 8351.026763916016, "training_acc": 72.0, "val_loss": 2627.676773071289, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6348.204116821289, "training_acc": 74.0, "val_loss": 1166.5053367614746, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3559.9673767089844, "training_acc": 74.0, "val_loss": 1199.7106552124023, "val_acc": 56.0}
{"epoch": 13, "training_loss": 6693.093811035156, "training_acc": 55.0, "val_loss": 849.0262031555176, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2319.5775299072266, "training_acc": 73.0, "val_loss": 1700.3171920776367, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5446.765716552734, "training_acc": 72.0, "val_loss": 985.9104156494141, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2275.9811115264893, "training_acc": 77.0, "val_loss": 1277.7798652648926, "val_acc": 36.0}
{"epoch": 17, "training_loss": 4658.562347412109, "training_acc": 43.0, "val_loss": 459.1618537902832, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1841.2265853881836, "training_acc": 74.0, "val_loss": 738.7545585632324, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2255.195869445801, "training_acc": 68.0, "val_loss": 352.40423679351807, "val_acc": 60.0}
{"epoch": 20, "training_loss": 1428.1306495666504, "training_acc": 61.0, "val_loss": 173.2818603515625, "val_acc": 76.0}
{"epoch": 21, "training_loss": 512.1085939407349, "training_acc": 81.0, "val_loss": 197.182035446167, "val_acc": 60.0}
{"epoch": 22, "training_loss": 687.4606113433838, "training_acc": 67.0, "val_loss": 23.719000816345215, "val_acc": 80.0}
{"epoch": 23, "training_loss": 779.6765785217285, "training_acc": 62.0, "val_loss": 277.4592638015747, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1548.7014961242676, "training_acc": 72.0, "val_loss": 62.06207275390625, "val_acc": 68.0}
{"epoch": 25, "training_loss": 415.16711616516113, "training_acc": 71.0, "val_loss": 250.7211208343506, "val_acc": 76.0}
{"epoch": 26, "training_loss": 809.799747467041, "training_acc": 73.0, "val_loss": 386.40947341918945, "val_acc": 36.0}
{"epoch": 27, "training_loss": 1297.5065517425537, "training_acc": 57.0, "val_loss": 296.4556932449341, "val_acc": 76.0}
{"epoch": 28, "training_loss": 784.896656036377, "training_acc": 76.0, "val_loss": 454.693603515625, "val_acc": 40.0}
{"epoch": 29, "training_loss": 1255.8579235076904, "training_acc": 57.0, "val_loss": 656.5690994262695, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2301.9205474853516, "training_acc": 72.0, "val_loss": 473.2454299926758, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1063.4244174957275, "training_acc": 72.0, "val_loss": 345.0659513473511, "val_acc": 48.0}
{"epoch": 32, "training_loss": 1333.1522827148438, "training_acc": 68.0, "val_loss": 603.9677619934082, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1642.8350448608398, "training_acc": 74.0, "val_loss": 199.141526222229, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1175.3148498535156, "training_acc": 62.0, "val_loss": 322.611141204834, "val_acc": 76.0}
{"epoch": 35, "training_loss": 1057.02103805542, "training_acc": 77.0, "val_loss": 190.33944606781006, "val_acc": 80.0}
{"epoch": 36, "training_loss": 867.968620300293, "training_acc": 73.0, "val_loss": 76.1635959148407, "val_acc": 80.0}
{"epoch": 37, "training_loss": 315.83876037597656, "training_acc": 83.0, "val_loss": 139.34475183486938, "val_acc": 80.0}
{"epoch": 38, "training_loss": 561.9746112823486, "training_acc": 70.0, "val_loss": 74.94710087776184, "val_acc": 84.0}
{"epoch": 39, "training_loss": 302.496395111084, "training_acc": 81.0, "val_loss": 42.12208390235901, "val_acc": 72.0}
{"epoch": 40, "training_loss": 258.4005546569824, "training_acc": 77.0, "val_loss": 151.21606588363647, "val_acc": 76.0}
{"epoch": 41, "training_loss": 548.3577861785889, "training_acc": 79.0, "val_loss": 270.10607719421387, "val_acc": 48.0}
