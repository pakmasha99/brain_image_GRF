"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10035.923545837402, "training_acc": 72.0, "val_loss": 3939.4580841064453, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9860.950202941895, "training_acc": 72.0, "val_loss": 7933.900451660156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 29425.67987060547, "training_acc": 28.0, "val_loss": 2304.509925842285, "val_acc": 36.0}
{"epoch": 3, "training_loss": 8080.1259765625, "training_acc": 44.0, "val_loss": 3301.5098571777344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 13477.720886230469, "training_acc": 72.0, "val_loss": 4296.006774902344, "val_acc": 72.0}
{"epoch": 5, "training_loss": 15197.49462890625, "training_acc": 72.0, "val_loss": 2987.4120712280273, "val_acc": 72.0}
{"epoch": 6, "training_loss": 9275.244812011719, "training_acc": 73.0, "val_loss": 2016.7587280273438, "val_acc": 64.0}
{"epoch": 7, "training_loss": 7501.0762939453125, "training_acc": 61.0, "val_loss": 3199.8281478881836, "val_acc": 48.0}
{"epoch": 8, "training_loss": 9808.24105834961, "training_acc": 49.0, "val_loss": 2196.2820053100586, "val_acc": 60.0}
{"epoch": 9, "training_loss": 5035.293212890625, "training_acc": 71.0, "val_loss": 2142.9515838623047, "val_acc": 76.0}
{"epoch": 10, "training_loss": 7145.928375244141, "training_acc": 74.0, "val_loss": 2143.0253982543945, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6384.588226318359, "training_acc": 74.0, "val_loss": 1732.313346862793, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4295.127487182617, "training_acc": 71.0, "val_loss": 2141.012191772461, "val_acc": 68.0}
{"epoch": 13, "training_loss": 6270.619430541992, "training_acc": 55.0, "val_loss": 1356.2976837158203, "val_acc": 68.0}
{"epoch": 14, "training_loss": 3251.591812133789, "training_acc": 71.0, "val_loss": 1437.4444007873535, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5512.493255615234, "training_acc": 72.0, "val_loss": 925.2955436706543, "val_acc": 76.0}
{"epoch": 16, "training_loss": 3184.6759757995605, "training_acc": 71.0, "val_loss": 1508.526611328125, "val_acc": 36.0}
{"epoch": 17, "training_loss": 4542.86213684082, "training_acc": 42.0, "val_loss": 464.50862884521484, "val_acc": 76.0}
{"epoch": 18, "training_loss": 3254.6236572265625, "training_acc": 73.0, "val_loss": 1097.0748901367188, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3609.989013671875, "training_acc": 72.0, "val_loss": 463.97318840026855, "val_acc": 44.0}
{"epoch": 20, "training_loss": 2356.824920654297, "training_acc": 49.0, "val_loss": 212.50886917114258, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1064.2903518676758, "training_acc": 75.0, "val_loss": 727.6586532592773, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2449.3336029052734, "training_acc": 72.0, "val_loss": 424.7037410736084, "val_acc": 56.0}
{"epoch": 23, "training_loss": 1367.3999099731445, "training_acc": 60.0, "val_loss": 260.779070854187, "val_acc": 72.0}
{"epoch": 24, "training_loss": 719.4272041320801, "training_acc": 74.0, "val_loss": 231.85410499572754, "val_acc": 76.0}
{"epoch": 25, "training_loss": 721.1991271972656, "training_acc": 72.0, "val_loss": 316.4414882659912, "val_acc": 60.0}
{"epoch": 26, "training_loss": 922.8522529602051, "training_acc": 66.0, "val_loss": 223.7534999847412, "val_acc": 80.0}
{"epoch": 27, "training_loss": 791.8713474273682, "training_acc": 73.0, "val_loss": 230.08348941802979, "val_acc": 56.0}
{"epoch": 28, "training_loss": 660.8381614685059, "training_acc": 72.0, "val_loss": 296.95048332214355, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1275.1954698562622, "training_acc": 66.0, "val_loss": 45.51476240158081, "val_acc": 72.0}
{"epoch": 30, "training_loss": 184.87230968475342, "training_acc": 85.0, "val_loss": 46.77601456642151, "val_acc": 72.0}
{"epoch": 31, "training_loss": 313.5315227508545, "training_acc": 76.0, "val_loss": 66.11958146095276, "val_acc": 84.0}
{"epoch": 32, "training_loss": 430.42440700531006, "training_acc": 74.0, "val_loss": 36.208575963974, "val_acc": 80.0}
{"epoch": 33, "training_loss": 243.7251100540161, "training_acc": 81.0, "val_loss": 82.90258646011353, "val_acc": 80.0}
{"epoch": 34, "training_loss": 302.37915992736816, "training_acc": 81.0, "val_loss": 164.21247720718384, "val_acc": 60.0}
{"epoch": 35, "training_loss": 392.81370735168457, "training_acc": 75.0, "val_loss": 97.39499688148499, "val_acc": 76.0}
{"epoch": 36, "training_loss": 343.02738189697266, "training_acc": 82.0, "val_loss": 118.26484203338623, "val_acc": 68.0}
{"epoch": 37, "training_loss": 260.36772441864014, "training_acc": 78.0, "val_loss": 329.6036958694458, "val_acc": 40.0}
{"epoch": 38, "training_loss": 470.8935384750366, "training_acc": 74.0, "val_loss": 68.3652937412262, "val_acc": 68.0}
{"epoch": 39, "training_loss": 702.0182304382324, "training_acc": 64.0, "val_loss": 249.81703758239746, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1099.8876724243164, "training_acc": 72.0, "val_loss": 281.55016899108887, "val_acc": 44.0}
{"epoch": 41, "training_loss": 398.34968757629395, "training_acc": 65.0, "val_loss": 274.1163969039917, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1177.8863830566406, "training_acc": 74.0, "val_loss": 282.98730850219727, "val_acc": 60.0}
{"epoch": 43, "training_loss": 928.5395050048828, "training_acc": 64.0, "val_loss": 446.9317436218262, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2279.320785522461, "training_acc": 72.0, "val_loss": 363.7939929962158, "val_acc": 80.0}
{"epoch": 45, "training_loss": 1234.5166015625, "training_acc": 74.0, "val_loss": 754.286003112793, "val_acc": 48.0}
{"epoch": 46, "training_loss": 1507.6949100494385, "training_acc": 67.0, "val_loss": 440.59624671936035, "val_acc": 76.0}
{"epoch": 47, "training_loss": 1716.4134559631348, "training_acc": 74.0, "val_loss": 220.74272632598877, "val_acc": 72.0}
{"epoch": 48, "training_loss": 773.4521713256836, "training_acc": 76.0, "val_loss": 156.79430961608887, "val_acc": 72.0}
{"epoch": 49, "training_loss": 634.411434173584, "training_acc": 79.0, "val_loss": 73.04129004478455, "val_acc": 76.0}
{"epoch": 50, "training_loss": 593.8339424133301, "training_acc": 75.0, "val_loss": 18.814583122730255, "val_acc": 84.0}
{"epoch": 51, "training_loss": 475.1438903808594, "training_acc": 83.0, "val_loss": 145.9545612335205, "val_acc": 60.0}
{"epoch": 52, "training_loss": 322.95882987976074, "training_acc": 74.0, "val_loss": 180.45480251312256, "val_acc": 72.0}
{"epoch": 53, "training_loss": 611.2069535255432, "training_acc": 78.0, "val_loss": 477.7637004852295, "val_acc": 36.0}
{"epoch": 54, "training_loss": 931.5305461883545, "training_acc": 63.0, "val_loss": 354.6527624130249, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1068.5371570587158, "training_acc": 74.0, "val_loss": 563.7406349182129, "val_acc": 44.0}
{"epoch": 56, "training_loss": 1106.7923250198364, "training_acc": 64.0, "val_loss": 324.5224952697754, "val_acc": 80.0}
{"epoch": 57, "training_loss": 902.2008199691772, "training_acc": 80.0, "val_loss": 216.74935817718506, "val_acc": 72.0}
{"epoch": 58, "training_loss": 483.18966484069824, "training_acc": 79.0, "val_loss": 243.9469337463379, "val_acc": 68.0}
{"epoch": 59, "training_loss": 463.3955669403076, "training_acc": 80.0, "val_loss": 230.5624485015869, "val_acc": 84.0}
{"epoch": 60, "training_loss": 693.7535057067871, "training_acc": 77.0, "val_loss": 421.73686027526855, "val_acc": 40.0}
{"epoch": 61, "training_loss": 792.2096309661865, "training_acc": 69.0, "val_loss": 198.27866554260254, "val_acc": 72.0}
{"epoch": 62, "training_loss": 571.3570771217346, "training_acc": 79.0, "val_loss": 545.6142425537109, "val_acc": 36.0}
{"epoch": 63, "training_loss": 1101.243579864502, "training_acc": 62.0, "val_loss": 556.2105655670166, "val_acc": 72.0}
{"epoch": 64, "training_loss": 1774.310749053955, "training_acc": 72.0, "val_loss": 998.2864379882812, "val_acc": 36.0}
{"epoch": 65, "training_loss": 1839.4859800338745, "training_acc": 52.0, "val_loss": 352.20956802368164, "val_acc": 72.0}
{"epoch": 66, "training_loss": 1539.1425323486328, "training_acc": 73.0, "val_loss": 113.62971067428589, "val_acc": 80.0}
{"epoch": 67, "training_loss": 1207.5088958740234, "training_acc": 65.0, "val_loss": 163.5905623435974, "val_acc": 80.0}
{"epoch": 68, "training_loss": 423.3135757446289, "training_acc": 80.0, "val_loss": 454.0069580078125, "val_acc": 76.0}
{"epoch": 69, "training_loss": 1433.037302017212, "training_acc": 78.0, "val_loss": 501.973819732666, "val_acc": 56.0}
