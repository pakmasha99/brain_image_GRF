"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 32 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1598.7512702941895, "training_acc": 62.0, "val_loss": 1058.292293548584, "val_acc": 28.0}
{"epoch": 1, "training_loss": 3202.056442260742, "training_acc": 26.0, "val_loss": 422.2076416015625, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1736.7685852050781, "training_acc": 72.0, "val_loss": 271.0980415344238, "val_acc": 72.0}
{"epoch": 3, "training_loss": 493.76561737060547, "training_acc": 64.0, "val_loss": 79.84107732772827, "val_acc": 72.0}
{"epoch": 4, "training_loss": 506.43479919433594, "training_acc": 72.0, "val_loss": 54.80859875679016, "val_acc": 28.0}
{"epoch": 5, "training_loss": 160.42061042785645, "training_acc": 62.0, "val_loss": 55.86179494857788, "val_acc": 28.0}
{"epoch": 6, "training_loss": 101.9915246963501, "training_acc": 64.0, "val_loss": 172.37650156021118, "val_acc": 28.0}
{"epoch": 7, "training_loss": 386.28295516967773, "training_acc": 51.0, "val_loss": 158.41174125671387, "val_acc": 72.0}
{"epoch": 8, "training_loss": 375.3801078796387, "training_acc": 72.0, "val_loss": 369.1457509994507, "val_acc": 28.0}
{"epoch": 9, "training_loss": 820.0830993652344, "training_acc": 46.0, "val_loss": 458.30087661743164, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1907.7350616455078, "training_acc": 72.0, "val_loss": 335.2816343307495, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1088.857292175293, "training_acc": 50.0, "val_loss": 53.38863134384155, "val_acc": 28.0}
{"epoch": 12, "training_loss": 745.9066009521484, "training_acc": 58.0, "val_loss": 410.12558937072754, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1409.1886615753174, "training_acc": 72.0, "val_loss": 20.920880138874054, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1370.0982971191406, "training_acc": 38.0, "val_loss": 119.33261156082153, "val_acc": 72.0}
{"epoch": 15, "training_loss": 801.0144882202148, "training_acc": 72.0, "val_loss": 329.5305013656616, "val_acc": 72.0}
{"epoch": 16, "training_loss": 994.4107704162598, "training_acc": 68.0, "val_loss": 14.874133467674255, "val_acc": 76.0}
{"epoch": 17, "training_loss": 104.50854301452637, "training_acc": 69.0, "val_loss": 123.16722869873047, "val_acc": 72.0}
{"epoch": 18, "training_loss": 873.1056842803955, "training_acc": 72.0, "val_loss": 143.54000091552734, "val_acc": 72.0}
{"epoch": 19, "training_loss": 721.649112701416, "training_acc": 54.0, "val_loss": 21.20148092508316, "val_acc": 24.0}
{"epoch": 20, "training_loss": 819.8330554962158, "training_acc": 59.0, "val_loss": 412.4521255493164, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1346.4723739624023, "training_acc": 72.0, "val_loss": 163.95606994628906, "val_acc": 28.0}
{"epoch": 22, "training_loss": 663.860912322998, "training_acc": 30.0, "val_loss": 295.78051567077637, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1382.0350036621094, "training_acc": 72.0, "val_loss": 186.0357165336609, "val_acc": 72.0}
{"epoch": 24, "training_loss": 566.9125852584839, "training_acc": 40.0, "val_loss": 191.6117548942566, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1303.5787506103516, "training_acc": 72.0, "val_loss": 426.9595146179199, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1297.3947219848633, "training_acc": 72.0, "val_loss": 224.6403694152832, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1405.874713897705, "training_acc": 28.0, "val_loss": 132.84368515014648, "val_acc": 72.0}
{"epoch": 28, "training_loss": 506.371024094522, "training_acc": 72.0, "val_loss": 67.6734983921051, "val_acc": 28.0}
{"epoch": 29, "training_loss": 153.37835121154785, "training_acc": 58.0, "val_loss": 75.4503846168518, "val_acc": 28.0}
{"epoch": 30, "training_loss": 342.06059169769287, "training_acc": 54.0, "val_loss": 20.328420400619507, "val_acc": 76.0}
{"epoch": 31, "training_loss": 315.77160835266113, "training_acc": 44.0, "val_loss": 204.46240901947021, "val_acc": 72.0}
{"epoch": 32, "training_loss": 836.9151611328125, "training_acc": 72.0, "val_loss": 56.12814426422119, "val_acc": 72.0}
{"epoch": 33, "training_loss": 371.53912353515625, "training_acc": 40.0, "val_loss": 99.62188601493835, "val_acc": 72.0}
{"epoch": 34, "training_loss": 291.50733947753906, "training_acc": 58.0, "val_loss": 120.42039632797241, "val_acc": 72.0}
{"epoch": 35, "training_loss": 682.3055877685547, "training_acc": 72.0, "val_loss": 79.92762327194214, "val_acc": 72.0}
