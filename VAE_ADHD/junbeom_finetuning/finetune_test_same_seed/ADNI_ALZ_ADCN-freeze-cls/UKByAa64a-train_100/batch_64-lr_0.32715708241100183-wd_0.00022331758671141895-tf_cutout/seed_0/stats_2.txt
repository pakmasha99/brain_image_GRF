"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 461.62548065185547, "training_acc": 49.0, "val_loss": 292.27821826934814, "val_acc": 72.0}
{"epoch": 1, "training_loss": 910.0739936828613, "training_acc": 72.0, "val_loss": 71.44129872322083, "val_acc": 36.0}
{"epoch": 2, "training_loss": 322.42131519317627, "training_acc": 36.0, "val_loss": 62.26624250411987, "val_acc": 72.0}
{"epoch": 3, "training_loss": 285.78350830078125, "training_acc": 72.0, "val_loss": 84.28418040275574, "val_acc": 72.0}
{"epoch": 4, "training_loss": 211.9966745376587, "training_acc": 74.0, "val_loss": 61.59105896949768, "val_acc": 44.0}
{"epoch": 5, "training_loss": 350.18962478637695, "training_acc": 43.0, "val_loss": 35.98177134990692, "val_acc": 72.0}
{"epoch": 6, "training_loss": 142.35302066802979, "training_acc": 73.0, "val_loss": 100.20898580551147, "val_acc": 72.0}
{"epoch": 7, "training_loss": 336.6678829193115, "training_acc": 72.0, "val_loss": 51.40617489814758, "val_acc": 76.0}
{"epoch": 8, "training_loss": 133.02085542678833, "training_acc": 69.0, "val_loss": 59.90070700645447, "val_acc": 40.0}
{"epoch": 9, "training_loss": 234.27344131469727, "training_acc": 55.0, "val_loss": 47.985753417015076, "val_acc": 72.0}
{"epoch": 10, "training_loss": 142.65888833999634, "training_acc": 73.0, "val_loss": 45.91781198978424, "val_acc": 72.0}
{"epoch": 11, "training_loss": 104.89338397979736, "training_acc": 76.0, "val_loss": 34.046584367752075, "val_acc": 48.0}
{"epoch": 12, "training_loss": 125.65403389930725, "training_acc": 58.0, "val_loss": 32.30508863925934, "val_acc": 64.0}
{"epoch": 13, "training_loss": 71.27232885360718, "training_acc": 75.0, "val_loss": 23.040281236171722, "val_acc": 56.0}
{"epoch": 14, "training_loss": 63.32540273666382, "training_acc": 65.0, "val_loss": 31.297510862350464, "val_acc": 72.0}
{"epoch": 15, "training_loss": 85.96128034591675, "training_acc": 72.0, "val_loss": 14.795413613319397, "val_acc": 76.0}
{"epoch": 16, "training_loss": 59.98887825012207, "training_acc": 71.0, "val_loss": 16.575898230075836, "val_acc": 76.0}
{"epoch": 17, "training_loss": 60.20538258552551, "training_acc": 79.0, "val_loss": 15.161506831645966, "val_acc": 76.0}
{"epoch": 18, "training_loss": 60.00961637496948, "training_acc": 74.0, "val_loss": 12.759707868099213, "val_acc": 84.0}
{"epoch": 19, "training_loss": 65.80951118469238, "training_acc": 70.0, "val_loss": 23.471976816654205, "val_acc": 72.0}
{"epoch": 20, "training_loss": 75.815678358078, "training_acc": 67.0, "val_loss": 12.420190870761871, "val_acc": 68.0}
{"epoch": 21, "training_loss": 73.70368266105652, "training_acc": 63.0, "val_loss": 24.948853254318237, "val_acc": 72.0}
{"epoch": 22, "training_loss": 78.61621856689453, "training_acc": 65.0, "val_loss": 12.33983039855957, "val_acc": 72.0}
{"epoch": 23, "training_loss": 44.97689366340637, "training_acc": 78.0, "val_loss": 21.91389799118042, "val_acc": 72.0}
{"epoch": 24, "training_loss": 63.01411414146423, "training_acc": 72.0, "val_loss": 13.685610890388489, "val_acc": 72.0}
{"epoch": 25, "training_loss": 44.37027728557587, "training_acc": 80.0, "val_loss": 16.615645587444305, "val_acc": 68.0}
{"epoch": 26, "training_loss": 47.84189295768738, "training_acc": 76.0, "val_loss": 17.250482738018036, "val_acc": 72.0}
{"epoch": 27, "training_loss": 41.35123860836029, "training_acc": 79.0, "val_loss": 14.163100719451904, "val_acc": 64.0}
{"epoch": 28, "training_loss": 31.792847394943237, "training_acc": 89.0, "val_loss": 14.364863932132721, "val_acc": 64.0}
{"epoch": 29, "training_loss": 41.58754348754883, "training_acc": 82.0, "val_loss": 14.272955060005188, "val_acc": 64.0}
{"epoch": 30, "training_loss": 37.98177623748779, "training_acc": 84.0, "val_loss": 17.37513691186905, "val_acc": 72.0}
{"epoch": 31, "training_loss": 37.468469977378845, "training_acc": 84.0, "val_loss": 15.127179026603699, "val_acc": 68.0}
{"epoch": 32, "training_loss": 39.50009882450104, "training_acc": 83.0, "val_loss": 15.822392702102661, "val_acc": 72.0}
{"epoch": 33, "training_loss": 35.70560431480408, "training_acc": 84.0, "val_loss": 13.174687325954437, "val_acc": 68.0}
{"epoch": 34, "training_loss": 33.76027071475983, "training_acc": 88.0, "val_loss": 14.220009744167328, "val_acc": 72.0}
{"epoch": 35, "training_loss": 34.0841943025589, "training_acc": 87.0, "val_loss": 13.81910890340805, "val_acc": 64.0}
{"epoch": 36, "training_loss": 31.75799334049225, "training_acc": 88.0, "val_loss": 13.498751819133759, "val_acc": 64.0}
{"epoch": 37, "training_loss": 33.59160542488098, "training_acc": 87.0, "val_loss": 13.03272396326065, "val_acc": 60.0}
{"epoch": 38, "training_loss": 31.15087217092514, "training_acc": 86.0, "val_loss": 17.044298350811005, "val_acc": 76.0}
{"epoch": 39, "training_loss": 35.09441006183624, "training_acc": 87.0, "val_loss": 14.563848078250885, "val_acc": 68.0}
{"epoch": 40, "training_loss": 32.55691385269165, "training_acc": 86.0, "val_loss": 19.69456374645233, "val_acc": 72.0}
{"epoch": 41, "training_loss": 50.91748654842377, "training_acc": 75.0, "val_loss": 18.906307220458984, "val_acc": 72.0}
