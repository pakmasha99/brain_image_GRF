"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 331.60696029663086, "training_acc": 72.0, "val_loss": 217.04933643341064, "val_acc": 72.0}
{"epoch": 1, "training_loss": 656.2823371887207, "training_acc": 66.0, "val_loss": 140.88053703308105, "val_acc": 32.0}
{"epoch": 2, "training_loss": 382.1898159980774, "training_acc": 51.0, "val_loss": 97.0190942287445, "val_acc": 72.0}
{"epoch": 3, "training_loss": 354.42981243133545, "training_acc": 72.0, "val_loss": 57.546573877334595, "val_acc": 72.0}
{"epoch": 4, "training_loss": 172.20015048980713, "training_acc": 66.0, "val_loss": 67.82508492469788, "val_acc": 64.0}
{"epoch": 5, "training_loss": 153.94960117340088, "training_acc": 66.0, "val_loss": 57.11214542388916, "val_acc": 72.0}
{"epoch": 6, "training_loss": 181.32006216049194, "training_acc": 73.0, "val_loss": 43.55760216712952, "val_acc": 64.0}
{"epoch": 7, "training_loss": 125.7432107925415, "training_acc": 62.0, "val_loss": 24.474254250526428, "val_acc": 72.0}
{"epoch": 8, "training_loss": 81.54860353469849, "training_acc": 74.0, "val_loss": 21.86475694179535, "val_acc": 76.0}
{"epoch": 9, "training_loss": 91.59359645843506, "training_acc": 65.0, "val_loss": 14.851117134094238, "val_acc": 56.0}
{"epoch": 10, "training_loss": 117.58689594268799, "training_acc": 62.0, "val_loss": 13.074356317520142, "val_acc": 72.0}
{"epoch": 11, "training_loss": 98.67202091217041, "training_acc": 61.0, "val_loss": 15.825001895427704, "val_acc": 76.0}
{"epoch": 12, "training_loss": 72.97836446762085, "training_acc": 78.0, "val_loss": 22.34247773885727, "val_acc": 80.0}
{"epoch": 13, "training_loss": 79.00717210769653, "training_acc": 72.0, "val_loss": 31.582921743392944, "val_acc": 56.0}
{"epoch": 14, "training_loss": 70.60475671291351, "training_acc": 74.0, "val_loss": 45.62685191631317, "val_acc": 72.0}
{"epoch": 15, "training_loss": 181.26504230499268, "training_acc": 72.0, "val_loss": 24.110591411590576, "val_acc": 76.0}
{"epoch": 16, "training_loss": 99.91358137130737, "training_acc": 68.0, "val_loss": 48.090505599975586, "val_acc": 52.0}
{"epoch": 17, "training_loss": 123.14783430099487, "training_acc": 63.0, "val_loss": 45.0568825006485, "val_acc": 72.0}
{"epoch": 18, "training_loss": 169.9687623977661, "training_acc": 72.0, "val_loss": 19.498854875564575, "val_acc": 72.0}
{"epoch": 19, "training_loss": 99.11015701293945, "training_acc": 70.0, "val_loss": 27.933555841445923, "val_acc": 64.0}
{"epoch": 20, "training_loss": 118.0675721168518, "training_acc": 63.0, "val_loss": 42.07066297531128, "val_acc": 72.0}
{"epoch": 21, "training_loss": 149.11803197860718, "training_acc": 72.0, "val_loss": 37.77129948139191, "val_acc": 36.0}
{"epoch": 22, "training_loss": 99.93857765197754, "training_acc": 62.0, "val_loss": 21.633808314800262, "val_acc": 80.0}
{"epoch": 23, "training_loss": 74.47854244709015, "training_acc": 73.0, "val_loss": 16.202063858509064, "val_acc": 72.0}
{"epoch": 24, "training_loss": 48.24292206764221, "training_acc": 77.0, "val_loss": 16.035522520542145, "val_acc": 64.0}
{"epoch": 25, "training_loss": 38.023683309555054, "training_acc": 80.0, "val_loss": 13.210819661617279, "val_acc": 76.0}
{"epoch": 26, "training_loss": 42.21128261089325, "training_acc": 81.0, "val_loss": 13.264213502407074, "val_acc": 60.0}
{"epoch": 27, "training_loss": 39.32191014289856, "training_acc": 78.0, "val_loss": 11.817256361246109, "val_acc": 64.0}
{"epoch": 28, "training_loss": 39.104177832603455, "training_acc": 79.0, "val_loss": 12.956511974334717, "val_acc": 56.0}
{"epoch": 29, "training_loss": 39.632675766944885, "training_acc": 82.0, "val_loss": 12.005878239870071, "val_acc": 64.0}
{"epoch": 30, "training_loss": 41.501975655555725, "training_acc": 84.0, "val_loss": 11.427810043096542, "val_acc": 60.0}
{"epoch": 31, "training_loss": 29.972121000289917, "training_acc": 88.0, "val_loss": 10.549825429916382, "val_acc": 72.0}
{"epoch": 32, "training_loss": 34.2569774389267, "training_acc": 85.0, "val_loss": 10.490285605192184, "val_acc": 72.0}
{"epoch": 33, "training_loss": 36.032920479774475, "training_acc": 83.0, "val_loss": 21.735206246376038, "val_acc": 52.0}
{"epoch": 34, "training_loss": 51.281018018722534, "training_acc": 69.0, "val_loss": 33.96145701408386, "val_acc": 72.0}
{"epoch": 35, "training_loss": 137.03093099594116, "training_acc": 72.0, "val_loss": 15.156792104244232, "val_acc": 76.0}
{"epoch": 36, "training_loss": 90.73814725875854, "training_acc": 63.0, "val_loss": 19.659914076328278, "val_acc": 72.0}
{"epoch": 37, "training_loss": 73.43110466003418, "training_acc": 76.0, "val_loss": 28.56496274471283, "val_acc": 80.0}
{"epoch": 38, "training_loss": 63.96961045265198, "training_acc": 81.0, "val_loss": 59.33784246444702, "val_acc": 40.0}
{"epoch": 39, "training_loss": 121.05864906311035, "training_acc": 62.0, "val_loss": 32.11311995983124, "val_acc": 80.0}
{"epoch": 40, "training_loss": 145.23203420639038, "training_acc": 74.0, "val_loss": 23.528210818767548, "val_acc": 76.0}
{"epoch": 41, "training_loss": 154.43505859375, "training_acc": 58.0, "val_loss": 31.48649036884308, "val_acc": 60.0}
{"epoch": 42, "training_loss": 94.5670256614685, "training_acc": 74.0, "val_loss": 37.70211040973663, "val_acc": 72.0}
{"epoch": 43, "training_loss": 124.85940670967102, "training_acc": 75.0, "val_loss": 45.600348711013794, "val_acc": 44.0}
{"epoch": 44, "training_loss": 104.00661873817444, "training_acc": 59.0, "val_loss": 25.58867335319519, "val_acc": 76.0}
{"epoch": 45, "training_loss": 140.80169105529785, "training_acc": 72.0, "val_loss": 15.317696332931519, "val_acc": 80.0}
{"epoch": 46, "training_loss": 93.46058225631714, "training_acc": 68.0, "val_loss": 27.47338116168976, "val_acc": 56.0}
{"epoch": 47, "training_loss": 66.39816784858704, "training_acc": 76.0, "val_loss": 40.208446979522705, "val_acc": 72.0}
{"epoch": 48, "training_loss": 140.10937595367432, "training_acc": 74.0, "val_loss": 31.239980459213257, "val_acc": 60.0}
{"epoch": 49, "training_loss": 91.64404249191284, "training_acc": 69.0, "val_loss": 23.475705087184906, "val_acc": 72.0}
{"epoch": 50, "training_loss": 69.93076848983765, "training_acc": 78.0, "val_loss": 29.26425337791443, "val_acc": 80.0}
{"epoch": 51, "training_loss": 85.26198697090149, "training_acc": 78.0, "val_loss": 42.73708164691925, "val_acc": 52.0}
