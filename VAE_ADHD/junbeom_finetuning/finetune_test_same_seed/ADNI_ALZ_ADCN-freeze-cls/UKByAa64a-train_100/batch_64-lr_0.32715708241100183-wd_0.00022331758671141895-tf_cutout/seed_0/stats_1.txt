"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 441.7413139343262, "training_acc": 70.0, "val_loss": 260.848069190979, "val_acc": 72.0}
{"epoch": 1, "training_loss": 785.4217748641968, "training_acc": 72.0, "val_loss": 383.5939884185791, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1336.9971389770508, "training_acc": 28.0, "val_loss": 29.2385071516037, "val_acc": 56.0}
{"epoch": 3, "training_loss": 200.63340187072754, "training_acc": 72.0, "val_loss": 165.37896394729614, "val_acc": 72.0}
{"epoch": 4, "training_loss": 631.0153770446777, "training_acc": 72.0, "val_loss": 125.90686082839966, "val_acc": 72.0}
{"epoch": 5, "training_loss": 382.5979175567627, "training_acc": 74.0, "val_loss": 75.85700750350952, "val_acc": 56.0}
{"epoch": 6, "training_loss": 367.3553123474121, "training_acc": 55.0, "val_loss": 122.43895530700684, "val_acc": 60.0}
{"epoch": 7, "training_loss": 434.51183557510376, "training_acc": 50.0, "val_loss": 66.14033579826355, "val_acc": 76.0}
{"epoch": 8, "training_loss": 331.4480619430542, "training_acc": 72.0, "val_loss": 130.35333156585693, "val_acc": 72.0}
{"epoch": 9, "training_loss": 493.8218574523926, "training_acc": 72.0, "val_loss": 74.32671189308167, "val_acc": 80.0}
{"epoch": 10, "training_loss": 226.68916940689087, "training_acc": 73.0, "val_loss": 90.5450701713562, "val_acc": 60.0}
{"epoch": 11, "training_loss": 411.6068115234375, "training_acc": 50.0, "val_loss": 59.65628623962402, "val_acc": 56.0}
{"epoch": 12, "training_loss": 174.86003637313843, "training_acc": 64.0, "val_loss": 63.09430003166199, "val_acc": 72.0}
{"epoch": 13, "training_loss": 274.4408235549927, "training_acc": 72.0, "val_loss": 59.9325954914093, "val_acc": 72.0}
{"epoch": 14, "training_loss": 219.84869992733002, "training_acc": 72.0, "val_loss": 43.46489608287811, "val_acc": 52.0}
{"epoch": 15, "training_loss": 165.33427476882935, "training_acc": 57.0, "val_loss": 15.485623478889465, "val_acc": 72.0}
{"epoch": 16, "training_loss": 87.12090492248535, "training_acc": 78.0, "val_loss": 43.17443072795868, "val_acc": 72.0}
{"epoch": 17, "training_loss": 129.90198230743408, "training_acc": 74.0, "val_loss": 30.584406852722168, "val_acc": 48.0}
{"epoch": 18, "training_loss": 114.2618761062622, "training_acc": 52.0, "val_loss": 28.08029353618622, "val_acc": 72.0}
{"epoch": 19, "training_loss": 104.28798627853394, "training_acc": 72.0, "val_loss": 26.659667491912842, "val_acc": 72.0}
{"epoch": 20, "training_loss": 82.58412575721741, "training_acc": 68.0, "val_loss": 25.847426056861877, "val_acc": 44.0}
{"epoch": 21, "training_loss": 70.10860693454742, "training_acc": 69.0, "val_loss": 41.441091895103455, "val_acc": 72.0}
{"epoch": 22, "training_loss": 115.6923315525055, "training_acc": 72.0, "val_loss": 18.11404824256897, "val_acc": 60.0}
{"epoch": 23, "training_loss": 81.71505737304688, "training_acc": 64.0, "val_loss": 17.81240403652191, "val_acc": 68.0}
{"epoch": 24, "training_loss": 55.16639852523804, "training_acc": 79.0, "val_loss": 42.321157455444336, "val_acc": 72.0}
{"epoch": 25, "training_loss": 100.84729743003845, "training_acc": 73.0, "val_loss": 24.174809455871582, "val_acc": 56.0}
{"epoch": 26, "training_loss": 66.94456458091736, "training_acc": 69.0, "val_loss": 20.648345351219177, "val_acc": 76.0}
{"epoch": 27, "training_loss": 46.41295540332794, "training_acc": 82.0, "val_loss": 18.294593691825867, "val_acc": 68.0}
{"epoch": 28, "training_loss": 37.38835942745209, "training_acc": 81.0, "val_loss": 18.661651015281677, "val_acc": 60.0}
{"epoch": 29, "training_loss": 38.513986706733704, "training_acc": 81.0, "val_loss": 19.41915452480316, "val_acc": 52.0}
{"epoch": 30, "training_loss": 37.14590287208557, "training_acc": 84.0, "val_loss": 22.91944772005081, "val_acc": 68.0}
{"epoch": 31, "training_loss": 48.6847505569458, "training_acc": 80.0, "val_loss": 18.26423555612564, "val_acc": 64.0}
{"epoch": 32, "training_loss": 34.31539857387543, "training_acc": 83.0, "val_loss": 17.600101232528687, "val_acc": 64.0}
{"epoch": 33, "training_loss": 36.15838539600372, "training_acc": 83.0, "val_loss": 18.390294909477234, "val_acc": 76.0}
{"epoch": 34, "training_loss": 36.11832571029663, "training_acc": 83.0, "val_loss": 17.446225881576538, "val_acc": 64.0}
