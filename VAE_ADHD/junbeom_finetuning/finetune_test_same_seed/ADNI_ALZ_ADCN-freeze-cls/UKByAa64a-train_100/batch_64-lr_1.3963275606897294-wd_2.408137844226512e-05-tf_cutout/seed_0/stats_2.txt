"main_optuna_fix.py --pretrained_path /sdcc/u/dyhan316/misc_VAE/junbeom_weights/UKByAa64a.pth --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2274.082649230957, "training_acc": 40.0, "val_loss": 1076.280403137207, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3235.6447792053223, "training_acc": 72.0, "val_loss": 1122.122573852539, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4485.256927490234, "training_acc": 28.0, "val_loss": 139.95836973190308, "val_acc": 80.0}
{"epoch": 3, "training_loss": 1099.8212356567383, "training_acc": 70.0, "val_loss": 770.5147743225098, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2953.7398376464844, "training_acc": 72.0, "val_loss": 678.8094520568848, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2023.9658813476562, "training_acc": 70.0, "val_loss": 219.83065605163574, "val_acc": 76.0}
{"epoch": 6, "training_loss": 1410.0316162109375, "training_acc": 64.0, "val_loss": 379.32140827178955, "val_acc": 48.0}
{"epoch": 7, "training_loss": 1717.6064414978027, "training_acc": 54.0, "val_loss": 322.48144149780273, "val_acc": 76.0}
{"epoch": 8, "training_loss": 999.334997177124, "training_acc": 74.0, "val_loss": 481.73413276672363, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1440.3755416870117, "training_acc": 70.0, "val_loss": 247.69020080566406, "val_acc": 68.0}
{"epoch": 10, "training_loss": 744.8447856903076, "training_acc": 68.0, "val_loss": 182.34859704971313, "val_acc": 76.0}
{"epoch": 11, "training_loss": 535.2662620544434, "training_acc": 71.0, "val_loss": 199.37078952789307, "val_acc": 72.0}
{"epoch": 12, "training_loss": 523.2098731994629, "training_acc": 75.0, "val_loss": 139.01466131210327, "val_acc": 60.0}
{"epoch": 13, "training_loss": 421.5389766693115, "training_acc": 66.0, "val_loss": 117.08453893661499, "val_acc": 52.0}
{"epoch": 14, "training_loss": 464.85305404663086, "training_acc": 63.0, "val_loss": 221.51007652282715, "val_acc": 72.0}
{"epoch": 15, "training_loss": 631.877760887146, "training_acc": 72.0, "val_loss": 155.643892288208, "val_acc": 48.0}
{"epoch": 16, "training_loss": 415.2113847732544, "training_acc": 49.0, "val_loss": 116.63714647293091, "val_acc": 68.0}
{"epoch": 17, "training_loss": 300.23260402679443, "training_acc": 73.0, "val_loss": 80.04502654075623, "val_acc": 56.0}
{"epoch": 18, "training_loss": 217.13172435760498, "training_acc": 68.0, "val_loss": 114.93034362792969, "val_acc": 72.0}
{"epoch": 19, "training_loss": 239.58709716796875, "training_acc": 74.0, "val_loss": 102.07327604293823, "val_acc": 60.0}
{"epoch": 20, "training_loss": 402.0919346809387, "training_acc": 55.0, "val_loss": 126.40355825424194, "val_acc": 72.0}
{"epoch": 21, "training_loss": 323.4234027862549, "training_acc": 73.0, "val_loss": 74.99823570251465, "val_acc": 80.0}
{"epoch": 22, "training_loss": 221.3694658279419, "training_acc": 70.0, "val_loss": 74.41889643669128, "val_acc": 80.0}
{"epoch": 23, "training_loss": 303.3837375640869, "training_acc": 73.0, "val_loss": 146.0455298423767, "val_acc": 72.0}
{"epoch": 24, "training_loss": 319.0641360282898, "training_acc": 78.0, "val_loss": 56.64358139038086, "val_acc": 72.0}
{"epoch": 25, "training_loss": 186.1880979537964, "training_acc": 70.0, "val_loss": 41.52742922306061, "val_acc": 72.0}
{"epoch": 26, "training_loss": 71.87539768218994, "training_acc": 86.0, "val_loss": 80.4525375366211, "val_acc": 72.0}
{"epoch": 27, "training_loss": 165.68896555900574, "training_acc": 76.0, "val_loss": 61.137646436691284, "val_acc": 52.0}
{"epoch": 28, "training_loss": 155.32071495056152, "training_acc": 71.0, "val_loss": 28.323039412498474, "val_acc": 72.0}
{"epoch": 29, "training_loss": 49.59138631820679, "training_acc": 81.0, "val_loss": 38.23407292366028, "val_acc": 72.0}
{"epoch": 30, "training_loss": 66.70443439483643, "training_acc": 87.0, "val_loss": 26.722735166549683, "val_acc": 68.0}
{"epoch": 31, "training_loss": 113.90607213973999, "training_acc": 72.0, "val_loss": 37.65493631362915, "val_acc": 72.0}
{"epoch": 32, "training_loss": 107.08315229415894, "training_acc": 69.0, "val_loss": 111.19225025177002, "val_acc": 72.0}
{"epoch": 33, "training_loss": 338.8511905670166, "training_acc": 72.0, "val_loss": 33.24884474277496, "val_acc": 64.0}
{"epoch": 34, "training_loss": 150.01587533950806, "training_acc": 65.0, "val_loss": 125.46579837799072, "val_acc": 72.0}
{"epoch": 35, "training_loss": 390.36599922180176, "training_acc": 73.0, "val_loss": 43.51023733615875, "val_acc": 76.0}
{"epoch": 36, "training_loss": 253.8867588043213, "training_acc": 69.0, "val_loss": 49.736207723617554, "val_acc": 68.0}
{"epoch": 37, "training_loss": 218.18866539001465, "training_acc": 81.0, "val_loss": 94.11847591400146, "val_acc": 72.0}
{"epoch": 38, "training_loss": 208.96746444702148, "training_acc": 68.0, "val_loss": 50.91613531112671, "val_acc": 68.0}
{"epoch": 39, "training_loss": 84.00309324264526, "training_acc": 84.0, "val_loss": 65.1123046875, "val_acc": 68.0}
{"epoch": 40, "training_loss": 129.8308825492859, "training_acc": 74.0, "val_loss": 73.17419052124023, "val_acc": 68.0}
{"epoch": 41, "training_loss": 151.7509126663208, "training_acc": 81.0, "val_loss": 58.396148681640625, "val_acc": 60.0}
{"epoch": 42, "training_loss": 95.47850227355957, "training_acc": 73.0, "val_loss": 97.41551280021667, "val_acc": 72.0}
{"epoch": 43, "training_loss": 177.2333915233612, "training_acc": 78.0, "val_loss": 62.123048305511475, "val_acc": 60.0}
{"epoch": 44, "training_loss": 104.2062920331955, "training_acc": 74.0, "val_loss": 65.25794863700867, "val_acc": 68.0}
{"epoch": 45, "training_loss": 76.21531343460083, "training_acc": 84.0, "val_loss": 69.47181820869446, "val_acc": 60.0}
{"epoch": 46, "training_loss": 236.4536714553833, "training_acc": 61.0, "val_loss": 62.32801675796509, "val_acc": 72.0}
{"epoch": 47, "training_loss": 98.0371766090393, "training_acc": 84.0, "val_loss": 25.517478585243225, "val_acc": 64.0}
{"epoch": 48, "training_loss": 39.25494718551636, "training_acc": 89.0, "val_loss": 69.87560987472534, "val_acc": 72.0}
{"epoch": 49, "training_loss": 157.98114490509033, "training_acc": 64.0, "val_loss": 97.92643785476685, "val_acc": 72.0}
{"epoch": 50, "training_loss": 222.1506700515747, "training_acc": 72.0, "val_loss": 70.29643058776855, "val_acc": 48.0}
{"epoch": 51, "training_loss": 171.1362646818161, "training_acc": 70.0, "val_loss": 76.38480067253113, "val_acc": 72.0}
{"epoch": 52, "training_loss": 108.01416540145874, "training_acc": 83.0, "val_loss": 47.53258526325226, "val_acc": 68.0}
{"epoch": 53, "training_loss": 170.83614826202393, "training_acc": 68.0, "val_loss": 218.88699531555176, "val_acc": 72.0}
{"epoch": 54, "training_loss": 694.3648738861084, "training_acc": 72.0, "val_loss": 257.1392059326172, "val_acc": 72.0}
{"epoch": 55, "training_loss": 542.1042852401733, "training_acc": 76.0, "val_loss": 197.23827838897705, "val_acc": 44.0}
{"epoch": 56, "training_loss": 717.2131395339966, "training_acc": 47.0, "val_loss": 116.78814888000488, "val_acc": 76.0}
{"epoch": 57, "training_loss": 335.25633239746094, "training_acc": 78.0, "val_loss": 99.22045469284058, "val_acc": 72.0}
{"epoch": 58, "training_loss": 226.88623428344727, "training_acc": 76.0, "val_loss": 66.70368909835815, "val_acc": 64.0}
{"epoch": 59, "training_loss": 194.67180061340332, "training_acc": 70.0, "val_loss": 122.08343744277954, "val_acc": 72.0}
{"epoch": 60, "training_loss": 148.5548496246338, "training_acc": 83.0, "val_loss": 111.94522380828857, "val_acc": 56.0}
{"epoch": 61, "training_loss": 260.0216381549835, "training_acc": 62.0, "val_loss": 162.21071481704712, "val_acc": 72.0}
{"epoch": 62, "training_loss": 299.2404019832611, "training_acc": 75.0, "val_loss": 111.9196891784668, "val_acc": 56.0}
{"epoch": 63, "training_loss": 283.220338344574, "training_acc": 57.0, "val_loss": 117.34627485275269, "val_acc": 72.0}
{"epoch": 64, "training_loss": 185.43130350112915, "training_acc": 76.0, "val_loss": 53.49581241607666, "val_acc": 60.0}
{"epoch": 65, "training_loss": 123.97336769104004, "training_acc": 75.0, "val_loss": 99.94205832481384, "val_acc": 72.0}
{"epoch": 66, "training_loss": 126.56614398956299, "training_acc": 82.0, "val_loss": 55.26620149612427, "val_acc": 64.0}
