"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3755.354648590088, "training_acc": 42.0, "val_loss": 2068.681526184082, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6775.949432373047, "training_acc": 72.0, "val_loss": 1030.2724838256836, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3070.1366577148438, "training_acc": 28.0, "val_loss": 835.5786323547363, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3965.723373413086, "training_acc": 72.0, "val_loss": 1502.6865005493164, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5853.170257568359, "training_acc": 72.0, "val_loss": 1052.0536422729492, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3515.4824600219727, "training_acc": 72.0, "val_loss": 437.49728202819824, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1806.4940567016602, "training_acc": 28.0, "val_loss": 313.98253440856934, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1726.4141998291016, "training_acc": 72.0, "val_loss": 615.2984619140625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2219.164810180664, "training_acc": 72.0, "val_loss": 117.0567274093628, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1660.3392486572266, "training_acc": 56.0, "val_loss": 842.9303169250488, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2334.8089847564697, "training_acc": 44.0, "val_loss": 374.10314083099365, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1619.316650390625, "training_acc": 72.0, "val_loss": 321.4381694793701, "val_acc": 72.0}
{"epoch": 12, "training_loss": 825.2453308105469, "training_acc": 72.0, "val_loss": 972.2840309143066, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3740.8407287597656, "training_acc": 28.0, "val_loss": 82.25982189178467, "val_acc": 72.0}
{"epoch": 14, "training_loss": 482.7579517364502, "training_acc": 72.0, "val_loss": 348.98314476013184, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1294.18212890625, "training_acc": 72.0, "val_loss": 34.002891182899475, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1440.8465423583984, "training_acc": 56.0, "val_loss": 820.875072479248, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2245.681468963623, "training_acc": 44.0, "val_loss": 338.704252243042, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1395.1250343322754, "training_acc": 72.0, "val_loss": 301.4827251434326, "val_acc": 72.0}
{"epoch": 19, "training_loss": 834.4123592376709, "training_acc": 72.0, "val_loss": 723.0623722076416, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2608.7505416870117, "training_acc": 28.0, "val_loss": 212.9652738571167, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1192.9887619018555, "training_acc": 72.0, "val_loss": 478.04508209228516, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1732.1415100097656, "training_acc": 72.0, "val_loss": 112.16943264007568, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1271.0603866577148, "training_acc": 58.0, "val_loss": 664.6718978881836, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2177.211368560791, "training_acc": 36.0, "val_loss": 350.8384943008423, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1400.3840713500977, "training_acc": 72.0, "val_loss": 235.1954698562622, "val_acc": 72.0}
{"epoch": 26, "training_loss": 829.1632881164551, "training_acc": 52.0, "val_loss": 115.16448259353638, "val_acc": 72.0}
{"epoch": 27, "training_loss": 466.96656799316406, "training_acc": 72.0, "val_loss": 90.26547074317932, "val_acc": 28.0}
{"epoch": 28, "training_loss": 408.82074546813965, "training_acc": 48.0, "val_loss": 244.54939365386963, "val_acc": 72.0}
{"epoch": 29, "training_loss": 863.7203874588013, "training_acc": 72.0, "val_loss": 159.86682176589966, "val_acc": 28.0}
{"epoch": 30, "training_loss": 646.3947982788086, "training_acc": 42.0, "val_loss": 180.54605722427368, "val_acc": 72.0}
{"epoch": 31, "training_loss": 530.1391048431396, "training_acc": 72.0, "val_loss": 492.2853946685791, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1428.3877429962158, "training_acc": 28.0, "val_loss": 448.8797187805176, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2042.6311416625977, "training_acc": 72.0, "val_loss": 853.9591789245605, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3365.048858642578, "training_acc": 72.0, "val_loss": 665.4948711395264, "val_acc": 72.0}
