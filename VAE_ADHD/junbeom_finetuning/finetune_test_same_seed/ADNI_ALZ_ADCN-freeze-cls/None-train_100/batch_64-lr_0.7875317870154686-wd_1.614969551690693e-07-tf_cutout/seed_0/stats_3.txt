"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4429.015838623047, "training_acc": 38.0, "val_loss": 1940.9296035766602, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6761.251014709473, "training_acc": 72.0, "val_loss": 1354.9440383911133, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4336.582809448242, "training_acc": 28.0, "val_loss": 718.0814743041992, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3270.228858947754, "training_acc": 72.0, "val_loss": 1431.5958976745605, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5729.940246582031, "training_acc": 72.0, "val_loss": 1120.6344604492188, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3806.0353622436523, "training_acc": 72.0, "val_loss": 197.9083776473999, "val_acc": 28.0}
{"epoch": 6, "training_loss": 813.3260650634766, "training_acc": 28.0, "val_loss": 396.39697074890137, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1929.2476348876953, "training_acc": 72.0, "val_loss": 669.596004486084, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2444.263572692871, "training_acc": 72.0, "val_loss": 193.7589168548584, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1487.0695190429688, "training_acc": 58.0, "val_loss": 676.3552188873291, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1978.5571460723877, "training_acc": 44.0, "val_loss": 408.33725929260254, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1663.305778503418, "training_acc": 72.0, "val_loss": 328.06239128112793, "val_acc": 72.0}
{"epoch": 12, "training_loss": 961.9919509887695, "training_acc": 72.0, "val_loss": 868.8976287841797, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3162.498466491699, "training_acc": 28.0, "val_loss": 194.01659965515137, "val_acc": 72.0}
{"epoch": 14, "training_loss": 914.7823543548584, "training_acc": 72.0, "val_loss": 488.6897087097168, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1856.4693794250488, "training_acc": 72.0, "val_loss": 200.37283897399902, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1209.9179229736328, "training_acc": 52.0, "val_loss": 119.8906421661377, "val_acc": 28.0}
{"epoch": 17, "training_loss": 847.2998809814453, "training_acc": 46.0, "val_loss": 722.391414642334, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3150.1333618164062, "training_acc": 72.0, "val_loss": 794.0301418304443, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3022.5493659973145, "training_acc": 72.0, "val_loss": 223.3424186706543, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1248.458251953125, "training_acc": 58.0, "val_loss": 496.453857421875, "val_acc": 28.0}
{"epoch": 21, "training_loss": 1185.613980293274, "training_acc": 56.0, "val_loss": 393.3419704437256, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1698.2685012817383, "training_acc": 72.0, "val_loss": 378.8989067077637, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1171.3450050354004, "training_acc": 72.0, "val_loss": 595.5474853515625, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2172.6948623657227, "training_acc": 28.0, "val_loss": 268.61791610717773, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1709.450180053711, "training_acc": 72.0, "val_loss": 608.7555885314941, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2269.1357345581055, "training_acc": 72.0, "val_loss": 245.57573795318604, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1269.757469177246, "training_acc": 54.0, "val_loss": 286.2377643585205, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1393.2101135253906, "training_acc": 38.0, "val_loss": 538.2870197296143, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2248.3028717041016, "training_acc": 72.0, "val_loss": 468.48511695861816, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1522.1973114013672, "training_acc": 72.0, "val_loss": 473.39911460876465, "val_acc": 28.0}
{"epoch": 31, "training_loss": 1691.1622848510742, "training_acc": 28.0, "val_loss": 275.39398670196533, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1328.1501350402832, "training_acc": 72.0, "val_loss": 537.0308876037598, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2016.3800086975098, "training_acc": 72.0, "val_loss": 210.61749458312988, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1064.587890625, "training_acc": 56.0, "val_loss": 189.85546827316284, "val_acc": 28.0}
{"epoch": 35, "training_loss": 997.1516418457031, "training_acc": 44.0, "val_loss": 610.1778507232666, "val_acc": 72.0}
