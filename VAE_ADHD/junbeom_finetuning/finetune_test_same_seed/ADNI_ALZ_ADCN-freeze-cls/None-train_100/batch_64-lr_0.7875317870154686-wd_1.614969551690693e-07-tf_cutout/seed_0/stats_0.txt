"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3754.0206298828125, "training_acc": 42.0, "val_loss": 2031.3379287719727, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6378.985504150391, "training_acc": 72.0, "val_loss": 1181.4114570617676, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4029.177978515625, "training_acc": 28.0, "val_loss": 645.6930160522461, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3328.4190826416016, "training_acc": 72.0, "val_loss": 1360.240650177002, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5325.874954223633, "training_acc": 72.0, "val_loss": 961.3824844360352, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3355.451072692871, "training_acc": 72.0, "val_loss": 656.4458847045898, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2584.7970962524414, "training_acc": 28.0, "val_loss": 247.4437952041626, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1209.135570526123, "training_acc": 72.0, "val_loss": 538.6680126190186, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1977.9554443359375, "training_acc": 72.0, "val_loss": 127.4998426437378, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1843.373031616211, "training_acc": 50.0, "val_loss": 691.2968635559082, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2072.7004051208496, "training_acc": 44.0, "val_loss": 489.0566349029541, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2079.325035095215, "training_acc": 72.0, "val_loss": 496.4956760406494, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1669.594913482666, "training_acc": 72.0, "val_loss": 290.1970148086548, "val_acc": 28.0}
{"epoch": 13, "training_loss": 949.6408023834229, "training_acc": 28.0, "val_loss": 426.4636993408203, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2233.550277709961, "training_acc": 72.0, "val_loss": 834.296703338623, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3253.3162384033203, "training_acc": 72.0, "val_loss": 562.1897220611572, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1660.1971130371094, "training_acc": 72.0, "val_loss": 697.4898338317871, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3086.819564819336, "training_acc": 28.0, "val_loss": 19.325163960456848, "val_acc": 72.0}
{"epoch": 18, "training_loss": 518.9014739990234, "training_acc": 72.0, "val_loss": 283.65211486816406, "val_acc": 72.0}
{"epoch": 19, "training_loss": 980.3899841308594, "training_acc": 72.0, "val_loss": 278.2611608505249, "val_acc": 28.0}
{"epoch": 20, "training_loss": 757.756998538971, "training_acc": 46.0, "val_loss": 57.23848342895508, "val_acc": 72.0}
{"epoch": 21, "training_loss": 307.48670196533203, "training_acc": 62.0, "val_loss": 175.93694925308228, "val_acc": 72.0}
{"epoch": 22, "training_loss": 790.6413078308105, "training_acc": 72.0, "val_loss": 147.52105474472046, "val_acc": 72.0}
{"epoch": 23, "training_loss": 756.3016319274902, "training_acc": 54.0, "val_loss": 86.65295839309692, "val_acc": 72.0}
{"epoch": 24, "training_loss": 364.9492950439453, "training_acc": 72.0, "val_loss": 76.65466070175171, "val_acc": 28.0}
{"epoch": 25, "training_loss": 559.3585968017578, "training_acc": 42.0, "val_loss": 301.19574069976807, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1085.041971206665, "training_acc": 72.0, "val_loss": 17.251895368099213, "val_acc": 40.0}
{"epoch": 27, "training_loss": 162.6418170928955, "training_acc": 38.0, "val_loss": 315.3456449508667, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1460.1198501586914, "training_acc": 72.0, "val_loss": 483.1723690032959, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1725.3410835266113, "training_acc": 72.0, "val_loss": 64.09966945648193, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1688.6029968261719, "training_acc": 50.0, "val_loss": 800.6754875183105, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2498.695858001709, "training_acc": 36.0, "val_loss": 339.6218776702881, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1376.4696731567383, "training_acc": 72.0, "val_loss": 261.1440420150757, "val_acc": 72.0}
{"epoch": 33, "training_loss": 760.222953915596, "training_acc": 73.0, "val_loss": 502.1754741668701, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1377.7760155200958, "training_acc": 40.0, "val_loss": 91.52478575706482, "val_acc": 72.0}
{"epoch": 35, "training_loss": 253.64764213562012, "training_acc": 72.0, "val_loss": 359.83331203460693, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1019.5819597244263, "training_acc": 46.0, "val_loss": 166.05677604675293, "val_acc": 72.0}
{"epoch": 37, "training_loss": 564.8499088287354, "training_acc": 72.0, "val_loss": 326.09167098999023, "val_acc": 28.0}
{"epoch": 38, "training_loss": 919.6870007514954, "training_acc": 42.0, "val_loss": 26.14777386188507, "val_acc": 72.0}
{"epoch": 39, "training_loss": 319.2267894744873, "training_acc": 64.0, "val_loss": 135.53063869476318, "val_acc": 72.0}
{"epoch": 40, "training_loss": 653.442024230957, "training_acc": 72.0, "val_loss": 87.85309195518494, "val_acc": 72.0}
{"epoch": 41, "training_loss": 771.6779441833496, "training_acc": 58.0, "val_loss": 25.10429620742798, "val_acc": 28.0}
{"epoch": 42, "training_loss": 536.723747253418, "training_acc": 47.0, "val_loss": 577.8767108917236, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2330.1860733032227, "training_acc": 72.0, "val_loss": 500.79522132873535, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1651.693618774414, "training_acc": 72.0, "val_loss": 266.8394088745117, "val_acc": 28.0}
{"epoch": 45, "training_loss": 851.6800022125244, "training_acc": 28.0, "val_loss": 382.37178325653076, "val_acc": 72.0}
