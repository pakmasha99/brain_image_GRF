"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 247.95282173156738, "training_acc": 52.0, "val_loss": 206.57691955566406, "val_acc": 72.0}
{"epoch": 1, "training_loss": 614.0599822998047, "training_acc": 72.0, "val_loss": 255.2161693572998, "val_acc": 28.0}
{"epoch": 2, "training_loss": 884.202823638916, "training_acc": 28.0, "val_loss": 41.31626784801483, "val_acc": 72.0}
{"epoch": 3, "training_loss": 245.21266651153564, "training_acc": 72.0, "val_loss": 114.41634893417358, "val_acc": 72.0}
{"epoch": 4, "training_loss": 439.160062789917, "training_acc": 72.0, "val_loss": 63.744986057281494, "val_acc": 72.0}
{"epoch": 5, "training_loss": 201.2254707813263, "training_acc": 72.0, "val_loss": 96.07517719268799, "val_acc": 28.0}
{"epoch": 6, "training_loss": 305.88616943359375, "training_acc": 28.0, "val_loss": 47.35836386680603, "val_acc": 72.0}
{"epoch": 7, "training_loss": 250.41313552856445, "training_acc": 72.0, "val_loss": 88.8720154762268, "val_acc": 72.0}
{"epoch": 8, "training_loss": 333.54712104797363, "training_acc": 72.0, "val_loss": 41.67408645153046, "val_acc": 72.0}
{"epoch": 9, "training_loss": 151.0144181251526, "training_acc": 54.0, "val_loss": 41.2045955657959, "val_acc": 28.0}
{"epoch": 10, "training_loss": 122.78067421913147, "training_acc": 48.0, "val_loss": 34.09488499164581, "val_acc": 72.0}
{"epoch": 11, "training_loss": 131.00920343399048, "training_acc": 72.0, "val_loss": 15.936367213726044, "val_acc": 72.0}
{"epoch": 12, "training_loss": 84.88422870635986, "training_acc": 56.0, "val_loss": 14.77997601032257, "val_acc": 72.0}
{"epoch": 13, "training_loss": 93.89619588851929, "training_acc": 72.0, "val_loss": 18.479035794734955, "val_acc": 72.0}
{"epoch": 14, "training_loss": 80.74578046798706, "training_acc": 56.0, "val_loss": 15.63107967376709, "val_acc": 28.0}
{"epoch": 15, "training_loss": 64.74667930603027, "training_acc": 72.0, "val_loss": 19.397632777690887, "val_acc": 72.0}
{"epoch": 16, "training_loss": 73.75000476837158, "training_acc": 72.0, "val_loss": 17.286786437034607, "val_acc": 28.0}
{"epoch": 17, "training_loss": 60.903624176979065, "training_acc": 74.0, "val_loss": 24.69002902507782, "val_acc": 72.0}
{"epoch": 18, "training_loss": 98.23023653030396, "training_acc": 72.0, "val_loss": 15.025930106639862, "val_acc": 72.0}
{"epoch": 19, "training_loss": 76.56008386611938, "training_acc": 56.0, "val_loss": 17.473122477531433, "val_acc": 72.0}
{"epoch": 20, "training_loss": 74.98791432380676, "training_acc": 72.0, "val_loss": 15.809963643550873, "val_acc": 72.0}
{"epoch": 21, "training_loss": 68.50519108772278, "training_acc": 58.0, "val_loss": 14.769162237644196, "val_acc": 72.0}
{"epoch": 22, "training_loss": 63.45400261878967, "training_acc": 72.0, "val_loss": 15.374292433261871, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.37484073638916, "training_acc": 72.0, "val_loss": 15.754175186157227, "val_acc": 28.0}
{"epoch": 24, "training_loss": 58.23021101951599, "training_acc": 72.0, "val_loss": 20.009975135326385, "val_acc": 72.0}
{"epoch": 25, "training_loss": 73.62786149978638, "training_acc": 72.0, "val_loss": 20.675837993621826, "val_acc": 28.0}
{"epoch": 26, "training_loss": 69.01844048500061, "training_acc": 52.0, "val_loss": 24.897734820842743, "val_acc": 72.0}
{"epoch": 27, "training_loss": 99.75347471237183, "training_acc": 72.0, "val_loss": 18.140609562397003, "val_acc": 28.0}
{"epoch": 28, "training_loss": 78.07039761543274, "training_acc": 28.0, "val_loss": 24.131524562835693, "val_acc": 72.0}
{"epoch": 29, "training_loss": 102.16259908676147, "training_acc": 72.0, "val_loss": 15.803451836109161, "val_acc": 72.0}
{"epoch": 30, "training_loss": 89.96912813186646, "training_acc": 56.0, "val_loss": 16.06581211090088, "val_acc": 72.0}
{"epoch": 31, "training_loss": 81.01018762588501, "training_acc": 72.0, "val_loss": 16.06570929288864, "val_acc": 72.0}
{"epoch": 32, "training_loss": 76.94640350341797, "training_acc": 58.0, "val_loss": 15.21310806274414, "val_acc": 72.0}
{"epoch": 33, "training_loss": 67.4273271560669, "training_acc": 72.0, "val_loss": 15.08418619632721, "val_acc": 72.0}
{"epoch": 34, "training_loss": 78.69686269760132, "training_acc": 52.0, "val_loss": 19.95321661233902, "val_acc": 72.0}
{"epoch": 35, "training_loss": 83.0018253326416, "training_acc": 72.0, "val_loss": 14.876003563404083, "val_acc": 72.0}
{"epoch": 36, "training_loss": 62.48342442512512, "training_acc": 62.0, "val_loss": 14.757639169692993, "val_acc": 72.0}
{"epoch": 37, "training_loss": 57.89584410190582, "training_acc": 72.0, "val_loss": 19.180192053318024, "val_acc": 72.0}
{"epoch": 38, "training_loss": 73.69165921211243, "training_acc": 72.0, "val_loss": 15.688811242580414, "val_acc": 28.0}
{"epoch": 39, "training_loss": 59.97440695762634, "training_acc": 72.0, "val_loss": 17.31618493795395, "val_acc": 72.0}
{"epoch": 40, "training_loss": 67.07525610923767, "training_acc": 72.0, "val_loss": 15.37708193063736, "val_acc": 28.0}
{"epoch": 41, "training_loss": 68.36919975280762, "training_acc": 72.0, "val_loss": 15.418359637260437, "val_acc": 28.0}
{"epoch": 42, "training_loss": 78.73203897476196, "training_acc": 44.0, "val_loss": 33.69998037815094, "val_acc": 72.0}
{"epoch": 43, "training_loss": 152.49379587173462, "training_acc": 72.0, "val_loss": 29.983273148536682, "val_acc": 72.0}
{"epoch": 44, "training_loss": 165.61212015151978, "training_acc": 44.0, "val_loss": 15.81394374370575, "val_acc": 72.0}
{"epoch": 45, "training_loss": 77.4234709739685, "training_acc": 72.0, "val_loss": 16.325537860393524, "val_acc": 72.0}
{"epoch": 46, "training_loss": 81.74346494674683, "training_acc": 56.0, "val_loss": 16.38121008872986, "val_acc": 72.0}
{"epoch": 47, "training_loss": 69.48735523223877, "training_acc": 72.0, "val_loss": 14.870534837245941, "val_acc": 72.0}
{"epoch": 48, "training_loss": 56.71333026885986, "training_acc": 72.0, "val_loss": 19.808585941791534, "val_acc": 28.0}
{"epoch": 49, "training_loss": 88.2558069229126, "training_acc": 40.0, "val_loss": 19.309499859809875, "val_acc": 72.0}
{"epoch": 50, "training_loss": 81.58804631233215, "training_acc": 54.0, "val_loss": 14.885357022285461, "val_acc": 72.0}
{"epoch": 51, "training_loss": 70.41348671913147, "training_acc": 72.0, "val_loss": 15.611124038696289, "val_acc": 28.0}
{"epoch": 52, "training_loss": 62.585392475128174, "training_acc": 72.0, "val_loss": 15.027186274528503, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.96551871299744, "training_acc": 72.0, "val_loss": 14.755599200725555, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.51734471321106, "training_acc": 72.0, "val_loss": 16.00991040468216, "val_acc": 28.0}
{"epoch": 55, "training_loss": 60.741931438446045, "training_acc": 72.0, "val_loss": 17.84072071313858, "val_acc": 72.0}
{"epoch": 56, "training_loss": 68.38295769691467, "training_acc": 72.0, "val_loss": 15.806970000267029, "val_acc": 28.0}
{"epoch": 57, "training_loss": 62.861337423324585, "training_acc": 72.0, "val_loss": 15.12429416179657, "val_acc": 72.0}
{"epoch": 58, "training_loss": 61.995267152786255, "training_acc": 72.0, "val_loss": 15.036340057849884, "val_acc": 72.0}
{"epoch": 59, "training_loss": 60.302127838134766, "training_acc": 72.0, "val_loss": 15.26467353105545, "val_acc": 72.0}
{"epoch": 60, "training_loss": 60.771690368652344, "training_acc": 72.0, "val_loss": 18.701936304569244, "val_acc": 72.0}
{"epoch": 61, "training_loss": 70.06932973861694, "training_acc": 72.0, "val_loss": 23.094719648361206, "val_acc": 28.0}
{"epoch": 62, "training_loss": 84.4122884273529, "training_acc": 44.0, "val_loss": 19.157487154006958, "val_acc": 72.0}
{"epoch": 63, "training_loss": 72.76078295707703, "training_acc": 72.0, "val_loss": 15.362310409545898, "val_acc": 28.0}
{"epoch": 64, "training_loss": 61.49661731719971, "training_acc": 72.0, "val_loss": 15.641088783740997, "val_acc": 72.0}
{"epoch": 65, "training_loss": 62.37833905220032, "training_acc": 72.0, "val_loss": 14.752574265003204, "val_acc": 72.0}
{"epoch": 66, "training_loss": 60.30422759056091, "training_acc": 72.0, "val_loss": 14.808088541030884, "val_acc": 72.0}
{"epoch": 67, "training_loss": 63.50316905975342, "training_acc": 72.0, "val_loss": 20.77944576740265, "val_acc": 72.0}
{"epoch": 68, "training_loss": 83.18853330612183, "training_acc": 72.0, "val_loss": 26.853308081626892, "val_acc": 28.0}
{"epoch": 69, "training_loss": 95.10866045951843, "training_acc": 42.0, "val_loss": 17.779336869716644, "val_acc": 72.0}
{"epoch": 70, "training_loss": 82.14713597297668, "training_acc": 50.0, "val_loss": 19.734561443328857, "val_acc": 72.0}
{"epoch": 71, "training_loss": 76.32001376152039, "training_acc": 72.0, "val_loss": 16.23595952987671, "val_acc": 28.0}
{"epoch": 72, "training_loss": 63.53511166572571, "training_acc": 72.0, "val_loss": 21.29257470369339, "val_acc": 72.0}
{"epoch": 73, "training_loss": 79.25878143310547, "training_acc": 72.0, "val_loss": 23.09313714504242, "val_acc": 28.0}
{"epoch": 74, "training_loss": 76.93030118942261, "training_acc": 48.0, "val_loss": 21.513324975967407, "val_acc": 72.0}
{"epoch": 75, "training_loss": 84.70292210578918, "training_acc": 72.0, "val_loss": 14.75905328989029, "val_acc": 72.0}
{"epoch": 76, "training_loss": 61.1473650932312, "training_acc": 72.0, "val_loss": 15.458819270133972, "val_acc": 28.0}
{"epoch": 77, "training_loss": 60.78708624839783, "training_acc": 72.0, "val_loss": 17.14824289083481, "val_acc": 72.0}
{"epoch": 78, "training_loss": 64.70586037635803, "training_acc": 72.0, "val_loss": 24.524636566638947, "val_acc": 28.0}
{"epoch": 79, "training_loss": 92.06398510932922, "training_acc": 44.0, "val_loss": 21.933849155902863, "val_acc": 72.0}
{"epoch": 80, "training_loss": 102.96479034423828, "training_acc": 48.0, "val_loss": 20.127420127391815, "val_acc": 72.0}
{"epoch": 81, "training_loss": 80.65385365486145, "training_acc": 72.0, "val_loss": 17.62770414352417, "val_acc": 28.0}
{"epoch": 82, "training_loss": 66.67428588867188, "training_acc": 46.0, "val_loss": 20.17425447702408, "val_acc": 72.0}
{"epoch": 83, "training_loss": 77.10011219978333, "training_acc": 72.0, "val_loss": 32.05728530883789, "val_acc": 28.0}
{"epoch": 84, "training_loss": 102.85780310630798, "training_acc": 46.0, "val_loss": 23.88245314359665, "val_acc": 72.0}
