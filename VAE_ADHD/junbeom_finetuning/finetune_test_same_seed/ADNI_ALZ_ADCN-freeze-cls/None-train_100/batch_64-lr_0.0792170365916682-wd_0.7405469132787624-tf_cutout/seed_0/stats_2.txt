"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 453.11913681030273, "training_acc": 40.0, "val_loss": 188.72100114822388, "val_acc": 72.0}
{"epoch": 1, "training_loss": 600.7669105529785, "training_acc": 72.0, "val_loss": 191.7935609817505, "val_acc": 28.0}
{"epoch": 2, "training_loss": 651.295389175415, "training_acc": 28.0, "val_loss": 54.03774976730347, "val_acc": 72.0}
{"epoch": 3, "training_loss": 339.691125869751, "training_acc": 72.0, "val_loss": 116.94979667663574, "val_acc": 72.0}
{"epoch": 4, "training_loss": 434.6562271118164, "training_acc": 72.0, "val_loss": 51.71584486961365, "val_acc": 72.0}
{"epoch": 5, "training_loss": 142.40248656272888, "training_acc": 62.0, "val_loss": 65.58722257614136, "val_acc": 28.0}
{"epoch": 6, "training_loss": 216.85518670082092, "training_acc": 36.0, "val_loss": 29.024845361709595, "val_acc": 72.0}
{"epoch": 7, "training_loss": 105.83688306808472, "training_acc": 72.0, "val_loss": 20.311008393764496, "val_acc": 28.0}
{"epoch": 8, "training_loss": 83.23058342933655, "training_acc": 28.0, "val_loss": 26.52895748615265, "val_acc": 72.0}
{"epoch": 9, "training_loss": 132.77289295196533, "training_acc": 72.0, "val_loss": 22.394543886184692, "val_acc": 72.0}
{"epoch": 10, "training_loss": 94.8840103149414, "training_acc": 58.0, "val_loss": 19.140855967998505, "val_acc": 28.0}
{"epoch": 11, "training_loss": 88.24208688735962, "training_acc": 42.0, "val_loss": 28.37710976600647, "val_acc": 72.0}
{"epoch": 12, "training_loss": 96.73980498313904, "training_acc": 72.0, "val_loss": 29.482632875442505, "val_acc": 28.0}
{"epoch": 13, "training_loss": 98.8556661605835, "training_acc": 42.0, "val_loss": 20.156757533550262, "val_acc": 72.0}
{"epoch": 14, "training_loss": 81.86239004135132, "training_acc": 72.0, "val_loss": 21.545082330703735, "val_acc": 28.0}
{"epoch": 15, "training_loss": 80.27715611457825, "training_acc": 28.0, "val_loss": 21.92283272743225, "val_acc": 72.0}
{"epoch": 16, "training_loss": 88.79518818855286, "training_acc": 72.0, "val_loss": 15.050262212753296, "val_acc": 72.0}
{"epoch": 17, "training_loss": 74.78279399871826, "training_acc": 56.0, "val_loss": 15.551421046257019, "val_acc": 72.0}
{"epoch": 18, "training_loss": 66.31830477714539, "training_acc": 72.0, "val_loss": 15.707358717918396, "val_acc": 72.0}
{"epoch": 19, "training_loss": 64.51521563529968, "training_acc": 58.0, "val_loss": 14.937271177768707, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.36906385421753, "training_acc": 72.0, "val_loss": 15.7687246799469, "val_acc": 72.0}
{"epoch": 21, "training_loss": 63.3270845413208, "training_acc": 72.0, "val_loss": 14.882893860340118, "val_acc": 72.0}
{"epoch": 22, "training_loss": 58.29188585281372, "training_acc": 72.0, "val_loss": 17.063279449939728, "val_acc": 72.0}
{"epoch": 23, "training_loss": 64.17343139648438, "training_acc": 72.0, "val_loss": 18.98406744003296, "val_acc": 28.0}
{"epoch": 24, "training_loss": 66.95381212234497, "training_acc": 48.0, "val_loss": 19.741801917552948, "val_acc": 72.0}
{"epoch": 25, "training_loss": 72.10494184494019, "training_acc": 72.0, "val_loss": 20.64109891653061, "val_acc": 28.0}
{"epoch": 26, "training_loss": 70.83261299133301, "training_acc": 48.0, "val_loss": 20.701496303081512, "val_acc": 72.0}
{"epoch": 27, "training_loss": 75.82360577583313, "training_acc": 72.0, "val_loss": 19.405116140842438, "val_acc": 28.0}
{"epoch": 28, "training_loss": 66.34524130821228, "training_acc": 50.0, "val_loss": 21.67929857969284, "val_acc": 72.0}
{"epoch": 29, "training_loss": 82.12770509719849, "training_acc": 72.0, "val_loss": 16.321775317192078, "val_acc": 28.0}
{"epoch": 30, "training_loss": 63.6486930847168, "training_acc": 72.0, "val_loss": 15.465186536312103, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.35284423828125, "training_acc": 72.0, "val_loss": 17.401671409606934, "val_acc": 28.0}
{"epoch": 32, "training_loss": 66.2220230102539, "training_acc": 52.0, "val_loss": 17.376144230365753, "val_acc": 72.0}
{"epoch": 33, "training_loss": 75.39405798912048, "training_acc": 52.0, "val_loss": 16.588564217090607, "val_acc": 72.0}
{"epoch": 34, "training_loss": 65.20421981811523, "training_acc": 72.0, "val_loss": 15.640518069267273, "val_acc": 28.0}
{"epoch": 35, "training_loss": 61.09335279464722, "training_acc": 72.0, "val_loss": 17.158423364162445, "val_acc": 72.0}
{"epoch": 36, "training_loss": 64.89539885520935, "training_acc": 72.0, "val_loss": 23.78324121236801, "val_acc": 28.0}
{"epoch": 37, "training_loss": 87.69287776947021, "training_acc": 44.0, "val_loss": 20.426569879055023, "val_acc": 72.0}
{"epoch": 38, "training_loss": 75.58452200889587, "training_acc": 72.0, "val_loss": 16.155023872852325, "val_acc": 28.0}
{"epoch": 39, "training_loss": 67.47743368148804, "training_acc": 72.0, "val_loss": 15.968555212020874, "val_acc": 72.0}
{"epoch": 40, "training_loss": 62.44131565093994, "training_acc": 66.0, "val_loss": 14.883176982402802, "val_acc": 72.0}
