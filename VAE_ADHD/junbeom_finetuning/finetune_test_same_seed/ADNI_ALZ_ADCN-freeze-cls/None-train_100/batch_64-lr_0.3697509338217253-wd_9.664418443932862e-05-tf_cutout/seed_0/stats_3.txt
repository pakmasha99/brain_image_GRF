"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1239.2360305786133, "training_acc": 50.0, "val_loss": 1079.1085243225098, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3453.0589179992676, "training_acc": 72.0, "val_loss": 960.3100776672363, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3211.9887466430664, "training_acc": 28.0, "val_loss": 289.9362802505493, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1657.5673828125, "training_acc": 72.0, "val_loss": 673.0765342712402, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2567.5025482177734, "training_acc": 72.0, "val_loss": 419.0948963165283, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1301.0376348495483, "training_acc": 72.0, "val_loss": 665.5490398406982, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2695.474838256836, "training_acc": 28.0, "val_loss": 128.81124019622803, "val_acc": 28.0}
{"epoch": 7, "training_loss": 720.6111373901367, "training_acc": 48.0, "val_loss": 669.8495864868164, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2831.7312088012695, "training_acc": 72.0, "val_loss": 916.4422988891602, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3585.4684829711914, "training_acc": 72.0, "val_loss": 780.9836387634277, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2776.2061157226562, "training_acc": 72.0, "val_loss": 331.8168878555298, "val_acc": 72.0}
{"epoch": 11, "training_loss": 819.488484621048, "training_acc": 72.0, "val_loss": 665.2778148651123, "val_acc": 28.0}
{"epoch": 12, "training_loss": 2665.6004943847656, "training_acc": 28.0, "val_loss": 169.2483425140381, "val_acc": 28.0}
{"epoch": 13, "training_loss": 748.6075630187988, "training_acc": 48.0, "val_loss": 587.3685836791992, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2449.351776123047, "training_acc": 72.0, "val_loss": 823.4348297119141, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3241.495086669922, "training_acc": 72.0, "val_loss": 728.1313419342041, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2561.1453552246094, "training_acc": 72.0, "val_loss": 332.914662361145, "val_acc": 72.0}
{"epoch": 17, "training_loss": 872.2870652675629, "training_acc": 72.0, "val_loss": 824.4282722473145, "val_acc": 28.0}
{"epoch": 18, "training_loss": 3614.6660766601562, "training_acc": 28.0, "val_loss": 766.6860103607178, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1926.3583755493164, "training_acc": 41.0, "val_loss": 347.56438732147217, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1495.7101860046387, "training_acc": 72.0, "val_loss": 720.7334041595459, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2952.518798828125, "training_acc": 72.0, "val_loss": 763.2274150848389, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2864.596481323242, "training_acc": 72.0, "val_loss": 479.95572090148926, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1578.9480056762695, "training_acc": 72.0, "val_loss": 152.84887552261353, "val_acc": 28.0}
{"epoch": 24, "training_loss": 774.0443229675293, "training_acc": 28.0, "val_loss": 25.976207852363586, "val_acc": 68.0}
{"epoch": 25, "training_loss": 180.25940799713135, "training_acc": 72.0, "val_loss": 54.81869578361511, "val_acc": 72.0}
{"epoch": 26, "training_loss": 236.74961948394775, "training_acc": 60.0, "val_loss": 55.78294396400452, "val_acc": 72.0}
{"epoch": 27, "training_loss": 212.99692726135254, "training_acc": 72.0, "val_loss": 29.348403215408325, "val_acc": 32.0}
{"epoch": 28, "training_loss": 143.3908977508545, "training_acc": 56.0, "val_loss": 39.35821056365967, "val_acc": 72.0}
{"epoch": 29, "training_loss": 404.1703472137451, "training_acc": 48.0, "val_loss": 53.77589464187622, "val_acc": 72.0}
{"epoch": 30, "training_loss": 304.5212707519531, "training_acc": 72.0, "val_loss": 46.42359912395477, "val_acc": 72.0}
{"epoch": 31, "training_loss": 434.4885711669922, "training_acc": 54.0, "val_loss": 21.032874286174774, "val_acc": 68.0}
{"epoch": 32, "training_loss": 210.44865798950195, "training_acc": 73.0, "val_loss": 152.51721143722534, "val_acc": 72.0}
{"epoch": 33, "training_loss": 532.025146484375, "training_acc": 72.0, "val_loss": 49.662595987319946, "val_acc": 28.0}
{"epoch": 34, "training_loss": 165.04067134857178, "training_acc": 42.0, "val_loss": 25.490665435791016, "val_acc": 52.0}
{"epoch": 35, "training_loss": 102.73617029190063, "training_acc": 62.0, "val_loss": 26.419597864151, "val_acc": 52.0}
{"epoch": 36, "training_loss": 101.62090587615967, "training_acc": 66.0, "val_loss": 21.058185398578644, "val_acc": 72.0}
{"epoch": 37, "training_loss": 63.8035671710968, "training_acc": 64.0, "val_loss": 74.88672733306885, "val_acc": 72.0}
{"epoch": 38, "training_loss": 285.86511421203613, "training_acc": 72.0, "val_loss": 42.22111105918884, "val_acc": 32.0}
{"epoch": 39, "training_loss": 213.59042167663574, "training_acc": 43.0, "val_loss": 39.6060585975647, "val_acc": 68.0}
{"epoch": 40, "training_loss": 477.65099334716797, "training_acc": 46.0, "val_loss": 38.885730504989624, "val_acc": 68.0}
{"epoch": 41, "training_loss": 184.61742639541626, "training_acc": 72.0, "val_loss": 27.545756101608276, "val_acc": 68.0}
{"epoch": 42, "training_loss": 393.59642791748047, "training_acc": 52.0, "val_loss": 26.39070749282837, "val_acc": 72.0}
{"epoch": 43, "training_loss": 128.52792358398438, "training_acc": 72.0, "val_loss": 20.913779735565186, "val_acc": 72.0}
{"epoch": 44, "training_loss": 118.79585552215576, "training_acc": 63.0, "val_loss": 85.14472842216492, "val_acc": 72.0}
{"epoch": 45, "training_loss": 344.63342237472534, "training_acc": 72.0, "val_loss": 60.488325357437134, "val_acc": 72.0}
{"epoch": 46, "training_loss": 263.38982486724854, "training_acc": 58.0, "val_loss": 55.136680603027344, "val_acc": 72.0}
{"epoch": 47, "training_loss": 210.19086956977844, "training_acc": 72.0, "val_loss": 32.49412775039673, "val_acc": 40.0}
{"epoch": 48, "training_loss": 134.9869556427002, "training_acc": 57.0, "val_loss": 26.39450430870056, "val_acc": 72.0}
{"epoch": 49, "training_loss": 285.6497173309326, "training_acc": 56.0, "val_loss": 49.9521404504776, "val_acc": 68.0}
{"epoch": 50, "training_loss": 229.74549674987793, "training_acc": 72.0, "val_loss": 29.362040758132935, "val_acc": 72.0}
{"epoch": 51, "training_loss": 232.5373363494873, "training_acc": 65.0, "val_loss": 23.126299679279327, "val_acc": 68.0}
{"epoch": 52, "training_loss": 135.18464374542236, "training_acc": 73.0, "val_loss": 23.544669151306152, "val_acc": 72.0}
{"epoch": 53, "training_loss": 162.2934045791626, "training_acc": 53.0, "val_loss": 122.6963758468628, "val_acc": 72.0}
{"epoch": 54, "training_loss": 639.4595642089844, "training_acc": 72.0, "val_loss": 172.48445749282837, "val_acc": 72.0}
{"epoch": 55, "training_loss": 511.3883056640625, "training_acc": 72.0, "val_loss": 282.63561725616455, "val_acc": 28.0}
{"epoch": 56, "training_loss": 965.6833477020264, "training_acc": 28.0, "val_loss": 150.60878992080688, "val_acc": 72.0}
{"epoch": 57, "training_loss": 842.2044258117676, "training_acc": 72.0, "val_loss": 326.26237869262695, "val_acc": 72.0}
{"epoch": 58, "training_loss": 1223.0722122192383, "training_acc": 72.0, "val_loss": 141.25741720199585, "val_acc": 72.0}
{"epoch": 59, "training_loss": 539.1346492767334, "training_acc": 54.0, "val_loss": 42.09309220314026, "val_acc": 36.0}
{"epoch": 60, "training_loss": 290.8374500274658, "training_acc": 57.0, "val_loss": 207.79688358306885, "val_acc": 72.0}
{"epoch": 61, "training_loss": 796.1088962554932, "training_acc": 72.0, "val_loss": 83.08306932449341, "val_acc": 72.0}
{"epoch": 62, "training_loss": 488.98934745788574, "training_acc": 56.0, "val_loss": 83.76467823982239, "val_acc": 28.0}
