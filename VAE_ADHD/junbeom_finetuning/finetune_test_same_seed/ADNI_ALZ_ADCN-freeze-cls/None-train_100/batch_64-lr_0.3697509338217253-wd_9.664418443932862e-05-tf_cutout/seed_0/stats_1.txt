"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1146.313835144043, "training_acc": 71.0, "val_loss": 1189.9259567260742, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3486.9978256225586, "training_acc": 72.0, "val_loss": 1238.456153869629, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4298.612564086914, "training_acc": 28.0, "val_loss": 211.95709705352783, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1354.8982238769531, "training_acc": 72.0, "val_loss": 595.8258152008057, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2225.777900695801, "training_acc": 72.0, "val_loss": 281.62243366241455, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1044.0782852172852, "training_acc": 52.0, "val_loss": 18.549257516860962, "val_acc": 28.0}
{"epoch": 6, "training_loss": 124.54478168487549, "training_acc": 58.0, "val_loss": 223.89719486236572, "val_acc": 72.0}
{"epoch": 7, "training_loss": 818.4558563232422, "training_acc": 72.0, "val_loss": 18.992337584495544, "val_acc": 72.0}
{"epoch": 8, "training_loss": 918.690990447998, "training_acc": 52.0, "val_loss": 331.0368299484253, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1098.0787315368652, "training_acc": 44.0, "val_loss": 393.18509101867676, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1609.3229637145996, "training_acc": 72.0, "val_loss": 437.9188537597656, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1574.906421661377, "training_acc": 72.0, "val_loss": 118.49299669265747, "val_acc": 72.0}
{"epoch": 12, "training_loss": 866.5751266479492, "training_acc": 56.0, "val_loss": 397.78666496276855, "val_acc": 28.0}
{"epoch": 13, "training_loss": 924.4042711257935, "training_acc": 54.0, "val_loss": 194.74923610687256, "val_acc": 72.0}
{"epoch": 14, "training_loss": 817.8410224914551, "training_acc": 72.0, "val_loss": 168.16657781600952, "val_acc": 72.0}
{"epoch": 15, "training_loss": 494.05130767822266, "training_acc": 70.0, "val_loss": 282.2017192840576, "val_acc": 28.0}
{"epoch": 16, "training_loss": 672.5447826385498, "training_acc": 28.0, "val_loss": 273.71392250061035, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1280.560962677002, "training_acc": 72.0, "val_loss": 490.6588554382324, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1869.350326538086, "training_acc": 72.0, "val_loss": 320.09050846099854, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1004.5443696975708, "training_acc": 72.0, "val_loss": 448.2614994049072, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1764.3590393066406, "training_acc": 28.0, "val_loss": 28.187617659568787, "val_acc": 72.0}
{"epoch": 21, "training_loss": 275.6760654449463, "training_acc": 72.0, "val_loss": 135.73380708694458, "val_acc": 72.0}
{"epoch": 22, "training_loss": 397.0055503845215, "training_acc": 72.0, "val_loss": 325.75361728668213, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1048.4042377471924, "training_acc": 28.0, "val_loss": 216.94235801696777, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1095.9726753234863, "training_acc": 72.0, "val_loss": 453.4496784210205, "val_acc": 72.0}
