"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 71.04007387161255, "training_acc": 28.0, "val_loss": 17.40550696849823, "val_acc": 28.0}
{"epoch": 1, "training_loss": 69.40433192253113, "training_acc": 40.0, "val_loss": 17.01546460390091, "val_acc": 28.0}
{"epoch": 2, "training_loss": 67.68256258964539, "training_acc": 72.0, "val_loss": 16.664794087409973, "val_acc": 28.0}
{"epoch": 3, "training_loss": 66.41150784492493, "training_acc": 72.0, "val_loss": 16.34562611579895, "val_acc": 28.0}
{"epoch": 4, "training_loss": 65.18862223625183, "training_acc": 72.0, "val_loss": 16.062702238559723, "val_acc": 28.0}
{"epoch": 5, "training_loss": 63.914504528045654, "training_acc": 72.0, "val_loss": 15.818983316421509, "val_acc": 28.0}
{"epoch": 6, "training_loss": 63.11165189743042, "training_acc": 72.0, "val_loss": 15.60489684343338, "val_acc": 28.0}
{"epoch": 7, "training_loss": 62.195655822753906, "training_acc": 72.0, "val_loss": 15.425217151641846, "val_acc": 28.0}
{"epoch": 8, "training_loss": 61.61995029449463, "training_acc": 72.0, "val_loss": 15.273568034172058, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.90855050086975, "training_acc": 72.0, "val_loss": 15.152612328529358, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.506691694259644, "training_acc": 72.0, "val_loss": 15.054480731487274, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.14907169342041, "training_acc": 72.0, "val_loss": 14.97926265001297, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.81434369087219, "training_acc": 72.0, "val_loss": 14.923453330993652, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.552958488464355, "training_acc": 72.0, "val_loss": 14.883492887020111, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.532875299453735, "training_acc": 72.0, "val_loss": 14.855064451694489, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.44364953041077, "training_acc": 72.0, "val_loss": 14.838093519210815, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.37075710296631, "training_acc": 72.0, "val_loss": 14.828984439373016, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.270241498947144, "training_acc": 72.0, "val_loss": 14.82497900724411, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.342777490615845, "training_acc": 72.0, "val_loss": 14.823921024799347, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.28284239768982, "training_acc": 72.0, "val_loss": 14.824756979942322, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.26794457435608, "training_acc": 72.0, "val_loss": 14.8267462849617, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.32045388221741, "training_acc": 72.0, "val_loss": 14.829297363758087, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.300334453582764, "training_acc": 72.0, "val_loss": 14.831113815307617, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.296202182769775, "training_acc": 72.0, "val_loss": 14.832445979118347, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.301424980163574, "training_acc": 72.0, "val_loss": 14.833460748195648, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.30646324157715, "training_acc": 72.0, "val_loss": 14.833900332450867, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.32827949523926, "training_acc": 72.0, "val_loss": 14.83352780342102, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.304280281066895, "training_acc": 72.0, "val_loss": 14.833018183708191, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.31555485725403, "training_acc": 72.0, "val_loss": 14.832155406475067, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.302417039871216, "training_acc": 72.0, "val_loss": 14.831307530403137, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.32892155647278, "training_acc": 72.0, "val_loss": 14.83023464679718, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.308425188064575, "training_acc": 72.0, "val_loss": 14.829792082309723, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.30121660232544, "training_acc": 72.0, "val_loss": 14.828316867351532, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.31366562843323, "training_acc": 72.0, "val_loss": 14.827343821525574, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.30483818054199, "training_acc": 72.0, "val_loss": 14.826782047748566, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.282357931137085, "training_acc": 72.0, "val_loss": 14.825892448425293, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.29890489578247, "training_acc": 72.0, "val_loss": 14.825129508972168, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.2808575630188, "training_acc": 72.0, "val_loss": 14.824651181697845, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.28482413291931, "training_acc": 72.0, "val_loss": 14.82391357421875, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.283188581466675, "training_acc": 72.0, "val_loss": 14.823439717292786, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.28624081611633, "training_acc": 72.0, "val_loss": 14.823183417320251, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.27946352958679, "training_acc": 72.0, "val_loss": 14.823374152183533, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.29207992553711, "training_acc": 72.0, "val_loss": 14.823921024799347, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.295456886291504, "training_acc": 72.0, "val_loss": 14.82444852590561, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.28073453903198, "training_acc": 72.0, "val_loss": 14.82461392879486, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.28604984283447, "training_acc": 72.0, "val_loss": 14.824634790420532, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.30525207519531, "training_acc": 72.0, "val_loss": 14.824678003787994, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.3009614944458, "training_acc": 72.0, "val_loss": 14.824318885803223, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.30296301841736, "training_acc": 72.0, "val_loss": 14.824193716049194, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.331167459487915, "training_acc": 72.0, "val_loss": 14.82379138469696, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.283743143081665, "training_acc": 72.0, "val_loss": 14.823371171951294, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.29038619995117, "training_acc": 72.0, "val_loss": 14.822956919670105, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.273767709732056, "training_acc": 72.0, "val_loss": 14.822730422019958, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.29482102394104, "training_acc": 72.0, "val_loss": 14.822694659233093, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.25775218009949, "training_acc": 72.0, "val_loss": 14.822906255722046, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.27981185913086, "training_acc": 72.0, "val_loss": 14.823247492313385, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.28178095817566, "training_acc": 72.0, "val_loss": 14.823812246322632, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.27519607543945, "training_acc": 72.0, "val_loss": 14.824607968330383, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.285935163497925, "training_acc": 72.0, "val_loss": 14.825686812400818, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.29923629760742, "training_acc": 72.0, "val_loss": 14.825652539730072, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.30048727989197, "training_acc": 72.0, "val_loss": 14.825589954853058, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.284093141555786, "training_acc": 72.0, "val_loss": 14.825718104839325, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.28857064247131, "training_acc": 72.0, "val_loss": 14.82582688331604, "val_acc": 72.0}
{"epoch": 63, "training_loss": 59.297931432724, "training_acc": 72.0, "val_loss": 14.825542271137238, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.299076557159424, "training_acc": 72.0, "val_loss": 14.824390411376953, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.28150701522827, "training_acc": 72.0, "val_loss": 14.823545515537262, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.30218148231506, "training_acc": 72.0, "val_loss": 14.822550117969513, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.2918016910553, "training_acc": 72.0, "val_loss": 14.822220802307129, "val_acc": 72.0}
{"epoch": 68, "training_loss": 59.28397738933563, "training_acc": 72.0, "val_loss": 14.822092652320862, "val_acc": 72.0}
{"epoch": 69, "training_loss": 59.2730073928833, "training_acc": 72.0, "val_loss": 14.822117984294891, "val_acc": 72.0}
{"epoch": 70, "training_loss": 59.270427942276, "training_acc": 72.0, "val_loss": 14.822134375572205, "val_acc": 72.0}
{"epoch": 71, "training_loss": 59.29421949386597, "training_acc": 72.0, "val_loss": 14.822350442409515, "val_acc": 72.0}
{"epoch": 72, "training_loss": 59.27307915687561, "training_acc": 72.0, "val_loss": 14.822360873222351, "val_acc": 72.0}
{"epoch": 73, "training_loss": 59.316887855529785, "training_acc": 72.0, "val_loss": 14.822766184806824, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.27918362617493, "training_acc": 72.0, "val_loss": 14.822518825531006, "val_acc": 72.0}
{"epoch": 75, "training_loss": 59.25178670883179, "training_acc": 72.0, "val_loss": 14.82248604297638, "val_acc": 72.0}
{"epoch": 76, "training_loss": 59.28390955924988, "training_acc": 72.0, "val_loss": 14.822301268577576, "val_acc": 72.0}
{"epoch": 77, "training_loss": 59.255253076553345, "training_acc": 72.0, "val_loss": 14.822308719158173, "val_acc": 72.0}
{"epoch": 78, "training_loss": 59.27080512046814, "training_acc": 72.0, "val_loss": 14.8220956325531, "val_acc": 72.0}
{"epoch": 79, "training_loss": 59.27395749092102, "training_acc": 72.0, "val_loss": 14.821836352348328, "val_acc": 72.0}
{"epoch": 80, "training_loss": 59.270179986953735, "training_acc": 72.0, "val_loss": 14.821703732013702, "val_acc": 72.0}
{"epoch": 81, "training_loss": 59.25779461860657, "training_acc": 72.0, "val_loss": 14.821521937847137, "val_acc": 72.0}
{"epoch": 82, "training_loss": 59.296738386154175, "training_acc": 72.0, "val_loss": 14.821413159370422, "val_acc": 72.0}
{"epoch": 83, "training_loss": 59.25805997848511, "training_acc": 72.0, "val_loss": 14.821437001228333, "val_acc": 72.0}
{"epoch": 84, "training_loss": 59.2997522354126, "training_acc": 72.0, "val_loss": 14.821597933769226, "val_acc": 72.0}
{"epoch": 85, "training_loss": 59.31267595291138, "training_acc": 72.0, "val_loss": 14.821985363960266, "val_acc": 72.0}
{"epoch": 86, "training_loss": 59.26593828201294, "training_acc": 72.0, "val_loss": 14.822207391262054, "val_acc": 72.0}
{"epoch": 87, "training_loss": 59.26855206489563, "training_acc": 72.0, "val_loss": 14.822602272033691, "val_acc": 72.0}
{"epoch": 88, "training_loss": 59.28625440597534, "training_acc": 72.0, "val_loss": 14.8226797580719, "val_acc": 72.0}
{"epoch": 89, "training_loss": 59.28276753425598, "training_acc": 72.0, "val_loss": 14.822621643543243, "val_acc": 72.0}
{"epoch": 90, "training_loss": 59.26941394805908, "training_acc": 72.0, "val_loss": 14.822138845920563, "val_acc": 72.0}
{"epoch": 91, "training_loss": 59.29322147369385, "training_acc": 72.0, "val_loss": 14.821918308734894, "val_acc": 72.0}
{"epoch": 92, "training_loss": 59.2553596496582, "training_acc": 72.0, "val_loss": 14.821897447109222, "val_acc": 72.0}
{"epoch": 93, "training_loss": 59.25877523422241, "training_acc": 72.0, "val_loss": 14.821776747703552, "val_acc": 72.0}
{"epoch": 94, "training_loss": 59.27340316772461, "training_acc": 72.0, "val_loss": 14.821691811084747, "val_acc": 72.0}
{"epoch": 95, "training_loss": 59.283929109573364, "training_acc": 72.0, "val_loss": 14.821764826774597, "val_acc": 72.0}
{"epoch": 96, "training_loss": 59.26683163642883, "training_acc": 72.0, "val_loss": 14.82185274362564, "val_acc": 72.0}
{"epoch": 97, "training_loss": 59.30032968521118, "training_acc": 72.0, "val_loss": 14.82190191745758, "val_acc": 72.0}
{"epoch": 98, "training_loss": 59.315879464149475, "training_acc": 72.0, "val_loss": 14.822699129581451, "val_acc": 72.0}
{"epoch": 99, "training_loss": 59.28118848800659, "training_acc": 72.0, "val_loss": 14.822347462177277, "val_acc": 72.0}
{"epoch": 100, "training_loss": 59.29214072227478, "training_acc": 72.0, "val_loss": 14.821739494800568, "val_acc": 72.0}
{"epoch": 101, "training_loss": 59.28777766227722, "training_acc": 72.0, "val_loss": 14.821726083755493, "val_acc": 72.0}
