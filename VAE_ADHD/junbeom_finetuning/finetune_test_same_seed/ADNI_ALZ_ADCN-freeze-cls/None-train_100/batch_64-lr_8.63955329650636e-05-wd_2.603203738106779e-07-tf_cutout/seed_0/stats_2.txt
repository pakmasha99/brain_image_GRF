"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 73.67084527015686, "training_acc": 28.0, "val_loss": 18.049822747707367, "val_acc": 28.0}
{"epoch": 1, "training_loss": 71.84033155441284, "training_acc": 28.0, "val_loss": 17.6115483045578, "val_acc": 28.0}
{"epoch": 2, "training_loss": 70.13170623779297, "training_acc": 28.0, "val_loss": 17.208214104175568, "val_acc": 28.0}
{"epoch": 3, "training_loss": 68.51727724075317, "training_acc": 72.0, "val_loss": 16.84197187423706, "val_acc": 28.0}
{"epoch": 4, "training_loss": 67.11237263679504, "training_acc": 72.0, "val_loss": 16.511377692222595, "val_acc": 28.0}
{"epoch": 5, "training_loss": 65.76326489448547, "training_acc": 72.0, "val_loss": 16.218113899230957, "val_acc": 28.0}
{"epoch": 6, "training_loss": 64.74463391304016, "training_acc": 72.0, "val_loss": 15.95875769853592, "val_acc": 28.0}
{"epoch": 7, "training_loss": 63.62254357337952, "training_acc": 72.0, "val_loss": 15.736807882785797, "val_acc": 28.0}
{"epoch": 8, "training_loss": 62.94605755805969, "training_acc": 72.0, "val_loss": 15.546512603759766, "val_acc": 28.0}
{"epoch": 9, "training_loss": 62.06981348991394, "training_acc": 72.0, "val_loss": 15.390481054782867, "val_acc": 28.0}
{"epoch": 10, "training_loss": 61.597041845321655, "training_acc": 72.0, "val_loss": 15.260235965251923, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.96574902534485, "training_acc": 72.0, "val_loss": 15.156693756580353, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.6208930015564, "training_acc": 72.0, "val_loss": 15.072843432426453, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.20082068443298, "training_acc": 72.0, "val_loss": 15.006960928440094, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.953086137771606, "training_acc": 72.0, "val_loss": 14.954976737499237, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.74646806716919, "training_acc": 72.0, "val_loss": 14.91452306509018, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.65456032752991, "training_acc": 72.0, "val_loss": 14.884041249752045, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.447306871414185, "training_acc": 72.0, "val_loss": 14.862856268882751, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.393245697021484, "training_acc": 72.0, "val_loss": 14.847694337368011, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.35608768463135, "training_acc": 72.0, "val_loss": 14.83796089887619, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.334277868270874, "training_acc": 72.0, "val_loss": 14.832550287246704, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.276870012283325, "training_acc": 72.0, "val_loss": 14.830581843852997, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.307430028915405, "training_acc": 72.0, "val_loss": 14.83071893453598, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.26630139350891, "training_acc": 72.0, "val_loss": 14.832057058811188, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.29255485534668, "training_acc": 72.0, "val_loss": 14.83422964811325, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.353041887283325, "training_acc": 72.0, "val_loss": 14.837074279785156, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.32346510887146, "training_acc": 72.0, "val_loss": 14.838849008083344, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.335034132003784, "training_acc": 72.0, "val_loss": 14.84014093875885, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.342121601104736, "training_acc": 72.0, "val_loss": 14.840196073055267, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.34894895553589, "training_acc": 72.0, "val_loss": 14.839345216751099, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.32625198364258, "training_acc": 72.0, "val_loss": 14.838957786560059, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.31673288345337, "training_acc": 72.0, "val_loss": 14.838333427906036, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.330650806427, "training_acc": 72.0, "val_loss": 14.836952090263367, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.315085649490356, "training_acc": 72.0, "val_loss": 14.83512669801712, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.34411001205444, "training_acc": 72.0, "val_loss": 14.83379453420639, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.311320781707764, "training_acc": 72.0, "val_loss": 14.833006262779236, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.32187581062317, "training_acc": 72.0, "val_loss": 14.832104742527008, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.34024238586426, "training_acc": 72.0, "val_loss": 14.831508696079254, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.2964973449707, "training_acc": 72.0, "val_loss": 14.831307530403137, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.31751322746277, "training_acc": 72.0, "val_loss": 14.830976724624634, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.3196976184845, "training_acc": 72.0, "val_loss": 14.83071893453598, "val_acc": 72.0}
