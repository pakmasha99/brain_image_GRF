"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 859.9207305908203, "training_acc": 72.0, "val_loss": 405.8049201965332, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1236.893970489502, "training_acc": 72.0, "val_loss": 536.1358642578125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1965.5764770507812, "training_acc": 28.0, "val_loss": 43.25443208217621, "val_acc": 72.0}
{"epoch": 3, "training_loss": 356.2489643096924, "training_acc": 72.0, "val_loss": 195.79204320907593, "val_acc": 72.0}
{"epoch": 4, "training_loss": 745.8520469665527, "training_acc": 72.0, "val_loss": 93.61883997917175, "val_acc": 72.0}
{"epoch": 5, "training_loss": 395.34890842437744, "training_acc": 52.0, "val_loss": 21.994805335998535, "val_acc": 28.0}
{"epoch": 6, "training_loss": 216.68281745910645, "training_acc": 38.0, "val_loss": 109.10459756851196, "val_acc": 72.0}
{"epoch": 7, "training_loss": 405.2081937789917, "training_acc": 72.0, "val_loss": 26.323765516281128, "val_acc": 72.0}
{"epoch": 8, "training_loss": 396.54344940185547, "training_acc": 50.0, "val_loss": 129.74401712417603, "val_acc": 28.0}
{"epoch": 9, "training_loss": 386.96845960617065, "training_acc": 48.0, "val_loss": 133.38276147842407, "val_acc": 72.0}
{"epoch": 10, "training_loss": 560.4097671508789, "training_acc": 72.0, "val_loss": 149.98139142990112, "val_acc": 72.0}
{"epoch": 11, "training_loss": 537.0697803497314, "training_acc": 72.0, "val_loss": 30.508461594581604, "val_acc": 72.0}
{"epoch": 12, "training_loss": 398.1035385131836, "training_acc": 52.0, "val_loss": 186.79653406143188, "val_acc": 28.0}
{"epoch": 13, "training_loss": 464.8737053871155, "training_acc": 50.0, "val_loss": 83.36302042007446, "val_acc": 72.0}
{"epoch": 14, "training_loss": 380.75952339172363, "training_acc": 72.0, "val_loss": 103.17260026931763, "val_acc": 72.0}
{"epoch": 15, "training_loss": 352.2602424621582, "training_acc": 72.0, "val_loss": 45.44421136379242, "val_acc": 28.0}
{"epoch": 16, "training_loss": 145.28020572662354, "training_acc": 39.0, "val_loss": 35.59209108352661, "val_acc": 72.0}
{"epoch": 17, "training_loss": 138.6668734550476, "training_acc": 72.0, "val_loss": 19.6806401014328, "val_acc": 28.0}
{"epoch": 18, "training_loss": 79.93994450569153, "training_acc": 28.0, "val_loss": 51.92035436630249, "val_acc": 72.0}
{"epoch": 19, "training_loss": 227.98436069488525, "training_acc": 72.0, "val_loss": 44.40810978412628, "val_acc": 72.0}
{"epoch": 20, "training_loss": 175.0517783164978, "training_acc": 54.0, "val_loss": 16.482849419116974, "val_acc": 72.0}
{"epoch": 21, "training_loss": 82.19038152694702, "training_acc": 72.0, "val_loss": 26.85779631137848, "val_acc": 28.0}
{"epoch": 22, "training_loss": 96.21057605743408, "training_acc": 46.0, "val_loss": 22.54844754934311, "val_acc": 72.0}
{"epoch": 23, "training_loss": 89.84313607215881, "training_acc": 58.0, "val_loss": 22.510109841823578, "val_acc": 72.0}
{"epoch": 24, "training_loss": 83.06260251998901, "training_acc": 72.0, "val_loss": 30.520790815353394, "val_acc": 28.0}
{"epoch": 25, "training_loss": 159.2897891998291, "training_acc": 38.0, "val_loss": 41.95055365562439, "val_acc": 72.0}
{"epoch": 26, "training_loss": 120.12783098220825, "training_acc": 72.0, "val_loss": 95.98577618598938, "val_acc": 28.0}
{"epoch": 27, "training_loss": 287.14781641960144, "training_acc": 40.0, "val_loss": 33.31874907016754, "val_acc": 72.0}
{"epoch": 28, "training_loss": 108.18446278572083, "training_acc": 72.0, "val_loss": 70.68542838096619, "val_acc": 28.0}
{"epoch": 29, "training_loss": 189.90756916999817, "training_acc": 50.0, "val_loss": 43.07648837566376, "val_acc": 72.0}
{"epoch": 30, "training_loss": 152.55350160598755, "training_acc": 72.0, "val_loss": 42.95208752155304, "val_acc": 28.0}
{"epoch": 31, "training_loss": 178.87334156036377, "training_acc": 38.0, "val_loss": 32.8380286693573, "val_acc": 72.0}
{"epoch": 32, "training_loss": 98.27424192428589, "training_acc": 72.0, "val_loss": 31.774553656578064, "val_acc": 28.0}
{"epoch": 33, "training_loss": 186.07001781463623, "training_acc": 38.0, "val_loss": 66.30780100822449, "val_acc": 72.0}
{"epoch": 34, "training_loss": 227.52007389068604, "training_acc": 72.0, "val_loss": 47.02524542808533, "val_acc": 28.0}
{"epoch": 35, "training_loss": 137.68158411979675, "training_acc": 46.0, "val_loss": 30.90273141860962, "val_acc": 72.0}
{"epoch": 36, "training_loss": 106.07181930541992, "training_acc": 72.0, "val_loss": 60.92846989631653, "val_acc": 28.0}
{"epoch": 37, "training_loss": 205.0646996498108, "training_acc": 42.0, "val_loss": 39.113786816596985, "val_acc": 72.0}
{"epoch": 38, "training_loss": 129.40512990951538, "training_acc": 72.0, "val_loss": 49.86807107925415, "val_acc": 28.0}
{"epoch": 39, "training_loss": 198.30525302886963, "training_acc": 42.0, "val_loss": 60.26682257652283, "val_acc": 72.0}
