"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 862.5752105712891, "training_acc": 42.0, "val_loss": 447.4276542663574, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1404.7843208312988, "training_acc": 72.0, "val_loss": 261.7171287536621, "val_acc": 28.0}
{"epoch": 2, "training_loss": 893.370792388916, "training_acc": 28.0, "val_loss": 141.84463024139404, "val_acc": 72.0}
{"epoch": 3, "training_loss": 731.7462387084961, "training_acc": 72.0, "val_loss": 299.3441104888916, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1172.006519317627, "training_acc": 72.0, "val_loss": 211.34347915649414, "val_acc": 72.0}
{"epoch": 5, "training_loss": 737.0949077606201, "training_acc": 72.0, "val_loss": 146.41692638397217, "val_acc": 28.0}
{"epoch": 6, "training_loss": 576.9514427185059, "training_acc": 28.0, "val_loss": 53.79440784454346, "val_acc": 72.0}
{"epoch": 7, "training_loss": 263.51654052734375, "training_acc": 72.0, "val_loss": 117.97748804092407, "val_acc": 72.0}
{"epoch": 8, "training_loss": 432.8355712890625, "training_acc": 72.0, "val_loss": 27.778208255767822, "val_acc": 72.0}
{"epoch": 9, "training_loss": 397.88722229003906, "training_acc": 50.0, "val_loss": 141.76571369171143, "val_acc": 28.0}
{"epoch": 10, "training_loss": 438.6873302459717, "training_acc": 44.0, "val_loss": 116.01349115371704, "val_acc": 72.0}
{"epoch": 11, "training_loss": 493.6095314025879, "training_acc": 72.0, "val_loss": 120.76407670974731, "val_acc": 72.0}
{"epoch": 12, "training_loss": 414.7864646911621, "training_acc": 72.0, "val_loss": 33.45593810081482, "val_acc": 28.0}
{"epoch": 13, "training_loss": 165.64003086090088, "training_acc": 28.0, "val_loss": 67.34915971755981, "val_acc": 72.0}
{"epoch": 14, "training_loss": 351.7844467163086, "training_acc": 72.0, "val_loss": 118.64621639251709, "val_acc": 72.0}
{"epoch": 15, "training_loss": 425.5560245513916, "training_acc": 72.0, "val_loss": 24.559348821640015, "val_acc": 72.0}
{"epoch": 16, "training_loss": 274.1783847808838, "training_acc": 60.0, "val_loss": 152.79901027679443, "val_acc": 28.0}
{"epoch": 17, "training_loss": 390.57718992233276, "training_acc": 50.0, "val_loss": 80.36186099052429, "val_acc": 72.0}
{"epoch": 18, "training_loss": 362.9948196411133, "training_acc": 72.0, "val_loss": 79.79448437690735, "val_acc": 72.0}
{"epoch": 19, "training_loss": 259.6566708087921, "training_acc": 72.0, "val_loss": 135.050368309021, "val_acc": 28.0}
{"epoch": 20, "training_loss": 458.6599760055542, "training_acc": 28.0, "val_loss": 74.80370998382568, "val_acc": 72.0}
{"epoch": 21, "training_loss": 425.40664863586426, "training_acc": 72.0, "val_loss": 161.90589666366577, "val_acc": 72.0}
{"epoch": 22, "training_loss": 622.9106712341309, "training_acc": 72.0, "val_loss": 96.6817855834961, "val_acc": 72.0}
{"epoch": 23, "training_loss": 286.08002495765686, "training_acc": 72.0, "val_loss": 194.93567943572998, "val_acc": 28.0}
{"epoch": 24, "training_loss": 767.1963882446289, "training_acc": 28.0, "val_loss": 18.19295436143875, "val_acc": 72.0}
{"epoch": 25, "training_loss": 161.97422409057617, "training_acc": 72.0, "val_loss": 92.69207715988159, "val_acc": 72.0}
{"epoch": 26, "training_loss": 344.38087940216064, "training_acc": 72.0, "val_loss": 25.576019287109375, "val_acc": 72.0}
{"epoch": 27, "training_loss": 246.81690979003906, "training_acc": 56.0, "val_loss": 73.52897524833679, "val_acc": 28.0}
{"epoch": 28, "training_loss": 275.3857889175415, "training_acc": 46.0, "val_loss": 129.67208623886108, "val_acc": 72.0}
{"epoch": 29, "training_loss": 547.276819229126, "training_acc": 72.0, "val_loss": 136.06301546096802, "val_acc": 72.0}
{"epoch": 30, "training_loss": 490.94791984558105, "training_acc": 72.0, "val_loss": 16.37829691171646, "val_acc": 72.0}
{"epoch": 31, "training_loss": 228.35090446472168, "training_acc": 64.0, "val_loss": 140.18621444702148, "val_acc": 28.0}
{"epoch": 32, "training_loss": 381.99178981781006, "training_acc": 48.0, "val_loss": 86.73064708709717, "val_acc": 72.0}
{"epoch": 33, "training_loss": 358.5718355178833, "training_acc": 72.0, "val_loss": 81.27068281173706, "val_acc": 72.0}
{"epoch": 34, "training_loss": 246.10184621810913, "training_acc": 72.0, "val_loss": 114.21616077423096, "val_acc": 28.0}
{"epoch": 35, "training_loss": 406.6164131164551, "training_acc": 28.0, "val_loss": 66.32354855537415, "val_acc": 72.0}
{"epoch": 36, "training_loss": 331.37768363952637, "training_acc": 72.0, "val_loss": 136.02174520492554, "val_acc": 72.0}
{"epoch": 37, "training_loss": 521.5663528442383, "training_acc": 72.0, "val_loss": 68.89614462852478, "val_acc": 72.0}
{"epoch": 38, "training_loss": 219.64861917495728, "training_acc": 58.0, "val_loss": 50.21570920944214, "val_acc": 28.0}
{"epoch": 39, "training_loss": 263.25049018859863, "training_acc": 36.0, "val_loss": 88.12058568000793, "val_acc": 72.0}
{"epoch": 40, "training_loss": 341.40907764434814, "training_acc": 72.0, "val_loss": 37.27239966392517, "val_acc": 72.0}
{"epoch": 41, "training_loss": 213.77624034881592, "training_acc": 58.0, "val_loss": 44.63336169719696, "val_acc": 28.0}
{"epoch": 42, "training_loss": 205.01437091827393, "training_acc": 46.0, "val_loss": 123.39433431625366, "val_acc": 72.0}
{"epoch": 43, "training_loss": 502.38515853881836, "training_acc": 72.0, "val_loss": 113.67137432098389, "val_acc": 72.0}
{"epoch": 44, "training_loss": 380.7737159729004, "training_acc": 72.0, "val_loss": 42.000678181648254, "val_acc": 28.0}
{"epoch": 45, "training_loss": 153.92535018920898, "training_acc": 28.0, "val_loss": 54.77246642112732, "val_acc": 72.0}
{"epoch": 46, "training_loss": 241.75629806518555, "training_acc": 72.0, "val_loss": 68.33874583244324, "val_acc": 72.0}
{"epoch": 47, "training_loss": 208.33543252944946, "training_acc": 72.0, "val_loss": 103.82670164108276, "val_acc": 28.0}
{"epoch": 48, "training_loss": 349.8720541000366, "training_acc": 28.0, "val_loss": 80.52195310592651, "val_acc": 72.0}
{"epoch": 49, "training_loss": 396.00650215148926, "training_acc": 72.0, "val_loss": 162.23081350326538, "val_acc": 72.0}
