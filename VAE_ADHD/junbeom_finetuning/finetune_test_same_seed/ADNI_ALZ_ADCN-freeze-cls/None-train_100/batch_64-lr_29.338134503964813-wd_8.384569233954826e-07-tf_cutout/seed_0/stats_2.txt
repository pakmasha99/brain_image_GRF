"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 221636.62215805054, "training_acc": 45.0, "val_loss": 79846.41723632812, "val_acc": 72.0}
{"epoch": 1, "training_loss": 239469.82763671875, "training_acc": 72.0, "val_loss": 72152.26440429688, "val_acc": 28.0}
{"epoch": 2, "training_loss": 265066.92578125, "training_acc": 28.0, "val_loss": 12773.491668701172, "val_acc": 72.0}
{"epoch": 3, "training_loss": 88264.373046875, "training_acc": 72.0, "val_loss": 35331.4453125, "val_acc": 72.0}
{"epoch": 4, "training_loss": 126769.720703125, "training_acc": 72.0, "val_loss": 8079.38232421875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 88202.1611328125, "training_acc": 56.0, "val_loss": 42966.552734375, "val_acc": 28.0}
{"epoch": 6, "training_loss": 113064.11029052734, "training_acc": 46.0, "val_loss": 17295.677185058594, "val_acc": 72.0}
{"epoch": 7, "training_loss": 72155.484375, "training_acc": 72.0, "val_loss": 14290.481567382812, "val_acc": 72.0}
{"epoch": 8, "training_loss": 32146.228576660156, "training_acc": 72.0, "val_loss": 46605.560302734375, "val_acc": 28.0}
{"epoch": 9, "training_loss": 181469.4072265625, "training_acc": 28.0, "val_loss": 768.4372425079346, "val_acc": 72.0}
{"epoch": 10, "training_loss": 22984.304443359375, "training_acc": 72.0, "val_loss": 12976.414489746094, "val_acc": 72.0}
{"epoch": 11, "training_loss": 40825.894775390625, "training_acc": 72.0, "val_loss": 15724.565124511719, "val_acc": 28.0}
{"epoch": 12, "training_loss": 44266.35534667969, "training_acc": 28.0, "val_loss": 20023.6328125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 89243.01586914062, "training_acc": 72.0, "val_loss": 36487.640380859375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 143837.5078125, "training_acc": 72.0, "val_loss": 26183.047485351562, "val_acc": 72.0}
{"epoch": 15, "training_loss": 77590.017578125, "training_acc": 72.0, "val_loss": 27976.437377929688, "val_acc": 28.0}
{"epoch": 16, "training_loss": 117679.70263671875, "training_acc": 28.0, "val_loss": 1528.1594276428223, "val_acc": 72.0}
{"epoch": 17, "training_loss": 14640.215209960938, "training_acc": 72.0, "val_loss": 8713.886260986328, "val_acc": 72.0}
{"epoch": 18, "training_loss": 22904.323516845703, "training_acc": 72.0, "val_loss": 26646.88720703125, "val_acc": 28.0}
{"epoch": 19, "training_loss": 86664.79638671875, "training_acc": 28.0, "val_loss": 15333.468627929688, "val_acc": 72.0}
{"epoch": 20, "training_loss": 72090.73950195312, "training_acc": 72.0, "val_loss": 29484.222412109375, "val_acc": 72.0}
{"epoch": 21, "training_loss": 110356.72998046875, "training_acc": 72.0, "val_loss": 16696.0205078125, "val_acc": 72.0}
{"epoch": 22, "training_loss": 42751.37989807129, "training_acc": 72.0, "val_loss": 46287.890625, "val_acc": 28.0}
{"epoch": 23, "training_loss": 190310.419921875, "training_acc": 28.0, "val_loss": 11452.701568603516, "val_acc": 28.0}
{"epoch": 24, "training_loss": 68846.66015625, "training_acc": 42.0, "val_loss": 45445.843505859375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 192762.21142578125, "training_acc": 72.0, "val_loss": 61442.2119140625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 237569.9345703125, "training_acc": 72.0, "val_loss": 50521.68884277344, "val_acc": 72.0}
{"epoch": 27, "training_loss": 182931.09399414062, "training_acc": 72.0, "val_loss": 16524.034118652344, "val_acc": 72.0}
{"epoch": 28, "training_loss": 60040.798583984375, "training_acc": 58.0, "val_loss": 28143.817138671875, "val_acc": 28.0}
