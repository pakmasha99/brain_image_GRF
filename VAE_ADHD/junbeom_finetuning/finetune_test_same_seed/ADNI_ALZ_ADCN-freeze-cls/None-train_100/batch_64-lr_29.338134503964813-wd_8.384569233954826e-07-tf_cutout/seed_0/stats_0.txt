"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 130022.66387939453, "training_acc": 42.0, "val_loss": 80935.9375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 268847.849609375, "training_acc": 72.0, "val_loss": 5570.64208984375, "val_acc": 72.0}
{"epoch": 2, "training_loss": 218616.890625, "training_acc": 50.0, "val_loss": 122773.32763671875, "val_acc": 28.0}
{"epoch": 3, "training_loss": 403505.837890625, "training_acc": 28.0, "val_loss": 14106.640625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 97139.595703125, "training_acc": 72.0, "val_loss": 56214.886474609375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 223669.05908203125, "training_acc": 72.0, "val_loss": 59720.3125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 223085.7470703125, "training_acc": 72.0, "val_loss": 37841.27502441406, "val_acc": 72.0}
{"epoch": 7, "training_loss": 128221.77380371094, "training_acc": 72.0, "val_loss": 15701.620483398438, "val_acc": 28.0}
{"epoch": 8, "training_loss": 72869.18920898438, "training_acc": 28.0, "val_loss": 3026.2428283691406, "val_acc": 72.0}
{"epoch": 9, "training_loss": 15462.368103027344, "training_acc": 72.0, "val_loss": 6208.161163330078, "val_acc": 72.0}
{"epoch": 10, "training_loss": 16933.049240112305, "training_acc": 56.0, "val_loss": 8229.865264892578, "val_acc": 72.0}
{"epoch": 11, "training_loss": 35033.8759765625, "training_acc": 72.0, "val_loss": 6252.0599365234375, "val_acc": 72.0}
{"epoch": 12, "training_loss": 29367.920776367188, "training_acc": 54.0, "val_loss": 2633.5506439208984, "val_acc": 72.0}
{"epoch": 13, "training_loss": 9043.130531311035, "training_acc": 72.0, "val_loss": 7244.387054443359, "val_acc": 28.0}
{"epoch": 14, "training_loss": 32281.97412109375, "training_acc": 40.0, "val_loss": 10164.077758789062, "val_acc": 72.0}
{"epoch": 15, "training_loss": 35671.74938964844, "training_acc": 72.0, "val_loss": 1627.293586730957, "val_acc": 28.0}
{"epoch": 16, "training_loss": 14635.316772460938, "training_acc": 40.0, "val_loss": 5041.244888305664, "val_acc": 72.0}
{"epoch": 17, "training_loss": 21093.266479492188, "training_acc": 50.0, "val_loss": 7114.289093017578, "val_acc": 72.0}
{"epoch": 18, "training_loss": 34350.175048828125, "training_acc": 72.0, "val_loss": 7174.371337890625, "val_acc": 72.0}
{"epoch": 19, "training_loss": 29401.035217285156, "training_acc": 50.0, "val_loss": 4096.357345581055, "val_acc": 72.0}
{"epoch": 20, "training_loss": 16079.129699707031, "training_acc": 72.0, "val_loss": 185.64786911010742, "val_acc": 76.0}
{"epoch": 21, "training_loss": 1953.9523620605469, "training_acc": 58.0, "val_loss": 8244.015502929688, "val_acc": 72.0}
{"epoch": 22, "training_loss": 35822.09948730469, "training_acc": 72.0, "val_loss": 8003.556060791016, "val_acc": 72.0}
{"epoch": 23, "training_loss": 21994.796905517578, "training_acc": 64.0, "val_loss": 4111.6790771484375, "val_acc": 28.0}
{"epoch": 24, "training_loss": 24625.439697265625, "training_acc": 44.0, "val_loss": 15062.545776367188, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58452.51123046875, "training_acc": 72.0, "val_loss": 8695.353698730469, "val_acc": 72.0}
{"epoch": 26, "training_loss": 30765.319213867188, "training_acc": 54.0, "val_loss": 1168.593978881836, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4330.053298950195, "training_acc": 63.0, "val_loss": 7428.424835205078, "val_acc": 72.0}
{"epoch": 28, "training_loss": 30987.771118164062, "training_acc": 72.0, "val_loss": 5888.0706787109375, "val_acc": 72.0}
{"epoch": 29, "training_loss": 21961.55859375, "training_acc": 56.0, "val_loss": 3469.757080078125, "val_acc": 72.0}
{"epoch": 30, "training_loss": 12508.80712890625, "training_acc": 72.0, "val_loss": 3264.44091796875, "val_acc": 28.0}
{"epoch": 31, "training_loss": 26498.619750976562, "training_acc": 36.0, "val_loss": 10589.68734741211, "val_acc": 72.0}
{"epoch": 32, "training_loss": 36603.48718261719, "training_acc": 72.0, "val_loss": 2287.7527236938477, "val_acc": 40.0}
{"epoch": 33, "training_loss": 10416.627319335938, "training_acc": 49.0, "val_loss": 4418.812942504883, "val_acc": 72.0}
{"epoch": 34, "training_loss": 10497.542457580566, "training_acc": 74.0, "val_loss": 12364.219665527344, "val_acc": 28.0}
{"epoch": 35, "training_loss": 37518.18783569336, "training_acc": 44.0, "val_loss": 4914.040756225586, "val_acc": 72.0}
{"epoch": 36, "training_loss": 14066.441619873047, "training_acc": 73.0, "val_loss": 14304.278564453125, "val_acc": 28.0}
{"epoch": 37, "training_loss": 43661.03909301758, "training_acc": 36.0, "val_loss": 913.5671615600586, "val_acc": 72.0}
{"epoch": 38, "training_loss": 9336.049499511719, "training_acc": 59.0, "val_loss": 6399.405670166016, "val_acc": 72.0}
{"epoch": 39, "training_loss": 33232.8115234375, "training_acc": 72.0, "val_loss": 6966.868591308594, "val_acc": 72.0}
