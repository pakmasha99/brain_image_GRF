"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 376.358341217041, "training_acc": 72.0, "val_loss": 133.03512334823608, "val_acc": 72.0}
{"epoch": 1, "training_loss": 402.9603109359741, "training_acc": 72.0, "val_loss": 271.2380886077881, "val_acc": 28.0}
{"epoch": 2, "training_loss": 997.0545120239258, "training_acc": 28.0, "val_loss": 18.323127925395966, "val_acc": 28.0}
{"epoch": 3, "training_loss": 162.50295639038086, "training_acc": 46.0, "val_loss": 148.8805055618286, "val_acc": 72.0}
{"epoch": 4, "training_loss": 632.4840888977051, "training_acc": 72.0, "val_loss": 183.69203805923462, "val_acc": 72.0}
{"epoch": 5, "training_loss": 714.5247840881348, "training_acc": 72.0, "val_loss": 137.25210428237915, "val_acc": 72.0}
{"epoch": 6, "training_loss": 469.77608489990234, "training_acc": 72.0, "val_loss": 28.200101852416992, "val_acc": 72.0}
{"epoch": 7, "training_loss": 242.39942169189453, "training_acc": 56.0, "val_loss": 160.15057563781738, "val_acc": 28.0}
{"epoch": 8, "training_loss": 545.8604326248169, "training_acc": 28.0, "val_loss": 22.420096397399902, "val_acc": 72.0}
{"epoch": 9, "training_loss": 167.6412172317505, "training_acc": 72.0, "val_loss": 83.90648365020752, "val_acc": 72.0}
{"epoch": 10, "training_loss": 336.2733850479126, "training_acc": 72.0, "val_loss": 76.14070177078247, "val_acc": 72.0}
{"epoch": 11, "training_loss": 271.9117259979248, "training_acc": 72.0, "val_loss": 21.982595324516296, "val_acc": 72.0}
{"epoch": 12, "training_loss": 177.90256786346436, "training_acc": 48.0, "val_loss": 66.25944375991821, "val_acc": 28.0}
{"epoch": 13, "training_loss": 205.22841215133667, "training_acc": 38.0, "val_loss": 33.41484069824219, "val_acc": 72.0}
{"epoch": 14, "training_loss": 145.093505859375, "training_acc": 72.0, "val_loss": 38.63447606563568, "val_acc": 72.0}
{"epoch": 15, "training_loss": 132.60522508621216, "training_acc": 72.0, "val_loss": 21.343348920345306, "val_acc": 28.0}
{"epoch": 16, "training_loss": 107.34929132461548, "training_acc": 28.0, "val_loss": 15.317368507385254, "val_acc": 72.0}
{"epoch": 17, "training_loss": 80.67661142349243, "training_acc": 72.0, "val_loss": 28.531619906425476, "val_acc": 72.0}
{"epoch": 18, "training_loss": 104.18533706665039, "training_acc": 72.0, "val_loss": 18.833312392234802, "val_acc": 28.0}
{"epoch": 19, "training_loss": 75.9144721031189, "training_acc": 28.0, "val_loss": 15.49551784992218, "val_acc": 72.0}
{"epoch": 20, "training_loss": 65.8052933216095, "training_acc": 72.0, "val_loss": 16.859321296215057, "val_acc": 72.0}
{"epoch": 21, "training_loss": 67.63962864875793, "training_acc": 72.0, "val_loss": 16.77376925945282, "val_acc": 28.0}
{"epoch": 22, "training_loss": 68.07356381416321, "training_acc": 72.0, "val_loss": 15.943656861782074, "val_acc": 72.0}
{"epoch": 23, "training_loss": 63.02628302574158, "training_acc": 72.0, "val_loss": 15.355736017227173, "val_acc": 36.0}
{"epoch": 24, "training_loss": 61.17149043083191, "training_acc": 72.0, "val_loss": 14.879110455513, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.972491979599, "training_acc": 72.0, "val_loss": 16.064830124378204, "val_acc": 28.0}
{"epoch": 26, "training_loss": 63.468586921691895, "training_acc": 72.0, "val_loss": 14.710626006126404, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.48527240753174, "training_acc": 72.0, "val_loss": 14.733463525772095, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.485923290252686, "training_acc": 72.0, "val_loss": 14.673055708408356, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.19928455352783, "training_acc": 72.0, "val_loss": 14.608444273471832, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.06661415100098, "training_acc": 72.0, "val_loss": 14.602303504943848, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.6268208026886, "training_acc": 72.0, "val_loss": 14.591032266616821, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.54772138595581, "training_acc": 72.0, "val_loss": 14.690245687961578, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.84454679489136, "training_acc": 72.0, "val_loss": 14.598540961742401, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.26951599121094, "training_acc": 72.0, "val_loss": 14.613494277000427, "val_acc": 72.0}
{"epoch": 35, "training_loss": 62.20772910118103, "training_acc": 72.0, "val_loss": 18.41241419315338, "val_acc": 72.0}
{"epoch": 36, "training_loss": 86.16661214828491, "training_acc": 72.0, "val_loss": 16.725465655326843, "val_acc": 28.0}
{"epoch": 37, "training_loss": 82.32610177993774, "training_acc": 58.0, "val_loss": 18.459579348564148, "val_acc": 72.0}
{"epoch": 38, "training_loss": 80.34448266029358, "training_acc": 72.0, "val_loss": 20.15417367219925, "val_acc": 72.0}
{"epoch": 39, "training_loss": 79.90521931648254, "training_acc": 58.0, "val_loss": 17.744465172290802, "val_acc": 28.0}
{"epoch": 40, "training_loss": 85.00613117218018, "training_acc": 37.0, "val_loss": 17.931419610977173, "val_acc": 72.0}
{"epoch": 41, "training_loss": 64.27987217903137, "training_acc": 72.0, "val_loss": 22.047145664691925, "val_acc": 28.0}
{"epoch": 42, "training_loss": 74.15055823326111, "training_acc": 48.0, "val_loss": 22.394482791423798, "val_acc": 72.0}
{"epoch": 43, "training_loss": 84.70115494728088, "training_acc": 72.0, "val_loss": 15.902911126613617, "val_acc": 28.0}
{"epoch": 44, "training_loss": 66.8019654750824, "training_acc": 54.0, "val_loss": 18.754415214061737, "val_acc": 72.0}
{"epoch": 45, "training_loss": 82.05402421951294, "training_acc": 72.0, "val_loss": 14.519999921321869, "val_acc": 72.0}
{"epoch": 46, "training_loss": 69.91924357414246, "training_acc": 58.0, "val_loss": 14.511516690254211, "val_acc": 72.0}
{"epoch": 47, "training_loss": 65.23460054397583, "training_acc": 72.0, "val_loss": 16.86360388994217, "val_acc": 72.0}
{"epoch": 48, "training_loss": 68.52228116989136, "training_acc": 61.0, "val_loss": 15.47389030456543, "val_acc": 32.0}
{"epoch": 49, "training_loss": 59.39460825920105, "training_acc": 72.0, "val_loss": 17.99611747264862, "val_acc": 72.0}
{"epoch": 50, "training_loss": 66.93168330192566, "training_acc": 72.0, "val_loss": 18.30057054758072, "val_acc": 28.0}
{"epoch": 51, "training_loss": 66.46545910835266, "training_acc": 46.0, "val_loss": 18.101081252098083, "val_acc": 72.0}
{"epoch": 52, "training_loss": 68.65510988235474, "training_acc": 72.0, "val_loss": 16.707870364189148, "val_acc": 28.0}
{"epoch": 53, "training_loss": 64.38735151290894, "training_acc": 69.0, "val_loss": 15.291792154312134, "val_acc": 72.0}
{"epoch": 54, "training_loss": 64.80928611755371, "training_acc": 72.0, "val_loss": 23.82577806711197, "val_acc": 28.0}
{"epoch": 55, "training_loss": 85.88895511627197, "training_acc": 40.0, "val_loss": 16.958965361118317, "val_acc": 72.0}
{"epoch": 56, "training_loss": 65.18410968780518, "training_acc": 72.0, "val_loss": 21.25740945339203, "val_acc": 28.0}
{"epoch": 57, "training_loss": 76.65231275558472, "training_acc": 42.0, "val_loss": 17.260847985744476, "val_acc": 72.0}
{"epoch": 58, "training_loss": 70.63256502151489, "training_acc": 72.0, "val_loss": 14.393506944179535, "val_acc": 72.0}
{"epoch": 59, "training_loss": 57.77536725997925, "training_acc": 72.0, "val_loss": 14.446654915809631, "val_acc": 72.0}
{"epoch": 60, "training_loss": 62.72011685371399, "training_acc": 72.0, "val_loss": 17.419667541980743, "val_acc": 72.0}
{"epoch": 61, "training_loss": 71.39096331596375, "training_acc": 72.0, "val_loss": 16.5145143866539, "val_acc": 28.0}
{"epoch": 62, "training_loss": 70.35163235664368, "training_acc": 57.0, "val_loss": 21.520468592643738, "val_acc": 72.0}
{"epoch": 63, "training_loss": 88.002681016922, "training_acc": 72.0, "val_loss": 15.365955233573914, "val_acc": 72.0}
{"epoch": 64, "training_loss": 72.39666414260864, "training_acc": 58.0, "val_loss": 14.33241218328476, "val_acc": 72.0}
{"epoch": 65, "training_loss": 67.88421559333801, "training_acc": 72.0, "val_loss": 16.054007411003113, "val_acc": 72.0}
{"epoch": 66, "training_loss": 70.19964027404785, "training_acc": 56.0, "val_loss": 14.317642152309418, "val_acc": 72.0}
{"epoch": 67, "training_loss": 60.041651487350464, "training_acc": 72.0, "val_loss": 15.66811203956604, "val_acc": 72.0}
{"epoch": 68, "training_loss": 59.297709941864014, "training_acc": 72.0, "val_loss": 17.069965600967407, "val_acc": 28.0}
{"epoch": 69, "training_loss": 67.26342272758484, "training_acc": 64.0, "val_loss": 17.40707904100418, "val_acc": 72.0}
{"epoch": 70, "training_loss": 65.98487854003906, "training_acc": 72.0, "val_loss": 16.842271387577057, "val_acc": 28.0}
{"epoch": 71, "training_loss": 66.44717359542847, "training_acc": 64.0, "val_loss": 16.75248295068741, "val_acc": 72.0}
{"epoch": 72, "training_loss": 62.667455434799194, "training_acc": 72.0, "val_loss": 18.118225038051605, "val_acc": 28.0}
{"epoch": 73, "training_loss": 73.2884418964386, "training_acc": 42.0, "val_loss": 16.971668601036072, "val_acc": 72.0}
{"epoch": 74, "training_loss": 60.43442177772522, "training_acc": 72.0, "val_loss": 23.982003331184387, "val_acc": 28.0}
{"epoch": 75, "training_loss": 89.83459877967834, "training_acc": 42.0, "val_loss": 20.886699855327606, "val_acc": 72.0}
{"epoch": 76, "training_loss": 71.34134292602539, "training_acc": 72.0, "val_loss": 32.29077756404877, "val_acc": 28.0}
{"epoch": 77, "training_loss": 111.66071105003357, "training_acc": 40.0, "val_loss": 20.40209174156189, "val_acc": 72.0}
{"epoch": 78, "training_loss": 73.05509853363037, "training_acc": 72.0, "val_loss": 23.955897986888885, "val_acc": 28.0}
{"epoch": 79, "training_loss": 82.32181572914124, "training_acc": 44.0, "val_loss": 19.698187708854675, "val_acc": 72.0}
{"epoch": 80, "training_loss": 75.40975952148438, "training_acc": 72.0, "val_loss": 15.564723312854767, "val_acc": 36.0}
{"epoch": 81, "training_loss": 60.74448919296265, "training_acc": 74.0, "val_loss": 15.196830034255981, "val_acc": 72.0}
{"epoch": 82, "training_loss": 66.93187642097473, "training_acc": 72.0, "val_loss": 16.123202443122864, "val_acc": 72.0}
{"epoch": 83, "training_loss": 65.36609768867493, "training_acc": 72.0, "val_loss": 16.109095513820648, "val_acc": 28.0}
{"epoch": 84, "training_loss": 63.00901913642883, "training_acc": 69.0, "val_loss": 15.191876888275146, "val_acc": 72.0}
{"epoch": 85, "training_loss": 62.25546383857727, "training_acc": 72.0, "val_loss": 19.096186757087708, "val_acc": 28.0}
