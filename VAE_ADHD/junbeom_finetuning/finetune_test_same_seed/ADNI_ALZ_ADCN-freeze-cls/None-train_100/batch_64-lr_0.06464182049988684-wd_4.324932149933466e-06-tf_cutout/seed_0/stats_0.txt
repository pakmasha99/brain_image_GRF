"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 349.2179832458496, "training_acc": 42.0, "val_loss": 166.18670225143433, "val_acc": 72.0}
{"epoch": 1, "training_loss": 521.4380779266357, "training_acc": 72.0, "val_loss": 98.51840138435364, "val_acc": 28.0}
{"epoch": 2, "training_loss": 339.6669454574585, "training_acc": 28.0, "val_loss": 50.65627098083496, "val_acc": 72.0}
{"epoch": 3, "training_loss": 261.6300382614136, "training_acc": 72.0, "val_loss": 106.10606670379639, "val_acc": 72.0}
{"epoch": 4, "training_loss": 412.22304916381836, "training_acc": 72.0, "val_loss": 69.76948976516724, "val_acc": 72.0}
{"epoch": 5, "training_loss": 238.87215280532837, "training_acc": 72.0, "val_loss": 79.47170734405518, "val_acc": 28.0}
{"epoch": 6, "training_loss": 311.12872409820557, "training_acc": 28.0, "val_loss": 16.144420206546783, "val_acc": 72.0}
{"epoch": 7, "training_loss": 85.79201745986938, "training_acc": 72.0, "val_loss": 52.78748273849487, "val_acc": 72.0}
{"epoch": 8, "training_loss": 207.09573459625244, "training_acc": 72.0, "val_loss": 31.531676650047302, "val_acc": 72.0}
{"epoch": 9, "training_loss": 125.05950498580933, "training_acc": 50.0, "val_loss": 33.22480618953705, "val_acc": 28.0}
{"epoch": 10, "training_loss": 107.30102181434631, "training_acc": 44.0, "val_loss": 25.893795490264893, "val_acc": 72.0}
{"epoch": 11, "training_loss": 103.02596044540405, "training_acc": 72.0, "val_loss": 15.837563574314117, "val_acc": 72.0}
{"epoch": 12, "training_loss": 82.94058895111084, "training_acc": 54.0, "val_loss": 16.168493032455444, "val_acc": 28.0}
{"epoch": 13, "training_loss": 59.29528868198395, "training_acc": 72.0, "val_loss": 25.425323843955994, "val_acc": 72.0}
{"epoch": 14, "training_loss": 95.75569343566895, "training_acc": 72.0, "val_loss": 15.81721305847168, "val_acc": 28.0}
{"epoch": 15, "training_loss": 72.17107343673706, "training_acc": 60.0, "val_loss": 14.731672406196594, "val_acc": 72.0}
{"epoch": 16, "training_loss": 71.11404776573181, "training_acc": 72.0, "val_loss": 17.997421324253082, "val_acc": 72.0}
{"epoch": 17, "training_loss": 78.93183088302612, "training_acc": 50.0, "val_loss": 15.335769951343536, "val_acc": 44.0}
{"epoch": 18, "training_loss": 70.2053005695343, "training_acc": 72.0, "val_loss": 15.958423912525177, "val_acc": 72.0}
{"epoch": 19, "training_loss": 72.87912011146545, "training_acc": 50.0, "val_loss": 14.70310240983963, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.28440022468567, "training_acc": 72.0, "val_loss": 15.955138206481934, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.61582326889038, "training_acc": 72.0, "val_loss": 19.979916512966156, "val_acc": 28.0}
{"epoch": 22, "training_loss": 72.54162526130676, "training_acc": 44.0, "val_loss": 18.162892758846283, "val_acc": 72.0}
{"epoch": 23, "training_loss": 69.37246823310852, "training_acc": 72.0, "val_loss": 15.888085961341858, "val_acc": 28.0}
{"epoch": 24, "training_loss": 62.88444471359253, "training_acc": 72.0, "val_loss": 15.701629221439362, "val_acc": 72.0}
{"epoch": 25, "training_loss": 63.66344451904297, "training_acc": 72.0, "val_loss": 15.095129609107971, "val_acc": 72.0}
{"epoch": 26, "training_loss": 63.54243469238281, "training_acc": 73.0, "val_loss": 16.12837016582489, "val_acc": 72.0}
{"epoch": 27, "training_loss": 66.06787657737732, "training_acc": 72.0, "val_loss": 14.647595584392548, "val_acc": 72.0}
{"epoch": 28, "training_loss": 65.5078375339508, "training_acc": 54.0, "val_loss": 15.696825087070465, "val_acc": 72.0}
{"epoch": 29, "training_loss": 65.86916279792786, "training_acc": 72.0, "val_loss": 14.67721164226532, "val_acc": 72.0}
{"epoch": 30, "training_loss": 74.8043704032898, "training_acc": 50.0, "val_loss": 17.492492496967316, "val_acc": 72.0}
{"epoch": 31, "training_loss": 87.12401533126831, "training_acc": 72.0, "val_loss": 15.42644053697586, "val_acc": 72.0}
{"epoch": 32, "training_loss": 93.08390092849731, "training_acc": 52.0, "val_loss": 14.823490381240845, "val_acc": 72.0}
{"epoch": 33, "training_loss": 65.76229929924011, "training_acc": 72.0, "val_loss": 21.813449263572693, "val_acc": 72.0}
{"epoch": 34, "training_loss": 72.88370990753174, "training_acc": 72.0, "val_loss": 29.975032806396484, "val_acc": 28.0}
{"epoch": 35, "training_loss": 98.65582275390625, "training_acc": 44.0, "val_loss": 22.664189338684082, "val_acc": 72.0}
{"epoch": 36, "training_loss": 85.47513198852539, "training_acc": 72.0, "val_loss": 15.917535126209259, "val_acc": 28.0}
{"epoch": 37, "training_loss": 63.79783296585083, "training_acc": 72.0, "val_loss": 14.647935330867767, "val_acc": 72.0}
{"epoch": 38, "training_loss": 61.09805631637573, "training_acc": 72.0, "val_loss": 14.609336853027344, "val_acc": 72.0}
{"epoch": 39, "training_loss": 57.59894108772278, "training_acc": 72.0, "val_loss": 18.242530524730682, "val_acc": 28.0}
{"epoch": 40, "training_loss": 73.7809510231018, "training_acc": 40.0, "val_loss": 15.93284010887146, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.96671962738037, "training_acc": 72.0, "val_loss": 16.491501033306122, "val_acc": 28.0}
{"epoch": 42, "training_loss": 62.624006271362305, "training_acc": 71.0, "val_loss": 17.383578419685364, "val_acc": 72.0}
{"epoch": 43, "training_loss": 68.46946620941162, "training_acc": 72.0, "val_loss": 14.832299947738647, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.346800565719604, "training_acc": 72.0, "val_loss": 14.84445184469223, "val_acc": 72.0}
{"epoch": 45, "training_loss": 58.372982025146484, "training_acc": 72.0, "val_loss": 15.278039872646332, "val_acc": 44.0}
{"epoch": 46, "training_loss": 58.97920298576355, "training_acc": 72.0, "val_loss": 17.150889337062836, "val_acc": 72.0}
{"epoch": 47, "training_loss": 65.10009789466858, "training_acc": 72.0, "val_loss": 20.30579298734665, "val_acc": 28.0}
{"epoch": 48, "training_loss": 70.77248883247375, "training_acc": 48.0, "val_loss": 21.422526240348816, "val_acc": 72.0}
{"epoch": 49, "training_loss": 80.93890452384949, "training_acc": 72.0, "val_loss": 16.506174206733704, "val_acc": 28.0}
{"epoch": 50, "training_loss": 67.96927237510681, "training_acc": 61.0, "val_loss": 21.309928596019745, "val_acc": 72.0}
{"epoch": 51, "training_loss": 85.38591408729553, "training_acc": 72.0, "val_loss": 14.434248208999634, "val_acc": 72.0}
{"epoch": 52, "training_loss": 73.09151411056519, "training_acc": 56.0, "val_loss": 17.01054871082306, "val_acc": 72.0}
{"epoch": 53, "training_loss": 69.22625279426575, "training_acc": 72.0, "val_loss": 15.656661987304688, "val_acc": 72.0}
{"epoch": 54, "training_loss": 67.84124755859375, "training_acc": 56.0, "val_loss": 14.490443468093872, "val_acc": 72.0}
{"epoch": 55, "training_loss": 58.56990432739258, "training_acc": 72.0, "val_loss": 15.330129861831665, "val_acc": 72.0}
{"epoch": 56, "training_loss": 67.32578992843628, "training_acc": 61.0, "val_loss": 15.349237620830536, "val_acc": 72.0}
{"epoch": 57, "training_loss": 60.9800763130188, "training_acc": 72.0, "val_loss": 14.418600499629974, "val_acc": 72.0}
{"epoch": 58, "training_loss": 57.33725094795227, "training_acc": 72.0, "val_loss": 18.551425635814667, "val_acc": 28.0}
{"epoch": 59, "training_loss": 68.12539625167847, "training_acc": 46.0, "val_loss": 18.723392486572266, "val_acc": 72.0}
{"epoch": 60, "training_loss": 71.66531205177307, "training_acc": 72.0, "val_loss": 15.332746505737305, "val_acc": 44.0}
{"epoch": 61, "training_loss": 59.41926884651184, "training_acc": 72.0, "val_loss": 16.26473069190979, "val_acc": 72.0}
{"epoch": 62, "training_loss": 61.317195415496826, "training_acc": 72.0, "val_loss": 17.098087072372437, "val_acc": 28.0}
{"epoch": 63, "training_loss": 80.19703364372253, "training_acc": 50.0, "val_loss": 14.555482566356659, "val_acc": 72.0}
{"epoch": 64, "training_loss": 65.39321565628052, "training_acc": 56.0, "val_loss": 15.614268183708191, "val_acc": 72.0}
{"epoch": 65, "training_loss": 74.32253408432007, "training_acc": 72.0, "val_loss": 15.548419952392578, "val_acc": 28.0}
{"epoch": 66, "training_loss": 77.76352024078369, "training_acc": 53.0, "val_loss": 26.294681429862976, "val_acc": 72.0}
{"epoch": 67, "training_loss": 111.234619140625, "training_acc": 72.0, "val_loss": 23.06574136018753, "val_acc": 72.0}
{"epoch": 68, "training_loss": 121.08481454849243, "training_acc": 48.0, "val_loss": 14.690321683883667, "val_acc": 72.0}
{"epoch": 69, "training_loss": 69.13551378250122, "training_acc": 72.0, "val_loss": 17.38794296979904, "val_acc": 72.0}
{"epoch": 70, "training_loss": 92.0421462059021, "training_acc": 50.0, "val_loss": 16.37911945581436, "val_acc": 72.0}
{"epoch": 71, "training_loss": 78.60754156112671, "training_acc": 72.0, "val_loss": 14.909628033638, "val_acc": 72.0}
{"epoch": 72, "training_loss": 104.97898244857788, "training_acc": 48.0, "val_loss": 19.193318486213684, "val_acc": 72.0}
{"epoch": 73, "training_loss": 112.74728298187256, "training_acc": 72.0, "val_loss": 23.228685557842255, "val_acc": 72.0}
{"epoch": 74, "training_loss": 110.7645115852356, "training_acc": 52.0, "val_loss": 14.749078452587128, "val_acc": 64.0}
{"epoch": 75, "training_loss": 74.69953346252441, "training_acc": 72.0, "val_loss": 22.738604247570038, "val_acc": 72.0}
{"epoch": 76, "training_loss": 85.88617992401123, "training_acc": 73.0, "val_loss": 17.50587373971939, "val_acc": 28.0}
