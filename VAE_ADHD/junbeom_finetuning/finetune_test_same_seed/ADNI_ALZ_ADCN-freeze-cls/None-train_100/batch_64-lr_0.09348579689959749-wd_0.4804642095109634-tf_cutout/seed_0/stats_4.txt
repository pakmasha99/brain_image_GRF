"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 363.15074920654297, "training_acc": 72.0, "val_loss": 222.3121166229248, "val_acc": 72.0}
{"epoch": 1, "training_loss": 643.4473114013672, "training_acc": 72.0, "val_loss": 338.08538913726807, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1208.7371788024902, "training_acc": 28.0, "val_loss": 26.656067371368408, "val_acc": 72.0}
{"epoch": 3, "training_loss": 235.66511154174805, "training_acc": 72.0, "val_loss": 109.85137224197388, "val_acc": 72.0}
{"epoch": 4, "training_loss": 410.058780670166, "training_acc": 72.0, "val_loss": 42.549699544906616, "val_acc": 72.0}
{"epoch": 5, "training_loss": 211.81295013427734, "training_acc": 56.0, "val_loss": 43.02310049533844, "val_acc": 28.0}
{"epoch": 6, "training_loss": 155.6363081932068, "training_acc": 48.0, "val_loss": 75.98485946655273, "val_acc": 72.0}
{"epoch": 7, "training_loss": 308.9671688079834, "training_acc": 72.0, "val_loss": 59.181833267211914, "val_acc": 72.0}
{"epoch": 8, "training_loss": 202.4236799478531, "training_acc": 72.0, "val_loss": 75.99189877510071, "val_acc": 28.0}
{"epoch": 9, "training_loss": 240.6894826889038, "training_acc": 28.0, "val_loss": 49.68564510345459, "val_acc": 72.0}
{"epoch": 10, "training_loss": 252.53582668304443, "training_acc": 72.0, "val_loss": 90.55536985397339, "val_acc": 72.0}
{"epoch": 11, "training_loss": 339.7016134262085, "training_acc": 72.0, "val_loss": 41.351118683815, "val_acc": 72.0}
{"epoch": 12, "training_loss": 152.5584201812744, "training_acc": 56.0, "val_loss": 41.532257199287415, "val_acc": 28.0}
{"epoch": 13, "training_loss": 135.13496899604797, "training_acc": 46.0, "val_loss": 41.20851159095764, "val_acc": 72.0}
{"epoch": 14, "training_loss": 159.52557563781738, "training_acc": 72.0, "val_loss": 16.710616648197174, "val_acc": 72.0}
{"epoch": 15, "training_loss": 115.39993858337402, "training_acc": 56.0, "val_loss": 16.941189765930176, "val_acc": 28.0}
{"epoch": 16, "training_loss": 83.02376794815063, "training_acc": 72.0, "val_loss": 39.503878355026245, "val_acc": 72.0}
{"epoch": 17, "training_loss": 141.22526693344116, "training_acc": 72.0, "val_loss": 19.209378957748413, "val_acc": 28.0}
{"epoch": 18, "training_loss": 89.36945295333862, "training_acc": 28.0, "val_loss": 22.406265139579773, "val_acc": 72.0}
{"epoch": 19, "training_loss": 95.75829434394836, "training_acc": 72.0, "val_loss": 19.961653649806976, "val_acc": 72.0}
{"epoch": 20, "training_loss": 119.61790132522583, "training_acc": 46.0, "val_loss": 16.732215881347656, "val_acc": 72.0}
{"epoch": 21, "training_loss": 91.92322397232056, "training_acc": 72.0, "val_loss": 17.152222990989685, "val_acc": 72.0}
{"epoch": 22, "training_loss": 88.40946435928345, "training_acc": 56.0, "val_loss": 14.80146050453186, "val_acc": 72.0}
{"epoch": 23, "training_loss": 66.17317938804626, "training_acc": 72.0, "val_loss": 18.401217460632324, "val_acc": 72.0}
{"epoch": 24, "training_loss": 69.62890720367432, "training_acc": 73.0, "val_loss": 17.056719958782196, "val_acc": 28.0}
{"epoch": 25, "training_loss": 73.17360711097717, "training_acc": 72.0, "val_loss": 17.477573454380035, "val_acc": 72.0}
{"epoch": 26, "training_loss": 70.05690479278564, "training_acc": 56.0, "val_loss": 15.028662979602814, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.097580671310425, "training_acc": 72.0, "val_loss": 16.503314673900604, "val_acc": 72.0}
{"epoch": 28, "training_loss": 62.71508836746216, "training_acc": 72.0, "val_loss": 16.979262232780457, "val_acc": 28.0}
{"epoch": 29, "training_loss": 67.23902082443237, "training_acc": 72.0, "val_loss": 16.37665182352066, "val_acc": 72.0}
{"epoch": 30, "training_loss": 63.29278898239136, "training_acc": 72.0, "val_loss": 15.727683901786804, "val_acc": 28.0}
{"epoch": 31, "training_loss": 61.92539119720459, "training_acc": 72.0, "val_loss": 16.241376101970673, "val_acc": 72.0}
{"epoch": 32, "training_loss": 67.98108744621277, "training_acc": 72.0, "val_loss": 15.207105875015259, "val_acc": 72.0}
{"epoch": 33, "training_loss": 62.655802726745605, "training_acc": 72.0, "val_loss": 16.26502126455307, "val_acc": 28.0}
{"epoch": 34, "training_loss": 63.63960099220276, "training_acc": 72.0, "val_loss": 14.96439278125763, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.212600231170654, "training_acc": 72.0, "val_loss": 15.597090125083923, "val_acc": 28.0}
{"epoch": 36, "training_loss": 61.93233799934387, "training_acc": 72.0, "val_loss": 15.03293663263321, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.79246640205383, "training_acc": 72.0, "val_loss": 16.49242788553238, "val_acc": 28.0}
{"epoch": 38, "training_loss": 69.41414976119995, "training_acc": 72.0, "val_loss": 15.070171654224396, "val_acc": 72.0}
{"epoch": 39, "training_loss": 60.2740204334259, "training_acc": 72.0, "val_loss": 14.775706827640533, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.586108446121216, "training_acc": 72.0, "val_loss": 15.667332708835602, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.85979914665222, "training_acc": 72.0, "val_loss": 18.197020888328552, "val_acc": 28.0}
{"epoch": 42, "training_loss": 73.79905080795288, "training_acc": 44.0, "val_loss": 17.33664721250534, "val_acc": 72.0}
{"epoch": 43, "training_loss": 93.23592329025269, "training_acc": 50.0, "val_loss": 25.234785676002502, "val_acc": 72.0}
{"epoch": 44, "training_loss": 107.05521202087402, "training_acc": 72.0, "val_loss": 15.068915486335754, "val_acc": 72.0}
{"epoch": 45, "training_loss": 105.02652788162231, "training_acc": 54.0, "val_loss": 23.29673171043396, "val_acc": 72.0}
{"epoch": 46, "training_loss": 111.49866533279419, "training_acc": 72.0, "val_loss": 20.038259029388428, "val_acc": 72.0}
{"epoch": 47, "training_loss": 112.07113885879517, "training_acc": 56.0, "val_loss": 16.008205711841583, "val_acc": 72.0}
{"epoch": 48, "training_loss": 88.85129356384277, "training_acc": 72.0, "val_loss": 15.760044753551483, "val_acc": 72.0}
{"epoch": 49, "training_loss": 112.63918542861938, "training_acc": 52.0, "val_loss": 22.348345816135406, "val_acc": 72.0}
{"epoch": 50, "training_loss": 101.11158561706543, "training_acc": 72.0, "val_loss": 20.48095315694809, "val_acc": 72.0}
{"epoch": 51, "training_loss": 128.39915084838867, "training_acc": 50.0, "val_loss": 19.107867777347565, "val_acc": 72.0}
{"epoch": 52, "training_loss": 83.18016624450684, "training_acc": 72.0, "val_loss": 17.33758896589279, "val_acc": 72.0}
{"epoch": 53, "training_loss": 102.82526779174805, "training_acc": 52.0, "val_loss": 21.13742083311081, "val_acc": 72.0}
{"epoch": 54, "training_loss": 87.3735523223877, "training_acc": 72.0, "val_loss": 16.421419382095337, "val_acc": 72.0}
{"epoch": 55, "training_loss": 106.86767101287842, "training_acc": 50.0, "val_loss": 23.71094822883606, "val_acc": 72.0}
{"epoch": 56, "training_loss": 115.16599178314209, "training_acc": 72.0, "val_loss": 19.63280886411667, "val_acc": 72.0}
{"epoch": 57, "training_loss": 111.22404909133911, "training_acc": 56.0, "val_loss": 15.177354216575623, "val_acc": 72.0}
{"epoch": 58, "training_loss": 87.97432041168213, "training_acc": 72.0, "val_loss": 17.67713576555252, "val_acc": 72.0}
