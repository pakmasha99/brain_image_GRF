"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 366.12098693847656, "training_acc": 48.0, "val_loss": 239.4322395324707, "val_acc": 72.0}
{"epoch": 1, "training_loss": 712.0556468963623, "training_acc": 72.0, "val_loss": 248.66487979888916, "val_acc": 28.0}
{"epoch": 2, "training_loss": 861.9678001403809, "training_acc": 28.0, "val_loss": 55.99950551986694, "val_acc": 72.0}
{"epoch": 3, "training_loss": 349.89496994018555, "training_acc": 72.0, "val_loss": 136.51717901229858, "val_acc": 72.0}
{"epoch": 4, "training_loss": 515.3518314361572, "training_acc": 72.0, "val_loss": 68.15690994262695, "val_acc": 72.0}
{"epoch": 5, "training_loss": 217.84212923049927, "training_acc": 54.0, "val_loss": 63.00978660583496, "val_acc": 28.0}
{"epoch": 6, "training_loss": 209.48050260543823, "training_acc": 40.0, "val_loss": 38.31713795661926, "val_acc": 72.0}
{"epoch": 7, "training_loss": 138.3754382133484, "training_acc": 72.0, "val_loss": 21.062080562114716, "val_acc": 28.0}
{"epoch": 8, "training_loss": 78.10657358169556, "training_acc": 46.0, "val_loss": 24.686133861541748, "val_acc": 72.0}
{"epoch": 9, "training_loss": 98.15542578697205, "training_acc": 72.0, "val_loss": 15.588715672492981, "val_acc": 28.0}
{"epoch": 10, "training_loss": 72.9673547744751, "training_acc": 56.0, "val_loss": 22.246825695037842, "val_acc": 72.0}
{"epoch": 11, "training_loss": 92.66816830635071, "training_acc": 72.0, "val_loss": 14.778347313404083, "val_acc": 72.0}
{"epoch": 12, "training_loss": 90.70699405670166, "training_acc": 52.0, "val_loss": 24.457688629627228, "val_acc": 72.0}
{"epoch": 13, "training_loss": 114.23631525039673, "training_acc": 72.0, "val_loss": 21.351000666618347, "val_acc": 72.0}
{"epoch": 14, "training_loss": 103.32673645019531, "training_acc": 56.0, "val_loss": 14.760909974575043, "val_acc": 72.0}
{"epoch": 15, "training_loss": 70.76491951942444, "training_acc": 72.0, "val_loss": 18.52123588323593, "val_acc": 72.0}
{"epoch": 16, "training_loss": 84.94743275642395, "training_acc": 54.0, "val_loss": 15.750867128372192, "val_acc": 72.0}
{"epoch": 17, "training_loss": 69.48918080329895, "training_acc": 72.0, "val_loss": 14.97313380241394, "val_acc": 72.0}
{"epoch": 18, "training_loss": 65.99679613113403, "training_acc": 56.0, "val_loss": 18.873727321624756, "val_acc": 72.0}
{"epoch": 19, "training_loss": 73.64070725440979, "training_acc": 72.0, "val_loss": 15.516471862792969, "val_acc": 28.0}
{"epoch": 20, "training_loss": 62.75001573562622, "training_acc": 72.0, "val_loss": 15.610136091709137, "val_acc": 28.0}
{"epoch": 21, "training_loss": 63.53944492340088, "training_acc": 72.0, "val_loss": 14.747628569602966, "val_acc": 72.0}
{"epoch": 22, "training_loss": 67.58444571495056, "training_acc": 50.0, "val_loss": 23.659533262252808, "val_acc": 72.0}
{"epoch": 23, "training_loss": 91.3445394039154, "training_acc": 72.0, "val_loss": 16.046661138534546, "val_acc": 28.0}
{"epoch": 24, "training_loss": 70.1766927242279, "training_acc": 52.0, "val_loss": 26.682212948799133, "val_acc": 72.0}
{"epoch": 25, "training_loss": 108.47126722335815, "training_acc": 72.0, "val_loss": 14.798620343208313, "val_acc": 72.0}
{"epoch": 26, "training_loss": 98.61597919464111, "training_acc": 52.0, "val_loss": 27.96550989151001, "val_acc": 72.0}
{"epoch": 27, "training_loss": 119.48471879959106, "training_acc": 72.0, "val_loss": 26.721501350402832, "val_acc": 72.0}
{"epoch": 28, "training_loss": 94.41970801353455, "training_acc": 58.0, "val_loss": 18.083642423152924, "val_acc": 28.0}
{"epoch": 29, "training_loss": 76.20406723022461, "training_acc": 46.0, "val_loss": 24.493731558322906, "val_acc": 72.0}
{"epoch": 30, "training_loss": 78.95317769050598, "training_acc": 72.0, "val_loss": 34.79051887989044, "val_acc": 28.0}
{"epoch": 31, "training_loss": 123.53934836387634, "training_acc": 44.0, "val_loss": 32.5045645236969, "val_acc": 72.0}
{"epoch": 32, "training_loss": 118.10456442832947, "training_acc": 72.0, "val_loss": 25.8722722530365, "val_acc": 28.0}
{"epoch": 33, "training_loss": 94.72495627403259, "training_acc": 44.0, "val_loss": 22.59741574525833, "val_acc": 72.0}
{"epoch": 34, "training_loss": 83.91131782531738, "training_acc": 72.0, "val_loss": 16.23939722776413, "val_acc": 28.0}
{"epoch": 35, "training_loss": 80.98743200302124, "training_acc": 72.0, "val_loss": 15.012110769748688, "val_acc": 72.0}
{"epoch": 36, "training_loss": 81.43940210342407, "training_acc": 54.0, "val_loss": 24.073760211467743, "val_acc": 72.0}
{"epoch": 37, "training_loss": 105.53247404098511, "training_acc": 72.0, "val_loss": 14.99258279800415, "val_acc": 72.0}
{"epoch": 38, "training_loss": 105.29440259933472, "training_acc": 54.0, "val_loss": 22.213126718997955, "val_acc": 72.0}
{"epoch": 39, "training_loss": 115.88957452774048, "training_acc": 72.0, "val_loss": 19.801947474479675, "val_acc": 72.0}
{"epoch": 40, "training_loss": 98.0612940788269, "training_acc": 60.0, "val_loss": 14.734485745429993, "val_acc": 72.0}
{"epoch": 41, "training_loss": 82.2112340927124, "training_acc": 72.0, "val_loss": 18.29623430967331, "val_acc": 72.0}
{"epoch": 42, "training_loss": 84.84466028213501, "training_acc": 58.0, "val_loss": 15.98016768693924, "val_acc": 72.0}
{"epoch": 43, "training_loss": 64.64313793182373, "training_acc": 72.0, "val_loss": 15.064750611782074, "val_acc": 72.0}
{"epoch": 44, "training_loss": 74.02053833007812, "training_acc": 52.0, "val_loss": 23.19873422384262, "val_acc": 72.0}
{"epoch": 45, "training_loss": 102.0546817779541, "training_acc": 72.0, "val_loss": 16.082948446273804, "val_acc": 28.0}
{"epoch": 46, "training_loss": 70.00900650024414, "training_acc": 60.0, "val_loss": 19.963689148426056, "val_acc": 72.0}
{"epoch": 47, "training_loss": 86.00808477401733, "training_acc": 72.0, "val_loss": 20.563781261444092, "val_acc": 28.0}
{"epoch": 48, "training_loss": 76.98451828956604, "training_acc": 40.0, "val_loss": 15.204140543937683, "val_acc": 72.0}
{"epoch": 49, "training_loss": 62.51130247116089, "training_acc": 72.0, "val_loss": 15.57500958442688, "val_acc": 72.0}
{"epoch": 50, "training_loss": 61.509663581848145, "training_acc": 72.0, "val_loss": 18.04947257041931, "val_acc": 28.0}
{"epoch": 51, "training_loss": 73.37250757217407, "training_acc": 42.0, "val_loss": 15.278324484825134, "val_acc": 72.0}
{"epoch": 52, "training_loss": 76.23895716667175, "training_acc": 52.0, "val_loss": 24.26704317331314, "val_acc": 72.0}
{"epoch": 53, "training_loss": 101.39569568634033, "training_acc": 72.0, "val_loss": 15.487891435623169, "val_acc": 28.0}
{"epoch": 54, "training_loss": 86.84512329101562, "training_acc": 52.0, "val_loss": 32.793715596199036, "val_acc": 72.0}
{"epoch": 55, "training_loss": 146.8571000099182, "training_acc": 72.0, "val_loss": 28.356286883354187, "val_acc": 72.0}
{"epoch": 56, "training_loss": 92.77104687690735, "training_acc": 62.0, "val_loss": 21.348416805267334, "val_acc": 28.0}
{"epoch": 57, "training_loss": 74.51627898216248, "training_acc": 52.0, "val_loss": 36.66115403175354, "val_acc": 72.0}
{"epoch": 58, "training_loss": 126.74786376953125, "training_acc": 72.0, "val_loss": 36.62165403366089, "val_acc": 28.0}
{"epoch": 59, "training_loss": 112.95579814910889, "training_acc": 46.0, "val_loss": 24.952557682991028, "val_acc": 72.0}
