"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 485.1089744567871, "training_acc": 42.0, "val_loss": 228.07292938232422, "val_acc": 72.0}
{"epoch": 1, "training_loss": 687.4999027252197, "training_acc": 72.0, "val_loss": 211.47465705871582, "val_acc": 28.0}
{"epoch": 2, "training_loss": 747.8605461120605, "training_acc": 28.0, "val_loss": 55.270200967788696, "val_acc": 72.0}
{"epoch": 3, "training_loss": 306.0922546386719, "training_acc": 72.0, "val_loss": 132.47888088226318, "val_acc": 72.0}
{"epoch": 4, "training_loss": 506.9757423400879, "training_acc": 72.0, "val_loss": 73.884516954422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 252.71648359298706, "training_acc": 72.0, "val_loss": 89.38878178596497, "val_acc": 28.0}
{"epoch": 6, "training_loss": 255.05563306808472, "training_acc": 28.0, "val_loss": 50.24370551109314, "val_acc": 72.0}
{"epoch": 7, "training_loss": 216.47271728515625, "training_acc": 72.0, "val_loss": 62.66385316848755, "val_acc": 72.0}
{"epoch": 8, "training_loss": 210.71122121810913, "training_acc": 72.0, "val_loss": 30.414628982543945, "val_acc": 28.0}
{"epoch": 9, "training_loss": 124.56809949874878, "training_acc": 28.0, "val_loss": 37.060546875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 175.53140354156494, "training_acc": 72.0, "val_loss": 51.32781267166138, "val_acc": 72.0}
{"epoch": 11, "training_loss": 168.66748142242432, "training_acc": 72.0, "val_loss": 45.58972716331482, "val_acc": 28.0}
{"epoch": 12, "training_loss": 148.51747846603394, "training_acc": 28.0, "val_loss": 36.52936518192291, "val_acc": 72.0}
{"epoch": 13, "training_loss": 154.94606399536133, "training_acc": 72.0, "val_loss": 44.06619966030121, "val_acc": 72.0}
{"epoch": 14, "training_loss": 140.5901780128479, "training_acc": 72.0, "val_loss": 48.24139177799225, "val_acc": 28.0}
{"epoch": 15, "training_loss": 156.3554925918579, "training_acc": 28.0, "val_loss": 29.939764738082886, "val_acc": 72.0}
{"epoch": 16, "training_loss": 137.19278049468994, "training_acc": 72.0, "val_loss": 25.47776997089386, "val_acc": 72.0}
{"epoch": 17, "training_loss": 126.813148021698, "training_acc": 50.0, "val_loss": 14.933183789253235, "val_acc": 72.0}
{"epoch": 18, "training_loss": 84.33535623550415, "training_acc": 72.0, "val_loss": 20.475390553474426, "val_acc": 72.0}
{"epoch": 19, "training_loss": 98.62192440032959, "training_acc": 50.0, "val_loss": 15.17748236656189, "val_acc": 72.0}
{"epoch": 20, "training_loss": 64.48405027389526, "training_acc": 72.0, "val_loss": 15.382392704486847, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.049920320510864, "training_acc": 72.0, "val_loss": 16.919608414173126, "val_acc": 28.0}
{"epoch": 22, "training_loss": 68.74402594566345, "training_acc": 72.0, "val_loss": 17.371627688407898, "val_acc": 72.0}
{"epoch": 23, "training_loss": 71.70007348060608, "training_acc": 56.0, "val_loss": 14.736293256282806, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.91441631317139, "training_acc": 72.0, "val_loss": 14.72388356924057, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.57737731933594, "training_acc": 72.0, "val_loss": 14.749424159526825, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.006097078323364, "training_acc": 72.0, "val_loss": 14.792656898498535, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.39755201339722, "training_acc": 72.0, "val_loss": 14.734666049480438, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.00170016288757, "training_acc": 72.0, "val_loss": 14.908204972743988, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.431061029434204, "training_acc": 72.0, "val_loss": 14.745205640792847, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.34064602851868, "training_acc": 72.0, "val_loss": 19.06318962574005, "val_acc": 72.0}
{"epoch": 31, "training_loss": 74.74891781806946, "training_acc": 72.0, "val_loss": 32.45381414890289, "val_acc": 28.0}
{"epoch": 32, "training_loss": 99.35763120651245, "training_acc": 48.0, "val_loss": 26.002317667007446, "val_acc": 72.0}
{"epoch": 33, "training_loss": 93.81124091148376, "training_acc": 72.0, "val_loss": 23.369574546813965, "val_acc": 28.0}
{"epoch": 34, "training_loss": 93.94446659088135, "training_acc": 40.0, "val_loss": 17.306123673915863, "val_acc": 72.0}
{"epoch": 35, "training_loss": 73.13107085227966, "training_acc": 56.0, "val_loss": 15.538322925567627, "val_acc": 72.0}
{"epoch": 36, "training_loss": 62.54870867729187, "training_acc": 72.0, "val_loss": 14.973476529121399, "val_acc": 72.0}
{"epoch": 37, "training_loss": 63.10377740859985, "training_acc": 72.0, "val_loss": 19.6180060505867, "val_acc": 28.0}
{"epoch": 38, "training_loss": 79.78038763999939, "training_acc": 42.0, "val_loss": 16.52796119451523, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.99771595001221, "training_acc": 72.0, "val_loss": 21.491238474845886, "val_acc": 28.0}
{"epoch": 40, "training_loss": 102.1043848991394, "training_acc": 40.0, "val_loss": 24.76135343313217, "val_acc": 72.0}
{"epoch": 41, "training_loss": 84.35835862159729, "training_acc": 72.0, "val_loss": 20.810848474502563, "val_acc": 28.0}
{"epoch": 42, "training_loss": 83.51472401618958, "training_acc": 46.0, "val_loss": 26.720035076141357, "val_acc": 72.0}
{"epoch": 43, "training_loss": 98.22685647010803, "training_acc": 72.0, "val_loss": 17.074213922023773, "val_acc": 28.0}
