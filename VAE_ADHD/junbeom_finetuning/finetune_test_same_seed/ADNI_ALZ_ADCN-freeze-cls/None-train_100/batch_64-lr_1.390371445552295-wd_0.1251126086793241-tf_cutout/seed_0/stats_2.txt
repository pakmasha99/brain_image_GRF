"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5981.678398132324, "training_acc": 44.0, "val_loss": 2975.6370544433594, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8464.260009765625, "training_acc": 72.0, "val_loss": 5375.8880615234375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 18303.80484008789, "training_acc": 28.0, "val_loss": 711.8857383728027, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4126.728851318359, "training_acc": 72.0, "val_loss": 1544.6139335632324, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5412.20149230957, "training_acc": 72.0, "val_loss": 249.2769479751587, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3477.2528076171875, "training_acc": 58.0, "val_loss": 1358.7233543395996, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4256.388931274414, "training_acc": 44.0, "val_loss": 997.6779937744141, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3930.5205078125, "training_acc": 72.0, "val_loss": 608.2242488861084, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1583.0615112781525, "training_acc": 72.0, "val_loss": 1284.9614143371582, "val_acc": 28.0}
{"epoch": 9, "training_loss": 3726.9969177246094, "training_acc": 34.0, "val_loss": 30.369991064071655, "val_acc": 28.0}
{"epoch": 10, "training_loss": 892.8107986450195, "training_acc": 42.0, "val_loss": 581.1574459075928, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1929.3417053222656, "training_acc": 72.0, "val_loss": 446.4594841003418, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1697.1106491088867, "training_acc": 36.0, "val_loss": 135.7494354248047, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1050.356430053711, "training_acc": 58.0, "val_loss": 233.0371856689453, "val_acc": 72.0}
{"epoch": 14, "training_loss": 931.1084423065186, "training_acc": 72.0, "val_loss": 40.892988443374634, "val_acc": 72.0}
{"epoch": 15, "training_loss": 984.8953323364258, "training_acc": 66.0, "val_loss": 21.265991032123566, "val_acc": 72.0}
{"epoch": 16, "training_loss": 137.96740818023682, "training_acc": 72.0, "val_loss": 562.8071784973145, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1926.469440460205, "training_acc": 42.0, "val_loss": 373.8403797149658, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1182.6695194244385, "training_acc": 72.0, "val_loss": 717.0987606048584, "val_acc": 28.0}
{"epoch": 19, "training_loss": 2044.284086227417, "training_acc": 42.0, "val_loss": 106.43932819366455, "val_acc": 72.0}
{"epoch": 20, "training_loss": 476.2266025543213, "training_acc": 66.0, "val_loss": 317.76320934295654, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1291.1122856140137, "training_acc": 72.0, "val_loss": 102.00669765472412, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1671.4123840332031, "training_acc": 54.0, "val_loss": 21.092602610588074, "val_acc": 72.0}
{"epoch": 23, "training_loss": 183.55187129974365, "training_acc": 72.0, "val_loss": 314.4420623779297, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1283.60054397583, "training_acc": 46.0, "val_loss": 525.4034519195557, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1848.248176574707, "training_acc": 72.0, "val_loss": 134.83929634094238, "val_acc": 28.0}
{"epoch": 26, "training_loss": 730.5440788269043, "training_acc": 46.0, "val_loss": 332.56163597106934, "val_acc": 72.0}
{"epoch": 27, "training_loss": 963.5619783401489, "training_acc": 72.0, "val_loss": 979.0529251098633, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2638.275547027588, "training_acc": 28.0, "val_loss": 902.7370452880859, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4338.882858276367, "training_acc": 72.0, "val_loss": 1407.0035934448242, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5291.645935058594, "training_acc": 72.0, "val_loss": 672.3828792572021, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1812.642689704895, "training_acc": 72.0, "val_loss": 1704.207992553711, "val_acc": 28.0}
{"epoch": 32, "training_loss": 6289.956741333008, "training_acc": 28.0, "val_loss": 299.58269596099854, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1629.767333984375, "training_acc": 72.0, "val_loss": 644.7715282440186, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2261.2970542907715, "training_acc": 72.0, "val_loss": 243.12918186187744, "val_acc": 28.0}
{"epoch": 35, "training_loss": 805.6745872497559, "training_acc": 50.0, "val_loss": 277.1570682525635, "val_acc": 72.0}
{"epoch": 36, "training_loss": 774.3948183059692, "training_acc": 72.0, "val_loss": 1008.4054946899414, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2714.0429503917694, "training_acc": 37.0, "val_loss": 464.25490379333496, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1927.8093643188477, "training_acc": 72.0, "val_loss": 317.9455518722534, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1458.0455474853516, "training_acc": 52.0, "val_loss": 263.5768413543701, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1070.2033729553223, "training_acc": 72.0, "val_loss": 47.037091851234436, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1698.4900741577148, "training_acc": 54.0, "val_loss": 70.75479030609131, "val_acc": 28.0}
