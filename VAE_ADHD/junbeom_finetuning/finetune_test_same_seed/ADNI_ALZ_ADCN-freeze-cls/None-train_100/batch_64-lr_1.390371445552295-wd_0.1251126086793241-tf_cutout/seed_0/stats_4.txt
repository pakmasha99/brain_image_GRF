"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5993.16987991333, "training_acc": 72.0, "val_loss": 2218.5083389282227, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8027.813873291016, "training_acc": 56.0, "val_loss": 537.3736381530762, "val_acc": 72.0}
{"epoch": 2, "training_loss": 2260.519760131836, "training_acc": 72.0, "val_loss": 202.50091552734375, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1385.9451751708984, "training_acc": 48.0, "val_loss": 984.6408843994141, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3442.2404708862305, "training_acc": 72.0, "val_loss": 209.31077003479004, "val_acc": 28.0}
{"epoch": 5, "training_loss": 1204.9796295166016, "training_acc": 44.0, "val_loss": 478.497314453125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1396.9719047546387, "training_acc": 72.0, "val_loss": 1426.1994361877441, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3998.0381965637207, "training_acc": 28.0, "val_loss": 1030.2669525146484, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4685.887908935547, "training_acc": 72.0, "val_loss": 1615.139389038086, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6067.775833129883, "training_acc": 72.0, "val_loss": 813.3628845214844, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2055.3575401306152, "training_acc": 72.0, "val_loss": 1992.442512512207, "val_acc": 28.0}
{"epoch": 11, "training_loss": 7311.935043334961, "training_acc": 28.0, "val_loss": 214.6378755569458, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1418.4247665405273, "training_acc": 72.0, "val_loss": 435.8336925506592, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1213.0397357940674, "training_acc": 72.0, "val_loss": 1281.8309783935547, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3943.507987976074, "training_acc": 28.0, "val_loss": 740.0705814361572, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3451.288345336914, "training_acc": 72.0, "val_loss": 1144.627285003662, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4174.46467590332, "training_acc": 72.0, "val_loss": 377.7254343032837, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2182.3018493652344, "training_acc": 54.0, "val_loss": 169.30370330810547, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1541.0593643188477, "training_acc": 44.0, "val_loss": 1130.9423446655273, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4522.248886108398, "training_acc": 72.0, "val_loss": 816.8832778930664, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2533.755828857422, "training_acc": 72.0, "val_loss": 912.5347137451172, "val_acc": 28.0}
{"epoch": 21, "training_loss": 2887.931842803955, "training_acc": 28.0, "val_loss": 669.6710109710693, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3395.638641357422, "training_acc": 72.0, "val_loss": 986.7072105407715, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3504.9345169067383, "training_acc": 72.0, "val_loss": 136.07571125030518, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2248.01220703125, "training_acc": 56.0, "val_loss": 769.7977066040039, "val_acc": 28.0}
{"epoch": 25, "training_loss": 2578.3487701416016, "training_acc": 46.0, "val_loss": 871.7926025390625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3599.271514892578, "training_acc": 72.0, "val_loss": 588.1378173828125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1548.9768695831299, "training_acc": 72.0, "val_loss": 1532.296085357666, "val_acc": 28.0}
{"epoch": 28, "training_loss": 5462.968063354492, "training_acc": 28.0, "val_loss": 398.7872838973999, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2094.8532485961914, "training_acc": 72.0, "val_loss": 738.3127212524414, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2514.87255859375, "training_acc": 72.0, "val_loss": 54.932427406311035, "val_acc": 28.0}
{"epoch": 31, "training_loss": 395.93064308166504, "training_acc": 46.0, "val_loss": 130.78347444534302, "val_acc": 72.0}
{"epoch": 32, "training_loss": 749.0834159851074, "training_acc": 62.0, "val_loss": 250.66211223602295, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1069.312816619873, "training_acc": 72.0, "val_loss": 33.85210037231445, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1758.206527709961, "training_acc": 54.0, "val_loss": 179.43785190582275, "val_acc": 28.0}
{"epoch": 35, "training_loss": 1682.6355590820312, "training_acc": 44.0, "val_loss": 1277.4276733398438, "val_acc": 72.0}
{"epoch": 36, "training_loss": 5221.191680908203, "training_acc": 72.0, "val_loss": 1054.317855834961, "val_acc": 72.0}
{"epoch": 37, "training_loss": 3624.069496154785, "training_acc": 72.0, "val_loss": 190.37116765975952, "val_acc": 28.0}
{"epoch": 38, "training_loss": 750.1205043792725, "training_acc": 42.0, "val_loss": 49.61877465248108, "val_acc": 72.0}
{"epoch": 39, "training_loss": 761.2396469116211, "training_acc": 66.0, "val_loss": 121.10347747802734, "val_acc": 72.0}
{"epoch": 40, "training_loss": 442.8027515411377, "training_acc": 72.0, "val_loss": 391.39580726623535, "val_acc": 28.0}
{"epoch": 41, "training_loss": 1401.2039031982422, "training_acc": 46.0, "val_loss": 448.4973430633545, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1536.621696472168, "training_acc": 72.0, "val_loss": 340.3477430343628, "val_acc": 28.0}
{"epoch": 43, "training_loss": 953.8911380767822, "training_acc": 52.0, "val_loss": 264.71855640411377, "val_acc": 72.0}
{"epoch": 44, "training_loss": 812.3387467861176, "training_acc": 72.0, "val_loss": 505.19394874572754, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1665.6385040283203, "training_acc": 46.0, "val_loss": 452.79693603515625, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1617.1102619171143, "training_acc": 72.0, "val_loss": 271.92633152008057, "val_acc": 28.0}
{"epoch": 47, "training_loss": 1161.3935050964355, "training_acc": 44.0, "val_loss": 381.3183546066284, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1180.565128326416, "training_acc": 72.0, "val_loss": 742.6511287689209, "val_acc": 28.0}
{"epoch": 49, "training_loss": 1963.9289536476135, "training_acc": 44.0, "val_loss": 34.443479776382446, "val_acc": 72.0}
{"epoch": 50, "training_loss": 778.4169692993164, "training_acc": 60.0, "val_loss": 249.3699073791504, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1254.3697357177734, "training_acc": 72.0, "val_loss": 99.31437373161316, "val_acc": 72.0}
{"epoch": 52, "training_loss": 1905.5767974853516, "training_acc": 52.0, "val_loss": 104.51970100402832, "val_acc": 28.0}
