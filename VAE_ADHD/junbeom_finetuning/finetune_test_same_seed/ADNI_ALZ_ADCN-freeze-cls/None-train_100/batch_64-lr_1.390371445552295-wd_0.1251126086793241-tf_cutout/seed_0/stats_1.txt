"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5386.8110275268555, "training_acc": 72.0, "val_loss": 2726.958465576172, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7460.496736526489, "training_acc": 72.0, "val_loss": 7027.947235107422, "val_acc": 28.0}
{"epoch": 2, "training_loss": 24464.249572753906, "training_acc": 28.0, "val_loss": 317.1269416809082, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2190.941360473633, "training_acc": 72.0, "val_loss": 1288.1447792053223, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4604.989562988281, "training_acc": 72.0, "val_loss": 161.35512590408325, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3463.2184448242188, "training_acc": 56.0, "val_loss": 1129.3532371520996, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4673.804000854492, "training_acc": 36.0, "val_loss": 1171.966552734375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4587.218856811523, "training_acc": 72.0, "val_loss": 737.6918792724609, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2233.347719192505, "training_acc": 72.0, "val_loss": 1588.3811950683594, "val_acc": 28.0}
{"epoch": 9, "training_loss": 5360.354888916016, "training_acc": 28.0, "val_loss": 617.8313255310059, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3390.300079345703, "training_acc": 72.0, "val_loss": 1090.1857376098633, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3901.111083984375, "training_acc": 72.0, "val_loss": 231.02574348449707, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2159.352493286133, "training_acc": 58.0, "val_loss": 602.8144836425781, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3002.339370727539, "training_acc": 36.0, "val_loss": 951.276683807373, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3719.854949951172, "training_acc": 72.0, "val_loss": 548.9249229431152, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1527.456687927246, "training_acc": 54.0, "val_loss": 26.62525177001953, "val_acc": 72.0}
{"epoch": 16, "training_loss": 992.1227340698242, "training_acc": 52.0, "val_loss": 317.77398586273193, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1562.3224868774414, "training_acc": 72.0, "val_loss": 291.5461301803589, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1107.7326049804688, "training_acc": 58.0, "val_loss": 242.37060546875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1016.7911949157715, "training_acc": 72.0, "val_loss": 72.17543125152588, "val_acc": 28.0}
{"epoch": 20, "training_loss": 680.1910438537598, "training_acc": 46.0, "val_loss": 460.8693599700928, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1563.0753574371338, "training_acc": 72.0, "val_loss": 467.356014251709, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1102.9244542121887, "training_acc": 56.0, "val_loss": 226.51517391204834, "val_acc": 72.0}
{"epoch": 23, "training_loss": 643.1838140487671, "training_acc": 72.0, "val_loss": 921.1543083190918, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2276.286610364914, "training_acc": 40.0, "val_loss": 530.4646968841553, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2296.664649963379, "training_acc": 72.0, "val_loss": 467.0989513397217, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1419.560287475586, "training_acc": 72.0, "val_loss": 735.913610458374, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2061.4172229766846, "training_acc": 46.0, "val_loss": 273.793363571167, "val_acc": 72.0}
{"epoch": 28, "training_loss": 811.3796110153198, "training_acc": 72.0, "val_loss": 883.1575393676758, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2154.4268341064453, "training_acc": 28.0, "val_loss": 988.2386207580566, "val_acc": 72.0}
{"epoch": 30, "training_loss": 4643.791275024414, "training_acc": 72.0, "val_loss": 1545.1178550720215, "val_acc": 72.0}
{"epoch": 31, "training_loss": 5878.102249145508, "training_acc": 72.0, "val_loss": 847.4530220031738, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2906.240436553955, "training_acc": 72.0, "val_loss": 1223.4063148498535, "val_acc": 28.0}
{"epoch": 33, "training_loss": 4109.028419494629, "training_acc": 28.0, "val_loss": 582.5507164001465, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2852.351348876953, "training_acc": 72.0, "val_loss": 942.161750793457, "val_acc": 72.0}
