"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1013.504768371582, "training_acc": 42.0, "val_loss": 530.1134586334229, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1664.490177154541, "training_acc": 72.0, "val_loss": 309.73100662231445, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1057.0925483703613, "training_acc": 28.0, "val_loss": 168.14385652542114, "val_acc": 72.0}
{"epoch": 3, "training_loss": 867.2989501953125, "training_acc": 72.0, "val_loss": 354.73601818084717, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1388.9169883728027, "training_acc": 72.0, "val_loss": 250.52292346954346, "val_acc": 72.0}
{"epoch": 5, "training_loss": 873.8468790054321, "training_acc": 72.0, "val_loss": 172.90493249893188, "val_acc": 28.0}
{"epoch": 6, "training_loss": 681.1049156188965, "training_acc": 28.0, "val_loss": 64.03961181640625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 313.4474229812622, "training_acc": 72.0, "val_loss": 140.10889530181885, "val_acc": 72.0}
{"epoch": 8, "training_loss": 514.1900539398193, "training_acc": 72.0, "val_loss": 32.9609751701355, "val_acc": 72.0}
{"epoch": 9, "training_loss": 476.7330856323242, "training_acc": 50.0, "val_loss": 174.96577501296997, "val_acc": 28.0}
{"epoch": 10, "training_loss": 531.7929782867432, "training_acc": 44.0, "val_loss": 132.13050365447998, "val_acc": 72.0}
{"epoch": 11, "training_loss": 562.0358390808105, "training_acc": 72.0, "val_loss": 135.785174369812, "val_acc": 72.0}
{"epoch": 12, "training_loss": 461.2744493484497, "training_acc": 72.0, "val_loss": 57.79140591621399, "val_acc": 28.0}
{"epoch": 13, "training_loss": 201.23946332931519, "training_acc": 28.0, "val_loss": 95.21128535270691, "val_acc": 72.0}
{"epoch": 14, "training_loss": 488.79166412353516, "training_acc": 72.0, "val_loss": 167.72124767303467, "val_acc": 72.0}
{"epoch": 15, "training_loss": 621.9423561096191, "training_acc": 72.0, "val_loss": 65.73312282562256, "val_acc": 72.0}
{"epoch": 16, "training_loss": 278.88364028930664, "training_acc": 60.0, "val_loss": 86.79502606391907, "val_acc": 28.0}
{"epoch": 17, "training_loss": 270.6848244667053, "training_acc": 50.0, "val_loss": 122.95013666152954, "val_acc": 72.0}
{"epoch": 18, "training_loss": 530.2919864654541, "training_acc": 72.0, "val_loss": 111.55836582183838, "val_acc": 72.0}
{"epoch": 19, "training_loss": 368.8831799030304, "training_acc": 72.0, "val_loss": 157.89525508880615, "val_acc": 28.0}
{"epoch": 20, "training_loss": 577.288990020752, "training_acc": 28.0, "val_loss": 69.3801760673523, "val_acc": 72.0}
{"epoch": 21, "training_loss": 412.33936500549316, "training_acc": 72.0, "val_loss": 157.8190565109253, "val_acc": 72.0}
{"epoch": 22, "training_loss": 593.5588436126709, "training_acc": 72.0, "val_loss": 69.46597099304199, "val_acc": 72.0}
{"epoch": 23, "training_loss": 300.31743240356445, "training_acc": 54.0, "val_loss": 38.114309310913086, "val_acc": 28.0}
{"epoch": 24, "training_loss": 215.38957500457764, "training_acc": 44.0, "val_loss": 130.94645738601685, "val_acc": 72.0}
{"epoch": 25, "training_loss": 533.3666896820068, "training_acc": 72.0, "val_loss": 101.03341341018677, "val_acc": 72.0}
{"epoch": 26, "training_loss": 307.1675343513489, "training_acc": 72.0, "val_loss": 190.19277095794678, "val_acc": 28.0}
{"epoch": 27, "training_loss": 719.654863357544, "training_acc": 28.0, "val_loss": 47.215285897254944, "val_acc": 72.0}
