"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1013.523754119873, "training_acc": 42.0, "val_loss": 546.2648868560791, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1778.5666313171387, "training_acc": 72.0, "val_loss": 213.57543468475342, "val_acc": 28.0}
{"epoch": 2, "training_loss": 615.6530132293701, "training_acc": 28.0, "val_loss": 218.3513879776001, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1057.2294425964355, "training_acc": 72.0, "val_loss": 386.8978261947632, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1504.1701736450195, "training_acc": 72.0, "val_loss": 260.798978805542, "val_acc": 72.0}
{"epoch": 5, "training_loss": 863.5341997146606, "training_acc": 72.0, "val_loss": 220.94111442565918, "val_acc": 28.0}
{"epoch": 6, "training_loss": 906.1368942260742, "training_acc": 28.0, "val_loss": 26.992714405059814, "val_acc": 72.0}
{"epoch": 7, "training_loss": 266.76698112487793, "training_acc": 72.0, "val_loss": 93.9393162727356, "val_acc": 72.0}
{"epoch": 8, "training_loss": 307.2795686721802, "training_acc": 72.0, "val_loss": 147.68033027648926, "val_acc": 28.0}
{"epoch": 9, "training_loss": 450.35214138031006, "training_acc": 28.0, "val_loss": 118.5831069946289, "val_acc": 72.0}
{"epoch": 10, "training_loss": 591.7259826660156, "training_acc": 72.0, "val_loss": 231.8204402923584, "val_acc": 72.0}
{"epoch": 11, "training_loss": 906.2058868408203, "training_acc": 72.0, "val_loss": 158.1884741783142, "val_acc": 72.0}
{"epoch": 12, "training_loss": 538.0604538917542, "training_acc": 72.0, "val_loss": 135.9362006187439, "val_acc": 28.0}
{"epoch": 13, "training_loss": 524.3672122955322, "training_acc": 28.0, "val_loss": 64.79812264442444, "val_acc": 72.0}
{"epoch": 14, "training_loss": 303.4853391647339, "training_acc": 72.0, "val_loss": 139.34975862503052, "val_acc": 72.0}
{"epoch": 15, "training_loss": 527.5908756256104, "training_acc": 72.0, "val_loss": 58.62619876861572, "val_acc": 72.0}
{"epoch": 16, "training_loss": 246.36059951782227, "training_acc": 60.0, "val_loss": 46.9025194644928, "val_acc": 28.0}
{"epoch": 17, "training_loss": 244.84056854248047, "training_acc": 44.0, "val_loss": 142.95929670333862, "val_acc": 72.0}
{"epoch": 18, "training_loss": 595.972375869751, "training_acc": 72.0, "val_loss": 121.43869400024414, "val_acc": 72.0}
{"epoch": 19, "training_loss": 357.10343837738037, "training_acc": 72.0, "val_loss": 147.49690294265747, "val_acc": 28.0}
{"epoch": 20, "training_loss": 601.3737354278564, "training_acc": 28.0, "val_loss": 45.81538140773773, "val_acc": 72.0}
{"epoch": 21, "training_loss": 264.10945892333984, "training_acc": 72.0, "val_loss": 114.74872827529907, "val_acc": 72.0}
{"epoch": 22, "training_loss": 418.91447734832764, "training_acc": 72.0, "val_loss": 21.192577481269836, "val_acc": 72.0}
{"epoch": 23, "training_loss": 359.02227783203125, "training_acc": 52.0, "val_loss": 125.54645538330078, "val_acc": 28.0}
{"epoch": 24, "training_loss": 314.0444715023041, "training_acc": 56.0, "val_loss": 144.5547103881836, "val_acc": 72.0}
{"epoch": 25, "training_loss": 638.6646881103516, "training_acc": 72.0, "val_loss": 174.93689060211182, "val_acc": 72.0}
{"epoch": 26, "training_loss": 628.3763637542725, "training_acc": 72.0, "val_loss": 44.99370455741882, "val_acc": 72.0}
{"epoch": 27, "training_loss": 332.9942283630371, "training_acc": 60.0, "val_loss": 185.70880889892578, "val_acc": 28.0}
{"epoch": 28, "training_loss": 509.6399235725403, "training_acc": 44.0, "val_loss": 75.7578194141388, "val_acc": 72.0}
{"epoch": 29, "training_loss": 318.19313526153564, "training_acc": 72.0, "val_loss": 51.28602981567383, "val_acc": 72.0}
{"epoch": 30, "training_loss": 143.3477749824524, "training_acc": 64.0, "val_loss": 21.386870741844177, "val_acc": 28.0}
{"epoch": 31, "training_loss": 169.25400066375732, "training_acc": 38.0, "val_loss": 67.4558937549591, "val_acc": 72.0}
{"epoch": 32, "training_loss": 223.07388544082642, "training_acc": 72.0, "val_loss": 92.54316687583923, "val_acc": 28.0}
{"epoch": 33, "training_loss": 248.28713655471802, "training_acc": 31.0, "val_loss": 78.88105511665344, "val_acc": 72.0}
{"epoch": 34, "training_loss": 353.0376319885254, "training_acc": 72.0, "val_loss": 99.0952730178833, "val_acc": 72.0}
{"epoch": 35, "training_loss": 316.9758930206299, "training_acc": 72.0, "val_loss": 87.3220145702362, "val_acc": 28.0}
{"epoch": 36, "training_loss": 279.8299708366394, "training_acc": 28.0, "val_loss": 93.59829425811768, "val_acc": 72.0}
{"epoch": 37, "training_loss": 435.2676410675049, "training_acc": 72.0, "val_loss": 163.4801745414734, "val_acc": 72.0}
{"epoch": 38, "training_loss": 621.2153024673462, "training_acc": 72.0, "val_loss": 73.3205258846283, "val_acc": 72.0}
{"epoch": 39, "training_loss": 283.2760124206543, "training_acc": 54.0, "val_loss": 21.881230175495148, "val_acc": 28.0}
{"epoch": 40, "training_loss": 175.59360122680664, "training_acc": 40.0, "val_loss": 87.98507452011108, "val_acc": 72.0}
{"epoch": 41, "training_loss": 317.93907165527344, "training_acc": 72.0, "val_loss": 15.03143161535263, "val_acc": 60.0}
{"epoch": 42, "training_loss": 241.5545883178711, "training_acc": 48.0, "val_loss": 28.019079566001892, "val_acc": 72.0}
{"epoch": 43, "training_loss": 139.84216356277466, "training_acc": 72.0, "val_loss": 43.92455816268921, "val_acc": 72.0}
{"epoch": 44, "training_loss": 144.7185070514679, "training_acc": 56.0, "val_loss": 14.437326788902283, "val_acc": 72.0}
{"epoch": 45, "training_loss": 79.51297998428345, "training_acc": 72.0, "val_loss": 39.130812883377075, "val_acc": 28.0}
{"epoch": 46, "training_loss": 146.64557123184204, "training_acc": 46.0, "val_loss": 48.44427704811096, "val_acc": 72.0}
{"epoch": 47, "training_loss": 149.31828212738037, "training_acc": 72.0, "val_loss": 117.7646279335022, "val_acc": 28.0}
{"epoch": 48, "training_loss": 332.78319931030273, "training_acc": 28.0, "val_loss": 97.09396362304688, "val_acc": 72.0}
{"epoch": 49, "training_loss": 474.9995651245117, "training_acc": 72.0, "val_loss": 157.93914794921875, "val_acc": 72.0}
{"epoch": 50, "training_loss": 576.4564304351807, "training_acc": 72.0, "val_loss": 48.39433133602142, "val_acc": 72.0}
{"epoch": 51, "training_loss": 331.8330841064453, "training_acc": 58.0, "val_loss": 144.00407075881958, "val_acc": 28.0}
{"epoch": 52, "training_loss": 407.66887760162354, "training_acc": 48.0, "val_loss": 107.6772928237915, "val_acc": 72.0}
{"epoch": 53, "training_loss": 469.0923557281494, "training_acc": 72.0, "val_loss": 94.79458332061768, "val_acc": 72.0}
{"epoch": 54, "training_loss": 303.14433217048645, "training_acc": 72.0, "val_loss": 180.7708978652954, "val_acc": 28.0}
{"epoch": 55, "training_loss": 641.2166366577148, "training_acc": 28.0, "val_loss": 83.10964703559875, "val_acc": 72.0}
{"epoch": 56, "training_loss": 431.57045555114746, "training_acc": 72.0, "val_loss": 195.22535800933838, "val_acc": 72.0}
{"epoch": 57, "training_loss": 768.0985298156738, "training_acc": 72.0, "val_loss": 135.78234910964966, "val_acc": 72.0}
{"epoch": 58, "training_loss": 408.0094347000122, "training_acc": 72.0, "val_loss": 181.29217624664307, "val_acc": 28.0}
{"epoch": 59, "training_loss": 733.9331932067871, "training_acc": 28.0, "val_loss": 25.68267285823822, "val_acc": 72.0}
{"epoch": 60, "training_loss": 210.05506324768066, "training_acc": 72.0, "val_loss": 84.30255055427551, "val_acc": 72.0}
{"epoch": 61, "training_loss": 276.25716972351074, "training_acc": 72.0, "val_loss": 80.8367133140564, "val_acc": 28.0}
{"epoch": 62, "training_loss": 232.28081917762756, "training_acc": 42.0, "val_loss": 59.791988134384155, "val_acc": 72.0}
{"epoch": 63, "training_loss": 248.38277053833008, "training_acc": 72.0, "val_loss": 44.10471320152283, "val_acc": 72.0}
