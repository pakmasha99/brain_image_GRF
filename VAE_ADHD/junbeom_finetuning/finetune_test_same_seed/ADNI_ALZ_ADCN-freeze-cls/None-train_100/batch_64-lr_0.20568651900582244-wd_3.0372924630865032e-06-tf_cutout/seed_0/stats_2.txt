"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 925.4003143310547, "training_acc": 44.0, "val_loss": 530.4839134216309, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1669.9052848815918, "training_acc": 72.0, "val_loss": 391.60356521606445, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1304.4949131011963, "training_acc": 28.0, "val_loss": 166.08026027679443, "val_acc": 72.0}
{"epoch": 3, "training_loss": 801.9266777038574, "training_acc": 72.0, "val_loss": 335.693097114563, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1303.5059394836426, "training_acc": 72.0, "val_loss": 218.2103157043457, "val_acc": 72.0}
{"epoch": 5, "training_loss": 652.7536277770996, "training_acc": 72.0, "val_loss": 245.46005725860596, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1002.5849533081055, "training_acc": 28.0, "val_loss": 24.36399757862091, "val_acc": 72.0}
{"epoch": 7, "training_loss": 191.95612621307373, "training_acc": 72.0, "val_loss": 102.45707035064697, "val_acc": 72.0}
{"epoch": 8, "training_loss": 361.7251625061035, "training_acc": 72.0, "val_loss": 55.60557246208191, "val_acc": 28.0}
{"epoch": 9, "training_loss": 169.27193188667297, "training_acc": 46.0, "val_loss": 27.495360374450684, "val_acc": 72.0}
{"epoch": 10, "training_loss": 121.26259469985962, "training_acc": 56.0, "val_loss": 46.24343514442444, "val_acc": 72.0}
{"epoch": 11, "training_loss": 205.46670627593994, "training_acc": 72.0, "val_loss": 18.79883110523224, "val_acc": 72.0}
{"epoch": 12, "training_loss": 227.68345260620117, "training_acc": 58.0, "val_loss": 18.220503628253937, "val_acc": 28.0}
{"epoch": 13, "training_loss": 216.7830104827881, "training_acc": 38.0, "val_loss": 119.27429437637329, "val_acc": 72.0}
{"epoch": 14, "training_loss": 448.8074722290039, "training_acc": 72.0, "val_loss": 39.26890790462494, "val_acc": 72.0}
{"epoch": 15, "training_loss": 329.36625480651855, "training_acc": 56.0, "val_loss": 101.17099285125732, "val_acc": 28.0}
{"epoch": 16, "training_loss": 359.9605255126953, "training_acc": 46.0, "val_loss": 157.51076936721802, "val_acc": 72.0}
{"epoch": 17, "training_loss": 663.6215267181396, "training_acc": 72.0, "val_loss": 163.54011297225952, "val_acc": 72.0}
{"epoch": 18, "training_loss": 549.022050857544, "training_acc": 72.0, "val_loss": 15.110798180103302, "val_acc": 72.0}
{"epoch": 19, "training_loss": 378.19525146484375, "training_acc": 58.0, "val_loss": 216.579270362854, "val_acc": 28.0}
{"epoch": 20, "training_loss": 656.8434090614319, "training_acc": 38.0, "val_loss": 93.82786154747009, "val_acc": 72.0}
{"epoch": 21, "training_loss": 413.307580947876, "training_acc": 72.0, "val_loss": 75.04438757896423, "val_acc": 72.0}
{"epoch": 22, "training_loss": 204.6405725479126, "training_acc": 76.0, "val_loss": 105.04496097564697, "val_acc": 28.0}
{"epoch": 23, "training_loss": 272.7886006832123, "training_acc": 50.0, "val_loss": 54.535919427871704, "val_acc": 72.0}
{"epoch": 24, "training_loss": 218.7421293258667, "training_acc": 72.0, "val_loss": 21.718379855155945, "val_acc": 28.0}
{"epoch": 25, "training_loss": 81.17250370979309, "training_acc": 30.0, "val_loss": 37.05229163169861, "val_acc": 72.0}
{"epoch": 26, "training_loss": 138.1983585357666, "training_acc": 72.0, "val_loss": 44.46561336517334, "val_acc": 28.0}
{"epoch": 27, "training_loss": 162.18050527572632, "training_acc": 44.0, "val_loss": 40.22413492202759, "val_acc": 72.0}
{"epoch": 28, "training_loss": 117.29620122909546, "training_acc": 72.0, "val_loss": 65.78719019889832, "val_acc": 28.0}
{"epoch": 29, "training_loss": 316.9816617965698, "training_acc": 34.0, "val_loss": 77.71899104118347, "val_acc": 72.0}
{"epoch": 30, "training_loss": 269.9539017677307, "training_acc": 72.0, "val_loss": 41.93417131900787, "val_acc": 28.0}
{"epoch": 31, "training_loss": 128.324383020401, "training_acc": 46.0, "val_loss": 22.858375310897827, "val_acc": 72.0}
{"epoch": 32, "training_loss": 99.85846853256226, "training_acc": 56.0, "val_loss": 40.12369513511658, "val_acc": 72.0}
{"epoch": 33, "training_loss": 158.3406572341919, "training_acc": 72.0, "val_loss": 14.853829145431519, "val_acc": 64.0}
{"epoch": 34, "training_loss": 95.87945795059204, "training_acc": 58.0, "val_loss": 56.104183197021484, "val_acc": 72.0}
{"epoch": 35, "training_loss": 247.10582065582275, "training_acc": 72.0, "val_loss": 57.09744691848755, "val_acc": 72.0}
{"epoch": 36, "training_loss": 172.8488585948944, "training_acc": 56.0, "val_loss": 24.25766885280609, "val_acc": 28.0}
{"epoch": 37, "training_loss": 108.64883327484131, "training_acc": 50.0, "val_loss": 71.61813974380493, "val_acc": 72.0}
{"epoch": 38, "training_loss": 248.39217281341553, "training_acc": 72.0, "val_loss": 43.66632103919983, "val_acc": 28.0}
{"epoch": 39, "training_loss": 128.04058265686035, "training_acc": 48.0, "val_loss": 26.163065433502197, "val_acc": 72.0}
{"epoch": 40, "training_loss": 98.00058460235596, "training_acc": 56.0, "val_loss": 30.832719802856445, "val_acc": 72.0}
{"epoch": 41, "training_loss": 106.0897605419159, "training_acc": 72.0, "val_loss": 44.56362724304199, "val_acc": 28.0}
{"epoch": 42, "training_loss": 175.28518152236938, "training_acc": 46.0, "val_loss": 70.67096829414368, "val_acc": 72.0}
{"epoch": 43, "training_loss": 246.62262535095215, "training_acc": 72.0, "val_loss": 51.06912851333618, "val_acc": 28.0}
{"epoch": 44, "training_loss": 146.51168537139893, "training_acc": 50.0, "val_loss": 37.51083314418793, "val_acc": 72.0}
{"epoch": 45, "training_loss": 113.10005235671997, "training_acc": 72.0, "val_loss": 55.47342300415039, "val_acc": 28.0}
{"epoch": 46, "training_loss": 254.6276617050171, "training_acc": 40.0, "val_loss": 86.83812022209167, "val_acc": 72.0}
{"epoch": 47, "training_loss": 310.8892574310303, "training_acc": 72.0, "val_loss": 15.97614735364914, "val_acc": 36.0}
{"epoch": 48, "training_loss": 166.259934425354, "training_acc": 56.0, "val_loss": 57.282555103302, "val_acc": 72.0}
{"epoch": 49, "training_loss": 268.4186496734619, "training_acc": 72.0, "val_loss": 83.94944667816162, "val_acc": 72.0}
{"epoch": 50, "training_loss": 262.65940713882446, "training_acc": 72.0, "val_loss": 138.95118236541748, "val_acc": 28.0}
{"epoch": 51, "training_loss": 423.4130234718323, "training_acc": 28.0, "val_loss": 106.55471086502075, "val_acc": 72.0}
{"epoch": 52, "training_loss": 514.8549880981445, "training_acc": 72.0, "val_loss": 189.17053937911987, "val_acc": 72.0}
