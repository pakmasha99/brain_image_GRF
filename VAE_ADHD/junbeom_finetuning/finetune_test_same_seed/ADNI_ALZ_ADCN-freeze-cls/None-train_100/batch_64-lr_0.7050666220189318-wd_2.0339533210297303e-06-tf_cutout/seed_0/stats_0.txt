"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3365.4652404785156, "training_acc": 42.0, "val_loss": 1818.623924255371, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5711.550399780273, "training_acc": 72.0, "val_loss": 1057.9240798950195, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3608.387855529785, "training_acc": 28.0, "val_loss": 577.8453826904297, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2978.9297943115234, "training_acc": 72.0, "val_loss": 1217.4775123596191, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4767.042266845703, "training_acc": 72.0, "val_loss": 860.2689743041992, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3001.54585647583, "training_acc": 72.0, "val_loss": 588.7184143066406, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2318.596076965332, "training_acc": 28.0, "val_loss": 221.17092609405518, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1081.109489440918, "training_acc": 72.0, "val_loss": 481.97174072265625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1769.4416885375977, "training_acc": 72.0, "val_loss": 113.9681339263916, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1650.5209350585938, "training_acc": 50.0, "val_loss": 619.3954944610596, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1856.4495887756348, "training_acc": 44.0, "val_loss": 437.5399112701416, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1860.545036315918, "training_acc": 72.0, "val_loss": 444.0442085266113, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1492.5580787658691, "training_acc": 72.0, "val_loss": 261.3525867462158, "val_acc": 28.0}
{"epoch": 13, "training_loss": 856.6264038085938, "training_acc": 28.0, "val_loss": 381.13605976104736, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1996.6563720703125, "training_acc": 72.0, "val_loss": 746.226167678833, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2909.591278076172, "training_acc": 72.0, "val_loss": 502.5810718536377, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1483.1079139709473, "training_acc": 72.0, "val_loss": 626.4254093170166, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2772.430694580078, "training_acc": 28.0, "val_loss": 17.48654544353485, "val_acc": 72.0}
{"epoch": 18, "training_loss": 488.9246711730957, "training_acc": 72.0, "val_loss": 278.7886381149292, "val_acc": 72.0}
{"epoch": 19, "training_loss": 987.091854095459, "training_acc": 72.0, "val_loss": 132.11019039154053, "val_acc": 28.0}
{"epoch": 20, "training_loss": 454.8812074661255, "training_acc": 46.0, "val_loss": 112.36214637756348, "val_acc": 72.0}
{"epoch": 21, "training_loss": 269.47623324394226, "training_acc": 72.0, "val_loss": 507.546329498291, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1476.956859588623, "training_acc": 28.0, "val_loss": 420.4012393951416, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2044.2744216918945, "training_acc": 72.0, "val_loss": 846.8610763549805, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3375.469436645508, "training_acc": 72.0, "val_loss": 704.5031070709229, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2419.276268005371, "training_acc": 72.0, "val_loss": 79.28927540779114, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1757.8029022216797, "training_acc": 54.0, "val_loss": 1208.6308479309082, "val_acc": 28.0}
{"epoch": 27, "training_loss": 3822.55233001709, "training_acc": 28.0, "val_loss": 378.9813756942749, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2005.8080215454102, "training_acc": 72.0, "val_loss": 994.2666053771973, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4083.142562866211, "training_acc": 72.0, "val_loss": 1010.971736907959, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3829.5662155151367, "training_acc": 72.0, "val_loss": 518.2541370391846, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1347.4910469055176, "training_acc": 72.0, "val_loss": 903.7893295288086, "val_acc": 28.0}
{"epoch": 32, "training_loss": 4141.615310668945, "training_acc": 28.0, "val_loss": 595.9060668945312, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1808.437126159668, "training_acc": 48.0, "val_loss": 689.8260116577148, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3150.577590942383, "training_acc": 72.0, "val_loss": 974.2823600769043, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3769.908248901367, "training_acc": 72.0, "val_loss": 681.9808006286621, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2300.0307006835938, "training_acc": 72.0, "val_loss": 153.3738374710083, "val_acc": 28.0}
