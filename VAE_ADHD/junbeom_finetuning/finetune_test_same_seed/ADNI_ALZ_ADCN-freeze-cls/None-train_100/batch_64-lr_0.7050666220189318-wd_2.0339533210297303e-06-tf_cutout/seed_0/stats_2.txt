"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3980.2081985473633, "training_acc": 72.0, "val_loss": 1653.2800674438477, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5138.609146118164, "training_acc": 72.0, "val_loss": 1801.1449813842773, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6677.88525390625, "training_acc": 28.0, "val_loss": 248.07612895965576, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1728.836326599121, "training_acc": 72.0, "val_loss": 866.2291526794434, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3326.1650466918945, "training_acc": 72.0, "val_loss": 469.2690849304199, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1229.094857931137, "training_acc": 72.0, "val_loss": 1306.9381713867188, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5067.060073852539, "training_acc": 28.0, "val_loss": 30.555519461631775, "val_acc": 72.0}
{"epoch": 7, "training_loss": 474.8994483947754, "training_acc": 72.0, "val_loss": 406.9408416748047, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1521.2143058776855, "training_acc": 72.0, "val_loss": 95.87240219116211, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1451.6579132080078, "training_acc": 50.0, "val_loss": 412.05906867980957, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1497.9339179992676, "training_acc": 44.0, "val_loss": 595.906925201416, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2597.218505859375, "training_acc": 72.0, "val_loss": 665.0807857513428, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2390.0760345458984, "training_acc": 72.0, "val_loss": 141.64071083068848, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1632.4961242675781, "training_acc": 52.0, "val_loss": 785.1160526275635, "val_acc": 28.0}
{"epoch": 14, "training_loss": 2010.1089463233948, "training_acc": 46.0, "val_loss": 228.129243850708, "val_acc": 72.0}
{"epoch": 15, "training_loss": 942.6936492919922, "training_acc": 72.0, "val_loss": 156.73409700393677, "val_acc": 72.0}
{"epoch": 16, "training_loss": 550.9682025909424, "training_acc": 60.0, "val_loss": 78.82766723632812, "val_acc": 72.0}
{"epoch": 17, "training_loss": 288.7753896713257, "training_acc": 72.0, "val_loss": 219.43230628967285, "val_acc": 28.0}
{"epoch": 18, "training_loss": 743.4763298034668, "training_acc": 44.0, "val_loss": 187.42153644561768, "val_acc": 72.0}
{"epoch": 19, "training_loss": 624.6727390289307, "training_acc": 72.0, "val_loss": 274.11487102508545, "val_acc": 28.0}
{"epoch": 20, "training_loss": 841.8504457473755, "training_acc": 40.0, "val_loss": 62.07308769226074, "val_acc": 72.0}
{"epoch": 21, "training_loss": 351.8106174468994, "training_acc": 60.0, "val_loss": 145.1467752456665, "val_acc": 72.0}
{"epoch": 22, "training_loss": 668.3699264526367, "training_acc": 72.0, "val_loss": 113.31729888916016, "val_acc": 72.0}
{"epoch": 23, "training_loss": 932.348503112793, "training_acc": 48.0, "val_loss": 37.331801652908325, "val_acc": 72.0}
{"epoch": 24, "training_loss": 276.5776176452637, "training_acc": 72.0, "val_loss": 101.09878778457642, "val_acc": 28.0}
{"epoch": 25, "training_loss": 499.0214214324951, "training_acc": 44.0, "val_loss": 229.01208400726318, "val_acc": 72.0}
