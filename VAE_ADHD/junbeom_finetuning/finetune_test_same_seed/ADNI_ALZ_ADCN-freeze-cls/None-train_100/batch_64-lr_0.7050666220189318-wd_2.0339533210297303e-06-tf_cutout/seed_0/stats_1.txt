"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3358.6016540527344, "training_acc": 72.0, "val_loss": 1697.9591369628906, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4909.978530883789, "training_acc": 72.0, "val_loss": 1633.748435974121, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6085.724563598633, "training_acc": 28.0, "val_loss": 268.12334060668945, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1528.4271392822266, "training_acc": 72.0, "val_loss": 824.8299598693848, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3178.4702072143555, "training_acc": 72.0, "val_loss": 438.7180805206299, "val_acc": 72.0}
{"epoch": 5, "training_loss": 995.1509466171265, "training_acc": 72.0, "val_loss": 1502.4209022521973, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6072.825500488281, "training_acc": 28.0, "val_loss": 472.3386287689209, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2125.5090408325195, "training_acc": 42.0, "val_loss": 1072.2831726074219, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4964.632232666016, "training_acc": 72.0, "val_loss": 1494.471549987793, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5881.215286254883, "training_acc": 72.0, "val_loss": 1204.7670364379883, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4357.689231872559, "training_acc": 72.0, "val_loss": 379.491662979126, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1910.1615295410156, "training_acc": 52.0, "val_loss": 785.261344909668, "val_acc": 28.0}
{"epoch": 12, "training_loss": 2172.22456073761, "training_acc": 28.0, "val_loss": 525.9105205535889, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2687.5984954833984, "training_acc": 72.0, "val_loss": 1081.308364868164, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4410.412628173828, "training_acc": 72.0, "val_loss": 1007.3273658752441, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3706.143913269043, "training_acc": 72.0, "val_loss": 397.5733757019043, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1445.4424438476562, "training_acc": 52.0, "val_loss": 301.6815423965454, "val_acc": 28.0}
{"epoch": 17, "training_loss": 752.4591445922852, "training_acc": 56.0, "val_loss": 323.787784576416, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1341.959342956543, "training_acc": 72.0, "val_loss": 247.86362648010254, "val_acc": 72.0}
{"epoch": 19, "training_loss": 732.5413584709167, "training_acc": 69.0, "val_loss": 277.7454137802124, "val_acc": 28.0}
{"epoch": 20, "training_loss": 908.7458438873291, "training_acc": 44.0, "val_loss": 229.0257692337036, "val_acc": 72.0}
{"epoch": 21, "training_loss": 842.3955974578857, "training_acc": 72.0, "val_loss": 31.16302490234375, "val_acc": 28.0}
{"epoch": 22, "training_loss": 198.73465824127197, "training_acc": 46.0, "val_loss": 66.1589503288269, "val_acc": 72.0}
{"epoch": 23, "training_loss": 521.2348709106445, "training_acc": 56.0, "val_loss": 108.38600397109985, "val_acc": 72.0}
{"epoch": 24, "training_loss": 444.1685314178467, "training_acc": 72.0, "val_loss": 62.0275616645813, "val_acc": 72.0}
{"epoch": 25, "training_loss": 628.6755790710449, "training_acc": 56.0, "val_loss": 52.04846262931824, "val_acc": 72.0}
{"epoch": 26, "training_loss": 224.4808053970337, "training_acc": 72.0, "val_loss": 80.71439266204834, "val_acc": 28.0}
{"epoch": 27, "training_loss": 315.7459716796875, "training_acc": 54.0, "val_loss": 312.06862926483154, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1215.6627807617188, "training_acc": 72.0, "val_loss": 136.22348308563232, "val_acc": 72.0}
{"epoch": 29, "training_loss": 849.8122711181641, "training_acc": 56.0, "val_loss": 63.56282830238342, "val_acc": 28.0}
{"epoch": 30, "training_loss": 597.8998069763184, "training_acc": 48.0, "val_loss": 652.7534484863281, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2822.0652618408203, "training_acc": 72.0, "val_loss": 719.1302299499512, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2601.224411010742, "training_acc": 72.0, "val_loss": 229.42728996276855, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1205.4033584594727, "training_acc": 58.0, "val_loss": 536.0052585601807, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1473.423327445984, "training_acc": 46.0, "val_loss": 265.1123046875, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1079.1329231262207, "training_acc": 72.0, "val_loss": 149.63711500167847, "val_acc": 72.0}
{"epoch": 36, "training_loss": 822.1678047180176, "training_acc": 54.0, "val_loss": 23.311378061771393, "val_acc": 72.0}
{"epoch": 37, "training_loss": 86.53004789352417, "training_acc": 72.0, "val_loss": 145.89837789535522, "val_acc": 28.0}
{"epoch": 38, "training_loss": 640.024471282959, "training_acc": 46.0, "val_loss": 343.24398040771484, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1380.1017837524414, "training_acc": 72.0, "val_loss": 170.0228214263916, "val_acc": 72.0}
{"epoch": 40, "training_loss": 967.2355690002441, "training_acc": 54.0, "val_loss": 94.14123892784119, "val_acc": 28.0}
{"epoch": 41, "training_loss": 653.6730308532715, "training_acc": 48.0, "val_loss": 633.652400970459, "val_acc": 72.0}
{"epoch": 42, "training_loss": 2620.9949111938477, "training_acc": 72.0, "val_loss": 691.3110256195068, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2560.7162857055664, "training_acc": 72.0, "val_loss": 256.4992666244507, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1198.9482460021973, "training_acc": 54.0, "val_loss": 290.21852016448975, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1153.4785118103027, "training_acc": 42.0, "val_loss": 434.3271732330322, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1821.232063293457, "training_acc": 72.0, "val_loss": 360.5048179626465, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1097.6462593078613, "training_acc": 72.0, "val_loss": 606.7341804504395, "val_acc": 28.0}
{"epoch": 48, "training_loss": 2318.18204498291, "training_acc": 28.0, "val_loss": 160.61707735061646, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1061.8275833129883, "training_acc": 72.0, "val_loss": 411.0913276672363, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1529.2898960113525, "training_acc": 72.0, "val_loss": 63.221901655197144, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1045.0710372924805, "training_acc": 58.0, "val_loss": 506.1068534851074, "val_acc": 28.0}
{"epoch": 52, "training_loss": 1320.6224393844604, "training_acc": 52.0, "val_loss": 404.654598236084, "val_acc": 72.0}
{"epoch": 53, "training_loss": 1827.3896255493164, "training_acc": 72.0, "val_loss": 437.3420238494873, "val_acc": 72.0}
{"epoch": 54, "training_loss": 1482.2024536132812, "training_acc": 72.0, "val_loss": 214.1122341156006, "val_acc": 28.0}
{"epoch": 55, "training_loss": 612.5840682983398, "training_acc": 28.0, "val_loss": 345.63865661621094, "val_acc": 72.0}
