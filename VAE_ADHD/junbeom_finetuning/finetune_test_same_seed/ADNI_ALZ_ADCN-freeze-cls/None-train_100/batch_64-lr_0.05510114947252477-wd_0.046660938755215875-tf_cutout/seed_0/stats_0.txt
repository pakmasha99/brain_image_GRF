"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 304.2862186431885, "training_acc": 42.0, "val_loss": 141.14797115325928, "val_acc": 72.0}
{"epoch": 1, "training_loss": 441.8121747970581, "training_acc": 72.0, "val_loss": 86.79467439651489, "val_acc": 28.0}
{"epoch": 2, "training_loss": 302.2956371307373, "training_acc": 28.0, "val_loss": 41.438597440719604, "val_acc": 72.0}
{"epoch": 3, "training_loss": 215.15400409698486, "training_acc": 72.0, "val_loss": 87.33054399490356, "val_acc": 72.0}
{"epoch": 4, "training_loss": 337.6241912841797, "training_acc": 72.0, "val_loss": 54.687875509262085, "val_acc": 72.0}
{"epoch": 5, "training_loss": 187.96837675571442, "training_acc": 72.0, "val_loss": 69.47941184043884, "val_acc": 28.0}
{"epoch": 6, "training_loss": 258.06321716308594, "training_acc": 28.0, "val_loss": 18.495839834213257, "val_acc": 72.0}
{"epoch": 7, "training_loss": 92.58785486221313, "training_acc": 72.0, "val_loss": 48.62194061279297, "val_acc": 72.0}
{"epoch": 8, "training_loss": 189.18882179260254, "training_acc": 72.0, "val_loss": 28.346002101898193, "val_acc": 72.0}
{"epoch": 9, "training_loss": 113.7197151184082, "training_acc": 50.0, "val_loss": 32.91206359863281, "val_acc": 28.0}
{"epoch": 10, "training_loss": 105.45940947532654, "training_acc": 44.0, "val_loss": 23.40838313102722, "val_acc": 72.0}
{"epoch": 11, "training_loss": 97.98111724853516, "training_acc": 72.0, "val_loss": 19.44294571876526, "val_acc": 72.0}
{"epoch": 12, "training_loss": 77.66085290908813, "training_acc": 54.0, "val_loss": 21.73147201538086, "val_acc": 28.0}
{"epoch": 13, "training_loss": 70.81602478027344, "training_acc": 52.0, "val_loss": 22.70861566066742, "val_acc": 72.0}
{"epoch": 14, "training_loss": 96.94021129608154, "training_acc": 72.0, "val_loss": 17.621642351150513, "val_acc": 72.0}
{"epoch": 15, "training_loss": 67.69114184379578, "training_acc": 60.0, "val_loss": 23.786799609661102, "val_acc": 28.0}
{"epoch": 16, "training_loss": 88.90926456451416, "training_acc": 40.0, "val_loss": 20.74924409389496, "val_acc": 72.0}
{"epoch": 17, "training_loss": 79.58746361732483, "training_acc": 72.0, "val_loss": 14.934006333351135, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.08704352378845, "training_acc": 72.0, "val_loss": 15.395070612430573, "val_acc": 28.0}
{"epoch": 19, "training_loss": 58.87500500679016, "training_acc": 72.0, "val_loss": 17.361418902873993, "val_acc": 72.0}
{"epoch": 20, "training_loss": 67.5817596912384, "training_acc": 72.0, "val_loss": 14.940835535526276, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.813596963882446, "training_acc": 72.0, "val_loss": 15.204647183418274, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.35562014579773, "training_acc": 72.0, "val_loss": 15.380051732063293, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.07052731513977, "training_acc": 72.0, "val_loss": 14.878198504447937, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.20443844795227, "training_acc": 72.0, "val_loss": 14.874230325222015, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.30077362060547, "training_acc": 72.0, "val_loss": 14.99706655740738, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.192097187042236, "training_acc": 72.0, "val_loss": 15.30766636133194, "val_acc": 72.0}
{"epoch": 27, "training_loss": 61.25482130050659, "training_acc": 72.0, "val_loss": 14.753444492816925, "val_acc": 72.0}
{"epoch": 28, "training_loss": 61.233131885528564, "training_acc": 72.0, "val_loss": 15.121670067310333, "val_acc": 72.0}
{"epoch": 29, "training_loss": 61.53048396110535, "training_acc": 72.0, "val_loss": 14.651857316493988, "val_acc": 72.0}
{"epoch": 30, "training_loss": 66.9175717830658, "training_acc": 50.0, "val_loss": 16.45284593105316, "val_acc": 72.0}
{"epoch": 31, "training_loss": 77.42779397964478, "training_acc": 72.0, "val_loss": 14.645856618881226, "val_acc": 72.0}
{"epoch": 32, "training_loss": 80.72837114334106, "training_acc": 52.0, "val_loss": 15.501752495765686, "val_acc": 72.0}
{"epoch": 33, "training_loss": 66.94909262657166, "training_acc": 72.0, "val_loss": 19.293376803398132, "val_acc": 72.0}
{"epoch": 34, "training_loss": 66.95684504508972, "training_acc": 72.0, "val_loss": 24.81705993413925, "val_acc": 28.0}
{"epoch": 35, "training_loss": 85.57622456550598, "training_acc": 44.0, "val_loss": 20.895516872406006, "val_acc": 72.0}
{"epoch": 36, "training_loss": 78.52341151237488, "training_acc": 72.0, "val_loss": 16.292521357536316, "val_acc": 28.0}
{"epoch": 37, "training_loss": 65.13501214981079, "training_acc": 72.0, "val_loss": 14.700521528720856, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.024269104003906, "training_acc": 72.0, "val_loss": 14.61191177368164, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.858033418655396, "training_acc": 72.0, "val_loss": 17.3922598361969, "val_acc": 28.0}
{"epoch": 40, "training_loss": 68.8530056476593, "training_acc": 45.0, "val_loss": 15.224933624267578, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.36018109321594, "training_acc": 72.0, "val_loss": 15.794241428375244, "val_acc": 28.0}
{"epoch": 42, "training_loss": 60.87673354148865, "training_acc": 72.0, "val_loss": 16.464294493198395, "val_acc": 72.0}
{"epoch": 43, "training_loss": 64.81845784187317, "training_acc": 72.0, "val_loss": 14.702096581459045, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.702553510665894, "training_acc": 72.0, "val_loss": 14.718525111675262, "val_acc": 72.0}
{"epoch": 45, "training_loss": 58.72253131866455, "training_acc": 72.0, "val_loss": 15.04535973072052, "val_acc": 64.0}
{"epoch": 46, "training_loss": 60.15811562538147, "training_acc": 72.0, "val_loss": 16.944245994091034, "val_acc": 72.0}
{"epoch": 47, "training_loss": 67.79915404319763, "training_acc": 72.0, "val_loss": 17.002829909324646, "val_acc": 28.0}
{"epoch": 48, "training_loss": 68.58489799499512, "training_acc": 59.0, "val_loss": 20.43815553188324, "val_acc": 72.0}
{"epoch": 49, "training_loss": 82.56965208053589, "training_acc": 72.0, "val_loss": 14.641045033931732, "val_acc": 72.0}
{"epoch": 50, "training_loss": 80.70362997055054, "training_acc": 52.0, "val_loss": 16.730597615242004, "val_acc": 72.0}
{"epoch": 51, "training_loss": 73.38262677192688, "training_acc": 72.0, "val_loss": 17.285655438899994, "val_acc": 72.0}
{"epoch": 52, "training_loss": 73.28207468986511, "training_acc": 56.0, "val_loss": 14.926043152809143, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.65836453437805, "training_acc": 72.0, "val_loss": 19.06988173723221, "val_acc": 72.0}
{"epoch": 54, "training_loss": 69.54414010047913, "training_acc": 72.0, "val_loss": 19.529902935028076, "val_acc": 28.0}
{"epoch": 55, "training_loss": 68.4675784111023, "training_acc": 48.0, "val_loss": 20.418016612529755, "val_acc": 72.0}
{"epoch": 56, "training_loss": 76.86189794540405, "training_acc": 72.0, "val_loss": 16.18035137653351, "val_acc": 28.0}
{"epoch": 57, "training_loss": 64.6821174621582, "training_acc": 76.0, "val_loss": 19.249095022678375, "val_acc": 72.0}
