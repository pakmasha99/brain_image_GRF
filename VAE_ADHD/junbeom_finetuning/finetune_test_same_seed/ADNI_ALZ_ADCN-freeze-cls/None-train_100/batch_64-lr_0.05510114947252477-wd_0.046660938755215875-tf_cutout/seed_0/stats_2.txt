"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 257.71354484558105, "training_acc": 46.0, "val_loss": 147.28924036026, "val_acc": 72.0}
{"epoch": 1, "training_loss": 505.4887990951538, "training_acc": 72.0, "val_loss": 94.53518390655518, "val_acc": 28.0}
{"epoch": 2, "training_loss": 298.8177578449249, "training_acc": 28.0, "val_loss": 44.47627663612366, "val_acc": 72.0}
{"epoch": 3, "training_loss": 210.70135307312012, "training_acc": 72.0, "val_loss": 59.27593111991882, "val_acc": 72.0}
{"epoch": 4, "training_loss": 198.35227394104004, "training_acc": 72.0, "val_loss": 27.45470702648163, "val_acc": 28.0}
{"epoch": 5, "training_loss": 120.75313663482666, "training_acc": 28.0, "val_loss": 20.014606416225433, "val_acc": 72.0}
{"epoch": 6, "training_loss": 102.03759431838989, "training_acc": 72.0, "val_loss": 30.581873655319214, "val_acc": 72.0}
{"epoch": 7, "training_loss": 95.31971549987793, "training_acc": 72.0, "val_loss": 39.717429876327515, "val_acc": 28.0}
{"epoch": 8, "training_loss": 143.57285928726196, "training_acc": 28.0, "val_loss": 22.99111932516098, "val_acc": 72.0}
{"epoch": 9, "training_loss": 110.12286567687988, "training_acc": 72.0, "val_loss": 38.76742422580719, "val_acc": 72.0}
{"epoch": 10, "training_loss": 137.88391399383545, "training_acc": 72.0, "val_loss": 15.745483338832855, "val_acc": 28.0}
{"epoch": 11, "training_loss": 96.8484377861023, "training_acc": 54.0, "val_loss": 15.591093897819519, "val_acc": 28.0}
{"epoch": 12, "training_loss": 78.14470624923706, "training_acc": 72.0, "val_loss": 30.050334334373474, "val_acc": 72.0}
{"epoch": 13, "training_loss": 110.30120968818665, "training_acc": 72.0, "val_loss": 15.250611305236816, "val_acc": 68.0}
{"epoch": 14, "training_loss": 78.10084533691406, "training_acc": 56.0, "val_loss": 14.934852719306946, "val_acc": 72.0}
{"epoch": 15, "training_loss": 60.05190348625183, "training_acc": 72.0, "val_loss": 22.918319702148438, "val_acc": 72.0}
{"epoch": 16, "training_loss": 83.4853949546814, "training_acc": 72.0, "val_loss": 17.804646492004395, "val_acc": 28.0}
{"epoch": 17, "training_loss": 78.63388085365295, "training_acc": 28.0, "val_loss": 16.89494550228119, "val_acc": 72.0}
{"epoch": 18, "training_loss": 76.2478494644165, "training_acc": 72.0, "val_loss": 19.908198714256287, "val_acc": 72.0}
{"epoch": 19, "training_loss": 78.24807453155518, "training_acc": 72.0, "val_loss": 19.083912670612335, "val_acc": 28.0}
{"epoch": 20, "training_loss": 68.61801481246948, "training_acc": 46.0, "val_loss": 18.93494725227356, "val_acc": 72.0}
{"epoch": 21, "training_loss": 73.22835516929626, "training_acc": 72.0, "val_loss": 14.885272085666656, "val_acc": 72.0}
{"epoch": 22, "training_loss": 66.63356518745422, "training_acc": 50.0, "val_loss": 15.836246311664581, "val_acc": 72.0}
{"epoch": 23, "training_loss": 66.84071063995361, "training_acc": 72.0, "val_loss": 15.598134696483612, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.19410705566406, "training_acc": 72.0, "val_loss": 17.861658334732056, "val_acc": 28.0}
{"epoch": 25, "training_loss": 65.80795669555664, "training_acc": 46.0, "val_loss": 18.60162317752838, "val_acc": 72.0}
{"epoch": 26, "training_loss": 71.0383186340332, "training_acc": 72.0, "val_loss": 15.63495546579361, "val_acc": 28.0}
{"epoch": 27, "training_loss": 62.44641447067261, "training_acc": 72.0, "val_loss": 15.916156768798828, "val_acc": 72.0}
{"epoch": 28, "training_loss": 63.41822361946106, "training_acc": 72.0, "val_loss": 14.793406426906586, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.54481053352356, "training_acc": 72.0, "val_loss": 15.485458076000214, "val_acc": 32.0}
{"epoch": 30, "training_loss": 60.932713747024536, "training_acc": 72.0, "val_loss": 15.686337649822235, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.86005234718323, "training_acc": 72.0, "val_loss": 15.592209994792938, "val_acc": 28.0}
{"epoch": 32, "training_loss": 60.666629791259766, "training_acc": 72.0, "val_loss": 15.475130081176758, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.402005434036255, "training_acc": 72.0, "val_loss": 16.78183376789093, "val_acc": 28.0}
{"epoch": 34, "training_loss": 65.36597657203674, "training_acc": 73.0, "val_loss": 15.055486559867859, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.007083892822266, "training_acc": 72.0, "val_loss": 15.399664640426636, "val_acc": 44.0}
{"epoch": 36, "training_loss": 62.52216649055481, "training_acc": 72.0, "val_loss": 19.613316655158997, "val_acc": 72.0}
{"epoch": 37, "training_loss": 88.47393655776978, "training_acc": 72.0, "val_loss": 15.020331740379333, "val_acc": 72.0}
{"epoch": 38, "training_loss": 78.8654146194458, "training_acc": 56.0, "val_loss": 15.730011463165283, "val_acc": 72.0}
{"epoch": 39, "training_loss": 72.32708764076233, "training_acc": 72.0, "val_loss": 18.837901949882507, "val_acc": 72.0}
{"epoch": 40, "training_loss": 81.38503956794739, "training_acc": 52.0, "val_loss": 15.255594253540039, "val_acc": 60.0}
{"epoch": 41, "training_loss": 69.46466851234436, "training_acc": 72.0, "val_loss": 16.676482558250427, "val_acc": 72.0}
{"epoch": 42, "training_loss": 58.568599224090576, "training_acc": 72.0, "val_loss": 23.83859157562256, "val_acc": 28.0}
{"epoch": 43, "training_loss": 86.55172753334045, "training_acc": 42.0, "val_loss": 20.552028715610504, "val_acc": 72.0}
{"epoch": 44, "training_loss": 73.63485884666443, "training_acc": 72.0, "val_loss": 24.286243319511414, "val_acc": 28.0}
{"epoch": 45, "training_loss": 84.6879723072052, "training_acc": 42.0, "val_loss": 18.990558385849, "val_acc": 72.0}
{"epoch": 46, "training_loss": 79.08782911300659, "training_acc": 72.0, "val_loss": 16.53692275285721, "val_acc": 28.0}
{"epoch": 47, "training_loss": 75.21647572517395, "training_acc": 54.0, "val_loss": 18.70061308145523, "val_acc": 72.0}
