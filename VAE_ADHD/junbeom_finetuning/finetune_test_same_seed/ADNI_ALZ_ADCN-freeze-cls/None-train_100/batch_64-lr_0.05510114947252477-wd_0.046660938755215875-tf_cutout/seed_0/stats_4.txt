"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 209.95031547546387, "training_acc": 50.0, "val_loss": 148.3418107032776, "val_acc": 72.0}
{"epoch": 1, "training_loss": 444.2644319534302, "training_acc": 72.0, "val_loss": 120.06886005401611, "val_acc": 28.0}
{"epoch": 2, "training_loss": 415.2109365463257, "training_acc": 28.0, "val_loss": 37.613239884376526, "val_acc": 72.0}
{"epoch": 3, "training_loss": 203.1415138244629, "training_acc": 72.0, "val_loss": 87.09880113601685, "val_acc": 72.0}
{"epoch": 4, "training_loss": 337.35522747039795, "training_acc": 72.0, "val_loss": 55.02319931983948, "val_acc": 72.0}
{"epoch": 5, "training_loss": 153.3044147491455, "training_acc": 72.0, "val_loss": 76.22115015983582, "val_acc": 28.0}
{"epoch": 6, "training_loss": 310.1078224182129, "training_acc": 28.0, "val_loss": 16.634826362133026, "val_acc": 28.0}
{"epoch": 7, "training_loss": 91.51376914978027, "training_acc": 72.0, "val_loss": 58.92567038536072, "val_acc": 72.0}
{"epoch": 8, "training_loss": 243.36288261413574, "training_acc": 72.0, "val_loss": 55.776119232177734, "val_acc": 72.0}
{"epoch": 9, "training_loss": 188.2845630645752, "training_acc": 72.0, "val_loss": 15.373742580413818, "val_acc": 28.0}
{"epoch": 10, "training_loss": 129.91146183013916, "training_acc": 54.0, "val_loss": 37.364330887794495, "val_acc": 28.0}
{"epoch": 11, "training_loss": 144.44473600387573, "training_acc": 38.0, "val_loss": 40.79172909259796, "val_acc": 72.0}
{"epoch": 12, "training_loss": 171.00332593917847, "training_acc": 72.0, "val_loss": 37.203994393348694, "val_acc": 72.0}
{"epoch": 13, "training_loss": 125.50155782699585, "training_acc": 72.0, "val_loss": 29.34357225894928, "val_acc": 28.0}
{"epoch": 14, "training_loss": 120.22166442871094, "training_acc": 28.0, "val_loss": 15.862846374511719, "val_acc": 72.0}
{"epoch": 15, "training_loss": 84.99529647827148, "training_acc": 72.0, "val_loss": 28.575146198272705, "val_acc": 72.0}
{"epoch": 16, "training_loss": 103.3037462234497, "training_acc": 72.0, "val_loss": 17.582082748413086, "val_acc": 28.0}
{"epoch": 17, "training_loss": 76.29508328437805, "training_acc": 28.0, "val_loss": 14.773903787136078, "val_acc": 72.0}
{"epoch": 18, "training_loss": 78.36592435836792, "training_acc": 72.0, "val_loss": 18.52753758430481, "val_acc": 72.0}
{"epoch": 19, "training_loss": 74.03560423851013, "training_acc": 72.0, "val_loss": 18.505334854125977, "val_acc": 28.0}
{"epoch": 20, "training_loss": 67.4354567527771, "training_acc": 46.0, "val_loss": 17.845813930034637, "val_acc": 72.0}
{"epoch": 21, "training_loss": 71.03447389602661, "training_acc": 72.0, "val_loss": 14.743773639202118, "val_acc": 72.0}
{"epoch": 22, "training_loss": 74.45115780830383, "training_acc": 48.0, "val_loss": 14.913460612297058, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.803080797195435, "training_acc": 72.0, "val_loss": 18.859151005744934, "val_acc": 72.0}
{"epoch": 24, "training_loss": 70.92786860466003, "training_acc": 72.0, "val_loss": 17.388150095939636, "val_acc": 28.0}
{"epoch": 25, "training_loss": 68.90070247650146, "training_acc": 52.0, "val_loss": 18.533332645893097, "val_acc": 72.0}
{"epoch": 26, "training_loss": 79.71418690681458, "training_acc": 72.0, "val_loss": 17.475727200508118, "val_acc": 72.0}
{"epoch": 27, "training_loss": 64.32740712165833, "training_acc": 72.0, "val_loss": 22.324368357658386, "val_acc": 28.0}
{"epoch": 28, "training_loss": 78.48095440864563, "training_acc": 44.0, "val_loss": 19.818124175071716, "val_acc": 72.0}
{"epoch": 29, "training_loss": 78.67760586738586, "training_acc": 72.0, "val_loss": 14.98364508152008, "val_acc": 72.0}
{"epoch": 30, "training_loss": 61.54766011238098, "training_acc": 64.0, "val_loss": 16.00027084350586, "val_acc": 28.0}
{"epoch": 31, "training_loss": 60.69929909706116, "training_acc": 72.0, "val_loss": 18.724703788757324, "val_acc": 72.0}
{"epoch": 32, "training_loss": 70.6745331287384, "training_acc": 72.0, "val_loss": 16.510139405727386, "val_acc": 28.0}
{"epoch": 33, "training_loss": 66.82718992233276, "training_acc": 73.0, "val_loss": 16.164594888687134, "val_acc": 72.0}
{"epoch": 34, "training_loss": 65.58938145637512, "training_acc": 72.0, "val_loss": 15.345498919487, "val_acc": 72.0}
{"epoch": 35, "training_loss": 80.82718682289124, "training_acc": 44.0, "val_loss": 15.74195772409439, "val_acc": 72.0}
{"epoch": 36, "training_loss": 71.17222309112549, "training_acc": 72.0, "val_loss": 16.665877401828766, "val_acc": 72.0}
{"epoch": 37, "training_loss": 65.30835819244385, "training_acc": 71.0, "val_loss": 18.341107666492462, "val_acc": 28.0}
{"epoch": 38, "training_loss": 74.72263026237488, "training_acc": 40.0, "val_loss": 17.816756665706635, "val_acc": 72.0}
{"epoch": 39, "training_loss": 66.72546315193176, "training_acc": 72.0, "val_loss": 17.776335775852203, "val_acc": 28.0}
{"epoch": 40, "training_loss": 67.68741464614868, "training_acc": 42.0, "val_loss": 15.87008684873581, "val_acc": 72.0}
