"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 229.3897190093994, "training_acc": 38.0, "val_loss": 81.96688890457153, "val_acc": 72.0}
{"epoch": 1, "training_loss": 264.33416175842285, "training_acc": 72.0, "val_loss": 55.461907386779785, "val_acc": 28.0}
{"epoch": 2, "training_loss": 195.3977723121643, "training_acc": 28.0, "val_loss": 21.317751705646515, "val_acc": 72.0}
{"epoch": 3, "training_loss": 107.3822808265686, "training_acc": 72.0, "val_loss": 39.27187919616699, "val_acc": 72.0}
{"epoch": 4, "training_loss": 142.79106187820435, "training_acc": 72.0, "val_loss": 15.544234216213226, "val_acc": 72.0}
{"epoch": 5, "training_loss": 71.11860179901123, "training_acc": 64.0, "val_loss": 32.22646713256836, "val_acc": 28.0}
{"epoch": 6, "training_loss": 98.86980938911438, "training_acc": 48.0, "val_loss": 24.648796021938324, "val_acc": 72.0}
{"epoch": 7, "training_loss": 107.5713996887207, "training_acc": 72.0, "val_loss": 28.21527123451233, "val_acc": 72.0}
{"epoch": 8, "training_loss": 99.89528274536133, "training_acc": 72.0, "val_loss": 18.01961064338684, "val_acc": 28.0}
{"epoch": 9, "training_loss": 81.01622438430786, "training_acc": 28.0, "val_loss": 15.77102243900299, "val_acc": 28.0}
{"epoch": 10, "training_loss": 61.43632936477661, "training_acc": 72.0, "val_loss": 22.00794219970703, "val_acc": 72.0}
{"epoch": 11, "training_loss": 85.4983479976654, "training_acc": 72.0, "val_loss": 15.508103370666504, "val_acc": 72.0}
{"epoch": 12, "training_loss": 64.40840482711792, "training_acc": 73.0, "val_loss": 18.751733005046844, "val_acc": 28.0}
{"epoch": 13, "training_loss": 70.31028532981873, "training_acc": 42.0, "val_loss": 16.853545606136322, "val_acc": 72.0}
{"epoch": 14, "training_loss": 66.94179081916809, "training_acc": 72.0, "val_loss": 15.221163630485535, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.85809659957886, "training_acc": 72.0, "val_loss": 16.488391160964966, "val_acc": 28.0}
{"epoch": 16, "training_loss": 64.77488279342651, "training_acc": 72.0, "val_loss": 15.132878720760345, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.733309268951416, "training_acc": 72.0, "val_loss": 14.810869097709656, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.581998109817505, "training_acc": 72.0, "val_loss": 16.072124242782593, "val_acc": 28.0}
{"epoch": 19, "training_loss": 62.99561023712158, "training_acc": 72.0, "val_loss": 15.61138927936554, "val_acc": 72.0}
{"epoch": 20, "training_loss": 66.33262372016907, "training_acc": 72.0, "val_loss": 15.315626561641693, "val_acc": 72.0}
{"epoch": 21, "training_loss": 62.17776131629944, "training_acc": 72.0, "val_loss": 16.649608314037323, "val_acc": 28.0}
{"epoch": 22, "training_loss": 62.12452816963196, "training_acc": 72.0, "val_loss": 17.140834033489227, "val_acc": 72.0}
{"epoch": 23, "training_loss": 69.10410332679749, "training_acc": 72.0, "val_loss": 14.86733853816986, "val_acc": 72.0}
{"epoch": 24, "training_loss": 61.186866998672485, "training_acc": 72.0, "val_loss": 16.351211071014404, "val_acc": 28.0}
{"epoch": 25, "training_loss": 63.39208173751831, "training_acc": 72.0, "val_loss": 16.96276366710663, "val_acc": 72.0}
{"epoch": 26, "training_loss": 67.37087655067444, "training_acc": 72.0, "val_loss": 15.746298432350159, "val_acc": 28.0}
{"epoch": 27, "training_loss": 66.16688871383667, "training_acc": 58.0, "val_loss": 14.853432774543762, "val_acc": 72.0}
{"epoch": 28, "training_loss": 67.29943442344666, "training_acc": 72.0, "val_loss": 16.484113037586212, "val_acc": 72.0}
{"epoch": 29, "training_loss": 71.28607654571533, "training_acc": 72.0, "val_loss": 15.298070013523102, "val_acc": 56.0}
{"epoch": 30, "training_loss": 63.0577175617218, "training_acc": 72.0, "val_loss": 15.46497642993927, "val_acc": 72.0}
{"epoch": 31, "training_loss": 62.33354663848877, "training_acc": 72.0, "val_loss": 14.996959269046783, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.04446625709534, "training_acc": 72.0, "val_loss": 15.26482105255127, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.31536841392517, "training_acc": 72.0, "val_loss": 14.802968502044678, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.10180640220642, "training_acc": 72.0, "val_loss": 15.322771668434143, "val_acc": 60.0}
{"epoch": 35, "training_loss": 62.81403827667236, "training_acc": 72.0, "val_loss": 16.437608003616333, "val_acc": 72.0}
{"epoch": 36, "training_loss": 70.60548067092896, "training_acc": 72.0, "val_loss": 15.34217894077301, "val_acc": 72.0}
{"epoch": 37, "training_loss": 70.14443922042847, "training_acc": 52.0, "val_loss": 15.415987372398376, "val_acc": 36.0}
{"epoch": 38, "training_loss": 69.57551670074463, "training_acc": 72.0, "val_loss": 17.211852967739105, "val_acc": 72.0}
{"epoch": 39, "training_loss": 62.210339069366455, "training_acc": 72.0, "val_loss": 20.137503743171692, "val_acc": 28.0}
{"epoch": 40, "training_loss": 74.01791143417358, "training_acc": 44.0, "val_loss": 16.870486736297607, "val_acc": 72.0}
{"epoch": 41, "training_loss": 70.77332305908203, "training_acc": 72.0, "val_loss": 15.477527678012848, "val_acc": 72.0}
{"epoch": 42, "training_loss": 66.70464038848877, "training_acc": 54.0, "val_loss": 16.015468537807465, "val_acc": 28.0}
{"epoch": 43, "training_loss": 59.00500512123108, "training_acc": 72.0, "val_loss": 18.967942893505096, "val_acc": 72.0}
{"epoch": 44, "training_loss": 72.64260530471802, "training_acc": 72.0, "val_loss": 14.86542522907257, "val_acc": 72.0}
{"epoch": 45, "training_loss": 62.09534192085266, "training_acc": 74.0, "val_loss": 14.835625886917114, "val_acc": 72.0}
{"epoch": 46, "training_loss": 57.441043972969055, "training_acc": 72.0, "val_loss": 16.9361412525177, "val_acc": 72.0}
{"epoch": 47, "training_loss": 64.54278349876404, "training_acc": 72.0, "val_loss": 15.654468536376953, "val_acc": 28.0}
{"epoch": 48, "training_loss": 61.73561429977417, "training_acc": 72.0, "val_loss": 14.794619381427765, "val_acc": 72.0}
{"epoch": 49, "training_loss": 61.89820313453674, "training_acc": 72.0, "val_loss": 14.79729413986206, "val_acc": 72.0}
{"epoch": 50, "training_loss": 67.20525121688843, "training_acc": 48.0, "val_loss": 15.440493822097778, "val_acc": 72.0}
{"epoch": 51, "training_loss": 65.02006912231445, "training_acc": 72.0, "val_loss": 16.155971586704254, "val_acc": 72.0}
{"epoch": 52, "training_loss": 60.10203552246094, "training_acc": 72.0, "val_loss": 18.97345930337906, "val_acc": 28.0}
{"epoch": 53, "training_loss": 70.63674521446228, "training_acc": 42.0, "val_loss": 17.006108164787292, "val_acc": 72.0}
{"epoch": 54, "training_loss": 65.41323399543762, "training_acc": 72.0, "val_loss": 14.97555524110794, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.86948752403259, "training_acc": 72.0, "val_loss": 14.804250001907349, "val_acc": 72.0}
{"epoch": 56, "training_loss": 66.79157376289368, "training_acc": 72.0, "val_loss": 14.794394373893738, "val_acc": 72.0}
{"epoch": 57, "training_loss": 61.893837451934814, "training_acc": 74.0, "val_loss": 14.843180775642395, "val_acc": 72.0}
{"epoch": 58, "training_loss": 56.79139757156372, "training_acc": 72.0, "val_loss": 17.52033531665802, "val_acc": 72.0}
{"epoch": 59, "training_loss": 66.50400137901306, "training_acc": 72.0, "val_loss": 15.641121566295624, "val_acc": 32.0}
{"epoch": 60, "training_loss": 63.97307634353638, "training_acc": 72.0, "val_loss": 15.472757816314697, "val_acc": 72.0}
{"epoch": 61, "training_loss": 61.63776159286499, "training_acc": 72.0, "val_loss": 15.680776536464691, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.83453702926636, "training_acc": 72.0, "val_loss": 16.640889644622803, "val_acc": 28.0}
{"epoch": 63, "training_loss": 61.59931468963623, "training_acc": 74.0, "val_loss": 18.264320492744446, "val_acc": 72.0}
{"epoch": 64, "training_loss": 74.16813683509827, "training_acc": 72.0, "val_loss": 14.78521078824997, "val_acc": 72.0}
{"epoch": 65, "training_loss": 58.61369013786316, "training_acc": 70.0, "val_loss": 17.124618589878082, "val_acc": 28.0}
{"epoch": 66, "training_loss": 70.44152760505676, "training_acc": 73.0, "val_loss": 17.5943523645401, "val_acc": 72.0}
{"epoch": 67, "training_loss": 65.0602376461029, "training_acc": 72.0, "val_loss": 17.34939217567444, "val_acc": 28.0}
{"epoch": 68, "training_loss": 65.80776143074036, "training_acc": 61.0, "val_loss": 15.75230211019516, "val_acc": 72.0}
{"epoch": 69, "training_loss": 62.47533082962036, "training_acc": 72.0, "val_loss": 15.23277461528778, "val_acc": 60.0}
{"epoch": 70, "training_loss": 60.9664363861084, "training_acc": 72.0, "val_loss": 14.786127209663391, "val_acc": 72.0}
{"epoch": 71, "training_loss": 59.338332653045654, "training_acc": 72.0, "val_loss": 15.16513079404831, "val_acc": 72.0}
{"epoch": 72, "training_loss": 57.55672311782837, "training_acc": 72.0, "val_loss": 17.256388068199158, "val_acc": 28.0}
{"epoch": 73, "training_loss": 66.67274403572083, "training_acc": 63.0, "val_loss": 15.47277420759201, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.801772594451904, "training_acc": 72.0, "val_loss": 15.103283524513245, "val_acc": 64.0}
{"epoch": 75, "training_loss": 61.13143539428711, "training_acc": 72.0, "val_loss": 16.402091085910797, "val_acc": 72.0}
{"epoch": 76, "training_loss": 63.988773584365845, "training_acc": 72.0, "val_loss": 15.188702940940857, "val_acc": 72.0}
{"epoch": 77, "training_loss": 57.90650224685669, "training_acc": 72.0, "val_loss": 16.503368318080902, "val_acc": 28.0}
{"epoch": 78, "training_loss": 62.39469814300537, "training_acc": 73.0, "val_loss": 16.296008229255676, "val_acc": 72.0}
{"epoch": 79, "training_loss": 62.24481201171875, "training_acc": 72.0, "val_loss": 15.116804838180542, "val_acc": 68.0}
{"epoch": 80, "training_loss": 59.247925758361816, "training_acc": 72.0, "val_loss": 15.009263157844543, "val_acc": 72.0}
{"epoch": 81, "training_loss": 59.348442792892456, "training_acc": 72.0, "val_loss": 14.813770353794098, "val_acc": 72.0}
{"epoch": 82, "training_loss": 57.99250507354736, "training_acc": 72.0, "val_loss": 15.045295655727386, "val_acc": 64.0}
{"epoch": 83, "training_loss": 57.987658739089966, "training_acc": 72.0, "val_loss": 16.650567948818207, "val_acc": 72.0}
