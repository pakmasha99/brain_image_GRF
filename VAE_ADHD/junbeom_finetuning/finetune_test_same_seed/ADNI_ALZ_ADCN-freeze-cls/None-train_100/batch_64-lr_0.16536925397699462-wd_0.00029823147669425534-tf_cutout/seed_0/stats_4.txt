"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1148.091007232666, "training_acc": 42.0, "val_loss": 611.1137390136719, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2001.972957611084, "training_acc": 72.0, "val_loss": 290.28053283691406, "val_acc": 28.0}
{"epoch": 2, "training_loss": 896.5523796081543, "training_acc": 28.0, "val_loss": 230.30953407287598, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1078.521671295166, "training_acc": 72.0, "val_loss": 428.352689743042, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1679.9495468139648, "training_acc": 72.0, "val_loss": 301.0777473449707, "val_acc": 72.0}
{"epoch": 5, "training_loss": 991.1455669403076, "training_acc": 72.0, "val_loss": 72.08462357521057, "val_acc": 28.0}
{"epoch": 6, "training_loss": 288.469162940979, "training_acc": 28.0, "val_loss": 107.91044235229492, "val_acc": 72.0}
{"epoch": 7, "training_loss": 552.6031455993652, "training_acc": 72.0, "val_loss": 175.568687915802, "val_acc": 72.0}
{"epoch": 8, "training_loss": 612.9437599182129, "training_acc": 72.0, "val_loss": 13.987229764461517, "val_acc": 72.0}
{"epoch": 9, "training_loss": 340.43071365356445, "training_acc": 58.0, "val_loss": 97.7503776550293, "val_acc": 28.0}
{"epoch": 10, "training_loss": 543.5017356872559, "training_acc": 36.0, "val_loss": 222.44203090667725, "val_acc": 72.0}
{"epoch": 11, "training_loss": 959.3405303955078, "training_acc": 72.0, "val_loss": 229.17773723602295, "val_acc": 72.0}
{"epoch": 12, "training_loss": 812.8120212554932, "training_acc": 72.0, "val_loss": 31.384429335594177, "val_acc": 72.0}
{"epoch": 13, "training_loss": 610.0879173278809, "training_acc": 50.0, "val_loss": 338.4737491607666, "val_acc": 28.0}
{"epoch": 14, "training_loss": 949.2243280410767, "training_acc": 28.0, "val_loss": 179.25481796264648, "val_acc": 72.0}
{"epoch": 15, "training_loss": 987.3984603881836, "training_acc": 72.0, "val_loss": 408.88776779174805, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1661.6746406555176, "training_acc": 72.0, "val_loss": 411.9957447052002, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1561.651840209961, "training_acc": 72.0, "val_loss": 244.43519115447998, "val_acc": 72.0}
{"epoch": 18, "training_loss": 825.5449714660645, "training_acc": 72.0, "val_loss": 148.77550601959229, "val_acc": 28.0}
{"epoch": 19, "training_loss": 720.7307167053223, "training_acc": 28.0, "val_loss": 17.230936884880066, "val_acc": 32.0}
{"epoch": 20, "training_loss": 258.96753692626953, "training_acc": 54.0, "val_loss": 189.84644412994385, "val_acc": 72.0}
{"epoch": 21, "training_loss": 773.3692665100098, "training_acc": 72.0, "val_loss": 168.1276559829712, "val_acc": 72.0}
{"epoch": 22, "training_loss": 589.3415699005127, "training_acc": 72.0, "val_loss": 66.10395908355713, "val_acc": 28.0}
{"epoch": 23, "training_loss": 243.61940002441406, "training_acc": 28.0, "val_loss": 95.54044008255005, "val_acc": 72.0}
{"epoch": 24, "training_loss": 458.4644718170166, "training_acc": 72.0, "val_loss": 164.48214054107666, "val_acc": 72.0}
{"epoch": 25, "training_loss": 593.0704326629639, "training_acc": 72.0, "val_loss": 49.604544043540955, "val_acc": 72.0}
{"epoch": 26, "training_loss": 417.8146209716797, "training_acc": 54.0, "val_loss": 172.08611965179443, "val_acc": 28.0}
{"epoch": 27, "training_loss": 569.6481513977051, "training_acc": 38.0, "val_loss": 103.91579866409302, "val_acc": 72.0}
