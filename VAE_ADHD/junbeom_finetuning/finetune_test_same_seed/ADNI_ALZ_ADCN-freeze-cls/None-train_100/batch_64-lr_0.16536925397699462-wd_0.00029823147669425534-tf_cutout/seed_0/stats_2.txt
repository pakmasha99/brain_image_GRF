"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 823.9138450622559, "training_acc": 72.0, "val_loss": 436.0825538635254, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1432.9463319778442, "training_acc": 72.0, "val_loss": 551.8555641174316, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1972.2575378417969, "training_acc": 28.0, "val_loss": 63.5703444480896, "val_acc": 72.0}
{"epoch": 3, "training_loss": 434.895751953125, "training_acc": 72.0, "val_loss": 239.42694664001465, "val_acc": 72.0}
{"epoch": 4, "training_loss": 929.886604309082, "training_acc": 72.0, "val_loss": 146.46440744400024, "val_acc": 72.0}
{"epoch": 5, "training_loss": 415.29531049728394, "training_acc": 72.0, "val_loss": 332.07879066467285, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1314.4909858703613, "training_acc": 28.0, "val_loss": 33.3232581615448, "val_acc": 28.0}
{"epoch": 7, "training_loss": 301.79604148864746, "training_acc": 46.0, "val_loss": 299.4875192642212, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1273.4942474365234, "training_acc": 72.0, "val_loss": 392.80333518981934, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1530.161964416504, "training_acc": 72.0, "val_loss": 313.17851543426514, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1097.9585647583008, "training_acc": 72.0, "val_loss": 81.97425603866577, "val_acc": 72.0}
{"epoch": 11, "training_loss": 487.01965522766113, "training_acc": 56.0, "val_loss": 291.8558359146118, "val_acc": 28.0}
{"epoch": 12, "training_loss": 925.3718318939209, "training_acc": 28.0, "val_loss": 95.87794542312622, "val_acc": 72.0}
{"epoch": 13, "training_loss": 547.1847496032715, "training_acc": 72.0, "val_loss": 243.54510307312012, "val_acc": 72.0}
{"epoch": 14, "training_loss": 976.025074005127, "training_acc": 72.0, "val_loss": 216.6506290435791, "val_acc": 72.0}
{"epoch": 15, "training_loss": 746.5537357330322, "training_acc": 72.0, "val_loss": 45.357394218444824, "val_acc": 72.0}
{"epoch": 16, "training_loss": 523.6262245178223, "training_acc": 48.0, "val_loss": 270.8171844482422, "val_acc": 28.0}
{"epoch": 17, "training_loss": 829.0341954231262, "training_acc": 28.0, "val_loss": 118.95217895507812, "val_acc": 72.0}
{"epoch": 18, "training_loss": 597.1861877441406, "training_acc": 72.0, "val_loss": 261.067795753479, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1042.7355995178223, "training_acc": 72.0, "val_loss": 242.95969009399414, "val_acc": 72.0}
{"epoch": 20, "training_loss": 882.5198459625244, "training_acc": 72.0, "val_loss": 91.96725487709045, "val_acc": 72.0}
{"epoch": 21, "training_loss": 267.19296407699585, "training_acc": 60.0, "val_loss": 109.03346538543701, "val_acc": 28.0}
{"epoch": 22, "training_loss": 353.3020725250244, "training_acc": 36.0, "val_loss": 49.73897337913513, "val_acc": 72.0}
{"epoch": 23, "training_loss": 162.11835432052612, "training_acc": 72.0, "val_loss": 42.22390949726105, "val_acc": 28.0}
{"epoch": 24, "training_loss": 146.9976954460144, "training_acc": 38.0, "val_loss": 19.40482258796692, "val_acc": 72.0}
{"epoch": 25, "training_loss": 77.05050778388977, "training_acc": 60.0, "val_loss": 25.817394256591797, "val_acc": 72.0}
{"epoch": 26, "training_loss": 100.53367042541504, "training_acc": 72.0, "val_loss": 34.98752415180206, "val_acc": 28.0}
{"epoch": 27, "training_loss": 108.01866006851196, "training_acc": 46.0, "val_loss": 28.082293272018433, "val_acc": 72.0}
{"epoch": 28, "training_loss": 93.03552317619324, "training_acc": 64.0, "val_loss": 15.751157701015472, "val_acc": 64.0}
{"epoch": 29, "training_loss": 58.5690495967865, "training_acc": 70.0, "val_loss": 21.608680486679077, "val_acc": 32.0}
{"epoch": 30, "training_loss": 69.26398777961731, "training_acc": 55.0, "val_loss": 24.755561351776123, "val_acc": 72.0}
{"epoch": 31, "training_loss": 118.97353076934814, "training_acc": 48.0, "val_loss": 41.01792871952057, "val_acc": 72.0}
{"epoch": 32, "training_loss": 166.772873878479, "training_acc": 72.0, "val_loss": 26.820695400238037, "val_acc": 72.0}
{"epoch": 33, "training_loss": 167.79505443572998, "training_acc": 58.0, "val_loss": 15.648722648620605, "val_acc": 68.0}
{"epoch": 34, "training_loss": 102.44819259643555, "training_acc": 74.0, "val_loss": 36.55242919921875, "val_acc": 72.0}
{"epoch": 35, "training_loss": 156.57104349136353, "training_acc": 50.0, "val_loss": 26.69665515422821, "val_acc": 72.0}
{"epoch": 36, "training_loss": 96.91144037246704, "training_acc": 72.0, "val_loss": 17.11246520280838, "val_acc": 52.0}
{"epoch": 37, "training_loss": 60.331584215164185, "training_acc": 71.0, "val_loss": 19.45537179708481, "val_acc": 72.0}
{"epoch": 38, "training_loss": 57.427136182785034, "training_acc": 71.0, "val_loss": 25.146207213401794, "val_acc": 32.0}
{"epoch": 39, "training_loss": 116.03346729278564, "training_acc": 48.0, "val_loss": 42.4203097820282, "val_acc": 72.0}
{"epoch": 40, "training_loss": 148.69498682022095, "training_acc": 58.0, "val_loss": 17.723090946674347, "val_acc": 64.0}
{"epoch": 41, "training_loss": 62.90301704406738, "training_acc": 71.0, "val_loss": 38.26445937156677, "val_acc": 28.0}
{"epoch": 42, "training_loss": 174.15865182876587, "training_acc": 38.0, "val_loss": 43.28204393386841, "val_acc": 72.0}
{"epoch": 43, "training_loss": 111.93523073196411, "training_acc": 75.0, "val_loss": 57.171207666397095, "val_acc": 28.0}
{"epoch": 44, "training_loss": 183.25371599197388, "training_acc": 48.0, "val_loss": 60.62607765197754, "val_acc": 72.0}
{"epoch": 45, "training_loss": 196.43989038467407, "training_acc": 72.0, "val_loss": 29.627609252929688, "val_acc": 28.0}
{"epoch": 46, "training_loss": 96.12247014045715, "training_acc": 43.0, "val_loss": 20.241935551166534, "val_acc": 72.0}
{"epoch": 47, "training_loss": 56.29626250267029, "training_acc": 73.0, "val_loss": 18.642202019691467, "val_acc": 44.0}
{"epoch": 48, "training_loss": 72.64350056648254, "training_acc": 70.0, "val_loss": 23.506923019886017, "val_acc": 72.0}
{"epoch": 49, "training_loss": 83.93843650817871, "training_acc": 60.0, "val_loss": 25.637653470039368, "val_acc": 72.0}
{"epoch": 50, "training_loss": 80.08520436286926, "training_acc": 72.0, "val_loss": 27.707913517951965, "val_acc": 32.0}
{"epoch": 51, "training_loss": 122.91613721847534, "training_acc": 44.0, "val_loss": 29.092928767204285, "val_acc": 72.0}
{"epoch": 52, "training_loss": 85.36547064781189, "training_acc": 64.0, "val_loss": 17.877860367298126, "val_acc": 64.0}
