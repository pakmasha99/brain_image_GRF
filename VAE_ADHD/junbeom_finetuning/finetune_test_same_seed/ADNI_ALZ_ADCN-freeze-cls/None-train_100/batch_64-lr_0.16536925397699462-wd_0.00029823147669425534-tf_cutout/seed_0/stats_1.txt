"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 973.0214920043945, "training_acc": 36.0, "val_loss": 470.33963203430176, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1689.0634651184082, "training_acc": 72.0, "val_loss": 138.05495500564575, "val_acc": 72.0}
{"epoch": 2, "training_loss": 740.390926361084, "training_acc": 56.0, "val_loss": 244.14823055267334, "val_acc": 28.0}
{"epoch": 3, "training_loss": 614.070839881897, "training_acc": 50.0, "val_loss": 124.93494749069214, "val_acc": 72.0}
{"epoch": 4, "training_loss": 512.6387901306152, "training_acc": 72.0, "val_loss": 116.8956995010376, "val_acc": 72.0}
{"epoch": 5, "training_loss": 356.1478490829468, "training_acc": 72.0, "val_loss": 158.9268445968628, "val_acc": 28.0}
{"epoch": 6, "training_loss": 594.3991222381592, "training_acc": 28.0, "val_loss": 60.048848390579224, "val_acc": 72.0}
{"epoch": 7, "training_loss": 329.37332916259766, "training_acc": 72.0, "val_loss": 151.86294317245483, "val_acc": 72.0}
{"epoch": 8, "training_loss": 575.4075832366943, "training_acc": 72.0, "val_loss": 86.52786016464233, "val_acc": 72.0}
{"epoch": 9, "training_loss": 304.2882590293884, "training_acc": 60.0, "val_loss": 81.98673725128174, "val_acc": 28.0}
{"epoch": 10, "training_loss": 228.24005937576294, "training_acc": 46.0, "val_loss": 46.122366189956665, "val_acc": 72.0}
{"epoch": 11, "training_loss": 164.36124420166016, "training_acc": 72.0, "val_loss": 29.988309741020203, "val_acc": 28.0}
{"epoch": 12, "training_loss": 90.85857820510864, "training_acc": 48.0, "val_loss": 27.396884560585022, "val_acc": 72.0}
{"epoch": 13, "training_loss": 92.56232357025146, "training_acc": 72.0, "val_loss": 57.480233907699585, "val_acc": 28.0}
{"epoch": 14, "training_loss": 182.7938871383667, "training_acc": 42.0, "val_loss": 33.13469588756561, "val_acc": 72.0}
{"epoch": 15, "training_loss": 102.19465231895447, "training_acc": 72.0, "val_loss": 63.25523257255554, "val_acc": 28.0}
{"epoch": 16, "training_loss": 180.4054868221283, "training_acc": 46.0, "val_loss": 37.781912088394165, "val_acc": 72.0}
{"epoch": 17, "training_loss": 125.3254702091217, "training_acc": 72.0, "val_loss": 54.638755321502686, "val_acc": 28.0}
{"epoch": 18, "training_loss": 155.31952095031738, "training_acc": 46.0, "val_loss": 31.125354766845703, "val_acc": 72.0}
{"epoch": 19, "training_loss": 103.56659436225891, "training_acc": 72.0, "val_loss": 44.529274106025696, "val_acc": 28.0}
{"epoch": 20, "training_loss": 142.06459164619446, "training_acc": 46.0, "val_loss": 40.626418590545654, "val_acc": 72.0}
{"epoch": 21, "training_loss": 130.71405696868896, "training_acc": 72.0, "val_loss": 72.14862108230591, "val_acc": 28.0}
{"epoch": 22, "training_loss": 195.7461757659912, "training_acc": 47.0, "val_loss": 51.20285153388977, "val_acc": 72.0}
{"epoch": 23, "training_loss": 208.80632209777832, "training_acc": 72.0, "val_loss": 39.99529182910919, "val_acc": 72.0}
{"epoch": 24, "training_loss": 183.25901985168457, "training_acc": 50.0, "val_loss": 16.857248544692993, "val_acc": 72.0}
{"epoch": 25, "training_loss": 71.16806149482727, "training_acc": 72.0, "val_loss": 14.760278165340424, "val_acc": 60.0}
{"epoch": 26, "training_loss": 61.83230710029602, "training_acc": 73.0, "val_loss": 28.074821829795837, "val_acc": 72.0}
{"epoch": 27, "training_loss": 104.7056565284729, "training_acc": 72.0, "val_loss": 32.77044594287872, "val_acc": 28.0}
{"epoch": 28, "training_loss": 123.36597347259521, "training_acc": 40.0, "val_loss": 20.059233903884888, "val_acc": 72.0}
{"epoch": 29, "training_loss": 93.46244096755981, "training_acc": 56.0, "val_loss": 25.15241503715515, "val_acc": 72.0}
{"epoch": 30, "training_loss": 99.97961568832397, "training_acc": 72.0, "val_loss": 18.047359585762024, "val_acc": 28.0}
{"epoch": 31, "training_loss": 72.74747467041016, "training_acc": 51.0, "val_loss": 16.089701652526855, "val_acc": 40.0}
{"epoch": 32, "training_loss": 57.15026867389679, "training_acc": 71.0, "val_loss": 24.4190514087677, "val_acc": 72.0}
{"epoch": 33, "training_loss": 79.31404852867126, "training_acc": 72.0, "val_loss": 45.74804604053497, "val_acc": 28.0}
{"epoch": 34, "training_loss": 128.18637895584106, "training_acc": 52.0, "val_loss": 49.21385049819946, "val_acc": 72.0}
{"epoch": 35, "training_loss": 174.9205846786499, "training_acc": 72.0, "val_loss": 30.710572004318237, "val_acc": 28.0}
{"epoch": 36, "training_loss": 95.40658926963806, "training_acc": 45.0, "val_loss": 27.594131231307983, "val_acc": 72.0}
{"epoch": 37, "training_loss": 93.77750992774963, "training_acc": 72.0, "val_loss": 43.17217171192169, "val_acc": 28.0}
{"epoch": 38, "training_loss": 135.64430165290833, "training_acc": 48.0, "val_loss": 41.51940047740936, "val_acc": 72.0}
{"epoch": 39, "training_loss": 132.15544176101685, "training_acc": 72.0, "val_loss": 70.09222507476807, "val_acc": 28.0}
{"epoch": 40, "training_loss": 181.83834433555603, "training_acc": 50.0, "val_loss": 47.58089482784271, "val_acc": 72.0}
{"epoch": 41, "training_loss": 193.34063053131104, "training_acc": 72.0, "val_loss": 19.05885636806488, "val_acc": 72.0}
{"epoch": 42, "training_loss": 199.12285995483398, "training_acc": 54.0, "val_loss": 17.8028866648674, "val_acc": 40.0}
{"epoch": 43, "training_loss": 123.56070137023926, "training_acc": 67.0, "val_loss": 93.67921352386475, "val_acc": 72.0}
{"epoch": 44, "training_loss": 355.4252052307129, "training_acc": 72.0, "val_loss": 42.133140563964844, "val_acc": 72.0}
