"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 74.03246307373047, "training_acc": 50.0, "val_loss": 28.62507700920105, "val_acc": 72.0}
{"epoch": 1, "training_loss": 103.47245740890503, "training_acc": 72.0, "val_loss": 14.856229722499847, "val_acc": 72.0}
{"epoch": 2, "training_loss": 68.46490907669067, "training_acc": 58.0, "val_loss": 20.287878811359406, "val_acc": 28.0}
{"epoch": 3, "training_loss": 72.49775624275208, "training_acc": 46.0, "val_loss": 16.503295302391052, "val_acc": 72.0}
{"epoch": 4, "training_loss": 71.01149654388428, "training_acc": 72.0, "val_loss": 19.452594220638275, "val_acc": 72.0}
{"epoch": 5, "training_loss": 73.8013768196106, "training_acc": 72.0, "val_loss": 14.914783835411072, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.769004106521606, "training_acc": 72.0, "val_loss": 19.11664754152298, "val_acc": 28.0}
{"epoch": 7, "training_loss": 75.4197735786438, "training_acc": 28.0, "val_loss": 15.06093144416809, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.238739132881165, "training_acc": 72.0, "val_loss": 17.79482662677765, "val_acc": 72.0}
{"epoch": 9, "training_loss": 72.52995300292969, "training_acc": 72.0, "val_loss": 18.296660482883453, "val_acc": 72.0}
{"epoch": 10, "training_loss": 70.75672698020935, "training_acc": 72.0, "val_loss": 14.846466481685638, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.35627245903015, "training_acc": 72.0, "val_loss": 16.920754313468933, "val_acc": 28.0}
{"epoch": 12, "training_loss": 66.73392128944397, "training_acc": 72.0, "val_loss": 15.007339417934418, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.25706160068512, "training_acc": 72.0, "val_loss": 15.70405662059784, "val_acc": 72.0}
{"epoch": 14, "training_loss": 63.2429986000061, "training_acc": 72.0, "val_loss": 16.291052103042603, "val_acc": 72.0}
{"epoch": 15, "training_loss": 64.24392771720886, "training_acc": 72.0, "val_loss": 14.832638204097748, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.84208798408508, "training_acc": 72.0, "val_loss": 15.512789785861969, "val_acc": 28.0}
{"epoch": 17, "training_loss": 61.67234778404236, "training_acc": 72.0, "val_loss": 14.831376075744629, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.89373850822449, "training_acc": 72.0, "val_loss": 15.130005776882172, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.52776551246643, "training_acc": 72.0, "val_loss": 15.128077566623688, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.06114196777344, "training_acc": 72.0, "val_loss": 14.812687039375305, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.87548017501831, "training_acc": 72.0, "val_loss": 15.418685972690582, "val_acc": 28.0}
{"epoch": 22, "training_loss": 61.6388738155365, "training_acc": 72.0, "val_loss": 15.097707509994507, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.54918456077576, "training_acc": 72.0, "val_loss": 14.852972328662872, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.39615297317505, "training_acc": 72.0, "val_loss": 14.919109642505646, "val_acc": 72.0}
{"epoch": 25, "training_loss": 60.312986731529236, "training_acc": 72.0, "val_loss": 14.831358194351196, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.615798234939575, "training_acc": 72.0, "val_loss": 14.808650314807892, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.49436640739441, "training_acc": 72.0, "val_loss": 14.879205822944641, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.66433644294739, "training_acc": 72.0, "val_loss": 14.798164367675781, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.5412335395813, "training_acc": 72.0, "val_loss": 14.80761170387268, "val_acc": 72.0}
{"epoch": 30, "training_loss": 61.50089693069458, "training_acc": 72.0, "val_loss": 14.868295192718506, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.3456346988678, "training_acc": 72.0, "val_loss": 15.0303453207016, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.9271879196167, "training_acc": 72.0, "val_loss": 14.792366325855255, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.08068799972534, "training_acc": 72.0, "val_loss": 14.973880350589752, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.93875074386597, "training_acc": 72.0, "val_loss": 14.837892353534698, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.265650033950806, "training_acc": 72.0, "val_loss": 14.802514016628265, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.63773703575134, "training_acc": 72.0, "val_loss": 14.797288179397583, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.79568147659302, "training_acc": 72.0, "val_loss": 14.838854968547821, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.10530686378479, "training_acc": 72.0, "val_loss": 14.93571400642395, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.821918964385986, "training_acc": 72.0, "val_loss": 14.842164516448975, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.107508182525635, "training_acc": 72.0, "val_loss": 14.930285513401031, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.81616401672363, "training_acc": 72.0, "val_loss": 14.884859323501587, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.38792896270752, "training_acc": 72.0, "val_loss": 14.878162741661072, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.74911832809448, "training_acc": 72.0, "val_loss": 14.806181192398071, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.88328671455383, "training_acc": 72.0, "val_loss": 15.010924637317657, "val_acc": 72.0}
{"epoch": 45, "training_loss": 60.371731758117676, "training_acc": 72.0, "val_loss": 14.88872617483139, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.85752582550049, "training_acc": 72.0, "val_loss": 15.00183492898941, "val_acc": 72.0}
{"epoch": 47, "training_loss": 60.301429748535156, "training_acc": 72.0, "val_loss": 14.800876379013062, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.21949005126953, "training_acc": 72.0, "val_loss": 14.779849350452423, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.665770530700684, "training_acc": 72.0, "val_loss": 14.795573055744171, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.28124666213989, "training_acc": 72.0, "val_loss": 14.912086725234985, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.940922021865845, "training_acc": 72.0, "val_loss": 14.780755341053009, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.16089224815369, "training_acc": 72.0, "val_loss": 14.77692723274231, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.11777424812317, "training_acc": 72.0, "val_loss": 14.849314093589783, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.371861696243286, "training_acc": 72.0, "val_loss": 14.851394295692444, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.537232875823975, "training_acc": 72.0, "val_loss": 14.782340824604034, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.74838304519653, "training_acc": 72.0, "val_loss": 14.911487698554993, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.404568910598755, "training_acc": 72.0, "val_loss": 14.899744093418121, "val_acc": 72.0}
{"epoch": 58, "training_loss": 60.05534017086029, "training_acc": 72.0, "val_loss": 14.931583404541016, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.69596600532532, "training_acc": 72.0, "val_loss": 14.797811210155487, "val_acc": 72.0}
{"epoch": 60, "training_loss": 58.99218726158142, "training_acc": 72.0, "val_loss": 15.014438331127167, "val_acc": 72.0}
{"epoch": 61, "training_loss": 60.628281116485596, "training_acc": 72.0, "val_loss": 14.826253056526184, "val_acc": 72.0}
{"epoch": 62, "training_loss": 58.97221493721008, "training_acc": 72.0, "val_loss": 15.25542438030243, "val_acc": 72.0}
{"epoch": 63, "training_loss": 61.03799796104431, "training_acc": 72.0, "val_loss": 14.797486364841461, "val_acc": 72.0}
{"epoch": 64, "training_loss": 60.06289029121399, "training_acc": 72.0, "val_loss": 15.17796665430069, "val_acc": 72.0}
{"epoch": 65, "training_loss": 60.13822150230408, "training_acc": 72.0, "val_loss": 14.85830843448639, "val_acc": 72.0}
{"epoch": 66, "training_loss": 60.04127621650696, "training_acc": 72.0, "val_loss": 14.93498682975769, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.06145119667053, "training_acc": 72.0, "val_loss": 15.158629417419434, "val_acc": 72.0}
{"epoch": 68, "training_loss": 61.6874144077301, "training_acc": 72.0, "val_loss": 14.877188205718994, "val_acc": 72.0}
{"epoch": 69, "training_loss": 59.02136206626892, "training_acc": 72.0, "val_loss": 15.538555383682251, "val_acc": 72.0}
{"epoch": 70, "training_loss": 61.82665824890137, "training_acc": 72.0, "val_loss": 14.851051568984985, "val_acc": 72.0}
{"epoch": 71, "training_loss": 62.320801734924316, "training_acc": 72.0, "val_loss": 14.918971061706543, "val_acc": 72.0}
