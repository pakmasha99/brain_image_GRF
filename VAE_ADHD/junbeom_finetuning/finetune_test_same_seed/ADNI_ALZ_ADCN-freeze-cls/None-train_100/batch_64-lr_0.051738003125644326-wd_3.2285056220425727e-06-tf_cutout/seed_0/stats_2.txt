"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 200.0609836578369, "training_acc": 50.0, "val_loss": 151.85678005218506, "val_acc": 72.0}
{"epoch": 1, "training_loss": 506.94801902770996, "training_acc": 72.0, "val_loss": 45.90977430343628, "val_acc": 28.0}
{"epoch": 2, "training_loss": 144.79658246040344, "training_acc": 28.0, "val_loss": 46.535852551460266, "val_acc": 72.0}
{"epoch": 3, "training_loss": 201.53317308425903, "training_acc": 72.0, "val_loss": 60.06028652191162, "val_acc": 72.0}
{"epoch": 4, "training_loss": 205.28713274002075, "training_acc": 72.0, "val_loss": 18.173864483833313, "val_acc": 28.0}
{"epoch": 5, "training_loss": 119.29726219177246, "training_acc": 28.0, "val_loss": 14.862175285816193, "val_acc": 72.0}
{"epoch": 6, "training_loss": 76.13811445236206, "training_acc": 72.0, "val_loss": 35.499387979507446, "val_acc": 72.0}
{"epoch": 7, "training_loss": 128.6912522315979, "training_acc": 72.0, "val_loss": 15.626980364322662, "val_acc": 28.0}
{"epoch": 8, "training_loss": 83.35240745544434, "training_acc": 58.0, "val_loss": 14.861142635345459, "val_acc": 72.0}
{"epoch": 9, "training_loss": 77.31631183624268, "training_acc": 72.0, "val_loss": 23.782745003700256, "val_acc": 72.0}
{"epoch": 10, "training_loss": 88.89714431762695, "training_acc": 72.0, "val_loss": 20.715774595737457, "val_acc": 28.0}
{"epoch": 11, "training_loss": 76.93845415115356, "training_acc": 40.0, "val_loss": 16.607065498828888, "val_acc": 72.0}
{"epoch": 12, "training_loss": 68.07028019428253, "training_acc": 72.0, "val_loss": 14.991886913776398, "val_acc": 72.0}
{"epoch": 13, "training_loss": 60.62281394004822, "training_acc": 72.0, "val_loss": 15.933418273925781, "val_acc": 28.0}
{"epoch": 14, "training_loss": 64.23706936836243, "training_acc": 72.0, "val_loss": 16.814428567886353, "val_acc": 72.0}
{"epoch": 15, "training_loss": 68.91278767585754, "training_acc": 72.0, "val_loss": 14.882349967956543, "val_acc": 72.0}
{"epoch": 16, "training_loss": 67.21486449241638, "training_acc": 54.0, "val_loss": 14.849348366260529, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.90978467464447, "training_acc": 72.0, "val_loss": 17.169199883937836, "val_acc": 72.0}
{"epoch": 18, "training_loss": 68.02643322944641, "training_acc": 72.0, "val_loss": 15.502257645130157, "val_acc": 28.0}
{"epoch": 19, "training_loss": 60.751216650009155, "training_acc": 72.0, "val_loss": 15.546584129333496, "val_acc": 72.0}
{"epoch": 20, "training_loss": 62.61839818954468, "training_acc": 72.0, "val_loss": 14.814454317092896, "val_acc": 72.0}
{"epoch": 21, "training_loss": 58.936012744903564, "training_acc": 72.0, "val_loss": 14.839451014995575, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.734179735183716, "training_acc": 72.0, "val_loss": 14.900493621826172, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.02996110916138, "training_acc": 72.0, "val_loss": 14.85716998577118, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.936939001083374, "training_acc": 72.0, "val_loss": 14.82236534357071, "val_acc": 72.0}
{"epoch": 25, "training_loss": 58.68743848800659, "training_acc": 72.0, "val_loss": 14.839661121368408, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.45777130126953, "training_acc": 72.0, "val_loss": 15.465699136257172, "val_acc": 72.0}
{"epoch": 27, "training_loss": 64.11680912971497, "training_acc": 72.0, "val_loss": 17.10788905620575, "val_acc": 28.0}
{"epoch": 28, "training_loss": 65.60214257240295, "training_acc": 78.0, "val_loss": 17.00480580329895, "val_acc": 72.0}
{"epoch": 29, "training_loss": 67.16909432411194, "training_acc": 72.0, "val_loss": 16.43635183572769, "val_acc": 28.0}
{"epoch": 30, "training_loss": 64.64583373069763, "training_acc": 72.0, "val_loss": 14.808198809623718, "val_acc": 72.0}
{"epoch": 31, "training_loss": 58.53179597854614, "training_acc": 72.0, "val_loss": 14.818212389945984, "val_acc": 72.0}
{"epoch": 32, "training_loss": 62.33618092536926, "training_acc": 72.0, "val_loss": 17.29557067155838, "val_acc": 72.0}
{"epoch": 33, "training_loss": 66.91937279701233, "training_acc": 72.0, "val_loss": 15.40982574224472, "val_acc": 48.0}
{"epoch": 34, "training_loss": 63.72117900848389, "training_acc": 72.0, "val_loss": 17.386651039123535, "val_acc": 28.0}
{"epoch": 35, "training_loss": 65.09365701675415, "training_acc": 61.0, "val_loss": 16.621609032154083, "val_acc": 72.0}
{"epoch": 36, "training_loss": 61.90050172805786, "training_acc": 72.0, "val_loss": 20.306208729743958, "val_acc": 28.0}
{"epoch": 37, "training_loss": 75.83318996429443, "training_acc": 42.0, "val_loss": 17.311115562915802, "val_acc": 72.0}
{"epoch": 38, "training_loss": 66.66519618034363, "training_acc": 72.0, "val_loss": 15.43450653553009, "val_acc": 48.0}
{"epoch": 39, "training_loss": 70.8587372303009, "training_acc": 72.0, "val_loss": 14.898596704006195, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.4479615688324, "training_acc": 72.0, "val_loss": 14.791159331798553, "val_acc": 72.0}
{"epoch": 41, "training_loss": 57.69894981384277, "training_acc": 72.0, "val_loss": 15.646697580814362, "val_acc": 72.0}
{"epoch": 42, "training_loss": 63.857670545578, "training_acc": 72.0, "val_loss": 15.142127871513367, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.31127214431763, "training_acc": 72.0, "val_loss": 15.00326544046402, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.29994583129883, "training_acc": 72.0, "val_loss": 16.760511696338654, "val_acc": 28.0}
{"epoch": 45, "training_loss": 65.24352765083313, "training_acc": 75.0, "val_loss": 15.426717698574066, "val_acc": 72.0}
{"epoch": 46, "training_loss": 60.75115942955017, "training_acc": 72.0, "val_loss": 14.797765016555786, "val_acc": 72.0}
{"epoch": 47, "training_loss": 58.75850987434387, "training_acc": 72.0, "val_loss": 14.79790210723877, "val_acc": 72.0}
{"epoch": 48, "training_loss": 57.44091510772705, "training_acc": 72.0, "val_loss": 15.70875495672226, "val_acc": 32.0}
{"epoch": 49, "training_loss": 59.85398817062378, "training_acc": 72.0, "val_loss": 16.20088517665863, "val_acc": 72.0}
{"epoch": 50, "training_loss": 60.37492537498474, "training_acc": 72.0, "val_loss": 16.908420622348785, "val_acc": 28.0}
{"epoch": 51, "training_loss": 65.11927390098572, "training_acc": 73.0, "val_loss": 16.453680396080017, "val_acc": 72.0}
{"epoch": 52, "training_loss": 69.87315106391907, "training_acc": 61.0, "val_loss": 15.886564552783966, "val_acc": 72.0}
{"epoch": 53, "training_loss": 65.85673999786377, "training_acc": 72.0, "val_loss": 16.90429598093033, "val_acc": 28.0}
{"epoch": 54, "training_loss": 64.63584327697754, "training_acc": 76.0, "val_loss": 19.830839335918427, "val_acc": 72.0}
{"epoch": 55, "training_loss": 81.48472213745117, "training_acc": 72.0, "val_loss": 21.529796719551086, "val_acc": 28.0}
{"epoch": 56, "training_loss": 76.90560269355774, "training_acc": 42.0, "val_loss": 18.6746284365654, "val_acc": 72.0}
{"epoch": 57, "training_loss": 82.42226791381836, "training_acc": 72.0, "val_loss": 26.78830325603485, "val_acc": 28.0}
{"epoch": 58, "training_loss": 92.61970257759094, "training_acc": 40.0, "val_loss": 18.686950206756592, "val_acc": 72.0}
{"epoch": 59, "training_loss": 68.96141743659973, "training_acc": 72.0, "val_loss": 17.06412434577942, "val_acc": 28.0}
