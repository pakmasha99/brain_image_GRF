"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 334.5794925689697, "training_acc": 38.0, "val_loss": 139.0118956565857, "val_acc": 72.0}
{"epoch": 1, "training_loss": 484.2716636657715, "training_acc": 72.0, "val_loss": 21.54819816350937, "val_acc": 28.0}
{"epoch": 2, "training_loss": 132.73314094543457, "training_acc": 28.0, "val_loss": 25.421592593193054, "val_acc": 72.0}
{"epoch": 3, "training_loss": 136.75684642791748, "training_acc": 72.0, "val_loss": 39.430296421051025, "val_acc": 72.0}
{"epoch": 4, "training_loss": 121.61891293525696, "training_acc": 72.0, "val_loss": 52.76765823364258, "val_acc": 28.0}
{"epoch": 5, "training_loss": 178.62867045402527, "training_acc": 28.0, "val_loss": 24.117717146873474, "val_acc": 72.0}
{"epoch": 6, "training_loss": 113.97064256668091, "training_acc": 72.0, "val_loss": 33.66050720214844, "val_acc": 72.0}
{"epoch": 7, "training_loss": 108.55157804489136, "training_acc": 72.0, "val_loss": 30.2525132894516, "val_acc": 28.0}
{"epoch": 8, "training_loss": 122.52314233779907, "training_acc": 28.0, "val_loss": 17.347657680511475, "val_acc": 72.0}
{"epoch": 9, "training_loss": 92.40440511703491, "training_acc": 72.0, "val_loss": 29.559558629989624, "val_acc": 72.0}
{"epoch": 10, "training_loss": 99.21082067489624, "training_acc": 72.0, "val_loss": 23.626261949539185, "val_acc": 28.0}
{"epoch": 11, "training_loss": 106.25559949874878, "training_acc": 28.0, "val_loss": 16.174282133579254, "val_acc": 72.0}
{"epoch": 12, "training_loss": 86.11646127700806, "training_acc": 72.0, "val_loss": 28.129976987838745, "val_acc": 72.0}
{"epoch": 13, "training_loss": 99.55376505851746, "training_acc": 72.0, "val_loss": 19.965140521526337, "val_acc": 28.0}
{"epoch": 14, "training_loss": 85.061603307724, "training_acc": 28.0, "val_loss": 15.951484441757202, "val_acc": 72.0}
{"epoch": 15, "training_loss": 73.3119592666626, "training_acc": 72.0, "val_loss": 21.427766978740692, "val_acc": 72.0}
{"epoch": 16, "training_loss": 74.91379165649414, "training_acc": 72.0, "val_loss": 22.99485355615616, "val_acc": 28.0}
{"epoch": 17, "training_loss": 83.4046413898468, "training_acc": 45.0, "val_loss": 17.721931636333466, "val_acc": 72.0}
{"epoch": 18, "training_loss": 77.77319025993347, "training_acc": 72.0, "val_loss": 17.267489433288574, "val_acc": 72.0}
{"epoch": 19, "training_loss": 78.15804815292358, "training_acc": 50.0, "val_loss": 16.4594367146492, "val_acc": 28.0}
{"epoch": 20, "training_loss": 61.61999225616455, "training_acc": 72.0, "val_loss": 19.281204044818878, "val_acc": 72.0}
{"epoch": 21, "training_loss": 73.69959330558777, "training_acc": 72.0, "val_loss": 15.721304714679718, "val_acc": 28.0}
{"epoch": 22, "training_loss": 64.68624591827393, "training_acc": 60.0, "val_loss": 14.766868948936462, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.13619041442871, "training_acc": 72.0, "val_loss": 16.004692018032074, "val_acc": 72.0}
{"epoch": 24, "training_loss": 62.37501621246338, "training_acc": 72.0, "val_loss": 16.302618384361267, "val_acc": 28.0}
{"epoch": 25, "training_loss": 63.86447215080261, "training_acc": 72.0, "val_loss": 15.515126287937164, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.94410800933838, "training_acc": 72.0, "val_loss": 15.520265698432922, "val_acc": 28.0}
{"epoch": 27, "training_loss": 61.573434352874756, "training_acc": 72.0, "val_loss": 15.136858820915222, "val_acc": 72.0}
{"epoch": 28, "training_loss": 60.44286799430847, "training_acc": 72.0, "val_loss": 14.744828641414642, "val_acc": 72.0}
{"epoch": 29, "training_loss": 62.10211420059204, "training_acc": 72.0, "val_loss": 14.932084083557129, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.106322288513184, "training_acc": 72.0, "val_loss": 14.891624450683594, "val_acc": 72.0}
{"epoch": 31, "training_loss": 61.25100779533386, "training_acc": 72.0, "val_loss": 14.712180197238922, "val_acc": 72.0}
{"epoch": 32, "training_loss": 58.72941613197327, "training_acc": 72.0, "val_loss": 15.152791142463684, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.434285163879395, "training_acc": 72.0, "val_loss": 15.68669080734253, "val_acc": 28.0}
{"epoch": 34, "training_loss": 68.6958532333374, "training_acc": 72.0, "val_loss": 14.896538853645325, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.64447784423828, "training_acc": 72.0, "val_loss": 15.204760432243347, "val_acc": 56.0}
{"epoch": 36, "training_loss": 59.56647992134094, "training_acc": 72.0, "val_loss": 15.719012916088104, "val_acc": 72.0}
{"epoch": 37, "training_loss": 62.698848247528076, "training_acc": 72.0, "val_loss": 14.706267416477203, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.121315240859985, "training_acc": 72.0, "val_loss": 16.270487010478973, "val_acc": 72.0}
{"epoch": 39, "training_loss": 64.06029462814331, "training_acc": 72.0, "val_loss": 14.689205586910248, "val_acc": 72.0}
{"epoch": 40, "training_loss": 62.11053800582886, "training_acc": 72.0, "val_loss": 15.779899060726166, "val_acc": 72.0}
{"epoch": 41, "training_loss": 65.07846593856812, "training_acc": 72.0, "val_loss": 14.838504791259766, "val_acc": 72.0}
{"epoch": 42, "training_loss": 70.21497440338135, "training_acc": 50.0, "val_loss": 18.06660294532776, "val_acc": 72.0}
{"epoch": 43, "training_loss": 77.637202501297, "training_acc": 72.0, "val_loss": 15.707939863204956, "val_acc": 72.0}
{"epoch": 44, "training_loss": 64.65093517303467, "training_acc": 60.0, "val_loss": 16.20396375656128, "val_acc": 28.0}
{"epoch": 45, "training_loss": 60.03820061683655, "training_acc": 72.0, "val_loss": 21.048933267593384, "val_acc": 72.0}
{"epoch": 46, "training_loss": 76.00537729263306, "training_acc": 72.0, "val_loss": 22.90412038564682, "val_acc": 28.0}
{"epoch": 47, "training_loss": 81.8308036327362, "training_acc": 42.0, "val_loss": 18.110595643520355, "val_acc": 72.0}
{"epoch": 48, "training_loss": 70.32391333580017, "training_acc": 72.0, "val_loss": 15.136571228504181, "val_acc": 56.0}
{"epoch": 49, "training_loss": 61.418205976486206, "training_acc": 72.0, "val_loss": 16.544458270072937, "val_acc": 28.0}
{"epoch": 50, "training_loss": 62.374839067459106, "training_acc": 75.0, "val_loss": 17.077313363552094, "val_acc": 72.0}
{"epoch": 51, "training_loss": 65.63681364059448, "training_acc": 72.0, "val_loss": 15.726567804813385, "val_acc": 28.0}
{"epoch": 52, "training_loss": 61.929142236709595, "training_acc": 72.0, "val_loss": 14.906765520572662, "val_acc": 72.0}
{"epoch": 53, "training_loss": 60.40765404701233, "training_acc": 72.0, "val_loss": 14.730581641197205, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.225208044052124, "training_acc": 72.0, "val_loss": 14.951063692569733, "val_acc": 80.0}
{"epoch": 55, "training_loss": 61.04163408279419, "training_acc": 72.0, "val_loss": 16.869911551475525, "val_acc": 72.0}
{"epoch": 56, "training_loss": 66.30674338340759, "training_acc": 72.0, "val_loss": 14.92263376712799, "val_acc": 80.0}
{"epoch": 57, "training_loss": 69.0718743801117, "training_acc": 48.0, "val_loss": 21.01060599088669, "val_acc": 72.0}
{"epoch": 58, "training_loss": 87.38700556755066, "training_acc": 72.0, "val_loss": 15.88343232870102, "val_acc": 72.0}
