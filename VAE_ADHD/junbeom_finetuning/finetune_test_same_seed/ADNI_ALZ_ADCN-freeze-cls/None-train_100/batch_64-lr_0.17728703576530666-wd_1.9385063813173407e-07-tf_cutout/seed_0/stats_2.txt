"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 882.479362487793, "training_acc": 42.0, "val_loss": 455.0913333892822, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1419.982063293457, "training_acc": 72.0, "val_loss": 289.81499671936035, "val_acc": 28.0}
{"epoch": 2, "training_loss": 981.0344886779785, "training_acc": 28.0, "val_loss": 141.66451692581177, "val_acc": 72.0}
{"epoch": 3, "training_loss": 687.4529361724854, "training_acc": 72.0, "val_loss": 292.89376735687256, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1141.550495147705, "training_acc": 72.0, "val_loss": 201.4674425125122, "val_acc": 72.0}
{"epoch": 5, "training_loss": 653.2031860351562, "training_acc": 72.0, "val_loss": 175.3476858139038, "val_acc": 28.0}
{"epoch": 6, "training_loss": 683.2320899963379, "training_acc": 28.0, "val_loss": 43.83123219013214, "val_acc": 72.0}
{"epoch": 7, "training_loss": 249.953462600708, "training_acc": 72.0, "val_loss": 101.74270868301392, "val_acc": 72.0}
{"epoch": 8, "training_loss": 352.22345066070557, "training_acc": 72.0, "val_loss": 33.491697907447815, "val_acc": 28.0}
{"epoch": 9, "training_loss": 107.59753894805908, "training_acc": 44.0, "val_loss": 32.44740962982178, "val_acc": 72.0}
{"epoch": 10, "training_loss": 114.45238018035889, "training_acc": 72.0, "val_loss": 73.17925095558167, "val_acc": 28.0}
{"epoch": 11, "training_loss": 244.3052773475647, "training_acc": 40.0, "val_loss": 36.786916851997375, "val_acc": 72.0}
{"epoch": 12, "training_loss": 110.96375894546509, "training_acc": 72.0, "val_loss": 67.66889691352844, "val_acc": 28.0}
{"epoch": 13, "training_loss": 183.99226021766663, "training_acc": 52.0, "val_loss": 60.15610098838806, "val_acc": 72.0}
{"epoch": 14, "training_loss": 237.94476222991943, "training_acc": 72.0, "val_loss": 15.972453355789185, "val_acc": 28.0}
{"epoch": 15, "training_loss": 150.18283081054688, "training_acc": 56.0, "val_loss": 37.82318830490112, "val_acc": 72.0}
{"epoch": 16, "training_loss": 183.54490756988525, "training_acc": 72.0, "val_loss": 45.4487144947052, "val_acc": 72.0}
{"epoch": 17, "training_loss": 179.48444318771362, "training_acc": 52.0, "val_loss": 21.079078316688538, "val_acc": 72.0}
{"epoch": 18, "training_loss": 86.03161525726318, "training_acc": 72.0, "val_loss": 41.714370250701904, "val_acc": 28.0}
{"epoch": 19, "training_loss": 196.58387660980225, "training_acc": 36.0, "val_loss": 41.55595302581787, "val_acc": 72.0}
{"epoch": 20, "training_loss": 121.69941473007202, "training_acc": 72.0, "val_loss": 74.81305003166199, "val_acc": 28.0}
{"epoch": 21, "training_loss": 270.076735496521, "training_acc": 38.0, "val_loss": 49.38192665576935, "val_acc": 72.0}
{"epoch": 22, "training_loss": 160.75669860839844, "training_acc": 72.0, "val_loss": 79.9686849117279, "val_acc": 28.0}
{"epoch": 23, "training_loss": 257.45523381233215, "training_acc": 36.0, "val_loss": 22.337785363197327, "val_acc": 72.0}
{"epoch": 24, "training_loss": 97.11076402664185, "training_acc": 54.0, "val_loss": 30.038532614707947, "val_acc": 72.0}
{"epoch": 25, "training_loss": 112.57340908050537, "training_acc": 72.0, "val_loss": 23.284487426280975, "val_acc": 28.0}
{"epoch": 26, "training_loss": 102.56157302856445, "training_acc": 40.0, "val_loss": 16.076602041721344, "val_acc": 72.0}
{"epoch": 27, "training_loss": 125.5687952041626, "training_acc": 52.0, "val_loss": 45.09214758872986, "val_acc": 72.0}
{"epoch": 28, "training_loss": 190.43753290176392, "training_acc": 72.0, "val_loss": 51.29290819168091, "val_acc": 72.0}
{"epoch": 29, "training_loss": 145.18571996688843, "training_acc": 72.0, "val_loss": 104.84057664871216, "val_acc": 28.0}
{"epoch": 30, "training_loss": 295.6890037059784, "training_acc": 42.0, "val_loss": 42.69217252731323, "val_acc": 72.0}
{"epoch": 31, "training_loss": 164.1955885887146, "training_acc": 72.0, "val_loss": 22.853396832942963, "val_acc": 28.0}
{"epoch": 32, "training_loss": 79.53620648384094, "training_acc": 49.0, "val_loss": 43.33454072475433, "val_acc": 72.0}
{"epoch": 33, "training_loss": 173.17462348937988, "training_acc": 72.0, "val_loss": 15.292197465896606, "val_acc": 72.0}
{"epoch": 34, "training_loss": 157.72557830810547, "training_acc": 56.0, "val_loss": 24.701929092407227, "val_acc": 72.0}
{"epoch": 35, "training_loss": 132.8728494644165, "training_acc": 72.0, "val_loss": 23.1471985578537, "val_acc": 72.0}
{"epoch": 36, "training_loss": 173.65228748321533, "training_acc": 56.0, "val_loss": 17.427685856819153, "val_acc": 72.0}
{"epoch": 37, "training_loss": 73.16713809967041, "training_acc": 72.0, "val_loss": 19.245122373104095, "val_acc": 72.0}
{"epoch": 38, "training_loss": 83.61661624908447, "training_acc": 62.0, "val_loss": 27.116239070892334, "val_acc": 72.0}
{"epoch": 39, "training_loss": 115.63311672210693, "training_acc": 72.0, "val_loss": 29.868221282958984, "val_acc": 28.0}
{"epoch": 40, "training_loss": 114.53929567337036, "training_acc": 42.0, "val_loss": 19.47781890630722, "val_acc": 72.0}
{"epoch": 41, "training_loss": 132.10543155670166, "training_acc": 52.0, "val_loss": 42.85072088241577, "val_acc": 72.0}
{"epoch": 42, "training_loss": 201.3366994857788, "training_acc": 72.0, "val_loss": 42.78121888637543, "val_acc": 72.0}
{"epoch": 43, "training_loss": 149.33216333389282, "training_acc": 58.0, "val_loss": 15.747782588005066, "val_acc": 72.0}
{"epoch": 44, "training_loss": 77.34336423873901, "training_acc": 72.0, "val_loss": 28.846096992492676, "val_acc": 28.0}
{"epoch": 45, "training_loss": 106.10795283317566, "training_acc": 46.0, "val_loss": 29.225894808769226, "val_acc": 72.0}
{"epoch": 46, "training_loss": 96.25912880897522, "training_acc": 58.0, "val_loss": 15.051428973674774, "val_acc": 72.0}
{"epoch": 47, "training_loss": 57.59641742706299, "training_acc": 72.0, "val_loss": 15.454170107841492, "val_acc": 52.0}
{"epoch": 48, "training_loss": 68.11993527412415, "training_acc": 72.0, "val_loss": 21.512311697006226, "val_acc": 28.0}
{"epoch": 49, "training_loss": 116.46020841598511, "training_acc": 38.0, "val_loss": 20.50086110830307, "val_acc": 72.0}
{"epoch": 50, "training_loss": 152.7882843017578, "training_acc": 54.0, "val_loss": 33.113810420036316, "val_acc": 72.0}
{"epoch": 51, "training_loss": 141.3576979637146, "training_acc": 72.0, "val_loss": 25.90663731098175, "val_acc": 72.0}
{"epoch": 52, "training_loss": 135.87707614898682, "training_acc": 60.0, "val_loss": 21.45199328660965, "val_acc": 72.0}
{"epoch": 53, "training_loss": 91.65975618362427, "training_acc": 72.0, "val_loss": 17.35013723373413, "val_acc": 28.0}
{"epoch": 54, "training_loss": 63.285444021224976, "training_acc": 62.0, "val_loss": 16.856418550014496, "val_acc": 72.0}
{"epoch": 55, "training_loss": 72.77692198753357, "training_acc": 54.0, "val_loss": 34.18215811252594, "val_acc": 72.0}
{"epoch": 56, "training_loss": 126.1655821800232, "training_acc": 72.0, "val_loss": 32.01060891151428, "val_acc": 28.0}
{"epoch": 57, "training_loss": 106.20912623405457, "training_acc": 48.0, "val_loss": 29.405128955841064, "val_acc": 72.0}
{"epoch": 58, "training_loss": 94.37012100219727, "training_acc": 61.0, "val_loss": 14.768071472644806, "val_acc": 72.0}
{"epoch": 59, "training_loss": 56.65088653564453, "training_acc": 72.0, "val_loss": 15.349020063877106, "val_acc": 52.0}
{"epoch": 60, "training_loss": 65.23904085159302, "training_acc": 72.0, "val_loss": 24.006037414073944, "val_acc": 28.0}
{"epoch": 61, "training_loss": 108.28744745254517, "training_acc": 44.0, "val_loss": 33.021438121795654, "val_acc": 72.0}
{"epoch": 62, "training_loss": 157.25124597549438, "training_acc": 50.0, "val_loss": 41.06914699077606, "val_acc": 72.0}
{"epoch": 63, "training_loss": 162.59928226470947, "training_acc": 72.0, "val_loss": 22.195537388324738, "val_acc": 72.0}
{"epoch": 64, "training_loss": 132.5113925933838, "training_acc": 62.0, "val_loss": 19.616372883319855, "val_acc": 72.0}
{"epoch": 65, "training_loss": 117.99265956878662, "training_acc": 72.0, "val_loss": 16.278672218322754, "val_acc": 32.0}
{"epoch": 66, "training_loss": 69.59101223945618, "training_acc": 62.0, "val_loss": 38.94032835960388, "val_acc": 72.0}
{"epoch": 67, "training_loss": 143.02052569389343, "training_acc": 72.0, "val_loss": 17.30213165283203, "val_acc": 32.0}
{"epoch": 68, "training_loss": 62.45979356765747, "training_acc": 67.0, "val_loss": 24.437332153320312, "val_acc": 72.0}
{"epoch": 69, "training_loss": 76.91733527183533, "training_acc": 72.0, "val_loss": 37.04499006271362, "val_acc": 28.0}
{"epoch": 70, "training_loss": 132.49435472488403, "training_acc": 50.0, "val_loss": 71.26023173332214, "val_acc": 72.0}
{"epoch": 71, "training_loss": 258.7586917877197, "training_acc": 72.0, "val_loss": 18.523511290550232, "val_acc": 28.0}
{"epoch": 72, "training_loss": 180.68259048461914, "training_acc": 36.0, "val_loss": 69.75581049919128, "val_acc": 72.0}
{"epoch": 73, "training_loss": 307.6358699798584, "training_acc": 72.0, "val_loss": 123.51744174957275, "val_acc": 72.0}
{"epoch": 74, "training_loss": 446.1242961883545, "training_acc": 72.0, "val_loss": 30.232903361320496, "val_acc": 72.0}
{"epoch": 75, "training_loss": 291.9668254852295, "training_acc": 60.0, "val_loss": 147.42013216018677, "val_acc": 28.0}
{"epoch": 76, "training_loss": 505.0394163131714, "training_acc": 38.0, "val_loss": 111.88333034515381, "val_acc": 72.0}
{"epoch": 77, "training_loss": 458.0529899597168, "training_acc": 72.0, "val_loss": 89.03579711914062, "val_acc": 72.0}
