"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 423.7594985961914, "training_acc": 72.0, "val_loss": 425.1220703125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1181.7022151947021, "training_acc": 72.0, "val_loss": 808.8638305664062, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2976.865882873535, "training_acc": 28.0, "val_loss": 49.389585852622986, "val_acc": 28.0}
{"epoch": 3, "training_loss": 488.1005401611328, "training_acc": 46.0, "val_loss": 493.2915687561035, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2111.325454711914, "training_acc": 72.0, "val_loss": 676.3243198394775, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2698.2669105529785, "training_acc": 72.0, "val_loss": 628.5900592803955, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2401.1412658691406, "training_acc": 72.0, "val_loss": 428.6146640777588, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1532.0374183654785, "training_acc": 72.0, "val_loss": 85.59198379516602, "val_acc": 72.0}
{"epoch": 8, "training_loss": 685.3610572814941, "training_acc": 56.0, "val_loss": 476.82342529296875, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1708.1827545166016, "training_acc": 28.0, "val_loss": 15.868817269802094, "val_acc": 72.0}
{"epoch": 10, "training_loss": 207.00252532958984, "training_acc": 72.0, "val_loss": 198.47670793533325, "val_acc": 72.0}
{"epoch": 11, "training_loss": 830.247314453125, "training_acc": 72.0, "val_loss": 207.7775478363037, "val_acc": 72.0}
{"epoch": 12, "training_loss": 786.3352727890015, "training_acc": 72.0, "val_loss": 67.27670431137085, "val_acc": 72.0}
{"epoch": 13, "training_loss": 326.2721424102783, "training_acc": 56.0, "val_loss": 99.90116953849792, "val_acc": 28.0}
{"epoch": 14, "training_loss": 302.702109336853, "training_acc": 48.0, "val_loss": 104.02987003326416, "val_acc": 72.0}
{"epoch": 15, "training_loss": 417.3572368621826, "training_acc": 72.0, "val_loss": 87.66456246376038, "val_acc": 72.0}
{"epoch": 16, "training_loss": 280.99406576156616, "training_acc": 72.0, "val_loss": 124.93512630462646, "val_acc": 28.0}
{"epoch": 17, "training_loss": 421.83154106140137, "training_acc": 28.0, "val_loss": 78.71020436286926, "val_acc": 72.0}
{"epoch": 18, "training_loss": 380.4694023132324, "training_acc": 72.0, "val_loss": 159.232759475708, "val_acc": 72.0}
{"epoch": 19, "training_loss": 619.5483169555664, "training_acc": 72.0, "val_loss": 96.35290503501892, "val_acc": 72.0}
{"epoch": 20, "training_loss": 261.8470504283905, "training_acc": 72.0, "val_loss": 218.89305114746094, "val_acc": 28.0}
{"epoch": 21, "training_loss": 857.4057102203369, "training_acc": 28.0, "val_loss": 15.148168802261353, "val_acc": 72.0}
{"epoch": 22, "training_loss": 141.4385805130005, "training_acc": 72.0, "val_loss": 108.48876237869263, "val_acc": 72.0}
{"epoch": 23, "training_loss": 422.9869680404663, "training_acc": 72.0, "val_loss": 57.365888357162476, "val_acc": 72.0}
{"epoch": 24, "training_loss": 231.50355911254883, "training_acc": 54.0, "val_loss": 17.25427806377411, "val_acc": 28.0}
{"epoch": 25, "training_loss": 100.0754075050354, "training_acc": 58.0, "val_loss": 51.43193602561951, "val_acc": 72.0}
{"epoch": 26, "training_loss": 168.78105974197388, "training_acc": 72.0, "val_loss": 83.82539749145508, "val_acc": 28.0}
{"epoch": 27, "training_loss": 259.50700402259827, "training_acc": 38.0, "val_loss": 25.785616040229797, "val_acc": 72.0}
{"epoch": 28, "training_loss": 94.55268955230713, "training_acc": 71.0, "val_loss": 14.470301568508148, "val_acc": 72.0}
{"epoch": 29, "training_loss": 58.906471967697144, "training_acc": 72.0, "val_loss": 16.980212926864624, "val_acc": 72.0}
{"epoch": 30, "training_loss": 87.39644527435303, "training_acc": 50.0, "val_loss": 41.26320481300354, "val_acc": 72.0}
{"epoch": 31, "training_loss": 171.73196458816528, "training_acc": 72.0, "val_loss": 19.0960094332695, "val_acc": 72.0}
{"epoch": 32, "training_loss": 197.37026023864746, "training_acc": 54.0, "val_loss": 14.90517407655716, "val_acc": 72.0}
{"epoch": 33, "training_loss": 105.41526985168457, "training_acc": 72.0, "val_loss": 33.58220458030701, "val_acc": 72.0}
{"epoch": 34, "training_loss": 111.50984501838684, "training_acc": 60.0, "val_loss": 14.397506415843964, "val_acc": 72.0}
{"epoch": 35, "training_loss": 63.16460347175598, "training_acc": 72.0, "val_loss": 18.23137402534485, "val_acc": 28.0}
{"epoch": 36, "training_loss": 76.36886930465698, "training_acc": 44.0, "val_loss": 14.495836198329926, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.575352907180786, "training_acc": 62.0, "val_loss": 19.529883563518524, "val_acc": 72.0}
{"epoch": 38, "training_loss": 86.0185854434967, "training_acc": 60.0, "val_loss": 29.24138605594635, "val_acc": 72.0}
{"epoch": 39, "training_loss": 107.1121973991394, "training_acc": 72.0, "val_loss": 55.60733675956726, "val_acc": 28.0}
{"epoch": 40, "training_loss": 151.37718152999878, "training_acc": 52.0, "val_loss": 45.17371952533722, "val_acc": 72.0}
{"epoch": 41, "training_loss": 159.74935913085938, "training_acc": 72.0, "val_loss": 66.51135683059692, "val_acc": 28.0}
{"epoch": 42, "training_loss": 188.412700176239, "training_acc": 46.0, "val_loss": 31.34685456752777, "val_acc": 72.0}
{"epoch": 43, "training_loss": 103.21933722496033, "training_acc": 72.0, "val_loss": 57.73111581802368, "val_acc": 28.0}
{"epoch": 44, "training_loss": 183.33201456069946, "training_acc": 48.0, "val_loss": 59.79521870613098, "val_acc": 72.0}
{"epoch": 45, "training_loss": 216.58747339248657, "training_acc": 72.0, "val_loss": 31.330198049545288, "val_acc": 28.0}
{"epoch": 46, "training_loss": 93.51945340633392, "training_acc": 50.0, "val_loss": 32.39280581474304, "val_acc": 72.0}
{"epoch": 47, "training_loss": 113.32831645011902, "training_acc": 72.0, "val_loss": 65.97694158554077, "val_acc": 28.0}
{"epoch": 48, "training_loss": 198.62981534004211, "training_acc": 46.0, "val_loss": 40.89478254318237, "val_acc": 72.0}
{"epoch": 49, "training_loss": 134.51618313789368, "training_acc": 72.0, "val_loss": 75.09303092956543, "val_acc": 28.0}
{"epoch": 50, "training_loss": 255.37468194961548, "training_acc": 40.0, "val_loss": 42.53155291080475, "val_acc": 72.0}
{"epoch": 51, "training_loss": 137.76983642578125, "training_acc": 72.0, "val_loss": 77.32844352722168, "val_acc": 28.0}
{"epoch": 52, "training_loss": 249.46971035003662, "training_acc": 42.0, "val_loss": 43.73692274093628, "val_acc": 72.0}
{"epoch": 53, "training_loss": 141.86596632003784, "training_acc": 72.0, "val_loss": 96.19298577308655, "val_acc": 28.0}
