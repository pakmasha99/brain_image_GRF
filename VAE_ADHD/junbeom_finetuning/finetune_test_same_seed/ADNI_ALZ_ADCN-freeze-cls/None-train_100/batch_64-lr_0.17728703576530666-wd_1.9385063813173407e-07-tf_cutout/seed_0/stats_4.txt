"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 806.6867332458496, "training_acc": 72.0, "val_loss": 427.8995990753174, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1346.5583839416504, "training_acc": 72.0, "val_loss": 539.2698764801025, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1925.261604309082, "training_acc": 28.0, "val_loss": 70.16651630401611, "val_acc": 72.0}
{"epoch": 3, "training_loss": 495.1038703918457, "training_acc": 72.0, "val_loss": 228.24618816375732, "val_acc": 72.0}
{"epoch": 4, "training_loss": 870.1723365783691, "training_acc": 72.0, "val_loss": 115.15213251113892, "val_acc": 72.0}
{"epoch": 5, "training_loss": 413.6241798400879, "training_acc": 52.0, "val_loss": 19.88019347190857, "val_acc": 28.0}
{"epoch": 6, "training_loss": 188.65591049194336, "training_acc": 38.0, "val_loss": 81.85927867889404, "val_acc": 72.0}
{"epoch": 7, "training_loss": 282.29847049713135, "training_acc": 72.0, "val_loss": 88.73324394226074, "val_acc": 28.0}
{"epoch": 8, "training_loss": 231.5130455493927, "training_acc": 50.0, "val_loss": 59.96676683425903, "val_acc": 72.0}
{"epoch": 9, "training_loss": 245.5141315460205, "training_acc": 72.0, "val_loss": 31.317630410194397, "val_acc": 72.0}
{"epoch": 10, "training_loss": 208.8434133529663, "training_acc": 58.0, "val_loss": 15.512646734714508, "val_acc": 28.0}
{"epoch": 11, "training_loss": 132.51401138305664, "training_acc": 72.0, "val_loss": 66.41770601272583, "val_acc": 72.0}
{"epoch": 12, "training_loss": 215.90393257141113, "training_acc": 72.0, "val_loss": 94.1352128982544, "val_acc": 28.0}
{"epoch": 13, "training_loss": 280.52898716926575, "training_acc": 38.0, "val_loss": 36.261722445487976, "val_acc": 72.0}
{"epoch": 14, "training_loss": 131.6473126411438, "training_acc": 72.0, "val_loss": 52.434295415878296, "val_acc": 28.0}
{"epoch": 15, "training_loss": 174.89042139053345, "training_acc": 44.0, "val_loss": 36.18530333042145, "val_acc": 72.0}
{"epoch": 16, "training_loss": 125.11277937889099, "training_acc": 72.0, "val_loss": 17.805545032024384, "val_acc": 28.0}
{"epoch": 17, "training_loss": 91.20340776443481, "training_acc": 44.0, "val_loss": 24.62492287158966, "val_acc": 72.0}
{"epoch": 18, "training_loss": 189.64528369903564, "training_acc": 48.0, "val_loss": 38.17401826381683, "val_acc": 72.0}
{"epoch": 19, "training_loss": 167.19843912124634, "training_acc": 72.0, "val_loss": 40.684717893600464, "val_acc": 72.0}
{"epoch": 20, "training_loss": 132.52971649169922, "training_acc": 58.0, "val_loss": 14.538386464118958, "val_acc": 72.0}
{"epoch": 21, "training_loss": 77.19884014129639, "training_acc": 72.0, "val_loss": 17.683452367782593, "val_acc": 28.0}
{"epoch": 22, "training_loss": 68.23240756988525, "training_acc": 46.0, "val_loss": 14.481879770755768, "val_acc": 72.0}
{"epoch": 23, "training_loss": 62.02447485923767, "training_acc": 71.0, "val_loss": 28.54343056678772, "val_acc": 72.0}
{"epoch": 24, "training_loss": 99.93133091926575, "training_acc": 72.0, "val_loss": 63.370126485824585, "val_acc": 28.0}
{"epoch": 25, "training_loss": 211.74986839294434, "training_acc": 44.0, "val_loss": 48.726463317871094, "val_acc": 72.0}
{"epoch": 26, "training_loss": 160.0377163887024, "training_acc": 72.0, "val_loss": 84.41991806030273, "val_acc": 28.0}
{"epoch": 27, "training_loss": 263.7963128089905, "training_acc": 40.0, "val_loss": 31.160691380500793, "val_acc": 72.0}
{"epoch": 28, "training_loss": 102.26052117347717, "training_acc": 72.0, "val_loss": 20.214390754699707, "val_acc": 28.0}
{"epoch": 29, "training_loss": 90.05691003799438, "training_acc": 48.0, "val_loss": 38.379767537117004, "val_acc": 72.0}
{"epoch": 30, "training_loss": 170.30893564224243, "training_acc": 46.0, "val_loss": 36.488914489746094, "val_acc": 72.0}
{"epoch": 31, "training_loss": 166.3537721633911, "training_acc": 72.0, "val_loss": 15.329152345657349, "val_acc": 32.0}
{"epoch": 32, "training_loss": 111.43619346618652, "training_acc": 56.0, "val_loss": 53.66728901863098, "val_acc": 72.0}
{"epoch": 33, "training_loss": 245.48745822906494, "training_acc": 72.0, "val_loss": 65.22401571273804, "val_acc": 72.0}
{"epoch": 34, "training_loss": 186.65273571014404, "training_acc": 72.0, "val_loss": 149.50624704360962, "val_acc": 28.0}
{"epoch": 35, "training_loss": 475.4844102859497, "training_acc": 28.0, "val_loss": 97.72102236747742, "val_acc": 72.0}
{"epoch": 36, "training_loss": 492.0052127838135, "training_acc": 72.0, "val_loss": 194.83083486557007, "val_acc": 72.0}
{"epoch": 37, "training_loss": 756.5592880249023, "training_acc": 72.0, "val_loss": 126.80164575576782, "val_acc": 72.0}
{"epoch": 38, "training_loss": 379.60275173187256, "training_acc": 72.0, "val_loss": 175.22889375686646, "val_acc": 28.0}
{"epoch": 39, "training_loss": 716.286506652832, "training_acc": 28.0, "val_loss": 22.758258879184723, "val_acc": 72.0}
{"epoch": 40, "training_loss": 174.9794454574585, "training_acc": 72.0, "val_loss": 84.52096581459045, "val_acc": 72.0}
{"epoch": 41, "training_loss": 294.76879930496216, "training_acc": 72.0, "val_loss": 34.68438982963562, "val_acc": 28.0}
