"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 577.1469230651855, "training_acc": 72.0, "val_loss": 446.63782119750977, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1262.7853546142578, "training_acc": 72.0, "val_loss": 563.2477760314941, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2042.663444519043, "training_acc": 28.0, "val_loss": 51.58456563949585, "val_acc": 72.0}
{"epoch": 3, "training_loss": 308.36646461486816, "training_acc": 72.0, "val_loss": 199.21990633010864, "val_acc": 72.0}
{"epoch": 4, "training_loss": 765.7781639099121, "training_acc": 72.0, "val_loss": 102.20787525177002, "val_acc": 72.0}
{"epoch": 5, "training_loss": 377.34968757629395, "training_acc": 52.0, "val_loss": 15.185803174972534, "val_acc": 72.0}
{"epoch": 6, "training_loss": 73.42047238349915, "training_acc": 72.0, "val_loss": 24.697570502758026, "val_acc": 28.0}
{"epoch": 7, "training_loss": 101.18373441696167, "training_acc": 48.0, "val_loss": 35.58972775936127, "val_acc": 72.0}
{"epoch": 8, "training_loss": 178.43994331359863, "training_acc": 50.0, "val_loss": 49.111372232437134, "val_acc": 72.0}
{"epoch": 9, "training_loss": 226.51171016693115, "training_acc": 72.0, "val_loss": 39.532825350761414, "val_acc": 72.0}
{"epoch": 10, "training_loss": 224.7205286026001, "training_acc": 54.0, "val_loss": 17.30385571718216, "val_acc": 72.0}
{"epoch": 11, "training_loss": 101.31510162353516, "training_acc": 72.0, "val_loss": 14.829640090465546, "val_acc": 72.0}
{"epoch": 12, "training_loss": 125.75125980377197, "training_acc": 56.0, "val_loss": 43.88665556907654, "val_acc": 72.0}
{"epoch": 13, "training_loss": 187.11631870269775, "training_acc": 72.0, "val_loss": 46.795716881752014, "val_acc": 72.0}
{"epoch": 14, "training_loss": 147.25466585159302, "training_acc": 56.0, "val_loss": 24.351906776428223, "val_acc": 28.0}
{"epoch": 15, "training_loss": 121.94251298904419, "training_acc": 46.0, "val_loss": 60.039544105529785, "val_acc": 72.0}
{"epoch": 16, "training_loss": 201.55018424987793, "training_acc": 72.0, "val_loss": 75.99713206291199, "val_acc": 28.0}
{"epoch": 17, "training_loss": 210.9869875907898, "training_acc": 46.0, "val_loss": 49.58896040916443, "val_acc": 72.0}
{"epoch": 18, "training_loss": 205.87599754333496, "training_acc": 72.0, "val_loss": 18.709783256053925, "val_acc": 72.0}
{"epoch": 19, "training_loss": 232.50750160217285, "training_acc": 54.0, "val_loss": 18.966026604175568, "val_acc": 28.0}
{"epoch": 20, "training_loss": 205.4426383972168, "training_acc": 38.0, "val_loss": 112.87744045257568, "val_acc": 72.0}
{"epoch": 21, "training_loss": 438.05377769470215, "training_acc": 72.0, "val_loss": 52.61966586112976, "val_acc": 72.0}
{"epoch": 22, "training_loss": 219.2658233642578, "training_acc": 60.0, "val_loss": 37.834563851356506, "val_acc": 28.0}
{"epoch": 23, "training_loss": 225.27823066711426, "training_acc": 42.0, "val_loss": 124.72659349441528, "val_acc": 72.0}
{"epoch": 24, "training_loss": 495.19415187835693, "training_acc": 72.0, "val_loss": 91.67789816856384, "val_acc": 72.0}
{"epoch": 25, "training_loss": 289.49766516685486, "training_acc": 72.0, "val_loss": 165.09358882904053, "val_acc": 28.0}
{"epoch": 26, "training_loss": 580.528730392456, "training_acc": 28.0, "val_loss": 64.2841100692749, "val_acc": 72.0}
{"epoch": 27, "training_loss": 362.9086399078369, "training_acc": 72.0, "val_loss": 138.02725076675415, "val_acc": 72.0}
{"epoch": 28, "training_loss": 514.5275268554688, "training_acc": 72.0, "val_loss": 52.0355761051178, "val_acc": 72.0}
{"epoch": 29, "training_loss": 257.80499362945557, "training_acc": 60.0, "val_loss": 91.80848598480225, "val_acc": 28.0}
{"epoch": 30, "training_loss": 304.2399625778198, "training_acc": 46.0, "val_loss": 110.73975563049316, "val_acc": 72.0}
