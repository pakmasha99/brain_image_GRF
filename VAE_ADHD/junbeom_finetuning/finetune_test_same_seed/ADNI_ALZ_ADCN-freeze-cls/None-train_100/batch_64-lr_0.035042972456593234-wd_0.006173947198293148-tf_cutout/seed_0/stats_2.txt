"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 298.75506019592285, "training_acc": 30.0, "val_loss": 81.52201771736145, "val_acc": 72.0}
{"epoch": 1, "training_loss": 242.19415760040283, "training_acc": 72.0, "val_loss": 48.377725481987, "val_acc": 28.0}
{"epoch": 2, "training_loss": 193.03924465179443, "training_acc": 28.0, "val_loss": 15.818411111831665, "val_acc": 72.0}
{"epoch": 3, "training_loss": 89.79187631607056, "training_acc": 72.0, "val_loss": 37.63355910778046, "val_acc": 72.0}
{"epoch": 4, "training_loss": 140.81559801101685, "training_acc": 72.0, "val_loss": 17.270734906196594, "val_acc": 72.0}
{"epoch": 5, "training_loss": 77.29936146736145, "training_acc": 58.0, "val_loss": 28.602543473243713, "val_acc": 28.0}
{"epoch": 6, "training_loss": 107.59246015548706, "training_acc": 34.0, "val_loss": 20.06991356611252, "val_acc": 72.0}
{"epoch": 7, "training_loss": 80.16432118415833, "training_acc": 72.0, "val_loss": 16.33029133081436, "val_acc": 72.0}
{"epoch": 8, "training_loss": 66.53020453453064, "training_acc": 72.0, "val_loss": 18.52596253156662, "val_acc": 28.0}
{"epoch": 9, "training_loss": 68.74447584152222, "training_acc": 44.0, "val_loss": 16.429772973060608, "val_acc": 72.0}
{"epoch": 10, "training_loss": 66.33128237724304, "training_acc": 72.0, "val_loss": 15.67121297121048, "val_acc": 72.0}
{"epoch": 11, "training_loss": 60.66731834411621, "training_acc": 72.0, "val_loss": 17.090266942977905, "val_acc": 28.0}
{"epoch": 12, "training_loss": 65.3531265258789, "training_acc": 72.0, "val_loss": 15.669426321983337, "val_acc": 72.0}
{"epoch": 13, "training_loss": 64.40443539619446, "training_acc": 72.0, "val_loss": 15.690213441848755, "val_acc": 72.0}
{"epoch": 14, "training_loss": 66.28939962387085, "training_acc": 72.0, "val_loss": 15.535841882228851, "val_acc": 28.0}
{"epoch": 15, "training_loss": 61.73609900474548, "training_acc": 72.0, "val_loss": 15.531060099601746, "val_acc": 72.0}
{"epoch": 16, "training_loss": 61.71335434913635, "training_acc": 72.0, "val_loss": 14.851278066635132, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.16046357154846, "training_acc": 72.0, "val_loss": 14.837981760501862, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58.990899324417114, "training_acc": 72.0, "val_loss": 15.100815892219543, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.93973469734192, "training_acc": 72.0, "val_loss": 14.842484891414642, "val_acc": 72.0}
{"epoch": 20, "training_loss": 61.313533782958984, "training_acc": 72.0, "val_loss": 14.93782252073288, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.179672598838806, "training_acc": 72.0, "val_loss": 15.529830753803253, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.759846925735474, "training_acc": 72.0, "val_loss": 15.130634605884552, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.1080219745636, "training_acc": 72.0, "val_loss": 14.872357249259949, "val_acc": 72.0}
{"epoch": 24, "training_loss": 58.85691952705383, "training_acc": 72.0, "val_loss": 15.059582889080048, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.975990295410156, "training_acc": 72.0, "val_loss": 14.87075537443161, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.09981918334961, "training_acc": 72.0, "val_loss": 14.846600592136383, "val_acc": 72.0}
{"epoch": 27, "training_loss": 58.93466567993164, "training_acc": 72.0, "val_loss": 14.877559244632721, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.49640393257141, "training_acc": 72.0, "val_loss": 15.060803294181824, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.97842574119568, "training_acc": 72.0, "val_loss": 14.886660873889923, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.4389545917511, "training_acc": 72.0, "val_loss": 14.893701672554016, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.23396396636963, "training_acc": 72.0, "val_loss": 14.963285624980927, "val_acc": 72.0}
{"epoch": 32, "training_loss": 60.88229179382324, "training_acc": 72.0, "val_loss": 14.845851063728333, "val_acc": 72.0}
{"epoch": 33, "training_loss": 58.39805746078491, "training_acc": 72.0, "val_loss": 15.441522002220154, "val_acc": 36.0}
{"epoch": 34, "training_loss": 60.78505063056946, "training_acc": 72.0, "val_loss": 15.074539184570312, "val_acc": 72.0}
{"epoch": 35, "training_loss": 62.89717507362366, "training_acc": 72.0, "val_loss": 15.375545620918274, "val_acc": 72.0}
{"epoch": 36, "training_loss": 68.0122230052948, "training_acc": 72.0, "val_loss": 15.389111638069153, "val_acc": 52.0}
