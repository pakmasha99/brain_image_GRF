"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 43185.82069015503, "training_acc": 72.0, "val_loss": 16352.360534667969, "val_acc": 72.0}
{"epoch": 1, "training_loss": 47349.625244140625, "training_acc": 72.0, "val_loss": 30613.150024414062, "val_acc": 28.0}
{"epoch": 2, "training_loss": 117498.54345703125, "training_acc": 28.0, "val_loss": 4894.441604614258, "val_acc": 28.0}
{"epoch": 3, "training_loss": 27839.877563476562, "training_acc": 44.0, "val_loss": 19381.092834472656, "val_acc": 72.0}
{"epoch": 4, "training_loss": 82488.85522460938, "training_acc": 72.0, "val_loss": 27157.965087890625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 109088.48413085938, "training_acc": 72.0, "val_loss": 25843.841552734375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 98479.86083984375, "training_acc": 72.0, "val_loss": 17308.0322265625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 64271.16467285156, "training_acc": 72.0, "val_loss": 2994.661521911621, "val_acc": 72.0}
{"epoch": 8, "training_loss": 28177.17236328125, "training_acc": 56.0, "val_loss": 20302.804565429688, "val_acc": 28.0}
{"epoch": 9, "training_loss": 72519.69750976562, "training_acc": 28.0, "val_loss": 546.6328144073486, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4744.793670654297, "training_acc": 72.0, "val_loss": 6572.519683837891, "val_acc": 72.0}
{"epoch": 11, "training_loss": 26957.54705810547, "training_acc": 72.0, "val_loss": 6088.043975830078, "val_acc": 72.0}
{"epoch": 12, "training_loss": 20770.91864013672, "training_acc": 72.0, "val_loss": 822.6642608642578, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2186.880323410034, "training_acc": 48.0, "val_loss": 1712.849998474121, "val_acc": 28.0}
{"epoch": 14, "training_loss": 9192.562744140625, "training_acc": 40.0, "val_loss": 3909.579849243164, "val_acc": 72.0}
{"epoch": 15, "training_loss": 15097.545715332031, "training_acc": 72.0, "val_loss": 1555.0188064575195, "val_acc": 72.0}
{"epoch": 16, "training_loss": 9933.111755371094, "training_acc": 58.0, "val_loss": 2190.0646209716797, "val_acc": 28.0}
{"epoch": 17, "training_loss": 10115.205871582031, "training_acc": 46.0, "val_loss": 6331.472015380859, "val_acc": 72.0}
{"epoch": 18, "training_loss": 26730.3525390625, "training_acc": 72.0, "val_loss": 6678.577423095703, "val_acc": 72.0}
{"epoch": 19, "training_loss": 23946.43048095703, "training_acc": 72.0, "val_loss": 1198.0073928833008, "val_acc": 72.0}
{"epoch": 20, "training_loss": 16445.70263671875, "training_acc": 54.0, "val_loss": 8946.458435058594, "val_acc": 28.0}
{"epoch": 21, "training_loss": 22517.676273345947, "training_acc": 46.0, "val_loss": 2101.149559020996, "val_acc": 72.0}
{"epoch": 22, "training_loss": 9420.058410644531, "training_acc": 72.0, "val_loss": 1208.7554931640625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 9717.315979003906, "training_acc": 54.0, "val_loss": 712.6031398773193, "val_acc": 28.0}
{"epoch": 24, "training_loss": 6876.87841796875, "training_acc": 48.0, "val_loss": 7656.768035888672, "val_acc": 72.0}
{"epoch": 25, "training_loss": 31807.576416015625, "training_acc": 72.0, "val_loss": 8839.481353759766, "val_acc": 72.0}
{"epoch": 26, "training_loss": 33399.785888671875, "training_acc": 72.0, "val_loss": 4568.851470947266, "val_acc": 72.0}
{"epoch": 27, "training_loss": 13082.577621459961, "training_acc": 72.0, "val_loss": 11521.638488769531, "val_acc": 28.0}
{"epoch": 28, "training_loss": 48073.601806640625, "training_acc": 28.0, "val_loss": 4901.736831665039, "val_acc": 28.0}
