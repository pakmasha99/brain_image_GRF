"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 36292.64828491211, "training_acc": 40.0, "val_loss": 17232.8369140625, "val_acc": 72.0}
{"epoch": 1, "training_loss": 53485.72229003906, "training_acc": 72.0, "val_loss": 15085.157775878906, "val_acc": 28.0}
{"epoch": 2, "training_loss": 53276.58166503906, "training_acc": 28.0, "val_loss": 4134.723663330078, "val_acc": 72.0}
{"epoch": 3, "training_loss": 23637.100463867188, "training_acc": 72.0, "val_loss": 9949.5849609375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 38595.705078125, "training_acc": 72.0, "val_loss": 5709.861373901367, "val_acc": 72.0}
{"epoch": 5, "training_loss": 15792.212116241455, "training_acc": 72.0, "val_loss": 16547.373962402344, "val_acc": 28.0}
{"epoch": 6, "training_loss": 68994.81323242188, "training_acc": 28.0, "val_loss": 8420.014190673828, "val_acc": 28.0}
{"epoch": 7, "training_loss": 27144.720947265625, "training_acc": 44.0, "val_loss": 8877.20718383789, "val_acc": 72.0}
{"epoch": 8, "training_loss": 39066.3955078125, "training_acc": 72.0, "val_loss": 12823.641967773438, "val_acc": 72.0}
{"epoch": 9, "training_loss": 50588.559326171875, "training_acc": 72.0, "val_loss": 10347.618865966797, "val_acc": 72.0}
{"epoch": 10, "training_loss": 36876.512634277344, "training_acc": 72.0, "val_loss": 2369.3437576293945, "val_acc": 72.0}
{"epoch": 11, "training_loss": 18106.024047851562, "training_acc": 56.0, "val_loss": 10962.214660644531, "val_acc": 28.0}
{"epoch": 12, "training_loss": 33468.46600341797, "training_acc": 28.0, "val_loss": 4275.461959838867, "val_acc": 72.0}
{"epoch": 13, "training_loss": 23610.301025390625, "training_acc": 72.0, "val_loss": 10735.847473144531, "val_acc": 72.0}
{"epoch": 14, "training_loss": 43495.8173828125, "training_acc": 72.0, "val_loss": 10668.157958984375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 39836.9619140625, "training_acc": 72.0, "val_loss": 5584.638595581055, "val_acc": 72.0}
{"epoch": 16, "training_loss": 17249.830276489258, "training_acc": 72.0, "val_loss": 10107.052612304688, "val_acc": 28.0}
{"epoch": 17, "training_loss": 44400.25244140625, "training_acc": 28.0, "val_loss": 5860.412979125977, "val_acc": 28.0}
{"epoch": 18, "training_loss": 17245.400360107422, "training_acc": 50.0, "val_loss": 7328.986358642578, "val_acc": 72.0}
{"epoch": 19, "training_loss": 31385.57861328125, "training_acc": 72.0, "val_loss": 10480.491638183594, "val_acc": 72.0}
{"epoch": 20, "training_loss": 41213.20349121094, "training_acc": 72.0, "val_loss": 8293.885803222656, "val_acc": 72.0}
{"epoch": 21, "training_loss": 28288.583740234375, "training_acc": 72.0, "val_loss": 1322.1715927124023, "val_acc": 72.0}
{"epoch": 22, "training_loss": 18612.2861328125, "training_acc": 54.0, "val_loss": 12595.98388671875, "val_acc": 28.0}
{"epoch": 23, "training_loss": 40860.60412597656, "training_acc": 28.0, "val_loss": 3194.5966720581055, "val_acc": 72.0}
{"epoch": 24, "training_loss": 17563.650512695312, "training_acc": 72.0, "val_loss": 9230.735778808594, "val_acc": 72.0}
{"epoch": 25, "training_loss": 37629.458740234375, "training_acc": 72.0, "val_loss": 9255.912017822266, "val_acc": 72.0}
{"epoch": 26, "training_loss": 33919.13098144531, "training_acc": 72.0, "val_loss": 4325.918960571289, "val_acc": 72.0}
{"epoch": 27, "training_loss": 11164.682518959045, "training_acc": 72.0, "val_loss": 13074.577331542969, "val_acc": 28.0}
{"epoch": 28, "training_loss": 56606.291748046875, "training_acc": 28.0, "val_loss": 9932.621002197266, "val_acc": 28.0}
{"epoch": 29, "training_loss": 27629.28515625, "training_acc": 44.0, "val_loss": 5218.897247314453, "val_acc": 72.0}
{"epoch": 30, "training_loss": 24390.715209960938, "training_acc": 72.0, "val_loss": 7674.754333496094, "val_acc": 72.0}
{"epoch": 31, "training_loss": 29081.557250976562, "training_acc": 72.0, "val_loss": 4420.222473144531, "val_acc": 72.0}
{"epoch": 32, "training_loss": 12198.556396484375, "training_acc": 72.0, "val_loss": 9137.142181396484, "val_acc": 28.0}
{"epoch": 33, "training_loss": 40600.657958984375, "training_acc": 28.0, "val_loss": 3697.4292755126953, "val_acc": 28.0}
{"epoch": 34, "training_loss": 20993.321899414062, "training_acc": 34.0, "val_loss": 8756.986236572266, "val_acc": 72.0}
{"epoch": 35, "training_loss": 37979.50244140625, "training_acc": 72.0, "val_loss": 11578.972625732422, "val_acc": 72.0}
{"epoch": 36, "training_loss": 45157.06201171875, "training_acc": 72.0, "val_loss": 8921.906280517578, "val_acc": 72.0}
{"epoch": 37, "training_loss": 31863.966796875, "training_acc": 72.0, "val_loss": 1729.517936706543, "val_acc": 72.0}
{"epoch": 38, "training_loss": 14304.670166015625, "training_acc": 60.0, "val_loss": 10706.710815429688, "val_acc": 28.0}
{"epoch": 39, "training_loss": 34571.479736328125, "training_acc": 28.0, "val_loss": 3647.8012084960938, "val_acc": 72.0}
{"epoch": 40, "training_loss": 19874.91943359375, "training_acc": 72.0, "val_loss": 8793.16177368164, "val_acc": 72.0}
