"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 39344.40272140503, "training_acc": 72.0, "val_loss": 14896.452331542969, "val_acc": 72.0}
{"epoch": 1, "training_loss": 43134.05596923828, "training_acc": 72.0, "val_loss": 27886.9873046875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 107035.017578125, "training_acc": 28.0, "val_loss": 4458.306884765625, "val_acc": 28.0}
{"epoch": 3, "training_loss": 25360.325927734375, "training_acc": 44.0, "val_loss": 17655.503845214844, "val_acc": 72.0}
{"epoch": 4, "training_loss": 75144.44116210938, "training_acc": 72.0, "val_loss": 24739.910888671875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 99375.6103515625, "training_acc": 72.0, "val_loss": 23542.796325683594, "val_acc": 72.0}
{"epoch": 6, "training_loss": 89711.5791015625, "training_acc": 72.0, "val_loss": 15767.027282714844, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58548.8740234375, "training_acc": 72.0, "val_loss": 2728.138542175293, "val_acc": 72.0}
{"epoch": 8, "training_loss": 25668.100341796875, "training_acc": 56.0, "val_loss": 18494.69757080078, "val_acc": 28.0}
{"epoch": 9, "training_loss": 66061.18481445312, "training_acc": 28.0, "val_loss": 498.08502197265625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4322.808135986328, "training_acc": 72.0, "val_loss": 5987.418746948242, "val_acc": 72.0}
{"epoch": 11, "training_loss": 24557.70831298828, "training_acc": 72.0, "val_loss": 5546.08154296875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 18921.940002441406, "training_acc": 72.0, "val_loss": 749.094295501709, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1991.5256023406982, "training_acc": 48.0, "val_loss": 1560.0168228149414, "val_acc": 28.0}
{"epoch": 14, "training_loss": 8373.414093017578, "training_acc": 40.0, "val_loss": 3561.5901947021484, "val_acc": 72.0}
{"epoch": 15, "training_loss": 13753.734558105469, "training_acc": 72.0, "val_loss": 1416.6826248168945, "val_acc": 72.0}
{"epoch": 16, "training_loss": 9048.518798828125, "training_acc": 58.0, "val_loss": 1994.740104675293, "val_acc": 28.0}
{"epoch": 17, "training_loss": 9213.905731201172, "training_acc": 46.0, "val_loss": 5767.83332824707, "val_acc": 72.0}
{"epoch": 18, "training_loss": 24350.738159179688, "training_acc": 72.0, "val_loss": 6084.033203125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 21814.701049804688, "training_acc": 72.0, "val_loss": 1091.4596557617188, "val_acc": 72.0}
{"epoch": 20, "training_loss": 14981.214477539062, "training_acc": 54.0, "val_loss": 8149.537658691406, "val_acc": 28.0}
{"epoch": 21, "training_loss": 20512.046392440796, "training_acc": 46.0, "val_loss": 1914.1847610473633, "val_acc": 72.0}
{"epoch": 22, "training_loss": 8581.775299072266, "training_acc": 72.0, "val_loss": 1101.2508392333984, "val_acc": 72.0}
{"epoch": 23, "training_loss": 8851.933959960938, "training_acc": 54.0, "val_loss": 648.833703994751, "val_acc": 28.0}
{"epoch": 24, "training_loss": 6263.9267578125, "training_acc": 48.0, "val_loss": 6975.1251220703125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 28975.882751464844, "training_acc": 72.0, "val_loss": 8052.52685546875, "val_acc": 72.0}
{"epoch": 26, "training_loss": 30426.31329345703, "training_acc": 72.0, "val_loss": 4162.160110473633, "val_acc": 72.0}
{"epoch": 27, "training_loss": 11918.180458068848, "training_acc": 72.0, "val_loss": 10495.417785644531, "val_acc": 28.0}
{"epoch": 28, "training_loss": 43791.80310058594, "training_acc": 28.0, "val_loss": 4464.960861206055, "val_acc": 28.0}
