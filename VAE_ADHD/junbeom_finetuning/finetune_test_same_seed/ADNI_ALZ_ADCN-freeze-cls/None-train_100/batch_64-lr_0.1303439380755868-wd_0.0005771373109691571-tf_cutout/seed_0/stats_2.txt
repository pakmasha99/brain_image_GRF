"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 658.1919975280762, "training_acc": 42.0, "val_loss": 339.79876041412354, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1148.7736129760742, "training_acc": 72.0, "val_loss": 185.3057622909546, "val_acc": 28.0}
{"epoch": 2, "training_loss": 559.1017599105835, "training_acc": 28.0, "val_loss": 135.2145791053772, "val_acc": 72.0}
{"epoch": 3, "training_loss": 650.3567771911621, "training_acc": 72.0, "val_loss": 254.8558235168457, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1002.8868446350098, "training_acc": 72.0, "val_loss": 188.90743255615234, "val_acc": 72.0}
{"epoch": 5, "training_loss": 625.9223785400391, "training_acc": 72.0, "val_loss": 51.918041706085205, "val_acc": 28.0}
{"epoch": 6, "training_loss": 251.2414674758911, "training_acc": 28.0, "val_loss": 39.65016007423401, "val_acc": 72.0}
{"epoch": 7, "training_loss": 203.9044828414917, "training_acc": 72.0, "val_loss": 69.45188641548157, "val_acc": 72.0}
{"epoch": 8, "training_loss": 225.48925638198853, "training_acc": 72.0, "val_loss": 63.03287148475647, "val_acc": 28.0}
{"epoch": 9, "training_loss": 196.05773997306824, "training_acc": 28.0, "val_loss": 44.58967745304108, "val_acc": 72.0}
{"epoch": 10, "training_loss": 201.61587047576904, "training_acc": 72.0, "val_loss": 42.05474853515625, "val_acc": 72.0}
{"epoch": 11, "training_loss": 179.88324165344238, "training_acc": 48.0, "val_loss": 14.983732998371124, "val_acc": 72.0}
{"epoch": 12, "training_loss": 90.97314167022705, "training_acc": 72.0, "val_loss": 15.029828250408173, "val_acc": 72.0}
{"epoch": 13, "training_loss": 82.19051218032837, "training_acc": 56.0, "val_loss": 30.347558856010437, "val_acc": 72.0}
{"epoch": 14, "training_loss": 132.9827103614807, "training_acc": 72.0, "val_loss": 21.213971078395844, "val_acc": 72.0}
{"epoch": 15, "training_loss": 155.10773181915283, "training_acc": 52.0, "val_loss": 15.791544318199158, "val_acc": 72.0}
{"epoch": 16, "training_loss": 96.52779912948608, "training_acc": 72.0, "val_loss": 24.974486231803894, "val_acc": 72.0}
{"epoch": 17, "training_loss": 78.66220021247864, "training_acc": 64.0, "val_loss": 21.136313676834106, "val_acc": 28.0}
{"epoch": 18, "training_loss": 106.58581113815308, "training_acc": 42.0, "val_loss": 37.37691938877106, "val_acc": 72.0}
{"epoch": 19, "training_loss": 114.2926721572876, "training_acc": 72.0, "val_loss": 74.91158246994019, "val_acc": 28.0}
{"epoch": 20, "training_loss": 219.45353651046753, "training_acc": 43.0, "val_loss": 44.550612568855286, "val_acc": 72.0}
{"epoch": 21, "training_loss": 212.09404850006104, "training_acc": 72.0, "val_loss": 39.44945931434631, "val_acc": 72.0}
{"epoch": 22, "training_loss": 154.114248752594, "training_acc": 54.0, "val_loss": 16.160695254802704, "val_acc": 28.0}
{"epoch": 23, "training_loss": 71.91290020942688, "training_acc": 72.0, "val_loss": 29.171636700630188, "val_acc": 72.0}
{"epoch": 24, "training_loss": 88.66369581222534, "training_acc": 72.0, "val_loss": 50.91431140899658, "val_acc": 28.0}
{"epoch": 25, "training_loss": 148.8732943534851, "training_acc": 48.0, "val_loss": 39.228078722953796, "val_acc": 72.0}
{"epoch": 26, "training_loss": 141.50950980186462, "training_acc": 72.0, "val_loss": 25.348705053329468, "val_acc": 28.0}
{"epoch": 27, "training_loss": 92.20513033866882, "training_acc": 42.0, "val_loss": 17.280979454517365, "val_acc": 72.0}
{"epoch": 28, "training_loss": 67.7379801273346, "training_acc": 58.0, "val_loss": 15.513482689857483, "val_acc": 72.0}
{"epoch": 29, "training_loss": 64.05955648422241, "training_acc": 72.0, "val_loss": 22.539067268371582, "val_acc": 28.0}
{"epoch": 30, "training_loss": 73.51205110549927, "training_acc": 50.0, "val_loss": 24.032820761203766, "val_acc": 72.0}
