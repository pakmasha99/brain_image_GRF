"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 655.1309700012207, "training_acc": 42.0, "val_loss": 331.75621032714844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1037.602975845337, "training_acc": 72.0, "val_loss": 207.6655626296997, "val_acc": 28.0}
{"epoch": 2, "training_loss": 728.9553260803223, "training_acc": 28.0, "val_loss": 97.9479432106018, "val_acc": 72.0}
{"epoch": 3, "training_loss": 516.2091445922852, "training_acc": 72.0, "val_loss": 217.70265102386475, "val_acc": 72.0}
{"epoch": 4, "training_loss": 852.3991985321045, "training_acc": 72.0, "val_loss": 153.15322875976562, "val_acc": 72.0}
{"epoch": 5, "training_loss": 481.64303970336914, "training_acc": 72.0, "val_loss": 70.14341354370117, "val_acc": 28.0}
{"epoch": 6, "training_loss": 304.3051166534424, "training_acc": 28.0, "val_loss": 42.76575446128845, "val_acc": 72.0}
{"epoch": 7, "training_loss": 224.69219970703125, "training_acc": 72.0, "val_loss": 84.06065106391907, "val_acc": 72.0}
{"epoch": 8, "training_loss": 297.7460117340088, "training_acc": 72.0, "val_loss": 15.34690111875534, "val_acc": 32.0}
{"epoch": 9, "training_loss": 145.17167854309082, "training_acc": 60.0, "val_loss": 14.739122986793518, "val_acc": 72.0}
{"epoch": 10, "training_loss": 102.90783548355103, "training_acc": 72.0, "val_loss": 42.456987500190735, "val_acc": 72.0}
{"epoch": 11, "training_loss": 133.39483284950256, "training_acc": 72.0, "val_loss": 73.56657385826111, "val_acc": 28.0}
{"epoch": 12, "training_loss": 202.05837178230286, "training_acc": 48.0, "val_loss": 50.07694363594055, "val_acc": 72.0}
{"epoch": 13, "training_loss": 217.2276086807251, "training_acc": 72.0, "val_loss": 49.96748864650726, "val_acc": 72.0}
{"epoch": 14, "training_loss": 137.38542866706848, "training_acc": 72.0, "val_loss": 111.64350509643555, "val_acc": 28.0}
{"epoch": 15, "training_loss": 386.75984477996826, "training_acc": 28.0, "val_loss": 61.79073452949524, "val_acc": 72.0}
{"epoch": 16, "training_loss": 307.9729747772217, "training_acc": 72.0, "val_loss": 141.98148250579834, "val_acc": 72.0}
{"epoch": 17, "training_loss": 561.3166790008545, "training_acc": 72.0, "val_loss": 109.85373258590698, "val_acc": 72.0}
{"epoch": 18, "training_loss": 371.38631534576416, "training_acc": 72.0, "val_loss": 41.24688506126404, "val_acc": 28.0}
{"epoch": 19, "training_loss": 166.03089952468872, "training_acc": 28.0, "val_loss": 35.25998294353485, "val_acc": 72.0}
{"epoch": 20, "training_loss": 146.75680899620056, "training_acc": 72.0, "val_loss": 45.1656699180603, "val_acc": 72.0}
{"epoch": 21, "training_loss": 141.74977207183838, "training_acc": 72.0, "val_loss": 72.38470315933228, "val_acc": 28.0}
{"epoch": 22, "training_loss": 221.95813846588135, "training_acc": 28.0, "val_loss": 70.26620507240295, "val_acc": 72.0}
{"epoch": 23, "training_loss": 359.2498779296875, "training_acc": 72.0, "val_loss": 136.56384944915771, "val_acc": 72.0}
{"epoch": 24, "training_loss": 529.6944484710693, "training_acc": 72.0, "val_loss": 87.93066143989563, "val_acc": 72.0}
{"epoch": 25, "training_loss": 273.04067969322205, "training_acc": 72.0, "val_loss": 131.51971101760864, "val_acc": 28.0}
{"epoch": 26, "training_loss": 507.5082998275757, "training_acc": 28.0, "val_loss": 17.226894199848175, "val_acc": 72.0}
{"epoch": 27, "training_loss": 134.85827732086182, "training_acc": 72.0, "val_loss": 61.34796142578125, "val_acc": 72.0}
{"epoch": 28, "training_loss": 216.44057655334473, "training_acc": 72.0, "val_loss": 21.801944077014923, "val_acc": 28.0}
