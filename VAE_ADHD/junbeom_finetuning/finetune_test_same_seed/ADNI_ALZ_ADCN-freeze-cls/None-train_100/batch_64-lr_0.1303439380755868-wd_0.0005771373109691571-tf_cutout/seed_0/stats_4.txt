"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 658.9676170349121, "training_acc": 42.0, "val_loss": 345.71287631988525, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1125.3002681732178, "training_acc": 72.0, "val_loss": 136.74416542053223, "val_acc": 28.0}
{"epoch": 2, "training_loss": 399.7558264732361, "training_acc": 28.0, "val_loss": 130.10656833648682, "val_acc": 72.0}
{"epoch": 3, "training_loss": 625.0000457763672, "training_acc": 72.0, "val_loss": 219.4629430770874, "val_acc": 72.0}
{"epoch": 4, "training_loss": 834.4522132873535, "training_acc": 72.0, "val_loss": 121.16353511810303, "val_acc": 72.0}
{"epoch": 5, "training_loss": 366.0041091442108, "training_acc": 72.0, "val_loss": 247.55024909973145, "val_acc": 28.0}
{"epoch": 6, "training_loss": 958.2894668579102, "training_acc": 28.0, "val_loss": 16.93490892648697, "val_acc": 28.0}
{"epoch": 7, "training_loss": 280.4654769897461, "training_acc": 72.0, "val_loss": 161.10398769378662, "val_acc": 72.0}
{"epoch": 8, "training_loss": 656.3636150360107, "training_acc": 72.0, "val_loss": 155.72357177734375, "val_acc": 72.0}
{"epoch": 9, "training_loss": 562.9645223617554, "training_acc": 72.0, "val_loss": 39.20086622238159, "val_acc": 72.0}
{"epoch": 10, "training_loss": 302.6225757598877, "training_acc": 56.0, "val_loss": 149.93717670440674, "val_acc": 28.0}
{"epoch": 11, "training_loss": 369.9155237674713, "training_acc": 52.0, "val_loss": 80.49560189247131, "val_acc": 72.0}
{"epoch": 12, "training_loss": 358.52746963500977, "training_acc": 72.0, "val_loss": 130.17678260803223, "val_acc": 72.0}
{"epoch": 13, "training_loss": 497.692964553833, "training_acc": 72.0, "val_loss": 70.39313316345215, "val_acc": 72.0}
{"epoch": 14, "training_loss": 249.98403143882751, "training_acc": 48.0, "val_loss": 67.38181710243225, "val_acc": 28.0}
{"epoch": 15, "training_loss": 203.98218965530396, "training_acc": 44.0, "val_loss": 40.9919410943985, "val_acc": 72.0}
{"epoch": 16, "training_loss": 153.12385177612305, "training_acc": 72.0, "val_loss": 20.736022293567657, "val_acc": 28.0}
{"epoch": 17, "training_loss": 83.84030055999756, "training_acc": 28.0, "val_loss": 31.625324487686157, "val_acc": 72.0}
{"epoch": 18, "training_loss": 140.1878457069397, "training_acc": 72.0, "val_loss": 17.02280342578888, "val_acc": 72.0}
{"epoch": 19, "training_loss": 98.93146657943726, "training_acc": 64.0, "val_loss": 14.702817797660828, "val_acc": 72.0}
{"epoch": 20, "training_loss": 71.40403437614441, "training_acc": 72.0, "val_loss": 26.671361923217773, "val_acc": 72.0}
{"epoch": 21, "training_loss": 95.12210202217102, "training_acc": 56.0, "val_loss": 16.02751314640045, "val_acc": 28.0}
{"epoch": 22, "training_loss": 68.41839957237244, "training_acc": 72.0, "val_loss": 17.997893691062927, "val_acc": 72.0}
{"epoch": 23, "training_loss": 99.77715539932251, "training_acc": 52.0, "val_loss": 28.31319272518158, "val_acc": 72.0}
{"epoch": 24, "training_loss": 112.11448729038239, "training_acc": 72.0, "val_loss": 17.455127835273743, "val_acc": 72.0}
{"epoch": 25, "training_loss": 90.44169855117798, "training_acc": 58.0, "val_loss": 21.706843376159668, "val_acc": 72.0}
{"epoch": 26, "training_loss": 96.1102523803711, "training_acc": 72.0, "val_loss": 15.230508148670197, "val_acc": 56.0}
{"epoch": 27, "training_loss": 68.12007093429565, "training_acc": 60.0, "val_loss": 23.258551955223083, "val_acc": 72.0}
{"epoch": 28, "training_loss": 90.74734115600586, "training_acc": 72.0, "val_loss": 23.175644874572754, "val_acc": 28.0}
{"epoch": 29, "training_loss": 88.75318217277527, "training_acc": 42.0, "val_loss": 16.21236801147461, "val_acc": 72.0}
{"epoch": 30, "training_loss": 58.701003551483154, "training_acc": 72.0, "val_loss": 17.762799561023712, "val_acc": 28.0}
{"epoch": 31, "training_loss": 101.5010232925415, "training_acc": 38.0, "val_loss": 20.670688152313232, "val_acc": 72.0}
{"epoch": 32, "training_loss": 121.24163246154785, "training_acc": 54.0, "val_loss": 24.311107397079468, "val_acc": 72.0}
{"epoch": 33, "training_loss": 100.58973336219788, "training_acc": 72.0, "val_loss": 16.04219228029251, "val_acc": 72.0}
{"epoch": 34, "training_loss": 115.21093845367432, "training_acc": 54.0, "val_loss": 28.452759981155396, "val_acc": 72.0}
{"epoch": 35, "training_loss": 147.47831058502197, "training_acc": 72.0, "val_loss": 25.02475380897522, "val_acc": 72.0}
{"epoch": 36, "training_loss": 162.97668552398682, "training_acc": 54.0, "val_loss": 14.781035482883453, "val_acc": 72.0}
{"epoch": 37, "training_loss": 74.38535690307617, "training_acc": 72.0, "val_loss": 26.45791471004486, "val_acc": 72.0}
{"epoch": 38, "training_loss": 127.3256459236145, "training_acc": 50.0, "val_loss": 23.572060465812683, "val_acc": 72.0}
