"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 66.55291247367859, "training_acc": 72.0, "val_loss": 15.32779186964035, "val_acc": 72.0}
{"epoch": 1, "training_loss": 61.50473117828369, "training_acc": 72.0, "val_loss": 14.907990396022797, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.5646812915802, "training_acc": 72.0, "val_loss": 15.172550082206726, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61.07355713844299, "training_acc": 72.0, "val_loss": 15.122808516025543, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.064743995666504, "training_acc": 72.0, "val_loss": 14.836938679218292, "val_acc": 72.0}
{"epoch": 5, "training_loss": 59.0717716217041, "training_acc": 72.0, "val_loss": 15.12087732553482, "val_acc": 72.0}
{"epoch": 6, "training_loss": 60.69358825683594, "training_acc": 72.0, "val_loss": 15.110372006893158, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.931063413619995, "training_acc": 72.0, "val_loss": 14.814737439155579, "val_acc": 72.0}
{"epoch": 8, "training_loss": 58.805858850479126, "training_acc": 72.0, "val_loss": 15.173642337322235, "val_acc": 72.0}
{"epoch": 9, "training_loss": 60.703704595565796, "training_acc": 72.0, "val_loss": 15.273633599281311, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.65376663208008, "training_acc": 72.0, "val_loss": 14.848794043064117, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.817586183547974, "training_acc": 72.0, "val_loss": 14.976699650287628, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.83770728111267, "training_acc": 72.0, "val_loss": 15.019544959068298, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.98084807395935, "training_acc": 72.0, "val_loss": 14.85813856124878, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.02190399169922, "training_acc": 72.0, "val_loss": 14.873546361923218, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.45187211036682, "training_acc": 72.0, "val_loss": 14.87366110086441, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.33675503730774, "training_acc": 72.0, "val_loss": 14.811225235462189, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.05824828147888, "training_acc": 72.0, "val_loss": 14.875669777393341, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.824936866760254, "training_acc": 72.0, "val_loss": 14.964412152767181, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.71013951301575, "training_acc": 72.0, "val_loss": 14.815327525138855, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.70655632019043, "training_acc": 72.0, "val_loss": 14.845918118953705, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.31572961807251, "training_acc": 72.0, "val_loss": 14.812219142913818, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.110007524490356, "training_acc": 72.0, "val_loss": 14.854918420314789, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.51439595222473, "training_acc": 72.0, "val_loss": 14.862924814224243, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.24907445907593, "training_acc": 72.0, "val_loss": 14.812563359737396, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.11477756500244, "training_acc": 72.0, "val_loss": 14.870665967464447, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.382665157318115, "training_acc": 72.0, "val_loss": 14.84534740447998, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.168172121047974, "training_acc": 72.0, "val_loss": 14.810284972190857, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.052191734313965, "training_acc": 72.0, "val_loss": 14.88054245710373, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.40581250190735, "training_acc": 72.0, "val_loss": 14.863009750843048, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.675434589385986, "training_acc": 72.0, "val_loss": 14.805343747138977, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.09219551086426, "training_acc": 72.0, "val_loss": 14.805030822753906, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.21062445640564, "training_acc": 72.0, "val_loss": 14.810217916965485, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.40149974822998, "training_acc": 72.0, "val_loss": 14.860133826732635, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.40756058692932, "training_acc": 72.0, "val_loss": 14.804638922214508, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.0944664478302, "training_acc": 72.0, "val_loss": 14.804613590240479, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.12580466270447, "training_acc": 72.0, "val_loss": 14.803460240364075, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.010422468185425, "training_acc": 72.0, "val_loss": 14.838357269763947, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.31354093551636, "training_acc": 72.0, "val_loss": 14.86111730337143, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.4200394153595, "training_acc": 72.0, "val_loss": 14.801345765590668, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.12403988838196, "training_acc": 72.0, "val_loss": 14.810174703598022, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.018375635147095, "training_acc": 72.0, "val_loss": 14.862516522407532, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.527549028396606, "training_acc": 72.0, "val_loss": 14.81507271528244, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.89606595039368, "training_acc": 72.0, "val_loss": 14.89684283733368, "val_acc": 72.0}
{"epoch": 44, "training_loss": 60.03856372833252, "training_acc": 72.0, "val_loss": 14.95094895362854, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.80373001098633, "training_acc": 72.0, "val_loss": 14.80964869260788, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.982320070266724, "training_acc": 72.0, "val_loss": 14.874543249607086, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.58505725860596, "training_acc": 72.0, "val_loss": 14.833630621433258, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.15553283691406, "training_acc": 72.0, "val_loss": 14.81606513261795, "val_acc": 72.0}
{"epoch": 49, "training_loss": 58.89445877075195, "training_acc": 72.0, "val_loss": 14.81674313545227, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.106826066970825, "training_acc": 72.0, "val_loss": 14.91561233997345, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.45271325111389, "training_acc": 72.0, "val_loss": 14.817723631858826, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.74265265464783, "training_acc": 72.0, "val_loss": 14.896093308925629, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.32481551170349, "training_acc": 72.0, "val_loss": 15.14355093240738, "val_acc": 72.0}
{"epoch": 54, "training_loss": 60.22142696380615, "training_acc": 72.0, "val_loss": 14.846351742744446, "val_acc": 72.0}
{"epoch": 55, "training_loss": 58.87309432029724, "training_acc": 72.0, "val_loss": 14.947141706943512, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.48869860172272, "training_acc": 72.0, "val_loss": 15.110284090042114, "val_acc": 72.0}
{"epoch": 57, "training_loss": 60.148053884506226, "training_acc": 72.0, "val_loss": 14.894358813762665, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.16660022735596, "training_acc": 72.0, "val_loss": 14.9038165807724, "val_acc": 72.0}
