"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 11654.04097366333, "training_acc": 72.0, "val_loss": 2906.546974182129, "val_acc": 72.0}
{"epoch": 1, "training_loss": 18584.469116210938, "training_acc": 60.0, "val_loss": 5409.437561035156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 16389.19482421875, "training_acc": 44.0, "val_loss": 4005.111312866211, "val_acc": 72.0}
{"epoch": 3, "training_loss": 17260.63702392578, "training_acc": 72.0, "val_loss": 4488.126754760742, "val_acc": 72.0}
{"epoch": 4, "training_loss": 15752.343078613281, "training_acc": 72.0, "val_loss": 1266.6322708129883, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7090.029266357422, "training_acc": 62.0, "val_loss": 4343.34716796875, "val_acc": 28.0}
{"epoch": 6, "training_loss": 11789.599708557129, "training_acc": 28.0, "val_loss": 2643.2796478271484, "val_acc": 72.0}
{"epoch": 7, "training_loss": 12391.99609375, "training_acc": 72.0, "val_loss": 5674.405670166016, "val_acc": 72.0}
{"epoch": 8, "training_loss": 23162.76190185547, "training_acc": 72.0, "val_loss": 5874.209976196289, "val_acc": 72.0}
{"epoch": 9, "training_loss": 22110.121826171875, "training_acc": 72.0, "val_loss": 3710.4564666748047, "val_acc": 72.0}
{"epoch": 10, "training_loss": 12329.14778137207, "training_acc": 72.0, "val_loss": 1421.6537475585938, "val_acc": 28.0}
{"epoch": 11, "training_loss": 7897.023101806641, "training_acc": 28.0, "val_loss": 117.08626747131348, "val_acc": 32.0}
{"epoch": 12, "training_loss": 2400.9639434814453, "training_acc": 52.0, "val_loss": 3672.696304321289, "val_acc": 72.0}
{"epoch": 13, "training_loss": 15695.384155273438, "training_acc": 72.0, "val_loss": 4767.9443359375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 18533.066528320312, "training_acc": 72.0, "val_loss": 3583.941650390625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 12105.47817993164, "training_acc": 72.0, "val_loss": 357.804012298584, "val_acc": 72.0}
{"epoch": 16, "training_loss": 9351.739074707031, "training_acc": 48.0, "val_loss": 6204.989242553711, "val_acc": 28.0}
{"epoch": 17, "training_loss": 21359.814392089844, "training_acc": 28.0, "val_loss": 561.7823123931885, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4239.646545410156, "training_acc": 72.0, "val_loss": 2792.9277420043945, "val_acc": 72.0}
{"epoch": 19, "training_loss": 11673.787414550781, "training_acc": 72.0, "val_loss": 2634.327507019043, "val_acc": 72.0}
{"epoch": 20, "training_loss": 9204.565475463867, "training_acc": 72.0, "val_loss": 287.4367952346802, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4994.755584716797, "training_acc": 62.0, "val_loss": 4225.440216064453, "val_acc": 28.0}
{"epoch": 22, "training_loss": 13147.55404663086, "training_acc": 28.0, "val_loss": 1538.227367401123, "val_acc": 72.0}
{"epoch": 23, "training_loss": 8494.395690917969, "training_acc": 72.0, "val_loss": 3903.476333618164, "val_acc": 72.0}
{"epoch": 24, "training_loss": 15966.092102050781, "training_acc": 72.0, "val_loss": 3819.271469116211, "val_acc": 72.0}
{"epoch": 25, "training_loss": 13871.471252441406, "training_acc": 72.0, "val_loss": 1662.2993469238281, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4948.758241653442, "training_acc": 56.0, "val_loss": 1099.1424560546875, "val_acc": 28.0}
{"epoch": 27, "training_loss": 4049.89884185791, "training_acc": 38.0, "val_loss": 854.8280715942383, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2967.4377250671387, "training_acc": 72.0, "val_loss": 278.5926818847656, "val_acc": 32.0}
{"epoch": 29, "training_loss": 1227.134708404541, "training_acc": 51.0, "val_loss": 546.6816902160645, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1552.290937423706, "training_acc": 72.0, "val_loss": 1375.3387451171875, "val_acc": 28.0}
