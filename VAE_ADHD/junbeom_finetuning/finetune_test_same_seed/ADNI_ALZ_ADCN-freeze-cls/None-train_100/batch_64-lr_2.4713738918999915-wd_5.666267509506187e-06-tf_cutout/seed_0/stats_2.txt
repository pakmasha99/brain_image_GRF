"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 11627.43814086914, "training_acc": 42.0, "val_loss": 7684.986114501953, "val_acc": 72.0}
{"epoch": 1, "training_loss": 27233.056884765625, "training_acc": 72.0, "val_loss": 2253.1436920166016, "val_acc": 72.0}
{"epoch": 2, "training_loss": 12943.871337890625, "training_acc": 58.0, "val_loss": 5532.940292358398, "val_acc": 28.0}
{"epoch": 3, "training_loss": 13780.857940673828, "training_acc": 28.0, "val_loss": 3366.320037841797, "val_acc": 72.0}
{"epoch": 4, "training_loss": 18915.266967773438, "training_acc": 72.0, "val_loss": 7165.519714355469, "val_acc": 72.0}
{"epoch": 5, "training_loss": 29367.082397460938, "training_acc": 72.0, "val_loss": 7301.902008056641, "val_acc": 72.0}
{"epoch": 6, "training_loss": 27734.872436523438, "training_acc": 72.0, "val_loss": 4957.108688354492, "val_acc": 72.0}
{"epoch": 7, "training_loss": 16991.717834472656, "training_acc": 72.0, "val_loss": 694.7625637054443, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8520.313598632812, "training_acc": 58.0, "val_loss": 7136.77978515625, "val_acc": 28.0}
{"epoch": 9, "training_loss": 26228.375122070312, "training_acc": 28.0, "val_loss": 915.5826568603516, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5251.170562744141, "training_acc": 46.0, "val_loss": 4298.115158081055, "val_acc": 72.0}
{"epoch": 11, "training_loss": 18720.018310546875, "training_acc": 72.0, "val_loss": 6255.958938598633, "val_acc": 72.0}
{"epoch": 12, "training_loss": 25103.902221679688, "training_acc": 72.0, "val_loss": 5995.254898071289, "val_acc": 72.0}
{"epoch": 13, "training_loss": 22751.388305664062, "training_acc": 72.0, "val_loss": 3855.649185180664, "val_acc": 72.0}
{"epoch": 14, "training_loss": 12770.294036865234, "training_acc": 72.0, "val_loss": 216.318678855896, "val_acc": 72.0}
{"epoch": 15, "training_loss": 8609.530487060547, "training_acc": 54.0, "val_loss": 7351.161956787109, "val_acc": 28.0}
{"epoch": 16, "training_loss": 27350.712768554688, "training_acc": 28.0, "val_loss": 1819.3572998046875, "val_acc": 28.0}
{"epoch": 17, "training_loss": 6154.458312988281, "training_acc": 50.0, "val_loss": 3806.189727783203, "val_acc": 72.0}
{"epoch": 18, "training_loss": 17217.79071044922, "training_acc": 72.0, "val_loss": 5874.898147583008, "val_acc": 72.0}
{"epoch": 19, "training_loss": 23488.02618408203, "training_acc": 72.0, "val_loss": 5715.985107421875, "val_acc": 72.0}
{"epoch": 20, "training_loss": 21696.667236328125, "training_acc": 72.0, "val_loss": 3839.754867553711, "val_acc": 72.0}
{"epoch": 21, "training_loss": 13414.868621826172, "training_acc": 72.0, "val_loss": 446.9996929168701, "val_acc": 72.0}
{"epoch": 22, "training_loss": 7361.50830078125, "training_acc": 54.0, "val_loss": 5979.094696044922, "val_acc": 28.0}
{"epoch": 23, "training_loss": 21741.73504638672, "training_acc": 28.0, "val_loss": 246.58746719360352, "val_acc": 32.0}
{"epoch": 24, "training_loss": 3078.699920654297, "training_acc": 50.0, "val_loss": 4579.276275634766, "val_acc": 72.0}
{"epoch": 25, "training_loss": 20075.421936035156, "training_acc": 72.0, "val_loss": 6788.37890625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 27479.055541992188, "training_acc": 72.0, "val_loss": 6820.687103271484, "val_acc": 72.0}
{"epoch": 27, "training_loss": 26094.49298095703, "training_acc": 72.0, "val_loss": 4961.817169189453, "val_acc": 72.0}
{"epoch": 28, "training_loss": 17851.844787597656, "training_acc": 72.0, "val_loss": 1662.6312255859375, "val_acc": 72.0}
{"epoch": 29, "training_loss": 6084.304946899414, "training_acc": 54.0, "val_loss": 2675.151252746582, "val_acc": 28.0}
{"epoch": 30, "training_loss": 8453.331588745117, "training_acc": 28.0, "val_loss": 1263.522720336914, "val_acc": 72.0}
{"epoch": 31, "training_loss": 6796.588562011719, "training_acc": 72.0, "val_loss": 2905.1488876342773, "val_acc": 72.0}
{"epoch": 32, "training_loss": 11332.234497070312, "training_acc": 72.0, "val_loss": 2376.619529724121, "val_acc": 72.0}
{"epoch": 33, "training_loss": 7935.520217895508, "training_acc": 72.0, "val_loss": 152.59361267089844, "val_acc": 64.0}
{"epoch": 34, "training_loss": 5205.733306884766, "training_acc": 57.0, "val_loss": 3858.290481567383, "val_acc": 28.0}
{"epoch": 35, "training_loss": 11839.344284057617, "training_acc": 28.0, "val_loss": 1552.8915405273438, "val_acc": 72.0}
{"epoch": 36, "training_loss": 8411.460266113281, "training_acc": 72.0, "val_loss": 3690.0955200195312, "val_acc": 72.0}
{"epoch": 37, "training_loss": 14806.190368652344, "training_acc": 72.0, "val_loss": 3565.876007080078, "val_acc": 72.0}
{"epoch": 38, "training_loss": 13185.895065307617, "training_acc": 72.0, "val_loss": 1619.9710845947266, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3362.189624786377, "training_acc": 72.0, "val_loss": 3962.9993438720703, "val_acc": 28.0}
{"epoch": 40, "training_loss": 17707.33905029297, "training_acc": 28.0, "val_loss": 3411.239242553711, "val_acc": 28.0}
{"epoch": 41, "training_loss": 9300.786804199219, "training_acc": 44.0, "val_loss": 1614.546012878418, "val_acc": 72.0}
{"epoch": 42, "training_loss": 6736.786560058594, "training_acc": 72.0, "val_loss": 2279.372978210449, "val_acc": 72.0}
{"epoch": 43, "training_loss": 8257.312591552734, "training_acc": 72.0, "val_loss": 1129.1342735290527, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2249.6462173461914, "training_acc": 71.0, "val_loss": 1500.118637084961, "val_acc": 28.0}
{"epoch": 45, "training_loss": 4051.4463715553284, "training_acc": 43.0, "val_loss": 916.5713310241699, "val_acc": 72.0}
{"epoch": 46, "training_loss": 4043.393600463867, "training_acc": 72.0, "val_loss": 1053.0595779418945, "val_acc": 72.0}
{"epoch": 47, "training_loss": 2767.789966583252, "training_acc": 72.0, "val_loss": 1900.5298614501953, "val_acc": 28.0}
{"epoch": 48, "training_loss": 6826.471618652344, "training_acc": 28.0, "val_loss": 740.4626846313477, "val_acc": 72.0}
{"epoch": 49, "training_loss": 3389.6475219726562, "training_acc": 72.0, "val_loss": 1493.7548637390137, "val_acc": 72.0}
{"epoch": 50, "training_loss": 5144.2672119140625, "training_acc": 72.0, "val_loss": 339.0338897705078, "val_acc": 72.0}
{"epoch": 51, "training_loss": 3065.1700134277344, "training_acc": 60.0, "val_loss": 1554.483699798584, "val_acc": 28.0}
{"epoch": 52, "training_loss": 4235.719440460205, "training_acc": 48.0, "val_loss": 1335.6598854064941, "val_acc": 72.0}
