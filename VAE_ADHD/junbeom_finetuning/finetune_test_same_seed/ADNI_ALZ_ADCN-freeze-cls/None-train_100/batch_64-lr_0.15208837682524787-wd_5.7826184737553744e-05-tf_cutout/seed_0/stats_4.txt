"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 933.8557014465332, "training_acc": 42.0, "val_loss": 565.7444953918457, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1957.544075012207, "training_acc": 72.0, "val_loss": 122.14912176132202, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1067.352767944336, "training_acc": 58.0, "val_loss": 570.0236797332764, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1685.3621578216553, "training_acc": 28.0, "val_loss": 204.404616355896, "val_acc": 72.0}
{"epoch": 4, "training_loss": 927.7023029327393, "training_acc": 72.0, "val_loss": 476.3697624206543, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1952.153579711914, "training_acc": 72.0, "val_loss": 515.8714294433594, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1977.7534408569336, "training_acc": 72.0, "val_loss": 361.97428703308105, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1200.3849029541016, "training_acc": 72.0, "val_loss": 56.334179639816284, "val_acc": 72.0}
{"epoch": 8, "training_loss": 748.2212600708008, "training_acc": 52.0, "val_loss": 523.0990886688232, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1878.4353942871094, "training_acc": 28.0, "val_loss": 22.866393625736237, "val_acc": 28.0}
{"epoch": 10, "training_loss": 348.2491264343262, "training_acc": 42.0, "val_loss": 318.4093475341797, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1377.9659576416016, "training_acc": 72.0, "val_loss": 433.705997467041, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1714.178726196289, "training_acc": 72.0, "val_loss": 380.2988290786743, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1395.90185546875, "training_acc": 72.0, "val_loss": 191.67276620864868, "val_acc": 72.0}
{"epoch": 14, "training_loss": 558.9902420043945, "training_acc": 72.0, "val_loss": 286.791467666626, "val_acc": 28.0}
{"epoch": 15, "training_loss": 1258.2738151550293, "training_acc": 28.0, "val_loss": 274.9234676361084, "val_acc": 28.0}
{"epoch": 16, "training_loss": 790.340126991272, "training_acc": 38.0, "val_loss": 101.68683528900146, "val_acc": 72.0}
{"epoch": 17, "training_loss": 449.17249488830566, "training_acc": 72.0, "val_loss": 131.83038234710693, "val_acc": 72.0}
{"epoch": 18, "training_loss": 454.12522315979004, "training_acc": 72.0, "val_loss": 19.27974224090576, "val_acc": 72.0}
{"epoch": 19, "training_loss": 414.5442886352539, "training_acc": 50.0, "val_loss": 198.27831983566284, "val_acc": 28.0}
{"epoch": 20, "training_loss": 484.1842371225357, "training_acc": 52.0, "val_loss": 95.99468111991882, "val_acc": 72.0}
{"epoch": 21, "training_loss": 448.67105293273926, "training_acc": 72.0, "val_loss": 142.63715744018555, "val_acc": 72.0}
{"epoch": 22, "training_loss": 513.4613466262817, "training_acc": 72.0, "val_loss": 38.450390100479126, "val_acc": 72.0}
{"epoch": 23, "training_loss": 367.17419052124023, "training_acc": 50.0, "val_loss": 127.20456123352051, "val_acc": 28.0}
{"epoch": 24, "training_loss": 391.3729863166809, "training_acc": 44.0, "val_loss": 99.37528967857361, "val_acc": 72.0}
{"epoch": 25, "training_loss": 407.2425079345703, "training_acc": 72.0, "val_loss": 88.46487402915955, "val_acc": 72.0}
{"epoch": 26, "training_loss": 248.82521772384644, "training_acc": 72.0, "val_loss": 133.77201557159424, "val_acc": 28.0}
{"epoch": 27, "training_loss": 516.0778217315674, "training_acc": 28.0, "val_loss": 46.22455537319183, "val_acc": 72.0}
{"epoch": 28, "training_loss": 258.5027847290039, "training_acc": 72.0, "val_loss": 108.50987434387207, "val_acc": 72.0}
{"epoch": 29, "training_loss": 384.0444641113281, "training_acc": 72.0, "val_loss": 21.27958983182907, "val_acc": 72.0}
{"epoch": 30, "training_loss": 253.8149871826172, "training_acc": 58.0, "val_loss": 109.44664478302002, "val_acc": 28.0}
{"epoch": 31, "training_loss": 388.3209743499756, "training_acc": 40.0, "val_loss": 109.30490493774414, "val_acc": 72.0}
{"epoch": 32, "training_loss": 431.8659334182739, "training_acc": 72.0, "val_loss": 94.51519846916199, "val_acc": 72.0}
{"epoch": 33, "training_loss": 295.58821392059326, "training_acc": 72.0, "val_loss": 99.64004158973694, "val_acc": 28.0}
{"epoch": 34, "training_loss": 356.12537479400635, "training_acc": 28.0, "val_loss": 71.33433222770691, "val_acc": 72.0}
{"epoch": 35, "training_loss": 341.41269302368164, "training_acc": 72.0, "val_loss": 139.42497968673706, "val_acc": 72.0}
{"epoch": 36, "training_loss": 516.0213861465454, "training_acc": 72.0, "val_loss": 61.52830719947815, "val_acc": 72.0}
{"epoch": 37, "training_loss": 173.8781156539917, "training_acc": 62.0, "val_loss": 50.906550884246826, "val_acc": 28.0}
