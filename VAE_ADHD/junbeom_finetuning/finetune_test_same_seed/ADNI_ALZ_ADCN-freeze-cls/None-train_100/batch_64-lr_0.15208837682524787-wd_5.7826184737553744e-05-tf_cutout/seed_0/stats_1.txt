"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 567.1716842651367, "training_acc": 72.0, "val_loss": 309.7153663635254, "val_acc": 72.0}
{"epoch": 1, "training_loss": 810.1236610412598, "training_acc": 72.0, "val_loss": 566.3868427276611, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2115.13045501709, "training_acc": 28.0, "val_loss": 94.49282884597778, "val_acc": 28.0}
{"epoch": 3, "training_loss": 606.5763168334961, "training_acc": 38.0, "val_loss": 330.7364225387573, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1457.683853149414, "training_acc": 72.0, "val_loss": 444.74358558654785, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1748.4088287353516, "training_acc": 72.0, "val_loss": 381.9556713104248, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1403.6674194335938, "training_acc": 72.0, "val_loss": 189.90342617034912, "val_acc": 72.0}
{"epoch": 7, "training_loss": 620.4848046302795, "training_acc": 72.0, "val_loss": 248.38902950286865, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1129.2929229736328, "training_acc": 28.0, "val_loss": 245.62804698944092, "val_acc": 28.0}
{"epoch": 9, "training_loss": 578.9076346158981, "training_acc": 52.0, "val_loss": 112.80524730682373, "val_acc": 72.0}
{"epoch": 10, "training_loss": 552.229377746582, "training_acc": 72.0, "val_loss": 209.47494506835938, "val_acc": 72.0}
{"epoch": 11, "training_loss": 828.7038192749023, "training_acc": 72.0, "val_loss": 172.11573123931885, "val_acc": 72.0}
{"epoch": 12, "training_loss": 579.6926517486572, "training_acc": 72.0, "val_loss": 25.62299370765686, "val_acc": 72.0}
{"epoch": 13, "training_loss": 323.2637004852295, "training_acc": 60.0, "val_loss": 260.41693687438965, "val_acc": 28.0}
{"epoch": 14, "training_loss": 844.40061378479, "training_acc": 28.0, "val_loss": 57.30973482131958, "val_acc": 72.0}
{"epoch": 15, "training_loss": 333.4953155517578, "training_acc": 72.0, "val_loss": 172.37545251846313, "val_acc": 72.0}
{"epoch": 16, "training_loss": 694.9468860626221, "training_acc": 72.0, "val_loss": 160.46979427337646, "val_acc": 72.0}
{"epoch": 17, "training_loss": 578.060956954956, "training_acc": 72.0, "val_loss": 45.727333426475525, "val_acc": 72.0}
{"epoch": 18, "training_loss": 252.87904834747314, "training_acc": 58.0, "val_loss": 133.77156257629395, "val_acc": 28.0}
{"epoch": 19, "training_loss": 402.9341118335724, "training_acc": 34.0, "val_loss": 45.56252956390381, "val_acc": 72.0}
{"epoch": 20, "training_loss": 187.2918405532837, "training_acc": 72.0, "val_loss": 27.827316522598267, "val_acc": 72.0}
{"epoch": 21, "training_loss": 117.35202026367188, "training_acc": 60.0, "val_loss": 16.240879893302917, "val_acc": 36.0}
{"epoch": 22, "training_loss": 63.680379152297974, "training_acc": 73.0, "val_loss": 36.41948699951172, "val_acc": 72.0}
{"epoch": 23, "training_loss": 128.43251764774323, "training_acc": 72.0, "val_loss": 33.34539830684662, "val_acc": 28.0}
{"epoch": 24, "training_loss": 128.60202264785767, "training_acc": 40.0, "val_loss": 25.397783517837524, "val_acc": 72.0}
{"epoch": 25, "training_loss": 81.8492169380188, "training_acc": 73.0, "val_loss": 27.741089463233948, "val_acc": 28.0}
{"epoch": 26, "training_loss": 100.765052318573, "training_acc": 46.0, "val_loss": 33.445778489112854, "val_acc": 72.0}
{"epoch": 27, "training_loss": 112.76023530960083, "training_acc": 72.0, "val_loss": 40.61741232872009, "val_acc": 28.0}
{"epoch": 28, "training_loss": 133.1323163509369, "training_acc": 42.0, "val_loss": 27.707073092460632, "val_acc": 72.0}
{"epoch": 29, "training_loss": 107.44486975669861, "training_acc": 66.0, "val_loss": 13.983473181724548, "val_acc": 60.0}
{"epoch": 30, "training_loss": 64.22159814834595, "training_acc": 73.0, "val_loss": 14.5480215549469, "val_acc": 56.0}
{"epoch": 31, "training_loss": 57.48097610473633, "training_acc": 76.0, "val_loss": 16.92940890789032, "val_acc": 72.0}
{"epoch": 32, "training_loss": 62.37118864059448, "training_acc": 72.0, "val_loss": 18.444640934467316, "val_acc": 36.0}
{"epoch": 33, "training_loss": 90.19054079055786, "training_acc": 54.0, "val_loss": 15.007930994033813, "val_acc": 72.0}
{"epoch": 34, "training_loss": 92.37766313552856, "training_acc": 54.0, "val_loss": 25.58194398880005, "val_acc": 72.0}
{"epoch": 35, "training_loss": 106.06967949867249, "training_acc": 72.0, "val_loss": 15.401196479797363, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.76094651222229, "training_acc": 68.0, "val_loss": 13.678696751594543, "val_acc": 68.0}
{"epoch": 37, "training_loss": 71.762526512146, "training_acc": 74.0, "val_loss": 15.235668420791626, "val_acc": 72.0}
{"epoch": 38, "training_loss": 80.11106872558594, "training_acc": 58.0, "val_loss": 20.94414234161377, "val_acc": 72.0}
{"epoch": 39, "training_loss": 87.26226830482483, "training_acc": 72.0, "val_loss": 15.318693220615387, "val_acc": 56.0}
{"epoch": 40, "training_loss": 61.15082669258118, "training_acc": 64.0, "val_loss": 16.773368418216705, "val_acc": 40.0}
{"epoch": 41, "training_loss": 68.505042552948, "training_acc": 67.0, "val_loss": 17.134326696395874, "val_acc": 72.0}
{"epoch": 42, "training_loss": 73.1933822631836, "training_acc": 58.0, "val_loss": 17.77540147304535, "val_acc": 72.0}
{"epoch": 43, "training_loss": 67.67501044273376, "training_acc": 72.0, "val_loss": 13.648243248462677, "val_acc": 68.0}
{"epoch": 44, "training_loss": 56.76813340187073, "training_acc": 72.0, "val_loss": 19.60180550813675, "val_acc": 36.0}
{"epoch": 45, "training_loss": 93.3016266822815, "training_acc": 53.0, "val_loss": 15.144550800323486, "val_acc": 72.0}
{"epoch": 46, "training_loss": 107.5559983253479, "training_acc": 52.0, "val_loss": 29.3523907661438, "val_acc": 72.0}
{"epoch": 47, "training_loss": 143.34472560882568, "training_acc": 72.0, "val_loss": 22.26756364107132, "val_acc": 72.0}
{"epoch": 48, "training_loss": 136.3516387939453, "training_acc": 58.0, "val_loss": 13.49639892578125, "val_acc": 64.0}
{"epoch": 49, "training_loss": 83.62170791625977, "training_acc": 74.0, "val_loss": 31.170299649238586, "val_acc": 72.0}
{"epoch": 50, "training_loss": 121.06168794631958, "training_acc": 56.0, "val_loss": 14.118552207946777, "val_acc": 80.0}
{"epoch": 51, "training_loss": 61.051265478134155, "training_acc": 72.0, "val_loss": 20.709536969661713, "val_acc": 36.0}
{"epoch": 52, "training_loss": 73.7288727760315, "training_acc": 52.0, "val_loss": 15.772594511508942, "val_acc": 72.0}
{"epoch": 53, "training_loss": 55.189605951309204, "training_acc": 78.0, "val_loss": 14.773444831371307, "val_acc": 56.0}
{"epoch": 54, "training_loss": 55.437114000320435, "training_acc": 74.0, "val_loss": 17.57228672504425, "val_acc": 72.0}
{"epoch": 55, "training_loss": 94.00141334533691, "training_acc": 50.0, "val_loss": 29.623404145240784, "val_acc": 72.0}
{"epoch": 56, "training_loss": 126.79672479629517, "training_acc": 72.0, "val_loss": 13.728685677051544, "val_acc": 76.0}
{"epoch": 57, "training_loss": 111.19349384307861, "training_acc": 57.0, "val_loss": 22.445973753929138, "val_acc": 72.0}
{"epoch": 58, "training_loss": 98.11865234375, "training_acc": 72.0, "val_loss": 17.434372007846832, "val_acc": 72.0}
{"epoch": 59, "training_loss": 135.24500274658203, "training_acc": 52.0, "val_loss": 22.355209290981293, "val_acc": 72.0}
{"epoch": 60, "training_loss": 90.0741274356842, "training_acc": 72.0, "val_loss": 18.698756396770477, "val_acc": 72.0}
{"epoch": 61, "training_loss": 102.38582849502563, "training_acc": 56.0, "val_loss": 22.327111661434174, "val_acc": 72.0}
{"epoch": 62, "training_loss": 89.52694845199585, "training_acc": 72.0, "val_loss": 13.534964621067047, "val_acc": 64.0}
{"epoch": 63, "training_loss": 74.79227924346924, "training_acc": 62.0, "val_loss": 32.91570842266083, "val_acc": 72.0}
{"epoch": 64, "training_loss": 144.47236490249634, "training_acc": 72.0, "val_loss": 18.179377913475037, "val_acc": 72.0}
{"epoch": 65, "training_loss": 148.36186695098877, "training_acc": 56.0, "val_loss": 13.433480262756348, "val_acc": 68.0}
{"epoch": 66, "training_loss": 81.69234704971313, "training_acc": 76.0, "val_loss": 38.08552920818329, "val_acc": 72.0}
{"epoch": 67, "training_loss": 109.08335947990417, "training_acc": 72.0, "val_loss": 65.26975631713867, "val_acc": 28.0}
{"epoch": 68, "training_loss": 170.6908233165741, "training_acc": 46.0, "val_loss": 37.08749711513519, "val_acc": 72.0}
{"epoch": 69, "training_loss": 129.7509481906891, "training_acc": 72.0, "val_loss": 29.619932174682617, "val_acc": 28.0}
{"epoch": 70, "training_loss": 108.69485116004944, "training_acc": 37.0, "val_loss": 13.639651238918304, "val_acc": 72.0}
{"epoch": 71, "training_loss": 62.57562708854675, "training_acc": 65.0, "val_loss": 24.111148715019226, "val_acc": 72.0}
{"epoch": 72, "training_loss": 88.52401304244995, "training_acc": 72.0, "val_loss": 20.2065572142601, "val_acc": 40.0}
{"epoch": 73, "training_loss": 65.40776801109314, "training_acc": 64.0, "val_loss": 16.5245458483696, "val_acc": 72.0}
{"epoch": 74, "training_loss": 58.3874409198761, "training_acc": 70.0, "val_loss": 14.045345783233643, "val_acc": 64.0}
{"epoch": 75, "training_loss": 52.161110401153564, "training_acc": 75.0, "val_loss": 14.767758548259735, "val_acc": 80.0}
{"epoch": 76, "training_loss": 63.40061831474304, "training_acc": 63.0, "val_loss": 20.40623426437378, "val_acc": 72.0}
{"epoch": 77, "training_loss": 71.98817813396454, "training_acc": 72.0, "val_loss": 20.294246077537537, "val_acc": 40.0}
{"epoch": 78, "training_loss": 81.60266947746277, "training_acc": 53.0, "val_loss": 18.654564023017883, "val_acc": 72.0}
{"epoch": 79, "training_loss": 60.4027054309845, "training_acc": 72.0, "val_loss": 17.032676935195923, "val_acc": 52.0}
{"epoch": 80, "training_loss": 66.91121792793274, "training_acc": 72.0, "val_loss": 21.595388650894165, "val_acc": 72.0}
{"epoch": 81, "training_loss": 90.91851377487183, "training_acc": 60.0, "val_loss": 17.587395012378693, "val_acc": 72.0}
{"epoch": 82, "training_loss": 65.51331305503845, "training_acc": 72.0, "val_loss": 18.57019066810608, "val_acc": 40.0}
{"epoch": 83, "training_loss": 59.694175004959106, "training_acc": 70.0, "val_loss": 17.251670360565186, "val_acc": 72.0}
{"epoch": 84, "training_loss": 62.25497102737427, "training_acc": 74.0, "val_loss": 13.523168861865997, "val_acc": 68.0}
