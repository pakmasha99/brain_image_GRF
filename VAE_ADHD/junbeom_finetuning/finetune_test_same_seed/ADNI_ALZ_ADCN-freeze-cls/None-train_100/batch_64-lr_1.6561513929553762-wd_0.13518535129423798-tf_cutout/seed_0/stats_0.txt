"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7845.059234619141, "training_acc": 42.0, "val_loss": 3161.0694885253906, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7761.085891723633, "training_acc": 72.0, "val_loss": 7345.644378662109, "val_acc": 28.0}
{"epoch": 2, "training_loss": 25262.122680664062, "training_acc": 28.0, "val_loss": 524.7793674468994, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3500.716018676758, "training_acc": 72.0, "val_loss": 1572.33304977417, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5496.760284423828, "training_acc": 72.0, "val_loss": 141.97527170181274, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5113.927947998047, "training_acc": 48.0, "val_loss": 1331.9254875183105, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4615.228775024414, "training_acc": 44.0, "val_loss": 1399.212646484375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5500.67138671875, "training_acc": 72.0, "val_loss": 950.4011154174805, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2819.015323638916, "training_acc": 72.0, "val_loss": 1342.1027183532715, "val_acc": 28.0}
{"epoch": 9, "training_loss": 4109.805847167969, "training_acc": 28.0, "val_loss": 940.1837348937988, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4411.893447875977, "training_acc": 72.0, "val_loss": 1357.718276977539, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4867.945587158203, "training_acc": 72.0, "val_loss": 336.9105100631714, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2712.971237182617, "training_acc": 54.0, "val_loss": 326.73394680023193, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1485.6687927246094, "training_acc": 52.0, "val_loss": 1321.8106269836426, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5326.339782714844, "training_acc": 72.0, "val_loss": 952.3402214050293, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2805.50984954834, "training_acc": 72.0, "val_loss": 1118.8066482543945, "val_acc": 28.0}
{"epoch": 16, "training_loss": 3414.598041534424, "training_acc": 28.0, "val_loss": 821.595287322998, "val_acc": 72.0}
{"epoch": 17, "training_loss": 3570.439208984375, "training_acc": 72.0, "val_loss": 1068.7299728393555, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3693.986297607422, "training_acc": 72.0, "val_loss": 115.28545618057251, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3277.4735412597656, "training_acc": 50.0, "val_loss": 930.073070526123, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3151.224510192871, "training_acc": 46.0, "val_loss": 1065.408706665039, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4295.049880981445, "training_acc": 72.0, "val_loss": 677.3857116699219, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1835.6713199615479, "training_acc": 72.0, "val_loss": 1729.9482345581055, "val_acc": 28.0}
{"epoch": 23, "training_loss": 5845.062484741211, "training_acc": 28.0, "val_loss": 612.0401859283447, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3004.5181427001953, "training_acc": 72.0, "val_loss": 954.1463851928711, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3273.5793838500977, "training_acc": 72.0, "val_loss": 20.582252740859985, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2591.795627593994, "training_acc": 54.0, "val_loss": 743.8164710998535, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2961.5913009643555, "training_acc": 44.0, "val_loss": 1152.304744720459, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4532.109390258789, "training_acc": 72.0, "val_loss": 756.3764095306396, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2222.548734664917, "training_acc": 72.0, "val_loss": 1308.798599243164, "val_acc": 28.0}
{"epoch": 30, "training_loss": 4163.216567993164, "training_acc": 28.0, "val_loss": 797.4413394927979, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4155.879577636719, "training_acc": 72.0, "val_loss": 1171.4839935302734, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4179.461685180664, "training_acc": 72.0, "val_loss": 162.00191974639893, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2792.0939025878906, "training_acc": 52.0, "val_loss": 615.2103900909424, "val_acc": 28.0}
{"epoch": 34, "training_loss": 3018.547866821289, "training_acc": 40.0, "val_loss": 1160.4208946228027, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4529.367904663086, "training_acc": 72.0, "val_loss": 706.1730861663818, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2049.551862716675, "training_acc": 72.0, "val_loss": 1524.9411582946777, "val_acc": 28.0}
{"epoch": 37, "training_loss": 4919.438018798828, "training_acc": 28.0, "val_loss": 702.2725582122803, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3350.0692749023438, "training_acc": 72.0, "val_loss": 936.6973876953125, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3076.291015625, "training_acc": 72.0, "val_loss": 175.23717880249023, "val_acc": 28.0}
{"epoch": 40, "training_loss": 942.010498046875, "training_acc": 40.0, "val_loss": 152.88681983947754, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1172.5634536743164, "training_acc": 58.0, "val_loss": 265.3970003128052, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1083.5359115600586, "training_acc": 72.0, "val_loss": 20.467282831668854, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1818.0246505737305, "training_acc": 52.0, "val_loss": 89.7994339466095, "val_acc": 72.0}
{"epoch": 44, "training_loss": 453.03542137145996, "training_acc": 72.0, "val_loss": 261.45970821380615, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1485.6706466674805, "training_acc": 42.0, "val_loss": 599.8636245727539, "val_acc": 72.0}
{"epoch": 46, "training_loss": 2068.961193084717, "training_acc": 72.0, "val_loss": 354.49070930480957, "val_acc": 28.0}
{"epoch": 47, "training_loss": 1563.051368713379, "training_acc": 40.0, "val_loss": 342.4792766571045, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1041.325087070465, "training_acc": 52.0, "val_loss": 460.50853729248047, "val_acc": 72.0}
{"epoch": 49, "training_loss": 1845.312759399414, "training_acc": 72.0, "val_loss": 185.74655055999756, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1937.7213439941406, "training_acc": 52.0, "val_loss": 120.65504789352417, "val_acc": 72.0}
{"epoch": 51, "training_loss": 492.9158000946045, "training_acc": 72.0, "val_loss": 353.22933197021484, "val_acc": 28.0}
{"epoch": 52, "training_loss": 1548.9493408203125, "training_acc": 44.0, "val_loss": 557.3497295379639, "val_acc": 72.0}
{"epoch": 53, "training_loss": 1935.0638484954834, "training_acc": 72.0, "val_loss": 404.9686908721924, "val_acc": 28.0}
{"epoch": 54, "training_loss": 1502.5295600891113, "training_acc": 44.0, "val_loss": 359.9423408508301, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1069.4116501808167, "training_acc": 72.0, "val_loss": 1096.4263916015625, "val_acc": 28.0}
{"epoch": 56, "training_loss": 2700.2111904621124, "training_acc": 48.0, "val_loss": 421.78473472595215, "val_acc": 72.0}
{"epoch": 57, "training_loss": 1620.5347061157227, "training_acc": 72.0, "val_loss": 74.40548539161682, "val_acc": 72.0}
{"epoch": 58, "training_loss": 1312.078369140625, "training_acc": 64.0, "val_loss": 20.771831274032593, "val_acc": 28.0}
{"epoch": 59, "training_loss": 851.8018913269043, "training_acc": 46.0, "val_loss": 772.0008850097656, "val_acc": 72.0}
{"epoch": 60, "training_loss": 2795.2500228881836, "training_acc": 72.0, "val_loss": 81.80752396583557, "val_acc": 72.0}
{"epoch": 61, "training_loss": 2354.746780395508, "training_acc": 54.0, "val_loss": 401.53918266296387, "val_acc": 28.0}
