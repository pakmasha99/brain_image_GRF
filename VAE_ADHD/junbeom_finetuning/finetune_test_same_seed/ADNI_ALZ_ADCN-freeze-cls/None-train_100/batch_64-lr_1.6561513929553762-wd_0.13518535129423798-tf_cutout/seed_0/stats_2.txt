"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9963.161602020264, "training_acc": 36.0, "val_loss": 3087.6420974731445, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8730.818225860596, "training_acc": 72.0, "val_loss": 6478.261566162109, "val_acc": 28.0}
{"epoch": 2, "training_loss": 22007.28936767578, "training_acc": 28.0, "val_loss": 796.4939594268799, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4366.272796630859, "training_acc": 72.0, "val_loss": 1579.6452522277832, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5443.936981201172, "training_acc": 72.0, "val_loss": 19.950439035892487, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3821.3548889160156, "training_acc": 56.0, "val_loss": 1175.3318786621094, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4808.13850402832, "training_acc": 40.0, "val_loss": 1472.38130569458, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5821.272735595703, "training_acc": 72.0, "val_loss": 915.036678314209, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2483.548858642578, "training_acc": 72.0, "val_loss": 1983.2025527954102, "val_acc": 28.0}
{"epoch": 9, "training_loss": 6856.925048828125, "training_acc": 28.0, "val_loss": 662.1427059173584, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3869.1205139160156, "training_acc": 72.0, "val_loss": 1101.4432907104492, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3753.3762283325195, "training_acc": 72.0, "val_loss": 53.947460651397705, "val_acc": 28.0}
{"epoch": 12, "training_loss": 580.9327011108398, "training_acc": 44.0, "val_loss": 210.39199829101562, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1525.2492446899414, "training_acc": 52.0, "val_loss": 356.78982734680176, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1634.4399490356445, "training_acc": 72.0, "val_loss": 174.86964464187622, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1273.4115371704102, "training_acc": 64.0, "val_loss": 81.21441602706909, "val_acc": 72.0}
{"epoch": 16, "training_loss": 260.90038537979126, "training_acc": 72.0, "val_loss": 855.8414459228516, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2832.3633995056152, "training_acc": 38.0, "val_loss": 287.1344566345215, "val_acc": 72.0}
{"epoch": 18, "training_loss": 727.8630821704865, "training_acc": 58.0, "val_loss": 203.37305068969727, "val_acc": 72.0}
{"epoch": 19, "training_loss": 601.5057106018066, "training_acc": 72.0, "val_loss": 1073.1524467468262, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2712.671679496765, "training_acc": 46.0, "val_loss": 101.69870853424072, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1071.1929779052734, "training_acc": 52.0, "val_loss": 461.4762306213379, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2144.836929321289, "training_acc": 72.0, "val_loss": 377.1421432495117, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1726.0258712768555, "training_acc": 52.0, "val_loss": 322.64928817749023, "val_acc": 72.0}
