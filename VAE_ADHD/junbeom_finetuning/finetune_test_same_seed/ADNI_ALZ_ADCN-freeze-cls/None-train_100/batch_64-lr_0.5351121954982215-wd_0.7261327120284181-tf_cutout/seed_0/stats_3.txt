"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2567.6745529174805, "training_acc": 53.0, "val_loss": 690.5712127685547, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2911.677963256836, "training_acc": 58.0, "val_loss": 211.39373779296875, "val_acc": 72.0}
{"epoch": 2, "training_loss": 796.1752071380615, "training_acc": 72.0, "val_loss": 218.3581829071045, "val_acc": 28.0}
{"epoch": 3, "training_loss": 877.612476348877, "training_acc": 48.0, "val_loss": 338.16094398498535, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1162.6849269866943, "training_acc": 72.0, "val_loss": 291.77637100219727, "val_acc": 28.0}
{"epoch": 5, "training_loss": 1000.7068881988525, "training_acc": 44.0, "val_loss": 179.68597412109375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 476.38272857666016, "training_acc": 72.0, "val_loss": 545.6652164459229, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1433.7690382003784, "training_acc": 28.0, "val_loss": 315.0233030319214, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1300.2992362976074, "training_acc": 72.0, "val_loss": 238.7704610824585, "val_acc": 72.0}
{"epoch": 9, "training_loss": 697.4284677505493, "training_acc": 72.0, "val_loss": 469.35338973999023, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1151.4710578918457, "training_acc": 28.0, "val_loss": 395.17712593078613, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1755.8037033081055, "training_acc": 72.0, "val_loss": 428.0916690826416, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1467.5924491882324, "training_acc": 72.0, "val_loss": 42.22067892551422, "val_acc": 72.0}
{"epoch": 13, "training_loss": 868.9954986572266, "training_acc": 54.0, "val_loss": 60.801762342453, "val_acc": 28.0}
{"epoch": 14, "training_loss": 676.7395515441895, "training_acc": 42.0, "val_loss": 398.4165668487549, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1476.3015670776367, "training_acc": 72.0, "val_loss": 154.52771186828613, "val_acc": 72.0}
{"epoch": 16, "training_loss": 475.58545684814453, "training_acc": 60.0, "val_loss": 108.93738269805908, "val_acc": 72.0}
{"epoch": 17, "training_loss": 390.7362766265869, "training_acc": 72.0, "val_loss": 95.28301954269409, "val_acc": 28.0}
{"epoch": 18, "training_loss": 495.3762626647949, "training_acc": 44.0, "val_loss": 185.51158905029297, "val_acc": 72.0}
{"epoch": 19, "training_loss": 631.0890431404114, "training_acc": 72.0, "val_loss": 205.1145315170288, "val_acc": 28.0}
{"epoch": 20, "training_loss": 800.0631408691406, "training_acc": 38.0, "val_loss": 109.03208255767822, "val_acc": 72.0}
{"epoch": 21, "training_loss": 359.643346786499, "training_acc": 54.0, "val_loss": 153.62756252288818, "val_acc": 72.0}
{"epoch": 22, "training_loss": 593.8758182525635, "training_acc": 72.0, "val_loss": 25.274348258972168, "val_acc": 72.0}
{"epoch": 23, "training_loss": 558.5942306518555, "training_acc": 56.0, "val_loss": 49.45710003376007, "val_acc": 72.0}
{"epoch": 24, "training_loss": 212.18449115753174, "training_acc": 72.0, "val_loss": 157.48777389526367, "val_acc": 28.0}
{"epoch": 25, "training_loss": 632.3295383453369, "training_acc": 42.0, "val_loss": 137.03831434249878, "val_acc": 72.0}
{"epoch": 26, "training_loss": 392.6759705543518, "training_acc": 72.0, "val_loss": 329.744815826416, "val_acc": 28.0}
{"epoch": 27, "training_loss": 852.2168793678284, "training_acc": 48.0, "val_loss": 52.572548389434814, "val_acc": 72.0}
{"epoch": 28, "training_loss": 337.0806064605713, "training_acc": 54.0, "val_loss": 164.5790934562683, "val_acc": 72.0}
{"epoch": 29, "training_loss": 711.1146850585938, "training_acc": 72.0, "val_loss": 71.04483842849731, "val_acc": 72.0}
{"epoch": 30, "training_loss": 805.5372352600098, "training_acc": 46.0, "val_loss": 74.2981493473053, "val_acc": 72.0}
{"epoch": 31, "training_loss": 295.39791679382324, "training_acc": 72.0, "val_loss": 31.390193104743958, "val_acc": 28.0}
{"epoch": 32, "training_loss": 217.79799270629883, "training_acc": 48.0, "val_loss": 112.08633184432983, "val_acc": 72.0}
{"epoch": 33, "training_loss": 338.0217740535736, "training_acc": 54.0, "val_loss": 84.3350350856781, "val_acc": 72.0}
{"epoch": 34, "training_loss": 265.4734992980957, "training_acc": 72.0, "val_loss": 278.22299003601074, "val_acc": 28.0}
{"epoch": 35, "training_loss": 640.1503949165344, "training_acc": 56.0, "val_loss": 78.72790098190308, "val_acc": 72.0}
{"epoch": 36, "training_loss": 214.8595769405365, "training_acc": 72.0, "val_loss": 16.379325091838837, "val_acc": 72.0}
{"epoch": 37, "training_loss": 362.73046112060547, "training_acc": 44.0, "val_loss": 213.52567672729492, "val_acc": 72.0}
{"epoch": 38, "training_loss": 934.12353515625, "training_acc": 72.0, "val_loss": 171.38047218322754, "val_acc": 72.0}
{"epoch": 39, "training_loss": 462.75905442237854, "training_acc": 72.0, "val_loss": 295.4028367996216, "val_acc": 28.0}
{"epoch": 40, "training_loss": 838.619870185852, "training_acc": 46.0, "val_loss": 89.98171091079712, "val_acc": 72.0}
{"epoch": 41, "training_loss": 209.35696697235107, "training_acc": 72.0, "val_loss": 388.15906047821045, "val_acc": 28.0}
{"epoch": 42, "training_loss": 1098.0047659873962, "training_acc": 40.0, "val_loss": 20.401595532894135, "val_acc": 72.0}
{"epoch": 43, "training_loss": 352.81907653808594, "training_acc": 54.0, "val_loss": 145.88558673858643, "val_acc": 72.0}
{"epoch": 44, "training_loss": 643.7592697143555, "training_acc": 72.0, "val_loss": 57.6782763004303, "val_acc": 72.0}
{"epoch": 45, "training_loss": 483.6670112609863, "training_acc": 60.0, "val_loss": 56.55528903007507, "val_acc": 72.0}
{"epoch": 46, "training_loss": 197.54165029525757, "training_acc": 72.0, "val_loss": 175.63050985336304, "val_acc": 28.0}
{"epoch": 47, "training_loss": 726.4284915924072, "training_acc": 40.0, "val_loss": 144.51621770858765, "val_acc": 72.0}
{"epoch": 48, "training_loss": 439.2925522327423, "training_acc": 72.0, "val_loss": 289.9479389190674, "val_acc": 28.0}
{"epoch": 49, "training_loss": 819.4534139633179, "training_acc": 46.0, "val_loss": 82.71784782409668, "val_acc": 72.0}
{"epoch": 50, "training_loss": 281.9867401123047, "training_acc": 56.0, "val_loss": 164.05792236328125, "val_acc": 72.0}
{"epoch": 51, "training_loss": 644.4776878356934, "training_acc": 72.0, "val_loss": 44.14695501327515, "val_acc": 72.0}
{"epoch": 52, "training_loss": 565.2281227111816, "training_acc": 56.0, "val_loss": 55.4137647151947, "val_acc": 72.0}
{"epoch": 53, "training_loss": 201.0229935646057, "training_acc": 72.0, "val_loss": 137.46155500411987, "val_acc": 28.0}
{"epoch": 54, "training_loss": 618.4013996124268, "training_acc": 42.0, "val_loss": 168.53258609771729, "val_acc": 72.0}
{"epoch": 55, "training_loss": 521.171856880188, "training_acc": 72.0, "val_loss": 260.3233575820923, "val_acc": 28.0}
