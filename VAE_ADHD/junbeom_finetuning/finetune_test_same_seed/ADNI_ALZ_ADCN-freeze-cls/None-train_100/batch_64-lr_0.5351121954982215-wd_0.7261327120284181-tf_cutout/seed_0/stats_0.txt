"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2565.3900146484375, "training_acc": 42.0, "val_loss": 757.0269584655762, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2512.9686889648438, "training_acc": 60.0, "val_loss": 296.38609886169434, "val_acc": 72.0}
{"epoch": 2, "training_loss": 1085.3250465393066, "training_acc": 72.0, "val_loss": 123.07144403457642, "val_acc": 28.0}
{"epoch": 3, "training_loss": 832.7725105285645, "training_acc": 44.0, "val_loss": 371.2653160095215, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1191.4342651367188, "training_acc": 72.0, "val_loss": 292.65222549438477, "val_acc": 28.0}
{"epoch": 5, "training_loss": 777.4787406921387, "training_acc": 52.0, "val_loss": 137.69909143447876, "val_acc": 72.0}
{"epoch": 6, "training_loss": 384.79198479652405, "training_acc": 56.0, "val_loss": 108.8077187538147, "val_acc": 72.0}
{"epoch": 7, "training_loss": 355.9462180137634, "training_acc": 50.0, "val_loss": 137.1099352836609, "val_acc": 72.0}
{"epoch": 8, "training_loss": 453.11698627471924, "training_acc": 72.0, "val_loss": 281.2795639038086, "val_acc": 28.0}
{"epoch": 9, "training_loss": 781.494930267334, "training_acc": 50.0, "val_loss": 136.96964979171753, "val_acc": 72.0}
{"epoch": 10, "training_loss": 379.9403009414673, "training_acc": 72.0, "val_loss": 367.7171468734741, "val_acc": 28.0}
{"epoch": 11, "training_loss": 1073.8287811279297, "training_acc": 44.0, "val_loss": 100.5666732788086, "val_acc": 72.0}
{"epoch": 12, "training_loss": 383.4065294265747, "training_acc": 54.0, "val_loss": 207.89849758148193, "val_acc": 72.0}
{"epoch": 13, "training_loss": 814.3558750152588, "training_acc": 72.0, "val_loss": 101.46564245223999, "val_acc": 72.0}
{"epoch": 14, "training_loss": 419.25317573547363, "training_acc": 60.0, "val_loss": 134.14541482925415, "val_acc": 72.0}
{"epoch": 15, "training_loss": 532.9303607940674, "training_acc": 72.0, "val_loss": 30.275386571884155, "val_acc": 28.0}
{"epoch": 16, "training_loss": 309.7795009613037, "training_acc": 40.0, "val_loss": 73.95550608634949, "val_acc": 72.0}
{"epoch": 17, "training_loss": 610.9524002075195, "training_acc": 50.0, "val_loss": 133.63940715789795, "val_acc": 72.0}
{"epoch": 18, "training_loss": 590.3129463195801, "training_acc": 72.0, "val_loss": 33.72337222099304, "val_acc": 72.0}
{"epoch": 19, "training_loss": 783.3940353393555, "training_acc": 50.0, "val_loss": 42.51390099525452, "val_acc": 72.0}
{"epoch": 20, "training_loss": 171.5295171737671, "training_acc": 72.0, "val_loss": 133.13663005828857, "val_acc": 28.0}
{"epoch": 21, "training_loss": 704.1091766357422, "training_acc": 38.0, "val_loss": 172.43976593017578, "val_acc": 72.0}
{"epoch": 22, "training_loss": 520.7451162338257, "training_acc": 72.0, "val_loss": 302.42342948913574, "val_acc": 28.0}
{"epoch": 23, "training_loss": 826.8631820678711, "training_acc": 46.0, "val_loss": 55.86060881614685, "val_acc": 72.0}
{"epoch": 24, "training_loss": 332.8285846710205, "training_acc": 56.0, "val_loss": 158.83805751800537, "val_acc": 72.0}
{"epoch": 25, "training_loss": 654.102258682251, "training_acc": 72.0, "val_loss": 57.91220664978027, "val_acc": 72.0}
{"epoch": 26, "training_loss": 609.8925514221191, "training_acc": 54.0, "val_loss": 67.90044903755188, "val_acc": 72.0}
{"epoch": 27, "training_loss": 266.49047470092773, "training_acc": 72.0, "val_loss": 109.085214138031, "val_acc": 28.0}
{"epoch": 28, "training_loss": 474.6627025604248, "training_acc": 46.0, "val_loss": 169.90188360214233, "val_acc": 72.0}
{"epoch": 29, "training_loss": 532.5888233184814, "training_acc": 72.0, "val_loss": 244.20387744903564, "val_acc": 28.0}
{"epoch": 30, "training_loss": 650.0808253288269, "training_acc": 50.0, "val_loss": 82.50330090522766, "val_acc": 72.0}
{"epoch": 31, "training_loss": 190.21040081977844, "training_acc": 72.0, "val_loss": 207.81874656677246, "val_acc": 28.0}
{"epoch": 32, "training_loss": 654.8089923858643, "training_acc": 48.0, "val_loss": 157.12519884109497, "val_acc": 72.0}
{"epoch": 33, "training_loss": 506.74311113357544, "training_acc": 72.0, "val_loss": 238.56561183929443, "val_acc": 28.0}
{"epoch": 34, "training_loss": 824.6793880462646, "training_acc": 40.0, "val_loss": 94.56185102462769, "val_acc": 72.0}
