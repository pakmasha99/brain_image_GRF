"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3478.046127319336, "training_acc": 34.0, "val_loss": 689.9619579315186, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2937.221534729004, "training_acc": 54.0, "val_loss": 198.23205471038818, "val_acc": 72.0}
{"epoch": 2, "training_loss": 725.4740858078003, "training_acc": 72.0, "val_loss": 163.22839260101318, "val_acc": 28.0}
{"epoch": 3, "training_loss": 883.1279945373535, "training_acc": 44.0, "val_loss": 342.39213466644287, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1099.8025588989258, "training_acc": 72.0, "val_loss": 255.20684719085693, "val_acc": 28.0}
{"epoch": 5, "training_loss": 843.2778568267822, "training_acc": 44.0, "val_loss": 116.02230072021484, "val_acc": 72.0}
{"epoch": 6, "training_loss": 338.81792640686035, "training_acc": 60.0, "val_loss": 193.3186173439026, "val_acc": 72.0}
{"epoch": 7, "training_loss": 793.5512847900391, "training_acc": 72.0, "val_loss": 25.948607921600342, "val_acc": 72.0}
{"epoch": 8, "training_loss": 877.6128540039062, "training_acc": 52.0, "val_loss": 19.516661763191223, "val_acc": 72.0}
{"epoch": 9, "training_loss": 124.82637310028076, "training_acc": 72.0, "val_loss": 116.41796827316284, "val_acc": 28.0}
{"epoch": 10, "training_loss": 525.7242584228516, "training_acc": 46.0, "val_loss": 202.4726152420044, "val_acc": 72.0}
{"epoch": 11, "training_loss": 672.3895711898804, "training_acc": 72.0, "val_loss": 195.43511867523193, "val_acc": 28.0}
{"epoch": 12, "training_loss": 482.9660315513611, "training_acc": 56.0, "val_loss": 127.88734436035156, "val_acc": 72.0}
{"epoch": 13, "training_loss": 377.6783208847046, "training_acc": 72.0, "val_loss": 323.0565309524536, "val_acc": 28.0}
{"epoch": 14, "training_loss": 954.3960847854614, "training_acc": 42.0, "val_loss": 59.63643193244934, "val_acc": 72.0}
{"epoch": 15, "training_loss": 288.20542335510254, "training_acc": 60.0, "val_loss": 150.69897174835205, "val_acc": 72.0}
{"epoch": 16, "training_loss": 597.9691104888916, "training_acc": 72.0, "val_loss": 34.98785197734833, "val_acc": 72.0}
{"epoch": 17, "training_loss": 539.7522201538086, "training_acc": 58.0, "val_loss": 49.78007674217224, "val_acc": 72.0}
{"epoch": 18, "training_loss": 228.65029907226562, "training_acc": 72.0, "val_loss": 194.3195343017578, "val_acc": 28.0}
{"epoch": 19, "training_loss": 774.7972507476807, "training_acc": 38.0, "val_loss": 109.73198413848877, "val_acc": 72.0}
{"epoch": 20, "training_loss": 362.38205909729004, "training_acc": 54.0, "val_loss": 153.84145975112915, "val_acc": 72.0}
{"epoch": 21, "training_loss": 584.2400541305542, "training_acc": 72.0, "val_loss": 30.047357082366943, "val_acc": 72.0}
{"epoch": 22, "training_loss": 571.675609588623, "training_acc": 54.0, "val_loss": 64.89490866661072, "val_acc": 72.0}
{"epoch": 23, "training_loss": 294.7556438446045, "training_acc": 72.0, "val_loss": 103.80394458770752, "val_acc": 28.0}
{"epoch": 24, "training_loss": 445.9710807800293, "training_acc": 46.0, "val_loss": 152.1749496459961, "val_acc": 72.0}
{"epoch": 25, "training_loss": 477.66474771499634, "training_acc": 72.0, "val_loss": 275.57365894317627, "val_acc": 28.0}
{"epoch": 26, "training_loss": 719.4806680679321, "training_acc": 50.0, "val_loss": 81.5469741821289, "val_acc": 72.0}
{"epoch": 27, "training_loss": 294.7848787307739, "training_acc": 54.0, "val_loss": 173.8794207572937, "val_acc": 72.0}
