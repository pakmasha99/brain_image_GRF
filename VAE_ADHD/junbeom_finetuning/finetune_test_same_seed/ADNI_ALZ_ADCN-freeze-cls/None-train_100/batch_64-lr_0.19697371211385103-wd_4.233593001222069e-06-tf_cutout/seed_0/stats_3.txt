"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 889.6703948974609, "training_acc": 68.0, "val_loss": 489.60556983947754, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1603.7651672363281, "training_acc": 72.0, "val_loss": 506.14914894104004, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1753.5227813720703, "training_acc": 28.0, "val_loss": 120.46476602554321, "val_acc": 72.0}
{"epoch": 3, "training_loss": 679.7514305114746, "training_acc": 72.0, "val_loss": 310.8896017074585, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1214.266170501709, "training_acc": 72.0, "val_loss": 210.58578491210938, "val_acc": 72.0}
{"epoch": 5, "training_loss": 654.5738849639893, "training_acc": 72.0, "val_loss": 245.57664394378662, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1020.3923645019531, "training_acc": 28.0, "val_loss": 20.47486901283264, "val_acc": 72.0}
{"epoch": 7, "training_loss": 200.62473487854004, "training_acc": 72.0, "val_loss": 113.63258361816406, "val_acc": 72.0}
{"epoch": 8, "training_loss": 409.8779020309448, "training_acc": 72.0, "val_loss": 14.957374334335327, "val_acc": 72.0}
{"epoch": 9, "training_loss": 290.39056396484375, "training_acc": 56.0, "val_loss": 50.621503591537476, "val_acc": 28.0}
{"epoch": 10, "training_loss": 280.12390899658203, "training_acc": 46.0, "val_loss": 206.84056282043457, "val_acc": 72.0}
{"epoch": 11, "training_loss": 888.0602531433105, "training_acc": 72.0, "val_loss": 234.23123359680176, "val_acc": 72.0}
{"epoch": 12, "training_loss": 860.9324893951416, "training_acc": 72.0, "val_loss": 91.07862710952759, "val_acc": 72.0}
{"epoch": 13, "training_loss": 411.2548027038574, "training_acc": 52.0, "val_loss": 92.30884909629822, "val_acc": 28.0}
{"epoch": 14, "training_loss": 383.6553020477295, "training_acc": 38.0, "val_loss": 117.87811517715454, "val_acc": 72.0}
{"epoch": 15, "training_loss": 478.7486209869385, "training_acc": 72.0, "val_loss": 83.92505645751953, "val_acc": 72.0}
{"epoch": 16, "training_loss": 272.6647644042969, "training_acc": 72.0, "val_loss": 105.76004981994629, "val_acc": 28.0}
{"epoch": 17, "training_loss": 279.6934883594513, "training_acc": 48.0, "val_loss": 49.583032727241516, "val_acc": 72.0}
{"epoch": 18, "training_loss": 183.20077228546143, "training_acc": 72.0, "val_loss": 24.209682643413544, "val_acc": 28.0}
{"epoch": 19, "training_loss": 87.33675694465637, "training_acc": 44.0, "val_loss": 15.092574059963226, "val_acc": 72.0}
{"epoch": 20, "training_loss": 93.42775201797485, "training_acc": 52.0, "val_loss": 57.2966992855072, "val_acc": 72.0}
{"epoch": 21, "training_loss": 244.29109382629395, "training_acc": 72.0, "val_loss": 58.748143911361694, "val_acc": 72.0}
{"epoch": 22, "training_loss": 164.45352339744568, "training_acc": 72.0, "val_loss": 121.15042209625244, "val_acc": 28.0}
{"epoch": 23, "training_loss": 323.48882126808167, "training_acc": 46.0, "val_loss": 64.05920386314392, "val_acc": 72.0}
{"epoch": 24, "training_loss": 285.39489555358887, "training_acc": 72.0, "val_loss": 48.38739633560181, "val_acc": 72.0}
{"epoch": 25, "training_loss": 208.42954921722412, "training_acc": 56.0, "val_loss": 16.564875841140747, "val_acc": 72.0}
{"epoch": 26, "training_loss": 66.28356575965881, "training_acc": 72.0, "val_loss": 14.64359313249588, "val_acc": 72.0}
{"epoch": 27, "training_loss": 66.69921517372131, "training_acc": 56.0, "val_loss": 36.831480264663696, "val_acc": 72.0}
{"epoch": 28, "training_loss": 137.9083399772644, "training_acc": 72.0, "val_loss": 34.59175527095795, "val_acc": 28.0}
{"epoch": 29, "training_loss": 169.81138134002686, "training_acc": 38.0, "val_loss": 36.26266419887543, "val_acc": 72.0}
{"epoch": 30, "training_loss": 148.29544496536255, "training_acc": 54.0, "val_loss": 32.29664862155914, "val_acc": 72.0}
{"epoch": 31, "training_loss": 131.0613112449646, "training_acc": 72.0, "val_loss": 28.210100531578064, "val_acc": 28.0}
{"epoch": 32, "training_loss": 102.23304796218872, "training_acc": 46.0, "val_loss": 21.74854278564453, "val_acc": 72.0}
{"epoch": 33, "training_loss": 86.22001647949219, "training_acc": 62.0, "val_loss": 28.91385853290558, "val_acc": 72.0}
{"epoch": 34, "training_loss": 114.46681118011475, "training_acc": 72.0, "val_loss": 50.920867919921875, "val_acc": 28.0}
{"epoch": 35, "training_loss": 205.24569749832153, "training_acc": 40.0, "val_loss": 45.43074369430542, "val_acc": 72.0}
{"epoch": 36, "training_loss": 132.93407440185547, "training_acc": 72.0, "val_loss": 102.28697061538696, "val_acc": 28.0}
{"epoch": 37, "training_loss": 263.1473345756531, "training_acc": 50.0, "val_loss": 51.28084421157837, "val_acc": 72.0}
{"epoch": 38, "training_loss": 190.01133346557617, "training_acc": 72.0, "val_loss": 22.685450315475464, "val_acc": 28.0}
{"epoch": 39, "training_loss": 100.53532934188843, "training_acc": 38.0, "val_loss": 18.752174079418182, "val_acc": 28.0}
{"epoch": 40, "training_loss": 92.00968027114868, "training_acc": 40.0, "val_loss": 15.029008686542511, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.80135703086853, "training_acc": 72.0, "val_loss": 16.124631464481354, "val_acc": 28.0}
{"epoch": 42, "training_loss": 90.12519216537476, "training_acc": 71.0, "val_loss": 14.570821821689606, "val_acc": 72.0}
{"epoch": 43, "training_loss": 90.27338123321533, "training_acc": 54.0, "val_loss": 63.89067769050598, "val_acc": 72.0}
{"epoch": 44, "training_loss": 298.76753425598145, "training_acc": 72.0, "val_loss": 70.43566703796387, "val_acc": 72.0}
{"epoch": 45, "training_loss": 193.07484412193298, "training_acc": 72.0, "val_loss": 159.5428705215454, "val_acc": 28.0}
{"epoch": 46, "training_loss": 476.6570281982422, "training_acc": 28.0, "val_loss": 125.16908645629883, "val_acc": 72.0}
{"epoch": 47, "training_loss": 644.4475708007812, "training_acc": 72.0, "val_loss": 254.203462600708, "val_acc": 72.0}
{"epoch": 48, "training_loss": 998.8367309570312, "training_acc": 72.0, "val_loss": 192.86901950836182, "val_acc": 72.0}
{"epoch": 49, "training_loss": 648.3297214508057, "training_acc": 72.0, "val_loss": 34.33070778846741, "val_acc": 28.0}
{"epoch": 50, "training_loss": 177.64336013793945, "training_acc": 28.0, "val_loss": 54.46348190307617, "val_acc": 72.0}
{"epoch": 51, "training_loss": 233.9255919456482, "training_acc": 72.0, "val_loss": 68.28457713127136, "val_acc": 72.0}
{"epoch": 52, "training_loss": 209.05991673469543, "training_acc": 72.0, "val_loss": 140.95687866210938, "val_acc": 28.0}
{"epoch": 53, "training_loss": 408.79875659942627, "training_acc": 28.0, "val_loss": 116.04472398757935, "val_acc": 72.0}
{"epoch": 54, "training_loss": 614.8752326965332, "training_acc": 72.0, "val_loss": 217.03364849090576, "val_acc": 72.0}
{"epoch": 55, "training_loss": 837.3916301727295, "training_acc": 72.0, "val_loss": 126.01721286773682, "val_acc": 72.0}
{"epoch": 56, "training_loss": 369.3701138496399, "training_acc": 72.0, "val_loss": 237.26634979248047, "val_acc": 28.0}
{"epoch": 57, "training_loss": 924.8914794921875, "training_acc": 28.0, "val_loss": 15.046513080596924, "val_acc": 72.0}
{"epoch": 58, "training_loss": 198.31132698059082, "training_acc": 72.0, "val_loss": 105.12231588363647, "val_acc": 72.0}
{"epoch": 59, "training_loss": 380.1118793487549, "training_acc": 72.0, "val_loss": 15.619532763957977, "val_acc": 72.0}
{"epoch": 60, "training_loss": 308.7753219604492, "training_acc": 54.0, "val_loss": 75.76841711997986, "val_acc": 28.0}
{"epoch": 61, "training_loss": 397.8675422668457, "training_acc": 40.0, "val_loss": 194.85111236572266, "val_acc": 72.0}
