"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7238.1188888549805, "training_acc": 38.0, "val_loss": 3185.654640197754, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10444.3017578125, "training_acc": 72.0, "val_loss": 2260.0595474243164, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7443.779037475586, "training_acc": 28.0, "val_loss": 1067.1059608459473, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5504.7470703125, "training_acc": 72.0, "val_loss": 2045.56884765625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7827.806213378906, "training_acc": 72.0, "val_loss": 1156.6267013549805, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3295.730667114258, "training_acc": 72.0, "val_loss": 2527.646827697754, "val_acc": 28.0}
{"epoch": 6, "training_loss": 10176.343841552734, "training_acc": 28.0, "val_loss": 780.539608001709, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3250.0900115966797, "training_acc": 46.0, "val_loss": 1929.097557067871, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8809.109741210938, "training_acc": 72.0, "val_loss": 2665.5921936035156, "val_acc": 72.0}
{"epoch": 9, "training_loss": 10450.648529052734, "training_acc": 72.0, "val_loss": 2094.8795318603516, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7490.248504638672, "training_acc": 72.0, "val_loss": 518.2497501373291, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3432.728302001953, "training_acc": 56.0, "val_loss": 2025.6584167480469, "val_acc": 28.0}
{"epoch": 12, "training_loss": 6367.040626525879, "training_acc": 28.0, "val_loss": 760.8259677886963, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3797.574203491211, "training_acc": 72.0, "val_loss": 1815.200424194336, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7443.444305419922, "training_acc": 72.0, "val_loss": 1751.633644104004, "val_acc": 72.0}
{"epoch": 15, "training_loss": 6259.5003662109375, "training_acc": 72.0, "val_loss": 701.5344142913818, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2886.420928955078, "training_acc": 52.0, "val_loss": 832.958984375, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2339.0933532714844, "training_acc": 46.0, "val_loss": 453.9623737335205, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1789.4134521484375, "training_acc": 72.0, "val_loss": 170.40038108825684, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2145.463363647461, "training_acc": 48.0, "val_loss": 333.0179691314697, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1455.7877883911133, "training_acc": 50.0, "val_loss": 1208.7559700012207, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5147.025970458984, "training_acc": 72.0, "val_loss": 1451.0457038879395, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5548.791374206543, "training_acc": 72.0, "val_loss": 733.0556392669678, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2034.161750793457, "training_acc": 72.0, "val_loss": 1825.839614868164, "val_acc": 28.0}
{"epoch": 24, "training_loss": 7526.388153076172, "training_acc": 28.0, "val_loss": 660.533857345581, "val_acc": 28.0}
{"epoch": 25, "training_loss": 2844.899429321289, "training_acc": 44.0, "val_loss": 1539.963436126709, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6926.9459228515625, "training_acc": 72.0, "val_loss": 2102.872085571289, "val_acc": 72.0}
{"epoch": 27, "training_loss": 8244.60220336914, "training_acc": 72.0, "val_loss": 1603.519058227539, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5674.911903381348, "training_acc": 72.0, "val_loss": 173.26782941818237, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3348.8295288085938, "training_acc": 56.0, "val_loss": 2571.1225509643555, "val_acc": 28.0}
{"epoch": 30, "training_loss": 8704.133010864258, "training_acc": 28.0, "val_loss": 408.3204746246338, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2360.8228302001953, "training_acc": 72.0, "val_loss": 1433.065128326416, "val_acc": 72.0}
{"epoch": 32, "training_loss": 5749.618804931641, "training_acc": 72.0, "val_loss": 1389.0817642211914, "val_acc": 72.0}
{"epoch": 33, "training_loss": 5092.965118408203, "training_acc": 72.0, "val_loss": 560.4156494140625, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1908.2321815490723, "training_acc": 58.0, "val_loss": 480.189847946167, "val_acc": 28.0}
{"epoch": 35, "training_loss": 2001.381103515625, "training_acc": 40.0, "val_loss": 687.0779991149902, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2743.9747009277344, "training_acc": 72.0, "val_loss": 441.78009033203125, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1106.0201873779297, "training_acc": 59.0, "val_loss": 136.20065450668335, "val_acc": 28.0}
{"epoch": 38, "training_loss": 1524.8498611450195, "training_acc": 36.0, "val_loss": 804.5023918151855, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3232.3167114257812, "training_acc": 72.0, "val_loss": 505.41958808898926, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1474.1519327163696, "training_acc": 54.0, "val_loss": 119.74629163742065, "val_acc": 72.0}
{"epoch": 41, "training_loss": 465.48768520355225, "training_acc": 50.0, "val_loss": 503.3623695373535, "val_acc": 72.0}
{"epoch": 42, "training_loss": 2303.22078704834, "training_acc": 72.0, "val_loss": 720.1954364776611, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2488.081298828125, "training_acc": 72.0, "val_loss": 13.020026683807373, "val_acc": 80.0}
{"epoch": 44, "training_loss": 1907.9513359069824, "training_acc": 57.0, "val_loss": 720.3735828399658, "val_acc": 28.0}
{"epoch": 45, "training_loss": 2320.885639190674, "training_acc": 48.0, "val_loss": 991.2705421447754, "val_acc": 72.0}
{"epoch": 46, "training_loss": 4138.695022583008, "training_acc": 72.0, "val_loss": 1154.3703079223633, "val_acc": 72.0}
{"epoch": 47, "training_loss": 4274.7228927612305, "training_acc": 72.0, "val_loss": 428.86881828308105, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1668.587287902832, "training_acc": 60.0, "val_loss": 480.4986000061035, "val_acc": 28.0}
{"epoch": 49, "training_loss": 1968.1302108764648, "training_acc": 42.0, "val_loss": 767.9415702819824, "val_acc": 72.0}
{"epoch": 50, "training_loss": 3063.004783630371, "training_acc": 72.0, "val_loss": 601.5435695648193, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1934.567518234253, "training_acc": 72.0, "val_loss": 955.9370040893555, "val_acc": 28.0}
{"epoch": 52, "training_loss": 3392.9582595825195, "training_acc": 28.0, "val_loss": 467.02637672424316, "val_acc": 72.0}
{"epoch": 53, "training_loss": 2799.6050567626953, "training_acc": 72.0, "val_loss": 1018.3972358703613, "val_acc": 72.0}
{"epoch": 54, "training_loss": 3838.9927825927734, "training_acc": 72.0, "val_loss": 457.5815200805664, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1259.3104820251465, "training_acc": 62.0, "val_loss": 56.94306492805481, "val_acc": 28.0}
{"epoch": 56, "training_loss": 919.1268310546875, "training_acc": 46.0, "val_loss": 952.3539543151855, "val_acc": 72.0}
{"epoch": 57, "training_loss": 3942.702850341797, "training_acc": 72.0, "val_loss": 850.4915237426758, "val_acc": 72.0}
{"epoch": 58, "training_loss": 2735.042854309082, "training_acc": 72.0, "val_loss": 447.1917152404785, "val_acc": 28.0}
{"epoch": 59, "training_loss": 1561.3633499145508, "training_acc": 28.0, "val_loss": 542.1464920043945, "val_acc": 72.0}
{"epoch": 60, "training_loss": 2535.7139587402344, "training_acc": 72.0, "val_loss": 962.3303413391113, "val_acc": 72.0}
{"epoch": 61, "training_loss": 3631.903289794922, "training_acc": 72.0, "val_loss": 428.6194324493408, "val_acc": 72.0}
{"epoch": 62, "training_loss": 2236.9027099609375, "training_acc": 50.0, "val_loss": 321.2134838104248, "val_acc": 28.0}
