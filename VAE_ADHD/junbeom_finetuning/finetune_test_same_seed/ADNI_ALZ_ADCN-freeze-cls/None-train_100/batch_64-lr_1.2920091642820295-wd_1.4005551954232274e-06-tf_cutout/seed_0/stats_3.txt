"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7782.72399520874, "training_acc": 36.0, "val_loss": 3124.5712280273438, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9677.899841308594, "training_acc": 72.0, "val_loss": 2160.785675048828, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7555.661605834961, "training_acc": 28.0, "val_loss": 851.4726638793945, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4308.178573608398, "training_acc": 72.0, "val_loss": 1780.9206008911133, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6822.781799316406, "training_acc": 72.0, "val_loss": 970.5361366271973, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3069.670614719391, "training_acc": 72.0, "val_loss": 2576.591682434082, "val_acc": 28.0}
{"epoch": 6, "training_loss": 10100.995697021484, "training_acc": 28.0, "val_loss": 271.64504528045654, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3964.315185546875, "training_acc": 32.0, "val_loss": 2279.1561126708984, "val_acc": 72.0}
{"epoch": 8, "training_loss": 9858.33285522461, "training_acc": 72.0, "val_loss": 2998.3163833618164, "val_acc": 72.0}
{"epoch": 9, "training_loss": 11846.816986083984, "training_acc": 72.0, "val_loss": 2541.8853759765625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 9392.793579101562, "training_acc": 72.0, "val_loss": 1153.89404296875, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4001.9014110565186, "training_acc": 72.0, "val_loss": 2572.8206634521484, "val_acc": 28.0}
{"epoch": 12, "training_loss": 11146.53466796875, "training_acc": 28.0, "val_loss": 2101.3734817504883, "val_acc": 28.0}
{"epoch": 13, "training_loss": 5630.611124038696, "training_acc": 44.0, "val_loss": 839.8724555969238, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3784.039291381836, "training_acc": 72.0, "val_loss": 1250.5768775939941, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4736.134841918945, "training_acc": 72.0, "val_loss": 654.5571327209473, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1702.6270079612732, "training_acc": 72.0, "val_loss": 1792.4524307250977, "val_acc": 28.0}
{"epoch": 17, "training_loss": 7002.220001220703, "training_acc": 28.0, "val_loss": 61.6847038269043, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1056.3154830932617, "training_acc": 52.0, "val_loss": 1912.2200012207031, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8388.46939086914, "training_acc": 72.0, "val_loss": 2660.153007507324, "val_acc": 72.0}
{"epoch": 20, "training_loss": 10550.943435668945, "training_acc": 72.0, "val_loss": 2324.429702758789, "val_acc": 72.0}
{"epoch": 21, "training_loss": 8504.926818847656, "training_acc": 72.0, "val_loss": 1189.5394325256348, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3585.7738609313965, "training_acc": 72.0, "val_loss": 1982.485008239746, "val_acc": 28.0}
{"epoch": 23, "training_loss": 8991.13510131836, "training_acc": 28.0, "val_loss": 1742.042350769043, "val_acc": 28.0}
{"epoch": 24, "training_loss": 4843.379413604736, "training_acc": 44.0, "val_loss": 899.6129989624023, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4191.719223022461, "training_acc": 72.0, "val_loss": 1269.0412521362305, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4737.864212036133, "training_acc": 72.0, "val_loss": 592.1048641204834, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1799.7401371002197, "training_acc": 56.0, "val_loss": 92.5513744354248, "val_acc": 28.0}
{"epoch": 28, "training_loss": 893.4001007080078, "training_acc": 48.0, "val_loss": 957.8031539916992, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3927.196578979492, "training_acc": 72.0, "val_loss": 884.6930503845215, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2897.93603515625, "training_acc": 72.0, "val_loss": 219.95501518249512, "val_acc": 28.0}
{"epoch": 31, "training_loss": 873.1494560241699, "training_acc": 28.0, "val_loss": 654.2972087860107, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3070.035354614258, "training_acc": 72.0, "val_loss": 1223.4944343566895, "val_acc": 72.0}
{"epoch": 33, "training_loss": 4755.685089111328, "training_acc": 72.0, "val_loss": 802.5684356689453, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2520.6304206848145, "training_acc": 72.0, "val_loss": 1112.901496887207, "val_acc": 28.0}
{"epoch": 35, "training_loss": 4312.971664428711, "training_acc": 28.0, "val_loss": 197.01873064041138, "val_acc": 72.0}
{"epoch": 36, "training_loss": 903.6777381896973, "training_acc": 72.0, "val_loss": 495.3726291656494, "val_acc": 72.0}
