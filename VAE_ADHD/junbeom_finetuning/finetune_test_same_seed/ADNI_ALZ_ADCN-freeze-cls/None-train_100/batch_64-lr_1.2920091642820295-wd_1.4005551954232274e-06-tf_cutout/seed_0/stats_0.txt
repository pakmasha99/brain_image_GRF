"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6129.823699951172, "training_acc": 42.0, "val_loss": 3333.063507080078, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10468.226776123047, "training_acc": 72.0, "val_loss": 1937.3119354248047, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6607.052505493164, "training_acc": 28.0, "val_loss": 1059.3806266784668, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5460.796569824219, "training_acc": 72.0, "val_loss": 2231.482696533203, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8737.442321777344, "training_acc": 72.0, "val_loss": 1576.9088745117188, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5502.235488891602, "training_acc": 72.0, "val_loss": 1077.5168418884277, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4243.573303222656, "training_acc": 28.0, "val_loss": 405.78436851501465, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1983.0869369506836, "training_acc": 72.0, "val_loss": 883.6920738220215, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3244.434814453125, "training_acc": 72.0, "val_loss": 209.3381643295288, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3023.9522705078125, "training_acc": 50.0, "val_loss": 1133.7333679199219, "val_acc": 28.0}
{"epoch": 10, "training_loss": 3399.340076446533, "training_acc": 44.0, "val_loss": 802.271556854248, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3411.3906860351562, "training_acc": 72.0, "val_loss": 814.1898155212402, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2737.0740280151367, "training_acc": 72.0, "val_loss": 477.63609886169434, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1564.572925567627, "training_acc": 28.0, "val_loss": 699.1334915161133, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3662.054977416992, "training_acc": 72.0, "val_loss": 1368.5572624206543, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5336.548889160156, "training_acc": 72.0, "val_loss": 922.4594116210938, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2724.0391006469727, "training_acc": 72.0, "val_loss": 1143.1547164916992, "val_acc": 28.0}
{"epoch": 17, "training_loss": 5060.871643066406, "training_acc": 28.0, "val_loss": 29.96807098388672, "val_acc": 72.0}
{"epoch": 18, "training_loss": 756.4196586608887, "training_acc": 72.0, "val_loss": 373.6021041870117, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1201.0074863433838, "training_acc": 72.0, "val_loss": 883.5372924804688, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2675.722225189209, "training_acc": 28.0, "val_loss": 711.456298828125, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3871.9760131835938, "training_acc": 72.0, "val_loss": 1460.2100372314453, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5739.219924926758, "training_acc": 72.0, "val_loss": 1093.0251121520996, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3682.961196899414, "training_acc": 72.0, "val_loss": 339.7257089614868, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1371.662857055664, "training_acc": 28.0, "val_loss": 476.17974281311035, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2412.929931640625, "training_acc": 72.0, "val_loss": 839.0528678894043, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3061.755500793457, "training_acc": 72.0, "val_loss": 196.2717890739441, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2077.941848754883, "training_acc": 56.0, "val_loss": 917.7921295166016, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2685.03165435791, "training_acc": 46.0, "val_loss": 673.4654426574707, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2833.5366592407227, "training_acc": 72.0, "val_loss": 630.3600788116455, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2099.294927597046, "training_acc": 72.0, "val_loss": 837.4762535095215, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2783.4240684509277, "training_acc": 28.0, "val_loss": 540.8553123474121, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2558.0616912841797, "training_acc": 72.0, "val_loss": 1022.6497650146484, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3907.137222290039, "training_acc": 72.0, "val_loss": 539.1647338867188, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1263.32675075531, "training_acc": 72.0, "val_loss": 1792.0761108398438, "val_acc": 28.0}
{"epoch": 35, "training_loss": 7272.460357666016, "training_acc": 28.0, "val_loss": 314.33470249176025, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2078.5782012939453, "training_acc": 46.0, "val_loss": 1806.2471389770508, "val_acc": 72.0}
