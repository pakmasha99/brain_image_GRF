"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5036.995464324951, "training_acc": 46.0, "val_loss": 3477.9685974121094, "val_acc": 72.0}
{"epoch": 1, "training_loss": 11956.700408935547, "training_acc": 72.0, "val_loss": 2120.408248901367, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6318.170413970947, "training_acc": 28.0, "val_loss": 1490.8226013183594, "val_acc": 72.0}
{"epoch": 3, "training_loss": 7370.340667724609, "training_acc": 72.0, "val_loss": 2651.689338684082, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10311.98696899414, "training_acc": 72.0, "val_loss": 1840.4983520507812, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5993.436660766602, "training_acc": 72.0, "val_loss": 913.6858940124512, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3855.2676391601562, "training_acc": 28.0, "val_loss": 332.9617500305176, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2267.1856536865234, "training_acc": 72.0, "val_loss": 693.7716960906982, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2261.854423522949, "training_acc": 72.0, "val_loss": 855.7403564453125, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2680.0124435424805, "training_acc": 28.0, "val_loss": 749.0110874176025, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3746.896194458008, "training_acc": 72.0, "val_loss": 1484.5629692077637, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5801.398468017578, "training_acc": 72.0, "val_loss": 1044.7824478149414, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3283.645164489746, "training_acc": 72.0, "val_loss": 850.765323638916, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3543.9293212890625, "training_acc": 28.0, "val_loss": 282.7504873275757, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1596.6097717285156, "training_acc": 72.0, "val_loss": 658.7437152862549, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2365.9764289855957, "training_acc": 72.0, "val_loss": 55.810219049453735, "val_acc": 28.0}
{"epoch": 16, "training_loss": 521.0989837646484, "training_acc": 42.0, "val_loss": 196.73457145690918, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1061.569107055664, "training_acc": 52.0, "val_loss": 278.9389371871948, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1272.9714965820312, "training_acc": 72.0, "val_loss": 253.5215139389038, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1341.8190078735352, "training_acc": 52.0, "val_loss": 164.90635871887207, "val_acc": 72.0}
{"epoch": 20, "training_loss": 687.3796405792236, "training_acc": 72.0, "val_loss": 16.94958060979843, "val_acc": 40.0}
{"epoch": 21, "training_loss": 67.72857880592346, "training_acc": 52.0, "val_loss": 343.129825592041, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1379.4658699035645, "training_acc": 72.0, "val_loss": 201.4573335647583, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1246.9606704711914, "training_acc": 56.0, "val_loss": 92.07600355148315, "val_acc": 72.0}
{"epoch": 24, "training_loss": 422.3761405944824, "training_acc": 72.0, "val_loss": 342.0898914337158, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1182.660026550293, "training_acc": 46.0, "val_loss": 383.97860527038574, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1335.7906169891357, "training_acc": 72.0, "val_loss": 326.15275382995605, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1052.9001598358154, "training_acc": 46.0, "val_loss": 250.62925815582275, "val_acc": 72.0}
{"epoch": 28, "training_loss": 718.1666326522827, "training_acc": 72.0, "val_loss": 953.7729263305664, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2788.617883682251, "training_acc": 28.0, "val_loss": 780.6612491607666, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3852.5911712646484, "training_acc": 72.0, "val_loss": 1530.0860404968262, "val_acc": 72.0}
{"epoch": 31, "training_loss": 6038.895767211914, "training_acc": 72.0, "val_loss": 1195.8195686340332, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4033.598243713379, "training_acc": 72.0, "val_loss": 83.77659916877747, "val_acc": 28.0}
{"epoch": 33, "training_loss": 263.4696931838989, "training_acc": 28.0, "val_loss": 421.13165855407715, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1951.0654067993164, "training_acc": 72.0, "val_loss": 439.80565071105957, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1154.4652843475342, "training_acc": 72.0, "val_loss": 1398.336410522461, "val_acc": 28.0}
{"epoch": 36, "training_loss": 5421.639190673828, "training_acc": 28.0, "val_loss": 263.55278491973877, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2136.904312133789, "training_acc": 72.0, "val_loss": 874.7912406921387, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3245.6278381347656, "training_acc": 72.0, "val_loss": 318.5347318649292, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1872.2295989990234, "training_acc": 56.0, "val_loss": 488.52081298828125, "val_acc": 28.0}
