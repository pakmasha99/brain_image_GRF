"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 469.9384002685547, "training_acc": 42.0, "val_loss": 221.00675106048584, "val_acc": 72.0}
{"epoch": 1, "training_loss": 668.0548629760742, "training_acc": 72.0, "val_loss": 199.96639490127563, "val_acc": 28.0}
{"epoch": 2, "training_loss": 706.4941501617432, "training_acc": 28.0, "val_loss": 54.46634292602539, "val_acc": 72.0}
{"epoch": 3, "training_loss": 300.1005115509033, "training_acc": 72.0, "val_loss": 129.3994903564453, "val_acc": 72.0}
{"epoch": 4, "training_loss": 495.9390411376953, "training_acc": 72.0, "val_loss": 73.39553833007812, "val_acc": 72.0}
{"epoch": 5, "training_loss": 249.08786273002625, "training_acc": 72.0, "val_loss": 98.25915098190308, "val_acc": 28.0}
{"epoch": 6, "training_loss": 297.8248338699341, "training_acc": 28.0, "val_loss": 55.26837110519409, "val_acc": 72.0}
{"epoch": 7, "training_loss": 250.90312671661377, "training_acc": 72.0, "val_loss": 95.48991322517395, "val_acc": 72.0}
{"epoch": 8, "training_loss": 362.1678190231323, "training_acc": 72.0, "val_loss": 48.22849929332733, "val_acc": 72.0}
{"epoch": 9, "training_loss": 184.83796072006226, "training_acc": 50.0, "val_loss": 36.795106530189514, "val_acc": 28.0}
{"epoch": 10, "training_loss": 129.80967020988464, "training_acc": 44.0, "val_loss": 38.42990696430206, "val_acc": 72.0}
{"epoch": 11, "training_loss": 142.5065999031067, "training_acc": 72.0, "val_loss": 15.050952136516571, "val_acc": 72.0}
{"epoch": 12, "training_loss": 99.17963600158691, "training_acc": 54.0, "val_loss": 17.79503971338272, "val_acc": 72.0}
{"epoch": 13, "training_loss": 75.63037371635437, "training_acc": 72.0, "val_loss": 22.532932460308075, "val_acc": 72.0}
{"epoch": 14, "training_loss": 74.51670455932617, "training_acc": 72.0, "val_loss": 29.974883794784546, "val_acc": 28.0}
{"epoch": 15, "training_loss": 112.59653186798096, "training_acc": 40.0, "val_loss": 23.522673547267914, "val_acc": 72.0}
{"epoch": 16, "training_loss": 79.71594977378845, "training_acc": 72.0, "val_loss": 32.53912627696991, "val_acc": 28.0}
{"epoch": 17, "training_loss": 97.22073721885681, "training_acc": 50.0, "val_loss": 28.55406403541565, "val_acc": 72.0}
{"epoch": 18, "training_loss": 119.2326021194458, "training_acc": 72.0, "val_loss": 14.805394411087036, "val_acc": 72.0}
{"epoch": 19, "training_loss": 120.50079822540283, "training_acc": 50.0, "val_loss": 16.398948431015015, "val_acc": 72.0}
{"epoch": 20, "training_loss": 80.92376375198364, "training_acc": 72.0, "val_loss": 25.795531272888184, "val_acc": 72.0}
{"epoch": 21, "training_loss": 79.55155515670776, "training_acc": 72.0, "val_loss": 42.60846674442291, "val_acc": 28.0}
{"epoch": 22, "training_loss": 131.24898076057434, "training_acc": 44.0, "val_loss": 26.761394739151, "val_acc": 72.0}
{"epoch": 23, "training_loss": 99.73525190353394, "training_acc": 72.0, "val_loss": 17.39341765642166, "val_acc": 28.0}
{"epoch": 24, "training_loss": 70.27244663238525, "training_acc": 31.0, "val_loss": 19.3616583943367, "val_acc": 72.0}
{"epoch": 25, "training_loss": 79.02363514900208, "training_acc": 72.0, "val_loss": 16.01676195859909, "val_acc": 28.0}
{"epoch": 26, "training_loss": 69.66063714027405, "training_acc": 54.0, "val_loss": 20.897439122200012, "val_acc": 72.0}
{"epoch": 27, "training_loss": 85.42119669914246, "training_acc": 72.0, "val_loss": 14.88225907087326, "val_acc": 72.0}
{"epoch": 28, "training_loss": 75.69419765472412, "training_acc": 54.0, "val_loss": 21.204516291618347, "val_acc": 72.0}
{"epoch": 29, "training_loss": 91.03505182266235, "training_acc": 72.0, "val_loss": 15.258854627609253, "val_acc": 72.0}
{"epoch": 30, "training_loss": 104.75960445404053, "training_acc": 50.0, "val_loss": 20.301257073879242, "val_acc": 72.0}
{"epoch": 31, "training_loss": 111.16210556030273, "training_acc": 72.0, "val_loss": 20.69142460823059, "val_acc": 72.0}
{"epoch": 32, "training_loss": 118.41555166244507, "training_acc": 52.0, "val_loss": 14.806592464447021, "val_acc": 72.0}
{"epoch": 33, "training_loss": 66.34983468055725, "training_acc": 72.0, "val_loss": 20.99599987268448, "val_acc": 72.0}
{"epoch": 34, "training_loss": 71.2443277835846, "training_acc": 72.0, "val_loss": 25.126227736473083, "val_acc": 28.0}
{"epoch": 35, "training_loss": 94.1509940624237, "training_acc": 44.0, "val_loss": 25.35150945186615, "val_acc": 72.0}
{"epoch": 36, "training_loss": 88.68029832839966, "training_acc": 72.0, "val_loss": 25.96127986907959, "val_acc": 28.0}
{"epoch": 37, "training_loss": 112.0757884979248, "training_acc": 36.0, "val_loss": 19.08373534679413, "val_acc": 72.0}
