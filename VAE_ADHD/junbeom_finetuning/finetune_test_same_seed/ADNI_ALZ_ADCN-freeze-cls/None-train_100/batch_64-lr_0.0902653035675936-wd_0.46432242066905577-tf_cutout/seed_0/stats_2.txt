"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 430.97071838378906, "training_acc": 72.0, "val_loss": 210.0907325744629, "val_acc": 72.0}
{"epoch": 1, "training_loss": 614.1593675613403, "training_acc": 72.0, "val_loss": 301.36687755584717, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1094.9271507263184, "training_acc": 28.0, "val_loss": 24.04417395591736, "val_acc": 72.0}
{"epoch": 3, "training_loss": 185.8341474533081, "training_acc": 72.0, "val_loss": 108.44993591308594, "val_acc": 72.0}
{"epoch": 4, "training_loss": 415.58277702331543, "training_acc": 72.0, "val_loss": 56.36258125305176, "val_acc": 72.0}
{"epoch": 5, "training_loss": 184.01510334014893, "training_acc": 54.0, "val_loss": 45.833954215049744, "val_acc": 28.0}
{"epoch": 6, "training_loss": 135.4533941745758, "training_acc": 50.0, "val_loss": 45.661407709121704, "val_acc": 72.0}
{"epoch": 7, "training_loss": 172.1940507888794, "training_acc": 72.0, "val_loss": 15.403163433074951, "val_acc": 72.0}
{"epoch": 8, "training_loss": 114.03709983825684, "training_acc": 56.0, "val_loss": 15.382800996303558, "val_acc": 72.0}
{"epoch": 9, "training_loss": 90.12513828277588, "training_acc": 72.0, "val_loss": 24.128077924251556, "val_acc": 72.0}
{"epoch": 10, "training_loss": 97.88834881782532, "training_acc": 54.0, "val_loss": 15.16377478837967, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.10922312736511, "training_acc": 72.0, "val_loss": 18.039976060390472, "val_acc": 72.0}
{"epoch": 12, "training_loss": 73.9903290271759, "training_acc": 54.0, "val_loss": 14.85777497291565, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.88153004646301, "training_acc": 72.0, "val_loss": 14.841872453689575, "val_acc": 72.0}
{"epoch": 14, "training_loss": 58.52879977226257, "training_acc": 72.0, "val_loss": 15.643413364887238, "val_acc": 28.0}
{"epoch": 15, "training_loss": 62.65247821807861, "training_acc": 72.0, "val_loss": 15.112237632274628, "val_acc": 72.0}
{"epoch": 16, "training_loss": 62.236494064331055, "training_acc": 72.0, "val_loss": 15.467002987861633, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.28149628639221, "training_acc": 72.0, "val_loss": 15.922464430332184, "val_acc": 28.0}
{"epoch": 18, "training_loss": 65.75658464431763, "training_acc": 72.0, "val_loss": 15.144863724708557, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.83450889587402, "training_acc": 72.0, "val_loss": 15.421807765960693, "val_acc": 32.0}
{"epoch": 20, "training_loss": 62.54559111595154, "training_acc": 72.0, "val_loss": 14.886657893657684, "val_acc": 72.0}
{"epoch": 21, "training_loss": 68.68458461761475, "training_acc": 48.0, "val_loss": 30.035173892974854, "val_acc": 72.0}
{"epoch": 22, "training_loss": 138.31258869171143, "training_acc": 72.0, "val_loss": 14.809857308864594, "val_acc": 72.0}
{"epoch": 23, "training_loss": 120.458083152771, "training_acc": 56.0, "val_loss": 18.45283806324005, "val_acc": 72.0}
{"epoch": 24, "training_loss": 92.38318729400635, "training_acc": 72.0, "val_loss": 21.83740884065628, "val_acc": 72.0}
{"epoch": 25, "training_loss": 118.97149181365967, "training_acc": 52.0, "val_loss": 18.365631997585297, "val_acc": 72.0}
{"epoch": 26, "training_loss": 89.24761629104614, "training_acc": 72.0, "val_loss": 15.042714774608612, "val_acc": 72.0}
{"epoch": 27, "training_loss": 66.47345781326294, "training_acc": 64.0, "val_loss": 15.394248068332672, "val_acc": 72.0}
{"epoch": 28, "training_loss": 68.67410802841187, "training_acc": 72.0, "val_loss": 15.213677287101746, "val_acc": 64.0}
{"epoch": 29, "training_loss": 60.513667821884155, "training_acc": 72.0, "val_loss": 14.898350834846497, "val_acc": 72.0}
{"epoch": 30, "training_loss": 61.82374286651611, "training_acc": 72.0, "val_loss": 15.195582807064056, "val_acc": 64.0}
{"epoch": 31, "training_loss": 64.57901859283447, "training_acc": 72.0, "val_loss": 20.214098691940308, "val_acc": 28.0}
{"epoch": 32, "training_loss": 73.76343083381653, "training_acc": 46.0, "val_loss": 18.844352662563324, "val_acc": 72.0}
{"epoch": 33, "training_loss": 82.62084197998047, "training_acc": 52.0, "val_loss": 18.5756653547287, "val_acc": 72.0}
{"epoch": 34, "training_loss": 75.54857277870178, "training_acc": 72.0, "val_loss": 23.635756969451904, "val_acc": 28.0}
{"epoch": 35, "training_loss": 77.55838894844055, "training_acc": 48.0, "val_loss": 22.16891646385193, "val_acc": 72.0}
{"epoch": 36, "training_loss": 89.81904196739197, "training_acc": 72.0, "val_loss": 15.388324856758118, "val_acc": 72.0}
{"epoch": 37, "training_loss": 60.7500479221344, "training_acc": 72.0, "val_loss": 17.940600216388702, "val_acc": 28.0}
{"epoch": 38, "training_loss": 73.55467057228088, "training_acc": 42.0, "val_loss": 15.227827429771423, "val_acc": 72.0}
{"epoch": 39, "training_loss": 60.91680455207825, "training_acc": 64.0, "val_loss": 14.969801902770996, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.98963904380798, "training_acc": 72.0, "val_loss": 16.895365715026855, "val_acc": 72.0}
{"epoch": 41, "training_loss": 64.34998297691345, "training_acc": 72.0, "val_loss": 15.340331196784973, "val_acc": 52.0}
{"epoch": 42, "training_loss": 62.536054849624634, "training_acc": 72.0, "val_loss": 14.781051874160767, "val_acc": 72.0}
{"epoch": 43, "training_loss": 58.30192494392395, "training_acc": 72.0, "val_loss": 15.06342887878418, "val_acc": 72.0}
{"epoch": 44, "training_loss": 61.08657503128052, "training_acc": 72.0, "val_loss": 14.810548722743988, "val_acc": 72.0}
{"epoch": 45, "training_loss": 72.55620861053467, "training_acc": 48.0, "val_loss": 35.28536260128021, "val_acc": 72.0}
{"epoch": 46, "training_loss": 158.31977939605713, "training_acc": 72.0, "val_loss": 18.736357986927032, "val_acc": 72.0}
{"epoch": 47, "training_loss": 118.22449207305908, "training_acc": 62.0, "val_loss": 15.20293653011322, "val_acc": 68.0}
{"epoch": 48, "training_loss": 97.09413146972656, "training_acc": 72.0, "val_loss": 36.537256836891174, "val_acc": 72.0}
{"epoch": 49, "training_loss": 123.83827185630798, "training_acc": 72.0, "val_loss": 32.51589834690094, "val_acc": 28.0}
{"epoch": 50, "training_loss": 134.52859497070312, "training_acc": 42.0, "val_loss": 39.05383348464966, "val_acc": 72.0}
{"epoch": 51, "training_loss": 126.45306038856506, "training_acc": 72.0, "val_loss": 57.79884457588196, "val_acc": 28.0}
{"epoch": 52, "training_loss": 186.5264093875885, "training_acc": 38.0, "val_loss": 22.713439166545868, "val_acc": 72.0}
{"epoch": 53, "training_loss": 81.72056937217712, "training_acc": 72.0, "val_loss": 18.092980980873108, "val_acc": 28.0}
{"epoch": 54, "training_loss": 80.30076289176941, "training_acc": 42.0, "val_loss": 17.390176653862, "val_acc": 72.0}
{"epoch": 55, "training_loss": 88.74011945724487, "training_acc": 54.0, "val_loss": 23.175790905952454, "val_acc": 72.0}
{"epoch": 56, "training_loss": 102.07080841064453, "training_acc": 72.0, "val_loss": 15.239199995994568, "val_acc": 64.0}
{"epoch": 57, "training_loss": 67.1685938835144, "training_acc": 62.0, "val_loss": 19.191625714302063, "val_acc": 72.0}
{"epoch": 58, "training_loss": 74.1836564540863, "training_acc": 72.0, "val_loss": 18.094642460346222, "val_acc": 28.0}
{"epoch": 59, "training_loss": 64.83475947380066, "training_acc": 48.0, "val_loss": 20.199231803417206, "val_acc": 72.0}
{"epoch": 60, "training_loss": 71.01049733161926, "training_acc": 72.0, "val_loss": 33.151817321777344, "val_acc": 28.0}
{"epoch": 61, "training_loss": 119.74367570877075, "training_acc": 44.0, "val_loss": 30.47015368938446, "val_acc": 72.0}
