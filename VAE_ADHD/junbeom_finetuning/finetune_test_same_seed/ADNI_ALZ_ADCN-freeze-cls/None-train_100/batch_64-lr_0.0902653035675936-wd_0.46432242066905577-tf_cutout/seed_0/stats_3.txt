"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 546.8639526367188, "training_acc": 38.0, "val_loss": 214.67816829681396, "val_acc": 72.0}
{"epoch": 1, "training_loss": 776.5541610717773, "training_acc": 72.0, "val_loss": 179.68517541885376, "val_acc": 28.0}
{"epoch": 2, "training_loss": 566.5584783554077, "training_acc": 28.0, "val_loss": 83.71106386184692, "val_acc": 72.0}
{"epoch": 3, "training_loss": 416.9895763397217, "training_acc": 72.0, "val_loss": 157.35481977462769, "val_acc": 72.0}
{"epoch": 4, "training_loss": 605.5649127960205, "training_acc": 72.0, "val_loss": 97.10302352905273, "val_acc": 72.0}
{"epoch": 5, "training_loss": 268.1830768585205, "training_acc": 72.0, "val_loss": 115.02630710601807, "val_acc": 28.0}
{"epoch": 6, "training_loss": 466.927396774292, "training_acc": 28.0, "val_loss": 15.302293002605438, "val_acc": 72.0}
{"epoch": 7, "training_loss": 108.03741455078125, "training_acc": 72.0, "val_loss": 76.33157968521118, "val_acc": 72.0}
{"epoch": 8, "training_loss": 308.25242805480957, "training_acc": 72.0, "val_loss": 51.34493112564087, "val_acc": 72.0}
{"epoch": 9, "training_loss": 141.61530303955078, "training_acc": 72.0, "val_loss": 94.72330808639526, "val_acc": 28.0}
{"epoch": 10, "training_loss": 328.74870014190674, "training_acc": 28.0, "val_loss": 36.66693866252899, "val_acc": 72.0}
{"epoch": 11, "training_loss": 206.53684616088867, "training_acc": 72.0, "val_loss": 78.57537865638733, "val_acc": 72.0}
{"epoch": 12, "training_loss": 296.2293462753296, "training_acc": 72.0, "val_loss": 33.667391538619995, "val_acc": 72.0}
{"epoch": 13, "training_loss": 143.6093897819519, "training_acc": 54.0, "val_loss": 30.58336079120636, "val_acc": 28.0}
{"epoch": 14, "training_loss": 117.45537805557251, "training_acc": 44.0, "val_loss": 41.42261743545532, "val_acc": 72.0}
{"epoch": 15, "training_loss": 156.64980936050415, "training_acc": 72.0, "val_loss": 15.635576844215393, "val_acc": 72.0}
{"epoch": 16, "training_loss": 107.82676362991333, "training_acc": 56.0, "val_loss": 15.990032255649567, "val_acc": 28.0}
{"epoch": 17, "training_loss": 72.94589352607727, "training_acc": 72.0, "val_loss": 34.94808077812195, "val_acc": 72.0}
{"epoch": 18, "training_loss": 123.41777276992798, "training_acc": 72.0, "val_loss": 22.19867706298828, "val_acc": 28.0}
{"epoch": 19, "training_loss": 86.13520884513855, "training_acc": 28.0, "val_loss": 22.244837880134583, "val_acc": 72.0}
{"epoch": 20, "training_loss": 94.73583364486694, "training_acc": 72.0, "val_loss": 16.097833216190338, "val_acc": 72.0}
{"epoch": 21, "training_loss": 89.7167158126831, "training_acc": 54.0, "val_loss": 15.283450484275818, "val_acc": 72.0}
{"epoch": 22, "training_loss": 74.33199548721313, "training_acc": 72.0, "val_loss": 17.304149270057678, "val_acc": 72.0}
{"epoch": 23, "training_loss": 76.64984583854675, "training_acc": 56.0, "val_loss": 14.754477143287659, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.15251874923706, "training_acc": 72.0, "val_loss": 16.696183383464813, "val_acc": 72.0}
{"epoch": 25, "training_loss": 60.70041251182556, "training_acc": 72.0, "val_loss": 22.04238623380661, "val_acc": 28.0}
{"epoch": 26, "training_loss": 85.95461368560791, "training_acc": 42.0, "val_loss": 19.84219253063202, "val_acc": 72.0}
{"epoch": 27, "training_loss": 82.86991143226624, "training_acc": 72.0, "val_loss": 14.749455451965332, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.733577489852905, "training_acc": 72.0, "val_loss": 15.46223759651184, "val_acc": 72.0}
{"epoch": 29, "training_loss": 65.68237781524658, "training_acc": 72.0, "val_loss": 15.674437582492828, "val_acc": 72.0}
{"epoch": 30, "training_loss": 62.515294551849365, "training_acc": 72.0, "val_loss": 15.606412291526794, "val_acc": 28.0}
{"epoch": 31, "training_loss": 62.139445543289185, "training_acc": 72.0, "val_loss": 18.98094117641449, "val_acc": 72.0}
{"epoch": 32, "training_loss": 73.56687140464783, "training_acc": 72.0, "val_loss": 15.186524391174316, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.6157763004303, "training_acc": 72.0, "val_loss": 14.74287360906601, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.56087803840637, "training_acc": 72.0, "val_loss": 15.397191047668457, "val_acc": 72.0}
{"epoch": 35, "training_loss": 61.23730397224426, "training_acc": 72.0, "val_loss": 19.004960358142853, "val_acc": 28.0}
{"epoch": 36, "training_loss": 71.49999690055847, "training_acc": 44.0, "val_loss": 16.829383373260498, "val_acc": 72.0}
{"epoch": 37, "training_loss": 82.55971336364746, "training_acc": 48.0, "val_loss": 21.300911903381348, "val_acc": 72.0}
{"epoch": 38, "training_loss": 86.37258863449097, "training_acc": 72.0, "val_loss": 15.689945220947266, "val_acc": 28.0}
{"epoch": 39, "training_loss": 71.30671787261963, "training_acc": 54.0, "val_loss": 23.828214406967163, "val_acc": 72.0}
{"epoch": 40, "training_loss": 105.8885006904602, "training_acc": 72.0, "val_loss": 14.87191915512085, "val_acc": 72.0}
{"epoch": 41, "training_loss": 94.95068883895874, "training_acc": 54.0, "val_loss": 24.142606556415558, "val_acc": 72.0}
{"epoch": 42, "training_loss": 114.47851514816284, "training_acc": 72.0, "val_loss": 21.732284128665924, "val_acc": 72.0}
{"epoch": 43, "training_loss": 114.82334041595459, "training_acc": 54.0, "val_loss": 15.173456072807312, "val_acc": 72.0}
{"epoch": 44, "training_loss": 85.00106763839722, "training_acc": 72.0, "val_loss": 16.52531921863556, "val_acc": 72.0}
{"epoch": 45, "training_loss": 77.37908697128296, "training_acc": 60.0, "val_loss": 15.22742360830307, "val_acc": 72.0}
{"epoch": 46, "training_loss": 74.39405632019043, "training_acc": 72.0, "val_loss": 14.740467071533203, "val_acc": 72.0}
{"epoch": 47, "training_loss": 69.15938997268677, "training_acc": 58.0, "val_loss": 18.167197704315186, "val_acc": 72.0}
{"epoch": 48, "training_loss": 71.79956483840942, "training_acc": 72.0, "val_loss": 14.748452603816986, "val_acc": 72.0}
{"epoch": 49, "training_loss": 68.27265000343323, "training_acc": 52.0, "val_loss": 22.453704476356506, "val_acc": 72.0}
{"epoch": 50, "training_loss": 96.78199052810669, "training_acc": 72.0, "val_loss": 16.944435238838196, "val_acc": 28.0}
{"epoch": 51, "training_loss": 69.15682125091553, "training_acc": 61.0, "val_loss": 17.925414443016052, "val_acc": 72.0}
{"epoch": 52, "training_loss": 75.27230787277222, "training_acc": 72.0, "val_loss": 22.577430307865143, "val_acc": 28.0}
{"epoch": 53, "training_loss": 84.98217487335205, "training_acc": 40.0, "val_loss": 15.594705939292908, "val_acc": 72.0}
{"epoch": 54, "training_loss": 66.72628855705261, "training_acc": 58.0, "val_loss": 16.364896297454834, "val_acc": 72.0}
{"epoch": 55, "training_loss": 65.57488560676575, "training_acc": 72.0, "val_loss": 18.739570677280426, "val_acc": 28.0}
{"epoch": 56, "training_loss": 72.44098591804504, "training_acc": 42.0, "val_loss": 15.369458496570587, "val_acc": 72.0}
{"epoch": 57, "training_loss": 69.95130658149719, "training_acc": 52.0, "val_loss": 19.614018499851227, "val_acc": 72.0}
{"epoch": 58, "training_loss": 78.14855170249939, "training_acc": 72.0, "val_loss": 20.152322947978973, "val_acc": 28.0}
{"epoch": 59, "training_loss": 70.55382227897644, "training_acc": 48.0, "val_loss": 22.335155308246613, "val_acc": 72.0}
{"epoch": 60, "training_loss": 81.7859718799591, "training_acc": 72.0, "val_loss": 24.810010194778442, "val_acc": 28.0}
{"epoch": 61, "training_loss": 103.21226739883423, "training_acc": 38.0, "val_loss": 17.076297104358673, "val_acc": 72.0}
{"epoch": 62, "training_loss": 102.40055561065674, "training_acc": 48.0, "val_loss": 26.293453574180603, "val_acc": 72.0}
{"epoch": 63, "training_loss": 113.45242929458618, "training_acc": 72.0, "val_loss": 19.264690577983856, "val_acc": 72.0}
{"epoch": 64, "training_loss": 114.39519119262695, "training_acc": 54.0, "val_loss": 16.72435700893402, "val_acc": 72.0}
{"epoch": 65, "training_loss": 91.29551935195923, "training_acc": 72.0, "val_loss": 16.09363555908203, "val_acc": 72.0}
