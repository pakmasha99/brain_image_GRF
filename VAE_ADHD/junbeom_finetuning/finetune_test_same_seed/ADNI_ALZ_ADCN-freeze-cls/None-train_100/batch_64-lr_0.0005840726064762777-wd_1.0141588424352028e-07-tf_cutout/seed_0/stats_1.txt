"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 65.1264111995697, "training_acc": 72.0, "val_loss": 15.13732373714447, "val_acc": 72.0}
{"epoch": 1, "training_loss": 60.062785148620605, "training_acc": 72.0, "val_loss": 14.861245453357697, "val_acc": 72.0}
{"epoch": 2, "training_loss": 59.738635301589966, "training_acc": 72.0, "val_loss": 15.155142545700073, "val_acc": 72.0}
{"epoch": 3, "training_loss": 60.89129304885864, "training_acc": 72.0, "val_loss": 15.288414061069489, "val_acc": 72.0}
{"epoch": 4, "training_loss": 60.993754625320435, "training_acc": 72.0, "val_loss": 15.142391622066498, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60.32856607437134, "training_acc": 72.0, "val_loss": 14.927530288696289, "val_acc": 72.0}
{"epoch": 6, "training_loss": 59.49279451370239, "training_acc": 72.0, "val_loss": 14.8382768034935, "val_acc": 72.0}
{"epoch": 7, "training_loss": 59.309754371643066, "training_acc": 72.0, "val_loss": 14.893631637096405, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.415069580078125, "training_acc": 72.0, "val_loss": 14.976201951503754, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.83943581581116, "training_acc": 72.0, "val_loss": 15.027129650115967, "val_acc": 72.0}
{"epoch": 10, "training_loss": 60.04803490638733, "training_acc": 72.0, "val_loss": 14.983630180358887, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.813098669052124, "training_acc": 72.0, "val_loss": 14.88087773323059, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.40188646316528, "training_acc": 72.0, "val_loss": 14.837288856506348, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.2467086315155, "training_acc": 72.0, "val_loss": 14.853547513484955, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.322654008865356, "training_acc": 72.0, "val_loss": 14.89352434873581, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.52634882926941, "training_acc": 72.0, "val_loss": 14.915131032466888, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.58512783050537, "training_acc": 72.0, "val_loss": 14.887847006320953, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.50048851966858, "training_acc": 72.0, "val_loss": 14.854402840137482, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.295318365097046, "training_acc": 72.0, "val_loss": 14.836737513542175, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.237205028533936, "training_acc": 72.0, "val_loss": 14.841137826442719, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.49561643600464, "training_acc": 72.0, "val_loss": 14.864036440849304, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.471508502960205, "training_acc": 72.0, "val_loss": 14.856626093387604, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.34402346611023, "training_acc": 72.0, "val_loss": 14.835582673549652, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.188509702682495, "training_acc": 72.0, "val_loss": 14.837020635604858, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.40108585357666, "training_acc": 72.0, "val_loss": 14.861854910850525, "val_acc": 72.0}
