"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1555.3838081359863, "training_acc": 42.0, "val_loss": 832.9729080200195, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2864.100772857666, "training_acc": 72.0, "val_loss": 480.3584575653076, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1436.1741027832031, "training_acc": 28.0, "val_loss": 345.0397253036499, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1789.402931213379, "training_acc": 72.0, "val_loss": 658.946943283081, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2574.103645324707, "training_acc": 72.0, "val_loss": 481.8495750427246, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1670.1722717285156, "training_acc": 72.0, "val_loss": 43.39540898799896, "val_acc": 28.0}
{"epoch": 6, "training_loss": 298.04179191589355, "training_acc": 28.0, "val_loss": 135.10098457336426, "val_acc": 72.0}
{"epoch": 7, "training_loss": 643.2132301330566, "training_acc": 72.0, "val_loss": 220.16549110412598, "val_acc": 72.0}
{"epoch": 8, "training_loss": 765.7829265594482, "training_acc": 72.0, "val_loss": 15.057383477687836, "val_acc": 68.0}
{"epoch": 9, "training_loss": 455.0278854370117, "training_acc": 56.0, "val_loss": 62.75337338447571, "val_acc": 28.0}
{"epoch": 10, "training_loss": 474.1315002441406, "training_acc": 44.0, "val_loss": 371.9921588897705, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1581.701286315918, "training_acc": 72.0, "val_loss": 432.68933296203613, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1609.6411590576172, "training_acc": 72.0, "val_loss": 220.1347827911377, "val_acc": 72.0}
{"epoch": 13, "training_loss": 548.0708622932434, "training_acc": 72.0, "val_loss": 575.8734703063965, "val_acc": 28.0}
{"epoch": 14, "training_loss": 2452.2928771972656, "training_acc": 28.0, "val_loss": 362.49852180480957, "val_acc": 28.0}
{"epoch": 15, "training_loss": 945.0460233688354, "training_acc": 52.0, "val_loss": 311.8233919143677, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1523.8603134155273, "training_acc": 72.0, "val_loss": 465.252161026001, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1792.588020324707, "training_acc": 72.0, "val_loss": 316.07048511505127, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1030.9878253936768, "training_acc": 72.0, "val_loss": 139.14920091629028, "val_acc": 28.0}
{"epoch": 19, "training_loss": 666.6606025695801, "training_acc": 28.0, "val_loss": 67.1940267086029, "val_acc": 72.0}
{"epoch": 20, "training_loss": 399.5266914367676, "training_acc": 72.0, "val_loss": 142.70589351654053, "val_acc": 72.0}
{"epoch": 21, "training_loss": 461.1709613800049, "training_acc": 72.0, "val_loss": 116.18044376373291, "val_acc": 28.0}
{"epoch": 22, "training_loss": 330.6151056289673, "training_acc": 28.0, "val_loss": 99.77769255638123, "val_acc": 72.0}
{"epoch": 23, "training_loss": 467.81611251831055, "training_acc": 72.0, "val_loss": 94.42901611328125, "val_acc": 72.0}
{"epoch": 24, "training_loss": 261.75639724731445, "training_acc": 58.0, "val_loss": 17.97783225774765, "val_acc": 28.0}
{"epoch": 25, "training_loss": 196.0854034423828, "training_acc": 46.0, "val_loss": 58.202046155929565, "val_acc": 72.0}
{"epoch": 26, "training_loss": 256.71709156036377, "training_acc": 54.0, "val_loss": 62.28427290916443, "val_acc": 72.0}
{"epoch": 27, "training_loss": 254.7024097442627, "training_acc": 72.0, "val_loss": 30.896243453025818, "val_acc": 72.0}
{"epoch": 28, "training_loss": 276.21499824523926, "training_acc": 60.0, "val_loss": 14.963039755821228, "val_acc": 72.0}
{"epoch": 29, "training_loss": 100.59323596954346, "training_acc": 72.0, "val_loss": 51.43709182739258, "val_acc": 72.0}
{"epoch": 30, "training_loss": 294.40845108032227, "training_acc": 48.0, "val_loss": 78.18716168403625, "val_acc": 72.0}
{"epoch": 31, "training_loss": 369.4112739562988, "training_acc": 72.0, "val_loss": 85.9392762184143, "val_acc": 72.0}
{"epoch": 32, "training_loss": 234.2641417980194, "training_acc": 58.0, "val_loss": 25.339949131011963, "val_acc": 28.0}
{"epoch": 33, "training_loss": 231.20168685913086, "training_acc": 40.0, "val_loss": 118.20337772369385, "val_acc": 72.0}
{"epoch": 34, "training_loss": 408.5700535774231, "training_acc": 72.0, "val_loss": 90.70345759391785, "val_acc": 28.0}
{"epoch": 35, "training_loss": 288.9707498550415, "training_acc": 44.0, "val_loss": 46.57698571681976, "val_acc": 72.0}
{"epoch": 36, "training_loss": 162.4239296913147, "training_acc": 56.0, "val_loss": 64.00321125984192, "val_acc": 72.0}
{"epoch": 37, "training_loss": 267.79506397247314, "training_acc": 72.0, "val_loss": 15.420253574848175, "val_acc": 72.0}
{"epoch": 38, "training_loss": 272.9837074279785, "training_acc": 56.0, "val_loss": 34.11405384540558, "val_acc": 72.0}
{"epoch": 39, "training_loss": 138.71672248840332, "training_acc": 72.0, "val_loss": 21.248435974121094, "val_acc": 72.0}
{"epoch": 40, "training_loss": 186.37990188598633, "training_acc": 62.0, "val_loss": 44.86093521118164, "val_acc": 72.0}
{"epoch": 41, "training_loss": 220.69303607940674, "training_acc": 72.0, "val_loss": 16.73734188079834, "val_acc": 72.0}
{"epoch": 42, "training_loss": 278.2774028778076, "training_acc": 58.0, "val_loss": 20.999033749103546, "val_acc": 72.0}
{"epoch": 43, "training_loss": 99.21488237380981, "training_acc": 72.0, "val_loss": 16.342243552207947, "val_acc": 72.0}
{"epoch": 44, "training_loss": 172.6879062652588, "training_acc": 58.0, "val_loss": 75.16724467277527, "val_acc": 72.0}
{"epoch": 45, "training_loss": 356.2643184661865, "training_acc": 72.0, "val_loss": 83.35949778556824, "val_acc": 72.0}
{"epoch": 46, "training_loss": 197.55640864372253, "training_acc": 68.0, "val_loss": 81.06698989868164, "val_acc": 28.0}
{"epoch": 47, "training_loss": 328.88008403778076, "training_acc": 46.0, "val_loss": 161.95217370986938, "val_acc": 72.0}
