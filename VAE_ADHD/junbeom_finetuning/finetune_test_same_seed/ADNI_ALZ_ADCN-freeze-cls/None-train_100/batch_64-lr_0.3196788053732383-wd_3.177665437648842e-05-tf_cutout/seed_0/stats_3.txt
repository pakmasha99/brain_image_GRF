"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1692.1670761108398, "training_acc": 40.0, "val_loss": 794.8814392089844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2414.522735595703, "training_acc": 72.0, "val_loss": 567.2553539276123, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2125.018684387207, "training_acc": 28.0, "val_loss": 183.21255445480347, "val_acc": 72.0}
{"epoch": 3, "training_loss": 954.3323707580566, "training_acc": 72.0, "val_loss": 464.2773151397705, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1814.2659950256348, "training_acc": 72.0, "val_loss": 319.00622844696045, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1023.4160537719727, "training_acc": 72.0, "val_loss": 340.2514457702637, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1292.4884872436523, "training_acc": 28.0, "val_loss": 79.30696606636047, "val_acc": 72.0}
{"epoch": 7, "training_loss": 356.1272621154785, "training_acc": 72.0, "val_loss": 180.75032234191895, "val_acc": 72.0}
{"epoch": 8, "training_loss": 656.6177101135254, "training_acc": 72.0, "val_loss": 21.813909709453583, "val_acc": 72.0}
{"epoch": 9, "training_loss": 854.7170791625977, "training_acc": 44.0, "val_loss": 294.52788829803467, "val_acc": 28.0}
{"epoch": 10, "training_loss": 927.1033515930176, "training_acc": 42.0, "val_loss": 225.4516839981079, "val_acc": 72.0}
{"epoch": 11, "training_loss": 969.4318542480469, "training_acc": 72.0, "val_loss": 253.25822830200195, "val_acc": 72.0}
{"epoch": 12, "training_loss": 900.1638622283936, "training_acc": 72.0, "val_loss": 30.122491717338562, "val_acc": 72.0}
{"epoch": 13, "training_loss": 470.79108810424805, "training_acc": 66.0, "val_loss": 392.8180694580078, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1072.6026046276093, "training_acc": 41.0, "val_loss": 176.18768215179443, "val_acc": 72.0}
{"epoch": 15, "training_loss": 822.9798393249512, "training_acc": 72.0, "val_loss": 296.8289613723755, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1133.255283355713, "training_acc": 72.0, "val_loss": 160.896897315979, "val_acc": 72.0}
{"epoch": 17, "training_loss": 389.5483729839325, "training_acc": 72.0, "val_loss": 366.40625, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1357.0409927368164, "training_acc": 28.0, "val_loss": 75.49195885658264, "val_acc": 72.0}
{"epoch": 19, "training_loss": 501.2247200012207, "training_acc": 72.0, "val_loss": 223.905611038208, "val_acc": 72.0}
{"epoch": 20, "training_loss": 846.903564453125, "training_acc": 72.0, "val_loss": 94.92533802986145, "val_acc": 72.0}
{"epoch": 21, "training_loss": 453.283655166626, "training_acc": 54.0, "val_loss": 38.45130205154419, "val_acc": 28.0}
{"epoch": 22, "training_loss": 314.10674476623535, "training_acc": 44.0, "val_loss": 238.2699489593506, "val_acc": 72.0}
{"epoch": 23, "training_loss": 976.3015327453613, "training_acc": 72.0, "val_loss": 209.81547832489014, "val_acc": 72.0}
{"epoch": 24, "training_loss": 688.3672142028809, "training_acc": 72.0, "val_loss": 130.4107666015625, "val_acc": 28.0}
{"epoch": 25, "training_loss": 472.14776039123535, "training_acc": 28.0, "val_loss": 140.56189060211182, "val_acc": 72.0}
{"epoch": 26, "training_loss": 724.4183464050293, "training_acc": 72.0, "val_loss": 272.25706577301025, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1034.088279724121, "training_acc": 72.0, "val_loss": 140.07995128631592, "val_acc": 72.0}
