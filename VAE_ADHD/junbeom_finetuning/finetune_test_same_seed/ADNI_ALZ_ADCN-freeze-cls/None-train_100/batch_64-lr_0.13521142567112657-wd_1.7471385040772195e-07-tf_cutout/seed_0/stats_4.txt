"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 855.2696685791016, "training_acc": 36.0, "val_loss": 337.89830207824707, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1125.2234745025635, "training_acc": 72.0, "val_loss": 166.23061895370483, "val_acc": 28.0}
{"epoch": 2, "training_loss": 516.988697052002, "training_acc": 28.0, "val_loss": 127.57809162139893, "val_acc": 72.0}
{"epoch": 3, "training_loss": 678.3857574462891, "training_acc": 72.0, "val_loss": 236.45613193511963, "val_acc": 72.0}
{"epoch": 4, "training_loss": 908.2725925445557, "training_acc": 72.0, "val_loss": 143.65628957748413, "val_acc": 72.0}
{"epoch": 5, "training_loss": 407.2598476409912, "training_acc": 72.0, "val_loss": 194.4321870803833, "val_acc": 28.0}
{"epoch": 6, "training_loss": 817.2752571105957, "training_acc": 28.0, "val_loss": 44.004687666893005, "val_acc": 28.0}
{"epoch": 7, "training_loss": 251.9082841873169, "training_acc": 46.0, "val_loss": 196.76200151443481, "val_acc": 72.0}
{"epoch": 8, "training_loss": 854.9950332641602, "training_acc": 72.0, "val_loss": 256.6662788391113, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1000.1962509155273, "training_acc": 72.0, "val_loss": 191.52642488479614, "val_acc": 72.0}
{"epoch": 10, "training_loss": 677.3000497817993, "training_acc": 72.0, "val_loss": 20.79571932554245, "val_acc": 72.0}
{"epoch": 11, "training_loss": 366.2960433959961, "training_acc": 58.0, "val_loss": 280.95011711120605, "val_acc": 28.0}
{"epoch": 12, "training_loss": 944.428918838501, "training_acc": 28.0, "val_loss": 58.804136514663696, "val_acc": 72.0}
{"epoch": 13, "training_loss": 312.75953483581543, "training_acc": 72.0, "val_loss": 166.8443202972412, "val_acc": 72.0}
{"epoch": 14, "training_loss": 677.2022895812988, "training_acc": 72.0, "val_loss": 156.9021463394165, "val_acc": 72.0}
{"epoch": 15, "training_loss": 565.7401218414307, "training_acc": 72.0, "val_loss": 46.957311034202576, "val_acc": 72.0}
{"epoch": 16, "training_loss": 348.1757125854492, "training_acc": 48.0, "val_loss": 126.14268064498901, "val_acc": 28.0}
{"epoch": 17, "training_loss": 319.2813090085983, "training_acc": 50.0, "val_loss": 63.4668231010437, "val_acc": 72.0}
{"epoch": 18, "training_loss": 279.25310039520264, "training_acc": 72.0, "val_loss": 77.52653360366821, "val_acc": 72.0}
{"epoch": 19, "training_loss": 277.7730133533478, "training_acc": 72.0, "val_loss": 31.16728961467743, "val_acc": 28.0}
{"epoch": 20, "training_loss": 111.49555444717407, "training_acc": 28.0, "val_loss": 36.55560314655304, "val_acc": 72.0}
{"epoch": 21, "training_loss": 169.37491512298584, "training_acc": 72.0, "val_loss": 30.890953540802002, "val_acc": 72.0}
{"epoch": 22, "training_loss": 132.9690899848938, "training_acc": 56.0, "val_loss": 14.917309582233429, "val_acc": 72.0}
{"epoch": 23, "training_loss": 88.2292275428772, "training_acc": 72.0, "val_loss": 22.68638163805008, "val_acc": 72.0}
{"epoch": 24, "training_loss": 72.81296277046204, "training_acc": 64.0, "val_loss": 21.74219787120819, "val_acc": 28.0}
{"epoch": 25, "training_loss": 86.75021362304688, "training_acc": 48.0, "val_loss": 36.555689573287964, "val_acc": 72.0}
{"epoch": 26, "training_loss": 120.94018149375916, "training_acc": 72.0, "val_loss": 53.72617840766907, "val_acc": 28.0}
{"epoch": 27, "training_loss": 155.52085852622986, "training_acc": 46.0, "val_loss": 31.729036569595337, "val_acc": 72.0}
{"epoch": 28, "training_loss": 115.0627453327179, "training_acc": 72.0, "val_loss": 26.419681310653687, "val_acc": 28.0}
{"epoch": 29, "training_loss": 78.01632869243622, "training_acc": 56.0, "val_loss": 38.265204429626465, "val_acc": 72.0}
{"epoch": 30, "training_loss": 157.9592523574829, "training_acc": 72.0, "val_loss": 16.676998138427734, "val_acc": 72.0}
{"epoch": 31, "training_loss": 136.02003574371338, "training_acc": 58.0, "val_loss": 14.584487676620483, "val_acc": 72.0}
{"epoch": 32, "training_loss": 102.94022226333618, "training_acc": 72.0, "val_loss": 35.37122905254364, "val_acc": 72.0}
{"epoch": 33, "training_loss": 112.55035877227783, "training_acc": 72.0, "val_loss": 40.272456407547, "val_acc": 28.0}
{"epoch": 34, "training_loss": 158.02491664886475, "training_acc": 42.0, "val_loss": 46.300697326660156, "val_acc": 72.0}
{"epoch": 35, "training_loss": 163.47281742095947, "training_acc": 72.0, "val_loss": 38.20140063762665, "val_acc": 28.0}
{"epoch": 36, "training_loss": 128.10682082176208, "training_acc": 38.0, "val_loss": 17.796558141708374, "val_acc": 72.0}
{"epoch": 37, "training_loss": 70.2849133014679, "training_acc": 72.0, "val_loss": 14.837710559368134, "val_acc": 72.0}
{"epoch": 38, "training_loss": 61.372795820236206, "training_acc": 72.0, "val_loss": 18.804456293582916, "val_acc": 72.0}
{"epoch": 39, "training_loss": 70.68042802810669, "training_acc": 72.0, "val_loss": 15.847484767436981, "val_acc": 28.0}
{"epoch": 40, "training_loss": 78.68406438827515, "training_acc": 72.0, "val_loss": 14.969752728939056, "val_acc": 72.0}
{"epoch": 41, "training_loss": 67.72845935821533, "training_acc": 54.0, "val_loss": 29.02734875679016, "val_acc": 72.0}
{"epoch": 42, "training_loss": 112.13780546188354, "training_acc": 72.0, "val_loss": 16.27260595560074, "val_acc": 28.0}
{"epoch": 43, "training_loss": 79.63794040679932, "training_acc": 54.0, "val_loss": 42.933398485183716, "val_acc": 72.0}
{"epoch": 44, "training_loss": 187.28547763824463, "training_acc": 72.0, "val_loss": 39.2904669046402, "val_acc": 72.0}
{"epoch": 45, "training_loss": 116.50368881225586, "training_acc": 60.0, "val_loss": 36.14685833454132, "val_acc": 28.0}
{"epoch": 46, "training_loss": 160.69409799575806, "training_acc": 42.0, "val_loss": 58.88814330101013, "val_acc": 72.0}
{"epoch": 47, "training_loss": 216.08293271064758, "training_acc": 72.0, "val_loss": 17.96206682920456, "val_acc": 28.0}
{"epoch": 48, "training_loss": 91.44971656799316, "training_acc": 30.0, "val_loss": 45.155203342437744, "val_acc": 72.0}
{"epoch": 49, "training_loss": 207.37673664093018, "training_acc": 72.0, "val_loss": 50.91060400009155, "val_acc": 72.0}
{"epoch": 50, "training_loss": 135.30307030677795, "training_acc": 72.0, "val_loss": 124.52867031097412, "val_acc": 28.0}
