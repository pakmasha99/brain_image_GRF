"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 563.823314666748, "training_acc": 72.0, "val_loss": 335.6374740600586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1066.6562595367432, "training_acc": 72.0, "val_loss": 382.6896905899048, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1336.4024238586426, "training_acc": 28.0, "val_loss": 72.42578864097595, "val_acc": 72.0}
{"epoch": 3, "training_loss": 385.2135200500488, "training_acc": 72.0, "val_loss": 190.7188057899475, "val_acc": 72.0}
{"epoch": 4, "training_loss": 740.4423027038574, "training_acc": 72.0, "val_loss": 117.91566610336304, "val_acc": 72.0}
{"epoch": 5, "training_loss": 340.1495671272278, "training_acc": 72.0, "val_loss": 242.61236190795898, "val_acc": 28.0}
{"epoch": 6, "training_loss": 945.2323017120361, "training_acc": 28.0, "val_loss": 25.242656469345093, "val_acc": 28.0}
{"epoch": 7, "training_loss": 189.53907299041748, "training_acc": 48.0, "val_loss": 190.83776473999023, "val_acc": 72.0}
{"epoch": 8, "training_loss": 803.9329471588135, "training_acc": 72.0, "val_loss": 232.14271068572998, "val_acc": 72.0}
{"epoch": 9, "training_loss": 896.4765930175781, "training_acc": 72.0, "val_loss": 148.56094121932983, "val_acc": 72.0}
{"epoch": 10, "training_loss": 458.0757169723511, "training_acc": 72.0, "val_loss": 81.39259815216064, "val_acc": 28.0}
{"epoch": 11, "training_loss": 378.4230480194092, "training_acc": 28.0, "val_loss": 18.121223151683807, "val_acc": 72.0}
{"epoch": 12, "training_loss": 129.24166202545166, "training_acc": 72.0, "val_loss": 56.97973370552063, "val_acc": 72.0}
{"epoch": 13, "training_loss": 188.12040519714355, "training_acc": 72.0, "val_loss": 54.577070474624634, "val_acc": 28.0}
{"epoch": 14, "training_loss": 170.10440015792847, "training_acc": 28.0, "val_loss": 42.15961992740631, "val_acc": 72.0}
{"epoch": 15, "training_loss": 182.1817650794983, "training_acc": 72.0, "val_loss": 36.79623305797577, "val_acc": 72.0}
{"epoch": 16, "training_loss": 149.5683045387268, "training_acc": 52.0, "val_loss": 14.671938121318817, "val_acc": 72.0}
{"epoch": 17, "training_loss": 77.39071655273438, "training_acc": 72.0, "val_loss": 14.805515110492706, "val_acc": 72.0}
{"epoch": 18, "training_loss": 77.45947360992432, "training_acc": 58.0, "val_loss": 24.98418688774109, "val_acc": 72.0}
{"epoch": 19, "training_loss": 112.1886076927185, "training_acc": 72.0, "val_loss": 14.735646545886993, "val_acc": 72.0}
{"epoch": 20, "training_loss": 105.25819873809814, "training_acc": 54.0, "val_loss": 32.19132423400879, "val_acc": 72.0}
{"epoch": 21, "training_loss": 143.34683847427368, "training_acc": 72.0, "val_loss": 33.96245241165161, "val_acc": 72.0}
{"epoch": 22, "training_loss": 184.56703853607178, "training_acc": 44.0, "val_loss": 22.1608504652977, "val_acc": 72.0}
{"epoch": 23, "training_loss": 99.29492044448853, "training_acc": 72.0, "val_loss": 15.176263451576233, "val_acc": 72.0}
{"epoch": 24, "training_loss": 122.9042911529541, "training_acc": 52.0, "val_loss": 26.47707760334015, "val_acc": 72.0}
{"epoch": 25, "training_loss": 127.70368528366089, "training_acc": 72.0, "val_loss": 28.283515572547913, "val_acc": 72.0}
{"epoch": 26, "training_loss": 153.18042993545532, "training_acc": 50.0, "val_loss": 18.265187740325928, "val_acc": 72.0}
{"epoch": 27, "training_loss": 81.56567311286926, "training_acc": 72.0, "val_loss": 15.011289715766907, "val_acc": 72.0}
{"epoch": 28, "training_loss": 88.3215708732605, "training_acc": 56.0, "val_loss": 26.242849230766296, "val_acc": 72.0}
{"epoch": 29, "training_loss": 105.34133172035217, "training_acc": 72.0, "val_loss": 17.21806526184082, "val_acc": 72.0}
{"epoch": 30, "training_loss": 98.92656564712524, "training_acc": 56.0, "val_loss": 22.640548646450043, "val_acc": 72.0}
{"epoch": 31, "training_loss": 95.21824955940247, "training_acc": 72.0, "val_loss": 15.026436746120453, "val_acc": 72.0}
{"epoch": 32, "training_loss": 142.32387447357178, "training_acc": 46.0, "val_loss": 32.66107141971588, "val_acc": 72.0}
{"epoch": 33, "training_loss": 156.58915662765503, "training_acc": 72.0, "val_loss": 45.588016510009766, "val_acc": 72.0}
{"epoch": 34, "training_loss": 139.65841603279114, "training_acc": 72.0, "val_loss": 80.9281587600708, "val_acc": 28.0}
{"epoch": 35, "training_loss": 224.0630807876587, "training_acc": 28.0, "val_loss": 57.967835664749146, "val_acc": 72.0}
