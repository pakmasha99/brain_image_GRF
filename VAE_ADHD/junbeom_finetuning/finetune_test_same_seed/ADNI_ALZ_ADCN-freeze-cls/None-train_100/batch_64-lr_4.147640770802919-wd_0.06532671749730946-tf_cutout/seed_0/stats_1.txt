"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14244.19690322876, "training_acc": 72.0, "val_loss": 5985.25276184082, "val_acc": 72.0}
{"epoch": 1, "training_loss": 23251.234619140625, "training_acc": 60.0, "val_loss": 1477.5723457336426, "val_acc": 72.0}
{"epoch": 2, "training_loss": 5783.628845214844, "training_acc": 72.0, "val_loss": 1667.538833618164, "val_acc": 28.0}
{"epoch": 3, "training_loss": 6764.457672119141, "training_acc": 48.0, "val_loss": 2929.171562194824, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10747.723365783691, "training_acc": 72.0, "val_loss": 1232.9560279846191, "val_acc": 28.0}
{"epoch": 5, "training_loss": 5593.089599609375, "training_acc": 44.0, "val_loss": 1884.6942901611328, "val_acc": 72.0}
{"epoch": 6, "training_loss": 6119.421142578125, "training_acc": 72.0, "val_loss": 2833.9576721191406, "val_acc": 28.0}
{"epoch": 7, "training_loss": 8084.500473022461, "training_acc": 44.0, "val_loss": 651.5544414520264, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4117.536437988281, "training_acc": 50.0, "val_loss": 1471.168327331543, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6250.458755493164, "training_acc": 72.0, "val_loss": 1066.456413269043, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4021.0352325439453, "training_acc": 56.0, "val_loss": 1055.3505897521973, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4054.3215942382812, "training_acc": 72.0, "val_loss": 205.26785850524902, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4589.707061767578, "training_acc": 56.0, "val_loss": 317.60575771331787, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1239.1193885803223, "training_acc": 72.0, "val_loss": 1067.3493385314941, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3183.627212524414, "training_acc": 54.0, "val_loss": 1586.0827445983887, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5590.806427001953, "training_acc": 72.0, "val_loss": 448.974084854126, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2864.9226837158203, "training_acc": 44.0, "val_loss": 1257.3713302612305, "val_acc": 72.0}
{"epoch": 17, "training_loss": 3972.8254776000977, "training_acc": 72.0, "val_loss": 2456.291961669922, "val_acc": 28.0}
{"epoch": 18, "training_loss": 7301.589691162109, "training_acc": 40.0, "val_loss": 373.7941265106201, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2545.013214111328, "training_acc": 58.0, "val_loss": 1016.7403221130371, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4353.169403076172, "training_acc": 72.0, "val_loss": 397.4308729171753, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4965.120330810547, "training_acc": 54.0, "val_loss": 264.07787799835205, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1095.0284614562988, "training_acc": 72.0, "val_loss": 1287.136173248291, "val_acc": 28.0}
{"epoch": 23, "training_loss": 4498.368103027344, "training_acc": 46.0, "val_loss": 1247.5778579711914, "val_acc": 72.0}
{"epoch": 24, "training_loss": 4070.9479446411133, "training_acc": 72.0, "val_loss": 1740.6906127929688, "val_acc": 28.0}
{"epoch": 25, "training_loss": 5068.623382568359, "training_acc": 46.0, "val_loss": 647.133207321167, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1421.1257288455963, "training_acc": 72.0, "val_loss": 3110.903739929199, "val_acc": 28.0}
{"epoch": 27, "training_loss": 7818.931950569153, "training_acc": 46.0, "val_loss": 158.909273147583, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3093.6621704101562, "training_acc": 52.0, "val_loss": 1023.6153602600098, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4251.638977050781, "training_acc": 72.0, "val_loss": 697.9113101959229, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3765.929489135742, "training_acc": 54.0, "val_loss": 874.9646186828613, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3547.2942657470703, "training_acc": 72.0, "val_loss": 200.68113803863525, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4165.585662841797, "training_acc": 58.0, "val_loss": 160.53540706634521, "val_acc": 72.0}
{"epoch": 33, "training_loss": 768.0728912353516, "training_acc": 72.0, "val_loss": 1727.6647567749023, "val_acc": 28.0}
{"epoch": 34, "training_loss": 5527.563369750977, "training_acc": 44.0, "val_loss": 932.4575424194336, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2703.646251678467, "training_acc": 72.0, "val_loss": 2716.738510131836, "val_acc": 28.0}
{"epoch": 36, "training_loss": 7953.347587585449, "training_acc": 38.0, "val_loss": 171.309232711792, "val_acc": 72.0}
{"epoch": 37, "training_loss": 4336.797271728516, "training_acc": 48.0, "val_loss": 766.2312984466553, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3586.7664794921875, "training_acc": 72.0, "val_loss": 433.47182273864746, "val_acc": 72.0}
{"epoch": 39, "training_loss": 5545.65673828125, "training_acc": 48.0, "val_loss": 438.55957984924316, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2263.3628540039062, "training_acc": 72.0, "val_loss": 328.2616138458252, "val_acc": 28.0}
{"epoch": 41, "training_loss": 2442.8847045898438, "training_acc": 46.0, "val_loss": 1453.7787437438965, "val_acc": 72.0}
{"epoch": 42, "training_loss": 4832.457763671875, "training_acc": 72.0, "val_loss": 1238.2477760314941, "val_acc": 28.0}
{"epoch": 43, "training_loss": 3731.884635925293, "training_acc": 48.0, "val_loss": 709.3547344207764, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1749.5671846866608, "training_acc": 72.0, "val_loss": 2507.3896408081055, "val_acc": 28.0}
{"epoch": 45, "training_loss": 6260.66997718811, "training_acc": 50.0, "val_loss": 545.859432220459, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1433.68248462677, "training_acc": 58.0, "val_loss": 1485.0411415100098, "val_acc": 72.0}
