"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14246.972671508789, "training_acc": 48.0, "val_loss": 7757.756805419922, "val_acc": 72.0}
{"epoch": 1, "training_loss": 21875.504180908203, "training_acc": 56.0, "val_loss": 3404.146957397461, "val_acc": 72.0}
{"epoch": 2, "training_loss": 13246.499450683594, "training_acc": 72.0, "val_loss": 1179.3258666992188, "val_acc": 72.0}
{"epoch": 3, "training_loss": 10816.438293457031, "training_acc": 54.0, "val_loss": 385.12823581695557, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1416.8739681243896, "training_acc": 72.0, "val_loss": 1898.3348846435547, "val_acc": 28.0}
{"epoch": 5, "training_loss": 6051.290481567383, "training_acc": 50.0, "val_loss": 2138.3119583129883, "val_acc": 72.0}
{"epoch": 6, "training_loss": 7396.417633056641, "training_acc": 72.0, "val_loss": 867.6003456115723, "val_acc": 28.0}
{"epoch": 7, "training_loss": 4694.710601806641, "training_acc": 40.0, "val_loss": 1284.375, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3650.453769683838, "training_acc": 72.0, "val_loss": 3875.534439086914, "val_acc": 28.0}
{"epoch": 9, "training_loss": 10188.650299072266, "training_acc": 28.0, "val_loss": 3048.6751556396484, "val_acc": 72.0}
{"epoch": 10, "training_loss": 13620.849609375, "training_acc": 72.0, "val_loss": 4017.927932739258, "val_acc": 72.0}
{"epoch": 11, "training_loss": 14609.951934814453, "training_acc": 72.0, "val_loss": 1290.0854110717773, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4944.452346801758, "training_acc": 60.0, "val_loss": 272.979736328125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 797.9786138534546, "training_acc": 56.0, "val_loss": 1845.1423645019531, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7881.195068359375, "training_acc": 72.0, "val_loss": 1551.6663551330566, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4331.9854736328125, "training_acc": 72.0, "val_loss": 3754.267120361328, "val_acc": 28.0}
{"epoch": 16, "training_loss": 11077.196762084961, "training_acc": 28.0, "val_loss": 2332.023811340332, "val_acc": 72.0}
{"epoch": 17, "training_loss": 10986.154846191406, "training_acc": 72.0, "val_loss": 2900.874900817871, "val_acc": 72.0}
{"epoch": 18, "training_loss": 9854.279815673828, "training_acc": 72.0, "val_loss": 128.13979387283325, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8852.864715576172, "training_acc": 48.0, "val_loss": 2281.2171936035156, "val_acc": 28.0}
{"epoch": 20, "training_loss": 10782.51480102539, "training_acc": 34.0, "val_loss": 2728.951835632324, "val_acc": 72.0}
{"epoch": 21, "training_loss": 10370.845123291016, "training_acc": 72.0, "val_loss": 1275.5949020385742, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4217.4079513549805, "training_acc": 56.0, "val_loss": 748.717451095581, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2739.636474609375, "training_acc": 72.0, "val_loss": 629.6832084655762, "val_acc": 28.0}
{"epoch": 24, "training_loss": 3918.752975463867, "training_acc": 40.0, "val_loss": 1384.8225593566895, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4360.662063598633, "training_acc": 72.0, "val_loss": 1753.8969039916992, "val_acc": 28.0}
{"epoch": 26, "training_loss": 5174.948348999023, "training_acc": 42.0, "val_loss": 235.20662784576416, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2179.1243743896484, "training_acc": 62.0, "val_loss": 760.7671737670898, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3182.524871826172, "training_acc": 72.0, "val_loss": 50.35766959190369, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3506.700927734375, "training_acc": 64.0, "val_loss": 287.5673532485962, "val_acc": 28.0}
{"epoch": 30, "training_loss": 3843.0209350585938, "training_acc": 46.0, "val_loss": 3367.0589447021484, "val_acc": 72.0}
{"epoch": 31, "training_loss": 13081.587310791016, "training_acc": 72.0, "val_loss": 2128.818893432617, "val_acc": 72.0}
{"epoch": 32, "training_loss": 6198.726821899414, "training_acc": 72.0, "val_loss": 2713.924217224121, "val_acc": 28.0}
{"epoch": 33, "training_loss": 7919.93830871582, "training_acc": 28.0, "val_loss": 2275.7875442504883, "val_acc": 72.0}
{"epoch": 34, "training_loss": 9706.652252197266, "training_acc": 72.0, "val_loss": 2927.212905883789, "val_acc": 72.0}
{"epoch": 35, "training_loss": 10367.826477050781, "training_acc": 72.0, "val_loss": 620.8723068237305, "val_acc": 72.0}
{"epoch": 36, "training_loss": 5413.033630371094, "training_acc": 58.0, "val_loss": 681.6697120666504, "val_acc": 28.0}
{"epoch": 37, "training_loss": 5789.412658691406, "training_acc": 40.0, "val_loss": 3050.7619857788086, "val_acc": 72.0}
{"epoch": 38, "training_loss": 11697.674713134766, "training_acc": 72.0, "val_loss": 1626.9393920898438, "val_acc": 72.0}
{"epoch": 39, "training_loss": 4459.151248931885, "training_acc": 72.0, "val_loss": 3909.7702026367188, "val_acc": 28.0}
{"epoch": 40, "training_loss": 12288.706008911133, "training_acc": 28.0, "val_loss": 1950.6572723388672, "val_acc": 72.0}
{"epoch": 41, "training_loss": 9439.361389160156, "training_acc": 72.0, "val_loss": 2552.900505065918, "val_acc": 72.0}
{"epoch": 42, "training_loss": 8667.510299682617, "training_acc": 72.0, "val_loss": 91.27644896507263, "val_acc": 28.0}
{"epoch": 43, "training_loss": 865.1091384887695, "training_acc": 52.0, "val_loss": 808.9995384216309, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2046.0479927062988, "training_acc": 72.0, "val_loss": 3226.4820098876953, "val_acc": 28.0}
{"epoch": 45, "training_loss": 8923.127866744995, "training_acc": 28.0, "val_loss": 2487.0580673217773, "val_acc": 72.0}
{"epoch": 46, "training_loss": 11311.270629882812, "training_acc": 72.0, "val_loss": 3008.3797454833984, "val_acc": 72.0}
{"epoch": 47, "training_loss": 10686.20654296875, "training_acc": 72.0, "val_loss": 402.106237411499, "val_acc": 72.0}
