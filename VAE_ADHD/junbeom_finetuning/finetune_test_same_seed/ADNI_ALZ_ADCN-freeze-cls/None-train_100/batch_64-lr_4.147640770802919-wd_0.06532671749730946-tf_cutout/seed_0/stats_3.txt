"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19644.905876159668, "training_acc": 72.0, "val_loss": 6521.3897705078125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 21035.93603515625, "training_acc": 58.0, "val_loss": 2158.7656021118164, "val_acc": 72.0}
{"epoch": 2, "training_loss": 8373.595123291016, "training_acc": 72.0, "val_loss": 481.7500114440918, "val_acc": 28.0}
{"epoch": 3, "training_loss": 4032.4671325683594, "training_acc": 48.0, "val_loss": 2929.7624588012695, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9992.990463256836, "training_acc": 72.0, "val_loss": 1400.9297370910645, "val_acc": 28.0}
{"epoch": 5, "training_loss": 6564.474456787109, "training_acc": 38.0, "val_loss": 1267.7477836608887, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5575.030471801758, "training_acc": 46.0, "val_loss": 1739.9938583374023, "val_acc": 72.0}
{"epoch": 7, "training_loss": 7215.772415161133, "training_acc": 72.0, "val_loss": 1305.8939933776855, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4582.341262817383, "training_acc": 52.0, "val_loss": 1301.954460144043, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5244.775344848633, "training_acc": 72.0, "val_loss": 535.3250503540039, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3577.2349853515625, "training_acc": 62.0, "val_loss": 415.7867908477783, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1440.568996310234, "training_acc": 72.0, "val_loss": 1319.5588111877441, "val_acc": 28.0}
{"epoch": 12, "training_loss": 5511.357223510742, "training_acc": 42.0, "val_loss": 1587.8207206726074, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5797.6428146362305, "training_acc": 72.0, "val_loss": 931.5682411193848, "val_acc": 28.0}
{"epoch": 14, "training_loss": 4208.20426940918, "training_acc": 42.0, "val_loss": 1205.9284210205078, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3685.862663269043, "training_acc": 72.0, "val_loss": 2399.220848083496, "val_acc": 28.0}
{"epoch": 16, "training_loss": 6296.765087127686, "training_acc": 46.0, "val_loss": 284.1573476791382, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1350.142318725586, "training_acc": 66.0, "val_loss": 1032.5566291809082, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4335.105453491211, "training_acc": 72.0, "val_loss": 244.4136619567871, "val_acc": 72.0}
{"epoch": 19, "training_loss": 5370.415344238281, "training_acc": 54.0, "val_loss": 17.573966085910797, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3088.4412803649902, "training_acc": 48.0, "val_loss": 1649.161720275879, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5306.050857543945, "training_acc": 72.0, "val_loss": 1488.228702545166, "val_acc": 28.0}
{"epoch": 22, "training_loss": 4327.87922668457, "training_acc": 46.0, "val_loss": 444.16661262512207, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2042.7933654785156, "training_acc": 60.0, "val_loss": 1107.0928573608398, "val_acc": 72.0}
{"epoch": 24, "training_loss": 4442.289627075195, "training_acc": 72.0, "val_loss": 467.9844379425049, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4454.16552734375, "training_acc": 54.0, "val_loss": 476.6110897064209, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1979.7028045654297, "training_acc": 72.0, "val_loss": 616.9965744018555, "val_acc": 28.0}
{"epoch": 27, "training_loss": 3406.706512451172, "training_acc": 44.0, "val_loss": 1471.7873573303223, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4873.064071655273, "training_acc": 72.0, "val_loss": 1318.6908721923828, "val_acc": 28.0}
{"epoch": 29, "training_loss": 3913.9676361083984, "training_acc": 48.0, "val_loss": 700.4806518554688, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1739.5039601325989, "training_acc": 58.0, "val_loss": 857.4830055236816, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3067.89884185791, "training_acc": 72.0, "val_loss": 957.375431060791, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3926.019302368164, "training_acc": 44.0, "val_loss": 1149.8208045959473, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3567.3813438415527, "training_acc": 72.0, "val_loss": 2323.9625930786133, "val_acc": 28.0}
{"epoch": 34, "training_loss": 6675.488800048828, "training_acc": 42.0, "val_loss": 361.3682270050049, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2658.2009887695312, "training_acc": 56.0, "val_loss": 1043.705940246582, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4269.162994384766, "training_acc": 72.0, "val_loss": 524.0195751190186, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2949.983901977539, "training_acc": 62.0, "val_loss": 564.3753528594971, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2207.233528137207, "training_acc": 72.0, "val_loss": 957.4799537658691, "val_acc": 28.0}
