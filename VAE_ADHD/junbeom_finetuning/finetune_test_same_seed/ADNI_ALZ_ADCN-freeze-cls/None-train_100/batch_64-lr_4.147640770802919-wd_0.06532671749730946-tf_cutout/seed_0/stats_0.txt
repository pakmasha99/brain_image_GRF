"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19579.42007446289, "training_acc": 42.0, "val_loss": 7331.8023681640625, "val_acc": 72.0}
{"epoch": 1, "training_loss": 16799.71712589264, "training_acc": 60.0, "val_loss": 2383.186149597168, "val_acc": 72.0}
{"epoch": 2, "training_loss": 7829.329002380371, "training_acc": 72.0, "val_loss": 5070.864105224609, "val_acc": 28.0}
{"epoch": 3, "training_loss": 14654.360824584961, "training_acc": 44.0, "val_loss": 1560.69917678833, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4287.3447265625, "training_acc": 72.0, "val_loss": 5242.629623413086, "val_acc": 28.0}
{"epoch": 5, "training_loss": 13691.143264770508, "training_acc": 28.0, "val_loss": 3777.895736694336, "val_acc": 72.0}
{"epoch": 6, "training_loss": 17248.072387695312, "training_acc": 72.0, "val_loss": 5075.029754638672, "val_acc": 72.0}
{"epoch": 7, "training_loss": 18811.737579345703, "training_acc": 72.0, "val_loss": 1819.1577911376953, "val_acc": 72.0}
{"epoch": 8, "training_loss": 5673.881423950195, "training_acc": 58.0, "val_loss": 678.9609432220459, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2265.696071624756, "training_acc": 72.0, "val_loss": 1867.0417785644531, "val_acc": 28.0}
{"epoch": 10, "training_loss": 6199.923843383789, "training_acc": 44.0, "val_loss": 1221.4689254760742, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3761.7606887817383, "training_acc": 72.0, "val_loss": 2522.4212646484375, "val_acc": 28.0}
{"epoch": 12, "training_loss": 6720.637580871582, "training_acc": 46.0, "val_loss": 403.6505699157715, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3896.9085998535156, "training_acc": 48.0, "val_loss": 1213.601016998291, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5607.974456787109, "training_acc": 72.0, "val_loss": 918.6113357543945, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3239.8125, "training_acc": 60.0, "val_loss": 807.6625823974609, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3236.5171661376953, "training_acc": 72.0, "val_loss": 464.84007835388184, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2221.6342697143555, "training_acc": 50.0, "val_loss": 1375.6034851074219, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4495.698013305664, "training_acc": 72.0, "val_loss": 1530.6397438049316, "val_acc": 28.0}
{"epoch": 19, "training_loss": 4082.1440200805664, "training_acc": 50.0, "val_loss": 529.3342113494873, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2499.1564712524414, "training_acc": 54.0, "val_loss": 1339.3754959106445, "val_acc": 72.0}
{"epoch": 21, "training_loss": 6035.843994140625, "training_acc": 72.0, "val_loss": 870.0286865234375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4135.22184753418, "training_acc": 56.0, "val_loss": 650.5129337310791, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2483.211181640625, "training_acc": 72.0, "val_loss": 581.2783241271973, "val_acc": 28.0}
{"epoch": 24, "training_loss": 3323.426071166992, "training_acc": 44.0, "val_loss": 1470.8273887634277, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4829.632553100586, "training_acc": 72.0, "val_loss": 1359.370231628418, "val_acc": 28.0}
{"epoch": 26, "training_loss": 4169.696701049805, "training_acc": 46.0, "val_loss": 623.259449005127, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2245.4638671875, "training_acc": 56.0, "val_loss": 1333.6122512817383, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5495.23876953125, "training_acc": 72.0, "val_loss": 801.3875961303711, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3732.85693359375, "training_acc": 56.0, "val_loss": 772.0772743225098, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2951.6987915039062, "training_acc": 72.0, "val_loss": 42.882758378982544, "val_acc": 28.0}
{"epoch": 31, "training_loss": 3094.4363403320312, "training_acc": 36.0, "val_loss": 1350.3985404968262, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4253.063465118408, "training_acc": 72.0, "val_loss": 2440.569305419922, "val_acc": 28.0}
{"epoch": 33, "training_loss": 6143.797328948975, "training_acc": 48.0, "val_loss": 258.59482288360596, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1910.0869445800781, "training_acc": 60.0, "val_loss": 1070.8608627319336, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4484.027572631836, "training_acc": 72.0, "val_loss": 493.5609817504883, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4551.678009033203, "training_acc": 54.0, "val_loss": 427.4500846862793, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2121.603973388672, "training_acc": 72.0, "val_loss": 872.8621482849121, "val_acc": 28.0}
{"epoch": 38, "training_loss": 3976.834487915039, "training_acc": 42.0, "val_loss": 1133.3014488220215, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3318.3466567993164, "training_acc": 72.0, "val_loss": 2513.3691787719727, "val_acc": 28.0}
{"epoch": 40, "training_loss": 6971.380184173584, "training_acc": 40.0, "val_loss": 67.75131821632385, "val_acc": 28.0}
{"epoch": 41, "training_loss": 3032.7154388427734, "training_acc": 42.0, "val_loss": 2139.7470474243164, "val_acc": 72.0}
{"epoch": 42, "training_loss": 7697.876449584961, "training_acc": 72.0, "val_loss": 298.191499710083, "val_acc": 72.0}
{"epoch": 43, "training_loss": 6270.6182861328125, "training_acc": 52.0, "val_loss": 613.6560916900635, "val_acc": 28.0}
{"epoch": 44, "training_loss": 5085.387908935547, "training_acc": 44.0, "val_loss": 3410.851287841797, "val_acc": 72.0}
{"epoch": 45, "training_loss": 13332.849914550781, "training_acc": 72.0, "val_loss": 2157.674217224121, "val_acc": 72.0}
{"epoch": 46, "training_loss": 6776.556777954102, "training_acc": 72.0, "val_loss": 2986.504364013672, "val_acc": 28.0}
{"epoch": 47, "training_loss": 8519.08617401123, "training_acc": 28.0, "val_loss": 2319.576644897461, "val_acc": 72.0}
{"epoch": 48, "training_loss": 10090.518157958984, "training_acc": 72.0, "val_loss": 2812.116813659668, "val_acc": 72.0}
{"epoch": 49, "training_loss": 9906.482727050781, "training_acc": 72.0, "val_loss": 344.55480575561523, "val_acc": 72.0}
