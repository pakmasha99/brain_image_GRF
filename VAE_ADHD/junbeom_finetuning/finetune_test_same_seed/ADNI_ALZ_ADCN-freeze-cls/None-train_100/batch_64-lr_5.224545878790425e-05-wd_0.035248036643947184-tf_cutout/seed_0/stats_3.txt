"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 74.13599920272827, "training_acc": 28.0, "val_loss": 18.281665444374084, "val_acc": 28.0}
{"epoch": 1, "training_loss": 72.92450404167175, "training_acc": 28.0, "val_loss": 17.99761950969696, "val_acc": 28.0}
{"epoch": 2, "training_loss": 71.80403971672058, "training_acc": 28.0, "val_loss": 17.72695481777191, "val_acc": 28.0}
{"epoch": 3, "training_loss": 70.72656965255737, "training_acc": 28.0, "val_loss": 17.470118403434753, "val_acc": 28.0}
{"epoch": 4, "training_loss": 69.8035900592804, "training_acc": 31.0, "val_loss": 17.22724437713623, "val_acc": 28.0}
{"epoch": 5, "training_loss": 68.7828369140625, "training_acc": 72.0, "val_loss": 17.000313103199005, "val_acc": 28.0}
{"epoch": 6, "training_loss": 67.83416271209717, "training_acc": 72.0, "val_loss": 16.78735315799713, "val_acc": 28.0}
{"epoch": 7, "training_loss": 67.03240251541138, "training_acc": 72.0, "val_loss": 16.58686399459839, "val_acc": 28.0}
{"epoch": 8, "training_loss": 66.19816327095032, "training_acc": 72.0, "val_loss": 16.401688754558563, "val_acc": 28.0}
{"epoch": 9, "training_loss": 65.53950834274292, "training_acc": 72.0, "val_loss": 16.228780150413513, "val_acc": 28.0}
{"epoch": 10, "training_loss": 64.82704734802246, "training_acc": 72.0, "val_loss": 16.070498526096344, "val_acc": 28.0}
{"epoch": 11, "training_loss": 64.2613594532013, "training_acc": 72.0, "val_loss": 15.925592184066772, "val_acc": 28.0}
{"epoch": 12, "training_loss": 63.64850211143494, "training_acc": 72.0, "val_loss": 15.795612335205078, "val_acc": 28.0}
{"epoch": 13, "training_loss": 63.11681270599365, "training_acc": 72.0, "val_loss": 15.677683055400848, "val_acc": 28.0}
{"epoch": 14, "training_loss": 62.71493339538574, "training_acc": 72.0, "val_loss": 15.569789707660675, "val_acc": 28.0}
{"epoch": 15, "training_loss": 62.21685171127319, "training_acc": 72.0, "val_loss": 15.474404394626617, "val_acc": 28.0}
{"epoch": 16, "training_loss": 61.880829095840454, "training_acc": 72.0, "val_loss": 15.388157963752747, "val_acc": 28.0}
{"epoch": 17, "training_loss": 61.568299531936646, "training_acc": 72.0, "val_loss": 15.311917662620544, "val_acc": 76.0}
{"epoch": 18, "training_loss": 61.222309589385986, "training_acc": 72.0, "val_loss": 15.244728326797485, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.9799120426178, "training_acc": 72.0, "val_loss": 15.184475481510162, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.77947163581848, "training_acc": 72.0, "val_loss": 15.13141542673111, "val_acc": 72.0}
{"epoch": 21, "training_loss": 60.53589940071106, "training_acc": 72.0, "val_loss": 15.086527168750763, "val_acc": 72.0}
{"epoch": 22, "training_loss": 60.31525540351868, "training_acc": 72.0, "val_loss": 15.046477317810059, "val_acc": 72.0}
{"epoch": 23, "training_loss": 60.18241810798645, "training_acc": 72.0, "val_loss": 15.01099020242691, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.05308270454407, "training_acc": 72.0, "val_loss": 14.979757368564606, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.91650724411011, "training_acc": 72.0, "val_loss": 14.95242565870285, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.8492169380188, "training_acc": 72.0, "val_loss": 14.929461479187012, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.7386999130249, "training_acc": 72.0, "val_loss": 14.910590648651123, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.65642333030701, "training_acc": 72.0, "val_loss": 14.894440770149231, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.59687924385071, "training_acc": 72.0, "val_loss": 14.880023896694183, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.535040616989136, "training_acc": 72.0, "val_loss": 14.867576956748962, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.545711517333984, "training_acc": 72.0, "val_loss": 14.857451617717743, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.44963836669922, "training_acc": 72.0, "val_loss": 14.849494397640228, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.43623232841492, "training_acc": 72.0, "val_loss": 14.8427814245224, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.41877031326294, "training_acc": 72.0, "val_loss": 14.837107062339783, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.380945920944214, "training_acc": 72.0, "val_loss": 14.833159744739532, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.34266710281372, "training_acc": 72.0, "val_loss": 14.829733967781067, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.36124777793884, "training_acc": 72.0, "val_loss": 14.82677012681961, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.31591463088989, "training_acc": 72.0, "val_loss": 14.824242889881134, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.30267024040222, "training_acc": 72.0, "val_loss": 14.821802079677582, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.33106255531311, "training_acc": 72.0, "val_loss": 14.81936126947403, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.32299065589905, "training_acc": 72.0, "val_loss": 14.81727510690689, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.327282428741455, "training_acc": 72.0, "val_loss": 14.815855026245117, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.31653618812561, "training_acc": 72.0, "val_loss": 14.81480598449707, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.28577136993408, "training_acc": 72.0, "val_loss": 14.814038574695587, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.256054401397705, "training_acc": 72.0, "val_loss": 14.813511073589325, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.3014714717865, "training_acc": 72.0, "val_loss": 14.812779426574707, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.29111695289612, "training_acc": 72.0, "val_loss": 14.812316000461578, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.259926557540894, "training_acc": 72.0, "val_loss": 14.811478555202484, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.26187038421631, "training_acc": 72.0, "val_loss": 14.81093317270279, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.26116967201233, "training_acc": 72.0, "val_loss": 14.810535311698914, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.27075457572937, "training_acc": 72.0, "val_loss": 14.810177683830261, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.26927137374878, "training_acc": 72.0, "val_loss": 14.81001228094101, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.279011487960815, "training_acc": 72.0, "val_loss": 14.80996459722519, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.25972104072571, "training_acc": 72.0, "val_loss": 14.809627830982208, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.28689527511597, "training_acc": 72.0, "val_loss": 14.809311926364899, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.276142597198486, "training_acc": 72.0, "val_loss": 14.809048175811768, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.237722396850586, "training_acc": 72.0, "val_loss": 14.808906614780426, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.276368856430054, "training_acc": 72.0, "val_loss": 14.808820188045502, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.26638650894165, "training_acc": 72.0, "val_loss": 14.808942377567291, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.263023853302, "training_acc": 72.0, "val_loss": 14.809131622314453, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.234981536865234, "training_acc": 72.0, "val_loss": 14.809374511241913, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.26917576789856, "training_acc": 72.0, "val_loss": 14.809705317020416, "val_acc": 72.0}
{"epoch": 63, "training_loss": 59.24363374710083, "training_acc": 72.0, "val_loss": 14.809884130954742, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.26733446121216, "training_acc": 72.0, "val_loss": 14.810067415237427, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.27181625366211, "training_acc": 72.0, "val_loss": 14.81018215417862, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.291192293167114, "training_acc": 72.0, "val_loss": 14.810298383235931, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.257457971572876, "training_acc": 72.0, "val_loss": 14.810319244861603, "val_acc": 72.0}
{"epoch": 68, "training_loss": 59.26026511192322, "training_acc": 72.0, "val_loss": 14.810630679130554, "val_acc": 72.0}
{"epoch": 69, "training_loss": 59.29888463020325, "training_acc": 72.0, "val_loss": 14.810927212238312, "val_acc": 72.0}
{"epoch": 70, "training_loss": 59.26164388656616, "training_acc": 72.0, "val_loss": 14.811038970947266, "val_acc": 72.0}
{"epoch": 71, "training_loss": 59.2777054309845, "training_acc": 72.0, "val_loss": 14.81088399887085, "val_acc": 72.0}
{"epoch": 72, "training_loss": 59.27271819114685, "training_acc": 72.0, "val_loss": 14.810769259929657, "val_acc": 72.0}
{"epoch": 73, "training_loss": 59.254424810409546, "training_acc": 72.0, "val_loss": 14.810606837272644, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.286097049713135, "training_acc": 72.0, "val_loss": 14.810416102409363, "val_acc": 72.0}
{"epoch": 75, "training_loss": 59.268702030181885, "training_acc": 72.0, "val_loss": 14.810216426849365, "val_acc": 72.0}
{"epoch": 76, "training_loss": 59.27032017707825, "training_acc": 72.0, "val_loss": 14.809869229793549, "val_acc": 72.0}
{"epoch": 77, "training_loss": 59.25541806221008, "training_acc": 72.0, "val_loss": 14.80957418680191, "val_acc": 72.0}
