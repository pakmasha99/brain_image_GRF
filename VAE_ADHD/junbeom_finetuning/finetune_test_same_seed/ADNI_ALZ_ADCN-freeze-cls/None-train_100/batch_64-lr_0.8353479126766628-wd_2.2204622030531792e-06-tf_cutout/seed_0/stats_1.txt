"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3971.0128173828125, "training_acc": 72.0, "val_loss": 2011.6771697998047, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5817.111862182617, "training_acc": 72.0, "val_loss": 1935.7080459594727, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7210.5694580078125, "training_acc": 28.0, "val_loss": 317.6375389099121, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1810.72216796875, "training_acc": 72.0, "val_loss": 977.2110939025879, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3765.6580810546875, "training_acc": 72.0, "val_loss": 519.7532176971436, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1178.5064148902893, "training_acc": 72.0, "val_loss": 1795.7828521728516, "val_acc": 28.0}
{"epoch": 6, "training_loss": 7279.208892822266, "training_acc": 28.0, "val_loss": 603.4418106079102, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2598.646827697754, "training_acc": 42.0, "val_loss": 1244.7758674621582, "val_acc": 72.0}
{"epoch": 8, "training_loss": 5772.374664306641, "training_acc": 72.0, "val_loss": 1738.6280059814453, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6835.980377197266, "training_acc": 72.0, "val_loss": 1390.854549407959, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5014.443313598633, "training_acc": 72.0, "val_loss": 409.8979949951172, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2313.3325576782227, "training_acc": 52.0, "val_loss": 1039.1186714172363, "val_acc": 28.0}
{"epoch": 12, "training_loss": 3011.7606296539307, "training_acc": 28.0, "val_loss": 596.9832420349121, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3105.8529052734375, "training_acc": 72.0, "val_loss": 1287.523365020752, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5276.900390625, "training_acc": 72.0, "val_loss": 1229.461669921875, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4552.96711730957, "training_acc": 72.0, "val_loss": 534.1662406921387, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1593.0293827056885, "training_acc": 52.0, "val_loss": 289.6559953689575, "val_acc": 28.0}
{"epoch": 17, "training_loss": 732.2135353088379, "training_acc": 56.0, "val_loss": 330.10292053222656, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1324.638385772705, "training_acc": 72.0, "val_loss": 171.15191221237183, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1100.023338317871, "training_acc": 52.0, "val_loss": 15.41363149881363, "val_acc": 36.0}
{"epoch": 20, "training_loss": 389.86458587646484, "training_acc": 72.0, "val_loss": 306.51726722717285, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1098.0460453033447, "training_acc": 72.0, "val_loss": 141.36234521865845, "val_acc": 28.0}
{"epoch": 22, "training_loss": 530.978214263916, "training_acc": 46.0, "val_loss": 170.49208879470825, "val_acc": 72.0}
{"epoch": 23, "training_loss": 496.7504668235779, "training_acc": 72.0, "val_loss": 609.3247413635254, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1909.893196105957, "training_acc": 28.0, "val_loss": 461.4724636077881, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2378.0476837158203, "training_acc": 72.0, "val_loss": 1009.8706245422363, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4029.3786544799805, "training_acc": 72.0, "val_loss": 856.2796592712402, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3195.1727981567383, "training_acc": 72.0, "val_loss": 147.05055952072144, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1808.9852142333984, "training_acc": 54.0, "val_loss": 1013.5646820068359, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2662.022229194641, "training_acc": 28.0, "val_loss": 677.5284290313721, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3241.14990234375, "training_acc": 72.0, "val_loss": 1427.5151252746582, "val_acc": 72.0}
{"epoch": 31, "training_loss": 5930.001953125, "training_acc": 72.0, "val_loss": 1474.4215965270996, "val_acc": 72.0}
{"epoch": 32, "training_loss": 5561.252914428711, "training_acc": 72.0, "val_loss": 882.9687118530273, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2771.3875045776367, "training_acc": 72.0, "val_loss": 560.7076168060303, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2820.420379638672, "training_acc": 28.0, "val_loss": 207.4169158935547, "val_acc": 28.0}
{"epoch": 35, "training_loss": 1345.2776718139648, "training_acc": 44.0, "val_loss": 1003.0693054199219, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4313.361770629883, "training_acc": 72.0, "val_loss": 1297.2911834716797, "val_acc": 72.0}
{"epoch": 37, "training_loss": 5060.941116333008, "training_acc": 72.0, "val_loss": 952.7125358581543, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3325.5571823120117, "training_acc": 72.0, "val_loss": 81.40085339546204, "val_acc": 72.0}
