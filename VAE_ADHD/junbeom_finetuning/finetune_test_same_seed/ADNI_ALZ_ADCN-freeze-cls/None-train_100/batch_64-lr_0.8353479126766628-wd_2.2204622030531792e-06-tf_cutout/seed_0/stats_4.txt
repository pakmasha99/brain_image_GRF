"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5761.777267456055, "training_acc": 32.0, "val_loss": 1989.266586303711, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6419.839385986328, "training_acc": 72.0, "val_loss": 1257.2592735290527, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4408.222076416016, "training_acc": 28.0, "val_loss": 577.639627456665, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3425.849334716797, "training_acc": 72.0, "val_loss": 1234.9430084228516, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4696.962417602539, "training_acc": 72.0, "val_loss": 672.7139949798584, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1905.0129127502441, "training_acc": 72.0, "val_loss": 1777.8230667114258, "val_acc": 28.0}
{"epoch": 6, "training_loss": 7340.050323486328, "training_acc": 28.0, "val_loss": 779.1196346282959, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3156.6645736694336, "training_acc": 38.0, "val_loss": 1095.3433990478516, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4763.780075073242, "training_acc": 72.0, "val_loss": 1501.468563079834, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5917.864166259766, "training_acc": 72.0, "val_loss": 1182.7301025390625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4087.1275177001953, "training_acc": 72.0, "val_loss": 210.64269542694092, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2430.099624633789, "training_acc": 54.0, "val_loss": 1609.5815658569336, "val_acc": 28.0}
{"epoch": 12, "training_loss": 5365.082229614258, "training_acc": 28.0, "val_loss": 316.9551372528076, "val_acc": 72.0}
{"epoch": 13, "training_loss": 2043.9841918945312, "training_acc": 72.0, "val_loss": 990.5858993530273, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3989.920394897461, "training_acc": 72.0, "val_loss": 908.0703735351562, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3243.2191162109375, "training_acc": 72.0, "val_loss": 259.5574617385864, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1145.3102416992188, "training_acc": 66.0, "val_loss": 807.2477340698242, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2022.7089743614197, "training_acc": 28.0, "val_loss": 585.1845741271973, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2822.3922119140625, "training_acc": 72.0, "val_loss": 1158.6139678955078, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4666.024688720703, "training_acc": 72.0, "val_loss": 1041.1460876464844, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3890.176856994629, "training_acc": 72.0, "val_loss": 331.44426345825195, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1854.2793045043945, "training_acc": 50.0, "val_loss": 585.0006103515625, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1645.2459163665771, "training_acc": 46.0, "val_loss": 339.1003370285034, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1343.2597675323486, "training_acc": 72.0, "val_loss": 218.43459606170654, "val_acc": 72.0}
{"epoch": 24, "training_loss": 694.6830148696899, "training_acc": 56.0, "val_loss": 135.4678511619568, "val_acc": 72.0}
{"epoch": 25, "training_loss": 569.2335529327393, "training_acc": 72.0, "val_loss": 50.50208568572998, "val_acc": 28.0}
{"epoch": 26, "training_loss": 404.44091033935547, "training_acc": 44.0, "val_loss": 230.74777126312256, "val_acc": 72.0}
{"epoch": 27, "training_loss": 739.6427822113037, "training_acc": 72.0, "val_loss": 406.0293197631836, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1174.9698853492737, "training_acc": 36.0, "val_loss": 25.31282901763916, "val_acc": 28.0}
{"epoch": 29, "training_loss": 303.7265853881836, "training_acc": 48.0, "val_loss": 283.07220935821533, "val_acc": 72.0}
{"epoch": 30, "training_loss": 999.5079345703125, "training_acc": 72.0, "val_loss": 118.76206398010254, "val_acc": 28.0}
{"epoch": 31, "training_loss": 470.49777030944824, "training_acc": 46.0, "val_loss": 151.62713527679443, "val_acc": 72.0}
{"epoch": 32, "training_loss": 460.64631628990173, "training_acc": 55.0, "val_loss": 78.08658480644226, "val_acc": 72.0}
{"epoch": 33, "training_loss": 528.4299583435059, "training_acc": 44.0, "val_loss": 312.0246410369873, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1541.855125427246, "training_acc": 72.0, "val_loss": 499.2405414581299, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1760.5131950378418, "training_acc": 72.0, "val_loss": 42.581671476364136, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1378.3570404052734, "training_acc": 60.0, "val_loss": 956.922435760498, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2484.4379589557648, "training_acc": 44.0, "val_loss": 245.3596830368042, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1060.4970321655273, "training_acc": 72.0, "val_loss": 171.14440202713013, "val_acc": 72.0}
{"epoch": 39, "training_loss": 542.6220111846924, "training_acc": 64.0, "val_loss": 65.31426906585693, "val_acc": 72.0}
{"epoch": 40, "training_loss": 233.614764213562, "training_acc": 72.0, "val_loss": 414.3892288208008, "val_acc": 28.0}
{"epoch": 41, "training_loss": 1087.3787007331848, "training_acc": 46.0, "val_loss": 80.18618822097778, "val_acc": 72.0}
{"epoch": 42, "training_loss": 498.2735366821289, "training_acc": 50.0, "val_loss": 253.10792922973633, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1167.818775177002, "training_acc": 72.0, "val_loss": 345.35627365112305, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1085.3474006652832, "training_acc": 72.0, "val_loss": 402.62818336486816, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1293.5620822906494, "training_acc": 28.0, "val_loss": 412.6485347747803, "val_acc": 72.0}
{"epoch": 46, "training_loss": 1955.0075073242188, "training_acc": 72.0, "val_loss": 799.5730876922607, "val_acc": 72.0}
{"epoch": 47, "training_loss": 3119.218162536621, "training_acc": 72.0, "val_loss": 545.6091403961182, "val_acc": 72.0}
