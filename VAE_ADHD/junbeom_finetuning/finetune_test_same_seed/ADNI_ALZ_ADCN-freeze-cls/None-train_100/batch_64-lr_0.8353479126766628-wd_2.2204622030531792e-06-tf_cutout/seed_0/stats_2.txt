"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3258.4034423828125, "training_acc": 46.0, "val_loss": 2301.8680572509766, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7482.18620300293, "training_acc": 72.0, "val_loss": 937.0927810668945, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2575.9170248508453, "training_acc": 39.0, "val_loss": 500.2851963043213, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2277.3231353759766, "training_acc": 72.0, "val_loss": 289.60278034210205, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1821.6052551269531, "training_acc": 58.0, "val_loss": 274.45385456085205, "val_acc": 28.0}
{"epoch": 5, "training_loss": 1273.8200988769531, "training_acc": 50.0, "val_loss": 1103.4603118896484, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4981.848815917969, "training_acc": 72.0, "val_loss": 1272.13716506958, "val_acc": 72.0}
{"epoch": 7, "training_loss": 4619.2032470703125, "training_acc": 72.0, "val_loss": 476.7336368560791, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1780.3419342041016, "training_acc": 58.0, "val_loss": 572.245454788208, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1769.528392791748, "training_acc": 44.0, "val_loss": 425.5915641784668, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1717.5214233398438, "training_acc": 72.0, "val_loss": 245.20387649536133, "val_acc": 72.0}
{"epoch": 11, "training_loss": 648.3757419586182, "training_acc": 66.0, "val_loss": 42.855510115623474, "val_acc": 72.0}
{"epoch": 12, "training_loss": 312.137845993042, "training_acc": 54.0, "val_loss": 331.3743829727173, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1528.2788314819336, "training_acc": 72.0, "val_loss": 483.06117057800293, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1662.2944641113281, "training_acc": 72.0, "val_loss": 113.53429555892944, "val_acc": 28.0}
{"epoch": 15, "training_loss": 391.40249729156494, "training_acc": 46.0, "val_loss": 49.10735487937927, "val_acc": 72.0}
{"epoch": 16, "training_loss": 638.406623840332, "training_acc": 58.0, "val_loss": 98.42345118522644, "val_acc": 72.0}
{"epoch": 17, "training_loss": 442.4345588684082, "training_acc": 72.0, "val_loss": 29.28437888622284, "val_acc": 72.0}
{"epoch": 18, "training_loss": 940.2378845214844, "training_acc": 56.0, "val_loss": 92.38149523735046, "val_acc": 28.0}
{"epoch": 19, "training_loss": 744.4432754516602, "training_acc": 50.0, "val_loss": 922.213077545166, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3998.107177734375, "training_acc": 72.0, "val_loss": 1126.227855682373, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4286.1149978637695, "training_acc": 72.0, "val_loss": 641.5205001831055, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1927.633550643921, "training_acc": 72.0, "val_loss": 944.538688659668, "val_acc": 28.0}
{"epoch": 23, "training_loss": 4147.875946044922, "training_acc": 28.0, "val_loss": 230.112886428833, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1395.355079650879, "training_acc": 46.0, "val_loss": 1154.3933868408203, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4885.386016845703, "training_acc": 72.0, "val_loss": 1570.732307434082, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6206.661544799805, "training_acc": 72.0, "val_loss": 1331.8774223327637, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4855.803421020508, "training_acc": 72.0, "val_loss": 553.2419204711914, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1294.508107662201, "training_acc": 60.0, "val_loss": 644.9045658111572, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1819.6133289337158, "training_acc": 28.0, "val_loss": 551.7842769622803, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2614.356201171875, "training_acc": 72.0, "val_loss": 1121.5255737304688, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4486.979507446289, "training_acc": 72.0, "val_loss": 994.3883895874023, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3581.0964736938477, "training_acc": 72.0, "val_loss": 277.0644187927246, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1484.0285568237305, "training_acc": 60.0, "val_loss": 839.9684906005859, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2178.4946982860565, "training_acc": 44.0, "val_loss": 203.412127494812, "val_acc": 72.0}
{"epoch": 35, "training_loss": 800.1581516265869, "training_acc": 72.0, "val_loss": 38.84766697883606, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1102.4534072875977, "training_acc": 56.0, "val_loss": 328.8381814956665, "val_acc": 28.0}
