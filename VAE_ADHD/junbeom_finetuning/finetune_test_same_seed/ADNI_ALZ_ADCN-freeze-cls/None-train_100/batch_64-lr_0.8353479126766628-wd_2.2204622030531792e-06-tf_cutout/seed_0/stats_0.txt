"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3979.05908203125, "training_acc": 42.0, "val_loss": 2154.7773361206055, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6767.367156982422, "training_acc": 72.0, "val_loss": 1253.1225204467773, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4274.005645751953, "training_acc": 28.0, "val_loss": 684.728479385376, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3529.8140411376953, "training_acc": 72.0, "val_loss": 1442.550277709961, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5648.327362060547, "training_acc": 72.0, "val_loss": 1019.3358421325684, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3556.6021156311035, "training_acc": 72.0, "val_loss": 697.2234725952148, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2745.909164428711, "training_acc": 28.0, "val_loss": 262.14568614959717, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1281.3051719665527, "training_acc": 72.0, "val_loss": 571.1366653442383, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2096.826187133789, "training_acc": 72.0, "val_loss": 135.1333737373352, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1955.3804016113281, "training_acc": 50.0, "val_loss": 733.5703372955322, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2198.937812805176, "training_acc": 44.0, "val_loss": 518.4943199157715, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2204.7653884887695, "training_acc": 72.0, "val_loss": 526.1999607086182, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1768.7819862365723, "training_acc": 72.0, "val_loss": 309.3712329864502, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1013.8042526245117, "training_acc": 28.0, "val_loss": 451.7781734466553, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2366.648193359375, "training_acc": 72.0, "val_loss": 884.5340728759766, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3449.0706939697266, "training_acc": 72.0, "val_loss": 596.0554122924805, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1759.7380294799805, "training_acc": 72.0, "val_loss": 740.1663780212402, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3276.4200134277344, "training_acc": 28.0, "val_loss": 20.176662504673004, "val_acc": 72.0}
{"epoch": 18, "training_loss": 539.5533828735352, "training_acc": 72.0, "val_loss": 290.9397602081299, "val_acc": 72.0}
{"epoch": 19, "training_loss": 995.0375165939331, "training_acc": 72.0, "val_loss": 341.24085903167725, "val_acc": 28.0}
{"epoch": 20, "training_loss": 891.5795109272003, "training_acc": 46.0, "val_loss": 45.525652170181274, "val_acc": 72.0}
{"epoch": 21, "training_loss": 324.3999271392822, "training_acc": 62.0, "val_loss": 183.2780122756958, "val_acc": 72.0}
{"epoch": 22, "training_loss": 832.4370346069336, "training_acc": 72.0, "val_loss": 162.885844707489, "val_acc": 72.0}
{"epoch": 23, "training_loss": 778.3124351501465, "training_acc": 54.0, "val_loss": 106.28455877304077, "val_acc": 72.0}
{"epoch": 24, "training_loss": 448.6599521636963, "training_acc": 72.0, "val_loss": 32.332754135131836, "val_acc": 28.0}
{"epoch": 25, "training_loss": 375.81578826904297, "training_acc": 42.0, "val_loss": 192.60295629501343, "val_acc": 72.0}
{"epoch": 26, "training_loss": 559.1205387115479, "training_acc": 72.0, "val_loss": 640.2408123016357, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2004.053638458252, "training_acc": 28.0, "val_loss": 436.07096672058105, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2149.7637100219727, "training_acc": 72.0, "val_loss": 904.0848731994629, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3578.040328979492, "training_acc": 72.0, "val_loss": 703.1577110290527, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2461.38143157959, "training_acc": 72.0, "val_loss": 166.9094204902649, "val_acc": 28.0}
{"epoch": 31, "training_loss": 498.7457194328308, "training_acc": 28.0, "val_loss": 212.90228366851807, "val_acc": 72.0}
{"epoch": 32, "training_loss": 869.9589900970459, "training_acc": 72.0, "val_loss": 126.55099630355835, "val_acc": 72.0}
{"epoch": 33, "training_loss": 946.9948806762695, "training_acc": 52.0, "val_loss": 44.50446963310242, "val_acc": 72.0}
{"epoch": 34, "training_loss": 231.8459825515747, "training_acc": 72.0, "val_loss": 191.54704809188843, "val_acc": 28.0}
{"epoch": 35, "training_loss": 764.3942852020264, "training_acc": 44.0, "val_loss": 265.12510776519775, "val_acc": 72.0}
{"epoch": 36, "training_loss": 933.666181564331, "training_acc": 72.0, "val_loss": 134.01446342468262, "val_acc": 28.0}
