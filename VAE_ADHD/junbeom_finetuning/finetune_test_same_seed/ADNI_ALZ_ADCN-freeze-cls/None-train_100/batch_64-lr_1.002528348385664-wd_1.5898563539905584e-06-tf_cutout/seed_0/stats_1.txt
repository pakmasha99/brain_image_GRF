"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5627.029369354248, "training_acc": 72.0, "val_loss": 2117.452049255371, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6132.574859619141, "training_acc": 72.0, "val_loss": 3958.6044311523438, "val_acc": 28.0}
{"epoch": 2, "training_loss": 15193.366271972656, "training_acc": 28.0, "val_loss": 630.2484035491943, "val_acc": 28.0}
{"epoch": 3, "training_loss": 3596.5744018554688, "training_acc": 44.0, "val_loss": 2509.409523010254, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10680.061584472656, "training_acc": 72.0, "val_loss": 3515.8340454101562, "val_acc": 72.0}
{"epoch": 5, "training_loss": 14122.410095214844, "training_acc": 72.0, "val_loss": 3345.759963989258, "val_acc": 72.0}
{"epoch": 6, "training_loss": 12749.44140625, "training_acc": 72.0, "val_loss": 2241.103744506836, "val_acc": 72.0}
{"epoch": 7, "training_loss": 8322.36922454834, "training_acc": 72.0, "val_loss": 388.75672817230225, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3645.1624755859375, "training_acc": 56.0, "val_loss": 2624.374008178711, "val_acc": 28.0}
{"epoch": 9, "training_loss": 9372.790435791016, "training_acc": 28.0, "val_loss": 71.95228934288025, "val_acc": 72.0}
{"epoch": 10, "training_loss": 618.862922668457, "training_acc": 72.0, "val_loss": 851.8292427062988, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3493.692367553711, "training_acc": 72.0, "val_loss": 789.1664981842041, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2693.1463012695312, "training_acc": 72.0, "val_loss": 103.17598581314087, "val_acc": 28.0}
{"epoch": 13, "training_loss": 276.2326533794403, "training_acc": 48.0, "val_loss": 115.96180200576782, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1041.2154006958008, "training_acc": 40.0, "val_loss": 616.1264896392822, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2440.2113647460938, "training_acc": 72.0, "val_loss": 365.89343547821045, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1016.1837635040283, "training_acc": 58.0, "val_loss": 92.91354417800903, "val_acc": 72.0}
{"epoch": 17, "training_loss": 274.71654057502747, "training_acc": 72.0, "val_loss": 50.50964951515198, "val_acc": 72.0}
{"epoch": 18, "training_loss": 517.1711387634277, "training_acc": 56.0, "val_loss": 261.3074541091919, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1205.1933326721191, "training_acc": 72.0, "val_loss": 321.16944789886475, "val_acc": 72.0}
{"epoch": 20, "training_loss": 940.4202218055725, "training_acc": 72.0, "val_loss": 943.6844825744629, "val_acc": 28.0}
{"epoch": 21, "training_loss": 3310.0501708984375, "training_acc": 28.0, "val_loss": 369.3157196044922, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2219.9744873046875, "training_acc": 72.0, "val_loss": 878.8103103637695, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3383.619873046875, "training_acc": 72.0, "val_loss": 503.751802444458, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1488.1704969406128, "training_acc": 72.0, "val_loss": 1368.1658744812012, "val_acc": 28.0}
{"epoch": 25, "training_loss": 5649.1739501953125, "training_acc": 28.0, "val_loss": 166.97280406951904, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1518.1300201416016, "training_acc": 46.0, "val_loss": 1521.1410522460938, "val_acc": 72.0}
{"epoch": 27, "training_loss": 6607.093688964844, "training_acc": 72.0, "val_loss": 2117.2670364379883, "val_acc": 72.0}
{"epoch": 28, "training_loss": 8466.40591430664, "training_acc": 72.0, "val_loss": 1895.9465026855469, "val_acc": 72.0}
{"epoch": 29, "training_loss": 6958.820556640625, "training_acc": 72.0, "val_loss": 965.517520904541, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2857.7038917541504, "training_acc": 72.0, "val_loss": 1464.077091217041, "val_acc": 28.0}
{"epoch": 31, "training_loss": 6756.122406005859, "training_acc": 28.0, "val_loss": 1375.8892059326172, "val_acc": 28.0}
{"epoch": 32, "training_loss": 4157.688659667969, "training_acc": 38.0, "val_loss": 661.5429401397705, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2792.072708129883, "training_acc": 72.0, "val_loss": 866.5106773376465, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3238.569580078125, "training_acc": 72.0, "val_loss": 379.1834592819214, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1885.9427795410156, "training_acc": 48.0, "val_loss": 208.16879272460938, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1487.704444885254, "training_acc": 38.0, "val_loss": 779.1007041931152, "val_acc": 72.0}
