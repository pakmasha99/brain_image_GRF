"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3480.8883666992188, "training_acc": 48.0, "val_loss": 2788.937187194824, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9833.214126586914, "training_acc": 72.0, "val_loss": 1383.515739440918, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3721.9026069641113, "training_acc": 28.0, "val_loss": 1262.685489654541, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6047.5302734375, "training_acc": 72.0, "val_loss": 2400.887870788574, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9526.023422241211, "training_acc": 72.0, "val_loss": 2044.029426574707, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7393.099868774414, "training_acc": 72.0, "val_loss": 715.2505874633789, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2471.199317932129, "training_acc": 60.0, "val_loss": 979.3684959411621, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2694.8462238311768, "training_acc": 44.0, "val_loss": 354.9149990081787, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1387.9264068603516, "training_acc": 72.0, "val_loss": 34.812864661216736, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1387.2494277954102, "training_acc": 64.0, "val_loss": 794.0379619598389, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2306.7053413391113, "training_acc": 48.0, "val_loss": 713.8898849487305, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3050.04052734375, "training_acc": 72.0, "val_loss": 754.8135757446289, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2607.889892578125, "training_acc": 72.0, "val_loss": 124.1689682006836, "val_acc": 28.0}
{"epoch": 13, "training_loss": 364.5982346534729, "training_acc": 48.0, "val_loss": 65.52770733833313, "val_acc": 28.0}
{"epoch": 14, "training_loss": 347.8797378540039, "training_acc": 56.0, "val_loss": 613.8964653015137, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2510.172264099121, "training_acc": 72.0, "val_loss": 448.76842498779297, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1190.4845485687256, "training_acc": 72.0, "val_loss": 1325.4828453063965, "val_acc": 28.0}
{"epoch": 17, "training_loss": 5133.231262207031, "training_acc": 28.0, "val_loss": 58.12622904777527, "val_acc": 72.0}
{"epoch": 18, "training_loss": 619.3724555969238, "training_acc": 72.0, "val_loss": 372.5332021713257, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1243.9918327331543, "training_acc": 72.0, "val_loss": 379.29580211639404, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1231.3308811187744, "training_acc": 36.0, "val_loss": 26.710575819015503, "val_acc": 72.0}
{"epoch": 21, "training_loss": 657.5757026672363, "training_acc": 62.0, "val_loss": 81.41144514083862, "val_acc": 72.0}
{"epoch": 22, "training_loss": 362.5103597640991, "training_acc": 72.0, "val_loss": 101.60489082336426, "val_acc": 28.0}
{"epoch": 23, "training_loss": 539.087345123291, "training_acc": 50.0, "val_loss": 461.3439083099365, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1765.8737754821777, "training_acc": 72.0, "val_loss": 166.1121129989624, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1054.4887466430664, "training_acc": 62.0, "val_loss": 247.86319732666016, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1262.5542907714844, "training_acc": 46.0, "val_loss": 860.3192329406738, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3562.08447265625, "training_acc": 72.0, "val_loss": 906.3642501831055, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3333.716911315918, "training_acc": 72.0, "val_loss": 214.22631740570068, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1975.5876922607422, "training_acc": 54.0, "val_loss": 873.4903335571289, "val_acc": 28.0}
{"epoch": 30, "training_loss": 2668.279098510742, "training_acc": 40.0, "val_loss": 454.78625297546387, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1887.8171157836914, "training_acc": 72.0, "val_loss": 325.07481575012207, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1327.9785270690918, "training_acc": 48.0, "val_loss": 148.22555780410767, "val_acc": 72.0}
{"epoch": 33, "training_loss": 573.7889995574951, "training_acc": 72.0, "val_loss": 81.19819164276123, "val_acc": 28.0}
{"epoch": 34, "training_loss": 640.276782989502, "training_acc": 44.0, "val_loss": 417.19961166381836, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1567.2630996704102, "training_acc": 72.0, "val_loss": 52.504962682724, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1828.4443359375, "training_acc": 54.0, "val_loss": 913.887882232666, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2928.0526428222656, "training_acc": 38.0, "val_loss": 520.99289894104, "val_acc": 72.0}
{"epoch": 38, "training_loss": 2154.6295852661133, "training_acc": 72.0, "val_loss": 457.98654556274414, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1371.5372352600098, "training_acc": 72.0, "val_loss": 783.1863880157471, "val_acc": 28.0}
