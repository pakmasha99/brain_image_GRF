"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2626.256202697754, "training_acc": 52.0, "val_loss": 2837.062644958496, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9491.80549621582, "training_acc": 72.0, "val_loss": 2082.889938354492, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6561.397705078125, "training_acc": 28.0, "val_loss": 992.1590805053711, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4945.485076904297, "training_acc": 72.0, "val_loss": 2095.7557678222656, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8374.646514892578, "training_acc": 72.0, "val_loss": 1702.9117584228516, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5805.154602050781, "training_acc": 72.0, "val_loss": 168.3889865875244, "val_acc": 72.0}
{"epoch": 6, "training_loss": 4064.9627380371094, "training_acc": 54.0, "val_loss": 2837.870979309082, "val_acc": 28.0}
{"epoch": 7, "training_loss": 9532.613739013672, "training_acc": 28.0, "val_loss": 340.55187702178955, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1887.3271408081055, "training_acc": 72.0, "val_loss": 1378.2620429992676, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5739.447982788086, "training_acc": 72.0, "val_loss": 1463.1193161010742, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5357.862457275391, "training_acc": 72.0, "val_loss": 707.4362754821777, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1841.2497324943542, "training_acc": 71.0, "val_loss": 1312.1928215026855, "val_acc": 28.0}
{"epoch": 12, "training_loss": 4904.359100341797, "training_acc": 28.0, "val_loss": 195.24493217468262, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1220.955093383789, "training_acc": 72.0, "val_loss": 666.8829917907715, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2576.357349395752, "training_acc": 72.0, "val_loss": 285.0513458251953, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1095.3471183776855, "training_acc": 58.0, "val_loss": 34.69875752925873, "val_acc": 72.0}
{"epoch": 16, "training_loss": 186.7314796447754, "training_acc": 56.0, "val_loss": 408.55960845947266, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1871.5148086547852, "training_acc": 72.0, "val_loss": 584.6251010894775, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2024.4219970703125, "training_acc": 72.0, "val_loss": 34.10545289516449, "val_acc": 28.0}
{"epoch": 19, "training_loss": 143.79520654678345, "training_acc": 44.0, "val_loss": 280.6297779083252, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1230.3866119384766, "training_acc": 40.0, "val_loss": 400.53882598876953, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1486.9834594726562, "training_acc": 72.0, "val_loss": 30.871036648750305, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1469.7340698242188, "training_acc": 56.0, "val_loss": 593.1387424468994, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1679.7976341247559, "training_acc": 52.0, "val_loss": 754.6953678131104, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3402.2916412353516, "training_acc": 72.0, "val_loss": 897.2429275512695, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3243.095016479492, "training_acc": 72.0, "val_loss": 210.92073917388916, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1898.1348876953125, "training_acc": 56.0, "val_loss": 957.8531265258789, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2605.6945610046387, "training_acc": 44.0, "val_loss": 360.1186513900757, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1526.4377822875977, "training_acc": 72.0, "val_loss": 226.08778476715088, "val_acc": 72.0}
{"epoch": 29, "training_loss": 993.3543090820312, "training_acc": 58.0, "val_loss": 37.581101059913635, "val_acc": 72.0}
{"epoch": 30, "training_loss": 121.14409327507019, "training_acc": 62.0, "val_loss": 178.97562980651855, "val_acc": 72.0}
{"epoch": 31, "training_loss": 654.2877368927002, "training_acc": 72.0, "val_loss": 188.37493658065796, "val_acc": 28.0}
{"epoch": 32, "training_loss": 772.0366096496582, "training_acc": 46.0, "val_loss": 334.25183296203613, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1203.8939094543457, "training_acc": 72.0, "val_loss": 129.97195720672607, "val_acc": 28.0}
{"epoch": 34, "training_loss": 370.5208749771118, "training_acc": 54.0, "val_loss": 158.32375288009644, "val_acc": 72.0}
{"epoch": 35, "training_loss": 511.21833658218384, "training_acc": 52.0, "val_loss": 277.441143989563, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1161.3466835021973, "training_acc": 72.0, "val_loss": 210.25137901306152, "val_acc": 72.0}
{"epoch": 37, "training_loss": 953.633056640625, "training_acc": 54.0, "val_loss": 142.51463413238525, "val_acc": 72.0}
{"epoch": 38, "training_loss": 674.4728965759277, "training_acc": 72.0, "val_loss": 14.946337044239044, "val_acc": 68.0}
{"epoch": 39, "training_loss": 554.0083694458008, "training_acc": 50.0, "val_loss": 393.4783935546875, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2006.9983444213867, "training_acc": 72.0, "val_loss": 709.5921516418457, "val_acc": 72.0}
{"epoch": 41, "training_loss": 2707.3185386657715, "training_acc": 72.0, "val_loss": 200.05240440368652, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1334.4826354980469, "training_acc": 58.0, "val_loss": 381.9833278656006, "val_acc": 28.0}
{"epoch": 43, "training_loss": 1575.835952758789, "training_acc": 44.0, "val_loss": 748.6346244812012, "val_acc": 72.0}
{"epoch": 44, "training_loss": 3106.6053314208984, "training_acc": 72.0, "val_loss": 744.5440292358398, "val_acc": 72.0}
{"epoch": 45, "training_loss": 2491.1086502075195, "training_acc": 72.0, "val_loss": 23.396046459674835, "val_acc": 72.0}
{"epoch": 46, "training_loss": 2015.4132614135742, "training_acc": 60.0, "val_loss": 1654.141616821289, "val_acc": 28.0}
{"epoch": 47, "training_loss": 4986.7534255981445, "training_acc": 28.0, "val_loss": 663.8672828674316, "val_acc": 72.0}
{"epoch": 48, "training_loss": 3846.2451782226562, "training_acc": 72.0, "val_loss": 1637.5377655029297, "val_acc": 72.0}
{"epoch": 49, "training_loss": 6764.746978759766, "training_acc": 72.0, "val_loss": 1647.6303100585938, "val_acc": 72.0}
{"epoch": 50, "training_loss": 6187.710510253906, "training_acc": 72.0, "val_loss": 881.8618774414062, "val_acc": 72.0}
{"epoch": 51, "training_loss": 2521.712387084961, "training_acc": 72.0, "val_loss": 1180.5495262145996, "val_acc": 28.0}
{"epoch": 52, "training_loss": 5531.489013671875, "training_acc": 28.0, "val_loss": 790.3501987457275, "val_acc": 28.0}
{"epoch": 53, "training_loss": 2594.2385330200195, "training_acc": 46.0, "val_loss": 1029.9965858459473, "val_acc": 72.0}
{"epoch": 54, "training_loss": 4546.895278930664, "training_acc": 72.0, "val_loss": 1412.056827545166, "val_acc": 72.0}
{"epoch": 55, "training_loss": 5472.339111328125, "training_acc": 72.0, "val_loss": 989.5917892456055, "val_acc": 72.0}
{"epoch": 56, "training_loss": 3289.0901412963867, "training_acc": 72.0, "val_loss": 221.50399684906006, "val_acc": 28.0}
{"epoch": 57, "training_loss": 1187.1862564086914, "training_acc": 28.0, "val_loss": 299.10638332366943, "val_acc": 72.0}
