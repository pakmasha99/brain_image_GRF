"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1700.1114768981934, "training_acc": 72.0, "val_loss": 604.4882774353027, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1816.6354446411133, "training_acc": 72.0, "val_loss": 846.0455894470215, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3085.8093872070312, "training_acc": 28.0, "val_loss": 69.37212944030762, "val_acc": 72.0}
{"epoch": 3, "training_loss": 646.9678268432617, "training_acc": 72.0, "val_loss": 274.52893257141113, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1005.0790367126465, "training_acc": 72.0, "val_loss": 56.26910924911499, "val_acc": 72.0}
{"epoch": 5, "training_loss": 758.2181854248047, "training_acc": 52.0, "val_loss": 265.87812900543213, "val_acc": 28.0}
{"epoch": 6, "training_loss": 726.1244029998779, "training_acc": 50.0, "val_loss": 211.81340217590332, "val_acc": 72.0}
{"epoch": 7, "training_loss": 936.3800201416016, "training_acc": 72.0, "val_loss": 216.20514392852783, "val_acc": 72.0}
{"epoch": 8, "training_loss": 718.5127296447754, "training_acc": 72.0, "val_loss": 96.6225802898407, "val_acc": 28.0}
{"epoch": 9, "training_loss": 281.87878489494324, "training_acc": 28.0, "val_loss": 93.7897801399231, "val_acc": 72.0}
{"epoch": 10, "training_loss": 449.55871200561523, "training_acc": 72.0, "val_loss": 79.55915927886963, "val_acc": 72.0}
{"epoch": 11, "training_loss": 271.04297161102295, "training_acc": 58.0, "val_loss": 28.44853401184082, "val_acc": 72.0}
{"epoch": 12, "training_loss": 99.16566896438599, "training_acc": 72.0, "val_loss": 63.56053948402405, "val_acc": 28.0}
{"epoch": 13, "training_loss": 242.87513732910156, "training_acc": 48.0, "val_loss": 118.72704029083252, "val_acc": 72.0}
{"epoch": 14, "training_loss": 449.22098541259766, "training_acc": 72.0, "val_loss": 23.215675354003906, "val_acc": 72.0}
{"epoch": 15, "training_loss": 395.054443359375, "training_acc": 58.0, "val_loss": 136.93294525146484, "val_acc": 28.0}
{"epoch": 16, "training_loss": 581.245756149292, "training_acc": 40.0, "val_loss": 215.46237468719482, "val_acc": 72.0}
{"epoch": 17, "training_loss": 886.0398788452148, "training_acc": 72.0, "val_loss": 200.33605098724365, "val_acc": 72.0}
{"epoch": 18, "training_loss": 696.7511463165283, "training_acc": 72.0, "val_loss": 40.518492460250854, "val_acc": 28.0}
{"epoch": 19, "training_loss": 177.65587043762207, "training_acc": 28.0, "val_loss": 134.3861699104309, "val_acc": 72.0}
{"epoch": 20, "training_loss": 649.0663719177246, "training_acc": 72.0, "val_loss": 225.40733814239502, "val_acc": 72.0}
{"epoch": 21, "training_loss": 844.5122680664062, "training_acc": 72.0, "val_loss": 88.03757429122925, "val_acc": 72.0}
{"epoch": 22, "training_loss": 384.4490661621094, "training_acc": 56.0, "val_loss": 40.064677596092224, "val_acc": 28.0}
{"epoch": 23, "training_loss": 212.4361867904663, "training_acc": 50.0, "val_loss": 191.2742257118225, "val_acc": 72.0}
{"epoch": 24, "training_loss": 774.3799743652344, "training_acc": 72.0, "val_loss": 155.1912784576416, "val_acc": 72.0}
{"epoch": 25, "training_loss": 488.46831798553467, "training_acc": 72.0, "val_loss": 185.25211811065674, "val_acc": 28.0}
{"epoch": 26, "training_loss": 696.7319622039795, "training_acc": 28.0, "val_loss": 108.20891857147217, "val_acc": 72.0}
{"epoch": 27, "training_loss": 566.7352447509766, "training_acc": 72.0, "val_loss": 229.158353805542, "val_acc": 72.0}
{"epoch": 28, "training_loss": 874.5168380737305, "training_acc": 72.0, "val_loss": 116.506028175354, "val_acc": 72.0}
{"epoch": 29, "training_loss": 465.0108127593994, "training_acc": 46.0, "val_loss": 19.36083883047104, "val_acc": 72.0}
{"epoch": 30, "training_loss": 72.65335249900818, "training_acc": 72.0, "val_loss": 14.7647425532341, "val_acc": 72.0}
{"epoch": 31, "training_loss": 62.048842668533325, "training_acc": 72.0, "val_loss": 28.37740182876587, "val_acc": 28.0}
{"epoch": 32, "training_loss": 140.57607412338257, "training_acc": 48.0, "val_loss": 78.87995839118958, "val_acc": 72.0}
{"epoch": 33, "training_loss": 256.7192907333374, "training_acc": 72.0, "val_loss": 129.22965288162231, "val_acc": 28.0}
{"epoch": 34, "training_loss": 361.60397267341614, "training_acc": 42.0, "val_loss": 36.75399422645569, "val_acc": 72.0}
{"epoch": 35, "training_loss": 111.47533082962036, "training_acc": 72.0, "val_loss": 71.54737710952759, "val_acc": 28.0}
{"epoch": 36, "training_loss": 276.4213123321533, "training_acc": 46.0, "val_loss": 115.92243909835815, "val_acc": 72.0}
{"epoch": 37, "training_loss": 433.61371326446533, "training_acc": 72.0, "val_loss": 22.566016018390656, "val_acc": 72.0}
{"epoch": 38, "training_loss": 416.02342987060547, "training_acc": 54.0, "val_loss": 106.33993148803711, "val_acc": 28.0}
{"epoch": 39, "training_loss": 441.8583641052246, "training_acc": 46.0, "val_loss": 241.73669815063477, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1007.6759223937988, "training_acc": 72.0, "val_loss": 250.62315464019775, "val_acc": 72.0}
{"epoch": 41, "training_loss": 878.785099029541, "training_acc": 72.0, "val_loss": 54.73892092704773, "val_acc": 72.0}
{"epoch": 42, "training_loss": 592.6948204040527, "training_acc": 54.0, "val_loss": 289.8139476776123, "val_acc": 28.0}
{"epoch": 43, "training_loss": 734.9605002403259, "training_acc": 48.0, "val_loss": 103.26900482177734, "val_acc": 72.0}
{"epoch": 44, "training_loss": 418.7854223251343, "training_acc": 72.0, "val_loss": 75.55487751960754, "val_acc": 72.0}
{"epoch": 45, "training_loss": 255.2319622039795, "training_acc": 54.0, "val_loss": 28.358429670333862, "val_acc": 72.0}
{"epoch": 46, "training_loss": 96.92647361755371, "training_acc": 72.0, "val_loss": 30.331289768218994, "val_acc": 28.0}
{"epoch": 47, "training_loss": 204.47381019592285, "training_acc": 42.0, "val_loss": 96.90194725990295, "val_acc": 72.0}
{"epoch": 48, "training_loss": 327.75031757354736, "training_acc": 72.0, "val_loss": 87.16561198234558, "val_acc": 28.0}
{"epoch": 49, "training_loss": 257.24365186691284, "training_acc": 44.0, "val_loss": 25.484514236450195, "val_acc": 72.0}
