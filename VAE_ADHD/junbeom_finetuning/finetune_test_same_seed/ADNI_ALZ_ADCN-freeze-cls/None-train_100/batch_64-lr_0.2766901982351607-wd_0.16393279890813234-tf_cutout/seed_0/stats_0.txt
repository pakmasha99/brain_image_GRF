"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1347.9581909179688, "training_acc": 42.0, "val_loss": 675.7410049438477, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2037.1095657348633, "training_acc": 72.0, "val_loss": 625.2684116363525, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2210.462677001953, "training_acc": 28.0, "val_loss": 163.99675607681274, "val_acc": 72.0}
{"epoch": 3, "training_loss": 907.4045448303223, "training_acc": 72.0, "val_loss": 392.1354293823242, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1500.341999053955, "training_acc": 72.0, "val_loss": 218.33865642547607, "val_acc": 72.0}
{"epoch": 5, "training_loss": 702.3292846679688, "training_acc": 72.0, "val_loss": 389.931845664978, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1314.3252029418945, "training_acc": 28.0, "val_loss": 136.90814971923828, "val_acc": 72.0}
{"epoch": 7, "training_loss": 658.9615612030029, "training_acc": 72.0, "val_loss": 298.419189453125, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1160.96040725708, "training_acc": 72.0, "val_loss": 188.76211643218994, "val_acc": 72.0}
{"epoch": 9, "training_loss": 602.5672926902771, "training_acc": 72.0, "val_loss": 356.0370206832886, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1368.4369621276855, "training_acc": 28.0, "val_loss": 38.24847638607025, "val_acc": 72.0}
{"epoch": 11, "training_loss": 269.571569442749, "training_acc": 72.0, "val_loss": 132.9278826713562, "val_acc": 72.0}
{"epoch": 12, "training_loss": 465.3896150588989, "training_acc": 72.0, "val_loss": 40.22568464279175, "val_acc": 28.0}
{"epoch": 13, "training_loss": 111.98220229148865, "training_acc": 52.0, "val_loss": 27.61901319026947, "val_acc": 72.0}
{"epoch": 14, "training_loss": 107.22120714187622, "training_acc": 60.0, "val_loss": 58.395397663116455, "val_acc": 72.0}
{"epoch": 15, "training_loss": 246.9107789993286, "training_acc": 72.0, "val_loss": 14.918690919876099, "val_acc": 72.0}
{"epoch": 16, "training_loss": 131.4244909286499, "training_acc": 60.0, "val_loss": 78.69434356689453, "val_acc": 72.0}
{"epoch": 17, "training_loss": 338.05891036987305, "training_acc": 72.0, "val_loss": 82.52360224723816, "val_acc": 72.0}
{"epoch": 18, "training_loss": 209.56082940101624, "training_acc": 72.0, "val_loss": 251.19895935058594, "val_acc": 28.0}
{"epoch": 19, "training_loss": 829.9223098754883, "training_acc": 28.0, "val_loss": 138.7858271598816, "val_acc": 72.0}
{"epoch": 20, "training_loss": 693.6152877807617, "training_acc": 72.0, "val_loss": 289.9604082107544, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1138.249038696289, "training_acc": 72.0, "val_loss": 195.11351585388184, "val_acc": 72.0}
{"epoch": 22, "training_loss": 594.1916627883911, "training_acc": 72.0, "val_loss": 266.20945930480957, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1071.5670890808105, "training_acc": 28.0, "val_loss": 39.92966413497925, "val_acc": 72.0}
{"epoch": 24, "training_loss": 260.229700088501, "training_acc": 72.0, "val_loss": 116.92831516265869, "val_acc": 72.0}
{"epoch": 25, "training_loss": 392.20910453796387, "training_acc": 72.0, "val_loss": 83.61437320709229, "val_acc": 28.0}
{"epoch": 26, "training_loss": 234.51908612251282, "training_acc": 46.0, "val_loss": 26.978138089179993, "val_acc": 72.0}
{"epoch": 27, "training_loss": 132.61406183242798, "training_acc": 56.0, "val_loss": 71.10571265220642, "val_acc": 72.0}
{"epoch": 28, "training_loss": 305.7430200576782, "training_acc": 72.0, "val_loss": 53.11092138290405, "val_acc": 72.0}
{"epoch": 29, "training_loss": 258.01997566223145, "training_acc": 56.0, "val_loss": 33.77479612827301, "val_acc": 72.0}
{"epoch": 30, "training_loss": 129.5389528274536, "training_acc": 72.0, "val_loss": 33.23662877082825, "val_acc": 28.0}
{"epoch": 31, "training_loss": 241.73738288879395, "training_acc": 36.0, "val_loss": 73.18750023841858, "val_acc": 72.0}
{"epoch": 32, "training_loss": 227.39454197883606, "training_acc": 72.0, "val_loss": 130.83806037902832, "val_acc": 28.0}
{"epoch": 33, "training_loss": 356.35936307907104, "training_acc": 48.0, "val_loss": 60.97919940948486, "val_acc": 72.0}
{"epoch": 34, "training_loss": 202.48193216323853, "training_acc": 72.0, "val_loss": 124.06512498855591, "val_acc": 28.0}
