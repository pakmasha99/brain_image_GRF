"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 207771.9183998108, "training_acc": 42.0, "val_loss": 114575.6591796875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 393905.31494140625, "training_acc": 72.0, "val_loss": 66237.02392578125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 198163.83569335938, "training_acc": 28.0, "val_loss": 47410.6201171875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 245894.623046875, "training_acc": 72.0, "val_loss": 90534.0087890625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 353604.73046875, "training_acc": 72.0, "val_loss": 66109.34448242188, "val_acc": 72.0}
{"epoch": 5, "training_loss": 229032.8271484375, "training_acc": 72.0, "val_loss": 6107.429885864258, "val_acc": 28.0}
{"epoch": 6, "training_loss": 26663.762329101562, "training_acc": 28.0, "val_loss": 24993.870544433594, "val_acc": 72.0}
{"epoch": 7, "training_loss": 117405.83740234375, "training_acc": 72.0, "val_loss": 41755.755615234375, "val_acc": 72.0}
{"epoch": 8, "training_loss": 155366.94775390625, "training_acc": 72.0, "val_loss": 16925.135803222656, "val_acc": 72.0}
{"epoch": 9, "training_loss": 79585.640625, "training_acc": 56.0, "val_loss": 18840.475463867188, "val_acc": 28.0}
{"epoch": 10, "training_loss": 74223.76879882812, "training_acc": 44.0, "val_loss": 32272.265625, "val_acc": 72.0}
{"epoch": 11, "training_loss": 133481.6552734375, "training_acc": 72.0, "val_loss": 29491.549682617188, "val_acc": 72.0}
{"epoch": 12, "training_loss": 93800.58032226562, "training_acc": 72.0, "val_loss": 20214.83154296875, "val_acc": 28.0}
{"epoch": 13, "training_loss": 68648.44360351562, "training_acc": 28.0, "val_loss": 19414.0380859375, "val_acc": 72.0}
{"epoch": 14, "training_loss": 97952.923828125, "training_acc": 72.0, "val_loss": 35026.49841308594, "val_acc": 72.0}
{"epoch": 15, "training_loss": 132275.09619140625, "training_acc": 72.0, "val_loss": 13432.670593261719, "val_acc": 72.0}
{"epoch": 16, "training_loss": 39284.56848144531, "training_acc": 66.0, "val_loss": 7116.590118408203, "val_acc": 28.0}
{"epoch": 17, "training_loss": 47973.255126953125, "training_acc": 44.0, "val_loss": 33897.4609375, "val_acc": 72.0}
{"epoch": 18, "training_loss": 139344.27099609375, "training_acc": 72.0, "val_loss": 31092.626953125, "val_acc": 72.0}
{"epoch": 19, "training_loss": 106589.66577148438, "training_acc": 72.0, "val_loss": 11631.544494628906, "val_acc": 28.0}
{"epoch": 20, "training_loss": 31516.367321014404, "training_acc": 40.0, "val_loss": 12941.5283203125, "val_acc": 28.0}
{"epoch": 21, "training_loss": 62838.839111328125, "training_acc": 36.0, "val_loss": 18725.550842285156, "val_acc": 72.0}
{"epoch": 22, "training_loss": 68976.19677734375, "training_acc": 72.0, "val_loss": 3084.188461303711, "val_acc": 72.0}
{"epoch": 23, "training_loss": 56303.43408203125, "training_acc": 62.0, "val_loss": 31299.795532226562, "val_acc": 28.0}
{"epoch": 24, "training_loss": 100614.3759765625, "training_acc": 42.0, "val_loss": 25154.85076904297, "val_acc": 72.0}
{"epoch": 25, "training_loss": 110228.47216796875, "training_acc": 72.0, "val_loss": 23381.390380859375, "val_acc": 72.0}
{"epoch": 26, "training_loss": 73134.60803222656, "training_acc": 72.0, "val_loss": 33997.92175292969, "val_acc": 28.0}
{"epoch": 27, "training_loss": 129784.52734375, "training_acc": 28.0, "val_loss": 12599.254608154297, "val_acc": 72.0}
{"epoch": 28, "training_loss": 74478.68212890625, "training_acc": 72.0, "val_loss": 30421.017456054688, "val_acc": 72.0}
{"epoch": 29, "training_loss": 113508.7109375, "training_acc": 72.0, "val_loss": 11689.836883544922, "val_acc": 72.0}
{"epoch": 30, "training_loss": 78003.65673828125, "training_acc": 48.0, "val_loss": 10881.624603271484, "val_acc": 28.0}
{"epoch": 31, "training_loss": 62797.95068359375, "training_acc": 42.0, "val_loss": 36823.687744140625, "val_acc": 72.0}
{"epoch": 32, "training_loss": 155081.14892578125, "training_acc": 72.0, "val_loss": 38527.23388671875, "val_acc": 72.0}
{"epoch": 33, "training_loss": 134343.939453125, "training_acc": 72.0, "val_loss": 7851.587677001953, "val_acc": 72.0}
{"epoch": 34, "training_loss": 104456.7587890625, "training_acc": 50.0, "val_loss": 52810.07080078125, "val_acc": 28.0}
{"epoch": 35, "training_loss": 136929.4994354248, "training_acc": 28.0, "val_loss": 38104.86755371094, "val_acc": 72.0}
{"epoch": 36, "training_loss": 189447.875, "training_acc": 72.0, "val_loss": 81006.03637695312, "val_acc": 72.0}
{"epoch": 37, "training_loss": 335303.662109375, "training_acc": 72.0, "val_loss": 85245.4345703125, "val_acc": 72.0}
{"epoch": 38, "training_loss": 323959.181640625, "training_acc": 72.0, "val_loss": 56106.982421875, "val_acc": 72.0}
{"epoch": 39, "training_loss": 200472.70263671875, "training_acc": 72.0, "val_loss": 773.542594909668, "val_acc": 72.0}
{"epoch": 40, "training_loss": 107220.85620117188, "training_acc": 62.0, "val_loss": 110377.7587890625, "val_acc": 28.0}
{"epoch": 41, "training_loss": 399526.8447265625, "training_acc": 28.0, "val_loss": 331.97460174560547, "val_acc": 48.0}
{"epoch": 42, "training_loss": 57876.02490234375, "training_acc": 64.0, "val_loss": 61016.80908203125, "val_acc": 72.0}
{"epoch": 43, "training_loss": 257156.1396484375, "training_acc": 72.0, "val_loss": 78687.2314453125, "val_acc": 72.0}
{"epoch": 44, "training_loss": 308064.9345703125, "training_acc": 72.0, "val_loss": 63207.415771484375, "val_acc": 72.0}
{"epoch": 45, "training_loss": 221836.1728515625, "training_acc": 72.0, "val_loss": 18276.73797607422, "val_acc": 72.0}
{"epoch": 46, "training_loss": 78927.87109375, "training_acc": 62.0, "val_loss": 53042.00439453125, "val_acc": 28.0}
{"epoch": 47, "training_loss": 161119.76611328125, "training_acc": 28.0, "val_loss": 26513.226318359375, "val_acc": 72.0}
{"epoch": 48, "training_loss": 140298.8955078125, "training_acc": 72.0, "val_loss": 60765.234375, "val_acc": 72.0}
{"epoch": 49, "training_loss": 243679.4404296875, "training_acc": 72.0, "val_loss": 56446.600341796875, "val_acc": 72.0}
{"epoch": 50, "training_loss": 202316.4716796875, "training_acc": 72.0, "val_loss": 22171.925354003906, "val_acc": 72.0}
{"epoch": 51, "training_loss": 60725.13537597656, "training_acc": 62.0, "val_loss": 22654.79278564453, "val_acc": 28.0}
{"epoch": 52, "training_loss": 66592.16186523438, "training_acc": 46.0, "val_loss": 15447.447204589844, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57589.56823730469, "training_acc": 72.0, "val_loss": 4250.823593139648, "val_acc": 72.0}
{"epoch": 54, "training_loss": 47105.7314453125, "training_acc": 60.0, "val_loss": 13091.317749023438, "val_acc": 28.0}
{"epoch": 55, "training_loss": 63839.451171875, "training_acc": 44.0, "val_loss": 37282.73010253906, "val_acc": 72.0}
{"epoch": 56, "training_loss": 155835.20263671875, "training_acc": 72.0, "val_loss": 40230.279541015625, "val_acc": 72.0}
{"epoch": 57, "training_loss": 144542.94213867188, "training_acc": 72.0, "val_loss": 10841.129302978516, "val_acc": 72.0}
{"epoch": 58, "training_loss": 77307.24072265625, "training_acc": 56.0, "val_loss": 36236.77673339844, "val_acc": 28.0}
{"epoch": 59, "training_loss": 95229.23425292969, "training_acc": 48.0, "val_loss": 17329.0771484375, "val_acc": 72.0}
{"epoch": 60, "training_loss": 71386.12231445312, "training_acc": 72.0, "val_loss": 12804.457092285156, "val_acc": 72.0}
