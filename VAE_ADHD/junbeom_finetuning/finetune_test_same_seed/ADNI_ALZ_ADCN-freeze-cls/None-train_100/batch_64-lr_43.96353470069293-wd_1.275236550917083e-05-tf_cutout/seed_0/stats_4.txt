"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 208582.79342269897, "training_acc": 42.0, "val_loss": 116315.185546875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 427223.49951171875, "training_acc": 72.0, "val_loss": 49832.568359375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 134355.11959838867, "training_acc": 42.0, "val_loss": 2497.2579956054688, "val_acc": 28.0}
{"epoch": 3, "training_loss": 64537.30224609375, "training_acc": 42.0, "val_loss": 53291.558837890625, "val_acc": 72.0}
{"epoch": 4, "training_loss": 215979.8779296875, "training_acc": 72.0, "val_loss": 40074.420166015625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 122779.38403320312, "training_acc": 72.0, "val_loss": 57088.17138671875, "val_acc": 28.0}
{"epoch": 6, "training_loss": 223287.06640625, "training_acc": 28.0, "val_loss": 6460.97412109375, "val_acc": 72.0}
{"epoch": 7, "training_loss": 58332.59716796875, "training_acc": 72.0, "val_loss": 22779.640197753906, "val_acc": 72.0}
{"epoch": 8, "training_loss": 75220.24755859375, "training_acc": 72.0, "val_loss": 16648.50311279297, "val_acc": 28.0}
{"epoch": 9, "training_loss": 41737.858550071716, "training_acc": 44.0, "val_loss": 12949.76806640625, "val_acc": 72.0}
{"epoch": 10, "training_loss": 52160.167236328125, "training_acc": 72.0, "val_loss": 6974.89013671875, "val_acc": 72.0}
{"epoch": 11, "training_loss": 53537.278564453125, "training_acc": 54.0, "val_loss": 1927.2890090942383, "val_acc": 72.0}
{"epoch": 12, "training_loss": 11669.203979492188, "training_acc": 72.0, "val_loss": 14842.720031738281, "val_acc": 28.0}
{"epoch": 13, "training_loss": 47272.480224609375, "training_acc": 46.0, "val_loss": 12251.126861572266, "val_acc": 72.0}
{"epoch": 14, "training_loss": 42074.12286376953, "training_acc": 72.0, "val_loss": 16243.527221679688, "val_acc": 28.0}
{"epoch": 15, "training_loss": 42500.36926269531, "training_acc": 50.0, "val_loss": 6594.760894775391, "val_acc": 72.0}
{"epoch": 16, "training_loss": 18334.79302597046, "training_acc": 54.0, "val_loss": 16210.533142089844, "val_acc": 72.0}
{"epoch": 17, "training_loss": 76899.67529296875, "training_acc": 72.0, "val_loss": 19277.55889892578, "val_acc": 72.0}
{"epoch": 18, "training_loss": 58218.812255859375, "training_acc": 72.0, "val_loss": 33574.37744140625, "val_acc": 28.0}
{"epoch": 19, "training_loss": 124811.41455078125, "training_acc": 28.0, "val_loss": 15988.429260253906, "val_acc": 72.0}
{"epoch": 20, "training_loss": 80921.88989257812, "training_acc": 72.0, "val_loss": 37668.90563964844, "val_acc": 72.0}
{"epoch": 21, "training_loss": 147157.087890625, "training_acc": 72.0, "val_loss": 24529.039001464844, "val_acc": 72.0}
{"epoch": 22, "training_loss": 65120.84753417969, "training_acc": 72.0, "val_loss": 48043.194580078125, "val_acc": 28.0}
{"epoch": 23, "training_loss": 201625.9716796875, "training_acc": 28.0, "val_loss": 2151.6679763793945, "val_acc": 28.0}
{"epoch": 24, "training_loss": 78794.25048828125, "training_acc": 38.0, "val_loss": 64818.182373046875, "val_acc": 72.0}
{"epoch": 25, "training_loss": 277833.3203125, "training_acc": 72.0, "val_loss": 84981.81762695312, "val_acc": 72.0}
{"epoch": 26, "training_loss": 335623.734375, "training_acc": 72.0, "val_loss": 70608.04443359375, "val_acc": 72.0}
{"epoch": 27, "training_loss": 251465.5, "training_acc": 72.0, "val_loss": 26216.6748046875, "val_acc": 72.0}
{"epoch": 28, "training_loss": 83498.30834960938, "training_acc": 58.0, "val_loss": 33607.79113769531, "val_acc": 28.0}
{"epoch": 29, "training_loss": 83051.1480178833, "training_acc": 48.0, "val_loss": 6230.962371826172, "val_acc": 72.0}
{"epoch": 30, "training_loss": 21439.442810058594, "training_acc": 72.0, "val_loss": 20361.976623535156, "val_acc": 28.0}
