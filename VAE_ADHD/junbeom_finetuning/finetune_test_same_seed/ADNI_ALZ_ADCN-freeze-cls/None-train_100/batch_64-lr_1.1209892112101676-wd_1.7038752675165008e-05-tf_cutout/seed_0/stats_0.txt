"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5324.361053466797, "training_acc": 42.0, "val_loss": 2891.736602783203, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9081.934692382812, "training_acc": 72.0, "val_loss": 1681.4245223999023, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5734.646041870117, "training_acc": 28.0, "val_loss": 918.958568572998, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4737.161376953125, "training_acc": 72.0, "val_loss": 1935.867691040039, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7579.877410888672, "training_acc": 72.0, "val_loss": 1367.8730010986328, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4772.677543640137, "training_acc": 72.0, "val_loss": 935.7595443725586, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3685.323532104492, "training_acc": 28.0, "val_loss": 351.74639225006104, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1719.2829055786133, "training_acc": 72.0, "val_loss": 766.377067565918, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2813.583267211914, "training_acc": 72.0, "val_loss": 181.261944770813, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2624.1132202148438, "training_acc": 50.0, "val_loss": 984.5953941345215, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2951.244239807129, "training_acc": 44.0, "val_loss": 695.7173824310303, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2958.3743896484375, "training_acc": 72.0, "val_loss": 706.0317039489746, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2373.210834503174, "training_acc": 72.0, "val_loss": 415.4557228088379, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1361.6337966918945, "training_acc": 28.0, "val_loss": 606.1898231506348, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3175.6888427734375, "training_acc": 72.0, "val_loss": 1186.9725227355957, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4628.397933959961, "training_acc": 72.0, "val_loss": 799.8813152313232, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2361.541519165039, "training_acc": 72.0, "val_loss": 993.117618560791, "val_acc": 28.0}
{"epoch": 17, "training_loss": 4396.065292358398, "training_acc": 28.0, "val_loss": 25.82070529460907, "val_acc": 72.0}
{"epoch": 18, "training_loss": 670.9463996887207, "training_acc": 72.0, "val_loss": 339.7047758102417, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1110.9962463378906, "training_acc": 72.0, "val_loss": 693.4983253479004, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2007.9204177856445, "training_acc": 28.0, "val_loss": 656.215763092041, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3523.4424896240234, "training_acc": 72.0, "val_loss": 1314.2731666564941, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5173.897079467773, "training_acc": 72.0, "val_loss": 1002.3337364196777, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3414.9094314575195, "training_acc": 72.0, "val_loss": 142.34042167663574, "val_acc": 28.0}
{"epoch": 24, "training_loss": 572.8689708709717, "training_acc": 28.0, "val_loss": 476.18889808654785, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2347.9391326904297, "training_acc": 72.0, "val_loss": 793.7748908996582, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2920.957794189453, "training_acc": 72.0, "val_loss": 238.09130191802979, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1722.279899597168, "training_acc": 56.0, "val_loss": 617.6055908203125, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1973.4338264465332, "training_acc": 46.0, "val_loss": 655.4044246673584, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2743.6353759765625, "training_acc": 72.0, "val_loss": 619.1302299499512, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2110.5928173065186, "training_acc": 72.0, "val_loss": 538.9328956604004, "val_acc": 28.0}
{"epoch": 31, "training_loss": 1663.1419620513916, "training_acc": 28.0, "val_loss": 542.6052093505859, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2512.612892150879, "training_acc": 72.0, "val_loss": 960.3779792785645, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3682.0283126831055, "training_acc": 72.0, "val_loss": 540.4823303222656, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1385.074945449829, "training_acc": 72.0, "val_loss": 1443.7050819396973, "val_acc": 28.0}
{"epoch": 35, "training_loss": 5963.331359863281, "training_acc": 28.0, "val_loss": 290.62860012054443, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1811.5942306518555, "training_acc": 46.0, "val_loss": 1519.3389892578125, "val_acc": 72.0}
