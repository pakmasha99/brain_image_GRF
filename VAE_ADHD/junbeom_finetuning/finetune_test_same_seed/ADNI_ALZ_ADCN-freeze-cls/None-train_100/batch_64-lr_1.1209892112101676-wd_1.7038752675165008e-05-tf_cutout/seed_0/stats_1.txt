"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5313.7222900390625, "training_acc": 72.0, "val_loss": 2699.446678161621, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7805.684997558594, "training_acc": 72.0, "val_loss": 2598.065185546875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9677.967254638672, "training_acc": 28.0, "val_loss": 426.1068820953369, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2429.2830505371094, "training_acc": 72.0, "val_loss": 1311.191463470459, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5052.582778930664, "training_acc": 72.0, "val_loss": 697.2672462463379, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1580.3120574951172, "training_acc": 72.0, "val_loss": 2425.395965576172, "val_acc": 28.0}
{"epoch": 6, "training_loss": 9850.878448486328, "training_acc": 28.0, "val_loss": 852.2369384765625, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3565.172164916992, "training_acc": 42.0, "val_loss": 1645.6180572509766, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7640.15869140625, "training_acc": 72.0, "val_loss": 2302.170181274414, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9045.712707519531, "training_acc": 72.0, "val_loss": 1831.0476303100586, "val_acc": 72.0}
{"epoch": 10, "training_loss": 6585.209045410156, "training_acc": 72.0, "val_loss": 511.5583896636963, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3153.0030059814453, "training_acc": 52.0, "val_loss": 1499.7934341430664, "val_acc": 28.0}
{"epoch": 12, "training_loss": 4467.642051696777, "training_acc": 28.0, "val_loss": 757.5599670410156, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3991.7164611816406, "training_acc": 72.0, "val_loss": 1682.1517944335938, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6897.243469238281, "training_acc": 72.0, "val_loss": 1602.8087615966797, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5920.756805419922, "training_acc": 72.0, "val_loss": 668.889045715332, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2188.5186195373535, "training_acc": 52.0, "val_loss": 311.16459369659424, "val_acc": 28.0}
{"epoch": 17, "training_loss": 864.3723812103271, "training_acc": 56.0, "val_loss": 596.8431949615479, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2473.794578552246, "training_acc": 72.0, "val_loss": 492.61412620544434, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1533.4503831863403, "training_acc": 72.0, "val_loss": 1064.3521308898926, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3939.586151123047, "training_acc": 28.0, "val_loss": 281.1716318130493, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1437.9291381835938, "training_acc": 72.0, "val_loss": 723.0625629425049, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2764.3044815063477, "training_acc": 72.0, "val_loss": 334.60140228271484, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1366.159538269043, "training_acc": 56.0, "val_loss": 30.3484708070755, "val_acc": 28.0}
{"epoch": 24, "training_loss": 389.1799507141113, "training_acc": 54.0, "val_loss": 752.451229095459, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3108.384719848633, "training_acc": 72.0, "val_loss": 663.7488842010498, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2226.8367958068848, "training_acc": 72.0, "val_loss": 588.723087310791, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2213.37638092041, "training_acc": 28.0, "val_loss": 470.9887504577637, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2383.481590270996, "training_acc": 72.0, "val_loss": 1014.5357131958008, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3967.596435546875, "training_acc": 72.0, "val_loss": 670.5959796905518, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2132.064516067505, "training_acc": 72.0, "val_loss": 1094.4489479064941, "val_acc": 28.0}
{"epoch": 31, "training_loss": 4286.972183227539, "training_acc": 28.0, "val_loss": 120.91764211654663, "val_acc": 72.0}
{"epoch": 32, "training_loss": 918.4146957397461, "training_acc": 72.0, "val_loss": 410.20727157592773, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1352.105396270752, "training_acc": 72.0, "val_loss": 453.4111976623535, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1164.163046836853, "training_acc": 32.0, "val_loss": 440.60163497924805, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2043.1070861816406, "training_acc": 72.0, "val_loss": 594.2727088928223, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2048.2194175720215, "training_acc": 72.0, "val_loss": 236.5229845046997, "val_acc": 28.0}
{"epoch": 37, "training_loss": 664.5975637435913, "training_acc": 46.0, "val_loss": 12.250028550624847, "val_acc": 76.0}
{"epoch": 38, "training_loss": 336.71665954589844, "training_acc": 53.0, "val_loss": 410.77637672424316, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2146.397171020508, "training_acc": 72.0, "val_loss": 642.6712512969971, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2244.8907165527344, "training_acc": 72.0, "val_loss": 99.68968033790588, "val_acc": 28.0}
{"epoch": 41, "training_loss": 355.0649061203003, "training_acc": 48.0, "val_loss": 54.0935218334198, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1127.3879623413086, "training_acc": 50.0, "val_loss": 116.22594594955444, "val_acc": 72.0}
{"epoch": 43, "training_loss": 591.585334777832, "training_acc": 72.0, "val_loss": 102.02842950820923, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1115.8386306762695, "training_acc": 54.0, "val_loss": 58.008044958114624, "val_acc": 72.0}
{"epoch": 45, "training_loss": 319.75451850891113, "training_acc": 72.0, "val_loss": 184.5198154449463, "val_acc": 28.0}
{"epoch": 46, "training_loss": 1047.6146850585938, "training_acc": 40.0, "val_loss": 430.38201332092285, "val_acc": 72.0}
{"epoch": 47, "training_loss": 1564.1537399291992, "training_acc": 72.0, "val_loss": 12.547393143177032, "val_acc": 72.0}
{"epoch": 48, "training_loss": 807.8822860717773, "training_acc": 57.0, "val_loss": 141.88095331192017, "val_acc": 72.0}
{"epoch": 49, "training_loss": 842.619571685791, "training_acc": 72.0, "val_loss": 140.32833576202393, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1504.516502380371, "training_acc": 48.0, "val_loss": 25.792798399925232, "val_acc": 72.0}
{"epoch": 51, "training_loss": 209.17987251281738, "training_acc": 72.0, "val_loss": 204.74259853363037, "val_acc": 28.0}
{"epoch": 52, "training_loss": 699.3181762695312, "training_acc": 52.0, "val_loss": 431.6446304321289, "val_acc": 72.0}
{"epoch": 53, "training_loss": 1706.840087890625, "training_acc": 72.0, "val_loss": 126.64756774902344, "val_acc": 72.0}
{"epoch": 54, "training_loss": 1711.0095977783203, "training_acc": 54.0, "val_loss": 568.0603504180908, "val_acc": 28.0}
{"epoch": 55, "training_loss": 2067.745216369629, "training_acc": 44.0, "val_loss": 815.0003433227539, "val_acc": 72.0}
{"epoch": 56, "training_loss": 3397.970558166504, "training_acc": 72.0, "val_loss": 859.2147827148438, "val_acc": 72.0}
