"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6293.658256530762, "training_acc": 72.0, "val_loss": 2628.4210205078125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8767.540138244629, "training_acc": 72.0, "val_loss": 2848.565673828125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 10005.168670654297, "training_acc": 28.0, "val_loss": 596.7592716217041, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3147.9156036376953, "training_acc": 72.0, "val_loss": 1543.015956878662, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5983.81526184082, "training_acc": 72.0, "val_loss": 952.2304534912109, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2905.254985809326, "training_acc": 72.0, "val_loss": 2054.475975036621, "val_acc": 28.0}
{"epoch": 6, "training_loss": 8286.04263305664, "training_acc": 28.0, "val_loss": 277.39763259887695, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1755.4227294921875, "training_acc": 50.0, "val_loss": 1999.477767944336, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8504.848327636719, "training_acc": 72.0, "val_loss": 2807.6913833618164, "val_acc": 72.0}
{"epoch": 9, "training_loss": 11232.815368652344, "training_acc": 72.0, "val_loss": 2578.2487869262695, "val_acc": 72.0}
{"epoch": 10, "training_loss": 9546.571685791016, "training_acc": 72.0, "val_loss": 1444.1621780395508, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4622.238876342773, "training_acc": 72.0, "val_loss": 1217.4296379089355, "val_acc": 28.0}
{"epoch": 12, "training_loss": 6048.2542724609375, "training_acc": 28.0, "val_loss": 989.5155906677246, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3116.5774688720703, "training_acc": 46.0, "val_loss": 1106.0669898986816, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4812.555252075195, "training_acc": 72.0, "val_loss": 1497.8927612304688, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5758.917694091797, "training_acc": 72.0, "val_loss": 984.4694137573242, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3101.818817138672, "training_acc": 72.0, "val_loss": 878.6618232727051, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3831.1807403564453, "training_acc": 28.0, "val_loss": 58.04622173309326, "val_acc": 72.0}
{"epoch": 18, "training_loss": 535.6876678466797, "training_acc": 72.0, "val_loss": 260.9137296676636, "val_acc": 72.0}
{"epoch": 19, "training_loss": 666.4644145965576, "training_acc": 72.0, "val_loss": 1043.9350128173828, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3563.4072799682617, "training_acc": 28.0, "val_loss": 436.4597797393799, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2358.4745483398438, "training_acc": 72.0, "val_loss": 962.0963096618652, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3704.951156616211, "training_acc": 72.0, "val_loss": 546.1448669433594, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1312.6177101135254, "training_acc": 72.0, "val_loss": 1385.4939460754395, "val_acc": 28.0}
{"epoch": 24, "training_loss": 5743.908706665039, "training_acc": 28.0, "val_loss": 243.7347412109375, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1874.6871948242188, "training_acc": 44.0, "val_loss": 1553.8471221923828, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6625.49934387207, "training_acc": 72.0, "val_loss": 2102.108383178711, "val_acc": 72.0}
{"epoch": 27, "training_loss": 8329.217712402344, "training_acc": 72.0, "val_loss": 1783.3507537841797, "val_acc": 72.0}
{"epoch": 28, "training_loss": 6260.689605712891, "training_acc": 72.0, "val_loss": 673.7082481384277, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2158.2410888671875, "training_acc": 58.0, "val_loss": 900.0057220458984, "val_acc": 28.0}
{"epoch": 30, "training_loss": 2524.9751329421997, "training_acc": 38.0, "val_loss": 133.5060954093933, "val_acc": 72.0}
{"epoch": 31, "training_loss": 332.9671747684479, "training_acc": 73.0, "val_loss": 437.8180980682373, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1709.7134857177734, "training_acc": 36.0, "val_loss": 341.1193370819092, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1161.0413455963135, "training_acc": 72.0, "val_loss": 307.03461170196533, "val_acc": 28.0}
{"epoch": 34, "training_loss": 879.68492603302, "training_acc": 48.0, "val_loss": 153.2698631286621, "val_acc": 72.0}
{"epoch": 35, "training_loss": 358.8468211889267, "training_acc": 76.0, "val_loss": 72.86289930343628, "val_acc": 28.0}
{"epoch": 36, "training_loss": 679.9617233276367, "training_acc": 48.0, "val_loss": 711.7110252380371, "val_acc": 72.0}
