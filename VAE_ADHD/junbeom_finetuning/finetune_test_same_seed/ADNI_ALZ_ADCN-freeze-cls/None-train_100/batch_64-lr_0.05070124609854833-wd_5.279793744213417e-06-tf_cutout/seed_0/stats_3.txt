"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 261.9360523223877, "training_acc": 44.0, "val_loss": 130.3986668586731, "val_acc": 72.0}
{"epoch": 1, "training_loss": 453.7289824485779, "training_acc": 72.0, "val_loss": 97.85500764846802, "val_acc": 28.0}
{"epoch": 2, "training_loss": 313.22714138031006, "training_acc": 28.0, "val_loss": 45.75580954551697, "val_acc": 72.0}
{"epoch": 3, "training_loss": 225.17648315429688, "training_acc": 72.0, "val_loss": 90.73770046234131, "val_acc": 72.0}
{"epoch": 4, "training_loss": 355.0964984893799, "training_acc": 72.0, "val_loss": 61.66626811027527, "val_acc": 72.0}
{"epoch": 5, "training_loss": 213.16612911224365, "training_acc": 72.0, "val_loss": 59.78912711143494, "val_acc": 28.0}
{"epoch": 6, "training_loss": 240.37154006958008, "training_acc": 28.0, "val_loss": 14.869336783885956, "val_acc": 72.0}
{"epoch": 7, "training_loss": 113.85392379760742, "training_acc": 72.0, "val_loss": 45.91743350028992, "val_acc": 72.0}
{"epoch": 8, "training_loss": 177.55157089233398, "training_acc": 72.0, "val_loss": 24.739287793636322, "val_acc": 72.0}
{"epoch": 9, "training_loss": 94.19897198677063, "training_acc": 56.0, "val_loss": 37.150636315345764, "val_acc": 28.0}
{"epoch": 10, "training_loss": 115.08304619789124, "training_acc": 46.0, "val_loss": 24.44632351398468, "val_acc": 72.0}
{"epoch": 11, "training_loss": 113.21759986877441, "training_acc": 72.0, "val_loss": 28.547966480255127, "val_acc": 72.0}
{"epoch": 12, "training_loss": 89.16892910003662, "training_acc": 72.0, "val_loss": 30.3403377532959, "val_acc": 28.0}
{"epoch": 13, "training_loss": 123.03903102874756, "training_acc": 28.0, "val_loss": 14.96046930551529, "val_acc": 72.0}
{"epoch": 14, "training_loss": 76.24804830551147, "training_acc": 72.0, "val_loss": 27.423784136772156, "val_acc": 72.0}
{"epoch": 15, "training_loss": 99.23001027107239, "training_acc": 72.0, "val_loss": 15.835867822170258, "val_acc": 28.0}
{"epoch": 16, "training_loss": 80.18365240097046, "training_acc": 54.0, "val_loss": 14.930550754070282, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.76967692375183, "training_acc": 72.0, "val_loss": 22.938017547130585, "val_acc": 72.0}
{"epoch": 18, "training_loss": 87.76605248451233, "training_acc": 72.0, "val_loss": 14.970345795154572, "val_acc": 72.0}
{"epoch": 19, "training_loss": 66.5128562450409, "training_acc": 54.0, "val_loss": 14.705313742160797, "val_acc": 72.0}
{"epoch": 20, "training_loss": 63.90081524848938, "training_acc": 72.0, "val_loss": 16.88414365053177, "val_acc": 72.0}
{"epoch": 21, "training_loss": 62.49847722053528, "training_acc": 72.0, "val_loss": 18.898658454418182, "val_acc": 28.0}
{"epoch": 22, "training_loss": 70.61506843566895, "training_acc": 44.0, "val_loss": 16.38582944869995, "val_acc": 72.0}
{"epoch": 23, "training_loss": 69.68463087081909, "training_acc": 72.0, "val_loss": 14.831328392028809, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.23103332519531, "training_acc": 80.0, "val_loss": 16.8722927570343, "val_acc": 28.0}
{"epoch": 25, "training_loss": 65.29631924629211, "training_acc": 75.0, "val_loss": 17.623840272426605, "val_acc": 72.0}
{"epoch": 26, "training_loss": 67.7506582736969, "training_acc": 72.0, "val_loss": 16.972829401493073, "val_acc": 28.0}
{"epoch": 27, "training_loss": 76.46607899665833, "training_acc": 51.0, "val_loss": 17.597287893295288, "val_acc": 72.0}
{"epoch": 28, "training_loss": 79.73728656768799, "training_acc": 72.0, "val_loss": 20.825380086898804, "val_acc": 72.0}
{"epoch": 29, "training_loss": 86.17293286323547, "training_acc": 72.0, "val_loss": 18.009406328201294, "val_acc": 28.0}
{"epoch": 30, "training_loss": 63.916404008865356, "training_acc": 50.0, "val_loss": 19.508500397205353, "val_acc": 72.0}
{"epoch": 31, "training_loss": 77.55155968666077, "training_acc": 72.0, "val_loss": 14.628587663173676, "val_acc": 72.0}
{"epoch": 32, "training_loss": 76.14275431632996, "training_acc": 50.0, "val_loss": 14.657464623451233, "val_acc": 72.0}
{"epoch": 33, "training_loss": 70.57265543937683, "training_acc": 72.0, "val_loss": 18.471473455429077, "val_acc": 72.0}
{"epoch": 34, "training_loss": 65.23257827758789, "training_acc": 72.0, "val_loss": 22.98676073551178, "val_acc": 28.0}
{"epoch": 35, "training_loss": 77.47745108604431, "training_acc": 50.0, "val_loss": 21.671363711357117, "val_acc": 72.0}
