"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 347.2968406677246, "training_acc": 72.0, "val_loss": 113.26292753219604, "val_acc": 72.0}
{"epoch": 1, "training_loss": 344.7928147315979, "training_acc": 72.0, "val_loss": 149.55309629440308, "val_acc": 28.0}
{"epoch": 2, "training_loss": 583.2674694061279, "training_acc": 28.0, "val_loss": 15.274490416049957, "val_acc": 72.0}
{"epoch": 3, "training_loss": 196.59609031677246, "training_acc": 72.0, "val_loss": 91.59043431282043, "val_acc": 72.0}
{"epoch": 4, "training_loss": 374.32379245758057, "training_acc": 72.0, "val_loss": 89.6349549293518, "val_acc": 72.0}
{"epoch": 5, "training_loss": 332.70394134521484, "training_acc": 72.0, "val_loss": 35.396772623062134, "val_acc": 72.0}
{"epoch": 6, "training_loss": 134.3460178375244, "training_acc": 54.0, "val_loss": 54.17715907096863, "val_acc": 28.0}
{"epoch": 7, "training_loss": 175.14927196502686, "training_acc": 28.0, "val_loss": 24.134135246276855, "val_acc": 72.0}
{"epoch": 8, "training_loss": 116.07284450531006, "training_acc": 72.0, "val_loss": 32.05866515636444, "val_acc": 72.0}
{"epoch": 9, "training_loss": 113.37658262252808, "training_acc": 72.0, "val_loss": 21.47555500268936, "val_acc": 28.0}
{"epoch": 10, "training_loss": 97.95774793624878, "training_acc": 28.0, "val_loss": 15.770098567008972, "val_acc": 72.0}
{"epoch": 11, "training_loss": 71.60649585723877, "training_acc": 72.0, "val_loss": 26.749464869499207, "val_acc": 72.0}
{"epoch": 12, "training_loss": 96.83939480781555, "training_acc": 72.0, "val_loss": 16.156673431396484, "val_acc": 28.0}
{"epoch": 13, "training_loss": 77.32964372634888, "training_acc": 58.0, "val_loss": 15.402641892433167, "val_acc": 28.0}
{"epoch": 14, "training_loss": 66.7197539806366, "training_acc": 72.0, "val_loss": 22.159047424793243, "val_acc": 72.0}
{"epoch": 15, "training_loss": 82.1469612121582, "training_acc": 72.0, "val_loss": 16.213031113147736, "val_acc": 28.0}
{"epoch": 16, "training_loss": 75.2367250919342, "training_acc": 52.0, "val_loss": 14.995305240154266, "val_acc": 72.0}
{"epoch": 17, "training_loss": 67.30744218826294, "training_acc": 72.0, "val_loss": 19.52226758003235, "val_acc": 72.0}
{"epoch": 18, "training_loss": 72.98951697349548, "training_acc": 72.0, "val_loss": 18.917709589004517, "val_acc": 28.0}
{"epoch": 19, "training_loss": 70.65475869178772, "training_acc": 46.0, "val_loss": 16.85931384563446, "val_acc": 72.0}
{"epoch": 20, "training_loss": 71.81433248519897, "training_acc": 72.0, "val_loss": 15.406863391399384, "val_acc": 72.0}
{"epoch": 21, "training_loss": 55.80847668647766, "training_acc": 72.0, "val_loss": 24.0041121840477, "val_acc": 28.0}
{"epoch": 22, "training_loss": 86.03740310668945, "training_acc": 40.0, "val_loss": 17.842036485671997, "val_acc": 72.0}
{"epoch": 23, "training_loss": 73.9820168018341, "training_acc": 72.0, "val_loss": 14.818160235881805, "val_acc": 72.0}
{"epoch": 24, "training_loss": 65.81667351722717, "training_acc": 58.0, "val_loss": 15.049923956394196, "val_acc": 72.0}
{"epoch": 25, "training_loss": 57.11121594905853, "training_acc": 72.0, "val_loss": 19.383487105369568, "val_acc": 72.0}
{"epoch": 26, "training_loss": 74.01464128494263, "training_acc": 72.0, "val_loss": 15.600071847438812, "val_acc": 28.0}
{"epoch": 27, "training_loss": 72.61467814445496, "training_acc": 48.0, "val_loss": 16.82959496974945, "val_acc": 72.0}
{"epoch": 28, "training_loss": 79.58413982391357, "training_acc": 72.0, "val_loss": 18.256479501724243, "val_acc": 72.0}
{"epoch": 29, "training_loss": 78.19982552528381, "training_acc": 52.0, "val_loss": 17.675210535526276, "val_acc": 28.0}
{"epoch": 30, "training_loss": 64.18030953407288, "training_acc": 48.0, "val_loss": 19.934777915477753, "val_acc": 72.0}
{"epoch": 31, "training_loss": 76.76719975471497, "training_acc": 72.0, "val_loss": 15.696913003921509, "val_acc": 28.0}
{"epoch": 32, "training_loss": 66.74235105514526, "training_acc": 58.0, "val_loss": 14.730848371982574, "val_acc": 72.0}
{"epoch": 33, "training_loss": 62.91203427314758, "training_acc": 72.0, "val_loss": 16.047684848308563, "val_acc": 72.0}
{"epoch": 34, "training_loss": 65.44088697433472, "training_acc": 72.0, "val_loss": 15.77402800321579, "val_acc": 28.0}
{"epoch": 35, "training_loss": 65.58784937858582, "training_acc": 72.0, "val_loss": 15.414983034133911, "val_acc": 72.0}
{"epoch": 36, "training_loss": 61.16919445991516, "training_acc": 72.0, "val_loss": 15.600451827049255, "val_acc": 28.0}
{"epoch": 37, "training_loss": 61.156726121902466, "training_acc": 72.0, "val_loss": 15.462985634803772, "val_acc": 72.0}
{"epoch": 38, "training_loss": 61.05098342895508, "training_acc": 72.0, "val_loss": 15.21424800157547, "val_acc": 48.0}
{"epoch": 39, "training_loss": 60.56188178062439, "training_acc": 72.0, "val_loss": 14.711852371692657, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.32854413986206, "training_acc": 72.0, "val_loss": 14.82078731060028, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.185680866241455, "training_acc": 72.0, "val_loss": 15.093994140625, "val_acc": 72.0}
{"epoch": 42, "training_loss": 60.24977445602417, "training_acc": 72.0, "val_loss": 14.690414071083069, "val_acc": 72.0}
{"epoch": 43, "training_loss": 60.045687437057495, "training_acc": 72.0, "val_loss": 15.841896831989288, "val_acc": 28.0}
{"epoch": 44, "training_loss": 62.80094075202942, "training_acc": 72.0, "val_loss": 14.657755196094513, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.18603825569153, "training_acc": 72.0, "val_loss": 14.802202582359314, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.380783557891846, "training_acc": 72.0, "val_loss": 14.743563532829285, "val_acc": 72.0}
{"epoch": 47, "training_loss": 60.0488486289978, "training_acc": 72.0, "val_loss": 15.174001455307007, "val_acc": 72.0}
{"epoch": 48, "training_loss": 60.39236807823181, "training_acc": 72.0, "val_loss": 14.981214702129364, "val_acc": 76.0}
{"epoch": 49, "training_loss": 63.624245405197144, "training_acc": 72.0, "val_loss": 18.47839504480362, "val_acc": 72.0}
{"epoch": 50, "training_loss": 77.57448172569275, "training_acc": 72.0, "val_loss": 14.592590928077698, "val_acc": 72.0}
{"epoch": 51, "training_loss": 66.62474846839905, "training_acc": 58.0, "val_loss": 14.598007500171661, "val_acc": 72.0}
{"epoch": 52, "training_loss": 71.97916841506958, "training_acc": 72.0, "val_loss": 15.54301232099533, "val_acc": 72.0}
{"epoch": 53, "training_loss": 62.525022983551025, "training_acc": 60.0, "val_loss": 16.63265973329544, "val_acc": 28.0}
{"epoch": 54, "training_loss": 64.56746864318848, "training_acc": 72.0, "val_loss": 18.99895817041397, "val_acc": 72.0}
{"epoch": 55, "training_loss": 70.17856812477112, "training_acc": 72.0, "val_loss": 19.667769968509674, "val_acc": 28.0}
{"epoch": 56, "training_loss": 69.99456882476807, "training_acc": 46.0, "val_loss": 18.71776133775711, "val_acc": 72.0}
{"epoch": 57, "training_loss": 72.23540949821472, "training_acc": 72.0, "val_loss": 15.808574855327606, "val_acc": 28.0}
{"epoch": 58, "training_loss": 62.86926770210266, "training_acc": 72.0, "val_loss": 14.991168677806854, "val_acc": 72.0}
{"epoch": 59, "training_loss": 68.7449107170105, "training_acc": 72.0, "val_loss": 16.611330211162567, "val_acc": 28.0}
{"epoch": 60, "training_loss": 67.75820922851562, "training_acc": 64.0, "val_loss": 16.70466810464859, "val_acc": 72.0}
{"epoch": 61, "training_loss": 72.67272233963013, "training_acc": 72.0, "val_loss": 14.618933200836182, "val_acc": 72.0}
{"epoch": 62, "training_loss": 84.9079818725586, "training_acc": 48.0, "val_loss": 19.12645250558853, "val_acc": 72.0}
{"epoch": 63, "training_loss": 80.54861760139465, "training_acc": 72.0, "val_loss": 21.640534698963165, "val_acc": 72.0}
{"epoch": 64, "training_loss": 72.54297208786011, "training_acc": 72.0, "val_loss": 30.13535737991333, "val_acc": 28.0}
{"epoch": 65, "training_loss": 101.4509494304657, "training_acc": 42.0, "val_loss": 21.749205887317657, "val_acc": 72.0}
{"epoch": 66, "training_loss": 82.04124569892883, "training_acc": 72.0, "val_loss": 16.708435118198395, "val_acc": 28.0}
{"epoch": 67, "training_loss": 70.31714057922363, "training_acc": 56.0, "val_loss": 19.155380129814148, "val_acc": 72.0}
{"epoch": 68, "training_loss": 84.13197326660156, "training_acc": 72.0, "val_loss": 15.349499881267548, "val_acc": 72.0}
{"epoch": 69, "training_loss": 97.94983673095703, "training_acc": 48.0, "val_loss": 15.21390676498413, "val_acc": 72.0}
