"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 261.7556781768799, "training_acc": 44.0, "val_loss": 131.605064868927, "val_acc": 72.0}
{"epoch": 1, "training_loss": 416.87671279907227, "training_acc": 72.0, "val_loss": 89.51752781867981, "val_acc": 28.0}
{"epoch": 2, "training_loss": 297.1794390678406, "training_acc": 28.0, "val_loss": 39.20864462852478, "val_acc": 72.0}
{"epoch": 3, "training_loss": 194.41515064239502, "training_acc": 72.0, "val_loss": 70.1640784740448, "val_acc": 72.0}
{"epoch": 4, "training_loss": 263.68232250213623, "training_acc": 72.0, "val_loss": 27.455663681030273, "val_acc": 72.0}
{"epoch": 5, "training_loss": 105.0944299697876, "training_acc": 60.0, "val_loss": 40.57269096374512, "val_acc": 28.0}
{"epoch": 6, "training_loss": 118.83054780960083, "training_acc": 48.0, "val_loss": 31.989529728889465, "val_acc": 72.0}
{"epoch": 7, "training_loss": 130.96694898605347, "training_acc": 72.0, "val_loss": 27.220401167869568, "val_acc": 72.0}
{"epoch": 8, "training_loss": 100.94666790962219, "training_acc": 72.0, "val_loss": 27.613425254821777, "val_acc": 28.0}
{"epoch": 9, "training_loss": 93.86400270462036, "training_acc": 42.0, "val_loss": 19.846366345882416, "val_acc": 72.0}
{"epoch": 10, "training_loss": 80.83202481269836, "training_acc": 72.0, "val_loss": 15.54936170578003, "val_acc": 72.0}
{"epoch": 11, "training_loss": 68.31586050987244, "training_acc": 56.0, "val_loss": 16.59223586320877, "val_acc": 28.0}
{"epoch": 12, "training_loss": 66.25289845466614, "training_acc": 72.0, "val_loss": 19.261226058006287, "val_acc": 72.0}
{"epoch": 13, "training_loss": 70.8846390247345, "training_acc": 72.0, "val_loss": 18.625304102897644, "val_acc": 28.0}
{"epoch": 14, "training_loss": 72.62069797515869, "training_acc": 31.0, "val_loss": 16.36623740196228, "val_acc": 72.0}
{"epoch": 15, "training_loss": 72.3691337108612, "training_acc": 72.0, "val_loss": 15.610350668430328, "val_acc": 72.0}
{"epoch": 16, "training_loss": 57.85603356361389, "training_acc": 72.0, "val_loss": 21.187567710876465, "val_acc": 28.0}
{"epoch": 17, "training_loss": 71.8238091468811, "training_acc": 48.0, "val_loss": 21.32551074028015, "val_acc": 72.0}
{"epoch": 18, "training_loss": 83.35936307907104, "training_acc": 72.0, "val_loss": 14.821426570415497, "val_acc": 72.0}
{"epoch": 19, "training_loss": 72.81218647956848, "training_acc": 54.0, "val_loss": 14.823628962039948, "val_acc": 72.0}
{"epoch": 20, "training_loss": 67.7578353881836, "training_acc": 72.0, "val_loss": 18.579605221748352, "val_acc": 72.0}
{"epoch": 21, "training_loss": 73.66375303268433, "training_acc": 72.0, "val_loss": 17.037923634052277, "val_acc": 28.0}
{"epoch": 22, "training_loss": 62.29193997383118, "training_acc": 74.0, "val_loss": 18.469825387001038, "val_acc": 72.0}
{"epoch": 23, "training_loss": 70.40852975845337, "training_acc": 72.0, "val_loss": 15.751905739307404, "val_acc": 28.0}
{"epoch": 24, "training_loss": 63.42529034614563, "training_acc": 72.0, "val_loss": 15.032730996608734, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.44327688217163, "training_acc": 72.0, "val_loss": 15.41411280632019, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.46319651603699, "training_acc": 72.0, "val_loss": 16.078734397888184, "val_acc": 28.0}
{"epoch": 27, "training_loss": 64.45629000663757, "training_acc": 72.0, "val_loss": 15.095588564872742, "val_acc": 72.0}
{"epoch": 28, "training_loss": 58.62485194206238, "training_acc": 72.0, "val_loss": 15.510985255241394, "val_acc": 32.0}
{"epoch": 29, "training_loss": 66.07455801963806, "training_acc": 72.0, "val_loss": 14.888191223144531, "val_acc": 72.0}
{"epoch": 30, "training_loss": 63.04981303215027, "training_acc": 71.0, "val_loss": 16.11597239971161, "val_acc": 72.0}
{"epoch": 31, "training_loss": 68.26719260215759, "training_acc": 72.0, "val_loss": 14.864420890808105, "val_acc": 72.0}
{"epoch": 32, "training_loss": 65.36027979850769, "training_acc": 56.0, "val_loss": 15.166258811950684, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.83854627609253, "training_acc": 72.0, "val_loss": 15.967623889446259, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.94525623321533, "training_acc": 72.0, "val_loss": 16.590990126132965, "val_acc": 28.0}
{"epoch": 35, "training_loss": 66.00854539871216, "training_acc": 72.0, "val_loss": 16.230416297912598, "val_acc": 72.0}
{"epoch": 36, "training_loss": 62.01520657539368, "training_acc": 72.0, "val_loss": 16.062404215335846, "val_acc": 28.0}
{"epoch": 37, "training_loss": 70.71107530593872, "training_acc": 72.0, "val_loss": 14.842049777507782, "val_acc": 72.0}
