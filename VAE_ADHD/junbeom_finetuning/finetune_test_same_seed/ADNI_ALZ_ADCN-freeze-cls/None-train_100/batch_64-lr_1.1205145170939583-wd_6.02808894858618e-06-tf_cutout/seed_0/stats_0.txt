"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5322.364837646484, "training_acc": 42.0, "val_loss": 2890.456962585449, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9077.040466308594, "training_acc": 72.0, "val_loss": 1680.4027557373047, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5730.649078369141, "training_acc": 28.0, "val_loss": 918.9149856567383, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4736.574554443359, "training_acc": 72.0, "val_loss": 1935.5693817138672, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7578.514373779297, "training_acc": 72.0, "val_loss": 1368.041706085205, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4774.879581451416, "training_acc": 72.0, "val_loss": 933.5949897766113, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3676.0533447265625, "training_acc": 28.0, "val_loss": 352.2286891937256, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1721.026969909668, "training_acc": 72.0, "val_loss": 766.5810585021973, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2814.8843994140625, "training_acc": 72.0, "val_loss": 181.55437707901, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2622.6322174072266, "training_acc": 50.0, "val_loss": 983.2049369812012, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2948.3262825012207, "training_acc": 44.0, "val_loss": 695.9866046905518, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2959.094680786133, "training_acc": 72.0, "val_loss": 706.5608978271484, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2376.0937423706055, "training_acc": 72.0, "val_loss": 412.55555152893066, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1349.7721900939941, "training_acc": 28.0, "val_loss": 606.9925308227539, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3178.929962158203, "training_acc": 72.0, "val_loss": 1187.4019622802734, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4630.384414672852, "training_acc": 72.0, "val_loss": 800.3629684448242, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2364.1503868103027, "training_acc": 72.0, "val_loss": 990.8886909484863, "val_acc": 28.0}
{"epoch": 17, "training_loss": 4385.728866577148, "training_acc": 28.0, "val_loss": 26.300710439682007, "val_acc": 72.0}
{"epoch": 18, "training_loss": 670.3449630737305, "training_acc": 72.0, "val_loss": 337.362265586853, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1101.8384218215942, "training_acc": 72.0, "val_loss": 704.611873626709, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2057.0435905456543, "training_acc": 28.0, "val_loss": 649.7011661529541, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3494.967742919922, "training_acc": 72.0, "val_loss": 1306.151294708252, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5141.020736694336, "training_acc": 72.0, "val_loss": 993.3100700378418, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3380.425926208496, "training_acc": 72.0, "val_loss": 166.65477752685547, "val_acc": 28.0}
{"epoch": 24, "training_loss": 670.7650089263916, "training_acc": 28.0, "val_loss": 466.3276672363281, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2309.212905883789, "training_acc": 72.0, "val_loss": 783.9148998260498, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2881.985511779785, "training_acc": 72.0, "val_loss": 228.67283821105957, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1731.2078704833984, "training_acc": 56.0, "val_loss": 640.8836364746094, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2018.7462310791016, "training_acc": 46.0, "val_loss": 645.8730220794678, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2704.9412841796875, "training_acc": 72.0, "val_loss": 609.6521854400635, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2072.4432735443115, "training_acc": 72.0, "val_loss": 561.8715763092041, "val_acc": 28.0}
{"epoch": 31, "training_loss": 1753.889612197876, "training_acc": 28.0, "val_loss": 533.7648391723633, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2477.937156677246, "training_acc": 72.0, "val_loss": 952.1228790283203, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3649.4717712402344, "training_acc": 72.0, "val_loss": 533.0789089202881, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1356.9644813537598, "training_acc": 72.0, "val_loss": 1459.9531173706055, "val_acc": 28.0}
{"epoch": 35, "training_loss": 6029.367431640625, "training_acc": 28.0, "val_loss": 306.4748525619507, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1843.532096862793, "training_acc": 46.0, "val_loss": 1512.5322341918945, "val_acc": 72.0}
