"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4375.767925262451, "training_acc": 46.0, "val_loss": 3015.6850814819336, "val_acc": 72.0}
{"epoch": 1, "training_loss": 10365.802032470703, "training_acc": 72.0, "val_loss": 1840.9557342529297, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5487.182008743286, "training_acc": 28.0, "val_loss": 1292.1268463134766, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6388.599090576172, "training_acc": 72.0, "val_loss": 2298.8494873046875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8938.090454101562, "training_acc": 72.0, "val_loss": 1595.4198837280273, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5193.235382080078, "training_acc": 72.0, "val_loss": 793.4654235839844, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3346.813217163086, "training_acc": 28.0, "val_loss": 288.44311237335205, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1964.7999572753906, "training_acc": 72.0, "val_loss": 601.3404369354248, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1960.2108993530273, "training_acc": 72.0, "val_loss": 743.791675567627, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2331.9649238586426, "training_acc": 28.0, "val_loss": 649.0541934967041, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3246.4779052734375, "training_acc": 72.0, "val_loss": 1287.0128631591797, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5029.343765258789, "training_acc": 72.0, "val_loss": 905.6424140930176, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2845.7545013427734, "training_acc": 72.0, "val_loss": 739.5738124847412, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3080.515106201172, "training_acc": 28.0, "val_loss": 244.41049098968506, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1380.4673690795898, "training_acc": 72.0, "val_loss": 570.4099178314209, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2047.443286895752, "training_acc": 72.0, "val_loss": 51.49729251861572, "val_acc": 28.0}
{"epoch": 16, "training_loss": 442.2587890625, "training_acc": 42.0, "val_loss": 150.18020868301392, "val_acc": 72.0}
{"epoch": 17, "training_loss": 979.3117561340332, "training_acc": 52.0, "val_loss": 205.6940793991089, "val_acc": 72.0}
{"epoch": 18, "training_loss": 949.8086128234863, "training_acc": 72.0, "val_loss": 170.96080780029297, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1243.7276000976562, "training_acc": 52.0, "val_loss": 83.75544548034668, "val_acc": 72.0}
{"epoch": 20, "training_loss": 353.04956436157227, "training_acc": 72.0, "val_loss": 171.52868509292603, "val_acc": 28.0}
{"epoch": 21, "training_loss": 699.0398654937744, "training_acc": 50.0, "val_loss": 462.10780143737793, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1742.4893684387207, "training_acc": 72.0, "val_loss": 132.91995525360107, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1441.1312637329102, "training_acc": 56.0, "val_loss": 330.5548667907715, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1876.0789108276367, "training_acc": 40.0, "val_loss": 972.1731185913086, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4045.063186645508, "training_acc": 72.0, "val_loss": 1030.5421829223633, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3763.3290786743164, "training_acc": 72.0, "val_loss": 281.8704128265381, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2104.7339630126953, "training_acc": 54.0, "val_loss": 873.5589027404785, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2435.2090740203857, "training_acc": 46.0, "val_loss": 489.64576721191406, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2079.581657409668, "training_acc": 72.0, "val_loss": 386.0233783721924, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1000.074604511261, "training_acc": 72.0, "val_loss": 829.6941757202148, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2383.7960147857666, "training_acc": 28.0, "val_loss": 693.8998699188232, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3446.4264373779297, "training_acc": 72.0, "val_loss": 1398.1620788574219, "val_acc": 72.0}
{"epoch": 33, "training_loss": 5599.085998535156, "training_acc": 72.0, "val_loss": 1168.5298919677734, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3952.7401580810547, "training_acc": 72.0, "val_loss": 130.42805194854736, "val_acc": 72.0}
