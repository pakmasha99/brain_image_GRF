"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5310.170959472656, "training_acc": 72.0, "val_loss": 2698.7369537353516, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7804.259552001953, "training_acc": 72.0, "val_loss": 2594.9987411499023, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9665.563385009766, "training_acc": 28.0, "val_loss": 426.76854133605957, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2431.1815490722656, "training_acc": 72.0, "val_loss": 1311.875057220459, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5055.7651443481445, "training_acc": 72.0, "val_loss": 698.5489845275879, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1586.1191244125366, "training_acc": 72.0, "val_loss": 2419.831657409668, "val_acc": 28.0}
{"epoch": 6, "training_loss": 9828.343933105469, "training_acc": 28.0, "val_loss": 847.5696563720703, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3554.473114013672, "training_acc": 42.0, "val_loss": 1646.272850036621, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7641.6119384765625, "training_acc": 72.0, "val_loss": 2302.470588684082, "val_acc": 72.0}
{"epoch": 9, "training_loss": 9045.682189941406, "training_acc": 72.0, "val_loss": 1831.6669464111328, "val_acc": 72.0}
{"epoch": 10, "training_loss": 6589.237609863281, "training_acc": 72.0, "val_loss": 512.7391815185547, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3149.3247680664062, "training_acc": 52.0, "val_loss": 1495.3392028808594, "val_acc": 28.0}
{"epoch": 12, "training_loss": 4450.678592681885, "training_acc": 28.0, "val_loss": 758.5619449615479, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3995.179214477539, "training_acc": 72.0, "val_loss": 1682.7783584594727, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6899.806884765625, "training_acc": 72.0, "val_loss": 1603.4454345703125, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5923.166732788086, "training_acc": 72.0, "val_loss": 669.8941707611084, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2184.1310062408447, "training_acc": 52.0, "val_loss": 307.33087062835693, "val_acc": 28.0}
{"epoch": 17, "training_loss": 856.6690921783447, "training_acc": 56.0, "val_loss": 598.0996131896973, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2478.6418838500977, "training_acc": 72.0, "val_loss": 494.09146308898926, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1539.8855724334717, "training_acc": 72.0, "val_loss": 1059.0259552001953, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3918.320343017578, "training_acc": 28.0, "val_loss": 282.9075336456299, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1444.1233139038086, "training_acc": 72.0, "val_loss": 724.6336460113525, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2771.3420486450195, "training_acc": 72.0, "val_loss": 336.22353076934814, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1363.4798583984375, "training_acc": 56.0, "val_loss": 27.322113513946533, "val_acc": 28.0}
{"epoch": 24, "training_loss": 364.1951560974121, "training_acc": 54.0, "val_loss": 701.5830993652344, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2872.4157943725586, "training_acc": 72.0, "val_loss": 569.0775394439697, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1825.3225955963135, "training_acc": 72.0, "val_loss": 927.242374420166, "val_acc": 28.0}
{"epoch": 27, "training_loss": 3635.409423828125, "training_acc": 28.0, "val_loss": 311.57870292663574, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1730.2314224243164, "training_acc": 72.0, "val_loss": 832.7672958374023, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3224.7556381225586, "training_acc": 72.0, "val_loss": 469.788122177124, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1436.226315498352, "training_acc": 52.0, "val_loss": 91.38630628585815, "val_acc": 72.0}
{"epoch": 31, "training_loss": 233.7542576789856, "training_acc": 72.0, "val_loss": 469.85177993774414, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1532.5233039855957, "training_acc": 42.0, "val_loss": 306.37948513031006, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1073.6744117736816, "training_acc": 72.0, "val_loss": 289.6207809448242, "val_acc": 28.0}
{"epoch": 34, "training_loss": 888.2808704376221, "training_acc": 46.0, "val_loss": 155.8122992515564, "val_acc": 72.0}
{"epoch": 35, "training_loss": 499.8659791946411, "training_acc": 56.0, "val_loss": 327.18958854675293, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1443.1245002746582, "training_acc": 72.0, "val_loss": 326.0106086730957, "val_acc": 72.0}
{"epoch": 37, "training_loss": 907.9602100849152, "training_acc": 72.0, "val_loss": 892.9958343505859, "val_acc": 28.0}
{"epoch": 38, "training_loss": 2751.2911987304688, "training_acc": 28.0, "val_loss": 612.1230125427246, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3390.142578125, "training_acc": 72.0, "val_loss": 1296.4017868041992, "val_acc": 72.0}
{"epoch": 40, "training_loss": 5116.0699462890625, "training_acc": 72.0, "val_loss": 989.332389831543, "val_acc": 72.0}
{"epoch": 41, "training_loss": 3438.7864990234375, "training_acc": 72.0, "val_loss": 133.61093997955322, "val_acc": 28.0}
{"epoch": 42, "training_loss": 588.1200904846191, "training_acc": 28.0, "val_loss": 522.3995208740234, "val_acc": 72.0}
