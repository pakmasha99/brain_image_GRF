"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2461.837917327881, "training_acc": 46.0, "val_loss": 1563.0059242248535, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4962.813583374023, "training_acc": 72.0, "val_loss": 1736.672592163086, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6031.986526489258, "training_acc": 28.0, "val_loss": 362.6446485519409, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1854.7363052368164, "training_acc": 72.0, "val_loss": 956.3960075378418, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3745.8021240234375, "training_acc": 72.0, "val_loss": 659.5193386077881, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2164.4426612854004, "training_acc": 72.0, "val_loss": 671.7603206634521, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2505.9481201171875, "training_acc": 28.0, "val_loss": 207.18865394592285, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1264.9463958740234, "training_acc": 72.0, "val_loss": 450.00014305114746, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1578.6053161621094, "training_acc": 72.0, "val_loss": 37.67034113407135, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1527.4005966186523, "training_acc": 54.0, "val_loss": 855.1819801330566, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2172.074172258377, "training_acc": 46.0, "val_loss": 234.12084579467773, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1006.766788482666, "training_acc": 72.0, "val_loss": 195.57946920394897, "val_acc": 72.0}
{"epoch": 12, "training_loss": 470.8774416446686, "training_acc": 74.0, "val_loss": 244.58379745483398, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1038.5706825256348, "training_acc": 36.0, "val_loss": 242.31128692626953, "val_acc": 72.0}
{"epoch": 14, "training_loss": 866.6951637268066, "training_acc": 72.0, "val_loss": 55.18118739128113, "val_acc": 28.0}
{"epoch": 15, "training_loss": 380.57915115356445, "training_acc": 38.0, "val_loss": 90.79806804656982, "val_acc": 72.0}
{"epoch": 16, "training_loss": 467.67420768737793, "training_acc": 56.0, "val_loss": 118.08899641036987, "val_acc": 72.0}
{"epoch": 17, "training_loss": 509.8102397918701, "training_acc": 72.0, "val_loss": 64.06880021095276, "val_acc": 72.0}
{"epoch": 18, "training_loss": 505.75500869750977, "training_acc": 62.0, "val_loss": 16.574011743068695, "val_acc": 72.0}
{"epoch": 19, "training_loss": 124.4125394821167, "training_acc": 72.0, "val_loss": 65.15711545944214, "val_acc": 28.0}
{"epoch": 20, "training_loss": 497.7811698913574, "training_acc": 42.0, "val_loss": 280.5121421813965, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1037.4116802215576, "training_acc": 72.0, "val_loss": 44.37900185585022, "val_acc": 72.0}
{"epoch": 22, "training_loss": 997.2170715332031, "training_acc": 54.0, "val_loss": 348.3177423477173, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1306.4206008911133, "training_acc": 42.0, "val_loss": 462.51893043518066, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1938.6861724853516, "training_acc": 72.0, "val_loss": 458.8535785675049, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1576.652214050293, "training_acc": 72.0, "val_loss": 17.24323183298111, "val_acc": 28.0}
{"epoch": 26, "training_loss": 582.6464233398438, "training_acc": 46.0, "val_loss": 41.10713005065918, "val_acc": 72.0}
{"epoch": 27, "training_loss": 225.11420154571533, "training_acc": 72.0, "val_loss": 16.04321002960205, "val_acc": 28.0}
{"epoch": 28, "training_loss": 71.94914746284485, "training_acc": 72.0, "val_loss": 204.63638305664062, "val_acc": 28.0}
{"epoch": 29, "training_loss": 693.4380016326904, "training_acc": 46.0, "val_loss": 225.68881511688232, "val_acc": 72.0}
{"epoch": 30, "training_loss": 834.9754104614258, "training_acc": 72.0, "val_loss": 15.486659109592438, "val_acc": 72.0}
{"epoch": 31, "training_loss": 800.4614028930664, "training_acc": 54.0, "val_loss": 124.36329126358032, "val_acc": 28.0}
{"epoch": 32, "training_loss": 869.6184768676758, "training_acc": 44.0, "val_loss": 646.1369514465332, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2784.438186645508, "training_acc": 72.0, "val_loss": 718.4269428253174, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2626.1570205688477, "training_acc": 72.0, "val_loss": 288.179874420166, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1174.0323791503906, "training_acc": 52.0, "val_loss": 190.20313024520874, "val_acc": 28.0}
{"epoch": 36, "training_loss": 835.255298614502, "training_acc": 44.0, "val_loss": 403.6763668060303, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1618.0793342590332, "training_acc": 72.0, "val_loss": 312.5237464904785, "val_acc": 72.0}
{"epoch": 38, "training_loss": 998.9853258132935, "training_acc": 72.0, "val_loss": 500.398588180542, "val_acc": 28.0}
{"epoch": 39, "training_loss": 1788.0921516418457, "training_acc": 28.0, "val_loss": 227.46717929840088, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1275.1831588745117, "training_acc": 72.0, "val_loss": 483.278226852417, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1808.410011291504, "training_acc": 72.0, "val_loss": 202.1812915802002, "val_acc": 72.0}
{"epoch": 42, "training_loss": 945.5140571594238, "training_acc": 54.0, "val_loss": 114.39831256866455, "val_acc": 28.0}
{"epoch": 43, "training_loss": 618.9511642456055, "training_acc": 48.0, "val_loss": 499.87010955810547, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2024.3184394836426, "training_acc": 72.0, "val_loss": 480.56626319885254, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1686.3387145996094, "training_acc": 72.0, "val_loss": 51.01678967475891, "val_acc": 72.0}
{"epoch": 46, "training_loss": 835.1227188110352, "training_acc": 68.0, "val_loss": 749.9165534973145, "val_acc": 28.0}
{"epoch": 47, "training_loss": 1956.1188950538635, "training_acc": 28.0, "val_loss": 448.5664367675781, "val_acc": 72.0}
{"epoch": 48, "training_loss": 2141.467758178711, "training_acc": 72.0, "val_loss": 845.5319404602051, "val_acc": 72.0}
{"epoch": 49, "training_loss": 3355.5324630737305, "training_acc": 72.0, "val_loss": 695.9253311157227, "val_acc": 72.0}
