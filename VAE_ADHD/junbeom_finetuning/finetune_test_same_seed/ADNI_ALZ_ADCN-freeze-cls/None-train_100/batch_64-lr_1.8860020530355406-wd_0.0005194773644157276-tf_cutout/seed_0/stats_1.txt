"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8909.804016113281, "training_acc": 72.0, "val_loss": 4536.1541748046875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 13101.794036865234, "training_acc": 72.0, "val_loss": 4401.4984130859375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 16397.73370361328, "training_acc": 28.0, "val_loss": 708.0942630767822, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4051.0611114501953, "training_acc": 72.0, "val_loss": 2194.819450378418, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8453.758361816406, "training_acc": 72.0, "val_loss": 1158.0315589904785, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2596.244092941284, "training_acc": 72.0, "val_loss": 4127.80647277832, "val_acc": 28.0}
{"epoch": 6, "training_loss": 16764.001586914062, "training_acc": 28.0, "val_loss": 1482.5982093811035, "val_acc": 28.0}
{"epoch": 7, "training_loss": 6094.183883666992, "training_acc": 42.0, "val_loss": 2745.962905883789, "val_acc": 72.0}
{"epoch": 8, "training_loss": 12755.567260742188, "training_acc": 72.0, "val_loss": 3842.27294921875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 15087.626220703125, "training_acc": 72.0, "val_loss": 3040.8809661865234, "val_acc": 72.0}
{"epoch": 10, "training_loss": 10915.552276611328, "training_acc": 72.0, "val_loss": 814.9266242980957, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5361.9771728515625, "training_acc": 52.0, "val_loss": 2643.5394287109375, "val_acc": 28.0}
{"epoch": 12, "training_loss": 7995.7727127075195, "training_acc": 28.0, "val_loss": 1228.1947135925293, "val_acc": 72.0}
{"epoch": 13, "training_loss": 6527.703857421875, "training_acc": 72.0, "val_loss": 2779.6810150146484, "val_acc": 72.0}
{"epoch": 14, "training_loss": 11397.133911132812, "training_acc": 72.0, "val_loss": 2640.19775390625, "val_acc": 72.0}
{"epoch": 15, "training_loss": 9731.802825927734, "training_acc": 72.0, "val_loss": 1064.1788482666016, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3756.844757080078, "training_acc": 52.0, "val_loss": 683.8784694671631, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1774.9638137817383, "training_acc": 56.0, "val_loss": 941.557502746582, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3909.899185180664, "training_acc": 72.0, "val_loss": 764.1905307769775, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2320.3116731643677, "training_acc": 72.0, "val_loss": 1959.4755172729492, "val_acc": 28.0}
{"epoch": 20, "training_loss": 7300.685119628906, "training_acc": 28.0, "val_loss": 408.7977886199951, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2161.371078491211, "training_acc": 72.0, "val_loss": 1150.8692741394043, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4386.423049926758, "training_acc": 72.0, "val_loss": 495.2486991882324, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2378.1891174316406, "training_acc": 56.0, "val_loss": 217.30024814605713, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1141.9450378417969, "training_acc": 54.0, "val_loss": 1622.9833602905273, "val_acc": 72.0}
{"epoch": 25, "training_loss": 6925.418884277344, "training_acc": 72.0, "val_loss": 1832.1067810058594, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6792.473037719727, "training_acc": 72.0, "val_loss": 631.6630840301514, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4199.022033691406, "training_acc": 46.0, "val_loss": 947.2052574157715, "val_acc": 28.0}
{"epoch": 28, "training_loss": 3137.0387420654297, "training_acc": 46.0, "val_loss": 1165.7753944396973, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4901.742874145508, "training_acc": 72.0, "val_loss": 1115.786361694336, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3805.740951538086, "training_acc": 72.0, "val_loss": 710.0629329681396, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2070.475486755371, "training_acc": 28.0, "val_loss": 971.2067604064941, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4835.518310546875, "training_acc": 72.0, "val_loss": 1724.3341445922852, "val_acc": 72.0}
{"epoch": 33, "training_loss": 6604.774444580078, "training_acc": 72.0, "val_loss": 964.3377304077148, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2726.3936500549316, "training_acc": 72.0, "val_loss": 2674.2326736450195, "val_acc": 28.0}
{"epoch": 35, "training_loss": 11021.270568847656, "training_acc": 28.0, "val_loss": 772.1909046173096, "val_acc": 28.0}
{"epoch": 36, "training_loss": 3602.4910430908203, "training_acc": 46.0, "val_loss": 2438.4044647216797, "val_acc": 72.0}
{"epoch": 37, "training_loss": 10619.791809082031, "training_acc": 72.0, "val_loss": 3377.0469665527344, "val_acc": 72.0}
{"epoch": 38, "training_loss": 13373.984313964844, "training_acc": 72.0, "val_loss": 2829.8763275146484, "val_acc": 72.0}
{"epoch": 39, "training_loss": 10068.074401855469, "training_acc": 72.0, "val_loss": 1071.1488723754883, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3965.654037475586, "training_acc": 54.0, "val_loss": 1343.868350982666, "val_acc": 28.0}
{"epoch": 41, "training_loss": 3407.0155353546143, "training_acc": 48.0, "val_loss": 402.04553604125977, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1473.9310054779053, "training_acc": 72.0, "val_loss": 297.11992740631104, "val_acc": 28.0}
