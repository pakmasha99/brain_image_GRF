"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8927.38833618164, "training_acc": 42.0, "val_loss": 4860.165786743164, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15251.784576416016, "training_acc": 72.0, "val_loss": 2859.807586669922, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9767.360778808594, "training_acc": 28.0, "val_loss": 1535.833740234375, "val_acc": 72.0}
{"epoch": 3, "training_loss": 7926.880065917969, "training_acc": 72.0, "val_loss": 3242.574691772461, "val_acc": 72.0}
{"epoch": 4, "training_loss": 12690.202392578125, "training_acc": 72.0, "val_loss": 2280.895233154297, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7946.046043395996, "training_acc": 72.0, "val_loss": 1634.9554061889648, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6440.307876586914, "training_acc": 28.0, "val_loss": 569.4486141204834, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2802.7208251953125, "training_acc": 72.0, "val_loss": 1265.4410362243652, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4636.062042236328, "training_acc": 72.0, "val_loss": 278.8445472717285, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4446.024963378906, "training_acc": 50.0, "val_loss": 1722.3114013671875, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5097.7570877075195, "training_acc": 44.0, "val_loss": 1145.1403617858887, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4874.363525390625, "training_acc": 72.0, "val_loss": 1160.0934982299805, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3880.4248046875, "training_acc": 72.0, "val_loss": 774.7988700866699, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2592.639533996582, "training_acc": 28.0, "val_loss": 990.9224510192871, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5225.599090576172, "training_acc": 72.0, "val_loss": 1965.4483795166016, "val_acc": 72.0}
{"epoch": 15, "training_loss": 7657.648101806641, "training_acc": 72.0, "val_loss": 1310.5286598205566, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3830.2220611572266, "training_acc": 72.0, "val_loss": 1766.1079406738281, "val_acc": 28.0}
{"epoch": 17, "training_loss": 7773.942962646484, "training_acc": 28.0, "val_loss": 13.197039067745209, "val_acc": 68.0}
{"epoch": 18, "training_loss": 1508.135606765747, "training_acc": 73.0, "val_loss": 1052.016258239746, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4009.4808349609375, "training_acc": 72.0, "val_loss": 439.10608291625977, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2446.403610229492, "training_acc": 54.0, "val_loss": 121.35857343673706, "val_acc": 28.0}
{"epoch": 21, "training_loss": 2453.624786376953, "training_acc": 38.0, "val_loss": 1761.0515594482422, "val_acc": 72.0}
{"epoch": 22, "training_loss": 7340.081085205078, "training_acc": 72.0, "val_loss": 1817.8375244140625, "val_acc": 72.0}
{"epoch": 23, "training_loss": 6595.589691162109, "training_acc": 72.0, "val_loss": 515.2333736419678, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3372.680160522461, "training_acc": 56.0, "val_loss": 1511.0568046569824, "val_acc": 28.0}
{"epoch": 25, "training_loss": 4392.416969299316, "training_acc": 42.0, "val_loss": 694.8397159576416, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2771.519088745117, "training_acc": 72.0, "val_loss": 382.46843814849854, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1913.656837463379, "training_acc": 56.0, "val_loss": 77.90078520774841, "val_acc": 72.0}
{"epoch": 28, "training_loss": 221.76796340942383, "training_acc": 72.0, "val_loss": 291.15936756134033, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1706.4446868896484, "training_acc": 44.0, "val_loss": 1021.4025497436523, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3987.0337524414062, "training_acc": 72.0, "val_loss": 606.5627098083496, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1269.4901452064514, "training_acc": 72.0, "val_loss": 2457.901382446289, "val_acc": 28.0}
{"epoch": 32, "training_loss": 9922.289794921875, "training_acc": 28.0, "val_loss": 53.174036741256714, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1981.3286895751953, "training_acc": 48.0, "val_loss": 2821.55704498291, "val_acc": 72.0}
{"epoch": 34, "training_loss": 12607.619506835938, "training_acc": 72.0, "val_loss": 3888.214874267578, "val_acc": 72.0}
{"epoch": 35, "training_loss": 15399.253173828125, "training_acc": 72.0, "val_loss": 3357.029342651367, "val_acc": 72.0}
{"epoch": 36, "training_loss": 12422.93618774414, "training_acc": 72.0, "val_loss": 1572.4881172180176, "val_acc": 72.0}
