"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9751.201068878174, "training_acc": 40.0, "val_loss": 4694.181442260742, "val_acc": 72.0}
{"epoch": 1, "training_loss": 13876.02197265625, "training_acc": 72.0, "val_loss": 2565.6469345092773, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9112.409088134766, "training_acc": 28.0, "val_loss": 1299.1291046142578, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6477.403137207031, "training_acc": 72.0, "val_loss": 2600.2443313598633, "val_acc": 72.0}
{"epoch": 4, "training_loss": 9927.256774902344, "training_acc": 72.0, "val_loss": 1386.4852905273438, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5143.913745880127, "training_acc": 44.0, "val_loss": 286.418080329895, "val_acc": 72.0}
{"epoch": 6, "training_loss": 976.6140995025635, "training_acc": 72.0, "val_loss": 1057.6638221740723, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2959.1220684051514, "training_acc": 44.0, "val_loss": 288.48352432250977, "val_acc": 72.0}
{"epoch": 8, "training_loss": 986.9607849121094, "training_acc": 54.0, "val_loss": 703.6662578582764, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3302.0489349365234, "training_acc": 72.0, "val_loss": 867.1444892883301, "val_acc": 72.0}
{"epoch": 10, "training_loss": 2715.536407470703, "training_acc": 72.0, "val_loss": 1340.8679008483887, "val_acc": 28.0}
{"epoch": 11, "training_loss": 4466.347198486328, "training_acc": 28.0, "val_loss": 830.0536155700684, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3778.571334838867, "training_acc": 72.0, "val_loss": 1636.0952377319336, "val_acc": 72.0}
{"epoch": 13, "training_loss": 6362.111038208008, "training_acc": 72.0, "val_loss": 1027.8556823730469, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3346.543164253235, "training_acc": 72.0, "val_loss": 2286.4030838012695, "val_acc": 28.0}
{"epoch": 15, "training_loss": 8837.779510498047, "training_acc": 28.0, "val_loss": 95.2816903591156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 929.3395767211914, "training_acc": 72.0, "val_loss": 592.0633316040039, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1934.423599243164, "training_acc": 72.0, "val_loss": 873.8759994506836, "val_acc": 28.0}
{"epoch": 18, "training_loss": 2253.232081413269, "training_acc": 44.0, "val_loss": 159.39277410507202, "val_acc": 72.0}
{"epoch": 19, "training_loss": 458.1511116027832, "training_acc": 60.0, "val_loss": 623.6311435699463, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2887.150177001953, "training_acc": 72.0, "val_loss": 710.1770401000977, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2104.1798343658447, "training_acc": 72.0, "val_loss": 1607.1691513061523, "val_acc": 28.0}
{"epoch": 22, "training_loss": 5833.189407348633, "training_acc": 28.0, "val_loss": 624.9917984008789, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3298.4886322021484, "training_acc": 72.0, "val_loss": 1499.1337776184082, "val_acc": 72.0}
{"epoch": 24, "training_loss": 5858.678680419922, "training_acc": 72.0, "val_loss": 898.4179496765137, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3106.521722793579, "training_acc": 46.0, "val_loss": 206.81509971618652, "val_acc": 72.0}
{"epoch": 26, "training_loss": 627.244414806366, "training_acc": 72.0, "val_loss": 994.9268341064453, "val_acc": 28.0}
{"epoch": 27, "training_loss": 2534.1985807418823, "training_acc": 48.0, "val_loss": 240.06760120391846, "val_acc": 72.0}
{"epoch": 28, "training_loss": 667.0929679870605, "training_acc": 72.0, "val_loss": 248.11513423919678, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2098.420181274414, "training_acc": 38.0, "val_loss": 1089.2606735229492, "val_acc": 72.0}
{"epoch": 30, "training_loss": 4250.471935272217, "training_acc": 72.0, "val_loss": 609.6170425415039, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1497.898708820343, "training_acc": 71.0, "val_loss": 905.4615020751953, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2084.8158435821533, "training_acc": 56.0, "val_loss": 411.940860748291, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1516.4470176696777, "training_acc": 72.0, "val_loss": 330.27610778808594, "val_acc": 28.0}
{"epoch": 34, "training_loss": 1371.981559753418, "training_acc": 44.0, "val_loss": 467.6989555358887, "val_acc": 72.0}
