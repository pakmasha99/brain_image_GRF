"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7332.122356414795, "training_acc": 46.0, "val_loss": 5071.694183349609, "val_acc": 72.0}
{"epoch": 1, "training_loss": 17427.713165283203, "training_acc": 72.0, "val_loss": 3127.0912170410156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 9346.701671600342, "training_acc": 28.0, "val_loss": 2165.198516845703, "val_acc": 72.0}
{"epoch": 3, "training_loss": 10711.353149414062, "training_acc": 72.0, "val_loss": 3854.2556762695312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 14980.766662597656, "training_acc": 72.0, "val_loss": 2662.859344482422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8649.917068481445, "training_acc": 72.0, "val_loss": 1404.8527717590332, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5910.174575805664, "training_acc": 28.0, "val_loss": 459.553861618042, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3202.5709838867188, "training_acc": 72.0, "val_loss": 984.7208976745605, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3188.459114074707, "training_acc": 72.0, "val_loss": 1324.731159210205, "val_acc": 28.0}
{"epoch": 9, "training_loss": 4212.392860412598, "training_acc": 28.0, "val_loss": 1064.7296905517578, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5353.489929199219, "training_acc": 72.0, "val_loss": 2135.610771179199, "val_acc": 72.0}
{"epoch": 11, "training_loss": 8340.009307861328, "training_acc": 72.0, "val_loss": 1489.6162033081055, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4649.056655883789, "training_acc": 72.0, "val_loss": 1338.6611938476562, "val_acc": 28.0}
{"epoch": 13, "training_loss": 5558.275665283203, "training_acc": 28.0, "val_loss": 376.2105941772461, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2184.073944091797, "training_acc": 72.0, "val_loss": 923.8560676574707, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3301.9365310668945, "training_acc": 72.0, "val_loss": 180.50460815429688, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1040.5331001281738, "training_acc": 42.0, "val_loss": 348.9872455596924, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1295.814109802246, "training_acc": 52.0, "val_loss": 550.9217262268066, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2481.4924087524414, "training_acc": 72.0, "val_loss": 578.9756774902344, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1659.9486622810364, "training_acc": 72.0, "val_loss": 1360.7985496520996, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3770.509365081787, "training_acc": 28.0, "val_loss": 1233.4062576293945, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5700.3486328125, "training_acc": 72.0, "val_loss": 2478.691864013672, "val_acc": 72.0}
{"epoch": 22, "training_loss": 9895.50601196289, "training_acc": 72.0, "val_loss": 2215.386390686035, "val_acc": 72.0}
{"epoch": 23, "training_loss": 7986.338836669922, "training_acc": 72.0, "val_loss": 708.3155155181885, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3118.821548461914, "training_acc": 60.0, "val_loss": 1527.4447441101074, "val_acc": 28.0}
{"epoch": 25, "training_loss": 4037.608865737915, "training_acc": 46.0, "val_loss": 541.3546085357666, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2065.7623252868652, "training_acc": 72.0, "val_loss": 118.89595985412598, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2574.7262115478516, "training_acc": 54.0, "val_loss": 636.7451190948486, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2806.3250274658203, "training_acc": 46.0, "val_loss": 1704.001235961914, "val_acc": 72.0}
{"epoch": 29, "training_loss": 7421.455596923828, "training_acc": 72.0, "val_loss": 1971.6636657714844, "val_acc": 72.0}
{"epoch": 30, "training_loss": 7214.781326293945, "training_acc": 72.0, "val_loss": 747.9388236999512, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3074.7029571533203, "training_acc": 56.0, "val_loss": 840.3557777404785, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2960.8632888793945, "training_acc": 44.0, "val_loss": 1034.6257209777832, "val_acc": 72.0}
{"epoch": 33, "training_loss": 4277.042556762695, "training_acc": 72.0, "val_loss": 786.134147644043, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2030.0561504364014, "training_acc": 72.0, "val_loss": 2189.029312133789, "val_acc": 28.0}
{"epoch": 35, "training_loss": 8580.910278320312, "training_acc": 28.0, "val_loss": 121.89732789993286, "val_acc": 72.0}
{"epoch": 36, "training_loss": 798.7035255432129, "training_acc": 72.0, "val_loss": 664.1239643096924, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2348.111801147461, "training_acc": 72.0, "val_loss": 301.6998291015625, "val_acc": 28.0}
{"epoch": 38, "training_loss": 1072.549602508545, "training_acc": 44.0, "val_loss": 162.0444893836975, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1306.885726928711, "training_acc": 56.0, "val_loss": 305.84118366241455, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1308.529369354248, "training_acc": 72.0, "val_loss": 213.17119598388672, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1428.362548828125, "training_acc": 60.0, "val_loss": 124.97169971466064, "val_acc": 72.0}
{"epoch": 42, "training_loss": 642.0569343566895, "training_acc": 72.0, "val_loss": 527.4355411529541, "val_acc": 28.0}
{"epoch": 43, "training_loss": 1919.2262496948242, "training_acc": 42.0, "val_loss": 467.12098121643066, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1468.625545501709, "training_acc": 72.0, "val_loss": 942.4492835998535, "val_acc": 28.0}
{"epoch": 45, "training_loss": 2498.818615436554, "training_acc": 37.0, "val_loss": 834.2962265014648, "val_acc": 72.0}
