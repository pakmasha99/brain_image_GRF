"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12138.586002349854, "training_acc": 34.0, "val_loss": 4629.333877563477, "val_acc": 72.0}
{"epoch": 1, "training_loss": 15104.68212890625, "training_acc": 72.0, "val_loss": 2370.0485229492188, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7514.252227783203, "training_acc": 28.0, "val_loss": 1688.5215759277344, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8058.795837402344, "training_acc": 72.0, "val_loss": 3018.728256225586, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11647.347961425781, "training_acc": 72.0, "val_loss": 1843.9359664916992, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5232.142219543457, "training_acc": 72.0, "val_loss": 3377.9014587402344, "val_acc": 28.0}
{"epoch": 6, "training_loss": 14315.213623046875, "training_acc": 28.0, "val_loss": 1287.9181861877441, "val_acc": 28.0}
{"epoch": 7, "training_loss": 5299.565444946289, "training_acc": 44.0, "val_loss": 2707.0682525634766, "val_acc": 72.0}
{"epoch": 8, "training_loss": 12209.0263671875, "training_acc": 72.0, "val_loss": 3743.527603149414, "val_acc": 72.0}
{"epoch": 9, "training_loss": 14696.579223632812, "training_acc": 72.0, "val_loss": 2954.5745849609375, "val_acc": 72.0}
{"epoch": 10, "training_loss": 10440.921020507812, "training_acc": 72.0, "val_loss": 842.2746658325195, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3278.7228393554688, "training_acc": 66.0, "val_loss": 2509.5712661743164, "val_acc": 28.0}
{"epoch": 12, "training_loss": 7669.018173217773, "training_acc": 28.0, "val_loss": 1141.916275024414, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5839.124664306641, "training_acc": 72.0, "val_loss": 2693.985366821289, "val_acc": 72.0}
{"epoch": 14, "training_loss": 10970.004486083984, "training_acc": 72.0, "val_loss": 2579.9516677856445, "val_acc": 72.0}
{"epoch": 15, "training_loss": 9733.737045288086, "training_acc": 72.0, "val_loss": 1046.5712547302246, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3805.9531326293945, "training_acc": 50.0, "val_loss": 399.2277145385742, "val_acc": 28.0}
{"epoch": 17, "training_loss": 1953.7918701171875, "training_acc": 46.0, "val_loss": 1236.5707397460938, "val_acc": 72.0}
{"epoch": 18, "training_loss": 4948.689720153809, "training_acc": 72.0, "val_loss": 1026.8445014953613, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3305.1440505981445, "training_acc": 72.0, "val_loss": 1036.5585327148438, "val_acc": 28.0}
{"epoch": 20, "training_loss": 3471.8327865600586, "training_acc": 28.0, "val_loss": 806.425666809082, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4026.4392700195312, "training_acc": 72.0, "val_loss": 1521.7540740966797, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5775.25959777832, "training_acc": 72.0, "val_loss": 743.5312747955322, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1727.2375221252441, "training_acc": 64.0, "val_loss": 58.96817445755005, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1122.4538955688477, "training_acc": 48.0, "val_loss": 1360.0543975830078, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5581.659469604492, "training_acc": 72.0, "val_loss": 1188.9216423034668, "val_acc": 72.0}
{"epoch": 26, "training_loss": 3946.123260498047, "training_acc": 72.0, "val_loss": 857.2304725646973, "val_acc": 28.0}
{"epoch": 27, "training_loss": 3067.630241394043, "training_acc": 28.0, "val_loss": 818.0501937866211, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3550.3587799072266, "training_acc": 72.0, "val_loss": 1598.8800048828125, "val_acc": 72.0}
{"epoch": 29, "training_loss": 6281.006286621094, "training_acc": 72.0, "val_loss": 1065.1790618896484, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3064.8189239501953, "training_acc": 72.0, "val_loss": 1992.9044723510742, "val_acc": 28.0}
{"epoch": 31, "training_loss": 7975.9739990234375, "training_acc": 28.0, "val_loss": 68.70664358139038, "val_acc": 72.0}
{"epoch": 32, "training_loss": 855.4306335449219, "training_acc": 72.0, "val_loss": 487.9192352294922, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1433.0137577056885, "training_acc": 72.0, "val_loss": 1362.597370147705, "val_acc": 28.0}
{"epoch": 34, "training_loss": 4264.229351043701, "training_acc": 28.0, "val_loss": 954.7664642333984, "val_acc": 72.0}
{"epoch": 35, "training_loss": 5132.518493652344, "training_acc": 72.0, "val_loss": 1838.917350769043, "val_acc": 72.0}
{"epoch": 36, "training_loss": 7075.739944458008, "training_acc": 72.0, "val_loss": 1101.1223793029785, "val_acc": 72.0}
{"epoch": 37, "training_loss": 3512.9551734924316, "training_acc": 72.0, "val_loss": 2157.0600509643555, "val_acc": 28.0}
{"epoch": 38, "training_loss": 8787.02865600586, "training_acc": 28.0, "val_loss": 29.35449481010437, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1133.3071975708008, "training_acc": 72.0, "val_loss": 611.8441104888916, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1999.3480987548828, "training_acc": 72.0, "val_loss": 938.2597923278809, "val_acc": 28.0}
{"epoch": 41, "training_loss": 2527.261468887329, "training_acc": 28.0, "val_loss": 1186.2561225891113, "val_acc": 72.0}
{"epoch": 42, "training_loss": 5460.868927001953, "training_acc": 72.0, "val_loss": 2298.9843368530273, "val_acc": 72.0}
{"epoch": 43, "training_loss": 9173.531951904297, "training_acc": 72.0, "val_loss": 1946.9768524169922, "val_acc": 72.0}
{"epoch": 44, "training_loss": 6722.182083129883, "training_acc": 72.0, "val_loss": 336.07025146484375, "val_acc": 72.0}
{"epoch": 45, "training_loss": 4002.1657104492188, "training_acc": 58.0, "val_loss": 2838.266944885254, "val_acc": 28.0}
{"epoch": 46, "training_loss": 8609.192398071289, "training_acc": 28.0, "val_loss": 1143.1398391723633, "val_acc": 72.0}
{"epoch": 47, "training_loss": 5788.231475830078, "training_acc": 72.0, "val_loss": 2883.220672607422, "val_acc": 72.0}
{"epoch": 48, "training_loss": 11897.287689208984, "training_acc": 72.0, "val_loss": 3018.050956726074, "val_acc": 72.0}
{"epoch": 49, "training_loss": 11296.860107421875, "training_acc": 72.0, "val_loss": 1784.0158462524414, "val_acc": 72.0}
{"epoch": 50, "training_loss": 5666.66357421875, "training_acc": 72.0, "val_loss": 1802.1251678466797, "val_acc": 28.0}
{"epoch": 51, "training_loss": 7975.131439208984, "training_acc": 28.0, "val_loss": 845.7414627075195, "val_acc": 28.0}
{"epoch": 52, "training_loss": 3514.411605834961, "training_acc": 46.0, "val_loss": 2046.3830947875977, "val_acc": 72.0}
{"epoch": 53, "training_loss": 9025.87841796875, "training_acc": 72.0, "val_loss": 2677.787208557129, "val_acc": 72.0}
{"epoch": 54, "training_loss": 10317.998931884766, "training_acc": 72.0, "val_loss": 1813.8740539550781, "val_acc": 72.0}
{"epoch": 55, "training_loss": 5829.78303527832, "training_acc": 72.0, "val_loss": 763.8129711151123, "val_acc": 28.0}
{"epoch": 56, "training_loss": 3897.5872344970703, "training_acc": 28.0, "val_loss": 280.1469087600708, "val_acc": 72.0}
{"epoch": 57, "training_loss": 1904.1717071533203, "training_acc": 72.0, "val_loss": 622.859525680542, "val_acc": 72.0}
