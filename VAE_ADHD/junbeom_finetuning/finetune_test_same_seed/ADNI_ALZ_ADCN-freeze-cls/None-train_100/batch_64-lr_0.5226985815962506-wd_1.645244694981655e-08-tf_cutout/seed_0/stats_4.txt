"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4347.74112701416, "training_acc": 34.0, "val_loss": 1885.738754272461, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6677.940155029297, "training_acc": 72.0, "val_loss": 352.5456666946411, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3054.449188232422, "training_acc": 62.0, "val_loss": 1955.1946640014648, "val_acc": 28.0}
{"epoch": 3, "training_loss": 5763.811943054199, "training_acc": 28.0, "val_loss": 685.0111484527588, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3948.784423828125, "training_acc": 72.0, "val_loss": 1651.7690658569336, "val_acc": 72.0}
{"epoch": 5, "training_loss": 6784.30078125, "training_acc": 72.0, "val_loss": 1662.1152877807617, "val_acc": 72.0}
{"epoch": 6, "training_loss": 6297.846633911133, "training_acc": 72.0, "val_loss": 995.6571578979492, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3240.077751159668, "training_acc": 72.0, "val_loss": 403.1567096710205, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1994.7448272705078, "training_acc": 28.0, "val_loss": 96.12323045730591, "val_acc": 28.0}
{"epoch": 9, "training_loss": 793.4112434387207, "training_acc": 48.0, "val_loss": 869.7262763977051, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3790.9153442382812, "training_acc": 72.0, "val_loss": 1102.2422790527344, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4252.027618408203, "training_acc": 72.0, "val_loss": 747.0361232757568, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2523.402416229248, "training_acc": 72.0, "val_loss": 356.69195652008057, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1754.2776260375977, "training_acc": 28.0, "val_loss": 39.12816047668457, "val_acc": 72.0}
{"epoch": 14, "training_loss": 319.23720932006836, "training_acc": 72.0, "val_loss": 123.8917350769043, "val_acc": 72.0}
{"epoch": 15, "training_loss": 658.5227069854736, "training_acc": 48.0, "val_loss": 139.72772359848022, "val_acc": 72.0}
{"epoch": 16, "training_loss": 593.0842571258545, "training_acc": 72.0, "val_loss": 118.85823011398315, "val_acc": 72.0}
{"epoch": 17, "training_loss": 572.1305599212646, "training_acc": 54.0, "val_loss": 94.72700953483582, "val_acc": 72.0}
{"epoch": 18, "training_loss": 369.5019865036011, "training_acc": 72.0, "val_loss": 12.50443309545517, "val_acc": 76.0}
{"epoch": 19, "training_loss": 308.05432510375977, "training_acc": 56.0, "val_loss": 162.8715991973877, "val_acc": 72.0}
{"epoch": 20, "training_loss": 828.2622375488281, "training_acc": 72.0, "val_loss": 213.04221153259277, "val_acc": 72.0}
{"epoch": 21, "training_loss": 590.6734223365784, "training_acc": 72.0, "val_loss": 615.6008243560791, "val_acc": 28.0}
{"epoch": 22, "training_loss": 2196.724983215332, "training_acc": 28.0, "val_loss": 190.69112539291382, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1222.6222763061523, "training_acc": 72.0, "val_loss": 453.2008647918701, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1683.7546997070312, "training_acc": 72.0, "val_loss": 132.99354314804077, "val_acc": 72.0}
{"epoch": 25, "training_loss": 981.080322265625, "training_acc": 56.0, "val_loss": 338.70396614074707, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1119.289026260376, "training_acc": 46.0, "val_loss": 397.05920219421387, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1627.0756378173828, "training_acc": 72.0, "val_loss": 368.58556270599365, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1337.975152015686, "training_acc": 72.0, "val_loss": 288.3826494216919, "val_acc": 28.0}
{"epoch": 29, "training_loss": 847.0089712142944, "training_acc": 29.0, "val_loss": 322.95353412628174, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1609.4244079589844, "training_acc": 72.0, "val_loss": 566.1606311798096, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2131.5060119628906, "training_acc": 72.0, "val_loss": 268.0294990539551, "val_acc": 72.0}
{"epoch": 32, "training_loss": 874.8475685119629, "training_acc": 56.0, "val_loss": 77.59268283843994, "val_acc": 28.0}
{"epoch": 33, "training_loss": 656.2686653137207, "training_acc": 42.0, "val_loss": 446.8310356140137, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1881.2561798095703, "training_acc": 72.0, "val_loss": 357.8465461730957, "val_acc": 72.0}
{"epoch": 35, "training_loss": 993.2769412994385, "training_acc": 72.0, "val_loss": 585.8858585357666, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2431.974838256836, "training_acc": 28.0, "val_loss": 38.209667801856995, "val_acc": 72.0}
{"epoch": 37, "training_loss": 281.51595306396484, "training_acc": 72.0, "val_loss": 201.24785900115967, "val_acc": 72.0}
