"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2359.363739013672, "training_acc": 42.0, "val_loss": 1440.4494285583496, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4786.394317626953, "training_acc": 72.0, "val_loss": 97.95923233032227, "val_acc": 72.0}
{"epoch": 2, "training_loss": 3896.7614135742188, "training_acc": 50.0, "val_loss": 2189.688491821289, "val_acc": 28.0}
{"epoch": 3, "training_loss": 7196.029357910156, "training_acc": 28.0, "val_loss": 250.48937797546387, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1725.729591369629, "training_acc": 72.0, "val_loss": 1000.0085830688477, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3981.1757583618164, "training_acc": 72.0, "val_loss": 1061.7355346679688, "val_acc": 72.0}
{"epoch": 6, "training_loss": 3966.619827270508, "training_acc": 72.0, "val_loss": 670.8834648132324, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2269.678211212158, "training_acc": 72.0, "val_loss": 290.15040397644043, "val_acc": 28.0}
{"epoch": 8, "training_loss": 1340.717845916748, "training_acc": 28.0, "val_loss": 49.31417107582092, "val_acc": 72.0}
{"epoch": 9, "training_loss": 257.77051544189453, "training_acc": 72.0, "val_loss": 106.56042098999023, "val_acc": 72.0}
{"epoch": 10, "training_loss": 311.5673370361328, "training_acc": 56.0, "val_loss": 79.32543754577637, "val_acc": 72.0}
{"epoch": 11, "training_loss": 275.6152296066284, "training_acc": 72.0, "val_loss": 166.82080030441284, "val_acc": 28.0}
{"epoch": 12, "training_loss": 515.1614227294922, "training_acc": 46.0, "val_loss": 110.82543134689331, "val_acc": 72.0}
{"epoch": 13, "training_loss": 357.00845682621, "training_acc": 72.0, "val_loss": 244.52006816864014, "val_acc": 28.0}
{"epoch": 14, "training_loss": 758.4878559112549, "training_acc": 40.0, "val_loss": 78.78574132919312, "val_acc": 72.0}
{"epoch": 15, "training_loss": 197.186203956604, "training_acc": 73.0, "val_loss": 224.26273822784424, "val_acc": 28.0}
{"epoch": 16, "training_loss": 739.7229118347168, "training_acc": 40.0, "val_loss": 107.80259370803833, "val_acc": 72.0}
{"epoch": 17, "training_loss": 336.1046233177185, "training_acc": 72.0, "val_loss": 252.12218761444092, "val_acc": 28.0}
{"epoch": 18, "training_loss": 762.1506953239441, "training_acc": 38.0, "val_loss": 47.839149832725525, "val_acc": 72.0}
{"epoch": 19, "training_loss": 361.5408401489258, "training_acc": 50.0, "val_loss": 117.7509069442749, "val_acc": 72.0}
{"epoch": 20, "training_loss": 532.1877346038818, "training_acc": 72.0, "val_loss": 142.00310707092285, "val_acc": 72.0}
{"epoch": 21, "training_loss": 348.08640241622925, "training_acc": 72.0, "val_loss": 458.0298900604248, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1691.3434677124023, "training_acc": 28.0, "val_loss": 130.19280433654785, "val_acc": 72.0}
{"epoch": 23, "training_loss": 690.4564018249512, "training_acc": 72.0, "val_loss": 332.08563327789307, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1228.4231452941895, "training_acc": 72.0, "val_loss": 142.7257776260376, "val_acc": 72.0}
{"epoch": 25, "training_loss": 583.8581237792969, "training_acc": 58.0, "val_loss": 67.61801242828369, "val_acc": 28.0}
{"epoch": 26, "training_loss": 479.7916316986084, "training_acc": 46.0, "val_loss": 378.7337064743042, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1540.002784729004, "training_acc": 72.0, "val_loss": 363.3887529373169, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1223.9353065490723, "training_acc": 72.0, "val_loss": 27.16217041015625, "val_acc": 44.0}
{"epoch": 29, "training_loss": 244.96033096313477, "training_acc": 37.0, "val_loss": 154.68238592147827, "val_acc": 72.0}
{"epoch": 30, "training_loss": 676.7709636688232, "training_acc": 72.0, "val_loss": 231.14449977874756, "val_acc": 72.0}
{"epoch": 31, "training_loss": 750.9794845581055, "training_acc": 72.0, "val_loss": 88.89151811599731, "val_acc": 28.0}
{"epoch": 32, "training_loss": 261.7669417858124, "training_acc": 46.0, "val_loss": 76.91567540168762, "val_acc": 72.0}
{"epoch": 33, "training_loss": 250.33242416381836, "training_acc": 72.0, "val_loss": 146.74694538116455, "val_acc": 28.0}
{"epoch": 34, "training_loss": 569.4366445541382, "training_acc": 40.0, "val_loss": 110.68261861801147, "val_acc": 72.0}
{"epoch": 35, "training_loss": 319.4463748931885, "training_acc": 72.0, "val_loss": 268.81346702575684, "val_acc": 28.0}
{"epoch": 36, "training_loss": 760.0468544960022, "training_acc": 32.0, "val_loss": 264.7843599319458, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1398.607521057129, "training_acc": 72.0, "val_loss": 484.40208435058594, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1794.390739440918, "training_acc": 72.0, "val_loss": 260.34252643585205, "val_acc": 72.0}
{"epoch": 39, "training_loss": 570.5311903953552, "training_acc": 72.0, "val_loss": 695.8768367767334, "val_acc": 28.0}
{"epoch": 40, "training_loss": 2969.335922241211, "training_acc": 28.0, "val_loss": 345.40045261383057, "val_acc": 28.0}
{"epoch": 41, "training_loss": 1307.5163497924805, "training_acc": 42.0, "val_loss": 516.6525840759277, "val_acc": 72.0}
{"epoch": 42, "training_loss": 2196.777992248535, "training_acc": 72.0, "val_loss": 690.73486328125, "val_acc": 72.0}
{"epoch": 43, "training_loss": 2615.9972534179688, "training_acc": 72.0, "val_loss": 472.47533798217773, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1527.6760902404785, "training_acc": 72.0, "val_loss": 105.13163805007935, "val_acc": 28.0}
{"epoch": 45, "training_loss": 555.837158203125, "training_acc": 28.0, "val_loss": 127.66671180725098, "val_acc": 72.0}
{"epoch": 46, "training_loss": 584.8703289031982, "training_acc": 72.0, "val_loss": 211.2016201019287, "val_acc": 72.0}
{"epoch": 47, "training_loss": 671.5350017547607, "training_acc": 72.0, "val_loss": 129.9560785293579, "val_acc": 28.0}
