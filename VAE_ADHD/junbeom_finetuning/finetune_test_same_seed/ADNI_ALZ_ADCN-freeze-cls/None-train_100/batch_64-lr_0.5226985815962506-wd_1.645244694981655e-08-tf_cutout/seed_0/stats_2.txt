"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3395.2906036376953, "training_acc": 40.0, "val_loss": 1859.251594543457, "val_acc": 72.0}
{"epoch": 1, "training_loss": 6511.3350830078125, "training_acc": 72.0, "val_loss": 135.05691289901733, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4229.28662109375, "training_acc": 56.0, "val_loss": 2684.0429306030273, "val_acc": 28.0}
{"epoch": 3, "training_loss": 8848.673873901367, "training_acc": 28.0, "val_loss": 463.5739803314209, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2791.207275390625, "training_acc": 72.0, "val_loss": 1395.2375411987305, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5820.967956542969, "training_acc": 72.0, "val_loss": 1420.2604293823242, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5204.646270751953, "training_acc": 72.0, "val_loss": 740.7713413238525, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2069.0361976623535, "training_acc": 72.0, "val_loss": 1232.0192337036133, "val_acc": 28.0}
{"epoch": 8, "training_loss": 5739.183868408203, "training_acc": 28.0, "val_loss": 1154.4157028198242, "val_acc": 28.0}
{"epoch": 9, "training_loss": 3466.2375831604004, "training_acc": 34.0, "val_loss": 416.473388671875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1884.3814163208008, "training_acc": 72.0, "val_loss": 562.8858089447021, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2019.9672470092773, "training_acc": 72.0, "val_loss": 164.96827602386475, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1163.7257614135742, "training_acc": 56.0, "val_loss": 513.6622428894043, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1521.849370956421, "training_acc": 42.0, "val_loss": 269.01488304138184, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1154.8301849365234, "training_acc": 72.0, "val_loss": 170.64179182052612, "val_acc": 72.0}
{"epoch": 15, "training_loss": 795.4400901794434, "training_acc": 54.0, "val_loss": 25.632193684577942, "val_acc": 40.0}
{"epoch": 16, "training_loss": 367.1700248718262, "training_acc": 58.0, "val_loss": 361.7781400680542, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1390.0556640625, "training_acc": 72.0, "val_loss": 201.46808624267578, "val_acc": 72.0}
{"epoch": 18, "training_loss": 742.6590919494629, "training_acc": 54.0, "val_loss": 29.83701229095459, "val_acc": 72.0}
{"epoch": 19, "training_loss": 80.61123967170715, "training_acc": 73.0, "val_loss": 73.96001815795898, "val_acc": 28.0}
{"epoch": 20, "training_loss": 465.1432647705078, "training_acc": 46.0, "val_loss": 334.35192108154297, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1272.8864402770996, "training_acc": 72.0, "val_loss": 170.4304814338684, "val_acc": 72.0}
{"epoch": 22, "training_loss": 894.0805244445801, "training_acc": 50.0, "val_loss": 22.109849750995636, "val_acc": 52.0}
{"epoch": 23, "training_loss": 451.2519989013672, "training_acc": 58.0, "val_loss": 353.06975841522217, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1311.1301460266113, "training_acc": 72.0, "val_loss": 158.34718942642212, "val_acc": 72.0}
{"epoch": 25, "training_loss": 737.2233352661133, "training_acc": 56.0, "val_loss": 34.32678282260895, "val_acc": 40.0}
{"epoch": 26, "training_loss": 372.45590591430664, "training_acc": 60.0, "val_loss": 405.2925109863281, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1574.9522171020508, "training_acc": 72.0, "val_loss": 292.49277114868164, "val_acc": 72.0}
{"epoch": 28, "training_loss": 866.1105647087097, "training_acc": 72.0, "val_loss": 667.875862121582, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2619.0954818725586, "training_acc": 28.0, "val_loss": 111.01065874099731, "val_acc": 72.0}
{"epoch": 30, "training_loss": 681.7261619567871, "training_acc": 72.0, "val_loss": 375.4686117172241, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1352.9804229736328, "training_acc": 72.0, "val_loss": 115.7416820526123, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1009.8592071533203, "training_acc": 54.0, "val_loss": 383.9769124984741, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1136.7189311981201, "training_acc": 48.0, "val_loss": 380.37736415863037, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1536.7584190368652, "training_acc": 72.0, "val_loss": 366.64910316467285, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1162.3796405792236, "training_acc": 72.0, "val_loss": 266.9583797454834, "val_acc": 28.0}
{"epoch": 36, "training_loss": 865.6060781478882, "training_acc": 28.0, "val_loss": 294.244122505188, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1362.4087142944336, "training_acc": 72.0, "val_loss": 508.53867530822754, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1835.1646270751953, "training_acc": 72.0, "val_loss": 206.8070411682129, "val_acc": 72.0}
{"epoch": 39, "training_loss": 868.2063522338867, "training_acc": 56.0, "val_loss": 165.91500043869019, "val_acc": 28.0}
{"epoch": 40, "training_loss": 921.708423614502, "training_acc": 40.0, "val_loss": 453.3721923828125, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1823.3669509887695, "training_acc": 72.0, "val_loss": 387.86168098449707, "val_acc": 72.0}
