"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 336.9719696044922, "training_acc": 42.0, "val_loss": 159.47201251983643, "val_acc": 72.0}
{"epoch": 1, "training_loss": 500.2979145050049, "training_acc": 72.0, "val_loss": 94.6455180644989, "val_acc": 28.0}
{"epoch": 2, "training_loss": 326.8978691101074, "training_acc": 28.0, "val_loss": 48.319804668426514, "val_acc": 72.0}
{"epoch": 3, "training_loss": 249.6274995803833, "training_acc": 72.0, "val_loss": 101.11627578735352, "val_acc": 72.0}
{"epoch": 4, "training_loss": 392.3720188140869, "training_acc": 72.0, "val_loss": 65.76441526412964, "val_acc": 72.0}
{"epoch": 5, "training_loss": 225.02608942985535, "training_acc": 72.0, "val_loss": 77.9093086719513, "val_acc": 28.0}
{"epoch": 6, "training_loss": 302.4602098464966, "training_acc": 28.0, "val_loss": 16.22512936592102, "val_acc": 72.0}
{"epoch": 7, "training_loss": 85.46163415908813, "training_acc": 72.0, "val_loss": 51.86280608177185, "val_acc": 72.0}
{"epoch": 8, "training_loss": 203.88763427734375, "training_acc": 72.0, "val_loss": 31.7772775888443, "val_acc": 72.0}
{"epoch": 9, "training_loss": 122.39730477333069, "training_acc": 50.0, "val_loss": 35.262927412986755, "val_acc": 28.0}
{"epoch": 10, "training_loss": 111.49231791496277, "training_acc": 44.0, "val_loss": 24.883219599723816, "val_acc": 72.0}
{"epoch": 11, "training_loss": 102.4776701927185, "training_acc": 72.0, "val_loss": 18.12821328639984, "val_acc": 72.0}
{"epoch": 12, "training_loss": 81.38794803619385, "training_acc": 54.0, "val_loss": 18.74862313270569, "val_acc": 28.0}
{"epoch": 13, "training_loss": 63.2669677734375, "training_acc": 52.0, "val_loss": 24.62335377931595, "val_acc": 72.0}
{"epoch": 14, "training_loss": 97.08318138122559, "training_acc": 72.0, "val_loss": 14.737191796302795, "val_acc": 72.0}
{"epoch": 15, "training_loss": 70.48715996742249, "training_acc": 60.0, "val_loss": 15.996898710727692, "val_acc": 28.0}
{"epoch": 16, "training_loss": 75.94817447662354, "training_acc": 72.0, "val_loss": 21.918092668056488, "val_acc": 72.0}
{"epoch": 17, "training_loss": 83.24466109275818, "training_acc": 72.0, "val_loss": 18.46100240945816, "val_acc": 28.0}
{"epoch": 18, "training_loss": 72.74848675727844, "training_acc": 38.0, "val_loss": 15.34166932106018, "val_acc": 72.0}
{"epoch": 19, "training_loss": 63.403945207595825, "training_acc": 72.0, "val_loss": 14.763504266738892, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.06098651885986, "training_acc": 72.0, "val_loss": 14.788377285003662, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.32400941848755, "training_acc": 72.0, "val_loss": 16.240528225898743, "val_acc": 28.0}
{"epoch": 22, "training_loss": 62.9866943359375, "training_acc": 72.0, "val_loss": 15.758998692035675, "val_acc": 72.0}
{"epoch": 23, "training_loss": 62.237056255340576, "training_acc": 72.0, "val_loss": 14.803500473499298, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.64237952232361, "training_acc": 72.0, "val_loss": 14.814496040344238, "val_acc": 72.0}
{"epoch": 25, "training_loss": 60.20896100997925, "training_acc": 72.0, "val_loss": 14.809596538543701, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.93063998222351, "training_acc": 72.0, "val_loss": 15.411640703678131, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.100663900375366, "training_acc": 72.0, "val_loss": 14.755475521087646, "val_acc": 72.0}
{"epoch": 28, "training_loss": 62.003642559051514, "training_acc": 72.0, "val_loss": 15.631154179573059, "val_acc": 72.0}
{"epoch": 29, "training_loss": 63.54151487350464, "training_acc": 72.0, "val_loss": 14.709115028381348, "val_acc": 72.0}
{"epoch": 30, "training_loss": 68.6116189956665, "training_acc": 50.0, "val_loss": 18.618243932724, "val_acc": 72.0}
{"epoch": 31, "training_loss": 88.16079902648926, "training_acc": 72.0, "val_loss": 14.747783541679382, "val_acc": 72.0}
{"epoch": 32, "training_loss": 92.69690465927124, "training_acc": 52.0, "val_loss": 15.475520491600037, "val_acc": 72.0}
{"epoch": 33, "training_loss": 69.31654334068298, "training_acc": 72.0, "val_loss": 21.925635635852814, "val_acc": 72.0}
{"epoch": 34, "training_loss": 72.82394528388977, "training_acc": 72.0, "val_loss": 30.32039701938629, "val_acc": 28.0}
{"epoch": 35, "training_loss": 100.06512188911438, "training_acc": 44.0, "val_loss": 23.145438730716705, "val_acc": 72.0}
{"epoch": 36, "training_loss": 86.68953061103821, "training_acc": 72.0, "val_loss": 16.389736533164978, "val_acc": 28.0}
{"epoch": 37, "training_loss": 65.34527540206909, "training_acc": 74.0, "val_loss": 14.597466588020325, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.47309184074402, "training_acc": 72.0, "val_loss": 14.55070823431015, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.08522629737854, "training_acc": 72.0, "val_loss": 17.668160796165466, "val_acc": 28.0}
{"epoch": 40, "training_loss": 71.43187308311462, "training_acc": 41.0, "val_loss": 15.501506626605988, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.04274225234985, "training_acc": 72.0, "val_loss": 15.914742648601532, "val_acc": 28.0}
{"epoch": 42, "training_loss": 61.19506883621216, "training_acc": 72.0, "val_loss": 16.801486909389496, "val_acc": 72.0}
{"epoch": 43, "training_loss": 66.91869688034058, "training_acc": 72.0, "val_loss": 14.600500464439392, "val_acc": 72.0}
{"epoch": 44, "training_loss": 58.62207770347595, "training_acc": 72.0, "val_loss": 14.633743464946747, "val_acc": 72.0}
{"epoch": 45, "training_loss": 58.03120565414429, "training_acc": 72.0, "val_loss": 14.907102286815643, "val_acc": 72.0}
{"epoch": 46, "training_loss": 58.447957277297974, "training_acc": 72.0, "val_loss": 16.694191098213196, "val_acc": 72.0}
{"epoch": 47, "training_loss": 64.05849480628967, "training_acc": 72.0, "val_loss": 19.63949203491211, "val_acc": 28.0}
{"epoch": 48, "training_loss": 69.12053036689758, "training_acc": 48.0, "val_loss": 21.03867679834366, "val_acc": 72.0}
{"epoch": 49, "training_loss": 79.2955071926117, "training_acc": 72.0, "val_loss": 16.701380908489227, "val_acc": 28.0}
{"epoch": 50, "training_loss": 67.15189003944397, "training_acc": 70.0, "val_loss": 21.033252775669098, "val_acc": 72.0}
{"epoch": 51, "training_loss": 83.33564329147339, "training_acc": 72.0, "val_loss": 14.503709971904755, "val_acc": 72.0}
{"epoch": 52, "training_loss": 69.7762680053711, "training_acc": 56.0, "val_loss": 17.571640014648438, "val_acc": 72.0}
{"epoch": 53, "training_loss": 70.53651785850525, "training_acc": 72.0, "val_loss": 15.016724169254303, "val_acc": 72.0}
{"epoch": 54, "training_loss": 66.23968434333801, "training_acc": 56.0, "val_loss": 14.83675092458725, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.69667077064514, "training_acc": 72.0, "val_loss": 14.831642806529999, "val_acc": 72.0}
{"epoch": 56, "training_loss": 66.32210278511047, "training_acc": 56.0, "val_loss": 16.16380214691162, "val_acc": 72.0}
{"epoch": 57, "training_loss": 64.06190609931946, "training_acc": 72.0, "val_loss": 14.379258453845978, "val_acc": 72.0}
{"epoch": 58, "training_loss": 57.561675786972046, "training_acc": 72.0, "val_loss": 17.39700883626938, "val_acc": 28.0}
{"epoch": 59, "training_loss": 65.1419427394867, "training_acc": 54.0, "val_loss": 17.872823774814606, "val_acc": 72.0}
{"epoch": 60, "training_loss": 70.05295300483704, "training_acc": 72.0, "val_loss": 14.685161411762238, "val_acc": 76.0}
{"epoch": 61, "training_loss": 58.038477182388306, "training_acc": 72.0, "val_loss": 15.501828491687775, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.629024028778076, "training_acc": 72.0, "val_loss": 15.792745351791382, "val_acc": 28.0}
{"epoch": 63, "training_loss": 74.3094630241394, "training_acc": 76.0, "val_loss": 14.330558478832245, "val_acc": 72.0}
{"epoch": 64, "training_loss": 62.695561170578, "training_acc": 57.0, "val_loss": 16.26315265893936, "val_acc": 72.0}
{"epoch": 65, "training_loss": 74.33303880691528, "training_acc": 72.0, "val_loss": 16.90467745065689, "val_acc": 28.0}
{"epoch": 66, "training_loss": 74.90071034431458, "training_acc": 42.0, "val_loss": 26.98882818222046, "val_acc": 72.0}
{"epoch": 67, "training_loss": 112.16999793052673, "training_acc": 72.0, "val_loss": 20.883968472480774, "val_acc": 72.0}
{"epoch": 68, "training_loss": 124.31111574172974, "training_acc": 48.0, "val_loss": 15.099409222602844, "val_acc": 72.0}
{"epoch": 69, "training_loss": 73.89787650108337, "training_acc": 72.0, "val_loss": 19.65770274400711, "val_acc": 72.0}
{"epoch": 70, "training_loss": 96.5298523902893, "training_acc": 50.0, "val_loss": 14.98032957315445, "val_acc": 72.0}
{"epoch": 71, "training_loss": 72.30407953262329, "training_acc": 72.0, "val_loss": 14.71865028142929, "val_acc": 72.0}
{"epoch": 72, "training_loss": 96.89329242706299, "training_acc": 48.0, "val_loss": 20.36614567041397, "val_acc": 72.0}
{"epoch": 73, "training_loss": 114.80056476593018, "training_acc": 72.0, "val_loss": 22.29578197002411, "val_acc": 72.0}
{"epoch": 74, "training_loss": 113.26673364639282, "training_acc": 52.0, "val_loss": 14.666478335857391, "val_acc": 68.0}
{"epoch": 75, "training_loss": 76.54462242126465, "training_acc": 72.0, "val_loss": 24.629534780979156, "val_acc": 72.0}
{"epoch": 76, "training_loss": 89.26766681671143, "training_acc": 72.0, "val_loss": 21.10278308391571, "val_acc": 28.0}
{"epoch": 77, "training_loss": 86.96495747566223, "training_acc": 40.0, "val_loss": 19.84628438949585, "val_acc": 72.0}
{"epoch": 78, "training_loss": 68.88283061981201, "training_acc": 72.0, "val_loss": 23.3392134308815, "val_acc": 28.0}
{"epoch": 79, "training_loss": 81.06250309944153, "training_acc": 46.0, "val_loss": 22.467266023159027, "val_acc": 72.0}
{"epoch": 80, "training_loss": 79.77663373947144, "training_acc": 72.0, "val_loss": 24.99096989631653, "val_acc": 28.0}
{"epoch": 81, "training_loss": 92.59522891044617, "training_acc": 38.0, "val_loss": 16.283366084098816, "val_acc": 72.0}
{"epoch": 82, "training_loss": 62.857407093048096, "training_acc": 72.0, "val_loss": 14.743521809577942, "val_acc": 60.0}
{"epoch": 83, "training_loss": 62.30270457267761, "training_acc": 72.0, "val_loss": 14.155758917331696, "val_acc": 72.0}
{"epoch": 84, "training_loss": 56.450706005096436, "training_acc": 72.0, "val_loss": 14.49311375617981, "val_acc": 72.0}
{"epoch": 85, "training_loss": 57.53391098976135, "training_acc": 72.0, "val_loss": 15.248863399028778, "val_acc": 72.0}
{"epoch": 86, "training_loss": 58.1405553817749, "training_acc": 72.0, "val_loss": 17.355716228485107, "val_acc": 28.0}
{"epoch": 87, "training_loss": 64.31319069862366, "training_acc": 56.0, "val_loss": 17.98759549856186, "val_acc": 72.0}
{"epoch": 88, "training_loss": 66.06132054328918, "training_acc": 72.0, "val_loss": 18.112647533416748, "val_acc": 28.0}
{"epoch": 89, "training_loss": 65.0964286327362, "training_acc": 52.0, "val_loss": 19.98187154531479, "val_acc": 72.0}
{"epoch": 90, "training_loss": 74.59758687019348, "training_acc": 72.0, "val_loss": 20.95048874616623, "val_acc": 28.0}
{"epoch": 91, "training_loss": 79.08336782455444, "training_acc": 40.0, "val_loss": 15.686792135238647, "val_acc": 72.0}
{"epoch": 92, "training_loss": 60.26280641555786, "training_acc": 72.0, "val_loss": 15.05429893732071, "val_acc": 48.0}
{"epoch": 93, "training_loss": 61.641780376434326, "training_acc": 75.0, "val_loss": 14.353390038013458, "val_acc": 72.0}
{"epoch": 94, "training_loss": 56.105555295944214, "training_acc": 72.0, "val_loss": 15.376931428909302, "val_acc": 44.0}
{"epoch": 95, "training_loss": 63.93539834022522, "training_acc": 77.0, "val_loss": 14.673729240894318, "val_acc": 72.0}
{"epoch": 96, "training_loss": 57.830764055252075, "training_acc": 72.0, "val_loss": 14.334101974964142, "val_acc": 76.0}
{"epoch": 97, "training_loss": 72.19268989562988, "training_acc": 72.0, "val_loss": 14.467255771160126, "val_acc": 68.0}
{"epoch": 98, "training_loss": 81.17559385299683, "training_acc": 46.0, "val_loss": 27.78589427471161, "val_acc": 72.0}
{"epoch": 99, "training_loss": 122.59724617004395, "training_acc": 72.0, "val_loss": 29.30762767791748, "val_acc": 72.0}
{"epoch": 100, "training_loss": 81.35574412345886, "training_acc": 72.0, "val_loss": 54.73576784133911, "val_acc": 28.0}
{"epoch": 101, "training_loss": 166.6654372215271, "training_acc": 42.0, "val_loss": 31.022584438323975, "val_acc": 72.0}
{"epoch": 102, "training_loss": 135.79337978363037, "training_acc": 72.0, "val_loss": 19.756992161273956, "val_acc": 72.0}
