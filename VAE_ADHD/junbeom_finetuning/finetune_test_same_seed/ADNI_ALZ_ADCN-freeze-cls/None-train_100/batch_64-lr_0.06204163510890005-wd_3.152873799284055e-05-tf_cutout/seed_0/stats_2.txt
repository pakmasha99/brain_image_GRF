"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 204.97718620300293, "training_acc": 52.0, "val_loss": 188.24636936187744, "val_acc": 72.0}
{"epoch": 1, "training_loss": 610.8912906646729, "training_acc": 72.0, "val_loss": 47.808265686035156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 153.51841640472412, "training_acc": 38.0, "val_loss": 21.532157063484192, "val_acc": 72.0}
{"epoch": 3, "training_loss": 78.38879370689392, "training_acc": 72.0, "val_loss": 18.963971734046936, "val_acc": 28.0}
{"epoch": 4, "training_loss": 69.81188988685608, "training_acc": 48.0, "val_loss": 20.871901512145996, "val_acc": 72.0}
{"epoch": 5, "training_loss": 70.80006837844849, "training_acc": 72.0, "val_loss": 25.706997513771057, "val_acc": 28.0}
{"epoch": 6, "training_loss": 99.5542380809784, "training_acc": 44.0, "val_loss": 29.2263001203537, "val_acc": 72.0}
{"epoch": 7, "training_loss": 97.93933081626892, "training_acc": 72.0, "val_loss": 37.514105439186096, "val_acc": 28.0}
{"epoch": 8, "training_loss": 114.10071969032288, "training_acc": 46.0, "val_loss": 27.31439471244812, "val_acc": 72.0}
{"epoch": 9, "training_loss": 105.17566251754761, "training_acc": 72.0, "val_loss": 15.231834352016449, "val_acc": 64.0}
{"epoch": 10, "training_loss": 88.94222116470337, "training_acc": 52.0, "val_loss": 19.810017943382263, "val_acc": 72.0}
{"epoch": 11, "training_loss": 95.98568868637085, "training_acc": 72.0, "val_loss": 23.042306303977966, "val_acc": 72.0}
{"epoch": 12, "training_loss": 90.83815050125122, "training_acc": 54.0, "val_loss": 18.806494772434235, "val_acc": 28.0}
{"epoch": 13, "training_loss": 83.96663618087769, "training_acc": 40.0, "val_loss": 22.100090980529785, "val_acc": 72.0}
{"epoch": 14, "training_loss": 77.30331230163574, "training_acc": 72.0, "val_loss": 24.280555546283722, "val_acc": 28.0}
{"epoch": 15, "training_loss": 77.45682692527771, "training_acc": 50.0, "val_loss": 24.6931791305542, "val_acc": 72.0}
{"epoch": 16, "training_loss": 94.16697788238525, "training_acc": 72.0, "val_loss": 14.801055192947388, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.089781284332275, "training_acc": 62.0, "val_loss": 14.972257614135742, "val_acc": 72.0}
{"epoch": 18, "training_loss": 78.54194974899292, "training_acc": 72.0, "val_loss": 15.070441365242004, "val_acc": 72.0}
{"epoch": 19, "training_loss": 64.02214002609253, "training_acc": 60.0, "val_loss": 14.897935092449188, "val_acc": 72.0}
{"epoch": 20, "training_loss": 56.50578486919403, "training_acc": 72.0, "val_loss": 19.161006808280945, "val_acc": 72.0}
{"epoch": 21, "training_loss": 70.75836038589478, "training_acc": 72.0, "val_loss": 17.833910882472992, "val_acc": 28.0}
{"epoch": 22, "training_loss": 68.76656746864319, "training_acc": 42.0, "val_loss": 16.194789111614227, "val_acc": 72.0}
{"epoch": 23, "training_loss": 69.22186994552612, "training_acc": 73.0, "val_loss": 15.46356976032257, "val_acc": 72.0}
{"epoch": 24, "training_loss": 66.59683299064636, "training_acc": 72.0, "val_loss": 16.25937670469284, "val_acc": 28.0}
{"epoch": 25, "training_loss": 81.57308721542358, "training_acc": 44.0, "val_loss": 29.191842675209045, "val_acc": 72.0}
{"epoch": 26, "training_loss": 121.80511784553528, "training_acc": 72.0, "val_loss": 33.45397114753723, "val_acc": 72.0}
{"epoch": 27, "training_loss": 102.30178880691528, "training_acc": 72.0, "val_loss": 50.21078586578369, "val_acc": 28.0}
{"epoch": 28, "training_loss": 159.03709983825684, "training_acc": 36.0, "val_loss": 29.15586829185486, "val_acc": 72.0}
{"epoch": 29, "training_loss": 135.8563690185547, "training_acc": 72.0, "val_loss": 27.388057112693787, "val_acc": 72.0}
{"epoch": 30, "training_loss": 92.05510091781616, "training_acc": 58.0, "val_loss": 30.81561028957367, "val_acc": 28.0}
{"epoch": 31, "training_loss": 111.05667543411255, "training_acc": 42.0, "val_loss": 28.79069745540619, "val_acc": 72.0}
{"epoch": 32, "training_loss": 103.97610902786255, "training_acc": 72.0, "val_loss": 20.117667317390442, "val_acc": 28.0}
{"epoch": 33, "training_loss": 83.57562208175659, "training_acc": 28.0, "val_loss": 20.714136958122253, "val_acc": 72.0}
{"epoch": 34, "training_loss": 84.13040089607239, "training_acc": 72.0, "val_loss": 19.00756061077118, "val_acc": 72.0}
{"epoch": 35, "training_loss": 67.23992872238159, "training_acc": 74.0, "val_loss": 21.303759515285492, "val_acc": 28.0}
