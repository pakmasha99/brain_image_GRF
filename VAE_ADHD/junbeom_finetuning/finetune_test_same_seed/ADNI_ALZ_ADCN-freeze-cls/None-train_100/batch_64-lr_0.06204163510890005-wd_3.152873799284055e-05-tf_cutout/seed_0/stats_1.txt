"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 336.5694580078125, "training_acc": 72.0, "val_loss": 143.0549144744873, "val_acc": 72.0}
{"epoch": 1, "training_loss": 421.12377071380615, "training_acc": 72.0, "val_loss": 203.4379005432129, "val_acc": 28.0}
{"epoch": 2, "training_loss": 753.4102764129639, "training_acc": 28.0, "val_loss": 15.034665167331696, "val_acc": 72.0}
{"epoch": 3, "training_loss": 133.5377378463745, "training_acc": 72.0, "val_loss": 94.231778383255, "val_acc": 72.0}
{"epoch": 4, "training_loss": 381.85778617858887, "training_acc": 72.0, "val_loss": 80.22133708000183, "val_acc": 72.0}
{"epoch": 5, "training_loss": 268.2716474533081, "training_acc": 72.0, "val_loss": 20.941179990768433, "val_acc": 28.0}
{"epoch": 6, "training_loss": 139.43376350402832, "training_acc": 28.0, "val_loss": 17.72179752588272, "val_acc": 28.0}
{"epoch": 7, "training_loss": 107.04883241653442, "training_acc": 40.0, "val_loss": 48.9642858505249, "val_acc": 72.0}
{"epoch": 8, "training_loss": 189.92061853408813, "training_acc": 72.0, "val_loss": 25.68739950656891, "val_acc": 72.0}
{"epoch": 9, "training_loss": 148.56124258041382, "training_acc": 44.0, "val_loss": 22.037914395332336, "val_acc": 28.0}
{"epoch": 10, "training_loss": 126.48188972473145, "training_acc": 30.0, "val_loss": 32.001060247421265, "val_acc": 72.0}
{"epoch": 11, "training_loss": 116.74662351608276, "training_acc": 72.0, "val_loss": 15.651696920394897, "val_acc": 28.0}
{"epoch": 12, "training_loss": 89.1518006324768, "training_acc": 52.0, "val_loss": 14.831657707691193, "val_acc": 72.0}
{"epoch": 13, "training_loss": 68.58128833770752, "training_acc": 72.0, "val_loss": 24.61041659116745, "val_acc": 72.0}
{"epoch": 14, "training_loss": 85.8202600479126, "training_acc": 72.0, "val_loss": 23.600080609321594, "val_acc": 28.0}
{"epoch": 15, "training_loss": 90.36202502250671, "training_acc": 28.0, "val_loss": 16.59112274646759, "val_acc": 72.0}
{"epoch": 16, "training_loss": 70.08326649665833, "training_acc": 72.0, "val_loss": 18.09389442205429, "val_acc": 72.0}
{"epoch": 17, "training_loss": 76.72367548942566, "training_acc": 72.0, "val_loss": 16.078615188598633, "val_acc": 28.0}
{"epoch": 18, "training_loss": 60.73379111289978, "training_acc": 72.0, "val_loss": 17.910125851631165, "val_acc": 72.0}
{"epoch": 19, "training_loss": 69.21895337104797, "training_acc": 72.0, "val_loss": 17.093364894390106, "val_acc": 28.0}
{"epoch": 20, "training_loss": 67.79169964790344, "training_acc": 71.0, "val_loss": 15.39861112833023, "val_acc": 72.0}
{"epoch": 21, "training_loss": 63.81692624092102, "training_acc": 72.0, "val_loss": 14.842329919338226, "val_acc": 72.0}
{"epoch": 22, "training_loss": 62.309476137161255, "training_acc": 72.0, "val_loss": 14.836890995502472, "val_acc": 72.0}
{"epoch": 23, "training_loss": 58.66677808761597, "training_acc": 72.0, "val_loss": 16.316358745098114, "val_acc": 72.0}
{"epoch": 24, "training_loss": 63.202507734298706, "training_acc": 72.0, "val_loss": 16.25989079475403, "val_acc": 28.0}
{"epoch": 25, "training_loss": 62.34454345703125, "training_acc": 72.0, "val_loss": 16.496366262435913, "val_acc": 72.0}
{"epoch": 26, "training_loss": 64.814293384552, "training_acc": 72.0, "val_loss": 15.125799179077148, "val_acc": 72.0}
{"epoch": 27, "training_loss": 60.50994420051575, "training_acc": 72.0, "val_loss": 14.750242233276367, "val_acc": 72.0}
{"epoch": 28, "training_loss": 68.90296173095703, "training_acc": 72.0, "val_loss": 17.062687873840332, "val_acc": 28.0}
{"epoch": 29, "training_loss": 67.04384684562683, "training_acc": 73.0, "val_loss": 15.114983916282654, "val_acc": 72.0}
{"epoch": 30, "training_loss": 65.38568139076233, "training_acc": 72.0, "val_loss": 15.508775413036346, "val_acc": 28.0}
{"epoch": 31, "training_loss": 63.205775022506714, "training_acc": 72.0, "val_loss": 15.108390152454376, "val_acc": 72.0}
{"epoch": 32, "training_loss": 61.03821361064911, "training_acc": 72.0, "val_loss": 15.754897892475128, "val_acc": 72.0}
{"epoch": 33, "training_loss": 62.51622796058655, "training_acc": 72.0, "val_loss": 15.008485317230225, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.877724170684814, "training_acc": 72.0, "val_loss": 18.896296620368958, "val_acc": 72.0}
{"epoch": 35, "training_loss": 76.94758939743042, "training_acc": 72.0, "val_loss": 16.416892409324646, "val_acc": 28.0}
{"epoch": 36, "training_loss": 74.361163854599, "training_acc": 52.0, "val_loss": 20.71225643157959, "val_acc": 72.0}
{"epoch": 37, "training_loss": 86.88721203804016, "training_acc": 72.0, "val_loss": 17.31414496898651, "val_acc": 72.0}
{"epoch": 38, "training_loss": 72.97642230987549, "training_acc": 58.0, "val_loss": 15.9070685505867, "val_acc": 28.0}
{"epoch": 39, "training_loss": 71.92477798461914, "training_acc": 72.0, "val_loss": 19.097861647605896, "val_acc": 72.0}
{"epoch": 40, "training_loss": 71.82306265830994, "training_acc": 72.0, "val_loss": 18.622691929340363, "val_acc": 28.0}
{"epoch": 41, "training_loss": 68.9709107875824, "training_acc": 46.0, "val_loss": 19.653449952602386, "val_acc": 72.0}
{"epoch": 42, "training_loss": 70.70289015769958, "training_acc": 72.0, "val_loss": 25.113749504089355, "val_acc": 28.0}
{"epoch": 43, "training_loss": 85.5016815662384, "training_acc": 44.0, "val_loss": 20.22036463022232, "val_acc": 72.0}
{"epoch": 44, "training_loss": 76.1206865310669, "training_acc": 72.0, "val_loss": 18.678702414035797, "val_acc": 28.0}
{"epoch": 45, "training_loss": 69.45375156402588, "training_acc": 44.0, "val_loss": 17.490386962890625, "val_acc": 72.0}
{"epoch": 46, "training_loss": 68.9680871963501, "training_acc": 72.0, "val_loss": 17.24534183740616, "val_acc": 28.0}
