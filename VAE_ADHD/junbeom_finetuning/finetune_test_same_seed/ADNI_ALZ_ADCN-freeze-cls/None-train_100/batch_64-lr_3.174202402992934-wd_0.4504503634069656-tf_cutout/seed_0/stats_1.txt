"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19103.40314102173, "training_acc": 72.0, "val_loss": 16030.375671386719, "val_acc": 28.0}
{"epoch": 1, "training_loss": 50751.162841796875, "training_acc": 44.0, "val_loss": 3583.1119537353516, "val_acc": 28.0}
{"epoch": 2, "training_loss": 19932.346435546875, "training_acc": 36.0, "val_loss": 223.25444221496582, "val_acc": 28.0}
{"epoch": 3, "training_loss": 6278.6483154296875, "training_acc": 44.0, "val_loss": 816.8145179748535, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3864.069107055664, "training_acc": 72.0, "val_loss": 731.8161964416504, "val_acc": 28.0}
{"epoch": 5, "training_loss": 6341.209381103516, "training_acc": 38.0, "val_loss": 19.036544859409332, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2689.872917175293, "training_acc": 42.0, "val_loss": 28.371885418891907, "val_acc": 28.0}
{"epoch": 7, "training_loss": 2100.4195861816406, "training_acc": 48.0, "val_loss": 277.22253799438477, "val_acc": 72.0}
{"epoch": 8, "training_loss": 859.546552658081, "training_acc": 50.0, "val_loss": 975.2960205078125, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3694.192138671875, "training_acc": 54.0, "val_loss": 1974.5880126953125, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4945.4149169921875, "training_acc": 72.0, "val_loss": 108.6443305015564, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2616.933319091797, "training_acc": 52.0, "val_loss": 1509.898853302002, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4372.833190917969, "training_acc": 56.0, "val_loss": 2052.313232421875, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5737.268653869629, "training_acc": 72.0, "val_loss": 349.0614175796509, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1283.8544540405273, "training_acc": 64.0, "val_loss": 1357.8499794006348, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4287.8831214904785, "training_acc": 52.0, "val_loss": 2084.799575805664, "val_acc": 72.0}
{"epoch": 16, "training_loss": 6299.246494293213, "training_acc": 72.0, "val_loss": 485.24627685546875, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2912.234176635742, "training_acc": 50.0, "val_loss": 1683.8396072387695, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3946.6957092285156, "training_acc": 72.0, "val_loss": 35.82527935504913, "val_acc": 28.0}
{"epoch": 19, "training_loss": 1876.4953994750977, "training_acc": 44.0, "val_loss": 16.18211269378662, "val_acc": 72.0}
{"epoch": 20, "training_loss": 427.0563735961914, "training_acc": 72.0, "val_loss": 1346.4430809020996, "val_acc": 28.0}
{"epoch": 21, "training_loss": 6679.345672607422, "training_acc": 36.0, "val_loss": 804.6979904174805, "val_acc": 28.0}
{"epoch": 22, "training_loss": 5099.869415283203, "training_acc": 42.0, "val_loss": 160.7806921005249, "val_acc": 72.0}
{"epoch": 23, "training_loss": 705.1443519592285, "training_acc": 72.0, "val_loss": 912.9769325256348, "val_acc": 28.0}
{"epoch": 24, "training_loss": 3741.6726837158203, "training_acc": 48.0, "val_loss": 34.625405073165894, "val_acc": 72.0}
{"epoch": 25, "training_loss": 127.61683130264282, "training_acc": 72.0, "val_loss": 1618.2714462280273, "val_acc": 28.0}
{"epoch": 26, "training_loss": 6156.045593261719, "training_acc": 42.0, "val_loss": 748.1190204620361, "val_acc": 28.0}
{"epoch": 27, "training_loss": 5180.253753662109, "training_acc": 40.0, "val_loss": 88.05131316184998, "val_acc": 72.0}
{"epoch": 28, "training_loss": 439.6675109863281, "training_acc": 72.0, "val_loss": 1046.66109085083, "val_acc": 28.0}
{"epoch": 29, "training_loss": 4016.075241088867, "training_acc": 48.0, "val_loss": 27.73434817790985, "val_acc": 28.0}
{"epoch": 30, "training_loss": 800.3194389343262, "training_acc": 56.0, "val_loss": 381.48961067199707, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1118.9940919876099, "training_acc": 72.0, "val_loss": 997.8785514831543, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3906.747360229492, "training_acc": 48.0, "val_loss": 21.219314634799957, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1817.7381324768066, "training_acc": 44.0, "val_loss": 17.176957428455353, "val_acc": 28.0}
{"epoch": 34, "training_loss": 880.6320343017578, "training_acc": 75.0, "val_loss": 43.753233551979065, "val_acc": 28.0}
{"epoch": 35, "training_loss": 2177.2503967285156, "training_acc": 46.0, "val_loss": 226.0950803756714, "val_acc": 72.0}
{"epoch": 36, "training_loss": 770.2738132476807, "training_acc": 72.0, "val_loss": 1144.2597389221191, "val_acc": 28.0}
{"epoch": 37, "training_loss": 3468.3604888916016, "training_acc": 54.0, "val_loss": 104.07664775848389, "val_acc": 72.0}
{"epoch": 38, "training_loss": 588.2009696960449, "training_acc": 56.0, "val_loss": 1535.3271484375, "val_acc": 72.0}
