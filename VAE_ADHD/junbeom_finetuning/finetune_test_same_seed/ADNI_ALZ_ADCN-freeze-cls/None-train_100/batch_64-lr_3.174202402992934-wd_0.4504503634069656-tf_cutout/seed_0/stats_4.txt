"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12297.14847946167, "training_acc": 72.0, "val_loss": 15918.853759765625, "val_acc": 28.0}
{"epoch": 1, "training_loss": 53613.322265625, "training_acc": 42.0, "val_loss": 3744.5205688476562, "val_acc": 28.0}
{"epoch": 2, "training_loss": 18943.28143310547, "training_acc": 40.0, "val_loss": 154.93234395980835, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2544.136688232422, "training_acc": 72.0, "val_loss": 2423.619842529297, "val_acc": 28.0}
{"epoch": 4, "training_loss": 10633.624084472656, "training_acc": 40.0, "val_loss": 780.8382511138916, "val_acc": 28.0}
{"epoch": 5, "training_loss": 5869.109588623047, "training_acc": 44.0, "val_loss": 368.9542055130005, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1672.941551208496, "training_acc": 72.0, "val_loss": 1139.2130851745605, "val_acc": 28.0}
{"epoch": 7, "training_loss": 5081.662826538086, "training_acc": 46.0, "val_loss": 25.716066360473633, "val_acc": 72.0}
{"epoch": 8, "training_loss": 211.1338996887207, "training_acc": 72.0, "val_loss": 1795.1223373413086, "val_acc": 28.0}
{"epoch": 9, "training_loss": 6264.740921020508, "training_acc": 46.0, "val_loss": 523.6726760864258, "val_acc": 28.0}
{"epoch": 10, "training_loss": 4237.042388916016, "training_acc": 44.0, "val_loss": 257.8864097595215, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1117.7009239196777, "training_acc": 72.0, "val_loss": 1136.6256713867188, "val_acc": 28.0}
{"epoch": 12, "training_loss": 5029.69123840332, "training_acc": 44.0, "val_loss": 188.0120038986206, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3403.1685180664062, "training_acc": 44.0, "val_loss": 353.312611579895, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1618.778076171875, "training_acc": 72.0, "val_loss": 1082.1596145629883, "val_acc": 28.0}
{"epoch": 15, "training_loss": 4583.361526489258, "training_acc": 46.0, "val_loss": 14.978577196598053, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1033.2858200073242, "training_acc": 72.0, "val_loss": 679.8632621765137, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3787.8443450927734, "training_acc": 46.0, "val_loss": 141.69303178787231, "val_acc": 72.0}
{"epoch": 18, "training_loss": 750.9216384887695, "training_acc": 72.0, "val_loss": 1715.7196044921875, "val_acc": 28.0}
{"epoch": 19, "training_loss": 6565.537628173828, "training_acc": 42.0, "val_loss": 700.8080959320068, "val_acc": 28.0}
{"epoch": 20, "training_loss": 4110.057464599609, "training_acc": 46.0, "val_loss": 247.22678661346436, "val_acc": 72.0}
{"epoch": 21, "training_loss": 981.9895820617676, "training_acc": 72.0, "val_loss": 962.3761177062988, "val_acc": 28.0}
{"epoch": 22, "training_loss": 5413.827453613281, "training_acc": 38.0, "val_loss": 467.18735694885254, "val_acc": 28.0}
{"epoch": 23, "training_loss": 3644.9977111816406, "training_acc": 46.0, "val_loss": 332.67292976379395, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1500.4350280761719, "training_acc": 72.0, "val_loss": 1081.649112701416, "val_acc": 28.0}
{"epoch": 25, "training_loss": 5139.107604980469, "training_acc": 42.0, "val_loss": 238.15345764160156, "val_acc": 28.0}
{"epoch": 26, "training_loss": 3099.112823486328, "training_acc": 46.0, "val_loss": 380.0555944442749, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1492.8094520568848, "training_acc": 72.0, "val_loss": 655.1627159118652, "val_acc": 28.0}
{"epoch": 28, "training_loss": 4402.682891845703, "training_acc": 40.0, "val_loss": 120.48933506011963, "val_acc": 28.0}
{"epoch": 29, "training_loss": 2535.6195678710938, "training_acc": 48.0, "val_loss": 461.9555950164795, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1811.0564575195312, "training_acc": 72.0, "val_loss": 620.6552505493164, "val_acc": 28.0}
{"epoch": 31, "training_loss": 5339.526763916016, "training_acc": 34.0, "val_loss": 387.2363090515137, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3180.273452758789, "training_acc": 48.0, "val_loss": 420.875883102417, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1600.3820457458496, "training_acc": 72.0, "val_loss": 457.1951389312744, "val_acc": 28.0}
{"epoch": 34, "training_loss": 3323.844757080078, "training_acc": 44.0, "val_loss": 81.93725347518921, "val_acc": 72.0}
