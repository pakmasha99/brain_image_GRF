"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14995.86245727539, "training_acc": 42.0, "val_loss": 13943.357849121094, "val_acc": 28.0}
{"epoch": 1, "training_loss": 49538.525634765625, "training_acc": 40.0, "val_loss": 3591.4840698242188, "val_acc": 28.0}
{"epoch": 2, "training_loss": 13415.84228515625, "training_acc": 50.0, "val_loss": 681.3128471374512, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3041.879165649414, "training_acc": 72.0, "val_loss": 1134.9870681762695, "val_acc": 28.0}
{"epoch": 4, "training_loss": 6979.996795654297, "training_acc": 42.0, "val_loss": 21.091285347938538, "val_acc": 28.0}
{"epoch": 5, "training_loss": 1654.0457496643066, "training_acc": 52.0, "val_loss": 352.0602226257324, "val_acc": 72.0}
{"epoch": 6, "training_loss": 934.8752353191376, "training_acc": 72.0, "val_loss": 1339.7445678710938, "val_acc": 28.0}
{"epoch": 7, "training_loss": 4862.64501953125, "training_acc": 50.0, "val_loss": 41.41767919063568, "val_acc": 72.0}
{"epoch": 8, "training_loss": 335.8254337310791, "training_acc": 58.0, "val_loss": 1779.7178268432617, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5500.2909507751465, "training_acc": 50.0, "val_loss": 2531.5576553344727, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7233.517135620117, "training_acc": 72.0, "val_loss": 558.3818435668945, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2222.952049255371, "training_acc": 56.0, "val_loss": 1768.025779724121, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4890.568927764893, "training_acc": 72.0, "val_loss": 145.69365978240967, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3444.394775390625, "training_acc": 48.0, "val_loss": 1585.8181953430176, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3854.8568210601807, "training_acc": 60.0, "val_loss": 2005.1652908325195, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5245.022003173828, "training_acc": 72.0, "val_loss": 235.54329872131348, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1516.1310729980469, "training_acc": 60.0, "val_loss": 1393.23091506958, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4834.637596130371, "training_acc": 50.0, "val_loss": 2135.579299926758, "val_acc": 72.0}
{"epoch": 18, "training_loss": 5437.739891052246, "training_acc": 72.0, "val_loss": 285.78991889953613, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2431.6950073242188, "training_acc": 50.0, "val_loss": 1601.0017395019531, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4373.0131919384, "training_acc": 54.0, "val_loss": 1336.8618965148926, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3131.662534713745, "training_acc": 72.0, "val_loss": 447.39508628845215, "val_acc": 28.0}
{"epoch": 22, "training_loss": 3236.552215576172, "training_acc": 44.0, "val_loss": 50.55108666419983, "val_acc": 72.0}
{"epoch": 23, "training_loss": 239.673508644104, "training_acc": 54.0, "val_loss": 1507.0887565612793, "val_acc": 72.0}
