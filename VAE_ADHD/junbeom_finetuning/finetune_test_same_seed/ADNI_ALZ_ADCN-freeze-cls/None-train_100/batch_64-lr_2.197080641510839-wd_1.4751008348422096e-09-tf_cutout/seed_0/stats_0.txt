"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 10392.493194580078, "training_acc": 42.0, "val_loss": 5668.358612060547, "val_acc": 72.0}
{"epoch": 1, "training_loss": 17803.142028808594, "training_acc": 72.0, "val_loss": 3293.2601928710938, "val_acc": 28.0}
{"epoch": 2, "training_loss": 11230.728454589844, "training_acc": 28.0, "val_loss": 1801.9384384155273, "val_acc": 72.0}
{"epoch": 3, "training_loss": 9287.967224121094, "training_acc": 72.0, "val_loss": 3795.124053955078, "val_acc": 72.0}
{"epoch": 4, "training_loss": 14859.992492675781, "training_acc": 72.0, "val_loss": 2682.025146484375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9358.527954101562, "training_acc": 72.0, "val_loss": 1831.102180480957, "val_acc": 28.0}
{"epoch": 6, "training_loss": 7211.324371337891, "training_acc": 28.0, "val_loss": 690.5145645141602, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3374.1641235351562, "training_acc": 72.0, "val_loss": 1503.2072067260742, "val_acc": 72.0}
{"epoch": 8, "training_loss": 5519.127349853516, "training_acc": 72.0, "val_loss": 356.4633369445801, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5141.720977783203, "training_acc": 50.0, "val_loss": 1926.6864776611328, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5778.169471740723, "training_acc": 44.0, "val_loss": 1364.7541046142578, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5803.064025878906, "training_acc": 72.0, "val_loss": 1385.026454925537, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4656.4069747924805, "training_acc": 72.0, "val_loss": 810.9609603881836, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2655.508529663086, "training_acc": 28.0, "val_loss": 1189.3746376037598, "val_acc": 72.0}
{"epoch": 14, "training_loss": 6229.3636474609375, "training_acc": 72.0, "val_loss": 2327.74600982666, "val_acc": 72.0}
{"epoch": 15, "training_loss": 9076.868835449219, "training_acc": 72.0, "val_loss": 1569.1591262817383, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4634.294204711914, "training_acc": 72.0, "val_loss": 1942.6347732543945, "val_acc": 28.0}
{"epoch": 17, "training_loss": 8600.825592041016, "training_acc": 28.0, "val_loss": 50.98217725753784, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1252.5938034057617, "training_acc": 72.0, "val_loss": 600.8288383483887, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1889.6825399398804, "training_acc": 72.0, "val_loss": 1663.3073806762695, "val_acc": 28.0}
{"epoch": 20, "training_loss": 5239.866455078125, "training_acc": 28.0, "val_loss": 1124.2701530456543, "val_acc": 72.0}
{"epoch": 21, "training_loss": 6223.872222900391, "training_acc": 72.0, "val_loss": 2378.970718383789, "val_acc": 72.0}
{"epoch": 22, "training_loss": 9332.098693847656, "training_acc": 72.0, "val_loss": 1739.8860931396484, "val_acc": 72.0}
{"epoch": 23, "training_loss": 5779.961334228516, "training_acc": 72.0, "val_loss": 913.2109642028809, "val_acc": 28.0}
{"epoch": 24, "training_loss": 3693.0715942382812, "training_acc": 28.0, "val_loss": 669.4151401519775, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3535.3809967041016, "training_acc": 72.0, "val_loss": 1278.4899711608887, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4609.173072814941, "training_acc": 72.0, "val_loss": 179.30747270584106, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3719.7520446777344, "training_acc": 56.0, "val_loss": 1970.9278106689453, "val_acc": 28.0}
{"epoch": 28, "training_loss": 5383.043964385986, "training_acc": 46.0, "val_loss": 981.2667846679688, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4160.128662109375, "training_acc": 72.0, "val_loss": 904.5961380004883, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2899.380079269409, "training_acc": 72.0, "val_loss": 1860.9107971191406, "val_acc": 28.0}
{"epoch": 31, "training_loss": 6483.595153808594, "training_acc": 28.0, "val_loss": 747.4695682525635, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3659.986785888672, "training_acc": 72.0, "val_loss": 1564.8038864135742, "val_acc": 72.0}
{"epoch": 33, "training_loss": 5946.637725830078, "training_acc": 72.0, "val_loss": 741.338586807251, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2128.163070678711, "training_acc": 60.0, "val_loss": 56.45550489425659, "val_acc": 72.0}
{"epoch": 35, "training_loss": 773.270393371582, "training_acc": 56.0, "val_loss": 660.0906848907471, "val_acc": 72.0}
{"epoch": 36, "training_loss": 3045.2967834472656, "training_acc": 72.0, "val_loss": 914.0183448791504, "val_acc": 72.0}
