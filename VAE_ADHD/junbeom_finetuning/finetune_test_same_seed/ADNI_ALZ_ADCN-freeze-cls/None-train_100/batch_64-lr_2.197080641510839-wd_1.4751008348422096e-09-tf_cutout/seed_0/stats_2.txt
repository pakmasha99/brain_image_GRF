"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12292.834465026855, "training_acc": 72.0, "val_loss": 5151.432418823242, "val_acc": 72.0}
{"epoch": 1, "training_loss": 17183.49887084961, "training_acc": 72.0, "val_loss": 5583.072662353516, "val_acc": 28.0}
{"epoch": 2, "training_loss": 19609.780395507812, "training_acc": 28.0, "val_loss": 1169.5446968078613, "val_acc": 72.0}
{"epoch": 3, "training_loss": 6169.505889892578, "training_acc": 72.0, "val_loss": 3024.2284774780273, "val_acc": 72.0}
{"epoch": 4, "training_loss": 11728.043365478516, "training_acc": 72.0, "val_loss": 1866.4297103881836, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5694.617248535156, "training_acc": 72.0, "val_loss": 4026.302719116211, "val_acc": 28.0}
{"epoch": 6, "training_loss": 16238.768676757812, "training_acc": 28.0, "val_loss": 543.4770584106445, "val_acc": 28.0}
{"epoch": 7, "training_loss": 3440.0618438720703, "training_acc": 50.0, "val_loss": 3918.9990997314453, "val_acc": 72.0}
{"epoch": 8, "training_loss": 16669.68328857422, "training_acc": 72.0, "val_loss": 5503.224563598633, "val_acc": 72.0}
{"epoch": 9, "training_loss": 22017.103576660156, "training_acc": 72.0, "val_loss": 5053.740310668945, "val_acc": 72.0}
{"epoch": 10, "training_loss": 18712.975524902344, "training_acc": 72.0, "val_loss": 2831.1655044555664, "val_acc": 72.0}
{"epoch": 11, "training_loss": 9062.17121887207, "training_acc": 72.0, "val_loss": 2384.1705322265625, "val_acc": 28.0}
{"epoch": 12, "training_loss": 11846.522277832031, "training_acc": 28.0, "val_loss": 1937.5896453857422, "val_acc": 28.0}
{"epoch": 13, "training_loss": 6104.624221801758, "training_acc": 46.0, "val_loss": 2168.5497283935547, "val_acc": 72.0}
{"epoch": 14, "training_loss": 9435.279693603516, "training_acc": 72.0, "val_loss": 2936.6024017333984, "val_acc": 72.0}
{"epoch": 15, "training_loss": 11290.536041259766, "training_acc": 72.0, "val_loss": 1930.4264068603516, "val_acc": 72.0}
{"epoch": 16, "training_loss": 6083.139305114746, "training_acc": 72.0, "val_loss": 1719.6578979492188, "val_acc": 28.0}
{"epoch": 17, "training_loss": 7498.950500488281, "training_acc": 28.0, "val_loss": 114.69639539718628, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1053.003059387207, "training_acc": 72.0, "val_loss": 511.4755630493164, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1305.9301452636719, "training_acc": 72.0, "val_loss": 2052.8133392333984, "val_acc": 28.0}
{"epoch": 20, "training_loss": 7018.446533203125, "training_acc": 28.0, "val_loss": 848.6654281616211, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4592.668975830078, "training_acc": 72.0, "val_loss": 1875.609016418457, "val_acc": 72.0}
{"epoch": 22, "training_loss": 7220.188095092773, "training_acc": 72.0, "val_loss": 1057.814884185791, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2519.9829025268555, "training_acc": 72.0, "val_loss": 2753.1368255615234, "val_acc": 28.0}
{"epoch": 24, "training_loss": 11411.703735351562, "training_acc": 28.0, "val_loss": 520.0112342834473, "val_acc": 28.0}
{"epoch": 25, "training_loss": 3757.71337890625, "training_acc": 44.0, "val_loss": 3027.51407623291, "val_acc": 72.0}
{"epoch": 26, "training_loss": 12913.26220703125, "training_acc": 72.0, "val_loss": 4101.037979125977, "val_acc": 72.0}
{"epoch": 27, "training_loss": 16248.280517578125, "training_acc": 72.0, "val_loss": 3475.562286376953, "val_acc": 72.0}
{"epoch": 28, "training_loss": 12191.22265625, "training_acc": 72.0, "val_loss": 1300.1962661743164, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4253.9829177856445, "training_acc": 58.0, "val_loss": 1817.2706604003906, "val_acc": 28.0}
{"epoch": 30, "training_loss": 5054.684960365295, "training_acc": 38.0, "val_loss": 237.09185123443604, "val_acc": 72.0}
{"epoch": 31, "training_loss": 587.4729053974152, "training_acc": 68.0, "val_loss": 301.50890350341797, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1066.2228660583496, "training_acc": 72.0, "val_loss": 964.0769004821777, "val_acc": 28.0}
{"epoch": 33, "training_loss": 2537.2020025253296, "training_acc": 46.0, "val_loss": 169.59787607192993, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1399.8300552368164, "training_acc": 52.0, "val_loss": 544.2127704620361, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2714.477584838867, "training_acc": 72.0, "val_loss": 694.0650463104248, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2007.1282529830933, "training_acc": 72.0, "val_loss": 2169.282913208008, "val_acc": 28.0}
