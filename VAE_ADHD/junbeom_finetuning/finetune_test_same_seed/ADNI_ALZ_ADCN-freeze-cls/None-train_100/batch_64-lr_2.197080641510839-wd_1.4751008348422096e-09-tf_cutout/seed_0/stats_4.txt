"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7575.043792724609, "training_acc": 48.0, "val_loss": 6112.95280456543, "val_acc": 72.0}
{"epoch": 1, "training_loss": 21553.391632080078, "training_acc": 72.0, "val_loss": 3029.728889465332, "val_acc": 28.0}
{"epoch": 2, "training_loss": 8147.5781326293945, "training_acc": 28.0, "val_loss": 2768.124198913574, "val_acc": 72.0}
{"epoch": 3, "training_loss": 13256.97314453125, "training_acc": 72.0, "val_loss": 5262.553405761719, "val_acc": 72.0}
{"epoch": 4, "training_loss": 20880.290649414062, "training_acc": 72.0, "val_loss": 4480.502700805664, "val_acc": 72.0}
{"epoch": 5, "training_loss": 16206.008911132812, "training_acc": 72.0, "val_loss": 1568.4457778930664, "val_acc": 72.0}
{"epoch": 6, "training_loss": 5414.62663269043, "training_acc": 60.0, "val_loss": 2143.8989639282227, "val_acc": 28.0}
{"epoch": 7, "training_loss": 5901.004783630371, "training_acc": 44.0, "val_loss": 778.7590980529785, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3045.4537353515625, "training_acc": 72.0, "val_loss": 76.89236998558044, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3075.3248901367188, "training_acc": 64.0, "val_loss": 1795.4736709594727, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5155.043701171875, "training_acc": 48.0, "val_loss": 1525.1017570495605, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6515.951751708984, "training_acc": 72.0, "val_loss": 1600.813865661621, "val_acc": 72.0}
{"epoch": 12, "training_loss": 5494.423645019531, "training_acc": 72.0, "val_loss": 437.1170997619629, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1125.3106665611267, "training_acc": 48.0, "val_loss": 319.5202589035034, "val_acc": 28.0}
{"epoch": 14, "training_loss": 1134.0947799682617, "training_acc": 56.0, "val_loss": 1345.5537796020508, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5551.388397216797, "training_acc": 72.0, "val_loss": 1045.2973365783691, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2901.1359329223633, "training_acc": 72.0, "val_loss": 2602.262306213379, "val_acc": 28.0}
{"epoch": 17, "training_loss": 9971.195770263672, "training_acc": 28.0, "val_loss": 279.65569496154785, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1986.7188262939453, "training_acc": 72.0, "val_loss": 996.8551635742188, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3469.614372253418, "training_acc": 72.0, "val_loss": 296.712327003479, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1647.2925720214844, "training_acc": 36.0, "val_loss": 283.66408348083496, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1253.7134246826172, "training_acc": 62.0, "val_loss": 359.0708017349243, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1491.9873733520508, "training_acc": 72.0, "val_loss": 53.05821895599365, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3366.1036071777344, "training_acc": 50.0, "val_loss": 695.0628280639648, "val_acc": 28.0}
{"epoch": 24, "training_loss": 3312.6576385498047, "training_acc": 46.0, "val_loss": 2207.648468017578, "val_acc": 72.0}
{"epoch": 25, "training_loss": 9820.546630859375, "training_acc": 72.0, "val_loss": 2670.8099365234375, "val_acc": 72.0}
{"epoch": 26, "training_loss": 10013.367553710938, "training_acc": 72.0, "val_loss": 1297.708511352539, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3751.0918140411377, "training_acc": 72.0, "val_loss": 3686.349105834961, "val_acc": 28.0}
{"epoch": 28, "training_loss": 15925.801696777344, "training_acc": 28.0, "val_loss": 1931.4104080200195, "val_acc": 28.0}
{"epoch": 29, "training_loss": 6302.333511352539, "training_acc": 46.0, "val_loss": 2486.714744567871, "val_acc": 72.0}
{"epoch": 30, "training_loss": 11386.76708984375, "training_acc": 72.0, "val_loss": 3589.066696166992, "val_acc": 72.0}
{"epoch": 31, "training_loss": 14089.969665527344, "training_acc": 72.0, "val_loss": 2806.7405700683594, "val_acc": 72.0}
{"epoch": 32, "training_loss": 10295.95166015625, "training_acc": 72.0, "val_loss": 495.11709213256836, "val_acc": 72.0}
{"epoch": 33, "training_loss": 5781.589691162109, "training_acc": 52.0, "val_loss": 3408.4083557128906, "val_acc": 28.0}
{"epoch": 34, "training_loss": 10431.249877929688, "training_acc": 28.0, "val_loss": 1369.0242767333984, "val_acc": 72.0}
{"epoch": 35, "training_loss": 8144.48583984375, "training_acc": 72.0, "val_loss": 3333.279037475586, "val_acc": 72.0}
{"epoch": 36, "training_loss": 13488.047760009766, "training_acc": 72.0, "val_loss": 3195.1438903808594, "val_acc": 72.0}
{"epoch": 37, "training_loss": 11679.889221191406, "training_acc": 72.0, "val_loss": 1527.5009155273438, "val_acc": 72.0}
{"epoch": 38, "training_loss": 4275.511659622192, "training_acc": 72.0, "val_loss": 3995.148468017578, "val_acc": 28.0}
{"epoch": 39, "training_loss": 17348.90252685547, "training_acc": 28.0, "val_loss": 3172.9583740234375, "val_acc": 28.0}
{"epoch": 40, "training_loss": 9304.969444274902, "training_acc": 40.0, "val_loss": 1544.7668075561523, "val_acc": 72.0}
{"epoch": 41, "training_loss": 7065.05419921875, "training_acc": 72.0, "val_loss": 2171.883201599121, "val_acc": 72.0}
