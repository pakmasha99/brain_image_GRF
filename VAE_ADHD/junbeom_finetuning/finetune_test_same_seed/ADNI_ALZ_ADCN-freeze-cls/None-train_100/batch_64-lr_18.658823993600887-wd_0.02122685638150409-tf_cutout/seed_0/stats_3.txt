"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 141476.04302215576, "training_acc": 46.0, "val_loss": 67148.71826171875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 150237.1343307495, "training_acc": 72.0, "val_loss": 163126.47705078125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 501022.11328125, "training_acc": 28.0, "val_loss": 29599.313354492188, "val_acc": 72.0}
{"epoch": 3, "training_loss": 138645.7119140625, "training_acc": 72.0, "val_loss": 34892.85888671875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 112557.05590820312, "training_acc": 72.0, "val_loss": 16126.165771484375, "val_acc": 28.0}
{"epoch": 5, "training_loss": 54447.99572753906, "training_acc": 44.0, "val_loss": 7992.137908935547, "val_acc": 72.0}
{"epoch": 6, "training_loss": 25372.16571044922, "training_acc": 60.0, "val_loss": 14359.977722167969, "val_acc": 72.0}
{"epoch": 7, "training_loss": 55776.05712890625, "training_acc": 72.0, "val_loss": 3376.654052734375, "val_acc": 72.0}
{"epoch": 8, "training_loss": 57968.9677734375, "training_acc": 52.0, "val_loss": 2796.597671508789, "val_acc": 72.0}
{"epoch": 9, "training_loss": 10850.565460205078, "training_acc": 72.0, "val_loss": 14231.315612792969, "val_acc": 28.0}
{"epoch": 10, "training_loss": 44733.574951171875, "training_acc": 48.0, "val_loss": 10891.988372802734, "val_acc": 72.0}
{"epoch": 11, "training_loss": 33326.100830078125, "training_acc": 72.0, "val_loss": 21848.16131591797, "val_acc": 28.0}
{"epoch": 12, "training_loss": 60194.3076171875, "training_acc": 46.0, "val_loss": 5285.382080078125, "val_acc": 72.0}
{"epoch": 13, "training_loss": 17254.977416992188, "training_acc": 60.0, "val_loss": 12384.809112548828, "val_acc": 72.0}
{"epoch": 14, "training_loss": 48730.825439453125, "training_acc": 72.0, "val_loss": 3549.363327026367, "val_acc": 72.0}
{"epoch": 15, "training_loss": 44657.638916015625, "training_acc": 54.0, "val_loss": 3415.154266357422, "val_acc": 72.0}
{"epoch": 16, "training_loss": 11885.842514038086, "training_acc": 72.0, "val_loss": 11713.355255126953, "val_acc": 28.0}
{"epoch": 17, "training_loss": 34409.72058105469, "training_acc": 52.0, "val_loss": 11404.402160644531, "val_acc": 72.0}
{"epoch": 18, "training_loss": 35696.63000488281, "training_acc": 72.0, "val_loss": 15618.913269042969, "val_acc": 28.0}
{"epoch": 19, "training_loss": 63774.2001953125, "training_acc": 32.0, "val_loss": 4840.805435180664, "val_acc": 72.0}
{"epoch": 20, "training_loss": 29367.736328125, "training_acc": 56.0, "val_loss": 8312.747192382812, "val_acc": 72.0}
{"epoch": 21, "training_loss": 31745.063232421875, "training_acc": 72.0, "val_loss": 373.57921600341797, "val_acc": 72.0}
{"epoch": 22, "training_loss": 42276.70666503906, "training_acc": 54.0, "val_loss": 1528.2200813293457, "val_acc": 72.0}
{"epoch": 23, "training_loss": 9921.6904296875, "training_acc": 44.0, "val_loss": 19243.179321289062, "val_acc": 72.0}
{"epoch": 24, "training_loss": 81539.82006835938, "training_acc": 72.0, "val_loss": 16623.117065429688, "val_acc": 72.0}
{"epoch": 25, "training_loss": 49704.359375, "training_acc": 72.0, "val_loss": 19948.6083984375, "val_acc": 28.0}
{"epoch": 26, "training_loss": 51870.445373535156, "training_acc": 46.0, "val_loss": 1560.5915069580078, "val_acc": 72.0}
{"epoch": 27, "training_loss": 22866.640380859375, "training_acc": 58.0, "val_loss": 7725.753021240234, "val_acc": 72.0}
{"epoch": 28, "training_loss": 30201.996337890625, "training_acc": 72.0, "val_loss": 388.90483379364014, "val_acc": 72.0}
{"epoch": 29, "training_loss": 33274.62451171875, "training_acc": 60.0, "val_loss": 1305.6537628173828, "val_acc": 72.0}
{"epoch": 30, "training_loss": 9379.682250976562, "training_acc": 48.0, "val_loss": 17555.499267578125, "val_acc": 72.0}
{"epoch": 31, "training_loss": 72699.07446289062, "training_acc": 72.0, "val_loss": 14001.5380859375, "val_acc": 72.0}
{"epoch": 32, "training_loss": 44606.74075317383, "training_acc": 72.0, "val_loss": 24203.80859375, "val_acc": 28.0}
{"epoch": 33, "training_loss": 70923.7808227539, "training_acc": 38.0, "val_loss": 1494.1356658935547, "val_acc": 72.0}
{"epoch": 34, "training_loss": 29984.12744140625, "training_acc": 54.0, "val_loss": 6910.841369628906, "val_acc": 72.0}
{"epoch": 35, "training_loss": 27715.662353515625, "training_acc": 72.0, "val_loss": 237.27355003356934, "val_acc": 72.0}
{"epoch": 36, "training_loss": 38715.45666503906, "training_acc": 56.0, "val_loss": 1640.932273864746, "val_acc": 72.0}
{"epoch": 37, "training_loss": 7243.304870605469, "training_acc": 72.0, "val_loss": 15323.171997070312, "val_acc": 28.0}
{"epoch": 38, "training_loss": 50855.1875, "training_acc": 42.0, "val_loss": 7051.081085205078, "val_acc": 72.0}
{"epoch": 39, "training_loss": 19525.085189819336, "training_acc": 56.0, "val_loss": 12840.727233886719, "val_acc": 72.0}
{"epoch": 40, "training_loss": 49352.05065917969, "training_acc": 72.0, "val_loss": 5406.0638427734375, "val_acc": 72.0}
{"epoch": 41, "training_loss": 35490.323974609375, "training_acc": 54.0, "val_loss": 6526.420593261719, "val_acc": 72.0}
{"epoch": 42, "training_loss": 26832.723266601562, "training_acc": 72.0, "val_loss": 4293.015670776367, "val_acc": 28.0}
{"epoch": 43, "training_loss": 15953.862365722656, "training_acc": 54.0, "val_loss": 11090.443420410156, "val_acc": 72.0}
{"epoch": 44, "training_loss": 35611.439025878906, "training_acc": 72.0, "val_loss": 13980.889892578125, "val_acc": 28.0}
{"epoch": 45, "training_loss": 40542.866149902344, "training_acc": 48.0, "val_loss": 6835.984039306641, "val_acc": 72.0}
{"epoch": 46, "training_loss": 20064.781997680664, "training_acc": 54.0, "val_loss": 13986.392211914062, "val_acc": 72.0}
{"epoch": 47, "training_loss": 57803.32421875, "training_acc": 72.0, "val_loss": 6728.959655761719, "val_acc": 72.0}
{"epoch": 48, "training_loss": 55980.62939453125, "training_acc": 44.0, "val_loss": 6348.896026611328, "val_acc": 72.0}
{"epoch": 49, "training_loss": 26265.638916015625, "training_acc": 72.0, "val_loss": 664.8263931274414, "val_acc": 28.0}
{"epoch": 50, "training_loss": 7531.066955566406, "training_acc": 56.0, "val_loss": 13652.516174316406, "val_acc": 72.0}
{"epoch": 51, "training_loss": 44995.674560546875, "training_acc": 72.0, "val_loss": 7130.232238769531, "val_acc": 28.0}
{"epoch": 52, "training_loss": 30081.556396484375, "training_acc": 44.0, "val_loss": 7822.418975830078, "val_acc": 72.0}
{"epoch": 53, "training_loss": 22345.667266845703, "training_acc": 54.0, "val_loss": 13390.966796875, "val_acc": 72.0}
{"epoch": 54, "training_loss": 56934.47607421875, "training_acc": 72.0, "val_loss": 5477.803421020508, "val_acc": 72.0}
