"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 82606.62091064453, "training_acc": 42.0, "val_loss": 30303.302001953125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 67641.5755186081, "training_acc": 72.0, "val_loss": 73077.84423828125, "val_acc": 28.0}
{"epoch": 2, "training_loss": 227898.4384765625, "training_acc": 28.0, "val_loss": 13301.332092285156, "val_acc": 72.0}
{"epoch": 3, "training_loss": 61431.826904296875, "training_acc": 72.0, "val_loss": 16461.746215820312, "val_acc": 72.0}
{"epoch": 4, "training_loss": 51971.886962890625, "training_acc": 72.0, "val_loss": 5774.643325805664, "val_acc": 28.0}
{"epoch": 5, "training_loss": 16782.992889404297, "training_acc": 52.0, "val_loss": 4252.311325073242, "val_acc": 72.0}
{"epoch": 6, "training_loss": 12569.987274169922, "training_acc": 56.0, "val_loss": 8110.0982666015625, "val_acc": 72.0}
{"epoch": 7, "training_loss": 31015.624145507812, "training_acc": 72.0, "val_loss": 3627.057647705078, "val_acc": 72.0}
{"epoch": 8, "training_loss": 17774.650268554688, "training_acc": 58.0, "val_loss": 4026.675796508789, "val_acc": 72.0}
{"epoch": 9, "training_loss": 14550.255187988281, "training_acc": 72.0, "val_loss": 2014.9320602416992, "val_acc": 28.0}
{"epoch": 10, "training_loss": 15037.05712890625, "training_acc": 44.0, "val_loss": 7212.73193359375, "val_acc": 72.0}
{"epoch": 11, "training_loss": 22649.451293945312, "training_acc": 72.0, "val_loss": 7216.748809814453, "val_acc": 28.0}
{"epoch": 12, "training_loss": 21981.167602539062, "training_acc": 46.0, "val_loss": 3031.28604888916, "val_acc": 72.0}
{"epoch": 13, "training_loss": 16307.312316894531, "training_acc": 48.0, "val_loss": 6239.270782470703, "val_acc": 72.0}
{"epoch": 14, "training_loss": 26095.501831054688, "training_acc": 72.0, "val_loss": 3173.5057830810547, "val_acc": 72.0}
{"epoch": 15, "training_loss": 14805.128112792969, "training_acc": 60.0, "val_loss": 2975.1806259155273, "val_acc": 72.0}
{"epoch": 16, "training_loss": 11095.669830322266, "training_acc": 72.0, "val_loss": 4580.586242675781, "val_acc": 28.0}
{"epoch": 17, "training_loss": 14810.056274414062, "training_acc": 50.0, "val_loss": 4497.306442260742, "val_acc": 72.0}
{"epoch": 18, "training_loss": 12537.535369873047, "training_acc": 72.0, "val_loss": 10914.019012451172, "val_acc": 28.0}
{"epoch": 19, "training_loss": 26574.359771728516, "training_acc": 50.0, "val_loss": 883.3827018737793, "val_acc": 72.0}
{"epoch": 20, "training_loss": 12383.142944335938, "training_acc": 54.0, "val_loss": 4580.205917358398, "val_acc": 72.0}
{"epoch": 21, "training_loss": 19588.272583007812, "training_acc": 72.0, "val_loss": 1343.0102348327637, "val_acc": 72.0}
{"epoch": 22, "training_loss": 19224.405517578125, "training_acc": 56.0, "val_loss": 1242.637538909912, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4108.541152954102, "training_acc": 72.0, "val_loss": 6746.502685546875, "val_acc": 28.0}
{"epoch": 24, "training_loss": 22996.641540527344, "training_acc": 44.0, "val_loss": 4284.461975097656, "val_acc": 72.0}
{"epoch": 25, "training_loss": 11655.758316040039, "training_acc": 72.0, "val_loss": 11495.406341552734, "val_acc": 28.0}
{"epoch": 26, "training_loss": 30145.78923034668, "training_acc": 46.0, "val_loss": 914.1637802124023, "val_acc": 72.0}
{"epoch": 27, "training_loss": 11542.97802734375, "training_acc": 56.0, "val_loss": 4178.767395019531, "val_acc": 72.0}
{"epoch": 28, "training_loss": 16283.285705566406, "training_acc": 72.0, "val_loss": 858.4784507751465, "val_acc": 72.0}
{"epoch": 29, "training_loss": 17954.45458984375, "training_acc": 56.0, "val_loss": 1512.9528045654297, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5138.291664123535, "training_acc": 72.0, "val_loss": 5290.590286254883, "val_acc": 28.0}
{"epoch": 31, "training_loss": 25640.016723632812, "training_acc": 36.0, "val_loss": 4910.652160644531, "val_acc": 72.0}
{"epoch": 32, "training_loss": 14421.350044250488, "training_acc": 72.0, "val_loss": 11192.609405517578, "val_acc": 28.0}
{"epoch": 33, "training_loss": 28486.93519592285, "training_acc": 48.0, "val_loss": 1286.3143920898438, "val_acc": 72.0}
{"epoch": 34, "training_loss": 8200.160949707031, "training_acc": 60.0, "val_loss": 4690.417861938477, "val_acc": 72.0}
{"epoch": 35, "training_loss": 18203.192260742188, "training_acc": 72.0, "val_loss": 914.5378112792969, "val_acc": 72.0}
{"epoch": 36, "training_loss": 19969.219970703125, "training_acc": 54.0, "val_loss": 1289.0729904174805, "val_acc": 72.0}
{"epoch": 37, "training_loss": 6256.6890869140625, "training_acc": 72.0, "val_loss": 6377.945327758789, "val_acc": 28.0}
{"epoch": 38, "training_loss": 22755.235473632812, "training_acc": 42.0, "val_loss": 3453.0147552490234, "val_acc": 72.0}
{"epoch": 39, "training_loss": 7678.259056091309, "training_acc": 72.0, "val_loss": 14538.601684570312, "val_acc": 28.0}
{"epoch": 40, "training_loss": 39718.29731750488, "training_acc": 28.0, "val_loss": 10545.330047607422, "val_acc": 72.0}
{"epoch": 41, "training_loss": 44955.735107421875, "training_acc": 72.0, "val_loss": 9975.283813476562, "val_acc": 72.0}
{"epoch": 42, "training_loss": 32023.78692626953, "training_acc": 72.0, "val_loss": 4423.130798339844, "val_acc": 28.0}
{"epoch": 43, "training_loss": 13913.031280517578, "training_acc": 48.0, "val_loss": 2616.5395736694336, "val_acc": 72.0}
{"epoch": 44, "training_loss": 10290.920227050781, "training_acc": 56.0, "val_loss": 5439.530181884766, "val_acc": 72.0}
{"epoch": 45, "training_loss": 21477.9306640625, "training_acc": 72.0, "val_loss": 1745.4994201660156, "val_acc": 72.0}
{"epoch": 46, "training_loss": 20967.540161132812, "training_acc": 52.0, "val_loss": 1977.1686553955078, "val_acc": 72.0}
{"epoch": 47, "training_loss": 8236.919036865234, "training_acc": 72.0, "val_loss": 4189.133071899414, "val_acc": 28.0}
