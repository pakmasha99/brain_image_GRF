"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 55619.09460449219, "training_acc": 71.0, "val_loss": 33385.21423339844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 127699.27099609375, "training_acc": 60.0, "val_loss": 11706.143188476562, "val_acc": 72.0}
{"epoch": 2, "training_loss": 45556.886962890625, "training_acc": 72.0, "val_loss": 6087.78190612793, "val_acc": 28.0}
{"epoch": 3, "training_loss": 41610.5849609375, "training_acc": 40.0, "val_loss": 13395.249938964844, "val_acc": 72.0}
{"epoch": 4, "training_loss": 40510.22561645508, "training_acc": 72.0, "val_loss": 21311.155700683594, "val_acc": 28.0}
{"epoch": 5, "training_loss": 53590.40139770508, "training_acc": 48.0, "val_loss": 2802.111053466797, "val_acc": 72.0}
{"epoch": 6, "training_loss": 33078.560791015625, "training_acc": 44.0, "val_loss": 7860.411071777344, "val_acc": 72.0}
{"epoch": 7, "training_loss": 33008.423583984375, "training_acc": 72.0, "val_loss": 4440.767288208008, "val_acc": 72.0}
{"epoch": 8, "training_loss": 28606.400512695312, "training_acc": 52.0, "val_loss": 4939.714813232422, "val_acc": 72.0}
{"epoch": 9, "training_loss": 19237.68438720703, "training_acc": 72.0, "val_loss": 621.5956687927246, "val_acc": 28.0}
{"epoch": 10, "training_loss": 9517.420593261719, "training_acc": 50.0, "val_loss": 9017.230987548828, "val_acc": 72.0}
{"epoch": 11, "training_loss": 29441.777587890625, "training_acc": 72.0, "val_loss": 7145.531463623047, "val_acc": 28.0}
{"epoch": 12, "training_loss": 25096.637451171875, "training_acc": 44.0, "val_loss": 4663.594055175781, "val_acc": 72.0}
{"epoch": 13, "training_loss": 21786.615661621094, "training_acc": 46.0, "val_loss": 8313.683319091797, "val_acc": 72.0}
{"epoch": 14, "training_loss": 33857.06884765625, "training_acc": 72.0, "val_loss": 4737.001419067383, "val_acc": 72.0}
{"epoch": 15, "training_loss": 24156.908447265625, "training_acc": 52.0, "val_loss": 5066.371154785156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 18968.237060546875, "training_acc": 72.0, "val_loss": 652.8727054595947, "val_acc": 72.0}
{"epoch": 17, "training_loss": 22612.418823242188, "training_acc": 54.0, "val_loss": 2417.9140090942383, "val_acc": 72.0}
{"epoch": 18, "training_loss": 9596.467193603516, "training_acc": 72.0, "val_loss": 4644.958877563477, "val_acc": 28.0}
{"epoch": 19, "training_loss": 17947.134216308594, "training_acc": 48.0, "val_loss": 6682.555389404297, "val_acc": 72.0}
{"epoch": 20, "training_loss": 20154.78729248047, "training_acc": 72.0, "val_loss": 10591.964721679688, "val_acc": 28.0}
{"epoch": 21, "training_loss": 31517.831573486328, "training_acc": 42.0, "val_loss": 2077.5033950805664, "val_acc": 72.0}
{"epoch": 22, "training_loss": 13328.507019042969, "training_acc": 58.0, "val_loss": 5417.910003662109, "val_acc": 72.0}
{"epoch": 23, "training_loss": 20832.923767089844, "training_acc": 72.0, "val_loss": 913.306713104248, "val_acc": 72.0}
{"epoch": 24, "training_loss": 22516.56494140625, "training_acc": 56.0, "val_loss": 1700.4264831542969, "val_acc": 72.0}
{"epoch": 25, "training_loss": 6052.032211303711, "training_acc": 72.0, "val_loss": 7385.597991943359, "val_acc": 28.0}
{"epoch": 26, "training_loss": 24783.64080810547, "training_acc": 46.0, "val_loss": 5792.847061157227, "val_acc": 72.0}
{"epoch": 27, "training_loss": 17194.051681518555, "training_acc": 72.0, "val_loss": 12360.575866699219, "val_acc": 28.0}
{"epoch": 28, "training_loss": 38947.12530517578, "training_acc": 38.0, "val_loss": 2004.4919967651367, "val_acc": 72.0}
