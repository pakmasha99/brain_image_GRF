"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 142374.86144256592, "training_acc": 37.0, "val_loss": 27083.535766601562, "val_acc": 72.0}
{"epoch": 1, "training_loss": 104917.33056640625, "training_acc": 62.0, "val_loss": 6151.26838684082, "val_acc": 72.0}
{"epoch": 2, "training_loss": 24107.387817382812, "training_acc": 72.0, "val_loss": 25668.8232421875, "val_acc": 28.0}
{"epoch": 3, "training_loss": 76287.45361328125, "training_acc": 42.0, "val_loss": 5053.575134277344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 34689.8564453125, "training_acc": 50.0, "val_loss": 9321.345520019531, "val_acc": 72.0}
{"epoch": 5, "training_loss": 42573.579345703125, "training_acc": 72.0, "val_loss": 3283.001708984375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 33178.082275390625, "training_acc": 58.0, "val_loss": 1598.148250579834, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5301.1300048828125, "training_acc": 72.0, "val_loss": 13598.799133300781, "val_acc": 28.0}
{"epoch": 8, "training_loss": 41227.837890625, "training_acc": 44.0, "val_loss": 4608.90998840332, "val_acc": 72.0}
{"epoch": 9, "training_loss": 12682.679931640625, "training_acc": 58.0, "val_loss": 8871.892547607422, "val_acc": 72.0}
{"epoch": 10, "training_loss": 38049.773681640625, "training_acc": 72.0, "val_loss": 2841.0497665405273, "val_acc": 72.0}
{"epoch": 11, "training_loss": 31652.811767578125, "training_acc": 54.0, "val_loss": 1272.056770324707, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3851.2731590270996, "training_acc": 72.0, "val_loss": 10910.922241210938, "val_acc": 28.0}
{"epoch": 13, "training_loss": 34885.74304199219, "training_acc": 44.0, "val_loss": 5105.493927001953, "val_acc": 72.0}
{"epoch": 14, "training_loss": 13986.883347988129, "training_acc": 72.0, "val_loss": 14380.142211914062, "val_acc": 28.0}
{"epoch": 15, "training_loss": 42584.94171142578, "training_acc": 42.0, "val_loss": 2822.9921340942383, "val_acc": 72.0}
{"epoch": 16, "training_loss": 16493.897888183594, "training_acc": 54.0, "val_loss": 6654.3365478515625, "val_acc": 72.0}
{"epoch": 17, "training_loss": 26759.495849609375, "training_acc": 72.0, "val_loss": 2109.9130630493164, "val_acc": 72.0}
{"epoch": 18, "training_loss": 29619.501953125, "training_acc": 50.0, "val_loss": 2547.1622467041016, "val_acc": 72.0}
{"epoch": 19, "training_loss": 10517.387786865234, "training_acc": 72.0, "val_loss": 5202.791976928711, "val_acc": 28.0}
{"epoch": 20, "training_loss": 19515.006286621094, "training_acc": 48.0, "val_loss": 6540.528869628906, "val_acc": 72.0}
{"epoch": 21, "training_loss": 19858.746551513672, "training_acc": 72.0, "val_loss": 12116.759490966797, "val_acc": 28.0}
{"epoch": 22, "training_loss": 31946.065490722656, "training_acc": 48.0, "val_loss": 2383.9494705200195, "val_acc": 72.0}
{"epoch": 23, "training_loss": 14918.451477050781, "training_acc": 54.0, "val_loss": 6520.589447021484, "val_acc": 72.0}
{"epoch": 24, "training_loss": 25431.580627441406, "training_acc": 72.0, "val_loss": 2220.588493347168, "val_acc": 72.0}
{"epoch": 25, "training_loss": 27446.529296875, "training_acc": 50.0, "val_loss": 3367.6158905029297, "val_acc": 72.0}
{"epoch": 26, "training_loss": 13512.718444824219, "training_acc": 72.0, "val_loss": 2583.0429077148438, "val_acc": 28.0}
{"epoch": 27, "training_loss": 20706.034790039062, "training_acc": 40.0, "val_loss": 7490.741729736328, "val_acc": 72.0}
{"epoch": 28, "training_loss": 23172.865631103516, "training_acc": 72.0, "val_loss": 11844.135284423828, "val_acc": 28.0}
{"epoch": 29, "training_loss": 31608.935577392578, "training_acc": 48.0, "val_loss": 2467.344856262207, "val_acc": 72.0}
{"epoch": 30, "training_loss": 15274.905395507812, "training_acc": 54.0, "val_loss": 6759.677886962891, "val_acc": 72.0}
