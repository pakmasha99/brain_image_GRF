"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 189.2676820755005, "training_acc": 48.0, "val_loss": 120.14423608779907, "val_acc": 72.0}
{"epoch": 1, "training_loss": 390.45627212524414, "training_acc": 72.0, "val_loss": 35.11216938495636, "val_acc": 28.0}
{"epoch": 2, "training_loss": 127.7483139038086, "training_acc": 28.0, "val_loss": 30.300050973892212, "val_acc": 72.0}
{"epoch": 3, "training_loss": 136.04962396621704, "training_acc": 72.0, "val_loss": 36.29344403743744, "val_acc": 72.0}
{"epoch": 4, "training_loss": 120.74938178062439, "training_acc": 72.0, "val_loss": 38.625526428222656, "val_acc": 28.0}
{"epoch": 5, "training_loss": 130.47681832313538, "training_acc": 28.0, "val_loss": 22.145533561706543, "val_acc": 72.0}
{"epoch": 6, "training_loss": 95.42708158493042, "training_acc": 72.0, "val_loss": 28.345176577568054, "val_acc": 72.0}
{"epoch": 7, "training_loss": 100.79575371742249, "training_acc": 72.0, "val_loss": 22.08160012960434, "val_acc": 28.0}
{"epoch": 8, "training_loss": 87.6563196182251, "training_acc": 28.0, "val_loss": 17.594963312149048, "val_acc": 72.0}
{"epoch": 9, "training_loss": 83.0221619606018, "training_acc": 72.0, "val_loss": 22.825244069099426, "val_acc": 72.0}
{"epoch": 10, "training_loss": 83.96038556098938, "training_acc": 72.0, "val_loss": 21.739274263381958, "val_acc": 28.0}
{"epoch": 11, "training_loss": 79.27374172210693, "training_acc": 42.0, "val_loss": 16.68073683977127, "val_acc": 72.0}
{"epoch": 12, "training_loss": 67.00751066207886, "training_acc": 72.0, "val_loss": 16.146747767925262, "val_acc": 72.0}
{"epoch": 13, "training_loss": 68.60240650177002, "training_acc": 72.0, "val_loss": 15.359166264533997, "val_acc": 44.0}
{"epoch": 14, "training_loss": 66.97428584098816, "training_acc": 72.0, "val_loss": 15.106087923049927, "val_acc": 72.0}
{"epoch": 15, "training_loss": 60.60243201255798, "training_acc": 72.0, "val_loss": 15.509974956512451, "val_acc": 28.0}
{"epoch": 16, "training_loss": 64.46192479133606, "training_acc": 72.0, "val_loss": 14.992408454418182, "val_acc": 72.0}
{"epoch": 17, "training_loss": 58.82523822784424, "training_acc": 72.0, "val_loss": 15.916736423969269, "val_acc": 28.0}
{"epoch": 18, "training_loss": 62.340850591659546, "training_acc": 72.0, "val_loss": 16.87263697385788, "val_acc": 72.0}
{"epoch": 19, "training_loss": 68.71000862121582, "training_acc": 72.0, "val_loss": 14.971725642681122, "val_acc": 72.0}
{"epoch": 20, "training_loss": 58.365028619766235, "training_acc": 72.0, "val_loss": 17.60489195585251, "val_acc": 28.0}
{"epoch": 21, "training_loss": 72.46801996231079, "training_acc": 38.0, "val_loss": 16.272519528865814, "val_acc": 72.0}
{"epoch": 22, "training_loss": 63.600305795669556, "training_acc": 72.0, "val_loss": 15.70465862751007, "val_acc": 28.0}
{"epoch": 23, "training_loss": 60.7523889541626, "training_acc": 72.0, "val_loss": 16.482025384902954, "val_acc": 72.0}
{"epoch": 24, "training_loss": 66.91410756111145, "training_acc": 72.0, "val_loss": 15.089920163154602, "val_acc": 72.0}
{"epoch": 25, "training_loss": 66.46133542060852, "training_acc": 54.0, "val_loss": 15.12736976146698, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.45372462272644, "training_acc": 72.0, "val_loss": 16.844940185546875, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.1368682384491, "training_acc": 72.0, "val_loss": 19.261561334133148, "val_acc": 28.0}
{"epoch": 28, "training_loss": 70.31839442253113, "training_acc": 44.0, "val_loss": 17.360475659370422, "val_acc": 72.0}
{"epoch": 29, "training_loss": 67.91142463684082, "training_acc": 72.0, "val_loss": 14.800921082496643, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.86921525001526, "training_acc": 72.0, "val_loss": 14.80821818113327, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.377344846725464, "training_acc": 72.0, "val_loss": 15.040960907936096, "val_acc": 72.0}
{"epoch": 32, "training_loss": 64.16698408126831, "training_acc": 72.0, "val_loss": 15.122781693935394, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.3072783946991, "training_acc": 72.0, "val_loss": 14.965052902698517, "val_acc": 72.0}
{"epoch": 34, "training_loss": 57.761677503585815, "training_acc": 72.0, "val_loss": 17.089837789535522, "val_acc": 28.0}
{"epoch": 35, "training_loss": 67.33759260177612, "training_acc": 76.0, "val_loss": 15.489393472671509, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.684364318847656, "training_acc": 72.0, "val_loss": 16.094543039798737, "val_acc": 28.0}
{"epoch": 37, "training_loss": 62.755518198013306, "training_acc": 72.0, "val_loss": 15.267379581928253, "val_acc": 72.0}
{"epoch": 38, "training_loss": 61.09803628921509, "training_acc": 72.0, "val_loss": 14.817094802856445, "val_acc": 72.0}
{"epoch": 39, "training_loss": 58.489500284194946, "training_acc": 72.0, "val_loss": 14.795732498168945, "val_acc": 72.0}
{"epoch": 40, "training_loss": 58.425331592559814, "training_acc": 72.0, "val_loss": 14.795282483100891, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.23764181137085, "training_acc": 72.0, "val_loss": 16.098254919052124, "val_acc": 72.0}
{"epoch": 42, "training_loss": 63.567230463027954, "training_acc": 72.0, "val_loss": 16.4972722530365, "val_acc": 28.0}
{"epoch": 43, "training_loss": 64.103431224823, "training_acc": 72.0, "val_loss": 14.981542527675629, "val_acc": 72.0}
{"epoch": 44, "training_loss": 62.115421295166016, "training_acc": 72.0, "val_loss": 15.863299369812012, "val_acc": 28.0}
{"epoch": 45, "training_loss": 63.58946657180786, "training_acc": 72.0, "val_loss": 16.969673335552216, "val_acc": 72.0}
{"epoch": 46, "training_loss": 72.65310597419739, "training_acc": 72.0, "val_loss": 15.26697725057602, "val_acc": 60.0}
{"epoch": 47, "training_loss": 74.50868701934814, "training_acc": 52.0, "val_loss": 17.998501658439636, "val_acc": 72.0}
{"epoch": 48, "training_loss": 81.24966526031494, "training_acc": 72.0, "val_loss": 17.554011940956116, "val_acc": 72.0}
{"epoch": 49, "training_loss": 70.80717468261719, "training_acc": 58.0, "val_loss": 17.48899668455124, "val_acc": 28.0}
{"epoch": 50, "training_loss": 74.06311535835266, "training_acc": 54.0, "val_loss": 20.97000479698181, "val_acc": 72.0}
{"epoch": 51, "training_loss": 71.35448145866394, "training_acc": 72.0, "val_loss": 26.16749405860901, "val_acc": 28.0}
{"epoch": 52, "training_loss": 87.4361834526062, "training_acc": 44.0, "val_loss": 20.915856957435608, "val_acc": 72.0}
{"epoch": 53, "training_loss": 80.89774656295776, "training_acc": 72.0, "val_loss": 14.959006011486053, "val_acc": 72.0}
{"epoch": 54, "training_loss": 79.64492225646973, "training_acc": 50.0, "val_loss": 17.54661202430725, "val_acc": 72.0}
{"epoch": 55, "training_loss": 76.47887945175171, "training_acc": 72.0, "val_loss": 19.91737335920334, "val_acc": 72.0}
{"epoch": 56, "training_loss": 73.54104161262512, "training_acc": 73.0, "val_loss": 20.17805427312851, "val_acc": 28.0}
{"epoch": 57, "training_loss": 77.04702067375183, "training_acc": 42.0, "val_loss": 19.834895431995392, "val_acc": 72.0}
{"epoch": 58, "training_loss": 70.36176991462708, "training_acc": 72.0, "val_loss": 20.548489689826965, "val_acc": 28.0}
{"epoch": 59, "training_loss": 73.13533329963684, "training_acc": 50.0, "val_loss": 22.072450816631317, "val_acc": 72.0}
