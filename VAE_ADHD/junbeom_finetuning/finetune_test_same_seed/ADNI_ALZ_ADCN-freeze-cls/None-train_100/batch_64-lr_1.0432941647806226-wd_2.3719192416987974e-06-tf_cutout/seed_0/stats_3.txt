"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 5414.088214874268, "training_acc": 40.0, "val_loss": 2599.619483947754, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7693.346282958984, "training_acc": 72.0, "val_loss": 1401.7248153686523, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4972.650817871094, "training_acc": 28.0, "val_loss": 724.5562553405762, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3607.702346801758, "training_acc": 72.0, "val_loss": 1446.2471961975098, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5524.756881713867, "training_acc": 72.0, "val_loss": 777.4339199066162, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2830.3231468200684, "training_acc": 44.0, "val_loss": 164.61107730865479, "val_acc": 72.0}
{"epoch": 6, "training_loss": 557.447696685791, "training_acc": 72.0, "val_loss": 593.6840534210205, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1649.4693279266357, "training_acc": 44.0, "val_loss": 149.983549118042, "val_acc": 72.0}
{"epoch": 8, "training_loss": 568.451452255249, "training_acc": 54.0, "val_loss": 373.4440803527832, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1758.8806991577148, "training_acc": 72.0, "val_loss": 458.28962326049805, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1412.536964416504, "training_acc": 72.0, "val_loss": 811.9935035705566, "val_acc": 28.0}
{"epoch": 11, "training_loss": 2759.61678314209, "training_acc": 28.0, "val_loss": 428.24015617370605, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1965.6734924316406, "training_acc": 72.0, "val_loss": 872.5491523742676, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3388.4489517211914, "training_acc": 72.0, "val_loss": 534.6918106079102, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1714.7074823379517, "training_acc": 72.0, "val_loss": 1354.7316551208496, "val_acc": 28.0}
{"epoch": 15, "training_loss": 5248.1964111328125, "training_acc": 28.0, "val_loss": 20.008449256420135, "val_acc": 72.0}
{"epoch": 16, "training_loss": 437.5780258178711, "training_acc": 72.0, "val_loss": 376.6622543334961, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1316.9268226623535, "training_acc": 72.0, "val_loss": 186.70510053634644, "val_acc": 28.0}
{"epoch": 18, "training_loss": 690.458589553833, "training_acc": 44.0, "val_loss": 157.89997577667236, "val_acc": 72.0}
{"epoch": 19, "training_loss": 408.24241876602173, "training_acc": 60.0, "val_loss": 207.37359523773193, "val_acc": 72.0}
{"epoch": 20, "training_loss": 844.7709541320801, "training_acc": 72.0, "val_loss": 14.402572810649872, "val_acc": 72.0}
{"epoch": 21, "training_loss": 946.2664833068848, "training_acc": 56.0, "val_loss": 39.51411843299866, "val_acc": 72.0}
{"epoch": 22, "training_loss": 199.15721130371094, "training_acc": 72.0, "val_loss": 113.03313970565796, "val_acc": 28.0}
{"epoch": 23, "training_loss": 721.2504920959473, "training_acc": 46.0, "val_loss": 509.8561763763428, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2014.5326309204102, "training_acc": 72.0, "val_loss": 226.90677642822266, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1958.1497650146484, "training_acc": 46.0, "val_loss": 284.2193603515625, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1270.627700805664, "training_acc": 48.0, "val_loss": 912.308406829834, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3817.78759765625, "training_acc": 72.0, "val_loss": 1040.6725883483887, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3866.3152236938477, "training_acc": 72.0, "val_loss": 427.56457328796387, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1191.4357986450195, "training_acc": 62.0, "val_loss": 237.57362365722656, "val_acc": 28.0}
{"epoch": 30, "training_loss": 723.9039688110352, "training_acc": 56.0, "val_loss": 650.3228664398193, "val_acc": 72.0}
{"epoch": 31, "training_loss": 2747.943405151367, "training_acc": 72.0, "val_loss": 612.4559879302979, "val_acc": 72.0}
{"epoch": 32, "training_loss": 2225.085111618042, "training_acc": 72.0, "val_loss": 524.1195678710938, "val_acc": 28.0}
{"epoch": 33, "training_loss": 1603.0800075531006, "training_acc": 28.0, "val_loss": 542.850923538208, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2674.048583984375, "training_acc": 72.0, "val_loss": 1020.3769683837891, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3950.376235961914, "training_acc": 72.0, "val_loss": 651.5006065368652, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1766.7645225524902, "training_acc": 72.0, "val_loss": 989.3884658813477, "val_acc": 28.0}
{"epoch": 37, "training_loss": 4115.658477783203, "training_acc": 28.0, "val_loss": 17.577704787254333, "val_acc": 36.0}
{"epoch": 38, "training_loss": 788.2255325317383, "training_acc": 61.0, "val_loss": 928.6101341247559, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3987.8125762939453, "training_acc": 72.0, "val_loss": 954.3594360351562, "val_acc": 72.0}
