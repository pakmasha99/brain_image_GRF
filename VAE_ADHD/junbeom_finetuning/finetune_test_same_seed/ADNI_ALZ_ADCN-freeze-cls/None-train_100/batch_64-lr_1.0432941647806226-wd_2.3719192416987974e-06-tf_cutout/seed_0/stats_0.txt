"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4958.436126708984, "training_acc": 42.0, "val_loss": 2691.3219451904297, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8452.586242675781, "training_acc": 72.0, "val_loss": 1564.6892547607422, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5336.4368896484375, "training_acc": 28.0, "val_loss": 855.3265571594238, "val_acc": 72.0}
{"epoch": 3, "training_loss": 4409.092041015625, "training_acc": 72.0, "val_loss": 1801.7942428588867, "val_acc": 72.0}
{"epoch": 4, "training_loss": 7054.9678955078125, "training_acc": 72.0, "val_loss": 1273.2253074645996, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4442.535980224609, "training_acc": 72.0, "val_loss": 870.4194068908691, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3427.9867248535156, "training_acc": 28.0, "val_loss": 327.54414081573486, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1600.8331985473633, "training_acc": 72.0, "val_loss": 713.4527206420898, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2619.36376953125, "training_acc": 72.0, "val_loss": 168.91274452209473, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2441.9803466796875, "training_acc": 50.0, "val_loss": 915.8164024353027, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2745.609733581543, "training_acc": 44.0, "val_loss": 647.7053165435791, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2754.1746978759766, "training_acc": 72.0, "val_loss": 657.3282241821289, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2209.659526824951, "training_acc": 72.0, "val_loss": 386.02373600006104, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1264.725959777832, "training_acc": 28.0, "val_loss": 564.41650390625, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2956.5578002929688, "training_acc": 72.0, "val_loss": 1104.9667358398438, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4308.6837158203125, "training_acc": 72.0, "val_loss": 744.7364330291748, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2199.0581092834473, "training_acc": 72.0, "val_loss": 923.4921455383301, "val_acc": 28.0}
{"epoch": 17, "training_loss": 4088.23828125, "training_acc": 28.0, "val_loss": 24.49435591697693, "val_acc": 72.0}
{"epoch": 18, "training_loss": 633.2526092529297, "training_acc": 72.0, "val_loss": 323.7698793411255, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1067.5126342773438, "training_acc": 72.0, "val_loss": 610.7402801513672, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1720.3487949371338, "training_acc": 28.0, "val_loss": 628.4945011138916, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3353.1856536865234, "training_acc": 72.0, "val_loss": 1243.9000129699707, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4899.88703918457, "training_acc": 72.0, "val_loss": 955.8658599853516, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3271.39013671875, "training_acc": 72.0, "val_loss": 69.3762719631195, "val_acc": 28.0}
{"epoch": 24, "training_loss": 323.601749420166, "training_acc": 28.0, "val_loss": 443.83654594421387, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2169.757354736328, "training_acc": 72.0, "val_loss": 717.1710014343262, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2619.240058898926, "training_acc": 72.0, "val_loss": 180.5391788482666, "val_acc": 72.0}
{"epoch": 27, "training_loss": 1682.7548065185547, "training_acc": 56.0, "val_loss": 721.2289333343506, "val_acc": 28.0}
{"epoch": 28, "training_loss": 2122.3479652404785, "training_acc": 46.0, "val_loss": 542.2984600067139, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2275.6095428466797, "training_acc": 72.0, "val_loss": 498.6663341522217, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1649.4697666168213, "training_acc": 72.0, "val_loss": 724.7193336486816, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2450.0756225585938, "training_acc": 28.0, "val_loss": 413.30389976501465, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1969.6378173828125, "training_acc": 72.0, "val_loss": 798.3106136322021, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3042.642692565918, "training_acc": 72.0, "val_loss": 403.5046577453613, "val_acc": 72.0}
{"epoch": 34, "training_loss": 964.421220779419, "training_acc": 60.0, "val_loss": 53.69296073913574, "val_acc": 28.0}
{"epoch": 35, "training_loss": 781.2403030395508, "training_acc": 44.0, "val_loss": 669.7930812835693, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2669.187873840332, "training_acc": 72.0, "val_loss": 489.5678520202637, "val_acc": 72.0}
