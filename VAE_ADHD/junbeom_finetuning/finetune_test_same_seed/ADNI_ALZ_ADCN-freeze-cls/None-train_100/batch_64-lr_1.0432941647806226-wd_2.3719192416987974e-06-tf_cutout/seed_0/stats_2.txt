"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4075.9867362976074, "training_acc": 46.0, "val_loss": 2808.3248138427734, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9654.517059326172, "training_acc": 72.0, "val_loss": 1712.544822692871, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5103.1787033081055, "training_acc": 28.0, "val_loss": 1203.7018775939941, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5951.007843017578, "training_acc": 72.0, "val_loss": 2141.0852432250977, "val_acc": 72.0}
{"epoch": 4, "training_loss": 8326.318481445312, "training_acc": 72.0, "val_loss": 1486.0356330871582, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4839.049697875977, "training_acc": 72.0, "val_loss": 738.2388114929199, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3114.888397216797, "training_acc": 28.0, "val_loss": 268.6863660812378, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1830.0462951660156, "training_acc": 72.0, "val_loss": 560.0352764129639, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1825.7225646972656, "training_acc": 72.0, "val_loss": 691.4815902709961, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2165.997303009033, "training_acc": 28.0, "val_loss": 604.6347618103027, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3024.869094848633, "training_acc": 72.0, "val_loss": 1198.5883712768555, "val_acc": 72.0}
{"epoch": 11, "training_loss": 4683.862503051758, "training_acc": 72.0, "val_loss": 843.4633255004883, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2650.7720489501953, "training_acc": 72.0, "val_loss": 687.4915599822998, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2863.709701538086, "training_acc": 28.0, "val_loss": 228.121018409729, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1288.4763641357422, "training_acc": 72.0, "val_loss": 531.733512878418, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1909.7362060546875, "training_acc": 72.0, "val_loss": 46.64407968521118, "val_acc": 28.0}
{"epoch": 16, "training_loss": 391.6941680908203, "training_acc": 42.0, "val_loss": 118.44971179962158, "val_acc": 72.0}
{"epoch": 17, "training_loss": 976.5232315063477, "training_acc": 52.0, "val_loss": 152.20898389816284, "val_acc": 72.0}
{"epoch": 18, "training_loss": 716.385669708252, "training_acc": 72.0, "val_loss": 105.3324818611145, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1245.853645324707, "training_acc": 52.0, "val_loss": 16.309574246406555, "val_acc": 72.0}
{"epoch": 20, "training_loss": 223.2169303894043, "training_acc": 72.0, "val_loss": 85.53212285041809, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1096.5112380981445, "training_acc": 50.0, "val_loss": 106.0356616973877, "val_acc": 72.0}
{"epoch": 22, "training_loss": 464.88943099975586, "training_acc": 72.0, "val_loss": 62.80183792114258, "val_acc": 72.0}
{"epoch": 23, "training_loss": 980.5820083618164, "training_acc": 56.0, "val_loss": 32.84439742565155, "val_acc": 72.0}
{"epoch": 24, "training_loss": 227.60905075073242, "training_acc": 72.0, "val_loss": 217.5426959991455, "val_acc": 28.0}
{"epoch": 25, "training_loss": 861.1778030395508, "training_acc": 46.0, "val_loss": 371.81718349456787, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1352.5070457458496, "training_acc": 72.0, "val_loss": 14.977258443832397, "val_acc": 64.0}
{"epoch": 27, "training_loss": 948.3955154418945, "training_acc": 54.0, "val_loss": 75.08137822151184, "val_acc": 72.0}
{"epoch": 28, "training_loss": 381.0640811920166, "training_acc": 72.0, "val_loss": 34.51757729053497, "val_acc": 72.0}
{"epoch": 29, "training_loss": 896.1638870239258, "training_acc": 60.0, "val_loss": 35.28185188770294, "val_acc": 28.0}
{"epoch": 30, "training_loss": 946.3995742797852, "training_acc": 44.0, "val_loss": 958.796215057373, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3997.6903381347656, "training_acc": 72.0, "val_loss": 995.1265335083008, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3566.56827545166, "training_acc": 72.0, "val_loss": 259.53497886657715, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1725.913688659668, "training_acc": 60.0, "val_loss": 981.1544418334961, "val_acc": 28.0}
{"epoch": 34, "training_loss": 2785.262372970581, "training_acc": 40.0, "val_loss": 308.66286754608154, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1210.18745803833, "training_acc": 72.0, "val_loss": 79.26342487335205, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1820.2604522705078, "training_acc": 48.0, "val_loss": 457.16609954833984, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2454.090072631836, "training_acc": 34.0, "val_loss": 905.6039810180664, "val_acc": 72.0}
{"epoch": 38, "training_loss": 3791.1477813720703, "training_acc": 72.0, "val_loss": 959.0459823608398, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3438.635887145996, "training_acc": 72.0, "val_loss": 253.6959409713745, "val_acc": 72.0}
{"epoch": 40, "training_loss": 2165.662063598633, "training_acc": 52.0, "val_loss": 942.0608520507812, "val_acc": 28.0}
{"epoch": 41, "training_loss": 2761.8500328063965, "training_acc": 40.0, "val_loss": 382.21428394317627, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1628.2173690795898, "training_acc": 72.0, "val_loss": 223.10900688171387, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1102.1617584228516, "training_acc": 58.0, "val_loss": 49.8888224363327, "val_acc": 28.0}
{"epoch": 44, "training_loss": 1216.1374893188477, "training_acc": 38.0, "val_loss": 884.3280792236328, "val_acc": 72.0}
{"epoch": 45, "training_loss": 3649.154037475586, "training_acc": 72.0, "val_loss": 832.5927734375, "val_acc": 72.0}
