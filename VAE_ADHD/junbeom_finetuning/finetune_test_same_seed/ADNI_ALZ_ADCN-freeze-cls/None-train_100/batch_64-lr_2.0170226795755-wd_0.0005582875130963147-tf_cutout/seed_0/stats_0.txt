"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 9544.46401977539, "training_acc": 42.0, "val_loss": 5196.959686279297, "val_acc": 72.0}
{"epoch": 1, "training_loss": 16306.657318115234, "training_acc": 72.0, "val_loss": 3063.5698318481445, "val_acc": 28.0}
{"epoch": 2, "training_loss": 10465.526306152344, "training_acc": 28.0, "val_loss": 1640.838623046875, "val_acc": 72.0}
{"epoch": 3, "training_loss": 8470.46533203125, "training_acc": 72.0, "val_loss": 3465.4747009277344, "val_acc": 72.0}
{"epoch": 4, "training_loss": 13561.554138183594, "training_acc": 72.0, "val_loss": 2436.0055923461914, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8484.389877319336, "training_acc": 72.0, "val_loss": 1758.4077835083008, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6926.796051025391, "training_acc": 28.0, "val_loss": 605.3762912750244, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2982.8209686279297, "training_acc": 72.0, "val_loss": 1349.4668006896973, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4942.294967651367, "training_acc": 72.0, "val_loss": 293.9861297607422, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4759.908172607422, "training_acc": 50.0, "val_loss": 1852.5886535644531, "val_acc": 28.0}
{"epoch": 10, "training_loss": 5473.304359436035, "training_acc": 44.0, "val_loss": 1220.6049919128418, "val_acc": 72.0}
{"epoch": 11, "training_loss": 5196.396469116211, "training_acc": 72.0, "val_loss": 1236.2150192260742, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4131.908561706543, "training_acc": 72.0, "val_loss": 840.8135414123535, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2821.240966796875, "training_acc": 28.0, "val_loss": 1055.1175117492676, "val_acc": 72.0}
{"epoch": 14, "training_loss": 5569.807525634766, "training_acc": 72.0, "val_loss": 2096.9284057617188, "val_acc": 72.0}
{"epoch": 15, "training_loss": 8168.888702392578, "training_acc": 72.0, "val_loss": 1395.9259986877441, "val_acc": 72.0}
{"epoch": 16, "training_loss": 4073.405792236328, "training_acc": 72.0, "val_loss": 1904.0435791015625, "val_acc": 28.0}
{"epoch": 17, "training_loss": 8374.434997558594, "training_acc": 28.0, "val_loss": 13.053566217422485, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1955.0171241760254, "training_acc": 70.0, "val_loss": 1480.0579071044922, "val_acc": 72.0}
{"epoch": 19, "training_loss": 5862.632034301758, "training_acc": 72.0, "val_loss": 1120.7584381103516, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3582.4211921691895, "training_acc": 72.0, "val_loss": 1394.34175491333, "val_acc": 28.0}
{"epoch": 21, "training_loss": 4983.956390380859, "training_acc": 28.0, "val_loss": 662.8598690032959, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3423.2230834960938, "training_acc": 72.0, "val_loss": 1324.9733924865723, "val_acc": 72.0}
{"epoch": 23, "training_loss": 4901.771453857422, "training_acc": 72.0, "val_loss": 408.3186149597168, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3030.5540771484375, "training_acc": 56.0, "val_loss": 991.3349151611328, "val_acc": 28.0}
{"epoch": 25, "training_loss": 3721.4673080444336, "training_acc": 42.0, "val_loss": 1312.7086639404297, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5414.594268798828, "training_acc": 72.0, "val_loss": 1231.3881874084473, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4084.6785202026367, "training_acc": 72.0, "val_loss": 635.3649616241455, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1993.8151969909668, "training_acc": 28.0, "val_loss": 1027.0584106445312, "val_acc": 72.0}
{"epoch": 29, "training_loss": 5019.82177734375, "training_acc": 72.0, "val_loss": 1882.6807022094727, "val_acc": 72.0}
{"epoch": 30, "training_loss": 7265.099914550781, "training_acc": 72.0, "val_loss": 1134.023380279541, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3031.855140686035, "training_acc": 72.0, "val_loss": 2084.0438842773438, "val_acc": 28.0}
{"epoch": 32, "training_loss": 8919.87954711914, "training_acc": 28.0, "val_loss": 87.884122133255, "val_acc": 28.0}
{"epoch": 33, "training_loss": 2135.493896484375, "training_acc": 48.0, "val_loss": 2926.318359375, "val_acc": 72.0}
{"epoch": 34, "training_loss": 13058.545166015625, "training_acc": 72.0, "val_loss": 3999.9622344970703, "val_acc": 72.0}
{"epoch": 35, "training_loss": 15792.666198730469, "training_acc": 72.0, "val_loss": 3374.2332458496094, "val_acc": 72.0}
{"epoch": 36, "training_loss": 12388.631286621094, "training_acc": 72.0, "val_loss": 1416.3898468017578, "val_acc": 72.0}
