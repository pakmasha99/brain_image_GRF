"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6960.952796936035, "training_acc": 72.0, "val_loss": 5091.197204589844, "val_acc": 72.0}
{"epoch": 1, "training_loss": 16118.135299682617, "training_acc": 72.0, "val_loss": 6041.620635986328, "val_acc": 28.0}
{"epoch": 2, "training_loss": 21085.149291992188, "training_acc": 28.0, "val_loss": 1073.3193397521973, "val_acc": 72.0}
{"epoch": 3, "training_loss": 5962.707702636719, "training_acc": 72.0, "val_loss": 2849.2177963256836, "val_acc": 72.0}
{"epoch": 4, "training_loss": 10992.053009033203, "training_acc": 72.0, "val_loss": 1655.7611465454102, "val_acc": 72.0}
{"epoch": 5, "training_loss": 5143.835187911987, "training_acc": 72.0, "val_loss": 4043.1488037109375, "val_acc": 28.0}
{"epoch": 6, "training_loss": 16125.081848144531, "training_acc": 28.0, "val_loss": 545.9098815917969, "val_acc": 28.0}
{"epoch": 7, "training_loss": 5075.852020263672, "training_acc": 40.0, "val_loss": 3645.6863403320312, "val_acc": 72.0}
{"epoch": 8, "training_loss": 16071.290893554688, "training_acc": 72.0, "val_loss": 4954.922866821289, "val_acc": 72.0}
{"epoch": 9, "training_loss": 19624.05010986328, "training_acc": 72.0, "val_loss": 4259.855270385742, "val_acc": 72.0}
{"epoch": 10, "training_loss": 15982.659301757812, "training_acc": 72.0, "val_loss": 2150.682258605957, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6424.0544509887695, "training_acc": 72.0, "val_loss": 3047.677230834961, "val_acc": 28.0}
{"epoch": 12, "training_loss": 13318.568054199219, "training_acc": 28.0, "val_loss": 2437.2413635253906, "val_acc": 28.0}
{"epoch": 13, "training_loss": 6822.5625, "training_acc": 46.0, "val_loss": 1576.1491775512695, "val_acc": 72.0}
{"epoch": 14, "training_loss": 7372.637268066406, "training_acc": 72.0, "val_loss": 2153.3403396606445, "val_acc": 72.0}
{"epoch": 15, "training_loss": 8052.651092529297, "training_acc": 72.0, "val_loss": 965.1165962219238, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2720.8697471618652, "training_acc": 58.0, "val_loss": 131.8735957145691, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2127.030471801758, "training_acc": 40.0, "val_loss": 1545.83740234375, "val_acc": 72.0}
{"epoch": 18, "training_loss": 6326.184478759766, "training_acc": 72.0, "val_loss": 1295.8309173583984, "val_acc": 72.0}
{"epoch": 19, "training_loss": 4315.346206665039, "training_acc": 72.0, "val_loss": 1161.2524032592773, "val_acc": 28.0}
{"epoch": 20, "training_loss": 4041.8228759765625, "training_acc": 28.0, "val_loss": 771.8601703643799, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3569.773468017578, "training_acc": 72.0, "val_loss": 1434.60693359375, "val_acc": 72.0}
{"epoch": 22, "training_loss": 5431.831275939941, "training_acc": 72.0, "val_loss": 591.6701316833496, "val_acc": 72.0}
{"epoch": 23, "training_loss": 2814.173309326172, "training_acc": 54.0, "val_loss": 199.7302770614624, "val_acc": 28.0}
{"epoch": 24, "training_loss": 2290.6455688476562, "training_acc": 42.0, "val_loss": 1785.164451599121, "val_acc": 72.0}
{"epoch": 25, "training_loss": 7513.5806884765625, "training_acc": 72.0, "val_loss": 1824.6076583862305, "val_acc": 72.0}
{"epoch": 26, "training_loss": 6425.337829589844, "training_acc": 72.0, "val_loss": 353.8019895553589, "val_acc": 72.0}
{"epoch": 27, "training_loss": 3385.0399475097656, "training_acc": 62.0, "val_loss": 2439.909553527832, "val_acc": 28.0}
{"epoch": 28, "training_loss": 6678.277843475342, "training_acc": 28.0, "val_loss": 1616.1556243896484, "val_acc": 72.0}
{"epoch": 29, "training_loss": 8109.530487060547, "training_acc": 72.0, "val_loss": 3446.527099609375, "val_acc": 72.0}
{"epoch": 30, "training_loss": 13980.774536132812, "training_acc": 72.0, "val_loss": 3483.544158935547, "val_acc": 72.0}
{"epoch": 31, "training_loss": 13182.203552246094, "training_acc": 72.0, "val_loss": 2116.325569152832, "val_acc": 72.0}
{"epoch": 32, "training_loss": 7387.401573181152, "training_acc": 72.0, "val_loss": 1232.9364776611328, "val_acc": 28.0}
{"epoch": 33, "training_loss": 6113.263214111328, "training_acc": 28.0, "val_loss": 80.17885684967041, "val_acc": 72.0}
{"epoch": 34, "training_loss": 939.7800445556641, "training_acc": 72.0, "val_loss": 428.4632682800293, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1027.1660828590393, "training_acc": 72.0, "val_loss": 1948.5759735107422, "val_acc": 28.0}
{"epoch": 36, "training_loss": 6816.348937988281, "training_acc": 28.0, "val_loss": 716.7758464813232, "val_acc": 72.0}
{"epoch": 37, "training_loss": 3744.1146392822266, "training_acc": 72.0, "val_loss": 1696.287727355957, "val_acc": 72.0}
{"epoch": 38, "training_loss": 6606.4521484375, "training_acc": 72.0, "val_loss": 1078.236961364746, "val_acc": 72.0}
{"epoch": 39, "training_loss": 3081.3781929016113, "training_acc": 72.0, "val_loss": 2350.8527755737305, "val_acc": 28.0}
{"epoch": 40, "training_loss": 9675.512145996094, "training_acc": 28.0, "val_loss": 46.680948138237, "val_acc": 28.0}
{"epoch": 41, "training_loss": 3050.3165130615234, "training_acc": 41.0, "val_loss": 2814.4018173217773, "val_acc": 72.0}
{"epoch": 42, "training_loss": 12130.566101074219, "training_acc": 72.0, "val_loss": 3620.9678649902344, "val_acc": 72.0}
{"epoch": 43, "training_loss": 14171.727935791016, "training_acc": 72.0, "val_loss": 2823.5979080200195, "val_acc": 72.0}
{"epoch": 44, "training_loss": 10579.11752319336, "training_acc": 72.0, "val_loss": 772.2181797027588, "val_acc": 72.0}
{"epoch": 45, "training_loss": 3085.078323364258, "training_acc": 64.0, "val_loss": 2022.3995208740234, "val_acc": 28.0}
{"epoch": 46, "training_loss": 5465.150575637817, "training_acc": 28.0, "val_loss": 1529.9063682556152, "val_acc": 72.0}
{"epoch": 47, "training_loss": 7453.999603271484, "training_acc": 72.0, "val_loss": 3190.64884185791, "val_acc": 72.0}
{"epoch": 48, "training_loss": 13041.481567382812, "training_acc": 72.0, "val_loss": 3127.6451110839844, "val_acc": 72.0}
{"epoch": 49, "training_loss": 11570.170623779297, "training_acc": 72.0, "val_loss": 1584.648323059082, "val_acc": 72.0}
{"epoch": 50, "training_loss": 4537.759216308594, "training_acc": 72.0, "val_loss": 2985.298728942871, "val_acc": 28.0}
{"epoch": 51, "training_loss": 13582.760986328125, "training_acc": 28.0, "val_loss": 2214.7932052612305, "val_acc": 28.0}
{"epoch": 52, "training_loss": 6980.251861572266, "training_acc": 42.0, "val_loss": 1784.9592208862305, "val_acc": 72.0}
{"epoch": 53, "training_loss": 7922.312652587891, "training_acc": 72.0, "val_loss": 2469.927978515625, "val_acc": 72.0}
{"epoch": 54, "training_loss": 9469.103088378906, "training_acc": 72.0, "val_loss": 1578.4069061279297, "val_acc": 72.0}
{"epoch": 55, "training_loss": 5024.320045471191, "training_acc": 72.0, "val_loss": 1615.8447265625, "val_acc": 28.0}
{"epoch": 56, "training_loss": 7047.3818359375, "training_acc": 28.0, "val_loss": 109.71777439117432, "val_acc": 72.0}
{"epoch": 57, "training_loss": 1114.745735168457, "training_acc": 72.0, "val_loss": 535.6979846954346, "val_acc": 72.0}
{"epoch": 58, "training_loss": 1527.9608936309814, "training_acc": 72.0, "val_loss": 1509.68599319458, "val_acc": 28.0}
{"epoch": 59, "training_loss": 4927.926734924316, "training_acc": 28.0, "val_loss": 944.9501991271973, "val_acc": 72.0}
