"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 637.7244033813477, "training_acc": 72.0, "val_loss": 208.45694541931152, "val_acc": 72.0}
{"epoch": 1, "training_loss": 645.694305896759, "training_acc": 72.0, "val_loss": 376.17876529693604, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1417.8734169006348, "training_acc": 28.0, "val_loss": 35.074010491371155, "val_acc": 28.0}
{"epoch": 3, "training_loss": 221.76736545562744, "training_acc": 50.0, "val_loss": 245.3435182571411, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1060.9878768920898, "training_acc": 72.0, "val_loss": 333.8632822036743, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1328.8834342956543, "training_acc": 72.0, "val_loss": 296.0094451904297, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1139.251516342163, "training_acc": 72.0, "val_loss": 161.05800867080688, "val_acc": 72.0}
{"epoch": 7, "training_loss": 515.4653148651123, "training_acc": 72.0, "val_loss": 94.13795471191406, "val_acc": 28.0}
{"epoch": 8, "training_loss": 490.2902011871338, "training_acc": 28.0, "val_loss": 67.08189249038696, "val_acc": 28.0}
{"epoch": 9, "training_loss": 192.52094745635986, "training_acc": 54.0, "val_loss": 118.32815408706665, "val_acc": 72.0}
{"epoch": 10, "training_loss": 516.6977310180664, "training_acc": 72.0, "val_loss": 162.7379059791565, "val_acc": 72.0}
{"epoch": 11, "training_loss": 634.1465435028076, "training_acc": 72.0, "val_loss": 117.85917282104492, "val_acc": 72.0}
{"epoch": 12, "training_loss": 410.1472520828247, "training_acc": 72.0, "val_loss": 19.27388906478882, "val_acc": 28.0}
{"epoch": 13, "training_loss": 173.83213806152344, "training_acc": 28.0, "val_loss": 42.02808141708374, "val_acc": 28.0}
{"epoch": 14, "training_loss": 187.2331829071045, "training_acc": 42.0, "val_loss": 85.39286851882935, "val_acc": 72.0}
{"epoch": 15, "training_loss": 361.9955520629883, "training_acc": 72.0, "val_loss": 87.03184127807617, "val_acc": 72.0}
{"epoch": 16, "training_loss": 306.84947299957275, "training_acc": 72.0, "val_loss": 14.72240686416626, "val_acc": 72.0}
{"epoch": 17, "training_loss": 176.6583652496338, "training_acc": 56.0, "val_loss": 59.593796730041504, "val_acc": 28.0}
{"epoch": 18, "training_loss": 197.8369598388672, "training_acc": 46.0, "val_loss": 75.05877614021301, "val_acc": 72.0}
{"epoch": 19, "training_loss": 316.1310977935791, "training_acc": 72.0, "val_loss": 79.70386147499084, "val_acc": 72.0}
{"epoch": 20, "training_loss": 282.42157888412476, "training_acc": 72.0, "val_loss": 14.700493216514587, "val_acc": 72.0}
{"epoch": 21, "training_loss": 136.01300811767578, "training_acc": 62.0, "val_loss": 47.64871895313263, "val_acc": 28.0}
{"epoch": 22, "training_loss": 169.59050273895264, "training_acc": 46.0, "val_loss": 72.75105118751526, "val_acc": 72.0}
{"epoch": 23, "training_loss": 299.99144172668457, "training_acc": 72.0, "val_loss": 70.86573839187622, "val_acc": 72.0}
{"epoch": 24, "training_loss": 251.100079536438, "training_acc": 72.0, "val_loss": 23.6041858792305, "val_acc": 28.0}
{"epoch": 25, "training_loss": 123.94577836990356, "training_acc": 28.0, "val_loss": 23.890505731105804, "val_acc": 72.0}
{"epoch": 26, "training_loss": 115.19357585906982, "training_acc": 72.0, "val_loss": 35.372233390808105, "val_acc": 72.0}
{"epoch": 27, "training_loss": 111.35818409919739, "training_acc": 72.0, "val_loss": 53.302425146102905, "val_acc": 28.0}
{"epoch": 28, "training_loss": 165.52241039276123, "training_acc": 40.0, "val_loss": 29.549488425254822, "val_acc": 72.0}
{"epoch": 29, "training_loss": 125.33218336105347, "training_acc": 72.0, "val_loss": 20.132674276828766, "val_acc": 72.0}
{"epoch": 30, "training_loss": 101.5430998802185, "training_acc": 56.0, "val_loss": 15.28308391571045, "val_acc": 40.0}
{"epoch": 31, "training_loss": 90.97746801376343, "training_acc": 72.0, "val_loss": 25.614431500434875, "val_acc": 72.0}
{"epoch": 32, "training_loss": 108.19401097297668, "training_acc": 48.0, "val_loss": 15.075945854187012, "val_acc": 80.0}
{"epoch": 33, "training_loss": 67.22800898551941, "training_acc": 72.0, "val_loss": 15.64551442861557, "val_acc": 72.0}
{"epoch": 34, "training_loss": 87.89012002944946, "training_acc": 48.0, "val_loss": 20.770403742790222, "val_acc": 72.0}
{"epoch": 35, "training_loss": 101.21132230758667, "training_acc": 72.0, "val_loss": 16.299976408481598, "val_acc": 72.0}
{"epoch": 36, "training_loss": 105.080397605896, "training_acc": 54.0, "val_loss": 14.972983300685883, "val_acc": 72.0}
{"epoch": 37, "training_loss": 76.05137157440186, "training_acc": 72.0, "val_loss": 21.985717117786407, "val_acc": 72.0}
{"epoch": 38, "training_loss": 94.06474232673645, "training_acc": 52.0, "val_loss": 14.648820459842682, "val_acc": 72.0}
{"epoch": 39, "training_loss": 67.17220258712769, "training_acc": 72.0, "val_loss": 15.307232737541199, "val_acc": 72.0}
{"epoch": 40, "training_loss": 84.62164211273193, "training_acc": 50.0, "val_loss": 20.419692993164062, "val_acc": 72.0}
{"epoch": 41, "training_loss": 92.6272759437561, "training_acc": 72.0, "val_loss": 15.739160776138306, "val_acc": 72.0}
{"epoch": 42, "training_loss": 97.38340520858765, "training_acc": 54.0, "val_loss": 16.347162425518036, "val_acc": 72.0}
{"epoch": 43, "training_loss": 75.56903719902039, "training_acc": 72.0, "val_loss": 18.45049560070038, "val_acc": 72.0}
{"epoch": 44, "training_loss": 71.11991047859192, "training_acc": 60.0, "val_loss": 16.231314837932587, "val_acc": 28.0}
{"epoch": 45, "training_loss": 67.16496920585632, "training_acc": 72.0, "val_loss": 20.127221941947937, "val_acc": 72.0}
{"epoch": 46, "training_loss": 71.3855369091034, "training_acc": 72.0, "val_loss": 21.804529428482056, "val_acc": 28.0}
{"epoch": 47, "training_loss": 100.62470817565918, "training_acc": 38.0, "val_loss": 21.5937539935112, "val_acc": 72.0}
{"epoch": 48, "training_loss": 72.82502388954163, "training_acc": 72.0, "val_loss": 26.60895586013794, "val_acc": 28.0}
{"epoch": 49, "training_loss": 105.39455342292786, "training_acc": 42.0, "val_loss": 27.7803897857666, "val_acc": 72.0}
{"epoch": 50, "training_loss": 93.71440434455872, "training_acc": 72.0, "val_loss": 36.05612814426422, "val_acc": 28.0}
{"epoch": 51, "training_loss": 116.12573337554932, "training_acc": 44.0, "val_loss": 25.101977586746216, "val_acc": 72.0}
{"epoch": 52, "training_loss": 89.11459422111511, "training_acc": 72.0, "val_loss": 27.9887855052948, "val_acc": 28.0}
{"epoch": 53, "training_loss": 97.83827304840088, "training_acc": 42.0, "val_loss": 19.63973641395569, "val_acc": 72.0}
{"epoch": 54, "training_loss": 70.02916049957275, "training_acc": 72.0, "val_loss": 23.929327726364136, "val_acc": 28.0}
{"epoch": 55, "training_loss": 98.16334509849548, "training_acc": 40.0, "val_loss": 20.847827196121216, "val_acc": 72.0}
{"epoch": 56, "training_loss": 76.9463210105896, "training_acc": 72.0, "val_loss": 17.655271291732788, "val_acc": 28.0}
{"epoch": 57, "training_loss": 57.907724142074585, "training_acc": 59.0, "val_loss": 26.627251505851746, "val_acc": 72.0}
