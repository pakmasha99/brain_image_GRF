"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 598.8979110717773, "training_acc": 38.0, "val_loss": 246.5787649154663, "val_acc": 72.0}
{"epoch": 1, "training_loss": 880.0542840957642, "training_acc": 72.0, "val_loss": 157.21513032913208, "val_acc": 28.0}
{"epoch": 2, "training_loss": 490.5530014038086, "training_acc": 28.0, "val_loss": 96.10209465026855, "val_acc": 72.0}
{"epoch": 3, "training_loss": 458.5533084869385, "training_acc": 72.0, "val_loss": 190.76370000839233, "val_acc": 72.0}
{"epoch": 4, "training_loss": 752.5113296508789, "training_acc": 72.0, "val_loss": 147.67144918441772, "val_acc": 72.0}
{"epoch": 5, "training_loss": 486.00780296325684, "training_acc": 72.0, "val_loss": 14.94583785533905, "val_acc": 72.0}
{"epoch": 6, "training_loss": 395.55491638183594, "training_acc": 44.0, "val_loss": 155.94778060913086, "val_acc": 28.0}
{"epoch": 7, "training_loss": 432.39287185668945, "training_acc": 42.0, "val_loss": 65.29282331466675, "val_acc": 72.0}
{"epoch": 8, "training_loss": 270.8632264137268, "training_acc": 72.0, "val_loss": 88.2386326789856, "val_acc": 72.0}
{"epoch": 9, "training_loss": 328.08459091186523, "training_acc": 72.0, "val_loss": 33.72040390968323, "val_acc": 72.0}
{"epoch": 10, "training_loss": 174.63143920898438, "training_acc": 56.0, "val_loss": 51.28961205482483, "val_acc": 28.0}
{"epoch": 11, "training_loss": 169.1213459968567, "training_acc": 46.0, "val_loss": 59.8761260509491, "val_acc": 72.0}
{"epoch": 12, "training_loss": 262.25105476379395, "training_acc": 72.0, "val_loss": 48.97946119308472, "val_acc": 72.0}
{"epoch": 13, "training_loss": 137.43023467063904, "training_acc": 72.0, "val_loss": 92.02516078948975, "val_acc": 28.0}
{"epoch": 14, "training_loss": 329.73132038116455, "training_acc": 28.0, "val_loss": 34.12821888923645, "val_acc": 72.0}
{"epoch": 15, "training_loss": 207.14884757995605, "training_acc": 72.0, "val_loss": 80.8415174484253, "val_acc": 72.0}
{"epoch": 16, "training_loss": 306.35432720184326, "training_acc": 72.0, "val_loss": 38.25973570346832, "val_acc": 72.0}
{"epoch": 17, "training_loss": 156.8091540336609, "training_acc": 54.0, "val_loss": 40.204787254333496, "val_acc": 28.0}
{"epoch": 18, "training_loss": 154.98809051513672, "training_acc": 40.0, "val_loss": 44.15077865123749, "val_acc": 72.0}
{"epoch": 19, "training_loss": 168.77841806411743, "training_acc": 72.0, "val_loss": 18.009337782859802, "val_acc": 72.0}
{"epoch": 20, "training_loss": 121.4323673248291, "training_acc": 54.0, "val_loss": 17.636463046073914, "val_acc": 28.0}
{"epoch": 21, "training_loss": 91.76199531555176, "training_acc": 48.0, "val_loss": 43.25433969497681, "val_acc": 72.0}
{"epoch": 22, "training_loss": 159.060781955719, "training_acc": 72.0, "val_loss": 14.684277772903442, "val_acc": 72.0}
{"epoch": 23, "training_loss": 105.11205005645752, "training_acc": 56.0, "val_loss": 14.726707339286804, "val_acc": 72.0}
{"epoch": 24, "training_loss": 70.43663358688354, "training_acc": 72.0, "val_loss": 28.078722953796387, "val_acc": 72.0}
{"epoch": 25, "training_loss": 92.25527286529541, "training_acc": 72.0, "val_loss": 38.39178383350372, "val_acc": 28.0}
{"epoch": 26, "training_loss": 118.91751909255981, "training_acc": 44.0, "val_loss": 25.711780786514282, "val_acc": 72.0}
{"epoch": 27, "training_loss": 99.94666600227356, "training_acc": 72.0, "val_loss": 15.223459899425507, "val_acc": 48.0}
{"epoch": 28, "training_loss": 79.32500696182251, "training_acc": 54.0, "val_loss": 20.86661159992218, "val_acc": 72.0}
{"epoch": 29, "training_loss": 96.52420139312744, "training_acc": 72.0, "val_loss": 17.91856586933136, "val_acc": 72.0}
{"epoch": 30, "training_loss": 92.42121124267578, "training_acc": 56.0, "val_loss": 14.518842101097107, "val_acc": 72.0}
{"epoch": 31, "training_loss": 63.208964824676514, "training_acc": 72.0, "val_loss": 19.971629977226257, "val_acc": 72.0}
{"epoch": 32, "training_loss": 66.5554301738739, "training_acc": 72.0, "val_loss": 29.73926067352295, "val_acc": 28.0}
{"epoch": 33, "training_loss": 109.0506203174591, "training_acc": 42.0, "val_loss": 25.668704509735107, "val_acc": 72.0}
{"epoch": 34, "training_loss": 94.18177473545074, "training_acc": 72.0, "val_loss": 21.328091621398926, "val_acc": 28.0}
{"epoch": 35, "training_loss": 72.12045407295227, "training_acc": 48.0, "val_loss": 21.590805053710938, "val_acc": 72.0}
{"epoch": 36, "training_loss": 79.81950354576111, "training_acc": 72.0, "val_loss": 18.737371265888214, "val_acc": 28.0}
{"epoch": 37, "training_loss": 69.48828959465027, "training_acc": 44.0, "val_loss": 17.122481763362885, "val_acc": 72.0}
{"epoch": 38, "training_loss": 70.04543662071228, "training_acc": 72.0, "val_loss": 14.481672644615173, "val_acc": 72.0}
{"epoch": 39, "training_loss": 57.89311981201172, "training_acc": 72.0, "val_loss": 15.830373764038086, "val_acc": 72.0}
{"epoch": 40, "training_loss": 60.524054765701294, "training_acc": 72.0, "val_loss": 17.889253795146942, "val_acc": 28.0}
{"epoch": 41, "training_loss": 66.06951856613159, "training_acc": 51.0, "val_loss": 17.7973672747612, "val_acc": 72.0}
{"epoch": 42, "training_loss": 63.807705879211426, "training_acc": 72.0, "val_loss": 23.367711901664734, "val_acc": 28.0}
{"epoch": 43, "training_loss": 87.1776168346405, "training_acc": 44.0, "val_loss": 22.602203488349915, "val_acc": 72.0}
{"epoch": 44, "training_loss": 94.41893744468689, "training_acc": 67.0, "val_loss": 14.47550654411316, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.36416792869568, "training_acc": 72.0, "val_loss": 14.499902725219727, "val_acc": 72.0}
{"epoch": 46, "training_loss": 60.038106203079224, "training_acc": 72.0, "val_loss": 16.81182086467743, "val_acc": 72.0}
{"epoch": 47, "training_loss": 68.35290193557739, "training_acc": 72.0, "val_loss": 24.532169103622437, "val_acc": 28.0}
{"epoch": 48, "training_loss": 81.71890616416931, "training_acc": 46.0, "val_loss": 21.011996269226074, "val_acc": 72.0}
{"epoch": 49, "training_loss": 73.89935398101807, "training_acc": 72.0, "val_loss": 28.428974747657776, "val_acc": 28.0}
{"epoch": 50, "training_loss": 95.50359416007996, "training_acc": 46.0, "val_loss": 25.290030241012573, "val_acc": 72.0}
{"epoch": 51, "training_loss": 84.68364763259888, "training_acc": 72.0, "val_loss": 45.14618515968323, "val_acc": 28.0}
{"epoch": 52, "training_loss": 146.8646981716156, "training_acc": 40.0, "val_loss": 23.530329763889313, "val_acc": 72.0}
{"epoch": 53, "training_loss": 80.460529088974, "training_acc": 72.0, "val_loss": 37.96810209751129, "val_acc": 28.0}
{"epoch": 54, "training_loss": 126.83463835716248, "training_acc": 42.0, "val_loss": 24.257799983024597, "val_acc": 72.0}
{"epoch": 55, "training_loss": 90.31507086753845, "training_acc": 72.0, "val_loss": 17.981763184070587, "val_acc": 28.0}
{"epoch": 56, "training_loss": 64.44503498077393, "training_acc": 55.0, "val_loss": 19.727347791194916, "val_acc": 72.0}
{"epoch": 57, "training_loss": 66.94971132278442, "training_acc": 72.0, "val_loss": 34.61180925369263, "val_acc": 28.0}
{"epoch": 58, "training_loss": 130.0481572151184, "training_acc": 40.0, "val_loss": 27.031585574150085, "val_acc": 72.0}
{"epoch": 59, "training_loss": 85.72245740890503, "training_acc": 72.0, "val_loss": 51.12870931625366, "val_acc": 28.0}
{"epoch": 60, "training_loss": 161.36692810058594, "training_acc": 40.0, "val_loss": 25.296679139137268, "val_acc": 72.0}
{"epoch": 61, "training_loss": 89.42759728431702, "training_acc": 72.0, "val_loss": 27.158141136169434, "val_acc": 28.0}
{"epoch": 62, "training_loss": 98.37017273902893, "training_acc": 42.0, "val_loss": 20.464222133159637, "val_acc": 72.0}
{"epoch": 63, "training_loss": 71.20179486274719, "training_acc": 72.0, "val_loss": 22.189275920391083, "val_acc": 28.0}
