"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 258.3738327026367, "training_acc": 44.0, "val_loss": 141.29650592803955, "val_acc": 72.0}
{"epoch": 1, "training_loss": 481.9852590560913, "training_acc": 72.0, "val_loss": 18.2009756565094, "val_acc": 28.0}
{"epoch": 2, "training_loss": 194.42978286743164, "training_acc": 28.0, "val_loss": 14.94644582271576, "val_acc": 72.0}
{"epoch": 3, "training_loss": 110.43370342254639, "training_acc": 72.0, "val_loss": 59.413427114486694, "val_acc": 72.0}
{"epoch": 4, "training_loss": 226.58289051055908, "training_acc": 72.0, "val_loss": 27.062073349952698, "val_acc": 72.0}
{"epoch": 5, "training_loss": 138.20784711837769, "training_acc": 52.0, "val_loss": 30.91769814491272, "val_acc": 28.0}
{"epoch": 6, "training_loss": 104.74233937263489, "training_acc": 46.0, "val_loss": 36.22982203960419, "val_acc": 72.0}
{"epoch": 7, "training_loss": 146.24875116348267, "training_acc": 72.0, "val_loss": 25.35502314567566, "val_acc": 72.0}
{"epoch": 8, "training_loss": 102.39991331100464, "training_acc": 50.0, "val_loss": 26.308128237724304, "val_acc": 28.0}
{"epoch": 9, "training_loss": 91.25725841522217, "training_acc": 42.0, "val_loss": 21.232539415359497, "val_acc": 72.0}
{"epoch": 10, "training_loss": 86.77439165115356, "training_acc": 72.0, "val_loss": 14.834989607334137, "val_acc": 72.0}
{"epoch": 11, "training_loss": 76.75813436508179, "training_acc": 54.0, "val_loss": 15.742376446723938, "val_acc": 28.0}
{"epoch": 12, "training_loss": 64.82088112831116, "training_acc": 72.0, "val_loss": 22.380565106868744, "val_acc": 72.0}
{"epoch": 13, "training_loss": 82.55215525627136, "training_acc": 72.0, "val_loss": 16.587340831756592, "val_acc": 28.0}
{"epoch": 14, "training_loss": 77.93324732780457, "training_acc": 50.0, "val_loss": 16.04679524898529, "val_acc": 72.0}
{"epoch": 15, "training_loss": 78.1142578125, "training_acc": 72.0, "val_loss": 20.36224752664566, "val_acc": 72.0}
{"epoch": 16, "training_loss": 71.58502745628357, "training_acc": 72.0, "val_loss": 24.42176192998886, "val_acc": 28.0}
{"epoch": 17, "training_loss": 87.00149893760681, "training_acc": 40.0, "val_loss": 17.678512632846832, "val_acc": 72.0}
{"epoch": 18, "training_loss": 72.1054036617279, "training_acc": 72.0, "val_loss": 14.776092767715454, "val_acc": 72.0}
{"epoch": 19, "training_loss": 63.06898331642151, "training_acc": 58.0, "val_loss": 15.547944605350494, "val_acc": 28.0}
{"epoch": 20, "training_loss": 65.11989665031433, "training_acc": 72.0, "val_loss": 17.098769545555115, "val_acc": 72.0}
{"epoch": 21, "training_loss": 64.05960321426392, "training_acc": 72.0, "val_loss": 18.079209327697754, "val_acc": 28.0}
{"epoch": 22, "training_loss": 69.45371222496033, "training_acc": 40.0, "val_loss": 15.44441133737564, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.656094789505005, "training_acc": 72.0, "val_loss": 15.069174766540527, "val_acc": 72.0}
{"epoch": 24, "training_loss": 63.516345262527466, "training_acc": 72.0, "val_loss": 15.589737892150879, "val_acc": 72.0}
{"epoch": 25, "training_loss": 62.26843309402466, "training_acc": 72.0, "val_loss": 15.821671485900879, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60.38775610923767, "training_acc": 72.0, "val_loss": 17.655612528324127, "val_acc": 28.0}
{"epoch": 27, "training_loss": 65.6895649433136, "training_acc": 48.0, "val_loss": 18.138743937015533, "val_acc": 72.0}
{"epoch": 28, "training_loss": 75.32263255119324, "training_acc": 72.0, "val_loss": 14.757153391838074, "val_acc": 72.0}
{"epoch": 29, "training_loss": 68.85071539878845, "training_acc": 56.0, "val_loss": 14.74205106496811, "val_acc": 72.0}
{"epoch": 30, "training_loss": 66.7891857624054, "training_acc": 72.0, "val_loss": 16.849173605442047, "val_acc": 72.0}
{"epoch": 31, "training_loss": 72.30884027481079, "training_acc": 58.0, "val_loss": 15.274854004383087, "val_acc": 52.0}
{"epoch": 32, "training_loss": 62.227471590042114, "training_acc": 72.0, "val_loss": 16.57606214284897, "val_acc": 72.0}
{"epoch": 33, "training_loss": 61.510887145996094, "training_acc": 72.0, "val_loss": 22.056545317173004, "val_acc": 28.0}
{"epoch": 34, "training_loss": 77.02329206466675, "training_acc": 46.0, "val_loss": 19.82233077287674, "val_acc": 72.0}
{"epoch": 35, "training_loss": 77.9118082523346, "training_acc": 72.0, "val_loss": 14.95872586965561, "val_acc": 72.0}
{"epoch": 36, "training_loss": 63.56046223640442, "training_acc": 59.0, "val_loss": 14.830636978149414, "val_acc": 72.0}
{"epoch": 37, "training_loss": 63.27492928504944, "training_acc": 72.0, "val_loss": 15.603537857532501, "val_acc": 72.0}
{"epoch": 38, "training_loss": 58.607825756073, "training_acc": 72.0, "val_loss": 19.241274893283844, "val_acc": 28.0}
{"epoch": 39, "training_loss": 69.00535535812378, "training_acc": 46.0, "val_loss": 18.831774592399597, "val_acc": 72.0}
{"epoch": 40, "training_loss": 71.84504771232605, "training_acc": 72.0, "val_loss": 16.399948298931122, "val_acc": 28.0}
{"epoch": 41, "training_loss": 64.70619583129883, "training_acc": 72.0, "val_loss": 14.824646711349487, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.874717235565186, "training_acc": 72.0, "val_loss": 14.619125425815582, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.63546276092529, "training_acc": 72.0, "val_loss": 18.057556450366974, "val_acc": 28.0}
{"epoch": 44, "training_loss": 68.64825129508972, "training_acc": 42.0, "val_loss": 16.04234278202057, "val_acc": 72.0}
{"epoch": 45, "training_loss": 61.86481833457947, "training_acc": 72.0, "val_loss": 16.583284735679626, "val_acc": 28.0}
{"epoch": 46, "training_loss": 64.33964204788208, "training_acc": 73.0, "val_loss": 19.5991188287735, "val_acc": 72.0}
{"epoch": 47, "training_loss": 80.49539184570312, "training_acc": 72.0, "val_loss": 14.611206948757172, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.759751081466675, "training_acc": 64.0, "val_loss": 15.57304859161377, "val_acc": 28.0}
{"epoch": 49, "training_loss": 70.08344578742981, "training_acc": 72.0, "val_loss": 16.668877005577087, "val_acc": 72.0}
{"epoch": 50, "training_loss": 66.30287837982178, "training_acc": 72.0, "val_loss": 15.881167352199554, "val_acc": 28.0}
{"epoch": 51, "training_loss": 61.57063341140747, "training_acc": 72.0, "val_loss": 17.369505763053894, "val_acc": 72.0}
{"epoch": 52, "training_loss": 64.00110936164856, "training_acc": 72.0, "val_loss": 22.56084382534027, "val_acc": 28.0}
{"epoch": 53, "training_loss": 85.7310860157013, "training_acc": 38.0, "val_loss": 16.242071986198425, "val_acc": 72.0}
{"epoch": 54, "training_loss": 63.60246014595032, "training_acc": 72.0, "val_loss": 15.278297662734985, "val_acc": 44.0}
{"epoch": 55, "training_loss": 59.93067526817322, "training_acc": 72.0, "val_loss": 19.330866634845734, "val_acc": 72.0}
{"epoch": 56, "training_loss": 75.901691198349, "training_acc": 72.0, "val_loss": 15.166899561882019, "val_acc": 56.0}
{"epoch": 57, "training_loss": 71.06791543960571, "training_acc": 52.0, "val_loss": 18.356479704380035, "val_acc": 72.0}
{"epoch": 58, "training_loss": 90.31415748596191, "training_acc": 72.0, "val_loss": 15.592370927333832, "val_acc": 72.0}
{"epoch": 59, "training_loss": 77.28736686706543, "training_acc": 58.0, "val_loss": 15.015897154808044, "val_acc": 64.0}
{"epoch": 60, "training_loss": 86.12315320968628, "training_acc": 72.0, "val_loss": 21.446190774440765, "val_acc": 72.0}
{"epoch": 61, "training_loss": 71.59233021736145, "training_acc": 72.0, "val_loss": 28.66623103618622, "val_acc": 28.0}
{"epoch": 62, "training_loss": 95.30653810501099, "training_acc": 44.0, "val_loss": 23.147448897361755, "val_acc": 72.0}
{"epoch": 63, "training_loss": 86.69405150413513, "training_acc": 72.0, "val_loss": 16.57678931951523, "val_acc": 28.0}
{"epoch": 64, "training_loss": 72.3065710067749, "training_acc": 56.0, "val_loss": 18.433375656604767, "val_acc": 72.0}
{"epoch": 65, "training_loss": 79.52067160606384, "training_acc": 72.0, "val_loss": 15.900927782058716, "val_acc": 72.0}
{"epoch": 66, "training_loss": 65.0981228351593, "training_acc": 60.0, "val_loss": 16.50948077440262, "val_acc": 28.0}
