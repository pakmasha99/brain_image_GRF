"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 193.16936874389648, "training_acc": 50.0, "val_loss": 141.7661428451538, "val_acc": 72.0}
{"epoch": 1, "training_loss": 458.7758913040161, "training_acc": 72.0, "val_loss": 63.80530595779419, "val_acc": 28.0}
{"epoch": 2, "training_loss": 200.92011260986328, "training_acc": 28.0, "val_loss": 45.823097229003906, "val_acc": 72.0}
{"epoch": 3, "training_loss": 225.34007167816162, "training_acc": 72.0, "val_loss": 74.5515525341034, "val_acc": 72.0}
{"epoch": 4, "training_loss": 272.95819568634033, "training_acc": 72.0, "val_loss": 26.475048065185547, "val_acc": 72.0}
{"epoch": 5, "training_loss": 112.69746208190918, "training_acc": 62.0, "val_loss": 51.832592487335205, "val_acc": 28.0}
{"epoch": 6, "training_loss": 150.23531675338745, "training_acc": 46.0, "val_loss": 33.82469415664673, "val_acc": 72.0}
{"epoch": 7, "training_loss": 148.43638610839844, "training_acc": 72.0, "val_loss": 35.477808117866516, "val_acc": 72.0}
{"epoch": 8, "training_loss": 119.20428514480591, "training_acc": 72.0, "val_loss": 31.533366441726685, "val_acc": 28.0}
{"epoch": 9, "training_loss": 117.10531640052795, "training_acc": 28.0, "val_loss": 17.398446798324585, "val_acc": 72.0}
{"epoch": 10, "training_loss": 90.00085544586182, "training_acc": 72.0, "val_loss": 24.64921921491623, "val_acc": 72.0}
{"epoch": 11, "training_loss": 86.65643358230591, "training_acc": 72.0, "val_loss": 24.709029495716095, "val_acc": 28.0}
{"epoch": 12, "training_loss": 88.80003786087036, "training_acc": 28.0, "val_loss": 19.563309848308563, "val_acc": 72.0}
{"epoch": 13, "training_loss": 92.12219333648682, "training_acc": 72.0, "val_loss": 22.81348705291748, "val_acc": 72.0}
{"epoch": 14, "training_loss": 79.35250544548035, "training_acc": 72.0, "val_loss": 26.27348005771637, "val_acc": 28.0}
{"epoch": 15, "training_loss": 90.58817148208618, "training_acc": 44.0, "val_loss": 19.206425547599792, "val_acc": 72.0}
{"epoch": 16, "training_loss": 80.47253680229187, "training_acc": 72.0, "val_loss": 18.440549075603485, "val_acc": 72.0}
{"epoch": 17, "training_loss": 69.3908851146698, "training_acc": 72.0, "val_loss": 20.96923440694809, "val_acc": 28.0}
{"epoch": 18, "training_loss": 72.15995407104492, "training_acc": 48.0, "val_loss": 19.916929304599762, "val_acc": 72.0}
{"epoch": 19, "training_loss": 81.70680928230286, "training_acc": 72.0, "val_loss": 15.391764044761658, "val_acc": 72.0}
{"epoch": 20, "training_loss": 71.99124264717102, "training_acc": 54.0, "val_loss": 16.031362116336823, "val_acc": 28.0}
{"epoch": 21, "training_loss": 70.96617150306702, "training_acc": 72.0, "val_loss": 19.341252744197845, "val_acc": 72.0}
{"epoch": 22, "training_loss": 70.50917482376099, "training_acc": 72.0, "val_loss": 18.675827980041504, "val_acc": 28.0}
{"epoch": 23, "training_loss": 71.20249152183533, "training_acc": 48.0, "val_loss": 18.722301721572876, "val_acc": 72.0}
{"epoch": 24, "training_loss": 75.81292653083801, "training_acc": 72.0, "val_loss": 17.836257815361023, "val_acc": 72.0}
{"epoch": 25, "training_loss": 62.01897430419922, "training_acc": 72.0, "val_loss": 23.906615376472473, "val_acc": 28.0}
{"epoch": 26, "training_loss": 92.99293494224548, "training_acc": 34.0, "val_loss": 16.40620231628418, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.825615882873535, "training_acc": 72.0, "val_loss": 16.398273408412933, "val_acc": 28.0}
{"epoch": 28, "training_loss": 69.63816595077515, "training_acc": 48.0, "val_loss": 18.225659430027008, "val_acc": 72.0}
{"epoch": 29, "training_loss": 76.87900471687317, "training_acc": 72.0, "val_loss": 18.13993752002716, "val_acc": 72.0}
{"epoch": 30, "training_loss": 66.65769124031067, "training_acc": 72.0, "val_loss": 21.063104271888733, "val_acc": 28.0}
{"epoch": 31, "training_loss": 70.13689494132996, "training_acc": 50.0, "val_loss": 21.82854562997818, "val_acc": 72.0}
{"epoch": 32, "training_loss": 91.08193254470825, "training_acc": 72.0, "val_loss": 15.083029866218567, "val_acc": 72.0}
{"epoch": 33, "training_loss": 107.12129068374634, "training_acc": 44.0, "val_loss": 14.713163673877716, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.829118728637695, "training_acc": 72.0, "val_loss": 27.872532606124878, "val_acc": 72.0}
{"epoch": 35, "training_loss": 101.53305387496948, "training_acc": 72.0, "val_loss": 15.694564580917358, "val_acc": 28.0}
{"epoch": 36, "training_loss": 73.36352109909058, "training_acc": 60.0, "val_loss": 14.827357232570648, "val_acc": 72.0}
{"epoch": 37, "training_loss": 74.3994779586792, "training_acc": 72.0, "val_loss": 20.218613743782043, "val_acc": 72.0}
{"epoch": 38, "training_loss": 70.09210324287415, "training_acc": 72.0, "val_loss": 22.985897958278656, "val_acc": 28.0}
{"epoch": 39, "training_loss": 81.00285363197327, "training_acc": 42.0, "val_loss": 18.191945552825928, "val_acc": 72.0}
{"epoch": 40, "training_loss": 74.43421125411987, "training_acc": 72.0, "val_loss": 14.793796837329865, "val_acc": 72.0}
{"epoch": 41, "training_loss": 68.23810315132141, "training_acc": 56.0, "val_loss": 14.6925687789917, "val_acc": 72.0}
{"epoch": 42, "training_loss": 57.76964569091797, "training_acc": 72.0, "val_loss": 18.84496957063675, "val_acc": 72.0}
{"epoch": 43, "training_loss": 67.10474419593811, "training_acc": 72.0, "val_loss": 20.008304715156555, "val_acc": 28.0}
{"epoch": 44, "training_loss": 73.77614331245422, "training_acc": 48.0, "val_loss": 19.463519752025604, "val_acc": 72.0}
{"epoch": 45, "training_loss": 78.37511420249939, "training_acc": 72.0, "val_loss": 17.070545256137848, "val_acc": 72.0}
{"epoch": 46, "training_loss": 78.25385761260986, "training_acc": 50.0, "val_loss": 15.124966204166412, "val_acc": 68.0}
{"epoch": 47, "training_loss": 64.6927604675293, "training_acc": 72.0, "val_loss": 17.748266458511353, "val_acc": 72.0}
{"epoch": 48, "training_loss": 65.15416407585144, "training_acc": 72.0, "val_loss": 18.026958405971527, "val_acc": 28.0}
{"epoch": 49, "training_loss": 66.25110101699829, "training_acc": 48.0, "val_loss": 17.17413365840912, "val_acc": 72.0}
{"epoch": 50, "training_loss": 65.2165379524231, "training_acc": 72.0, "val_loss": 15.312124788761139, "val_acc": 48.0}
{"epoch": 51, "training_loss": 60.107996702194214, "training_acc": 72.0, "val_loss": 14.670532941818237, "val_acc": 72.0}
{"epoch": 52, "training_loss": 57.906705379486084, "training_acc": 72.0, "val_loss": 14.877958595752716, "val_acc": 72.0}
{"epoch": 53, "training_loss": 57.093376874923706, "training_acc": 72.0, "val_loss": 15.875017642974854, "val_acc": 28.0}
{"epoch": 54, "training_loss": 65.91100478172302, "training_acc": 72.0, "val_loss": 14.658194780349731, "val_acc": 72.0}
{"epoch": 55, "training_loss": 60.48455357551575, "training_acc": 72.0, "val_loss": 15.282918512821198, "val_acc": 72.0}
{"epoch": 56, "training_loss": 60.68326735496521, "training_acc": 72.0, "val_loss": 14.678309857845306, "val_acc": 72.0}
{"epoch": 57, "training_loss": 60.9707407951355, "training_acc": 74.0, "val_loss": 14.758558571338654, "val_acc": 72.0}
{"epoch": 58, "training_loss": 60.82660436630249, "training_acc": 72.0, "val_loss": 14.799347519874573, "val_acc": 72.0}
{"epoch": 59, "training_loss": 64.57111096382141, "training_acc": 58.0, "val_loss": 14.972734451293945, "val_acc": 72.0}
{"epoch": 60, "training_loss": 58.80231976509094, "training_acc": 72.0, "val_loss": 15.612022578716278, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.92971086502075, "training_acc": 72.0, "val_loss": 15.450985729694366, "val_acc": 40.0}
{"epoch": 62, "training_loss": 60.939815521240234, "training_acc": 72.0, "val_loss": 15.400373935699463, "val_acc": 72.0}
{"epoch": 63, "training_loss": 61.78478670120239, "training_acc": 72.0, "val_loss": 14.647457003593445, "val_acc": 72.0}
{"epoch": 64, "training_loss": 58.460713386535645, "training_acc": 72.0, "val_loss": 14.646494388580322, "val_acc": 72.0}
{"epoch": 65, "training_loss": 56.55389404296875, "training_acc": 72.0, "val_loss": 15.168219804763794, "val_acc": 56.0}
{"epoch": 66, "training_loss": 59.49154591560364, "training_acc": 72.0, "val_loss": 14.979539811611176, "val_acc": 72.0}
{"epoch": 67, "training_loss": 57.39639186859131, "training_acc": 72.0, "val_loss": 18.01910698413849, "val_acc": 28.0}
{"epoch": 68, "training_loss": 64.71141910552979, "training_acc": 58.0, "val_loss": 19.350457191467285, "val_acc": 72.0}
{"epoch": 69, "training_loss": 76.39857077598572, "training_acc": 72.0, "val_loss": 15.0511234998703, "val_acc": 68.0}
{"epoch": 70, "training_loss": 68.11134076118469, "training_acc": 56.0, "val_loss": 15.826398134231567, "val_acc": 72.0}
{"epoch": 71, "training_loss": 63.45716905593872, "training_acc": 72.0, "val_loss": 16.45953357219696, "val_acc": 72.0}
{"epoch": 72, "training_loss": 61.522895097732544, "training_acc": 73.0, "val_loss": 16.658854484558105, "val_acc": 28.0}
{"epoch": 73, "training_loss": 66.84868550300598, "training_acc": 69.0, "val_loss": 17.059199512004852, "val_acc": 72.0}
{"epoch": 74, "training_loss": 62.392857789993286, "training_acc": 72.0, "val_loss": 17.11525321006775, "val_acc": 28.0}
{"epoch": 75, "training_loss": 73.51614832878113, "training_acc": 59.0, "val_loss": 15.112194418907166, "val_acc": 72.0}
{"epoch": 76, "training_loss": 57.75376534461975, "training_acc": 72.0, "val_loss": 15.215583145618439, "val_acc": 56.0}
{"epoch": 77, "training_loss": 65.72544598579407, "training_acc": 72.0, "val_loss": 14.844949543476105, "val_acc": 72.0}
{"epoch": 78, "training_loss": 72.06580567359924, "training_acc": 48.0, "val_loss": 17.249388992786407, "val_acc": 72.0}
{"epoch": 79, "training_loss": 75.77983856201172, "training_acc": 72.0, "val_loss": 15.37666916847229, "val_acc": 72.0}
{"epoch": 80, "training_loss": 79.48892974853516, "training_acc": 52.0, "val_loss": 14.81994241476059, "val_acc": 72.0}
{"epoch": 81, "training_loss": 63.156968116760254, "training_acc": 72.0, "val_loss": 18.99561583995819, "val_acc": 72.0}
{"epoch": 82, "training_loss": 70.86384868621826, "training_acc": 73.0, "val_loss": 17.196397483348846, "val_acc": 28.0}
{"epoch": 83, "training_loss": 74.00689244270325, "training_acc": 61.0, "val_loss": 16.652148962020874, "val_acc": 72.0}
