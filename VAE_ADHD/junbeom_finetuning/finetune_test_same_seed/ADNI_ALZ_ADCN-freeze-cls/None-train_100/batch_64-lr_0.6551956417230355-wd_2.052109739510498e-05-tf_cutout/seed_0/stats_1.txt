"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3124.1734619140625, "training_acc": 72.0, "val_loss": 1577.8456687927246, "val_acc": 72.0}
{"epoch": 1, "training_loss": 4562.598342895508, "training_acc": 72.0, "val_loss": 1518.293285369873, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5655.644515991211, "training_acc": 28.0, "val_loss": 249.13091659545898, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1420.2078018188477, "training_acc": 72.0, "val_loss": 766.4499282836914, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2953.4912033081055, "training_acc": 72.0, "val_loss": 407.6315402984619, "val_acc": 72.0}
{"epoch": 5, "training_loss": 924.7688851356506, "training_acc": 72.0, "val_loss": 1388.2478713989258, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5600.745880126953, "training_acc": 28.0, "val_loss": 416.6175842285156, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1934.2569961547852, "training_acc": 42.0, "val_loss": 1009.5020294189453, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4669.304595947266, "training_acc": 72.0, "val_loss": 1405.045986175537, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5532.371078491211, "training_acc": 72.0, "val_loss": 1138.1247520446777, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4124.939125061035, "training_acc": 72.0, "val_loss": 372.8379726409912, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1749.5101699829102, "training_acc": 52.0, "val_loss": 674.4029521942139, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1821.8966069221497, "training_acc": 41.0, "val_loss": 296.651291847229, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1416.7131805419922, "training_acc": 72.0, "val_loss": 430.4128170013428, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1506.1442337036133, "training_acc": 72.0, "val_loss": 32.19244182109833, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1431.84033203125, "training_acc": 54.0, "val_loss": 868.3703422546387, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2213.1942205429077, "training_acc": 28.0, "val_loss": 571.7370986938477, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2504.721866607666, "training_acc": 72.0, "val_loss": 1238.1508827209473, "val_acc": 72.0}
{"epoch": 18, "training_loss": 5159.5269775390625, "training_acc": 72.0, "val_loss": 1382.4138641357422, "val_acc": 72.0}
{"epoch": 19, "training_loss": 5381.116989135742, "training_acc": 72.0, "val_loss": 1023.2389450073242, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3627.3010330200195, "training_acc": 72.0, "val_loss": 269.2739725112915, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1898.5250778198242, "training_acc": 50.0, "val_loss": 956.1574935913086, "val_acc": 28.0}
{"epoch": 22, "training_loss": 3011.643669128418, "training_acc": 28.0, "val_loss": 344.0471410751343, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1861.7209243774414, "training_acc": 72.0, "val_loss": 867.1881675720215, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3482.33992767334, "training_acc": 72.0, "val_loss": 828.2991409301758, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3075.3553771972656, "training_acc": 72.0, "val_loss": 382.369065284729, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1127.2027633190155, "training_acc": 52.0, "val_loss": 413.049840927124, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1019.7426652908325, "training_acc": 28.0, "val_loss": 444.68517303466797, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2156.4630737304688, "training_acc": 72.0, "val_loss": 889.5813941955566, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3587.334182739258, "training_acc": 72.0, "val_loss": 797.4912166595459, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2925.557289123535, "training_acc": 72.0, "val_loss": 248.62444400787354, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1063.5015983581543, "training_acc": 60.0, "val_loss": 514.957332611084, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1453.462529182434, "training_acc": 42.0, "val_loss": 180.00398874282837, "val_acc": 72.0}
{"epoch": 33, "training_loss": 697.4949684143066, "training_acc": 72.0, "val_loss": 15.927794575691223, "val_acc": 72.0}
{"epoch": 34, "training_loss": 834.6298141479492, "training_acc": 54.0, "val_loss": 181.40888214111328, "val_acc": 28.0}
{"epoch": 35, "training_loss": 978.2405204772949, "training_acc": 44.0, "val_loss": 627.245044708252, "val_acc": 72.0}
{"epoch": 36, "training_loss": 2659.952911376953, "training_acc": 72.0, "val_loss": 732.3572158813477, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2757.76513671875, "training_acc": 72.0, "val_loss": 358.1812620162964, "val_acc": 72.0}
{"epoch": 38, "training_loss": 997.0791358947754, "training_acc": 72.0, "val_loss": 920.7431793212891, "val_acc": 28.0}
{"epoch": 39, "training_loss": 3659.7277755737305, "training_acc": 28.0, "val_loss": 163.76547813415527, "val_acc": 28.0}
{"epoch": 40, "training_loss": 1045.7767181396484, "training_acc": 46.0, "val_loss": 893.382453918457, "val_acc": 72.0}
{"epoch": 41, "training_loss": 3834.2894592285156, "training_acc": 72.0, "val_loss": 1220.0027465820312, "val_acc": 72.0}
{"epoch": 42, "training_loss": 4837.294021606445, "training_acc": 72.0, "val_loss": 1036.1320495605469, "val_acc": 72.0}
{"epoch": 43, "training_loss": 3828.7201919555664, "training_acc": 72.0, "val_loss": 444.81334686279297, "val_acc": 72.0}
{"epoch": 44, "training_loss": 1229.0144138336182, "training_acc": 72.0, "val_loss": 1009.0994834899902, "val_acc": 28.0}
{"epoch": 45, "training_loss": 4140.509750366211, "training_acc": 28.0, "val_loss": 358.79032611846924, "val_acc": 28.0}
{"epoch": 46, "training_loss": 1707.2207641601562, "training_acc": 40.0, "val_loss": 812.5269889831543, "val_acc": 72.0}
{"epoch": 47, "training_loss": 3565.2840118408203, "training_acc": 72.0, "val_loss": 1100.7492065429688, "val_acc": 72.0}
{"epoch": 48, "training_loss": 4326.740707397461, "training_acc": 72.0, "val_loss": 864.1317367553711, "val_acc": 72.0}
{"epoch": 49, "training_loss": 2971.8170318603516, "training_acc": 72.0, "val_loss": 199.23648834228516, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1966.0769500732422, "training_acc": 48.0, "val_loss": 1030.1709175109863, "val_acc": 28.0}
{"epoch": 51, "training_loss": 3252.275577545166, "training_acc": 28.0, "val_loss": 358.00492763519287, "val_acc": 72.0}
{"epoch": 52, "training_loss": 1711.9701919555664, "training_acc": 72.0, "val_loss": 891.2592887878418, "val_acc": 72.0}
