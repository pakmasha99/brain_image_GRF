"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3971.541473388672, "training_acc": 36.0, "val_loss": 1668.8470840454102, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5306.4140625, "training_acc": 72.0, "val_loss": 502.7298927307129, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1445.9562816619873, "training_acc": 28.0, "val_loss": 661.3645076751709, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3100.115249633789, "training_acc": 72.0, "val_loss": 1129.5479774475098, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4358.679168701172, "training_acc": 72.0, "val_loss": 724.1713523864746, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2147.6338653564453, "training_acc": 72.0, "val_loss": 821.1898803710938, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3564.217498779297, "training_acc": 28.0, "val_loss": 50.74891448020935, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1137.1801528930664, "training_acc": 42.0, "val_loss": 1072.7375030517578, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4903.720275878906, "training_acc": 72.0, "val_loss": 1403.605079650879, "val_acc": 72.0}
{"epoch": 9, "training_loss": 5477.753112792969, "training_acc": 72.0, "val_loss": 1067.5460815429688, "val_acc": 72.0}
{"epoch": 10, "training_loss": 3822.6495208740234, "training_acc": 72.0, "val_loss": 281.6932201385498, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1677.6618041992188, "training_acc": 56.0, "val_loss": 950.5788803100586, "val_acc": 28.0}
{"epoch": 12, "training_loss": 2907.228485107422, "training_acc": 28.0, "val_loss": 387.3039484024048, "val_acc": 72.0}
{"epoch": 13, "training_loss": 1896.2675094604492, "training_acc": 72.0, "val_loss": 965.943431854248, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3955.0374298095703, "training_acc": 72.0, "val_loss": 992.4440383911133, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3796.5482864379883, "training_acc": 72.0, "val_loss": 535.405683517456, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1620.5249519348145, "training_acc": 72.0, "val_loss": 735.5239868164062, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3152.9664306640625, "training_acc": 28.0, "val_loss": 272.48876094818115, "val_acc": 28.0}
{"epoch": 18, "training_loss": 1291.1987228393555, "training_acc": 44.0, "val_loss": 769.9657917022705, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3438.4068450927734, "training_acc": 72.0, "val_loss": 1023.8875389099121, "val_acc": 72.0}
{"epoch": 20, "training_loss": 3976.7154083251953, "training_acc": 72.0, "val_loss": 740.5763149261475, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2567.0384941101074, "training_acc": 72.0, "val_loss": 38.44851553440094, "val_acc": 28.0}
{"epoch": 22, "training_loss": 517.8609733581543, "training_acc": 28.0, "val_loss": 115.43232202529907, "val_acc": 72.0}
{"epoch": 23, "training_loss": 558.5728034973145, "training_acc": 72.0, "val_loss": 150.70912837982178, "val_acc": 72.0}
{"epoch": 24, "training_loss": 527.7562704086304, "training_acc": 52.0, "val_loss": 145.5222487449646, "val_acc": 72.0}
{"epoch": 25, "training_loss": 574.575198173523, "training_acc": 72.0, "val_loss": 78.0684769153595, "val_acc": 72.0}
{"epoch": 26, "training_loss": 511.98551177978516, "training_acc": 58.0, "val_loss": 60.90885400772095, "val_acc": 72.0}
{"epoch": 27, "training_loss": 275.7838935852051, "training_acc": 72.0, "val_loss": 81.24844431877136, "val_acc": 28.0}
{"epoch": 28, "training_loss": 537.0857582092285, "training_acc": 40.0, "val_loss": 239.66567516326904, "val_acc": 72.0}
{"epoch": 29, "training_loss": 848.1252613067627, "training_acc": 72.0, "val_loss": 66.78733825683594, "val_acc": 28.0}
{"epoch": 30, "training_loss": 354.492883682251, "training_acc": 42.0, "val_loss": 106.31178617477417, "val_acc": 72.0}
{"epoch": 31, "training_loss": 234.22624969482422, "training_acc": 73.0, "val_loss": 260.7184648513794, "val_acc": 28.0}
{"epoch": 32, "training_loss": 964.6294193267822, "training_acc": 38.0, "val_loss": 194.9235200881958, "val_acc": 72.0}
{"epoch": 33, "training_loss": 677.2736892700195, "training_acc": 72.0, "val_loss": 160.73304414749146, "val_acc": 28.0}
{"epoch": 34, "training_loss": 454.68254804611206, "training_acc": 50.0, "val_loss": 102.98782587051392, "val_acc": 72.0}
{"epoch": 35, "training_loss": 299.17305850982666, "training_acc": 72.0, "val_loss": 67.15582609176636, "val_acc": 28.0}
{"epoch": 36, "training_loss": 690.7147827148438, "training_acc": 38.0, "val_loss": 382.8502655029297, "val_acc": 72.0}
{"epoch": 37, "training_loss": 1488.5953102111816, "training_acc": 72.0, "val_loss": 212.62335777282715, "val_acc": 72.0}
{"epoch": 38, "training_loss": 807.0612182617188, "training_acc": 52.0, "val_loss": 54.17305827140808, "val_acc": 72.0}
{"epoch": 39, "training_loss": 177.9935041666031, "training_acc": 72.0, "val_loss": 15.388333797454834, "val_acc": 44.0}
{"epoch": 40, "training_loss": 141.16955280303955, "training_acc": 71.0, "val_loss": 39.44934010505676, "val_acc": 72.0}
{"epoch": 41, "training_loss": 454.43071365356445, "training_acc": 60.0, "val_loss": 58.68169069290161, "val_acc": 72.0}
{"epoch": 42, "training_loss": 281.8673896789551, "training_acc": 72.0, "val_loss": 44.523462653160095, "val_acc": 28.0}
{"epoch": 43, "training_loss": 231.68151569366455, "training_acc": 52.0, "val_loss": 215.979266166687, "val_acc": 72.0}
{"epoch": 44, "training_loss": 775.2896003723145, "training_acc": 72.0, "val_loss": 68.82785558700562, "val_acc": 28.0}
{"epoch": 45, "training_loss": 364.7224311828613, "training_acc": 44.0, "val_loss": 154.61344718933105, "val_acc": 72.0}
{"epoch": 46, "training_loss": 456.17706298828125, "training_acc": 72.0, "val_loss": 437.8726005554199, "val_acc": 28.0}
{"epoch": 47, "training_loss": 1390.3622589111328, "training_acc": 28.0, "val_loss": 339.32368755340576, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1860.6820449829102, "training_acc": 72.0, "val_loss": 696.6521263122559, "val_acc": 72.0}
{"epoch": 49, "training_loss": 2710.44034576416, "training_acc": 72.0, "val_loss": 476.1394500732422, "val_acc": 72.0}
{"epoch": 50, "training_loss": 1481.1535758972168, "training_acc": 72.0, "val_loss": 433.35118293762207, "val_acc": 28.0}
{"epoch": 51, "training_loss": 1746.4424209594727, "training_acc": 28.0, "val_loss": 120.69414854049683, "val_acc": 72.0}
{"epoch": 52, "training_loss": 711.4419708251953, "training_acc": 72.0, "val_loss": 264.25840854644775, "val_acc": 72.0}
{"epoch": 53, "training_loss": 890.0576448440552, "training_acc": 72.0, "val_loss": 272.843337059021, "val_acc": 28.0}
{"epoch": 54, "training_loss": 791.4331040382385, "training_acc": 38.0, "val_loss": 15.118667483329773, "val_acc": 56.0}
{"epoch": 55, "training_loss": 88.77379655838013, "training_acc": 78.0, "val_loss": 13.898462057113647, "val_acc": 72.0}
{"epoch": 56, "training_loss": 380.95348358154297, "training_acc": 50.0, "val_loss": 189.9942398071289, "val_acc": 72.0}
{"epoch": 57, "training_loss": 905.5641555786133, "training_acc": 72.0, "val_loss": 297.94676303863525, "val_acc": 72.0}
{"epoch": 58, "training_loss": 988.8306331634521, "training_acc": 72.0, "val_loss": 200.69081783294678, "val_acc": 28.0}
{"epoch": 59, "training_loss": 565.8390243053436, "training_acc": 42.0, "val_loss": 19.61730122566223, "val_acc": 28.0}
{"epoch": 60, "training_loss": 254.47388458251953, "training_acc": 51.0, "val_loss": 117.34887361526489, "val_acc": 72.0}
{"epoch": 61, "training_loss": 270.5003807544708, "training_acc": 75.0, "val_loss": 139.24572467803955, "val_acc": 28.0}
{"epoch": 62, "training_loss": 716.9573707580566, "training_acc": 42.0, "val_loss": 337.3380422592163, "val_acc": 72.0}
{"epoch": 63, "training_loss": 1312.29146194458, "training_acc": 72.0, "val_loss": 165.9977674484253, "val_acc": 72.0}
{"epoch": 64, "training_loss": 893.1152534484863, "training_acc": 52.0, "val_loss": 16.610249876976013, "val_acc": 44.0}
{"epoch": 65, "training_loss": 372.7317008972168, "training_acc": 60.0, "val_loss": 312.78703212738037, "val_acc": 72.0}
{"epoch": 66, "training_loss": 1179.0005283355713, "training_acc": 72.0, "val_loss": 84.59660410881042, "val_acc": 72.0}
{"epoch": 67, "training_loss": 1055.932388305664, "training_acc": 50.0, "val_loss": 213.88494968414307, "val_acc": 28.0}
{"epoch": 68, "training_loss": 1093.7704963684082, "training_acc": 42.0, "val_loss": 590.8637046813965, "val_acc": 72.0}
{"epoch": 69, "training_loss": 2551.0995483398438, "training_acc": 72.0, "val_loss": 654.3688297271729, "val_acc": 72.0}
{"epoch": 70, "training_loss": 2369.266212463379, "training_acc": 72.0, "val_loss": 202.85813808441162, "val_acc": 72.0}
{"epoch": 71, "training_loss": 1245.7817459106445, "training_acc": 54.0, "val_loss": 485.04300117492676, "val_acc": 28.0}
{"epoch": 72, "training_loss": 1468.087984085083, "training_acc": 42.0, "val_loss": 281.33068084716797, "val_acc": 72.0}
{"epoch": 73, "training_loss": 1137.142375946045, "training_acc": 72.0, "val_loss": 178.06352376937866, "val_acc": 72.0}
{"epoch": 74, "training_loss": 696.5254898071289, "training_acc": 54.0, "val_loss": 64.35892581939697, "val_acc": 72.0}
