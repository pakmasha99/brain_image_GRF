"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2858.456817626953, "training_acc": 44.0, "val_loss": 1690.5878067016602, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5410.544227600098, "training_acc": 72.0, "val_loss": 1303.1439781188965, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4388.7160720825195, "training_acc": 28.0, "val_loss": 512.6679420471191, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2607.337692260742, "training_acc": 72.0, "val_loss": 1121.6911315917969, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4406.615924835205, "training_acc": 72.0, "val_loss": 784.6810340881348, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2554.3096466064453, "training_acc": 72.0, "val_loss": 324.1903305053711, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1225.5275115966797, "training_acc": 28.0, "val_loss": 317.2792673110962, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1540.1495742797852, "training_acc": 72.0, "val_loss": 579.8303604125977, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2157.005485534668, "training_acc": 72.0, "val_loss": 216.82770252227783, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1192.7543640136719, "training_acc": 56.0, "val_loss": 323.95009994506836, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1339.0566673278809, "training_acc": 40.0, "val_loss": 478.053617477417, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1921.8277778625488, "training_acc": 72.0, "val_loss": 422.34654426574707, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1400.7491989135742, "training_acc": 72.0, "val_loss": 246.83842658996582, "val_acc": 28.0}
{"epoch": 13, "training_loss": 833.3944072723389, "training_acc": 28.0, "val_loss": 348.42517375946045, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1880.6649169921875, "training_acc": 72.0, "val_loss": 684.6370697021484, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2644.3894653320312, "training_acc": 72.0, "val_loss": 433.34898948669434, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1311.340690612793, "training_acc": 72.0, "val_loss": 658.8542461395264, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2708.3436279296875, "training_acc": 28.0, "val_loss": 28.10451090335846, "val_acc": 72.0}
{"epoch": 18, "training_loss": 404.05384826660156, "training_acc": 72.0, "val_loss": 204.66468334197998, "val_acc": 72.0}
{"epoch": 19, "training_loss": 635.1322679519653, "training_acc": 72.0, "val_loss": 393.43838691711426, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1182.5404644012451, "training_acc": 28.0, "val_loss": 359.4163656234741, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1699.8397521972656, "training_acc": 72.0, "val_loss": 703.6874771118164, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2772.0710372924805, "training_acc": 72.0, "val_loss": 534.0871334075928, "val_acc": 72.0}
{"epoch": 23, "training_loss": 1702.7603149414062, "training_acc": 72.0, "val_loss": 177.09418535232544, "val_acc": 28.0}
{"epoch": 24, "training_loss": 909.3404083251953, "training_acc": 28.0, "val_loss": 218.98674964904785, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1063.0765533447266, "training_acc": 72.0, "val_loss": 438.05131912231445, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1646.1532592773438, "training_acc": 72.0, "val_loss": 167.8751826286316, "val_acc": 72.0}
{"epoch": 27, "training_loss": 942.4226875305176, "training_acc": 54.0, "val_loss": 149.79256391525269, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1023.3294448852539, "training_acc": 38.0, "val_loss": 526.3044357299805, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2109.3925819396973, "training_acc": 72.0, "val_loss": 504.74514961242676, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1780.805103302002, "training_acc": 72.0, "val_loss": 86.04387640953064, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1763.5731964111328, "training_acc": 44.0, "val_loss": 762.9313945770264, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2051.1238489151, "training_acc": 42.0, "val_loss": 211.324143409729, "val_acc": 72.0}
{"epoch": 33, "training_loss": 894.2498779296875, "training_acc": 72.0, "val_loss": 160.71027517318726, "val_acc": 72.0}
{"epoch": 34, "training_loss": 609.9389305114746, "training_acc": 54.0, "val_loss": 89.6641194820404, "val_acc": 72.0}
{"epoch": 35, "training_loss": 432.24242210388184, "training_acc": 72.0, "val_loss": 52.15047597885132, "val_acc": 28.0}
{"epoch": 36, "training_loss": 386.84425163269043, "training_acc": 40.0, "val_loss": 151.92474126815796, "val_acc": 72.0}
