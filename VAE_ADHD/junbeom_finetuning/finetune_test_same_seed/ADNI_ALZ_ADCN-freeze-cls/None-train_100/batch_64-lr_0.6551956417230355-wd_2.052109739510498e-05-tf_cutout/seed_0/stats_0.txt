"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3130.5849609375, "training_acc": 42.0, "val_loss": 1689.9221420288086, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5307.258041381836, "training_acc": 72.0, "val_loss": 983.3447456359863, "val_acc": 28.0}
{"epoch": 2, "training_loss": 3354.1399002075195, "training_acc": 28.0, "val_loss": 536.8837833404541, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2767.8553619384766, "training_acc": 72.0, "val_loss": 1131.255054473877, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4429.40592956543, "training_acc": 72.0, "val_loss": 799.2861270904541, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2788.6934852600098, "training_acc": 72.0, "val_loss": 547.45774269104, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2156.1107177734375, "training_acc": 28.0, "val_loss": 205.38442134857178, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1004.0670967102051, "training_acc": 72.0, "val_loss": 447.73106575012207, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1643.6768379211426, "training_acc": 72.0, "val_loss": 105.74754476547241, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1533.9638671875, "training_acc": 50.0, "val_loss": 575.9893894195557, "val_acc": 28.0}
{"epoch": 10, "training_loss": 1725.949562072754, "training_acc": 44.0, "val_loss": 406.4353942871094, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1728.3104553222656, "training_acc": 72.0, "val_loss": 412.46910095214844, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1386.3095169067383, "training_acc": 72.0, "val_loss": 243.3164358139038, "val_acc": 28.0}
{"epoch": 13, "training_loss": 797.8395481109619, "training_acc": 28.0, "val_loss": 353.92210483551025, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1854.26318359375, "training_acc": 72.0, "val_loss": 693.0237770080566, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2701.9731521606445, "training_acc": 72.0, "val_loss": 466.4562702178955, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1375.7784156799316, "training_acc": 72.0, "val_loss": 583.9513301849365, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2583.8479766845703, "training_acc": 28.0, "val_loss": 16.343016922473907, "val_acc": 72.0}
{"epoch": 18, "training_loss": 474.9600257873535, "training_acc": 72.0, "val_loss": 280.1561117172241, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1010.876371383667, "training_acc": 72.0, "val_loss": 28.95892560482025, "val_acc": 28.0}
{"epoch": 20, "training_loss": 136.70373439788818, "training_acc": 46.0, "val_loss": 23.831281065940857, "val_acc": 28.0}
{"epoch": 21, "training_loss": 366.94533920288086, "training_acc": 38.0, "val_loss": 153.3765196800232, "val_acc": 72.0}
{"epoch": 22, "training_loss": 420.87789607048035, "training_acc": 72.0, "val_loss": 514.9835586547852, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1609.6068534851074, "training_acc": 28.0, "val_loss": 348.6255407333374, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1772.992416381836, "training_acc": 72.0, "val_loss": 735.8224868774414, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2923.7099990844727, "training_acc": 72.0, "val_loss": 580.5046081542969, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1977.9186897277832, "training_acc": 72.0, "val_loss": 89.85241651535034, "val_acc": 28.0}
{"epoch": 27, "training_loss": 350.8969211578369, "training_acc": 28.0, "val_loss": 283.46447944641113, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1329.3729820251465, "training_acc": 72.0, "val_loss": 467.7813529968262, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1726.3275260925293, "training_acc": 72.0, "val_loss": 155.69387674331665, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1223.5346603393555, "training_acc": 50.0, "val_loss": 327.4042844772339, "val_acc": 28.0}
{"epoch": 31, "training_loss": 1426.512092590332, "training_acc": 36.0, "val_loss": 437.4242305755615, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1775.3738899230957, "training_acc": 72.0, "val_loss": 390.97704887390137, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1326.6709995269775, "training_acc": 72.0, "val_loss": 237.7323865890503, "val_acc": 28.0}
{"epoch": 34, "training_loss": 702.4286532402039, "training_acc": 28.0, "val_loss": 302.1991014480591, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1442.6027145385742, "training_acc": 72.0, "val_loss": 499.16348457336426, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1858.261661529541, "training_acc": 72.0, "val_loss": 190.95302820205688, "val_acc": 72.0}
