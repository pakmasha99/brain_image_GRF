"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 3404.2554206848145, "training_acc": 73.0, "val_loss": 1573.3400344848633, "val_acc": 72.0}
{"epoch": 1, "training_loss": 5041.857040405273, "training_acc": 72.0, "val_loss": 1580.3215026855469, "val_acc": 28.0}
{"epoch": 2, "training_loss": 5544.314498901367, "training_acc": 28.0, "val_loss": 366.58973693847656, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1978.0741577148438, "training_acc": 72.0, "val_loss": 912.0336532592773, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3518.48681640625, "training_acc": 72.0, "val_loss": 539.9497032165527, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1677.2634749412537, "training_acc": 72.0, "val_loss": 1297.208023071289, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5155.324508666992, "training_acc": 28.0, "val_loss": 241.30046367645264, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1279.4910583496094, "training_acc": 48.0, "val_loss": 1114.356803894043, "val_acc": 72.0}
{"epoch": 8, "training_loss": 4895.642181396484, "training_acc": 72.0, "val_loss": 1558.3369255065918, "val_acc": 72.0}
{"epoch": 9, "training_loss": 6179.228622436523, "training_acc": 72.0, "val_loss": 1360.142993927002, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5056.233474731445, "training_acc": 72.0, "val_loss": 669.1043376922607, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2144.0336923599243, "training_acc": 72.0, "val_loss": 1126.841163635254, "val_acc": 28.0}
{"epoch": 12, "training_loss": 5177.054443359375, "training_acc": 28.0, "val_loss": 909.7878456115723, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2593.8055381774902, "training_acc": 44.0, "val_loss": 551.7045974731445, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2565.633514404297, "training_acc": 72.0, "val_loss": 802.0282745361328, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3066.1186752319336, "training_acc": 72.0, "val_loss": 484.28616523742676, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1542.5033321380615, "training_acc": 72.0, "val_loss": 691.0818099975586, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2906.9761657714844, "training_acc": 28.0, "val_loss": 17.620576918125153, "val_acc": 32.0}
{"epoch": 18, "training_loss": 543.6380043029785, "training_acc": 59.0, "val_loss": 631.1534404754639, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2693.6270751953125, "training_acc": 72.0, "val_loss": 674.7546195983887, "val_acc": 72.0}
{"epoch": 20, "training_loss": 2426.1845321655273, "training_acc": 72.0, "val_loss": 193.75008344650269, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1256.2727737426758, "training_acc": 56.0, "val_loss": 582.7856540679932, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1597.5387620925903, "training_acc": 44.0, "val_loss": 226.35271549224854, "val_acc": 72.0}
{"epoch": 23, "training_loss": 933.9481773376465, "training_acc": 72.0, "val_loss": 116.71018600463867, "val_acc": 72.0}
{"epoch": 24, "training_loss": 665.9066047668457, "training_acc": 60.0, "val_loss": 59.24457311630249, "val_acc": 28.0}
{"epoch": 25, "training_loss": 728.9847869873047, "training_acc": 42.0, "val_loss": 588.973331451416, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2382.4264030456543, "training_acc": 72.0, "val_loss": 597.0555782318115, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2109.1301498413086, "training_acc": 72.0, "val_loss": 170.2524185180664, "val_acc": 72.0}
{"epoch": 28, "training_loss": 1288.5746459960938, "training_acc": 56.0, "val_loss": 671.6478824615479, "val_acc": 28.0}
{"epoch": 29, "training_loss": 1758.011109828949, "training_acc": 44.0, "val_loss": 176.74560546875, "val_acc": 72.0}
{"epoch": 30, "training_loss": 686.3878421783447, "training_acc": 72.0, "val_loss": 63.480669260025024, "val_acc": 72.0}
{"epoch": 31, "training_loss": 634.4350166320801, "training_acc": 60.0, "val_loss": 83.30544829368591, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1037.531234741211, "training_acc": 36.0, "val_loss": 630.7878971099854, "val_acc": 72.0}
{"epoch": 33, "training_loss": 2642.5034103393555, "training_acc": 72.0, "val_loss": 657.3326110839844, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2321.309371948242, "training_acc": 72.0, "val_loss": 194.4102168083191, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1179.974983215332, "training_acc": 58.0, "val_loss": 621.2398529052734, "val_acc": 28.0}
{"epoch": 36, "training_loss": 1845.4302978515625, "training_acc": 36.0, "val_loss": 167.59896278381348, "val_acc": 72.0}
