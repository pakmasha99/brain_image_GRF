"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 37683.95275878906, "training_acc": 50.0, "val_loss": 33626.37023925781, "val_acc": 72.0}
{"epoch": 1, "training_loss": 116503.41198730469, "training_acc": 72.0, "val_loss": 29072.564697265625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 92801.99487304688, "training_acc": 28.0, "val_loss": 11874.282836914062, "val_acc": 72.0}
{"epoch": 3, "training_loss": 73472.2529296875, "training_acc": 72.0, "val_loss": 25753.366088867188, "val_acc": 72.0}
{"epoch": 4, "training_loss": 100214.57153320312, "training_acc": 72.0, "val_loss": 18122.92938232422, "val_acc": 72.0}
{"epoch": 5, "training_loss": 60858.04479980469, "training_acc": 72.0, "val_loss": 5938.847351074219, "val_acc": 28.0}
{"epoch": 6, "training_loss": 26172.297607421875, "training_acc": 28.0, "val_loss": 4666.340255737305, "val_acc": 72.0}
{"epoch": 7, "training_loss": 20229.117095947266, "training_acc": 72.0, "val_loss": 8700.502014160156, "val_acc": 72.0}
{"epoch": 8, "training_loss": 32189.467407226562, "training_acc": 72.0, "val_loss": 2334.3164443969727, "val_acc": 72.0}
{"epoch": 9, "training_loss": 23972.88330078125, "training_acc": 56.0, "val_loss": 9710.722351074219, "val_acc": 28.0}
{"epoch": 10, "training_loss": 29048.06072998047, "training_acc": 46.0, "val_loss": 8145.470428466797, "val_acc": 72.0}
{"epoch": 11, "training_loss": 34919.53564453125, "training_acc": 72.0, "val_loss": 8094.246673583984, "val_acc": 72.0}
{"epoch": 12, "training_loss": 26565.9033203125, "training_acc": 72.0, "val_loss": 5819.908142089844, "val_acc": 28.0}
{"epoch": 13, "training_loss": 18503.154846191406, "training_acc": 28.0, "val_loss": 6229.301452636719, "val_acc": 72.0}
{"epoch": 14, "training_loss": 27796.86749267578, "training_acc": 72.0, "val_loss": 11171.573638916016, "val_acc": 72.0}
{"epoch": 15, "training_loss": 43095.779296875, "training_acc": 72.0, "val_loss": 6565.926361083984, "val_acc": 72.0}
{"epoch": 16, "training_loss": 20870.462490081787, "training_acc": 72.0, "val_loss": 17781.663513183594, "val_acc": 28.0}
{"epoch": 17, "training_loss": 69560.09912109375, "training_acc": 28.0, "val_loss": 1190.886402130127, "val_acc": 28.0}
{"epoch": 18, "training_loss": 16761.802856445312, "training_acc": 46.0, "val_loss": 18754.942321777344, "val_acc": 72.0}
{"epoch": 19, "training_loss": 81931.46533203125, "training_acc": 72.0, "val_loss": 25608.554077148438, "val_acc": 72.0}
{"epoch": 20, "training_loss": 101531.59887695312, "training_acc": 72.0, "val_loss": 21970.648193359375, "val_acc": 72.0}
{"epoch": 21, "training_loss": 79440.51440429688, "training_acc": 72.0, "val_loss": 9659.724426269531, "val_acc": 72.0}
{"epoch": 22, "training_loss": 24393.40724182129, "training_acc": 72.0, "val_loss": 26461.697387695312, "val_acc": 28.0}
{"epoch": 23, "training_loss": 118281.68212890625, "training_acc": 28.0, "val_loss": 26641.693115234375, "val_acc": 28.0}
{"epoch": 24, "training_loss": 71790.7421875, "training_acc": 28.0, "val_loss": 12429.232025146484, "val_acc": 72.0}
{"epoch": 25, "training_loss": 62917.53955078125, "training_acc": 72.0, "val_loss": 29955.242919921875, "val_acc": 72.0}
{"epoch": 26, "training_loss": 128301.21435546875, "training_acc": 72.0, "val_loss": 35613.12561035156, "val_acc": 72.0}
{"epoch": 27, "training_loss": 140945.74243164062, "training_acc": 72.0, "val_loss": 30477.264404296875, "val_acc": 72.0}
{"epoch": 28, "training_loss": 115676.78344726562, "training_acc": 72.0, "val_loss": 18167.257690429688, "val_acc": 72.0}
{"epoch": 29, "training_loss": 62461.23059082031, "training_acc": 72.0, "val_loss": 1849.531364440918, "val_acc": 28.0}
{"epoch": 30, "training_loss": 18304.443725585938, "training_acc": 28.0, "val_loss": 284.4712495803833, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3854.6453552246094, "training_acc": 72.0, "val_loss": 42.24100112915039, "val_acc": 68.0}
{"epoch": 32, "training_loss": 15696.325782775879, "training_acc": 44.0, "val_loss": 972.5370407104492, "val_acc": 72.0}
{"epoch": 33, "training_loss": 6599.627349853516, "training_acc": 72.0, "val_loss": 1715.233039855957, "val_acc": 72.0}
{"epoch": 34, "training_loss": 16557.893188476562, "training_acc": 44.0, "val_loss": 1409.4240188598633, "val_acc": 72.0}
{"epoch": 35, "training_loss": 7472.704650878906, "training_acc": 72.0, "val_loss": 1145.992374420166, "val_acc": 72.0}
{"epoch": 36, "training_loss": 12294.90087890625, "training_acc": 56.0, "val_loss": 177.38827466964722, "val_acc": 72.0}
{"epoch": 37, "training_loss": 616.8754634857178, "training_acc": 72.0, "val_loss": 4940.731430053711, "val_acc": 28.0}
{"epoch": 38, "training_loss": 19873.852172851562, "training_acc": 34.0, "val_loss": 3567.6021575927734, "val_acc": 72.0}
{"epoch": 39, "training_loss": 11904.696807861328, "training_acc": 72.0, "val_loss": 4499.991989135742, "val_acc": 28.0}
{"epoch": 40, "training_loss": 11823.758499145508, "training_acc": 46.0, "val_loss": 419.0305709838867, "val_acc": 72.0}
{"epoch": 41, "training_loss": 5881.6661376953125, "training_acc": 62.0, "val_loss": 1938.3493423461914, "val_acc": 72.0}
{"epoch": 42, "training_loss": 9554.099243164062, "training_acc": 72.0, "val_loss": 1242.9678916931152, "val_acc": 72.0}
{"epoch": 43, "training_loss": 14171.496215820312, "training_acc": 54.0, "val_loss": 671.2156295776367, "val_acc": 28.0}
{"epoch": 44, "training_loss": 15730.467407226562, "training_acc": 40.0, "val_loss": 13010.287475585938, "val_acc": 72.0}
{"epoch": 45, "training_loss": 54083.82189941406, "training_acc": 72.0, "val_loss": 14636.6455078125, "val_acc": 72.0}
{"epoch": 46, "training_loss": 55078.02392578125, "training_acc": 72.0, "val_loss": 7521.125793457031, "val_acc": 72.0}
{"epoch": 47, "training_loss": 20865.13703918457, "training_acc": 72.0, "val_loss": 17843.597412109375, "val_acc": 28.0}
{"epoch": 48, "training_loss": 76034.77270507812, "training_acc": 28.0, "val_loss": 8540.625762939453, "val_acc": 28.0}
{"epoch": 49, "training_loss": 31668.313720703125, "training_acc": 44.0, "val_loss": 13825.096130371094, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59486.175537109375, "training_acc": 72.0, "val_loss": 19028.964233398438, "val_acc": 72.0}
