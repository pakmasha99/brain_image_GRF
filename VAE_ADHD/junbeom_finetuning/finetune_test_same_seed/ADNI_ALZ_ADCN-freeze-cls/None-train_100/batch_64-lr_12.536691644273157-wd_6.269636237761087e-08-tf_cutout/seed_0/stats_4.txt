"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 43012.5690612793, "training_acc": 48.0, "val_loss": 34884.3505859375, "val_acc": 72.0}
{"epoch": 1, "training_loss": 122998.67163085938, "training_acc": 72.0, "val_loss": 17279.17938232422, "val_acc": 28.0}
{"epoch": 2, "training_loss": 46456.27423095703, "training_acc": 28.0, "val_loss": 15798.501586914062, "val_acc": 72.0}
{"epoch": 3, "training_loss": 75658.64038085938, "training_acc": 72.0, "val_loss": 30031.854248046875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 119157.67944335938, "training_acc": 72.0, "val_loss": 25569.37255859375, "val_acc": 72.0}
{"epoch": 5, "training_loss": 92485.83764648438, "training_acc": 72.0, "val_loss": 8952.943420410156, "val_acc": 72.0}
{"epoch": 6, "training_loss": 30892.452880859375, "training_acc": 60.0, "val_loss": 12224.851989746094, "val_acc": 28.0}
{"epoch": 7, "training_loss": 33654.77429199219, "training_acc": 44.0, "val_loss": 4446.93489074707, "val_acc": 72.0}
{"epoch": 8, "training_loss": 17390.534423828125, "training_acc": 72.0, "val_loss": 442.02680587768555, "val_acc": 72.0}
{"epoch": 9, "training_loss": 17544.72314453125, "training_acc": 64.0, "val_loss": 10237.470245361328, "val_acc": 28.0}
{"epoch": 10, "training_loss": 29399.727935791016, "training_acc": 48.0, "val_loss": 8705.088806152344, "val_acc": 72.0}
{"epoch": 11, "training_loss": 37191.239990234375, "training_acc": 72.0, "val_loss": 9136.910247802734, "val_acc": 72.0}
{"epoch": 12, "training_loss": 31361.59197998047, "training_acc": 72.0, "val_loss": 2488.0897521972656, "val_acc": 28.0}
{"epoch": 13, "training_loss": 6408.495975494385, "training_acc": 48.0, "val_loss": 1849.1270065307617, "val_acc": 28.0}
{"epoch": 14, "training_loss": 6516.859466552734, "training_acc": 56.0, "val_loss": 7646.4447021484375, "val_acc": 72.0}
{"epoch": 15, "training_loss": 31536.82861328125, "training_acc": 72.0, "val_loss": 5916.13655090332, "val_acc": 72.0}
{"epoch": 16, "training_loss": 16349.090774536133, "training_acc": 72.0, "val_loss": 15007.603454589844, "val_acc": 28.0}
{"epoch": 17, "training_loss": 57552.16076660156, "training_acc": 28.0, "val_loss": 1522.84517288208, "val_acc": 72.0}
{"epoch": 18, "training_loss": 11037.858154296875, "training_acc": 72.0, "val_loss": 5606.333541870117, "val_acc": 72.0}
{"epoch": 19, "training_loss": 19464.974853515625, "training_acc": 72.0, "val_loss": 1921.1894989013672, "val_acc": 28.0}
{"epoch": 20, "training_loss": 9849.716918945312, "training_acc": 36.0, "val_loss": 1524.2376327514648, "val_acc": 72.0}
{"epoch": 21, "training_loss": 7269.408294677734, "training_acc": 62.0, "val_loss": 1949.9557495117188, "val_acc": 72.0}
{"epoch": 22, "training_loss": 8115.056610107422, "training_acc": 72.0, "val_loss": 200.14894008636475, "val_acc": 72.0}
{"epoch": 23, "training_loss": 19346.4404296875, "training_acc": 50.0, "val_loss": 4256.552505493164, "val_acc": 28.0}
{"epoch": 24, "training_loss": 19477.308837890625, "training_acc": 46.0, "val_loss": 12475.196838378906, "val_acc": 72.0}
{"epoch": 25, "training_loss": 55542.43798828125, "training_acc": 72.0, "val_loss": 15111.143493652344, "val_acc": 72.0}
{"epoch": 26, "training_loss": 56618.53759765625, "training_acc": 72.0, "val_loss": 7270.945739746094, "val_acc": 72.0}
{"epoch": 27, "training_loss": 20865.494522094727, "training_acc": 72.0, "val_loss": 21436.822509765625, "val_acc": 28.0}
{"epoch": 28, "training_loss": 92560.3857421875, "training_acc": 28.0, "val_loss": 11514.88265991211, "val_acc": 28.0}
{"epoch": 29, "training_loss": 36929.625, "training_acc": 46.0, "val_loss": 13967.782592773438, "val_acc": 72.0}
{"epoch": 30, "training_loss": 64065.9599609375, "training_acc": 72.0, "val_loss": 20234.410095214844, "val_acc": 72.0}
{"epoch": 31, "training_loss": 79402.52465820312, "training_acc": 72.0, "val_loss": 15751.96533203125, "val_acc": 72.0}
{"epoch": 32, "training_loss": 57689.11706542969, "training_acc": 72.0, "val_loss": 2547.3501205444336, "val_acc": 72.0}
{"epoch": 33, "training_loss": 33331.862548828125, "training_acc": 52.0, "val_loss": 20193.153381347656, "val_acc": 28.0}
{"epoch": 34, "training_loss": 62520.36096191406, "training_acc": 28.0, "val_loss": 7511.534118652344, "val_acc": 72.0}
{"epoch": 35, "training_loss": 45262.77099609375, "training_acc": 72.0, "val_loss": 18711.05194091797, "val_acc": 72.0}
{"epoch": 36, "training_loss": 75723.73120117188, "training_acc": 72.0, "val_loss": 17916.41387939453, "val_acc": 72.0}
{"epoch": 37, "training_loss": 65380.094970703125, "training_acc": 72.0, "val_loss": 8396.041870117188, "val_acc": 72.0}
{"epoch": 38, "training_loss": 23114.18242263794, "training_acc": 72.0, "val_loss": 23627.951049804688, "val_acc": 28.0}
{"epoch": 39, "training_loss": 102325.74951171875, "training_acc": 28.0, "val_loss": 18945.5322265625, "val_acc": 28.0}
{"epoch": 40, "training_loss": 54772.531829833984, "training_acc": 40.0, "val_loss": 8484.21401977539, "val_acc": 72.0}
{"epoch": 41, "training_loss": 38990.21484375, "training_acc": 72.0, "val_loss": 12060.132598876953, "val_acc": 72.0}
