"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 64439.68685913086, "training_acc": 40.0, "val_loss": 30614.334106445312, "val_acc": 72.0}
{"epoch": 1, "training_loss": 95018.05737304688, "training_acc": 72.0, "val_loss": 26798.770141601562, "val_acc": 28.0}
{"epoch": 2, "training_loss": 94645.70361328125, "training_acc": 28.0, "val_loss": 7345.427703857422, "val_acc": 72.0}
{"epoch": 3, "training_loss": 41991.722900390625, "training_acc": 72.0, "val_loss": 17675.559997558594, "val_acc": 72.0}
{"epoch": 4, "training_loss": 68565.75341796875, "training_acc": 72.0, "val_loss": 10143.648529052734, "val_acc": 72.0}
{"epoch": 5, "training_loss": 28055.105461120605, "training_acc": 72.0, "val_loss": 29396.456909179688, "val_acc": 28.0}
{"epoch": 6, "training_loss": 122569.4833984375, "training_acc": 28.0, "val_loss": 14958.122253417969, "val_acc": 28.0}
{"epoch": 7, "training_loss": 48222.61767578125, "training_acc": 44.0, "val_loss": 15770.463562011719, "val_acc": 72.0}
{"epoch": 8, "training_loss": 69401.89965820312, "training_acc": 72.0, "val_loss": 22781.317138671875, "val_acc": 72.0}
{"epoch": 9, "training_loss": 89871.04370117188, "training_acc": 72.0, "val_loss": 18382.626342773438, "val_acc": 72.0}
{"epoch": 10, "training_loss": 65511.39416503906, "training_acc": 72.0, "val_loss": 4209.149932861328, "val_acc": 72.0}
{"epoch": 11, "training_loss": 32165.527587890625, "training_acc": 56.0, "val_loss": 19474.47967529297, "val_acc": 28.0}
{"epoch": 12, "training_loss": 59457.08752441406, "training_acc": 28.0, "val_loss": 7595.387268066406, "val_acc": 72.0}
{"epoch": 13, "training_loss": 41943.86328125, "training_acc": 72.0, "val_loss": 19072.300720214844, "val_acc": 72.0}
{"epoch": 14, "training_loss": 77270.57373046875, "training_acc": 72.0, "val_loss": 18952.03399658203, "val_acc": 72.0}
{"epoch": 15, "training_loss": 70770.53833007812, "training_acc": 72.0, "val_loss": 9921.109008789062, "val_acc": 72.0}
{"epoch": 16, "training_loss": 30644.258911132812, "training_acc": 72.0, "val_loss": 17955.386352539062, "val_acc": 28.0}
{"epoch": 17, "training_loss": 78877.8984375, "training_acc": 28.0, "val_loss": 10411.182403564453, "val_acc": 28.0}
{"epoch": 18, "training_loss": 30636.82196044922, "training_acc": 50.0, "val_loss": 13019.955444335938, "val_acc": 72.0}
{"epoch": 19, "training_loss": 55756.5390625, "training_acc": 72.0, "val_loss": 18618.617248535156, "val_acc": 72.0}
{"epoch": 20, "training_loss": 73215.31567382812, "training_acc": 72.0, "val_loss": 14734.080505371094, "val_acc": 72.0}
{"epoch": 21, "training_loss": 50254.58752441406, "training_acc": 72.0, "val_loss": 2348.768997192383, "val_acc": 72.0}
{"epoch": 22, "training_loss": 33064.981689453125, "training_acc": 54.0, "val_loss": 22377.066040039062, "val_acc": 28.0}
{"epoch": 23, "training_loss": 72589.99975585938, "training_acc": 28.0, "val_loss": 5675.152587890625, "val_acc": 72.0}
{"epoch": 24, "training_loss": 31201.64697265625, "training_acc": 72.0, "val_loss": 16398.390197753906, "val_acc": 72.0}
{"epoch": 25, "training_loss": 66848.66796875, "training_acc": 72.0, "val_loss": 16443.099975585938, "val_acc": 72.0}
{"epoch": 26, "training_loss": 60257.188232421875, "training_acc": 72.0, "val_loss": 7684.918975830078, "val_acc": 72.0}
{"epoch": 27, "training_loss": 19833.698892593384, "training_acc": 72.0, "val_loss": 23228.47442626953, "val_acc": 28.0}
{"epoch": 28, "training_loss": 100568.50927734375, "training_acc": 28.0, "val_loss": 17648.635864257812, "val_acc": 28.0}
{"epoch": 29, "training_loss": 49089.704010009766, "training_acc": 44.0, "val_loss": 9269.544982910156, "val_acc": 72.0}
{"epoch": 30, "training_loss": 43322.382080078125, "training_acc": 72.0, "val_loss": 13631.900024414062, "val_acc": 72.0}
{"epoch": 31, "training_loss": 51653.811767578125, "training_acc": 72.0, "val_loss": 7849.806976318359, "val_acc": 72.0}
{"epoch": 32, "training_loss": 21659.548400878906, "training_acc": 72.0, "val_loss": 16240.074157714844, "val_acc": 28.0}
{"epoch": 33, "training_loss": 72159.44653320312, "training_acc": 28.0, "val_loss": 6577.031707763672, "val_acc": 28.0}
{"epoch": 34, "training_loss": 37311.604736328125, "training_acc": 34.0, "val_loss": 15553.317260742188, "val_acc": 72.0}
{"epoch": 35, "training_loss": 67456.60131835938, "training_acc": 72.0, "val_loss": 20566.41387939453, "val_acc": 72.0}
{"epoch": 36, "training_loss": 80206.85229492188, "training_acc": 72.0, "val_loss": 15845.968627929688, "val_acc": 72.0}
{"epoch": 37, "training_loss": 56591.047119140625, "training_acc": 72.0, "val_loss": 3068.532180786133, "val_acc": 72.0}
{"epoch": 38, "training_loss": 25417.038330078125, "training_acc": 60.0, "val_loss": 19030.967712402344, "val_acc": 28.0}
{"epoch": 39, "training_loss": 61458.25762939453, "training_acc": 28.0, "val_loss": 6476.219940185547, "val_acc": 72.0}
{"epoch": 40, "training_loss": 35291.3544921875, "training_acc": 72.0, "val_loss": 15616.915893554688, "val_acc": 72.0}
