"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 69861.53944015503, "training_acc": 72.0, "val_loss": 26462.530517578125, "val_acc": 72.0}
{"epoch": 1, "training_loss": 76623.48834228516, "training_acc": 72.0, "val_loss": 49544.342041015625, "val_acc": 28.0}
{"epoch": 2, "training_loss": 190159.99853515625, "training_acc": 28.0, "val_loss": 7923.081970214844, "val_acc": 28.0}
{"epoch": 3, "training_loss": 45058.508544921875, "training_acc": 44.0, "val_loss": 31363.998413085938, "val_acc": 72.0}
{"epoch": 4, "training_loss": 133490.14990234375, "training_acc": 72.0, "val_loss": 43949.468994140625, "val_acc": 72.0}
{"epoch": 5, "training_loss": 176536.85107421875, "training_acc": 72.0, "val_loss": 41822.747802734375, "val_acc": 72.0}
{"epoch": 6, "training_loss": 159368.50341796875, "training_acc": 72.0, "val_loss": 28009.011840820312, "val_acc": 72.0}
{"epoch": 7, "training_loss": 104007.60546875, "training_acc": 72.0, "val_loss": 4845.309829711914, "val_acc": 72.0}
{"epoch": 8, "training_loss": 45600.964599609375, "training_acc": 56.0, "val_loss": 32859.14306640625, "val_acc": 28.0}
{"epoch": 9, "training_loss": 117370.7724609375, "training_acc": 28.0, "val_loss": 883.6153030395508, "val_acc": 72.0}
{"epoch": 10, "training_loss": 7674.5863037109375, "training_acc": 72.0, "val_loss": 10635.453796386719, "val_acc": 72.0}
{"epoch": 11, "training_loss": 43622.0107421875, "training_acc": 72.0, "val_loss": 9851.405334472656, "val_acc": 72.0}
{"epoch": 12, "training_loss": 33610.026428222656, "training_acc": 72.0, "val_loss": 1333.9792251586914, "val_acc": 28.0}
{"epoch": 13, "training_loss": 3544.326145172119, "training_acc": 48.0, "val_loss": 2774.588394165039, "val_acc": 28.0}
{"epoch": 14, "training_loss": 14881.773803710938, "training_acc": 40.0, "val_loss": 6325.934600830078, "val_acc": 72.0}
{"epoch": 15, "training_loss": 24428.631713867188, "training_acc": 72.0, "val_loss": 2515.485382080078, "val_acc": 72.0}
{"epoch": 16, "training_loss": 16076.150146484375, "training_acc": 58.0, "val_loss": 3546.8929290771484, "val_acc": 28.0}
{"epoch": 17, "training_loss": 16374.9501953125, "training_acc": 46.0, "val_loss": 10245.33462524414, "val_acc": 72.0}
{"epoch": 18, "training_loss": 43254.23889160156, "training_acc": 72.0, "val_loss": 10807.0556640625, "val_acc": 72.0}
{"epoch": 19, "training_loss": 38748.928466796875, "training_acc": 72.0, "val_loss": 1937.7063751220703, "val_acc": 72.0}
{"epoch": 20, "training_loss": 26615.688232421875, "training_acc": 54.0, "val_loss": 14480.976867675781, "val_acc": 28.0}
{"epoch": 21, "training_loss": 36446.2675743103, "training_acc": 46.0, "val_loss": 3399.286651611328, "val_acc": 72.0}
{"epoch": 22, "training_loss": 15240.525695800781, "training_acc": 72.0, "val_loss": 1955.1000595092773, "val_acc": 72.0}
{"epoch": 23, "training_loss": 15726.967651367188, "training_acc": 54.0, "val_loss": 1155.9285163879395, "val_acc": 28.0}
{"epoch": 24, "training_loss": 11134.353332519531, "training_acc": 48.0, "val_loss": 12390.07568359375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 51470.753173828125, "training_acc": 72.0, "val_loss": 14304.0771484375, "val_acc": 72.0}
{"epoch": 26, "training_loss": 54047.44677734375, "training_acc": 72.0, "val_loss": 7392.8009033203125, "val_acc": 72.0}
{"epoch": 27, "training_loss": 21167.561042785645, "training_acc": 72.0, "val_loss": 18648.53057861328, "val_acc": 28.0}
{"epoch": 28, "training_loss": 77809.71899414062, "training_acc": 28.0, "val_loss": 7935.365295410156, "val_acc": 28.0}
