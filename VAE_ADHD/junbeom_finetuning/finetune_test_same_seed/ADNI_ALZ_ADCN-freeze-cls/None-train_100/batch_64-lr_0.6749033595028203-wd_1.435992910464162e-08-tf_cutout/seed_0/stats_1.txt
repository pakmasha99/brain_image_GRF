"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2688.795051574707, "training_acc": 72.0, "val_loss": 1298.8277435302734, "val_acc": 72.0}
{"epoch": 1, "training_loss": 3430.5815353393555, "training_acc": 72.0, "val_loss": 1956.1655044555664, "val_acc": 28.0}
{"epoch": 2, "training_loss": 7478.552642822266, "training_acc": 28.0, "val_loss": 220.32432556152344, "val_acc": 28.0}
{"epoch": 3, "training_loss": 1484.1619415283203, "training_acc": 48.0, "val_loss": 1482.573413848877, "val_acc": 72.0}
{"epoch": 4, "training_loss": 6243.802429199219, "training_acc": 72.0, "val_loss": 2055.1483154296875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8235.526947021484, "training_acc": 72.0, "val_loss": 1937.5255584716797, "val_acc": 72.0}
{"epoch": 6, "training_loss": 7260.964752197266, "training_acc": 72.0, "val_loss": 1214.6681785583496, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3993.596939086914, "training_acc": 72.0, "val_loss": 67.13489890098572, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1988.1122131347656, "training_acc": 64.0, "val_loss": 2254.903030395508, "val_acc": 28.0}
{"epoch": 9, "training_loss": 8514.704498291016, "training_acc": 28.0, "val_loss": 996.2131500244141, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2752.6892433166504, "training_acc": 46.0, "val_loss": 695.4114437103271, "val_acc": 72.0}
{"epoch": 11, "training_loss": 3076.631019592285, "training_acc": 72.0, "val_loss": 1134.9225044250488, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4563.269027709961, "training_acc": 72.0, "val_loss": 1055.9688568115234, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3854.146530151367, "training_acc": 72.0, "val_loss": 505.4748058319092, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1308.644437789917, "training_acc": 72.0, "val_loss": 1048.1528282165527, "val_acc": 28.0}
{"epoch": 15, "training_loss": 4710.135070800781, "training_acc": 28.0, "val_loss": 1024.7516632080078, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2486.5775035619736, "training_acc": 48.0, "val_loss": 388.8507604598999, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1649.5901985168457, "training_acc": 72.0, "val_loss": 711.6035461425781, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2830.7446823120117, "training_acc": 72.0, "val_loss": 597.783899307251, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2105.491397857666, "training_acc": 72.0, "val_loss": 57.36974477767944, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1346.1600494384766, "training_acc": 56.0, "val_loss": 980.6645393371582, "val_acc": 28.0}
{"epoch": 21, "training_loss": 2989.1252212524414, "training_acc": 28.0, "val_loss": 323.1217622756958, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1707.517478942871, "training_acc": 72.0, "val_loss": 859.3276023864746, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3505.649383544922, "training_acc": 72.0, "val_loss": 880.5952072143555, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3354.975067138672, "training_acc": 72.0, "val_loss": 461.0565662384033, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1368.2386150360107, "training_acc": 72.0, "val_loss": 659.3539714813232, "val_acc": 28.0}
{"epoch": 26, "training_loss": 2940.070602416992, "training_acc": 28.0, "val_loss": 313.0334138870239, "val_acc": 28.0}
{"epoch": 27, "training_loss": 919.1063938140869, "training_acc": 54.0, "val_loss": 667.1034812927246, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2896.639419555664, "training_acc": 72.0, "val_loss": 946.1080551147461, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3692.332962036133, "training_acc": 72.0, "val_loss": 753.6539077758789, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2684.95015335083, "training_acc": 72.0, "val_loss": 159.5996379852295, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1129.850730895996, "training_acc": 60.0, "val_loss": 823.7018585205078, "val_acc": 28.0}
{"epoch": 32, "training_loss": 2531.210391998291, "training_acc": 28.0, "val_loss": 321.07560634613037, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1750.505859375, "training_acc": 72.0, "val_loss": 774.2735385894775, "val_acc": 72.0}
{"epoch": 34, "training_loss": 3093.2843322753906, "training_acc": 72.0, "val_loss": 703.5499095916748, "val_acc": 72.0}
{"epoch": 35, "training_loss": 2516.182487487793, "training_acc": 72.0, "val_loss": 223.82981777191162, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1151.7863845825195, "training_acc": 54.0, "val_loss": 471.98967933654785, "val_acc": 28.0}
{"epoch": 37, "training_loss": 1204.3071374893188, "training_acc": 46.0, "val_loss": 155.14272451400757, "val_acc": 72.0}
{"epoch": 38, "training_loss": 598.1753215789795, "training_acc": 72.0, "val_loss": 29.20530140399933, "val_acc": 72.0}
{"epoch": 39, "training_loss": 520.1230697631836, "training_acc": 62.0, "val_loss": 167.49600172042847, "val_acc": 28.0}
{"epoch": 40, "training_loss": 731.8954048156738, "training_acc": 46.0, "val_loss": 475.2387523651123, "val_acc": 72.0}
{"epoch": 41, "training_loss": 1961.0636367797852, "training_acc": 72.0, "val_loss": 507.1791648864746, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1858.8353233337402, "training_acc": 72.0, "val_loss": 118.68659257888794, "val_acc": 72.0}
{"epoch": 43, "training_loss": 1031.9280014038086, "training_acc": 54.0, "val_loss": 468.7075138092041, "val_acc": 28.0}
{"epoch": 44, "training_loss": 1258.1884775161743, "training_acc": 46.0, "val_loss": 232.04689025878906, "val_acc": 72.0}
{"epoch": 45, "training_loss": 964.9449348449707, "training_acc": 72.0, "val_loss": 166.74466133117676, "val_acc": 72.0}
{"epoch": 46, "training_loss": 421.62846994400024, "training_acc": 70.0, "val_loss": 71.7742919921875, "val_acc": 36.0}
{"epoch": 47, "training_loss": 433.490421295166, "training_acc": 47.0, "val_loss": 275.6982088088989, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1046.8158645629883, "training_acc": 72.0, "val_loss": 101.15615129470825, "val_acc": 72.0}
{"epoch": 49, "training_loss": 538.6164321899414, "training_acc": 62.0, "val_loss": 145.5404758453369, "val_acc": 28.0}
{"epoch": 50, "training_loss": 523.9081363677979, "training_acc": 52.0, "val_loss": 433.3970069885254, "val_acc": 72.0}
{"epoch": 51, "training_loss": 1839.8841857910156, "training_acc": 72.0, "val_loss": 456.6781520843506, "val_acc": 72.0}
{"epoch": 52, "training_loss": 1638.8096828460693, "training_acc": 72.0, "val_loss": 29.61837649345398, "val_acc": 76.0}
{"epoch": 53, "training_loss": 871.4219360351562, "training_acc": 63.0, "val_loss": 661.0990047454834, "val_acc": 28.0}
{"epoch": 54, "training_loss": 1661.3543584346771, "training_acc": 42.0, "val_loss": 278.31928730010986, "val_acc": 72.0}
{"epoch": 55, "training_loss": 1318.0066146850586, "training_acc": 72.0, "val_loss": 433.349609375, "val_acc": 72.0}
{"epoch": 56, "training_loss": 1592.9912223815918, "training_acc": 72.0, "val_loss": 118.43805313110352, "val_acc": 72.0}
{"epoch": 57, "training_loss": 803.9975891113281, "training_acc": 58.0, "val_loss": 326.4697790145874, "val_acc": 28.0}
