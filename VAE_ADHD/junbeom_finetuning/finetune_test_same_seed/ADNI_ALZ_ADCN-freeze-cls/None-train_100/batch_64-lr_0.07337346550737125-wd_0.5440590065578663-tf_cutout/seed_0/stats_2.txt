"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 454.061710357666, "training_acc": 71.0, "val_loss": 166.4301872253418, "val_acc": 72.0}
{"epoch": 1, "training_loss": 519.223228931427, "training_acc": 72.0, "val_loss": 214.22646045684814, "val_acc": 28.0}
{"epoch": 2, "training_loss": 765.980037689209, "training_acc": 28.0, "val_loss": 28.96782159805298, "val_acc": 72.0}
{"epoch": 3, "training_loss": 157.2215600013733, "training_acc": 72.0, "val_loss": 88.18218111991882, "val_acc": 72.0}
{"epoch": 4, "training_loss": 339.0517587661743, "training_acc": 72.0, "val_loss": 46.87855839729309, "val_acc": 72.0}
{"epoch": 5, "training_loss": 169.61875534057617, "training_acc": 52.0, "val_loss": 37.05510497093201, "val_acc": 28.0}
{"epoch": 6, "training_loss": 127.47473478317261, "training_acc": 44.0, "val_loss": 35.53035259246826, "val_acc": 72.0}
{"epoch": 7, "training_loss": 131.6881229877472, "training_acc": 72.0, "val_loss": 15.102778375148773, "val_acc": 72.0}
{"epoch": 8, "training_loss": 87.44166803359985, "training_acc": 54.0, "val_loss": 17.374712228775024, "val_acc": 72.0}
{"epoch": 9, "training_loss": 74.16154789924622, "training_acc": 72.0, "val_loss": 20.273128151893616, "val_acc": 72.0}
{"epoch": 10, "training_loss": 87.6010901927948, "training_acc": 50.0, "val_loss": 14.971251785755157, "val_acc": 72.0}
{"epoch": 11, "training_loss": 62.76349949836731, "training_acc": 72.0, "val_loss": 15.938545763492584, "val_acc": 72.0}
{"epoch": 12, "training_loss": 60.410011529922485, "training_acc": 72.0, "val_loss": 17.743445932865143, "val_acc": 28.0}
{"epoch": 13, "training_loss": 66.20703506469727, "training_acc": 46.0, "val_loss": 18.275125324726105, "val_acc": 72.0}
{"epoch": 14, "training_loss": 71.29037284851074, "training_acc": 72.0, "val_loss": 15.4536634683609, "val_acc": 28.0}
{"epoch": 15, "training_loss": 60.072182178497314, "training_acc": 72.0, "val_loss": 15.99304974079132, "val_acc": 72.0}
{"epoch": 16, "training_loss": 63.22132182121277, "training_acc": 72.0, "val_loss": 14.916738867759705, "val_acc": 72.0}
{"epoch": 17, "training_loss": 62.338770627975464, "training_acc": 72.0, "val_loss": 15.013112127780914, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.20807766914368, "training_acc": 72.0, "val_loss": 15.376397967338562, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.6748309135437, "training_acc": 72.0, "val_loss": 15.378355979919434, "val_acc": 32.0}
{"epoch": 20, "training_loss": 60.380707025527954, "training_acc": 72.0, "val_loss": 15.258345007896423, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.85142469406128, "training_acc": 72.0, "val_loss": 18.031583726406097, "val_acc": 28.0}
{"epoch": 22, "training_loss": 74.45005631446838, "training_acc": 40.0, "val_loss": 15.20170271396637, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.50324201583862, "training_acc": 72.0, "val_loss": 14.76227194070816, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.187971115112305, "training_acc": 72.0, "val_loss": 18.317347764968872, "val_acc": 72.0}
{"epoch": 25, "training_loss": 71.2968680858612, "training_acc": 72.0, "val_loss": 34.425368905067444, "val_acc": 28.0}
{"epoch": 26, "training_loss": 110.55231475830078, "training_acc": 44.0, "val_loss": 23.3262300491333, "val_acc": 72.0}
{"epoch": 27, "training_loss": 82.46037411689758, "training_acc": 72.0, "val_loss": 26.167839765548706, "val_acc": 28.0}
{"epoch": 28, "training_loss": 84.05847644805908, "training_acc": 48.0, "val_loss": 23.725761473178864, "val_acc": 72.0}
{"epoch": 29, "training_loss": 84.2803282737732, "training_acc": 72.0, "val_loss": 30.959802865982056, "val_acc": 28.0}
{"epoch": 30, "training_loss": 119.14240264892578, "training_acc": 36.0, "val_loss": 17.3394575715065, "val_acc": 72.0}
{"epoch": 31, "training_loss": 65.73968386650085, "training_acc": 72.0, "val_loss": 15.891779959201813, "val_acc": 28.0}
{"epoch": 32, "training_loss": 75.85014915466309, "training_acc": 72.0, "val_loss": 14.980591833591461, "val_acc": 72.0}
{"epoch": 33, "training_loss": 65.66523790359497, "training_acc": 58.0, "val_loss": 15.860781073570251, "val_acc": 72.0}
{"epoch": 34, "training_loss": 74.7434983253479, "training_acc": 72.0, "val_loss": 17.59047657251358, "val_acc": 28.0}
{"epoch": 35, "training_loss": 69.35773921012878, "training_acc": 46.0, "val_loss": 21.871091425418854, "val_acc": 72.0}
{"epoch": 36, "training_loss": 83.63004970550537, "training_acc": 72.0, "val_loss": 15.939825773239136, "val_acc": 28.0}
{"epoch": 37, "training_loss": 62.879124879837036, "training_acc": 72.0, "val_loss": 14.864097535610199, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.78444719314575, "training_acc": 72.0, "val_loss": 15.710532665252686, "val_acc": 72.0}
{"epoch": 39, "training_loss": 68.62412571907043, "training_acc": 72.0, "val_loss": 18.87401193380356, "val_acc": 72.0}
{"epoch": 40, "training_loss": 72.50671911239624, "training_acc": 72.0, "val_loss": 21.033799648284912, "val_acc": 28.0}
{"epoch": 41, "training_loss": 78.32447981834412, "training_acc": 42.0, "val_loss": 16.412143409252167, "val_acc": 72.0}
{"epoch": 42, "training_loss": 60.907567501068115, "training_acc": 72.0, "val_loss": 18.410274386405945, "val_acc": 28.0}
