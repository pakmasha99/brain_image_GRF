"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 389.1020812988281, "training_acc": 72.0, "val_loss": 166.1844253540039, "val_acc": 72.0}
{"epoch": 1, "training_loss": 510.1982102394104, "training_acc": 72.0, "val_loss": 250.00436305999756, "val_acc": 28.0}
{"epoch": 2, "training_loss": 892.5634441375732, "training_acc": 28.0, "val_loss": 24.04925227165222, "val_acc": 72.0}
{"epoch": 3, "training_loss": 154.61242771148682, "training_acc": 72.0, "val_loss": 84.82983708381653, "val_acc": 72.0}
{"epoch": 4, "training_loss": 321.79845428466797, "training_acc": 72.0, "val_loss": 38.19441199302673, "val_acc": 72.0}
{"epoch": 5, "training_loss": 135.53081560134888, "training_acc": 60.0, "val_loss": 36.53742074966431, "val_acc": 28.0}
{"epoch": 6, "training_loss": 141.41736459732056, "training_acc": 42.0, "val_loss": 44.31983232498169, "val_acc": 72.0}
{"epoch": 7, "training_loss": 167.752610206604, "training_acc": 72.0, "val_loss": 17.02660471200943, "val_acc": 72.0}
{"epoch": 8, "training_loss": 86.14063835144043, "training_acc": 62.0, "val_loss": 19.178393483161926, "val_acc": 28.0}
{"epoch": 9, "training_loss": 73.07031655311584, "training_acc": 50.0, "val_loss": 35.421937704086304, "val_acc": 72.0}
{"epoch": 10, "training_loss": 131.17852425575256, "training_acc": 72.0, "val_loss": 15.38027673959732, "val_acc": 28.0}
{"epoch": 11, "training_loss": 83.00642585754395, "training_acc": 54.0, "val_loss": 17.921382188796997, "val_acc": 72.0}
{"epoch": 12, "training_loss": 84.8350248336792, "training_acc": 72.0, "val_loss": 18.47647875547409, "val_acc": 72.0}
{"epoch": 13, "training_loss": 74.76316380500793, "training_acc": 58.0, "val_loss": 16.967187821865082, "val_acc": 28.0}
{"epoch": 14, "training_loss": 74.58881998062134, "training_acc": 72.0, "val_loss": 19.953887164592743, "val_acc": 72.0}
{"epoch": 15, "training_loss": 67.55961537361145, "training_acc": 72.0, "val_loss": 29.189014434814453, "val_acc": 28.0}
{"epoch": 16, "training_loss": 100.49943900108337, "training_acc": 42.0, "val_loss": 21.273833513259888, "val_acc": 72.0}
{"epoch": 17, "training_loss": 77.50386953353882, "training_acc": 72.0, "val_loss": 20.63327729701996, "val_acc": 28.0}
{"epoch": 18, "training_loss": 72.41817951202393, "training_acc": 48.0, "val_loss": 21.203453838825226, "val_acc": 72.0}
{"epoch": 19, "training_loss": 82.68307065963745, "training_acc": 72.0, "val_loss": 15.83157479763031, "val_acc": 28.0}
{"epoch": 20, "training_loss": 80.69200801849365, "training_acc": 48.0, "val_loss": 24.355997145175934, "val_acc": 72.0}
{"epoch": 21, "training_loss": 102.1693925857544, "training_acc": 72.0, "val_loss": 22.779063880443573, "val_acc": 72.0}
{"epoch": 22, "training_loss": 80.32893061637878, "training_acc": 62.0, "val_loss": 23.128390312194824, "val_acc": 28.0}
{"epoch": 23, "training_loss": 96.55991101264954, "training_acc": 40.0, "val_loss": 23.367346823215485, "val_acc": 72.0}
{"epoch": 24, "training_loss": 81.1521954536438, "training_acc": 72.0, "val_loss": 26.00972056388855, "val_acc": 28.0}
{"epoch": 25, "training_loss": 86.06135678291321, "training_acc": 46.0, "val_loss": 22.245627641677856, "val_acc": 72.0}
{"epoch": 26, "training_loss": 81.68346333503723, "training_acc": 72.0, "val_loss": 21.648070216178894, "val_acc": 28.0}
{"epoch": 27, "training_loss": 76.87679100036621, "training_acc": 44.0, "val_loss": 18.841883540153503, "val_acc": 72.0}
{"epoch": 28, "training_loss": 71.94783735275269, "training_acc": 72.0, "val_loss": 16.54704064130783, "val_acc": 28.0}
{"epoch": 29, "training_loss": 65.12283325195312, "training_acc": 72.0, "val_loss": 14.798097312450409, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.04263424873352, "training_acc": 72.0, "val_loss": 14.746814966201782, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.47434139251709, "training_acc": 72.0, "val_loss": 16.18151068687439, "val_acc": 72.0}
{"epoch": 32, "training_loss": 70.40979290008545, "training_acc": 72.0, "val_loss": 17.196175456047058, "val_acc": 72.0}
{"epoch": 33, "training_loss": 71.6412513256073, "training_acc": 72.0, "val_loss": 22.161971032619476, "val_acc": 28.0}
{"epoch": 34, "training_loss": 77.9533576965332, "training_acc": 44.0, "val_loss": 18.91123205423355, "val_acc": 72.0}
{"epoch": 35, "training_loss": 71.29707646369934, "training_acc": 72.0, "val_loss": 17.42061972618103, "val_acc": 28.0}
{"epoch": 36, "training_loss": 67.61103940010071, "training_acc": 47.0, "val_loss": 15.362182259559631, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.94019365310669, "training_acc": 72.0, "val_loss": 15.70105105638504, "val_acc": 28.0}
{"epoch": 38, "training_loss": 62.45687985420227, "training_acc": 72.0, "val_loss": 15.299180150032043, "val_acc": 72.0}
{"epoch": 39, "training_loss": 67.09523439407349, "training_acc": 60.0, "val_loss": 16.80396944284439, "val_acc": 72.0}
{"epoch": 40, "training_loss": 67.80784296989441, "training_acc": 72.0, "val_loss": 17.434147000312805, "val_acc": 28.0}
{"epoch": 41, "training_loss": 65.89277243614197, "training_acc": 47.0, "val_loss": 16.681207716464996, "val_acc": 72.0}
{"epoch": 42, "training_loss": 63.594887495040894, "training_acc": 72.0, "val_loss": 19.050417840480804, "val_acc": 28.0}
{"epoch": 43, "training_loss": 69.16373777389526, "training_acc": 46.0, "val_loss": 18.292029201984406, "val_acc": 72.0}
{"epoch": 44, "training_loss": 70.39900970458984, "training_acc": 72.0, "val_loss": 15.407630801200867, "val_acc": 28.0}
{"epoch": 45, "training_loss": 64.51609230041504, "training_acc": 72.0, "val_loss": 14.756089448928833, "val_acc": 72.0}
{"epoch": 46, "training_loss": 60.055283069610596, "training_acc": 72.0, "val_loss": 14.807915687561035, "val_acc": 72.0}
{"epoch": 47, "training_loss": 61.0398268699646, "training_acc": 72.0, "val_loss": 15.73244035243988, "val_acc": 28.0}
{"epoch": 48, "training_loss": 61.39664959907532, "training_acc": 72.0, "val_loss": 15.636000037193298, "val_acc": 72.0}
{"epoch": 49, "training_loss": 60.60299611091614, "training_acc": 72.0, "val_loss": 19.843295216560364, "val_acc": 28.0}
