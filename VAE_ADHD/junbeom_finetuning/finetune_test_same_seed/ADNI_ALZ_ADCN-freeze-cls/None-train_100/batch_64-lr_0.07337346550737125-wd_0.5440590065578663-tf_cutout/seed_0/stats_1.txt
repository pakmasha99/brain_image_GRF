"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 451.9075126647949, "training_acc": 72.0, "val_loss": 163.9404535293579, "val_acc": 72.0}
{"epoch": 1, "training_loss": 521.917085647583, "training_acc": 72.0, "val_loss": 223.28674793243408, "val_acc": 28.0}
{"epoch": 2, "training_loss": 808.224552154541, "training_acc": 28.0, "val_loss": 24.832728505134583, "val_acc": 72.0}
{"epoch": 3, "training_loss": 202.1610336303711, "training_acc": 72.0, "val_loss": 94.10260319709778, "val_acc": 72.0}
{"epoch": 4, "training_loss": 359.0475769042969, "training_acc": 72.0, "val_loss": 49.30756986141205, "val_acc": 72.0}
{"epoch": 5, "training_loss": 144.007009267807, "training_acc": 72.0, "val_loss": 71.90478444099426, "val_acc": 28.0}
{"epoch": 6, "training_loss": 223.63081288337708, "training_acc": 36.0, "val_loss": 30.59597909450531, "val_acc": 72.0}
{"epoch": 7, "training_loss": 132.40169620513916, "training_acc": 72.0, "val_loss": 23.25419932603836, "val_acc": 72.0}
{"epoch": 8, "training_loss": 102.37979745864868, "training_acc": 54.0, "val_loss": 17.716169357299805, "val_acc": 28.0}
{"epoch": 9, "training_loss": 68.97853565216064, "training_acc": 48.0, "val_loss": 25.861316919326782, "val_acc": 72.0}
{"epoch": 10, "training_loss": 90.4107506275177, "training_acc": 72.0, "val_loss": 26.554179191589355, "val_acc": 28.0}
{"epoch": 11, "training_loss": 91.7349579334259, "training_acc": 42.0, "val_loss": 19.691330194473267, "val_acc": 72.0}
{"epoch": 12, "training_loss": 80.77614712715149, "training_acc": 72.0, "val_loss": 15.570230782032013, "val_acc": 28.0}
{"epoch": 13, "training_loss": 73.48875784873962, "training_acc": 54.0, "val_loss": 18.037451803684235, "val_acc": 72.0}
{"epoch": 14, "training_loss": 74.95335745811462, "training_acc": 72.0, "val_loss": 15.983378887176514, "val_acc": 72.0}
{"epoch": 15, "training_loss": 101.20306015014648, "training_acc": 44.0, "val_loss": 18.44462901353836, "val_acc": 72.0}
{"epoch": 16, "training_loss": 85.25186109542847, "training_acc": 72.0, "val_loss": 19.938696920871735, "val_acc": 72.0}
{"epoch": 17, "training_loss": 88.72192311286926, "training_acc": 52.0, "val_loss": 15.305490791797638, "val_acc": 44.0}
{"epoch": 18, "training_loss": 65.85521578788757, "training_acc": 72.0, "val_loss": 17.87547767162323, "val_acc": 72.0}
{"epoch": 19, "training_loss": 78.03179430961609, "training_acc": 50.0, "val_loss": 14.75580632686615, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.00304937362671, "training_acc": 72.0, "val_loss": 15.247303247451782, "val_acc": 72.0}
{"epoch": 21, "training_loss": 61.68805646896362, "training_acc": 72.0, "val_loss": 14.872390031814575, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.66090250015259, "training_acc": 72.0, "val_loss": 19.69747543334961, "val_acc": 72.0}
{"epoch": 23, "training_loss": 75.6625452041626, "training_acc": 72.0, "val_loss": 17.217902839183807, "val_acc": 28.0}
{"epoch": 24, "training_loss": 68.42898511886597, "training_acc": 76.0, "val_loss": 20.651736855506897, "val_acc": 72.0}
{"epoch": 25, "training_loss": 81.30748224258423, "training_acc": 72.0, "val_loss": 14.882053434848785, "val_acc": 72.0}
{"epoch": 26, "training_loss": 66.44123554229736, "training_acc": 54.0, "val_loss": 15.951880812644958, "val_acc": 72.0}
{"epoch": 27, "training_loss": 65.75387263298035, "training_acc": 72.0, "val_loss": 14.94564414024353, "val_acc": 72.0}
{"epoch": 28, "training_loss": 67.31880283355713, "training_acc": 52.0, "val_loss": 19.432498514652252, "val_acc": 72.0}
{"epoch": 29, "training_loss": 83.3222393989563, "training_acc": 72.0, "val_loss": 15.246213972568512, "val_acc": 72.0}
{"epoch": 30, "training_loss": 68.83934807777405, "training_acc": 58.0, "val_loss": 17.156335711479187, "val_acc": 72.0}
{"epoch": 31, "training_loss": 73.85445356369019, "training_acc": 72.0, "val_loss": 14.919663965702057, "val_acc": 72.0}
{"epoch": 32, "training_loss": 71.39421153068542, "training_acc": 54.0, "val_loss": 19.551624357700348, "val_acc": 72.0}
{"epoch": 33, "training_loss": 82.43006134033203, "training_acc": 72.0, "val_loss": 14.740516245365143, "val_acc": 72.0}
{"epoch": 34, "training_loss": 78.90816068649292, "training_acc": 54.0, "val_loss": 19.044993817806244, "val_acc": 72.0}
{"epoch": 35, "training_loss": 81.45561575889587, "training_acc": 72.0, "val_loss": 15.62635451555252, "val_acc": 72.0}
{"epoch": 36, "training_loss": 83.2376389503479, "training_acc": 54.0, "val_loss": 16.87716245651245, "val_acc": 72.0}
{"epoch": 37, "training_loss": 83.93001174926758, "training_acc": 72.0, "val_loss": 14.992782473564148, "val_acc": 72.0}
{"epoch": 38, "training_loss": 87.44493818283081, "training_acc": 54.0, "val_loss": 17.598803341388702, "val_acc": 72.0}
{"epoch": 39, "training_loss": 75.70708298683167, "training_acc": 72.0, "val_loss": 17.131999135017395, "val_acc": 72.0}
{"epoch": 40, "training_loss": 93.48314714431763, "training_acc": 50.0, "val_loss": 17.402637004852295, "val_acc": 72.0}
{"epoch": 41, "training_loss": 75.02382349967957, "training_acc": 72.0, "val_loss": 15.582577884197235, "val_acc": 72.0}
{"epoch": 42, "training_loss": 78.78422594070435, "training_acc": 54.0, "val_loss": 16.49339199066162, "val_acc": 72.0}
{"epoch": 43, "training_loss": 74.25836205482483, "training_acc": 72.0, "val_loss": 14.79766070842743, "val_acc": 72.0}
{"epoch": 44, "training_loss": 64.4737560749054, "training_acc": 60.0, "val_loss": 14.84205424785614, "val_acc": 72.0}
{"epoch": 45, "training_loss": 63.287670612335205, "training_acc": 72.0, "val_loss": 14.787288010120392, "val_acc": 72.0}
{"epoch": 46, "training_loss": 63.910080671310425, "training_acc": 56.0, "val_loss": 15.538367629051208, "val_acc": 72.0}
{"epoch": 47, "training_loss": 69.08416295051575, "training_acc": 72.0, "val_loss": 16.897688806056976, "val_acc": 28.0}
{"epoch": 48, "training_loss": 73.6540219783783, "training_acc": 48.0, "val_loss": 27.50319540500641, "val_acc": 72.0}
{"epoch": 49, "training_loss": 120.66558265686035, "training_acc": 72.0, "val_loss": 19.281207025051117, "val_acc": 72.0}
{"epoch": 50, "training_loss": 136.8478593826294, "training_acc": 48.0, "val_loss": 15.078207850456238, "val_acc": 72.0}
{"epoch": 51, "training_loss": 91.87282800674438, "training_acc": 72.0, "val_loss": 23.783574998378754, "val_acc": 72.0}
{"epoch": 52, "training_loss": 94.10717058181763, "training_acc": 54.0, "val_loss": 16.519778966903687, "val_acc": 28.0}
