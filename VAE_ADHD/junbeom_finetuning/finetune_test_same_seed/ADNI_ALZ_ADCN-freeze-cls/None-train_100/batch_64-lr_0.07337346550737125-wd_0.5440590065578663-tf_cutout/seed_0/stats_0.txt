"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 390.37994384765625, "training_acc": 42.0, "val_loss": 179.98095750808716, "val_acc": 72.0}
{"epoch": 1, "training_loss": 544.9558000564575, "training_acc": 72.0, "val_loss": 160.4784369468689, "val_acc": 28.0}
{"epoch": 2, "training_loss": 566.7772159576416, "training_acc": 28.0, "val_loss": 44.75608766078949, "val_acc": 72.0}
{"epoch": 3, "training_loss": 245.9789276123047, "training_acc": 72.0, "val_loss": 105.91462850570679, "val_acc": 72.0}
{"epoch": 4, "training_loss": 406.31186294555664, "training_acc": 72.0, "val_loss": 60.680562257766724, "val_acc": 72.0}
{"epoch": 5, "training_loss": 209.05923461914062, "training_acc": 72.0, "val_loss": 78.33601236343384, "val_acc": 28.0}
{"epoch": 6, "training_loss": 241.9615182876587, "training_acc": 28.0, "val_loss": 41.96011126041412, "val_acc": 72.0}
{"epoch": 7, "training_loss": 189.58382892608643, "training_acc": 72.0, "val_loss": 70.01334428787231, "val_acc": 72.0}
{"epoch": 8, "training_loss": 260.87091159820557, "training_acc": 72.0, "val_loss": 28.21963131427765, "val_acc": 72.0}
{"epoch": 9, "training_loss": 161.11468315124512, "training_acc": 50.0, "val_loss": 33.13996195793152, "val_acc": 28.0}
{"epoch": 10, "training_loss": 123.01096963882446, "training_acc": 44.0, "val_loss": 43.75895857810974, "val_acc": 72.0}
{"epoch": 11, "training_loss": 173.33113145828247, "training_acc": 72.0, "val_loss": 26.23642385005951, "val_acc": 72.0}
{"epoch": 12, "training_loss": 104.48424935340881, "training_acc": 54.0, "val_loss": 25.72610080242157, "val_acc": 28.0}
{"epoch": 13, "training_loss": 78.2915768623352, "training_acc": 52.0, "val_loss": 29.409953951835632, "val_acc": 72.0}
{"epoch": 14, "training_loss": 117.10008382797241, "training_acc": 72.0, "val_loss": 15.319953858852386, "val_acc": 72.0}
{"epoch": 15, "training_loss": 77.99078178405762, "training_acc": 60.0, "val_loss": 16.73841029405594, "val_acc": 28.0}
{"epoch": 16, "training_loss": 83.58010673522949, "training_acc": 72.0, "val_loss": 25.569817423820496, "val_acc": 72.0}
{"epoch": 17, "training_loss": 94.04163360595703, "training_acc": 72.0, "val_loss": 21.057836711406708, "val_acc": 28.0}
{"epoch": 18, "training_loss": 81.10392999649048, "training_acc": 38.0, "val_loss": 15.875445306301117, "val_acc": 72.0}
{"epoch": 19, "training_loss": 66.22015452384949, "training_acc": 72.0, "val_loss": 14.811636507511139, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.2514374256134, "training_acc": 72.0, "val_loss": 14.829593896865845, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.371848583221436, "training_acc": 72.0, "val_loss": 16.86570644378662, "val_acc": 28.0}
{"epoch": 22, "training_loss": 64.44715237617493, "training_acc": 72.0, "val_loss": 16.123566031455994, "val_acc": 72.0}
{"epoch": 23, "training_loss": 63.210511445999146, "training_acc": 72.0, "val_loss": 15.169665217399597, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.037416219711304, "training_acc": 72.0, "val_loss": 15.086409449577332, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.683940410614014, "training_acc": 72.0, "val_loss": 15.630719065666199, "val_acc": 28.0}
{"epoch": 26, "training_loss": 60.81597828865051, "training_acc": 72.0, "val_loss": 16.20519608259201, "val_acc": 72.0}
{"epoch": 27, "training_loss": 62.89193081855774, "training_acc": 72.0, "val_loss": 16.062982380390167, "val_acc": 28.0}
{"epoch": 28, "training_loss": 61.78930974006653, "training_acc": 72.0, "val_loss": 16.613218188285828, "val_acc": 72.0}
{"epoch": 29, "training_loss": 63.948962450027466, "training_acc": 72.0, "val_loss": 16.58518612384796, "val_acc": 28.0}
{"epoch": 30, "training_loss": 62.37333679199219, "training_acc": 72.0, "val_loss": 20.297688245773315, "val_acc": 72.0}
{"epoch": 31, "training_loss": 82.13330459594727, "training_acc": 72.0, "val_loss": 22.129632532596588, "val_acc": 28.0}
{"epoch": 32, "training_loss": 79.61566472053528, "training_acc": 48.0, "val_loss": 24.88616704940796, "val_acc": 72.0}
{"epoch": 33, "training_loss": 98.83905529975891, "training_acc": 72.0, "val_loss": 15.00832736492157, "val_acc": 72.0}
{"epoch": 34, "training_loss": 69.5147430896759, "training_acc": 60.0, "val_loss": 14.942795038223267, "val_acc": 72.0}
{"epoch": 35, "training_loss": 65.93475461006165, "training_acc": 72.0, "val_loss": 15.17774760723114, "val_acc": 72.0}
{"epoch": 36, "training_loss": 72.56252002716064, "training_acc": 54.0, "val_loss": 17.054352164268494, "val_acc": 72.0}
{"epoch": 37, "training_loss": 81.71767234802246, "training_acc": 72.0, "val_loss": 15.394914150238037, "val_acc": 28.0}
{"epoch": 38, "training_loss": 69.24099159240723, "training_acc": 58.0, "val_loss": 17.834563553333282, "val_acc": 72.0}
