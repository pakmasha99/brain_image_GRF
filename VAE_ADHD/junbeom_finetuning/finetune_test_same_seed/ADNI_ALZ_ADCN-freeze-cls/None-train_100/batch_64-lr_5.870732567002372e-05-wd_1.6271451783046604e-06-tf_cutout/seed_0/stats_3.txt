"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 72.6351854801178, "training_acc": 28.0, "val_loss": 17.909182608127594, "val_acc": 28.0}
{"epoch": 1, "training_loss": 71.4133791923523, "training_acc": 28.0, "val_loss": 17.61048138141632, "val_acc": 28.0}
{"epoch": 2, "training_loss": 70.25897336006165, "training_acc": 28.0, "val_loss": 17.328602075576782, "val_acc": 28.0}
{"epoch": 3, "training_loss": 69.12335538864136, "training_acc": 60.0, "val_loss": 17.064471542835236, "val_acc": 28.0}
{"epoch": 4, "training_loss": 68.0611469745636, "training_acc": 72.0, "val_loss": 16.818198561668396, "val_acc": 28.0}
{"epoch": 5, "training_loss": 67.17504620552063, "training_acc": 72.0, "val_loss": 16.58938378095627, "val_acc": 28.0}
{"epoch": 6, "training_loss": 66.18222188949585, "training_acc": 72.0, "val_loss": 16.3801908493042, "val_acc": 28.0}
{"epoch": 7, "training_loss": 65.33163118362427, "training_acc": 72.0, "val_loss": 16.188107430934906, "val_acc": 28.0}
{"epoch": 8, "training_loss": 64.63712120056152, "training_acc": 72.0, "val_loss": 16.011063754558563, "val_acc": 28.0}
{"epoch": 9, "training_loss": 63.88763499259949, "training_acc": 72.0, "val_loss": 15.851879119873047, "val_acc": 28.0}
{"epoch": 10, "training_loss": 63.33489108085632, "training_acc": 72.0, "val_loss": 15.706899762153625, "val_acc": 28.0}
{"epoch": 11, "training_loss": 62.68584871292114, "training_acc": 72.0, "val_loss": 15.578261017799377, "val_acc": 28.0}
{"epoch": 12, "training_loss": 62.305906534194946, "training_acc": 72.0, "val_loss": 15.46420007944107, "val_acc": 28.0}
{"epoch": 13, "training_loss": 61.794788122177124, "training_acc": 72.0, "val_loss": 15.365876257419586, "val_acc": 24.0}
{"epoch": 14, "training_loss": 61.37703061103821, "training_acc": 72.0, "val_loss": 15.27995765209198, "val_acc": 72.0}
{"epoch": 15, "training_loss": 61.10644841194153, "training_acc": 72.0, "val_loss": 15.204082429409027, "val_acc": 72.0}
{"epoch": 16, "training_loss": 60.75565314292908, "training_acc": 72.0, "val_loss": 15.140199661254883, "val_acc": 72.0}
{"epoch": 17, "training_loss": 60.55001664161682, "training_acc": 72.0, "val_loss": 15.084804594516754, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.321770429611206, "training_acc": 72.0, "val_loss": 15.038295090198517, "val_acc": 72.0}
{"epoch": 19, "training_loss": 60.106690645217896, "training_acc": 72.0, "val_loss": 14.999482035636902, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.98637413978577, "training_acc": 72.0, "val_loss": 14.966298639774323, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.89841604232788, "training_acc": 72.0, "val_loss": 14.938685297966003, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.72588753700256, "training_acc": 72.0, "val_loss": 14.917100965976715, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.66239643096924, "training_acc": 72.0, "val_loss": 14.898796379566193, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.582560300827026, "training_acc": 72.0, "val_loss": 14.883451163768768, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.54005169868469, "training_acc": 72.0, "val_loss": 14.870741963386536, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.49124264717102, "training_acc": 72.0, "val_loss": 14.860320091247559, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.443217754364014, "training_acc": 72.0, "val_loss": 14.85234946012497, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.415029764175415, "training_acc": 72.0, "val_loss": 14.846526086330414, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.380642890930176, "training_acc": 72.0, "val_loss": 14.841945469379425, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.358402729034424, "training_acc": 72.0, "val_loss": 14.838027954101562, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.34831142425537, "training_acc": 72.0, "val_loss": 14.834889769554138, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.307029008865356, "training_acc": 72.0, "val_loss": 14.83265906572342, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.34372067451477, "training_acc": 72.0, "val_loss": 14.831213653087616, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.31570076942444, "training_acc": 72.0, "val_loss": 14.830106496810913, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.32151246070862, "training_acc": 72.0, "val_loss": 14.82924371957779, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.296818256378174, "training_acc": 72.0, "val_loss": 14.828923344612122, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.31857252120972, "training_acc": 72.0, "val_loss": 14.82866108417511, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.31841206550598, "training_acc": 72.0, "val_loss": 14.828439056873322, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.31387734413147, "training_acc": 72.0, "val_loss": 14.828266203403473, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.32114768028259, "training_acc": 72.0, "val_loss": 14.827989041805267, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.33594512939453, "training_acc": 72.0, "val_loss": 14.827573299407959, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.30991005897522, "training_acc": 72.0, "val_loss": 14.82720673084259, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.3071768283844, "training_acc": 72.0, "val_loss": 14.827051758766174, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.31689453125, "training_acc": 72.0, "val_loss": 14.826993644237518, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.301724672317505, "training_acc": 72.0, "val_loss": 14.827007055282593, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.31369137763977, "training_acc": 72.0, "val_loss": 14.827097952365875, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.30935025215149, "training_acc": 72.0, "val_loss": 14.827008545398712, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.309967041015625, "training_acc": 72.0, "val_loss": 14.827029407024384, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.31550645828247, "training_acc": 72.0, "val_loss": 14.826728403568268, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.28593063354492, "training_acc": 72.0, "val_loss": 14.826574921607971, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.29653358459473, "training_acc": 72.0, "val_loss": 14.826475083827972, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.30762076377869, "training_acc": 72.0, "val_loss": 14.826372265815735, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.30967736244202, "training_acc": 72.0, "val_loss": 14.826375246047974, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.32216835021973, "training_acc": 72.0, "val_loss": 14.826460182666779, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.313167095184326, "training_acc": 72.0, "val_loss": 14.826273918151855, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.28519916534424, "training_acc": 72.0, "val_loss": 14.826087653636932, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.30042052268982, "training_acc": 72.0, "val_loss": 14.825950562953949, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.312689542770386, "training_acc": 72.0, "val_loss": 14.825905859470367, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.287678480148315, "training_acc": 72.0, "val_loss": 14.826001226902008, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.31155514717102, "training_acc": 72.0, "val_loss": 14.826373755931854, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.32878112792969, "training_acc": 72.0, "val_loss": 14.826735854148865, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.30498480796814, "training_acc": 72.0, "val_loss": 14.827132225036621, "val_acc": 72.0}
{"epoch": 63, "training_loss": 59.308276653289795, "training_acc": 72.0, "val_loss": 14.827635884284973, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.30751347541809, "training_acc": 72.0, "val_loss": 14.827850461006165, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.31651997566223, "training_acc": 72.0, "val_loss": 14.82805460691452, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.293076515197754, "training_acc": 72.0, "val_loss": 14.828141033649445, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.30395531654358, "training_acc": 72.0, "val_loss": 14.82822448015213, "val_acc": 72.0}
{"epoch": 68, "training_loss": 59.31173288822174, "training_acc": 72.0, "val_loss": 14.828166365623474, "val_acc": 72.0}
{"epoch": 69, "training_loss": 59.31446576118469, "training_acc": 72.0, "val_loss": 14.828535914421082, "val_acc": 72.0}
{"epoch": 70, "training_loss": 59.303760290145874, "training_acc": 72.0, "val_loss": 14.82887715101242, "val_acc": 72.0}
{"epoch": 71, "training_loss": 59.316126346588135, "training_acc": 72.0, "val_loss": 14.828947186470032, "val_acc": 72.0}
{"epoch": 72, "training_loss": 59.303163051605225, "training_acc": 72.0, "val_loss": 14.828647673130035, "val_acc": 72.0}
{"epoch": 73, "training_loss": 59.312554597854614, "training_acc": 72.0, "val_loss": 14.828415215015411, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.28765034675598, "training_acc": 72.0, "val_loss": 14.828132092952728, "val_acc": 72.0}
{"epoch": 75, "training_loss": 59.30650496482849, "training_acc": 72.0, "val_loss": 14.827825129032135, "val_acc": 72.0}
{"epoch": 76, "training_loss": 59.3114550113678, "training_acc": 72.0, "val_loss": 14.8275226354599, "val_acc": 72.0}
{"epoch": 77, "training_loss": 59.31837606430054, "training_acc": 72.0, "val_loss": 14.82706069946289, "val_acc": 72.0}
