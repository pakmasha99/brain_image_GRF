"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 2963.1918716430664, "training_acc": 48.0, "val_loss": 839.5238876342773, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2453.5342621803284, "training_acc": 72.0, "val_loss": 1877.6277542114258, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6603.715377807617, "training_acc": 28.0, "val_loss": 104.94457483291626, "val_acc": 72.0}
{"epoch": 3, "training_loss": 655.8559112548828, "training_acc": 72.0, "val_loss": 402.8583526611328, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1476.0690307617188, "training_acc": 72.0, "val_loss": 69.38177943229675, "val_acc": 72.0}
{"epoch": 5, "training_loss": 974.8894424438477, "training_acc": 56.0, "val_loss": 217.92700290679932, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1085.510643005371, "training_acc": 40.0, "val_loss": 441.7116165161133, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1750.7874183654785, "training_acc": 72.0, "val_loss": 322.0698833465576, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1054.0569305419922, "training_acc": 72.0, "val_loss": 303.77471446990967, "val_acc": 28.0}
{"epoch": 9, "training_loss": 895.1824474334717, "training_acc": 28.0, "val_loss": 270.99270820617676, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1244.1428756713867, "training_acc": 72.0, "val_loss": 402.25181579589844, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1458.6778106689453, "training_acc": 72.0, "val_loss": 134.32109355926514, "val_acc": 72.0}
{"epoch": 12, "training_loss": 710.5738716125488, "training_acc": 56.0, "val_loss": 78.91348004341125, "val_acc": 28.0}
{"epoch": 13, "training_loss": 543.827953338623, "training_acc": 44.0, "val_loss": 352.30844020843506, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1393.1457977294922, "training_acc": 72.0, "val_loss": 241.51880741119385, "val_acc": 72.0}
{"epoch": 15, "training_loss": 690.5012340545654, "training_acc": 72.0, "val_loss": 376.22082233428955, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1262.2726459503174, "training_acc": 28.0, "val_loss": 180.76190948486328, "val_acc": 72.0}
{"epoch": 17, "training_loss": 892.3347244262695, "training_acc": 72.0, "val_loss": 272.79369831085205, "val_acc": 72.0}
{"epoch": 18, "training_loss": 983.4583740234375, "training_acc": 72.0, "val_loss": 15.973012149333954, "val_acc": 28.0}
{"epoch": 19, "training_loss": 152.2398223876953, "training_acc": 66.0, "val_loss": 113.97891044616699, "val_acc": 72.0}
{"epoch": 20, "training_loss": 489.2191562652588, "training_acc": 72.0, "val_loss": 66.79412722587585, "val_acc": 72.0}
{"epoch": 21, "training_loss": 457.048303604126, "training_acc": 56.0, "val_loss": 43.20913553237915, "val_acc": 72.0}
{"epoch": 22, "training_loss": 163.91002702713013, "training_acc": 72.0, "val_loss": 96.9029188156128, "val_acc": 28.0}
{"epoch": 23, "training_loss": 495.23653984069824, "training_acc": 40.0, "val_loss": 165.37569761276245, "val_acc": 72.0}
{"epoch": 24, "training_loss": 559.6020927429199, "training_acc": 72.0, "val_loss": 117.09716320037842, "val_acc": 28.0}
{"epoch": 25, "training_loss": 402.0699110031128, "training_acc": 42.0, "val_loss": 47.12279438972473, "val_acc": 72.0}
{"epoch": 26, "training_loss": 221.3677110671997, "training_acc": 62.0, "val_loss": 96.19078636169434, "val_acc": 72.0}
{"epoch": 27, "training_loss": 409.59844398498535, "training_acc": 72.0, "val_loss": 29.315131902694702, "val_acc": 72.0}
{"epoch": 28, "training_loss": 366.0044250488281, "training_acc": 64.0, "val_loss": 18.464459478855133, "val_acc": 28.0}
{"epoch": 29, "training_loss": 239.27134895324707, "training_acc": 46.0, "val_loss": 183.58488082885742, "val_acc": 72.0}
{"epoch": 30, "training_loss": 646.3528575897217, "training_acc": 72.0, "val_loss": 55.704307556152344, "val_acc": 28.0}
{"epoch": 31, "training_loss": 325.15573501586914, "training_acc": 40.0, "val_loss": 91.14476442337036, "val_acc": 72.0}
{"epoch": 32, "training_loss": 332.7199878692627, "training_acc": 52.0, "val_loss": 120.2782392501831, "val_acc": 72.0}
{"epoch": 33, "training_loss": 475.30860710144043, "training_acc": 72.0, "val_loss": 57.005107402801514, "val_acc": 72.0}
{"epoch": 34, "training_loss": 390.57944679260254, "training_acc": 58.0, "val_loss": 51.73702836036682, "val_acc": 72.0}
{"epoch": 35, "training_loss": 219.4609603881836, "training_acc": 72.0, "val_loss": 76.83843970298767, "val_acc": 28.0}
{"epoch": 36, "training_loss": 430.09594917297363, "training_acc": 40.0, "val_loss": 147.47982025146484, "val_acc": 72.0}
{"epoch": 37, "training_loss": 496.08532667160034, "training_acc": 72.0, "val_loss": 196.1604118347168, "val_acc": 28.0}
