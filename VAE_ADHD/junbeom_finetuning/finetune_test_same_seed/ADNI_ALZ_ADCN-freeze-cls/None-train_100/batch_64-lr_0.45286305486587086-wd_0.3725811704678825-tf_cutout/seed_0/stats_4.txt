"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1594.4667053222656, "training_acc": 48.0, "val_loss": 1009.7818374633789, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2863.82061958313, "training_acc": 72.0, "val_loss": 1874.418830871582, "val_acc": 28.0}
{"epoch": 2, "training_loss": 6380.680755615234, "training_acc": 28.0, "val_loss": 226.25606060028076, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1190.6085243225098, "training_acc": 72.0, "val_loss": 518.5236930847168, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1876.8875885009766, "training_acc": 72.0, "val_loss": 132.27816820144653, "val_acc": 72.0}
{"epoch": 5, "training_loss": 745.2278823852539, "training_acc": 66.0, "val_loss": 233.3585500717163, "val_acc": 28.0}
{"epoch": 6, "training_loss": 859.0647659301758, "training_acc": 48.0, "val_loss": 409.85350608825684, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1622.207820892334, "training_acc": 72.0, "val_loss": 276.2626886367798, "val_acc": 72.0}
{"epoch": 8, "training_loss": 807.171727180481, "training_acc": 72.0, "val_loss": 518.7263011932373, "val_acc": 28.0}
{"epoch": 9, "training_loss": 1790.723762512207, "training_acc": 28.0, "val_loss": 204.65352535247803, "val_acc": 72.0}
{"epoch": 10, "training_loss": 955.032642364502, "training_acc": 72.0, "val_loss": 369.70694065093994, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1365.5503730773926, "training_acc": 72.0, "val_loss": 122.20747470855713, "val_acc": 72.0}
{"epoch": 12, "training_loss": 895.1684379577637, "training_acc": 48.0, "val_loss": 32.73651301860809, "val_acc": 28.0}
{"epoch": 13, "training_loss": 434.8160858154297, "training_acc": 44.0, "val_loss": 344.25628185272217, "val_acc": 72.0}
{"epoch": 14, "training_loss": 1355.0769729614258, "training_acc": 72.0, "val_loss": 206.19966983795166, "val_acc": 72.0}
{"epoch": 15, "training_loss": 557.0103325843811, "training_acc": 72.0, "val_loss": 488.9700412750244, "val_acc": 28.0}
{"epoch": 16, "training_loss": 1625.2744064331055, "training_acc": 28.0, "val_loss": 188.14455270767212, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1033.7465286254883, "training_acc": 72.0, "val_loss": 305.02917766571045, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1080.9714374542236, "training_acc": 72.0, "val_loss": 18.85490119457245, "val_acc": 72.0}
{"epoch": 19, "training_loss": 691.2949066162109, "training_acc": 56.0, "val_loss": 205.6368112564087, "val_acc": 28.0}
{"epoch": 20, "training_loss": 780.6064472198486, "training_acc": 46.0, "val_loss": 342.0840263366699, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1366.975341796875, "training_acc": 72.0, "val_loss": 263.9151334762573, "val_acc": 72.0}
{"epoch": 22, "training_loss": 952.942262172699, "training_acc": 72.0, "val_loss": 228.4055471420288, "val_acc": 28.0}
{"epoch": 23, "training_loss": 624.6122188568115, "training_acc": 42.0, "val_loss": 28.842806816101074, "val_acc": 72.0}
{"epoch": 24, "training_loss": 216.52270889282227, "training_acc": 58.0, "val_loss": 123.80448579788208, "val_acc": 72.0}
{"epoch": 25, "training_loss": 570.6001300811768, "training_acc": 72.0, "val_loss": 93.11741590499878, "val_acc": 72.0}
{"epoch": 26, "training_loss": 437.19238662719727, "training_acc": 56.0, "val_loss": 64.27038908004761, "val_acc": 72.0}
{"epoch": 27, "training_loss": 264.18957710266113, "training_acc": 72.0, "val_loss": 64.04174566268921, "val_acc": 28.0}
{"epoch": 28, "training_loss": 455.5405101776123, "training_acc": 36.0, "val_loss": 139.29582834243774, "val_acc": 72.0}
{"epoch": 29, "training_loss": 418.7383918762207, "training_acc": 72.0, "val_loss": 269.14031505584717, "val_acc": 28.0}
{"epoch": 30, "training_loss": 724.3546280860901, "training_acc": 28.0, "val_loss": 238.21547031402588, "val_acc": 72.0}
{"epoch": 31, "training_loss": 1036.689712524414, "training_acc": 72.0, "val_loss": 319.5955753326416, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1152.0751342773438, "training_acc": 72.0, "val_loss": 65.6288206577301, "val_acc": 72.0}
{"epoch": 33, "training_loss": 552.8849296569824, "training_acc": 62.0, "val_loss": 172.05926179885864, "val_acc": 28.0}
{"epoch": 34, "training_loss": 678.2355442047119, "training_acc": 46.0, "val_loss": 308.1448793411255, "val_acc": 72.0}
{"epoch": 35, "training_loss": 1216.1154098510742, "training_acc": 72.0, "val_loss": 208.28516483306885, "val_acc": 72.0}
{"epoch": 36, "training_loss": 663.9928503036499, "training_acc": 72.0, "val_loss": 382.3739528656006, "val_acc": 28.0}
{"epoch": 37, "training_loss": 1214.2543087005615, "training_acc": 28.0, "val_loss": 223.7635850906372, "val_acc": 72.0}
