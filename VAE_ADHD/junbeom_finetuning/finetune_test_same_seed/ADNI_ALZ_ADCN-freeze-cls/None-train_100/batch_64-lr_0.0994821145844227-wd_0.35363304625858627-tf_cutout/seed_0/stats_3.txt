"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 429.6202049255371, "training_acc": 46.0, "val_loss": 259.19432640075684, "val_acc": 72.0}
{"epoch": 1, "training_loss": 859.1389760971069, "training_acc": 72.0, "val_loss": 213.64328861236572, "val_acc": 28.0}
{"epoch": 2, "training_loss": 685.4381446838379, "training_acc": 28.0, "val_loss": 90.82380533218384, "val_acc": 72.0}
{"epoch": 3, "training_loss": 505.15066146850586, "training_acc": 72.0, "val_loss": 184.67252254486084, "val_acc": 72.0}
{"epoch": 4, "training_loss": 721.4836597442627, "training_acc": 72.0, "val_loss": 116.41044616699219, "val_acc": 72.0}
{"epoch": 5, "training_loss": 367.36606788635254, "training_acc": 72.0, "val_loss": 81.95776343345642, "val_acc": 28.0}
{"epoch": 6, "training_loss": 362.23843574523926, "training_acc": 28.0, "val_loss": 30.155202746391296, "val_acc": 72.0}
{"epoch": 7, "training_loss": 180.58349704742432, "training_acc": 72.0, "val_loss": 75.9990930557251, "val_acc": 72.0}
{"epoch": 8, "training_loss": 279.6770610809326, "training_acc": 72.0, "val_loss": 22.52519428730011, "val_acc": 72.0}
{"epoch": 9, "training_loss": 185.39842987060547, "training_acc": 54.0, "val_loss": 49.1472452878952, "val_acc": 28.0}
{"epoch": 10, "training_loss": 237.91015625, "training_acc": 34.0, "val_loss": 71.79225087165833, "val_acc": 72.0}
{"epoch": 11, "training_loss": 293.5305004119873, "training_acc": 72.0, "val_loss": 54.38418984413147, "val_acc": 72.0}
{"epoch": 12, "training_loss": 170.0567169189453, "training_acc": 72.0, "val_loss": 80.19770383834839, "val_acc": 28.0}
{"epoch": 13, "training_loss": 272.03463220596313, "training_acc": 28.0, "val_loss": 36.01507842540741, "val_acc": 72.0}
{"epoch": 14, "training_loss": 190.77262783050537, "training_acc": 72.0, "val_loss": 63.4874165058136, "val_acc": 72.0}
{"epoch": 15, "training_loss": 226.86092567443848, "training_acc": 72.0, "val_loss": 14.789023995399475, "val_acc": 72.0}
{"epoch": 16, "training_loss": 115.37804317474365, "training_acc": 60.0, "val_loss": 20.05135715007782, "val_acc": 28.0}
{"epoch": 17, "training_loss": 90.7333436012268, "training_acc": 48.0, "val_loss": 52.61411666870117, "val_acc": 72.0}
{"epoch": 18, "training_loss": 202.39557218551636, "training_acc": 72.0, "val_loss": 23.891906440258026, "val_acc": 72.0}
{"epoch": 19, "training_loss": 122.47239303588867, "training_acc": 56.0, "val_loss": 20.856525003910065, "val_acc": 28.0}
{"epoch": 20, "training_loss": 98.61474084854126, "training_acc": 44.0, "val_loss": 42.78089106082916, "val_acc": 72.0}
{"epoch": 21, "training_loss": 156.14120435714722, "training_acc": 72.0, "val_loss": 15.419237315654755, "val_acc": 28.0}
{"epoch": 22, "training_loss": 109.93321132659912, "training_acc": 52.0, "val_loss": 18.90028715133667, "val_acc": 72.0}
{"epoch": 23, "training_loss": 97.68804025650024, "training_acc": 72.0, "val_loss": 25.348839163780212, "val_acc": 72.0}
{"epoch": 24, "training_loss": 91.15933203697205, "training_acc": 56.0, "val_loss": 21.774224936962128, "val_acc": 28.0}
{"epoch": 25, "training_loss": 86.31708574295044, "training_acc": 44.0, "val_loss": 25.33486783504486, "val_acc": 72.0}
{"epoch": 26, "training_loss": 88.7175362110138, "training_acc": 72.0, "val_loss": 26.18105709552765, "val_acc": 28.0}
{"epoch": 27, "training_loss": 95.27044129371643, "training_acc": 42.0, "val_loss": 20.651744306087494, "val_acc": 72.0}
{"epoch": 28, "training_loss": 74.23289632797241, "training_acc": 72.0, "val_loss": 21.21930718421936, "val_acc": 28.0}
{"epoch": 29, "training_loss": 72.93392944335938, "training_acc": 48.0, "val_loss": 21.8936949968338, "val_acc": 72.0}
{"epoch": 30, "training_loss": 76.85627865791321, "training_acc": 72.0, "val_loss": 33.58321189880371, "val_acc": 28.0}
{"epoch": 31, "training_loss": 112.3210678100586, "training_acc": 42.0, "val_loss": 21.601398289203644, "val_acc": 72.0}
{"epoch": 32, "training_loss": 82.93495273590088, "training_acc": 72.0, "val_loss": 16.039977967739105, "val_acc": 28.0}
{"epoch": 33, "training_loss": 60.594993591308594, "training_acc": 72.0, "val_loss": 17.673304677009583, "val_acc": 72.0}
{"epoch": 34, "training_loss": 70.21785855293274, "training_acc": 72.0, "val_loss": 14.80093002319336, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.49074339866638, "training_acc": 72.0, "val_loss": 14.76687639951706, "val_acc": 72.0}
{"epoch": 36, "training_loss": 62.61791372299194, "training_acc": 72.0, "val_loss": 18.075980246067047, "val_acc": 72.0}
{"epoch": 37, "training_loss": 70.7486799955368, "training_acc": 72.0, "val_loss": 14.873585104942322, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.59689998626709, "training_acc": 72.0, "val_loss": 14.854322373867035, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.285090923309326, "training_acc": 72.0, "val_loss": 15.72970300912857, "val_acc": 72.0}
{"epoch": 40, "training_loss": 61.207645654678345, "training_acc": 72.0, "val_loss": 20.221564173698425, "val_acc": 28.0}
{"epoch": 41, "training_loss": 77.16786742210388, "training_acc": 44.0, "val_loss": 18.0826336145401, "val_acc": 72.0}
{"epoch": 42, "training_loss": 93.12456750869751, "training_acc": 48.0, "val_loss": 23.16814810037613, "val_acc": 72.0}
{"epoch": 43, "training_loss": 96.4840841293335, "training_acc": 72.0, "val_loss": 14.786362648010254, "val_acc": 72.0}
{"epoch": 44, "training_loss": 86.58739709854126, "training_acc": 54.0, "val_loss": 25.831791758537292, "val_acc": 72.0}
{"epoch": 45, "training_loss": 126.214280128479, "training_acc": 72.0, "val_loss": 19.57477331161499, "val_acc": 72.0}
{"epoch": 46, "training_loss": 131.0624008178711, "training_acc": 54.0, "val_loss": 14.9404376745224, "val_acc": 72.0}
{"epoch": 47, "training_loss": 84.46140718460083, "training_acc": 72.0, "val_loss": 23.86297583580017, "val_acc": 72.0}
{"epoch": 48, "training_loss": 100.16885352134705, "training_acc": 54.0, "val_loss": 14.907434582710266, "val_acc": 72.0}
{"epoch": 49, "training_loss": 74.66401863098145, "training_acc": 72.0, "val_loss": 15.111953020095825, "val_acc": 72.0}
{"epoch": 50, "training_loss": 63.1313579082489, "training_acc": 60.0, "val_loss": 16.241362690925598, "val_acc": 72.0}
{"epoch": 51, "training_loss": 67.20386862754822, "training_acc": 72.0, "val_loss": 20.622001588344574, "val_acc": 28.0}
{"epoch": 52, "training_loss": 78.36063408851624, "training_acc": 42.0, "val_loss": 16.002735495567322, "val_acc": 72.0}
{"epoch": 53, "training_loss": 79.07363176345825, "training_acc": 50.0, "val_loss": 23.1876939535141, "val_acc": 72.0}
{"epoch": 54, "training_loss": 91.20630884170532, "training_acc": 72.0, "val_loss": 15.153349936008453, "val_acc": 72.0}
