"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 178.93589973449707, "training_acc": 38.0, "val_loss": 63.82438540458679, "val_acc": 72.0}
{"epoch": 1, "training_loss": 221.41362762451172, "training_acc": 72.0, "val_loss": 16.519422829151154, "val_acc": 28.0}
{"epoch": 2, "training_loss": 104.78081750869751, "training_acc": 58.0, "val_loss": 19.83746886253357, "val_acc": 28.0}
{"epoch": 3, "training_loss": 94.39935064315796, "training_acc": 38.0, "val_loss": 31.938430666923523, "val_acc": 72.0}
{"epoch": 4, "training_loss": 127.51738786697388, "training_acc": 72.0, "val_loss": 23.019947111606598, "val_acc": 72.0}
{"epoch": 5, "training_loss": 78.29210829734802, "training_acc": 72.0, "val_loss": 27.31691002845764, "val_acc": 28.0}
{"epoch": 6, "training_loss": 107.90198802947998, "training_acc": 28.0, "val_loss": 14.80182409286499, "val_acc": 72.0}
{"epoch": 7, "training_loss": 65.68008852005005, "training_acc": 72.0, "val_loss": 25.682953000068665, "val_acc": 72.0}
{"epoch": 8, "training_loss": 101.5217342376709, "training_acc": 72.0, "val_loss": 18.524129688739777, "val_acc": 72.0}
{"epoch": 9, "training_loss": 71.32744979858398, "training_acc": 72.0, "val_loss": 22.057120501995087, "val_acc": 28.0}
{"epoch": 10, "training_loss": 84.18137884140015, "training_acc": 28.0, "val_loss": 14.824523031711578, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.111090898513794, "training_acc": 72.0, "val_loss": 20.137318968772888, "val_acc": 72.0}
{"epoch": 12, "training_loss": 78.46246767044067, "training_acc": 72.0, "val_loss": 15.145321190357208, "val_acc": 72.0}
{"epoch": 13, "training_loss": 61.37290620803833, "training_acc": 72.0, "val_loss": 19.329388439655304, "val_acc": 28.0}
{"epoch": 14, "training_loss": 71.54289174079895, "training_acc": 48.0, "val_loss": 15.647721290588379, "val_acc": 72.0}
{"epoch": 15, "training_loss": 65.77284979820251, "training_acc": 72.0, "val_loss": 18.665583431720734, "val_acc": 72.0}
{"epoch": 16, "training_loss": 70.74947738647461, "training_acc": 72.0, "val_loss": 15.136006474494934, "val_acc": 72.0}
{"epoch": 17, "training_loss": 68.90143609046936, "training_acc": 50.0, "val_loss": 15.553221106529236, "val_acc": 28.0}
{"epoch": 18, "training_loss": 63.335442543029785, "training_acc": 72.0, "val_loss": 17.461960017681122, "val_acc": 72.0}
{"epoch": 19, "training_loss": 69.79224252700806, "training_acc": 72.0, "val_loss": 14.807653427124023, "val_acc": 72.0}
{"epoch": 20, "training_loss": 63.930708169937134, "training_acc": 71.0, "val_loss": 17.11409091949463, "val_acc": 28.0}
{"epoch": 21, "training_loss": 64.22381210327148, "training_acc": 74.0, "val_loss": 16.28318727016449, "val_acc": 72.0}
{"epoch": 22, "training_loss": 66.78037285804749, "training_acc": 72.0, "val_loss": 15.934181213378906, "val_acc": 72.0}
{"epoch": 23, "training_loss": 65.75291514396667, "training_acc": 72.0, "val_loss": 15.900924801826477, "val_acc": 28.0}
{"epoch": 24, "training_loss": 62.948296546936035, "training_acc": 72.0, "val_loss": 14.810098707675934, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.92747116088867, "training_acc": 72.0, "val_loss": 14.847657084465027, "val_acc": 72.0}
