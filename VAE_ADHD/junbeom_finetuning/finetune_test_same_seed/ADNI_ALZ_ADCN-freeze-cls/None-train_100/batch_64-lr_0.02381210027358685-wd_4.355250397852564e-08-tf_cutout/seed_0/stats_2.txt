"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 156.60815525054932, "training_acc": 42.0, "val_loss": 62.178993225097656, "val_acc": 72.0}
{"epoch": 1, "training_loss": 220.37625646591187, "training_acc": 72.0, "val_loss": 29.648077487945557, "val_acc": 28.0}
{"epoch": 2, "training_loss": 112.18894052505493, "training_acc": 28.0, "val_loss": 17.24749356508255, "val_acc": 72.0}
{"epoch": 3, "training_loss": 79.01262760162354, "training_acc": 72.0, "val_loss": 25.764751434326172, "val_acc": 72.0}
{"epoch": 4, "training_loss": 91.59568881988525, "training_acc": 72.0, "val_loss": 16.237148642539978, "val_acc": 28.0}
{"epoch": 5, "training_loss": 83.43690824508667, "training_acc": 52.0, "val_loss": 16.608405113220215, "val_acc": 28.0}
{"epoch": 6, "training_loss": 67.3807783126831, "training_acc": 72.0, "val_loss": 22.549298405647278, "val_acc": 72.0}
{"epoch": 7, "training_loss": 88.65847945213318, "training_acc": 72.0, "val_loss": 16.841590404510498, "val_acc": 72.0}
{"epoch": 8, "training_loss": 67.21691513061523, "training_acc": 72.0, "val_loss": 19.492241740226746, "val_acc": 28.0}
{"epoch": 9, "training_loss": 72.89631032943726, "training_acc": 46.0, "val_loss": 15.520165860652924, "val_acc": 72.0}
{"epoch": 10, "training_loss": 68.7091417312622, "training_acc": 72.0, "val_loss": 17.95862913131714, "val_acc": 72.0}
{"epoch": 11, "training_loss": 70.70530796051025, "training_acc": 72.0, "val_loss": 15.945956110954285, "val_acc": 28.0}
{"epoch": 12, "training_loss": 63.88700199127197, "training_acc": 72.0, "val_loss": 15.231962502002716, "val_acc": 72.0}
{"epoch": 13, "training_loss": 62.01299285888672, "training_acc": 72.0, "val_loss": 14.92445170879364, "val_acc": 72.0}
{"epoch": 14, "training_loss": 60.29537487030029, "training_acc": 72.0, "val_loss": 15.039761364459991, "val_acc": 72.0}
{"epoch": 15, "training_loss": 61.11224722862244, "training_acc": 72.0, "val_loss": 15.005108714103699, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.26680064201355, "training_acc": 72.0, "val_loss": 15.630462765693665, "val_acc": 72.0}
{"epoch": 17, "training_loss": 61.985607385635376, "training_acc": 72.0, "val_loss": 14.820794761180878, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.348581314086914, "training_acc": 72.0, "val_loss": 15.336142480373383, "val_acc": 48.0}
{"epoch": 19, "training_loss": 60.40895938873291, "training_acc": 72.0, "val_loss": 15.147572755813599, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.32787227630615, "training_acc": 72.0, "val_loss": 14.880964159965515, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.01064372062683, "training_acc": 72.0, "val_loss": 15.436942875385284, "val_acc": 28.0}
{"epoch": 22, "training_loss": 62.38895773887634, "training_acc": 72.0, "val_loss": 14.980705082416534, "val_acc": 72.0}
{"epoch": 23, "training_loss": 61.354442834854126, "training_acc": 72.0, "val_loss": 15.710404515266418, "val_acc": 72.0}
{"epoch": 24, "training_loss": 60.02817416191101, "training_acc": 72.0, "val_loss": 17.076949775218964, "val_acc": 28.0}
{"epoch": 25, "training_loss": 67.18298029899597, "training_acc": 73.0, "val_loss": 14.825071394443512, "val_acc": 72.0}
{"epoch": 26, "training_loss": 62.61692023277283, "training_acc": 72.0, "val_loss": 15.536260604858398, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.66228222846985, "training_acc": 72.0, "val_loss": 16.645614802837372, "val_acc": 28.0}
{"epoch": 28, "training_loss": 64.80917072296143, "training_acc": 72.0, "val_loss": 15.009437501430511, "val_acc": 72.0}
{"epoch": 29, "training_loss": 60.15555500984192, "training_acc": 72.0, "val_loss": 15.301847457885742, "val_acc": 72.0}
{"epoch": 30, "training_loss": 60.949477672576904, "training_acc": 72.0, "val_loss": 15.191687643527985, "val_acc": 72.0}
{"epoch": 31, "training_loss": 61.54871416091919, "training_acc": 72.0, "val_loss": 14.821930229663849, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.31576490402222, "training_acc": 72.0, "val_loss": 15.149766206741333, "val_acc": 72.0}
{"epoch": 33, "training_loss": 60.219629526138306, "training_acc": 72.0, "val_loss": 14.85118418931961, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.290432929992676, "training_acc": 72.0, "val_loss": 15.355315804481506, "val_acc": 72.0}
{"epoch": 35, "training_loss": 60.9419686794281, "training_acc": 72.0, "val_loss": 14.884491264820099, "val_acc": 72.0}
{"epoch": 36, "training_loss": 58.531922817230225, "training_acc": 72.0, "val_loss": 15.593217313289642, "val_acc": 28.0}
