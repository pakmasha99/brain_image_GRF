"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 24328.956939697266, "training_acc": 42.0, "val_loss": 1652.0139694213867, "val_acc": 28.0}
{"epoch": 1, "training_loss": 17906.781860351562, "training_acc": 40.0, "val_loss": 3543.147659301758, "val_acc": 72.0}
{"epoch": 2, "training_loss": 11889.807815551758, "training_acc": 50.0, "val_loss": 4701.442718505859, "val_acc": 72.0}
{"epoch": 3, "training_loss": 16066.709503173828, "training_acc": 72.0, "val_loss": 664.295768737793, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5497.352691650391, "training_acc": 58.0, "val_loss": 2419.7967529296875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 8281.95011138916, "training_acc": 72.0, "val_loss": 565.4585361480713, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5522.640045166016, "training_acc": 44.0, "val_loss": 1651.722526550293, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5008.326547622681, "training_acc": 50.0, "val_loss": 2478.935432434082, "val_acc": 72.0}
{"epoch": 8, "training_loss": 8228.855453491211, "training_acc": 72.0, "val_loss": 96.12123370170593, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2618.3755950927734, "training_acc": 50.0, "val_loss": 1653.6584854125977, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4769.121524810791, "training_acc": 72.0, "val_loss": 2188.286590576172, "val_acc": 28.0}
{"epoch": 11, "training_loss": 8158.099578857422, "training_acc": 44.0, "val_loss": 850.4025459289551, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3875.502960205078, "training_acc": 54.0, "val_loss": 2202.715301513672, "val_acc": 72.0}
{"epoch": 13, "training_loss": 7788.814064025879, "training_acc": 72.0, "val_loss": 226.4042854309082, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3146.1057739257812, "training_acc": 60.0, "val_loss": 1585.3903770446777, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4945.340103149414, "training_acc": 72.0, "val_loss": 1430.1027297973633, "val_acc": 28.0}
{"epoch": 16, "training_loss": 7225.878570556641, "training_acc": 40.0, "val_loss": 884.274959564209, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4453.318069458008, "training_acc": 50.0, "val_loss": 2226.267433166504, "val_acc": 72.0}
{"epoch": 18, "training_loss": 7514.102966308594, "training_acc": 72.0, "val_loss": 49.09818172454834, "val_acc": 72.0}
{"epoch": 19, "training_loss": 5138.890640258789, "training_acc": 50.0, "val_loss": 1513.8315200805664, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4915.093246459961, "training_acc": 72.0, "val_loss": 896.2504386901855, "val_acc": 28.0}
{"epoch": 21, "training_loss": 6416.847869873047, "training_acc": 38.0, "val_loss": 974.134349822998, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3071.3196983337402, "training_acc": 56.0, "val_loss": 2143.1949615478516, "val_acc": 72.0}
{"epoch": 23, "training_loss": 7332.421035766602, "training_acc": 72.0, "val_loss": 162.0732545852661, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3706.697052001953, "training_acc": 56.0, "val_loss": 1501.6634941101074, "val_acc": 72.0}
{"epoch": 25, "training_loss": 4748.921775817871, "training_acc": 72.0, "val_loss": 1157.3381423950195, "val_acc": 28.0}
{"epoch": 26, "training_loss": 5228.554748535156, "training_acc": 46.0, "val_loss": 1033.2651138305664, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2893.5546550750732, "training_acc": 56.0, "val_loss": 2229.4593811035156, "val_acc": 72.0}
{"epoch": 28, "training_loss": 7665.784133911133, "training_acc": 72.0, "val_loss": 229.9915313720703, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3650.389678955078, "training_acc": 56.0, "val_loss": 1560.433292388916, "val_acc": 72.0}
{"epoch": 30, "training_loss": 5225.187267303467, "training_acc": 72.0, "val_loss": 621.5264797210693, "val_acc": 28.0}
{"epoch": 31, "training_loss": 6309.2957763671875, "training_acc": 36.0, "val_loss": 1028.4184455871582, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3774.27725982666, "training_acc": 52.0, "val_loss": 2251.1865615844727, "val_acc": 72.0}
{"epoch": 33, "training_loss": 7853.64501953125, "training_acc": 72.0, "val_loss": 316.2269592285156, "val_acc": 72.0}
{"epoch": 34, "training_loss": 2862.3565368652344, "training_acc": 60.0, "val_loss": 1554.2719841003418, "val_acc": 72.0}
{"epoch": 35, "training_loss": 4967.18017578125, "training_acc": 72.0, "val_loss": 975.8829116821289, "val_acc": 28.0}
{"epoch": 36, "training_loss": 4864.991607666016, "training_acc": 46.0, "val_loss": 1095.1464653015137, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2593.1281089782715, "training_acc": 72.0, "val_loss": 3070.8383560180664, "val_acc": 28.0}
