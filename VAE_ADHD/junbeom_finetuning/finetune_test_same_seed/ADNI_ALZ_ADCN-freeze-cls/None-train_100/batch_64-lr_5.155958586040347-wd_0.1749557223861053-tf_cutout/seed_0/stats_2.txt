"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 19967.607097625732, "training_acc": 46.0, "val_loss": 256.79571628570557, "val_acc": 28.0}
{"epoch": 1, "training_loss": 8902.904296875, "training_acc": 50.0, "val_loss": 5130.68733215332, "val_acc": 72.0}
{"epoch": 2, "training_loss": 13580.347198486328, "training_acc": 72.0, "val_loss": 6395.611190795898, "val_acc": 28.0}
{"epoch": 3, "training_loss": 21253.794860839844, "training_acc": 42.0, "val_loss": 1011.4522933959961, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5690.018493652344, "training_acc": 58.0, "val_loss": 2822.182083129883, "val_acc": 72.0}
{"epoch": 5, "training_loss": 9222.259780883789, "training_acc": 72.0, "val_loss": 797.2406387329102, "val_acc": 28.0}
{"epoch": 6, "training_loss": 6732.045959472656, "training_acc": 42.0, "val_loss": 1570.3184127807617, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3755.609016418457, "training_acc": 72.0, "val_loss": 4065.493392944336, "val_acc": 28.0}
{"epoch": 8, "training_loss": 11919.411575317383, "training_acc": 46.0, "val_loss": 478.1904697418213, "val_acc": 72.0}
{"epoch": 9, "training_loss": 4603.806549072266, "training_acc": 54.0, "val_loss": 2032.3028564453125, "val_acc": 72.0}
{"epoch": 10, "training_loss": 6688.624282836914, "training_acc": 72.0, "val_loss": 582.6603889465332, "val_acc": 28.0}
{"epoch": 11, "training_loss": 4406.4022216796875, "training_acc": 46.0, "val_loss": 1392.458438873291, "val_acc": 72.0}
{"epoch": 12, "training_loss": 3695.7775917053223, "training_acc": 72.0, "val_loss": 2742.2645568847656, "val_acc": 28.0}
{"epoch": 13, "training_loss": 8777.919616699219, "training_acc": 46.0, "val_loss": 685.2925777435303, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3525.7582092285156, "training_acc": 56.0, "val_loss": 2041.5351867675781, "val_acc": 72.0}
{"epoch": 15, "training_loss": 7042.784934997559, "training_acc": 72.0, "val_loss": 44.38839554786682, "val_acc": 72.0}
{"epoch": 16, "training_loss": 3644.338119506836, "training_acc": 58.0, "val_loss": 1477.8915405273438, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4749.267822265625, "training_acc": 72.0, "val_loss": 1186.0160827636719, "val_acc": 28.0}
{"epoch": 18, "training_loss": 5912.3753662109375, "training_acc": 44.0, "val_loss": 1089.8544311523438, "val_acc": 72.0}
{"epoch": 19, "training_loss": 3866.1919860839844, "training_acc": 52.0, "val_loss": 2393.425178527832, "val_acc": 72.0}
{"epoch": 20, "training_loss": 8286.523681640625, "training_acc": 72.0, "val_loss": 316.4212465286255, "val_acc": 72.0}
{"epoch": 21, "training_loss": 4894.2857666015625, "training_acc": 50.0, "val_loss": 1785.8396530151367, "val_acc": 72.0}
{"epoch": 22, "training_loss": 6109.79972076416, "training_acc": 72.0, "val_loss": 187.98654079437256, "val_acc": 28.0}
{"epoch": 23, "training_loss": 3763.5531005859375, "training_acc": 44.0, "val_loss": 1365.9567832946777, "val_acc": 72.0}
{"epoch": 24, "training_loss": 3651.093879699707, "training_acc": 72.0, "val_loss": 2469.724464416504, "val_acc": 28.0}
{"epoch": 25, "training_loss": 7995.561874389648, "training_acc": 46.0, "val_loss": 652.0761966705322, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4044.241912841797, "training_acc": 52.0, "val_loss": 2030.8055877685547, "val_acc": 72.0}
{"epoch": 27, "training_loss": 6897.007308959961, "training_acc": 72.0, "val_loss": 49.233028292655945, "val_acc": 72.0}
{"epoch": 28, "training_loss": 4224.402908325195, "training_acc": 54.0, "val_loss": 1483.4674835205078, "val_acc": 72.0}
{"epoch": 29, "training_loss": 4647.000991821289, "training_acc": 72.0, "val_loss": 1370.1469421386719, "val_acc": 28.0}
{"epoch": 30, "training_loss": 6116.301483154297, "training_acc": 44.0, "val_loss": 941.9025421142578, "val_acc": 72.0}
{"epoch": 31, "training_loss": 3067.668113708496, "training_acc": 56.0, "val_loss": 2173.1685638427734, "val_acc": 72.0}
{"epoch": 32, "training_loss": 7365.82487487793, "training_acc": 72.0, "val_loss": 112.03209161758423, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3172.535171508789, "training_acc": 60.0, "val_loss": 1402.226448059082, "val_acc": 72.0}
{"epoch": 34, "training_loss": 4287.169937133789, "training_acc": 72.0, "val_loss": 1616.3150787353516, "val_acc": 28.0}
