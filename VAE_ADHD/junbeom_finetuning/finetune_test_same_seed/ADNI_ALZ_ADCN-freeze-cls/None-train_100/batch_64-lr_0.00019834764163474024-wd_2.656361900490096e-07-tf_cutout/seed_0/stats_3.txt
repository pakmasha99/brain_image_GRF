"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 80.82592368125916, "training_acc": 28.0, "val_loss": 19.127042591571808, "val_acc": 28.0}
{"epoch": 1, "training_loss": 75.9033739566803, "training_acc": 28.0, "val_loss": 17.992152273654938, "val_acc": 28.0}
{"epoch": 2, "training_loss": 71.2845458984375, "training_acc": 28.0, "val_loss": 17.052431404590607, "val_acc": 28.0}
{"epoch": 3, "training_loss": 67.66841721534729, "training_acc": 72.0, "val_loss": 16.2947416305542, "val_acc": 28.0}
{"epoch": 4, "training_loss": 64.61712121963501, "training_acc": 72.0, "val_loss": 15.717899799346924, "val_acc": 28.0}
{"epoch": 5, "training_loss": 62.67016649246216, "training_acc": 72.0, "val_loss": 15.301689505577087, "val_acc": 76.0}
{"epoch": 6, "training_loss": 60.887211561203, "training_acc": 72.0, "val_loss": 15.0321826338768, "val_acc": 72.0}
{"epoch": 7, "training_loss": 60.17106080055237, "training_acc": 72.0, "val_loss": 14.875467121601105, "val_acc": 72.0}
{"epoch": 8, "training_loss": 59.35754728317261, "training_acc": 72.0, "val_loss": 14.80768620967865, "val_acc": 72.0}
{"epoch": 9, "training_loss": 59.448968172073364, "training_acc": 72.0, "val_loss": 14.79676365852356, "val_acc": 72.0}
{"epoch": 10, "training_loss": 59.17125725746155, "training_acc": 72.0, "val_loss": 14.817209541797638, "val_acc": 72.0}
{"epoch": 11, "training_loss": 59.38263702392578, "training_acc": 72.0, "val_loss": 14.851619303226471, "val_acc": 72.0}
{"epoch": 12, "training_loss": 59.460288524627686, "training_acc": 72.0, "val_loss": 14.883626997470856, "val_acc": 72.0}
{"epoch": 13, "training_loss": 59.591838121414185, "training_acc": 72.0, "val_loss": 14.908993244171143, "val_acc": 72.0}
{"epoch": 14, "training_loss": 59.63374376296997, "training_acc": 72.0, "val_loss": 14.92038369178772, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.708916664123535, "training_acc": 72.0, "val_loss": 14.927917718887329, "val_acc": 72.0}
{"epoch": 16, "training_loss": 59.76259803771973, "training_acc": 72.0, "val_loss": 14.922116696834564, "val_acc": 72.0}
{"epoch": 17, "training_loss": 59.70054364204407, "training_acc": 72.0, "val_loss": 14.904236793518066, "val_acc": 72.0}
{"epoch": 18, "training_loss": 59.644145250320435, "training_acc": 72.0, "val_loss": 14.88230675458908, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.586952209472656, "training_acc": 72.0, "val_loss": 14.855663478374481, "val_acc": 72.0}
{"epoch": 20, "training_loss": 59.42574667930603, "training_acc": 72.0, "val_loss": 14.834700524806976, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.36595129966736, "training_acc": 72.0, "val_loss": 14.817734062671661, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.356682538986206, "training_acc": 72.0, "val_loss": 14.806127548217773, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.25662541389465, "training_acc": 72.0, "val_loss": 14.799949526786804, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.26839256286621, "training_acc": 72.0, "val_loss": 14.796291291713715, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.224732875823975, "training_acc": 72.0, "val_loss": 14.795015752315521, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.24109625816345, "training_acc": 72.0, "val_loss": 14.794622361660004, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.20444965362549, "training_acc": 72.0, "val_loss": 14.794573187828064, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.208670139312744, "training_acc": 72.0, "val_loss": 14.794567227363586, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.25952911376953, "training_acc": 72.0, "val_loss": 14.79463130235672, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.256104469299316, "training_acc": 72.0, "val_loss": 14.794950187206268, "val_acc": 72.0}
{"epoch": 31, "training_loss": 59.23574376106262, "training_acc": 72.0, "val_loss": 14.795082807540894, "val_acc": 72.0}
{"epoch": 32, "training_loss": 59.192732095718384, "training_acc": 72.0, "val_loss": 14.795298874378204, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.212761640548706, "training_acc": 72.0, "val_loss": 14.795595407485962, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.20351552963257, "training_acc": 72.0, "val_loss": 14.79594111442566, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.230520486831665, "training_acc": 72.0, "val_loss": 14.796645939350128, "val_acc": 72.0}
{"epoch": 36, "training_loss": 59.2264358997345, "training_acc": 72.0, "val_loss": 14.79700654745102, "val_acc": 72.0}
{"epoch": 37, "training_loss": 59.24649167060852, "training_acc": 72.0, "val_loss": 14.7970512509346, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.23751425743103, "training_acc": 72.0, "val_loss": 14.795751869678497, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.225553035736084, "training_acc": 72.0, "val_loss": 14.795216917991638, "val_acc": 72.0}
{"epoch": 40, "training_loss": 59.198387145996094, "training_acc": 72.0, "val_loss": 14.794525504112244, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.219844818115234, "training_acc": 72.0, "val_loss": 14.793717861175537, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.20667266845703, "training_acc": 72.0, "val_loss": 14.793576300144196, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.23470616340637, "training_acc": 72.0, "val_loss": 14.793938398361206, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.24377083778381, "training_acc": 72.0, "val_loss": 14.793890714645386, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.19720005989075, "training_acc": 72.0, "val_loss": 14.793886244297028, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.20736646652222, "training_acc": 72.0, "val_loss": 14.794108271598816, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.22013783454895, "training_acc": 72.0, "val_loss": 14.794978499412537, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.25539684295654, "training_acc": 72.0, "val_loss": 14.794853329658508, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.21410155296326, "training_acc": 72.0, "val_loss": 14.795324206352234, "val_acc": 72.0}
{"epoch": 50, "training_loss": 59.2452757358551, "training_acc": 72.0, "val_loss": 14.796511828899384, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.228344202041626, "training_acc": 72.0, "val_loss": 14.797498285770416, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.249324798583984, "training_acc": 72.0, "val_loss": 14.798121154308319, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.22986078262329, "training_acc": 72.0, "val_loss": 14.798364043235779, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.20626950263977, "training_acc": 72.0, "val_loss": 14.797082543373108, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.21535682678223, "training_acc": 72.0, "val_loss": 14.796346426010132, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.221943855285645, "training_acc": 72.0, "val_loss": 14.795538783073425, "val_acc": 72.0}
{"epoch": 57, "training_loss": 59.241440296173096, "training_acc": 72.0, "val_loss": 14.795579016208649, "val_acc": 72.0}
{"epoch": 58, "training_loss": 59.21161508560181, "training_acc": 72.0, "val_loss": 14.796432852745056, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.226284980773926, "training_acc": 72.0, "val_loss": 14.796464145183563, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.32590126991272, "training_acc": 72.0, "val_loss": 14.7955983877182, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.235965728759766, "training_acc": 72.0, "val_loss": 14.797268807888031, "val_acc": 72.0}
