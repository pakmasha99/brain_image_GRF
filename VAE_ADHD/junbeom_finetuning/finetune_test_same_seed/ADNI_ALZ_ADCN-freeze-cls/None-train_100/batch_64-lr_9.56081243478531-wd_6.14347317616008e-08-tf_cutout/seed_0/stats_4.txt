"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 32813.17184448242, "training_acc": 48.0, "val_loss": 26603.561401367188, "val_acc": 72.0}
{"epoch": 1, "training_loss": 93801.37377929688, "training_acc": 72.0, "val_loss": 13177.976989746094, "val_acc": 28.0}
{"epoch": 2, "training_loss": 35430.44827270508, "training_acc": 28.0, "val_loss": 12048.189544677734, "val_acc": 72.0}
{"epoch": 3, "training_loss": 57698.628173828125, "training_acc": 72.0, "val_loss": 22902.9296875, "val_acc": 72.0}
{"epoch": 4, "training_loss": 90872.171875, "training_acc": 72.0, "val_loss": 19499.728393554688, "val_acc": 72.0}
{"epoch": 5, "training_loss": 70531.54663085938, "training_acc": 72.0, "val_loss": 6827.605438232422, "val_acc": 72.0}
{"epoch": 6, "training_loss": 23559.5634765625, "training_acc": 60.0, "val_loss": 9323.36196899414, "val_acc": 28.0}
{"epoch": 7, "training_loss": 25666.752182006836, "training_acc": 44.0, "val_loss": 3391.2059783935547, "val_acc": 72.0}
{"epoch": 8, "training_loss": 13261.912658691406, "training_acc": 72.0, "val_loss": 336.95857524871826, "val_acc": 72.0}
{"epoch": 9, "training_loss": 13380.23291015625, "training_acc": 64.0, "val_loss": 7807.731628417969, "val_acc": 28.0}
{"epoch": 10, "training_loss": 22421.736236572266, "training_acc": 48.0, "val_loss": 6638.587951660156, "val_acc": 72.0}
{"epoch": 11, "training_loss": 28362.455078125, "training_acc": 72.0, "val_loss": 6967.90771484375, "val_acc": 72.0}
{"epoch": 12, "training_loss": 23916.62139892578, "training_acc": 72.0, "val_loss": 1897.8368759155273, "val_acc": 28.0}
{"epoch": 13, "training_loss": 4887.996608734131, "training_acc": 48.0, "val_loss": 1410.5473518371582, "val_acc": 28.0}
{"epoch": 14, "training_loss": 4970.628372192383, "training_acc": 56.0, "val_loss": 5831.241989135742, "val_acc": 72.0}
{"epoch": 15, "training_loss": 24050.2705078125, "training_acc": 72.0, "val_loss": 4511.665725708008, "val_acc": 72.0}
{"epoch": 16, "training_loss": 12467.714126586914, "training_acc": 72.0, "val_loss": 11445.540618896484, "val_acc": 28.0}
{"epoch": 17, "training_loss": 43892.16845703125, "training_acc": 28.0, "val_loss": 1161.2245559692383, "val_acc": 72.0}
{"epoch": 18, "training_loss": 8417.221252441406, "training_acc": 72.0, "val_loss": 4275.401306152344, "val_acc": 72.0}
{"epoch": 19, "training_loss": 14843.95669555664, "training_acc": 72.0, "val_loss": 1465.4940605163574, "val_acc": 28.0}
{"epoch": 20, "training_loss": 7512.341522216797, "training_acc": 36.0, "val_loss": 1162.289047241211, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5543.998809814453, "training_acc": 62.0, "val_loss": 1486.9528770446777, "val_acc": 72.0}
{"epoch": 22, "training_loss": 6188.22590637207, "training_acc": 72.0, "val_loss": 152.50457525253296, "val_acc": 72.0}
{"epoch": 23, "training_loss": 14754.258605957031, "training_acc": 50.0, "val_loss": 3246.5038299560547, "val_acc": 28.0}
{"epoch": 24, "training_loss": 14854.595092773438, "training_acc": 46.0, "val_loss": 9513.780975341797, "val_acc": 72.0}
{"epoch": 25, "training_loss": 42357.60546875, "training_acc": 72.0, "val_loss": 11524.027252197266, "val_acc": 72.0}
{"epoch": 26, "training_loss": 43178.286376953125, "training_acc": 72.0, "val_loss": 5544.888687133789, "val_acc": 72.0}
{"epoch": 27, "training_loss": 15912.089436531067, "training_acc": 72.0, "val_loss": 16346.392822265625, "val_acc": 28.0}
{"epoch": 28, "training_loss": 70578.19067382812, "training_acc": 28.0, "val_loss": 8775.868225097656, "val_acc": 28.0}
{"epoch": 29, "training_loss": 28152.948974609375, "training_acc": 46.0, "val_loss": 10655.606842041016, "val_acc": 72.0}
{"epoch": 30, "training_loss": 48872.909423828125, "training_acc": 72.0, "val_loss": 15435.675048828125, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60572.625732421875, "training_acc": 72.0, "val_loss": 12018.017578125, "val_acc": 72.0}
{"epoch": 32, "training_loss": 44016.129150390625, "training_acc": 72.0, "val_loss": 1948.4426498413086, "val_acc": 72.0}
{"epoch": 33, "training_loss": 25412.131103515625, "training_acc": 52.0, "val_loss": 15383.72802734375, "val_acc": 28.0}
{"epoch": 34, "training_loss": 47614.43151855469, "training_acc": 28.0, "val_loss": 5735.182571411133, "val_acc": 72.0}
{"epoch": 35, "training_loss": 34545.7138671875, "training_acc": 72.0, "val_loss": 14276.579284667969, "val_acc": 72.0}
{"epoch": 36, "training_loss": 57777.25390625, "training_acc": 72.0, "val_loss": 13670.838928222656, "val_acc": 72.0}
{"epoch": 37, "training_loss": 49890.04541015625, "training_acc": 72.0, "val_loss": 6410.560607910156, "val_acc": 72.0}
{"epoch": 38, "training_loss": 17657.66166114807, "training_acc": 72.0, "val_loss": 17999.56817626953, "val_acc": 28.0}
{"epoch": 39, "training_loss": 77957.1298828125, "training_acc": 28.0, "val_loss": 14428.269958496094, "val_acc": 28.0}
{"epoch": 40, "training_loss": 41730.90252685547, "training_acc": 40.0, "val_loss": 6478.232574462891, "val_acc": 72.0}
{"epoch": 41, "training_loss": 29766.841674804688, "training_acc": 72.0, "val_loss": 9205.421447753906, "val_acc": 72.0}
