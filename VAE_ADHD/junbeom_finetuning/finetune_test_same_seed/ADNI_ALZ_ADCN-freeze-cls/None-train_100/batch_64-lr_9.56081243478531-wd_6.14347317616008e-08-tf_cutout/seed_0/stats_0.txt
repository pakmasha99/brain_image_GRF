"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 45073.904205322266, "training_acc": 42.0, "val_loss": 24668.42498779297, "val_acc": 72.0}
{"epoch": 1, "training_loss": 77480.18481445312, "training_acc": 72.0, "val_loss": 14325.794982910156, "val_acc": 28.0}
{"epoch": 2, "training_loss": 48850.98876953125, "training_acc": 28.0, "val_loss": 7843.3013916015625, "val_acc": 72.0}
{"epoch": 3, "training_loss": 40425.526611328125, "training_acc": 72.0, "val_loss": 16516.831970214844, "val_acc": 72.0}
{"epoch": 4, "training_loss": 64672.676025390625, "training_acc": 72.0, "val_loss": 11673.054504394531, "val_acc": 72.0}
{"epoch": 5, "training_loss": 40732.47848510742, "training_acc": 72.0, "val_loss": 7963.160705566406, "val_acc": 28.0}
{"epoch": 6, "training_loss": 31360.477172851562, "training_acc": 28.0, "val_loss": 3006.794548034668, "val_acc": 72.0}
{"epoch": 7, "training_loss": 14690.842041015625, "training_acc": 72.0, "val_loss": 6543.3013916015625, "val_acc": 72.0}
{"epoch": 8, "training_loss": 24024.85723876953, "training_acc": 72.0, "val_loss": 1553.1256675720215, "val_acc": 72.0}
{"epoch": 9, "training_loss": 22372.482788085938, "training_acc": 50.0, "val_loss": 8379.122924804688, "val_acc": 28.0}
{"epoch": 10, "training_loss": 25134.335510253906, "training_acc": 44.0, "val_loss": 5940.804672241211, "val_acc": 72.0}
{"epoch": 11, "training_loss": 25260.481811523438, "training_acc": 72.0, "val_loss": 6029.014205932617, "val_acc": 72.0}
{"epoch": 12, "training_loss": 20270.695068359375, "training_acc": 72.0, "val_loss": 3523.965835571289, "val_acc": 28.0}
{"epoch": 13, "training_loss": 11535.615814208984, "training_acc": 28.0, "val_loss": 5177.612686157227, "val_acc": 72.0}
{"epoch": 14, "training_loss": 27115.548950195312, "training_acc": 72.0, "val_loss": 10131.339263916016, "val_acc": 72.0}
{"epoch": 15, "training_loss": 39506.58801269531, "training_acc": 72.0, "val_loss": 6830.26123046875, "val_acc": 72.0}
{"epoch": 16, "training_loss": 20174.258728027344, "training_acc": 72.0, "val_loss": 8448.61831665039, "val_acc": 28.0}
{"epoch": 17, "training_loss": 37407.538818359375, "training_acc": 28.0, "val_loss": 223.70550632476807, "val_acc": 72.0}
{"epoch": 18, "training_loss": 5450.080474853516, "training_acc": 72.0, "val_loss": 2608.161735534668, "val_acc": 72.0}
{"epoch": 19, "training_loss": 8194.025035858154, "training_acc": 72.0, "val_loss": 7271.61865234375, "val_acc": 28.0}
{"epoch": 20, "training_loss": 22947.04913330078, "training_acc": 28.0, "val_loss": 4873.818588256836, "val_acc": 72.0}
{"epoch": 21, "training_loss": 27005.322875976562, "training_acc": 72.0, "val_loss": 10329.341888427734, "val_acc": 72.0}
{"epoch": 22, "training_loss": 40515.091552734375, "training_acc": 72.0, "val_loss": 7544.795227050781, "val_acc": 72.0}
{"epoch": 23, "training_loss": 25044.39471435547, "training_acc": 72.0, "val_loss": 4049.140167236328, "val_acc": 28.0}
{"epoch": 24, "training_loss": 16376.071411132812, "training_acc": 28.0, "val_loss": 2881.411552429199, "val_acc": 72.0}
{"epoch": 25, "training_loss": 15256.672058105469, "training_acc": 72.0, "val_loss": 5529.951095581055, "val_acc": 72.0}
{"epoch": 26, "training_loss": 19922.271606445312, "training_acc": 72.0, "val_loss": 745.2879428863525, "val_acc": 72.0}
{"epoch": 27, "training_loss": 16229.123413085938, "training_acc": 56.0, "val_loss": 8669.698333740234, "val_acc": 28.0}
{"epoch": 28, "training_loss": 23610.036193847656, "training_acc": 46.0, "val_loss": 4232.830429077148, "val_acc": 72.0}
{"epoch": 29, "training_loss": 17953.739013671875, "training_acc": 72.0, "val_loss": 3898.381805419922, "val_acc": 72.0}
{"epoch": 30, "training_loss": 12464.486465454102, "training_acc": 72.0, "val_loss": 8197.293853759766, "val_acc": 28.0}
{"epoch": 31, "training_loss": 28612.206115722656, "training_acc": 28.0, "val_loss": 3213.459014892578, "val_acc": 72.0}
{"epoch": 32, "training_loss": 15769.762756347656, "training_acc": 72.0, "val_loss": 6769.694519042969, "val_acc": 72.0}
{"epoch": 33, "training_loss": 25718.452087402344, "training_acc": 72.0, "val_loss": 3185.989189147949, "val_acc": 72.0}
{"epoch": 34, "training_loss": 9307.040069580078, "training_acc": 60.0, "val_loss": 205.37419319152832, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3423.57275390625, "training_acc": 56.0, "val_loss": 2825.6919860839844, "val_acc": 72.0}
{"epoch": 36, "training_loss": 13061.441589355469, "training_acc": 72.0, "val_loss": 3925.4440307617188, "val_acc": 72.0}
{"epoch": 37, "training_loss": 12252.306640625, "training_acc": 72.0, "val_loss": 4506.264495849609, "val_acc": 28.0}
{"epoch": 38, "training_loss": 14303.698364257812, "training_acc": 28.0, "val_loss": 4646.742248535156, "val_acc": 72.0}
{"epoch": 39, "training_loss": 25446.09033203125, "training_acc": 72.0, "val_loss": 8750.666046142578, "val_acc": 72.0}
{"epoch": 40, "training_loss": 33202.75439453125, "training_acc": 72.0, "val_loss": 4697.941207885742, "val_acc": 72.0}
{"epoch": 41, "training_loss": 11716.309711456299, "training_acc": 72.0, "val_loss": 14657.980346679688, "val_acc": 28.0}
{"epoch": 42, "training_loss": 62096.357177734375, "training_acc": 28.0, "val_loss": 6600.8026123046875, "val_acc": 28.0}
{"epoch": 43, "training_loss": 22146.542053222656, "training_acc": 48.0, "val_loss": 10963.249969482422, "val_acc": 72.0}
{"epoch": 44, "training_loss": 48607.072265625, "training_acc": 72.0, "val_loss": 15643.043518066406, "val_acc": 72.0}
{"epoch": 45, "training_loss": 61672.539794921875, "training_acc": 72.0, "val_loss": 12700.462341308594, "val_acc": 72.0}
{"epoch": 46, "training_loss": 45923.41638183594, "training_acc": 72.0, "val_loss": 3300.7320404052734, "val_acc": 72.0}
{"epoch": 47, "training_loss": 17724.429321289062, "training_acc": 60.0, "val_loss": 11161.209106445312, "val_acc": 28.0}
{"epoch": 48, "training_loss": 32250.441528320312, "training_acc": 28.0, "val_loss": 6458.221435546875, "val_acc": 72.0}
{"epoch": 49, "training_loss": 32282.130859375, "training_acc": 72.0, "val_loss": 14544.358825683594, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58914.14453125, "training_acc": 72.0, "val_loss": 14506.285095214844, "val_acc": 72.0}
{"epoch": 51, "training_loss": 54600.342529296875, "training_acc": 72.0, "val_loss": 7973.111724853516, "val_acc": 72.0}
{"epoch": 52, "training_loss": 24110.27944946289, "training_acc": 72.0, "val_loss": 10232.676696777344, "val_acc": 28.0}
{"epoch": 53, "training_loss": 47906.009521484375, "training_acc": 28.0, "val_loss": 4960.216522216797, "val_acc": 28.0}
