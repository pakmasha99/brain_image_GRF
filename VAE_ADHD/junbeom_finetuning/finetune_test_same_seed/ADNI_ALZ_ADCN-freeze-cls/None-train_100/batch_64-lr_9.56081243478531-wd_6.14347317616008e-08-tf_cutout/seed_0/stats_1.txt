"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 53288.67225265503, "training_acc": 72.0, "val_loss": 20181.370544433594, "val_acc": 72.0}
{"epoch": 1, "training_loss": 58436.467712402344, "training_acc": 72.0, "val_loss": 37782.928466796875, "val_acc": 28.0}
{"epoch": 2, "training_loss": 145017.50439453125, "training_acc": 28.0, "val_loss": 6041.474151611328, "val_acc": 28.0}
{"epoch": 3, "training_loss": 34361.06494140625, "training_acc": 44.0, "val_loss": 23919.358825683594, "val_acc": 72.0}
{"epoch": 4, "training_loss": 101804.49755859375, "training_acc": 72.0, "val_loss": 33517.3828125, "val_acc": 72.0}
{"epoch": 5, "training_loss": 134633.10205078125, "training_acc": 72.0, "val_loss": 31895.5078125, "val_acc": 72.0}
{"epoch": 6, "training_loss": 121540.10498046875, "training_acc": 72.0, "val_loss": 21360.787963867188, "val_acc": 72.0}
{"epoch": 7, "training_loss": 79320.44732666016, "training_acc": 72.0, "val_loss": 3695.545196533203, "val_acc": 72.0}
{"epoch": 8, "training_loss": 34776.067626953125, "training_acc": 56.0, "val_loss": 25058.270263671875, "val_acc": 28.0}
{"epoch": 9, "training_loss": 89506.17309570312, "training_acc": 28.0, "val_loss": 674.2489337921143, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5854.354888916016, "training_acc": 72.0, "val_loss": 8111.259460449219, "val_acc": 72.0}
{"epoch": 11, "training_loss": 33268.81872558594, "training_acc": 72.0, "val_loss": 7513.3270263671875, "val_acc": 72.0}
{"epoch": 12, "training_loss": 25633.41729736328, "training_acc": 72.0, "val_loss": 1016.3389205932617, "val_acc": 28.0}
{"epoch": 13, "training_loss": 2701.034044265747, "training_acc": 48.0, "val_loss": 2114.9858474731445, "val_acc": 28.0}
{"epoch": 14, "training_loss": 11347.278991699219, "training_acc": 40.0, "val_loss": 4824.711990356445, "val_acc": 72.0}
{"epoch": 15, "training_loss": 18631.454711914062, "training_acc": 72.0, "val_loss": 1918.7646865844727, "val_acc": 72.0}
{"epoch": 16, "training_loss": 12259.667175292969, "training_acc": 58.0, "val_loss": 2703.959846496582, "val_acc": 28.0}
{"epoch": 17, "training_loss": 12486.002258300781, "training_acc": 46.0, "val_loss": 7813.753509521484, "val_acc": 72.0}
{"epoch": 18, "training_loss": 32988.37731933594, "training_acc": 72.0, "val_loss": 8242.138671875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 29552.514038085938, "training_acc": 72.0, "val_loss": 1478.141689300537, "val_acc": 72.0}
{"epoch": 20, "training_loss": 20297.37744140625, "training_acc": 54.0, "val_loss": 11042.567443847656, "val_acc": 28.0}
{"epoch": 21, "training_loss": 27792.887460708618, "training_acc": 46.0, "val_loss": 2592.7806854248047, "val_acc": 72.0}
{"epoch": 22, "training_loss": 11624.392517089844, "training_acc": 72.0, "val_loss": 1491.4067268371582, "val_acc": 72.0}
{"epoch": 23, "training_loss": 11993.35546875, "training_acc": 54.0, "val_loss": 880.5306434631348, "val_acc": 28.0}
{"epoch": 24, "training_loss": 8489.360656738281, "training_acc": 48.0, "val_loss": 9449.394989013672, "val_acc": 72.0}
{"epoch": 25, "training_loss": 39254.537109375, "training_acc": 72.0, "val_loss": 10909.068298339844, "val_acc": 72.0}
{"epoch": 26, "training_loss": 41219.593505859375, "training_acc": 72.0, "val_loss": 5638.349533081055, "val_acc": 72.0}
{"epoch": 27, "training_loss": 16144.54174041748, "training_acc": 72.0, "val_loss": 14220.8251953125, "val_acc": 28.0}
{"epoch": 28, "training_loss": 59335.641357421875, "training_acc": 28.0, "val_loss": 6050.689315795898, "val_acc": 28.0}
