"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 469783.1619987488, "training_acc": 72.0, "val_loss": 178024.8046875, "val_acc": 72.0}
{"epoch": 1, "training_loss": 515450.78173828125, "training_acc": 72.0, "val_loss": 333403.80859375, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1279654.1875, "training_acc": 28.0, "val_loss": 53349.224853515625, "val_acc": 28.0}
{"epoch": 3, "training_loss": 303242.49609375, "training_acc": 44.0, "val_loss": 210999.7802734375, "val_acc": 72.0}
{"epoch": 4, "training_loss": 898046.255859375, "training_acc": 72.0, "val_loss": 295658.544921875, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1187592.0625, "training_acc": 72.0, "val_loss": 281328.0029296875, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1071994.33984375, "training_acc": 72.0, "val_loss": 188368.75, "val_acc": 72.0}
{"epoch": 7, "training_loss": 699454.017578125, "training_acc": 72.0, "val_loss": 32510.385131835938, "val_acc": 72.0}
{"epoch": 8, "training_loss": 306913.70703125, "training_acc": 56.0, "val_loss": 221306.2255859375, "val_acc": 28.0}
{"epoch": 9, "training_loss": 790575.658203125, "training_acc": 28.0, "val_loss": 5862.19482421875, "val_acc": 72.0}
{"epoch": 10, "training_loss": 51303.776611328125, "training_acc": 72.0, "val_loss": 71471.55151367188, "val_acc": 72.0}
{"epoch": 11, "training_loss": 293150.486328125, "training_acc": 72.0, "val_loss": 66190.98510742188, "val_acc": 72.0}
{"epoch": 12, "training_loss": 225767.4375, "training_acc": 72.0, "val_loss": 9216.874694824219, "val_acc": 28.0}
{"epoch": 13, "training_loss": 24329.846435546875, "training_acc": 48.0, "val_loss": 18909.234619140625, "val_acc": 28.0}
{"epoch": 14, "training_loss": 100608.9462890625, "training_acc": 40.0, "val_loss": 42466.74499511719, "val_acc": 72.0}
{"epoch": 15, "training_loss": 163976.9365234375, "training_acc": 72.0, "val_loss": 16826.747131347656, "val_acc": 72.0}
{"epoch": 16, "training_loss": 108275.44189453125, "training_acc": 58.0, "val_loss": 24114.906311035156, "val_acc": 28.0}
{"epoch": 17, "training_loss": 110674.39306640625, "training_acc": 46.0, "val_loss": 68832.84301757812, "val_acc": 72.0}
{"epoch": 18, "training_loss": 290619.962890625, "training_acc": 72.0, "val_loss": 72606.72607421875, "val_acc": 72.0}
{"epoch": 19, "training_loss": 260286.5888671875, "training_acc": 72.0, "val_loss": 12928.515625, "val_acc": 72.0}
{"epoch": 20, "training_loss": 179198.8994140625, "training_acc": 54.0, "val_loss": 97706.3720703125, "val_acc": 28.0}
{"epoch": 21, "training_loss": 245769.40745544434, "training_acc": 46.0, "val_loss": 22764.39666748047, "val_acc": 72.0}
{"epoch": 22, "training_loss": 102112.8115234375, "training_acc": 72.0, "val_loss": 13045.901489257812, "val_acc": 72.0}
{"epoch": 23, "training_loss": 105938.04833984375, "training_acc": 54.0, "val_loss": 8055.240631103516, "val_acc": 28.0}
{"epoch": 24, "training_loss": 75468.4609375, "training_acc": 48.0, "val_loss": 83251.86767578125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 345858.0029296875, "training_acc": 72.0, "val_loss": 96122.86987304688, "val_acc": 72.0}
{"epoch": 26, "training_loss": 363166.6533203125, "training_acc": 72.0, "val_loss": 49616.78771972656, "val_acc": 72.0}
{"epoch": 27, "training_loss": 141924.39630126953, "training_acc": 72.0, "val_loss": 125789.95361328125, "val_acc": 28.0}
{"epoch": 28, "training_loss": 524787.12109375, "training_acc": 28.0, "val_loss": 53701.07421875, "val_acc": 28.0}
