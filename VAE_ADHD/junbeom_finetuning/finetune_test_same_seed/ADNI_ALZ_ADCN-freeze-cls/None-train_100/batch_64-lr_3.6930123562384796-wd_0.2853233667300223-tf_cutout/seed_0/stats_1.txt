"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 14290.277492523193, "training_acc": 72.0, "val_loss": 8818.247985839844, "val_acc": 28.0}
{"epoch": 1, "training_loss": 29556.47686767578, "training_acc": 46.0, "val_loss": 2086.299705505371, "val_acc": 72.0}
{"epoch": 2, "training_loss": 7612.688064575195, "training_acc": 52.0, "val_loss": 3706.340789794922, "val_acc": 72.0}
{"epoch": 3, "training_loss": 13365.089317321777, "training_acc": 72.0, "val_loss": 613.2509708404541, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4040.627227783203, "training_acc": 56.0, "val_loss": 2226.1171340942383, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7132.4848709106445, "training_acc": 72.0, "val_loss": 321.3285446166992, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4034.1070556640625, "training_acc": 44.0, "val_loss": 990.900707244873, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3379.1914863586426, "training_acc": 50.0, "val_loss": 2276.622772216797, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7555.837417602539, "training_acc": 72.0, "val_loss": 299.73340034484863, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2619.6074981689453, "training_acc": 56.0, "val_loss": 1568.4965133666992, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5393.424444198608, "training_acc": 72.0, "val_loss": 47.82967269420624, "val_acc": 28.0}
{"epoch": 11, "training_loss": 2552.246467590332, "training_acc": 44.0, "val_loss": 711.461877822876, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2595.3872680664062, "training_acc": 52.0, "val_loss": 1886.178970336914, "val_acc": 72.0}
{"epoch": 13, "training_loss": 6688.3081703186035, "training_acc": 72.0, "val_loss": 320.2418804168701, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2635.67236328125, "training_acc": 54.0, "val_loss": 1505.1410675048828, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4668.93692779541, "training_acc": 72.0, "val_loss": 388.26310634613037, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2769.855926513672, "training_acc": 48.0, "val_loss": 800.8038520812988, "val_acc": 72.0}
{"epoch": 17, "training_loss": 2064.885766983032, "training_acc": 72.0, "val_loss": 1753.536605834961, "val_acc": 28.0}
{"epoch": 18, "training_loss": 6530.552780151367, "training_acc": 42.0, "val_loss": 272.1538543701172, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1967.6586608886719, "training_acc": 58.0, "val_loss": 1399.3815422058105, "val_acc": 72.0}
{"epoch": 20, "training_loss": 4376.212272644043, "training_acc": 72.0, "val_loss": 428.28941345214844, "val_acc": 28.0}
{"epoch": 21, "training_loss": 3412.75634765625, "training_acc": 44.0, "val_loss": 697.490930557251, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2103.183485031128, "training_acc": 54.0, "val_loss": 1788.5576248168945, "val_acc": 72.0}
{"epoch": 23, "training_loss": 5891.753921508789, "training_acc": 72.0, "val_loss": 163.34573030471802, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2558.8404083251953, "training_acc": 54.0, "val_loss": 1355.258560180664, "val_acc": 72.0}
{"epoch": 25, "training_loss": 3950.5691146850586, "training_acc": 72.0, "val_loss": 859.0655326843262, "val_acc": 28.0}
{"epoch": 26, "training_loss": 3989.972686767578, "training_acc": 46.0, "val_loss": 601.2451171875, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2422.6857986450195, "training_acc": 52.0, "val_loss": 1734.2111587524414, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5887.219612121582, "training_acc": 72.0, "val_loss": 197.02563285827637, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2532.8541412353516, "training_acc": 54.0, "val_loss": 1367.1342849731445, "val_acc": 72.0}
