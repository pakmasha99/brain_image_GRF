"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 11158.171886444092, "training_acc": 50.0, "val_loss": 4079.7298431396484, "val_acc": 28.0}
{"epoch": 1, "training_loss": 18494.478576660156, "training_acc": 46.0, "val_loss": 2564.7884368896484, "val_acc": 72.0}
{"epoch": 2, "training_loss": 6810.644723892212, "training_acc": 72.0, "val_loss": 4100.774002075195, "val_acc": 28.0}
{"epoch": 3, "training_loss": 15508.025970458984, "training_acc": 40.0, "val_loss": 523.0229377746582, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3480.782470703125, "training_acc": 58.0, "val_loss": 2214.8340225219727, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7052.313941955566, "training_acc": 72.0, "val_loss": 451.2263774871826, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4376.034362792969, "training_acc": 44.0, "val_loss": 975.6593704223633, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3108.496738433838, "training_acc": 52.0, "val_loss": 2263.0626678466797, "val_acc": 72.0}
{"epoch": 8, "training_loss": 7593.073036193848, "training_acc": 72.0, "val_loss": 298.28546047210693, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2989.546340942383, "training_acc": 54.0, "val_loss": 1621.7239379882812, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4841.875267028809, "training_acc": 72.0, "val_loss": 713.7648582458496, "val_acc": 28.0}
{"epoch": 11, "training_loss": 4585.519836425781, "training_acc": 42.0, "val_loss": 653.6092758178711, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2328.669677734375, "training_acc": 54.0, "val_loss": 1813.6381149291992, "val_acc": 72.0}
{"epoch": 13, "training_loss": 6025.985130310059, "training_acc": 72.0, "val_loss": 149.7685670852661, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3554.5465087890625, "training_acc": 48.0, "val_loss": 1474.7138023376465, "val_acc": 72.0}
{"epoch": 15, "training_loss": 4542.088180541992, "training_acc": 72.0, "val_loss": 443.2461738586426, "val_acc": 28.0}
{"epoch": 16, "training_loss": 5481.422760009766, "training_acc": 32.0, "val_loss": 477.7215003967285, "val_acc": 72.0}
{"epoch": 17, "training_loss": 1908.1595077514648, "training_acc": 56.0, "val_loss": 1580.59663772583, "val_acc": 72.0}
{"epoch": 18, "training_loss": 5099.402496337891, "training_acc": 72.0, "val_loss": 17.741137742996216, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1683.732521057129, "training_acc": 54.0, "val_loss": 1428.2869338989258, "val_acc": 72.0}
{"epoch": 20, "training_loss": 5067.7960777282715, "training_acc": 72.0, "val_loss": 59.52067971229553, "val_acc": 72.0}
{"epoch": 21, "training_loss": 2204.0030822753906, "training_acc": 58.0, "val_loss": 1177.6187896728516, "val_acc": 72.0}
{"epoch": 22, "training_loss": 3456.9841804504395, "training_acc": 72.0, "val_loss": 918.0037498474121, "val_acc": 28.0}
{"epoch": 23, "training_loss": 4079.9229278564453, "training_acc": 46.0, "val_loss": 568.9030647277832, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1695.520092010498, "training_acc": 58.0, "val_loss": 1606.195068359375, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5115.762580871582, "training_acc": 72.0, "val_loss": 19.875766336917877, "val_acc": 28.0}
{"epoch": 26, "training_loss": 1541.1324157714844, "training_acc": 40.0, "val_loss": 183.21787118911743, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1763.5402374267578, "training_acc": 52.0, "val_loss": 923.0932235717773, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2625.5881671905518, "training_acc": 72.0, "val_loss": 1245.8940505981445, "val_acc": 28.0}
{"epoch": 29, "training_loss": 3929.7376861572266, "training_acc": 52.0, "val_loss": 587.699031829834, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1318.339859008789, "training_acc": 62.0, "val_loss": 1383.2048416137695, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4326.9697265625, "training_acc": 72.0, "val_loss": 438.56592178344727, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3453.7882690429688, "training_acc": 44.0, "val_loss": 699.7785568237305, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1869.992157459259, "training_acc": 56.0, "val_loss": 1619.9581146240234, "val_acc": 72.0}
{"epoch": 34, "training_loss": 5010.909912109375, "training_acc": 72.0, "val_loss": 242.47183799743652, "val_acc": 28.0}
{"epoch": 35, "training_loss": 3376.0606689453125, "training_acc": 42.0, "val_loss": 732.6809406280518, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1911.0732386112213, "training_acc": 72.0, "val_loss": 1138.3424758911133, "val_acc": 28.0}
{"epoch": 37, "training_loss": 4281.938720703125, "training_acc": 48.0, "val_loss": 548.5942363739014, "val_acc": 72.0}
