"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 26843.808586120605, "training_acc": 30.0, "val_loss": 7777.361297607422, "val_acc": 28.0}
{"epoch": 1, "training_loss": 32244.632568359375, "training_acc": 34.0, "val_loss": 716.9528484344482, "val_acc": 72.0}
{"epoch": 2, "training_loss": 4213.967193603516, "training_acc": 58.0, "val_loss": 2638.111114501953, "val_acc": 72.0}
{"epoch": 3, "training_loss": 7915.684814453125, "training_acc": 72.0, "val_loss": 844.7859764099121, "val_acc": 28.0}
{"epoch": 4, "training_loss": 5472.537261962891, "training_acc": 44.0, "val_loss": 948.2913970947266, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2322.1957943439484, "training_acc": 72.0, "val_loss": 114.55894708633423, "val_acc": 72.0}
{"epoch": 6, "training_loss": 1953.0859985351562, "training_acc": 66.0, "val_loss": 1377.8861999511719, "val_acc": 72.0}
{"epoch": 7, "training_loss": 3996.0608234405518, "training_acc": 72.0, "val_loss": 1383.0253601074219, "val_acc": 28.0}
{"epoch": 8, "training_loss": 5544.199935913086, "training_acc": 46.0, "val_loss": 625.0303268432617, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2376.5197525024414, "training_acc": 56.0, "val_loss": 1841.2055969238281, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5937.059799194336, "training_acc": 72.0, "val_loss": 28.081607818603516, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2286.280502319336, "training_acc": 58.0, "val_loss": 1340.506935119629, "val_acc": 72.0}
{"epoch": 12, "training_loss": 4043.478656768799, "training_acc": 72.0, "val_loss": 856.443977355957, "val_acc": 28.0}
{"epoch": 13, "training_loss": 4470.102981567383, "training_acc": 44.0, "val_loss": 623.9181995391846, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2888.163101196289, "training_acc": 50.0, "val_loss": 1839.5328521728516, "val_acc": 72.0}
{"epoch": 15, "training_loss": 5858.426773071289, "training_acc": 72.0, "val_loss": 75.5915641784668, "val_acc": 72.0}
{"epoch": 16, "training_loss": 2951.8275756835938, "training_acc": 52.0, "val_loss": 1353.3461570739746, "val_acc": 72.0}
{"epoch": 17, "training_loss": 4083.58154296875, "training_acc": 72.0, "val_loss": 672.9030609130859, "val_acc": 28.0}
{"epoch": 18, "training_loss": 3333.6956176757812, "training_acc": 48.0, "val_loss": 704.5169353485107, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2148.0730018615723, "training_acc": 54.0, "val_loss": 1793.9170837402344, "val_acc": 72.0}
{"epoch": 20, "training_loss": 6103.090026855469, "training_acc": 72.0, "val_loss": 232.34338760375977, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3072.5210876464844, "training_acc": 50.0, "val_loss": 1470.4086303710938, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4556.182876586914, "training_acc": 72.0, "val_loss": 351.24220848083496, "val_acc": 28.0}
{"epoch": 23, "training_loss": 3847.454132080078, "training_acc": 40.0, "val_loss": 641.3714408874512, "val_acc": 72.0}
{"epoch": 24, "training_loss": 2068.6060791015625, "training_acc": 54.0, "val_loss": 1734.3334197998047, "val_acc": 72.0}
{"epoch": 25, "training_loss": 5780.919471740723, "training_acc": 72.0, "val_loss": 174.2002248764038, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2519.5267486572266, "training_acc": 54.0, "val_loss": 1344.7954177856445, "val_acc": 72.0}
{"epoch": 27, "training_loss": 4174.716133117676, "training_acc": 72.0, "val_loss": 470.36023139953613, "val_acc": 28.0}
{"epoch": 28, "training_loss": 4061.52490234375, "training_acc": 40.0, "val_loss": 594.0699100494385, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1841.8093299865723, "training_acc": 56.0, "val_loss": 1659.172248840332, "val_acc": 72.0}
