"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 12725.869537353516, "training_acc": 48.0, "val_loss": 4628.751754760742, "val_acc": 28.0}
{"epoch": 1, "training_loss": 19622.15692138672, "training_acc": 46.0, "val_loss": 2450.969123840332, "val_acc": 72.0}
{"epoch": 2, "training_loss": 6439.884093284607, "training_acc": 72.0, "val_loss": 4164.582061767578, "val_acc": 28.0}
{"epoch": 3, "training_loss": 14898.820007324219, "training_acc": 42.0, "val_loss": 567.4905776977539, "val_acc": 72.0}
{"epoch": 4, "training_loss": 3918.8158264160156, "training_acc": 56.0, "val_loss": 2272.4796295166016, "val_acc": 72.0}
{"epoch": 5, "training_loss": 7003.657699584961, "training_acc": 72.0, "val_loss": 578.2121658325195, "val_acc": 28.0}
{"epoch": 6, "training_loss": 5898.497406005859, "training_acc": 38.0, "val_loss": 780.6546688079834, "val_acc": 72.0}
{"epoch": 7, "training_loss": 2741.573829650879, "training_acc": 54.0, "val_loss": 2071.3008880615234, "val_acc": 72.0}
{"epoch": 8, "training_loss": 6660.85009765625, "training_acc": 72.0, "val_loss": 89.82678651809692, "val_acc": 72.0}
{"epoch": 9, "training_loss": 3059.20947265625, "training_acc": 54.0, "val_loss": 1449.015712738037, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4108.886672973633, "training_acc": 72.0, "val_loss": 1211.845874786377, "val_acc": 28.0}
{"epoch": 11, "training_loss": 5590.225921630859, "training_acc": 42.0, "val_loss": 496.15345001220703, "val_acc": 72.0}
{"epoch": 12, "training_loss": 2405.7910537719727, "training_acc": 54.0, "val_loss": 1673.5931396484375, "val_acc": 72.0}
{"epoch": 13, "training_loss": 5314.282073974609, "training_acc": 72.0, "val_loss": 51.363301277160645, "val_acc": 28.0}
{"epoch": 14, "training_loss": 3399.1471557617188, "training_acc": 38.0, "val_loss": 597.5324153900146, "val_acc": 72.0}
{"epoch": 15, "training_loss": 2164.3676834106445, "training_acc": 54.0, "val_loss": 1715.4901504516602, "val_acc": 72.0}
{"epoch": 16, "training_loss": 5332.226821899414, "training_acc": 72.0, "val_loss": 101.57750844955444, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3010.3673400878906, "training_acc": 42.0, "val_loss": 755.0025463104248, "val_acc": 72.0}
{"epoch": 18, "training_loss": 2073.9139041900635, "training_acc": 72.0, "val_loss": 708.3924293518066, "val_acc": 28.0}
{"epoch": 19, "training_loss": 3931.716812133789, "training_acc": 44.0, "val_loss": 586.0785961151123, "val_acc": 72.0}
{"epoch": 20, "training_loss": 1448.9109325408936, "training_acc": 60.0, "val_loss": 1565.5793190002441, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5141.961814880371, "training_acc": 72.0, "val_loss": 36.32109463214874, "val_acc": 72.0}
{"epoch": 22, "training_loss": 2137.797409057617, "training_acc": 58.0, "val_loss": 1188.2176399230957, "val_acc": 72.0}
{"epoch": 23, "training_loss": 3270.7138442993164, "training_acc": 72.0, "val_loss": 1365.7380104064941, "val_acc": 28.0}
{"epoch": 24, "training_loss": 4736.407180786133, "training_acc": 48.0, "val_loss": 482.55763053894043, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2267.1742248535156, "training_acc": 54.0, "val_loss": 1601.52587890625, "val_acc": 72.0}
{"epoch": 26, "training_loss": 5091.224426269531, "training_acc": 72.0, "val_loss": 36.12612783908844, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1164.1716918945312, "training_acc": 52.0, "val_loss": 669.1141128540039, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2702.5963745117188, "training_acc": 50.0, "val_loss": 1814.0201568603516, "val_acc": 72.0}
{"epoch": 29, "training_loss": 5986.460914611816, "training_acc": 72.0, "val_loss": 187.58904933929443, "val_acc": 72.0}
{"epoch": 30, "training_loss": 3300.8965759277344, "training_acc": 48.0, "val_loss": 1463.2403373718262, "val_acc": 72.0}
{"epoch": 31, "training_loss": 4541.274688720703, "training_acc": 72.0, "val_loss": 340.9785270690918, "val_acc": 28.0}
{"epoch": 32, "training_loss": 3809.8385009765625, "training_acc": 40.0, "val_loss": 638.4219646453857, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1815.0408115386963, "training_acc": 56.0, "val_loss": 1694.2262649536133, "val_acc": 72.0}
{"epoch": 34, "training_loss": 5326.032791137695, "training_acc": 72.0, "val_loss": 14.764302968978882, "val_acc": 72.0}
{"epoch": 35, "training_loss": 471.9666633605957, "training_acc": 72.0, "val_loss": 1929.7813415527344, "val_acc": 28.0}
{"epoch": 36, "training_loss": 5884.445724487305, "training_acc": 48.0, "val_loss": 300.2908945083618, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2157.2863159179688, "training_acc": 56.0, "val_loss": 1425.1408576965332, "val_acc": 72.0}
{"epoch": 38, "training_loss": 4491.891700744629, "training_acc": 72.0, "val_loss": 312.81394958496094, "val_acc": 28.0}
{"epoch": 39, "training_loss": 2550.978240966797, "training_acc": 48.0, "val_loss": 789.8277282714844, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3421.7935791015625, "training_acc": 44.0, "val_loss": 2008.9855194091797, "val_acc": 72.0}
{"epoch": 41, "training_loss": 6565.100189208984, "training_acc": 72.0, "val_loss": 278.69458198547363, "val_acc": 72.0}
{"epoch": 42, "training_loss": 1915.0586395263672, "training_acc": 58.0, "val_loss": 1370.096492767334, "val_acc": 72.0}
{"epoch": 43, "training_loss": 4081.378189086914, "training_acc": 72.0, "val_loss": 673.8801956176758, "val_acc": 28.0}
{"epoch": 44, "training_loss": 3880.830093383789, "training_acc": 44.0, "val_loss": 610.5159282684326, "val_acc": 72.0}
{"epoch": 45, "training_loss": 1636.642177581787, "training_acc": 58.0, "val_loss": 1636.0895156860352, "val_acc": 72.0}
{"epoch": 46, "training_loss": 5011.046401977539, "training_acc": 72.0, "val_loss": 292.0825242996216, "val_acc": 28.0}
{"epoch": 47, "training_loss": 4060.662139892578, "training_acc": 38.0, "val_loss": 628.9462566375732, "val_acc": 72.0}
{"epoch": 48, "training_loss": 2042.5839958190918, "training_acc": 54.0, "val_loss": 1726.0648727416992, "val_acc": 72.0}
{"epoch": 49, "training_loss": 5867.411605834961, "training_acc": 72.0, "val_loss": 204.34579849243164, "val_acc": 72.0}
{"epoch": 50, "training_loss": 2485.6586303710938, "training_acc": 54.0, "val_loss": 1362.1381759643555, "val_acc": 72.0}
{"epoch": 51, "training_loss": 3994.094985961914, "training_acc": 72.0, "val_loss": 777.7121543884277, "val_acc": 28.0}
{"epoch": 52, "training_loss": 3788.703399658203, "training_acc": 46.0, "val_loss": 611.5099430084229, "val_acc": 72.0}
{"epoch": 53, "training_loss": 2365.2372817993164, "training_acc": 52.0, "val_loss": 1733.0080032348633, "val_acc": 72.0}
