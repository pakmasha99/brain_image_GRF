"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 830.2679252624512, "training_acc": 44.0, "val_loss": 466.68238639831543, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1431.5852394104004, "training_acc": 72.0, "val_loss": 375.4462718963623, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1321.6180381774902, "training_acc": 28.0, "val_loss": 118.47429275512695, "val_acc": 72.0}
{"epoch": 3, "training_loss": 624.6071510314941, "training_acc": 72.0, "val_loss": 282.18069076538086, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1100.2666473388672, "training_acc": 72.0, "val_loss": 188.34593296051025, "val_acc": 72.0}
{"epoch": 5, "training_loss": 579.9273529052734, "training_acc": 72.0, "val_loss": 241.30330085754395, "val_acc": 28.0}
{"epoch": 6, "training_loss": 979.404167175293, "training_acc": 28.0, "val_loss": 16.475827991962433, "val_acc": 72.0}
{"epoch": 7, "training_loss": 142.74260711669922, "training_acc": 72.0, "val_loss": 114.75220918655396, "val_acc": 72.0}
{"epoch": 8, "training_loss": 435.64647483825684, "training_acc": 72.0, "val_loss": 39.5890086889267, "val_acc": 72.0}
{"epoch": 9, "training_loss": 316.46196937561035, "training_acc": 56.0, "val_loss": 90.39655923843384, "val_acc": 28.0}
{"epoch": 10, "training_loss": 348.26695251464844, "training_acc": 44.0, "val_loss": 149.64622259140015, "val_acc": 72.0}
{"epoch": 11, "training_loss": 623.7996463775635, "training_acc": 72.0, "val_loss": 152.925705909729, "val_acc": 72.0}
{"epoch": 12, "training_loss": 529.5311679840088, "training_acc": 72.0, "val_loss": 15.820442140102386, "val_acc": 72.0}
{"epoch": 13, "training_loss": 363.18109130859375, "training_acc": 56.0, "val_loss": 190.35589694976807, "val_acc": 28.0}
{"epoch": 14, "training_loss": 496.8845257759094, "training_acc": 48.0, "val_loss": 92.1446442604065, "val_acc": 72.0}
{"epoch": 15, "training_loss": 420.13490295410156, "training_acc": 72.0, "val_loss": 97.19309210777283, "val_acc": 72.0}
{"epoch": 16, "training_loss": 300.0865626335144, "training_acc": 72.0, "val_loss": 129.72620725631714, "val_acc": 28.0}
{"epoch": 17, "training_loss": 487.3952293395996, "training_acc": 28.0, "val_loss": 65.30669331550598, "val_acc": 72.0}
{"epoch": 18, "training_loss": 327.38571071624756, "training_acc": 72.0, "val_loss": 147.9136347770691, "val_acc": 72.0}
{"epoch": 19, "training_loss": 570.4108772277832, "training_acc": 72.0, "val_loss": 84.45687890052795, "val_acc": 72.0}
{"epoch": 20, "training_loss": 237.97897672653198, "training_acc": 72.0, "val_loss": 165.29070138931274, "val_acc": 28.0}
{"epoch": 21, "training_loss": 557.8302307128906, "training_acc": 28.0, "val_loss": 81.54668807983398, "val_acc": 72.0}
{"epoch": 22, "training_loss": 392.949010848999, "training_acc": 72.0, "val_loss": 184.80603694915771, "val_acc": 72.0}
{"epoch": 23, "training_loss": 736.7676048278809, "training_acc": 72.0, "val_loss": 142.95014142990112, "val_acc": 72.0}
{"epoch": 24, "training_loss": 474.7992744445801, "training_acc": 72.0, "val_loss": 83.28726291656494, "val_acc": 28.0}
{"epoch": 25, "training_loss": 313.83494567871094, "training_acc": 28.0, "val_loss": 59.68758463859558, "val_acc": 72.0}
{"epoch": 26, "training_loss": 299.38502502441406, "training_acc": 72.0, "val_loss": 105.54845333099365, "val_acc": 72.0}
{"epoch": 27, "training_loss": 386.58978509902954, "training_acc": 72.0, "val_loss": 14.562922716140747, "val_acc": 72.0}
{"epoch": 28, "training_loss": 206.40531158447266, "training_acc": 56.0, "val_loss": 16.517162322998047, "val_acc": 28.0}
{"epoch": 29, "training_loss": 127.11430549621582, "training_acc": 73.0, "val_loss": 92.60786771774292, "val_acc": 72.0}
{"epoch": 30, "training_loss": 358.3798027038574, "training_acc": 72.0, "val_loss": 33.97080898284912, "val_acc": 72.0}
{"epoch": 31, "training_loss": 289.987154006958, "training_acc": 54.0, "val_loss": 78.36593389511108, "val_acc": 28.0}
{"epoch": 32, "training_loss": 329.2610158920288, "training_acc": 42.0, "val_loss": 139.78523015975952, "val_acc": 72.0}
{"epoch": 33, "training_loss": 579.9993534088135, "training_acc": 72.0, "val_loss": 139.66647386550903, "val_acc": 72.0}
{"epoch": 34, "training_loss": 473.46767234802246, "training_acc": 72.0, "val_loss": 14.496853947639465, "val_acc": 72.0}
{"epoch": 35, "training_loss": 271.7045249938965, "training_acc": 60.0, "val_loss": 129.44729328155518, "val_acc": 28.0}
{"epoch": 36, "training_loss": 450.07189559936523, "training_acc": 40.0, "val_loss": 119.17567253112793, "val_acc": 72.0}
{"epoch": 37, "training_loss": 505.8266258239746, "training_acc": 72.0, "val_loss": 115.63795804977417, "val_acc": 72.0}
{"epoch": 38, "training_loss": 399.52644538879395, "training_acc": 72.0, "val_loss": 71.65514826774597, "val_acc": 28.0}
{"epoch": 39, "training_loss": 237.9637475013733, "training_acc": 28.0, "val_loss": 81.86436295509338, "val_acc": 72.0}
{"epoch": 40, "training_loss": 434.23121070861816, "training_acc": 72.0, "val_loss": 145.56539058685303, "val_acc": 72.0}
{"epoch": 41, "training_loss": 535.8701419830322, "training_acc": 72.0, "val_loss": 51.92804932594299, "val_acc": 72.0}
{"epoch": 42, "training_loss": 237.23269939422607, "training_acc": 62.0, "val_loss": 97.40151762962341, "val_acc": 28.0}
{"epoch": 43, "training_loss": 356.1329183578491, "training_acc": 40.0, "val_loss": 99.77970719337463, "val_acc": 72.0}
{"epoch": 44, "training_loss": 400.11777210235596, "training_acc": 72.0, "val_loss": 70.25201320648193, "val_acc": 72.0}
{"epoch": 45, "training_loss": 192.41376161575317, "training_acc": 72.0, "val_loss": 147.28410243988037, "val_acc": 28.0}
{"epoch": 46, "training_loss": 466.6214761734009, "training_acc": 28.0, "val_loss": 91.27262830734253, "val_acc": 72.0}
{"epoch": 47, "training_loss": 437.26525497436523, "training_acc": 72.0, "val_loss": 183.7976336479187, "val_acc": 72.0}
{"epoch": 48, "training_loss": 722.1057815551758, "training_acc": 72.0, "val_loss": 129.75918054580688, "val_acc": 72.0}
{"epoch": 49, "training_loss": 424.78240442276, "training_acc": 72.0, "val_loss": 139.08525705337524, "val_acc": 28.0}
{"epoch": 50, "training_loss": 555.573450088501, "training_acc": 28.0, "val_loss": 37.80703544616699, "val_acc": 72.0}
{"epoch": 51, "training_loss": 250.49154090881348, "training_acc": 72.0, "val_loss": 94.00289058685303, "val_acc": 72.0}
{"epoch": 52, "training_loss": 339.94102573394775, "training_acc": 72.0, "val_loss": 23.835934698581696, "val_acc": 28.0}
{"epoch": 53, "training_loss": 97.86587381362915, "training_acc": 28.0, "val_loss": 53.795647621154785, "val_acc": 72.0}
