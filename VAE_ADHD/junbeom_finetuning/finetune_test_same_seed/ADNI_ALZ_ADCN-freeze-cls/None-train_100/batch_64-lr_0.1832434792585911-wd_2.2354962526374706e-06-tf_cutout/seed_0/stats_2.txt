"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1065.4562530517578, "training_acc": 38.0, "val_loss": 469.85769271850586, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1503.9237594604492, "training_acc": 72.0, "val_loss": 180.55025339126587, "val_acc": 28.0}
{"epoch": 2, "training_loss": 548.6312494277954, "training_acc": 28.0, "val_loss": 177.6231288909912, "val_acc": 72.0}
{"epoch": 3, "training_loss": 860.7900505065918, "training_acc": 72.0, "val_loss": 312.86449432373047, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1202.2508544921875, "training_acc": 72.0, "val_loss": 192.5608515739441, "val_acc": 72.0}
{"epoch": 5, "training_loss": 553.1513233184814, "training_acc": 72.0, "val_loss": 278.30114364624023, "val_acc": 28.0}
{"epoch": 6, "training_loss": 1148.8273429870605, "training_acc": 28.0, "val_loss": 58.10116529464722, "val_acc": 28.0}
{"epoch": 7, "training_loss": 402.4483528137207, "training_acc": 42.0, "val_loss": 278.2214641571045, "val_acc": 72.0}
{"epoch": 8, "training_loss": 1159.9335117340088, "training_acc": 72.0, "val_loss": 361.0386610031128, "val_acc": 72.0}
{"epoch": 9, "training_loss": 1431.059226989746, "training_acc": 72.0, "val_loss": 291.17164611816406, "val_acc": 72.0}
{"epoch": 10, "training_loss": 1022.9779014587402, "training_acc": 72.0, "val_loss": 64.19740319252014, "val_acc": 72.0}
{"epoch": 11, "training_loss": 505.96638107299805, "training_acc": 56.0, "val_loss": 326.7717123031616, "val_acc": 28.0}
{"epoch": 12, "training_loss": 1067.4768924713135, "training_acc": 28.0, "val_loss": 82.7329158782959, "val_acc": 72.0}
{"epoch": 13, "training_loss": 507.8590278625488, "training_acc": 72.0, "val_loss": 238.1791591644287, "val_acc": 72.0}
{"epoch": 14, "training_loss": 988.3380088806152, "training_acc": 72.0, "val_loss": 223.76644611358643, "val_acc": 72.0}
{"epoch": 15, "training_loss": 792.5239543914795, "training_acc": 72.0, "val_loss": 62.019795179367065, "val_acc": 72.0}
{"epoch": 16, "training_loss": 319.7465000152588, "training_acc": 62.0, "val_loss": 206.22942447662354, "val_acc": 28.0}
{"epoch": 17, "training_loss": 580.9360871315002, "training_acc": 28.0, "val_loss": 115.05753993988037, "val_acc": 72.0}
{"epoch": 18, "training_loss": 629.7912216186523, "training_acc": 72.0, "val_loss": 229.49965000152588, "val_acc": 72.0}
{"epoch": 19, "training_loss": 901.5251560211182, "training_acc": 72.0, "val_loss": 176.28053426742554, "val_acc": 72.0}
{"epoch": 20, "training_loss": 614.4590616226196, "training_acc": 72.0, "val_loss": 17.304959893226624, "val_acc": 28.0}
{"epoch": 21, "training_loss": 238.0496368408203, "training_acc": 46.0, "val_loss": 57.43343234062195, "val_acc": 28.0}
{"epoch": 22, "training_loss": 241.6527681350708, "training_acc": 48.0, "val_loss": 162.46240139007568, "val_acc": 72.0}
{"epoch": 23, "training_loss": 666.7140026092529, "training_acc": 72.0, "val_loss": 184.29522514343262, "val_acc": 72.0}
{"epoch": 24, "training_loss": 680.3575210571289, "training_acc": 72.0, "val_loss": 78.82014513015747, "val_acc": 72.0}
{"epoch": 25, "training_loss": 262.27088737487793, "training_acc": 58.0, "val_loss": 65.58206081390381, "val_acc": 28.0}
{"epoch": 26, "training_loss": 277.2297763824463, "training_acc": 40.0, "val_loss": 95.92787623405457, "val_acc": 72.0}
{"epoch": 27, "training_loss": 371.80633544921875, "training_acc": 72.0, "val_loss": 53.15141677856445, "val_acc": 72.0}
{"epoch": 28, "training_loss": 187.47999477386475, "training_acc": 56.0, "val_loss": 15.646979212760925, "val_acc": 32.0}
{"epoch": 29, "training_loss": 88.17203712463379, "training_acc": 72.0, "val_loss": 29.04643714427948, "val_acc": 72.0}
{"epoch": 30, "training_loss": 99.23316311836243, "training_acc": 60.0, "val_loss": 16.231447458267212, "val_acc": 72.0}
{"epoch": 31, "training_loss": 62.908806562423706, "training_acc": 72.0, "val_loss": 22.510789334774017, "val_acc": 28.0}
{"epoch": 32, "training_loss": 74.64650678634644, "training_acc": 52.0, "val_loss": 31.241437792778015, "val_acc": 72.0}
{"epoch": 33, "training_loss": 89.65152668952942, "training_acc": 72.0, "val_loss": 74.28973317146301, "val_acc": 28.0}
{"epoch": 34, "training_loss": 269.8822021484375, "training_acc": 38.0, "val_loss": 49.19421374797821, "val_acc": 72.0}
{"epoch": 35, "training_loss": 156.67803049087524, "training_acc": 72.0, "val_loss": 86.21076941490173, "val_acc": 28.0}
{"epoch": 36, "training_loss": 232.30681943893433, "training_acc": 48.0, "val_loss": 57.1753203868866, "val_acc": 72.0}
{"epoch": 37, "training_loss": 245.74647331237793, "training_acc": 72.0, "val_loss": 41.165924072265625, "val_acc": 72.0}
{"epoch": 38, "training_loss": 172.44101524353027, "training_acc": 58.0, "val_loss": 15.386615693569183, "val_acc": 72.0}
{"epoch": 39, "training_loss": 92.04414510726929, "training_acc": 72.0, "val_loss": 14.814981818199158, "val_acc": 64.0}
{"epoch": 40, "training_loss": 98.0513687133789, "training_acc": 54.0, "val_loss": 53.652167320251465, "val_acc": 72.0}
{"epoch": 41, "training_loss": 252.31451511383057, "training_acc": 72.0, "val_loss": 62.53407597541809, "val_acc": 72.0}
{"epoch": 42, "training_loss": 185.95690941810608, "training_acc": 72.0, "val_loss": 103.16003561019897, "val_acc": 28.0}
{"epoch": 43, "training_loss": 307.0189559459686, "training_acc": 40.0, "val_loss": 35.917624831199646, "val_acc": 72.0}
{"epoch": 44, "training_loss": 114.70380306243896, "training_acc": 72.0, "val_loss": 86.58770322799683, "val_acc": 28.0}
{"epoch": 45, "training_loss": 236.78278374671936, "training_acc": 46.0, "val_loss": 42.71484911441803, "val_acc": 72.0}
{"epoch": 46, "training_loss": 153.14030575752258, "training_acc": 72.0, "val_loss": 28.180691599845886, "val_acc": 28.0}
{"epoch": 47, "training_loss": 120.49509620666504, "training_acc": 40.0, "val_loss": 19.52877789735794, "val_acc": 72.0}
{"epoch": 48, "training_loss": 118.8855676651001, "training_acc": 56.0, "val_loss": 37.41448223590851, "val_acc": 72.0}
{"epoch": 49, "training_loss": 164.03402757644653, "training_acc": 72.0, "val_loss": 25.888121128082275, "val_acc": 72.0}
{"epoch": 50, "training_loss": 199.1673936843872, "training_acc": 54.0, "val_loss": 16.25804901123047, "val_acc": 72.0}
{"epoch": 51, "training_loss": 91.42932939529419, "training_acc": 72.0, "val_loss": 23.98727983236313, "val_acc": 72.0}
{"epoch": 52, "training_loss": 172.00041484832764, "training_acc": 52.0, "val_loss": 30.013126134872437, "val_acc": 72.0}
{"epoch": 53, "training_loss": 142.30456638336182, "training_acc": 72.0, "val_loss": 23.036177456378937, "val_acc": 72.0}
{"epoch": 54, "training_loss": 192.42321014404297, "training_acc": 54.0, "val_loss": 16.9542133808136, "val_acc": 72.0}
{"epoch": 55, "training_loss": 106.12267351150513, "training_acc": 72.0, "val_loss": 22.852593660354614, "val_acc": 72.0}
{"epoch": 56, "training_loss": 159.1661548614502, "training_acc": 56.0, "val_loss": 23.070937395095825, "val_acc": 72.0}
{"epoch": 57, "training_loss": 93.46498990058899, "training_acc": 72.0, "val_loss": 15.72665274143219, "val_acc": 72.0}
{"epoch": 58, "training_loss": 148.80823230743408, "training_acc": 50.0, "val_loss": 45.75251042842865, "val_acc": 72.0}
