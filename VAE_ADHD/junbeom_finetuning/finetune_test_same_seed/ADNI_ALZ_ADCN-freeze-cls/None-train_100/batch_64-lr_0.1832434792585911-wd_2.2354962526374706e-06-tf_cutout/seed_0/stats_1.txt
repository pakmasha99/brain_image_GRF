"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 985.598014831543, "training_acc": 72.0, "val_loss": 384.57462787628174, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1132.3261547088623, "training_acc": 72.0, "val_loss": 789.313268661499, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2997.0992431640625, "training_acc": 28.0, "val_loss": 137.42434978485107, "val_acc": 28.0}
{"epoch": 3, "training_loss": 754.2210807800293, "training_acc": 42.0, "val_loss": 454.94837760925293, "val_acc": 72.0}
{"epoch": 4, "training_loss": 2044.1095657348633, "training_acc": 72.0, "val_loss": 639.0902042388916, "val_acc": 72.0}
{"epoch": 5, "training_loss": 2552.039192199707, "training_acc": 72.0, "val_loss": 585.1511478424072, "val_acc": 72.0}
{"epoch": 6, "training_loss": 2207.346481323242, "training_acc": 72.0, "val_loss": 361.5811586380005, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1156.5786094665527, "training_acc": 72.0, "val_loss": 14.878138899803162, "val_acc": 72.0}
{"epoch": 8, "training_loss": 849.7475242614746, "training_acc": 48.0, "val_loss": 571.983528137207, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2023.319938659668, "training_acc": 28.0, "val_loss": 14.800882339477539, "val_acc": 72.0}
{"epoch": 10, "training_loss": 159.66656303405762, "training_acc": 72.0, "val_loss": 231.51898384094238, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1025.7830924987793, "training_acc": 72.0, "val_loss": 284.10582542419434, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1083.2023010253906, "training_acc": 72.0, "val_loss": 170.7876205444336, "val_acc": 72.0}
{"epoch": 13, "training_loss": 535.0702352523804, "training_acc": 72.0, "val_loss": 166.77623987197876, "val_acc": 28.0}
{"epoch": 14, "training_loss": 758.7739562988281, "training_acc": 28.0, "val_loss": 27.27448344230652, "val_acc": 28.0}
{"epoch": 15, "training_loss": 268.6796760559082, "training_acc": 42.0, "val_loss": 207.80677795410156, "val_acc": 72.0}
{"epoch": 16, "training_loss": 863.2666339874268, "training_acc": 72.0, "val_loss": 243.59071254730225, "val_acc": 72.0}
{"epoch": 17, "training_loss": 925.5198974609375, "training_acc": 72.0, "val_loss": 144.29137706756592, "val_acc": 72.0}
{"epoch": 18, "training_loss": 447.75518703460693, "training_acc": 72.0, "val_loss": 206.47075176239014, "val_acc": 28.0}
{"epoch": 19, "training_loss": 895.5176124572754, "training_acc": 28.0, "val_loss": 52.56837606430054, "val_acc": 28.0}
{"epoch": 20, "training_loss": 371.47190284729004, "training_acc": 40.0, "val_loss": 233.8583469390869, "val_acc": 72.0}
{"epoch": 21, "training_loss": 1002.9235076904297, "training_acc": 72.0, "val_loss": 302.5247812271118, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1180.4519348144531, "training_acc": 72.0, "val_loss": 227.78520584106445, "val_acc": 72.0}
{"epoch": 23, "training_loss": 761.419677734375, "training_acc": 72.0, "val_loss": 28.669831156730652, "val_acc": 72.0}
{"epoch": 24, "training_loss": 440.69485092163086, "training_acc": 60.0, "val_loss": 377.64577865600586, "val_acc": 28.0}
{"epoch": 25, "training_loss": 1301.1348152160645, "training_acc": 28.0, "val_loss": 48.53387773036957, "val_acc": 72.0}
{"epoch": 26, "training_loss": 322.1171932220459, "training_acc": 72.0, "val_loss": 184.5046043395996, "val_acc": 72.0}
{"epoch": 27, "training_loss": 747.8812351226807, "training_acc": 72.0, "val_loss": 162.81085014343262, "val_acc": 72.0}
{"epoch": 28, "training_loss": 563.7689762115479, "training_acc": 72.0, "val_loss": 15.428641438484192, "val_acc": 72.0}
