"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 8923.587783813477, "training_acc": 71.0, "val_loss": 3154.718589782715, "val_acc": 72.0}
{"epoch": 1, "training_loss": 9083.71416091919, "training_acc": 72.0, "val_loss": 6551.538848876953, "val_acc": 28.0}
{"epoch": 2, "training_loss": 23236.197265625, "training_acc": 28.0, "val_loss": 328.1470537185669, "val_acc": 72.0}
{"epoch": 3, "training_loss": 2165.299545288086, "training_acc": 72.0, "val_loss": 1435.5666160583496, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5224.278884887695, "training_acc": 72.0, "val_loss": 298.75519275665283, "val_acc": 72.0}
{"epoch": 5, "training_loss": 4276.183990478516, "training_acc": 52.0, "val_loss": 1153.1256675720215, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4121.567718505859, "training_acc": 44.0, "val_loss": 1419.8909759521484, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5703.397735595703, "training_acc": 72.0, "val_loss": 1151.5119552612305, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3784.8512115478516, "training_acc": 72.0, "val_loss": 803.5876274108887, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2260.052314758301, "training_acc": 28.0, "val_loss": 1022.5916862487793, "val_acc": 72.0}
{"epoch": 10, "training_loss": 4551.2125244140625, "training_acc": 72.0, "val_loss": 1607.7875137329102, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6059.084991455078, "training_acc": 72.0, "val_loss": 806.3965797424316, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1966.314832687378, "training_acc": 72.0, "val_loss": 2290.660285949707, "val_acc": 28.0}
{"epoch": 13, "training_loss": 8810.550323486328, "training_acc": 28.0, "val_loss": 105.72149753570557, "val_acc": 72.0}
{"epoch": 14, "training_loss": 834.064510345459, "training_acc": 72.0, "val_loss": 501.6861915588379, "val_acc": 72.0}
{"epoch": 15, "training_loss": 1602.2446022033691, "training_acc": 72.0, "val_loss": 866.6896820068359, "val_acc": 28.0}
{"epoch": 16, "training_loss": 2214.9373083114624, "training_acc": 46.0, "val_loss": 60.35236120223999, "val_acc": 72.0}
{"epoch": 17, "training_loss": 817.5974273681641, "training_acc": 60.0, "val_loss": 331.1055898666382, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1469.1775283813477, "training_acc": 72.0, "val_loss": 204.91044521331787, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1598.2960357666016, "training_acc": 56.0, "val_loss": 120.63325643539429, "val_acc": 72.0}
{"epoch": 20, "training_loss": 498.9670810699463, "training_acc": 72.0, "val_loss": 412.44311332702637, "val_acc": 28.0}
{"epoch": 21, "training_loss": 1818.801124572754, "training_acc": 40.0, "val_loss": 510.56995391845703, "val_acc": 72.0}
{"epoch": 22, "training_loss": 1686.092544555664, "training_acc": 72.0, "val_loss": 571.0485935211182, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1742.4029006958008, "training_acc": 42.0, "val_loss": 132.03743696212769, "val_acc": 72.0}
{"epoch": 24, "training_loss": 1534.3407592773438, "training_acc": 48.0, "val_loss": 316.9189453125, "val_acc": 72.0}
{"epoch": 25, "training_loss": 1769.3676147460938, "training_acc": 72.0, "val_loss": 289.0261173248291, "val_acc": 72.0}
{"epoch": 26, "training_loss": 1559.2751693725586, "training_acc": 56.0, "val_loss": 148.59265089035034, "val_acc": 72.0}
{"epoch": 27, "training_loss": 578.1213665008545, "training_acc": 72.0, "val_loss": 418.97406578063965, "val_acc": 28.0}
{"epoch": 28, "training_loss": 1395.9150352478027, "training_acc": 48.0, "val_loss": 470.4802989959717, "val_acc": 72.0}
{"epoch": 29, "training_loss": 1608.8075561523438, "training_acc": 72.0, "val_loss": 431.41493797302246, "val_acc": 28.0}
{"epoch": 30, "training_loss": 1763.467529296875, "training_acc": 36.0, "val_loss": 223.8372802734375, "val_acc": 72.0}
{"epoch": 31, "training_loss": 916.8143272399902, "training_acc": 58.0, "val_loss": 366.6105031967163, "val_acc": 72.0}
{"epoch": 32, "training_loss": 1684.0723114013672, "training_acc": 72.0, "val_loss": 193.27725172042847, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1606.4934616088867, "training_acc": 58.0, "val_loss": 18.917907774448395, "val_acc": 72.0}
{"epoch": 34, "training_loss": 310.8878746032715, "training_acc": 72.0, "val_loss": 462.6837730407715, "val_acc": 28.0}
{"epoch": 35, "training_loss": 1558.4613761901855, "training_acc": 46.0, "val_loss": 430.8441638946533, "val_acc": 72.0}
{"epoch": 36, "training_loss": 1443.164951324463, "training_acc": 72.0, "val_loss": 610.6366634368896, "val_acc": 28.0}
{"epoch": 37, "training_loss": 2008.475929260254, "training_acc": 40.0, "val_loss": 228.57632637023926, "val_acc": 72.0}
{"epoch": 38, "training_loss": 1044.9891815185547, "training_acc": 52.0, "val_loss": 460.7059955596924, "val_acc": 72.0}
{"epoch": 39, "training_loss": 1900.8499031066895, "training_acc": 72.0, "val_loss": 408.089542388916, "val_acc": 72.0}
{"epoch": 40, "training_loss": 1028.0689492225647, "training_acc": 72.0, "val_loss": 1461.9396209716797, "val_acc": 28.0}
{"epoch": 41, "training_loss": 4708.380783081055, "training_acc": 28.0, "val_loss": 722.0836162567139, "val_acc": 72.0}
{"epoch": 42, "training_loss": 3724.5794067382812, "training_acc": 72.0, "val_loss": 1231.1145782470703, "val_acc": 72.0}
{"epoch": 43, "training_loss": 4574.380424499512, "training_acc": 72.0, "val_loss": 398.1877326965332, "val_acc": 72.0}
{"epoch": 44, "training_loss": 2079.8275299072266, "training_acc": 56.0, "val_loss": 131.52759075164795, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1590.3970642089844, "training_acc": 44.0, "val_loss": 1301.2473106384277, "val_acc": 72.0}
{"epoch": 46, "training_loss": 5291.816680908203, "training_acc": 72.0, "val_loss": 1028.2320022583008, "val_acc": 72.0}
{"epoch": 47, "training_loss": 3300.865966796875, "training_acc": 72.0, "val_loss": 713.7639999389648, "val_acc": 28.0}
{"epoch": 48, "training_loss": 2342.3680419921875, "training_acc": 28.0, "val_loss": 802.1144866943359, "val_acc": 72.0}
{"epoch": 49, "training_loss": 4126.109924316406, "training_acc": 72.0, "val_loss": 1291.7173385620117, "val_acc": 72.0}
{"epoch": 50, "training_loss": 4663.97492980957, "training_acc": 72.0, "val_loss": 422.1435546875, "val_acc": 72.0}
{"epoch": 51, "training_loss": 2215.421661376953, "training_acc": 58.0, "val_loss": 480.05924224853516, "val_acc": 28.0}
{"epoch": 52, "training_loss": 1910.7788848876953, "training_acc": 48.0, "val_loss": 1055.1623344421387, "val_acc": 72.0}
