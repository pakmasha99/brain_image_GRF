"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 7558.195915222168, "training_acc": 72.0, "val_loss": 3154.06551361084, "val_acc": 72.0}
{"epoch": 1, "training_loss": 8208.307006835938, "training_acc": 72.0, "val_loss": 7346.581268310547, "val_acc": 28.0}
{"epoch": 2, "training_loss": 26331.85272216797, "training_acc": 28.0, "val_loss": 88.10703754425049, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1401.3040390014648, "training_acc": 72.0, "val_loss": 1246.004581451416, "val_acc": 72.0}
{"epoch": 4, "training_loss": 4471.973121643066, "training_acc": 72.0, "val_loss": 80.53070902824402, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3203.1473236083984, "training_acc": 62.0, "val_loss": 1499.8197555541992, "val_acc": 28.0}
{"epoch": 6, "training_loss": 3847.1832733154297, "training_acc": 54.0, "val_loss": 1321.7341423034668, "val_acc": 72.0}
{"epoch": 7, "training_loss": 5378.913528442383, "training_acc": 72.0, "val_loss": 1128.6784172058105, "val_acc": 72.0}
{"epoch": 8, "training_loss": 3745.0475997924805, "training_acc": 72.0, "val_loss": 997.3599433898926, "val_acc": 28.0}
{"epoch": 9, "training_loss": 2735.909996032715, "training_acc": 28.0, "val_loss": 1100.0983238220215, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5523.681243896484, "training_acc": 72.0, "val_loss": 1705.620002746582, "val_acc": 72.0}
{"epoch": 11, "training_loss": 6543.480491638184, "training_acc": 72.0, "val_loss": 688.7400150299072, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1910.9804573059082, "training_acc": 58.0, "val_loss": 196.62389755249023, "val_acc": 72.0}
{"epoch": 13, "training_loss": 885.9522743225098, "training_acc": 44.0, "val_loss": 767.3041820526123, "val_acc": 72.0}
{"epoch": 14, "training_loss": 3586.478057861328, "training_acc": 72.0, "val_loss": 996.5958595275879, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3398.2922286987305, "training_acc": 72.0, "val_loss": 153.93050909042358, "val_acc": 28.0}
{"epoch": 16, "training_loss": 681.5369262695312, "training_acc": 46.0, "val_loss": 177.5787591934204, "val_acc": 72.0}
{"epoch": 17, "training_loss": 615.6946811676025, "training_acc": 66.0, "val_loss": 344.6629762649536, "val_acc": 72.0}
{"epoch": 18, "training_loss": 1482.6361618041992, "training_acc": 72.0, "val_loss": 74.1064190864563, "val_acc": 72.0}
{"epoch": 19, "training_loss": 2213.613006591797, "training_acc": 54.0, "val_loss": 360.2002143859863, "val_acc": 28.0}
{"epoch": 20, "training_loss": 2784.926971435547, "training_acc": 38.0, "val_loss": 1440.7475471496582, "val_acc": 72.0}
{"epoch": 21, "training_loss": 5896.711975097656, "training_acc": 72.0, "val_loss": 1199.9382972717285, "val_acc": 72.0}
{"epoch": 22, "training_loss": 4039.2962646484375, "training_acc": 72.0, "val_loss": 349.4910717010498, "val_acc": 28.0}
{"epoch": 23, "training_loss": 1111.109764099121, "training_acc": 40.0, "val_loss": 175.17086267471313, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1036.2902374267578, "training_acc": 48.0, "val_loss": 757.9402446746826, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2833.8916244506836, "training_acc": 72.0, "val_loss": 206.43672943115234, "val_acc": 72.0}
{"epoch": 26, "training_loss": 2070.791702270508, "training_acc": 56.0, "val_loss": 282.3173761367798, "val_acc": 28.0}
{"epoch": 27, "training_loss": 1986.2511291503906, "training_acc": 44.0, "val_loss": 1359.7601890563965, "val_acc": 72.0}
{"epoch": 28, "training_loss": 5512.192398071289, "training_acc": 72.0, "val_loss": 1137.786865234375, "val_acc": 72.0}
{"epoch": 29, "training_loss": 3900.966209411621, "training_acc": 72.0, "val_loss": 314.25468921661377, "val_acc": 28.0}
{"epoch": 30, "training_loss": 1028.6147193908691, "training_acc": 42.0, "val_loss": 15.102189779281616, "val_acc": 68.0}
{"epoch": 31, "training_loss": 60.31950354576111, "training_acc": 72.0, "val_loss": 231.47244453430176, "val_acc": 28.0}
{"epoch": 32, "training_loss": 1458.7531814575195, "training_acc": 44.0, "val_loss": 845.3438758850098, "val_acc": 72.0}
{"epoch": 33, "training_loss": 3190.211395263672, "training_acc": 72.0, "val_loss": 301.0876655578613, "val_acc": 72.0}
{"epoch": 34, "training_loss": 1818.2347717285156, "training_acc": 58.0, "val_loss": 38.80535066127777, "val_acc": 28.0}
{"epoch": 35, "training_loss": 1319.1082000732422, "training_acc": 44.0, "val_loss": 1224.325180053711, "val_acc": 72.0}
{"epoch": 36, "training_loss": 4818.906234741211, "training_acc": 72.0, "val_loss": 847.4458694458008, "val_acc": 72.0}
{"epoch": 37, "training_loss": 2440.4526596069336, "training_acc": 72.0, "val_loss": 1191.6068077087402, "val_acc": 28.0}
{"epoch": 38, "training_loss": 4091.590789794922, "training_acc": 28.0, "val_loss": 621.4807987213135, "val_acc": 72.0}
{"epoch": 39, "training_loss": 2823.229019165039, "training_acc": 72.0, "val_loss": 1002.249813079834, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3641.2924575805664, "training_acc": 72.0, "val_loss": 179.72897291183472, "val_acc": 72.0}
{"epoch": 41, "training_loss": 2742.523635864258, "training_acc": 52.0, "val_loss": 706.0991287231445, "val_acc": 28.0}
{"epoch": 42, "training_loss": 2827.615577697754, "training_acc": 44.0, "val_loss": 1185.4480743408203, "val_acc": 72.0}
{"epoch": 43, "training_loss": 4755.102020263672, "training_acc": 72.0, "val_loss": 953.199577331543, "val_acc": 72.0}
{"epoch": 44, "training_loss": 3250.8727226257324, "training_acc": 72.0, "val_loss": 677.6577472686768, "val_acc": 28.0}
{"epoch": 45, "training_loss": 1812.8347115516663, "training_acc": 42.0, "val_loss": 142.26521253585815, "val_acc": 28.0}
{"epoch": 46, "training_loss": 1172.9087753295898, "training_acc": 46.0, "val_loss": 899.8349189758301, "val_acc": 72.0}
{"epoch": 47, "training_loss": 3467.308578491211, "training_acc": 72.0, "val_loss": 391.5130615234375, "val_acc": 72.0}
{"epoch": 48, "training_loss": 1960.3357696533203, "training_acc": 56.0, "val_loss": 25.299280881881714, "val_acc": 72.0}
{"epoch": 49, "training_loss": 492.0112991333008, "training_acc": 48.0, "val_loss": 700.9401798248291, "val_acc": 72.0}
