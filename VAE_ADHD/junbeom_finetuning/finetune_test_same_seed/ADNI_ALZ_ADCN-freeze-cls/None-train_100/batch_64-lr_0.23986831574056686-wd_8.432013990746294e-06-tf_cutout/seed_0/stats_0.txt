"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1174.4928588867188, "training_acc": 42.0, "val_loss": 618.3090686798096, "val_acc": 72.0}
{"epoch": 1, "training_loss": 1941.500114440918, "training_acc": 72.0, "val_loss": 360.949182510376, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1231.7455596923828, "training_acc": 28.0, "val_loss": 196.187162399292, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1011.8389358520508, "training_acc": 72.0, "val_loss": 413.79284858703613, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1620.161376953125, "training_acc": 72.0, "val_loss": 292.2663450241089, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1019.5156526565552, "training_acc": 72.0, "val_loss": 201.33557319641113, "val_acc": 28.0}
{"epoch": 6, "training_loss": 793.0259399414062, "training_acc": 28.0, "val_loss": 74.83087182044983, "val_acc": 72.0}
{"epoch": 7, "training_loss": 366.1418151855469, "training_acc": 72.0, "val_loss": 163.5536789894104, "val_acc": 72.0}
{"epoch": 8, "training_loss": 600.2974185943604, "training_acc": 72.0, "val_loss": 38.45297396183014, "val_acc": 72.0}
{"epoch": 9, "training_loss": 559.1356544494629, "training_acc": 50.0, "val_loss": 208.10163021087646, "val_acc": 28.0}
{"epoch": 10, "training_loss": 627.20290184021, "training_acc": 44.0, "val_loss": 151.0622501373291, "val_acc": 72.0}
{"epoch": 11, "training_loss": 642.4804954528809, "training_acc": 72.0, "val_loss": 154.19610738754272, "val_acc": 72.0}
{"epoch": 12, "training_loss": 520.7410144805908, "training_acc": 72.0, "val_loss": 79.37545776367188, "val_acc": 28.0}
{"epoch": 13, "training_loss": 262.9631862640381, "training_acc": 28.0, "val_loss": 119.30177211761475, "val_acc": 72.0}
{"epoch": 14, "training_loss": 617.5006904602051, "training_acc": 72.0, "val_loss": 220.3047513961792, "val_acc": 72.0}
{"epoch": 15, "training_loss": 837.1602058410645, "training_acc": 72.0, "val_loss": 116.27460718154907, "val_acc": 72.0}
{"epoch": 16, "training_loss": 287.9666004180908, "training_acc": 72.0, "val_loss": 225.19652843475342, "val_acc": 28.0}
{"epoch": 17, "training_loss": 764.2056121826172, "training_acc": 28.0, "val_loss": 105.05388975143433, "val_acc": 72.0}
{"epoch": 18, "training_loss": 617.0212097167969, "training_acc": 72.0, "val_loss": 248.56815338134766, "val_acc": 72.0}
{"epoch": 19, "training_loss": 972.4593906402588, "training_acc": 72.0, "val_loss": 177.07780599594116, "val_acc": 72.0}
{"epoch": 20, "training_loss": 584.0063953399658, "training_acc": 72.0, "val_loss": 119.83963251113892, "val_acc": 28.0}
{"epoch": 21, "training_loss": 441.2923746109009, "training_acc": 28.0, "val_loss": 78.40792536735535, "val_acc": 72.0}
{"epoch": 22, "training_loss": 393.6885051727295, "training_acc": 72.0, "val_loss": 141.12533330917358, "val_acc": 72.0}
{"epoch": 23, "training_loss": 507.2076711654663, "training_acc": 72.0, "val_loss": 18.943671882152557, "val_acc": 72.0}
{"epoch": 24, "training_loss": 381.2393112182617, "training_acc": 56.0, "val_loss": 168.50857734680176, "val_acc": 28.0}
{"epoch": 25, "training_loss": 554.9702234268188, "training_acc": 42.0, "val_loss": 149.51658248901367, "val_acc": 72.0}
{"epoch": 26, "training_loss": 623.7382774353027, "training_acc": 72.0, "val_loss": 148.68117570877075, "val_acc": 72.0}
{"epoch": 27, "training_loss": 498.90191173553467, "training_acc": 72.0, "val_loss": 57.592445611953735, "val_acc": 28.0}
{"epoch": 28, "training_loss": 185.95743465423584, "training_acc": 28.0, "val_loss": 86.29615306854248, "val_acc": 72.0}
{"epoch": 29, "training_loss": 400.0150260925293, "training_acc": 72.0, "val_loss": 115.60931205749512, "val_acc": 72.0}
{"epoch": 30, "training_loss": 397.89918756484985, "training_acc": 72.0, "val_loss": 93.1115984916687, "val_acc": 28.0}
{"epoch": 31, "training_loss": 287.8639454841614, "training_acc": 36.0, "val_loss": 20.952777564525604, "val_acc": 72.0}
{"epoch": 32, "training_loss": 117.88657665252686, "training_acc": 52.0, "val_loss": 62.586647272109985, "val_acc": 72.0}
{"epoch": 33, "training_loss": 269.71260833740234, "training_acc": 72.0, "val_loss": 60.93306541442871, "val_acc": 72.0}
{"epoch": 34, "training_loss": 160.40805888175964, "training_acc": 73.0, "val_loss": 90.48194885253906, "val_acc": 28.0}
{"epoch": 35, "training_loss": 302.9673295021057, "training_acc": 44.0, "val_loss": 78.09770703315735, "val_acc": 72.0}
{"epoch": 36, "training_loss": 282.37398624420166, "training_acc": 72.0, "val_loss": 21.642181277275085, "val_acc": 28.0}
{"epoch": 37, "training_loss": 91.45795440673828, "training_acc": 36.0, "val_loss": 36.294424533843994, "val_acc": 28.0}
{"epoch": 38, "training_loss": 195.02890586853027, "training_acc": 42.0, "val_loss": 79.5640230178833, "val_acc": 72.0}
{"epoch": 39, "training_loss": 275.1203203201294, "training_acc": 72.0, "val_loss": 62.61678338050842, "val_acc": 28.0}
{"epoch": 40, "training_loss": 205.36486506462097, "training_acc": 40.0, "val_loss": 16.83269888162613, "val_acc": 72.0}
{"epoch": 41, "training_loss": 101.41889476776123, "training_acc": 58.0, "val_loss": 56.72420859336853, "val_acc": 72.0}
{"epoch": 42, "training_loss": 246.81252765655518, "training_acc": 72.0, "val_loss": 46.91213369369507, "val_acc": 72.0}
{"epoch": 43, "training_loss": 250.44343662261963, "training_acc": 52.0, "val_loss": 29.550760984420776, "val_acc": 72.0}
{"epoch": 44, "training_loss": 128.26507711410522, "training_acc": 72.0, "val_loss": 15.793351829051971, "val_acc": 44.0}
{"epoch": 45, "training_loss": 62.785701274871826, "training_acc": 71.0, "val_loss": 20.812226831912994, "val_acc": 72.0}
{"epoch": 46, "training_loss": 99.32851696014404, "training_acc": 52.0, "val_loss": 57.10654854774475, "val_acc": 72.0}
{"epoch": 47, "training_loss": 255.32474040985107, "training_acc": 72.0, "val_loss": 33.27011168003082, "val_acc": 72.0}
{"epoch": 48, "training_loss": 313.9463653564453, "training_acc": 52.0, "val_loss": 19.33005154132843, "val_acc": 28.0}
{"epoch": 49, "training_loss": 171.95567893981934, "training_acc": 47.0, "val_loss": 144.31231021881104, "val_acc": 72.0}
{"epoch": 50, "training_loss": 564.1983966827393, "training_acc": 72.0, "val_loss": 88.43470811843872, "val_acc": 72.0}
{"epoch": 51, "training_loss": 268.3418343067169, "training_acc": 56.0, "val_loss": 57.56552219390869, "val_acc": 28.0}
{"epoch": 52, "training_loss": 254.3067502975464, "training_acc": 44.0, "val_loss": 115.82328081130981, "val_acc": 72.0}
{"epoch": 53, "training_loss": 442.35365772247314, "training_acc": 72.0, "val_loss": 47.22501337528229, "val_acc": 72.0}
{"epoch": 54, "training_loss": 286.74319076538086, "training_acc": 56.0, "val_loss": 22.332845628261566, "val_acc": 28.0}
{"epoch": 55, "training_loss": 165.9205083847046, "training_acc": 48.0, "val_loss": 149.12574291229248, "val_acc": 72.0}
{"epoch": 56, "training_loss": 588.7665100097656, "training_acc": 72.0, "val_loss": 102.06326246261597, "val_acc": 72.0}
{"epoch": 57, "training_loss": 307.3495054244995, "training_acc": 72.0, "val_loss": 202.59802341461182, "val_acc": 28.0}
{"epoch": 58, "training_loss": 651.7388181686401, "training_acc": 28.0, "val_loss": 119.85659599304199, "val_acc": 72.0}
{"epoch": 59, "training_loss": 582.9824886322021, "training_acc": 72.0, "val_loss": 234.47394371032715, "val_acc": 72.0}
{"epoch": 60, "training_loss": 906.4441204071045, "training_acc": 72.0, "val_loss": 149.393630027771, "val_acc": 72.0}
{"epoch": 61, "training_loss": 459.25828647613525, "training_acc": 72.0, "val_loss": 237.58926391601562, "val_acc": 28.0}
{"epoch": 62, "training_loss": 948.2376289367676, "training_acc": 28.0, "val_loss": 28.76272201538086, "val_acc": 72.0}
{"epoch": 63, "training_loss": 259.8799514770508, "training_acc": 72.0, "val_loss": 102.63644456863403, "val_acc": 72.0}
