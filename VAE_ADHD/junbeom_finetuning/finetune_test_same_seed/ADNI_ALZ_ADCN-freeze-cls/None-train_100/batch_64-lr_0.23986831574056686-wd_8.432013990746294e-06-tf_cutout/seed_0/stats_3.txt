"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 1276.994400024414, "training_acc": 40.0, "val_loss": 594.2432880401611, "val_acc": 72.0}
{"epoch": 1, "training_loss": 2161.0733489990234, "training_acc": 72.0, "val_loss": 428.10678482055664, "val_acc": 28.0}
{"epoch": 2, "training_loss": 1323.9286766052246, "training_acc": 28.0, "val_loss": 241.7116641998291, "val_acc": 72.0}
{"epoch": 3, "training_loss": 1207.3137435913086, "training_acc": 72.0, "val_loss": 474.1139888763428, "val_acc": 72.0}
{"epoch": 4, "training_loss": 1860.4932975769043, "training_acc": 72.0, "val_loss": 354.6459197998047, "val_acc": 72.0}
{"epoch": 5, "training_loss": 1181.4283561706543, "training_acc": 72.0, "val_loss": 25.347566604614258, "val_acc": 28.0}
{"epoch": 6, "training_loss": 355.4785690307617, "training_acc": 28.0, "val_loss": 23.081307113170624, "val_acc": 72.0}
{"epoch": 7, "training_loss": 166.9462890625, "training_acc": 72.0, "val_loss": 34.410396218299866, "val_acc": 72.0}
{"epoch": 8, "training_loss": 388.95616912841797, "training_acc": 48.0, "val_loss": 16.300828754901886, "val_acc": 72.0}
{"epoch": 9, "training_loss": 122.0362195968628, "training_acc": 72.0, "val_loss": 41.939714550971985, "val_acc": 72.0}
{"epoch": 10, "training_loss": 286.51781845092773, "training_acc": 48.0, "val_loss": 45.70719003677368, "val_acc": 72.0}
{"epoch": 11, "training_loss": 243.1588077545166, "training_acc": 72.0, "val_loss": 42.945700883865356, "val_acc": 72.0}
{"epoch": 12, "training_loss": 276.2425079345703, "training_acc": 54.0, "val_loss": 16.687294840812683, "val_acc": 72.0}
{"epoch": 13, "training_loss": 94.9518609046936, "training_acc": 72.0, "val_loss": 15.058335661888123, "val_acc": 72.0}
{"epoch": 14, "training_loss": 150.57135486602783, "training_acc": 56.0, "val_loss": 55.22952079772949, "val_acc": 72.0}
{"epoch": 15, "training_loss": 280.47643661499023, "training_acc": 72.0, "val_loss": 64.26457166671753, "val_acc": 72.0}
{"epoch": 16, "training_loss": 186.85509872436523, "training_acc": 58.0, "val_loss": 24.00476336479187, "val_acc": 28.0}
{"epoch": 17, "training_loss": 155.21433448791504, "training_acc": 44.0, "val_loss": 82.32823610305786, "val_acc": 72.0}
{"epoch": 18, "training_loss": 284.48722743988037, "training_acc": 72.0, "val_loss": 78.61442565917969, "val_acc": 28.0}
{"epoch": 19, "training_loss": 227.05631637573242, "training_acc": 46.0, "val_loss": 33.93014371395111, "val_acc": 72.0}
{"epoch": 20, "training_loss": 95.70696210861206, "training_acc": 72.0, "val_loss": 71.13375663757324, "val_acc": 28.0}
{"epoch": 21, "training_loss": 197.76317286491394, "training_acc": 54.0, "val_loss": 97.53682017326355, "val_acc": 72.0}
{"epoch": 22, "training_loss": 376.12019634246826, "training_acc": 72.0, "val_loss": 35.12377738952637, "val_acc": 72.0}
{"epoch": 23, "training_loss": 356.3954620361328, "training_acc": 52.0, "val_loss": 46.179214119911194, "val_acc": 28.0}
{"epoch": 24, "training_loss": 281.98167419433594, "training_acc": 46.0, "val_loss": 221.34137153625488, "val_acc": 72.0}
{"epoch": 25, "training_loss": 963.866771697998, "training_acc": 72.0, "val_loss": 239.21737670898438, "val_acc": 72.0}
{"epoch": 26, "training_loss": 907.2564334869385, "training_acc": 72.0, "val_loss": 54.053425788879395, "val_acc": 72.0}
{"epoch": 27, "training_loss": 418.8650493621826, "training_acc": 58.0, "val_loss": 206.73000812530518, "val_acc": 28.0}
{"epoch": 28, "training_loss": 474.74369978904724, "training_acc": 56.0, "val_loss": 107.04631805419922, "val_acc": 72.0}
{"epoch": 29, "training_loss": 472.0336608886719, "training_acc": 72.0, "val_loss": 107.39462375640869, "val_acc": 72.0}
{"epoch": 30, "training_loss": 323.8450012207031, "training_acc": 72.0, "val_loss": 205.24024963378906, "val_acc": 28.0}
{"epoch": 31, "training_loss": 744.1371402740479, "training_acc": 28.0, "val_loss": 83.86160135269165, "val_acc": 72.0}
{"epoch": 32, "training_loss": 542.1086616516113, "training_acc": 72.0, "val_loss": 196.14815711975098, "val_acc": 72.0}
