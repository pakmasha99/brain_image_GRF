"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 4199.613739013672, "training_acc": 42.0, "val_loss": 2275.6088256835938, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7146.887893676758, "training_acc": 72.0, "val_loss": 1323.275089263916, "val_acc": 28.0}
{"epoch": 2, "training_loss": 4513.218078613281, "training_acc": 28.0, "val_loss": 723.1509685516357, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3727.8434143066406, "training_acc": 72.0, "val_loss": 1523.4572410583496, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5965.125534057617, "training_acc": 72.0, "val_loss": 1076.5192985534668, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3756.145580291748, "training_acc": 72.0, "val_loss": 736.2039566040039, "val_acc": 28.0}
{"epoch": 6, "training_loss": 2899.4206466674805, "training_acc": 28.0, "val_loss": 276.8819570541382, "val_acc": 72.0}
{"epoch": 7, "training_loss": 1353.2971954345703, "training_acc": 72.0, "val_loss": 603.1952857971191, "val_acc": 72.0}
{"epoch": 8, "training_loss": 2214.5387268066406, "training_acc": 72.0, "val_loss": 142.75050163269043, "val_acc": 72.0}
{"epoch": 9, "training_loss": 2064.9502716064453, "training_acc": 50.0, "val_loss": 774.5867252349854, "val_acc": 28.0}
{"epoch": 10, "training_loss": 2321.9969787597656, "training_acc": 44.0, "val_loss": 547.6022720336914, "val_acc": 72.0}
{"epoch": 11, "training_loss": 2328.5315475463867, "training_acc": 72.0, "val_loss": 555.7406425476074, "val_acc": 72.0}
{"epoch": 12, "training_loss": 1868.1105270385742, "training_acc": 72.0, "val_loss": 326.60415172576904, "val_acc": 28.0}
{"epoch": 13, "training_loss": 1070.1948051452637, "training_acc": 28.0, "val_loss": 477.1613121032715, "val_acc": 72.0}
{"epoch": 14, "training_loss": 2499.5735626220703, "training_acc": 72.0, "val_loss": 934.2041969299316, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3642.780014038086, "training_acc": 72.0, "val_loss": 629.5783996582031, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1858.8420372009277, "training_acc": 72.0, "val_loss": 781.3225746154785, "val_acc": 28.0}
{"epoch": 17, "training_loss": 3458.713836669922, "training_acc": 28.0, "val_loss": 21.145224571228027, "val_acc": 72.0}
{"epoch": 18, "training_loss": 559.6280479431152, "training_acc": 72.0, "val_loss": 297.2731351852417, "val_acc": 72.0}
{"epoch": 19, "training_loss": 1006.6462516784668, "training_acc": 72.0, "val_loss": 406.9833755493164, "val_acc": 28.0}
{"epoch": 20, "training_loss": 1039.3198852539062, "training_acc": 46.0, "val_loss": 151.91738605499268, "val_acc": 72.0}
{"epoch": 21, "training_loss": 584.2966346740723, "training_acc": 72.0, "val_loss": 214.99707698822021, "val_acc": 28.0}
{"epoch": 22, "training_loss": 752.73268699646, "training_acc": 44.0, "val_loss": 176.54882669448853, "val_acc": 72.0}
{"epoch": 23, "training_loss": 517.8529987335205, "training_acc": 72.0, "val_loss": 616.1403656005859, "val_acc": 28.0}
{"epoch": 24, "training_loss": 1798.1886386871338, "training_acc": 28.0, "val_loss": 520.8854675292969, "val_acc": 72.0}
{"epoch": 25, "training_loss": 2661.1698608398438, "training_acc": 72.0, "val_loss": 1047.3580360412598, "val_acc": 72.0}
{"epoch": 26, "training_loss": 4139.624771118164, "training_acc": 72.0, "val_loss": 832.2986602783203, "val_acc": 72.0}
{"epoch": 27, "training_loss": 2849.8582611083984, "training_acc": 72.0, "val_loss": 34.2229038476944, "val_acc": 72.0}
{"epoch": 28, "training_loss": 2252.357162475586, "training_acc": 54.0, "val_loss": 1651.8098831176758, "val_acc": 28.0}
{"epoch": 29, "training_loss": 5321.483436584473, "training_acc": 28.0, "val_loss": 430.53622245788574, "val_acc": 72.0}
{"epoch": 30, "training_loss": 2183.4732666015625, "training_acc": 72.0, "val_loss": 1206.418514251709, "val_acc": 72.0}
{"epoch": 31, "training_loss": 5122.590393066406, "training_acc": 72.0, "val_loss": 1265.2347564697266, "val_acc": 72.0}
{"epoch": 32, "training_loss": 4746.6890869140625, "training_acc": 72.0, "val_loss": 621.5147018432617, "val_acc": 72.0}
{"epoch": 33, "training_loss": 1879.1258583068848, "training_acc": 72.0, "val_loss": 1311.1034393310547, "val_acc": 28.0}
{"epoch": 34, "training_loss": 5588.214141845703, "training_acc": 28.0, "val_loss": 771.8192100524902, "val_acc": 28.0}
{"epoch": 35, "training_loss": 2534.4654541015625, "training_acc": 44.0, "val_loss": 846.7596054077148, "val_acc": 72.0}
{"epoch": 36, "training_loss": 3692.7854766845703, "training_acc": 72.0, "val_loss": 1162.6989364624023, "val_acc": 72.0}
