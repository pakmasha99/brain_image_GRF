"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 6096.8319664001465, "training_acc": 32.0, "val_loss": 2195.6214904785156, "val_acc": 72.0}
{"epoch": 1, "training_loss": 7051.5, "training_acc": 72.0, "val_loss": 684.4099521636963, "val_acc": 28.0}
{"epoch": 2, "training_loss": 2038.4884052276611, "training_acc": 28.0, "val_loss": 850.2205848693848, "val_acc": 72.0}
{"epoch": 3, "training_loss": 3751.088150024414, "training_acc": 72.0, "val_loss": 1453.8618087768555, "val_acc": 72.0}
{"epoch": 4, "training_loss": 5734.013275146484, "training_acc": 72.0, "val_loss": 997.9144096374512, "val_acc": 72.0}
{"epoch": 5, "training_loss": 3090.7733268737793, "training_acc": 72.0, "val_loss": 1109.4343185424805, "val_acc": 28.0}
{"epoch": 6, "training_loss": 4693.001815795898, "training_acc": 28.0, "val_loss": 68.203866481781, "val_acc": 28.0}
{"epoch": 7, "training_loss": 1117.4109725952148, "training_acc": 48.0, "val_loss": 1452.9064178466797, "val_acc": 72.0}
{"epoch": 8, "training_loss": 6464.938415527344, "training_acc": 72.0, "val_loss": 1955.3491592407227, "val_acc": 72.0}
{"epoch": 9, "training_loss": 7721.211181640625, "training_acc": 72.0, "val_loss": 1606.4104080200195, "val_acc": 72.0}
{"epoch": 10, "training_loss": 5700.558410644531, "training_acc": 72.0, "val_loss": 533.2308769226074, "val_acc": 72.0}
{"epoch": 11, "training_loss": 1749.5868911743164, "training_acc": 62.0, "val_loss": 997.2805976867676, "val_acc": 28.0}
{"epoch": 12, "training_loss": 2954.5642738342285, "training_acc": 28.0, "val_loss": 578.5955905914307, "val_acc": 72.0}
{"epoch": 13, "training_loss": 3263.852813720703, "training_acc": 72.0, "val_loss": 1249.6953010559082, "val_acc": 72.0}
{"epoch": 14, "training_loss": 4975.478546142578, "training_acc": 72.0, "val_loss": 1075.0922203063965, "val_acc": 72.0}
{"epoch": 15, "training_loss": 3897.0387115478516, "training_acc": 72.0, "val_loss": 279.270076751709, "val_acc": 72.0}
{"epoch": 16, "training_loss": 1622.8698120117188, "training_acc": 60.0, "val_loss": 963.5313034057617, "val_acc": 28.0}
{"epoch": 17, "training_loss": 2494.051983833313, "training_acc": 28.0, "val_loss": 715.7254695892334, "val_acc": 72.0}
{"epoch": 18, "training_loss": 3259.347023010254, "training_acc": 72.0, "val_loss": 1524.10249710083, "val_acc": 72.0}
{"epoch": 19, "training_loss": 6306.848175048828, "training_acc": 72.0, "val_loss": 1611.2220764160156, "val_acc": 72.0}
{"epoch": 20, "training_loss": 6099.9228515625, "training_acc": 72.0, "val_loss": 1022.6167678833008, "val_acc": 72.0}
{"epoch": 21, "training_loss": 3229.4314575195312, "training_acc": 72.0, "val_loss": 322.69842624664307, "val_acc": 28.0}
{"epoch": 22, "training_loss": 1997.8858032226562, "training_acc": 28.0, "val_loss": 30.257609486579895, "val_acc": 72.0}
{"epoch": 23, "training_loss": 308.26311111450195, "training_acc": 72.0, "val_loss": 127.1521806716919, "val_acc": 72.0}
{"epoch": 24, "training_loss": 608.6168365478516, "training_acc": 56.0, "val_loss": 165.71229696273804, "val_acc": 72.0}
{"epoch": 25, "training_loss": 775.2494163513184, "training_acc": 72.0, "val_loss": 105.56962490081787, "val_acc": 72.0}
{"epoch": 26, "training_loss": 942.6430206298828, "training_acc": 56.0, "val_loss": 36.31493151187897, "val_acc": 28.0}
{"epoch": 27, "training_loss": 464.1557502746582, "training_acc": 52.0, "val_loss": 766.7108058929443, "val_acc": 72.0}
{"epoch": 28, "training_loss": 3330.2946166992188, "training_acc": 72.0, "val_loss": 833.8362693786621, "val_acc": 72.0}
{"epoch": 29, "training_loss": 2919.367057800293, "training_acc": 72.0, "val_loss": 206.2931776046753, "val_acc": 72.0}
{"epoch": 30, "training_loss": 1664.5884857177734, "training_acc": 58.0, "val_loss": 992.088508605957, "val_acc": 28.0}
{"epoch": 31, "training_loss": 2548.224229812622, "training_acc": 28.0, "val_loss": 730.2462100982666, "val_acc": 72.0}
{"epoch": 32, "training_loss": 3741.3926544189453, "training_acc": 72.0, "val_loss": 1564.3349647521973, "val_acc": 72.0}
{"epoch": 33, "training_loss": 6419.063781738281, "training_acc": 72.0, "val_loss": 1602.357292175293, "val_acc": 72.0}
{"epoch": 34, "training_loss": 5997.3515625, "training_acc": 72.0, "val_loss": 986.5443229675293, "val_acc": 72.0}
{"epoch": 35, "training_loss": 3226.5079383850098, "training_acc": 72.0, "val_loss": 519.5338726043701, "val_acc": 28.0}
{"epoch": 36, "training_loss": 2558.0704956054688, "training_acc": 28.0, "val_loss": 115.8722996711731, "val_acc": 28.0}
{"epoch": 37, "training_loss": 1093.8743515014648, "training_acc": 46.0, "val_loss": 1082.9432487487793, "val_acc": 72.0}
{"epoch": 38, "training_loss": 4770.800201416016, "training_acc": 72.0, "val_loss": 1393.945026397705, "val_acc": 72.0}
{"epoch": 39, "training_loss": 5368.082763671875, "training_acc": 72.0, "val_loss": 988.7799263000488, "val_acc": 72.0}
{"epoch": 40, "training_loss": 3351.467414855957, "training_acc": 72.0, "val_loss": 62.47938275337219, "val_acc": 28.0}
{"epoch": 41, "training_loss": 685.3468742370605, "training_acc": 28.0, "val_loss": 226.4538288116455, "val_acc": 72.0}
