"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 97.62111949920654, "training_acc": 40.0, "val_loss": 26.741597056388855, "val_acc": 72.0}
{"epoch": 1, "training_loss": 93.51862406730652, "training_acc": 72.0, "val_loss": 17.525000870227814, "val_acc": 28.0}
{"epoch": 2, "training_loss": 77.77534484863281, "training_acc": 28.0, "val_loss": 16.955962777137756, "val_acc": 28.0}
{"epoch": 3, "training_loss": 63.81180238723755, "training_acc": 72.0, "val_loss": 18.345214426517487, "val_acc": 72.0}
{"epoch": 4, "training_loss": 76.09880590438843, "training_acc": 72.0, "val_loss": 18.35840791463852, "val_acc": 72.0}
{"epoch": 5, "training_loss": 69.2984688282013, "training_acc": 72.0, "val_loss": 15.260061621665955, "val_acc": 72.0}
{"epoch": 6, "training_loss": 69.30552124977112, "training_acc": 48.0, "val_loss": 17.111022770404816, "val_acc": 28.0}
{"epoch": 7, "training_loss": 65.14634919166565, "training_acc": 72.0, "val_loss": 15.567350387573242, "val_acc": 72.0}
{"epoch": 8, "training_loss": 63.563194274902344, "training_acc": 72.0, "val_loss": 17.158350348472595, "val_acc": 72.0}
{"epoch": 9, "training_loss": 66.87334251403809, "training_acc": 72.0, "val_loss": 14.921373128890991, "val_acc": 72.0}
{"epoch": 10, "training_loss": 62.05652141571045, "training_acc": 72.0, "val_loss": 16.523751616477966, "val_acc": 28.0}
{"epoch": 11, "training_loss": 64.97631406784058, "training_acc": 72.0, "val_loss": 14.86424058675766, "val_acc": 72.0}
{"epoch": 12, "training_loss": 58.714550733566284, "training_acc": 72.0, "val_loss": 15.867197513580322, "val_acc": 72.0}
{"epoch": 13, "training_loss": 63.420756816864014, "training_acc": 72.0, "val_loss": 15.486642718315125, "val_acc": 72.0}
{"epoch": 14, "training_loss": 61.33928084373474, "training_acc": 72.0, "val_loss": 14.999468624591827, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.9523229598999, "training_acc": 72.0, "val_loss": 15.296962857246399, "val_acc": 68.0}
{"epoch": 16, "training_loss": 60.592172384262085, "training_acc": 72.0, "val_loss": 14.859212934970856, "val_acc": 72.0}
{"epoch": 17, "training_loss": 63.42154121398926, "training_acc": 72.0, "val_loss": 15.516228973865509, "val_acc": 72.0}
{"epoch": 18, "training_loss": 60.49878716468811, "training_acc": 72.0, "val_loss": 14.997448027133942, "val_acc": 72.0}
{"epoch": 19, "training_loss": 59.61216068267822, "training_acc": 72.0, "val_loss": 16.083498299121857, "val_acc": 28.0}
{"epoch": 20, "training_loss": 63.226990938186646, "training_acc": 72.0, "val_loss": 14.82202559709549, "val_acc": 72.0}
{"epoch": 21, "training_loss": 59.142582416534424, "training_acc": 72.0, "val_loss": 15.684185922145844, "val_acc": 72.0}
{"epoch": 22, "training_loss": 62.28239393234253, "training_acc": 72.0, "val_loss": 14.970509707927704, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.161750078201294, "training_acc": 72.0, "val_loss": 15.355144441127777, "val_acc": 52.0}
{"epoch": 24, "training_loss": 61.369924545288086, "training_acc": 72.0, "val_loss": 14.93903249502182, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.07590413093567, "training_acc": 72.0, "val_loss": 15.243087708950043, "val_acc": 72.0}
{"epoch": 26, "training_loss": 61.94811940193176, "training_acc": 72.0, "val_loss": 15.00219851732254, "val_acc": 72.0}
{"epoch": 27, "training_loss": 60.95215845108032, "training_acc": 72.0, "val_loss": 15.336565673351288, "val_acc": 56.0}
{"epoch": 28, "training_loss": 60.76103234291077, "training_acc": 72.0, "val_loss": 14.817824959754944, "val_acc": 72.0}
{"epoch": 29, "training_loss": 61.548545598983765, "training_acc": 72.0, "val_loss": 15.077508985996246, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.297919511795044, "training_acc": 72.0, "val_loss": 15.039564669132233, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.01438856124878, "training_acc": 72.0, "val_loss": 15.206317603588104, "val_acc": 72.0}
{"epoch": 32, "training_loss": 60.65896129608154, "training_acc": 72.0, "val_loss": 14.86395001411438, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.4481999874115, "training_acc": 72.0, "val_loss": 14.872238039970398, "val_acc": 72.0}
{"epoch": 34, "training_loss": 59.40230584144592, "training_acc": 72.0, "val_loss": 14.878444373607635, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.238118171691895, "training_acc": 72.0, "val_loss": 14.816030859947205, "val_acc": 72.0}
{"epoch": 36, "training_loss": 60.20549392700195, "training_acc": 72.0, "val_loss": 14.878827333450317, "val_acc": 72.0}
{"epoch": 37, "training_loss": 58.74007225036621, "training_acc": 72.0, "val_loss": 15.088620781898499, "val_acc": 72.0}
{"epoch": 38, "training_loss": 60.0579195022583, "training_acc": 72.0, "val_loss": 15.044648945331573, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.378238916397095, "training_acc": 72.0, "val_loss": 15.032893419265747, "val_acc": 72.0}
{"epoch": 40, "training_loss": 60.08335471153259, "training_acc": 72.0, "val_loss": 15.431007742881775, "val_acc": 72.0}
{"epoch": 41, "training_loss": 60.36230683326721, "training_acc": 72.0, "val_loss": 14.940497279167175, "val_acc": 72.0}
{"epoch": 42, "training_loss": 60.48510456085205, "training_acc": 72.0, "val_loss": 15.321138501167297, "val_acc": 60.0}
{"epoch": 43, "training_loss": 59.582977294921875, "training_acc": 72.0, "val_loss": 15.279090404510498, "val_acc": 72.0}
{"epoch": 44, "training_loss": 60.59898543357849, "training_acc": 72.0, "val_loss": 15.640003979206085, "val_acc": 72.0}
{"epoch": 45, "training_loss": 61.844196796417236, "training_acc": 72.0, "val_loss": 14.859196543693542, "val_acc": 72.0}
{"epoch": 46, "training_loss": 62.79341459274292, "training_acc": 72.0, "val_loss": 15.717445313930511, "val_acc": 28.0}
{"epoch": 47, "training_loss": 62.62538981437683, "training_acc": 72.0, "val_loss": 15.43332040309906, "val_acc": 72.0}
{"epoch": 48, "training_loss": 62.00546884536743, "training_acc": 72.0, "val_loss": 14.968021214008331, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.4861376285553, "training_acc": 72.0, "val_loss": 15.606160461902618, "val_acc": 28.0}
{"epoch": 50, "training_loss": 61.498793840408325, "training_acc": 72.0, "val_loss": 14.807786047458649, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.091466665267944, "training_acc": 72.0, "val_loss": 15.205676853656769, "val_acc": 72.0}
{"epoch": 52, "training_loss": 59.9500093460083, "training_acc": 72.0, "val_loss": 14.834262430667877, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.61697292327881, "training_acc": 72.0, "val_loss": 15.22560864686966, "val_acc": 64.0}
{"epoch": 54, "training_loss": 60.66392946243286, "training_acc": 72.0, "val_loss": 14.93161916732788, "val_acc": 72.0}
{"epoch": 55, "training_loss": 59.34976625442505, "training_acc": 72.0, "val_loss": 14.827580749988556, "val_acc": 72.0}
{"epoch": 56, "training_loss": 58.45087289810181, "training_acc": 72.0, "val_loss": 15.074734389781952, "val_acc": 72.0}
{"epoch": 57, "training_loss": 60.0747287273407, "training_acc": 72.0, "val_loss": 14.806750416755676, "val_acc": 72.0}
{"epoch": 58, "training_loss": 60.07619571685791, "training_acc": 72.0, "val_loss": 15.128333866596222, "val_acc": 72.0}
{"epoch": 59, "training_loss": 59.50357389450073, "training_acc": 72.0, "val_loss": 14.913548529148102, "val_acc": 72.0}
{"epoch": 60, "training_loss": 59.188366413116455, "training_acc": 72.0, "val_loss": 15.001998841762543, "val_acc": 72.0}
{"epoch": 61, "training_loss": 59.93014454841614, "training_acc": 72.0, "val_loss": 14.804285764694214, "val_acc": 72.0}
{"epoch": 62, "training_loss": 58.76349759101868, "training_acc": 72.0, "val_loss": 14.804986119270325, "val_acc": 72.0}
{"epoch": 63, "training_loss": 58.80757284164429, "training_acc": 72.0, "val_loss": 14.825432002544403, "val_acc": 72.0}
{"epoch": 64, "training_loss": 58.58432126045227, "training_acc": 72.0, "val_loss": 14.898931980133057, "val_acc": 72.0}
{"epoch": 65, "training_loss": 59.879246950149536, "training_acc": 72.0, "val_loss": 14.80458676815033, "val_acc": 72.0}
{"epoch": 66, "training_loss": 59.427802324295044, "training_acc": 72.0, "val_loss": 15.168757736682892, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.798755407333374, "training_acc": 72.0, "val_loss": 14.833436906337738, "val_acc": 72.0}
{"epoch": 68, "training_loss": 58.93008065223694, "training_acc": 72.0, "val_loss": 14.84302282333374, "val_acc": 72.0}
{"epoch": 69, "training_loss": 58.54409861564636, "training_acc": 72.0, "val_loss": 14.929015934467316, "val_acc": 72.0}
{"epoch": 70, "training_loss": 59.075278759002686, "training_acc": 72.0, "val_loss": 14.848476648330688, "val_acc": 72.0}
{"epoch": 71, "training_loss": 59.49491310119629, "training_acc": 72.0, "val_loss": 14.837129414081573, "val_acc": 72.0}
{"epoch": 72, "training_loss": 59.23019862174988, "training_acc": 72.0, "val_loss": 14.821653068065643, "val_acc": 72.0}
{"epoch": 73, "training_loss": 58.78221607208252, "training_acc": 72.0, "val_loss": 14.805558323860168, "val_acc": 72.0}
{"epoch": 74, "training_loss": 59.925737380981445, "training_acc": 72.0, "val_loss": 14.806200563907623, "val_acc": 72.0}
{"epoch": 75, "training_loss": 58.86810755729675, "training_acc": 72.0, "val_loss": 14.942193031311035, "val_acc": 72.0}
{"epoch": 76, "training_loss": 60.87363386154175, "training_acc": 72.0, "val_loss": 14.812692999839783, "val_acc": 72.0}
{"epoch": 77, "training_loss": 58.388084173202515, "training_acc": 72.0, "val_loss": 14.923417568206787, "val_acc": 72.0}
{"epoch": 78, "training_loss": 59.15816855430603, "training_acc": 72.0, "val_loss": 14.805445075035095, "val_acc": 72.0}
{"epoch": 79, "training_loss": 58.514188051223755, "training_acc": 72.0, "val_loss": 14.804193377494812, "val_acc": 72.0}
{"epoch": 80, "training_loss": 58.406604290008545, "training_acc": 72.0, "val_loss": 14.81415182352066, "val_acc": 72.0}
{"epoch": 81, "training_loss": 58.56594109535217, "training_acc": 72.0, "val_loss": 14.804159104824066, "val_acc": 72.0}
{"epoch": 82, "training_loss": 58.52680540084839, "training_acc": 72.0, "val_loss": 14.792037010192871, "val_acc": 72.0}
{"epoch": 83, "training_loss": 59.613239765167236, "training_acc": 72.0, "val_loss": 14.794100821018219, "val_acc": 72.0}
{"epoch": 84, "training_loss": 58.08087205886841, "training_acc": 72.0, "val_loss": 15.225642919540405, "val_acc": 72.0}
{"epoch": 85, "training_loss": 60.03242254257202, "training_acc": 72.0, "val_loss": 14.805868268013, "val_acc": 72.0}
{"epoch": 86, "training_loss": 58.31880497932434, "training_acc": 72.0, "val_loss": 14.88296091556549, "val_acc": 72.0}
{"epoch": 87, "training_loss": 59.210923194885254, "training_acc": 72.0, "val_loss": 14.818848669528961, "val_acc": 72.0}
{"epoch": 88, "training_loss": 59.40759873390198, "training_acc": 72.0, "val_loss": 15.06381630897522, "val_acc": 72.0}
{"epoch": 89, "training_loss": 60.704312324523926, "training_acc": 72.0, "val_loss": 14.860500395298004, "val_acc": 72.0}
{"epoch": 90, "training_loss": 58.70301961898804, "training_acc": 72.0, "val_loss": 15.027229487895966, "val_acc": 72.0}
{"epoch": 91, "training_loss": 62.51972579956055, "training_acc": 72.0, "val_loss": 14.92817997932434, "val_acc": 72.0}
{"epoch": 92, "training_loss": 59.3549268245697, "training_acc": 72.0, "val_loss": 15.802471339702606, "val_acc": 28.0}
{"epoch": 93, "training_loss": 62.62781643867493, "training_acc": 72.0, "val_loss": 14.879333972930908, "val_acc": 72.0}
{"epoch": 94, "training_loss": 59.31308174133301, "training_acc": 72.0, "val_loss": 14.799046516418457, "val_acc": 72.0}
{"epoch": 95, "training_loss": 60.67439246177673, "training_acc": 72.0, "val_loss": 14.863219857215881, "val_acc": 72.0}
{"epoch": 96, "training_loss": 58.53943586349487, "training_acc": 72.0, "val_loss": 15.215736627578735, "val_acc": 72.0}
{"epoch": 97, "training_loss": 60.11563587188721, "training_acc": 72.0, "val_loss": 14.816996455192566, "val_acc": 72.0}
{"epoch": 98, "training_loss": 58.26318573951721, "training_acc": 72.0, "val_loss": 15.709991753101349, "val_acc": 28.0}
{"epoch": 99, "training_loss": 60.823710918426514, "training_acc": 72.0, "val_loss": 15.075665712356567, "val_acc": 72.0}
{"epoch": 100, "training_loss": 59.34558439254761, "training_acc": 72.0, "val_loss": 15.534281730651855, "val_acc": 72.0}
{"epoch": 101, "training_loss": 59.905986070632935, "training_acc": 72.0, "val_loss": 15.088029205799103, "val_acc": 68.0}
