"main_optuna_fix.py --pretrained_path None --mode finetuning --train_num 100 --layer_control freeze --stratify strat --random_seed 0 --task ADNI_ALZ_ADCN --input_option yAware --batch_size 64 --save_path finetune_test_same_seed --binary_class True --run_where sdcc"
{"epoch": 0, "training_loss": 92.82512140274048, "training_acc": 42.0, "val_loss": 26.656195521354675, "val_acc": 72.0}
{"epoch": 1, "training_loss": 89.50302839279175, "training_acc": 72.0, "val_loss": 19.838473200798035, "val_acc": 28.0}
{"epoch": 2, "training_loss": 90.25001764297485, "training_acc": 28.0, "val_loss": 16.57351851463318, "val_acc": 28.0}
{"epoch": 3, "training_loss": 65.19458627700806, "training_acc": 72.0, "val_loss": 20.122794806957245, "val_acc": 72.0}
{"epoch": 4, "training_loss": 83.53437829017639, "training_acc": 72.0, "val_loss": 20.22707313299179, "val_acc": 72.0}
{"epoch": 5, "training_loss": 78.76359915733337, "training_acc": 72.0, "val_loss": 14.82754796743393, "val_acc": 72.0}
{"epoch": 6, "training_loss": 61.94720816612244, "training_acc": 72.0, "val_loss": 17.855949699878693, "val_acc": 28.0}
{"epoch": 7, "training_loss": 68.9769058227539, "training_acc": 50.0, "val_loss": 14.815126359462738, "val_acc": 72.0}
{"epoch": 8, "training_loss": 61.62095236778259, "training_acc": 72.0, "val_loss": 17.248840630054474, "val_acc": 72.0}
{"epoch": 9, "training_loss": 68.61959838867188, "training_acc": 72.0, "val_loss": 15.870881080627441, "val_acc": 72.0}
{"epoch": 10, "training_loss": 62.0886869430542, "training_acc": 72.0, "val_loss": 15.072835981845856, "val_acc": 72.0}
{"epoch": 11, "training_loss": 61.54950666427612, "training_acc": 72.0, "val_loss": 15.801487863063812, "val_acc": 28.0}
{"epoch": 12, "training_loss": 61.79397940635681, "training_acc": 72.0, "val_loss": 14.878197014331818, "val_acc": 72.0}
{"epoch": 13, "training_loss": 58.994354367256165, "training_acc": 72.0, "val_loss": 15.859413146972656, "val_acc": 72.0}
{"epoch": 14, "training_loss": 63.805867433547974, "training_acc": 72.0, "val_loss": 15.187433362007141, "val_acc": 72.0}
{"epoch": 15, "training_loss": 59.3798611164093, "training_acc": 72.0, "val_loss": 15.498307347297668, "val_acc": 28.0}
{"epoch": 16, "training_loss": 62.30280327796936, "training_acc": 72.0, "val_loss": 15.506789088249207, "val_acc": 28.0}
{"epoch": 17, "training_loss": 60.484638929367065, "training_acc": 72.0, "val_loss": 15.025299787521362, "val_acc": 72.0}
{"epoch": 18, "training_loss": 63.18026804924011, "training_acc": 72.0, "val_loss": 15.948261320590973, "val_acc": 72.0}
{"epoch": 19, "training_loss": 63.775455951690674, "training_acc": 72.0, "val_loss": 14.812803268432617, "val_acc": 72.0}
{"epoch": 20, "training_loss": 60.11110877990723, "training_acc": 72.0, "val_loss": 15.150430798530579, "val_acc": 72.0}
{"epoch": 21, "training_loss": 61.07106375694275, "training_acc": 72.0, "val_loss": 14.802974462509155, "val_acc": 72.0}
{"epoch": 22, "training_loss": 59.24755907058716, "training_acc": 72.0, "val_loss": 14.830915629863739, "val_acc": 72.0}
{"epoch": 23, "training_loss": 59.34337759017944, "training_acc": 72.0, "val_loss": 14.782871305942535, "val_acc": 72.0}
{"epoch": 24, "training_loss": 59.10826826095581, "training_acc": 72.0, "val_loss": 14.783070981502533, "val_acc": 72.0}
{"epoch": 25, "training_loss": 59.16454315185547, "training_acc": 72.0, "val_loss": 14.777697622776031, "val_acc": 72.0}
{"epoch": 26, "training_loss": 59.1919641494751, "training_acc": 72.0, "val_loss": 14.775136113166809, "val_acc": 72.0}
{"epoch": 27, "training_loss": 59.07240390777588, "training_acc": 72.0, "val_loss": 14.786531031131744, "val_acc": 72.0}
{"epoch": 28, "training_loss": 59.18689465522766, "training_acc": 72.0, "val_loss": 14.773623645305634, "val_acc": 72.0}
{"epoch": 29, "training_loss": 59.064082622528076, "training_acc": 72.0, "val_loss": 14.768821001052856, "val_acc": 72.0}
{"epoch": 30, "training_loss": 59.666508197784424, "training_acc": 72.0, "val_loss": 14.771530032157898, "val_acc": 72.0}
{"epoch": 31, "training_loss": 60.824233293533325, "training_acc": 72.0, "val_loss": 14.816385507583618, "val_acc": 72.0}
{"epoch": 32, "training_loss": 60.1764030456543, "training_acc": 72.0, "val_loss": 14.941450953483582, "val_acc": 72.0}
{"epoch": 33, "training_loss": 59.59109568595886, "training_acc": 72.0, "val_loss": 14.812101423740387, "val_acc": 72.0}
{"epoch": 34, "training_loss": 60.554619789123535, "training_acc": 72.0, "val_loss": 15.056443214416504, "val_acc": 72.0}
{"epoch": 35, "training_loss": 59.76261258125305, "training_acc": 72.0, "val_loss": 14.92953896522522, "val_acc": 72.0}
{"epoch": 36, "training_loss": 60.30683612823486, "training_acc": 72.0, "val_loss": 14.822211861610413, "val_acc": 72.0}
{"epoch": 37, "training_loss": 61.630616903305054, "training_acc": 72.0, "val_loss": 14.936849474906921, "val_acc": 72.0}
{"epoch": 38, "training_loss": 59.32303166389465, "training_acc": 72.0, "val_loss": 14.85207974910736, "val_acc": 72.0}
{"epoch": 39, "training_loss": 59.60543394088745, "training_acc": 72.0, "val_loss": 15.040667355060577, "val_acc": 72.0}
{"epoch": 40, "training_loss": 60.21624779701233, "training_acc": 72.0, "val_loss": 14.755348861217499, "val_acc": 72.0}
{"epoch": 41, "training_loss": 59.203837871551514, "training_acc": 72.0, "val_loss": 14.779530465602875, "val_acc": 72.0}
{"epoch": 42, "training_loss": 59.194409132003784, "training_acc": 72.0, "val_loss": 14.733164012432098, "val_acc": 72.0}
{"epoch": 43, "training_loss": 59.25609517097473, "training_acc": 72.0, "val_loss": 14.737974107265472, "val_acc": 72.0}
{"epoch": 44, "training_loss": 59.02485227584839, "training_acc": 72.0, "val_loss": 14.80284035205841, "val_acc": 72.0}
{"epoch": 45, "training_loss": 59.081496715545654, "training_acc": 72.0, "val_loss": 14.74812626838684, "val_acc": 72.0}
{"epoch": 46, "training_loss": 59.876383781433105, "training_acc": 72.0, "val_loss": 14.744459092617035, "val_acc": 72.0}
{"epoch": 47, "training_loss": 59.945565700531006, "training_acc": 72.0, "val_loss": 14.895054697990417, "val_acc": 72.0}
{"epoch": 48, "training_loss": 59.951924085617065, "training_acc": 72.0, "val_loss": 14.732111990451813, "val_acc": 72.0}
{"epoch": 49, "training_loss": 59.07564663887024, "training_acc": 72.0, "val_loss": 14.72003161907196, "val_acc": 72.0}
{"epoch": 50, "training_loss": 58.87250089645386, "training_acc": 72.0, "val_loss": 14.83934223651886, "val_acc": 72.0}
{"epoch": 51, "training_loss": 59.319865465164185, "training_acc": 72.0, "val_loss": 14.748455584049225, "val_acc": 72.0}
{"epoch": 52, "training_loss": 58.92735004425049, "training_acc": 72.0, "val_loss": 14.736789464950562, "val_acc": 72.0}
{"epoch": 53, "training_loss": 59.79681324958801, "training_acc": 72.0, "val_loss": 14.726153016090393, "val_acc": 72.0}
{"epoch": 54, "training_loss": 59.270517349243164, "training_acc": 72.0, "val_loss": 15.042053163051605, "val_acc": 72.0}
{"epoch": 55, "training_loss": 60.367592096328735, "training_acc": 72.0, "val_loss": 14.721764624118805, "val_acc": 72.0}
{"epoch": 56, "training_loss": 59.42254638671875, "training_acc": 72.0, "val_loss": 14.698942005634308, "val_acc": 72.0}
{"epoch": 57, "training_loss": 58.59735870361328, "training_acc": 72.0, "val_loss": 14.995284378528595, "val_acc": 72.0}
{"epoch": 58, "training_loss": 61.15531826019287, "training_acc": 72.0, "val_loss": 14.695152640342712, "val_acc": 72.0}
{"epoch": 59, "training_loss": 60.75733137130737, "training_acc": 72.0, "val_loss": 15.29596596956253, "val_acc": 48.0}
{"epoch": 60, "training_loss": 59.655219316482544, "training_acc": 72.0, "val_loss": 15.326184034347534, "val_acc": 72.0}
{"epoch": 61, "training_loss": 61.64081025123596, "training_acc": 72.0, "val_loss": 15.320566296577454, "val_acc": 72.0}
{"epoch": 62, "training_loss": 59.966617822647095, "training_acc": 72.0, "val_loss": 15.223133563995361, "val_acc": 60.0}
{"epoch": 63, "training_loss": 61.09581017494202, "training_acc": 72.0, "val_loss": 15.013101696968079, "val_acc": 72.0}
{"epoch": 64, "training_loss": 59.69182014465332, "training_acc": 72.0, "val_loss": 14.814992249011993, "val_acc": 72.0}
{"epoch": 65, "training_loss": 61.540406227111816, "training_acc": 72.0, "val_loss": 14.717264473438263, "val_acc": 72.0}
{"epoch": 66, "training_loss": 62.115500926971436, "training_acc": 72.0, "val_loss": 15.061405301094055, "val_acc": 72.0}
{"epoch": 67, "training_loss": 59.03307294845581, "training_acc": 72.0, "val_loss": 15.3211310505867, "val_acc": 72.0}
{"epoch": 68, "training_loss": 61.20693242549896, "training_acc": 72.0, "val_loss": 15.283539891242981, "val_acc": 72.0}
{"epoch": 69, "training_loss": 60.33682560920715, "training_acc": 72.0, "val_loss": 14.749453961849213, "val_acc": 72.0}
{"epoch": 70, "training_loss": 61.531232595443726, "training_acc": 72.0, "val_loss": 14.701201021671295, "val_acc": 72.0}
{"epoch": 71, "training_loss": 60.844844818115234, "training_acc": 72.0, "val_loss": 15.320269763469696, "val_acc": 72.0}
{"epoch": 72, "training_loss": 62.53745651245117, "training_acc": 72.0, "val_loss": 14.667753875255585, "val_acc": 72.0}
{"epoch": 73, "training_loss": 60.29210162162781, "training_acc": 72.0, "val_loss": 14.723187685012817, "val_acc": 72.0}
{"epoch": 74, "training_loss": 60.54571557044983, "training_acc": 72.0, "val_loss": 14.727537333965302, "val_acc": 72.0}
{"epoch": 75, "training_loss": 59.598551750183105, "training_acc": 72.0, "val_loss": 15.141667425632477, "val_acc": 72.0}
{"epoch": 76, "training_loss": 60.4621217250824, "training_acc": 72.0, "val_loss": 14.648294448852539, "val_acc": 72.0}
{"epoch": 77, "training_loss": 58.54832887649536, "training_acc": 72.0, "val_loss": 14.767612516880035, "val_acc": 72.0}
{"epoch": 78, "training_loss": 59.06442213058472, "training_acc": 72.0, "val_loss": 14.651617407798767, "val_acc": 72.0}
{"epoch": 79, "training_loss": 58.560983657836914, "training_acc": 72.0, "val_loss": 14.727126061916351, "val_acc": 72.0}
{"epoch": 80, "training_loss": 59.407636404037476, "training_acc": 72.0, "val_loss": 14.641223847866058, "val_acc": 72.0}
{"epoch": 81, "training_loss": 58.2605984210968, "training_acc": 72.0, "val_loss": 15.103040635585785, "val_acc": 76.0}
{"epoch": 82, "training_loss": 60.55832242965698, "training_acc": 72.0, "val_loss": 14.641319215297699, "val_acc": 72.0}
{"epoch": 83, "training_loss": 60.590320110321045, "training_acc": 72.0, "val_loss": 15.10837972164154, "val_acc": 72.0}
{"epoch": 84, "training_loss": 59.189637184143066, "training_acc": 72.0, "val_loss": 15.099477767944336, "val_acc": 72.0}
{"epoch": 85, "training_loss": 61.72085952758789, "training_acc": 72.0, "val_loss": 14.687535166740417, "val_acc": 72.0}
{"epoch": 86, "training_loss": 60.84465789794922, "training_acc": 72.0, "val_loss": 15.414968132972717, "val_acc": 72.0}
{"epoch": 87, "training_loss": 60.9859344959259, "training_acc": 72.0, "val_loss": 14.702150225639343, "val_acc": 72.0}
{"epoch": 88, "training_loss": 59.25027942657471, "training_acc": 72.0, "val_loss": 14.72613662481308, "val_acc": 72.0}
{"epoch": 89, "training_loss": 58.47130346298218, "training_acc": 72.0, "val_loss": 14.999556541442871, "val_acc": 72.0}
{"epoch": 90, "training_loss": 60.95928168296814, "training_acc": 72.0, "val_loss": 14.709405601024628, "val_acc": 72.0}
{"epoch": 91, "training_loss": 58.06636452674866, "training_acc": 72.0, "val_loss": 15.56321382522583, "val_acc": 28.0}
{"epoch": 92, "training_loss": 61.652400970458984, "training_acc": 72.0, "val_loss": 14.645572006702423, "val_acc": 72.0}
{"epoch": 93, "training_loss": 59.998027324676514, "training_acc": 72.0, "val_loss": 15.204128623008728, "val_acc": 72.0}
{"epoch": 94, "training_loss": 59.432018756866455, "training_acc": 72.0, "val_loss": 15.050067007541656, "val_acc": 76.0}
{"epoch": 95, "training_loss": 60.767582654953, "training_acc": 72.0, "val_loss": 14.80409950017929, "val_acc": 72.0}
{"epoch": 96, "training_loss": 59.73086452484131, "training_acc": 72.0, "val_loss": 15.102919936180115, "val_acc": 72.0}
{"epoch": 97, "training_loss": 61.59294605255127, "training_acc": 72.0, "val_loss": 14.677020907402039, "val_acc": 72.0}
{"epoch": 98, "training_loss": 67.6484727859497, "training_acc": 46.0, "val_loss": 14.877036213874817, "val_acc": 72.0}
{"epoch": 99, "training_loss": 59.1067898273468, "training_acc": 72.0, "val_loss": 17.021450400352478, "val_acc": 72.0}
